Unsupervised Sense Disambiguation Using Bilingual Probabilistic Models
Indrajit Bhattacharya
Dept. of Computer Science
University of Maryland
College Park, MD,
USA
indrajit@cs.umd.edu
Lise Getoor
Dept. of Computer Science
University of Maryland
College Park, MD,
USA
getoor@cs.umd.edu
Yoshua Bengio
Dept. IRO
Universit?e de Montr?eal
Montr?eal, Qu?ebec,
Canada
bengioy@IRO.UMontreal.CA
Abstract
We describe two probabilistic models for unsuper-
vised word-sense disambiguation using parallel cor-
pora. The first model, which we call the Sense
model, builds on the work of Diab and Resnik
(2002) that uses both parallel text and a sense in-
ventory for the target language, and recasts their ap-
proach in a probabilistic framework. The second
model, which we call the Concept model, is a hier-
archical model that uses a concept latent variable to
relate different language specific sense labels. We
show that both models improve performance on the
word sense disambiguation task over previous unsu-
pervised approaches, with the Concept model show-
ing the largest improvement. Furthermore, in learn-
ing the Concept model, as a by-product, we learn a
sense inventory for the parallel language.
1 Introduction
Word sense disambiguation (WSD) has been a cen-
tral question in the computational linguistics com-
munity since its inception. WSD is fundamental to
natural language understanding and is a useful in-
termediate step for many other language process-
ing tasks (Ide and Veronis, 1998). Many recent
approaches make use of ideas from statistical ma-
chine learning; the availability of shared sense defi-
nitions (e.g. WordNet (Fellbaum, 1998)) and recent
international competitions (Kilgarrif and Rosen-
zweig, 2000) have enabled researchers to compare
their results. Supervised approaches which make
use of a small hand-labeled training set (Bruce
and Wiebe, 1994; Yarowsky, 1993) typically out-
perform unsupervised approaches (Agirre et al,
2000; Litkowski, 2000; Lin, 2000; Resnik, 1997;
Yarowsky, 1992; Yarowsky, 1995), but tend to be
tuned to a specific corpus and are constrained by
scarcity of labeled data.
In an effort to overcome the difficulty of find-
ing sense-labeled training data, researchers have be-
gun investigating unsupervised approaches to word-
sense disambiguation. For example, the use of par-
allel corpora for sense tagging can help with word
sense disambiguation (Brown et al, 1991; Dagan,
1991; Dagan and Itai, 1994; Ide, 2000; Resnik and
Yarowsky, 1999). As an illustration of sense disam-
biguation from translation data, when the English
word bank is translated to Spanish as orilla, it is
clear that we are referring to the shore sense of bank,
rather than the nancial institution sense.
The main inspiration for our work is Diab and
Resnik (2002), who use translations and linguistic
knowledge for disambiguation and automatic sense
tagging. Bengio and Kermorvant (2003) present
a graphical model that is an attempt to formalize
probabilistically the main ideas in Diab and Resnik
(2002). They assume the same semantic hierarchy
(in particular, WordNet) for both the languages and
assign English words as well as their translations
to WordNet synsets. Here we present two variants
of the graphical model in Bengio and Kermorvant
(2003), along with a method to discover a cluster
structure for the Spanish senses. We also present
empirical word sense disambiguation results which
demonstrate the gain brought by this probabilistic
approach, even while only using the translated word
to provide disambiguation information.
Our first generative model, the Sense Model,
groups semantically related words from the two
languages into senses, and translations are gener-
ated by probabilistically choosing a sense and then
words from the sense. We show that this improves
on the results of Diab and Resnik (2002).
Our next model, which we call the Concept
Model, aims to improve on the above sense struc-
ture by modeling the senses of the two languages
separately and relating senses from both languages
through a higher-level, semantically less precise
concept. The intuition here is that not all of the
senses that are possible for a word will be relevant
for a concept. In other words, the distribution over
the senses of a word given a concept can be expected
to have a lower entropy than the distribution over
the senses of the word in the language as a whole.
In this paper, we look at translation data as a re-
source for identification of semantic concepts. Note
that actual translated word pairs are not always good
matches semantically, because the translation pro-
cess is not on a word by word basis. This intro-
duces a kind of noise in the translation, and an addi-
tional hidden variable to represent the shared mean-
ing helps to take it into account. Improved perfor-
mance over the Sense Model validates the use of
concepts in modeling translations.
An interesting by-product of the Concept Model
is a semantic structure for the secondary language.
This is automatically constructed using background
knowledge of the structure for the primary language
and the observed translation pairs. In the model,
words sharing the same sense are synonyms while
senses under the same concept are semantically re-
lated in the corpus. An investigation of the model
trained over real data reveals that it can indeed
group related words together.
It may be noted that predicting senses from trans-
lations need not necessarily be an end result in it-
self. As we have already mentioned, lack of labeled
data is a severe hindrance for supervised approaches
to word sense disambiguation. At the same time,
there is an abundance of bilingual documents and
many more can potentially be mined from the web.
It should be possible using our approach to (noisily)
assign sense tags to words in such documents, thus
providing huge resources of labeled data for super-
vised approaches to make use of.
For the rest of this paper, for simplicity we will
refer to the primary language of the parallel docu-
ment as English and to the secondary as Spanish.
The paper is organized as follows. We begin by for-
mally describing the models in Section 2. We de-
scribe our approach for constructing the senses and
concepts in Section 3. Our algorithm for learning
the model parameters is described in Section 4. We
present experimental results in Section 5 and our
analysis in Section 6. We conclude in Section 7.
2 Probabilistic Models for Parallel
Corpora
We motivate the use of a probabilistic model by il-
lustrating that disambiguation using translations is
possible even when a word has a unique transla-
tion. For example, according to WordNet, the word
prevention has two senses in English, which may
be abbreviated as hindrance (the act of hindering
or obstruction) and control (by prevention, e.g. the
control of a disease). It has a single translation in
our corpus, that being prevenci ?on. The first En-
glish sense, hindrance, also has other words like
bar that occur in the corpus and all of these other
words are observed to be translated in Spanish as
the word obstrucci?on. In addition, none of these
other words translate to prevenci ?on. So it is not
unreasonable to suppose that the intended sense for
prevention when translated as prevenci ?on is differ-
ent from that of bar. Therefore, the intended sense
is most likely to be control. At the very heart of
the reasoning is probabilistic analysis and indepen-
dence assumptions. We are assuming that senses
and words have certain occurrence probabilities and
that the choice of the word can be made indepen-
dently once the sense has been decided. This is the
flavor that we look to add to modeling parallel doc-
uments for sense disambiguation. We formally de-
scribe the two generative models that use these ideas
in Subsections 2.2 and 2.3.
T
We Ws
Te Ts
C
WsWeword
concept
sense
b) Concept Modela) Sense Model
Figure 1: Graphical Representations of the a) Sense
Model and the b) Concept Model
2.1 Notation
Throughout, we use uppercase letters to denote ran-
dom variables and lowercase letters to denote spe-
cific instances of the random variables. A transla-
tion pair is (   ,   ) where the subscript  and 
indicate the primary language (English) and the sec-
ondary language (Spanish).   	


and   
  
 The University of Maryland SENSEVAL-3 System Descriptions
Clara Cabezas, Indrajit Bhattacharya, and Philip Resnik
University of Maryland, College Park, MD 20742 USA
clarac@umiacs.umd.edu, indrajit@cs.umd.edu, resnik@umd.edu
Abstract
For SENSEVAL-3, the University of Maryland
(UMD) team focused on two primary issues: the
portability of sense disambigation across languages,
and the exploitation of real-world bilingual text as a
resource for unsupervised sense tagging. We vali-
dated the portability of our supervised disambigua-
tion approach by applying it in seven tasks (En-
glish, Basque, Catalan, Chinese, Romanian, Span-
ish, and ?multilingual? lexical samples), and we ex-
perimented with a new unsupervised algorithm for
sense modeling using parallel corpora.
1 Supervised Sense Tagging for Lexical
Samples
1.1 Tagging Framework
For the English, Basque, Catalan, Chinese, Roma-
nian, Spanish, and ?multilingual? lexical samples,
we employed the UMD-SST system developed for
SENSEVAL-2 (Cabezas et al, 2001); we refer the
reader to that paper for a detailed system descrip-
tion. Briefly, UMD-SST takes a supervised learning
approach, treating each word in a task?s vocabulary
as an independent problem of classification into that
word?s sense inventory. Each training and test item
is represented as a weighted feature vector, with di-
mensions corresponding to properties of the con-
text. As in SENSEVAL-2, our system supported the
following kinds of features:
  Local context. For each  = 1, 2, and 3, and for
each word  in the vocabulary, there is a fea-
ture  representing the presence of word
 at a distance of  words to the left of the word
being disambigated; there is a corresponding
set of features 	

 for the local context to
the right of the word.
  Wide context. Each word  in the training set
vocabulary has a corresponding feature indi-
cating its presence. For SENSEVAL-3, wide
context features were taken from the entire
training or test instance. In other settings, one
might make further distinctions, e.g. between
words in the same paragraph and words in the
document.
We also experimented with the following additional
kinds of features for English:
  Grammatical context. We use a syntactic de-
pendency parser (Lin, 1998) to produce, for
each word to be disambiguated, features iden-
tifying relevant syntactic relationships in the
sentence where it occurs. For example, in the
sentence The U.S. government announced a
new visa waiver policy, the word government
would have syntactic features like DET:THE,
MOD:U.S., and SUBJ-OF:ANNOUNCED.
  Expanded context. In information retrieval,
we and other researchers have found that it
can be useful to expand the representation of a
document to include informative words from
similar documents (Levow et al, 2001). In
a similar spirit, we create a set of expanded-
context features  by (a) treating the
WSD context as a bag of words, (b) issuing it
as a query to a standard information retrieval
system that has indexed a large collection
of documents, and (c) including the non-
stopword vocabulary of the top  documents
returned. So, for example, in a context
containing the sentence The U.S. government
announced a new visa waiver policy, the query
might retrieve news articles like ?US to Ex-
tend Fingerprinting to Europeans, Japanese?
(Bloomberg.com, April 2, 2004), leading to
the addition of features like EXT:EUROPEAN,
EXT:JAPANESE, EXT:FINGERPRINTING
EXT:VISITORS, EXT:TOURISM, and so forth.
                                             Association for Computational Linguistics
                        for the Semantic Analysis of Text, Barcelona, Spain, July 2004
                 SENSEVAL-3: Third International Workshop on the Evaluation of Systems
Lexical Sample Coarse (prec/rec) Fine (prec/rec)
UMD-SST 0.643/0.643 0.568/0.568
UMD-SST-gram 0.600/0.600 0.576/0.576
UMD-SST-docexp 0.541/0.542 0.516/0.491
Table 1: UMD-SST variations on the SENSEVAL-2
English lexical sample task
As described by Cabezas et al (2001), we have
adopted the framework of support vector machines
(SVMs) in order to perform supervised classifica-
tion. Because we used a version of SVM learn-
ing designed for binary classification tasks, rather
than the multi-way classification needed for disam-
biguating among   senses, we constructed a family
of SVM classifiers for each word  ? one for each
of the word?s   senses. All positive training ex-
amples for a sense   of  were treated as negative
training examples for all the other senses  , 	  .
Table 1 shows the performance of our approach
on the English lexical sample task from the previ-
ous SENSEVAL exercise (SENSEVAL-2), includ-
ing the basic system (UMD-SST), the basic sys-
tem with grammatical features added (UMD-SST-
gram), and the basic system with document expan-
sion features added (UMD-SST-docexp). (We have
not done a run with both sets of features added.) The
results showed a possible potential benefit for us-
ing grammatical features, in the fine-grained scor-
ing. However, we deemed the benefit too small to
rely upon, and submitted our official SENSEVAL-3
runs using UMD-SST without the grammatical or
document-expansion features.
1.2 SENSEVAL-3 Lexical Sample Tasks
For SENSEVAL-3, the modularity of our system
made it very easy to participate in the many lex-
ical sample tasks, including the multilingual lexi-
cal sample, where the ?sense inventory? consisted
of vocabulary items from a second language.1 In-
deed, we participated in several tasks without hav-
ing anyone on the team who could read the lan-
guage. (Whether or not this was a good idea remains
to be seen.) For Basque, Catalan, and Spanish, we
used the lemmatized word forms provided by the
task organizers; for the other languages, including
English, we used only simple tokenization.
Table 2 shows the UMD-SST system?s official
1Data format problems prevented us from participating in
the Italian lexical sample task.
Lexical Sample Precision (%) Recall (%)
Basque 65.6 58.7
Catalan 81.5 80.3
Chinese 51.3 51.2
English 66.0 66.0
Romanian 70.7 70.7
Spanish 82.5 82.5
Multilingual 58.8 58.8
Table 2: UMD-SST results (fine-grained) on
SENSEVAL-3 lexical sample tasks
Lexical Sample Coarse (prec/rec) Fine (prec/rec)
UMD-SST 0.709/0.709 0.660/0.660
UMD-SST-gram 0.703/0.703 0.655/0.655
UMD-SST-docexp 0.691/0.680 0.637/0.627
Table 3: UMD-SST variations on the SENSEVAL-3
English lexical sample task
SENSEVAL-3 performance on the lexical sample
runs in which we participated, using fine-grained
scores.
In unofficial runs, we also experimented with
the grammatical and document-expansion features.
Table 3 shows the results, which indicate that on this
task the additional features did not help and may
have hurt performance slightly. Although we have
not yet reached any firm conclusions, we conjecture
that value potentially added by these features may
have been offset by the expansion in the size of the
feature space; in future work we plan to explore fea-
ture selection and alternative learning frameworks.
2 Unsupervised Sense Tagging using
Bilingual Text
2.1 Probabilistic Sense Model
For the past several years, the University of Mary-
land group has been exploring unsupervised ap-
proaches to word sense disambiguation that take ad-
vantage of parallel corpora (Diab and Resnik, 2002;
Diab, 2003). Recently, Bhattacharya et al (2004)
(in a UMD/Montreal collaboration) have developed
a variation on this bilingual approach that is in-
spired by the central insight of Diab?s work, but re-
casts it in a probabilistic framework. A generative
model, it is a variant of the graphical model of Ben-
gio and Kermorvant (2003), which groups seman-
tically related words from the two languages into
?senses?; translations are generated by probabilis-
tically choosing a sense and then words from the
sense.
Briefly, the model of Bhattacharya et al uses
probabilistic analysis and independence assump-
tions: it assumes that senses and words have cer-
tain occurrence probabilities and that the choice of
the word can be made independently once the sense
has been decided. Here interaction between dif-
ferent words arising from the same sense comes
into play, even if the words are not related through
translations, and this interdependence of the senses
through common words plays a role in sense disam-
biguation.
The model takes as its starting point the idea of a
?translation pair? ? a pair of words  and   that are
aligned in two sentences (here ?English? and ?non-
English?) that are translations of each other. For
example, in the English-Spanish sentence pair Me
gusta la ciudad/I like the city, one would find the
translation pairs  	 , 
      ,    
 ,
and   