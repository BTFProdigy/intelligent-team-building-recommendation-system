Message  C lass i f i ca t ion  in the  Ca l l  Center  
Stephan Busemann, Seen Schmeier~ Roman G. Arens 
DFKI GmbH 
Stuhlsatzenhausweg 3, D-66123 Saarbriicken, Germany 
e-mail: {busemann, schmeier, arens}@dfki.de 
Abstract 
Customer care in technical domains is increasingly 
based on e-mail communication, allowing for the re- 
production of approved solutions. Identifying the 
customer's problem is often time-consuming, as the 
problem space changes if new products are launched. 
This paper describes a new approach to the classifi- 
cation of e-mail requests based on shallow text pro- 
cessing and machine learning techniques. It is im- 
plemented within an assistance system for call center 
agents that is used in a commercial setting. 
1 I n t roduct ion  
Customer care in technical domains is increasingly 
based on e-mail communication, allowing for the re- 
production of approved solutions. For a call cen- 
ter agent, identifying the customer's problem is of- 
ten time-consuming, as the problem space changes 
if new products are launched or existing regulations 
are modified. The typical task of a call center agent 
processing e-mail requests consists of the following 
steps: 
Recogn ize  the  prob lem(s) :  read and understand 
the e-mail request; 
Search  a solut ion:  identify and select predefined 
text blocks; 
P rov ide  the  solut ion:  if necessary, customize 
text blocks to meet the current request, and 
send the text. 
This task can partly be automated by a system 
suggesting relevant solutions for an incoming e-mail. 
This would cover the first two steps. The last step 
can be delicate, as its primary goal is to keep the 
customer satisfied. Thus human intervention seems 
mandatory to allow for individual, customized an- 
swers. Such a system will 
? reduce the training effort required since agents 
don't have to know every possible solution for 
every possible problem; 
? increase the agents' performance since agents 
can more quickly select a solution among several 
offered than searching one; 
? improve the quality of responses ince agents 
will behave more homogeneously - both as a 
group and over time - and commit fewer errors. 
Given that free text about arbitrary topics must 
be processed, in-depth approaches to language un- 
derstanding are not feasible. Given further that the 
topics may change over time, a top-down approach 
to knowledge modeling is out of the question. Rather 
a combination of shallow text processing (STP) with 
statistics-based machine learning techniques (SML) 
is called for. STP gathers partial information about 
text such as part of speech, word stems, negations, 
or sentence type. These types of information can be 
used to identify the linguistic properties of a large 
training set of categorized e-mails. SML techniques 
are used to build a classifier that is used for new, 
incoming messages. Obviously, the change of topics 
can be accommodated by adding new categories and 
e-mails and producing a new classifier on the basis 
of old and new data. We call this replacement of a 
classifier "relearning". 
This paper describes a new approach to the clas- 
sification of e-mail requests along these lines. It is 
implemented within the ICe-MAIL system, which 
is an assistance system for call center agents that 
is currently used in a commercial setting. Section 2 
describes important properties of the input data, i.e. 
the e-mail texts on the one hand, and the categories 
on the other. These properties influenced the system 
architecture, which is presented in Section 3. Vari- 
ous publicly available SML systems have been tested 
with different methods of STP-based preprocessing. 
Section 4 describes the results. The implementation 
and usage of the system including the graphical user 
interface is presented in Section 5. We conclude by 
giving an outlook to further expected improvements 
(Section 6). 
2 Data  Character ist ics  
A closer look at the data the ICe-MAIL system is 
processing will clarify the task further. We carried 
out experiments with unmodified e-mail data accu- 
mulated over a period of three months in the call 
center database. The total amount was 4777 e-mails. 
158
We used 47 categories, which contained at least 30 
documents. This minimum amount of documents 
turned out to render the category sufficiently dis- 
tinguishable for the SML tools. The database con- 
tained 74 categories with at least 10 documents, but 
the selected ones covered 94% of all e-malls, i.e. 4490 
documents. 
It has not yet generally been investigated how the 
type of data influences the learning result (Yang, 
1999), or under which circumstances which kind of 
preprocessing and which learning algorithm is most 
appropriate. Several aspects must be considered: 
Length of the documents, morphological and syn- 
tactic well-formedness, the degree to which a docu- 
ment can be uniquely classified, and, of course, the 
language of the documents. 
In our application domain the documents differ 
very much from documents generally used in bench- 
mark tests, for example the Reuters corpus 1. First 
of all, we have to deal with German, whereas the 
Reuters data are in English. The average length of 
our e-mails is 60 words, whereas for documents of 
Reuters-21578 it is 129 words. The number of cat- 
egories we used compares to the top 47 categories 
of the Reuters TOPICS category set. While we 
have 5008 documents, TOPICS consists of 13321 in- 
stances 2. The Reuters documents usually are mor- 
phologically and syntactically well-formed. As e- 
mails are a more spontaneously created and infor- 
mal type of document, they require us to cope with 
a large amount of jargon, misspellings and gram- 
matical inaccuracy. A drastic example is shown in 
Figure 2. The bad conformance to linguistic stan- 
dards was a major argument in favor of STP instead 
of in-depth syntactic and semantic analysis. 
The degree to which a document can be uniquely 
classified is hard to verify and can only be inferred 
from the results in general terms. 3 It is, however, 
dependent on the ability to uniquely distinguish the 
classes. In our application we encounter overlapping 
and non-exhaustive categories as the category sys- 
tem develops over time. 
3 Integrating Language Technology 
With  Machine Learning 
STP and SML correspond to two different 
paradigms. STP tools used for classification tasks 
promise very high recall/precision or accuracy val- 
ues. Usually human experts define one or several 
template structures to be filled automatically by ex- 
tracting information from the documents (cf. e.g. 
(Ciravegna et al, 1999)). Afterwards, the partially 
lhttp ://~wv. research, a~t. com/'le~is/reuters21578. 
html 
2We took only uniquely classified ocuments into account.  
3Documents containing multiple requests can at present 
only be treated manually, as described in Section 5. 
filled templates are classified by hand-made rules. 
The whole process brings about high costs in analyz- 
ing and modeling the application domain, especially 
if it is to take into account he problem of changing 
categories in the present application. 
SML promises low costs both in analyzing and 
modeling the application at the expense of a lower 
accuracy. It is independent of the domain on the 
one hand, but does not consider any domain specific 
knowledge on the other. 
By combining both methodologies in ICe -MAIL ,  
we achieve high accuracy and can still preserve a use- 
ful degree of domain-independence. STP may use 
both general inguistic knowledge and linguistic al- 
gorithms or heuristics adapted to the application in 
order to extract information from texts that is rele- 
vant for classification. The input to the SML tool is 
enriched with that information. The tool builds one 
or several categorizers 4 that will classify new texts. 
In general, SML tools work with a vector epresen- 
tation of data. First, a relevancy vector of relevant 
features for each class is computed (Yang and Ped- 
ersen, 1997). In our case the relevant features con- 
sist of the user-defined output of the linguistic pre- 
processor. Then each single document is translated 
into a vector of numbers isomorphic to the defining 
vector. Each entry represents the occurrence of the 
corresponding feature. More details will be given in 
Section 4 
The ICe-MAIL architecture is shown in Figure 1. 
The workflow of the system consists of a learning 
step carried out off-line (the light gray box) and an 
online categorization step (the dark gray box). In 
the off-line part, categorizers are built by processing 
classified data first by an STP and then by an SML 
tool. In this way, categorizers can be replaced by the 
system administrator as she wants to include new 
or remove expired categories. The categorizers are 
used on-line in order to classify new documents after 
they have passed the linguistic preprocessing. The 
resulting category is in our application associated 
with a standard text that the call center agent uses 
in her answer. The on-line step provides new clas- 
sified data that is stored in a dedicated ICe-MAIL 
database (not shown in Figure 1). The relearning 
step is based on data from this database. 
3.1 Shal low Text  Processing 
Linguistic preprocessing of text documents is car- 
ried out by re-using sines, an information extrac- 
tion core system for real-world German text pro- 
cessing (Neumann et al, 1997). The fundamental 
design criterion of sines is to provide a set of basic, 
powerful, robust, and efficient STP components and 
4Almost all tools we examined build a single multi- 
categorizer except for SVM-Light, which builds multiple bi- 
nary classifiers. 
1 I ;Q  159
Cate gorY) 
J 
Figure 1: Architecture of the ICC-MAIL System. 
generic linguistic knowledge sources that can eas- 
ily be customized to deal with different asks in a 
flexible manner, sines includes a text tokenizer, a 
lexical processor and a chunk parser. The chunk 
parser itself is subdivided into three components. In 
the first step, phrasal fragments like general nominal 
expressions and verb groups are recognized. Next, 
the dependency-based structure of the fragments of 
each sentence is computed using a set of specific sen- 
tence patterns. Third, the grammatical functions 
are determined for each dependency-based structure 
on the basis of a large subcategorization lexicon. 
The present application benefits from the high mod- 
ularity of the usage of the components. Thus, it is 
possible to run only a subset of the components and 
to tailor their output. The experiments described in 
Section 4 make use of this feature. 
3.2 Statistics-Based Machine Learning 
Several SML tools representing different learning 
paradigms have been selected and evaluated in dif- 
ferent settings of our domain: 
Lazy Learning: Lazy Learners are also known 
as memory-based, instance-based, exemplar- 
based, case-based, experience-based, or k- 
nearest neighbor algorithms. They store all 
documents as vectors during the learning phase. 
In the categorization phase, the new document 
vector is compared to the stored ones and is 
categorized to same class as the k-nearest neigh- 
bors. The distance is measured by computing 
e.g. the Euclidean distance between the vectors. 
By changing the number of neighbors k or the 
kind of distance measure, the amount of gener- 
alization can be controlled. 
We used IB (Aha, 1992), which is part of 
the MLC++ library (Kohavi and Sommerfield, 
1996). 
Symbolic Eager Learning: This type of learners 
constructs a representation for document vec- 
tors belonging to a certain class during the 
learning phase, e.g. decision trees, decision rules 
or probability weightings. During the catego- 
rization phase, the representation is used to as- 
sign the appropriate class to a new document 
vector. Several pruning or specialization heuris- 
tics can be used to control the amount of gen- 
eralization. 
We used ID3 (Quinlan, 1986), C4.5 (Quinlan, 
1992) and C5.0, R IPPER (Cohen, 1995), and 
the Naive Bayes inducer (Good, 1965) con- 
tained in the MLCq-q- library. ID3, C4.5 and 
C5.0 produce decision trees, R IPPER i sa  rule- 
based learner and the Naive Bayes algorithm 
computes conditional probabilities of the classes 
from the instances. 
Support Vector Machines (SVMs) :  SVMs are 
described in (Vapnik, 1995). SVMs are binary 
learners in that they distinguish positive and 
negative examples for each class. Like eager 
learners, they construct a representation dur- 
ing the learning phase, namely a hyper plane 
supported by vectors of positive and negative 
examples. For each class, a categorizer is built 
by computing such a hyper plane. During the 
categorization phase, each categorizer is applied 
to the new document vector, yielding the prob- 
abilities of the document belonging to a class. 
The probability increases with the distance of 
thevector from the hyper plane. A document 
is said to belong to the class with the highest 
probability. 
We chose SVM_Light (Joachims, 1998). 
Neura l  Networks :  Neural Networks are a special 
kind of "non-symbolic" eager learning algo- 
1 60 
rithm. The neural network links the vector el- 
ements to the document categories The learn- 
ing phase defines thresholds for the activation 
of neurons. In the categorization phase, a new 
document vector leads to the activation of a sin- 
gle category. For details we refer to (Wiener et 
al., 1995). 
In our application, we tried out the Learning 
Vector Quantization (LVQ) (Kohonen et al, 
1996). LVQ has been used in its default config- 
uration only. No adaptation to the application 
domain has been made. 
4 Exper iments  and  Resu l ts  
We describe the experiments and results we achieved 
with different linguistic preprocessing and learning 
algorithms and provide some interpretations. 
We start out from the corpus of categorized e- 
mails described in Section 2. In order to normalize 
the vectors representing the preprocessing results of 
texts of different length, and to concentrate on rel- 
evant material (cf. (Yang and Pedersen, 1997)), we 
define the relevancy vector as follows. First, all doc- 
uments are preprocessed, yielding a list of results 
for each category. From each of these lists, the 100 
most frequent results - according to a TF / IDF  mea- 
sure - are selected. The relevancy vector consists of 
all selected results, where doubles are eliminated. 
Its length was about 2500 for the 47 categories; it 
slightly varied with the kind of preprocessing used. 
During the learning phase, each document is pre- 
processed. The result is mapped onto a vector of 
the same length as the relevancy vector. For ev- 
ery position in the relevancy vector, it is determined 
whether the corresponding result has been found. In 
that case, the value of the result vector element is 1, 
otherwise it is 0. 
In the categorization phase, the new document is 
preprocessed, and a result vector is built as described 
above and handed over to the categorizer (cf. Fig- 
ure 1). 
While we tried various kinds of linguistic prepro- 
cessing, systematic experiments have been carried 
out with morphological nalysis (MorphAna), shal- 
low parsing heuristics (STP-Heuristics), and a com- 
bination of both (Combined). 
MorphAna:  Morphological Analysis provided by 
sines yields the word stems of nouns, verbs and 
adjectives, as well as the full forms of unknown 
words. We are using a lexicon of approx. 100000 
word stems of German (Neumann et al, 1997). 
STP-Heur i s t i cs :  Shallow parsing techniques are 
used to heuristically identify sentences contain- 
ing relevant information. The e-mails usually 
contain questions and/or descriptions of prob- 
lems. The manual analysis of a sample of 
the data suggested some linguistic constructions 
frequently used to express the problem. We ex- 
pected that content words in these construc- 
tions should be particularly influential to the 
categorization. Words in these constructions 
are extracted and processed as in MorphAna, 
and all other words are ignored. 5 The heuris- 
tics were implemented in ICC-MAIL  using sines. 
The constructions of interest include negations 
at the sentence and the phrasal level, yes-no 
and wh-questions, and declaratives immediately 
preceding questions. Negations were found to 
describe a state to be changed or to refer to 
missing objects, as in I cannot read my email 
or There is no correct date. We identified them 
through negation particles. 8 Questions most of- 
ten refer to the problem in hand, either directly, 
e.g. How can I start my email program. ~ or in- 
directly, e.g. Why is this the case?. The lat- 
ter most likely refers to the preceding sentence, 
e.g. My system drops my e-mails. Questions are 
identified by their word order, i.e. yes-no ques- 
tions start with a verb and wh-questions with a 
wh-particle. 
Combined:  In order to emphasize words found 
relevant by the STP heuristics without losing 
other information retrieved by MorphAna, the 
previous two techniques are combined. Empha- 
sis is represented here by doubling the number 
of occurrences of the tokens in the normaliza- 
tion phase, thus increasing their TF / IDF  value. 
Call center agents judge the performance of ICC-  
MAIL  most easily in terms of accuracy: In what per- 
centage of cases does the classifier suggest the correct 
text block? In Table 1, detailed information about 
the accuracy achieved is presented. All experiments 
were carried out using 10-fold cross-validation  the 
data described in Section 2. 
In all experiments he SVM_Light system outper- 
formed other learning algorithms, which confirms 
Yang's (Yang and Liu, 1999) results for SVMs fed 
with Reuters data. The k-nearest neighbor algo- 
rithm IB performed surprisingly badly although dif- 
ferent values ofk were used. For IB, ID3, C4.5, C5.0, 
Naive Bayes, R IPPER and SVM_Light, linguis- 
tic preprocessing increased the overall performance. 
In fact, the method performing best, SVM_Light, 
gained 3.5% by including the task-oriented heuris- 
tics. However, the boosted R IPPER and LVQ scored 
a decreased accuracy value there. For LVQ the de- 
crease may be due to the fact that no adaptations to 
5If no results were found this way, MorphAna was applied 
instead. 
6We certainly would have benefited from lexical semantic 
information, e.g. The correct date is missing would not be 
captured by our approach. 
161 
Neural Nets 
Lazy Learner 
Symbolic Eager 
Learners 
Support Vectors \[\] 
SML algorithm 
LVQ 
IB 
Naive Bayes 
ID3 
R IPPER 
Boosted Ripper 
C4.5 
C5.0 
SVM_L ight  
MorphAna 
Best Best5 
35.66 
33.81 
33.83 
38.53 
47.08 
52.73 
52.00 
52.60 
53.85 74.91 
STP-Heuristics 
Best Best5 
22.29 
33.01 
33.76 
38.11 
49.38 
49.96 
52.90 
53.20 
54.84 78.05 
Combined 
Best Best5 
25.97 
35.14 
34.01 
40.02 
50.54 
50.78 
53.40 
54.20 
56.23 78.17 
Table 1: Results of Experiments. Most SML tools deliver the best result only. SVM_Light produces ranked 
results, allowing to measure the accuracy of the top five alternatives (Best5). 
the domain were made, such as adapting the number 
of codebook vectors, the initial learning parameters 
or the number of iterations during training (cf. (Ko- 
honen et al, 1996)). Neural networks are rather sen- 
sitive to misconfigurations. The boosting for RIP- 
PER seems to run into problems of overfitting. We 
noted that in six trials the accuracy could be im- 
proved in Combined compared to MorphAna, but in 
four trials, boosting led to deterioration. This effect 
is also mentioned in (Quinlan, 1996). 
These figures are slightly lower than the ones re- 
ported by (Neumann and Schmeier, 1999) that were 
obtained from a different data set. Moreover, these 
data did not contain multiple queries in one e-mall. 
It would be desirable to provide explanations for 
the behavior of the SML algorithms on our data. As 
we have emphasized in Section 2, general methods 
of explanation do not exist yet. In the application 
in hand, we found it difficult to account for the ef- 
fects of e.g. ungrammatical text or redundant cate- 
gories. For the time being, we can only offer some 
speculative and inconclusive assumptions: Some of 
the tools performing badly - IB, ID3, and the Naive 
Bayes inducer of the MLC++ library - have no or 
little pruning ability. With rarely occurring data, 
this leads to very low generalization rates, which 
again is a problem of overfitting. This suggests that 
a more canonical representation for the many ways 
of expressing a technical problem should be sought 
for. Would more extensive linguistic preprocessing 
help? 
Other tests not reported in Table 1 looked at im- 
provements hrough more general and sophisticated 
STP such as chunk parsing. The results were very 
discouraging, leading to a significant decrease com- 
pared to MorphAna. We explain this with the bad 
compliance of e-mall texts to grammatical standards 
(cf. the example in Figure 2). 
However, the practical usefulness of chunk parsing 
or even deeper language understanding such as se- 
mantic analysis may be questioned in general: In a 
moving domain, the coverage of linguistic knowledge 
will always be incomplete, as it would be too expen- 
sive for a call center to have language technology 
experts keep pace with the occurrence of new to~ 
ics. Thus the preprocessing results will often differ 
for e-mails expressing the same problem and hence 
not be useful for SML. 
As a result of the tests in our application domain, 
we identified a favorite statistical tool and found that 
task-specific linguistic preprocessing is encouraging, 
while general STP is not. 
5 Imp lementat ion  and  Use  
In this section we describe the integration of the 
ICC-MAIL system into the workflow of the call cen- 
ter of AOL Bertelsmann Online GmbH & Co. KG, 
which answers requests about the German version 
of AOL software. A client/server solution was built 
that allows the call center agents to connect as 
clients to the ICe-MAIL server, which implements 
the system described in Section 3. For this purpose, 
it was necessary to 
? connect the server module to AOL's own Sybase 
database that delivers the incoming mail and 
dispatches the outgoing answers, and to I ce -  
MAIL'S own database that stores the classified 
e-mall texts; 
? design the GUI of the client module in a self- 
explanatory and easy to use way (cf. Figure 2). 
The agent reads in an e-mall and starts ICe-MAIL 
using GUI buttons. She verifies the correctness of 
the suggested answer, displaying and perhaps se- 
lecting alternative solutions. If the agent finds the 
appropriate answer within these proposals, the asso- 
ciated text is filled in at the correct position of the 
answer e-mall. If, on the other hand, no proposed 
solution is found to be adequate, the ICe-MAIL tool 
can still be used to manually select any text block 
162 
0" ~ GPF 
~) ~ In~allatice, 
~AOL. 
\[~CD, $o'el~alt, Ha~du~te 
~) FAO - (fmlln 
r~ i$ON 
\[~ Me4em 
Before deinstalling the AOL-Soltware please check your folders for 
-downloaded data 
-saved passwords 
and copy them into a backup folder. 
Then remove the AOL-Software using the Windows Control Panel and 
reinstall it from your CD. 
Alter reinstallation please copy the data from the bac~p folder into 
the dght destinations. 
Figure 2: The GUI of the ICe-MAIL Client. All labels and texts were translated by the authors. The English 
input is based on the following original text, which is similarly awkward though understandable: Wie mache 
ich zurn mein Programm total deinstalieren, und wieder neu instalierem, mit, wen Sic mir senden Version 
4.0 ??????????????. The suggested answer text is associated with the category named "Delete & Reinstall 
AOL 4.0". Four alternative answers can be selected using the tabs. The left-hand side window displays the 
active category in context. 
from the database. The ICe-MAIL client had to pro- 
vide the functionality of the tool already in use since 
an additional tool was not acceptable to the agents, 
who are working under time pressure. 
In the answer e-mail window, the original e-mail 
is automatically added as a quote. If an e-mail con- 
tains several questions, the classification process can 
be repeated by marking each question and iteratively 
applying the process to the marked part. The agent 
can edit the suggested texts before sending them off. 
In each case, the classified text together with the se- 
lected category is stored in the ICe-MAIL database 
for use in future learning steps. 
Other features of the ICe-MAIL client module in- 
clude a spell checker and a history view. The latter 
displays not only the previous e-mails of the same 
author but also the solutions that have been pro- 
posed and the elapsed time before an answer was 
sent. 
The assumed average time for an agent to an- 
swer an e-mail is a bit more than two minutes with 
AOL's own mail processing system. ~With the ICC- 
MAIL system the complete cycle of fetching the mail, 
checking the proposed solutions, choosing the ap- 
propriate solutions, inserting additional text frag- 
ments and sending the answer back can probably 
be achieved in half the time. Systematic tests sup- 
~This system does not include automatic analysis of mails. 
porting this claim are not completed yet, s but the 
following preliminary results are encouraging: 
? A test under real-time conditions at the call- 
center envisaged the use of the ICe -MAIL  sys- 
tem as a mail tool only, i.e. without taking ad- 
vantage of the system's intelligence. It showed 
that the surface and the look-and-feel is ac- 
cepted and the functionality corresponds to the 
real-time needs of the call center agents, as users 
were slightly faster than within their usual en- 
vironment. 
? A preliminary test of the throughput achieved 
by using the STP and SML technology in I ce -  
MAIL showed that experienced users take about 
50-70 seconds on average for one cycle, as de- 
scribed above. This figure was gained through 
experiments with three users over a duration of 
about one hour each. 
Using the system with a constant set of categories 
will improve its accuracy after repeating the off-line 
learning step. If a new category is introduced, the 
accuracy will slightly decline until 30 documents are 
manually classified and the category is automatically 
included into a new classifier. Relearning may take 
place at regular intervals. The definition of new cat- 
egories must be fed into ICe-MAIL by a "knowledge 
8As of end of February 2000. 
163
engineer", who maintains the system. The effects of 
new categories and new data have not been tested 
yet. 
The optimum performance of ICe-MAIL can be 
achieved only with a well-maintained category sys- 
tem. For a call center, this may be a difficult task 
to achieve, espescially under severe time pressure, 
but it will pay off. In particular, all new categories 
should be added, outdated ones should be removed, 
and redundant ones merged. Agents should only use 
these categories and no others. The organizational 
structure of the team should reflect this by defin- 
ing the tasks of the "knowledge ngineer" and her 
interactions with the agents. 
6 Conc lus ions  and  Future  Work  
We have presented new combinations of STP and 
SML methods to classify unrestricted e-mail text ac- 
cording to a changing set of categories. The current 
accuracy of the ICC-MAIL system is 78% (correct so- 
lution among the top five proposals), corresponding 
to an overall performance of 73% since ICC-MAIL 
processes only 94% of the incoming e-mails. The 
accuracy improves with usage, since each relearning 
step will yield better classifiers. The accuracy is ex- 
pected to approximate that of the agents, but not 
improve on it. With ICe-MAIL, the performance of
an experienced agent can approximately be doubled. 
The system is currently undergoing extensive tests 
at the call center of AOL Bertelsmann Online. De- 
tails about the development of the performance de- 
pending on the throughput and change of categories 
are expected to be available by mid 2000. 
Technically, we expect improvements from the fol- 
lowing areas of future work. 
? Further task-specific heuristics aiming at gen- 
eral structural inguistic properties hould be 
defined. This includes heuristics for the identi- 
fication of multiple requests in a single e-mail 
that could be based on key words and key 
phrases as well as on the analysis of the doc- 
ument structure. 
? Our initial experiments with the integration 
of GermaNet (Hamp and Feldweg, 1997), the 
evolving German version of WordNet, seem to 
confirm the positive results described for Word- 
Net (de Buenaga Rodriguez et al, 1997) and 
will thus be extended. 
? A reorganization f the existing three-level cate- 
gory system into a semantically consistent tree 
structure would allow us to explore the non- 
terminal nodes of the tree for multi-layered 
SML. This places additional requirements on 
the knowledge ngineering task and thus needs 
to be thoroughly investigated for pay-off. 
? Where system-generated answers are acceptable 
to customers, a straightforward extension of 
ICe-MAIL can provide this functionality. For 
the application in hand, this was not the case. 
The potential of the technology presented extends 
beyond call center applications. We intend to ex- 
plore its use within an information broking assis- 
tant in document classification. In a further indus- 
trial project with German Telekom, the ICC-MAIL 
technology will be extended to process multi-lingual 
press releases. The nature of these documents will 
allow us to explore the application of more sophis- 
ticated language technologies during linguistic pre- 
processing. 
Acknowledgments  
We are grateful to our colleagues Giinter Neumann, 
Matthias Fischmann, Volker Morbach, and Matthias 
Rinck for fruitful discussions and for support with 
sines modules. This work was partially supported by 
a grant of the Minister of Economy and Commerce 
of the Saarland, Germany, to the project ICC. 
References  
David W. Aha. 1992. Tolerating noisy, irrelevant 
and novel attributes in instance based learning al- 
gorithms. International Journal of Man-Machine 
Studies, 36(1), pages 267-287. 
Fabio Ciravegna, Alberto Lavelli, Nadia Mana, Jo- 
hannes Matiasek, Luca Gilardoni, Silvia Mazza, 
Massimo Ferraro, William J.Black, Fabio RJ- 
naldi, and David Mowatt. 1999. Facile: Classi- 
fying texts integrating pattern matching and in- 
formation extraction. In Proceedings of IJCAI'99, 
Stockholm, pages 890-895. 
William W. Cohen. 1995. Fast effective rule induc- 
tion. In Proceedings of the Twelfth International 
Conference on Machine Learning, Lake Tahoe, 
California. 
Manuel de Buenaga Rodriguez, Jose Maria Gomez- 
Hidalgo, and Belen Diaz-Agudo. 1997. Using 
WordNet to complement training information in 
text categorization. In Proceedings of the Second 
International Conference on Recent Advances in 
Natural Language Processing, Montreal, Canada. 
I.J. Good. 1965. The Estimation of Probabilities. 
An Essay on Modern Bayesian Methods. MIT- 
Press. 
Birgit Hamp and Helmut Feldweg. 1997. GermaNet 
- a lexical-semantic net for German. In Proceed- 
ings of A CL workshop Automatic Information Ex- 
traction and Building of Lexical Semantic Re- 
sources for NLP Applications, Madrid, Spain 
Thorsten Joachims. 1998. Text categorization with 
support vector machines - learning with meany 
relevant features. In Proceedings of the Euro- 
164 
pean Conference on Machine Learning (ECML), 
Chemnitz, Germany, pages 137-142. 
Ronny Kohavi and Dan Sommerfield, 1996. 
MLC++ Machine Learning library in C++. 
http://www.sgi.com/Technology/mlc. 
Teuvo Kohonen, Jussi Hynninen, Jari Kangas, 
Jorma Laaksonen, and Kari Torkkola. 1996. 
LVQ-PAK the learning vector quantization pro- 
gram package. Technical Report A30, Helsinki 
University of Technology. 
G/inter Neumann, Rolf Backofen, Judith Baur, 
Markus Becket, and Christian Braun. 1997. An 
information extraction core system for real world 
German text processing. In Proceedings of 5th 
ANLP, Washington, pages 209-216. 
G/inter Neumann and Sven Schmeier. 1999. Com- 
bining shallow text processing and macine learn- 
ing in real world applications. In Proceedings of 
IJCAI workshop on Machine Learning for Infor- 
mation Filtering, Stockholm, pages 55-60. 
J.R. Quinlan. 1986. Induction of Decision Trees. 
Reprinted in Shavlik, Jude W. and Dietterich, 
Thomas G, Readings in machine learning. Ma- 
chine learning series. Morgan Kaufmann (1990) 
J.R. Quinlan. 1992. C4.5: Programs for Machine 
Learning. Morgan Kaufmann, San Mateo, Cali- 
fornia. 
J.R. Quinlan. 1996. Bagging, Boosting and C4.5. In 
Proceedings of AAAI'96, Portland, pages 725-730. 
Vladimir N. Vapnik. 1995. The Nature of Statistical 
Learning Theory. Springer. 
E.D. Wiener, J. Pedersen, and A.S. Weigend. 1995. 
A neural network approach to topic spotting. In 
Proceedings of the SDAIR. 
Y. Yang and Xin Liu. 1999. A re-examination f 
text categorization methods. In Proceedings of 
A CMSIGIR Conference on Research and Devel- 
opment in Information Retrieval, Berkley, Calfor- 
nia. 
Y. Yang and J.P. Pedersen. 1997. A comparative 
study on feature selection. In Proceedings of the 
Fourteenth International Conference on Machine 
Learning (ICML '97). 
Y. Yang. 1999. An evaluation of statistical ap- 
proaches to text categorization. Information Re- 
trieval Journal (May 1999). 
165 
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 20?25,
Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational Linguistics
A Mobile Touchable Application for Online Topic Graph Extraction and
Exploration of Web Content
Gu?nter Neumann and Sven Schmeier
Language Technology Lab, DFKI GmbH
Stuhlsatzenhausweg 3, D-66123 Saarbru?cken
{neumann|schmeier}@dfki.de
Abstract
We present a mobile touchable application for
online topic graph extraction and exploration
of web content. The system has been imple-
mented for operation on an iPad. The topic
graph is constructed from N web snippets
which are determined by a standard search en-
gine. We consider the extraction of a topic
graph as a specific empirical collocation ex-
traction task where collocations are extracted
between chunks. Our measure of association
strength is based on the pointwise mutual in-
formation between chunk pairs which explic-
itly takes their distance into account. An ini-
tial user evaluation shows that this system is
especially helpful for finding new interesting
information on topics about which the user has
only a vague idea or even no idea at all.
1 Introduction
Today?s Web search is still dominated by a docu-
ment perspective: a user enters one or more key-
words that represent the information of interest and
receives a ranked list of documents. This technology
has been shown to be very successful when used on
an ordinary computer, because it very often delivers
concrete documents or web pages that contain the
information the user is interested in. The following
aspects are important in this context: 1) Users basi-
cally have to know what they are looking for. 2) The
documents serve as answers to user queries. 3) Each
document in the ranked list is considered indepen-
dently.
If the user only has a vague idea of the informa-
tion in question or just wants to explore the infor-
mation space, the current search engine paradigm
does not provide enough assistance for these kind
of searches. The user has to read through the docu-
ments and then eventually reformulate the query in
order to find new information. This can be a tedious
task especially on mobile devices. Seen in this con-
text, current search engines seem to be best suited
for ?one-shot search? and do not support content-
oriented interaction.
In order to overcome this restricted document per-
spective, and to provide a mobile device searches to
?find out about something?, we want to help users
with the web content exploration process in two
ways:
1. We consider a user query as a specification of
a topic that the user wants to know and learn
more about. Hence, the search result is basi-
cally a graphical structure of the topic and as-
sociated topics that are found.
2. The user can interactively explore this topic
graph using a simple and intuitive touchable
user interface in order to either learn more
about the content of a topic or to interactively
expand a topic with newly computed related
topics.
In the first step, the topic graph is computed on
the fly from the a set of web snippets that has been
collected by a standard search engine using the ini-
tial user query. Rather than considering each snip-
pet in isolation, all snippets are collected into one
document from which the topic graph is computed.
We consider each topic as an entity, and the edges
20
between topics are considered as a kind of (hidden)
relationship between the connected topics. The con-
tent of a topic are the set of snippets it has been ex-
tracted from, and the documents retrievable via the
snippets? web links.
A topic graph is then displayed on a mobile de-
vice (in our case an iPad) as a touch-sensitive graph.
By just touching on a node, the user can either in-
spect the content of a topic (i.e, the snippets or web
pages) or activate the expansion of the graph through
an on the fly computation of new related topics for
the selected node.
In a second step, we provide additional back-
ground knowledge on the topic which consists of ex-
plicit relationships that are generated from an online
Encyclopedia (in our case Wikipedia). The relevant
background relation graph is also represented as a
touchable graph in the same way as a topic graph.
The major difference is that the edges are actually
labeled with the specific relation that exists between
the nodes.
In this way the user can explore in an uniform way
both new information nuggets and validated back-
ground information nuggets interactively. Fig. 1
summarizes the main components and the informa-
tion flow.
Figure 1: Blueprint of the proposed system.
2 Touchable User Interface: Examples
The following screenshots show some results for the
search query ?Justin Bieber? running on the cur-
rent iPad demo?app. At the bottom of the iPad
screen, the user can select whether to perform text
exploration from the Web (via button labeled ?i?
GNSSMM?) or via Wikipedia (touching button ?i?
MILREX?). The Figures 2, 3, 4, 5 show results for
the ?i?GNSSMM? mode, and Fig. 6 for the ?i-
MILREX? mode. General settings of the iPad demo-
app can easily be changed. Current settings allow
e.g., language selection (so far, English and German
are supported) or selection of the maximum number
of snippets to be retrieved for each query. The other
parameters mainly affect the display structure of the
topic graph.
Figure 2: The topic graph computed from the snippets for
the query ?Justin Bieber?. The user can double touch on
a node to display the associated snippets and web pages.
Since a topic graph can be very large, not all nodes are
displayed. Nodes, which can be expanded are marked by
the number of hidden immediate nodes. A single touch
on such a node expands it, as shown in Fig. 3. A single
touch on a node that cannot be expanded adds its label to
the initial user query and triggers a new search with that
expanded query.
21
Figure 3: The topic graph from Fig. 2 has been expanded
by a single touch on the node labeled ?selena gomez?.
Double touching on that node triggers the display of as-
sociated web snippets (Fig. 4) and the web pages (Fig.
5).
3 Topic Graph Extraction
We consider the extraction of a topic graph as a spe-
cific empirical collocation extraction task. How-
ever, instead of extracting collations between words,
which is still the dominating approach in collocation
extraction research, e.g., (Baroni and Evert, 2008),
we are extracting collocations between chunks, i.e.,
word sequences. Furthermore, our measure of asso-
ciation strength takes into account the distance be-
tween chunks and combines it with the PMI (point-
wise mutual information) approach (Turney, 2001).
The core idea is to compute a set of chunk?
pair?distance elements for the N first web snip-
pets returned by a search engine for the topic Q,
and to compute the topic graph from these ele-
ments.1 In general for two chunks, a single chunk?
pair?distance element stores the distance between
1For the remainder of the paper N=1000. We are using Bing
(http://www.bing.com/) for Web search.
Figure 4: The snippets that are associated with the node
label ?selena gomez? of the topic graph from Fig. 3.In or-
der to go back to the topic graph, the user simply touches
the button labeled i-GNSSMM on the left upper corner of
the iPad screen.
the chunks by counting the number of chunks in?
between them. We distinguish elements which have
the same words in the same order, but have different
distances. For example, (Peter, Mary, 3) is different
from (Peter, Mary, 5) and (Mary, Peter, 3).
We begin by creating a document S from the
N -first web snippets so that each line of S con-
tains a complete snippet. Each textline of S is
then tagged with Part?of?Speech using the SVM-
Tagger (Gime?nez and Ma`rquez, 2004) and chun-
ked in the next step. The chunker recognizes two
types of word chains. Each chain consists of longest
matching sequences of words with the same PoS
class, namely noun chains or verb chains, where
an element of a noun chain belongs to one of
the extended noun tags2, and elements of a verb
2Concerning the English PoS tags, ?word/PoS? expressions
that match the following regular expression are considered as
extended noun tag: ?/(N(N|P))|/VB(N|G)|/IN|/DT?. The En-
22
Figure 5: The web page associated with the first snippet
of Fig. 4. A single touch on that snippet triggers a call
to the iPad browser in order to display the corresponding
web page. The left upper corner button labeled ?Snip-
pets? has to be touched in order to go back to the snippets
page.
chain only contains verb tags. We finally ap-
ply a kind of ?phrasal head test? on each iden-
tified chunk to guarantee that the right?most ele-
ment only belongs to a proper noun or verb tag.
For example, the chunk ?a/DT british/NNP for-
mula/NNP one/NN racing/VBG driver/NN from/IN
scotland/NNP? would be accepted as proper NP
chunk, where ?compelling/VBG power/NN of/IN?
is not.
Performing this sort of shallow chunking is based
on the assumptions: 1) noun groups can represent
the arguments of a relation, a verb group the relation
itself, and 2) web snippet chunking needs highly ro-
bust NL technologies. In general, chunking crucially
depends on the quality of the embedded PoS?tagger.
However, it is known that PoS?tagging performance
of even the best taggers decreases substantially when
glish Verbs are those whose PoS tag start with VB. We are us-
ing the tag sets from the Penn treebank (English) and the Negra
treebank (German).
Figure 6: If mode ?i?MILREX? is chosen then text ex-
ploration is performed based on relations computed from
the info?boxes extracted from Wikipedia. The central
node corresponds to the query. The outer nodes repre-
sent the arguments and the inner nodes the predicate of a
info?box relation. The center of the graph corresponds to
the search query.
applied on web pages (Giesbrecht and Evert, 2009).
Web snippets are even harder to process because
they are not necessary contiguous pieces of texts,
and usually are not syntactically well-formed para-
graphs due to some intentionally introduced breaks
(e.g., denoted by . . . betweens text fragments). On
the other hand, we want to benefit from PoS tag-
ging during chunk recognition in order to be able to
identify, on the fly, a shallow phrase structure in web
snippets with minimal efforts.
The chunk?pair?distance model is computed
from the list of chunks. This is done by traversing
the chunks from left to right. For each chunk ci, a
set is computed by considering all remaining chunks
and their distance to ci, i.e., (ci, ci+1, disti(i+1)),
(ci, ci+2, disti(i+2)), etc. We do this for each chunk
list computed for each web snippet. The distance
distij of two chunks ci and cj is computed directly
from the chunk list, i.e., we do not count the position
23
of ignored words lying between two chunks.
The motivation for using chunk?pair?distance
statistics is the assumption that the strength of hid-
den relationships between chunks can be covered by
means of their collocation degree and the frequency
of their relative positions in sentences extracted from
web snippets; cf. (Figueroa and Neumann, 2006)
who demonstrated the effectiveness of this hypothe-
sis for web?based question answering.
Finally, we compute the frequencies of each
chunk, each chunk pair, and each chunk pair dis-
tance. The set of all these frequencies establishes
the chunk?pair?distance model CPDM . It is used
for constructing the topic graph in the final step. For-
mally, a topic graph TG = (V,E,A) consists of a
set V of nodes, a set E of edges, and a set A of node
actions. Each node v ? V represents a chunk and
is labeled with the corresponding PoS?tagged word
group. Node actions are used to trigger additional
processing, e.g., displaying the snippets, expanding
the graph etc.
The nodes and edges are computed from the
chunk?pair?distance elements. Since, the number
of these elements is quite large (up to several
thousands), the elements are ranked according to
a weighting scheme which takes into account the
frequency information of the chunks and their collo-
cations. More precisely, the weight of a chunk?pair?
distance element cpd = (ci, cj , Dij), with Di,j =
{(freq1, dist1), (freq2, dist2), ..., (freqn, distn)},
is computed based on PMI as follows:
PMI(cpd) = log2((p(ci, cj)/(p(ci) ? p(cj)))
= log2(p(ci, cj))? log2(p(ci) ? p(cj))
where relative frequency is used for approximating
the probabilities p(ci) and p(cj). For log2(p(ci, cj))
we took the (unsigned) polynomials of the corre-
sponding Taylor series3 using (freqk, distk) in the
k-th Taylor polynomial and adding them up:
PMI(cpd) = (
n?
k=1
(xk)
k
k
)? log2(p(ci) ? p(cj))
, where xk =
freqk
?n
k=1 freqk
3In fact we used the polynomials of the Taylor series for
ln(1 + x). Note also that k is actually restricted by the number
of chunks in a snippet.
The visualized topic graph TG is then computed
from a subset CPD?M ? CPDM using the m high-
est ranked cpd for fixed ci. In other words, we re-
strict the complexity of a TG by restricting the num-
ber of edges connected to a node.
4 Wikipedia?s Infoboxes
In order to provide query specific background
knowledge we make use of Wikipedia?s infoboxes.
These infoboxes contain facts and important rela-
tionships related to articles. We also tested DB-
pedia as a background source (Bizer et al, 2009).
However, it turned out that currently it contains
too much and redundant information. For exam-
ple, the Wikipedia infobox for Justin Bieber contains
eleven basic relations whereas DBpedia has fifty re-
lations containing lots of redundancies. In our cur-
rent prototype, we followed a straightforward ap-
proach for extracting infobox relations: We down-
loaded a snapshot of the whole English Wikipedia
database (images excluded), extracted the infoboxes
for all articles if available and built a Lucene Index
running on our server. We ended up with 1.124.076
infoboxes representing more than 2 million differ-
ent searchable titles. The average access time is
about 0.5 seconds. Currently, we only support ex-
act matches between the user?s query and an infobox
title in order to avoid ambiguities. We plan to ex-
tend our user interface so that the user may choose
different options. Furthermore we need to find tech-
niques to cope with undesired or redundant informa-
tion (see above). This extension is not only needed
for partial matches but also when opening the sys-
tem to other knowledgesources like DBpedia, new-
sticker, stock information and more.
5 Evaluation
For an initial evaluation we had 20 testers: 7 came
from our lab and 13 from non?computer science re-
lated fields. 15 persons had never used an iPad be-
fore. After a brief introduction to our system (and
the iPad), the testers were asked to perform three
different searches (using Google, i?GNSSMM and
i?MILREX) by choosing the queries from a set of
ten themes. The queries covered definition ques-
tions like EEUU and NLF, questions about persons
like Justin Bieber, David Beckham, Pete Best, Clark
24
Kent, and Wendy Carlos , and general themes like
Brisbane, Balancity, and Adidas. The task was
not only to get answers on questions like ?Who is
. . . ? or ?What is . . . ? but also to acquire knowledge
about background facts, news, rumors (gossip) and
more interesting facts that come into mind during
the search. Half of the testers were asked to first
use Google and then our system in order to compare
the results and the usage on the mobile device. We
hoped to get feedback concerning the usability of
our approach compared to the well known internet
search paradigm. The second half of the participants
used only our system. Here our research focus was
to get information on user satisfaction of the search
results. After each task, both testers had to rate sev-
eral statements on a Likert scale and a general ques-
tionnaire had to be filled out after completing the
entire test. Table 1 and 2 show the overall result.
Table 1: Google
#Question v.good good avg. poor
results first sight 55% 40% 15% -
query answered 71% 29% - -
interesting facts 33% 33% 33% -
suprising facts 33% - - 66%
overall feeling 33% 50% 17% 4%
Table 2: i-GNSSMM
#Question v.good good avg. poor
results first sight 43% 38% 20% -
query answered 65% 20% 15% -
interesting facts 62% 24% 10% 4%
suprising facts 66% 15% 13% 6%
overall feeling 54% 28% 14% 4%
The results show that people in general prefer
the result representation and accuracy in the Google
style. Especially for the general themes the presen-
tation of web snippets is more convenient and more
easy to understand. However when it comes to in-
teresting and suprising facts users enjoyed exploring
the results using the topic graph. The overall feeling
was in favor of our system which might also be due
to the fact that it is new and somewhat more playful.
The replies to the final questions: How success-
ful were you from your point of view? What did you
like most/least? What could be improved? were in-
formative and contained positive feedback. Users
felt they had been successful using the system. They
liked the paradigm of the explorative search on the
iPad and preferred touching the graph instead of re-
formulating their queries. The presentation of back-
ground facts in i?MILREX was highly appreciated.
However some users complained that the topic graph
became confusing after expanding more than three
nodes. As a result, in future versions of our system,
we will automatically collapse nodes with higher
distances from the node in focus. Although all of our
test persons make use of standard search engines,
most of them can imagine to using our system at
least in combination with a search engine even on
their own personal computers.
6 Acknowledgments
The presented work was partially supported by
grants from the German Federal Ministry of Eco-
nomics and Technology (BMWi) to the DFKI The-
seus projects (FKZ: 01MQ07016) TechWatch?Ordo
and Alexandria4Media.
References
Marco Baroni and Stefan Evert. 2008. Statistical meth-
ods for corpus exploitation. In A. Lu?deling and
M. Kyto? (eds.), Corpus Linguistics. An International
Handbook, Mouton de Gruyter, Berlin.
Christian Bizer, Jens Lehmann, Georgi Kobilarov, Soren
Auer, Christian Becker, Richard Cyganiak, Sebastian
Hellmann. 2009. DBpedia - A crystallization point for
the Web of Data. Web Semantics: Science, Services
and Agents on the World Wide Web 7 (3): 154165.
Alejandro Figueroa and Gu?nter Neumann. 2006. Lan-
guage Independent Answer Prediction from the Web.
In proceedings of the 5th FinTAL, Finland.
Eugenie Giesbrecht and Stefan Evert. 2009. Part-of-
speech tagging - a solved task? An evaluation of PoS
taggers for the Web as corpus. In proceedings of the
5th Web as Corpus Workshop, San Sebastian, Spain.
Jesu?s Gime?nez and Llu??s Ma`rquez. 2004. SVMTool: A
general PoS tagger generator based on Support Vector
Machines. In proceedings of LREC?04, Lisbon, Por-
tugal.
Peter Turney. 2001. Mining the web for synonyms: PMI-
IR versus LSA on TOEFL. In proceedings of the 12th
ECML, Freiburg, Germany.
25
