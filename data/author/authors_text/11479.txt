Proceedings of the EACL 2009 Workshop on GEMS: GEometical Models of Natural Language Semantics, pages 25?32,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
A Study of Convolution Tree Kernel with Local Alignment
Lidan Zhang
Department of Computer Science
HKU, Hong Kong
lzhang@cs.hku.hk
Kwok-Ping Chan
Department of Computer Science
HKU, Hong Kong
kpchan@cs.hku.hk
Abstract
This paper discusses a new convolu-
tion tree kernel by introducing local
alignments. The main idea of the new
kernel is to allow some syntactic al-
ternations during each match between
subtrees. In this paper, we give an
algorithm to calculate the composite
kernel. The experiment results show
promising improvements on two tasks:
semantic role labeling and question
classification.
1 Introduction
Recently kernel-based methods have become
a state-of-art technique and been widely used
in natural language processing applications.
In this method, a key problem is how to de-
sign a proper kernel function in terms of dif-
ferent data representations. So far, there are
two kinds of data representations. One is to
encode an object with a flat vector whose ele-
ment correspond to an extracted feature from
the object. However the feature vector is sen-
sitive to the structural variations. The ex-
traction schema is heavily dependent on dif-
ferent problems. On the other hand, kernel
function can be directly calculated on the ob-
ject. The advantages are that the original
topological information is to a large extent
preserved and the introduction of additional
noise may be avoided. Thus structure-based
kernels can well model syntactic parse tree
in a variety of applications, such as relation
extraction(Zelenko et al, 2003), named en-
tity recognition(Culotta and Sorensen, 2004),
semantic role labeling(Moschitti et al, 2008)
and so on.
To compute the structural kernel function,
Haussler (1999) introduced a general type of
kernel function, called? Convolution kernel?.
Based on this work, Collins and Duffy (2002)
proposed a tree kernel calculation by count-
ing the common subtrees. In other words,
two trees are considered if and only if these
two trees are exactly same. In real sentences,
some structural alternations within a given
phrase are permitted without changing its us-
age. Therefore, Moschitti (2004) proposed
partial trees to partially match between sub-
trees. Kashima and Koyanagi (2002) general-
ize the tree kernel to labeled order tree kernel
with more flexible match. And from the idea
of introducing linguistical knowledge, Zhang
et al (2007) proposed a grammar-driven tree
kernel, in which two subtrees are same if and
only if the corresponding two productions are
in the same manually defined set. In addi-
tion, the problem of hard matching can be al-
leviated by processing or mapping the trees.
For example, Tai mapping (Kuboyama et al,
2006) generalized the kernel from counting
subtrees to counting the function of mapping.
Moreover multi-source knowledge can benefit
kernel calculation, such as using dependency
information to dynamically determine the tree
span (Qian et al, 2008).
In this paper, we propose a tree kernel cal-
culation algorithm by allowing variations in
productions. The variation is measured with
local alignment score between two derivative
POS sequences. To reduce the computation
complexity, we use the dynamic programming
algorithm to compute the score of any align-
ment. And the top n alignments are consid-
ered in the kernel.
25
Another problem in Collins and Duffy?s
tree kernel is context-free. It does not con-
sider any semantic information located at the
leaf nodes of the parsing trees. To lexicalized
tree kernel, Bloehdorn et al (2007) consid-
ered the associated term similarity by virtue
of WordNet. Shen et al (2003) constructed a
separate lexical feature containing words on a
given path and merged into the kernel in linear
combination.
The paper is organized as follows. In sec-
tion 2, we describe the commonly used tree
kernel. In section 3, we propose our method
to make use of the local alignment informa-
tion in kernel calculation. Section 4 presents
the results of our experiments for two differ-
ent applications ( Semantic Role Labeling and
Question Classification). Finally section 5
provides our conclusions.
2 Convolution Tree Kernel
The main idea of tree kernel is to count
the number of common subtrees between
two trees T1 and T2. In convolutional
tree kernel (Collins and Duffy, 2002), a
tree(T ) is represented as a vector h(T ) =
(h1(T ), ..., hi(T ), ..., hn(T )), where hi(T ) is
the number of occurrences of the ith tree frag-
ment in the tree T . Since the number of sub-
trees is exponential with the parse tree size,
it is infeasible to directly count the common
subtrees. To reduce the computation complex-
ity, a recursive kernel calculation algorithm
was presented. Given two trees T1 and T2,
K(T1, T2) = < h(T1), h(T2) > (1)
=
?
i
hi(T1)hi(T2)
=
?
i
(
?
n1?NT1
Ii(n1)
?
n2?NT2
Ii(n2))
=
?
n1?NT1
?
n2?NT2
4(n1, n2)
where, NT1 and NT2 are the sets of all nodes in
trees T1 and T2, respectively. Ii(n) is the indi-
cator function to be 1 if i-th subtree is rooted
at node n and 0 otherwise. And 4(n1, n2) is
the number of common subtrees rooted at n1
and n2. It can be computed efficiently accord-
ing to the following rules:
(1) If the productions at n1 and n2 are differ-
ent, 4(n1, n2) = 0
(2) If the productions at n1 and n2 are same,
and n1 and n2 are pre-terminals, then
4(n1, n2) = ?
(3) Else, 4(n1, n2) = ?
?nc(n1)
j (1 +
4(ch(n1, j), ch(n2, j)))
where nc(n1) is the number of children of
n1 in the tree. Note that n1 = n2 be-
cause the productions at n1 and n2 are same.
ch(n1, j) represents the jth child of node
n1. And 0 < ? ? 1 is the parameter
to downweight the contribution of larger tree
fragments to the kernel. It corresponds to
K(T1, T2) =
?
i ?sizeihi(T1)hi(T2), where
sizei is the number of rules in the i?th frag-
ment. The time complexity of computing this
kernel is O(|NT1| ? |NT2|).
3 Tree Kernel with Local Alignment
3.1 General Framework
As we referred, one of problems in the ba-
sic tree kernel is its hard match between two
rules. In other words, at each tree level,
the two subtrees are required to be perfectly
equal. However, in real sentences, some
modifiers can be added into a phrase with-
out changing the phrase?s function. For ex-
ample, two sentences are given in Figure 1.
Considering ?A1? role, the similarities be-
tween two subtrees(in circle) are 0 in (Collins
and Duffy, 2002), because the productions
?NP?DT ADJP NN? and ?NP?DT NN?
are not identical. From linguistical point of
view, the adjective phrase is optional in real
sentences, which does not change the corre-
sponding semantic role. Thus the modifier
components(like ?ADJP? in the above exam-
ple) should be neglected in similarity compar-
isons.
To make the hard match flexible, we can
align two string sequences derived from the
same node. Considering the above example,
26
S
NP
NNP
Richard
VP
VPAUX
has VBN
taken
NP
DT
a
NN
approach
ADJP
RBR
more
JJ
audience-friendly
S
NP
NNP
Richard
VP
VPAUX
has VBN
taken
NP
DT
a
NN
approach
S
NP
NNP
Richard
VP
VPAUX
has VBN
taken
NP
DT
a
NN
approach
NULL
v
A0
A1
A1
A1
(a) (b) (c)
Figure 1: Syntactic parse tree with ?A1? semantic role
an alignment might be ?DT ADJP NN? vs
?DT - NN?, by inserting a symbol(-). The
symbol(-) corresponds to a ?NULL? subtree
in the parser tree. And the ?NULL? subtree
can be regarded as a null character in the sen-
tence, see Figure 1(c).
Convolution kernels, studied in (Haussler,
1999) gave the framework to construct a com-
plex kernel from its simple elements. Suppose
x ? X can be decomposed into x1, ..., xm ?
~x. Let R be a relation over X1? ...?Xm?X
such that R(~x) is true iff x1, ..., xm are parts
of x. R?1(x) = {~x|R(~x, x)}, which returns
all components. For example, x is any string,
then ~x can be its characters. The convolution
kernel K is defined as:
K(x, y) =
?
~x?R?1(x),~y?R?1(y)
m?
d=1
Kd(xd, yd)
(2)
Considering our problem, for example, a
derived string sequence x by the rule ?n1 ?
x?. R(xi, x) is true iff xi appears in the right
hand of x. Given two POS sequences x and
y derived from two nodes n1 and n2, respec-
tively, A(x, y) denotes all the possible align-
ments of the sequence. The general form of
the kernel with local alignment is defined as:
K ?(n1, n2) =
?
(i,j)?A(x,y)
K(ni1, nj2) (3)
4?(n1, n2) = ?
?
(i,j)?A(x,y)
AS(i,j)
nc(n1,i)?
d=1
(1 +4?(ch(n1, i, d), ch(n2, j, d))
where, (i, j) denotes the ith and jth variation
for x and y, AS(i,j) is the score for alignment i
and j. And ch(n1, i, d) selects the dth subtree
for the ith aligned schema of node n1.
It is easily to prove the above kernel is pos-
itive semi-definite, since the kernel K(ni1, nj2)
is positive semi-definite. The native computa-
tion is impractical because the number of all
possible alignments(|A(x, y)|) is exponential
with respect to |x| and |y|. In the next sec-
tion, we will discuss how to calculate AS(i,j)
for each alignment.
3.2 Local Alignment Kernel
The local alignment(LA) kernel was usually
used in bioinformatics, to compare the sim-
ilarity between two protein sequences(x and
y) by exploring their alignments(Saigo et al,
2004).
KLA(x, y) =
?
pi?A(x,y)
exp?s(x,y,pi) (4)
where ? ? 0 is a parameter, A(x, y) denotes
all possible local alignments between x and y,
and s(x, y, pi) is the local alignment score for
a given alignment schema pi, which is equal
to:
s(x, y, pi) =
|pi|?
i=1
S(xpii1 , ypii2)?
|pi|?1?
j=1
[g(pii+11 ? pii1) + g(pii+12 ? pii2)]
(5)
In equation( 5), S is a substitution matrix, and
g is a gap penalty function. The alignment
score is the sum of the substitution score be-
tween the correspondence at the aligned posi-
tion, minus the sum of the gap penalty for the
27
case that ?-? symbol is inserted. In natural lan-
guage processing, the substitution matrix can
be selected as identity matrix and no penalty
is accounted.
Obviously, the direct computation of the
original KLA is not practical. Saigo (2004)
presented a dynamic programming algorithm
with time complexity O(|x|?|y|). In this paper,
this dynamic algorithm is used to compute the
kernel matrix, whose element(i, j) is used as
AS(i,j) measurement in equation(3).
3.3 Local Alignment Tree Kernel
Now we embed the above local alignment
score into the general tree kernel computation.
Equation(3) can be re-written into following:
4? (n1, n2) = ?
?
pi?A(x,y)
(exp?s(x,y,pi)?
nc(n1,i)?
k=1
(1 +4?(ch(n1, i, k), ch(n2, j, k))))
(6)
To further reduce the computation com-
plexity, a threshold (?) is used to filter out
alignments with low scores. This can help to
avoid over-generated subtrees and only select
the significant alignments. In other words,
by using the threshold (?), we can select the
salient subtree variations for kernels. The fi-
nal kernel calculation is shown below:
4? (n1, n2) = ?
?
pi ? A(x, y)
s(x, y, pi) > ?
(??s(x,y,pi)?
nc(n1,i)?
k=1
(1 +4?(ch(n1, i, k), ch(n2, j, k))))
(7)
After filtering, the kernel is still positive
semi-definite. This can be easily proved using
the theorem in (Shin and Kuboyama, 2008),
since this subset selection is transitive. More
specifically, if s(x, y, pi) > ?? s(y, z, pi?) >
?, then s(x, z, pi + pi?) > ?.
The algorithm to compute the local align-
ment tree kernel is given in algorithm 1. For
any two nodes pair(xi and yj), the local align-
ment score M(xi, yj) is assigned. In the ker-
nel matrix calculation, the worst case occurs
when the tree is balanced and most of the
alignments are selected.
Algorithm 1 algorithm for local alignment
tree kernel
Require: 2 nodes n1,n2 in parse trees;The
productions are n1 ? x1, ..., xm and n2 ?
y1, ..., yn
return 4?(n1, n2)
if n1 and n2 are not same then
4?(n1, n2) = 0
else
if both n1 and n2 are pre-terminals then
4?(n1, n2) = 1
else
calculate kernel matrix by equation( 4)
for each possible alignment do
calculate 4?(n1, n2) by equation(7)
end for
end if
end if
4 Experiments
4.1 Semantic Role Labeling
4.1.1 Experiment Setup
We use the CoNLL-2005 SRL shared task
data(Carreras and Marquez, 2005) as our ex-
perimental data. It is from the Wall Street
Journal part of the Penn Treebank, together
with predicate-arguments information from
the PropBank. According to the shared task,
sections 02-21 are used for training, section
24 for development and section 23 as well as
some data from Brown corpus are left for test.
The data sets are described in Table 1.
Sentences Arguments
Training 39,832 239,858
Dev 1,346 8,346
Test WSJ 1,346 8,346Brown 450 2,350
Table 1: Data sets statistics
28
Considering the two steps in semantic role
labeling, i.e. semantic role identification and
recognition. We assume identification has
been done correctly, and only consider the
semantic role classification. In our experi-
ment, we focus on the semantic classes in-
clude 6 core (A0-A5), 12 adjunct(AM-) and
8 reference(R-) arguments.
In our implementation, SVM-Light-TK1
(Moschitti, 2004) is modified. For SVM
multi-classifier, the ONE-vs-ALL (OVA)
strategy is selected. In all, we prepare the data
for each semantic role (r) as following:
(1) Given a sentence and its correct full syn-
tactic parse tree;
(2) Let P be the predicate. Its potential argu-
ments A are extracted according to (Xue
and Palmer, 2004)
(3) For each pair < p, a >? P ? A: if a
covers exactly the words of semantic role
of p, put minimal subtree < p, a > into
positive example set (T+r ); else put it in
the negative examples (T?r )
In our experiments, we set ? = 0.5.
4.1.2 Experimental Results
The classification performance is evalu-
ated with respect to accuracy, precision(p),
recall(r) and F1 = 2pr/(p+ r).
Accuracy(%)
(Collins and Duffy, 2002) 84.35
(Moschitti, 2004) 86.72
(Zhang et al, 2007) 87.96
Our Kernel 88.48
Table 2: Performance comparison between
different kernel performance on WSJ data
1http://dit.unitn.it/ moschitt/Tree-Kernel.htm
P(%) R(%) F?=1
Development 81.03 68.91 74.48
WSJ Test 84.97 79.45 82.11
Brown Test 76.95 70.94 73.51
WSJ+Brown 82.98 75.40 79.01
WSJ P(%) R(%) F
A0 81.28 83.90 82.56
A1 84.22 66.39 74.25
A2 77.27 62.36 69.02
A3 93.33 21.21 34.57
A4 82.61 51.35 63.33
A5 100.00 40.00 57.41
AM-ADV 74.21 56.21 63.92
AM-CAU 75.00 46.09 57.09
AM-DIR 57.14 16.00 25.00
AM-DIS 77.78 70.00 73.68
AM-EXT 75.00 53.10 62.18
AM-LOC 89.66 74.83 81.57
AM-MNR 84.62 48.20 61.41
AM-MOD 96.64 92.00 94.26
AM-NEG 99.30 95.30 97.26
AM-PNC 48.20 28.31 35.67
AM-PRD 50.00 30.00 37.50
AM-TMP 87.87 73.43 80.00
R-A0 81.08 67.80 73.85
R-A1 77.50 49.60 60.49
R-A2 58.00 42.67 49.17
R-AM-CAU 100.00 25.00 40.00
R-AM-EXT 100.00 100.00 100.00
R-AM-LOC 100.00 55.00 70.97
R-AM-MNR 50.00 25.00 33.33
R-AM-TMP 85.71 52.94 65.46
Table 3: top: overall performance result on
data sets ; bottom: detail result on WSJ
data
Table 2 compares the performance of our
method and other three famous kernels on
WSJ test data. We implemented these three
methods with the same settings described
in the papers. It shows that our kernel
achieves the best performance with 88.48%
accuracy. The advantages of our approach
are: 1). the alignments allow soft syntactic
structure match; 2). threshold can avoid over-
generation and selected salient alignments.
Table 3 gives our performance on data sets
and the detail result on WSJ test data.
29
Similarity Definition
Wu and Palmer simWUP (c1, c2) = 2dep(lso(c1,c2))d(c1,lso(c1,c2))+d(c2,lso(c1,c2))+2dep(lso(c1,c2))
Resnik simRES(c1, c2) = ? logP (lso(c1, c2))
Lin simLIN(c1, c2) = 2 logP (lso(c1,c2))logP (c1)+logP (c2)
Table 4: popular semantic similarity measurements
4.2 Question Classification
4.2.1 Semantic-enriched Tree Kernel
Another problem in the tree kernel (Collins
and Duffy, 2002) is the lack of semantic in-
formation, since the match stops at the pre-
terminals. All the lexical information is en-
coded at the leaf nodes of parsing trees. How-
ever, the semantic knowledge is important in
some text applications, like Question Classi-
fication. To introduce semantic similarities
between words into our kernel, we use the
framework in Bloehdorn et al (2007) and
rewrite the rule (2) in the iterative tree kernel
calculation(in section 2).
(2) If the productions at n1 and
n2 are same, and n1 and n2 are
pre-terminals, then 4(n1, n2) =
??kw(w1, w2)
where w1 and w2 are two words derived from
pre-terminals n1 and n2, respectively, and the
parameter ? is to control the contribution of
the leaves. Note that each preterminal has
one child or equally covers one word. So
kw(w1, w2) actually calculate the similarity
between two words w1 and w2.
In general, there are two ways to mea-
sure the semantic similarities. One is to de-
rive from semantic networks such as Word-
Net (Mavroeidis et al, 2005; Bloehdorn et
al., 2006). The other way is to use statisti-
cal methods of distributional or co-occurrence
(O? Se?aghdha and Copestake, 2008) behavior
of the words.
WordNet2 can be regarded as direct graphs
semantically linking concepts by means of
relations. Table 4 gives some similarity
measures between two arbitrary concepts c1
2http://wordnet.princeton.edu/
and c2. For our application, the word-to-
word similarity can be obtained by maximiz-
ing the corresponding concept-based similar-
ity scores. In our implementation, we use
WordNet::Similarity package3(Patwardhan et
al., 2003) and the noun hierarchy of WordNet.
In Table 4, dep is the length of path from a
node to its global root, lso(c1, c2) represents
the lowest super-ordinate of c1 and c2. The
detail definitions can be found in (Budanitsky
and Hirst, 2006) .
As an alternative, Latent Semantic Anal-
ysis(LSA) is a technique. It calculates the
words similarities by means of occurrence
of terms in documents. Given a term-by-
document matrix X , its singular value decom-
position is: X = U?V T , where ? is a diago-
nal matrix with singular values in decreasing
arrangement. The column of U are singular
vectors corresponding to the individual singu-
lar value. Then the latent semantic similarity
kernel of terms ti and tj is:
simLSA =< U ik(U jk)T > (8)
where Uk = IkU is to project U onto its first
k dimensions. Ik is the identity matrix whose
first k diagonal elements are 1 and all the other
elements are 0. And U ik is the i-th row of
the matrix Uk. From equation (8), the LSA-
based similarity between two terms is the in-
ner product of the two projected vectors. The
details of LSA can be found in (Cristianini et
al., 2002; Choi et al, 2001).
4.2.2 Experiment Results
In this set of experiment, we evaluate differ-
ent types of kernels for Question Classifica-
tion(QC) task. The duty of QC is to cat-
egorize questions into different classes. In
3http://search.cpan.org/dist/WordNet-Similarity
30
Accuracy(%) 1000 2000 3000 4000 5500
BOW 77.1 83.3 87.2 87.3 89.2
TK 80.2 86.2 87.4 88.6 91.2
LATK 80.4 86.5 87.5 88.8 91.6
? = 1
WUP 81.3 87.3 88.0 89.8 92.5
RES 81.0 87.1 87.9 89.5 92.2
LIN 81.1 87.0 88.0 89.3 92.4
LSA(k = 50) 80.8 86.9 87.8 89.3 91.7
Table 5: Classification accuracy of different kernels on different data sets
this paper we use the same dataset as intro-
duced in(Li and Roth, 2002). The dataset is
divided4 into 5500 questions for training and
500 questions from TREC 20 for testing. The
total training samples are randomly divided
into 5 subsets with sizes 1,000, 2,000, 3,000,
4,000 and 5,500 respectively. All the ques-
tions are labeled into 6 coarse grained cate-
gories and 50 fine grained categories: Abbre-
viations (abbreviation and expansion), Entity
(animal, body, color, creation, currency, med-
ical, event, food, instrument, language, let-
ter, plant, product, religion, sport, substance,
symbol, technique, term, vehicle, word), De-
scription (definition, description, manner, rea-
son), Human (description, group, individual,
title), Location (city, country, mountain, state)
and Numeric (code, count, date, distance,
money, order, percent, period, speed, temper-
ature, size, weight).
In this paper, we compare the linear ker-
nel based on bag-of-word (BOW), the original
tree kernel (TK), the local alignment tree ker-
nel (section 3, LATK) and its correspondences
with LSA similarity and a set of semantic-
enriched LATK with different similarity met-
rics.
To obtain the parse tree, we use Charniak
parser5 for every question. Like the previ-
ous experiment, SVM-Light-TK software and
the OVA strategy are implemented. In all ex-
periments, we use the default parameter in
SVM(e.g. margin parameter) and set ? = 1.
In LSA model, we set k = 50. Finally, we
use multi-classification accuracy to evaluate
4http://l2r.cs.uiuc.edu/ cogcomp/Data/QA/QC/
5ftp://ftp.cs.brown.edu/pub/nlparser/
the performance.
Table 5 gives the results of the experiments.
We can see that the local alignment tree ker-
nel increase the multi-classification accuracy
of the basic tree kernel by about 0.4%. The
introduction of semantic information further
improves accuracy. Among WordNet-based
metrics, ?Wu and Palmer? metric achieves
the best result, i.e. 92.5%. As a whole,
the WordNet-based similarities perform better
than LSA-based measurement.
5 Conclusion
In this paper, we propose a tree kernel calcula-
tion by allowing local alignments. More flex-
ible productions are considered in line with
modifiers in real sentences. Considering text
related applications, words similarities have
been merged into the presented tree kernel.
These similarities can be derived from dif-
ferent WordNet-based metrics or document
statistics. Finally experiments are carried on
two different applications (Semantic Role La-
beling and Question Classification).
For further work, we plan to study exploit-
ing semantic knowledge in the kernel. A
promising direction is to study the different
effects of these semantic similarities. We are
interested in some distributional similarities
(Lee, 1999) given certain context. Also the
effectivenss of the semantic-enriched tree ker-
nel in SRL is another problem.
References
Stephan Bloehdorn, Roberto Basili, Marco Cammisa,
and Alessandro Moschitti. 2006. Semantic kernels
for text classification based on topological measures
31
of feature similarity. In ICDM ?06: Proceedings of
the Sixth International Conference on Data Mining,
pages 808?812, Washington, DC, USA. IEEE Com-
puter Society.
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating wordnet-based measures of lexical semantic
relatedness. Computational Linguistics, 32(1):13?
47.
X. Carreras and L. Marquez. 2005. Introduction to the
conll-2005 shared task: Semantic role labeling. In
CoNLL ?05: Proceedings of the 9th Conference on
Computational Natural Language Learning.
Freddy Y. Y. Choi, Peter Wiemer-hastings, and Johanna
Moore. 2001. Latent semantic analysis for text
segmentation. In In Proceedings of EMNLP, pages
109?117.
Michael Collins and Nigel Duffy. 2002. New rank-
ing algorithms for parsing and tagging: Kernels over
discrete structures, and the voted perceptron. In
ACL, pages 263?270.
Nello Cristianini, John Shawe-Taylor, and Huma
Lodhi. 2002. Latent semantic kernels. J. Intell.
Inf. Syst., 18(2-3):127?152.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In ACL ?04:
Proceedings of the 42nd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 423?
429, Morristown, NJ, USA. Association for Com-
putational Linguistics.
David Haussler. 1999. Convolution kernels on discrete
structures. Technical report.
Tetsuji Kuboyama, Kilho Shin, and Hisashi Kashima.
2006. Flexible tree kernels based on counting the
number of tree mappings. In ECML/PKDD Work-
shop on Mining and Learning with Graphs.
Lillian Lee. 1999. Measures of distributional similar-
ity. In 37th Annual Meeting of the Association for
Computational Linguistics, pages 25?32.
Xin Li and Dan Roth. 2002. Learning question clas-
sifiers. In Proceedings of the 19th international
conference on Computational linguistics, pages 1?
7, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Dimitrios Mavroeidis, George Tsatsaronis, Michalis
Vazirgiannis, Martin Theobald, and Gerhard
Weikum. 2005. Word sense disambiguation for
exploiting hierarchical thesauri in text classification.
In Al??pio Jorge, Lu??s Torgo, Pavel Brazdil, Rui
Camacho, and Gama Joao, editors, Knowledge
discovery in databases: PKDD 2005 : 9th Eu-
ropean Conference on Principles and Practice
of Knowledge Discovery in Databases, volume
3721 of Lecture Notes in Computer Science, pages
181?192, Porto, Portugal. Springer.
Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2008. Tree kernels for semantic role label-
ing. Comput. Linguist., 34(2):193?224.
Alessandro Moschitti. 2004. A study on convolution
kernels for shallow semantic parsing. In ACL ?04:
Proceedings of the 42nd Annual Meeting on Asso-
ciation for Computational Linguistics, pages 335?
342, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Diarmuid O? Se?aghdha and Ann Copestake. 2008. Se-
mantic classification with distributional kernels. In
Proceedings of the 22nd International Conference
on Computational Linguistics (Coling 2008), pages
649?656, Manchester, UK, August. Coling 2008 Or-
ganizing Committee.
Siddharth Patwardhan, Satanjeev Banerjee, and Ted
Pedersen. 2003. Using measures of semantic re-
latedness for word sense disambiguation. In In Pro-
ceedings of the Fourth International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLING-03), pages 241?257.
Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming
Zhu, and Peide Qian. 2008. Exploiting constituent
dependencies for tree kernel-based semantic relation
extraction. In Proceedings of the 22nd International
Conference on Computational Linguistics (Coling
2008), pages 697?704, Manchester, UK, August.
Coling 2008 Organizing Committee.
Hiroto Saigo, Jean-Philippe Vert, Nobuhisa Ueda, and
Tatsuya Akutsu. 2004. Protein homology detec-
tion using string alignment kernels. Bioinformatics,
20(11):1682?1689.
Kilho Shin and Tetsuji Kuboyama. 2008. A gener-
alization of haussler?s convolution kernel: mapping
kernel. In ICML, pages 944?951.
Nianwen Xue and Martha Palmer. 2004. Calibrat-
ing features for semantic role labeling. In Dekang
Lin and Dekai Wu, editors, Proceedings of EMNLP
2004, pages 88?94, Barcelona, Spain, July. Associ-
ation for Computational Linguistics.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. J. Mach. Learn. Res., 3:1083?1106.
Min Zhang, Wanxiang Che, Aiti Aw, Chew Lim Tan,
Guodong Zhou, Ting Liu, and Sheng Li. 2007.
A grammar-driven convolution tree kernel for se-
mantic role classification. In Proceedings of the
45th Annual Meeting of the Association of Compu-
tational Linguistics, pages 200?207, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
32
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 234?237,
Paris, October 2009. c?2009 Association for Computational Linguistics
Dependency Parsing with Energy-based Reinforcement Learning
Lidan Zhang
Department of Computer Science
The University of Hong Kong
Pokfulam Road, Hong Kong
lzhang@cs.hku.hk
Kwok Ping Chan
Department of Computer Science
The University of Hong Kong
Pokfulam Road, Hong Kong
kpchan@cs.hku.hk
Abstract
We present a model which integrates
dependency parsing with reinforcement
learning based on Markov decision pro-
cess. At each time step, a transition is
picked up to construct the dependency tree
in terms of the long-run reward. The op-
timal policy for choosing transitions can
be found with the SARSA algorithm. In
SARSA, an approximation of the state-
action function can be obtained by calcu-
lating the negative free energies for the
Restricted Boltzmann Machine. The ex-
perimental results on CoNLL-X multilin-
gual data show that the proposed model
achieves comparable results with the cur-
rent state-of-the-art methods.
1 Introduction
Dependency parsing, an important task, can be
used to facilitate some natural language applica-
tions. Given a sentence, dependency parsing is
to find an acyclic labeled directed tree, projective
or non-projective.The label of each edge gives the
syntactic relationship between two words.
Data-driven dependency parsers can be catego-
rized into graph-based and transition-based mod-
els. Both of these two models have their advan-
tages as well as drawbacks. As discussed in (Mc-
Donald and Satta, 2007), transition-based mod-
els use local training and greedy inference algo-
rithms, with a rich feature set, whereas they might
lead to error propagation. In contrast, graph-based
models are globally trained coupled with exact in-
ference algorithms, whereas their features are re-
stricted to a limited number of graph arcs. Nivre
and McDonald (2008) presented a successful at-
tempt to integrate these two models by exploiting
their complementary strengths.
There are other researches on improving the
individual model with a novel framework. For
example, Daume? et al (2006) applied a greedy
search to transition-based model, which was ad-
justed by the resulting errors. Motivated by his
work, our transition-based model is expected to
overcome local dependencies by using a long-term
desirability introduced by reinforcement learning
(RL). We rely on a ?global? policy to guide each
action selection for a particular state during pars-
ing. This policy considers not only the current
configuration but also a few of look-ahead steps.
Thus it yields an optimal action from the long-
term goal. For example, an action might return
a high value even if it produces a low immediate
reward, because its following state-actions might
yield high rewards. The reverse also holds true.
Finally we formulate the parsing problem with the
Markov Decision Process (MDP) for the dynamic
settings.
The reminder of this paper is organized as fol-
lows: Section 2 describes the transition-based de-
pendency parsing. Section 3 presents the proposed
reinforcement learning model. Section 4 gives the
experimental results. Finally, Section 5 concludes
the paper.
2 Transition-based Dependency Parsing
In this paper, we focus on the transition-based
dependency parsing in a shift-reduce frame-
work (Ku?bler et al, 2009). Given a sentence
x = w0, w1, ..., wn, its dependency tree is con-
structed by a sequence of transitions. The data
structures include a stack S to store partially pro-
cessed words and a queue I to record the remain-
ing input words and the partial labeled dependency
structure constructed by the previous transitions.
Four permissible transitions are considered: Re-
duce: pops word wi from the stack; Shift: pushes
the next input wj onto the stack; Left-Arcr: adds
a labeled dependency arc r from the next input wj
to the top of the stack wi, then pops word wi from
the stack; Right-Arcr: adds a dependency arc r
234
S1
A1
r1
S2
A2
r2
St
At
rt
St+1
At+1
rt+1 AtSt
Ht
tis tja
tkh
tikw tjkv
t
Figure 1: The MDP with factored states and actions. Left: The general network. Right: Detailed network
with one hidden layer at time t. Visible variables (states and actions) are shaded. Clear circles represent
hidden variables.
from the top of the stack wi to the next input wj ,
and pushes word wj onto the stack.
Starting from the empty stack and initializing
the queue I as the input words, the parser termi-
nates when the queue I is empty. The optimal
transition (or say, action/decision A) in each step
is conditioned on the current configuration c of
the parser. For non-projective cases, preprocess-
ing and postprocessing are applied.
3 Reinforcement Learning
3.1 General Framework
We begin with looking at the general framework to
integrate RL into the transition-based dependency
model. In this paper, we reformulate the depen-
dency parsing as Markov Decision Process (MDP,
(S,A, T , r)) where:
? S is the set of states.
? A is the set of possible actions.
? T is the transition function, T : S ?A ? S.
we denote the transition probability Pij(a) =
P (st+1 = j|st = i, At = a).
? r is the reward function by executing action
a in a certain state, which is denoted as ri(a).
As aforesaid, the key task of dependency pars-
ing is to select the optimal action to be performed
based on the current state. Given the expected im-
mediate reward r, the optimal policy (pi : S 7? A)
is to maximize the long-term expected reward as
follows:
Rt =
??
k=0
?krt+k (1)
Given a policy pi, state-action function Qpi(i, a)
can be defined as the expected accumulative re-
ward received by taking action a in state s. It takes
the following form:
Qpi(i, a) = Epi[
??
k=0
?krt+k|st = i, at = a]
= ?
j
Pij(a)[ri(a) + ?
?
b
pi(j, b)Qpi(j, b)]
(2)
Here pi(j, b) is the probability of picking up action
b in state j, ? ? [0, 1] is a discount factor to con-
trol the involvement of further actions. According
to the Bellman equation, the state-action function
can be updated iteratively with equation( 2).
Given the state-action function, a greedy policy
can be found by maximizing over possible actions:
pi? = argmax
a
Qpi(i, a) (3)
In the following, we will discuss how to com-
pute the state-action function Q by investigating
the free energy in RBM.
3.2 Restricted Boltzmann Machine
3.2.1 Free Energy
Figure 1 shows the general framework of our
model. At each time step t, there is no connections
between nodes within the same layer. In the net-
work, ?visible? variables include both states and
actions (V = S?A). The visible layer is fully con-
nected to a ?hidden? layer, which can be regarded
as a Restricted Boltzmann Machine (RBM).
In our model, both states and actions are fac-
tored. They are consisted of a sets of discrete vari-
ables (Sallans and Hinton, 2004). The stochas-
tic energy of the network can be computed by
the conductivities between visible and hidden vari-
ables.
E(s, a, h) = ??
i,k
wiksihk ?
?
j,k
?jkajhk (4)
235
The above energy determine their equilibrium
probabilities via the Boltzmann distribution:
P (s, a, h) = exp(?E(s, a, h))?
s?,a?,h? exp(?E(s?, a?, h?))
(5)
By marginalizing out the hidden variables, we
can obtain the ?equilibrium free energy? of s and
a, which can be expressed as an expected energy
minus an entropy:
F (s,a)=??k(
?
i(wiksi?hk?)+
?
j(?jkaj?hk?))
+
?
k?hk? log?hk?+(1??hk?) log(1??hk?)
(6)
where ?hk? is the expected value of variable hk:
?hk? = ?(
?
i,k
wiksi +
?
j,k
?jkaj) (7)
where ? = 1/(1 + e?x) is a sigmoid function.
As is proved in (Sallans and Hinton, 2004), the
value of a state-action function can be approxi-
mated by the negative free energy of the network:
Q(s, a) ? ?F (s, a) (8)
3.2.2 Parameter Learning
The parameters of the network can be updated by
the SARSA (State-Action-Reward-State-Action)
algorithm. The inputs of the SARSA algorithm
are the state-action pairs of the two neighboring
slices. Then the error can be computed as:
E(st, at) = [rt+?Q(st+1, tt+1)]?Q(st, at) (9)
Suppose the state-action function is parameter-
ized by ?. The update equation for the parameter
is:
4? ? E(st, at)??Q(st, at) (10)
Back to our model, the parameters ? = (w, u)
are given by:
?wik ?(rt+?Q(st+1,at+1)?Q(st,at))sti?hk?
?ujk ?(rt+?Q(st+1,at+1)?Q(st,at))atj?hk?
(11)
Leemon (1993) showed that the above update
rules can work well in practice even though there
is no proof of convergence in theory. In addition,
in dependency parsing task, the possible action
number is small (=4). Our experimental results
also showed that the learning rule can converge in
practice.
3.3 Action Selection
After training, we use the softmax rules to select
the optimal action for a given state. The probabil-
ity of an action is given by Boltzmann distribution:
P (a|s) ? e
Q(s,a)/?
Z (12)
Here Z is an normalization factor. ? is a pos-
itive number called the temperature. High tem-
perature means the actions are evenly distributed.
Low temperature case a great variety in selection
probability. In the limit as ? ? 0, softmax action
selection becomes greedy action selection.
4 Experiments
4.1 Settings
We use the CoNLL-X (Buchholz and Marsi,
2006) distribution data from seven different lan-
guages (Arabic, Bulgarian, Dutch, Portuguese,
Slovene, Spanish and Swedish). These treebanks
varied in sizes from 29,000 to 207,000 tokens. The
cut-off frequency for training data is 20, which
means we ignores any attribute (FORM, LEMMA,
POS or FEATS) occurred less than 20. Further-
more we randomly selected 10 percent of train-
ing data to construct the validation set. Test sets
are about equal for all languages. Since our algo-
rithm only deals with projective cases, we use pro-
jectivization/deprojectivization method for train-
ing and testing data.
For fair comparison, we use the exactly same
feature set as Nivre et al (2006), which is com-
prised of a variety of features extracted from the
stack, the queue and the partially built dependency
graph.
In our experiment, the immediate reward value
is defined as the Hamming Loss between partial
tree and expected tree, which counts the number
of places that the partial output y? differs from the
true output y: ?Ti=1 1[yi 6= y?i].As shown in Figure 1, we compute the state-
action function using a feed-forward neural net-
work with one hidden layer. The number of hid-
den variables is set to match the variable number in
the visible layer (i.e. total number of state and ac-
tion variables). The parameters of the network are
modified by SARSA algorithm according to equa-
tion 2. Finally, 10-width beam search is employed
for all languages, during testing.
There are other parameters in our experiments,
which can be tuned using search. For simplicity,
236
Ar Bu Du Po Sl Sp Sw
LAS Our 63.24 88.89 79.06 87.54 72.44 82.79 87.20Nivre 66.71 87.41 78.59 87.60 70.30 81.29 84.58
UAS Our 75.30 92.88 83.14 91.34 80.06 86.18 91.84Nivre 77.51 91.72 81.35 91.22 78.72 84.67 89.50
Table 1: Comparison of dependency accuracy with Nivre
the learning rate was exponentially decreased form
0.1 to 0.01 in the course of each epoch. In ideal
cases, the discount factor should be set to 1. In our
experiments, discount factor is fixed to 0.6 consid-
ering the computational burden in long sentence.
The study of the this parameter is still left for fu-
ture work. Finally, the inverse temperature linearly
increased from 0 to 2.
4.2 Results
The performance of our model is evaluated by
the official attachment score, including labeled
(LAS=the percentage of tokens with the correct
head and label) and unlabeled (UAS=the percent-
age of tokens with the correct head). Punctuation
tokens were excluded from scoring.
The result comparison between our system and
Nivre?s transition-based system is shown in Ta-
ble 11. From the table, we can see that the pro-
posed model outperformed the Nivre?s score in all
languages except Arabic. In Arabic, our results are
worse than Nivre, with about 3.5% performance
reduction in LAS measure and 2.2% in UAS. Most
of our errors occur in POSTAGS with N (16%
head errors and 31% dep errors) and P (47% head
errors and 8% dep errors), which is probably due
to the flexible usage of those two tags in Ara-
bic. The best performance of our model happens
in Swedish. The LAS improves from 84.58% to
87.20%, whereas UAS improves from 89.5% to
91.84%. The reason might be that the long depen-
dent relationship is not popular in Swedish. Fi-
nally, we believe the performance will be further
improved by carefully tuning parameters or broad-
ening the beam search width.
5 Conclusions
In this paper we proposed a dependency parsing
based on reinforcement learning. The parser uses
a policy to select the optimal transition in each
parsing stage. The policy is learned from RL in
1The performance of other systems can be accessed from
http://nextens.uvt.nl/?conll
terms of the long-term reward. Tentative experi-
mental evaluations show that the introduction of
RL is feasible for some NLP applications. Finally,
there are a lot of future work, including the hierar-
chical model and parameter selections.
References
Sabine Buchholz and Erwin Marsi. 2006. Conll-
x shared task on multilingual dependency parsing.
In Proceedings of the Tenth Conference on Com-
putational Natural Language Learning (CoNLL-X),
pages 149?164, New York City, June. Association
for Computational Linguistics.
Hal Daume? III, John Langford, and Daniel Marcu.
2006. Searn in practice.
Leemon C. Baird III and A. Harry. Klopf. 1993. Rein-
forcement learning with high-dimensional, contin-
uous actions. Technical Report WL?TR-93-1147,
Wright-Patterson Air Force Base Ohio: Wright Lab-
oratory.
Sandra Ku?bler, Ryan McDonald, and Joakim Nivre.
2009. Dependency parsing. Calif, Morgan & Clay-
pool publishers, US.
Ryan McDonald and Giorgio Satta. 2007. On the com-
plexity of non-projective data-driven dependency
parsing. In Proceedings of the Tenth International
Conference on Parsing Technologies, pages 121?
132, Prague, Czech Republic, June. Association for
Computational Linguistics.
Joakim Nivre and Ryan McDonald. 2008. Integrat-
ing graph-based and transition-based dependency
parsers. In Proceedings of ACL-08: HLT, pages
950?958, Columbus, Ohio, June. Association for
Computational Linguistics.
Joakim Nivre, Johan Hall, Jens Nilsson, Gu?ls?en
Eryig?it, and Svetoslav Marinov. 2006. Labeled
pseudo-projective dependency parsing with support
vector machines. In Proceedings of the Tenth Con-
ference on Computational Natural Language Learn-
ing (CoNLL-X), pages 221?225, New York City,
June. Association for Computational Linguistics.
Brian Sallans and Geoffrey E. Hinton. 2004. Rein-
forcement learning with factored states and actions.
Journal of Machine Learning Research, 5:1063?
1088.
237
Bigram HMM with Context Distribution Clustering for Unsupervised
Chinese Part-of-Speech tagging
Lidan Zhang
Department of Computer Science
the University of Hong Kong
Hong Kong
lzhang@cs.hku.hk
Kwok-Ping Chan
Department of Computer Science
the University of Hong Kong
Hong Kong
kpchan@cs.hku.hk
Abstract
This paper presents an unsupervised
Chinese Part-of-Speech (POS) tagging
model based on the first-order HMM.
Unlike the conventional HMM, the num-
ber of hidden states is not fixed and will
be increased to fit the training data. In
favor of sparse distribution, the Dirich-
let priors are introduced with variational
inference method. To reduce the emis-
sion variables, words are represented by
their contexts and clustered based on the
distributional similarities between con-
texts. Experiment results show the out-
put state sequence of HMM are highly
correlated to the latent annotations of
gold POS tags, in context of clustering
similarity measures. The other exper-
iments on a real application, unsuper-
vised dependency parsing, reveal that the
output sequence can replace the manu-
ally annotated tags without loss of accu-
racies.
1 Introduction
Recently latent variable model has shown great
potential in recovering the underlying structures.
For example, the task of POS tagging is to re-
cover the appropriate sequence structure given
the input word sequence (Goldwater and Grif-
fiths, 2007). One of the most popular exam-
ple of latent models is Hidden Markov Model
(HMM), which has been extensively studied for
many years (Rabiner, 1989). The key problem
of HMM is how to find an optimal hidden state
number and the topology appropriately.
In most cases, the topology of HMM is pre-
defined by exploiting the domain or empirical
knowledge. This topology will be fixed during
the whole process. Therefore how to select the
optimal topology for a certain application or a set
of training data is still a problem, because many
researches show that varying the size of the state
space greatly affects the performance of HMM.
Generally there are two ways to adjust the state
number: top-down and bottom-up methods. In
the bottom-up methods (Brand, 1999), the state
number is initialized with a relatively large num-
ber. During the training, the states are merged or
trimmed and ended with a small set of states. On
the other hand, the top-down methods (Siddiqi et
al., 2007) start from a small state set and split one
or some states until no further improvement can
be obtained. The bottom-up approaches require
huge computational cost in deciding the states to
be merged, which makes it impractical for appli-
cations with large state space. In this paper, we
focus on the latter approaches.
Another problem in HMM is that EM algo-
rithm might yield local maximum value. John-
son (2007) points out that training HMM with
EM gives poor results because it leads to a fairly
flat distribution of hidden states when the empiri-
cal distribution is highly skewed. A multinomial
prior, which favors sparse distribution, is a good
choice for natural language tasks. In this paper,
we proposed a new procedure for inferring the
HMM topology and estimating its parameters si-
multaneously. Gibbs sampling has been used in
infinite HMM (iHMM) (Beal et al, 2001; Fox et
al., 2008; Van Gael et al, 2008) for inference.
Unfortunately Gibbs sampling is slow and diffi-
cult to be converged. In this paper, we proposed
the variational Bayesian inference for the adap-
tive HMMmodel with Dirichlet prior. It involves
a modification to the Baum-Welch algorithm. In
each iteration, we replaced only one hidden state
with two new states until convergence.
To reduce the number of observation vari-
ables, the words are pre-clustered and repre-
sented by the exemplar within the same clus-
ter. It is a one-to-many clustering, because the
same word play different roles under different
contexts. We evaluate the similarity between the
distribution of contexts, with the assumption that
the context distribution implies syntactic pattern
of the given word (Zelling, 1968; Weeds and
Weir, 2003). With this clustering, more contex-
tual information can be considered without in-
creasing the model complexity. A relatively sim-
ple model is important for unsupervised task in
terms of computational burden and data sparse-
ness. This is the reason why we do not increase
the order of HMM(Kaji and Kitsuregawa, 2008;
Headden et al, 2008).
With unsupervised algorithms, there are two
aspects to be evaluated (Van Gael et al, 2009).
Fist one is how good the outcome clusters are.
We compare the HMM results with the manu-
ally POS tags and report the similarity measures
based on information theory. On the other hand,
we test how good the outputs act as an interme-
diate results. In many natural language tasks, the
inputs are word class, not the actual lexical item,
for reason of sparsity. In this paper, we choose
the unsupervised dependency parsing as the ap-
plication to investigate whether our clusters can
replace the manual labeled tags or not.
The paper is organized as below: in section 2,
we describe the definition of HMM and its vari-
ance inference. We present our dynamic HMM
in section 3. To overcome the context limitation
in the first-order HMM, we present our distribu-
tional similarity clustering in section 4. In sec-
tion 5, we reported the results of the mentioned
experiments while section 6 concludes the paper.
2 Terminology
The task of POS tagging is to assign a syntac-
tic category sequence to the input words. Let
S be defined as the set of all possible hidden
states, which are expected to be highly correlated
to POS tags. ? represents the set of all words.
Therefore the task is to find a sequence of tag
sequence S = s1...sn ? S given a sequence of
words (i.e. a sentence, W = w1...wn ? ?). The
optimal tags is to maximize the conditional prob-
ability p(S |W), which is equal to:
max
S
p(S |W) = max
S
p(S )p(W |S )
= max
S
p(W, S )
(1)
In this paper,we consider the first-order HMM,
where the POS tags are regarded as hidden states
and words as observed variables. According to
the Markov assumption, the best sequence of
tags S for a given sequence of words W is done
by maximizing (with s0 = 0) the joint probabil-
ity:
p(W, S ) =
n
?
i=1
p(si|si?1)p(wi|si) (2)
where w0 is the special boundary marker of sen-
tences.
2.1 Variational Inference for HMM
Let the HMM be modeled with parameter ? =
(A, B, pi), where A = {ai j} = {P(st = j|st?1 = i)}
is the transition matrix governing the dynamic of
the HMM. B = {bt(i)} = {P(wt = i|st}) is the state
emission matrix and pi = {pii} = {P(s1 = i)} as-
signs the initial probabilities to all hidden states.
In favor of sparse distributions, a natural choice
is to encode Dirichlet prior into parameters p(?).
In particular, we have:
p(A) =
N
?
i=1
Dir({ai1, ..., aiN} |u(A))
p(B) =
N
?
i=1
Dir({bi1, ..., biN} |u(B))
p(pi) = Dir({pi1, ..., piN} |u(pi))
(3)
where the Dirichlet distribution of order N with
hyperparameter vector u is defined as:
Dir(x|u) =
?(
?N
i=1 ui)
?N
i=1 ?(ui)
N
?
i=1
xui?1i . (4)
In this paper, we consider the symmetric
Dirichlet distribution with a fixed length, i.e.
u = [
?N
i=1 ui/N, ...,
?N
i=1 ui/N].
In the Bayesian framework, the model param-
eters are also regarded as hidden variables. The
marginal likelihood can be calculated by sum-
ming up all hidden variables. According to the
Jensen?s inequality, the lower bound of marginal
likelihood is defined as:
ln p(W) = ln
?
?
S
p(?)p(W, S |?)d?
?
?
?
S
q(?, S ) ln
p(W, S , ?)
q(?, S )
d?
= F
(5)
Generally, Variational Bayesian Inference
aims to find a tractable distribution q(?, s) that
maximizes the lower bound F . To make infer-
ence flexible, the posterior distribution can be
assumed to be factorized according to the mean-
field assumption. We have:
p(W, S , ?) ? q(S , ?) = q
?
(?)qS (S ) (6)
Then an extension of EM algorithm (called
Baum-Welch algorithm) can be used to alter-
nately optimize the qS and q?. The EM process
is described as follows:
? E Step: Forward-Backward algorithm to
find the optimal state sequence S (t+1) =
argmax p(S (t)|W, ?(t))
? M Step: The parameters ?(t+1) are re-
estimated given the optimal state S (t+1)
The E and M steps are repeated until a conver-
gence criteria is satisfied. Beal (2003) proved
that only need to do minor modifications in M
step (in 1) is needed, when Dirichlet prior is in-
troduced.
3 Adaptive Hidden Markov Model
As aforementioned, the key problem of HMM is
how to initialize the number of hidden states and
select the topology of HMM. In this paper, we
use the top-down scheme: starting from a small
number of states, only one state is chosen in each
step and splitted into two new states. This binary
split scheme is described in Figure 1.
Algorithm 1 Outline of our adpative HMM
Initialization: Initialize: t = 0, N(t)
repeat
Optimization: Find the optimal parameters
for current Nt
Candidate Generation: Split states and
generate candidate HMMs
Candidate Selection: Select the optimal
HMM from the candidates, whose hidden
state number is Nt+1
untilNo further improvement can be achieved
after splitting
In the following, we will discuss the details of
each step one by one.
3.1 Candidate Generation
Let N(t) represent the number of hidden states at
timestep t. The problem is how to choose the
states for splitting. A straightforward way is to
select all states and generate N(t) + 1 candidate
HMMs, including the original un-splitted one.
Obviously the exhaustive search is inefficient es-
pecially for large state space. To make the algo-
rithm more efficient, some constraints must be
set to narrow the search space.
Intuitively entropy implies uncertainty. So
hidden states with large conditional entropies are
desirable to be splitted. We can define the con-
ditional entropy of the state sequences given ob-
servation W as:
H(S |W) = ?
?
S
[P(S |W) log P(S |W)] (8)
Our assumption is the state to be splitted must
be the states sequence with the highest condi-
tional entropy value. This entropy can be recur-
sively calculated with complexity O(N2T ) (Her-
nando et al, 2005). Here N is the number of
A(t+1) = {a(t+1)i j } = exp[?(?
(A)
i j ) ? ?(
N
?
j=1
?
(A)
i j )] ; ?
(A)
i j = u
(A)
j + Eq(s)[ni j]
B(t+1) = {b(t+1)ik } = exp[?(?
(B)
ik ) ? ?(
T
?
k=1
?
(B)
ik )] ; ?
(B)
ik = u
(B)
k + Eq(s)[n
?
ik]
pi
(t+1)
= {pi(t+1)i } = exp[?(?
(pi)
i ) ? ?(
N
?
i=1
?
(pi)
j )]; ?
(pi)
i = u
(pi)
i + Eq(s)[n
??
i ]
(7)
Figure 1: Parameters update equations in M-step. Here E is the expectation with respect to the
model parameters. And ni j is the expected number of transition from state si to state s j; n?ik is the
expected number of times word wk occurs with state si; n??i is the occurrence of s0 = i
states and T is the length of sequence. Using
this entropy constraint, the size of candidate state
set is always smaller than the minimal value be-
tween N and T .
3.2 Candidate Selection
Given the above candidate set, the parameters of
each HMM are to be updated. Note that we just
update the parameters related to the split state,
whilst keep the others fixed. Suppose the i-th
hidden state is replaced by two new states. First
the transition matrix is enlarged from N(t) ? N(t)
dimension to (N(t) + 1) ? (N(t) + 1) dimension,
by inserting one column and row after the i-th
column and row. In the process of update, we
only change the items in the two (i and i + 1)
rows and columns. The other elements irrelevant
to the split state are not involved in the update
procedure. Similarly EM algorithm is used to
find the optimal parameters. Note that most of
the calculations can be skipped by making use
of the forward and backward probability matrix
achieved in the previous step. Therefore the con-
vergence is fast.
Given the candidate selection, we can use a
modified Baum-Welch algorithm to find optimal
states and parameters. Here we use the algorithm
in (Siddiqi et al, 2007) with some modifications
for the Dirichlet prior. In particular, in E step,
we follow their partial Forward-Background al-
gorithm to calculate E[ni j] and E[n?ik], if si or s j
is candidate state to be splitted. Then in M-step,
only rows and columns related to the candidate
state are updated according to equation (7). The
detailed description is given as appendix.
Finally it is natural to use variational bound
of marginal likelihood in equation (5) for model
scoring and convergence criterion.
4 Distributional Clustering
To reduce the number of observation variables,
the words are clustered before HMM training.
Intuitively, the words share the similar contexts
have similar syntactic property. The categories
of many words are varied in different contexts.
In other words, the cluster of a given word is
heavily dependent on the context it appears. For
example,?? can be a noun (meaning: discov-
ery) if it acts as an object, or a verb (meaning: to
discover) if it is followed with a noun. Further-
more the introduction of context can overcome
the limited context in the first-order HMM.
The underlying hypothesis of clustering based
on distributional similarity is that the words oc-
curring in similar contexts behave as similar syn-
tactic roles. In this work, the context of a word
is a trigram consist of the word immediately pre-
ceding the target and the word immediately fol-
lowing it. The similarity between two words
is measured by Pointwise Mutual Information
(PMI) between the context pair in which they ap-
pear:
PMI(wi,w j) = log
P(ci, c j)
P(ci)P(c j)
(9)
where ci denotes the context of wi. P(ci, c j) is
the co-occurrence probability of ci and c j, and
P(ci) =
?
j P(ci, c j) is the occurrence probabil-
ity of ci. In our experiments, the cutoff context
count is set to 10, which means the frequency
less than the threshold is labeled as the unknown
context.
The above distributional similarity can be
used as a distance measure. Hence any cluster-
ing algorithm can be adopted. In this paper, we
use the affinity propagation algorithm (Frey and
Dueck, 2007). Its parameter ?dampfact? is set
to 0.9, and the other parameters are set as de-
fault. After running the clustering algorithm, the
contexts are clustered into 1869 clusterings. It
is noted that one word might be classified into
several clusters , if its contexts are clustered into
several clusters.
5 Experiments
As aforementioned, the outputs of our HMM
model are evaluated in two ways, clustering met-
ric and parsing performance. The data used in all
experiments are the Chinese data set in CoNLL-
2007 shared task. The number of tokens in
training, development and test sets are 609,060,
49,620 and 73,153 respectively. We use all train-
ing data set for training the model, whose maxi-
mum length is 242.
The hyper parameters of Dirichlet priors are
initialized in a homogeneous way. The initial
hidden state is set to 40 in all experiments. After
several iterations, the hidden states number con-
verged to 247, which is much larger than the size
of the manually defined POS tags. Our expec-
tation is the refinement variables can reveal the
deep granularity of the POS tags.
5.1 Clustering Evaluation
In this paper, we use information theoretic based
metrics to quantify the information shared by
two clusters. The most common information-
based clustering metric is the variational of In-
formation (VI)(Meila?, 2007). Given the cluster-
ing resultCr and the gold clusteringCg, VI sums
up the conditional entropy of one cluster distri-
bution given the other one:
VI(Cr,Cg) = H(Cr) + H(Cg) ? 2I(Cr,Cg)
= H(Cr |Cg) + H(Cg|Cr)
(10)
where H(Cr) is the entropy associated with the
clustering Cr, and mutual information I(Cr,Cg)
quantifies the mutual dependence between two
clusterings, or say the shared information be-
tween two variables. It is easy to see that
VI? [0, log(N)], where N is the number of data
points. However, the standard VI is not normal-
ized, which favors clusterings with a small num-
ber of clusters. It can be normalized by divid-
ing by log(N), because the number of training
instances are fixed. However the normalized VI
score is misleadingly large, if the N is very large
which is the case in our task. In this paper only
un-normalized VI scores are reported to show the
score ranking.
To standardize the measures to have fixed
bounds, (Strehl and Ghosh, 2003) defined the
normalized Mutual Information (NMI) as:
NMI(Cr,Cg) =
I(Cr,Cg)
?
H(Cr)H(Cg)
(11)
NMI takes its lower bound of 0 if no information
is shared by two clusters and the upper bound
of 1 if two clusterings are identical. The NMI
however, still has problems, whose variation is
sensitive to the choice of the number of clusters.
Rosenberg and Hirschberg (2007) proposed
V-measure to combine two desirable properties
of clustering: homogeneity (h) and completeness
(c) as follows:
h = 1 ? H(Cg|Cr)/H(Cg)
c = 1 ? H(Cr |Cg)/H(Cr)
V = 2hc/(h + c)
(12)
Generally homogeneity and completeness
runs in opposite way, whose harmonic mean (i.e.
V-measure) is a comprise score, just like F-score
for the precision and recall.
Let us first examine the contextual word clus-
tering performance. The VI score between dis-
tributional word categories and gold standard is
2.39. The NMI and V-measure score are 0.53
and 0.48, respectively.
The clustering performance of the HMM out-
puts are reported in Figure 2. The best VI
score achieved was 3.9524, while V-measure
was 62.09% and NMI reached 0.8051. Previous
40 60 80 100 120 140 160 180 200 220 2403.8
4
4.2
4.4
4.6
4.8
5
(a) VI score
40 60 80 100 120 140 160 180 200 220 2400
0.1
0.2
0.3
0.4
0.5
0.6
0.7
 
 
NMIhomogeneitycompletenessV?measure
(b) normalized scores
Figure 2: Clustering evaluation metrics against number of hidden states
work of Chinese tagging focuses on the tagging
accuracies, e.g. Wang (Wang and Schuurmans,
) and Huang et al (Huang et al, 2007). To
our knowledge, this is the first work to report
the distributional clustering similarity measures
based on informatics view for Chinese . Simi-
lar works can be found on English of WSJ cor-
pus (Van Gael et al, 2009). Their best results of
VI, V-measure, achieved with Pitman-Yor prior,
were 3.73 and 59%. We believe the Chinese re-
sults are not good as English correspondences
because of the rich unknown words in Chinese
(Tseng et al, 2005).
5.2 Dependency Parsing Evaluation
The next experiment is to test the goodness of the
outcome states of our model in the context of real
tasks. In this work, we consider unsupervised
dependency parsing for a fully unsupervised sys-
tem. The dependency parsing is to extract the
dependency graph whose nodes are the words of
the given sentence. The dependency graph is a
directed acyclic graph in which every edge links
from a head word to its dependent. Because we
work on unsupervised methods in this paper, we
choose a simple generative head-outward model
(DependencyModel with Valence, DMV) (Klein
and Manning, 2004; Headden III et al, 2009) for
parsing. The data through the experiment is re-
stricted to the sentences up to length 10 (exclud-
ing punctuation).
Because the main purpose is to test the HMM
output rather than to improve the parsing perfor-
mance, we select the original DMV model with-
out extensions or modifications. Starting from
the root, DMV generates the head, and then each
head recursively generates its left and right de-
pendents. In each direction, the possible depen-
dents are repeatedly chosen until a STOP marker
is seen. DMV use inside-outside algorithm for
re-estimation. We choose the ?harmonic? ini-
tializer proposed in (Klein and Manning, 2004)
for initialization. The valence information is the
simplest binary value indicating the adjacency.
For different HMM candidates with varied hid-
den state number, we directly use the outputs as
the input of the DMV and trained a set of models.
Performing test on these individual models, we
report the directed dependency accuracies (the
fraction of words assigned the correct parent) in
Figure 3.
40 60 80 100 120 140 160 180 200 220 24035
40
45
50
55
Figure 3: Directed accuracies for different hid-
den states
It is noted that the accuracy monotonically
increases when the number of states increases.
The most drastic increase happened when state
changes from 40 to 120. The accuracy increased
from 38.56% to 50.60%. If the state number is
larger than 180, the increase is not obvious. The
final best accuracy is 54.20%, which improve the
standard DMV model by 5.6%. Therefore we
can see that the introduction of more annotations
can help the parsing results. However, the im-
provement is limited and stable when the num-
ber of state number is large. To further improve
the parsing performance, one might turn to the
extension of DMV model, e.g. introducing more
knowledge (prior or lexical information) or more
sophistical smoothing techniques. However, the
development of parser is not the focus of this pa-
per.
6 Conclusion and Future Work
This paper works on the unsupervised Chinese
POS tagging based on the first-order HMM. Our
contributions are: 1). The number of hidden
states can be adjusted to fit the data. 2). For in-
ference, we use the variational inference, which
is faster and is guaranteed theoretically to con-
vergence. 3). To overcome the context limitation
in HMM, the words are clustered based on dis-
tributional similarities. It is a 1-to-many cluster-
ing, which means one word might be classified
into different clusters under different contexts.
Finally, experiments show the hidden states are
correlated to the latent annotations of the stan-
dard POS tags.
The future work includes to improve the per-
formance by incorporating a small amount of su-
pervision. The typical supervision used before
is dictionary extracted from a large corpus like
Chinese Gigaword. Another interesting idea is
to select some exemplars (Haghighi and Klein,
2006).
References
Beal, Matthew J., Zoubin Ghahramani, and Carl Ed-
ward Rasmussen. 2001. The infinite hidden
markov model. In NIPS, pages 577?584.
Beal, M. J. 2003. Variational algorithms for
approximate bayesian inference. Phd Thesis.
Gatsby Computational Neuroscience Unit, Uni-
versity College London.
Brand, Matthew. 1999. An entropic estimator for
structure discovery. In Proceedings of the 1998
conference on Advances in neural information pro-
cessing systems II, pages 723?729, Cambridge,
MA, USA. MIT Press.
Fox, Emily B., Erik B. Sudderth, Michael I. Jordan,
and Alan S. Willsky. 2008. An hdp-hmm for sys-
tems with state persistence. In ICML ?08: Pro-
ceedings of the 25th international conference on
Machine learning.
Frey, Brendan J. and Delbert Dueck. 2007. Clus-
tering by passing messages between data points.
Science, 315:972?976.
Goldwater, Sharon and Tom Griffiths. 2007. A
fully bayesian approach to unsupervised part-of-
speech tagging. In Proceedings of the 45th Annual
Meeting of the Association of Computational Lin-
guistics, pages 744?751, Prague, Czech Republic,
June. Association for Computational Linguistics.
Haghighi, Aria and Dan Klein. 2006. Prototype-
driven learning for sequence models. In Pro-
ceedings of the main conference on Human Lan-
guage Technology Conference of the North Amer-
ican Chapter of the Association of Computational
Linguistics, pages 320?327.
Headden, III, William P., David McClosky, and Eu-
gene Charniak. 2008. Evaluating unsupervised
part-of-speech tagging for grammar induction. In
COLING ?08: Proceedings of the 22nd Interna-
tional Conference on Computational Linguistics,
pages 329?336, Morristown, NJ, USA. Associa-
tion for Computational Linguistics.
Headden III, William P., Mark Johnson, and David
McClosky. 2009. Improving unsupervised depen-
dency parsing with richer contexts and smoothing.
In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics, pages 101?109, Boulder, Colorado,
June. Association for Computational Linguistics.
Hernando, D., V. Crespi, and G. Cybenko. 2005. Ef-
ficient computation of the hidden markov model
entropy for a given observation sequence. vol-
ume 51, pages 2681?2685.
Huang, Zhongqiang, Mary Harper, and Wen Wang.
2007. Mandarin part-of-speech tagging and dis-
criminative reranking. In Proceedings of the 2007
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Nat-
ural Language Learning (EMNLP-CoNLL), pages
1093?1102, Prague, Czech Republic, June. Asso-
ciation for Computational Linguistics.
Johnson, Mark. 2007. Why doesn?t EM find good
HMM POS-taggers? In Proceedings of the 2007
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Nat-
ural Language Learning (EMNLP-CoNLL), pages
296?305, Prague, Czech Republic, June. Associa-
tion for Computational Linguistics.
Kaji, Nobuhiro and Masaru Kitsuregawa. 2008. Us-
ing hidden markov random fields to combine dis-
tributional and pattern-based word clustering. In
COLING ?08: Proceedings of the 22nd Interna-
tional Conference on Computational Linguistics,
pages 401?408, Morristown, NJ, USA. Associa-
tion for Computational Linguistics.
Klein, Dan and Christopher Manning. 2004. Corpus-
based induction of syntactic structure: Models of
dependency and constituency. In Proceedings of
the 42nd Meeting of the Association for Computa-
tional Linguistics (ACL?04), Main Volume, pages
478?485, Barcelona, Spain, July.
Meila?, Marina. 2007. Comparing clusterings?an in-
formation based distance. volume 98, pages 873?
895.
Rabiner, Lawrence R. 1989. A tutorial on hidden
markov models and selected applications in speech
recognition. In Proceedings of the IEEE, pages
257?286.
Rosenberg, Andrew and Julia Hirschberg. 2007.
V-measure: A conditional entropy-based exter-
nal cluster evaluation measure. In Proceedings
of the 2007 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 410?420.
Siddiqi, Sajid, Geoffrey Gordon, and Andrew Moore.
2007. Fast state discovery for hmm model selec-
tion and learning. In Proceedings of the Eleventh
International Conference on Artificial Intelligence
and Statistics (AI-STATS).
Strehl, Alexander and Joydeep Ghosh. 2003. Clus-
ter ensembles ? a knowledge reuse framework
for combining multiple partitions. Journal of Ma-
chine Learning Research, 3:583?617.
Tseng, Huihsin, Daniel Jurafsky, and Christopher
Manning. 2005. Morphological features help pos
tagging of unknown words across language vari-
eties. pages 32?39.
Van Gael, Jurgen, Yunus Saatci, Yee Whye Teh, and
Zoubin Ghahramani. 2008. Beam sampling for
the infinite hidden markov model. In ICML ?08:
Proceedings of the 25th international conference
on Machine learning.
Van Gael, Jurgen, Andreas Vlachos, and Zoubin
Ghahramani. 2009. The infinite HMM for unsu-
pervised PoS tagging. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 678?687, Singapore, Au-
gust. Association for Computational Linguistics.
Wang, Qin Iris and Dale Schuurmans. Improved es-
timation for unsupervised part-of-speech tagging.
page 2005, Wuhan, China.
Weeds, Julie and David Weir. 2003. A general
framework for distributional similarity. In Pro-
ceedings of the 2003 conference on Empirical
methods in natural language processing, pages
81?88, Morristown, NJ, USA. Association for
Computational Linguistics.
Zelling, Harris. 1968. Mathematical sturcture of lan-
guage. NewYork:Wiley.
APPENDIX
Pseudo-code of the extended Baum-Welch Al-
gorithm in our dynamic HMM
Input: Time step t:
State Candidate: k ? (k(1), k(2)) ;
Sate Number: Nt;
Model Parameter: ?(t) = (A(t), B(t), pi(t));
Initialize
u(l)[k(1), k(2)]? [ u
(l)[k]
2 ,
u(l)[k]
2 ], l ? {A, B, pi}
pik(1) ? 12pik; pik(2) ?
1
2pik
ak?k(i) ? 12ak?k(i) ; ak(i)k? ? ak(i)k?;
ak(i)k( j) ? 12ak(i)k( j) , here i, j ? 1, 2, k? , k
repeat
E step:
update forward: ?t(k(1)) and ?t(k(2))
backward: ?t(k(1)) and ?t(k(2))
update ?t(i, j) and ?t(i); if i, j ? {k(1), k(2)}
update E[ni j] =
?
t ?t(i, j)/
?
t ?t(i)
E[nik] =
?
t,wt=k ?t( j)/
?
t ?t( j)
M step:
update ?(t+1) using equation (7)
until (4F < ?)
Output: ?(t+1), F
