Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 601?608
Manchester, August 2008
Modeling the Structure and Dynamics of the
Consonant Inventories: A Complex Network Approach
Animesh Mukherjee1, Monojit Choudhury2, Anupam Basu1, Niloy Ganguly1
1Department of Computer Science and Engineering,
Indian Institute of Technology, Kharagpur, India ? 721302
2Microsoft Research India, Bangalore, India ? 560080
{animeshm,anupam,niloy}@cse.iitkgp.ernet.in,
monojitc@microsoft.com
Abstract
We study the self-organization of the con-
sonant inventories through a complex net-
work approach. We observe that the dis-
tribution of occurrence as well as co-
occurrence of the consonants across lan-
guages follow a power-law behavior. The
co-occurrence network of consonants ex-
hibits a high clustering coefficient. We
propose four novel synthesis models for
these networks (each of which is a refine-
ment of the earlier) so as to successively
match with higher accuracy (a) the above
mentioned topological properties as well
as (b) the linguistic property of feature
economy exhibited by the consonant inven-
tories. We conclude by arguing that a pos-
sible interpretation of this mechanism of
network growth is the process of child lan-
guage acquisition. Such models essentially
increase our understanding of the struc-
ture of languages that is influenced by their
evolutionary dynamics and this, in turn,
can be extremely useful for building future
NLP applications.
1 Introduction
A large number of regular patterns are observed
across the sound inventories of human languages.
These regularities are arguably a consequence of
the self-organization that is instrumental in the
emergence of these inventories (de Boer, 2000).
Many attempts have been made by functional pho-
nologists for explaining this self-organizing behav-
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
ior through certain general principles such as max-
imal perceptual contrast (Liljencrants and Lind-
blom, 1972), ease of articulation (Lindblom and
Maddieson, 1988; de Boer, 2000), and ease of
learnability (de Boer, 2000). In fact, there are a
lot of studies that attempt to explain the emergence
of the vowel inventories through the application of
one or more of the above principles (Liljencrants
and Lindblom, 1972; de Boer, 2000). Some studies
have also been carried out in the area of linguistics
that seek to reason the observed patterns in the con-
sonant inventories (Trubetzkoy, 1939; Lindblom
and Maddieson, 1988; Boersma, 1998; Clements,
2008). Nevertheless, most of these works are con-
fined to certain individual principles rather than
formulating a general theory describing the emer-
gence of these regular patterns across the conso-
nant inventories.
The self-organization of the consonant inven-
tories emerges due to an interaction of different
forces acting upon them. In order to identify the
nature of these interactions one has to understand
the growth dynamics of these inventories. The the-
ories of complex networks provide a number of
growth models that have proved to be extremely
successful in explaining the evolutionary dynam-
ics of various social (Newman, 2001; Ramasco et
al., 2004), biological (Jeong et al, 2000) and other
natural systems. The basic framework for the cur-
rent study develops around two such complex net-
works namely, the Phoneme-Language Network
or PlaNet (Choudhury et al, 2006) and its one-
mode projection, the Phoneme-Phoneme Network
or PhoNet (Mukherjee et al2007a). We begin by
analyzing some of the structural properties (Sec. 2)
of the networks and observe that the consonant
nodes in both PlaNet and PhoNet follow a power-
law-like degree distribution. Moreover, PhoNet
601
is characterized by a high clustering coefficient,
a property that has been found to be prevalent in
many other social networks (Newman, 2001; Ra-
masco et al, 2004).
We propose four synthesis models for PlaNet
(Sec. 3), each of which employ a variant of a pref-
erential attachment (Baraba?si and Albert, 1999)
based growth kernel1. While the first two mod-
els are independent of the characteristic proper-
ties of the (consonant) nodes, the following two
use them. These models are successively refined
not only to reproduce the topological properties of
PlaNet and PhoNet, but also to match the linguis-
tic property of feature economy (Boersma, 1998;
Clements, 2008) that is observed across the conso-
nant inventories. The underlying growth rules for
each of these individual models helps us to inter-
pret the cause of the emergence of at least one (or
more) of the aforementioned properties. We con-
clude (Sec. 4) by providing a possible interpreta-
tion of the proposed mathematical model that we
finally develop in terms of child language acquisi-
tion.
There are three major contributions of this work.
Firstly, it provides a fascinating account of the
structure and the evolution of the human speech
sound systems. Furthermore, the introduction of
the node property based synthesis model is a sig-
nificant contribution to the field of complex net-
works. On a broader perspective, this work shows
how statistical mechanics can be applied in under-
standing the structure of a linguistic system, which
in turn can be extremely useful in developing fu-
ture NLP applications.
2 Properties of the Consonant
Inventories
In this section, we briefly recapitulate the defi-
nitions of PlaNet and PhoNet, the data source,
construction procedure for the networks and some
of their important structural properties. We also
revisit the concept of feature economy and the
method used for its quantification.
2.1 Structural Properties of the Consonant
Networks
PlaNet is a bipartite graph G = ? V
L
, V
C
, E
pl
? con-
sisting of two sets of nodes namely, V
L
(labeled by
the languages) and V
C
(labeled by the consonants);
1The word kernel here refers to the function or mathemat-
ical formula that drives the growth of the network.
Figure 1: Illustration of the nodes and edges of
PlaNet and PhoNet.
E
pl
is the set of edges running between V
L
and V
C
.
There is an edge e ? E
pl
from a node v
l
? V
L
to a
node v
c
? V
C
iff the consonant c is present in the
inventory of language l.
PhoNet is the one-mode projection of PlaNet
onto the consonant nodes i.e., a network of con-
sonants in which two nodes are linked by an edge
with weight as many times as they co-occur across
languages. Hence, it can be represented by a graph
G = ? V
C
, E
ph
?, where V
C
is the set of conso-
nant nodes and E
ph
is the set of edges connecting
these nodes in G. There is an edge e ? E
ph
if the
two nodes (read consonants) that are connected by
e co-occur in at least one language and the number
of languages they co-occur in defines the weight of
the edge e. Figure 1 shows the nodes and the edges
of PlaNet and PhoNet.
Data Source and Network Construction: Like
many other earlier studies (Liljencrants and Lind-
blom, 1972; Lindblom and Maddieson, 1988; de
Boer, 2000; Hinskens and Weijer, 2003), we use
the UCLA Phonological Segment Inventory Data-
base (UPSID) (Maddieson, 1984) as the source of
our data. There are 317 languages in the data-
base with a total of 541 consonants found across
them. Each consonant is characterized by a set of
phonological features (Trubetzkoy, 1931), which
distinguishes it from others. UPSID uses articula-
tory features to describe the consonants, which can
be broadly categorized into three different types
namely the manner of articulation, the place of
articulation and phonation. Manner of articu-
lation specifies how the flow of air takes place
in the vocal tract during articulation of a conso-
nant, whereas place of articulation specifies the
active speech organ and also the place where it
acts. Phonation describes the vibration of the vo-
602
Manner of Articulation Place of Articulation Phonation
tap velar voiced
flap uvular voiceless
trill dental
click palatal
nasal glottal
plosive bilabial
r-sound alveolar
fricative retroflex
affricate pharyngeal
implosive labial-velar
approximant labio-dental
ejective stop labial-palatal
affricated click dental-palatal
ejective affricate dental-alveolar
ejective fricative palato-alveolar
lateral approximant
Table 1: The table shows some of the important
features listed in UPSID. Over 99% of the UPSID
languages have bilabial, dental-alveolar and velar
plosives. Furthermore, voiceless plosives outnum-
ber the voiced ones (92% vs. 67%). 93% of the
languages have at least one fricative, 97% have at
least one nasal and 96% have at least one liquid.
Approximants occur in fewer than 95% of the lan-
guages.
cal cords during the articulation of a consonant.
Apart from these three major classes there are also
some secondary articulatory features found in cer-
tain languages. There are around 52 features listed
in UPSID; the important ones are noted in Table 1.
Note that in UPSID the features are assumed to be
binary-valued and therefore, each consonant can
be represented by a binary vector.
We have used UPSID in order to construct
PlaNet and PhoNet. Consequently, |V
L
| = 317 (in
PlaNet) and |V
C
| = 541. The number of edges in
PlaNet and PhoNet are 7022 and 30412 respec-
tively.
Degree Distributions of PlaNet and PhoNet:
The degree distribution is the fraction of nodes, de-
noted by P
k
, which have a degree2 greater than or
equal to k (Newman, 2003). The degree distribu-
tion of the consonant nodes in PlaNet and PhoNet
are shown in Figure 2 in the log-log scale. Both the
plots show a power-law behavior (P
k
? k
??) with
exponential cut-offs towards the ends. The value
of ? is 0.71 for PlaNet and 0.89 for PhoNet.
Clustering Coefficient of PhoNet: The clus-
tering coefficient for a node i is the proportion of
links between the nodes that are the neighbors of
i divided by the number of links that could pos-
sibly exist between them (Newman, 2003). Since
PhoNet is a weighted graph the above definition is
2For a weighted graph like PhoNet, the degree of a node i
is the sum of weights on the edges that are incident on i.
suitably modified by the one presented in (Barrat
et al, 2004). According to this definition, the clus-
tering coefficient for a node i is,
c
i
=
1
(
?
?j
w
ij
)
(k
i
? 1)
?
?j,l
(w
ij
+ w
il
)
2
a
ij
a
il
a
jl
(1)
where j and l are neighbors of i; k
i
represents the
plain degree of the node i; w
ij
, w
jl
and w
il
de-
note the weights of the edges connecting nodes i
and j, j and l, and i and l respectively; a
ij
, a
il
,
a
jl
are boolean variables, which are true iff there
is an edge between the nodes i and j, i and l, and j
and l respectively. The clustering coefficient of the
network (c
av
) is equal to the average clustering co-
efficient of the nodes. The value of c
av
for PhoNet
is 0.89, which is significantly higher than that of a
random graph with the same number of nodes and
edges (0.08).
2.2 Linguistic Properties: Feature Economy
and its Quantification
The principle of feature economy states that lan-
guages tend to use a small number of distinctive
features and maximize their combinatorial pos-
sibilities to generate a large number of conso-
nants (Boersma, 1998; Clements, 2008). Stated
differently, a given consonant will have a higher
than expected chance of occurrence in invento-
ries in which all of its features have already dis-
tinctively occurred in the other consonants. This
principle immediately implies that the consonants
chosen by a language should share a considerable
number of features among them. The quantifica-
tion process, which is a refinement of the idea pre-
sented in (Mukherjee et al2007b), is as follows.
Feature Entropy: For an inventory of size N ,
let there be p
f
consonants for which a particular
feature f (recall that we assume f to be binary-
valued) is present and q
f
other consonants for
which the same is absent. Therefore, the proba-
bility that a consonant (chosen uniformly at ran-
dom from this inventory) contains the feature f is
p
f
N
and the probability that it does not contain the
feature is qf
N
(=1?pf
N
). One can think of f as an in-
dependent random variable, which can take values
1 and 0, and pf
N
and qf
N
define the probability dis-
tribution of f . Therefore, for any given inventory,
we can define the binary entropy H
f
(Shannon and
Weaver, 1949) for the feature f as
H
f
= ?
p
f
N
log
2
p
f
N
?
q
f
N
log
2
q
f
N
(2)
603
Figure 2: Degree distribution (DD) of PlaNet alng with that of PlaNet
syn
obtained from Model I and II
respectively; (b) DD of PhoNet alng with that of PhoNet
syn
obtained from Model I and II respectively.
Both the plots are in log-log scale.
If F is the set of all features present in the conso-
nants forming the inventory, then feature entropy
F
E
is the sum of the binary entropies with respect
to all the features, that is
F
E
=
?
f?F
H
f
=
?
f?F
(?
p
f
N
log
2
p
f
N
?
q
f
N
log
2
q
f
N
)
(3)
Since we have assumed that f is an independent
random variable, F
E
is the joint entropy of the
system. In other words, F
E
provides an estimate
of the number of discriminative features present
in the consonants of an inventory that a speaker
(e.g., parent) has to communicate to a learner (e.g.,
child) during language transmission. The lower the
value of F
E
the higher is the feature economy. The
curve marked as (R) in Figure 3 shows the average
feature entropy of the consonant inventories of a
particular size3 (y-axis) versus the inventory size
(x-axis).
3 Synthesis Models
In this section, we describe four synthesis mod-
els that incrementally attempt to explain the emer-
gence of the structural properties of PlaNet and
PhoNet as well as the feature entropy exhibited by
the consonant inventories. In all these models, we
assume that the distribution of the consonant in-
ventory size, i.e., the degrees of the language nodes
in PlaNet, are known a priori.
3Let there be n inventories of a particular size k. The
average feature entropy of the inventories of size k is
1
n
?
n
i=1
F
E
i
, where F
E
i
signifies the feature entropy of the
i
th inventory of size k.
3.1 Model I: Preferential Attachment Kernel
This model employs a modified version of the ker-
nel described in (Choudhury et al, 2006), which is
the only work in literature that attempts to explain
the emergence of the consonant inventories in the
framework of complex networks.
Let us assume that a language node L
i
? V
L
has a degree k
i
. The consonant nodes in V
C
are
assumed to be unlabeled, i.e, they are not marked
by the distinctive features that characterize them.
We first sort the nodes L
1
through L
317
in the as-
cending order of their degrees. At each time step a
node L
j
, chosen in order, preferentially attaches it-
self with k
j
distinct nodes (call each such node C
i
)
of the set V
C
. The probability Pr(C
i
) with which
the node L
j
attaches itself to the node C
i
is given
by,
Pr(C
i
) =
d
i
?
+ ?
?
i
?
?V
?
C
(d
i
?
?
+ ?)
(4)
where, d
i
is the current degree of the node C
i
,
V
?
C
is the set of nodes in V
C
that are not already
connected to L
j
, ? is the smoothing parameter
that facilitates random attachments and ? indi-
cates whether the attachment kernel is sub-linear
(? < 1), linear (? = 1) or super-linear (? > 1).
Note that the modification from the earlier ker-
nel (Choudhury et al, 2006) is brought about by
the introduction of ?. The above process is re-
peated until all the language nodes L
j
? V
L
get
connected to k
j
consonant nodes (refer to Figure.
6 of (Choudhury et al, 2006) for an illustration of
the steps of the synthesis process). Thus, we have
604
the synthesized version of PlaNet, which we shall
call PlaNet
syn
henceforth.
The Simulation Results: We simulate the
above model to obtain PlaNet
syn
for 100 differ-
ent runs and average the results over all of them.
We find that the degree distributions that emerge
fit the empirical data well for ? ? [1.4,1.5] and
? ? [0.4,0.6], the best being at ? = 1.44 and ? = 0.5
(shown in Figure 2). In fact, the mean error4 be-
tween the real and the synthesized distributions for
the best choice of parameters is as small as 0.01.
Note that this error in case of the model presented
in (Choudhury et al, 2006) was 0.03. Furthermore,
as we shall see shortly, a super-linear kernel can
explain various other topological properties more
accurately than a linear kernel.
In absence of preferential attachment i.e., when
all the connections to the consonant nodes are
equiprobable, the mean error rises to 0.35.
A possible reason behind the success of this
model is the fact that language is a constantly
changing system and preferential attachment plays
a significant role in this change. For instance, dur-
ing the change those consonants that belong to lan-
guages that are more prevalent among the speak-
ers of a generation have higher chances of being
transmitted to the speakers of the subsequent gen-
erations (Blevins, 2004). This heterogeneity in the
choice of the consonants manifests itself as pref-
erential attachment. We conjecture that the value
of ? is a function of the societal structure and the
cognitive capabilities of human beings. The exact
nature of this function is currently not known and
a topic for future research. The parameter ? in this
case may be thought of as modeling the random-
ness of the system.
Nevertheless, the degree distribution of
PhoNet
syn
, which is the one-mode projection
of PlaNet
syn
, does not match the real data well
(see Figure 2). The mean error between the two
distributions is 0.45. Furthermore, the clustering
coefficient of PhoNet
syn
is 0.55 and differs largely
from that of PhoNet. The primary reason for this
deviation in the results is that PhoNet exhibits
strong patterns of co-occurrences (Mukherjee et
al.2007a) and this fact is not taken into account
by Model I. In order to circumvent the above
4Mean error is defined as the average difference between
the ordinate pairs (say y and y? ) where the abscissas are equal.
In other words, if there are N such ordinate pairs then the
mean error can be expressed as
?
|y?y
?
|
N
.
problem, we introduce the concept of triad (i.e.,
fully connected triplet) formation and thereby
refine the model in the following section.
3.2 Model II: Kernel based on Triad
Formation
The triad model (Peltoma?ki and Alava, 2006)
builds up on the concept of neighborhood forma-
tion. Two consonant nodes C
1
and C
2
become
neighbors if a language node at any step of the
synthesis process attaches itself to both C
1
and
C
2
. Let the probability of triad formation be de-
noted by p
t
. At each time step a language node
L
j
(chosen from the set of language nodes sorted
in ascending order of their degrees) makes the first
connection preferentially to a consonant node C
i
? V
C
to which L
j
is not already connected fol-
lowing the distribution Pr(C
i
). For the rest of the
(k
j
-1) connections L
j
attaches itself preferentially
to only the neighbors of C
i
to which L
j
is not yet
connected with a probability p
t
. Consequently, L
j
connects itself preferentially to the non-neighbors
of C
i
to which L
j
is not yet connected with a prob-
ability (1 ? p
t
). The neighbor set of C
i
gets up-
dated accordingly. Note that every time the node
C
i
and its neighbors are chosen they together im-
pose a clique on the one-mode projection. This
phenomenon leads to the formation of a large num-
ber of triangles in the one-mode projection thereby
increasing the clustering coefficient of the resultant
network.
The Simulation Results: We carry out 100 dif-
ferent simulation runs of the above model for a par-
ticular set of parameter values to obtain PlaNet
syn
and average the results over all of them. We ex-
plore several parameter settings in the range as fol-
lows: ? ? [1,1.5] (in steps of 0.1), ? ? [0.2,0.4]
(in steps of 0.1) and p
t
? [0.70,0.95] (in steps of
0.05). We also observe that if we traverse any fur-
ther along one or more of the dimensions of the pa-
rameter space then the results get worse. The best
result emerges for ? = 1.3, ? = 0.3 and p
t
= 0.8.
Figure 2 shows the degree distribution of the
consonant nodes of PlaNet
syn
and PlaNet. The
mean error between the two distributions is 0.04
approximately and is therefore worse than the re-
sult obtained from Model I. Nevertheless, the aver-
age clustering coefficient of PhoNet
syn
in this case
is 0.85, which is within 4.5% of that of PhoNet.
Moreover, in this process the mean error between
the degree distribution of PhoNet
syn
and PhoNet
605
(as illustrated in Figure 2) has got reduced drasti-
cally from 0.45 to 0.03.
One can again find a possible association of this
model with the phenomena of language change. If
a group of consonants largely co-occur in the lan-
guages of a generation of speakers then it is very
likely that all of them get transmitted together in
the subsequent generations (Blevins, 2004). The
triad formation probability ensures that if a pair of
consonant nodes become neighbors of each other
in a particular step of the synthesis process then
the choice of such a pair should be highly pre-
ferred in the subsequent steps of the process. This
is coherent with the aforementioned phenomenon
of transmission of consonants in groups over lin-
guistic generations. Since the value of p
t
that we
obtain is quite high, it may be argued that such
transmissions are largely prevalent in nature.
Although Model II reproduces the structural
properties of PlaNet and PhoNet quite accurately,
as we shall see shortly, it fails to generate inven-
tories that closely match the real ones in terms
of feature entropy. However, at this point, recall
that Model II assumes that the consonant nodes are
unlabeled; therefore, the inventories that are pro-
duced as a result of the synthesis are composed of
consonants, which unlike the real inventories, are
not marked by their distinctive features. In order
to label them we perform the following,
The Labeling Scheme:
1. Sort the consonants of UPSID in the decreasing
order of their frequency of occurrence and call this
list of consonants ListC[1 ? ? ? 541],
2. Sort the V
C
nodes of PlaNet
syn
in decreasing
order of their degree and call this list of nodes
ListN [1 ? ? ? 541],
3. ?
1?i?541
ListN [i] ?? ListC[i]
The Figure 3 indicates that the curve for the real
inventories (R) and those obtained from Model II
(M2) are significantly different from each other.
This difference arises due to the fact that in Model
II, the choice of a consonant from the set of neigh-
bors is solely degree-dependent, where the rela-
tionships between the features are not taken into
consideration. Therefore, in order to eliminate this
problem, we introduce the model using the feature-
based kernel in the next section.
3.3 Model III: Feature-based Kernel
In this model, we assume that each of the conso-
nant nodes are labeled, that is each of them are
Figure 3: Average feature entropy of the invento-
ries of a particular size (y-axis) versus the inven-
tory size (x-axis).
marked by a set of distinctive features. The attach-
ment kernel in this case has two components one
of which is preferential while the other favors the
choice of those consonants that are at a low fea-
ture distance (the number of feature positions they
differ at) from the already chosen ones. Let us de-
note the feature distance between two consonants
C
i
and C ?
i
by D(C
i
, C
?
i
). We define the affinity,
A(C
i
, C
?
i
), between C
i
and C ?
i
as
A(C
i
, C
?
i
) =
1
D(C
i
, C
?
i
)
(5)
Therefore, the lower the feature distance between
C
i
and C ?
i
the higher is the affinity between them.
At each time step a language node estab-
lishes the first connection with a consonant node
(say C
i
) preferentially following the distribution
Pr(C
i
) like the previous models. The rest of
the connections to any arbitrary consonant node
C
?
i
(not yet connected to the language node) are
made following the distribution (1?w)Pr(C ?
i
) +
wPr
aff
(C
i
, C
?
i
), where
Pr
aff
(C
i
, C
?
i
) =
A(C
i
, C
?
i
)
?
?C
?
i
A(C
i
, C
?
i
)
(6)
and 0 < w < 1.
Simulation Results: We perform 100 different
simulation runs of the above model for a particular
set of parameter values to obtain PlaNet
syn
and av-
erage the results over all of them. We explore dif-
ferent parameter settings in the range as follows:
? ? [1,2] (in steps of 0.1), ? ? [0.1,1] (in steps
of 0.1) and w ? [0.1,0.5] (in steps of 0.05). The
606
best result in terms of the structural properties of
PlaNet and PhoNet emerges for ? = 1.6, ? = 0.3
and w = 0.2.
In this case, the mean error between the de-
gree distribution curves for PlaNet
syn
and PlaNet
is 0.05 and that between of PhoNet
syn
and PhoNet
is 0.02. Furthermore, the clustering coefficient of
PhoNet
syn
in this case is 0.84, which is within
5.6% of that of PhoNet. The above results show
that the structural properties of the synthesized
networks in this case are quite similar to those
obtained through the triad model. Nevertheless,
the average feature entropy of the inventories pro-
duced (see curve M3 in Figure 3) are more close to
that of the real ones now (for quantitative compar-
ison see Table 2).
Therefore, it turns out that the groups of con-
sonants that largely co-occur in the languages
of a linguistic generation are actually driven by
the principle of feature economy (see (Clements,
2008; Mukherjee et al2007a) for details).
However, note that even for Model III the nodes
that are chosen for attachment in the initial stages
of the synthesis process are arbitrary and conse-
quently, the labels of the nodes of PlaNet
syn
do
not have a one-to-one correspondence with that of
PlaNet, which is the main reason behind the differ-
ence in the result between them. In order to over-
come this problem we can make use of a small set
of real inventories to bootstrap the model.
3.4 Model IV: Feature-based Kernel and
Bootstrapping
In order to create a bias towards the labeling
scheme prevalent in PlaNet, we use 30 (around
10% of the) real languages as a seed (chosen ran-
domly) for Model III; i.e., they are used by the
model for bootstrapping. The idea is summarized
below.
1. Select 30 real inventories at random and con-
struct a PlaNet from them. Call this network the
initial PlaNet
syn
.
2. The rest of the language nodes are incrementally
added to this initial PlaNet
syn
using Model III.
Simulation Results: The best fit now emerges
at ? = 1.35, ? = 0.3 and w = 0.15. The mean er-
ror between the degree distribution of PlaNet and
PlaNet
syn
is 0.05 and that between PhoNet and
PhoNet
syn
is 0.02. The clustering coefficient of
PhoNet
syn
is 0.83 in this case (within 6.7% of that
of PhoNet).
Results Model I Model II Model III Model IV
ME: DD of PlaNet & PlaNet
syn
0.01 0.04 0.05 0.05
ME: DD of PhoNet & PhoNet
syn
0.45 0.03 0.02 0.02
% Err: Clustering Coefficient 38.2 04.5 05.6 06.7
ME: Avg. F
E
of Real & Synth. Inv. 3.40 3.00 2.10 0.93
? 1.44 1.30 1.60 1.35
? 0.5 0.3 0.3 0.3
p
t
? 0.8 ? ?
w ? ? 0.20 0.15
Table 2: Important results obtained from each of
the models. ME: Mean Error, DD: Degree Distri-
bution.
The inventories that are produced as a result of
the bootstrapping have an average feature entropy
closer to the real inventories (see curve M4 in Fig-
ure 3) than the earlier models. Hence, we find
that this improved labeling strategy brings about
a global betterment in our results unlike in the pre-
vious cases. The larger the number of languages
used for the purpose of bootstrapping the better are
the results mainly in terms of the match in the fea-
ture entropy curves.
4 Conclusion
We dedicated the preceding sections of this article
to analyze and synthesize the consonant invento-
ries of the world?s languages in the framework of a
complex network. Table 2 summarizes the results
obtained from the four models so that the reader
can easily compare them. Some of our important
observations are
? The distribution of occurrence and co-occurrence
of consonants across languages roughly follow a
power law,
? The co-occurrence network of consonants has a
large clustering coefficient,
? Groups of consonants that largely co-occur
across languages are driven by feature economy
(which can be expressed through feature entropy),
? Each of the above properties emerges due to dif-
ferent reasons, which are successively unfurled by
our models.
So far, we have tried to explain the physical sig-
nificance of our models in terms of the process
of language change. Language change is a col-
lective phenomenon that functions at the level of
a population of speakers (Steels, 2000). Never-
theless, it is also possible to explain the signif-
icance of the models at the level of an individ-
ual, primarily in terms of the process of language
acquisition, which largely governs the course of
language change. In the initial years of language
development every child passes through a stage
607
called babbling during which he/she learns to pro-
duce non-meaningful sequences of consonants and
vowels, some of which are not even used in the
language to which they are exposed (Jakobson,
1968; Locke, 1983). Clear preferences can be
observed for learning certain sounds such as plo-
sives and nasals, whereas fricatives and liquids are
avoided. In fact, this hierarchy of preference dur-
ing the babbling stage follows the cross-linguistic
frequency distribution of the consonants. This in-
nate frequency dependent preference towards cer-
tain phonemes might be because of phonetic rea-
sons (i.e., for articulatory/perceptual benefits). In
all our models, this innate preference gets cap-
tured through the process of preferential attach-
ment. However, at the same time, in the context of
learning a particular inventory the ease of learning
the individual consonants also plays an important
role. The lower the number of new feature distinc-
tions to be learnt, the higher the ease of learning
the consonant. Therefore, there are two orthogonal
preferences: (a) the occurrence frequency depen-
dent preference (that is innate), and (b) the feature-
dependent preference (that increases the ease of
learning), which are instrumental in the acquisi-
tion of the inventories. The feature-based kernel is
essentially a linear combination of these two mu-
tually orthogonal factors.
References
A.-L. Baraba?si and R. Albert. 1999. Emergence of
scaling in random networks. Science 286, 509-512.
A. Barrat, M. Barthe?lemy, R. Pastor-Satorras and A.
Vespignani. 2004. The architecture of complex
weighted networks. PNAS 101, 3747?3752.
J. Blevins. 2004. Evolutionary Phonology: The
Emergence of Sound Patterns, Cambridge University
Press, Cambridge.
B. de Boer. 2000. Self-organisation in vowel systems.
Journal of Phonetics 28(4), 441?465.
P. Boersma. 1998. Functional Phonology, The Hague:
Holland Academic Graphics.
M. Choudhury, A. Mukherjee, A. Basu and N. Ganguly.
2006. Analysis and synthesis of the distribution of
consonants over languages: A complex network ap-
proach. Proceedings of COLING-ACL06, 128?135.
G. N. Clements. 2008. The role of features in speech
sound inventories. In Eric Raimy & Charles Cairns,
eds.,Contemporary Views on Architecture and Rep-
resentations in Phonological Theory, Cambridge,
MA: MIT Press.
F. Hinskens and J. Weijer. 2003. Patterns of segmen-
tal modification in consonant inventories: A cross-
linguistic study. Linguistics 41(6), 1041?1084.
R. Jakobson. 1968. Child Language, Aphasia and
Phonological Universals. The Hague: Mouton.
H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai and A.
L. Baraba?si. 2000. The large-scale organization of
metabolic networks. Nature 406 651-654.
J. Liljencrants and B. Lindblom. 1972. Numerical sim-
ulation of vowel quality systems: the role of percep-
tual contrast. Language 48, 839?862.
B. Lindblom and I. Maddieson. 1988. Phonetic univer-
sals in consonant systems. Language, Speech, and
Mind, 62?78, Routledge, London.
J. L. Locke. 1983. Phonological Acquisition and
Change. Academic Press New York.
I. Maddieson. 1984. Patterns of Sounds, Cambridge
University Press, Cambridge.
A. Mukherjee, M. Choudhury, A. Basu and N. Gan-
guly. 2007a. Modeling the co-occurrence principles
of the consonant inventories: A complex network ap-
proach. Int. Jour. of Mod. Phys. C 18(2), 281?295.
A. Mukherjee, M. Choudhury, A. Basu and N. Ganguly.
2007b. Redundancy ratio: An invariant property of
the consonant inventories of the world?s languages
Proceedings of ACL07, 104?111.
M. E. J. Newman. 2001. Scientific collaboration net-
works. Physical Review E 64, 016131.
M. E. J. Newman. 2003. The structure and function of
complex networks. SIAM Review 45, 167?256.
M. Peltoma?ki and M. Alava. 2006. Correlations in bi-
partite collaboration networks. Journal of Statistical
Mechanics: Theory and Experiment, P01010.
J. J. Ramasco, S. N. Dorogovtsev and R. Pastor-
Satorras. 2004. Self-organization of collaboration
networks. Physical Review E 70, 036106.
C. E. Shannon and W. Weaver. 1949. The Mathe-
matical Theory of Information. University of Illinois
Press, Urbana.
L. Steels. 2000. Language as a complex adaptive
system. In: Schoenauer, M., editor, Proceedings of
PPSN VI, LNCS, 17?26.
N. Trubetzkoy. 1931. Die phonologischen systeme.
TCLP 4, 96?116.
N. Trubetzkoy. 1969. Principles of Phonology. Eng-
lish translation of Grundzu?ge der Phonologie, 1939,
University of California Press, Berkeley.
608
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 121?129,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Large-Coverage Root Lexicon Extraction for Hindi
Cohan Sujay Carlos Monojit Choudhury Sandipan Dandapat
Microsoft Research India
monojitc@microsoft.com
Abstract
This paper describes a method using mor-
phological rules and heuristics, for the au-
tomatic extraction of large-coverage lexi-
cons of stems and root word-forms from
a raw text corpus. We cast the problem
of high-coverage lexicon extraction as one
of stemming followed by root word-form
selection. We examine the use of POS
tagging to improve precision and recall of
stemming and thereby the coverage of the
lexicon. We present accuracy, precision
and recall scores for the system on a Hindi
corpus.
1 Introduction
Large-coverage morphological lexicons are an es-
sential component of morphological analysers.
Morphological analysers find application in lan-
guage processing systems for tasks like tagging,
parsing and machine translation. While raw text
is an abundant and easily accessible linguistic re-
source, high-coverage morphological lexicons are
scarce or unavailable in Hindi as in many other
languages (Cle?ment et al, 2004). Thus, the devel-
opment of better algorithms for the extraction of
morphological lexicons from raw text corpora is a
task of considerable importance.
A root word-form lexicon is an intermediate
stage in the creation of a morphological lexicon.
In this paper, we consider the problem of extract-
ing a large-coverage root word-form lexicon for
the Hindi language, a highly inflectional and mod-
erately agglutinative Indo-European language spo-
ken widely in South Asia.
Since a POS tagger, another basic tool, was
available along with POS tagged data to train it,
and since the error patterns indicated that POS tag-
ging could greatly improve the accuracy of the lex-
icon, we used the POS tagger in our experiments
on lexicon extraction.
Previous work in morphological lexicon extrac-
tion from a raw corpus often does not achieve very
high precision and recall (de Lima, 1998; Oliver
and Tadic?, 2004). In some previous work the pro-
cess of lexicon extraction involves incremental or
post-construction manual validation of the entire
lexicon (Cle?ment et al, 2004; Sagot, 2005; Fors-
berg et al, 2006; Sagot et al, 2006; Sagot, 2007).
Our method attempts to improve on and extend
the previous work by increasing the precision and
recall of the system to such a point that manual
validation might even be rendered unnecessary.
Yet another difference, to our knowledge, is that
in our method we cast the problem of lexicon ex-
traction as two subproblems: that of stemming and
following it, that of root word-form selection.
The input resources for our system are as fol-
lows: a) raw text corpus, b) morphological rules,
c) POS tagger and d) word-segmentation labelled
data. We output a stem lexicon and a root word-
form lexicon.
We take as input a raw text corpus and a set
of morphological rules. We first run a stemming
algorithm that uses the morphological rules and
some heuristics to obtain a stem dictionary. We
then create a root dictionary from the stem dictio-
nary.
The last two input resources are optional but
when a POS tagger is utilized, the F-score (har-
monic mean of precision and recall) of the root
lexicon can be as high as 94.6%.
In the rest of the paper, we provide a brief
overview of the morphological features of the
Hindi language, followed by a description of our
method including the specification of rules, the
corpora and the heuristics for stemming and root
word-form selection. We then evaluate the system
with and without the POS tagger.
121
2 Hindi Orthography and Morphology
There are some features peculiar to Hindi orthog-
raphy and to the character encoding system that
we use. These need to be compensated for in the
system. It was also found that Hindi?s inflectional
morphology has certain characteristics that sim-
plify the word segmentation rules.
2.1 Orthography
Hindi is written in the partially-phonemic Devana-
gari script. Most consonant clusters that occur in
the language are represented by characters and lig-
atures, while a very few are represented as diacrit-
ics. Vowels that follow consonants or consonant
clusters are marked with diacritics. However, each
consonant in the Devanagari script also carries an
implicit vowel a1 unless its absence is marked by a
special diacritic ?halant?. Vowels are represented
by vowel characters when they occur at the head
of a word or after another vowel.
The y sound sometimes does not surface in the
pronunciation when it occurs between two vow-
els. So suffixes where the y is followed by e or I
can be written in two ways, with or without the y
sound in them. For instance the suffix ie can also
be written as iye.
Certain stemming rules will therefore need to
be duplicated in order to accommodate the differ-
ent spelling possibilities and the different vowel
representations in Hindi. The character encoding
also plays a small but significant role in the ease
of stemming of Hindi word-forms.
2.2 Unicode Representation
We used Unicode to encode Hindi characters. The
Unicode representation of Devanagari treats sim-
ple consonants and vowels as separate units and so
makes it easier to match substrings at consonant-
vowel boundaries. Ligatures and diacritical forms
of consonants are therefore represented by the
same character code and they can be equated very
simply.
However, when using Unicode as the charac-
ter encoding, it must be borne in mind that there
are different character codes for the vowel diacrit-
ics and for the vowel characters for one and the
same vowel sound, and that the long and short
1In the discussion in Section 2 and in Table 1 and
Table 2, we have used a loose phonetic transcription
that resembles ITRANS (developed by Avinash Chopde
http://www.aczoom.com/itrans/).
Word Form Derivational Segmentation Root
karnA kar + nA kar
karAnA kar + A + nA kar
karvAnA kar + vA + nA kar
Word Form Inflectional Segmentation Root
karnA kar + nA kar
karAnA karA + nA karA
karvAnA karvA + nA karvA
Table 1: Morpheme Segmentation
laDkA Nominative Oblique
Singular laDkA laDke
Plural laDke laDkon
laDkI Nominative Oblique
Singular laDkI laDkI
Plural laDkI laDkiyAn
Table 2: Sample Paradigms
forms of the vowels are represented by different
codes. These artifacts of the character encoding
need to be compensated for when using substring
matches to identify the short vowel sound as being
part of the corresponding prolonged vowel sound
and when stemming.
2.3 Morphology
The inflectional morphology of Hindi does not
permit agglutination. This helps keep the num-
ber of inflectional morphological rules manage-
able. However, the derivational suffixes are agglu-
tinative, leading to an explosion in the number of
root word-forms in the inflectional root lexicon.
The example in Table 1 shows that verbs can
take one of the two causative suffixes A and vA.
These being derivational suffixes are not stemmed
in our system and cause the verb lexicon to be
larger than it would have otherwise.
2.4 Paradigms
Nouns, verbs and adjectives are the main POS cat-
egories that undergo inflection in Hindi according
to regular paradigm rules.
For example, Hindi nouns inflect for case and
number. The inflections for the paradigms that the
words laDkA (meaning boy) and laDkI (mean-
ing girl) belong to are shown in Table 2. The root
word-forms are laDkA and laDkI respectively
(the singular and nominative forms).
122
Hindi verbs are inflected by gender, number,
person, mood and tense. Hindi adjectives take
inflections for gender and case. The number of
inflected forms in different POS categories varies
considerably, with verbs tending to have a lot more
inflections than other POS categories.
3 System Description
In order to construct a morphological lexicon, we
used a rule-based approach combined with heuris-
tics for stem and root selection. When used in
concert with a POS tagger, they could extract a
very accurate morphological lexicon from a raw
text corpus. Our system therefore consists of the
following components:
1. A raw text corpus in the Hindi language large
enough to contain a few hundred thousand
unique word-forms and a smaller labelled
corpus to train a POS tagger with.
2. A list of rules comprising suffix strings and
constraints on the word-forms and POS cate-
gories that they can be applied to.
3. A stemmer that uses the above rules, and
some heuristics to identify and reduce in-
flected word-forms to stems.
4. A POS tagger to identify the POS category or
categories that the word forms in the raw text
corpus can belong to.
5. A root selector that identifies a root word-
form and its paradigm from a stem and a set
of inflections of the stem.
The components of the system are described in
more detail below.
3.1 Text Corpora
Rules alone are not always sufficient to identify
the best stem or root for a word-form, when the
words being stemmed have very few inflectional
forms or when a word might be stemmed in one
of many ways. In that case, a raw text corpus can
provide important clues for identifying them.
The raw text corpus that we use is the Web-
Duniya corpus which consists of 1.4 million sen-
tences of newswire and 21.8 million words. The
corpus, being newswire, is clearly not balanced.
It has a preponderance of third-person forms
whereas first and second person inflectional forms
are under-represented.
Name POS Paradigm Suffixes Root
laDkA noun {?A?,?e?,?on?} ?A?
laDkI noun {?I?,?iyAn?} ?I?
dho verb {??,?yogI?,?nA?,. . .} ??
chal verb {??,?ogI?,?nA?,. . .} ??
Table 3: Sample Paradigm Suffix Sets
Since Hindi word boundaries are clearly marked
with punctuation and spaces, tokenization was
an easy task. The raw text corpus yielded ap-
proximately 331000 unique word-forms. When
words beginning with numbers were removed, we
were left with about 316000 unique word-forms of
which almost half occurred only once in the cor-
pus.
In addition, we needed a corpus of 45,000
words labelled with POS categories using the IL-
POST tagset (Sankaran et al, 2008) for the POS
tagger.
3.2 Rules
The morphological rules input into the system are
used to recognize word-forms that together be-
long to a paradigm. Paradigms can be treated as a
set of suffixes that can be used to generate inflec-
tional word-forms from a stem. The set of suffixes
that constitutes a paradigm defines an equivalence
class on the set of unique word-forms in the cor-
pus.
For example, the laDkA paradigm in Table 2
would be represented by the set of suffix strings
{?A?, ?e?, ?on?} derived from the word-forms
laDkA, laDke and laDkon. A few paradigms
are listed in Table 3.
The suffix set formalism of a paradigm closely
resembles the one used in a previous attempt at
unsupervised paradigm extraction (Zeman, 2007)
but differs from it in that Zeman (2007) considers
the set of word-forms that match the paradigm to
be a part of the paradigm definition.
In our system, we represent the morphological
rules by a list of suffix add-delete rules. Each rule
in our method is a five-tuple {?, ?, ?, ?, ?} where:
? ? is the suffix string to be matched for the
rule to apply.
? ? is the portion of the suffix string after which
the stem ends.
? ? is a POS category in which the string ? is a
valid suffix.
123
? ? ? ? ?
?A? ?? Noun N1 ?A?
?on? ?? Noun N1,N3 ?A?
?e? ?? Noun N1 ?A?
?oyogI? ?o? Verb V5 ?o?
Table 4: Sample Paradigm Rules
Word Form ? Match Stem Root
laDkA laDk + A laDk laDkA
laDkon laDk + on laDk laDkA
laDke laDk + e laDk laDkA
dhoyogI dh + oyogI dh + o dho
Table 5: Rule Application
? ? is a list of paradigms that contain the suffix
string ?.
? ? is the root suffix
The sample paradigm rules shown in Table 4
would match the words laDkA, laDkon, laDke
and dhoyogI respectively and cause them to be
stemmed and assigned roots as shown in Table 5.
The rules by themselves can identify word-and-
paradigm entries from the raw text corpus if a suf-
ficient number of inflectional forms were present.
For instance, if the words laDkA and laDkon
were present in the corpus, by taking the intersec-
tion of the paradigms associated with the match-
ing rules in Table 4, it would be possible to infer
that the root word-form was laDkA and that the
paradigm was N1.
We needed to create about 300 rules for Hindi.
The rules could be stored in a list indexed by the
suffix in the case of Hindi because the number of
possible suffixes was small. For highly aggluti-
native languages, such as Tamil and Malayalam,
which can have thousands of suffixes, it would be
necessary to use a Finite State Machine represen-
tation of the rules.
3.3 Suffix Evidence
We define the term ?suffix evidence? for a poten-
tial stem as the number of word-forms in the cor-
pus that are composed of a concatenation of the
stem and any valid suffix. For instance, the suf-
fix evidence for the stem laDk is 2 if the word-
forms laDkA and laDkon are the only word-
forms with the prefix laDk that exist in the corpus
and A and on are both valid suffixes.
BSE Word-forms Accuracy
1 20.5% 79%
2 20.0% 70%
3 13.2% 70%
4 10.8% 81%
5 & more 35.5% 80%
Table 6: % Frequency and Accuracy by BSE
BSE Nouns Verbs Others
1 292 6 94
2 245 2 136
3 172 15 66
4 120 16 71
5 & more 103 326 112
Table 7: Frequency by POS Category
Table 6 presents word-form counts for differ-
ent suffix evidence values for the WebDuniya cor-
pus. Since the real stems for the word-forms were
not known, the prefix substring with the highest
suffix evidence was used as the stem. We shall
call this heuristically selected stem the best-suffix-
evidence stem and its suffix evidence as the best-
suffix-evidence (BSE).
It will be seen from Table 6 that about 20% of
the words have a BSE of only 1. Altogether about
40% of the words have a BSE of 1 or 2. Note
that all words have a BSE of atleast 1 since the
empty string is also considered a valid suffix. The
fraction is even higher for nouns as shown in Table
7.
It must be noted that the number of nouns with
a BSE of 5 or more is in the hundreds only be-
cause of erroneous concatenations of suffixes with
stems. Nouns in Hindi do not usually have more
than four inflectional forms.
The scarcity of suffix evidence for most word-
forms poses a huge obstacle to the extraction of a
high-coverage lexicon because :
1. There are usually multiple ways to pick a
stem from word-forms with a BSE of 1 or 2.
2. Spurious stems cannot be detected easily
when there is no overwhelming suffix evi-
dence in favour of the correct stem.
3.4 Gold Standard
The gold standard consists of one thousand word-
forms picked at random from the intersection of
124
the unique word-forms in the unlabelled Web-
Duniya corpus and the POS labelled corpus. Each
word-form in the gold standard was manually ex-
amined and a stem and a root word-form found for
it.
For word-forms associated with multiple POS
categories, the stem and root of a word-form were
listed once for each POS category because the seg-
mentation of a word could depend on its POS cat-
egory. There were 1913 word and POS category
combinations in the gold standard.
The creation of the stem gold standard needed
some arbitrary choices which had to be reflected
in the rules as well. These concerned some words
which could be stemmed in multiple ways. For in-
stance, the noun laDkI meaning ?girl? could be
segmented into the morphemes laDk and I or al-
lowed to remain unsegmented as laDkI. This is
because by doing the former, the stems of both
laDkA and laDkI could be conflated whereas
by doing the latter, they could be kept separate
from each other. We arbitrarily made the choice
to keep nouns ending in I unsegmented and made
our rules reflect that choice.
A second gold standard consisting of 1000
word-forms was also created to be used in eval-
uation and as training data for supervised algo-
rithms. The second gold standard contained 1906
word and POS category combinations. Only word-
forms that did not appear in the first gold standard
were included in the second one.
3.5 Stemmer
Since the list of valid suffixes is given, the stem-
mer does not need to discover the stems in the lan-
guage but only learn to apply the right one in the
right place. We experimented with three heuristics
for finding the right stem for a word-form. The
heuristics were:
? Longest Suffix Match (LSM) - Picking the
longest suffix that can be applied to the word-
form.
? Highest Suffix Evidence (HSE) - Picking the
suffix which yields the stem with the highest
value for suffix evidence.
? Highest Suffix Evidence with Supervised
Rule Selection (HSE + Sup) - Using labelled
data to modulate suffix matching.
3.5.1 Longest Suffix Match (LSM)
In the LSM heuristic, when multiple suffixes can
be applied to a word-form to stem it, we choose
the longest one. Since Hindi has concatenative
morphology with only postfix inflection, we only
need to find one matching suffix to stem it. It is
claimed in the literature that the method of us-
ing the longest suffix match works better than ran-
dom suffix selection (Sarkar and Bandyopadhyay,
2008). This heuristic was used as the baseline for
our experiments.
3.5.2 Highest Suffix Evidence (HSE)
In the HSE heuristic, which has been applied be-
fore to unsupervised morphological segmentation
(Goldsmith, 2001), stemming (Pandey and Sid-
diqui, 2008), and automatic paradigm extraction
(Zeman, 2007), when multiple suffixes can be ap-
plied to stem a word-form, the suffix that is picked
is the one that results in the stem with the high-
est suffix evidence. In our case, when computing
the suffix evidence, the following additional con-
straint is applied: all the suffixes used to compute
the suffix evidence score for any stem must be as-
sociated with the same POS category.
For example, the suffix yon is only applicable
to nouns, whereas the suffix ta is only applicable
to verbs. These two suffixes will therefore never
be counted together in computing the suffix evi-
dence for a stem. The algorithm for determining
the suffix evidence computes the suffix evidence
once for each POS category and then returns the
maximum.
In the absence of this constraint, the accuracy
drops as the size of the raw word corpus increases.
3.5.3 HSE and Supervised Rule Selection
(HSE + Sup)
The problem with the aforementioned heuristics is
that there are no weights assigned to rules. Since
the rules for the system were written to be as gen-
eral and flexible as possible, false positives were
commonly encountered. We propose a very sim-
ple supervised learning method to circumvent this
problem.
The training data used was a set of 1000 word-
forms sampled, like the gold standard, from the
unique word-forms in the intersection of the raw
text corpus and the POS labelled corpus. The set
of word-forms in the training data was disjoint
from the set of word-forms in the gold standard.
125
Rules Accur Prec Recall F-Score
Rules1 73.65% 68.25% 69.4% 68.8%
Rules2 75.0% 69.0% 77.6% 73.0%
Table 8: Comparison of Rules
Gold 1 Accur Prec Recall F-Score
LSM 71.6% 65.8% 66.1% 65.9%
HSE 76.7% 70.6% 77.9% 74.1%
HSE+Sup 78.0% 72.3% 79.8% 75.9%
Gold 2 Accur Prec Recall F-Score
LSM 75.7% 70.7% 72.7% 71.7%
HSE 75.0% 69.0% 77.6% 73.0%
HSE+Sup 75.3% 69.3% 78.0% 73.4%
Table 9: Comparison of Heuristics
The feature set consisted of two features: the
last character (or diacritic) of the word-form, and
the suffix. The POS category was an optional fea-
ture and used when available. If the number of in-
correct splits exceeded the number of correct splits
given a feature set, the rule was assigned a weight
of 0, else it was given a weight of 1.
3.5.4 Comparison
We compare the performance of our rules with
the performance of the Lightweight Stemmer for
Hindi (Ramanathan and Rao, 2003) with a re-
ported accuracy of 81.5%. The scores we report
in Table 8 are the average of the LSM scores
on the two gold standards. The stemmer using
the standard rule-set (Rules1) does not perform as
well as the Lightweight Stemmer. We then hand-
crafted a different set of rules (Rules2) with ad-
justments to maximize its performance. The ac-
curacy was better than Rules1 but not quite equal
to the Lightweight Stemmer. However, since our
gold standard is different from that used to eval-
uate the Lightweight Stemmer, the comparison is
not necessarily very meaningful.
As shown in Table 9, in F-score comparisons,
HSE seems to outperform LSM and HSE+Sup
seems to outperform HSE, but the improvement
in performance is not very large in the case of the
second gold standard. In terms of accuracy scores,
LSM outperforms HSE and HSE+Sup when eval-
uated against the second gold standard.
POS Correct Incorrect POS Errors
Noun 749 231 154
Verb 324 108 0
Adjective 227 49 13
Others 136 82 35
Table 10: Errors by POS Category
3.5.5 Error Analysis
Table 10 lists the number of correct stems, in-
correct stems, and finally a count of those incor-
rect stems that the HSE+Sup heuristic would have
gotten right if the POS category had been avail-
able. From the numbers it appears that a size-
able fraction of the errors, especially with noun
word-forms, is caused when a suffix of the wrong
POS category is applied to a word-form. More-
over, prior work in Bangla (Sarkar and Bandy-
opadhyay, 2008) indicates that POS category in-
formation could improve the accuracy of stem-
ming.
Assigning POS categories to word-forms re-
quires a POS tagger and a substantial amount of
POS labelled data as described below.
3.5.6 POS Tagging
The POS tagset used was the hierarchical tagset
IL-POST (Sankaran et al, 2008). The hierarchical
tagset supports broad POS categories like nouns
and verbs, less broad POS types like common and
proper nouns and finally, at its finest granularity,
attributes like gender, number, case and mood.
We found that with a training corpus of about
45,000 tagged words (2366 sentences), it was pos-
sible to produce a reasonably accurate POS tag-
ger2, use it to label the raw text corpus with broad
POS tags, and consequently improve the accuracy
of stemming. For our experiments, we used both
the full training corpus of 45,000 words and a sub-
set of the same consisting of about 20,000 words.
The POS tagging accuracies obtained were ap-
proximately 87% and 65% respectively.
The reason for repeating the experiment using
the 20,000 word subset of the training data was to
demonstrate that a mere 20,000 words of labelled
data, which does not take a very great amount of
2The Part-of-Speech tagger used was an implementa-
tion of a Cyclic Dependency Network Part-of-Speech tagger
(Toutanova et al, 2003). The following feature set was used
in the tagger: tag of previous word, tag of next word, word
prefixes and suffixes of length exactly four, bigrams and the
presence of numbers or symbols.
126
time and effort to create, can produce significant
improvements in stemming performance.
In order to assign tags to the words of the gold
standard, sentences from the raw text corpus con-
taining word-forms present in the gold standard
were tagged using a POS tagger. The POS cate-
gories assigned to each word-form were then read
off and stored in a table.
Once POS tags were associated with all the
words, a more restrictive criterion for matching a
rule to a word-form could be used to calculate the
BSE in order to determine the stem of the word-
form. When searching for rules, and consequently
the suffixes, to be applied to a word-form, only
rules whose ? value matches the word-form?s POS
category were considered. We shall call the HSE
heuristic that uses POS information in this way
HSE+Pos.
3.6 Root Selection
The stem lexicon obtained by the process de-
scribed above had to be converted into a root word-
form lexicon. A root word-form lexicon is in some
cases more useful than a stem lexicon, for the fol-
lowing reasons:
1. Morphological lexicons are traditionally in-
dexed by root word-forms
2. Multiple root word-forms may map to one
stem and be conflated.
3. Tools that use the morphological lexicon may
expect the lexicon to consist of roots instead
of stems.
4. Multiple root word-forms may map to one
stem and be conflated.
5. Stems are entirely dependent on the way
stemming rules are crafted. Roots are inde-
pendent of the stemming rules.
The stem lexicon can be converted into a root
lexicon using the raw text corpus and the morpho-
logical rules that were used for stemming, as fol-
lows:
1. For any word-form and its stem, list all rules
that match.
2. Generate all the root word-forms possible
from the matching rules and stems.
3. From the choices, select the root word-form
with the highest frequency in the corpus.
Relative frequencies of word-forms have been
used in previous work to detect incorrect affix at-
tachments in Bengali and English (Dasgupta and
Ng, 2007). Our evaluation of the system showed
that relative frequencies could be very effective
predictors of root word-forms when applied within
the framework of a rule-based system.
4 Evaluation
The goal of our experiment was to build a high-
coverage morphological lexicon for Hindi and to
evaluate the same. Having developed a multi-stage
system for lexicon extraction with a POS tagging
step following by stemming and root word-form
discovery, we proceeded to evaluate it as follows.
The stemming and the root discovery module
were evaluated against the gold standard of 1000
word-forms. In the first experiment, the precision
and recall of stemming using the HSE+Pos algo-
rithm were measured at different POS tagging ac-
curacies.
In the second experiment the root word-form
discovery module was provided the entire raw
word corpus to use in determining the best pos-
sible candidate for a root and tested using the gold
standard. The scores obtained reflect the perfor-
mance of the overall system.
For stemming, the recall was calculated as the
fraction of stems and suffixes in the gold standard
that were returned by the stemmer for each word-
form examined. The precision was calculated as
the fraction of stems and suffixes returned by the
stemmer that matched the gold standard. The F-
score was calculated as the harmonic mean of the
precision and recall.
The recall of the root lexicon was measured as
the fraction of gold standard roots that were in the
lexicon. The precision was calculated as the frac-
tion of roots in the lexicon that were also in the
gold standard. Accuracy was the percentage of
gold word-forms? roots that were matched exactly.
In order to approximately estimate the accuracy
of a stemmer or morphological analyzer that used
such a lexicon, we also calculated the accuracy
weighted by the frequency of the word-forms in
a small corpus of running text. The gold standard
tokens were seen in this corpus about 4400 times.
We only considered content words (nouns, verbs,
adjectives and adverbs) in this calculation.
127
Gold1 Accur Prec Recall F-Sco
POS 86.7% 82.4% 86.2% 84.2%
Sup+POS 88.2% 85.2% 87.3% 86.3%
Gold2 Accur Prec Recall F-Sco
POS 81.8% 77.8% 82.0% 79.8%
Sup+POS 83.5% 80.2% 82.6% 81.3%
Table 11: Stemming Performance Comparisons
Gold 1 Accur Prec Recall F-Sco
No POS 76.7% 70.6% 77.9% 74.1%
65% POS 82.3% 77.5% 81.4% 79.4%
87% POS 85.4% 80.8% 85.1% 82.9%
Gold POS 86.7% 82.4% 86.2% 84.2%
Table 12: Stemming Performance at Different
POS Tagger Accuracies
5 Results
The performance of our system using POS tag in-
formation is comparable to that obtained by Sarkar
and Bandyopadhyay (2008). Sarkar and Bandy-
opadhyay (2008) obtained stemming accuracies of
90.2% for Bangla using gold POS tags. So in the
comparisons in Table 11, we use gold POS tags
(row two) and also supervised learning (row three)
using the other gold corpus as the labelled training
corpus. We present the scores for the two gold
standards separately. It must be noted that Sarkar
and Bandyopadhyay (2008) conducted their ex-
periments on Bangla, and so the results are not
exactly comparable.
We also evaluate the performance of stemming
using HSE with POS tagging by a real tagger at
two different tagging accuracies - approximately
65% and 87% - as shown in Table 12. We com-
pare the performance with gold POS tags and a
baseline system which does not use POS tags. We
do not use labelled training data for this section of
the experiments and only evaluate against the first
gold standard.
Table 13 compares the F-scores for root discov-
Gold 1 Accur Prec Recall F-Sco
No POS 71.7% 77.6% 78.8% 78.1%
65% POS 82.5% 87.2% 88.9% 88.0%
87% POS 87.0% 94.1% 95.3% 94.6%
Gold POS 89.1% 95.4% 97.9% 96.6%
Table 13: Root Finding Accuracy
Gold 1 Stemming Root Finding
65% POS 85.6% 87.0%
87% POS 87.5% 90.6%
Gold POS 88.5% 90.2%
Table 14: Weighted Stemming and Root Finding
Accuracies (only Content Words)
ery at different POS tagging accuracies against a
baseline which excludes the use of POS tags alto-
gether. There seems to be very little prior work
that we can use for comparison here. To our
knowledge, the closest comparable work is a sys-
tem built by Oliver and Tadic? (2004) in order to
enlarge a Croatian Morphological Lexicon. The
overall performance reported by Tadic? et alwas
as follows: (precision=86.13%, recall=35.36%,
F1=50.14%).
Lastly, Table 14 shows the accuracy of stem-
ming and root finding weighted by the frequencies
of the words in a running text corpus. This was
calculated only for content words.
6 Conclusion
We have described a system for automatically con-
structing a root word-form lexicon from a raw
text corpus. The system is rule-based and uti-
lizes a POS tagger. Though preliminary, our re-
sults demonstrate that it is possible, using this
method, to extract a high-precision and high-recall
root word-form lexicon. Specifically, we show
that with a POS tagger capable of labelling word-
forms with POS categories at an accuracy of about
88%, we can extract root word-forms with an ac-
curacy of about 87% and a precision and recall of
94.1% and 95.3% respectively.
Though the system has been evaluated on Hindi,
the techniques described herein can probably be
applied to other inflectional languages. The rules
selected by the system and applied to the word-
forms also contain information that can be used to
determine the paradigm membership of each root
word-form. Further work could evaluate the accu-
racy with which we can accomplish this task.
7 Acknowledgements
We would like to thank our colleagues Priyanka
Biswas, Kalika Bali and Shalini Hada, of Mi-
crosoft Research India, for their assistance in the
creation of the Hindi root and stem gold standards.
128
References
Lionel Cle?ment, Beno??t Sagot and Bernard Lang.
2004. Morphology based automatic acquisition of
large-coverage lexica. In Proceedings of LREC
2004, Lisbon, Portugal.
Sajib Dasgupta and Vincent Ng. 2007. High-
Performance, Language-Independent Morphologi-
cal Segmentation. In Main Proceedings of NAACL
HLT 2007, Rochester, NY, USA.
Markus Forsberg, Harald Hammarstro?m and Aarne
Ranta. 2006. Morphological Lexicon Extraction
from Raw Text Data. In Proceedings of the 5th In-
ternational Conference on Advances in Natural Lan-
guage Processing, FinTAL, Finland.
John A. Goldsmith. 2001. Linguistica: An Automatic
Morphological Analyzer. In Arika Okrent and John
Boyle, editors, CLS 36: The Main Session, volume
36-1, Chicago Linguistic Society, Chicago.
Erika de Lima. 1998. Induction of a Stem Lexicon for
Two-Level Morphological Analysis. In Proceedings
of the Joint Conferences on New Methods in Lan-
guage Processing and Computational Natural Lan-
guage Learning, NeMLaP3/CoNLL98, pp 267-268,
Sydney, Australia.
Antoni Oliver, Marko Tadic?. 2004. Enlarging the
Croatian Morphological Lexicon by Automatic Lex-
ical Acquisition from Raw Corpora. In Proceedings
of LREC 2004, Lisbon, Portugal.
Amaresh Kumar Pandey and Tanveer J. Siddiqui.
2008. An Unsupervised Hindi Stemmer with
Heuristic Improvements. In Proceedings of the Sec-
ond Workshop on Analytics for Noisy Unstructured
Text Data, AND 2008, pp 99-105, Singapore.
A Ramanathan and D. D. Rao. 2003. A Lightweight
Stemmer for Hindi. Presented at EACL 2003, Bu-
dapest, Hungary.
Beno??t Sagot. 2005. Automatic Acquisition of a
Slovak Lexicon from a Raw Corpus. In Lecture
Notes in Artificial Intelligence 3658, Proceedings of
TSD?05, Karlovy Vary, Czech Republic.
Beno??t Sagot. 2007. Building a Morphosyntactic Lexi-
con and a Pre-Syntactic Processing Chain for Polish.
In Proceedings of LTC 2007, Poznan?, Poland.
Beno??t Sagot, Lionel Cle?ment, E?ric Villemonte de la
Clergerie and Pierre Boullier. 2006. The Lefff 2
Syntactic Lexicon for French: Architecture, Acqui-
sition, Use. In Proceedings of LREC?06, Genoa,
Italy.
Baskaran Sankaran, Kalika Bali, Monojit Choudhury,
Tanmoy Bhattacharya, Pushpak Bhattacharyya,
Girish Nath Jha, S. Rajendran, K. Saravanan, L.
Sobha and K.V. Subbarao. 2008. A Common Parts-
of-Speech Tagset Framework for Indian Languages.
In Proceedings of the Sixth International Language
Resources and Evaluation (LREC?08), Marrakech,
Morocco.
Sandipan Sarkar and Sivaji Bandyopadhyay. 2008.
Design of a Rule-based Stemmer for Natural Lan-
guage Text in Bengali. In Proceedings of the
IJCNLP-08 Workshop on NLP for Less Privileged
Languages, Hyderabad, India.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning and Yoram Singer. 2003. Feature-Rich Part-
of-Speech Tagging with a Cyclic Dependependency
Network In Proceedings of HLT-NAACL 2003
pages 252-259.
Daniel Zeman. 2007. Unsupervised Acquisition of
Morphological Paradigms from Tokenized Text. In
Working Notes for the Cross Language Evaluation
Forum CLEF 2007 Workshop, Budapest, Hungary.
129
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 585?593,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Discovering Global Patterns in Linguistic Networks through
Spectral Analysis: A Case Study of the Consonant Inventories
Animesh Mukherjee?
Indian Institute of Technology, Kharagpur
animeshm@cse.iitkgp.ernet.in
Monojit Choudhury and Ravi Kannan
Microsoft Research India
{monojitc,kannan}@microsoft.com
Abstract
Recent research has shown that language
and the socio-cognitive phenomena asso-
ciated with it can be aptly modeled and
visualized through networks of linguistic
entities. However, most of the existing
works on linguistic networks focus only
on the local properties of the networks.
This study is an attempt to analyze the
structure of languages via a purely struc-
tural technique, namely spectral analysis,
which is ideally suited for discovering the
global correlations in a network. Appli-
cation of this technique to PhoNet, the
co-occurrence network of consonants, not
only reveals several natural linguistic prin-
ciples governing the structure of the con-
sonant inventories, but is also able to quan-
tify their relative importance. We believe
that this powerful technique can be suc-
cessfully applied, in general, to study the
structure of natural languages.
1 Introduction
Language and the associated socio-cognitive phe-
nomena can be modeled as networks, where the
nodes correspond to linguistic entities and the
edges denote the pairwise interaction or relation-
ship between these entities. The study of lin-
guistic networks has been quite popular in the re-
cent times and has provided us with several in-
teresting insights into the nature of language (see
Choudhury and Mukherjee (to appear) for an ex-
tensive survey). Examples include study of the
WordNet (Sigman and Cecchi, 2002), syntactic
dependency network of words (Ferrer-i-Cancho,
2005) and network of co-occurrence of conso-
nants in sound inventories (Mukherjee et al, 2008;
Mukherjee et al, 2007).
?This research has been conducted during the author?s in-
ternship at Microsoft Research India.
Most of the existing studies on linguistic net-
works, however, focus only on the local structural
properties such as the degree and clustering coef-
ficient of the nodes, and shortest paths between
pairs of nodes. On the other hand, although it is
a well known fact that the spectrum of a network
can provide important information about its global
structure, the use of this powerful mathematical
machinery to infer global patterns in linguistic net-
works is rarely found in the literature. Note that
spectral analysis, however, has been successfully
employed in the domains of biological and social
networks (Farkas et al, 2001; Gkantsidis et al,
2003; Banerjee and Jost, 2007). In the context of
linguistic networks, (Belkin and Goldsmith, 2002)
is the only work we are aware of that analyzes the
eigenvectors to obtain a two dimensional visualize
of the network. Nevertheless, the work does not
study the spectrum of the graph.
The aim of the present work is to demonstrate
the use of spectral analysis for discovering the
global patterns in linguistic networks. These pat-
terns, in turn, are then interpreted in the light of ex-
isting linguistic theories to gather deeper insights
into the nature of the underlying linguistic phe-
nomena. We apply this rather generic technique
to find the principles that are responsible for shap-
ing the consonant inventories, which is a well re-
searched problem in phonology since 1931 (Tru-
betzkoy, 1931; Lindblom and Maddieson, 1988;
Boersma, 1998; Clements, 2008). The analysis
is carried out on a network defined in (Mukherjee
et al, 2007), where the consonants are the nodes
and there is an edge between two nodes u and v
if the consonants corresponding to them co-occur
in a language. The number of times they co-occur
across languages define the weight of the edge. We
explain the results obtained from the spectral anal-
ysis of the network post-facto using three linguis-
tic principles. The method also automatically re-
veals the quantitative importance of each of these
585
principles.
It is worth mentioning here that earlier re-
searchers have also noted the importance of the
aforementioned principles. However, what was
not known was how much importance one should
associate with each of these principles. We also
note that the technique of spectral analysis neither
explicitly nor implicitly assumes that these princi-
ples exist or are important, but deduces them auto-
matically. Thus, we believe that spectral analysis
is a promising approach that is well suited to the
discovery of linguistic principles underlying a set
of observations represented as a network of enti-
ties. The fact that the principles ?discovered? in
this study are already well established results adds
to the credibility of the method. Spectral analysis
of large linguistic networks in the future can possi-
bly reveal hitherto unknown universal principles.
The rest of the paper is organized as follows.
Sec. 2 introduces the technique of spectral anal-
ysis of networks and illustrates some of its ap-
plications. The problem of consonant inventories
and how it can be modeled and studied within the
framework of linguistic networks are described in
Sec. 3. Sec. 4 presents the spectral analysis of
the consonant co-occurrence network, the obser-
vations and interpretations. Sec. 5 concludes by
summarizing the work and the contributions and
listing out future research directions.
2 A Primer to Spectral Analysis
Spectral analysis1 is a powerful tool capable of
revealing the global structural patterns underly-
ing an enormous and complicated environment
of interacting entities. Essentially, it refers to
the systematic study of the eigenvalues and the
eigenvectors of the adjacency matrix of the net-
work of these interacting entities. Here we shall
briefly review the basic concepts involved in spec-
tral analysis and describe some of its applications
(see (Chung, 1994; Kannan and Vempala, 2008)
for details).
A network or a graph consisting of n nodes (la-
beled as 1 through n) can be represented by a n?n
square matrix A, where the entry aij represents the
weight of the edge from node i to node j. A, which
is known as the adjacency matrix, is symmetric for
an undirected graph and have binary entries for an
1The term spectral analysis is also used in the context of
signal processing, where it refers to the study of the frequency
spectrum of a signal.
unweighted graph. ? is an eigenvalue of A if there
is an n-dimensional vector x such that
Ax = ?x
Any real symmetric matrix A has n (possibly non-
distinct) eigenvalues ?0 ? ?1 ? . . . ? ?n?1, and
corresponding n eigenvectors that are mutually or-
thogonal. The spectrum of a graph is the set of the
distinct eigenvalues of the graph and their corre-
sponding multiplicities. It is usually represented
as a plot with the eigenvalues in x-axis and their
multiplicities plotted in the y-axis.
The spectrum of real and random graphs dis-
play several interesting properties. Banerjee and
Jost (2007) report the spectrum of several biologi-
cal networks that are significantly different from
the spectrum of artificially generated graphs2.
Spectral analysis is also closely related to Prin-
cipal Component Analysis and Multidimensional
Scaling. If the first few (say d) eigenvalues of a
matrix are much higher than the rest of the eigen-
values, then it can be concluded that the rows of
the matrix can be approximately represented as
linear combinations of d orthogonal vectors. This
further implies that the corresponding graph has
a few motifs (subgraphs) that are repeated a large
number of time to obtain the global structure of
the graph (Banerjee and Jost, to appear).
Spectral properties are representative of an n-
dimensional average behavior of the underlying
system, thereby providing considerable insight
into its global organization. For example, the prin-
cipal eigenvector (i.e., the eigenvector correspond-
ing to the largest eigenvalue) is the direction in
which the sum of the square of the projections
of the row vectors of the matrix is maximum. In
fact, the principal eigenvector of a graph is used to
compute the centrality of the nodes, which is also
known as PageRank in the context of WWW. Sim-
ilarly, the second eigen vector component is used
for graph clustering.
In the next two sections we describe how spec-
tral analysis can be applied to discover the orga-
nizing principles underneath the structure of con-
sonant inventories.
2Banerjee and Jost (2007) report the spectrum of the
graph?s Laplacian matrix rather than the adjacency matrix.
It is increasingly popular these days to analyze the spectral
properties of the graph?s Laplacian matrix. However, for rea-
sons explained later, here we will be conduct spectral analysis
of the adjacency matrix rather than its Laplacian.
586
Figure 1: Illustration of the nodes and edges of PlaNet and PhoNet alng with their respective adjacency
matrix representations.
3 Consonant Co-occurrence Network
The most basic unit of human languages are the
speech sounds. The repertoire of sounds that make
up the sound inventory of a language are not cho-
sen arbitrarily even though the speakers are ca-
pable of producing and perceiving a plethora of
them. In contrast, these inventories show excep-
tionally regular patterns across the languages of
the world, which is in fact, a common point of
consensus in phonology. Right from the begin-
ning of the 20th century, there have been a large
number of linguistically motivated attempts (Tru-
betzkoy, 1969; Lindblom and Maddieson, 1988;
Boersma, 1998; Clements, 2008) to explain the
formation of these patterns across the consonant
inventories. More recently, Mukherjee and his col-
leagues (Choudhury et al, 2006; Mukherjee et al,
2007; Mukherjee et al, 2008) studied this problem
in the framework of complex networks. Since here
we shall conduct a spectral analysis of the network
defined in Mukherjee et al (2007), we briefly sur-
vey the models and the important results of their
work.
Choudhury et al (2006) introduced a bipartite
network model for the consonant inventories. For-
mally, a set of consonant inventories is represented
as a graph G = ?VL, VC , Elc?, where the nodes in
one partition correspond to the languages (VL) and
that in the other partition correspond to the conso-
nants (VC). There is an edge (vl, vc) between a
language node vl ? VL (representing the language
l) and a consonant node vc ? VC (representing the
consonant c) iff the consonant c is present in the
inventory of the language l. This network is called
the Phoneme-Language Network or PlaNet and
represent the connections between the language
and the consonant nodes through a 0-1 matrix A
as shown by a hypothetical example in Fig. 1. Fur-
ther, in (Mukherjee et al, 2007), the authors define
the Phoneme-Phoneme Network or PhoNet as the
one-mode projection of PlaNet onto the consonant
nodes, i.e., a network G = ?VC , Ecc? ?, where the
nodes are the consonants and two nodes vc and
vc? are linked by an edge with weight equal to the
number of languages in which both c and c? occur
together. In other words, PhoNet can be expressed
as a matrixB (see Fig. 1) such thatB = AAT?D
where D is a diagonal matrix with its entries cor-
responding to the frequency of occurrence of the
consonants. Similarly, we can also construct the
one-mode projection of PlaNet onto the language
nodes (which we shall refer to as the Language-
Language Graph or LangGraph) can be expressed
as B? = ATA ?D?, where D? is a diagonal ma-
trix with its entries corresponding to the size of the
consonant inventories for each language.
The matrix A and hence, B and B? have been
constructed from the UCLA Phonological Seg-
ment Inventory Database (UPSID) (Maddieson,
1984) that hosts the consonant inventories of 317
languages with a total of 541 consonants found
across them. Note that, UPSID uses articulatory
587
features to describe the consonants and assumes
these features to be binary-valued, which in turn
implies that every consonant can be represented
by a binary vector. Later on, we shall use this rep-
resentation for our experiments.
By construction, we have |VL| = 317, |VC | =
541, |Elc| = 7022, and |Ecc? | = 30412. Conse-
quently, the order of the matrix A is 541 ? 317
and that of the matrix B? is 541 ? 541. It has been
found that the degree distribution of both PlaNet
and PhoNet roughly indicate a power-law behavior
with exponential cut-offs towards the tail (Choud-
hury et al, 2006; Mukherjee et al, 2007). Further-
more, PhoNet is also characterized by a very high
clustering coefficient. The topological properties
of the two networks and the generative model
explaining the emergence of these properties are
summarized in (Mukherjee et al, 2008). However,
all the above properties are useful in characteriz-
ing the local patterns of the network and provide
very little insight about its global structure.
4 Spectral Analysis of PhoNet
In this section we describe the procedure and re-
sults of the spectral analysis of PhoNet. We begin
with computation of the spectrum of PhoNet. Af-
ter the analysis of the spectrum, we systematically
investigate the top few eigenvectors of PhoNet
and attempt to characterize their linguistic signif-
icance. In the process, we also analyze the corre-
sponding eigenvectors of LanGraph that helps us
in characterizing the properties of languages.
4.1 Spectrum of PhoNet
Using a simple Matlab script we compute the
spectrum (i.e., the list of eignevalues along with
their multiplicities) of the matrix B correspond-
ing to PhoNet. Fig. 2(a) shows the spectral plot,
which has been obtained through binning3 with a
fixed bin size of 20. In order to have a better visu-
alization of the spectrum, in Figs. 2(b) and (c) we
further plot the top 50 (absolute) eigenvalues from
the two ends of the spectrum versus the index rep-
resenting their sorted order in doubly-logarithmic
scale. Some of the important observations that one
can make from these results are as follows.
First, the major bulk of the eigenvalues are con-
centrated at around 0. This indicates that though
3Binning is the process of dividing the entire range of a
variable into smaller intervals and counting the number of
observations within each bin or interval. In fixed binning, all
the intervals are of the same size.
the order of B is 541 ? 541, its numerical rank is
quite low. Second, there are at least a few very
large eigenvalues that dominate the entire spec-
trum. In fact, 89% of the spectrum, or the square
of the Frobenius norm, is occupied by the princi-
pal (i.e., the topmost) eigenvalue, 92% is occupied
by the first and the second eigenvalues taken to-
gether, while 93% is occupied by the first three
taken together. The individual contribution of the
other eigenvalues to the spectrum is significantly
lower than that of the top three. Third, the eigen-
values on either ends of the spectrum tend to decay
gradually, mostly indicating a power-law behavior.
The power-law exponents at the positive and the
negative ends are -1.33 (the R2 value of the fit is
0.98) and -0.88 (R2 ? 0.92) respectively.
The numerically low rank of PhoNet suggests
that there are certain prototypical structures that
frequently repeat themselves across the consonant
inventories, thereby, increasing the number of 0
eigenvalues to a large extent. In other words, all
the rows of the matrix B (i.e., the inventories) can
be expressed as the linear combination of a few
independent row vectors, also known as factors.
Furthermore, the fact that the principal eigen-
value constitutes 89% of the Frobenius norm of the
spectrum implies that there exist one very strong
organizing principle which should be able to ex-
plain the basic structure of the inventories to a very
good extent. Since the second and third eigen-
values are also significantly larger than the rest
of the eigenvalues, one should expect two other
organizing principles, which along with the basic
principle, should be able to explain, (almost) com-
pletely, the structure of the inventories. In order
to ?discover? these principles, we now focus our
attention to the first three eigenvectors of PhoNet.
4.2 The First Eigenvector of PhoNet
Fig. 2(d) shows the first eigenvector component
for each consonant node versus its frequency of
occurrence across the language inventories (i.e., its
degree in PlaNet). The figure clearly indicates that
the two are highly correlated (r = 0.99), which in
turn means that 89% of the spectrum and hence,
the organization of the consonant inventories, can
be explained to a large extent by the occurrence
frequency of the consonants. The question arises:
Does this tell us something special about the struc-
ture of PhoNet or is it always the case for any sym-
metric matrix that the principal eigenvector will
588
Figure 2: Eigenvalues and eigenvectors of B. (a) Binned distribution of the eigenvalues (bin size = 20)
versus their multiplicities. (b) the top 50 (absolute) eigenvalues from the positive end of the spectrum and
their ranks. (c) Same as (b) for the negative end of the spectrum. (d), (e) and (f) respectively represents
the first, second and the third eigenvector components versus the occurrence frequency of the consonants.
be highly correlated with the frequency? We as-
sert that the former is true, and indeed, the high
correlation between the principal eigenvector and
the frequency indicates high ?proportionate co-
occurrence? - a term which we will explain.
To see this, consider the following 2n? 2n ma-
trix X
X =
?
???????
0 M1 0 0 0 . . .
M1 0 0 0 0 . . .
0 0 0 M2 0 . . .
0 0 M2 0 0 . . .
... ... ... ... ... . . .
?
???????
where Xi,i+1 = Xi+1,i = M(i+1)/2 for all odd
i and 0 elsewhere. Also, M1 > M2 > . . . >
Mn ? 1. Essentially, this matrix represents a
graph which is a collection of n disconnected
edges, each having weights M1, M2, and so on.
It is easy to see that the principal eigenvector of
this matrix is (1/?2, 1/?2, 0, 0, . . . , 0)>, which
of course is very different from the frequency vec-
tor: (M1,M1,M2,M2, . . . ,Mn,Mn)>.
At the other extreme, consider an n ? n ma-
trix X with Xi,j = Cfifj for some vector f =
(f1, f2, . . . fn)> that represents the frequency of
the nodes and a normalization constant C. This is
what we refer to as ?proportionate co-occurrence?
because the extent of co-occurrence between the
nodes i and j (which is Xi,j or the weight of the
edge between i and j) is exactly proportionate to
the frequencies of the two nodes. The principal
eigenvector in this case is f itself, and thus, corre-
lates perfectly with the frequencies. Unlike this
hypothetical matrix X, PhoNet has all 0 entries
in the diagonal. Nevertheless, this perturbation,
which is equivalent to subtracting f2i from the ith
diagonal, seems to be sufficiently small to preserve
the ?proportionate co-occurrence? behavior of the
adjacency matrix thereby resulting into a high cor-
relation between the principal eigenvector compo-
nent and the frequencies.
On the other hand, to construct the Lapla-
cian matrix, we would have subtracted fi
?n
j=1 fj
from the ith diagonal entry, which is a much
larger quantity than f2i . In fact, this operation
would have completely destroyed the correlation
between the frequency and the principal eigen-
vector component because the eigenvector corre-
sponding to the smallest4 eigenvalue of the Lapla-
cian matrix is [1, 1, . . . , 1]>.
Since the first eigenvector of B is perfectly cor-
4The role played by the top eigenvalues and eigenvectors
in the spectral analysis of the adjacency matrix is compara-
ble to that of the smallest eigenvalues and the corresponding
eigenvectors of the Laplacian matrix (Chung, 1994)
589
related with the frequency of occurrence of the
consonants across languages it is reasonable to
argue that there is a universally observed innate
preference towards certain consonants. This pref-
erence is often described through the linguistic
concept of markedness, which in the context of
phonology tells us that the substantive conditions
that underlie the human capacity of speech pro-
duction and perception renders certain consonants
more favorable to be included in the inventory than
some other consonants (Clements, 2008). We ob-
serve that markedness plays a very important role
in shaping the global structure of the consonant in-
ventories. In fact, if we arrange the consonants in a
non-increasing order of the first eigenvector com-
ponents (which is equivalent to increasing order
of statistical markedness), and compare the set of
consonants present in an inventory of size s with
that of the first s entries from this hierarchy, we
find that the two are, on an average, more than
50% similar. This figure is surprisingly high be-
cause, in spite of the fact that ?s s ? 5412 , on an
average s2 consonants in an inventory are drawn
from the first s entries of the markedness hierarchy
(a small set), whereas the rest s2 are drawn from the
remaining (541? s) entries (a much larger set).
The high degree of proportionate co-occurrence
in PhoNet implied by this high correlation be-
tween the principal eigenvector and frequency fur-
ther indicates that the innate preference towards
certain phonemes is independent of the presence
of other phonemes in the inventory of a language.
4.3 The Second Eigenvector of PhoNet
Fig. 2(e) shows the second eigenvector component
for each node versus their occurrence frequency. It
is evident from the figure that the consonants have
been clustered into three groups. Those that have
a very low or a very high frequency club around 0
whereas, the medium frequency zone has clearly
split into two parts. In order to investigate the ba-
sis for this split we carry out the following experi-
ment.
Experiment I
(i) Remove all consonants whose frequency of oc-
currence across the inventories is very low (< 5).
(ii) Denote the absolute maximum value of the
positive component of the second eigenvector as
MAX+ and the absolute maximum value of the
negative component as MAX?. If the absolute
value of a positive component is less than 15% of
MAX+ then assign a neutral class to the corre-
sponding consonant; else assign it a positive class.
Denote the set of consonants in the positive class
by C+. Similarly, if the absolute value of a nega-
tive component is less than 15% of MAX? then
assign a neutral class to the corresponding conso-
nant; else assign it a negative class. Denote the set
of consonants in the negative class by C?.
(iii) Using the above training set of the classified
consonants (represented as boolean feature vec-
tors) learn a decision tree (C4.5 algorithm (Quin-
lan, 1993)) to determine the features that are re-
sponsible for the split of the medium frequency
zone into the negative and the positive classes.
Fig. 3(a) shows the decision rules learnt from
the above training set. It is clear from these rules
that the split into C? and C+ has taken place
mainly based on whether the consonants have
the combined ?dental alveolar? feature (negative
class) or the ?dental? and the ?alveolar? features
separately (positive class). Such a combined fea-
ture is often termed ambiguous and its presence in
a particular consonant c of a language l indicates
that the speakers of l are unable to make a distinc-
tion as to whether c is articulated with the tongue
against the upper teeth or the alveolar ridge. In
contrast, if the features are present separately then
the speakers are capable of making this distinc-
tion. In fact, through the following experiment,
we find that the consonant inventories of almost
all the languages in UPSID get classified based on
whether they preserve this distinction or not.
Experiment II
(i) Construct B? = ATA ? D? (i.e., the adjacency
matrix of LangGraph).
(ii) Compute the second eigenvector of B?. Once
again, the positive and the negative components
split the languages into two distinct groups L+ and
L? respectively.
(iii) For each language l ? L+ count the num-
ber of consonants in C+ that occur in l. Sum up
the counts for all the languages in L+ and nor-
malize this sum by |L+||C+|. Similarly, perform
the same step for the pairs (L+,C?), (L?,C+) and
(L?,C?).
From the above experiment, the values obtained
for the pairs (i) (L+,C+), (L+,C?) are 0.35, 0.08
respectively, and (ii) (L?,C+), (L?,C?) are 0.07,
0.32 respectively. This immediately implies that
almost all the languages in L+ preserve the den-
tal/alveolar distinction while those in L? do not.
590
Figure 3: Decision rules obtained from the study of (a) the second, and (b) the third eigenvectors. The
classification errors for both (a) and (b) are less than 15%.
4.4 The Third Eigenvector of PhoNet
We next investigate the relationship between the
third eigenvector components of B and the occur-
rence frequency of the consonants (Fig. 2(f)). The
consonants are once again found to get clustered
into three groups, though not as clearly as in the
previous case. Therefore, in order to determine the
basis of the split, we repeat experiments I and II.
Fig. 3(b) clearly indicates that in this case the con-
sonants in C+ lack the complex features that are
considered difficult for articulation. On the other
hand, the consonants in C? are mostly composed
of such complex features. The values obtained for
the pairs (i) (L+,C+), (L+,C?) are 0.34, 0.06 re-
spectively, and (ii) (L?,C+), (L?,C?) are 0.19,
0.18 respectively. This implies that while there is
a prevalence of the consonants from C+ in the lan-
guages of L+, the consonants from C? are almost
absent. However, there is an equal prevalence of
the consonants from C+ and C? in the languages
of L?. Therefore, it can be argued that the pres-
ence of the consonants from C? in a language can
(phonologically) imply the presence of the conso-
nants from C+, but not vice versa. We do not find
any such aforementioned pattern for the fourth and
the higher eigenvector components.
4.5 Control Experiment
As a control experiment we generated a set of ran-
dom inventories and carried out the experiments
I and II on the adjacency matrix, BR, of the ran-
dom version of PhoNet. We construct these in-
ventories as follows. Let the frequency of occur-
rence for each consonant c in UPSID be denoted
by fc. Let there be 317 bins each corresponding to
a language in UPSID. fc bins are then chosen uni-
formly at random and the consonant c is packed
into these bins. Thus the consonant inventories
of the 317 languages corresponding to the bins
are generated. Note that this method of inventory
construction leads to proportionate co-occurrence.
Consequently, the first eigenvector components of
BR are highly correlated to the occurrence fre-
quency of the consonants. However, the plots of
the second and the third eigenvector components
versus the occurrence frequency of the consonants
indicate absolutely no pattern thereby, resulting in
a large number of decision rules and very high
classification errors (upto 50%).
591
5 Discussion and Conclusion
Are there any linguistic inferences that can be
drawn from the results obtained through the
study of the spectral plot and the eigenvectors of
PhoNet? In fact, one can correlate several phono-
logical theories to the aforementioned observa-
tions, which have been construed by the past re-
searchers through very specific studies.
One of the most important problems in defin-
ing a feature-based classificatory system is to de-
cide when a sound in one language is different
from a similar sound in another language. Ac-
cording to Ladefoged (2005) ?two sounds in dif-
ferent languages should be considered as distinct
if we can point to a third language in which the
same two sounds distinguish words?. The den-
tal versus alveolar distinction that we find to be
highly instrumental in splitting the world?s lan-
guages into two different groups (i.e., L+ and L?
obtained from the analysis of the second eigen-
vectors of B and B?) also has a strong classifi-
catory basis. It may well be the case that cer-
tain categories of sounds like the dental and the
alveolar sibilants are not sufficiently distinct to
constitute a reliable linguistic contrast (see (Lade-
foged, 2005) for reference). Nevertheless, by al-
lowing the possibility for the dental versus alveo-
lar distinction, one does not increase the complex-
ity or introduce any redundancy in the classifica-
tory system. This is because, such a distinction
is prevalent in many other sounds, some of which
are (a) nasals in Tamil (Shanmugam, 1972) and
Malayalam (Shanmugam, 1972; Ladefoged and
Maddieson, 1996), (b) laterals in Albanian (Lade-
foged and Maddieson, 1996), and (c) stops in cer-
tain dialectal variations of Swahili (Hayward et al,
1989). Therefore, it is sensible to conclude that the
two distinct groups L+ and L? induced by our al-
gorithm are true representatives of two important
linguistic typologies.
The results obtained from the analysis of the
third eigenvectors of B and B? indicate that im-
plicational universals also play a crucial role in
determining linguistic typologies. The two ty-
pologies that are predominant in this case con-
sist of (a) languages using only those sounds that
have simple features (e.g., plosives), and (b) lan-
guages using sounds with complex features (e.g.,
lateral, ejectives, and fricatives) that automatically
imply the presence of the sounds having sim-
ple features. The distinction between the simple
and complex phonological features is a very com-
mon hypothesis underlying the implicational hier-
archy and the corresponding typological classifi-
cation (Clements, 2008). In this context, Locke
and Pearson (1992) remark that ?Infants heavily
favor stop consonants over fricatives, and there
are languages that have stops and no fricatives but
no languages that exemplify the reverse pattern.
[Such] ?phonologically universal? patterns, which
cut across languages and speakers are, in fact, the
phonetic properties of Homo sapiens.? (as quoted
in (Vallee et al, 2002)).
Therefore, it turns out that the methodology pre-
sented here essentially facilitates the induction of
linguistic typologies. Indeed, spectral analysis de-
rives, in a unified way, the importance of these
principles and at the same time quantifies their ap-
plicability in explaining the structural patterns ob-
served across the inventories. In this context, there
are at least two other novelties of this work. The
first novelty is in the systematic study of the spec-
tral plots (i.e., the distribution of the eigenvalues),
which is in general rare for linguistic networks,
although there have been quite a number of such
studies in the domain of biological and social net-
works (Farkas et al, 2001; Gkantsidis et al, 2003;
Banerjee and Jost, 2007). The second novelty is
in the fact that there is not much work in the com-
plex network literature that investigates the nature
of the eigenvectors and their interactions to infer
the organizing principles of the system represented
through the network.
To summarize, spectral analysis of the com-
plex network of speech sounds is able to provide
a holistic as well as quantitative explanation of
the organizing principles of the sound inventories.
This scheme for typology induction is not depen-
dent on the specific data set used as long as it is
representative of the real world. Thus, we believe
that the scheme introduced here can be applied as
a generic technique for typological classifications
of phonological, syntactic and semantic networks;
each of these are equally interesting from the per-
spective of understanding the structure and evolu-
tion of human language, and are topics of future
research.
Acknowledgement
We would like to thank Kalika Bali for her valu-
able inputs towards the linguistic analysis.
592
References
A. Banerjee and J. Jost. 2007. Spectral plots and the
representation and interpretation of biological data.
Theory in Biosciences, 126(1):15?21.
A. Banerjee and J. Jost. to appear. Graph spectra as a
systematic tool in computational biology. Discrete
Applied Mathematics.
M. Belkin and J. Goldsmith. 2002. Using eigenvectors
of the bigram graph to infer morpheme identity. In
Proceedings of the ACL-02 Workshop on Morpho-
logical and Phonological Learning, pages 41?47.
Association for Computational Linguistics.
P. Boersma. 1998. Functional Phonology. The Hague:
Holland Academic Graphics.
M. Choudhury and A. Mukherjee. to appear. The
structure and dynamics of linguistic networks. In
N. Ganguly, A. Deutsch, and A. Mukherjee, editors,
Dynamics on and of Complex Networks: Applica-
tions to Biology, Computer Science, Economics, and
the Social Sciences. Birkhauser.
M. Choudhury, A. Mukherjee, A. Basu, and N. Gan-
guly. 2006. Analysis and synthesis of the distribu-
tion of consonants over languages: A complex net-
work approach. In COLING-ACL?06, pages 128?
135.
F. R. K. Chung. 1994. Spectral Graph Theory. Num-
ber 2 in CBMS Regional Conference Series in Math-
ematics. American Mathematical Society.
G. N. Clements. 2008. The role of features in speech
sound inventories. In E. Raimy and C. Cairns, edi-
tors, Contemporary Views on Architecture and Rep-
resentations in Phonological Theory. Cambridge,
MA: MIT Press.
E. J. Farkas, I. Derenyi, A. -L. Baraba?si, and T. Vic-
seck. 2001. Real-world graphs: Beyond the semi-
circle law. Phy. Rev. E, 64:026704.
R. Ferrer-i-Cancho. 2005. The structure of syntac-
tic dependency networks: Insights from recent ad-
vances in network theory. In Levickij V. and Altm-
man G., editors, Problems of quantitative linguistics,
pages 60?75.
C. Gkantsidis, M. Mihail, and E. Zegura. 2003.
Spectral analysis of internet topologies. In INFO-
COM?03, pages 364?374.
K. M. Hayward, Y. A. Omar, and M. Goesche. 1989.
Dental and alveolar stops in Kimvita Swahili: An
electropalatographic study. African Languages and
Cultures, 2(1):51?72.
R. Kannan and S. Vempala. 2008. Spec-
tral Algorithms. Course Lecture Notes:
http://www.cc.gatech.edu/?vempala/spectral/spectral.pdf.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
Worlds Languages. Oxford: Blackwell.
P. Ladefoged. 2005. Features and parameters for
different purposes. In Working Papers in Phonet-
ics, volume 104, pages 1?13. Dept. of Linguistics,
UCLA.
B. Lindblom and I. Maddieson. 1988. Phonetic univer-
sals in consonant systems. In M. Hyman and C. N.
Li, editors, Language, Speech, and Mind, pages 62?
78.
J. L. Locke and D. M. Pearson. 1992. Vocal learn-
ing and the emergence of phonological capacity. A
neurobiological approach. In Phonological devel-
opment. Models, Research, Implications, pages 91?
129. York Press.
I. Maddieson. 1984. Patterns of Sounds. Cambridge
University Press.
A. Mukherjee, M. Choudhury, A. Basu, and N. Gan-
guly. 2007. Modeling the co-occurrence principles
of the consonant inventories: A complex network
approach. Int. Jour. of Mod. Phys. C, 18(2):281?
295.
A. Mukherjee, M. Choudhury, A. Basu, and N. Gan-
guly. 2008. Modeling the structure and dynamics of
the consonant inventories: A complex network ap-
proach. In COLING-08, pages 601?608.
J. R. Quinlan. 1993. C4.5: Programs for Machine
Learning. Morgan Kaufmann.
S. V. Shanmugam. 1972. Dental and alveolar nasals in
Dravidian. In Bulletin of the School of Oriental and
African Studies, volume 35, pages 74?84. University
of London.
M. Sigman and G. A. Cecchi. 2002. Global organi-
zation of the wordnet lexicon. Proceedings of the
National Academy of Science, 99(3):1742?1747.
N. Trubetzkoy. 1931. Die phonologischen systeme.
TCLP, 4:96?116.
N. Trubetzkoy. 1969. Principles of Phonology. Uni-
versity of California Press, Berkeley.
N. Vallee, L J Boe, J. L. Schwartz, P. Badin, and
C. Abry. 2002. The weight of phonetic substance in
the structure of sound inventories. ZASPiL, 28:145?
168.
593
Social Network Inspired Models of NLP and Language Evolution
Monojit Choudhury
Microsoft Research Lab India
196/36 2nd Main, Sadashivnagar, Bangalore, India 560080
monojitc@microsoft.com
Animesh Mukherjee and Niloy Ganguly
Department of Computer Science and Engineering
Indian Institute of Technology Kharagpur, India 721302
{animesh,niloy}@cse.iitkgp.ernet.in
Abstract
Human language with all its intricacies is per-
haps one of the finest examples of a complex sys-
tem. Therefore, it becomes absolutely necessary
to study the faculty of language from the perspec-
tive of a complex system. Of late, there has been
an upsurge in the use of networks in modeling the
complex dynamics of various natural and artificial
systems. While some of these works aim at us-
ing social network techniques to build certain end-
user applications, others are more fundamental in
the sense that they employ these techniques to ex-
plain the emergent properties of a complex system
as a whole. A substantial amount of research have
also been done in the field of linguistics to employ
social networks in the design of efficient solutions
for numerous problems in NLP and language evolu-
tion. The objective of this tutorial is to show how
language and its dynamics can be successfully stud-
ied in the framework of social networks. The tuto-
rial will particularly demonstrate the relevance of so-
cial network-based methods in the development of a
large variety of NLP applications and in understand-
ing the dynamics of language evolution and change.
The tutorial is divided into two parts. Part I begins
with a brief introduction to this field showing how
linguistic entities and the interactions between them
can be respectively represented through the nodes
and edges of a network. This will be followed by a
comprehensive survey of the general theory of social
networks with a special emphasis on the methods of
analysis and models of synthesis for such networks.
Part II presents three case studies. The first case
study is on unsupervised POS tagging, the second
one involves modeling of the mental lexicon and ap-
plications of such models in spell checking and word
sense disambiguation. The third case study demon-
strates the usefulness of social networks in explain-
ing some of the evolutionary dynamics of language
pertaining to the sound inventories.
The tutorial is concluded by (a) comparing the
above methods with more traditional methods of do-
ing NLP, (b) providing pointers as to where to look
for/publish materials in this area, and, (c) indicating
some of the future research directions.
Biography
Monojit Choudhury is a post doctoral researcher
at Microsoft Research, India. He has submitted his
PhD from the Department of Computer Science and
Engineering, IIT Kharagpur and earlier, received his
B.Tech from the same department. Mr. Choudhury
received the Young Scientist Award from the Indian
Science Congress Association in 2003.
Animesh Mukherjee is a PhD student in the De-
partment of Computer Science and Engineering, IIT
Kharagpur and also a Microsoft Research fellow.
He received his MTech from the same department,
and BTech from Haldia Institute of Technology. Mr.
Mukherjee received the Young Scientist Award from
the Indian Science Congress Association in 2006.
Niloy Ganguly is an assistant professor in the De-
partment of Computer Science and Engineering, IIT
Kharagpur. He has received his PhD in Computer
Science from Bengal Engineering and Science Uni-
versity, Calcutta and his Bachelors from IIT Kharag-
pur. He was a post doctoral fellow in Technical
University of Dresden, Germany. He has numer-
ous publications in international journals and con-
ferences including ACL, PODC, SIGCOMM, ACM
and IEEE Trans.
937
Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 5?6,
Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language Processing
Breaking the Zipfian Barrier of NLP 
Monojit Choudhury 
Microsoft Research India, 
Bangalore 
monojit.choudhury@gmail.com 
 
 
 
 
 
 
 
Abstract 
We know that the distribution of most of the linguistic entities (e.g. phones, words, grammar rules) follow 
a power law or the Zipf's law. This makes NLP hard. Interestingly, the distribution of speakers over the 
world, content over the web and linguistic resources available across languages also follow power 
law. However, the correlation between the distribution of number of speakers to that of web content and 
linguistic resources is rather poor, and the latter distributions are much more skewed than the former. In 
other words, there is a large volume of resources only for a very few languages and a large number of 
widely spoken languages, including all the Indian languages, have little or no linguistic resource at all. 
This is a serious challenge for NLP in these languages, primarily because state-of-the-art techniques and 
tools in NLP are all data-driven.  I refer to this situation as the "Zipfian Barrier of NLP" and offer 
a mathematical analysis of the growth dynamics of the linguistic resources and NLP research worldwide, 
which, afterall, is very much a socio-economic process. Based on the analysis and otherwise, I propose 
certain technical ( e.g. unsupervised learning, wiki based approaches to gather data) and community-wide 
(e.g. acceptance of language specific works and resource building projects in top NLP confer-
ences/journals, Special Interest Groups) initiatives that could possibly break this Zipfian Barrier.  
 
5
 6
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 245?248,
Suntec, Singapore, 4 August 2009.
c?2009 ACL and AFNLP
Syntax is from Mars while Semantics from Venus!
Insights from Spectral Analysis of Distributional Similarity Networks
Chris Biemann
Microsoft/Powerset, San Francisco
Chris.Biemann@microsoft.com
Monojit Choudhury
Microsoft Research Lab India
monojitc@microsoft.com
Animesh Mukherjee
Indian Institute of Technology Kharagpur, India
animeshm@cse.iitkgp.ac.in
Abstract
We study the global topology of the syn-
tactic and semantic distributional similar-
ity networks for English through the tech-
nique of spectral analysis. We observe that
while the syntactic network has a hierar-
chical structure with strong communities
and their mixtures, the semantic network
has several tightly knit communities along
with a large core without any such well-
defined community structure.
1 Introduction
Syntax and semantics are two tightly coupled, yet
very different properties of any natural language
? as if one is from ?Mars? and the other from
?Venus?. Indeed, this exploratory work shows that
the distributional properties of syntax are quite dif-
ferent from those of semantics. Distributional hy-
pothesis states that the words that occur in the
same contexts tend to have similar meanings (Har-
ris, 1968). Using this hypothesis, one can define a
vector space model for words where every word
is a point in some n-dimensional space and the
distance between them can be interpreted as the
inverse of the semantic or syntactic similarity be-
tween their corresponding distributional patterns.
Usually, the co-occurrence patterns with respect to
the function words are used to define the syntactic
context, whereas that with respect to the content
words define the semantic context. An alternative,
but equally popular, visualization of distributional
similarity is through graphs or networks, where
each word is represented as nodes and weighted
edges indicate the extent of distributional similar-
ity between them.
What are the commonalities and differences be-
tween the syntactic and semantic distributional
patterns of the words of a language? This study is
an initial attempt to answer this fundamental and
intriguing question, whereby we construct the syn-
tactic and semantic distributional similarity net-
work (DSN) and analyze their spectrum to un-
derstand their global topology. We observe that
there are significant differences between the two
networks: the syntactic network has well-defined
hierarchical community structure implying a sys-
tematic organization of natural classes and their
mixtures (e.g., words which are both nouns and
verbs); on the other hand, the semantic network
has several isolated clusters or the so called tightly
knit communities and a core component that lacks
a clear community structure. Spectral analysis
also reveals the basis of formation of the natu-
ral classes or communities within these networks.
These observations collectively point towards a
well accepted fact that the semantic space of nat-
ural languages has extremely high dimension with
no clearly observable subspaces, which makes the-
orizing and engineering harder compared to its
syntactic counterpart.
Spectral analysis is the backbone of several
techniques, such as multi-dimensional scaling,
principle component analysis and latent semantic
analysis, that are commonly used in NLP. In re-
cent times, there have been some work on spec-
tral analysis of linguistic networks as well. Belkin
and Goldsmith (2002) applied spectral analysis to
understand the struture of morpho-syntactic net-
works of English words. The current work, on
the other hand, is along the lines of Mukherjee et
al. (2009), where the aim is to understand not only
the principles of organization, but also the global
topology of the network through the study of the
spectrum. The most important contribution here,
however, lies in the comparison of the topology
of the syntactic and semantic DSNs, which, to the
best of our knowledge, has not been explored pre-
viously.
245
2 Network Construction
The syntactic and semantic DSNs are constructed
from a raw text corpus. This work is restricted to
the study of English DSNs only
1
.
Syntactic DSN: We define our syntactic net-
work in a similar way as previous works in unsu-
pervised parts-of-speech induction (cf. (Sch?utze,
1995; Biemann, 2006)): The most frequent 200
words in the corpus (July 2008 dump of English
Wikipedia) are used as features in a word window
of ?2 around the target words. Thus, each target
word is described by an 800-dimensional feature
vector, containing the number of times we observe
one of the most frequent 200 words in the respec-
tive positions relative to the target word. In our
experiments, we collect data for the most frequent
1000 and 5000 target words, arguing that all syn-
tactic classes should be represented in those. A
similarity measure between target words is defined
by the cosine between the feature vectors. The
syntactic graph is formed by inserting the target
words as nodes and connecting nodes with edge
weights equal to their cosine similarity if this sim-
ilarity exceeds a threshold t = 0.66.
Semantic DSN: The construction of this net-
work is inspired by (Lin, 1998). Specifically,
we parsed a dump of English Wikipedia (July
2008) with the XLE parser (Riezler et al, 2002)
and extracted the following dependency relations
for nouns: Verb-Subject, Verb-Object, Noun-
coordination, NN-compound, Adj-Mod. These
lexicalized relations act as features for the nouns.
Verbs are recorded together with their subcatego-
rization frame, i.e. the same verb lemmas in dif-
ferent subcat frames would be treated as if they
were different verbs. We compute log-likelihood
significance between features and target nouns (as
in (Dunning, 1993)) and keep only the most signif-
icant 200 features per target word. Each feature f
gets a feature weight that is inversely proportional
to the logarithm of the number of target words it
applies on. The similarity of two target nouns is
then computed as the sum of the feature weights
they share. For our analysis, we restrict the graph
to the most frequent 5000 target common nouns
and keep only the 200 highest weighted edges per
target noun. Note that the degree of a node can
1
As shown in (Nath et al, 2008), the basic structure
of these networks are insensitive to minor variations in the
parameters (e.g., thresholds and number of words) and the
choice of distance metric.
Figure 1: The spectrum of the syntactic and se-
mantic DSNs of 1000 nodes.
still be larger than 200 if this node is contained in
many 200 highest weighted edges of other target
nouns.
3 Spectrum of DSNs
Spectral analysis refers to the systematic study of
the eigenvalues and eigenvectors of a network. Al-
though here we study the spectrum of the adja-
cency matrix of the weighted networks, it is also
quite common to study the spectrum of the Lapla-
cian of the adjacency matrix (see for example,
Belkin and Goldsmith (2002)). Fig. 1 compares
the spectrum of the syntactic and semantic DSNs
with 1000 nodes, which has been computed as fol-
lows. First, the 1000 eigenvalues of the adjacency
matrix are sorted in descending order. Then we
compute the spectral coverage till the ith eigen-
value by adding the squares of the first i eigenval-
ues and normalizing it by the sum of the squares
of all the eigenvalues - a quantity also known as
the Frobenius norm of the matrix.
We observe that for the semantic DSN the first
10 eigenvalues cover only 40% of the spectrum
and the first 500 together make up 75% of the
spectrum. On the other hand, for the syntactic
DSN, the first 10 eigenvalues cover 75% of the
spectrum while the first 20 covers 80%. In other
words, the structure of the syntactic DSN is gov-
erned by a few (order of 10) significant principles,
whereas that of the semantic DSN is controlled by
a large number of equally insignificant factors.
The aforementioned observation has the fol-
lowing alternative, but equivalent interpretations:
(a) the syntactic DSN can be clustered in lower
dimensions (e.g., 10 or 20) because, most of
the rows in the matrix can be approximately ex-
pressed as a linear combination of the top 10 to 20
246
Figure 2: Plot of corpus frequency based rank vs.
eigenvector centrality of the words in the DSNs of
5000 nodes.
eigenvectors. Furthermore, the graceful decay of
the eigenvalues of the syntactic DSN implies the
existence of a hierarchical community structure,
which has been independently verified by Nath et
al. (2008) through analysis of the degree distribu-
tion of such networks; and (b) a random walk con-
ducted on the semantic DSN will have a high ten-
dency to drift away very soon from the semantic
class of the starting node, whereas in the syntactic
DSN, the random walk is expected to stay within
the same syntactic class for a long time. There-
fore, it is reasonable to advocate that characteriza-
tion and processing of syntatic classes is far less
confusing than that of the semantic classes ? a fact
that requires no emphasis.
4 Eigenvector Analysis
The first eigenvalue tells us to what extent the
rows of the adjacency matrix are correlated and
therefore, the corresponding eigenvector is not a
dimension pointing to any classificatory basis of
the words. However, as we shall see shortly, the
other eigenvectors corresponding to the signifi-
cantly high eigenvalues are important classifica-
tory dimensions.
Fig 2 shows the plot of the first eigenvector
component (aka eigenvector centrality) of a word
versus its rank based on the corpus frequency. We
observe that the very high frequency (i.e., low
rank) nodes in both the networks have low eigen-
vector centrality, whereas the medium frequency
nodes display a wide range of centrality values.
However, the most striking difference between the
networks is that while in the syntactic DSN the
centrality values are approximately normally dis-
tributed for the medium frequency words, the least
frequent words enjoy the highest centrality for the
semantic DSN. Furthermore, we observe that the
most central nodes in the semantic DSN corre-
spond to semantically unambiguous words of sim-
ilar nature (e.g., deterioration, abandonment, frag-
mentation, turmoil). This indicates the existence
of several ?tightly knit communities consisting of
not so high frequency words? which pull in a sig-
nificant fraction of the overall centrality. Since
the high frequency words are usually polysemous,
they on the other hand form a large, but non-
cliqueish structure at the core of the network with
a few connections to the tightly knit communities.
This is known as the tightly knit community ef-
fect (TKC effect) that renders very low central-
ity values to the ?truly? central nodes of the net-
work (Lempel and Moran, 2000). The structure
of the syntactic DSN, however, is not governed by
the TKC effect to such an extreme extent. Hence,
one can expect to easily identify the natural classes
of the syntactic DSN, but not its semantic counter-
part.
In fact, this observation is further corroborated
by the higher eigenvectors. Fig. 3 shows the plot
of the second eigenvector component versus the
fourth one for the two DSNs consisting of 5000
words. It is observed that for the syntactic net-
work, the words get neatly clustered into two sets
comprised of words with the positive and negative
second eigenvector components. The same plot
for the semantic DSN shows that a large number of
words have both the components close to zero and
only a few words stand out on one side of the axes
? those with positive second eigenvector compo-
nent and those with negative fourth eigenvector
component. In essence, none of these eigenvec-
tors can neatly classify the words into two sets ?
a trend which is observed for all the higher eigen-
vectors (we conducted experiments for up to the
twentieth eigenvector).
Study of the individual eignevectors further re-
veals that the nodes with either the extreme pos-
itive or the extreme negative components have
strong linguistic correlates. For instance, in the
syntactic DSN, the two ends of the second eigen-
247
Figure 3: Plot of the second vs. fourth eigenvector
components of the words in the DSNs.
vector correspond to nouns and adjectives; one of
the ends of the fourth, fifth, sixth and the twelfth
eigenvectors respectively correspond to location
nouns, prepositions, first names and initials, and
verbs. In the semantic DSN, one of the ends of
the second, third, fourth and tenth eigenvectors
respectively correspond to professions, abstract
terms, food items and body parts. One would ex-
pect that the higher eigenvectors (say the 50
th
one)
would show no clear classificatory basis for the
syntactic DSN, while for the semantic DSN those
could be still associated with prominent linguistic
correlates.
5 Conclusion and Future Work
Here, we presented some initial investigations into
the nature of the syntactic and semantic DSNs
through the method of spectral analysis, whereby
we could observe that the global topology of the
two networks are significantly different in terms
of the organization of their natural classes. While
the syntactic DSN seems to exhibit a hierarchi-
cal structure with a few strong natural classes and
their mixtures, the semantic DSN is composed of
several tightly knit small communities along with
a large core consisting of very many smaller ill-
defined and ambiguous sets of words. To visual-
ize, one could draw an analogy of the syntactic
and semantic DSNs respectively to ?crystalline?
and ?amorphous? solids.
This work can be furthered in several directions,
such as, (a) testing the robustness of the findings
across languages, different network construction
policies, and corpora of different sizes and from
various domains; (b) clustering of the words on the
basis of eigenvector components and using them in
NLP applications such as unsupervised POS tag-
ging and WSD; and (c) spectral analysis of Word-
Net and other manually constructed ontologies.
Acknowledgement
CB and AM are grateful to Microsoft Research
India, respectively for hosting him while this re-
search was conducted, and financial support.
References
M. Belkin and J. Goldsmith 2002. Using eigenvec-
tors of the bigram graph to infer morpheme identity.
In Proceedings of the ACL-02Workshop onMorpho-
logical and Phonological Learning, pages 4147, As-
sociation for Computational Linguistics.
Chris Biemann 2006. Unsupervised part-of-speech
tagging employing efficient graph clustering. In
Proceedings of the COLING/ACL-06 Student Re-
search Workshop.
Ted Dunning 1993. Accurate methods for the statis-
tics of surprise and coincidence. In Computational
Linguistics 19, 1, pages 61?74
Z.S. Harris 1968. Mathematical Structures of Lan-
guage. Wiley, New York.
R. Lempel and S. Moran 2000. The stochastic ap-
proach for link-structure analysis (SALSA) and the
TKC effect. In Computer Networks, 33, pages 387-
401
Dekang Lin 1998. Automatic retrieval and clustering
of similar words. In Proceedings of COLING?98.
Animesh Mukherjee, Monojit Choudhury and Ravi
Kannan 2009. Discovering Global Patterns in Lin-
guistic Networks through Spectral Analysis: A Case
Study of the Consonant Inventories. In The Pro-
ceedings of EACL 2009, pages 585-593.
Joydeep Nath, Monojit Choudhury, Animesh Mukher-
jee, Christian Biemann and Niloy Ganguly 2008.
Unsupervised parts-of-speech induction for Bengali.
In The Proceedings of LREC?08, ELRA.
S. Riezler, T.H. King, R.M. Kaplan, R. Crouch, J.T.
Maxwell, M. Johnson 2002. Parsing the Wall Street
Journal using a lexical-functional grammar and dis-
criminative estimation techniques. In Proceedings
of the 40th Annual Meeting of the ACL, pages 271-
278.
Hinrich Sch?utze 1995. Distributional part-of-speech
tagging. In Proceedings of EACL, pages 141-148.
248
Proceedings of the EACL 2009 Workshop on Cognitive Aspects of Computational Language Acquisition, pages 51?58,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
Language Diversity across the Consonant Inventories:
A Study in the Framework of Complex Networks
Monojit Choudhury
Microsoft Research India, Bangalore, India ? 560080
Email: monojitc@microsoft.com
Animesh Mukherjee, Anupam Basu and Niloy Ganguly
Indian Institute of Technology, Kharagpur, India ? 721302
Ashish Garg and Vaibhav Jalan
Malaviya National Institute of Technology, Jaipur, India ? 302017
Abstract
In this paper, we attempt to explain the
emergence of the linguistic diversity that
exists across the consonant inventories of
some of the major language families of the
world through a complex network based
growth model. There is only a single pa-
rameter for this model that is meant to
introduce a small amount of randomness
in the otherwise preferential attachment
based growth process. The experiments
with this model parameter indicates that
the choice of consonants among the lan-
guages within a family are far more pref-
erential than it is across the families. Fur-
thermore, our observations indicate that
this parameter might bear a correlation
with the period of existence of the lan-
guage families under investigation. These
findings lead us to argue that preferential
attachement seems to be an appropriate
high level abstraction for language acqui-
sition and change.
1 Introduction
In one of their seminal papers (Hauser et al,
2002), Noam Chomsky and his co-authors re-
marked that if a Martian ever graced our planet
then it would be awe-struck by the unique abil-
ity of the humans to communicate among them-
selves through the medium of language. How-
ever, if our Martian naturalist were meticulous
then it might also note the surprising co-existence
of 6700 such mutually unintelligible languages
across the world. Till date, the terrestrial scientists
have no definitive answer as to why this linguistic
diversity exists (Pinker, 1994). Previous work in
the area of language evolution has tried to explain
the emergence of this diversity through two differ-
ent background models. The first one assumes that
there is a set of predefined language configurations
and the movement of a particular language on this
landscape is no more than a random walk (Tom-
lin, 1986; Dryer, 1992). The second line of re-
search attempts to relate the ecological, cultural
and demographic parameters with the linguistic
parameters responsible for this diversity (Arita and
Taylor, 1996; Kirby, 1998; Livingstone and Fyfe,
1999; Nettle, 1999). From the above studies, it
turns out that linguistic diversity is an outcome of
the language dynamics in terms of its evolution,
acquisition and change.
In this work, we attempt to investigate the di-
versity that exists across the consonant inventories
of the world?s languages through an evolutionary
framework based on network growth. The use of
a network based model is motivated from the fact
that in the recent years, complex networks have
proved to be an extremely suitable framework for
modeling and studying the structure and dynam-
ics of linguistic systems (Cancho and Sole?, 2001;
Dorogovtsev and Mendes, 2001; Cancho and Sole?,
2004; Sole? et al, 2005).
Along the lines of the study presented
in (Choudhury et al, 2006), we model the struc-
ture of the inventories through a bipartite network,
which has two different sets of nodes, one la-
beled by the languages and the other by the con-
sonants. Edges run in between these two sets
depending on whether a particular consonant is
found in a particular language. This network
is termed the Phoneme?Language Network or
PlaNet in (Choudhury et al, 2006). We construct
five such networks that respectively represent the
consonant inventories belonging to the five ma-
51
jor language families namely, the Indo-European
(IE-PlaNet), the Afro-Asiatic (AA-PlaNet), the
Niger-Congo (NC-PlaNet), the Austronesian (AN-
PlaNet) and the Sino-Tibetan (ST-PlaNet).
The emergence of the distribution of occurrence
of the consonants across the languages of a fam-
ily can be explained through a growth model for
the PlaNet representing the family. We employ the
preferential attachment based growth model intro-
duced in (Choudhury et al, 2006) and later ana-
lytically solved in (Peruani et al, 2007) to explain
this emergence for each of the five families. The
model involves a single parameter that is essen-
tially meant to introduce randomness in the oth-
erwise predominantly preferential growth process.
We observe that if we combine the inventories for
all the families together and then attempt to fit this
new data with our model, the value of the param-
eter is significantly different from that of the in-
dividual families. This indicates that the dynam-
ics within the families is quite different from that
across them. There are possibly two factors that
regulate this dynamics: the innate preference of
the speakers towards acquiring certain linguistic
structures over others and shared ancestry of the
languages within a family.
The prime contribution of this paper lies in the
mathematical model that naturally captures and
quantifies the diversification process of the lan-
guage inventories. This diversification, which is
arguably an effect of language acquisition and
change, can be viewed as a manifestation of the
process of preferential attachment at a higher level
of abstraction.
The rest of the paper is laid out as follows. Sec-
tion 2 states the definition of PlaNet, briefly de-
scribes the data source and outlines the construc-
tion procedure for the five networks. In section 3
we review the growth model for the networks. The
experiments and the results are explained in the
next section. Section 5 concludes the paper by ex-
plaining how preferential attachment could possi-
bly model the phenomena of language acquisition,
change and evolution.
2 Definition and Construction of the
Networks
In this section, we revisit the definition of PlaNet,
discuss briefly about the data source, and explain
how we constructed the networks for each of the
families.
Figure 1: Illustration of the nodes and edges of
PlaNet.
2.1 Definition of PlaNet
PlaNet is a bipartite graph G = ? VL,VC ,Epl ? con-
sisting of two sets of nodes namely, VL (labeled
by the languages) and VC (labeled by the conso-
nants); Epl is the set of edges running between VL
and VC . There is an edge e ? Epl from a node
vl ? VL to a node vc ? VC iff the consonant c is
present in the inventory of the language l. Figure 1
illustrates the nodes and edges of PlaNet.
2.2 Data Source
We use the UCLA Phonological Segment Inven-
tory Database (UPSID) (Maddieson, 1984) as the
source of data for this work. The choice of this
database is motivated by a large number of typo-
logical studies (Lindblom and Maddieson, 1988;
Ladefoged and Maddieson, 1996; de Boer, 2000;
Hinskens and Weijer, 2003) that have been car-
ried out on it by earlier researchers. It is a well
known fact that UPSID suffers from several prob-
lems, especially those involving representational
issues (Vaux and Samuels, 2005). Therefore,
any analysis carried on UPSID and the inferences
drawn from them are subject to questions. How-
ever, the current analysis requires a large amount
of segment inventory data and to the best of our
knowledge UPSID is the biggest database of this
kind. Moreover, we would like to emphasize that
the prime contribution of this work lies in the
mathematical modeling of the data rather than the
results obtained, which, as we shall see shortly, are
not very surprising or novel. The current model
applied to a different database of segment inven-
52
tories may lead to different results, though we be-
lieve that the basic trends will remain similar. In
essence, the results described here should be taken
as indicative and not sacrosanct.
There are 317 languages in the database with
541 consonants found across them. From these
data we manually sort the languages into five
groups representing the five families. Note that we
included a language in any group if and only if we
could find a direct evidence of its presence in the
corresponding family. A brief description of each
of these groups and languages found within them
are listed below (Haspelmath et al, 2005; Gordon,
2005).
Indo-European: This family includes most of the
major languages of Europe and south, central and
south-west Asia. Currently, it has around 3 bil-
lion native speakers, which is largest among all
the recognized families of languages in the world.
The total number of languages appearing in this
family is 449. The earliest evidences of the Indo-
European languages have been found to date 4000
years back.
Languages ? Albanian, Lithuanian, Breton, Irish,
German, Norwegian, Greek, Bengali, Hindi-
Urdu, Kashmiri, Sinhalese, Farsi, Kurdish, Pashto,
French, Romanian, Spanish, Russian, Bulgarian.
Afro-Asiatic: Afro-Asiatic languages have about
200 million native speakers spread over north,
east, west, central and south-west Africa. This
family is divided into five subgroups with a total of
375 languages. The proto-language of this family
began to diverge into separate branches approxi-
mately 6000 years ago.
Languages ? Shilha, Margi, Angas, Dera, Hausa,
Kanakuru, Ngizim, Awiya, Somali, Iraqw, Dizi,
Kefa, Kullo, Hamer, Arabic, Amharic, Socotri.
Niger-Congo: The majority of the languages that
belong to this family are found in the sub-Saharan
parts of Africa. The number of native speakers
is around 300 million and the total number of
languages is 1514. This family descends from a
proto-language, which dates back 5000 years.
Languages ? Diola, Temne, Wolof, Akan, Amo,
Bariba, Beembe, Birom, Cham, Dagbani, Doayo,
Efik, Ga, Gbeya, Igbo, Ik, Koma, Lelemi, Senadi,
Tampulma, Tarok, Teke, Zande, Zulu, Kadugli,
Moro, Bisa, Dan, Bambara, Kpelle.
Austronesian: The languages of the Austronesian
family are widely dispersed throughout the islands
of south-east Asia and the Pacific. There are 1268
Networks |VL| |VC | |Epl|
IE-PlaNet 19 148 534
AA-PlaNet 17 123 453
NC-PlaNet 30 135 692
AN-PlaNet 12 82 221
ST-PlaNet 9 71 201
Table 1: Number of nodes and edges in the five
bipartite networks corresponding to the five fami-
lies.
languages in this family, which are spoken by a
population of 6 million native speakers. Around
4000 years back it separated out from its ancestral
branch.
Languages ? Rukai, Tsou, Hawaiian, Iai, Adz-
era, Kaliai, Roro, Malagasy, Chamorro, Tagalog,
Batak, Javanese.
Sino-Tibetan: Most of the languages in this fam-
ily are distributed over the entire east Asia. With
a population of around 2 billion native speakers it
ranks second after Indo-European. The total num-
ber of languages in this family is 403. Some of the
first evidences of this family can be traced 6000
years back.
Languages ? Hakka, Mandarin, Taishan, Jingpho,
Ao, Karen, Burmese, Lahu, Dafla.
2.3 Construction of the Networks
We use the consonant inventories of the languages
enlisted above to construct the five bipartite net-
works ? IE-PlaNet, AA-PlaNet, NC-PlaNet, AN-
PlaNet and ST-PlaNet. The number of nodes and
edges in each of these networks are noted in Ta-
ble 1.
3 The Growth Model for the Networks
As mentioned earlier, we employ the growth
model introduced in (Choudhury et al, 2006) and
later (approximately) solved in (Peruani et al,
2007) to explain the emergence of the degree dis-
tribution of the consonant nodes for the five bipar-
tite networks. For the purpose of readability, we
briefly summarize the idea below.
Degree Distribution: The degree of a node v, de-
noted by k, is the number of edges incident on
v. The degree distribution is the fraction of nodes
pk that have a degree equal to k (Newman, 2003).
The cumulative degree distribution Pk is the frac-
tion of nodes having degree greater than or equal
to k. Therefore, if there are N nodes in a network
53
then,
Pk =
N?
k=k?
pk? (1)
Model Description: The model assumes that the
size of the consonant inventories (i.e., the degree
of the language nodes in PlaNet) are known a pri-
ori.
Let the degree of a language node Li ? VL
be denoted by di (i.e., di refers to the inventory
size of the language Li in UPSID). The conso-
nant nodes in VC are assumed to be unlabeled, i.e,
they are not marked by the articulatory/acoustic
features (see (Trubetzkoy, 1931) for further refer-
ence) that characterize them. In other words, the
model does not take into account the phonetic sim-
ilarity among the segments. The nodes L1 through
L317 are sorted in the ascending order of their de-
grees. At each time step a node Lj , chosen in
order, preferentially gets connected to dj distinct
nodes (call each such node C) of the set VC . The
probability Pr(C) with which the node Lj gets
connected to the node C is given by,
Pr(C) = k + ??
?C? (k? + ?)
(2)
where k is the current degree of the node C, C ?
represents the nodes in VC that are not already
connected to Lj and ? is the model parameter that
is meant to introduce a small amount of random-
ness into the growth process. The above steps are
repeated until all the language nodes Lj ? VL get
connected to dj consonant nodes.
Intuitively, the model works as follows: If a
consonant is very frequently found in the invento-
ries of the languages, then there is a higher chance
of that consonant being included in the inventory
of a ?new language?. Here the term ?new lan-
guage? can be interpreted either as a new and hith-
erto unseen sample from the universal set of lan-
guages, or the formation of a new language due
to some form of language change. The param-
eter ? on the other hand ensures that the conso-
nants which are found in none of the languages
from the current sample also have a chance of be-
ing included in the new language. It is similar to
the add-? smoothing used to avoid zero probabil-
ities while estimating probability distributions. It
is easy to see that for very large values of ? the fre-
quency factor will play a very minor role and the
consonants will be chosen randomly by the new
language, irrespective of its present prevalence. It
is natural to ask why and how this particular pro-
cess would model the growth of the language in-
ventories. We defer this question until the last sec-
tion of the paper, and instead focus on some empir-
ical studies to see if the model can really explain
the observed data.
Peruani et al (2007) analytically derived an ap-
proximate expression for the degree distribution of
the consonant nodes for this model. Let the aver-
age consonant inventory size be denoted by ? and
the number of consonant nodes be N. The solu-
tion obtained in (Peruani et al, 2007) is based on
the assumption that at each time step t, a language
node gets attached to ? consonant nodes, follow-
ing the distribution Pr(C). Under the above as-
sumptions, the degree distribution pk,t for the con-
sonant nodes, obtained by solving the model, is a
?-distribution as follows
pk,t ' A
(k
t
)??1 (
1? kt
)N?
? ???1 (3)
where A is a constant term. Using equations 1
and 3 one can easily compute the value of Pk,t.
There is a subtle point that needs a mention
here. The concept of a time step is very crucial
for a growing network. It might refer to the addi-
tion of an edge or a node to the network. While
these two concepts coincide when every new node
has exactly one edge, there are obvious differences
when the new node has degree greater than one.
The analysis presented in Peruani et al (2007)
holds good for the case when only one edge is
added per time step. However, if the degree of the
new node being introduced to the system is much
less than N , then Eq. 3 is a good approximation of
the emergent degree distribution for the case when
a node with more than one edge is added per time
step. Therefore, the experiments presented in the
next section attempt to fit the degree distribution
of the real networks with Eq. 3 by tuning the pa-
rameter ?.
4 Experiments and Results
In this section, we attempt to fit the degree dis-
tribution of the five empirical networks with the
expression for Pk,t described in the previous sec-
tion. For all the experiments we set N = 541, t =
number of languages in the family under investi-
gation and ? = average degree of the language
nodes of the PlaNet representing the family under
investigation, that is, the average inventory size for
54
Network ? for least LSE Value of LSE
IE-PlaNet 0.055 0.16AA-PlaNet 0.040 0.24NC-PlaNet 0.035 0.19AN-PlaNet 0.030 0.17ST-PlaNet 0.035 0.03Combined-PlaNet 0.070 1.47
Table 2: The values of ? and the least LSE for the
different networks. Combined-PlaNet refers to the
network constructed after mixing all the languages
from all the families. For all the experiments
the family. Therefore, given the value of k we
can compute pk,t using Eq. 3 if ? is known, and
from pk,t we can further compute Pk,t. In order to
find the best fitting theoretical degree distribution,
we vary the value of ? in steps of 0.005 within the
range of 0 to 1 and choose that ? for which the log-
arithmic standard error1 (LSE) between the the-
oretical degree distribution and the epirically ob-
served degree distribution of the real network and
the equation is least. LSE is defined as the sum of
the square of the difference between the logarithm
of the ordinate pairs (say y and y?) for which the
abscissas are equal. The best fits obtained for each
of the five networks are shown in Figure 2. The
values of ? and the corresponding least LSE for
each of them are noted in Table 2. We make the
following significant and interesting observations.
Observation I: The very low value of the parame-
ter ? indicates that the choice of consonants within
the languages of a family is strongly preferential.
In this context, ? may be thought of as modeling
the (accidental) errors or drifts that can occur dur-
ing language transmission. The fact that the val-
ues of ? across the four major language families,
namely Afro-Asiatic,Niger-Congo, Sino-Tibetan
and Austronesian, are comparable indicates that
the rate of error propagation is a universal factor
that is largely constant across the families. The
value of ? for IE-PlaNet is slightly higher than
the other four families, which might be an effect
of higher diversification within the family due to
geographical or socio-political factors. Neverthe-
less, it is still smaller than the ? of the Combined-
1LSE = (log y ? log y?)2. We use LSE as the good-
ness of the fit because the degree distributions of PlaNets are
highly skewed. There are very few high degree nodes and a
large number of low degree nodes. The logarithmic error en-
sures that even very small errors made while fitting the high
degrees are penalized equally as compared to that of the low
degrees. Standard error would not capture this fact and de-
clare a fit as good if it is able to replicate the distribution for
low degrees, but fits the high degrees poorly .
PlaNet.
The optimal ? obtained for Combined-PlaNet is
higher than that of all the families (see Table 2),
though it is comparable to the Indo-European
PlaNet. This points to the fact that the choice
of consonants within the languages of a family is
far more preferential than it is across the families;
this fact is possibly an outcome of shared ances-
try. In other words, the inventories of genetically
related languages are similar (i.e., they share a lot
of consonants) because they have evolved from the
same parent language through a series of linguis-
tic changes, and the chances that they use a large
number of consonants used by the parent language
is naturally high.
Observation II: We observe a very interesting
relationship between the approximate age of the
language family and the values of ? obtained in
each case (see Table 3). The only anomaly is the
Indo-European branch, which possibly indicates
that this might be much older than it is believed
to be. In fact, a recent study (Balter, 2003) has
shown that the age of this family dates back to
8000 years. If this last argument is assumed to
be true then the values of ? have a one-to-one cor-
respondence with the approximate period of ex-
istence of the language families. As a matter of
fact, this correlation can be intuitively justified ?
the higher is the period of existence of a family, the
higher are the chances of transmission errors lead-
ing to its diversification into smaller subgroups,
and hence, the values of ? comes out to be more
for the older families. It should be noted that the
difference between the values of ? for the language
families are not significant2. Therefore, the afore-
mentioned observation should be interpreted only
as an interesting possibility; more experimentation
is required for making any stronger claim.
4.1 Control Experiment
How could one be sure that the aforementioned
observations are not an obvious outcome of the
construction of the PlaNet or some spurious cor-
relations? To this end, we conduct a control ex-
periment where a set of inventories is randomly
selected from UPSID to represent a family. The
2Note that in order to obtain the best fit for the cumulative
distribution, ? has been varied in steps of 0.005. Therefore,
the values of ? in Table 2 cannot be more accurate than ? ?
0.005. However, in many cases the difference between the
best-fit ? for two language families is exactly 0.005, which
indicates that the difference is not significant.
55
Figure 2: The degree distribution of the different real networks (black dots) along with the fits obtained
from the equation for the optimal values of ? (grey lines).
Families Age (in years) ?
Austronasean 4000 0.030
Niger-Congo 5000 0.035
Sino-Tibetan 6000 0.035
Afro-Asiatic 6000 0.040
Indo-European 4000 (or 8000) 0.055
Table 3: Table showing the relationship between
the age of a family and the value of ?.
number of languages chosen is the same as that of
the PlaNets of the various language families. We
observe that the average value of ? for these ran-
domly constructed PlaNets is 0.068, which, as one
would expect, is close to that of the Combined-
PlaNet. This reinforces the fact that the inherent
proximity among the languages of a real family is
not due to chance.
4.2 Correlation between Families
It can be shown theoretically that if we merge two
PlaNets (say PlaNet1 and PlaNet2) synthesized us-
ing the growth model described here using param-
eters ?1 and ?2, then the ? of the combined PlaNet
can be much greater than both ?1 and ?2 when
there is a low correlation between the degrees of
the consonant nodes between the two PlaNets.
This can be understood as follows. Suppose that
the consonant /k/ is very frequent (i.e., has a high
degree) in PlaNet1, but the consonant /m/ is not.
On the other hand suppose that /m/ is very fre-
quenct in PlaNeT2, but /k/ is not. In the combined
PlaNet the degrees of /m/ and /k/ will even out and
the degree distribution will therefore, be much less
skewed than the original degree distributions of
PlaNet1 and PlaNet2. This is equivalent to the fact
that while ?1 and ?2 were very small, the ? of the
combined PlaNet is quite high. By the same logic
it follows that if the degrees of the consonants are
highly correlated in PlaNet1 and PlaNet2, then the
combined PlaNet will have an ? that is compara-
ble in magnitude to ?1 and ?2. The fact that the
? for the Combined-PlaNet is higher than that of
family-specific PlaNets, therefore, implies that the
correlation between the frequencies of the conso-
nants across language families is not very high.
In order to verify the above observation we esti-
mate the correlation between the frequency of oc-
currence of the consonants for the different lan-
guage family pairs (i.e., how the frequencies of
the consonants /p/, /t/, /k/, /m/, /n/ . . . are corre-
lated across the different families). Table 4 notes
the value of this correlation among the five fami-
lies. The values in Table 4 indicate that, in general,
the families are somewhat weakly correlated with
each other, the average correlation being ? 0.47.
Note that, the correlation between the Afro-
Asiatic and the Niger-Congo families is high not
only because they share the same African origin,
but also due to higher chances of language con-
tacts among their groups of speakers. On the other
hand, the Indo-European and the Sino-Tibetan
families show least correlation because it is usu-
56
Families IE AA NC AN ST
IE ? 0.49 0.48 0.42 0.25
AA 0.49 ? 0.66 0.53 0.43
NC 0.48 0.66 ? 0.55 0.37
AN 0.42 0.53 0.55 ? 0.50
ST 0.25 0.43 0.37 0.50 ?
Table 4: The Pearson?s correlation between the
frequency distributions obtained for the family
pairs. IE: Indo-European, AA: Afro-Asiatic,
NC: Niger-Congo, AN: Austronesian, ST: Sino-
Tibetan.
ally believed that they share absolutely no genetic
connections. Interestingly, similar trends are ob-
served for the values of the parameter ?. If we
combine the languages of the Afro-Asiatic and the
Niger-Congo families and try to fit the new data
then ? turns out to be 0.035 while if we do the same
for the Indo-European and the Sino-Tibetan fam-
ilies then ? is 0.058. For many of the other com-
binations the value of ? and the correlation coeffi-
cient have a one-to-one correspondence. However,
there are clear exceptions also. For instance, if we
combine the Afro-Asiatic and the Indo-European
families then the value of ? is very low (close to
0.04) although the correlation between them is not
very high. The reasons for these exceptions should
be interesting and we plan to further explore this
issue in future.
5 Conclusion
In this paper, we presented a method of network
evolution to capture the emergence of linguistic
diversity that manifests in the five major language
families of the world. How does the growth model,
if at all, captures the process of language dynam-
ics? We argue that preferential attachment is a
high level abstraction of language acquisition as
well as language change. We sketch out two pos-
sible explanations for this fact, both of which are
merely speculations at this point and call for de-
tailed experimentation.
It is a well known fact that the process of lan-
guage acquisition by an individual largely gov-
erns the course of language change in a linguis-
tic community. In the initial years of language
development every child passes through a stage
called babbling during which he/she learns to pro-
duce non-meaningful sequences of consonants and
vowels, some of which are not even used in the
language to which they are exposed (Jakobson,
1968; Locke, 1983). Clear preferences can be
observed for learning certain sounds such as plo-
sives and nasals, whereas fricatives and liquids are
avoided. In fact, this hierarchy of preference dur-
ing the babbling stage follows the cross-linguistic
frequency distribution of the consonants. This in-
nate frequency dependent preference towards cer-
tain phonemes might be because of phonetic rea-
sons (i.e., for articulatory/perceptual benefits). It
can be argued that in the current model, this in-
nate preference gets captured through the process
of preferential attachment.
An alternative explanation could be conceived
of based on the phenomenon of language trans-
mission. Let there be a community of N speak-
ers communicating among themselves by means
of only two consonants say /k/ and /g/. Let the
number of /k/ speakers be m and that of /g/ speak-
ers be n. If we assume that each speaker has l de-
scendants and that language inventories are trans-
mitted with high fidelity then after i generations,
the number of /k/ speakers should be mli and that
of /g/ speakers should be nli. Now if m > n
and l > 1 then for sufficiently large values of i
we have mli ? nli. Stated differently, the /k/
speakers by far outnumbers the /g/ speakers after a
few generations even though the initial difference
between them is quite small. This phenomenon
is similar to that of preferential attachment where
language communities get attached to, i.e., select
consonants that are already highly preferred. In
this context ? can be thought to model the acciden-
tal errors during transmission. Since these errors
accumulate over time, this can intuitively explain
why older language families have a higher value
of ? than the younger ones.
In fact, preferential attachment (PA) is a uni-
versally observed evolutionary mechanism that
is known to shape several physical, biological
and socio-economic systems (Newman, 2003).
This phenomenon has also been called for to ex-
plain various linguistic phenomena (Choudhury
and Mukherjee, to appear). We believe that PA
also provides a suitable abstraction for the mech-
anism of language acquisition. Acquisition of vo-
cabulary and growth of the mental lexicon are few
examples of PA in language acquisition. This
work illustrates another variant of PA applied to
explain the structure of consonant inventories and
their diversification across the language families.
57
References
T. Arita and C. E. Taylor. 1996. A simple model
for the evolution of communication. In L. J. Fo-
gel, P. J. Angeline and T. Ba?ck, editors, The Fifth
Annual Conference On Evolutionary Programming,
405?410. MIT Press.
M. Balter. 2003. Early date for the birth of Indo-
European languages. Science 302(5650), 1490.
A.-L. Baraba?si and R. Albert. 1999. Emergence of
scaling in random networks. Science 286, 509-512.
D. Bickerton. 1990. Language and Species, The Uni-
versity of Chicago Press, Chicago.
B. de Boer. 2000. Self-organization in vowel systems.
Journal of Phonetics, 28(4), 441?465.
R. Ferrer i Cancho and R. V. Sole?. 2001. The small-
world of human language. Proceedings of the Royal
Society of London, Series B, Biological Sciences,
268(1482), 1228?1235.
R. Ferrer i Cancho and R. V. Sole?. 2004. Patterns
in syntactic dependency networks. Phys. Rev. E,
69(051915).
R. G. Gordon (ed.) 2005. Ethnologue: Languages of
the World, Fifteenth edition, SIL International.
M. Haspelmath, M. S. Dryer, D. Gil and B. Comrie
(ed.) 2005. World Atlas of Language Structures,
Oxford University Press.
M. Choudhury, A. Mukherjee, A. Basu and N. Gan-
guly. 2006. Analysis and synthesis of the distri-
bution of consonants over languages: A complex
network approach. Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Com-
putational Linguistics, Main Conference Poster Ses-
sions, 128?135.
M. Choudhury and A. Mukherjee. to appear. The
structure and dynamics of linguistic networks. In N.
Ganguly, A. Deutsch and A. Mukherjee, editors, Dy-
namics on and of Complex Networks: Applications
to Biology, Computer Science, Economics, and the
Social Sciences, Birkhauser, Springer, Boston.
S. N. Dorogovtsev and J. F. F. Mendes. 2001. Lan-
guage as an evolving word web. Proceedings of the
Royal Society of London, Series B, Biological Sci-
ences, 268(1485), 2603?2606.
M. S. Dryer. 1992. The Greenbergian word order cor-
relations. Language, 68, 81?138.
M. D. Hauser, N. Chomsky and W. T. Fitch. 2002. The
faculty of language: What is it, who has it, and how
did it evolve? Science, 298, 1569?1579.
F. Hinskens and J. Weijer. 2003. Patterns of segmen-
tal modification in consonant inventories: a cross-
linguistic study. Linguistics, 41(6), 1041?1084.
R. Jakobson. 1968. Child Language, Aphasia and
Phonological Universals. The Hague: Mouton.
H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai and A.
L. Baraba?si. 2000. The large-scale organization of
metabolic networks. Nature, 406, 651-654.
S. Kirby. 1998. Fitness and the selective adaptation
of language. In J. R. Hurford, M. Studdert-Kennedy
and C. Knight, editors, Approaches to the Evolution
of Language: Social and Cognitive Bases, 359?383.
Cambridge: Cambridge University Press.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
Worlds Languages, Oxford: Blackwell.
B. Lindblom and I. Maddieson. 1988. Phonetic univer-
sals in consonant systems. In L.M. Hyman and C.N.
Li, eds., Language, Speech, and Mind, Routledge,
London, 62?78.
D. Livingstone and C. Fyfe. 1999. Modelling the
evolution of linguistic diversity. In D. Floreano, J.
Nicoud and F. Mondada, editors, ECAL 99, 704?
708, Berlin: Springer-Verlag.
J. L. Locke. 1983. Phonological Acquisition and
Change. Academic Press New York.
I. Maddieson. 1984. Patterns of Sounds, Cambridge
University Press, Cambridge.
D. Nettle. 1999. Is the rate of linguistic change con-
stant? Lingua, 108(2):119?136.
M. E. J. Newman. 2001. Scientific collaboration net-
works. Physical Review E 64, 016131.
M. E. J. Newman. 2003. The structure and function of
complex networks. SIAM Review 45, 167?256.
F. Peruani, M. Choudhury, A. Mukherjee and N. Gan-
guly. 2007. Emergence of a non-scaling degree dis-
tribution in bipartite networks: a numerical and ana-
lytical study. Euro. Phys. Letters 76, 28001 (p1?p6).
S. Pinker. 1994. The Language Instinct, New York:
William Morrow.
E. Pulleyblank. 1993. The typology of Indo-European.
Journal of Indo-European Studies, p. 109.
Jose? J. Ramasco, S. N. Dorogovtsev, and Romualdo
Pastor-Satorras. 2004. Self-organization of collabo-
ration networks. Physical Review E, 70, 036106.
R. V. Sole? , B. C. Murtra, S. Valverde and L. Steels.
2005. Language networks: Their structure, function
and evolution. Santa Fe working paper, 05-12-042.
R. Tomlin. 1986. Basic Word Order: Functional Prin-
ciples, Croom Helm, London.
N. Trubetzkoy. 1931. Die phonologischen systeme.
TCLP 4, 96?116.
B. Vaux and B. Samuel. 2005. Laryngeal markedness
and aspiration Phonology 22(3), 96?116.
58
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 10?18,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Complex Linguistic Annotation ? No Easy Way Out!  A Case from Bangla and Hindi POS Labeling Tasks  Sandipan Dandapat1         Priyanka Biswas1       Monojit Choudhury  Kalika Bali Dublin City University       LDCIL         Microsoft Research Labs India Ireland                   CIIL-Mysore, India               Bangalore, India E-mail:  sdandapat@computing.dcu.ie, biswas.priyanka@gmail.com, monojitc@microsoft.com, kalikab@microsoft.com   Abstract 
Alternative paths to linguistic annotation, such as those utilizing games or exploiting the web users, are becoming popular in recent times owing to their very high benefit-to-cost ratios. In this paper, however, we report a case study on POS annotation for Bangla and Hindi, where we observe that reliable linguis-tic annotation requires not only expert anno-tators, but also a great deal of supervision. For our hierarchical POS annotation scheme, we find that close supervision and training is necessary at every level of the hierarchy, or equivalently, complexity of the tagset. Never-theless, an intelligent annotation tool can sig-nificantly accelerate the annotation process and increase the inter-annotator agreement for both expert and non-expert annotators. These findings lead us to believe that reliable annotation requiring deep linguistic knowl-edge (e.g., POS, chunking, Treebank, seman-tic role labeling) requires expertise and su-pervision. The focus, therefore, should be on design and development of appropriate anno-tation tools equipped with machine learning based predictive modules that can signifi-cantly boost the productivity of the annota-tors.1  1 Introduction Access to reliable annotated data is the first hur-dle encountered in most NLP tasks be it at the level of Parts-of-Speech (POS) tagging or a more complex discourse level annotation. The per-formance of the machine learning approaches which have become de rigueur for most NLP tasks are dependent on accurately annotated large datasets. Creation of such databases is, hence, a highly resource intensive task both in terms of time and expertise.                                                  1 This work has been done during the authors? internship at Microsoft Research Lab India. 
While the cost of an annotation task can be characterized by the number of man-hours and the level of expertise required, the productivity or the benefit can be measured in terms of the reliability and usability of the end-product, i.e., the annotated dataset. It is thus no surprise that considerable effort has gone into developing techniques and tools that can effectively boost the benefit-to-cost ratio of the annotation proc-ess. These include, but are not limited to: (a) exploiting the reach of the web to reduce the effort required for annotation (see, e.g., Snow et al (2008) and references therein) (b) smartly designed User Interfaces for aiding the annotators (see, e.g., Eryigit (2007); Koutsis et al (2007); Reidsma et al (2004)) (c) using supervised learning to bootstrap a small annotated dataset to automatically la-bel a larger corpus and getting it corrected by human annotators (see, e.g., Tomanek et al (2007); Wu et al (2007)) (d) Active Learning (Ringger et al 2007) where only those data-points which are directly re-levant for training are presented for manual annotation. Methods exploiting the web-users for linguis-tic annotation are particularly popular these days, presumably because of the success of the ESP-Game (von Ahn and Dabbish, 2004) and its suc-cessors in image annotation. A more recent study by (Snow et al, 2008) shows that annotated data obtained from non-expert anonymous web-users is as good as those obtained from experts. How-ever, unlike the game model, here the task is dis-tributed among non-experts through an Internet portal such as Amazon Mechanical Turk, and the users are paid for their annotations.  This might lead to an impression that the ex-pert knowledge is dispensable for NLP annota-tion tasks. However, while these approaches may work for more simple tasks like those described in (Snow et al, 2008), most NLP related annota-tion tasks such as POS tagging, chunking, se-mantic role labeling, Treebank annotation and 
10
discourse level tagging, require expertise in the relevant linguistic area. In this work, we present a case study of POS annotation in Bangla and Hindi using a hierarchical tagset, where we ob-serve that reliable linguistic annotation requires not only expert annotators, but also a great deal of supervision. A generic user interface for facili-tating the task of hierarchical word level linguis-tic annotation was designed and experiments conducted to measure the inter-annotator agreement (IA) and annotation time. It is ob-served that the tool can significantly accelerate the annotation process and increase the IA. The productivity of the annotation process is further enhanced through bootstrapping, whereby a little amount of manually annotated data is used to train an automatic POS tagger. The annotators are then asked to edit the data already tagged by the automatic tagger using an appropriate user interface.      However, the most significant observation to emerge from these experiments is that irrespec-tive of the complexity of the annotation task (see Sec. 2 for definition), language, design of the user interface and the accuracy of the automatic POS tagger used during bootstrapping, the pro-ductivity and reliability of the expert annotators working under close supervision of the dataset designer is higher than that of non-experts or those working without expert-supervision. This leads us to believe that among the four aforemen-tioned approaches for improving the benefit-to-cost ratio of the annotation tasks, solution (a) does not seem to be the right choice for involved linguistic annotations; rather, approaches (b), (c) and (d) show more promise. The paper is organized as follows: Section 2 provides a brief introduction to IL-POST ? a hi-erarchical POS Tag framework for Indian Lan-guages which is used for defining the specific annotation tasks used for the experiments. The design and features of the data annotation tool are described in Section 3. Section 4 presents the experiments conducted for POS labeling task of Bangla and Hindi while the results of these ex-periments are discussed in Section 5. The con-clusions are presented in Section 6. 2 IL-POST IL-POST is a POS-tagset framework for Indian Languages, which has been designed to cover the morphosyntactic details of Indian Languages (Baskaran et al 2008).  It  supports  a  three-level 
 Figure 1: A schematic of IL-POST framework  hierarchy of Categories, Types  and  Attributes that provides a systematic method to annotate language specific categories without disregarding the shared traits of the Indian languages. This allows the framework to offer flexibility, cross-linguistic compatibility and reusability across several languages and applications. An important consequence of its hierarchical structure and decomposable tags is that it allows users to spec-ify the morpho-syntactic information applicable at the desired granularity according to the spe-cific language and task. The complete framework supports 11 categories at the top level with 32 types at the second level to represent the main POS categories and their sub-types. Further, 18 morphological attributes or features are associ-ated with the types. The framework can thus, be used to derive a flat tagset of only 11 categories or a complex three level tagset of several thou-sand tags depending on the language and/or ap-plication. Figure 1 shows a schematic of the IL-POST framework. The current framework has been used to derive maximally specified tagsets for Bangla and Hindi (see Baskaran et al (2008) for the descriptions of the tagsets), which have been used to design the experiments presented in this paper. 3 Annotation Tool  Though a number of POS annotation tools are available none are readily suitable for hierarchi-cal tagging. The tools from other domains (like discourse annotation, for example) that use hier-archical tagsets require considerable customiza-tion for the task described here. Thus, in order to facilitate the task of word-level linguistic annota-tion for complex tagsets we developed a generic annotation tool. The annotation tool can be cus-tomized to work for any tagset that has up to 
11
 Figure 2: The basic Interface Window and Controls. See the text for details.  three levels of hierarchy and for any word level linguistic annotation task, such as Named Entity annotation and Chunk boundary labeling. In this section we describe the design of the user inter-face and other features of the annotation tool. 3.1 Interface Design Principles The annotation scheme followed for linguistic data creation is heavily dependent on the end-application the data will cater to. Moreover, an-notations are often performed by trained linguists who, in the Indian context, are either novice or intermittent users of computer. These observa-tions led us to adopt the following principles: (1) customizability of the interface to any word level annotation task; (2) mouse driven selection of tags for faster and less erroneous annotation; and (3) display of all possible choices at every stage of the task to reduce memorization overload.   3.2 Basic Interface Figure 2 depicts the basic interface of the annota-tion tool 3.2.1 Automatic Handling Apart from the surface controls, the interface also supports automatic selection facility that highlights the next unlabeled word that needs to be annotated. After loading the task (i.e., a sen-tence) it automatically highlights the first unla-beled word. Once a tag is assigned to the high-lighted word, the next unlabeled word is auto-matically selected. However, the automatic se-lection module can be stopped by selecting a par-ticular word through a mouse click. 3.2.2 Handling Hierarchical Annotation The first two levels of the IL-POST hierarchy are displayed (on a right mouse click) as a two level 
context menu. This is illustrated in Fig. 3(a). On selection of the category and type by left clicks, a window is dynamically generated for the as-signment of the attribute values, i.e., the third level of the hierarchy. A drop down box is asso-ciated with each attribute for selecting the appro-priate values. This is shown in Fig. 3(b). The default values for each of the attributes are set based on the frequency of occurrence of the val-ues in a general corpus. This further reduces the time of tag assignment. When the user clicks ?OK? on the attribute assignment window, the system automatically generates the tag as per the user?s selection and displays it in the Text-box just after the selected word.  3.3 Edit Mode Annotation While performing the annotation task, human annotators need to label every word of a sen-tence. Instead of annotating every word from scratch, we incorporate machine intelligence to automatically label every word in a sentence. Suppose that we have an automatic POS tag pre-diction module that does a fairly accurate job. In that case, the task of annotation would mean ed-iting the pre-assigned tags to the words. We hy-pothesize that such an editing based annotation task that incorporates some intelligence in the form of a tagger will be much faster than purely manual annotation, provided that the pre-assigned tags are ?sufficiently accurate?. Thus, human annotators only need to edit a particular word whenever machine assigns an incorrect tag making the process faster. We also make certain changes to the basic interface for facilitating easy editing.  In particular, when the corpus is loaded using the interface, the predicted tags are shown for each word and the first category-type is high-lighted automatically. The user can navigate 
12
                                                       (a)                                 (b)  Figure 3: Annotation at a) Category-Type level, b) Attribute level  to the next or pervious editable positions (Cate-gory-Type or Attributes) by using the Shift and the Ctrl keys respectively. The user may edit a particular pre-assigned tag by making a right mouse click and choosing from the usual context menus or attribute editing window.  The user also has the provision to choose an editable loca-tion by left mouse-click. 3.3.1 Automatic POS Tagger We developed a statistical POS tagger based on Cyclic Dependency Network (Toutanova et al, 2003) as an initial annotator for the Edit mode annotation. The tagger was trained for Bangla and Hindi on the data that was created during the first phase of annotation (i.e. annotation from scratch). We developed taggers for both Cate-gory+Type level (CT) and Category+Type+ At-tribute level (CTA). We also developed two ver-sions of the same tagger with high and low accu-racies for each level of the annotation by control-ling the amount of training data.  As we shall see in Sec. 4 and 5, the different versions of the tag-ger at various levels of the hierarchy and accu-racy will help us to understand the relation be-tween the Edit mode annotation, and the com-plexity of the tagset and the accuracy of the tag-ger used for initial annotation. The taggers were trained on 1457 sentences (approximately 20,000 words) for Bangla and 2366 sentences (approxi-mately 45,000 words) for Hindi. The taggers were tested on 256 sentences (~ 3,500 words) for Bangla and 591 sentences for Hindi, which are disjoint from the training corpus. The evaluation of a hierarchical tagset is non-trivial because the error in the machine tagged data with respect to the gold standard should take into account the level of the hierarchy where the mismatch be-tween the two takes place. Clearly, mismatch at the category or type level should incur a higher 
penalty than one at the level of the attributes. If for a word, there is a mismatch between the type assigned by the machine and that present in the gold standard, then it is assumed to be a full error (equivalent to 1 unit). On the other hand, if the type assigned is correct, then the error is 0.5 times the fraction of attributes that do not agree with the gold standard.  Table 1 reports the accuracies of the various taggers. Note that the attributes in IL-POST cor-respond to morphological features. Unlike Bangla, we do not have access to a morphologi-cal analyzer for Hindi to predict the attributes during the POS tagging at the CTA level. There-fore, the tagging accuracy in the CTA level for Hindi is lower than that of Bangla even though the amount of training data used in Hindi is much higher than that in Bangla.  4 Experiments The objective of the current work is to study the cognitive load associated with the task of linguis-tic annotation, more specifically, POS annota-tion. Cognitive load relates to the higher level of processing required by the working memory of an annotator when more learning is to be done in a shorter time. Hence, a higher cognitive load implies more time required for annotation and higher error rates. The time required for annota-tion can be readily measured by keeping track of the time taken by the annotators while tagging a sentence. The timer facility provided with the annotation tool helps us keep track of the annota-tion time. Measuring the error rate is slightly trickier as we do not have any ground truth (gold standard) against which we can measure the ac-curacy of the manual annotators. Therefore, we measure the IA, which should be high if the error rate is low. Details of the evaluation metrics are discussed in the next section. 
13
 Table 1: Tagging accuracy in % for Bangla and Hindi  The cognitive load of the annotation task is de-pendent on the complexity of the tagset, (un)availability of an appropriate annotation tool and bootstrapping facility. Therefore, in order to quantify the effect of these factors on the annota-tion task, annotation experiments are conducted under eight different settings. Four experiments are done for annotation at the Category+Type (CT) level. These are: ? CT-AT: without using annotation tool, i.e., using any standard text editor2. ? CT+AT: with the help of the basic anno-tation tool.  ? CT+ATL: with the help of the annota-tion tool in the edit mode, where the POS tagger used has low accuracy. ? CT+ATH: in the edit mode where the POS tagger used has a high accuracy. Similarly, four experiments are conducted at the Category+Type+Attribute (CTA) level, which are named following the same convention: CTA-AT, CTA+AT, CTA+ATL, CTA+ATH.  4.1 Subjects The reliability of annotation is dependent on the expertise of the annotators. In order to analyze the effect of annotator expertise, we chose sub-jects with various levels of expertise and pro-vided them different amount of training and su-pervision during the annotation experiments.  The experiments for Bangla have been con-ducted with 4 users (henceforth referred to as B1, B2, B3 and B4), all of whom are trained linguists having at least a post-graduate degree in linguis-tics. Two of them, namely B1 and B2, were pro-vided rigorous training in-house before the anno-tation task. During the training phase the tagset and the annotation guidelines were explained to them in detail. This was followed by 3-4 rounds of trial annotation tasks, during which the anno-                                                2 The experiments without the tool were also conducted using the basic interface, where the annotator has to type in the tag strings; the function of the tool here is limited to loading the corpus and the timer.  
tators were asked to annotate a set of 10-15 sen-tences and they were given feedback regarding the correctness of their annotations as judged by other human experts. For B1 and B2, the experi-ments were conducted in-house and under close supervision of the designers of the tagset and the tool, as well as a senior research linguist.   The other two annotators, B3 and B4, were provided with the data, the required annotation tools and the experimental setup, annotation guidelines and the tool usage guidelines, and the task were described in another document. Thus, the annotators were self-trained as far as the tool usage and the annotation scheme were con-cerned. They were asked to return the annotated data (and the time logs that are automatically generated during the annotation) at the end of all the experiments. This situation is similar to that of linguistic annotation using the Internet users, where the annotators are self-trained and work under no supervision. However, unlike ordinary Internet users, our subjects are trained linguists.    Experiments in Hindi were conducted with two users (henceforth referred to as H1 and H2), both of whom are trained linguists. As in the case of B1 and B2, the experiments were conducted under close supervision of a senior linguist, but H1 and H2 were self-trained in the use of the tool.   The tasks were randomized to minimize the effect of familiarity with the task as well as the tool. 4.2 Data The annotators were asked to annotate approxi-mately 2000 words for CT+AT and CTA+AT experiments and around 1000 words for CT-AT and CTA-AT experiments. The edit mode ex-periments (CT+ATL, CT+ATH, CTA+ATL and CTA+ATH) have been conducted on approxi-mately 1000 words. The amount of data was de-cided based primarily on the time constraints for the experiments. For all the experiments in a par-ticular language, 25-35% of the data was com-mon between every pair of annotators. These common sets have been used to measure the IA. However, there was no single complete set common to all the annotators. In order to meas-ure the influence of the pre-assigned labels on the judgment of the annotators, some amount of data was kept common between CTA+AT and CTA+ATL/H experiments for every annotator. 
CT CTA Language High Low High Low Bangla 81.43 66.73 76.98 64.52 Hindi 87.66 67.85 69.53 57.90 
14
  
 (a)        (b) Figure 4: Mean annotation time (in sec per word) for different users at (a) CT and (b) CTA levels  Mean Time (in Sec) Level -AT +AT +ATL +ATH CT 6.3 5.0 (20.7) 2.6 (59.4) 2.5 (59.8) CTA 15.2 10.9 (28.1) 5.2 (66.0) 4.8 (68.3) Table 2: Mean annotation time for Bangla ex-periments (%reduction in time with respect to ?AT is given within parentheses). 5 Analysis of Results In this section we report the observations from our annotation experiments and analyze those to identify trends and their underlying reasons.  5.1 Mean Annotation Time We measure the mean annotation time by com-puting the average time required to annotate a word for a sentence and then average it over all sentences for a given experiment by a specific annotator. Fig. 4 shows the mean annotation time (in seconds per word) for the different experi-ments by the different annotators. It is evident that complex annotation task (i.e., CTA level) takes much more time compared to a simple one (i.e., CT level). We also note that the tool effec-tively reduces the annotation time for most of the subjects. There is some variation in time (for ex-ample, B3) where the subject took longer to get accustomed to the annotation tool. As expected, the annotation process is accelerated by boot-strapping. In fact, the higher the accuracy of the automatic tagger, the faster is the annotation. Table 2 presents the mean time averaged over the six subjects for the 8 experiments in Bangla along with the %reduction in the time with re-spect to the case when no tool is present (i.e., ?-AT?). We observe that (a) the tool is more effec-tive for complex annotation, (b) on average, an-notation at the CTA level take twice the time of their CT level counterparts, and (c) bootstrapping   
IA (in %) Level -AT +AT +ATL +ATH CT 68.9 79.2 (15.0) 77.2 (12.2) 89.9 (30.6) CTA 51.4 72.5 (41.0) 79.3 (54.2) 83.4 (62.1) Table 3: Average IA for Bangla experiments (%increase in IA with respect to ?AT is given within parentheses).  can significantly accelerate the annotation proc-ess.  We also note that experts working under close supervision (B1 and B2) are in general faster than self-trained annotators (B3 and B4). 5.2 Inter-annotator Agreement Inter-annotator agreement (IA) is a very good indicator of the reliability of an annotated data. A high IA denotes that at least two annotators agree on the annotation and therefore, the probability that the annotation is erroneous is very small. There are various ways to quantify the IA rang-ing from a very simple percentage agreement to more complex measures such as the kappa statis-tics (Cohen, 1960; Geertzen and Bunt, 2006). For a hierarchical tagset the measurement of IA is non-trivial because the extent of disagreement should take into account the level of the hierar-chy where the mismatch between two annotators takes place. Here we use percentage agreement which takes into consideration the level of hier-archy where the disagreement between the two annotators takes place. For example, the differ-ence in IA at the category level between say, a Noun and a Nominal Modifier, versus the differ-ence at the number attribute level between singu-lar and plural. The extent of agreement for each of the tags is computed in the same way as we have evaluated our POS tagger (Sec.3.2.1). We have also measured the Cohen?s Kappa (Cohen, 1960) for the CT level experiments. Its behavior is similar to that of percentage agreement. 
15
 (a)      (b) Figure 5: Pair-wise IA (in %) at (a) CT and (b) CTA levels  Fig. 5 shows the pair-wise percentage IA for the eight experiments and Table 3 summarizes the %increase in IA due to the use of tool/bootstrapping with respect to the ?-AT? ex-periments at CT and CTA levels. We observe the following basic trends: (a) IA is consistently lower for a complex annotation (CTA) task than a simpler one (CT),  (b)  use  of  annotation  tool  helps in improvement of the IA, more so for the CTA level experiments, (c) bootstrapping helps in further improvement in IA, especially when the POS tagger used has high accuracy, and (d) IA between the trained subjects (B1 and B2) is always higher than the other pairs. IA is dependent on several factors such as the ambiguity in the tagset, inherently ambiguous cases, underspecified or ambiguously specified annotation guidelines, and errors due to careless-ness of the annotator. However, manual inspec-tion reveals that the factor which results in very low IA in ?-AT? case that the tool helps improve significantly is the typographical errors made by the annotators while using a standard text editor for annotation (e.g., NC mistyped as MC). This is more prominent in the CTA level experiments, where typing the string of attributes in the wrong order or missing out on some attributes, which are very common when annotation tool is not used, lead to a very low IA. Thus, memorization has a huge overload during the annotation proc-ess, especially for complex annotation schemes, which the annotation tool can effectively handle. In fact, more than 50% errors in CTA level are due to the above phenomenon. The analysis of other factors that lower the IA is discussed in Sec. 5.4. We would like to emphasize the fact that al-though the absolute time difference between the trained and un-trained users reduces when the  tool and/or bootstrapping is used, the IA does not decrease significantly in case of the untrained users for the complex annotation task.   
 Subjects Level Tagger B1 B2 B3 B4 Low 89.6 89.8 74.2 81.8 CT High 90.8 90.1 64.8 77.8 Low 85.4 85.1 68.2 76.1 CTA High 86.4 85.4 59.1 73.4 Table 4: Percentage agreement between the edit and the normal mode annotations (for Bangla).   5.3 Machine Influence We have seen that the IA increases in the edit mode experiments. This apparent positive result might be an unacceptable artifact of machine influence, which is to say that the annotators, whenever in confusion, might blindly agree with the pre-assigned labels.  In order to understand the influence of the pre-assigned labels on the annotators, we calculate the percentage agree-ment for a subject between the data annotated from scratch using the tool (+AT) and that in the edit mode (+ATL and +ATH). The results are summarized in Table 4.  The low agreement between the data anno-tated under the two modes for the untrained an-notators (B3 and B4) shows that there is a strong influence of pre-assigned labels for these users. Untrained annotators have lower agreement while using a high accuracy initial POS tagger compared to the case when a low accuracy POS tagger is used. This is because the high accuracy tagger assigns an erroneous label mainly for the highly ambiguous cases where a larger context is required to disambiguate. These cases are also difficult for human annotators to verify and un-trained annotators tend to miss these cases during edit mode experiments. The trained annotators show a consistent performance. Nevertheless, there is still some influence of the pre-assigned labels. 
16
5.4 Error Patterns In order to understand the reasons of disagree-ment between the annotators, we analyze the confusion matrix for different pairs of users for the various experimental scenarios. We observe that the causes of disagreement are primarily of three kinds: (1) unspecified and/or ambiguous guidelines, (2) ignorance about the guidelines, and (3) inherent ambiguities present in the sen-tences. We have found that a large number of the errors are due to type (1). For example, in attrib-ute level annotation, for every attribute two spe-cial values are ?0? (denotes ?not applicable for the particular lexical item?) and ?x? (denotes ?undecided or doubtful to the annotator?). How-ever, we find that both trained and untrained an-notators have their own distinct patterns of as-signing ?0? or ?x?. Later we made this point clearer with examples and enumerated possible cases of ?0? and ?x? tags. This was very helpful in improving the IA.   A major portion of the errors made by the un-trained users are due to type (2).  For example, it was clearly mentioned in the annotation guide-lines that if a borrowed/foreign word is written in the native script, then it has to be tagged accord-ing to its normal morpho-syntactic function in the sentence. However, if a word is typed in for-eign script, then it has to be tagged as a foreign word.  However, none of the untrained annota-tors adhered to these rules strictly.  Finally, there are instances which are inher-ently ambiguous. For example, in noun-noun compounds, a common confusion is whether the first noun is to be tagged as a nouns or an adjec-tive. These kinds of confusions are evenly dis-tributed over all the users and at every level of annotation. One important fact that we arrive at through the analysis of the confusion matrices is that the trained annotators working under close supervi-sion have few and consistent error patterns over all the experiments, whereas the untrained anno-tators exhibit no consistent and clearly definable error patterns. This is not surprising because the training helps the annotators to understand the task and the annotation scheme clearly; on the other hand, constant supervision helps clarifying doubts arising during annotation.  6 Conclusion In this paper we reported our observations for POS annotation experiments for Bangla and Hindi using the IL-POST annotation scheme un-
der various scenarios. Experiments in Tamil and Sanskrit are planned in the future. We argue that the observations from the various experiments make a case for the need of training and supervision for the annotators as well as the use of appropriate annotation interfaces and techniques such as bootstrapping. The results are indicative in nature and need to be validated with larger number of annotators. We summarize our salient contributions/conclusions: ? The generic tool described here for complex and hierarchical word level annotation is ef-fective in accelerating the annotation task as well as improving the IA. Thus, the tool helps reducing the cognitive load associated with annotation. ? Bootstrapping, whereby POS tags are pre-assigned by an automatic tagger and human annotators are required to edit the incorrect labels, further accelerates the task, at the risk of slight influence of the pre-assigned labels. ? Although with the help of the tool and tech-niques such as bootstrapping we are able to bring down the time required by untrained annotators to the level of their trained coun-terparts, the IA, and hence the reliability of the annotated data for the former is always poorer. Hence, training and supervision is very important for reliable linguistic annota-tion. We would like to emphasize the last point be-cause recently it is being argued that Internet and other game based techniques can be effectively used for gathering annotated data for NLP. While this may be suitable for certain types of annota-tions, such as word sense, lexical similarity or affect (see Snow et al (2008) for details), we argue that many mainstream linguistic annotation tasks such as POS, chunk, semantic roles and Treebank annotations call for expertise, training and close supervision. We believe that there is no easy way out to this kind of complex linguistic annotations, though smartly designed annotation interfaces and methods such as bootstrapping and active learning can significantly improve the productivity and reliability, and therefore, should be explored and exploited in future. Acknowledgements We would like to thank the annotators Dripta Piplai, Anumitra Ghosh Dastidar, Narayan Choudhary and Maansi Sharma. We would also like to thank Prof. Girish Nath Jha for his help in conducting the experiments. 
17
References  S. Baskaran, K. Bali, M. Choudhury, T. Bhattacharya, P. Bhattacharyya, G. N. Jha, S. Rajendran, K. Sa-ravanan, L. Sobha and K.V. Subbarao. 2008. A Common Parts-of-Speech Tagset Framework for Indian Languages. In Proc. of LREC 2008. J.  Cohen. 1960. A coefficient of agreement for nomi-nal scales. Educational and Psychological Meas-urement, 20 (1):37-46 J. Geertzen, and H. Bunt. 2006.  Measuring annotator agreement in a complex hierarchical dialogue act annotation scheme. In Proc. of the Workshop on Discourse and Dialogue, ACL 2006, pp. 126-133. G. Eryigit. 2007. ITU Treebank annotation tool. In Proc. of Linguistic Annotation Workshop, ACL 2007, pp. 117-120. I. Koutsis, G. Markopoulos, and G. Mikros. 2007. Episimiotis: A Multilingual Tool for Hierarchical Annotation of Texts. In Corpus Linguistics, 2007. D. Reidsma, N. Jovanovi, and D. Hofs. 2004. Design-ing annotation tools based on the properties of an-notation problems. Report, Centre for Telematics and Information Technology, 2004. E. Ringger, P. McClanahan, R. Haertel, G. Busby, M. Carmen, J. Carroll, K. Seppi, and D. Lonsdale. 2007. Active Learning for Part-of-Speech Tagging: Accelerating Corpus Annotation. In Proc. of Lin-guistic Annotation Workshop, ACL 2007, pp.  101-108. R. Snow, B. O?Connor, D. Jurafsky and A. Y. Ng. 2008. Cheap and Fast ? But is it Good? Evaluat-ing Non-Expert Annotations for Natural Language Tasks. In Proc of EMNLP-08 K. Tomanek, J. Wermter, and U. Hahn. 2007. Effi-cient annotation with the Jena ANotation Environ-ment (JANE). In Proc. of Linguistic Annotation Workshop, ACL 2007, pp.  9-16. L. von Ahn and L. Dabbish. 2004. Labeling Images with a Computer Game. In ACM Conference on Human Factors in Computing Systems, CHI 2004. Y. Wu, P. Jin, T. Guo and S. Yu. 2007. Building Chi-nese sense annotated corpus with the help of soft-ware tools. In Proc. of Linguistic Annotation Workshop, ACL 2007, pp. 125-131.  
18
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 128?135,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Analysis and Synthesis of the Distribution of Consonants over Languages:
A Complex Network Approach
Monojit Choudhury and Animesh Mukherjee and Anupam Basu and Niloy Ganguly
Department of Computer Science and Engineering,
Indian Institute of Technology Kharagpur
{monojit,animeshm,anupam,niloy}@cse.iitkgp.ernet.in
Abstract
Cross-linguistic similarities are reflected
by the speech sound systems of languages
all over the world. In this work we try
to model such similarities observed in the
consonant inventories, through a complex
bipartite network. We present a systematic
study of some of the appealing features of
these inventories with the help of the bi-
partite network. An important observation
is that the occurrence of consonants fol-
lows a two regime power law distribution.
We find that the consonant inventory size
distribution together with the principle of
preferential attachment are the main rea-
sons behind the emergence of such a two
regime behavior. In order to further sup-
port our explanation we present a synthe-
sis model for this network based on the
general theory of preferential attachment.
1 Introduction
Sound systems of the world?s languages show re-
markable regularities. Any arbitrary set of conso-
nants and vowels does not make up the sound sys-
tem of a particular language. Several lines of re-
search suggest that cross-linguistic similarities get
reflected in the consonant and vowel inventories
of the languages all over the world (Greenberg,
1966; Pinker, 1994; Ladefoged and Maddieson,
1996). Previously it has been argued that these
similarities are the results of certain general prin-
ciples like maximal perceptual contrast (Lindblom
and Maddieson, 1988), feature economy (Mar-
tinet, 1968; Boersma, 1998; Clements, 2004) and
robustness (Jakobson and Halle, 1956; Chomsky
and Halle, 1968). Maximal perceptual contrast
between the phonemes of a language is desir-
able for proper perception in a noisy environment.
In fact the organization of the vowel inventories
across languages has been satisfactorily explained
in terms of the single principle of maximal percep-
tual contrast (Jakobson, 1941; Wang, 1968).
There have been several attempts to reason
the observed patterns in consonant inventories
since 1930s (Trubetzkoy, 1969/1939; Lindblom
and Maddieson, 1988; Boersma, 1998; Flemming,
2002; Clements, 2004), but unlike the case of vow-
els, the structure of consonant inventories lacks a
complete and holistic explanation (de Boer, 2000).
Most of the works are confined to certain indi-
vidual principles (Abry, 2003; Hinskens and Wei-
jer, 2003) rather than formulating a general the-
ory describing the structural patterns and/or their
stability. Thus, the structure of the consonant in-
ventories continues to be a complex jigsaw puzzle,
though the parts and pieces are known.
In this work we attempt to represent the cross-
linguistic similarities that exist in the consonant
inventories of the world?s languages through a
bipartite network named PlaNet (the Phoneme
Language Network). PlaNet has two different sets
of nodes, one labeled by the languages while the
other labeled by the consonants. Edges run be-
tween these two sets depending on whether or not
a particular consonant occurs in a particular lan-
guage. This representation is motivated by similar
modeling of certain complex phenomena observed
in nature and society, such as,
? Movie-actor network, where movies and ac-
tors constitute the two partitions and an edge
between them signifies that a particular actor
acted in a particular movie (Ramasco et al,
2004).
128
? Article-author network, where the edges de-
note which person has authored which arti-
cles (Newman, 2001b).
? Metabolic network of organisms, where the
corresponding partitions are chemical com-
pounds and metabolic reactions. Edges run
between partitions depending on whether a
particular compound is a substrate or result
of a reaction (Jeong et al, 2000).
Modeling of complex systems as networks has
proved to be a comprehensive and emerging way
of capturing the underlying generating mecha-
nism of such systems (for a review on complex
networks and their generation see (Albert and
Baraba?si, 2002; Newman, 2003)). There have
been some attempts as well to model the intri-
cacies of human languages through complex net-
works. Word networks based on synonymy (Yook
et al, 2001b), co-occurrence (Cancho et al, 2001),
and phonemic edit-distance (Vitevitch, 2005) are
examples of such attempts. The present work also
uses the concept of complex networks to develop
a platform for a holistic analysis as well as synthe-
sis of the distribution of the consonants across the
languages.
In the current work, with the help of PlaNet we
provide a systematic study of certain interesting
features of the consonant inventories. An impor-
tant property that we observe is the two regime
power law degree distribution1 of the nodes la-
beled by the consonants. We try to explain this
property in the light of the size of the consonant
inventories coupled with the principle of preferen-
tial attachment (Baraba?si and Albert, 1999). Next
we present a simplified mathematical model ex-
plaining the emergence of the two regimes. In or-
der to support our analytical explanations, we also
provide a synthesis model for PlaNet.
The rest of the paper is organized into five sec-
tions. In section 2 we formally define PlaNet, out-
line its construction procedure and present some
studies on its degree distribution. We dedicate sec-
tion 3 to state and explain the inferences that can
be drawn from the degree distribution studies of
PlaNet. In section 4 we provide a simplified the-
oretical explanation of the analytical results ob-
1Two regime power law distributions have also been
observed in syntactic networks of words (Cancho et al,
2001), network of mathematics collaborators (Grossman et
al., 1995), and language diversity over countries (Gomes et
al., 1999).
Figure 1: Illustration of the nodes and edges of
PlaNet
tained. In section 5 we present a synthesis model
for PlaNet to hold up the inferences that we draw
in section 3. Finally we conclude in section 6 by
summarizing our contributions, pointing out some
of the implications of the current work and indi-
cating the possible future directions.
2 PlaNet: The Phoneme-Language
Network
We define the network of consonants and lan-
guages, PlaNet, as a bipartite graph represented as
G = ?VL, VC , E? where VL is the set of nodes la-
beled by the languages and VC is the set of nodes
labeled by the consonants. E is the set of edges
that run between VL and VC . There is an edge e ?
E between two nodes vl ? VL and vc ? VC if and
only if the consonant c occurs in the language l.
Figure 1 illustrates the nodes and edges of PlaNet.
2.1 Construction of PlaNet
Many typological studies (Lindblom and Mad-
dieson, 1988; Ladefoged and Maddieson, 1996;
Hinskens and Weijer, 2003) of segmental inven-
tories have been carried out in past on the UCLA
Phonological Segment Inventory Database (UP-
SID) (Maddieson, 1984). UPSID initially had 317
languages and was later extended to include 451
languages covering all the major language families
of the world. In this work we have used the older
version of UPSID comprising of 317 languages
and 541 consonants (henceforth UPSID317), for
constructing PlaNet. Consequently, there are 317
elements (nodes) in the set VL and 541 elements
129
(nodes) in the set VC . The number of elements
(edges) in the set E as computed from PlaNet is
7022. At this point it is important to mention that
in order to avoid any confusion in the construc-
tion of PlaNet we have appropriately filtered out
the anomalous and the ambiguous segments (Mad-
dieson, 1984) from it. We have completely ig-
nored the anomalous segments from the data set
(since the existence of such segments is doubtful),
and included the ambiguous ones as separate seg-
ments because there are no descriptive sources ex-
plaining how such ambiguities might be resolved.
A similar approach has also been described in Per-
icliev and Valde?s-Pe?rez (2002).
2.2 Degree Distribution of PlaNet
The degree of a node u, denoted by ku is defined as
the number of edges connected to u. The term de-
gree distribution is used to denote the way degrees
(ku) are distributed over the nodes (u). The de-
gree distribution studies find a lot of importance in
understanding the complex topology of any large
network, which is very difficult to visualize oth-
erwise. Since PlaNet is bipartite in nature it has
two degree distribution curves one corresponding
to the nodes in the set VL and the other corre-
sponding to the nodes in the set VC .
Degree distribution of the nodes in VL: Fig-
ure 2 shows the degree distribution of the nodes
in VL where the x-axis denotes the degree of each
node expressed as a fraction of the maximum de-
gree and the y-axis denotes the number of nodes
having a given degree expressed as a fraction of
the total number of nodes in VL .
It is evident from Figure 2 that the number of
consonants appearing in different languages fol-
low a ?-distribution 2 (see (Bulmer, 1979) for ref-
erence). The figure shows an asymmetric right
skewed distribution with the values of ? and ?
equal to 7.06 and 47.64 (obtained using maximum
likelihood estimation method) respectively. The
asymmetry points to the fact that languages usu-
ally tend to have smaller consonant inventory size,
2A random variable is said to have a ?-distribution with
parameters ?> 0 and ? > 0 if and only if its probability mass
function is given by
f(x) =
?(?+ ?)
?(?)?(?)
x??1(1 ? x)??1
for 0 < x < 1 and f(x) = 0 otherwise. ?(?) is the Euler?s
gamma function.
Figure 2: Degree distribution of PlaNet for the set
VL. The figure in the inner box is a magnified
version of a portion of the original figure.
the best value being somewhere between 10 and
30. The distribution peaks roughly at 21 indicating
that majority of the languages in UPSID317 have a
consonant inventory size of around 21 consonants.
Degree distribution of the nodes in VC: Fig-
ure 3 illustrates two different types of degree dis-
tribution plots for the nodes in VC ; Figure 3(a)
corresponding to the rank, i.e., the sorted order of
degrees, (x-axis) versus degree (y-axis) and Fig-
ure 3(b) corresponding to the degree (k) (x-axis)
versus Pk (y-axis) where Pk is the fraction of
nodes having degree greater than or equal to k.
Figure 3 clearly shows that both the curves have
two distinct regimes and the distribution is scale-
free. Regime 1 in Figure 3(a) consists of 21 con-
sonants which have a very high frequency (i.e.,
the degree k) of occurrence. Regime 2 of Fig-
ure 3(b) also correspond to these 21 consonants.
On the other hand Regime 2 of Figure 3(a) as well
as Regime 1 of Figure 3(b) comprises of the rest
of the consonants. The point marked as x in both
the figures indicates the breakpoint. Each of the
regime in both Figure 3(a) and (b) exhibit a power
law of the form
y = Ax??
In Figure 3(a) y represents the degree k of a node
corresponding to its rank x whereas in Figure 3(b)
y corresponds to Pk and x, the degree k. The val-
ues of the parameters A and ?, for Regime 1 and
Regime 2 in both the figures, as computed by the
least square error method, are shown in Table 1.
130
Regime Figure 3(a) Figure 3(b)
Regime 1 A = 368.70 ? = 0.4 A = 1.040 ? = 0.71
Regime 2 A = 12456.5 ? = 1.54 A = 2326.2 ? = 2.36
Table 1: The values of the parameters A and ?
Figure 3: Degree distribution of PlaNet for the set
VC in a log-log scale
It becomes necessary to mention here that such
power law distributions, known variously as Zipf?s
law (Zipf, 1949), are also observed in an extra-
ordinarily diverse range of phenomena including
the frequency of the use of words in human lan-
guage (Zipf, 1949), the number of papers scien-
tists write (Lotka, 1926), the number of hits on
web pages (Adamic and Huberman, 2000) and so
on. Thus our inferences, detailed out in the next
section, mainly centers around this power law be-
havior.
3 Inferences Drawn from the Analysis of
PlaNet
In most of the networked systems like the society,
the Internet, the World Wide Web, and many oth-
ers, power law degree distribution emerges for the
phenomenon of preferential attachment, i.e., when
?the rich get richer? (Simon, 1955). With refer-
ence to PlaNet this preferential attachment can be
interpreted as the tendency of a language to choose
a consonant that has been already chosen by a
large number of other languages. We posit that it is
this preferential property of languages that results
in the power law degree distributions observed in
Figure 3(a) and (b).
Nevertheless there is one question that still re-
mains unanswered. Whereas the power law distri-
bution is well understood, the reason for the two
distinct regimes (with a sharp break) still remains
unexplored. We hypothesize that,
Hypothesis The typical distribution of the conso-
nant inventory size over languages coupled with
the principle of preferential attachment enforces
the two distinct regimes to appear in the power
law curves.
As the average consonant inventory size in
UPSID317 is 21, so following the principle of
preferential attachment, on an average, the first
21 most frequent consonants are much more pre-
ferred than the rest. Consequently, the nature of
the frequency distribution for the highly frequent
consonants is different from the less frequent ones,
and hence there is a transition from Regime 1 to
Regime 2 in the Figure 3(a) and (b).
Support Experiment: In order to establish that
the consonant inventory size plays an important
role in giving rise to the two regimes discussed
above we present a support experiment in which
we try to observe whether the breakpoint x shifts
as we shift the average consonant inventory size.
Experiment: In order to shift the average con-
sonant inventory size from 21 to 25, 30 and 38
we neglected the contribution of the languages
with consonant inventory size less than n where
n is 15, 20 and 25 respectively and subsequently
recorded the degree distributions obtained each
time. We did not carry out our experiments for
average consonant inventory size more than 38 be-
cause the number of such languages are very rare
in UPSID317.
Observations: Figure 4 shows the effect of this
shifting of the average consonant inventory size on
the rank versus degree distribution curves. Table 2
presents the results observed from these curves
with the left column indicating the average inven-
tory size and the right column the breakpoint x.
131
Figure 4: Degree distributions at different average
consonant inventory sizes
Avg. consonant inv. size Transition
25 25
30 30
38 37
Table 2: The transition points for different average
consonant inventory size
The table clearly indicates that the transition oc-
curs at values corresponding to the average conso-
nant inventory size in each of the three cases.
Inferences: It is quite evident from our observa-
tions that the breakpoint x has a strong correlation
with the average consonant inventory size, which
therefore plays a key role in the emergence of the
two regime degree distribution curves.
In the next section we provide a simplistic math-
ematical model for explaining the two regime
power law with a breakpoint corresponding to the
average consonant inventory size.
4 Theoretical Explanation for the Two
Regimes
Let us assume that the inventory of all the lan-
guages comprises of 21 consonants. We further as-
sume that the consonants are arranged in their hier-
archy of preference. A language traverses the hier-
archy of consonants and at every step decides with
a probability p to choose the current consonant. It
stops as soon as it has chosen all the 21 conso-
nants. Since languages must traverse through the
first 21 consonants regardless of whether the pre-
vious consonants are chosen or not, the probability
of choosing any one of these 21 consonants must
be p. But the case is different for the 22nd conso-
nant, which is chosen by a language if it has pre-
viously chosen zero, one, two, or at most 20, but
not all of the first 21 consonants. Therefore, the
probability of the 22nd consonant being chosen is,
P (22) = p
20?
i=0
(
21
i
)
pi(1? p)21?i
where (
21
i
)
pi(1? p)21?i
denotes the probability of choosing i consonants
from the first 21. In general the probability of
choosing the n+1th consonant from the hierarchy
is given by,
P (n+ 1) = p
20?
i=0
(
n
i
)
pi(1? p)n?i
Figure 5 shows the plot of the function P (n) for
various values of p which are 0.99, 0.95, 0.9, 0.85,
0.75 and 0.7 respectively in log-log scale. All the
curves, for different values of p, have a nature sim-
ilar to that of the degree distribution plot we ob-
tained for PlaNet. This is indicative of the fact that
languages choose consonants from the hierarchy
with a probability function comparable to P (n).
Owing to the simplified assumption that all
the languages have only 21 consonants, the first
regime is a straight line; however we believe a
more rigorous mathematical model can be built
taking into consideration the ?-distribution rather
than just the mean value of the inventory size that
can explain the negative slope of the first regime.
We look forward to do the same as a part of our fu-
ture work. Rather, here we try to investigate the ef-
fect of the exact distribution of the language inven-
tory size on the nature of the degree distribution of
the consonants through a synthetic approach based
on the principle of preferential attachment, which
is described in the subsequent section.
5 The Synthesis Model based on
Preferential Attachment
Albert and Baraba?si (1999) observed that a com-
mon property of many large networks is that the
vertex connectivities follow a scale-free power
law distribution. They remarked that two generic
mechanisms can be considered to be the cause
of this observation: (i) networks expand contin-
uously by the addition of new vertices, and (ii)
new vertices attach preferentially to sites (vertices)
that are already well connected. They found that
132
Figure 5: Plot of the function P (n) in log-log
scale
a model based on these two ingredients repro-
duces the observed stationary scale-free distrib-
utions, which in turn indicates that the develop-
ment of large networks is governed by robust self-
organizing phenomena that go beyond the particu-
lars of the individual systems.
Inspired by their work and the empirical as well
as the mathematical analysis presented above, we
propose a preferential attachment model for syn-
thesizing PlaNet (PlaNetsyn henceforth) in which
the degree distribution of the nodes in VL is
known. Hence VL={L1, L2, . . ., L317} have
degrees (consonant inventory size) {k1, k2, . . .,
k317} respectively. We assume that the nodes in
the set VC are unlabeled. At each time step, a
node Lj (j = 1 to 317) from VL tries to attach itself
with a new node i ? VC to which it is not already
connected. The probability Pr(i) with which the
node Lj gets attached to i depends on the current
degree of i and is given by
Pr(i) =
ki + 
?
i??Vj
(ki? + )
where ki is the current degree of the node i, Vj
is the set of nodes in VC to which Lj is not al-
ready connected and  is the smoothing parameter
which is used to reduce bias and favor at least a
few attachments with nodes in Vj that do not have
a high Pr(i). The above process is repeated un-
til all Lj ? VL get connected to exactly kj nodes
in VC . The entire idea is summarized in Algo-
rithm 1. Figure 6 shows a partial step of the syn-
thesis process illustrated in Algorithm 1.
Simulation Results: Simulations reveal that for
PlaNetsyn the degree distribution of the nodes be-
longing to VC fit well with the analytical results
we obtained earlier in section 2. Good fits emerge
repeat
for j = 1 to 317 do
if there is a node Lj ? VL with at least
one or more consonants to be chosen
from VC then
Compute Vj = VC-V (Lj), where
V (Lj) is the set of nodes in VC to
which Lj is already connected;
end
for each node i ? Vj do
Pr(i) =
ki + 
?
i??Vj
(ki? + )
where ki is the current degree of
the node i and  is the model
parameter. Pr(i) is the
probability of connecting Lj to i.
end
Connect Lj to a node i ? Vj
following the distribution Pr(i);
end
until all languages complete their inventory
quota ;
Algorithm 1: Algorithm for synthesis of
PlaNet based on preferential attachment
Figure 6: A partial step of the synthesis process.
When the language L4 has to connect itself with
one of the nodes in the set VC it does so with the
one having the highest degree (=3) rather than with
others in order to achieve preferential attachment
which is the working principle of our algorithm
for the range 0.06 ?  ? 0.08 with the best being
at  = 0.0701. Figure 7 shows the degree k versus
133
Figure 7: Degree distribution of the nodes in
VC for both PlaNetsyn, PlaNet, and when the
model incorporates no preferential attachment; for
PlaNetsyn,  = 0.0701 and the results are averaged
over 100 simulation runs
Pk plots for  = 0.0701 averaged over 100 simula-
tion runs.
The mean error3 between the degree distribu-
tion plots of PlaNet and PlaNetsyn is 0.03 which
intuitively signifies that on an average the varia-
tion in the two curves is 3%. On the contrary, if
there were no preferential attachment incorporated
in the model (i.e., all connections were equiprob-
able) then the mean error would have been 0.35
(35% variation on an average).
6 Conclusions, Discussion and Future
Work
In this paper, we have analyzed and synthesized
the consonant inventories of the world?s languages
in terms of a complex network. We dedicated the
preceding sections essentially to,
? Represent the consonant inventories through
a bipartite network called PlaNet,
? Provide a systematic study of certain impor-
tant properties of the consonant inventories
with the help of PlaNet,
? Propose analytical explanations for the two
regime power law curves (obtained from
PlaNet) on the basis of the distribution of the
consonant inventory size over languages to-
gether with the principle of preferential at-
tachment,
3Mean error is defined as the average difference between
the ordinate pairs where the abscissas are equal.
? Provide a simplified mathematical model to
support our analytical explanations, and
? Develop a synthesis model for PlaNet based
on preferential attachment where the conso-
nant inventory size distribution is known a
priori.
We believe that the general explanation pro-
vided here for the two regime power law is a fun-
damental result, and can have a far reaching im-
pact, because two regime behavior is observed in
many other networked systems.
Until now we have been mainly dealing with the
computational aspects of the distribution of conso-
nants over the languages rather than exploring the
real world dynamics that gives rise to such a distri-
bution. An issue that draws immediate attention is
that how preferential attachment, which is a gen-
eral phenomenon associated with network evolu-
tion, can play a prime role in shaping the conso-
nant inventories of the world?s languages. The an-
swer perhaps is hidden in the fact that language is
an evolving system and its present structure is de-
termined by its past evolutionary history. Indeed
an explanation based on this evolutionary model,
with an initial disparity in the distribution of con-
sonants over languages, can be intuitively verified
as follows ? let there be a language community
of N speakers communicating among themselves
by means of only two consonants say /k/ and /g/.
If we assume that every speaker has l descendants
and language inventories are transmitted with high
fidelity, then after i generations it is expected that
the community will consist of mli /k/ speakers and
nli /g/ speakers. Now if m > n and l > 1, then for
sufficiently large i, mli  nli. Stated differently,
the /k/ speakers by far outnumbers the /g/ speak-
ers even if initially the number of /k/ speakers is
only slightly higher than that of the /g/ speakers.
This phenomenon is similar to that of preferen-
tial attachment where language communities get
attached to, i.e., select, consonants that are already
highly preferred. Nevertheless, it remains to be
seen where from such an initial disparity in the dis-
tribution of the consonants over languages might
have originated.
In this paper, we mainly dealt with the occur-
rence principles of the consonants in the invento-
ries of the world?s languages. The work can be fur-
ther extended to identify the co-occurrence likeli-
hood of the consonants in the language inventories
134
and subsequently identify the groups or commu-
nities within them. Information about such com-
munities can then help in providing an improved
insight about the organizing principles of the con-
sonant inventories.
References
C. Abry. 2003. [b]-[d]-[g] as a universal triangle as
acoustically optimal as [i]-[a]-[u]. 15th Int. Congr.
Phonetics Sciences ICPhS, 727?730.
L. A. Adamic and B. A. Huberman. 2000. The na-
ture of markets in the World Wide Web. Quarterly
Journal of Electronic Commerce 1, 512.
R. Albert and A.-L. Baraba?si. 2002. Statistical me-
chanics of complex networks. Reviews of Modern
Physics 74, 47?97.
A.-L. Baraba?si and R. Albert. 1999. Emergence of
scaling in random networks. Science 286, 509-512.
Bart de Boer. 2000. Self-Organisation in Vowel Sys-
tems. Journal of Phonetics, Elsevier.
P. Boersma. 1998. Functional Phonology. (Doctoral
thesis, University of Amsterdam), The Hague: Hol-
land Academic Graphics.
M. G. Bulmer. 1979. Principles of Statistics, Mathe-
matics.
Ferrer i Cancho and R. V. Sole?. 2001. Santa Fe work-
ing paper 01-03-016.
N. Chomsky and M. Halle. 1968. The Sound Pattern
of English, New York: Harper and Row.
N. Clements. 2004. Features and Sound Inventories.
Symposium on Phonological Theory: Representa-
tions and Architecture, CUNY.
E. Flemming. 2002. Auditory Representations in
Phonology, New York and London: Routledge.
M. A. F. Gomes, G. L. Vasconcelos, I. J. Tsang, and I.
R. Tsang. 1999. Scaling relations for diversity of
languages. Physica A, 271, 489.
J. H. Greenberg. 1966. Language Universals with Spe-
cial Reference to Feature Hierarchies, The Hague
Mouton.
J. W. Grossman and P. D. F. Ion. 1995. On a portion
of the well-known collaboration graph. Congressus
Numerantium, 108, 129-131.
F. Hinskens and J. Weijer. 2003. Patterns of segmen-
tal modification in consonant inventories: a cross-
linguistic study. Linguistics.
R. Jakobson. 1941. Kindersprache, Aphasie und allge-
meine Lautgesetze, Uppsala, Reprinted in Selected
Writings I. Mouton, The Hague, 1962, pages 328-
401.
H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai, and A.
L. Baraba?si. 2000. The large-scale organization of
metabolic networks. Nature, 406:651-654.
R. Jakobson and M. Halle. 1956. Fundamentals of
Language, The Hague: Mouton and Co.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
Worlds Languages, Oxford: Blackwell.
B. Lindblom and I. Maddieson. 1988. Phonetic Uni-
versals in Consonant Systems. In L.M. Hyman and
C.N. Li, eds., Language, Speech, and Mind, Rout-
ledge, London, 62?78.
A. J. Lotka. 1926. The frequency distribution of scien-
tific production. J. Wash. Acad. Sci. 16, 317-323.
I. Maddieson. 1984. Patterns of Sounds, Cambridge
University Press, Cambridge.
A. Martinet. 1968. Phonetics and linguistic evolu-
tion. In Bertil Malmberg (ed.), Manual of phonetics,
revised and extended edition, Amsterdam: North-
Holland Publishing Co. 464?487.
M. E. J. Newman. 2001b. Scientific collaboration net-
works. I and II. Phys. Rev., E 64.
M. E. J. Newman. 2003. The structure and function of
complex networks. SIAM Review 45, 167?256.
V. Pericliev, R. E. Valde?s-Pe?rez. 2002. Differentiating
451 languages in terms of their segment inventories.
Studia Linguistica, Blackwell Publishing.
S. Pinker. 1994. The Language Instinct, New York:
Morrowo.
Jose? J. Ramasco, S. N. Dorogovtsev, and Romualdo
Pastor-Satorras. 2004. Self-organization of collabo-
ration networks. Physical Review E, 70, 036106.
H. A. Simon. 1955. On a class of skew distribution
functions. Biometrika 42, 425-440.
N. Trubetzkoy. 1969. Principles of phonology.
(English translation of Grundzu?ge der Phonologie,
1939), Berkeley: University of California Press.
M. S. Vitevitch. 2005. Phonological neighbors in a
small world: What can graph theory tell us about
word learning? Spring 2005 Talk Series on Networks
and Complex Systems, Indiana University, Bloom-
ington.
William S.-Y. Wang. 1968. The basis of speech,
Project on Linguistic Analysis Reports, University
of California at Berkeley. Reprinted in The Learning
of Language, ed. by C. E. Reed, 1971.
S. Yook, H. Jeong and A.-L. Baraba?si. 2001b. preprint.
G. K. Zipf. 1949. Human Behaviour and the Principle
of Least Effort, Addison-Wesley, Reading, MA.
135
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 104?111,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Redundancy Ratio: An Invariant Property of the
Consonant Inventories of the World?s Languages
Animesh Mukherjee, Monojit Choudhury, Anupam Basu, Niloy Ganguly
Department of Computer Science and Engineering,
Indian Institute of Technology, Kharagpur
{animeshm,monojit,anupam,niloy}@cse.iitkgp.ernet.in
Abstract
In this paper, we put forward an information
theoretic definition of the redundancy that is
observed across the sound inventories of the
world?s languages. Through rigorous statis-
tical analysis, we find that this redundancy
is an invariant property of the consonant in-
ventories. The statistical analysis further un-
folds that the vowel inventories do not ex-
hibit any such property, which in turn points
to the fact that the organizing principles of
the vowel and the consonant inventories are
quite different in nature.
1 Introduction
Redundancy is a strikingly common phenomenon
that is observed across many natural systems. This
redundancy is present mainly to reduce the risk
of the complete loss of information that might oc-
cur due to accidental errors (Krakauer and Plotkin,
2002). Moreover, redundancy is found in every level
of granularity of a system. For instance, in biologi-
cal systems we find redundancy in the codons (Lesk,
2002), in the genes (Woollard, 2005) and as well in
the proteins (Gatlin, 1974). A linguistic system is
also not an exception. There is for example, a num-
ber of words with the same meaning (synonyms) in
almost every language of the world. Similarly, the
basic unit of language, the human speech sounds or
the phonemes, is also expected to exhibit some sort
of a redundancy in the information that it encodes.
In this work, we attempt to mathematically cap-
ture the redundancy observed across the sound
(more specifically the consonant) inventories of
the world?s languages. For this purpose, we
present an information theoretic definition of redun-
dancy, which is calculated based on the set of fea-
tures1 (Trubetzkoy, 1931) that are used to express
the consonants. An interesting observation is that
this quantitative feature-based measure of redun-
dancy is almost an invariance over the consonant
inventories of the world?s languages. The observa-
tion is important since it can shed enough light on
the organization of the consonant inventories, which
unlike the vowel inventories, lack a complete and
holistic explanation. The invariance of our measure
implies that every inventory tries to be similar in
terms of the measure, which leads us to argue that
redundancy plays a very important role in shaping
the structure of the consonant inventories. In order
to validate this argument we determine the possibil-
ity of observing such an invariance if the consonant
inventories had evolved by random chance. We find
that the redundancy observed across the randomly
generated inventories is substantially different from
their real counterparts, which leads us to conclude
that the invariance is not just ?by-chance? and the
measure that we define, indeed, largely governs the
organizing principles of the consonant inventories.
1In phonology, features are the elements, which distin-
guish one phoneme from another. The features that distinguish
the consonants can be broadly categorized into three different
classes namely the manner of articulation, the place of articu-
lation and phonation. Manner of articulation specifies how the
flow of air takes place in the vocal tract during articulation of
a consonant, whereas place of articulation specifies the active
speech organ and also the place where it acts. Phonation de-
scribes the activity regarding the vibration of the vocal cords
during the articulation of a consonant.
104
Interestingly, this redundancy, when measured for
the vowel inventories, does not exhibit any similar
invariance. This immediately reveals that the prin-
ciples that govern the formation of these two types
of inventories are quite different in nature. Such
an observation is significant since whether or not
these principles are similar/different for the two in-
ventories had been a question giving rise to peren-
nial debate among the past researchers (Trubet-
zkoy, 1969/1939; Lindblom and Maddieson, 1988;
Boersma, 1998; Clements, 2004). A possible rea-
son for the observed dichotomy in the behavior of
the vowel and consonant inventories with respect to
redundancy can be as follows: while the organiza-
tion of the vowel inventories is known to be gov-
erned by a single force - the maximal perceptual
contrast (Jakobson, 1941; Liljencrants and Lind-
blom, 1972; de Boer, 2000)), consonant invento-
ries are shaped by a complex interplay of several
forces (Mukherjee et al, 2006). The invariance of
redundancy, perhaps, reflects some sort of an equi-
librium that arises from the interaction of these di-
vergent forces.
The rest of the paper is structured as follows. In
section 2 we briefly discuss the earlier works in con-
nection to the sound inventories and then systemat-
ically build up the quantitative definition of redun-
dancy from the linguistic theories that are already
available in the literature. Section 3 details out the
data source necessary for the experiments, describes
the baseline for the experiments, reports the exper-
iments performed, and presents the results obtained
each time comparing the same with the baseline re-
sults. Finally we conclude in section 4 by summa-
rizing our contributions, pointing out some of the
implications of the current work and indicating the
possible future directions.
2 Formulation of Redundancy
Linguistic research has documented a wide range of
regularities across the sound systems of the world?s
languages. It has been postulated earlier by func-
tional phonologists that such regularities are the con-
sequences of certain general principles like maxi-
mal perceptual contrast (Liljencrants and Lindblom,
1972), which is desirable between the phonemes of
a language for proper perception of each individ-
ual phoneme in a noisy environment, ease of artic-
ulation (Lindblom and Maddieson, 1988; de Boer,
2000), which requires that the sound systems of
all languages are formed of certain universal (and
highly frequent) sounds, and ease of learnability (de
Boer, 2000), which is necessary for a speaker to
learn the sounds of a language with minimum ef-
fort. In fact, the organization of the vowel inven-
tories (especially those with a smaller size) across
languages has been satisfactorily explained in terms
of the single principle of maximal perceptual con-
trast (Jakobson, 1941; Liljencrants and Lindblom,
1972; de Boer, 2000).
On the other hand, in spite of several at-
tempts (Lindblom and Maddieson, 1988; Boersma,
1998; Clements, 2004) the organization of the con-
sonant inventories lacks a satisfactory explanation.
However, one of the earliest observations about the
consonant inventories has been that consonants tend
to occur in pairs that exhibit strong correlation in
terms of their features (Trubetzkoy, 1931). In or-
der to explain these trends, feature economy was
proposed as the organizing principle of the con-
sonant inventories (Martinet, 1955). According to
this principle, languages tend to maximize the com-
binatorial possibilities of a few distinctive features
to generate a large number of consonants. Stated
differently, a given consonant will have a higher
than expected chance of occurrence in inventories in
which all of its features have distinctively occurred
in other consonants. The idea is illustrated, with an
example, through Table 1. Various attempts have
been made in the past to explain the aforementioned
trends through linguistic insights (Boersma, 1998;
Clements, 2004) mainly establishing their statistical
significance. On the contrary, there has been very
little work pertaining to the quantification of feature
economy except in (Clements, 2004), where the au-
thor defines economy index, which is the ratio of the
size of an inventory to the number of features that
characterizes the inventory. However, this definition
does not take into account the complexity that is in-
volved in communicating the information about the
inventory in terms of its constituent features.
Inspired by the aforementioned studies and
the concepts of information theory (Shannon and
Weaver, 1949) we try to quantitatively capture the
amount of redundancy found across the consonant
105
plosive voiced voiceless
dental /d/ /t/
bilabial /b/ /p/
Table 1: The table shows four plosives. If a language
has in its consonant inventory any three of the four
phonemes listed in this table, then there is a higher
than average chance that it will also have the fourth
phoneme of the table in its inventory.
inventories in terms of their constituent features. Let
us assume that we want to communicate the infor-
mation about an inventory of size N over a transmis-
sion channel. Ideally, one should require logN bits
to do the same (where the logarithm is with respect
to base 2). However, since every natural system is
to some extent redundant and languages are no ex-
ceptions, the number of bits actually used to encode
the information is more than logN . If we assume
that the features are boolean in nature, then we can
compute the number of bits used by a language to
encode the information about its inventory by mea-
suring the entropy as follows. For an inventory of
size N let there be pf consonants for which a partic-
ular feature f (where f is assumed to be boolean in
nature) is present and qf other consonants for which
the same is absent. Thus the probability that a par-
ticular consonant chosen uniformly at random from
this inventory has the feature f is pfN and the prob-
ability that the consonant lacks the feature f is qfN
(=1?pfN ). If F is the set of all features present in
the consonants forming the inventory, then feature
entropy FE can be expressed as
FE =
?
f?F
(?
pf
N
log
pf
N
?
qf
N
log
qf
N
) (1)
FE is therefore the measure of the minimum number
of bits that is required to communicate the informa-
tion about the entire inventory through the transmis-
sion channel. The lower the value of FE the better
it is in terms of the information transmission over-
head. In order to capture the redundancy involved in
the encoding we define the term redundancy ratio as
follows,
RR =
FE
logN
(2)
which expresses the excess number of bits that is
used by the constituent consonants of the inventory
Figure 1: The process of computing RR for a hypo-
thetical inventory.
in terms of a ratio. The process of computing the
value of RR for a hypothetical consonant inventory
is illustrated in Figure 1.
In the following section, we present the experi-
mental setup and also report the experiments which
we perform based on the above definition of redun-
dancy. We subsequently show that redundancy ratio
is invariant across the consonant inventories whereas
the same is not true in the case of the vowel invento-
ries.
3 Experiments and Results
In this section we discuss the data source necessary
for the experiments, describe the baseline for the
experiments, report the experiments performed, and
present the results obtained each time comparing the
same with the baseline results.
3.1 Data Source
Many typological studies (Ladefoged and Mad-
dieson, 1996; Lindblom and Maddieson, 1988)
of segmental inventories have been carried out in
past on the UCLA Phonological Segment Inven-
tory Database (UPSID) (Maddieson, 1984). UPSID
gathers phonological systems of languages from all
over the world, sampling more or less uniformly all
the linguistic families. In this work we have used
UPSID comprising of 317 languages and 541 con-
sonants found across them, for our experiments.
106
3.2 Redundancy Ratio across the Consonant
Inventories
In this section we measure the redundancy ratio (de-
scribed earlier) of the consonant inventories of the
languages recorded in UPSID. Figure 2 shows the
scatter-plot of the redundancy ratio RR of each of
the consonant inventories (y-axis) versus the inven-
tory size (x-axis). The plot immediately reveals that
the measure (i.e., RR) is almost invariant across the
consonant inventories with respect to the inventory
size. In fact, we can fit the scatter-plot with a straight
line (by means of least square regression), which as
depicted in Figure 2, has a negligible slope (m = ?
0.018) and this in turn further confirms the above
fact that RR is an invariant property of the conso-
nant inventories with regard to their size. It is im-
portant to mention here that in this experiment we
report the redundancy ratio of all the inventories of
size less than or equal to 40. We neglect the inven-
tories of the size greater than 40 since they are ex-
tremely rare (less than 0.5% of the languages of UP-
SID), and therefore, cannot provide us with statis-
tically meaningful estimates. The same convention
has been followed in all the subsequent experiments.
Nevertheless, we have also computed the values of
RR for larger inventories, whereby we have found
that for an inventory size ? 60 the results are sim-
ilar to those reported here. It is interesting to note
that the largest of the consonant inventories Ga (size
= 173) has an RR = 1.9, which is lower than all the
other inventories.
The aforementioned claim that RR is an invari-
ant across consonant inventories can be validated by
performing a standard test of hypothesis. For this
purpose, we randomly construct language invento-
ries, as discussed later, and formulate a null hypoth-
esis based on them.
Null Hypothesis: The invariance in the distribution
of RRs observed across the real consonant invento-
ries is also prevalent across the randomly generated
inventories.
Having formulated the null hypothesis we now
systematically attempt to reject the same with a very
high probability. For this purpose we first construct
random inventories and then perform a two sample
t-test (Cohen, 1995) comparing the RRs of the real
and the random inventories. The results show that
Figure 2: The scatter-plot of the redundancy ratio
RR of each of the consonant inventories (y-axis)
versus the inventory size (x-axis). The straight line-
fit is also depicted by the bold line in the figure.
indeed the null hypothesis can be rejected with a
very high probability. We proceed as follows.
3.2.1 Construction of Random Inventories
We employ two different models to generate the
random inventories. In the first model the invento-
ries are filled uniformly at random from the pool of
541 consonants. In the second model we assume
that the distribution of the occurrence of the conso-
nants over languages is known a priori. Note that
in both of these cases, the size of the random in-
ventories is same as its real counterpart. The results
show that the distribution of RRs obtained from the
second model has a closer match with the real in-
ventories than that of the first model. This indicates
that the occurrence frequency to some extent gov-
erns the law of organization of the consonant inven-
tories. The detail of each of the models follow.
Model I ? Purely Random Model: In this model
we assume that the distribution of the consonant in-
ventory size is known a priori. For each language
inventory L let the size recorded in UPSID be de-
noted by sL. Let there be 317 bins corresponding to
each consonant inventory L. A bin corresponding to
an inventory L is packed with sL consonants chosen
uniformly at random (without repetition) from the
pool of 541 available consonants. Thus the conso-
nant inventories of the 317 languages corresponding
to the bins are generated. The method is summarized
107
in Algorithm 1.
for I = 1 to 317 do
for size = 1 to sL do
Choose a consonant c uniformly at
random (without repetition) from the
pool of 541 available consonants;
Pack the consonant c in the bin
corresponding to the inventory L;
end
end
Algorithm 1: Algorithm to construct random in-
ventories using Model I
Model II ? Occurrence Frequency based Random
Model: For each consonant c let the frequency of
occurrence in UPSID be denoted by fc. Let there be
317 bins each corresponding to a language in UP-
SID. fc bins are then chosen uniformly at random
and the consonant c is packed into these bins. Thus
the consonant inventories of the 317 languages cor-
responding to the bins are generated. The entire idea
is summarized in Algorithm 2.
for each consonant c do
for i = 1 to fc do
Choose one of the 317 bins,
corresponding to the languages in
UPSID, uniformly at random;
Pack the consonant c into the bin so
chosen if it has not been already packed
into this bin earlier;
end
end
Algorithm 2: Algorithm to construct random in-
ventories using Model II
3.2.2 Results Obtained from the Random
Models
In this section we enumerate the results obtained
by computing the RRs of the randomly generated
inventories using Model I and Model II respectively.
We compare the results with those of the real inven-
Parameters Real Inv. Random Inv.
Mean 2.51177 3.59331
SDV 0.209531 0.475072
Parameters Values
t 12.15
DF 66
p ? 9.289e-17
Table 2: The results of the t-test comparing the dis-
tribution of RRs for the real and the random invento-
ries (obtained through Model I). SDV: standard devi-
ation, t: t-value of the test, DF: degrees of freedom,
p: residual uncertainty.
tories and in each case show that the null hypothesis
can be rejected with a significantly high probability.
Results from Model I: Figure 3 illustrates, for all
the inventories obtained from 100 different simula-
tion runs of Algorithm 1, the average redundancy
ratio exhibited by the inventories of a particular size
(y-axis), versus the inventory size (x-axis). The
term ?redundancy ratio exhibited by the inventories
of a particular size? actually means the following.
Let there be n consonant inventories of a particu-
lar inventory-size k. The average redundancy ra-
tio of the inventories of size k is therefore given by
1
n
?n
i=1 RRi where RRi signifies the redundancy ra-
tio of the ith inventory of size k. In Figure 3 we also
present the same curve for the real consonant inven-
tories appearing in UPSID. In these curves we fur-
ther depict the error bars spanning the entire range of
values starting from the minimum RR to the max-
imum RR for a given inventory size. The curves
show that in case of real inventories the error bars
span a very small range as compared to that of the
randomly constructed ones. Moreover, the slopes of
the curves are also significantly different. In order
to test whether this difference is significant, we per-
form a t-test comparing the distribution of the val-
ues of RR that gives rise to such curves for the real
and the random inventories. The results of the test
are noted in Table 2. These statistics clearly shows
that the distribution of RRs for the real and the ran-
dom inventories are significantly different in nature.
Stated differently, we can reject the null hypothesis
with (100 - 9.29e-15)% confidence.
Results from Model II: Figure 4 illustrates, for
all the inventories obtained from 100 different simu-
108
Figure 3: Curves showing the average redundancy
ratio exhibited by the real as well as the random in-
ventories (obtained through Model I) of a particular
size (y-axis), versus the inventory size (x-axis).
lation runs of Algorithm 2, the average redundancy
ratio exhibited by the inventories of a particular size
(y-axis), versus the inventory size (x-axis). The fig-
ure shows the same curve for the real consonant in-
ventories also. For each of the curve, the error bars
span the entire range of values starting from the min-
imum RR to the maximum RR for a given inventory
size. It is quite evident from the figure that the error
bars for the curve representing the real inventories
are smaller than those of the random ones. The na-
ture of the two curves are also different though the
difference is not as pronounced as in case of Model I.
This is indicative of the fact that it is not only the oc-
currence frequency that governs the organization of
the consonant inventories and there is a more com-
plex phenomenon that results in such an invariant
property. In fact, in this case also, the t-test statistics
comparing the distribution of RRs for the real and
the random inventories, reported in Table 3, allows
us to reject the null hypothesis with (100?2.55e?3)%
confidence.
3.3 Comparison with Vowel Inventories
Until now we have been looking into the organiza-
tional aspects of the consonant inventories. In this
section we show that this organization is largely dif-
ferent from that of the vowel inventories in the sense
that there is no such invariance observed across the
vowel inventories unlike that of consonants. For
this reason we start by computing the RRs of all
Figure 4: Curves showing the average redundancy
ratio exhibited by the real as well as the random in-
ventories (obtained through Model II) of a particular
size (y-axis), versus the inventory size (x-axis).
Parameters Real Inv. Random Inv.
Mean 2.51177 2.76679
SDV 0.209531 0.228017
Parameters Values
t 4.583
DF 60
p ? 2.552e-05
Table 3: The results of the t-test comparing the dis-
tribution of RRs for the real and the random inven-
tories (obtained through Model II).
the vowel inventories appearing in UPSID. Figure 5
shows the scatter plot of the redundancy ratio of each
of the vowel inventories (y-axis) versus the inven-
tory size (x-axis). The plot clearly indicates that the
measure (i.e., RR) is not invariant across the vowel
inventories and in fact, the straight line that fits the
distribution has a slope of ?0.14, which is around 10
times higher than that of the consonant inventories.
Figure 6 illustrates the average redundancy ratio
exhibited by the vowel and the consonant inventories
of a particular size (y-axis), versus the inventory size
(x-axis). The error bars indicating the variability of
RR among the inventories of a fixed size also span a
much larger range for the vowel inventories than for
the consonant inventories.
The significance of the difference in the nature of
the distribution of RRs for the vowel and the conso-
nant inventories can be again estimated by perform-
ing a t-test. The null hypothesis in this case is as
follows.
109
Figure 5: The scatter-plot of the redundancy ratio
RR of each of the vowel inventories (y-axis) versus
the inventory size (x-axis). The straight line-fit is
depicted by the bold line in the figure.
Figure 6: Curves showing the average redundancy
ratio exhibited by the vowel as well as the consonant
inventories of a particular size (y-axis), versus the
inventory size (x-axis).
Null Hypothesis: The nature of the distribution of
RRs for the vowel and the consonant inventories is
same.
We can now perform the t-test to verify whether
we can reject the above hypothesis. Table 4 presents
the results of the test. The statistics immediately
confirms that the null hypothesis can be rejected
with 99.932% confidence.
Parameters Consonant Inv. Vowel Inv.
Mean 2.51177 2.98797
SDV 0.209531 0.726547
Parameters Values
t 3.612
DF 54
p ? 0.000683
Table 4: The results of the t-test comparing the dis-
tribution of RRs for the consonant and the vowel
inventories.
4 Conclusions, Discussion and Future
Work
In this paper we have mathematically captured the
redundancy observed across the sound inventories of
the world?s languages. We started by systematically
defining the term redundancy ratio and measuring
the value of the same for the inventories. Some of
our important findings are,
1. Redundancy ratio is an invariant property of the
consonant inventories with respect to the inventory
size.
2. A more complex phenomenon than merely the
occurrence frequency results in such an invariance.
3. Unlike the consonant inventories, the vowel in-
ventories are not indicative of such an invariance.
Until now we have concentrated on establishing
the invariance of the redundancy ratio across the
consonant inventories rather than reasoning why it
could have emerged. One possible way to answer
this question is to look for the error correcting ca-
pability of the encoding scheme that nature had em-
ployed for characterization of the consonants. Ide-
ally, if redundancy has to be invariant, then this ca-
pability should be almost constant. As a proof of
concept we randomly select a consonant from in-
ventories of different size and compute its hamming
distance from the rest of the consonants in the inven-
tory. Figure 7 shows for a randomly chosen conso-
nant c from an inventory of size 10, 15, 20 and 30
respectively, the number of the consonants at a par-
ticular hamming distance from c (y-axis) versus the
hamming distance (x-axis). The curve clearly indi-
cates that majority of the consonants are at a ham-
ming distance of 4 from c, which in turn implies that
the encoding scheme has almost a fixed error cor-
recting capability of 1 bit. This can be the precise
reason behind the invariance of the redundancy ra-
110
Figure 7: Histograms showing the the number of consonants at a particular hamming distance (y-axis), from
a randomly chosen consonant c, versus the hamming distance (x-axis).
tio. Initial studies into the vowel inventories show
that for a randomly chosen vowel, its hamming dis-
tance from the other vowels in the same inventory
varies with the inventory size. In other words, the er-
ror correcting capability of a vowel inventory seems
to be dependent on the size of the inventory.
We believe that these results are significant as well
as insightful. Nevertheless, one should be aware of
the fact that the formulation of RR heavily banks
on the set of features that are used to represent the
phonemes. Unfortunately, there is no consensus on
the set of representative features, even though there
are numerous suggestions available in the literature.
However, the basic concept of RR and the process of
analysis presented here is independent of the choice
of the feature set. In the current study we have used
the binary features provided in UPSID, which could
be very well replaced by other representations, in-
cluding multi-valued feature systems; we look for-
ward to do the same as a part of our future work.
References
B. de Boer. 2000. Self-organisation in vowel systems.
Journal of Phonetics, 28(4), 441?465.
P. Boersma. 1998. Functional phonology, Doctoral the-
sis, University of Amsterdam, The Hague: Holland
Academic Graphics.
N. Clements. 2004. Features and sound inventories.
Symposium on Phonological Theory: Representations
and Architecture, CUNY.
P. R. Cohen. 1995. Empirical methods for artificial in-
telligence, MIT Press, Cambridge.
L. L. Gatlin. 1974. Conservation of Shannon?s redun-
dancy for proteins Jour. Mol. Evol., 3, 189?208.
R. Jakobson. 1941. Kindersprache, aphasie und all-
gemeine lautgesetze, Uppsala, Reprinted in Selected
Writings I. Mouton, The Hague, 1962, 328-401.
D. C. Krakauer and J. B. Plotkin. 2002. Redundancy,
antiredundancy, and the robustness of genomes. PNAS,
99(3), 1405-1409.
A. M. Lesk. 2002. Introduction to bioinformatics, Ox-
ford University Press, New York.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
world?s languages, Oxford: Blackwell.
J. Liljencrants and B. Lindblom. 1972. Numerical simu-
lation of vowel quality systems: the role of perceptual
contrast. Language, 48, 839?862.
B. Lindblom and I. Maddieson. 1988. Phonetic uni-
versals in consonant systems. Language, Speech, and
Mind, 62?78.
I. Maddieson. 1984. Patterns of sounds, Cambridge Uni-
versity Press, Cambridge.
A. Martinet 1955. `Economie des changements
phone?tiques, Berne: A. Francke.
A. Mukherjee, M. Choudhury, A. Basu and N. Ganguly.
2006. Modeling the co-occurrence principles of the
consonant inventories: A complex network approach.
arXiv:physics/0606132 (preprint).
C. E. Shannon and W. Weaver. 1949. The mathematical
theory of information, Urbana: University of Illinois
Press.
N. Trubetzkoy. 1931. Die phonologischen systeme.
TCLP, 4, 96?116.
N. Trubetzkoy. 1969. Principles of phonology, Berkeley:
University of California Press.
A. Woollard. 2005. Gene duplications and genetic re-
dundancy in C. elegans, WormBook.
111
A Diachronic Approach for Schwa Deletion in Indo Aryan Languages 
Monojit CHOUDHURY, Anupam BASU and Sudeshna SARKAR 
Dept.. of Computer Science & Engineering, 
Indian Institute of Technology, Kharagpur 
INDIA, PIN-721302 
{ monojit, anupam, sudeshna } @cse.iitkgp.ernet.in  
 
 
Abstract 
Schwa deletion is an important issue in 
grapheme-to-phoneme conversion for Indo-
Aryan languages (IAL). In this paper, we 
describe a syllable minimization based 
algorithm for dealing with this that 
outperforms the existing methods in terms of 
efficiency and accuracy. The algorithm is 
motivated by the fact that deletion of schwa is 
a diachronic and sociolinguistic phenomenon 
that facilitates faster communication through 
syllable economy. The contribution of the 
paper is not just a better algorithm for schwa 
deletion; rather we describe here a constrained 
optimization based framework that can partly 
model the evolution of languages, and hence, 
can be used for solving many problems in 
computational linguistics that call for 
diachronic explanations. 
 
1 Introduction 
Linguists propose new models for languages 
in order to explain language acquisition and 
processing by humans. Irregularities and 
exceptions to the theories are often explained by 
evidence from diachronic linguistics and other 
social and external phenomena. Absence of 
diachronic analysis in computational modelling of 
languages results in a large number of exceptions, 
which are commonly handled by ad hoc rules or 
exhaustive enumeration. These techniques lead to 
poor scalability and lack of graceful degradation of 
the systems along with increased complexity. 
Although complete modelling of the evolution of 
language is impossible due to the involvement of 
myriads of socio-political and cultural factors, it is 
definitely possible to model certain basic 
principles of language change. 
In this paper we describe an algorithm for 
schwa deletion in Indo-Aryan Languages (IAL) 
that is motivated by the diachronic evolution of the 
languages. The proposed computational framework 
models languages as a constrained optimization 
system, where a language evolves by optimizing 
the rate of communication, subjected to a set of 
constraints such as ease of articulation and 
learning, and acoustic distinctiveness. A syllable 
minimization based optimization function fitted to 
the aforementioned model has been used for 
solving the problem of schwa deletion with 
considerable success.  
The paper is organized as follows: Section 2 
defines the problem and discusses some of the 
previous works. Section 3 describes the current 
models of language evolution, which has been 
used to develop a computational framework 
described in the next section. Section 5 and 6 
presents the algorithm and its experimental 
analysis respectively. Section 7 concludes the 
paper summarizing our contributions. 
2 The Problem  
Schwa is defined as the mid-central vowel that 
occurs in unstressed syllables. The first vowel of 
the IAL alphabet {a}1 is the schwa. Normally, it is 
pronounced as /?/ in Hindi and Sanskrit, and as /?/ 
in Bengali. Schwa deletion is a phonological 
phenomenon where schwa is absent in the 
pronunciation of a particular word, although 
ideally it should have been pronounced (Ohala, 
1983).  
Sanskrit and some of the modern IAL that have 
evolved from it (e.g. Hindi and Bengali), are 
written from left to right using Brahmi-derived 
scripts. All the vowels are explicitly represented 
using diacritical or non-diacritical marks around 
the consonant except for the schwa, which is the 
inherent vowel. Unlike Sanskrit, many modern 
IAL like Hindi and Bengali allow deletion of 
schwa in certain contexts. Table I illustrates this 
phenomenon for the three languages. In order to 
determine the proper pronunciation of the words, it 
is necessary to predict which schwas are deleted 
and which are not. Thus, schwa deletion is an 
                                                     
1 The graphemes for Indo-Aryan languages are written within ?{? and ?}? 
according to the scheme adopted by the International Congress of Orientalists at 
Athens in 1992. The phonetic transcriptions are written within two ?/? using the 
IPA symbols. 
                                                                  Barcelona, July 2004
                                              Association for Computations Linguistics
                       ACL Special Interest Group on Computational Phonology (SIGPHON)
                                                    Proceedings of the Workshop of the
important issue for grapheme-to-phoneme 
conversion of IAL, which in turn is required for a 
good Text-to-Speech synthesizer (Narasimhan et 
al, 2001).  
 
Pronunciation   The  
Spelling Sanskri
t 
Hind
i 
Bengali 
s?phaly
a 
(succes
s) 
sa??ly
? 
(3) 
sa??
lj? 
(3) 
?a?ol lo 
(3) 
racan? 
(creati
on) 
r?c?na 
(3) 
r?cn
a 
(2) 
r?cona 
(3) 
veda 
(Veda) 
ved? 
(2) 
ved 
(1) 
bed 
(1) 
 
Table 1. Pronunciation of three different words 
in three different IAL. The number of syllables is 
denoted within parenthesis below the 
pronunciations. In Bengali {a} can also be 
pronounced as /o/ in certain contexts. 
 
Several theories have been proposed on the 
linguistic aspects of schwa deletion in Hindi (Pray, 
1970; Kaira 1976; Ohala, 1977, 1983) and its 
diachronic evolution (Misra, 1967). Ohala (1983) 
has summarized the rule for schwa deletion in 
Hindi as  
? ?   ? / VC __ CV 
Condition 1: There may be no morpheme 
boundary in the environment to the left. 
Condition 2: The output of the rule should not 
violate the phonotactic constraints of Hindi 
Convention: The rule applies from right to left 
 
The explanation of the rule was based on 
psycholinguistic evidence; diachronic facts were 
used only to explain the exceptions. Narsimhan et 
al (2001) designed an algorithm for schwa deletion 
in Hindi based on this work. The reported accuracy 
of the algorithm is 89%. Some rules for word final 
schwa deletion in Bengali have been proposed by 
Chatterji (1926), but we do not know of any work 
on computational modelling. 
 
3 Factors governing language change 
The fact that schwa deletion in IAL is a diachronic 
phenomenon has been substantiated by Misra 
(1967). According to Ohala (1983) the deletion of 
schwas is more frequent in casual and fast speech 
compared to formal and slower ones. It can be 
inferred from these facts that the motivation behind 
schwa deletion is faster communication through 
minimization of syllables (Tranel 1999).  
 Some recent works on mathematical and 
simulation based modelling of language evolution 
(Boer, 2000; Cangelosi and Parisi, 2002; Nowak et 
al, 2002) suggests that several features of 
languages emerge due to some basic cognitive and 
articulatory factors. These models assume a) ease 
of articulation, b) ease of learning, and c) acoustic 
distinctiveness as the primary driving forces 
behind language evolution. The three forces 
operate simultaneously over the language in order 
to maximize the rate of successful communication 
in terms of time and effort spent by the language 
users to generate, understand and learn the 
language. Thus, language can be modelled as a 
multi-objective optimization system, where the 
optimization criteria are 
 
? Minimization of effort (in terms of energy and 
time spent while conveying a piece of 
information)  
? Minimization of learning time and effort 
? Minimization of probability of 
misunderstanding (in the sense of confusing 
one word with another) 
 
These three criteria are mutually contradictory and 
therefore there exists no global optimum. Let us 
examine the phenomenon of schwa deletion under 
this multi-objective optimization model for 
language evolution. When a vowel is deleted from 
a word the number of syllables reduces by one. For 
example, in Table 1, for the second word, Sanskrit 
and Bengali have three syllables, whereas due to 
the deletion of a schwa, the Hindi pronunciation 
has only two syllables. Reduction of syllables 
implies shorter time for pronunciation of a word, 
and hence faster communication. However, 
deletion of schwas in certain contexts might result 
in a consonant cluster which the native speakers 
find very difficult or impossible to pronounce. This 
beats the very purpose of schwa deletion, i.e. the 
minimization of effort of articulation and therefore, 
is unacceptable. The second condition for the rule 
proposed by Ohala (section 2) refers to this 
constraint. 
 There are contexts where deletion of schwa 
would not give rise to inadmissible consonant 
clusters. For example, in the Hindi/Bengali word 
pari (fairy, /p?ri/ in Hindi), if the first schwa is 
deleted, the pronunciation would be /pri/, which 
does not violate the phonotactic constraints of the 
languages. The schwa, however, is not deleted, 
because /p?ri/ and /pri/ are too distinct from each 
other to be interpreted as the same word. 
Moreover, /pri/ is closer to other Hindi words like 
priya (favorite, /prij?/). In this case, the deletion of 
schwa reduces the acoustic distinctiveness of the 
word from other words in the lexicon, which 
increases the probability of misunderstanding, and 
hence the schwa might not be deleted in such a 
context. 
4 Computational framework 
We propose the following diachronic 
explanation for schwa deletion in IAL.  
In old IAL none of the schwas are deleted. The 
modern IAL use the script and spelling 
conventions similar to Sanskrit. Due to a higher 
evolutionary pressure on the spoken forms of the 
languages than on the written forms, schwas are 
deleted in the pronunciation, but are still present in 
the graphemic forms. The deletion is a slow 
diachronic phenomenon, where in order to 
communicate faster, initially the speakers 
unintentionally deleted the schwas. Only those 
deletions were acceptable that did not lead to a 
syllable structure which was too difficult to 
pronounce, learn or understand for the native 
speakers. Gradually, the pattern of deletion spread 
across the population and over the different items 
in the lexicon. 
In this section, we describe a computational 
framework for modelling the aforementioned 
hypothesis based on the three optimization criteria 
stated in the last section. The aim of the proposed 
framework is not to validate the hypothesis 
through micro-simulation (Cangelosi and Parisi, 
2002); rather it tries to predict the schwa deletion 
pattern based on the optimizations that might have 
affected the deletion of schwas diachronically. In 
the next section, we present an efficient algorithm 
for schwa deletion in IAL, which can be 
automatically constructed from this model, without 
the help of any other evidence. 
 
4.1 Basic definitions 
 All the unexplained symbols used below stand 
for their usual meaning in the context of formal 
language theory. Please refer to (Hopcroft and 
Ullman, 1979) for details. 
 
?g (?p): A finite set of the graphemes 2 
(phonemes) in the language  
?g = Vg ? Cg,  ?p = Vp  ? Cp  
                                                     
2  Graphemes here do not refer to glyphs. Free vowels and their 
corresponding diacritical marks are considered to be the same symbol 
Where 
Vg (Vp): Finite set of graphemes (phonemes), 
which are vowels 
Cg (Cp): Finite set of graphemes (phonemes), 
which are consonants. Semivowels are also 
considered as consonants. 
 
? ? Vg is a special symbol that represents schwa. 
We define, 
fg2p: ?g ? ?p 
fg2p is the default mapping of the graphemes to 
the phonemes. This oversimplification is made 
here for two reasons. First, since IAL use a 
phonetic script, this in general is true3 and second, 
this assumption does not have any affect on the 
schwa deletion algorithm.  
 
A word w is defined as a 2-tuple <wg, wp>, 
where  
wg ? ?g+ and wp? ?p+ 
 
A lexicon ? is the union of all the valid words w 
of a language. A grapheme-to-phoneme converter 
is defined as a function Fg2p: ?g+? ?p+, such that 
?w < wg, wp >? ?, Fg2p(wg) = wp 
 
4.2 Phonotactic constraints 
In order to model the ease of articulation, we 
start with the modelling of phonotactic constraints. 
A consonant cluster is a string of the form CpCp+. 
Phonotactic constraints restrict the presence of 
some of the consonant clusters in the phonetic 
representation of a word (wp). At the most generic 
level we can think of a consonant cluster ranking 
(CCR) function, where ? is the set of natural 
numbers       
                 
CCR: Cp+ ? ? 
 
The function CCR is independent of any 
language and every language has a threshold ?CCR, 
such that a consonant cluster x ? Cp+ is allowed in 
the language if and only if    
           
CCR (x) ? ?CCR 
 
We define two special variants of CCR, O_CCR 
and C_CCR, which ranks the admissibility of the 
consonant clusters at the onset and coda positions 
respectively. The definition is similar to that of 
CCR, and ?OCCR and ?CCCR are the corresponding 
threshold values.  
                                                     
3 This assumption is not strictly valid since a cluster of consonant might be 
mapped to a single consonant or a different cluster.    
The sonority hierarchy (Vennemann, 1988) and 
markedness conditions (Kager, 1999) along with 
the physiology of the articulatory mechanism point 
towards the existence of a language independent 
ranking function as hypothesized above. However, 
there might be accidental gaps in the list of 
admissible consonant clusters of a language 
(Ohala, 1983), which can not be explained on the 
basis of CCR alone. Therefore, we define a 
Boolean function ADM that tell us about the 
admissibility of consonant clusters in a language. 
 
ADM: Cp+ ? {0, 1}, such that for s ? Cp+ 
 (ADM (s) = 1) ?  (s is an admissible cluster) 
 
In general, we can derive this function from 
CCR as 
ADM (s) = sign (?CCR    ? CCR (s)) 
 
However, we might have to forcefully convert 
some values to 0 due to accidental gaps.   
 
4.3 Syllable and Syllabification 
We define a syllable ? as a regular expression, 
with the assumption that the nucleus contains a 
single vowel. Thus, 
? ? Cp* Vp Cp* 
 
The syllabification function SYL maps the 
phonetic representation wp of a word w to a string 
of syllables ?1?2??m such that the effort of 
articulation and learning are minimum. 
 
We model the effort of articulation using a 
syllable ranking function SR, which is similar to 
CCR. 
 SR : Cp*VpCp* ? ? 
 
SR is mainly dependent on the structure of the 
syllable. We enumerate the first few terms of the 
function SR.          
 
SR (Vp) = 1,  SR (CpVp) = 2   
SR (CpVpCp) = 3, SR (VpCp) = 4 
SR (CpCpVp) = 5,  SR (CpCpVpCp) = 6 
SR (CpCpCpVp) = 7,  SR (CpVpCpCp) = 8 
 
For all other possible syllable structures ??,  
SR (??) > 8 
 
Also, for any syllable ?,    
[O_CCR (onset(?)) >  ?OCCR] ? 
[C_CCR (coda(?)) >  ?CCCR] ? (SR (?) = ? ) 
 
This means that if either the coda or the onset of 
a syllable is inadmissible, then the ranking 
function maps the syllable to the highest possible 
rank, represented symbolically by the infinity (?). 
onset and coda are projection functions that project 
the longest valid prefix and suffix of a syllable 
respectively that are elements of  Cp*. 
 
We define a syllabification to be valid if all the 
syllables are valid (i.e. strings of the form 
Cp*VpCp*) and every symbol in the word is a part 
of one and only one syllable in the syllabification. 
We can define a partial ordering, ??, among the 
possible valid syllabifications of a given word 
based on SRp such that the syllabification with 
smaller number of high ranked syllables is 
preferred to one that has more hard (high ranked) 
syllables. Now we define SYL (wp) as the set of all 
possible syllabifications ?1?2??m such that (i) 
?1?2??m is a valid syllabification of  wp and (ii) 
there exist no other valid syllabification v of wp 
such that v ?? ?1?2??m.  
 
The definitions of syllable and syllabification are 
motivated by the markedness conditions (Kager, 
1999) and experimental results on child language 
acquisition (MacNeilage and Davis, 2000), that 
show that some syllables and syllabifications are 
easier to learn and pronounce than others. 
 
4.4 Acoustic distinctiveness constraints 
Perceptual experiments show that speakers 
always articulate the onset of the syllables more 
clearly and correctly compared to the articulations 
of the vowel and the coda (Fosler-Lussier et al 
1999; Greenberg, 1999). Therefore, it is likely that 
the hearer distinguish between syllables by paying 
more weight to the onset than to the coda. A 
continuous distance metric D? might be defined 
based on these experimental results, such that the 
probability of confusion (interpreting one syllable 
as another) between two syllables ? and ?? 
increases as the value of D?(? , ??) decreases. We 
can further define an acoustic distance function Dw 
using the function D? , which measures the 
probability of confusion between two arbitrary 
words in the phonetic domain. 
In the case of schwa deletion, however, we want 
the acoustic distance between the ideal 
pronunciation (without any schwa deletion) and 
the normal pronunciation (with schwa deletion) to 
be smaller, so that the word is not confused with 
other words in the lexicon. Formally, for the 
graphemic representation of a word wg = x1x2 ? 
xn, 
Dw(fg2p (x1).fg2p (x2)? fg2p (xn), Fg2p(wg)) < 
?critical, where ?critical is the maximum allowable 
distance and ?.? is the concatenation operator. 
Rather than modelling this as an optimization 
criterion, we reformulate this as a constraint. The 
simplification in this case serves our purpose. 
 
We define, where x ? Cp   
D?(x. fg2p(?), ?) = 0                  (4a) 
 D?(?, ?.x) = 0          (4b) 
For all other cases D?  is infinity (?), unless the 
two syllables are identical.             (4c) 
 
(4a) allows the deletion of a schwa from an open 
syllable; (4b) allows the concatenation of a 
consonant at the coda position. This is motivated 
by the fact that coda has least distinctiveness 
(Greenberg, 1999). (4c) restricts any change at the 
onset of a syllable or the vowels other than schwa.  
 
On the basis of D? we can define  Dw(wp1, wp2) = 
0 if and only if there exists an alignment between 
the sequences SYL (wp1) and SYL (wp2), with 
possible gaps (? or null syllables) such that for all 
the corresponding pairs of syllable taken from the 
two sequences, the acoustic distinctiveness (D?) 
between them is 0. Thus, only operations allowed 
are deletion of a schwa and addition of a consonant 
at the coda position. Anything else is forbidden for 
the sake of acoustic distinctiveness.  
 
We conclude this section by summarizing below 
the salient features of the model by comparing it 
with the optimization criteria stated in section 3. 
 
? The functions SR, CCR and its variants 
that rank the phonotactic constraints is a measure 
of the effort of articulation, learning and the 
probability of misunderstanding. Therefore we 
want to minimize it. However, it has been 
modelled as a constraint (ADM). 
? The function SYL is so defined that the 
efforts of articulation and learning are minimized. 
? Dw models the acoustic distinctiveness i.e. 
the criterion 3c, but it has been reformulated as a 
constraint as well.  
5 The algorithm 
We want to define Fg2p for a language given 
ADM and Dw. Fg2p should be such that it enables 
faster communication by minimization of syllables 
by deletion of schwa. 
 
5.1 Formal definition 
Let wg be an input sequence of graphemes to the 
function Fg2p. Let wp ? ?p* be obtained by 
replacing all graphemes x in wg by fg2p(x). Let wp? 
be obtained by deletion of some (possibly all or 
none) of the schwas (fg2p(?)) in wp. Fg2p(wg) = wp?, 
if and only if Dw(wp, wp?) = 0  and (? vp)[( vp can 
be obtained by deleting schwas from  wp) ? 
(Dw(wp, vp) = 0) ? |SYLg(wp?)| ? |SYLg(vp)| ] 
 
In words it means that among all wp? obtainable 
by deletion of some of the schwas from wp, that 
respects both the ADM (phonotactic) and Dw 
(acoustic distinctiveness) constraints, the one with 
the minimum number of syllables is chosen as the 
output of Fg2p.  
 
procedure SYL : 
input: wp, O_CCR, C_CCR 
output:  ?1?2??m  //The syllabification 
 
1. Include up to the first vowel in wp in ?1 
2. If there are 2 consonants c1c2 between the 
current vowel and the next vowel, include c1 in the 
current syllable and c2 in the next syllable. 
3. If there are 3 consonants c1c2c3 between the 
current vowel and the next vowel,  
     3.1 if O_CCRp(c2c3)? ?OCCR , include c1 in the 
current syllable and c2c3 in the next syllable  
     3.2 else if C_CCRp(c1c2)? ?CCCR include c1c2 in the 
current syllable and c3 in the next syllable 
     3.3 else NO syllabification is possible 
4. If there is one or no consonant between the 
current vowel and the next vowel, terminate the 
current syllable and begin the next syllable 
5. Continue from step 2 till there are symbols not 
included in any syllable.  
end procedure 
 
 
Figure 1. Algorithm for syllabification 
 
5.2 A greedy strategy  
Figure 1 describes a linear time algorithm for 
syllabification (SYL) that conforms to the 
definition provided in section 4.3. This uses the 
fact that the maximum length of allowable 
consonant clusters for IAL is three. After 
syllabification of wp, we try to greedily delete the 
schwas so that the constraints specified by 4a, 4b 
and 4c are not violated. 4a states that only a schwa 
which is a part of an open syllable (c?, where c ? 
Cp) can be deleted and 4b states that after schwa 
deletion, 
the consonant c is appended to the coda of the 
previous syllable. Therefore, both of them together 
imply schwas in two consecutive syllables cannot 
be deleted. Along with that, the following 
constraints can also be derived from the Dw 
constraints (the reasons are omitted due to space 
constraints): 
R1. Schwa of the first syllable cannot be deleted 
R2. Schwa cannot be deleted before a consonant 
cluster. 
R3. The word final schwa can always be deleted 
unless the appending of the penultimate 
consonant to the previous syllable results in an 
inadmissible cluster. 
R4. For Bengali, which does not allow complex 
codas, schwas cannot be deleted after 
consonant clusters. 
R5. A schwa followed by a vowel cannot be 
deleted. 
 
procedure Fg2p: 
input: wg , ADM 
output:  wp  //The pronunciation 
 
1. wp?  = fg2p(x1).fg2p (x2)? fg2p (xn), where wg is 
<x1x2 ? xn > 
2. Syllabify wp?  using procedure SYL 
3. Using rules R1 to R6 and ADM constraints mark 
the schwas which cannot be deleted as F 
4.  While traversing the word from right to left 
         4.1 Delete a schwa if it is not marked F 
         4.2 Appended the dangling consonant to the 
coda of the adjacent syllable (to the left) 
         4.3 If the adjacent syllable (to the left) has a 
schwa which is unmarked, mark it F 
         4.4 Go to 4.1 if there are more schwas to the left 
of the current position. 
5. At the end of step 4 we get the syllabified string of 
phonemes <x?1x?2 ? x?m >, which is the required 
output 
end procedure 
 
Figure 2. Algorithm for schwa deletion 
 
 We have the following rule that cannot be 
captured by the constraints: 
R6. Schwa following a y (pronounced as /j/) 
cannot be deleted if it is preceded by a high 
vowel because /j/ is a glide from high vowel to 
a low/medium vowel (schwa), deletion of 
schwa would make the presence of the glide 
imperceptible. 
This rule could have been captured by the D? 
constraints but we state it here as a separate rule 
for the sake of simplicity. Figure 2 describes an 
algorithm for schwa deletion using the rules above. 
It is easy to see that the time complexity of the 
algorithm is O(|wg|). Due to limited space, we omit 
the proof that the algorithm for Fg2p indeed 
minimizes the number of syllables without 
violating the constraints specified by ADM and Dw. 
However, there might be more than one (precisely 
2) possible solutions and in that case the algorithm 
chooses one of the solutions on the basis of the 
direction of traversal at step 4. The right to left 
traversal gives better results (as has been 
confirmed by Ohala, 1983) because the duration of 
syllables reduces towards the end of the word and 
hence the tendency to delete schwas at the word 
final position increases. 
6 Experimental Results and Discussions 
The algorithm was implemented for Bengali and 
Hindi and tested on a set of words. Table 2 
summarizes the results for Hindi (tested on the 
words in a pocket dictionary (Hindi-Bangla-
English, 2001)). The algorithm for Bengali was 
tested on 1000 randomly selected words from a 
corpus and found to be around 85% accurate.  
Some of the important features of the algorithm 
are as follows. 
? Efficiency: The algorithm runs in linear time 
on the input word length. It scans the whole 
word just twice. Thus, the hidden constant is 
also very small. 
? Polymorphemic Words: The algorithm can 
handle polymorphemic words, if the 
morphological information about the word is 
provided. This is because schwa deletion is not 
carried across morpheme boundaries. 
Morphological analyzer for Hindi and Bengali 
were implemented and integrated with the 
algorithm. For Hindi, the results were nearly 
perfect (99.89%) 
Exceptions: For Hindi there was hardly any 
exception to the algorithm. For Bengali, the types 
of words that were incorrectly processed by the 
algorithm include a class of very frequently used, 
disyllabic modifier adjectives, certain suffixes, 
borrowed words from Sanskrit and compound 
words. In Bengali, the schwa which is retained (as 
opposed to the predictions by the algorithm) are 
pronounced as /o/ and not as / ?/. Since, /o/ is not a 
central vowel, deletion of /o/ is marked as 
compared to deletion of / ?/ which is unmarked. 
Transformation of schwa to some non-neutral 
vowel in Hindi is unknown and therefore, the 
algorithm works perfectly for Hindi. 
 
Experiment
al results for 
Hindi 
Test 
Size 
(No. of 
words) 
Incorre
ct results 
Accurac
y 
Without 
MA 
1109
5 
431 96.12% 
With MA 1109
5 
12 99.89% 
 
Table 2. Experimental results for Hindi schwa 
deletion. The results are for individual words. MA 
stands for Morphological Analysis 
7 Conclusion 
In this paper, we have described the 
phenomenon of schwa deletion in the IAL and 
proposed a diachronic explanation for it. In order 
to model the diachronic evolution, we used the 
concepts of ease of articulation, ease of learning 
and acoustic distinctiveness. We developed a 
computational framework, where we reformulated 
some of the optimization criteria as constraints and 
one of them (the syllable minimization) as the 
basic optimization function. The outcome of this is 
an efficient and accurate algorithm for solving 
schwa deletion in IAL. 
The contribution of this paper is not just a 
better algorithm for schwa deletion, which is 
necessary for developing Text-to-speech 
synthesizers for IAL, but a new approach based on 
a constrained optimization framework, motivated 
by the diachronic evolution of languages. A closer 
look at the algorithm will reveal that it is not much 
different from the schwa deletion rule proposed by 
Ohala (1983). However, Ohala?s rule was based on 
psycholinguistic and empirical observations, 
whereas we have derived the rule from a set of 
very basic assumptions (minimization of syllables 
and certain constraints). The algorithm itself can 
provide an explanation for the phenomenon. 
It must be mentioned that neither the aim nor 
the findings of this work are meant to propose a 
new model of language change. The models and 
concepts used here were all present previously and 
we have assumed and included some of them 
directly in our model. Our finding is not a proof of 
those models and can be considered only as a 
further validation. Our only claim here is that 
diachronic clues can help solve important 
problems in computational linguistics and for this 
we provide a computational framework and a 
specific example. 
 Some of the questions that we would like to 
address in the future include modelling of optional 
schwa deletion in Bengali compound words, 
evolution of morpho-phonology for Bengali verb 
systems, and modelling of dialect diversity using 
diachronic clues. More realistic, yet manageable 
computational frameworks for holistic or detailed 
modelling of language evolution can also be an 
interesting area of future research. 
References  
Bart de Boer 2000. Self Organization in Vowel 
Systems. Journal of Phonetics, 28:441-465 
Angelo Cangelosi and Domenico Parisi (Eds) 
2002. Simulating the Evolution of Language. 
Springer-Verlag, London  
Suniti K. Chatterji 1926. The Origin and 
Development of the Bengali Language. Rupa and 
Co. 
Eric Fosler-Lussier, Steven Greenberg and N 
Morgan  1999. Incorporating contextual 
phonetics into automatic speech recognition. 
Proc. Int. Cong. Phon. Sci., San Francisco, pp. 
611-614. 
Steven Greenberg 1999. Speaking in shorthand - A 
syllablecentric perspective for understanding 
pronunciation variation. Speech Communication, 
29:159-176.  
Hindi Bangla English ? Tribhasa Abhidhaan. 2001 
Sandhya Publication  
John E. Hopcroft and Jeffery D. Ullman 1979. 
Introduction to Automata Theory, Languages 
and Computation, Addison-Wesley, USA  
Rene Kager 1999. Optimality Theory. Cambridge 
University Press 
S. Kaira 1976. Schwa-deletion in Hindi. Language 
forum (back volumes), Bhari publications, 2 (1)  
Peter F. MacNeilage and Barbara L. Davis 2000. 
On the Origin of Internal Structure of Word 
Forms. Science, 288:527-31 
B. G. Misra 1967. Historical Phonology of 
Standard Hindi: Proto Indo European to the 
present. Cornell University Ph. D. dissertation 
Manjari Ohala 1977. The Treatment of 
Phonological variation: An example from Hindi. 
Lingua, 42: 161-76 
Manjari Ohala. 1983. Aspects of Hindi Phonology, 
volume II. MLBD Series in Linguistics, Motilal 
Banarsidass, New Delhi.  
Bhuvana Narasimhan, Richard Sproat and G Kiraz. 
2001. Schwa-deletion in Hindi Text-to-Speech 
Synthesis. Workshop on Computational 
Linguistics in South Asian Languages, 21st 
SALA, Konstanz  
Martin A. Nowak, Natalia L. Komarova and Partha 
Niyogi 2002. Computational and Evolutionary 
Aspects of Language, Nature, 417:611-17 
B. R. Pray 1970. Topics in Hindi ? Urdu grammar. 
Research Monograph 1, Berkeley: Center for 
South and Southeast Asia Studies, University of 
California 
Bernard Tranel 1999. Optional Schwa Deletion: on 
syllable economy in French. Formal 
Perspectives on Romance Linguistics, Ed. By J. 
Mark Authier, Barbar S. Bullock, & Lisa A. 
Reed.  
T. Vennemann 1988. Preference Laws for Syllable 
Structures. Mouton de Gruyter, Berlin 
 
TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 81?88,
Rochester, April 2007 c?2007 Association for Computational Linguistics
How Difficult is it to Develop a Perfect Spell-checker?
A Cross-linguistic Analysis through Complex Network Approach
Monojit Choudhury1, Markose Thomas2, Animesh Mukherjee1,
Anupam Basu1, and Niloy Ganguly1
1Department of Computer Science and Engineering, IIT Kharagpur, India
{monojit,animeshm,anupam,niloy}@cse.iitkgp.ernet.in
2Google Inc. Bangalore, India
markysays@gmail.com
Abstract
The difficulties involved in spelling er-
ror detection and correction in a lan-
guage have been investigated in this work
through the conceptualization of SpellNet
? the weighted network of words, where
edges indicate orthographic proximity be-
tween two words. We construct SpellNets
for three languages - Bengali, English and
Hindi. Through appropriate mathemati-
cal analysis and/or intuitive justification,
we interpret the different topological met-
rics of SpellNet from the perspective of
the issues related to spell-checking. We
make many interesting observations, the
most significant among them being that
the probability of making a real word error
in a language is propotionate to the aver-
age weighted degree of SpellNet, which is
found to be highest for Hindi, followed by
Bengali and English.
1 Introduction
Spell-checking is a well researched area in NLP,
which deals with detection and automatic correc-
tion of spelling errors in an electronic text docu-
ment. Several approaches to spell-checking have
been described in the literature that use statistical,
rule-based, dictionary-based or hybrid techniques
(see (Kukich, 1992) for a dated but substantial sur-
vey). Spelling errors are broadly classified as non-
word errors (NWE) and real word errors (RWE). If
the misspelt string is a valid word in the language,
then it is called an RWE, else it is an NWE. For ex-
ample, in English, the word ?fun? might be misspelt
as ?gun? or ?vun?; while the former is an RWE, the
latter is a case of NWE. It is easy to detect an NWE,
but correction process is non-trivial. RWE, on the
other hand are extremely difficult to detect as it re-
quires syntactic and semantic analysis of the text,
though the difficulty of correction is comparable to
that of NWE (see (Hirst and Budanitsky, 2005) and
references therein).
Given a lexicon of a particular language, how
hard is it to develop a perfect spell-checker for that
language? Since context-insensitive spell-checkers
cannot detect RWE and neither they can effectively
correct NWE, the difficulty in building a perfect
spell-checker, therefore, is reflected by quantities
such as the probability of a misspelling being RWE,
probability of more than one word being orthograph-
ically closer to an NWE, and so on. In this work,
we make an attempt to understand and formalize
some of these issues related to the challenges of
spell-checking through a complex network approach
(see (Albert and Baraba?si, 2002; Newman, 2003)
for a review of the field). This in turn allows us to
provide language-specific quantitative bounds on the
performance level of spell-checkers.
In order to formally represent the orthographic
structure (spelling conventions) of a language, we
conceptualize the lexicon as a weighted network,
where the nodes represent the words and the weights
of the edges indicate the orthoraphic similarity be-
tween the pair of nodes (read words) they connect.
We shall call this network the Spelling Network or
SpellNet for short. We build the SpellNets for three
languages ? Bengali, English and Hindi, and carry
out standard topological analysis of the networks
following complex network theory. Through appro-
priate mathematical analysis and/or intuitive justi-
81
fication, we interpret the different topological met-
rics of SpellNet from the perspective of difficulties
related to spell-checking. Finally, we make sev-
eral cross-linguistic observations, both invariances
and variances, revealing quite a few interesting facts.
For example, we see that among the three languages
studied, the probability of RWE is highest in Hindi
followed by Bengali and English. A similar obser-
vation has been previously reported in (Bhatt et al,
2005) for RWEs in Bengali and English.
Apart from providing insight into spell-checking,
the complex structure of SpellNet alo reveals the
self-organization and evolutionary dynamics under-
lying the orthographic properties of natural lan-
guages. In recent times, complex networks have
been successfully employed to model and explain
the structure and organization of several natural
and social phenomena, such as the foodweb, pro-
tien interaction, formation of language invento-
ries (Choudhury et al, 2006), syntactic structure of
languages (i Cancho and Sole?, 2004), WWW, social
collaboration, scientific citations and many more
(see (Albert and Baraba?si, 2002; Newman, 2003)
and references therein). This work is inspired by
the aforementioned models, and more specifically
a couple of similar works on phonological neigh-
bors? network of words (Kapatsinski, 2006; Vite-
vitch, 2005), which try to explain the human per-
ceptual and cognitive processes in terms of the orga-
nization of the mental lexicon.
The rest of the paper is organized as follows. Sec-
tion 2 defines the structure and construction pro-
cedure of SpellNet. Section 3 and 4 describes the
degree and clustering related properties of Spell-
Net and their significance in the context of spell-
checking, respectively. Section 5 summarizes the
findings and discusses possible directions for future
work. The derivation of the probability of RWE in a
language is presented in Appendix A.
2 SpellNet: Definition and Construction
In order to study and formalize the orthographic
characteristics of a language, we model the lexicon
? of the language as an undirected and fully con-
nected weighted graph G(V,E). Each word w ? ?
is represented by a vertex vw ? V , and for every
pair of vertices vw and vw? in V , there is an edge
Figure 1: The structure of SpellNet: (a) the weighted
SpellNet for 6 English words, (b) Thresholded coun-
terpart of (a), for ? = 1
(vw, vw?) ? E. The weight of the edge (vw, vw?), is
equal to ed(w,w?) ? the orthographic edit distance
between w and w? (considering substitution, dele-
tion and insertion to have a cost of 1). Each node
vw ? V is also assigned a node weight WV (vw)
equal to the unigram occurrence frequency of the
word w. We shall refer to the graph G(V,E) as the
SpellNet. Figure 1(a) shows a hypothetical SpellNet
for 6 common English words.
We define unweighted versions of the graph
G(V,E) through the concept of thresholding as
described below. For a threshold ?, the graph
G?(V,E?) is an unweighted sub-graph of G(V,E),
where an edge (vw, vw?) ? E is assigned a weight 1
in E? if and only if the weight of the edge is less than
or equal to ?, else it is assigned a weight 0. In other
words, E? consists of only those edges in E whose
edge weight is less than or equal to ?. Note that all
the edges in E? are unweighted. Figure 1(b) shows
the thresholded SpellNet shown in 1(a) for ? = 1.
2.1 Construction of SpellNets
We construct the SpellNets for three languages ?
Bengali, English and Hindi. While the two Indian
languages ? Bengali and Hindi ? use Brahmi derived
scripts ? Bengali and Devanagari respectively, En-
glish uses the Roman script. Moreover, the orthog-
raphy of the two Indian languages are highly phone-
mic in nature, in contrast to the morpheme-based or-
thography of English. Another point of disparity lies
in the fact that while the English alphabet consists
of 26 characters, the alphabet size of both Hindi and
Bengali is around 50.
82
The lexica for the three languages have
been taken from public sources. For En-
glish it has been obtained from the website
www.audiencedialogue.org/susteng.html; for Hindi
and Bengali, the word lists as well as the unigram
frequencies have been estimated from the mono-
lingual corpora published by Central Institute of
Indian Languages. We chose to work with the most
frequent 10000 words, as the medium size of the
two Indian language corpora (around 3M words
each) does not provide sufficient data for estimation
of the unigram frequencies of a large number
of words (say 50000). Therefore, all the results
described in this work pertain to the SpellNets
corresponding to the most frequent 10000 words.
However, we believe that the trends observed do not
reverse as we increase the size of the networks.
In this paper, we focus on the networks at three
different thresholds, that is for ? = 1, 3, 5, and study
the properties of G? for the three languages. We
do not go for higher thresholds as the networks be-
come completely connected at ? = 5. Table 1 re-
ports the values of different topological metrics of
the SpellNets for the three languages at three thresh-
olds. In the following two sections, we describe in
detail some of the topological properties of Spell-
Net, their implications to spell-checking, and obser-
vations in the three languages.
3 Degree Distribution
The degree of a vertex in a network is the number of
edges incident on that vertex. Let Pk be the prob-
ability that a randomly chosen vertex has degree k
or more than k. A plot of Pk for any given network
can be formed by making a histogram of the degrees
of the vertices, and this plot is known as the cumu-
lative degree distribution of the network (Newman,
2003). The (cumulative) degree distribution of a net-
work provides important insights into the topologi-
cal properties of the network.
Figure 2 shows the plots for the cumulative de-
gree distribution for ? = 1, 3, 5, plotted on a log-
linear scale. The linear nature of the curves in the
semi-logarithmic scale indicates that the distribution
is exponential in nature. The exponential behaviour
is clearly visible for ? = 1, however at higher thresh-
olds, there are very few nodes in the network with
low degrees, and therefore only the tail of the curve
shows a pure exponential behavior. We also observe
that the steepness (i.e. slope) of the log(Pk) with re-
spect to k increases with ?. It is interesting to note
that although most of the naturally and socially oc-
curring networks exhibit a power-law degree distri-
bution (see (Albert and Baraba?si, 2002; Newman,
2003; i Cancho and Sole?, 2004; Choudhury et al,
2006) and references therein), SpellNets feature ex-
ponential degree distribution. Nevertheless, similar
results have also been reported for the phonological
neighbors? network (Kapatsinski, 2006).
3.1 Average Degree
Let the degree of the node v be denoted by k(v). We
define the quantities ? the average degree ?k? and the
weighted average degree ?kwt? for a given network
as follows (we drop the subscript w for clarity of
notation).
?k? = 1N
?
v?V
k(v) (1)
?kwt? =
?
v?V k(v)WV (v)?
v?V WV (v)
(2)
where N is the number of nodes in the network.
Implication: The average weighted degree of
SpellNet can be interpreted as the probability of
RWE in a language. This correlation can be derived
as follows. Given a lexicon ? of a language, it can
be shown that the probability of RWE in a language,
denoted by prwe(?) is given by the following equa-
tion (see Appendix A for the derivation)
prwe(?) =
?
w??
?
w???
w 6=w?
?ed(w,w?)p(w) (3)
Let neighbor(w, d) be the number of words in ?
whose edit distance from w is d. Eqn 3 can be rewrit-
ten in terms of neighbor(w, d) as follows.
prwe(?) =
?
w??
??
d=1
?d neighbor(w, d)p(w) (4)
Practically, we can always assume that d is bounded
by a small positive integer. In other words, the
number of errors simultaneously made on a word
is always small (usually assumed to be 1 or a
83
English Hindi Bengali
? = 1 ? = 3 ? = 5 ? = 1 ? = 3 ? = 5 ? = 1 ? = 3 ? = 5
M 8.97k 0.70M 8.46M 17.6k 1.73M 17.1M 11.9k 1.11M 13.2M
?k? 2.79 140.25 1692.65 4.52 347.93 3440.06 3.38 223.72 2640.11
?kwt? 6.81 408.03 1812.56 13.45 751.24 4629.36 7.73 447.16 3645.37
rdd 0.696 0.480 0.289 0.696 0.364 0.129 0.702 0.389 0.155?CC? 0.101 0.340 0.563 0.172 0.400 0.697 0.131 0.381 0.645
?CCwt? 0.221 0.412 0.680 0.341 0.436 0.760 0.229 0.418 0.681
?l? 7.07 3.50 N.E 7.47 2.74 N.E 8.19 2.95 N.E
D 24 14 N.E 26 12 N.E 29 12 N.E
Table 1: Various topological metrics and their associated values for the SpellNets of the three languages
at thresholds 1, 3 and 5. Metrics: M ? number of edges; ?k? ? average degree; ?kwt? ? average weighted
degree; ?CC? ? average clustering coefficient; ?CCwt? - average weighted clustering coefficient; rdd ?
Pearson correlation coefficient between degrees of neighbors; ?l? ? average shortest path; D ? diameter.
N.E ? Not Estimated. See the text for further details on definition, computation and significance of the
metrics.
 1e-04
 0.001
 0.01
 0.1
 1
 0  10  20  30  40  50  60
P k
Degree
Threshold 1
EnglishHindiBengali
 1e-04
 0.001
 0.01
 0.1
 1
 0  500  1000  1500  2000  2500
P k
Degree
Threshold 3
EnglishHindiBengali
 1e-04
 0.001
 0.01
 0.1
 1
 0  1000 2000 3000 4000 5000 6000 7000 8000
P k
Degree
Threshold 5
EnglishHindiBengali
Figure 2: Cumulative degree distribution of SpellNets at different thresholds presented in semi-logarithmic
scale.
slowly growing function of the word length (Kukich,
1992)). Let us denote this bound by ?. Therefore,
prwe(?) ?
?
w??
??
d=1
?d neighbor(w, d)p(w) (5)
Since ? < 1, we can substitute ?d by ? to get an
upper bound on prwe(?), which gives
prwe(?) < ?
?
w??
??
d=1
neighbor(w, d)p(w) (6)
The term ??d=1 neighbor(w, d) computes the
number of words in the lexicon, whose edit distance
from w is atmost ?. This is nothing but k(vw), i.e.
the degree of the node vw, in G?. Moreover, the term
p(w) is proportionate to the node weight WV (vw).
Thus, rewriting Eqn 6 in terms of the network pa-
rameters for G?, we get (subscript w is dropped for
clarity)
prwe(?) < ?
?
v?V k(v)WV (v)?
v?V WV (v)
(7)
Comparing Eqn 2 with the above equation, we can
directly obtain the relation
prwe(?) < C1?kwt? (8)
where C1 is some constant of proportionality. Note
that for ? = 1, prwe(?) ? ?kwt?. If we ignore
the distribution of the words, that is if we assume
p(w) = 1/N , then prwe(?) ? ?k?.
Thus, the quantity ?kwt? provides a good estimate
of the probability of RWE in a language.
Observations and Inference: At ? = 1, the av-
erage weighted degrees for Hindi, Bengali and En-
glish are 13.81, 7.73 and 6.61 respectively. Thus, the
probability of RWE in Hindi is significantly higher
84
 1
 10
 100
 10  100  1000  10000 100000 1e+06
Deg
ree
Frequency
Threshold 1
 1
 10
 100
 1000
 10000
 10  100  1000 10000 100000 1e+06
Deg
ree
Frequency
Threshold 3
 1
 10
 100
 1000
 10000
 10  100  1000 10000 100000 1e+06
Deg
ree
Frequency
Threshold 5
Figure 3: Scatter-plots for degree versus unigram
frequency at different ? for Hindi
than that of Bengali, which in turn is higher than
that of English (Bhatt et al, 2005). Similar trends
are observed at all the thresholds for both ?kwt? and
?k?. This is also evident from Figures 2, which show
the distribution of Hindi to lie above that of Bengali,
which lies above English (for all thresholds).
The average degree ?k? is substantially smaller
(0.5 to 0.33 times) than the average weighted de-
gree ?kwt? for all the 9 SpellNets. This suggests
that the higher degree nodes in SpellNet have higher
node weight (i.e. occurrence frequency). Indeed, as
shown in Figure 3 for Hindi, the high unigram fre-
quency of a node implies higher degree, though the
reverse is not true. The scatter-plots for the other
languages are similar in nature.
3.2 Correlation between Degrees of Neighbors
The relation between the degrees of adjacent words
is described by the degree assortativity coefficient.
One way to define the assortativity of a network is
through the Pearson correlation coefficient between
the degrees of the two vertices connected by an edge.
Each edge (u, v) in the network adds a data item
corresponding to the degrees of u and v to two data
sets x and y respectively. The Pearson correlation
coefficient for the data sets x and y of n items each
is then defined as
r = n
?xy ??x? y?[n?x2 ? (?x)2][n? y2 ? (? y)2]
Observation: r is positive for the networks in
which words tend to associate with other words of
similar degree (i.e. high degree with high degree
and vice versa), and it is negative for networks in
which words associate with words having degrees
in the opposite spectrum. Refering to table 1, we
see that the correlation coefficient rdd is roughly the
same and equal to around 0.7 for all languages at
? = 1. As ? increases, the correlation decreases as
expected, due to the addition of edges between dis-
similar words.
Implication: The high positive correlation coeffi-
cients suggest that SpellNets feature assortative mix-
ing of nodes in terms of degrees. If there is an RWE
corresponding to a high degree node vw, then due
to the assortative mixing of nodes, the misspelling
w? obtained from w, is also expected to have a high
degree. Since w? has a high degree, even after detec-
tion of the fact that w? is a misspelling, choosing the
right suggestion (i.e. w) is extremely difficult un-
less the linguistic context of the word is taken into
account. Thus, more often than not it is difficult to
correct an RWE, even after successful detection.
4 Clustering and Small World Properties
In the previous section, we looked at some of the de-
gree based features of SpellNets. These features pro-
vide us insights regarding the probability of RWE in
a language and the level of difficulty in correcting
the same. In this section, we discuss some of the
other characteristics of SpellNets that are useful in
predicting the difficulty of non-word error correc-
tion.
4.1 Clustering Coefficient
Recall that in the presence of a complete list of valid
words in a language, detection of NWE is a trivial
task. However, correction of NWE is far from triv-
ial. Spell-checkers usually generate a suggestion list
of possible candidate words that are within a small
edit distance of the misspelling. Thus, correction be-
comes hard as the number of words within a given
edit distance from the misspelling increases. Sup-
pose that a word w ? ? is transformed into w? due
to some typing error, such that w? /? ?. Also assume
that ed(w,w?) ? ?. We want to estimate the number
of words in ? that are within an edit distance ? of
w?. In other words we are interested in finding out
the degree of the node vw? in G?, but since there is
no such node in SpellNet, we cannot compute this
quantity directly. Nevertheless, we can provide an
85
approximate estimate of the same as follows.
Let us conceive of a hypothetical node vw? . By
definition of SpellNet, there should be an edge con-
necting vw? and vw in G?. A crude estimate of
k(vw?) can be ?kwt? of G?. Due to the assortative
nature of the network, we expect to see a high corre-
lation between the values of k(vw) and k(vw?), and
therefore, a slightly better estimate of k(vw?) could
be k(vw). However, as vw? is not a part of the net-
work, it?s behavior in SpellNet may not resemble
that of a real node, and such estimates can be grossly
erroneous.
One way to circumvent this problem is to look
at the local neighborhood of the node vw. Let us
ask the question ? what is the probability that two
randomly chosen neighbors of vw in G? are con-
nected to each other? If this probability is high, then
we can expect the local neighborhood of vw to be
dense in the sense that almost all the neighbors of
vw are connected to each other forming a clique-like
local structure. Since vw? is a neighbor of vw, it is
a part of this dense cluster, and therefore, its degree
k(vw?) is of the order of k(vw). On the other hand,
if this probability is low, then even if k(vw) is high,
the space around vw is sparse, and the local neigh-
borhood is star-like. In such a situation, we expect
k(vw?) to be low.
The topological property that measures the prob-
ability of the neighbors of a node being connected
is called the clustering coefficient (CC). One of the
ways to define the clustering coefficient C(v) for a
vertex v in a network is
C(v) = number of triangles connected to vertex vnumber of triplets centered on v
For vertices with degree 0 or 1, we put C(v) = 0.
Then the clustering coefficient for the whole net-
work ?CC? is the mean CC of the nodes in the net-
work. A corresponding weighted version of the CC
?CCwt? can be defined by taking the node weights
into account.
Implication: The higher the value of
k(vw)C(vw) for a node, the higher is the probability
that an NWE made while typing w is hard to correct
due to the presence of a large number of ortho-
graphic neighbors of the misspelling. Therefore,
in a way ?CCwt? reflects the level of difficulty in
correcting NWE for the language in general.
Observation and Inference: At threshold 1,
the values of ?CC? as well as ?CCwt? is higher
for Hindi (0.172 and 0.341 respectively) and Ben-
gali (0.131 and 0.229 respectively) than that of En-
glish (0.101 and 0.221 respectively), though for
higher thresholds, the difference between the CC
for the languages reduces. This observation further
strengthens our claim that the level of difficulty in
spelling error detection and correction are language
dependent, and for the three languages studied, it is
hardest for Hindi, followed by Bengali and English.
4.2 Small World Property
As an aside, it is interesting to see whether the Spell-
Nets exhibit the so called small world effect that is
prevalent in many social and natural systems (see
(Albert and Baraba?si, 2002; Newman, 2003) for def-
inition and examles). A network is said to be a small
world if it has a high clustering coefficient and if the
average shortest path between any two nodes of the
network is small.
Observation: We observe that SpellNets indeed
feature a high CC that grows with the threshold. The
average shortest path, denoted by ?l? in Table 1, for
? = 1 is around 7 for all the languages, and reduces
to around 3 for ? = 3; at ? = 5 the networks are
near-cliques. Thus, SpellNet is a small world net-
work.
Implication: By the application of triangle in-
equality of edit distance, it can be easily shown that
?l? ? ? provides an upper bound on the average edit
distance between all pairs of the words in the lexi-
con. Thus, a small world network, which implies a
small ?l?, in turn implies that as we increase the error
bound (i.e. ?), the number of edges increases sharply
in the network and soon the network becomes fully
connected. Therefore, it becomes increasingly more
difficult to correct or detect the errors, as any word
can be a possible suggestion for any misspelling. In
fact this is independently observed through the ex-
ponential rise in M ? the number of edges, and fall
in ?l? as we increase ?.
Inference: It is impossible to correct very noisy
texts, where the nature of the noise is random and
words are distorted by a large edit distance (say 3 or
more).
86
5 Conclusion
In this work, we have proposed the network of ortho-
graphic neighbors of words or the SpellNet and stud-
ied the structure of the same across three languages.
We have also made an attempt to relate some of the
topological properties of SpellNet to spelling error
distribution and hardness of spell-checking in a lan-
guage. The important observations of this study are
summarized below.
? The probability of RWE in a language can
be equated to the average weighted degree of
SpellNet. This probablity is highest in Hindi
followed by Bengali and English.
? In all the languages, the words that are more
prone to undergo an RWE are more likely to be
misspelt. Effectively, this makes RWE correc-
tion very hard.
? The hardness of NWE correction correlates
with the weighted clustering coefficient of the
network. This is highest for Hindi, followed by
Bengali and English.
? The basic topology of SpellNet seems to be an
invariant across languages. For example, all
the networks feature exponential degree distri-
bution, high clustering, assortative mixing with
respect to degree and node weight, small world
effect and positive correlation between degree
and node weight, and CC and degree. However,
the networks vary to a large extent in terms of
the actual values of some of these metrics.
Arguably, the language-invariant properties of
SpellNet can be attributed to the organization of
the human mental lexicon (see (Kapatsinski, 2006)
and references therein), self-organization of ortho-
graphic systems and certain properties of edit dis-
tance measure. The differences across the lan-
guages, perhaps, are an outcome of the specific or-
thographic features, such as the size of the alphabet.
Another interesting observation is that the phonemic
nature of the orthography strongly correlates with
the difficulty of spell-checking. Among the three
languages, Hindi has the most phonemic and En-
glish the least phonemic orthography. This corre-
lation calls for further investigation.
Throughout the present discussion, we have fo-
cussed on spell-checkers that ignore the context;
consequently, many of the aforementioned results,
especially those involving spelling correction, are
valid only for context-insensitive spell-checkers.
Nevertheless, many of the practically useful spell-
checkers incorporate context information and the
current analysis on SpellNet can be extended for
such spell-checkers by conceptualizing a network
of words that capture the word co-occurrence pat-
terns (Biemann, 2006). The word co-occurrence
network can be superimposed on SpellNet and the
properties of the resulting structure can be appro-
priately analyzed to obtain similar bounds on hard-
ness of context-sensitive spell-checkers. We deem
this to be a part of our future work. Another way
to improve the study could be to incorporate a more
realistic measure for the orthographic similarity be-
tween the words. Nevertheless, such a modification
will have no effect on the analysis technique, though
the results of the analysis may be different from the
ones reported here.
Appendix A: Derivation of the Probability
of RWE
We take a noisy channel approach, which is a com-
mon technique in NLP (for example (Brown et al,
1993)), including spellchecking (Kernighan et al,
1990). Depending on the situation. the channel may
model typing or OCR errors. Suppose that a word w,
while passing through the channel, gets transformed
to a word w?. Therefore, the aim of spelling cor-
rection is to find the w? ? ? (the lexicon), which
maximizes p(w?|w?), that is
argmax
w??
p(w|w?) = argmax
w??
p(w?|w)p(w)
(9)
The likelihood p(w?|w) models the noisy channel,
whereas the term p(w) is traditionally referred to
as the language model (see (Jurafsky and Martin,
2000) for an introduction). In this equation, as well
as throughout this discussion, we shall assume a uni-
gram language model, where p(w) is the normalized
frequency of occurrence of w in a standard corpus.
We define the probability of RWE for a word w,
87
prwe(w), as follows
prwe(w) =
?
w???
w 6=w?
p(w?|w) (10)
Stated differently, prwe(w) is a measure of the prob-
ability that while passing through the channel, w
gets transformed into a form w?, such that w? ? ?
and w? 6= w. The probability of RWE in the lan-
guage, denoted by prwe(?), can then be defined in
terms of the probability prwe(w) as follows.
prwe(?) =
?
w??
prwe(w)p(w) (11)
=
?
w??
?
w???
w 6=w?
p(w?|w)p(w)
In order to obtain an estimate of the likelihood
p(w?|w), we use the concept of edit distance (also
known as Levenstein distance (Levenstein, 1965)).
We shall denote the edit distance between two words
w and w? by ed(w,w?). If we assume that the proba-
bility of a single error (i.e. a character deletion, sub-
stitution or insertion) is ? and errors are independent
of each other, then we can approximate the likeli-
hood estimate as follows.
p(w?|w) = ?ed(w,w?) (12)
Exponentiation of edit distance is a common mea-
sure of word similarity or likelihood (see for exam-
ple (Bailey and Hahn, 2001)).
Substituting for p(w?|w) in Eqn 11, we get
prwe(?) =
?
w??
?
w???
w 6=w?
?ed(w,w?)p(w) (13)
References
R. Albert and A. L. Baraba?si. 2002. Statistical mechan-
ics of complex networks. Reviews of Modern Physics,
74:47?97.
Todd M. Bailey and Ulrike Hahn. 2001. Determinants of
wordlikeness: Phonotactics or lexical neighborhoods?
Journal of Memory and Language, 44:568 ? 591.
A. Bhatt, M. Choudhury, S. Sarkar, and A. Basu. 2005.
Exploring the limits of spellcheckers: A compara-
tive study in bengali and english. In Proceedings of
the Symposium on Indian Morphology, Phonology and
Language Engineering (SIMPLE?05), pages 60?65.
C. Biemann. 2006. Unsupervised part-of-speech tag-
ging employing efficient graph clustering. In Pro-
ceedings of the COLING/ACL 2006 Student Research
Workshop, pages 7?12.
P. F. Brown, S. A. D. Pietra, V. J. D. Pietra, and R. L.
Mercer. 1993. The mathematics of statistical machine
translation: Parameter estimation. Computational Lin-
guistics, 19(2):263?312.
M. Choudhury, A. Mukherjee, A. Basu, and N. Ganguly.
2006. Analysis and synthesis of the distribution of
consonants over languages: A complex network ap-
proach. In Proceedings of the COLING/ACL Main
Conference Poster Sessions, pages 128?135.
G. Hirst and A. Budanitsky. 2005. Correcting real-word
spelling errors by restoring lexical cohesion. Natural
Language Engineering, 11:87 ? 111.
R. Ferrer i Cancho and R. V. Sole?. 2004. Patterns in
syntactic dependency networks. Physical Review E,
69:051915.
D. Jurafsky and J. H. Martin. 2000. An Introduction
to Natural Language Processing, Computational Lin-
guistics, and Speech Recognition. Prentice Hall.
V. Kapatsinski. 2006. Sound similarity relations in
the mental lexicon: Modeling the lexicon as a com-
plex network. Speech research Lab Progress Report,
27:133 ? 152.
M. D. Kernighan, K. W. Church, and W. A. Gale. 1990.
A spelling correction program based on a noisy chan-
nel model. In Proceedings of COLING, pages 205?
210, NJ, USA. ACL.
K. Kukich. 1992. Technique for automatically correcting
words in text. ACM Computing Surveys, 24:377 ? 439.
V. I. Levenstein. 1965. Binary codes capable of cor-
recting deletions, insertions and reversals. Doklady
Akademii Nauk SSSR, 19:1 ? 36.
M. E. J. Newman. 2003. The structure and function of
complex networks. SIAM Review, 45:167?256.
M. S. Vitevitch. 2005. Phonological neighbors in a small
world: What can graph theory tell us about word learn-
ing? Spring 2005 Talk Series on Networks and Com-
plex Systems, Indiana University.
88
Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 65?74,
Prague, June 2007. c?2007 Association for Computational Linguistics
Evolution, Optimization, and Language Change:
The Case of Bengali Verb Inflections
Monojit Choudhury1, Vaibhav Jalan2, Sudeshna Sarkar1, Anupam Basu1
1 Department of Computer Science and Engineering
Indian Institute of Technology, Kharagpur, India
{monojit,sudeshna,anupam}@cse.iitkgp.ernet.in
2 Department of Computer Engineering
Malaviya National Institute of Technology, Jaipur, India
vaibhavjalan.mnit@gmail.com
Abstract
The verb inflections of Bengali underwent
a series of phonological change between
10th and 18th centuries, which gave rise
to several modern dialects of the language.
In this paper, we offer a functional ex-
planation for this change by quantifying
the functional pressures of ease of artic-
ulation, perceptual contrast and learnabil-
ity through objective functions or con-
straints, or both. The multi-objective and
multi-constraint optimization problem has
been solved through genetic algorithm,
whereby we have observed the emergence
of Pareto-optimal dialects in the system
that closely resemble some of the real
ones.
1 Introduction
Numerous theories have been proposed to explain
the phenomenon of linguistic change, which, of late,
are also being supported by allied mathematical or
computational models. See (Steels, 1997; Perfors,
2002) for surveys on computational models of lan-
guage evolution, and (Wang et al, 2005; Niyogi,
2006) for reviews of works on language change.
The aim of these models is to explain why and how
languages change under specific socio-cognitive as-
sumptions. Although computational modeling is a
useful tool in exploring linguistic change (Cangelosi
and Parisi, 2002), due to the inherent complexi-
ties of our linguistic and social structures, modeling
of real language change turns out to be extremely
hard. Consequently, with the exception of a few
(e.g., Hare and Elman (1995); Dras et al (2003);
Ke et al (2003); Choudhury et al (2006b)), all the
mathematical and computational models developed
for explaining language change are built for artifi-
cial toy languages. This has led several researchers
to cast a doubt on the validity of the current compu-
tational models as well as the general applicability
of computational techniques in diachronic explana-
tions (Hauser et al, 2002; Poibeau, 2006).
In this paper, we offer a functional explanation1
of a real world language change ? the morpho-
phonological change affecting the Bengali verb
inflections (BVI). We model the problem as a
multi-objective and multi-constraint optimization
and solve the same using Multi-Objective Genetic
Algorithm2 (MOGA). We show that the different
forms of the BVIs, as found in the several modern
dialects, automatically emerge in the MOGA frame-
work under suitable modeling of the objective and
constraint functions. The model also predicts several
1Functionalist accounts of language change invoke the basic
function of language, i.e. communication, as the driving force
behind linguistic change (Boersma, 1998). Stated differently,
languages change in a way to optimize their function, such that
speakers can communicate maximum information with min-
imum effort (ease of articulation) and ambiguity (perceptual
contrast). Often, ease of learnability is also considered a func-
tional benefit. For an overview of different explanations in di-
achronic linguistics see (Kroch, 2001) and Ch. 3 of (Blevins,
2004).
2Genetic algorithm was initially proposed by Hol-
land (1975) as a self-organizing adaptation process mimicking
the biological evolution. They are also used for optimization
and machine learning purposes, especially when the nature of
the solution space is unknown or there are more than one objec-
tive functions. See Goldberg (1989) for an accessible introduc-
tion to single and multi-objective Genetic algorithms. Note that
in case of a multi-objective optimization problem, MOGA gives
a set of Pareto-optimal solutions rather than a single optimum.
The concept of Pareto-optimality is defined later.
65
other possible dialectal forms of Bengali that seems
linguistically plausible and might exist or have ex-
isted in the past, present or future. Note that the
evolutionary algorithm (i.e., MOGA) has been used
here as a tool for optimization, and has no relevance
to the evolution of the dialects as such.
Previously, Redford et al (2001) has modeled the
emergence of syllable systems in a multi-constraint
and multi-objective framework using Genetic al-
gorithms. Since the model fuses the individual
objectives into a single objective function through
a weighted linear combination, it is not a multi-
objective optimization in its true sense and nei-
ther does it use MOGA for the optimization pro-
cess. Nevertheless, the present work draws heavily
from the quantitative formulation of the objectives
and constraints described in (Redford, 1999; Red-
ford and Diehl, 1999; Redford et al, 2001). Ke et
al. (2003) has demonstrated the applicability and ad-
vantages of MOGA in the context of the vowel and
tonal systems, but the model is not explicit about the
process of change that could give rise to the optimal
vowel systems. As we shall see that the conception
of the genotype, which is arguably the most impor-
tant part of any MOGA model, is a novel and signif-
icant contribution of this work. The present formu-
lation of the genotype not only captures a snapshot
of the linguistic system, but also explicitly models
the course of change that has given rise to the partic-
ular system. Thus, we believe that the current model
is more suitable in explaining a case of linguistic
change.
The paper is organized as follows: Sec. 2 intro-
duces the problem of historical change affecting the
BVIs and presents a mathematical formulation of the
same; Sec. 3 describes the MOGA model; Sec. 4
reports the experiments, observations and their in-
terpretations; Sec. 5 concludes the paper by sum-
marizing the contributions. In this paper, Bengali
graphemes are represented in Roman script follow-
ing the ITRANS notation (Chopde, 2001). Since
Bengali uses a phonemic orthography, the phonemes
are also transcribed using ITRANS within two /s.
2 The Problem
Bengali is an agglutinative language. There are
more than 150 different inflected forms of a single
Attributes Classical (?0) SCB ACB Sylheti
PrS1 kari kori kori kori
PrS2 kara karo kara kara
PrS3 kare kare kare kare
PrSF karen karen karen karoin
PrC1 kariteChi korChi kartAsi koirtAsi
PrC2 kariteCha korCho kartAsa koirtAsae
PrC3 kariteChe korChe kartAse koirtAse
PrCF kariteChen korChen kartAsen kortAsoin
PrP1 kariAChi koreChi korsi koirsi
PrP2 kariACha koreCho karsa koirsae
PrP3 kariAChe koreChe karse koirse
PrPF kariAChen koreChen karsen korsoin
Table 1: The different inflected verb forms of Clas-
sical Bengali and three other modern dialects. All
the forms are in the phonetic forms and for the verb
root kar. Legend: (tense) Pr ? present; (aspects) S
? simple, C ? continuous, P ? perfect, ; (person) 1
? first, 2 ? second normal, 3 ? third, F ? formal in
second and third persons. See (Bhattacharya et al,
2005) for list of all the forms.
verb root in Bengali, which are obtained through af-
fixation of one of the 52 inflectional suffixes, option-
ally followed by the emphasizers. The suffixes mark
for the tense, aspect, modality, person and polarity
information (Bhattacharya et al, 2005). The ori-
gin of modern Bengali can be traced back to Vedic
Sanskrit (circa 1500 BC 600 BC), which during
the middle Indo-Aryan period gave rise to the di-
alects like Ma?gadhi?, and Ardhama?gadhi? (circa
600 BC 200 AD), followed by the Ma?gadhi? ?
apabhramsha, and finally crystallizing to Bengali
(circa 10th century AD) (Chatterji, 1926). The ver-
bal inflections underwent a series of phonological
changes during the middle Bengali period (1200 -
1800 AD), which gave rise to the several dialectal
forms of Bengali, including the standard form ? the
Standard Colloquial Bengali (SCB).
The Bengali literature of the 19th century was
written in the Classical Bengali dialect or the
sa?dhubha?sha? that used the older verb forms and
drew heavily from the Sanskrit vocabulary, even
though the forms had disappeared from the spoken
dialects by 17th century. Here, we shall take the lib-
erty to use the terms ?classical forms? and ?Classi-
cal Bengali? to refer to the dialectal forms of middle
Bengali and not Classical Bengali of the 19th cen-
66
tury literature. Table 1 enlists some of the corre-
sponding verb forms of classical Bengali and SCB.
Table 3 shows the derivation of some of the current
verb inflections of SCB from its classical counter-
parts as reported in (Chatterji, 1926).
2.1 Dialect Data
Presently, there are several dialects of Bengali that
vary mainly in terms of the verb inflections and in-
tonation, but rarely over syntax or semantics. We do
not know of any previous study, during which the
different dialectal forms for BVI were collected and
systematically listed. Therefore, we have collected
dialectal data for the following three modern dialects
of Bengali by enquiring the na?ive informants.
? Standard Colloquial Bengali (SCB) spoken in a
region around Kolkata, the capital of West Ben-
gal,
? Agartala Colloquial Bengali (ACB) spoken in
and around Agartala, the capital of Tripura, and
? Sylheti, the dialect of the Sylhet region of
Bangladesh.
Some of the dialectal forms are listed in Table 1.
The scope of the current study is restricted to 28 in-
flected forms (12 present tense forms + 12 past tense
forms + 4 forms of habitual past) of a single verb
root, i.e., kar.
2.2 Problem Formulation
Choudhury et al (2006a) has shown that a sequence
of simple phonological changes, which we shall
call the Atomic Phonological Operators or APO for
short, when applied to the classical Bengali lexicon,
gives rise to the modern dialects. We conceive of
four basic types of APOs, namely Del or deletion,
Met or metathesis, Asm or assimilation, and Mut
or mutation. The complete specification of an APO
includes specification of its type, the phoneme(s)
that is(are) affected by the operation and the left and
right context of application of the operator specified
as regular expressions on phonemes. The seman-
tics of the basic APOs in terms of rewrite rules are
shown in Table 2.2. Since Bengali features assim-
ilation only with respect to vowel height, here we
shall interpret Asm(p, LC,RC) as the height as-
similation of the vowel p in the context of LC or
APO Semantics
Del(p, LC,RC) p? ?/LC?RC
Met(pipj , LC,RC) pipj ? pjpi/LC?RC
Asm(p, LC,RC) p? p?/LC?RC
Mut(p, p?, LC,RC) p? p?/LC?RC
Table 2: Semantics of the basic APOs in terms of
rewrite rules. LC and RC are regular expressions
specifying the left and right contexts respectively. p,
p?, pi and pj represent phonemes.
Rule APO Example Derivations
No. kar ? iteChe kar ? iten kar ? iAChi
1 Del(e, ?, Ch) kar ? itChe NA NA
2 Del(t, ?, Ch) kar ? iChe NA NA
3 Met(ri, ?, ?) kair ? Che kair ? ten kair ?AChi
5 Mut(A, e, ?, Ch) NA NA kair-eChi
6 Asm(a, i, ?, ?) koir ? Che koir ? ten koir ? eChi
7 Del(i, o, ?) kor ? Che kor ? ten kor ? eChi
Table 3: Derivations of the verb forms of SCB from
classical Bengali using APOs. ?NA? means the rule
is not applicable for the form. See (Choudhury et
al., 2006a) for the complete list of APOs involved in
the derivation of SCB and ACB forms
RC. Also, we do not consider epenthesis or inser-
tion as an APO, because epenthesis is not observed
for the case of the change affecting BVI.
The motivation behind defining APOs rather than
representing the change in terms of rewrite rules is
as follows. Rewrite rules are quite expressive and
therefore, it is possible to represent complex phono-
logical changes using a single rewrite rule. On the
other hand, APOs are simple phonological changes
that can be explained independently in terms of pho-
netic factors (Ohala, 1993). In fact, there are also
computational models satisfactorily accounting for
cases of vowel deletion (Choudhury et al, 2004;
Choudhury et al, 2006b) and assimilation (Dras et
al., 2003).
Table 3 shows the derivation of the SCB verb
forms from classical Bengali in terms of APOs. The
derivations are constructed based on the data pro-
vided in (Chatterji, 1926).
2.3 Functional Explanation for Change of BVI
Let ?0 be the lexicon of classical Bengali verb
forms. Let ? : ?1, ?2, ? ? ? ?r be a sequence of r
APOs. Application of an APO on a lexicon implies
the application of the operator on every word of the
67
lexicon. The sequence of operators ?, thus, repre-
sent a dialect obtained through the process of change
from ?0, which can be represented as follows.
?(?0) = ?r(? ? ? ?2(?1(?0)) ? ? ?) = ?d
The derivation of the dialect ?d from ?0 can be con-
structed by following the APOs in the sequence of
their application.
We propose the following functional explanation
for the change of BVI.
A sequence of APOs, ? is preferred if ?(?0) has
some functional benefit over ?0. Thus, the modern
Bengali dialects are those, which have some func-
tional advantage over the classical dialect.
We would like to emphasize the word ?some? in
the aforementioned statements, because the modern
dialects are not better than the classical one (i.e., the
ancestor language) in an absolute sense. Rather, the
classical dialect is suboptimal compared to the mod-
ern dialects only with respect to ?some? of the func-
tional forces and is better than the them with respect
to ?some other? forces. Stated differently, we expect
both the classical as well as the modern dialects of
Bengali to be Pareto-optimal3 with respect to the set
of functional forces.
In order to validate the aforementioned hypoth-
esis, we carry out a multi-objective and multi-
constraint optimization over the possible dialectal
forms of Bengali, thereby obtaining the Pareto-
optimal set, which has been achieved through
MOGA.
3 The MOGA Model
Specification of a problem within the MOGA frame-
work requires the definition of the genotype, phe-
notype and genotype-to-phenotype mapping plus the
objective functions and constraints. In this section,
we discuss the design choices explored for the prob-
lem of BVI.
3Consider an optimization problem with n objective func-
tions f1 to fn, where we want to minimize all the objectives.
Let S be the solution space, representing the set of all possible
solutions. A soulution sinS is said to be Pareto-optimal with re-
spect to the objective functions f1 to fn, if and only if there does
not exist any other solution s? ? S such that fi(s?) ? fi(s) for
all 1 ? i ? n and fi(s?) < fi(s) for at least one i.
3.1 Phenotype and Genotype
We define the phenotype of a dialect d to be the lex-
icon of the dialect, ?d, consisting of the 28 inflected
forms of the root verb kar. This choice of phenotype
is justified because, at the end of the optimization
process, we would like to obtain the Pareto-optimal
dialects of Bengali and compare them with their real
counterparts.
The genotype of a dialect d could also be defined
as ?d, where the word forms are the genes. How-
ever, for such a choice of genotype, crossover and
mutation lead to counter-intuitive results. For ex-
ample, mutation would affect only a single word in
the lexicon, which is against the regularity principle
of sound change (see Bhat (2001) for explanation).
Similarly, exchanging a set of words between a pair
of lexica, as crossover would lead to, seems insensi-
ble.
Therefore, considering the basic properties of
sound change as well as the genetic operators used
in MOGA, we define a chromosome (and thus the
genotype) as a sequence of APOs. The salient fea-
tures of the genotype are described below.
? Gene: A gene is defined as an APO. Since in
order to implement the MOGA, every gene must be
mapped to a number, we have chosen an 8-bit binary
representation for a gene. This allows us to spec-
ify 256 distinct genes or APOs. However, for rea-
sons described below, we use the first bit of a gene
to denote whether the gene (i.e., the APO) is active
(the bit is set to 1) or not. Thus, we are left with
128 distinct choices for APOs. Since the number of
words in the lexicon is only 28, the APOs for Del,
Asm andMet are limited, even after accounting for
the various contexts in which an APO is applicable.
Nevertheless, there are numerous choices for Mut.
To restrain the possible repertoire of APOs to 128,
we avoided any APO related to the mutation of con-
sonants. This allowed us to design a comprehensive
set of APOs that are applicable on the classical Ben-
gali lexicon and its derivatives.
? Chromosome: A chromosome is a sequence of
15 genes. The number 15 has been arrived through
experimentation, where we have observed that in-
creasing the length of a chromosome beyond 15
does not yield richer results for the current choice
of APOs and ?0. Since the probability of any gene
68
Figure 1: Schematic of genotype, phenotype and
genotype-to-phenotype mapping.
being switched off (i.e., the first bit being 0) is 0.5,
the expected number of active APOs on a chromo-
some with 15 genes is 7.5. It is interesting to note
that this value is almost equal to the number of APOs
required (7 to be precise) for derivation of the SCB
verb forms.
? Genotype to phenotype mapping: Let for a given
chromosome, the set of active APOs (whose first bit
is 1) in sequence be ?1, ?2, ? ? ? , ?r. Then the pheno-
type corresponding to this chromosome is the lex-
icon ?d = ?r(? ? ? ?2(?1(?0)) ? ? ?). In other words,
the phenotype is the lexicon obtained by successive
application of the active APOs on the chromosome
on the lexicon of classical Bengali.
The concepts of gene, chromosome and the map-
ping from genotype to the phenotype are illustrated
in Fig. 3.1. It is easy to see that the regularity hy-
pothesis regarding the sound change holds good for
the aforementioned choice of genotype. Further-
more, crossover in this context can be interpreted as
a shift in the course of language change. Similarly,
mutation of the first bit turns a gene on or off, and of
the other bits changes the APO. Note that according
to this formulation, a chromosome not only models
a dialect, but also the steps of its evolution from the
classical forms.
3.2 Objectives and Constraints
Formulation of the objective functions and con-
straints are crucial to the model, because the linguis-
tic plausibility, computational tractability and the re-
sults of the model are overtly dependent on them.
We shall define here three basic objectives of ease
of articulation, perceptual contrast and learnability,
which can be expressed as functions or constraints.
Several models have been proposed in the past for
estimating the articulatory effort (Boersma (1998),
Ch. 2, 5 and 7) and perceptual distance between
phonemes and/or syllables (Boersma (1998), Ch.
3, 4 and 8). Nevertheless, as we are interested in
modeling the effort and perceptual contrast of the
whole lexicon rather than a syllable, we have cho-
sen to work with simpler formulations of the objec-
tive functions. Due to paucity of space, we are not
able to provide adequate details and justification for
the choices made.
3.2.1 fe: Articulatory Effort
Articulatory effort of a lexicon ? is a positive real
number that gives an estimate of the effort required
to articulate the words in ? in some unit. If fe de-
notes the effort function, then
fe(?) =
1
|?|
?
w??
fe(w) (1)
The term fe(w) depends on three parameters: 1)
the length of w in terms of phonemes, 2) the struc-
ture of the syllables, and 3) the features of adjacent
phonemes, as they control the effort spent in co-
articulation. We define fe(w) to be a weighted sum
of these three.
fe(w) = ?1fe1(w) + ?2fe2(w) + ?3fe3(w) (2)
where, ?1 = 1, ?2 = 1 and ?3 = 0.1 are the relative
weights.
The value of fe1 is simply the length of the word,
that is
fe1(w) = |w| (3)
Suppose ? = ?1?2 ? ? ??k is the usual syllabifica-
tion of w, where the usual or optimal syllabification
for Bengali is defined similar to that of Hindi as de-
scribed in (Choudhury et al, 2004). Then, fe2 is
defined as follows.
fe2(w) =
k?
i=1
hr(?i) (4)
hr(?) measures the hardness of the syllable ? and is
a function of the syllable structure (i.e. the CV pat-
tern) of ?. The values of hr(?) for different syllable
structures are taken from (Choudhury et al, 2004).
69
Since vowel height assimilation is the primary
co-articulation phenomenon observed across the di-
alects of Bengali, we define fe3 so as to model
only the effort required due to the difference in the
heights of the adjacent vowels.
Let there be n vowels in w represented by Vi,
where 1 ? i ? n. Then fe3 is defined by the fol-
lowing equation.
fe3(w) =
n?1?
i=1
|ht(Vi)? ht(Vi+1)| (5)
The function ht(Vi) is the tongue height associ-
ated with the vowel Vi. The value of the function
ht(Vi) for the vowels /A/, /a/, /E/ /o/, /e/, /i/
and /u/ are 0, 1, 1, 2, 2, 3, and 3 respectively. Note
that the values are indicative of the ordering of the
vowels with respect to tongue height, and do not re-
flect the absolute height of the tongue in any sense.
3.2.2 fd and Cd: Acoustic Distinctiveness
We define the acoustic distinctiveness between
two words wi and wj as the edit distance between
them, which is denoted as ed(wi, wj). The cost of
insertion and deletion of any phoneme is assumed to
be 1; the cost of substitution of a vowel (consonant)
for a vowel (consonant) is also 1, whereas that of a
vowel (consonant) for a consonant (vowel) is 2, ir-
respective of the phonemes being compared. Since
languages are expected to increase the acoustic dis-
tinctiveness between the words, we define a mini-
mizing objective function fd over a lexicon ? as the
sum of the inverse of the edit distance between all
pair of words in ?.
fd(?) =
2
|?|(|?| ? 1)
?
ij,i6=j
ed(wi, wj)
?1 (6)
If for any pair of words wi and wj , ed(wi, wj) =
0, we redefine ed(wi, wj)?1 as 20 (a large penalty).
We say that a lexicon ? violates the acoustic dis-
tinctiveness constraintCd, if there are more than two
pairs of words in ?, which are identical.
3.2.3 Cp: Phonotactic constraints
A lexicon ? is said to violate the constraint Cp if
any of the words in ? violates the phonotactic con-
straints of Bengali. As described in (Choudhury et
al., 2004), the PCs are defined at the level of sylla-
ble onsets and codas and therefore, syllabification is
a preprocessing step before evaluation of Cp.
3.2.4 fr and Cr: Regularity
Although learnability is a complex notion, one
can safely equate the learnability of a system to the
regularity of the patterns within the system. In fact,
in the context of morphology, it has been observed
that the so called learning bottleneck has a regular-
izing effect on the morphological structures, thereby
leaving out only the most frequently used roots to
behave irregularly (Hare and Elman, 1995; Kirby,
2001).
In the present context, we define the regularity
of the verb forms in a lexicon as the predictability
of the inflectional suffix on the basis of the mor-
phological attributes. Brighton et al (2005) discuss
the use of Pearson correlation between phonologi-
cal edit distance and semantic/morphological ham-
ming distance measures as a metric for learnabil-
ity. On a similar note, we define the regularity func-
tion fr as follows. For two words wi, wj ? ?, the
(dis)similarity between them is given by ed(wi, wj).
Let ma(wi, wj) be the number of morphological at-
tributes shared by wi and wj . We define the reg-
ularity of ?, fr(?), as the Pearson correlation co-
efficient between ed(wi, wj) and ma(wi, wj) for
all pairs of words in ?. Note that for a regular
lexicon, ed(wi, wj) decreases with an increase in
ma(wi, wj). Therefore, fr(?) is negative for a reg-
ular lexicon and 0 or positive for an irregular one.
In other words, fr(?) is also a minimizing objective
function.
We also define a regularity constraint Cr, such
that a lexicon ? violates Cr if fr(?) > ?0.8.
4 Experiments and Observations
In order to implement the MOGA model, we have
used the Non-dominated Sorting GA-II or NSGA-
II (Deb et al, 2002), which is a multi-objective,
multi-constraint elitist GA. Different MOGA mod-
els have been incrementally constructed by intro-
ducing the different objectives and constraints. The
motivation behind the incorporation of a new ob-
jective or constraint comes from the observations
made on the emergent dialects of the previous mod-
els. For instance, with two objectives fe and fd,
70
and no constraints, we obtain dialects that violate
phonotactic constraints or/and are highly irregular.
One such example of an emergent dialect4 is ? =
{ kor, kara, kar, kore, korea, kore, karA, karAa,
karA, *korAlm, *korl, korla, *koreAlm, korel, ko-
rela, *karAlm, karAl, karAla }. The * marked forms
violate the phonotactic constraints. Also note that
the forms are quite indistinct or close to each other.
These observations led to the formulation of the con-
straints Cp and Cd.
Through a series of similar experiments, finally
we arrived at a model, where we could observe the
emergence of dialects, some of which closely resem-
ble the real dialects and others also seem linguisti-
cally plausible. In this final model, there are two
objectives, fe and fd, and 3 constraints, Cp, Cd and
Cr. Table 4 lists the corresponding forms of some
of the emergent dialects, whose real counterparts are
shown in Table 1.
Fig. 2 shows the Pareto-optimal front obtained
for the aforementioned model after 500 generations,
with a population size of 1000. Since the objectives
are minimizing in nature, the area on the plot below
and left of the Pareto-optimal front represents im-
possible languages, whereas the area to the right and
top of the curve pertains to unstable or suboptimal
languages. It is interesting to note that the four real
dialects lie very close to the Pareto-optimal front. In
fact, ACB and SCB lie on the front, whereas clas-
sical Bengali and Sylheti appears to be slightly sub-
optimal. Nevertheless, one should always be aware
that impossibility and suboptimality are to be inter-
preted in the context of the model and any general-
ization or extrapolation of these concepts for the real
languages is controversial and better avoided.
Several inferences can be drawn from the exper-
iments with the MOGA models. We have observed
that the Pareto-optimal fronts for all the MOGA
Models look like rectangular hyperbola with a hori-
zontal and vertical limb; the specific curve of Fig. 2
satisfies the equation:
fd(?)
0.3(fe(?)? 5.6) = 0.26 (7)
Several interesting facts, can be inferred from the
above equation. First, the minimum value of fe un-
der the constraints Cr and Cd, and for the given
4Due to space constraints, we intentionally omit the corre-
sponding classical forms.
Figure 2: The Pareto-optimal front. The gray trian-
gles (light blue in colored version available online)
show the position of the real dialects: 0 ? Classi-
cal Bengali, 1 ? SCB, 2 ? ACB, 3 ? Sylheti. The
top-most dot in the plot corresponds to the emergent
dialect D0 shown in Table 4.
repertoire of APOs is 5.6. Second, at fe(?) = 6,
the slope of the front, i.e. dfd/dfe, is approximately
?2, and the second derivative d2fd/df2e is around
20. This implies that there is sharp transition be-
tween the vertical and horizontal limbs at around
fe(?) = 6.
Interestingly, all the real dialects studied here lie
on the horizontal limb of the Pareto-optimal front
(i.e., fe(?) ? 6), classical Bengali being placed at
the extreme right. We also note the negative corre-
lation between the value of fe for the real dialects,
and the number of APOs invoked during derivation
of these dialects from classical Bengali. These facts
together imply that the natural direction of language
change in the case of BVIs has been along the hor-
izontal limb of the Pareto-optimal front, leading to
the formation of dialects with higher and higher ar-
ticulatory ease. Among the four dialects, SCB has
the minimum value for fe(?) and it is positioned on
the horizontal limb of the front just before the begin-
ning of the vertical limb.
Therefore, it is natural to ask whether there are
any real dialects of modern Bengali that lie on the
vertical limb of the Pareto-optimal front; and if not,
what may be the possible reasons behind their inex-
istence? In the absence of any comprehensive col-
lection of Bengali dialects, we do not have a clear
answer to the above questions. Nevertheless, it may
71
Attributes D0 D1 D2 D3
PrS1 kar kor kori kori
PrS2 kara kora kora kora
PrS3 kare kore kore korA
PrSF karen koren koren koren
PrC1 kartA karChi karteChi kairteChi
PrC2 kartAa karCha karteCha kairteCha
PrC3 kartAe karChe karteChe kairteChA
PrCF kartAen karChen karteChen kairteChen
PrP1 karA korChi koriChi koriChAi
PrP2 karAa korCha koriCha koriACha
PrP3 karAe korChe koriChe koriAChA
PrPF karAen korChen koriChen koriAChen
Table 4: Examples of emergent dialects in the
MOGA model. Note that the dialects D1, D2 and
D3 resemble SCB, ACB and Sylheti, whereas D0
seems to be linguistically implausible. For legends,
refer to Table 1
be worthwhile to analyze the emergent dialects of
the MOGA models that lie on the vertical limb. We
have observed that the vertical limb consists of di-
alects similar to D0 ? the one shown in the first
column of Table 4. Besides poor distinctiveness,
D0 also features a large number of diphthongs that
might result in poorer perception or higher effort of
articulation of the forms. Thus, in order to eliminate
the emergence of such seemingly implausible cases
in the model, the formulations of the objectives fe
and fd require further refinements.
Similarly, it can also be argued that the structure
of the whole lexicon, which has not been modeled
here, has also a strong effect on the BVIs. This is
because even though we have measured the acous-
tic distinctiveness fd with respect to the 28 inflected
forms of a single verb root kar, ideally fd should be
computed with respect to the entire lexicon. Thus,
change in other lexical items (borrowing or extinc-
tion of words or change in the phonological struc-
tures) can trigger or restrain an event of change in
the BVIs.
Furthermore, merging, extinction or appearence
of morphological attributes can also have significant
effects on the phonological change of inflections. It
is interesting to note that while Vedic Sanskrit had
different morphological markers for three numbers
(singular, dual and plural) and no gender markers
for the verbs, Hindi makes a distinction between the
genders (masculine and feminine) as well as num-
bers (but only singular and plural), and Bengali has
markers for neither gender nor number. Since both
Hindi and Bengali are offshoots of Vedic Sanskrit,
presumably the differences between the phonologi-
cal structure of the verb inflections of these two lan-
guages must have also been affected by the loss or
addition of morphological attributes. It would be in-
teresting to study the precise nature of the interac-
tion between the inflections and attributes within the
current computational framework, which we deem
to be a future extension of this work.
5 Conclusions
In this paper, we have described a MOGA based
model for the morpho-phonological change of BVIs.
The salient contributions of the work include: (1) the
conception of the genotype as a sequence of APOs,
whereby we have been able to capture not only the
emergent dialects, but also the path towards their
emergence, and (2) a plausible functional explana-
tion for the morpho-phonological changes affecting
the BVIs. Nevertheless, the results of the experi-
ments with the MOGA models must be interpreted
with caution. This is because, the results are very
much dependent on the formulation of the fitness
functions and the choice of the constraints. The set
of APOs in the repertoire also play a major role in
shaping the Pareto-optimal front of the model.
Before we conclude, we would like to re-
emphasize that the model proposed here is a func-
tional one, and it does not tell us how the dialects
of Bengali have self-organized themselves to strike
a balance between the functional pressures, if at all
this had been the case. The evolutionary algorithm
(i.e., MOGA) has been used here as a tool for op-
timization, and has no relevance to the evolution of
the dialects as such. Nevertheless, if it is possible
to provide linguistically grounded accounts of the
sources of variation and the process of selection,
then the MOGA model could qualify as an evolu-
tionary explanation of language change as well. Al-
though such models have been proposed in the liter-
ature (Croft, 2000; Baxter et al, 2006), the fact, that
global optimization can be an outcome of local inter-
actions between the speakers (e.g., Kirby (1999), de
72
Boer (2001), Choudhury et al (2006b)), alone pro-
vides sufficient ground to believe that there is also an
underlying self-organizational model for the present
functional explanation.
References
G. J. Baxter, R. A. Blythe, W. Croft, and A. J. McKane.
2006. Utterance selection model of language change.
Physical Review E, 73(046118).
D.N.S. Bhat. 2001. Sound Change. Motilal Banarsidass,
New Delhi.
S. Bhattacharya, M. Choudhury, S. Sarkar, and A. Basu.
2005. Inflectional morphology synthesis for bengali
noun, pronoun and verb systems. In Proc. of NCCPB,
pages 34?43, Dhaka.
Julia Blevins. 2004. Evolutionary Phonology. Cam-
bridge University Press, Cambridge, MA.
P. Boersma. 1998. Functional Phonology: Formaliz-
ing the interactions between articulatory and percep-
tual drives. Uitgave van Holland Academic Graphics,
Hague.
Henry Brighton, Kenny Smith, and Simon Kirby. 2005.
Language as an evolutionary system. Physics of Life
Reviews, 2(3):177?226, September.
A. Cangelosi and D. Parisi. 2002. Comuputer simula-
tion: A new scientific approach to the study of lan-
guage evolution. In Simulating the Evolution of Lan-
guage, pages 3?28. Springer Verlag, London.
S. K. Chatterji. 1926. The Origin and Development of
the Bengali Language. Rupa and Co., New Delhi.
A. Chopde. 2001. Itrans version 5.30: A package
for printing text in indian languages using english-
encoded input. http://www.aczoom.com/itrans/.
M. Choudhury, A. Basu, and S. Sarkar. 2004. A di-
achronic approach for schwa deletion in indo-aryan
languages. In Proc. of ACL SIGPHON-04, pages 20?
26, Barcelona.
M. Choudhury, M. Alam, S. Sarkar, and A. Basu.
2006a. A rewrite rule based model of bangla morpho-
phonological change. In Proc. of ICCPB, pages 64?
71, Dhaka.
M. Choudhury, A. Basu, and S. Sarkar. 2006b. Multi-
agent simulation of emergence of the schwa deletion
pattern in hindi. JASSS, 9(2).
W. Croft. 2000. Explaining Language Change: An Evo-
lutionary Approach. Longman Linguistic Library.
B. de Boer. 2001. The Origins of Vowel Systems. Oxford
University Press.
K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. 2002.
A fast and elitist multi-objective genetic algorithm:
NSGA-II. IEEE Transactions on Evolutionary Com-
putation, 6:182?197.
M. Dras, D. Harrison, and B. Kapicioglu. 2003. Emer-
gent behavior in phonological pattern change. In Arti-
ficial Life VIII. MIT Press.
David E. Goldberg. 1989. Genetic Algorithms in Search,
Optimization and Machine Learning. Addison-
Wesley.
M. Hare and J. L. Elman. 1995. Learning and morpho-
logical change. Cognition, 56(1):61?98, July.
M. D. Hauser, N. Chomsky, and W. T. Fitch. 2002. The
faculty of language: What is it, who has it, and how
did it evolve? Science, 298:1569?1579, 11.
John H. Holland. 1975. Adaptation in Natural and Arti-
ficial Systems. The University of Michigan Press, Ann
Arbor.
Jinyun Ke, Mieko Ogura, and William S-Y. Wang. 2003.
Modeling evolution of sound systems with genetic al-
gorithm. Computational Linguistics, 29(1):1?18.
S. Kirby. 1999. Function, Selection and Innateness: the
Emergence of Language Universals. Oxford Univer-
sity Press. The full-text is only a sample (chapter 1: A
Puzzle of Fit).
S. Kirby. 2001. Spontaneous evolution of linguistic
structure: an iterated learning model of the emergence
of regularity and irregularity. IEEE Transactions on
Evolutionary Computation, 5(2):102?110.
Anthony Kroch. 2001. Syntactic change. In Mark baltin
and Chris Collins, editors, Handbook of Syntax, pages
699?729. Blackwell.
P. Niyogi. 2006. The Computational Nature of Language
Learning and Evolution. MIT Press, Cambridge, MA.
J. Ohala. 1993. The phonetics of sound change. In
C. Jones, editor, Historical linguistics: Problems and
perspectives, page 237278. Longman, London.
A. Perfors. 2002. Simulated evolution of language: a
review of the field. Journal of Artificial Societies and
Social Simulation, 5(2).
T. Poibeau. 2006. Linguistically grounded models of
language change. In Proc. of CogSci 2006, pages 255?
276.
73
Melissa A. Redford and R. L. Diehl. 1999. The rela-
tive perceptibility of syllable-initial and syllable-final
consonants. Journal of Acoustic Society of America,
106:1555?1565.
Melissa A. Redford, Chun Chi Chen, and Risto Mi-
ikkulainen. 2001. Constrained emergence of univer-
sals and variation in syllable systems. Language and
Speech, 44:27?56.
Melissa A. Redford. 1999. An Articulatory Basis for
the Syllable. Ph.D. thesis, Psychology, University of
Texas, Austin.
L. Steels. 1997. The synthetic modeling of language
origins. Evolution of Communication, 1(1):1?34.
W. S-Y. Wang, J. Ke, and J. W. Minett. 2005. Computa-
tional studies of language evolution. In Computational
Linguistics and Beyond: Perspectives at the beginning
of the 21st Century, Frontiers in Linguistics 1. Lan-
guage and Linguistics.
74
Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 101?108,
Prague, June 2007. c?2007 Association for Computational Linguistics
Emergence of Community Structures in Vowel Inventories:
An Analysis based on Complex Networks
Animesh Mukherjee, Monojit Choudhury, Anupam Basu, Niloy Ganguly
Department of Computer Science and Engineering,
Indian Institute of Technology, Kharagpur
{animeshm,monojit,anupam,niloy}@cse.iitkgp.ernet.in
Abstract
In this work, we attempt to capture patterns
of co-occurrence across vowel systems and
at the same time figure out the nature of the
force leading to the emergence of such pat-
terns. For this purpose we define a weighted
network where the vowels are the nodes
and an edge between two nodes (read vow-
els) signify their co-occurrence likelihood
over the vowel inventories. Through this
network we identify communities of vow-
els, which essentially reflect their patterns
of co-occurrence across languages. We ob-
serve that in the assortative vowel communi-
ties the constituent nodes (read vowels) are
largely uncorrelated in terms of their fea-
tures indicating that they are formed based
on the principle of maximal perceptual con-
trast. However, in the rest of the communi-
ties, strong correlations are reflected among
the constituent vowels with respect to their
features indicating that it is the principle of
feature economy that binds them together.
1 Introduction
Linguistic research has documented a wide range of
regularities across the sound systems of the world?s
languages (Liljencrants and Lindblom, 1972; Lind-
blom, 1986; de Boer, 2000; Choudhury et al, 2006;
Mukherjee et al, 2006a; Mukherjee et al, 2006b).
Functional phonologists argue that such regulari-
ties are the consequences of certain general princi-
ples like maximal perceptual contrast (Liljencrants
and Lindblom, 1972), which is desirable between
the phonemes of a language for proper percep-
tion of each individual phoneme in a noisy envi-
ronment, ease of articulation (Lindblom and Mad-
dieson, 1988; de Boer, 2000), which requires that
the sound systems of all languages are formed of
certain universal (and highly frequent) sounds, and
ease of learnability (de Boer, 2000), which is re-
quired so that a speaker can learn the sounds of
a language with minimum effort. In the study of
vowel systems the optimizing principle, which has
a long tradition (Jakobson, 1941; Wang, 1968) in
linguistics, is maximal perceptual contrast. A num-
ber of numerical studies based on this principle have
been reported in literature (Liljencrants and Lind-
blom, 1972; Lindblom, 1986; Schwartz et al, 1997).
Of late, there have been some attempts to explain the
vowel systems through multi agent simulations (de
Boer, 2000) and genetic algorithms (Ke et al, 2003);
all of these experiments also use the principle of per-
ceptual contrast for optimization purposes.
An exception to the above trend is a school of
linguists (Boersma, 1998; Clements, 2004) who ar-
gue that perceptual contrast-based theories fail to ac-
count for certain fundamental aspects such as the
patterns of co-occurrence of vowels based on sim-
ilar acoustic/articulatory features1 observed across
1In linguistics, features are the elements, which distinguish
one phoneme from another. The features that describe the
vowles can be broadly categorized into three different classes
namely the height, the backness and the roundedness. Height
refers to the vertical position of the tongue relative to either the
roof of the mouth or the aperture of the jaw. Backness refers
to the horizontal tongue position during the articulation of a
vowel relative to the back of the mouth. Roundedness refers to
whether the lips are rounded or not during the articulation of a
101
the vowel inventories. Instead, they posit that the
observed patterns, especially found in larger size in-
ventories (Boersma, 1998), can be explained only
through the principle of feature economy (de Groot,
1931; Martinet, 1955). According to this principle,
languages tend to maximize the combinatorial pos-
sibilities of a few distinctive features to generate a
large number of sounds.
The aforementioned ideas can be possibly linked
together through the example illustrated by Figure 1.
As shown in the figure, the initial plane P constitutes
of a set of three very frequently occurring vowels /i/,
/a/ and /u/, which usually make up the smaller in-
ventories and do not have any single feature in com-
mon. Thus, smaller inventories are quite likely to
have vowels that exhibit a large extent of contrast
in their constituent features. However, in bigger in-
ventories, members from the higher planes (P? and
P
??) are also present and they in turn exhibit fea-
ture economy. For instance, in the plane P? com-
prising of the set of vowels /?i/, /a?/, /u?/, we find a
nasal modification applied equally on all the three
members of the set. This is actually indicative of an
economic behavior that the larger inventories show
while choosing a new feature in order to reduce the
learnability effort of the speakers. The third plane
P
?? reinforces this idea by showing that the larger
the size of the inventories the greater is the urge for
this economy in the choice of new features. An-
other interesting facet of the figure are the relations
that exist across the planes (indicated by the bro-
ken lines). All these relations are representative of a
common linguistic concept of robustness (Clements,
2004) in which one less frequently occurring vowel
(say /?i/) implies the presence of the other (and not
vice versa) frequently occurring vowel (say /i/) in a
language inventory. These cross-planar relations are
also indicative of feature economy since all the fea-
tures present in the frequent vowel (e.g., /i/) are also
shared by the less frequent one (e.g., /?i/). In sum-
mary, while the basis of organization of the vowel
inventories is perceptual contrast as indicated by
the plane P in Figure 1, economic modifications of
the perceptually distinct vowels takes place with the
vowel. There are however still more possible features of vowel
quality, such as the velum position (e.g., nasality), type of vocal
fold vibration (i.e., phonation), and tongue root position (i.e.,
secondary place of articulation).
increase in the inventory size (as indicated by the
planes P ? and P ?? in Figure 1).
In this work we attempt to corroborate the above
conjecture by automatically capturing the patterns of
co-occurrence that are prevalent in and across the
planes illustrated in Figure 1. In order to do so,
we define the ?Vowel-Vowel Network? or VoNet,
which is a weighted network where the vowels are
the nodes and an edge between two nodes (read vow-
els) signify their co-occurrence likelihood over the
vowel inventories. We conduct community struc-
ture analysis of different versions of VoNet in or-
der to capture the patterns of co-occurrence in and
across the planes P , P ? and P ?? shown in Figure 1.
The plane P consists of the communities, which
are formed of those vowels that have a very high
frequency of occurrence (usually assortative (New-
man, 2003) in nature). We observe that the con-
stituent nodes (read vowels) of these assortative
vowel communities are largely uncorrelated in terms
of their features. On the other hand, the commu-
nities obtained from VoNet, in which the links be-
tween the assortative nodes are absent, corresponds
to the co-occurrence patterns of the planes P? and
P
??
. In these communities, strong correlations are
reflected among the constituent vowels with respect
to their features. Moreover, the co-occurrences
across the planes can be captured by the community
analysis of VoNet where only the connections be-
tween the assortative and the non-assortative nodes,
with the non-assortative node co-occurring very fre-
quently with the assortative one, are retained while
the rest of the connections are filtered out. We find
that these communities again exhibit a high correla-
tion among the constituent vowels.
This article is organized as follows: Section 2 de-
scribes the experimental setup in order to explore
the co-occurrence principles of the vowel inven-
tories. In this section we formally define VoNet,
outline its construction procedure, and present a
community-finding algorithm in order to capture the
co-occurrence patterns across the vowel systems. In
section 3 we report the experiments performed to
obtain the community structures, which are repre-
sentative of the co-occurrence patterns in and across
the planes discussed above. Finally, we conclude in
section 4 by summarizing our contributions, point-
ing out some of the implications of the current work
102
Figure 1: The organizational principles of the vowels (in decreasing frequency of occurrence) indicated
through different hypothetical planes.
and indicating the possible future directions.
2 Experimental Setup
In this section we systematically develop the ex-
perimental setup in order to investigate the co-
occurrence principles of the vowel inventories. For
this purpose, we formally define VoNet, outline
its construction procedure, describe a community-
finding algorithm to decompose VoNet to obtain the
community structures that essentially reflects the co-
occurrence patterns of the vowel inventories.
2.1 Definition and Construction of VoNet
Definition of VoNet: We define VoNet as a network
of vowels, represented as G = ? V
V
, E ? where V
V
is the set of nodes labeled by the vowels and E is
the set of edges occurring in VoNet. There is an
edge e ? E between two nodes, if and only if there
exists one or more language(s) where the nodes
(read vowels) co-occur. The weight of the edge e
(also edge-weight) is the number of languages in
which the vowels connected by e co-occur. The
weight of a node u (also node-weight) is the number
of languages in which the vowel represented by u
occurs. In other words, if a vowel v
i
represented by
the node u occurs in the inventory of n languages
then the node-weight of u is assigned the value
n. Also if the vowel v
j
is represented by the node
v and there are w languages in which vowels v
i
and v
j
occur together then the weight of the edge
connecting u and v is assigned the value v. Figure 2
illustrates this structure by reproducing some of the
nodes and edges of VoNet.
Construction of VoNet: Many typological stud-
ies (Lindblom and Maddieson, 1988; Ladefoged
and Maddieson, 1996; Hinskens and Weijer, 2003;
Choudhury et al, 2006; Mukherjee et al, 2006a;
Mukherjee et al, 2006b) of segmental inventories
have been carried out in past on the UCLA Phono-
logical Segment Inventory Database (UPSID) (Mad-
dieson, 1984). Currently UPSID records the sound
inventories of 451 languages covering all the major
language families of the world. The selection of the
languages for the inclusion on UPSID is governed
by a quota principle seeking maximum genetic di-
versity among extant languages in order to reduce
bias towards any particular family. In this work we
have therefore used UPSID comprising of these 451
languages and 180 vowels found across them, for
103
Figure 3: A partial illustration of VoNet. All edges in this figure have an edge-weight greater than or equal to
15. The number on each node corresponds to a particular vowel. For instance, node number 72 corresponds
to /?i/.
constructing VoNet. Consequently, the set V
V
com-
prises 180 elements (nodes) and the set E comprises
3135 elements (edges). Figure 3 presents a partial
illustration of VoNet as constructed from UPSID.
2.2 Finding Community Structures
We attempt to identify the communities appearing
in VoNet by the extended Radicchi et al (Radic-
chi et al, 2003) algorithm for weighted networks
presented in (Mukherjee et al, 2006a). The ba-
sic idea is that if the weights on the edges form-
ing a triangle (loops of length three) are comparable
then the group of vowels represented by this trian-
gle highly occur together rendering a pattern of co-
occurrence while if these weights are not compara-
ble then there is no such pattern. In order to capture
this property we define a strength metric S (in the
lines of (Mukherjee et al, 2006a)) for each of the
edges of VoNet as follows. Let the weight of the
edge (u,v), where u, v ? V
V
, be denoted by w
uv
.
We define S as,
S =
w
uv
?
?
i?V
C
?{u,v}
(w
ui
? w
vi
)
2
(1)
if
?
?
i?V
C
?{u,v}
(w
ui
? w
vi
)
2
> 0 else S = ?.
The denominator in this expression essentially tries
to capture whether or not the weights on the edges
forming triangles are comparable (the higher the
value of S the more comparable the weights are).
The network can be then decomposed into clusters
104
Figure 2: A partial illustration of the nodes and
edges in VoNet. The labels of the nodes denote the
vowels represented in IPA (International Phonetic
Alphabet). The numerical values against the edges
and nodes represent their corresponding weights.
For example /i/ occurs in 393 languages; /e/ occurs
in 124 languages while they co-occur in 117 lan-
guages.
or communities by removing edges that have S less
than a specified threshold (say ?).
At this point it is worthwhile to clarify the sig-
nificance of a vowel community. A community of
vowels actually refers to a set of vowels which occur
together in the language inventories very frequently.
In other words, there is a higher than expected prob-
ability of finding a vowel v in an inventory which al-
ready hosts the other members of the community to
which v belongs. For instance, if /i/, /a/ and /u/ form
a vowel community and if /i/ and /a/ are present in
any inventory then there is a very high chance that
the third member /u/ is also present in the inventory.
3 Experiments and Results
In this section we describe the experiments per-
formed and the results obtained from the analysis of
VoNet. In order to find the co-occurrence patterns
in and across the planes of Figure 1 we define three
versions of VoNet namely VoNet
assort
, VoNet
rest
and VoNet
rest
? . The construction procedure for
each of these versions are presented below.
Construction of VoNet
assort
: VoNet
assort
com-
prises the assortative2 nodes having node-weights
2The term ?assortative node? here refers to the nodes having
a very high node-weight, i.e., consonants having a very high
above 120 (i.e, vowels occurring in more than 120
languages in UPSID), along with only the edges
inter-connecting these nodes. The rest of the nodes
(having node-weight less than 120) and edges are
removed from the network. We make a choice
of this node-weight for classifying the assortative
nodes from the non-assortative ones by observing
the distribution of the occurrence frequency of the
vowels illustrated in Figure 4. The curve shows
the frequency of a vowel (y-axis) versus the rank
of the vowel according to this frequency (x-axis)
in log-log scale. The high frequency zone (marked
by a circle in the figure) can be easily distinguished
from the low-frequency one since there is distinct
gap featuring between the two in the curve.
Figure 4: The frequency (y-axis) versus rank (x-
axis) curve in log-log scale illustrating the distrib-
ution of the occurrence of the vowels over the lan-
guage inventories of UPSID.
Figure 5 illustrates how VoNet
assort
is con-
structed from VoNet. Presently, the number of
nodes in VoNet
assort
is 9 and the number of edges
is 36.
Construction of VoNet
rest
: VoNet
rest
comprises
all the nodes as that of VoNet. It also has all
the edges of VoNet except for those edges that
inter-connect the assortative nodes. Figure 6 shows
how VoNet
rest
can be constructed from VoNet. The
number of nodes and edges in VoNet
rest
are 180
frequency of occurrence.
105
Figure 5: The construction procedure of VoNet
assort
from VoNet.
and 12933 respectively.
Construction of VoNet
rest
?: VoNet
rest
? again
comprises all the nodes as that of VoNet. It con-
sists of only the edges that connect an assorta-
tive node with a non-assortative one if the non-
assortative node co-occurs more than ninety five per-
cent of times with the assortative nodes. The basic
idea behind such a construction is to capture the co-
occurrence patterns based on robustness (Clements,
2004) (discussed earlier in the introductory section)
that actually defines the cross-planar relationships in
Figure 1. Figure 7 shows how VoNet
rest
? can be
constructed from VoNet. The number of nodes in
VoNet
rest
? is 180 while the number of edges is 1144.
We separately apply the community-finding al-
gorithm (discussed earlier) on each of VoNet
assort
,
VoNet
rest
and VoNet
rest
? in order to obtain the re-
spective vowel communities. We can obtain dif-
ferent sets of communities by varying the threshold
?. A few assortative vowel communities (obtained
from VoNet
assort
) are noted in Table 1. Some of the
3We have neglected nodes with node-weight less than 3
since these nodes correspond to vowels that occur in less than 3
languages in UPSID and the communities they form are there-
fore statistically insignificant.
4The network does not get disconnected due to this construc-
tion since, there is always a small fraction of edges that run be-
tween assortative and low node-weight non-assortative nodes of
otherwise disjoint groups.
communities obtained from VoNet
rest
are presented
in Table 2. We also note some of the communities
obtained from VoNet
rest
? in Table 3.
Tables 1 , 2 and 3 indicate that the communi-
ties in VoNet
assort
are formed based on the princi-
ple of perceptual contrast whereas the formation of
the communities in VoNet
rest
as well as VoNet
rest
?
is largely governed by feature economy. Hence,
the smaller vowel inventories which are composed
of mainly the members of VoNet
assort
are orga-
nized based on the principle of maximal percep-
tual contrast whereas the larger vowel inventories,
which also contain members from VoNet
rest
and
VoNet
rest
? apart from VoNet
assort
, show a consider-
able extent of feature economy. Note that the groups
presented in the tables are quite representative and
the technique described above indeed captures many
other such groups; however, due to paucity of space
we are unable to present all of them here.
4 Conclusion
In this paper we explored the co-occurrence prin-
ciples of the vowels, across the inventories of the
world?s languages. In order to do so we started with
a concise review of the available literature on vowel
inventories. We proposed an automatic procedure
to extract the co-occurrence patterns of the vowels
across languages.
Some of our important findings from this work
are,
? The smaller vowel inventories (corresponding
to the communities of
VoNet
assort
) tend to be organized based on the
principle of maximal perceptual contrast;
? On the other hand, the larger vowel invento-
ries (mainly comprising of the communities of
VoNet
rest
) reflect a considerable extent of fea-
ture economy;
? Co-occurrences based on robustness are preva-
lent across vowel inventories (captured through
the communities of VoNet
rest
?) and their emer-
gence is again a consequence of feature econ-
omy.
Until now, we have concentrated mainly on the
methodology that can be used to automatically cap-
106
Figure 6: The construction procedure of VoNet
rest
from VoNet.
Figure 7: The construction procedure of VoNet
rest
? from VoNet.
Community Features in Contrast
/i/, /a/, /u/ (low/high), (front/central/back), (unrounded/rounded)
/e/, /o/ (higher-mid/mid), (front/back), (unrounded/rounded)
Table 1: Assortative vowel communities. The contrastive features separated by slashes (/) are shown within
parentheses. Comma-separated entries represent the features that are in use from the three respective classes
namely the height, the backness, and the roundedness.
ture the co-occurrence patterns across the vowel sys-
tems. However, it would be also interesting to in-
vestigate the extent to which these patterns are gov-
erned by the forces of maximal perceptual contrast
and feature economy. Such an investigation calls
for quantitative definitions of the above forces and
107
Community Features in Common
/
?
i/, /a?/, /u?/ nasalized
/?i:/, /a?:/, /u?:/ long, nasalized
/i:/, /u:/, /a:/, /o:/, /e:/ long
Table 2: Some of the vowel communities obtained from VoNet
rest
.
Community Features in Common
/i/, /?i/ high, front, unrounded
/a/, /a?/ low, central, unrounded
/u/, /u?/ high, back, rounded
Table 3: Some of the vowel communities obtained from VoNet
rest
? . Comma-separated entries represent the
features that are in use from the three respective classes namely the height, the backness, and the rounded-
ness.
a thorough evaluation of the vowel communities in
terms of these definitions. We look forward to ac-
complish the same as a part of our future work.
References
B. de Boer. 2000. Self-organisation in vowel systems,
Journal of Phonetics, 28(4), 441?465.
P. Boersma. 1998. Functional phonology, Doctoral the-
sis, University of Amsterdam, The Hague: Holland
Academic Graphics.
M. Choudhury, A. Mukherjee, A. Basu and N. Ganguly.
2006. Analysis and synthesis of the distribution of
consonants over languages: A complex network ap-
proach, Proceedings of COLING?ACL, 128?135, Syd-
ney, Australia.
N. Clements. 2004. Features and sound inventories,
Symposium on Phonological Theory: Representations
and Architecture, CUNY.
A. W. de Groot. 1931. Phonologie und Phonetik als
funktionswissenschaften, Travaux du Cercle Linguis-
tique de, 4, 116?147.
F. Hinskens and J. Weijer. 2003. Patterns of segmen-
tal modification in consonant inventories: A cross-
linguistic study, Linguistics, 41, 6.
R. Jakobson. 2003. Kindersprache, aphasie und allge-
meine lautgesetze, Uppsala, reprinted in Selected Writ-
ings I. Mouton, (The Hague, 1962), 328-401.
J. Ke, M. Ogura and W.S.-Y. Wang. 2003. Optimization
models of sound systems using genetic algorithms,
Computational Linguistics, 29(1), 1?18.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
worlds languages, Oxford: Blackwell.
J. Liljencrants and B. Lindblom. 1972. Numerical simu-
lation of vowel quality systems: the role of perceptual
contrast, Language, 48, 839?862.
B. Lindblom. 1986. Phonetic universals in vowel sys-
tems, Experimental Phonology, 13?44.
B. Lindblom and I. Maddieson. 1988. Phonetic uni-
versals in consonant systems, Language, Speech, and
Mind, Routledge, London, 62?78.
I. Maddieson. Patterns of sounds, 1984. Cambridge
University Press, Cambridge.
A. Martinet. 1955. `Economie des changements
phone?tiques, Berne: A. Francke.
A. Mukherjee, M. Choudhury, A. Basu and N. Ganguly.
2006. Modeling the co-occurrence principles of the
consonant inventories: A complex network approach,
arXiv:physics/0606132 (preprint).
A. Mukherjee, M. Choudhury, A. Basu and N. Gan-
guly. 2006. Self-organization of the Sound In-
ventories: Analysis and Synthesis of the Occur-
rence and Co-occurrence Networks of Consonants.
arXiv:physics/0610120 (preprint).
M. E. J. Newman. 2003. The structure and function of
complex networks, SIAM Review, 45, 167?256.
F. Radicchi, C. Castellano, F. Cecconi, V. Loreto and D.
Parisi. 2003. Defining and identifying communities in
networks, PNAS, 101(9), 2658?2663.
J-L. Schwartz, L-J. Bo?e, N. Valle?e and C. Abry. 1997.
The dispersion-focalization theory of vowel systems,
Journal of Phonetics, 25, 255?286.
W. S.-Y. Wang. 1968. The basis of speech. Project
on linguistic analysis reports, University of California,
Berkeley, (reprinted in The Learning of Language in
1971).
108
Coling 2010: Poster Volume, pages 162?170,
Beijing, August 2010
Global topology of word co-occurrence networks:
Beyond the two-regime power-law
Monojit Choudhury
Microsoft Research Lab India
monojitc@microsoft.com
Diptesh Chatterjee
Indian Institute of Technology Kharagpur
diptesh.chh.1987@gmail.com
Animesh Mukherjee
Complex Systems Lagrange Lab, ISI Foundation
animesh.mukherjee@isi.it
Abstract
Word co-occurrence networks are one
of the most common linguistic networks
studied in the past and they are known
to exhibit several interesting topological
characteristics. In this article, we inves-
tigate the global topological properties of
word co-occurrence networks and, in par-
ticular, present a detailed study of their
spectrum. Our experiments reveal cer-
tain universal trends found across the net-
works for seven different languages from
three different language families, which
are neither reported nor explained by any
of the previous studies and models of
word-cooccurrence networks. We hy-
pothesize that since word co-occurrences
are governed by syntactic properties of
a language, the network has much con-
strained topology than that predicted by
the previously proposed growth model. A
deeper empirical and theoretical investiga-
tion into the evolution of these networks
further suggests that they have a core-
periphery structure, where the core hardly
evolves with time and new words are only
attached to the periphery of the network.
These properties are fundamental to the
nature of word co-occurrence across lan-
guages.
1 Introduction
In a natural language, words interact among them-
selves in different ways ? some words co-occur
with certain words at a very high probability
than other words. These co-occurrences are non-
trivial, as in their patterns cannot be inferred from
the frequency distribution of the individual words.
Understanding the structure and the emergence of
these patterns can present us with important clues
and insights about how we evolved this extremely
complex phenomenon, that is language.
In this paper, we present an in-depth study of
the word co-occurrence patterns of a language in
the framework of complex networks. The choice
of this framework is strongly motivated by its
success in explaining various properties of word
co-occurrences previously (Ferrer-i-Cancho and
Sole?, 2001; Ferrer-i-Cancho et al 2007; Kapustin
and Jamsen, 2007). Local properties, such as
the degree distribution and clustering coefficient
of the word co-occurrence networks, have been
thoroughly studied for a few languages (Ferrer-
i-Cancho and Sole?, 2001; Ferrer-i-Cancho et al
2007; Kapustin and Jamsen, 2007) and many in-
teresting conclusions have been drawn. For in-
stance, it has been found that these networks are
small-world in nature and are characterized by a
two regime power-law degree distribution. Efforts
have also been made to explain the emergence of
such a two regime degree distribution through net-
work growth models (Dorogovstev and Mendes,
2001). Although it is tempting to believe that a
lot is known about word co-occurrences, in or-
der to obtain a deeper insight into how these co-
occurrence patterns emerged there are many other
interesting properties that need to be investigated.
One such property is the spectrum of the word co-
162
occurrence network which can provide important
information about its global organization. In fact,
the application of this powerful mathematical ma-
chinery to infer global patterns in linguistic net-
works is rarely found in the literature (few excep-
tions are (Belkin and Goldsmith, 2002; Mukher-
jee et al 2009)). However, note that spectral anal-
ysis has been quite successfully applied in the
analysis of biological and social networks (Baner-
jee and Jost, 2007; Farkas et al 2001).
The aim of the present work is to investigate
the spectral properties of a word co-occurrence
network in order to understand its global struc-
ture. In particular, we study the properties of
seven different languages namely Bangla (Indo-
European family), English (Indo-European fam-
ily), Estonian (Finno-Ugric family), French (Indo-
European family), German (Indo-European fam-
ily), Hindi (Indo-European family) and Tamil
(Dravidian family). Quite importantly, as we shall
see, the most popular growth model proposed by
Dorogovtsev and Mendes (DM) (Dorogovstev and
Mendes, 2001) for explaining the degree distribu-
tion of such a network is not adequate to repro-
duce the spectrum of the network. This observa-
tion holds for all the seven different languages un-
der investigation. We shall further attempt to iden-
tify the precise (linguistic) reasons behind this dif-
ference in the spectrum of the empirical network
and the one reproduced by the model. Finally, as
an additional objective, we shall present a hitherto
unreported deeper analysis of this popular model
and show how its most important parameter is cor-
related to the size of the corpus from which the
empirical network is constructed.
The rest of the paper is laid out as follows.
In section 2, we shall present a brief review of
the previous works on word co-occurrence net-
works. This is followed by a short primer to spec-
tral analysis. In section 4, we outline the construc-
tion methodology of the word co-occurrence net-
works and present the experiments comparing the
spectrum of these real networks with those gen-
erated by the DM model. Section 5 shows how
the most important parameter of the DM model
varies with the size of the corpus from which the
co-occurrence networks are constructed. Finally,
we conclude in section 6 by summarizing our con-
tributions and pointing out some of the implica-
tions of the current work.
2 Word Co-occurrence Networks
In this section, we present a short review of the
earlier works on word co-occurrence networks,
where the nodes are the words and an edge be-
tween two words indicate that the words have co-
occurred in a language in certain context(s). The
most basic and well studied form of word co-
occurrence networks are the word collocation net-
works, where two words are linked by an edge if
they are neighbors (i.e., they collocate) in a sen-
tence (Ferrer-i-Cancho and Sole?, 2001).
In (Ferrer-i-Cancho and Sole?, 2001), the au-
thors study the properties of two types of col-
location networks for English, namely the unre-
stricted and the restricted ones. While in the unre-
stricted network, all the collocation edges are pre-
served, in the restricted one only those edges are
preserved for which the probability of occurrence
of the edge is higher than the case when the two
words collocate independently. They found that
both the networks exhibit small-world properties;
while the average path length between any two
nodes in these networks is small (between 2 and
3), the clustering coefficients are high (0.69 for the
unrestricted and 0.44 for the restricted networks).
Nevertheless, the most striking observation about
these networks is that the degree distributions fol-
low a two regime power-law. The degree distribu-
tion of the 5000 most connected words (i.e., the
kernel lexicon) follow a power-law with an expo-
nent ?3.07, which is very close to that predicted
by the Baraba?si-Albert growth model (Baraba?si
and Albert, 1999). These findings led the au-
thors to argue that the word usage of the human
languages is preferential in nature, where the fre-
quency of a word defines the comprehensibility
and production capability. Thus, higher the us-
age frequency of a word, higher is the probability
that the speakers will be able to produce it eas-
ily and the listeners will comprehend it fast. This
idea is closely related to the recency effect in lin-
guistics (Akmajian, 1995).
Properties of word collocation networks have
also been studied for languages other than En-
glish (Ferrer-i-Cancho et al 2007; Kapustin and
163
Jamsen, 2007). The basic topological characteris-
tics of all these networks (e.g., scale-free, small
world, assortative) are similar across languages
and thus, point to the fact that like Zipf?s law,
these are also linguistic universals whose emer-
gence and existence call for a non-trivial psycho-
linguistic account.
In order to explain the two regime power-
law in word collocation networks, Dorogovtsev
and Mendes (Dorogovstev and Mendes, 2001)
proposed a preferential attachment based growth
model (henceforth referred to as the DM model).
In this model, at every time step t, a new word
(i.e., a node) enters the language (i.e., the net-
work) and connects itself preferentially to one of
the pre-existing nodes. Simultaneously, ct (where
c is a positive constant and a parameter of the
model) new edges are grown between pairs of
old nodes that are chosen preferentially. Through
mathematical analysis and simulations, the au-
thors successfully establish that this model gives
rise to a two regime power-law with exponents
very close to those observed in (Ferrer-i-Cancho
and Sole?, 2001). In fact, for English, the val-
ues kcross (i.e., the point where the two power
law regimes intersect) and kcut (i.e., the point
where the degree distribution cuts the x-axis) ob-
tained from the model are in perfect agreement
with those observed for the empirical network.
Although the DM model is capable of explain-
ing the local topological properties of the word
collocation network, as we shall see in the forth-
coming sections, it is unable to reproduce the
global properties (e.g., the spectrum) of the net-
work.
3 A Primer to Spectral Analysis
Spectral analysis1 is a powerful mathematical
method capable of revealing the global structural
patterns underlying an enormous and complicated
environment of interacting entities. Essentially, it
refers to the systematic investigation of the eigen-
values and the eigenvectors of the adjacency ma-
trix of the network of these interacting entities.
In this section, we shall briefly outline the basic
1The term spectral analysis is also used in the context
of signal processing, where it refers to the study of the fre-
quency spectrum of a signal.
concepts involved in spectral analysis and discuss
some of its applications (see (Chung, 1994) for
details).
A network consisting of n nodes (labeled as
1 through n) can be represented by an n ? n
square matrix A, where the entry aij represents
the weight of the edge from node i to node j. Note
that A, which is known as the adjacency matrix,
is symmetric for an undirected graph and have
binary entries for an unweighted graph. ? is an
eigenvalue of A if there is an n-dimensional vec-
tor x such that
Ax = ?x
Any real symmetric matrix A has n (possibly non-
distinct) eigenvalues ?0 ? ?1 ? . . . ? ?n?1,
and corresponding n eigenvectors that are mutu-
ally orthogonal. The spectrum of a network is
the set of the distinct eigenvalues of the graph and
their corresponding multiplicities. It is a distribu-
tion usually represented in the form of a plot with
the eigenvalues in x-axis and their multiplicities in
the y-axis.
The spectrum of real and random networks dis-
play several interesting properties. Banerjee and
Jost (Banerjee and Jost, 2007) report the spectrum
of several biological networks and show that these
are significantly different from the spectrum of ar-
tificially generated networks. It is worthwhile to
mention here that spectral analysis is also closely
related to Principal Component Analysis and Mul-
tidimensional Scaling. If the first few (say d)
eigenvalues of a matrix are much higher than the
rest of the eigenvalues, then one can conclude that
the rows of the matrix can be approximately rep-
resented as linear combinations of d orthogonal
vectors. This further implies that the correspond-
ing graph has a few motifs (subgraphs) that are re-
peated a large number of time to obtain the global
structure of the graph (Banerjee and Jost, 2009).
In the next section, we shall present a thorough
study of the spectrum of the word co-occurrence
networks across various languages.
4 Experiments and Results
For the purpose of our experiments, we con-
struct word collocation networks for seven dif-
ferent languages namely, Bangla, English, Esto-
164
Figure 1: Cumulative degree distributions for Bangla, English, Estonian, French, German, Hindi and
Tamil respectively. Each red line signifies the degree distribution for the empirical network while each
blue line signifies the one obtained from the DM model.
Lang. Tokens (Mill.) Words KLD c Max. Eig. (Real) Max. Eig. (DM)
English 32.5 97144 0.21 5.0e-4 849.1 756.8Hindi 20.2 99210 0.32 2.3e-4 472.5 329.5Bangla 12.7 100000 0.29 2.0e-3 326.2 245.0German 5.0 159842 0.19 6.3e-5 192.3 110.7Estonian 4.0 100000 0.25 1.1e-4 158.6 124.0Tamil 2.3 75929 0.24 9.9e-4 116.4 73.06French 1.8 100006 0.44 8.0e-5 236.1 170.1
Table 1: Summary of results comparing the structural properties of the empirical networks for the seven
languages and the corresponding best fits (in terms of KLD) obtained from the DM model.
nian, French, German, Hindi and Tamil. We used
the corpora available in the Lipezig Corpora Col-
lection (http://corpora.informatik.uni-leipzig.de/)
for English, Estonian, French and German. The
Hindi, Bangla and Tamil corpora were collected
by crawling some online newspapers. In these net-
works, each distinct word corresponds to a ver-
tex and two vertices are connected by an edge
if the corresponding two words are adjacent in
one or more sentences in the corpus. We assume
the network to be undirected and unweighted (as
in (Ferrer-i-Cancho and Sole?, 2001)).
As a following step, we simulate the DM model
and reproduce the degree distribution of the col-
location networks for the seven languages. We
vary the parameter c in order to minimize the KL
165
divergence (KLD) (Kullback and Leibler, 1951)
between the empirical and the synthesized dis-
tributions and, thereby, obtain the best match.
The results of these experiments are summarized
through Figure 1 and Table 1. The results clearly
show that the DM model is indeed capable of gen-
erating the degree distribution of the collocation
networks to a very close approximation for cer-
tain values of the parameter c (see Table 1 for the
values of c and the corresponding KLD).
Subsequently, for the purpose of spectral anal-
ysis, we construct subgraphs induced by the top
5000 nodes for each of the seven empirical net-
works as well as those generated by the DM model
(i.e., those for which the degree distribution fits
best in terms of KLD with the real data). We then
compute and compare the spectrum of the real
and the synthesized networks (see Figure 2 and
Table 1). It is quite apparent from these results
that the spectra of the empirical networks are sig-
nificantly different from those obtained using the
DM model. In general, the spectral plots indicate
that the adjacency matrices for networks obtained
from the DM model have a higher rank than those
for the empirical networks. Further, in case of the
synthesized networks, the first eigenvalue is sig-
nificantly larger than the second whereas for the
empirical networks the top 3 to 4 eigenvalues are
found to dominate. Interestingly, this property is
observed across all the languages under investiga-
tion.
We believe that the difference in the spectra is
due to the fact that the ordering of the words in
a sentence are strongly governed by the grammar
or the syntax of the language. Words belong to
a smaller set of lexico-syntactic categories, which
are more commonly known as the parts-of-speech
(POS). The co-occurrence patterns of the words
are influenced, primarily, by its POS category. For
instance, nouns are typically preceded by articles
or adjectives, whereas verbs might be preceded by
auxiliary verbs, adverbs or nouns, but never ar-
ticles or adjectives. Therefore, the words ?car?
and ?camera? are more likely to be structurally
similar in the word co-occurrence network, than
?car? and ?jumped?. In general, the local neigh-
borhoods of the words belonging to a particular
POS is expected to be very similar, which means
that several rows in the adjacency matrix will be
very similar to each other. Thus, the matrix is ex-
pected to have low rank.
In fact, this property is not only applicable to
syntax, but also semantics. For instance, even
though adjectives are typically followed by nouns,
semantic constraints make certain adjective-noun
co-occurrences (e.g., ?green leaves?) much more
likely than some others (e.g., ?green dreams? or
?happy leaves?). These notions are at the core of
latent semantics and vector space models of se-
mantics (see, for instance, Turney and Pantel (Tur-
ney and Pantel, 2010) for a recent study). The DM
model, on the other hand, is based on the recency
effect that says that the words which are produced
most recently are easier to remember and there-
fore, easier to produce in the future. Preferential
attachment models the recency effect in word pro-
duction, which perhaps is sufficient to replicate
the degree distribution of the networks. However,
the model fails to explain the global properties,
precisely because it does not take into account
the constraints that govern the distribution of the
words.
It is quite well known that the spectrum of a net-
work can be usually obtained by iteratively pow-
ering the adjacency matrix of the network (aka
power iteration method). Note that if the adja-
cency matrices of the empirical and the synthe-
sized networks are powered even once (i.e., they
are squared)2, their degree distributions match no
longer (see Figure 3). This result further cor-
roborates that although the degree distribution of
a word co-occurrence network is quite appropri-
ately reproduced by the DM model, more global
structural properties remain unexplained. We be-
lieve that word association in human languages
is not arbitrary and therefore, a model which ac-
counts for the clustering of words around their
POS categories might possibly turn out to present
a more accurate explanation of the spectral prop-
erties of the co-occurrence networks.
166
Figure 2: The spectrum for Bangla, English, Estonian, French, German, Hindi and Tamil respectively.
The last plot shows a portion of the spectrum for English magnified around 0 for better visualization.
All the curves are binned distributions with bin size = 100. The blue line in each case is the spectrum
for the network obtained from the DM model while each red line corresponds to the spectrum for the
empirical network.
5 Reinvestigating the DM Model
In this section, we shall delve deeper into explor-
ing the properties of the DM model since it is one
of the most popular and well accepted models for
explaining the emergence of word associations in
a language. In particular, we shall investigate the
influence of the model parameter c on the emer-
gent results.
If we plot the value of the parameter c (from
Table 1) versus the size of the corpora (from Ta-
ble 1) used to construct the empirical networks for
the different languages we find that the two are
highly correlated (see Figure 4).
2Note that this squared network is weighted in nature. We
threshold all edges below the weight 0.07 so that the resultant
network is neither too dense nor too sparse. The value of the
threshold is chosen based on the inspection of the data.
In order to further check the dependence of c
on the corpus size we perform the following ex-
periment. We draw samples of varying corpus
size and construct empirical networks from each
of them. We then simulate the DM model and at-
tempt to reproduce the degree distribution for each
of these empirical networks. In each case, we note
the value c for which the KLD between the empir-
ical and the corresponding synthesized network is
minimum. Figure 5 shows the result of the above
experiment for English. The figure clearly indi-
cates that as the corpus size increases the value of
the parameter c decreases. Similar trends are ob-
served for all the other languages.
In general, one can mathematically prove that
the parameter c is equal to the rate of change of
the average degree of the network with respect to
167
Figure 3: Cumulative degree distribution for the
squared version of the networks for English. The
red line is the degree distribution for the squared
version of the empirical network while the blue
line is degree distribution of the squared version
of the network obtained from the DM model. The
trends are similar for all the other languages.
the time t. The proof is as follows.
At every time step t, the number of new edges
formed is (1+ct). Since each edge contributes to
a total degree of 2 to the network, the sum of the
degrees of all the nodes in the network (ktot) is
ktot = 2
T?
t=1
(1 + ct) = 2T + cT (T + 1) (1)
At every time step, only one new node is added
to the network and therefore the total number of
nodes at the end of time T is exactly equal to T .
Thus the average degree of the network is
?k? = 2T + cT (T + 1)T = 2 + c(T + 1) (2)
The rate of change of average degree is
d?k?
dT = c (3)
and this completes the proof.
In fact, it is also possible to make a precise
empirical estimate of the value of the parameter
c. One can express the average degree of the co-
occurrence networks as the ratio of twice the bi-
gram frequency (i.e., twice the number of edges
in the network) to the unigram frequency (i.e., the
0 5 10 15 20 25 30 350.5
1
1.5
2
2.5
3
3.5
4
4.5
5 x 10?4
Corpus Size(Across Languages)
c
Figure 4: The parameter c versus the corpus size
for the seven languages.
Figure 5: The parameter c versus the corpus size
for English.
number of nodes or unique words in the network).
Therefore, if we can estimate this ratio we can eas-
ily estimate the value of c using equation 3. Let
us denote the total number of distinct bigrams and
unigrams after processing a corpus of size N by
B(N) and W (N) respectively. Hence we have
?k? = 2B(N)W (N) (4)
Further, the number of distinct new unigrams after
Language B(N) W (N) c
English 29.2N.67 59.3N.43 .009N?.20
Hindi 26.2N.66 49.7N.46 .009N?.26
Tamil 1.9N.91 6.4N.71 .207N?.50
Table 2: Summary of expressions for B(N),
W (N) and c for English, Hindi and Tamil.
168
Figure 6: Variation of B(N) and W (N) with N
for English (in doubly-logarithmic scale). The
blue dots correspond to variation of B(N) while
the red dots correspond to the variation of W (N).
processing a corpus of size N is equivalent to T
and therefore
T = W (N) (5)
Sampling experiments across different languages
demonstrate that W (N) and B(N) are of the form
?N? (? < 1) where ? and ? are constants. For
instance, Figure 6 shows in doubly-logarithmic
scale how B(N) and W (N) varies with N for
English. The R2 values obtained as a result of
fitting the B(N) versus N and the W (N) ver-
sus N plots using equations of the form ?N? for
English, Hindi and Tamil are greater than 0.99.
This reflects the high accuracy of the fits. Similar
trends are observed for all the other languages.
Finally, using equations 3, 4 and 5 we have
c = d?k?dT =
d?k?
dN
dN
dT (6)
and plugging the values of B(N) and W (N) in
equation 6 we find that c has the form ?N?? (? <
1) where ? and ? are language dependent positive
constants. The values of c obtained in this way
for three different languages English, Hindi and
Tamil are noted in Table 5.
Thus, we find that as N ? ?, c ? 0. In
other words, as the corpus size grows the number
of distinct new bigrams goes on decreasing and
ultimately reaches (almost) zero for a very large
sized corpus. Now, if one plugs in the values of c
and T obtained above in the expressions for kcross
and kcut in (Dorogovstev and Mendes, 2001), one
observes that limN?? kcrosskcut = 0. This impliesthat as the corpus size becomes very large, the
two-regime power law (almost) converges to a sin-
gle regime with an exponent equal to -3 as is ex-
hibited by the Baraba?si-Albert model (Baraba?si
and Albert, 1999). Therefore, it is reasonable to
conclude that although the DM model provides a
good explanation of the degree distribution of a
word co-occurrence network built from a medium
sized corpora, it does not perform well for very
small or very large sized corpora.
6 Conclusions
In this paper, we have tried to investigate in de-
tail the co-occurrence properties of words in a
language. Some of our important observations
are: (a) while the DM model is able to reproduce
the degree distributions of the word co-occurrence
networks, it is not quite appropriate for explaining
the spectrum of these networks; (b) the parameter
c in the DM model signifies the rate of change of
the average degree of the network with respect to
time; and (c) the DM model does not perform well
in explaining the degree distribution of a word co-
occurrence network when the corpus size is very
large.
It is worthwhile to mention here that our analy-
sis of the DM model leads us to a very important
observation. As N grows, the value of kcut grows
at a much faster rate than the value of kcross and
in the limit N ?? the value of kcut is so high as
compared to kcross that the ratio kcrosskcut becomes(almost) zero. In other words, the kernel lexicon,
formed of the words in the first regime of the two
regime power-law and required to ?say everything
or almost everything? (Ferrer-i-Cancho and Sole?,
2001) in a language, grows quite slowly as new
words creep into the language. In contrast, the pe-
ripheral lexicon making the other part of the two
regime grows very fast as new words enter the lan-
guage. Consequently, it may be argued that since
the kernel lexicon remains almost unaffected, the
effort to learn and retain a language by its speak-
ers increases only negligibly as new words creep
into the language.
169
References
A. Akmajian. Linguistics: An introduction to Lan-
guage and Communication. MIT Press, Cambridge,
MA, 1995.
A. Banerjee and J. Jost. Spectral plots and the repre-
sentation and interpretation of biological data. The-
ory in Biosciences, 126(1), 15-21, 2007.
A. Banerjee and J. Jost. Graph spectra as a system-
atic tool in computational biology. Discrete Applied
Mathematics, 157(10), 2425?2431, 2009.
A.-L. Baraba?si and R. Albert. Emergence of scaling in
random networks. Science, 286, 509-512, 1999.
M. Belkin and J. Goldsmith. Using eigenvectors of
the bigram graph to infer morpheme identity. In
Proceedings of Morphological and Phonological
Learning, Association for Computational Linguis-
tics, 41-47, 2002.
F. R. K. Chung. Spectral Graph Theory. Number 2 in
CBMS Regional Conference Series in Mathematics,
American Mathematical Society, 1994.
S. N. Dorogovstev and J. F .F. Mendes. Language as an
evolving word Web. Proceedings of the Royal Soci-
ety of London B, 268, 2603-2606, 2001.
I. J. Farkas, I. Dere?nyi, A. -L. Baraba?si and T. Vicsek.
Spectra of ?real-world? graphs: Beyond the semi-
circle law, Physical Review E, 64, 026704, 2001.
R. Ferrer-i-Cancho and R. V. Sole?. The small-world of
human language. Proceedings of the Royal Society
of London B, 268, 2261?2266, 2001.
R. Ferrer-i-Cancho, A. Mehler, O. Pustylnikov and
A. D??az-Guilera. Correlations in the organization
of large-scale syntactic dependency networks. In
Proceedings of TextGraphs-2: Graph-Based Algo-
rithms for Natural Language Processing, 65-72, As-
sociation for Computational Linguistics, 2007.
V. Kapustin and A. Jamsen. Vertex degree distribution
for the graph of word co-occurrences in Russian. In
Proceedings of TextGraphs-2: Graph-Based Algo-
rithms for Natural Language Processing, 89-92, As-
sociation for Computational Linguistics, 2007.
S. Kullback and R. A. Leibler. On information and
sufficiency. Annals of Mathematical Statistics 22(1),
79-86, 1951.
A. Mukerjee, M. Choudhury and R. Kannan. Discov-
ering global patterns in linguistic networks through
spectral analysis: A case study of the consonant in-
ventories. In Proceedings of EACL, 585?593, Asso-
ciation for Computational Linguistics, 2009.
P. D. Turney and P. Pantel. From frequency to meaning:
Vector space models of semantics. In JAIR, 37, 141-
188, 2010.
170
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1037?1046, Dublin, Ireland, August 23-29 2014.
Automatic Discovery of Adposition Typology
Rishiraj Saha Roy
IIT Kharagpur
Kharagpur, India ? 721302.
rishiraj@cse.iitkgp.ernet.in
Rahul Katare
?
IIT Kharagpur
Kharagpur, India ? 721302.
rah.ykg@gmail.com
Niloy Ganguly
IIT Kharagpur
Kharagpur, India ? 721302.
niloy@cse.iitkgp.ernet.in
Monojit Choudhury
Microsoft Research India
Bangalore, India ? 560001.
monojitc@microsoft.com
Abstract
Natural languages (NL) can be classified as prepositional or postpositional based on the order of
the noun phrase and the adposition. Categorizing a language by its adposition typology helps in
addressing several challenges in linguistics and natural language processing (NLP). Understand-
ing the adposition typologies for less-studied languages by manual analysis of large text corpora
can be quite expensive, yet automatic discovery of the same has received very little attention till
date. This research presents a simple unsupervised technique to automatically predict the adpo-
sition typology for a language. Most of the function words of a language are adpositions, and we
show that function words can be effectively separated from content words by leveraging differ-
ences in their distributional properties in a corpus. Using this principle, we show that languages
can be classified as prepositional or postpositional based on the rank correlations derived from
entropies of word co-occurrence distributions. Our claims are substantiated through experiments
on 23 languages from ten diverse families, 19 of which are correctly classified by our technique.
1 Introduction
Adpositions form a subcategory of function words that combine with noun phrases to denote their se-
mantic or grammatical relationships with verbs, and sometimes other noun phrases. NLs can be neatly
divided into a few basic typologies based on the order of the noun phrase and its adposition. If the ad-
position is placed before the noun phrase, it is called a preposition. Postpositions and inpositions, on the
other hand, are adpositions that are placed after and inside noun phrases respectively. If prepositions are
predominantly used in the language, for example in English, Bulgarian and Russian, then the language
is said to be prepositional. Similarly, Japanese, Hindi and Turkish are some examples of postpositional
languages, which predominantly use postpositions. These two are the most commonly found adposition
typologies across the globe. Out of 1185 languages analyzed on the World Atlas of Language Structures
(WALS)
1
(Dryer and Haspelmath, 2011), there are 577 postpositional, 512 prepositional and only 8 in-
positional languages. There are a few (30 and 58 respectively) languages which use no or both kinds of
adpositions. The order of adpositions is strongly correlated with many other word order typologies. For
instance, postpositional languages usually have Object-Verb ordering, whereas prepositional languages
have Verb-Object ordering (Greenberg, 1963). Daum?e and Campbell (2007) present a statistical model
for automatically discovering such implications from a large typological database and discuss many other
typological implications involving adpositions.
Motivation. Knowledge of the typological characteristics of languages is not only of interest to lin-
guists, but also very useful in NLP for two main reasons. First, typological information, if appropriately
exploited while designing computational methods, can lead to very promising results in tasks like co-
reference resolution and machine translation (Haghighi and Klein, 2007; Moore and Quirk, 2007). Sec-
ond, as Bender and Langendoen (2010) have pointed out, in order to claim that a computational technique
?
This work was done during the author?s internship at Microsoft Research India.
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1
http://wals.info/
1037
is truly language independent, one must show its usefulness for languages having diverse typological fea-
tures. However, there is very little work on the automatic discovery of typological characteristics, primar-
ily because it is assumed that such information is readily available. However, Hammarstr?om et al. (2008)
argue that documenting a language and its typological features is a time consuming process for the lin-
guists and therefore, automatic methods for bootstrapping language description is a worthwhile effort
towards language preservation. Lewis and Xia (2008) mine inter-linearized data from the Web and infer
typological features for ?low-density? languages, i.e. languages represented in scarce quantities on the
Web. We argue that apart from documenting and understanding the typology of ?low-density? languages,
unsupervised discovery of adposition typology is also useful for analyzing undeciphered languages and
scripts, such as the Indus valley script (Rao et al., 2009) and the Cypro-Minoan syllabary (Palaima,
1989), as well as newly emerging languages, such as the language of Web search queries (Saha Roy et
al., 2012) or the Nicaraguan sign language (Meir et al., 2010). While the former cases are interesting
from historical and language change perspectives, the latter cases are useful for more practical reasons
(for example, improvement in query understanding leading to better Web search, and development of
interactive systems for deaf children).
Approach. In this work, we show that some simple word co-occurrence statistics, that can easily be
computed from any medium-sized text corpus, can be used as reliable predictors of adposition typology
of a language. These statistics have been arrived at based on two fundamental assumptions: (a) adposi-
tions constitute a large fraction of function words; and (b) the strict ordering between the adposition and
the noun phrase leads to differential co-occurrence characteristics on the left and right sides of the adpo-
sition. Therefore, if the function words of a language are automatically detected and the co-occurrence
statistics on the left and right of those words are appropriately analyzed, then it should be possible to
tell the prepositional languages apart from the postpositional ones. Specifically, we measure counts and
entropies of left, right and total (either side) co-occurrence distributions for each word. We show that left
co-occurrence statistics are better indicators of function words for prepositional languages, while right
co-occurrence statistics perform better for postpositional languages. Interestingly, the performance of
total co-occurrence statistics lie in between the two for both types of languages. Thus, the nature of the
difference in performances of left (or right) and total co-occurrences is likely to be indicative of the ad-
position typology of the language. We formalize this intuition to devise our test for adposition typology.
We demonstrate our technique on 23 languages from ten language families, of which 14 are prepositional
and 9 are postpositional. Our technique is able to consistently predict the correct adposition typology for
19 of these languages. The remaining four languages are highly inflectional and agglutinating in nature,
and hence not amenable to the present technique.
Organization. The rest of this paper is organized as follows. In Sec. 2, we present our method for
function word detection using word co-occurrence statistics, along with results showing the effectiveness
of such an approach. In Sec. 3, we propose our test for discovering the adposition typology of a language
based on correlations inferred from different co-occurrence statistics. Sec. 4 discusses experiments con-
ducted on diverse languages and inferences drawn from the observations. Finally, Sec. 5 summarizes our
contribution and indicates possible directions for future work.
2 Function Word Detection
Our method for the prediction of the adposition typology of a language relies on the facts that most
adpositions are function words, and the distributional properties of function words are very different
from those of content words. We exploit this difference to first formulate a method for extracting the
function words of a language from a corpus. We then proceed to use the same underlying principle
to automatically discover the adposition typology for languages, where we do not assume that the true
function word lists are available.
By function words, we refer to all the closed-class lexical items in a language, e.g., pronouns, de-
terminers, prepositions, conjunctions, interjections and other particles (as opposed to open-class items,
e.g., nouns, verbs, adjectives and adverbs). For the function word detection experiments, we shall look
at four languages from different families: English, Italian, Hindi and Bangla. English is a Germanic
1038
Language Corpus source S N V Function word list source F
English Leipzig Corpora
a
1M 19.8M 342157 Sequence Publishing
b
229
Italian -do- 1M 20M 434680 -do- 257
Hindi -do- 0.3M 5.5M 127428 Manually constructed by linguists and 481
augmented by extracting pronouns,
determiners, prepositions, conjunctions
and interjections from POS-tagged
corpora available at LDC
c
Bangla Crawl of Anandabazar Patrika
d
0.05M 16.2M 411878 -do- 510
a
http://corpora.informatik.uni-leipzig.de/download.html
b
http://www.sequencepublishing.com/academic.html\#function-words
c
http://www.ldc.upenn.edu (Catalog Nos. LDC2010T24 and LDC2010T16 for Hindi and Bangla respectively)
d
http://www.anandabazar.com/
Table 1: Details of NL corpora for function word detection experiments.
language, Italian is a Romanic language, and Hindi and Bangla belong to the Indo-Aryan family. English
and Italian are prepositional languages with subject-verb-object word order, while Hindi and Bangla are
postpositional, relatively free word order with preference for subject-object-verb. Therefore, any func-
tion word characterization strategy that works across these languages is expected to work for a large
variety of languages.
The details of the corpora used for these four languages are summarized in Table 1. M in the value
columns denotes million. S, N , V and F denote the numbers of all sentences, all words, unique words
(vocabulary size) and function words, respectively. We note that the Indian languages have almost twice
as many function words as compared to the European ones. This is due to morphological richness and
the existence of large numbers of modal and vector verbs.
Frequency is often used as an indicator for detecting function words, but the following factors affect
its robustness. If the corpus size is not large, many function words will not occur a sufficient num-
ber of times. For example, even though the and in will be very frequent in most English corpora,
meanwhile and off may not be so. As a result, if frequency is used as a function word detector with
small datasets, we will have a problem of low recall. In our experiments, we measure corpus size, N ,
as the total number of words present. If our language corpus is restricted, or sampled only from specific
domains, words specific to those domains will have high frequencies and will get detected as function
words. For example, the word government will be much more frequent in political news corpora than
although. The number of unique words in a corpus, or the vocabulary size, V , is a good indicator of
its diversity. For restricted domain corpora, V grows much more slowly withN than in a general domain
corpus.
We now introduce other properties of function words that may help in more robust detection. We
observe the following interesting characteristics about the syntactic distributions of function and content
words in NL, which can be summarized by the following two postulates.
Postulate I. Function words, in general, tend to co-occur with a larger number of distinct words than
content words. What can occur to the immediate left or right of a content word is much more restricted
than that in the case of function words. We hypothesize that even if a content word, e.g., government,
might have high frequency owing to the nature of the domain, there will only be a relatively fewer number
of words that can co-occur immediately after or before it. Therefore, the co-occurrence count may be a
more robust indicator of function words.
Postulate II. The co-occurrence patterns of function words are less likely to show bias towards spe-
cific words than those for content words. For example, and will occur beside several other words like
school, elephant and pipe with more or less equally distributed co-occurrence counts with all of
these words. In contrast, the co-occurrence distribution of school will be skewed, with more bias to-
wards to, high and bus than over, through and coast, with the list of words occurring beside
school also being much smaller than that for and.
In order to test Postulate I, we measure the number of distinct words that occur to the immediate left,
1039
right and either side of each unique word in the sub-sampled corpora. We shall refer to these statistics
as left, right and total co-occurrence counts (LCC, RCC and TCC) respectively. To test Postulate II, we
compute the entropy of the co-occurrence distributions of the words occurring to the left, right and either
side (i.e., total) contexts of a word w:
Entropy(w) = ?
?
t
i
? context(w)
p
t
i
|w
log
2
(p
t
i
|w
) (1)
where, context(w) is the set of all words co-occurring with w either in the left, the right or the total
contexts, and p(t
i
|w) is the probability of observing word t
i
in that specific context.
Context. In this paper, the left, right and total contexts of a word w respectively denote the imme-
diately preceding (one) word, immediately succeeding (one) word and both the immediately preceding
and the immediately succeeding words for w respectively, in sentences of the corpus. The definition of
context (i.e., whether it includes the preceding or the succeeding one or two or three words) will change
the absolute values of our results, but all the trends are expected to remain the same.
We shall refer to the co-occurrence entropies as left, right and total Co-occurrence Entropies (LCE,
RCE and TCE respectively). Due to their pivotal role in syntactically connecting the different words or
parts of a sentence to each other, we would expect LCC, RCC or TCC of function words to be higher
than that of content words due to Postulate I; similarly, due to Postulate II we can expect the LCE, RCE
or TCE to be higher for function words than for content words. If the LCE or LCC of a word w is high,
it means that a large number of distinct words can precede w in the language (additionally, almost with
equal probabilities for high LCE). Thus, predicting the previous word of w is difficult. Similarly, if RCE
or RCC of w is high, it means that a large number of words can follow w in the language (additionally,
almost with equal probabilities for high RCE). Thus, predicting the next word of w is difficult. A high
TCE for a word implies that the word can be preceded and followed by a large number of words, making
the prediction of either the next or the previous word (or both) for w difficult.
2.1 Experiments and Results
In our approach, the output is a ranked list of words sorted in descending order of the corresponding
property. Here we adopt a popular metric, Average Precision (AP), used in Information Retrieval (IR)
for the evaluation of ranked lists. More specifically, let w
1
, w
2
, . . . , w
n
be a ranked list of words sorted
according to some corpus statistic, say, frequency. Thus, if i < j, then frequency of w
i
is greater than
the frequency of w
j
. Precision at rank k, denoted by P@k, is defined as
P@k =
1
k
k
?
i=1
f(w
i
) (2)
where, f(w
i
) is one if w
i
is a function word, and is zero otherwise. This function can be computed
based on the gold standard lists of function words. Subsequently, average precision at rank n, denoted
by AP@n, is defined as
AP@n =
1
n
n
?
k=1
P@k (3)
AP@n is a better metric than P@k because P@k is insensitive to the rank at which function words
occur in the list. In our experiments, we compute AP@n averaged overN corpus sub-samples, which is
given by
1
N
?
N
r=1
(AP@n)
r
where (AP@n)
r
is the AP@n for the r
th
sub-sample. We note that there are
other metrics popularly used in IR, e.g. the Normalized Discounted Cumulative Gain (nDCG). However,
these are more sensitive to the correctness of the top few items in the list and hence, are not suitable for
us. Knowing that the number of function words in a popular NL is at least 200 (Table 1), we compute
AP@200 with respect to the gold standard lists of function words for all our experiments.
1040
Language Typology Fr LCC LCE TCC TCE RCC RCE
English Prepositional 0.663 0.702
?
0.729
?
0.684
?
0.679
?
0.637 0.527
Italian Prepositional 0.611 0.639
?
0.645
?
0.636
?
0.620 0.606 0.601
Hindi Postpositional 0.682 0.614 0.510 0.698
?
0.694
?
0.716
?
0.713
?
Bangla Postpositional 0.648 0.684
?
0.691
?
0.730
?
0.763
?
0.741
?
0.757
?
The four highest values in a row are marked in boldface. Statistically significant improvement over frequency is marked by
?
.
The paired t-test was performed and the null hypothesis was rejected if p-value < 0.05.
Table 2: AP@200 for all indicators, averaged over 200 (N , V ) pairs for each language.
(a) (b)
Figure 1: (Colour online) Performance of co-occurrence statistics for (a) English, and (b) Hindi, with
respect to frequency for AP@200 with variation in N.
We now sort the list of all words in descending order of each of the seven indicators. We then compute
AP@200 for these seven lists. To bring out the performance difference of each of the six co-occurrence
features with respect to frequency, we plot (in Figs. 1 and 2) the following measure against N :
Value plotted =
Metric for indicator ? Metric for Fr
Metric for Fr
(4)
The x-axis can now be thought of as representing the performance of frequency. In Fig. 1, for a
particular N , the data points were averaged over all (N , V ) pairs (we had 20 (N , V ) pairs for each N ).
For Fig. 2, V was binned into five zones, and for each zone, the AP was averaged over all corresponding
(N , V ) pairs. The observations (both N and V variation) for French and Italian were similar to that of
English, while those for Hindi and Bangla were similar to each other. Table 2 reports AP values for all
statistics for the four languages. From Table 2, we see that for all the languages, AP for some of the
co-occurrence statistics are higher than AP obtained using frequency.
Regular improvements over frequency. From the plots and Table 2, it is evident that some of the
co-occurrence statistics consistently beat frequency as indicators. In fact, as evident from Figs. 1 and
2, use of co-occurrence statistics results in systematic improvement over frequency with variations in N
and V , and hence, are very robust indicators. Among the co-occurrence statistics, both entropies and
counts are observed to have comparable performance.
3 Detection of Adposition Typology
From the results presented above, we observe that the best function word indicator depends upon lan-
guage typology. Interestingly, while LCE and LCC are the best indicators of function words for the two
prepositional languages of English and Italian, RCE and RCC perform better for Hindi and Bangla, the
postpositional languages. This observation can be explained as follows. For a prepositional language,
the function words, which are often the adpositions, precede the content word it is linked to. Therefore,
the words following an adposition (or a function word) mark the beginnings of syntactic units such as
1041
(a) (b)
Figure 2: (Colour online) Performance of co-occurrence statistics for (a) Italian, and (b) Bangla, with
respect to frequency for AP@200 with variation in V.
noun phrases and are typically restricted to certain syntactic categories. However, the words that precede
the adpositions have no or much weaker syntactic restrictions. Hence, the LCE and LCC are higher and
consequently better and more robust indicators of function words for prepositional languages. For very
similar reasons, the RCE and RCC are better indicators of function words for postpositional languages.
Importantly, we observe that TCE and TCC seem to be reasonably good predictors of function words
irrespective of the typology, with performances lying in between the poorest indicators (RCE and RCC
for prepositional languages and LCE and LCC for postpositional languages) and the best indicators (LCE
and LCC for prepositional languages and RCE and RCC for postpositional languages) for all the four
languages. This makes them safe indicators to rely on when not much is known about the language
syntax. In fact, the philosophy of this research is to be of assistance in these less-known cases. Thus,
co-occurrence statistics have potential in predicting the adposition typology of a new language, which
we leverage in this research.
We now describe our intuition and method behind our tests for automatically detecting the adposition
typology of a language. In this context, we do not know the actual function words or adpositions of the
language under consideration. Let us take the three lists of the top 200 words from a language corpus,
sorted according to the statistics TCE, LCE and RCE. For a prepositional language, we can expect to see
the highest number of function words towards the top of the list when sorted according to LCE, followed
by the number of function words towards the top of the TCE list. The RCE list would be expected to be
the poorest in this regard. Thus, we expect a higher overlap between the top 200 word lists for TCE and
LCE, than for TCE and RCE. The reverse is expected to be true for postpositional languages. Similar
arguments can be presented for LCC, RCC and TCC as well. We quantify this correlation between
the lists using two different statistics ? the Pearson?s correlation coefficient (r) and Spearman?s Rank
Correlation Coefficient (?).
For computing Pearson?s coefficients, we use the actual values of the distributional statistics, while for
Spearman?s rank coeffcients, we use the ranks of the words. Let r(TL) and ?(TL) respectively denote
the Pearson?s and Spearman?s Rank correlation coefficients of the lists sorted by TCE and LCE (or TCC
and LCC), and similarly, let r(TR) and ?(TR) denote the respective coefficients for the lists sorted by
TCE and RCE (or TCC and RCC).
Postulate. For a prepositional language, the top-200 words by LCE will have a higher correlation with
the top-200 words by TCE than the corresponding correlation of RCE with TCE. For a postpositional
language, the top-200 words by RCE will have a higher correlation with the top-200 words by TCE.
Formally, for prepositional languages, r(TL) > r(TR), and ?(TL) > ?(TR), while for postpositional
languages r(TL) < r(TR) and ?(TL) < ?(TR).
1042
Language Family ?(TL) ?(TR) ?(Diff .) Predicted True
Bulgarian Slavic (Indo-European) 0.726 0.518 0.208 Pre- Pre- (Scatton, 1984)
Danish Germanic (Indo-European) 0.621 0.495 0.126 Pre- Pre- (Allan et al., 1995)
Dutch Germanic (Indo-European) 0.662 0.204 0.458 Pre- Pre- (Shetter, 1958)
English Germanic (Indo-European) 0.461 0.436 0.025 Pre- Pre- (Selkirk, 1996)
German Germanic (Indo-European) 0.563 0.517 0.046 Pre- Pre- (Lederer, 1969)
Italian Romance (Indo-European) 0.730 0.456 0.274 Pre- Pre- (Sauer, 1891)
Macedonian Slavic (Indo-European) 0.692 0.488 0.205 Pre- Pre- (Friedman, 1993)
Norwegian Germanic (Indo-European) 0.619 0.600 0.019 Pre- Pre- (Olson, 1901)
Polish Slavic (Indo-European) 0.798 0.554 0.243 Pre- Pre- (Bielec, 1998)
Russian Slavic (Indo-European) 0.743 0.652 0.091 Pre- Pre- (Borras and Christian, 1959)
Slovenian Slavic (Indo-European) 0.701 0.668 0.032 Pre- Pre- (Priestly, 1993)
Swedish Germanic (Indo-European) 0.663 0.525 0.138 Pre- Pre- (Holmes and Hinchliffe, 1994)
Ukrainian Slavic (Indo-European) 0.785 0.714 0.070 Pre- Pre- (Stechishin, 1958)
Gujarati Indic (Indo-European) 0.540 0.581 ?0.041 Post- Post- (Cardona, 1965)
Hindi Indic (Indo-European) 0.529 0.731 ?0.202 Post- Post- (McGregor, 1977)
Japanese Japanese (Japanese) 0.429 0.626 ?0.197 Post- Post- (Hinds, 1986)
Nepali Indic (Indo-European) 0.495 0.719 ?0.224 Post- Post- (Bandhu, 1973)
Tamil Southern Dravidian (Dravidian) 0.748 0.805 ?0.057 Post- Post- (Asher, 1982)
Turkish Turkic (Altaic) 0.531 0.769 ?0.238 Post- Post- (Underhill, 1976)
Estonian Finnic(Uralic) 0.790 0.733 0.057 Pre- Post- (Tauli, 1983)
Finnish Finnic (Uralic) 0.671 0.656 0.015 Pre- Post- (Sulkala and Karjalainen, 1992)
Hungarian Ugric (Uralic) 0.457 0.329 0.128 Pre- Post- (Kenesei et al., 1998)
Lithuanian Baltic (Indo-European) 0.715 0.724 ?0.009 Post- Pre- (Dambriunas et al., 1966)
Misclassified languages are marked in gray.
Table 3: Detecting adposition typology using Spearman?s rank correlation coefficients on entropy lists.
4 Experimental Results and Observations
In this section, we first present our datasets, followed by detailed experiments on adposition typology
detection and inferences drawn from the observations.
4.1 Datasets
For all our typology detection experiments, we use datasets from the publicly available Leipzig Corpora
2
.
We selected 23 languages from various families that are typologically diverse. A (300, 000)-sentence
corpora was used for all the languages so as to ensure similar-sized corpora for all the languages (many
languages do not have a larger corpus). All languages examined have been listed in Table 3, along with
their families and true adposition typologies (accompanied by appropriate references).
4.2 Experiments and Results
We extracted the top-200 words by TCE, LCE and RCE, and TCC, LCC and RCC from the 300k-
sentence corpora. We then computed r(TL), ?(TL), r(TR) and ?(TR), for both entropies and counts.
As per our postulate, if ?(TL)? ?(TR) (= ?(Difference)) is positive, the language is prepositional; if it
is negative, the language is postpositional. The same can be expected for r(Difference).
The performance of ? as a predictor was found to be better than r. Results when the entropy lists are
used are presented in Table 3. For only 4 out of 23 languages, the typology predictions are incorrect. We
observe that three of these misclassified languages are from the Uralic family that are synthetic in nature
characterized by extensive regular agglutination of modifiers to verbs, nouns, adjectives and numerals.
2
http://corpora.informatik.uni-leipzig.de/download.html
1043
Corpus Size Entropy lists (r) Entropy lists (?) Count lists (r) Count lists (?)
10k 17/23 21/23 17/23 13/23
100k 17/23 19/23 18/23 13/23
300k 16/23 19/23 16/23 13/23
The highest value in a row is marked in boldface.
Table 4: Correct predictions by strategy with varying factors.
The average number of characters in words of these languages were found to be in the relatively higher
range of nine to eleven. Thus, function words, especially the adpositions, seldom occur as free words in
these languages and hence our method cannot capture the distributional characteristics of the adpositions.
It is worthwhile to note that the method can predict the correct typology for other languages that employ
agglutination to a lesser degree (Bulgarian, Dutch, German, Tamil and Turkish). Lithuanian, though not
synthetic, is a highly inflectional language and therefore, instead of adpositions it makes extensive use
of case-markers. With ?(Difference) very close to zero, our prediction for Lithuanian is inconclusive.
A note on synthetic languages: For synthetic languages, the difference between the two rank corre-
lation coefficients are close to zero, which provides us with a direct way to identify them. One could
also employ unsupervised morphological analysis to automatically identify and segment affixes, which
will provide deeper insight into the morpho-syntactic properties of the language. Nevertheless, affixes
(like infixes in Arabic or case-marking suffixes in Bangla) are technically not considered as adposi-
tions, and therefore, they do not really determine the adposition typology. Languages are divided into
four classes according to their adposition usage: prepositional, postpositional, ambi-positional (use both
types) and adposition-less (use none). Thus, as far as adposition typology is concerned, it suffices to
identify whether a language is primarily adposition-less, which our technique is potentially capable of
doing (we demonstrate it for four languages, but we believe more experimentation is needed to establish
this claim). Note that a language may use case-marking affixes along with adpositions. In such cases our
method is able to correctly determine the typology, as demonstrated for Bangla.
4.3 Experimental variations
We repeated the above experiments with lists of TCC, LCC and RCC instead of the co-occurrence en-
tropies. The performance was found to be poorer than the entropy lists, with nine classification errors
instead of the earlier four. Performance of these lists by co-occurrence counts was found to be poorer in
other cases as well (Table 4). We systematically experimented with r instead of ?. To test the perfor-
mance of our method with even smaller corpora, we sub-sampled 3 and 30 corpora containing 100k and
10k sentences respectively from the 300k corpus. We computed the correlation between the original top
200 words obtained using TCE (or TCC) from the 300k corpus and the corresponding LCE and RCE (or
LCC and RCC) lists obtained from the smaller corpora. For a given language, the mean of ?(Difference)
and r(Difference) were used to predict the typology (observed standard deviations were very low, of the
order of 10
?3
). The results of these experiments are summarized in Table 4. Out of 23 languages, 21 and
19 were correctly classified by ? for corpora of 10k and 100k sentences. The corresponding number for
r are 18 for both 10k and 100k, and 17 for 300k corpora. Thus, the sensitivity of the method improves
with slightly smaller corpora, provided that the TCE list, which is being used as a proxy for the gold
standard function word list, is computed from a slightly larger corpus. Finally, we note that using Spear-
man?s rank correlation coefficient with lists constructed by co-occurrence entropy consistently produces
the best results.
5 Conclusions and Future Work
Knowing the adposition typology of a natural language can be useful in several NLP tasks, and can be
especially useful in understanding new or undeciphered languages. In this research, we have taken one
1044
of the first steps towards automatic discovery of adposition typology. First, we have shown, through ex-
periments on two prepositional and two postpositional languages, that function words can be effectively
extracted from medium-sized corpora using word co-occurrence statistics, and such measures usually
outperform simple frequency when used for the same task. Next, difference in behavior of various co-
occurrence statistics for prepositional and postpositional languages has been exploited to devise a simple
strategy for predicting the adposition typology of a language. Simple differences of rank correlation
coefficients among total, left and right word co-occurrence entropies have been shown to be potent sig-
nals towards automatic discovery of adposition and noun phrase typology in a language. Results show
sufficient promise through an extensive evaluation over 23 languages.
We ventured into this study while solving a very practical and important problem: query understanding
through analysis of the structure of Web search queries. While queries seem to have an emergent syntax,
it is unclear whether they have function words, and if so what role they play in determining the query
grammar. To this end, we conducted the current study. Thus, we envisage that this technique will be
applicable for any such emergent linguistic system, such as pidgins, creoles, and computer mediated
communications (CMCs) like SMS and chats, where there is a large amount of text data available but
the grammar is emerging or yet to be analyzed. Other examples are that of undeciphered languages,
e.g., Indus valley language or script. In fact, our method can be applied to any system of symbols, be it
linguistic or non-linguistic, such as musical note sequences.
As future work, it is important to improve our prediction accuracy further, while including more
languages in the experimental setup. Combining clues from other sources to resolve uncertain cases
and devising better ways of choosing corpus size and significance thresholds are some of the avenues in
which effort may be channelized. Extending our approach to a morpheme-level analysis would also be
beneficial in dealing with highly agglutinative and inflectional languages.
Acknowledgements
The first author was supported by Microsoft Corporation and Microsoft Research India under the Mi-
crosoft Research India PhD Fellowship Award. We would like to thank Amritayan Nayak, Walmart
eCommerce (who was then a student of IIT Kharagpur working as an intern at Microsoft Research India)
for contributing to some of the early experiments related to this study.
References
Robin Allan, Philip Holmes, and Tom Lundsk?r-Nielsen. 1995. Danish: A Comprehensive Grammar. Routledge,
London.
R. E. Asher. 1982. Tamil, volume 7 of Lingua Descriptive Studies. North-Holland, Amsterdam.
Churamani Bandhu. 1973. Clause patterns in nepali. In Austin Hale, editor, Clause, sentence, and discourse
patterns in selected languages of Nepal 2, volume 40.2 of Summer Institute of Linguistics Publications in
Linguistics and Related Fields, pages 1?79. Summer Institute of Linguistics of the University of Oklahoma,
Norman.
Emily M. Bender and D Terence Langendoen. 2010. Computational linguistics in support of linguistic theory.
Linguistic Issues in Language Technology, 3(1).
Dana Bielec. 1998. Polish: An Essential Grammar. Routledge, London.
F. M. Borras and R. F. Christian. 1959. Russian Syntax: Aspects of Modern Russian Syntax and Vocabulary.
Clarendon Press, Oxford.
George Cardona. 1965. A Gujarati Reference Grammar. The University of Pennsylvania Press, Philadelphia.
Leonardas Dambriunas, Antanas Klimas, and William R. Schmalstieg. 1966. Introduction to Modern Lithuanian.
Franciscan Fathers Press, Brooklyn.
Hal Daum?e and Lyle Campbell. 2007. A bayesian model for discovering typological implications. In Annual
Meeting of the Association for Computational Linguistics, pages 65?72.
1045
Matthew S. Dryer and Martin Haspelmath, editors. 2011. The World Atlas of Language Structures Online. Max
Planck Digital Library, Munich, 2011 edition.
Victor A. Friedman. 1993. Macedonian. In Bernard Comrie and Greville G. Corbett, editors, The Slavonic
Languages, pages 249?305. Routledge, London / New York.
Joseph H. Greenberg. 1963. Some universals of grammar with particular reference to the order of meaningful
elements. Universals of language, 2:73?113.
Aria Haghighi and Dan Klein. 2007. Unsupervised coreference resolution in a nonparametric bayesian model. In
Annual meeting-Association for Computational Linguistics, pages 848?855.
Harald Hammarstr?om, Christina Thornell, Malin Petzell, and Torbj?orn Westerlund. 2008. Bootstrapping language
description: The case of mpiemo (bantu a, central african republic). In Proceedings of the Sixth international
conference on Language Resources and Evaluation, LREC ?08.
John Hinds. 1986. Japanese, volume 4 of Croom Helm Descriptive Grammars. Croom Helm, Routledge, London.
Philip Holmes and Ian Hinchliffe. 1994. Swedish: A Comprehensive Grammar. Routledge, London.
Istvn Kenesei, Robert M. Vago, and Anna Fenyvesi. 1998. Hungarian. Descriptive Grammars. Routledge, London
/ New York.
Herbert Lederer. 1969. Reference Grammar of the German Language. Charles Scribner?s Sons, New York. Based
on Grammatik der Deutschen Sprache, by Doras Schulz and Heinz Griesbach.
W. Lewis and F. Xia. 2008. Automatically identifying computationally relevant typological features. In Proc. of
the Third International Joint Conference on Natural Language Processing (IJCNLP-2008).
R. S. McGregor. 1977. Outline of Hindi Grammar. Oxford University Press, Delhi. 2nd edition.
Irit Meir, Wendy Sandler, Carol Padden, and Mark Aronoff. 2010. Emerging sign languages. Oxford handbook of
deaf studies, language, and education, 2:267?280.
R. C. Moore and C. Quirk. 2007. An iteratively-trained segmentation-free phrase translation model for statistical
machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 112?
119. Association for Computational Linguistics.
Julius E. Olson. 1901. Norwegian Grammar and Reader. Scott, Foresman and Co, Chicago.
Thomas G. Palaima. 1989. Cypro-minoan scripts: Problems of historical context in problems in decipherment.
Biblioth`eque des Cahiers de l?Institut de Linguistique de Louvain, 49:121?187.
T. M. S. Priestly. 1993. Slovene. In Bernard Comrie and Greville G. Corbett, editors, The Slavonic Languages,
pages 388?451. Routledge, London.
R.P.N. Rao, N. Yadav, M.N. Vahia, H. Joglekar, R. Adhikari, and I. Mahadevan. 2009. Entropic evidence for
linguistic structure in the Indus script. Science, 324(5931):1165?1165.
Rishiraj Saha Roy, Monojit Choudhury, and Kalika Bali. 2012. Are web search queries an evolving protolan-
guage? In Proceedings of the 9th International Conference on the Evolution of Language, Evolang 9, pages
304?311, Singapore. World Scientific Publishing Co.
Charles Marquard Sauer. 1891. Italian Conversational Grammar. Julius Gross, Heidelberg.
Ernest A. Scatton. 1984. A Reference Grammar of Modern Bulgarian. Slavica Publishers, Columbus, Ohio.
Elizabeth Selkirk. 1996. The Prosodic Structure of Function Words. In James L. Morgan and Katherine Demuth,
editors, Signal to Syntax: Bootstrapping from Speech to Grammar in Early Acquisition. Routledge.
William Z. Shetter. 1958. Introduction to Dutch. Martinus Nijhoff, The Hague.
J. W. Stechishin. 1958. Ukrainian Grammar. Trident Press, Winnipeg.
Helena Sulkala and Merja Karjalainen. 1992. Finnish. Descriptive Grammar Series. Routledge, London.
Valter Tauli. 1983. Standard Estonian Grammar. Volume 2: Syntax, volume 14 of Studia Uralica et Altaica
Upsaliensia. Almqvist and Wiksell, Uppsala.
Robert Underhill. 1976. Turkish Grammar. Massachusetts Institute of Technology (MIT) Press, Cambridge.
1046
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 974?979,
October 25-29, 2014, Doha, Qatar.
c?2014 Association for Computational Linguistics
POS Tagging of English-Hindi Code-Mixed Social Media Content
Yogarshi Vyas
?
University of Maryland
yogarshi@cs.umd.edu
Spandana Gella
?
Xerox Research Centre Europe
spandanagella@gmail.com
Jatin Sharma Kalika Bali Monojit Choudhury
Microsoft Research India
{jatin.sharma,kalikab,monojitc}@microsoft.com
Abstract
Code-mixing is frequently observed in
user generated content on social media,
especially from multilingual users. The
linguistic complexity of such content is
compounded by presence of spelling vari-
ations, transliteration and non-adherance
to formal grammar. We describe our
initial efforts to create a multi-level an-
notated corpus of Hindi-English code-
mixed text collated from Facebook fo-
rums, and explore language identifica-
tion, back-transliteration, normalization
and POS tagging of this data. Our re-
sults show that language identification and
transliteration for Hindi are two major
challenges that impact POS tagging accu-
racy.
1 Introduction
Code-Switching and Code-Mixing are typical
and well-studied phenomena of multilingual so-
cieties (Gumperz, 1964; Auer, 1984; Myers-
Scotton, 1993; Danet and Herring, 2007;
Cardenas-Claros and Isharyanti, 2009). Lin-
guists differentiate between the two, where
Code-Switching is juxtaposition within the same
speech exchange of passages of speech be-
longing to two different grammatical systems
or sub-systems (Gumperz, 1982), and Code-
Mixing (CM) refers to the embedding of linguis-
tic units such as phrases, words and morphemes
of one language into an utterance of another lan-
guage (Myers-Scotton, 1993). The first exam-
ple in Fig. 1 features CM where English words
are embedded in a Hindi sentence, whereas the
second example shows codeswitching. Here, we
will use CM to imply both. Work on computa-
?
This work was done during authors? internship at Mi-
crosoft Research India.
tional models of CM have been few and far be-
tween (Solorio and Liu, 2008a; Solorio and Liu,
2008b; Nguyen and Dogruoz, 2013), primarily
due to the paucity of CM data in conventional
text-corpora which makes data-intensive methods
hard to apply. Solorio and Liu (2008a) in their
work on English-Spanish CM use models built on
smaller datasets to predict valid switching points
to synthetically generate data from monolingual
corpora, and in another work (2008b) describe
parts-of-speech (POS) tagging of CM text.
CM though typically observed in spoken lan-
guage is now increasingly more common in text,
thanks to the proliferation of the Computer Me-
diated Communication channels, especially so-
cial media like Twitter and Facebook (Crys-
tal, 2001; Herring, 2003; Danet and Herring,
2007; Cardenas-Claros and Isharyanti, 2009).
Social media content is tremendously important
for studying trends, reviews, events, human-
behaviour as well as linguistic analysis, and there-
fore in recent times has spurred a lot of interest
in automatic processing of such data. Neverthe-
less, CM on social media has not been studied
from a computational aspect. Moreover, social
media content presents additional challenges due
to contractions, non-standard spellings and non-
grammatical constructions. Furthermore, for lan-
guages written in scripts other than Roman, like
Hindi, Bangla, Japanese, Chinese and Arabic, Ro-
man transliterations are typically used for repre-
senting the words (Sowmya et al., 2010). This can
prove a challenge for language identification and
segregation of the two languages.
In this paper, we describe our initial efforts to
POS tag social media content from English-Hindi
(henceforth En-Hi) bilinguals while trying to ad-
dress the challenges of CM, transliteration and
non-standard spelling, as well as lack of anno-
tated data. POS tagging is one of the fundamen-
tal pre-processing steps for NLP, and while there
974
have been works on POS tagging of social media
data (Gimpel et al., 2011; Owoputi et al., 2013)
and of CM (Solorio and Liu, 2008b), but we do
not know of any work on POS tagging of CM
text from social media that involves transliteration.
The salient contributions of this work are in for-
malizing the problem and related challenges for
processing of En-Hi social media data, creation
of an annotated dataset and some initial experi-
ments for language identification, transliteration,
normalization and POS tagging of this data.
2 Corpus Creation
For this study, we collected data from Face-
book public pages of three celebrities: Amitabh
Bachchan, Shahrukh Khan, Narendra Modi, and
the BBC Hindi news page. All these pages are
very popular with 1.8 to 15.5 million ?likes?. A to-
tal of 40 posts were manually selected from these
pages, which were published between 22nd ? 28th
October 2013. The posts having a long thread of
comments (50+) were preferred, because CM and
non-standard usage of language is more common
in the comments. We shall use the term post to re-
fer to either a post or a comment. The corpus thus
created has 6,983 posts and 113,578 words. The
data was semi-automatically cleaned and format-
ted. The user names were removed for anonymity,
but the names appearing in comments, which are
mostly of celebrities, were retained.
2.1 Annotation
There are various interesting linguistic as well as
socio-pragmatic features (e.g., user demograph-
ics, presence of sarcasm or humor, polarity) for
which this corpus could be annotated because CM
is influenced by both linguistic as well as extra-
linguistic features. However, initial attempts at
such detailed and layered annotation soon revealed
the resource-intensiveness of the task. We, thus,
scaled down the annotation to the following four
layers:
Matrix: The posts are split into contiguous
fragments of words such that each fragment has
a unique matrix language (either En or Hi). The
matrix language is defined as the language which
governs the grammatical relation between the con-
stituents of the utterance. Any other language
words that are nested into the matrix constitute the
embedded language(s). Usually, matrix language
can be assigned to clauses or sentences.
Word origin: Every word is marked for its ori-
gin or source language, En or Hi, depending on
whether it is an English or Hindi word. Words that
are of neither Hindi nor English origin are marked
as Ot or Other. Here, we assume that code-mixing
does not happen at sublexical levels, as it is un-
common in this data; Hi and En have a sim-
pler inflectional morphology and thus, sub-lexical
mixing though present (e.g., computeron has
a En root - computer and a Hi plural marker
on) is relatively less common. In languages with
richer morphology and agglutination, like Bangla
and most Dravidian languages, more frequent sub-
lexical mixing may be observed. Also note that
words are borrowed extensively between Hi and
En such that certain English words (e.g., bus,
party, vote etc) are no longer perceived as English
words by the Hindi speakers. However, here we
will not distinguish between CM and borrowing,
and such borrowed English words have also been
labeled as En words.
Normalization/Transliteration: Whenever the
word is in a transliterated form, which is often the
case for the Hi words, it is labeled with the in-
tended word in the native script (e.g., Devanagari
for Hi). If the word is in native script, but uses
a non-standard spelling, it is labeled with the cor-
rect standard spelling. We call this the spelling
normalization layer.
Parts-of-Speech (POS): Finally, each word is
also labeled with its POS. We use the Universal
POS tagset proposed by Petrov et al. (2011) which
has 12 POS tags that are applicable to both En
and Hi. The POS labels are decided based on the
function of a word in the context, rather than a
decontextualized lexical category. This is an im-
portant notion, especially for CM text, because of-
ten the original lexical category of an embedded
word is lost in the context of the matrix language,
and it plays the role of a different lexical category.
Though the Universal POS tagset does not pre-
scribe a separate tag for Named Entities, we felt
the necessity of marking three different kinds of
NEs - people, location and organization, because
almost every comment has one or more NEs and
strictly speaking word origin does not make sense
for these words.
Annotation Scheme: Fig. 1 illustrates the an-
notation scheme through two examples. Each
post is enclosed within <s></s> tags. The
matrices within a post are separated by the
<matrix></matrix> tags which take the matrix
language as an argument. Each word is anno-
975
Figure 1: Two example annotations.
tated for POS, and the language (/E or /H for En
or Hi respectively) only if it is different from the
language of the matrix. In case of non-standard
spelling in English, the correct spelling is ap-
pended as ?sol NOUN=soul?, while for the
Hindi words, the correct Devanagari translitera-
tion is appended. The NEs are marked with the
tags P (person), L (location) or O (organization)
and multiword NEs are enclosed within square
brackets ?[]?.
A random subsample of 1062 posts consisting
of 10171 words were annotated by a linguist who
is a native speaker of Hi and proficient in En. The
annotations were reviewed and corrected by two
experts linguists. During this phase, it was also
observed that a large number of comments were
very short, typically an eulogism of their favorite
celebrity and hence were not interesting from a
linguistic point of view. For our experiments, we
removed all posts that had fewer than 5 words.
The resulting corpus had 381 comments/posts and
4135 words.
2.2 CM Distribution
Most of the posts (93.17%) are in Roman script,
and only 2.93% were in Devanagari. Around 3.5%
of the posts contain words in both the scripts (typ-
ically a post in Devanagari with hashtags or urls in
Roman script), and a very small fraction of the text
(0.4% of comments/posts and 0.6% words) was in
some other script. The fraction of words present
in Roman and Devanagri scripts are 80.76% and
15.32% respectively, which shows that the De-
vanagari posts are relatively longer than the Ro-
man posts. Due to their relative rarity, the posts
containing words in Devanagari or any other script
were not considered for annotation.
In the annotated data, 1102 sentences are in a
single matrix (398 Hi, 698 En and 6 Ot) and in
45 posts there is at least one switch of matrix
(mostly between Hi and En. Thus, 4.2% of the
data shows code-switching. This is a strict defi-
nition of code-switching; if we consider a change
in matrix within a conversation thread as a code-
switch, then in this data all the threads exhibit
code-switching. However, out of the 398 com-
ments in Hi-matrix, 23.37% feature CM (i.e., they
have at least one or more non-Hi (or rather, al-
most always En) words embedded. On the other
hand, only 7.34% En-matrix comments feature
CM (again almost always with Hi). Thus, a total
of 17.2% comments/posts, which contains a quar-
ter of all the words in the annotated corpus, fea-
ture either CM or code-switching or both. We also
note that more than 40% words in the corpus are
in Hi or other Indian languages, but written in Ro-
man script; hence, they are in transliterated form.
See (Bali et al., 2014) for an in-depth discussion
on the characteristics of the CM data.
This analysis demonstrates the necessity of CM
and transliterated text processing in the context of
Indian user-generated social media content. Per-
haps, the numbers are not too different for such
content generated by the users of any other bilin-
gual and multilingual societies.
3 Models and Experiments
POS tagging of En-Hi code-mixed data requires
language identification at both word and matrix
level as well back-transliteration of the text into
976
Actual Predicted Label Recall
Label Hi En
Hi 1057 515 0.672
En 45 2023 0.978
Precision 0.959 0.797
Table 1: Confusion matrix, precision and recall of
the language identification module.
the native script. Additionaly, since we are work-
ing with content from social media, the usage of
non-standard spelling is rampant and thus, nor-
malization of text into some standard form is re-
quired. Ideally, these tasks should be performed
jointly since they are interdependent. However,
due to lack of resources, we implement a pipelined
approach in which the tasks - language identifica-
tion, text normalization and POS tagging - are per-
formed sequentially, in that order. This pipelined
approach also allows us to use various off-the-
shelf tools for solving these subtasks and quickly
create a baseline system. The baseline results can
also provide useful insight into the inherent hard-
ness of POS tagging of code-mixed social media
text. In this section, we first describe our approach
to solve these three tasks, and then discuss the ex-
periments and results.
3.1 Language identification
Langauge identification is a well studied prob-
lem (King and Abney, 2013; Carter et al., 2013;
Goldszmidt et al., 2013; Nguyen and Dogruoz,
2013), though for CM text, especially those in-
volving transliterations and orthographic varia-
tion, this is far from a solved problem (Nguyen and
Dogruoz, 2013). There was a shared task in FIRE
2013 (Saha Roy et al., 2013) on language iden-
tification and back transliteration for En mixed
with Hi, Bangla and Gujarati. Along the lines
of Gella et al (Gella et al., 2013), which was the
best performing system in this shared task, we
used the word-level logistic regression classifier
built by King and Abney (2013). This system pro-
vides a source language with a confidence prob-
ability for each word in the test set. We trained
the classifier on 3201 English words extracted
from the SMS corpus developed by Choudhury
et al (2007), while the Hindi data was obtained
by sampling 3218 Hindi transliterations out of the
En-Hi transliteration pairs developed by Sowmya
et al. (Sowmya et al., 2010). Ideally, the context of
a token is important for identifying the language.
Again, following (Gella et al., 2013) we incorpo-
rate context information through a code-switching
probability, P
s
. A higher value of P
s
implies a
lower probability of code-switching, i.e., adjacent
words are more likely to be in the same language.
Table 1 shows the token (word) level confusion
matrix for the language identification task on our
dataset. The language labels of 84.6% of the to-
kens were correctly predicted by the system. As
can be seen from the Table, the precision for pre-
dicting Hi is high, whereas that for En is low. This
is mainly due to the presence of a large number of
contracted and distorted Hi words in the dataset,
e.g. h for hai (Fig. 1), which were tagged as
En by our system because the training examples
had no contracted Hi words, but short and non-
conventional spellings were in plenty in the En
training examples as those were extracted from the
SMS corpus.
3.2 Normalization
In our dataset, if a word is identified as Hi, then
it must be back-transliterated to Devanagari script
so that any off-the-shelf Hindi POS tagger can be
used. We used the system by Gella et al. (Gella
et al., 2013) for this task, which is part rule-based
and part statistical. The system was trained on the
35000 unique transliteration pairs extracted from
Hindi song lyrics (Gupta et al., 2012). This corpus
has a reasonably wide coverage of Hindi words,
and past researchers have also shown that translit-
eration does not require a very large amount of
training data. Normalization of the En text was
not needed because the POS tagger (Owoputi et
al., 2013) could handle unnormalized text.
3.3 POS tagging
Solorio and Liu (2008b) describes a few ap-
proaches to POS-tagging of code-switched Span-
glish text, all of which primarily relies on two
monolingual taggers and certain heuristics to com-
bine the output from the two. One of the sim-
pler heuristics is based on language identification,
where the POS tag of a word is the output of the
monolingual tagger of the language in which the
word is. In this initial study, we apply this ba-
sic idea for POS tagging of CM data. We divide
the text (which is already sentence-separated) into
contiguous maximal chunks of words which are in
the same language. Then we apply a Hi POS tag-
ger to the Hi chunks, and an En POS tagger to the
En chunks.
977
Model LI HN Tagger Hi Acc. En Acc. Total Acc. Hi CA En CA Total CA
1a K K Standard 75.14 81.91 79.02 27.34 39.67 34.05
1b K K Twitter 75.14 82.66 79.02 27.34 35.74 31.91
2 K NK Twitter 65.61 81.73 74.87 17.58 33.77 26.38
3 NK NK Twitter 44.74 80.68 65.39 40.00 13.17 25.00
Table 2: POS Tagging accuracies for the different models. K=Known, NK = Not Known. LI = Language
labels, HN = Hindi normalized forms, Acc. = Token level accuracy, CA = Chunk level accuracy.
We use a CRF++ based POS tagger for Hi,
which is freely available from http://nltr.
org/snltr-software/. For En, we use the
Twitter POS tagger (Owoputi et al., 2013). It
also has an inbuilt tokenizer and can work di-
rectly on unnormalized text. This tagger has been
chosen because Facebook posts and comments
are more Twitter-like. We also use the Stanford
POS Tagger (Toutanova et al., 2003) which, un-
like the Twitter POS Tagger, has not been tuned
for Twitter-like text. These taggers use different
tagsets - the ILPOST for Hi (Sankaran et al., 2008)
and Penn-TreeBank for En (Marcus et al., 1993).
The output tags are appropriately mapped to the
smaller Universal tagset (Petrov et al., 2011).
3.4 Experiments and Results
We conducted three different experiments as fol-
lows. In the first experiment, we assume that
we know the language identities and normal-
ized/transliterated forms of the words, and only do
the POS tagging. This experiment gives us an idea
of the accuracy of POS tagging task, if normal-
ization, transliteration and language identification
could be done perfectly. We conduct this exper-
iments with two different En POS taggers: the
Stanford POS tagger which is trained on formal
English text (Model 1a) and the Twitter POS tag-
ger (Model 1b). In the next experiment (Model
2), we assume that only the language identity of
the words are known, but for Hindi we apply our
model to generate the back transliterations. For
English, we apply the Twitter POS tagger directly
because it can handle unnormalized social media
text. The third experiment (Model 3) assumes that
nothing is known. So language identifier is first
applied, and based on the language detected, we
apply the Hi translitertaion module, and Hi POS
tagger, or the En tagger. This is the most chal-
lenging and realistic setting. Note that the matrix
information is not used in any of our experiments,
though it could be potentially useful for POS tag-
ging and could be explored in future.
Table 2 gives a summary of the four models
along with the POS tagging accuracies (in %). It
shows token level as well as chunk leve accuracies
(CA), i.e., what percentage of chunks have been
correctly POS tagged. As can be seen, Hi POS
tagging has relatively low accuracies than En POS
tagging at word level for all cases. This is primar-
ily due to the errors of the transliteration module,
which in turn, is because the transliteration does
not address spelling contractions. This is also re-
flected in the drop in the accuracies for the case
where LI is unknown. The very low CA for En
for model 3 is primarily because some of the Hi
chunks are incorrectly identified as En by the lan-
guage identification module (see Table 1). How-
ever, the gradual drop of token and chunk level
accuracies from model 1 to model 3 clearly shows
the effect of gradual error accumulation from each
of the modules. We observe that Nouns were
usually confused most with Verbs and vice versa,
while the Adj were mostly confused with Nouns,
Pronouns with Determiners, and Adpositions with
Conjunctions.
4 Conclusion
This is a work in progress. We have identified
normalization and transliteration as two very chal-
lenging problems for En-Hi CM text. Joint mod-
elling of language identification, normalization,
transliteration as well as POS tagging is expected
to yield better results. We plan to continue our
work in that direction, specifically for conversa-
tional text in social media in a multilingual con-
text. CM is a common phenomenon found in all
bilingual and multilingual societies. The issue of
transliteration exist for most of the South Asian
languages as well as many other languages such as
Arabic and Greek, which use a non-Roman based
script (Gupta et al., 2014). The challenges and is-
sues identified in this study are likely to hold for
many other languages as well, which makes this a
very important and globally prevalent problem.
978
References
Peter Auer. 1984. The Pragmatics of Code-Switching:
A Sequential Approach. Cambridge University
Press.
Kalika Bali, Yogarshi Vyas, Jatin Sharma, and Monojit
Choudhury. 2014. ??i am borrowing ya mixing?? an
analysis of English-Hindi code mixing in Facebook.
In Proceedings of the First Workshop on Computa-
tional Approaches to Code Switching, EMNLP.
M?onica Stella Cardenas-Claros and Neny Isharyanti.
2009. Code-switching and code-mixing in internet
chatting: Between yes, ya, and si a case study. In
The JALT CALL Journal, 5.
Simon Carter, Wouter Weerkamp, and Manos
Tsagkias. 2013. Microblog language identification:
Overcoming the limitations of short, unedited and
idiomatic text. Language Resources and Evaluation
Journal, 47:195?215.
Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh
Mukherjee, Sudeshna Sarkar, and Anupam Basu.
2007. Investigation and modeling of the structure
of texting language. IJDAR, 10(3-4):157?174.
David Crystal. 2001. Language and the Internet.
Cambridge University Press.
Brenda Danet and Susan Herring. 2007. The Multilin-
gual Internet: Language, Culture, and Communica-
tion Online. Oxford University Press., New York.
Spandana Gella, Jatin Sharma, and Kalika Bali. 2013.
Query word labeling and back transliteration for in-
dian languages: Shared task system description. In
FIRE Working Notes.
Kevin Gimpel, N. Schneider, B. O?Connor, D. Das,
D. Mills, J. Eisenstein, M. Heilman, D. Yogatama,
J. Flanigan, and N. A. Smith. 2011. Part-of-speech
tagging for twitter: Annotation, features, and exper-
iments. In Proceedings of ACL.
Moises Goldszmidt, Marc Najork, and Stelios Papari-
zos. 2013. Boot-strapping language identifiers for
short colloquial postings. In Machine Learning and
Knowledge Discovery in Databases, volume 8189 of
Lecture Notes in Computer Science, pages 95?111.
John J. Gumperz. 1964. Hindi-punjabi code-switching
in Delhi. In Proceedings of the Ninth International
Congress of Linguistics. Mouton:The Hague.
John J. Gumperz. 1982. Discourse Strategies. Oxford
University Press.
Kanika Gupta, Monojit Choudhury, and Kalika Bali.
2012. Mining Hindi-English transliteration pairs
from online Hindi lyrics. In Proceedings of LREC.
Parth Gupta, Kalika Bali, Rafael E. Banchs, Monojit
Choudhury, and Paolo Rosso. 2014. Query ex-
pansion for mixed-script information retrieval. In
Proc. of SIGIR, pages 677?686. ACM Association
for Computing Machinery.
Susan Herring, editor. 2003. Media and Language
Change. Special issue of Journal of Historical Prag-
matics 4:1.
Ben King and Steven Abney. 2013. Labeling the lan-
guages of words in mixed-language documents us-
ing weakly supervised methods. In Proceedings of
NAACL-HLT, pages 1110?1119.
Mitchell P Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: The penn treebank. Compu-
tational linguistics, 19(2):313?330.
Carol Myers-Scotton. 1993. Dueling Languages:
Grammatical Structure in Code-Switching. Clare-
don, Oxford.
Dong Nguyen and A. Seza Dogruoz. 2013. Word
level language identification in online multilingual
communication. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 857?862.
Olutobi Owoputi, Brendan OConnor, Chris Dyer,
Kevin Gimpel, Nathan Schneider, and Noah A.
Smith. 2013. Improved part-of-speech tagging for
online conversational text with word clusters. In
Proceedings of NAACL.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011.
A universal part-of-speech tagset. arXiv preprint
arXiv:1104.2086.
Rishiraj Saha Roy, Monojit Choudhury, Prasenjit Ma-
jumder, and Komal Agarwal. 2013. Overview and
datasets of fire 2013 track on transliterated search.
In FIRE Working Notes.
Bhaskaran Sankaran, Kalika Bali, Monojit Choudhury,
Tanmoy Bhattacharya, Pushpak Bhattacharyya,
Girish Nath Jha, S. Rajendran, K. Saravanan,
L. Sobha, and K. V. Subbarao. 2008. A com-
mon parts-of-speech tagset framework for indian
languages. In Proceedings of LREC.
Thamar Solorio and Yang Liu. 2008a. Learning to
predict code-switching points. In Proceedings of the
Empirical Methods in natural Language Processing.
Thamar Solorio and Yang Liu. 2008b. Parts-of-speech
tagging for English-Spanish code-switched text. In
Proceedings of the Empirical Methods in natural
Language Processing.
V. B. Sowmya, Monojit Choudhury, Kalika Bali,
Tirthankar Dasgupta, and Anupam Basu. 2010. Re-
source creation for training and testing of translitera-
tion systems for indian languages. In Proceedings of
the Language Resource and Evaluation Conference
(LREC).
Kristina Toutanova, Dan Klein, Christopher Manning,
and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of HLT-NAACL.
979
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1713?1722,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing
Reveals Turker Biases in Query Segmentation
Rohan Ramanath?
R. V. College of Engineering
Bangalore, India
ronramanath@gmail.com
Monojit Choudhury
Microsoft Research Lab India
Bangalore, India
monojitc@microsoft.com
Kalika Bali
Microsoft Research Lab India
Bangalore, India
kalikab@microsoft.com
Rishiraj Saha Roy?
Indian Institute of Technology Kharagpur
Kharagpur, India
rishiraj@cse.iitkgp.ernet.in
Abstract
Query segmentation, like text chunking,
is the first step towards query understand-
ing. In this study, we explore the effec-
tiveness of crowdsourcing for this task.
Through carefully designed control ex-
periments and Inter Annotator Agreement
metrics for analysis of experimental data,
we show that crowdsourcing may not be a
suitable approach for query segmentation
because the crowd seems to have a very
strong bias towards dividing the query into
roughly equal (often only two) parts. Sim-
ilarly, in the case of hierarchical or nested
segmentation, turkers have a strong prefer-
ence towards balanced binary trees.
1 Introduction
Text chunking of Natural Language (NL) sentences
is a well studied problem that is an essential pre-
processing step for many NLP applications (Ab-
ney, 1991; Abney, 1995). In the context of Web
search queries, query segmentation is similarly the
first step towards analysis and understanding of
queries (Hagen et al, 2011). The task in both the
cases is to divide the sentence or the query into
contiguous segments or chunks of words such that
the words from a segment are related to each other
more strongly than words from different segments
(Bendersky et al, 2009). It is typically assumed
that the segments are structurally and semantically
coherent and, therefore, the information contained
in them can be processed holistically.
?The work was done during author?s internship at Mi-
crosoft Research Lab India.
? This author was supported by Microsoft Corporation
and Microsoft Research India under the Microsoft Research
India PhD Fellowship Award.
f Pipe representation Boundary var.
4 apply | first aid course | on line 1 0 0 1 0
3 apply first aid course | on line 0 0 0 1 0
2 apply first aid | course on line 0 0 1 0 0
1 apply | first aid | course | on line 1 0 1 1 0
Table 1: Example of flat segmentation by Turkers.
f is the frequency of annotations; segment bound-
aries are represented by |.
f Bracket representation Boundary var.
4 ((apply first) ((aid course) (on line))) 0 2 0 1 0
2 (((apply (first aid)) course) (on line)) 1 0 2 3 0
2 ((apply ((first aid) course)) (on line)) 2 0 1 3 0
1 (apply (((first aid) course) (on line))) 3 0 1 2 0
1 ((apply (first aid)) (course (on line))) 1 0 2 1 0
Table 2: Example of nested segmentation by Turk-
ers. f is the frequency of annotations.
A majority of work on query segmentation re-
lies on manually segmented queries by human ex-
perts for training and evaluation of segmentation
algorithms. These are typically small datasets and
even with detailed annotation guidelines and/or
close supervision, low Inter Annotator Agreement
(IAA) remains an issue. For instance, Table 1 il-
lustrates the variation in flat segmentation by 10
annotators. This confusion is mainly because the
definition of a segment in a query is ambiguous
and of an unspecified granularity. This is fur-
ther compounded by the fact that other than eas-
ily recognizable and agreed upon segments such as
Named Entities or Multi-Word Expressions, there
is no established notion of linguistic grouping such
as phrases and clauses in a query.
Although there is little work on the use of
crowdsourcing for query segmentation (Hagen et
al., 2011; Hagen et al, 2012), the idea that the
1713
crowd could be a potential (and cheaper) source
for reliable segmentation seems a reasonable as-
sumption. The need for larger datasets makes this
an attractive proposition. Also, a larger number
of annotations could be appropriately distilled to
obtain better quality segmentations.
In this paper we explore crowdsourcing as an
option for query segmentation through experi-
ments designed using Amazon Mechanical Turk
(AMT)1. We compare the results against gold
datasets created by trained annotators. We ad-
dress the issues pertaining to disagreements due to
both ambiguity and granularity and attempt to ob-
jectively quantify their role in IAA. To this end,
we also conduct similar annotation experiments
for NL sentences and randomly generated queries.
While queries are not as structured as NL sen-
tences they are not simply a set of random words.
Thus, it is necessary to compare query segmenta-
tion to the u?ber-structure of NL sentences as well
as the unter-structure of random n-grams. This has
important implications for understanding any in-
herent biases annotators may have as a result of
the apparent lack of structure of the queries.
To quantify the effect of granularity on segmen-
tation, we also ask annotators to provide hierar-
chical or nested segmentations for real and ran-
dom queries, as well as sentences. Following
Abney?s (1992) proposal for hierarchical chunk-
ing of NL, we ask the annotators to group ex-
actly two words or segments at a time to recur-
sively form bigger segments. The concept is illus-
trated in Fig. 1. Table 2 shows annotations from
10 Turkers. It is important to constrain the join-
ing of exactly two segments or words at a time
to avoid the issue of fuzziness in granularity. We
shall refer to this style of annotation as Nested
segmentation, whereas the non-hierarchical non-
constrained chunking will be referred to as Flat
segmentation.
Through statistical analysis of the experimen-
tal data we show that crowdsourcing may not be
the best practice for query segmentation, not only
because of ambiguity and granularity issues, but
because there exist very strong biases amongst an-
notators to divide a query into two roughly equal
parts that result in misleadingly high agreements.
As a part of our analysis framework, we introduce
a new IAA metric for comparison across flat and
nested segmentations. This versatile metric can be
1https://www.mturk.com/mturk/welcome
3
2
1
apply 0
first aid
course
0
on line
Figure 1: Nested Segmentation: Illustration.
readily adapted for measuring IAA for other lin-
guistic annotation tasks, especially when done us-
ing crowdsourcing.
The rest of the paper is organized as follows.
Sec 2 provides a brief overview of related work.
Sec 3 describes the experiment design and proce-
dure. In Sec 4, we introduce a new metric for IAA,
that could be uniformly applied across flat and
nested segmentations. Results of the annotation
experiments are reported in Sec 5. In Sec 6, we an-
alyze the possible statistical and linguistic biases
in annotation. Sec 7 concludes the paper by sum-
marizing the work and discussing future research
directions. All the annotated datasets used in this
research are freely available for non-commercial
research purposes2.
2 Related Work
Query segmentation was introduced by Risvik et.
al. (2003) as a possible means to improve Informa-
tion Retrieval. Since then there has been a signif-
icant amount of research exploring various algo-
rithms for this task and its use in IR (see Hagen et.
al. (2011) for a survey). Most of the research and
evaluation considers query segmentation as a pro-
cess analogous to identification of phrases within
a query which when put within double-quotes (im-
plying exact matching of the quoted phrase in the
document) leads to better IR performance. How-
ever, this is a very restricted view of the process
and does not take into account the full potential of
query segmentation.
A more generic notion of segments leads to di-
verse and ambiguous definitions, making its eval-
uation a hard problem (see Saha Roy et. al. (2012)
for a discussion on issues with evaluation). Most
automatic segmentation techniques (Bergsma and
Wang, 2007; Tan and Peng, 2008; Zhang et al,
2Related datasets and supplementary material can be ac-
cessed from http://bit.ly/161Gkk9 or can be ob-
tained by directly emailing the authors.
1714
2009; Brenes et al, 2010; Hagen et al, 2011; Li et
al., 2011) have so far been evaluated only against
a small set of human-annotated queries (Bergsma
and Wang, 2007). The reported low IAA for such
datasets casts serious doubts on the reliability of
annotation and the performance of the algorithms
evaluated on them (Hagen et al, 2011; Saha Roy
et al, 2012).
To address the problem of data scarcity, Ha-
gen et. al. (2011) have created larger annotated
datasets through crowdsourcing3. However, in
their approach the crowd is provided with a few
(four) possible segmentations of a query to choose
from (known through a personal communication
with a authors). Thus, it presupposes an automatic
process that can generate the correct segmentation
of a query within top few options. It is far from
obvious how to generate these initial segmenta-
tions in a reliable manner. This may also result
in an over-optimistic IAA. An ideal segmentation
should be based on the annotators? own interpreta-
tion of the query. Nevertheless, if large scale data
has to be procured, crowdsourcing seems to be the
only efficient and effective model for this task, and
has been proven to be so for other IR and linguistic
annotations; see Carvalho et al (2011) for exam-
ples of crowdsourcing for IR resources and (Snow
et al, 2008; Callison-Burch, 2009) for language
resources.
In the context of NL text, segmentation has
been traditionally referred to as chunking and is
a well-studied problem. Abney (1991; 1992;
1995) defines a chunk as a sub-tree within a
syntactic phrase structure tree corresponding to
Noun, Prepositional, Adjectival, Adverbial and
Verb Phrases. Similarly, Bharati et al(1995) de-
fines it as Noun Group and Verb Group based only
on local surface information. However, cognitive
and annotation experiments for chunking of En-
glish (Abney, 1992) and other language text (Bali
et al, 2009) have shown that native speakers agree
on major clause and phrase boundaries, but may
not do so on more fine-grained chunks. One im-
portant implication of this is that annotators are
expected to agree more on the higher level bound-
aries for nested segmentation than the lower ones.
We note that hierarchical query segmentation was
proposed for the first time by Huang et al (2010),
where the authors recursively split a query (or its
fragment) into exactly two parts and evaluate the
3http://www.webis.de/research/corpora
final output against human annotations.
3 Experiments
The annotation experiments have been designed to
systematically study the various aspects of query
segmentation. In order to verify the effective-
ness and reliability of crowdsourcing, we designed
an AMT experiment for flat segmentation of Web
search queries. As a baseline, we would like to
compare these annotations with those from hu-
man experts trained for the task. We shall refer
to this baseline as the Gold annotation set. Since
we believe that the issue of granularity could be
the prime reason for previously reported low IAA
for segmentation, we also designed AMT-based
nested segmentation experiments for the same set
of queries, and obtained the corresponding gold
annotations.
Finally, to estimate the role of ambiguity inher-
ent in the structure of Web search queries on IAA,
we conducted two more control experiments, both
through crowdsourcing. First, flat and nested seg-
mentation of well-formed English, i.e., NL sen-
tences of similar length distribution; and second,
flat and nested segmentation of randomly gener-
ated queries. Higher IAA for NL sentences would
lead us to conclude that ambiguity and lack of
structure in queries is the main reason for low
agreements. On the other hand high or comparable
IAA for random queries would mean that annota-
tions have strong biases.
Thus, we have the following four pairs of anno-
tation experiments: flat and nested segmentation
of queries from crowdsourcing, corresponding flat
and nested gold annotations, flat and nested seg-
mentation of English sentences from crowdsourc-
ing, and flat and nested segmentations for ran-
domly generated queries through crowdsourcing.
3.1 Dataset
For our experiments, we need a set of Web search
queries and well-formed English sentences. Fur-
thermore, for generating the random queries, we
will use search query logs to learn n-gram mod-
els. In particular, we use the following datasets:
Q500, QG500: Saha Roy et al (2012) re-
leased a dataset of 500 queries, 5 to 8 words long,
for evaluation of various segmentation algorithms.
This dataset has flat segmentations from three an-
notators obtained under controlled experimental
settings, and can be considered as Gold annota-
1715
Figure 2: Length distribution of datasets.
tions. Hence, we select this set for our experiments
as well. We procured the corresponding nested
segmentation for these queries from two human
experts, who are regular search engine users, be-
tween 20 and 30 years old, and familiar with var-
ious linguistic annotation tasks. They annotated
the data under supervision. They were trained and
paid for the task. We shall refer to the set of flat
and nested gold annotations as QG500, whereas
Q500 will be reserved for AMT experiments.
Q700: Since 500 queries may not be enough
for reliable conclusion and since the queries may
not have been chosen specifically for the purpose
of annotation experiments, we expanded the set
with another 700 queries sampled from a slice of
the query logs of Bing Australia4 containing 16.7
million queries issued over a period of one month
(May 2010). We picked, uniformly at random,
queries that are 4 to 8 words long, have only En-
glish letters and numerals, and a high click entropy
because ?a query with a larger click entropy value
is more likely to be an informational or ambiguous
query? (Dou et al, 2008). Q500 consists of tail-
ish queries with frequency between 5 and 15 that
have at least one multiword named entity; but un-
like the case of Q700, click-entropy was not con-
sidered during sampling. As we shall see, this dif-
ference is clearly reflected in the results.
S300: We randomly selected 300 English sen-
tences from a collection of full texts of public do-
main books5 that were 5 to 15 words long, and
checked them for well-formedness. This set will
be referred to as S300.
QRand: Instead of generating search queries
by throwing in words randomly, we thought it
will be more interesting to explore annotation of
4http://www.bing.com/?cc=au
5http://www.gutenberg.org
Parameter Flat Details Nested Details
Time needed: actual (allotted) 49 sec (10 min) 1 min 52 sec (15 min)
Reward per HIT $0.02 $0.06
Instruction video duration 26 sec 1 min 40 sec
Turker qualification Completion rate >100 tasks
Turker approval rate Acceptance rate >60 %
Turker location United States of America
Table 3: Specifics of the HITs for AMT.
queries generated using n-gram models for n =
1, 2, 3. We estimated the models from the Bing
Australia log of 16.7 million queries. We gener-
ated 250 queries each of desired length distribu-
tion using the 1, 2 and 3-gram models. We shall
refer to these as U250, B250, T250 (for Uni, Bi
and Trigram) respectively, and the whole dataset
as QRand. Fig. 2 shows the query and sentence
length distribution for the various sets.
3.2 Crowdsourcing Experiments
We used AMT to get our annotations through
crowdsourcing. Pilot experiments were carried out
to test the instruction set and examples presented.
Based on the feedback, the precise instructions for
the final experiments were designed.
Two separate AMT Human Intelligence Tasks
(HITs) were designed for flat and nested query
segmentation. Also, the experiments for queries
(Q500+Q700) were conducted separately from
S300 and QRand. Thus, we had six HITs in
all. The concept of flat and nested segmentation
was introduced to the Turkers with the help of ex-
amples presented in two short videos6. When in
doubt regarding the meaning of a query, the Turk-
ers were advised to issue the query on a search
engine of their choice and find out its possible
interpretation(s). Note that we intentionally kept
definitions of flat and nested segmentation fuzzy
because (a) it would require very long instruction
manuals to cover all possible cases and (b) Turkers
do not tend to read verbose and complex instruc-
tions. Table 3 summarizes other specifics of HITs.
Honey pots or trap questions whose answers are
known a priori are often included in a HIT to iden-
tify turkers who are unable to solve the task ap-
propriately leading to incorrect annotations. How-
ever, this trick cannot be employed in our case be-
cause there is no notion of an absolutely correct
segmentation. We observe that even with unam-
biguous queries, even expert annotators may dis-
6Flat: http://youtu.be/eMeLjJIvIh0, Nested:
http://youtu.be/xE3rwANbFvU
1716
agree on some of the segment boundaries. Hence,
we decided to include annotations from all the
turkers, except for those that were syntactically ill-
formed (e.g., non-binary nested segmentation).
4 Inter Annotator Agreement
Inter Annotator Agreement is the only way to
judge the reliability of annotated data in absence
of an end application. Therefore, before we can
venture into analysis of the experimental data, we
need to formalize the notion of IAA for flat and
nested queries. The task is non-trivial for two
reasons. First, traditional IAA measures are de-
fined for a fixed set of annotators. However, for
crowdsourcing based annotations, different anno-
tators might have annotated different parts of the
dataset. For instance, we observed that a total
of 128 turkers have provided the flat annotations
for Q700, when we had only asked for 10 anno-
tations per query. Thus, on average, a turker has
annotated only 7.81% of the 700 queries. In fact,
we found that 31 turkers had annotated less than
5 queries. Hence, measures such as Cohen?s ?
(1960) cannot be directly applied in this context
because for crowdsourced annotations, we cannot
meaningfully compute annotator-specific distribu-
tion of the labels and biases.
Second, most of the standard annotation metrics
do not generalize for flat segmentation and trees.
Artstein and Poesio (2008) provides a comprehen-
sive survey of the IAA metrics and their usage in
NLP. They note that all the metrics assume that
a fixed set of labels are used for items. There-
fore, it is far from obvious how to compare chunk-
ing or segmentation that covers the whole text or
that might have overlapping units as in the case of
nested segmentation. Furthermore, we would like
to compare the reliability of flat and nested seg-
mentation, and therefore, ideally we would like to
have an IAA metric that can be meaningfully ap-
plied to both of these cases.
After considering various measures, we decided
to appropriately generalize one of the most versa-
tile and effective IAA metrics proposed till date,
the Kripendorff?s ? (2004). To be consistent with
prior work, we will stick to the notation used
in Artstein and Poesio (2008) and redefine the
? in the context of flat and nested segmentation.
Note that though the notations introduced here will
be from the perspective of queries, it is equally
applicable to sentences and the generalization is
straightforward.
4.1 Notations and Definitions
Let Q be the set of all queries with cardinality q.
A query q ? Q can be represented as a sequence of
|q| words: w1w2 . . . w|q|. We introduce |q?1| ran-
dom variables, b1, b2, . . . b|q|?1, such that bi rep-
resents the boundary between the words wi and
wi+1. A flat or nested segmentation of q, repre-
sented by qj , j varying from 1 to total number of
annotations c, is a particular instantiation of these
boundary variables as described below.
Definition. A flat segmentation, qj can be
uniquely defined by a binary assignment of the
boundary variables bj,i, where bj,i = 1 iff wi and
wi+1 belong to two different flat segments. Oth-
erwise, bj,i = 0. Thus, q has 2|q|?1 possible flat
segmentations.
Definition. A nested segmentation qj can also
be uniquely defined by assigning non-negative in-
tegers to the boundary variables such that bj,i = 0
iff words wi and wi+1 form an atomic segment
(i.e., they are grouped together), else bj,i = 1 +
max(lefti, righti), where lefti and righti are
the heights of the largest subtrees ending at wi and
beginning at wi+1 respectively.
This numbering scheme for nested segmenta-
tion can be understood through Fig. 1. Every in-
ternal node of the binary tree corresponding to the
nested segmentation is numbered according to its
height. The lowest internal nodes, both of whose
children are query words, are assigned a value of
0. Other internal nodes get a value of one greater
than the height of its higher child. Since every in-
ternal node corresponds to a boundary, we assign
the height of the node to the corresponding bound-
aries. The number of unique nested segmentations
of a query of length |q| is its corresponding Cata-
lan number7.
Boundary variables for flat and nested segmen-
tation are illustrated with an example of each kind
in Tables 1 and 2 (last column).
4.2 Krippendorff ?s ? for Segmentation
Krippendorff ?s ? (Krippendorff, 2004) is an ex-
tremely versatile agreement coefficient, which is
based on the assumption that the expected agree-
ment is calculated by looking at the overall distri-
bution of judgments without regard to which anno-
tator produced them (Artstein and Poesio, 2008).
7http://goo.gl/vKQvK
1717
Hence, it is appropriate for crowdsourced annota-
tion, where the judgments come from a large num-
ber of unrelated annotators. Moreover, it allows
for different magnitudes of disagreement, which
is a useful feature as we might want to differen-
tially penalize disagreements at various levels of
the tree for nested segmentation.
? is defined as
? = 1? DoDe
= 1? s
2
within
s2total
(1)
where Do and De are, respectively, the observed
and expected disagreements that are measured by
s2within ? the variance within the annotation of an
item and s2total ? variance across annotations of
all items. We adapt the equations presented in
pp.565-566 of Artstein and Poesio (2008) for mea-
suring these quantities for queries:
s2within =
1
2qc(c? 1)
?
q?Q
c?
m=1
c?
n=1
d(qm, qn)
(2)
s2total =
1
2qc(qc? 1)
?
q?Q
c?
m=1
?
q??Q
c?
n=1
d(qm, q?n)
(3)
where, d(qm, q?n) is a distance metric for the agree-
ment between annotations qm and q?n.
We define two different distance metrics d1 and
d2 that are applicable to flat and nested segmenta-
tion. We shall first define these metrics for com-
paring queries with equal length (i.e., |q| = |q?|):
d1(qm, q?n) =
1
|q| ? 1
|q|?1?
i=1
|bm,i ? b?n,i| (4)
d2(qm, q?n) =
1
|q| ? 1
|q|?1?
i=1
|b2m,i ? (b?n,i)2| (5)
While d1 penalizes all disagreements equally, d2
penalizes disagreements higher up the tree more.
d2 might be a desirable metric for nested seg-
mentation, because research on sentence chunk-
ing shows that annotators agree more on clause or
major phrase boundaries, even though they may
not always agree on intra-clausal or intra-phrasal
boundaries (Bali et al, 2009). Note that for flat
segmentation, d1 and d2 are identical, and hence
we will denote them as d.
We propose the following extension to these
metrics for queries of unequal lengths. Without
loss of generality, let us assume that |q| < |q?|. k
is 1 or 2; r = |q?| ? |q|+ 1.
dk(qm, q?n) =
1
r(|q| ? 1)
r?1?
a=0
|q|?1?
i=1
|bkm,i ? (b?n,i+a)k| (6)
4.3 IAA under Random Bias Assumption
Krippendorff?s ? uses the cross-item variance as
an estimate of chance agreement, which is reli-
able in general. However, this might result in mis-
leadingly low values of IAA, especially when the
items in the set are indeed expected to have sim-
ilar annotations. To resolve this, we also com-
pute the chance agreement under a random bias
model. The random model assumes that all the
structural annotations of q are equiprobable. For
flat segmentation, it boils down to the fact that
all the 2|q|?1 annotations are equally likely, which
is equivalent to the assumption that any boundary
variable bi has 0.5 probability of being 0 and 0.5
for 1.
Analytical computation of the expected proba-
bility distributions of d1(qm, qn) and d2(qm, qn)
is harder for nested segmentation. Therefore, we
programmatically generate all possible trees for q,
which is again dependent only on |q| and com-
pute d1 and d2 between all pairs of trees, from
which the expected distributions can be readily
estimated. Let us denote this expected cumula-
tive probability distribution for flat segmentation
as Pd(x; |q|) = the probability that for a pair
of randomly chosen flat segmentations of q, qm
and qn, d(qm, qn) ? x. Likewise, let Pd1(x; |q|)
and Pd2(x; |q|) be the respective probabilities that
for any two nested segmentations qm and qn of
q, the following holds: d1(qm, qn) ? x and
d2(qm, qn) ? x.
We define the IAA under random bias model as
(k is 1, 2 or null):
S = 1qc2
?
q?Q
c?
m=1
c?
n=1
Pdk(dk(qm, qn); |q|) (7)
Thus, S is the expected probability of observing a
similar or worse agreement by random chance, av-
eraged over all pairs of annotations for all queries,
and not a chance corrected IAA metric such as
?. Thus, S = 1 implies that the observed agree-
ment is almost always better than that by random
chance and S = 0.5 and 0 respectively imply that
the observed agreement is as good as and almost
always worse than that by random chance. We
1718
Dataset Flat Nested
d1 d1 d2
Q700 0.21(0.59) 0.21(0.89) 0.16(0.68)
Q500 0.22(0.62) 0.15(0.70) 0.15(0.44)
QG500 0.61(0.88) 0.66(0.88) 0.67(0.80)
S300 0.27(0.74) 0.18(0.94) 0.14(0.75)
U250 0.23(0.89) 0.42(0.90) 0.30(0.78)
B250 0.22(0.86) 0.34(0.88) 0.22(0.71)
T250 0.20(0.86) 0.44(0.89) 0.34(0.76)
Table 4: Agreement Statistics: ?(S).
also note that a high value of S and low value
of ? indicate that though the annotators agree on
the judgment of individual items, they also tend to
agree on judgments of two different items, which
in turn, could be due to strong annotator biases or
due to lack of variability of the dataset.
In the supplementary material, computations of
? and S have been explained in further details
through worked out examples. Tables for the ex-
pected distributions of d, d1 and d2 under the ran-
dom annotation assumption are also available.
5 Results
Table 4 reports the values of ? and S for flat
and nested segmentation on the various datasets.
For nested segmentation, the values were com-
puted for two different distance metrics d1 and
d2. As expected, the highest value of ? for both
flat and nested segmentation is observed for gold
annotations. An ? > 0.6 indicates quite good
IAA, and thus, reliable annotations. Higher ? for
nested segmentation QG500 than flat further vali-
dates our initial postulate that nested segmentation
may reduce disagreement from granularity issues
inherent in the definition of flat segmentation.
Opposite trends are observed for Q700, Q500
and S300, where ? for flat is the highest, followed
by that for nested using d1, and then d2. More-
over, except for flat segmentation of sentences, ?
lies between 0.14 and 0.22, which is quite low.
This clearly shows that segmentation, either flat
or nested, cannot be reliably procured through
crowdsourcing. Lower ? for d2 than d1 further
indicates that annotators disagree more for higher
levels of the trees, contrary to what we had ex-
pected. However, nearly equal IAA for sentences
and queries implies that low agreement may not be
an outcome of inherent ambiguity in the structure
of queries. Slightly higher ? for flat segmentation
and a much higher ? for nested segmentation of
QRand reinforce the fact that low IAA is not due
to a lack of structure in queries.
It is interesting to note that ? for nested segmen-
tation of S300 and all segmentations of QRand
are low or medium despite the fact that S is very
high in all these cases. Thus, it is clear that an-
notators have a strong bias towards certain struc-
tures across queries. In the next section, we will
analyze some of these biases. We also computed
the IAA between QG500 and Q500, and found
? = 0.27. This is much lower than ? for QG500,
though slightly higher than that for Q500. We did
not observe any significant variation in agreement
with respect to the length of the queries.
6 Biases in Annotation
The IAA statistics clearly show that there are cer-
tain strong biases in both flat and nested query
segmentation, especially those obtained through
crowdsourcing. To identify these biases, we went
through the annotations and came up with possi-
ble hypotheses, which we tried to verify through
statistical analysis of the data. Here, we report the
most prominent biases that were thus discovered.
Bias 1: During flat segmentation, annotators pre-
fer dividing the query into two segments of roughly
equal length.
As discussed earlier, one of the major problems
of flat segmentation is the fuzziness in granularity.
In our experiments, we intentionally left the de-
cision of whether to go for fine or coarse-grained
segmentation to the annotator. However, it is sur-
prising to observe that annotators typically divide
the query into two segments (see Fig. 3, plots A1
and A2), and at times three, but hardly ever more
than three. This bias is observed across queries,
sentences and random queries, where the percent-
age of annotations with 2 or 3 segments are greater
than 83%, 91% and 96% respectively. This bias
is most strongly visible for QRand because the
lack of syntactic or semantic cohesion between the
words provides no clue for segmentation.
Furthermore, we observe that typically seg-
ments tend to be of equal length. For this, we com-
puted standard deviations (sd) of segment lengths
for all annotations having 2 or 3 segments; the dis-
tribution of sd is shown in Fig. 3, plots B1 and B2.
We observe that for all datasets, sd lies mainly be-
tween 0.5 and 1 (for perspective, consider a query
1719
Figure 3: Analysis of annotation biases: A1, A2 ? number of segments per flat segmentation vs. length;
B1, B2 ? standard deviation of segment length for flat segmentation; C1, C2 ? distribution of the tree
heights in nested segmentation.
Length Expected Q500 QG500 Q700 S300 QRand
5 2.57 2.00 2.02 2.08 2.02 2.01
6 3.24 2.26 2.23 2.23 2.24 2.02
7 3.88 2.70 2.71 2.67 2.55 2.62
8 4.47 2.89 2.68 2.72 2.72 2.35
Table 5: Average height for nested segmentation.
with 7 words; with two segments of length 3 and
4 the sd is 0.5, and for 2 and 5, the sd is 1.5), im-
plying that segments are roughly of equal length.
It is likely that due to this bias, the S or observed
agreement is moderately high for queries and very
high for sentences, but then it also leads to high
agreement across different queries and sentences
(i.e., high s2total) especially when they are of equal
length, which in turn brings down the value of ? ?
the true agreement after bias correction.
Bias 2: During nested segmentation, annotators
prefer balanced binary trees.
Quite analogous to bias 1, for nested segmen-
tation we observe that annotators tend to prefer
more balanced binary trees. Fig. 3 plots C1 and C2
show the distribution of the tree heights for various
cases and Table 5 reports the corresponding aver-
age height of the trees for queries and sentences
of various lengths and the the expected value of
the height if all trees were equally likely. The ob-
served heights are much lower than the expected
values clearly implying the preference of the an-
notators for more balanced trees.
Thus, the crowd seems to choose the middle
path, avoiding extremes and hence may not be a
reliable source of annotation for query segmen-
tation. It can be argued that similar biases are
also observed for gold annotations, and therefore,
probably it is the inherent structure of the queries
and sentences that lead to such biased distribution
of segmentation patterns. However, note that ? for
QG500 is much higher than all other cases, which
shows that the true agreement between gold anno-
tators is immune to such biases or skewed distri-
butions in the datasets. Furthermore, high values
of ? for QRand despite the very strong biases in
annotation shows that there perhaps is very little
choice that the annotators have while segmenting
randomly generated queries. On the other hand,
the textual coherence of the real queries and sen-
tences provide many different choices for segmen-
tation and the Turker typically gets carried away
by these biases, leading to low ?.
Bias 3: Phrase structure drives segmentation only
when reconcilable with Bias 1. Whenever the sen-
tence or query has a verb phrase (VP) spanning
roughly half of it, annotators seem to chunk be-
fore the VP as one would expect, quite as of-
ten as just after the verb, which is quite unex-
pected. For instance, the sentence A gentle
sarcasm ruffled her anger. gathers as
many as eight flat annotations with a boundary be-
tween sarcasm and ruffled, and four with
a boundary between ruffled and her. How-
ever, if the VP is very short consisting of a single
1720
Position Q500 QG500 Q700 S300 QRand
Both 2.24 0.37 2.78 2.08 0.63
None 50.34 56.85 35.74 35.84 39.81
Right 23.86 21.50 19.02 12.52 15.23
Left 18.08 15.97 40.59 45.96 21.21
Table 6: Percentages of positions of segment
boundaries with respect to prepositions. Prepo-
sitions occurring in the beginning or end of a
query/sentence have been excluded from the anal-
ysis; hence, numbers in a column do not total 100.
verb, as in A fleeting and furtive air
of triumph erupted., annotators seem to
attempt for a balanced annotation due to Bias 1.
As a clear middle boundary is not present in such
sentences, the annotations show a lot more varia-
tion and disagreement. For instance, only 1 out of
10 annotations had a boundary before erupted
in the above example. In fact, at least one anno-
tation had a boundary after each word in the sen-
tence, with no clear majority.
Bias 4: Prepositions influence segment bound-
aries differently for queries and sentences. We
automatically labeled all the prepositions in the
flat annotations and classified them according to
the criterion of whether a boundary was placed
immediately before or after it, or on both sides
or neither side. The statistics, reported in Ta-
ble 6, show that for NL sentences a majority
of the boundaries are present before the prepo-
sition, marking the beginning of a prepositional
phrase. However, for queries, a much richer pat-
tern emerges depending on the specific preposi-
tion. For instance, to, of and for are often
chunked with the previous word (e.g., how to |
choose a bike size, birthday party
ideas for | one year old). We believe
that this difference is because in sentences due
to the presence of a verb, the PP has a well-
defined head, lack of which leads to preposition
in queries getting chunked with words that form
more commonly seen patterns (e.g., flights
to and tickets for).
Bias 3 and 4 present the complex interpretation
of the structure of queries by the annotators which
could be due to some emerging cognitive model of
queries among the search engine users. This is a
fascinating and unexplored aspect of query struc-
tures that demands deeper investigation through
cognitive and psycholinguistic experiments.
7 Conclusion
We have studied various aspects of query segmen-
tation through crowdsourcing by designing and
conducting suitable experiments. Analysis of ex-
perimental data leads us to conclude the follow-
ing: (a) crowdsoucing may not be a very effective
way to collect judgments for query segmentation;
(b) addressing fuzziness of granularity for flat seg-
mentation by introducing strict binary nested seg-
ments does not lead to better agreement in crowd-
sourced annotations, though it definitely improves
the IAA for gold standard segmentations, imply-
ing that low IAA in flat segmentation among ex-
perts is primarily an effect of unspecified granular-
ity of segments; (c) low IAA is not due to the in-
herent structural ambiguity in queries as this holds
true for sentences as well; (d) there are strong bi-
ases in crowdsourced annotations, mostly because
turkers prefer more balanced segment structures;
and (e) while annotators are by and large guided
by linguistic principles, application of these prin-
ciples differ between query and NL sentences and
also closely interact with other biases.
One of the important contributions of this work
is the formulation of a new IAA metric for com-
paring across flat and nested segmentations, espe-
cially for crowdsourcing based annotations. Since
trees are commonly used across various linguistic
annotations, this metric can have wide applicabil-
ity. The metric, moreover, can be easily adapted
to other annotation schemes as well by defining an
appropriate distance metric between annotations.
Since large scale data for query segmentation is
very useful, it would be interesting to see if the
problem can be rephrased to the Turkers in a way
so as to obtain more reliable judgments. Yet a
deeper question is regarding the theoretical status
of query structure, which though in an emergent
state is definitely an operating model for the anno-
tators. Our future work in this area would specifi-
cally target understanding and formalization of the
theoretical model underpinning a query.
Acknowledgments
We thank Ed Cutrell and Andrew Cross, Microsoft
Research Lab India, for their help in setting up the
AMT experiments. We would also like to thank
Anusha Suresh, IIT Kharagpur, India, for helping
us with data preparation.
1721
References
Steven P. Abney. 1991. Parsing By Chunks. Kluwer
Academic Publishers.
Steven P. Abney. 1992. Prosodic Structure, Perfor-
mance Structure And Phrase Structure. In Proceed-
ings 5th DARPA Workshop on Speech and Natural
Language, pages 425?428. Morgan Kaufmann.
Steven P. Abney. 1995. Chunks and dependencies:
Bringing processing evidence to bear on syntax.
Computational Linguistics and the Foundations of
Linguistic Theory, pages 145?164.
Ron Artstein and Massimo Poesio. 2008. Inter-coder
agreement for computational linguistics. Computa-
tional Linguistics, 34(4):555?596.
Kalika Bali, Monojit Choudhury, Diptesh Chatterjee,
Sankalan Prasad, and Arpit Maheswari. 2009. Cor-
relates between Performance, Prosodic and Phrase
Structures in Bangla and Hindi: Insights from a Psy-
cholinguistic Experiment. In Proceedings of Inter-
national Conference on Natural Language Process-
ing, pages 101 ? 110.
Michael Bendersky, W. B. Croft, and David A. Smith.
2009. Two-stage query segmentation for informa-
tion retrieval. In Proceedings of the 32nd interna-
tional ACM Special Interest Group on Information
Retrieval (SIGIR) Conference on Research and De-
velopment in Information Retrieval, pages 810?811.
ACM.
Shane Bergsma and Qin Iris Wang. 2007. Learning
Noun Phrase Query Segmentation. In Proceedings
of Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL), pages 819?826.
Akshar Bharati, Vineet Chaitanya, Rajeev Sangal, and
KV Ramakrishnamacharyulu. 1995. Natural lan-
guage processing: a Paninian perspective. Prentice-
Hall of India New Delhi.
David J. Brenes, Daniel Gayo-Avello, and Rodrigo
Garcia. 2010. On the fly query segmentation using
snippets. In CERI ?10, pages 259?266.
Chris Callison-Burch. 2009. Fast, cheap, and cre-
ative: evaluating translation quality using amazon?s
mechanical turk. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing, EMNLP ?09, pages 286?295. Associa-
tion for Computational Linguistics.
Vitor R Carvalho, Matthew Lease, and Emine Yilmaz.
2011. Crowdsourcing for search evaluation. ACM
Sigir forum, 44(2):17?22.
Jacob Cohen. 1960. A Coefficient of Agreement for
Nominal Scales. Educational and Psychological
Measurement, 20(1):37?46.
Zhicheng Dou, Ruihua Song, Xiaojie Yuan, and Ji-
Rong Wen. 2008. Are Click-through Data Adequate
for Learning Web Search Rankings? In Proceed-
ings of the 17th ACM Conference on Information
and Knowledge Management, pages 73?82. ACM.
Matthias Hagen, Martin Potthast, Benno Stein, and
Christof Bra?utigam. 2011. Query Segmentation
Revisited. In Proceedings of the 20th Interna-
tional Conference on World Wide Web, pages 97?
106. ACM.
Matthias Hagen, Martin Potthast, Anna Beyer, and
Benno Stein. 2012. Towards Optimum Query Seg-
mentation: In Doubt Without. In Proceedings of the
Conference on Information and Knowledge Man-
agement, pages 1015?1024.
Jian Huang, Jianfeng Gao, Jiangbo Miao, Xiaolong
Li, Kuansan Wang, Fritz Behr, and C. Lee Giles.
2010. Exploring web scale language models for
search query processing. In Proceedings of the 19th
international conference on World wide web, WWW
?10, pages 451?460, New York, NY, USA. ACM.
Klaus Krippendorff. 2004. Content Analysis: An
Introduction to its Methodology. Sage,Thousand
Oaks, CA.
Yanen Li, Bo-Jun Paul Hsu, ChengXiang Zhai, and
Kuansan Wang. 2011. Unsupervised query segmen-
tation using clickthrough for information retrieval.
In SIGIR ?11, pages 285?294. ACM.
Knut Magne Risvik, Tomasz Mikolajewski, and Peter
Boros. 2003. Query segmentation for web search.
In WWW (Posters).
Rishiraj Saha Roy, Niloy Ganguly, Monojit Choud-
hury, and Srivatsan Laxman. 2012. An IR-based
Evaluation Framework for Web Search Query Seg-
mentation. In Proceedings of the International ACM
Special Interest Group on Information Retrieval (SI-
GIR) Conference on Research and Development in
Information Retrieval, pages 881?890. ACM.
Rion Snow, Brendan O?Connor, Daniel Jurafsky, and
Andrew Y. Ng. 2008. Cheap and fast?but is it
good?: evaluating non-expert annotations for natural
language tasks. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ?08, pages 254?263, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Bin Tan and Fuchun Peng. 2008. Unsupervised Query
Segmentation Using Generative Language Models
and Wikipedia. In Proceedings of the 17th Inter-
national Conference on World Wide Web (WWW),
pages 347?356. ACM.
Chao Zhang, Nan Sun, Xia Hu, Tingzhu Huang, and
Tat-Seng Chua. 2009. Query segmentation based on
eigenspace similarity. In Proceedings of the ACL-
IJCNLP 2009 Conference Short Papers, ACLShort
?09, pages 185?188, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
1722
Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 42?50,
Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational Linguistics
Entailment: An Effective Metric for Comparing and Evaluating
Hierarchical and Non-hierarchical Annotation Schemes
Rohan Ramanath?
R. V. College of Engineering, India
ronramanath@gmail.com
Monojit Choudhury Kalika Bali
Microsoft Research Lab India
{monojitc, kalikab}@microsoft.com
Abstract
Hierarchical or nested annotation of lin-
guistic data often co-exists with simpler
non-hierarchical or flat counterparts, a
classic example being that of annotations
used for parsing and chunking. In this
work, we propose a general strategy for
comparing across these two schemes of
annotation using the concept of entailment
that formalizes a correspondence between
them. We use crowdsourcing to obtain
query and sentence chunking and show
that entailment can not only be used as
an effective evaluation metric to assess the
quality of annotations, but it can also be
employed to filter out noisy annotations.
1 Introduction
Linguistic annotations at all levels of linguistic or-
ganization ? phonological, morpho-syntactic, se-
mantic, discourse and pragmatic, are often hierar-
chical or nested in nature. For instance, syntac-
tic dependencies are annotated as phrase structure
or dependency trees (Jurafsky and Martin, 2000).
Nevertheless, the inherent cognitive load associ-
ated with nested segmentation and the sufficiency
of simpler annotation schemes for building NLP
applications have often lead researchers to define
non-hierarchical or flat annotation schemes. The
flat annotation, in essence, is a ?flattened? ver-
sion of the tree. For instance, chunking of Natu-
ral Language (NL) text, which is often considered
an essential preprocessing step for many NLP ap-
plications (Abney, 1991; Abney, 1995), is, loosely
speaking, a flattened version of the phrase struc-
ture tree. The closely related task of Query Seg-
mentation is of special interest to us here, as it is
?The work was done during author?s internship at Mi-
crosoft Research Lab India.
f Pipe representation Boundary var.
3 barbie dress up | games 0 0 1
3 barbie dress | up games 0 1 0
2 barbie | dress up | games 1 0 1
2 barbie | dress up games 1 0 0
Table 1: Example of flat segmentations from 10
Turkers. f is the frequency of annotations; seg-
ment boundaries are represented by |.
the first step in further analysis and understanding
of Web search queries (Hagen et al, 2011).
The task in both query and sentence chunking is
to divide the string of words into contiguous sub-
strings of words (commonly refered to as segments
or chunks) such that the words from a segment
are related to each other more strongly than words
from different segments. It is typically assumed
that the segments are syntactically and semanti-
cally coherent. Table 1 illustrates the concept of
segmentation of a query. The crowdsourced an-
notations for this data were obtained from 10 an-
notators, the experimental details of which will be
described in Sec. 5. We shall refer to this style of
text chunking as flat segmentation.
Nested segmentation of a query or a sentence,
on the other hand, is a recursive application of flat
segmentation, whereby the longer flat segments
are further divided into smaller chunks recursively.
The process stops when a segment consists of less
than three words or is a multiword entity that can-
not be segmented further. This style of segmenta-
tion can be represented through nested parenthe-
sization of the text, as illustrated in Table 2. These
annotations were also obtained through the same
crowdsourcing experiment (Sec. 5). Fig. 1 shows
an alternative visualization of a nested segmenta-
tion in the form of a tree.
An important problem that arises in the con-
text of flat segmentation is the issue of granular-
42
f Bracket representation Boundary var.
4 ((barbie dress)( up games)) 0 1 0
3 (barbie ((dress up) games)) 2 0 1
2 (barbie (dress (up games))) 2 1 0
1 ((barbie (dress up)) games) 1 0 2
Table 2: Example of nested segmentation from 10
Turkers. f is the frequency of annotations.
2
barbie 1
0
dress up
games
Figure 1: Tree representation of the nested seg-
mentation: (barbie ((dress up) games))
ity. For instance, in the case of NL chunking, it
is not clear whether the chunk boundaries should
correspond to the innermost parentheses in the
nested segmentation marking very short chunks,
or should one annotate the larger chunks corre-
sponding to clausal boundaries. For this reason,
Inter-Annotator Agreement (IAA) for flat annota-
tion tasks is often poor (Bali et al, 2009; Hagen
et al, 2011; Saha Roy et al, 2012). However, low
IAA does not necessarily imply low quality anno-
tation, and could as well be due to the inherent am-
biguity in the task definition with respect to gran-
ularity. Although we have illustrated the concept
and problems of flat and nested annotations using
the examples of sentence and query segmentation,
these issues are generic and typical of any flat an-
notation scheme which tries to flatten or approx-
imate an underlying hierarchical structure. There
are three important research questions pertaining
to the linguistic annotations of this kind:
? How to measure the true IAA and the quality
of the flat annotations?
? How to compare the agreement between the
flat and the nested annotations?
? How can we identify or construct the opti-
mal or error-free flat annotations from a noisy
mixture of nested and flat annotations?
In this paper, we introduce the concept of ?en-
tailment of a flat annotation by a nested annota-
tion?. For a given linguistic unit (a query or a sen-
tence, for example), a nested annotation is said to
entail a flat annotation if the structure of the lat-
ter does not contradict the more specific structure
represented by the former. Based on this simple
notion, which will be formalized in Sec. 3, we
develop effective techniques for comparing across
and evaluating the quality of flat and nested an-
notations, and identifying the optimal flat annota-
tion. We validate our theoretical framework on the
tasks of query and sentence segmentation. In par-
ticular, we conduct crowdsourcing based flat and
nested segmentation experiments for Web search
queries and sentences using Amazon Mechanical
Turk (AMT)1. We also obtain annotations for the
same datasets by trained experts which are ex-
pected to be of better quality than the AMT-based
annotations. Various statistical analyses of the an-
notated data bring out the effectiveness of entail-
ment as a metric for comparison and evaluation of
flat and nested annotations.
The rest of the paper is organized as fol-
lows. Sec. 2 provides some background on the
annotation tasks and related work on IAA. In
Sec. 3, we introduce the notion of entailment
and develop theoretical models and related
strategies for assessing the quality of annotation.
In Sec. 4, we introduce some strategies based
on entailment for the identification of error-free
annotations from a given set of noisy annotations.
Sec. 5 describes the annotation experiments
and results. Sec. 6 concludes the paper by
summarizing the work and discussing future
research directions. All the annotated datasets
used in this research can be obtained freely from
http://research.microsoft.com/
apps/pubs/default.aspx?id=192002
and used for non-commercial research purposes.
2 Background
Segmentation or chunking of NL text is a well-
studied problem. Abney (1991; 1992; 1995)
defines a chunk as a sub-tree within a syntac-
tic phrase structure tree corresponding to Noun,
Prepositional, Adjectival, Adverbial and Verb
Phrases. Similarly, Bharati et al(1995) define it
as Noun Group and Verb Group based only on lo-
cal surface information. Chunking is an important
preprocessing step towards parsing.
Like chunking, query segmentation is an im-
portant step towards query understanding and is
generally believed to be useful for Web search
1https://www.mturk.com/mturk/welcome
43
(see Hagen et al (2011) for a survey). Auto-
matic query segmentation algorithms are typically
evaluated against a small set of human-annotated
queries (Bergsma and Wang, 2007). The reported
low IAA for such datasets casts serious doubts on
the reliability of annotation and the performance
of the algorithms evaluated on them (Hagen et al,
2011; Saha Roy et al, 2012). To address the is-
sue of data scarcity, Hagen et al (2011) created
a large set of manually segmented queries through
crowdsourcing2. However, their approach has cer-
tain limitations because the crowd is already pro-
vided with a few possible segmentations of a query
to choose from. Nevertheless, if large scale data
has to be procured crowdsourcing seems to be the
only efficient and effective model for the task, and
has been proven to be so for other IR and lin-
guistic annotations (see Lease et al (2011) for
examples). It should be noted that almost all the
work on query segmentation, except (Huang et al,
2010), has considered only flat segments.
An important problem that arises in the context
of flat annotations is the issue of granularity. In the
absence of a set of guidelines that explicitly state
the granularity expected, Inter-Annotator Agree-
ment (IAA) for flat annotation tasks are often poor.
Bali et al (2009) showed that for NL chunking,
annotators typically agree on major (i.e., clausal)
boundaries but do not agree on minor (i.e., phrasal
or intra-phrasal) boundaries. Similarly, for query
segmentation, low IAA remains an issue (Hagen
et al, 2011; Saha Roy et al, 2012).
The issue of granularity is effectively addressed
in nested annotation, because the annotator is ex-
pected to mark the most atomic segments (such
as named entities and multiword expressions) and
then recursively combine them to obtain larger
segments. Certain amount of ambiguity, that may
arise because of lack of specific guidelines on the
number of valid segments at the last level (i.e., top-
most level of the nested segmentation tree), can
also be resolved by forcing the annotator to recur-
sively divide the sentence/query always into ex-
actly two parts (Abney, 1992; Bali et al, 2009).
The present study is an extension of our recent
work (Ramanath et al, 2013) on analysis of the
effectiveness of crowdsourcing for query and sen-
tence segmentation. We introduced a novel IAA
metric based on Kripendorff?s ?, and showed that
while the apparent agreement between the annota-
2http://www.webis.de/research/corpora
tors in a crowdsourced experiment might be high,
the chance corrected agreement is actually low for
both flat and nested segmentations (as compared
to gold annotations obtained from three experts).
The reason for the apparently high agreement is
due to an inherent bias of the crowd to divide
a piece of text in roughly two equal parts. The
present study extends this work by introducing a
metric to compare across flat and nested segmen-
tations that enables us to further analyze the relia-
bility of the crowdsourced annotations. This met-
ric is then employed to identify the optimal flat
segmentation(s) from a set of noisy annotations.
The study uses the same experimental setup and
annotated datasets as described in (Ramanath et
al., 2013). Nevertheless, for the sake of readability
and self-containedness, the relevant details will be
mentioned here again.
We do not know of any previous work that com-
pares flat and nested schemes of annotation. In
fact, Artstein and Poesio (2008), in a detailed sur-
vey of IAA metrics and their usage in NLP, men-
tion that defining IAA metrics for trees (hierarchi-
cal annotations) is a difficult problem due to the
existence of overlapping annotations. Vadas and
Curran (2011) and Brants (2000) discuss measur-
ing IAA of nested segmentations employing the
concepts of precision, recall, and f-score. How-
ever, neither of these studies apply statistical cor-
rection for chance agreement.
3 Entailment: Definition and Modeling
In this section, we shall introduce certain notations
and use them to formalize the notion of entail-
ment, which in turn, is used for the computation of
agreement between flat and nested segmentations.
Although we shall develop the whole framework
in the context of queries, it is applicable to sen-
tence segmentation and, in fact, more generally to
any flat and nested annotations.
3.1 Basic Definitions
Let Q be the set of all queries. A query q ? Q
can be represented as a sequence of |q| words:
w1w2 . . . w|q|. We introduce |q| ? 1 random vari-
ables, b1, b2, . . . b|q|?1, such that bi represents the
boundary between the words wi and wi+1. A flat
and nested segmentation of q, represented by F jq
and N jq respectively, j varying from 1 to total
number of annotations, c, is a particular instan-
tiation of these boundary variables as follows.
44
Definition. Flat Segmentation: A flat segmen-
tation, F jq , can be uniquely defined by a binary
assignment of the boundary variables bji , where
bji = 1 iff wi and wi+1 belong to two different flat
segments. Otherwise, bji = 0. Thus, q has 2
|q|?1
possible flat segmentations.
Definition. Nested Segmentation: A nested seg-
mentation, N jq , is defined as an assignment of
non-negative integers to the boundary variables
such that bji = 0 iff words wi and wi+1 form an
atomic segment (i.e., they are grouped together),
else bji = 1 + max(lefti, righti), where lefti
and righti are the heights of the largest subtrees
ending at wi and beginning at wi+1 respectively.
This numbering scheme can be understood
through Fig. 1. Every internal node of the binary
tree corresponding to the nested segmentation is
numbered according to its height. The lowest in-
ternal nodes, both of whose children are query
words, are assigned a value of 0. Other internal
nodes get a value of one greater than the height
of its higher child. Since every internal node cor-
responds to a boundary, we assign the height of
the node to the corresponding boundary variables.
The number of unique nested segmentations of q
is the corresponding Catalan number3 C|q|?1.
Note that, following Abney?s (1992) suggestion
for nested chunking, we define nested segmenta-
tion as a strict binary tree or binary bracketing of
the query. This is not only helpful for theoretical
analysis, but also necessary to ensure that there
is no ambiguity related to the granularity of seg-
ments.
3.2 Entailment
Given a nested segmentation N jq , there are several
possible ways to ?flatten? it. Flat segmentations of
q, where bi = 0 for all i (i.e., the whole query is
one segment) and bi = 1 for all i (i.e., all words are
in different segments) are trivially obtainable from
N jq , and therefore, are not neither informative nor
interesting. Intuitively, any flat segmentation, F kq ,
can be said to agree with N jq if for every flat seg-
ment in F kq there is a corresponding internal node
in N jq , such that the subgraph rooted at that node
spans (contains) all and only those words present
in the flat segment (Abney, 1991).
Let us take the examples of flat and nested
segmentations shown in Tables 1 and 2 to illus-
3http://en.wikipedia.org/wiki/Catalan\
_number
trate this notion. Consider two nested segmenta-
tions, N1q = ((barbie (dress up)) games), N
2
q =
(barbie ((dress up) games)) and three flat seg-
mentations, F 1q = barbie | dress up | games,
F 2q = barbie | dress up games, F
3
q =
barbie dress | up games. Figure 2 diagram-
matically compares the two nested segmentations
(the two rows) with the three flat segmentations
(columns A, B and C). There are three flat seg-
ments in F 1q , of which the two single word
segments barbie and games trivially coincide
with the corresponding leaf nodes. The segment
dressup coincides exactly with the words spanned
by the node marked 0 of N1q (Fig. 2, top row, col-
umn A). Hence, F 1q can be said to be in agree-
ment withN1q . On the other hand, there is no node
in N1q , which exactly coincides with the segment
dressupgames of F 2q (Fig. 2, top row, column B).
Hence, we say that N1q does not agree with F
2
q .
We formalize this notion of agreement in terms
of entailment, which is defined as follows.
Definition: Entailment. A nested segmentation,
N jq is said to entail a flat segmentation, F
k
q , (or
equivalently, F kq is entailed by N
j
q ) if and only if
for every multiword segment wi+1, wi+2, ..., wi+l
in F kq , the corresponding boundary variables in
N jq follows the constraint: bi > bi+m and bi+l >
bi+m for all 1 ? m < l.
It can be proved that this definition of entail-
ment is equivalent to the intuitive description pro-
vided earlier. Yet another equivalent definition of
entailment is presented in the form of Algorithm 1.
Due to paucity of space, the proofs of equivalence
are omitted.
Definition: Average Observed Entailment. For
the set of queries Q, and corresponding sets of
c flat and nested segmentations, there are |Q|c2
pairs of flat and nested segmentations that can be
compared for entailment. We define the average
observed entailment for this annotation set as the
fraction of these |Q|c2 annotation pairs for which
the flat segmentation is entailed by the correspond-
ing nested segmentation. We shall express this
fraction as percentage.
3.3 Entailment by Random Chance
Average observed Entailment can be considered
as a measure of the IAA, and hence, an indica-
tor of the quality of the annotations. However,
in order to interpret the significance of this value,
we need an estimate of the average entailment that
45
Figure 2: Every node of the tree represent boundary values, nested(flat). Column A: F 1q is entailed by
both N1q and N
2
q , Column B: F
2
q is entailed by N
2
q but not N
1
q , Column C: F
3
q is entailed by neither
N1q nor N
2
q . The nodes (or equivalently the boundaries) violating the entailment constraint are marked a
cross, and those agreeing are marked with ticks.
Algorithm 1 Algorithm: isEntail
1: procedure ISENTAIL(flat, nested) . flat,
nested are lists containing boundary values
2: if len(nested) ? 1 or len(flat) ? 1 then
3: return True
4: end if
5: h? largest element in nested
6: i? index of h
7: if flat[i] = 1 then
8: if ! isEntail(flat[: i], nested[: i]) or
! isEntail(flat[i+1 :], nested[i+1 :]) then
9: return False
10: else
11: return True
12: end if
13: else
14: while h 6= 0 do
15: nested[i]? ?nested[i]
16: h? largest element in nested
17: i? index of h
18: if flat[i] = 1 then
19: return False
20: end if
21: end while
22: return True
23: end if
24: end procedure
one would expect if the annotations, both flat and
nested, were drawn uniformly at random from the
set of all possible annotations. From our exper-
iments we observe that trivial flat segmentations
are, in fact, extremely rare, and a very large frac-
tion of the flat annotations have two or three seg-
ments. Therefore, for computing the chance en-
tailment, we assume that the number of segments
in the flat segmentation is known and fixed, which
is either 2 or 3, but all segmentations with these
many segments are equally likely to be chosen.
We also assume that all nested segmentations are
equally likely.
When there are 2 segments: For a query q, the
number of flat segmentations with two segments,
i.e., one boundary, is
(|q|?1
1
)
= |q| ? 1. Note
that for any nested segmentation N jq , all flat seg-
mentations that have at least one boundary and is
entailed by it must have a boundary between wi?
and wi?+1, where bi? has the highest value in N jq .
In other words, bi? is the boundary corresponding
to the root of the nested tree (the proof is intu-
itive and is omitted). Therefore, there is exactly
one ?flat segmentation with one boundary? that is
entailed by a given N jq . Therefore, the random
chance that a nested segmentation N jq will entail
a flat segmentation with one boundary is given by
(|q| ? 1)?1 (for |q| > 1).
When there are 3 segments: Number of flat
segmentations with two boundaries is
(|q|?1
2
)
. The
flat segmentation(s) entailed by N jq can be gener-
ated as follows. As argued above, every flat seg-
mentation entailed by N jq must have a boundary
46
at position i?. The second boundary can be either
in the left or right of i?. But in either case, the
choice of the boundary is unique which will corre-
spond to the highest node in the left or right sub-
tree of the root node. Thus, every nested segmen-
tation entails at most 2 flat segmentations. How-
ever, if i? = 1 or |q| ? 1 for a N jq , then, respec-
tively, the left or right subtrees do not exist. In
such cases, there is only one flat segmentation en-
tailed by N jq . Note that there are exactly C|q|?2
nested segmentations for which the i? = 1, and
similarly another C|q|?2 for which i
? = |q| ? 1.
Therefore, out of C|q|?1 ?
(|q|?1
2
)
pairs, exactly
2C|q|?1?2C|q|?2 pairs satisfy the entailment con-
ditions. Thus, the expected probability of entail-
ment by random chance when there are exactly
two boundaries in the flat segmentation of q is:
2(C|q|?1 ? C|q|?2)
C|q|?1
(|q|?1
2
) = 2
(
|q| ? 1
2
)?1
(1?
C|q|?2
C|q|?1
)
The values of the probability of observing a ran-
dom nested segmentation entailing a flat segmen-
tation with exactly two boundaries for |q| =
3, 4, 5, 6, 7 and 8 are 1, 0.4, 0.213. 0.133, 0.091
and 0.049 respectively.
3.4 Other IAA Metrics
Although entailment can be used as a measure of
agreement between flat and nested segmentations,
IAA within flat or within nested segmentations
cannot be computed using this notion. In (Ra-
manath et al, 2013), we have extensively dealt
with the issue of computing IAA for these cases.
Krippendorff?s ? (Krippendorff, 2004), which is
an extremely versatile agreement coefficient, has
been appropriately modified to be applicable to a
crowdsourced annotation scenario. ? = 1 im-
plies perfect agreement, ? = 0 implies that the
observed agreement is just as good as that by ran-
dom chance, whereas ? < 0 implies that the ob-
served agreement is less than that one would ex-
pect by random chance. Due to paucity of space
we omit any further discussion on this and refer
the reader to (Ramanath et al, 2013). Here, we
will use the ? values as an alternative indicator of
IAA and therefore, the quality of annotation.
4 Optimal Segmentation
Suppose that we have a large number of flat and
nested annotations coming from a noisy source
such as crowdsourcing; is it possible to employ
the notion of entailment to identify the annota-
tions which are most likely to be correct? Here,
we describe two such strategies to obtain the opti-
mal (error-free) flat segmentation.
Flat Entailed by Most Nested (FEMN): The
intuition behind this approach is that if a flat seg-
mentation F kq is entailed by most of the nested
segmentations of q, then it is very likely that F kq
is correct. Therefore, for each flat segmentations
of q, we count the number of nested segmentations
of q that entail it, and the one with highest count is
declared as the optimal FEMN segmentation. It is
interesting to note that while computing the opti-
mal FEMN segmentation, we never encountered a
tie between two flat segmentations. The trivial flat
segmentations (i.e., if the whole query is one seg-
ment or every word is in different segments) are
filtered as a preprocessing step.
Iterative Voting (IV): FEMN assumes that the
nested segmentations are relatively noise-free. If
most of the nested segmentations are erroneous,
FEMN would select an erroneous optimal flat seg-
mentation. To circumvent this issue, we propose a
more sophisticated iterative voting process, where
we count the number of flat segmentations entailed
by each nested segmentation of q, and similarly,
number of nested segmentations that entail each
flat segmentation. The flat and nested segmenta-
tions with the least scores are then removed from
the dataset. Then we recursively apply the IV pro-
cess on the reduced set of annotations until we are
left with a single flat segmentation.
5 Experiments and Results
We obtained nested and flat segmentation of Web
search queries through crowdsourcing as well as
from trained experts. Furthermore, we also con-
ducted similar crowdsourcing experiments for NL
sentences, which helped us understand the specific
challenges in annotating queries because of their
apparent lack of a well-defined syntactic structure.
In this section, we first describe the experimen-
tal setup and datasets, and then present the obser-
vations and results.
5.1 Crowdsourcing Experiment
In this study we use the same set of crowd-
sourced annotations as described in (Ramanath
et al, 2013). For the sake of completeness, we
briefly describe the annotation procedure here as
47
well. We used Amazon Mechanical Turk for the
crowdsourcing experiments. Two separate Hu-
man Intelligence Tasks were designed for flat and
nested segmentation. The concept of flat and
nested segmentation was introduced to the Turk-
ers with the help of two short videos4.
When in doubt regarding the meaning of a
query, the Turkers were advised to issue the query
on a search engine of their choice and find out its
possible interpretation(s). Only Turkers who had
completed more than 100 tasks at an acceptance
rate of ? 60% were allowed to participate in the
task and were paid $0.02 for a flat and $0.06 for a
nested segmentation. Every query was annotated
by 10 different annotators.
5.2 Dataset
The following sets of queries and sentences were
used for annotations:
Q500, QG500: Saha Roy et al (2012) re-
leased a dataset of 500 queries, 5 to 8 words long,
for the evaluation of various segmentation algo-
rithms. This dataset has flat segmentations from
three annotators obtained under controlled exper-
imental settings, and could be considered as Gold
annotation. Hence, we selected this set for our ex-
periments as well. We procured the correspond-
ing nested segmentation for these queries from
two human experts who are regular search engine
users. They annotated the data under supervision
and were trained and paid for the task. We shall
refer to the set of flat and nested gold annotations
as QG500, whereas Q500 will be reserved for the
dataset procured through the AMT experiments.
Q700: As 500 queries are not enough for mak-
ing reliable conclusions and also, since the queries
may not have been chosen specifically for the pur-
pose of annotation experiments, we expanded the
set with another 700 queries sampled from the
logs of a popular commercial search engine. We
picked, uniformly at random, queries that were 4
to 8 words long.
S300: We randomly selected 300 English sen-
tences from a collection of full texts of public do-
main books5 that were 5 to 15 words long, and
manually checked them for well-formedness.
4Flat: http://youtu.be/eMeLjJIvIh0, Nested:
http://youtu.be/xE3rwANbFvU
5http://www.gutenberg.org
5.3 Entailment Statistics
Table 3 reports two statistics ? the values of
Kripendorff?s ? and the average observed entail-
ment (expressed as %) for flat and nested segmen-
tations along with the corresponding expected val-
ues for entailment by chance. For nested segmen-
tation, the ? values were computed for two differ-
ent distance metrics6 d1 and d2.
As expected, the highest value of ? for both
flat and nested segmentation is observed for the
gold annotations. An ? > 0.6 indicates a rea-
sonably good7 IAA, and thus, reliable annota-
tions. We note that the entailment statistics fol-
low a very similar trend as ?, and for all the cases,
the observed average entailment is much higher
than what we would expect by random chance.
These two observations clearly point to the fact
that entailment is indeed a good indicator of the
agreement between the nested and flat segmenta-
tions, and consequently, the reliability of the an-
notations. We also observe that the average en-
tailment for S300 is in the same ballpark as for
the queries. This indicates that the apparent lack
of structure in queries does not specifically influ-
ence the annotations. Along the same lines, one
can also argue that the length of a text, which
is higher for sentences than queries, does not af-
fect the crowdsourced annotations. In fact, in our
previous study (Ramanath et al, 2013), we show
that it is the bias of the Turkers to divide a text
in approximately two segments of equal size (ir-
respective of other factors, like syntactic structure
or length), that leads to very similar IAA across
different types of texts. Our current study on en-
tailment further strengthens this fact.
Figure 3 plots the distribution of the entailment
values for the three datasets. The distributions are
normal-like implying that entailment is a robust
metric and its average value is a usable statistic.
In order to analyze the agreement between the
Turkers and the experts, we computed the av-
erage entailment between Q500 flat annotations
(from AMT) with QG500 nested annotations, and
similarly, Q500 nested annotations with QG500
6Intuitively, for d1 disagreements between segment
boundaries are equally penalized at all the levels of nested
tree, whereas for d2 disagreements higher up the tree (i.e.,
close to the root) are penalized more than those at lower lev-
els.
7It should be noted that there is no consensus on what is
a good value of ? for linguistic annotations, partly because
it is dependent on the nature of the annotation task and the
demand of the end applications that use the annotated data.
48
Dataset Krippendorff?s ? Entailment Statistics
Flat Nested Observed Chance
d1 d1 d2
Q700 0.21 0.21 0.16 49.68 12.63
Q500 0.22 0.15 0.15 56.69 19.08
QG500 0.61 0.66 0.67 87.07 11.91
S300 0.27 0.18 0.14 52.86 19.12
Table 3: ? and Average Entailment Statistics
Figure 3: Distribution of the entailment values (x-
axis) plotted as the % of comparable flat-nested
annotation pairs.
Figure 4: Distribution of percentage of entailed
pairs using QG500 as reference.
flat annotations, which turned out to be 70.42%
and 63.24% respectively. The corresponding dis-
tributions are shown as Nested and Flat in Fig.
4. Thus, the flat segmentations from the Turkers
seem to be more accurate than their nested seg-
mentations, a fact also supported by the ? values.
This could be due to the much higher cognitive
load associated with nested segmentation that de-
mands more time and concentration that an ordi-
nary Turker may not be willing to invest.
5.4 Optimal Segmentation Results
In order to evaluate the optimal flat segmentation
selection strategies, FEMN and IV, we computed
the percentage of queries in Q500 for which the
optimal flat segmentation (as obtained by apply-
ing these strategies on AMT annotations) is en-
tailed by the corresponding nested segmentations
in QG500. The average entailment values for
FEMN and IV turns out to be 79.60% and 82.80%
respectively. This shows that the strategies are in-
deed able to pull out the more accurate flat seg-
mentations from the set, though, as one would ex-
pect, IV performs better than FEMN, and its cho-
sen segmentations are almost as good as that by
expert annotators.
Another experiment was conducted to precisely
characterize the effectiveness of these strategies
whereby we mixed the annotations from the Q500
and QG500, and then applied FEMN and IV to
pull out the optimal flat segmentations. We ob-
served that for 63.71% and 91.44% of the queries,
the optimal segmentation chosen by FEMN and IV
respectively was indeed one of the three gold flat
annotations in QG500. This reinforces our con-
clusion that IV can effectively identify the optimal
flat segmentation of a query from a noisy set of flat
and nested segmentations.
6 Conclusion
In this paper, we proposed entailment as a theo-
retical model for comparing hierarchical and non-
hierarchical annotations. We present a formaliza-
tion of the notion of entailment and use it for de-
vising two strategies, FEMN and IV, for identify-
ing the optimal flat segmentation in a noisy set of
annotations. One of the main contributions of this
work resides in our following experimental find-
ing: Even though annotations obtained through
crowdsourcing for a difficult task like query seg-
mentation might be very noisy, a small fraction of
the annotations are nevertheless correct; it is pos-
sible to filter out these correct annotations using
the Iterative Voting strategy when both hierarchi-
cal and non-hierarchical segmentations are avail-
able from the crowd.
The proposed model is generic and we be-
lieve that the experimental findings extend beyond
query and sentence segmentation to other kinds of
linguistic annotations where hierarchical and non-
hierarchical schemes co-exist.
Acknowledgment
Thanks to Rishiraj Saha Roy, IIT Kharagpur, for
his valuable inputs during this work.
49
References
Steven P. Abney. 1991. Parsing By Chunks. Kluwer
Academic Publishers.
Steven P. Abney. 1992. Prosodic Structure, Perfor-
mance Structure And Phrase Structure. In Proceed-
ings 5th Darpa Workshop on Speech and Natural
Language, pages 425?428. Morgan Kaufmann.
Steven P. Abney. 1995. Chunks and dependencies:
Bringing processing evidence to bear on syntax.
Computational Linguistics and the Foundations of
Linguistic Theory, pages 145?164.
Ron Artstein and Massimo Poesio. 2008. Inter-coder
agreement for computational linguistics. Computa-
tional Linguistics, 34(4):555?596.
Kalika Bali, Monojit Choudhury, Diptesh Chatterjee,
Sankalan Prasad, and Arpit Maheswari. 2009. Cor-
relates between Performance, Prosodic and Phrase
Structures in Bangla and Hindi: Insights from a Psy-
cholinguistic Experiment. In ICON ?09, pages 101
? 110.
Shane Bergsma and Qin Iris Wang. 2007. Learn-
ing Noun Phrase Query Segmentation. In EMNLP-
CoNLL ?07, pages 819?826.
Akshar Bharati, Vineet Chaitanya, and Rajeev Sangal.
1995. Natural Language Processing: A Paninian
Perspective. Prentice.
Thorsten Brants. 2000. Inter-annotator agreement for
a German newspaper corpus. In In Proceedings of
Second International Conference on Language Re-
sources and Evaluation LREC-2000.
Matthias Hagen, Martin Potthast, Benno Stein, and
Christof Bra?utigam. 2011. Query segmentation re-
visited. In WWW ?11, pages 97?106.
Jian Huang, Jianfeng Gao, Jiangbo Miao, Xiaolong Li,
Kuansan Wang, Fritz Behr, and C. Lee Giles. 2010.
Exploring Web Scale Language Models for Search
Query Processing. In WWW ?10, pages 451?460.
Dan Jurafsky and James H Martin. 2000. Speech &
Language Processing. Pearson Education India.
Klaus Krippendorff. 2004. Content Analysis: An
Introduction to Its Methodology. Sage,Thousand
Oaks, CA.
Matthew Lease, Vaughn Hester, Alexander Sorokin,
and Emine Yilmaz, editors. 2011. Proceedings of
the ACM SIGIR 2011 Workshop on Crowdsourcing
for Information Retrieval (CIR 2011).
Rohan Ramanath, Monojit Choudhury, Kalika Bali,
and Rishiraj Saha Roy. 2013. Crowd Prefers the
Middle Path: A New IAA Metric for Crowdsourc-
ing Reveals Turker Biases in Query Segmentation.
In Proceedings of ACL. ACL.
Rishiraj Saha Roy, Niloy Ganguly, Monojit Choud-
hury, and Srivatsan Laxman. 2012. An IR-based
Evaluation Framework for Web Search Query Seg-
mentation. In SIGIR ?12, pages 881?890. ACM.
David Vadas and James R. Curran. 2011. Parsing
Noun Phrases in the Penn Treebank. Comput. Lin-
guist., 37(4):753?809, December.
50
Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 73?79,
October 25, 2014, Doha, Qatar.
c?2014 Association for Computational Linguistics
Word-level Language Identification using CRF: Code-switching Shared
Task Report of MSR India System
Gokul Chittaranjan
Microsoft Research India
t-gochit@microsoft.com
Yogarshi Vyas
?
University of Maryland
yogarshi@cs.umd.edu
Kalika Bali Monojit Choudhury
Microsoft Research India
{kalikab, monojitc}@microsoft.com
Abstract
We describe a CRF based system for
word-level language identification of
code-mixed text. Our method uses lexical,
contextual, character n-gram, and special
character features, and therefore, can
easily be replicated across languages. Its
performance is benchmarked against the
test sets provided by the shared task on
code-mixing (Solorio et al., 2014) for
four language pairs, namely, English-
Spanish (En-Es), English-Nepali (En-Ne),
English-Mandarin (En-Cn), and Standard
Arabic-Arabic (Ar-Ar) Dialects. The
experimental results show a consistent
performance across the language pairs.
1 Introduction
Code-mixing and code-switching in conversations
has been an extensively studied topic for sev-
eral years; it has been analyzed from structural,
psycholinguistic, and sociolinguistic perspec-
tives (Muysken, 2001; Poplack, 2004; Senaratne,
2009; Boztepe, 2005). Although bilingualism
is very common in many countries, it has sel-
dom been studied in detail in computer-mediated-
communication, and more particularly in social
media. A large portion of related work (Androut-
sopoulos, 2013; Paolillo, 2011; Dabrowska, 2013;
Halim and Maros, 2014), does not explicitly deal
with computational modeling of this phenomena.
Therefore, identifying code-mixing in social me-
dia conversations and the web is a very relevant
topic today. It has garnered interest recently, in
the context of basic NLP tasks (Solorio and Liu,
2008b; Solorio and Liu, 2008a), IR (Roy et al.,
2013) and social media analysis (Lignos and Mar-
cus, 2013). It should also be noted that the identi-
?
The author contributed to this work during his intern-
ship at Microsoft Research India
fication of languages due to code-switching is dif-
ferent from identifying multiple languages in doc-
uments (Nguyen and Dogruz, 2013), as the dif-
ferent languages contained in a single document
might not necessarily be due to instances of code
switching.
In this paper, we present a system built with
off-the-shelf tools that utilize several character and
word-level features to solve the EMNLP Code-
Switching shared task (Solorio et al., 2014) of
labeling a sequence of words with six tags viz.
lang1, lang2, mixed, ne, ambiguous, and others.
Here, lang1 and lang2 refer to the two languages
that are mixed in the text, which could be English-
Spanish, English-Nepali, English-Mandarin or
Standard Arabic-dialectal Arabic. mixed refers
to tokens with morphemes from both, lang1 and
lang2, ne are named entities, a word whose label
cannot be determined with certainty in the given
context is labeled ambiguous, and everything else
is tagged other (Smileys, punctuations, etc.).
The report is organized as follows. In Sec. 2,
we present an overview of the system and detail
out the features. Sec. 3 describes the training ex-
periments to fine tune the system. The shared task
results on test data provided by the organizers is
reported and discussed in Sec. 4. In Sec. 5 we con-
clude with some pointers to future work.
2 System overview
The task can be viewed as a sequence labeling
problem, where, like POS tagging, each token in a
sentence needs to be labeled with one of the 6 tags.
Conditional Random Fields (CRF) are a reason-
able choice for such sequence labeling tasks (Laf-
ferty et al., 2001); previous work (King and Ab-
ney, 2013) has shown that it provides good perfor-
mance for the language identification task as well.
Therefore, in our work, we explored various token
level and contextual features to build an optimal
CRF using the provided training data. The features
73
Lang. Given Ids Available Available (%)
Train Test Train Test Train Test
Es 11,400 3,014 11,400 1,672 100% 54.5%
Ne 9,999 3,018 9,296 2,874 93% 95.2%
Cn 999 316 995 313 99.6% 99.1%
Ar 5,839 2,363 5,839 2,363 100% 100%
Ar 2 - 1,777 - 1,777 - 100%
Table 2: Number of tweets retrieved for the vari-
ous datasets.
used can be broadly grouped as described below:
Capitalization Features: They capture if let-
ter(s) in a token has been capitalized or not. The
reason for using this feature is that in several lan-
guages, capital Roman letters are used to denote
proper nouns which could correspond to named
entities. This feature is meaningful only for lan-
guages which make case distinction (e.g., Roman,
Greek and Cyrillic scripts).
Contextual Features: They constitute the cur-
rent and surrounding tokens and the length of the
current token. Code-switching points are context
sensitive and depend on various structural restric-
tions (Muysken, 2001; Poplack, 1980).
Special Character Features: They capture the
existence of special characters and numbers in the
token. Tweets contain various entities like hash-
tags, mentions, links, smileys, etc., which are sig-
naled by #, @ and other special characters.
Lexicon Features: These features indicate the
existence of a token in lexicons. Common words
in a language and named entities can be curated
into finite, manageable lexicons and were there-
fore used for cases where such data was available.
Character n-gram features: Following King
and Abney (2013), we also used charagter n-grams
for n=1 to 5. However, instead of directly using
the n-grams as features in the CRF, we trained
two binary maximum entropy classifiers to identify
words of lang1 and lang2. The classifiers returned
the probability that a word is of lang1 (or lang2),
which were then binned into 10 equal buckets and
used as features.
The features are listed in Table 1.
3 Experiments
3.1 Data extraction and pre-processing
The ruby script provided by the shared task orga-
nizers was used to retrieve tweets for each of the
language pairs. Tweets that could not be down-
loaded either because they were deleted or pro-
Source Language For
instance types en.nt.bz2
1
English NE
instance types es.nt.bz2
1
Spanish NE
eng wikipedia 2010 1M-text.tar.gz
2
English FW
spa wikipedia 2011 1M-text.tar.gz
2
Spanish FW
Table 3: External resources used in the task.
1
http://wiki.dbpedia.org/Download,
2
http://corpora.uni-
leipzig.de/download.html; NE:Named entities, FW:Word fre-
quency list
tected were excluded from the training set. Ta-
ble 2 shows the number of tweets that we were
able to retrieve for the released datasets. Further,
we found a few rare cases of tokenization errors,
as evident from the occurrence of spaces within
tokens. These were not removed from the training
set and instead, the spaces in these tokens were re-
placed by an underscore.
3.2 Feature extraction and labeling
Named entities for English and Spanish were
obtained from DBPedia instance types, namely,
Agent, Award, Device, Holiday, Language, Mean-
sOfTransportation, Name, PersonFunction, Place,
and Work. Frequency lists for these languages
were obtained from the Leipzig Copora Collec-
tion(Quasthoff et al., 2006); words containing spe-
cial characters and numbers were removed from
the list. The files used are listed in table 3. The
character n-gram classifiers were implemented
using the MaxEnt classifier provided in MAL-
LET (McCallum, 2002). The classifiers were
trained on 6,000 positive examples randomly sam-
pled from the training set and negative examples
sampled from both, the training set and from word
lists of multiple languages from (Quasthoff et al.,
2006); the number of examples used for each of
these classifiers is given in Table 4.
We used CRF++ (Kudo, 2014) for labeling the
tweets. For all language pairs, CRF++ was run
under its default settings.
3.3 Model selection
For each language pair, we experimented with var-
ious feature combinations using 3-fold cross vali-
dation on the released training sets. Table 5 reports
the token-level labeling accuracies for the various
models, based on which the optimal feature sets
for each language pairs were chosen. These opti-
mal features are reported in Table 1, and the cor-
responding performance for 3-fold cross valida-
tion in Table 5. The final runs submitted for the
74
ID Feature Description Type Features used in the final submission (Optimal set)
En-Es En-Ne En-Cn Ar-Ar
Capitalization Features
CAP1 Is first letter capitalized? True/False 3 3 3 NA
CAP2 Is any character capitalized? True/False 3 3 3 NA
CAP3 Are all characters capitalized? True/False 3 3 3 NA
Contextual Features
CON1 Current Token String 3 3 3 3
CON2 Previous 3 and next 3 tokens Array (Strings) 3 3 3
CON3 Word length String 3 3 3 3
Special Character Features
CHR0 Is English alphabet word? True/False 3 NA
CHR1 Contains @ in locations 2-end True/False 3 3 3 3
CHR2 Contains # in locations 2-end True/False 3 3 3 3
CHR3 Contains ? in locations 2-end True/False 3 3 3 3
CHR4 Contains / in locations 2-end True/False 3 3 3 3
CHR5 Contains number in locations 2-end True/False 3 3 3 3
CHR6 Contains punctuation in locations 2-
end
True/False 3 3 3 3
CHR7 Starts with @ True/False 3 3 3 3
CHR8 Starts with # True/False 3 3 3 3
CHR9 Starts with ? True/False 3 3 3 3
CHR10 Starts with / True/False 3 3 3 3
CHR11 Starts with number True/False 3 3 3 3
CHR12 Starts with punctuation True/False 3 3 3 3
CHR13 Token is a number? True/False 3 3 3 3
CHR14 Token is a punctuation? True/False 3 3 3 3
CHR15 Token contains a number? True/False 3 3 3 3
Lexicon Features
LEX1 In lang1 dictionary of most frequent
words?
True/False 3 3 3 NA
LEX2 In lang2 dictionary of most frequent
words?
True/False 3 NA NA
LEX3 Is NE? True/False 3 3 NA NA
LEX4 Is Acronym True/False 3 3 NA NA
Character n-gram Features
CNG0 Output of two MaxEnt classifiers
that classify lang1 vs. others and
lang2 vs. others. This gives 2 prob-
ability values binned into 10 bns,
two from each classifier, for the two
classes.
Array (binned
probability)
3 3 NA NA
CRF Feature Type U U U B
Table 1: A description of features used. NA refers to features that were either not applicable to the
language pair or were not available. B/U implies that the CRF has/does not have access to the features
of the previous token.
75
Classifier Languages used (And # words)
English-Spanish Language Pair
Spanish vs Others [es (6000)], [en (4000), fr (500), hi (500), it (500), po (500)]
English vs Others [en (6000)], [es (4000), fr (500), hi (500), it (500), po (500)]
English-Nepali Language Pair
Nepali vs Others [ne (6000)], [en (3500), fr (500), hi (500), it (500), po (500)]
English vs Others [en (6000)], [ne (3500), fr (500), hi (500), it (500), po (500)]
Standard Arabic vs. Arabic Dialects
Std vs. Dialect [lang1 (9000)], [lang2 (3256)]
Table 4: Data to train character n-gram classifiers.
shared task, including those for the surprise test
sets, use the corresponding optimal feature sets for
each language pair.
Feature Context Language Pair
En-
Es
En-
Ne
?
En-
Cn
Ar-
Ar
Ar-
Ar
(2)
Development Set
All B 92.8 94.3 93.1 85.5 -
- CON2 B 93.8 95.6 94.9 81.2 -
- CHR* B 92.3 93.5 91.0 85.3 -
- CAP* B 92.7 94.2 90.1 - -
- CON2 U 93.0 94.3 93.1 85.6 -
- CNG0 B 92.7 94.2 - - -
- LEX* B 92.7 94.1 - - -
Optimal - 95.0 95.6 95.0 85.5 -
Results on Test data for the optimal feature sets
Regular 85.0 95.2 90.4 90.1 53.6
Surprise 91.8 80.8 - 65.0 -
Table 5: The overall token labeling accuracies (in
%) for all language pairs on the training and test
datasets. ?-? indicates the removal of the given
feature. ?*? is used to indicate a group of features.
Refer tab. 1) for the feature Ids and the optimal
set. B and U stand for bigram and unigram respec-
tively, where the former refers to the case when the
CRF had access to features of the current and pre-
vious tokens, and the latter to the case where the
CRF had access only to the features of the current
token. ?: Lexical resources available for En only.
4 Results and Observations
4.1 Overall token labeling accuracy
The overall token labeling accuracies for the regu-
lar and surpise test sets (wherever applicable) and
a second set of dialectal and standard Arabic are
reported in the last two rows of Table 5. The same
table also reports the results of the 3-fold cross val-
idation on the training datasets. Several important
observations can be made from these accuracy val-
ues.
Firstly, accuracies observed during the training
phase was quite high (? 95%) and exactly simi-
lar for En-Es, En-Ne and En-Cn data; but for Ar-
Ar dataset our method could achieve only up to
85% accuracy. We believe that this is due to un-
availability of any of the lexicon features, which
in turn was because we did not have access to any
lexicon for dialectal Arabic. While complete set
of lexical features were not available for En-Cn as
well, we did have English lexicon; also, we no-
ticed that in the En-Cn dataset, almost always the
En words were written in Roman script and the Cn
words were written in the Chinese script. Hence,
in this case, script itself is a very effective feature
for classification, which has been indirectly mod-
eled by the CHR0 feature. On the other hand, in
the Ar-Ar datasets, both the dialects are written us-
ing the same script (Arabic). Further, we found
that using the CNG0 feature that is obtained by
training a character n-gram classifier for the lan-
guage pairs resulted in the drop of performance.
Since we are not familiar with arabic scripts, we
are not sure how effective the character n-gram
based features are in differentiating between the
standard and the dialectal Arabic. Based on our
experiment with CNG0, we hypothesize that the
dialects may not show a drastic difference in their
character n-gram distributions and therefore may
not contribute to the performance of our system.
Secondly, we observe that effectiveness of the
different feature sets vary across language pairs.
Using all the features of the previous words (con-
text = B) seems to hurt the performance, though
just looking at the previous 3 and next 3 tokens
was useful. On the other hand, in Ar-Ar the re-
verse has been observed. Apart from lexicons,
76
character n-grams seems to be a very useful fea-
ture in En-Es classification. As discussed above,
CHR* features are effective for En-Cn because,
among other things, one of these features also cap-
tures whether the word is in Roman script. For En-
Ne, we do not see any particular feature or sets of
features that strongly influence the classification.
The overall token labeling accuracy of the
shared task runs, at least in some cases, differ quite
significantly from our 3-fold cross validation re-
sults. On the regular test sets, the results for En-
Ne is very similar to, and En-Cn and Ar-Ar are
within expected range of the training set results.
However, we observe a 10% drop in En-Es. We
observe an even bigger drop in the accuracy of the
second Ar-Ar test set. We will discuss the possible
reason for this in the next subsection. The accura-
cies on the surprise sets do not show any specific
trend. While for En-Es the accuracy is higher by
5% for the surprise set than the regular set, En-Ne
and Ar-Ar show the reverse, and a more expected
trend. The rather drastic drops in the accuracy for
these two pairs on the surprise sets makes error
analysis and comparative analysis of the training,
test and surprise datasets imperative.
4.2 Error Analysis
Table 6 reports the F-scores for the six labels, i.e.,
classes, and also an overall tweet/post level accu-
racy. The latter is defined as the percentage of in-
put units (which could be either a tweet or a post or
just a sentence depending on the dataset) that are
correctly identified as either code-mixed or mono-
lingual; an input unit is considered code-mixed if
there is at least one word labeled as lang1 and one
as lang2.
For all the language pairs other than Arabic, the
F-score for NE is much lower than that for lang1
and lang2. Thus, the performance of the system
can be significantly improved by identifying NEs
better. Currently, we have used lexicons for only
English and Spanish. This information was not
available for the other languages, namely, Nepali,
Mandarin, and Arabic. The problem of NE detec-
tion is further compounded by the informal nature
of sentences, because of which they may not al-
ways be capitalized or spelt properly. Better de-
tection of NEs in code-mixed and informal text is
an interesting research challenge that we plan to
tackle in the future.
Note that the ambiguous and mixed classes can
be ignored because their combined occurrence is
less than 0.5% in all the datasets, and hence they
have practically no effect on the final labeling ac-
curacy. In fact, their rarity (especially in the train-
ing set) is also the reason behind the very poor F-
scores for these classes. In En-Cn, we also observe
a low F-score for other.
In the Ar-Ar training data as well as the test set,
there are fewer words of lang2, i.e., dialectal Ara-
bic. Since our system was trained primarily on the
context and word features (and not lexicon or char-
acter n-grams), there was not enough examples in
the training set for lang2 to learn a reliable model
for identifying lang2. Moreover, due to the dis-
tributional skew, the system learnt to label the to-
kens as lang1 with very high probability. The high
accuracy in the Ar-Ar original test set is because
81.5% of the tokens were indeed of type lang1
in the test data while only 0.26% were labeled as
lang2. This is also reflected by the fact that though
the F-score for lang2 in Ar-Ar test set is 0.158, the
overall accuracy is still 90.1% because F-score for
lang1 is 94.2%.
As shown in Table 7, the distribution of the
classes in the second Ar-Ar test set and the sur-
prise set is much less skewed and thus, very differ-
ent from that of the training and original test sets.
In fact, words of lang2 occur more frequently in
these sets than those of lang1. This difference in
class distributions, we believe, is the primary rea-
son behind the poorer performance of the system
on some of the Ar-Ar test sets.
We also observe a significant drop in accuracy
for En-Ne surprise data, as compared to the accu-
racy on the regular En-Ne test and training data.
We suspect that it could be either due to the dif-
ference in the class distribution or the genre/style
of the two datasets, or both. An analysis of the
surprise test set reveals that a good fraction of
the data consist of long song titles or part of the
lyrics of various Nepali songs. Many of these
words were labeled as lang2 (i.e., Nepali) by our
system, but were actually labeled as NEs in the
gold annotations
1
While song titles can certainly
be considered as NEs, it is very difficult to iden-
tify them without appropriate resources. It should
however be noted that the En-Ne surprise set has
only 1087 tokens, which is too small to base any
strong claims or conclusions on.
1
Confirmed by the shared task organizers over email com-
munication.
77
Language Pair F-measure (Token-level) Accuracy of
Ambiguous lang1 lang2 mixed NE Other Comment/Post
En-Es 0.000 0.856 0.879 0.000 0.156 0.856 82.1
En-Ne - 0.948 0.969 0.000 0.454 0.972 95.3
En-Cn - 0.980 0.762 0.000 0.664 0.344 81.8
Ar-Ar 0.000 0.942 0.158 - 0.577 0.911 94.7
Ar-Ar (2) 0.015 0.587 0.505 0.000 0.424 0.438 71.4
En-Es Surprise 0.000 0.845 0.864 0.000 0.148 0.837 81.5
En-Ne Surprise - 0.785 0.874 - 0.370 0.808 71.6
Ar-Ar Surprise 0.000 0.563 0.698 0.000 0.332 0.966 84.8
Table 6: Class-wise F-scores and comment/post level accuracy of the submitted runs.
Dataset Percentage of
Amb. lang1 lang2 mixed NE Other
Training 0.89 66.36 13.60 0.01 11.83 7.30
Test-1 0.02 81.54 0.26 0.00 10.97 7.21
Test-2 0.37 32.04 45.34 0.01 13.24 9.01
Surprise 0.91 22.36 57.67 0.03 9.13 9.90
Table 7: Distribution (in %) of the classes in the
training and the three test sets for Ar-Ar.
5 Conclusion
In this paper, we have described a CRF based word
labeling system for word-level language identifi-
cation of code-mixed text. The system relies on
annotated data for supervised training and also
lexicons of the languages, if available. Character
n-grams of the words were also used in a MaxEnt
classifier to detect the language of a word. This
feature has been found to be useful for some lan-
guage pairs. Since none of the techniques or con-
cepts used here is language specific, we believe
that this approach is applicable for word labeling
for code-mixed text between any two (or more)
languages as long as annotated data is available.
This is demonstrated by the fact that the sys-
tem performs more or less consistently with accu-
racies ranging from 80% - 95% across four lan-
guage pairs (except for the case of Ar-Ar second
test set and the surprise set which is due to stark
distributional differences between the training and
test sets). NE detection is one of the most chal-
lenging problems, improving which will definitely
improve the overall performance of our system. It
will be interesting to explore semi-supervised and
unsupervised techniques for solving this task be-
cause creating annotated datasets is expensive and
effort-intensive.
References
Jannis Androutsopoulos. 2013. Code-switching in
computer-mediated communication. In Pragmatics
of Computer-mediated Communication, pages 667?
694. Berlin/Boston: de Gruyter Mouton.
Erman Boztepe. 2005. Issues in code-switching:
competing theories and models. Teachers College,
Columbia University Working Papers in TESOL &
Applied Linguistics, 3.2.
Marta Dabrowska. 2013. Functions of code-switching
in polish and hindi facebook users? post. Studia
Linguistica Universitatis Lagellonicae Cracovien-
sis, 130:63?84.
Nur Syazwani Halim and Marlyana Maros. 2014.
The functions of code-switching in facebook inter-
actions. In Proceedings of the International Con-
ference on Knowledge-Innovation-Excellence: Syn-
ergy in Language Research and Practice; Social and
Behavioural Sciences, volume 118, pages 126?133.
Ben King and Steven Abney. 2013. Labeling the lan-
guages of words in mixed-language documents us-
ing weakly supervised methods. In Proceedings of
NAACL-HLT, pages 1110?1119.
Taku Kudo. 2014. Crf++: Yet another crf
toolkit. http://crfpp.googlecode.com/
svn/trunk/doc/index.html?source=
navbar#links, Retrieved 11.09.2014.
John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the International
Conference on Machine Learning (ICML), pages
282?289.
Constantine Lignos and Mitch Marcus. 2013. Toward
web-scale analysis of codeswitching. In 87th An-
nual Meeting of the Linguistic Society of America.
Andrew Kachites McCallum. 2002. Mallet: A ma-
chine learning for language toolkit. http://
mallet.cs.umass.edu.
Pieter Muysken. 2001. The study of code-mixing. In
Bilingual Speech: A typology of Code-Mixing. Cam-
bridge University Press.
78
Dong Nguyen and A. Seza Dogruz. 2013. Word level
language identification in online multilingual com-
munication. In Proceedings of the 2013 Conference
on Empirical Methods in natural Language Process-
ing, pages 857?862.
John C. Paolillo. 2011. Conversational codeswitch-
ing on usenet and internet relay chat. Lan-
guage@Internet, 8.
Shana Poplack. 1980. Sometimes i?ll start a sentence
in Spanish y termino en espanol: Toward a typology
of code-switching. Linguistics, 18:581?618.
Shana Poplack. 2004. Code-switching. In U. Am-
mon, N. Dittmar, K.K. Mattheier, and P. Turdgill,
editors, Soziolinguistik. An international handbook
of the science of language. Walter de Gruyter.
U. Quasthoff, M. Richter, and C. Biemann. 2006. Cor-
pus portal for search in monolingual corpora. In
Proceedings of the fifth International Conference on
Language Resource and Evaluation, pages 1799?
1802.
Rishiraj Saha Roy, Monojit Choudhury, Prasenjit Ma-
jumder, and Komal Agarwal. 2013. Overview and
datasets of fire 2013 track on transliterated search.
In Proceedings of the FIRE 2013 Shared Task on
Transliterated Search.
Chamindi Dilkushi Senaratne, 2009. Sinhala-English
code-mixing in Sri Lanka: A sociolinguistic study,
chapter Code-mixing as a research topic. LOT Pub-
lications.
Thamar Solorio and Yang Liu. 2008a. Learning to pre-
dict code-switching points. In Proceedings of the
Empirical Methods on Natural Language Process-
ing (EMNLP), pages 973?981.
Thamar Solorio and Yang Liu. 2008b. Part-of-speech
tagging for English-Spanish code-switched text. In
Proceedings of the Empirical Methods on Natural
Language Processing (EMNLP), pages 1051?1060.
Thamar Solorio, Elizabeth Blair, Suraj Maharjan, Steve
Bethard, Mona Diab, Mahmoud Gonheim, Abdelati
Hawwari, Fahad AlGhamdi, Julia Hirshberg, Alison
Chang, and Pascale Fung. 2014. Overview for the
first shared task on language identifiation in code-
switched data. In Proceedings of the First Workshop
on Computational Approaches to Code-Switching.
Conferencfe on Empirical Methods in Natural Lan-
guage Processing.
79
Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 116?126,
October 25, 2014, Doha, Qatar. c?2014 Association for Computational Linguistics
?I am borrowing ya mixing ?? 
An Analysis of English-Hindi Code Mixing in Facebook 
 
 
Kalika Bali          Jatin Sharma           Monojit Choudhury 
Microsoft Research Lab India 
{kalikab,jatin.sharma,monojitc}@microsoft.com 
 
Yogarshi Vyas* 
University of Maryland  
yogarshi@cs.umd.edu 
 
Abstract1 
Code-Mixing is a frequently observed 
phenomenon in social media content gen-
erated by multi-lingual users. The pro-
cessing of such data for linguistic analysis 
as well as computational modelling is 
challenging due to the linguistic complex-
ity resulting from the nature of the mixing 
as well as the presence of non-standard 
variations in spellings and grammar, and 
transliteration. Our analysis shows the ex-
tent of Code-Mixing in English-Hindi 
data. The classification of Code-Mixed 
words based on frequency and linguistic 
typology underline the fact that while 
there are easily identifiable cases of bor-
rowing and mixing at the two ends, a large 
majority of the words form a continuum in 
the middle, emphasizing the need to han-
dle these at different levels for automatic 
processing of the data. 
1 Introduction 
The past decade has seen an explosion of Com-
puter Mediated Communication (CMC) world-
wide (Herring 2003). CMC provides users with 
multiple options, both asynchronous and synchro-
nous, like email, chat, and more recently, social 
media like Facebook and Twitter (Isharayanti et al 
2009, Paolillo 2011). This form of communica-
tion raises interesting questions on language use 
across these media. Language use in CMC lies 
somewhere in between spoken and written forms 
                                                 
1 This work was done during the author?s internship at Mi-
crosoft Research Lab India.  
of a language, and tend to use simple shorter con-
structions, contractions, and phrasal repetitions 
typical of speech (Dannett and Herring 2007) 
Such conversations, especially in social-media are 
also multi-party and multilingual, with switching 
between, and mixing of two or more languages, 
the choice of language-use being highly influ-
enced by the speakers and their communicative 
goals (Crystal 2001). 
Code-Switching and Code-Mixing are stable and 
well-studied linguistic phenomena of multilingual 
speech communities. Code-Switching is ?juxta-
position within the same speech exchange of pas-
sages of speech belonging to two different gram-
matical systems or sub-systems? (Gumperz 1982), 
and Code-Mixing refers to the embedding of lin-
guistic units such as phrases, words and mor-
phemes of one language into an utterance of an-
other language (Myers-Scotton 1993, 2002). 
Thus, Code-Switching is usually inter-sentences 
while Code-Mixing (CM) is an intra-sentential 
phenomenon. Linguists believe that there exists a 
continuum in the manner in which a lexical item 
transfers from one to another of two languages in 
contact (Myers-Scotton 2002, Thomason 2003). 
Example (1) below illustrates the phenomenon of 
Code-Switching, while (2) shows Code-Mixing. 
 
(1) I was going for a movie yesterday. raaste 
men mujhe Sudha mil gayi.  
Gloss: [I was going for a movie yesterday.] 
way in I Sudha meet went 
Translation: I was going for a movie yester-
day; I met Sudha on the way. 
116
 (2) Main kal movie dekhne jaa rahi thi and 
raaste me I met Sudha. 
Gloss: I yesterday [movie] to-see go Contin-
uous-marker was [and] way in [I met] Sudha.  
Translation: I was going for a movie yester-
day and on the way I met Sudha. 
 
The main view held by linguists being that a lexi-
cal item goes from being used as a foreign word 
to a valid loanword indistinguishable from the na-
tive vocabulary by virtue of repeated use and 
adoption of morpho-syntactic features of the re-
cipient language (Auer 1984). However, in the 
case of single words, most scholars agree that it is 
difficult to determine whether or not a word is a 
?bona fide loanword/borrowing? or an instance of 
nonce borrowing2 or CM (Alex 2008, Bentahila 
and Davies, 1991, Field 2002, Myers-Scotton 
2002, Winford 2003). In this study, we only con-
sider Code-mixing examples, i.e., intra-sentential 
embedding of a language in another language. 
Processing such language data is challenging 
from the perspective of linguistic understanding 
vis-?-vis discourse and conversational analysis, as 
well as computational modelling and applications 
to Machine Translation, Information Retrieval 
and Natural Interfaces. Especially, in the case of 
social-media content where there are added com-
plications due to contractions, non-standard spell-
ings, and ungrammatical constructions as well as 
mixing of scripts. Many languages that use non-
Roman scripts, like Hindi, Bangla, Chinese, Ara-
bic etc., are often represented using Roman trans-
literations (Virga and Khudanpur 2003, Sowmya 
et al 2010). This poses additional challenges of ac-
curately identifying and separating the two lan-
guages. Further, it is often difficult to disambigu-
ate a borrowing as a valid native vocabulary from 
a mixing of a second language when dealing with 
single words. An understanding of the nature of 
mixing in such data is one of the first steps to-
wards processing this data and hence, making a 
more natural interaction in CMC a real possibility. 
                                                 
2 Nonce-borrowings are typically borrowings that do 
not necessarily follow any phonological, morpho-syn-
tactic or sociolinguistic constraints on their assimila-
tion into the host language (Poplack et al 1988). How-
ever, it is not clear if this is always a defining feature 
In this paper, we analyze social media content 
from English-Hindi (En-Hin) bilingual users to 
better understand CM in such data. We look at the 
extent of CM in both Hindi embedding in English, 
as well as English in Hindi. Our analysis of the 
type of CM in this context based on frequency of 
use and linguistic typology helps further an under-
standing of the different kinds of CM employed 
by users and emphasizes the need to tackle these 
at different levels. 
Facebook 
Page 
No. of 
likes 
No. of 
posts col-
lected 
No. of 
comments 
collected 
Amitabh 
Bachchan 
12,674,509 5 3364 
BBC 
Hindi 
1,876,306 18 240 
Narendra 
Modi 
15,150,669 15 2779 
Shahrukh 
Khan 
8,699,146 2 600 
Total  40 6983 
 
Table 1: Facebook Data Source  
2 Corpus Creation and Annotation 
For the creation of corpus for studying En-Hin 
CM, data from public Facebook pages in which 
En-Hin bilinguals are highly active was consid-
ered appropriate. Hence, we chose the Facebook 
pages of three Indian public figures, two promi-
nent Bollywood stars viz, Amitabh Bachchan and 
Shahrukh Khan, and the then-PM-elect Narendra 
Modi. We also collected data from the BBC Hindi 
News page. The assumption was that Bollywood, 
politics and news being three very popular areas 
of interest for Indians, we would see a lot of activ-
ity from the community on these pages. A total of 
40 posts from Oct 22- 28, 2013 were manually 
collected and preference was given to posts hav-
ing a long (50+) thread of comments. This is be-
cause CM and non-standard use of language is 
more frequent in comments. In the rest of the pa-
per, we shall use the term posts to cover both com-
ments and posts. The data was semi-automatically 
cleaned and formatted, removing user names for 
privacy. The names of public figures in the posts 
were retained. The final corpus consisted of 6983 
between established loanwords and nonce-borrowing, 
the line between them being extremely tenuous 
(Sankoff et al, 1990) 
117
posts and 113,578 words. Table 1 shows the data 
source statistics.  
While a number of posts were in the Devanagari 
script, the largest representation was that of Ro-
man script. A small number of posts were found 
in the script of other Indian languages like Bangla, 
Telugu etc. Tables 2 (a) and (b) show the distribu-
tion of posts and words by script 
 
 
Facebook 
Page 
Deva-
nagari 
Roman Mixed 
Script 
Other 
Script 
Amitabh 
Bachhcan 
73 3168 112 16 
BBC 
Hindi 
56 175 27 0 
Narendra 
Modi 
77 2633 84 11 
Shahrukh 
Khan 
0 578 23 1 
 
Table 2 (a): Script used for Posts 
 
 
Facebook 
Page 
Deva-
nagari 
Roman Other 
Script 
Symbols 
Amitabh 
Bachhcan 
2661 38144 439 1768 
BBC 
Hindi 
5225 4265 23 160 
Narendra 
Modi 
9509 43,804 217 1470 
Shahrukh 
Khan 
0 5,514 105 274 
 
Table 2(b): Script used for Words 
2.1 Annotation 
As a first step towards analysis, it is imperative 
that an annotation scheme be arrived at that cap-
tures the richness, diversity and uniqueness of the 
data. Any analysis of code-mixed CMC language-
use requires inputs at social, contextual, and dif-
ferent linguistic and meta-linguistic levels that op-
erate on various sub-parts of the conversation. 
This would help label not only the structural lin-
guistics phenomena such as POS tagging, 
Chunks, Phrases, Semantic Roles etc.  but also the 
various socio-pragmatic contexts (User de-
mographics, Communicative intent, Polarity etc.). 
However, an initial attempt at such a rich, layered 
annotation proved the task to be immensely re-
source intensive. Hence, for the initial analysis the 
annotation scheme was scaled down to four la-
bels: 
Matrix: Myers Scotton?s (1993) framework, CM 
occurs where one language provides the morpho-
syntactic frame into which a second language in-
serts words and phrases. The former is termed as 
the Matrix while the latter is called Embedding. 
Usually, matrix language can be assigned to 
clauses and sentences. 
Following this framework, the annotator was 
asked to split all posts into contiguous fragments 
of words such that each fragment has a unique ma-
trix language (En or Hin) 
Word Origin: Every embedded word is marked 
for its origin (En or Hin) depending on whether 
the source language was English or Hindi. A word 
from a language other than English or Hindi was 
marked as Other (Ot). It was assumed that the un-
marked words within a matrix language origi-
nated in that language. In our data we did not find 
examples of sub-lexical CM. For example an Eng-
lish word with Hindi inflection like computeron 
(???????????) were the English word ?computer? is 
inflected by the Hindi plural marker ?on. How-
ever, this can be a possible occurrence in En-Hin 
CM and needs to be marked as such. 
Normalization: Whenever a word in its native 
script uses a non-standard spelling (including con-
tractions) it is marked with its correct spellings. 
For transliterations of Hindi in Roman script, the 
word is marked with the correct spelling in Deva-
nagari script.  
POS tagging: Each word is labelled with its POS 
tag following the Universal Tagset proposed by 
Petrov et al (2011). This tagset uses 12 high-level 
tags for main POS classes. While, this tagset is not 
good at capturing granularity at a deeper level, we 
chose this because of a) its applicability to both 
English and Hindi doing away with the need for 
any mapping of labels between the two languages, 
and b) the small size of the corpus posed serious 
doubts on the usefulness of a more granular tagset 
for any analysis. 
The POS tags were decided on the basis of the 
function of the word in a context rather than a de-
contextualized absolute word class. This was done 
because often in the case of embedded words, the 
lexical category of the original language is com-
pletely lost and it is the function of the word in the 
matrix language that applies and assumes im-
portance. 
Named Entities: Named Entities (NE) are per-
haps the most common and amongst the first to 
form the borrowed or mixed vocabulary in CM. 
As the Universal Tagset did not have a separate 
118
category for NEs, we chose to label and classify 
them as people, locations and organizations. It is 
important to remember that while NEs are perhaps 
the most frequent ?borrowings? the notion of 
Word Origin in the context of CM is debatable. 
However, these need to be analyzed and processed 
separately for any NLP application. 
1062 posts consisting of 1071 words were ran-
domly selected and annotated by a linguist who is 
a native speaker of Hindi and proficient in Eng-
lish. Non-overlapping subsets of the annotations 
were then reviewed and corrected by two expert 
linguists.  
The two annotated examples from the corpus of 
En in Hin Matrix and Hin in En Matrix are given 
below: 
 
 
<s> 
 <matrix name="Hindi"> 
love_NOUN/E affection_NOUN/E le-
kar_VERB/??? ??  ?
salose_NOUN=saalon/?????? ??  ?
sunday_NOUN/E ke_ADP/???  ?
din_NOUN/????  ?chali_VERB/ ????  ?aar-
ahi_VERB/?? ???  ?divine_ADJ/E param-
para_NOUN/???????? ko_ADP/ ???  ?
age_NOUN=aage/?????badhha_VERB/????  ?
rahe_VERB/????  ?ho_VERB/???  ?
 </matrix> 
</s> 
Translation: The divine tradition that (you) have 
been carrying forward every Sunday with love 
and affection.  
 
<s> 
<matrix name="English"> 
 sir_NOUN u_PRON=you r_VERB=are 
blessed_VERB by_ADP entire_ADJ brah-
mand_NOUN/H???????????  ?
 </matrix> 
</s> 
Translation: Sir, you are blessed by the entire 
Universe. 
 
It was observed that a large chunk of data con-
sisted of short posts typically a greeting or a eu-
logy from a fan of the public figures and were un-
interesting from a structural linguistic analysis of 
CM. Thus, all such posts (consisting of 5 or less 
words) were deleted from the corpus and the re-
maining corpus of 381 posts and 4135 words was 
used for further analysis. 
3 An Analysis of Code Mixed Data 
The annotated data consists of 398 Hin sentences, 
698 En and 6 Ot in a single language. 45 posts 
show at least one switch in matrix between En and 
Hin. Thus, at least 4.2% of the data is Code-
Switched. It should be noted however that this is 
matrix switching within an utterance. If we con-
sider Code-Switching at a global level to include 
switching from one language to another within a 
conversation thread then all the threads in the data 
show code-switching as they contain utterances 
from both English and Hindi.  
Looking at the 398 Hindi matrices, we find that 
23.7% of them show at least one En embedding as 
compared to only 7.2% of the En matrices with 
Hin embedding. In total 17.2% of all posts which 
consist of nearly a quarter of all words in the data 
show some amount of CM. 
 If we look at the number of points in a single ma-
trix where embedding happens, we find that in 
86% of  the En matrices, Hin embeddings appear 
only once or twice. En embeddings in Hin matrix 
is not only twice as more frequent, but can occur 
more often in a single matrix (more than 3 times 
in at least 10% of the cases). Table 3 shows the 
distribution of CM points for both the cases. 
 
# of points Hin in En En in Hin 
1 11 (36.66%) 19 (31.15%) 
2 15 (50%) 28 (45.9%) 
3 2   (6.67%) 2   (3.28%) 
4 2   (6.67%) 9   (5.49%) 
5 0 2   (3.28%) 
6 0 1   (1.64%) 
Total 30 61 
 
Table 3: Distribution of CM points 
 
 
 
Table 4: Distribution of NE by Type 
 
As expected, NEs are common in the corpus and 
there are a total of 233 NEs in 406 matrices (322 
of 4134 words). The distribution of NEs by sub-
classes is given in Table 4. 
Table 5 shows the distribution of the various POS 
in the entire corpus, as well as for the embedded 
words. Nouns do form the largest class of words 
NE Type Person 159 
NE Type Location 39 
NE Type Organization 35 
Total NE 233 
119
overall as well as for Hin as well as En embed-
ding. In fact, for Hin in English matrix, there are 
only two instances of words which are not Nouns. 
Table 5 shows the distribution of POS for Hin in 
En matrix, and En in Hin matrix 
Looking at these top-level distributions we can 
observe that though there are some similarities be-
tween the patterns of CM for Hin in English and 
En in Hindi matrices (the high frequency of 
nouns, for instance), they both exhibit distinct pat-
terns in terms of how often CM occurs as well as 
in the prevalence of POS other than Nouns. In 
Section 3.1 and 3.2 we will look at both these L1 
embedding in L2 matrix individually in more de-
tail. 
3.1 Hindi words in English matrix 
As mentioned above, most of the Hin embedding 
in En (32 out of 33) matrices are Nouns. The ex-
ception is variation of the particle ?ji? used as an 
honorific marker in Hindi. The particle is used to 
denote respect and occurs in formulaic expression 
of the kind <(name/address form)> ji as in: 
 
?Amit ji, I am your fan and have seen all your 
movies? 
 
A closer look at the embedded Hin Nouns shows 
that a large number of them are actually part of 
multi-word Named Entities which do not fall un-
der the categories defined in the annotation guide-
lines. Almost all of them also function as regular 
Nouns or Verbs in Hindi. For example, the word 
?hunkaar? (a roar) is not an NE, however its use 
in the following sentence, where it is used to de 
note the name of a particular rally (event) can be 
viewed as an NE. 
 
?hunkar rally will be held tomorrow? 
 
Similarly, the word ?yaatraa? in Hindi means 
journey whereas its use in the phrase ?Kerala 
yaatraa? is specific to a tour of Kerala. 
 
There are some instances of nonce-borrowing or 
CM where Hindi Nouns are not used as a part of a 
potential NE or formulaic expressions. For exam-
ple, in the following sentence: 
 
??and the party workers (will) come with me 
without virodh? 
 
The Hindi word ?virodh? is used instead of the 
English alternative ?protest? or ?objection?. It can 
only be assumed that the user did this for sociolin-
guistic or pragmatic reasons to emphasize or hu-
mour. 
 
Kinship terms form another domain of frequent 
embedding of Hin in En. Hindi has a more com-
plex system of kinship terms where not only are 
there finer distinctions maintained between mater-
nal and paternal relations but also kinship terms 
are used to address older (and hence) respectable 
people. Thus, we find the use of ?chacha? (fa-
ther?s younger brother), ?bhaiya? (elder brother) 
as well as ?baapu? (father) used frequently in the 
data as address forms. 
3.2 English words in Hindi matrix 
There is a far greater use of English words in 
Hindi matrices both as single words as well as 
multi-word expressions. A total of 116 unique 
Hindi words are found embedded in En matrices 
of which 76 are single word embedding and the 
rest are a part of 16 multi-word expressions. 
While Nouns continue to dominate the POS class 
of the Hindi embedding as well, there is far more 
variations in the type of CM that seems to be hap-
pening in this case. 
3.2.1 Single Word Embedding 
As in the case of English embedding (3.1) we find 
a number of Hindi Noun embedding to be of kin-
ship terms, greetings and other address form. 
POS 
Tag 
Over-
all 
En in Hin 
matrix* 
Hin in  En 
matrix* 
NOUN 1260 77 32 
VERB 856 8  
PRON 499 4  
ADP 445 0  
ADJ 302 16  
PRT 241 4 1 
DET 141 2  
. 125 NA  
ADV 104 3  
CNJ 98 2  
NUM 46 0  
X 18 0  
Total 4135   
Table 5: POS distribution for the Annotated 
Corpus.  
* Overall distribution is given at token level 
whereas the embedding En in Hin matrix, and 
Hin in E matrix are at Unique Word level. 
 
120
Words like, ?sir?, ?uncle?, ?hello?, ?good morn-
ing? etc are used frequently to start or end a par-
ticular turn.  
A fraction of Nouns are genuine borrowings into 
the language is no Hindi equivalent for that 
word/concept. Common examples are words like 
?goal? and ?bomb? which may be considered a 
part of the Hindi vocabulary. What is interesting 
is that users? variations in spellings these words 
either in English (?goal?, ?bomb?) or in equiva-
lent Hindi transliteration (?gol?, ?bam?). This 
may be taken as an indication that the user is not 
actively conscious of using an English word. 
However, there are a fairly large number of Nouns 
as single words where this is not applicable as in: 
 
?agar aap BJP ke follower hain to is page ko like 
karen? 
 
(If you are a BJP follower then like this page) 
 
where there are frequently used Hindi equivalents 
but the user seems to be following certain conven-
tions on Facebook (?page? and ?like?) or is mix-
ing for other purposes (?follower?) 
 
Single adjectives are not as common and when 
used are mostly intensifiers such as ?very? or 
?best? etc. There are some instances of adjectives 
as nonce-borrowings such as in the following ex-
ample: 
 
??divine paramparaa ko aage?? 
(?(taking the) divine tradition forward?) 
 
Single verb embedding of En words are always of 
the form V + kar in the data. The verb karnaa (?to 
do?) in Hindi is used to form conjunctives in 
Hindi. Thus, we have a number of Hindi phrases 
of the type: kaam karnaa  ? work to do? (to work), 
and a closer look at the English Verbs embedded 
in Hindi shows that most of these are actually in 
their nominalized form, such as ? driving kar-
naa?, or as a V + V conjunct such as ?admit kar-
naa?. 
There are fewer instances of other POS classes, 
however, one interesting case is the use of con-
juncts like ?but? and ?and? to join two Hindi 
clauses as in: 
 
?main to gayi thi but wo wahaan nahi thaa? 
(I had gone but he wasn?t there) 
 
3.2.2 Multi Word Embedding 
Multi word expressions in English used in a Hindi 
matrix range from standard formulaic expressions 
to clause or phrase insertion. Other than standard 
greetings, these formulaic (or frozen) expression 
may work as Named Entities or Nominal com-
pounds as in the case of  ?Film star?, ?Cricket 
player?, ?Health minister?, ?Educational Insti-
tutes? and ?Participation Certificate?. There are 
also other expressions that border on formulaic in 
English but which nevertheless have an ambigu-
ous status within Hindi, such as, ?love and affec-
tion?. Another example of such a case of MW em-
bedding is: 
 
?Befitting reply to mere papa ne maaraa? 
 
(my father gave a befitting reply) 
 
Here, while ?befitting reply? is not really a formu-
laic expression in Hindi, the user is clearly using 
it as such with the use of  the  emphatic to and the 
use of the verb maaraa (?hit?) instead of  diyaa 
(?gave?) 
 
Clause or phrase level mixing, though less fre-
quent can also be found in the data. For example,  
 
?Those who support the opposition kabhi Mu-
zaffarnagar aa kar dekho? 
 
(Those who support the opposition should come 
to Muzaffarnagar and see (for themselves)) 
 
This is a classic case of CM where both the 
phrases retain the grammatical structure of the 
language concerned. 
 
As can be seen from the analysis of the annotated 
corpus above, Code-Mixing if understood as the 
insertion of words from a language into the gram-
matical structure of another, can show a wide var-
iation in its structural linguistic manifestation.  
4 Borrowing ya Mixing? 
In linguistic literature on ?other language embed-
ding? there has been a long-standing debate on 
what is true Code-mixing, what is nonce-word 
borrowing, and what are  ?loanwords? that 
are integrated into the native vocabulary and 
grammatical structure (Bentahila and Davies,  
1991, Field 2002, Myers-Scotton 2002, Winford 
2003, Poplack and Dion 2012). Many linguists be-
lieve that loan-words start out as a CM or Nonce-
121
borrowing but by repeated use and diffusion 
across the language they gradually convert to na-
tive vocabulary and acquire the characteristics of 
the ?borrowing? language (see Alex (2008) for a 
discussion). Normally, they look at spoken forms 
to see phonological convergence and inflections 
for morpho-syntactic convergence. However, as 
pointed out by Poplack and Dion (2012) the prob-
lem with this is that in many cases a native ?ac-
cent? might be mistaken for phonological conver-
gence, and a morpho-syntactic marking might not 
be readily visible. For example, most Hindi speak-
ers of English would pronounce an English alve-
olar /d/ as a retroflex because an alveolar plosive 
is not a part of the Hindi phonology. However, 
this does not imply that the said English word has 
become a part of the native vocabulary. Similarly, 
if we look at the two sentences: 
 
?sab artists ko bulayaa hai?  
(all artists have been called), 
 
and 
 
?sab artist kal aayenge? 
(all artists will come tomorrow) 
 
In the first sentence the English inflection ?s on 
the word artist marks it as plural but in the second 
case, the plural is marked on the Hindi Verb. Does 
this imply that in the first case it is CM and in the 
second a case of borrowing given that both the 
forms and the structures are equally acceptable 
and common in Hindi?  
Many studies (Mysken 2000, Gardner-Chloros. 
2009, Poplack and Dion 2012 etc.) thus point out 
that it is not easy to decide these categories espe-
cially for single words without looking at dia-
chronic data and the inherent fuzziness of the dis-
tinction itself. In general, it is believed that there 
exists a sort of continuum between CM and loan 
vocabulary where the edges might be clearly dis-
tinguishable but it is difficult to disambiguate the 
vast majority in the middle especially for single 
words.  
As we have seen in the preceding Section CM of 
Hin in English matrix mainly follows a very dis-
tinct pattern of using NEs (and functional NEs) 
and formulaic expressions. However, in the case 
of En in Hindi CM, there is a far wider variation 
and it could be difficult in many instances to de-
cide by just looking at the data whether a certain 
embedding is a borrowing or CM. 
One way to make a distinction between a borrow-
ing and CM could be to look at the diffusion of the 
word in the native language. Borrowed words of-
ten appear in monolingual usage long before dic-
tionaries and lexicons adopt them as native vocab-
ulary. Thus, to judge the diffusion of an English 
word one would have to look at the frequency of 
its use in suitable monolingual context such as 
news wire data, chat logs or telephone conversa-
tions.  
For a further analysis of En embedding in Hin 
matrix in our data, we decided to check their fre-
quency based diffusion in a monolingual new cor-
pus of Hindi. For this purpose we took a corpus of 
51,277,891words from Dainik Jagaran 
(http://www.jagran.com/), a popular daily news-
paper in Hindi, and created a frequency count of 
the 230,116 unique words in it. News corpora are 
a reasonable choice for monolingual frequencies 
as code-mixing is relatively rare and frowned 
upon in news unless it refers to a named entity or 
is a part of a direct quote. We then mapped com-
mon Hindi equivalents of all the English words 
used in the corpora. Finally, we checked the fre-
quency of both the English embedding as well as 
their corresponding Hindi equivalents. As men-
tioned before, a number of English words do not 
have Hindi equivalents and for these words we ex-
pect the English words themselves to have a high 
frequency count in the corpus. 
An analysis of the results thus obtained shows 
that the English words do indeed fall into two dis-
tinct buckets at the edges. Thus, for words such as 
?party? (as in ?political party?), ?vote?, ?team? 
we find that not only are the word counts quite 
high (over 67K for ?party? and over 18k for 
?vote? and ?team?) but the counts for the equiva-
lent Hindi forms are relatively low. Similarly, 
words like ?affection?, ?driving?, ?easily? etc. 
were not found in the corpus, while their Hindi 
equivalents had relatively medium to high counts. 
However, there is a large number of words in the 
middle where both the English and the Hindi 
equivalents have a comparative count or the dif-
ference is not significant. For these words it is dif-
ficult to decide whether they ought to be classified 
as borrowing or CM.  
Let us denote the frequency of an En word as fe 
and that of its Hin synonym as fh. Let ? be an ar-
bitrary margin > 0. The aforementioned intuition 
about the nature of CM and borrowing can be for-
malized as follows:  
? If for a given word log(fh/fe)> ?, we call it 
CM  
122
?  If for a given word log(fh/fe) < -?, we call 
it a borrowing. 
? If -? ? log(fh/fe) ? ?, it is not possible to 
decide between the two cases, and hence 
we call the word ambiguous. 
Figure 1 shows the scatter plot of the frequency of 
all the En words that occur within Hin matrix (119 
in total) in the Dainik Jagaran data (x-axis) against 
the frequency of its Hindi synonym (y-axis) in the 
same corpus. Since frequency follows Zipfs law, 
the axes are in log-scale. The words, which are 
represented by dots in Figure 1, are scattered all 
over the plot without any discernable pattern. This 
indicates that there are no distinct classes of words 
that can be called borrowings or mixing; rather, it 
is a continuum. If we assume ? to be 1, an arbi-
trary value, we can divide the plot into three zones 
using the three rules proposed above. These 
zones, bounded by the blue lines are shown in Fig-
ure 1: Mixing ? words that are code-mixed (top-
left triangle), borrowings (bottom-right triangle) 
and ambiguous (the narrow zone running diago-
nally between the two with a width of 2?. 
However, we observe that some En words which 
has very high frequency in our corpus (e.g., vote, 
party, team), are classified as ambiguous because 
their Hin synonyms have a comparable high fre-
quency as well. To a native speaker of Hindi, 
these words are clearly borrowings and used even 
in formal Hin text. In fact, it seems reasonable to 
declare an En word as a borrowing solely on the 
basis of its very high frequency in the monolin-
gual corpus. We could choose another arbitrary 
threshold ? = 1000, such that a word is declared 
as a borrowing if the following two conditions are 
satisfied: 
? -? ? log(fh/fe) ? ?  
? fe > ? 
Note that the choice of ? should also depend on 
the size of the corpus. Table 6 reports the number 
of CM in the data with and without applying the 
large frequency rule. We see that the number of 
CM words is the highest followed by ambiguous 
words. This clearly indicates that CM is a very 
common phenomenon on social media. Appendix 
A lists all the En words and their classes.  
 Using arbitrary thresholds, ? and ?, to classify the 
words into three distinct set is a convenient tool to 
deal with code-mixing; but it ignores the fact that 
in reality it is not possible to classify words into a 
few distinct categories. There is always a contin-
uum between borrowing and mixing. Figure 1 
shows a more appropriate gradient based visuali-
zation of the space. Words falling on the darker 
regions of this plot are more likely to be borrow-
ing. The gradients reflect the two equations dis-
cussed above. The darkness linearly increases 
with log(fe) and decreases with log(fh/fe). The 
overall darkness is a simple linear combination of 
these two independent factors. Note that this for-
mulation is only for a visualization purpose, and 
should not be interpreted as some formal proba-
bility or measure of ?borrowing-ness? of a word. 
 
 
 
Figure 1: Plot of the frequencies of En words em-
bedded in Hin matrix (x-axis) and their Hin syno-
nyms (y-axis) in the Dainik Jagaran corpus. 
 
 CM Ambigu-
ous 
Borrowing 
w/o ?-Rule 69 39 11 
w/ ?-Rule 69 31 19 
 
Table 6: Classification of embedded En words 
into three classes for ? =1. 
 
A note on synonym selection: Which syno-
nym(s) of an En word should be considered for 
CM vs. borrowing analysis is a difficult question. 
First, a word can have many senses. E.g., the word 
party can mean a political party, a group of peo-
ple, or a social gathering, and also a verb ? to par-
ticipate in a social gathering. Each of these senses 
can be translated in, often more than one ways. 
E.g., dala in the sense of political party, 
anusThANa or dAwata in the sense of social gath-
ering, etc. To complicate the situation further, 
these Hindi words can have many senses as well 
(e.g., the word dala can mean a sports team, or a 
political party or group of people or animals).  
Thus, when we compare synonyms without 
context, we cannot be sure in which sense the 
123
words are used and therefore, the frequency 
counts maybe misleading. A second problem arise 
with phrase embedding. While an entire phrase 
can be borrowed, its words may not be (e.g., clean 
chit  -Indian version of the English expression 
?clean sheet?- is a borrowed expression in Hindi, 
but clean is not). However, we had access to only 
the wordlist and word frequencies, which made it 
impossible to disentangle such effects. Compar-
ing contexts automatically deciphering word 
sense is a complex problem in itself. For this 
work, we used an En to Hin lexicon 
(http://shabdkosh.raftaar.in/) to find out the syno-
nyms, and for every synonym extracted the fre-
quency from the wordlist, and deemed the highest 
frequency as the fh for the word. A more thorough 
synonym selection using context and phrase level 
analysis would be an interesting extension of this 
work. 
4.1 Ambiguous Words 
The words classified as ambiguous pose a prob-
lem as we do not know whether these words are 
in the process of being borrowed, or are working 
as near-synonym of the Hindi equivalent, or are 
CMs where the intention of the user is the motiva-
tion for the ?other language? use.  
Poplack and Dion (2012) are of the view that there 
does not exist a continuum between CM, Nonce-
borrowing and loanwords. In their diachronic 
study on En-French CM, the authors show that the 
frequency of all three categories remain stable. 
According to them, a user is always aware 
whether they are using an ?other language? word 
as a CM (for socio-linguistic purposes) or as a so-
cio-linguistically unmarked borrowing. Our data 
does not capture diachronic statistics neither does 
our monolingual corpus is at the scale at which 
language changes occur. However, we interpret 
our results to indicate that there is indeed a fuzzy 
boundary between CM and borrowing. Neverthe-
less, this distinction may not be readily observable 
through word classification or even diffusion 
and/or other structural linguistic features. The no-
tion of ?social acceptance? of a particular word in 
that language community may play a big role. 
Further, the perception of a word as either CM, 
or borrowing could depend on a large number of 
meta- and extra-linguistic factors that may include 
including the fluency of the user in English, famil-
iarity with the word, and the pragmatic/dis-
course/socio-linguistics reasons for using them. 
Thus, for a true bilingual, fluent in both lan-
guages, an adverb like ?easily? might be more sta-
ble and almost a borrowing, but for someone with 
less familiarity with English, it might be a mixing.  
Similarly, whether or not a person is consciously 
using the English word to make a point can matter. 
A frequent example of this in our data is the use 
of swear words and expletives which are often ac-
companied by a switch in language. These words 
thus are difficult to disambiguate without more in-
formation and data, and an analysis that takes into 
account the non-structural linguistic motivations.  
5 Conclusion 
In this paper, we present an analysis of data from 
Facebook generated by En-Hin bilingual users. 
Our analysis shows that a significant amount of 
this data shows Code Mixing in the form of En in 
Hindi matrix as well as Hin in English matrix. 
While the embedding of Hindi words in English 
mostly follows formulaic patterns of Nouns and 
Particles, the mixing of English in Hindi is clearly 
happening at different levels, and is of different 
types. This can range from single words to multi-
word phrases ranging from frozen expressions to 
clauses. Considering monolingual corpus fre-
quency counts clearly shows that the words them-
selves fall into three categories of clear CM, clear 
Borrowings and Ambiguous where the distinction 
becomes fuzzy. The problem is amplified because 
in transliterated text, even the borrowings are 
mostly in English spellings and sometimes Hindi 
spellings (goal vs gol), and will be identified as 
English words. From an NLP perspective, all 
these have to be handled differently. Some are 
easier to handle (?party? would be in a Hindi lex-
icon, for example, and NEs) and some are more 
difficult for example where Adverbials or clauses 
are involved. 
The insights from this analysis indicate that any 
future work on CM in social media content would 
have to involve a deeper analysis at the intersec-
tion of structural and discourse linguistics. We 
plan to continue our work in this area in the future 
with focus on larger data sets, richer annotations 
which take into account not only structural lin-
guistics annotation but also discourse and prag-
matic level annotations. We believe that an under-
standing of the interaction between morpho-syn-
tax and discourse, and a deeper look at sociolin-
guistic context of the interaction in the future will 
help us to better define and understand this phe-
nomenon and hence, implement suitable NLP 
techniques for processing such data. 
 
 
 
124
Appendix A 
List of English words embedded in Hindi matrix 
found in our data, classified into three classes for 
? = 1 and ? = 1000. 
Code-mixed words: health, public, army, India, 
affection, divine, pm, drama, clean, anti, 
young, follower, page, like, request, easily, In-
dian, uncle, comment, reply, sun, bomb, means, 
game, month, spokesperson, actor, I, word, ad-
mit, good, afternoon, time, look, please, help, 
husband, artists, very, sad, but, higher, plan-
ning, mad, keep, failure, well, strike, sorry, 
girlfriend, those, who, support, opposition, 
and, profile, right, good, men, driving, lady, 
leader, singer, shift, culture, only, with, befit-
ting, reply 
Ambiguous words: blast, daily, love, sir, bloody, 
cheapo, chit, hello, it, football, style, pant, hi, 
commonwealth, participation, certificates, ed-
ucation, robot, Bollywood, player, big, bee, the, 
agency, women, line, trolling, ODI, tiger, com-
edy 
Borrowings: CBI, goal, rally, match, police, film, 
cricket, appeal, Italian, fan, best, vote, party, 
power, minister, team, you, photo, star 
Reference 
Beatrice Alex. 2008.  Automatic Detection of Eng-
lish Inclusions in Mixed-lingual Data with an 
Application to Parsing, Doctor of Philosophy 
Thesis, School of Informatics, University of 
Edinburgh, Edinburgh, UK. 
Celso Alvarez-C?ccamo. 2011. "Rethinking con-
versational code-switching: codes, speech vari-
eties, and contextualization." Proceedings of 
the Annual Meeting of the Berkeley Linguistics 
Society. Vol. 16. 
Peter Auer. 1984. The Pragmatics of Code-
Switching: A Sequential Approach. Cambridge 
University Press. 
Abdelali Bentahila and Eirlys E. Davies. 1991. 
"Constraints on code-switching: A look beyond 
grammar. Papers for the symposium on code-
switching in blingual studies: Theory, signifi-
cance and perspectives. Strasbourg: European 
Science Foundation.  
MS Cardenas-Claros and N Isharyanti. 2009. 
Code-switching and code-mixing in internet 
chatting: Between yes, ya, and si- a case study. 
In The JALT CALL Journal, 5 
David Crystal. 2001. Language and the Internet. 
Cambridge University Press. 
B. Danet and S. Herring. 2007. The Multilingual 
Internet: Language, Culture, and Communica-
tion Online. Oxford University Press, New 
York. 
Frederic Field. 2002. Linguistic borrowing in bi-
lingual contexts. Amsterdam: Benjamins. 
Penelope Gardner-Chloros. 2009. Code-Switch-
ing. Cambrudge University Press 
J. Gumperz. 1964. Hindi-Punjabi code-switching 
in Delhi. In Proceedings of the Ninth Interna-
tional Congress of Linguistics, Mouton: The 
Hague. 
J. Gumperz. 1982. Discourse Strategies. Oxford 
University Press. 
S. Herring. 2003. Media and Language Change: 
Special Issue. 
Jeff MacSwan. 2012." Code-Switching and 
Grammatical Theory." In The Handbook of Bi-
lingualism and Multilingualism (2012). 323. 
Carol Myers-Scotton. 1993. Duelling Languages: 
Grammatical Structure in Code-switching. 
Claredon. Oxford. 
Carol Myers-Scotton. 2002. Contact linguistics: 
Bilingual encounters and grammatical out-
comes. Oxford University Press. 
Pieter Muysken. 2000. Bilingual speech: A typol-
ogy of code-mixing. Cambridge University 
Press. 
John C. Paolillo. 2011. ?Conversational? 
codeswitching on Usenet and Internet Relay 
Chat. In Language@Internet, 8, article 3. 
Slav Petrov, Dipanjan Das, and Ryan McDonald. 
2011. A universal part-of-speech tagset. arXiv 
preprint arXiv:1104.2086  
Shana Poplack, D. Sankoff, and C. Miller. 1988. 
The social correlates and linguistic processes of 
lexical borrowing and assimilation. Linguistics 
26:47-104. 
Shana Poplack and Nathalie Dion. 2012. "Myths 
and facts about loanword development." in 
Language Variation and Change 24, 3. 
David Sankoff, Shana Poplack, and Swathi 
Vanniarajan. 1990. The case of the nonce loan 
in Tamil. Language Variation and Change, 2 
(1990), 71-101. Cambridge University Press. 
125
V.B. Sowmya, M. Choudhury, K. Bali, T. Das-
gupta, and A. Basu. 2010. Resource creation for 
training and transliteration systems for Indian 
languages. In Proceedings of Language Re-
source and Evaluations Conference (LREC 
2010). 
Sarah G. Thomason. 2003. Contact as a Source of 
Language Change. In R.D. Janda & B. D. Jo-
seph (eds), A handbook of historical linguistics, 
Oxford: Blackwell. 
Paola Virga and Sanjeev Khudanpur. 2003. 
Transliteration of proper names in cross-lingual 
information retrieval. Proceedings of the ACL 
2003 workshop on Multilingual and mixed-lan-
guage named entity recognition-Volume 15. 
Association for Computational Linguistics. 
Donald Winford. 2003. An Introduction to Con-
tact Linguistics. Malden, MA: Blackwell. 
 
 
 
 
 
 
126
