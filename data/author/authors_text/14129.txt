Proceedings of the ACL 2010 Student Research Workshop, pages 1?6,
Uppsala, Sweden, 13 July 2010.
c
?2010 Association for Computational Linguistics
Non-Cooperation in Dialogue
Brian Pl?uss
Centre for Research in Computing
The Open University
Milton Keynes, UK
b.pluss@open.ac.uk
Abstract
This paper presents ongoing research on
computational models for non-cooperative
dialogue. We start by analysing differ-
ent levels of cooperation in conversation.
Then, inspired by findings from an em-
pirical study, we propose a technique for
measuring non-cooperation in political in-
terviews. Finally, we describe a research
programme towards obtaining a suitable
model and discuss previous accounts for
conflictive dialogue, identifying the differ-
ences with our work.
1 Introduction
Most approaches to modeling conversation are
based on a strong notion of cooperation be-
tween the dialogue participants (DPs). Traditional
models using intentions (Cohen and Levesque,
1991), dialogue games (Power, 1979), shared
plans (Grosz and Sidner, 1990) or collaborative
problem-solving (Blaylock and Allen, 2005) ex-
plain dialogue situations in which DPs recognise
each other?s intentions and, at least to a certain ex-
tent, accept each other?s goals when deciding on
their actions. These assumptions are theoretically
grounded, as most work in linguistics has consid-
ered situations in which DPs share a common goal
and cooperate to achieve it by means of conver-
sation (Grice, 1975; Clark and Schaefer, 1989).
They are also practically sound: dialogue models
are usually implemented in the form of dialogue
systems, built for the purpose of providing a ser-
vice to their users (e.g., TRAINS (Allen and Schu-
bert, 1991)). In this scenario, failure to cooperate,
either on the side of the system or of the user, is
against the premises on which the system is con-
ceived and used.
In everyday conversation, however, a great
many situations escape the arguments above. Con-
sider the following example
1
:
(1) PAXMAN [1]: (interrupting) Did you threaten to over-
rule him?
HOWARD [2]: I, I, was not entitled to instruct Derek
Lewis, and I did not instruct him.
PAXMAN [3]: Did you threaten to overrule him?
HOWARD [4]: The truth of the matter is that Mr. Mar-
riott was not suspended. I. . .
PAXMAN [5]: (overlappling) Did you threaten to
overrule him?
HOWARD [6]: . . . did not overrule Derek Lewis.
PAXMAN [7]: Did you threaten to overrule him?
HOWARD [8]: I took advice on what I could or could
not do. . .
PAXMAN [9]: (overlappling) Did you threaten to
overrule him, Mr. Howard?
HOWARD[10]: . . . and I acted scrupulously in accor-
dance with that advice, I did not over-
rule Derek Lewis. . .
PAXMAN [11]: (overlapping) Did you threaten to over-
rule him?
HOWARD[12]: . . . Mr. Marriott was not suspended.
PAXMAN [13]: Did you threaten to overrule him?
HOWARD[14]: (pauses) I have accounted for my deci-
sion to dismiss Derek Lewis. . .
PAXMAN [15]: (overlapping) Did you threaten to over-
rule him?
HOWARD[16]: . . . in great detail, before the House of
Commons.
PAXMAN [17]: I note that you?re not answering the
question of whether you threatened to
overrule him.
(Newsnight, BBC, 1997)
We take it for granted that, at some level, Pax-
man and Howard are sharing a goal, for otherwise
they would not be having an interview. Still, the
exchange is clearly conflictive, to the point that
their behaviour compromises the flow of the con-
versation.
Heritage (1998) analyses the distinctive roles of
DPs in news interviews:
1
BBC presenter Jeremy Paxman questions former UK
Home Secretary Michael Howard with respect to a meeting
in 1995 between Howard and the head of the Prison Service,
Derek Lewis, about the dismissal of the governor of Parkhurst
Prison, John Marriott, due to repeated security failures. The
case was given considerable attention in the media, as a result
of accusations by Lewis that Howard had instructed him, thus
exceeding the powers of his office.
1
?the participants -IRs [=interviewers] and IEs
[=interviewees]- exclude themselves from a wide
variety of actions that they are normally free to
do in the give and take of ordinary conversa-
tion. If IRs restrict themselves to asking ques-
tions, then they cannot - at least overtly - express
opinions, or argue with, debate or criticize the in-
terviewees? positions nor, conversely, agree with,
support or defend them. Correspondingly, if IEs
restrict themselves to answers (or responses) to
questions, then they cannot ask questions (of IRs
or other IEs), nor make unsolicited comments on
previous remarks, initiate changes of topic, or di-
vert the discussion into criticisms of the IR or the
broadcasting organization.?
(Heritage, 1998, p.8)
Now, consider the fragment below
2
:
(2) PAXMAN [1]: Can you clear up whether or not you
did threaten to overrule Derek Lewis
when you were Home Secretary?
HOWARD[2]: Oh, come on, Jeremy, you are really
going to go back over that again? As...
PAXMAN [3]: (overlapping) You?ve had seven years
to think about it!
HOWARD[4]: (overlapping). . . as, as it happens, I
didn?t. Are you satisfied now?
PAXMAN [5]: Thank you. Why didn?t you say that at
the time?
HOWARD[6]: I, well, we?ve been over this many,
many times. I, I, I knew that everyone
was crawling over every syllable I said
about that, and I wanted to check very
carefully what I said before answering
your question.
(Newsnight, BBC, 2004)
On this occasion, Howard provides an answer
almost immediately and the flow of the conver-
sation contrasts noticeably with that in (1). The
investigation reported in this article aims at shed-
ding light on the nature of non-cooperation in dia-
logue, by capturing the intuitions that allow us to
differentiate between both conversations in terms
of participant behaviour.
Dialogue games supporters could say that there
is a game that describes the interaction in the first
example. While this might be true, such an ap-
proach would force us, in the limit, to define one
game for each possible conversation that would
not fit a certain standard. Walton and Krabbe
(1995) attempt a game-based approach in their
study of natural argumentation. They claim that
a rigorous model of conversational interaction is
useful, but accept that most of the huge variety of
everyday conversation escapes it. Dialogue games
are based on strict rules that capture typical dia-
logue situations while leaving out considerable de-
tail. As example (1) shows, DPs behaviour can
2
This exchange took place seven years after (1), when
public awareness of the 1995 affair had dissipated.
divert from the typical case in unexpected ways,
falling outside the characterisation
3
.
Nevertheless, the rules and patterns captured by
game models are useful, as they describe the ex-
pected behaviour of the DPs under a certain con-
versational scenario. In our research, we aim at
reconciling two worlds, using the insights from di-
alogue games to provide a description of expected
behaviour in the form of social obligations, but
looking at naturally occurring cases that deviate
from the norm. This, in turn, calls for a technique
to measure non-cooperation in dialogue and in this
paper we provide one that is theoretically sound
and supported by empirical evidence.
The following section discusses levels of co-
operation in dialogue; Section 3 presents an em-
pirical study and a practical measure of non-
cooperation in political interviews; in Section 4 we
discuss related work, our working hypothesis and
a methodology; and Section 5 has the conclusions.
2 Linguistic and Non-Linguistic
Cooperation
Cooperation in dialogue can happen at different
levels. In most cases, conversation supports a so-
cial activity that constrains the behaviour accept-
able or expected from the participants. In addi-
tion, conversational behaviour determines how co-
operatively participants engage in a social activity.
However, cooperation at the conversational level
does not necessarily translate to the social level.
Consider, for instance, a witness under interroga-
tion in a U.S. trial refusing to answer a question by
appealing to the Fifth Amendment of the Constitu-
tion
4
. Such behaviour will be accepted in the con-
versational setting as established by law, although
it is not cooperative in relation with the goals of
the trial. Non-cooperation at the conversational
level, on the other hand, usually results in lack of
cooperation at the social level. Take as an exam-
ple, the same witness remaining silent, rather than
answering or appealing to the Fifth Amendment.
To illustrate further, consider a fictional alter-
native to (1), where Howard replies by saying ?I
will not answer that question, as it is not relevant
to whether I exceeded the powers of my office?.
3
Consider, for instance, Giznburg?s QUD model
(Ginzburg, 1996) when applied to dialogue (1), in which
Howard repeatedly fails to either accept or reject Paxman?s
question.
4
?No person shall (. . . ) be compelled in any criminal case
to be a witness against himself ?.
2
This is not cooperative for the interview, but it is
so at the linguistic level. It would help in preserv-
ing the flow of the conversation, e.g., by triggering
a sub-dialogue to solve the disagreement.
The distinction between linguistic and non-
linguistic (also called task-related, high-level or
social) cooperation has been addressed before. At-
tardo (1997) revisits Gricean pragmatics, relat-
ing non-linguistic cooperation to participants? be-
haviour towards realising task-related goals, and
linguistic cooperation to assumptions on their re-
spective behaviour in order to encode and decode
intended meaning. From a computational perspec-
tive, Bunt (1994) relies on a similar distinction for
defining dialogue acts. Also, Traum and Allen
(1994) introduce discourse obligations as an alter-
native to joint intentions and shared plans, to al-
low for models of dialogues in which participants
do not share the same high-level goals and where
behaviour is also determined by ?a sense of obli-
gation to behave within limits set by the society?
(Traum and Allen, 1994, p.2).
Walton and Krabbe (1995) proposed a typology
of dialogue based on the initial situation trigger-
ing the exchange and participants? shared aims and
individual goals. Based on their work, Reed and
Long (1997) distinguish cases where participants
follow a common set of dialogue rules and stay
within a mutually acknowledged framework from
a stronger notion in which their individual goals
are in the same direction. Borrowing from the lat-
ter, in the rest of the paper, we will speak of collab-
oration when DPs share the same task-level goals,
and use cooperation when participants follow the
conversational obligations imposed by the social
activity (i.e., linguistic cooperation as discussed
above). We will not deal with collaboration here,
though, as our focus is on non-cooperation.
3 An Empirical Study
In this section, we describe an empirical pilot
study aimed at identifying a set of features that
distinguish cooperative from non-cooperative con-
versational behaviour and at establishing a suitable
domain in which to focus our work.
3.1 The Corpus
We collected the transcripts of 10 adversarial di-
alogues: 4 political interviews, 2 entertainment
interviews, 1 parliamentary inquiry, 1 courtroom
confrontation, 1 courtroom interrogation and 1
dispute. The corpus includes 2 collaborative polit-
ical interviews for result comparison and is nearly
14,500 words long
5
.
In a first analysis, we identified those surface
features that characterised each conversation as
conflictive: e.g., interruptions, short turns, unfin-
ished adjacency pairs, verbatim repetition. Next,
looking for a better understanding, we preformed
an in-depth case study of one of the examples, ap-
proaching the analysis from different angles.
By studying, e.g., the observance of turn-taking
rules, the implicatures of the participants and,
more extensively, how the case fitted within the
normative framework proposed by Walton and
Krabbe (1995), we were able to better identify the
nature of non-cooperative features present in the
dialogue and establish a formalisable framework
for approaching non-cooperative dialogue.
As for the domain, the wealth of interesting con-
versational situations that arise in political inter-
views make a suitable context for this research. In
the English-speaking world, journalists are well-
known for their incisive approach to public ser-
vants. At the same time, politicians are usually
well trained to deliver a set of key messages when
speaking in public, and to avoid issues unfavorable
to their image. We will only consider naturally oc-
curring (i.e. non-scripted) two-party interviews.
3.2 Degrees of Non-Cooperation
Based on the analysis described above, we pro-
pose a technique for measuring non-cooperation in
political interviews using a set of non-cooperative
features (NCFs). The number of occurrences of
these features will determine the degree of non-
cooperation (DNC) of an exchange.
We grouped NCFs following three aspects of
conversation: turn-taking, grounding and speech
acts (see Table 1 for a complete list).
Turn-taking rules (Sacks et al, 1974) estab-
lish that speakers make their contributions at ad-
equate places and in particular ways. Interlocu-
tors in a political interview are expected to respect
transition-relevance places, openings and closings
according to social conventions. Failing to do so
(e.g., by interrupting each other) constitutes a non-
cooperative feature.
Grounding (Clark and Schaefer, 1989) refers
to participants? acknowledgement of each other?s
5
These resources are available at http://www.open.
ac.uk/blogs/brianpluss/pilot-study/.
3
Turn-
Taking
For both speakers:
? interrupting
? overlapping
? ending the exchange abruptly
Grounding Interviewer fails to either:
? ask next relevant question
? move to next topical issue
? state irrelevance of answer
Interviewee fails to either:
? give relevant answer
? reject question
Speech
Acts
Interviewer either:
? expresses personal opinion
? argues, debates with or criticises
interviewee?s position subjectively
? agrees with, supports or defends
interviewee?s position subjectively
Interviewee either:
? asks (non-CR) question
? makes irrelevant comment
? initiates change of topic
? criticises interviewer
Table 1: NCFs for political interviews
contributions by providing evidence of under-
standing (e.g, continued attention, relevant next
contribution). In political interviews a question is
acknowledged by rejecting it or by providing a di-
rect answer. Likewise, answers are acknowledged
by rejecting their relevance, by asking a next rel-
evant question or by moving on to a new topical
issue. Failing to provide sufficient evidence of un-
derstanding is also a non-cooperative feature.
Speech Act theory (Searle, 1979) classifies ut-
terances according to their associated force and
propositional content. Going back to Heritage?s
comment, in a political interview participants can
fail to restrict their speech acts to the force and
content expected for their role. Non-cooperative
features related to speech acts include the inter-
viewer expressing a personal opinion or criticising
subjectively the interviewee?s positions and the in-
terviewee asking questions (except for clarifica-
tion requests) or making irrelevant comments.
We define the degree of non-cooperation (DNC)
of a dialogue as the proportion of utterances with
one of more occurrences of these non-cooperative
features
6
. Furthermore, the DNC could be thus
computed for the whole conversation and also for
each participant, by counting only occurrences of
features and utterances from each DP.
As an example, consider an extended fragment
6
At this stage, all NCFs are weighted equally. This is
a simplifying assumption we will remove in the future so
that, e.g., an interviewee attempting a change of topic has
a stronger impact on the DNC than, say, one interrupting.
of (1) annotated with non-cooperative features (O:
overlap; GF: grounding failure; UC: unsolicited
comment; I: interruption; TC: topic change):
(3) P [11] : Uir.1 (overlapping) Did you threaten to
overrule him?
O
H[12] : Uie.1 . . . Mr. Marriot was not suspended. GF
P [13] : Uir.2 Did you threaten to overrule him? GF
H[14] : Uie.2 (pauses) I have accounted for my de-
cision to dismiss Derek Lewis. . .
P [15] : Uir.3 (overlapping) Did you threaten to
overrule him?
O
H[16] : Uie.2 . . . in great detail before the House of
Commons.
UC
P [17] : Uir.4 I note that you?re not answering the
question whether you threatened to
overrule him.
H[18] : Uie.3 Well, the important aspect of this
which it?s very clear to bear in
mind. . .
GF
P [19] : Uir.5 (interrupting) I?m sorry, I?m going to
be frightfully rude but. . .
I
H[20] : Uie.4 Yes, you can. . .
P [21] : Uir.6 (overlapping) I?m sorry. . . O
H[22] : Uie.4 (overlapping) . . . you can put the
question and I will give you, I will
give you an answer.
O
P [23] : Uir.7 . . . it?s a straight yes-or-no question
and a straight yes-or-no answer:
Uir.8 did you threaten to overrule him?
H[24] : Uie.5 I discussed the matter with Derek
Lewis.
Uie.6 I gave him the benefit of my opinion.
Uie.7 I gave him the benefit of my opin-
ion in strong language, but I did not
instruct him because I was not, er,
entitled to instruct him.
UC
Uie.8 I was entitled to express my opinion
and that is what I did.
UC
P [25] : Uir.9 With respect, that is not answering
the question of whether you threat-
ened to overrule him.
H[26] : Uie.9 It?s dealing with the relevant point
which was what I was entitled to do
and what I was not entitled to do,
TC
Uie.10 and I have dealt with this in detail
before the House of Commons and
before the select committee.
UC
Table 2 summarises non-cooperative features,
utterances and the degree of non-cooperation for
each participant and for the whole fragment.
P (ir) H (ie) Fragment
Interruptions 1 0 1
Overlaps 3 1 4
Grounding Failure 1 2 3
Unsolicited Comments 0 4 4
Topic Change 0 1 1
Total NCFs 5 8 13
Utterances 9 10 19
DNC 0.56 0.80 0.68
Table 2: Computing the DNC for dialogue (3)
The DNC was computed for all the political in-
terviews in the corpus. Table 3 shows the val-
4
Table 3: DNC of political interviews in the corpus
ues obtained. Adversarial interviews have a large
number of NCFs, thus a high value for the DNC.
On the other hand, collaborative exchanges have
low occurrence of NCFs (or none at all)
7
.
4 Discussion
There have been previous approaches to modeling
dialogue on the basis that participants are not al-
ways fully cooperative. Jameson (1989) presents
an extensive study for modeling bias, individual
goals, projected image and belief ascription in
conversation. User-model approaches are flexi-
ble to account for intricate situations but, as noted
by Taylor et al (1996), can lead to problems like
infinite regress in nested beliefs. Taylor (1994)
addressed non-cooperative dialogue behaviour by
implementing CYNIC, a dialogue system able to
generate and recognise deception; a notion of non-
cooperation weaker than the one we address.
More recently, Traum (2008) brought attention
to the need for computational accounts of dia-
logue situations in which a broader notion of co-
operation is not assumed: e.g., intelligent tutoring
systems, bargaining agents, role-playing training
7
These results and the validity of DNC measure need fur-
ther evaluation. We are currently performing two studies: one
to determine inter-annotator agreement of the coding scheme
for NCFs, and another to test how NCFs correlate to human
judgements of non-cooperative conversational behaviour.
agents
8
. Traum?s work on conflictive dialogue is
mainly aimed at creating virtual humans with abil-
ities to engage in adversarial dialogue. Traum et
al. (2008) present a model of conversation strate-
gies for negotiation, that includes variables repre-
senting trust, politeness and emotions, and a set of
conversational strategies. Despite being adversar-
ial in nature, the conversational scenarios are mod-
eled by means of rules, that are followed by the
interlocutors, according to the values of some of
the variables. Hence, the dialogues are adversar-
ial, but cooperative under our characterisation of
linguistic non-cooperation, and it is not clear how
effectively the model accounts for cases in which
participants fail to follow the rules of a scenario.
4.1 Working Hypothesis
Finding a suitable model of non-cooperative dia-
logue involves bridging the gap between the the-
oretical aspects mentioned so far and the evi-
dence in the empirical data of the previous section.
Following Traum and Allen (1994), we base on
the hypothesis that non-cooperative features result
from decisions that participants make during the
conversation, by considering the obligations im-
posed by the social activity and their individual
goals, with an adequate configuration of the pri-
orities for goals and obligations.
Thus, a participant with high priorities for in-
dividual goals might compromise the workings of
a conversation by choosing contributions that go
against the norms of the social activity. On the
other hand, participants with higher priorities as-
sociated with obligations will favour contributions
consistent with the rules of the social activity.
4.2 Research Methodology
For the next steps of the project, we will construct
a model based on the hypothesis and test it by
means of simulation
9
.
The construction of the model is a formaliza-
tion of the working hypothesis, including rules for
political interviews, goals, obligations, priorities
and a dialogue management component. At the
8
Traum also provides a list of ?behaviours of interest?,
along the lines of the NCFs we identified above: e.g., uni-
lateral topic shifts or topic maintenance, unhelpful criticism,
withholding of information, lying, deception, antagonism.
9
The use of simulation in dialogue modeling was pio-
neered by Power (1979). It suits our project better than al-
ternatives (e.g., Wizard-of-Oz, dialogue systems), by making
it easier to introduce modifications, do re-runs, and generate
a large number of cases with different parameter settings.
5
moment of writing, we are investigating the line
of research on obligation-driven dialogue model-
ing, initiated by Traum and Allen (1994) and de-
veloped further by Poesio and Traum (1998) and
Kreutel and Matheson (2003).
For the simulation, DPs will be autonomous
conversational agents with a cognitive state con-
sisting of goals, a notion of their expected be-
haviour in a political interview, priorities, and
some knowledge of the world. We are currently
implementing a prototype based on EDIS (Mathe-
son et al, 2000).
5 Conclusions
In this paper we presented an attempt to shed light
on non-cooperation in dialogue by proposing a
practical measure of the degree of linguistic non-
cooperation in political interviews and a method-
ology towards a suitable computational model.
Acknowledgments
We would like to thank the NLG group at The
Open University (especially Paul Piwek, Richard
Power and Sandra Williams) for helpful dis-
cussion and comments on previous versions of
this paper; and three anonymous reviewers for
thoughtful feedback and suggestions.
References
J.F. Allen and L.K. Schubert. 1991. The TRAINS
project. TRAINS Technical Note 91-1. Computer
Science Dept. University of Rochester.
S. Attardo. 1997. Locutionary and perlocutionary co-
operation: The perlocutionary cooperative principle.
Journal of Pragmatics, 27(6):753?779.
N. Blaylock and J. Allen. 2005. A collaborative
problem-solving model of dialogue. In Proceedings
of the 6th SIGdial Workshop on Discourse and Dia-
logue, pages 200?211, Lisbon, Portugal.
Harry Bunt. 1994. Context and dialogue control.
THINK Quarterly, 3.
H.H. Clark and E.F. Schaefer. 1989. Contributing to
discourse. Cognitive science, 13(2):259?294.
P.R. Cohen and H.J. Levesque. 1991. Confirmations
and joint action. In Proceedings of the 12 th Inter-
national Joint Conference on Artificial Intelligence,
pages 951?957.
J. Ginzburg. 1996. Interrogatives: Questions, facts and
dialogue. The handbook of contemporary semantic
theory, 5:359?423.
H. P. Grice. 1975. Logic and conversation. Syntax and
Semantics, 3:41?58.
B.J. Grosz and C.L. Sidner. 1990. Plans for discourse.
Intentions in communication, pages 417?444.
J. Heritage. 1998. Conversation analysis and insti-
tutional talk. Analyzing distinctive turn-taking sys-
tems. In Proceedings of the 6th International
Congress of IADA, Tubingen, Niemeyer.
A. Jameson. 1989. But what will the listener think?
Belief ascription and image maintenance in dialog.
User Models in Dialog Systems. Springer-Verlag,
pages 255?312.
J. Kreutel and C. Matheson. 2003. Incremental in-
formation state updates in an obligation-driven dia-
logue model. Logic Journal of IGPL, 11(4):485.
C. Matheson, M. Poesio, and D. Traum. 2000. Mod-
elling grounding and discourse obligations using up-
date rules. In Proceedings of the 1st NAACL confer-
ence, pages 1?8, San Francisco, CA, USA.
M. Poesio and D. Traum. 1998. Towards an ax-
iomatization of dialogue acts. In Proceedings of
the Twente Workshop on the Formal Semantics and
Pragmatics of Dialogues, pages 207?222.
R. Power. 1979. The organisation of purposeful dia-
logues. Linguistics, 17:107?152.
C. Reed and D. Long. 1997. Collaboration, cooper-
ation and dialogue classification. Working Notes of
the IJCAI97 Workshop on Collaboration, Cooper-
ation and Conflict in Dialogue Systems, IJCAI 97,
pages 73?78.
H. Sacks, E.A. Schegloff, and G. Jefferson. 1974. A
simplest systematics for the organization of turn-
taking for conversation. Language, pages 696?735.
J.R. Searle. 1979. A Taxonomy of lllocutionary Acts.
Expression and meaning: studies in the theory of
speech acts, pages 1?29.
J. A. Taylor, J. Carletta, and C. Mellish. 1996. Re-
quirements for belief models in cooperative dia-
logue. User Modeling and User-Adapted Interac-
tion, 6(1):23?68.
J.A. Taylor. 1994. A multi-agent planner for mod-
elling dialogue. Ph.D. Thesis, School of Cognitive
and Computing Sciences, University of Sussex.
D.R. Traum and J.F. Allen. 1994. Discourse obli-
gations in dialogue processing. In Proceedings of
the 32nd annual meeting of ACL, pages 1?8. Mor-
ristown, NJ, USA.
D. Traum, W. Swartout, J. Gratch, and S. Marsella.
2008. A virtual human dialogue model for non-team
interaction. Recent Trends in Discourse and Dia-
logue. Springer.
D. Traum. 2008. Extended Abstract: Computational
Models of Non-cooperative dialogue. In Proceed-
ings of LONDIAL 2008, the 12th Workshop on the
Semantics and Pragmatics of Dialogue, pages 11?
14, London, UK.
D. Walton and E. Krabbe. 1995. Commitment in di-
alogue: Basic concepts of interpersonal reasoning.
State University of New York Press.
6
Generating Natural Language Descriptions of Z Test Cases
Maximiliano Cristia?
Flowgate Consulting and CIFASIS
Rosario, Argentina
mcristia@flowgate.net
Brian Plu?ss
Centre for Research in Computing
The Open University
Milton Keynes, UK
b.pluss@open.ac.uk
Abstract
Critical software most often requires an
independent validation and verification
(IVV). IVV is usually performed by do-
main experts, who are not familiar with
specific, many times formal, development
technologies. In addition, model-based
testing (MBT) is a promising testing tech-
nique for the verification of critical soft-
ware. Test cases generated by MBT tools
are logical descriptions. The problem is,
then, to provide natural language (NL) de-
scriptions of these test cases, making them
accessible to domain experts. In this pa-
per, we present ongoing research aimed at
finding a suitable method for generating
NL descriptions from test cases in a for-
mal specification language. A first proto-
type has been developed and applied to a
real-world project in the aerospace sector.
1 Introduction
Model-based testing (MBT) is an active research
area and a promising theory of software and hard-
ware testing (Utting and Legeard, 2006; Hierons
et al, 2009). MBT approaches start with a formal
model or specification of the software, from which
test cases are generated. These techniques have
been developed and applied to models written in
different formal notations, such as Z (Stocks and
Carrington, 1996), finite state machines and their
extensions (Grieskamp et al, 2002), B (Legeard et
al., 2002), algebraic specifications (Bernot et al,
1991), and so on.
The fundamental hypothesis behind MBT is
that, as a program is correct if it verifies its specifi-
cation, then the specification is an excellent source
of test cases. Once test cases are derived from the
model, they are refined to the level of the imple-
mentation language and executed. The resulting
output is then abstracted to the level of the speci-
fication language, and the model is used again to
verify if the test case has detected an error.
The Test Template Framework (TTF) described
by Stocks and Carrington (1996) is a particular
MBT theory specially well suited for unit testing.
The TTF uses Z specifications (Spivey, 1989) as
the entry models and prescribes how to generate
test cases for each operation included in the model.
Fastest (Cristia? and Rodr??guez Monetti, 2009) im-
plements the TTF allowing users to automatically
produce test cases for a given Z specification. Re-
cently, we used Fastest to test an on-board satellite
software for a major aerospace company in South
America. Since Fastest uses models written in the
Z specification language, test cases generated by
this tool are paragraphs of formal text (see Section
2). This description is suitable for the automatic
tasks involved in testing (e.g., automatic execu-
tion, hyperlinking, traceability), but humans need
to be able to read Z specifications in order to un-
derstand what is being tested. In projects where
independent verification and validation (IVV) is
required this might be a problem, as most stake-
holders will not necessarily be fluent in Z.
This is precisely the case in the project men-
tioned above, where the aerospace company re-
quested not only the test cases in Z, but also in
English. As it can be expected, in a project with
hundreds of test cases, manual translation would
increase the overall cost of testing and, most criti-
cally, reduce its quality due to the introduction of
human errors. Interestingly, this problem is op-
posite to those in mainstream industrial practice,
where test cases are described in natural language
and must be formalised, in order to augment the
quality and, hopefully, reduce the costs of testing.
Given the formal, structured nature of the
source text, natural language generation (NLG)
techniques seem to be an appropriate approach
to solving this problem. In the rest of the pa-
per, we give an example of a test case from the
project mentioned above (Section 2), describe a
template-based method for generating NL descrip-
tions (Section 3), and propose further work to-
wards a more general NLG solution (Section 4).
2 An Example from the Aerospace
Industry
The problem of generating NL descriptions of
specifications in Z arises in the following scenario:
a company developing the software for a satellite
needs to verify that the implementation conforms
to a certain aerospace standard (ECSS, 2003) de-
scribing the basic functionality of any satellite
software. We therefore started by modelling in Z
the services described by the standard and used the
Fastest tool to generate test cases.
The model is a ?standard? Z specification: it
has a schema box that defines the state space of
the system and operations defining the transition
relation between states1. Each operation formal-
izes one of the services described by the standard
(e.g., memory dump, telecommand verification,
enabling or disabling on-board monitoring, etc.).
Figure 1 shows one of the test cases generated
for the operation DumpMemoryAbsAdd, that mod-
els a remote request for the on-board software to
dump some portion of its memory. In TTF and
Fastest, a Z test case is essentially a set of bind-
ings between variables and values, and test cases
are grouped according to the operation they test.
Identifiers appearing in a test case are the input
and state variables from the definition of the oper-
ation. These are bound to certain values defining
the state in which the system must be tested and
the input given to the operation in each unique test
case. In the example, input variables are those dec-
orated with a question mark, while state variables
are plain identifiers. All these variables are de-
clared somewhere else in the specification, by us-
ing a special schema box called valid input space,
associated with each operation.
For example, the Z schema in Figure 1 indicates
that the implementation of the dump memory ser-
vice must be tested in a state where the system is
processing a telecommand (processingTC = yes),
the telecommand is a request for a memory dump
(srv = DMMA), the system has one memory block
1The Z specification language is essentially typed first or-
der logic, with syntactic sugar in the form of operators, that
serve as shortcuts for frequently used complex expressions.
DumpMemoryAbsAdd SP 7 TCASE
mid = mid0 ? srv = DMAA ? lengths = ?
processingTC = yes ? adds = ?
blocks = {mid0 7? {1 7? byte0, 2 7? byte1,
3 7? byte2, 4 7? byte3}}
m? = mid0 ? sa? = ?1? ? len? = ?2?
Figure 1: A test case described in Z
which is four bytes long (blocks = {. . .}), there
are no other pending requests (adds = lengths =
?); and the request is for a memory dump of
length two (len? = ?2?) starting at the first ad-
dress (sa? = ?1?) of the available memory block
(m? = mid0 = mid).
Fastest generated almost 200 test cases like the
one depicted in Figure 1 from a model describ-
ing a simplified version of five services listed in
the standard. The customer requested to deliver a
natural language description of each one of them
and a model describing all the services would have
thousands of test cases. Clearly, trying to make
the translation by hand would have been not only
a source of errors, but also a technical retreat.
3 A Template-Based NLG Solution
As a first approach, we used a template-based
method. We started by defining a grammar to
express what we called NL test case templates
(NLTCT). It appears in Figure 22. Each NLTCT
specifies how an NL description is generated for
the Z test cases of a given operation. It starts with
the name of the operation. Next follows a text sec-
tion, intended as a parametrized NL description of
the test case, where calls to translation rules can
be inserted as needed. Finally, all necessary trans-
lation rules are defined, by indicating what is writ-
ten in replacement for a call when a certain vari-
able in the formal description of a test case appears
bound to a specific value. In this way, a different
text is generated for each test case, according to
the binding between values and variables that de-
fines the case. The Appendix shows the NLTCT
for the operation DumpMemoryAbsAdd.
We implemented a parser in awk that takes an
NLTCT and a Z test case, and generates the NL
description of each test case in the input. Figure 3
shows the result for the test case in Figure 1.
This first prototype showed that NLTCTs tend
2Fastest saves formal test cases in text files written in ZLa-
TeX, an extension of the LATEX markup language, what ex-
plains the use of this format in the NLTCT grammar.
NLTCT ::= ?Operation? eol
?NLTCD? eol
?TCRule?{, ?TCRule?}
Operation ::= operation =?identifier?
NLTCD ::= \begin{tcase} eol
?LaTeXText? eol
\end{tcase}
LaTeXText ::= LaTeX | ?TCRuleCall? | ?LaTeXText?
TCRuleCall ::= & rule ?identifier? &
TCRule ::= \begin{trule}{?identifier?} eol
case ?identifier?[, ?identifier?] eol
?RuleDef ? eol {, ?RuleDef ? eol}
endcase eol
\end{trule}
RuleDef ::= $?ZLaTeX?[? | ? ?ZLaTeX? | & ?ZLaTeX?]
: ?LaTeX? eol
LaTeX ::= free LATEX text
ZLaTeX ::= free Z LATEX text
Figure 2: Grammar for NLTC templates
to be relatively small and simple, in spite of the
large number of test cases. This is due to test cases
combining a small set of values in many differ-
ent ways. However, NLTCTs for large operations
tend to become increasingly more complex, for
the number of combinations grows exponentially.
As a consequence, these operations require a large
number of cases within translation rules and some-
times even more translation rules3.
A thorough evaluation of this method is due. Its
suitability must be measured from the perspective
of two kinds of users: (a) the engineers who write
the formal models, generate the formal test cases
and write the NLTCTs; and (b) other stakeholders
(e.g., the customer, auditors, domain experts), who
read the descriptions of the test cases in natural
language. For the engineers, applying the method
should be more efficient, in terms of time and ef-
fort, than writing the descriptions by hand. For the
readers, success will be determined by the read-
ability of the output and, more critically, by its
precision with respect to the specification. At the
moment of writing, we are designing two empiri-
cal studies aimed at obtaining these measures.
4 Future and Related Work
The solution presented above was successful in
generating adequate NL descriptions of the test
3This is because templates are written in terms of the val-
ues bound to variables, and not in terms of the predicates sat-
isfied by those values, which are nonetheless available as part
of the MBT approach.
Test case: DumpMemoryAbsAdd SP 7 TCASE
Service (6,5) will be tested in a situation that verifies that:
? the state is such that:
? the on-board system is currently processing a
telecommand and has not answered it yet.
? the service type of the telecommand is
DMAA.
? the set of sequences of available memory
cells contains only one sequence, associated
to a memory ID, which has four different
bytes.
? the set of starting addresses of the chunks
of memory that have been requested by the
ground is empty.
? the input memory ID to be dumped is the avail-
able memory ID, the input set of start addresses
of the memory regions to be dumped is the uni-
tary sequence composed of 1, the set of numbers of
memory cells to be dumped is the unitary sequence
composed of 2.
Figure 3: NL description of the test in Figure 1
cases in one particular project. However, the lim-
itations mentioned in the previous section show
that this solution would not generalise well to
specifications in other domains. Moreover, it re-
quires defining a new template for each operation;
a task of still considerable size for large systems.
At the same time, Z specifications contain all
the information necessary to produce the tem-
plates for the operations in the system, regardless
of its domain of application. This information is
structured according to the syntax of the formal
language. Additionally, when formally specifying
a system, it is common practice to include associ-
ations between the identifiers in the specification
(new types, operations, state schemata, variables,
constants, etc.) and the elements they refer to in
the application domain (i.e., aerospace software).
These associations are called designations (Jack-
son, 1995), some of which, relevant to the test case
in Figure 1, are shown in Figure 4.
These considerations lead us to believe in the
srv?Service type of the telecommand
DMAA?Dump memory using absolute addresses
processingTC?The on-board system is currently processing
a telecommand and has not answered it yet
m??Memory ID to be dumped
sa??Start addresses of the memory regions to be
dumped
len??The number of memory cells to be dumped
for each start address
Figure 4: Designations for the test in Figure 1
possibility of generating NL descriptions of Z test
cases automatically by using their definitions, the
system specification and the designations of iden-
tifiers. Such a solution would be independent of
the application domain and, more importantly, of
the number of operations in the model.
The linguistic properties of the target document
are relevant in devising an adequate treatment for
the input, but the overall structure of the output re-
mains rigid and its content is determined by the
definition of each test case. The approach would
still be template-based, but in terms of the NLG
architecture of Reiter and Dale (2000), templates
would be defined at the level of the document
structure4, with minimal microplanning and sur-
face strings generated according to the part of the
test case being processed and the designations of
the identifiers5. The next stages of our project will
point in this direction, using techniques from NLG
for automating the definition of the templates pre-
sented in the previous section.
There have been efforts for producing nat-
ural language versions of formal specifications
in the past. Punshon et al (1997) use a case
study to present the REVIEW system (Salek et
al., 1994)6. REVIEW automatically paraphrases
specifications developed with Metaview (Soren-
son et al, 1988), an academic research metasys-
tem that facilitates the construction of CASE envi-
ronments to support software specification tasks.
Coscoy (1997) describes a mechanism based on
program extraction, for generating explanations of
formal proofs in the Calculus of Inductive Con-
structions, implemented in the Coq Proof Assis-
tant (Bertot and Caste?ran, 2004). Lavoie et al
(1997) present MODEX, a tool that generates cus-
tomizable descriptions of the relations between
classes in object-oriented models specified in the
ODL standard (Cattell and Barry, 1997). Bertani
et al (1999) describe a controlled natural language
approach to translating formal specifications writ-
ten in an extension of TRIO (Ghezzi et al, 1990)
by transforming syntactic trees in TRIO into syn-
tactic trees of the controlled language.
The solutions presented in the related work
above are highly dependant on particular aspects
4Somewhat along the lines of what Wilcock (2005) de-
scribes for XML-based NLG.
5This approach is similar to the method proposed by Kit-
tredge and Lavoie (1998) for generating weather forecasts.
6Salek et al (1994) also give a comprehensive survey of
related work for generating NL explanations for particular
specification languages (most of which are now obsolete).
of the source language and do not apply directly
to specifications written in Z. To our knowledge,
no work has been done towards producing NL de-
scriptions of Z specifications. The same holds for
test cases generated using the MBT approach.
5 Conclusion
In this paper we presented a concrete NLG prob-
lem in the area of software development involv-
ing formal methods. We focused the description
on the generation of NL descriptions of test cases,
but nothing prevents us from extending the idea to
entire system specifications.
The development of a general technique for ver-
balising formal specification would fill the com-
munication gap between system designers and
other stakeholders in the development process,
while preserving the advantages associated to the
use of formal methods: precision, lack of ambigu-
ity, formal proof of system properties, etc.
Finally, we hope this paper draws attention from
NLG experts to an area which would benefit sub-
stantially from their expertise.
Acnowledgements
A substantial part of this research was funded by
Flowgate Consulting. We would also like to thank
Richard Power from the NLG group at The Open
University for help in finding financial support,
Eva Banik for helpful comments on earlier ver-
sions of this paper, and three anonymous reviewers
for useful feedback and suggestions.
References
G. Bernot, M.C. Gaudel, and B. Marre. 1991. Soft-
ware testing based on formal specifications: a the-
ory and a tool. Software Engineering Journal (SEJ),
6(6):387?405.
A. Bertani, W. Castelnovo, E. Ciapessoni, and G.
Mauri. 1999. Natural language translations of for-
mal specifications for complex industrial systems.
In AI*IA 1992: Proceedings of the 6th Congress
of the Italian Association for Artificial Intelligence,
pages 185?194, Bologna, Italy.
Y. Bertot and P. Caste?ran. 2004. Interactive Theorem
Proving and Program Development. Coq?Art: The
Calculus of Inductive Constructions. Texts in Theo-
retical Computer Science. Springer-Verlag.
R.G.G. Cattell and D.K. Barry, editors. 1997. The ob-
ject database standard: ODMG 2.0. Morgan Kauf-
mann Publishers Inc., San Francisco, CA.
Y. Coscoy. 1997. A natural language explanation for
formal proofs. In LACL ?96: Selected papers from
the First International Conference on Logical As-
pects of Computational Linguistics, pages 149?167,
London, UK. Springer-Verlag.
M. Cristia? and P. Rodr??guez Monetti. 2009. Imple-
menting and applying the Stocks-Carrington frame-
work for model-based testing. In Karin Breitman
and Ana Cavalcanti, editors, ICFEM, volume 5885
of Lecture Notes in Computer Science, pages 167?
185. Springer-Verlag.
ECSS. 2003. Space Engineering ? Ground Sys-
tems and Operations: Telemetry and Telecommand
Packet Utilization. Technical Report ECSS-E-70-
41A, European Space Agency.
C. Ghezzi, D. Mandrioli, and A. Morzenti. 1990.
TRIO: A logic language for executable specifica-
tions of real-time systems. Journal of Systems and
Software, 12(2):107?123.
W. Grieskamp, Y. Gurevich, W. Schulte, and M.
Veanes. 2002. Generating finite state machines
from abstract state machines. In ISSTA ?02: Pro-
ceedings of the 2002 ACM SIGSOFT International
Symposium on Software Testing and Analysis, pages
112?122, Rome, Italy.
R.M. Hierons, K. Bogdanov, J.P. Bowen, R. Cleave-
land, J. Derrick, et al 2009. Using formal specifi-
cations to support testing. ACM Computing Surveys
(CSUR), 41(2):9.
M. Jackson. 1995. Software requirements & specifi-
cations: a lexicon of practice, principles, and preju-
dices. Addison-Wesley.
R. Kittredge and B. Lavoie. 1998. Meteocogent: A
knowledge-based tool for generating weather fore-
cast texts. In Proceedings of American Meteorolog-
ical Society AI Conference (AMS-98), Phoenix, AZ.
B. Lavoie, O. Rambow, and E. Reiter. 1997. Cus-
tomizable descriptions of object-oriented models. In
Proceedings of the Conference on Applied Natural
Language Processing (ANLP?97, pages 253?256,
Washington, DC.
B. Legeard, F. Peureux, and M. Utting. 2002. A Com-
parison of the BTT and TTF Test-Generation Meth-
ods. In ZB ?02: Proceedings of the 2nd Interna-
tional Conference of B and Z Users on Formal Spec-
ification and Development in Z and B, pages 309?
329, London, UK. Springer-Verlag.
J.M. Punshon, J.P Tremblay, P.G. Sorenson, and P.S.
Findeisen. 1997. From formal specifications to nat-
ural language: A case study. In 12th IEEE Interna-
tional Conference Automated Software Engineering,
pages 309?310.
E. Reiter and Robert Dale. 2000. Building Natural
Language Generation Systems. Cambridge Univer-
sity Press, Cambridge, UK.
A. Salek, P.G. Sorenson, J.P. Tremblay, and J.M. Pun-
shon. 1994. The REVIEW system: From formal
specifications to natural language. In Proceedings of
the First International Conference on Requirements
Engineering, pages 220?229.
P.G. Sorenson, J.P. Tremblay, and A.J. McAllister.
1988. The Metaview system for many specification
environments. IEEE Software, 5(2):30?38.
J.M. Spivey. 1989. The Z Notation: A Reference Man-
ual. Prentice-Hall, Inc.
P. Stocks and D. Carrington. 1996. A Framework for
Specification-Based Testing. IEEE Transactions on
Software Engineering, 22(11):777?793.
M. Utting and B. Legeard. 2006. Practical Model-
Based Testing: A Tools Approach. Morgan Kauf-
mann Publishers Inc., San Francisco, CA.
G. Wilcock. 2005. An Overview of Shallow XML-
based Natural Language Generation. In Proceed-
ings of the 2nd Baltic Conference on Human Lan-
guage Technolgies, pages 67?78, Tallinn, Estonia.
Appendix A. NLTCT for the Example
NLTCT for DumpMemoryAbsAdd (some parts
were replaced by [...] due to space restrictions):
operation = DumpMemoryAbsAdd
\begin{tcase}
\centerline{{\bf Test case: \ltcaseid}}
The service (6,5) will be tested in the
situation that verifies that:
\begin{itemize}
\item the state is such that:
\begin{itemize}
\item the on-board system is &trule PTCr&.
\item the service type of the telecommand
is &trule SRVr&.
[...]
\item the set of starting addresses of the
chunks of memory that have been
requested by the ground is &trule
ADSr&.
\end{itemize}
[...]
\end{itemize}
\end{tcase}
\begin{trule}{PTCr}
case processingTC
$yes :currently processing a telecommand and
has not answered it yet
$no :not currently processing a telecommand
endcase
\end{trule}
\begin{trule}{SRVr}
case srv
$* :*
endcase
\end{trule}
\begin{trule}{ADSr}
case adds
$\emptyset :empty
$\langle 0 \rangle :the unitary sequence
composed of 0
endcase
\end{trule}
[...]
