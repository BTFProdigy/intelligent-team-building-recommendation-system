Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 417?424,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Integrating Syntactic Priming into an Incremental Probabilistic Parser,
with an Application to Psycholinguistic Modeling
Amit Dubey and Frank Keller and Patrick Sturt
Human Communication Research Centre, University of Edinburgh
2 Buccleuch Place, Edinburgh EH8 9LW, UK
{amit.dubey,patrick.sturt,frank.keller}@ed.ac.uk
Abstract
The psycholinguistic literature provides
evidence for syntactic priming, i.e., the
tendency to repeat structures. This pa-
per describes a method for incorporating
priming into an incremental probabilis-
tic parser. Three models are compared,
which involve priming of rules between
sentences, within sentences, and within
coordinate structures. These models sim-
ulate the reading time advantage for par-
allel structures found in human data, and
also yield a small increase in overall pars-
ing accuracy.
1 Introduction
Over the last two decades, the psycholinguistic
literature has provided a wealth of experimental
evidence for syntactic priming, i.e., the tendency
to repeat syntactic structures (e.g., Bock, 1986).
Most work on syntactic priming has been con-
cerned with sentence production; however, recent
studies also demonstrate a preference for struc-
tural repetition in human parsing. This includes
the so-called parallelism effect demonstrated by
Frazier et al (2000): speakers processes coordi-
nated structures more quickly when the second
conjunct repeats the syntactic structure of the first
conjunct.
Two alternative accounts of the parallelism ef-
fect have been proposed. Dubey et al (2005) ar-
gue that the effect is simply an instance of a perva-
sive syntactic priming mechanism in human pars-
ing. They provide evidence from a series of cor-
pus studies which show that parallelism is not lim-
ited to co-ordination, but occurs in a wide range
of syntactic structures, both within and between
sentences, as predicted if a general priming mech-
anism is assumed. (They also show this effect is
stronger in coordinate structures, which could ex-
plain Frazier et al?s (2000) results.)
Frazier and Clifton (2001) propose an alterna-
tive account of the parallelism effect in terms of a
copying mechanism. Unlike priming, this mecha-
nism is highly specialized and only applies to co-
ordinate structures: if the second conjunct is en-
countered, then instead of building new structure,
the language processor simply copies the structure
of the first conjunct; this explains why a speed-
up is observed if the two conjuncts are parallel. If
the copying account is correct, then we would ex-
pect parallelism effects to be restricted to coordi-
nate structures and not to apply in other contexts.
This paper presents a parsing model which im-
plements both the priming mechanism and the
copying mechanism, making it possible to com-
pare their predictions on human reading time data.
Our model also simulates other important aspects
of human parsing: (i) it is broad-coverage, i.e.,
it yields accurate parses for unrestricted input,
and (ii) it processes sentences incrementally, i.e.,
on a word-by-word basis. This general modeling
framework builds on probabilistic accounts of hu-
man parsing as proposed by Jurafsky (1996) and
Crocker and Brants (2000).
A priming-based parser is also interesting from
an engineering point of view. To avoid sparse
data problems, probabilistic parsing models make
strong independence assumptions; in particular,
they generally assume that sentences are indepen-
dent of each other, in spite of corpus evidence for
structural repetition between sentences. We there-
fore expect a parsing model that includes struc-
tural repetition to provide a better fit with real cor-
pus data, resulting in better parsing performance.
A simple and principled approach to handling
structure re-use would be to use adaptation prob-
abilities for probabilistic grammar rules (Church,
2000), analogous to cache probabilities used in
caching language models (Kuhn and de Mori,
1990). This is the approach we will pursue in this
paper.
Dubey et al (2005) present a corpus study that
demonstrates the existence of parallelism in cor-
pus data. This is an important precondition for un-
derstanding the parallelism effect; however, they
417
do not develop a parsing model that accounts for
the effect, which means they are unable to evaluate
their claims against experimental data. The present
paper overcomes this limitation. In Section 2, we
present a formalization of the priming and copy-
ing models of parallelism and integrate them into
an incremental probabilistic parser. In Section 3,
we evaluate this parser against reading time data
taken from Frazier et al?s (2000) parallelism ex-
periments. In Section 4, we test the engineering
aspects of our model by demonstrating that a small
increase in parsing accuracy can be obtained with
a parallelism-based model. Section 5 provides an
analysis of the performance of our model, focus-
ing on the role of the distance between prime and
target.
2 Priming Models
We propose three models designed to capture the
different theories of structural repetition discussed
above. To keep our model as simple as possi-
ble, each formulation is based on an unlexicalized
probabilistic context free grammar (PCFG). In this
section, we introduce the models and discuss the
novel techniques used to model structural similar-
ity. We also discuss the design of the probabilistic
parser used to evaluate the models.
2.1 Baseline Model
The unmodified PCFG model serves as the Base-
line. A PCFG assigns trees probabilities by treat-
ing each rule expansion as conditionally indepen-
dent given the parent node. The probability of a
rule LHS ? RHS is estimated as:
P(RHS|LHS) = c(LHS ? RHS)
c(LHS)
2.2 Copy Model
The first model we introduce is a probabilistic
variant of Frazier and Clifton?s (2001) copying
mechanism: it models parallelism in coordination
and nothing else. This is achieved by assuming
that the default operation upon observing a coordi-
nator (assumed to be anything with a CC tag, e.g.,
?and?) is to copy the full subtree of the preced-
ing coordinate sister. Copying impacts on how the
parser works (see Section 2.5), and in a probabilis-
tic setting, it also changes the probability of trees
with parallel coordinated structures. If coordina-
tion is present, the structure of the second item is
either identical to the first, or it is not.1 Let us call
1The model only considers two-item coordination or thelast two sisters of multiple-item coordination.
the probability of having a copied tree as pident.This value may be estimated directly from a cor-
pus using the formula
p?ident =
cident
ctotal
Here, cident is the number of coordinate structuresin which the two conjuncts have the same internal
structure and ctotal is the total number of coordi-nate structures. Note we assume there is only one
parameter pident applicable everywhere (i.e., it hasthe same value for all rules).
How is this used in a PCFG parser? Let t1 and t2represent, respectively, the first and second coor-
dinate sisters and let PPCFG(t) be the PCFG prob-ability of an arbitrary subtree t.
Because of the independence assumptions of
the PCFG, we know that pident ? PPCFG(t). Oneway to proceed would be to assign a probability
of pident when structures match, and (1? pident) ?
PPCFG(t2) when structures do not match. However,some probability mass is lost this way: there is
a nonzero PCFG probability (namely, PPCFG(t1))that the structures match.
In other words, we may have identical subtrees
in two different ways: either due to a copy oper-
ation, or due to a PCFG derivation. If pcopy is theprobability of a copy operation, we can write this
fact more formally as: pident = PPCFG(t1)+ pcopy.Thus, if the structures do match, we assign the
second sister a probability of:
pcopy +PPCFG(t1)
If they do not match, we assign the second con-
junct the following probability:
1?PPCFG(t1)? pcopy
1?PPCFG(t1) ?PPCFG(t2)
This accounts for both a copy mismatch and a
PCFG derivation mismatch, and assures the prob-
abilities still sum to one. These probabilities for
parallel and non-parallel coordinate sisters, there-
fore, gives us the basis of the Copy model.
This leaves us with the problem of finding an
estimate for pcopy. This value is approximated as:
p?copy = p?ident ?
1
|T2| ?t?T2 PPCFG(t)
In this equation, T2 is the set of all second con-juncts.
2.3 Between Model
While the Copy model limits itself to parallelism
in coordination, the next two models simulate
structural priming in general. Both are similar in
design, and are based on a simple insight: we may
418
condition a PCFG rule expansion on whether the
rule occurred in some previous context. If Prime is
a binary-valued random variable denoting if a rule
occurred in the context, then we define:
P(RHS|LHS,Prime) = c(LHS ? RHS,Prime)
c(LHS,Prime)
This is essentially an instantiation of Church?s
(2000) adaptation probability, albeit with PCFG
rules instead of words. For our first model, this
context is the previous sentence. Thus, the model
can be said to capture the degree to which rule use
is primed between sentences. We henceforth refer
to this as the Between model. Following the con-
vention in the psycholinguistic literature, we refer
to a rule use in the previous sentence as a ?prime?,
and a rule use in the current sentence as the ?tar-
get?. Each rule acts once as a target (i.e., the event
of interest) and once as a prime. We may classify
such adapted probabilities into ?positive adapta-
tion?, i.e., the probability of a rule given the rule
occurred in the preceding sentence, and ?negative
adaptation?, i.e., the probability of a rule given that
the rule did not occur in the preceding sentence.
2.4 Within Model
Just as the Between model conditions on rules
from the previous sentence, the Within sentence
model conditions on rules from earlier in the cur-
rent sentence. Each rule acts once as a target, and
possibly several times as a prime (for each subse-
quent rule in the sentence). A rule is considered
?used? once the parser passes the word on the left-
most corner of the rule. Because the Within model
is finer grained than the Between model, it can be
used to capture the parallelism effect in coordina-
tion. In other words, this model could explain par-
allelism in coordination as an instance of a more
general priming effect.
2.5 Parser
As our main purpose is to build a psycholinguistic
model of structure repetition, the most important
feature of the parsing model is to build structures
incrementally.2
Reading time experiments, including the paral-
lelism studies of Frazier et al (2000), make word-
by-word measurements of the time taken to read
2In addition to incremental parsing, a characteristic someof psycholinguistic models of sentence comprehension is toparse deterministically. While we can compute the best in-cremental analysis at any point, ours models do not parse de-terministically. However, following the principles of rationalanalysis (Anderson, 1991), our goal is not to mimic the hu-man parsing mechanism, but rather to create a model of hu-man parsing behavior.
a novel and a bookwrote
0 3
Terry
4 5 61 2 7
NP NP
NP
a novel and a bookTerry wrote
0 31 4 5 62 7
NP
NP NP
Figure 1: Upon encountering a coordinator, the
copy model copies the most likely first conjunct.
sentences. Slower reading times are known to be
correlated with processing difficulty, and faster
reading times (as is the case with parallel struc-
tures) are correlated with processing ease. A prob-
abilistic parser may be considered to be a sen-
tence processing model via a ?linking hypothesis?,
which links the parser?s word-by-word behavior to
human reading behavior. We discuss this topic in
more detail in Section 3. At this point, it suffices
to say that we require a parser which has the pre-
fix property, i.e., which parses incrementally, from
left to right.
Therefore, we use an Earley-style probabilis-
tic parser, which outputs Viterbi parses (Stolcke,
1995). We have two versions of the parser: one
which parses exhaustively, and a second which
uses a variable width beam, pruning any edges
whose merit is 12000 of the best edge. The meritof an edge is its inside probability times a prior
P(LHS) times a lookahead probability (Roark and
Johnson, 1999). To speed up parsing time, we right
binarize the grammar,3 remove empty nodes, coin-
dexation and grammatical functions. As our goal
is to create the simplest possible model which can
nonetheless model experimental data, we do not
make any tree modification designed to improve
accuracy (as, e.g., Klein and Manning 2003).
The approach used to implement the Copy
model is to have the parser copy the subtree of the
first conjunct whenever it comes across a CC tag.
Before copying, though, the parser looks ahead to
check if the part-of-speech tags after the CC are
equivalent to those inside the first conjunct. The
copying model is visualized in Figure 1: the top
panel depicts a partially completed edge upon see-
ing a CC tag, and the second panel shows the com-
pleted copying operation. It should be clear that
3We found that using an unbinarized grammar did not al-ter the results, at least in the exhaustive parsing case.
419
the copy operation gives the most probable sub-
tree in a given span. To illustrate this, consider Fig-
ure 1. If the most likely NP between spans 2 and 7
does not involve copying (i.e. only standard PCFG
rule derivations), the parser will find it using nor-
mal rule derivations. If it does involve copying, for
this particular rule, it must involve the most likely
NP subtree from spans 2 to 3. As we parse in-
crementally, we are guaranteed to have found this
edge, and can use it to construct the copied con-
junct over spans 5 to 7 and therefore the whole
co-ordinated NP from spans 2 to 7.
To simplify the implementation of the copying
operation, we turn off right binarization so that the
constituent before and after a coordinator are part
of the same rule, and therefore accessible from the
same edge. This makes it simple to calculate the
new probability: construct the copied subtree, and
decide where to place the resulting edge on the
chart.
The Between and Within models require a cache
of recently used rules. This raises two dilem-
mas. First, in the Within model, keeping track of
full contextual history is incompatible with chart
parsing. Second, whenever a parsing error occurs,
the accuracy of the contextual history is compro-
mised. As we are using a simple unlexicalized
parser, such parsing errors are probably quite fre-
quent.
We handle the first problem by using one sin-
gle parse as an approximation of the history. The
more realistic choice for this single parse is the
best parse so far according to the parser. Indeed,
this is the approach we use for our main results in
Section 3. However, because of the second prob-
lem noted above, in Section 4, we simulated the
context by filling the cache with rules from the
correct tree. In the Between model, these are the
rules of the correct parse of the previous tree; in
the Within model, these are the rules used in the
correct parse at points up to (but not including) the
current word.
3 Human Reading Time Experiment
In this section, we test our models by applying
them to experimental reading time data. Frazier
et al (2000) reported a series of experiments that
examined the parallelism preference in reading. In
one of their experiments, they monitored subjects?
eye-movements while they read sentences like (1):
(1) a. Hilda noticed a strange man and a tall
woman when she entered the house.
b. Hilda noticed a man and a tall woman
when she entered the house.
They found that total reading times were faster on
the phrase tall woman in (1a), where the coordi-
nated noun phrases are parallel in structure, com-
pared with in (1b), where they are not.
There are various approaches to modeling pro-
cessing difficulty using a probabilistic approach.
One possibility is to use an incremental parser
with a beam search or an n-best approach. Pro-
cessing difficulty is predicted at points in the input
string where the current best parse is replaced by
an alternative derivation (Jurafsky, 1996; Crocker
and Brants, 2000). An alternative is to keep track
of all derivations, and predict difficulty at points
where there is a large change in the shape of
the probability distribution across adjacent pars-
ing states (Hale, 2001). A third approach is to
calculate the forward probability (Stolcke, 1995)
of the sentence using a PCFG. Low probabilities
are then predicted to correspond to high process-
ing difficulty. A variant of this third approach is
to assume that processing difficulty is correlated
with the (log) probability of the best parse (Keller,
2003). This final formulation is the one used for
the experiments presented in this paper.
3.1 Method
The item set was adapted from that of Frazier et al
(2000). The original two relevant conditions of
their experiment (1a,b) differ in terms of length.
This results in a confound in the PCFG frame-
work, because longer sentences tend to result in
lower probabilities (as the parses tend to involve
more rules). To control for such length differences,
we adapted the materials by adding two extra con-
ditions in which the relation between syntactic
parallelism and length was reversed. This resulted
in the following four conditions:
(2) a. DT JJ NN and DT JJ NN (parallel)
Hilda noticed a tall man and a strange
woman when she entered the house.
b. DT NN and DT JJ NN (non-parallel)
Hilda noticed a man and a strange
woman when she entered the house.
c. DT JJ NN and DT NN (non-parallel)
Hilda noticed a tall man and a woman
when she entered the house.
d. DT NN and DT NN (parallel)
Hilda noticed a man and a woman when
she entered the house.
420
In order to account for Frazier et al?s paral-
lelism effect a probabilistic model should pre-
dict a greater difference in probability be-
tween (2a) and (2b) than between (2c) and (2d)
(i.e., (2a)?(2b) > (2c)?(2d)). This effect will not
be confounded with length, because the relation
between length and parallelism is reversed be-
tween (2a,b) and (2c,d). We added 8 items to the
original Frazier et al materials, resulting in a new
set of 24 items similar to (2).
We tested three of our PCFG-based models on
all 24 sets of 4 conditions. The models were the
Baseline, the Within and the Copy models, trained
exactly as described above. The Between model
was not tested as the experimental stimuli were
presented without context. Each experimental sen-
tence was input as a sequence of correct POS tags,
and the log probability estimate of the best parse
was recorded.
3.2 Results and Discussion
Table 1 shows the mean log probabilities estimated
by the models for the four conditions, along with
the relevant differences between parallel and non-
parallel conditions.
Both the Within and the Copy models show a
parallelism advantage, with this effect being much
more pronounced for the Copy model than the
Within model. To evaluate statistical significance,
the two differences for each item were compared
using a Wilcoxon signed ranks test. Significant
results were obtained both for the Within model
(N = 24, Z = 1.67, p < .05, one-tailed) and for
the Copy model (N = 24, Z = 4.27, p < .001, one-
tailed). However, the effect was much larger for
the Copy model, a conclusion which is confirmed
by comparing the differences of differences be-
tween the two models (N = 24, Z = 4.27, p < .001,
one-tailed). The Baseline model was not evalu-
ated statistically, because by definition it predicts a
constant value for (2a)?(2b) and (2c)?(2d) across
all items. This is simply a consequence of the
PCFG independence assumption, coupled with the
fact that the four conditions of each experimen-
tal item differ only in the occurrences of two NP
rules.
The results show that the approach taken here
can be successfully applied to the modeling of
experimental data. In particular, both the Within
and the Copy models show statistically reliable
parallelism effects. It is not surprising that the
copy model shows a large parallelism effect for
the Frazier et al (2000) items, as it was explicitly
designed to prefer structurally parallel conjuncts.
The more interesting result is the parallelism ef-
fect found for the Within model, which shows that
such an effect can arise from a more general prob-
abilistic priming mechanism.
4 Parsing Experiment
In the previous section, we were able to show that
the Copy and Within models are able to account
for human reading-time performance for parallel
coordinate structures. While this result alone is
sufficient to claim success as a psycholinguistic
model, it has been argued that more realistic psy-
cholinguistic models ought to also exhibit high ac-
curacy and broad-coverage, both crucial properties
of the human parsing mechanism (e.g., Crocker
and Brants, 2000).
This should not be difficult: our starting point
was a PCFG, which already has broad coverage
behavior (albeit with only moderate accuracy).
However, in this section we explore what effects
our modifications have to overall coverage, and,
perhaps more interestingly, to parsing accuracy.
4.1 Method
The models used here were the ones introduced
in Section 2 (which also contains a detailed de-
scription of the parser that we used to apply the
models). The corpus used for both training and
evaluation is the Wall Street Journal part of the
Penn Treebank. We use sections 1?22 for train-
ing, section 0 for development and section 23 for
testing. Because the Copy model posits coordi-
nated structures whenever POS tags match, pars-
ing efficiency decreases if POS tags are not pre-
determined. Therefore, we assume POS tags as in-
put, using the gold-standard tags from the treebank
(following, e.g., Roark and Johnson 1999).
4.2 Results and Discussion
Table 2 lists the results in terms of F-score on
the test set.4 Using exhaustive search, the base-
line model achieves an F-score of 73.3, which is
comparable to results reported for unlexicalized
incremental parsers in the literature (e.g. the RB1
model of Roark and Johnson, 1999). All models
exhibit a small decline in performance when beam
search is used. For the Within model we observe a
slight improvement in performance over the base-
line, both for the exhaustive search and the beam
4Based on a ?2 test on precision and recall, all results arestatistically different from each other. The Copy model actu-ally performs slightly better than the Baseline in the exhaus-tive case.
421
Model para: (2a) non-para: (2b) non-para: (2c) para: (2d) (2a)?(2b) (2c)?(2d)
Baseline ?33.47 ?32.37 ?32.37 ?31.27 ?1.10 ?1.10
Within ?33.28 ?31.67 ?31.70 ?29.92 ?1.61 ?1.78
Copy ?16.18 ?27.22 ?26.91 ?15.87 11.04 ?11.04
Table 1: Mean log probability estimates for Frazier et al(2000) items
Exhaustive Search Beam Search Beam + Coord Fixed Coverage
Model F-score Coverage F-score Coverage F-score Coverage F-score Coverage
Baseline 73.3 100 73.0 98.0 73.1 98.1 73.0 97.5
Within 73.6 100 73.4 98.4 73.0 98.5 73.4 97.5
Between 71.6 100 71.7 98.7 71.5 99.0 71.8 97.5
Copy 73.3 100 ? ? 73.0 98.1 73.1 97.5
Table 2: Parsing results for the Within, Between, and Copy model compared to a PCFG baseline.
search conditions. The Between model, however,
resulted in a decrease in performance.
We also find that the Copy model performs at
the baseline level. Recall that in order to simplify
the implementation of the copying, we had to dis-
able binarization for coordinate constituents. This
means that quaternary rules were used for coordi-
nation (X ? X1 CC X2 X ?), while normal binaryrules (X ? Y X ?) were used everywhere else. It
is conceivable that this difference in binarization
explains the difference in performance between
the Between and Within models and the Copy
model when beam search was used. We there-
fore also state the performance for Between and
Within models with binarization limited to non-
coordinate structures in the column labeled ?Beam
+ Coord? in Table 2. The pattern of results, how-
ever, remains the same.
The fact that coverage differs between models
poses a problem in that it makes it difficult to
compare the F-scores directly. We therefore com-
pute separate F-scores for just those sentences that
were covered by all four models. The results are
reported in the ?Fixed Coverage? column of Ta-
ble 2. Again, we observe that the copy model per-
forms at baseline level, while the Within model
slightly outperforms the baseline, and the Between
model performs worse than the baseline. In Sec-
tion 5 below we will present an error analysis that
tries to investigate why the adaptation models do
not perform as well as expected.
Overall, we find that the modifications we intro-
duced to model the parallelism effect in humans
have a positive, but small, effect on parsing ac-
curacy. Nonetheless, the results also indicate the
success of both the Copy and Within approaches
to parallelism as psycholinguistic models: a mod-
ification primarily useful for modeling human be-
havior has no negative effects on computational
measures of coverage or accuracy.
5 Distance Between Rule Uses
Although both the Within and Copy models suc-
ceed at the main task of modeling the paral-
lelism effect, the parsing experiments in Section 4
showed mixed results with respect to F-scores:
a slight increase in F-score was observed for the
Within model, but the Between model performed
below the baseline. We therefore turn to an error
analysis, focusing on these two models.
Recall that the Within and Between models es-
timate two probabilities for a rule, which we have
been calling the positive adaptation (the probabil-
ity of a rule when the rule is also in the history),
and the negative adaptation (the probability of a
rule when the rule is not in the history). While
the effect is not always strong, we expect positive
adaptation to be higher than negative adaptation
(Dubey et al, 2005). However, this is not always
the case.
In the Within model, for example, the rule
NP ? DT JJ NN has a higher negative than posi-
tive adaptation (we will refer to such rules as ?neg-
atively adapted?). The more common rule NP ?
DT NN has a higher positive adaptation (?pos-
itively adapted?). Since the latter is three times
more common, this raises a concern: what if adap-
tation is an artifact of frequency? This ?frequency?
hypothesis posits that a rule recurring in a sentence
is simply an artifact of the its higher frequency.
The frequency hypothesis could explain an inter-
esting fact: while the majority of rules tokens have
positive adaptation, the majority of rule types have
negative adaptation. An important corollary of the
frequency hypothesis is that we would not expect
to find a bias towards local rule re-uses.
422
Iterate through the treebank
Remember how many words each constituent spans
Iterate through the treebank
Iterate through each tree
Upon finding a constituent spanning 1-4 words
Swap it with a randomly chosen constituent
of 1-4 words
Update the remembered size of the swapped
constituents and their subtrees
Iterate through the treebank 4 more times
Swap constituents of size 5-9, 10-19, 20-35
and 35+ words, respectively
Figure 2: The treebank randomization algorithm
Nevertheless, the NP ? DT JJ NN rule is
an exception: most negatively adapted rules have
very low frequencies. This raises the possibility
that sparse data is the cause of the negatively
adapted rules. This makes intuitive sense: we need
many rule occurrences to accurately estimate pos-
itive or negative adaptation.
We measure the distribution of rule use to ex-
plore if negatively adapted rules owe more to fre-
quency effects or to sparse data. This distributional
analysis also serves to measure ?decay? effects in
structural repetition. The decay effect in priming
has been observed elsewhere (Szmrecsanyi, 2005),
and suggests that positive adaptation is higher the
closer together two rules are.
5.1 Method
We investigate the dispersion of rules by plot-
ting histograms of the distance between subse-
quent rule uses. The basic premise is to look for
evidence of an early peak or skew, which sug-
gests rule re-use. To ensure that the histogram it-
self is not sensitive to sparse data problems, we
group all rules into two categories: those which are
positively adapted, and those which are negatively
adapted.
If adaptation is not due to frequency alone, we
would expect the histograms for both positively
and negatively adapted rules to be skewed towards
local rule repetition. Detecting a skew requires a
baseline without repetition. We propose the con-
cept of ?randomizing? the treebank to create such
a baseline. The randomization algorithm is de-
scribed in Figure 2. The algorithm entails swap-
ping subtrees, taking care that small subtrees are
swapped first (otherwise large chunks would be
swapped at once, preserving a great deal of con-
text). This removes local effects, giving a distribu-
tion due frequency alone.
After applying the randomization algorithm to
the treebank, we may construct the distance his-
0 5 10Logarithm of Word Distance
0
0.005
0.01
0.015
0.02
No
rm
aliz
ed 
Fre
que
ncy
 of 
Ru
le O
ccu
ran
ce
+ Adapt, Untouched Corpus
+ Adapt, Randomized Corpus
- Adapt, Untouched Corpus
- Adapt, Randomized Corpus
Figure 3: Log of number of words between rule
invocations
togram for both the non-randomized and random-
ized treebanks. The distance between two occur-
rences of a rule is calculated as the number of
words between the first word on the left corner of
each rule. A special case occurs if a rule expansion
invokes another use of the same rule. When this
happens, we do not count the distance between the
first and second expansion. However, the second
expansion is still remembered as the most recent.
We group rules into those that have a higher
positive adaptation and those that have a higher
negative adaptation. We then plot a histogram of
rule re-occurrence distance for both groups, in
both the non-randomized and randomized corpora.
5.2 Results and Discussion
The resulting plot for the Within model is shown
in Figure 3. For both the positive and negatively
adapted rules, we find that randomization results
in a lower, less skewed peak, and a longer tail.
We conclude that rules tend to be repeated close
to one another more than we expect by chance,
even for negatively adapted rules. This is evidence
against the frequency hypothesis, and in favor of
the sparse data hypothesis. This means that the
small size of the increase in F-score we found in
Section 4 is not due to the fact that the adaption
is just an artifact of rule frequency. Rather, it can
probably be attributed to data sparseness.
Note also that the shape of the histogram pro-
vides a decay curve. Speculatively, we suggest that
this shape could be used to parameterize the decay
effect and therefore provide an estimate for adap-
tation which is more robust to sparse data. How-
ever, we leave the development of such a smooth-
ing function to future research.
423
6 Conclusions and Future Work
The main contribution of this paper has been to
show that an incremental parser can simulate syn-
tactic priming effects in human parsing by incor-
porating probability models that take account of
previous rule use. Frazier et al (2000) argued that
the best account of their observed parallelism ad-
vantage was a model in which structure is copied
from one coordinate sister to another. Here, we ex-
plored a probabilistic variant of the copy mecha-
nism, along with two more general models based
on within- and between-sentence priming. Al-
though the copy mechanism provided the strongest
parallelism effect in simulating the human reading
time data, the effect was also successfully simu-
lated by a general within-sentence priming model.
On the basis of simplicity, we therefore argue that
it is preferable to assume a simpler and more gen-
eral mechanism, and that the copy mechanism is
not needed. This conclusion is strengthened when
we turn to consider the performance of the parser
on the standard Penn Treebank test set: the Within
model showed a small increase in F-score over the
PCFG baseline, while the copy model showed no
such advantage.5
All the models we proposed offer a broad-
coverage account of human parsing, not just a lim-
ited model on a hand-selected set of examples,
such as the models proposed by Jurafsky (1996)
and Hale (2001) (but see Crocker and Brants
2000).
A further contribution of the present paper has
been to develop a methodology for analyzing the
(re-)use of syntactic rules over time in a corpus. In
particular, we have defined an algorithm for ran-
domizing the constituents of a treebank, yielding
a baseline estimate of chance repetition.
In the research reported in this paper, we have
adopted a very simple model based on an unlex-
icalized PCFG. In the future, we intend to ex-
plore the consequences of introducing lexicaliza-
tion into the parser. This is particularly interest-
ing from the point of view of psycholinguistic
modeling, because there are well known inter-
actions between lexical repetition and syntactic
priming, which require lexicalization for a proper
treatment. Future work will also involve the use
of smoothing to increase the benefit of priming
for parsing accuracy. The investigations reported
5The broad-coverage parsing experiment speaks againsta ?facilitation? hypothesis, i.e., that the copying and prim-ing mechanisms work together. However, a full test of this(e.g., by combining the two models) is left to future research.
in Section 5 provide a basis for estimating the
smoothing parameters.
References
Anderson, John. 1991. Cognitive architectures in a ratio-nal analysis. In K. VanLehn, editor, Architectures for In-
telligence, Lawrence Erlbaum Associates, Hillsdale, N.J.,pages 1?24.
Bock, J. Kathryn. 1986. Syntactic persistence in languageproduction. Cognitive Psychology 18:355?387.
Church, Kenneth W. 2000. Empirical estimates of adapta-
tion: the chance of two Noriegas is closer to p/2 than p2.In Proceedings of the 17th Conference on Computational
Linguistics. Saarbru?cken, Germany, pages 180?186.
Crocker, Matthew W. and Thorsten Brants. 2000. Wide-coverage probabilistic sentence processing. Journal of
Psycholinguistic Research 29(6):647?669.
Dubey, Amit, Patrick Sturt, and Frank Keller. 2005. Paral-lelism in coordination as an instance of syntactic priming:Evidence from corpus-based modeling. In Proceedings
of the Human Language Technology Conference and the
Conference on Empirical Methods in Natural Language
Processing. Vancouver, pages 827?834.
Frazier, Lyn, Alan Munn, and Chuck Clifton. 2000. Process-ing coordinate structures. Journal of Psycholinguistic Re-
search 29(4):343?370.
Frazier, Lynn and Charles Clifton. 2001. Parsing coordinatesand ellipsis: Copy ?. Syntax 4(1):1?22.
Hale, John. 2001. A probabilistic Earley parser as a psy-cholinguistic model. In Proceedings of the 2nd Confer-
ence of the North American Chapter of the Association
for Computational Linguistics. Pittsburgh, PA.
Jurafsky, Daniel. 1996. A probabilistic model of lexical andsyntactic access and disambiguation. Cognitive Science20(2):137?194.
Keller, Frank. 2003. A probabilistic parser as a model ofglobal processing difficulty. In R. Alterman and D. Kirsh,editors, Proceedings of the 25th Annual Conference of the
Cognitive Science Society. Boston, pages 646?651.
Klein, Dan and Christopher D. Manning. 2003. Accurate Un-lexicalized Parsing. In Proceedings of the 41st Annual
Meeting of the Association for Computational Linguistics.Sapporo, Japan, pages 423?430.
Kuhn, Roland and Renate de Mori. 1990. A cache-based nat-ural language model for speech recognition. IEEE Tran-
sanctions on Pattern Analysis and Machine Intelligence12(6):570?583.
Roark, Brian and Mark Johnson. 1999. Efficient probabilistictop-down and left-corner parsing. In Proceedings of the
37th Annual Meeting of the Association for Computational
Linguistics. pages 421?428.
Stolcke, Andreas. 1995. An efficient probabilistic context-free parsing algorithm that computes prefix probabilities.
Computational Linguistics 21(2):165?201.
Szmrecsanyi, Benedikt. 2005. Creatures of habit: A corpus-linguistic analysis of persistence in spoken English. Cor-
pus Linguistics and Linguistic Theory 1(1):113?149.
424
Competence and Performance Grammar
in Incremental Processing
Vincenzo Lombardo
Dipartimento di Informatica
Universita` di Torino
c.so Svizzera, 185
10149, Torino, Italy
vincenzo@di.unito.it
Alessandro Mazzei
Dipartimento di Informatica
Universita` di Torino
c.so Svizzera, 185
10149, Torino, Italy
mazzei@di.unito.it
Patrick Sturt
Department of Psychology
University of Glasgow
58 Hillhead Street
Glasgow, G12 8QB, UK
patrick@psy.gla.ac.uk
Abstract
The goal of this paper is to explore some conse-
quences of the dichotomy between competence
and performance from the point of view of in-
crementality. We introduce a TAG?based for-
malism that encodes a strong notion of incre-
mentality directly into the operations of the
formal system. A left-associative operation is
used to build a lexicon of extended elementary
trees. Extended elementary trees allow deriva-
tions in which a single fully connected struc-
ture is mantained through the course of a left-
to-right word-by-word derivation. In the paper,
we describe the consequences of this view for
semantic interpretation, and we also evaluate
some of the computational consequences of en-
larging the lexicon in this way.
1 Introduction
Incremental processing can be achieved with a
combination of grammar formalism and deriva-
tion/parsing strategy. In this paper we explore
some of the computational consequences of de-
riving the incremental character of the human
language processor from the competence gram-
mar. In the following paragraphs, we assume
that incremental processing proceeds through a
sequence of processing steps. Each step consists
of a configuration of partial syntactic structures
(possibly connected into only one structure) and
a configuration of semantic structures (again,
possibly connected into one single expression).
These semantic structures result from the ap-
plication of the semantic interpreter to the syn-
tactic structures in the same processing step.
Depending on the semantic rules, some syntac-
tic structures may not be interpretable?that
is, some processing steps do not involve an up-
dating of the semantic representation. In the
view we present here, competence grammar is
responsible for the definition of both the set of
well-formed sentences of the language and the
set of possible partial structures that are yielded
by the derivation process. According to this
view, the performance component is responsible
for other aspects of language processing, includ-
ing ambiguity handling and error handling. The
latter issues are not addressed in this paper.
In the psycholinguistic and computational lit-
erature, many models for incremental process-
ing have been discussed. These models can be
characterized in terms of the location of the bor-
der between competence and performance. In
particular, we discuss the relative responsibility
of the competence and performance components
on three key areas of syntactic processing: a)
the space of well-formed partial syntactic struc-
tures; b) the space of the possible configurations
of partial syntactic structures at each process-
ing step; c) the sub-space of partial structures
that can actually be interpreted.
The definition of well-formedness is almost
universally assigned to the competence compo-
nent, whether in a direct implementation of the
grammar formalism (cf. the Type Transparency
hypothesis (Berwick and Weinberg, 1984)) or a
compiled version of the competence grammar
(e.g. LR parsing (Shieber and Johnson, 1993)).
The space of the possible configurations of
partial structures refers to those partial syntac-
tic structures that are built and stored during
parsing or derivation. Different algorithms re-
sult in different possibilities for the configura-
tions of partial structures that the parser builds.
For example, a bottom?up algorithm will never
build a partial structure with non?terminal leaf
nodes. The standard approach is to assign this
responsibility to the parsing algorithm, whether
the grammar is based on standard context-free
formalisms (Roark, 2001), on generative syntac-
tic theories based on a context-free backbone
(Crocker, 1992), or on categorial approaches,
like e.g. Combinatory Categorial Grammar
(CCG ? (Steedman, 2000)). A different method
is to assign this responsibility to the compe-
tence component. In this case the space of
possible configurations of partial structures is
constrained by the grammatical derivation pro-
cess itself, and the parsing algorithm needs to
be aligned with these requirements. This ap-
proach is exemplified by the works of Kempson
et al (2000) and Phillips (2003), who argue
that many problems in theoretical syntax, like
the definition of constituency, can be solved by
extending this responsability to the competence
grammar.
This issue of constituency is also relevant in
the third key area, which is the definition of the
space of interpretable structures. The assign-
ment of responsibility with respect to current
approaches usually depends on the implementa-
tion of the incremental technique. Approaches
based on a coupling of syntactic and seman-
tic rules in the competence grammar (Steed-
man, 2000; Kempson et al, 2000) adhere to the
so-called Strict Competence Hypothesis (Steed-
man, 2000), which constrains the interpreter to
deal only with grammatical constituents, so the
responsibility for deciding the interpretable par-
tial structures is assigned to competence1. In
contrast, approaches that are based on com-
petence grammars that do not include seman-
tic rules, like CFG, implement semantic inter-
preters that mimic such semantic rules (Stabler,
1991), and so they assign the responsibility for
deciding the interpretable partial structures to
performance.
In this paper we explore the empirical con-
sequences of building a realistic grammar when
the formalism constrains all these three areas,
as is the case with Kempson et al (2000)
and Phillips (2003). The work relies upon the
Dynamic Version of Lexicalized Tree Adjoin-
ing Grammar (DV?TAG), introduced in (Lom-
bardo and Sturt, 2002b), a formalism that en-
codes a dynamic grammar (cf. (Milward, 1994))
in LTAG terms (Joshi and Schabes, 1997). The
consequence of encoding a dynamic grammar
is that the configurations of partial structures
discussed above are limited to fully connected
structures, that is no disconnected structures
are allowed in a configuration. In particular,
the paper focuses on the problem of building a
realistic DV?TAG grammar through a conver-
sion from an LTAG, in order to maintain the
1Notice that these approaches may, however, differ in
the time-course with which semantic rules are applied
in the interpreter, and this issue depends directly on
the space of configurations of partial structures discussed
above
linguistic significance of elementary trees while
extending them to allow the full connectivity.
2 Dynamic Version of Tree
Adjoining Grammar
This section reviews the major aspects of the
Dynamic Version of Tree Adjoining Grammar
(DV?TAG), with special reference to similari-
ties and differences with respect to LTAG.
Dynamic grammars define well-formedness in
terms of states and transitions between states.
They allow a natural formulation of incremental
processing, where each word wi defines a tran-
sition from Statei?1, also called the left context,
to Statei (Milward, 1994). The states can be
defined as partial syntactic or semantic struc-
tures that are ?updated? as each word is recog-
nized; roughly speaking, two adjacent states can
be thought of as two parse trees before and af-
ter the attachment of a word, respectively. The
derivation process proceeds from left to right
by extending a fully connected left context to
include the next input word.
Like an LTAG (Joshi and Schabes, 1997), a
Dynamic Version of Tree Adjoining Grammar
(DV?TAG) consists of a set of elementary trees,
divided into initial trees and auxiliary trees,
and attachment operations for combining them.
Lexicalization is expressed through the associ-
ation of a lexical anchor with each elementary
tree. The anchor defines the semantic content of
the elementary tree: the whole elementary tree
can be seen as an extended projection of the an-
chor (Frank, 2000). LTAG is said to define an
extended domain of locality ?unlike context-free
grammars, which use rules that describe one?
branch deep fragments of trees, TAG elemen-
tary trees can describe larger structures (e.g. a
verb, its maximal S node and subject NP node).
In figures 1(a) and 2(a) we can see the ele-
mentary trees for a derivation of the sentence
Bill often pleases Sue for LTAG and DV?TAG
respectively. Auxiliary trees in DV?TAG are
split into left auxiliary trees, where the lexical
anchor is on the left of the foot node, and right
auxiliary trees, where the lexical anchor is on
the right of the foot node. The tree anchored
by often in fig. 2(a) is a left auxiliary tree.
Non-terminal nodes have a distinguished
head daughter, which provides the lexical head
of the mother node: unlike in LTAG, each node
in the elementary trees is augmented with a fea-
ture indicating the lexical head that projects
the node. This feature is needed for the no-
Bill often pleases Sue. 
NNP 
Sue 
NP 
ADV
often
ADVP 
VP 
VP* 
NP 
NNP 
Sue 
S
V
pleases
NP 
VP NNP 
Bill 
ADV
often
ADVP 
VP 
V
pleases 
NP$ 
NP$ 
S
VP 
adjunction
Bill
pleases
Sueoften
(a)
(b)
(c)
substitutionNNP 
Bill 
NP 
substitution
 
Bill
 
pleases

often
 
Sue
Figure 1: The LTAG derivation of the sentence
Bill often pleases Sue.
NNP 
Sue 
NP(Sue)
ADV
often
ADVP(often)
VP(_j)
VP*(_j)
NP(Sue)
NNP 
Sue 
S(pleases)
V
pleases
NP(Bill)
VP(pleases)NNP 
Bill 
ADV
often
ADVP(often)
VP(pleases)
V(_i) NP$(_k)NNP 
Bill 
NP(Bill)
S(_i)
VP( i)
pleases 
likes 
eats 
plays 
?
1. adjunction 
from the left 
2. shift 
Bill
pleases
Sueoften
(a)
(b)
(c)
3. substitution 
Figure 2: The DVTAG derivation of the sen-
tence Bill often pleases Sue.
tion of derivation?dependency tree (see below).
If several unheaded nodes share the same lexical
head, they are all co-indexed with a head vari-
able (e.g. i in the elementary tree anchored by
Bill in figure 2(a)); the head variable is a vari-
able in logic terms: i will be unified with the
constant (?lexical head?) pleases.
In both LTAG and DV?TAG the lexical an-
chor does not necessarily provide the head fea-
ture of the root of the elementary tree. This is
trivially true for auxiliary trees (e.g. the tree
anchored often in figure 1(a) and figure 2(a)).
However, in DV?TAG this can also occur with
initial trees (e.g. the tree anchored by Bill in
figure 2(a)), because initial trees can include
not only the head projection of the anchor, but
also other higher projections that are required
to account for the full connectedness of the par-
tial parse tree. The elementary tree anchored
by Bill is linguistically motivated up to the NP
projection; the rest of the structure depends on
connectivity. These extra nodes are called pre-
dicted nodes. A predicted preterminal node is
referred by a set of lexical items. In the sec-
tion 3 we illustrate a method for building such
extended elementary trees.
The derivation process in LTAG and DV?
TAG builds a derived tree by combining the ele-
mentary trees via some operations that are illus-
trated below. DV?TAG implements the incre-
mental process by constraining the derivation
process to be a series of steps in which an ele-
mentary tree is combined with the partial tree
spanning the left fragment of the sentence. The
result of a step is an updated partial structure.
Specifically, at the processing step i, the ele-
mentary tree anchored by the i-th word in the
sentence is combined with the partial structure
spanning the words from 1 to i ? 1 positions;
the result is a partial structure spanning the
words from 1 to i. In contrast, LTAG does
not pose any order constraint on the deriva-
tion process, and the combinatorial operations
are defined over pairs of elementary trees. In
DV?TAG the derivation process starts from an
elementary tree anchored by the first word in
the sentence and that does not require any at-
tachment that would introduce lexical material
on the left of the anchor (such as in the case
that a Substitution node is on the left of the
anchor). This elementary tree becomes the first
left context that has to be combined with some
elementary tree on the right.
Since in DV?TAG we always combine a left
context with an elementary tree, the number
of attachment operations increases from two
in LTAG to six in DV?TAG. Three operations
(substitution, adjunction from the left and ad-
junction from the right) are called forward op-
erations because they insert the current elemen-
tary tree into the left context; two other oper-
ations (inverse substitution and inverse adjunc-
tion) are called inverse operations because they
insert the left context into the current elemen-
tary tree; the sixth operation (shift) does not
involve any insertion of new structural material.
The first operation in DV?TAG is the stan-
dard LTAG substitution, where some elemen-
tary tree replaces a substitution node in another
tree structure (see fig. 2(a)).
Standard LTAG adjunction is split into two
operations: adjunction from the left and ad-
junction from the right. The type of adjunction
depends on the position of the lexical material
introduced by the auxiliary tree with respect
to the material currently dominated by the ad-
joined node (which is in the left context). In
figure 2(a) we have an adjunction from the left
in the case of the left auxiliary tree anchored by
often.
Inverse operations account for the insertion
of the left context into the elementary tree. In
the case of inverse substitution the left context
replaces a substitution node in the elementary
tree; in the case of inverse adjunction, the left
context acts like an auxiliary tree, and the el-
ementary tree is split because of the adjoining
of the left context at some node. In (Lombardo
and Sturt, 2002b) there is shown the importance
of the latter operation to obtain the correct de-
pendencies for cross-serial Dutch dependencies
in DV?TAG.
Finally, the shift operation either scans a lex-
ical item which has been already introduced in
the structure or derives a lexical item from some
predicted preterminal node.
It is important to notice that, during the
derivation process, not all the nodes in the left
context and the elementary tree are accessible
for performing some operation: given the i? 1-
th word in the sentence we can compute a set
of accessible nodes in the left context (the right
fringe); also, given the lexical anchor of the el-
ementary tree, that in the derivation process
matches the i-th word in the sentence, we can
compute a set of accessible nodes in the elemen-
tary tree (the left fringe).
At the end of the derivation process the left
context structure spans the whole sentence, and
is called the derived tree: in the figures 1(c) and
2(c) there are the derived trees for Bill often
pleases Sue in LTAG and DV?TAG respectively.
A key device in LTAG is the derivation tree
(fig. 1(b)). The derivation tree represents the
history of the derivation of the sentence: it de-
scribes the substitutions and the adjoinings that
occur in a sentence derivation through a tree
structure. The nodes of the derivation tree are
identifiers of the elementary trees, and one edge
represents the operation that combines two ele-
mentary trees. Given an edge, the mother node
identifies the elementary tree where the elemen-
tary tree identified by the daughter node is sub-
stituted in or adjoined to, respectively. The
derivation tree provides a factorized representa-
tion of the derived tree. Since each elementary
is anchored by a lexical item, the derivation tree
also describes the syntactic dependencies in the
sentence in the terms of a dependency?style rep-
resentation (Rambow and Joshi, 1999) (Dras et
al., 2003).
The notion of derivation tree is not ade-
quate for DV?TAG, since the elementary trees
contain unheaded predicted nodes. For exam-
ple, the elementary tree anchored by Bill ac-
tually involves two anchors, Bill and pleases,
even if the latter anchor remains unspecified
until it is scanned/derived in the linear or-
der. We introduce a new word?based structure
that represents syntactic dependencies, namely
a derivation-dependency tree.
A derivation-dependency tree is a head-based
version of the derivation tree. Each node in an
elementary tree is augmented with the lexical
head that projects that node. The derivation-
dependency tree contains one node per lexi-
cal head, and a lexical head dominates another
when the corresponding projections in the de-
rived tree stand in a dominance relation. Each
elementary tree can contain only one overtly
marked lexical head, that represents the seman-
tic unit, but the presence of predicted nodes
in the partial derived tree corresponds to pre-
dicted heads in the derivation-dependency tree.
In figure 3 is depicted the evolution of the
derivation?dependency tree for the sentence Bill
often pleases Sue.
The DV?TAG derivation process requires the
full connectivity of the left context at all times.
The extended domain of locality provided by
LTAG elementary trees appears to be a desir-
able feature for implementing full connectivity.
However, each new word in a string has to be
connected with the preceding left context, and
there is no a priori limit on the amount of struc-
ture that may intervene between that word and
the preceding context. For example, in a DV?
TAG derivation of John said that tasty apples
     	


    	
 Incrementality in Syntactic Processing: Computational Models
and Experimental Evidence
Patrick STURT
Human Communication Research Centre
Department of Psychology
University of Glasgow
58 Hillhead Street
Glasgow, SCOTLAND
patrick@psy.gla.ac.uk
Abstract
It is a well-known intuition that human sentence
understanding works in an incremental fashion,
with a seemingly constant update of the inter-
pretation through the left-to-right processing of
a string. Such intuitions are backed up by ex-
perimental evidence dating from at least as far
back as Marslen-Wilson (1973), showing that
under many circumstances, interpretations are
indeed updated very quickly.
From a parsing point of view it is interesting
to consider the structure-building processes that
might underlie incremental interpretation?
what kinds of partial structures are built dur-
ing sentence processing, and with what time-
course?
In this talk I will give an overview of the state-
of-the-art of experimental psycholinguistic re-
search, paying particular attention to the time-
course of structure-building. The discussion will
focus on a new line of research (some as yet un-
published) in which syntactic phenomena such
as binding relations (e.g., Sturt, 2003) and un-
bounded dependencies (e.g., Aoshima, Phillips,
& Weinberg, in press) are exploited to make a
very direct test of the availability of syntactic
structure over time.
The experimental research will be viewed
from the perspective of a space of computa-
tional models, which make different predictions
about time-course of structure building. One
dimension in this space is represented by the
parsing algorithm used: For example, within
the framework of Generalized Left Corner Pars-
ing (Demers, 1977), algorithms can be char-
acterized in terms of the point at which a
context-free rule is recognized, in relation to the
recognition-point of the symbols on its right-
hand side. Another relevant dimension is repre-
sented by the type of grammar formalism that
is assumed. For example, with bottom-up pars-
ing algorithms, the degree to which structure-
building is delayed in right-branching structures
depends heavily on whether we employ a tra-
ditional phrase-structure formalism with rigid
constituency, or a cateogorial formalism with
flexible constituency (e.g., Steedman, 2000).
I will argue that the evidence is incompatible
with models which predict systematic delays in
the construction of syntactic structure. In par-
ticular, I will argue against both head-driven
strategies (e.g., Mulders, 2002), and purely
bottom-up parsing strategies, even when flex-
ible constituency is employed. Instead, I will
argue that to capture the data in the most par-
simonious way, we should turn our attention to
those models in which a fully connected syn-
tactic structure is maintained throughout the
processing of a string.
References
Aoshima, S., Phillips, C., & Weinberg, A. (in
press). Processing filler-gap dependencies
in a head-final language. To appear in
Journal of Memory and Language.
Demers, A. J. (1977). Generalized left cor-
ner parsing. In Proceedings of the 4th
acm sigact-sigplan symposium on princi-
ples of programming languages (pp. 170?
182). ACM Press.
Marslen-Wilson, W. (1973). Linguistic struc-
ture and speech shadowing at very short
latencies. Nature, 244, 522?533.
Mulders, I. (2002). Transparent parsing: Head-
driven processing of verb-final structures.
Utrecht: LOT.
Steedman, M. (2000). The syntactic process.
Cambridge, MA: MIT press.
Sturt, P. (2003). The time-course of the appli-
cation of binding constraints in reference
resolution. Journal of Memory and Lan-
guage, 48 (3), 542?562.
Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language
Processing (HLT/EMNLP), pages 827?834, Vancouver, October 2005. c?2005 Association for Computational Linguistics
Parallelism in Coordination as an Instance of Syntactic Priming:
Evidence from Corpus-based Modeling
Amit Dubey and Patrick Sturt and Frank Keller
Human Communication Research Centre, Universities of Edinburgh and Glasgow
2 Buccleuch Place, Edinburgh EH8 9LW, UK
{adubey,sturt,keller}@inf.ed.ac.uk
Abstract
Experimental research in psycholinguis-
tics has demonstrated a parallelism effect
in coordination: speakers are faster at pro-
cessing the second conjunct of a coordi-
nate structure if it has the same internal
structure as the first conjunct. We show
that this phenomenon can be explained by
the prevalence of parallel structures in cor-
pus data. We demonstrate that parallelism
is not limited to coordination, but also ap-
plies to arbitrary syntactic configurations,
and even to documents. This indicates that
the parallelism effect is an instance of a
general syntactic priming mechanism in
human language processing.
1 Introduction
Experimental work in psycholinguistics has pro-
vided evidence for the so-called parallelism prefer-
ence effect: speakers processes coordinated struc-
tures more quickly when the two conjuncts have
the same internal syntactic structure. The processing
advantage for parallel structures has been demon-
strated for a range coordinate constructions, includ-
ing NP coordination (Frazier et al, 2000), sentence
coordination (Frazier et al, 1984), and gapping and
ellipsis (Carlson, 2002; Mauner et al, 1995).
The parallelism preference in NP coordination
can be illustrated using Frazier et al?s (2000) Exper-
iment 3, which recorded subjects? eye-movements
while they read sentences like (1):
(1) a. Terry wrote a long novel and a short poem
during her sabbatical.
b. Terry wrote a novel and a short poem dur-
ing her sabbatical
Total reading times for the underlined region were
faster in (1-a), where short poem is coordinated with
a syntactically parallel noun phrase (a long novel),
compared to (1-b), where it is coordinated with a
syntactically non-parallel phrase.
These results raise an important question that the
present paper tries to answer through corpus-based
modeling studies: what is the mechanism underlying
the parallelism preference? One hypothesis is that
the effect is caused by low-level processes such as
syntactic priming, i.e., the tendency to repeat syntac-
tic structures (e.g., Bock, 1986). Priming is a very
general mechanism that can affect a wide range of
linguistic units, including words, constituents, and
semantic concepts. If the parallelism effect is an in-
stance of syntactic priming, then we expect it to ap-
ply to a wide range of syntactic construction, and
both within and between sentences. Previous work
has demonstrated priming effects in corpora (Gries,
2005; Szmrecsanyi, 2005); however, these results
are limited to instances of priming that involve a
choice between two structural alternatives (e.g., da-
tive alternation). In order to study the parallelism ef-
fect, we need to model priming as general syntac-
tic repetition (independent of the structural choices
available). This is what the present paper attempts.
Frazier and Clifton (2001) propose an alternative
account of the parallelism effect in terms of a copy-
ing mechanism. Unlike priming, this mechanism is
highly specialized and only applies to coordinate
structures: if the second conjunct is encountered,
then instead of building new structure, the language
processor simply copies the structure of the first con-
junct; this explains why a speed-up is observed if
the second conjunct is parallel to the first one. If
the copying account is correct, then we would ex-
pect parallelism effects to be restricted to coordinate
structures and would not apply in other contexts.
In the present paper, we present corpus evidence
that allows us to distinguish between these two com-
peting explanations. Our investigation will proceed
as follows: we first establish that there is evidence
827
for a parallelism effect in corpus data (Section 3).
This is a crucial prerequisite for our wider inves-
tigation: previous work has only dealt with paral-
lelism in comprehension, hence we need to establish
that parallelism is also present in production data,
such as corpus data. We then investigate whether
the parallelism effect is restricted to coordination, or
whether it also applies also arbitrary syntactic con-
figurations. We also test if parallelism can be found
for larger segments of text, including, in the limit,
the whole document (Section 4). Then we investi-
gate parallelism in dialog, testing the psycholinguis-
tic prediction that parallelism in dialog occurs be-
tween speakers (Section 5). In the next section, we
discuss a number of methodological issues and ex-
plain the way we measure parallelism in corpus data.
2 Adaptation
Psycholinguistic studies have shown that priming
affects both speech production (Bock, 1986) and
comprehension (Branigan et al, 2005). The impor-
tance of comprehension priming has also been noted
by the speech recognition community (Kuhn and
de Mori, 1990), who use so-called caching language
models to improve the performance of speech com-
prehension software. The concept of caching lan-
guage models is quite simple: a cache of recently
seen words is maintained, and the probability of
words in the cache is higher than those outside the
cache.
While the performance of caching language mod-
els is judged by their success in improving speech
recognition accuracy, it is also possible to use an
abstract measure to diagnose their efficacy more
closely. Church (2000) introduces such a diagnostic
for lexical priming: adaptation probabilities. Adap-
tation probabilities provide a method to separate the
general problem of priming from a particular imple-
mentation (i.e., caching models). They measure the
amount of priming that occurs for a given construc-
tion, and therefore provide an upper limit for the per-
formance of models such as caching models.
Adaptation is based upon three concepts. First is
the prior, which serves as a baseline. The prior mea-
sures the probability of a word appearing, ignoring
the presence or absence of a prime. Second is the
positive adaptation, which is the probability of a
word appearing given that it has been primed. Third
is the negative adaptation, the probability of a word
appearing given it has not been primed.
In Church?s case, the prior and adaptation prob-
abilities are estimated as follows. If a corpus is di-
vided into individual documents, then each docu-
ment is then split in half. We refer to the halves as the
prime set (or prime half) and the target set (or target
half).1 We measure how frequently a document half
contains a particular word. For each word w, there
are four combinations of the prime and target halves
containing the word. This gives us four frequencies
to measure, which are summarized in the following
table:
fwp,t fwp?,t
fwp,?t fwp?,?t
These frequencies represent:
fwp,t = # of times w occurs in prime set
and target set
fwp?,t = # of times w occurs in target set
but not prime set
fwp,?t = # of times w occurs in prime set
but not target set
fwp?,?t = # of times w does not occur in either
target set or prime set
In addition, let N represent the sum of these four
frequencies. From the frequencies, we may formally
define the prior, positive adaptation and negative
adaptation:
Prior Pprior(w) =
fwp,t + fw p?,t
N
(1)
Positive Adaptation P+(w) =
fwp,t
fwp,t + fwp,?t
(2)
Negative Adaptation P?(w) =
fw p?,t
fw p?,t+ fw p?,?t
(3)
In the case of lexical priming, Church observes that
P+  Pprior > P?. In fact, even in cases when Pprior
quite small, P+ may be higher than 0.8. Intuitively,
a positive adaptation which is higher than the prior
entails that a word is likely to reappear in the target
set given that it has already appeared in the prime
set. We intend to show that adaptation probabilities
provide evidence that syntactic constructions behave
1Our terminology differs from that of Church, who uses ?his-
tory? to describe the first half, and ?test? to describe the second.
Our terms avoid the ambiguity of the phrase ?test set? and coin-
cide with the common usage in the psycholinguistic literature.
828
similarity to lexical priming, showing positive adap-
tation P+ greater than the prior. As P? must become
smaller than Pprior whenever P+ is larger than Pprior,
we only report the positive adaptation P+ and the
prior Pprior.
While Church?s technique was developed with
speech recognition in mind, we will show that
it is useful for investigating psycholinguistic phe-
nomenon. However, the connection between cogni-
tive phenomenon and engineering approaches go in
both directions: it is possible that syntactic parsers
could be improved using a model of syntactic prim-
ing, just as speech recognition has been improved
using models of lexical priming.
3 Experiment 1: Parallelism in
Coordination
In this section, we investigate the use of Church?s
adaptation metrics to measure the effect of syntac-
tic parallelism in coordinated constructions. For the
sake of comparison, we restrict our study to several
constructions used in Frazier et al (2000). All of
these constructions occur in NPs with two coordi-
nate sisters, i.e., constructions such as NP1 CC NP2,
where CC represents a coordinator such as and.
3.1 Method
The application of the adaptation metric is straight-
forward: we pick NP1 as the prime set and NP2 as
the target set. Instead of measuring the frequency of
lexical elements, we measure the frequency of the
following syntactic constructions:
SBAR An NP with a relative clause, i.e.,
NP ? NP SBAR.
PP An NP with a PP modifier, i.e., NP ? NP PP.
NN An NP with a single noun, i.e., NP ? NN.
DT NN An NP with a determiner and a noun, i.e.,
NP ? DT NN.
DT JJ NN An NP with a determiner, an adjective
and a noun, i.e., NP ? DT JJ NN.
Parameter estimation is accomplished by iterating
through the corpus for applications of the rule NP
? NP CC NP. From each rule application, we create
a list of prime-target pairs. We then estimate adap-
tation probabilities for each construction, by count-
ing the number of prime-target pairs in which the
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 1: Adaptation within coordinate structures in
the Brown corpus
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 2: Adaptation within coordinate structures in
the WSJ corpus
construction does or does not occur. This is done
similarly to the document half case described above.
There are four frequencies of interest, but now they
refer to the frequency that a particular construction
(rather than a word) either occurs or does not occur
in the prime and target set.
To ensure results were general across genres, we
used all three parts of the English Penn Treebank:
the Wall Street Journal (WSJ), the balanced Brown
corpus of written text (Brown) and the Switchboard
corpus of spontaneous dialog. In each case, we use
the entire corpus.
Therefore, in total, we report 30 probabilities: the
prior and positive adaptation for each of the five con-
structions in each of the three corpora. The primary
objective is to observe the difference between the
prior and positive adaptation for a given construction
in a particular corpus. Therefore, we also perform a
?2 test to determine if the difference between these
two probabilities are statistically significant.
829
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 3: Adaptation within coordinate structures in
the Switchboard corpus
3.2 Results
The results are shown in Figure 1 for the Brown cor-
pus, Figure 2 for the WSJ and Figure 3 for Switch-
board. Each figure shows the prior and positive
adaptation for all five constructions: relative clauses
(SBAR) a PP modifier (PP), a single common noun
(N), a determiner and noun (DT N), and a determiner
adjective and noun (DT ADJ N). Only in the case of
a single common noun in the WSJ and Switchboard
corpora is the prior probability higher than the posi-
tive adaptation. In all other cases, the probability of
the given construction is more likely to occur in NP2
given that it has occurred in NP1. According to the
?2 tests, all differences between priors and positive
adaptations were significant at the 0.01 level. The
size of the data sets means that even small differ-
ences in probability are statistically significant. All
differences reported in the remainder of this paper
are statistically significant; we omit the details of in-
dividual ?2 tests.
3.3 Discussion
The main conclusion we draw is that the parallelism
effect in corpora mirrors the ones found experimen-
tally by Frazier et al (2000), if we assume higher
probabilities are correlated with easier human pro-
cessing. This conclusion is important, as the experi-
ments of Frazier et al (2000) only provided evidence
for parallelism in comprehension data. Corpus data,
however, are production data, which means that the
our findings are first ones to demonstrate parallelism
effects in production.
The question of the relationship between compre-
hension and production data is an interesting one.
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 4: Adaptation within sentences in the Brown
corpus
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 5: Adaptation within sentences in the WSJ
corpus
We can expect that production data, such as corpus
data, are generated by speakers through a process
that involves self-monitoring. Written texts (such as
the WSJ and Brown) involve proofreading and edit-
ing, i.e., explicit comprehension processes. Even the
data in a spontaneous speech corpus such as Swtich-
board can be expected to involve a certain amount
of self-monitoring (speakers listen to themselves and
correct themselves if necessary). It follows that it is
not entirely unexpected that similar effects can be
found in both comprehension and production data.
4 Experiment 2: Parallelism in Documents
The results in the previous section showed that
the parallelism effect, which so far had only been
demonstrated in comprehension studies, is also at-
tested in corpora, i.e., in production data. In the
present experiment, we will investigate the mech-
anisms underlying the parallelism effect. As dis-
cussed in Section 1, there are two possible explana-
830
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 6: Adaptation between sentences in the
Brown corpus
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 7: Adaptation between sentences in the WSJ
corpus
tion for the effect: one in terms of a construction-
specific copying mechanism, and one in terms of
a generalized syntactic priming mechanism. In the
first case, we predict that the parallelism effect is re-
stricted to coordinate structures, while in the second
case, we expect that parallelism (a) is independent of
coordination, and (b) occurs in the wider discourse,
i.e., not only within sentences but also between sen-
tences.
4.1 Method
The method used was the same as in Experiment 1
(see Section 3.1), with the exception that the prime
set and the target set are no longer restricted to
being the first and second conjunct in a coordi-
nate structure. We investigated three levels of gran-
ularity: within sentences, between sentences, and
within documents. Within-sentence parallelism oc-
curs when the prime NP and the target NP oc-
cur within the same sentence, but stand in an ar-
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 8: Adaptation within documents in the Brown
corpus (all items exhibit weak yet statistically signif-
icant positive adaptation)
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 9: Adaptation within documents in the WSJ
corpus
bitrary structural relationship. Coordinate NPs were
excluded from this analysis, so as to make sure that
any within-sentence parallelism is not confounded
coordination parallelism as established in Experi-
ment 1. Between-sentence parallelism was measured
by regarding as the target the sentence immediately
following the prime sentence. In order to investi-
gate within-document parallelism, we split the doc-
uments into equal-sized halves; then the adaptation
probability was computed by regarding the first half
as the prime and the second half as the target (this
method is the same as Church?s method for measur-
ing lexical adaptation).
The analyses were conducted using the Wall
Street Journal and the Brown portion of the Penn
Treebank. The document boundary was taken to be
the file boundary in these corpora. The Switchboard
corpus is a dialog corpus, and therefore needs to
be treated differently: turns between speakers rather
831
than sentences should be level of analysis. We will
investigate this separately in Experiment 3 below.
4.2 Results
The results for the within-sentence analysis are
graphed in Figures 4 and 5 for the Brown and WSJ
corpus, respectively. We find that there is a paral-
lelism effect in both corpora, for all the NP types
investigated. Figures 6?9 show that the same is true
also for the between-sentence and within-document
analysis: parallelism effects are obtained for all NP
types and for both corpora, even it the parallel struc-
tures occur in different sentences or in different doc-
ument halves. (The within-document probabilities
for the Brown corpus (in Figure 8) are close to one
in most cases; the differences between the prior and
adaptation are nevertheless significant.)
In general, note that the parallelism effects un-
covered in this experiment are smaller than the
effect demonstrated in Experiment 1: The differ-
ences between the prior probabilities and the adap-
tation probabilities (while significant) are markedly
smaller than those uncovered for parallelism in co-
ordinate structure.2
4.3 Discussion
This experiment demonstrated that the parallelism
effect is not restricted to coordinate structures.
Rather, we found that it holds across the board: for
NPs that occur in the same sentence (and are not part
of a coordinate structure), for NPs that occur in ad-
jacent sentences, and for NPs that occur in differ-
ent document halves. The between-sentence effect
has been demonstrated in a more restricted from by
Gries (2005) and Szmrecsanyi (2005), who investi-
gate priming in corpora for cases of structural choice
(e.g., between a dative object and a PP object for
verbs like give). The present results extend this find-
ing to arbitrary NPs, both within and between sen-
tences.
The fact that parallelism is a pervasive phe-
nomenon, rather than being limited to coordinate
structures, strongly suggests that it is an instance of
a general syntactic priming mechanism, which has
been an established feature of accounts of the human
sentence production system for a while (e.g., Bock,
2The differences between the priors and adaptation proba-
bilities are also much smaller than noted by Church (2000). The
probabilities of the rules we investigate have a higher marginal
probability than the lexical items of interest to Church.
1986). This runs counter to the claims made by Fra-
zier et al (2000) and Frazier and Clifton (2001), who
have argued that parallelism only occurs in coordi-
nate structures, and should be accounted for using a
specialized copying mechanism. (It is important to
bear in mind, however, that Frazier et al only make
explicit claims about comprehension, not about pro-
duction.)
However, we also found that parallelism effects
are clearly strongest in coordinate structures (com-
pare the differences between prior and adaptation
in Figures 1?3 with those in Figures 4?9). This
could explain why Frazier et al?s (2000) experi-
ments failed to find a significant parallelism effect
in non-coordinated structures: the effect is simply
too week to detect (especially using the self-paced
reading paradigm they employed).
5 Experiment 3: Parallelism in
Spontaneous Dialog
Experiment 1 showed that parallelism effects can be
found not only in written corpora, but also in the
Switchboard corpus of spontaneous dialog. We did
not include Switchboard in our analysis in Experi-
ment 2, as this corpus has a different structure from
the two text corpora we investigated: it is organized
in terms of turns between two speakers. Here, we
exploit this property and conduct a further experi-
ment in which we compare parallelism effects be-
tween speakers and within speakers.
The phenomenon of structural repetition between
speakers has been discussed in the experimental
psycholinguistic literature (see Pickering and Gar-
rod 2004 for a review). According to Pickering
and Garrod (2004), the act of engaging in a dia-
log facilitates the use of similar representations at
all linguistic levels, and these representations are
shared between speech production and comprehen-
sion processes. Thus structural adaptation should be
observed in a dialog setting, both within and be-
tween speakers. An alternative view is that produc-
tion and comprehension processes are distinct. Bock
and Loebell (1990) suggest that syntactic priming
in speech production is due to facilitation of the
retrieval and assembly procedures that occur dur-
ing the formulation of utterances. Bock and Loebell
point out that this production-based procedural view
predicts a lack of priming between comprehension
and production or vice versa, on the assumption that
832
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 10: Adaptation between speakers in the
Switchboard corpus
production and parsing use distinct mechanisms. In
our terms, it predicts that between-speaker positive
adaptation should not be found, because it can only
result from priming from comprehension to produc-
tion, or vice versa. Conversely, the prodedural view
outlined by Bock and Loebell predicts that positive
adaptation should be found within a given speaker?s
dialog turns, because such adaptation can indeed be
the result of the facilitation of production routines
within a given speaker.
5.1 Method
We created two sets of prime and target data to
test within-speaker and between-speaker adaptation.
The prime and target sets were defined in terms of
pairs of utterances. To test between-speaker adapta-
tion, we took each adjacent pair of utterances spo-
ken by speaker A and speaker B, in each dialog, and
these were treated as prime and target sets respec-
tively. In the within-speaker analysis, the prime and
target sets were taken from the dialog turns of only
one speaker?we took each adjacent pair of dialog
turns uttered by a given speaker, excluding the in-
tervening utterance of the other speaker. The earlier
utterance of the pair was treated as the prime, and
the later utterance as the target. The remainder of
the method was the same as in Experiments 1 and 2
(see Section 3.1).
5.2 Results
The results for the between-speaker and within-
speaker adaptation are shown in Figure 10 and Fig-
ure 11 for same five phrase types as in the previous
experiments.
PP SBAR N DT N DT ADJ N0
0.5
1
Pr
ob
ab
ili
ty
Prior
Adaptation
Figure 11: Adaptation within speakers in the Switch-
board corpus
A positive adaptation effect can be seen in the
between-speaker data. For each phrase type, the
adaptation probability is greater than the prior. In the
within-speaker data, by comparison, the magnitude
of the adaptation advantage is greatly decreased, in
comparison with Figure 10. Indeed, for most phrase
types, the adaptation probability is lower than the
prior, i.e., we have a case of negative adaptation.
5.3 Discussion
The results of the two analyses confirm that adap-
tation can indeed be found between speakers in di-
alog, supporting the results of experimental work
reviewed by Pickering and Garrod (2004). The re-
sults do not support the notion that priming is due
to the facilitation of production processes within a
given speaker, an account which would have pre-
dicted adaptation within speakers, but not between
speakers.
The lack of clear positive adaptation effects in
the within-speaker data is harder to explain?all
current theories of priming would predict some ef-
fect here. One possibility is that such effects may
have been obscured by decay processes: doing a
within-speaker analysis entails skipping an interven-
ing turn, in which priming effects were lost. We in-
tend to address these concerns using more elaborate
experimental designs in future work.
6 Conclusions
In this paper, we have demonstrated a robust, perva-
sive effect of parallelism for noun phrases. We found
the tendency for structural repetition in two different
corpora of written English, and also in a dialog cor-
833
pus. The effect occurs in a wide range of contexts:
within coordinate structures (Experiment 1), within
sentences for NPs in an arbitrary structural config-
uration, between sentences, and within documents
(Experiment 2). This strongly indicates that the par-
allelism effect is an instance of a general processing
mechanism, such as syntactic priming (Bock, 1986),
rather than specific to coordination, as suggested
by (Frazier and Clifton, 2001). However, we also
found that the parallelism effect is strongest in co-
ordinate structures, which could explain why com-
prehension experiments so far failed to demonstrate
the effect for other structural configurations (Frazier
et al, 2000). We leave it to future work to explain
why adaptation is much stronger in co-ordination:
is co-ordination special because of extra constrains
(i.e., some kind of expected contrast/comparison be-
tween co-ordinate sisters) or because of fewer con-
straints (i.e., both co-ordinate sisters have a similar
grammatical role in the sentence)?
Another result (Experiment 3) is that the paral-
lelism effect occurs between speakers in dialog. This
finding is compatible with Pickering and Garrod?s
(2004) interactive alignment model, and strengthens
the argument for parallelism as an instance of a gen-
eral priming mechanism.
Previous experimental work has found parallelism
effects, but only in comprehension data. The present
work demonstrates that parallelism effects also oc-
cur in production data, which raises an interesting
question of the relationship between the two data
types. It has been hypothesized that the human lan-
guage processing system is tuned to mirror the prob-
ability distributions in its environment, including the
probabilities of syntactic structures (Mitchell et al,
1996). If this tuning hypothesis is correct, then the
parallelism effect in comprehension data can be ex-
plained as an adaptation of the human parser to the
prevalence of parallel structures in its environment
(as approximated by corpus data) that we demon-
strated in this paper.
Note that the results in this paper not only have an
impact on theoretical issues regarding human sen-
tence processing, but also on engineering problems
in natural language processing, e.g., in probabilistic
parsing. To avoid sparse data problems, probabilistic
parsing models make strong independence assump-
tions; in particular, they generally assume that sen-
tences are independent of each other. This is partly
due to the fact it is difficult to parameterize the many
possible dependencies which may occur between
adjacent sentences. However, in this paper, we show
that structure re-use is one possible way in which
the independence assumption is broken. A simple
and principled approach to handling structure re-use
would be to use adaptation probabilities for prob-
abilistic grammar rules, analogous to cache proba-
bilities used in caching language models (Kuhn and
de Mori, 1990). We are currently conducting further
experiments to investigate of the effect of syntactic
priming on probabilistic parsing.
References
Bock, J. Kathryn. 1986. Syntactic persistence in language pro-
duction. Cognitive Psychology 18:355?387.
Bock, Kathryn and Helga Loebell. 1990. Framing sentences.
Cognition 35(1):1?39.
Branigan, Holly P., Marin J. Pickering, and Janet F. McLean.
2005. Priming prepositional-phrase attachment during com-
prehension. Journal of Experimental Psychology: Learning,
Memory and Cognition 31(3):468?481.
Carlson, Katy. 2002. The effects of parallelism and prosody on
the processing of gapping structures. Language and Speech
44(1):1?26.
Church, Kenneth W. 2000. Empirical estimates of adaptation:
the chance of two Noriegas is closer to p/2 than p2. In Pro-
ceedings of the 17th Conference on Computational Linguis-
tics. Saarbru?cken, Germany, pages 180?186.
Frazier, Lyn, Alan Munn, and Chuck Clifton. 2000. Processing
coordinate structures. Journal of Psycholinguistic Research
29(4):343?370.
Frazier, Lyn, Lori Taft, Tom Roeper, Charles Clifton, and Kate
Ehrlich. 1984. Parallel structure: A source of facilitation in
sentence comprehension. Memory and Cognition 12(5):421?
430.
Frazier, Lynn and Charles Clifton. 2001. Parsing coordinates
and ellipsis: Copy ?. Syntax 4(1):1?22.
Gries, Stefan T. 2005. Syntactic priming: A corpus-based ap-
proach. Journal of Psycholinguistic Research 35.
Kuhn, Roland and Renate de Mori. 1990. A cache-based natural
language model for speech recognition. IEEE Transanctions
on Pattern Analysis and Machine Intelligence 12(6):570?
583.
Mauner, Gail, Michael K. Tanenhaus, and Greg Carlson. 1995.
A note on parallelism effects in processing deep and surface
verb-phrase anaphors. Language and Cognitive Processes
10:1?12.
Mitchell, Don C., Fernando Cuetos, Martin M. B. Corley, and
Marc Brysbaert. 1996. Exposure-based models of human
parsing: Evidence for the use of coarse-grained (non-lexical)
statistical records. Journal of Psycholinguistic Research
24(6):469?488.
Pickering, Martin J. and Simon Garrod. 2004. Toward a mech-
anistic psychology of dialogue. Behavioral and Brain Sci-
ences 27(2):169?225.
Szmrecsanyi, Benedikt. 2005. Creatures of habit: A corpus-
linguistic analysis of persistence in spoken English. Corpus
Linguistics and Linguistic Theory 1(1):113?149.
834
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 304?312,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
A Model of Discourse Predictions in Human Sentence Processing
Amit Dubey and Frank Keller and Patrick Sturt
Human Communication Research Centre, University of Edinburgh
10 Crichton Street, Edinburgh EH8 9AB, UK
{amit.dubey,frank.keller,patrick.sturt}@ed.ac.uk
Abstract
This paper introduces a psycholinguistic
model of sentence processing which combines
a Hidden Markov Model noun phrase chun-
ker with a co-reference classifier. Both mod-
els are fully incremental and generative, giv-
ing probabilities of lexical elements condi-
tional upon linguistic structure. This allows
us to compute the information theoretic mea-
sure of surprisal, which is known to correlate
with human processing effort. We evaluate
our surprisal predictions on the Dundee corpus
of eye-movement data show that our model
achieve a better fit with human reading times
than a syntax-only model which does not have
access to co-reference information.
1 Introduction
Recent research in psycholinguistics has seen a
growing interest in the role of prediction in sentence
processing. Prediction refers to the fact that the hu-
man sentence processor is able to anticipate upcom-
ing material, and that processing is facilitated when
predictions turn out to be correct (evidenced, e.g.,
by shorter reading times on the predicted word or
phrase). Prediction is presumably one of the factors
that contribute to the efficiency of human language
understanding. Sentence processing is incremental
(i.e., it proceeds on a word-by-word basis); there-
fore, it is beneficial if unseen input can be antici-
pated and relevant syntactic and semantic structure
constructed in advance. This allows the processor to
save time and makes it easier to cope with the con-
stant stream of new input.
Evidence for prediction has been found in a range
of psycholinguistic processing domains. Semantic
prediction has been demonstrated by studies that
show anticipation based on selectional restrictions:
listeners are able to launch eye-movements to the
predicted argument of a verb before having encoun-
tered it, e.g., they will fixate an edible object as soon
as they hear the word eat (Altmann and Kamide,
1999). Semantic prediction has also been shown in
the context of semantic priming: a word that is pre-
ceded by a semantically related prime or by a seman-
tically congruous sentence fragment is processed
faster (Stanovich and West, 1981; Clifton et al,
2007). An example for syntactic prediction can be
found in coordinate structures: readers predict that
the second conjunct in a coordination will have the
same syntactic structure as the first conjunct (Fra-
zier et al, 2000). In a similar vein, having encoun-
tered the word either, readers predict that or and a
conjunct will follow it (Staub and Clifton, 2006).
Again, priming studies corroborate this: Compre-
henders are faster at naming words that are syntacti-
cally compatible with prior context, even when they
bear no semantic relationship to it (Wright and Gar-
rett, 1984).
Predictive processing is not confined to the sen-
tence level. Recent experimental results also provide
evidence for discourse prediction. An example is the
study by van Berkum et al (2005), who used a con-
text that made a target noun highly predictable, and
found a mismatch effect in the ERP (event-related
brain potential) when an adjective appeared that was
inconsistent with the target noun. An example is (we
give translations of their Dutch materials):
(1) The burglar had no trouble locating the secret
family safe.
a. Of course, it was situated behind a
304
bigneu but unobtrusive paintingneu.
b. Of course, it was situated behind a
bigcom but unobtrusive bookcasecom.
Here, the adjective big, which can have neutral or
common gender in Dutch, is consistent with the pre-
dicted noun painting in (1-a), but inconsistent with it
in (1-b), leading to a mismatch ERP on big in (1-b)
but not in (1-a).
Previous results on discourse effects in sentence
processing can also be interpreted in terms of pre-
diction. In a classical paper, Altmann and Steed-
man (1988) demonstrated that PP-attachment pref-
erences can change through discourse context: if the
context contains two potential referents for the tar-
get NP, then NP-attachment of a subsequent PP is
preferred (to disambiguate between the two refer-
ents), while if the context only contains one target
NP, VP-attachment is preferred (as there is no need
to disambiguate). This result (and a large body of
related findings) is compatible with an interpretation
in which the processor predicts upcoming syntactic
attachment based on the presence of referents in the
preceding discourse.
Most attempts to model prediction in human lan-
guage processing have focused on syntactic pre-
diction. Examples include Hale?s (2001) surprisal
model, which relates processing effort to the con-
ditional probability of the current word given the
previous words in the sentence. This approach has
been elaborated by Demberg and Keller (2009) in a
model that explicitly constructs predicted structure,
and includes a verification process that incurs ad-
ditional processing cost if predictions are not met.
Recent work has attempted to integrate semantic
and discourse prediction with models of syntactic
processing. This includes Mitchell et al?s (2010)
approach, which combines an incremental parser
with a vector-space model of semantics. However,
this approach only provides a loose integration of
the two components (through simple addition of
their probabilities), and the notion of semantics used
is restricted to lexical meaning approximated by
word co-occurrences. At the discourse level, Dubey
(2010) has proposed a model that combines an incre-
mental parser with a probabilistic logic-based model
of co-reference resolution. However, this model
does not explicitly model discourse effects in terms
of prediction, and again only proposes a loose in-
tegration of co-reference and syntax. Furthermore,
Dubey?s (2010) model has only been tested on two
experimental data sets (pertaining to the interaction
of ambiguity resolution with context), no broad cov-
erage evaluation is available.
The aim of the present paper is to overcome these
limitations. We propose a computational model that
captures discourse effects on syntax in terms of pre-
diction. The model comprises a co-reference com-
ponent which explicitly stores discourse mentions
of NPs, and a syntactic component which adjust
the probabilities of NPs in the syntactic structure
based on the mentions tracked by the discourse com-
ponent. Our model is HMM-based, which makes
it possible to efficiently process large amounts of
data, allowing an evaluation on eye-tracking cor-
pora, which has recently become the gold-standard
in computational psycholinguistics (e.g., Demberg
and Keller 2008; Frank 2009; Boston et al 2008;
Mitchell et al 2010).
The paper is structured as follows: In Section 2,
we describe the co-reference and the syntactic mod-
els and evaluate their performance on standard data
sets. Section 3 presents an evaluation of the overall
model on the Dundee eye-tracking corpus. The pa-
per closes with a comparison with related work and
a general discussion in Sections 4 and 5.
2 Model
This model utilises an NP chunker based upon a hid-
den Markov model (HMM) as an approximation to
syntax. Using a simple model such as an HMM fa-
cilitates the integration of a co-reference component,
and the fact that the model is generative is a prereq-
uisite to using surprisal as our metric of interest (as
surprisal require the computation of prefix probabil-
ities). The key insight in our model is that human
sentence processing is, on average, facilitated when
a previously-mentioned discourse entity is repeated.
This facilitation depends upon keeping track of a list
of previously-mentioned entities, which requires (at
the least) shallow syntactic information, yet the fa-
cilitation itself is modeled primarily as a lexical phe-
nomenon. This allows a straightforward separation
of concerns: shallow syntax is captured using the
HMM?s hidden states, whereas the co-reference fa-
305
cilitation is modeled using the HMM?s emissions.
The vocabulary of hidden states is described in Sec-
tion 2.1 and the emission distribution in Section 2.2
2.1 Syntactic Model
A key feature of the co-reference component of our
model (described below) is that syntactic analysis
and co-reference resolution happen simultaneously.
This could potentially slow down the syntactic anal-
ysis, which tends to already be quite slow for ex-
haustive surprisal-based incremental parsers. There-
fore, rather than using full parsing, we use an HMM-
based NP chunker which allows for a fast analysis.
NP chunking is sufficient to extract NP discourse
mentions and, as we show below, surprisal values
computed using HMM chunks provide a useful fit
on the Dundee eye-movement data.
To allow the HMM to handle possessive construc-
tions as well as NP with simple modifiers and com-
plements, the HMM decodes NP subtrees with depth
of 2, by encoding the start, middle and end of a
syntactic category X as ?(X?, ?X? and ?X)?, respec-
tively. To reduce an explosion in the number of
states, the category begin state ?(X? only appears at
the rightmost lexical token of the constituent?s left-
most daughter. Likewise, ?X)? only appears at the
leftmost lexical token of the constituent?s rightmost
daughter. An example use of this state vocabulary
can be seen in Figure 1. Here, a small degree of re-
cursion allows for the NP ((new york city?s) general
obligation fund) to be encoded, with the outer NP?s
left bracket being ?announced? at the token ?s, which
is the rightmost lexical token of the inner NP. Hid-
den states also include part-of-speech (POS) tags,
allowing simultaneous POS tagging. In the exam-
ple given in Figure 1, the full state can be read by
listing the labels written above a word, from top to
bottom. For example, the full state associated with
?s is (NP-NP)-POS. As ?s can also be a contraction
of is, another possible state for ?s is VBZ (without
recursive categories as we are only interested in NP
chunks).
The model uses unsmoothed bi-gram transition
probabilities, along with a maximum entropy dis-
tribution to guess unknown word features. The re-
sulting distribution has the form P(tag|word) and is
therefore unsuitable for computing surprisal values.
However, using Bayes? theorem we can compute:
P(word|tag) = P(tag|word)P(word)P(tag) (1)
which is what we need for surprisal. The pri-
mary information from this probability comes from
P(tag|word), however, reasonable estimates of
P(tag) and P(word) are required to ensure the prob-
ability distribution is proper. P(tag) may be esti-
mated on a parsed treebank. P(word), the probabil-
ity of a particular unseen word, is difficult to esti-
mate directly. Given that our training data contains
approximately 106 words, we assume that this prob-
ability must be bounded above by 10?6. As an ap-
proximation, we use this upper bound as the proba-
bility of P(word).
Training The chunker is trained on sections 2?
22 of the Wall Street Journal section of the Penn
Treebank. CoNLL 2000 included chunking as a
shared task, and the results are summarized by Tjong
Kim Sang and Buchholz (2000). Our chunker is not
comparable to the systems in the shared task for sev-
eral reasons: we use more training data, we tag si-
multaneously (the CoNLL systems used gold stan-
dard tags) and our notion of a chunk is somewhat
more complex than that used in CoNLL. The best
performing chunker from CoNLL 2000 achieved an
F-score of 93.5%, and the worst performing system
an F-score of 85.8%. Our chunker achieves a com-
parable F-score of 85.5%, despite the fact that it si-
multaneously tags and chunks, and only uses a bi-
gram model.
2.2 Co-Reference Model
In a standard HMM, the emission probabilities are
computed as P(wi|si) where wi is the ith word and si
is the ith state. In our model, we replace this with a
choice between two alternatives:
P(wi|si) =
{ ?Pseen before(wi|si)
(1??)Pdiscourse new(wi|si) (2)
The ?discourse new? probability distribution is the
standard HMM emission distribution. The ?seen be-
fore? distribution is more complicated. It is in part
based upon caching language models. However, the
contents of the cache are not individual words but
306
(NP NP NP NP)
(NP NP) (NP NP NP NP) NP (NP NP NP)
JJ NN IN NNP NNP NNP POS JJ NN NNS VBN RP DT NN NN
strong demand for new york city ?s general obligation bonds propped up the municipal market
Figure 1: The chunk notation of a tree from the training data.
Variable Type
l, l? List of trie nodes
w,wi Words
t Tag
n,n? Trie nodes
l? List(root of mention trie)
for w? w0 to wn do
l?? l
l? /0
Clear tag freq array f t
Clear word freq array f wt
for t ? tag set do
for n ? l? do
f t(t)? f t(t)+FreqO f (n, t)
n?? Getchild(w, t)
if n? 6= /0 then
f wt(t)? f wt(t)+FreqO f (n?,w, t)
l? n? :: l
end if
end for
end for
Pseen before(w|t) = f t(t)/ f wt(t)
end for
Figure 2: Looking up entries from the NP Cache
rather a collection of all NPs mentioned so far in the
document.
Using a collection of NPs rather than individual
words complicates the decoding process. If m is the
size of a document, and n is the size of the current
sentence, decoding occurs in O(mn) time as opposed
to O(n), as the collection of NPs needs to be ac-
cessed at each word. However, we do not store the
NPs in a list, but rather a trie. This allows decoding
to occur in O(n logm) time, which we have found
to be quite fast in practise. The algorithm used to
keep track of currently active NPs is presented in
Figure 2. This shows how the distribution Pseen before
is updated on a word-by-word basis. At the end of
each sentence, the NPs of the Viterbi parse are added
to the mention trie after having their leading arti-
cles stripped. A weakness of the algorithm is that
mentions are only added on a sentence-by-sentence
basis (disallowing within-sentence references). Al-
though the algorithm is intended to find whole-string
matches, in practise, it will count any NP whose pre-
fix matches as being co-referent.
A consequence of Equation 2 is that co-reference
resolution is handled at the same time as HMM de-
coding. Whenever the ?seen before? distribution is
applied, an NP is co-referent with one occurring ear-
lier. Likewise, whenever the ?discourse new? dis-
tribution is applied, the NP is not co-referent with
any NP appearing previously. As one choice or the
other is made during decoding, the decoder there-
fore also selects a chain of co-referent entities. Gen-
erally, for words which have been used in this dis-
course, the magnitude of probabilities in the ?seen
before? distribution are much higher than in the ?dis-
course new? distribution. Thus, there is a strong
bias to classify NPs which match word-for-word as
being co-referent. There remains a possibility that
the model primarily captures lexical priming, rather
than co-reference. However, we note that string
match is a strong indicator of two NPs being corefer-
307
ent (cf. Soon et al 2001), and, moreover, the match-
ing is done on an NP-by-NP basis, which is more
suitable for finding entity coreference, rather than a
word-by-word basis, which would be more suitable
for lexical priming.
An appealing side-effect of using a simple co-
reference decision rule which is applied incremen-
tally is that it is relatively simple to incremen-
tally compute the transitive closure of co-reference
chains, resulting in the entity sets which are then
used in evaluation.
The co-reference model only has one free param-
eter, ?, which is estimated from the ACE-2 corpus.
The estimate is computed by counting how often a
repeated NP actually is discourse new. In the current
implementation of the model, ? is constant through-
out the test runs. However, ? could possibly be
a function of the previous discourse, allowing for
more complicated classification probabilities.
3 Evaluation
3.1 Data
Our evaluation experiments were conducted upon
the Dundee corpus (Kennedy et al, 2003), which
contains the eye-movement record of 10 participants
each reading 2,368 sentences of newspaper text.
This data set has previously been used by Demberg
and Keller (2008) and Frank (2009) among others.
3.2 Evaluation
Eye tracking data is noisy for a number of rea-
sons, including the fact that experimental partici-
pants can look at any word which is currently dis-
played. While English is normally read in a left-
to-right manner, readers often skip words or make
regressions (i.e., look at a word to the left of the
one they are currently fixating). Deviations from
a strict left-to-right progression of fixations moti-
vate the need for several different measures of eye
movement. The model presented here predicts the
Total Time that participants spent looking at a re-
gion, which includes any re-fixations after looking
away. In addition to total time, other possible mea-
sures include (a) First Pass, which measures the ini-
tial fixation and any re-fixations before looking at
any other word (this occurs, for instance, if the eye
initially lands at the start of a long word ? the eye
will tend to re-fixate on a more central viewing lo-
cation), (b) Right Bounded reading time, which in-
cludes all fixations on a word before moving to the
right of the word (i.e., re-fixations after moving left
are included), and (c) Second Pass, which includes
any re-fixation on a word after looking at any other
word (be it to the left or the right of the word of inter-
est). We found that the model performed similarly
across all these reading time metrics, we therefore
only report results for Total Time.
As mentioned above, reading measures are hy-
pothesised to correlate with Surprisal, which is de-
fined as:
S(wt) =? log(P(wt |w1...wt1) (3)
We compute the surprisal scores for the syntax-only
HMM, which does not have access to co-reference
information (henceforth referred to as ?HMM?)
and the full model, which combines the syntax-
only HMM with the co-reference model (henceforth
?HMM+Ref?). To determine if our Dundee corpus
simulations provide a reasonable model of human
sentence processing, we perform a regression anal-
ysis with the Dundee corpus reading time measure
as the dependent variable and the surprisal scores as
the independent variable.
To account for noise in the corpus, we also use
a number of additional explanatory variables which
are known to strongly influence reading times.
These include the logarithm of the frequency of a
word (measured in occurrences per million) and the
length of a word in letters. Two additional explana-
tory variables were available in the Dundee corpus,
which we also included in the regression model.
These were the position of a word on a line, and
which line in a document a word appeared in. As
participants could only view one line at a time (i.e.,
one line per screen), these covariates are known as
line position and screen position, respectively.
All the covariates, including the surprisal es-
timates, were centered before including them in
the regression model. Because the HMM and
HMM+Ref surprisal values are highly collinear, the
HMM+Ref surprisal values were added as residuals
of the HMM surprisal values.
In a normal regression analysis, one must either
assume that participants or the particular choice of
308
items add some randomness to the experiment, and
either each participant?s responses for all items must
be averaged (treating participants as a random fac-
tor), or all participant?s responses for each item is
averaged (treating items as a random factor). How-
ever, in the present analysis we utilise a mixed ef-
fects model, which allows both items and partici-
pants to be treated as random factors.1
The are a number of criteria which can be used
to test the efficacy of one regression model over an-
other. These include the Aikake Information Cri-
terion (AIC), the Bayesian Information Criterion
(BIC), which trade off model fit and number of
model parameters (lower scores are better). It is also
common to compare the log-likelihood of the mod-
els (higher log-likelihood is better), in which case a
?2 can be used to evaluate if a model offers a sig-
nificantly better fit, given the number of parameters
is uses. We test three models: (i) a baseline, with
only low-level factors as independent variables; (ii)
the HMM model, with the baseline factors plus sur-
prisal computed by the syntax-only HMM; and (iii)
the HMM+Ref model which includes the raw sur-
prisal values of the syntax-only HMM and the sur-
prisal of the HMM+Ref models as computed as a
residual of the HMM surprisal score. We compare
the HMM and HMM+Ref to the baseline, and the
HMM+Ref model against the HMM model.
Some of the data needed to be trimmed. If, due to
data sparsity, the surprisal of a word goes to infinity
for one of the models, we entirely remove that word
from the analysis. This occurred seven times form
the HMM+Ref model, but did not occur at all with
the HMM model. Some of the eye-movement data
was trimmed, as well. Fixations on the first and last
words of a line were excluded, as were tracklosses.
However, we did not trim any items due to abnor-
1We assume that each participant and item bias the reading
time of the experiment. Such an analysis is known as having
random intercepts of participant and item. It is also possible
to assume a more involved analysis, known as random slopes,
where the participants and items bias the slope of the predictor.
The model did not converge when using random intercept and
slopes on both participant and item. If random slopes on items
were left out, the HMM regression model did converge, but not
the HMM+Ref model. As the HMM+Ref is the model of inter-
est random slopes were left out entirely to allow a like-with-like
comparison between the HMM and HMM+Ref regression mod-
els.
mally short or abnormally long fixation durations.
3.3 Results
The result of the model comparison on Total Time
reading data is summarised in Table 1. To allow this
work to be compared with other models, the lower
part of the table gives the abosolute AIC, BIC and
log likelihood of the baseline model, while the upper
part gives delta AIC, BIC and log likelihood scores
of pairs of models.
We found that both the HMM and HMM+Ref
provide a significantly better fit with the reading
time data than the Baseline model; all three crite-
ria agree: AIC and BIC lower than for the base-
line, and log-likelihood is higher. Moreover, the
HMM+Ref model provides a significantly better fit
than the HMM model, which demonstrates the bene-
fit of co-reference information for modeling reading
times. Again, all three measures provide the same
result.
Table 2 corroborates this result. It list the
mixed-model coefficients for the HMM+Ref model
and shows that all factors are significant predic-
tors, including both HMM surprisal and residualized
HMM+Ref surprisal.
4 Related Work
There have been few computational models of hu-
man sentence processing that have incorporated
a referential or discourse-level component. Niv
(1994) proposed a parsing model based on Com-
binatory Categorial Grammar (Steedman, 2001), in
which referential information was used to resolve
syntactic ambiguities. The model was able to cap-
ture effects of referential information on syntactic
garden paths (Altmann and Steedman, 1988). This
model differs from that proposed in the present pa-
per, as it is intended to capture psycholinguistic pref-
erences in a qualitative manner, whereas the aim
of the present model is to provide a quantitative
fit to measures of processing difficulty. Moreover,
the model was not based on a large-scale grammar,
and was not tested on unrestricted text. Spivey and
Tanenhaus (1998) proposed a sentence processing
model that examined the effects of referential infor-
mation, as well as other constraints, on the resolu-
tion of ambiguous sentences. Unlike Niv (1994),
309
From To ? AIC ? BIC ? logLik ?2 Significance
Baseline HMM -80 -69 41 82.112 p < .001
Baseline HMM+Ref -99 -89 51 101.54 p < .001
HMM HMM+Ref -19 -8 11 21.424 p < .001
Model AIC BIC logLik
Baseline 10567789 10567880 -5283886
Table 1: Model comparison (upper part) and absolute scores for the Baseline model (lower part)
Coefficient Estimate Std Error t-value
(Intercept) 991.4346 23.7968 41.66
log(Word Frequency) -55.3045 1.4830 -37.29
Word Length 128.6216 1.4677 87.63
Screen Position -1.7769 0.1326 -13.40
Line Position 10.1592 0.7387 13.75
HMM 12.1287 1.3366 9.07
HMM+Ref 19.2772 4.1627 4.63
Table 2: Coefficients of the HMM+Ref model on Total Reading Times. Note that t > 2 indicates that the factor in
question is a significant predictor.
Spivey and Tanenhaus?s (1998) model was specifi-
cally designed to provide a quantitative fit to reading
times. However, the model lacked generality, being
designed to deal with only one type of sentence. In
contrast to both of these earlier models, the model
proposed here aims to be general enough to provide
estimated reading times for unrestricted text. In fact,
as far as we are aware, the present paper represents
the first wide-coverage model of human parsing that
has incorporated discourse-level information.
5 Discussion
The primary finding of this work is that incorporat-
ing discourse information such as co-reference into
an incremental probabilistic model of sentence pro-
cessing has a beneficial effect on the ability of the
model to predict broad-coverage human parsing be-
haviour.
Although not thoroughly explored in this paper,
our finding is related to an ongoing debate about the
structure of the human sentence processor. In par-
ticular, the model of Dubey (2010), which also sim-
ulates the effect of discourse on syntax, is aimed at
examining interactivity in the human sentence pro-
cessor. Interactivity describes the degree to which
human parsing is influenced by non-syntactic fac-
tors. Under the weakly interactive hypothesis, dis-
course factors may prune or re-weight parses, but
only when assuming the strongly interactive hypoth-
esis would we argue that the sentence processor pre-
dicts upcoming material due to discourse factors.
Dubey found that a weakly interactive model sim-
ulated a pattern of results in an experiment (Grodner
et al, 2005) which was previously believed to pro-
vide evidence for the strongly interactive hypothesis.
However, as Dubey does not provide broad-coverage
parsing results, this leaves open the possibility that
the model cannot generalise beyond the experiments
expressly modeled in Dubey (2010).
The model presented here, on the other hand,
is not only broad-coverage but could also be de-
scribed as a strongly interactive model. The strong
interactivity arises because co-reference resolution
is strongly tied to lexical generation probabilities,
which are part of the syntactic portion of our model.
This cannot be achieve in a weakly interactive
model, which is limited to pruning or re-weighting
of parses based on discourse information. As our
analysis on the Dundee corpus showed, the lexical
probabilities (in the form of HMM+Ref surprisal)
are key to improving the fit on eye-tracking data.
We therefore argue that our results provide evidence
310
against a weakly interactive approach, which may be
sufficient to model individual phenomena (as shown
by Dubey 2010), but is unlikely to be able to match
the broad-coverage result we have presented here.
We also note that psycholinguistic evidence for dis-
course prediction (such as the context based lexi-
cal prediction shown by van Berkum et al 2005,
see Section 1) is also evidence for strong interac-
tivity; prediction goes beyond mere pruning or re-
weighting and requires strong interactivity.
References
Gerry Altmann and Mark Steedman. Interaction
with context during human sentence processing.
Cognition, 30:191?238, 1988.
Gerry T. M. Altmann and Yuki Kamide. Incremen-
tal interpretation at verbs: Restricting the domain
of subsequent reference. Cognition, 73:247?264,
1999.
Marisa Ferrara Boston, John T. Hale, Reinhold
Kliegl, and Shravan Vasisht. Surprising parser
actions and reading difficulty. In Proceedings of
ACL-08:HLT, Short Papers, pages 5?8, 2008.
Charles Clifton, Adrian Staub, and Keith Rayner.
Eye movement in reading words and sentences.
In R V Gompel, M Fisher, W Murray, and R L
Hill, editors, Eye Movements: A Window in Mind
and Brain, pages 341?372. Elsevier, 2007.
Vera Demberg and Frank Keller. Data from eye-
tracking corpora as evidence for theories of syn-
tactic processing complexity. Cognition, 109:
192?210, 2008.
Vera Demberg and Frank Keller. A computational
model of prediction in human parsing: Unifying
locality and surprisal effects. In Proceedings of
the 29th meeting of the Cognitive Science Society
(CogSci-09), 2009.
Amit Dubey. The influence of discourse on syntax:
A psycholinguistic model of sentence processing.
In Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics (ACL
2010), Uppsala, Sweden, 2010.
Stefan Frank. Surprisal-based comparison between
a symbolic and a connectionist model of sentence
processing. In 31st Annual Conference of the
Cognitive Science Society (COGSCI 2009), Ams-
terdam, The Netherlands, 2009.
Lyn Frazier, Alan Munn, and Charles Clifton. Pro-
cessing coordinate structure. Journal of Psy-
cholinguistic Research, 29:343?368, 2000.
Daniel J. Grodner, Edward A. F. Gibson, and Du-
ane Watson. The influence of contextual constrast
on syntactic processing: Evidence for strong-
interaction in sentence comprehension. Cogni-
tion, 95(3):275?296, 2005.
John T. Hale. A probabilistic earley parser as a psy-
cholinguistic model. In In Proceedings of the Sec-
ond Meeting of the North American Chapter of
the Asssociation for Computational Linguistics,
2001.
A. Kennedy, R. Hill, and J. Pynte. The dundee cor-
pus. In Proceedings of the 12th European confer-
ence on eye movement, 2003.
Jeff Mitchell, Mirella Lapata, Vera Demberg, and
Frank Keller. Syntactic and semantic factors in
processing difficulty: An integrated measure. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, Uppsala,
Sweden, 2010.
M. Niv. A psycholinguistically motivated parser for
CCG. In Proceedings of the 32nd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL-94), pages 125?132, Las Cruces, NM,
1994.
W. M. Soon, H. T. Ng, and D. C. Y. Lim. A ma-
chine learning approach to coreference resolution
of noun phrases. Computational Linguistics, 27
(4):521?544, 2001.
M. J. Spivey and M. K. Tanenhaus. Syntactic am-
biguity resolution in discourse: Modeling the ef-
fects of referential context and lexical frequency.
Journal of Experimental Psychology: Learning,
Memory and Cognition, 24(6):1521?1543, 1998.
Kieth E. Stanovich and Richard F. West. The effect
of sentence context on ongoing word recognition:
Tests of a two-pricess theory. Journal of Exper-
imental Psychology: Human Perception and Per-
formance, 7:658?672, 1981.
Adrian Staub and Charles Clifton. Syntactic predic-
tion in language comprehension: Evidence from
311
either . . .or. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 32:425?436,
2006.
Mark Steedman. The Syntactic Process. Bradford
Books, 2001.
Erik F. Tjong Kim Sang and Sabine Buchholz. In-
troduction to the conll-2000 shared task: Chunk-
ing. In Proceedings of CoNLL-2000 and LLL-
2000, pages 127?132. Lisbon, Portugal, 2000.
Jos J. A. van Berkum, Colin M. Brown, Pienie Zwit-
serlood, Valesca Kooijman, and Peter Hagoort.
Anticipating upcoming words in discourse: Evi-
dence from erps and reading times. Journal of Ex-
perimental Psychology: Learning, Memory and
Cognition, 31(3):443?467, 2005.
Barton Wright and Merrill F. Garrett. Lexical deci-
sion in sentences: Effects of syntactic structure.
Memory and Cognition, 12:31?45, 1984.
312
