Squibs and Discussions 
Nonminimal Derivations in Unification-based 
Parsing 
Noriko Tomuro* 
DePaul University 
Steven L. Lytinen t 
DePaul University 
Shieber's abstract parsing algorithm (Shieber 1992)for unification grammars is an extension of 
Earley's algorithm (Earley 1970)for context-free grammars to feature structures. In this paper, 
we show that, under certain conditions, Shieber ' salgorithm produces what we call a nonminimal 
derivation: aparse tree which contains additional features that are not in the licensing productions. 
While Shieber's definition of parse tree allows for such nonminimal derivations, we claim that they 
should be viewed as invalid. We describe the sources of the nonminimal derivation problem, and 
propose aprecise definition of minimal parse tree, as well as a modification to Shieber's algorithm 
which ensures minimality, although at some computational cost. 
1. Introduction 
Unification grammar is a term often used to describe a family of feature-based gram- 
mar formalisms, including GPSG (Gazdar et al 1985), PATR-II (Shieber 1986), DCG 
(Pereira and Warren 1980), and HPSG (Pollard and Sag 1994). In an effort to formalize 
the common elements of unification-style grammars, Shieber (1992) developed a logic 
for describing them, and used this logic to define an abstract parsing algorithm. The 
algorithm uses the same set of operations as Earley's (1970) algorithm for context-free 
grammars, but modified for unification grammars. 
In this paper, we show that, under certain conditions, Shieber's algorithm produces 
unintended, spurious parses in addition to the intended ones. We call these spurious 
parses nonminimal derivations (or nonminimal parse trees), because they contain 
extra features which are not in the productions that license the parse, aWe claim that 
such nonminimal derivations are invalid. The basis of our claim is that the unifica- 
tion operation as set union preserves minimality; thus any correct unification-based 
parsing algorithm should produce parses that contain all and only features from the 
licensing productions (i.e., minimal derivations or minimal parse trees). Nonminimal 
derivations are also undesirable in practice because, given a parse tree, we cannot ell 
whether a particular feature should be in the model or not unless we reconstruct the 
whole tree. 
Despite the nonminimal derivations, Shieber (1992) proved the correctness of his 
algorithm. As it turned out, his definition of parse tree, which his proof relied on, was 
* School of Computer  Science, Telecommunications and Information Systems, Chicago, IL 60604. E-mail: 
tomuro@cs.depaul.edu 
t School of Computer  Science, Telecommunications and Information Systems, Chicago, IL 60604. E-maih 
lytinen@cs.depaul.edu 
1 In this paper, we use "nonminimal  derivations" synonymous ly  with "nonminimal  parses". Normal ly 
the notions of derivation and parse tree are different. However, in this paper we focus on parse trees as 
the final result of derivation, thus we mean that a derivation is nonminimal  when its result is a 
nonminimal  parse, in contrast o a minimal  derivation which produces a minimal  parse. Unfortunately, 
formal definitions of min imal  and nonmin imal  derivations are outside the scope of this short paper; 
interested readers are encouraged to read Tomuro (1999). 
(~) 2001 Association for Computat ional  Linguistics 
Computational Linguistics Volume 27, Number 2 
((cat) - S 
/ (1 cat) =" NP 
.J (2 cat) -- VP 
P0 = (2, ~0 : \] (head) -- (2 head) 
/ / head subj) - (1 head} 
~, (head agr> - (1 head agr> 
((cat) - VP 
J <1 cat/----" V 
P2 : (1, q)2 : ~ (head) -- (1 head} > 
I, (head type) - intrans ,/ 
Figure 1 
Examples of productions. 
((cat) -- NP 
pl = ("John",~l : ~ (head agr pers) - 3rd } > 
~, (head agr num)-  singJ 
((cat) -- V "\] 
~l (head agr pers) - 3rd / P3 = ("sleeps", ,I~ 3 : \] (head agr num) - sing ) 
I, (head tense} - pres 
not constrain ing enough to disal low nonmin imal  derivat ions.  To solve this twofo ld  
prob lem,  we propose  an alternate def init ion of min ima l  parse tree for unif icat ion gram-  
mars,  and present  a modi f icat ion to Shieber 's  a lgor i thm which ensures minimality.  
It is impor tant  to note that the same spur ious  parses also occur in context-free 
parsing,  specif ically in Ear ley's  algor i thm. However ,  since the only in format ion a con- 
st ituent carries in context-free grammar  is the grammar  symbol ,  the spur ious  der iva-  
t ions only produce  exactly the same results as the normal  ones. When the a lgor i thm 
is extended to unif icat ion grammar ,  however ,  these spur ious  parses are a prob lem.  
2. Unification Grammar and Parse Trees 
Shieber (1992) defines a unif icat ion grammar  as a 3-tuple (G, P, p0), where  ~ is the 
vocabu lary  of the grammar ,  P is the set of product ions ,  and P0 E P is the start pro-  
duct ion.  G contains L, a set of labels  (feature names);  C, a set of constants (feature 
values); and W, a set of terminals. There are two k inds of product ions  in P: phrasal 
and lexical. A phrasa l  product ion  is a 2-tuple (a, ~),  where  a is the arity of the rule (the 
number  of r ight-hand-s ide \[RHS\] constituents),  and ~ is a logical formula.  Typically, 
q~ is a conjunct ion of equat ions of the form pl - p2 or pl -" c, where  pl, p2 E L* are 
paths,  and c E C. In an equat ion,  any  path  wh ich  begins wi th  an integer i (1 < i < a) 
represents the ith RHS const i tuent of the rule. 2 A lexical p roduct ion  is a 2-tuple (w, ~), 
where  w E W and q~ is the same as above,  except that there are no RHS constituents. 
F igure 1 shows some example  phrasa l  and lexical product ions  (P0 cor responds  to the 
context-free rule S --+ NP  VP and is the start product ion) .  Then a mode l  M relates to 
a formula  q~ by  a satisfaction relat ion ~ as usual  (M ~ ~), and when q~ is the formula  
in a product ion  p = (a, ~),  p is said to l icense M. 
Based on the logic above,  Shieber defines a parse tree and the language of a 
g rammar  expressed in his formal ism. To define a val id parse tree, he first def ines the 
set of possible parse trees I1 = Ui>_0 Hi for a g iven grammar  G, where  each Eli is def ined 
as follows: 
Definition 
A parse tree r is a mode l  that is a member  of the infinite un ion of sets of bounded-  
depth  parse trees FI = Ui_>0 I1i, where  each IIi is def ined as: 
2 Shieber (1992) also uses a path that begins with 0 for the left-hand-side (LHS) constituent of a rule. In 
this paper, we omit the 0 arcs and place the features of the LHS constituent directly at the root. This 
change does not affect the formalism for the purpose of this paper. 
278 
Tomuro and Lytinen Nonminimal Derivations 
. 
. 
rio is the set of models 7- for which there is a lexical production 
p = <w, q)) E G such that 7- ~ 4< 
I I i ( i  > 0) is the set of models 7- for which there is a phrasal production 
p = (a, q~) C G such that 7- ~ ~ and, for all 1 < i < a, 7-/{i) is defined and 
7-/<i} C Uj<iIIy. 
In the second condition, the extraction operator, denoted by / ,  retrieves the feature 
structure found at the end of a particular path; so for instance 7-/<1) retrieves the first 
subconstituent on the RHS of the production that licenses 7-. In the definition above, 
II0 contains all models that satisfy any lexical production in the grammar, while Hi 
contains all models that satisfy a phrasal production, and whose subconstituents are 
all i n  UjGi I\]j. 
To specify what constitutes a valid parse for a particular sentence, the next step is 
to define the yield of a parse tree. It is defined recursively as follows: if 7- is licensed by 
some lexical production p = {w, q~/, then the yield of 7- is w; or if 7- is licensed by some 
phrasal production {a, q~} and O~ 1 . . . . .  (X a are the yields of 7-/(1) . . . . .  7-/<a) respectively, 
then the yield of 7- is ~1 ...  %. 
Finally, Shieber defines a valid parse tree 7- c II for sentence Wl . . .  wn as follows: 
o 
2. 
The yield of 7- is Wl . . .  Wn 
7- is licensed by the start production po 
Notice that this definition allows extra features in a parse tree, because a parse tree 
7- is defined by the satisfaction relation (7- ~ ~), which allows the existence of features 
in the model that are not in the licensing production's formula. Given this definition, 
for any valid parse tree 7-, we can construct another parse tree 7-' by simply adding an 
arbitrary (nonnumeric) feature to any node in 7-. Such a parse tree T' is nonminimal 
because extra features are nonminimal with respect o the minimal features in the 
licensing productions. We will return to the issue of minimal and nonminimal parse 
trees in Section 4. 
3. The Abstract Parsing Algorithm 
Based on the logic described above, Shieber defines an abstract parsing algorithm as a 
set of four logical deduction rules. Each rule derives a new item, from previous items 
and/or  productions in the grammar. An item is a 5-tuple {i,j, p, M, d), where i and j are 
indices into the sentence and specify which words in the sentence have been used to 
construct the item; p is the production used to construct the item; M is a model; and d 
is the position of the "dot"; i.e., how many subconstituents in p have been completed 
so far. 
The logical rules of the abstract algorithm are shown in Figure 2. The Initial Item 
rule produces the first item, and is constructed from the start production P0. It spans 
none of the input (i and j are both 0), and its model is the minimal model (ram) of P0. 
The Prediction rule is essentially the top-down rewriting of the expectation (a 
subconstituent just after the dot) in a prior item. In this rule, the extraction of M/(d  + 
1 / retrieves the d + 1st submodel in M (i.e., expectation). The function p, which is 
left underspecified as a parameter in the abstract algorithm, filters out some features 
predefined in the various instantiations of the algorithm. Here, it is applied to the 
expectation, by which it effectively controls the top-down predictive power of the 
279 
Computational Linguistics Volume 27, Number 2 
INITIAL ITEM: {O,O, po, mm(~o),O) 
PREDICTION: 
SCANNING: 
li, j,p = la, ~l,M,d) 
(j,j, p', p(M/(d+l)) t3 mm(~'), 0) ' where d K a and p' = (a',O') ? P 
(i,j,p = (a, ~},M,d} 
{i,j+lip, M t_l (mm(~2') \ {d+l ) ) ,d+l}  ' where  d < a and  (wj+l, O'} ? P 
COMPLETION: li'j'P = la' ~l 'M'd) (j,k,p' = (a',/I~'),M',a' / where d < a 
I {i, kip, M El (M' \ {d+l) ,d+l) 
Figure 2 
Shieber's parsing operations. 
I0 = (O,O, po, mm(420),O) 
11 = (O, 1,po, Ml,1) 
12 = (1,1,p2,M2,0 I 
I3 = (1,2,p2,M3,1) 
I4 = (0, 2, p0, M4, 2) 
ag 5 ?yP? 
pers~ -n~ p mtrans 
3rd sing 
Figure 3 
Items produced in the parse of John sleeps, and the final parse. 
algorithm and provides flexibility to the instantiated algorithms. Then the expectation 
is unified with a production (~'), which can consistently rewrite it. By this operation, 
some features in the expectation may be propagated own in the production. 
The remaining two rules advance the dot in a prior item, by unifying the sub- 
constituent to the right of the dot with either a lexical item from the input string (the 
Scanning rule) or some other completed higher-level item (the Completion rule). Both 
rules perform the correct unification by utilizing the embedding operator (signified 
by \), which places a model M under a path p (M\p). 
We illustrate these operators with a simple step-by-step example parse. Consider 
the grammar that consists of the rules presented in Figure 1. Using this grammar, 
Figure 3 shows the parse of the sentence John sleeps. First, the Initial Item operator 
is applied, producing item I0, whose model is mm(~o). Next, the Scanning operator 
scans the word John, producing 11. The Prediction operator then produces 12. Next, 
the word sleeps is scanned (since the first subconstituent of the model in 12 is a V), 
producing 13. Finally, since the item in 13 is complete (d = 1, the arity of production 
p2), Completion is applied to items 11 and/3, producing 14. Model M4 is the final parse 
of the sentence. 
4. Nonminimal Derivations 
In Section 2, we noted that Shieber's definition of parse trees allows them to be non- 
minimal. We consider these to be invalid based on a principle that, since the unification 
operation as set union preserves minimality (as proved in Shieber, \[1992\]), repeated 
applications of unification using licensing productions hould result in parses that 
contain features only from those productions and nothing more. In this section, we 
280 
Tomuro and Lytinen Nonminimal Derivations 
((cat) - VP 
I (1 cat) -- VP 
p4 = (2,~4: { (2 cat} -- ADV } 
| (head) - (1 head) / 
( (head modified) - true ) 
Figure 4 
A phrasal production that results in a nonminimal derivation. 
I~ = (1,1,p4,M~, 0} 
/~' = (1,1, p2,M~r, 0) 
I~ = (1,2,p2,M~, 1) 
I~ = {0, 2, p0, M~, 2} 
M4 ~ ." 
cat~-43 
c S a l t  
NP nea~/ l~Vub~V t 
ag~.. 7se.t~pe~modified 
per~ n~ lntrans t}ue 
3rd sing 
Figure 5 
Nonminimal derivation of John sleeps. 
formally define minimal and nonminimal parse trees, and show an example in which 
nonminimal parse trees are produced by Shieber's algorithm. 
Our definition of minimal parse tree is to a large extent similar to Shieber's def- 
inition, but to ensure minimality, our definition uses the equality relation instead of 
D, and inductively specifies a minimal parse tree bottom-up. 
Definition 
Given a grammar G, a minimal parse tree r admitted by G is a model that is a member 
of the infinite union of sets of bounded-depth parse trees 11' = Oi>0 IIl, where each 
171 is defined as: 
. 
2. 
For each lexical production p = (w, ~b) E G, mm(~) E 11'o. 
For each phrasal production p = (a, ~} E G, let rl . . . . .  ra E Uj<i I1;. If 
r = mm(~) l i t1\(1) t3.. .  I lr l \(a}, then r E 1I;. 
It is obvious that 1I' is a subset of 17 in Shieber's definition. Then, a nonminimal parse 
tree is defined as a model that is a member of the difference of the two sets (II - 1I'). 3 
Here is a simple example in which a nonminimal parse is produced in Shieber's 
algorithm. Say that we add the production in Figure 4 to the grammar in the previous 
section. The intent of this production is to mark the verb with the feature modified if an 
adverb follows. Using this grammar, Shieber's algorithm will produce a nonminimal 
parse for the sentence John sleeps, in addition to the minimal parse shown in the 
previous section. 4 The nonminimal parse, shown in Figure 5, arises as follows: after 
scanning John, Prediction can produce items I~ and I~', first using production p4 (thus 
inserting /head modified} - true into the model), and then P2. Scanning the word 
3 Note that using subsumption (which we will discuss in Section 5) here does not work, for instance by 
saying "a model r"  is a nonminimal parse tree if r "  E 17 and there exists r '  E II such that r '  _< r"",  
because some r" 's  are minimal. See the example in Section 5. 
4 Here, we are assuming that the filtering function/9 is the identity function. 
281 
Computational Linguistics Volume 27, Number 2 
sleeps then produces I~ from I~ I. Completion then can be applied directly to 11 and 11 by 
skipping a completion using I~ and I~, thereby producing item I~. The feature modified 
remains in I~, even though an adverb was never encountered in the sentence. The 
final parse M~, shown in Figure 5, is clearly nonminimal according to our definition 
because of this feature. 
Note that the example grammar can be changed to prevent he nonminimal parse, 
by moving the feature modified off of the head path in ff~4 (i.e., (modified / - true 
instead of (head modified / - true), sHowever, the point of the example is not to argue 
whether or not well-designed grammars will produce erroneous parses. A formally 
defined parser (see the discussion below) should in principle produce correct parses 
regardless of the grammar used; otherwise, the grammar formalism (i.e., Shieber's logic 
for unification grammars) must be revised and properly constrained to allow only the 
kinds of productions with which the parser produces correct results. 
In general, nonminimal derivations may arise whenever two or more predictions 
that are not mutually exclusive can be produced at the same point in the sentence; 
i.e., two prediction items (i, i, p, M, 0 / and (i, i, p', M ~, 0 / are produced such that M 
M / and M and M ~ are unifiable. In the example, items 12 = (1,1, p2, M2, 0/ and I~ -- 
(1,1, P4, M~, 0) (as well as I2 and I~ ~ = (1,1, p2, M~ ~, 0/) are two such items. Since the two 
predictions did not have any conflicting features from the beginning, a situation may 
occur where a completion generated from one prediction can fill the other prediction 
without causing conflict. When this happens, features that were in the other prediction 
but not the original one become nonminimal in the resulting model. 
As to what causes nonminimal situations, we speculate that there are a number 
of possibilRies. First, nonminimal derivations occur when a prediction is filled by a 
complete item that was not generated from the prediction. This mismatch will not 
happen if parsing is done in one direction only (e.g. purely top-down or bottom-up 
parsing). Thus, the mixed-direction parsing strategy is a contributing factor. 
Second, wrong complete items are retrieved because Shieber's item-based algo- 
rithm makes all partial results available during parsing, as if they are kept in a global 
structure (such as a chart in chart parsing). But if the accessibility of items were some- 
how restricted, prediction-completion mismatch would not happen. In this respect, 
other chart-based algorithms for unification grammars which adopt mixed-direction 
parsing strategy, including head-corner parsing (van Noord 1997) and left-corner pars- 
ing (Alshawi 1992), are subject o the same problem. 
Third, extra features can only appear when the grammar contains rules which 
interact in a certain way (such as rules P2 and P4 above). If the grammar contained 
no such rules, or if p (the filtering function applied in Prediction) filtered out those 
features, even the prediction-completion mismatch would not produce nonminimal 
derivations. 
As we stated in the beginning of this section, we consider nonminimal parses to 
be invalid on the basis of minimality. It then immediately follows that any parsing 
algorithm that produces nonminimal parses is considered to be unsound; in particular, 
Shieber's algorithm is unsound. However, since nonminimal parse trees have the same 
yield as their minimal counterparts, his algorithm does indeed recognize xactly the 
language of a given grammar. So, Shieber's algorithm is sound as a recognizer, 6 but 
not as a transducer or parser (as in van Noord, \[1997\]) where the correctness of output 
models (i.e., parse trees) is critical. In other words, Shieber's algorithm is correct up to 
5 Note that adding (head modified) -- false to ~2 (VP --* V) or ~3 (sleeps) isnot feasible, because they 
cannot specify the modified feature at their level, 
6 In fact, Shieber hints at this: "The process of parsing (more properly, recognition)..." (Shieber 1992, 78). 
282 
Tomuro and Lytinen Nonminimal Derivations 
licensing, but incorrect on the basis of a stronger criteria of minimality. Thus, to guar-  
antee correctness based on minimality, we need another algorithm; such an a lgor i thm 
is exactly the solution to the nonmin imal  der ivat ion problem. 
5. Practical Techniques 
Before present ing our solution to the nonmin imal  der ivat ion problem, we discuss 
several possible practical techniques to get around the prob lem in implemented sys- 
tems. These are known techniques, which have been appl ied to solve other problems 
in unif ication-based systems. However ,  most  of them only offer partial solutions to 
the nonmin imal  derivat ion problem. First, whenever  Shieber's a lgor i thm produces a 
nonmin imal  derivation, it also produces a corresponding minimal  der ivat ion (Tomuro 
1999). Thus, one possible solution is to use subsumpt ion  to discard items that are more 
specific than any other items that are produced.  Subsumpt ion  has often been used in 
unif ication-based systems to pack items or models  (e.g., A lshawi  1992). However,  
s imple subsumpt ion  may filter out val id parses for some grammars,  thus sacrificing 
completeness. 7 
Another  possibil ity is to filter out problematic features in the Prediction step by 
using the funct ion p. However,  automatic detection of such features (i.e., automatic 
derivat ion of p) is undecidable for the same reason as the prediction nontermination 
problem (caused by left recursion) for unif ication grammars  (Shieber 1985). Manual  
detection is also problematic:  when a grammar  is large, part icular ly if semantic fea- 
tures are included, complete detection is nearly impossible. As for the techniques 
developed so far which (partially) solve predict ion nonterminat ion (e.g., Shieber 1985; 
Haas 1989; Samuelsson 1993), they do not apply  to nonmin imal  derivations because 
nonmin imal  derivations may arise wi thout  left recursion or recursion in genera l  s One 
way  is to define p to filter out all features except the context-free backbone of predic- 
tions. However ,  this severely restricts the range of possible instantiations of Shieber's 
algorithm. 9 
A third possibil ity is to manual ly  fix the grammar  so that nonmin imal  derivations 
do not occur, as we noted in Section 4. However ,  this approach is problematic for the 
same reason as the manua l  der ivat ion of p ment ioned above. 
6. Modified Algorithm 
Finally, we propose an algor i thm that does not produce nonmin imal  derivations. It is a 
modif icat ion of Shieber's a lgor i thm that incorporates parent pointers. Figure 6 shows 
7 For example, when there are two predictions M1 and M2 for category C and a production p where 
M1 : {<cat> -- C, <x> - a}, M2 : {<cat> - C, <y> - b}, and p = <1, {<cat> - C, <1 cat> "- D, <x> - a}> 
respectively, the resulting model M2 ~ = {<cat> - C, <1 cat> - D, <x> -- a, <y> -- b} will have strictly more 
information than the other esulting model MI' = {<cat> ~ C, <1 cat> - D, <x> - a}, although both 
models are minimal. 
8 We do not show any particular example here, but if we change the left-recursive VP rule in the earlier 
example to a non-left-recursive rule, for instance VP --* VP2 ADV, and add some rules, a nonrninimal 
parse will indeed arise. 
Note also that some (but not all) cases of prediction ontermination will produce nonminimal 
derivations. Those cases occur when there is a prediction for a category, and repeated applications of 
some left-recursive rule(s) generate predictions for the same category that are not mutually exclusive to 
the original prediction or each other. 
9 In head-corner parsing, Sikkel (1997) proposes the use of transitive features: features that propagate 
only through ead arcs. However, this method oes not solve nonminimal derivations either, because 
problematic features may be subfeatures of a head (such as the example case shown earlier), which will 
not be filtered. 
283 
Computational Linguistics Volume 27, Number 2 
INITIAL ITEM: 
PREDICTION: 
(id, nil, (O,O, po, mm( ~o),O) ' where id is a new symbol 
(id, pid, (i,j,p = (a, ~),M,d) ) 
(id', id, (j,j, p', p(M/ (d+l) ) U mm(~I,'), 0))' 
where id I is a new symbol, and d ( a and pl = (ar,~t) C P 
SCANNING: 
COMPLETION: 
(id, pid, (i,j,p = (a, ~),M,d) ) 
(id, pid, (i,j+l,p,M U mm( ~') \ (d+l),d+l)) ' where d< a and (wj+D ~') E P 
(id, pid,(i,j,p,M,d)) (id",id,(j,k,p',M',a')) where d < a 
(ia, pie, (i,k,p, UU (U' \ (d+l)),d+l)) ' 
Figure 6 
Shieber's parsing operations modified. 
the modified algorithm. In the figure, an item is represented by a nested 3-tuple, where 
the first argument is the self index, the second is the parent index/pointer, and the 
third is the old 5-tuple used in Shieber's original algorithm. A parent pointer, then, 
is set in Prediction--the r sulting item has the index of the antecedent item (id) as 
its parent. By generating a new symbol for the self index in every Prediction item 
(id'), parent pointers in those items are threaded to form a prediction path. Then in 
Completion, the parent pointer is used to restrict he antecedent items: the complete 
item (on the right) must have the prior expectation (on the left) as its parent (id), 
thereby ensuring a prediction path to be precisely restored. 
While this modified algorithm offers a complete solution on the level of logic, it 
has some undesirable implications in implemented systems. The most prominent one 
is that the parent pointer scheme makes implementation f memoizat ion rather diffi- 
cult. Normally, memoization is used to avoid storing duplicate items that are identical; 
however, in the modified algorithm, many items that are otherwise identical will have 
different parent pointers, thereby changing the polynomial time algorithm (O(n3); Ear- 
ley \[1970\]) to an exponential one. To avoid computational inefficiency, a way must be 
devised for items that are identical except for parent poInters to share information, 
especially models, and thus avoid the expense of duplicate identical unification opera- 
tions. One possibility is to represent the 5-tuple from Shieber's original algorithm by a 
separate structure and have an index to it in the new 3-tuple item. This way, not only 
can the items be shared, they can still be memoized in the usual way as well. Another 
possibility is to adopt an efficiency technique along the line of selective memoization 
(van Noord 1997). Implementation a d empirical analysis is our future research. 
Whatever the practical performance will turn out to be, it is important to note 
that the proposed algorithm is a formal solution that guarantees minimality for any 
grammar defined in Shieber's logic. Moreover the algorithm preserves the same gen- 
erality and flexibility as Shieber's: a mixed top-down, bottom-up arsing with the 
filtering function p to allow various instantiations of the algorithm to characterize 
their algorithms. 
References 
Alshawi, H., editor. 1992. The Core Language 
Engine. MIT Press. 
Earley, J. 1970. An efficient context-free 
parsing algorithm. Communications ofthe 
ACM, 13(2). 
Gazdar, G., E. Klein, G. Pullum, and I. Sag. 
1985. Generalized Phrase Structure Grammar. 
Blackwell Publishing. 
Haas, A. 1989. A parsing algorithm for 
unification grammar. Computational 
Linguistics, 15(4):219-232. 
284 
Tomuro and Lytinen Nonminimal Derivations 
Pereira, F. and D. Warren. 1980. Definite 
clause grammars for language analysis. 
Arti~'cial Intelligence, 13:231-278. 
Pollard, C. and I. Sag. 1994. Head-driven 
Phrase Structure Grammar. CSLI. University 
of Chicago Press. 
Samuelsson, C. 1993. Avoiding 
non-termination in unification grammars. 
In Natural Language Understanding and Logic 
Programming IV. 
Shieber, S. 1985. Using restriction to extend 
parsing algorithms for complex-feature- 
based formalisms. In Proceedings ofthe 23rd 
Annual Meeting, Association for 
Computational Linguistics. 
Shieber, S. 1986. An Introduction to 
UniX'cation-Based Approaches to Grammar. 
CSLI. University of Chicago Press. 
Shieber, S. 1992. Constraint-based Grammar 
Formalisms. MIT Press. 
Sikkel, K. 1997. Parsing Schemata. 
Springer?Verlag. 
Tomuro, N. 1999. Left-Corner Parsing 
Algorithm for UniX'cation Grammars. Ph.D. 
thesis, DePaul University. 
van Noord, G. 1997. An efficient 
implementation f the head-corner parser. 
Computational Linguistics, 23(3):425-456. 
285 
 QARAB: A Question Answering System to Support 
the Arabic Language 
 
Bassam Hammo  Hani Abu-Salem  Steven Lytinen 
 
DePaul University 
School of Computer Science, Telecommunications and Information Systems  
243 S. Wabash Avenue, Chicago IL 60604 
  
bhammo@condor.depaul.edu habusalem@cti.depaul.edu lytinen@cs.depaul.edu 
 
Martha Evens 
Illinois Institute of Technology 
Computer Science Department 
10 West 31st Street, Chicago, IL 60616 
evens@iit.edu 
 
 
 
Abstract 
 
We describe the design and 
implementation of a question answering 
(QA) system called QARAB. It is a 
system that takes natural language 
questions expressed in the Arabic 
language and attempts to provide short 
answers. The system?s primary source 
of knowledge is a collection of Arabic 
newspaper text extracted from Al-Raya, 
a newspaper published in Qatar. During 
the last few years the information 
retrieval community has attacked this 
problem for English using standard IR 
techniques with only mediocre success. 
We are tackling this problem for Arabic 
using traditional Information Retrieval 
(IR) techniques coupled with a 
sophisticated Natural Language 
Processing (NLP) approach. To identify 
the answer, we adopt a keyword 
matching strategy along with matching 
simple structures extracted from both 
the question and the candidate 
documents selected by the IR system. 
To achieve this goal, we use an existing 
tagger to identify proper names and 
other crucial lexical items and build 
lexical entries for them on the fly.  We 
also carry out an analysis of Arabic 
question forms and attempt a better 
understanding of what kinds of answers 
users find satisfactory.  The paucity of 
studies of real users has limited results 
in earlier research. 
 
1 Introduction 
 
In recent years, there has been a marked increase 
in the amount of data available on the Internet.   
Users often have specific questions in mind, for 
which they hope to get answers. They would like 
the answers to be short and precise, and they 
always prefer to express the questions in their 
native language without being restricted to a 
specific query language, query formation rules, or 
even a specific knowledge domain. The new 
approach taken to matching the user needs is to 
carry out actual analysis of the question from a 
linguistic point of view and to attempt to 
understand what the user really means.  
 QARAB is the result of coupling traditional 
Information Retrieval (IR) techniques with a 
sophisticated Natural Language Processing (NLP) 
approach. The approach can be summarized as 
follows: the IR system treats the question as a 
query in an attempt to identify the candidate 
 documents that may contain the answer; then the 
NLP techniques are used to parse the question and 
analyze the top ranked documents returned by the 
IR system. 
 Natural Language Processing (NLP) in the 
Arabic language is still in its initial stage 
compared to the work in the English language, 
which has already benefited from the extensive 
research in this field.  There are some aspects that 
slow down progress in Arabic Natural Language 
Processing (NLP) compared to the 
accomplishments in English and other European 
languages [Al-Daimi & Abdel-Amir, 1994]. 
These aspects include: 
? Arabic is highly inflectional and derivational, 
which makes morphological analysis a very 
complex task. 
? The absence of diacritics (which represent 
most vowels) in the written text creates 
ambiguity and therefore, complex 
morphological rules are required to identify 
the tokens and parse the text. 
? The writing direction is from right-to-left and 
some of the characters change their shapes 
based on their location in the word. 
? Capitalization is not used in Arabic, which 
makes it hard to identify proper names, 
acronyms, and abbreviations. 
 
In addition to the above linguistic issues, there 
is also a lack of Arabic corpora, lexicons, and 
machine-readable dictionaries, which are essential to 
advance research in different areas. 
 
 
2 Background 
 
Advances in natural language processing (NLP), 
information retrieval techniques (IR), information 
extraction (IE), as well as the computer industry, 
have given QA a strong boost. Modern question-
answering systems have started incorporating 
NLP techniques to parse natural language 
documents, extract entities and relations between 
entities, resolve anaphora, and other language 
ambiguities [Harabagiu et al, 2000; Vicedo & 
Ferr?ndez, 2000].   
 Research in Question-Answering (QA) is not 
new.  The QA problem has been addressed in the 
literature since the beginning of computing 
machines.  The AI/NLP communities initiated 
traditional work to address question-answering 
using structural methods. Early experiments in 
this direction implemented systems that operate in 
very restricted domains (e.g. SHRDLU 
[Winogard, 1972] and LUNAR [Woods, 1972]).   
In the QUALM system, Lehnert [1978] took a 
further step, based on the conceptual theories of 
Schank & Abelson [1977], to understand the 
nature of the questions and classify them in a way 
similar to how human beings understand and 
answer questions. SCISOR [Jacobs & Rau 1990] 
aimed at question answering and text extraction 
more than information retrieval. It combined 
natural language processing, knowledge 
representation, and information retrieval 
techniques with lexical analysis and word-based 
text searches. The MURAX system [Kupiec, 
1993] used robust linguistic methods to answer 
closed-class natural language questions. It 
presented the user with relevant text in which 
noun phrases are marked. A less automated 
approach like Ask Jeeves [1996] approached the 
QA problem by pointing the questioner to Web 
links that might contain information relevant to 
the answer to the question. Ask Jeeves benefited 
from advanced natural language processing 
techniques combined with data mining processing 
and a huge expanding knowledge base. Another 
system, with a different approach, is the 
FAQFinder system [Burke et al, 1997], which 
attempted to solve the question-answering 
problem using a database of question-answer pairs 
built from existing frequently asked question 
(FAQ) files.  Two other important systems are the 
START system [Katz, 1997], which is based on 
annotations from the Web and the Q&A system 
[Budzik & Hammond, 1999], which is a 
semiautomatic, natural language question-
answering and referral system. The system is 
based on a huge knowledge base and human 
experts who volunteered their time to respond to 
the users? questions. 
 Recently, attention has begun to be focused 
on developing question-answering systems that do 
 not rely on a knowledge base and that can fetch 
answers from huge unstructured text.  New QA 
systems enhanced with NLP and IR techniques 
have been developed to extract textual answers for 
open-domain questions and provide a framework 
for modern information retrieval [TREC-8, 1999; 
TREC-9, 2000].  
 The overall aim of this QA track was to 
retrieve small pieces of text that contain the actual 
answer to the question rather than the list of 
documents traditionally returned by retrieval 
engines [Voorhees & Tice, 2000].  The TREC-8 
QA track attracted researchers from both industry 
and academia. Twenty organizations participated 
in this track with different approaches and their 
systems were evaluated.  The participating 
systems were tested on a huge set of unstructured 
documents and a set of fact-based questions.   
 Generally speaking, most of the TREC-8 
long-string answer (250-bytes) participants 
attempted to solve the QA problem from the 
information retrieval (IR) point of view by 
locating the most relevant documents from the 
collection and then extracting the sentences most 
relevant to the query from the documents just 
located. The systems relying on this ?bag-of-
words? approach (e.g. [Allan et al, 1999]; 
[Cormack et al, 1999]; [Lin & Chen, 1999]; [Shin 
et al, 1999] and the passage-retrieval run of 
AT&T [Singhal et al, 1999]) deal with the 
question without considering its grammatical or 
semantic characteristics and they apply 
conventional IR techniques to extract the answer.  
Even though the ?bag-of-words? approach was 
commonly used in TREC-8, the systems based on 
this approach were inadequate to handle the short-
string (50-byte) answers. 
 On the contrary, the short string (50-byte) 
participants (e.g. [Breck et al, 1999]; [Ferret et 
al., 1999]; [Hull, 1999]; [Humphreys et al, 1999]; 
[Litkowski, 1999]; [Moldovan et al, 2000]; [Oard 
et al, 1999]; [Singhal et al, 1999]) agreed on the 
importance of applying several natural language 
processing techniques to solve the problem.  
Among these techniques are: part-of-speech 
tagging, shallow parsing, query type identification 
and named entity recognition.  Because the 
number of test documents to be analyzed for each 
query was huge, the majority of the systems in 
this band used the ?bag-of-words? approach as an 
initial step to retrieve the relevant passages that 
contain the possible answer. Another approach to 
the QA problem combines IR techniques with 
Information Extraction (IE) techniques for 
extracting named entities, e.g., [Ogden et al, 
1999]; [Takaki, 1999]; and [Srihari & Li, 1999]. 
A detailed description of the track and the results 
are available at [Voorhees & Tice, 1999]. 
 It is obvious from the increasing number of 
systems participating in TREC-9 and the 
worldwide interest in this research area that 
Question Answering is the most promising 
framework for finding answers to natural 
language questions from a huge amount of textual 
data.  Cardie et al [2000] pointed out that 
building ?open-ended question answering systems 
that allow users to pose questions of any type and 
in any language, without domain restrictions, is 
still beyond the scope of any QA system today? (p. 
180).  Harabagiu et al [2000] indicated that 
advanced tools (such as dialog understanding and 
text mining) are essential for the success of future 
QA systems. Until the advanced tools are 
implemented, she suggested that we keep 
approximating the complexity of Question 
Answering with NLP enhancements of IR and IE 
techniques [Harabagiu et al, 2000]. 
 
 
3 QARAB System 
 
3.1 Overview 
 
In the last decade, the volume of Arabic 
textual data has started growing on the Web and 
Arabic software for browsing the Web is 
improving.  Unfortunately, much of the earlier 
Arabic text available on the Web was posted as 
images, which makes it unsuitable for search or 
processing. As of today, there is an increase in the 
amount of Arabic textual material available on the 
Web in the form of news articles and books.  
 The main goal of the QARAB system is to 
identify text passages that answer a natural 
language question. The task can be summarized as 
follows: Given a set of questions expressed in 
 Arabic, find answers to the questions under the 
following assumptions: 
? The answer exists in a collection of Arabic 
newspaper text extracted from the Al-Raya 
newspaper published in Qatar. 
? The answer does not span through documents 
(i.e. all supporting information for the answer 
lies in one document) 
? The answer is a short passage. 
 
 
The basic QA processing in QARAB is 
composed of three major steps: 
? Processing the input question 
? Retrieving the candidate documents 
(paragraphs) containing answers from the IR 
system 
? Processing each one of the candidate 
documents (paragraphs) in the same way as 
the question is processed and returning 
sentences that may contain the answer. 
 
The QARAB system will be evaluated over a 
wide range of question types provided by Arabic 
users during the testing and the final phases. The 
same users will then assess whether the answers 
produced by the system are satisfactory. 
 
 
3.2 QARAB Structure 
  
The complete QARAB system is depicted in 
Figure 1; it has the following overall structure: 
 
 
3.2.1 The IR System    
 
The IR system, which we are implementing from 
scratch, is based on Salton?s vector space model 
[Salton, 1971]. First, it processes the text 
collection from the Al-Raya newspaper and 
constructs an inverted file system, from which the 
answers to the natural language questions will be 
extracted. The purpose of the IR system is to 
search the document collection to select 
documents containing information relevant to the 
user?s query. 
Implementing the Information Retrieval 
System 
 
Information Retrieval (IR) systems can be 
constructed in many various ways.  Lundquist et 
al. [1999] proposed an Information Retrieval (IR) 
system that can be constructed using a relational 
database management system (RDBMS). Our IR 
system is depicted in Figure 2 and it contains the 
following database relations: 
? ROOT_TABLE (Root_ID, Root) ? to store the 
available distinct roots of the terms extracted 
from the Al-Raya document collection (one 
row per root). 
? STEM_TABLE (Stem_ID, Root_ID, Stem, 
Document_Frequency, IDF) ? to store all 
distinct stems from the document collection.  
The stem frequency in the entire document 
collection and the inverse document 
frequency of each stem are calculated and 
stored (one row per stem). 
? POSTING_TABLE (Posting_ID, Stem_ID, 
Document_ID, Paragraph_ID, Position, 
Length) ? to store all the occurrences of the 
stems extracted from the entire document 
collection (one row per stem).      
? DOCUMENT_TABLE (Document_ID, 
Document_Title, Document_Date, 
Document_Path) ? to store document 
information (one row per document) 
? PARAGRAPH_TABLE (Paragraph_ID, 
Document_ID, Paragraph) ? to store all the 
paragraphs extracted from the document 
collection (one row per paragraph). This 
speeds up the analysis and the processing of 
the relevant passages that might answer to the 
user?s question.  
? QUERY_TABLE (Word, Weight) ? to store 
query information. This includes the original 
query words and the set of expanded words. 
The set of expanded words is obtained by 
extracting the available roots of the original 
query words, finding their equivalent 
Root_ID?s in the ROOT_TABLE, and then 
finding their corresponding terms stored in the 
STEM_TABLE. The weight of each word is 
calculated and stored (one row per word).  
 
 NLP Tools 
Lexicon
Morphology
Analyzer
System
Tokenizer
System
Type Finder
System &
Parsing PNP
System
 Main
 Table
Pronoun
Table
Particle
Table
Noun
Table
Verb
Table
Keyword
Table
Adjective
Table
Propernoun
Table
Category
Table
Product
Table
Time
Table
Political
Location
Natural
Location
Personal
Name
Events
Table
Organization
Table
 
 
 
Figure 1.  System Components 
 
 
3.2.2 The NLP System 
 
The second component of the system (the NLP 
system) shown in Figure 1 was implemented by 
Abuleil [1999] to experiment in building a large 
Arabic lexicon. The NLP system is composed of a 
set of tools to tokenize and tag Arabic text, 
identify some features of the tokens and, most 
important, to identify proper names. The 
following is a description of the overall structure 
and functionality of the NLP system. 
 
 
Figure 2.  Relational Database Information 
Retrieval System 
 
 The tagger was designed to construct a 
comprehensive Arabic lexicon. The system is 
used to parse Arabic words and determine their 
parts of speech (verbs, nouns, particles).  Also it is 
used to figure out the features of each word 
(gender, number, person, tense), mark proper 
nouns in the text and determine their types 
(personal names, locations, organizations, times, 
dates, etc.). 
 The NLP system comprises the following 
modules: 
? The tokenizer, which is used to extract the 
tokens. 
? The type finder, which is used to assign a 
part-of-speech to each token. 
? The feature finder, which is used to determine 
the features of each word.   
? The proper noun phrase parser, which is used 
to mark proper nouns. 
 
The type finder module starts a lexicon lookup 
process for each token. When there is an unknown 
word in the text, the system can apply the proper 
noun phrase parser to tag the word as a proper 
noun. The recognition process occurs in multiple 
stages in which a list of patterns and heuristics 
may be applied to mark the proper noun. When 
the word is tagged as a proper noun, it is added 
automatically to the lexicon with all its possible 
 features. Being able to identify the proper names, 
among other actual entities, in the text is an 
important step in understanding and using the text.  
Unfortunately, this is not a straightforward task in 
Arabic as it is in English and most European 
languages since the uppercase/lowercase 
distinction does not exist in Arabic text. Thus, we 
have to learn more about the common patterns in 
which these entities occur in Arabic contexts.   
 
 
4 The Basic Outline of Processing 
in the IR System 
 
4.1 Document Processing 
 
This step is essential for our system. First, the 
newspaper articles from the Al-Raya newspaper 
are saved in text format using the Arabic Windows 
1256 encoding scheme. This is performed to 
extract all the html tags and to get the pure text 
contents of the articles.  Second, the IR system is 
constructed using the relational database model as 
explained above. This step involves tokenization, 
stop-word removal, root extraction, and term 
weighting. 
 
4.2 Extracting the Root 
 
In general, to extract Arabic roots from their 
words, the stemmer has to process each word in 
the following order [Khoja, 1999]:  
? Removing the Definite Article ?? ?al? 
? Removing the Conjunction Letter ?   ?w? 
? Removing Suffixes  
? Removing Prefixes  
? Pattern Matching  
 
The following example demonstrates the 
whole stemming process applied to the Arabic 
word ?????????  ?wlydrsooha?, which is mapped to 
the complete English sentence ?and they are 
going to study it?. The root of this word can be 
extracted as follows: 
 
(w)-(l)-(y)-drs-(oo)-(ha)      )??)(?(??? -)?( -(?)-(? ) 
 
1. Removing the conjunction letter (w) )?(  
? )??)(?( ???-)?( -(?) 
2. Removing the suffix (ha) )??( , which indicates 
a feminine, singular patient  
? )?(??? -)?(  -(?) 
3. Removing the suffix: (oo) )?( , which indicates 
a masculine third person plural agent  
? )??? -)?  -(?) 
4. Removing the preposition prefix (l) )?(   
 ? )??? -)?  
5. Removing the prefix: (y) )?( , which indicates 
a 3rd person, present tense ? ???   
6. The pattern ??? F9L has the same length as the 
word ??? drs. Then the stemmer detects that 
the word ??? matches the pattern  ????, since 
all the letters of the word match those in the 
pattern (i.e. ?? ?? ? ) 
7. Finally, the stemmer checks the trilateral roots 
table and concludes that the root ??? drs (he 
studied) is a valid root. 
 
 
5 Question Processing in QARAB 
 
Achieving question understanding requires deep 
semantic processing, which is a non-trivial task of 
natural language processing. In fact, Arabic NLP 
does not have solid research at the semantic level. 
Therefore, QARAB uses shallow language 
understanding to process questions and it does not 
attempt to understand the content of the question 
at a deep, semantic level. 
 QARAB treats the incoming question as a 
?bag of words? against which the index file is 
searched to obtain a list of ranked documents that 
possibly contain the answer. The question 
processing begins by performing tokenization to 
extract individual terms. Then, the stop-words are 
removed. The remaining words are tagged for 
part-of-speech in an attempt to highlight the main 
words that should appear in the hypothesized 
answer. The greatest effort should be spent on 
identifying proper names, as they are our best 
guidance to identify the possible answer. The 
interrogative particles that precede the questions 
will determine what types of answers are expected 
as shown in Table 1.  
 
 5.1  Query Expansion 
 
To achieve better search and retrieval results the 
query is expanded to include all the terms (verbs 
and nouns derived from verbs) that occur in the 
index file and have the same roots, which were 
extracted from the original query words. The 
result of the query processing is then passed to the 
IR system to retrieve a ranked list of documents 
that match the terms of the query. 
 
5.2  Query Type 
 
Questions are classified based on a set of known 
?question types?. These question types help us to 
determine the type of processing needed to 
identify and extract the final answer. The QARAB 
system recognizes the following set of question 
types (Table1):   
 
Table 1.  Question Types Processed by the 
QARAB System 
 
Query Starting with Query Type 
?? Who, Whose Person 
??? When Date, Time 
????? ??  What, Which Organization, Product,Event 
??? Where Location (natural,                 political) 
?? How Much, How Many 
Number, Quantity 
 
 There are two other types of question 
particles, namely ??? and ????? (How and Why). 
Although they will form legitimate query 
structures, they require long and procedural 
answers and are beyond the scope of our research. 
It is worth mentioning that the How and the Why 
queries also caused problems for many TREC-8 
participants.  
 
 
5.3  Query Keyword Identification 
 
The remaining words of the query (after removing 
punctuation and stop-words) are tagged for part of 
speech. This process requires using the Type-
Finder  & the Proper Name-Finder system 
implemented by Abuleil [1999]. Verbs, which 
almost always follow clear morphological 
patterns, are the easiest to identify. Nouns, 
especially proper nouns, are considered as our 
best guide to find the expected answer from the 
relevant documents returned by the IR system. 
They have to occur within the selected answer 
passage and must be in the same order as they 
appeared in the original question.   A list of 
keywords to identify personal names, 
organization names, locations, numbers, money 
and dates, has been constructed for Arabic to help 
in identifying proper names.  
 
 
6 Answer Processing in QARAB 
 
The input to the QARAB Answer Generator 
module is a natural language question and a small 
set of ranked documents. The question is first 
processed by tagging all the words. Then the set 
of relevant documents that may contain the 
answer are retrieved by the IR system. In the 
answer generation process, the passages of the 
relevant documents that match (are similar to) the 
query?s ?bag of words? closely are collected for 
further processing. The answer zones usually 
include most of the terms appearing in the original 
query in addition to the proper nouns that should 
appear in the final answer.  The following 
example illustrates the whole process taken by the 
QARAB system to answer a question. 
 
The following document extracted from the 
newspaper Al-Raya published in Qatar was 
processed by the IR system: 
 
 
 ??? ????? ????? ??????? ??????? ????? ???? ??? ??????
 ?????? ??? ?? ????? ??? ????? ????? ???? ???? ??????? ???????
 ???? ??? ??? ????  .???? ?? ????? ???????? ?? ?????????
 ??????? ???? ??????? ?????? ?????????? ?? ??????? ???????
???????. 
? ????? ??????? ?? ???? ???? ?????? ?????? ???? ????? ???? ?
 ??? ??????? ?? ???? ????? ?? . ?????? ????? ?? ?????????
 ???? ????? ?? ????? ??? ??????? ????/??????????? ??? 
 ?????. 
 Translated by ajeeb: www.ajeeb.com 
 
Said the governor of the Kuwaiti central bank is 
sheikh Salem Abd Al-Aziz Al-Sabah yesterday 
that his countries not have her the intention to the 
Kuwaiti dinar devaluation to the restriction from 
the increasing inability in the budget. And 
believed that the dinar devaluation will harm the 
Kuwait economy and her credibility in the 
international exchanges. 
And confirmed the sheikh Salem is that the central 
bank will not reduce the currency value as a 
means to the inability reduction in the budget. 
From it is expected that the inability in a budget 
reaches a year 1998 / 1999 that ends in June is six 
billions dollar. 
  
Assume the user posed the following question to 
QARAB: 
 ?? ?? ????? ????? ??????? ??????? ????? ??? ??? ????? ???
????? ????? ???? ???? ??????? ???? ?? ??? ?????????? 
Translated by ajeeb: www.ajeeb.com 
 
Who he is the governor of the Kuwaiti central 
bank and that believed by that his country not 
have her the intention to the dinar devaluation to 
the restriction from the budget inability? 
 
 
Step 1: The query is processed as shown in 
Table 2 
 
Table 2. Query Processing 
 
Token Stem Part of 
Speech 
Stop 
Word
?? he ?? Pronoun Yes 
????? governor ????? Noun  
????? bank ??? Noun  
??????? central ???? Noun  
??????? Kuwaiti ???? Noun  
? and ? Conjunction Yes 
???? that ???? Pronoun Yes 
??? said ??? Verb  
??? that ??? Particle Yes 
????? his country ???? Noun  
??? not ??? Verb Yes 
????? have ??? Particle Yes 
????? intention ??? Noun  
???? devaluation ??? Noun  
???? value ???? Noun  
???????  dinar ????? Noun  
???? restriction ?? Noun  
?? from ?? Preposition Yes 
??? inability ??? Noun  
????????? budget ??????? Noun  
? ? ? Punctuation Yes 
 
Step 2: QARAB constructs the query as a ?bag 
 of words? and passes it to the IR system  
 
Table 3. Bag of words 
 
????? 
??? 
???? 
???? 
???? 
??? 
??? 
???? 
????? 
?? 
??? 
???????
 
Assume the system returned the following 
document as the top ranked document that closely 
matches the query. 
 
 ?????  ????? ???? ??? ? ????? ????? ??????? ??????? ???
 ???? ???? ???????  ????? ??? ????? ??????????? ??? ?? 
 ??? ???? ???  .????????? ???????? ?? ????? ?? ??????? ????
 ?????????? ?? ??????? ?????? ???? ??????? ???? ??????? 
??????? ???????. 
 ?????? ?????? ???? ???? ?? ????? ??????????? ????? ???? ?? 
?? ???????? ??????? ?? ????  . ????????? ?? ????? ?????? 
???? ????? ?? ????? ??? ??????? ????/???? ??? ??????? 
?????. 
 
Step 3: Determine the expected type of the 
answer 
 
?? ?Who? ? Person Name 
 Step 4: Generating the answer 
 
The Answer Generator looks for keywords that 
might identify a person name using the personal 
names keywords. The input to the Answer 
Generator is the ?bag of words? and the 
paragraphs extracted from the top ranked relevant 
documents. 
 ????? ???? ??? ?????? ??????? ???????  ????? ????? ??? 
 ????? ???? ???? ???????  ??? ????? ??????? ?? ?????? ? 
???  ???? ??? .????????? ???????? ?? ????? ?? ???? ???????
 ?????????? ?? ??????? ?????? ???? ??????? ???? ??????? 
??????? ???????. 
 ?????? ?????? ???? ????  ?? ????? ??????????? ????? ???? ??
 ?? ????? ??? ??????? ?? ???? .????????? ?? ??????????? 
???? ????? ?? ????? ??? ??????? ????/???? ??? ??????? 
?????. 
 
Keywords that might identify personal names: 
 
The keyword ????? sheikh is used to mark an 
Arabic personal name. 
The keyword ??? A?bd is used to mark the 
beginning of a personal name. 
 ?????? ??? ???? ???????? ????? ????? ??????? ??????? 
 ?????? ??? ?? ????? ??? ????? ????? ???? ???? ??????? ???????
???? ??? ??? ???? ???????  .???? ?? ????? ???????? ?? ?????????
??????? ???? ??????? ?????? ?????????? ?? ??????? ??????? . 
 ???? ?? ????? ??????? ?? ???? ???? ?????? ????????? 
 ??? ??????? ?? ???? ????? . ?????? ?????? ????? ?? ?????????
 ???? ????? ?? ????? ??? ??????? ????/?????? ??????? ??? 
 ?????. 
 
The first paragraph has most of the query words 
and the keywords that might identify a personal 
name. Therefore, the first paragraph is returned as 
the potential answer. 
 ????? ???? ??? ?????? ??? ????? ????? ??????? ??????? 
??? ?? ????? ??? ????? ????? ???? ???? ??????? ??????? ?????? 
???? ??? ??? ???? ???????  .???? ?? ????? ???????? ?? ?????????
 ???? ??????? ?????? ?????????? ?? ??????? ??????? ???????. 
 
 
7  Conclusion 
 
We have described an approach to question 
answering system that provides short answers to 
questions expressed in the Arabic language. The 
system utilizes techniques from IR and NLP to 
process a collection of Arabic text documents as 
its primary source of knowledge. An actual 
system named QARAB is implemented and an 
initial ad-hoc analysis seems to be promising. The 
overall success of the system is limited to the 
amount of available tools developed for the 
Arabic language.  Work is undergoing to get 
retrieval integrated into the system and to extend 
the functionality of the NLP system by developing 
more sophisticated algorithms to produce a 
concise answer in a timely manner.  
 
 
References 
 
Abuleil, S., and Evens, M., 1998. ?Discovering 
Lexical Information by Tagging Arabic 
Newspaper Text?, Workshop on Semantic 
Language Processing. COLING-ACL ?98, 
University of Montreal, Montreal, PQ, 
Canada, Aug. 16 1998, pp. 1-7. 
Al-Daimi, K., and Abdel-Amir, M. 1994. ?The 
Syntactic Analysis of Arabic by Machine?. 
Computers and Humanities, Vol. 28, No. 1, 
pp. 29-37. 
Allan, J., Callan, J., Feng, F-F., and Malin D. 
1999. ?INQUERY and TREC-8?. Proceedings 
of the 8th Text REtrieval Conference (TREC-
8), NIST Special Publications 500-246, pp. 
637-645. 
Ask Jeeves. 1996. www.ask.com Site last visited 
 in March 2001. 
Breck, E., Burger, J., Ferro, L., House, D., Light, 
M., and Mani, I. 1999. ?A Sys Called Qanda?. 
Proceedings of the 8th Text REtrieval 
Conference, NIST Special Publications, pp. 
499-507. 
Budzik, J. and Hammond, K. 1999. ?Q&A: A 
System for the Capture, Organization and 
Reuse of Expertise?. Proceedings of the Sixty-
second Annual Meeting of the American 
Society for Information Science. Information 
 Today, Inc., Medford, NJ. Available on the 
Web at 
http://dent.infolab.nwu.edu/infolab/downloads
/papers/paper10061.pdf. Site last visited in 
August 2001. 
Burke, R., Hammond, K., Kulyukin, V., Lytinen, 
S., Tomuro, N., and Schoenberg, S. 1997. 
?Question Answering from Frequently-Asked 
Question Files: Experiences with the FAQ 
Finder System?. AI Magazine, Vol. 18, No.2, 
pp. 57-66. 
Cardie, C., Ng, V., Pierce, D., and Buckley, C. 
2000. ?Examining the Role of Statistical and 
Linguistic Knowledge Sources in a General-
Knowledge Question-Answering System?.  
Proceedings of the Sixth Applied Natural 
Language Processing Conference, pp. 180-
187. 
Cormack, G., Clarke, C., and Kisman, D. 1999. 
?Fast Automatic Passage Ranking (MultiText 
Experiments for TREC-8)?. Proceedings of 
the 8th Text REtrieval Conference (TREC-8), 
NIST Special Publications 500-246, pp. 735-
743. 
Ferret, O., Grau, B., Illouz, G., Jacquemin, C., and 
Masson, N. 1999.  ?QALC - the Question-
Answering Program of the Language and 
Cognition Group at LIMSI-CNRS?. 
Proceedings of the 8th Text REtrieval 
Conference, NIST Special Publications, pp. 
465-475. 
Harabagiu, S., Pasca, M., and Maiorano, S. 2000. 
?Experiments with Open-Domain Textual 
Question Answering?.  Proceedings of 18th 
International Conference on Computational 
Linguistics (COLING-2000), Saarbrucken, 
Germany, pp. 292-298 
Hull, D. 1999. ?Xerox TREC-8 Question 
Answering Track Report?. Proceedings of the 
8thText REtrieval Conference (TREC-8), 
NIST Special Publications 500-246, pp. 743-
751. 
Humphreys, K., Gaizauskas, R., Hepple, M., and 
Sanderson, M. 1999. ?University of Sheffield 
TREC-8 Q & A System?. Proceedings of the 
8th Text REtrieval Conference (TREC-8), 
NIST Special Publications 500-246, pp. 707-
717. 
Jacobs, P., and Rau, L. 1990. ?SCISOR: 
Extracting Information from On-line News?. 
Communications of the ACM, Vol. 33, No.11, 
pp. 88-97. 
Katz, B. 1997. ?From Sentence Processing to 
Information Access on the World Wide Web?. 
Proceedings of the American Association for 
Artificial Intelligence Conference, Spring 
Symposium, NLP for WWW, pp. 77-86. 
Khoja, S. 1999. ?Stemming Arabic Text?.  
Available on the Web at: 
http://www.comp.lancs.ac.uk/computing/users
/khoja/stemmer.ps. Site last visited in March 
2001. 
Kupiec, J. 1993. ?MURAX: A Robust Linguistic 
Approach for Question Answering Using an 
On-line Encyclopedia?. Proceedings of the 
16th Annual Int. ACM SIGIR Conference, pp. 
181-190. 
Lehnert, W. 1978. The Process of Question 
Answering. Lawrence Erlbaum Associates, 
Hillsdale, NJ. 
Lin, C-J, and Chen, H-H. 1999. ?Description of 
Preliminary Results to TREC-8 QA Task?. 
Proceedings of the 8th Text REtrieval 
Conference(TERC-8), NIST Special 
Publications 500-246, pp. 507-513. 
Litkowski, K. 1999.  ?Question-Answering Using 
Semantic Relation Triples?. Proceedings of  
the 8th Text REtrieval Conference (TREC-8), 
NIST Special Publications 500-248, pp. 349-
357 
Lundquist, C., Grossman, D., and Frieder, O. 
1999. "Improving Relevance Feedback in the 
Vector Space Model". Proceedings of 6th 
ACM Annual Conference on Information and 
Knowledge Management (CIKM), pp. 16-23. 
Moldovan, D., Harabagiu, S., Pasca, M., 
Mihalcea, R., Girju, R., Goodrum, R., and 
Rus, V. 2000. ?The Structure and 
Performance of an Open-Domain Question-
Answering System?. Proceedings of the 38th 
Annual Meeting of the Association for 
Computational Linguistics, pp. 563-570. 
Oard, D., Wang, J., Lin, D., and Soboroff, I. 1999. 
?TREC-8 Experiments at Maryland: CLIR, 
QA and Routing?. Proceedings of the 8th Text 
 REtrieval Conference (TERC-8), NIST 
Special Publications 500-246, pp. 623-637. 
Ogden, B., Cowie, J., Ludovik, E. Molina- 
Salgado, H., Nirenburg, S., Sharples, N., and 
Sheremtyeva, S. 1999.  ?CRL's TREC-8 
Systems Cross-Lingual IR, and Q&A?. 
Proceedings of the 8th Text REtrieval 
Conference (TERC-8), NIST Special 
Publications 500-246, pp. 513-523. 
Salton, G. 1971. The SMART Retrieval System 
Experiments in Automatic Document 
Processing. Prentice Hall Inc., Englewood 
Cliffs, NJ. 
Schank, R., and Abelson, R. 1977. Scripts, Plans, 
Goals, and Understanding. Lawrence Erlbaum 
Associates, Hillsdale, NJ. 
Shin, D-H, Kim, Y-H, Kim, S., Eom, J-H, Shin, 
H-J, and Zhang B-T. 1999. ?SCAI TREC-8 
Experiments?. Proceedings of the 8th Text 
REtrieval Conference (TREC-8), NIST 
Special Publications 500-246, pp. 583-591. 
Singhal, A., Abney, S., Bacchiani, M., Collins, 
M., Hindle, D., and  Pereira, F. 1999. ?AT&T 
at TREC-8?.  Proceedings of the 8th Text 
REtrieval Conference, NIST Special 
Publications, pp. 317-331. 
Srihari, R., and Li, W. 1999.  ?Information 
Extraction Supported Question Answering?. 
Proceedings of the 8th Text REtrieval 
Conference (TREC-8), NIST Special 
Publications 500-246, pp. 185-197. 
Takaki, T. 1999. ?NTT DATA: Overview of  
System Approach at TREC-8 ad-hoc and 
Question Answering?. Proceedings of the 8th 
Text REtrieval Conference (TREC-8), NIST 
Special Publications 500-246, pp. 523-531. 
TREC-8. 1999. NIST Special Publication 500- 
246: The Eighth Text REtrieval Conference. 
Available on the Web at: 
http://trec.nist.gov/pubs/trec8/t8_proceedings.
html. Site last visited in August 2001. 
TREC-9. 2000. NIST Special Publication: The 
Ninth Text REtrieval Conference. Available 
on the Web at: 
http://trec.nist.gov/pubs/trec9/t9_proceedings.
html. Site last visited in August 2001. 
Vicedo, J., and Ferr?ndez, A. 2000. ?Importance 
of Pronominal Anaphora Resolution in 
Question- Answering System?. Proceedings 
of the 38th Annual Meeting of the Association 
for Computational Linguistics, pp. 555-562. 
Voorhees, E., and Tice, D. 1999. "The TREC-8 
Question Answering Track Evaluation". 
Proceedings of the 8th Text REtrieval 
Conference (TREC-8), NIST Special 
Publication 500-246, pp. 83-106. 
Voorhees, E., and Tice, D. 2000. ?Building a 
Question Answering Test Collection?. 
Proceedings of the 23rd Annual International 
ACM SIGIR Conference on Research and 
Development in Information Retrieval, 
Athens, Greece, pp. 200-207. 
Winograd, T. 1972. Understanding Natural 
Language. Academic Press, New York, NY. 
Woods, W., Kaplan, R., and Webber, B. 1972. 
?The Lunar Sciences Natural Language 
Information System: Final Report?. Bolt 
Beranek and Newman Inc. (BBN), Report No. 
2378.  
 
 
 
