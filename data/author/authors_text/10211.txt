Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 43?48,
Columbus, June 2008. c?2008 Association for Computational Linguistics
Impact of Initiative on Collaborative Problem Solving ?
Cynthia Kersey
Department of Computer Science
University of Illinois at Chicago
Chicago, Illinois 60613
ckerse2@uic.edu
Abstract
Even though collaboration in peer learning has
been shown to have a positive impact for stu-
dents, there has been little research into col-
laborative peer learning dialogues. We ana-
lyze such dialogues in order to derive a model
of knowledge co-construction that incorpo-
rates initiative and the balance of initiative.
This model will be embedded in an artificial
agent that will collaborate with students.
1 Introduction
While collaboration in dialogue has long been re-
searched in computational linguistics (Chu-Carroll
and Carberry, 1998; Constantino-Gonza?lez and
Suthers, 2000; Jordan and Di Eugenio, 1997;
Lochbaum and Sidner, 1990; Soller, 2004; Vizca??no,
2005), there has been little research on collabora-
tion in peer learning. However, this is an important
area of study because collaboration has been shown
to promote learning, potentially for all of the par-
ticipants (Tin, 2003). Additionally, while there has
been a focus on using natural language for intelli-
gent tutoring systems (Evens et al, 1997; Graesser
et al, 2004; VanLehn et al, 2002), peer to peer in-
teractions are notably different from those of expert-
novice pairings, especially with respect to the rich-
ness of the problem-solving deliberations and ne-
gotiations. Using natural language in collaborative
learning could have a profound impact on the way
in which educational applications engage students in
learning.
?This work is funded by NSF grants 0536968 and 0536959.
There are various theories as to why collaboration
in peer learning is effective, but one of that is com-
monly referenced is co-construction (Hausmann et
al., 2004). This theory is a derivative of construc-
tivism which proposes that students construct an un-
derstanding of a topic by interpreting new material
in the context of prior knowledge (Chi et al, 2001).
Essentially, students who are active in the learn-
ing process are more successful. In a collaborative
situation this suggests that all collaborators should
be active participants in order to have a successful
learning experience. Given the lack of research in
modeling peer learning dialogues, there has been lit-
tle study of what features of dialogue characterize
co-construction. I hypothesize that since instances
of co-construction closely resemble the concepts of
control and initiative, these dialogue features can be
used as identifiers of co-construction.
While there is some dispute as to the definitions
of control and initiative (Jordan and Di Eugenio,
1997; Chu-Carroll and Brown, 1998), it is generally
accepted that one or more threads of control pass
between participants in a dialogue. Intuitively, this
suggests that tracking the transfer of control can be
useful in determining when co-construction is occur-
ring. Frequent transfer of control between partici-
pants would indicate that they are working together
to solve the problem and perhaps also to construct
knowledge.
The ultimate goal of this research is to develop a
model of co-construction that incorporates initiative
and the balance of initiative. This model will be em-
bedded in KSC-PaL, a natural language based peer
agent that will collaborate with students to solve
43
Figure 1: The data collection interface
problems in the domain of computer science data
structures.
In section 2, I will describe how we collected the
dialogues and the initial analysis of those dialogues.
Section 3 details the on-going annotation of the cor-
pus. Section 4 describes the future development of
the computational model and artificial agent. This is
followed by the conclusion in section 5.
2 Data Collection
In a current research project on peer learning, we
have collected computer-mediated dialogues be-
tween pairs of students solving program comprehen-
sion and error diagnosis problems in the domain of
data structures. The data structures that we are fo-
cusing on are (1) linked lists, (2) stacks and (3) bi-
nary search trees. This domain was chosen because
data structures and their related algorithms are one
of the core components of computer science educa-
tion and a deep understanding of these topics is es-
sential to a strong computer science foundation.
2.1 Interface
A computer mediated environment was chosen to
more closely mimic the situation a student will have
to face when interacting with KSC-PaL, the artificial
peer agent. After observing face-to-face interactions
of students solving these problems, I developed an
interface consisting of four distinct areas (see Fig-
ure 1):
1. Problem display: Displays the problem de-
scription that is retrieved from a database.
2. Code display: Displays the code from the prob-
lem statement. The students are able to make
changes to the code, such as crossing-out lines
and inserting lines, as well as undoing these
corrections.
3. Chat Area: Allows for user input and an inter-
leaved dialogue history of both students partic-
ipating in the problem solving. The history is
logged for analysis.
4. Drawing area: Here users can diagram data
structures to aid in the explanation of parts of
the problem being solved. The drawing area
has objects representing nodes and links. These
objects can then be placed in the drawing area
to build lists, stacks or trees depending on the
type of problem being solved.
The changes made in the shared workspace
(drawing and code areas) are logged and propagated
to the partner?s window. In order to prevent users
from making changes at the same time, I imple-
mented a system that allows only one user to draw or
make changes to code at any point in time. In order
to make a change in the shared workspace, a user
must request the ?pencil? (Constantino-Gonza?lez
and Suthers, 2000). If the pencil is not currently al-
located to her partner, the user receives the pencil
and can make changes in the workspace. Otherwise,
the partner is informed, through both text and an au-
dible alert, that his peer is requesting the pencil. The
chat area, however, allows users to type at the same
time, although they are notified by a red circle at the
top of the screen when their partner is typing. While,
this potentially results in interleaved conversations,
it allows for more natural communication between
the peers.
Using this interface, we collected dialogues for
a total of 15 pairs where each pair was presented
with five problems. Prior to the collaborative prob-
lem solving activities, the participants were individ-
ually given pre-tests and at the conclusion of the ses-
sion, they were each given another test, the post-
test. During problem solving the participants were
seated in front of computers in separate rooms and
all problem solving activity was conducted using the
computer-mediated interface. The initial exercise let
the users become acquainted with the interface. The
44
Prob. 3 Prob. 4 Prob. 5
Predictor (Lists) (Stacks) (Trees)
Pre-Test 0.530
(p=0.005)
0.657
(p=0.000)
0.663
(p=0.000)
Words 0.189
(p=0.021)
Words
per Turn
0.141
(p=0.049)
Pencil
Time
0.154
(p=0.039)
Total
Turns
0.108
(p=0.088)
Code
Turns
0.136
(p=0.076)
Table 1: Post-test Score Predictors (R2)
participants were allowed to ask questions regarding
the interface and were limited to 30 minutes to solve
the problem. The remaining exercises had no time
limits, however the total session, including pre-test
and post-test could not exceed three hours. There-
fore not all pairs completed all five problems.
2.2 Initial Analysis
After the completion of data collection, I established
that the interface and task were conducive to learn-
ing by conducting a paired t-test on the pre-test and
post-test scores. This analysis showed that the post-
test score was moderately higher than the pre-test
score (t(30)=2.83; p=0.007; effect size = 0.3).
I then performed an initial analysis of the col-
lected dialogues using linear regression analysis to
identify correlations between actions of the dyads
and their success at solving the problems presented
to them. Besides the post-test, students solutions
to the problems were scored, as well; this is what
we refer to as problem solving success. The par-
ticipant actions were also correlated with post-test
scores and learning gains (the difference between
post-test score and pre-test score). The data that
was analyzed came from three of the five problems
for all 15 dyads, although not all dyads attempted
all three problems. Thus, I analyzed a total of 40
subdialogues. The problems that were analyzed are
all error diagnosis problems, but each problem in-
volves a different data structure - linked list, array-
based stack and binary search tree. Additionally,
I analyzed the relationship between initiative and
post-test score, learning gain and successful problem
solving. Before embarking on an exhaustive man-
ual annotation of initiative, I chose to get a sense of
whether initiative may indeed affect learning in this
context by automatically tagging for initiative using
an approximation of Walker and Whittaker?s utter-
ance based allocation of control rules (Walker and
Whittaker, 1990). In this scheme, first each turn in
the dialogue must be tagged as either: (1) an asser-
tion, (2) a command, (3) a question or (4) a prompt
(turns not expressing propositional content). This
was done automatically, by marking turns that end
in a question mark as questions, those that start with
a verb as commands, prompts from a list of com-
monly used prompts (e.g. ok, yeah) and the remain-
ing turns as assertions. Control is then allocated by
using the following rules based on the turn type:
1. Assertion: Control is allocated to the speaker
unless it is a response to a question.
2. Command: Control is allocated to the speaker.
3. Question: Control is allocated to the speaker,
unless it is a response to a question or a com-
mand.
4. Prompt: Control is allocated to the hearer.
Since the dialogues also have a graphics compo-
nent, all drawing and code change moves had con-
trol assigned to the peer drawing or making the code
change.
The results of the regression analysis are summa-
rized in tables 1 and 2, with blank cells representing
non-significant correlations. Pre-test score, which
represents the student?s initial knowledge and/or ap-
titude in the area, was selected as a feature because
it is important to understand the strength of the cor-
relation between previous knowledge and post test
score when identifying additional correlating fea-
tures (Yap, 1979). The same holds for the time re-
lated features (pencil time and total time). The re-
maining correlations and trends to correlation sug-
gest that participation is an important factor in suc-
cessful collaboration. Since a student is more likely
to take initiative when actively participating in prob-
45
Prob. 3 Prob. 4 Prob. 5
Predictor (Lists) (Stacks) (Trees)
Pre-Test 0.334
(p=0.001)
0.214
(p=0.017)
0.269
(p=0.009)
Total
Time
0.186
(p=0.022)
0.125
(p=0.076)
0.129
(p=0.085)
Total
Turns
0.129
(p=0.061)
0.134
(p=0.065)
Draw
Turns
0.116
(p=0.076)
0.122
(p=0.080)
Code
Turns
0.130
(p=0.071)
Table 2: Problem Score Predictors (R2)
lem solving, potentially there there is a relation be-
tween these participation correlations and initiative.
An analysis of initiative shows that there is a cor-
relation of initiative and successful collaboration. In
problem 3, learning gain positively correlates with
the number of turns where a student has initiative
(R2 = 0.156, p = 0.037). And in problem 4, taking
initiative through drawing has a positive impact on
post-test score (R2 = 0.155, p = 0.047).
3 Annotation
Since the preliminary analysis showed a correlation
of initiative with learning gain, I chose to begin a
thorough data analysis by annotating the dialogues
with initiative shifts. Walker and Whittaker claim
that initiative encompasses both dialogue control
and task control (Walker and Whittaker, 1990), how-
ever, several others disagree. Jordan and Di Eugenio
propose that control and initiative are two separate
features in collaborative problem solving dialogues
(Jordan and Di Eugenio, 1997). While control and
initiative might be synonymous for the dialogues an-
alyzed by Walker and Whittaker where a master-
slave assumption holds, it is not the case in collab-
orative dialogues where no such assumption exists.
Jordan and Di Eugenio argue that the notion of con-
trol should apply to the dialogue level, while ini-
tiative should pertain to the problem-solving goals.
In a similar vein, Chu-Carroll and Brown also ar-
gue for a distinction between control and initiative,
which they term task initiative and dialogue initia-
tive (Chu-Carroll and Brown, 1998). Since there is
no universally agreed upon definition for initiative, I
have decided to annotate for both dialogue initiative
and task initiative. For dialogue initiative annota-
tion, I am using Walker and Whittaker?s utterance
based allocation of control rules (Walker and Whit-
taker, 1990), which are widely used to identify di-
alogue initiative. For task initiative, I have derived
an annotation scheme based on other research in the
area. According to Jordan and Di Eugenio, in prob-
lem solving (task) initiative the agent takes it upon
himself to address domain goals by either (1)propos-
ing a solution or (2)reformulating goals. In a simi-
lar vein, Guinn (Guinn, 1998) defines task initiative
as belonging to the participant who dictates which
decomposition of the goal will be used by both par-
ticipants during problem-solving. A third definition
is from Chu-Carroll and Brown. They suggest that
task initiative tracks the lead in development of the
agent?s plan. Since the primary goal of the dialogues
studied by Chu-Carroll and Brown is to develop a
plan, this could be re-worded to state that task ini-
tiative tracks the lead in development of the agent?s
goal. Combining these definitions, task initiative can
be defined as any action by a participant to either
achieve a goal directly, decompose a goal or refor-
mulate a goal. Since the goals of our problems are
understanding and potentially correcting a program,
actions in our domain that show task initiative in-
clude actions such as explaining what a section of
code does or identifying a section of code that is in-
correct.
Two coders, the author and an outside annotator,
have coded 24 dialogues (1449 utterances) for both
dialogue and task initiative. This is approximately
45% of the corpus. The resulting intercoder reli-
ability, measured with the Kappa statistic, is 0.77
for dialogue initiative annotation and 0.68 for task
initiative, both of which are high enough to support
tentative conclusions. Using multiple linear regres-
sion analysis on these annotated dialogues, I found
that, in a subset of the problems, there was a sig-
nicant correlation between post-test score (after re-
moving the effects of pre-test scores) and the num-
ber of switches in dialogue initiative (R2 =0.157,
p=0.014). Also, in the same subset, there was a
correlation between post-test score and the number
of turns that a student had initiative (R2 =0.077,
p=0.065). This suggests that both taking the ini-
46
tiative and taking turns in leading problem solving
results in learning.
Given my hypothesis that initiative can be used
to identify co-construction, the next step is to an-
notate the dialogues using a subset of the DAMSL
scheme (Core and Allen, 1997) to identify episodes
of co-construction. Once annotated, I will use ma-
chine learning techniques to identify co-construction
using initiative as a feature. Since this is a classi-
fication problem, algorithms such as Classification
Based on Associations (Liu, 2007) will be used. Ad-
ditionally, I will explore those algorithms that take
into account the sequence of actions, such as hidden
Markov models or neural networks.
4 Computational Model
The model will be implemented as an artificial
agent, KSC-PaL, that interacts with a peer in collab-
orative problem solving using an interface similar to
the one that was used in data collection (see Fig-
ure 1). This agent will be an extension of the TuTalk
system, which is designed to support natural lan-
guage dialogues for educational applications (Jordan
et al, 2006). TuTalk contains a core set of dialogue
system modules that can be replaced or enhanced as
required by the application. The core modules are
understanding and generation, a dialogue manager
which is loosely characterized as a finite state ma-
chine with a stack and a student model. To imple-
ment the peer agent, I will replace TuTalk?s student
model and add a planner module.
Managing the information state of the dialogue
(Larsson and Traum, 2000), which includes the be-
liefs and intentions of the participants, is important
in the implementation of any dialogue agent. KSC-
PaL will use a student model to assist in manage-
ment of the information state. This student model
tracks the current state of problem solving as well
as estimates the student?s knowledge of concepts
involved in solving the problem by incorporating
problem solution graphs (Conati et al, 2002). So-
lution graphs are Bayesian networks where each
node represents either an action required to solve
the problem or a concept required as part of prob-
lem solving. After analyzing our dialogues, I real-
ized that the solutions to the problems in our do-
main are different from standard problem-solving
tasks. Given that our tasks are program compre-
hension tasks and that the dialogues are peer led,
there can be no assumption as to the order in which
a student will analyze code statements. Therefore
a graph comprised of connected subgraphs that each
represent a section of the code more closely matches
what I observed in our dialogues. So, we are using a
modified version of solution graphs that has clusters
of nodes representing facts that are relevant to the
problem. Each cluster contains facts that are depen-
dent on one another. For example, one cluster repre-
sents facts related to the push method for a stack. As
the code is written, it would be impossible to com-
prehend the method without understanding the pre-
fix notation for incrementing. A user?s utterances
and actions can then be matched to the nodes within
the clusters. This provides the agent with informa-
tion related to the student?s knowledge as well as the
current topic under discussion.
A planner module will be added to TuTalk to pro-
vide KSC-PaL with a more sophisticated method of
selecting scripts. Unlike TuTalk?s dialogue manager
which uses a simple matching of utterances to con-
cepts in order to determine the script to be followed,
KSC-PaL?s planner will incorporate the results of the
data analysis above and will also include the status
of the student?s knowledge, as reflected in the stu-
dent model, in making script selections. This plan-
ner will potentially be a probabilistic planner such
as the one in (Lu, 2007).
5 Conclusion
In conclusion, we are developing a computational
model of knowledge construction which incorpo-
rates initiative and the balance of initiative. This
model will be embedded in an artificial agent that
collaborates with students to solve data structure
problems. As knowledge construction has been
shown to promote learning, this research could have
a profound impact on educational applications by
changing the way in which they engage students in
learning.
Acknowledgments
The graphical interface is based on a graphical inter-
face developed by Davide Fossati for an intelligent
tutoring system in the same domain.
47
References
Michelene T. H. Chi, Stephanie A. Siler, Jeong Heisawn,
Takashi Yamauchi, and Robert G. Hausmann. 2001.
Learning from human tutoring. Cognitive Science,
25(4):471?533.
Jennifer Chu-Carroll and Michael K. Brown. 1998. An
evidential model for tracking initiative in collabora-
tive dialogue interactions. User Modeling and User-
Adapted Interaction, 8(3?4):215?253, September.
Jennifer Chu-Carroll and Sandra Carberry. 1998. Col-
laborative response generation in planning dialogues.
Computational Linguistics, 24(3):355?400.
Cristina Conati, Abigail Gertner, and Kurt Vanlehn.
2002. Using bayesian networks to manage uncer-
tainty in student modeling. User Modeling and User-
Adapted Interaction, 12(4):371?417.
Mar??a de los Angeles Constantino-Gonza?lez and
Daniel D. Suthers. 2000. A coached collaborative
learning environment for entity-relationship modeling.
Intelligent Tutoring Systems, pages 324?333.
Mark G. Core and James F. Allen. 1997. Coding dia-
logues with the DAMSL annotation scheme. In David
Traum, editor, Working Notes: AAAI Fall Symposium
on Communicative Action in Humans and Machines,
pages 28?35, Menlo Park, California. American Asso-
ciation for Artificial Intelligence.
Martha W. Evens, Ru-Charn Chang, Yoon Hee Lee,
Leem Seop Shim, Chong Woo Woo, Yuemei Zhang,
Joel A. Michael, and Allen A. Rovick. 1997. Circsim-
tutor: an intelligent tutoring system using natural lan-
guage dialogue. In Proceedings of the fifth conference
on Applied natural language processing, pages 13?14,
San Francisco, CA, USA. Morgan Kaufmann Publish-
ers Inc.
Arthur C. Graesser, Shulan Lu, George Tanner Jackson,
Heather Hite Mitchell, Mathew Ventura, Andrew Ol-
ney, and Max M. Louwerse. 2004. Autotutor: A tutor
with dialogue in natural language. Behavior Research
Methods, Instruments, & Computers, 36:180?192(13),
May.
Curry I. Guinn. 1998. An analysis of initiative selection
in collaborative task-oriented discourse. User Model-
ing and User-Adapted Interaction, 8(3-4):255?314.
Robert G.M. Hausmann, Michelee T.H. Chi, and Mar-
guerite Roy. 2004. Learning from collaborative prob-
lem solving: An analysis of three hypothesized mech-
anisms. In K.D Forbus, D. Gentner, and T. Regier, edi-
tors, 26th Annual Converence of the Cognitive Science
Society, pages 547?552, Mahwah, NJ.
Pamela W. Jordan and Barbara Di Eugenio. 1997. Con-
trol and initiative in collaborative problem solving di-
alogues. In Working Notes of the AAAI Spring Sympo-
sium on Computational Models for Mixed Initiative,
pages 81?84, Menlo Park, CA.
Pamela W. Jordan, Michael Ringenberg, and Brian Hall.
2006. Rapidly developing dialogue systems that sup-
port learning studies. In Proceedings of ITS06 Work-
shop on Teaching with Robots, Agents, and NLP, pages
1?8.
Staffan Larsson and David R. Traum. 2000. Information
state and dialogue management in the trindi dialogue
move engine toolkit. Nat. Lang. Eng., 6(3-4):323?340.
Bing Liu. 2007. Web data mining: exploring hyperlinks,
contents, and usage data. Springer.
Karen E. Lochbaum and Candice L. Sidner. 1990. Mod-
els of plans to support communication: An initial re-
port. In Thomas Dietterich and William Swartout, ed-
itors, Proceedings of the Eighth National Conference
on Artificial Intelligence, pages 485?490, Menlo Park,
California. AAAI Press.
Xin Lu. 2007. Expert Tutoring and Natural Language
Feedback in Intelligent Tutoring Systems. Ph.D. thesis,
University of Illinois at Chicago.
Amy Soller. 2004. Computational modeling and analysis
of knowledge sharing in collaborative distance learn-
ing. User Modeling and User-Adapted Interaction,
Volume 14(4):351?381, January.
Tan Bee Tin. 2003. Does talking with peers help learn-
ing? the role of expertise and talk in convergent group
discussion tasks. Journal of English for Academic
Purposes, 2(1):53?66.
Kurt VanLehn, Pamela W. Jordan, Carolyn Penstein
Rose?, Dumisizwe Bhembe, Michael Bo?ttner, Andy
Gaydos, Maxim Makatchev, Umarani Pappuswamy,
Michael A. Ringenberg, Antonio Roque, Stephanie
Siler, and Ramesh Srivastava. 2002. The architec-
ture of why2-atlas: A coach for qualitative physics es-
say writing. In ITS ?02: Proceedings of the 6th Inter-
national Conference on Intelligent Tutoring Systems,
pages 158?167, London, UK. Springer-Verlag.
Aurora Vizca??no. 2005. A simulated student can im-
prove collaborative learning. International Journal of
Artificial Intelligence in Education, 15(1):3?40.
Marilyn Walker and Steve Whittaker. 1990. Mixed ini-
tiative in dialogue: an investigation into discourse seg-
mentation. In Proceedings of the 28th annual meeting
on Association for Computational Linguistics, pages
70?78, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Kim Onn Yap. 1979. Pretest-posttest correlation and
regression models. Presented at the Annual Meet-
ing of the American Educational Research Association
(63rd, San Francisco, California), April 8?12.
48
Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 55?63,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
KSC-PaL: A Peer Learning Agent that Encourages Students to take the
Initiative?
Cynthia Kersey and Barbara Di Eugenio
Department of Computer Science
University of Illinois at Chicago
Chicago, IL 60607 USA
ckerse2@uic.edu
bdieugen@cs.uic.edu
Pamela Jordan and Sandra Katz
Learning Research and Development Center
University of Pittsburgh
Pittsburgh, PA 15260 USA
pjordan+@pitt.edu
katz+@pitt.edu
Abstract
We present an innovative application of dis-
course processing concepts to educational
technology. In our corpus analysis of peer
learning dialogues, we found that initiative
and initiative shifts are indicative of learn-
ing, and of learning-conducive episodes. We
are incorporating this finding in KSC-PaL, the
peer learning agent we have been developing.
KSC-PaL will promote learning by encourag-
ing shifts in task initiative.
1 Introduction
Collaboration in dialogue has long been researched
in computational linguistics (Chu-Carroll and Car-
berry, 1998; Constantino-Gonza?lez and Suthers,
2000; Jordan and Di Eugenio, 1997; Lochbaum and
Sidner, 1990; Soller, 2004; Vizca??no, 2005), how-
ever, the study of peer learning from a computa-
tional perspective is still in the early stages. This
is an important area of study because peer learning
has been shown to be an effective mode of learn-
ing, potentially for all of the participants (Cohen et
al., 1982; Brown and Palincsar, 1989; Birtz et al,
1989; Rekrut, 1992). Additionally, while there has
been a focus on using natural language for intelli-
gent tutoring systems (Evens et al, 1997; Graesser
et al, 2004; VanLehn et al, 2002), peer to peer in-
teractions are notably different from those of expert-
novice pairings, especially with respect to the rich-
ness of the problem-solving deliberations and ne-
gotiations. Using natural language in collaborative
?This work is funded by NSF grants 0536968 and 0536959.
learning could have a profound impact on the way
in which educational applications engage students in
learning.
Previous research has suggested several mecha-
nisms that explain why peer learning is effective for
all participants. Among them are: self-directed ex-
plaining(Chi et al, 1994), other-directed explaining
(Ploetzner et al, 1999; Roscoe and Chi, 2007) and
Knowledge Co-construction ? KCC for short (Haus-
mann et al, 2004). KCC episodes are defined as
portions of the dialogue in which students are jointly
constructing a shared meaning of a concept required
for problem solving. This last mechanism is the
most interesting from a peer learning perspective be-
cause it is a truly collaborative construct and also be-
cause it is consistent with the widely accepted con-
structivist view of learning.
Since KCC is a high-level concept that is not eas-
ily recognized by an artificial agent we collected
peer learning interactions from students and stud-
ied them to identify features that might be useful in
identifying KCC. We found that linguistically based
initiative shifts seem to capture the notion of col-
laborative construction. A more thorough analysis
found a strong relationship between KCC and initia-
tive shifts and moderate correlations between initia-
tive shifts and learning.
The results of this analysis are being incorporated
into KSC-PaL, an artificial agent that can collaborate
with a human student via natural-language dialogue
and actions within a graphical workspace. KSC-PaL
has been developed in the last two years. Dialogue-
wise, its core is TuTalk (Jordan et al, 2007), a dia-
logue management system that supports natural lan-
55
guage dialogue in educational applications. As we
will describe, we have already developed its user
interface and its student model and have extended
TuTalk?s planner to provide KSC-PaL with the abil-
ity to induce initiative shifts. For the version of
KSCPal we will present in this paper, we wanted to
focus on the question of whether this style of inter-
action helps learning; and we were concerned that
its limitations in disambiguating the student?s input
could impact this interaction. Hence, this round of
experiments employs a human ?helper? that is given
a list of concepts the input may match, and chooses
the most appropriate one.
The work presented in this paper is part of a larger
research program: we analyze different paradigms ?
tutoring dialogues and peer-learning dialogues? in
the same basic domain, devise computational mod-
els for both, and implement them in two separate
SW systems, an ITS and the peer-learning system
we present here. For our work on the tutoring dia-
logue corpus and the ITS please see (Fossati et al,
accepted for publication 2009).
Our domain in both cases is problem solving in
basic data structure and algorithms, which is part of
foundations of Computer Science. While in recent
years, interest in CS in the US has dropped dramat-
ically, CS is of enormous strategic interest, and is
projected to foster vast job growth in the next few
years (AA. VV., 2006). We believe that by support-
ing CS education in its core we can have the largest
impact on reversing the trend of students? disinter-
est. Our belief is grounded in the observation that
the rate of attrition is highest at the earliest phases
of undergraduate CS curricula. This is due in part
to students? difficulty with mastering basic concepts
(Katz et al, 2003), which require a deep understand-
ing of static structures and the dynamic procedures
used to manipulate them (AA. VV., 2001). These
concepts also require the ability to move seamlessly
among multiple representations, such as text, pic-
tures, pseudo-code, and real code in a specific pro-
gramming language.
Surprisingly, few educational SW systems ad-
dress CS topics, e.g. teaching a specific program-
ming language like LISP (Corbett and Anderson,
1990) or database concepts (Mitrovic? et al, 2004).
Additionally, basically they are all ITSs, where the
relationship between the system and the student
is one of ?subordination?. Only two or three of
these ITSs address foundations, including: Autotu-
tor (Graesser et al, 2004) addresses basic literacy,
but not data structures or algorithms; ADIS (Waren-
dorf and Tan, 1997) tutors on basic data structures,
but its emphasis is on visualization, and it appears to
have been more of a proof of concept than a work-
ing system; ProPL (Lane and VanLehn, 2003) helps
novices design their programs, by stressing problem
solving and design skills.
In this paper, we will first discuss the collection
and analysis of peer learning interactions. Then, we
discuss the design of our peer agent, and how it is
guided by the results of our analysis. We conclude
by briefly describing the user experiments we are
about to undertake, and whose preliminary results
will be available at the time of the workshop.
2 Data collection
We have collected peer learning interactions from 15
pairs of students solving problems in the domain of
computer science data structures. Students were re-
cruited from introductory courses on data structures
and algorithms. Each problem involved one of three
types of data structures: linked-lists, stacks and bi-
nary search trees. Each problem was either a debug-
ging problem where the students were asked to work
together to identify errors in the code or an explana-
tion problems in which the students jointly created
an explanation of a segment of code.
The students interacted using a computer me-
diated interface1 where they could communicate
via text-based chat, drawing and making changes
to code (see Figure 1). The graphical workspace
(drawing and coding areas) was shared such that
changes made by one student were propagated to
his/her partner?s workspace. Access to this graph-
ical workspace was controlled so that only one stu-
dent was allowed to draw or make changes to code
at any point in time.
Each pair was presented with a total of 5 prob-
lems, although not all pairs completed all prob-
lems due to time limitations. The interactions for
each pair were subdivided into separate dialogues
1Using text to communicate versus face-to-face interactions
should be comfortable for most students given the prevalence
of communication methods such as text messaging and instant
messengers.
56
Figure 1: The data collection / KSC-PaL interface
for each problem. Thus, we collected a corpus con-
sisting of a total of 73 dialogues.
In addition to collecting problem solving data,
we also presented each student with a pre-test prior
to problem solving and an identical post-test at the
conclusion of problem solving in order to measure
learning gains. A paired t-test of pre- and post-test
scores showed that students did learn during collab-
orative problem solving (t(30)=2.83; p=0.007). The
interactions produced an average normalized learn-
ing gain of 17.5 (possible total points are 50).
3 Analysis of Peer Learning Interactions
Next, we undertook an extensive analysis of the cor-
pus of peer learning interactions in order to deter-
mine the behaviors with which to endow KSC-PaL.
3.1 Initiative: Annotation
Given the definition of KCC, it appeared to us that
the concept of initiative from discourse and dialogue
processing should play a role: intuitively, if the stu-
dents are jointly contructing a concept, the initiative
cannot reside only with one, otherwise the partner
would just be passive. Hence, we annotated the dia-
logues for both KCC and initiative.
The KCC annotation involved coding the dia-
logues for KCC episodes. These are defined as a
series of utterances and graphical actions in which
students are jointly constructing a shared meaning of
a concept required for problem solving (Hausmann
et al, 2004). Using this definition, an outside anno-
tator and one of the authors coded 30 dialogues (ap-
proximately 46% of the corpus) for KCC episodes.
This entailed marking the beginning utterance and
the end utterance of such episodes, under the as-
sumption that all intervening utterances do belong to
the same KCC episode (otherwise the coder would
mark an earlier end for the episode). The result-
ing intercoder reliability, measured with the Kappa
statistic(Carletta, 1996), is considered excellent (? =
0.80).
Our annotation of initiative was two fold. Since
there is disagreement in the computational lin-
guistics community as to the precise definition of
57
initiative(Chu-Carroll and Carberry, 1998; Jordan
and Di Eugenio, 1997), we annotated the dialogues
for both dialogue initiative, which tracks who is
leading the conversation and determining the cur-
rent conversational focus, and task initiative, which
tracks the lead in problem solving.
For dialogue initiative annotation, we used the
well-known utterance-based rules for allocation of
control from (Walker and Whittaker, 1990). In
this scheme, each utterance is tagged with one of
four dialogue acts (assertion, command, question or
prompt) and control is then allocated based on a set
of rules. The dialogue act annotation was done au-
tomatically, by marking turns that end in a question
mark as questions, those that start with a verb as
commands, prompts from a list of commonly used
prompts (e.g. ok, yeah) and the remaining turns as
assertions. To verify that the automatic annotation
was good, we manually annotated a sizable portion
of the dialogues with those four dialogue acts. We
then compared the automatic annotation against the
human gold standard, and we found an excellent ac-
curacy: it ranged from 86% for assertions and ques-
tions, to 97% for prompts, to 100% for commands.
Once the dialogue acts had been automatically an-
notated, two coders, one of the authors and an out-
side annotator, coded 24 dialogues (1449 utterances,
approximately 45% of the corpus) for dialogue ini-
tiative, by using the four control rules from (Walker
and Whittaker, 1990):
1. Assertion: Control is allocated to the speaker
unless it is a response to a question.
2. Command: Control is allocated to the speaker.
3. Question: Control is allocated to the speaker,
unless it is a response to a question or a com-
mand.
4. Prompt: Control is allocated to the hearer.
The resulting intercoder reliability on dialogue ini-
tiative was 0.77, a quite acceptable level of agree-
ment. We then experimented with automatically an-
notating dialogue initiative according to those con-
trol rules. Since the accuracy against the gold stan-
dard was 82%, the remaining 55% of the corpus was
also automatically annotated for dialogue initiative,
using those four control rules.
As concerns task initiative, we define it as any ac-
tion by a participant to either achieve a goal directly,
decompose a goal or reformulate a goal (Guinn,
1998; Chu-Carroll and Brown, 1998). Actions in
our domain that show task initiative include:
? Explaining what a section of code does.
? Identifying that a section of code as correct or
incorrect.
? Suggesting a correction to a section of code
? Making a correction to a section of code prior
to discussion with the other participant.
The same two coders annotated for task initiative
the same portion of the corpus already annotated for
dialogue initiative. The resulting intercoder reliabil-
ity for task initiative is 0.68, which is high enough
to support tentative conclusions. The outside coder
then manually coded the remaining 55% of the cor-
pus for task initiative.
3.2 KCC, initiative and learning
In analyzing the annotated dialogues, we used mul-
tiple linear regression to identify correlations of the
annotated features and post-test score. We used pre-
test score as a covariate because of its significant
positive correlations with post-test score. Due to
variations in student ability in the different problem
types, our analysis focused only on a portion of the
collected interactions. In the tree problem there was
a wide variation in experience level of the students
which would inhibit KCC. In the stack problem, the
students had a better understanding of stacks prior
to problem solving and spent less time in discussion
and problem solving. Thus, our analysis focused
only on the linked-list problems.
We started by analyzing the relationship between
KCC and learning. As a measurement of KCC we
used KCC actions which is the number of utter-
ances and graphical actions that occur during KCC
episodes. This analysis showed that KCC does have
a positive correlation with learning in our corpus. In
Table 1, the first row shows the benefit for the dyad
overall by correlating the mean post-test score with
the mean pre-test score and the dyad?s KCC actions.
The second row shows the benefit for individuals by
58
correlating individual post-test scores with individ-
ual pre-test scores and the dyad?s KCC actions. The
difference in the strength of these correlations sug-
gests that members of the dyads are not benefitting
equally from KCC. If the subjects are divided into
two groups, those with a pre-test score below the
mean score ( n=14) and those with a pre-test score
above the mean score ( n=16) , it can be seen that
those with a low pre-test score benefit more from
the KCC episodes than do those with a high pre-test
score (rows 3 and 4 in Table 1).
KCC actions predict ? R2 p
Mean post-test score 0.43 0.14 0.02
Individual post-test score 0.33 0.08 0.03
Individual post-test score 0.61 0.37 0.03
(low pre-test subjects)
Individual post-test score 0.33 0.09 ns
(high pre-test subjects)
Table 1: KCC Actions as Predictor of Post-test Score
Next, we explored the relationship between learn-
ing and the number of times initiative shifted be-
tween the students. Intuitively, we assumed that fre-
quent shifts of initiative would reflect students work-
ing together to solve the problem. We found there
was a significant correlation between post-test score
(after removing the effects of pre-test scores) and the
number of shifts in dialogue initiative and the num-
ber of shifts in task initiative (see Table 2). This
analysis excluded two dyads whose problem solving
collaboration had gone awry.
Predictor of Post-test ? R2 p
Dialogue initiative shifts 0.45 0.20 0.00
Task initiative shifts 0.42 0.20 0.01
Table 2: Initiative Predictors of Post-test Score
We then computed a second measure of KCC that
is meant to reflect the density of the KCC episodes.
KCC initiative shifts is the number of task initiative
shifts that occur during KCC episodes. Many task
initiative shifts reflect more active KCC.
Table 3 uses KCC initiative shifts as the measure
of co-construction. It shows similar results to ta-
ble 1, where KCC actions was used. Note that when
the outlier dyads were removed the correlation with
learning is much stronger for the low pre-test score
subjects when KCC initiative shifts are used as the
measure of KCC (R2 = 0.45, p = 0.02) than when
KCC actions are used.
KCC initiative shifts predict ? R2 p
Mean post-test score 0.46 0.15 0.01
Individual post-test score 0.35 0.09 0.02
Individual post-test score 0.67 0.45 0.02
(low pre-test subjects)
Individual post-test score 0.10 0.01 ns
(high pre-test subjects)
Table 3: KCC Initiative Shifts Predictors of Post-test
Score
Lastly we investigated the hypothesis that KCC
episodes involve frequent shifts in initiative, as both
participants are actively participating in problem
solving. To test this hypothesis, we calculated
the average initiative shifts per line during KCC
episodes and the average initiative shifts per line
during problem solving outside of KCC episodes for
each dyad. A paired t-test was then used to verify
that there is a difference between the two groups.
The t-test showed no significant difference in aver-
age dialogue initiative shifts in KCC episodes com-
pared with non-KCC problem solving. However,
there is a significant difference between average task
initiative shifts in KCC episodes compared with the
rest of the dialogue ( t(57) = 3.32, p = 0.0016). The
effect difference between the two groups (effect size
= 0.65 ) shows that there is a meaningful increase in
the number of task initiative shifts in KCC episodes
compared with problem solving activity outside of
the KCC episodes.
3.3 Indicators of task initiative shifts
Since our results show that task initiative shifts are
conducive to learning, we want to endow our soft-
ware agent with the ability to encourage a shift in
initiative from the agent to the student, when the
student is overly passive. The question is, what are
natural indicators in dialogue that the partner should
take the initiative? We explored two different meth-
ods for encouraging initiative shifts. One is that stu-
dent uncertainty may lead to a shift in initiative. The
other consists of cues for initiative shifts identified
59
in related literature(Chu-Carroll and Brown, 1998;
Walker and Whittaker, 1990).
Intuitively, uncertainty by a peer might lead to his
partner taking the initiative. One possible identi-
fier of student uncertainty is hedging. To validate
this hypothesis, we annotated utterances in the cor-
pus with hedging categories as identified in (Bhatt
et al, 2004). Using these categories we were unable
to reliably annotate for hedging. But, after collaps-
ing the categories into a single binary value of hedg-
ing/not hedging we arrived at an acceptable agree-
ment (? = 0.71).
Another identifier of uncertainty is a student?s re-
quest for feedback from his partner. When uncertain
of his contribution, a student may request an evalua-
tion from his peer. So, we annotated utterances with
?request for feedback? and were able to arrive at an
excellent level of intercoder reliability (? = 0.82).
(Chu-Carroll and Brown, 1998) identifies cues
that may contribute to the shift of task and dialogue
initiative. Since task initiative shifts appear to iden-
tify KCC episodes, we chose to explore the follow-
ing cues that potentially result in the shift of task
initiative.
? Give up task. These are utterances where
the student explicitly gives up the task using
phrases like ?Any other ideas??.
? Pause. A pause may suggest that the speaker
has nothing more to say in the current turn and
intends to give up his initiative.
? Prompts. A prompt is an utterance that has no
propositional content.
? Invalid statements. These are incorrect state-
ments made by a student.
Using hedging, request for feedback and initia-
tive cues, we were able to identify 283 shifts in task
initiative or approximately 67% of all task initiative
shifts in the corpus. The remaining shifts were likely
an explicit take over of initiative without a preceding
predictor.
Since we found several possible ways to predict
and encourage initiative shifts, the next step was to
identify which of these predictors more often re-
sulted in an initiative shift; and, for which predic-
tors the resulting initiative shift more often led to an
increase in the student?s knowledge level. Table 4
shows the percentage of instances of each predictor
that resulted in an initiative shift.
Percent of instances that
Cue/Identifier led to initiative shift
Hedge 23.94%
Request feedback 21.88%
Give-up task 20.00%
Pause 25.27%
Prompt 29.29%
Invalid statement 38.64%
Table 4: Cues for Shifts in Initiative
Along with the likelihood of a predictor leading
to an initiative shift, we also examined the impact
of a shift of task initiative on a student?s level of
knowledge, measured using knowledge score, cal-
culated on the basis of the student model (see Sec-
tion 4). This is an important characteristic since we
want to encourage initiative shifts in an effort to in-
crease learning. First, we analyzed initiative shifts
to determine if they resulted in an increase in knowl-
edge score. We found that in our corpus, an initiative
shift leads to an increase in a student?s knowledge
level in 37.0% of task initiative shifts, a decrease
in knowledge level in 5.2% of shifts and unchanged
in 57.8% of shifts. Even though over one-half of
the time knowledge scores were not impacted, in
only a small minority of instances did a shift have
a negative impact on a student?s level of knowledge.
Therefore, we more closely examined the predictors
to see which more frequently led to an increase in
student knowledge. The results of that analysis is
show in table 5.
Percent of shifts where
Predictor knowledge level increased
Hedge 23.52%
Request feedback 17.65%
Give-up task 0.00%
Prompt 32.93%
Pause 14.22%
Invalid statement 23.53%
Table 5: Task Initiative Shifts/Knowledge Level Change
60
4 KSC-PaL, a software peer
Our peer-learning agent, KSC-PaL, has at its core
the TuTalk System(Jordan et al, 2007), a dialogue
management system that supports natural language
dialogue in educational applications. Since TuTalk
does not include an interface or a student model, we
developed both in previous years. We also needed to
extend the TuTalk planner to recognize and promote
initiative shifts.
The user interface is structured similarly to the
one used in data collection(see Figure 1). How-
ever, we added additional features to allow a stu-
dent to effectively communicate with the KSC-PaL.
First, all drawing and coding actions of the student
are interpreted and passed to the agent as a natural
language utterance. Graphical actions are matched
to a set of known actions and when a student sig-
nals that he/she has finished drawing or coding ei-
ther by ceding control of the graphical workspace or
by starting to communicate through typed text, the
interface will attempt to match what the student has
drawn or coded with its database of known graphi-
cal actions. These graphical actions include not only
correct ones but also anticipated misconceptions that
were collected from the data collection interactions.
The second enhancement to the interface is a spell
corrector for ?chat slang?. We found in the corpus,
that students often used abbreviations that are com-
mon to text messaging. These abbreviations are not
recognized by the English language spell corrector
in the TuTalk system, so a chat slang interpretation
module was added.
KSC-PaL requires a student model to track the
current state of problem solving as well as esti-
mate the student?s knowledge of concepts involved
in solving the problem in order to guide its behav-
ior. Our student model incorporates problem solu-
tion graphs (Conati et al, 2002). Solution graphs
are Bayesian networks where each node represents
either an action required to solve the problem, a
concept required as part of problem solving or an
anticipated misconception. A user?s utterances and
actions are then matched to these nodes. A knowl-
edge score can be calculated at any point in time by
taking a sum of the probabilities of all nodes in the
graph, except the misconception nodes. The sum of
the probabilities of the misconception nodes are sub-
tracted from the total to arrive at a knowledge score.
This score is then normalized by dividing it by the
maximum possible knowledge score for the solution
graph.
4.1 KSC-PaL and initiative
Since our corpus study showed that the level of task
initiative can be used to identify when KCC and
potentially learning is occurring, we have endowed
KSC-PaL with behaviors to manipulate shifts in task
initiative in order to encourage KCC and learning.
This required three enhancements: first, the ability
to recognize the initiative holder in each utterance
or action; second, the ability to encourage the shift
of initiative from the agent to the student; and three,
extending the TuTalk planner so that it can process
task initiative shifts.
As concerns the first step, that the agent recog-
nize the initiative holder in each utterance or action,
we resorted to machine learning. Using the Weka
Toolkit(Witten and Frank, 2005), we explored var-
ious machine learning algorithms and feature sets
that could reliably identify the holder of task initia-
tive. We found that the relevant features of an ac-
tion in the graphical workspace were substantially
different from those of a natural language utterance.
Therefore, we trained and tested separate classifiers
for each type of student action. After examining a
wide variety of machine learning algorithms we se-
lected the following two classifiers: (1) K* (Cleary
and Trigg, 1995), a clustering algorithm, for clas-
sifying natural language utterances which correctly
classified 71.7699% of utterance and (2) JRip (Co-
hen, 1995), a rule-based algorithm, for classifying
drawing and coding actions which correctly classi-
fied 86.971% of the instances.
As concerns the second step, encouraging initia-
tive shifts so that the student assumes the task initia-
tive, we use the results of our analysis of the indica-
tors of task initiative shifts from Section 3.3. KSC-
PaL will use prompts, request feedback and make
invalid statements in order to encourage initiative
shifts and promote learning.
Finally, we augmented the TuTalk planner so that
it selects scripts to manage task initiative shifts. Two
factors will determine whether a script that encour-
ages initiative shifts will be selected: the current
level of initiative shifts and the change in the stu-
61
dent?s knowledge score. Task initiative shifts will be
tracked using the classifier described above. Scripts
will be selected to encourage initiative shifts when
the average level of initiative shifts is less than the
mean initiative shifts in KCC episodes (calculated
from the corpus data) and the student?s knowledge
level has not increased since the last time a script
selection was requested. The scripts are based on
the analysis of methods for encouraging initiative
shifts described above. Specifically, KSC-PaL will
encourage initiative shifts by responding to student
input using prompts, requesting feedback from the
student and encouraging student criticism by inten-
tionally making errors in problem solving.
We are now poised to run user experiments. We
will run subjects in two conditions with KSC-PaL:
in the first condition (control), KSC-PaL will not en-
courage task initiative shifts and act more as a tutor;
in the second condition, KSC-PaL will encourage
task initiative shifts as we just discussed. One final
note: because we do not want our experiments to be
affected by the inability of the agent to interpret an
utterance, given current NLU technology, the inter-
face will ?incorporate? a human interpreter. The in-
terpreter will receive student utterances along with a
list of possible matching concepts from TuTalk. The
interpreter will select the most likely matching con-
cept, thus assisting TuTalk in natural language in-
terpretation. Note that the interpreter has a limited,
predetermined sets of choices, corresponding to the
concepts TuTalk knows about. In this way, his / her
intervention is circumscribed.
5 Conclusions
After an extensive analysis of peer-learning interac-
tions, we have found that task initiative shifts can
be used to determine when students are engaged
in knowledge co-construction. We have embed-
ded this finding in a peer-learning agent, KSC-PaL,
that varies its behavior to encourage initiative shifts
and knowledge co-construction in order to promote
learning. We are poised to run our user experiments,
and we will have preliminary results available by the
workshop time.
References
AA. VV. 2001. Computer Science, Final Report, The
Joint Task Force on Computing Curricula. IEEE Com-
puter Society and Association for Computing Machin-
ery, IEEE Computer Society.
AA. VV. 2006. US bureau of labor statistics
http://www.bls.gov/oco/oco20016.htm.
Khelan Bhatt, Martha Evens, and Shlomo Argamon.
2004. Hedged responses and expressions of affect in
human/human and human computer tutorial interac-
tions. In Proceedings Cognitive Science.
M. W. Birtz, J. Dixon, and T. F. McLaughlin. 1989. The
effects of peer tutoring on mathematics performance:
A recent review. B. C. Journal of Special Education,
13(1):17?33.
A. L. Brown and A. S. Palincsar, 1989. Guided, cooper-
ative learning and individual knowledge acquisition,
pages 307?226. Lawrence Erlbaum Associates, Hills-
dale, NJ.
Jean Carletta. 1996. Assessing agreement on classifi-
cation tasks: the kappa statistic. Comput. Linguist.,
22(2):249?254.
M.T.H. Chi, N. De Leeuw, M.H. Chiu, and C. LaVancher.
1994. Eliciting self-explanations improves under-
standing. Cognitive Science, 18(3):439?477.
Jennifer Chu-Carroll and Michael K. Brown. 1998. An
evidential model for tracking initiative in collabora-
tive dialogue interactions. User Modeling and User-
Adapted Interaction, 8(3?4):215?253, September.
Jennifer Chu-Carroll and Sandra Carberry. 1998. Col-
laborative response generation in planning dialogues.
Computational Linguistics, 24(3):355?400.
John G. Cleary and Leonard E. Trigg. 1995. K*: An
instance-based learner using an entropic distance mea-
sure. In Proc. of the 12th International Conference on
Machine Learning, pages 108?114.
P.A. Cohen, J.A. Kulik, and C.C. Kulik. 1982. Educa-
tion outcomes of tutoring: A meta-analysis of findings.
American Education Research Journal, 19(2):237?
248.
William W. Cohen. 1995. Fast effective rule induction.
In Machine Learning: Proceedings of the Twelve In-
ternational Conference.
Cristina Conati, Abigail Gertner, and Kurt Vanlehn.
2002. Using bayesian networks to manage uncer-
tainty in student modeling. User Modeling and User-
Adapted Interaction, 12(4):371?417.
Mar??a de los Angeles Constantino-Gonza?lez and
Daniel D. Suthers. 2000. A coached collaborative
learning environment for entity-relationship modeling.
Intelligent Tutoring Systems, pages 324?333.
Albert T. Corbett and John R. Anderson. 1990. The ef-
fect of feedback control on learning to program with
the LISP tutor. In Proceedings of the Twelfth Annual
Conference of the Cognitive Science Society, pages
796?803.
62
Martha W. Evens, Ru-Charn Chang, Yoon Hee Lee,
Leem Seop Shim, Chong Woo Woo, Yuemei Zhang,
Joel A. Michael, and Allen A. Rovick. 1997. Circsim-
tutor: an intelligent tutoring system using natural lan-
guage dialogue. In Proceedings of the fifth conference
on Applied natural language processing, pages 13?14,
San Francisco, CA, USA. Morgan Kaufmann Publish-
ers Inc.
Davide Fossati, Barbara Di Eugenio, Christopher Brown,
Stellan Ohlsson, David Cosejo, and Lin Chen. ac-
cepted for publication, 2009. Supporting Computer
Science curriculum: Exploring and learning linked
lists with iList. EEE Transactions on Learning Tech-
nologies, Special Issue on Real-World Applications of
Intelligent Tutoring Systems.
Arthur C. Graesser, Shulan Lu, George Tanner Jackson,
Heather Hite Mitchell, Mathew Ventura, Andrew Ol-
ney, and Max M. Louwerse. 2004. Autotutor: A tutor
with dialogue in natural language. Behavior Research
Methods, Instruments, & Computers, 36:180?192(13),
May.
Curry I. Guinn. 1998. An analysis of initiative selection
in collaborative task-oriented discourse. User Model-
ing and User-Adapted Interaction, 8(3-4):255?314.
Robert G.M. Hausmann, Michelene T.H. Chi, and Mar-
guerite Roy. 2004. Learning from collaborative prob-
lem solving: An analysis of three hypothesized mech-
anisms. In K.D Forbus, D. Gentner, and T. Regier, edi-
tors, 26th Annual Conference of the Cognitive Science
Society, pages 547?552, Mahwah, NJ.
Pamela W. Jordan and Barbara Di Eugenio. 1997. Con-
trol and initiative in collaborative problem solving di-
alogues. In Working Notes of the AAAI Spring Sympo-
sium on Computational Models for Mixed Initiative,
pages 81?84, Menlo Park, CA.
Pamela W Jordan, Brian Hall, Michael A. Ringenberg,
Yui Cue, and Carolyn Penstein Rose?. 2007. Tools for
authoring a dialogue agent that participates in learning
studies. In Artificial Intelligence in Education, AIED
2007, pages 43?50.
S. Katz, J. Aronis, D. Allbritton, C. Wilson, and M.L.
Soffa. 2003. Gender and race in predicting achieve-
ment in computer science. Technology and Society
Magazine, IEEE, 22(3):20?27.
H. Chad Lane and Kurt VanLehn. 2003. Coached pro-
gram planning: dialogue-based support for novice pro-
gram design. SIGCSE Bull., 35(1):148?152.
Karen E. Lochbaum and Candace L Sidner. 1990. Mod-
els of plans to support communication: An initial re-
port. In Proceedings of the Eighth National Confer-
ence on Artificial Intelligence, pages 485?490. AAAI
Press.
A. Mitrovic?, P. Suraweera, B. Martin, and A. Weeras-
inghe. 2004. DB-Suite: Experiences with Three In-
telligent, Web-Based Database Tutors. Journal of In-
teractive Learning Research, 15(4):409?433.
R. Ploetzner, P. Dillenbourg, M. Preier, and D. Traum.
1999. Learning by explaining to oneself and to others.
Collaborative learning: Cognitive and computational
approaches, pages 103?121.
M. D. Rekrut. 1992. Teaching to learn: Cross-age tutor-
ing to enhance strategy instruction. American Educa-
tion Research Association.
Rod D. Roscoe and Michelene T. H. Chi. 2007.
Understanding tutor learning: Knowledge-building
and knowledge-telling in peer tutors? explanations
and questions. Review of Educational Research,
77(4):534?574.
Amy Soller. 2004. Computational modeling and analysis
of knowledge sharing in collaborative distance learn-
ing. User Modeling and User-Adapted Interaction,
Volume 14(4):351?381, January.
Kurt VanLehn, Pamela W. Jordan, Carolyn Penstein
Rose?, Dumisizwe Bhembe, Michael Bo?ttner, Andy
Gaydos, Maxim Makatchev, Umarani Pappuswamy,
Michael A. Ringenberg, Antonio Roque, Stephanie
Siler, and Ramesh Srivastava. 2002. The architec-
ture of why2-atlas: A coach for qualitative physics es-
say writing. In ITS ?02: Proceedings of the 6th Inter-
national Conference on Intelligent Tutoring Systems,
pages 158?167, London, UK. Springer-Verlag.
Aurora Vizca??no. 2005. A simulated student can im-
prove collaborative learning. International Journal of
Artificial Intelligence in Education, 15(1):3?40.
Marilyn Walker and Steve Whittaker. 1990. Mixed ini-
tiative in dialogue: an investigation into discourse seg-
mentation. In Proceedings of the 28th annual meeting
on Association for Computational Linguistics, pages
70?78, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Kai Warendorf and Colin Tan. 1997. Adis-an animated
data structure intelligent tutoring system or putting an
interactive tutor on the www. In Intelligent Educa-
tional Systems on the World Wide Web (Workshop Pro-
ceedings), at the Eight International Conference on
Artficial Intellignece in Education.
Ian H. Witten and Eibe Frank. 2005. Data Mining: Prac-
tical machine learning tools and techniques. Morgan
Kaufmann, San Francisco.
63
Proceedings of the NAACL HLT 2010: Demonstration Session, pages 17?20,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
KSC-PaL: A Peer Learning Agent that Encourages Students to take the
Initiative?
Cynthia Kersey
Lewis University
Romeoville, IL 60446 USA
kerseycy@lewisu.edu
Barbara Di Eugenio
University of Illinois at Chicago
Chicago, IL 60607 USA
bdieugen@cs.uic.edu
Pamela Jordan and Sandra Katz
University of Pittsburgh
Pittsburgh, PA 15260 USA
pjordan+@pitt.edu
katz+@pitt.edu
Abstract
We present an innovative application of dia-
logue processing concepts to educational tech-
nology. In a previous corpus analysis of peer
learning dialogues, we found that initiative
and initiative shifts are indicative of learning,
and of learning-conducive episodes. We have
incorporated this finding in KSC-PaL, a peer
learning agent. KSC-PaL promotes learning
by encouraging shifts in task initiative.
1 Introduction
Collaborative learning has been shown to be an ef-
fective mode of learning for potentially all partic-
ipants (Brown and Palincsar, 1989; Fisher, 1993;
Tin, 2003). While collaboration in dialogue has long
been researched in computational linguistics (Chu-
Carroll and Carberry, 1998; Constantino-Gonza?lez
and Suthers, 2000; Jordan and Di Eugenio, 1997;
Soller, 2004), the study of peer learning from a com-
putational perspective is still in the early stages.
Previous research has suggested several mecha-
nisms that explain why peer learning is effective.
Among them are: self-directed explaining (Chi et
al., 1994), other-directed explaining (Ploetzner et
al., 1999; Roscoe and Chi, 2007) and Knowledge
Co-construction ? KCC for short (Hausmann et al,
2004). KCC episodes are defined as portions of the
dialogue in which students are jointly constructing
a shared meaning of a concept required for problem
solving. This last mechanism is the most interesting
from a peer learning perspective because it is a truly
?This work is funded by NSF grants 0536968 and 0536959.
collaborative construct and also because it is consis-
tent with the widely accepted constructivist view of
learning.
In our previous work (Kersey et al, 2009) we de-
rived a model of peer interactions that operational-
izes KCC via the notion of initiative shifts in dia-
logue. This model was based on an extensive corpus
analysis in which we found a strong relationship be-
tween initiative shifts and KCC episodes. A paired t-
test showed that there were significantly more initia-
tive shifts in the annotated KCC episodes compared
with the rest of the dialogue ( t(57) = 3.32, p =
0.0016). The moderate effect difference between
the two groups (effect size = 0.49 ) shows that there
is a meaningful increase in the number of initia-
tive shifts in KCC episodes compared with problem
solving activity outside of the KCC episodes. Addi-
tionally, we found moderate correlations of learning
with both KCC (R2 = 0.14, p = 0.02) and with
initiative shifts (R2 = 0.20, p = 0.00).
We have incorporated this model in an innovative
peer learning agent, KSC-PaL, that is designed to
collaborate with a student to solve problems in the
domain of computer science data structures.
2 KSC-PaL
KSC-PaL, has at its core the TuTalk System (Jordan
et al, 2007), a dialogue management system that
supports natural language dialogue in educational
applications. In developing KSC-PaL we extended
TuTalk in three ways.
The first extension is a user interface (see Fig-
ure 1) which manages communication between
TuTalk and the student. Students interact with KSC-
17
Figure 1: The KSC-PaL interface
PaL using natural language and graphical actions.
The student input is processed by the interface and
its related modules into an appropriate format and
passed to TuTalk. Since TuTalk?s interpretation
module is not able to appropriately handle all stu-
dent utterances, a human interpreter assists in this
process. The interpreter receives a student utterance
along with a list of possible matching concepts from
TuTalk (see Figure 4). The interpreter then selects
the most likely matching concepts from TuTalk thus
assisting in natural language interpretation. If the
student utterance doesn?t match any of these con-
cepts, a second list of concepts, containing student
initiative utterances, are presented to the interpreter.
If none of these match then all known concepts are
presented to the interpreter for matching. Note that
the interpreter has a limited, predetermined set of
choices, corresponding to the concepts that TuTalk
is aware of. In this way, his/her intervention is cir-
cumscribed.
The second addition is the incorporation of a stu-
dent model that allows the KSC-PaL to track the
current state of problem solving and the student?s
knowledge in order to guide its behavior. TuTalk?s
student model was replaced with one that incorpo-
rates problem solution graphs (Conati et al, 2002).
Solution graphs are Bayesian networks where each
node represents either an action required to solve the
problem or a concept required as part of problem
solving. A user?s utterances and actions are then
matched to these nodes. This provides KSC-PaL
with information related to the student?s knowledge
of problem solving concepts as well as the current
topic under discussion.
Thirdly, a planning module was added to TuTalk
to make decisions on implementation of problem
solving goals and responses to student initiative in
order to manage shifts in initiative. The planning
module includes an initiative tracker that codes turns
with with either student initiative or agent initiative
using one classifier for natural language utterances
and a separate classifier for drawing and coding ac-
tions. Once a turn is classified, it is determined
whether a shift in initiative has occurred by compar-
18
ing the current classification with the classification
of the previous turn. An average level of initiative
shifts is then computed by dividing the number of
initiative shifts by the total number of turns. Based
on the initiative level, KSC-PaL encourages initia-
tive shifts by using prompts, hedging, requesting
feedback from the student and encouraging student
criticism by intentionally making errors in problem
solving.
Our evaluation of KSC-PaL (Kersey et al, June
2010) found that students learned using the agent
and that KSC-PaL was was successful in encourag-
ing shifts in initiative.
3 Demonstration Outline
We will demonstrate a problem solving episode with
KSC-PaL where a user will interact with the agent as
a student. Specifically we will show how KSC-PaL
attempts to manage the level of initiative and how
KSC-PaL reacts to student initiative.
1. Amy: hi there, are you ready
to start?
2. Mary: sure
3. Amy: where to begin?
4. Mary: i don?t know
5. Amy: maybe we should draw this
6. Amy: do you want to draw it?
7. Mary: ok
8. Amy: so, line 1 ...
9. Mary: how?s that?
10. Amy: hmmm
11. Amy: line 2: first.next=
second.next
(Mary diagrams the code segment)
12. Mary: there i finished it
13. Amy: looks good
14. Amy: i think we?re done drawing
15. Mary: yes
16. Amy: basically, it switches the
first and second elements
17. Mary: right
18. Amy: ill write the explanation
19. Mary: ok
Figure 2: Problem Solving Example
Figure 2 shows an excerpt from a typical prob-
lem solving session. Amy, the agent, attempts to
maintain a balanced level of initiative either by en-
couraging the student (Mary) to take initiative, or by
taking initiative. In lines 10 and 11, the agent uses a
prompt followed by repetition of the problem solv-
ing goal to encourage the student to retain the initia-
tive. However, in line 16 the agent takes initiative by
proposing a solution to the problem.
KSC-PaL is also able to manage the situation
where the student takes initiative in the dialogue in
an unanticipated manner, as shown in Figure 3. In
line 3, Mary asks a question that is not expected
at this point in the problem solving process and the
agent responds appropriately in line 4. KSC-PaL is
able to respond to a set of student initiations derived
from corpus data, such as the one in this excerpt.
Additionally, the agent responds in a generic man-
ner to other unanticipated initiations and directs the
student back to problem solving.
1. Mary: let?s look at the code
2. Amy: so, i think first and
second both equal bat
3. Mary: is second a reference or
a node?
4. Amy: second is a reference
Figure 3: Student Initiative Example
References
A. L. Brown and A. S. Palincsar, 1989. Guided, cooper-
ative learning and individual knowledge acquisition,
pages 307?226. Lawrence Erlbaum Associates, Hills-
dale, NJ.
M.T.H. Chi, N. De Leeuw, M.H. Chiu, and C. LaVancher.
1994. Eliciting self-explanations improves under-
standing. Cognitive Science, 18(3):439?477.
Jennifer Chu-Carroll and Sandra Carberry. 1998. Col-
laborative response generation in planning dialogues.
Computational Linguistics, 24(3):355?400.
Cristina Conati, Abigail Gertner, and Kurt VanLehn.
2002. Using Bayesian networks to manage uncer-
tainty in student modeling. User Modeling and User-
Adapted Interaction, 12(4):371?417.
Mar??a de los Angeles Constantino-Gonza?lez and
Daniel D. Suthers. 2000. A coached collaborative
learning environment for entity-relationship modeling.
Intelligent Tutoring Systems, pages 324?333.
19
Figure 4: The interface for the human interpreter
E. Fisher. 1993. Distinctive features of pupil-pupil class-
room talk and their relationship to learning: How dis-
cursive exploration might be encouraged. Language
and Education, 7:239?257.
Robert G.M. Hausmann, Michelene T.H. Chi, and Mar-
guerite Roy. 2004. Learning from collaborative prob-
lem solving: An analysis of three hypothesized mech-
anisms. In K.D Forbus, D. Gentner, and T. Regier, edi-
tors, 26th Annual Conference of the Cognitive Science
Society, pages 547?552, Mahwah, NJ.
Pamela W. Jordan and Barbara Di Eugenio. 1997. Con-
trol and initiative in collaborative problem solving di-
alogues. In Working Notes of the AAAI Spring Sympo-
sium on Computational Models for Mixed Initiative,
pages 81?84, Menlo Park, CA.
Pamela W Jordan, Brian Hall, Michael A. Ringenberg,
Yui Cue, and Carolyn Penstein Rose?. 2007. Tools for
authoring a dialogue agent that participates in learning
studies. In Artificial Intelligence in Education, AIED
2007, pages 43?50.
Cynthia Kersey, Barbara Di Eugenio, Pamela Jordan, and
Sandra Katz. 2009. KSC-PaL: a peer learning agent
that encourages students to take the initiative. In Pro-
ceedings of the Fourth Workshop on Innovative Use of
NLP for Building Educational Applications, pages 55?
63. Association for Computational Linguistics.
Cynthia Kersey, Barbara Di Eugenio, Pamela Jordan, and
Sandra Katz. June 2010. KSC-PaL: A peer learning
agent. In ITS 2010, The 10th International Conference
on Intelligent Tutoring Systems, Pittsburgh, PA.
R. Ploetzner, P. Dillenbourg, M. Preier, and D. Traum.
1999. Learning by explaining to oneself and to others.
Collaborative learning: Cognitive and computational
approaches, pages 103?121.
Rod D. Roscoe and Michelene T. H. Chi. 2007.
Understanding tutor learning: Knowledge-building
and knowledge-telling in peer tutors? explanations
and questions. Review of Educational Research,
77(4):534?574.
Amy Soller. 2004. Computational modeling and analysis
of knowledge sharing in collaborative distance learn-
ing. User Modeling and User-Adapted Interaction,
Volume 14(4):351?381, January.
Tan Bee Tin. 2003. Does talking with peers help learn-
ing? the role of expertise and talk in convergent group
discussion tasks. Journal of English for Academic
Purposes, 2(1):53?66.
20
