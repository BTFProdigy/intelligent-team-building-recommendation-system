Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 555?562,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Modeling Adjectives in Computational Relational Lexica 
 
Palmira Marrafa 
Department of Linguistics, Faculty of Arts, 
University of Lisbon and 
CLG ? Group for the Computation of Lexical 
and Grammatical Knowledge,  
Center of Linguistics ? University of Lisbon, 
Avenida Professor Gama Pinto, 2 
1649-003 Lisbon Portugal 
palmira.marrafa@netcabo.pt 
Sara Mendes 
CLG ? Group for the Computation of Lexical 
and Grammatical Knowledge 
Center of Linguistics ? University of Lisbon 
Avenida Professor Gama Pinto, 2 
1649-003 Lisbon, Portugal 
sara.mendes@clul.ul.pt 
  
Abstract 
In this paper we propose a small set of 
lexical conceptual relations which allow 
to encode adjectives in computational re-
lational lexica in a principled and inte-
grated way. Our main motivation comes 
from the fact that adjectives and certain 
classes of verbs, related in a way or an-
other with adjectives, do not have a satis-
factory representation in this kind of 
lexica. This is due to a great extent to the 
heterogeneity of their semantic and syn-
tactic properties. We sustain that such 
properties are mostly derived from the 
relations holding between adjectives and 
other POS. Accordingly, our proposal is 
mainly concerned with the specification 
of appropriate cross-POS relations to en-
code adjectives in lexica of the type con-
sidered here.  
1 Introduction 
As well known, the experiment conducted by 
George Miller on the mental lexicon properties 
in the early 80s pointed out that lexical meaning 
is derived from a set of lexical and conceptual 
relations among concepts. Subsequently, a com-
putational lexicon conceived as a semantic net-
work has been built (the Princeton WordNet 
(Miller, 1990; Fellbaum, 1998)). Given its psy-
chological plausibility and its crucial role for 
applications like machine translation, informa-
tion retrieval and language learning systems, 
among many others, this relational lexicon 
model is being extensively adopted for machine 
lexical knowledge representations, playing a 
leading role in this field.  
One of the most salient undertaking in this 
domain is EuroWordNet (Vossen, 1998), a mul-
tilingual database which stores wordnets for sev-
eral European languages that follow the same 
main lines as the Princeton WordNet (Miller, 
1990; Fellbaum, 1998) and are inter-related 
amongst them.   
EuroWordNet wordnets follow the Princeton 
WordNet model, but they are richer concerning 
both the number and the nature of conceptual 
relations.  
The work depicted here programmatically 
adopts the EuroWordNet framework. 
In general terms, it deals with the specifica-
tions for an accurate modeling of lexical knowl-
edge in a EuroWordNet wordnet-like database 
for Portuguese (WordNet.PT, henceforth), spe-
cifically focusing on the lexical semantics of 
adjectives. 
Although WordNet.PT (Marrafa, 2001; Mar-
rafa, 2002) is being developed in the general Eu-
roWordNet framework, basic research has been 
carried out on Portuguese in order to guarantee 
the WordNet.PT accuracy. This work has al-
ready led to some changes and new directions 
(cf. Marrafa et al, (2006) and Amaro et al, 
(2006), for instance).  
In this paper we propose a small set of new re-
lations which allow a strongly empirical moti-
vated encoding of the major POS in Word-
Net.PT, despite the fact that we particularly fo-
cus on adjectives. The empirical issues at stake 
are described in section 2. In section 3 we dis-
cuss the strategies adopted in previous work car-
ried out both in WordNet and EuroWordNet 
frameworks, in order to make their shortcomings 
apparent. In section 4 we present our proposal 
555
and argue for its relevance and soundness. Sec-
tion 5 presents some results concerning the en-
coding of adjectives in WordNet.PT. We con-
clude the paper with some final remarks. 
2 Empirical Issues 
Adjective semantic analysis and representation is 
far from being a trivial issue, as adjectives show 
a very particular linguistic behavior, namely in 
what concerns sense change depending on lin-
guistic context. Being so, there are several dif-
ferent typologies and classifications of adjectives 
in the literature: semantic based classifications, 
syntactic based classifications, classifications 
regarding the relation holding between the adjec-
tive and the modified noun, and so on.  
As our work on this issue progresses, it has 
become clear that only a combination of syntac-
tic and semantic criteria can offer interesting 
insights concerning adjective linguistic behavior 
and the identification of relevant common fea-
tures, which may set the basis for an accurate 
modeling of this POS in computational relational 
lexica. In this section we will briefly look at 
some of the main adjective classifications. 
Regarding the way adjectives relate to the 
noun they modify, we consider two classes: 
property ascribing adjectives (in (1)), which add 
a new restriction to the properties introduced by 
the modified noun; and reference modifying ad-
jectives (in (2)), which behave like a semantic 
operator, taking the reference of the modified 
noun as its argument1.  
 
(1) o livro azul 
     ?the blue book? 
(2) o diamante falso 
    ?the fake diamond? 
 
Adjectives like falso (fake), for instance, deal 
with concepts instead of real or referential ob-
jects, showing how a concept applies to a par-
ticular object. These adjectives constitute a 
closed class with very particular properties, 
which makes them somewhat close to semantic 
operators. In this work we will therefore focus 
on property ascribing adjectives. 
                                                          
1 This distinction between property ascribing adjectives and 
reference modifying adjectives is basically equivalent to 
the one used in the SIMPLE project (Lenci et al, 2000)  
(extensional vs. intensional adjectives, following Chier-
chia and McConnel-Ginet (1990)) to address the seman-
tics of adjectives. This distinction is also included in the 
EAGLES recommendations for a semantic typology of 
adjectives. 
Demonte (1999) classifies property ascribing 
adjectives based on their intrinsic meaning, a 
classification combining syntactic and semantic 
criteria to determine which adjectives belong to 
which class. Two main subclasses are consid-
ered: descriptive adjectives and relational adjec-
tives. Each of these classes displays specific se-
mantic and syntactic properties.  
In languages like Portuguese, descriptive ad-
jectives can occur both in attributive and predi-
cative contexts, while relational adjectives occur 
almost exclusively in attributive contexts2. Both 
prenominal and postnominal positions are possi-
ble for descriptive adjectives in attributive con-
texts. Relational adjectives, on the contrary, can 
only occur in postnominal position. Finally, de-
scriptive adjectives are gradable, i.e. they can co-
occur with degree adverbs, which is not the case 
for relational adjectives. However, these criteria 
are not always sufficient to make a clear-cut dis-
tinction between relational and descriptive adjec-
tives. Demonte (1999) proposes some additional 
criteria in order to make a more accurate distinc-
tion between these adjectives: their occurrence 
in comparative structures, and the formation of 
polarity systems. 
 
(3) a. O sabor desta laranja ? mais doce do que o  
          daquela. 
         ?this orange taste is sweeter than that one's? 
      b. o rapaz alto / o rapaz baixo 
         ?the tall boy / the short boy? 
(4) a. *Este sabor ? mais mineral do que aquele. 
          ?this taste is more mineral than that one? 
      b. o sabor mineral / *o sabor amineral 
         ?the mineral taste / the amineral taste? 
 
But most of all, and besides all the syntactical 
contrasts we have mentioned above, there is a 
clear contrast in the way these two adjective 
classes relate to the noun they modify. Descrip-
tive adjectives ascribe a single property, setting a 
value for an attribute, whereas relational adjec-
tives introduce a set of properties. 
 
(5) o pr?dio alto 
     ?the high building? 
 
                                                          
2 Predicative contexts with relational adjectives are gener-
ally ruled out in Portuguese. Nonetheless, some specific 
contexts, like contrastive contexts, for instance, seem to 
license predicative uses of relational adjectives: 
 
(I) As pr?ximas elei??es s?o aut?rquicas, n?o s?o 
presidenciais. 
    ?next election will be autarchic, not presidential? 
556
(6) a ind?stria alimentar 
     ?the alimentary industry? 
 
Looking at (5) and (6), we see that, while alto 
(high) sets the value of the height attribute of 
pr?dio (building) to high, alimentar (alimentary) 
does not ascribe a single property, but a set of 
properties to ind?stria (industry). Moreover, this 
set of properties corresponds to the main features 
describing another noun ? alimento (food) in the 
example above. In fact, the way properties are 
ascribed to the modified nouns in (5) and in (6) 
are quite different. Ascribing a singular property 
usually corresponds to an incidence relation of 
this property in the nominal referent, while as-
cribing sets of properties usually entails more 
complex and diversified semantic relations.  
However, despite the relevance of the descrip-
tive/relational dichotomy, it cannot account for 
the following contrasts: 
 
(7) a. *Ele viu a Maria alta. 
          ?He saw Mary tall?  
     b. Ele viu a Maria triste. 
        ?He saw Mary sad?. 
 
Both alta and triste are descriptive adjectives, 
but they do not behave in the same way regard-
ing secondary predication. 
We can refine the classification, considering, 
for instance, the opposition between accidental 
properties and permanent or inherent properties 
(this distinction goes back to Milsark (1974; 
1977) and Carlson (1977)). According to this 
distinction, the property denoted by alta (tall) 
belongs to the latter class and the property de-
noted by triste (sad) to the former one. However, 
as pointed out by Marrafa (2004) and previous 
work, the characterization of adjectives on the 
basis of this dichotomy is not straightforward, 
since certain adjectives are ambiguous with re-
gard to those properties, as it is the case of triste 
(sad). In the example above triste (sad) denotes 
an accidental property, but in an expression like 
um livro triste (a sad book) it denotes a perma-
nent property. 
Intuitively, we can say that triste (sad) ex-
presses a state of tristeza (sadness), but we let 
the discussion of the status of this relation out of 
the scope of this paper. 
Nevertheless, this kind of adjectives is of 
great importance to model telic verbs. The se-
mantics of telic verbs involves a change of state 
of their theme argument, i.e. the subevent that 
closes the whole event is an atomic event, (a 
state) that affects the theme and is different from 
its initial state. As argued in Marrafa (2005) and 
previous work, by default, verbs like lavar (to 
wash) are associated to the following Lexical-
Conceptual Structure (LCS? in Pustejovsky 
(1991)): 
 
(8) [T [P act(x,y)and ~ Q(y)],  [eQ(y)]] 
T:transition, P:process, e: event, Q: atomic event 
 
When syntactically realized, the telic subevent 
generally corresponds to an adjectival constitu-
ent, like in the example below: 
 
(9) Ele lavou a camisa bem lavada. 
      'He washed the shirt well washed' 
 
In (9) the absence of the telic expression bem 
lavada (well washed) does not induce ungram-
maticality. However, in the case of verbs like 
tornar (to make), it seems impossible to assign a 
value to Q independently of the telic expression. 
 
(10) a. Ele tornou a Maria triste. 
            ?He made Mary sad? 
        b. *Ele tornou a Maria. 
            'He made Mary' 
 
Along the lines of Marrafa (1993) and further 
work, verbs like tornar (to make) are assumed 
here to be LCS deficitary, the telic expression 
filling the gap of the LCS of the verb.   
As shown below, the troponyms of these verbs 
incorporate the telic state:  
 
(12) a. Ele entristeceu a Maria. 
           'He saddened Mary' 
        b. *Ele entristeceu a Maria triste. 
           'He saddened Mary sad' 
 
The grammaticality contrast above is due to 
the fact that entristecer (to sadden) incorporates 
the telic state. This justifies that this verb can be 
paraphrased by tornar triste (to make sad). 
In this section we have mainly focused on 
property ascribing adjectives. We have consid-
ered two main subclasses, descriptive and rela-
tional adjectives, briefly presenting their syntac-
tic and semantic behavior with regard to grad-
ability, formation of polarity systems and their 
occurrence in predicative and attributive (both 
pronominally and postnominally) contexts and 
comparative structures. We have also addressed 
the issue of adjective relation with the noun they 
modify. Different adjective behavior regarding 
secondary predication is also discussed and ana-
lyzed in terms of the opposition between acci-
557
dental and permanent properties. The properties 
discussed in this section should be encoded in 
computational relational lexica such as wordnets. 
3 Adjectives in WordNet and in Eu-
roWordNet 
Hyponymy is the main structuring relation both 
in WordNet and in EuroWordNet. However, the 
semantic organization of adjectives is entirely 
different from that of other POS: nothing like the 
hierarchies of hyponymic (in the semantic or-
ganization of nouns) and troponymic relations 
(in the semantic organization of verbs) is avail-
able for adjectives. Even if it is possible to find 
some small local hierarchies, hypero-
nymy/hyponymy is far from being the crucial 
semantic relation in the organization of adjec-
tives in relational lexical databases such as 
wordnets. 
However, some authors working within the 
EuroWordNet framework have reconsidered the 
possibility of encoding hyponymy for adjectives. 
Hamp and Feldweg (1998), in the development 
of GermaNet, abandon the cluster organization 
of WordNet in favor of a hierarchical structuring 
of adjectives, arguing for a uniform treatment of 
all POS. Even though taxonomic chains of adjec-
tives yield rather flat in comparison to those of 
nouns and verbs, these authors claim to derive 
more structural information from these small 
taxonomies than from clusters, as they seek to 
eliminate what they consider to be the ?rather 
fuzzy concept of indirect antonyms?. Even 
though the concept of indirect antonymy is not 
completely clear, it is not obvious to us why this 
fact should entail that adjectives must show a 
hierarchical organization instead. 
In ItalWordNet, Alonge et al (2000) also or-
ganize adjectives into classes sharing a su-
perordinate. These classes correspond to adjec-
tives sharing some semantic features, and are 
generally rather flat. These authors argue for the 
possibility of inferring semantic preferences and 
syntactic characteristics of adjectives found in 
the same taxonomy. The SIMPLE project ad-
dresses the semantics of adjectives in a similar 
way, identifying a set of common features rele-
vant for classifying and describing adjective be-
havior. However, as noted by Peters and Peters 
(2000), even though similarities exist ?adjectives 
belonging to the same semantic class may differ 
from each other in numerous ways?, i.e. the 
classes established in this way are not homoge-
neous.   
In WordNet, descriptive and relational adjec-
tives are distinguished, first, by being encoded in 
separate files, and second, by the relations hold-
ing between synsets.  
Descriptive adjectives are organized in clus-
ters of synsets, each cluster being associated by 
semantic similarity to a focal adjective which is 
linked to a contrasting cluster through an an-
tonymy relation. Therefore, antonymy is the ba-
sic semantic relation used in WordNet to encode 
descriptive adjectives. As argued for in Miller 
(1998), this cluster organization of adjectives 
seems to mirror psychological principles. In fact, 
this organization is clearly motivated if we rec-
ognize that these adjectives main function re-
gards the expression of attributes, and that an 
important number of attributes are bipolar. 
Relational adjectives, on the other hand, do 
not have antonyms. Therefore, they cannot be 
organized in opposite clusters. As pointed out by 
Levi (1978), the intrinsic meaning of these ad-
jectives is something along the following lines: 
?of, relating/pertaining to, associated with? some 
noun. The way these adjectives are encoded in 
WordNet mirrors this as it links relational adjec-
tives to the nouns they relate to.  
In GermaNet a distinct treatment of relational 
and descriptive adjectives is abandoned, as the 
distinction between these two classes is consid-
ered to be ?not at all clear?. Nonetheless, the 
WordNet strategy for distinguishing between 
different adjective classes is maintained: listing 
lexical items in different files3. 
As pointed out in the previous section, even if 
the distinction between these two classes is not 
always clear-cut, testing adjectives against the 
set of syntactic and semantic criteria presented in 
section 2 allows us to distinguish descriptive 
from relational adjectives. We consider that this 
distinction can be mirrored in the database via 
the semantic relations expressed in the network, 
adjective listing in different files not being there-
fore necessary. In order to do this we propose 
several cross-POS relations, since in the Eu-
roWordNet model, unlike what happens in 
WordNet where each POS forms a separate sys-
tem, it is possible to relate lexical items belong-
ing to different POS. Such an approach has the 
                                                          
3 GermaNet classifies the adjectives into 15 semantic 
classes, following the classes proposed by Hundsnurscher 
and Splett (1982), with some minor changes: percep-
tional, spatial, temporality-related, motion-related, mate-
rial-related, weather-related, body-related, mood-related, 
spirit-related, behaviour-related, social-related, quantity-
related, relational and general adjectives. One special 
class is added for pertainyms. 
558
advantage of coping with adjective representa-
tion in lexical semantic databases without using 
strategies external to the lexical model, such as a 
priori semantic classes or separate files corre-
sponding to different classes.  
4 Relating adjectives, nouns and verbs 
It is undeniable that important structural infor-
mation can be extracted from the hierarchical 
organization of lexical items, namely of nouns 
and verbs. However, extending wordnets to all 
the main POS involves a revision of certain 
commonly used relations and the specification of 
several cross-POS relations. 
We previously mentioned that adjectives show 
a very particular semantic organization. Thus, 
encoding adjectives in wordnets calls for the 
specification of a number of cross-POS semantic 
relations. Here we use these cross-POS semantic 
relations to mirror adjectives main features in 
wordnet-like databases, which allows us to make 
adjective classes emerge from the relations ex-
pressed in the network. 
According to the strategies discussed in Men-
des (2006), we present here the relations we ar-
gue are appropriate to encode adjectives and 
show how they conform to some complex phe-
nomena. 
4.1 Relating Adjectives and Nouns 
To put it somewhat simplistically, descriptive 
adjectives ascribe a value of an attribute to a 
noun. We link each descriptive adjective to the 
attribute it modifies via the semantic relation 
characterizes with regard to/can be character-
ized by4. Thus, instead of linking adjectives 
amongst themselves by a similarity relation, fol-
lowing what is done in WordNet, all adjectives 
modifying the same attribute are linked to the 
noun that lexicalizes this attribute. This way, and 
in combination with the antonymy relation, we 
obtain the cluster effect argued to be the basis of 
the organization of adjectives (Miller, 1998; 
Fellbaum et al 1993), without having to encode 
it directly in the database. 
As shown by word association tests, antonymy 
is also a basic relation in the organization of de-
scriptive adjectives. Nonetheless, this relation 
does not correspond to conceptual opposition, 
which is one of the semantic relations used for 
                                                          
4 This semantic relation is very close to the is a value 
of/attributes relation used in WordNet. We have changed 
its label in order to make it more straightforward to the 
common user. 
the definition of adjective clusters. We argue 
that conceptual opposition does not have to be 
explicitly encoded in wordnets, since it is possi-
ble to infer it from the combination of synonymy 
and antonymy relations (see Mendes (2006) for 
more details). 
Concerning relational adjectives, even though 
they are also property ascribing adjectives, they 
entail more complex and diversified relations 
between the set of properties they introduce and 
the modified noun, often pointing to the denota-
tion of another noun (cf. section 2). We use the 
is related to relation to encode this. 
Therefore, the characterizes with regard 
to/can be characterized by and the antonymy 
relations, for descriptive adjectives, and the is 
related to relation for relational adjectives, al-
lows us to encode the basic features of these ad-
jectives in computational relational lexica such 
as wordnets, while making it possible to derive 
membership to these classes from the relations 
expressed in the network. 
Another issue regarding adjectives is that they 
have a rather sparse net of relations. We intro-
duce a new relation to encode salient characteris-
tics of nouns: is characteristic of/has as a char-
acteristic to be. These characteristics are often 
expressed by adjectival expressions. Although in 
terms of lexical knowledge we can discuss the 
status of this relation, it regards crucial informa-
tion for many wordnet-based applications, 
namely those using inference systems, allowing 
for richer and clearer synsets. 
Also, it may allow for deducing semantic do-
mains from the database, as it makes it possible 
to identify the typical semantic domains of ap-
plication of adjectives. Research on the classes 
and semantic domains emerging from the rela-
tions expressed in the database is still ongoing. 
Thus, the combination of these relations al-
lows us to encode a less sparse net of adjectives. 
Besides the importance of having a more dense 
net from the point of view of wordnet-based ap-
plications, as mentioned above, this is also cru-
cial with regard to relational lexica such as 
wordnets themselves, as the meaning of each 
unit is determined by the set of relations it holds 
with other units. Thus, a denser network of rela-
tions allows for richer and clearer synsets. Fig. 1 
illustrates this idea, presenting an example of the 
way adjectives are being encoded in Word-
Net.PT. 
559
Figure 1. Fragment showing relations between adjectives and nouns5 
 
4.2 Relating Adjectives and Verbs 
We also introduce new semantic relations to en-
code telic verbs in the database (on this issue see 
also Marrafa, 2005; Amaro et al, 2006).  
As shown in section 2, the facts render evident 
that the representation of LCS deficitary telic 
verbs has to include information regarding the 
telic expression. Obviously, it would not be ade-
quate to overtly include in the synset al the ex-
pressions that can integrate the predicate, among 
other reasons, because they seem to constitute an 
open set. Rather, we claim that we can capture 
the telicity of these verbs by including a new 
relation in the set of internal relations of word-
nets: the telic sub-event relation, as exemplified 
below. 
 
(13) {make} has_telic_sub-event    {state} 
        {state}   is_telic_sub-event_of{make}5 
                                                    (defeasible)6 
 
Relating make to state by means of this rela-
tion, we capture the telic properties of the verb 
and let the specific nature of the final state un-
derspecified. This way, we also account for the 
weakness of the verb selection restrictions. As 
expected, we can also use this relation to encode 
telicity in the case of the troponyms of the class 
of verbs discussed in section 2. 
                                                          
5
 Word senses presented here correspond to Princeton 
WordNet synsets (2.1 version). 
6
 The relation is not obligatory in this direction.  
In these cases, we use the telic sub-event rela-
tion to relate the verb to the expression corre-
sponding to the incorporated telic information: 
 
(14) {sadden} has_telic_sub-event   {sad} 
        {sad}       is_telic_sub-event of {sadden} 
                                                         (defeasable) 
 
The global solution is schematically pre-
sented below: 
 
 
 
 
 
 
 
Figure 2. Relations between adjectives and verbs 
 
As shown, the telic sub-event relation straight-
forwardly allows the encoding of lexical telicity 
in wordnets, in accordance with the empirical 
evidence. 
It should be noticed that the existing sub-event 
relation in the EuroWordNet framework is dif-
ferent from the relation proposed here. It only 
stands for lexical entailment involving temporal 
proper inclusion. Therefore, it does not account 
for the geometry of the event. On the contrary, 
the telic sub-event relation regards the atomic 
sub-event that is the ending point of the global 
event.  
{make} 
 
 
{sadden} 
is hypernym of is hypernym of 
{state} 
 
 
{sad} 
has telic sub-event 
is telic sub-event of 
has telic sub-event 
is telic sub-event of 
 
is antonym of 
(adj){young1} 
 
(adj){old1} is characteristic of characterizes with regard to  (n){age1} 
is hypernym of 
(n){kid5} 
(adj){alimentary1} 
 
 (adj){caprine1} 
(adj){creeping1} 
 
(adj){biped1, two-footed1} 
 
(adj){quadruped1, four-footed1} 
is characteristic of 
 
(n){snake1} 
(n){snail1} 
(n){slug3} 
characterizes with regard to 
(n){locomotion1} 
(n){fare1,feeding1} 
characterizes with regard to 
characterizes with regard to 
is related to 
(adj){herbivorous1} 
 
(adj){carnivorous1} 
 
is near-antonym of 
 
is characteristic of (n){ruminant1} 
is characteristic of 
(n){goat1} 
is hypernym of 
is related to 
560
5 Encoding adjectives in WordNet.PT 
As previously mentioned, the proposal presented 
in this paper is mainly concerned with the speci-
fication of appropriate cross-POS relations to 
encode adjectives in computational relational 
lexica.  
In order to test whether the set of relations 
presented here is appropriate and allows the en-
coding of adjectives in wordnet-like lexica, we 
have introduced a selection of Portuguese adjec-
tives in WordNet.PT.  
In the first phase of the WordNet.PT project 
mostly nouns were encoded in the database. 
Thus, we have mainly focused on the encoding 
of relations between adjectives and nouns7. Ta-
ble 1 presents the number of entries and relations 
specified at the present stage. 
 
total number of adjectives  1462 
synonymy relation 252 
antonymy relation 134 
near-antonymy relation 40 
is related to relation 331 
is characteristic of relation 1293 
characterizes with regard to relation 261 
total number of relations 2311 
 
Table1. Statistics concerning the encoding of 
adjectives in WordNet.PT 
 
Besides the discussion presented above, the 
implemented data, being already a representative 
sample, show that the cross-POS relations pro-
posed here effectively allow for a fine-grained 
encoding of adjectives in relational lexica (spe-
cifically in wordnet-like lexica) through the 
specification of a denser network of relations. 
6 Conclusion 
In this paper we argue that the semantics of ad-
jectives can be appropriately captured in word-
net-like lexica by means of the implementation 
of a small set of new relations, which have a 
strong linguistic motivation and preserve the co-
herence of the model. 
We focus on property ascribing adjectives and 
we distinguish between descriptive and rela-
tional adjectives. Besides the relevance of this 
dichotomy, we also address the opposition be-
tween accidental and permanent properties, as 
adjective association to certain kind of properties 
determines their syntactic and semantic behav-
                                                          
7
 Nevertheless, relations between adjectives and verbs are 
already being implemented at the current stage. 
ior, namely with regard to secondary predication. 
Here, we model these distinctions in Word-
Net.PT via cross-POS relations: characterizes 
with regard to/can be characterized by to model 
descriptive adjectives introducing permanent 
properties; has_telic_subevent/is_telic_subevent 
to model descriptive adjectives associated to ac-
cidental properties; and the is related to to model 
relational adjectives. 
Moreover, we make apparent that increasing 
the expressive power of the system has an impor-
tant impact in precision concerning the specifica-
tions of all POS, mainly induced by the cross-
POS relations. 
This way, we provide a simple and integrated 
solution for a complex and heterogeneous prob-
lem. 
7 Acknowledgements 
We wish to thank Funda??o para a Ci?ncia e 
Tecnologia who has partially funded the research 
presented in this paper (grant 
SFRH/BD/8524/2002). We also have to thank 
Instituto Cam?es for the support it has been giv-
ing to our research in computational relational 
lexica. 
References 
A. Alonge, F. Bertagna, N. Calzolari, A. Roventini 
and A. Zampoli. 2000. Encoding information on 
adjectives in a lexical-semantic net for computa-
tional applications. Proceedings of NAACL 2000. 
Seattle, pp. 42-49. 
R. Amaro, R. P. Chaves, P. Marrafa and S. Mendes. 
2006. Enriching wordnets with new Relations and 
with event and argument structures. Proceedings of 
CICLing 2006 ? Conferences on Computational 
Linguistics and Intelligent Text Processing. Mex-
ico City, Mexico, pp. 28-40.  
G. Carlson. 1977. Reference to Kinds in English, PhD 
dissertation, University of Massachusetts-Amherst. 
G. Chierchia and S. McConnel-Ginet. 1990. Meaning 
and Grammar: an Introduction to Semantics, 
Cambridge, MA: The MIT Press. 
V. Demonte. 1999. El Adjectivo: classes y usos. La 
posici?n del adjectivo en el sintagma nominal. in I. 
Bosque and V. Demonte (orgs.) Gram?tica Des-
criptiva de la Lengua Espa?ola. volume 1. Madrid: 
Espasa. 
EAGLES Lexicon Interest Group. 1998. Preliminary 
Recommendations on Semantic Encoding Interim 
Report. 
C. Fellbaum, D. Gross and K. J. Millar. 1993. Adjec-
tives in WordNet. in Miller et al, Five papers on 
561
WordNet, Technical Report, Cognitive Science 
Laboratory, Princeton University, pp. 26?39. 
C. Fellbaum. 1998 A Semantic Network of English: 
The Mother of all WordNets. in P. Vossen (ed.) 
EuroWordNet: A Multilingual Database with Lexi-
cal Semantic Networks. Dordrecht: Kluwer Aca-
demic Publishers, pp. 137-148. 
B. Hamp and H. Feldweg. 1997. GermaNet ? a Lexi-
cal Semantic Net for German. Proceedings of ACL 
workshop on Automatic Information Extraction 
and Building of Lexical Semantic Resources for 
NLP Applications. Madrid. 
A. Lenci, N. Bel, F. Busa, N. Calzolari, E. Gola, M. 
Monachini, A. Ogonoski, I. Peters. W. Peters, N. 
Ruimy, M. Villegas & A. Zampolli. 2000. SIMPLE 
- A General Framework for the Development of 
Multilingual Lexicons. in T. Fontenelle (ed.) Inter-
national Journal of Lexicography. volume 13. pp. 
249-263. Oxford University Press. 
J. N. Levi. 1978. The Syntax and Semantic of complex 
nominals, New York: Academic Press. 
P. Marrafa. 1993. Predica??o Secund?ria e 
Predicados Complexos:  Modeliza??o e An?lise, 
PhD. dissertation, Lisbon, University of Lisbon. 
P. Marrafa. 2001. WordNet do Portugu?s: uma base 
de dados de conhecimento lingu?stico, Lisboa: 
Instituto Cam?es. 
P. Marrafa. 2002. Portuguese WordNet: general archi-
tecture and internal semantic relations. D.E.L.T.A., 
18. 
P. Marrafa. 2004. Modelling Constituency and Predi-
cation in Portuguese. Revista PaLavra. volume 12 
(special issue: Lingu?stica Computacional), pp. 
106-118. 
P. Marrafa. 2005. The Representation of Complex 
Telic Predicates in WordNets: the Case of Lexical-
Conceptual Structure Deficitary Verbs. Research 
on Computing Science. volume 12, pp. 109?116. 
P. Marrafa, R. Amaro, R. P. Chaves, S. Lourosa, C. 
Martins and S. Mendes. 2006. WordNet.PT new di-
rections. Proceedings of GWC?06: 3rd Interna-
tional Wordnet Conference. Jeju Island, Korea. 
S. Mendes. 2006. Adjectives in WordNet.PT. Pro-
ceedings of the GWA 2006 ? Global WordNet As-
sociation Conference. Jeju Island, Korea. 
G. A. Miller. 1990. WordNet: an on-line Lexical Da-
tabase. Special Issue of International Journal of 
Lexicography. volume 3, n? 4.  
K. J. Miller. 1998. Modifiers in WordNet. in C. Fell-
baum (ed.) WordNet: an electronic lexical data-
base. Cambridge, MA: The MIT Press, pp. 47-68. 
G. Milsark. 1974. Existential Sentences in English. 
PhD dissertation, MIT. 
G. Milsark. 1977. Toward an Explanation of Certain 
Pecularities of the Existencial Construction in Eng-
lish. Linguistic Analysis, 3, pp. 1-29. 
I. Peters and W. Peters. 2000. The Treatment of Ad-
jectives in SIMPLE: Theoretical Observations. 
Proceedings of LREC 2000.  
J. Pustejovsky. 1991. The Syntax of Event Structure. 
Cognition, 41, pp. 47?81. 
P. Vossen. 1998. (ed.) EuroWordNet: A Multilingual 
Database with Lexical Semantic Networks, 
Dordrecht: Kluwer Academic Publishers. 
562
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 508?519, Dublin, Ireland, August 23-29 2014.
Using unmarked contexts in nominal lexical semantic classification 
Lauren Romeo*, Sara Mendes*,?, N?ria Bel* 
*Universitat Pompeu Fabra, Roc Boronat, 138, Barcelona, Spain 
?Centro de Lingu?stica da Universidade de Lisboa, Av. Prof. Gama Pinto, 2, Lisboa, Portugal 
{lauren.romeo,sara.mendes,nuria.bel}@upf.edu 
Abstract 
The work presented here addresses the use of unmarked contexts in pattern-based nominal lexical semantic 
classification. We define unmarked contexts to be the counterposition of the class-indicatory, or marked, 
contexts. Its aim is to evaluate how unmarked contexts can be used to improve the accuracy and reliability 
of lexical semantic classifiers. Results demonstrate that the combined use of both types of distributional in-
formation (marked and unmarked) is crucial to improve classification. This result was replicated using two 
different corpora, demonstrating the robustness of the method proposed. 
1 Introduction 
Lexical resources annotated with lexical semantic classes have been successfully incorporated into a 
wide range of NLP applications, such as grammar induction (Agirre et al., 2011) and the building and 
extending of semantic ontologies (Abb?s et al., 2011). However, lexical semantic tagging in large 
lexica is mostly done by hand, implying high costs with regard to maintenance and domain tuning. As 
the use of an inadequate lexicon is one of the causes of poor performance of NLP applications, current 
research to improve the automatic production of rich language resources, and of class-annotated 
lexica, in particular, is critical.   
One way to approach this task is through supervised cue-based lexical semantic classification. 
Based on the distributional hypothesis (Harris, 1954), according to which words occurring in the same 
contexts can be said to belong to the same class, cue-based lexical semantic classification uses particu-
lar linguistic contexts where nouns occur as cues that represent distinctive distributional traits of a 
lexical class. Yet, training a classifier with information about word occurrences in a corpus within a 
selected number of contexts can present a challenge, mainly because specific words might be observed 
in a number of class-indicative contexts but not always are.  
This type of marked, or class-indicative, context (e.g. co-occurrence with specific prepositions, 
predicate selectional restrictions, and grammatical information, such as indirect objects) are sparse in 
any corpus as, being so specific, they do not occur often with each target noun. Using only exclusive 
class-indicative contexts as features in nominal lexical semantic classification has been shown to not 
always provide sufficient information to make a decision regarding class membership of a noun (Bel 
et al., 2012), especially when the data does not contain relevant co-occurrences or when those co-
occurrences are too disperse to be correlated.  
Recent work on the use of distributional models for nominal classification tasks (Romeo et al., 
2014) discusses potential bottlenecks of models using data extracted with lexico-syntactic patterns as 
features, identifying data sparsity as one of the major issues affecting the performance of these sys-
tems. In fact, the selection of class-indicative information, in an attempt to provide relevant informa-
tion to classifiers and thus reduce noise, naturally limits the amount of data available to the system, 
often resulting in sparse vectors.  
Resulting from the necessity of selecting the information provided to classifiers, in an attempt to 
improve the accuracy of classification decisions, the sparse data problem in nominal lexical semantic 
classification is one of the crucial issues to be addressed to improve the performance of these systems. 
We propose to approach this issue by utilizing a larger fraction of the distributional information avail-
able in a corpus, by incorporating information typically considered non-indicatory of semantic class 
membership, which we will designate as unmarked contexts (see Section 3 for a definition).  
                                                 
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings foo-
ter are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 
508
Our hypothesis is that the distributional behavior of nouns of a particular class in this type of gen-
erally occurring contexts can show certain characteristics in common that may be explored in the con-
text of lexical semantic classification. Our goal in the work presented here is to evaluate to which ex-
tent this information, in combination with the widely explored class-indicative lexico-syntactic con-
texts, can be used to improve results in classification tasks, by providing more information to classifi-
ers. To do this, we experiment with English nouns of the following lexical semantic classes: INFOR-
MATION (INF), ORGANIZATION (ORG), LOCATION (LOC), EVENT (EVT) and HUMAN (HUM).  
The work presented in this paper is structured as follows: Section 2 describes theoretical claims 
used in approaches to nominal lexical semantic classification, as well as related work; Section 3 elabo-
rates upon the concept of unmarked contexts; Section 4 describes the methodology followed; Section 5 
presents the results obtained; Section 6 discusses their implications; and Section 7 concludes with final 
remarks and future work. 
2 Motivation and Related Work 
In semantic classification approaches grounded in usage-based theories of grammar (Goldberg, 2006), 
a lexical class is seen as a generalization of the systematic co-distribution of a number of words and 
contexts. Construction-based grammar hypotheses allow us to predict there are sets of word occur-
rences that, together, constitute a class mark, indicating a particular semantic class, in line with the 
structuralist notion of markedness (Jakobson, 1971). 
The identification of relevant cues for machine learning classification is problematic as low fre-
quency evidence is typically disregarded by automatic systems. To overcome this problem, Bel (2010) 
applied smoothing methods, demonstrating increases in accuracy, though low frequency words re-
mained problematic for classifiers when evidence was scarce, and thus not considered as a positive cue 
for the class, although it was indicative.  
In Bel et al. (2012) we built on this hypothesis, assuming only frequently occurring contexts would 
be efficient for classification tasks, and considering only frequent predicates, prepositions, affixes, 
etc., as well as negative cases (i.e. marked cues for other classes), as indicators for a class membership 
decision. Thus, we ignored all information that, although frequent, co-occurred with nouns from all 
classes and was deemed not distinctive of a particular class, as well as all information that, though dis-
tinctive, was not frequent enough to be used by the classifier.  
Table 1 provides examples of contexts considered in that work, which did not rely on unique, ex-
clusive hints, but a number of them that, when correlated, could identify members of a given class. 
However, our results were inconclusive, a fact which we attributed to the high impact of sparse data. 
Class Examples of lexico-syntactic patterns 
ORG x-NN (found|establish|organize)-VBD 
LOC (inside|outside)-IN (the|a|an)-(DT|Z) x-NN 
INF (submit|publish|report)-V* (the|a|an)-(DT|Z) x-NN 
EVT during-IN (the|a|an)-(DT|Z) x-NN 
HUM x-(-er|?or| ?man)-NN 
Table 1: Examples of lexico-syntactic patterns indicative of 5 different lexico-semantic classes, which 
we refer to as marked contexts. 
According to Bybee (2010), general contexts, not exclusive to a particular class (i.e. unmarked con-
texts, as defined in Section 3), are more frequent than contexts marked toward a particular class, as 
they occur with nouns of all classes. In view of this, it becomes apparent that a large part of available 
distributional data is not taken into consideration when these very general co-occurrences observed 
with nouns of all classes (e.g. co-occurrence with an article) are treated as stop words or contexts in 
lexical semantic classification tasks. 
 The basic claim leading most authors to neglect this kind of context is that, due to its assumed un-
differentiated distribution, this information presents a challenge for classifiers to accurately use it in 
class membership decisions, which is bound to negatively affect results (see Cooke and Gillam (2008), 
Turney and Pantel (2010), Bullinaria and Levy (2012), among many others). In contrast with this 
mainstream position, Rumshisky et al. (2007) argued there is an asymmetry in the way certain word 
509
senses are used in language, preferably or rarely occurring in certain very general contexts (e.g. sub-
ject position, occurrence with an adjectival modifier, etc.).  
This type of asymmetry is essentially referring to a difference in how general, semantically neutral 
distributional contexts are more or less frequent in data, depending on the sense in which a word is 
used. We hypothesize that these tendencies can also be observed when considering different lexical 
semantic classes.  
In this paper, we propose a way to include this type of asymmetry in the information provided to 
classifiers to verify its impact on their overall performance. Considering such distributional evidence 
will increase the amount of information made available to classifiers. Our main claim is that devising a 
strategy to informatively include this type of distributional information in classification tasks can al-
low us to take advantage of a bigger portion of the data available in corpora and improve the accuracy 
of classifiers in this way. 
3 Unmarked contexts 
In contrast with mainstream approaches to cue-based lexical-semantic classification, we argue for the 
inclusion of a type of distributional information typically not considered to be indicatory of class 
membership, and thus not informative to automatic classification systems. These are very general con-
texts of occurrence typically disregarded as semantically-empty and thought to be too general to con-
tribute any relevant information. At the same time, they correspond to a large amount of corpus data 
that is a priori not considered due to the assumption that it does not provide any information.  
Examples of such distributional information regard whether nouns occur preceeded by an article, in 
singular or plural form, whether they are a head or a complement in NPs containing the preposition of, 
if they occur as the subject of the verb to be, etc. We will henceforth designate these contexts as un-
marked contexts, the counterposition of the class-indicatory contexts, i.e. marked contexts, used as 
class marks in cue-based lexical-semantic classification systems. 
Following the conclusions of Rumshisky et al. (2007) regarding asymmetries in the distribution of 
word senses in general contexts, our hypothesis is that the distribution of members of a class with re-
spect to their occurrence in particular unmarked contexts is consistent and thus can be captured and 
used to inform classifiers and improve results, when considered along with other indicatory, or 
marked, contexts.  
We also hypothesize that unmarked contexts will alleviate problems caused by data sparsity in 
classification tasks by providing additional information to classifiers. To assess to which extent this 
information can be used in classification tasks, we had to identify such contexts and verify whether 
our hypothesis was confirmed, i.e. if they showed significant variations in terms of distribution that 
might be explored to augment the amount of information made available to classifiers1. Additionally, 
and given the specific properties of this type of distributional information, we also had to define a 
strategy to informatively provide it to classifiers (see Section 3.2 for details). 
3.1 Identifying unmarked contexts 
Considering the characteristics of the contexts discussed above, we identified 32 unmarked con-
texts under a frequency criterion (see Table 2 for a description of the different contexts identified), 
hypothesizing that more frequent contexts combine with more nouns in the corpus and thus should not 
be marked for any restricted set. However, although they are not considered to be class marks, we ex-
pect these contexts to be asymmetrically distributed between lexical semantic classes, in an analogous 
way to what was observed by Rumshisky et al. (2007) with regard to the distributional behavior of 
different word senses in language use.  
We studied the distribution of these contexts in a web-crawled corpus (see Section 4), comparing 
the distribution of each context over all the nouns in the corpus and over nouns defined as part of a 
specific lexical semantic class, according to a gold standard (see Section 4.2). To do this, we calcu-
lated the mean of occurrence of nouns pertaining to a particular class in a specific unmarked context, 
                                                 
1 The approach detailed in this paper contrasts with a ?bag of words? approach to classification as, even in the case of what we call un-
marked contexts, we rely on cue information to populate our vectors. Thus, the information provided to classifiers takes into considera-
tion linguistic information, such as syntactic order or dependencies. Moreover, our use of linguistically-motivated features, from the 
inherently distinctive to the more generic, reduces the amount of data needed to obtain a desired level of performance.  
510
as well as the mean of occurrence of all the nouns in the corpus in that same context; we then deter-
mined if there was a statistically significant difference2 between the behavior of nouns from specific 
classes and the behavior of nouns in general with regard to the contexts identified as unmarked.  
Feature Type Description Examples 
article 
target noun preceded by a(n) (in)definite 
article  
(a|an)-(DT|Z) x-NN or  
(the)-(DT|Z) x-NN 
number target noun in plural/singular form x-NNS or x-NN 
copula  target noun as subject/object of verb to be  x-NN be-VBZ  or be-VBZ  x-NN 
modifiers 
adjective or nominal modifier preceding 
target noun  
x-JJ x-NN or x-NN x-NN 
preposition of 
target noun preceding/following the prepo-
sition of  
x-NN of-IN or of-IN x-NN 
subject of V 
target noun as subject of each of the 20 
most frequent verbs in the corpus  
x-NN 
(have|get|make|see|do|take|go| 
use|find|help|read|know|provide
|give|keep|come|say|create|visit)
-VB(Z|D) 
Table 2: Description of unmarked contexts identified and used in our experiments. 
The results showed there were statistically significant differences (p<0.05) in the behavior of nouns 
in particular classes with regard to certain unmarked contexts. For instance, the occurrence of INF, 
ORG, LOC, and HUM nouns with a definite article (the-DT) showed to be significantly different from its 
average occurrence with all the nouns in the corpus. The occurrence with an indefinite article (a|an-
DT), on the other hand, showed to be significantly different for LOC nouns, while the co-occurrence 
with an adjective (x-JJ) was significantly different for INF nouns.  
3.2 A strategy to encode unmarked context information in feature vectors 
The preliminary study mentioned in Section 3.1 provided evidence confirming that there are, in fact, 
differences in the behavior of particular lexical semantic classes with regard to their occurrence in 
unmarked contexts. Thus, the next step consisted in determining the best way to make this information 
available to classifiers. 
Aiming to check the validity of our hypothesis in general, the results obtained in the aforemen-
tioned study were not used directly to narrow down the information to include in the vectors used by 
the classifiers to avoid the risk of over-fitting. Moreover, what was at stake, considering our theoreti-
cal hypothesis, was to devise a strategy to account for specific differences between the behavior of 
each noun considered for classification and the average behavior of all nouns in the corpus with regard 
to each context considered. Thus, information regarding all 32 unmarked contexts was provided to the 
classifiers for all lexical classes considered.  
To mirror the specificity of the distribution of each noun with regard to each context considered, 
we subtracted the mean of occurrence of nouns in each context from the actual occurrences of the tar-
get noun represented by the vector in that same context to obtain each feature f, as defined in Equation 
1, where ci represents a given context, t a target noun, n any noun belonging to N, the set of all nouns 
in the corpus, and freq frequency of occurrence (e.g. )|( ictfreq = frequency of occurrence of the target 
noun t in context ci). 
  
 
Using the difference between the number of occurrences of a given noun and the average occur-
rence of all nouns in a specific context, we encode the deviation of the behavior of that noun with re-
                                                 
2 In this work, statistical significance was calculated using Student?s t-test (cf. Krenn and Samuelsson, 1997). 
Equation 1: 
Nn
ii
)n(freq
)c|n(freq
N)t(freq
)c|t(freqf 1
511
gard to the general behavior of all nouns in the corpus, under the hypothesis that nouns of the same 
class display similar tendencies in terms of deviant behavior in the contexts considered, providing re-
levant information to the classifier. We apply our method to two different corpora making apparent its 
robustness. 
4 Experimental design and setup 
In order to evaluate the impact of using distributional information on unmarked contexts for lexical-
semantic classification tasks, first, we had to extract distributional information regarding the unmarked 
contexts identified (see Section 3.1), as well as distributional information regarding class-indicative 
marked contexts. In our experiments, we used the marked contexts identified and described in Bel et 
al. (2012) (see Table 1 for examples).  
Once the distributional information was extracted, we incorporated it in feature vectors, using the 
different aforementioned strategies for encoding distributional information regarding marked and un-
marked contexts, respectively, as detailed further below in this section. Once all of the information 
was compiled, the vectors were provided to classifiers. 
As previously mentioned, our experiments covered English nouns of the classes: INF, ORG, HUM, 
EVT and LOC (see Section 4.2). For the purpose of the work presented here, we experimented with two 
corpora to determine the transferability and robustness of our method, independently of specific cor-
pus data.  
We first used a general web-crawled corpus (Pecina et al., 2011) consisting of 30 million PoS-
tagged English tokens (henceforth Corpus A) to identify unmarked contexts (see Section 3.1) as well 
as to train our classifiers.  
We also employed an excerpt of the web-crawled UkWaC corpus (Baroni et al., 2009), consisting 
of 60 million PoS-tagged English tokens (henceforth Corpus B) to test our approach on unknown data, 
in this way ensuring that our approach and classifiers are not over-fitted to any specific corpus, instead 
confirming that the method we propose can be generalized, and the results obtained are replicable 
given any dataset. 
Regular expressions over both corpora were used to identify occurrences of nouns in marked and 
unmarked contexts. For marked contexts, the relative frequency of each pattern seen with a particular 
noun was stored in an n-dimensional vector.3 The occurrences of a noun in unmarked contexts were 
encoded in the same vectors following the strategy outlined in Section 3.2 (see Equation 1). 
4.1 Classification 
For classification, we used the Logistic Model Trees (LMT) (Landwehr et al., 2005) Decision Tree 
(DT) classifier in the WEKA (Witten and Frank, 2005) implementation in a 10-fold cross-validation 
setting. We conducted binary classifications, one for each semantic class considered. We measure the 
success of our approach in regards to the joint performance of individual classifiers in accurately dis-
tinguishing members of each individual class from any other noun. This method was used in the clas-
sification experiments over both corpora described above. 
4.2 Gold Standard Description 
In regards to the gold standard lists used for training and evaluation, we automatically extracted from 
WordNet (Miller et al., 1990) all of the nouns encoded in this repository of lexical information that 
contained a sense corresponding to a class considered in our experiments (e.g. people in the case of 
HUM).  
The gold standards were not contrasted with the actual occurrences of the nouns in the corpora. 
They were, however, balanced with respect to class members and elements not belonging to the class, 
resulting in the dataset described in Table 3. Each noun appears x times in any corpus considered. The 
elements not belonging to a class were randomly selected from the set of nouns that do not contain a 
sense in WordNet that corresponded to the target class being classified.  
For a fair comparison, the baseline classification model was obtained using the context patterns de-
scribed in Bel et al. (2012) with the LMT classifier, using the previously described gold standard lists 
over Corpus A. This baseline allows us to assess the impact of unmarked contexts in nominal lexical 
                                                 
3 In this work, n is equal to the amount of marked contexts plus unmarked contexts considered for each class. 
512
semantic classification, since the classifiers proposed here that are provided with information on the 
distributional behavior of nouns in unmarked contexts also use Bel et al. (2012)?s context patterns to 
extract class-indicative, or marked,  distributional information regarding the nouns to classify. 
Class  ORG LOC EVT INF HUM 
Class members 138 157 260 262 246 
Elements not belonging to the class 135 156 260 259 246 
Table 3: Number of nouns included in gold standards per class. 
5 Results 
Tables 4 and 5 show results obtained in our experiments in terms of Precision (P), Recall (R) and F-
Measure (F). The overall accuracy of all classifiers for each experiment is also provided. The baseline 
classifiers achieve an average accuracy of 70.84%. By including unmarked contexts in the vectors 
provided to the classifiers, the average accuracy of the classifiers rises to 75.16%, representing an er-
ror reduction of 4.32 points. We tested the statistical significance ( p<0.1) of this increase in the accu-
racy of classification and, for all classes except for HUM, the increase in accuracy between the baseline 
results and those obtained when including unmarked contexts is significant. These results are dis-
cussed in detail in Section 6. 
Knowing a potential downside of using unmarked contexts in classification tasks is an increase in 
noise (see Section 6.1 for a detailed discussion regarding this concept), we conducted an error analysis 
of the results obtained, which made apparent that most of the noise was due to imprecise information 
extracted with our regular expressions, leading us to revise them. As these revisions resulted from the 
observation that a portion of the errors in the baseline results was due to imprecise regular expressions, 
they did not consist in the definition of new marked contexts, rather in a revision of how to extract 
marked contexts already considered in this work from corpora data. Thus, these revisions resulted in 
more accurate and better defined regular expressions.  
As indicated by the results, these revisions in combination with the unmarked contexts further 
raised the average accuracy of the classifiers to 76.35% (see Table 4), representing an error reduction 
of 5.51 points with regard to the baseline. Having obtained these promising results over the data in the 
corpus used to develop our approach (Corpus A), it was crucial to verify the replicability of our 
method using a different and completely independent corpus, as described in Section 4. Moreover, 
replicating the original experiments over a different corpus was also crucial to assure that the revisions 
made to the regular expressions did not result in any over-fitting between the extraction of distribu-
tional information and the corpus being used. The results obtained for the experiments conducted over 
Corpus B are presented in Table 5. 
Class 
baseline 
baseline + unmarked 
contexts 
marked contexts 
marked + unmarked  
contexts 
P R F P R F P R F P R F 
ORG 0.64 0.62 0.60 0.70 0.68 0.68 0.76 0.74 0.74 0.75 0.74 0.74 
LOC 0.72 0.70 0.70 0.73 0.73 0.73 0.70 0.70 0.70 0.77 0.79 0.77 
EVT 0.70 0.68 0.67 0.74 0.73 0.72 0.73 0.72 0.64 0.73 0.72 0.69 
INF 0.67 0.66 0.65 0.74 0.73 0.73 0.71 0.70 0.69 0.71 0.71 0.71 
HUM 0.86 0.84 0.86 0.87 0.86 0.86 0.87 0.87 0.87 0.85 0.84 0.84 
Acc 70.84% 75.16% 75.05% 76.35% 
Table 4: Precision (P), Recall (R), and F-Measure (F) of classifiers over Corpus A.  
The classifiers that include unmarked contexts yielded an average accuracy of 76.03% over Corpus 
B, representing an error reduction of 3.34 points with regard to the classifier including only marked 
contexts (using the revised version of Bel et al. (2012)?s cues), which is a statistically significant im-
provement (p<0.05). Moreover, these results represent an improvement of accuracy by 5.19 points 
with regard to the baseline. This demonstrates, on the one hand, that the definition of relevant contexts 
based on Corpus A data did not result in an over-fitted approach; and, on the other hand, that the 
513
method presented here is robust, as we used our classifiers over a completely different corpus (cf. Sec-
tion 3) and still yielded comparable results. Due to space limitations, below we detail only the results 
obtained on Corpus B data, as these are independent of all the preliminary studies conducted and thus 
demonstrate the potential applicability of our approach to any corpus. 
Class 
marked contexts  marked + unmarked contexts 
P R F P R F 
ORG  0.72 0.69 0.69 0.76 0.76 0.76 
LOC  0.74 0.71 0.71 0.75 0.75 0.75 
EVT  0.68 0.67 0.67 0.73 0.73 0.73 
INF  0.69 0.69 0.68 0.70 0.70 0.70 
HUM  0.86 0.86 0.86 0.84 0.84 0.84 
Acc 72.69% 76.03% 
Table 5: Precision (P), Recall (R), and F-Measure (F) of classifiers over Corpus B. 
Class 
marked contexts marked + unmarked context 
members non-members members non-members 
P R P R P R P R 
ORG  0.79 0.52 0.65 0.86 0.78 0.72 0.75 0.80 
LOC  0.82 0.55 0.66 0.73 0.78 0.70 0.73 0.80 
EVT  0.73 0.57 0.63 0.78 0.74 0.72 0.72 0.73 
INF  0.72 0.62 0.66 0.75 0.72 0.65 0.68 0.74 
HUM  0.87 0.84 0.84 0.87 0.86 0.82 0.82 0.86 
Table 6: Precision (P) and Recall (R) of classification of members and non-members of different lexi-
cal classes over Corpus B 
Table 6 presents the precision and the recall of each individual classifier over Corpus B both with 
regard to the members of a given class, and those nouns that are not members of that class. This table 
allows us to identify more precisely how the unmarked contexts contribute to the error reduction in 
classification.  
According to the results, unmarked contexts allow us to gain an average of 10.2 points in recall for 
class members, demonstrating that they provide useful information to classifiers, which allows them to 
cover cases which they were not able to before, most likely due to phenomena such as data sparsity. 
However, the impact on precision varies between classes, as the inclusion of very frequent information 
in the vectors representing target nouns may provide additional noise to the classifier (see Section 6.1). 
The precision of classification of class members decreases slightly with the inclusion of unmarked 
contexts, although the differences are not statistically significant (p<0.1). However, the precision of 
the classification of nouns not belonging to the classes considered significantly increases (p<0.1) with 
the inclusion of unmarked contexts in all cases except for HUM. This shows that although unmarked 
contexts do not contribute to a better definition of the characteristics of individual classes (see Table 
6), they allow for a cleaner discrimination of members and non-members of a class, contributing to a 
better partition of the classification space. 
Class 
marked contexts marked + unmarked contexts 
FN (%) FP (%) FN (%) FP (%) 
ORG 23.32 6.71 13.43 9.98 
LOC 22.30 5.75 14.74 9.71 
EVT 21.91 10.42 13.82 12.97 
INF 18.94 12.00 17.26 12.63 
HUM 7.79 6.01 8.90 6.45 
Table 7: Percentage of False Negatives (FN) and False Positives (FP) in classifiers over Corpus B with 
and without unmarked contexts. 
514
Table 7 presents the percentage of False Positives (FP), i.e. nouns incorrectly marked as members 
of the class, and False Negatives (FN), i.e. nouns incorrectly marked as not belonging to a class, in the 
results of each classifier both with and without the inclusion of unmarked contexts. Again, for each of 
the classes, except HUM, the inclusion of unmarked contexts decreases the percentage of FN, mirroring 
a reduction in silence. Yet, there was an increase of FP across all classes, signifying an increase of the 
noise provided to the classifier. These results are discussed in detail in Section 6. 
6 Discussion 
In Section 5, we presented the results obtained in our experiments using distributional information re-
garding both marked and unmarked contexts for the classification of English nouns. Overall, our re-
sults show that unmarked contexts either improve accuracy or do not affect classification results. Spe-
cifically, the improvements in accuracy are particularly significant for those classes for which there 
were difficulties to find enough occurrences in marked contexts in previous experiments, i.e. those 
classes with a higher level of FN when classified without using unmarked contexts. This way, the re-
sults confirm our general hypothesis that the distribution of words in unmarked contexts, when consid-
ered along with contexts marked towards a lexical semantic class, provides information to improve 
classifiers, particularly when not enough class-specific information is available. In this section we ana-
lyze the results obtained, making apparent the main advantages of our proposal.  
6.1 A trade-off between silence and noise 
An important result of our experiments is the overall reduction in the negative effect of silence in our 
classifiers, which decreased by an average of 5.21% (see the difference in terms of FN in Table 7), re-
sulting in an increase in accuracy (see Table 5): as more information is supplied to the classifier, the 
additional information permits more accurate membership decisions. To illustrate this, we consider 
examples from the INF, ORG and EVT classes, for which there was not enough information for classifi-
cation when unmarked contexts were not considered. The inclusion of unmarked contexts provided 
information resulting in correct classifications.  
The INF noun theorem illustrates this case: theorem occurs 118 times in the corpus, though only 8 
times in marked contexts, which was not enough to accurately classify it as a member of the INF class. 
As this noun occurs in class-marked contexts, but not enough times for the classifier to make an accu-
rate prediction regarding its class membership, we can consider that the lack of enough information 
provided to the classifier is responsible for its misclassification. However, after the inclusion of infor-
mation regarding the behavior of this noun in unmarked contexts, the classifier was able to accurately 
decide for its inclusion as a member of the INF class. This was also observed in the case of the ORG 
noun secretariat and the EVT noun impulse, which occur 190 and 154 times, respectively, in the cor-
pus, yet only 8 and 12 times in marked contexts, which was not enough for an accurate classification. 
Again, the inclusion of information regarding the distribution of these nouns in unmarked contexts 
provided the classifier with sufficient information to allow for correct classification. 
One of the main concerns regarding the use of unmarked distributional information was the intro-
duction of extra noise as a side effect and the way this affects classification results. For the purpose of 
the work presented in this paper, we define noise as contradictory distributional information, particu-
larly the occurrence of nouns that are not members of a particular class in prototypical contexts of that 
particular class, which provides misleading information to classifiers. The impact of this misleading 
information is made apparent by the amount of FP observed in classification results. In contrast, si-
lence has to do with the well known problem of data sparsity, which can be caused by the particular 
distribution of lexical, and thus strict, though informative, contexts used in cue-based classification 
tasks, which are often rare in any corpus of any size due to their specificity.  
In our experiment, we did identify some cases of nouns correctly ruled out as members of a class 
when using only marked cues, which were incorrectly classified as class members after the inclusion 
of unmarked contexts. The slight increase of FP in our results (see Table 7) shows our method does 
introduce some extra noise into the classifier, although, in the overall results, this is compensated by 
the larger amount of nouns that were correctly classified after the inclusion of unmarked distributional 
information (see Tables 4 and 5).  
Analyzing the additional FP observed, we identify two different cases: (i) nouns correctly classified 
using only marked contexts as not belonging to a class based on a borderline probability, which were 
515
incorrectly classified as members of that class when unmarked contexts were also considered, again 
based on a borderline probability; and (ii) nouns correctly classified as not belonging to a class as they 
hardly or never occurred in class-marked contexts, but whose behavior in unmarked contexts was simi-
lar to that of members of the class being classified, thus providing contradictory information to the 
classifier and resulting in incorrect classification.  
The first case is illustrated by a noun like biography, which was predicted not to be a member of 
the LOC class with a borderline probability score (0.47). The inclusion of unmarked contexts provided 
information to the classifier, which slightly changed this probability (0.56), and resulted in an incorrect 
classification. The noun megalopolis illustrates the other case. Occurring only 3 times in class-marked 
contexts of the INF class, this LOC noun had been correctly classified as not belonging to the INF class. 
Yet, its behavior in unmarked contexts showed more similarities with members of the INF class than 
with non-members, resulting in its incorrect classification. Illustrating two paradigmatic cases of noise 
in the results of the classifiers, these examples make apparent how unmarked contexts are sometimes 
responsible for incorrect class membership decisions, and how further improving their use in classifi-
cation tasks, particularly in the case of ?borderline? classification decisions, remains a promising line 
of research to explore in the future (see Section 7). 
6.2 More robust classification decisions 
Besides the reduction of the impact of silence in the results of the classifiers, with the consequent im-
provements in accuracy, as discussed in the previous section, we also noticed that the introduction of 
unmarked contexts provided additional information regarding the distribution of nouns that were clas-
sified by chance (i.e. correctly classified nouns, with a borderline probability score), resulting in more 
robust classification decisions. We saw this with the EVT noun consolidation and the LOC noun coal-
field. Each of these nouns was correctly classified using only marked contexts, yet with borderline 
probability scores: 0.52 and 0.53, respectively. Upon providing information on unmarked contexts to 
the classifier, these nouns continued to be correctly classified but with much higher probability scores, 
and thus more reliable: 0.75 and 0.76, respectively.  
These examples are considerably different from those discussed in Section 6.1, as these are far from 
being cases of silence. In fact, the EVT noun consolidation occurs 312 times in the corpus and 317 
times in marked contexts while the LOC noun coalfield occurs 52 times in the corpus and 53 times in 
marked contexts4. In both cases, almost all of the occurrences in marked contexts were found to be in 
only one cue, which was therefore not strongly valued by the classifier, as few correlations between 
the evidence available could be made, hence the low probability scores observed. The inclusion of un-
marked distributional information provides ?bridging information?, allowing for more reliable classifi-
cations, which is crucial to consider especially when the ultimate goal of improving and tuning classi-
fication systems is to employ classification results for the automatic production of language resources 
(see Section 1). 
6.3 Classification results unevenly affected by unmarked contexts 
As made apparent by the results, the contribution of unmarked contexts to the classification of differ-
ent semantic classes is not always the same. For example, we observed that classes whose members 
demonstrated a more heterogeneous linguistic behavior, such as the ORG, LOC or EVT classes, improve 
more with the inclusion of unmarked distributional information than classes with a more homogeneous 
distributional behavior. To make our statement clearer, we claim that some nominal classes are com-
posed of nouns that tend to occur in a wider range of contexts, thus displaying a more heterogeneous 
and disperse distributional behavior. This heterogeneity is made apparent by an analysis of the overall 
distribution of the marked cues between the members of each lexical semantic class. In contrast with 
heterogeneous noun classes, other classes are composed of members that display a more homogeneous 
collective behavior that is more easily captured by distributional approaches5.  
                                                 
4 Note that a single occurrence in corpus data can activate more than one cue considered in our experiments (for instance, in 
the case of a target noun that has a marked suffix and simultaneously occurs in a marked syntactic construction), hence the 
higher amount of occurrences in cues than overall occurrences in the corpus discussed in the examples introduced in this 
paragraph. 
5 Our analysis of the data showed that the dispersion of distributional behavior is independent of frequency. 
516
Analyzing the distribution of cues between class members in Corpus B, we identified, in each class, 
a set of cues that occurred with the majority of nouns of the class, and which we will consider to repre-
sent the core linguistic behavior of each specific class. We also observed the amount of cues included 
in this set differed considerably from class to class (see Figure 1). Thus, the larger the amount of 
marked contexts shared by the majority of the members of a class, the more homogeneous we can 
claim their behavior to be. 
In the specific case of the classes considered in this paper, 30.7% of the cues for the HUM class are 
shared by the majority of HUM nouns, while 26.6%, 13.3%, 9.5% and 9.1% of the cues for the INF, 
ORG, EVT and LOC classes, respectively, are shared by the majority of the nouns of these classes, as rep-
resented in Figure 1. An effect of a class collectively having a more heterogeneous linguistic behavior is 
that the evidence regarding each of its marks will typically be more disperse and, as a result, often not 
strong enough to be considered by classifiers, which explains the improvement introduced by un-
marked contexts. In contrast, classes like HUM are composed of nouns that generally occur in a com-
mon set of prototypical contexts of that class. Thus, on the one hand, identifying contexts that mirror 
the prototypical behavior of that class is more straightforward and, on the other, class members almost 
always show enough occurrences in such contexts to be accurately classified. 
 
Figure 1: Percentage of cues shared by the majority of class members, per class 
Additionally, there are also strong marks based on suffixes and degree of grammaticalization for the HUM 
class (as demonstrated in Bel et al. (2012)), which can be more readily captured by these more available 
marked contexts. For instance, on the one hand, suffixes, such as: ?-er? and ?-or? are indicative of many 
HUM type nouns (e.g. ?doctor?, ?painter?, ?officer?, etc.) while the preposition ?during?, when preceding a 
nominal phrase, is very indicative of occurrences of EVT nouns. These examples are both instances of features 
that can be easily identified for inclusion in a feature vector, readily providing a large amount of class-
indicative information. On the other hand, there are other types of features that although indicative, result in a 
much sparser vector because of their reliance of occurrence within corpus data. For instance the occurrence as 
the subject of an agentive verb, which is considered an indicative feature for the ORG class, does not necessar-
ily occur readily with all members of the class, thus making marked contexts that provide a homogeneous rep-
resentation of the class more difficult to capture. 
In this way, the inclusion of extra contexts (e.g. unmarked contexts) are rendered ineffective when 
class membership decisions are already accurately made to a great extent (in our case 86.19% of the 
times) based on the information provided by marked contexts. This is consistent with the stability of 
the results reported for the HUM class in the different experiments performed, which did not demon-
strate any significant changes with the inclusion of unmarked contexts. 
7 Conclusions and Final Remarks 
Our main goal in this paper was to evaluate how unmarked contexts can be used to improve the accu-
racy of nominal lexical semantic classification tasks. Departing from the hypothesis that these contexts 
can provide additional information to classifiers when there is not enough distinctive co-occurrence 
information available, the results reported demonstrate the use of unmarked contexts, which are typi-
cally discarded as non-discriminatory, can significantly improve the results of lexical semantic classi-
fication when considered along with marked contexts. Our results also show that using both types of 
517
distributional information (marked and unmarked) is crucial to reduce the sparse data problem, thus 
improving classification (see increase in classification accuracy in Tables 4 and 5). Moreover, in our 
experiments, we apply this method to two independent corpora obtaining comparable results and thus 
demonstrating the robustness and transferability of our approach to any dataset.  
The higher accuracy and error reduction achieved with the inclusion of unmarked contexts consti-
tute a significant improvement with respect to the state of the art (Bel, 2010; Bel et al., 2012; Romeo 
et al., 2014), contributing particularly to the increase of accuracy and reliability of classifiers for 
classes that exhibit more disperse linguistic behavior. Moreover, the approach depicted here leaves 
room for further improvements and future work, particularly with regard to designing strategies to 
minimize the introduction of borderline false positives in classification.  
One promising line of research to explore is the optimization of the inclusion of unmarked contexts 
in classification decisions. As detailed in the discussion, for the experiments depicted in this paper, we 
did not expect particular marked or unmarked features to be more useful than others, as we relied on 
the correlation of all the distributional information considered for each specific class to be indicative 
of class membership.  
Another aspect to be further explored consists of determining the most effective amount of un-
marked contexts to be provided to automatic systems. Building on the demonstration of the positive 
contribution of unmarked contexts in classification tasks, as indicated by the results obtained in the 
work depicted in this paper (see Section 5), we will start by determining the specific contribution to 
classification of each unmarked feature used. In this way, we would check whether there is a context, 
within our set, that is not contributing to the classification, in order to establish a threshold to syste-
matically identify the information that is not relevant or whether we need to widen/relax our frequency 
criterion to include more unmarked contexts with the goal of elaborating a set of information to be as 
robust as possible, thus resulting in more accurate and more reliable classification decisions. 
Finally, we believe the results obtained make a clear contribution towards the automatic production 
of high-quality language resources, which will benefit any NLP system that requires information on 
lexical semantic classes as an input. 
Acknowledgements 
This work was funded with the support of the SUR of the DEC of the Generalitat de Catalunya and the 
European Social Fund, by SKATER TIN2012-38584-C06-05, and by Funda??o para a Ci?ncia e a 
Tecnologia (FCT) post-doctoral fellowship SFRH/BPD/79900/2011.  
References 
Abb?s, S. B., Zargayouna, H. and Nazarenko, A. 2011. Evaluating Semantic Classes Used for Ontology Building 
and Learning from Texts. In Proceedings in the International Conference on Knowledge Engineering and On-
tology Development. Paris, France. 
Agirre, E., Bengoetxea, K., Gojenola, K. and Nivre, J. 2011. Improving Dependency Parsing with Semantic 
Classes. In Proceedings of the 49th Annual Meeting of the Association of Computational Linguistics, (ACL-
HLT 2011). Portland, Oregon. 
Baroni, M., Bernardini, S., Ferraresi, A. and Zanchetta, E. 2009. The WaCky wide web: A collection of very 
large linguistically processed web-crawled corpora. Language Resources and Evaluation, 43(3): 209-226. 
Bel, N. 2010. Handling of Missing Values in Lexical Acquisition, In Proceedings of the 7th International Confe-
rence on Language Resources and Evaluation (LREC 2010), Valletta, Malta. 
Bel, N., Romeo, L. and Padr?, M. 2012. Automatic Lexical Semantic Classification of Nouns. In Proceedings of 
the 8th Language Resources and Evaluation Conference (LREC 2012), Istanbul, Turkey. 
Bullinaria, J. A. and Levy, J. 2012. Extracting semantic representations from word co-occurrence statistics: Sto-
plists,stemming and svd. Behavior Research Methods,44:890-907. 
Bybee, J. 2010. Language, Usage and Cognition. Cambridge University Press, Cambridge. 
Cooke, N. and Gillam, L. 2008. Distributional lexical semantics for stop lists. In Proceedings of the 2008 BCS-
IRSG conference on Corpus Profiling (IRSG'08), Anne De Roeck, Dawei Song, and Udo Kruschwitz (Eds.). 
British Computer Society, Swinton, UK. 
518
Goldberg, A. E. 2006. Constructions at Work. The Nature of Generalization in Language. Oxford University 
Press: Oxford. 
Harris, Z. 1954. Distributional Structure. Word, 10(23): 146-162. 
Jakobson, R. 1971. Selected Writings II: Word & Language. Mouton, The Hague. 
Krenn, B. and Samuelsson, C. 1997. The Linguist?s Guide to Statistics ? Don?t Panic. 
http://nlp.stanford.edu/fsnlp/dontpanic.pdf 
Landwehr, N., Hall, M. and Frank, E. 2005. Logistic Model Trees. Machine Learning, 95(1-2): 161-205. 
Miller, G. A., Beckwith, R., Fellbaum, C., Gross, D. and Miller, K. J. 1990. Introduction to WordNet: An On-
line Lexical Database. International Journal of Lexicography, 3(4): 235-244.  
Pecina, P., Toral, A., Way, A., Papavassiliou, V., Prokopidis, P. and Giagkou, M. 2011. Towards Using Web-
Crawled Data for Domain Adaptation in Statistical Machine Translation. In Proceedings of the 15th Confer-
ence of the European Association for Machine Translation (EAMT 2011). Leuven, Belgium.  
Pustejovsky, J. 1995. Generative Lexicon. The MIT Press, Cambridge. 
Quinlan, R. J. 1993. C4.5: Programs for Machine Learning. Series in Machine Learning. Morgan Kaufman: San 
Mateo. 
Romeo, L., Lebani G. E., Bel, N. and Lenci, A. 2014 Choosing which to use? A study of distributional models 
for nominal lexical semantic classification. In Proceedings of the Ninth International Conference on Lan-
guage Resources and Evaluation (LREC 2014). Reykjavik, Iceland.: 4366-4373. 
Rumshisky, A., Grinberg, V. and Pustejovsky, J. 2007. Detecting Selectional Behavior of Complex Types in 
Text. In Proceedings of the 4th International Workshop on Generative Lexicon. Paris, France. 
Turney, P. D. and Pantel, P. 2010. From frequency to meaning: Vector space models of semantics. Journal of 
Artificial Intelligence Research, 37:141-188. 
Witten, I. H. and Frank, E. 2005. Data Mining: Practical Machine Learning Tools and Techniques. 2nd Edition, 
Morgan Kaufmann: San Francisco. 
519
Proceedings of EMNLP 2011, Conference on Empirical Methods in Natural Language Processing, pages 70?74,
Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational Linguistics
WordNet.PTglobal ? Extending WordNet.PT to Portuguese varieties 
 
 
Palmira Marrafa1, Raquel Amaro2 and Sara Mendes2 
Group for the Computation of Lexical and Grammatical Knowledge, 
Center of Linguistics of the University of Lisbon 
Avenida Professor Gama Pinto, 2 
1649-003 Lisboa, Portugal 
1palmira.marrafa@netcabo.pt 2{ramaro,sara.mendes}@clul.ul.pt 
 
 
 
 
 
 
Abstract 
This paper reports the results of the 
WordNet.PTglobal project, an extension of 
WordNet.PT to all Portuguese varieties. 
Profiting from a theoretical model of high 
level explanatory adequacy and from a 
convenient and flexible development tool, 
WordNet.PTglobal achieves a rich and multi-
purpose lexical resource, suitable for 
contrastive studies and for a vast range of 
language-based applications covering all 
Portuguese varieties.  
1 Introduction 
WordNet.PT is being built since July 1999, at the 
Center of Linguistics of the University of Lisbon 
as a project developed by the Group for the 
Computation of Lexical and Grammatical 
Knowledge (CLG). 
WordNet.PT is being developed within the 
general approach of EuroWordNet (Vossen 1998, 
1999). Therefore, like each wordnet in EWN, 
WordNet.PT has a general conceptual architecture 
structured along the lines of the Princeton 
WordNet (Miller et al 1990; Fellbaum 1998). 
For early strategic reasons concerning 
applications, this project is being carried out on the 
basis of manual work, assuring the accuracy and 
reliability of its results. 
Aiming at using the Portuguese WordNet in 
language learning applications, among others, the 
starting point for the specification of a fragment of 
the Portuguese lexicon, in the first phase of the 
project (1999-2003), consisted in the selection of a 
set of semantic domains covering concepts with 
high productivity in daily life communication. The 
encoding of language-internal relations followed a 
mixed top-down/bottom-up strategy for the 
extension of small local nets (Marrafa 2002). Such 
work firstly focused on nouns, but has since then 
been extended to all the main POS, a work which 
has resulted both in refining information 
specifications and increasing WordNet.PT 
coverage (Amaro et al 2006; Marrafa et al 2006; 
Amaro 2009; Mendes 2009).  
Relational lexica, and wordnets in particular, 
play a leading role in machine lexical knowledge 
representation. Hence, providing Portuguese with 
such a rich linguistic resource, and particularly 
Portuguese varieties not often considered in lexical 
resources, is crucial, not only to researchers 
working in contrastive studies or with the so-called 
non-standard varieties, but also to the general 
public, as the database is made available for 
consultation in the WWW through an intuitive and 
perspicuous web interface. Such work is also 
particularly relevant as the resulting database can 
be extensively used in a vast range of language-
based applications, able to cover, this way, all 
Portuguese varieties. 
This paper depicts the work developed and the 
results achieved under the scope of the 
WordNet.PTglobal project, funded by Instituto 
Cam?es, which, as mentioned above, aims at 
extending WordNet.PT to Portuguese varieties.  
70
2 The Data 
Portuguese is spoken in all five continents by over 
250 million speakers, according to recent studies, 
and is the official language of 8 countries: Angola, 
Brazil, Cape Verde, East Timor, Guinea Bissau, 
Mozambique, Portugal, and Sao Tome e Principe. 
Being spoken in geographically distant regions and 
by very different communities, both in terms of 
size and culture, Portuguese is naturally expected 
to show variation. Despite this, regional varieties 
are far from being equally provided with linguistic 
resources representing their specificities, as most 
research work is focused either on the Brazilian or 
the European varieties1. 
In the work depicted here we aim at contributing 
to reverse this situation, considering that this kind 
of resource is particularly adequate to achieve this 
goal, since it allows for representing lexical 
variation in a very straightforward way: concepts 
are the basic unit in wordnets, defined by a set of 
lexical conceptual relations with other concepts, 
and represented by the set of lexical expressions 
(tendentially all) that denote them. We have to 
antecipate the possibility of different varieties 
showing distinct lexicalization patterns, 
particularly some lexical gaps or lexicalizations of 
more specific concepts. This is straightforwardly 
dealt with in the WordNet model: once a system of 
relevant tags has been implemented in the database 
in order to identify lexical expressions with regard 
to their corresponding varieties, lexical gaps are 
simply encoded by not associating the tag of the 
variety at stake to any of the variants in the synset; 
specific lexicalizations, on the other hand, are 
added to the network as a new node and associated 
to the variety tag at stake. 
Our approach consisted in extracting 10 000 
concepts from WordNet.PT, and associating them 
with the lexical expressions that denote them in 
each Portuguese variety considered in this project. 
In order to accomplish this, we consulted native 
speakers from each of these varieties, resident in 
their original communities, and asked them to 
                                                           
1
 Official standardized versions of East Timorese and African 
varieties of Portuguese essentially correspond to that of 
European Portuguese. Moreover, these varieties are not 
provided with dedicated lexical resources, such as dictionaries 
or large-scale corpora. Being so, speakers in these regions 
generally use European Portuguese lexical resources, which 
only exceptionally cover lexical variants specific to these 
varieties. 
pinpoint the expressions used for denoting the 
aforementioned 10 000 concepts. Informants were 
selected by Instituto Cam?es among undergrad 
students in Portuguese studies and supervised by 
Portuguese lectors in each local university. Besides 
the European Portuguese variety, which is already 
encoded in WordNet.PT, specifications for six 
other Portuguese varieties were integrated in the 
database 2 : Angolan Portuguese, Brazilian 
Portuguese, Cape Verdean Portuguese, East 
Timorese Portuguese, Mozambican Portuguese and 
Sao Tome e Principe Portuguese. For each 
concept, several lexicalizations were identified and 
both the marked and unmarked expressions 
regarding usage information3 were considered and 
identified. 
2.1 Data selection  
As mentioned above, our approach for enriching 
WordNet.PT with lexicalizations from all 
Portuguese varieties consisted in extracting 10 000 
concepts from WordNet.PT and associating them 
to the lexical expressions which denote them in 
each variety. 
 
domain nouns verbs adjectives proper 
nouns 
total 
art 422 14 83 0 519 
clothes 467 62 74 0 603 
communication 314 151 106 82 653 
education 536 37 30 82 685 
food 1131 130 115 0 1376 
geography 281 0 166 200 647 
health 1159 92 175 0 1426 
housing 595 28 46 0 669 
human activities 641 0 0 0 641 
human relations 620 189 100 0 909 
living things 1597 113 119 1 1830 
sports 480 34 23 2 539 
transportation 659 562 67 30 659 
all domains 7893 802 1022 284 10001 
domain overlap 10,36% 12,54% 4,22% 22,62% 10,35% 
 
Table 1: concepts extended to Portuguese varieties 
                                                           
2
 All Portuguese varieties spoken in countries where 
Portuguese is the official language were considered. However, 
for the time being, data from Guinean Portuguese are not yet 
encoded in the WordNet.PTglobal database due to difficulties in 
maintaining a regular contact with the native speakers 
consulted. Despite this, we still hope to be able to include this 
variety in the database at some point in the future. 
3
 Informants were provided with a limited inventory of usage 
markers: slang; vulgar; informal; humerous; popular; unusual; 
regional; technical; old-fashioned. 
71
The semantic domain approach initially used in 
developing WordNet.PT, provided us with a 
natural starting point for the selection of data to be 
considered in this project. The table above presents 
the distribution, per POS and semantic domain4, of 
the WordNet.PT concepts extended to non-
European Portuguese varieties. 
2.2 Data implementation 
Once the data described above were presented to 
the native speakers consulted and their input 
organized, all the information obtained was 
incorporated in the database.  
This way, for a concept like bus (public 
transportation which has regular pre-established 
stops at short intervals, typically operating within 
cities), for instance, the following lexicalizations 
were obtained: autocarro, machibombo, 
machimbombo, ?nibus, and micro?nibus. 
Autocarro was found to be the more common 
expression used for denoting the concept at stake 
in Angola, Cape Verde, East Timor, Portugal, Sao 
Tome e Principe and Mozambique. However, this 
variant is marked as ?unusual? in Mozambique 
variety. Machibombo and machimbombo are only 
used in Mozambique, whereas ?nibus and 
micro?nibus are only used in Brazil. With this kind 
of data at hand, each lexicalization was tagged 
with regard to the varieties in which it is used and, 
for each variety, associated, when relevant, to a 
usage label, as illustrated below. 
 
 
 
In the codification of the aforementioned 
information we used Synsetter ? a new, very 
flexible wordnet development tool previously 
developed for the full implementation of 
                                                           
4
 Note that some of the concepts considered are associated to 
more than one semantic domain. This results in partial 
overlaps between semantic domains, whose extent is presented 
in the last row of Table 1. 
innovative research results in WordNet.PT. In 
order to do so, this computational tool has been 
developed to straightforwardly allow for updates 
and improvements. In the specific case of the task 
addressed in this paper, extending the coverage of 
the WordNet.PT database to lexicalizations of 
different Portuguese varieties involved the design 
of additional features regarding the identification 
of Portuguese varieties and variety-dependent 
usage label encoding.  
2.3 The results 
Encoding the data obtained in WordNet.PTglobal 
extends a relevant fragment of WordNet.PT to 
Portuguese varieties other than European 
Portuguese. This way, researchers are provided 
with a crucial database for developing contrastive 
studies on the lexicon of different Portuguese 
varieties or research on a specific Portuguese 
variety, just to mention a possible application. The 
table below presents the distribution of variants per 
variety in the fragment of the lexicon considered, 
making apparent, for instance, that in the collection 
of data considered in this project some varieties 
have more synonym forms for denoting the same 
concept than others (see average of variants per 
concept). 
 
Portuguese 
varieties 
number of 
concepts 
number of 
variants 
variants per 
concept (average) 
Angola 10 000 11713 1,17 
Brazil 10 000 12060 1,20 
Cape Verde 10 000 12563 1,26 
East Timor 10 000 12131 1,21 
Mozambique 10 000 11740 1,17 
Portugal 10 000 13006 1,30 
Sao Tome e 
Principe 6981 9552 1,37 
all varieties 10 000 14751 1,47 
 
Naturally, this is only an overall view of the 
results obtained. The new extended WordNet.PT 
version is also a crucial resource allowing for 
contrastive studies on lexicalization patterns 
depending on semantic domains or on frequency of 
use, for instance, for all or for specific Portuguese 
varieties.  
In order to make these data publicly available, a 
new WordNet.PT version, the WordNet.PTglobal has 
been released on the WWW 5 . Releasing the 
WordNet.PT fragment extended to Portuguese 
                                                           
5
 http://www.clul.ul.pt/wnglobal. 
72
varieties online involved developing an updated 
version of the web interface for wordnet online 
navigation. In Section 3 we present the main 
features of this web interface and how users can 
navigate and straightforwardly access the data on 
Portuguese varieties.  
3 Navigating the lexicon of Portuguese 
varieties online 
The new updated version of the web interface for 
wordnet navigation was developed with specific 
features allowing for the visualization of 
information on Portuguese varieties and for 
narrowing down searches depending on the needs 
of the user. Among the most salient aspects of the 
new web interface we underline the following: 
allowing the user to restrict the search to a given 
(or to a set of) Portuguese variety(ies) (see caption 
below); displaying information about each lexical 
expression regarding the varieties which use it and 
whether this use is marked or not.  
 
 
 
Going back to the example mentioned in section 
2.2, in Portuguese, the concept {bus} can be 
denoted by several expressions, depending on the 
variety considered. This information is 
straightforwardly displayed and made available to 
the user by a simple system of tags, as illustrated 
below. 
 
 
 
Also, all marked uses are indicated by 
underlining the variety label corresponding to the 
variety in which the use of the relevant expression 
is marked (see tags associated to autocarro in the 
caption above, particularly the MZ tag signaled by 
an arrow). By clicking on this label the relevant 
usage label is displayed, as illustrated below.  
 
4 Final Remarks  
WordNet.PTglobal is, thus, a relational lexicon 
allowing for modelling the lexicon of Portuguese 
varieties in a consistent and motivated way.  
Covering 10 000 concepts, lexicalized by a total 
of 14 751 expressions representing all the main 
POS (nouns, verbs, adjectives, and proper nouns), 
WordNet.PTglobal also provides a lexical-conceptual 
network of relations establishing the relevant links 
between each concept and the other concepts in the 
net, in a total of more than 30 000 relations, 
including relations with their corresponding 
lexicalizations in English.  
This way, Portuguese now has a rich and useful 
lexical resource covering all of its varieties 
(Angolan, Brazilian, Cape Verdean, East 
Timorese, European, Mozambican, Sao Tome e 
Principe and Guinean Portuguese (forthcoming ? 
see footnote 1)), freely available for online 
consultation both to researchers and to the general 
public.  
Moreover, the database presented in this paper 
can be extensively used in a vast range of 
language-based applications which are now able to 
cover all Portuguese varieties. As a final remark on 
future work, the data resulting from 
WordNet.PTglobal can be used as a basis for 
comparative studies regarding, for instance, variant 
distribution per variety. Note, however, that 
pursuing such studies requires comparable corpora 
for each variety, both with POS tagging and 
semantic annotation. Nonetheless, several 
advances are being taken in this direction6. 
                                                           
6
 see http://www.clul.ul.pt/en/research-teams/87-linguistic-
resources-for-the-study-of-the-african-varieties-of-portuguese-r. 
73
References  
Amaro, R. (2009) Computation of Verbal Predicates in 
Portuguese: relational network, lexical-conceptual 
structure and context ? the case of verbs of 
movement, PhD dissertation, University of Lisbon. 
Amaro, R., R. P. Chaves, P. Marrafa & S. Mendes 
(2006) ?Enriching WordNets with new relations and 
with event and argument structures?, Proceedings of  
CICLing 2006,  Mexico City, pp. 28-40. 
Fellbaum, C. (1998) (ed.) WordNet: an Electronic 
Lexical Database, MA: The MIT Press. 
Marrafa, P. (2002) ?The Portuguese WordNet: General 
Architecture and Semantic Internal Relations?, 
DELTA, Brasil. 
Marrafa, P., R. Amaro, R. P. Chaves, S. Lourosa & S. 
Mendes (2006) ?WordNet.PT new directions?, 
Proceedings of  GWC?06, Jeju Island, pp. 319-321. 
Mendes, S. (2009) Syntax and Semantics of Adjectives 
in Portuguese: analysis and modelling, PhD 
dissertation, University of Lisbon. 
Miller, G., R. Beckwith, C. Fellbaum, D. Gross & K. J. 
Miller (1990) ?Introduction to WordNet: An On-line 
Lexical Database?, International Journal of 
Lexicography, volume 3, number 4. 
Vossen, P. (1998) (ed.) EuroWordNet: A Multilingual 
Database with Lexical Semantic Networks, 
Dordrecht: Kluwer Academic Publishers.  
Vossen, P. (1999) EuroWordNet General Document, 
University of Amsterdam. 
74
