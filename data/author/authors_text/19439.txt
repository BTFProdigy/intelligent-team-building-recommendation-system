Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 49?54,
Baltimore, Maryland USA, June 23-24, 2014.
c?2014 Association for Computational Linguistics
WELT: Using Graphics Generation in Linguistic Fieldwork
Morgan Ulinski
?
mulinski@cs.columbia.edu
Anusha Balakrishnan
?
ab3596@columbia.edu
Daniel Bauer
?
bauer@cs.columbia.edu
Bob Coyne
?
coyne@cs.columbia.edu
Julia Hirschberg
?
julia@cs.columbia.edu
Owen Rambow
?
rambow@ccls.columbia.edu
?
Department of Computer Science
?
CCLS
Columbia University
New York, NY, USA
Abstract
We describe the WordsEye Linguistics
tool (WELT), a novel tool for the docu-
mentation and preservation of endangered
languages. WELT is based on Words-
Eye (Coyne and Sproat, 2001), a text-to-
scene tool that automatically generates 3D
scenes from written input. WELT has two
modes of operation. In the first mode, En-
glish input automatically generates a pic-
ture which can be used to elicit a de-
scription in the target language. In the
second mode, the linguist formally docu-
ments the grammar of an endangered lan-
guage, thereby creating a system that takes
input in the endangered language and gen-
erates a picture according to the grammar;
the picture can then be used to verify the
grammar with native speakers. We will
demonstrate WELT?s use on scenarios in-
volving Arrernte and Nahuatl.
1 Introduction
Although languages have appeared and disap-
peared throughout history, today languages are
facing extinction at an unprecedented pace. Over
40% of the estimated 7,000 languages in the world
are at risk of disappearing. When languages die
out, we lose access to an invaluable resource for
studying the culture, history, and experience of
peoples around the world (Alliance for Linguistic
Diversity, 2013). Efforts to document languages
and develop tools in support of collecting data on
them become even more important with the in-
creasing rate of extinction. Bird (2009) empha-
sizes a particular need to make use of computa-
tional linguistics during fieldwork.
To address this issue, we are developing the
WordsEye Linguistics Tool, or WELT. In the first
mode of operation, we provide a field linguist with
tools for running custom elicitation sessions based
on a collection of 3D scenes. In the second, input
in an endangered language generates a picture rep-
resenting the input?s meaning according to a for-
mal grammar.
WELT provides important advantages for elic-
itation over the pre-fabricated sets of static pic-
tures commonly used by field linguists today. The
field worker is not limited to a fixed set of pictures
but can, instead, create and modify scenes in real
time, based on the informants? answers. This al-
lows them to create additional follow-up scenes
and questions on the fly. In addition, since the
pictures are 3D scenes, the viewpoint can easily
be changed, allowing exploration of linguistic de-
scriptions based on different frames of reference.
This will be particularly useful in eliciting spatial
descriptions. Finally, since scenes and objects can
easily be added in the field, the linguist can cus-
tomize the images used for elicitation to be maxi-
mally relevant to the current informants.
WELT also provides a means to document the
semantics of a language in a formal way. Lin-
guists can customize their studies to be as deep or
shallow as they wish; however, we believe that a
major advantage of documenting a language with
WELT is that it enables such studies to be much
more precise. The fully functioning text-to-scene
system created as a result of this documentation
will let linguists easily test the theories they de-
velop with native speakers, making changes to
grammars and semantics in real time. The result-
ing text-to-scene system can be an important tool
for language preservation, spreading interest in the
language among younger generations of the com-
munity and recruiting new speakers.
We will demonstrate the features of WELT
for use in fieldwork, including designing elic-
itation sessions, building scenes, recording au-
dio, and adding descriptions and glosses to a
scene. We will use examples from sessions we
49
have conducted with a native speaker of Nahu-
atl, an endangered language spoken in Mexico.
We will demonstrate how to document seman-
tics with WELT, using examples from Arrernte,
an Australian aboriginal language spoken in Alice
Springs. We will also demonstrate a basic Arrernte
text-to-scene system created in WELT.
In the following sections, we will mention re-
lated work (Section 2), discuss the WordsEye sys-
tem that WELT is based on (Section 3), describe
WELT in more detail, highlighting the functional-
ity that will appear in our demonstration (Section
4), and briefly mention our future plans for WELT
(Section 5).
2 Related Work
One of the most widely-used computer toolkits for
field linguistics is SIL Fieldworks. FieldWorks is
a collection of software tools; the most relevant
for our research is FLEx, Fieldworks Language
Explorer. FLEx includes tools for eliciting and
recording lexical information, dictionary develop-
ment, interlinearization of texts, analysis of dis-
course features, and morphological analysis. An
important part of FLEx is its ?linguist-friendly?
morphological parser (Black and Simons, 2006),
which uses an underlying model of morphology
familiar to linguists, is fully integrated into lexicon
development and interlinear text analysis, and pro-
duces a human-readable grammar sketch as well
as a machine-interpretable parser.
Several computational tools aim to simplify the
formal documentation of syntax by eliminating
the need to master particular grammar formalisms.
First is the PAWS starter kit (Black and Black,
2012), a system that prompts linguists with a series
of guided questions about the target language and
uses their answers to produce a PC-PATR gram-
mar (McConnel, 1995). The LinGO Grammar
Matrix (Bender et al., 2002) is a similar tool de-
veloped for HPSG that uses a type hierarchy to
represent cross-linguistic generalizations.
The most commonly used resource for for-
mally documenting semantics across languages
is FrameNet (Filmore et al., 2003). FrameNets
have been developed for many languages, includ-
ing Spanish, Japanese, and Portuguese. Most
start with English FrameNet and adapt it for the
new language; a large portion of the frames end
up being substantially the same across languages
(Baker, 2008). ParSem (Butt et al., 2002) is a
collaboration to develop parallel semantic repre-
sentations across languages, by developing seman-
tic structures based on LFG. Neither of these re-
sources, however, are targeted at helping non-
computational linguists formally document a lan-
guage, as compared to the morphological parser in
FLEx or the syntactic documentation in PAWS.
3 WordsEye Text-to-Scene System
WordsEye (Coyne and Sproat, 2001) is a system
for automatically converting natural language text
into 3D scenes representing the meaning of that
text. WordsEye supports language-based control
of spatial relations, textures and colors, collec-
tions, facial expressions, and poses; it handles
simple anaphora and coreference resolution, al-
lowing for a variety of ways of referring to ob-
jects. The system assembles scenes from a library
of 2,500 3D objects and 10,000 images tied to an
English lexicon of about 15,000 nouns.
The system includes a user interface where the
user can type simple sentences that are processed
to produce a 3D scene. The user can then modify
the text to refine the scene. In addition, individual
objects and their parts can be selected and high-
lighted with a bounding box to focus attention.
Several thousand real-world people have used
WordsEye online (http://www.wordseye.com). It
has also been used as a tool in education, to en-
hance literacy (Coyne et al., 2011b). In this paper,
we describe how we are using WordsEye to create
a comprehensive tool for field linguistics.
Vignette Semantics and VigNet To interpret in-
put text, WordsEye uses a lexical resource called
VigNet (Coyne et al., 2011a). VigNet is inspired
by and based on FrameNet (Baker et al., 1998),
a resource for lexical semantics. In FrameNet,
lexical items are grouped together in frames ac-
cording to their shared semantic structure. Every
frame contains a number of frame elements (se-
mantic roles) which are participants in this struc-
ture. The English FrameNet defines the mapping
between syntax and semantics for a lexical item by
providing lists of valence patterns that map syntac-
tic functions to frame elements.
VigNet extends FrameNet in two ways in or-
der to capture ?graphical semantics?,? the knowl-
edge needed to generate graphical scenes from
language. First, graphical semantics are added
to the frames by adding primitive graphical (typ-
ically, spatial) relations between the frame ele-
50
ment fillers. Second, VigNet distinguishes be-
tween meanings of words that are distinguished
graphically. For example, the specific objects
and spatial relations in the graphical semantics for
cook depend on the object being cooked and on
the culture in which it is being cooked (cooking
turkey in Baltimore vs. cooking an egg in Alice
Springs), even though at an abstract level cook an
egg in Alice Springs and cook a turkey in Bal-
timore are perfectly compositional semantically.
Frames augmented with graphical semantics are
called vignettes.
4 WordsEye Linguistics Tool (WELT)
In this section, we describe the two modes of
WELT, focusing on the aspects of our system that
will appear in our demonstration.
4.1 Tools for Linguistic Fieldwork
WELT includes tools that allow linguists to elicit
language with WordsEye. Each elicitation session
is organized around a set of WordsEye scenes. We
will demonstrate how a linguist would use WELT
in fieldwork, including (1) creating an elicitation
session, either starting from scratch, or by import-
ing scenes from a previous session; (2) building
scenes in WordsEye, saving them to a WELT ses-
sion, and modifying scenes previously added to
the session, either overwriting the original scene or
saving the changes as a new scene; (3) adding tex-
tual descriptions, glosses, and notes to a scene; and
(4) recording audio, which is automatically synced
to open scenes, and playingit back tto review any
given scene. A screen shot of the scene annotation
window is included in Figure 1.
To test the fieldwork capabilities of WELT,
we created a set of scenes based on the Max
Planck topological relations picture series (Bower-
man and Pederson, 1992). We used these scenes to
elicit descriptions from a native Nahuatl speaker;
some examples of scenes and descriptions are in-
cluded in Figure 2.
4.2 Formal Documentation of a Language
WELT also provides the means to formally doc-
ument the semantics of a language and create a
text-to-scene system for that language. The formal
documentation allows precise description of the
lexical semantics of a language. We will demon-
strate both the user interface for documenting se-
mantics, as well as a text-to-scene system for Ar-
Figure 1: WELT interface for annotating a scene
rernte created with WELT.
When a sentence is processed by WordsEye, it
goes through three main stages: (1) morphological
analysis and syntactic parsing, (2) semantic anal-
ysis, and (3) graphical realization. We will walk
through these modules in the context of WELT,
discussing (a) the formal documentation required
for that component, (b) the processing of an ex-
ample sentence through that component, and (c)
the parts of that component that will feature in our
demonstration. We will use the Arrernte sentence
shown in (1) as a running example.
(1) artwe le goal arrerneme
man ERG goal put.nonpast
The man kicks a goal.
Morphology and Syntax WELT first parses a
sentence into its morphology and syntax. Since
the focus of WELT is documentation of semantics,
the exact mechanisms for parsing the morphology
and syntax may vary. To document Arrernte, we
are using XFST (Karttunen et al., 1997) to model
the morphology and XLE (Crouch et al., 2006) to
model the syntax in the LFG formalism (Kaplan
and Bresnan, 1982). These are mature systems
that we believe are sufficient for the formal doc-
umentation of morphology and syntax. In future,
we will provide interfaces to the third-party tools
so that common information, like the lexicon, can
51
(a) in amat? t?akentija se kutSara
the paper cover one spoon
(b) in kwawit? t?apanawi t?akoja se mansana
the stick pass.thru in.middle one apple
Figure 2: Nahuatl examples elicited with WELT
be shared.
Running each word of the sentence through
the morphological analyzer in XFST transforms
the verb arrerneme into ?arrerne+NONPAST.? The
other tokens in the sentence remain unchanged.
Parsing the sentence with XLE gives the c-
structure shown in Figure 3(a) and the f-structure
shown in Figure 3(b). The f-structure will be
passed on to the semantics module.
(a)
(b)
Figure 3: C-structure (a) and f-structure (b) for
artwe le goal arrerneme.
We have added one additional feature to the
morphology and syntax module of WELT?s text-
to-scene system: an interface for selecting an f-
structure from multiple options produced by XLE,
in case the grammar is ambiguous. This way, a
linguist can use the WELT text-to-scene system
to verify their semantic documentation even if the
syntactic documentation is fairly rough. We will
demonstrate this feature when demonstrating the
Arrernte text-to-scene system.
Semantics The WELT semantics is represented
using VigNet, which has been developed for
WordsEye based on English. We will assume that
large parts of VigNet are language-independent
(for instance, the set of low-level graphical rela-
tions used to express the graphical semantics is
based on physics and human anatomy and does not
depend on language). Therefore, it should not be
necessary to create a completely new VigNet for
every language that will be used in WELT. In fu-
ture, we will develop tools for modifying VigNet
to handle linguistic and cultural differences as they
occur.
In order to use VigNet with other languages,
we need to map between the formal syntax of the
language being studied and the (English) lexical
semantics required currently by VigNet. One in-
stance showing why this is necessary occurs in our
example Arrrente sentence. When discussing foot-
ball in English, one would say that someone kicks
a goal or makes a goal. In Arrente, one would say
goal arrerneme, which translates literally to ?put
a goal.? Although the semantics of both sentences
are the same, the entry for ?put? in the English
VigNet does not include this meaning, but the Ar-
rernte text-to-scene system needs to account for it.
To address such instances, we have created an
interface for a linguist to specify a set of rules that
map from syntax to semantics. The rules take syn-
tactic f-structures as input and output a high-level
semantic representation compatible with VigNet.
The left-hand side of a rule consists of a set of con-
ditions on the f-structure elements and the right-
hand side consists of the semantic structure that
should be returned. Figure 4(a) is an example of
a rule mapping Arrernte syntax to semantics, cre-
ated in WELT.
In addition to these rules, the linguist creates a
simple table mapping lexical items into VigNet se-
mantic concepts, so that nouns can be converted to
graphical objects. We have created a mapping for
the lexical items in the Arrernte grammar; a partial
mapping is shown in Table 1.
We now describe the semantic processing of our
example Arrernte sentence, assuming a set of rules
consisting solely of the one in Figure 4(a) and the
noun mapping in Table 1. The f-structure in Fig-
52
(a) (b)
Figure 4: Syntax-semantics rule (a) and semantic category browser (b) from WELT
Lexical Item artwe panikane angepe akngwelye apwerte tipwele
VigNet Concept PERSON.N CUP.N CROW.N DOG.N ROCK-ITEM.N TABLE.N
Table 1: A mapping from nouns (lexical items) to VigNet semantic concepts
ure 3(b) has main predicate arrerne with two ar-
guments; the object is goal. Therefore, it matches
the left-hand-side of our rule. The output of
the rule specifies predicate CAUSE MOTION.KICK
with three arguments. The latter two are straight-
forward; the Theme is the VigNet object FOOTY-
BALL.N, and the Goal is FOOTYGOAL.N. To deter-
mine the Agent, we need to find the VigNet con-
cept corresponding to var-1, which occupies the
subject position in the f-structure. The subject in
our f-structure is artwe, and according to Table 1,
it maps to the VigNet concept PERSON.N. The re-
sulting semantic representation is augmented with
its graphical semantics, taken from the vignette
for CAUSE MOTION.KICK (vignette definition not
shown for lack of space). The final representation
is shown in Figure 5, with lexical semantics at the
top and graphical semantics below. The Words-
Eye system then builds the scene from these con-
straints and renders it in 3D.
CAUSE_MOTION.KICK
FOOTYBALL
Theme
FOOTYGOAL
Goal
PERSON
Agent
20 ft
FRONT-OF
Dist
ORIENT-TOPOSITION-BETWEEN
Figure GroundGoal Ground
IN-POSE
FigureSource SubjectFigure
kick
Value
Figure 5: The semantics (lexical and graphical) for
sentence (1)
WELT provides an interface for creating rules
by defining the tree structures for the left-hand-
side and right-hand-side of the rule. Every node on
the left-hand-side can optionally contain boolean
logic, if for example we want to allow the sub-
ject to be [(artwe ?man? OR arhele ?woman?) AND
NOT ampe ?child?]; so rules can be as simple or
complex as desired. Rules need not specify lexical
items directly; it is also possible to refer to more
general semantic categories. For example, a rule
could select for all verbs of motion, or specify a
particular constraint on the subject or object. In
figure 4(a), for instance, we may want to only al-
low animate subjects.
Semantic categories are chosen through a
browser that allows the user to search through all
the semantic categories defined in VigNet. For ex-
ample, if we want to find the semantic category
to use as a constraint on our example subject, we
might start by searching for human. This takes us
to a portion of a tree of semantic concepts cen-
tered around HUMAN.N. The semantic categories
are displayed one level at a time, so we initially
see only the concepts directly above and directly
below the word we searched for. From there, it?s
easy to select the concepts we are interested in,
and go up or down the tree until we find the one we
want. Below HUMAN.N are HUMAN-FEMALE.N
and HUMAN-MALE.N, but we are more interested
in the more general categories above the node. A
screen shot showing the result of this search is
shown in Figure 4(b). Above HUMAN.N is HU-
MANOID.N; above that, ANIMATE-BEING.N. Do-
ing a quick check of further parents and chil-
dren, we can see that for the subject of ?put goal,?
we would probably want to choose ANIMATE-
BEING.N over LIVING-THING.N.
The table mapping lexical items to VigNet con-
cepts is built in a similar way; the lexicon is au-
tomatically extracted from the LFG grammar, and
the user can search and browse semantic concepts
to find the appropriate node for each lexical item.
We will demonstrate the WELT user inter-
53
face which supports the creation of syntax-to-
semantics rules, creates the mapping between
nouns in the lexicon and VigNet concepts, and ver-
ifies the rules using the WELT text-to-scene sys-
tem. We will show examples from our documenta-
tion of Arrernte and demonstrate entering text into
the Arrernte text-to-scene system to generate pic-
tures.
5 Summary and Future Work
We have described a novel tool for linguists work-
ing with endangered languages. It provides a new
way to elicit data from informants, an interface
for formally documenting the lexical semantics of
a language, and allows the creation of a text-to-
scene system for any language.
This project is in its early stages, so we are plan-
ning many additional features and improvements.
For both modes of WELT, we want to generate pic-
tures appropriate for the target culture. To han-
dle this, we will add the ability to include cus-
tom objects and modify VigNet with new vignettes
or new graphical semantics for existing vignettes.
We also plan to build tools to import and export
the work done in WELT in order to facilitate col-
laboration among linguists working on similar lan-
guages or cultures. Sharing sets of scenes will al-
low linguists to reuse work and avoid duplicated
effort. Importing different versions of VigNet will
make it easier to start out with WELT on a new
language if it is similar to one that has already
been studied. We might expect, for instance, that
other Australian aboriginal languages will require
the same kinds of cultural modifications to VigNet
that we make for Arrernte, or that two languages
in the same family might also have similar syntax
to semantics rules.
Acknowledgments
This material is based upon work supported by
the National Science Foundation under Grant No.
1160700.
References
Alliance for Linguistic Diversity. 2013. The En-
dangered Languages Project. http://www.
endangeredlanguages.com/.
C. Baker, J. Fillmore, and J. Lowe. 1998. The Berkeley
FrameNet project. In 36th Meeting of the Associa-
tion for Computational Linguistics and 17th Inter-
national Conference on Computational Linguistics
(COLING-ACL?98), pages 86?90, Montr?eal.
C. Baker. 2008. FrameNet, present and future. In The
First International Conference on Global Interoper-
ability for Language Resources, pages 12?17.
E. Bender, D. Flickinger, and S. Oepen. 2002. The
Grammar Matrix. In J. Carroll, N. Oostdijk, and
R. Sutcliffe, editors, Workshop on Grammar En-
gineering and Evaluation at the 19th International
Conference on Computational Linguistics, pages 8?
14, Taipei, Taiwan.
S. Bird. 2009. Natural language processing and
linguistic fieldwork. Computational Linguistics,
35(3):469?474.
C. Black and H.A. Black. 2012. Grammars for the
people, by the people, made easier using PAWS and
XLingPaper. In Sebastian Nordoff, editor, Elec-
tronic Grammaticography, pages 103?128. Univer-
sity of Hawaii Press, Honolulu.
H.A. Black and G.F. Simons. 2006. The SIL Field-
Works Language Explorer approach to morphologi-
cal parsing. In Computational Linguistics for Less-
studied Languages: Texas Linguistics Society 10,
Austin, TX, November.
M. Bowerman and E. Pederson. 1992. Topological re-
lations picture series. In S. Levinson, editor, Space
stimuli kit 1.2, page 51, Nijmegen. Max Planck In-
stitute for Psycholinguistics.
M. Butt, H. Dyvik, T.H. King, H. Masuichi, and
C. Rohrer. 2002. The parallel grammar project. In
2002 Workshop on Grammar Engineering and Eval-
uation - Volume 15, COLING-GEE ?02, pages 1?
7, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
B. Coyne and R. Sproat. 2001. WordsEye: An au-
tomatic text-to-scene conversion system. In SIG-
GRAPH.
B. Coyne, D. Bauer, and O. Rambow. 2011a. Vignet:
Grounding language in graphics using frame seman-
tics. In ACL Workshop on Relational Models of Se-
mantics (RELMS), Portland, OR.
B. Coyne, C. Schudel, M. Bitz, and J. Hirschberg.
2011b. Evaluating a text-to-scene generation system
as an aid to literacy. In SlaTE (Speech and Language
Technology in Education) Workshop at Interspeech,
Venice.
D. Crouch, M. Dalrymple, R. Kaplan, T. King,
J. Maxwell, and P. Newman, 2006. XLE Doc-
umentation. http://www2.parc.com/isl/
groups/nltt/xle/doc/xle.
C. Filmore, C. Johnson, and M. Petruck. 2003. Back-
ground to FrameNet. In International Journal of
Lexicography, pages 235?250.
R.M. Kaplan and J.W. Bresnan. 1982. Lexical-
functional grammar: A formal system for grammat-
ical representation. In J.W. Bresnan, editor, The
Mental Representation of Grammatical Relations.
MIT Press, Cambridge, Mass., December.
L. Karttunen, T. Ga?al, and A. Kempe. 1997. Xerox
finite-state tool. Technical report, Xerox Research
Centre Europe, Grenoble.
S. McConnel, 1995. PC-PATR Reference Manual.
Summer Institute for Linguistics.
54
Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages, pages 6?14,
Baltimore, Maryland, USA, 26 June 2014.
c?2014 Association for Computational Linguistics
Documenting Endangered Languages with the WordsEye Linguistics Tool
Morgan Ulinski
?
mulinski@cs.columbia.edu
Anusha Balakrishnan
?
ab3596@columbia.edu
Daniel Bauer
?
bauer@cs.columbia.edu
Bob Coyne
?
coyne@cs.columbia.edu
Julia Hirschberg
?
julia@cs.columbia.edu
Owen Rambow
?
rambow@ccls.columbia.edu
?
Department of Computer Science
?
CCLS
Columbia University
New York, NY, USA
Abstract
In this paper, we describe how field lin-
guists can use the WordsEye Linguistics
Tool (WELT) to study endangered lan-
guages. WELT is a tool under devel-
opment for eliciting endangered language
data and formally documenting a lan-
guage, based on WordsEye (Coyne and
Sproat, 2001), a text-to-scene generation
tool that produces 3D scenes from text in-
put. First, a linguist uses WELT to create
elicitation materials and collect language
data. Next, he or she uses WELT to for-
mally document the language. Finally, the
formal models are used to create a text-
to-scene system that takes input in the en-
dangered language and generates a picture
representing its meaning.
1 Introduction
Although languages have appeared and disap-
peared throughout history, today languages are
facing extinction at an unprecedented pace. Over
40% of the estimated 7,000 languages in the world
are at risk of disappearing. When languages die,
we lose access to an invaluable resource for study-
ing the culture, history, and experience of people
who spoke them (Alliance for Linguistic Diversity,
2013). Efforts to document languages and develop
tools to support these efforts become even more
important with the increasing rate of extinction.
Bird (2009) emphasizes a particular need to make
use of computational linguistics during fieldwork.
To address this issue, we are developing the
WordsEye Linguistics Tool, WELT. In one mode
of operation, we provide field linguists with tools
for building elicitation sessions based on custom
3D scenes. In another, we provide a way to for-
mally document the endangered language. For-
mal hypotheses can be verified using a text-to-
scene system that takes input in the endangered
language, analyzes it based on the formal model,
and generates a picture representing the meaning.
WELT provides important advantages to field
linguists for elicitation over the current practice of
using a set of pre-fabricated static pictures. Using
WELT the linguist can create and modify scenes
in real time, based on informants? responses, cre-
ating follow-up questions and scenes to support
them. Since the pictures WELT supports are 3D
scenes, the viewpoint can easily be changed, al-
lowing exploration of linguistic descriptions based
on different frames of reference, as for elicitations
of spatial descriptions. Finally, since scenes and
objects can easily be added in the field, the lin-
guist can customize the images used for elicitation
to be maximally relevant to the current informants.
Creating a text-to-scene system for an endan-
gered language with WELT also has advantages.
First, WELT allows documentation of the seman-
tics of a language in a formal way. Linguists can
customize the focus of their studies to be as deep
or shallow as they wish; however, we believe that a
major advantage of documenting a language with
WELT is that it enables studies that are much more
precise. The fact that a text-to-scene system is cre-
ated from this documentation will allow linguists
to test the theories they develop with native speak-
ers, making changes to grammars and semantics
in real time. The resulting text-to-scene system
can also be an important tool for language preser-
vation, spreading interest in the language among
younger generations of the community and re-
cruiting new speakers.
In this paper, we discuss the WELT toolkit and
its intended use, with examples from Arrernte and
Nahuatl. In Section 2 we discuss prior work on
field linguistics computational tools. In Section 3
we present an overview of the WELT system. We
describe using WELT for elicitation in Section 4
and describe the tools for language documentation
in Section 5. We conclude in Section 6.
6
2 Related Work
Computational tools for field linguistics fall into
two categories: tools for native speakers to use
directly, without substantial linguist intervention,
and tools for field linguists to use. Tools intended
for native speakers include the PAWS starter kit
(Black and Black, 2009), which uses the answers
to a series of guided questions to produce a draft
of a grammar. Similarly, Bird and Chiang (2012)
describe a simplified workflow and supporting MT
software that lets native speakers produce useable
documentation of their language on their own.
One of the most widely-used toolkits in the lat-
ter category is SIL FieldWorks (SIL FieldWorks,
2014), or specifically, FieldWorks Language Ex-
plorer (FLEx). FLEx includes tools for elicit-
ing and recording lexical information, dictionary
development, interlinearization of texts, analysis
of discourse features, and morphological analy-
sis. An important part of FLEx is its ?linguist-
friendly? morphological parser (Black and Si-
mons, 2006), which uses an underlying model
of morphology familiar to linguists, is fully in-
tegrated into lexicon development and interlin-
ear text analysis, and produces a human-readable
grammar sketch as well as a machine-interpretable
parser. The morphological parser is constructed
?stealthily? in the background, and can help a lin-
guist by predicting glosses for interlinear texts.
Linguist?s Assistant (Beale, 2011) provides a
corpus of semantic representations for linguists to
use as a guide for elicitation. After eliciting the
language data, a linguist writes rules translating
these semantic representations into surface forms.
The result is a description of the language that can
be used to generate text from documents that have
been converted into the semantic representation.
Linguists are encouraged to collect their own elic-
itations and naturally occurring texts and translate
them into the semantic representation.
The LinGO Grammar Matrix (Bender et al.,
2002) facilitates formal modeling of syntax by
generating basic HPSG ?starter grammars? for
languages from the answers to a typological ques-
tionnaire. Extending a grammar beyond the proto-
type, however, does require extensive knowledge
of HPSG, making this tool more feasibly used by
grammar engineers and computational linguists.
For semantics, the most common resource for for-
mal documentation across languages is FrameNet
(Filmore et al., 2003); FrameNets have been de-
veloped for many languages, including Spanish,
Japanese, and Portuguese. However, FrameNet is
also targeted toward computational linguists.
In general, we also lack tools for creating cus-
tom elicitation materials. With WELT, we hope to
fill some of the gaps in the range of available field
linguistics tools. WELT will enable the creation of
custom elicitation material and facilitate the man-
agement sessions with an informant. WELT will
also enable formal documentation of the semantics
of a language without knowledge of specific com-
putational formalisms. This is similar to the way
FLEx allows linguists to create a formal model of
morphology while also documenting the lexicon
of a language and glossing interlinear texts.
3 Overview of WELT Workflow
In this section, we briefly describe the workflow
for using WELT; a visual representation is pro-
vided in Figure 1. Since we are still in the early
stages of our project, this workflow has not been
tested in practice. The tools for scene creation and
elicitation are currently useable, although more
features will be added in the future. The tools for
modeling and documentation are still in develop-
ment; although some functionality has been imple-
mented, we are still testing it with toy grammars.
First, WELT will be used to prepare a set of 3D
scenes to be used to elicit targeted descriptions or
narratives. An important part of this phase will be
the cultural adaptation of the graphical semantics
used in WordsEye, so that scenes will be relevant
to the native speakers a linguist works with. We
will discuss cultural adaptation in more detail in
Section 4.1. Next, the linguist will work with an
informant to generate language data based on pre-
pared 3D scenes. This can be a dynamic process;
as new questions come up, a linguist can easily
modify existing scenes or create new ones. WELT
also automatically syncs recorded audio with open
scenes and provides an interface for the linguist to
write notes, textual descriptions, and glosses. We
will discuss creating scenes and eliciting data with
WELT in Section 4.2. After the elicitation session,
the linguist can use WELT to review the data col-
lected, listen to the audio recorded for each scene,
and revise notes and glosses. The linguist can then
create additional scenes to elicit more data or be-
gin the formal documentation of the language.
Creating a text-to-scene system with WELT re-
quires formal models of the morphology, syntax,
7
Define	 ?Lexicon	 ?
Cultural	 ?
Adapta?on	 ?of	 ?
VigNet	 ?
Create	 ?Scenes	 ? Collect	 ?Data	 ?from	 ?informant	 ?
Clean-??up	 ?notes/
glosses	 ?
Modify	 ?&	 ?add	 ?vigne?es	 ?
Define	 ?syntax	 ?to	 ?seman?cs	 ?rules	 ?
Define	 ?Morphology	 ?
Define	 ?Syntax	 ?
L2	 ?
Lexicon	 ?
L2	 ?Syntax-??
Seman?cs	 ?rules	 ?VigNet	 ?Resources 
Output	 ?&	 ?
Collabora?on	 ? Prepare	 ?L2	 ?scenes	 ?
Verify	 ?with	 ?
informant	 ?
XLE	 ? FieldWorks	 ?Tools WELT	 ?
Figure 1: WELT workflow
and semantics of a language. Since the focus
of WELT is on semantics, the formalisms used
to model morphology and syntax may vary. We
are using FieldWorks to document Nahuatl mor-
phology, XFST (Beesley and Karttunen, 2003) to
model Arrernte morphology, and XLE (Crouch et
al., 2011) to model syntax in the LFG formal-
ism (Kaplan and Bresnan, 1982). We will provide
tools to export WELT descriptions and glosses
into FLEx format and to export the lexicon cre-
ated during documentation into FLEx and XLE.
WELT will provide user interfaces for modeling
the syntax-semantics interface, lexical semantics,
and graphical semantics of a language. We will
discuss these in more detail in Section 5.3.
Once models of morphology, syntax, and se-
mantics are in place (note that these can be work-
ing models, and need not be complete), WELT
puts the components together into a text-to-scene
system that takes input in the endangered language
and uses the formal models to generate pictures.
This system can be used to verify theories with in-
formants and revise grammars. As new questions
arise, WELT can also continue to be used to create
elicitation materials and collect linguistic data.
Finally, we will create a website for WELT so
linguists can share resources such as modified ver-
sions of VigNet, 3D scenes, language data col-
lected, and formal grammars. This will allow
comparison of analyses across languages, as well
as facilitate the documentation of other languages
that are similar linguistically or spoken by cul-
turally similar communities. In addition, sharing
the resulting text-to-scene systems with a wider
audience can generate interest in endangered lan-
guages and, if shared with endangered-language-
speaking communities, encourage younger mem-
bers of the community to use the language.
4 Elicitation with WELT
WELT organizes elicitation sessions around a set
of 3D scenes, which are created by inputting En-
glish text into WordsEye. Scenes can be imported
and exported between sessions, so that useful
scenes can be reused and data compared. WELT
also provides tools for recording audio (which is
automatically synced with open scenes), textual
descriptions, glosses, and notes during a session.
Screenshots are included in Figure 2.
4.1 Cultural Adaptation of VigNet
To interpret input text, WordsEye uses VigNet
(Coyne et al., 2011), a lexical resource based on
FrameNet (Baker et al., 1998). As in FrameNet,
lexical items are grouped in frames according to
shared semantic structure. A frame contains a set
of frame elements (semantic roles). FrameNet de-
fines the mapping between syntax and semantics
for a lexical item with valence patterns that map
syntactic functions to frame elements.
VigNet extends FrameNet in order to capture
?graphical semantics?, a set of graphical con-
straints representing the position, orientation, size,
color, texture, and poses of objects in the scene,
8
Figure 2: Screenshots of WELT elicitation interfaces
which is used to construct and render a 3D
scene. Graphical semantics are added to frames by
adding primitive graphical (typically, spatial) rela-
tions between frame element fillers. VigNet distin-
guishes between meanings of words that are dis-
tinguished graphically. For example, the specific
objects (e.g., implements) and spatial relations in
the graphical semantics for cook depend on the
object being cooked and on the culture in which
it is being cooked (cooking turkey in Baltimore
vs. cooking an egg in Alice Springs), even though
at an abstract level cook an egg in Alice Springs
and cook a turkey in Baltimore are perfectly com-
positional semantically. Frames augmented with
graphical semantics are called vignettes.
Vignette Tailoring: Without digressing into a dis-
cussion on linguistic relativity, we assume that
large parts of VigNet are language- and culture-
independent. The low-level graphical relations
used to express graphical semantics are based on
physics and human anatomy and do not depend on
language. However, the graphical semantics for a
vignette may be culture-specific, and some new vi-
gnettes will need to be added for a culture. In the
U.S., for example, the sentence The woman boiled
the water might invoke a scene with a pot of wa-
ter on a stove in a kitchen. Among the Arrernte
people, it would instead invoke a woman sitting
on the ground in front of a kettle on a campfire.
Figure 3 shows an illustration from the Eastern
and Central Arrernte Picture Dictionary (Broad,
2008) of the sentence Ipmenhe-ipmenhele kwatye
urinpe-ilemele iteme, ?My grandmother is boiling
the water.? The lexical semantics for the English
verb boil and the Arrente verb urinpe-ileme are
the same, the relation APPLY-HEAT.BOIL. How-
ever, the vignettes map to different, culture-typical
graphical semantics. The vignettes for our exam-
ple are shown in Figure 4.
Figure 3: Illustration from Broad (2008).
To handle cultural differences like these, a lin-
guist will use WELT to extend VigNet with new
9
Figure 4: Vignettes for the woman boils the water.
The high-level semantics of APPLY-HEAT.BOIL
are decomposed into sets of objects and primitive
graphical relations that depend on cultural context.
graphical semantics for existing vignettes that
need to be modified, and new vignettes for scenar-
ios not already covered. We will create interfaces
so that VigNet can easily be adapted.
Custom WordsEye Objects: Another way to
adapt WordsEye to a culture or region is to add rel-
evant 3D objects to the database. WordsEye also
supports 2D-cutout images, which is an easy way
to add new material without 3D modeling. We
have created a corpus of 2D and 3D models for
WordsEye that are specifically relevant to aborig-
inal speakers of Arrernte, including native Aus-
tralian plants and animals and culturally relevant
objects and gestures. Many of the pictures we cre-
ated are based on images from IAD Press, used
with permission, which we enhanced and cropped
in PhotoShop. Some scenes that use these images
are included in Figure 5. Currently, each new ob-
ject has to be manually incorporated into Words-
Eye, but we will create tools to allow WELT users
to easily add pictures and objects.
New objects will also need to be incorporated
into the semantic ontology. VigNet?s ontology
consists of semantic concepts that are linked to-
gether with ISA relations. The ontology supports
multiple inheritance, allowing a given concept to
be a sub-type of more than one concept. For exam-
ple, a PRINCESS.N is a subtype of both FEMALE.N
and ARISTOCRAT.N, and a BLACK-WIDOW.N is a
subtype of SPIDER.N and POISONOUS-ENTITY.N.
Concepts are often linked to corresponding lexi-
cal items. If a lexical item has more than one
word sense, the different word senses would be
represented by different concepts. In addition, ev-
ery graphical object in VigNet is represented by
a unique concept. For example, a particular 3D
model of a dog would be a linked to the general
DOG.N concept by the ISA relation. The semantic
concepts in VigNet include the graphical objects
available in WordsEye as well as concepts tied to
related lexical items. While WordsEye might only
have a handful of graphical objects for dogs, Vi-
gNet will have concepts representing all common
types of dogs, even if there is no graphical object
associated with them. We will provide interfaces
both for adding new objects and for modifying the
semantic concepts in VigNet to reflect the differ-
ing lexical semantics of a new language.
4.2 Preparing Scenes and Eliciting Data
The next step in the workflow is the preparation
of scenes and elicitation of descriptions. To test
creating elicitation materials with WELT, we built
a set of scenes based on the Max Planck topolog-
ical relations picture series (Bowerman and Ped-
erson, 1992). In creating these, we used a feature
of WordsEye that allows highlighting specific ob-
jects (or parts of objects) in a scene. We used these
scenes to elicit descriptions from a native Nahuatl
speaker; some examples are included in Figure 6.
(a) in tapamet? t?atsakwa se kali
the fence/wall around the house
(b) in tsopelik katsekotok t?atsint?a in t?apetS
the candy sticking under the table
Figure 6: Nahuatl examples elicited with WELT
One topic we will explore with WELT is the re-
lationship in Arrernte between case and semantic
interpretation of a sentence. It is possible to signif-
icantly alter a sentence?s meaning by changing the
case on an argument. For example, the sentences
in (1) from Wilkins (1989) show that adding dative
10
Figure 5: WordsEye scenes using custom 2D gum tree and dingo from our corpus
case to the direct object of the sentence changes
the meaning from shooting and hitting the kanga-
roo to shooting at the kangaroo and not hitting it.
Wilkins calls this the ?dative of attempt.?
(1) a. re aherre tyerre-ke
he kangaroo shot-pc
He shot the kangaroo.
b. re aherre-ke tyerre-ke
he kangaroo-DAT shot-pc
He shot at the kangaroo (but missed).
In order to see how this example generalizes,
we will create pairs of pictures, one in which the
object of the sentence is acted upon, and one in
which the object fails to be acted upon. Figure 7
shows a pair of scenes contrasting an Australian
football player scoring a goal with a player aiming
at the goal but missing the shot. Sentences (2) and
(3) are two ways of saying ?score a goal? in Ar-
rernte; we want to see if a native Arrernte speaker
would use goal-ke in place of goal in this context.
(2) artwe le goal arrerne-me
man ERG goal put-NP
The man kicks a goal.
(3) artwe le goal kick-eme-ile-ke
man ERG goal kick-VF-TV-PST
The man kicked a goal.
5 Modeling a Language with WELT
WELT includes tools for documenting the seman-
tics of the language. It also uses this documenta-
tion to automatically generate a text-to-scene sys-
tem for the language. Because WELT is centered
around the idea of 3D scenes, the formal docu-
mentation will tend to focus on the parts of the se-
mantics that can be represented graphically. Note
that this can include figurative concepts as well,
although the visual representation of these may be
culture-specific. However, linguists do not need
to be limited by the graphical output; WELT can
be used to document other aspects of semantics as
well, but linguists will not be able to verify these
theories using the text-to-scene system.
To explain the necessary documentation, we
briefly describe the underlying architecture of
WordsEye, and how we are adapting it to sup-
port text-to-scene systems for other languages.
The WordsEye system parses each input sentence
into a labeled syntactic dependency structure, then
converts it into a lexical-semantic structure using
lexical valence patterns and other lexical and se-
mantic information. The resulting set of seman-
tic relations is converted to a ?graphical seman-
tics?, the knowledge needed to generate graphical
scenes from language.
To produce a text-to-scene system for a new lan-
guage, WELT must replace the English linguistic
processing modules with models for the new lan-
guage. The WELT processing pipeline is illus-
trated in Figure 8, with stages of the pipeline on
top and required resources below. In this section,
we will discuss creating the lexicon, morphologi-
cal and syntactic parsers, and syntax-to-semantics
rules. The vignettes and 3D objects will largely
have been done during cultural adaptation of Vi-
gNet; additional modifications needed to handle
the semantics can be defined using the same tools.
5.1 The Lexicon
The lexicon in WELT is a list of word forms
mapped to semantic concepts. The process of
building the lexicon begins during elicitation.
WELT?s elicitation interface includes an option to
display each object in the scene individually be-
fore progressing to the full scene. When an object
is labeled and glossed in this way, the word and
the semantic concept represented by the 3D ob-
ject are immediately added to the lexicon. Word
forms glossed in scene descriptions will also be
added to the lexicon, but will need to be mapped
to semantic concepts later. WELT will provide
11
Figure 7: WordsEye scenes to elicit the ?dative of attempt.?
Morph	 ? Lexical	 ?Seman?cs	 ?
Graphical	 ?
Seman?cs	 ? Scene	 ?
Input	 ?
Text	 ?
Processing	 ?Pipeline	 ?
VigNet	 ?
Vigne?s	 ? 2D/3D	 ?objects	 ?Lexicon	 ?
Syntax	 ?
Morphological	 ?
Analyzer	 ?
Syntac?c	 ?
Parser	 ?
Syntax-??Seman?cs	 ?
Rules	 ?
Figure 8: WELT architecture
tools for completing the lexicon by modifying
the automatically-added items, adding new lexical
items, and mapping each lexical item to a seman-
tic concept in VigNet. Figure 9(a) shows a partial
mapping of the nouns in our Arrernte lexicon.
WELT includes a visual interface for search-
ing VigNet?s ontology for semantic concepts and
browsing through the hierarchy to select a partic-
ular category. Figure 9(b) shows a portion of the
ontology that results from searching for cup. Here,
we have decided to map panikane to CUP.N. Se-
mantic categories are displayed one level at a time,
so initially only the concepts directly above and
below the search term are shown. From there, it is
simple to click on relevant concepts and navigate
the graph to find an appropriate semantic category.
To facilitate the modeling of morphology and syn-
tax, WELT will also export the lexicon into for-
mats compatible with FieldWorks and XLE, so the
list of word forms can be used as a starting point.
5.2 Morphology and Syntax
As mentioned earlier, the focus of our work on
WELT is on modeling the interface between syn-
tax, lexical semantics, and graphical semantics.
Therefore, although WELT requires models of
morphology and syntax to generate a text-to-scene
system, we are relying on third-party tools to build
those models. For morphology, a very good tool
already exists in FLEx, which allows the creation
Lexical VigNet
Item Concept
artwe PERSON.N
panikane CUP.N
angepe CROW.N
akngwelye DOG.N
tipwele TABLE.N
(a) (b)
Figure 9: (a) Arrernte lexical items mapped to Vi-
gNet concepts; (b) part of the VigNet ontology
of a morphological parser without knowledge of
any particular grammatical formalism. For syn-
tax, we are using XLE for our own work while
researching other options that would be more ac-
cessible to non-computational linguists. It is im-
portant to note, though, that the modeling done in
WELT does not require a perfect syntactic parser.
In fact, one can vastly over-generate syntax and
still accurately model semantics. Therefore, the
syntactic grammars provided as models do not
need to be complex. However, the question of syn-
tax is still an open area of research in our project.
5.3 Semantics
To use the WordsEye architecture, the system
needs to be able to map between the formal syntax
of the endangered language and a representation of
semantics compatible with VigNet. To accomplish
12
Figure 10: Creating syntax-semantics rules in WELT
this, WELT includes an interface for the linguist to
specify a set of rules that map from syntax to (lex-
ical) semantics. Since we are modeling Arrernte
syntax with LFG, the rules currently take syntactic
f-structures as input, but the system could easily be
modified to accommodate other formalisms. The
left-hand side of a rule consists of a set of con-
ditions on the f-structure elements and the right-
hand side is the desired semantic structure. Rules
are specified by defining a tree structure for the
left-hand (syntax) side and a DAG for the right-
hand (semantics) side.
As an example, we will construct a rule to
process sentence (2) from Section 4.2, artwe le
goal arrerneme. For this sentence, our Arrernte
grammar produces the f-structure in Figure 11.
We create a rule that selects for predicate ar-
rerne with object goal and any subject. Figure
10 shows the construction of this rule in WELT.
Note that var-1 on the left-hand side becomes
VIGNET(var-1) on the right-hand side; this in-
dicates that the lexical item found in the input is
mapped into a semantic concept using the lexicon.
Figure 11: F-structure for sentence 2, Section 4.2.
The rule shown in Figure 10 is a very sim-
ple example. Nodes on the left-hand side of
the rule can also contain boolean logic, if we
wanted to allow the subject to be [(artwe ?man? OR
arhele ?woman?) AND NOT ampe ?child?]. Rules
need not specify lexical items directly but may
refer to more general semantic categories. For
example, our rule could require a particular se-
mantic category for VIGNET(var-1), such as
ANIMATE-BEING.N. These categories are chosen
through the same ontology browser used to cre-
ate the lexicon. Finally, to ensure that our sen-
tence can be converted into graphics, we need
to make sure that a vignette definition exists for
CAUSE MOTION.KICK so that the lexical seman-
tics on the right-hand side of our rule can be aug-
mented with graphical semantics; the vignette def-
inition is given in Figure 12. The WordsEye sys-
tem will use the graphical constraints in the vi-
gnette to build a scene and render it in 3D.
Figure 12: Vignette definition for
CAUSE MOTION.KICK
6 Summary
We have described a novel tool under develop-
ment for linguists working with endangered lan-
guages. It will provide a new way to elicit data
from informants, an interface for formally docu-
menting the lexical semantics of a language, and
allow the creation of a text-to-scene system for any
language. In this paper, we have focused specifi-
cally on the workflow that a linguist would fol-
low while studying an endangered language with
WELT. WELT will provide useful tools for field
linguistics and language documentation, from cre-
ating elicitation materials, to eliciting data, to for-
mally documenting a language. In addition, the
text-to-scene system that results from document-
ing an endangered language with WELT will be
valuable for language preservation, generating in-
terest in the wider world, as well as encouraging
younger members of endangered language com-
munities to use the language.
Acknowledgments
This material is based upon work supported by
the National Science Foundation under Grant No.
1160700.
13
References
Alliance for Linguistic Diversity. 2013. The En-
dangered Languages Project. http://www.
endangeredlanguages.com.
C. Baker, J. Fillmore, and J. Lowe. 1998. The Berkeley
FrameNet project. In 36th Meeting of the Associa-
tion for Computational Linguistics and 17th Inter-
national Conference on Computational Linguistics
(COLING-ACL?98), pages 86?90, Montr?eal.
Stephen Beale. 2011. Using Linguist?s Assistant for
Language Description and Translation. In IJCNLP
2011 System Demonstrations, pages 5?8.
Kenneth R. Beesley and Lauri Karttunen. 2003. Finite-
State Morphology Homepage. http://www.
fsmbook.com.
E. Bender, D. Flickinger, and S. Oepen. 2002. The
Grammar Matrix. In J. Carroll, N. Oostdijk, and
R. Sutcliffe, editors, Workshop on Grammar En-
gineering and Evaluation at the 19th International
Conference on Computational Linguistics, pages 8?
14, Taipei, Taiwan.
S. Bird and D. Chiang. 2012. Machine translation for
language preservation. In COLING 2012: Posters,
pages 125?134, Mumbai, December.
S. Bird. 2009. Natural language processing and
linguistic fieldwork. Computational Linguistics,
35(3):469?474.
Cheryl A Black and H Andrew Black. 2009. PAWS:
Parser and Writer for Syntax. In SIL Forum for Lan-
guage Fieldwork 2009-002.
H.A. Black and G.F. Simons. 2006. The SIL Field-
Works Language Explorer approach to morphologi-
cal parsing. In Computational Linguistics for Less-
studied Languages: Texas Linguistics Society 10,
Austin, TX, November.
M. Bowerman and E. Pederson. 1992. Topological re-
lations picture series. In S. Levinson, editor, Space
stimuli kit 1.2, page 51, Nijmegen. Max Planck In-
stitute for Psycholinguistics.
N. Broad. 2008. Eastern and Central Arrernte Picture
Dictionary. IAD Press.
B. Coyne and R. Sproat. 2001. WordsEye: An au-
tomatic text-to-scene conversion system. In SIG-
GRAPH.
B. Coyne, D. Bauer, and O. Rambow. 2011. Vignet:
Grounding language in graphics using frame seman-
tics. In ACL Workshop on Relational Models of Se-
mantics (RELMS), Portland, OR.
D. Crouch, M. Dalrymple, R. Kaplan, T. King,
J. Maxwell, and P. Newman. 2011. XLE Doc-
umentation. http://www2.parc.com/isl/
groups/nltt/xle/doc/xle_toc.html.
C. Filmore, C. Johnson, and M. Petruck. 2003. Back-
ground to FrameNet. In International Journal of
Lexicography, pages 235?250.
R.M. Kaplan and J.W. Bresnan. 1982. Lexical-
functional grammar: A formal system for grammat-
ical representation. In J.W. Bresnan, editor, The
Mental Representation of Grammatical Relations.
MIT Press, Cambridge, Mass., December.
SIL FieldWorks. 2014. SIL FieldWorks. http://
fieldworks.sil.org.
D. Wilkins. 1989. Mparntwe Arrernte (Aranda): Stud-
ies in the structure and semantics of grammar. Ph.D.
thesis, Australian National University.
14
