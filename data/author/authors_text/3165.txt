Word Sense Disambiguation using a dictionary for sense similarity measure
Bruno Gaume Nabil Hathout Philippe Muller
IRIT ? CNRS, UPS & INPT ERSS ? CNRS & UTM IRIT ? CNRS, UPS & INPT
Toulouse, France Toulouse, France Toulouse, France
gaume@irit.fr hathout@univ-tlse2.fr muller@irit.fr
Abstract
This paper presents a disambiguation
method in which word senses are deter-
mined using a dictionary. We use a seman-
tic proximity measure between words in the
dictionary, taking into account the whole
topology of the dictionary, seen as a graph
on its entries. We have tested the method on
the problem of disambiguation of the dic-
tionary entries themselves, with promising
results considering we do not use any prior
annotated data.
1 Introduction
Various tasks dealing with natural language
data have to cope with the numerous different
senses possessed by every lexical item: ma-
chine translation, information retrieval, infor-
mation extraction ... This very old issue is far
from being solved, and evaluation of methods
addressing it is far from obvious (Resnik and
Yarowsky, 2000). This problem has been tack-
led in a number of ways1: by looking at con-
texts of use (with supervised learning or un-
supervised sense clustering) or by using lexi-
cal resources such as dictionaries or thesauri.
The first kind of approach relies on data that
are hard to collect (supervised) or very sensitive
to the type of corpus (unsupervised). The sec-
ond kind of approach tries to exploit the lexical
knowledge that is represented in dictionaries or
thesaurus, with various results from its incep-
tion up to now (Lesk, 1986; Banerjee and Ped-
ersen, 2003). In all cases, a distance between
words or word senses is used as a way to find
the right sense in a given context. Dictionary-
based approaches usually rely on a comparison
of the set of words used in sense definitions and
1A good introduction is (Ide and V?ronis, 1998), or
(Manning and Sch?tze, 1999), chap. 7.
in the context to disambiguate2.
This paper presents an algorithm which uses
a dictionary as a network of lexical items (cf.
sections 2 and 3) to compute a semantic simi-
larity measure between words and word senses.
It takes into account the whole topology of the
dictionary instead of just the entry of target
words. This arguably gives a certain robustness
of the results with respect to the dictionary. We
have begun testing this approach on word sense
disambiguation on definitions of the dictionary
itself (section 5), but the method is expected
to be more general, although this has not been
tested yet. Preliminary results are quite encour-
aging considering that the method does not re-
quire any prior annotated data, while operating
on an unconstrained vocabulary.
2 Building the graph of a
dictionary
The experiment we describe here has been
achieved on a dictionary restricted to nouns and
verbs only: we considered dictionary entries
classified as nouns and verbs and noun and verb
lemmas occurring within those entries. The
basic idea is to consider the dictionary as an
undirected graph whose nodes are noun entries,
and an edge exists between two nodes when-
ever one of them occur in the definition of the
other. More precisely, the graph of the dictio-
nary encodes two types of lexicographical in-
formations: (1) the definitions of the entries
sub-senses and (2) the structure of the entries
that is the hierarchical organisation of their sub-
senses. The graph then includes two types of
nodes: w-nodes used for the words that occur
2With the exceptions of the methods of (Kozima and
Furugori, 1993; Ide and V?ronis, 1990), both based on
models of activation of lexical relations, but who present
no quantified results.
in the definitions and ?-nodes used for the def-
initions of the sub-senses of the entries. The
graph is created in three phases:
1. For each dictionary entry, there is a ?-
node for the entry as a whole and there is
one ?-node for each of the sub-senses of
the entry. Then an edge is added between
each ?-node and the ?-nodes which rep-
resent the sub-senses of the next lower
level. In other words, the graph includes
a tree of ?-nodes which encodes the hier-
archical structure of each entry.
2. A w-node is created in the graph for each
word occurring in a definition and an edge
is added between the w-node and the ?-
node of that definition.
3. An edge is added between each w-node
and the top ?-node representing the dic-
tionary entry for that word.
For instance, given the entry for "tooth"3:
1. (Anat.) One of the hard, bony appendages
which are borne on the jaws, or on other
bones in the walls of the mouth or pharynx
of most vertebrates, and which usually aid
in the prehension and mastication of food.
2. Fig.: Taste; palate.
These are not dishes for thy dainty tooth.
?Dryden.
3. Any projection corresponding to the tooth
of an animal, in shape, position, or office;
as, the teeth, or cogs, of a cogwheel; a
tooth, prong, or tine, of a fork; a tooth, or
the teeth, of a rake, a saw, a file, a card.
4. (a) A projecting member resembling a
tenon, but fitting into a mortise that
is only sunk, not pierced through.
(b) One of several steps, or offsets, in a
tusk. See Tusk.
We would consider one ?-node for tooth as the
top-level entry, let us call it ?0. ?0 is con-
nected with an edge to the ?-nodes ?1, ?2 ,?3
and ?4 corresponding to the senses 1., 2., 3.
3Source: Webster?s Revised Unabridged Dictionary,
1996. The experiment has actually been done on a
French dictionary, Le Robert.
and 4.; the latter will have an edge towards the
two ?-nodes ?4.1 and ?4.2 for the sub-senses
4.a. and 4.b.; ?4.1 will have an edge to each w-
node built for nouns and verbs occurring in its
definition (member, resemble, tenon, fit, mor-
tise, sink, pierce). Then the w-node for tenon
will have an edge to the ?-node of the top-
level entry of tenon. We do not directly con-
nect ?4.1to the ?-nodes of the top-level entries
because these may have both w- and ?-node
daughters.
In the graph, ?-nodes have tags which indi-
cates their homograph number and their loca-
tion in the hierarchical structure of the entry.
These tags are sequences of integers where the
first one gives the homograph number and the
next ones indicate the rank of the sense-number
at each level. For instance, the previous nodes
?4.1 is tagged (0, 4, 1).
3 Prox, a distance between graph
nodes
We describe here our method (dubbed Prox) to
compute a distance between nodes in the kind
of graph described in the previous section. It is
a stochastic method for the study of so-called
hierarchical small-world graphs (Gaume et al,
2002) (see also the next section). The idea is to
see a graph as a Markov chain whose states are
the graph nodes and whose transitions are its
edges, with equal probabilities. Then we send
random particles walking through this graph,
and their trajectories and the dynamics of their
trajectories reveal their structural properties. In
short, we assume the average distance a parti-
cle has made between two nodes after a given
time is an indication of the semantic distance
between these nodes. Obviously, nodes located
in highly clustered areas will tend to be sepa-
rated by smaller distance.
Formally, if G = (V, E) is an irreflexive
graph with |V | = n, we note [G] the n ? n ad-
jacency matrix of G that is such that [G]i,j (the
ith row and jth column) is 1 if there is an edge
between node i and node j and 0 otherwise.
We note [G?] the Markovian matrix of G, such
that [G?]r,s = [G]r,s?
x?V ([G]r,x)
.
In the case of graphs built from a dictionary
as above,[G?]r,s is 0 if there is no edge between
nodes r and s, and 1/D otherwise, where D
is the number of neighbours of r. This is in-
deed a Markovian transition matrix since the
sum of each line is one (the graph considered
being connected).
We note [G?]i the matrix [G?] multiplied i
times by itself.
Let now PROX(G,i,r,s) be [G?]ir,s. This is thus
the probability that a random particle leaving
node r will be in node s after i time steps. This
is the measure we will use to determine if a
node s is closer to a node r than another node
t. Now we still have to find a proper value for
i. The next section explains the choice we have
made.
4 Dictionaries as hierarchical
small-worlds
Recent work in graph theory has revealed a set
of features shared by many graphs observed
"in the field" These features define the class
of "hierarchical small world" networks (hence-
forth HSW) (Watts and Strogatz, 1998; New-
man, 2003). The relevant features of a graph in
this respect are the following:
D the density of the network. HSWs typically
have a low D, i.e. they have rather few
edges compared to their number of ver-
tices.
L the average shortest path between two nodes.
It is also low in a HSW.
C the clustering rate. This is a measure of how
often neighbours of a vertex are also con-
nected in the graph. In a HSW, this feature
is typically high.
I the distribution of incidence degrees (i.e. the
number of neighbours) of vertices accord-
ing to the frequency of nodes (how many
nodes are there that have an incidence de-
gree of 1, 2, ... n). In a HSW network, this
distribution follows a power law: the prob-
ability P(k) that a given node has k neigh-
bours decreases as k??, with lambda > 0.
It means also that there are very few nodes
with a lot of neighbours, and a lot more
nodes with very few neighbours.
As a mean of comparison, table 1 shows the
differences between randoms graphs (nodes
are given, edges are drawn randomly between
nodes), regular graphs and HSWs.
The graph of a dictionary belongs to the class
of HSW. For instance, on the dictionary we
used, D=7, C=0.183, L=3.3. Table 2 gives a
few characteristics of the graph of nouns only
on the dictionary we used (starred columns in-
dicate values for the maximal self-connected
component).
We also think that the hierarchical aspect of
dictionaries (reflected in the distribution of in-
cidence degrees) is a consequence of the role
of hypernymy associated to the high polysemy
of some entries, while the high clustering rate
define local domains that are useful for dis-
ambiguation. We think these two aspects de-
termine the dynamics of random walks in the
graph as explained above, and we assume they
are what makes our method interesting for
sense disambiguation.
5 Word sense disambiguation
using Prox semantic distance
We will now present a method for disambiguat-
ing dictionary entries using the semantic dis-
tance introduced section (3).
The task can be defined as follows: we con-
sider a word lemma ? occurring in the defini-
tion of one of the senses of a word ?. We want
to tag ? with the most likely sense it has in
this context. Each dictionary entry is coded as
a tree of senses in the graph of the dictionary,
with a number list associated to each sub-entry.
For instance for a given word sense of word W,
listed as sub-sense II.3.1 in the dictionary, we
would record that sense as a node W(2,3,1) in
the graph. In fact, to take homography into ac-
count we had to add another level to this, for
instance W(1,1,2) is sense 1.2 of the first ho-
mograph of word W. In the absence of an ho-
mograph, the first number for a word sense will
conventionally be 0.
Let G=(V,E) the graph of words built as ex-
plained section 2, [G] is the adjacency matrix
of G, and [G?] is the corresponding Markovian
matrix . The following algorithm has then been
applied:
1. Delete all neighbours of ? in G, i.e. make
?x ? V, [G]?,x = [G]x,? = 0
2. Compute the new [G?]i where i is taken to
be 6
(with equal D) L C I
Random graphs small L small C Poisson Law
HSW small L high C power law
Regular graphs high L high C constant
Table 1: Comparing classes of graphs
nb nodes nb edges nb N* nb E* Diam* C* L*
Nouns 53770 392161 51511 392142 7 0.1829 3.3249
Nouns and sub-senses 140080 399969 140026 399941 11 0.0081 5.21
Table 2: Dictionary used
3. Let L be the line ? in the result. ?k, L[k] =
[G?]i?,k
4. Let E = {x1, x2, ..., xn} be the nodes cor-
responding to all the sub-senses induced
by the definition of ?.
Then take xk = argmaxx?E(L[x])
Then xk is the sub-sense with the best rank ac-
cording to the Prox distance.
The following steps needs a little explana-
tion:
1 This neighbours are deleted because other-
wise there is a bias towards the sub-senses
of ?, which then form a sort of "artificial"
cluster with respect to the given task. This
is done to allow the random walk to really
go into the larger network of senses.
2 Choosing a good value for the length of
the random walk through the graph is not
a simple matter. If it is too small, only lo-
cal relations appear (near synonyms, etc)
which might not appear in contexts to dis-
ambiguate (this is the main problem of
Lesk?s method); if it is too large, the dis-
tances between words will converge to a
constant value. So it has to be related in
some way to the average length between
two senses in the graph. A reasonable as-
sumption is therefore to stay close to this
average length. Hence we took i = 6 since
the average length is 5.21 (in the graph
with a node for every sub-sense, the graph
with a node for each entry having L=3.3)
6 Evaluating the results
The following methodology has been followed
to evaluate the process.
We have randomly taken about a hundred
of sub-entries in the chosen dictionary (out
of about 140,000 sub-entries), and have hand-
tagged all nouns and verbs in the entries with
their sub-senses (and homography number), ex-
cept those with only one sense, for a total of
about 350 words to disambiguate. For all pair
of (context,target), the algorithm gives a ranked
list of all the sub-senses of the target. Although
we have used both nouns and verbs to build the
graph of senses, we have tested disambiguation
first on nouns only, for a total of 237 nouns. We
have looked how the algorithm behaves when
we used both nouns and verbs in the graph of
senses.
To compare the human annotation to the au-
tomated one, we have applied the following
measures, where (h1, h2, , ...) is the human tag,
and (s1, s2, ..) is the top-ranked system output
for a context i defined as the entry and the target
word to disambiguate:
1. if h1 = 0 then do nothing else the homo-
graph score is 1 if h1 = s1, 0 otherwise;
2. in all cases, coarse polysemy count = 1 if
h2 = s2, 0 otherwise;
3. in all cases, fine polysemy count = 1 if ?i
hi = si
Thus, the coarse polysemy score computes how
many times the algorithm gives a sub-sense that
has the same "main" sense as the human tag
(the main-sense corresponds to the first level in
the hierarchy of senses as defined above). The
fine polysemy score gives the number of times
the algorithm gives exactly the same sense as
the human.
To give an idea of the difficult of the task,
we have computed the average number of main
entry target system output human tag
correct bal#n._m.*0_3 lieu#n. 1_1_3 1_1_1
correct van#n._m.*2_0_0_0_0 voiture#n. 0_2 0_2_3
error phon?tisme#n._m.*0 moyen#n. 1_1_1 2_1
error cr?ativit?#n._f.*0 pouvoir#n. 2_3 2_1
error acm?#n._m._ou_f.*0_1 phase#n. 0_1 0_4
Table 3: Detailed, main-sense evaluation of a couple of examples.
sub-senses and the number of all senses, for
each target word. This corresponds to a ran-
dom algorithm, choosing between all senses of
a given word. The expected value of this base-
line is thus:
? homograph score=?x 1/(number of ho-
mographs of x)
? coarse polysemy = ?x 1/(number of main
sub-senses of x)
? fine polysemy = ?x 1/(number of all sub-
senses of x)
A second baseline consists in answering al-
ways the first sense of the target word, since
this is often (but not always) the most common
usage of the word. We did not do this for homo-
graphs since the order in which they are given
in the dictionary does not seem to reflect their
importance.
Table 4 sums up the results.
7 Discussion
The result for homographs is very good but not
very significant given the low number of occur-
rences; this all the more true as we used a part-
of-speech tagger to disambiguate homographs
with different part-of-speech beforehand (these
have been left out of the computation of the
score).
The scores we get are rather good for coarse
polysemy, given the simplicity of the method.
As a means of comparison, (Patwardhan et
al., 2003) applies various measures of seman-
tic proximity (due to a number of authors), us-
ing the WordNet hierarchy, to the task of word
sense disambiguation of a few selected words
with results ranging from 0.2 to 0.4 with respect
to sense definition given in WordNet (the aver-
age of senses for each entry giving a random
score of about 0.2).
Our method already gives similar results
on the fine polysemy task (which has an
even harder random baseline) when using both
nouns and verbs as nodes, and does not focus
on selected targets.
A method not evaluated by (Patwardhan et
al., 2003) and using another semantic related-
ness measure ("conceptual density") is (Agirre
and Rigau, 1996). It is also based on a dis-
tance within the WordNet hierarchy. They used
a variable context size for the task and present
results only for the best size (thus being a
not fully unsupervised method). Their random
baseline is around 30%, and their precision is
43% for 80% attempted disambiguations.
Another study of disambiguation using a se-
mantic similarity derived from WordNet is (Ab-
ney and Light, 1999); it sees the task as a Hid-
den Markov Model, whose parameters are es-
timated from corpus data, so this is a mixed
model more than a purely dictionary-based
model. With a baseline of 0.285, they reach a
score of 0.423. Again, the method we used is
much simpler, for comparable or better results.
Besides, by using all connections simultane-
ously between words in the context to disam-
biguate and the rest of the lexicon, this method
avoids the combinatorial explosion of methods
purely based on a similarity measure, where ev-
ery potential sense of every meaningful word
in the context must be considered (unless ev-
ery word sense of words other than the target is
known beforehand, which is not a very realis-
tic assumption), so that only local optimization
can be achieved. In our case disambiguating
a lot of different words appearing in the same
context may result in poorer results than with
only a few words, but it will not take longer.
The only downside is heavy memory usage, as
with any dictionary-based method.
We have made the evaluation on dictionary
entries because they are already part of the net-
random first sense algorithm(n+v)
homographs 0.49 - 0.875 (14/16)
coarse polysemy 0.35 0.493 0.574 (136/237)
fine polysemy 0.18 0.40 0.346 (82/237)
Table 4: Results
work of senses, to avoid raising other issues too
early. Thus, we are not exactly in the context
of disambiguating free text. It could then be
argued that our task is simpler than standard
disambiguation, because dictionary definitions
might just be written in a more constrained and
precise language. That is why we give the score
when taking always the first sense for each en-
try, as an approximation of the most common
sense (since the dictionary does not have fre-
quency information). We can see that this score
is about 50% only for the coarse polysemy, and
40% for the fine polysemy, compared to a typ-
ical 70-80% in usual disambiguation test sets,
for similar sense dispersion (given by the ran-
dom baseline); in (Abney and Light, 1999), the
first-sense baseline gives 82%. So we could
in fact argue that disambiguating dictionary en-
tries seems harder. This fact remains however
to be confirmed with the actual most frequent
senses. Let us point out again that our al-
gorithm does not make use of the number of
senses in definitions.
Among the potential sources of improvement
for the future, or sources of errors in the past,
we can list at least the following:
? overlapping of some definitions for sub-
senses of an entry. Some entries of the
dictionary we used have sub-senses that
are very hard to distinguish. In order to
measure the impact of this, we should have
multiple annotations of the same data and
measure inter-annotator agreement, some-
thing that has not been done yet.
? part of speech tagging generates a few er-
rors when confusing adjectives and nouns
or adjectives and verbs having the same
lemma; this should be compensated when
we enrich the graph with entries for adjec-
tives.
? some time should be spent studying the
precise influence of the length of the ran-
dom walk considered; we have chosen a
value a priori to take into account the aver-
age length of a path in the graph, but once
we have more hand-tagged data we should
be able to have a better idea of the best
suited value for that parameter.
8 Conclusion
We have presented here an algorithm giving a
measure of lexical similarity, built from infor-
mation found in a dictionary. This has been
used to disambiguate dictionary entries, with a
method that needs no other source of informa-
tion (except part-of-speech tagging), no anno-
tated data. The coverage of the method depends
only on the lexical coverage of the dictionary
used. It seems to give promising results on dis-
ambiguating nouns, using only nouns or nouns
and verbs. We intend to try the method after
enriching the network of senses with adjectives
and/or adverbs. We also intend, of course, to try
the method on disambiguating verbs and adjec-
tives.
Moreover, the method can be rather straight-
forwardly extended to any type of disambigua-
tion by considering a context with a target
word as a node added in the graph of senses
(a kind of virtual definition). We have not
tested this idea yet. Since our method gives a
ranked list of sense candidates, we also con-
sider using finer performance measures, taking
into account confidence degrees, as proposed in
(Resnik and Yarowsky, 2000).
References
Steven Abney and Marc Light. 1999. Hiding
a semantic hierarchy in a markov model. In
ACL?99 Workshop Unsupervised Learning in
Natural Language Processing, University of
Maryland.
E. Agirre and G. Rigau. 1996. Word sense
disambiguation using conceptual density. In
Proceedings of COLING?96, pages 16?22,
Copenhagen (Denmark).
S. Banerjee and T. Pedersen. 2003. Extended
gloss overlaps as a measure of semantic re-
latedness. In Proceedings of the Eighteenth
International Conference on Artificial Intel-
ligence (IJCAI-03), Acapulco, Mexico.
B. Gaume, K. Duvignau, O. Gasquet, and M.-
D. Gineste. 2002. Forms of meaning, mean-
ing of forms. Journal of Experimental and
Theoretical Artificial Intelligence, 14(1):61?
74.
N. Ide and J. V?ronis. 1998. Introduction to
the special issue on word sense disambigua-
tion: The state of the art. Computational
Linguistics, 24(1).
N. Ide and J. V?ronis. 1990. Word sense dis-
ambiguation with very large neural networks
extracted from machine readable dictionar-
ies. In Proceedings of the 14th International
Conference on Computational Linguistics
(COLING?90), volume 2, pages 389?394.
H. Kozima and T. Furugori. 1993. Similarity
between words computed by spreading acti-
vation on an english dictionary. In Proceed-
ings of the conference of the European chap-
ter of the ACL, pages 232?239.
M. Lesk. 1986. Automatic sense disambigua-
tion using machine readable dictionaries:
how to tell a pine code from an ice cream
cone. In Proceedings of the 5th annual in-
ternational conference on Systems documen-
tation, pages 24?26, Toronto, Canada.
C. Manning and H. Sch?tze. 1999. Founda-
tions of Statistical Natural Language Pro-
cessing. MIT Press.
M. E. J. Newman. 2003. The structure and
function of complex networks. SIAM Re-
view, 45:167?256.
S. Patwardhan, S. Banerjee, and T. Pedersen.
2003. Using measures of semantic related-
ness for word sense disambiguation. In Pro-
ceedings of the Fourth International Confer-
ence on Intelligent Text Processing and Com-
putational Linguistics (CICLING-03).
P. Resnik and D. Yarowsky. 2000. Distinguish-
ing systems and distinguishing senses: New
evaluation methods for word sense disam-
biguation. Natural Language Engineering,
5(2):113?133.
D.J. Watts and S.H Strogatz. 1998. Collective
dynamics of ?small-world? networks. Na-
ture, (393):440?442.
Workshop on TextGraphs, at HLT-NAACL 2006, pages 65?72,
New York City, June 2006. c?2006 Association for Computational Linguistics
Synonym Extraction Using a Semantic Distance on a Dictionary
Philippe Muller
IRIT ? CNRS, UPS & INPT
Toulouse, France
muller@irit.fr
Nabil Hathout
ERSS ? CNRS & UTM
Toulouse, France
hathout@univ-tlse2.fr
Bruno Gaume
IRIT ? CNRS, UPS & INPT
Toulouse, France
gaume@irit.fr
Abstract
Synonyms extraction is a difficult task to
achieve and evaluate. Some studies have
tried to exploit general dictionaries for
that purpose, seeing them as graphs where
words are related by the definition they ap-
pear in, in a complex network of an ar-
guably semantic nature. The advantage
of using a general dictionary lies in the
coverage, and the availability of such re-
sources, in general and also in specialised
domains. We present here a method ex-
ploiting such a graph structure to compute
a distance between words. This distance
is used to isolate candidate synonyms for
a given word. We present an evaluation of
the relevance of the candidates on a sam-
ple of the lexicon.
1 Introduction
Thesaurus are an important resource in many natural
language processing tasks. They are used to help in-
formation retrieval (Zukerman et al, 2003), machine
or semi-automated translation, (Ploux and Ji, 2003;
Barzilay and McKeown, 2001; Edmonds and Hirst,
2002) or generation (Langkilde and Knight, 1998).
Since the gathering of such lexical information is a
delicate and time-consuming endeavour, some effort
has been devoted to the automatic building of sets of
synonyms words or expressions.
Synonym extraction suffers from a variety of
methodological problems, however. Synonymy it-
self is not an easily definable notion. Totally equiv-
alent words (in meaning and use) arguably do not
exist, and some people prefer to talk about near-
synonyms (Edmonds and Hirst, 2002). A near-
synonym is a word that can be used instead of
another one, in some contexts, without too much
change in meaning. This leaves of lot of freedom
in the degree of synonymy one is ready to accept.
Other authors include ?related? terms in the build-
ing of thesaurus, such as hyponyms and hypernyms,
(Blondel et al, 2004) in a somewhat arbitrary way.
More generally, paraphrase is a preferred term re-
ferring to alternative formulations of words or ex-
pressions, in the context of information retrieval or
machine translation.
Then there is the question of evaluating the results.
Comparing to already existing thesaurus is a de-
batable means when automatic construction is sup-
posed to complement an existing one, or when a spe-
cific domain is targeted, or when simply the auto-
matic procedure is supposed to fill a void. Manual
verification of a sample of synonyms extracted is a
common practice, either by the authors of a study
or by independent lexicographers. This of course
does not solve problems related to the definition of
synonymy in the ?manual? design of a thesaurus,
but can help evaluate the relevance of synonyms ex-
tracted automatically, and which could have been
forgotten. One can hope at best for a semi-automatic
procedure were lexicographers have to weed out bad
candidates in a set of proposals that is hopefully not
too noisy.
A few studies have tried to use the lexical informa-
tion available in a general dictionary and find pat-
terns that would indicate synonymy relations (Blon-
65
del et al, 2004; Ho and C?drick, 2004). The general
idea is that words are related by the definition they
appear in, in a complex network that must be seman-
tic in nature (this has been also applied to word sense
disambiguation, albeit with limited success (Veronis
and Ide, 1990; H.Kozima and Furugori, 1993)).
We present here a method exploiting the graph struc-
ture of a dictionary, where words are related by the
definition they appear in, to compute a distance be-
tween words. This distance is used to isolate can-
didate synonyms for a given word. We present an
evaluation of the relevance of the candidates on a
sample of the lexicon.
2 Semantic distance on a dictionary graph
We describe here our method (dubbed Prox) to com-
pute a distance between nodes in a graph. Basi-
cally, nodes are derived from entries in the dictio-
nary or words appearing in definitions, and there are
edges between an entry and the word in its definition
(more in section 3). Such graphs are "small world"
networks with distinguishing features and we hypo-
thetize these features reflect a linguistic and seman-
tic organisation that can be exploited (Gaume et al,
2005).
The idea is to see a graph as a Markov chain whose
states are the graph nodes and whose transitions are
its edges, valuated with probabilities. Then we send
random particles walking through this graph, and
their trajectories and the dynamics of their trajec-
tories reveal their structural properties. In short, we
assume the average distance a particle has made be-
tween two nodes after a given time is an indication
of the semantic distance between these nodes. Ob-
viously, nodes located in highly clustered areas will
tend to be separated by smaller distance.
Formally, if G = (V,E) is a reflexive graph (each
node is connected to itself) with |V | = n, we note
[G] the n ? n adjacency matrix of G that is such
that [G]i,j (the ith row and jth column) is non null
if there is an edge between node i and node j and
0 otherwise. We can have different weights for
the edge between nodes (cf. next section), but the
method will be similar.
The first step is to turn the matrix into a Markovian
matrix. We note [G?] the Markovian matrix of G,
such that
[G?]r,s =
[G]r,s
?
x?V ([G]r,x)
The sum of each line of G is different from 0 since
the graph is reflexive.
We note [G?]i the matrix [G?] multiplied i times by it-
self.
Let now PROX(G, i, r, s) be [G?]ir,s. This is thus
the probability that a random particle leaving node r
will be in node s after i time steps. This is the mea-
sure we will use to determine if a node s is closer
to a node r than another node t. The choice for i
will depend on the graph and is explained later (cf.
section 4).
3 Synonym extraction
We used for the experiment the XML tagged MRD
Tr?sor de la Langue Fran?aise informatis? (TLFi)
from ATILF (http://atilf.atilf.fr/), a
large French dictionary with 54,280 articles, 92,997
entries and 271,166 definitions. The extraction of
synonyms has been carried out only for nouns, verbs
and adjectives. The basic assumption is that words
with semantically close definitions are likely to be
synonyms. We then designed a oriented graph
that brings closer definitions that contain the same
words, especially when these words occur in the be-
ginning. We selected the noun, verb and adjective
definitions from the dictionary and created a record
for each of them with the information relevant to
the building of the graph: the word or expression
being defined (henceforth, definiendum); its gram-
matical category; the hierarchical position of the de-
fined (sub-)sense in the article; the definition proper
(henceforth definiens).
Definitions are made of 2 members: a definiendum
and a definiens and we strongly distinguish these 2
types of objects in the graph. They are represented
by 2 types of nodes: a-type nodes for the words be-
ing defined and for their sub-senses; o-type nodes
for the words that occur in definiens.
For instance, the noun nostalgie ?nostalgia? has 6 de-
fined sub-senses numbered A.1, A.2, B., C., C. ? and
D.:
66
NOSTALGIE, subst. f?m.
A. 1. ?tat de tristesse [...]
2. Trouble psychique [...]
B. Regret m?lancolique [...] d?sir d?un retour dans
le pass?.
C. Regret m?lancolique [...] d?sir insatisfait.
? Sentiment d?impuissance [...]
D. ?tat de m?lancolie [...]
The 6 sub-senses yield 6 a-nodes in the graph plus
one for the article entry:
a.S.nostalgie article entry
a.S.nostalgie.1_1 sub-sense A. 1.
a.S.nostalgie.1_2 sub-sense A. 2.
a.S.nostalgie.2 sub-sense B.
a.S.nostalgie.3 sub-sense C.
a.S.nostalgie.3_1 sub-sense C. ?
a.S.nostalgie.4 sub-sense D.
A-node tags have 4 fields: the node type (namely a);
its grammatical category (S for nouns, V for verbs
and A for adjectives); the lemma that correponds to
the definiendum; a representation of the hierarchi-
cal position of the sub-sense in the dictionary arti-
cle. For instance, the A. 2. sub-sense of nostalgie
corresponds to the hierarchical position 1_2.
O-nodes represent the types that occur in definiens.1
A second example can be used to present them. The
adjective jonceux ?rushy? has two sub-senses ?re-
sembling rushes? and ?populated with rushes?:
Jonceux, -euse,
a) Qui ressemble au jonc.
b) Peupl? de joncs.
Actually, TLFi definitions are POS-tagged and lem-
matized:
Jonceux/S
a) qui/Pro ressembler/V au/D jonc/S ./X
b) peupl?/A de/Prep jonc/S ./X 2
The 2 definiens yield the following o-type nodes in
the graph:
o.Pro.qui; o.V.ressembler; o.D.au;
o.S.jonc; o.X..; o.A.peupl?; o.Prep.de
1The tokens are represented by edges.
2In this sentence, peupl? is an adjective and not a verb.
All the types that occur in definiens are represented,
including the function words (pronouns, deter-
miners...) and the punctuation. Function words
play an important role in the graph because they
bring closer the words that belong to the same
semantical referential classes (e.g. the adjectives
of resemblance), that is words that are likely to
be synonyms. Their role is also reinforced by the
manner edges are weighted.
A large number of TLFi definitions concerns
phrases and locutions. However, these definitions
have been removed from the graph because:
? their tokens are not identified in the definiens;
? their grammatical categories are not given in
the articles and are difficult to calculate;
? many lexicalized phrases are not sub-senses of
the article entry.
O-node tags have 3 fields: the node type (namely o);
the grammatical category of the word; its lemma.
The oriented graph built for the experiment then
contains one a-node for each entry and each entry
sub-sense (i.e. each definiendum) and one o-node
for each type that occurs in a definition (i.e. in a
definiens). These nodes are connected as follows:
1. The graph is reflexive;
2. Sub-senses are connected to the words of their
definiens and vice versa (e.g. there is an edge
between a.A.jonceux.1 and o.Pro.qui,
and another one between o.Pro.qui and
a.A.jonceux.1).
3. Each a-node is connected to the a-nodes
of the immediately lower hierarchical
level but there is no edge between an
a-node and the a-nodes of higher hier-
archical levels (e.g. a.S.nostalgie
is connected to a.S.nostalgie.1_1,
a.S.nostalgie.1_2,
a.S.nostalgie.2, a.S.nostalgie.3
and a.S.nostalgie.4, but none of the
sub-senses is connected to the entry).
67
4. Each o-node is connected to the a-node that
represents its entry, but there is no edge be-
tween the a-node representing an entry and the
corresponding o-node (e.g. there is an edge be-
tween o.A.jonceux and a.A.jonceux,
but none between a.A.jonceux and
o.A.jonceux).
All edge weights are 1 with the exception of
the edges representing the 9 first words of each
definiens. For these words, the edge weight takes
into account their position in the definiens. The
weight of the edge that represent the first token is
10; it is 9 for the second word; and so on down to
1.3
These characteristics are illustrated by the fragment
of the graph representing the entry jonceux in table
1.
4 Experiment and results
Once the graph built, we used Prox to compute a se-
mantic similarity between the nodes. We first turned
the matrix G that represent the graph into a Marko-
vian matrix [G?] as described in section 2 and then
computed [G?]5, that correspond to 5-steps paths in
the Markovian graph.4 For a given word, we have
extracted as candidate synonyms the a-nodes (i) of
the same category as the word (ii) that are the clos-
est to the o-node representing that word in the dictio-
nary definitions. Moreover, only the first a-node of
each entry is considered. For instance, the candidate
synonyms of the verb accumuler ?accumulate? are
the a-nodes representing verbs (i.e. their tags begin
in a.V) that are the closer to the o.V.accumuler
node.
5-steps paths starting from an o-node representing a
word w reach six groups of a-nodes:
A1 the a-nodes of the sub-senses which have w in
their definition;
3Lexicographic definitions usually have two parts: a genus
and a differentia. This edge weight is intended to favour the
genus part of the definiens.
4The path length has been determined empirically.
A2 the a-nodes of the sub-senses with definiens
containing the same words as those of A1;
A3 the a-nodes of the sub-senses with definiens
containing the same words as those of A2;
B1 the a-nodes of the sub-senses of the article of w.
(These dummy candidates are not kept.)
B2 the a-nodes of the sub-senses with definiens
containing the same words as those of B1;
B3 the a-nodes of the sub-senses with definiens
containing the same words as those of B2;
The three first groups take advantage of the fact
that synonyms of the definiendum are often used in
definiens.
The question of the evaluation of the extraction of
synonyms is a difficult one, as was already men-
tioned in the introduction. We have at our disposal
several thesauri for French, with various coverages
(from about 2000 pairs of synonyms, to 140,000),
and a lot of discrepancies.5 If we compare the the-
saurus with each other and restrict the comparison
to their common lexicon for fairness, we still have
a lot of differences. The best f-score is never above
60%, and it raises the question of the proper gold
standard to begin with. This is all the more distress-
ing as the dictionary we used has a larger lexicon
than all the thesaurus considered together (roughly
twice as much). As our main purpose is to build a set
of synonyms from the TLF to go beyond the avail-
able thesaurus, we have no other way but to have
lexicographers look at the result and judge the qual-
ity of candidate synonyms. Before imposing this
workload on our lexicographer colleagues, we took
a sample of 50 verbs and 50 nouns, and evaluated
the first ten candidates for each, using the ranking
method presented above, and a simpler version with
equal weights and no distinction between sense lev-
els or node types. The basic version of the graph
also excludes nodes with too many neighbours, such
as "?tre" (be), "avoir" (have), "chose" (thing), etc. ).
Two of the authors separately evaluated the candi-
dates, with the synonyms from the existing thesauri
5These seven classical dictionaries of synonyms are all
available from http://www.crisco.unicaen.fr/dicosyn.html.
68
o
.A
.jo
nc
eu
x
a.
A
.jo
nc
eu
x
a.
A
.jo
nc
eu
x.1
a.
A
.jo
nc
eu
x.2
o
.P
ro
.q
ui
o
.V
.
re
ss
em
bl
er
o
.D
.a
u
o
.S
.jo
nc
o
.X
..
o
.A
.p
eu
pl
?
o
.P
re
p.
de
o.A.jonceux 1 1
a.A.jonceux 1 1 1
a.A.jonceux.1 1 1 1 1 1 1
a.A.jonceux.2 1 1 1 1 1
o.Pro.qui 10 1
o.V.ressembler 9 1
o.D.au 8 1
o.S.jonc 7 8 1
o.X.. 6 7 1
o.A.peupl? 10 1
o.Prep.de 9 1
Table 1: A fragment of the graph, presented as a matrix.
already marked. It turned out one of the judge was
much more liberal than the other about synonymy,
but most synonyms accepted by the first were ac-
cepted by the second judge (precision of 0.85).6
We also considered a few baselines inspired by the
method. Obviously a lot of synonyms appear in the
definition of a word, and words in a definition tend
to be consider close to the entry they appear in. So
we tried two different baselines to estimate this bias,
and how our method improves or not from this.
The first baseline considers as synonyms of a word
all the words of the same category (verbs or nouns
in each case) that appear in a definition of the word,
and all the entry the word appear in. Then we se-
lected ten words at random among this base.
The second baseline was similar, but restricted to the
first word appearing in a definition of another word.
Again we took ten words at random in this set if it
was larger than ten, and all of them otherwise.
We show the results of precision for the first can-
didate ranked by prox, the first 5, and the first 10
(always excluding the word itself). In the case of
the two baselines, results for the first ten are a bit
6The kappa score between the two annotators was 0.5 for
both verbs and nouns, which only moderately satisfactory.
misleading, since the average numbers of candidates
proposed by these methods were respectively 8 and
6 for verbs and 9 and 5.6 for nouns (Table 2). Also,
nouns had an average of 5.8 synonyms in the exist-
ing thesauri (when what was considered was the min
between 10 and the number of synonyms), and verbs
had an average of 8.9.
We can see that both baselines outperforms
weighted prox on the existing thesaurus for verbs,
and that the simpler prox is similar to baseline 2 (first
word only). For nouns, results are close between B2
and the two proxs. It is to be noted that a lot of
uncommon words appear as candidates, as they are
related with very few words, and a lot of these do
not appear in the existing thesauri.
By looking precisely at each candidate (see judges?
scores), we can see that both baselines are slightly
improved (and still close to one another), but are
now beaten by both prox for the first and the first
5 words. There is a big difference between the two
judges, so Judge 2 has better scores than Judge 1 for
the baselines, but in each case, prox was better. It
could be troubling to see how good the second base-
line is for the first 10 candidates, but one must re-
member this baseline actually proposes 6 candidates
on average (when prox was always at 10), making
it actually nothing more than a variation on the 5
69
Existing Thesauri (V) Judge 1 Judge 2 ET (N) J1 J2
baseline-1 1 0.30 0.42 0.38 0.06 0.12 0.12
5 0.29 0.39 0.375 0.08 0.12 0.13
10 0.31 0.41 0.39 0.10 0.14 0.15
baseline-2 1 0.32 0.52 0.44 0.21 0.22 0.23
5 0.36 0.50 0.446 0.21 0.24 0.25
10 0.28 0.51 0.46 0.19 0.245 0.255
simple prox 1 0.35 0.67 NA 0.27 0.415 0.417
5 0.34 0.52 NA 0.137 0.215 0.237
10 0.247 0.375 NA 0.123 0.17 0.19
weighted prox 1 0.22 0.56 0.76 0.18 0.44 0.5
5 0.196 0.44 0.58 0.148 0.31 0.39
10 0.17 0.36 0.47 0.10 0.22 0.3
Table 2: Experimental results on a sample, V=verbs, N=nouns,
candidate baseline, to which it should be compared
in all fairness (and we see that prox is much better
there). The difference between the two versions of
prox shows that a basic version is better for verbs
and the more elaborate one is better for nouns, with
overall better results for verbs than for nouns.
One could wonder why there was some many more
candidates marked as synonyms by both judges,
compared to the original compilation of thesaurus.
Mainly, it seemed to us that it can be accounted for
by a lot of infrequent words, or old senses of words
absent for more restricted dictionaries. We are cur-
rently investigating this matter. It could also be that
our sample picked out a lot of not so frequent words
since they outnumber frequent words in such a large
dictionary as the TLF. An indication is the average
frequency of words in a corpus of ten years of the
journal "Le Monde". The 50 words picked out in
our sample have an average frequency of 2000 oc-
currences, while when we consider all our about 430
candidates for synonymy, the average frequency is
5300.
The main conclusion to draw here is that our method
is able to recover a lot of synonyms that are in the
definition of words, and some in definitions not di-
rectly related, which seems to be an improvement on
previous attempts from dictionaries. There is some
arbitrariness in the method that should be further
investigated (the length of the random walk for in-
stance), but we believe the parameters are rather in-
tuitive wrt to graph concepts. We also have an as-
sessment of the quality of the method, even though
it is still on a sample. The precision seems fair on
the first ten candidates, enough to be used in a semi-
automatic way, coupled with a lexicographic analy-
sis.
5 Related work
Among the methods proposed to collect synonymy
information, two families can be distinguished ac-
cording to the input they consider. Either a gen-
eral dictionary is used (or more than one (Wu and
Zhou, 2003)), or a corpus of unconstrained texts
from which lexical distributions are computed (sim-
ple collocations or syntactic dependencies) (Lin,
1998; Freitag et al, 2005) . The approach of (Barzi-
lay and McKeown, 2001) uses a related kind of re-
source: multiple translations of the same text, with
additional constraints on availability, and problems
of text alignment, for only a third of the results be-
ing synonyms (when compared to Wordnet).
A measure of similarity is almost always used to
rank possible candidates. In the case of distribu-
tional approaches, similarity if determined from the
appearance in similar contexts (Lin, 1998); in the
case of dictionary-based methods, lexical relations
are deduced from the links between words expressed
in definitions of entries.
Approaches that rely on distributional data have two
major drawbacks: they need a lot of data, gener-
ally syntactically parsed sentences, that is not al-
ways available for a given language (English is an
exception), and they do not discriminate well among
lexical relations (mainly hyponyms, antonyms, hy-
pernyms) (Weeds et al, 2004) . Dictionary-based
70
approaches address the first problem since dictionar-
ies are readily available for a lot of language, even
electronically, and this is the raison d??tre of our ef-
fort. As we have seen here, it is not an obvious task
to sort related terms with respect to synonymy, hy-
pernymy, etc, just as with distribution approaches.
A lot of work has been done to extract lexical rela-
tions from the definitions taken in isolation (mostly
for ontology building), see recently (Nichols et al,
2005), with a syntactic/semantic parse, with usually
results around 60% of precision (that can be com-
pared with the same baseline we used, all words in
the definition with the same category), on dictionar-
ies with very small definitions (and thus a higher
proportions of synonyms and hypernyms). Estimat-
ing the recall of such methods have not been done.
Using dictionaries as network of lexical items or
senses has been quite popular for word sense dis-
ambiguation (Veronis and Ide, 1990; H.Kozima and
Furugori, 1993; Niwa and Nitta, 1994) before los-
ing ground to statistical approaches, even though
(Gaume et al, 2004; Mihalcea et al, 2004) tried a re-
vival of such methods. Both (Ho and C?drick, 2004)
and (Blondel et al, 2004) build a graph of lexical
items from a dictionary in a manner similar to ours.
In the first case, the method used to compute similar-
ity between two concepts (or words) is restricted to
neighbors, in the graph, of the two concepts; in the
second case, only directly related words are consid-
ered as potential candidates for synonymy: for two
words to be considered synonyms, one has to appear
in the definition of another. In both cases, only 6
or 7 words have been used as a test of synonymy,
with a validation provided by the authors with "re-
lated terms" (an unclear notion) considered correct.
The similarity measure itself was evaluated on a set
of related terms from (Miller and Charles, 1991), as
in (Budanitsky and Hirst, 2001; Banerjee and Ped-
ersen, 2003), with seemingly good results, but se-
mantically related terms is a very different notion
("car" and "tire" for instance are semantically related
terms, and thus considered similar).
We do not know of any dictionary-based graph ap-
proach which have been given a larger evaluation of
its results. Parsing definitions in isolation prevents a
complete coverage (we estimated that only 30% of
synonyms pairs in the TLF can be found from defi-
nitions).
As for distributional approaches, (Barzilay and
McKeown, 2001) gets a very high precision (around
90%) on valid paraphrases as judged by humans,
among which 35% are synonymy relations in Word-
net, 32% are hypernyms, 18% are coordinate terms.
Discriminating among the paraphrases types is not
addressed. Other approaches usually consider either
given sets of synonyms among which one is to be
chosen (for a translation for instance) (Edmonds and
Hirst, 2002) or must choose a synonym word against
unrelated terms in the context of a synonymy test
(Freitag et al, 2005), a seemingly easier task than
actually proposing synonyms. (Lin, 1998) proposes
a different methodology for evaluation of candidate
synonyms, by comparing similarity measures of the
terms he provides with the similarity measures be-
tween them in Wordnet, using various semantic dis-
tances. This makes for very complex evaluation pro-
cedures without an intuitive interpretation, and there
is no assessment of the quality of the automated the-
saurus.
6 Conclusion
We have developed a general method to extract near-
synonyms from a dictionary, improving on the two
baselines. There is some arbitrariness in the param-
eters we used, but we believe the parameters are
rather intuitive wrt to graph concepts.7 There is
room for improvement obviously, also for a combi-
nation with other methods to filter synonyms (with
frequency estimates for instance, such as tf.idf or
mutual information measures).
Clearly the advantage of using a dictionary is re-
tained: there is no restriction of coverage, and we
could have used a specialised dictionary to build a
specialised thesaurus. We have provided an assess-
ment of the quality of the results, although there
is not much to compare it to (to the best of our
knowledge), since previous accounts only had cur-
sory evaluation.
7The lexical graph can be explored at http://prox.irit.fr.
71
Acknowledgments
This research has been supported by the CNRS pro-
gram TCAN 04N85/0025. We sincerely thank the
ATILF laboratory and Pr. Jean-Marie Pierrel for
the opportunity they gave us to use the Tr?sor de la
Langue Fran?aise informatis?. We would also like
to thank Jean-Marc Destabeaux for his crucial help
in extracting the definitions from the TLFi.
References
S. Banerjee and T. Pedersen. 2003. Extended gloss over-
laps as a measure of semantic relatedness. In Proceed-
ings of IJCAI-03, Acapulco, Mexico.
Regina Barzilay and Kathleen R. McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Proceed-
ings of the 39th ACL, pages 00?00, Toulouse.
Vincent D. Blondel, Anah? Gajardo, Maureen Heymans,
Pierre Senellart, and Paul Van Dooren. 2004. A mea-
sure of similarity between graph vertices: Applications
to synonym extraction and web searching. SIAM Review,
46(4):647?666.
A. Budanitsky and G. Hirst. 2001. Semantic distance
in wordnet: An experimental, application-oriented eval-
uation of five measures. In Workshop on WordNet and
Other Lexical Resources, NAACL 2001, Pittsburgh.
Philip Edmonds and Graeme Hirst. 2002. Near-
Synonymy and lexical choice. Computational Linguis-
tics, 28(2):105?144.
Dayne Freitag, Matthias Blume, John Byrnes, Edmond
Chow, Sadik Kapadia, Richard Rohwer, and Zhiqiang
Wang. 2005. New experiments in distributional repre-
sentations of synonymy. In Proceedings of CoNLL, pages
25?32, Ann Arbor, Michigan, June. Association for Com-
putational Linguistics.
B. Gaume, N. Hathout, and P. Muller. 2004. Word
sense disambiguation using a dictionary for sense similar-
ity measure. In Proceedings of Coling 2004, volume II,
pages 1194?1200, Gen?ve.
B. Gaume, F. Venant, and B. Victorri. 2005. Hierarchy
in lexical organization of natural language. In D. Pumain,
editor, Hierarchy in natural and social sciences, Metho-
dos series, pages 121?143. Kluwer.
H.Kozima and T. Furugori. 1993. Similarity between
words computed by spreading activation on an english
dictionary. In Proceedings of the EACL, pages 232?239.
Ngoc-Diep Ho and Fairon C?drick. 2004. Lexical simi-
larity based on quantity of information exchanged - syn-
onym extraction. In Proc. of Intl. Conf. RIVF?04, Hanoi.
Irene Langkilde and Kevin Knight. 1998. Generation
that exploits corpus-based statistical knowledge. In Pro-
ceedings of COLING-ACL ?98, volume 1, pages 704?
710, Montreal.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of COLING-ACL ?98,
volume 2, pages 768?774, Montreal.
Rada Mihalcea, Paul Tarau, and Elizabeth Figa. 2004.
PageRank on semantic networks, with application to
word sense disambiguation. In Proceedings of Coling
2004, Geneva.
GA Miller and WG Charles. 1991. Contextual corre-
lates of semantic similarity. Language and Cognitive
Processes, 6(1):1?28.
Eric Nichols, Francis Bond, and Daniel Flickinger. 2005.
Robust ontology acquisition from machine-readable dic-
tionaries. In Proceedings of IJCAI?05.
Yoshiki Niwa and Yoshihiko Nitta. 1994. Co-occurrence
vectors from corpora vs. distance vectors from dictionar-
ies. In Proceedings of Coling 1994.
Sabine Ploux and Hyungsuk Ji. 2003. A
model for matching semantic maps between languages
(French/English, English/French). Computational Lin-
guistics, 29(2):155?178.
J. Veronis and N.M. Ide. 1990. Word sense disambigua-
tion with very large neural networks extracted from ma-
chine readable dictionaries. In COLING-90: Proceed-
ings of the 13th International Conference on Computa-
tional Linguistics, volume 2, pages 389?394, Helsinki,
Finland.
Julie Weeds, David Weir, and Diana McCarthy. 2004.
Characterising measures of lexical distributional similar-
ity. In Proceedings of Coling 2004, pages 1015?1021,
Geneva, Switzerland, Aug 23?Aug 27. COLING.
Hua Wu and Ming Zhou. 2003. Optimizing synonyms
extraction with mono and bilingual resources. In Pro-
ceedings of the Second International Workshop on Para-
phrasing, Sapporo, Japan. Association for Computational
Linguistics.
Ingrid Zukerman, Sarah George, and Yingying Wen.
2003. Lexical paraphrasing for document retrieval and
node identification. In Proceedings of the Second Inter-
national Workshop on Paraphrasing, Sapporo, Japan. As-
sociation for Computational Linguistics.
72
Coling 2008: Proceedings of 3rd Textgraphs workshop on Graph-Based Algorithms in Natural Language Processing, pages 1?8
Manchester, August 2008
Acquistion of the morphological structure of the lexicon
based on lexical similarity and formal analogy
Nabil Hathout
Universit? de Toulouse
Nabil.Hathout@univ-tlse2.fr
Abstract
The paper presents a computational model
aiming at making the morphological struc-
ture of the lexicon emerge from the for-
mal and semantic regularities of the words
it contains. The model is purely lexeme-
based. The proposed morphological struc-
ture consists of (1) binary relations that
connect each headword with words that
are morphologically related, and especially
with the members of its morphological
family and its derivational series, and of
(2) the analogies that hold between the
words. The model has been tested on the
lexicon of French using the TLFi machine
readable dictionary.
1 Lexeme-based morphology
Morphology is traditionally considered to be the
field of linguistics that studies the structure of
words. In this conception, words are made of
morphemes which combine according to rules
of inflexion, derivation and composition. If the
morpheme-based theoretical framework is both el-
egant and easy to implement, it suffers many draw-
backs pointed out by several authors (Anderson,
1992; Aronoff, 1994). The alternative theoreti-
cal models that have been proposed falls within
lexeme-based or word-based morphology in which
the minimal units are words instead of morphemes.
Words then do not have any structure at all and
morphology becomes a level of organization of the
lexicon based on the sharing of semantic and for-
mal properties.
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
The morpheme-based / lexeme-based distinc-
tion shows up on the computational level. In
the morpheme-based conception, the morpholog-
ical analysis of a word aims at segmenting it into
a sequence of morphemes (D?jean, 1998; Gold-
smith, 2001; Creutz and Lagus, 2002; Bernhard,
2006). In a lexeme-based approach, it is to dis-
cover the relations between the word and the other
lexical items. These relations serve to identify
the morphological family of the word, its deriva-
tional series, and the analogies in which it is in-
volved. For instance, the analysis of the French
word d?rivation may be considered as satisfac-
tory if it connects d?rivation with enough mem-
bers of its family (d?river ?derivate?, d?rivationnel
?derivational?, d?rivable, d?rive ?drift?, d?riveur
?sailing dinghy?, etc.) and of its derivational
series (formation ?education?, s?duction, varia-
tion, ?mission, etc.). Each of these relations
is integrated into a large collection of analogies
that characterizes it semantically and formally.
For instance, the relation between d?rivation and
d?rivable is part of a series of analogies which
includes d?rivation:d?rivable::variation:variable,
d?rivation:d?rivable::modification:modifiable, etc.
Similarly, d?rivation and variation participates in
a series of analogies such as d?rivation:varia-
tion::d?river:varier, d?rivation:variation::d?riva-
tionnel:variationnel, d?rivation:variation::d?riva-
ble:variable.
2 Computational modeling
The paper describes a computational model aiming
at making the morphological derivational structure
of the lexicon emerge from the semantic and the
formal regularities of the words it contains. A first
experiment is currently underway on the lexicon
of French using the TLFi machine readable dictio-
1
nary.
1
The main novelty of the paper is the com-
bination of lexical proximity with formal analogy.
We first use lexical similarity in order to select a
set of words that are likely to be morphologically
related to each other. Then, these candidates are
checked by means of analogy.
The two techniques are complementary. The
first one brings closer the words that are morpho-
logically close and especially the ones that are
members of the same morphological families and
the same derivational series. It is able to deal with
large number of words, but it is too coarse-grained
to discriminate the words that are actually mor-
phological related from the ones that are not. The
second technique, formal analogy, is then used to
perform a fine-grained filtering. Technically, our
model joins:
1. the representation of the lexicon as a graph
and its exploration through random walks,
along the line of (Gaume et al, 2002; Gaume
et al, 2005; Muller et al, 2006), and
2. formal analogies on words (Lepage, 1998;
Stroppa and Yvon, 2005). This approach does
do not make use of morphemes. Correspon-
dence between words is calculated directly on
their graphemic representations.
More generally, our approach is original in that:
1. Our computational model is pure lexeme-
based. The discovery of morphological rela-
tions between words do not involve the no-
tions of morpheme, affix, morphological ex-
ponent, etc. nor any representation of these
concepts.
2. The membership to the families and series is
gradient. It accounts, for instance, for the fact
that d?riveur is morphologically and semanti-
cally closer to d?rive than to d?rivationnelle-
ment, even if the three words belong to the
same family. The model connects the words
that share semantic and / or formal features.
The more features are shared, the closer the
words are.
Besides, the model integrates semantic and for-
mal informations in a uniform manner. All kind
of semantic informations (lexicographic defini-
tions, synonyms, synsets, etc.) and formal ones
1
Tr?sor de la Langue Fran?aise (http://atilf.atilf.fr/).
(graphemic, phonological, etc.) can be used. They
can be cumulated easily in spite of the differences
in nature and origin. The model takes advantage of
the redundancy of the features and is fairly insen-
sitive to variation and exceptions.
3 Related work
Many works in the field of computational mor-
phology aim at the discovery of relations be-
tween lexical units. All of them rely primarily on
finding similarities between the word graphemic
forms. These relations are mainly prefixal or suf-
fixal with two exceptions, (Yarowsky and Wicen-
towski, 2000) and (Baroni et al, 2002), who use
string edit distances to estimate formal similarity.
As far as we know, all the other perform some sort
of segmentation even when the goal is not to find
morphemes as in (Neuvel and Fulop, 2002). Our
model differs from these approaches in that the
graphemic similarities are determined solely on the
basis of the sharing of graphemic features. It is the
main contribution of this paper.
Our model is also related to approaches that
combine graphemic and semantic cues in order
to identify morphemes or morphological relations
between words. Usually, these semantic infor-
mations are automatically acquired from corpora
by means of various techniques as latent semantic
analysis (Schone and Jurafsky, 2000), mutual in-
formation (Baroni et al, 2002) or co-occurrence in
an n-word window (Xu and Croft, 1998; Zweigen-
baum and Grabar, 2003). In the experiment we
present here, semantic informations are extracted
from a machine readable dictionary and semantic
similarity is calculated through random walks in a
lexical graph. Our approach can also be compared
with (Hathout, 2002) where morphological knowl-
edge is acquired by using semantic informations
extracted from dictionaries of synonyms or from
WordNet.
4 Lexeme Description
In our model, the lexical units and their properties
are represented in a bipartite graph with the ver-
tices representing the lexemes in one sub-set and
the vertices representing the formal and semantic
features in the other. Lexeme vertices are identi-
fied by the lemma and the grammatical category.
In the experiment reported in the paper, the for-
mal properties are the n-grams of letters that occur
in the lexemes lemma. Figure 1 shows a sub-set of
2
$or; $ori; $orie; ...
$orientation; ori; orie; ...
orientation; orientation$; ...
tio; tion; tion$; ion; ion$; on$
Figure 1: Excerpt of the formal features associated
with the noun orientation.
N.action; N.action X.de; N.action
X.de V.orienter; X.de; X.de
V.orienter; V.orienter; X.de
V.s?orienter; V.s?orienter;
N.r?sultat; N.r?sultat X.de;
N.r?sultat X.de X.ce; N.r?sultat
X.de X.ce N.action; X.de X.ce;
X.de X.ce N.action; X.ce; X.ce
N.action; N.action
Figure 2: Semantic features induced by the defi-
nition ?Action d?orienter, de s?orienter ; r?sultat de
cette action.? of the noun orientation
the formal features associated with the word orien-
tation. The beginning and the end of the lemma are
marked by the character $. We impose a minimum
size on the n-grams (n ? 3).
The model is pure lexeme-based because this
decomposition does not confer a special status to
any of the individual n-grams which character-
ize the lexemes. All n-grams play the same role
and therefore no one has the status of morpheme.
These features are only used to bring closer the
words that share the same sounds.
The semantic properties we have used are ex-
tracted from the TLFi definitions. Each headword
is provided with the n-grams of words that occur
in its definitions. The n-grams that contain punc-
tuation marks are eliminated. In other words, we
only use n-grams of words that occur between two
punctuation marks. For instance, the semantic fea-
tures induced by the definition Action d?orienter,
de s?orienter ; r?sultat de cette action. (?act of ori-
enting, of finding one?s way; result of this action?)
of the noun orientation are presented in figure 2.
The words in the definitions are POS tagged and
lemmatized. The tags are A for adjectives, N for
nouns, R for adverbs, V for verbs and X for all
other categories.
This is a very coarse semantic representation in-
spired from the repeated segments (Lebart et al,
1998). It offers three advantages: (1) being heav-
ily redundant, it can capture various levels of sim-
$or
$ori
orient
entati
N.action X.de
N.r?sultat X.de X.ce
N.orientation
V.orienter
A.original
N.fermentation
N.pointage
Figure 3: Excerpt of the bipartite graph which rep-
resents the lexicon. Words are displayed in ovals,
semantic feature in rectangles and formal features
in octagons. The graph is symmetric.
ilarity between the definitions; (2) it integrates in-
formations of a syntagmatic nature without a deep
syntactic analysis of the definitions; (3) it slightly
reduces the strong variations in the lexicographi-
cal treatment of the headwords, especially in the
division into sub-senses and in the definitions.
The bipartite graph is built up by symmetrically
connecting each headword to its semantic and for-
mal features. For instance, the noun orientation
is connected with the formal feature $or, $ori,
$orie, $orien, etc. which are in turn connected
with the words orienter, orientable, orientement
?orientation?, orienteur ?orientor?, etc. Likewise,
orientation is connected with the semantic fea-
tures N.action X.de, N.r?sultat X.de
X.ce N.action, etc. which are themselves
connected with the nouns orientement, harmoni-
sation ?synchronization?, pointage ?checking?, etc.
The general schema is illustrated in figure 4. This
representation corresponds precisely to the Net-
work Model of Bybee (1995).
We use a bipartite graph mainly for two reasons:
(1) We can spread an activation synchronously into
the formal and the semantic sub-graphs. (2) It con-
tains representations of the formal and the seman-
tic properties of the lexemes which, for instance,
could be used in order to describe the semantics of
the -able suffixation or the characteristic endings
of the boat names (-ier, -eur, etc.). However, the
bipartite structure is not essential and we only need
3
to be able to compute morphological distances be-
tween words.
5 Random walks
The computational side of the method is based on
the estimation of the proximity between words rep-
resented in a lexical graph (Gaume et al, 2002;
Gaume et al, 2005; Muller et al, 2006). The
graphs used in this approach are slightly different
from the ones presented above. All their vertices
represent words and the edges describe semantic
relations such as synonymy. The proximity is com-
puted by simulating the spreading into the graph of
an activation initiated at a vertice. Following the
spreading, the nodes which are most excited are
regarded as being the closest to the initial vertice.
The same method can be used to estimate the
morphological proximity between words that are
described in a bipartite graph like the one we pro-
pose (see figure 4). It then connects words that
have the same semantic and formal features. One
has just to propagate the activation into the bipar-
tite graph for an even number of times. When the
graph is heavily redundant, two steps of propaga-
tion are sufficient to obtain the intended proximity
estimations.
In the example in figure 4, the morphological
neighbors of the noun orientation are identified by
activating the vertice which represents it. In the
first step, the activation is spread toward the ver-
tices which represent its formal and semantic fea-
tures. In the second step, the activation located on
the feature vertices is spread toward the headword
vertices. For instance, orienter becomes activated
via the formal features $or, $ori, orien and
fermentation through the formal feature entati
and the semantic feature N.r?sultat X.de
X.ce. The greater the number of features shared
by a headword with orientation, the stronger the
activation it receives.
The spreading of activation is simulated as a ran-
dom walk in the lexical graph, classically com-
puted as a multiplication of the stochastic adja-
cency matrix. More precisely, let G = (V,E,w)
be a weighted graph consisting of a set of ver-
tices V = {v
1
, . . . , v
n
}, a set of edges E ? V
2
and of a weight function w : E ? R. Let A
be the adjacency matrix of G, that is a n ? n
matrix such that A
ij
= 0 if (v
i
, v
j
) 6? E and
A
ij
= w(v
i
, v
j
) if (v
i
, v
j
) ? E. (In the experi-
ment, w(e) = 1,?e ? E.) We normalize the rows
of A in order to get a stochastic matrix M . M
n
ij
is
the probability of reaching node v
j
from the node
v
i
through a walk of n steps. This probability can
also be regarded as an activation level of node v
j
following an n-step spreading initiated at vertice
v
i
.
In the experiment presented in this paper, the ac-
tivation is spread for one half toward the seman-
tic feature and for the other toward the formal fea-
tures. The edges of the bipartite graph can be di-
vided in three parts E = J ?K ? L where J con-
tains the edges that connect a headword to a for-
mal feature, K the edges that connect a headword
to a semantic feature and L the edges that connect
a formal or semantic feature to a headword. The
values of M are defined as follows:
? if e
ij
= (v
i
, v
j
) ? J , M
ij
=
A
ij
2
P
e
ih
?J
A
ih
if
v
i
is connected to a semantic feature and
M
ij
=
A
ij
P
e
ik
?J
A
ik
otherwise.
? if e
ik
= (v
i
, v
k
) ? K, M
ik
=
A
ik
2
P
e
ih
?K
A
ih
if
v
i
is connected to a formal feature and
M
ik
=
A
ik
P
e
ih
?K
A
ih
otherwise.
? if e
il
= (v
i
, v
l
) ? L, M
il
=
A
il
P
e
ih
?L
A
ih
.
6 Lexical neighborhood
The graph used in the experiment has been built
from the definitions of the TLFi. We only removed
the definitions of non standard uses (old, slang,
etc.). The extraction and cleaning-up of the defi-
nitions have been carried out in collaboration with
Bruno Gaume and Philippe Muller. The bipartite
graph has been created from 225 529 definitions
describing 75 024 headwords (lexemes). We then
removed all the features associated only with one
headword. This reduces the size of the graph sig-
nificantly without changing the connections that
hold between the headwords. Table 1 shows that
this reduction is stronger for the semantic feature
(93%) than it is for the formal ones (69%). Indeed,
semantic descriptions show greater variability than
formal ones.
The use of the graph is illustrated in figure 4. It
shows the 20 nearest neighbors of the verb fruc-
tifier for various propagation configurations. The
examples in (a) and (b) show clearly that formal
features are the more predictive ones while seman-
tic features are the less reliable ones. The example
in (c) illustrates the contribution of the semantic
4
(a) V.fructifier N.fructification A.fructificateur A.fructifiant A.fructif?re V.sanctifier V.rectifier
A.rectifier V.fructidoriser N.fructidorien N.fructidor N.fructuosit? R.fructueusement A.fructueux
N.rectifieur A.obstructif A.instructif A.destructif A.constructif N.infructuosit?
(b) V.fructifier V.trouver N.missionnaire N.mission A.missionnaire N.saisie N.police N.hangar N.d?me
N.ban V.affruiter N.melon N.saisonnement N.az?darach A.fruitier A.bif?re V.saisonner N.roman
N.troubadour V.contaminer
(c) V.fructifier A.fructifiant N.fructification A.fructificateur V.trouver A.fructif?re V.rectifier
V.sanctifier A.rectifier V.fructidoriser N.fructidor N.fructidorien N.missionnaire N.mission
A.missionnaire A.fructueux R.fructueusement N.fructuosit? N.rectifieur N.saisie
Figure 4: The 20 nearest neighbors of the verb fructifier when the activation is spread (a) only toward
the formal features, (b) only toward the semantic ones, (c) toward both the semantic and formal features.
Words that do not belong to the family or series of fructifier are emphasized.
graph complete reduced
formal features 1 306 497 400 915
semantic features 7 650 490 548 641
Table 1: Number of the semantic and formal fea-
tures coming from TLFi.
features. They reorder the formal neighbors and
introduce among them the nearest semantic neigh-
bors. We see in the lists in (a) and (c) that the fam-
ily members are the nearest neighbors and that the
members of the series come next.
7 Analogy
The members of the series and families are mas-
sively involved in the analogies which structure the
lexicon. A word x belonging to a family F
x
partic-
ipates in several analogies with a large number of
other members of F
x
. The analogies that involve
two words (x, y) ? F
2
include two other words
(z, t) that belong to one same family F
?
. On the
other hand, if x is a complex word that belongs
to a series S
x
, then z ? S
x
, x ? S
z
, y ? S
t
and t ? S
y
. For instance, the couple of words
fructifier and fructification form analogies with of
members of other families (rectifier, rectification),
(certifier, certification), (plastifier, plastification),
etc. Moreover, the first elements of these couples
belong to series of fructifier and the second ones to
the series of fructification.
In a dual manner, a word u belonging to a se-
ries S participates in a set of analogies with a large
number of other members of S. The analogies that
involve two elements of the same series are made
up with words which themselves belong to a same
series. For instance, fructifier and sanctifier form
analogies with the members of other series (fruc-
tificateur, sanctificateur), (fructification, sanctifi-
cation) or (fructifiant, sanctifiant). These couples
are respectively made of members of the families
of fructifier and sanctifier.
7.1 Analogies and neighborhoods
The analogies that involve members of families
and series can be used to efficiently filter the
morphological neighbors that are identified by the
method presented above. If v is a correct morpho-
logical neighbor of w, then it is either a member of
the family of m or a member of its series. There-
fore, it exists another neighbor v
?
of w (v
?
belong
to the family of w if v belongs to the series of w
or vice versa) such that it exists a neighbor w
?
of v
and of v
?
such that w : v :: v
?
: w
?
.
2
Therefore, we
have two configurations:
1. if v ? F
w
, then ?v
?
? S
w
, ?w
?
? S
v
?F
v
?
, w :
v :: v
?
: w
?
2. if v ? S
w
, then ?v
?
? F
w
, ?w
?
? F
v
?S
v
?
, w :
v :: v
?
: w
?
The first case is illustrated by the above examples
with w = fructifier and v = fructification, and the
second one with w = fructifier et v = rectifier.
7.2 Formal analogy
A formal or graphemic analogy is a relation
a : b :: c : d that holds between four strings
such that the graphemic differences between a
2
The notation a : b :: c : d is used as a shorthand for the
statement that (a, b, c, d) forms an analogical quadruplet, or
in other words that a is to b as c is to d.
5
and b are the same as the ones between c and d.
It can be exemplified with the four Arabic words
kataba:maktoubon::fa3ala:maf3oulon
which respectively are transcriptions of the verb
?write?, the noun ?document?, the verb ?do? and
the noun ?effect.?
3
The differences between the
first two words and between the two last ones can
be described as in figure 5. They are identical for
the two couples of words.
 k a t a b a
ma k  t ou b on
 f a 3 a l a
ma f  3 ou l on
Figure 5: Formal analogy kataba:
maktoubon::fa3ala:maf3oulon. The
differences are locates in frame boxes.
More generally, formal analogies can be
defined in terms of factorization (Stroppa and
Yvon, 2005). Let L be an alphabet and a ? L
?
a string over L. A factorization of a is a se-
quence f = (f
1
, ? ? ? , f
n
) ? L
?
n
such that
a = f
1
? ? ? ? ? f
n
where ? denotes the concate-
nation. For instance, (ma, k, , t, ou, b, on)
is a factorization of length 7 of maktoubon.
Morphological analogies can be defined as
follows. Let (a, b, c, d) ? L
?
4
be for strings.
a : b :: c : d is a formal analogy iff there exists
n ? N and four factorizations of length n of the
four strings (f(a), f(b), f(c), f(d)) ? L
?
4
such that, ?i ? [1, n], (f
i
(b), f
i
(c)) ?
{(f
i
(a), f
i
(d)), (f
i
(d), f
i
(a))}. For the analogy
kataba:maktoubon::fa3ala:maf3oulon,
the property holds for n = 7 (see figure 5).
7.3 Implementation
A formal analogy a : b :: c : d can be easily
checked by comparing the sequences of string
edit operations between (a, b) and between (c, d).
Both sequences must minimize Levenshtein edit
distance (i.e. have a minimal cost). Each sequence
corresponds to a path in the edit lattices of the
couple of words. The lattice are represented by
a matrix computed using the standard string edit
algorithm (Jurafsky and Martin, 2000). The path
which describes the sequence of string edit opera-
tions starts at the last cell of the matrix and climbs
3
This example is adapted from examples in (Lepage,
1998; Lepage, 2003).
to the first one. Only three directions are allowed:
upward (deletion), to the left (insertion) or in
the upper left diagonal direction (substitution).
Figure 6 shows the sequence of edit operations for
the couple fructueux:infructueusement.
Sequences of edit operations can be simplified
by merging the series of identical character
matchings. The sequence in figure 6 then becomes
((I,,i), (I,,n), (M,fructueu,fructueu),
(S,x,s), (I,,e), (I,,m), (I,,e), (I,,n), (I,,t)).
This simplified sequence is identical to the one
for the couple soucieux:insoucieusement
except for the matching operation: ((I,,i),
(I,,n), (M,soucieu,soucieu), (S,x,s), (I,,e),
(I,,m), (I,,e), (I,,n), (I,,t)). The two se-
quences can be made identical if the matching
sub-strings are not specified. The resulting
sequence can then be assigned to both cou-
ples as their edit signatures (?). The formal
analogy fructueux:infructueusement::
soucieux:insoucieusement can be stated
in terms of identity the edit signatures:
?(fructueux,infructueusement) =
?(soucieux,insoucieusement) =
((I,,i), (I,,n), (M,@,@), (S,x,s), (I,,e),
(I,,m), (I,,e), (I,,n), (I,,t))
More generally, four strings (a, b, c, d) ? L
?
4
form
a formal analogy a : b :: c : d iff ?(a, b) = ?(c, d)
or ?(a, c) = ?(b, d).
7.4 First results
The computational model we have just presented
has been implemented and a first experiment has
been carried out. It consists in determining the
100 closest neighbors of every headword for the
three configurations presented in ? 6. All the for-
mal analogies that hold between these words have
then been collected. We have not been able to do a
standard evaluation in terms of recall and precision
because of the lack of morphological resources for
French. However, we have manually checked the
analogies of 22 headwords belonging to 4 morpho-
logical families. An analogy a : b :: c : d is ac-
cepted as correct if:
? b belongs to the family of a, c belongs to the
series of a, d belongs to series of b and to the
family of c, or
? b belongs to the series of a, c belongs to the
family of a, d belongs to family of b and to
the series of c.
6
I I M M M M M M M M S I I I I I
  f r u c t u e u x     
i n f r u c t u e u s e m e n t
Figure 6: Sequence of edit operations that transform fructueux into infructueusement. The
type of each operation is indicated on the first line: D for deletion, I for insertion, M for matching and S
for a substitution by a different character.
configuration analogies correct errors
formal 169 163 3.6%
semantics 5 5 0.0%
sem + form 130 128 1.5%
Table 2: Number of the analogies collected for a
sample of 22 headwords and error rate.
The results are summarized in table 2. Their qual-
ity is quite satisfactory. However, the number of
analogies strongly depends on the configuration of
propagation. The best trade-off is a simultaneous
propagation toward the semantic and formal fea-
tures. Here are some of the correct and erroneous
analogies collected:
? R.fructueusement:R.affectueusement::
A.infructueux:A.inaffectueux
? N.fructification:N.identification::
V.fructifier:V.identifier
? N.fruiterie:N.fruitier::N.laiterie:N.laitier
? * N.fruit:N.bruit::V.frusquer:V.brusquer
The first example is particularly interesting be-
cause it involves on one side suffixed words and
on the other prefixed ones.
The performance of the method strongly de-
pends on the length of the headwords. Table 3
presents the number of analogies and the error rate
for 13 groups of 5 words. The words of each group
are of the same length. Lengths range from 4 to 16
letters.
8 Conclusion
We have presented a computational model that
makes the morphological structure of the lexicon
emerge from the formal and semantic regularities
of the words it contains. The model is radically
lexeme-based. It integrates the semantic and for-
mal properties of the words in a uniform manner
and represents them into a bipartite graph. Ran-
dom walks are used to simulate the spreading of
length analogies correct errors
4 29 15 51.7%
5 22 8 36.4%
6 8 1 12.5%
7 10 2 20.0%
8 55 1 1.8%
9 29 2 6.9%
10 30 0 0.0%
11 32 0 0.0%
12 19 0 0.0%
13 11 0 0.0%
14 35 0 0.0%
15 63 0 0.0%
16 39 0 0.0%
Table 3: Number of the analogies and error rate for
headwords of length 4 to 16.
activations in this lexical network. The level of
activation obtained after the propagation indicates
the lexical relatedness of the words. The members
of the morphological family and the derivational
series of each word are then identified among its
lexical neighbors by means of formal analogies.
This is work in progress and we still have to sep-
arate the members of the families from the mem-
bers of the series. We also intend to conduct a
similar experiment on the English lexicon and to
evaluate our results in a more classical manner by
using the CELEX database (Baayen et al, 1995)
as gold standard. The evaluation should also be
done with respect to well known systems like Lin-
guistica (Goldsmith, 2001) or the morphological
analyzer of Bernhard (2006).
Acknowledgments
I would like to thank the ATILF laboratory and
Jean-Marie Pierrel for making available to me the
TLFi. I am in debt to Bruno Gaume and Philippe
Muller for the many discussions and exchanges we
have had on the cleaning-up of the TFLi and its ex-
ploitation through random walks. I am also grate-
ful to Gilles Boy?, Olivier Haute-C?ur and Lu-
7
dovic Tanguy for their comments and suggestions.
All errors are mine.
References
Anderson, Stephen R. 1992. A-Morphous Morphol-
ogy. Cambridge University Press, Cambridge, UK.
Aronoff, Mark. 1994. Morphology by Itself. Stem and
Inflexional Classes. MIT Press, Cambridge, Mass.
Baayen, R. Harald, Richard Piepenbrock, and Leon Gu-
likers. 1995. The CELEX lexical database (release
2). CD-ROM. Linguistic Data Consortium, Univer-
sity of Pennsylvania, Pennsylvania, USA.
Baroni, Marco, Johannes Matiasek, and Harald Trost.
2002. Unsupervised discovery of morphologically
related words based on orthographic and semantic
similarity. In Proceedings of the Workshop on Mor-
phological and Phonological Learning of ACL-2002,
pages 48?57, Philadelphia. ACL.
Bernhard, Delphine. 2006. Automatic acquisition of
semantic relationships from morphological related-
ness. In Advances in Natural Language Processing,
Proceedings of the 5th International Conference on
NLP, FinTAL 2006, volume 4139 of Lecture Notes in
Computer Science, pages 121?13. Springer.
Bybee, Joan L. 1995. Regular morphology and the lex-
icon. Language and cognitive processes, 10(5):425?
455.
Creutz, Mathias and Krista Lagus. 2002. Unsuper-
vised discovery of morphemes. In Proceedings of
the ACL Workshop on Morphological and Phono-
logical Learning, pages 21?30, Philadelphia, Penn.
ACL.
D?jean, Herv?. 1998. Morphemes as necessary con-
cept for structures discovery from untagged corpora.
In Proceedings of the Workshop on Paradigms and
Grounding in Natural Language Learning, pages
295?299, Adelaide, Australia.
Gaume, Bruno, Karine Duvigneau, Olivier Gasquet,
and Marie-Dominique Gineste. 2002. Forms of
meaning, meaning of forms. Journal of Experimen-
tal and Theoretical Artificial Intelligence, 14(1):61?
74.
Gaume, B., F. Venant, and B. Victorri. 2005. Hierar-
chy in lexical organization of natural language. In
Pumain, D., editor, Hierarchy in natural and social
sciences, Methodos series, pages 121?143. Kluwer.
Goldsmith, John. 2001. Unsupervised learning of
the morphology of natural language. Computational
Linguistics, 27(2):153?198.
Hathout, Nabil. 2002. From wordnet to celex: acquir-
ing morphological links from dictionaries of syn-
onyms. In Proceedings of the Third International
Conference on Language Resources and Evalua-
tion, pages 1478?1484, Las Palmas de Gran Canaria.
ELRA.
Jurafsky, Daniel and James H. Martin. 2000. Speech
and language processing. Prentice-Hall.
Lebart, Ludovic, Andr? Salem, and Lisette Berry.
1998. Exploring textual data. Kluwer Academic
Publishers, Dordrecht.
Lepage, Yves. 1998. Solving analogies on words: an
algorithm. In Proceedings of COLING-ACL?98, vol-
ume 2, pages 728?735, Montr?al, Canada.
Lepage, Yves. 2003. De l?analogie rendant compte de
la commutation en linguistique. M?moire de HDR,
Universit? Joseph Fourier, Grenoble.
Muller, Philippe, Nabil Hathout, and Bruno Gaume.
2006. Synonym extraction using a semantic dis-
tance on a dictionary. In Radev, Dragomir and Rada
Mihalcea, editors, Proceedings of the HLT/NAACL
workshop Textgraphs, pages 65?72, New York, NY.
Association for Computational Linguistics.
Neuvel, Sylvain and Sean A. Fulop. 2002. Unsuper-
vised learning of morphology without morphemes.
In Proceedings of the Workshop on Morphologi-
cal and Phonological Learning 2002, Philadelphia.
ACL Publications.
Schone, Patrick and Daniel S. Jurafsky. 2000.
Knowledge-free induction of morphology using la-
tent semantic analysis. In Proceedings of the Confer-
ence on Natural Language Learning 2000 (CoNLL-
2000), pages 67?72, Lisbon, Portugal.
Stroppa, Nicolas and Fran?ois Yvon. 2005. An analog-
ical learner for morphological analysis. In Proceed-
ings of the 9th Conference on Computational Natural
Language Learning (CoNLL-2005), pages 120?127,
Ann Arbor, Michigan, June. Association for Compu-
tational Linguistics.
Xu, Jinxi and W. Bruce Croft. 1998. Corpus-based
stemming using co-occurrence of word variants.
ACM Transaction on Information Systems, 16(1):61?
81.
Yarowsky, David and Richard Wicentowski. 2000.
Minimally supervised morphological analysis by
multimodal alignment. In Proceedings of the As-
sociation of Computational Linguistics (ACL-2000),
pages 207?216, Hong Kong.
Zweigenbaum, Pierre and Natalia Grabar. 2003.
Learning derived words from medical corpora. In
9th Conference on Artificial Intelligence in Medicine
Europe, pages 189?198, Cyprus.
8
Proceedings of the Workshop on Lexical and Grammatical Resources for Language Processing, pages 65?74,
Coling 2014, Dublin, Ireland, August 24 2014.
Acquisition and enrichment of morphological and morphosemantic
knowledge from the French Wiktionary
Nabil Hathout Franck Sajous Basilio Calderone
CLLE-ERSS (CNRS & Universit?e de Toulouse 2)
Abstract
We present two approaches to automatically acquire morphologically related words from Wik-
tionary. Starting with related words explicitly mentioned in the dictionary, we propose a method
based on orthographic similarity to detect new derived words from the entries? definitions with
an overall accuracy of 93.5%. Using word pairs from the initial lexicon as patterns of formal
analogies to filter new derived words enables us to rise the accuracy up to 99%, while extending
the lexicon?s size by 56%. In a last experiment, we show that it is possible to semantically type
the morphological definitions, focusing on the detection of process nominals.
1 Introduction
Around the 1980s the computational exploitation of machine-readable dictionaries (MRDs) for the au-
tomatic acquisition of lexical and semantic information enjoyed a great favor in NLP (Calzolari et al.,
1973; Chodorow et al., 1985). MRDs? definitions provided robust and structured knowledge from which
semantic relations were automatically extracted for linguistic studies (Markowitz et al., 1986) and lin-
guistic resources development (Calzolari, 1988). Today the scenario has changed as corpora have become
the main source for semantic knowledge acquisition. However, dictionaries are regaining some interest
thanks to the availability of public domain dictionaries, especially Wiktionary.
In the present work, we describe a method to create a morphosemantic and morphological French
lexicon from Wiktionary?s definitions. This type of large coverage resource is not available for almost
all languages, with the exception of the CELEX database (Baayen et al., 1995) for English, German and
Dutch, a paid resource distributed by the LDC.
The paper is organized as follows. Section 2 reports related work on semantic and morphological
acquisition from MRDs. In Section 3, we describe how we converted Wiktionnaire, the French language
edition of Wiktionary, into a structured XML-tagged MRD which contains, among other things, defini-
tions and morphological relations. In Section 4, we explain how we used Wiktionnaire?s morphological
sections to create a lexicon of morphologically related words. The notion of morphological definitions
and their automatic identification are introduced in Section 5. In Section 6, we show how these defini-
tions enable us to acquire new derived words and enrich the initial lexicon. Finally, Section 7 describes
an experiment where we semantically typed process nouns definitions.
2 Related work
Semantic relations are usually acquired using corpora (Curran and Moens, 2002; van der Plas and Bouma,
2005; Heylen et al., 2008) but may also be acquired from MRDs. MRDs-based approaches are bound
to the availability of such resources. However, for some languages including French, no such resource
exists. Recent years have seen the development of large resources built automatically by aggregating
and/or translating data originating from different sources. For example, Sagot and Fi?ser (2008) have
built WOLF, ?a free French Wordnet? and Navigli and Ponzetto (2010) BabelNet, a large multilingual
semantic network. Such resources tend to favor coverage over reliability and may contain errors and
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
65
inaccuracy, or be incomplete. Pierrel (2013), while criticizing these resources, describes the digitization
process of the Tr?esor de la Langue Franc?aise, a large printed French dictionary. The first impulse of this
long-course reverse-engineering project is described in (Dendien, 1994) and resulted in the TLFi, a fine-
grained XML-structured dictionary. Pierrel advocates mutualization, recommends resources sharing and
underlines how the use of the TLFi would be relevant for NLP. Though we totally agree on this assertion,
we deplore that the resource, being only available for manual use and not for download, prevents its use
for NLP.
Crowdsourcing has recently renewed the field of lexical resources development. For example Lafour-
cade (2007) designed JeuxDeMots, a game with a purpose, to collect a great number of relations between
words. Other works use the content of wikis produced by crowds of contributors. Initially in the shadow
of Wikipedia, the use of Wiktionary tends to grow in NLP studies since its exploitation by Zesch et al.
(2008). Its potential as an electronic lexicon was first studied by Navarro et al. (2009) for English and
French. The authors leverage the dictionary to build a synonymy network and perform random walks to
find missing links. Other works tackled data extraction: Anton P?erez et al. (2011) for instance, describe
the integration of the Portuguese Wiktionary and Onto.PT; S?erasset (2012) built Dbnary, a multilingual
network containing ?easily extractable? entries. If the assessment of Wiktionary?s quality from a lex-
icographic point of view has not been done yet, Zesch and Gurevych (2010) have shown that lexical
resources built by crowds lead to results comparable to those obtained with resources designed by pro-
fessionals, when used to compute semantic relatedness of words. In Sajous et al. (2013a), we created an
inflectional and phonological lexicon from Wiktionary and showed that its quality is comparable to those
of reference lexicons, while the coverage is much wider.
Comparatively little effort has been reported in literature on the exploitation of semantic relations to
automatically identify morphological relations. Schone and Jurafsky (2000) learn morphology with a
method based on semantic similarity extracted by latent semantic analysis. Baroni et al. (2002) combine
orthographic (string edit distances) and semantic similarity (words? contextual information) in order to
discover morphologically related words. Along the same line, Zweigenbaum and Grabar (2003) ac-
quire semantic information from a medical corpus and use it to detect morphologically derived words.
More recently, Hathout (2008) uses the TLFi to discover morphologically related words by combining
orthographic and semantic similarity with formal analogy.
I another work, Pentheroudakis and Vanderwende (1993) present a method to automatically extract
morphological relations from the definitions of MRDs. The authors automatically identify classes of
morphologically related words by comparing the semantic information in the entry of the derivative
with the information stored in the candidate base form. This effort shows the crucial importance and the
potential of the MRDs? definitions to acquire and discover morphological relationships of derived words.
3 Turning the French Wiktionary into a Machine-Readable Dictionary
As mentioned is section 2, the quality of collaboratively constructed resources has already been assessed
and we will not debate further the legitimacy of leveraging crowdsourced data for NLP purpose. We give
below a brief description of Wiktionary
1
and of the process of converting it into a structured resource.
Wiktionary is divided in language editions. Each language edition is regularly released as a so-called
XML dump.
2
The ?XML? mention is somewhat misleading because it suggests that XML markups
encode the articles? microstructure whereas only the macrostructure (articles? boundaries and titles) is
marked by XML tags. Remaining information is encoded in wikicode, an underspecified format used by
the MediaWiki content-management system. As explained by Sajous et al. (2013b) and S?erasset (2012),
this loose encoding format makes it difficult to extract consistent data. One can choose to either restrict
the extraction to prototypical articles or design a fine-grained parser that collects the maximum of the
available information. The former goal is relatively easily feasible but leads to a resource containing only
a small subset of Wiktionary?s entries. Our belief is that the tedious engineering work of handling all
1
For further details, read Zesch et al. (2008) and Sajous et al. (2013b).
2
The dump used in this work is https://dumps.wikimedia.org/frwiktionary/20140226/
frwiktionary-20140226-pages-articles.xml.bz2
66
== {{langue|fr}} ==
=== {{S|nom|fr}} ===
{{fr-r?eg|kurs}}
???course??? {{pron|kurs|fr}} {{f}}
# [[action|Action]] de [[courir]], [[mouvement]] de celui qui [[court]].
#
*
??[...], il n?est de bruit qu?un ver qui taraude incessamment les boiseries et dans le plafond,
la ???course??? d?un rongeur.?? {{source|{{w|Jean Rogissart}}, ??Passantes d?Octobre??, 1958}}
# {{sport|nocat=1}} Toute [[?epreuve]] [[sportif|sportive]] o`u la [[vitesse]] est en jeu.
#
*
??Nos p`eres ?etaient donc plus sages que nous lorsqu?ils repoussaient l?id?ee des ???courses???.
# {{vieilli|fr}} [[actes|Actes]] d?[[hostilit?e]] que l?on faisait [[courir|en courant]] les mers
ou [[entrer|en entrant]] dans le [[pays]] [[ennemi]].
{{usage}} On dit maintenant [[incursion]], [[reconnaissance]], [[pointe]], etc.
#
*
??Pendant les guerres de la r?evolution, Chausey, trop expos?e aux ???courses??? des corsaires
de Jersey, resta inhabit?e.??
# {{figur?e|fr}} [[marche|Marche]], [[progr`es]] [[rapide]] d?une personne ou d?une chose.
#
*
??Rien ne peut arr?eter ce conqu?erant, ce fl?eau dans sa ???course???.??
==== {{S|d?eriv?es}} ====
*
[[courser]]
*
[[coursier]]
Figure 1: Wikicode extract of the noun course
wikicode particularities is valuable. In our case, it enabled us to design an unprecedented large copylefted
lexicon that has no equivalent for French.
The basic unit of Wiktionary?s articles is the word form: several words from different languages having
the same word form occur in the same page (at the same URL). In such a page, a given language section
may be divided in several parts of speech which may in turn split into several homonyms subsections.
In the French Wiktionary, the course entry, for example, describes both the French and English lexemes.
The French section splits into a noun section (une course ?a run; a race?) and a section related to the
inflected forms of the verb courser ?to pursue?. The noun section distinguishes 11 senses that all have
definitions illustrated by examples. An extract of the noun section?s wikicode is depicted in Figure 1.
As can be seen, some wiki conventions are recurrent (e.g. double-brackets mark hyperlinks) and are
easy to handle. Handling dynamic templates (marked by curly brackets) is more tricky. In definitions,
they mark notes related to particular domains, registers, usages, geographic areas, languages, etc. In
Figure 1, the pattern {{sport}} indicates that the second sense relates to the domain of sport ; the pattern
{{vieilli|fr}} in the following definition denotes a dated usage ; the pattern {{figur?e|fr}} in the last
definition indicates a figurative one. We inventoried about 6,000 such templates and their aliases: for
example, 4 patterns (abbreviated or full form, with or without ligature) signal the domain of enology:
{{?nologie|fr}}, {{oenologie|fr}}, {{?nol|fr}} and {{oenol|fr}}. Unfortunately, the existence of
such patterns does not prevent a contributor to directly write domain name in the page: several versions
of ?hardcoded domains? may be found, e.g. (oenologie) or (?nologie).
Inventorying all these variations enabled us: 1) to remove them from the definitions? text and 2) to
mark them in a formal way. Thus, one can decide to remove or keep, on demand, entries that are marked
as rare or dated, build a sublexicon of a given domain, remove diatopic variations or investigate only
these forms (e.g. words that are used only in Quebec), etc.
The variations observed in the definitions also occur in phonemic transcriptions, inflectional features,
semantic relations, etc. We focus here only on the information used in sections 6 and 7: definitions
and morphological relations. However, we parsed Wiktionnaire?s full content and extracted all kind of
available information, handling the numerous variations that we observed to convert the online dictio-
nary into a structured resource, that we called GLAWI.
3
It contains more than 1.4 million inflected forms
(about 190,000 lemmas) with their definitions, examples, lexicosemantic relations and translations, de-
rived terms and phonemic transcriptions. A shortened extract resulting from the conversion of the noun
section of course is depicted in Figure 2. As can be seen, GLAWI includes both XML structured data
and the initial corresponding wikicode. This version of the resource is intended to remain close to the
Wiktionnaire?s content, whereas other lexicons focused on a particular aspect will be released. Our aim
is to provide ready-to-use lexicons resulting from different post-processing of GLAWI. Post-processing
3
Resulting from the unification of GL
`
AFF and an updated version of WiktionaryX, GLAWI stands for ?GL
`
AFF and Wik-
tionaryX?. This resource is freely available at http://redac.univ-tlse2.fr/lexicons/glawi.html.
67
Figure 2: Extract of the noun subsection of course converted into a workable format
steps will consist in 1) selecting information relevant to a particular need (e.g. phonemic transcriptions,
semantic relations, etc.) and 2) detecting inconsistencies and correcting them. The initial GLAWI re-
source, containing all the initial information, will also be released so that anyone can apply additional
post-processings. GLAWI unburdens such users from the efforts of parsing the wikicode.
Articles from Wiktionnaire may contain morphologically derived terms. Figures 1 and 2 show that
course produces the derived verb courser and noun coursier ?courier?. Such derivational relations are
collected from Wiktionnaire and included in GLAWI. We show below how we leverage this information,
in addition to GLAWI?s definitions, to acquire morphological and morphosemantic knowledge.
4 Acquisition of morphological relations from GLAWI morphological subsections
We first extracted from GLAWI the list of the lexeme headwords that have typographically simple writ-
ten forms (only letters) and that belong to the major POS: noun, verb, adjective, and adverb. This list
(GLAWI-HW) contains 152,567 entries: 79,961 nouns, 22,646 verbs, 47,181 adjective and 2,779 ad-
verbs). In what follows, we only consider these words.
Then we created a morphological lexicon extracted from the morphological subsections
4
of GLAWI
(hereafter GMS). The lexicon consists of all pairs of words (w
1
, w
2
), where w
1
and w
2
belong to
GLAWI-HW and where w
2
is listed in one of the morphological subsections of the article of w
1
or
vice versa. GMS contains 97,058 pairs. The extraction of this lexicon from GLAWI was very simple, all
the variability in Wiktionnaire?s lexicographic descriptions being supported by our parser (see Section 3).
The remainder of the paper presents two methods for extending GMS. In a first experiment, we com-
plement this lexicon with new pairs acquired from GLAWI?s definitions. In a second one, we show how
some of GMS?s morphological pairs can be classified with respect to a given semantic class.
4
The morphological subsections appear under 4 headings in Wiktionnaire: apparent?es; apparent?es ?etymologiques; com-
pos?es; d?eriv?es.
68
w1
w
2
w
1
w
2
bisannuel A an N r?epublicain N r?epublique N
compilation N compilateur A similaire A dissimilitude N
foudroyeur A foudre N tabasser V tabassage N
militance N militer V taxidermie N taxidermiser V
presse N pression N volcan N volcanique A
Figure 3: Excerpt of GMS lexicon. Letters following the underscore indicate the grammatical category.
5 Morphological definitions
Basically, a dictionary definition is a pair composed of a word and a gloss of its meaning. In the follow-
ing, we will use the terms definiendum for the defined word, definiens for the defining gloss and the
notation definiendum = definiens. The definition articulates a number of lexical semantic relations be-
tween the definiendum and some words of the definiens as in (1) where chair is a hyponym of furniture,
is the holonym of seat, legs, back and arm rests and is also the typical instrument of sit on. Some of the
relations are made explicit by lexical markers as used to or comprising.
(1) chair
N
= An item of furniture used to sit on or in comprising a seat, legs, back, and some-
times arm rests, for use by one person.
Martin (1983) uses these relations to characterize the definitions. In his typology, definitions as in (2)
are considered to be (morphological) derivational because the definiendum is defined with respect to
a morphologically related word. In these definitions, the lexical semantic relation only involves two
words that are morphologically related. Being members of the same derivational family, the orthographic
representations of these words show some degree of similarity that can help us identify the morphological
definitions. In (2) for example, the written forms nitrificateur ?nitrifying? and nitrification ?nitrification?
share a 10 letters prefix and only differ by 3 letters. This strong similarity is a reliable indicator of their
morphologically relatedness (Hathout, 2011b). Building on this observation, a definition is likely to be
morphological if its definiens contains a word which is orthographically similar to the definiendum.
(2) nitrificateur
A
= Qui produit, qui favorise la nitrification.
?nitrifying? ?that produces, that favors nitrification?
We used Proxinette, a measure of morphological similarity defined in (Hathout, 2008), to identify the
morphological definitions. Proxinette is designed to reduce the search space for derivational analogies.
The reduction is obtained by bringing closer the words that belong to the same derivational families and
series, since it is precisely within these paradigms that an entry is likely to form analogies (Hathout,
2011a). Proxinette describes the lexemes by all the n-grams of characters that appear in their inflected
forms in order to catch the inflectional stem allomorphy because it tends to also show up in derivation
(Bonami et al., 2009). The n-grams have an additional tag that indicates if they occur at the beginning,
at the end or in the middle of the word. This information is described by adding a # at the beginning
and end of the written forms. For example, in Figure 4, localisation ?localization?, localiser ?localize;
locate? and focalisation ?focalization? share the ions# ending because it occurs in their inflected forms
localisations (plural), localisions (1st person plural, indicative, imperfect) and focalisations (plural). n-
grams of size 1 and 2 are ignored because they occur in too many words and are not discriminant enough.
Proxinette builds a bipartite graph with the words of the lexicon on one side and the features (n-grams)
that characterize them on the other. Each word is linked to all its features and each feature is connected
to the words that own it (see Figure 4). The graph is weighted so that the sum of weights of the outgoing
edges of each node is equal to 1. Morphological similarity is estimated by simulating the spreading of
an activation. For a given entry, an activation is initiated at the node that represents it. This activation is
then propagated towards the features of the entry. In a second step, the activations in the feature nodes
are propagated towards the words that possess them. The words which obtain the highest activations are
the most similar to the entry. The edge weights and the way the graph is traversed brings closer the words
that share the largest number of common features and the most specific ones (i.e. the less frequent).
69
focalisation N
localiser V
#local
ocali
alisat
ation#
list
#foca
localiste A
localisation N
Figure 4: Excerpt of Proxinette bipartite graph. The graph is symmetric.
?
echolocalisation N relocalisation N radiolocalisation N g
?
eolocalisation N glocalisation N d
?
elocalisation N
antid
?
elocalisation A localisateur N localisateur A vocalisation N focalisation N localiser V localisable A
d
?
elocalisateur N localis
?
e A localiste N localiste A localisme N tropicalisation N
Figure 5: The most similar words to the noun localisation. Words in boldface belong to the derivational
family of localisation. Words in light type belong to its derivational series.
We applied Proxinette to GLAWI-HW and calculated for each of them a neighborhood consisting of
the 100 most similar words. Figure 5 shows an excerpt of the neighborhood of the noun localisation.
The occurrence of the verb localiser in this list enables us to identify the morphological definition (3).
(3) localisation
N
= Action de localiser, de se localiser.
?localization? ?the act of localizing, of locating?
The two experiments we conducted use the same data, namely the morphological definitions of GLAWI.
These definitions are selected as follows:
1. We extracted all GLAWI definition glosses (definientia) with their entries and POS (definienda).
2. We syntactically parsed the definientia with the Talismane dependency parser (Urieli, 2013). Figure
6 presents the dependencies syntactic trees for the definientia in (4).
3. We tagged as morphological all definitions where, in the parsed definiens, at least one lemma
(henceforth referred to as morphosemantic head) occurs in the definiendum neighborhood. For
example, in (4), both definitions are tagged as morphological because arr?eter occurs in the neigh-
borhood of arr?et, and d?ecouronner and couronne occur in that of d?ecouronnement.
(4) a. arr?et
N
= Action de la main pour arr?eter le cheval.
?stop? ?action of the hand to stop the horse?
b. d?ecouronnement
N
= L?action de d?ecouronner, d?enlever la couronne.
?uncrowning? ?the act of uncrowning, of removing the crown?
Morphosemantic heads may be the derivational base of the definiendum like d?ecouronner, a more distant
ancestor like couronne or a ?sibling? like in (2) where nitrification is a derivative of the definiendum base
nitrifier ?nitrify?.
Action de la main pour arr?ter le chevalNC P DET NC P VINF DET NC
dep detprep dep prep detobj L'action de d?couronner, d'enlever la couronneNC PDET P VINF DET NCVINF
detdet dep prep dep prep obj
Figure 6: POS-tags and syntactic dependencies of the definientia of (4).
70
6 Acquisition of morphological relations from GLAWI morphological definitions
We extracted from GLAWI?s morphological definitions the pairs of words (w
1
, w
2
) where w
1
is the
definiendum and w
2
the definiens morphosemantic heads (or one of its morphosemantic head if it has
many). After symmetrization, we obtained a lexicon (hereafter GMD) of 107,628 pairs. 32,256 of them
belongs to GMS. A manual check of the 75,372 remaining pairs would enable its addition to GMS.
GMD additional pairs have been evaluated by three judges in two steps. The judges were instructed to
set aside the orthographic variants as desperado N / desp?erado N. We first randomly selected 100 pairs
and had them checked by three judges in order to estimate the inter-annotator agreement. The average
F-measure of the agreement is 0.97 ; Fleiss?s kappa is 0.65. The judges then checked 100 randomly
selected pairs each. 9 out of the 300 pairs were variants and 19 errors were found in the 291 remaining
ones which results in an overall accuracy of 93.5%. This method would lead to an increase of GMS by
more than 70,000 pairs.
The general quality of these acquired pairs can be significantly increased by formal analogy filter-
ing. The idea is to use analogy as a proxy to find pairs of words that are in the same morphological
relation. GMS pairs being provided by Wiktionary contributors, we consider them as correct and use
them as analogical patterns to filter out the pairs acquired from the morphological definitions. By formal
analogy, we mean an analogy between the orthographic representations. For instance, the GMD pair cit-
rique A:citron N form an analogy with ?electrique A:?electron N. The latter being correct, we can assume
that the former is correct too.
(5) a. citrique A : citron N = ?electrique A : ?electron N
b. fragmentation N : d?efragmenter V = concentration N : d?econcentrer V
Analogies between strings are called formal analogies (Lepage, 2003; Stroppa and Yvon, 2005). One
way to check a formal analogy is to find a decomposition (or factorization) of the four strings such that
the differences between the first two are identical to the ones between the second two. In the analogy
in (5a), the ending ique is replaced by on and the POS A by N in both pairs. We applied analogical
filtering to GMS and GMD pairs. 86,228 pairs in GMD form at least one analogy with a pair in GMS;
53,972 of them do not occur in GMS. 300 of these pairs have been checked by three judges. They only
found 3 variants and one error. The obtained accuracy is therefore over 99% (see Table 1).
5
initial analogical
pairs accuracy pairs accuracy
GMS 97,058 ? ? ?
GMD 107,628 95.4% 86,228 99.8%
GMD \ GMS 75,372 93.5% 53,972 99.7%
Table 1: Summary of the quantitative results
GMD morphological relations will not be included into GLAWI. GMS and GMD are made available
as separate resources on the GLAWI web page.
7 Semantic typing of the morphological definitions
The next experiment aims to demonstrate that morphological definitions could easily and quite accurately
be typed semantically. We focus on a particular semantic type, namely definitions of process nominals
such as (6) because they can be evaluated with respect to the Verbaction database (Hathout and Tanguy,
2002). Deverbal nominals have been extensively studied in linguistics (Pustejovsky, 1995) and used
in a number of tools for various tasks. One of their distinctive feature is that they almost have the
same meaning as their base verb. For instance, in (7) the noun and verb phrases are paraphrases of one
another. Verbaction contains 9,393 verb-noun pairs where the noun is morphologically related to the
verb and can be used to express the act denoted by the verb (e.g. verrouiller:verrouillage).
6
It has been
5
Unfortunately, these results could not have been compared with those of Pentheroudakis and Vanderwende (1993) because
their system makes use of a number of lexical and semantic resources that are not available for French. However, a comparison
with Baroni et al. (2002) is underway although their method is corpus-based (and not MRD-based).
6
Verbaction is freely available at: http://redac.univ-tlse2.fr/lexiques/verbaction.html.
71
used in syntactic dependency parsing by Bourigault (2007), in the construction of the French TimeBank
by Bittar et al. (2011), in question answering systems by Bernhard et al. (2011), etc.
(6) verrouillage
N
= Action de verrouiller.
?locking? ?the act of locking.?
(7) nous v
?
erouillons la porte rapidement ?we quickly lock the gate?
le verrouillage de la porte est rapide ?gate locking is quick?
In our experiment, we used the linear SVM classifier liblinear of Fan et al. (2008) to assign a semantic
type to the definitions that have a nominal definiendum and where the morphosemantic head of the
definiens is a verb as in (4) or (6). Verbaction was used to select a corpus of 1,198 of such definitions.
Three judges annotated them. 608 definientia were tagged as processive and 590 ones as non processive.
We then divided the corpus into a test set made up of 100 processive and 100 non processive definitions
and a training set consisting of the remaining definientia.
The classifier is trained to recognize that the definientia in (4) express the same semantic relation
between the morphosemantic head of the definiens and the definiendum. We use the method proposed
by (Hathout, 2008) to capture this semantic similarity. Definientia are described by a large number
of redundant features based on lemmata, POSs and syntactic dependencies. The features are n-grams
calculated from Talismane parses (see figure 6). They are defined as follows:
1. We first collect all the paths that go from one word in the definiens to the syntactic root (e.g. [arr?eter,
pour, action] is a path that starts at arr?eter in (4a)).
2. We extract all the n-grams of consecutive nodes in these paths.
3. Each n-gram yields 3 features: the sequence of the node?s lemmata, the sequence of the nodes POS,
and the sequence of syntactic dependency relations.
We obtained an accuracy of 97% for the semantic typing of the 200 definientia of the test set. The
most immediate application of the classifier is the enrichment of Verbaction. Running the classifier on
all the definitions with a nominal definiendum and a verbal morphosemantic head will provide us with
new couples that could be added to the database. The classifier could also help us type process nouns
that are not morphologically derived such as audition ?hearing? which is defined with respect to the verb
entendre ?hear?. Similar typing could be performed for other semantic types such as agent nouns (in -eur
or -ant), change of state verbs (in -iser or -ifier) or adjectives expressing possibility (in -able), etc. The
experiment also shows that morphological definitions are well suited for semantic analysis because they
express regular semantic relationship between pairs of words that are distinguished by their orthographic
similarity.
8 Conclusion
In this paper, we have presented GLAWI, an XML machine-readable dictionary created from Wiktion-
naire, the French edition of the Wiktionary project. We then showed that GLAWI was well suited for
conducting computational morphology experiments. GLAWI contains morphological subsections which
provide a significant number of valid and varied morphological relations. In addition, morphological re-
lations can also be acquired from GLAWI morphological definitions. We presented a method to identify
these definitions and the words in relation with a fairly good accuracy. We then used formal analogy to
filter out almost all the erroneous pairs acquired from morphological definitions. In a second experiment,
we demonstrate how to assign the morphological definitions to semantic types with a high accuracy.
This work opens several research avenues leading to a formal representation of the different form
and meaning relations that underlie derivational morphology. The next move will be to organize the
morphological relations into a graph similar to D?emonette (Hathout and Namer, 2014) and identify the
paradigms which structure them. We also plan to apply the semantic classification to other semantic
types which could ultimately enable us to explore the intricate interplay between form and meaning.
72
References
Leticia Anton P?erez, Hugo Gonc?alo Oliveira, and Paulo Gomes. 2011. Extracting Lexical-Semantic Knowledge
from the Portuguese Wiktionary. In Proceedings of the 15th Portuguese Conference on Artificial Intelligence,
EPIA 2011, pages 703?717, Lisbon, Portugal.
Rolf Harald Baayen, Richard Piepenbrock, and Leon Gulikers. 1995. The CELEX lexical database (release 2).
CD-ROM. Linguistic Data Consortium, Philadelphia, PA.
Marco Baroni, Johannes Matiasek, and Harald Trost. 2002. Unsupervised discovery of morphologically related
words based on orthographic and semantic similarity. In Proceedings of the Workshop on Morphological and
Phonological Learning of ACL-2002, pages 48?57, Philadelphia, PA, USA.
Delphine Bernhard, Bruno Cartoni, and Delphine Tribout. 2011. A Task-Based Evaluation of French Morpholog-
ical Resources and Tools. Linguistic Issues in Language Technology, 5(2).
Andr?e Bittar, Pascal Amsili, Pascal Denis, et al. 2011. French TimeBank: un corpus de r?ef?erence sur la temporalit?e
en franc?ais. In Actes de la 18e Conf?erence Annuelle sur le Traitement Automatique des Langues Naturelles
(TALN-2011), volume 1, pages 259?270, Montpellier, France.
Olivier Bonami, Gilles Boy?e, and Franc?oise Kerleroux. 2009. L?allomorphie radicale et la relation flexion-
construction. In Bernard Fradin, Franc?oise Kerleroux, and Marc Pl?enat, editors, Aperc?us de morphologie du
franc?ais, pages 103?125. Presses universitaires de Vincennes, Saint-Denis.
Didier Bourigault. 2007. Un analyseur syntaxique op?erationnel : SYNTEX. Habilitation
`a diriger des recherches,
Universit?e Toulouse II-Le Mirail, Toulouse.
Nicoletta Calzolari, Laura Pecchia, and Antonio Zampolli. 1973. Working on the Italian Machine Dictionary:
A Semantic Approach. In Proceedings of the 5th Conference on Computational Linguistics - Volume 2, pages
49?52, Stroudsburg, PA, USA.
Nicoletta Calzolari. 1988. The dictionary and the thesaurus can be combined. In Martha Evens, editor, Relational
Models of the Lexicon, pages 75?96. Cambridge University Press.
Martin S. Chodorow, Roy J. Byrd, and George E. Heidorn. 1985. Extracting semantic hierarchies from a large
on-line dictionary. In Proceedings of the 23rd Annual Meeting on Association for Computational Linguistics,
ACL ?85, pages 299?304, Stroudsburg, PA, USA.
James R. Curran and Marc Moens. 2002. Improvements in Automatic Thesaurus Extraction. In Proceedings of
the ACL Workshop on Unsupervised Lexical Acquisition, pages 59?66, Philadelphia, USA.
Jacques Dendien. 1994. Le projet d?informatisation du TLF. In
?
Eveline Martin, editor, Les textes et
l?informatique, chapter 3, pages 31?63. Didier
?
Erudition, Paris, France.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for
large linear classification. The Journal of Machine Learning Research, 9:1871?1874.
Nabil Hathout and Fiammetta Namer. 2014. La base lexicale d?emonette : entre s?emantique constructionnelle et
morphologie d?erivationnelle. In Actes de la 21e conf?erence annuelle sur le traitement automatique des langues
naturelles (TALN-2014), Marseille, France.
Nabil Hathout and Ludovic Tanguy. 2002. Webaffix : Finding and validating morphological links on the WWW.
In Proceedings of the Third International Conference on Language Resources and Evaluation, pages 1799?
1804, Las Palmas de Gran Canaria, Spain.
Nabil Hathout. 2008. Acquisition of the morphological structure of the lexicon based on lexical similarity and
formal analogy. In Proceedings of the Coling workshop Textgraphs-3, pages 1?8, Manchester, England.
Nabil Hathout. 2011a. Morphonette: a paradigm-based morphological network. Lingue e linguaggio,
2011(2):243?262.
Nabil Hathout. 2011b. Une approche topologique de la construction des mots : propositions th?eoriques et appli-
cation `a la pr?efixation en anti-. In Des unit?es morphologiques au lexique (Roch
?e et al., 2011), pages 251?318.
Kris Heylen, Yves Peirsman, Dirk Geeraerts, and Dirk Speelman. 2008. Modelling Word Similarity: an Eval-
uation of Automatic Synonymy Extraction Algorithms. In Proceedings of the Sixth International Language
Resources and Evaluation (LREC?08), Marrakech, Morocco.
73
Mathieu Lafourcade. 2007. Making People Play for Lexical Acquisition with the JeuxDeMots prototype. In
SNLP?07: 7th International Symposium on Natural Language Processing, Pattaya, Thailand.
Yves Lepage. 2003. De l?analogie rendant compte de la commutation en linguistique. Habilitation `a diriger des
recherches, Universit?e Joseph Fourier, Grenoble.
Judith Markowitz, Thomas Ahlswede, and Martha Evens. 1986. Semantically significant patterns in dictionary
definitions. In Proceedings of the 24th Annual Meeting on Association for Computational Linguistics, pages
112?119, Stroudsburg, PA, USA.
Robert Martin. 1983. Pour une logique du sens. Linguistique nouvelle. Presses universitaires de France, Paris.
Emmanuel Navarro, Franck Sajous, Bruno Gaume, Laurent Pr?evot, ShuKai Hsieh, Ivy Kuo, Pierre Magistry, and
Chu-Ren Huang. 2009. Wiktionary and NLP: Improving synonymy networks. In Proceedings of the 2009
ACL-IJCNLP Workshop on The People?s Web Meets NLP: Collaboratively Constructed Semantic Resources,
pages 19?27, Singapore.
Roberto Navigli and Simone Paolo Ponzetto. 2010. BabelNet: Building a Very Large Multilingual Semantic
Network. In Proceedings of ACL?2010, pages 216?225, Uppsala, Sweden.
Joseph Pentheroudakis and Lucy Vanderwende. 1993. Automatically identifying morphological relations in
machine-readable dictionaries. In Proceedings of the Ninth Annual Conference of the UW Centre for the New
OED and Text Research, pages 114?131.
Jean-Marie Pierrel. 2013. Structuration et usage de ressources lexicales institutionnelles sur le franc?ais. Linguis-
ticae investigationes Supplementa, pages 119?152.
James Pustejovsky. 1995. The Generative Lexicon. MIT Press, Cambridge, MA.
Michel Roch?e, Gilles Boy?e, Nabil Hathout, St?ephanie Lignon, and Marc Pl?enat. 2011. Des unit?es morphologiques
au lexique. Herm`es Science-Lavoisier, Paris.
Beno??t Sagot and Darja Fi?ser. 2008. Building a Free French Wordnet from Multilingual Resources. In Proceedings
of OntoLex 2008, Marrakech, Morocco.
Franck Sajous, Nabil Hathout, and Basilio Calderone. 2013a. GL
`
AFF, un Gros Lexique
`
A tout Faire du Franc?ais.
In Actes de la 20e conf?erence sur le Traitement Automatique des Langues Naturelles (TALN?2013), pages 285?
298, Les Sables d?Olonne, France.
Franck Sajous, Emmanuel Navarro, Bruno Gaume, Laurent Pr?evot, and Yannick Chudy. 2013b. Semi-automatic
enrichment of crowdsourced synonymy networks: the WISIGOTH system applied to Wiktionary. Language
Resources and Evaluation, 47(1):63?96.
Patrick Schone and Daniel S. Jurafsky. 2000. Knowledge-free induction of morphology using latent semantic
analysis. In Proceedings of the Conference on Natural Language Learning 2000 (CoNLL-2000), pages 67?72,
Lisbon, Portugal.
Gilles S?erasset. 2012. Dbnary: Wiktionary as a LMF based Multilingual RDF network. In Proceedings of the
Eigth International Conference on Language Resources and Evaluation (LREC 2012), Istanbul, Turkey.
Nicolas Stroppa and Franc?ois Yvon. 2005. An analogical learner for morphological analysis. In Procs. of the 9th
Conference on Computational Natural Language Learning (CoNLL-2005), pages 120?127, Ann Arbor, MI.
Assaf Urieli. 2013. Robust French syntax analysis: reconciling statistical methods and linguistic knowledge in
the Talismane toolkit. Th`ese de doctorat, Universit?e de Toulouse-Le Mirail.
Lonneke van der Plas and Gosse Bouma. 2005. Syntactic Contexts for Finding Semantically Related Words. In
Ton van der Wouden, Michaela Po?, Hilke Reckman, and Crit Cremers, editors, Computational Linguistics in
the Netherlands 2004: Selected papers from the fifteenth CLIN meeting, volume 4 of LOT Occasional Series.
Utrecht University.
Torsten Zesch and Iryna Gurevych. 2010. Wisdom of Crowds versus Wisdom of Linguists - Measuring the
Semantic Relatedness of Words. Journal of Natural Language Engineering., 16(01):25?59.
Torsten Zesch, Christof M?uller, and Iryna Gurevych. 2008. Extracting Lexical Semantic Knowledge from
Wikipedia and Wiktionary. In Proceedings of the Sixth International Conference on Language Resources and
Evaluation (LREC 2008), Marrakech, Morocco.
Pierre Zweigenbaum and Natalia Grabar. 2003. Learning derived words from medical corpora. In 9th Conference
on Artificial Intelligence in Medicine Europe, pages 189?198.
74
