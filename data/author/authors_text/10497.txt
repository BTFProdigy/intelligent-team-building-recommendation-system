Event Detection and Summarization in Weblogs with Temporal Collocations 
Chun-Yuan Teng and Hsin-Hsi Chen 
Department of Computer Science and Information Engineering 
National Taiwan University 
Taipei, Taiwan 
{r93019, hhchen}@csie.ntu.edu.tw 
Abstract 
 
This paper deals with the relationship between weblog content and time. With the proposed temporal mutual information, we analyze 
the collocations in time dimension, and the interesting collocations related to special events. The temporal mutual information is 
employed to observe the strength of term-to-term associations over time. An event detection algorithm identifies the collocations that 
may cause an event in a specific timestamp. An event summarization algorithm retrieves a set of collocations which describe an event. 
We compare our approach with the approach without considering the time interval. The experimental results demonstrate that the 
temporal collocations capture the real world semantics and real world events over time. 
 
1. 
2. 
Introduction 
Compared with traditional media such as online news 
and enterprise websites, weblogs have several unique 
characteristics, e.g., containing abundant life experiences 
and public opinions toward different topics, highly 
sensitive to the events occurring in the real world, and 
associated with the personal information of bloggers. 
Some works have been proposed to leverage these 
characteristics, e.g., the study of the relationship between 
the content and bloggers? profiles (Adamic & Glance, 
2005; Burger & Henderson, 2006; Teng & Chen, 2006), 
and content and real events (Glance, Hurst & Tornkiyo, 
2004; Kim, 2005; Thelwall, 2006; Thompson, 2003). 
In this paper, we will use temporal collocation to 
model the term-to-term association over time.  In the past, 
some useful collocation models (Manning & Sch?tze, 
1999) have been proposed such as mean and variance, 
hypothesis test, mutual information, etc. Some works 
analyze the weblogs from the aspect of time like the 
dynamics of weblogs in time and location (Mei, et al, 
2006), the weblog posting behavior (Doran, Griffith & 
Henderson, 2006; Hurst, 2006), the topic extraction (Oka, 
Abe & Kato, 2006), etc. The impacts of events on social 
media are also discussed, e.g., the change of weblogs after 
London attack (Thelwall, 2006), the relationship between 
the warblog and weblogs (Kim, 2005; Thompson, 2003), 
etc. 
This paper is organized as follows. Section 2 defines 
temporal collocation to model the strength of term-to-term 
associations over time.  Section 3 introduces an event 
detection algorithm to detect the events in weblogs, and 
an event summarization algorithm to extract the 
description of an event in a specific time with temporal 
collocations. Section 4 shows and discusses the 
experimental results.  Section 5 concludes the remarks. 
Temporal Collocations 
We derive the temporal collocations from Shannon?s 
mutual information (Manning & Sch?tze, 1999) which is 
defined as follows (Definition 1). 
Definition 1 (Mutual Information) The mutual 
information of two terms x and y is defined as: 
)()(
),(log),(),(
yPxP
yxPyxPyxI =  
where P(x,y) is the co-occurrence probability of x and y, 
and P(x) and P(y) denote the occurrence probability of x 
and y, respectively. 
Following the definition of mutual information, we 
derive the temporal mutual information modeling the 
term-to-term association over time, and the definition is 
given as follows.  
 Definition 2 (Temporal Mutual Information) Given 
a timestamp t and a pair of terms x and y, the temporal 
mutual information of x and y in t is defined as: 
)|()|(
)|,(log)|,()|,(
tyPtxP
tyxPtyxPtyxI =
where P(x,y|t) is the probability of co-occurrence of terms 
x and y in timestamp t, P(x|t) and P(y|t) denote the 
probability of occurrences of x and y in timestamp t, 
respectively. 
To measure the change of mutual information in time 
dimension, we define the change of temporal mutual 
information as follows. 
Definition 3 (Change of Temporal Mutual 
Information) Given time interval [t1, t2], the change of 
temporal mutual information is defined as: 
12
12
21
)|,()|,(),,,(
tt
tyxItyxIttyxC ?
?=  
where C(x,y,t1,t2) is the change of temporal mutual 
information of terms x and y in time interval [t1, t2], I(x,y| 
t1) and I(x,y| t2) are the temporal mutual information in 
time t1 and t2, respectively. 
3. Event Detection 
Event detection aims to identify the collocations 
resulting in events and then retrieve the description of 
events. Figure 1 sketches an example of event detection. 
The weblog is parsed into a set of collocations. All 
collocations are processed and monitored to identify the 
plausible events.  Here, a regular event ?Mother?s day? 
and an irregular event ?Typhoon Chanchu? are detected.  
The event ?Typhoon Chanchu? is described by the words  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: An Example of Event Detection
?Typhoon?, ?Chanchu?, ?2k?, ?Eye?, ?Path? and 
?chinaphillippine?.  
The architecture of an event detection system includes 
a preprocessing phase for parsing the weblogs and 
retrieving the collocations; an event detection phase 
detecting the unusual peak of the change of temporal 
mutual information and identifying the set of collocations 
which may result in an event in a specific time duration; 
and an event summarization phase extracting the 
collocations related to the seed collocations found in a 
specific time duration. 
The most important part in the preprocessing phase is 
collocation extraction. We retrieve the collocations from 
the sentences in blog posts. The candidates are two terms 
within a window size. Due to the size of candidates, we 
have to identify the set of tracking terms for further 
analysis. In this paper, those candidates containing 
stopwords or with low change of temporal mutual 
information are removed. 
In the event detection phase, we detect events by 
using the peak of temporal mutual information in time 
dimension.  However, the regular pattern of temporal 
mutual information may cause problems to our detection. 
Therefore, we remove the regular pattern by seasonal 
index, and then detect the plausible events by measuring 
the unusual peak of temporal mutual information. 
If a topic is suddenly discussed, the relationship 
between the related terms will become higher. Two 
alternatives including change of temporal mutual 
information and relative change of temporal mutual 
information are employed to detect unusual events. Given 
timestamps t1 and t2 with temporal mutual information 
MI1 and MI2, the change of temporal mutual information 
is calculated by (MI2-MI1). The relative change of 
temporal mutual information is calculated by (MI2-
MI1)/MI1. 
For each plausible event, there is a seed collocation, 
e.g., ?Typhoon Chanchu?. In the event description 
retrieval phase, we try to select the collocations with the 
highest mutual information with the word w in a seed 
collocation. They will form a collocation network for the 
event.  Initially, the seed collocation is placed into the 
network.  When a new collocation is added, we compute 
the mutual information of the multiword collocations by 
the following formula, where n is the number of 
collocations in the network up to now. 
?= n iMInInformatioMutualMultiwo  
If the multiword mutual information is lower than a 
threshold, the algorithm stops and returns the words in the 
collocation network as a description of the event.  Figure 
2 sketches an example.  The collocations ?Chanchu?s 
path?, ?Typhoon eye?, and ?Chanchu affects? are added 
into the network in sequence based on their MI. 
We have two alternatives to add the collocations to 
the event description. The first method adds the 
collocations which have the highest mutual information 
as discussed above. In contrast, the second method adds 
the collocations which have the highest product of mutual 
information and change of temporal mutual information. 
 
 
 
 
 
 
Figure 2: An Example of Collocation network 
4. 
4.1. 
Experiments and Discussions 
Temporal Mutual Information versus 
Mutual Information 
In the experiments, we adopt the ICWSM weblog data 
set (Teng & Chen, 2007; ICWSM, 2007). This data set 
collected from May 1, 2006 through May 20, 2006 is 
about 20 GB. Without loss of generality, we use the 
English weblog of 2,734,518 articles for analysis. 
To evaluate the effectiveness of time information, we 
made the experiments based on mutual information 
(Definition 1) and temporal mutual information 
(Definition 2). The former called the incremental 
approach measures the mutual information at each time 
point based on all available temporal information at that 
time. The latter called the interval-based approach 
considers the temporal mutual information in different 
time stamps.  Figures 3 and 4 show the comparisons 
between interval-based approach and incremental 
approach, respectively, in the event of Da Vinci Code.   
We find that ?Tom Hanks? has higher change of 
temporal mutual information compared to ?Da Vinci 
Code?. Compared to the incremental approach in Figure 4, 
the interval-based approach can reflect the exact release 
date of ?Da Vinci Code.? 
 rd
=i 1 4.2. Evaluation of Event Detection 
We consider the events of May 2006 listed in 
wikipedia1 as gold standard. On the one hand, the events 
posted in wikipedia are not always complete, so that we 
adopt recall rate as our evaluation metric.  On the other 
hand, the events specified in wikipedia are not always 
discussed in weblogs.  Thus, we search the contents of 
blog post to verify if the events were touched on in our 
blog corpus. Before evaluation, we remove the events 
listed in wikipedia, but not referenced in the weblogs. 
 
 
 
 
 
 
 
 
 
 
 
Figure 3: Interval-based Approach in Da Vinci Code  
 
 
 
 
 
 
 
 
Figure 4: Incremental Approach in Da Vinci Code 
gure 5 sketches the idea of evaluation.  The left side 
of t s figure shows the collocations detected by our event 
dete tion system, and the right side shows the events 
liste  in wikipedia.  After matching these two lists, we 
can find that the first three listed events were correctly 
identified by our system.  Only the event ?Nepal Civil 
War? was listed, but not found. Thus, the recall rate is 
75% in this case. 
 
 
 
 
 
 
 
Figure 5: Evaluation of Event Detection Phase 
As discussed in Section 3, we adopt change of 
temporal mutual information, and relative change of 
temporal mutual information to detect the peak. In Figure 
6, we compare the two methods to detect the events in 
weblogs. The relative change of temporal mutual 
information achieves better performance than the change 
of temporal mutual information. 
                                                     
1 http://en.wikipedia.org/wiki/May_2006 
Table 1 and Table 2 list the top 20 collocations based 
on these two approaches, respectively. The results of the 
first approach show that some collocations are related to 
the feelings such as ?fell left? and time such as ?Saturday 
night?. In contrast, the results of the second approach 
show more interesting collocations related to the news 
events at that time, such as terrorists ?zacarias 
moussaoui? and ?paramod mahajan.? These two persons 
were killed in May 3. Besides, ?Geena Davis? got the 
golden award in May 3. That explains why the 
collocations detected by relative change of temporal 
mutual information are better than those detected by 
change of temporal mutual information. 
-20
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6: Performance of Event Detection Phase 
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
Collocations CMI Collocations CMI 
May 03 9276.08 Current music 1842.67
Illegal immigrants 5833.17 Hate studying 1722.32
Feel left 5411.57 Stephen Colbert 1709.59
Saturday night 4155.29 Thursday night 1678.78
Past weekend 2405.32 Can?t believe 1533.33
White house 2208.89 Feel asleep 1428.18
Red sox 2208.43 Ice cream 1373.23
Album tool 2120.30 Oh god 1369.52
Sunday morning 2006.78 Illegalimmigration 1368.12
16.56
f 
CMI
32.50
31.63
29.09
28.45
28.34
28.13Sunday night 1992.37 Pretty cool 13
Table 1: Top 20 collocations with highest change o
temporal mutual information 
Collocations CMI Collocations 
casinos online 618.36 Diet sodas 
zacarias moussaoui 154.68 Ving rhames 
Tsunami warning 107.93 Stock picks 
Conspirator zacarias 71.62 Happy hump 
Artist formerly 57.04 Wong kan 
Federal  
Jury 
41.78 Sixapartcom 
movabletype Wed 3 39.20 Aaron echolls 27.48
Pramod mahajan 35.41 Phnom penh 25.78
BBC  
Version 
35.21 Livejournal 
sixapartcom 
23.83  Fi
hi
c
dGeena davis 33.64 George yeo 20.34
Table 2: Top 20 collocations with highest relative change 
of mutual information 
4.3. Evaluation of Event Summarization 
As discussed in Section 3, we have two methods to 
include collocations to the event description. Method 1 
employs the highest mutual information, and Method 2 
utilizes the highest product of mutual information and 
change of temporal mutual information. Figure 7 shows 
the performance of Method 1 and Method 2. We can see 
that the performance of Method 2 is better than that of 
Method 1 in most cases. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7: Overall Performance of Event Summarization 
The results of event summarization by Method 2 are 
shown in Figure 8. Typhoon Chanchu appeared in the 
Pacific Ocean on May 10, 2006, passed through 
Philippine and China and resulted in disasters in these 
areas on May 13 and 18, 2006.  The appearance of the 
typhoon Chanchu cannot be found from the events listed 
in wikipedia on May 10.  However, we can identify the 
appearance of typhoon Chanchu from the description of 
the typhoon appearance such as ?typhoon named? and 
?Typhoon eye.  In addition, the typhoon Chanchu?s path 
can also be inferred from the retrieved collocations such 
as ?Philippine China? and ?near China?. The response of 
bloggers such as ?unexpected typhoon? and ?8 typhoons? 
is also extracted.   
 
 
 
 
 
 
 
 
 
 
Figure 8: Event Summarization for Typhoon Chanchu 
5. Concluding Remarks 
This paper introduces temporal mutual information to 
capture term-term association over time in weblogs. The 
extracted collocation with unusual peak which is in terms 
of relative change of temporal mutual information is 
selected to represent an event.  We collect those 
collocations with the highest product of mutual 
information and change of temporal mutual information 
to summarize the specific event.  The experiments on 
ICWSM weblog data set and evaluation with wikipedia 
event lists at the same period as weblogs demonstrate the 
feasibility of the proposed temporal collocation model 
and event detection algorithms. 
Currently, we do not consider user groups and 
locations. This methodology will be extended to model 
the collocations over time and location, and the 
relationship between the user-preferred usage of 
collocations and the profile of users. 
Acknowledgments 
Research of this paper was partially supported by 
National Science Council, Taiwan (NSC96-2628-E-002-
240-MY3) and Excellent Research Projects of National 
Taiwan University (96R0062-AE00-02). 
References 
Adamic, L.A., Glance, N. (2005). The Political 
Blogosphere and the 2004 U.S. Election: Divided 
They Blog. In: Proceedings of the 3rd International 
Workshop on Link Discovery, pp. 36--43. 
Burger, J.D., Henderson J.C. (2006). An Exploration of 
Observable Features Related to Blogger Age. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
15--20. 
Doran, C., Griffith, J., Henderson, J. (2006). Highlights 
from 12 Months of Blogs. In: Proceedings of AAAI 
2006 Spring Symposium on Computational 
Approaches to Analysing Weblogs, pp. 30--33. 
Glance, N., Hurst, M., Tornkiyo, T. (2004). Blogpulse: 
Automated Trend Discovery for Weblogs. In: 
Proceedings of WWW 2004 Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Hurst, M. (2006). 24 Hours in the Blogosphere. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
73--77. 
ICWSM (2007). http://www.icwsm.org/data.html 
Kim, J.H. (2005). Blog as an Oppositional Medium? A 
Semantic Network Analysis on the Iraq War Blogs. In: 
Internet Research 6.0: Internet Generations. 
 
Manning, C.D., Sch?tze, H. (1999). Foundations of 
Statistical Natural Language Processing, The MIT 
Press, London England. 
Mei, Q., Liu, C., Su, H., Zhai, C. (2006). A Probabilistic 
Approach to Spatiotemporal Theme Pattern Mining on 
Weblogs. In: Proceedings of the 15th International 
Conference on World Wide Web, Edinburgh, Scotland, 
pp. 533--542. 
Oka, M., Abe, H., Kato, K. (2006). Extracting Topics 
from Weblogs Through Frequency Segments. In: 
Proceedings of WWW 2006 Annual Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Teng, C.Y., Chen, H.H. (2006). Detection of Bloggers? 
Interest: Using Textual, Temporal, and Interactive 
Features. In: Proceeding of IEEE/WIC/ACM 
International Conference on Web Intelligence, pp. 
366--369. 
Teng, C.Y., Chen, H.H. (2007). Analyzing Temporal 
Collocations in Weblogs. In: Proceeding of 
International Conference on Weblogs and Social 
Media, 303--304. 
Thelwall, M. (2006). Blogs During the London Attacks: 
Top Information Sources and Topics. In: Proceedings 
of 3rd Annual Workshop on the Weblogging 
Ecosystem: Aggregation, Analysis and Dynamics. 
Thompson, G. (2003). Weblogs, Warblogs, the Public 
Sphere, and Bubbles. Transformations, 7(2). 
Proceedings of NAACL-HLT 2013, pages 569?578,
Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational Linguistics
On Quality Ratings for Spoken Dialogue Systems ? Experts vs. Users
Stefan Ultes, Alexander Schmitt, and Wolfgang Minker
Ulm University
Albert-Einstein-Allee 43
89073 Ulm, Germany
{stefan.ultes,alexander.schmitt,wolfgang.minker}@uni-ulm.de
Abstract
In the field of Intelligent User Interfaces, Spo-
ken Dialogue Systems (SDSs) play a key role
as speech represents a true intuitive means
of human communication. Deriving informa-
tion about its quality can help rendering SDSs
more user-adaptive. Work on automatic esti-
mation of subjective quality usually relies on
statistical models. To create those, manual
data annotation is required, which may be per-
formed by actual users or by experts. Here,
both variants have their advantages and draw-
backs. In this paper, we analyze the relation-
ship between user and expert ratings by in-
vestigating models which combine the advan-
tages of both types of ratings. We explore two
novel approaches using statistical classifica-
tion methods and evaluate those with a pre-
existing corpus providing user and expert rat-
ings. After analyzing the results, we eventu-
ally recommend to use expert ratings instead
of user ratings in general.
1 Introduction and Motivation
In human-machine interaction it is important that
user interfaces can adapt to the specific requirements
of its users. Handicapped persons or angry users, for
example, have specific needs and should be treated
differently than regular users.
Speech is a major component of modern user in-
terfaces as it is the natural means of human com-
munication. Therefore, it seems logical to use Spo-
ken Dialogue Systems (SDS) as part of Intelligent
User Interfaces enabling speech communication of
different complexity reaching from simple spoken
commands up to complex dialogues. Besides the
spoken words, the speech signal also may be used
to acquire information about the user state, e.g.,
about their emotional state (cf., e.g., (Polzehl et
al., 2011))). By additional analysis of the human-
computer-dialogues, even more abstract informa-
tion may be derived, e.g., the quality of the system
(cf., e.g., (Engelbrecht and Mo?ller, 2010)). System
quality information may be used to adapt the sys-
tem?s behavior online during the ongoing dialogue
(cf. (Ultes et al, 2012)).
For determining the quality of Spoken Dialogue
Systems, several aspects are of interest. Mo?ller et
al. (2009) presented a taxonomy of quality criteria.
They describe quality as a bipartite issue consisting
of Quality of Service (QoS) and Quality of Experi-
ence (QoE). Quality of Service describes objective
criteria like dialogue duration or number of turns.
While these are well-defined items that can be de-
termined easily, Quality of Experience, which de-
scribes the user experience with subjective criteria,
is more vague and without a sound definition, e.g.,
User Satisfaction (US).
Subjective aspects like US are either determined
by using questionnaires like SASSI (Hone and Gra-
ham, 2000) or the ITU-standard augmented frame-
work for questionnaires (Mo?ller, 2003), or by us-
ing single-valued ratings, i.e., a rater only applies
one single score. In general, two major categories
of work on determining single-valued User Satisfac-
tion exist. The satisfaction ratings are applied either
? by users during or right after the dialogue or
? by experts by listening to recorded dialogues.
569
In this work, users or user raters are people who
actually perform a dialogue with the system and ap-
ply ratings while doing so. There is no constraint
about their expertise in the field of Human Com-
puter Interaction or Spoken Dialogue Systems: They
may be novices or have a high expertise. With ex-
perts or expert raters, we refer to people who are
not participating in the dialogue thus constituting
a completely different set of people. Expert raters
listen to recorded dialogues after the interactions
and rate them by assuming the point of view of the
actual person performing the dialogue. These ex-
perts are supposed to have some experience with di-
alogue systems. In this work, expert raters were ?ad-
vanced students of computer science and engineer-
ing? (Schmitt et al, 2011a).
For User Satisfaction, ratings applied by the users
seem to be clearly the better choice over ratings ap-
plied by third persons. However, determining true
User Satisfaction is only possible by asking real
users interacting with the system. Ideally, the ratings
are applied by users talking to a system employed in
the field, e.g., commercial systems, as these users
have real concerns.
For such Spoken Dialogue Systems, though, it
is not easy to get users to apply quality ratings
to the dialogue ? especially for each system-user-
exchange. The users would have to rate either by
pressing a button on the phone or by speech, which
would significantly influence the performance of the
dialogue. Longer dialogues imply longer call dura-
tions which cost money. Further, most callers only
want to quickly get some information from the sys-
tem. Therefore, it may be assumed that most users
do not want to engage in dialogues which are ar-
tificially made longer. This also inhabits the risk
that users who participated in long dialogues do
not want to call again. Therefore, collecting rat-
ings applied by users are considered to be expensive.
One possible way of overcoming the problem of rat-
ing input would be to use some special installation
which enables the users to provide ratings more eas-
ily (cf. (Schmitt et al, 2011b)). However, this is also
expensive and the system?s usability would be very
restricted. Further, this setup could most likely only
be used in a lab situation.
Expert raters, on the other hand, are able to simply
listen to the recorded dialogues and to apply ratings,
e.g., by using a specialized rating software. This
process is much easier and does not require the same
amount of effort needed for acquiring user ratings.
Further, as already pointed out, we refer to experts
as people who have some basic understanding of di-
alogue systems but are not required to be high-level
experts in the field. That is why we believe that these
people can be found easily.
As both categories of ratings have their advan-
tages and disadvantages, this contribution aims at
learning about the differences and similarities of
user and expert ratings with the ultimate goal of
either being able to predict user ratings more effi-
ciently or of advocating for replacing the use of user
ratings by using only expert ratings in general.
Therefore, this work analyzes the relation be-
tween quality ratings applied by user and expert
raters by analyzing approaches which take advan-
tage of both categories: Using the less expensive
rating process with expert raters and still predict-
ing real User Satisfaction ratings. Moreover, this
works? goal is to shed light on the question whether
information about one rating (in this case the less
expensive expert ratings) may be used to predict the
other rating (the more expensive user ratings). For
this, we present two approaches applying two differ-
ent statistical classification methods for a showcase
corpus. Results of both methods are compared to a
given baseline.
The remainder of this paper is organized as fol-
lows. First, we give a brief overview of work done
in both categories (user ratings vs. expert ratings) in
Section 2 and present our choice of data the analy-
sis in this paper is based on in Section 3. Further,
evaluation metrics are illustrated in Section 4 and
approaches on facilitating prediction of user rater
scores by expert rater information are presented in
Section 5 followed by an evaluation and discussion
of the results in Section 6.
2 Significant Related Work
Predicting User Satisfaction for SDSs has been in
the focus of research for many years, most famously
the PARADISE framework by Walker et al (1997).
The authors assume a linear dependency between
quantitative parameters derived from the dialogue
and US, modeling this dependency using linear re-
570
gression. Unfortunately, for generating the regres-
sion model, weighting factors have to be computed
for each system anew. This generates high costs
as dialogues have to be performed with real users
where each user further has to complete a question-
naire after completing the dialogue. Moreover, in
the PARADISE framework, only quality measure-
ment for the whole dialogue (or system) is allowed.
However, this is not suitable for using quality infor-
mation for online adaption of the dialogue (cf. (Ultes
et al, 2012)). Furthermore, PARADISE relies on
questionnaires while we focus on work using single-
valued ratings.
Numerous work on predicting User Satisfaction
as a single-valued rating task for each system-user-
exchange has been performed in both categories.
This work is briefly presented in the following.
2.1 Expert Ratings
Higashinaka et al (2010a) proposed a model to pre-
dict turn-wise ratings for human-human dialogues
(transcribed conversation) and human-machine di-
alogues (text from chat system). Ratings ranging
from 1-7 were applied by two expert raters label-
ing ?Smoothness?, ?Closeness?, and ?Willingness?
not achieving a Match Rate per Rating (MR/R)1 of
more than 0.2-0.24. This results are only slightly
above the random baseline of 0.14. Further work
by Higashinaka et al (2010b) uses ratings for over-
all dialogues to predict ratings for each system-
user-exchange. Again, evaluating in three user
satisfaction categories ?Smoothness?, ?Closeness?,
and ?Willingness? with ratings ranging from 1-7
achieved best performance of 0.19 MR/R.
Interaction Quality (IQ) has been introduced by
Schmitt et al (2011a) as an alternative performance
measure to User Satisfaction. In their terminology,
US ratings are only applied by users. As their pre-
sented measure uses ratings applied by expert raters,
a different term is used. Each system-user exchange
was annotated by three different raters using strict
guidelines. The ratings ranging from 1-5 are used
as target variable for statistical classifiers using a set
of automatically derivable interaction parameters as
input. They achieve a MR/R of 0.58.
1MR/R is equal to Unweighted Average Recall (UAR)
which is explained in Section 4.
2.2 User Ratings
An approach presented by Engelbrecht et al (2009)
uses Hidden Markov Models (HMMs) to model the
SDS as a process evolving over time. User Satisfac-
tion was predicted at any point within the dialogue
on a 5 point scale. Evaluation was performed based
on labels the users applied themselves during the di-
alogue.
Hara et al (2010) derived turn level ratings from
an overall score applied by the users after the dia-
logue. Using n-gram models reflecting the dialogue
history, the achieved results for recognizing User
Satisfaction on a 5 point scale showed to be hardly
above chance.
Work by Schmitt et al (2011b) deals with deter-
mining User Satisfaction from ratings applied by the
users themselves during the dialogues. A statistical
classification model was trained using automatically
derived interaction parameter to predict User Satis-
faction for each system-user-exchange on a 5-point
scale achieving an MR/R of 0.49.
3 Corpus
The corpus used by Schmitt et al (2011b) not only
contains user ratings but also expert ratings which
makes it a perfect candidate for our research pre-
sented in this paper. Adopting the terminology by
Schmitt et al, user ratings are described as User Sat-
isfaction (US) whereas expert ratings are referred to
with the term Interaction Quality (IQ) (cf. (Schmitt
et al, 2011a)). The data used for all experiments
of this work was collected by Schmitt et al (2011b)
during a lab user study with 38 users in the domain
of the ?Let?s Go Bus Information? system (Raux et
al., 2006) of the Carnegie Mellon University in Pitts-
burgh. 128 calls were collected consisting of a total
of 2,897 system-user exchanges. Both ratings, IQ
and US, are at a scale from 1 to 5 where 1 stands for
?extremely unsatisfied? and 5 for ?satisfied?. Each
dialogue starts with a rating of 5 as the user is ex-
pected to be satisfied in the beginning because noth-
ing unsatisfying has happened yet.
Further, the corpus also provides interaction pa-
rameters which may be used as input variables
for the IQ and US recognition models. These
parameters have been derived automatically from
three dialogue modules: Automatic Speech Recog-
571
s 1
u 1
s 2
u 2
s 3
u 3
s n
u n
?
e 1
e 2
e 3
e n
e n
?
e n-
1
e n-
2
e 1
e 2
e 3
e n+
1
?
ex
ch
an
ge
 le
ve
l p
ara
me
ter
s
wi
nd
ow
 le
ve
l p
ara
me
ter
s: 
{#
}, {
M
ea
n}
, e
tc.
dia
log
ue
 le
ve
l p
ara
me
ter
s: 
#, 
M
ea
n, 
etc
.
Figure 1: The three different modeling levels representing the interaction at exchange en: The most detailed exchange
level, comprising parameters of the current exchange; the window level, capturing important parameters from the
previous n dialog steps (here n = 3); the dialog level, measuring overall performance values from the entire previous
interaction.
nition, Spoken Language Understanding, and Dia-
logue Management. Furthermore, the parameters
are modeled on three different levels (see Figure 1):
? Exchange level parameters can be derived di-
rectly from the respective dialogue modules,
e.g., ASRConfidence.
? Dialogue level parameters consist of counts (#),
means (Mean), etc. of the exchange level pa-
rameters calculated from all exchanges of the
whole dialogue up to the current exchange, e.g.,
MeanASRConfidence.
? Window level parameters consist of counts
({#}), means ({Mean}), etc. of the exchange
level parameters calculated from the last three
exchanges, e.g., {Mean}ASRConfidence.
4 Evaluation metrics
For measuring the performance of the classification
algorithms, we rely on Unweighted Average Recall
(UAR), Cohen?s Kappa and Spearman?s Rho. The
latter two also represent a measure for similarity of
paired data. All measures will be briefly described
in the following:
Unweighted Average Recall The Unweighted Av-
erage Recall (UAR) is defined as the sum of all
class-wise recalls rc divided by the number of
classes |C|:
UAR =
1
|C|
?
c?C
rc . (1)
Recall rc for class c is defined as
rc =
1
|Rc|
|Rc|?
i=1
?hiri , (2)
where ? is the Kronecker-delta, hi and ri rep-
resent the corresponding hypothesis-reference-
pair of rating i, and |Rc| the total number of
all ratings of class c. In other words, UAR
for multi-class classification problems is the ac-
curacy corrected by the effects of unbalanced
data.
Cohen?s Kappa To measure the relative agreement
between two corresponding sets of ratings, the
number of label agreements corrected by the
chance level of agreement divided by the max-
imum proportion of times the labelers could
agree is computed. ? is defined as
? =
p0 ? pc
1? pc
, (3)
where p0 is the rate of agreement and pc is the
chance agreement (Cohen, 1960). As US and
IQ are on an ordinal scale, a weighting factor w
is introduced reducing the discount of disagree-
ments the smaller the difference is between two
ratings (Cohen, 1968):
w =
|r1 ? r2|
|rmax ? rmin|
. (4)
Here, r1 and r2 denote the rating pair and rmax
and rmin the maximal and minimal rating. This
results inw = 0 for agreement andw = 1 if the
ratings have maximal difference.
Spearman?s Rho The correlation of two variables
describes the degree by that one variable can be
expressed by the other. Spearman?s Rank Cor-
relation Coefficient is a non-parametric method
assuming a monotonic function between the
572
two variables (Spearman, 1904). It is defined
by
? =
?
i(xi ? x?)(yi ? y?)??
i(xi ? x?)
2
?
i(yi ? y?)
2
, (5)
where xi and yi are corresponding ranked rat-
ings and x? and y? the mean ranks. Thus, two
sets of ratings can have total correlation even if
they never agree. This would happen if all rat-
ings are shifted by the same value, for example.
5 Recognition of US Using IQ Information
As discussed in Section 1, automatic recognition of
ratings applied by users as performed by Schmitt et
al. (2011b) for User Satisfaction is time-consuming
and expensive. Therefore, approaches are presented
which facilitate expert ratings, i.e., Interaction Qual-
ity, with the hope of making US recognition more
feasible. IQ an US are strongly related as both met-
rics represent the same quantity applied by differ-
ent rater groups. Results of the Mann-Whitney U
test, which is used to test for significant difference
between Interaction Quality and User Satisfaction,
show their difference (p < 0.05) but values for Co-
hen?s Kappa (Cohen, 1960) and Spearman?s Rank
Correlation Coefficient (Spearman, 1904) empha-
size the that IQ and US are quite similar. Achieving
? = 0.5 can be considered as a moderate agreement
according to Landis and Koch?s Kappa Benchmark
Scale (Landis and Koch, 1977). Furthermore, a cor-
relation of ? = 0.66 (p < 0.01) indicates a strong
relationship between IQ and US (Cohen, 1988).
While it has been shown that user and expert rat-
ings are similar, it is desirable nonetheless to being
able to predict real user ratings. These ratings are the
desired kind of ratings when it comes to subjective
dialogue system assessment. Only users can give a
rating about their satisfaction level, i.e., how they
like the system and the interaction with the system.
However, user ratings are expensive as elaborated in
Section 1. Therefore, we investigate approaches to
recognize US which rely on means of IQ recogni-
tion.
5.1 Belief-Based Sequential Recognition
Methods used for IQ and US recognition by Schmitt
et al (2011b; 2011a) suffer from the fact that the
sequential character of the data is modeled inade-
quately as they assume statistical independence be-
tween the single exchanges (recognition of IQ and
US does not depend on the respective value of the
previous exchange). Hence, we present a Marko-
vian approach overcoming these issues. A probabil-
ity distribution over all US states, called belief state,
is updated after each system-user-exchange taking
also into account the belief state of the previous ex-
change. This belief update2 is equivalent to the For-
ward Algorithm known from Hidden Markov Mod-
els (cf. (Rabiner, 1989)). In doing so, the new US
probabilities also depend on the US values of the
previous exchange. Moreover, a latent variable is
introduced in order to decouple the target variable
US with the variable the observation probability de-
pends on IQ. This results in an indirect approach
for recognizing User Satisfaction that is based on the
more affordable recognition of Interaction Quality
assuming that a universal mapping between IQ and
US exists.
Thus, to determine the probability b(US) of hav-
ing the true User Satisfaction label US after the cur-
rent system-user-exchange, we rely on Interaction
Quality recognition, whose observation probability
is depicted as P (o|IQ). Furthermore, for coupling
both quantities, we introduce a coherence probabil-
ity P (IQ|US). Belief update for estimating the new
values for b?(US?) is as follows:
b?(US?) = ? ?
?
IQ?
P (o?|IQ?) ? P (IQ?|US?)
?
?
US
P (US?|US)b(US) (6)
The observation probability P (o?|IQ?) is modeled
using confidence scores of classifiers applied for IQ
recognition. Further, we compute the sum over all
previous US beliefs b(US) weighted by the transi-
tion probability P (US?|US). Both, transition and
coherence probability have been computed by tak-
ing the frequency of their occurrences in the training
data. The ? factor is used for normalization only.
Since we are aiming at generating an estimate U?S
2Terminology is taken from Partially Observable Markov
Decision Processes, cf. (Kaelbling et al, 1998)
573
at each exchange, it is calculated by
U?S = arg max
US?
b?(US?) (7)
generating a sequence of estimates for each dia-
logue.
As the action of the system a can be expected to
influence the satisfaction level of the user, action-
dependency is added to Equation 6 resulting in
b?(US?) = ? ?
?
IQ?
P (o?|IQ?) ? P (IQ?|US?, a)
?
?
US
P (US?|US, a)b(US). (8)
Hence, each system action a influences coherence
and transition probabilities. It should be noted that
action-dependency can only be introduced as in a
SDS each turn a system action is selected and ex-
ecuted by the dialogue manager.
5.2 Model Exchange
While in Belief-Based Sequential Recognition, prob-
ability models are used for coupling expert and user
ratings explicitly, a simpler approach has also been
examined. A statistical classifier trained on the tar-
get variable IQ is used to evaluate classification of
the target variable US. This seems to be reasonable
as the set of scores and meaning of the scores of both
metrics are equivalent. Furthermore, necessary pre-
requisites are fulfilled: the sample corpus contains
both labels, the labels for US and IQ correspond, and
both recognition approaches are based on the same
feature set.
6 Experiments and Results
For evaluating Belief-Based Sequential Recognition,
not only the absolute performance is of interest but
also how this performance is influenced by the char-
acteristics of the observation probability, i.e., the
performance of the applied statistical classification
approach and the variance of their confidence scores.
In order to obtain different confidence characteris-
tics, multiple classification algorithms, or algorithm
variants respectively, are needed. Hence, five statis-
tical classifiers have been chosen arbitrarily to pro-
duce the observation probabilities for Belief-Based
Sequential Recognition:
? SVM3 with cubic kernel
? SVM with RBF-kernel
? Naive Bayes
? Naive Bayes with kernel
? Rule Induction
In contrast to Schmitt et al (2011b; 2011a), a re-
duced feature set was used consisting of 43 parame-
ters as some textual parameters were removed which
are very specific and take many different values, e.g.,
UTTERANCE (the system utterance) or INTERPRE-
TATION (the interpretation of the speech input).
The resulting feature set consists of the following
parameters (parameter names are in accordance with
the parameter names of the LEGO corpus (Schmitt
et al, 2012)):
Exchange Level ACTIVITY, ACTIVITYTYPE,
UTD, BARGED-IN?, ASRCONFIDENCE,
MEANASRCONFIDENCE, TURNNUMBER,
MODALITY, LOOPNAME, ASRRECOGNI-
TIONSTATUS, ROLEINDEX, ROLENAME,
NOISE?, HELPREQUEST?, REPROMPT?,
WPST, WPUT
Dialogue Level #BARGEINS #ASRSUCCESS,
#HELPREQUESTS, #TIMEOUTS, #TIME-
OUTS ASRREJECTIONS, #ASRREJEC-
TIONS, #REPROMPTS, #SYSTEMQUES-
TIONS, #SYSTEMTURNS, #USERTURNS,
%BARGEINS, %ASRSUCCESS, %HEL-
PREQUESTS, %TIMEOUTS, %TIME-
OUTS ASRREJECTIONS, %ASRREJEC-
TIONS, %REPROMPTS
Window Level {#}TIMEOUTS ASRREJCTIONS,
{#}HELPREQUESTS, {#}ASRREJECTIONS,
{MEAN}ASRCONFIDENCE, {#}TIMEOUTS,
{#}REPROMPTS, {#}SYSTEMQUESTIONS,
{#}ASRSUCCESS, {#}BARGEINS
All results are evaluated with respect to the ref-
erence experiment of direct US recognition (US
recognition using models trained on US). This is
performed in accordance to Schmitt et al (2011b)
using the statistical classification algorithms stated
3Support Vector Machine, cf. (Vapnik, 1995)
574
Table 1: Results (UAR, Cohen?s Kappa, and Spearman?s
Rho) of 10-fold cross-validation for US recognition of US
recognition using models trained on US
Classifier UAR ? ?
SVM (cubic Kernel) 0.39 0.33 0.48
SVM (RBF-Kernel) 0.39 0.42 0.55
Naive Bayes 0.36 0.40 0.55
Naive Bayes (Kernel) 0.42 0.44 0.59
Rule Induction 0.50 0.51 0.61
Table 2: Results (UAR, Cohen?s Kappa, and Spearman?s
Rho) of 10-fold cross-validation for US recognition of the
Model Exchange approach (trained on IQ, evaluated on
US)
Classifier UAR ? ?
SVM (cubic Kernel) 0.34 0.42 0.55
SVM (RBF-Kernel) 0.34 0.42 0.58
Naive Bayes 0.35 0.40 0.57
Naive Bayes (Kernel) 0.34 0.37 0.60
Rule Induction 0.34 0.42 0.59
above. The performance of the reference experiment
is shown in Table 1.
Using the same feature set, these classification al-
gorithms are also applied for the evaluation of the
Model Exchange approach using 10-fold cross val-
idation. Note that the parameters of the classifiers
also remained the same. The data was partitioned
randomly on exchange level, i.e., without regarding
their belonging to a specific dialogue. The measured
results of the Model Exchange approach for the five
classification methods can be seen in Table 2.
While the results are significantly above chance4,
comparing them to the reference experiment reveals
that in terms of UAR the reference experiment out-
performs Model Exchange for all five classifiers.
The achieved ? and ? values show similar scores
for both the reference experiment and the Model Ex-
change approach. However, in the data used for the
experiments, the amount of occurrences of the rat-
ings was not balanced (equal for all classes) which
has been identified as the most likely reason for this
effect.
Experiments for Belief-Based Sequential Recog-
nition have also been performed using 10-fold cross
validation. As complete dialogues and the order
4UAR of 0.2 for five classes
Table 3: Results (UAR, Cohen?s Kappa, and Spearman?s
Rho) of 10-fold cross-validation for US recognition of
action-independent Belief-Based Sequential Recognition
Classifier UAR ? ?
SVM (cubic Kernel) 0.28 0.36 0.48
SVM (RBF-Kernel) 0.30 0.40 0.54
Naive Bayes 0.32 0.39 0.54
Naive Bayes (Kernel) 0.33 0.45 0.61
Rule Induction 0.33 0.47 0.63
Table 4: Results (UAR, Cohen?s Kappa, and Spearman?s
Rho) of 10-fold cross-validation for US recognition of
action-dependent Belief-Based Sequential Recognition
Classifier UAR ? ?
SVM (cubic Kernel) 0.28 0.35 0.48
SVM (RBF-Kernel) 0.29 0.40 0.54
Naive Bayes 0.32 0.40 0.55
Naive Bayes (Kernel) 0.34 0.44 0.60
Rule Induction 0.35 0.47 0.62
of exchanges within the dialogues are important for
this approach, the data was partitioned randomly on
the dialogue level. As previously explained, for the
probability distributions of the observation proba-
bility model, classification results of IQ recognition
with 10-fold cross validation has been used in order
to get good estimates for the whole data set. Re-
sults for the action-independent version can be seen
in Table 3.
For the action-dependent version, four different
basic actions ANNOUNCEMENT, CONFIRMATION,
QUESTION, and WAIT have been used, generat-
ing results presented in Table 4. The results il-
lustrate that neither action-independent nor action-
dependent Belief-Based Sequential Recognition can
outperform the reference experiment (cf. Table 1).
Still, both variants achieve results clearly above
chance. Again, the unbalanced data causes ? and
? to be similar to the reference experiment.
A comparison of the action-independent with the
action-dependent approach shows almost no differ-
ences in their performances. Only a slight tendency
towards better UARs for action-dependency can be
spotted.
Figure 2 displays the performances of both vari-
ants of Belief-Based Sequential Recognition along
with performance of IQ recognition and the vari-
ance ?2 of the corresponding confidence distribu-
575
0.200.300.400.500.60 0.000.10
SVM
?(cub
ic)
SVM
?(RBF
)
Baye
s
Baye
s?(K)
Rule
IQ???
IQ
US?B
elief
US?B
elief
?Acti
on
Figure 2: UAR of IQ recognition and Belief-Based Se-
quential Recognition along with ?2 of confidence distri-
butions of IQ recognition
Table 5: Recognition performance and variance of confi-
dence distributions for IQ recognition
Classifier ?2 UAR ? ?
SVM (cubic Kernel) 0.03 0.38 0.54 0.69
SVM (RBF-Kernel) 0.05 0.48 0.65 0.77
Naive Bayes 0.13 0.49 0.57 0.71
Naive Bayes (Kernel) 0.12 0.52 0.59 0.73
Rule Induction 0.13 0.55 0.68 0.79
tion (cf. Table 5). It can easily be seen that with
rising UAR for IQ recognition, ?2 also rises. This
directly transfers to the performance of the Belief-
Based Sequential Recognition. The more accu-
rate the observation performance, the more accurate
the belief prediction. Furthermore, when compar-
ing the action-dependent to the action-independent
variant of Belief-Based Sequential Recognition, bet-
ter IQ performance and therefore a higher variance
also causes slightly better results for the action-
dependent variant. These differences, however, are
only marginally. Therefore, they do not allow for
drawing a conclusion.
7 Conclusions
For estimating User Satisfaction-like ratings, two
categories exist: work relying on user ratings and
work relying on expert ratings. To learn something
about their differences and similarities, we explored
the possibility of using the information encoded in
the expert ratings to predict user ratings with the
hope to get acceptable user rating prediction results.
Therefore, we investigated if it is possible to de-
termine the preferred true User Satisfaction value
based on less expensive expert ratings. For this, a
corpus containing both kinds of ratings was chosen,
i.e., User Satisfaction (US) and Interaction Qual-
ity (IQ) ratings. Furthermore, interaction parame-
ters were used to create statistical recognition mod-
els for predicting IQ and US, respectively. Two ap-
proaches have been investigated: Belief-Based Se-
quential Recognition, which is based on an HMM-
like structure with IQ as an additional latent variable,
and Model Exchange, which uses statistical models
trained on IQ to recognize US. Unfortunately, nei-
ther Belief-Based Sequential Recognition nor Model
Exchange achieved results with an acceptable UAR.
The high correlation between expert and user rat-
ings, depicted by high values for Cohen?s ? and
Spearman?s ?, already allow the conclusion that ex-
pert ratings can be used as a good replacement for
user ratings. Moreover, the presented recognition re-
sults of the Model Exchange approach being clearly
above chance underpin the strong similarity of IQ
and US. Furthermore, IQ recognition is much more
reliable and accurate than US recognition (shown by
higher UAR, ? and ? values).
While the experiments disproved the hope of get-
ting acceptable user rating prediction results, the ob-
tained results confirmed the similarity between both
kinds of ratings. And as it is not necessary to use
user ratings for most applications, e.g., for using the
quality information to automatically improve the in-
teraction (cf. (Ultes et al, 2012)), we believe that it
suffices to use expert ratings as those can be acquired
easier and less expensively and are similar enough
to user ratings. Prompting the user to apply quality
ratings in everyday situations with real-life systems
will always be annoying to the user while recording
of such interactions are always much easier to rate.
By providing a study for determining quality rat-
ings of dialogues, we hope to encourage other re-
searchers to look into this research for other param-
eters, e.g., emotion recognition.
References
Jacob Cohen. 1960. A coefficient of agreement for nom-
inal scales. In Educational and Psychological Mea-
surement, volume 20, pages 37?46, April.
Jacob Cohen. 1968. Weighted kappa: Nominal scale
576
agreement provision for scaled disagreement or partial
credit. Psychological bulletin, 70(4):213.
Jacob Cohen. 1988. Statistical power analysis for the
behavioral sciences. New Jersey: Lawrence Erlbaum
Associates, July.
Klaus-Peter Engelbrecht and Sebastian Mo?ller. 2010. A
User Model to Predict User Satisfaction with Spoken
Dialog Systems. In Gary Geunbae Lee, Joseph Mari-
ani, Wolfgang Minker, and Satoshi Nakamura, editors,
Spoken Dialogue Systems for Ambient Environments.
2nd Int. Workshop on Spoken Dialogue Systems Tech-
nology, Lecture Notes in Artificial Intelligence, pages
150?155. Springer, October.
Klaus-Peter Engelbrecht, Florian Go?dde, Felix Hartard,
Hamed Ketabdar, and Sebastian Mo?ller. 2009. Mod-
eling user satisfaction with hidden markov model. In
SIGDIAL ?09: Proceedings of the SIGDIAL 2009 Con-
ference, pages 170?177, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Sunao Hara, Norihide Kitaoka, and Kazuya Takeda.
2010. Estimation method of user satisfaction using
n-gram-based dialog history model for spoken dialog
system. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Bente Maegaard, Joseph Mariani,
Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel
Tapias, editors, Proceedings of the Seventh conference
on International Language Resources and Evaluation
(LREC?10), Valletta, Malta, May. European Language
Resources Association (ELRA).
Ryuichiro Higashinaka, Yasuhiro Minami, Kohji
Dohsaka, and Toyomi Meguro. 2010a. Issues in
predicting user satisfaction transitions in dialogues:
Individual differences, evaluation criteria, and predic-
tion models. In Gary Lee, Joseph Mariani, Wolfgang
Minker, and Satoshi Nakamura, editors, Spoken
Dialogue Systems for Ambient Environments, volume
6392 of Lecture Notes in Computer Science, pages
48?60. Springer Berlin / Heidelberg.
Ryuichiro Higashinaka, Yasuhiro Minami, Kohji
Dohsaka, and Toyomi Meguro. 2010b. Modeling
user satisfaction transitions in dialogues from over-
all ratings. In Proceedings of the SIGDIAL 2010
Conference, pages 18?27, Tokyo, Japan, September.
Association for Computational Linguistics.
Kate S. Hone and Robert Graham. 2000. Towards a tool
for the subjective assessment of speech system inter-
faces (sassi). Nat. Lang. Eng., 6(3-4):287?303.
L. P. Kaelbling, M. L. Littman, and A. R. Cassandra.
1998. Planning and acting in partially observable
stochastic domains. Artificial Intelligence, 101(1-
2):99?134.
J. R. Landis and G. G. Koch. 1977. The measurement of
observer agreement for categorical data. Biometrics,
33(1):159?174, March.
Sebastian Mo?ller, Klaus-Peter Engelbrecht, C. Ku?hnel,
I. Wechsung, and B. Weiss. 2009. A taxonomy of
quality of service and quality of experience of multi-
modal human-machine interaction. In Quality of Mul-
timedia Experience, 2009. QoMEx 2009. International
Workshop on, pages 7?12, July.
Sebastian Mo?ller. 2003. Subjective Quality Evalua-
tion of Telephone Services Based on Spoken Dia-
logue Systems. ITU-T Recommendation P.851, Inter-
national Telecommunication Union, Geneva, Switzer-
land, November. Based on ITU-T Contr. COM 12-59
(2003).
Tim Polzehl, Alexander Schmitt, and Florian Metze.
2011. Salient features for anger recognition in german
and english ivr portals. In Wolfgang Minker, Gary Ge-
unbae Lee, Satoshi Nakamura, and Joseph Mariani,
editors, Spoken Dialogue Systems Technology and De-
sign, pages 83?105. Springer New York. 10.1007/978-
1-4419-7934-6 4.
Lawrence R. Rabiner. 1989. A tutorial on hidden Markov
models and selected applications in speech recogni-
tion. Morgan Kaufmann Publishers Inc., San Fran-
cisco, CA, USA.
Antoine Raux, Dan Bohus, Brian Langner, Alan W.
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: One year of
lets go! experience. In Proc. of the International Con-
ference on Speech and Language Processing (ICSLP),
September.
Alexander Schmitt, Benjamin Schatz, and Wolfgang
Minker. 2011a. Modeling and predicting quality in
spoken human-computer interaction. In Proceedings
of the SIGDIAL 2011 Conference, Portland, Oregon,
USA, June. Association for Computational Linguis-
tics.
Alexander Schmitt, Benjamin Schatz, and Wolfgang
Minker. 2011b. A statistical approach for estimat-
ing user satisfaction in spoken human-machine inter-
action. In Proceedings of the IEEE Jordan Confer-
ence on Applied Electrical Engineering and Comput-
ing Technologies (AEECT), Amman, Jordan, Decem-
ber. IEEE.
Alexander Schmitt, Stefan Ultes, and Wolfgang Minker.
2012. A parameterized and annotated corpus of the
cmu let?s go bus information system. In International
Conference on Language Resources and Evaluation
(LREC).
C. Spearman. 1904. The proof and measurement of as-
sociation between two things. American Journal of
Psychology, 15:88?103.
Stefan Ultes, Alexander Schmitt, and Wolfgang Minker.
2012. Towards quality-adaptive spoken dialogue man-
agement. In NAACL-HLT Workshop on Future di-
rections and needs in the Spoken Dialog Commu-
577
nity: Tools and Data (SDCTD 2012), pages 49?52,
Montre?al, Canada, June. Association for Computa-
tional Linguistics.
Vladimir N. Vapnik. 1995. The nature of statistical
learning theory. Springer-Verlag New York, Inc., New
York, NY, USA.
Marilyn Walker, Diane Litman, Candace A. Kamm, and
Alicia Abella. 1997. Paradise: a framework for eval-
uating spoken dialogue agents. In Proceedings of the
eighth conference on European chapter of the Associ-
ation for Computational Linguistics, pages 271?280,
Morristown, NJ, USA. Association for Computational
Linguistics.
578
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 261?264,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Advances in the Witchcraft Workbench Project
Alexander Schmitt, Wolfgang Minker
Institute for Information Technology
University of Ulm, Germany
alexander.schmitt,
wolfgang.minker@uni-ulm.de
Nada Ahmed Hamed Sharaf
German University in Cairo, Egypt
nada.sharaf@student.guc.edu.eg
Abstract
The Workbench for Intelligent exploraTion
of Human ComputeR conversaTions is
a new platform-independent open-source
workbench designed for the analysis, min-
ing and management of large spoken di-
alogue system corpora. What makes
Witchcraft unique is its ability to visual-
ize the effect of classification and predic-
tion models on ongoing system-user inter-
actions. Witchcraft is now able to handle
predictions from binary and multi-class
discriminative classifiers as well as regres-
sion models. The new XML interface al-
lows a visualization of predictions stem-
ming from any kind of Machine Learning
(ML) framework. We adapted the wide-
spread CMU Let?s Go corpus to demon-
strate Witchcraft.
1 Introduction
Substantial effort has been invested in the past
years in exploring ways to render Spoken Di-
alogue Systems (SDS) more adaptive, natural
and user friendly. Recent studies investigated
the recognition of and adaption to specific user
groups, e.g. the novices and expert users, or
the elderly (Bocklet et al, 2008). Further, there
is a massive effort on recognizing angry users,
differentiate between genders (Burkhardt et al,
2007), spotting dialects, estimating the coopera-
tiveness of users or user satisfaction (Engelbrecht
et al, 2009) and finally, predicting task comple-
tion (Walker et al, 2002). When applied online,
i.e. during the interaction between user and sys-
tem, these models can add valuable information
to the dialogue system which would allow for an
adaption of the dialogue strategy, see Figure 1.
Until now we can report that these models1
1please note that we use the expression recognizer, classi-
Speech Recognition Parsing
Dialogue Manager
Text Generation and Synthesis
ApplicationUse
r Prediction Model
Figure 1: Enhanced SDS: The prediction model
that is used to render the dialogue system more
user-friendly delivers additional information to the
dialogue manager.
work more or less well in batch-test scenarios of-
fline. An anger classifier might deliver 74% accu-
racy when evaluated on utterance level. But which
impact would the deployment of this recognizer
have on specific dialogues when being employed
in a real system? Would it fail or would it suc-
ceed? Similarly, at what point in time would mod-
els predicting gender, speaker age, and expert sta-
tus deliver a reliable statement that can indeed be
used for adapting the dialogue? What we need
prior to deployment is an evaluation of the mod-
els and a statement on how well the models would
work when being shifted on dialogue level. At this
point, the Witchcraft Workbench enters the stage.
2 The Role of Witchcraft
For a more detailed introduction on the Witchcraft
Workbench please refer to (Schmitt et al, 2010a).
In a nutshell, Witchcraft allows managing, mining
and analyzing large dialogue corpora. It brings
logged conversations back to life in such that it
simulates the interaction between user and sys-
tem based on system logs and audio recordings.
Witchcraft is first of all not an annotation or tran-
scription tool in contrast to other workbenches
such as NITE (Bernsen et al, 2002), Transcriber2
fier and prediction model interchanging in this context
2http://trans.sourceforge.net
261
or DialogueView3. Although we also employ it
for annotation, its central purpose is a different
one:Witchcraft contrasts dialogue flows of spe-
cific dialogues which are obtained from a dialogue
corpus with the estimations of arbitrary predic-
tion and classification models. By that it is in-
stantly visible which knowledge the dialogue sys-
tem would have at what point in time in the dia-
logue. Imagine a dialogue system would be en-
dowed with an anger recognizer, a gender recog-
nizer and a recognizer that should predict the out-
come of a dialogue, i.e. task completion. Each of
the three recognizers would be designed to deliver
an estimation at each point in the dialogue. How
likely is the user angry? How likely is he male or
female and how likely will the task be completed
based on what we have seen so far in the dialogue.
To which extent the recognizers deliver a correct
result can be verified within Witchcraft.
3 Handling Models in Witchcraft
Witchcraft had several shortcomings when we first
reported on it in (Schmitt et al, 2010a). It was
only working with a proprietary industrial corpus
and was heavily tailored to our needs. It worked
only with specific models from binary discrimina-
tive classifiers. Since then we have put substantial
effort to generalize the functionality and to make
it available to the community.
To allow an analysis of other recognizers the
system has been extended to further handle pre-
dictions from multiclass discriminative classifica-
tion and regression tasks. Witchcraft does not con-
tain ?intelligence? on its own but makes use of
and manages the predictions of recognizers. We
assume that a recognizer is implemented either
as stand-alone recognizer or with help of a Ma-
chine Learning (ML) framework. We emphasize
that Witchcraft itself does neither perform fea-
ture extraction nor classification. Witchcraft op-
erates on turn level requesting the recognizer to
deliver a prediction based on information avail-
able at the currently processed dialogue turn of
a specific dialogue. Where and how the recog-
nizer accomplishes this is not part of the archi-
tecture. The ML framework of our choice that
was originally supported natively, i.e. directly ac-
cessed by Witchcraft (Schmitt et al, 2010a) was
RapidMiner4, an ML framework that covers a vast
3http://cslu.cse.ogi.edu/DialogueView/
4www.rapid-i.net
majority of supervised and unsupervised machine
learning techniques. The initial plan to interface
other ML frameworks natively (such as MatLab,
the R framework, BoosTexter, Ripper, HTK that
are frequently used in research) turned out not to
be practical. In order to still be able to cover the
broadest possible range of ML tools we introduced
a new generic XML interface. For simplicity we
removed the RapidMiner interface. An overview
of the dependency between Witchcraft and a rec-
ognizer is depicted in Figure 2.
ML Fra
mework Rec
ogn
izer
Witchc
raft
read
s
Dia
log
ue
ID
 78
74
3
Disp
lays
 
disc
ours
e
Chart
 Views
Dial
ogu
e 
View
Dia
log
ue
ID
 93
12
3
???? ???? ???? ???? ???.
Dial
ogu
e Flo
w
Use
r Sa
tisfac
tion
read
s
...
Da
tab
as
e
Log D
ata 
&
Aco
ustic
Featu
res
Dia
log
ue
ID
 67
34
3
Get
 pre
dicti
on
XML Pred
ictio
ns
Per 
turn
 & 
dialo
gue
Pred
ictio
n an
d 
Class
ificat
ion 
Mod
els
Prep
roce
ssin
g
Class
ificat
ion
Featu
re 
Retr
ieval
Di
alo
gu
e C
or
pu
s 
Inter
actio
n Log
s
Aud
io File
s
Aud
io Fe
atur
es
Witchc
raft
Disp
lays
 
Estimat
ionsDisp
lays
 
Dial
ogu
e Flo
w
gen
erat
es
read
s
Figure 2: Dependency of Witchcraft and related
recognizers that are implemented within an ML
framework.
Witchcraft has been extended to support an ar-
bitrary number of models, see Figure 3. They can
now be one of the types ?discriminative bin ry?,
?discriminative multiclass classification? and ?re-
gression?.
Figure 3: Definition of a model within Witchcraft.
External recognizers have to deliver predictions
for the defined models as XML documents.
A recognizer implemented in an ML framework
has to be defined in such a way that it delivers
XML documents that fit the model definition in
Witchcraft. Each XML document represents the
prediction of the recognizer for a specific dialogue
turn of a specific dialogue. It contains for discrimi-
native classification tasks, such as gender, or emo-
tion the number of the turn that has been classified,
262
the actual class label and the confidence scores of
the classifier.
<xml>
<turn>
<number>1</number>
<label>anger</label>
<prediction>non-anger</prediction>
<confidence class=?anger?>0.08</confidence>
<confidence class=?no-ang?>0.92</confidence>
</turn>
</xml>
In regression tasks, such as the prediction of
user satisfaction, retrieving cooperativeness scores
etc., the returned result contains the turn number,
the actual label and the prediction of the classifier:
<xml>
<turn>
<number>1</number>
<label>5</label>
<prediction>3.4</prediction>
</turn>
</xml>
After performing recognition on a number of di-
alogues with the recognizer Witchcraft reads in the
XML files and creates statistics based on the pre-
dictions and calculates dialogue-wise accuracy,
f-score, precision and recall values, root mean
squared error etc. The values give some indica-
tion of how precisely the classifier worked on dia-
logue level. That followed it allows to search for
dialogues with a low overall prediction accuracy,
or e.g. dialogues with high true positive rates, high
or low class-wise f-scores etc. via SQL. Now a de-
tailed analysis of the recognizer?s performance on
dialogue level and possible reasons for the failure
can be spotted.
4 Evaluating Models
In Figure 4 we see prediction series of two rec-
ognizers that have been applied on a specific dia-
logue: a gender recognizer that predicts the gen-
der on turn basis and an emotion recognizer that
predicts the user?s emotional state (angry vs. non-
angry) at the current turn. The red line symbol-
izes the confidence of the recognizers for each of
the predicted classes. For example, in the emotion
model the blue line is the confidence for a non-
angry utterance (0-100%), the red line for an an-
gry one. Exemplary for the two models we take
a closer look at the gender model. It predicts the
gender on turn basis, i.e. it takes the current speech
sample and delivers estimations on the speaker?s
gender. As we can see, there are a number of
misrecognitions in this call. It stems from a fe-
male speaker but the recognizer frequently esti-
Figure 4: Screenshot of charts in Witchcraft based
on turn-wise predictions an anger and a gender
recognizer.
mated a male speaker. The call could be spot-
ted by searching within Witchcraft for calls that
yield a low accuracy for gender. It turned out that
the misrecognized turns originate from the fact
that the user performed off-talk with other persons
in the background which caused the misrecogni-
tion. This finding suggests training the gender
recognizer with non-speech and cross-talk sam-
ples in order to broaden the recognition from two
(male, female) to three (male, female, non-speech)
classes. Further it appears sensitive, to create a
recognizer that would base its recognition on sev-
eral speech samples instead of one, which would
deliver a more robust result.
5 Portability towards other Corpora
Witchcraft has now been extended to cope with
an unlimited number of corpora. An integration
of new corpora is straight-forward. Witchcraft
requires an SQL database containing two tables.
The dialogues table hosts information on the over-
all dialogues (such as the dialogue ID, the cat-
egory, filename of complete recording) and the
exchanges table containing the turn-wise interac-
tions (dialogue ID, turn number, system prompt,
ASR parse, ASR confidence, semantic interpreta-
tion, hand transcription, utterance recording file,
barged in, etc.). Both tables are linked through a
1 : n relationship, i.e. one entry in the dialogues
table relates to n entries in the interactions table,
cf. Figure 5. To demonstrate portability and in
order to create a sample corpus that is deployed
with Witchcraft, we included the CMU Let?s Go
bus information system from 2006 as demo cor-
pus (Raux et al, 2006). It contains 328 dialogues
including full recordings. The Witchcraft project
includes a parser that allows to transform raw log
data from the Let?s Go system into the Witchcraft
table structure.
263
dialogues
PK, FK1 CallerID
CategoryGenderAgeAudioFile...
exchanges
CallerID
SystemPrompt
ASRTranscriptASRConfidenceSemanticInterpretationHandTranscriptRecognitionStatusBargedInAudioFile...
Figure 5: Dialogue and exchanges table with 1:n
relationship. Bold database columns are required,
others are optional.
6 Conclusion and Discussion
Witchcraft turned out to be a valuable framework
in our everyday work when dealing with large di-
alogue corpora. At the current stage several stu-
dents are working with it in multi-user mode to
listen, analyze and annotate dialogues from three
different corpora consisting of up to 100,000 di-
alogues each. Witchcraft allows them to search
for dialogues relevant to the current task. The
SQL-based access allows a powerful and standard-
ized querying and retrieval of dialogues from the
database. Witchcraft provides an overview and
presents decisive information about the dialogue at
one glance and allows to sort and group different
types of dialogue for further research. Moreover,
Witchcraft allows us to test arbitrary recognizers
that provide additional information to the dialogue
manager. Witchcraft tells us at which point in time
a dialogue system would possess which knowl-
edge. Further it allows us to conclude the relia-
bility of this knowledge for further employment
in the dialogue. For an evaluation of recognizers
within Witchcraft please refer to (Schmitt et al,
2010b) where the deployment of an anger recog-
nizer is simulated.
Witchcraft is now freely and publically avail-
able to the community. It is hosted under
GNU General Public License at Sourceforge un-
der witchcraftwb.sourceforge.org. The employed
component architecture allows for the develop-
ment of third-party plug-ins and components for
Witchcraft without the need for getting into detail
of the existing code. This facilitates the extension
of the workbench by other developers. We hope
that Witchcraft will help to foster research on fu-
ture dialogue systems and we encourage the com-
munity to contribute.
Acknowledgements
The research leading to these results has re-
ceived funding from the Transregional Collabora-
tive Research Centre SFB/TRR 62 ?Companion-
Technology for Cognitive Technical Systems?
funded by the German Research Foundation
(DFG). The authors would like to thank the CMU
Let?s Go Lab from Carnegie Mellon University
in Pittsburgh for their permission to deploy the
Let?s Go Bus Information Corpus jointly with
Witchcraft.
References
Niels Ole Bernsen, Laila Dybkjaer, and Mykola Kolod-
nytsky. 2002. The nite workbench - a tool for anno-
tation of natural interactivity and multimodal data.
In Proc. of LREC, pages 43?49, Las Palmas, Spain.
Tobias Bocklet, Andreas Maier, Josef Bauer, Felix
Burkhardt, and Elmar No?th. 2008. Age and gen-
der recognition for telephone applications based on
gmm supervectors and support vector machines. In
Proc. of ICASSP, volume 1, pages 1605?1608.
Felix Burkhardt, Florian Metze, and Joachim
Stegmann, 2007. Speaker Classification for
Next Generation Voice Dialog Systems. Advances
in Digital Speech Transmission. Wiley.
Klaus-Peter Engelbrecht, Florian Go?dde, Felix Har-
tard, Hamed Ketabdar, and Sebastian Mo?ller. 2009.
Modeling user satisfaction with hidden markov
model. In Proc. of SIGDIAL 2009, pages 170?177.
Antoine Raux, Dan Bohus, Brian Langner, Alan W.
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: One year
of lets go! experience. In Proc. of Interspeech,
September.
Alexander Schmitt, Gregor Bertrand, Tobias Heinroth,
and Jackson Liscombe. 2010a. Witchcraft: A work-
bench for intelligent exploration of human computer
conversations. In Proc. of LREC, Valetta, Malta,
May.
Alexander Schmitt, Tim Polzehl, and Wolfgang
Minker. 2010b. Facing reality: Simulating deploy-
ment of anger recognition in ivr systems. In Proc. of
IWSDS, September.
Marilyn Walker, I Langkilde-Geary, H W Hastie,
J Wright, and A Gorin. 2002. Automatically train-
ing a problematic dialogue predictor for a spoken
dialogue system. Journal of Artificial Intelligence
Research, (16):293?319.
264
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 173?184,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Modeling and Predicting Quality in Spoken Human-Computer Interaction
Alexander Schmitt, Benjamin Schatz and Wolfgang Minker
Dialogue Systems Research Group
Institute for Information Technology
Ulm University, Germany
{alexander.schmitt, benjamin.schatz, wolfgang.minker}@uni-ulm.de
Abstract
In this work we describe the modeling and
prediction of Interaction Quality (IQ) in Spo-
ken Dialogue Systems (SDS) using Support
Vector Machines. The model can be employed
to estimate the quality of the ongoing inter-
action at arbitrary points in a spoken human-
computer interaction. We show that the use
of 52 completely automatic features character-
izing the system-user exchange significantly
outperforms state-of-the-art approaches. The
model is evaluated on publically available data
from the CMU Let?s Go Bus Information sys-
tem. It reaches a performance of 61.6% un-
weighted average recall when discriminating
between 5 classes (good to very poor). It can
be further shown that incorporating knowl-
edge about the user?s emotional state does
hardly improve the performance.
1 Introduction
For years, the research community has been trying
to model quality of Spoken Dialogue Systems (SDS)
with statistical approaches. Most vividly discussed
has been the PARADISE approach which tries to
map objective performance metrics of an SDS to
subjective user ratings (Walker et al, 2000). The
paradigm assumes that task success and dialogue
costs contribute to user satisfaction which is the tar-
get variable in the model. By that, an automatic eval-
uation of an SDS should be enabled. While the in-
tention of PARADISE is to evaluate and compare
SDS or different system versions among each other,
it is not suited to evaluate a spoken dialogue at ar-
bitrary points during an interaction. Such a model
can be helpful for a number of reasons: Firstly,
it allows for a prediction of critical dialogue sit-
uations. These predictions could be employed to
adapt the dialogue strategy or - in telephone appli-
cations with human assistance - escalate to human
operators. Secondly, it could help to uncover poten-
tially weak dialogue design and point out problem-
atic turns that need a re-design. Thirdly, user sat-
isfaction models help understand the satisfaction of
the users. In this study we present such a statisti-
cal model that is trained with a large set of domain-
independent features taken from system logs and use
additional manually created features, such as emo-
tional state and dialogue acts, to create an upper
baseline.
This paper is organized as follows: In Section 2
we present related work and discuss afterwards in
Section 3 further issues that need to be addressed in
this field. There, we also disambiguate the term user
satisfaction from Interaction Quality. After that, we
describe the annotation scheme as well as the rating
process for modeling IQ and present, how we derive
a generic label from the different raters? opinions in
Section 4. The input feature groups along with their
features are presented in Section 5. We anticipate
that the problem is best modeled with Support Vec-
tor Machines (SVM), which is addressed in Section
6. Ensuing, the performance of the model is evalu-
ated. In the first place, we analyze the impact of dif-
ferent feature groups on the SVM classifier in Sec-
tion 7 and secondly, we optimize the model and de-
termine the most relevant features for predicting the
IQ score in Section 8. A linear modeling approach
of IQ by use of multivariate linear regression will be
173
presented and discussed in Section 9 to obtain com-
parability with PARADISE. This study closes with
a conclusion and a discussion in Section 10.
2 Related Work
Models predicting user satisfaction at any point in
an SDS have only been deficiently explored to date.
(Engelbrecht et al, 2009) modeled user satisfac-
tion as process evolving over time with Hidden
Markov Models (HMM). In the experiment, users
were asked to interact with a Wizard-of-Oz restau-
rant information system. Each participant followed
dialogues which have previously been defined fol-
lowing predefined scripts, i.e. specific scenarios.
This resulted in equally long dialogue transcripts
for each scenario. The users were constrained to
rate their satisfaction on a 5-point scale with ?bad?,
?poor?, ?fair?, ?good? and ?excellent? after each di-
alogue step. The interaction was halted while the
user voted.
In a similar spirit, (Higashinaka et al, 2010a)
developed a model for predicting turn-wise rat-
ings, which was evaluated on human-machine and
human-human dialogues. The data employed was
not spoken dialogue but text dialogues from a chat
system and a transcribed conversation between hu-
mans. The labels in the model originated from
two expert raters that listened to the recorded in-
teractions and provided turn-wise scores from 1-7
on smoothness (?Smoothness of the conversation?),
closeness (?Closeness perceived by the user towards
the system?) and willingness (?Willingness to con-
tinue the conversation?). Rater-independent perfor-
mance scores of the model reached about 0.2-0.24
unweighted average recall, which is about 0.1 points
above the baseline of app. 0.14.
(Hara et al, 2010) created n-gram models from
dialogue acts (DA) to predict user satisfaction based
on dialogues from real users interacting with a music
retrieval system. The model is based on overall rat-
ings from the users measuring their satisfaction on a
five point scale after the interaction. The best result
could be achieved with a 3-gram model that reached
34% accuracy in distinguishing between six classes
at any point in the dialogue. It seems that the predic-
tion of turn-level user satisfaction scores given only
one overall dialogue-level score seems hardly possi-
ble and is close to random: The prediction of the five
user satisfaction classes reach an average F-score as
low as 0.252, which is only 0.052 score points above
the baseline of 0.20. A similar result as (Hara et al,
2010) was obtained by (Higashinaka et al, 2010b).
Using HMMs they derived turn-level ratings from
dialogue-wide ratings. The model?s performance
when trained on dialogue-level ratings was closer to
random than when trained on turn-level ratings. The
open issues that arise from the cited work are ad-
dressed in the following.
3 Issues
Our aim is to create a general model that may be
used to predict the quality of the interaction - or
ideally the actual satisfaction of the user - at arbi-
trary system-user exchanges in an SDS. It has be-
come obvious from the cited work that current mod-
els are not suited for deployment due to low predic-
tion accuracy. Crucial for a successful recognition
of user satisfaction is the choice and appropriateness
of the input variables. (Higashinaka et al, 2010a),
(Higashinaka et al, 2010b) and (Hara et al, 2010)
employ a - mostly hand annotated - ?dialogue act?
feature to predict the target variable. Dialogue acts
are frequently highly system-dependent and do not
model the full bandwidth of the interaction. (Engel-
brecht et al, 2009) additionally employed contex-
tual appropriateness, confirmation strategy and task
success, of which many require hand annotation. Yet
it is mandatory for an automatic prediction of user
satisfaction to design and derive completely auto-
matic features that do not require manual interven-
tion. It is further easy to comprehend that the mod-
eling of user satisfaction in ongoing dialogues starts
with a dilemma: tracking user satisfaction from real
users in real environments performing real tasks is
virtually impracticable. Consequently data for de-
riving models can either be obtained under labora-
tory conditions with real users performing fake tasks
in an artificial environment, cf. (Engelbrecht et al,
2009), or by manual annotation of real-life data from
experts that pretend to be the users.
It is thus vital for modeling ?user satisfaction? to
understand the term itself. In the literature there ex-
ists no rigorous definition, however, it seems obvi-
ous that it is the user himself who determines the
174
satisfaction - and not expert annotators. Accord-
ing to (Doll and Torkzadeh, 1991) ?user satisfac-
tion? is the opinion of users about a specific com-
puter application, which they use. Other terms for
?user satisfaction? are common, such as ?user infor-
mation satisfaction?, which is defined as ?the extent
to which users believe the information system avail-
able to them meets their information requirements?
(Ives et al, 1983). User satisfaction and usability are
closely interwoven. (ISO, 1998) subsumes under the
definition ?usability? a compound of efficiency, ef-
fectiveness and satisfaction. Yet satisfaction is often
seen as a by-product of great usability in HCI lit-
erature (Lindgaard and Dudek, 2003). They could
also show that user satisfaction ratings are subject to
large fluctuations among different users and it can be
further assumed that those fluctuations do also occur
within a single dialogue of a user. As a result, gen-
eral prediction models that mirror a universal, un-
biased understanding of satisfaction can presumably
hardly be derived from user?s impressions. Large
influence of subjectivity - and also randomness in
assigning the scores - would prevent such a general
model. Consequently, it seems unavoidable to em-
ploy expert annotations. In the proper meaning of
the word, the scores then do not exactly mirror the
subjective impression of users but the more objec-
tive impression of expert raters.
Thus we decide against the use of the term user
satisfaction in the course of this work in contrast to
(Higashinaka et al, 2010a) and instead opt for the
expression Interaction Quality. It can be assumed
that basic attitudes towards dialogue systems in gen-
eral, opinions about the TTS voice, environmental
factors etc. that would typically influence user satis-
faction scores, and which are not of interest for our
prediction, are not dominant in expert satisfaction
scores in a series of annotated dialogues. Experts
are expected to fade out such system-dependent and
environment-dependent influences and instead focus
on the dialogue behavior (i.e. the Interaction Qual-
ity) only.
As a result, two key issues are addressed in this
work: First of all, the input feature set has to be de-
signed as a generic, domain-independent set that can
be derived from any spoken dialogue system log and
that takes into account a maximum of available in-
formation about the interaction. Secondly, the tar-
get variable, i.e. the IQ score, needs to be deter-
mined in a guided rating process in order to be re-
producible in future work and has to be empirically
derived from several expert annotators that provide
scores for each single system-user turn of an inter-
action.
4 Corpus Annotation
For our study we employ data from the Let?s Go
Bus information system (Raux et al, 2006). Three
raters, advanced students of computer science and
engineering, annotated respectively 200 dialogues
comprising 4885 system-user exchanges from the
2006 corpus. The raters were asked to annotate the
quality of the interaction at each system-user ex-
change with the scores 5 (very good), 4 (good), 3
(fair), 2 (poor) and 1 (very poor). Every dialogue
is initially rated with a score of 5 since every inter-
action at the beginning can be considered as good
until the opposite eventuates. Our model assumes
that users are initially interacting with an SDS with-
out bias, i.e. the basic attitude towards a dialogue
system is positive. Other assumptions would not be
statistically predictable. An example dialogue is de-
picted in Table 5 along with the ratings (cf. Figure 2
in the Appendix). (Higashinaka et al, 2010b) and
(Higashinaka et al, 2010a) report low correlation
among the ratings (Spearman?s ? 0.04-0.32), which
motivated us to develop a set of basic guidelines that
should be used by the raters (cf. Table 6 in the Ap-
pendix). The guidelines have been designed in such
a way that the raters still have sufficient level of free-
dom when choosing the labels but preventing them
from too strong variations among the neighboring
system-user exchanges.
The distribution of the labels provided by the sin-
gle raters is depicted in Figure 3. As expected, the
distribution is skew towards label ?5? since every di-
alogue initially is assumed to have a good IQ.
The inter-rater agreement shows that Interaction
Quality is still a subjective metric, although guide-
lines seem to synchronize the labels to a certain ex-
tent. The overall mean agreement can be reported
with Cohen?s ? = 0.31 and the correlation among
the raters can be reported with Spearman?s ? = 0.72
which depicts a by 0.4 points higher correlation as
reported by (Higashinaka et al, 2010a). Since we
175
aim to model a general opinion on Interaction Qual-
ity, i.e. the model should mirror the IQ score other
raters - and in the last instance users - agree with,
we determine the final label empirically. A major-
ity voting for the distinction of the final label can-
not be used since in 21% of the exchanges all three
raters opted for different scores. Thus we consider
the mean of all rater opinions as possible candidates
for the final class label:
ratingmean = b
(
1
R
R?
r=1
IQr
)
+ 0.5c
where IQ is the Interaction Quality score pro-
vided by rater r. byc denotes the biggest integer
value smaller than y. Every value IQr contributes
equally to the result that is finally rounded half up to
an integer value. Furthermore we consider the me-
dian, which we define as
ratingmedian = select(sort(IQR),
R+ 1
2
)
for an odd number of raters R, where sort is a func-
tion that orders the ratings of all raters ascending and
select(X = [x1, ..., xn], i) chooses the item with in-
dex i from X .
The compliance of the single user ratings with the
final label (calculated on mean and median) is de-
picted in Table 1. As can be seen, the agreement of
the three raters with the median label is significantly
higher than with the mean label. Consequently the
median label represents the most objective measure-
ment of Interaction Quality and commends itself for
creating the model.
5 Input Features
The system-user interaction is modeled on exchange
level. Each system-user exchange consists of a set
of fully automatic features that can be derived from
system logs. We used parameters similar to the ones
described in (Schmitt et al, 2008; Schmitt et al,
2010b). In the first place, we modeled each system-
user exchange with a number of Speech Recognition
(ASR), Spoken Language Understanding (SLU) and
Dialog Manager (DM)-related features:
Mean Label Median Label
Cohen?s ?
Rater1 0.557 0.688
Rater2 0.554 0.679
Rater3 0.402 0.478
Mean 0.504 0.608*
Spearman?s ?
Rater1 0.901 0.900
Rater2 0.911 0.907
Rater3 0.841 0.814
Mean 0.884 0.874
Accuracy
Rater1 0.651 0.755
Rater2 0.647 0.749
Rater3 0.539 0.598
Mean 0.612 0.701*
Table 1: Agreement of single rater opinions to the merged
label when determined by mean and median, measured in
?, ? and accuracy. (*)=significantly higher (? < 0.05)
ASR ASRRECOGNITIONSTATUS: one of ?suc-
cess?, ?reject?, ?timeout?; ASRCONFIDENCE:
confidence of the ASR; BARGED-IN?: did the
user barge-in?, MODALITY: one of ?speech?,
?DTMF?; EXMO: the modality expected from
the system (?speech?, ?DTMF?, ?both?); UN-
EXMO?: did the user employ another modal-
ity than expected?; GRAMMARNAMES: names
of the active grammars; TRIGGEREDGRAM-
MAR: name of grammar that matched; UTTER-
ANCE: raw ASR transcription; WPUT: num-
ber of words per user turn; UTD: utterance turn
duration;
SLU SEMANTICPARSE: semantic interpretation
of caller utterance; HELPREQUEST?: is the
current turn a help request?; OPERATORRE-
QUEST?: is the current turn an operator re-
quest?;
Dialog Manager ACTIVITY: identifier of
the current system action; ACTIVITY-
TYPE: one of ?question?, ?announcement?,
?wait for user feedback?; PROMPT: system
prompt; WPST: number of words per system
turn; REPROMPT?: is the current system turn
a reprompt?; CONFIRMATION?: whether the
176
current system prompt is a confirmation to
elicit common ground between user and system
due to low ASR confidence; TURNNUMBER:
current turn; DD: dialog duration up to this
point in seconds.
To account for the overall history of important
system events we added running tallies, percentages
and mean values for certain features symbolized
with the suffixes ?#?, ?%? and ?MEAN?. They
are: MEANASRCONFIDENCE, the average of
ASR confidence scores from all user utterances
so far in the dialog, and #ASRSUCCESS, the
number of succesfully parsed user utterances so far.
Further we calculate #ASRREJECTIONS, #TIME-
OUTPROMPTS, #BARGEINS, #UNEXMO and the
respective normalized equivalents with the prefix
?%? instead of ?#?. We consider the immediate
context within the previous 3 turns of the current
turn as particularly relevant for the Interaction Qual-
ity. Hence, derived from the basic parameters we
created further parameters that emphasize specific
user behavior prior to the classification point. They
are symbolized with the prefix {#} for a number and
{Mean} for the mean value. A number of successive
barge-ins or recognition problems might indicate a
low IQ. Thus we add {MEAN}ASRCONFIDENCE,
the mean confidence of the ASR within the win-
dow, {#}ASRSUCCESS, {#}ASRREJECTIONS
and {#}TIME-OUTPROMPTS, i.e. the number
of successfully and unsuccessfully parsed ut-
terances within the window and the number
of time-outs. The other counters are calcu-
lated likewise: {#}BARGEINS; {#}UNEXMO,
{#}HELPREQUESTS, {#}OPERATORREQUESTS,
{#}REPROMPT, {#}CONFIRMATIONS,
{#}SYSTEMQUESTIONS.
To provide comparability to previous work (Hi-
gashinaka et al, 2010a), we further introduce a
dialogue act feature group that we create semi-
automatically:
DAct SYSTEMDIALOGUEACT: one of 28 dis-
tinct dialogue acts, such as greeting,offer help,
ask bus, confirm departure, deliver result, etc.
USERDIALOGUEACT: one of 22 distinct DAs,
such as confirm departure, place information,
polite, reject time, request help, etc.
To create an upper baseline of our model we fur-
ther introduce the negative emotional state of the
user that is manually annotated by a human rater
who chooses one of the labels garbage, non-angry,
slightly angry, very angry for each single user turn:
Emo EMOTIONALSTATE: emotional state of the
caller in the current exchange. One of garbage,
non-angry, slightly angry, very angry.
The same annotation scheme as in our previous
work on anger detection has been applied, see e.g.
(Schmitt et al, 2009). From all 4,832 user turns,
68.5% were non-angry, 14.3% slightly angry, 5.0%
very angry and 12.2% contained garbage, i.e. non-
speech events. In total, the number of interaction
parameters servings as input variables for the model
amounts to 52.
6 Non-Linear Modeling with Support
Vector Machines
The IQ scores are classified with Support Vector
Machines (Bennett and Campbell, 2000). In short,
an SVM uses a set of training examples
(x1, y1) . . . (xn, yn)|xi ? X , yi ? {?1, 1}
to create a hyperplane that separates two classes
{?1, 1} in such a manner that the smallest margin
between all training samples is maximized. The hy-
perplane is described by a normal vector w and a
so-called bias b. To classify an unknown sample the
following decision rule is applied:
Y = sgn[wTx+ b > 0] =
{
+1, wTx+ b > 0
?1, wTx+ b ? 0
Depending on the position of the training sample in
relation to the hyperplane, the class 1 or ?1 is as-
signed to the unknown sample. Multi-class prob-
lems are solved by reducing the problem to several
binary classification problems where usually a one-
versus-all decision is applied.
The model is constructed with an SVM with lin-
ear kernel that uses the fast Sequential Minimal Op-
timization (SMO) algorithm (Platt, 1999). Input
variables are features from the described groups, i.e.
x ? {DAct,ASR, SLU,DM,Emo}. The target
variable is the IQ score.
177
7 Feature Group Evaluation
The skew distribution of the five classes requires the
employment of an evaluation metric that weights the
prediction of all classes equally. Hence, a perfor-
mance metric, such as accuracy, would not be a re-
liable measurement. We select the unweighted aver-
age recall (UAR) to assess the model performance.
Although it does not consider the severity of the er-
ror, i.e. predicting ?1? for an IQ of ?5? is considered
as fatal as predicting ?4?, it has been proven to be su-
perior to other evaluation metrics, see (Higashinaka
et al, 2010a), where the UAR is called Match Rate
per Rating (MR/R). It is defined as follows:
MR/R(R,H) =
1
K
K?
r=1
?
i?{i|Ri=r}
match(Ri, Hi)
?
i?{i|Ri=r}
1
,
where K is the number of classes, here ?5?, and
?match? is either ?1? or ?0? depending on whether
the classifier?s hypothesis Hi for the class r matches
the reference label Ri. In the course of this work
we will stick to the expression MR/R by reason of
clearness. We further list Cohen?s ? and Spearman?s
? to make our work comparable to other studies but
will use MR/R as central evaluation criterion and for
feature selection.
We have split all available data into two disjoint
subsets consisting of 60% of the dialogues for train-
ing and testing via 10-fold cross-validation and the
remaining 40% of the dialogues for optimization.
The dialogues have been selected randomly.
In order to assess the performance contribution of
the single feature groups, we trained the SVM re-
spectively with all features from the DAct, ASR, SLU
and DM groups. Further, we subsumed the groups
ASR, SLU and DM as AUTO features since they can
automatically be derived from logs without manual
intervention. In addition, the AUTOEMO group con-
tains all AUTO features plus the emotion label. Fi-
nally, the ALL group contains the AUTOEMO fea-
tures plus the DAct features. For all groups, the sup-
port vector classifier has been trained and evaluated
in 10-fold cross validation with the 3110 exchanges
from the 118 training/testing dialogues. The first
turn of each dialogue has been excluded from the
evaluation since each dialogue starts with a score of
?5?. Results are depicted in the first half of Table 2.
Input Feature Selection MR/R ? ?
Majority Baseline 0.200 0.0 NA
DAct no 0.269 0.136 0.363
ASR no 0.605 0.551 0.753
SLU no 0.250 0.083 0.293
DM no 0.429 0.334 0.653
AUTO no 0.584 0.526 0.776
AUTOEMO no 0.606 0.549 0.785
ALL no 0.619 0.559 0.800
DAct ? - - -
ASR 13/25 0.598 0.545 0.730
SLU 4/5 0.250 0.083 0.293
DM 10/17 0.436 0.338 0.649
AUTO 20/47 0.616 0.563 0.786
AUTOEMO 31/48 0.604 0.545 0.785
ALL 23/52 0.625 0.575 0.795
Table 2: Model performance after 10-fold cross valida-
tion on training/test set. The first half comprises results
when all features of a group are employed. The second
half contains results after feature selection on the opti-
mization set ((x/y)=where x is the number of features
used from all y available features.)
As can be seen, the model reaches a similar
performance as (Higashinaka et al, 2010a) with
MR/R=0.26, when trained with dialogue act features
alone. The slightly higher performance of our model
can potentially be explained by the lower number
of classes (5 vs. 7), a different definition of the
dialogue act set, the employment of Support Vec-
tor Machines instead of Hidden Markov Models or
the difference in the target variable (IQ vs. close-
ness/smoothness/willingness). It can be noted that
the utilization of other features considerably outper-
forms dialogue act features. Particularly the group
of the ASR features alone reaches a performance
of 60.5%. The employment of all AUTO features
delivers 58.4% which is 2.1% below the ASR fea-
tures. Consequently, other variables seem to be
less meaningful for predicting the Interaction Qual-
ity and seem to harm the performance of the SVM.
The knowledge of the emotional state of the user
contributes with merely another 0.1% in compari-
son to the ASR features. It can be assumed that the
emotion feature increases the recognition rate of the
lower IQ scores ?1? and ?2?. However, this could
not be confirmed: even when considering class-wise
178
performance values a significant contribution of the
emotion feature cannot be observed. We also have
to bear in mind that we employed hand-annotated
emotions. Emotion recognition itself is error-prone
and a distinction of the emotional state of the caller
with the employed annotation scheme can be ex-
pected with approximately 70%-80% UAR, see e.g.
(Schmitt et al, 2010a). The influence of emotion
recognition on the IQ distinction can be considered
as limited and is insofar not surprising as the occur-
rence of strong anger in the data is not dominant
(5.0%). The contribution of the single features to
the classification result (across the groups they are
assigned to) is analyzed in the following.
8 Optimizing the Model by Feature
Selection
Since too many (potentially irrelevant) features
might harm the classifier?s performance we perform
feature selection with the optimization set. First,
the features are ordered according to an Informa-
tion Gain Ratio (IGR) ranking. The 10 most rele-
vant features according to IGR for predicting IQ are
depicted in Table 3.
Feature IGR
1 #ASRREJECTIONS 1
2 #TIMEOUT ASRREJ 0.967288
3 #ASRSUCCESS 0.834238
4 #REPROMPTS 0.804752
5 %REPROMPTS 0.800462
6 #TIMEOUTPROMPTS 0.757596
7 #SYSTEMQUESTIONS 0.757596
8 ROLEINDEX 0.699246
9 DD 0.566836
10 #BARGE-INS 0.566836
Table 3: Top 10 features on optimization set according to
IGR.
As can be seen the Interaction Quality is obvi-
ously heavily influenced by the performance of the
ASR. In other words, it can be assumed that the
raters themselves are influenced by the ASR?s per-
formance when assigning the IQ scores. All features
belong to the group AUTO, i.e. they can be deter-
mined automatically during runtime. Furthermore,
nearly all features are related to the overall interac-
tion, i.e. features related to the current exchange,
such as UTTERANCE, ASRSUCCESS? etc. do not
even occur. It can also be noted that the emotional
state and the dialogue acts are not listed as most rel-
evant features. To determine the global maximum of
the classifier, i.e. the best performing feature set, we
incrementally select the k topmost features from the
list and perform 10-fold cross validation on the opti-
mization set. A plot of the iterative feature selection
is depicted in Figure 1.
8.2 Prediction Results 53
Rapidminer GUI
Missing
figure
Figure 8.2: The Graphical User Interface of RapidMiner 4.6
Table 8.1: Baseline perfomances.
Configurations Performance
Corpus Input Target MR/R ? ?
LetsGo DAct IQ-Med - - -AUTO IQ-Med - - -ALL IQ-Med - - -
LetsGoUser DAct IQ - - -AUTO IQ - - -ALL-U IQ - - -DAct US - - -AUTO US - - -ALL-U US - - -
5 10 15 20 25 30 35 40 45
0.45
0.5
0.55
0.6
0.65 max
#Parameters
MR
/R
IGR Parameter Selection
Figure 8.3: Parameter selection performance on the LetsGo Corpus for the optimizationset using set AUTO for prediction of IQ-Med.Figure 1: Performance of the SVM when iteratively in-
creasing the size of the feature vector with the k topmost
features according to IGR.
Several observations can be made: the best per-
forming feature set consists of 20 features with an
absolute performance of 65 % MR/R on the op-
timization set. However, a similar performance
can already be gained with the 7 top-most fea-
tures. All other features obviously neither signif-
icantly decrease nor increase the performance and
can be considered irrelevant for predicting the IQ
score. The impact of feature selection on the model
when evaluated on the single feature groups from
the test/training set using only the most relevant fea-
tures from the optimization set can be seen in the
lower part of Table 2. Again, 10-fold cross vali-
dation has been applied. The AUTO group benefits
from the selection and delivers the highest perfor-
mance with 20 features with an MR/R of 61.6%,
which is an increase of 3.2%. The upper baseline
with hand annotated features (ALL group) amounts
to 62.5%. The fact that the AUTOEMO set underper-
forms with 60.4% - in comparison to the AUTO set
- can be explained due to the potentially too small
size of the optimization set.
The confusion matrix for the AUTO feature set is
depicted in Table 4, along with the class-wise pre-
cision and recall values. The model yields the best
179
performance in predicting the scores at the edge, i.e.
?5? and ?1?. In between, the confusion is slightly
higher and the model performance lower.
Table 4: Confusion matrix including class-wise preci-
sion and recall values after 10-fold cross validation (train-
ing/test set) using the AUTO set. A (weighted average)
accuracy of 67.5% can be derived.
true 5 true 4 true 3 true 2 true 1 prec.
pred. 5 721 154 42 9 5 0.774
pred. 4 89 464 104 44 19 0.644
pred. 3 17 63 231 49 38 0.580
pred. 2 2 15 39 89 33 0.500
pred. 1 4 23 29 27 169 0.670
rec. 0.865 0.645 0.519 0.408 0.640
9 Linear Regression Modeling
Models from the initially mentioned PARADISE ap-
proach presume a linear relationship between input
variables - quantifying the dialogue - and the target
variable US, the user satisfaction. Assuming lin-
earity, such linear models allow inferences such as
?The longer the dialogue duration, the lower the sat-
isfaction?. While linear modeling is descriptive and
easy to read it delivers poor performance when ap-
plied on non-linear problems. Such non-linear prob-
lems reach a better predictability using Support Vec-
tor Machines (SVM). Although we anticipate that a
relationship between IQ and the interaction param-
eters is not given, we list a multivariate linear re-
gression model for comparison reasons with PAR-
ADISE.
The linear regression model of Interaction Quality
is calculated as follows:
IQ =
n?
i=1
wi ? N (pi)
where wi is the weight for the interaction parame-
ters pi, and N the z-score normalization function.
N normalizes the input variables to a mean of zero
and a standard deviation of one. This eliminates the
variying scales of the input variables.
From the CMU Let?s Go dataset we obtained the
following IQ function using the ALL feature set:
IQ = 0.7797 ? N (TURNNUMBER)
+ 0.7797 ? N (#SYSTEMTURNS)
? 0.7386 ? N (#ASRSuccess)
? 0.7175 ? N (#USERTURNS)
? 0.3019 ? N (%RePrompts)
? 0.2371 ? N (EMOTIONALSTATE)
? 0.2224 ? N (#ASRRejections)
? 0.1961 ? N (#TIMEOUTS ASRREJ)
+ 0.1912 ? N (ASRRECOGNITIONSTATUS)
+ 0.1648 ? N (ASRCONFIDENCE)
? 0.1592 ? N (#ASRSUCCESS)
? 0.1466 ? N (ACTIVITY)
+ 0.1388 ? N (ACTIVITYTYPE)
+ 0.1231 ? N (MEANASRCONFIDENCE)
? 0.0981 ? N (#SYSTEMQUESTIONS)
+ 0.0948 ? N (%ASRREJECTIONS)
? 0.0918 ? N (#TIMEOUTS ASRREJ)
+ 0.0835 ? N (#Reprompts)
+ 0.0812 ? N (%BARGE-INS)
? 0.0567 ? N (%TIME-OUTPROMPTS)
? 0.0555 ? N (#TIMEOUTS?ASRREJ)
? 0.0467 ? N (#Time-OutPrompts)
+ 0.0461 ? N (WPST)
+ 0.0432 ? N (HANDTRANSCRIPTION)
? 0.0425 ? N (LOOPNAME)
+ 0.0375 ? N (#SystemQuestions)
+ 0.0374 ? N (SEMANTICPARSE)
? 0.0345 ? N (BARGED-IN?)
+ 0.0338 ? N (RoleIndex)
? 0.0335 ? N (#REPROMPTS)
? 0.0316 ? N (#ASRREJECTIONS)
+ 0.0302 ? N (REPROMPT?)
+ 0.0249 ? N (WPUT)
+ 0.0225 ? N (ROLENAME)
Parameters occurring in the top 10 feature list ac-
cording to IGR (see Table 3) are printed in bold-
face. It is interesting to note that parameters related
to the progress of the dialogue (TURNNUMBER,
#SYSTEMTURNS, #USERTURNS) seem to play the
most important role, which can easily be explained:
the later in the dialogue, the higher the probabil-
ity that the score is low, due to the nature of IQ.
Remember that all dialogues have been annotated
with high IQ scores (?5?) in the beginning (see also
180
Table 5). However, many inconsistencies remain
unexplained, e.g. the negative sign in ??0.7175 ?
N (#USERTURNS)? contradicting the positive sign
in ?+0.7797 ? N (#SYSTEMTURNS)?. The nega-
tive sign in ??0.7386 ? N (#ASRSUCCESS)? would
further imply that the more successful the ASR, the
lower the IQ score. This corroborates our suspicion
that IQ is not a linear problem.
To assess the performance of linear regression for
predicting IQ we employed 10-fold cross validation,
again with all 200 annotated dialogues. We obtained
a root mean squared error of 0.594 and R2 = 0.646.
Mapping the continuous values to discrete score
classes from 1-5, we obtain MR/R = 45.5%
(62.5% using SVM), ? = 0.352 (0.575) and ? =
0.46 (0.795). All values finally suggest that IQ is
better modeled with non-linear classifiers such as
SVMs or Multilayer Perceptrons (MLP).
10 Conclusion and Discussion
In this work we have developed a statistical model
that predicts Interaction Quality, an objective mea-
sure of user satisfaction, at arbitrary points in an
SDS. The model targets on predicting critical situ-
ations on exchange level in ongoing dialogues. The
classifier, an SVM, reaches a performance of 61.6%
MR/R (? = 0.563, ? = 0.786) by use of an opti-
mized feature set that can be automatically derived
during the interaction. It could be further shown
that linear modeling with multivariate linear regres-
sion is not appropriate for predicting IQ and reaches
merely 45.5.% MR/R. Among all five feature groups
comprising altogether 52 features, the ASR and DM
groups contribute the most, while the EMOTIONAL-
STATE underperforms. We could further show that
features requiring manual annotation, such as dia-
logue acts, do not significantly improve the model?s
performance. The model has been evaluated with
200 dialogues from the CMU Let?s Go corpus com-
prising 4885 system-user exchanges where three an-
notators labeled the Interaction Quality on a score
from 1-5. We could show that the median of all three
opinions depicts the most generic view on the IQ and
is thus chosen as final score for the model.
Some issues have to be addressed in future work:
In the current study we assume that Interaction
Quality is an objective metric for determining the
satisfaction of users during the interaction. How
far this assumption is justified has to be empirically
proven in a laboratory study with real users. A cor-
responding study is in preparation and the results
will be published in a follow-up work. Although
the model?s performance can be considered as sat-
isfying, the direct deployment in dialogue systems
cannot be recommended at this stage. For enabling
a dialogue system to react on poor interaction qual-
ity, a correct prediction of the low IQ scores 1,2 and
3 is urgent, i.e. the classifier has to be optimized
to deliver a very high precision on such low scores
rather than towards a high general MR/R value. We
assume that the performance can be further driven
up by extending the feature space to the last n ex-
changes, which would take into account a larger
dialogue history for the decision (cf. (Schmitt et
al., 2010b)). The presented model can principally
be trained on data from any dialogue system; how-
ever, we did not yet deliver the proof that the present
model trained on Let?s Go data is general enough
for cross-domain and cross-system application with-
out significant performance loss. Due to the general
character of the ten most relevant features (cf. Table
3), portability can at least be assumed - without the
need for domain-dependent and system-dependent
re-training.
11 Acknowledgements
We would like to thank Maxine Eskenazi, Alan
Black, Lori Levin, Rita Singh, Antoine Raux and
Brian Langner from the Let?s Go Lab at Carnegie
Mellon University, Pittsburgh, for providing the
Let?s Go Sample Corpus. Further we would like to
thank the reviewers for their constructive advices.
The research leading to these results has re-
ceived funding from the Transregional Collabora-
tive Research Centre SFB/TRR 62 ?Companion-
Technology for Cognitive Technical Systems?
funded by the German Research Foundation (DFG).
181
References
K. P. Bennett and C. Campbell. 2000. Support vector
machines: Hype or hallelujah? Journal of SIGKDD
Explorations, 2(2):1?13.
W. J. Doll and G. Torkzadeh. 1991. The measure-
ment of end-user computing satisfaction: theoretical
and methodological issues. MIS Q., 15:5?10, March.
K.-P. Engelbrecht, F. Go?dde, F. Hartard, H. Ketabdar, and
S. Mo?ller. 2009. Modeling user satisfaction with hid-
den markov model. In Proc. of SIGDIAL 2009 Con-
ference, pages 170?177. ACL.
S. Hara, N. Kitaoka, and K. Takeda. 2010. Estimation
method of user satisfaction using n-gram-based dialog
history model for spoken dialog system. In Proc. of
the Seventh conference on International Language Re-
sources and Evaluation (LREC?10), Valletta, Malta.
R. Higashinaka, Y. Minami, K. Dohsaka, and T. Meguro.
2010a. Issues in predicting user satisfaction transi-
tions in dialogues: Individual differences, evaluation
criteria, and prediction models. In Spoken Dialogue
Systems for Ambient Environments, Lecture Notes in
Computer Science, pages 48?60. Springer Berlin /
Heidelberg.
R. Higashinaka, Y. Minami, K. Dohsaka, and T. Meguro.
2010b. Modeling user satisfaction transitions in dia-
logues from overall ratings. In Proceedings of the SIG-
DIAL 2010 Conference, pages 18?27, Tokyo, Japan,
September. ACL.
ISO. 1998. Ergonomic requirements for office work with
visual display terminals (VDTs), Part 11: Guidance on
usability. International Standardization Organization
(ISO).
B. Ives, M. H. Olson, and J. J. Baroudi. 1983. The mea-
surement of user information satisfaction. Commun.
ACM, 26:785?793.
D. Larcker and V. P. Lessig. 1980. Perceived usefulness
of information: A psychometric examination. Deci-
sion Sciences, pages 121?134, November.
G. Lindgaard and C. Dudek. 2003. What is this evasive
beast we call user satisfaction? Interacting with Com-
puters, 15(3):429?452.
J. C. Platt, 1999. Fast training of support vector ma-
chines using sequential minimal optimization, pages
185?208. MIT Press, Cambridge, MA, USA.
A. Raux, D. Bohus, B. Langner, A. W. Black, and M. Es-
kenazi. 2006. Doing research on a deployed spoken
dialogue system: One year of lets go! experience. In
Proc. of the International Conference on Speech and
Language Processing (ICSLP).
A. Schmitt, C. Hank, and J. Liscombe. 2008. Detecting
problematic calls with automated agents. In 4th IEEE
Tutorial and Research Workshop Perception and Inter-
active Technologies for Speech-Based Systems, Irsee
(Germany), June.
Alexander Schmitt, Tobias Heinroth, and Jackson Lis-
combe. 2009. On nomatchs, noinputs and bargeins:
Do non-acoustic features support anger detection? In
Proceedings of the 10th Annual SIGDIAL Meeting on
Discourse and Dialogue, SigDial Conference 2009,
London (UK), September. Association for Computa-
tional Linguistics.
Alexander Schmitt, Tim Polzehl, and Wolfgang Minker.
2010a. Facing reality: Simulating deployment of
anger recognition in ivr systems. In Second In-
ternational Workshop on Spoken Dialogue Systems
(IWSDS), September.
Alexander Schmitt, Michael Scholz, Wolfgang Minker,
Jackson Liscombe, and David Su?ndermann. 2010b.
Is it possible to predict task completion in automated
troubleshooters? In Proc. of the International Confer-
ence on Speech and Language Processing (ICSLP).
Marilyn Walker, Candace Kamm, and Diane Litman.
2000. Towards developing general models of usabil-
ity with paradise. Nat. Lang. Eng., 6(3-4):363?377.
182
Appendix
1 Welcome to the CMU Let?s Go bus information system.
2 To get help at any time, just say Help or press zero.
3 What can I do for you?
<DTMF-Zero>
4 I am an automated spoken dialogue system that can give you
schedule information for bus routes in Pittsburgh?s East End.
You can ask me about the following buses: 28X, 54C, 56U,
59U, 61A, 61B, 61C, 61D, 61F, 64A, 69A, and 501.
5 What bus schedule information are you looking for?
6 For example, you can say, when is the next 28X from DOWN-
TOWN to THE AIRPORT? or I?d like to go from MCK-
EESPORT to HOMESTEAD tomorrow at 10 a.m..
28X
7 The 56C . Is this correct?
No, 28X
8 What can I do for you?
I want to know whether /uh/ tomorrow the bus is available or
not.
9 Leaving at 11 p.m. . Did I get that right?
No, I just want to know is there any bus service for 28X tomor-
row.
10 Please use shorter answers because I have trouble understand-
ing long sentences.
11 Leaving at 11 p.m. . Is this correct?
On twenty third november.
12 Leaving at 11 p.m. . Is this correct?
No, I want to know the schedule on twenty third november
13 Leaving at 2 a.m. . Did I get that right?
<noise>
14 If you want to leave at 2 a.m. say yes or press one, otherwise
say no or press three.
no <noise>
15 Going to NORTH AND CEDAR. Did I get that right?
28x going to airport at seven a.m.
16 Please use shorter answers because I have trouble understand-
ing long sentences.
17 Going to NORTH AND CEDAR. Is this correct?
No.
18 Leaving from DYNAMO. Is this correct?
No.
19 Leaving from DYNAMO. Is this correct?
Leaving to airport.
20 Leaving from AIRPORT . Did I get that right?
yes
21 Right
22 Where are you going?
To airport.
23 Going to AIRPORT. Did I get that right?
yeah, yep
24 Okay
25 When would you like to travel?
yes
26 When would you like to travel?
Twenty third November.
27 When would you like to travel?
Tomorrow.
28 At what time do you wanna travel?
Seven a.m.
29 Leaving at 7 a.m. . Is this correct?
yep
30 Alright
31 Just a minute. I?ll look that up.
32 AIRPORT and AIRPORT are both the same stop. Please pro-
vide a different start or end point.
33 To ask about a different trip, you can say, start a new query. If
you are finished, you can say goodbye.
Yes.
34 You can say start a new query, or goodbye.
No.
35 To ask about a different trip, you can say, start a new query. If
you are finished, you can say goodbye.
<noise>
36 You can say start a new query, or goodbye.
<noise>
You can say start a new query, or goodbye.
<hangup>
Table 5: Example dialogue (ID: 2061122025) from the CMU Let?s Go System (2006 corpus) with low Interaction
Quality. The user utterances are printed in italic.
5
1
6
11
16
21
26
31
36
uality
Ex
ch
an
ge
s
m
ed
ian
ra
te
r1
1234
Interaction?Q
ra
te
r2
ra
te
r3
1 345
tion?Quality
m
ed
ian
m
od
el?
hy
po
th
es
is
12
Interac
Figure 2: Upper chart: Turn-wise Interaction Quality (IQ) annotation from 3 raters. The final label is the median of
all three opinions. Lower chart: median reference vs. hypothesis of the model trained with AUTO feature set.
183
1 2 3 4 50
500
1,000
1,500 12941220
792
595
983
Rating
Fre
que
ncy
Rater1
1 2 3 4 50
500
1,000
1,500 1417
1043
797
555
1072
Rating
Fre
que
ncy
Rater2
1 2 3 4 50
500
1,000
1,500
1656
1416
927
442443
Rating
Fre
que
ncy
Rater3
Figure 3: Rating distribution for Interaction Quality within the Let?s Go Corpus for each rater.
Table 6: Rater guidelines for annotating Interaction Quality.
Rule Description
1. The rater should try to mirror the users point of view on the interaction as objectively as possible.
2. An exchange consists of the system prompt and the user response. Due to system design, the latter is not always present.
3. The IQ score is defined on a 5-point scale with ?1=bad?, ?2=poor?, ?3=fair?, ?4=good? and ?5=excellent?.
4. The Interaction Quality is to be rated for each exchange in the dialogue. The history of the dialogue should be kept in
mind when assigning the score. For example, a dialogue that has proceeded fairly poor for a long time, should require
some time to recover.
5. A dialogue always starts with an Interaction Quality score of ?5?.
6. The first user input should also be rated with 5, since until this moment, no rateable interaction has taken place.
7. A request for help does not invariably cause a lower Interaction Quality, but can result in it.
8. In general, the score from one exchange to the following exchange is increased or decreased by one point at the most.
9. Exceptions, where the score can be decreased by two points are e.g. hot anger or sudden frustration. The rater?s
perception is decisive here.
10. Also, if the dialogue obviously collapses due to system or user behavior, the score can be set to ?1? immediately. An
example herefore is a reasonable frustrated sudden hang-up.
11. Anger does not need to influence the score, but can. The rater should try to figure out whether anger was caused by the
dialogue behavior or not.
12. In the case a user realizes that he should adapt his dialogue strategy to obtain the desired result or information and
succeeded that way, the Interaction Quality score can be raised up to two points per turn. In other words, the user
realizes that he caused the poor Interaction Quality by himself.
13. If the system does not reply with a bus schedule to a specific user query and prompts that the request is out of scope,
this can nevertheless be considered as ?task completed?. Therefore this does not need to affect the Interaction Quality.
14. If a dialogue consists of several independent queries, each query?s quality is to be rated independently. The former
dialogue history should not be considered when a new query begins. However, the score provided for the first exchange
should be equal to the last label of the previous query.
15. If a dialogue proceeds fairly poor for a long time, the rater should consider to increase the score more slowly if the
dialogue starts to recover. Also, in general, he should observe the remaining dialogue more critical.
16. If a constantly low-quality dialogue finishes with a reasonable result, the Interaction Quality can be increased.
184
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 126?130,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Estimating Adaptation of Dialogue Partners
with Different Verbal Intelligence
K.Zablotskaya
Inst. of Communications
Engineering,
University of Ulm, Germany
kseniya.zablotskaya@
uni-ulm.de
F.Ferna?ndez-Mart??nez
E.T.S.I. de Telecomunicac??on,
Universidad Polite?cnica
de Madrid, Spain
ffm@die.upm.es
W.Minker
Inst. of Communications
Engineering,
University of Ulm, Germany
wolfgang.minker@
uni-ulm.de
Abstract
This work investigates to what degree speak-
ers with different verbal intelligence may
adapt to each other. The work is based on
a corpus consisting of 100 descriptions of a
short film (monologues), 56 discussions about
the same topic (dialogues), and verbal intelli-
gence scores of the test participants. Adapta-
tion between two dialogue partners was mea-
sured using cross-referencing, proportion of
?I?, ?You? and ?We? words, between-subject
correlation and similarity of texts. It was
shown that lower verbal intelligence speak-
ers repeated more nouns and adjectives from
the other and used the same linguistic cat-
egories more often than higher verbal in-
telligence speakers. In dialogues between
strangers, participants with higher verbal in-
telligence showed a greater level of adapta-
tion.
1 Introduction
When two speakers are talking to each other, they try
to adapt to their dialogue partner and synchronize
their verbal behaviours. The adaptation may occur
at different levels: lexical (Garrod and Anderson,
1987; Brennan and Clark, 1996), syntactic (Reitter
et al, 2006), acoustic (Ward and Litman, 2007), ar-
ticulation (Bard et al, 2000), comprehension (Lev-
elt and Kelter, 1982), etc. Moreover, synchroniza-
tion of dialogue partners at one level may cause the
adaptation process at any other level (Pickering and
Garrod, 2004; Cleland and Pickering, 2003). In this
paper we analyse to what degree dialogue partners
with different verbal intelligence and levels of ac-
quaintance may adapt to each other during a conver-
sation.
Verbal intelligence (VI) is ?the ability to analyse
information and to solve problems using language-
based reasoning? (Logsdon, 2012). The ability to
find suitable words and expressions may be a great
help in accomplishing such goals as persuasions, en-
couragements, explanations, influence, etc. More-
over, there exists a dependency between an individ-
ual?s verbal intelligence level and his or her success
in life (Buzan, 2002).
The first hypothesis we check in this paper is that
both lower and higher verbal intelligence speakers
are able to adapt to their dialogue partners; how-
ever, this adaptation is reflected by different linguis-
tic features.
The second hypothesis we check in this work
is that when higher and lower verbal intelligence
speakers are talking to a stranger, the former ones
adapt better to their dialogue partner than the latter
ones.
This investigation may be helpful for improv-
ing the user-friendliness of spoken language dia-
logue systems. Systems which automatically adapt
to users? language styles and change their dialogue
strategies may help users to feel free and comfort-
able when interacting with them.
2 Method
2.1 Corpus Description
For the analysis, a corpus containing 100 mono-
logues, 56 dialogues and 100 verbal intelligence
126
scores of the participants was used. The corpus was
collected at the University of Ulm, Germany. All
the participants were German native speakers of dif-
ferent genders, ages, educational levels and social
status. For the monologue collection, the partici-
pants were shown a short film and were asked to
describe it with their own words. The candidates
were not asked to follow the language style of the
film; they were asked to talk as naturally as possi-
ble in order to capture their every day conversation
styles. Each monologue is about 3 minutes long and
contains 370 words on an average. For the dialogue
collection, the participants were asked to have a 10-
minute conversation with another test person. The
topic of the discussions was always the same: the
education system in Germany. The average num-
ber of turns in the dialogues is 55. Afterwards,
verbal intelligence of the candidates was measured
using the Hamburg Wechsler Intelligence Test for
Adults (Wechsler, 1982). Using this test, we ob-
tained verbal intelligence scores of the test persons
with a mean value of 113 and a standard deviation of
7.2. A more detailed description of the corpus can
be found in (Zablotskaya et al, 2010; Zablotskaya
et al, 2012).
2.2 Clustering
Using the k-means algorithm, the verbal intelligence
scores of the test persons were partitioned into:
a) 2 clusters (Cluster L consisted of test persons
with lower verbal intelligence, H contained
candidates with higher verbal intelligence);
b) 3 clusters (L - lower verbal intelligence, M -
average verbal intelligence, H - higher verbal
intelligence).
Using the two clusters L and H, all the dialogues
were partitioned into the following groups:
c) L-L is a group of dialogues where both partners
had lower verbal intelligence scores;
d) H-H is a group of dialogues where both part-
ners had higher verbal intelligence scores;
e) L-H is a group of all the other dialogues.
Using the information about the level of acquain-
tance of the dialogue partners, the following groups
were created:
f) F-F is a group of dialogues with dialogue part-
ners who were friends or relatives;
g) S-S is a group of dialogues with dialogue part-
ners who had not met each other before the ex-
periment (were strangers).
In the following sections the degree of adaptation
will be compared between these groups.
3 Measuring Adaptation
There exist different approaches for measuring
adaptation of dialogue partners. Reitter et al (2006)
used regression models to show that a speaker in
human-human interactions aligns his syntactic struc-
tures with those of his dialogue partner. Ward and
Litman (2007) modified the measures of conver-
gence offered by Reitter. According to this mod-
ification, prime words of the first dialogue part-
ner were determined. For measuring lexical con-
vergence, the use of prime words by the second
dialogue partner for each turn was calculated. In
(Nenkova et al, 2008) the measurements of adapta-
tion between dialogue partners were based on the us-
age of high-frequency words. Stoyanchev and Stent
(2009) analysed adaptation calculating the number
of reused verbs and prepositions by a speaker that
occurred in his dialogue partner?s turns.
In this work we measure adaptation as cross ref-
erencing, proportion of ?I?, ?You? and ?We? words,
between-subject correlation and similarity between
two texts. These approaches are described in the fol-
lowing sections.
3.1 Cross Referencing
Cross referencing is calculated as a number of re-
peated nouns and adjectives by a speaker P1 from
his dialogue partner P2 divided by the total number
of P1?s words (Sillars et al, 1997).
A one-way analysis of variance (ANOVA)
showed significant difference between Cross refer-
encing of speakers from the groups L, M and H
(AVL = 0.08, AVM = 0.047, AVH = 0.042, F(2,97) =
8.43, p = 0.00062). As we may see, speakers with
lower verbal intelligence reused more nouns and ad-
jectives of their dialogue partners than speakers with
average and higher verbal intelligence.
127
3.2 ?I?, ?You? and ?We? words
The number of ?I?, ?You? and ?We? words in a dis-
cussion may reflect the degree of closeness of speak-
ers. In Sillars et al (1997) these measures were used
for the analysis of language use in marital conver-
sations and closeness of relationships between part-
ners. It was found out that partners who had lived
with each other for a long time and were happy to-
gether used ?we? pronouns more often than sepa-
rate pairs. In addition, the proportion of ?I? and
?You? words were higher for separates. In our in-
vestigation we also calculated the proportion of ?I?,
?You? and ?We? words for each groups and com-
pared them using ANOVA. Interestingly, the pro-
portion of ?I?-words of friends was greater than
that of strangers (averaged value of ?I?-words for
friends AVF = 0.0033, for strangers AVS = 0.0017,
F(1,109) = 5.33, p = 0.024). This phenomena
may be explained in the following way. Even dis-
cussing the German education, friends might talk
about themselves. People who had not met each
other before avoided talking too much about their
own experience. On the other hand, the difference
of ?We?-words was not significant. This means that
even friends were not able to linguistically show
their closeness discussing such kind of topic.
3.3 Between-Subject Correlation
All the dialogue transcripts were compared with the
LIWC dictionary for the German language (Wolf et
al., 2008). The dictionary consists of different words
sorted by 64 categories. The categories may be di-
vided into the following groups:
? Language composition, for example number of
words, number of unique words, pronouns, ar-
ticles, etc.
? Psychological processes, for example positive
and negative emotions, causal words, words ex-
pressing certainty, etc.
? Relativity, for example words related to space,
motion and time.
? Topic-related categories, for example job,
school, sleep, etc.
Each word from the dictionary may refer to sev-
eral categories. For example, the word traurig (sad)
refers to the categories Affective Processes, Negative
emotions and Sadness.
For analysing the degree of adaptation of dialogue
participants, Pearson?s correlation coefficients be-
tween F(Ai) and F(Bi) for each feature F were cal-
culated (F(Ai) is the value of a feature F extracted
from the utterances of the first dialogue partner A
from a dialogue i, F(Bi) is the value of a feature F
extracted from the utterances of the second dialogue
partner B from a dialogue i). For participants from
the group L-L, 30% of the features showed a signif-
icant correlation, for participants from the group H-
L this value was 23%, for H-H this value was 12%.
Table 1 shows the percentage of features with sig-
nificant correlation for each LIWC group.
LIWC group H-H L-L H-L
Language composition 28% 37% 9%
Psychological precesses 10% 19% 23%
Relativity 10% 35% 30%
Topic-related categories 11% 37% 27%
Table 1: Percentage of LIWC categories with significant
correlation coefficients.
As we can see from the results, for almost all
LIWC groups lower verbal intelligence speakers en-
gaged in a conversation showed a higher degree of
adaptation.
3.4 Similarity between two Texts
If two dialogue partners adapt to each other during
a conversation, the similarity between their utter-
ances should be high. For measuring the similar-
ity between two texts, we calculated the degree of
alignment between frequency distributions of cer-
tain features (tokens) extracted from the dialogues.
For comparing the frequency distributions, the chi-
square test was chosen because it does not require
the normality of distributions and is easy to imple-
ment. A detailed explanation of this method may
be found in (Vogel and Lynch, 2007) and (Straker,
2012).
Let Fi and Fj be two text files containing ni and n j
tokens correspondingly. If Fi and Fj have the same
language style, we consider the texts to be taken
from the same population and the distributions of
tokens from the two files should not be significantly
different (null hypothesis). The chi-square statistic
128
is calculated based on the observed and expected
values of tokens in both text-files. If the chi-value
?2i is less than a certain significance threshold c2i
(based on the degrees of freedom and significance
level), the null hypothesis is accepted and the two
files may be considered as having a similar language
style (making an assumption that the language style
is reflected by tokens of this type). For estimating
the degree to which the two texts are similar, we cal-
culate the distance between these two values:
Similarityi = Si = ?2i ? c2i .
If ?c2i <= Si <= 0, the similarity between the texts
is significant. If Si > 0, the null hypothesis is re-
jected: the analysed texts have different language
styles.
In this investigation four different types of tokens
were extracted: Letter n-gram distributions, Word n-
gram distributions, Lemma n-gram distributions and
Part-of-speech n-gram distributions.
The mean values of Si for each group were com-
pared to each other using ANOVA. Features with
significant ANOVA results for the groups F-F and
S-S are shown in Table 2:
Feature Si for F-F Si for S-S F(1,54)
Word 3-g -48.7 -29.8 10.6
Lemma 3-g -41.8 -23.5 10.1
P.-of-speech 4-g -38.9 10.0 8.1
P.-of-speech 5-g -59.4 -34.3 8.6
Table 2: Significant features for F-F and S-S (p < 0.05).
The results show that the similarities of language
between friends or relatives were greater than be-
tween participants who had not met each other be-
fore.
Our next purpose was to check whether verbal
intelligence plays a certain role if we analyse di-
alogues between friends and strangers separately.
ANOVA was applied to the mean values of the
similarity measure Si calculated for the following
groups:
a) L-L, H-H and L-H only for dialogues between
friends;
b) L-L, H-H and L-H only for dialogues between
strangers.
ANOVA significant feature are shown in Tables 3
and 4.
Feature Si(L-L) Si(H-H) Si(L-H) F
Word 4-g -77.8 -62.4 -53.81 3.9
P.-of-sp. 6-g -83.5 -63.7 -53.9 4.7
Table 3: Significant features for L-L, H-H and L-H only
for dialogues between friends (p < 0.05, F(1,53)).
Feature Si(L-L) Si(H-H) Si(L-H) F
Word 4-g. -59.9 -90.1 -45.2 2.2
Table 4: Significant features for L-L, H-H and L-H only
for dialogues between strangers (p < 0.05, F(1,53)).
As we may see from the results, a lower verbal
intelligence speaker may adapt to his dialogue part-
ner if they both are relatives or friends. On the other
hand, if dialogue partners have not met each other
before, higher verbal intelligence speakers are bet-
ter able to adapt to their dialogue partner than lower
verbal intelligence speakers.
4 Discussions
As we may see from the results, it was difficult for
the candidates to linguistically show their closeness
discussing the education system in Germany. How-
ever, similarity of utterances in dialogues between
friends was greater than similarity in dialogues be-
tween strangers. Lower verbal intelligence speakers
repeated nouns and adjectives from their dialogue
partners and used words from the same linguistic
dimensions more often than higher verbal intelli-
gence speakers. The first hypothesis is just partly
proven because we did not find features that reflect
adaptation of higher verbal intelligence speakers. In
our future work we are going to further investigate
how higher verbal intelligence speakers linguisti-
cally show their closeness to the other. The results
also showed that speakers with lower verbal intelli-
gence are better able to adapt to the other if they both
are relatives or friends. As we suggested in our sec-
ond hypothesis, if dialogue partners are strangers,
higher verbal intelligence speakers show a higher
degree of adaptation. In our future work we are go-
ing to use this information for improving the clas-
sification of speakers into two and three groups ac-
cording to their verbal intelligence coefficients.
129
Acknowledgments
This work is partly supported by the DAAD (Ger-
man Academic Exchange Service).
Parts of the research described in this arti-
cle are supported by the Transregional Collabora-
tive Research Centre SFB/TRR 62 ?Companion-
Technology for Cognitive Technical Systems?
funded by the German Research Foundation (DFG).
References
Bard, E. G., Anderson, A. H., Sotillo, C., Aylett, M.,
Doherty-Sneddon, G. and Newlands, A. 2000. Con-
trolling the intelligibility of referring expressions in di-
alogue. Journal of Memory and Language, 42, p.1-22.
Brennan, S. E. and Clark, H. H. 1996. Conceptual pacts
and lexical choice in conversation. Journal of Exper-
imental Psychology: Learning, Memory, and Cogni-
tion, 22, p. 1482-1493.
Buzan, T. 2002. The power of verbal intelligence.
HarperCollins Publishers, Inc.
Cleland, A. A. and Pickering, M. J. 2003. The use of lex-
ical and syntactic information in language production:
Evidence from the priming of noun-phrase structure.
Journal of Memory and Language, 49, p.214-230.
Garrod, S. and Anderson, A. 1987. Saying what you
mean in dialogue: A study in conceptual and semantic
co-ordination. Cognition, 27, p. 181-218.
Levelt, W. J. M. and Kelter, S. 1982. Surface form
and memory in question answering. Cognitive Psy-
chology, 14, p.78-106.
Logsdon, A. 2012. Learning Disabilities.
http://www.learningdisabilities.about.com/
Nenkova, A., Gravano, A. and Hirschberg, J. 2008. High
frequency word entrainment in spoken dialogue. Pro-
ceedings of ACL/HLT 2008, p.169-172.
Pickering, M. and Garrod, S. 2004. Toward a mech-
anistic psychology of dialog. Behavioral and Brain
Sciences, 27, p.169-190.
Reitter, D., Keller, F. and Moore, J. 2006. Computational
modelling of structural priming in dialogue. In Pro-
ceedings of the Human Language Technology Confer-
ence of the NAACL, companion volume, 2006, p. 121-
124.
Sillars A.L., Shellen W., McIntosh A. and
Pomegranate M.A. Relational characteristics of
language: Elaboration and differentiation in marital
conversations. Western Journal of Communication,61,
p.403-422.
Stoyanchev, S. and Stent, A. 2009. Lexical and Syntactic
Priming and Their Impact in Deployed Spoken Dialog
Systems. Proceedings of NAACL HLT 2009, Boulder,
Colorado, p.189-192.
Straker D. Changing Minds. http://changingminds.org/
explanations/research/analysis/chi-square.htm.
Vogel C. and Lynch G. Computational Stylometry:
Who?s in a Play? In Proceedings of COST 2102 Work-
shop (Patras)?2007, p.169-186.
Ward, A. and Litman, D. 2007. Automatically measur-
ing lexical and acoustic/prosodic convergence in tu-
torial dialog corpora. In Proceedings of the SLaTE
Workshop on Speech and Language Technology in Ed-
ucation.
Wechsler D. 1982. Handanweisung zum Hamburg-
Wechsler-Intelligenztest fu?r Erwachsene (HAWIE).
Separatdr., Bern; Stuttgart; Wien; Huber.
Wolf M., Horn A.B., Mehl M.R. and Haug S. A?quivalenz
und Robustheit der deutschen Version des Linguistic
Inquiry and Word Count Diagnostica, 54, Heft 2,
p.85-98.
Zablotskaya K., Ferna?ndez-Mart??nez F. and Minker W.
2012. Investigating Verbal Intelligence using the TF-
IDF Approach. Proceedings of International Confer-
ence on Language Resources and Evaluation (LREC)
2012, European Language Resources Association
(ELRA).
Zablotskaya K., Walter S. and Minker W. 2010. Speech
data corpus for verbal intelligence estimation. In Pro-
ceedings of International Conference on Language Re-
sources and Evaluation (LREC) 2010, European Lan-
guage Resources Association (ELRA), Valetta, Malta.
130
NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 49?52,
Montre?al, Canada, June 7, 2012. c?2012 Association for Computational Linguistics
Towards Quality-Adaptive Spoken Dialogue Management
Stefan Ultes, Alexander Schmitt, Wolfgang Minker
Dialogue Systems - Ulm University
Albert-Einstein-Allee 43
89081 Ulm, Germany
{stefan.ultes,alexander.schmitt,wolfgang.minker}@uni-ulm.de
Abstract
Information about the quality of a Spoken Di-
alogue System (SDS) is usually used only for
comparing SDSs with each other or manually
improving the dialogue strategy. This infor-
mation, however, provides a means for inher-
ently improving the dialogue performance by
adapting the Dialogue Manager during the in-
teraction accordingly. For a quality metric to
be suitable, it must suffice certain conditions.
Therefore, we address requirements for the
quality metric and, additionally, present ap-
proaches for quality-adaptive dialogue man-
agement.
1 Introduction
For years, research has been focused on enabling
Spoken Dialogue Systems (SDSs) to behave more
adaptively to the user?s expectations and needs.
Mo?ller et al (2009) presented a taxonomy for qual-
ity of human-machine interaction, i.e., Quality of
Service (QoS) and Quality of Experience (QoE). For
QoE, several aspects are identified. They contribute
to good user experience, e.g., interaction quality, us-
ability and acceptability. These aspects can be com-
bined to the term User Satisfaction (US), describ-
ing the degree by which the user is satisfied with the
system?s performance. The dialogue community has
been investigating this aspect for years. Most promi-
nently is the PARADISE framework by Walker et al
(2000) which maps objective performance metrics
of an SDS to subjective user ratings.
Recent work mostly discusses how to evaluate
Spoken Dialogue Systems. However, the issue of
how this information can be useful for improv-
ing dialogue performance remains hardly addressed.
Hence, we focus on exploring techniques for incor-
porating dialogue quality information into the Dia-
logue Manager (DM). This is accompanied by the
problem of defining characteristics of a suitable dia-
logue quality metric.
In Section 2, we present related work both on
measuring dialogue quality and on approaches for
incorporating user state information into the DM.
In Section 3, requirements for a quality metric are
presented along with a suitable example. Section 4
presents our ongoing and future work on incorpo-
rating quality measures into dialogue strategies. Fi-
nally, Section 5 concludes this work.
2 Related Work
In recent years, several studies have been published
on determining the qualitative performance of a
SDS. Engelbrecht et al (2009) predicted User Sat-
isfaction on a five-point scale at any point within the
dialogue using Hidden Markov Models (HMMs).
Evaluation was based on labels the users applied
themselves during a Wizard-of-Oz experiment. To
guarantee for comparable conditions, the dialogue
flow was controlled by predefined scenarios creat-
ing transcripts with equal length for each scenario.
Further work based on HMMs was presented by
Higashinaka et al (2010). The HMM was trained on
US rated at each exchange. These exchange ratings
were derived from ratings for the whole dialogue.
The authors compare their approach with HMMs
trained on manually annotated exchanges achieving
a better performance for the latter.
49
In order to predict US, Hara et al (2010) created
n-gram models from dialogue acts (DA). Based on
dialogues from real users interacting with a music
retrieval system, overall ratings for the whole dia-
logue have been labeled on a five point scale after
the interaction. An accuracy (i.e., rate of correctly
predicted ratings) of 34% by a 3-gram model was
the best performance which could be achieved.
Dealing with true User Satisfaction, Schmitt et al
presented their work about statistical classification
methods for automatic recognition of US (Schmitt
et al, 2011b). The data was collected in a lab
study where the users themselves had to rate the
conversation during the ongoing dialogue. Labels
were applied on a scale from 1 to 5. Perform-
ing automatic classification using a Support Vector
Machine (SVM), they achieved an Unweighted Av-
erage Recall (UAR) of 49.2 (i.e., average rate of
correctly predicted ratings, compensated for unbal-
anced data).
An approach for affective dialogue modeling
based on Partially Observable Markov Decision
Processes (POMDPs) was presented by Bui et al
(2007). Adding stress to the dialogue state enables
the dialogue manager to adapt to the user. To make
belief-update tractable, the authors introduced Dy-
namic Decision Networks as means for reducing
complexity.
Pittermann et al (2007) presented another ap-
proach for adaptive dialogue management. The au-
thors incorporated emotions by modeling the dia-
logue in a semi-stochastic way. Thus, an emotional
dialogue model was created as a combination of a
probabilistic emotional model and probabilistic dia-
logue model defining the current dialogue state.
3 Interaction Quality Metric
In order to enable the Dialogue Manager to be
quality-adaptive, the quality metric must suffice cer-
tain criteria. In this Section, we identify the impor-
tant issues and render the requirements for a suitable
quality metric.
3.1 General Aspects
For adapting the dialogue strategy to the quality of
the dialogue, the quality metric is required to imple-
ment certain characteristics. We identify the follow-
ing items:
? exchange-level quality measurement,
? automatically derivable features,
? domain-independent features,
? consistent labeling process,
? reproducible labels and
? unbiased labels.
The performance of a Spoken Dialogue System
may be evaluated either on the dialogue level or on
the exchange level. As dialogue management is per-
formed after each system-user exchange, dynamic
adaption of the dialogue strategy to the dialogue
performance requires exchange-level performance
measures. Therefor, Dialogue-level approaches are
of no use. Furthermore, previous presented meth-
ods for exchange-level quality measuring could not
achieve satisfying accuracy in predicting dialogue
quality (Engelbrecht et al, 2009; Higashinaka et al,
2010).
Features serving as input variables for a classi-
fication algorithm must be automatically derivable
from the dialogue system modules. This is impor-
tant because other features, e.g., manually annotated
dialogue acts (Higashinaka et al, 2010; Hara et al,
2010), produce high costs and are also not available
immediately during run-time in order to use them as
additional input to the Dialogue Manager. Further-
more, for creating a general quality metric, features
have to be domain-independent, i.e., not depending
on the task domain of the dialogue system.
Another important issue is the consistency of the
labels. Labels applied by the users themselves are
subject to large fluctuations among the different
users (Lindgaard and Dudek, 2003). As this results
in inconsistent labels, which do not suffice for creat-
ing a generally valid quality model, ratings applied
by expert raters yield more consistent labels. The
experts are asked to estimate the user?s satisfaction
following previously established rating guidelines.
Furthermore, expert labelers are also not prone to be
influenced by certain aspects of the SDS, which are
not of interest in this context, e.g., the character of
the synthesized voice. Therefore, they create less bi-
ased labels.
50
3.2 Interaction Quality
As metric, which fulfills all previously addressed
requirements, we present the Interaction Quality
(IQ) metric, see also (2011a). Based on dialogues
from the ?Let?s Go Bus Information System? of the
Carnegie Mellon University in Pittsburgh (Raux et
al., 2006), IQ is labeled on a five point scale. The
labels are (from best (5) to worst (1)) ?satisfied?,
?slightly unsatisfied?, ?unsatisfied?, ?very unsatis-
fied? and ?extremely unsatisfied?. They are applied
by expert raters following rating guidelines, which
have been established to allow consistent and repro-
ducible ratings.
Additionally, domain-independent features used
for IQ recognition have been derived from the di-
alogue system modules automatically for each ex-
change grouped on three levels: the exchange level,
the dialogue level, and the window level. As parame-
ters like ASRCONFIDENCE or UTTERANCE can di-
rectly be acquired from the dialogue modules they
constitute the exchange level. Based on this, counts,
sums, means, and frequencies of exchange level pa-
rameters from multiple exchanges are computed to
constitute the dialogue level (all exchanges up to the
current one) and the window level (the three previous
exchanges).
A corpus containing the labeled data has been
published recently (Schmitt et al, in press) contain-
ing 200 calls annotated by three expert labelers, re-
sulting in a total of 4,885 labeled exchanges. Us-
ing statistical classification of IQ based on SVMs
achieves an Unweighted Average Recall of 0.58
(Schmitt et al, 2011a).
4 Quality-Adaptive Spoken Dialogue
Management
The goal of our work is to enable Dialogue Man-
agers to directly adapt to information about the qual-
ity of the ongoing dialogue. We present two differ-
ent approaches that outline our ongoing and future
work.
4.1 Dialogue Design-Patterns for Quality
Adaption
Rule-based Dialogue Managers are still state-of-the-
art for commercial SDSs. It is hardly arguable that
making the rules quality-dependent is a promising
way for dialogue improvement. However, the num-
ber of possibilities for adapting the dialogue strategy
to the dialogue quality is high. Based on the Speech-
Cycle RPA Dialogue Manager, we are planning on
identifying common dialogue situations in order to
create design-patterns. These patterns can be ap-
plied as a general means of dealing with situations
that arise by introducing quality-adaptiveness to the
dialogue.
4.2 Statistical Quality-Adaptive Dialogue
Management
For the incorporation of Interaction Quality into a
statistical DM, two approaches have been found.
First, based on work on factored Partially Observ-
able Markov Decision Processes by Williams and
Young (2007) and similar to Bui et al (2006), we
presented our own approach for incorporating addi-
tional user state information (Ultes et al, 2011).
In the factored POMDP by Williams and Young
(2007), the state of the underlying process is de-
fined as s = (u, g, h). To incorporate IQ, it is
extended by adding the IQ-state siq, resulting in
s = (u, g, h, siq).
Following the concept of user acts, we further in-
troduce IQ-acts iq that describe the current qual-
ity predicted by the classification algorithm for the
current exchange. Incorporating IQ acts into obser-
vation o results in the two-dimensional observation
space
O = U ? IQ,
where U denotes the set of all user actions and IQ
the set of all possible Interaction Quality values.
Second, for training an optimal policy for ac-
tion selection in POMDPs, a reward function has
to be defined. Common reward functions are task-
oriented and based on task success and dialogue
length. As an example, a considerable positive re-
ward is given for reaching the task goal, a consider-
able negative reward for aborting the dialogue, and a
small negative reward for each exchange in order to
keep the dialogue short. Interaction Quality scores
offer an interesting and promising way of defining a
reward function, e.g., by rewarding improvements in
IQ. By that, strategies that try to keep the quality at
an overall high can be trained allowing for a better
user experience.
51
5 Conclusion
For incorporating information about the dialogue
quality into the Dialogue Manager, we identified
characteristics of a quality metric defining neces-
sary prerequisites for being used during dialogue
management. Further, the Interaction Quality met-
ric has been proposed as measure, which suffices all
requirements. In addition, we presented concrete ap-
proaches of incorporating IQ into the DM outlining
our ongoing and future work.
Acknowledgements
We would like to thank Maxine Eskenazi, Alan
Black, Lori Levin, Rita Singh, Antoine Raux and
Brian Langner from the Lets Go Lab at Carnegie
Mellon University, Pittsburgh, for providing the Lets
Go Sample Corpus. We would further like to thank
Roberto Pieraccini and David Suendermann from
SpeechCycle, Inc., New York, for providing the
SpeechCycle RPA Dialogue Manager.
References
T. H. Bui, J. Zwiers, M. Poel, and A. Nijholt. 2006. To-
ward affective dialogue modeling using partially ob-
servable markov decision processes. In Proceedings
of workshop emotion and computing, 29th annual Ger-
man conference on artificial intelligence.
T. H. Bui, M. Poel, A. Nijholt, and J. Zwiers. 2007.
A tractable ddn-pomdp approach to affective dialogue
modeling for general probabilistic frame-based dia-
logue systems. In Proceedings of the 5th IJCAI Work-
shop on Knowledge and Reasoning in Practical Dia-
logue Systems, pages 34?37.
Klaus-Peter Engelbrecht, Florian Go?dde, Felix Hartard,
Hamed Ketabdar, and Sebastian Mo?ller. 2009. Mod-
eling user satisfaction with hidden markov model. In
SIGDIAL ?09: Proceedings of the SIGDIAL 2009 Con-
ference, pages 170?177. ACL.
Sunao Hara, Norihide Kitaoka, and Kazuya Takeda.
2010. Estimation method of user satisfaction using
n-gram-based dialog history model for spoken dia-
log system. In Proceedings of the Seventh conference
on International Language Resources and Evaluation
(LREC?10), Valletta, Malta, may. ELRA.
Ryuichiro Higashinaka, Yasuhiro Minami, Kohji
Dohsaka, and Toyomi Meguro. 2010. Modeling
user satisfaction transitions in dialogues from over-
all ratings. In Proceedings of the SIGDIAL 2010
Conference, pages 18?27, Tokyo, Japan, September.
Association for Computational Linguistics.
Gitte Lindgaard and Cathy Dudek. 2003. What is this
evasive beast we call user satisfaction? Interacting
with Computers, 15(3):429?452.
Sebastian Mo?ller, Klaus-Peter Engelbrecht, C. Ku?hnel,
I. Wechsung, and B. Weiss. 2009. A taxonomy of
quality of service and quality of experience of multi-
modal human-machine interaction. In Quality of Mul-
timedia Experience, 2009. QoMEx 2009. International
Workshop on, pages 7?12, July.
Johannes Pittermann, A. Pittermann, Hong Meng, and
W. Minker. 2007. Towards an emotion-sensitive
spoken dialogue system - classification and dialogue
modeling. In Intelligent Environments, 2007. IE 07.
3rd IET International Conference on, pages 239 ?246,
September.
Antoine Raux, Dan Bohus, Brian Langner, Alan W.
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: One year of
lets go! experience. In Proc. of the International Con-
ference on Speech and Language Processing (ICSLP),
September.
Alexander Schmitt, Benjamin Schatz, and Wolfgang
Minker. 2011a. Modeling and predicting quality in
spoken human-computer interaction. In Proceedings
of the SIGDIAL 2011 Conference, Portland, Oregon,
USA, June. Association for Computational Linguis-
tics.
Alexander Schmitt, Benjamin Schatz, and Wolfgang
Minker. 2011b. A statistical approach for estimat-
ing user satisfaction in spoken human-machine inter-
action. In Proceedings of the IEEE Jordan Confer-
ence on Applied Electrical Engineering and Comput-
ing Technologies (AEECT), Amman, Jordan, Decem-
ber. IEEE.
Alexander Schmitt, Stefan Ultes, and Wolfgang Minker.
in-press. A parameterized and annotated corpus of the
cmu let?s go bus information system. In International
Conference on Language Resources and Evaluation
(LREC).
Stefan Ultes, Tobias Heinroth, Alexander Schmitt, and
Wolfgang Minker. 2011. A theoretical framework for
a user-centered spoken dialog manager. In Proceed-
ings of the Paralinguistic Information and its Integra-
tion in Spoken Dialogue Systems Workshop, pages 241
? 246. Springer, September.
Marilyn Walker, Candace Kamm, and Diane Litman.
2000. Towards developing general models of usabil-
ity with paradise. Nat. Lang. Eng., 6(3-4):363?377.
Jason D. Williams and Steve J. Young. 2007. Par-
tially observable markov decision processes for spo-
ken dialog systems. Computer Speech and Language,
(21):393?422.
52
Proceedings of the SIGDIAL 2013 Conference, pages 122?126,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Improving Interaction Quality Recognition Using Error Correction
Stefan Ultes
Ulm University
Albert-Einstein-Allee 43
89081 Ulm, Germany
stefan.ultes@uni-ulm.de
Wolfgang Minker
Ulm University
Albert-Einstein-Allee 43
89081 Ulm, Germany
wolfgang.minker@uni-ulm.de
Abstract
Determining the quality of an ongoing in-
teraction in the field of Spoken Dialogue
Systems is a hard task. While existing
methods employing automatic estimation
already achieve reasonable results, still
there is a lot of room for improvement.
Hence, we aim at tackling the task by es-
timating the error of the applied statistical
classification algorithms in a two-stage ap-
proach. Correcting the hypotheses using
the estimated model error increases per-
formance by up to 4.1 % relative improve-
ment in Unweighted Average Recall.
1 Introduction
Evaluating the quality of Spoken Dialogue Sys-
tems (SDSs) has long since been a challenging
task. While objective metrics like task completion
and dialogue duration are not human-centered,
subjective measures compensate for this by mod-
eling the user?s subjective experience. This infor-
mation may be used to increase the dialogue sys-
tem?s performance (cf. (Ultes et al, 2012b)).
In human-machine dialogues, however, there is
no easy way of deriving the user?s satisfaction
level. Moreover, asking real users for answering
questions about the system performance requires
them to spend more time talking to the machine
than necessary. It can be assumed that a regular
user does not want to do this as human-machine
dialogues usually have no conversational charac-
ter but are task oriented. Hence, automatic ap-
proaches are the preferred choice.
Famous work on determining the satisfaction
level automatically is the PARADISE framework
by Walker et al (1997). Assuming a linear depen-
dency between objective measures and User Satis-
faction (US), a linear regression model is applied
to determine US on the dialogue level. This is not
only very costly, as dialogues must be performed
with real users, but also inadequate if quality on a
finer level is of interest, e.g., on the exchange level.
To overcome this issue, work by Schmitt et
al. (2011) introduced a new metric for measuring
the performance of an SDS on the exchange level
called Interaction Quality (IQ). They used statisti-
cal classification methods to automatically derive
the quality based on interaction parameters. Qual-
ity labels were applied by expert raters after the di-
alogue on the exchange level, i.e., for each system-
user-exchange. Automatically derived parameters
were then used as features for creating a statistical
classification model using static feature vectors.
Based on the same data, Ultes et al (2012a) put
an emphasis on the sequential character of the IQ
measure by applying temporal statistical classifi-
cation using Hidden Markov Models (HMMs) and
Continuous Hidden Markov Models (CHMMs).
However, statistical classifiers usually do not
achieve perfect performance, i.e., there will al-
ways be misclassification. While most work fo-
cuses on applying different statistical models and
improving them (Section 2), learning the error to
correct the result afterwards represents a different
approach. Therefore, we present our approach on
estimating the error of IQ recognition models to
correct their hypothesis in order to eventually yield
better recognition rates (Section 4). The definition
of IQ and data used for the evaluation of our ap-
proach (Section 5) is presented in Section 3. Our
approach is also compared to a simple hierarchical
approach also discussed in Section 5.
2 Related Work on Dialogue Quality
Besides Schmitt et al, other research groups have
performed numerous work on predicting subjec-
tive quality measures on an exchange level, all not
incorporating any form of error correction.
Engelbrecht et al (2009) presented an approach
using Hidden Markov Models (HMMs) to model
122
e n
?
e n-1
e n-2
e1
e n+1
?
exc
han
ge l
eve
l pa
ram
eter
s
win
dow
 lev
el p
aram
eter
s
dial
ogu
e le
vel 
para
met
ers
Figure 1: The three different modeling levels rep-
resenting the interaction at exchange en.
the SDS as a process evolving over time. Perfor-
mance ratings on a 5 point scale (?bad?, ?poor?,
?fair?, ?good?, ?excellent?) have been applied by
the users during the dialogue.
Higashinaka et al (2010) proposed a model for
predicting turn-wise ratings for human-human dia-
logues analyzed on a transcribed conversation and
human-machine dialogues with text from a chat
system. Ratings ranging from 1 to 7 were ap-
plied by two expert raters labeling for smoothness,
closeness, and willingness.
Hara et al (2010) derived turn level ratings from
overall ratings of the dialogue which were applied
by the users afterwards on a five point scale. Us-
ing n-grams to model the dialogue, results for dis-
tinguishing between six classes at any point in the
dialogue showed to be hardly above chance.
3 The LEGO Corpus
For estimating the Interaction Quality (IQ), the
LEGO corpus published by Schmitt et al (2012)
is used. IQ is defined similarly to user satisfac-
tion: While the latter represents the true disposi-
tion of the user, IQ is the disposition of the user as-
sumed by an expert rater. The LEGO corpus con-
tains 200 calls (4,885 system-user-exchanges) to a
bus information system (cf. (Raux et al, 2006)).
Labels for IQ on a scale from 1 (extremely un-
satisfied) to 5 (satisfied) have been assigned by
three expert raters with an inter-rater agreement of
? = 0.54. In order to ensure consistent labeling,
the expert raters had to follow labeling guidelines
(cf. (Schmitt et al, 2012)).
Parameters used as input variables for the IQ
model have been derived from the dialogue sys-
tem modules automatically for each exchange on
three levels: the exchange level, the dialogue level,
and the window level (see Figure 1). As parame-
ters like the confidence of the speech recognizer
can directly be acquired from the dialogue mod-
ules, they constitute the exchange level. Based on
this, counts, sums, means, and frequencies of ex-
change level parameters from multiple exchanges
are computed to constitute the dialogue level (all
exchanges up to the current one) and the window
level (the three previous exchanges). A complete
list of parameters is listed in (Schmitt et al, 2012).
Schmitt et al (2011) performed IQ recognition
on this data using linear SVMs. They achieved an
Unweighted Average Recall (UAR) of 0.58 based
on 10-fold cross-validation. Ultes et al (2012a)
applied HMMs and CHMMs using 6-fold cross
validation and a reduced feature set achieving an
UAR of 0.44 for HMMs and 0.39 for CHMMs.
4 Error Estimation Model
Error correction may be incorporated into the sta-
tistical classification process by a two-stage ap-
proach, which is depicted in Figure 2.
At the first stage, a statistical classification
model is created using interaction parameters as
input and IQ as target variable. For this work,
a Support Vector Machine (SVM) and a Rule
Learner are applied. At the second stage, the er-
ror er of the hypothesis h0 is calculated by
er = h0 ? r , (1)
where the reference r denotes the true IQ value.
In order to limit the number of error classes, the
signum function is applied. It is defined as
sgn(x) :=
?
??
??
?1 if x < 0 ,
0 if x = 0 ,
1 if x > 0 .
(2)
Therefore, the error is redefined as
er = sgn(h0 ? r) . (3)
Next, a statistical model is created similarly to
stage one but targeting the error er. The difference
is that the input parameter set is extended by the IQ
hypothesis h0 of stage one. Here, two approaches
are applied: Creating one model which estimates
all error classes (?1,0,1) and creating two mod-
els where each estimates positive (0,1) or negative
error (?1,0). For the latter variant, the error of
the class which is not estimated by the respective
model is mapped to 0. By this, the final error hy-
pothesis he may be calculated by simple addition
of both estimated error values:
he = he?1 + he+1 . (4)
Combining the hypothesis of the error estima-
tion he with the hypothesis of the IQ estimation h0
123
12
IQ
model
Interaction
Parameters
Hypothesis
IQ h0
Reference
IQ r
? ReferenceError IQ er?
Parameters
+
Hypothesis
Error IQ
modelError IQmodel
Hypothesis
Error IQ he
? FinalHypothesis IQ
hf
input
target
input
target
Figure 2: The complete IQ estimation process including error correction. After estimating IQ in Stage 1
(upper frame), the error is estimated and the initial hypothesis is corrected in Stage 2 (lower frame).
at stage one produces the final hypothesis hf de-
noting the Interaction Quality estimation corrected
by the estimated error of the statistical model:
hf = h0 ? he . (5)
As the error estimation will not work perfectly,
it might recognize an error where there is none or
? even worse ? it might recognize an error contrary
to the real error, e.g., ?1 instead of +1. Therefore,
the corrected hypothesis might be out of range. To
keep hf within the defined bounds of IQ, a lim-
iting functions is added to the computation of the
final hypothesis resulting in
hf = max(min(h0 ? he), bu), bl) , (6)
where bu denotes the upper bound of the IQ labels
and bl the lower bound.
5 Experiments and Results
All experiments are conducted using the LEGO
corpus presented in Section 3. By applying 5-fold
cross validation, hypotheses for each system-user-
exchange which is contained in the LEGO corpus
are estimated. Please note that some textual inter-
action parameters are discarded due to their task-
dependent nature leaving 45 parameters1.
For evaluation, we rely on two measures: The
unweighted average recall (UAR) and the root
1Removed parameters: Activity, LoopName, Prompt,
RoleName, SemanticParse, SystemDialogueAct, UserDia-
logueAct, Utterance
mean squared error (RMSE). UAR represents the
accuracy corrected by the effects of unbalanced
data and is also used by cited literature. RMSE is
used since the error correction method is limited
to correcting the results only by one. For bigger
errors, the true value cannot be reached.
The performances of two different statistical
classification methods are compared, both applied
for stage one and stage two: Support Vector Ma-
chine (SVM) (Vapnik, 1995) using a linear ker-
nel, which is also used by Schmitt et al (2011),
and Rule Induction (RI) based on Cohen (1995).
Furthermore, a normalization component is added
performing a range normalization of the input pa-
rameters in both stages. This is necessary for using
the implementation of the statistical classification
algorithms at hand.
For error estimation, two variants are explored:
using one combined model for all three error
classes (?1,0,+1) and using two separate models,
one for distinguishing between ?1 and 0 and one
for distinguishing between +1 and 0 with com-
bining their results afterwards. While using RI for
error estimation yields reasonable performance re-
sults for the combined model, it is not suitable for
error estimation using two separate models as all
input vectors are mapped to 0. Hence, for the two
model approach, only the SVM is applied .
Results for applying error correction (EC) are
presented in Table 1. Having an SVM at stage one
(column SVM), recognition performance is rela-
tively improved by up to 4.6 % using EC. With RI
124
Table 1: Results for IQ recognition: UAR and
RMSE for IQ recognition without stage two, with
error correction at stage two, and with a simple hi-
erarchical approach.
UAR RMSE
stage two SVM RI SVM RI
none 51.1% 60.3% 0.97 0.88
error correction
SVM 50.7% 59.6% 0.97 0.83
RI 52.5% 58.1% 0.88 0.85
2xSVM 53.2% 60.6% 0.88 0.85
simple hierarchical approach
SVM 50.2% 57.6% 0.97 0.85
RI 58.9% 58.7% 0.88 0.88
at stage one, performance is only increased by up
to 0.5 % which has shown to be not significant us-
ing the Wilcoxon test. The relative improvements
in UAR are depicted in Figure 3.
Furthermore, these results are compared to a
simple hierarchical approach (SH) where the hy-
pothesis h0 of the stage one classifier is used as
an additional feature for the stage two classifier
targeting IQ directly. Here, the performance of
the stage two classifier is of most interest since
this approach can be viewed as one stage classi-
fication with an additional feature. The results in
Table 1 show that RI does not benefit from addi-
tional information (comparison of last row with
one stage RI recognition). SVM recognition at
stage two, though, shows better results. While its
performance is reduced using the SVM hypothe-
sis as additional feature, adding the RI hypothesis
improved UAR up to 12.6 % relatively. However,
there is no reasonable scenario where one would
not use the better performing RI in favor of using
its results as additional input for SVM recognition.
The question remains why SVM benefits from
Error Correction as well as from adding additional
input parameters while RI does not. It remains un-
clear if this is an effect of the task characteristics
combined with the characteristics of the classifi-
cation method. It may as well be caused by low
classification performance. A classifier with low
performance might be more likely to improve its
performance by additional information or EC.
6 Conclusion
In this work, we presented an approach for im-
proving the recognition of Interaction Quality by
estimating the error of the classifier in order to cor-
rect the hypothesis. For the resulting two-staged
?0.8% ?1.3%
2.7%
?3.7%
4.1%
0.5%
?4%
?3%
?2%
?1%
0%
1%
2%
3%
4%
SVM RI
error?correction?(SVM)error?correction?(RI)error?correction?(2?x?SVM)
Figure 3: The relative improvement of EC in UAR
grouped by stage one classifiers SVM and RI.
approach, two different statistical classification al-
gorithm were applied for both stages, i.e., SVM
and Rule Learner. Performance could be improved
for both stage one classifiers using separate er-
ror models relatively improving IQ recognition by
up to 4.1 %. The proposed error correction ap-
proach has been compared to a simple hierarchi-
cal approach where the hypohtesis of stage one
is used as additional feature of stage two classi-
fication. This apprach relatively improved SVM
recognition by up to 12.6 % using a Rule Learner
hypothesis as additional feature. However, as one-
stage Rule Learner classification already provides
better results than this hierarchical approach, is
does not seem reasonable to employ this config-
uration. Nonethelesse, why only the SVM could
benefit from additional information (error correc-
tion or simple hierarchical appraach) remains un-
clear and should be investigated in future work.
Moreover, some aspects of the error correc-
tion approach have to be discussed controversially,
e.g., applying the signum function for calculating
the error. While the obvious advantage is to limit
the number of error classes a statistical classifica-
tion algorithm has to estimate, it also prohibits of
being able to correct all errors. If the absolute er-
ror is bigger than one it can never be corrected.
Acknowledgments
This work was supported by the Transregional
Collaborative Research Centre SFB/TRR 62
?Companion-Technology for Cognitive Technical
Systems? which is funded by the German Re-
search Foundation (DFG).
125
References
William W. Cohen. 1995. Fast effective rule induc-
tion. In Proceedings of the 12th International Con-
ference on Machine Learning, pages 115?123. Mor-
gan Kaufmann, July.
Klaus-Peter Engelbrecht, Florian Go?dde, Felix Har-
tard, Hamed Ketabdar, and Sebastian Mo?ller. 2009.
Modeling user satisfaction with hidden markov
model. In SIGDIAL ?09: Proceedings of the SIG-
DIAL 2009 Conference, pages 170?177, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Sunao Hara, Norihide Kitaoka, and Kazuya Takeda.
2010. Estimation method of user satisfaction us-
ing n-gram-based dialog history model for spoken
dialog system. In Nicoletta Calzolari (Conference
Chair), Khalid Choukri, Bente Maegaard, Joseph
Mariani, Jan Odijk, Stelios Piperidis, Mike Ros-
ner, and Daniel Tapias, editors, Proceedings of the
Seventh conference on International Language Re-
sources and Evaluation (LREC?10), Valletta, Malta,
May. European Language Resources Association
(ELRA).
Ryuichiro Higashinaka, Yasuhiro Minami, Kohji
Dohsaka, and Toyomi Meguro. 2010. Issues in pre-
dicting user satisfaction transitions in dialogues: In-
dividual differences, evaluation criteria, and predic-
tion models. In Gary Lee, Joseph Mariani, Wolf-
gang Minker, and Satoshi Nakamura, editors, Spo-
ken Dialogue Systems for Ambient Environments,
volume 6392 of Lecture Notes in Computer Sci-
ence, pages 48?60. Springer Berlin / Heidelberg.
10.1007/978-3-642-16202-2 5.
Antoine Raux, Dan Bohus, Brian Langner, Alan W.
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: One year
of lets go! experience. In Proc. of the Interna-
tional Conference on Speech and Language Process-
ing (ICSLP), September.
Alexander Schmitt, Benjamin Schatz, and Wolfgang
Minker. 2011. Modeling and predicting quality in
spoken human-computer interaction. In Proceed-
ings of the SIGDIAL 2011 Conference, Portland,
Oregon, USA, June. Association for Computational
Linguistics.
Alexander Schmitt, Stefan Ultes, and Wolfgang
Minker. 2012. A parameterized and annotated cor-
pus of the cmu let?s go bus information system. In
International Conference on Language Resources
and Evaluation (LREC).
Stefan Ultes, Robert ElChabb, and Wolfgang Minker.
2012a. Application and evaluation of a conditioned
hidden markov model for estimating interaction
quality of spoken dialogue systems. In Joseph Mari-
ani, Laurence Devillers, Martine Garnier-Rizet, and
Sophie Rosset, editors, Proceedings of the 4th In-
ternational Workshop on Spoken Language Dialog
System (IWSDS), pages 141?150. Springer, Novem-
ber.
Stefan Ultes, Alexander Schmitt, and Wolfgang
Minker. 2012b. Towards quality-adaptive spoken
dialogue management. In NAACL-HLT Workshop
on Future directions and needs in the Spoken Di-
alog Community: Tools and Data (SDCTD 2012),
pages 49?52, Montre?al, Canada, June. Association
for Computational Linguistics.
Vladimir N. Vapnik. 1995. The nature of statistical
learning theory. Springer-Verlag New York, Inc.,
New York, NY, USA.
Marilyn Walker, Diane Litman, Candace A. Kamm,
and Alicia Abella. 1997. Paradise: a framework
for evaluating spoken dialogue agents. In Proceed-
ings of the eighth conference on European chap-
ter of the Association for Computational Linguistics,
pages 271?280, Morristown, NJ, USA. Association
for Computational Linguistics.
126
Proceedings of the SIGDIAL 2013 Conference, pages 344?348,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
A Semi-supervised Approach for Natural Language Call Routing 
 
 
Tatiana Gasanova 
Institute of Communications Engineer-
ing, Ulm University, Germany 
tatiana.gasanova@uni-
ulm.de 
Eugene Zhukov 
Institute of Computer Science and 
Telecommunications, Siberian State 
Aerospace University, Russia 
zhukov.krsk@gmail.com 
Roman Sergienko 
Institute of Computer Science and 
Telecommunications, Siberian State 
Aerospace University, Russia 
romaserg@list.ru 
Eugene Semenkin 
Institute of Computer Science and 
Telecommunications, Siberian State 
Aerospace University, Russia 
eugenesemenkin@yandex.com 
Wolfgang Minker 
Institute of Communications Engineer-
ing, Ulm University, Germany 
wolfgang.minker@uni-ulm.de 
 
 
  
 
Abstract 
Natural Language call routing remains a com-
plex and challenging research area in machine 
intelligence and language understanding. This 
paper is in the area of classifying user utter-
ances into different categories. The focus is on 
design of algorithm that combines supervised 
and unsupervised learning models in order to 
improve classification quality. We have shown 
that the proposed approach is able to outper-
form existing methods on a large dataset and 
do not require morphological and stop-word 
filtering. In this paper we present a new for-
mula for term relevance estimation, which is a 
modification of fuzzy rules relevance estima-
tion for fuzzy classifier. Using this formula 
and only 300 frequent words for each class, we 
achieve an accuracy rate of 85.55% on the da-
tabase excluding the ?garbage? class (it in-
cludes utterances that cannot be assigned to 
any useful class or that can be assigned to 
more than one class). Dividing the ?garbage? 
class into the set of subclasses by agglomera-
tive hierarchical clustering we achieve about 
9% improvement of accuracy rate on the 
whole database. 
1 Introduction 
Natural language call routing can be treated as an 
instance of topic categorization of documents 
(where the collection of labeled documents is 
used for training and the problem is to classify 
the remaining set of unlabeled test documents) 
but it also has some differences. For instance, in 
document classification there are much more 
terms in one object than in single utterance from 
call routing task, where even one-word utteranc-
es are common. 
A number of works have recently been published 
on natural language call classification. B. Car-
penter, J. Chu-Carroll, C.-H. Lee and H.-K. Kuo 
proposed approaches using a vector-based in-
formation retrieval technique, the algorithms de-
signed by A. L. Gorin, G. Riccardi, and J. H. 
Wright use a probabilistic model with salient 
phrases. R. E. Schapire and Y. Singer focused on 
a boosting-based system for text categorization.  
The most similar work has been done by A. 
Albalate, D. Suendermann, R. Pieraccini, A. 
Suchindranath, S. Rhinow, J. Liscombe, K. 
Dayanidhi, and W. Minker. They have worked 
on the data with the same structure: the focus 
was on the problem of big part of non-labeled 
data and only few labeled utterances for each 
class, methods of matching the obtained clusters 
and the given classes have also been considered; 
they provided the comparison of several classifi-
cation methods that are able to perform on the 
large scale data.  
The information retrieval approach for call rout-
ing is based on the training of the routing matrix, 
which is formed by statistics of appearances of 
344
words and phrases in a training set (usually after 
morphological and stop-word filtering). The new 
caller request is represented as a feature vector 
and is routed to the most similar destination vec-
tor. The most commonly used similarity criterion 
is the cosine similarity. The performance of sys-
tems, based on this approach, often depends on 
the quality of the destination vectors.  
In this paper we propose a new term relevance 
estimation approach based on fuzzy rules rele-
vance for fuzzy classifier (H. Ishibuchi, T. 
Nakashima, and T. Murata., 1999) to improve 
routing accuracy. We have also used a decision 
rule different from the cosine similarity. We as-
sign relevancies to every destination (class), cal-
culate the sums of relevancies of words from the 
current utterance and choose the destination with 
the highest sum.  
The database for training and performance eval-
uation consists of about 300.000 user utterances 
recorded from caller interactions with commer-
cial automated agents. The utterances were man-
ually transcribed and classified into 20 classes 
(call reasons), such as appointments, operator, 
bill, internet, phone or video. Calls that cannot be 
routed certainly to one reason of the list are clas-
sified to class _TE_NOMATCH.  
A significant part of the database (about 27%) 
consists of utterances from the ?garbage? class 
(_TE_NOMATCH). Our proposed approach de-
composes the routing task into two steps. On the 
first step we divide the ?garbage? class into the 
set of subclasses by one of the clustering algo-
rithms and on the second step we define the call 
reason considering the ?garbage? subclasses as 
separate classes. We apply genetic algorithms 
with the whole numbers alphabet, vector quanti-
zation network and hierarchical agglomerative 
clustering in order to divide ?garbage? class into 
subclasses. The reason to perform such a cluster-
ing is due to simplify the detection of the class 
with non-uniform structure.  
Our approach uses the concept of salient phrases: 
for each call reason (class) only 300 words with 
the highest term relevancies are chosen. It allows 
us to eliminate the need for the stop and ignore 
word filtering. The algorithms are implemented 
in C++. 
As a baseline for results comparison we have 
tested some popular classifiers from RapidMiner, 
which we have applied to the whole database and 
the database with decomposition.  
This paper is organized as follows: In Section II, 
we describe the problem and how we perform the 
preprocessing. Section III describes in detail the 
way of the term relevance calculating and the 
possible rules of choosing the call class. In Sec-
tion IV we present the clustering algorithms 
which we apply to simplify the ?garbage? class 
detection. Section V reports on the experimental 
results. Finally, we provide concluding remarks 
in Section VI. 
2 Problem Description and Data Pre-
processing 
The data for testing and evaluation consists of 
about 300.000 user utterances recorded from 
caller interactions with commercial automated 
agents. Utterances from this database are manu-
ally labeled by experts and divided into 20 clas-
ses (_TE_NOMATCH, appointments, operator, 
bill, internet, phone etc). Class _TE_NOMATCH 
includes utterances that cannot be put into anoth-
er class or can be put into more than one class. 
The database is also unbalanced, some classes 
include much more utterances than others (the 
largest class _TE_NOMATCH includes 6790 ut-
terances and the smallest one consists of only 48 
utterances).  
The initial database has been preprocessed to be 
a binary matrix with rows representing utterances 
and columns representing the words from the 
vocabulary. An element from this binary matrix, 
aij, equals to 1 if in utterance i the word j appears 
and equals to 0 if it does not appear.  
Utterance duplicates were removed. The prepro-
cessed database consisting of 24458 utterances 
was divided into train (22020 utterances, 
90,032%) and test set (2438 utterances, 9,968%) 
such that the percentage of classes remained the 
same in both sets. The size of the dictionary of 
the whole database is 3464 words, 3294 words 
appear in training set, 1124 words appear in test 
set, 170 words which appear only in test set and 
do not appear in training set (unknown words), 
33 utterances consisted of only unknown words, 
and 160 utterances included at least one un-
known word. 
3 Term Relevance Estimation  
For each term we assign a real number term rele-
vance that depends on the frequency in utteranc-
es. Term relevance is calculated using a modified 
formula of fuzzy rules relevance estimation for 
fuzzy classifier. Membership function has been 
replaced by word frequency in the current class. 
The details of the procedure are:  
Let L be the number of classes; ni is the number 
of utterances of the ith class; Nij is the number of 
345
jth word occurrence in all utterances of the ith 
class; Tji=Nji/ni is the relative frequency of jth 
word occurrence in the ith class. 
Rj=maxi Tji, Sj=arg(maxi Tji) is the number of 
class which we assign to jth word; 
The term relevance, Cj, is given by 
 
 
 
 
Cj is higher if the word occurs often in few clas-
ses than if it appears in many classes.  
The learning phase consists of counting the C 
values for each term, it means that this algorithm 
uses the statistical information obtained from 
train set. We have tested several different 
decision rules defined in Table 1. 
 
 Decision rules 
RC 
 
For each class i we 
calculate Ai 
 
Then we find the num-
ber of class which 
achieves maximum of 
Ai 
 
RC max 
 
C 
 
C with 
limit 
 
R 
 
Table 1. Decision Rules  
 
The best obtained accuracies is achieved with the 
decision rule C, where the destination is chosen 
that has the highest sum of word relevancies 
from the current utterance. In Table 2 we show 
the obtained results on the whole database and 
database without ?garbage? class. 
 
 Train Test 
With class ?garbage? 0,614 0,551 
Without class ?garbage? 0,887 0,855 
Table 2. Performance of the new TRE approach 
4 Clustering methods 
After the analysis of the performances of stand-
ard classification algorithms on the given data-
base, we can conclude that there exists one spe-
cific class (class _TE_NOMATCH) where all 
standard techniques perform worse. Due to the 
non-uniform structure of the ?garbage? class it is 
difficult to detect the whole class by the pro-
posed procedure. If we apply this procedure di-
rectly we achieve only 55% of accuracy rate on 
the test data (61% on the train data). We suggest 
to divide the ?garbage? class into the set of sub-
classes using one of the clustering methods and 
then recount the values of Cj taking into account 
that there are 19 well defined classes and that the 
set of the ?garbage? subclasses can be consider 
as separate classes.  
In this paper the following clustering methods 
are used: a genetic algorithm with integers, vec-
tor quantization networks trained by a genetic 
algorithm, hierarchical agglomerative clustering 
with different metrics.  
4.1 Genetic Algorithm 
The train set accuracy is used as a fitness func-
tion. Each individual is the sequence of nonnega-
tive integer numbers (each number corresponds 
to the number of ?garbage? subclass). The length 
of this sequence is the number of utterances from 
train set which belong to the ?garbage? class. 
We apply this genetic algorithm to find directly 
the optimal clustering using different numbers of 
clusters and we can conclude that with increasing 
the clusters number (in the ?garbage? class) we 
get better classification accuracy on the whole 
database. We have used the following parameters 
of GA: population size = 50, number of genera-
tion = 50, weak mutation, tournament selection, 
uniform crossover, averaged by 50 runs. Apply-
ing this method we achieve about 7% improve-
ment of accuracy rate on train data and about 5% 
on test data.  
4.2 Vector Quantization Network 
We have also implemented vector quantization 
network. For a given number of subclasses we 
search for the set of code vectors (the number of 
code vectors is equal to the number of sub-
classes). These code vectors are optimized using 
genetic algorithm where as a fitness function we 
use the classification quality on the train set. 
Each code vector corresponds to a certain ?gar-
bage? subclass. The object belongs to the sub-
class if the distance between it and the corre-
sponding code vector is smaller than the distanc-
es between the object and all other code vectors. 
Applying this algorithm to the given database we 
obtain results similar to the results of the genetic 
algorithm.  
4.3 Hierarchical Agglomerative Clustering 
In this work we consider hierarchical agglomera-
tive binary clustering where we set each utter-
ance to one subclass and then we consequently 
group classes into pairs until there is only one 
).
1
1
(
1
1
1
?
? ?=
=
?
?=
L
Si
i
jijL
i
ji
j
j
T
L
R
T
C
?
=
=
iSj
jji
j
CRA
:
)maxarg(
i
iAwinner =
?
=
=
iSj
jji
j
CRA
:
max
?
=
=
iSj
ji
j
CA
:
?
>
=
=
constC
iSj
ji
j
j
CA
:
?
=
=
iSj
ji
j
RA
:
346
class containing all utterances or until we 
achieve a certain number of classes. The perfor-
mance of hierarchical clustering algorithms de-
pends on the metric (the way to calculate the dis-
tance between objects) and the criterion for clus-
ters union. In this work we use Hamming metric 
and Ward criterion (J. Ward. 1963).  
5 Experimental results 
The approach described above has been applied 
on the preprocessed corpus which has been pro-
vided by Speech Cycle company. We propose 
that only terms with highest value of RC (prod-
uct of R and C) are contributed to the total sum. 
We have investigated the dependence of the new 
TRE approach on the frequent words number 
(Figure 1). The best accuracy rate was obtained 
with more than 300 frequent words. By using 
only limited set of words we eliminated the need 
of stop and ignore words filtering. This also 
shows that the method works better if utterance 
includes terms with high C values. This approach 
requires informative well-defined classes and 
enough data for statistical model. 
 
Figure 1. New TRE approach with different numbers 
of frequent words (x-axis: number of frequent words; 
y-axis: accuracy) 
 
Figure 2. Overall accuracy 
Figure 3. Comparison of decision rules (x-axis: deci-
sion rule; y-axis: accuracy) 
 
We have tested standard classification algorithms 
(k-nearest neighbors algorithms, Bayes classifi-
ers, Decision Stump, Rule Induction, perceptron) 
and the proposed approach on the database with 
?garbage? class and on the database without it 
(Figure 2). The proposed algorithm outperforms 
all other methods with has an accuracy rate of 
85.55%. Figure 3 provides accuracies of different 
decision rules. Applying the proposed formula to 
the whole database we obtain 61% and 55% of 
classification quality on train and test data. We 
should also mention that the common tf.idf ap-
proach gives us on the given data 45% and 38% 
of accuracy rate on the train and test data. The 
proposed approach performs significantly better 
on this kind of data.  
Using the agglomerative hierarchical clustering 
we achieve about 9% improvement. The best 
classification quality is obtained with 35 sub-
classes on the train data (68.7%) and 45 sub-
classes on the test data (63.9%). Clustering into 
35 subclasses gives 63.7% of accuracy rate on 
the test data. 
6 Conclusion 
This paper reported on call classification experi-
ments on large corpora using a new term rele-
vance estimation approach. We propose to split 
the classification task into two steps: 1) cluster-
ing of the ?garbage? class in order to simplify its 
detection; 2) further classification into meaning-
ful classes and the set of ?garbage? subclasses. 
The performance of the proposed algorithm is 
compared to several standard classification algo-
rithms on the database without the ?garbage? 
class and found to outperform them with the ac-
curacy rate of 85.55%.  
Dividing the ?garbage? class into the set of sub-
classes by genetic algorithm and vector quantiza-
tion network we obtain about 5% improvement 
of accuracy rate and by agglomerative hierar-
chical clustering we achieve about 9% improve-
ment of accuracy rate on the whole database.  
0,6 
0,65 
0,7 
0,75 
0,8 
0,85 
0,9 
0 20 50 100 150 200 300 
Train set accuracy Test set accuracy 
0 
0,2 
0,4 
0,6 
0,8 
RC RC max C C with 
limit 
R 
Train Set Accuracy Test Set Accuracy 
347
References  
A. Albalate, D. Suendermann, R. Pieraccini, and W. 
Minker. 2009. Mathematical Analysis of Evolution, 
Information, and Complexity, Wiley, Hoboken, 
USA. 
A. Albalate, D. Suendermann D., and W. Minker. 
2011. International Journal on Artificial Intelli-
gence Tools, 20(5). 
A. Albalate, A. Suchindranath, D. Suendermann, and 
W. Minker. 2010. Proc. of the Interspeech 2010, 
11th Annual Conference of the International 
Speech Communication Association, Makuhari, Ja-
pan. 
A. Albalate, S. Rhinow, and D. Suendermann. 2010. 
Proc. of the ICAART 2010, 2nd International Con-
ference on Agents and Artificial Intelligence, Va-
lencia, Spain. 
A.L. Gorin, G. Riccardi, and J. H. Wright. 1997. 
Speech Commun., vol. 23, pp. 113?127. 
B. Carpenter and J. Chu-Carroll. 1998. Proc. ICSLP-
98, pp. 2059?2062. 
C.-H. Lee, B. Carpenter, W. Chou, J. Chu-Carroll, W. 
Reichl, A. Saad, and Q. Zhou. 2000. Speech 
Commun., vol. 31, no. 4, pp. 309?320. 
D. Suendermann, J. Liscombe, K. Dayanidhi, and R. 
Pieraccini. 2009. Proc. of the SIGDIAL 2009, Lon-
don, UK.  
H. Ishibuchi, T. Nakashima, and T. Murata. 1999. 
Trans. on Systems, Man, and Cybernetics, vol. 29, 
pp. 601-618. 
H.-K. Kuo and C.-H. Lee. 2000. Proc. of ICSLP?00. 
J. Chu-Carroll and B. Carpenter. 1999. Comput. Lin-
guist., vol. 25, no. 3, pp. 361- 388. 
J. Ward. 1963. Journal of the American Statistical 
Association, 58 (301): 236-244. 
J. H. Wright, A. L. Gorin, and G. Riccardi. 1997. 
Proc. Eurospeech-97, pp. 1419?1422. 
K. Evanini, D. Suendermann, and R. Pieraccini. 2007. 
Proc. of the ASRU 2007, Kyoto, Japan. 
R. E. Schapire and Y. Singer. 2000. Mach. Learn., 
vol. 39, no. 2/3, pp. 135?168. 
348
Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 84?89,
Baltimore, Maryland, USA. June 27, 2014. c?2014 Association for Computational Linguistics
Opinion Mining and Topic Categorization with Novel Term Weighting 
 
 
Tatiana Gasanova 
Institute of Communications Engineer-
ing, Ulm University, Germany 
tatiana.gasanova@uni-
ulm.de 
Roman Sergienko 
Institute of Communications Engineer-
ing, Ulm University, Germany 
roman.sergienko@uni-ulm.de 
Shakhnaz Akhmedova 
Institute of Computer Science and 
Telecommunications, Siberian State 
Aerospace University, Russia 
shahnaz@inbox.ru  
Eugene Semenkin 
Institute of Computer Science and 
Telecommunications, Siberian State 
Aerospace University, Russia 
eugenesemenkin@yandex.com 
Wolfgang Minker 
Institute of Communications Engineer-
ing, Ulm University, Germany 
wolfgang.minker@uni-ulm.de 
 
  
 
 
 
Abstract 
In this paper we investigate the efficiency of 
the novel term weighting algorithm for opin-
ion mining and topic categorization of arti-
cles from newspapers and Internet. We com-
pare the novel term weighting technique with 
existing approaches such as TF-IDF and 
ConfWeight. The performance on the data 
from the text-mining campaigns DEFT?07 
and DEFT?08 shows that the proposed meth-
od can compete with existing information re-
trieval models in classification quality and 
that it is computationally faster. The pro-
posed text preprocessing method can be ap-
plied in large-scale information retrieval and 
data mining problems and it can be easily 
transported to different domains and different 
languages since it does not require any do-
main-related or linguistic information. 
1 Introduction 
Nowadays, Internet and social media generate a 
huge amount of textual information. It is in-
creasingly important to develop methods of text 
processing such as text classification. Text clas-
sification is very important for such problems 
as automatic opining mining (sentiment analy-
sis) and topic categorization of different articles 
from newspapers and Internet. 
Text classification can be considered to be a 
part of natural language understanding, where 
there is a set of predefined categories and the 
task is to automatically assign new documents 
to one of these categories. The method of text 
preprocessing and text representation influences 
the results that are obtained even with the same 
classification algorithms.  
The most popular model for text classifica-
tion is vector space model. In this case text cat-
egorization may be considered as a machine 
learning problem. Complexity of text categori-
zation with vector space model is compounded 
by the need to extract the numerical data from 
text information before applying machine learn-
ing methods. Therefore text categorization con-
sists of two parts: text preprocessing and classi-
fication using obtained numerical data. 
All text preprocessing methods are based on 
the idea that the category of the document de-
pends on the words or phrases from this docu-
ment. The simplest approach is to take each 
word of the document as a binary coordinate 
and the dimension of the feature space will be 
the number of words in our dictionary.  
There exist more advanced approaches for 
text preprocessing to overcome this problem 
such as TF-IDF (Salton and Buckley, 1988) and 
ConfWeight methods (Soucy and Mineau, 
2005). A novel term weighting method (Gasa-
nova et al., 2013) is also considered, which has 
84
some similarities with the ConfWeight method, 
but has improved computational efficiency. It is 
important to notice that we use no morphologi-
cal or stop-word filtering before text prepro-
cessing. It means that the text preprocessing can 
be performed without expert or linguistic 
knowledge and that the text preprocessing is 
language-independent. 
In this paper we have used k-nearest neigh-
bors algorithm, Bayes Classifier, support vector 
machine (SVM) generated and optimized with 
COBRA (Co-Operation of Biology Related Al-
gorithms) which has been proposed by 
Akhmedova and Semenkin (2013), Rocchio 
Classifier or Nearest Centroid Algorithm (Roc-
chio, 1971) and Neural Network as classifica-
tion methods. RapidMiner and Microsoft Visual 
Studio C++ 2010 have been used as implemen-
tation software. 
For the application of algorithms and com-
parison of the results we have used the DEFT 
(?D?fi Fouille de Texte?) Evaluation Package 
2008 (Proceedings of the 4th DEFT Workshop, 
2008) which has been provided by ELRA and 
publically available corpora from DEFT?07 
(Proceedings of the 3rd DEFT Workshop, 
2007).  
The main aim of this work is to evaluate the 
competitiveness of the novel term weighting 
(Gasanova et al., 2013) in comparison with the 
state-of-the-art techniques for opining mining 
and topic categorization. The criteria using in 
the evaluation are classification quality and 
computational efficiency. 
This paper is organized as follows: in Section 
2, we describe details of the corpora. Section 3 
presents text preprocessing methods. In Section 
4 we describe the classification algorithms 
which we have used to compare different text 
preprocessing techniques. Section 5 reports on 
the experimental results. Finally, we provide 
concluding remarks in Section 6. 
2 Corpora Description 
The focus of DEFT 2007 campaign is the sen-
timent analysis, also called opinion mining. We 
have used 3 publically available corpora: re-
views on books and movies (Books), reviews on 
video games (Games) and political debates 
about energy project (Debates). 
The topic of DEFT 2008 edition is related to 
the text classification by categories and genres. 
The data consists of two corpora (T1 and T2) 
containing articles of two genres: articles ex-
tracted from French daily newspaper Le Monde 
and encyclopedic articles from Wikipedia in 
French language. This paper reports on the re-
sults obtained using both tasks of the campaign 
and focuses on detecting the category. 
 
Corpus Size Classes 
Books Train size = 2074 
Test size = 1386 
Vocabulary = 52507 
0: negative,  
1: neutral,  
2: positive 
Games Train size = 2537 
Test size = 1694 
Vocabulary = 63144 
0: negative,  
1: neutral,  
2: positive 
Debates Train size = 17299 
Test size = 11533 
Vocabulary = 59615 
0: against,  
1: for 
Table 1. Corpora description (DEFT?07) 
 
Corpus Size Classes 
T1 Train size = 15223 
Test size = 10596 
Vocabulary = 202979 
0: Sport,  
1: Economy,  
2: Art, 
3: Television 
T2 Train size = 23550 
Test size = 15693 
Vocabulary = 262400 
0: France,  
1: International,  
2: Literature, 
3: Science, 
4: Society 
Table 2. Corpora description (DEFT?08) 
 
All databases are divided into a training 
(60% of the whole number of articles) and a test 
set (40%). To apply our algorithms we extract-
ed all words which appear in the training set 
regardless of the letter case and we also exclud-
ed dots, commas and other punctual signs. We 
have not used any additional filtering as exclud-
ing the stop or ignore words. 
3 Text Preprocessing Methods 
3.1 Binary preprocessing 
We take each word of the document as a binary 
coordinate and the size of the feature space will 
be the size of our vocabulary (?bag of words?). 
3.2 TF-IDF 
TF-IDF is a well-known approach for text pre-
processing based on multiplication of term fre-
quency tfij (ratio between the number of times 
the ith word occurs in the jth document and the 
document size) and inverse document frequen-
cy idfi. 
 ???? =
???
??
,  (1) 
   
85
where tij is the number of times the i
th word oc-
curs in the jth document. Tj is the document size 
(number of the words in the document). 
There are different ways to calculate the 
weight of each word. In this paper we run clas-
sification algorithms with the following vari-
ants. 
1) TF-IDF 1 
 ???? = ???
|?|
??
, (2) 
where |D| is the number of document in the 
training set and ?? is the number of documents 
that have the ith word. 
2) TF-IDF 2 
The formula is given by equation (2) except 
??  is calculated as the number of times i
th word 
appears in all documents from the training set. 
3) TF-IDF 3 
 ???? = ?
|?|
??
?
?
,? ? (0,1), (3) 
where ?? is calculated as in TF-IDF 1 and ? is 
the parameter (in this paper we have tested ? = 
0.1, 0.5, 0.9). 
4) TF-IDF 4 
The formula is given by equation (3) except 
??  is calculated as in TF-IDF 4. 
3.3 ConfWeight 
Maximum Strength (Maxstr) is an alternative 
method to find the word weights. This approach 
has been proposed by Soucy and Mineau 
(2005). It implicitly does feature selection since 
all frequent words have zero weights. The main 
idea of the method is that the feature f has a 
non-zero weight in class c only if the f frequen-
cy in documents of the c class is greater than 
the f frequency in all other classes. 
The ConfWeight method uses Maxstr as an 
analog of IDF: 
???????????? = ???????? + 1? ? ??????(?). 
Numerical experiments (Soucy and Mineau, 
2005) have shown that the ConfWeight method 
could be more effective than TF-IDF with SVM 
and k-NN as classification methods. The main 
drawback of the ConfWeight method is compu-
tational complexity. This method is more com-
putationally demanding than TF-IDF method 
because the ConfWeight method requires time-
consuming statistical calculations such as Stu-
dent distribution calculation and confidence 
interval definition for each word. 
3.4 Novel Term Weighting (TW) 
The main idea of the method (Gasanova et al., 
2013) is similar to ConfWeight but it is not so 
time-consuming. The idea is that every word 
that appears in the article has to contribute 
some value to the certain class and the class 
with the biggest value we define as a winner for 
this article. 
For each term we assign a real number term 
relevance that depends on the frequency in ut-
terances. Term weight is calculated using a 
modified formula of fuzzy rules relevance esti-
mation for fuzzy classifiers (Ishibuchi et al., 
1999). Membership function has been replaced 
by word frequency in the current class. The de-
tails of the procedure are the following: 
Let L be the number of classes; ni is the 
number of articles which belong to the ith class; 
Nij is the number of the j
th word occurrence in 
all articles from the ith class; Tij = Nij / ni is the 
relative frequency of the jth word occurrence in 
the ith class. 
?? = max? ??? , ?? = arg (max? ???) is the 
number of class which we assign to the jth word; 
The term relevance, Cj, is given by 
 
).
1
1
(
1
1
1
?
? ?=
=
?
?=
L
Si
i
ijjL
i
ji
j
j
T
L
R
T
C  
(4) 
Cj is higher if the word occurs more often in 
one class than if it appears in many classes. We 
use novel TW as an analog of IDF for text pre-
processing. 
The learning phase consists of counting the C 
values for each term; it means that this 
algorithm uses the statistical information 
obtained from the training set.  
4 Classification Methods 
We have considered 11 different text prepro-
cessing methods (4 modifications of TF-IDF, 
two of them with three different values of ? 
parameter, binary representation, ConfWeight 
and the novel TW method) and compared them 
using different classification algorithms. The 
methods have been implemented using 
RapidMiner (Shafait, 2010) and Microsoft Vis-
ual Studio C++ 2010 for Rocchio classifier and 
SVM. The classification methods are: 
- k-nearest neighbors algorithm with dis-
tance weighting (we have varied k from 1 to 
15); 
- kernel Bayes classifier with Laplace cor-
rection; 
- neural network with error back propaga-
tion (standard setting in RapidMiner); 
- Rocchio classifier with different metrics 
and ? parameter; 
86
- support vector machine (SVM) generated 
and optimized with Co-Operation of Biology 
Related Algorithms (COBRA). 
Rocchio classifier (Rocchio, 1971) is a well-
known classifier based on the search of the 
nearest centroid. For each category we calculate 
a weighted centroid: 
?? =
1
|??|
? ? ? ?
1
???,???????
???? ? ?????,? , 
where ?? is a set of documents which belong to 
the class c; ??,?????? are k documents which do not 
belong to the class c and which are close to the 
centroid 
1
|??|
? ?;???? ? is parameter corresponds 
to relative importance of negative precedents. 
The given document is put to the class with the 
nearest centroid. In this work we have applied 
Rocchio classifier with ? ? (0.1; 0.9) and with 
three different metrics: taxicab distance, 
Euclidean metric and cosine similarity. 
COBRA is a new meta-heuristic algorithm 
which has been proposed by Akhmedova and 
Semenkin (2013). It is based on cooperation of 
biology inspired algorithms such as Particle 
Swarm Optimization (Kennedy and Eberhart, 
1995), Wolf Pack Search Algorithm (Yang, 
2007), Firefly Algorithm (Yang, 2008), Cuckoo 
Search Algorithm (Yang and Deb, 2009) and 
Bat Algorithm (Yang, 2010). For generating 
SVM-machine the original COBRA is used: 
each individual in all populations represents a 
set of kernel function?s parameters .,, d??  
Then for each individual constrained modifica-
tion of COBRA is applied for finding vector w 
and shift factor b. And finally individual that 
showed the best classification rate is chosen as 
the designed classifier. 
5 Experimental Results 
The DEFT (?D?fi Fouille de Texte?) Evaluation 
Package 2008 and publically available corpora 
from DEFT?07 (Books, Games and Debates) 
have been used for algorithms application and 
results comparison. In order to evaluate ob-
tained results with the campaign participants we 
have to use the same measure of classification 
quality: precision, recall and F-score. 
Precision for each class i is calculated as the 
number of correctly classified articles for class i 
divided by the number of all articles which al-
gorithm assigned for this class. Recall is the 
number of correctly classified articles for class i 
divided by the number of articles that should 
have been in this class. Overall precision and 
recall are calculated as the arithmetic mean of 
the precisions and recalls for all classes (macro-
average). F-score is calculated as the harmonic 
mean of precision and recall. 
Tables 3-7 present the F-scores obtained on 
the test corpora. The best values for each prob-
lem are shown in bold. Results of the all classi-
fication algorithms are presented with the best 
parameters. We also present for each corpus 
only the best TF-IDF modification.  
 
Classification 
algorithm 
Binary  TF-
IDF 
Conf 
Weight 
Novel 
TW 
Bayes 0.489 0.506 0.238 0.437 
k-NN 0.488  0.517 0.559 0.488 
Rocchio 0.479  0.498 0.557 0.537 
SVM (CO-
BRA) 
0.558  0.580 0.588 0.619 
Neural network 0.475  0.505 0.570 0.493 
Table 3. Classification results for Books 
 
Classification 
algorithm 
Binary  TF-
IDF 
Conf 
Weight 
Novel 
TW 
Bayes 0.653  0.652 0.210 0.675 
k-NN 0.703  0.701 0.720 0.700 
Rocchio 0.659  0.678 0.717 0.712 
SVM (CO-
BRA) 
0.682  0.687 0.645 0.696 
Neural network 0.701  0.679 0.717 0.691 
Table 4. Classification results for Games 
 
Classification 
algorithm 
Binary  TF-
IDF 
Conf 
Weight 
Novel 
TW 
Bayes 0.555  0.645 0.363 0.616 
k-NN 0.645  0.648 0.695 0.695 
Rocchio 0.636  0.646 0.697 0.696 
SVM (CO-
BRA) 
0.673  0.669 0.714 0.700 
Neural network 0.656  0.647 0.705 0.697 
Table 5. Classification results for Debates 
 
Classification 
algorithm 
Binary  TF-
IDF 
Conf 
Weight 
Novel 
TW 
Bayes 0.501  0.690 0.837 0.794 
k-NN 0.800  0.816 0.855 0.837 
Rocchio 0.794  0.825 0.853 0.838 
SVM (CO-
BRA) 
0.788  0.827 0.840 0.856 
Neural network 0.783  0.830 0.853 0.854 
Table 6. Classification results for T1 
 
Classification 
algorithm 
Binary  TF-
IDF 
Conf 
Weight 
Novel 
TW 
Bayes 0.569  0.728 0.712 0.746 
k-NN 0.728  0.786 0.785 0.811 
Rocchio 0.765  0.825 0.803 0.834 
SVM (CO-
BRA) 
0.794  0.837 0.813 0.851 
Neural network 0.799  0.838 0.820 0.843 
Table 7. Classification results for T2 
 
87
We can see from the Tables 3-7 that the best 
F-scores have been obtained with either 
ConfWeight or novel Term Weighting prepro-
cessing. The algorithm performances on the 
Games and Debates corpora achieved the best 
results with ConfWeight; however, we can see 
that the F-scores obtained with novel Term 
Weighting preprocessing are very similar 
(0.712 and 0.720 for Games; 0.700 and 0.714 
for Debates). Almost all best results have been 
obtained with SVM except the Games database 
where we achieved the highest F-score with k-
NN algorithm. 
This paper focuses on the text preprocessing 
methods which do not require language or do-
main-related information; therefore, we have 
not tried to achieve the best possible classifica-
tion quality. However, the result obtained on 
Books corpus with novel TW preprocessing and 
SVM (generated using COBRA) as classifica-
tion algorithm has reached 0.619 F-score which 
is higher than the best known performance 
0.603 (Proceedings of the 3rd DEFT Workshop, 
2007). Performances on other corpora have 
achieved close F-score values to the best sub-
missions of the DEFT?07 and DEFT?08 partici-
pants. 
We have also measured computational effi-
ciency of each text preprocessing technique. 
We have run each method 20 times using the 
Baden-W?rttemberg Grid (bwGRiD) Cluster 
Ulm (Every blade comprehends two 4-Core 
Intel Harpertown CPUs with 2.83 GHz and 16 
GByte RAM). After that we calculated average 
values and checked statistical significance of 
the results. 
Figure 1 and Figure 2 compare average com-
putational time in minutes for different prepro-
cessing methods applied on DEFT?07 and 
DEFT?08 corpora. 
 
Figure 1. Computational efficiency of text pre-
processing methods (DEFT?07) 
 
Figure 2. Computational efficiency of text pre-
processing methods (DEFT?08) 
 
The average value for all TF-IDF modifica-
tions is presented because the time variation for 
the modifications is not significant. 
We can see in Figure 1 and Figure 2 that TF-
IDF and novel TW require almost the same 
computational time. The most time-consuming 
method is ConfWeight (CW). It requires ap-
proximately six times more time than TF-IDF 
and novel TW for DEFT?08 corpora and about 
three-four times more time than TF-IDF and 
novel TW for DEFT?07 databases. 
6 Conclusion 
This paper reported on text classification exper-
iments on 5 different corpora of opinion mining 
and topic categorization using several classifi-
cation methods with different text prepro-
cessing. We have used ?bag of words?, TF-IDF 
modifications, ConfWeight and the novel term 
weighting approach as preprocessing tech-
niques. K-nearest neighbors algorithms, Bayes 
classifier, Rocchio classifier, support vector 
machine trained by COBRA and Neural Net-
work have been applied as classification algo-
rithms.  
The novel term weighting method gives simi-
lar or better classification quality than the 
ConfWeight method but it requires the same 
amount of time as TF-IDF. Almost all best re-
sults have been obtained with SVM generated 
and optimized with Co-Operation of Biology 
Related Algorithms (COBRA). 
We can conclude that numerical experiments 
have shown computational and classification 
efficiency of the proposed method (the novel 
TW) in comparison with existing text prepro-
cessing techniques for opinion mining and topic 
categorization. 
88
References  
Akhmedova Sh. and Semenkin E. 2013. Co-
Operation of Biology Related Algorithms. Pro-
ceedings of the IEEE Congress on Evolutionary 
Computation (CEC 2013):2207-2214. 
Association Fran?aise d?Intelligence Artificielle. 
2007. Proceedings of the 3rd DEFT Workshop. 
DEFT '07. AFIA, Grenoble, France. 
Gasanova T., Sergienko R., Minker W., Semenkin 
E. and Zhukov E. 2013. A Semi-supervised Ap-
proach for Natural Language Call Routing. Pro-
ceedings of the SIGDIAL 2013 Conference:344-
348. 
Ishibuchi H., Nakashima T., and Murata T. 1999. 
Performance evaluation of fuzzy classifier sys-
tems for multidimensional pattern classification 
problems. IEEE Trans. on Systems, Man, and Cy-
bernetics, 29:601-618. 
Kennedy J. and Eberhart R. 1995. Particle Swarm 
Optimization. Proceedings of IEEE International 
Conference on Neural Networks:1942-1948.   
Le traitement automatique du langage naturel ou de 
la langue naturelle. 2008. Proceedings of the 4th 
DEFT Workshop. DEFT '08. TALN, Avignon, 
France. 
Salton G. and Buckley C. 1988. Term-Weighting 
Approaches in Automatic Text Retrieval.  Infor-
mation Processing and Management:513-523. 
Shafait F., Reif M., Kofler C., and Breuel T. M. 
2010. Pattern Recognition Engineering. 
RapidMiner Community Meeting and Conference, 
9. 
Soucy P. and Mineau G.W. 2005. Beyond TFIDF 
Weighting for Text Categorization in the Vector 
Space Model. Proceedings of the 19th Interna-
tional Joint Conference on Artificial Intelligence 
(IJCAI 2005):1130-1135. 
Rocchio J. 1971. Relevance Feedback in Infor-
mation Retrieval. The SMART Retrieval System-
Experiments in Automatic Document Processing, 
Prentice-Hall:313-323. 
Yang Ch. 2007. Algorithm of Marriage in Honey 
Bees Optimization Based on the Wolf Pack 
Search. Proceedings of International Conference 
on Intelligent Pervasive Computing:462-467. 
Yang X.S. 2008. Nature-Inspired Metaheuristic Al-
gorithms. 
Yang X.S. and Deb S. 2009. Cuckoo search via 
Levy flights. Proceedings of World Congress on 
Nature & Biologically Inspired Computing:210-
214. 
Yang X.S. 2010. A New Metaheuristic Bat-Inspired 
Algorithm. Proceedings of Nature Inspired Co-
operative Strategies for Optimization (NISCO 
2010):65-74. 
 
 
 
 
89
Proceedings of the SIGDIAL 2014 Conference, pages 51?59,
Philadelphia, U.S.A., 18-20 June 2014.
c?2014 Association for Computational Linguistics
Probabilistic Human-Computer Trust Handling
Florian Nothdurft
?
, Felix Richter
?
and Wolfgang Minker
?
?
Institute of Communications Engineering
?
Institute of Artificial Intelligence
Ulm University
Ulm, Germany
florian.nothdurft, felix.richter, wolfgang.minker@uni-ulm.de
Abstract
Human-computer trust has shown to be a
critical factor in influencing the complex-
ity and frequency of interaction in techni-
cal systems. Particularly incomprehensi-
ble situations in human-computer interac-
tion may lead to a reduced users trust in the
system and by that influence the style of
interaction. Analogous to human-human
interaction, explaining these situations can
help to remedy negative effects. In this pa-
per we present our approach of augment-
ing task-oriented dialogs with selected ex-
planation dialogs to foster the human-
computer trust relationship in those kinds
of situations. We have conducted a web-
based study testing the effects of different
goals of explanations on the components
of human-computer trust. Subsequently,
we show how these results can be used in
our probabilistic trust handling architec-
ture to augment pre-defined task-oriented
dialogs.
1 Introduction
Human-computer interaction (HCI) has evolved in
the past decades from classic stationary interaction
paradigms featuring only human and computer to-
wards intelligent agent-based paradigms featuring
multiple devices and sensors in intelligent envi-
ronments. For example, ubiquitous computing no
longer seems to be a vision of future HCI, but has
become reality, at least in research labs and pro-
totypical environments. Additionally, the tasks a
technical system has to solve cooperatively with
the user have become increasingly complex. How-
ever, this change from simple task solver to intel-
ligent assistant requires the acceptance of and the
trust in the technical system as dialogue partner
and not only as ordinary service device.
Especially trust has shown to be a crucial part in
the interaction between human and technical sys-
tem. If the user does not trust the system and its
actions, advices or instructions the way of interac-
tion may change up to complete abortion of future
interaction (Parasuraman and Riley, 1997). Espe-
cially those situations in which the user does not
understand the system or does not expect the way
how the system acts are critical to have a negative
impact on the human-computer trust (HCT) rela-
tionship (Muir, 1992). Those situations do occur
usually due to incongruent models of the system:
During interaction the user builds a mental model
of the system and its underlying processes deter-
mining system actions and output. However, if
this perceived mental model and the actual system
model do not match the HCT relationship may be
influenced negatively (Muir, 1992). This may, for
example, be due to a mismatch in the expected and
the actual system action and output.
For example, if a technical system would assist
the user in having his day scheduled in a time ef-
fective manner, the user would be in a vulnerable
situation of relying on the reasoning capabilities of
the system. However, when the user-expected time
schedule does not match the system-generated, the
question arises if the user will trust the system, de-
spite lacking the knowledge if the schedule is cor-
rect. If the user trusts the automated day schedul-
ing capability of the system, he will probably at-
tend the appointments exactly as scheduled. How-
ever, if he does not trust this automated outcome
he won?t rely on it and will question the plan.
Therefore, the goal should be to detect those
critical situations in HCI and to react appropri-
ately. If we take a look at how humans detect
and handle critical situations, we can conclude that
they use contextual information combined with in-
terpreted multimodal body analysis (e.g., facial
expression, body posture, speech prosody) for de-
tection and usually some sort of explanation to
51
Goals Details
Transparency How was the systems answer reached?
Justification Explain the motives of the answer?
Relevance Why is the answer a relevant answer?
Conceptualization Clarify the meaning of concepts
Learning Learn something about the domain
Table 1: Goals of explanation after (S?rmo and
Cassens, 2004). These goals subsume different
kinds of explanation as e.g., why, why-not, what-
if, how-to explanations
clarify the process of reasoning (i.e. increasing
transparency and understandability). As even hu-
mans are sometimes insecure about judging the di-
alog partner and to decide whether and which type
of reaction would be appropriate, it seems valid
that a technical system will not overcome this is-
sue of uncertainty. Therefore, we assume that the
transfer of this problem to a technical system can
only be handled effectively by incorporating un-
certainty and thus using a probabilistic model. In
the remainder of this paper, we will first elaborate
how to react to not understandable situations and
secondly present how to incorporate these findings
into a multimodal dialogue system using a proba-
bilistic model.
2 Coping with Incomprehensible
Situations
Analogous to human-human interaction provid-
ing explanations in not understandable situations
in HCI can reduce the loss of trust (Glass et al.,
2008). However, HCT is not a one-dimensional
simple concept. It may be devided into several
components, which all have to be well-functioning
to have the user trust a technical system. Exis-
tent studies concentrated on showing that explana-
tions or different kinds of explanations can influ-
ence HCT in general (Lim et al., 2009). So, what
is lacking currently is which explanations do influ-
ence which bases of human-computer trust.
2.1 Explanations
In general, explanations are given to clarify,
change or impart knowledge. Usually the implicit
idea consists of aligning the mental models of the
participating parties. The mental model is the per-
ceived representation of the real world, or in our
case of the technical system and its underlying
processes. In this context explanations try to es-
tablish a common ground between the parties in
the sense that the technical system tries to clar-
ify its actual model to the user. This is the at-
tempt of aligning the user?s mental model to the
actual system. However, explanations do not al-
ways have the goal of aligning mental models, but
can be used for other purposes as well. Analogous
to human-human interaction, in human-computer
interaction the sender of the explanation pursues a
certain goal, with respect to the addressee, which
should be achieved. The question remains, how
these different goals of explanation (see table 1)
map to HCT, meaning, how they influence HCT
or components of it.
2.2 Human-Computer Trust
Mayer et al. (1995) define trust in human-human
interaction to be ?the extent to which one party is
willing to depend on somebody or something, in
a given situation with a feeling of relative secu-
rity, even though negative consequences are pos-
sible?. For HCI trust can be defined as ?the atti-
tude that an agent will help achieve an individual?s
goals in a situation characterized by uncertainty
and vulnerability? (Lee and See, 2004). Techni-
cal Systems which serve as intelligent assistants
with the purpose of helping the user in complex as
well as in critical situations seem to be very de-
pendent on an intact HCT relationship. However,
trust is multi-dimensional and consists of several
bases. For human relationships, Mayer et al. de-
fined three levels that build the bases of trust: abil-
ity, integrity and benevolence. The same holds for
HCI, where HCT is a composite of several bases.
For human-computer trust Madsen and Gregor
(2000) constructed a hierarchical model (see fig-
ure 1) resulting in five basic constructs or so-called
bases of trust, which can be divided in two general
components, namely cognitive-based and affect-
based bases. In short-term human-computer in-
teraction, cognitive-based HCT components seem
to be more important, because it will be easier to
influence those. Perceived understandability can
be seen in the sense that the human supervisor
or observer can form a mental model and predict
future system behavior. The perceived reliabil-
ity of the system, in the usual sense of repeated,
consistent functioning. And technical competence
means that the system is perceived to perform the
tasks accurately and correctly based on the input
information. In this context it is important to men-
tion, that as Mayer already stated, the bases of
trust are separable, yet related to one another. All
bases must be perceived highly for the trustee to be
52
Figure 1: Human-computer trust model: Personal
attachment and faith build the bases for affect-
based trust. Rerceived understandability, techni-
cal competence and reliability for cognition-based
trust.
deemed trustworthy. If any of the bases does not
fulfill this requirement, the overall trustworthiness
can suffer (Madsen and Gregor, 2000).
3 Related Work
Previous work on handling trust in technical sys-
tems was done for example by Glass et al. (2008).
They investigated factors that may change the
level of trust users are willing to place in adaptive
agents. Among these verified findings were state-
ments like ?provide the user with the information
provenance for sources used by the system?, ?in-
telligently modulating the granularity of feedback
based on context- and user-modeling? or ?supply
the user with access to information about the in-
ternal workings of the system?. However, what is
missing in Glass et al.?s work is the idea of rat-
ing the different methods to uphold HCT in gen-
eral and the use of a complex HCT model. Other
related work was for example done by Lim et al.
(2009) on how different kinds of explanations can
improve the intelligibility of context-aware intel-
ligent systems. They concentrate on the effect of
Why, Why-not, How-to and What-if explanations
on trust and understanding system?s actions or re-
actions. The results showed that Why and Why-
not explanations were the best kind of explanation
to increase the user?s understanding of the sys-
tem, though trust was only increase by providing
Why explanations. Drawbacks of this study were
that they did only concentrate on understanding
the system and trusting the system in general and
did not consider that HCT is on the one hand not
only influenced by the user?s understanding of the
system and on the other hand that if one base of
trust is flawed, the HCT in general will be dam-
aged (Mayer et al., 1995).
Regarding the issue of trusting a technical sys-
tem or its actions and reactions related work ex-
ists for example on ?credibility? (Fogg and Tseng,
1999). However, this term developed in the web
community focusing on the believability of exter-
nal sources. The term trust is used in the web
research community as well as in work on ?trust
in automation?. However, as Fogg stated himself
later (Tseng and Fogg, 1999) credibility should be
called believability and trust-in-automation should
be called dependability to reduce the missunder-
standings. In this work we use the term human-
computer trust and its model by Madsen and Gre-
gor (2000) subsuming both terms.
4 Experiment on Explanation
Effectiveness
The insight that human-computer trust is not a
simple but complex construct and the lack of di-
rected methods to influence components of HCT
motivated us to conduct an experiment which tried
to overcome some of these issues. The use of ex-
planations to influence HCT bases in a directed
and not arbitrary way, depends on whether an
effective mapping of explanation goals to HCT
bases can be found. This means, that we have
to identify which goal of explanation influences
which base of trust in the most effective way.
Therefore, the goal was to change undirected
strategies to handle HCT issues into directed and
well-founded ones, substantiating the choice and
goal of explanation.
For that we conducted a web-based study in-
ducing events to create not understandable or not
expected situations and then compared the effects
of the different goals of explanations on the HCT-
bases. For our experiment we concentrated on jus-
tification and transparency explanations. Justifica-
tions are the most obvious goal an explanation can
pursue. The main idea of this goal is to provide
support for and increase confidence in given sys-
tem advices or actions. The goal of transparency
is to increase the users understanding in how the
system works and reasons. This can help the user
to change his perception of the system from a
black-box to a system the user can comprehend.
Thereby, the user can build a mental model of the
system and its underlying reasoning processes.
The participants in the experiment where ac-
53
quired by using flyers in the university as well as
through facebook. The age of the participants was
in a range from 14 to 61, with the mean being 24,1.
Gender wise, the distribution was 59% (male) to
41% (female), with most of the participants be-
ing students. For the participation the students did
receive a five euro voucher for a famous online
store. However, this was only granted when fin-
ishing the complete experiment. Therefore, partic-
ipants dropping out of the experiment would waive
the right on the voucher.
4.1 Set-Up
The main objective of the participants to organize
four parties for friends or relatives in a web-based
environment. This means that they had to use the
browser at home or the university to organize for
example, the music, select the type and amount of
food or order drinks. Each party was described
by an initial screen depicting the key data for the
party. This included which tasks had to be accom-
plished and how many people were expected to
join (see figure 2). Each task was implemented
as a single web-page, with the goal to organize
one part of the party (i.e., dinner, drinks, or cham-
pagne reception). The user had to choose from
several drop-down menus which item should be
ordered for the party and in what number. For ex-
ample, the user had to order the components of
the dinner (see figure 3). When an entry inside
a drop-down menu was chosen, the system gave
an advice on how much of this would be needed
to satisfy the needs of one guest. Additionally, be-
fore the participant could move on to the next task,
the orders were checked by the system. The sys-
tem would output whether the user had selected
too much, too little or the right amount and only if
everything was alright could proceed to the next
task. The experiment consisted in total of four
rounds. The first two rounds were meant to go
smoothly and were supposed to get the subject
used to the system and by that building a men-
tal model of it. After the first two rounds a HCT
questionnaire was presented to the user. As ex-
pected the user has built a relationship with the
system by gaining an understanding of the systems
processes. The next two rounds were meant to
influence the HCT-relationship negative with un-
expected external events. These unexpected, and
incongruent to the user?s mental model, system
events were influencing pro-actively the decisions
Figure 2: General information on the party. How
many people plan to attend the event and what type
of tasks have to be accomplished.
and solutions the user made to solve the task. This
means, without warning, the user was overruled
by the system and either simply informed by this
change, or was presented an additional justifica-
tion or transparency explanation as seen in figure
3. In this figure we can see that the user?s order
(?Bestellungsliste?) was changed pro-actively be-
cause of an external event. Here the attendance of
some participants was cancelled in the reservation
system, thus the system did intervene. This pro-
active change was explained at the bottom of the
web-page by, in this case, providing a justification
(?The order was changed by the system, because
the number of attending persons decreased?). The
matching transparency explanation would not only
provide a reason, but explain how the system an-
swer was reached (?Due to recent events the or-
der was changed by the system. The order vol-
ume has been reduced, because several persons
canceled their attendance in the registration sys-
tem.?). Events like this occurred several times in
the rounds 3 and 4 of the party planning.
4.2 Results
139 starting participants were distributed among
the three test groups (no explanation, transparency,
justifications). 98 accomplished round 2, reach-
ing the point until the external events were in-
duced and 59 participants completed the experi-
ment. The first main result was that 47% from
the group receiving no explanations quit during
54
Figure 3: This screenshot shows one of the tasks the user has to accomplish. In this case dinner (?Haupt-
gerichte?) including entree (?Vorspeisen?) and desserts has to be ordered.
the critical rounds 3 and 4. However, if expla-
nations were presented only 33% (justifications)
and 35% (transparency) did quit. This means that
eventhough the participants would encounter neg-
ative consequences of losing the reward money,
they did drop out of the experiment. Therefore,
we can state that the use of explanations in incom-
prehensible and not expected situations can help
to keep the human-computer interaction running.
The main results from the HCT-questionnaires can
be seen in figure 4. The data states that providing
no explanations in rounds three and four resulted
in a decrease in several bases of trust. Therefore,
we can conclude that the external events did in-
deed result in our planned negative change in trust.
Perceived understandability diminished on aver-
age over the people questioned by 1.2 on a Lik-
ert scale with a range from 1 to 5 when providing
no explanation at all compared to only 0.4 when
providing transparency explanations (no explana-
tion vs. transparency t(34)=-3.557 p<0.001), and
on average by 0.5 with justifications (no expla-
nation vs. justifications t(36)=-2.023 p<0.045).
Omitting explanations resulted in an average de-
crease of 0.9 for the perceived reliability, with
transparency explanations in a decrease of 0.4 and
for justifications in a decrease of 0.6 (no explana-
tion vs. transparency t(34)=-2.55 p<0.015).
These results support our hypotheses that trans-
parency explanations can help to reduce the neg-
ative effects of trust loss regarding the user?s per-
ceived understandability and reliability of the sys-
tem in incomprehensible and unexpected situa-
tions. Especially for the base of understandability,
meaning the prediction of future outcomes, trans-
parency explanations fulfill their purpose in a good
way. Additionally, they seem to help with the per-
ception of a reliable, consistent system. The re-
sults show that it is worthwhile to augment ongo-
ing dialogs with explanations to maintain HCT.
While analyzing the data we did not find any
statistically significant differences between pro-
viding transparency and justification explanations.
However, this could be due to limited differences
in the goals of explanation. Usually, the trans-
parency explanations in the experiment were in-
cluding more information on what happened in-
side the system, and how the system did recognize
the external event (e.g., the reduction of attend-
ing persons). In future experiments we will try to
distinguish those two goals of explanations more
from each other. For example, the justification for
reduce attendance to an event can be changed to
something like ?The order was changed by the sys-
tem, because otherwise you would have too much
food? instead of ?The order was changed by the
system, because the number of attending persons
decreased? and by that making it more different
from the transparency explanation (?Due to recent
events the order was changed by the system. The
order volume has been reduced, because several
persons canceled their attendance in the registra-
tion system.?). In the following, we will describe
how this is used in our developed explanation aug-
55
Figure 4: This figure shows the changes of HCT bases from round 2 to round 4. The scale was a 5 point
likert scale with e. g., 1 the system being not understandable at all and 5 the opposite.
mentation architecture (see figure 5).
5 Implementation
The augmentation of the dialog is done using two
different kinds of dialog models. On the one hand
we are using a classic dialog model based on a
finite-state machine approach for the task-oriented
part of the dialog. On the other hand a planner
(M?uller et al., 2012) is used to generate from a
POMDP a decision tree. This POMDP is used
only for the augmentation of the task-oriented part
of the dialog with explanations. The communi-
cation between each module of the architecture
is controlled by a XML-based message-oriented
middleware (Schr?oder, 2010), using a publish-
subscribe system to distribute the XML-messages.
In order to decide when to induce additional ex-
planations, on one hand critical situations in HCI
have to be recognized and on the other hand, if
necessary the appropriate type of explanation has
to be given. Obviously, recognizing those situa-
tions cannot be done solely by using information
coming from interaction and its history. Multi-
modal input as speech recognition accuracy, fa-
cial expressions or any other sensor information
can help to improve the accuracy of recognizing
critical moments in HCI. However, mapping sen-
sor input to semantic information is usually done
by classifiers and those classifiers convey a certain
amount of probabilistic inaccuracy which has to
be handled. Therefore, a decision model has to be
able to handle probabilistic information in a suit-
able manner.
5.1 Probabilistic Decision Model
For the problem representation when and how to
react, a so-called partially observable Markov de-
cision process (POMDP) was chosen and formal-
ized in the Relational Dynamic Influence Dia-
gram Language (RDDL) (Sanner, 2010). RDDL
is a uniform language which allows an efficient
description of POMDPs by representing its con-
stituents (actions, observations, belief state) with
variables. Formally, a POMDP consists of a set
S of world states, a set A of system actions, and
a set O of possible observations the system can
make. Further, transition probabilities P (s
?
|s, a)
describe the dynamics of the environment, i.e., the
probability of the successor world state being s
?
when action a is executed in state s. The obser-
vation probabilities P (o|s
?
, a) represent the sen-
sors of the system in terms of the probability of
making observation o when executing a resulted
in successor world state s
?
. Each time the system
executes an action a, it receives a reward R(s, a)
which depends on the world state s the action was
executed in. The overall goal of the system is to
maximize the accumulated reward it receives over
a fixed number of time steps. (For more informa-
tion on POMDPs, see Kaelbling et al. (1998).)
A POMDP is then used by a planner (Silver and
Veness, 2010; M?uller et al., 2012) to search for a
policy that determines the system?s behavior. This
policy is, e.g., represented as a decision tree that
recommends the most suitable action based on the
system?s previous actions and observations. For
example, a policy for a POMDP that models HCI
with respect to HCT, can thus represent a decision
tree which represents a guideline for a dialog flow
which ensures an intact HCT-relationship.
The RDDL model is a probabilistic representa-
tion of the domain, which determines when and
how to augment the dialog with explanations at
run-time. Each observation o consists of the du-
56
Figure 5: The architecture consists of two dialog models, a fission and fusion engine, sensors as well as
the multimodal interface representation to interact with the user. The dialog models can be seperated in
a task-oriented FSM-dialog model and into a POMDP-based decision tree for explanation augmentation.
This decision tree is generated from a POMDP-model by a planner.
ration of interaction for each dialog step as well as
the semantic information of the input (i.e., which
action in the interface was triggered by speech,
touch or point-and-click interaction). Those types
of interaction can bring along uncertainty (e.g.,
speech recognition rate). The state s in terms of
HCT is modeled by its respective bases, namely
understandability, technical-competence, reliabil-
ity, faith and personal attachment. The system
actions A are the dialogs presented to the user.
These are the different goals of explanations (jus-
tification, transparency, conceptualization, rele-
vance and learning) as well as the task-oriented
part of the dialog represented by a so-called com-
municative function(c) with c from set C (e.g.,
question, inform, answer, offer, request, instruct).
This means, that in the POMDP only the com-
municative function of the task-oriented dialogs is
represented without the specific content.
The transition probabilities are defined as con-
ditional probability functions (CPFs) and model
user behavior dependent on the system?s actions
and the user?s current HCT values. Basically, con-
ditional functions are defined using if else for all
wanted cases. For example, we defined that the
user?s understanding in s
?
will probably be high
if a transparency explanation was the last system
action. When the user?s understanding is indeed
high in s
?
, the observation will probably be that
the user clicked okay, and the time he took for the
interaction was around his usual amount taken for
explanations. From this observation, a planner can
infer that the transparency explanation indeed in-
creased the user?s understanding.
Now, the quest is to define the reward func-
tion R(s, a) in a way that it leads to an optimal
flow of actions. I.e., the system should receive a
penalty when the bases of trust do not remain in-
tact, and actions should incur a cost so that the sys-
tem only executes them when trust is endangered.
However, because POMDPs tend to be become
very quick very complex, we chose to seperate
the task-oriented dialog from the additional dialog
augmentation with explanations when needed.
5.2 Dialog Augmentation Process
The task-oriented dialog is modeled as a classic
finite-state machine (FSM). Each dialog action has
several interaction possibilities, each leading to
another specified dialog action. Each of those di-
alog action is represented as POMDP action a as
part of C (communicative function(c)). As already
mentioned, only the communicative function is
modeled to reduce the complexity in the POMDP.
The HCI is started using the FSM-based di-
alog model approach and uses the POMDP to
check whether the user?s trust or components of
the user?s trust are endangered. At run-time the
next action in the FSM is compared to the one
determined by the POMDP (see figure 6). This
means, that if the next action in the FSM is not the
same as the one planned by the POMDP, the dia-
57
Figure 6: This figure shows the comparison of
FSM to Decision Tree. The next action m
3
in the
FSM does not correspond to the one endorsed by
the POMDP Decision Tree. Therefore, the dialog
will be augmented by explanation action m
E
.
log flow is interrupted, and the ongoing dialog is
augmented by the proposed explanation. For ex-
ample, if the user is presented currently a commu-
nicative function of type inform and the decision
tree recommends to provide a transparency expla-
nation, because the understanding and reliability
are probably false, the originally next step in the
FSM is postponed and first the explanation is pre-
sented. The other way around, if the next action in
the FSM is subsumed by the one scheduled by the
POMDP, the system does not need to intervene.
For example, if the next FSM-action is to instruct
the user about how to connect amplifier and re-
ceiver and the POMDP would recommend an ac-
tion of type communicative function instruct, no
dialog augmentation is needed.
6 Dialog Interface
Each dialog action in the FSM as well as the ex-
planation dialogs are represented by a so-called di-
alog goal, which is allocated on the one hand a
type of communicative function c. On the other
hand the dialog content is composed of multiple
information objects referencing so-called informa-
Figure 7: A typical output presentation of the fis-
sion component of a dialog goal. Here the user
gets instruction on how to connect the BluRay-
Player with an HDMI cable.
tion IDs in the information model. Each informa-
tion object can consist of different types (e.g., text,
audio, and pictures). For interface presentation
the dialog goal is passed to the fission which se-
lects and combines the information objects at run-
time by a fission sub-component to compose the
user interface in a user- and situation-adaptive way
(Honold et al., 2012). In figure 7 we can see a typi-
cal interface for a transmitted dialog goal in which
the user can interact via speech, touch or GUI.
7 Conclusion and Future Work
In this paper we showed the necessity to deal with
critical situations in HCI in a probabilistic ap-
proach. The advantage of our approach is that
the designer still can define a FSM-based task-
oriented dialog. Usually most commercial sys-
tems are still based on such approaches. However,
expanding the dialog by a probabilistic decision
model seems to be a valuable choice. Our experi-
ment on the influence of explanations on HCT has
clearly shown, that it is worthwhile to augment the
ongoing dialog by transparency or justification ex-
planations for an intact HCT relationship. In the
future we will run experiments on how effective
the hybrid FSM-POMDP approach is compared to
classic as well as POMDP dialog systems.
Acknowledgment
This work was supported by the Transregional
Collaborative Research Centre SFB/TRR 62
?Companion-Technology for Cognitive Technical
Systems? which is funded by the German Re-
search Foundation (DFG).
58
References
B. J. Fogg and Hsiang Tseng. 1999. The elements of
computer credibility. In Proceedings of the SIGCHI
conference on Human Factors in Computing Sys-
tems, CHI ?99, pages 80?87, New York, NY, USA.
ACM.
Alyssa Glass, Deborah L. McGuinness, and Michael
Wolverton. 2008. Toward establishing trust in adap-
tive agents. In IUI ?08: Proceedings of the 13th in-
ternational conference on Intelligent user interfaces,
pages 227?236, NY, USA. ACM.
Frank Honold, Felix Sch?ussel, and Michael Weber.
2012. Adaptive probabilistic fission for multimodal
systems. In Proceedings of the 24th Australian
Computer-Human Interaction Conference, OzCHI
?12, pages 222?231.
L. P. Kaelbling, M. L. Littman, and A. R. Cassandra.
1998. Planning and acting in partially observable
stochastic domains. Artificial Intelligence, pages
99?134.
John D. Lee and Katrina A. See. 2004. Trust in au-
tomation: Designing for appropriate reliance. Hu-
man Factors, 46(1):50?80.
Brian Y. Lim, Anind K. Dey, and Daniel Avrahami.
2009. Why and why not explanations improve the
intelligibility of context-aware intelligent systems.
In Proceedings of the SIGCHI Conference on Hu-
man Factors in Computing Systems, CHI ?09, pages
2119?2128, NY, USA. ACM.
Maria Madsen and Shirley Gregor. 2000. Measur-
ing human-computer trust. In Proceedings of the 11
th Australasian Conference on Information Systems,
pages 6?8.
Roger C. Mayer, James H. Davis, and F. David Schoor-
man. 1995. An Integrative Model of Organiza-
tional Trust. The Academy of Management Review,
20(3):709?734.
B M Muir. 1992. Trust in automation: Part i. theoret-
ical issues in the study of trust and human interven-
tion in automated systems. In Ergonomics, pages
1905?1922.
Felix M?uller, Christian Sp?ath, Thomas Geier, and Su-
sanne Biundo. 2012. Exploiting expert knowl-
edge in factored POMDPs. In Proceedings of the
20th European Conference on Artificial Intelligence
(ECAI 2012), pages 606?611.
Raja Parasuraman and Victor Riley. 1997. Humans
and automation: Use, misuse, disuse, abuse. Human
Factors: The Journal of the Human Factors and Er-
gonomics Society, 39(2):230?253, June.
Scott Sanner. 2010. Relational dynamic in-
fluence diagram language (rddl): Language
description. http://users.cecs.anu.edu.au/ ssan-
ner/IPPC2011/RDDL.pdf.
Marc Schr?oder. 2010. The semaine api: Towards
a standards-based framework for building emotion-
oriented systems. Advances in Human-Machine In-
teraction, (319406):21.
D. Silver and J. Veness. 2010. Monte-carlo planning
in large POMDPs. In NIPS, pages 2164?2172.
F. S?rmo and J. Cassens. 2004. Explanation goals
in case-based reasoning. In Proceedings of the
7th European Conference on Case-Based Reason-
ing, pages 165?174.
Shawn Tseng and B. J. Fogg. 1999. Credibility and
computing technology. Commun. ACM, 42(5):39?
44, May.
59
Proceedings of the SIGDIAL 2014 Conference, pages 208?217,
Philadelphia, U.S.A., 18-20 June 2014.
c?2014 Association for Computational Linguistics
Interaction Quality Estimation in Spoken Dialogue Systems Using
Hybrid-HMMs
Stefan Ultes
Ulm University
Albert-Einstein-Allee 43
89081 Ulm, Germany
stefan.ultes@uni-ulm.de
Wolfgang Minker
Ulm University
Albert-Einstein-Allee 43
89081 Ulm, Germany
wolfgang.minker@uni-ulm.de
Abstract
Research trends on SDS evaluation are
recently focusing on objective assess-
ment methods. Most existing methods,
which derive quality for each system-
user-exchange, do not consider tempo-
ral dependencies on the quality of pre-
vious exchanges. In this work, we in-
vestigate an approach for determining In-
teraction Quality for human-machine dia-
logue based on methods modeling the se-
quential characteristics using HMM mod-
eling. Our approach significantly outper-
forms conventional approaches by up to
4.5% relative improvement based on Un-
weighted Average Recall metrics.
1 Introduction
Spoken Dialogue Systems (SDSs) play a key role
in achieving natural human-machine interaction.
One reason is that speech is one major chan-
nel of natural human communication. Assess-
ing the quality of such SDSs has been discussed
frequently in recent years. The basic principles
which all approaches underlie have been analyzed
by M?oller et al. (2009) creating a taxonomy for
quality of human-machine interaction, i.e., Qual-
ity of Service (QoS) and Quality of Experience
(QoE). Quality of Service describes objective cri-
teria like total number of turns. The recent shift of
interest in dialogue assessment methods towards
subjective criteria is described as Quality of Expe-
rience, putting the user in the spotlight of dialogue
assessment. For QoE, M?oller et al. (2009) iden-
tified several aspects contributing to a good user
experience, e.g., usability or acceptability. These
aspects can be combined under the term user sat-
isfaction, describing the degree by which the user
is satisfied with the system?s performance. By as-
sessing QoE, the hope of the research community
is to better measure the human-like quality of an
SDS. While this information may be used during
the design process, enabling automatically derived
user satisfaction within the dialogue management
allows for adaption of the ongoing dialogue (Ultes
et al., 2012b).
First work on deriving subjective metrics au-
tomatically has been performed by Walker et
al. (1997) resulting in the PARADISE framework,
which is the current quasi-standard in this field.
Briefly explained, a linear dependency is assumed
between dialogue parameters and user satisfaction
to estimate qualitative performance on the dia-
logue level.
Measuring the performance of complete dia-
logues does not allow for adapting to the user dur-
ing the dialogue (Ultes et al., 2012b). Hence,
performance measures which provide a measure-
ment for each system-user-exchange
1
are of inter-
est. Approaches based on Hidden Markov Models
(HMMs) are widely used for sequence modeling.
Therefore, Engelbrecht et al. (2009) used these
models for predicting the dialogue quality on the
exchange level. Similar to this, we presented work
on estimating Interaction Quality using HMMs
and Conditioned HMMs (Ultes et al., 2012a). In
this contribution, we investigate an approach for
recognizing the dialogue quality using a hybrid
Markovian model. Here, hybrid means combin-
ing statistical approaches such as Support Vector
Machines with Hidden Markov Models by model-
ing the observation probability of the HMMs us-
ing classification. While this is the first time hy-
brid approaches are used for estimating Interaction
Quality, they are well-known and have been used
before for other classification tasks (e.g. (Valstar
and Pantic, 2007; Onaran et al., 2011)).
This paper is outlined as follows: Related work
on subjective quality measurement on the ex-
1
A system-user-exchange consists of a system dialogue
turn followed by a user dialogue turn
208
change level is presented in Section 2. All experi-
ments in this work are based on the Interaction
Quality metric of the LEGO corpus described in
Section 3. We motivate for introducing time de-
pendency and present our own approach on rec-
ognizing Interaction Quality using a Markovian
model presented in Section 4 and briefly present
the classification algorithms used for the experi-
ments in Section 5. Experiments are presented in
Section 6 and their results discussion in Section 7.
2 Significant Related Work
Much research on predicting subjective quality
measures on an exchange level has been per-
formed hitherto. However, most of this body of
work lacks of either taking account of the sequen-
tial structure of the dialogue or resulting in insuf-
ficient performance.
Engelbrecht et al. (2009) presented an approach
using Hidden Markov Models (HMMs) to model
the SDS as a process evolving over time. Perfor-
mance ratings on a 5 point scale (?bad?, ?poor?,
?fair?, ?good?, ?excellent?) have been applied by
the users of the SDS during the dialogue. The in-
teraction was halted while the user rated. A HMM
was created consisting of 5 states (one for each
rating) and a 6-dimensional input vector. While
Engelbrecht et al. (2009) relied on only 6 input
variables, we will pursue an approach with 29 in-
put variables. Moreover, we will investigate dia-
logues of a real world dialogue system annotated
with quality labels by expert annotators.
Higashinaka et al. (2010) proposed a model for
predicting turn-wise ratings for human-human di-
alogues. Ratings ranging from 1 to 7 were applied
by two expert annotators labeling for smooth-
ness, closeness, and willingness. They achieved
an UAR
2
of only 0.2-0.24 which is only slightly
above the random baseline of 0.14.
Hara et al. (2010) derived turn level ratings from
overall ratings of the dialogue which were applied
by the users after the interaction on a five point
scale within an online questionnaire. Using n-
grams to model the dialogue by calculating n-gram
occurrence frequencies for each satisfaction value
showed that results for distinguishing between six
classes at any point in the dialogue to be hardly
above chance.
A more robust measure for user satisfaction has
been presented by Schmitt et al. (2011) within
2
Unweighted Average Recall, see Section 6
s
u
s
u
s
u
s
u
?
s 1
u 1
s 2
u 2
s 3
u 3
s n
u n
?
e 1
e 2
e 3
e n
Figure 1: A dialogue may be separated into a se-
quence of system-user-exchanges where each ex-
change e
i
consists of a system turn s
i
followed by
a user turn u
i
.
their work about Interaction Quality (IQ) for Spo-
ken Dialogue Systems. In contrast to user satis-
faction, the labels were applied by expert annota-
tors after the dialogue at the exchange level. Auto-
matically derived parameters were used as features
for creating a statistical model using static fea-
ture vectors. Schmitt et al. (2011) performed IQ
recognition on the LEGO corpus (see Section 3)
using linear SVMs. They achieved an UAR
2
of
0.58 based on 10-fold cross-validation which is
clearly above the random baseline of 0.2. Ultes
et al. (2012a) put an emphasis on the sequential
character of the IQ measure by applying a Hid-
den Markov Models (HMMs) and a Conditioned
Hidden Markov Models (CHMMs). Both have
been applied using 6-fold cross validation and a
reduced feature set of the LEGO corpus achieving
an UAR
2
of 0.44 for HMMs and 0.39 for CHMMs.
While Ultes et al. (2012a) used generic Gaussian
Mixture Models to model the observation proba-
bilities, we use confidence distributions of static
classification algorithms.
3 The LEGO Corpus
For Interaction Quality (IQ) estimation, we use the
LEGO corpus published by Schmitt et al. (2012).
Interaction Quality is defined similarly to user sat-
isfaction: While the latter represents the true dis-
position of the user, IQ is the disposition of the
user assumed by an expert annotator. Here, ex-
pert annotators are people who listen to recorded
dialogues after the interactions and rate them by
assuming the point of view of the actual person
performing the dialogue. These experts are sup-
posed to have some experience with dialogue sys-
tems. In this work, expert annotators were ?ad-
vanced students of computer science and engineer-
ing? (Schmitt et al., 2011), i.e., grad students.
The LEGO corpus is based on 200 calls to
209
s 1
u 1
s 2
u 2
s 3
u 3
s n
u n
?
e 1
e 2
e 3
e n
e n
?
e n-
1
e n-
2
e 1
e 2
e 3
e n+
1
?
exc
ha
ng
e le
vel
 pa
ram
ete
rs
win
do
w l
eve
l p
ara
me
ter
s: {
#},
 {M
ean
}, e
tc.
dia
log
ue 
lev
el p
ara
me
ter
s: #
, M
ean
, et
c.
Figure 2: The three different modeling levels representing the interaction at exchange e
n
: The most
detailed exchange level, comprising parameters of the current exchange; the window level, capturing
important parameters from the previous n dialog steps (here n = 3); the dialog level, measuring overall
performance values from the entire previous interaction.
the ?Let?s Go Bus Information System? of the
Carnegie Mellon University in Pittsburgh (Raux et
al., 2006) recorded in 2006. Labels for IQ have
been assigned by three expert annotators to 200
calls consisting of 4,885 system-user-exchanges
(see Figure 1) in total with an inter-annotator
agreement of ? = 0.54. This may be considered
as a moderate agreement (cf. Landis and Koch?s
Kappa Benchmark Scale (1977)) which is quite
good considering the difficulty of the task that re-
quired to rate each exchange. For instance, if one
annotator reduces the IQ value only one exchange
earlier than another annotator, both already dis-
agree on two exchanges. The final label was as-
signed to each exchange by using the median of
all three individual ratings.
IQ was labeled on a scale from 1 (extremely un-
satisfied) to 5 (satisfied) considering the complete
dialogue up to the current exchange. Thus, each
exchange has been rated without regarding any up-
coming user utterance. As the users are expected
to be satisfied at the beginning, each dialogue?s
initial rating is 5. In order to ensure consistent la-
beling, the expert annotators had to follow labeling
guidelines (Schmitt et al., 2012).
An example of an annotated dialogue is shown
in Table 5. It starts off with a good IQ until the
system provides some results and then falls drasti-
cally as the user input does not correspond to what
the system expects. Thus, the system remains in a
loop until the user reacts appropriately.
Parameters used as input variables for the IQ
model have been derived from the dialogue system
modules automatically for each exchange. Fur-
thermore, parameters on three levels have been
created: the exchange level, the dialogue level,
and the window level (see Figure 2). As parame-
ters like ASRCONFIDENCE (confidence of speech
recognition) or UTTERANCE (word sequence rec-
ognized by speech recognition) can directly be
acquired from the dialogue modules they consti-
tute the exchange level. Counts, sums, means,
and frequencies of exchange level parameters from
multiple exchanges are computed to constitute the
dialogue level (all exchanges up to the current
one) and the window level (the three previous ex-
changes).
4 Hybrid-HMM
As Schmitt et al. (2011) model the sequential
character of the data only indirectly by design-
ing special features, our approach applies Marko-
vian modeling to directly model temporal de-
pendencies. Temporal dependencies on previous
system-user-exchanges are not taken into account
by Schmitt et al.; only parameters derived from
the current exchange are used. However, we found
out that Interaction Quality is highly dependent on
the IQ value of the previous exchange. Adding
the parameter IQ
prev
describing the previous IQ
value to the input vector to the IQ model consist-
ing of several parameters results in an extended in-
put vector. Calculating the Information Gain Ra-
tio (IGR) of each parameter of the extended input
vector shows that IQ
prev
achieves the highest IGR
value of 1.0. In other words, IQ
prev
represents the
parameter which contains the most information for
the classification task.
While performing IQ recognition on the ex-
tended features set using the annotated IQ values
results in an UAR of 0.82, rather using the esti-
mated IQ value results in an UAR of only 0.43.
Consequently, other configurations have to be in-
vestigated. Here, Markovian approaches offer a
self-contained concept of using these temporal de-
pendencies. However, Ultes et al. (2012a) showed
that applying neither a classical HMM nor a con-
ditioned HMM yields results outperforming static
approaches.
Therefore, in this Section we present a Hybrid-
210
HMM approach, which is based on the classical
HMM and takes advantage of good performing
existing static classification approaches. The clas-
sical HMM, specifically used for time-sequential
data, consists of a set of states S with transition
probability matrix A and initial probability vec-
tor pi over a set of observations B (also called vo-
cabulary) and an observation function b
q
t
depen-
dent on the state q
t
. For calculating the proba-
bility p(q
t
|O
t
, ?) of seeing observation sequence
O
t
= (o
1
, o
2
, . . . , o
t
) while being in state q
t
at
time t given the HMM ?, the Forward Algorithm
is used:
p(q
t
= s
j
|O
t
, ?) = ?
t
(j)
=
|S|
?
i=1
?
t?1
(i)a
ij
b
j
(o
t
) . (1)
Here, a
ij
describes the transition probability of
transitioning from state s
i
to state s
j
. To find
a suitable model ?, the HMM must be trained,
for example, by using the Baum-Welch algorithm.
Usually, the observation function b
q
t
is modeled
with Gaussian mixture models (GMMs). For more
information on general HMMs, please refer to Ra-
biner et al. (1989).
For determining the most likely class ??
t
at time
t, where each state j ? S is associated with one
class ?, the following equation is used:
??
t
= arg max
j
?
t
(j) . (2)
For applying an HMM while exploiting exist-
ing statistical classification approaches, the obser-
vation function b
j
(o
t
) is modeled by using con-
fidence score distributions of statistical classifiers,
e.g., a Support Vector Machine in accordance with
Schmitt et al. (2011) (see Section 5). Furthermore,
the transition function a
ij
is computed by taking
the frequencies of the state transitions contained
in the given corpus. Therefore, an ergodic HMM
is used comprising five states with each represent-
ing one of the five IQ scores.
Moreover, in SDSs, a system action act is per-
formed at the end of each system turn. This can
be utilized by adding an additional dependency on
this action to the state transition function a
ij
. By
augmenting Equation 1, this results in
?
t
(j) =
|S|
?
i=1
?
t?1
(i)a
ij,act
b
j
(o
t
) . (3)
This refinement models differences in state tran-
sitions evoked by different system actions, e.g.,
a different transition probability is expected if a
WAIT action is performed compared to a CONFIR-
MATION. Equation 3 is equal to the belief up-
date equation known from the Partially Observ-
able Markov Decision Process formalism (Kael-
bling et al., 1998).
Therefore, two versions of the Hybrid-HMM
are evaluated: an action-independent version as in
Equation 1 and an action-dependent version as in
Equation 3.
5 Classifier Types
For modeling the observation probability b
j
(o
t
)of
the hybrid HMM, multiple classification schemes
have been applied to investigate the influence of
observation distributions with different character-
istics on the overall performance.
In general, classification means estimating a
class ?? to the given observation o by comparing
the class-wise probabilities p(?|o). In this work,
this probability may be used to model the observa-
tion probability b
j
(o) of the HMM by the posterior
probability
p(?|o) = b
j
(o) (4)
for j = ?.
As not all classification algorithms provide a
posterior probability, it may be replaced by the
confidence distribution. A general description of
the classification algorithms used in this work are
described in the following Section along with a
motivation for the feature subset of the LEGO cor-
pus used for estimating the Interaction Quality in
this work.
5.1 Support Vector Machine
For a two class problem, a Support Vector Ma-
chine (SVM) (Vapnik, 1995) is based on the con-
cept of linear discrimination with maximum mar-
gin by defining a hyperplane separating the two
classes. The estimated class ?? for observation vec-
tor ~o is based on the sign of the decision function
k(~o) =
N
?
i=1
?
i
z
i
K(~m
i
, ~o) + b , (5)
where ~m
i
represent support vectors defining the
hyper plane (together with b), z
i
the known class
~m
i
belongs to, ?
i
the weight of ~m
i
, and K(?, ?) a
211
kernel function. The kernel function is defined as
K(~m, ~m
?
) = ??(~m), ?(~m
?
)? , (6)
where ?(~m) represents a transformation function
mapping ~m into a space ? of different dimension-
ality and ??, ?? defines a scalar product in ?. By
using the kernel function, the linear discrimina-
tion may happen in a space of high dimensional-
ity without explicitly transforming the observation
vectors into said space.
The SVM implementation which is used in this
contribution is libSVM (Chang and Lin, 2011). As
this algorithm does not provide class probabilities
directly, the respective confidence scores are used.
5.2 Naive Bayes
For deriving the posterior probability, the Naive
Bayes classifier may be used. It calculates the pos-
terior probability P (?|o) of having class ? when
seeing the n-dimensional observation vector ~o by
applying Bayes rule (Duda et al., 2001):
P (?|~o) =
p(~o|?) ? P (?)
p(~o)
. (7)
In general, observations, i.e., elements of the
observation vector, may be correlated with each
other and introducing independence assumptions
between these elements does usually not reflect
the true state of the world. However, correlations
are often not very high thus simplifying the Bayes
problem has proved to result in reasonable perfor-
mance. This is utilized by the Naive Bayes classi-
fier by assuming said independence thus calculat-
ing
p(~o|?) =
n
?
i=1
p(o
i
|?) . (8)
5.3 Rule Induction
The classification algorithm Rule Induction or
Rule Learner is based on the idea of defining rules
to assign classes ?? to observation vectors ~o. In this
work, the algorithm RIPPER (Repeated Incremen-
tal Pruning to Produce Error Reduction) (Cohen,
1995) is used where each rule consists of conjunc-
tions of A
n
= v, where A
n
is a nominal attribute,
or A
c
? ?,A
c
? ?, where A
c
is a continuous at-
tribute. Each part of the observation vector ~o is re-
flected by one of the attributes. The basic process
of the algorithm for generating rules is divided into
three steps: First, rules are grown by adding at-
tributes to the rule. Second, the rules are pruned.
If the resulting rule set is not of sufficient perfor-
mance, all training examples which are covered by
the generated rules are removed from the example
set and a new rule is created.
5.4 Feature selection
As stated previously, all experiments are based on
the LEGO corpus presented in Section 3. In order
to keep the presented results comparable to pre-
vious work based on HMM and CHMM (Ultes et
al., 2012a), a reduced parameter set is used. Pa-
rameters with constant values for most exchanges
have been excluded. These would result in rows
of zeros during computation of the covariance ma-
trices of the feature vectors, which are needed for
HMM and CHMM classification. A row of ze-
ros in the covariance matrix will make it non-
invertible, which will cause errors during the com-
putation of the emission probabilities.
Therefore, a feature set consisting of 29 inter-
action parameters is used for both defining a base-
line and for evaluating the Hybrid-HMM. The set
consists of the following parameters (for an expla-
nation of the features, please refer to (Schmitt et
al., 2012)):
Exchange Level ASRRECOGNITIONSTATUS, ACTIVITY-
TYPE, ASRCONFIDENCE, ROLEINDEX, ROLENAME,
UTD, REPROMPT?, BARGED-IN?, DD, WPST,
WPUT
Dialogue Level MEANASRCONFIDENCE, #ASRREJEC-
TIONS, #TIMEOUTS ASRREJ, #BARGEINS, %ASR-
REJECTIONS, %TIMEOUTS ASRREJ, %BARGEINS,
#REPROMPTS,
%REPROMPTS, #SYSTEMQUESTIONS
Window Level #TIMEOUTS ASRREJ, #ASRREJEC-
TIONS, #BARGEINS, %BARGEINS, #SYSTEMQUES-
TIONS, MEANASRCONFIDENCE, #ASRSUCCESS,
#RE-PROMPT
For act in Equation 3, the exchange level pa-
rameter ACTIVITYTYPE is used which may take
one out of the four values ?Announcement?, ?Con-
firmation?, ?Question?, or ?wait?. Their distribu-
tion within the LEGO corpus is depicted in Fig-
ure 3.
6 Experiments and Results
All experiments are conducted using 6-fold cross-
validation
3
. This includes the baseline approach
3
Six folds have been selected as a reasonable trade-off be-
tween validity and computation time.
212
3066
2477
3266
274
01000200030004000
Anno
unce
men
tC
onfir
mati
on
Ques
tion
wait
Figure 3: Distribution of the four values for act
in Equation 3 in the LEGO corpus. While ?wait?
occurs rarely, the other three main actions occur at
roughly the same frequency.
(also producing the observation probabilities of
the Hybrid-HMM approach) and the evaluation of
the Hybrid-HMM. For the latter, two phases of
cross-validation were applied.
Interaction Quality estimation is done by
using three commonly used evaluation met-
rics: Unweighted Average Recall (UAR), Co-
hen?s Kappa (Cohen, 1960) and Spearman?s
Rho (Spearman, 1904). These are also selected
as the same metrics have been used in Schmitt et
al. (2011) as well.
Recall in general is defined as the rate of cor-
rectly classified samples belonging to one class.
The recall in UAR for multi-class classification
problems with N classes recall
i
is computed for
each class i and then averaged over all class-wise
recalls:
UAR =
1
N
N
?
i=1
recall
i
. (9)
Cohen?s Kappa measures the relative agree-
ment between two corresponding sets of ratings.
In our case, we compute the number of label
agreements corrected by the chance level of agree-
ment divided by the maximum proportion of times
the labelers could agree. However, Cohen?s
weighted Kappa is applied as ordinal scores are
compared (Cohen, 1968). A weighting factor w is
introduced reducing the discount of disagreements
the smaller the difference is between two ratings:
w =
|r
1
? r
2
|
|r
max
? r
min
|
. (10)
Here, r
1
and r
2
denote the rating pair and r
max
and r
min
the maximum and minimum ratings pos-
sible.
Table 1: Results for IQ recognition of the statis-
tical classifiers: UAR, ? and ? for linear SVM,
Bayes classification and Rule Induction. ?
2
repre-
sents the variances of the confidence scores.
UAR ? ? ?
2
SVM (linear) .495 .611 .774 .020
Bayes .467 .541 .716 .127
Rule Induction .596 .678 .790 .131
Correlation between two variables describes the
degree by which one variable can be expressed by
the other. Spearman?s Rho is a non-parametric
method assuming a monotonic function between
the two variables (Spearman, 1904).
6.1 Baseline
As baseline, we adapted the approach of Schmitt
et al. (2011). While they focused only on an SVM
with linear kernel, we investigate three different
static classification approaches. Different clas-
sifiers will produce different confidence distribu-
tions. These distributions will have different char-
acteristics which is of special interest for evaluat-
ing the Hybrid-HMM as will be discussed in Sec-
tion 7. The confidence characteristics are repre-
sented by the variance of the confidence scores
?
2
. This variance is used as indicator for how cer-
tain the classifier is about its results. If one IQ
value has a high confidence while all others have
low confidence, the classifier is considered to be
very certain. This also results in a high variance.
Vice versa, if all IQ values have almost equal con-
fidence indicates high uncertainty. This will result
in a low variance.
The classification algorithms, which have been
selected arbitrarily, are SVM with linear kernel,
Naive Bayes, and Rule Induction (see Section 5).
The results in Table 1 show that an SVM with lin-
ear kernel (as used by Schmitt et al. (2011)) per-
forms second best with an UAR of 0.495 after
Rule Induction with an UAR of 0.596. The re-
sults of the SVM differ from the results obtained
by Schmitt et al. (UAR of 0.58) as we used a re-
duced feature set while they used all available fea-
tures.
6.2 Hybrid-HMM
For evaluating the Hybrid-HMM on Interaction
Quality recognition, three aspects are of inter-
est. Most prominent is whether the presented ap-
proaches outperform the baseline, i.e., the clas-
213
?3.7%
+4.0%?*
+2.0%?*
?2.3%
+4.5%?*
+2.1%?*
+2.2%?*
+4.1%?*
+2.0%?*
?7?%?5?%?3?%?1?%+1?
%
+3?
%
+5?
%
SVM (lin
ear
)
Bay
es
Rul
e
Ind
uct
ion
AI
AD
HC
Figure 4: Relative difference of UAR in percent between the baseline performance and the Hybrid-
HMM for the action-independent (AI), action-dependent (AD) and handcrafted (HC) transition matrix.
Differences marked with an * are significant (Wilcoxon test (Wilcoxon, 1945), ? < 0.05).
Table 2: Results for the Hybrid-HMM approach:
UAR, ? and ? for the action-independent (AI) and
action-dependent (AD) versions.
UAR ? ?
AI AD AI AD AI AD
SVM (linear) .477 .484 .599 .598 .770 .771
Bayes .486 .489 .563 .564 .737 .741
Rule Induction .608 .609 .712 .714 .826 .824
sifier which produces the observation probabili-
ties. Moreover, performance values of action-
dependent approaches and action-independent ap-
proaches are compared. In addition, the results are
analyzed with respect to the characteristic of the
confidence distribution.
For producing the confidence scores represent-
ing the observation probabilities, the statistical
classification algorithms presented in Section 6.1
are used. The initial distribution pi for each HMM
was chosen in accordance with the annotation
guidelines of the LEGO corpus starting each di-
alogue with an IQ score of 5 resulting in
pi
5
= P (IQ = 5) = 1.0
pi
4
= pi
3
= pi
2
= pi
1
= P (IQ 6= 5) = 0.0 .
Results of the experiments with action-dependent
(AD) and action-independent (AI) transition func-
tion may be seen in Table 2. Again, Rule Induction
performed best with Naive Bayes on the second
and SVM on the third place.
7 Discussion
While previous work on applying the HMM and
CHMM for IQ recognition could not outperform
the baseline (Ultes et al., 2012a), Hybrid-HMM
experiments show a significant improvement in
UAR, Cohen?s ? and Spearman?s ? for Naive
Bayes and Rule Induction. While performance
declines for the linear SVM, this difference has
shown to be not significant.
The relative difference of the Hybrid-HMM
compared to the respective baseline approaches
using an action-dependent and an action-
independent transition matrix is depicted in
Figure 4. Improvement for the Bayes method was
the highest significantly increasing UAR by up to
4.5% relative to the baseline. However, adding
action-dependency to the Hybrid-HMM does not
show any effect. This may be a result of using
ACTIVITYTYPE instead of the actual action.
However, using the actual action would result in
the need for more data as it contains 45 different
values. Significance for all results has been
calculated using the Wilcoxon test (Wilcoxon,
1945) by pair-wise comparison of the estimated
IQ values of all exchanges. All results except for
the decline in SVM performance are significant
with ? < 0.05.
Correlating the confidence variances shown in
Table 1 with the improvements of the Hybrid-
HMM reveals that for methods with a high
variance?and therefore with a greater certainty
about the classification result?, an improvement
could be accomplished. However, the perfor-
214
Table 3: Results of Hybrid-HMM with hand-
crafted transition matrix of the action-independent
version.
UAR ? ?
SVM (linear) .506 .642 .797
Bayes .487 .563 .734
Rule Induction .608 .712 .825
Table 4: Handcrafted transition matrix based on
empirical data.
P
P
P
P
P
P
from
to
1 2 3 4 5
1 0.7 0.3 0 0 0
2 0.25 0.5 0.25 0 0
3 0 0.25 0.5 0.25 0
4 0 0 0.25 0.5 0.25
5 0 0 0 0.3 0.7
mance declined for classification approaches with
a low confidence variance, which can be seen as a
sign for uncertain classification results.
While the results for Hybrid-HMM are encour-
aging, creating a simple handcrafted transition
matrix for the action-independent version shown
in Table 4 achieved even more promising results
as performance for all classifier types could be im-
proved significantly compared to the baseline (see
Table 3). The handcrafted matrix was created in a
way to smooth the resulting estimates as only tran-
sitions from one IQ rating to its neighbors have a
probability greater than zero. Drastic changes in
the estimated IQ value compared to the previous
exchange are thus less likely. The exact values
have been derived empirically. By applying this
handcrafted transition matrix, even SVM perfor-
mance with linear kernel could be improved sig-
nificantly by 2.2% in UAR (see Figure 4) com-
pared to the baseline.
For creating the Interaction Quality scores, an-
notation guidelines were used resulting in certain
characteristics of IQ. Therefore, it may be as-
sumed that the effect of exploiting the dependency
on previous states is just a reflection of the guide-
lines. While this might be true, applying a Hy-
brid HMM for IQ recognition is reasonable as, de-
spite the guidelines, the IQ metric itself is strongly
related to user satisfaction, i.e., ratings applied
by users (without guidelines), achieving a Spear-
man?s ? of 0.66 (? < 0.01) (Ultes et al., 2013).
8 Conclusions
As previously published, approaches for recogniz-
ing the Interaction Quality of Spoken Dialogue
Systems are based on static classification without
temporal dependency on previous values, a Hy-
brid Hidden Markov Model approach has been in-
vestigated based on three static classifiers. The
Hybrid-HMM achieved a relative improvement up
to 4.5% and a maximum of 0.61 UAR. Analyz-
ing the experiments revealed that, while an im-
provement could be achieved with the Hybrid-
HMM approach, handcrafting a transition model
achieved even better results as performance for all
analyzed classifier types could be improved signif-
icantly. Furthermore, applying the Hybrid-HMM
approach only yields improved performance if the
basic classifier itself has a high confidence about
its results.
Further research should be conducted investi-
gating the question how the presented approach as
well as the Interaction Quality paradigm in general
will generalize for different dialogue domains. As
IQ is designed to be domain independent, it may
be expected that the Hybrid-HMM will be appli-
cable for different dialogue domains as well.
Finally, it is notable that rule induction outper-
formed SVM approaches in the baseline by 10 per-
centage points. While this contribution does not
focus on this, analyzing the model may help in un-
derstanding the problem of estimating Interaction
Quality better, especially since rule-based recog-
nition methods allow easy interpretation.
Acknowledgments
This work was supported by the Transregional
Collaborative Research Centre SFB/TRR 62
?Companion-Technology for Cognitive Technical
Systems? which is funded by the German Re-
search Foundation (DFG).
References
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technology,
2:27:1?27:27.
Jacob Cohen. 1960. A coefficient of agreement for
nominal scales. In Educational and Psychological
Measurement, volume 20, pages 37?46, April.
Jacob Cohen. 1968. Weighted kappa: Nominal scale
agreement provision for scaled disagreement or par-
tial credit. Psychological bulletin, 70(4):213.
William W. Cohen. 1995. Fast effective rule induc-
tion. In Proceedings of the 12th International Con-
215
ference on Machine Learning, pages 115?123. Mor-
gan Kaufmann, July.
Richard O. Duda, Peter E. Hart, and David G. Stork.
2001. Pattern Classification (2nd Edition). Wiley-
Interscience, 2 edition, November.
Klaus-Peter Engelbrecht, Florian G?odde, Felix Har-
tard, Hamed Ketabdar, and Sebastian M?oller. 2009.
Modeling user satisfaction with hidden markov
model. In SIGDIAL ?09: Proceedings of the SIG-
DIAL 2009 Conference, pages 170?177, Morris-
town, NJ, USA. ACL.
Sunao Hara, Norihide Kitaoka, and Kazuya Takeda.
2010. Estimation method of user satisfaction us-
ing n-gram-based dialog history model for spo-
ken dialog system. In Proceedings of the Seventh
conference on International Language Resources
and Evaluation (LREC?10), Valletta, Malta, May.
ELRA.
Ryuichiro Higashinaka, Yasuhiro Minami, Kohji
Dohsaka, and Toyomi Meguro. 2010. Issues in pre-
dicting user satisfaction transitions in dialogues: In-
dividual differences, evaluation criteria, and predic-
tion models. In Spoken Dialogue Systems for Am-
bient Environments, volume 6392 of Lecture Notes
in Computer Science, pages 48?60. Springer Berlin
/ Heidelberg.
L. P. Kaelbling, M. L. Littman, and A. R. Cassandra.
1998. Planning and acting in partially observable
stochastic domains. Artificial Intelligence, 101(1-
2):99?134.
J. R. Landis and G. G. Koch. 1977. The measurement
of observer agreement for categorical data. Biomet-
rics, 33(1):159?174, March.
Sebastian M?oller, Klaus-Peter Engelbrecht, C. K?uhnel,
I. Wechsung, and B. Weiss. 2009. A taxonomy of
quality of service and quality of experience of mul-
timodal human-machine interaction. In Quality of
Multimedia Experience, 2009. QoMEx 2009. Inter-
national Workshop on, pages 7?12, July.
Ibrahim Onaran, N Firat Ince, A Enis Cetin, and Aviva
Abosch. 2011. A hybrid svm/hmm based system for
the state detection of individual finger movements
from multichannel ecog signals. In Neural Engi-
neering (NER), 2011 5th International IEEE/EMBS
Conference on, pages 457?460. IEEE.
Lawrence R. Rabiner. 1989. A tutorial on hidden
Markov models and selected applications in speech
recognition. Morgan Kaufmann Publishers Inc., San
Francisco, CA, USA.
Antoine Raux, Dan Bohus, Brian Langner, Alan W.
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: One year
of let?as go! experience. In Proc. of the Interna-
tional Conference on Speech and Language Process-
ing (ICSLP), September.
Alexander Schmitt, Benjamin Schatz, and Wolfgang
Minker. 2011. Modeling and predicting quality in
spoken human-computer interaction. In Proceed-
ings of the SIGDIAL 2011 Conference, Portland,
Oregon, USA, June. Association for Computational
Linguistics.
Alexander Schmitt, Stefan Ultes, and Wolfgang
Minker. 2012. A parameterized and annotated cor-
pus of the cmu let?s go bus information system. In
International Conference on Language Resources
and Evaluation (LREC).
Charles Edward Spearman. 1904. The proof and mea-
surement of association between two things. Ameri-
can Journal of Psychology, 15:88?103.
Stefan Ultes, Robert ElChabb, and Wolfgang Minker.
2012a. Application and evaluation of a condi-
tioned hidden markov model for estimating inter-
action quality of spoken dialogue systems. In Pro-
ceedings of the 4th International Workshop on Spo-
ken Language Dialog System (IWSDS), pages 141?
150. Springer, November.
Stefan Ultes, Alexander Schmitt, and Wolfgang
Minker. 2012b. Towards quality-adaptive spoken
dialogue management. In NAACL-HLT Workshop
on Future directions and needs in the Spoken Dialog
Community: Tools and Data (SDCTD 2012), pages
49?52, Montr?eal, Canada, June. ACL.
Stefan Ultes, Alexander Schmitt, and Wolfgang
Minker. 2013. On quality ratings for spoken dia-
logue systems ? experts vs. users. In Proceedings of
the 2013 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 569?
578. ACL, June.
Michel F. Valstar and Maja Pantic. 2007. Combined
support vector machines and hidden markov mod-
els for modeling facial action temporal dynamics.
In Human-Computer Interaction, volume 4796 of
Lecture Notes in Computer Science, pages 118?127.
Springer Berlin Heidelberg.
Vladimir N. Vapnik. 1995. The nature of statistical
learning theory. Springer-Verlag New York, Inc.,
New York, NY, USA.
Marilyn Walker, Diane Litman, Candace A. Kamm,
and Alicia Abella. 1997. Paradise: a framework
for evaluating spoken dialogue agents. In Proceed-
ings of the eighth conference on European chap-
ter of the Association for Computational Linguistics,
pages 271?280, Morristown, NJ, USA. ACL.
Frank Wilcoxon. 1945. Individual comparisons by
ranking methods. Biometrics bulletin, 1(6):80?83.
216
Appendix
Table 5: Example of a dialogue annotated with Interaction Quality for each system-user-exchange. As
the system fails to interact properly with the user in the end, the IQ value drops down to one. Utterance
represents either the system utterance or the recognized user utterance. (CallID 2061123000 of the
LEGO corpus.)
Utterance IQ
S: Welcome to the CMU Let?s Go bus information system.
U: 5
S: To get help at any time, just say Help or press zero.
U: 5
S: What can I do for you?
U: PENN AT BUTLER TIME IS IT IS THE CENTRE AT HIGHLAND FROM RUNS THE 61A EIGHT THIRTY 61B CAN?T OAKLAND 5
S: Leaving from OAKLAND . Is this correct?
U: OAKLAND 4
S: Leaving from OAKLAND . Is this correct?
U: YES 4
S: Right
U: - 4
S: Where do you want to go?
U: SQUIRREL HILL OF FIFTH AVENUE 4
S: Going to FIFTH AVENUE . Is this correct?
U: YES 5
S: Alright
U: - 5
S: When do you wanna travel?
U: SUNDAY 4
S: At what time do you wanna travel?
U: AT FIVE FOUR VERY ABOUT ELEVEN O?CLOCK 4
S: Leaving at 11 a.m. . Is this correct?
U: YES 5
S: Right
U: - 5
S: Hold on. Let me check that for you.
U: - 5
S: OAKLAND and FIFTH AVENUE are both the same stop. Please provide a different start or end point.
U: - 3
S: To ask about a different trip, you can say, start a new query. If you are finished, you can say goodbye.
U: 61A 2
S: You can say start a new query, or goodbye.
U: FIVE DUQUESNE 1
S: To ask about a different trip, you can say, start a new query. If you are finished, you can say goodbye.
U: LAST THE NEXT 1
S: You can say start a new query, or goodbye.
U: START WH 1
S: To ask about a different trip, you can say, start a new query. If you are finished, you can say goodbye.
U: THE 1
S: You can say start a new query, or goodbye.
U: THANK YOU QUERY ELEVEN BACK 1
S: To ask about a different trip, you can say, start a new query. If you are finished, you can say goodbye.
U: GOODBYE 1
S: Thank you for using the cmu Let?s Go Bus Information System. Goodbye.
U: - 1
217
