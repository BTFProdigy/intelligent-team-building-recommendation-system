Proceedings of the 12th Conference of the European Chapter of the ACL, pages 843?851,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Feature-based Method for Document Alignment in 
Comparable News Corpora 
 
Thuy Vu, Ai Ti Aw, Min Zhang 
Department of Human Language Technology, Institute for Infocomm Research 
1 Fusionopolis Way, #21-01 Connexis, South Tower, Singapore 138632 
{tvu, aaiti, mzhang}@i2r.a-star.edu.sg 
 
 
 
Abstract 
In this paper, we present a feature-based me-
thod to align documents with similar content 
across two sets of bilingual comparable cor-
pora from daily news texts. We evaluate the 
contribution of each individual feature and 
investigate the incorporation of these diverse 
statistical and heuristic features for the task of 
bilingual document alignment. Experimental 
results on the English-Chinese and English-
Malay comparable news corpora show that 
our proposed Discrete Fourier Transform-
based term frequency distribution feature is 
very effective. It contributes 4.1% and 8% to 
performance improvement over Pearson?s 
correlation method on the two comparable 
corpora. In addition, when more heuristic and 
statistical features as well as a bilingual dic-
tionary are utilized, our method shows an ab-
solute performance improvement of 23.2% 
and 15.3% on the two sets of bilingual corpo-
ra when comparing with a prior information 
retrieval-based method.  
1 Introduction 
The problem of document alignment is described 
as the task of aligning documents, news articles 
for instance, across two corpora based on content 
similarity. The groups of corpora can be in the 
same or in different languages, depending on the 
purpose of one?s task. In our study, we attempt to 
align similar documents across comparable cor-
pora which are bilingual, each set written in a 
different language but having similar content and 
domain coverage for different communication 
needs. 
Previous works on monolingual document 
alignment focus on automatic alignment between 
documents and their presentation slides or be-
tween documents and their abstracts. Kan (2007) 
uses two similarity measures, Cosine and Jac-
card, to calculate the candidate alignment score 
in his SlideSeer system, a digital library software 
that retrieves documents and their narrated slide 
presentations. Daum? and Marcu (2004) use a 
phrase-based HMM model to mine the alignment 
between documents and their human-written ab-
stracts. The main purpose of this work is to in-
crease the size of the training corpus for a 
statistical-based summarization system. 
The research on similarity calculation for mul-
tilingual comparable corpora has attracted more 
attention than monolingual comparable corpora. 
However, the purpose and scenario of these 
works are rather varied. Steinberger et al (2002) 
represent document contents using descriptor 
terms of a multilingual thesaurus EUROVOC1, 
and calculate the semantic similarity based on the 
distance between the two documents? representa-
tions. The assignment of descriptors is trained by 
log-likelihood test and computed by ?????, Co-
sine, and Okapi. Similarly, Pouliquen et al 
(2004) use a linear combination of three types of 
knowledge: cognates, geographical place names 
reference, and map documents based on the 
EUROVOC. The major limitation of these works 
is the use of EUROVOC, which is a specific re-
source workable only for European languages. 
Aligning documents across parallel corpora is 
another area of interest. Patry and Langlais (2005) 
use three similarity scores, Cosine, Normalized 
Edit Distance, and Sentence Alignment Score, to 
compute the similarity between two parallel doc-
uments. An Adaboost classifier is trained on a list 
of scored text pairs labeled as parallel or non-
parallel. Then, the learned classifier is used to 
check the correctness of each alignment candidate. 
Their method is simple but effective. However, 
the features used in this method are only suitable 
for parallel corpora as the measurement is mainly 
based on structural similarity. One goal of docu-
ment alignment is for parallel sentence extraction 
for applications like statistical machine transla-
tion. Cheung and Fung (2004) highlight that most 
                                                          
1 EUROVOC is a multilingual thesaurus covering the fields 
in which the European Communities are active.  
843
of the current sentence alignment models are ap-
plicable for parallel documents, rather than com-
parable documents. In addition, they argue that 
document alignment should be done before paral-
lel sentence extraction.  
Tao and Zhai (2005) propose a general method 
to extract comparable bilingual text without us-
ing any linguistic resources. The main feature of 
this method is the frequency correlation of words 
in different languages. They assume that those 
words in different languages should have similar 
frequency correlation if they are actually transla-
tions of each other. The association between two 
documents is then calculated based on this in-
formation using Pearson?s correlation together 
with two monolingual features 25?? , a term 
frequency normalization (Stephan et al, 1994), 
and ???. The main advantages of this approach 
are that it is purely statistical-based and it is lan-
guage-independent. However, its performance 
may be compromised due to the lack of linguistic 
knowledge, particularly across corpora which are 
linguistically very different. Recently, Munteanu 
(2006) introduces a rather simple way to get the 
group of similar content document in multilin-
gual comparable corpus by using the Lemur IR 
Toolkit (Ogilvie and Callan, 2001). This method 
first pushes all the target documents into the da-
tabase of the Lemur, and then uses a word-by-
word translation of each source document as a 
query to retrieve similar content target docu-
ments.  
This paper will leverage on previous work, 
and propose and explore diverse range of fea-
tures in our system. Our document alignment 
system consists of three stages: candidate genera-
tion, feature extraction and feature combination. 
We verify our method on two set of bilingual 
news comparable corpora English-Chinese and 
English-Malay. Experimental results show that 
1) when only using Fourier Transform-based 
term frequency, our method outperforms our re-
implementation of Tao (2005)?s method by 4.1% 
and 8% for the top 100 alignment candidates and, 
2) when using all features, our method signifi-
cantly outperforms our implementation of Mun-
teanu?s (2006) method by 23.2% and 15.3%.  
The paper is organized as follows. In section 
2, we describe the overall architecture of our sys-
tem. Section 3 discusses our improved frequency 
correlation-based feature, while Section 4 de-
scribes in detail the document relationship heu-
ristics used in our model. Section 5 reports the 
experimental results. Finally, we conclude our 
work in section 6. 
2 System Architecture 
Fig 1 shows the general architecture of our doc-
ument alignment system. It consists of three 
components: candidate generation, feature ex-
traction, and feature combination. Our system 
works on two sets of monolingual corpora to de-
rive a set of document alignments that are com-
parable in their content. 
Fig 1. Architecture for Document Alignment Model. 
2.1 Candidate Generation 
Like many other text processing systems, the 
system first defines two filtering criteria to prune 
out ?clearly bad? candidates. This will dramati-
cally reduce the search space. We implement the 
following filers for this purpose: 
Date-Window Filter: As mentioned earlier, 
the data used for the present work are news cor-
pora?a text genre that has very strong links with 
the time element. The published date of docu-
ment is available in data, and can easily be used 
as an indicator to evaluate the relation between 
two articles in terms of time. Similar to Muntea-
nu?s (2006), we aim to constrain the number of 
candidates by assuming that documents with 
similar content should have publication dates 
which are fairly close to each other, even though 
they reside in two different sets of corpora. By 
imposing this constraint, both the complexity and 
the cost in computation can be reduced tremend-
ously as the number of candidates would be sig-
nificantly reduced. For example, when a 1-day 
window size is set, this means that for a given 
source document, the search for its target candi-
dates is set within 3 days of the source document: 
the same day of publication, the day after, and 
the day before. With this filter, using the data of 
one-month in our experiment, a reduction of 90% 
of all possible alignments can be achieved (sec-
tion 5.1). Moreover, with our evaluation data, 
844
after filtering out document pairs using a 1-day 
window size, up to 81.6% for English-Chinese 
and 80.3% for English-Malay of the golden 
alignments are covered. If the window size is 
increased to 5, the coverage is 96.6% and 95.6% 
for two language pairs respectively. 
Title-n-Content Filter: previous date window 
filter constrains the number of candidates based 
purely on temporal information without exploit-
ing any knowledge of the documents? contents. 
The number of candidates to be generated is thus 
dependent on the number of published articles 
per day, instead of the candidates? potential con-
tent similarity. For this reason, we introduce 
another filter which makes use of document titles 
to gauge content-wise cross document similarity. 
As document titles are available in news data, we 
capitalize on words found in these document 
titles, favoring alignment candidates where at 
least one of the title-words in the source docu-
ment has its translation found in the content of 
the other target document. This filter can reduce 
a further 47.9% (English-Chinese) and 26.3% 
(English-Malay) of the remaining alignment can-
didates after applying the date-window filter. 
2.2 Feature Extraction 
The second step extracts all the features for each 
candidate and computes the score for each indi-
vidual feature function. In our model, the feature 
set is composed of the Title-n-Content score 
(???), Linguistic-Independent-Unit score (???), 
and Monolingual Term Distribution similarity 
(???). We will discuss all three features in sec-
tions 3 and 4. 
2.3 Feature Combination 
The final score for each alignment candidate is 
computed by combining all the feature function 
scores into a unique score. In literature, there are 
many methods concerning the estimation of the 
overall score for a given feature set, which vary 
from supervised to unsupervised method. Super-
vised methods such as Support Vector Machine 
(SVM) and Maximum Entropy (ME) estimate 
the weight of each feature based on training data 
which are then used to calculate the final score. 
However, these supervised learning-based me-
thods may not be applicable to our proposed is-
sue as we are motivated to build a language 
independent unsupervised system. We simply 
take a product of all normalized features to ob-
tain one unique score. This is because our fea-
tures are probabilistically independent. In our 
implementation, we normalize the scores to make 
them less sensitive to the absolute value by tak-
ing the logarithm ???. ? as follows: 
 
??????? ? ???
?? ? ??, ? ? ?? ? ??
1, ????
 (1)
 
 
?? ? ?? is a threshold for ? to contribute posi-
tively to the unique score. In our experiment, we 
empirically choose ?  be 2.2 , and the threshold 
for ? is 0.51828 (as ? ? 2.71828). 
3 Monolingual Term Distribution 
3.1 Baseline Model 
The main feature used in Tao and Zhai (2005) is 
the frequency distribution similarity or frequency 
correlation of words in two given corpora. It is 
assumed that frequency distributions of topically-
related words in multilingual comparable corpora 
are often correlated due to the correlated cover-
age of the same events.  
Let ? ? ???, ??, ? , ??? and ? ? ???, ??, ? , ??? 
be the frequency distribution vectors of two 
words ?  and ?  in two documents respectively. 
The frequency correlation of the two words is 
computed by Pearson?s Correlation Coefficient 
in (2). 
 
???, ?? ?
? ????
?
??? ?? ??
?
??? ? ??
?
???
??? ??
??
??? ?
?
?
?? ??
?
??? ?
?
??? ??
??
??? ?
?
?
?? ??
?
??? ?
?
?
 (2)
 
The similarity of two documents is calculated 
with the addition of two features namely Inverse 
Document Frequency (???) and 25?? term fre-
quency normalization shown in the equation (3). 
 
 
????, ??? ? ? ?????? ? ?????? ? ???, ?? ?????,????
25????, ??? ? 25????, ???  
(3)
 
 
Where 25????, ??  is the word frequency 
normalization for word ?  in document? , and 
????????? is the average length of a document. 
 
25????, ?? ? ???
??,??
???,???????????
|?|
??????????
  (4)
 
It is noted that the key feature used by Tao and 
Zhai (2005) is the ???, ?? score which depends 
purely on statistical information. Therefore, our 
motivation is to propose more features to link the 
source and target documents more effectively for 
a better performance.  
3.2 Study on Frequency Correlation 
We further investigate the frequency correlation of 
words from comparable sets of corpora compris-
ing three different languages using the above-
defined model.  
845
 
Fig 2. Sample of frequency correlation for ?Bank Dunia?, ?World Bank?, and ??????. 
 
 
Fig 3. Sample of frequency correlation for ?Dunia?, ?World?, and ????. 
 
 
Fig 4. Sample of frequency correlation for ?Filipina?, ?Information Technology?, and ?????. 
 
Using three months - May to July, 2006 ? of daily 
newspaper in Strait Times2 (in English), Zao Bao3 
(in Chinese), and Berita Harian4 (in Malay), we 
conduct the experiments described in the follow-
ing Fig 2, Fig 3, and Fig 4 showing three different 
cases of term or word correlation. In these figures, 
the ?-axis denotes time and the ?-axis shows the 
frequency distribution of the term or word.  
Multi-word versus Single-word: Fig 2 
illustrates that the distributions for multi-word 
term such as ?World Bank?, ?????(World 
Bank in Chinese)?, and ?Bank Dunia (World 
Bank in Malay)? in the three language corpora 
are almost similar because of the discriminative 
power of that phrase. The phrase has no variance 
and contains no ambiguity. On the other hand, 
the distributions for single words may have much 
less similarity. 
                                                          
2 http://www.straitstimes.com/ an English news agency in 
Singapore. Source ? Singapore Press Holdings Ltd. 
3 http://www.zaobao.com/ a Chinese news agency in Singa-
pore. Source ? Singapore Press Holdings Ltd. 
4 http://cyberita.asia1.com.sg/ a Malay news agency in Sin-
gapore. Source ? Singapore Press Holdings Ltd. 
Related Common Word: we also investigate 
the similarity in frequency distribution for related 
common single words in the case of ?World?, 
??? (world in Chinese)?, and ?Dunia (world in 
Malay)? as shown in Fig 3. It can be observed 
that the correlation of these common words is not 
as strong as that in the multi-word sample illu-
strated in Fig 2. The reason is that there are many 
variances of these common words, which usually 
do not have high discriminative power due to the 
ambiguities presented within them. Nonetheless, 
among these variances, there is still a small simi-
lar distribution trends that can be detected, which 
may enable us to discover the associations be-
tween them. 
Unrelated Common Word: Fig 4 shows the 
frequency distribution of three unrelated com-
mon words over the same three-month period. 
No correlation in distribution is found among 
them.
0
0.05
0.1
0.15
0.2
1 11 21 31 41 51 61 71 81 91
Bank?Dunia World?Bank ????
0
0.01
0.02
0.03
1 11 21 31 41 51 61 71 81 91
Dunia World ??
0
0.05
0.1
0.15
1 11 21 31 41 51 61 71 81 91
Filipina Information?Technology ???
846
3.3 Enhancement from Baseline Model 
3.3.1 Monolingual Term Correlation 
Due to the inadequacy of the baseline?s purely 
statistical approach, and our studies on the corre-
lations of single, multiple and commonly appear-
ing words, we propose using ?term? or ?multi-
word? instead of ?single-word? or ?word? to cal-
culate the similarity of term frequency 
distribution between two documents. This 
presents us with two main advantages. Firstly, 
the smaller number of terms compared to the 
number of words present in any document would 
imply fewer possible document alignment pairs 
for the system. This increases the computation 
speed remarkably. To extract automatically the 
list of terms in each document, we use the term 
extraction model from Vu et al (2008). In corpo-
ra used in our experiments, the average ratios of 
word/term per document are 556/37, 410/28 and 
384/28 for English, Chinese, and Malay respec-
tively. The other advantage of using terms is that 
terms are more distinctive than words as they 
contain less ambiguity, thus enabling high corre-
lation to be observed when compared with single 
words. 
3.3.2 Bilingual Dictionary Incorporation 
In addition to using terms for the computation, 
we observed from equation (3) that the only mu-
tual feature relating the two documents is the 
frequency distribution coefficient ???, ?? . It is 
likely that the alignment performance could be 
enhanced if more features relating the two doc-
uments are incorporated. 
Following that, we introduce a linguistic fea-
ture, ??????????, ?? , to the baseline model to 
enhance the association between two documents. 
This feature involves the comparison of the 
translations of words within a particular term in 
one language, and the presence of these transla-
tions in the corresponding target language term. 
If more translations obtained from a bilingual 
dictionary of words within a term are found in 
the term extracted from the other language?s 
document, it is more likely that the 2 bilingual 
terms are translations of each other. This feature 
counts the number of word translation found be-
tween the two terms, as described in the follow-
ing. Let ??  and ??  be the term list of ??  and ?? 
respectively, the similarity score in our model is: 
???????, ??? ? ? ?????? ? ?????? ? ???, ?? ?????,????
??????????, ?? ? 25????, ??? ? 25????, ???
(5) 
3.3.3 Distribution Similarity Measurement 
using Monolingual Term 
Finally, we apply the results of time-series re-
search to replace Pearson?s correlation which is 
used in the baseline model, in our calculation of 
the similarity score of two frequency distribu-
tions. A popular technique for time sequence 
matching is to use Discrete Fourier Transform 
(??? ) (Agrawal et al 1993). More recently, 
Klementiev and Roth (2006) also use F-index 
(Hetland, 2004), a score using ???, to calculate 
the time distribution similarity. In our model, we 
assume that the frequency chain of a word is a 
sequence, and calculate ???  score for each 
chain by the following formula: 
?? ? ???. ?
?????
??
???
 (6)
In time series research, it is proven that only 
the first few ?  coefficients of a ???  chain are 
strong and important for comparison (Agrawal et 
al, 1993). Our experiments in section 5 show that 
the best value for ? is 7 for both language pairs. 
???, ?? ?
?
??????? ? ????
?
?
???
?
?
??
 (7)
The ???, ??  in equation (5) is replaced by 
???, ?? in equation (8) to calculate the Monolin-
gual Term Distribution (???) score. 
4 Document Relationship Heuristics 
Besides the ???, we also propose two heuristic-
based features that focus directly on the 
relationship between two multilingual documents, 
namely the Title-n-Content score? ??? , which 
measures the relationship between the title and 
content of a document pair, and Linguistic Inde-
pendent Unit score ? ??? , which make use of 
orthographic similarity between unit of words for 
the different languages.  
4.1 Title-n-Content Score (???) 
Besides being a filter for removing bad align-
ment candidates, ???  is also incorporated as a 
feature in the computation of document align-
ment score. In the corpora used, in most docu-
ments, ?title? does reveal the main topic of a 
document. The use of words in a news title is 
???????, ??? ? ? ?????? ? ??????
????,????
? ???, ?? ? ??????????, ??
? 25????, ??? ? 25????, ??? 
(8)
847
typically concise and conveys the essence of the 
information in the document. Thus, a high ??? 
score would indicate a high likelihood of similar-
ity between two bilingual documents. Therefore, 
we use ??? as a quantitative feature in our fea-
ture set. Function ????, ?? checks whether the 
translation of a word in a document?s title is 
found in the content of its aligned document: 
 
????, ?? ? ?1,     translation of ? is in ?0,     else                                (9)
 
The ??? score of document ??  and ??  is cal-
culated by the following formula: 
 
??????, ??? ? 
? ?????, ???
???T?
? ? ?????, ???
???T?
 (10)
Where ??  and ??  are the content of document 
?? and ??; and ?? and ?? are the set of title words 
of two documents. 
In addition, this method speeds up the align-
ment process without compromising perfor-
mance when compared with the calculation 
based only on contents on both sides. 
4.2 Linguistic Independent Unit (???) 
Linguistic Independent Unit score (LIU) is de-
fined as the piece of information, which is writ-
ten in the same way for different languages. The 
following highlight the number 25, 11, and 50 as 
linguistic-independent-units for the two sen-
tences. 
English: Between Feb 25 and March 11 this 
year, she used counterfeit $50 notes 10 times to 
pay taxi fares ranging from $2.50 to $4.20. 
Chinese:????????????? 2 ?
25 ?? 3? 11 ??? 50 ????????
??? 2? 5?? 4? 2?????? 
5 Experiment and Evaluation 
5.1 Experimental Setup 
The experiments were conducted on two sets of 
comparable corpora namely English-Chinese and 
English-Malay. The data are from three news 
publications in Singapore: the Strait Times (ST, 
English), Lian He Zao Bao (ZB, Chinese), and 
Berita Harian (BH, Malay). Since these languag-
es are from different language families 5 , our 
model can be considered as language indepen-
dent. 
                                                          
5 English is in Indo-European; Chinese is in Sino-Tibetan; 
Malay is in Austronesian family [Wikipedia]. 
The evaluation is conducted based on a set of 
manually aligned documents prepared by a group 
of bilingual students. It is done by carefully read-
ing through each article in the month of June 
(2006) for both sets of corpora and trying to find 
articles of similar content in the other language 
within the given time window. Alignment is 
based on similarity of content where the same 
story or event is mentioned. Any two bilingual 
articles with at least 50% content overlapping are 
considered as comparable. This set of reference 
data is cross-validated between annotators. Table 
1 shows the statistics of our reference data for 
document alignment. 
 
Language pair ST ? ZB ST ? BH 
Distinct source 396 176
Distinct target 437 175
Total alignments 438 183
Table 1. Statistics on evaluation data. 
 
Note that although there are 438 alignments 
for ST-ZB, the number of unique ST articles are 
396, implying that the mapping is not one-to-one. 
5.2 Evaluation Metrics 
Evaluation is performed on two levels to reflect 
performance from two different perspectives. 
?Macro evaluation? is conducted to assess the 
correctness of the alignment candidates given 
their rank among all the alignment candidates. 
?Micro evaluation? concerns about the correctness 
of the aligned documents returned for a given 
source document. 
Macro evaluation: we present the perfor-
mance for macro evaluation using average preci-
sion. It is used to evaluate the performance of a 
ranked list and gives higher score for the list that 
returns more correct alignment in the top. 
Micro evaluation: for micro evaluation, we 
evaluate the F-Score, calculated from recall and 
precision, based on the number of correct align-
ments for the top of alignment candidates for 
each source document. 
5.3 Experiment and Result 
First we implement the method of Tao and Zhai 
(2005) as the baseline. Basically, this method 
does not depend on any linguistic resources and 
calculates the similarity between two documents 
purely by comparing all possible pairs of words. 
In addition to this, we also implement Muntea-
nu?s (2006) method which uses Okapi scoring 
function from the Lemur Toolkit (Ogilvie and 
848
Callan, 2001) to obtain the similarity score. This 
approach relies heavily on bilingual dictionaries. 
To assess performances more fairly, the result 
from baseline method of Tao and Zhai are com-
pared against the results of the following list of 
incremental approaches: the baseline (A); the 
baseline using term instead of word (B); replac-
ing ???, ?? by ???, ?? for ??? feature, with and 
without bilingual dictionaries in (C) and (D) re-
spectively; and including ???  and ???  for our 
final model in (E). Our model is also compared 
our model with results from the implementation 
of Munteanu (2006) using Okapi (F), and the 
results from a combination of our model with 
Okapi (G). Table 2 and Table 3 show the expe-
rimental results for two language pairs English ? 
Chinese (ST-ZB) and English ? Malay (ST-BH), 
respectively. Each row displays the result of each 
experiment at a certain cut-off among the top 
returned alignments. The ?Top? columns reflect 
the cut-off threshold. 
The first three cases (A), (B) and (C), which 
do not rely on linguistic resources, suggest that 
our new features lead to better performance im-
provement over the baseline. It can be seen that 
the use of term and ??? significantly improves 
the performance. The improvement indicated by 
a sharp increase in all cases from (C) to (D) 
shows that dictionaries can indeed help ??? fea-
tures. 
Based on the result of (E), our final model 
significantly outperforms the model of Munteanu  
(F) in both macro and micro evaluation. It is 
noted that our features rely less heavily on dic-
tionaries as it only makes use of this resource to 
translate term words and title words of a docu-
ment while Munteanu (2006) needs to translate 
entire documents, exclude stopword, and relying 
on an IR system. It is also observed that the per-
formance of (G) shows that although the incor-
poration of Okapi score in our final model (E) 
improves the average precision performance of 
ST-ZB slightly, it does not appear to be helpful 
for our ST-BH data. However, Okapi does help 
in the F-Measure on both corpora. 
 
 
Pair? Strait?Times???Zao?Bao?
Level? Top? A? B? C? D? E? F? G?
A
ve
/P
re
ci
si
on
?
M
ac
ro
? 50? 0.042? 0.083? 0.08? 0.559? 0.430? 0.209? 0.508?
100? 0.042? 0.069? 0.083? 0.438? 0.426? 0.194? 0.479?
200? 0.025? 0.069? 0.110? 0.342? 0.396? 0.153? 0.439?
500? 0.025? 0.054? 0.110? 0.270? 0.351? 0.111? 0.376?
F?
M
ea
su
re
?
M
ic
ro
?
1? 0.005? 0.007? 0.009? 0.297? 0.315? 0.157? 0.333?
2? 0.006? 0.005? 0.013? 0.277? 0.286? 0.133? 0.308?
5? 0.005? 0.006? 0.009? 0.200? 0.190? 0.096? 0.206?
10? 0.005? 0.005? 0.007? 0.123? 0.119? 0.063? 0.126?
20? 0.006? 0.008? 0.007? 0.073? 0.074? 0.038? 0.076?
 
Table 2. Performance of Strait Times ? Zao Bao.  
 
Pair? Strait?Times???Berita?Harian?
Level? Top? A? B? C? D? E? F? G?
A
ve
/P
re
ci
si
on
?
M
ac
ro
? 50? 0.000? 0.000? 0.000? 0.514? 0.818? 0.000? 0.782?
100? 0.000? 0.000? 0.080? 0.484? 0.759? 0.052? 0.729?
200? 0.000? 0.008? 0.090? 0.443? 0.687? 0.073? 0.673?
500? 0.005? 0.008? 0.010? 0.383? 0.604? 0.078? 0.591?
F?
M
ea
su
re
?
M
ic
ro
?
1? 0.000? 0.000? 0.005? 0.399? 0.634? 0.119? 0.650?
2? 0.000? 0.004? 0.010? 0.340? 0.515? 0.128? 0.515?
5? 0.002? 0.005? 0.010? 0.205? 0.270? 0.105? 0.273?
10? 0.004? 0.014? 0.013? 0.130? 0.150? 0.076? 0.150?
20? 0.006? 0.017? 0.017? 0.074? 0.078? 0.043? 0.078?
 
Table 3. Performance of Strait Times ? Berita Harian. 
 
 
849
5.4 Discussion 
It can be seen from Table 2 and Table 3 that by 
exploiting the frequency distribution of terms 
using Discrete Fourier Transform instead of 
words on Pearson?s Correlation, performance is 
noticeably improved. Fig 5 shows the incremen-
tal improvement of our model for top-200 and 
top-2 alignments using macro and micro evalua-
tion respectively. The sharp increase can be seen 
in Fig 5 from point (C) onwards. 
 
Fig 5. Step-wise improvement at top-200 for macro 
and top-2 for micro evaluation. 
Fig 6 compares the performance of our system 
with Tao and Zhai (2005) and Munteanu (2006). 
It is shown that our systems outperform these 
two systems under the same experimental 
parameters. Moreover, even without the use of 
dictionaries, our system?s performance on ST-
BH data is much better than Munteanu?s (2006) 
on the same data. 
 
Fig 6. System comparison for ST-ZB and ST-BH at 
top-500 for macro and top-5 for micro evaluation. 
 
We find that dictionary usage contributes 
much more to performance improvement in ST-
BH compared to that in ST-ZB. We attribute this 
to the fact that the feature LIU already contri-
butes markedly to the increase in the perfor-
mance of ST-BH. As a result, it is harder to make 
further improvements even with the application 
of bilingual dictionaries. 
6 Conclusion and Future Work 
In this paper, we propose a feature based model 
for aligning documents from multilingual com-
parable corpora. Our feature set is selected based 
on the need for a method to be adaptable to new 
language-pairs without relying heavily on lin-
guistic resources, unsupervised learning strategy. 
Thus, in the proposed method we make use of 
simple bilingual dictionaries, which are rather 
inexpensive and easily obtained nowadays. We 
also explore diverse features, including Mono-
lingual Term Distribution (??? ), Title-and-
Content (???), and Linguistic Independent Unit 
(???) and measure their contributions in an in-
cremental way. The experiment results show that 
our system can retrieve similar documents from 
two comparable corpora much better than using 
an information retrieval, such as that used by 
Munteanu (2006). It also performs better than a 
word correlation-based method such as Tao?s 
(2005). 
Besides document alignment as an end, there 
are many tasks that can directly benefit from 
comparable corpora with documents that are 
well-aligned. These include sentence alignment, 
term alignment, and machine translation, espe-
cially statistical machine translation. In the future, 
we aim to extract other valuable information 
from comparable corpora which benefits from 
comparable documents. 
Acknowledgements 
We would like to thank the anonymous review-
ers for their many constructive suggestions for 
improving this paper. Our thanks also go to Ma-
hani Aljunied for her contributions to the linguis-
tic assessment in our work.  
References 
Percy Cheung and Pascale Fung. 2004. Sentence 
Alignment in Parallel, Comparable, and Quasi-
comparable Corpora. In Proceedings of 4th Inter-
national Conference on Language Resources and 
Evaluation (LREC). Lisbon, Portugal. 
Hal Daume III and Daniel Marcu. 2004. A Phrase-
Based HMM Approach to Document/Abstract 
Alignment. In Proceedings of Empirical Methods 
in Natural Language Processing (EMNLP). Spain. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
A B C D E
ST?? ZB?A/Prec ST?? ZB?F?Score
ST?? BH?A/Prec ST?? BH?F?Score
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
A/Prec F?Score A/Prec F?Score
ST?? ZB ST?? BH
Tao?and?Zhai?(2005) Our?System?w/o?Dict
Our?System?w?Dict Munteanu?(2006)
850
Min-Yen Kan. 2007. SlideSeer: A Digital Library of 
Aligned Document and Presentation Pairs. In Pro-
ceedings of the Joint Conference on Digital Libra-
ries (JCDL). Vancouver, Canada. 
Soto Montalvo, Raquel Martinez, Arantza Casillas, 
and Victor Fresno. 2006. Multilingual Document 
Clustering: a Heuristic Approach Based on Cog-
nate Named Entities. In Proceedings of the 21st In-
ternational Conference on Computational 
Linguistics and the 44th Annual Meeting of the 
ACL. 
Stephen E. Robertson, Steve Walker, Susan Jones, 
Micheline Hancock-Beaulieu, and Mike Gatford. 
1994. Okapi at TREC-3. In Proceedings of the 
Third Text REtrieval Conference (TREC 1994). 
Gaithersburg, USA. 
Dragos Stefan Munteanu. 2006. Exploiting Compara-
ble Corpora. PhD Thesis. Information Sciences In-
stitute, University of Southern California. USA. 
Ogilvie, P., and Callan, J. 2001. Experiments using 
the Lemur toolkit. In Proceedings of the 10th Text 
REtrieval Conference (TREC). 
Alexandre Patry and Philippe Langlais. 2005. Auto-
matic Identification of Parallel Documents with 
light or without Linguistics Resources. In Proceed-
ings of 18th Annual Conference on Artificial Intel-
ligent. 
Bruno Pouliquen, Ralf Steinberger, Camelia Ignat, 
Emilia Kasper, and Irina Temnikova. 2004. Multi-
lingual and Cross-lingual news topic tracking. In 
Proceedings of the 20th International Conference 
on Computational Linguistics (COLING). 
Ralf Steinberger, Bruno Pouliquen, and Johan Hag-
man. 2002. Cross-lingual Document Similarity 
Calculation Using the Multilingual Thesaurus 
EUROVOC. Computational Linguistics and Intel-
ligent Text Processing. 
Tao Tao and ChengXiang Zhai. 2005. Mining Com-
parable Bilingual Text Corpora for Cross-
Language Information Integration. In Proceedings 
of the 2005 ACM SIGKDD International Confe-
rence on Knowledge Discovery and Data Mining. 
Thuy Vu, Ai Ti Aw and Min Zhang. 2008. Term ex-
traction through unithood and termhood unification. 
In Proceedings of the 3rd International Joint Con-
ference on Natural Language Processing 
(IJCNLP-08). Hyderabad, India. 
ChengXiang Zhai and John Lafferty. 2001. A study of 
smoothing methods for language models applied to 
Ad Hoc information retrieval. In Proceedings of 
the 24th annual international ACM SIGIR confe-
rence on Research and development in information 
retrieval. Louisiana, United States. 
R. Agrawal, C. Faloutsos, and A. Swami. 1993. Effi-
cient similarity search in sequence databases. In 
Proceedings of the 4th International Conference on 
Foundations of Data Organization and Algorithms. 
Chicago, United States. 
Magnus Lie Hetland. 2004. A survey of recent me-
thods for efficient retrieval of similar time se-
quences. In Data Mining in Time Series Databases. 
World Scientific. 
Alexandre Klementiev and Dan Roth. 2006. Weakly 
Supervised Named Entity Transliteration and Dis-
covery from Multilingual Comparable Corpora. In 
Proceedings of the 21st International Conference 
on Computational Linguistics and the 44th Annual 
Meeting of the ACL. 
851
Term Extraction Through Unithood And Termhood Unification 
Thuy VU, Ai Ti AW, Min ZHANG  
Department of Language Technology, Institute for Infocomm Research 
21 Heng Mui Keng Terrace, Singapore 119613 
{tvu, aaiti, mzhang}@i2r.a-star.edu.sg 
Abstract 
Term Extraction (TE) is an important com-
ponent of many NLP applications. In gen-
eral, terms are extracted for a given text 
collection based on global context and fre-
quency analysis on words/phrases associa-
tion. These extracted terms represent effec-
tively the text content of the collection for 
knowledge elicitation tasks. However, they 
fail to dictate the local contextual informa-
tion for each document effectively. In this 
paper, we refine the state-of-the-art C/NC-
Value term weighting method by consider-
ing both termhood and unithood measures, 
and use the former extracted terms to direct 
the local term extraction for each document. 
We performed the experiments on Straits 
Times year 2006 corpus and evaluated our 
performance using Wikipedia termbank.  
The experiments showed that our model 
outperforms C/NC-Value method for global 
term extraction by 24.4% based on term 
ranking. The precision for local term ex-
traction improves by 12% when compared 
to pure linguistic based extraction method. 
1 Introduction 
Terminology Extraction (TE) is a subtask of in-
formation extraction. The goal of TE is to auto-
matically extract relevant terms from a given cor-
pus. These extracted terms are used in a variety of 
NLP tasks such as information retrieval, text min-
ing, document summarization etc. In our applica-
tion scenario, we are interested in terms whose 
constituent words have strong collocation relations 
and can be translated to another language in stable 
single word or multi-word translation equivalents. 
Thus, we define ?term? as a word/phrase that car-
ries a special meaning. 
A general TE consists of two steps. The first 
step makes use of various degrees of linguistic fil-
tering (e.g., part-of-speech tagging, phrase chunk-
ing etc.), through which candidates of various lin-
guistic patterns are identified (e.g. noun-noun, ad-
jective-noun-noun combinations etc.). The second 
step involves the use of frequency- or statistical-
based evidence measures to compute weights indi-
cating to what degree a candidate qualifies as a 
terminological unit. There are many methods in 
literature trying to improve this second step. Some 
of them borrowed the metrics from Information 
Retrieval to evaluate how important a term is 
within a document or a corpus. Those metrics are 
Term Frequency/Inverse Document Frequency 
(TF/IDF), Mutual Information, T-Score, Cosine, 
and Information Gain. There are also other works 
(Nakagawa and Mori, 2002; Frantzi and 
Ananiadou, 1998) that introduced better method to 
weigh the term candidates. 
Currently, the C/NC method (Frantzi and 
Ananiadou, 1998) is widely considered as the 
state-of-the-art model for TE. Although this 
method was first applied on English, it also per-
formed well on other languages such as Japanese 
(Hideki Mima and Sophia Ananiadou, 2001), Slo-
vene (?pela Vintar, 2004), and other domains such 
as medical corpus (Frantzi and Ananiadou, 1998), 
and computer science (E. Milios et al 2003). 
In terminology research, a term is evaluated us-
ing two types of feature: termhood1 and unithood 
                                                 
1 Termhood refers to a degree of linguistic unit. It considers a 
term as a linguistic unit representative for the document con-
tent. 
631
2(Kyo Kageura, 1996). In C/NC method, the fea-
tures used to compute the term weight are based on 
termhood only. In this paper, we introduce a uni-
thood feature, T-Score, to the C/NC method. Ex-
periment results show that by incorporating T-
Score into C/NC to derive a new weight, 
NTCValue , it gives a better ranking of the global 
terms and outperforms C/NC method by 24.4%. 
On the other hand, C/NC method extracts term 
candidates using linguistic patterns and derives 
their weights based on distribution of terms over 
all documents. The extracted terms thus represent 
global content of the corpus, and do not represent 
well the contextual information for each individual 
document. So, we propose a method to enrich the 
local terms through a Term Re-Extraction Model 
(TREM). Experiment results show that the preci-
sion for local TE has been improved significantly, 
by 12% when compared to pure linguistic based 
extraction method. 
In the following sections, we introduce the state-
of-the-art method, the C/NC Value method. We 
then introduce our proposed methods, the 
NTCValue method on section 3, the Term Re-
Extraction Model (TREM) on section 4 followed 
by the experiment results and conclusion. 
2 The C/NC value Method 
C/NC method uses a combination of linguistic and 
statistical information to evaluate the weight of a 
term. This method has two steps: candidate 
extraction and term weighting by C/NC value. 
2.1 Term Candidate Extraction 
This method uses 3 linguistic patterns to extract the 
term candidates: 
? (Noun+Noun);  
? (Adj|Noun)+Noun;  
? (Adj|Noun)+|((Adj|Noun)*(NounPrep)?)(Adj|
Noun)*)Noun. 
The term candidates are passed to the second step. 
2.2 Term Weighting 
2.2.1 CValue 
CValue  is calculated based on the frequency of 
term and its subterms. 
                                                 
2 Unithood refers to a degree of strength or stability of syn-
tagmatic combinations or collocations. 
( ) ( ) ( ) ( )???
?
???
? ??= ?
? aTba
bf
TP
afaaCValue
1
log2  
Where, ( )af  is the frequency of term a  with a  
words, aT  is the set of extracted candidate terms that 
contain a  and ( )aTP  is the total number of longer 
candidate terms that contain a . The for-
mula ( ) ( )?? aTba bfTP
1
 will have value 0 when aT is 
empty. 
2.2.2 NC Value 
NCValue combines the context information of 
a term together with the CValue. The weight of a 
context word3 b is defined by the number of terms ( )bt in which it appears over the total number of 
terms considered, n . aC  is the set of distinct con-
text words and ( )bfa is the frequency of b  as con-
text word of a . 
( ) ( )
n
bt
bweight =  
( ) ( )?
?
?=
aCb
a bweightbfNValue  
( ) ( ) ( )aNValueaCValueaNCValue ?+?= 2.08.0
 
From the above formula, we find that 
NCValue is mainly weighted by CValue .It treats 
the term candidate as a linguistic unit and evaluates 
its weight based on characteristics of the termhood, 
i.e. frequency and context word of the term candi-
date. The performance can be improved if feature 
measuring the adhesion of words within the term is 
incorporated.  
3 Enhancement on Global TE: the 
NTCValue 
Theoretically, the C/NC method can be improved 
by adding unithood feature to the term weighting 
formula. Based on the comparison of (Evert, S and 
B. Krenn, 2001), we explore T-Score, a 
competitive metric to evaluate the association 
between two words, as a unithood feature. 
                                                 
3 All experiments in this paper use the length of context is 3. 
632
3.1 T-Score 
The T-Score is used to measure the adhesion 
between two words in a corpus. It is defined by the 
following formula (Manning and Schuetze, 1999): 
( ) ( ) ( ) ( )( )
N
wwP
wPwPwwP
wwTS
ji
jiji
ji ,
.,
,
?=  
Where, ( )ji wwP , is the probability of bi-gram 
jiww  in the corpus, ( )wP  is the probability of 
word w  in the corpus, and N  is the total number 
of words in the corpus. The adhesion is a type of 
unithood feature since it is used to evaluate the 
intrinsic strength between two words of a term. 
3.2 Incorporate T-Score within C/NC value 
As discussed in 2.2, the most influential feature in 
the C/NC method is the term frequency. Our idea 
here is to combine the frequency with T-Score, a 
unithood feature. Taking the example in Table 1, 
the candidates have similar rank in the output using 
C/NC termhood approach. 
 
massive tidal waves 
gigantic tidal waves 
killer tsunami tidal waves 
deadly tidal waves 
huge tidal waves 
giant tidal waves 
tsunamis tidal waves  
Table 1. Example of similar terms 4 
To give better ranking and differentiation, we 
introduce T-Score to measure the adhesion be-
tween the words within the term. We use the 
minimum T-Score of all bi-grams in term a , ( )aTSmin , as a weighted parameter for the term 
besides the term frequency. For a 
term nwwwa .... 21= , the ( )aTSmin  is defined as: ( ) ( ){ } ( )1...1,,minmin 1 ?== + niwwTSaTS ii  
Term ( )?TSmin
massive tidal waves 4.56 
gigantic tidal waves 2.44 
killer tsunami tidal waves 3.99 
deadly tidal waves 3.15 
huge tidal waves 2.20 
                                                 
4 The italic means a week adhesion. 
giant tidal waves 1.35 
tsunamis tidal waves  5.06 
Table 2. Term with Minimum T-Score value 
Table 2 shows the ( )aTSmin  of the different 
terms in table 1. Since ( )aTSmin can have a nega-
tive value, we only considered those terms with ( ) 0min >aTS  and combined it with the term fre-
quency. We redefine CValue to TCValue by re-
placing ( )af  using ( )aF , as follows: 
( ) ( ) ( )( ) ( )( ) ( )??
?
>+?
?=
0minifmin2ln
0minif
aTSaTSaf
aTSaf
aF
( ) ( ) ( ) ( )???
?
???
? ??= ?
? aTba
bF
TP
aFaaTCValue
1
log2  
The final weight, defined as NTCValue, is com-
puted using the same parameter as NCValue .  ( ) ( ) ( )aNValueaTCValueaNTCValue ?+?= 2.08.0
 
4 Enhancement on Local Terms: Term 
Re-Extraction Method (TREM) 
The extracted term candidates are ranked globally 
with best global terms promoted due to their dis-
tinguishing power. However, preliminary investi-
gation on using linguistic patterns for extracting 
global term candidates for identifying term candi-
dates of each document does not perform satisfac-
tory, as high rank global terms do not reconcile 
well with the local term candidates identified using 
the linguistic patterns. A re-extraction process is 
thus evolved to derive local terms of a document 
from global terms using the NTCValue of the 
global terms. 
4.1 Local Term Candidate Extraction 
A string (or term candidate) extracted based on 
linguistic pattern follows the maximum matching 
algorithm. As long as the longest string whose 
part-of-speech tag satisfies the linguistic pattern, it 
will be extracted. For this reason, some noises are 
extracted together with these candidates. Table 3 
shows some examples of noisy term candidates.  
Strait Times yesterday 
THE World Cup 
gross domestic product growth forecast 
senior vice-president of DBS Vickers security 
on-line 
Table 3. Examples of noisy candidates. 
633
Our intention here is to reduce the noise and also 
mine more good terms embedded within the noise 
by using the global terms. We favor recall over 
precision to get as many local terms as possible. 
The examples in table 3 show the problem in de-
tecting term candidate?s boundary using linguistic 
patterns. The ?Strait Times yesterday? is a bad 
term identified by linguistic patterns because all 
three words are tagged as ?noun?. The second one 
is caused by an error of the POS tagger. Because of 
capitalization, the word ?THE? is being tagged 
wrongly as a ?proper-noun? (NNP/NNPS), and not 
determiner (DT). Similarly, ?gross domestic prod-
uct growth forecast? and ?senior vice-president of 
DBS Vickers security on-line? are complex noun-
phrases that are not symbolized good terms in the 
document. The more expressive terms would be 
?gross domestic product?, ?DBS Vickers security?, 
etc. 
Our proposed algorithm utilizes the term weight 
from section 3.2 to do term re-extraction for each 
document through dynamic programming theory 
(Viterbi algorithm) to resolve the above problem.  
4.2 Proposed algorithm 
The algorithm for term re-extraction is outlined 
in Figure 1.  
Algorithm: Term re-extraction for a document 
Input: L ? global term list with NTCValue  
  T ? input for TREM nwww ...T 21=  
1: For 2=i  ? n   
2:  If ( ) L...T 1,1 ?= ii ww  
3:   ( ) ( )iNTCiMaxNTC ,1T,1 =  
4:  Else ( ) 0,1 =iMaxNTC  
5:  End If 
6:  For 1=j  ? 1?i  
7:   If ( ) LT ?= ++ ijij ww ...1,1  
8:    ( ) max,1 =iMaxNTC  
( ) ( ) ( ){ }iMaxNTCNTCjMaxNTC ij ,1;,1 ,1++ T  
9:   End If 
10:  End For 
11: End For 
Output: Updated term list for a document 
Figure 1. Term Re-Extraction Algorithm 
 
 
Where, ji,T  is the word chain formed by the 
words from i  to j  of the term nwww ...T 21= ; ( )iMaxNTC ,1  is the maximum NTCValue value 
from 1 to i  of the term nwww ...T 21= ; and ( )iNTC ,1T  is the NTCValue of ji,T . 
5 Experiments and Evaluations 
5.1 Term Bank Collection 
Term boundary is one of the main issues in termi-
nology research. In our experiments, we consider a 
term based on the resources from Wikipedia. In 
each Wikipedia article, the editor annotated the key 
terminologies through the use of hyperlinks. We 
extracted the key terms for each article based on 
this markup. The entire Wikipedia contains about 
1,910,974 English articles and 8,964,590 key terms. 
These terms are considered as Wikipedia term-
bank and we use it to evaluate our performance. 
An extracted term is considered correct if and only 
if it is in the term-bank. 
5.2 Corpus Collection 
To evaluate the model, we use the corpus collected 
from Straits Times in year 2006. We separate the 
data into 12 months as showed in Table 4.  
Month Total articles Total words 
1 3,134 1,844,419 
2 3,151 1,824,970 
3 3,622 2,098,459 
4 3,369 1,969,684 
5 3,395 1,957,962 
6 3,187 1,781,664 
7 3,253 1,818,606 
8 3,497 1,927,180 
9 3,463 1,853,902 
10 3,499 1,870,417 
11 3,493 1,845,254 
12 3,175 1,711,168 
Table 4. Evaluation data from Straits Times. 
5.3 NTCValue Evaluation 
We evaluate the performance of global ranked 
terms using average-precision. A higher average-
precision would mean that the list contains more 
good terms in higher rank. The average precision ( ).PAve  of a term-list { }LtttL ,...,, 21=  with 
634
cL as the list of all correct terms in L  ( )LLc ? , is 
calculated by the following formula: 
( ) ? ?
?? ??
??
???
? ??
???
??=
Lk ki
ik
c
r
k
r
L
LP
1 1
11
Ave  
Where: 
??
?
?
?=
ci
ci
i Lt
Lt
r
0
1
 
Table 5 shows the comparison result of the ori-
gin NCValue  and our NTCValue  on the ranking 
of global terms. The experiment is conducted on 
the data described in section 5.2. We evaluate the 
performance based on 8 different levels of top 
ranking terms. 
Each cell in Table 5 contains a couple of ( ).PAve  for NCValue  and NTCValue  
( )NTCValueNCValue / respectively. The 
( ).PAve  decreases gradually when we relax the 
threshold for the evaluation . The result shows that 
the term ranking using NTCValue  improves the 
performance significantly. 
 
Number of top high term 01 02 03 04 05 06 
50 0.70/0.77 0.57/0.81 0.52/0.80 0.51/0.78 0.55/0.80 0.67/0.69
100 0.60/0.73 0.59/0.77 0.51/0.79 0.50/0.74 0.57/0.78 0.64/0.70
200 0.55/0.70 0.56/0.75 0.53/0.78 0.49/0.72 0.55/0.77 0.62/0.69
500 0.53/0.67 0.54/0.70 0.54/0.71 0.48/0.68 0.53/0.71 0.57/0.65
1000 0.51/0.62 0.52/0.66 0.52/0.66 0.47/0.64 0.51/0.65 0.53/0.60
5000 0.48/0.58 0.49/0.61 0.49/0.62 0.45/0.60 0.49/0.61 0.49/0.56
10000 0.43/0.52 0.44/0.55 0.44/0.56 0.42/0.54 0.44/0.56 0.44/0.50
All_terms 0.38/0.47 0.39/0.49 0.40/0.50 0.37/0.48 0.39/0.49 0.38/0.45
Number of top high term 07 08 09 10 11 12 
50 0.67/0.67 0.65/0.70 0.49/0.65 0.62/0.71 0.65/0.76 0.63/0.86
100 0.64/0.71 0.62/0.74 0.47/0.66 0.59/0.74 0.59/0.76 0.61/0.82
200 0.65/0.72 0.59/0.75 0.48/0.68 0.55/0.72 0.56/0.73 0.58/0.77
500 0.62/0.71 0.56/0.70 0.50/0.66 0.52/0.66 0.54/0.67 0.55/0.69
1000 0.59/0.66 0.54/0.66 0.50/0.64 0.49/0.64 0.51/0.64 0.54/0.65
5000 0.54/0.60 0.51/0.62 0.49/0.60 0.46/0.61 0.48/0.60 0.51/0.61
10000 0.46/0.53 0.46/0.55 0.45/0.55 0.43/0.56 0.44/0.55 0.46/0.55
All_terms 0.40/0.47 0.40/0.50 0.40/0.50 0.38/0.49 0.38/0.48 0.39/0.48
Table 5. Performance of NTCValue with C/NC value. 
 
Method Without TREM TREM+NC TREM+NTC 
Month Precision No. terms Precision No. terms Precision No. terms 
1  44.98  23915  50.81  34910  50.85  34998  
2  44.74  23772  50.22  34527  50.33  34657  
3  44.39  28772  49.58  41691  49.59  41778  
4  42.89  25857  48.78  38564  48.91  38589  
5  44.67  25787  50.44  38252  50.38  38347  
6  46.58  23293  51.80  33574  51.91  33651  
7  46.35  23638  51.31  33990  51.35  34041  
8  46.50  25869  51.91  37896  51.96  37973  
9  46.16  25276  51.34  36632  51.39  36731  
10  45.79  24987  50.99  36082  51.05  36179  
11  45.28  24661  50.43  35894  50.54  35906  
12  45.67  22745  50.73  32594  50.73  32673  
Table 6. Term Re-Extraction evaluation result. 
635
5.4 TREM Evaluation 
We evaluate TREM based on the term bank de-
scribed in section 5.1. Let iM  be the number of 
extracted terms for article i , iN  be the number of 
extracted terms in the term bank for article i , and 
n is the total articles in the test corpus. The accu-
racy is evaluated by the following formula: 
?
=
=
n
i i
i
M
N
P
1
 
Table 6 shows the result of TREM. From the re-
sults, we can find that the accuracy has improved 
significantly after the re-extraction process. On top 
of that, the results of TREM based on NTCValue  
is also slightly better than using NCValue . More-
over, the number of correct terms extracted by 
TREM using NTCValue is higher than us-
ing NCValue . 
6 Conclusions and Future Works 
We introduce a term re-extraction process (TREM) 
using Viterbi algorithm to augment the local TE 
for each document in a corpus. The results in Table 
6 show that TREM improves the precision of terms 
in local documents and also increases the number 
of correct terms extracted. We also propose a 
method to combine the C/NC value with T-Score. 
The results of our method, NTCValue , show that 
the motivation to combine the termhood features 
used in C/NC method, with T-Score, a unithood 
feature, improves the term ranking result. Results 
on Table 6 also show that NTCValue gives a bet-
ter result than the origin NCValue for TREM. 
In Table 5, the average scores for ?All Term? 
are 38.8% and 48.3% for NCValue  and 
NTCValue respectively. Therefore, NTCValue 
method improves global TE by 24.4% when com-
pared to the origin NCValue method. With the 
same calculation, we also conclude that TREM 
outperforms the linguistic pattern method by 12% 
(average scores are 50.7% and 45.3% for TREM 
and TREM-NTC respectively).  
In the future, we will focus on improving the 
performance of TREM by using more features, 
besides the weighting score. 
 
References 
C. Manning and H. Schuetze. 1999. Foundations of Sta-
tistical Natural Language Processing. MIT Press 
Cambridge, Massachusetts. 
E. Milios, Y. Zhang, B. He, L. Dong. 2003. Automatic 
Term Extraction and Document Similarity in Special 
Text Corpora. Proceedings of the 6th Conference of 
the Pacific Association for Computational Linguistics 
(PACLing'03), Halifax, Nova Scotia, Canada, pp. 
275-284. 
Evert, S. and B. Krenn. 2001. Methods for Qualitative 
Evaluation of Lexical Association Measures. Pro-
ceedings of the 39th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 369 ? 381. 
Hideki Mima, Sophia Ananiadou. 2001. An Application 
and Evaluation of the C/NC-Value Approach for the 
Automatic Term Recognition of Multi-Word Units in 
Japanese. International Journal on Terminology. 
Hiroshi Nakagawa, Tatsunori Mori. 2000. Automatic 
Term Recognition based on Statistics of Compound 
Nouns. Terminology, Vol.6, No.2, pp.195 ? 210. 
Hiroshi Nakagawa, Tatsunori Mori. 2002. A Simple but 
Powerful Automatic Term Extraction Method. 2nd 
International Workshop on Computational Terminol-
ogy, ACL. 
Katerine T. Frantzi, Sophia Ananiadou, and Junichi 
Tsujii. 1998. The C-Value/NC-Value Method of 
Automatic Recognition for Multi-word terms. Journal 
on Research and Advanced Technology for Digital 
Libraries. 
Kyo Kageura. 1996. Methods of Automatic Term Rec-
ognition - A Review. Terminology, 3(2): 259 ? 289, 
1996. 
?pela Vintar. 2004. Comparative Evaluation of C-value 
in the Treatment of Nested Terms. Memura 2004 ? 
Methodologies and Evaluation of Multiword Units in 
Real-World Applications. Proceedings of the Interna-
tional Conference on Language Resources and 
Evaluation 2004, pp. 54-57. 
636
Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 21?24,
Suntec, Singapore, 3 August 2009. c?2009 ACL and AFNLP
MARS: Multilingual Access and Retrieval System with Enhanced 
Query Translation and Document Retrieval 
 
 
Lianhau Lee, Aiti Aw, Thuy Vu, Sharifah Aljunied Mahani, Min Zhang, Haizhou Li 
Institute for Infocomm Research 
1 Fusionopolis Way, #21-01 Connexis, Singapore 138632 
{lhlee, aaiti, tvu, smaljunied, mzhang, hli} 
@i2r.a-star.edu.sg 
 
  
 
Abstract 
In this paper, we introduce a multilingual ac-
cess and retrieval system with enhanced query 
translation and multilingual document retrieval, 
by mining bilingual terminologies and aligned 
document directly from the set of comparable 
corpora which are to be searched upon by us-
ers. By extracting bilingual terminologies and 
aligning bilingual documents with similar con-
tent prior to the search process provide more 
accurate translated terms for the in-domain 
data and support multilingual retrieval even 
without the use of translation tool during re-
trieval time. This system includes a user-
friendly graphical user interface designed to 
provide navigation and retrieval of information 
in browse mode and search mode respectively.  
1 Introduction 
Query translation is an important step in the 
cross-language information retrieval (CLIR). 
Currently, most of the CLIR system relies on 
various kinds of dictionaries, for example Word-
Nets (Luca and Nurnberger, 2006; Ranieri et al, 
2004), in query translation. Although dictionaries 
can provide effective translation on common 
words or even phrases, they are always limited in 
the coverage. Hence, there is a need to expand 
the existing collections of bilingual terminologies 
through various means. 
Recently, there has been more and more re-
search work focus on bilingual terminology ex-
traction from comparable corpora. Some promis-
ing results have been reported making use of sta-
tistics, linguistics (Sadat et al, 2003), translitera-
tion (Udupa et al, 2008), date information (Tao 
and Zhai, 2005) and document alignment ap-
proach (Talvensaari et al, 2007). 
In this paper, we introduce our Multilingual 
Access and Retrieval System ? MARS which 
addresses the query translation issue by using in-
domain bilingual terminologies extracted directly 
from the comparable corpora which are to be 
accessed by users. And at the same time, bilin-
gual documents are paired up prior to the search 
process based on their content similarities to 
overcome the limitation of traditional keyword 
matching based on the translated terms. These 
would provide better retrieval experiences as not 
only more accurate in-domain translated term 
will be used to retrieve the documents but also 
provide a new perspective of multilingual infor-
mation retrieval to process the time-consuming 
multilingual document matching at the backend. 
The following sections of this paper will de-
scribe the system architecture and the proposed 
functionalities of the MARS system. 
2 MARS System 
The MARS system is designed to enhance query 
translation and document retrieval through min-
ing the underlying multilingual structures of 
comparable corpora via a pivot language. There 
are three reasons for using a pivot language. 
Firstly, it is appropriate to use a universal lan-
guage among potential users of different native 
languages. Secondly, it reduces the backend data 
processing cost by just considering the pair-wise 
relationship between the pivot language and any 
other languages. Lastly, the dictionary resources 
between the pivot language and all the other lan-
guages are more likely to be available than oth-
erwise. 
There are two main parts in this system, 
namely data processing and user interface. The 
data processing is an offline process to mine the 
underlying multilingual structure of the compa-
21
rable corpora to support retrieval. The structure 
of the comparable corpora is presented visually 
in the user interface under browse mode and 
search mode to facilitate navigation and retrieval 
of information respectively. 
3 Data Processing  
For demo purpose, three different language 
newspapers from the year 1995 to 2006 pub-
lished by Singapore Press Holding (SPH), 
namely Strait Times1 (English), ZaoBao2 (Chi-
nese) and Berita Harian3  (Malay), are used as 
comparable corpora. In these particular corpora, 
English is chosen as the pivot language and noun 
terms are chosen as the basic semantic unit as 
they represent a huge amount of significant in-
formation. Our strategy is to organize and ma-
nipulate the corpora in three levels of abstraction 
? clusters, documents and terms. And our key 
task over here is to find the underlying associa-
tions of documents or terminologies in each level 
across different languages. 
First, monolingual documents are grouped into 
clusters by k-means algorithm using simple word 
vectors. Then, monolingual noun terms are ex-
tracted from each cluster using linguistic patterns 
and filtered by occurrence statistics globally 
(within cluster) and locally (within document), so 
that they are good representatives for cluster as a 
whole as well as individual documents (Vu et al, 
2008). The extracted terms are then used in 
document clustering in a new cycle and the 
whole process is repeated until the result con-
verges. 
Next, cluster alignment is carried out between 
the pivot language (English) and the other lan-
guages (Chinese, Malay). Clusters can be con-
ceptualized as the collection of documents with 
the same themes (e.g. finance, politics or sports) 
and their alignments as the correspondents in the 
other languages. Since there may be overlaps 
among themes, e.g. finance and economy, each 
cluster is allowed to align to more than one clus-
ter with varying degree of alignment score. 
After that, document alignment is carried out 
between aligned cluster pairs (Vu et al, 2009). 
Note that the corpora are comparable, thus the 
aligned document pairs are inherently compara-
                                                 
1 http://www.straitstimes.com/ an English news agency in 
Singapore. Source ? Singapore Press Holdings Ltd. 
2 http://www.zaobao.com/ a Chinese news agency in 
Singapore. Source ? Singapore Press Holdings Ltd. 
3 http://cyberita.asia1.com.sg/ a Malay news agency in 
Singapore. Source ? Singapore Press Holdings Ltd. 
ble, i.e. they are similar in contents but not iden-
tical as translation pairs. Also as important to 
note that, document alignment harvested over 
here is independent of user query. In other 
words, document alignment is not simply deter-
mined by mere occurrence of certain keyword 
and its absence does not hinder documents to be 
aligned. Hence mining of document alignment 
beforehand improves document retrieval after-
ward. 
Finally, term alignment is likewise generated 
between aligned document pairs. The aligned 
terms are expected to be in-domain translation 
pairs since they are both derived from documents 
of similar contents, and thus they have similar 
contexts. By making use of the results provided 
by each other, document alignment and term 
alignment can be improved over iterations. 
All the mentioned processes are done offline 
and the results are stored in a relational database 
which will handle online queries generated in the 
user interface later on. 
4 User Interface  
As mentioned, there are two modes provided in 
the user interface to facilitate navigation and re-
trieval of information, namely browse mode and 
search mode. Both modes can be switched sim-
ply by clicking on the respective tabs in the user 
interface. In the following, the functionalities of 
the browse mode and the search mode will be 
explained in details. 
4.1 Browse Mode 
Browse mode provides a means to navigate 
through the complex structures underneath an 
overwhelming data with an easily-understood, 
user-friendly graphical interface. In the figure 1, 
the graph in the browse mode gives an overall 
picture of the distribution of documents in vari-
ous clusters and among the different language 
collections. The outer circles represent the lan-
guage repositories and the inner circles represent 
the clusters. The sizes of the clusters are depend-
ing on the number of contained documents and 
the color represents the dominant theme. The 
labels of the highlighted clusters, characterized 
by a set of five distinguished words, are shown in 
the tooltips next to them. By clicking on a clus-
ter, the links depicting the cluster alignments will 
show up. The links to the clusters in the other 
languages are all propagated through the pivot 
language. 
22
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1 Browse mode in the MARS System 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2 Search mode in the MARS System 
23
The right hand side of the browse panel pro-
vides the detail information about the selected 
cluster using three sub-panels, i.e. top, middle 
and bottom. The top panel displays a list of ex-
tracted terms from the selected cluster. User may 
narrow down the list of interested terms by using 
the search-text column on top. By clicking on a 
term in the list, its translations in other lan-
guages, if any, will be displayed in the middle 
sub-panel and the document containing the term 
will be listed in the bottom sub-panel. The 
?Search? buttons next to the term translations 
provide a short-cut to jump to the search mode 
with the corresponding term translation being cut 
and pasted over. Last but not least, user may 
simply click on any document listed in the bot-
tom sub-panel to read the content of the docu-
ment and its aligned documents in a pop-up win-
dow. 
4.2 Search Mode 
Search mode provides a means for comprehen-
sive information retrieval. Refer to the figure 2, 
user may enter query in any of the selected lan-
guages to search for documents in all languages. 
The main difference is that query translation is 
done via bilingual terms extracted via the term 
alignment technology discussed earlier. For each 
retrieved document, documents with similar con-
tent in the other languages are also provided to 
supplement the searched results. This enables 
documents which are potentially relevant to the 
users be retrieved as some of these retrieved 
documents may not contain the translated terms 
at all. 
On top of the query translation, other informa-
tion such as related terms and similar terms to 
the query are shown at the tab panel on the right. 
Related terms are terms that correlate statistically 
with the query term and they are arranged by 
cluster, separated by dotted line in the list. Simi-
lar terms are longer terms that contains the query 
term in itself. Both the related terms and the 
similar terms provide user additional hints and 
guides to improve further queries. 
5 Conclusion  
The MARS system is developed to enable user to 
better navigate and search information from mul-
tilingual comparable corpora in a user-friendly 
graphical user interface. Query translation and 
document retrieval is enhanced by utilizing the 
in-domain bilingual terminologies and document 
alignment acquired from the comparable corpora 
itself, without limited by dictionaries and key-
word matching. 
Currently, the system only support simple 
query. Future work will improve on this to allow 
more general query. 
References  
Ernesto William De Luca, and Andreas Nurnberger. 
2006. A Word Sense-Oriented User Interface 
for Interactive Multilingual Text Retrieval, In 
Proceedings of the Workshop Information Re-
trieval, Hildesheim.  
M. Ranieri, E. Pianta, and L. Bentivogli. 2004. 
Browsing Multilingual Information with the 
MultiSemCor Web Interface, In Proceedings of 
the LREC-2004 Workshop ?The amazing utility of 
parallel and comparable corpora?, Lisban, Portu-
gal. 
Fatiha Sadat, Masatoshi Yoshikawa, Shunsuke Ue-
mura. 2003. Learning bilingual translations 
from comparable corpora to cross-language 
information retrieval: hybrid statistics-based 
and linguistics-based approach, In Proceedings 
of the 6th international workshop on Information 
Retrieval with Asian Languages, vol. 1: pp. 57-64. 
 Raghavendra Udupa, K. Saravanan, A. Kumaran, 
Jagadeesh Jagarlamudi. 2008. Mining named en-
tity transliteration equivalents from compara-
ble corpora. In Proceedings of the 17th ACM con-
ference on Information and knowledge manage-
ment. 
Tao Tao, and ChengXiang Zhai. 2005. Mining com-
parable bilingual text corpora for cross-
language information integration. In Proceed-
ings of the 11th ACM SIGKDD international con-
ference on Knowledge discovery in data mining. 
Tuomas Talvensaari, Jorma Laurikkala, Kalervo Jar-
velin, Martti Juhola, Heikki Keskustalo. 2007. 
Creating and exploiting a comparable corpus 
in cross-language information retrieval. ACM 
Transactions on Information System (TOIS), vol. 
25(1):  Article No 4. 
Thuy Vu, Aiti Aw, Min Zhang. 2008. Term extrac-
tion through unithood and termhood unifica-
tion. In Proceedings of the 3rd International Joint 
Conference on Natural Language Processing 
(IJCNLP-08), Hyderabad, India. 
Thuy Vu, Aiti Aw, Min Zhang. 2009. Feature-based 
Method for Document Alignment in Compara-
ble News Corpora. In Proceedings of the 12th 
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics (EACL-09), 
Athens, Greece. 
24
