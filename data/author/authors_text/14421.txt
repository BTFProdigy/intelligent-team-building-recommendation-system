A Study of Chinese Lexical Analysis Based on Discriminative Models 
Guang-Lu Sun  Cheng-Jie Sun  Ke Sun and Xiao-Long Wang 
Intelligent Technology & Natural Language Processing Laboratory, School of Computer 
Science and Technology, Harbin Institute of Technology, 150001, Harbin, China 
{glsun, cjsun, ksun, wangxl}@insun.hit.edu.cn 
 
Abstract 
This paper briefly describes our system in 
The Fourth SIGHAN Bakeoff. 
Discriminative models including maximum 
entropy model and conditional random 
fields are utilized in Chinese word 
segmentation and named entity recognition 
with different tag sets and features. 
Transformation-based learning model is 
used in part-of-speech tagging. Evaluation 
shows that our system achieves the 
F-scores: 92.64% and 92.73% in NCC 
Word Segmentation close and open tests, 
89.11% in MSRA name entity recognition 
open test, 91.13% and 91.97% in PKU 
part-of-speech tagging close and open tests. 
All the results get medium performances 
on the bakeoff tracks. 
1 Introduction 
Lexical analysis is the basic step in natural 
language processing. It is prerequisite to many 
further applications, such as question answer 
system, information retrieval and machine 
translation. Chinese lexical analysis chiefly 
consists of word segmentation (WS), name entity 
recognition (NER) and part-of-speech (POS) 
tagging. Because Chinese does not have explicit 
word delimiters to mark word boundaries like 
English, WS is essential process for Chinese. POS 
tagging and NER are just like those of English.  
Our system participated in The Fourth SIGHAN 
Bakeoff which held in 2007. Different approaches 
are applied to solve all the three tasks which are 
integrated into a unified system (ITNLP-IsLex). 
For WS task, conditional random fields (CRF) are 
used. For NER, maximum entropy model (MEM) 
is applied. And transformation-based learning 
(TBL) algorithm is utilized to solve POS tagging 
problem. The reasons using different models are 
listed in the rest sections of this paper. We give a 
brief introduction to our system sequentially. 
Section 2 describes WS. Section 3 and section 4 
introduce NER and POS tagging respectively. We 
give some experimental results in section 5. Finally 
we draw some conclusions. 
2 Chinese word segmentation 
For WS task, NCC corpus is chosen both in close 
test and open test.  
2.1 Conditional random fields 
Conditional random fields are undirected graphical 
models defined by Lafferty (2001). There are two 
advantages of CRF. One is their great flexibility to 
incorporate various types of arbitrary, 
non-independent features of the input, the other is 
their ability to overcome the label bias problem.  
Given the observation sequence X, on the basis 
of CRF, the conditional probability of the state 
sequence Y is: 
( ) (k k i-1 i
k
1
p Y X = exp l f y , y ,X,i
Z(X)
)? ?? ?? ??      (1)
(k k i-1 i
y Y k
)Z(X)= exp l f y , y ,X,i
?
? ?? ?? ?? ?          (2) 
Z(x) is the normalization factor. ( )1, , ,k i if y y X i?  
is the universal definition of features in CRF. 
2.2 Word segmentation based on CRF 
Inspired by Zhao (2006), the Chinese WS task is 
considered as a sequential labeling problem, i.e., 
assigning a label to each character in a sentence 
given its contexts. CRF model is adopted to do 
labeling. 
6 tags are utilized in this work: B, B1, B2, I, E, S. 
The meaning of each tag is listed in Table 1. The 
147
Sixth SIGHAN Workshop on Chinese Language Processing
raw training file format from NCC can be easily to 
convert to this 6 tags format. 
? ? ? ? ? ?An example: /S /B /B1 /B2 /I /I 
? ? ? ? ? ? ? ? ?/I /I /I /E /B /E /B /E /S.  
 
Table 1 Tags of character-based labeling 
Tag Meaning 
B The 1st character of a multi-character word
B1 The 2nd character of a multi-character word 
B2 The 3rd character of a multi-character word 
I Other than B, B1, B2 and last character in a multi-character word 
E The last character of a multi-character word 
S Single character word 
 
The contexts window size for each character is 5: 
C-2, C-1, C0, C1, and C2. There are 10 feature 
templates used to generate features for CRF model 
including uni-gram, bi-gram and tri-gram: C-2, C-1, 
C0, C1, C2, C-1C0, C0C1, C-2C-1C0, C-1C0C1, and 
C0C1C2. 
For the parameters in CRF model, we only do 
work to choose cut-off value for features. Our 
experiments show that the best performance can be 
achieved when cut-off value is set to 2. 
Maximum likelihood estimation and L-BFGS 
algorithm is used to estimate the weight of 
parameters in the training module. Baum-Welch 
algorithm is used to search the best sequence of 
test data. 
For close test, we only used CRF to do 
segmentation, no more post-processing, such as 
time and date finding, was done. So the 
performance could be further improved. 
For open test, we just use our NER system to tag 
the output of our close segmentation result, no more 
other resources were involved. 
3 Chinese name entity recognition 
For NER task, MSRA is chosen in open test. 
Chinese name dictionary, foreign name dictionary, 
Chinese place dictionary and organization 
dictionary are used in the model. 
3.1 Maximum entropy model 
Maximum entropy model is an exponential 
model that offers the flexibility of integrating 
multiple sources of knowledge into a model 
(Berger, 1996). It focuses on the modeling of 
tagging sequence, replacing the modeling of 
observation sequence. 
Given the observations sequence X, on the basis 
of MEM, the conditional probability of the state 
sequence Y is: 
1
( | ) exp ( , )
( ) j jj
p Y X f Y X
Z X
?? ?= ??? ?
? ??         (3) 
( ) exp ( , )j j
Y j
Z X f?? ?= ??? ?
? ? Y X ??              (4) 
 
Table 2 Feature templates of NER 
Feature 
template Description 
Ci 
The word tokens in the 
window 
i =-2, -1, 0, 1, 2 
Ti 
The NE tags 
i = -1  
CiCi-1 
The bigram of Ci 
i = -1, 1 
Pi 
The POS tags of word 
tokens 
i = -1, 0, 1 
P-1P1 
The combination of POS 
tags 
T-1C0 
The previous tag and the 
current word token 
B Ci is Chinese family name 
C Ci is part of Chinese first name 
W Ci is Chinese whole name 
F Ci is foreign name 
S Ci is Chinese first name 
W(Ci) 
O other 
W(Ci-1)W(Ci) 
The bigram of W(Ci) 
i = -1, 1 
IsInOrgDict(C0)
The current word token is in 
organization dictionary 
IsInPlaceDict(C0)
The current word token is in 
place dictionary 
148
Sixth SIGHAN Workshop on Chinese Language Processing
Being Similar to the definition of CRF, Z(x) is 
the normalization factor. ( ),jf Y X is the universal 
definition of features. 
3.2 Name entity recognition based on MEM 
Firstly, we use a segmentation tool to split both 
training and test corpus into word-token-based 
texts. Characters that are not in the dictionary are 
scattered in the texts. NE tags using in the model 
follow the tags in training corpus. Other word 
tokens that do not belong to NE are tagged as O. 
Based on the segmented text, the context window 
is also set as 5. Inspired by Zhang?s (2006) work, 
there are 10 types of feature templates for 
generating features for NER model in Table 2. 
When training our ME Model, the best 
performance can be achieved when cut-off value is 
set to 1. 
Maximum likelihood estimation and GIS 
algorithm is used to estimate the weight of 
parameters in the model. The iteration time is 500.  
4 Chinese part-of-speech tagging 
For POS tagging task, NCC corpus and PKU 
corpus are chosen both in the close test and open 
test. 
4.1 Transformation-based learning 
The formalism of Transformation-based learning is 
first introduced in 1992. It starts with the correctly 
tagged training corpus. A baseline heuristic for 
initial tag and a set of rule templates that specify the 
transformation rules match the context of a word. 
By transformating the error initial tags to the correct 
ones, a set of candidate rules are built to be the 
conditional pattern based on which the 
transformation is applied. Then, the candidate rule 
which has the best transformation effect is selected 
and stored as the first transformation rules in the 
TBL model. The training process is repeated until 
no more candidate rule has the positive effect. The 
selected rules are stored in the learned rule sequence 
in turn for the purpose of template correction 
learning. 
4.2 Part-of-speech tagging based on TBL 
POS tagging is a standard sequential labeling 
problem. CRF has some advantages to solve it. 
Because both corpora have relative many POS tags, 
our computational ability can not afford the CRF 
model in condition of these tags. TBL model is 
utilized to replace with CRF. 
We compute the max probability of current 
word?s POS tag in training corpus. The POS tag 
which has max occurrence probability for each 
word is used to tag its word token. By this method, 
we got the initial POS tag for each word.  
The rule templates which are formed from 
conjunctions of words match to particular 
combinations in the histories of the current 
position. 40 types of rule templates are built using 
the patterns. The cut-off value of the 
transformation rules is set to 3 (Sun, 2007). 
For open test, our NER system is used to tag the 
output of our POS tagging result. Parts of NE tags 
are corrected. 
5 Evaluation 
Following the measurement approach adopted in 
SIGHAN, we measure the performance of the three 
tasks in terms of the precision (P), recall (R), and 
F-score (F). 
5.1 Word segmentation results 
Table 3 Word segmentation results on NCC corpus 
NCC close test open test 
R .9268 .9268 
Cr .00133447 .00133458 
P .926 .928 
Cp .00134119 .00132534 
F .9264 .9273 
Roov .6094 .6265 
Poov .4948 .5032 
Foov .5462 .5581 
Riv .9426 .9417 
Piv .9527 .9546 
Fiv .9476 9481 
 
The WS results are listed on the Table 3. Some 
errors could be caused by the annotation 
differences between the training data and test data.  
For example, ???? (A Zhen) was considered as a 
whole word in training data, while ???? (A Lan)  
was annotated as two separate word ??? (A) and 
??? (Lan) in the test data. Some post-processing 
rules for English words, money unit and 
morphology can improve the performance further, 
Following are such errors in our results: ?vid eo?, 
149
Sixth SIGHAN Workshop on Chinese Language Processing
?? ?? (Japan yen), ?? ? ? ?? (not three 
not four). 
For open test, we hoped to use NER module to 
increase the OOV recall. But the NER module 
didn?t prompt the performance very much because 
it was trained by the MSRA NER data in Bakeoff3. 
The difference between two corpora may depress 
the NER modules effect. Also, the open test was 
done on the output of close test and all the errors 
were passed. 
5.2 Name entity recognition results 
The official results of our NER system on MSRA 
corpus for open track are showed in Table 4. As it 
shows, our system achieves a relatively high score 
on both PER and LOC task, but the performance of 
ORG is not so good, and the Avg1 performance is 
decreased by it. The reasons are: (1) The ORG 
sequences are often very long and our system is 
unable to deal with the long term, a MEMM or 
CRF model may perform better. (2) The resource 
for LOC and ORG are much smaller than that of 
PER. More sophisticated features such like 
?W(Ci)? may provide more useful information for 
the system. 
 
Table 4 NER results on MSRA corpus 
MSRA P R F 
PER .9498 .9549 .9524 
LOC .9129 .9194 .9161 
ORG .8408 .7469 .7911 
Avg1 .9035 .8791 .8911 
5.3 Part-of-speech tagging results 
We evaluate our POS tagging model on the PKU 
corpus for close and open track and NCC corpus 
for close track based on TBL. Table 5 is the 
official result of our system. In PKU open test, 
NER is used to recognize name entity of text, so its 
result is better than that of close test. The IV-R 
result is relative good, but the OOV-R is not so 
good, which drops the total performance. The 
reasons lie in: (1) TBL model is not good at 
tagging out of vocabulary words. CRF model may 
be a better selection if our computer can meet its 
huge memory requirements. (2) Our NER system 
is trained by MSRA corpus. It does not fit the PKU 
and NCC corpus. 
 
Table 5 POS results on PKU and NCC corpus 
Corpus Total-A IV-R OOV-R MT-R
PKU close 
test .9113 .9518 .2708 .8958
PKU open 
test .9197 .9512 .4222 .899 
NCC close 
test .9277 .9664 .2329 .9 
6 Conclusions 
Chinese lexical analysis system is built for the 
SIGHAN tracks which consists of Chinese word 
segmentation, name entity recognition and 
part-of-speech tagging. Conditional random fields, 
maximum entropy model and transformation-based 
learning model are utilized respectively. Our 
system achieves the medium results in all the three 
tasks. 
References 
A. Berger, S. A. Della Pietra and V. J. Della Pietra. A 
Maximum Entropy Approach to Natural Language 
Processing. Computational Linguistics, 1996. 22(1), 
pages 39-71. 
 
G. Sun, Y. Guan and X. Wang. A Maximum Entropy 
Chunking Model With N-fold Template Correction. 
Journal of Electronics, 2007. 24(5), pages 690-695. 
 
J. Lafferty, A. McCallum and F. Pereira. Conditional 
random fields: Probabilistic models for segmenting 
and labeling sequence data. In Proceedings of 
ICML-2001, Williams College, Massachusetts, USA. 
2001. pages 282-289. 
 
S. Zhang, Y. Qin, J. Wen, X. Wang. Word 
Segmentation and Named Entity Recognition for 
SIGHAN Bakeoff3. In Proceedings of the Fifth 
SIGHAN Workshop on Chinese Language Processing. 
Sydney, Australia. 2006. pages 158?161. 
 
H. Zhao, C. Huang, and M. Li. An improved Chinese 
word segmentation system with conditional random 
field. In Proceedings of the Fifth SIGHAN Workshop 
on Chinese Language Processing, Sydney, Australia. 
2006. pages 162?165.  
 
150
Sixth SIGHAN Workshop on Chinese Language Processing
 Selecting Optimal Feature Template Subset for CRFs 
Xingjun Xu1 and Guanglu Sun2 and Yi Guan1 and  
Xishuang Dong1 and Sheng Li1 
1: School of Computer Science and Technology,  
Harbin Institute of Technology,  
150001, Harbin, China 
2: School of Computer Science and Technology,  
Harbin University of Science and Technology 
150080, Harbin, China 
 xxjroom@163.com; guanglu.sun@gmail.com 
guanyi@hit.edu.cn; dongxishuang@gmail.com 
lisheng@hit.edu.cn 
 
 
 
Abstract 
Conditional Random Fields (CRFs) are the 
state-of-the-art models for sequential labe-
ling problems. A critical step is to select 
optimal feature template subset before em-
ploying CRFs, which is a tedious task. To 
improve the efficiency of this step, we pro-
pose a new method that adopts the maxi-
mum entropy (ME) model and maximum 
entropy Markov models (MEMMs) instead 
of CRFs considering the homology be-
tween ME, MEMMs, and CRFs. Moreover, 
empirical studies on the efficiency and ef-
fectiveness of the method are conducted in 
the field of Chinese text chunking, whose 
performance is ranked the first place in 
task two of CIPS-ParsEval-2009. 
1 Introduction 
Conditional Random Fields (CRFs) are the state-
of-the-art models for sequential labeling problem. 
In natural language processing, two aspects of 
CRFs have been investigated sufficiently: one is to 
apply it to new tasks, such as named entity recog-
nition (McCallum and Li, 2003; Li and McCallum, 
2003; Settles, 2004), part-of-speech tagging (Laf-
ferty et al, 2001), shallow parsing (Sha and Perei-
ra, 2003), and language modeling (Roark et al, 
2004); the other is to exploit new training methods 
for CRFs, such as improved iterative scaling (Laf-
ferty et al, 2001), L-BFGS (McCallum, 2003) and 
gradient tree boosting (Dietterich et al, 2004). 
One of the critical steps is to select optimal fea-
ture subset before employing CRFs. McCallum 
(2003) suggested an efficient method of feature 
induction by iteratively increasing conditional log-
likelihood for discrete features. However, since 
there are millions of features and feature selection 
is an NP problem, this is intractable when search-
ing optimal feature subset. Therefore, it is neces-
sary that selects feature at feature template level, 
which reduces input scale from millions of fea-
tures to tens or hundreds of candidate templates. 
In this paper, we propose a new method that 
adopts ME and MEMMs instead of CRFs to im-
prove the efficiency of selecting optimal feature 
template subset considering the homology between 
ME, MEMMs, and CRFs, which reduces the train-
ing time from hours to minutes without loss of 
performance. 
The rest of this paper is organized as follows. 
Section 2 presents an overview of previous work 
for feature template selection. We propose our op-
timal method for feature template selection in Sec-
tion 3. Section 4 presents our experiments and re-
sults. Finally, we end this paper with some con-
cluding remarks. 
2 Related Work 
Feature selection can be carried out from two le-
vels: feature level (feature selection, or FS), or 
feature template level (feature template selection, 
or FTS). FS has been sufficiently investigated and 
 share most concepts with FTS. For example, the 
target of FS is to select a subset from original fea-
ture set, whose optimality is measured by an eval-
uation criterion (Liu and Yu, 2005). Similarly, the 
target of FTS is to select a subset from original 
feature template set. To achieve optimal feature 
subset, two problems in original set must be elimi-
nated: irrelevance and redundancy (Yu and Liu, 
2004). The only difference between FS and FTS is 
that the number of elements in feature template set 
is much less than that in feature set. 
Liu and Yu (2005) classified FS models into 
three categories: the filter model, the wrapper 
model, and the hybrid model. The filter model 
(Hall 2000; Liu and Setiono, 1996; Yu and Liu, 
2004) relies on general characteristics of the data 
to evaluate and select feature subsets without any 
machine learning model. The wrapper model (Dy 
and Brodley, 2000; Kim et al, 2000; Kohavi and 
John, 1997) requires one predetermined machine 
learning model and uses its performance as the 
evaluation criterion. The hybrid model (Das, 2001) 
attempts to take advantage of the two models by 
exploiting their different evaluation criteria in dif-
ferent search stages. 
There are two reasons to employ the wrapper 
model to accomplish FTS: (1) The wrapper model 
tends to achieve better effectiveness than that of 
the filter model with respect of a more direct eval-
uation criterion; (2) The computational cost is trac-
table because it can reduce the number of subsets 
sharply by heuristic algorithm according to the 
human knowledge. And our method belongs to 
this type. 
Lafferty (2001) noticed the homology between 
MEMMs and CRFs, and chose optimal MEMMs 
parameter vector as a starting point for training the 
corresponding CRFs. And the training process of 
CRFs converges faster than that with all zero pa-
rameter vectors. 
On the other hand, the general framework that 
processes sequential labeling with CRFs has also 
been investigated well, which can be described as 
follows: 
1. Converting the new problem to sequential 
labeling problem; 
2. Selecting optimal feature template subset for 
CRFs; 
3. Parameter estimation for CRFs; 
4. Inference for new data. 
In the field of English text chunking (Sha and 
Pereira, 2003), the step 1, 3, and 4 have been stu-
died sufficiently, whereas the step 2, how to select 
optimal feature template subset efficiently, will be 
the main topic of this paper.  
3 Feature Template Selection 
3.1 The Wrapper Model for FTS 
The framework of FTS based on the wrapper 
model for CRFs can be described as: 
1. Generating the new feature template subset; 
2. Training a CRFs model; 
3. Updating optimal feature template subset if the 
new subset is better; 
4. Repeating step 1, 2, 3 until there are no new 
feature template subsets. 
Let N denote the number of feature templates, 
the number of non-empty feature template subsets 
will be (2N-1). And the wrapper model is unable to 
deal with such case without heuristic methods, 
which contains: 
1. Atomic feature templates are firstly added to 
feature template subset, which is carried out by: 
Given the position i, the current word Wi and the 
current part-of-speech Pi are firstly added to cur-
rent feature template subset, and then Wi-1 and Pi-1, 
or Wi+1 and Pi+1, and so on, until the effectiveness 
is of no improvement. Taking the Chinese text 
chunking as example, optimal atomic feature tem-
plate subset is {Wi-3~Wi+3, Pi-3~Pi+3}; 
2. Adding combined feature templates properly 
to feature template set will be helpful to improve 
the performance, however, too many combined 
feature templates will result in severe data sparse-
ness problem. Therefore, we present three restric-
tions for combined feature templates: (1) A com-
bined feature template that contains more than 
three atomic templates are not allowable; (2) If a 
combined feature template contains three atomic 
feature template, it can only contain at most one 
atomic word template; (3) In a combined template, 
at most one word is allowable between the two 
most adjacent atomic templates; For example, the 
combined feature templates, such as {Pi-1, Pi, Pi+1, 
Pi+2}, {Wi, Wi+1, Pi},  and {Pi-1, Pi+2}, are not al-
lowable, whereas the combined templates, such as 
{Pi, Pi+1, Pi+2}, {Pi-1, Wi, Pi+1}, and {Pi-1, Pi+1}, are 
allowable. 
3. After atomic templates have been added, {Wi-
1, Wi}, or {Wi, Wi+1}, or {Pi-1, Pi}, or {Pi, Pi+1} are 
firstly added to feature template subset. The tem-
plate window is moved forward, and then back-
ward. Such process will repeat with expanding 
template window, until the effectiveness is of no 
improvement. 
 Tens or hundreds of training processes are still 
needed even if the heuristic method is introduced. 
People usually employ CRFs model to estimate the 
effectiveness of template subset However, this is 
more tedious than that we use ME or MEMMs 
instead. The idea behind this lie in three aspects: 
first, in one iteration, the Forward-Backward Al-
gorithm adopted in CRFs training is time-
consuming; second, CRFs need more iterations 
than that of ME or MEMMs to converge because 
of larger parameter space; third, ME, MEMMs, 
and CRFs, are of the same type (log-linear models) 
and based on the same principle, as will be dis-
cussed in detail as follows. 
3.2 Homology of ME, MEMMs and CRFs 
ME, MEMMs, and CRFs are all based on the Prin-
ciple of Maximum Entropy (Jaynes, 1957). The 
mathematical expression for ME model is as for-
mula (1): 
1
1( | ) exp( ( , ))( )
m
i ii
P y x x yZ x f??? ?
    (1) 
, and Z(x) is the normalization factor. 
MEMMs can be considered as a sequential ex-
tension to the ME model. In MEMMs, the HMM 
transition and observation functions are replaced 
by a single function P(Yi|Yi-1, Xi). There are three 
kinds of implementations of MEMMs (McCallum 
et al, 2000) in which we realized the second type 
for its abundant expressiveness. In implementation 
two, which is denoted as MEMMs_2 in this paper, 
a distributed representation for the previous state 
Yi-1 is taken as a collection of features with 
weights set by maximum entropy, just as we have 
done for the observations Xi. However, label bias 
problem (Lafferty et al, 2001) exists in MEMMs, 
since it makes a local normalization of random 
field models. CRFs overcome the label bias prob-
lem by global normalization. 
Considering the homology between CRFs and 
MEMMs_2 (or ME), it is reasonable to suppose 
that a useful template for MEMMs_2 (or ME) is 
also useful for CRFs, and vice versa. And this is a 
necessary condition to replace CRFs with ME or 
MEMMs for FTS. 
3.3 A New Framework for FTS 
Besides the homology of these models, the other 
necessary condition to replace CRFs with ME or 
MEMMs for FTS is that all kinds of feature tem-
plates in CRFs can also be expressed by ME or 
MEMMs. There are two kinds of feature templates 
for CRFs: one is related to Yi-1, which is denoted 
as g(Yi-1, Yi, Xi); the other is not related to Yi-1, 
which is denoted as f(Yi, Xi). Both of them can be 
expressed by MEMMs_2. If there is only the 
second kind of feature templates in the subset, it 
can also be expressed by ME. For example, the 
feature function f(Yi, Pi) in CRFs can be expressed 
by feature template {Pi} in MEMMs_2 or ME; and 
g(Yi-1, Yi, Pi) can be expressed by feature template 
{Yi-1, Pi} in MEMM_2.  
Therefore, MEMMs_2 or ME can be employed 
to replace CRFs as machine learning model for 
improving the efficiency of   FTS. 
Then the new framework for FTS will be: 
1. Generating the new feature template subset; 
2. Training an MEMMs_2 or ME model; 
3. Updating optimal feature template subset 
if the new subset is better; 
4. Repeating step 1, 2, 3 until there are no 
new feature template subsets. 
The wrapper model evaluates the effectiveness 
of feature template subset by evaluating the model 
on testing data. However, there is a serious effi-
ciency problem when decoding a sequence by 
MEMMs_2. Given N as the length of a sentence, 
C as the number of candidate labels, the time 
complexity based on MEMMs_2 is O(NC2) when 
decoding by viterbi algorithm. Considering the C 
different Yi-1 for every word in a sentence, we 
need compute P(Yi|Yi-1, Xi) (N.C) times for 
MEMMs_2. 
Reducing the average number of candidate label 
C can help to improve the decoding efficiency. 
And in most cases, the Yi-1 in P(Yi|Yi-1, Xi) is not 
necessary (Koeling, 2000; Osbome, 2000). There-
fore, to reduce the average number of candidate 
labels C, it is reasonable to use an ME model to 
filter the candidate label. Given a threshold T (0 
<= T <= 1), the candidate label filtering algorithm 
is as follows: 
1. CP = 0; 
2. While CP <= T 
a) Add the most probable candidate label Y? 
to viterbi algorithm; 
b) Delete Y? from the candidate label set; 
c) CP = P(Y?|Xi) + CP. 
If the probability of the most probable candidate 
label has surpassed T, other labels are discarded. 
Otherwise, more labels need be added to viterbi 
algorithm. 
4 Evaluation and Result 
4.1 Evaluation 
We evaluate the effectiveness and efficiency of the 
new framework by the data set in the task two of 
 CIPS-ParsEval-2009 (Zhou and Li, 2010). The 
effectiveness is supported by high F-1 measure in 
the task two of CIPS-ParsEval-2009 (see Figure 1), 
which shows that optimal feature template subset 
driven by ME or MEMMs is also optimal for 
CRFs. The efficiency is shown by significant de-
cline in training time (see Figure 3), where the 
baseline is CRFs, and comparative methods are 
ME or MEMMs. 
We design six subsets of feature template set 
and six experiments to show the effectiveness and 
efficiency of the new framework. As shown in 
Table 1 and Table 2, the 1~3 experiments shows 
the influence of the feature templates, which are 
unrelated to Yi-1, for both ME and CRFs. And the 
4~6 experiments show the influence of the feature 
templates, which are related to Yi-1, for both 
MEMMs_2 and CRFs. In table 1, six template 
subsets can be divided into two sets by relevance 
of previous label: 1, 2, 3 and 4, 5, 6. Moreover, the 
first set can be divided into 1, 2, and 3 by distances 
between features with headwords;  the second set 
can be divided into 4, 5 and 6 by relevance of ob-
served value. In order to ensure the objectivity of 
comparative experiments, candidate label filtering 
algorithm is not adopted. 
 
Figure 1: the result in the task two of CIPS-
ParsEval-2009 
 
 
 
 
1 Wi, Wi-1, Wi-2, Wi+1, Wi+2, Pi, Pi-1, Pi-2, Pi+1, 
Pi+2, Wi-1_Wi, Wi_Wi+1, Wi-1_Wi+1, Pi-1_Pi, 
Pi-2_Pi-1, Pi_Pi+1, Pi-1_Pi+1, Pi-1_Pi_Pi+1, Pi-
2_Pi-1_Pi,     Pi_Pi+1_Pi+2, Wi_Pi+1, Wi_Pi+2, 
Pi_Wi-1, Wi-2_Pi-1_Pi, Pi_Wi+1_Pi+1, Pi-
1_Wi_Pi, Pi_Wi+1 
2 Wi-3, Wi+3, Pi-3, Pi+3, Wi-3_Wi-2, Wi+2_Wi+3, 
Pi-3_Pi-2, Pi+2_Pi+3 
3 Wi-4, Wi+4, Pi-4, Pi+4, Wi-4_Wi-3, Wi+3_Wi+4, 
Pi-4_Pi-3, Pi+3_Pi+4 
4 Yi-1 
5 Yi-1_Pi_Pi+1, Yi-1_Pi, Yi-1_Pi-1_Pi 
6 Yi-1_Pi-4, Yi-1_Pi+4 
Table 1: six subsets of feature template set 
 
id Model FT subset 
1 ME vs. CRFs 1 
2 ME vs. CRFs 1, 2 
3 ME vs. CRFs 1, 2, 3 
4 MEMMs vs. CRFs 1, 2, 4 
5 MEMMs vs. CRFs 1, 2, 4, 5 
6 MEMMs vs. CRFs 1, 2, 4, 5, 6 
Table 2: six experiments 
4.2 Empirical Results 
The F-measure curve is shown in Figure 2. For the 
same and optimal feature template subset, the F-1 
measure of CRFs is superior to that of ME because 
of global normalization; and it is superior to that of 
MEMMs since it overcomes the label bias. 
 
Figure 2: the F-measure curve 
 
 
Figure 3: the training time curve 
 
The significant decline in training time of the 
new framework is shown in Figure 3, while the 
testing time curve in Figure 4 and the total time 
curve in Figure 5. The testing time of ME is more 
 than that of CRFs because of local normalization; 
and the testing time of MEMMs_2 is much more 
than that of CRFs because of N.C times of P(Yi|Yi-
1, Xi) computation. 
 
 
Figure 4: the testing time curve 
 
Figure 5: the total time curve 
All results of ME and MEMMs in figures are 
represented by the same line because perfor-
mances of these two models are the same when 
features are only related to observed values. 
5 Conclusions 
In this paper, we propose a new optimal feature 
template selection method for CRFs, which is car-
ried out by replacing the CRFs with MEMM_2 
(ME) as the machine learning model to address the 
efficiency problem according to the homology of 
these models. Heuristic method and candidate la-
bel filtering algorithm, which can improve the ef-
ficiency of FTS further, are also introduced. The 
effectiveness and efficiency of the new method is 
confirmed by the experiments on Chinese text 
chunking.  
Two problems deserve further study: one is to 
prove the homology of ME, MEMMs, and CRFs 
theoretically; the other is to expand the method to 
other fields. 
For any statistical machine learning model, fea-
ture selection or feature template selection is a 
computation-intensive step. This work can be ade-
quately reduced by means of analyzing the homol-
ogy between models and using the model with less 
computation amount. Our research proves to be a 
successful attempt. 
References 
Das Sanmay. 2001. Filters, wrappers and a boosting-
based hybrid for feature selection. In Proceedings of 
the Eighteenth International Conference on Machine 
Learning, pages 74?81. 
Dietterich Thomas G., Adam Ashenfelter, Yaroslav 
Bulatov. 2004. Training Conditional Random Fields 
via Gradient Tree Boosting. In Proc. of the 21th In-
ternational Conference on Machine Learning 
(ICML). 
Dy Jennifer G., and Carla E. Brodley. 2000. Feature 
subset selection and order identification for unsuper-
vised learning. In Proceedings of the Seventeenth In-
ternational Conference on Machine Learning, pages 
247?254. 
Hall Mark A.. 2000. Correlation-based feature selection 
for discrete and numeric class machine learning. In 
Proceedings of the Seventeenth International Confe-
rence on Machine Learning, pages 359?366. 
Jaynes, Edwin T.. 1957. Information Theory and Statis-
tical Mechanics. Physical Review 106(1957), May. 
No.4, pp. 620-630. 
Kim YongSeog, W. Nick Street and Filippo Menczer. 
2000. Feature Selection in Unsupervised Learning 
via Evolutionary Search. In Proceedings of the Sixth 
ACM SIGKDD International Conference on Know-
ledge Discovery and Data Mining, pages 365?369. 
Koeling Rob. 2000. Chunking with Maximum Entropy 
Models. In Proceeding of CoNLL-2000 and LLL-
2000, Lisbon, Portugal, 2000, pp. 139-141. 
Kohavi Ron, and George H. John. 1997. Wrappers for 
feature subset selection. Artificial Intelligence, 97(1-
2):273?324. 
Lafferty John, Andrew McCallum, and Fernando Perei-
ra. 2001. Conditional Random Fields: Probabilistic 
Models for Segmenting and Labeling Sequence Data. 
Proceedings of the Eighteenth International Confe-
rence on Machine Learning. 
Li Wei, and Andrew McCallum. 2003. Rapid Devel-
opment of Hindi Named Entity Recognition using 
Conditional Random Fields and Feature Induction. 
ACM Transactions on Asian Language Information 
Processing (TALIP).  
Liu Huan, and Lei Yu. 2005. Toward Integrating Fea-
ture Selection Algorithms for Classification and 
Clustering. IEEE Transactions on knowledge and 
Data Engineering, v.17 n.4, p.491-502. 
Liu Huan, and Rudy Setiono. 1996. A probabilistic ap-
proach to feature selection - a filter solution. In Pro-
 ceedings of the Thirteenth International Conference 
on Machine Learning, pages 319?327. 
McCallum Andrew. 2003. Efficiently Inducing Features 
of Conditional Random Fields. In Proceedings of the 
Nineteenth Conference on Uncertainty in Artificial 
Intelligence. 
McCallum Andrew, DAyne Freitag, Fernando Pereira. 
2000. Maximum Entropy Markov Models for Infor-
mation Extraction and Segmentation. In Proceedings 
of ICML'2000, Stanford, CA, USA, 2000, pp. 591-
598. 
McCallum Andrew, and Wei Li. 2003. Early Results for 
Named Entity Recognition with Conditional Random 
Fields, Feature Induction and Web-Enhanced Lex-
icons. In Proceedings of The Seventh Conference on 
Natural Language Learning (CoNLL-2003), Edmon-
ton, Canada.  
Osbome Miles. 2000. Shallow Parsing as Part-of-
speech Tagging. In Proceeding of CoNLL-2000 and 
LLL-2000, Lisbon, Portugal, 2000,pp. 145-147. 
Roark Brian, Murat Saraclar, Michael Collins, and 
Mark Johnson. 2004. Discriminative language mod-
eling with conditional random fields and the percep-
tron algorithm. Proceedings of the 42nd Annual 
Meeting of the Association for Computational Lin-
guistics. 
Settles Burr. 2004. Biomedical Named Entity Recogni-
tion Using Conditional Random Fields and Rich Fea-
ture Sets. COLING 2004 International Joint Work-
shop on Natural Language Processing in Biomedi-
cine and its Applications (NLPBA). 
Sha Fei, and Fernando Pereira. 2003. Shallow Parsing 
with Conditional Random Fields. Proceedings of the 
2003 conference of the North American Chapter of 
the Association for Computational Linguistics on 
Human Language Technology, Edmonton, Canada. 
Yu Lei, and Huan Liu. 2004. Feature selection for high-
dimensional data: a fast correlation-based filter solu-
tion. In Proceedings of the twentieth International 
Conference on Machine Learning, pages 856?863. 
Zhou Qiang, and Yumei Li. 2010. Chinese Chunk Pars-
ing Evaluation Tasks. Journal of Chinese Informa-
tion Processing. 
