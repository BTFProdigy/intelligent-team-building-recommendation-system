Word Sense Disambiguation using a dictionary for sense similarity measure
Bruno Gaume Nabil Hathout Philippe Muller
IRIT ? CNRS, UPS & INPT ERSS ? CNRS & UTM IRIT ? CNRS, UPS & INPT
Toulouse, France Toulouse, France Toulouse, France
gaume@irit.fr hathout@univ-tlse2.fr muller@irit.fr
Abstract
This paper presents a disambiguation
method in which word senses are deter-
mined using a dictionary. We use a seman-
tic proximity measure between words in the
dictionary, taking into account the whole
topology of the dictionary, seen as a graph
on its entries. We have tested the method on
the problem of disambiguation of the dic-
tionary entries themselves, with promising
results considering we do not use any prior
annotated data.
1 Introduction
Various tasks dealing with natural language
data have to cope with the numerous different
senses possessed by every lexical item: ma-
chine translation, information retrieval, infor-
mation extraction ... This very old issue is far
from being solved, and evaluation of methods
addressing it is far from obvious (Resnik and
Yarowsky, 2000). This problem has been tack-
led in a number of ways1: by looking at con-
texts of use (with supervised learning or un-
supervised sense clustering) or by using lexi-
cal resources such as dictionaries or thesauri.
The first kind of approach relies on data that
are hard to collect (supervised) or very sensitive
to the type of corpus (unsupervised). The sec-
ond kind of approach tries to exploit the lexical
knowledge that is represented in dictionaries or
thesaurus, with various results from its incep-
tion up to now (Lesk, 1986; Banerjee and Ped-
ersen, 2003). In all cases, a distance between
words or word senses is used as a way to find
the right sense in a given context. Dictionary-
based approaches usually rely on a comparison
of the set of words used in sense definitions and
1A good introduction is (Ide and V?ronis, 1998), or
(Manning and Sch?tze, 1999), chap. 7.
in the context to disambiguate2.
This paper presents an algorithm which uses
a dictionary as a network of lexical items (cf.
sections 2 and 3) to compute a semantic simi-
larity measure between words and word senses.
It takes into account the whole topology of the
dictionary instead of just the entry of target
words. This arguably gives a certain robustness
of the results with respect to the dictionary. We
have begun testing this approach on word sense
disambiguation on definitions of the dictionary
itself (section 5), but the method is expected
to be more general, although this has not been
tested yet. Preliminary results are quite encour-
aging considering that the method does not re-
quire any prior annotated data, while operating
on an unconstrained vocabulary.
2 Building the graph of a
dictionary
The experiment we describe here has been
achieved on a dictionary restricted to nouns and
verbs only: we considered dictionary entries
classified as nouns and verbs and noun and verb
lemmas occurring within those entries. The
basic idea is to consider the dictionary as an
undirected graph whose nodes are noun entries,
and an edge exists between two nodes when-
ever one of them occur in the definition of the
other. More precisely, the graph of the dictio-
nary encodes two types of lexicographical in-
formations: (1) the definitions of the entries
sub-senses and (2) the structure of the entries
that is the hierarchical organisation of their sub-
senses. The graph then includes two types of
nodes: w-nodes used for the words that occur
2With the exceptions of the methods of (Kozima and
Furugori, 1993; Ide and V?ronis, 1990), both based on
models of activation of lexical relations, but who present
no quantified results.
in the definitions and ?-nodes used for the def-
initions of the sub-senses of the entries. The
graph is created in three phases:
1. For each dictionary entry, there is a ?-
node for the entry as a whole and there is
one ?-node for each of the sub-senses of
the entry. Then an edge is added between
each ?-node and the ?-nodes which rep-
resent the sub-senses of the next lower
level. In other words, the graph includes
a tree of ?-nodes which encodes the hier-
archical structure of each entry.
2. A w-node is created in the graph for each
word occurring in a definition and an edge
is added between the w-node and the ?-
node of that definition.
3. An edge is added between each w-node
and the top ?-node representing the dic-
tionary entry for that word.
For instance, given the entry for "tooth"3:
1. (Anat.) One of the hard, bony appendages
which are borne on the jaws, or on other
bones in the walls of the mouth or pharynx
of most vertebrates, and which usually aid
in the prehension and mastication of food.
2. Fig.: Taste; palate.
These are not dishes for thy dainty tooth.
?Dryden.
3. Any projection corresponding to the tooth
of an animal, in shape, position, or office;
as, the teeth, or cogs, of a cogwheel; a
tooth, prong, or tine, of a fork; a tooth, or
the teeth, of a rake, a saw, a file, a card.
4. (a) A projecting member resembling a
tenon, but fitting into a mortise that
is only sunk, not pierced through.
(b) One of several steps, or offsets, in a
tusk. See Tusk.
We would consider one ?-node for tooth as the
top-level entry, let us call it ?0. ?0 is con-
nected with an edge to the ?-nodes ?1, ?2 ,?3
and ?4 corresponding to the senses 1., 2., 3.
3Source: Webster?s Revised Unabridged Dictionary,
1996. The experiment has actually been done on a
French dictionary, Le Robert.
and 4.; the latter will have an edge towards the
two ?-nodes ?4.1 and ?4.2 for the sub-senses
4.a. and 4.b.; ?4.1 will have an edge to each w-
node built for nouns and verbs occurring in its
definition (member, resemble, tenon, fit, mor-
tise, sink, pierce). Then the w-node for tenon
will have an edge to the ?-node of the top-
level entry of tenon. We do not directly con-
nect ?4.1to the ?-nodes of the top-level entries
because these may have both w- and ?-node
daughters.
In the graph, ?-nodes have tags which indi-
cates their homograph number and their loca-
tion in the hierarchical structure of the entry.
These tags are sequences of integers where the
first one gives the homograph number and the
next ones indicate the rank of the sense-number
at each level. For instance, the previous nodes
?4.1 is tagged (0, 4, 1).
3 Prox, a distance between graph
nodes
We describe here our method (dubbed Prox) to
compute a distance between nodes in the kind
of graph described in the previous section. It is
a stochastic method for the study of so-called
hierarchical small-world graphs (Gaume et al,
2002) (see also the next section). The idea is to
see a graph as a Markov chain whose states are
the graph nodes and whose transitions are its
edges, with equal probabilities. Then we send
random particles walking through this graph,
and their trajectories and the dynamics of their
trajectories reveal their structural properties. In
short, we assume the average distance a parti-
cle has made between two nodes after a given
time is an indication of the semantic distance
between these nodes. Obviously, nodes located
in highly clustered areas will tend to be sepa-
rated by smaller distance.
Formally, if G = (V, E) is an irreflexive
graph with |V | = n, we note [G] the n ? n ad-
jacency matrix of G that is such that [G]i,j (the
ith row and jth column) is 1 if there is an edge
between node i and node j and 0 otherwise.
We note [G?] the Markovian matrix of G, such
that [G?]r,s = [G]r,s?
x?V ([G]r,x)
.
In the case of graphs built from a dictionary
as above,[G?]r,s is 0 if there is no edge between
nodes r and s, and 1/D otherwise, where D
is the number of neighbours of r. This is in-
deed a Markovian transition matrix since the
sum of each line is one (the graph considered
being connected).
We note [G?]i the matrix [G?] multiplied i
times by itself.
Let now PROX(G,i,r,s) be [G?]ir,s. This is thus
the probability that a random particle leaving
node r will be in node s after i time steps. This
is the measure we will use to determine if a
node s is closer to a node r than another node
t. Now we still have to find a proper value for
i. The next section explains the choice we have
made.
4 Dictionaries as hierarchical
small-worlds
Recent work in graph theory has revealed a set
of features shared by many graphs observed
"in the field" These features define the class
of "hierarchical small world" networks (hence-
forth HSW) (Watts and Strogatz, 1998; New-
man, 2003). The relevant features of a graph in
this respect are the following:
D the density of the network. HSWs typically
have a low D, i.e. they have rather few
edges compared to their number of ver-
tices.
L the average shortest path between two nodes.
It is also low in a HSW.
C the clustering rate. This is a measure of how
often neighbours of a vertex are also con-
nected in the graph. In a HSW, this feature
is typically high.
I the distribution of incidence degrees (i.e. the
number of neighbours) of vertices accord-
ing to the frequency of nodes (how many
nodes are there that have an incidence de-
gree of 1, 2, ... n). In a HSW network, this
distribution follows a power law: the prob-
ability P(k) that a given node has k neigh-
bours decreases as k??, with lambda > 0.
It means also that there are very few nodes
with a lot of neighbours, and a lot more
nodes with very few neighbours.
As a mean of comparison, table 1 shows the
differences between randoms graphs (nodes
are given, edges are drawn randomly between
nodes), regular graphs and HSWs.
The graph of a dictionary belongs to the class
of HSW. For instance, on the dictionary we
used, D=7, C=0.183, L=3.3. Table 2 gives a
few characteristics of the graph of nouns only
on the dictionary we used (starred columns in-
dicate values for the maximal self-connected
component).
We also think that the hierarchical aspect of
dictionaries (reflected in the distribution of in-
cidence degrees) is a consequence of the role
of hypernymy associated to the high polysemy
of some entries, while the high clustering rate
define local domains that are useful for dis-
ambiguation. We think these two aspects de-
termine the dynamics of random walks in the
graph as explained above, and we assume they
are what makes our method interesting for
sense disambiguation.
5 Word sense disambiguation
using Prox semantic distance
We will now present a method for disambiguat-
ing dictionary entries using the semantic dis-
tance introduced section (3).
The task can be defined as follows: we con-
sider a word lemma ? occurring in the defini-
tion of one of the senses of a word ?. We want
to tag ? with the most likely sense it has in
this context. Each dictionary entry is coded as
a tree of senses in the graph of the dictionary,
with a number list associated to each sub-entry.
For instance for a given word sense of word W,
listed as sub-sense II.3.1 in the dictionary, we
would record that sense as a node W(2,3,1) in
the graph. In fact, to take homography into ac-
count we had to add another level to this, for
instance W(1,1,2) is sense 1.2 of the first ho-
mograph of word W. In the absence of an ho-
mograph, the first number for a word sense will
conventionally be 0.
Let G=(V,E) the graph of words built as ex-
plained section 2, [G] is the adjacency matrix
of G, and [G?] is the corresponding Markovian
matrix . The following algorithm has then been
applied:
1. Delete all neighbours of ? in G, i.e. make
?x ? V, [G]?,x = [G]x,? = 0
2. Compute the new [G?]i where i is taken to
be 6
(with equal D) L C I
Random graphs small L small C Poisson Law
HSW small L high C power law
Regular graphs high L high C constant
Table 1: Comparing classes of graphs
nb nodes nb edges nb N* nb E* Diam* C* L*
Nouns 53770 392161 51511 392142 7 0.1829 3.3249
Nouns and sub-senses 140080 399969 140026 399941 11 0.0081 5.21
Table 2: Dictionary used
3. Let L be the line ? in the result. ?k, L[k] =
[G?]i?,k
4. Let E = {x1, x2, ..., xn} be the nodes cor-
responding to all the sub-senses induced
by the definition of ?.
Then take xk = argmaxx?E(L[x])
Then xk is the sub-sense with the best rank ac-
cording to the Prox distance.
The following steps needs a little explana-
tion:
1 This neighbours are deleted because other-
wise there is a bias towards the sub-senses
of ?, which then form a sort of "artificial"
cluster with respect to the given task. This
is done to allow the random walk to really
go into the larger network of senses.
2 Choosing a good value for the length of
the random walk through the graph is not
a simple matter. If it is too small, only lo-
cal relations appear (near synonyms, etc)
which might not appear in contexts to dis-
ambiguate (this is the main problem of
Lesk?s method); if it is too large, the dis-
tances between words will converge to a
constant value. So it has to be related in
some way to the average length between
two senses in the graph. A reasonable as-
sumption is therefore to stay close to this
average length. Hence we took i = 6 since
the average length is 5.21 (in the graph
with a node for every sub-sense, the graph
with a node for each entry having L=3.3)
6 Evaluating the results
The following methodology has been followed
to evaluate the process.
We have randomly taken about a hundred
of sub-entries in the chosen dictionary (out
of about 140,000 sub-entries), and have hand-
tagged all nouns and verbs in the entries with
their sub-senses (and homography number), ex-
cept those with only one sense, for a total of
about 350 words to disambiguate. For all pair
of (context,target), the algorithm gives a ranked
list of all the sub-senses of the target. Although
we have used both nouns and verbs to build the
graph of senses, we have tested disambiguation
first on nouns only, for a total of 237 nouns. We
have looked how the algorithm behaves when
we used both nouns and verbs in the graph of
senses.
To compare the human annotation to the au-
tomated one, we have applied the following
measures, where (h1, h2, , ...) is the human tag,
and (s1, s2, ..) is the top-ranked system output
for a context i defined as the entry and the target
word to disambiguate:
1. if h1 = 0 then do nothing else the homo-
graph score is 1 if h1 = s1, 0 otherwise;
2. in all cases, coarse polysemy count = 1 if
h2 = s2, 0 otherwise;
3. in all cases, fine polysemy count = 1 if ?i
hi = si
Thus, the coarse polysemy score computes how
many times the algorithm gives a sub-sense that
has the same "main" sense as the human tag
(the main-sense corresponds to the first level in
the hierarchy of senses as defined above). The
fine polysemy score gives the number of times
the algorithm gives exactly the same sense as
the human.
To give an idea of the difficult of the task,
we have computed the average number of main
entry target system output human tag
correct bal#n._m.*0_3 lieu#n. 1_1_3 1_1_1
correct van#n._m.*2_0_0_0_0 voiture#n. 0_2 0_2_3
error phon?tisme#n._m.*0 moyen#n. 1_1_1 2_1
error cr?ativit?#n._f.*0 pouvoir#n. 2_3 2_1
error acm?#n._m._ou_f.*0_1 phase#n. 0_1 0_4
Table 3: Detailed, main-sense evaluation of a couple of examples.
sub-senses and the number of all senses, for
each target word. This corresponds to a ran-
dom algorithm, choosing between all senses of
a given word. The expected value of this base-
line is thus:
? homograph score=?x 1/(number of ho-
mographs of x)
? coarse polysemy = ?x 1/(number of main
sub-senses of x)
? fine polysemy = ?x 1/(number of all sub-
senses of x)
A second baseline consists in answering al-
ways the first sense of the target word, since
this is often (but not always) the most common
usage of the word. We did not do this for homo-
graphs since the order in which they are given
in the dictionary does not seem to reflect their
importance.
Table 4 sums up the results.
7 Discussion
The result for homographs is very good but not
very significant given the low number of occur-
rences; this all the more true as we used a part-
of-speech tagger to disambiguate homographs
with different part-of-speech beforehand (these
have been left out of the computation of the
score).
The scores we get are rather good for coarse
polysemy, given the simplicity of the method.
As a means of comparison, (Patwardhan et
al., 2003) applies various measures of seman-
tic proximity (due to a number of authors), us-
ing the WordNet hierarchy, to the task of word
sense disambiguation of a few selected words
with results ranging from 0.2 to 0.4 with respect
to sense definition given in WordNet (the aver-
age of senses for each entry giving a random
score of about 0.2).
Our method already gives similar results
on the fine polysemy task (which has an
even harder random baseline) when using both
nouns and verbs as nodes, and does not focus
on selected targets.
A method not evaluated by (Patwardhan et
al., 2003) and using another semantic related-
ness measure ("conceptual density") is (Agirre
and Rigau, 1996). It is also based on a dis-
tance within the WordNet hierarchy. They used
a variable context size for the task and present
results only for the best size (thus being a
not fully unsupervised method). Their random
baseline is around 30%, and their precision is
43% for 80% attempted disambiguations.
Another study of disambiguation using a se-
mantic similarity derived from WordNet is (Ab-
ney and Light, 1999); it sees the task as a Hid-
den Markov Model, whose parameters are es-
timated from corpus data, so this is a mixed
model more than a purely dictionary-based
model. With a baseline of 0.285, they reach a
score of 0.423. Again, the method we used is
much simpler, for comparable or better results.
Besides, by using all connections simultane-
ously between words in the context to disam-
biguate and the rest of the lexicon, this method
avoids the combinatorial explosion of methods
purely based on a similarity measure, where ev-
ery potential sense of every meaningful word
in the context must be considered (unless ev-
ery word sense of words other than the target is
known beforehand, which is not a very realis-
tic assumption), so that only local optimization
can be achieved. In our case disambiguating
a lot of different words appearing in the same
context may result in poorer results than with
only a few words, but it will not take longer.
The only downside is heavy memory usage, as
with any dictionary-based method.
We have made the evaluation on dictionary
entries because they are already part of the net-
random first sense algorithm(n+v)
homographs 0.49 - 0.875 (14/16)
coarse polysemy 0.35 0.493 0.574 (136/237)
fine polysemy 0.18 0.40 0.346 (82/237)
Table 4: Results
work of senses, to avoid raising other issues too
early. Thus, we are not exactly in the context
of disambiguating free text. It could then be
argued that our task is simpler than standard
disambiguation, because dictionary definitions
might just be written in a more constrained and
precise language. That is why we give the score
when taking always the first sense for each en-
try, as an approximation of the most common
sense (since the dictionary does not have fre-
quency information). We can see that this score
is about 50% only for the coarse polysemy, and
40% for the fine polysemy, compared to a typ-
ical 70-80% in usual disambiguation test sets,
for similar sense dispersion (given by the ran-
dom baseline); in (Abney and Light, 1999), the
first-sense baseline gives 82%. So we could
in fact argue that disambiguating dictionary en-
tries seems harder. This fact remains however
to be confirmed with the actual most frequent
senses. Let us point out again that our al-
gorithm does not make use of the number of
senses in definitions.
Among the potential sources of improvement
for the future, or sources of errors in the past,
we can list at least the following:
? overlapping of some definitions for sub-
senses of an entry. Some entries of the
dictionary we used have sub-senses that
are very hard to distinguish. In order to
measure the impact of this, we should have
multiple annotations of the same data and
measure inter-annotator agreement, some-
thing that has not been done yet.
? part of speech tagging generates a few er-
rors when confusing adjectives and nouns
or adjectives and verbs having the same
lemma; this should be compensated when
we enrich the graph with entries for adjec-
tives.
? some time should be spent studying the
precise influence of the length of the ran-
dom walk considered; we have chosen a
value a priori to take into account the aver-
age length of a path in the graph, but once
we have more hand-tagged data we should
be able to have a better idea of the best
suited value for that parameter.
8 Conclusion
We have presented here an algorithm giving a
measure of lexical similarity, built from infor-
mation found in a dictionary. This has been
used to disambiguate dictionary entries, with a
method that needs no other source of informa-
tion (except part-of-speech tagging), no anno-
tated data. The coverage of the method depends
only on the lexical coverage of the dictionary
used. It seems to give promising results on dis-
ambiguating nouns, using only nouns or nouns
and verbs. We intend to try the method after
enriching the network of senses with adjectives
and/or adverbs. We also intend, of course, to try
the method on disambiguating verbs and adjec-
tives.
Moreover, the method can be rather straight-
forwardly extended to any type of disambigua-
tion by considering a context with a target
word as a node added in the graph of senses
(a kind of virtual definition). We have not
tested this idea yet. Since our method gives a
ranked list of sense candidates, we also con-
sider using finer performance measures, taking
into account confidence degrees, as proposed in
(Resnik and Yarowsky, 2000).
References
Steven Abney and Marc Light. 1999. Hiding
a semantic hierarchy in a markov model. In
ACL?99 Workshop Unsupervised Learning in
Natural Language Processing, University of
Maryland.
E. Agirre and G. Rigau. 1996. Word sense
disambiguation using conceptual density. In
Proceedings of COLING?96, pages 16?22,
Copenhagen (Denmark).
S. Banerjee and T. Pedersen. 2003. Extended
gloss overlaps as a measure of semantic re-
latedness. In Proceedings of the Eighteenth
International Conference on Artificial Intel-
ligence (IJCAI-03), Acapulco, Mexico.
B. Gaume, K. Duvignau, O. Gasquet, and M.-
D. Gineste. 2002. Forms of meaning, mean-
ing of forms. Journal of Experimental and
Theoretical Artificial Intelligence, 14(1):61?
74.
N. Ide and J. V?ronis. 1998. Introduction to
the special issue on word sense disambigua-
tion: The state of the art. Computational
Linguistics, 24(1).
N. Ide and J. V?ronis. 1990. Word sense dis-
ambiguation with very large neural networks
extracted from machine readable dictionar-
ies. In Proceedings of the 14th International
Conference on Computational Linguistics
(COLING?90), volume 2, pages 389?394.
H. Kozima and T. Furugori. 1993. Similarity
between words computed by spreading acti-
vation on an english dictionary. In Proceed-
ings of the conference of the European chap-
ter of the ACL, pages 232?239.
M. Lesk. 1986. Automatic sense disambigua-
tion using machine readable dictionaries:
how to tell a pine code from an ice cream
cone. In Proceedings of the 5th annual in-
ternational conference on Systems documen-
tation, pages 24?26, Toronto, Canada.
C. Manning and H. Sch?tze. 1999. Founda-
tions of Statistical Natural Language Pro-
cessing. MIT Press.
M. E. J. Newman. 2003. The structure and
function of complex networks. SIAM Re-
view, 45:167?256.
S. Patwardhan, S. Banerjee, and T. Pedersen.
2003. Using measures of semantic related-
ness for word sense disambiguation. In Pro-
ceedings of the Fourth International Confer-
ence on Intelligent Text Processing and Com-
putational Linguistics (CICLING-03).
P. Resnik and D. Yarowsky. 2000. Distinguish-
ing systems and distinguishing senses: New
evaluation methods for word sense disam-
biguation. Natural Language Engineering,
5(2):113?133.
D.J. Watts and S.H Strogatz. 1998. Collective
dynamics of ?small-world? networks. Na-
ture, (393):440?442.
Workshop on TextGraphs, at HLT-NAACL 2006, pages 65?72,
New York City, June 2006. c?2006 Association for Computational Linguistics
Synonym Extraction Using a Semantic Distance on a Dictionary
Philippe Muller
IRIT ? CNRS, UPS & INPT
Toulouse, France
muller@irit.fr
Nabil Hathout
ERSS ? CNRS & UTM
Toulouse, France
hathout@univ-tlse2.fr
Bruno Gaume
IRIT ? CNRS, UPS & INPT
Toulouse, France
gaume@irit.fr
Abstract
Synonyms extraction is a difficult task to
achieve and evaluate. Some studies have
tried to exploit general dictionaries for
that purpose, seeing them as graphs where
words are related by the definition they ap-
pear in, in a complex network of an ar-
guably semantic nature. The advantage
of using a general dictionary lies in the
coverage, and the availability of such re-
sources, in general and also in specialised
domains. We present here a method ex-
ploiting such a graph structure to compute
a distance between words. This distance
is used to isolate candidate synonyms for
a given word. We present an evaluation of
the relevance of the candidates on a sam-
ple of the lexicon.
1 Introduction
Thesaurus are an important resource in many natural
language processing tasks. They are used to help in-
formation retrieval (Zukerman et al, 2003), machine
or semi-automated translation, (Ploux and Ji, 2003;
Barzilay and McKeown, 2001; Edmonds and Hirst,
2002) or generation (Langkilde and Knight, 1998).
Since the gathering of such lexical information is a
delicate and time-consuming endeavour, some effort
has been devoted to the automatic building of sets of
synonyms words or expressions.
Synonym extraction suffers from a variety of
methodological problems, however. Synonymy it-
self is not an easily definable notion. Totally equiv-
alent words (in meaning and use) arguably do not
exist, and some people prefer to talk about near-
synonyms (Edmonds and Hirst, 2002). A near-
synonym is a word that can be used instead of
another one, in some contexts, without too much
change in meaning. This leaves of lot of freedom
in the degree of synonymy one is ready to accept.
Other authors include ?related? terms in the build-
ing of thesaurus, such as hyponyms and hypernyms,
(Blondel et al, 2004) in a somewhat arbitrary way.
More generally, paraphrase is a preferred term re-
ferring to alternative formulations of words or ex-
pressions, in the context of information retrieval or
machine translation.
Then there is the question of evaluating the results.
Comparing to already existing thesaurus is a de-
batable means when automatic construction is sup-
posed to complement an existing one, or when a spe-
cific domain is targeted, or when simply the auto-
matic procedure is supposed to fill a void. Manual
verification of a sample of synonyms extracted is a
common practice, either by the authors of a study
or by independent lexicographers. This of course
does not solve problems related to the definition of
synonymy in the ?manual? design of a thesaurus,
but can help evaluate the relevance of synonyms ex-
tracted automatically, and which could have been
forgotten. One can hope at best for a semi-automatic
procedure were lexicographers have to weed out bad
candidates in a set of proposals that is hopefully not
too noisy.
A few studies have tried to use the lexical informa-
tion available in a general dictionary and find pat-
terns that would indicate synonymy relations (Blon-
65
del et al, 2004; Ho and C?drick, 2004). The general
idea is that words are related by the definition they
appear in, in a complex network that must be seman-
tic in nature (this has been also applied to word sense
disambiguation, albeit with limited success (Veronis
and Ide, 1990; H.Kozima and Furugori, 1993)).
We present here a method exploiting the graph struc-
ture of a dictionary, where words are related by the
definition they appear in, to compute a distance be-
tween words. This distance is used to isolate can-
didate synonyms for a given word. We present an
evaluation of the relevance of the candidates on a
sample of the lexicon.
2 Semantic distance on a dictionary graph
We describe here our method (dubbed Prox) to com-
pute a distance between nodes in a graph. Basi-
cally, nodes are derived from entries in the dictio-
nary or words appearing in definitions, and there are
edges between an entry and the word in its definition
(more in section 3). Such graphs are "small world"
networks with distinguishing features and we hypo-
thetize these features reflect a linguistic and seman-
tic organisation that can be exploited (Gaume et al,
2005).
The idea is to see a graph as a Markov chain whose
states are the graph nodes and whose transitions are
its edges, valuated with probabilities. Then we send
random particles walking through this graph, and
their trajectories and the dynamics of their trajec-
tories reveal their structural properties. In short, we
assume the average distance a particle has made be-
tween two nodes after a given time is an indication
of the semantic distance between these nodes. Ob-
viously, nodes located in highly clustered areas will
tend to be separated by smaller distance.
Formally, if G = (V,E) is a reflexive graph (each
node is connected to itself) with |V | = n, we note
[G] the n ? n adjacency matrix of G that is such
that [G]i,j (the ith row and jth column) is non null
if there is an edge between node i and node j and
0 otherwise. We can have different weights for
the edge between nodes (cf. next section), but the
method will be similar.
The first step is to turn the matrix into a Markovian
matrix. We note [G?] the Markovian matrix of G,
such that
[G?]r,s =
[G]r,s
?
x?V ([G]r,x)
The sum of each line of G is different from 0 since
the graph is reflexive.
We note [G?]i the matrix [G?] multiplied i times by it-
self.
Let now PROX(G, i, r, s) be [G?]ir,s. This is thus
the probability that a random particle leaving node r
will be in node s after i time steps. This is the mea-
sure we will use to determine if a node s is closer
to a node r than another node t. The choice for i
will depend on the graph and is explained later (cf.
section 4).
3 Synonym extraction
We used for the experiment the XML tagged MRD
Tr?sor de la Langue Fran?aise informatis? (TLFi)
from ATILF (http://atilf.atilf.fr/), a
large French dictionary with 54,280 articles, 92,997
entries and 271,166 definitions. The extraction of
synonyms has been carried out only for nouns, verbs
and adjectives. The basic assumption is that words
with semantically close definitions are likely to be
synonyms. We then designed a oriented graph
that brings closer definitions that contain the same
words, especially when these words occur in the be-
ginning. We selected the noun, verb and adjective
definitions from the dictionary and created a record
for each of them with the information relevant to
the building of the graph: the word or expression
being defined (henceforth, definiendum); its gram-
matical category; the hierarchical position of the de-
fined (sub-)sense in the article; the definition proper
(henceforth definiens).
Definitions are made of 2 members: a definiendum
and a definiens and we strongly distinguish these 2
types of objects in the graph. They are represented
by 2 types of nodes: a-type nodes for the words be-
ing defined and for their sub-senses; o-type nodes
for the words that occur in definiens.
For instance, the noun nostalgie ?nostalgia? has 6 de-
fined sub-senses numbered A.1, A.2, B., C., C. ? and
D.:
66
NOSTALGIE, subst. f?m.
A. 1. ?tat de tristesse [...]
2. Trouble psychique [...]
B. Regret m?lancolique [...] d?sir d?un retour dans
le pass?.
C. Regret m?lancolique [...] d?sir insatisfait.
? Sentiment d?impuissance [...]
D. ?tat de m?lancolie [...]
The 6 sub-senses yield 6 a-nodes in the graph plus
one for the article entry:
a.S.nostalgie article entry
a.S.nostalgie.1_1 sub-sense A. 1.
a.S.nostalgie.1_2 sub-sense A. 2.
a.S.nostalgie.2 sub-sense B.
a.S.nostalgie.3 sub-sense C.
a.S.nostalgie.3_1 sub-sense C. ?
a.S.nostalgie.4 sub-sense D.
A-node tags have 4 fields: the node type (namely a);
its grammatical category (S for nouns, V for verbs
and A for adjectives); the lemma that correponds to
the definiendum; a representation of the hierarchi-
cal position of the sub-sense in the dictionary arti-
cle. For instance, the A. 2. sub-sense of nostalgie
corresponds to the hierarchical position 1_2.
O-nodes represent the types that occur in definiens.1
A second example can be used to present them. The
adjective jonceux ?rushy? has two sub-senses ?re-
sembling rushes? and ?populated with rushes?:
Jonceux, -euse,
a) Qui ressemble au jonc.
b) Peupl? de joncs.
Actually, TLFi definitions are POS-tagged and lem-
matized:
Jonceux/S
a) qui/Pro ressembler/V au/D jonc/S ./X
b) peupl?/A de/Prep jonc/S ./X 2
The 2 definiens yield the following o-type nodes in
the graph:
o.Pro.qui; o.V.ressembler; o.D.au;
o.S.jonc; o.X..; o.A.peupl?; o.Prep.de
1The tokens are represented by edges.
2In this sentence, peupl? is an adjective and not a verb.
All the types that occur in definiens are represented,
including the function words (pronouns, deter-
miners...) and the punctuation. Function words
play an important role in the graph because they
bring closer the words that belong to the same
semantical referential classes (e.g. the adjectives
of resemblance), that is words that are likely to
be synonyms. Their role is also reinforced by the
manner edges are weighted.
A large number of TLFi definitions concerns
phrases and locutions. However, these definitions
have been removed from the graph because:
? their tokens are not identified in the definiens;
? their grammatical categories are not given in
the articles and are difficult to calculate;
? many lexicalized phrases are not sub-senses of
the article entry.
O-node tags have 3 fields: the node type (namely o);
the grammatical category of the word; its lemma.
The oriented graph built for the experiment then
contains one a-node for each entry and each entry
sub-sense (i.e. each definiendum) and one o-node
for each type that occurs in a definition (i.e. in a
definiens). These nodes are connected as follows:
1. The graph is reflexive;
2. Sub-senses are connected to the words of their
definiens and vice versa (e.g. there is an edge
between a.A.jonceux.1 and o.Pro.qui,
and another one between o.Pro.qui and
a.A.jonceux.1).
3. Each a-node is connected to the a-nodes
of the immediately lower hierarchical
level but there is no edge between an
a-node and the a-nodes of higher hier-
archical levels (e.g. a.S.nostalgie
is connected to a.S.nostalgie.1_1,
a.S.nostalgie.1_2,
a.S.nostalgie.2, a.S.nostalgie.3
and a.S.nostalgie.4, but none of the
sub-senses is connected to the entry).
67
4. Each o-node is connected to the a-node that
represents its entry, but there is no edge be-
tween the a-node representing an entry and the
corresponding o-node (e.g. there is an edge be-
tween o.A.jonceux and a.A.jonceux,
but none between a.A.jonceux and
o.A.jonceux).
All edge weights are 1 with the exception of
the edges representing the 9 first words of each
definiens. For these words, the edge weight takes
into account their position in the definiens. The
weight of the edge that represent the first token is
10; it is 9 for the second word; and so on down to
1.3
These characteristics are illustrated by the fragment
of the graph representing the entry jonceux in table
1.
4 Experiment and results
Once the graph built, we used Prox to compute a se-
mantic similarity between the nodes. We first turned
the matrix G that represent the graph into a Marko-
vian matrix [G?] as described in section 2 and then
computed [G?]5, that correspond to 5-steps paths in
the Markovian graph.4 For a given word, we have
extracted as candidate synonyms the a-nodes (i) of
the same category as the word (ii) that are the clos-
est to the o-node representing that word in the dictio-
nary definitions. Moreover, only the first a-node of
each entry is considered. For instance, the candidate
synonyms of the verb accumuler ?accumulate? are
the a-nodes representing verbs (i.e. their tags begin
in a.V) that are the closer to the o.V.accumuler
node.
5-steps paths starting from an o-node representing a
word w reach six groups of a-nodes:
A1 the a-nodes of the sub-senses which have w in
their definition;
3Lexicographic definitions usually have two parts: a genus
and a differentia. This edge weight is intended to favour the
genus part of the definiens.
4The path length has been determined empirically.
A2 the a-nodes of the sub-senses with definiens
containing the same words as those of A1;
A3 the a-nodes of the sub-senses with definiens
containing the same words as those of A2;
B1 the a-nodes of the sub-senses of the article of w.
(These dummy candidates are not kept.)
B2 the a-nodes of the sub-senses with definiens
containing the same words as those of B1;
B3 the a-nodes of the sub-senses with definiens
containing the same words as those of B2;
The three first groups take advantage of the fact
that synonyms of the definiendum are often used in
definiens.
The question of the evaluation of the extraction of
synonyms is a difficult one, as was already men-
tioned in the introduction. We have at our disposal
several thesauri for French, with various coverages
(from about 2000 pairs of synonyms, to 140,000),
and a lot of discrepancies.5 If we compare the the-
saurus with each other and restrict the comparison
to their common lexicon for fairness, we still have
a lot of differences. The best f-score is never above
60%, and it raises the question of the proper gold
standard to begin with. This is all the more distress-
ing as the dictionary we used has a larger lexicon
than all the thesaurus considered together (roughly
twice as much). As our main purpose is to build a set
of synonyms from the TLF to go beyond the avail-
able thesaurus, we have no other way but to have
lexicographers look at the result and judge the qual-
ity of candidate synonyms. Before imposing this
workload on our lexicographer colleagues, we took
a sample of 50 verbs and 50 nouns, and evaluated
the first ten candidates for each, using the ranking
method presented above, and a simpler version with
equal weights and no distinction between sense lev-
els or node types. The basic version of the graph
also excludes nodes with too many neighbours, such
as "?tre" (be), "avoir" (have), "chose" (thing), etc. ).
Two of the authors separately evaluated the candi-
dates, with the synonyms from the existing thesauri
5These seven classical dictionaries of synonyms are all
available from http://www.crisco.unicaen.fr/dicosyn.html.
68
o
.A
.jo
nc
eu
x
a.
A
.jo
nc
eu
x
a.
A
.jo
nc
eu
x.1
a.
A
.jo
nc
eu
x.2
o
.P
ro
.q
ui
o
.V
.
re
ss
em
bl
er
o
.D
.a
u
o
.S
.jo
nc
o
.X
..
o
.A
.p
eu
pl
?
o
.P
re
p.
de
o.A.jonceux 1 1
a.A.jonceux 1 1 1
a.A.jonceux.1 1 1 1 1 1 1
a.A.jonceux.2 1 1 1 1 1
o.Pro.qui 10 1
o.V.ressembler 9 1
o.D.au 8 1
o.S.jonc 7 8 1
o.X.. 6 7 1
o.A.peupl? 10 1
o.Prep.de 9 1
Table 1: A fragment of the graph, presented as a matrix.
already marked. It turned out one of the judge was
much more liberal than the other about synonymy,
but most synonyms accepted by the first were ac-
cepted by the second judge (precision of 0.85).6
We also considered a few baselines inspired by the
method. Obviously a lot of synonyms appear in the
definition of a word, and words in a definition tend
to be consider close to the entry they appear in. So
we tried two different baselines to estimate this bias,
and how our method improves or not from this.
The first baseline considers as synonyms of a word
all the words of the same category (verbs or nouns
in each case) that appear in a definition of the word,
and all the entry the word appear in. Then we se-
lected ten words at random among this base.
The second baseline was similar, but restricted to the
first word appearing in a definition of another word.
Again we took ten words at random in this set if it
was larger than ten, and all of them otherwise.
We show the results of precision for the first can-
didate ranked by prox, the first 5, and the first 10
(always excluding the word itself). In the case of
the two baselines, results for the first ten are a bit
6The kappa score between the two annotators was 0.5 for
both verbs and nouns, which only moderately satisfactory.
misleading, since the average numbers of candidates
proposed by these methods were respectively 8 and
6 for verbs and 9 and 5.6 for nouns (Table 2). Also,
nouns had an average of 5.8 synonyms in the exist-
ing thesauri (when what was considered was the min
between 10 and the number of synonyms), and verbs
had an average of 8.9.
We can see that both baselines outperforms
weighted prox on the existing thesaurus for verbs,
and that the simpler prox is similar to baseline 2 (first
word only). For nouns, results are close between B2
and the two proxs. It is to be noted that a lot of
uncommon words appear as candidates, as they are
related with very few words, and a lot of these do
not appear in the existing thesauri.
By looking precisely at each candidate (see judges?
scores), we can see that both baselines are slightly
improved (and still close to one another), but are
now beaten by both prox for the first and the first
5 words. There is a big difference between the two
judges, so Judge 2 has better scores than Judge 1 for
the baselines, but in each case, prox was better. It
could be troubling to see how good the second base-
line is for the first 10 candidates, but one must re-
member this baseline actually proposes 6 candidates
on average (when prox was always at 10), making
it actually nothing more than a variation on the 5
69
Existing Thesauri (V) Judge 1 Judge 2 ET (N) J1 J2
baseline-1 1 0.30 0.42 0.38 0.06 0.12 0.12
5 0.29 0.39 0.375 0.08 0.12 0.13
10 0.31 0.41 0.39 0.10 0.14 0.15
baseline-2 1 0.32 0.52 0.44 0.21 0.22 0.23
5 0.36 0.50 0.446 0.21 0.24 0.25
10 0.28 0.51 0.46 0.19 0.245 0.255
simple prox 1 0.35 0.67 NA 0.27 0.415 0.417
5 0.34 0.52 NA 0.137 0.215 0.237
10 0.247 0.375 NA 0.123 0.17 0.19
weighted prox 1 0.22 0.56 0.76 0.18 0.44 0.5
5 0.196 0.44 0.58 0.148 0.31 0.39
10 0.17 0.36 0.47 0.10 0.22 0.3
Table 2: Experimental results on a sample, V=verbs, N=nouns,
candidate baseline, to which it should be compared
in all fairness (and we see that prox is much better
there). The difference between the two versions of
prox shows that a basic version is better for verbs
and the more elaborate one is better for nouns, with
overall better results for verbs than for nouns.
One could wonder why there was some many more
candidates marked as synonyms by both judges,
compared to the original compilation of thesaurus.
Mainly, it seemed to us that it can be accounted for
by a lot of infrequent words, or old senses of words
absent for more restricted dictionaries. We are cur-
rently investigating this matter. It could also be that
our sample picked out a lot of not so frequent words
since they outnumber frequent words in such a large
dictionary as the TLF. An indication is the average
frequency of words in a corpus of ten years of the
journal "Le Monde". The 50 words picked out in
our sample have an average frequency of 2000 oc-
currences, while when we consider all our about 430
candidates for synonymy, the average frequency is
5300.
The main conclusion to draw here is that our method
is able to recover a lot of synonyms that are in the
definition of words, and some in definitions not di-
rectly related, which seems to be an improvement on
previous attempts from dictionaries. There is some
arbitrariness in the method that should be further
investigated (the length of the random walk for in-
stance), but we believe the parameters are rather in-
tuitive wrt to graph concepts. We also have an as-
sessment of the quality of the method, even though
it is still on a sample. The precision seems fair on
the first ten candidates, enough to be used in a semi-
automatic way, coupled with a lexicographic analy-
sis.
5 Related work
Among the methods proposed to collect synonymy
information, two families can be distinguished ac-
cording to the input they consider. Either a gen-
eral dictionary is used (or more than one (Wu and
Zhou, 2003)), or a corpus of unconstrained texts
from which lexical distributions are computed (sim-
ple collocations or syntactic dependencies) (Lin,
1998; Freitag et al, 2005) . The approach of (Barzi-
lay and McKeown, 2001) uses a related kind of re-
source: multiple translations of the same text, with
additional constraints on availability, and problems
of text alignment, for only a third of the results be-
ing synonyms (when compared to Wordnet).
A measure of similarity is almost always used to
rank possible candidates. In the case of distribu-
tional approaches, similarity if determined from the
appearance in similar contexts (Lin, 1998); in the
case of dictionary-based methods, lexical relations
are deduced from the links between words expressed
in definitions of entries.
Approaches that rely on distributional data have two
major drawbacks: they need a lot of data, gener-
ally syntactically parsed sentences, that is not al-
ways available for a given language (English is an
exception), and they do not discriminate well among
lexical relations (mainly hyponyms, antonyms, hy-
pernyms) (Weeds et al, 2004) . Dictionary-based
70
approaches address the first problem since dictionar-
ies are readily available for a lot of language, even
electronically, and this is the raison d??tre of our ef-
fort. As we have seen here, it is not an obvious task
to sort related terms with respect to synonymy, hy-
pernymy, etc, just as with distribution approaches.
A lot of work has been done to extract lexical rela-
tions from the definitions taken in isolation (mostly
for ontology building), see recently (Nichols et al,
2005), with a syntactic/semantic parse, with usually
results around 60% of precision (that can be com-
pared with the same baseline we used, all words in
the definition with the same category), on dictionar-
ies with very small definitions (and thus a higher
proportions of synonyms and hypernyms). Estimat-
ing the recall of such methods have not been done.
Using dictionaries as network of lexical items or
senses has been quite popular for word sense dis-
ambiguation (Veronis and Ide, 1990; H.Kozima and
Furugori, 1993; Niwa and Nitta, 1994) before los-
ing ground to statistical approaches, even though
(Gaume et al, 2004; Mihalcea et al, 2004) tried a re-
vival of such methods. Both (Ho and C?drick, 2004)
and (Blondel et al, 2004) build a graph of lexical
items from a dictionary in a manner similar to ours.
In the first case, the method used to compute similar-
ity between two concepts (or words) is restricted to
neighbors, in the graph, of the two concepts; in the
second case, only directly related words are consid-
ered as potential candidates for synonymy: for two
words to be considered synonyms, one has to appear
in the definition of another. In both cases, only 6
or 7 words have been used as a test of synonymy,
with a validation provided by the authors with "re-
lated terms" (an unclear notion) considered correct.
The similarity measure itself was evaluated on a set
of related terms from (Miller and Charles, 1991), as
in (Budanitsky and Hirst, 2001; Banerjee and Ped-
ersen, 2003), with seemingly good results, but se-
mantically related terms is a very different notion
("car" and "tire" for instance are semantically related
terms, and thus considered similar).
We do not know of any dictionary-based graph ap-
proach which have been given a larger evaluation of
its results. Parsing definitions in isolation prevents a
complete coverage (we estimated that only 30% of
synonyms pairs in the TLF can be found from defi-
nitions).
As for distributional approaches, (Barzilay and
McKeown, 2001) gets a very high precision (around
90%) on valid paraphrases as judged by humans,
among which 35% are synonymy relations in Word-
net, 32% are hypernyms, 18% are coordinate terms.
Discriminating among the paraphrases types is not
addressed. Other approaches usually consider either
given sets of synonyms among which one is to be
chosen (for a translation for instance) (Edmonds and
Hirst, 2002) or must choose a synonym word against
unrelated terms in the context of a synonymy test
(Freitag et al, 2005), a seemingly easier task than
actually proposing synonyms. (Lin, 1998) proposes
a different methodology for evaluation of candidate
synonyms, by comparing similarity measures of the
terms he provides with the similarity measures be-
tween them in Wordnet, using various semantic dis-
tances. This makes for very complex evaluation pro-
cedures without an intuitive interpretation, and there
is no assessment of the quality of the automated the-
saurus.
6 Conclusion
We have developed a general method to extract near-
synonyms from a dictionary, improving on the two
baselines. There is some arbitrariness in the param-
eters we used, but we believe the parameters are
rather intuitive wrt to graph concepts.7 There is
room for improvement obviously, also for a combi-
nation with other methods to filter synonyms (with
frequency estimates for instance, such as tf.idf or
mutual information measures).
Clearly the advantage of using a dictionary is re-
tained: there is no restriction of coverage, and we
could have used a specialised dictionary to build a
specialised thesaurus. We have provided an assess-
ment of the quality of the results, although there
is not much to compare it to (to the best of our
knowledge), since previous accounts only had cur-
sory evaluation.
7The lexical graph can be explored at http://prox.irit.fr.
71
Acknowledgments
This research has been supported by the CNRS pro-
gram TCAN 04N85/0025. We sincerely thank the
ATILF laboratory and Pr. Jean-Marie Pierrel for
the opportunity they gave us to use the Tr?sor de la
Langue Fran?aise informatis?. We would also like
to thank Jean-Marc Destabeaux for his crucial help
in extracting the definitions from the TLFi.
References
S. Banerjee and T. Pedersen. 2003. Extended gloss over-
laps as a measure of semantic relatedness. In Proceed-
ings of IJCAI-03, Acapulco, Mexico.
Regina Barzilay and Kathleen R. McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Proceed-
ings of the 39th ACL, pages 00?00, Toulouse.
Vincent D. Blondel, Anah? Gajardo, Maureen Heymans,
Pierre Senellart, and Paul Van Dooren. 2004. A mea-
sure of similarity between graph vertices: Applications
to synonym extraction and web searching. SIAM Review,
46(4):647?666.
A. Budanitsky and G. Hirst. 2001. Semantic distance
in wordnet: An experimental, application-oriented eval-
uation of five measures. In Workshop on WordNet and
Other Lexical Resources, NAACL 2001, Pittsburgh.
Philip Edmonds and Graeme Hirst. 2002. Near-
Synonymy and lexical choice. Computational Linguis-
tics, 28(2):105?144.
Dayne Freitag, Matthias Blume, John Byrnes, Edmond
Chow, Sadik Kapadia, Richard Rohwer, and Zhiqiang
Wang. 2005. New experiments in distributional repre-
sentations of synonymy. In Proceedings of CoNLL, pages
25?32, Ann Arbor, Michigan, June. Association for Com-
putational Linguistics.
B. Gaume, N. Hathout, and P. Muller. 2004. Word
sense disambiguation using a dictionary for sense similar-
ity measure. In Proceedings of Coling 2004, volume II,
pages 1194?1200, Gen?ve.
B. Gaume, F. Venant, and B. Victorri. 2005. Hierarchy
in lexical organization of natural language. In D. Pumain,
editor, Hierarchy in natural and social sciences, Metho-
dos series, pages 121?143. Kluwer.
H.Kozima and T. Furugori. 1993. Similarity between
words computed by spreading activation on an english
dictionary. In Proceedings of the EACL, pages 232?239.
Ngoc-Diep Ho and Fairon C?drick. 2004. Lexical simi-
larity based on quantity of information exchanged - syn-
onym extraction. In Proc. of Intl. Conf. RIVF?04, Hanoi.
Irene Langkilde and Kevin Knight. 1998. Generation
that exploits corpus-based statistical knowledge. In Pro-
ceedings of COLING-ACL ?98, volume 1, pages 704?
710, Montreal.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of COLING-ACL ?98,
volume 2, pages 768?774, Montreal.
Rada Mihalcea, Paul Tarau, and Elizabeth Figa. 2004.
PageRank on semantic networks, with application to
word sense disambiguation. In Proceedings of Coling
2004, Geneva.
GA Miller and WG Charles. 1991. Contextual corre-
lates of semantic similarity. Language and Cognitive
Processes, 6(1):1?28.
Eric Nichols, Francis Bond, and Daniel Flickinger. 2005.
Robust ontology acquisition from machine-readable dic-
tionaries. In Proceedings of IJCAI?05.
Yoshiki Niwa and Yoshihiko Nitta. 1994. Co-occurrence
vectors from corpora vs. distance vectors from dictionar-
ies. In Proceedings of Coling 1994.
Sabine Ploux and Hyungsuk Ji. 2003. A
model for matching semantic maps between languages
(French/English, English/French). Computational Lin-
guistics, 29(2):155?178.
J. Veronis and N.M. Ide. 1990. Word sense disambigua-
tion with very large neural networks extracted from ma-
chine readable dictionaries. In COLING-90: Proceed-
ings of the 13th International Conference on Computa-
tional Linguistics, volume 2, pages 389?394, Helsinki,
Finland.
Julie Weeds, David Weir, and Diana McCarthy. 2004.
Characterising measures of lexical distributional similar-
ity. In Proceedings of Coling 2004, pages 1015?1021,
Geneva, Switzerland, Aug 23?Aug 27. COLING.
Hua Wu and Ming Zhou. 2003. Optimizing synonyms
extraction with mono and bilingual resources. In Pro-
ceedings of the Second International Workshop on Para-
phrasing, Sapporo, Japan. Association for Computational
Linguistics.
Ingrid Zukerman, Sarah George, and Yingying Wen.
2003. Lexical paraphrasing for document retrieval and
node identification. In Proceedings of the Second Inter-
national Workshop on Paraphrasing, Sapporo, Japan. As-
sociation for Computational Linguistics.
72
Proceedings of the 2009 Workshop on the People?s Web Meets NLP, ACL-IJCNLP 2009, pages 19?27,
Suntec, Singapore, 7 August 2009.
c?2009 ACL and AFNLP
Wiktionary and NLP: Improving synonymy networks
Emmanuel Navarro
IRIT, CNRS &
Universit? de Toulouse
navarro@irit.fr
Franck Sajous
CLLE-ERSS, CNRS &
Universit? de Toulouse
sajous@univ-tlse2.fr
Bruno Gaume
CLLE-ERSS & IRIT, CNRS &
Universit? de Toulouse
gaume@univ-tlse2.fr
Laurent Pr?vot
LPL, CNRS &
Universit? de Provence
laurent.prevot@lpl-aix.fr
Hsieh ShuKai
English Department
NTNU, Taiwan
shukai@gmail.com
Kuo Tzu-Yi
Graduate Institute of Linguistics
NTU, Taiwan
tzuyikuo@ntu.edu.tw
Pierre Magistry
TIGP, CLCLP, Academia Sinica,
GIL, NTU, Taiwan
pmagistry@gmail.com
Huang Chu-Ren
Dept. of Chinese and Bilingual Studies
Hong Kong Poly U. , Hong Kong.
churenhuang@gmail.com
Abstract
Wiktionary, a satellite of the Wikipedia
initiative, can be seen as a potential re-
source for Natural Language Processing.
It requires however to be processed be-
fore being used efficiently as an NLP re-
source. After describing the relevant as-
pects of Wiktionary for our purposes, we
focus on its structural properties. Then,
we describe how we extracted synonymy
networks from this resource. We pro-
vide an in-depth study of these synonymy
networks and compare them to those ex-
tracted from traditional resources. Fi-
nally, we describe two methods for semi-
automatically improving this network by
adding missing relations: (i) using a kind
of semantic proximity measure; (ii) using
translation relations of Wiktionary itself.
Note: The experiments of this paper are based on Wik-
tionary?s dumps downloaded in year 2008. Differences may
be observed with the current versions available online.
1 Introduction
Reliable and comprehensive lexical resources con-
stitute a crucial prerequisite for various NLP tasks.
However their building cost keeps them rare. In
this context, the success of the Princeton Word-
Net (PWN) (Fellbaum, 1998) can be explained by
the quality of the resource but also by the lack of
serious competitors. Widening this observation to
more languages only makes this observation more
acute. In spite of various initiatives, costs make
resource development extremely slow or/and re-
sult in non freely accessible resources. Collabo-
rative resources might bring an attractive solution
to this difficult situation. Among them Wiktionary
seems to be the perfect resource for building com-
putational mono-lingual and multi-lingual lexica.
This paper focuses therefore on Wiktionary, how
to improve it, and on its exploitation for creating
resources.
In next section, we present some relevant infor-
mation about Wiktionary. Section 3 presents the
lexical graphs we are using and the way we build
them. Then we pay some attention to evaluation
(?4) before exploring some tracks of improvement
suggested by Wiktionary structure itself.
2 Wiktionary
As previously said, NLP suffers from a lack of
lexical resources, be it due to the low-quality or
non-existence of such resources, or to copyrights-
related problems. As an example, we consider
French language resources. Jacquin et al (2002)
highlighted the limitations and inconsistencies
from the French EuroWordnet. Later, Sagot and
Fi?er (2008) explained how they needed to re-
course to PWN, BalkaNet (Tufis, 2000) and other
resources (notably Wikipedia) to build WOLF, a
free French WordNet that is promising but still a
very preliminary resource. Some languages are
straight-off purely under-resourced.
The Web as Corpus initiative arose (Kilgarriff
and Grefenstette, 2003) as an attempt to design
tools and methodologies to use the web for over-
coming data sparseness (Keller and Lapata, 2002).
Nevertheless, this initiative raised non-trivial tech-
nical problems described in Baroni et al (2008).
Moreover, the web is not structured enough to eas-
ily and massively extract semantic relations.
In this context, Wiktionary could appear to be
a paradisiac playground for creating various lexi-
19
cal resources. We describe below the Wiktionary
resource and we explain the restrictions and prob-
lems we are facing when trying to exploit it. This
description may complete few earlier ones, for ex-
ample Zesch et al (2008a).
2.1 Collaborative editing
Wiktionary, the lexical companion to Wikipedia,
is a collaborative project to produce a free-content
multilingual dictionary.
1
As the other Wikipedia?s
satellite projects, the resource is not experts-led,
rather filled by any kind of users. The might-be
inaccuracy of the resulting resource has lengthily
been discussed and we will not debate it: see Giles
(2005) and Britannica (2006) for an illustration
of the controversy. Nevertheless, we think that
Wiktionary should be less subject (so far) than
Wikipedia to voluntary misleading content (be it
for ideological, commercial reasons, or alike).
2.2 Articles content
As one may expect, a Wiktionary article
2
may (not
systematically) give information on a word?s part
of speech, etymology, definitions, examples, pro-
nunciation, translations, synonyms/antonyms, hy-
pernyms/hyponyms, etc.
2.2.1 Multilingual aspects
Wiktionary?s multilingual organisation may be
surprising and not always meet one?s expectations
or intuitions. Wiktionaries exist in 172 languages,
but we can read on the English language main
page, ?1,248,097 entries with English definitions
from over 295 languages?. Indeed, a given wik-
tionary describes the words in its own language
but also foreign words. For example, the English
article moral includes the word in English (adjec-
tive and noun) and Spanish (adjective and noun)
but not in French. Another example, boucher,
which does not exist in English, is an article of the
English wiktionary, dedicated to the French noun
(a butcher) and French verb (to cork up).
A given wiktionary?s ?in other languages? left
menu?s links, point to articles in other wiktionar-
ies describing the word in the current language.
For example, the Fran?ais link in the dictionary
article of the English wiktionary points to an arti-
cle in the French one, describing the English word
dictionary.
1
http://en.wiktionary.org/
2
What article refers to is more fuzzy than classical entry
or acceptance means.
2.2.2 Layouts
In the following paragraph, we outline wik-
tionary?s general structure. We only consider
words in the wiktionary?s own language.
An entry consists of a graphical form and a cor-
responding article that is divided into the follow-
ing, possibly embedded, sections:
? etymology sections separate homonyms when
relevant;
? among an etymology section, different parts
of speech may occur;
? definitions and examples belong to a part of
speech section and may be subdivided into sub-
senses;
? translations, synonyms/antonyms and hy-
pernyms/hyponyms are linked to a given part of
speech, with or without subsenses distinctions.
In figure 1 is depicted an article?s layout example.
Figure 1: Layout of boot article (shortened)
About subsenses, they are identified with an in-
dex when first introduced but they may appear as
a plain text semantic feature (without index) when
used in relations (translations, synonyms, etc.). It
is therefore impossible to associate the relations
arguments to subsenses. Secondly, subsense index
appears only in the current word (the source of the
relation) and not in the target word?s article it is
linked to (see orange French N. and Adj., Jan. 10,
2008
3
).
A more serious issue appears when relations are
shared by several parts of speech sections. In Ital-
3
http://fr.wiktionary.org/w/index.php?
title=orange&oldid=2981313
20
ian, both synonyms and translations parts are com-
mon to all words categories (see for example car-
dinale N. and Adj., Apr. 26, 2009
4
).
2.3 Technical issues
As Wikipedia and the other Wikimedia Founda-
tion?s projects, the Wiktionary?s content manage-
ment system relies on the MediaWiki software
and on the wikitext. As stated in Wikipedia?s
MetaWiki article, ?no formal syntax has been de-
fined? for the MediaWiki and consequently it is
not possible to write a 100% reliable parser.
Unlike Wikipedia, no HTML dump is available
and one has to parse the Wikicode. Wikicode
is difficult to handle since wiki templates require
handwritten rules that need to be regularly up-
dated. Another difficulty is the language-specific
encoding of the information. Just to mention one,
the target language of a translation link is iden-
tified by a 2 or 3 letters ISO-639 code for most
languages. However in the Polish wiktionary the
complete name of the language name (angielski,
francuski, . . . ) is used.
2.4 Parsing and modeling
The (non-exhaustive) aforementioned list of diffi-
culties (see ?2.2.2 and ?2.3) leads to the following
consequences:
? Writing a parser for a given wiktionary is
possible only after an in-depth observation of its
source. Even an intensive work will not prevent
all errors as long as (i) no syntax-checking is made
when editing an article and (ii) flexibility with the
?tacitly agreed? layout conventions is preserved.
Better, flexibility is presented as a characteristic of
the framework:
?[. . . ] it is not a set of rigid rules. You may
experiment with deviations, but other editors
may find those deviations unacceptable, and
revert those changes. They have just as much
right to do that as you have to make them.
5
?
Moreover, a parser has to be updated every new
dump, as templates, layout conventions (and so
on) may change.
?Writing parsers for different languages is not a
simple adjustment, rather a complete overhaul.
? When extracting a network of semantic rela-
tions from a given wiktionary, some choices are
more driven by the wiktionary inner format than
scientific modelling choices. An illustration fol-
4
http://it.wiktionary.org/w/index.php?
title=cardinale&oldid=758205
5
http://en.wiktionary.org/wiki/WT:ELE
lows in ?3.2. When merging information extracted
from several languages, the homogenisation of the
data structure often leads to the choice of the poor-
est one, resulting in a loss of information.
2.5 The bigger the better?
Taking advantage of colleagues mastering various
languages, we studied the wiktionary of the fol-
lowing languages: French, English, German, Pol-
ish and Mandarin Chinese. A first remark con-
cerns the size of the resource. The official num-
ber of declared articles in a given wiktionary in-
cludes a great number of meta-articles which are
not word entries As of April 2009, the French wik-
tionary reaches the first rank
6
, before the English
one. This can be explained by the automated im-
port of public-domain dictionaries articles (Littr?
1863 and Dictionnaire de l?Acad?mie Fran?aise
1932-1935). Table 1 shows the ratio between the
total number of articles and the ?relevant? ones
(numbers based on year 2008 snapshots).
Total Meta
?
Other
??
Relevant
fr 728,266 25,244 369,948 337,074 46%
en 905,963 46,202 667,430 192,331 21%
de 88,912 7,235 49,672 32,005 36%
pl 110,369 4,975 95,241 10,153 9%
zh 131,752 8,195 112,520 1,037 0.7%
?
templates definitions, help pages, user talks, etc.
??
other languages, redirection links, etc.
Table 1: Ratio of ?relevant? articles in wiktionaries
By ?relevant?, we mean an article about a word
in the wiktionary?s own language (e.g. not an
article about a French word in the English Wik-
tionary). Among the ?relevant? articles, some
are empty and some do not contain any transla-
tion nor synonym link. Therefore, before deciding
to use Wiktionary, it is necessary to compare the
amount of extracted information contribution and
the amount of work required to obtain it .
3 Study of synonymy networks
In this section, we study synonymy networks built
from different resources. First, we introduce
some general properties of lexical networks (?3.1).
Then we explain how we build Wiktionary?s syn-
onymy network and how we analyse its proper-
ties. In ?3.3, we show how we build similar graphs
from traditional resources for evaluation purposes.
3.1 Structure of lexical networks
In the following sections, a graph G = (V,E)
is defined by a set V of n vertices and a set
E ? V
2
of m edges. In this paper, V is
6
http://meta.wikimedia.org/wiki/List_
of_Wiktionaries
21
a set of words and E is defined by a relation
E
R
7?? E : (w
1
, w
2
) ? E if and only if w
1
R
? w
2
.
Most of lexical networks, as networks extracted
from real world, are small worlds (SW) net-
works. Comparing structural characteristics of
wiktionary-based lexical networks to some stan-
dard resource should be done according to well-
known properties of SW networks (Watts and
Strogatz, 1998; Barabasi et al, 2000; Newman,
2003; Gaume et al, 2008). These properties are:
? Edge sparsity: SW are sparse in edges
m = O(n) or m = O(n log(n))
? Short paths: in SW, the average path length
(L)
7
is short. Generally there is at least one short
path between any two nodes.
? High clustering: in SW, the clustering coef-
ficient (C) that expresses the probability that two
distinct nodes adjacent to a given third one are ad-
jacent, is an order of magnitude higher than for
Erdos-Renyi (random) graphs: C
SW
 C
random
;
this indicates that the graph is locally dense, al-
though it is globally sparse.
?Heavy-tailed degree distribution: the distri-
bution of the vertices incidence degrees follows a
power law in a SW graph. The probability P (k)
that a given node has k neighbours decreases as a
power law, P (k) ? k
a
(a being a constant charac-
teristic of the graph). Random graphs conforms to
a Poisson Law.
3.2 Wiktionary?s network
Graph extraction Considering what said in
?2.2.2 and ?2.4, we made the following choices:
8
? Vertices: a vertex is built for each entry?s part
of speech.
? Parts of speech: when modeling the links
from X (X having for part of speech Pos
X
) to
one of its synonyms Y , we assume that Pos
Y
=
Pos
X
, thus building vertex Pos
Y
.Y.
? Subsenses: subsenses are flattened. First, the
subsenses are not always mentioned in the syn-
onyms section. Second, if we take into account
the subsenses, they only appear in the source of the
relation. For example, considering in figure 1 the
relation boot
syn
??? kick (both nouns), and given the
10 subsenses for boot and the 5 ones for kick, we
should build 15 vertices. And we should then add
7
Average length of the shortest path between any two
nodes.
8
These choices can clearly be discussed from a linguis-
tic point of view and judged to be biased. Nevertheless, we
adopted them as a first approximation to make the modelling
possible.
all the links between the mentioned boot?s sub-
senses and the 5 kick?s existing subsenses. This
would lead to a high number of edges, but the
graph would not be closer to the reality. The way
subsenses appear in Wiktionary are unpredictable.
"Subsenses" correspond sometimes to homonyms
or clear-cut senses of polysemous words, but can
also correspond to facets, word usage or regu-
lar polysemy. Moreover, some entries have no
subsenses distinction whereas it would be wor-
thy. More globally, the relevance of discrete word
senses has been seriously questioned, see (Victorri
and Fuchs, 1996) or (Kilgarriff, 1997) for very
convincing discussions. Two more practical rea-
sons led us to this choice. We want our method to
be reproducible for other languages and some wik-
tionaries do not include subsenses. At last, some
gold standard resources (eg. Dicosyn) have their
subsenses flattened too and we want to compare
the resources against each other.
? Edges: wiktionary?s synonymy links are ori-
ented but we made the graph symmetric. For ex-
ample, boot does not appear in kick?s synonyms.
Some words even appear as synonyms without be-
ing an entry of Wiktionary.
From the boot example (figure 1), we extract ver-
tices {N.boot, V.boot}, build {N.buskin,
N.kick, V.kick} and we add the follow-
ing (symmetrized) edges: N.boot?N.buskin,
N.boot?N.kick and V.boot?V.kick.
Graph properties By observing the table 2, we
can see that the graphs of synonyms extracted
from Wiktionary are all typical small worlds. In-
deed their l
lcc
remains short, their C
lcc
is always
greater or equal than 0.2 and their distribution
curves of the vertices incidence degree is very
close to a power law (a least-square method gives
always exponent a
lcc
? ?2.35 with a confidence
r
2
lcc
always greater than 0.89). It can also be seen
that the average incidence k
lcc
ranges from 2.32
to 3.32.
9
It means that no matter which language
9
It is noteworthy that the mean incidence of vertices is al-
most always the same (close to 2.8) no matter the graph size
is. If we assume that all wiktionary?s graphs grow in a similar
way but at different speed rates (after all it is the same frame-
work), graphs (at least their statistical properties) from differ-
ent languages can be seen as snapshots of the same graph at
different times. This would mean that the number of graphs
edges tends to grow proportionally with the number of ver-
tices. This fits with the dynamic properties of small worlds
(Steyvers and Tenenbaum, 2005). It means that for a wik-
tionary system, even with many contributions, graph density
is likely to remain constant and we will see that in compar-
ison to traditional lexical resources this density is quite low.
22
graph n m n
lcc
m
lcc
k
lcc
l
lcc
C
lcc
a
lcc
r
2
lcc
fr-N 18017 9650 3945 4690 2.38 10.18 0.2 -2.03 0.89
fr-A 5411 2516 1160 1499 2.58 8.86 0.23 -2.04 0.95
fr-V 3897 1792 886 1104 2.49 9.84 0.21 -1.65 0.91
en-N 22075 11545 3863 4817 2.49 9.7 0.24 -2.31 0.95
en-A 8437 4178 2486 3276 2.64 8.26 0.2 -2.35 0.95
en-V 6368 3274 2093 2665 2.55 8.33 0.2 -2.01 0.93
de-N 32824 26622 12955 18521 2.86 7.99 0.28 -2.16 0.93
de-A 5856 6591 3690 5911 3.2 6.78 0.24 -1.93 0.9
de-V 5469 7838 4574 7594 3.32 5.75 0.23 -1.92 0.9
pl-N 8941 4333 2575 3143 2.44 9.85 0.24 -2.31 0.95
pl-A 1449 731 449 523 2.33 7.79 0.21 -1.71 0.94
pl-V 1315 848 601 698 2.32 5.34 0.2 -1.61 0.92
n: number of vertices m: number of edges
k: avg. number of neighbours per vertex l: avg. path length between vertices
C: clustering rate a: power law exponent with r
2
confidence
_
lcc
: denotes on largest connected component
Table 2: Wiktionary synonymy graphs properties
or part of speech, m = O(n) as for most of SW
graphs (Newman, 2003; Gaume et al, 2008).
3.3 Building synonymy networks from
known standards
WordNet There are many possible ways for
building lexical networks from PWN. We tried
several methods but only two of them are worth
to be mentioned here. The graphs we built have
words as vertices, not synsets or senses. A first
straightforward method (method A) consists in
adding an edge between two vertices only if the
corresponding words appear as elements of the
same synset. This method produced many discon-
nected graphs of various sizes. Both the compu-
tational method we planned to use and our intu-
itions about such graphs were pointing towards a
bigger graph that would cover most of the lexical
network.
We therefore decided to exploit the hypernymy
relation. Traditional dictionaries indeed propose
hypernyms when one look for synonyms of very
specific terms, making hypernymy the closest re-
lation to synonymy at least from a lexicographic
viewpoint. However, adding all the hypernymy re-
lations resulted in a network extremely dense in
edges with some vertices having a high number of
neighbours. This was due to the tree-like organi-
sation of WordNet that gives a very special impor-
tance to higher nodes of the tree.
In the end we retained method B that consists in
adding edges in following cases:
? if two words belong to the same synset;
? if a word only appears in a synset that is a leaf
of the tree and contains only this word, then cre-
ate edges linking to words included in the hyper-
nym(s) synset.
We would like to study the evolution through time of wik-
tionaries, however this is outside the scope of this paper.
Therefore when a vertice w do not get any neigh-
bour according to method A, method B adds edges
linking w to words included in the hypernym(s)
synset of the synset {w}. We only added hyper-
nyms for the leaves of the tree in order to keep our
relations close to the synonymy idea. This idea has
already been exploited for some WordNet-based
semantic distances calculation taking into account
the depth of the relation in the tree (Leacock and
Chodorow, 1998).
Dicosyn graphs Dicosyn is a compilation of
synonym relations extracted from seven dictionar-
ies (Bailly, Benac, Du Chazaud, Guizot, Lafaye,
Larousse and Robert):
10
there is an edge r ? s if
and only if r and s have the same syntactic cate-
gory and at least one dictionary proposes s being
a synonym in the dictionary entry r. Then, each
of the three graphs (Nouns, Verbs, Adjectives) ob-
tained is made symmetric (dicosyn-fr-N, dicosyn-
fr-V and dicosyn-fr-A).
Properties of the graphs extracted Table 3
sums-up the structural properties of the synonyms
networks built from standard resources.
We can see that all the synonymy graphs ex-
tracted from PWN or Dicosyn are SW graphs.
Indeed their l
lcc
remains short, their C
lcc
is al-
ways greater or equal than 0.35 and their distri-
bution curves of the vertices incidence degree is
very close to a power law (a least-square method
gives always exponent a
lcc
near of ?2.30 with a
confidence r
2
lcc
always greater than 0.85). It can
also be observed that no matter the part of speech,
the average incidence of Dicosyn-based graphs is
always lower than WordNet ones.
10
Dicosyn has been first produced at ATILF, before being
corrected at CRISCO laboratory.
(http://elsap1.unicaen.fr/dicosyn.html)
23
graph n m n
lcc
m
lcc
k
lcc
l
lcc
C
lcc
a
lcc
r
2
lcc
pwn-en-N-A 117798 104929 12617 28608 4.53 9.89 0.76 -2.62 0.89
pwn-en-N-B 117798 168704 40359 95439 4.73 7.79 0.72 -2.41 0.91
pwn-en-A-A 21479 22164 4406 11276 5.12 9.08 0.75 -2.32 0.85
pwn-en-A-B 21479 46614 15945 43925 5.51 6.23 0.78 -2.09 0.9
pwn-en-V-A 11529 23019 6534 20806 6.37 5.93 0.7 -2.34 0.87
pwn-en-V-B 11529 40919 9674 39459 8.16 4.66 0.64 -2.06 0.91
dicosyn-fr-N 29372 100759 26143 98627 7.55 5.37 0.35 -2.17 0.92
dicosyn-fr-A 9452 42403 8451 41753 9.88 4.7 0.37 -1.92 0.92
dicosyn-fr-V 9147 51423 8993 51333 11.42 4.2 0.41 -1.88 0.91
Table 3: Gold standard?s synonymy graphs properties
4 Wiktionary graphs evaluation
Coverage and global SW analysis By compar-
ing tables 2 and 3, one can observe that:
? The lexical coverage of Wiktionary-based syn-
onyms graphs is always quantitatively lower than
those of standard resources although this may
change. For example, to horn (in PWN), absent
from Wiktionary in 2008, appeared in 2009. At
last, Wiktionary is more inclined to include some
class of words such as to poo (childish) or to
prefetch, to google (technical neologisms).
? The average number of synonyms for an en-
try of a Wiktionary-based resource is smaller than
those of standard resources. For example, com-
mon synonyms such as to act/to play appear in
PWN and not in Wiktionary. Nevertheless, some
other appear (rightly) in Wiktionary: to reduce/to
decrease, to cook/to microwave.
? The clustering rate of Wiktionary-based
graphs is always smaller than those of standard re-
sources. This is particularly the case for English.
However, this specificity might be due to differ-
ences between the resources themselves (Dicosyn
vs. PWN) rather than structural differences at the
linguistic level.
Evaluation of synonymy In order to evaluate
the quality of extracted synonymy graphs from
Wiktionary, we use recall and precision measure.
The objects we compare are not simple sets but
graphs (G = (V ;E)), thus we should compare
separately set of vertices (V ) and set of edges (E).
Vertices are words and edges are synonymy links.
Vertices evaluation leads to measure the resource
(a) English Wiktionary vs. Wordnet
Precision Recall
Nouns 14120/22075 = 0.64 14120/117798 = 0.12
Adj. 5874/8437 = 0.70 5874/21479 = 0.27
Verbs 5157/6368 = 0.81 5157/11529 = 0.45
(b) French Wiktionary vs. Dicosyn
Precision Recall
Nouns 10393/18017 = 0.58 10393/29372 = 0.35
Adj. 3076/5411 = 0.57 3076/9452 = 0.33
Verbs 2966/3897 = 0.76 2966/9147 = 0.32
Table 4: Wiktionary coverage
coverage whereas edges evaluation leads to mea-
sure the quality of the synonymy links in Wik-
tionary resource.
First of all, the global picture (table 4) shows
clearly that the lexical coverage is rather poor. A
lot of words included in standard resources are not
included yet in the corresponding wiktionary re-
sources. Overall the lexical coverage is always
lower than 50%. This has to be kept in mind while
looking at the evaluation of relations shown in ta-
ble 5. To compute the relations evaluation, each
resource has been first restricted to the links be-
tween words being present in each resource.
About PWN, since every link added with
method A will also be added with method B, the
precision of Wiktionary-based graphs synonyms
links will be always lower for "method A graphs"
than for "method B graphs". Precision is rather
good while recall is very low. That means that a
lot of synonymy links of the standard resources
are missing within Wiktionary. As for Dicosyn,
the picture is similar with even better precision but
very low recall.
5 Exploiting Wiktionary for improving
Wiktionary
As seen in section 4, Wiktionary-based resources
are very incomplete with regard to synonymy. We
propose two tasks for adding some of these links:
Task 1: Adding synonyms to Wiktionary by
taking into account its Small World characteristics
for proposing new synonyms.
(a) English wiktionary vs. Wordnet
Precision Recall
Nouns (A) 2503/6453 = 0.39 2503/11021 = 0.23
Nouns (B) 2763/6453 = 0.43 2763/18440 = 0.15
Adj. (A) 786/3139 = 0.25 786/5712 = 0.14
Adj. (B) 1314/3139 = 0.42 1314/12792 = 0.10
Verbs (A) 866/2667 = 0.32 866/10332 = 0.08
Verbs (B) 993/2667 = 0.37 993/18725 = 0.05
(b) French wiktionary vs. Dicosyn
Precision Recall
Nouns 3510/5075 = 0.69 3510/44501 = 0.08
Adj. 1300/1677 = 0.78 1300/17404 = 0.07
Verbs 899/1267 = 0.71 899/23968 = 0.04
Table 5: Wiktionary synonymy links precision & recall
24
Task 2: Adding synonyms to Wiktionary by
taking into account the translation relations.
We evaluate these two tasks against the bench-
marks presented in section 3.2.
5.1 Improving synonymy in Wiktionary by
exploiting its small world structure
We propose here to enrich synonymy links of Wik-
tionary by taking into account that lexical net-
works have a high clustering coefficient. Our hy-
pothesis is that missing links in Wiktionary should
be within clusters.
A high clustering coefficient means that two
words which are connected to a third one are likely
to be connected together. In other words neigh-
bours of my neighbours should also be in my
neighbourhood. We propose to reverse this prop-
erty to the following hypothesis: "neighbour of my
neighbours which are not in my neighbourhood
should be a good neighbour candidate". Thus the
first method we test consist simply in connecting
every vertex to neighbours of its neighbours. One
can repeat this operation until the expected num-
ber of edges is obtained.
11
Secondly we used the PROX approach pro-
posed by (Gaume et al, 2009). It is a stochastic
method designed for studying ?Hierarchical Small
Worlds?. Briefly put, for a given vertex u, one
computes for all other vertices v the probability
that a randomly wandering particle starting from
u stands in v after a fixed number of steps. Let
P (u, v) be this value. We propose to connect u
to the k first vertices ranked in descending order
with respect of P (u, v). We always choose k pro-
portionally to the original degree of u (number of
neighbours of u).
For a small number of steps (3 in our case) ran-
dom wanderings tend to be trapped into local clus-
ter structures. So a vertex v with a high P (u, v) is
likely to belong to the same cluster as u, which
means that a link u?v might be relevant.
Figure 2 shows precision, recall and f-score
evolution for French verbs graph when edges are
added using ?neighourhood? method (neigh), and
using ?Prox? method. Dashed line correspond to
the value theoretically obtained by choosing edges
at random. First, both methods are clearly more
efficient than a random addition, which is not sur-
prising but it seems to confirm our hypothesis that
missing edges are within clusters. Adding sharply
11
We repeat it only two times, otherwise the number of
added edges is too large.
0 2000 4000 6000 8000 10000 12000 140000.0
0.10.2
0.30.4
0.50.6
0.70.8
P
prox3neighrandom
0 2000 4000 6000 8000 10000 12000 140000.03
0.040.05
0.060.07
0.080.09
R
0 2000 4000 6000 8000 10000 12000 140000.05
0.060.07
0.080.09
0.100.11
0.120.13
F
fr.V
Figure 2: Precision, recall and F-score of French verbs
graph enlarged using only existing synonymy links
neighbours of neighbours seems to be as good as
adding edges ranked by Prox, anyway the rank
provided by Prox permits to add a given number
of edges. This ranking can also be useful to order
potential links if one think about a user validation
system. Synonyms added by Prox and absent from
gold standards are not necessarily false.
For example Prox proposes a relevant link ab-
solve/forgive, not included in PWN. Moreover,
many false positive are still interesting to consider
for improving the resource. For example, Prox
adds relations such as hypernyms (to uncover/to
peel) or inter-domain ?synonyms? (to skin/to peel).
This is due to high clustering (see ?3.1) and to
the fact that clusters in synonymy networks corre-
lates with language concepts (Gaume et al, 2008;
Duvignau and Gaume, 2008; Gaume et al, 2009;
Fellbaum, 1999).
Finally note that results are similar for other
parts of speech and other languages.
5.2 Using Wiktionary?s translation links to
improve its synonymy network
Assuming that two words sharing many transla-
tions in different languages are likely to be syn-
onymous, we propose to use Wiktionary?s transla-
tion links to enhance the synonymy network of a
given language.
In order to rank links to be potentially added,
we use a simple Jaccard measure: let T
w
be the set
of a word w?s translations, then for every couple
of words (w,w
?
) we have:
Jaccard(w,w
?
) =
|T
w
? T
w
?
|
|T
w
? T
w
?
|
We compute this measure for every possible pair
of words and then, starting from Wiktionary?s syn-
onymy graph, we incrementally add links accord-
ing to their Jaccard rank.
25
We notice first that most of synonymy links
added by this method were not initially included
in Wiktionary?s synonymy network. For exam-
ple, regarding English verbs, 95% of 2000 best
ranked proposed links are new. Hence this method
may be efficient to improve graph density. How-
ever one can wonder about the quality of the new
added links, so we discuss precision in the next
paragraph.
In figure 3 is depicted the evolution of precision,
recall and F-score for French verbs in the enlarged
graph in regard of the total number of edges. We
use Dicosyn graph as a gold standard. The dashed
line corresponds to theoretical scores one can ex-
pect by adding randomly chosen links.
First we notice that both precision and recall
are significantly higher than we can expect from
random addition. This confirms that words shar-
ing the same translations are good synonym candi-
dates. Added links seem to be particularly relevant
at the beginning for higher Jaccard scores. From
the first dot to the second one we add about 1000
edges (whereas the original graph contains 1792
edges) and the precision only decreases from 0.71
to 0.69.
The methods we proposed in this section are
quite simple and there is room for improvement.
First, both methods can be combined in order
to improve the resource using translation links
and then using clusters structure. One can also
think to the corollary task that would consists in
adding translation links between two languages
using synonymy links of others languages.
0 2000 4000 6000 8000 10000 120000.0
0.10.2
0.30.4
0.50.6
0.70.8
P
random
0 2000 4000 6000 8000 10000 120000.02
0.040.06
0.080.10
0.120.14
0.16
R
0 2000 4000 6000 8000 10000 120000.04
0.060.08
0.100.12
0.140.16
0.180.20
0.22
F
fr.V
Figure 3: Precision, recall and F-score of French verbs
graph enlarged using translation links
6 Conclusion and future work
This paper gave us the opportunity to share some
Wiktionary experience related lexical resources
building. We presented in addition two approaches
for improving these resources and their evaluation.
The first approach relies on the small world struc-
ture of synonymy networks. We postulated that
many missing links in Wiktionary should be added
among members of the same cluster. The second
approach assumes that two words sharing many
translations in different languages are likely to be
synonymous. The comparison with traditional re-
sources shows that our hypotheses are confirmed.
We now plan to combine both approaches.
The work presented in this paper combines a
NLP contribution involving data extraction and
rough processing of the data and a mathematical
contribution concerning graph-like resource. In
our viewpoint the second aspect of our work is
therefore complementary of other NLP contribu-
tions, like (Zesch et al, 2008b), involving more
sophisticated NLP processing of the resource.
Support for collaborative editing Our results
should be useful for setting up a more efficient
framework for Wiktionary collaborative editing.
We should be able to always propose a set of syn-
onymy relations that are likely to be. For exam-
ple, when a contributor creates or edits an arti-
cle, he may think about adding very few links but
might not bother providing an exhaustive list of
synonyms. Our tool can propose a list of potential
synonyms, ordered by relevancy. Each item of this
list would only need to be validated (or not).
Diachronic study An interesting topic for future
work is a "diachronic" study of the resource. It
is possible to access Wiktionary at several stages,
this can be used for studying how such resources
evolve. Grounded on this kind of study, one may
predict the evolution of newer wiktionaries and
foresee contributors? NLP needs. We would like
to set up a framework for everyone to test out new
methodologies for enriching and using Wiktionary
resources. Such observatory, would allow to fol-
low not only the evolution of Wiktionary but also
of Wiktionary-grounded resources, that will only
improve thanks to steady collaborative develop-
ment.
Invariants and variabality Wiktionary as a
massively mutiligual synonymy networks is an
extremely promising resource for studying the
(in)variability of semantic pairings such as
house/family, child/fruit, feel/know... (Sweetser,
1991; Gaume et al, 2009). A systematic study
within the semantic approximation framework
presented in the paper on Wiktionary data will be
carried on in the future.
26
References
A-L. Barabasi, R. Albert, H. Jeong, and G. Bianconi.
2000. Power-Law Distribution of the World Wide
Web. Science, 287. (in Technical Comments).
M. Baroni, F. Chantree, A. Kilgarriff, and S. Sharoff.
2008. Cleaneval: a Competition for Cleaning
Web Pages. In Proceedings of the Conference on
Language Resources and Evaluation (LREC), Mar-
rakech.
Encyclopaedia Britannica. 2006. Fatally flawed: re-
futing the recent study on encyclopedic accuracy by
the journal Nature.
K. Duvignau and B. Gaume. 2008. Between words
and world: Verbal "metaphor" as semantic or prag-
matic approximation? In Proceedings of Interna-
tional Conference "Language, Communication and
Cognition", Brighton.
C. Fellbaum, editor. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
C. Fellbaum. 1999. La repr?sentation des verbes
dans le r?seau s?mantique Wordnet. Langages,
33(136):27?40.
B. Gaume, K. Duvignau, L. Pr?vot, and Y. Desalle.
2008. Toward a cognitive organization for electronic
dictionaries, the case for semantic proxemy. In Col-
ing 2008: Proceedings of the Workshop on Cogni-
tive Aspects of the Lexicon (COGALEX 2008), pages
86?93, Manchester.
B. Gaume, K. Duvignau, and M. Vanhove. 2009. Se-
mantic associations and confluences in paradigmatic
networks. In M. Vanhove, editor, From Polysemy to
Semantic Change: Towards a Typology of Lexical
Semantic Associations, pages 233?264. John Ben-
jamins Publishing.
J. Giles. 2005. Internet encyclopaedias go head to
head. Nature, 438:900?901.
C. Jacquin, E. Desmontils, and L. Monceaux. 2002.
French EuroWordNet Lexical Database Improve-
ments. In Proceedings of the Third International
Conference on Intelligent Text Processing and Com-
putational Linguistics (CICLING 2002), Mexico
City.
F. Keller and M. Lapata. 2002. Using the web to over-
come data sparseness. In Proceedings of EMNLP-
02, pages 230?237.
A. Kilgarriff and G. Grefenstette. 2003. Introduction
to the special issue on the web as corpus. Computa-
tional Linguistics, 29:333?347.
A. Kilgarriff. 1997. I don?t believe in word senses.
Computers and the humanities, 31(2):91?113.
C. Leacock and M. Chodorow. 1998. Combining local
context and wordnet similarity for word sense iden-
tification. In C. Fellbaum, editor, WordNet: An elec-
tronic lexical database, pages 265?283. MIT Press.
M. Newman. 2003. The structure and function of com-
plex networks.
B. Sagot and D. Fi?er. 2008. Building a Free French
Wordnet from Multilingual Resources. In Proceed-
ings of OntoLex 2008, Marrackech.
M. Steyvers and J. B. Tenenbaum. 2005. The large-
scale structure of semantic networks: Statistical
analyses and a model of semantic growth. Cogni-
tive Science, 29:41?78.
E. Sweetser. 1991. From etymology to pragmatics.
Cambridge University Press.
D. Tufis. 2000. Balkanet design and development of a
multilingual balkan wordnet. Romanian Journal of
Information Science and Technology, 7(1-2).
B. Victorri and C. Fuchs. 1996. La polys?mie, con-
struction dynamique du sens. Herm?s.
D.J. Watts and S.H. Strogatz. 1998. Collective dynam-
ics of small-world networks. Nature, 393:440?442.
T. Zesch, C. M?ller, and I. Gurevych. 2008a. Extract-
ing Lexical Semantic Knowledge from Wikipedia
and Wiktionary. In Proceedings of the Conference
on Language Resources and Evaluation (LREC),
Marrakech.
T. Zesch, C. Muller, and I. Gurevych. 2008b. Using
wiktionary for computing semantic relatedness. In
Proceedings of 23rd AAAI Conference on Artificial
Intelligence.
27
Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 86?93
Manchester, August 2008
Toward a cognitive organization for electronic dictionaries, the case for
semantic proxemy
Bruno Gaume, Karine Duvignau, Laurent Pr?vot, Yann Desalle
Universit? de Toulouse, CNRS
{gaume,duvignau,prevot,desalle}@univ-tlse2.fr
Abstract
We compare a psycholinguistic approach
of mental lexicon organization with a com-
putational approach of implicit lexical or-
ganization as found in dictionaries. In this
work, we associate dictionaries with ?small
world? graphs. This multidisciplinary ap-
proach aims at showing that implicit struc-
ture of dictionaries, mathematically iden-
tified, fits the way young children catego-
rize. These dictionary graphs might there-
fore be considered as ?cognitive artifacts?.
This shows the importance of semantic
proximity both in cognitive and computa-
tional organization of verbs lexicon.
1 Introduction
According to (Dik, 1991) a linguistic theory
should be compatible with psycholinguistic re-
search on language acquisition, treatment, pro-
duction, interpretation and memorization of lin-
guistic expressions. We agree with this view and
postulate that elaborating electronic dictionaries
on the ground of a linguistic theory, satisfying
Dik?s principle, will confer them good ergonomics
that will increase their usability. Our approach is
to some extent comparable to WordNet initiative
(Fellbaum, 1998), in the sense that we are trying
to characterize speakers? mental lexicon.
In this paper, we focus on verb lexical orga-
nization through the examination of verbal pivot
metaphorical utterances (VPMU). Such utterances
involve an understudied structural aspect of the
lexicon: interdomain co-hyponymy (Duvignau,
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
2002; Duvignau and Gaume, 2008). In this
context, we take semantic proximity as a cen-
tral principle for cognitive ergonomics influenc-
ing dynamic lexical acquisition and adult lexical
organization. VPMU generally consists in substi-
tuting elements from different semantic domains.
They are usually considered as deviants while they
might constitute a linguistic illustration of the cat-
egorial flexibility advocated in (Piaget, 1945; Ny,
1979; Hofstadter, 1995). They might therefore
reveal an early lexical structuring mode that may
form a ground for improving electronic dictionar-
ies.
This paper presents a mathematical method able
to discover the areas in which this structuring
mode appears in dictionaries. Our approach is to
take advantage of the mathematical structure of the
network generated by verb definitions. This struc-
ture has been mentioned in (Watts and Strogatz,
1998), studied for WordNet by (Sigman and Cec-
chi, 2002), refined in (Gaume et al, 2002) and ex-
ploited in the current proposal.
The paper is organized as follows. The next sec-
tion brings evidence of categorization by seman-
tic proximity from early lexicon acquisition ex-
periments. Section 3 presents the computational
model, hereafter ?proxemy?. Section 4 details our
work on lexical graphs while section 5 compares
the results of experimental studies with those of
the computational model.
2 Toward a categorization by semantic
proximity: evidences from early lexicon
acquisition
In order to show the importance of semantic ap-
proximation, we have chosen to support our claim
with productions observed at the crucial period
of lexical construction (between 2 and 4 years-of-
86
age) and to compare these with adult speakers that
have a stabilized lexicon.
2.1 Inter-domains vs. intra-domain semantic
approximations
Studies in this field are almost exclusively lim-
ited to nominal utterances. (Duvignau et al,
2005) established the existence of the production
of metaphor-like utterances with a verbal pivot in
2-4 years-old children and proposed to consider
them, at this stage of language development, as se-
mantic approximations and not as mistakes or true
metaphors. Duvignau distinguished two kinds of
semantic approximations: Inter-domains proxim-
ity and intra domain proximity between verbs (Du-
vignau, 2002).
- Inter-domains proximity / co-hyponymy be-
tween verbs : a ?linguistic approximation?
(1) Elle d?shabille l?orange (She undresses the
orange) [Age: 3 years] [movie: a lady peels
an orange]
In this category of approximation, the verb used
by the speaker constitutes a reference to a semantic
domain different from the one of element it is com-
bined to (?undress? / ?orange?). For this reason, the
approximate character of the verb is understand-
able independently of the context of the utterance:
detecting the approximation occurs at the linguis-
tic level. We call this type of production ?semantic
approximation?. They might constitute a metaphor
or an ?analogic surextention?.
When someone has a conventional verb in the
mental lexicon (?to peel?) and use a non conven-
tional but relevant verb like ?to undress the orange?
for the action [to peel the orange his verbal seman-
tic approximation constitutes a metaphor. On the
contrary when someone does not have a conven-
tional verb in the mental lexicon but manages to
use a non conventional but relevant verb in saying
?to undress? for this action, his verbal semantic ap-
proximation constitutes a ?surextension? but not an
error because of the lexical relation that links these
verbs. In fact, according to (Duvignau and Gaume,
2008) ?to undress? and ?to peel? are related by an
inter-domains synonymic relation.
- Intra-domain proximity / co-hyponymy be-
tween verbs: a ?pragmatic approximation? In
this category, illustrated by (2) the approximate
character of the verb comes only from a non-
correspondence between the verb used and the re-
ality it designates. This happens with utterances in
which the use of the verbal form does not create
any semantic tension within the utterance but des-
ignates a way of carrying out an activity that does
not correspond precisely to the action undertaken.
(2) Elle coupe l?orange (She cuts the or-
ange)[age: 3 years][movie: a lady peels an
orange]
We propose an experimental study of the produc-
tion of verbal semantic approximations like (2) or
(1) by way of a naming task of 17 action-movies
with young children (from 2 to 4 years old). We
compare their performances with adult?s ones.
2.2 Experimental Design
In order to elicit the production of semantic ap-
proximations we proposed to all our participants
an action-video naming task. The population sam-
ple consisted of:
? 54 non-disturbed children (2-4 years old),
monolingual in French
? 77 non-disturbed young adults (18-40 years
old), monolingual in French
The action movies sequences are coming from the
Approx protocol (Duvignau et al, 2005). The ma-
terial consists in 17 action-movies sequences de-
scribed in table 1.
The 17 action movies are presented in random
order to each participant. Instructions were given
at the time the action in the movie was completed
and its results were visible (e.g when the glass is
broken). At that moment a question was asked
to the participant:?What did the woman do? (just
now)?
2.3 Results
Each of the children produced between 2 and 5 ap-
proximations: ?Elle casse la tomate? -She breaks a
tomato ? [action = to squash], ?Elle ?pluche le bois?
- She peels the wood? [action = to strip the bark off
a log]. Globally, children produced semantic ap-
proximations for 34 % of the naming tasks, which
were distributed as follows: 24 % intra-domain
semantic approximations, 10 % inter-domains se-
mantic approximations. They produced them sig-
nificantly more frequent than adults : 5 % with
4% intra-domain semantic approximations and 1
% inter-domains semantic approximations.
87
Table 1: Approx 17 action movies
The student Test shows the difference between
children and adults in terms of production of se-
mantic approximation is very significant: here p <
0, 01 while p < 0, 05 is enough.
These results signal the importance of seman-
tic approximations and of semantic proximity be-
tween verbs in the cognitive organization of verbs
lexicon.
In the rest of the paper we present a computa-
tional model of semantic proximity and then com-
pare this model with the experimental data ob-
tained from the children.
3 Proxemy: a computational approach
A theory of language useful for computational
work must account for language statistical regu-
larities. Zipf law (Zipf, 1949) satisfy this obser-
vation but provides little insight on lexical struc-
tural organization. More recent graph theory stud-
ies (Ferrer-i-Cancho and Sole, 2001; Sigman and
Cecchi, 2002), capitalizing on results in other sci-
entific domains, provided interesting contributions
to the establishment of such a theory of language.
All structures discovered in this field research sat-
isfy the ?hierarchical small word? (HSW) defini-
tion (see section 3.1). Our approach takes place in
this general framework. Our specificities are:
? a new linguistic and psycholinguistic insight
that guides us and help us on our results vali-
dation;
? the kind of objects studied (dictionaries);
? our analysis of graph structure resulting in
a computational model of semantic proxim-
ity among vertices (here vertices are French
verbs).
The study by (Resnik and Diab, 2000) signaled
that although existing models for verb similarity
performed reasonably well against human judg-
ments, none managed to handle certain types of
metaphorical pairs such as to undress / to peel off
that are nonetheless declared to be rather similar
by speakers. We aim to develop a model address-
ing this issue.
3.1 Small World Networks
Networks corresponding to structures found in real
world (henceforth real world networks) are sparse:
in a graph with n nodes, the maximum num-
ber of possible edges is O(n
2
) while the number
of edges in real networks is generally inferior to
O(nlog(n)). Watts and Strogatz (Watts and Stro-
gatz, 1998) proposed two indicators to characterize
a large sparse graph G:
? L : the characteristic path length, i.e the mean
of the shortest path between two nodes of G
? C : the clustering coefficient, C ? [0, 1], it
measures the graph tendency to host zones
very dense in edges. (The more clustered the
graph is, the more the graph?s C approaches
1, whereas in random graphs C is very close
to 0).
In applying these criteria to different types of
graphs, Watts and Strogatz found that:
? real world networks have a tendency to have
a small L: generally there is at least one short
path between any two nodes ;
? real world networks have a tendency to have
a large C: this reflects a relative tendency for
two neighbors on the same node to be inter-
connected;
? random graphs have a small L: If someone
builds a graph randomly with a density of
edges comparable to real world networks, it
will obtain graphs with a small L;
? random graphs have a small C: They are not
composed of aggregates. In a random graph
88
there is no reason why neighbors of a same
node are more likely to be connected than any
two other nodes, hence their poor tendency to
form aggregates.
Watts and Strogatz proposed to call the graphs
having these two characteristics (a small L and
a large C) small worlds (SW). They recognized
these SW in all the real world networks they ob-
served, and therefore postulated for being a SW
was an universal property of real world networks.
A complete presentation of Small Words can be
found, for example, in (Newman, 2003).
More recent research has shown that most SW
also have a hierarchical structure (hereafter hier-
archical small worlds, HSW ). The distribution
of the vertices incidence degrees follows a power
law. The probability P (k) that a given node has k
neighbors decreases as a power law, P (k) ? k
??
,
where ? is a constant characteristic of the graph
(Barab?si and Albert, 1999), while random graphs
conforms to a Poisson Law.
In the next section, we present ?proxemy?, a se-
mantic proximity measure based on a distance we
define. A interesting particularity of this distance
is to calculate the distance between two vertices on
the ground of the complete graph, and not only on
their direct neighbors.
3.2 The mathematical model
PROX (PROXemy) is a stochastic method de-
signed for studying ?Hierarchical Small Worlds?.
1
This method takes graph as input and transform
them in a Markov chain whose states are graph ver-
tices. Metaphorically, energy particles wander ran-
domly from vertex to vertex through the edges of
the graph. It is their trajectory dynamics that give
us the structural properties of the graph.
PROX takes a graph in input and output a simi-
larity measure between the vertices of the graph.
Our problem is therefore the opposite than the
one of Pathfinder networks (PFNETs see (Schvan-
eveldt et al, 1988)). PFNETs take a full proximity
matrix in input and output a sparse graph. Their
goal is to minimize the number of edges required
in the sparse graph to be able to approximate the
full distance matrix corresponding to the initial full
proximity matrix.
1
In this paper we will use the term ?proxemy? to refer to the
obtained by PROX algorithm. It corresponds to some kind of
semantic proximity.
PROX build a similarity measure between the
vertices. The hypothesis is that areas having a
high density in edges (hereafter, these areas will
be called aggregates) correspond to closely related
verb meanings (in a graph of verbs).
Given a graph with n vertices, G = (V,E), we
will note [G] the matrix n ? n such that ?r, s ?
V , [G]
r,s
= 0 if {r, s} 6? E and 1 otherwise. [G]
is called the adjacency matrix of G.
Given G = (V,E) a reflexive graph with n ver-
tices. [
?
G] is a n ? n matrix defined by ?r, s ?
V , [
?
G]
r,s
=
[G]
r,s
?
x?V
{[G]
r,x
}
. [
?
G] is the Markovian
matrix of G.
[
?
G] is the n ? n matrix is a transition matrix of
the homogeneous Markov chain whose states are
the vertices of the graph such that the probability
of going from one vertex r ? V at an instant t onto
another s ? V at the instant t+ 1 is equal to:
? 0 if {r, s} 6? E (s is not neighbor of r)
? 1/D if {r, s} ? E and r has D neighbors (s
is a neighbor of r)
2
Given G = (V,E) a reflexive graph with n ver-
tices and [
?
G] its Markovian matrix, ?r, s ? V,?t ?
N
?
, PROX(G, t, r, s) = [
?
G
t
]
r,s
PROX(G, t, r, s) is therefore the probability
for a particle departing from r at the instant zero
to be on s at the instant t.
Therefore when, PROX(G, t, r, s) >
PROX(G, t, r, u), the particle has more proba-
bility to be, at instant t on s than on u and it is
graph structure that determine these probabilities.
For the rest of this paper we will set the value
of t to 4 since L is less than 4 in the kind of
graph we are concerned with. Therefore, we take
into account the global graph simply by calculating
PROX(G; 4; r; s).
Now we have defined our model we will present
lexical graphs on which we apply it.
4 Lexical graphs
Several types of lexical graphs can be built accord-
ing to the type of the semantic relation used for
defining the graph?s edges. The two principal types
of relations used are:
2
In the context of this presentation of the model we do not
consider weighted graphs. However when building the graphs
we do consider information, such as the position of the word
in the definition, for giving weight to the edges.s
89
? Syntagmatic relationships, like co-occurrence
relationships: they define edges between
nodes corresponding to words found near to
each other in a corpus.
? Paradigmatic relationships, like synonymy:
they define, on the ground of lexical databases
such as WordNet (Fellbaum, 1998), edges be-
tween nodes of words being in a synonymy
relationship in such resource.
Moreover, we are interested into less spe-
cific relations, called semantic proximity relations
or semantic relatedness, and which covers both
paradigmatic and syntagmatic dimensions.
4.1 Dictionary graphs
Meaning in dictionary definition is at least partially
brought by the relations they create between the
words constituting the entries. Our approach con-
sists in exploiting the small word properties of the
graphs corresponding to dictionaries. More pre-
cisely, we are taking advantage of our hypothe-
sis that aggregates correspond to areas of closely
related senses. We illustrate our approach on
two kinds of dictionary, two traditional dictionar-
ies, Le Grand Robert
3
and TLFi
4
, and an syn-
onym dictionary (Dicosyn) made of compilation
of synonym relations extracted from seven other
dictionaries (Bailly, Benac, Du Chazaud, Guizot,
Lafaye, Larousse et Robert).
5
We create a graph from a dictionary in the fol-
lowing way. The entries constituted the vertices.
Edges between two vertices A and B were added
if and only if B appears in A?s lemmatized defini-
tion
6
as illustrated in Figure 4.1
We proceed in this way for each entry and ob-
tained a graph of the dictionary. By extracting the
subgraph composed only of verbs, the ?neighbor-
hood? we get for the verb ??corcer? is illustrated
by Figure 4.1. Then we render the graph sym-
metric and reflexive. These modifications on the
graphs are allowed thanks to its paradigmatic na-
ture. Graphs created in this way are typical small
3
A significant amount of work has been done to encode
?Le Grand Robert in a graph.
4
We would like to thank ATILF for making the TLFi re-
source available to us.
5
Dicosyn has been first realized at ATILF (Analyse
et Traitement Informatique de la Langue Fran?aise),
before being corrected at CRISCO laboratory
(http://elsap1.unicaen.fr/dicosyn.html).
6
Lemmatization has been realized
with TreeTagger (http://www.ims.uni-
stuttgart.de/projekte/corplex/TreeTagger/).
Figure 1: Sub-graph near ??corcer (to bark ? a
tree?)? from Le Grand Robert
world network. For example, DicoSyn-Verb has
9043 vertices and 50948 edges, its L is 4,1694 and
its C 0,3186.
Figure 2: Sub-graph of the verbs near ??corcer?
from Robert
(Duvignau, 2002) has shown that co-hyponymy
verb lexical organization according fits with a
power law distribution of incidence degrees. In our
opinion, (i) the hierarchical organization of dictio-
naries is a consequence of the special role of the
hypernymy relation together with the polysemy of
some specific vertices; (ii) the strong C reflects
the role of interdomain co-hyponyny (Duvignau,
2002; Duvignau and Gaume, 2003). For example,
in French language, ?casser (to break)? appears in
many definitions: ??mietter (to crumble)?, ?frag-
menter (to fragment)?, ?d?t?riorer (to damage)?,
?r?voquer (to dismiss)?, ?abroger (to abrogate)?.
This results in a very high incidence for the vertex
?casser (to break)?. Moreover, many triangles ex-
ist ( {casser, ?mietter, fragmenter}, {casser, r?vo-
quer, abroger}...,) and they help to create aggre-
gates. These areas that are bringing co-hyponyms
closer in the resulting graph.
4.2 Disambiguization for creation dictionary
graphs
Word Sense Disambiguation is a general issue for
natural language processing that we need to ad-
dress when we build our graphs. We need to
disambiguate the verbs we found in the defini-
tion facing a similar problem as (Harabagiu et
90
al., 1999). For example, in French dictionary Le
Grand Robert, there are two distinct entries for the
verb ?causer?: to cause (3) and to chat (4).
(3) CAUSER-1: ?tre la cause de. (to be the
cause of)
(4) CAUSER-2: S?entretenir famili?rement
avec qqn. to chat with
Of course, the word ?causer? may appear in other
definitions like ?bavarder? (to chat) . Although
a French speaker knows that the ?causer? in (5)
refers to the definition (4) our system for building
the graph cannot disambiguate. The solution we
propose is to (i) first create a fictive vertex which
is not a dictionary entry and then (ii) adds two
edges {CAUSER, CAUSER-1} and {CAUSER,
CAUSER-2 }. When ?causer? is found in another
definition like (5), we add the edge { BAVARDER,
CAUSER } as illustrated in Figure (5).
(5) BAVARDER ?Parler beaucoup, longtemps
ou parler ensemble de choses superfi-
cielles. - Parler; babiller, bavasser (fam.),
cailleter, caqueter, causer, discourir, dis-
cuter, jaboter, jacasser, jaser, jaspiner (ar-
got), lantiponner (vx), papoter, potiner.
Bavarder avec qqn ... ?
Figure 3: Disambiguation: ?Causer?, fictive vertice
In Figure (5), many edges are hidden for clarity
reasons. Dashed edges ({Discuter, Causer2}) re-
sult from the fact ?Discuter? and ?Parler? are in the
definition of ?Causer-2?.
At this stage, we apply PROX to such graph as
the one Figure (5) in order to get a matrix [
?
G
4
]
as defined in section 3.2. [
?
G
4
]
bavarder,causer?1
<
[
?
G
4
]
bavarder,causer?2
. This comparison allows us
to disambiguate.
More generally, let suppose we found a word
with k entries in a definition, we will then have
S
1
, . . . , S
k
vertices corresponding to the entries a
fictive vertex S. In case there is an edge {A,S}
it is replaced by {A,S
i
} where S
i
is such that
[
?
G
4
]
A,S
i
= MAX
0<i?k
{
?
G
4
]
A,S
i
}. Then we re-
move all fictive vertices from the graph to get a
disambiguated graph.
We can then apply PROX a last time on the
disambiguated graph in order to get the closest
word of a word according to our proxemy mea-
sure. For example, the PROX-closest words of
?corcer (to bark ?a tree?), calculated with t =
6 are: 1 ECORCER (to bark), 2 D?POUILLER
(strip), 3 PELER (peel), 4 TONDRE (mow, shear),
5 ?TER (remove), 6 ?PLUCHER (peel, pare),
7 RASER (shave), 8 D?MUNIR (divest), 9 D?-
CORTIQUER (decorticate), 10 ?GORGER (slit
the throat of), 11 ?CORCHER (skin), 12 ?CALER
(husk), 13 VOLER (steal), 14 TAILLER (prune), 15
R?PER (grate), 16 PLUMER (pluck), 17 GRAT-
TER (scrape), 18 ENLEVER (remove), 19 D?-
SOSSER (bone), 20 D?POSS?DER (dispossess),
21 COUPER (cut), 22 BRETAUDER (shear slop-
pily), 23 INCISER (incise), 24 GEMMER (tap), 25
D?MASCLER (remove first layer of cork)
7
5 Proxemy and Experimental studies
Prox is a robust method: changing randomly a
few edges does not change significantly the results.
The repartition of aggregates is not strongly af-
fected by a random redistribution of some edges.
However the relevance of our proxemy approach
of lexical networks is tied to the linguistic rep-
resentativity of the networks we use. Therefore,
we tested the PROX model of four different dictio-
nary graphs and we compared them to the psycho-
linguistic experimental results presented in section
2. The graph we compared were:
1. Graph.TLFI.Verb, a graph built as explained
in 4.1 from TLFi
8
dictionary,
2. Graph.Robert.Verb, a graph built as explained
in 4.1 from Le Grand Robert dictionary,
3. Graph.DicoSyn.Verb, in which there is a edge
between two verbs if there are given as syn-
7
Proposing a translation for such fine grained and some-
times polysemous words is impossible since proposing the
translation include a certain form of disambiguisation as it is
suggested by the work of (Gale et al, 1992).
8
http://atilf.atilf.fr/tlf.htm
91
onyms by one of the synonym dictionary
composing DicoSyn
4. Graph.DicoSyn_20 built from
Graph.DicoSyn but in which 20% of the
edges are randomly removed and re-added.
For each of these graphs we looked at two vari-
ables to be related with the psycho-linguistics ex-
periments: the answers incidence and the proxim-
ity of answers to a ?reference verb?
Answers incidence We compare in the graph the
average incidence degree between adult (ID
adult
)
and children answers (ID
children
).
Table 2: Results for ?Answers incidence?
The proximity of answers to a ?reference verb?
Three linguist judges determined together for each
movie which was the most appropriate verb to de-
scribe the action performed in the movie (hereafter
R
i
is the reference verb for the movie M
i
). For
a given movie M
i
, an answer may therefore be
ranked according to its proxemy according to R
i
.
For a lexical graph G = (V,E) composed of n
words, and for a reference verb R
i
? V , one can
define rank
Ri
for ranking all the vertices of V in
decreasing order resulting from a PROX iteration
PROX(G, t,Ri, ?) on V (see section 3.2).
Table 3: Proximity between answers and reference
verb
Our first hypothesis was that ID
adult
<
ID
children
. According to the hypothesis children
would learn first words corresponding to high in-
cidence vertices. Then they would use them for
talking about an large lexical area (e.g ?casser? (to
break) is used by children while adults use a more
precise verb like ?d?chirer? (to tear) which has a
lower incidence in dictionary graphs).
Our second hypothesis was that the mean of the
rank of the children answers according to the ref-
erence verb is higher that the adult ones. When a
child is attempting to communicate an event (e.g
d?chirer un livre, to tear a book) for which he does
not have an already constituted verbal category, he
would do an analogy with a past event (e.g to break
a glass) and use this verb for describing the cur-
rent event (e.g casser un livre, to break a book).
The adult could use a number of more accurate
verbs but their proxemic rank, with regard to the
reference verb, is generally lower than the children
ones.
The table 2 shows the results concerning an-
swers incidence. Although some variability is ob-
served across the graphs, our first hypothesis is val-
idated for the 4 graphs. On the three first graphs
the average incidence of answers is roughly twice
as the adults one.
The table 3 illustrates the results concerning
proxemic rank of answers according to the ref-
erence verb. Again, in spite of some variability
across the graphs our second hypothesis is vali-
dated as well. Moreover, having in mind that the
graph has about 10 000 vertices, we observe that
although less close that adults answers, the chil-
dren answers remain relatively close to the refer-
ence verb according to our proxemic measure.
6 Conclusion
Our psycholinguistic approach allows us to estab-
lish that semantic proximity between verbs play a
fundamental role during the period of early lexi-
cal acquisition. We signaled the existence in the
organization of the lexicon of a relation of co-
hyponymy between verbs. Based on these first
observations we consider that productions based
on semantic proximity are particularly interesting:
they manifest the existence, at the surface level of
discourse, of a lexical relation of inter-domain ?se-
mantic proximity? between verbs not yet consid-
ered in linguistics.
Moreover we have seen that semantic approxi-
mations for verbs appear to fit the proximity values
calculated by PROX. On the ground of these first
results, we postulate that constructing electronic
dictionaries on the ground of linguistic theory of
lexical semantic organization that fits with early
lexicon acquisition as well with adult lexical orga-
nization will provide them interesting ergonomics
properties. This should increase their usability and
92
might be taken into account for normalizing elec-
tronic dictionaries.
For example, we are developing a ?proxemic
electronic dictionary? from TLFi. Such dictionar-
ies enable to find an uncommon but precise verb
like ?to bark? by using (i) a common verb like ?to
undress? which is related to ?to bark? by seman-
tic proximity and (ii) a word (e.g ?tree?) bringing a
relevant semantic domain. Moreover, in the def-
inition of ?to bark? one can find: ?tree?, ?grain?
?fruit? which are close from each other accord-
ing to PROX ran on nouns. Finally, when we
look for verbs that are close from both ?to un-
dress? and ?tree?, PROX provides the verbs: ?to
cut, to ring, to peel, to notch, to bark, to incise,...?
which constitute relevant verbs. Such a dictio-
nary can be useful for didactic studies where it can
complements approaches like and NLP for word
sense desambiguization (Gaume et al, 2004) or
de-metaphorization.
References
Barab?si, Albert-L?szl? and R?ka Albert. 1999. Emer-
gence of scaling in random networks. Science,
286:509?512, October.
Dik, S. 1991. Functional grammar. In Droste, F. and
J. Joseph., editors, Linguistic theory and grammati-
cal description. Amsterdam : Benjamins.
Duvignau, K. and B. Gaume. 2003. Linguistic, psy-
cholinguistic and computational approaches to the
lexicon: Contributions to early verb-learning. Jour-
nal of the European Society for the Study of Cogni-
tive Systems, 6(1).
Duvignau, Karine and Bruno Gaume. 2008. Between
words and world: Verbal ?metaphor? as semantic or
pragmatic approximation? In Proceedings of In-
ternational Conference ?Language, Communication
and Cognition?.
Duvignau, K., B. Gaume, and S. Kern. 2005. Seman-
tic approximations intraconcept
?
avs. interconcepts in
early verbal lexicon: flexibility against error. In Pro-
ceedings of ELA 2005, Emergence of language abil-
ities: ontogeny and phylogeny.
Duvignau, K. 2002. La m?taphore berceau et enfant
de la langue. Ph.D. thesis, Universit? Toulouse
?
U Le
mirail.
Fellbaum, C., editor. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
Ferrer-i-Cancho, Ramon and Ricard V. Sole. 2001. The
small world of human language. Proceedings of The
Royal Society of London. Series B, Biological Sci-
ences, 268(1482):2261?2265, November.
Gale, W., K. Church, and D. Yarowsky. 1992. A
method for disambiguating word senses in a large
corpus. Computers and the humanities, 26(2):415?
439.
Gaume, B., K. Duvignau K., O. Gasquet O., and M-
D. Gineste. 2002. Forms of meaning, meaning of
forms. Journal of Experimental and Theoretical Ar-
tificial Intelligence, 14:61?74.
Gaume, B., N. Hathout, and P. Muller. 2004. D?sam-
biguisation par proximit? structurelle. In Proceed-
ings of TALN 2004.
Harabagiu, Sanda M., George A. Miller, and Dan I.
Moldovan. 1999. Wordnet 2 - a morphologically
and semantically enhanced resource. In SIGLEX
1999.
Hofstadter, D. 1995. Fluid concepts and creative
analogies. New York : Basic Books.
Newman, M. 2003. The structure and function of com-
plex networks.
Ny, J-F. Le. 1979. La s?mantique psychologique. PUF.
Piaget, J. 1945. La formation du symbole chez l?en-
fant,. Delachaux et Niestl?.
Resnik, P. and M. Diab. 2000. Measuring verb similar-
ity. In Proceedings of the 22nd Annual Meeting of
the Cognitive Science Society.
Schvaneveldt, R. W., D. W D.W Dearholt, and F.T
Durso. 1988. Graph theoric foundations of
pathfinder networks. Computers and Mathematics
with Applications, 15:337?445.
Sigman, M. and G.A. Cecchi. 2002. Global organiza-
tion of the wordnet lexicon. Proc. Natl. Acad. Sci.,
99(3):1741?1747.
Watts, D.J. and S.H. Strogatz. 1998. Collective dynam-
ics of small-world networks. Nature, 393:440?442.
Zipf, G. K. 1949. Human behavior and the principle
of least effort. Addison-Wesley.
93
Proceedings of the TextGraphs-6 Workshop, pages 15?23,
Portland, Oregon, USA, 19-24 June 2011. c?2011 Association for Computational Linguistics
Invariants and Variability of Synonymy Networks:
Self Mediated Agreement by Confluence
Beno?t Gaillard
CLLE-ERSS, CNRS
University of Toulouse
Toulouse, France
benoit.gaillard@univ-tlse2.fr
Bruno Gaume
CLLE-ERSS, CNRS
University of Toulouse
Toulouse, France
bruno.gaume@univ-tlse2.fr
Emmanuel Navarro
IRIT
University of Toulouse
Toulouse, France
navarro@irit.fr
Abstract
Edges of graphs that model real data can be
seen as judgements whether pairs of objects
are in relation with each other or not. So,
one can evaluate the similarity of two graphs
with a measure of agreement between judges
classifying pairs of vertices into two cate-
gories (connected or not connected). When
applied to synonymy networks, such measures
demonstrate a surprisingly low agreement be-
tween various resources of the same language.
This seems to suggest that the judgements
on synonymy of lexemes of the same lexi-
con radically differ from one dictionary ed-
itor to another. In fact, even a strong dis-
agreement between edges does not necessarily
mean that graphs model a completely differ-
ent reality: although their edges seem to dis-
agree, synonymy resources may, at a coarser
grain level, outline similar semantics. To in-
vestigate this hypothesis, we relied on shared
common properties of real world data net-
works to look at the graphs at a more global
level by using random walks. They enabled
us to reveal a much better agreement between
dense zones than between edges of synonymy
graphs. These results suggest that although
synonymy resources may disagree at the level
of judgements on single pairs of words, they
may nevertheless convey an essentially simi-
lar semantic information.
1 Introduction
More and more resources exist, built with various
approaches and methods and with many different
aims and intended uses. A new issue raised by this
growth is that of comparing various resources. A
lexical resource is usually based on semantic judge-
ments about lexical elements (a human judgement
performed by a lexicographer, or a machine-based
judgement in the case of automatically built re-
sources). Often, two independently built resources
that describe the same linguistic reality only show a
weak agreement even when based on human judge-
ments under the same protocol (Murray and Green,
2004).
Many of such resources, such as WordNet (Fell-
baum, 1998) or Wiktionary1 (Zesch et al, 2008;
Sajous et al, 2010) can be modelled as graphs. A
graph encodes a binary relation on a set V of ver-
tices. A graph G = (V,E) is therefore defined by
a finite, non empty set of n = |V | vertices and by
a set E ? V ? V of m = |E| couples of vertices
(edges). In the linguistic field, vertices can be vari-
ous elements of the lexicon: lemmas, word senses,
syntactic frames... and edges can describe various
relations: synonymy, hyperonymy, translation, co-
occurrence... Edges between two vertices can be
seen as judgements that decide whether the consid-
ered relation applies to this pair. For example, in a
synonymy graph, an edge exists between two words
if they were judged to be synonyms by the lexicogra-
pher who was compiling the dictionary. So, different
graphs that model dictionaries of synonyms are built
according to the judgements of various ?judges?.
We first illustrate, in section 2, how various stan-
dard synonymy resources of English and French
share common structural properties: they all are Hi-
erarchical Small Worlds (HSW). However, we then
1http://www.wiktionary.org/
15
show that the synonymy judgements they describe
seem to disagree: the Kappa (Cohen, 1960) between
the edges of any two such resources remains surpris-
ingly low. In the third section, we analyse this appar-
ent disagreement and in section 4, we address it by
proposing an alternative view of the networks, based
on random walks. This more global view enables us
to assess if disagreeing synonymy networks never-
theless concord at a more global level, because they
model the same linguistic reality. Beyond the usual
Kappa agreement measure, which is based on the lo-
cal comparison of two category judgements (a pair is
or is not a pair of synonyms), we can show that syn-
onymy judgements do not essentially diverge on the
lexical semantic structure that emerges from them.
In the fifth section, we conclude by outlining possi-
ble applications and perspectives of this work.
2 Graph modelling of various synonymy
resources
In order to study the similarities and variations of
lexical resources, let us study a sample of graphs that
model several standard synonymy resources. We
analyse five standard, general purpose, paper dictio-
naries of French synonyms2: Bailly (Bai), Benac
(Ben), Bertaud du Chazaut (Ber), Larousse (Lar),
Robert (Rob). We also study synonymy relations ex-
tracted from the Princeton Word Net (PWN ) and
from the English Wiktionary (Wik). The PWN
synonymy network was built according to the fol-
lowing rule: an edge is drawn between any two
words that belong to the same synset. The Wik-
tionary synonymy network was extracted from Wik-
tionary dumps3 by methods exposed in (Sajous et
al., 2010). Each of these resources is split4 by parts
of speech (Nouns, Verbs, Adjectives) resulting in
three different synonymy graphs, designated, for ex-
ample for the Robert dictionary, as follows: RobN ,
RobV , RobA.
2Synonymy relations from each of these dictionaries were
extracted by the INALF/ATILF Research Unit and corrected by
the CRISCO Research Unit.
3http://redac.univ-tlse2.fr/lexiques/wiktionaryx.html
4Note that splitting is not necessary. The following work
would apply similarly to whole resources.
2.1 Invariants : similar structural properties
Most lexical networks, as most field networks5,
are Hierarchical Small World (HSW) Networks that
share similar properties (Watts and Strogatz, 1998;
Albert and Barabasi, 2002; Newman, 2003; Gaume
et al, 2010; Steyvers and Tenenbaum, 2005). They
exhibit a low density (not many edges), short paths
(the average number of edges L on the shortest
path between two vertices is low), a high clustering
rate C (locally densely connected subgraphs can be
found whereas the whole graph is globally sparse in
edges), and the distribution of their degrees follows
a power law. All graphs in our sample exhibit the
HSW properties. For example, Table 1 shows the
pedigrees of synonymy graphs of verbs(for space
reasons we only show results for verbs, results are
similar for the two other parts of speech). In this ta-
ble, n and m are the number of vertices and edges,
?k? is the average degree of vertices, and ? is the
coefficient of the power law that fits the distribution
of degrees, with a correlation coefficient r2. nlcc
and Llcc are the number of vertices and the aver-
age path length measured on the largest connected
component. Even if n and ?k? vary across dictionar-
ies, Llcc is always small, C is always higher than for
equivalent random graphs (Newman, 2003) and the
distribution of degrees remains close to a power law
with a good correlation coefficient.
Table 1: Pedigrees of seven synonymy graphs (verbs).
n m ?k? nlcc mlcc C Llcc ? r2
BaiV 3082 3648 2.46 2774 3417 0.04 8.24 -2.33 0.94
BenV 3549 4680 2.73 3318 4528 0.03 6.52 -2.10 0.96
BerV 6561 25177 7.71 6524 25149 0.13 4.52 -1.88 0.93
LarV 5377 22042 8.44 5193 21926 0.17 4.61 -1.94 0.88
RobV 7357 26567 7.48 7056 26401 0.12 4.59 -2.01 0.93
PWNV 11529 23019 6.3 6534 20806 0.47 5.9 -2.4 0.90
WikV 7339 8353 2.8 4285 6093 0.11 8.9 -2.4 0.94
2.2 Variability : a low agreement between
edges
Although all these graphs are HSW, Table 1 shows
that the lexical coverage (n) and the number of syn-
onymy links (m) significantly vary across graphs.
Given two graphs G1 = (V1, E1) and G2 =
5Field networks are networks that model real data gathered
by field work, for example in sociology, linguistics or biol-
ogy. They contrast with artificial networks (deterministic or
random).
16
(V2, E2), in order to compare their lexical cover-
ages, we compute the Recall (R?), Precision (P?)
and F-score (F?) of their vertex sets:
R?(G1, G2) =
|V1?V2|
|V2|
P?(G1, G2) =
|V1?V2|
|V1|
F?(G1, G2) = 2.
R?(G1,G2).P?(G1,G2)
R?(G1,G2)+P?(G1,G2)
F-scores of pairs of comparable graphs (same lan-
guage and same part of speech) of our sample re-
main moderate. Table 2 illustrates these measures on
the eleven pairs of graphs involving the five French
synonymy graphs (verbs) and the two English ones.
It shows that the lexical coverages of the various
synonymy graphs do not perfectly overlap.
Table 2: Precision, Recall and F-score of vertex sets of
eleven pairs of graphs. G1 in rows, G2 in cols.
BenV BerV LarV RobV WikV
BaiV
R? 0.66 0.45 0.51 0.40
P? 0.76 0.96 0.90 0.95
F? 0.71 0.61 0.65 0.56
BenV
R? 0.52 0.58 0.45
P? 0.96 0.88 0.93
F? 0.68 0.70 0.60
BerV
R? 0.85 0.73
P? 0.70 0.82
F? 0.77 0.77
LarV
R? 0.68
P? 0.92
F? 0.78
PWNV
R? 0.49
P? 0.31
F? 0.38
The value of F?(G1, G2) measures the relative
lexical coverage of G1 and G2 but does not eval-
uate the agreement between the synonymy judge-
ments modelled by the graphs? edges. The Kappa
of Cohen (Cohen, 1960) is a common measure of
agreement between different judges who categorize
the same set of objects. In the case of graphs, the
judgements are not applied to simple entities but to
relations between pairs of entities. Two synonymy
graphs G1 = (V1, E1) and G2 = (V2, E2) give two
judgements on pairs of vertices. For example, if a
pair (u, v) ? V1 ? V1 is judged as synonymous then
(u, v) ? E1, else (u, v) ? E1. To measure the
agreement between edges of G1 and G2, one first
has to reduce the two graphs to their common ver-
tices:
? G?1 =
(
V ? = (V1?V2), E?1 = E1? (V
??V ?)
)
;
? G?2 =
(
V ? = (V1?V2), E?2 = E2? (V
??V ?)
)
;
For each pair of vertices (a, b) ? (V ? ? V ?), four
cases are possible:
? (a, b) ? E?1
?
E?2: agreement on pair (a, b),
(a, b) is synonymous for G?1 and for G
?
2;
? (a, b) ? E?1
?
E?2: agreement on pair (a, b),
(a, b) is neither synonymous forG?1 nor forG
?
2;
? (a, b) ? E?1
?
E?2: disagreement on pair (a, b),
(a, b) is synonymous for G?1 but not for G
?
2;
? (a, b) ? E?1
?
E?2: disagreement on pair (a, b),
(a, b) is synonymous for G?2 but not for G
?
1;
The agreement between the two synonymy judge-
ments ofG1 andG2 is measured byKl(G
?
1, G
?
2), the
Kappa between the two sets of edges E?1 and E
?
2:
Kl(G
?
1, G
?
2) =
(p0 ? pe)
(1? pe)
(1)
where:
p0 =
1
?
.(|E?1 ? E
?
2|+ |E
?
1 ? E
?
2|) (2)
is the relative observed agreement between vertex
pairs of G?1 and vertex pairs of G
?
2, where ? is the
number of possible edges6 ? = 12 .|V
?|.(|V ?| ? 1).
pe =
1
?2
.(|E?1|.|E
?
2|+ |E
?
1|.|E
?
2|) (3)
is the hypothetical probability of chance agreement,
assuming that judgements are independent7.
The value of agreement on synonymy judgements
Kl(G
?
1, G
?
2) varies significantly across comparable
dictionary pairs of our sample, however it remains
quite low. For example: Kl(Rob
?
V , Lar
?
V ) = 0.518
and Kl(PWN
?
V ,Wik
?
V ) = 0.247 (cf. Table 3). On
the whole sample studied in this work this agreement
value ranges from 0.25 to 0.63 averaging to 0.39.
This shows that, although standard dictionaries of
synonyms show similar structural properties, they
considerably disagree on which pairs of words are
synonymous.
6Here, we do not consider reflexivity edges, that link ver-
tices to themselves, as they are obviously in agreement across
graphs and are not informative synonymy judgements.
7Note that Kl(G
?
1, G
?
2) = Kl(G
?
2, G
?
1).
17
3 Analysis of the disagreement between
synonymy networks
When comparing two lexical resources built by lexi-
cographers, one can be surprised to find such a level
of disagreement on synonymy relations. This diver-
gence in judgements can be explained by editorial
policies and choices (regarding, for example printed
size constraints, targeted audiences...). Furthermore,
lexicographers also have their subjectivity. Since
synonymy is more a continuous gradient than a dis-
crete choice (Edmonds and Hirst, 2002), an alterna-
tive limited to synonym/not synonym leaves ample
room for subjective interpretation. However, these
justifications do not account for such discrepancies
between resources describing the semantic relations
of words of the same language. Therefore, we ex-
pect that, if two words are deemed not synonyms
in one resource G1, but synonyms in another G2,
they will nevertheless share many neighbours in G1
and G2. In other words they will belong to the same
dense zones. Consequently the dense zones (or clus-
ters) found in G1 will be similar to those found in
G2. Random walks are an efficient way to reveal
these dense zones (Gaume et al, 2010). So, to eval-
uate the hypothesis, let us begin by studying the sim-
ilarity of random walks on various synonymy net-
works.
3.1 Random walks on synonymy networks
If G = (V,E) is a reflexive and undirected graph,
let us define dG(u) = |{v ? V/(u, v) ? E}| the
degree of vertex u in graph G, and let us imagine a
walker wandering on the graph G:
? At a time t ? N, the walker is on one vertex
u ? V ;
? At time t + 1, the walker can reach any neigh-
bouring vertex of u, with uniform probability.
This process is called a simple random walk (Bol-
lobas, 2002). It can be defined by a Markov chain
on V with a n? n transition matrix [G]:
[G] = (gu,v)u,v?V
with gu,v =
?
?
?
1
dG(u)
if (u, v) ? E,
0 else.
Since G is reflexive, each vertex has at least one
neighbour (itself) thus [G] is well defined. Further-
more, by construction, [G] is a stochastic matrix:
?u ? V,
?
v?V gu,v = 1.
The probability P tG(u v) of a walker starting on
vertex u to reach a vertex v after t steps is:
P tG(u v) = ([G]
t)u,v (4)
One can then prove (Gaume, 2004), with the
Perron-Frobenius theorem (Stewart, 1994), that if G
is connected8 (i.e. there is always at least one path
between any two vertices), reflexive and undirected,
then ?u, v ? V :
lim
t??
P tG(u v) = limt??
([G]t)u,v =
dG(v)
?
x?V dG(x)
(5)
It means that when t tends to infinity, the probability
of being on a vertex v at time t does not depend on
the starting vertex but only on the degree of v. In the
following we will refer to this limit as piG(v).
3.2 Confluence in synonymy networks
The dynamics of the convergence of random walks
towards the limit (Eq. (5)) is heavily dependent on
the starting node. Indeed, the trajectory of the ran-
dom walker is completely governed by the topology
of the graph: after t steps, any vertex v located at a
distance of t links or less can be reached. The prob-
ability of this event depends on the number of paths
between u and v, and on the structure of the graph
around the intermediary vertices along those paths.
The more interconnections between the vertices, the
higher the probability of reaching v from u.
For example, if we take G1 = RobV and
G2 = LarV , and choose the three vertices
u = ?plucher (peel), r = d?pecer (tear apart) and
s = sonner (ring), which are such that:
? u= ?plucher (peel) and r= d?pecer (tear apart)
are synonymous in RobV : (u, r) ? E1;
? u= ?plucher (peel) and r= d?pecer (tear apart)
are not synonymous in LarV : (u, r) /? E2;
? r= d?pecer (tear apart) and s= sonner (ring)
have the same number of synonyms in G1 :
dG1(r) = dG1(s) = d1;
8The graph needs to be connected for Eq. 5 to be valid but,
in practice, the work presented here also holds on disconnected
graphs.
18
? r= d?pecer (tear apart) and s= sonner (ring)
have the same number of synonyms in G2 :
dG2(r) = dG2(s) = d2.
Then Equation (5) states that (P tG1(u r))1?t and
(P tG1(u s))1?t converge to the same limit:
piG1(r) = piG1(s) =
d1
?
x?V1
dG1(x)
as do (P tG2(u r))1?t and (P
t
G2(u s))1?t:
piG2(r) = piG2(s) =
d2
?
x?V2
dG2(x)
However the two series do not converge with the
same dynamics. At the beginning of the walk, for t
small, one can expect that P tG1(u r) > P
t
G1(u s)
and P tG2(u r) > P
t
G2(u s) because ?plucher is
semantically closer to d?pecer than to sonner. In-
deed the number of short paths between ?plucher
and d?pecer is much greater than between ?plucher
and sonner.
Figure 1(a) shows the values of P tG1(u r)
and P tG1(u s) versus t, and compares them
to their common limit. Figure 1(b) shows
the values of P tG2(u r) and P
t
G2(u s) ver-
sus t, and compares them to their common limit.
These figures confirm our intuition that, since
?plucher (peel) and d?pecer (tear apart) are seman-
tically close, P tG1(u r) and P
t
G2(u r) decrease to
their limit. We call this phenomenon strong con-
fluence. It is worth noting that this remains true
even if ?plucher (peel) and d?pecer (tear apart)
are not synonyms in LarV . Conversely, since
?plucher (peel) and sonner (ring) are semantically
distant, P tG1(u s) and P
t
G2(u s) increase to their
asymptotic value. We call this phenomenon weak
confluence.
3.3 Correlation of the confluence of
disagreeing synonymy pairs
When two graphs G1 and G2 disagree on a pair of
vertices (a, b) (a is a neighbour of b in one graph but
not in the other) there are three possible cases for the
strength of the confluence between vertices a and b:
(1) strong in both graphs (confluence agreement),
10 20 30 40 50t : Length of random walk10-5
10-4
10-3
10-2
10-1
Pt (?
pluc
her
?) t>1
Pt (?plucher d?pecer)t >1Pt (?plucher sonner))t >1Common asymptotical value
(a) G1 = RobV
10 20 30 40 50t : Length of random walk10-5
10-4
10-3
10-2
Pt (?
pluc
her
?) t?1
Pt (?plucher d?pecer)t >1Pt (?plucher sonner)t >1Common asymptotical value
(b) G2 = LarV
Figure 1: Confluences between ?plucher (peel),
d?pecer (tear apart) and ?plucher (peel), sonner (ring)
in RobV and LarV .
(2) weak in both graphs (confluence agreement),
(3) strong in one graph, but weak in the other (con-
fluence disagreement).
To contrast cases (1) and (2) from case (3) we
measure the correlation between the confluences of
disagreeing pairs of two synonymy networks G?1
and G?2. We compare it to this same correlation on
two reflexive and undirected random graphs RG?1 =
(V ?, ER1 ) and RG?2 = (V
?, ER2 ) built such that:
|ER1 ? E
R
2 | = |E
?
1 ? E
?
2|,
|ER1 ? E
R
2 | = |E
?
1 ? E
?
2|,
|ER1 ? E
R
2 | = |E
?
1 ? E
?
2|,
19
which means that the Kappa agreement between
RG?1 and RG?2 is the same as between G
?
1 and G
?
2.
For a given t > 1 and a set of vertex pairs X ?
V ??V ?, the correlation of confluences ?X(G?1, G
?
2)
is defined by the Pearson?s linear correlation coef-
ficient of the two value tables
(
P tG?1
(u v)
)
(u,v)?X
and
(
P tG?2
(u v)
)
(u,v)?X .
For all comparable pairs of our sample, we
see that disagreeing pairs tend to have a much
higher correlation of confluence than disagreeing
pairs of equivalent random networks. As an ex-
ample, for G1 = RobV , G2 = LarV and
t = 3, we have ?E?1
T
E?2
(G?1, G
?
2) = 0.41 and
?E?1
T
E?2
(G?1, G
?
2) = 0.38, whereas in the case of
the equivalent random graphs the same figures are
close to zero.
This suggests that even if graphs disagree on the
synonymy of a significant number of pairs, they nev-
ertheless generally agree on the strength of their
confluence. In other words, occurrences of cases (1)
and (2) are the majority whereas occurrences of case
(3) are rare. We propose in the next section an exper-
iment to verify if we can rely on confluence to find a
greater agreement between two graphs that disagree
at the level of synonymy links.
4 Self mediated agreement by confluence
4.1 Hypothesis: Conciliation reveals structural
similarity beyond disagreement of local
synonymy
We saw in section 2.2 that the rate of agreement be-
tween edges of two standard synonymy networksG?1
and G?2, Kl(G
?
1, G
?
2), is usually low. However, we
have noticed in Section 3.3 that the confluences of
pairs on which synonymy graphs disagree are sig-
nificantly more correlated (? ? 0.4) than the conflu-
ence of equivalent random networks (? ? 0). This
suggests the following hypothesis: synonymy net-
works are in agreement at a level that is not taken
into account by the Kappa measure on edges.
To verify this hypothesis, we try to make each pair
of graphs conciliate on the basis of confluence val-
ues. We propose a conciliation process by which
a graph can accept the addition of another?s edges
if they do not contradict its structure (i.e. there
is a strong confluence value). We then assess if a
strong agreement is found between the two resulting
graphs.
Let G1 = (V1, E1) and G2 = (V2, E2) be two
synonymy networks, both reflexive, undirected, con-
nected, and a given t ? N?. We define:
? G?1 =
(
V ? = (V1 ?V2), E?1 = E1 ? (V
??V ?)
)
? G?2 =
(
V ? = (V1 ?V2), E?2 = E2 ? (V
??V ?)
)
? G(+G2)1 = (V
?, E+1 = E
?
1 ? C1) where
C1 =
n
(u, r) ? E?1 ? E
?
2
?
P tG?1
(u r) > piG?1 (r)
o
(6)
? G(+G1)2 = (V
?, E+2 = E
?
2 ? C2) where
C2 =
n
(u, r) ? E?1 ? E
?
2
?
P tG?2
(u r) > piG?2 (r)
o
(7)
G(+G2)1 and G
(+G1)
2 are called accommodating
graphs. The construction of the accommodating
graphs may be metaphorically understood as a con-
ciliation protocol by which two graphs accept pro-
posals of the other that they can reconsider. For ex-
ample, G(+G2)1 is the graph G
?
1 enriched by edges
(u, r) of G?2 such that there is a strong confluence
between vertices u and r in G?1
The following property is worth noticing:
Proposition 1. ?t ? N? :
(E?1 ? E
?
2) ? (E
+
1 ? E
+
2 ) ? (E
?
1 ? E
?
2) (8)
Proof. By definition, E+1 = E
?
1 ? C1 and E
+
2 =
E?2?C2, thus (E
?
1?E
?
2) ? (E
+
1 ?E
+
2 ), furthermore,
by definition, C1 ? E?1?E
?
2 and C2 ? E
?
1?E
?
2 thus
(E+1 ? E
+
2 ) ? (E
?
1 ? E
?
2).
4.2 Experimental protocol
If, for any (G1, G2) synonymy resources of the
same language, Kl(G
(+G2)
1 , G
(+G1)
2 ) is signifi-
cantly greater than Kl(G
?
1, G
?
2), then the hypothe-
sis is verified. The conciliation process depends on
confluence measures that depend on a given t, the
number of steps of the random walk. For t = 1,
only vertices in the neighbourhood of the starting
vertex are reachable. Consequently only pairs of
vertices that are edges have a non null confluence.
Thus Kl(G
(+G2)
1 , G
(+G1)
2 ) = Kl(G
?
1, G
?
2) which
does not help us to contrast conciliated graphs from
20
initial binary synonymy graphs. So we fix t = 2
the shortest walk length that still yields informative
results.
We propose a control experiment that consists
in applying the conciliation process to random net-
works that have the same Kappa as the pairs of syn-
onymy networks. The construction of these random
graphs is described above, in section 3.3. We mea-
sure the agreement after conciliation of 20 different
random graphs. With this control experiment we as-
sess that the observed results are specific to graphs
describing the same resource, and not a mere bias of
the protocol (let us imagine a protocol whereby one
would add all the disagreeing edges to the graphs:
not only the Kappa of the pseudo accommodating
synonymy graphs would be equal to one, but also the
Kappa of pseudo accommodating random graphs,
which would disqualify the protocol).
4.3 Results
Table 3 summarizes Kappa and conciliated Kappa
values on the pairs of synonymy graphs of verbs.
It shows a significant improvement of agreement
after conciliation. For example, from a moder-
ate Kappa (0.518) between graphs Rob?V and Lar
?
V
(constructed by experts), the conciliation process
leads to an excellent Kappa (0.852). Conversely the
random networks only increase their agreement by
0.01 (with a very low standard deviation ? < 0.001).
In English, from a poor (0.247) Kappa between
PWN ?V (constructed by experts) and Wik
?
V (con-
structed by the ?crowds?), the conciliation process
leads to a moderate Kappa (0.530), whereas the ran-
dom networks only marginally increase their agree-
ment (0.004).
Results are similar for other parts of speech. This
means that the conciliation process significantly im-
proves the agreement between resources, even if
they are originally significantly diverge.
It is interesting to notice that the most sim-
ilar pairs in terms of edge agreement do not
necessarily produce the most agreeing pairs
of accommodating graphs. For example, the
pair(BaiV , RobV ) agrees more than the pair
(BaiV , LarV ), whereas for their accommodating
graphs, the pair(Bai(+RobV )V , Rob
(+BaiV )
V ) agrees
less than the pair (Bai(+LarV )V , Lar
(+BaiV )
V ).
Table 3: Kappa (ori.) and accommodating Kappa (acc.)
values between French and English synonymy graphs (of
verbs), compared with the Kappa values between pairs of
equivalent random graphs (?ori. r.? and ?acc. r.?).
Kl BenV BerV LarV RobV WikV
BaiV
ori. 0.583 0.309 0.255 0.288
acc. 0.777 0.572 0.603 0.567
ori. r. 0.583 0.309 0.256 0.288
acc. r. 0.585 0.313 0.262 0.293
BenV
ori. 0.389 0.276 0.293
acc. 0.657 0.689 0.636
ori. r. 0.390 0.276 0.294
acc. r. 0.392 0.283 0.301
BerV
ori. 0.416 0.538
acc. 0.838 0.868
ori. r. 0.417 0.539
acc. r. 0.434 0.549
LarV
ori. 0.518
acc. 0.852
ori. r. 0.518
acc. r. 0.529
PWNV
ori. 0.247
acc. 0.540
ori. r. 0.247
acc. r. 0.251
So, when G1 and G2 are two synonymy graphs
of a given language, then they are able to address
their local synonymy disagreement and to reach a
significantly better agreement. On the other hand,
the agreement of random networks does not really
improve after conciliation. This proves that the syn-
onymy networks of the same language share specific
similar structures that can be detected with the help
of confluence measures.
5 Conclusion
Although graphs that encode synonymy judgements
of standard semantic lexical resources share simi-
lar HSW properties they diverge on their synonymy
judgements as measured by a low Kappa of edges.
So, one could wonder whether the notion of syn-
onymy is well defined, or if synonymy judgements
are really independent. Without directly address-
ing this question, we nevertheless have shown that
strong confluence measures help two synonymy
graphs accommodate each others? conflicting edges.
They reach a much better agreement, whereas ran-
dom graphs? divergence is maintained. Since the
graphs are HSW, they draw clusters of synonyms
in which pairs of vertices have a strong confluence.
21
This suggests two conclusions. First, different syn-
onymy resources that describe the same lexicon re-
veal dense zones that are much more similar across
graphs than the binary synonymy categorisation (the
synonym/not synonym alternative). These dense
zones convey information about the semantic organ-
isation of the lexicon. Second, random walks and
confluence measures seem an appropriate technique
to detect and compare the dense zones of various
synonymy graphs.
This theoretical work validates the random
walk/confluence approach as a potentially valid tool
for detecting semantic similarities. This opens many
perspectives for applications. For example, it can
be used to enrich resources as was done for the
Wisigoth project (Sajous et al, 2010). It may also
help to merge, or aggregate, resources. If we apply
the conciliation process to two graphs G1 and G2,
obtaining two accommodating graphs G(+G2)1 =
(V ?, E+1 )) and G
(+G1)
2 = (V
?, E+2 )) then the graph
G = (V ?, E?? = (E+1 ? E
+
2 )) could be a merged
resource. Indeed, G?s set of edges, E?? seems like
a good compromise because, according to the prop-
erty 1, (E?1 ? E
?
2) ? E
?? ? (E?1 ? E
?
2). This new
aggregation method would need to be validated by
comparing the quality of the merged resource to the
results of the union or intersection.
Furthermore, this work is a first step for defin-
ing a similarity measure between graphs, that could
take into account the structural agreement rather
than a simple edge-to-edge disagreement. Subse-
quent work should generalise the conciliation pro-
cess along several axes:
? The number of steps t was chosen as the short-
est possible for the confluence measures. It
would be worthwhile to investigate the effect
of the length of the walks on the agreement of
the accommodating graphs.
? Another line of research would be to alter the
conciliation ability of graphs, by increasing or
decreasing the criterion for strong confluence.
One can for example introduce a k parameter in
the definition of C1 (resp. C2), in Equation 6:
P tG?1(u r) > k.piG
?
1
(r) (9)
? The conciliation process seems unbalanced in-
sofar as graphs only accept to add edges. It
should be extended to a negotiating process
where a graph could also accept to remove one
edge if the other does not have it and its conflu-
ence is weak.
? The conciliation process could also be gen-
eralised to graphs that have different vertices,
such as two synonymy networks of different
languages. In that case the issue is not anymore
to reveal a deeper similarity, beyond a local
disagreement, because one can not compare
the graphs vertex by vertex or edge by edge.
However, questioning whether the semantic
structures revealed by dense zones are similar
from one lexicon to another is an interesting
line of research. One approach to compare two
synonymy graphs of two different languages
would be to draw edges between vertices that
are translations of each other. Random walks
could then reach vertices of the two lexicons,
so that the conciliation process could be
generalised to accommodating two synonymy
graphs via translation links.
Acknowledgements
The research presented in this paper was supported
by the ANR-NSC (France-Taiwan) bilateral project
M3 (Modeling and Measurement of Meaning). We
would like to thank the reviewers for their insightful
comments.
References
[Albert and Barabasi2002] R?ka Albert and Albert-
L?szl? Barabasi. 2002. Statistical Mechanics of
Complex Networks. Reviews of Modern Physics,
74:74?47.
[Bollobas2002] Bela Bollobas. 2002. Modern Graph
Theory. Springer-Verlag New York Inc., October.
[Cohen1960] Jacob Cohen. 1960. A coefficient of
agreement for nominal scales. Educ. Psychol. Meas.,
(20):27?46.
[Edmonds and Hirst2002] Philip Edmonds and Graeme
Hirst. 2002. Near-Synonymy and Lexical Choice.
Computational Linguistics, 28(2):105?144.
22
[Fellbaum1998] Christiane Fellbaum, editor. 1998.
WordNet: An Electronic Lexical Database. MIT Press.
[Gaume et al2010] Bruno Gaume, Fabien Mathieu, and
Emmanuel Navarro. 2010. Building Real-World
Complex Networks by Wandering on Random Graphs.
I3: Information Interaction Intelligence, 10(1).
[Gaume2004] Bruno Gaume. 2004. Balades Al?atoires
dans les Petits Mondes Lexicaux. I3: Information In-
teraction Intelligence, 4(2).
[Murray and Green2004] G. Craig Murray and Rebecca
Green. 2004. Lexical Knowledge and Human Dis-
agreement on a WSD Task. Computer Speech & Lan-
guage, 18(3):209?222.
[Newman2003] M. E. J. Newman. 2003. The Structure
and Function of Complex Networks. SIAM Review,
45:167?256.
[Sajous et al2010] Franck Sajous, Emmanuel Navarro,
Bruno Gaume, Laurent Pr?vot, and Yannick Chudy.
2010. Semi-automatic endogenous enrichment of col-
laboratively constructed lexical resources: Piggyback-
ing onto wiktionary. In Hrafn Loftsson, Eir?kur R?gn-
valdsson, and Sigr?n Helgad?ttir, editors, Advances in
NLP, volume 6233 of LNCS, pages 332?344. Springer
Berlin / Heidelberg.
[Stewart1994] G. W. Stewart. 1994. Perron-frobenius
theory: a new proof of the basics. Technical report,
College Park, MD, USA.
[Steyvers and Tenenbaum2005] Mark Steyvers and
Joshua B. Tenenbaum. 2005. The large-scale struc-
ture of semantic networks: Statistical analyses and
a model of semantic growth. Cognitive Science,
29(1):41?78.
[Watts and Strogatz1998] Duncan J. Watts and Steven H.
Strogatz. 1998. Collective Dynamics of Small-World
Networks. Nature, 393:440?442.
[Zesch et al2008] Torsten Zesch, Christof M?ller, and
Iryna Gurevych. 2008. Using wiktionary for comput-
ing semantic relatedness. In Proceedings of the 23rd
national conference on Artificial intelligence - Volume
2, pages 861?866, Chicago, Illinois. AAAI Press.
23
