Proceedings of the Third Workshop on Statistical Machine Translation, pages 127?130,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
The TALP-UPC Ngram-based statistical machine translation system for
ACL-WMT 2008
Maxim Khalilov, Adolfo Hern?ndez H., Marta R. Costa-juss?,
Josep M. Crego, Carlos A. Henr?quez Q., Patrik Lambert,
Jos? A. R. Fonollosa, Jos? B. Mari?o and Rafael E. Banchs
Department of Signal Theory and Communications
TALP Research Center (UPC)
Barcelona 08034, Spain
(khalilov, adolfohh, mruiz, jmcrego, carloshq, lambert, adrian, canton, rbanchs)@gps.tsc.upc.edu
Abstract
This paper reports on the participation of the TALP
Research Center of the UPC (Universitat Polit?cnica
de Catalunya) to the ACL WMT 2008 evaluation
campaign.
This year?s system is the evolution of the one we em-
ployed for the 2007 campaign. Main updates and
extensions involve linguistically motivated word re-
ordering based on the reordering patterns technique.
In addition, this system introduces a target language
model, based on linguistic classes (Part-of-Speech),
morphology reduction for an inflectional language
(Spanish) and an improved optimization procedure.
Results obtained over the development and test sets
on Spanish to English (and the other way round)
translations for both the traditional Europarl and
a challenging News stories tasks are analyzed and
commented.
1 Introduction
Over the past few years, the Statistical Machine Transla-
tion (SMT) group of the TALP-UPC has been develop-
ing the Ngram-based SMT system (Mari?o et al, 2006).
In previous evaluation campaigns the Ngram-based ap-
proach has proved to be comparable with the state-of-
the-art phrase-based systems, as shown in Koehn and
Monz(2006), Callison-Burch et al (2007).
We present a summary of the TALP-UPC Ngram-
based SMT system used for this shared task. We dis-
cuss the system configuration and novel features, namely
linguistically motivated reordering technique, which is
applied on the decoding step. Additionally, the reorder-
ing procedure is supported by an Ngram language model
(LM) of reordered source Part-of-Speech tags (POS).
In this year?s evaluation we submitted systems for
Spanish-English and English-Spanish language pairs for
the traditional (Europarl) and challenging (News) tasks.
In each case, we used only the supplied data for each lan-
guage pair for models training and optimization.
This paper is organized as follows. Section 2 briefly
outlines the 2008 system, including tuple definition and
extraction, translation model and additional feature mod-
els, decoding tool and optimization procedure. Section 3
describes the word reordering problem and presents the
proposed technique of reordering patterns learning and
application. Later on, Section 4 reports on the experi-
mental setups of the WMT 2008 evaluation campaign. In
Section 5 we sum up the main conclusions from the pa-
per.
2 Ngram-based SMT System
Our translation system implements a log-linear model in
which a foreign language sentence fJ1 = f1, f2, ..., fJ
is translated into another language eI1 = f1, f2, ..., eI by
searching for the translation hypothesis e?I1 maximizing a
log-linear combination of several feature models (Brown
et al, 1990):
e?I1 = argmax
eI1
{ M
?
m=1
?mhm(eI1, fJ1 )
}
where the feature functions hm refer to the system models
and the set of ?m refers to the weights corresponding to
these models.
The core part of the system constructed in that way
is a translation model, which is based on bilingual n-
grams. It actually constitutes an Ngram-based LM of
bilingual units (called tuples), which approximates the
joint probability between the languages under consider-
ation. The procedure of tuples extraction from a word-
to-word alignment according to certain constraints is ex-
plained in detail in Mari?o et al (2006).
The Ngram-based approach differs from the phrase-
based SMT mainly by distinct representating of the bilin-
gual units defined by word alignment and using a higher
127
order HMM of the translation process. While regular
phrase-based SMT considers context only for phrase re-
ordering but not for translation, the N-gram based ap-
proach conditions translation decisions on previous trans-
lation decisions.
The TALP-UPC 2008 translation system, besides the
bilingual translation model, which consists of a 4-gram
LM of tuples with Kneser-Ney discounting (estimated
with SRI Language Modeling Toolkit1), implements a
log-linear combination of five additional feature models:
? a target language model (a 4-gram model of words,
estimated with Kneser-Ney smoothing);
? a POS target language model (a 4-gram model of
tags with Good-Turing discounting (TPOS));
? a word bonus model, which is used to compensate
the system?s preference for short output sentences;
? a source-to-target lexicon model and a target-to-
source lexicon model, these models use word-to-
word IBM Model 1 probabilities (Och and Ney,
2004) to estimate the lexical weights for each tuple
in the translation table.
Decisions on the particular LM configuration and
smoothing technique were taken on the minimal-
perplexity and maximal-BLEU bases.
The decoder (called MARIE), an open source tool2,
implementing a beam search strategy with distortion ca-
pabilities was used in the translation system.
Given the development set and references, the log-
linear combination of weights was adjusted using a sim-
plex optimization method (with the optimization criteria
of the highest BLEU score ) and an n-best re-ranking
just as described in http://www.statmt.org/jhuws/. This
strategy allows for a faster and more efficient adjustment
of model weights by means of a double-loop optimiza-
tion, which provides significant reduction of the number
of translations that should be carried out.
3 Reordering framework
For a great number of translation tasks a certain reorder-
ing strategy is required. This is especially important
when the translation is performed between pairs of lan-
guages with non-monotonic word order. There are var-
ious types of distortion models, simplifying bilingual
translation. In our system we use an extended monotone
reordering model based on automatically learned reorder-
ing rules. A detailed description can be found in Crego
and Mari?o (2006).
1http://www.speech.sri.com/projects/srilm/
2http://gps-tsc.upc.es/veu/soft/soft/marie/
Apart from that, tuples were extracted by an unfold-
ing technique: this means that the tuples are broken into
smaller tuples, and these are sequenced in the order of the
target words.
3.1 Reordering patterns
Word movements are realized according to the reordering
rewrite rules, which have the form of:
t1, ..., tn 7? i1, ..., in
where t1, ..., tn is a sequence of POS tags (relating a
sequence of source words), and i1, ..., in indicates which
order of the source words generate monotonically the tar-
get words.
Patterns are extracted in training from the crossed links
found in the word alignment, in other words, found in
translation tuples (as no word within a tuple can be linked
to a word out of it (Crego and Mari?o, 2006)).
Having all the instances of rewrite patterns, a score for
each pattern on the basis of relative frequency is calcu-
lated as shown below:
p(t1, ..., tn 7? i1, ..., in) =
N(t1, ..., tn 7? i1, ..., in)
NN(t1, ..., tn)
3.2 Search graph extension and source POS model
The monotone search graph is extended with reorderings
following the patterns found in training. Once the search
graph is built, the decoder traverses the graph looking for
the best translation. Hence, the winning hypothesis is
computed using all the available information (the whole
SMT models).
Figure 1: Search graph extension. NC, CC and AQ stand re-
spectively for name, conjunction and adjective.
The procedure identifies first the sequences of words
in the input sentence that match any available pattern.
Then, each of the matchings implies the addition of an arc
into the search graph (encoding the reordering learned in
the pattern). However, this addition of a new arc is not
128
Task BL BL+SPOS
Europarl News Europarl News
es2en 32.79 36.09 32.88 36.36
en2es 32.05 33.91 32.10 33.63
Table 1: BLEU comparison demonstrating the impact of the
source-side POS tags model.
performed if a translation unit with the same source-side
words already exists in the training. Figure 1 shows how
two rewrite rules applied over an input sentence extend
the search graph given the reordering patterns that match
the source POS tag sequence.
The reordering strategy is additionally supported by
a 4-gram language model (estimated with Good-Turing
smoothing) of reordered source POS tags (SPOS). In
training, POS tags are reordered according with the ex-
tracted reordering patterns and word-to-word links. The
resulting sequence of source POS tags is used to train the
Ngram LM.
Table 1 presents the effect of the source POS LM in-
troduction to the reordering module of the Ngram-based
SMT. As it can be seen, the impactya le h of the source-
side POS LM is minimal, however we decided to consider
the model aiming at improving it in future. The reported
results are related to the Europarl and News Commen-
tary (News) development sets. BLEU calculation is case
insensitive and insensitive to tokenization. BL (baseline)
refers to the presented Ngram-based system considering
all the features, apart from the target and source POS
models.
4 WMT 2008 Evaluation Framework
4.1 Corpus
An extraction of the official transcriptions of the 3rd re-
lease of the European Parliament Plenary Sessions3 was
provided for the ACL WMT 2008 shared translation task.
About 40 times smaller corpus from news domain (called
News Commentary) was also available. For both tasks,
our training corpus was the catenation of the Europarl and
News Commentary corpora.
TALP UPC participated in the constraint to the
provided training data track for Spanish-English and
English-Spanish translation tasks. We used the same
training material for the traditional and challenging tasks,
while the development sets used to tune the system were
distinct (2000 sentences for Europarl task and 1057
for News Commentary, one reference translation for
each of them). A brief training and development corpora
statistics is presented in Table 2.
3http://www.statmt.org/wmt08/shared-task.html
Spanish English
Train
Sentences 1.3 M 1.3 M
Words 38.2 M 35.8 K
Vocabulary 156 K 120 K
Development Europarl
Sentences 2000 2000
Words 61.8 K 58.7 K
Vocabulary 8 K 6.5 K
Development News Commentary
Sentences 1057 1057
Words 29.8 K 25.8 K
Vocabulary 5.4 K 4.9 K
Table 2: Basic statistics of ACL WMT 2008 corpus.
4.2 Processing details
The training data was preprocessed by using provided
tools for tokenizing and filtering.
POS tagging. POS information for the source and the
target languages was considered for both translation tasks
that we have participated. The software tools available
for performing POS-tagging were Freeling (Carreras et
al., 2004) for Spanish and TnT (Brants, 2000) for En-
glish. The number of classes for English is 44, while
Spanish is considered as a more inflectional language,
and the tag set contains 376 different tags.
Word Alignment. The word alignment is automati-
cally computed by using GIZA++4(Och and Ney, 2000)
in both directions, which are symmetrized by using the
union operation. Instead of aligning words themselves,
stems are used for aligning. Afterwards case sensitive
words are recovered.
Spanish Morphology Reduction. We implemented a
morphology reduction of the Spanish language as a pre-
processing step. As a consequence, training data sparse-
ness due to Spanish morphology was reduced improving
the performance of the overall translation system. In par-
ticular, the pronouns attached to the verb were separated
and contractions as del or al were splitted into de el or
a el. As a post-processing, in the En2Es direction we
used a POS target LM as a feature (instead of the target
language model based on classes) that allowed to recover
the segmentations (de Gispert, 2006).
4.3 Experiments and Results
In contrast to the last year?s system where statistical
classes were used to train the target-side tags LM, this
year we used linguistically motivated word classes
4http://code.google.com/p/giza-pp/
129
Task BL+SPOS BL+SPOS+TPOS
(UPC 2008)
Europarl News Europarl News
es2en 32.88 36.36 32.89 36.31
en2es 31.52 34.13 30.72 32.72
en2es "clean"5 32.10 33.63 32.09 35.04
Table 3: BLEU scores for Spanish-English and English-Spanish
2008 development corpora (Europarl and News Commentary).
Task UPC 2008
Europarl News
es2en 32.80 19.61
en2es 31.31 19.28
en2es "clean"5 32.34 20.05
Table 4: BLEU scores for official tests 2008.
(POS) which were considered to train the POS target LM
and extract the reordering patterns. Other characteristics
of this year?s system are:
? reordering patterns technique;
? source POS model, supporting word reordering;
? no LM interpolation. For this year?s evaluation, we
trained two separate LMs for each domain-specific
corpus (i.e., Europarl and News Commentary tasks).
It is important to mention that 2008 training material is
identical to the one provided for the 2007 shared transla-
tion task.
Table 3 presents the BLEU score obtained for the 2008
development data sets and shows the impact of the target-
side POS LM introduction, which can be characterized as
highly corpus- and language-dependent feature. BL refers
to the same system configuration as described in subsec-
tion 3.2. The computed BLEU scores are case insensitive,
insensitive to tokenization and use one translation refer-
ence.
After submitting the systems we discovered a bug re-
lated to incorrect implementation of the target LMs of
words and tags for Spanish, it caused serious reduction
of translation quality (1.4 BLEU points for development
set in case of English-to-Spanish Europarl task and 2.3
points in case of the corresponding News Commentary
task). The last raw of table 3 (en2es "clean") repre-
sents the results corresponding to the UPC 2008 post-
evaluation system, while the previous one (en2es) refers
to the "bugged" system submitted to the evaluation.
The experiments presented in Table 4 correspond to the
2008 test evaluation sets.
5Corrected post-evaluation results (see subsection 4.3.)
5 Conclusions
In this paper we introduced the TALP UPC Ngram-based
SMT system participating in the WMT08 evaluation.
Apart from briefly summarizing the decoding and opti-
mization processes, we have presented the feature mod-
els that were taken into account, along with the bilingual
Ngram translation model. A reordering strategy based on
linguistically-motivated reordering patterns to harmonize
the source and target word order has been presented in
the framework of the Ngram-based system.
6 Acknowledgments
This work has been funded by the Spanish Government
under grant TEC2006-13964-C03 (AVIVAVOZ project).
The authors want to thank Adri? de Gispert (Cambridge
University) for his contribution to this work.
References
T. Brants. 2000. TnT ? a statistical part-of-speech tagger. In
Proceedings of the 6th Applied Natural Language Processing
(ANLP-2000).
P. Brown, J. Cocke, S. Della Pietra, V. Della Pietra, F. Jelinek,
J. D. Lafferty, R. Mercer, and P. S. Roossin. 1990. A sta-
tistical approach to machine translation. Computational Lin-
guistics, 16(2):79?85.
C. Callison-Burch, C. Fordyce, P. Koehn, C. Monz, and
J. Schroeder. 2007. (Meta-) evaluation of machine trans-
lation. In Proceedings of the ACL 2007 Workshop on Statis-
tical and Hybrid methods for Machine Translation (WMT),
pages 136?158.
X. Carreras, I. Chao, L. Padr?, and M. Padr?. 2004. Freeling:
An open-source suite of language analyzers. In Proceedings
of the 4th Int. Conf. on Language Resources and Evaluation
(LREC?04).
J. M. Crego and J. B. Mari?o. 2006. Improving statistical MT
by coupling reordering and decoding. Machine Translation,
20(3):199?215.
A. de Gispert. 2006. Introducing linguistic knowledge into
statistical machine translation. Ph.D. thesis, Universitat
Polit?cnica de Catalunya, December.
P. Koehn and C. Monz. 2006. Manual and automatic eval-
uation of machine translation between european languages.
In Proceedings of the ACL 2006 Workshop on Statistical and
Hybrid methods for Machine Translation (WMT), pages 102?
121.
J. B. Mari?o, R. E. Banchs, J. M. Crego, A. de Gispert, P. Lam-
bert, J. A. R. Fonollosa, and M. R. Costa-juss?. 2006. N-
gram based machine translation. Computational Linguistics,
32(4):527?549, December.
F. J. Och and H. Ney. 2000. Improved statistical alignment
models. In Proceedings of the the 38th Annual Meeting
on Association for Computational Linguistics (ACL), pages
440?447.
F. Och and H. Ney. 2004. The alignment template approach to
statistical machine translation. 30(4):417 ? 449, December.
130
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 85?89,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
The TALP-UPC phrase-based translation system for EACL-WMT 2009
Jos? A.R. Fonollosa and Maxim Khalilov and Marta R. Costa-juss? and
Jos? B. Mari?o and Carlos A. Henr?quez Q. and Adolfo Hern?ndez H. and
Rafael E. Banchs
TALP Research Center
Universitat Polit?cnica de Catalunya, Barcelona 08034
{adrian,khalilov,mruiz,canton,carloshq,adolfohh,rbanchs}@talp.upc.edu
Abstract
This study presents the TALP-UPC sub-
mission to the EACL Fourth Worskhop
on Statistical Machine Translation 2009
evaluation campaign. It outlines the ar-
chitecture and configuration of the 2009
phrase-based statistical machine transla-
tion (SMT) system, putting emphasis on
the major novelty of this year: combina-
tion of SMT systems implementing differ-
ent word reordering algorithms.
Traditionally, we have concentrated on
the Spanish-to-English and English-to-
Spanish News Commentary translation
tasks.
1 Introduction
TALP-UPC (Center of Speech and Language
Applications and Technology at the Universitat
Polit?cnica de Catalunya) is a permanent par-
ticipant of the ACL WMT shared translations
tasks, traditionally concentrating on the Spanish-
to-English and vice versa language pairs. In this
paper, we describe the 2009 system?s architecture
and design describing individual components and
distinguishing features of our model.
This year?s system stands aside from the
previous years? configurations which were per-
formed following an N -gram-based (tuple-based)
approach to SMT. By contrast to them, this
year we investigate the translation models (TMs)
interpolation for a state-of-the-art phrase-based
translation system. Inspired by the work pre-
sented in (Schwenk and Est?ve, 2008), we attack
this challenge using the coefficients obtained for
the corresponding monolingual language models
(LMs) for TMs interpolation.
On the second step, we have performed
additional word reordering experiments, com-
paring the results obtained with a statisti-
cal method (R. Costa-juss? and R. Fonollosa,
2009) and syntax-based algorithm (Khalilov and
R. Fonollosa, 2008). Further the outputs of
the systems were combined selecting the trans-
lation with the Minimum Bayes Risk (MBR) al-
gorithm (Kumar, 2004) that allowed significantly
outperforming the baseline configuration.
The remainder of this paper is organized as
follows: Section 2 presents the TALP-UPC?09
phrase-based system, along with the translation
models interpolation procedure and other minor
novelties of this year. Section 3 reports on the ex-
perimental setups and outlines the results of the
participation in the EACL WMT 2009 evaluation
campaign. Section 4 concludes the paper with dis-
cussions.
2 TALP-UPC phrase-based SMT
The system developed for this year?s shared
task is based on a state-of-the-art SMT sys-
tem implemented within the open-source MOSES
toolkit (Koehn et al, 2007). A phrase-based trans-
lation is considered as a three step algorithm:
(1) the source sequence of words is segmented
in phrases, (2) each phrase is translated into tar-
get language using translation table, (3) the target
phrases are reordered to be inherent in the target
language.
A bilingual phrase (which in the context of SMT
do not necessarily coincide with their linguistic
analogies) is any pair of m source words and n
target words that satisfies two basic constraints:
(1) words are consecutive along both sides of the
bilingual phrase and (2) no word on either side of
the phrase is aligned to a word outside the phrase.
Given a sentence pair and a corresponding word-
to-word alignment, phrases are extracted follow-
ing the criterion in (Och and Ney, 2004). The
probability of the phrases is estimated by relative
frequencies of their appearance in the training cor-
pus.
85
Classically, a phrase-based translation system
implements a log-linear model in which a foreign
language sentence fJ1 = f1, f2, ..., fJ is trans-
lated into another language eI1 = e1, e2, ..., eI by
searching for the translation hypothesis e?I1 maxi-
mizing a log-linear combination of several feature
models (Brown et al, 1990):
e?I1 = argmaxeI1
{ M?
m=1
?mhm(eI1, fJ1 )
}
where the feature functions hm refer to the system
models and the set of ?m refers to the weights cor-
responding to these models.
2.1 Translation models interpolation
We implemented a TM interpolation strategy fol-
lowing the ideas proposed in (Schwenk and Es-
t?ve, 2008), where the authors present a promis-
ing technique of target LMs linear interpolation;
in (Koehn and Schroeder, 2007) where a log-linear
combination of TMs is performed; and specifi-
cally in (Foster and Kuhn, 2007) where the authors
present various ways of TM combination and ana-
lyze in detail the TM domain adaptation.
In the framework of the evaluation campaign,
there were two Spanish-to-English parallel train-
ing corpora available: Europarl v.4 corpus (about
50M tokens) and News Commentary (NC) corpus
(about 2M tokens). The test dataset provided by
the organizers this year was from the news do-
main, so we considered the Europarl training cor-
pus as "out-of-domain" data and the News Com-
mentary as "in-domain" training material. Unfor-
tunately, the in-domain corpus is much smaller in
size, however the Europarl corpus can be also used
to increase the final translation and reordering ta-
bles in spite of its different nature.
A straightforward approach to the TM interpo-
lation would be an iterative TM reconstruction ad-
justing scale coefficients on each step of the loop
with use of the highest BLEU score as a maxi-
mization criterion.
However, we did not expect a significant gain
from this time-consumption strategy and we de-
cided to follow a simpler approach. In the pre-
sented results, we obtained the best interpola-
tion weight following the standard entropy-based
optimization of the target-side LM. We adjust
the weight coefficient ?Europarl (?NC = 1 ?
?Europarl) of the linear interpolation of the target-
side LMs:
P (w) = ?Europarl ? PwEuroparl + ?NC ? PwNC (1)
where PwEuroparl and PwNC are probabilities as-
signed to the word sequence w by the LM esti-
mated on Europarl and NC data, respectively.
The scale factor values are automatically opti-
mized to obtain the lowest perplexity ppl(w) pro-
duced by the interpolated LM P (w). We used the
standard script compute ? best ? mix from the
SRI LM package (Stolcke, 2002) for optimization.
On the next step, the optimized coefficients
?Europarl and ?NC are generalized on the interpo-
lated translation and reordering models. In other
words, reordering and translation models are in-
terpolated using the same weights which yield the
lowest perplexity for LM interpolation.
The word-to-word alignment was obtained from
the joint (merged) database (Europarl + NC).
Then, we separately computed the translation and
reordering tables corresponding to the in- and out-
of-domain parts of the joint alignment. The final
tables, as well as the final target LM were obtained
using linear interpolation. The weights were se-
lected using a minimum perplexity criterion esti-
mated on the corresponding interpolated combina-
tion of the target-side LMs.
The optimized coefficient values are: for Span-
ish: NC weight = 0.526, Europarl weight = 0.474;
for English: NC weight = 0.503, Europarl weight
= 0.497. The perplexity results obtained using
monolingual LMs and the 2009 development set
(English and Spanish references) can be found in
Table 1, while the corresponding improvement in
BLEU score is presented in Section 3.3 and sum-
mary of the obtained results (Table 4).
Europarl NC Interpolated
English 463.439 489.915 353.305
Spanish 308.802 347.092 246.573
Table 1: Perplexity results obtained on the Dev
2009 corpus and the monolingual LMs.
Note that the corresponding reordering models
are interpolated with the same weights.
2.2 Statistical Machine Reordering
The idea of the Statistical Machine Reordering
(SMR) stems from the idea of using the power-
ful techniques developed for SMT and to translate
86
the source language (S) into a reordered source
language (S?), which more closely matches the
order of the target language. To infer more re-
orderings, it makes use of word classes. To cor-
rectly integrate the SMT and SMR systems, both
are concatenated by using a word graph which of-
fers weighted reordering hypotheses to the SMT
system. The details are described in (?).
2.3 Syntax-based Reordering
Syntax-based Reordering (SBR) approach deals
with the word reordering problem and is based on
non-isomorphic parse subtree transfer as described
in details in (Khalilov and R. Fonollosa, 2008).
Local and long-range word reorderings are
driven by automatically extracted permutation pat-
terns operating with source language constituents.
Once the reordering patterns are extracted, they
are further applied to monotonize the bilingual
corpus in the same way as shown in the previ-
ous subsection. The target-side parse tree is con-
sidered as a filter constraining reordering rules to
the set of patterns covered both by the source- and
target-side subtrees.
2.4 System Combination
Over the past few years the MBR algorithm uti-
lization to find the best consensus outputs of dif-
ferent translation systems has proved to improve
the translation accuracy (Kumar, 2004). The sys-
tem combination is performed on the 200-best
lists which are generated by the three systems:
(1) MOSES-based system without pre-translation
monotonization (baseline), (2) MOSES-based
SMT enhanced with SMR monotonization and (3)
MOSES-based SMT augmented with SBR mono-
tonization. The results presented in Table 4 show
that the combined output significantly outperforms
the baseline system configuration.
3 Experiments and results
We followed the evaluation baseline instructions 1
to train the MOSES-based translation system.
In some experiments we used MBR decod-
ing (Kumar and Byrne, 2004) with the smoothed
BLEU score as a similarity criteria, that al-
lowed gaining 0.2 BLEU points comparing to the
standard procedure of outputting the translation
with the highest probability (HP). We applied the
Moses implementation of this algorithm to the list
1http://www.statmt.org/wmt09/baseline.html
of 200 best translations generated by the TALP-
UPC system. The results obtained over the official
2009 Test dataset can be found in Table 2.
Task HP MBR
EsEn 24.48 24.62
EnEs 23.46 23.64
Table 2: MBR versus MERT decoding.
The "recase" script provided within the base-
line was supplemented with and additional mod-
ule, which restore the original case for unknown
words (many of them are proper names and loos-
ing of case information leads to a significant per-
formance degradation).
3.1 Language models
The target-side language models were estimated
using the SRILM toolkit (Stolcke, 2002). We tried
to use all the available in-domain training mate-
rial: apart from the corresponding portions of the
bilingual NC corpora we involved the following
monolingual corpora:
? News monolingual corpus (49M tokens for
English and 49M for Spanish)
? Europarl monolingual corpus (about 504M
tokens for English and 463M for Spanish)
? A collection of News development and test
sets from previous evaluations (151K tokens
for English and 175K for Spanish)
? A collection of Europarl development and
test sets from previous evaluations (295K to-
kens for English and 311K for Spanish)
Five LMs per language were estimated on the
corresponding datasets and interpolated follow-
ing the maximum perplexity criteria. Hence, the
larger LMs incorporating in- and out-of-domain
data were used in decoding.
3.2 Spanish enclitics separation
For the Spanish portion of the corpus we imple-
mented an enclitics separation procedure on the
preprocessing step, i.e. the pronouns attached to
the verb were separated and contractions as del
or al were splitted into de el or a el. Conse-
quently, training data sparseness due to Spanish
morphology was reduced improving the perfor-
mance of the overall translation system. As a
87
post-processing, the segmentation was recovered
in the English-to-Spanish direction using target-
side Part-of-Speech tags (de Gispert, 2006).
3.3 Results
The automatic scores provided by the WMT?09
organizers for TALP-UPC submissions calculated
over the News 2009 dataset can be found in Ta-
ble 3. BLEU and NIST case-insensitive (CI) and
case-sensitive (CS) metrics are considered.
Task Bleu CI Bleu CS NIST CI NIST CS
EsEn 25.93 24.54 7.275 7.017
EnEs 24.85 23.37 6.963 6.689
Table 3: BLEU and NIST scores for preliminary
official test dataset 2009 (primary submission)
with 500 sentences excluded.
The TALP-UPC primary submission was
ranked the 3rd among 28 presented translations
for the Spanish-to-English task and the 4th for the
English-to-Spanish task among 9 systems.
The following system configurations and the in-
ternal results obtained are reported:
? Baseline: Moses-based SMT, as proposed
on the web-page of the evaluation campaign
with Spanish enclitics separation and modi-
fied version of ?recase? tool,
? Baseline+TMI: Baseline enhanced with TM
interpolation as described in subsection 2.1,
? Baseline+TMI+MBR: the same as the latter
but with MBR decoding,
? Baseline+TMI+SMR: the same as Base-
line+TMI but with SMR technique applied to
monotonize the source portion of the corpus,
as described in subsection 2.2,
? Baseline+SBR: the same as Baseline but with
SBR algorithm applied to monotonize the
source portion of the corpus, as described in
subsection 2.3,
? System Combination: a combined output of
the 3 previous systems done with the MBR
algorithm, as described in subsection 2.4.
Impact of TM interpolation and MBR decod-
ing is more significant for the English-to-Spanish
translation task, for which the target-side mono-
lingual corpus is smaller than for the Spanish-to-
English translation.
We did not have time to meet the evalua-
tion deadline for providing the system combi-
nation output. Nevertheless, during the post-
evaluation period we performed the experiments
reported in the last three lines of Table 4 (Base-
line+TMI+SMR, Baseline+SBR and System com-
bination).
Note that the results presented in Table 4 differ
from the ones which can be found the Table 3 due
to selective conditions of preliminary evaluation
done by the Shared Task organizers.
System News 2009 Test CI News 2009 Test CS
Spanish-to-English
Baseline 25.82 24.37
Baseline+TMI 25.84 24.47
Baseline+TMI+MBR (Primary) 26.04 24.62
Baseline+SMR 24.95 23.62
Baseline+SBR 24.24 22.89
System combination 26.44 25.00
English-to-Spanish
Baseline 24.56 23.05
Baseline+TMI 25.01 23.41
Baseline+TMI+MBR (Primary) 25.16 23.64
Baseline+SMR 24.09 22.65
Baseline+SBR 23.52 22.05
System combination 25.39 23.86
Table 4: Experiments summary.
88
4 Conclusions
In this paper, we present the TALP-UPC phrase-
based translation system developed for the EACL-
WMT 2009 evaluation campaign. The major nov-
elties of this year are translation models interpola-
tion done in linear way and combination of SMT
systems implementing different word reordering
algorithms. The system was ranked pretty well for
both translation tasks in which our institution has
participated.
Unfortunately, the promising reordering tech-
niques and the combination of their outputs were
not applied within the evaluation deadline, how-
ever we report the obtained results in the paper.
5 Acknowledgments
This work has been funded by the Spanish Gov-
ernment under grant TEC2006-13964-C03 (AVI-
VAVOZ project).
References
P. Brown, J. Cocke, S. Della Pietra, V. Della Pietra,
F. Jelinek, J.D. Lafferty, R. Mercer, and P.S.
Roossin. 1990. A statistical approach to machine
translation. Computational Linguistics, 16(2):79?
85.
A. de Gispert. 2006. Introducing linguistic knowledge
into Statistical Machine Translation. Ph.D. thesis,
Universitat Polit?cnica de Catalunya, December.
G. Foster and R. Kuhn. 2007. Mixture-model adap-
tation for SMT. In In Annual Meeting of the Asso-
ciation for Computational Linguistics: Proc. of the
Second Workshop on Statistical Machine Transla-
tion (WMT), pages 128?135, Prague, Czech Repub-
lic, June.
M. Khalilov and J. R. Fonollosa. 2008. A new subtree-
transfer approach to syntax-based reordering for sta-
tistical machine translation. Technical report, Uni-
versitat Polit?cnica de Catalunya.
Ph. Koehn and J. Schroeder. 2007. Experiments in do-
main adaptation for statistical machine translation.
In In Annual Meeting of the Association for Compu-
tational Linguistics: Proc. of the Second Workshop
on Statistical Machine Translation (WMT), pages
224?227, Prague, Czech Republic, June.
Ph. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Con-
stantin, and E. Herbst. 2007. Moses: open-source
toolkit for statistical machine translation. In Pro-
ceedings of the Association for Computational Lin-
guistics (ACL) 2007, pages 177?180.
Sh. Kumar and W. Byrne. 2004. Minimum bayes-risk
decoding for statistical machine translation. In In
HLTNAACL?04, pages 169?176.
Sh. Kumar. 2004. Minimum Bayes-Risk Techniques in
Automatic Speech Recognition and Statistical Ma-
chine Translation. Ph.D. thesis, Johns Hopkins Uni-
versity.
F. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Compu-
tational Linguistics, 3(4):417?449, December.
M. R. Costa-juss? and J. R. Fonollosa. 2009. An
Ngram reordering model. Computer Speech and
Language. ISSN 0885-2308, accepted for publica-
tion.
H. Schwenk and Y. Est?ve. 2008. Data selection and
smoothing in an open-source system for the 2008
nist machine translation evaluation. In Proceedings
of the Interspeech?08, pages 2727?2730, Brisbane,
Australia, September.
A. Stolcke. 2002. SRILM: an extensible language
modeling toolkit. In Proceedings of the Int. Conf.
on Spoken Language Processing, pages 901?904.
89
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 98?102,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Using collocation segmentation to augment the phrase table
Carlos A. Henr?quez Q.
?
, Marta R. Costa-juss?
?
, Vidas Daudaravicius?
Rafael E. Banchs
?
, Jos? B. Mari?o
?
?
TALP Research Center, Universitat Polit?cnica de Catalunya, Barcelona, Spain
{carlos.henriquez,jose.marino}@upc.edu
?
Barcelona Media Innovation Center, Barcelona, Spain
{marta.ruiz,rafael.banchs}@barcelonamedia.org
?Faculty of Informatics, Vytautas Magnus University, Kaunas, Lithuania
vidas@donelaitis.vdu.lt
Abstract
This paper describes the 2010 phrase-based
statistical machine translation system de-
veloped at the TALP Research Center of
the UPC
1
in cooperation with BMIC
2
and
VMU
3
. In phrase-based SMT, the phrase
table is the main tool in translation. It is
created extracting phrases from an aligned
parallel corpus and then computing trans-
lation model scores with them. Performing
a collocation segmentation over the source
and target corpus before the alignment
causes that different and larger phrases
are extracted from the same original doc-
uments. We performed this segmentation
and used the union of this phrase set with
the phrase set extracted from the non-
segmented corpus to compute the phrase
table. We present the configurations con-
sidered and also report results obtained
with internal and official test sets.
1 Introduction
The TALP Research Center of the UPC
1
in coop-
eration with BMIC
2
and VMU
3
participated in the
Spanish-to-English WMT task. Our primary sub-
mission was a phrase-based SMT system enhanced
with POS tags and our contrastive submission was
an augmented phrase-based system using colloca-
tion segmentation (Costa-juss? et al, 2010), which
mainly is a way of introducing new phrases in the
translation table. This paper presents the descrip-
tion of both systems together with the results that
we obtained in the evaluation task and is organized
as follows: first, Section 2 and 3 present a brief de-
scription of a phrase-based SMT, followed by a gen-
eral explanation of collocation segmentation. Sec-
tion 4 presents the experimental framework, corpus
used and a description of the different systems built
for the translation task; the section ends showing
the results we obtained over the official test set. Fi-
nally, section 5 presents the conclusions obtained
from the experiments.
1
Universitat Polit?cnica de Catalunya
2
Barcelona Media Innovation Center
3
Vytautas Magnus University
2 Phrase-based SMT
This approach to SMT performs the translation
splitting the source sentence in segments and as-
signing to each segment a bilingual phrase from
a phrase-table. Bilingual phrases are translation
units that contain source words and target words,
e.g. < unidad de traduccio?n | translation unit >,
and have different scores associated to them. These
bilingual phrases are then sorted in order to max-
imize a linear combination of feature functions.
Such strategy is known as the log-linear model
(Och and Ney, 2003) and it is formally defined as:
e? = arg max
e
[
M?
m=1
?mhm (e, f)
]
(1)
where hm are different feature functions with
weights ?m. The two main feature functions
are the translation model (TM) and the target
language model (LM). Additional models include
POS target language models, lexical weights, word
penalty and reordering models among others.
3 Collocation segmentation
Collocation segmentation is the process of de-
tecting boundaries between collocation segments
within a text (Daudaravicius and Marcinkeviciene,
2004). A collocation segment is a piece of text be-
tween boundaries. The boundaries are established
in two steps using two different measures: the Dice
score and a Average Minimum Law (AML).
The Dice score is used to measure the associa-
tion strength between two words. It has been used
before in the collocation compiler XTract (Smadja,
1993) and in the lexicon extraction system Cham-
pollion (Smadja et al, 1996). It is defined as fol-
lows:
Dice (x; y) =
2f (x, y)
f (x) + f (y)
(2)
where f (x, y) is the frequency of co-occurrence of
x and y, and f (x) and f (y) the frequencies of
occurrence of x and y anywhere in the text. It gives
high scores when x and y occur in conjunction.
The first step then establishes a boundary between
98
two adjacent words when the Dice score is lower
than a threshold t = exp (?8). Such a threshold
was established following the results obtained in
(Costa-juss? et al, 2010), where an integration of
this technique and a SMT system was performed
over the Bible corpus.
The second step of the procedure uses the AML.
It defines a boundary between words xi?1 and xi
when:
Dice (xi?2;xi?1) +Dice (xi;xi+1)
2
> Dice (xi?1;xi)
(3)
That is, the boundary is set when the Dice value
between words xi and xi?1 is lower than the aver-
age of preceding and following values.
4 Experimental Framework
All systems were built using Moses (Koehn et al,
2007), a state-of-the-art software for phrase-based
SMT. For preprocessing Spanish, we used Freeling
(Atserias et al, 2006), an open source library of
natural language analyzers. For English, we used
TnT (Brants, 2000) and Moses' tokenizer. The
language models were built using SRILM (Stolcke,
2002).
4.1 Corpus
This year, the translation task provided four dif-
ferent sources to collect corpora for the Spanish-
English pair. Bilingual corpora included version 5
of the Europarl Corpus (Koehn, 2005), the News
Commentary corpus and the United Nations cor-
pus. Additional English corpora was available from
the News corpus. The organizers also allowed the
use of the English Gigaword Third and Fourth Edi-
tion, released by the LDC. As for development
and internal test, the test sets from 2008 and 2009
translation tasks were available.
For our experiments, we selected as training data
the union of the Europarl and the News Commen-
tary. Development was performed with a section
of the 2008 test set and the 2009 test set was se-
lected as internal test. We deleted all empty lines,
removed pairs that were longer than 40 words, ei-
ther in Spanish or English; and also removed pairs
whose ratio between number of words were bigger
than 3.
As a preprocess, all corpora were lower-cased
and tokenized. The Spanish corpus was tokenized
and POS tags were extracted using Freeling, which
split clitics from verbs and also separated words
like del into de el. In order to build a POS tar-
get language model, we also obtained POS tags
from the English corpus using the TnT tagger.
Statistics of the selected corpus can be seen in Ta-
ble 1.
Corpora Spanish English
Training sent 1, 180, 623 1, 180, 623
Running words 26, 454, 280 25, 291, 370
Vocabulary 118, 073 89, 248
Development sent 1, 729 1, 729
Running words 37, 092 34, 774
Vocabulary 7, 025 6, 199
Internal test sent 2, 525 2, 525
Running words 69, 565 65, 595
Vocabulary 10, 539 8, 907
Official test sent 2, 489 -
Running words 66, 714 -
Vocabulary 10, 725 -
Table 1: Statistics for the training, development
and test sets.
Internal test Official test
Adjectives 137 72
Common nouns 369 188
Proper nouns 408 2, 106
Verbs 213 128
Others 119 168
Total 1246 2662
Table 2: Unknown words found in internal and
official test sets
It is important to notice that neither the United
Nations nor the Gigaword corpus were used for
bilingual training. Nevertheless, the English part
from the United Nations and the monolingual
News corpus were used to build the language model
of our systems.
4.1.1 Unknown words
We analyzed the content from the internal and of-
ficial test and realized that they both contained
many words that were not seen in the training data.
Table 2 shows the number of unknown words found
in both sets, classified according to their POS.
In average, we may expect an unknown word
every two sentences in the internal test and more
than one per sentence in the official test set. It can
also be seen that most of those unknown words are
proper nouns, representing 32% and 79% of the
unknown sets, respectively. Common nouns were
the second most frequent type of unknown words,
followed by verbs and adjectives.
4.2 Systems
We submitted two different systems for the trans-
lation task. First a baseline using the training data
mentioned before; and then an augmented system,
where the baseline-extracted phrase list was ex-
tended with additional phrases coming from a seg-
mented version of the training corpus.
We also considered an additional system built
99
with two different decoding path, a standard path
from words to words and POS and an alternative
path from stems to words and POS in the target
side. At the end, we did not submit this system
to the translation task because it did not provide
better results than the previous two in our internal
test.
The set of feature functions used include: source-
to-target and target-to-source relative frequen-
cies, source-to-target and target-to-source lexical
weights, word and phrase penalties, a target lan-
guage model, a POS target language model, and a
lexicalized reordering model (Tillman, 2004).
4.2.1 Considering stems as an alternate
decoding path.
Using Moses' framework for factored translation
models we defined a system with two decoding
paths: one decoding path using words and the
other decoding path using stems in the source lan-
guage and words in the target language. Both de-
coding paths only had a single translation step.
The possibility of using multiple alternative decod-
ing path was developed by Birch et. al. (2007).
This system tried to solve the problem with the
unknown words. Because Spanish is morphologi-
cally richer than English, this alternative decoding
path allowed the decoder translate words that were
not seen in the training data and shared the same
root with other known words.
4.2.2 Expanding the phrase table using
collocation segmentation.
In order to build the augmented phrase table with
the technique mentioned in section 3, we seg-
mented each language of the bilingual corpus in-
dependently and then, using the collocation seg-
ments as words, we aligned the corpus and ex-
tracted the phrases from it. Once the phrases were
extracted, the segments of each phrase were split
again in words to have standard phrases. Finally,
we use the union of this phrases and the phrases
extracted from the baseline system to compute the
final phrase table. A diagram of the whole proce-
dure can be seen in figure 1.
The objective of this integration is to add new
phrases in the translation table and to enhance
the relative frequency of the phrases that were ex-
tracted from both methods.
4.2.3 Language model interpolation.
Because SMT systems are trained with a bilingual
corpus, they ended highly tied to the domain the
corpus belong to. Therefore, when the documents
we want to translate belong to a different domain,
additional domain adaptation techniques are rec-
ommended to build the system. Those techniques
usually employ additional corpora that correspond
to the domain we want to translate from.
internal test
baseline 24.25
baseline+stem 23.45
augmented 23.9
Table 3: Internal test results.
test testcased?detok
baseline 26.1 25.1
augmented 26.1 25.1
Table 4: Results from translation task
The test set for this translation task comes from
the news domain, but most of our bilingual cor-
pora belonged to a political domain, the Europarl.
Therefore we use the additional monolingual cor-
pus to adapt the language model to the news do-
main.
The strategy used followed the experiment per-
formed last year in (R. Fonollosa et al, 2009).
We used SRILM during the whole process. All
language models were order five and used modi-
fied Kneser-Ney discount and interpolation. First,
we build three different language models accord-
ing to their domain: Europarl, United Nations and
news; then, we obtained the perplexity of each lan-
guage model over the News Commentary develop-
ment corpus; next, we used compute-best-mix to
obtain weights for each language model that di-
minish the global perplexity. Finally, the models
were combined using those weights.
In our experiments all systems used the resulting
language model, therefore the difference obtained
in our results were cause only by the translation
model.
4.3 Results
We present results from the three systems devel-
oped this year. First, the baseline, which included
all the features mentioned in section 4.2; then, the
system with an alternative decoding path, called
baseline+stem; and finally the augmented system,
which integrated collocation segmentation to the
baseline. Internal test results can be seen in table
3. Automatic scores provided by the WMT 2010
organizers for the official test can be found in ta-
ble 4. All BLEU scores are case-insensitive and
tokenized except for the official test set which also
contains case-sensitive and non-tokenized score.
We obtained a BLEU score of 26.1 and 25.1 for
our case-insensitive and sensitive outputs, respec-
tively. The highest score was obtained by Uni-
versity of Cambridge, with 30.5 and 29.1 BLEU
points.
100
Figure 1: Example of the expansion of the phrase table using collocation segmentation. New phrases
added by the collocation-based system are marked with a ??.
4.3.1 Comparing systems
Once we obtained the translation outputs from the
baseline and the augmented system, we performed
a manual comparison of them. Even though we
did not find any significant advantages of the aug-
mented system over the baseline, the collocation
segmentation strategy chose a better morphologi-
cal structures in some cases as can be seen in Table
5 (only sentence sub-segments are shown):
5 Conclusion
We presented two different submissions for the
Spanish-English language pair. The language
model for both system was built interpolating two
big out-of-domain language models and one smaller
in-domain language model. The first system was a
baseline with POS target language model; and the
second one an augmented system, that integrates
the baseline with collocation segmentation. Re-
sults over the official test set showed no difference
in BLEU between these two, even though internal
results showed that the baseline obtained a better
score.
We also considered adding an additional decod-
ing path from stems to words in the baseline but
internal tests showed that it did not improve trans-
lation quality either. The high number of unknown
words found in Spanish suggested us that consider-
ing in parallel the simple form of stems could help
us achieve better results. Nevertheless, a deeper
study of the unknown set showed us that most
of those words were proper nouns, which do not
have inflection and therefore cannot benefited from
stems.
Finally, despite that internal test did not showed
an improvement with the augmented system, we
submitted it as a secondary run looking for the
effect these phrases could have over human evalu-
ation.
Acknowledgment
The research leading to these results has received
funding from the European Community's Seventh
Framework Programme (FP7/2007-2013) under
grant agreement number 247762, from the Span-
ish Ministry of Science and Innovation through the
Buceador project (TEC2009-14094-C04-01) and
the Juan de la Cierva fellowship program. The
authors also wants to thank the Barcelona Media
Innovation Centre for its support and permission
to publish this research.
References
Jordi Atserias, Bernardino Casas, Elisabet
Comelles, Meritxell Gonz?lez, Llu?s Padr?, and
Muntsa Padr?. 2006. FreeLing 1.3: Syntactic
and semantic services in an open-source NLP
101
Original: sabiendo que est? recibiendo el premio
Baseline: knowing that it receive the prize
Augmented: knowing that he is receiving the prize
Original: muchos de mis amigos prefieren no separarla.
Baseline: many of my friends prefer not to separate them.
Augmented: many of my friends prefer not to separate it.
Original: Los estadounidenses contar?n con un tel?fono m?vil
Baseline: The Americans have a mobile phone
Augmented: The Americans will have a mobile phone
Original: es plenamente consciente del camino m?s largo que debe emprender
Baseline: is fully aware of the longest journey must undertake
Augmented: is fully aware of the longest journey that need to be taken
Table 5: Comparison between baseline and augmented outputs
library. In Proceedings of the fifth interna-
tional conference on Language Resources and
Evaluation (LREC 2006), ELRA, Genoa, Italy,
May.
Alexandra Birch, Miles Osborne, and Philipp
Koehn. 2007. Ccg supertags in factored statis-
tical machine translation. In StatMT '07: Pro-
ceedings of the Second Workshop on Statistical
Machine Translation, pages 916, Morristown,
NJ, USA. Association for Computational Lin-
guistics.
Thorsten Brants. 2000. TnT  a statistical part-
of-speech tagger. In Proceedings of the Sixth
Applied Natural Language Processing (ANLP-
2000), Seattle, WA.
Marta R. Costa-juss?, Vidas Daudaravicius, and
Rafael E. Banchs. 2010. Integration of statisti-
cal collocation segmentations in a phrase-based
statistical machine translation system. In 14th
Annual Conference of the European Association
for Machine Translation.
Vidas Daudaravicius and Ruta Marcinkeviciene.
2004. Gravity counts for the boundaries of col-
locations. International Journal of Corpus Lin-
guistics, 9:321348(28).
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ond?ej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open Source Toolkit for Statistical Ma-
chine Translation. In ACL '07: Proceedings of
the 45th Annual Meeting of the ACL on Interac-
tive Poster and Demonstration Sessions, pages
177180, Morristown, NJ, USA. Association for
Computational Linguistics.
Philipp Koehn. 2005. Europarl: A Parallel Corpus
for Statistical Machine Translation. In Machine
Translation Summit.
Franz Josef Och and Hermann Ney. 2003. A Sys-
tematic Comparison of Various Statistical Align-
ment Models. Computational Linguistics, 29:19
51.
Jos? A. R. Fonollosa, Maxim Khalilov, Marta R.
Costa-juss?, Jos? B. Mari?o, Carlos A. Hen-
r?quez Q., Adolfo Hern?ndez H., and Rafael E.
Banchs. 2009. The TALP-UPC phrase-based
translation system for EACL-WMT 2009. In
Proceedings of the Fourth Workshop on Statis-
tical Machine Translation, pages 8589, Athens,
Greece, March. Association for Computational
Linguistics.
Frank A. Smadja, Kathleen McKeown, and
Vasileios Hatzivassiloglou. 1996. Translating
collocations for bilingual lexicons: A statistical
approach. Computational Linguistics, 22(1):1
38.
Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Comput. Linguist., 19(1):143177.
Andreas Stolcke. 2002. SRILM  an extensible
language modeling toolkit. pages 901904.
Christoph Tillman. 2004. A Unigram Orientation
Model for Statistical Machine Translation. In
HLT-NAACL.
102
Proceedings of the 7th Workshop on Statistical Machine Translation, pages 275?282,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
The TALP-UPC phrase-based translation systems for WMT12: Morphologysimplification and domain adaptationLlu??s Formiga, Carlos A. Henr??quez Q., Adolfo Herna?ndez,Jose? B. Marin?o, Enric Monte and Jose? A. R. Fonollosa
TALP Research Centre
Universitat Polite`cnica de Catalunya
Barcelona, Spain
{lluis.formiga,carlos.henriquez,adolfo.hernandezjose.marino,enric.monte,jose.fonollosa}@upc.eduAbstract
This paper describes the UPC participation in
the WMT 12 evaluation campaign. All sys-
tems presented are based on standard phrase-
based Moses systems. Variations adopted sev-
eral improvement techniques such as mor-
phology simplification and generation and do-
main adaptation. The morphology simpli-
fication overcomes the data sparsity prob-
lem when translating into morphologically-
rich languages such as Spanish by translat-
ing first to a morphology-simplified language
and secondly leave the morphology gener-
ation to an independent classification task.
The domain adaptation approach improves the
SMT system by adding new translation units
learned from MT-output and reference align-
ment. Results depict an improvement on TER,
METEOR, NIST and BLEU scores compared
to our baseline system, obtaining on the of-
ficial test set more benefits from the domain
adaptation approach than from the morpho-
logical generalization method.1 Introduction
TALP-UPC (Center of Speech and Language
Applications and Technology at the Universitat
Polite`cnica de Catalunya) has participated in the
WMT12 shared task translating across two direc-
tions: English to Spanish and Spanish to English
tasks.
For the Spanish to English task we submitted a
baseline system that uses all parallel training data
and a combination of different target language mod-
els (LM) and Part-Of-Speech (POS) language mod-
els. A similar configuration was submitted for the
English to Spanish task as baseline. Our main ap-
proaches enriched the latter baseline in two indepen-
dent ways: morphology simplification and domain
adaptation by deriving new units into the phrase-
table. Furthermore, additional specific strategies
have been addressed on all systems to deal with well
known linguistic phenomena in Spanish such as cli-
tics and contractions.
The paper is presented as follows. Section 2
presents the main rationale for the phrase-based sys-
tem and the main pipeline of our baseline system.
Section 3 presents the approaches taken to improve
the baseline system on the English to Spanish task.
Section 4 presents the obtained results on internal
and official test sets while conclusions and further
work are presented in Section 5.2 Baseline system: Phrase-Based SMT
Classically, a phrase-based translation system im-
plements a log-linear model in which a foreign lan-
guage sentence f j1 = f1, f2, . . . , fj is translated into
another language sentence eI1 = e1, e2, . . . , eI by
searching for the translation hypothesis that max-
imizes a log-linear combination of feature models
(Brown et al, 1990):
e?I1 = argmaxeI1 ( MXm=1 mhm  eI1, fJ1  ) (1)
where the separate feature functions hm refer to
the system models and the set of  m refers to the
weights corresponding to these models. As fea-
ture functions we used the standard models available
275
the$ NATO$ mission$ officially$ ended$
la$ misi?n$ de$ la$ OTAN$ termin?$ oficialmente$
DAFS$ NCFS$ SPS$ DAFS$ NP$ VMIS3S0$ RG$
Figure 1: Factored phrase-based MT based on trans-
lation from surface to surface and Part-of-Speech
on Moses, i.e., relative frequencies, lexical weights,
word and phrase penalty, wbe-msd-bidirectional-fe
reordering models and two language models, one for
surface and one for POS tags. Phrase scoring was
computed using Good-Turing discounting (Foster et
al., 2006).
The tuning process was done using MERT (Och,
2003) with Minimum Bayes-Risk decoding (MBR)
(Kumar and Bryne, 2004) on Moses and focusing on
minimizing the BLEU score (Papineni et al, 2002)
of the development set. Final translations were also
computed using MBR decoding.
Additionally to the settings mentioned before, we
worked with a factored version of the corpus. Fac-
tored corpora augments surface forms with addi-
tional information, such as POS tags or lemmas as
shown in Figure 1. In that case, factors other than
surface (e.g. POS) are usually less sparse, allowing
to build factor-specific language models with higher-
order n-grams. These higher-order language models
usually help to obtain more syntactically correct out-
put. Concretely we map input source surfaces to tar-
get surfaces and POS tags.2.1 Corpus used
The baseline system was trained using all paral-
lel corpora, i.e. the European Parliament (EPPS)
(Koehn, 2005), News Commentary and United Na-
tions. Table 1 shows the statistics of the training data
after the cleaning process described later on Subsec-
tion 2.2.
Regarding the monolingual data, there was also
more News corpora separated by years for Spanish
and English and there was the Gigaword monolin-
gual corpus for English. All data can be found on
the Translation Task?s website1. We used all News
corpora (and Gigaword for English) to build the lan-
1http://www.statmt.org/wmt12/translation-task.html
Corpus Sent. Words Vocab. avg.len.
EPPS
Eng
1.90 M
49.40 M 124.03 k 26.05
Spa 52.66 M 154.67 k 27.28
News.Com
Eng
0.15 M
3.73 M 62.70 k 24.20
Spa 4.33 M 73.97 k 28.09
UN
Eng
8.38 M
205.68 M 575.04 k 24.54
Spa 239.40 M 598.54 k 28.56
Table 1: English-Spanish corpora statistics for
NAACL-WMT 2012 after cleaning process
guage model. Initially, a LM was built for every cor-
pus and then they were combined to produce de final
LM. Table 2 presents the statistics of each corpora,
again after the cleaning process.
Corpus Sent. Words Vocab.
EPPS
Eng 2.22 M 59.88 M 144.03 k
Spa 2.12 M 61.97 M 174.92 k
News.Com.
Eng 0.21 M 5.08 M 72.55 k
Spa 0.18 M 5.24 M 81.56 k
UN
Eng 11.20 M 315.90 M 767.12 k
Spa 11.20 M 372.21 M 725.73 k
News.07
Eng 3.79 M 90.25 M 711.55 k
Spa 0.05 M 1.33 M 64.10 k
News.08
Eng 13.01 M 308.82 M 1555.53 k
Spa 1.71 M 49.97 M 377.56 k
News.09
Eng 14.75 M 348.24 M 1648.05 k
Spa 1.07 M 30.57 M 287.81 k
News.10
Eng 6.81 M 158.15 M 915.14 k
Spa 0.69 M 19.58 M 226.76 k
News.11
Eng 13.46 M 312.50 M 1345.79 k
Spa 5.11 M 151.06 M 668.63 k
Giga Eng 22.52 M 657.88 M 3860.67 k
Table 2: Details of monolingual corpora used for
building language-models.
For internal testing we used the News 2011?s data
and concatenated the remaining three years of News
data as a single parallel corpus for development. Ta-
ble 3 shows the statistics for these two sets and in-
cludes in the last rows the statistics of the official test
set for this year?s translation task.2.2 Corpus processing
All corpora were processed in order to remove or
normalize ambiguous or special characters such as
quotes and spaces. Among other TALP-UPC spe-
cific scripts, we used a modified version of the
normalized-punctuation script provided by the orga-
nizers in order to skip the reordering rules which in-
volved quotes and stop punctuation signs.
276
Corpus Sent. Words Vocab. avg.len.
dev
Eng
7.57 k
189.01 k 18.61 k 24.98
Spa 202.80 k 21.75 k 26.80
test11
Eng
3.00 k
74.73 k 10.82 k 24.88
Spa 81.01 k 12.16 k 26.98
test12
Eng
3.00 k
72.91 k 10.24 k 24.28
Spa 80.38 k 12.02 k 26.77
Table 3: Detail of development and test corpora used
to tune and test the system.
POS-Tagging and tokenization for both Spanish
and English data sets were obtained using FreeLing
(Padro? et al, 2010). Freeling tokenization is able
to deal with contractions (?del? ! ?de el?) and cli-
tics separation (?co?mpramelo? ! ?compra me lo?)
in Spanish and English. Stemming was performed
using Snowball (Porter, 2001).
Surface text was lowercased conditionally based
on the POS tagging: proper nouns and adjectives
were separated from other POS categories to deter-
mine if a string should be fully lowercased (no spe-
cial property), partially lowercased (proper noun or
adjective) or not lowercased at all (acronym).
Bilingual corpora were cleaned with clean-
corpus-n script of Moses (Koehn et al, 2007) re-
moving all sentence pair with more than 70 words
in any language, considering the already tokenized
data. That script also ensures a maximum length
ratio below of nine (9) words between source and
target sentences.
Postprocessing in both languages consisted of a
recasing step using Moses recaser script. Further-
more we built an additional script in order to check
the casing of output names with respect to source
sentence names and case them accordingly, with ex-
ception of names placed at beginning of the sen-
tence. After recasing, a final detokenization step
was performed using standard Moses tools. Span-
ish postprocessing also included two special scripts
to recover contractions and clitics.2.3 Language Model and alignmentconfiguration
Word alignment was performed at stem level with
GIZA++ toolkit (Och and Ney, 2003) and grow-
diag-final-and joint alignment.
Language models were built from the monolin-
gual data provided covering different domains: Eu-
roparl, News and UN. We built them using Kneser-
Ney algorithm (Chen and Goodman, 1999), inter-
polation in order to avoid over-fitting and consider-
ing unknown words. First we built a 5-gram lan-
guage model for each corpus; then, the final LM
was obtained interpolating them all towards the de-
velopment set. We used SRI Language Model (Stol-
cke, 2002) toolkit, which provides compute-best-mix
script for the interpolation.
The POS language model was built analogously
to the surface language with some variants: it was a7-gram LM, without discounting nor interpolation.3 Improvement strategies3.1 Motivations
In order to improve the baseline system we present
two different strategies. First we present an im-
provement strategy based on morphology simplifi-
cation plus generation to deal with the problems
raised by morphological rich languages such as
Spanish. Second we present a domain adaptation
strategy that consists in deriving new units into the
phrase-table.3.2 Morphology simplification
The first improvement strategy is based on morphol-
ogy simplification when translating from English to
Spanish.
The problems raised when translating from a lan-
guage such as English into richer morphology lan-
guages are well known and are a research line of
interest nowadays (Popovic and Ney, 2004; Koehn
and Hoang, 2007; de Gispert and Marin?o, 2008;
Toutanova et al, 2008; Clifton and Sarkar, 2011). In
that direction, inflection causes a very large target-
language lexicon with a significant data sparsity
problem. In addition, system output is limited only
to the inflected phrases available in the parallel train-
ing corpus. Hence, SMT systems cannot gener-
ate proper inflections unless they have learned them
from the appropriate phrases. That would require to
have a parallel corpus containing all possible word
inflections for all phrases available, which it is an
unfeasible task.
The morphology related problems in MT have
been addressed from different approaches and may
277
????????????? ????????????????
??????????????????????? ???????????? ??????
??????????????????????????????
???????
???????
??????????????????????????
????????????????????????????????? ?? ???????????? ?? ??
????!???"#???$??%&%?$?%?'
????????????????????????
??????????????????????????????
????????????????????
%')???')?'??'????????????????? ?$?*
??)???
??????????????????????
?+$?,$???"?'??$?%?'?$??,?$?#
??$%'%'"???? ??????
Figure 2: Above, flow diagram of the training of simplified morphology translation models. Below, Spanish
morphology generation as an independent classification task.Type Text
PLAIN la Comisio?n puede llegar
TARGET: a paralizar el programa
TARGET+PoS la Comisio?n VMIP3S0[poder]
(Gen. Sur.): llegar a paralizar el programa
TARGET+PoS la Comisio?n VMIPpn0[poder]
(Simpl. PoS): llegar a paralizar el programa
Table 4: Example of morphology simplification
steps taken for Spanish verbs.
be summarized in four categories: i) factored mod-
els (Koehn and Hoang, 2007), enriched input mod-
els (Avramidis and Koehn, 2008; Ueffing and Ney,
2003), segmented translation (Virpioja et al, 2007)
and morphology generation (Toutanova et al, 2008;
de Gispert and Marin?o, 2008).
Our strategy for dealing with morphology gener-
ation is based in the latter approach (de Gispert and
Marin?o, 2008) (Figure 2). We center our strategy in
simplifying only verb forms as previous studies in-
dicate that they contribute to the main improvement
(Ueffing and Ney, 2003; de Gispert and Marin?o,
2008). That strategy makes clear the real impact
of morphology simplification by providing an upper
bound oracle for the studied scenarios.
The approach is as follows: First, target verbs
are simplified substituting them with their sim-
plified forms (Table 4). In this example, the
verb form ?puede? (he can) is transformed into
?VMIPpn0[poder]?, indicating simplified POS and
base form (lemma); where ?p? and ?n? represent any
person and number once simplified (from 3rd per-
son singular). Secondly, standard MT models are
obtained from English into simplified morphology
Spanish. Morphology prediction acts as a black box,
with its models estimated over a simplified morphol-
ogy parallel texts (including target language model
and lexicon models).
Generation is implemented by Decision Directed
Acyclic Graphs (DDAG) (Platt et al, 2000) com-
pound of binary SVM classifiers. In detail, a DDAG
combines many two-class classifiers to a multi-
classification task (Herna?ndez et al, 2010).3.3 Domain adaptation
Depending on the available resources, different do-
main adaptation techniques are possible. Usually,
the baseline system is built with a large out-of-
domain corpus (in our case the European Parlia-
ment) and we aim to adapt to another domain that
has limited data, either only monolingual or hope-
fully bilingual as well. The WMT Translation Task
focuses on adapting the system to a news domain,
offering an in-domain parallel corpus to work with.
In case of additional target monolingual data, pre-
vious works have focused on language model inter-
polations (Bulyko et al, 2007; Mohit et al, 2009;
Wu et al, 2008). When parallel in-domain data
is available, the latest researches have focused on
mixture model adaptation of the translation model
(Civera and Juan, 2007; Foster and Kuhn, 2007; Fos-
ter et al, 2010). Our work is closer to the latest ap-
278
proaches. We used the in-domain parallel data to
adapt the translation model, but focusing on the de-
coding errors that the out-of-domain baseline system
made while translating the in-domain corpus. The
idea is to detect where the system made its mistakes
and use the in-domain data to teach it how to correct
them.
Our approach began with a baseline system built
with the Parliament and the United Nations parallel
corpora but without the News parallel corpus. The
rest of the configuration remained the same for the
baseline. With this alternative baseline system, we
translated the source side of the News parallel cor-
pus to obtain a revised corpus of it, as defined in
(Henr??quez Q. et al, 2011). The revised corpus con-
sists of the source side, the output translation and the
target side, also called the target correction. The out-
put translation and its reference are then compare to
detect possible mistakes that the system caused dur-
ing decoding.
The translation was used as a pivot to find a word-
to-word alignment between the source side and the
target correction. The word-to-word alignment be-
tween source side and translation was provided by
Moses during decoding. The word-to-word align-
ment between the output translation and target cor-
rection was obtained following these steps:
1. Translation Edit Rate (Snover et al, 2006) be-
tween each output translation and target correc-
tion sentence pair was computed to obtain its
edit path and detect which words do not change
between sentences. Words that did not change
were directly linked
2. Going from left to right, for each unaligned
word wout on the output translation sentence
and each word wtrg on the target correction
sentence, a similarity function was computed
between them and wout got aligned with the
word wtrg that maximized this similarity.
The similarity function was defined as a linear
combination of features that considered if the words
wout and wtrg were identical, if the previous or fol-
lowing word of any of them were aligned with each
other and a lexical weight between them using the
bilingual lexical features from the baseline as refer-
ences.
With both word-to-word alignments computed for
a sentence pair, we linked source word wsrc with tar-
get word wtrg is and only if exists a output transla-
tion word wout such that there is a link between wsrc
and wout and a link between wout and wtrg.
After aligning the corpus, we built the transla-
tion and reordering model of it, using the baseline
settings. We called these translation and reorder-
ing models, revised models. They include phrases
found in the baseline that were correctly chosen dur-
ing decoding and also new phrases that came from
the differences between the output translation and its
correction.
Finally, the revised translation model features
were linearly combined with their corresponding
baseline features to build the final translation model,
called the derived translation model. The combina-
tion was computed in the following way:
hid(s, t) = ?hib(s, t) + (1  ?)hir(s, t) (2)
where hid(s, t) is the derived feature function i for
the bilingual phrase (s, t), hib(s, t) is the baseline
feature function of and hir(s, t) the revised feature
function. A value of ? = 0.60 was chosen after de-
termining it was the one that maximized the BLEU
score of the development set during tuning. Differ-
ent values for ? were considered, between 0.50 and0.95 with increments of 0.05 between them.
Regarding the reordering model, we added the un-
seen phrases from the revised reordering model into
the baseline reordering model, leaving the remaining
baseline phrase reordering weights intact.4 Results4.1 Language Model perplexities
LM
Perplexity
Surface POS
Baseline 205.36 13.23
Simplified 193.66 12.66
Table 6: Perplexities obtained across baseline and
morphology simplification.
Before evaluating translation performance, we
studied to what extent the morphology simplifica-
279
EN!ES
BLEU NIST TER METEOR
CS CI CS CI CS CI
test11
Baseline 30.7 32.53 7.820 8.120 57.19 55.05
Morph. Oracle 31.56 33.35 7.949 8.233 56.44 ?
Morph. Gen. 31.03 32.85 7.866 8.163 56.95 55.39
Adaptation 31.16 32.93 7.857 8.155 56.88 55.19
test12
Baseline 31.21 32.74 7.981 8.244 55.76 55.48
Morph. Oracle 32 33.41 8.090 8.339 55.15 ?
Morph. Gen. 31.46 32.98 8.010 8.274 55.62 55.66
Adaptation 31.73 33.24 8.037 8.294 55.37 55.82
(a) English!Spanish
ES!EN
BLEU NIST TER METEOR
CS CI CS CI CS CI
test11
Baseline
28.81 30.29 7.670 7.933 59.01 51.09
test12 32.27 33.81 8.014 8.282 56.26 53.96
(b) Spanish!English
Table 5: Automatic scores for English$Spanish translations. CS and CI indicate Case-Sensitive or Case-
Insensitive evaluations.
tion strategy may help decreasing the language mod-
els perplexity.
In table 6 we can see the effects of simplification.
Perplexity is computed from the corresponding in-
ternal test sets to the baseline or simplified language
models.
In general terms, the simplification process is
slightly effective, yielding an averaged improvement
of  5.02%.4.2 Translation performance
Evaluations were performed with different transla-
tion quality measures: BLEU, NIST, TER and ME-
TEOR (Denkowski and Lavie, 2011) which evalu-
ate distinct aspects of the quality of the translations.
First we evaluated the WMT11 test (test11) as an
internal indicator of our systems. Later we did the
same analysis with the WMT12 official test files.
Table 5 presents the obtained results. Experi-
ments began building the baseline system, which
included the special treatment for clitics, contrac-
tions and casing as described in Section 2.2. Once
the baseline was set, we proceeded with two paral-
lel lines, one for morphology simplification and the
other for domain adaptation.
For morphology generation approach (Table 5)
oracles (Morph. Oracle) represent how much gain
we could expect with a perfect generation module
and generation (Morph. Gen.) represent the actual
performance combining simplification and the gen-
eration strategies. Oracles achieve a promising av-
eraged improvement of +1.79% (depending on the
metric or the test set) with respect to the baseline.
However, generation only improves the baseline by
a +0.61%, encouraging us to keep working on that
strategy.
Regarding the domain adaptation approach, we
evaluated the internal test set (test11). As we can
see again on Table 5a the adaptation strategy outper-
forms the baseline on all quality measures starting
with an averaged gain of +0.94%.
Comparing the two approaches, we can see that
the domain adaptation method was better in terms of
BLEU score and TER than the morphology genera-
tion but the latter was better on NIST and METEOR
on our internal test set. This made us decided for the
latter as the primary system submitted, leaving the
domain adaptation approach system as a contrastive
submission. Additionally to the automatic quality
measures, we are particularly interested in the man-
ual evaluation results, as we believe the morphology
generation will be more sensitive to this type of eval-
280
uation than to automatic metrics.
Official results (test12) can be found on Table 5b.
Surprisingly, this time the domain adaptation ap-
proach performed better than the morphology sim-
plification on all metrics: BLEU, NIST, TER and
METEOR, with an averaged gain of +1.04% over
the baseline system, which ranks our submissions
second and third in terms of BLEU scores (con-
trastive and primary respectively) when compared
with all other submissions for the WMT12 transla-
tion task.5 Conclusions and further work
This papers describes the UPC participation during
the 2012 WMT?s Translation Task. We have partici-
pated with a baseline system for Spanish-to-English,
a baseline system for English-to-Spanish and two in-
dependent enhancements to the baseline system for
English-to-Spanish as well.
Our primary submission applied morphology sim-
plification and generation with the objective of ease
the translation process when dealing with rich mor-
phology languages like Spanish, deferring the mor-
phology generation as an external post-process clas-
sification task.
The second approach focused on domain adapta-
tion. Instead of concatenating the training News par-
allel data together with the European Parliament and
United Nations, a preliminary system was built with
the latter two and separated translation and reorder-
ing models were computed using the News parallel
data. These models were then added to the prelimi-
nary models in order to build the adapted system.
Results showed that both approaches performed
better than the baseline system, being the domain
adaptation configuration the one that performed bet-
ter for 2012 test in terms of all automatic quality
indicators: BLEU, NIST, TER and METEOR. We
look forward the the manual evaluation results as we
believe our primary system may be more sensitive to
this type of human evaluation.
Future work should focus on combining the two
approaches, applying first morphological general-
ization to the training data and then using the domain
adaptation technique on the resulting corpora in or-
der to determine the joined benefits of both strate-
gies.
Acknowledgments
This work has been partially funded by the Spanish
Government (Buceador, TEC2009-14094-C04-01)
and the European Community?s FP7 program under
grant agreement number 247762 (FAUST, FP7-ICT-
2009-4-247762).References
E. Avramidis and P. Koehn. 2008. Enriching morpho-
logically poor languages for statistical machine trans-
lation. Proceedings of ACL-08: HLT, pages 763?770.
P.F. Brown, J. Cocke, S.A.D. Pietra, V.J.D. Pietra, F. Je-
linek, J.D. Lafferty, R.L. Mercer, and P.S. Roossin.
1990. A statistical approach to machine translation.
Computational linguistics, 16(2):79?85.
Ivan Bulyko, Spyros Matsoukas, Richard Schwartz, Long
Nguyen, and John Makhoul. 2007. Language model
adaptation in machine translation from speech. Test,
4:117?120.
S.F. Chen and J. Goodman. 1999. An empirical study of
smoothing techniques for language modeling. Com-
puter Speech & Language, 13(4):359?393.
Jorge Civera and Alfons Juan. 2007. Domain adaptation
in statistical machine translation with mixture mod-
elling. In Proceedings of the Second Workshop on Sta-
tistical Machine Translation, StatMT ?07, pages 177?
180, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
A. Clifton and A. Sarkar. 2011. Combining morpheme-
based machine translation with post-processing mor-
pheme prediction. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies. Portland, OR,
USA.
Adria` de de Gispert and Jose? B. Marin?o. 2008. On the
impact of morphology in English to Spanish statistical
MT. Speech Communication, 50(11-12):1034?1046.
Michael Denkowski and Alon Lavie. 2011. Meteor 1.3:
Automatic Metric for Reliable Optimization and Eval-
uation of Machine Translation Systems. In Proceed-
ings of the EMNLP 2011 Workshop on Statistical Ma-
chine Translation.
George Foster and Roland Kuhn. 2007. Mixture-Model
Adaptation For SMT. In Proceedings of the Second
Workshop on Statistical Machine Translation, StatMT
?07, pages 128?135, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable smoothing for statistical machine
translation. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing,
281
EMNLP ?06, pages 53?61, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
George Foster, Cyril Goutte, and Roland Kuhn. 2010.
Discriminative instance weighting for domain adapta-
tion in statistical machine translation. In Proceedings
of the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 451?459, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Carlos A. Henr??quez Q., Jose? B. Marin?o, and Rafael E.
Banchs. 2011. Deriving translation units using small
additional corpora. In Proceedings of the 15th Confer-
ence of the European Association for Machine Trans-
lation.
Adolfo Herna?ndez, Enric Monte, and Jose? B. Marin?o.
2010. Multiclass classification for Morphology gener-
ation in statistical machine translation. In Proceedings
of the VI Jornadas en Tecnolog??a del Habla? and II
Iberian SLTech Workshop, pages 179?182, November.
http://fala2010.uvigo.es.
Philipp Koehn and Hieu Hoang. 2007. Factored transla-
tion models. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL), pages 868?876, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, et al 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Inter-
active Poster and Demonstration Sessions, pages 177?
180. Association for Computational Linguistics.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Machine Transla-
tion Summit.
Shankar Kumar and William Bryne. 2004. Minimum
bayes-risk decoding for statistical machine translation.
In Proceedings of the Human Language Technology
and North American Association for Computational
Linguistics Conference (HLT/NAACL), Boston,MA,
May 27-June 1.
Behrang Mohit, Frank Liberato, and Rebecca Hwa.
2009. Language Model Adaptation for Difficult to
Translate Phrases. In Proceedings of the 13th Annual
Conference of the EAMT.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Franz J. Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
Annual Meeting of the Association for Computational
Linguistics (ACL).
Llu??s Padro?, Miquel Collado, Samuel Reese, Marina
Lloberes, and Irene Castello?n. 2010. Freeling 2.1:
Five years of open-source language processing tools.
In Proceedings of 7th Language Resources and Evalu-
ation Conference (LREC 2010), La Valletta, MALTA,
May. ELRA.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proceedings of the
Annual Meeting of the Association for Computational
Linguistics (ACL).
John C. Platt, Nello Cristianini, and John Shawe-taylor.
2000. Large margin DAGs for multiclass classifica-
tion. In Advances in Neural Information Processing
Systems, pages 547?553. MIT Press.
Maja Popovic and Hermann Ney. 2004. Towards the
use of word stems and suffixes for statistical machine
translation. In Proceedings of the 4th International
Conference on Language Resources and Evaluation,
LREC?04, pages 1585?1588, May.
M. Porter. 2001. Snowball: A language for stemming
algorithms.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proceedings of Association for Machine
Translation in the Americas.
A. Stolcke. 2002. Srilm-an extensible language mod-
eling toolkit. In Seventh International Conference on
Spoken Language Processing.
Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.
2008. Applying morphology generation models to
machine translation. In Proceedings of ACL-08: HLT,
pages 514?522, Columbus, Ohio, June. Association
for Computational Linguistics.
Nicola Ueffing and Hermann Ney. 2003. Using pos in-
formation for statistical machine translation into mor-
phologically rich languages. In Proceedings of the
tenth conference on European chapter of the Associa-
tion for Computational Linguistics - Volume 1, EACL
?03, pages 347?354, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
S. Virpioja, J.J. Va?yrynen, M. Creutz, and M. Sadeniemi.
2007. Morphology-aware statistical machine transla-
tion based on morphs induced in an unsupervised man-
ner. Machine Translation Summit XI, 2007:491?498.
Hua Wu, Haifeng Wang, and Chengqing Zong. 2008.
Domain adaptation for statistical machine translation
with domain dictionary and monolingual corpora. In
Proceedings of the 22nd International Conference on
Computational Linguistics - Volume 1, COLING ?08,
pages 993?1000, Stroudsburg, PA, USA. Association
for Computational Linguistics.
282
