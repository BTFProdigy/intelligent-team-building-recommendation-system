Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 514?523,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Joint Satisfaction of Syntactic and Pragmatic Constraints
Improves Incremental Spoken Language Understanding
Andreas Peldszus
University of Potsdam
Department for Linguistics
peldszus@uni-potsdam.de
Okko Bu?
University of Potsdam
Department for Linguistics
okko@ling.uni-potsdam.de
Timo Baumann
University of Hamburg
Department for Informatics
baumann@informatik.uni-hamburg.de
David Schlangen
University of Bielefeld
Department for Linguistics
david.schlangen@uni-bielefeld.de
Abstract
We present a model of semantic processing
of spoken language that (a) is robust against
ill-formed input, such as can be expected
from automatic speech recognisers, (b) re-
spects both syntactic and pragmatic con-
straints in the computation of most likely
interpretations, (c) uses a principled, ex-
pressive semantic representation formalism
(RMRS) with a well-defined model the-
ory, and (d) works continuously (produc-
ing meaning representations on a word-
by-word basis, rather than only for full
utterances) and incrementally (computing
only the additional contribution by the new
word, rather than re-computing for the
whole utterance-so-far).
We show that the joint satisfaction of syn-
tactic and pragmatic constraints improves
the performance of the NLU component
(around 10% absolute, over a syntax-only
baseline).
1 Introduction
Incremental processing for spoken dialogue sys-
tems (i. e., the processing of user input even while
it still may be extended) has received renewed at-
tention recently (Aist et al 2007; Baumann et
al., 2009; Bu? and Schlangen, 2010; Skantze and
Hjalmarsson, 2010; DeVault et al 2011; Purver
et al 2011). Most of the practical work, how-
ever, has so far focussed on realising the poten-
tial for generating more responsive system be-
haviour through making available processing re-
sults earlier (e. g. (Skantze and Schlangen, 2009)),
but has otherwise followed a typical pipeline ar-
chitecture where processing results are passed
only in one direction towards the next module.
In this paper, we investigate whether the other
potential advantage of incremental processing?
providing ?higher-level?-feedback to lower-level
modules, in order to improve subsequent process-
ing of the lower-level module?can be realised as
well. Specifically, we experimented with giving a
syntactic parser feedback about whether semantic
readings of nominal phrases it is in the process of
constructing have a denotation in the given con-
text or not. Based on the assumption that speak-
ers do plan their referring expressions so that they
can successfully refer, we use this information to
re-rank derivations; this in turn has an influence
on how the derivations are expanded, given con-
tinued input. As we show in our experiments, for
a corpus of realistic dialogue utterances collected
in a Wizard-of-Oz setting, this strategy led to an
absolute improvement in computing the intended
denotation of around 10% over a baseline (even
more using a more permissive metric), both for
manually transcribed test data as well as for the
output of automatic speech recognition.
The remainder of this paper is structured as fol-
lows: We discuss related work in the next section,
and then describe in general terms our model and
its components. In Section 4 we then describe the
data resources we used for the experiments and
the actual implementation of the model, the base-
lines for comparison, and the results of our exper-
iments. We close with a discussion and an outlook
on future work.
2 Related Work
The idea of using real-world reference to inform
syntactic structure building has been previously
explored by a number of authors. Stoness et al
(2004, 2005) describe a proof-of-concept imple-
514
mentation of a ?continuous understanding? mod-
ule that uses reference information in guiding a
bottom-up chart-parser, which is evaluated on a
single dialogue transcript. In contrast, our model
uses a probabilistic top-down parser with beam
search (following Roark (2001)) and is evalu-
ated on a large number of real-world utterances
as processed by an automatic speech recogniser.
Similarly, DeVault and Stone (2003) describe a
system that implements interaction between a
parser and higher-level modules (in this case, even
more principled, trying to prove presuppositions),
which however is also only tested on a small, con-
structed data-set.
Schuler (2003) and Schuler et al(2009) present
a model where information about reference is
used directly within the speech recogniser, and
hence informs not only syntactic processing but
also word recognition. To this end, the processing
is folded into the decoding step of the ASR, and
is realised as a hierarchical HMM. While techni-
cally interesting, this approach is by design non-
modular and restricted in its syntactic expressiv-
ity.
The work presented here also has connections
to work in psycholinguistics. Pado? et al(2009)
present a model that combines syntactic and se-
mantic models into one plausibility judgement
that is computed incrementally. However, that
work is evaluated for its ability to predict reading
time data and not for its accuracy in computing
meaning.
3 The Model
3.1 Overview
Described abstractly, the model computes the
probability of a syntactic derivation (and its ac-
companying logical form) as a combination of a
syntactic probability (as in a typical PCFG) and
a semantic or pragmatic plausibility.1 The prag-
matic plausibility here comes from the presuppo-
sition that the speaker intended her utterance to
successfully refer, i. e. to have a denotation in the
current situation (a unique one, in the case of def-
inite reference). Hence, readings that do have a
denotation are preferred over those that do not.
1Note that, as described below, in the actual implemen-
tation the weights given to particular derivations are not real
probabilities anymore, as derivations fall out of the beam and
normalisation is not performed after re-weighting.
The components of our model are described in
the following sections: first the parser which com-
putes the syntactic probability in an incremental,
top-down manner; the semantic construction al-
gorithm which associates (underspecified) logi-
cal forms to derivations; the reference resolution
component that computes the pragmatic plausi-
bility; and the combination that incorporates the
feedback from this pragmatic signal.
3.2 Parser
Roark (2001) introduces a strategy for incremen-
tal probabilistic top-down parsing and shows that
it can compete with high-coverage bottom-up
parsers. One of the reasons he gives for choosing
a top-down approach is that it enables fully left-
connected derivations, where at every process-
ing step new increments directly find their place
in the existing structure. This monotonically en-
riched structure can then serve as a context for in-
cremental language understanding, as the author
claims, although this part is not further developed
by Roark (2001). He discusses a battery of dif-
ferent techniques for refining his results, mostly
based on grammar transformations and on con-
ditioning functions that manipulate a derivation
probability on the basis of local linguistic and lex-
ical information.
We implemented a basic version of his parser
without considering additional conditioning or
lexicalizations. However, we applied left-facto-
rization to parts of the grammar to delay cer-
tain structural decisions as long as possible. The
search-space is reduced by using beam search. To
match the next token, the parser tries to expand
the existing derivations. These derivations are
stored in a priorized queue, which means that the
most probable derivation will always be served
first. Derivations resulting from rule expansions
are kept in the current queue, derivations result-
ing from a successful lexical match are pushed in
a new queue. The parser proceeds with the next
most probable derivation until the current queue
is empty or until a threshhold is reached at which
remaining analyses are pruned. This threshhold
is determined dynamically: If the probability of
the current derivation is lower than the product of
the best derivation?s probability on the new queue,
the number of derivations in the new queue, and a
base beam factor (an initial parameter for the size
of the search beam), then all further old deriva-
515
FormulaIU
CandidateAnalysisIU
TagIU
TextualWordIU
FormulaIU[ [l0:a1:i2]{ [l0:a1:i2] } ] FormulaIU[ [l0:a1:e2]{ [l0:a1:e2] }ARG1(a1,x8),l6:a7:addressee(x8),l0:a1:_nehmen(e2)]
CandidateAnalysisIULD=[s*/s, s/vp, vp/vvimp-v1, m(vvimp)]P=0.49S=[V1, S!]
CandidateAnalysisIULD=[]P=1.00S=[S*,S!]
TagIUvvimp
FormulaIU...
CandidateAnalysisIULD=[s*/s,kon,s*, s/vp, vp/vvimp-v1, m(vvimp)]P=0.14S=[V1, kon, S*, S!]
FormulaIU[ [l0:a1:e2]{ [l18:a19:x14] [l0:a1:e2] }ARG1(a1,x8),l6:a7:addressee(x8),l0:a1:_nehmen(e2),ARG2(a1,x14),BV(a13,x14),RSTR(a13,h21),BODY(a13,h22),l12:a13:_def(),qeq(h21,l18)]
CandidateAnalysisIULD=[v1/np-vz, np/det-n1, m(det)]P=0.2205S=[N1, VZ, S!]
TagIUdet
FormulaIU...
CandidateAnalysisIULD=[v1/np-vz, np/pper, i(det)]P=0.00441S=[pper, VZ, S!]
FormulaIU[ [l0:a1:e2]{ [l29:a30:x14] [l0:a1:e2] }ARG1(a1,x8),l6:a7:addressee(x8),l0:a1:_nehmen(e2),ARG2(a1,x14),BV(a13,x14),RSTR(a13,h21),BODY(a13,h22),l12:a13:_def(),l18:a19:_winkel(x14),qeq(h21,l18)]
CandidateAnalysisIULD=[n1/nn-nz, m(nn)]P=0.06615S=[NZ, VZ, S!]
TagIUnn
FormulaIU...
CandidateAnalysisIULD=[n1/adjp-n1, adjp/adja, i(nn)]P=0.002646S=[adja, N1, VZ, S!]
FormulaIU...
CandidateAnalysisIULD=[n1/nadj-nz, nadj/adja, i(nn)]P=0.000441S=[adja, NZ, VZ, S!]
FormulaIU[ [l0:a1:e2]{ [l42:a43:x44] [l29:a30:x14] [l0:a1:e2] }ARG1(a1,x8),l6:a7:addressee(x8),l0:a1:_nehmen(e2),ARG2(a1,x14),BV(a13,x14),RSTR(a13,h21),BODY(a13,h22),l12:a13:_def(),l18:a19:_winkel(x14),ARG1(a40,x14),ARG2(a40,x44),l39:a40:_in(e41),qeq(h21,l18)]
CandidateAnalysisIULD=[nz/pp-nz, pp/appr-np, m(appr)]P=0.0178605S=[NP, NZ, VZ, S!]
TagIUappr
FormulaIU...
CandidateAnalysisIULD=[nz/advp-nz, advp/adv, i(appr)]P=0.0003969S=[adv, NZ, VZ, S!]
FormulaIU...
CandidateAnalysisIULD=[nz/eps, vz/advp-vz, advp/adv, i(appr)]P=0.00007938S=[adv, VZ, S!]
TagIU$TopOfTags
TextualWordIUnimm TextualWordIUden TextualWordIUwinkel TextualWordIUinTextualWordIU$TopOfWords
Figure 1: An example network of incremental units, including the levels of words, POS-tags, syntactic derivations
and logical forms. See section 3 for a more detailed description.
tions are pruned. Due to probabilistic weighing
and the left factorization of the rules, left recur-
sion poses no direct threat in such an approach.
Additionally, we implemented three robust lex-
ical operations: insertions consume the current
token without matching it to the top stack item;
deletions can ?consume? a requested but actu-
ally non-existent token; repairs adjust unknown
tokens to the requested token. These robust op-
erations have strong penalties on the probability
to make sure they will survive in the derivation
only in critical situations. Additionally, only a
single one of them is allowed to occur between
the recognition of two adjacent input tokens.
Figure 1 illustrates this process for the first few
words of the example sentence ?nimm den winkel
in der dritten reihe? (take the bracket in the third
row), using the incremental unit (IU) model to
represent increments and how they are linked; see
(Schlangen and Skantze, 2009).2 Here, syntactic
2Very briefly: rounded boxes in the Figures represent
IUs, and dashed arrows link an IU to its predecessor on the
same level, where the levels correspond to processing stages.
The Figure shows the levels of input words, POS-tags, syn-
tactic derivations and logical forms. Multiple IUs sharing
derivations (?CandidateAnalysisIUs?) are repre-
sented by three features: a list of the last parser ac-
tions of the derivation (LD), with rule expansions
or (robust) lexical matches; the derivation proba-
bility (P); and the remaining stack (S), where S*
is the grammar?s start symbol and S! an explicit
end-of-input marker. (To keep the Figure small,
we artificially reduced the beam size and cut off
alternatives paths, shown in grey.)
3.3 Semantic Construction Using RMRS
As a novel feature, we use for the representation
of meaning increments (that is, the contributions
of new words and syntactic constructions) as well
as for the resulting logical forms the formalism
Robust Minimal Recursion Semantics (Copestake,
2006). This is a representation formalism that was
originally constructed for semantic underspecifi-
cation (of scope and other phenomena) and then
adapted to serve the purposes of semantics repre-
the same predecessor can be regarded as alternatives. Solid
arrows indicate which information from a previous level an
IU is grounded in (based on); here, every semantic IU is
grounded in a syntactic IU, every syntactic IU in a POS-tag-
IU, and so on.
516
sentations in heterogeneous situations where in-
formation from deep and shallow parsers must be
combined. In RMRS, meaning representations of
a first order logic are underspecified in two ways:
First, the scope relationships can be underspeci-
fied by splitting the formula into a list of elemen-
tary predications (EP) which receive a label ` and
are explicitly related by stating scope constraints
to hold between them (e.g. qeq-constraints). This
way, all scope readings can be compactly repre-
sented. Second, RMRS allows underspecification
of the predicate-argument-structure of EPs. Ar-
guments are bound to a predicate by anchor vari-
ables a, expressed in the form of an argument re-
lation ARGREL(a,x). This way, predicates can
be introduced without fixed arity and arguments
can be introduced without knowing which predi-
cates they are arguments of. We will make use of
this second form of underspecification and enrich
lexical predicates with arguments incrementally.
Combining two RMRS structures involves at
least joining their list of EPs and ARGRELs and
of scope constraints. Additionally, equations be-
tween the variables can connect two structures,
which is an essential requirement for semantic
construction. A semantic algebra for the combi-
nation of RMRSs in a non-lexicalist setting is de-
fined in (Copestake, 2007). Unsaturated semantic
increments have open slots that need to be filled
by what is called the hook of another structure.
Hook and slot are triples [`:a:x] consisting of a
label, an anchor and an index variable. Every vari-
able of the hook is equated with the corresponding
one in the slot. This way the semantic representa-
tion can grow monotonically at each combinatory
step by simply adding predicates, constraints and
equations.
Our approach differs from (Copestake, 2007)
only in the organisation of the slots: In an incre-
mental setting, a proper semantic representation
is desired for every single state of growth of the
syntactic tree. Typically, RMRS composition as-
sumes that the order of semantic combination is
parallel to a bottom-up traversal of the syntactic
tree. Yet, this would require for every incremental
step first to calculate an adequate underspecified
semantic representation for the projected nodes
on the lower right border of the tree and then to
proceed with the combination not only of the new
semantic increments but of the complete tree. For
our purposes, it is more elegant to proceed with
semantic combination in synchronisation with the
syntactic expansion of the tree, i.e. in a top-down
left-to-right fashion. This way, no underspecifica-
tion of projected nodes and no re-interpretation of
already existing parts of the tree is required. This,
however, requires adjustments to the slot structure
of RMRS. Left-recursive rules can introduce mul-
tiple slots of the same sort before they are filled,
which is not allowed in the classic (R)MRS se-
mantic algebra, where only one named slot of
each sort can be open at a time. We thus organize
the slots as a stack of unnamed slots, where mul-
tiple slots of the same sort can be stored, but only
the one on top can be accessed. We then define
a basic combination operation equivalent to for-
ward function composition (as in standard lambda
calculus, or in CCG (Steedman, 2000)) and com-
bine substructures in a principled way across mul-
tiple syntactic rules without the need to represent
slot names.
Each lexical items receives a generic represen-
tation derived from its lemma and the basic se-
mantic type (individual, event, or underspecified
denotations), determined by its POS tag. This
makes the grammar independent of knowledge
about what later (semantic) components will ac-
tually be able to process (?understand?).3 Parallel
to the production of syntactic derivations, as the
tree is expanded top-down left-to-right, seman-
tic macros are activated for each syntactic rule,
composing the contribution of the new increment.
This allows for a monotonic semantics construc-
tion process that proceeds in lockstep with the
syntactic analysis.
Figure 1 (in the ?FormulaIU? box) illustrates
the results of this process for our example deriva-
tion. Again, alternatives paths have been cut to
keep the size of the illustration small. Notice that,
apart from the end-of-input marker, the stack of
semantic slots (in curly brackets) is always syn-
chronized with the parser?s stack.
3.4 Computing Noun Phrase Denotations
Formally, the task of this module is, given a model
M of the current context, to compute the set of
all variable assignments such that M satisfies ?:
G = {g | M |=g ?}. If |G| > 1, we say that ?
refers ambiguously; if |G| = 1, it refers uniquely;
3This feature is not used in the work presented here, but
it could be used for enabling the system to learn the meaning
of unknown words.
517
and if |G| = 0, it fails to refer. This process does
not work directly on RMRS formulae, but on ex-
tracted and unscoped first-order representations of
their nominal content.
3.5 Parse Pruning Using Reference
Information
After all possible syntactic hypotheses at an in-
crement have been derived by the parser and
the corresponding semantic representations have
been constructed, reference resolution informa-
tion can be used to re-rank the derivations. If
pragmatic feedback is enabled, the probability of
every reprentation that does not resolve in the cur-
rent context is degraded by a constant factor (we
used 0.001 in our experiments described below,
determined by experimentation). The degradation
thus changes the derivation order in the parsing
queue for the next input item and increases the
chances of degraded derivations to be pruned in
the following parsing step.
4 Experiments and Results
4.1 Data
We use data from the Pentomino puzzle piece do-
main (which has been used before for example
by (Ferna?ndez and Schlangen, 2007; Schlangen et
al., 2009)), collected in a Wizard-of-Oz study. In
this specific setting, users gave instructions to the
system (the wizard) in order to manipulate (select,
rotate, mirror, delete) puzzle pieces on an upper
board and to put them onto a lower board, reach-
ing a pre-specified goal state. Figure 2 shows an
example configuration. Each participant took part
in several rounds in which the distinguishing char-
acteristics for puzzle pieces (color, shape, pro-
posed name, position on the board) varied widely.
In total, 20 participants played 284 games.
We extracted the semantics of an utterance
from the wizard?s response action. In some cases,
such a mapping was not possible to do (e. g. be-
cause the wizard did not perform a next action,
mimicking a non-understanding by the system),
or potentially unreliable (if the wizard performed
several actions at or around the end of the utter-
ance). We discarded utterances without a clear se-
mantics alignment, leaving 1687 semantically an-
notated user utterances. The wizard of course was
able to use her model of the previous discourse for
resolving references, including anaphoric ones; as
Figure 2: The game board used in the study, as pre-
sented to the player: (a) the current state of the game
on the left, (b) the goal state to be reached on the right.
our study does not focus on these, we have dis-
regarded another 661 utterances in which pieces
are referred to by pronouns, leaving us with 1026
utterances for evaluation. These utterances con-
tained on average 5.2 words (median 5 words;
std dev 2 words).
In order to test the robustness of our method,
we generated speech recognition output using an
acoustic model trained for spontaneous (German)
speech. We used leave-one-out language model
training, i. e. we trained a language model for ev-
ery utterance to be recognized which was based
on all the other utterances in the corpus. Unfor-
tunately, the audio recordings of the first record-
ing day were too quiet for successful recognition
(with a deletion rate of 14%). We thus decided
to limit the analysis for speech recognition out-
put to the remaining 633 utterances from the other
recording days. On this part of the corpus word
error rate (WER) was at 18%.
The subset of the full corpus that we used for
evaluation, with the utterances selected according
to the criteria described above, nevertheless still
only consists of natural, spontaneous utterances
(with all the syntactic complexity that brings) that
are representative for interactions in this type of
domain.
4.2 Grammar and Resolution Model
The grammar used in our experiments was hand-
constructed, inspired by a cursory inspection of
the corpus and aiming to reach good coverage
518
Words Predicates Status
nimm nimm(e) -1
nimm den nimm(e,x) def(x) 0
nimm den Winkel nimm(e,x) def(x) winkel(x) 0
nimm den Winkel in nimm(e,x) def(x) winkel(x) in(x,y) 0
nimm den Winkel in der nimm(e,x) def(x) winkel(x) in(x,y) def(y) 0
nimm den Winkel in der dritten nimm(e,x) def(x) winkel(x) in(x,y) def(y) third(y) 1
nimm den Winkel in der dritten Reihe nimm(e,x) def(x) winkel(x) in(x,y) def(y) third(y) row(y) 1
Table 1: Example of logical forms (flattened into first-order base-language formulae) and reference resolution
results for incrementally parsing and resolving ?nimm den winkel in der dritten reihe?
for a core fragment. We created 30 rules, whose
weights were also set by hand (as discussed be-
low, this is an obvious area for future improve-
ment), sparingly and according to standard intu-
itions. When parsing, the first step is the assign-
ment of a POS tag to each word. This is done by
a simple lookup tagger that stores the most fre-
quent tag for each word (as determined on a small
subset of our corpus).4
The situation model used in reference resolu-
tion is automatically derived from the internal
representation of the current game state. (This
was recorded in an XML-format for each utter-
ance in our corpus.) Variable assignments were
then derived from the relevant nominal predicate
structures,5 consisting of extracted simple pred-
ications, e. g. red(x) and cross(x) for the NP in
a phrase such as ?take the red cross?. For each
unique predicate argument X in these EP struc-
tures (such as as x above), the set of domain ob-
jects that satisfied all predicates of which X was
an argument were determined. For example for
the phrase above, X mapped to all elements that
were red and crosses.
Finally, the size of these sets was determined:
no elements, one element, or multiple elements,
as described above. Emptiness of at least one set
denoted that no resolution was possible (for in-
stance, if no red crosses were available, x?s set
was empty), uniqueness of all sets denoted that
an exact resolution was possible while multiple
elements in at least some sets denoted ambiguity.
This status was then leveraged for parse pruning,
as per Section 3.5.
A more complex example using the scene de-
picted in Figure 2 and the sentence ?nimm den
4A more sophisticated approach has recently been pro-
posed by Beuck et al(2011); this could be used in our setup.
5The domain model did not allow making a plausibility
judgement based on verbal resolution.
winkel in der dritten reihe? (take the bracket in the
third row) is shown in Table 1. The first column
shows the incremental word hypothesis string, the
second the set of predicates derived from the most
recent RMRS representation and the third the res-
olution status (-1 for no resolution, 0 for some res-
olution and 1 for a unique resolution).
4.3 Baselines and Evaluation Metric
4.3.1 Variants / Baselines
To be able to accurately quantify and assess the
effect of our reference-feedback strategy, we im-
plemented different variants / baselines. These all
differ in how, at each step, the reading is deter-
mined that is evaluated against the gold standard,
and are described in the following:
In the Just Syntax (JS) variant, we simply take
single-best derivation, as determined by syntax
alone and evaluate this.
The External Filtering (EF) variant adds in-
formation from reference resolution, but keeps
it separate from the parsing process. Here, we
look at the 5 highest ranking derivations (as de-
termined by syntax alone), and go through them
beginning at the highest ranked, picking the first
derivation where reference resolution can be per-
formed uniquely; this reading is then put up for
evaluation. If there is no such reading, the highest
ranking one will be put forward for evaluation (as
in JS).
Syntax/Pragmatics Interaction (SPI) is the
variant described in the previous section. Here,
all active derivations are sent to the reference res-
olution module, and are re-weighted as described
above; after this has been done, the highest-
ranking reading is evaluated.
Finally, the Combined Interaction and Fil-
tering (CIF) variant combines the previous two
strategies, by using reference-feedback in com-
puting the ranking for the derivations, and then
519
again using reference-information to identify the
most promising reading within the set of 5 highest
ranking ones.
4.3.2 Metric
When a reading has been identified according
to one of these methods, a score s is computed as
follows: s = 1, if the correct referent (according
to the gold standard) is computed as the denota-
tion for this reading; s = 0 if no unique referent
can be computed, but the correct one is part of the
set of possible referents; s = ?1 if no referent
can be computed at all, or the correct one is not
part of the set of those that are computed.
As this is done incrementally for each word
(adding the new word to the parser chart), for an
utterance of length m we get a sequence of m
such numbers. (In our experiments we treat the
?end of utterance? signal as a pseudo-word, since
knowing that an utterance has concluded allows
the parser to close off derivations and remove
those that are still requiring elements. Hence, we
in fact have sequences ofm+1 numbers.) A com-
bined score for the whole utterance is computed
according to the following formula:
su =
m?
n=1
(sn ? n/m)
(where sn is the score at position n). The fac-
tor n/m causes ?later? decisions to count more
towards the final score, reflecting the idea that
it is more to be expected (and less harmful) to
be wrong early on in the utterance, whereas the
longer the utterance goes on, the more pressing
it becomes to get a correct result (and the more
damaging if mistakes are made).6
Note that this score is not normalised by utter-
ance length m; the maximally achievable score
being (m + 1)/2. This has the additional ef-
fect of increasing the weight of long utterances
when averaging over the score of all utterances;
we see this as desirable, as the analysis task be-
comes harder the longer the utterance is.
We use success in resolving reference to eval-
uate the performance of our parsing and semantic
construction component, where more tradition-
ally, metrics like parse bracketing accuracy might
6This metric compresses into a single number some of
the concerns of the incremental metrics developed in (Bau-
mann et al 2011), which can express more fine-grainedly
the temporal development of hypotheses.
be used. But as we are building this module for an
interactive system, ultimately, accuracy in recov-
ering meaning is what we are interested in, and so
we see this not just as a proxy, but actually as a
more valuable metric. Moreover, this metric can
be applied at each incremental step, which is not
clear how to do with more traditional metrics.
4.4 Experiments
Our parser, semantic construction and reference
resolution modules are implemented within the
InproTK toolkit for incremental spoken dialogue
systems development (Schlangen et al 2010). In
this toolkit, incremental hypotheses are modified
as more information becomes available over time.
Our modules support all such modifications (i. e.
also allow to revert their states and output if word
input is revoked).
As explained in Section 4.1, we used offline
recognition results in our evaluation. However,
the results would be identical if we were to use
the incremental speech recognition output of In-
proTK directly.
The system performs several times faster than
real-time on a standard workstation computer. We
thus consider it ready to improve practical end-to-
end incremental systems which perform within-
turn actions such as those outlined in (Bu? and
Schlangen, 2010).
The parser was run with a base-beam factor of
0.01; this parameter may need to be adjusted if a
larger grammar was used.
4.5 Results
Table 2 shows an overview of the experiment re-
sults. The table lists, separately for the manual
transcriptions and the ASR transcripts, first the
number of times that the final reading did not re-
solve at all, or to a wrong entitiy; did not uniquely
resolve, but included the correct entity in its de-
notiation; or did uniquely resolve to the correct
entity (-1, 0, and 1, respectively). The next lines
show ?strict accuracy? (proportion of ?1? among
all results) at the end of utterance, and ?relaxed
accuracy? (which allows ambiguity, i.e., is the set
{0, 1}). incr.scr is the incremental score as de-
scribed above, which includes in the evaluation
the development of references and not just the fi-
nal state. (And in that sense, is the most appro-
priate metric here, as it captures the incremental
behaviour.) This score is shown both as absolute
520
JS EF SPI CIF
tr
an
sc
ri
pt
?1 563 518 364 363
0 197 198 267 268
1 264 308 392 392
str.acc. 25.7% 30.0% 38.2% 38.2%
rel.acc. 44.9% 49.3% 64.2% 64.3%
incr.scr ?1568 ?1248 ?536 ?504
avg.incr.scr ?1.52 ?1.22 ?0.52 ?0.49
re
co
gn
ti
on
?1 362 348 254 255
0 122 121 173 173
1 143 158 196 195
str.acc. 22.6% 25.0% 31.0% 30.8%
rel.acc. 41.2% 44.1% 58.3% 58.1%
incr.scr ?1906 ?1730 ?1105 ?1076
avg.incr.scr ?1.86 ?1.69 ?1.01 ?1.05
Table 2: Results of the Experiments. See text for explanation of metrics.
number as well as averaged for each utterance.
As these results show, the strategy of provid-
ing the parser with feedback about the real-world
utility of constructed phrases (in the form of refer-
ence decisions) improves the parser, in the sense
that it helps the parser to successfully retrieve the
intended meaning more often compared to an ap-
proach that only uses syntactic information (JS)
or that uses pragmatic information only outside
of the main programme: 38.2% strict or 64.2%
relaxed for SPI over 25.7% / 44.9% for JS, an
absolute improvement of 12.5% for strict or even
more, 19.3%, for the relaxed metric; the incre-
mental metric shows that this advantage holds not
only at the final word, but also consistently within
the utterance, the average incremental score for
an utterance being ?0.49 for SPI and ?1.52
for JS. The improvement is somewhat smaller
against the variant that uses some reference infor-
mation, but does not integrate this into the parsing
process (EF), but it is still consistently present.
Adding such n-best-list processing to the output
of the parser+reference-combination (as variant
CIF does) finally does not further improve the
performance noticeably. When processing par-
tially defective material (the output of the speech
recogniser), the difference between the variants
is maintained, showing a clear advantage of SPI,
although performance of all variants is degraded
somewhat.
Clearly, accuracy is rather low for the base-
line condition (JS); this is due to the large num-
ber of non-standard constructions in our sponta-
neous material (e.g., utterances like ?lo?schen, un-
ten? (delete, bottom) which we did not try to cover
with syntactic rules, and which may not even con-
tain NPs. The SPI condition can promote deriva-
tions resulting from robust rules (here, deletion)
which then can refer. In general though state-of-
the art grammar engineering may narrow the gap
between JS and SPI ? this remains to be tested ?
but we see as an advantage of our approach that
it can improve over the (easy-to-engineer) set of
core grammar rules.
5 Conclusions
We have described a model of semantic process-
ing of natural, spontaneous speech that strives
to jointly satisfy syntactic and pragmatic con-
straints (the latter being approximated by the as-
sumption that referring expressions are intended
to indeed successfully refer in the given context).
The model is robust, accepting also input of the
kind that can be expected from automatic speech
recognisers, and incremental, that is, can be fed
input on a word-by-word basis, computing at each
increment only exactly the contribution of the new
word. Lastly, as another novel contribution, the
model makes use of a principled formalism for se-
mantic representation, RMRS (Copestake, 2006).
While the results show that our approach of
combining syntactic and pragmatic information
can work in a real-world setting on realistic
data?previous work in this direction has so far
521
only been at the proof-of-concept stage?there is
much room for improvement. First, we are now
exploring ways of bootstrapping a grammar and
derivation weights from hand-corrected parses.
Secondly, we are looking at making the variable
assignment / model checking function probabilis-
tic, assigning probabilities (degree of strength of
belief) to candidate resolutions (as for example
the model of Schlangen et al(2009) does). An-
other next step?which will be very easy to take,
given the modular nature of the implementation
framework that we have used?will be to integrate
this component into an interactive end-to-end sys-
tem, and testing other domains in the process.
Acknowledgements We thank the anonymous
reviewers for their helpful comments. The work
reported here was supported by a DFG grant in
the Emmy Noether programme to the last author
and a stipend from DFG-CRC (SFB) 632 to the
first author.
References
Gregory Aist, James Allen, Ellen Campana, Car-
los Gomez Gallo, Scott Stoness, Mary Swift, and
Michael K. Tanenhaus. 2007. Incremental under-
standing in human-computer dialogue and experi-
mental evidence for advantages over nonincremen-
tal methods. In Proceedings of Decalog 2007, the
11th International Workshop on the Semantics and
Pragmatics of Dialogue, Trento, Italy.
Timo Baumann, Michaela Atterer, and David
Schlangen. 2009. Assessing and improving the per-
formance of speech recognition for incremental sys-
tems. In Proceedings of the North American Chap-
ter of the Association for Computational Linguis-
tics - Human Language Technologies (NAACL HLT)
2009 Conference, Boulder, Colorado, USA, May.
Timo Baumann, Okko Bu?, and David Schlangen.
2011. Evaluation and optimization of incremen-
tal processors. Dialogue and Discourse, 2(1):113?
141.
Niels Beuck, Arne Ko?hn, and Wolfgang Menzel.
2011. Decision strategies for incremental pos tag-
ging. In Proceedings of the 18th Nordic Con-
ference of Computational Linguistics, NODALIDA-
2011, Riga, Latvia.
Okko Bu? and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue sys-
tems. In Proceedings of the 14th International
Workshop on the Semantics and Pragmatics of Dia-
logue (Pozdial 2010), pages 33?41, Poznan, Poland,
June.
Ann Copestake. 2006. Robust minimal recursion se-
mantics. Technical report, Cambridge Computer
Lab. Unpublished draft.
Ann Copestake. 2007. Semantic composition with
(robust) minimal recursion semantics. In Proceed-
ings of the Workshop on Deep Linguistic Process-
ing, DeepLP ?07, pages 73?80, Stroudsburg, PA,
USA. Association for Computational Linguistics.
David DeVault and Matthew Stone. 2003. Domain
inference in incremental interpretation. In Proceed-
ings of ICOS 4: Workshop on Inference in Compu-
tational Semantics, Nancy, France, September. IN-
RIA Lorraine.
David DeVault, Kenji Sagae, and David Traum. 2011.
Incremental Interpretation and Prediction of Utter-
ance Meaning for Interactive Dialogue. Dialogue
and Discourse, 2(1):143?170.
Raquel Ferna?ndez and David Schlangen. 2007. Re-
ferring under restricted interactivity conditions. In
Simon Keizer, Harry Bunt, and Tim Paek, editors,
Proceedings of the 8th SIGdial Workshop on Dis-
course and Dialogue, pages 136?139, Antwerp,
Belgium, September.
Ulrike Pado?, Matthew W Crocker, and Frank Keller.
2009. A probabilistic model of semantic plausi-
bility in sentence processing. Cognitive Science,
33(5):794?838.
Matthew Purver, Arash Eshghi, and Julian Hough.
2011. Incremental semantic construction in a di-
alogue system. In J. Bos and S. Pulman, editors,
Proceedings of the 9th International Conference on
Computational Semantics (IWCS), pages 365?369,
Oxford, UK, January.
Brian Roark. 2001. Robust Probabilistic Predictive
Syntactic Processing: Motivations, Models, and
Applications. Ph.D. thesis, Department of Cogni-
tive and Linguistic Sciences, Brown University.
David Schlangen and Gabriel Skantze. 2009. A gen-
eral, abstract model of incremental dialogue pro-
cessing. In EACL ?09: Proceedings of the 12th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, pages 710?718.
Association for Computational Linguistics, mar.
David Schlangen, Timo Baumann, and Michaela At-
terer. 2009. Incremental reference resolution: The
task, metrics for evaluation, and a bayesian filtering
model that is sensitive to disfluencies. In Proceed-
ings of SIGdial 2009, the 10th Annual SIGDIAL
Meeting on Discourse and Dialogue, London, UK,
September.
David Schlangen, Timo Baumann, Hendrik
Buschmeier, Okko Bu?, Stefan Kopp, Gabriel
Skantze, and Ramin Yaghoubzadeh. 2010. Middle-
ware for Incremental Processing in Conversational
Agents. In Proceedings of SigDial 2010, Tokyo,
Japan, September.
522
William Schuler, Stephen Wu, and Lane Schwartz.
2009. A framework for fast incremental interpre-
tation during speech decoding. Computational Lin-
guistics, 35(3).
William Schuler. 2003. Using model-theoretic se-
mantic interpretation to guide statistical parsing and
word recognition in a spoken language interface. In
Proceedings of the 41st Meeting of the Association
for Computational Linguistics (ACL 2003), Sap-
poro, Japan. Association for Computational Lin-
guistics.
Gabriel Skantze and Anna Hjalmarsson. 2010. To-
wards incremental speech generation in dialogue
systems. In Proceedings of the SIGdial 2010 Con-
ference, pages 1?8, Tokyo, Japan, September.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of the 12th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics (EACL 2009), pages 745?753, Athens,
Greece, March.
Mark Steedman. 2000. The Syntactic Process. MIT
Press, Cambridge, Massachusetts.
Scott C. Stoness, Joel Tetreault, and James Allen.
2004. Incremental parsing with reference inter-
action. In Proceedings of the Workshop on In-
cremental Parsing at the ACL 2004, pages 18?25,
Barcelona, Spain, July.
Scott C. Stoness, James Allen, Greg Aist, and Mary
Swift. 2005. Using real-world reference to improve
spoken language understanding. In AAAI Workshop
on Spoken Language Understanding, pages 38?45.
523
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 51?54,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Middleware for Incremental Processing in Conversational Agents
David Schlangen?, Timo Baumann?, Hendrik Buschmeier?, Okko Bu??
Stefan Kopp?, Gabriel Skantze?, Ramin Yaghoubzadeh?
?University of Potsdam ?Bielefeld University ?KTH, Stockholm
Germany Germany Sweden
david.schlangen@uni-potsdam.de
Abstract
We describe work done at three sites on
designing conversational agents capable of
incremental processing. We focus on the
?middleware? layer in these systems, which
takes care of passing around and maintain-
ing incremental information between the
modules of such agents. All implementa-
tions are based on the abstract model of
incremental dialogue processing proposed
by Schlangen and Skantze (2009), and the
paper shows what different instantiations
of the model can look like given specific
requirements and application areas.
1 Introduction
Schlangen and Skantze (2009) recently proposed
an abstract model of incremental dialogue process-
ing. While this model introduces useful concepts
(briefly reviewed in the next section), it does not
talk about how to actually implement such sys-
tems. We report here work done at three different
sites on setting up conversational agents capable
of incremental processing, inspired by the abstract
model. More specifically, we discuss what may
be called the ?middleware? layer in such systems,
which takes care of passing around and maintaining
incremental information between the modules of
such agents. The three approaches illustrate a range
of choices available in the implementation of such
a middle layer. We will make our software avail-
able as development kits in the hope of fostering
further research on incremental systems.1
In the next section, we briefly review the abstract
model. We then describe the implementations cre-
ated at Uni Bielefeld (BF), KTH Stockholm (KTH)
and Uni Potsdam (UP). We close with a brief dis-
cussion of similarities and differences, and an out-
look on further work.
1Links to the three packages described here can be found
at http://purl.org/net/Middlewares-SIGdial2010.
2 The IU-Model of Incremental Processing
Schlangen and Skantze (2009) model incremental
systems as consisting of a network of processing
modules. Each module has a left buffer, a proces-
sor, and a right buffer, where the normal mode of
processing is to take input from the left buffer, pro-
cess it, and provide output in the right buffer, from
where it goes to the next module?s left buffer. (Top-
down, expectation-based processing would work
in the opposite direction.) Modules exchange incre-
mental units (IUs), which are the smallest ?chunks?
of information that can trigger connected modules
into action. IUs typically are part of larger units;
e.g., individual words as parts of an utterance, or
frame elements as part of the representation of an
utterance meaning. This relation of being part of
the same larger unit is recorded through same level
links; the information that was used in creating a
given IU is linked to it via grounded in links. Mod-
ules have to be able to react to three basic situa-
tions: that IUs are added to a buffer, which triggers
processing; that IUs that were erroneously hypothe-
sised by an earlier module are revoked, which may
trigger a revision of a module?s own output; and
that modules signal that they commit to an IU, that
is, won?t revoke it anymore (or, respectively, expect
it to not be revoked anymore).
Implementations of this model then have to re-
alise the actual details of this information flow, and
must make available the basic module operations.
3 Sociable Agents Architecture
BF?s implementation is based on the ?D-Bus? mes-
sage bus system (Pennington et al, 2007), which
is used for remote procedure calls and the bi-
directional synchronisation of IUs, either locally
between processes or over the network. The bus sys-
tem provides proxies, which make the interface of
a local object accessible remotely without copying
data, thus ensuring that any access is guaranteed to
yield up-to-date information. D-Bus bindings exist
for most major programming languages, allowing
51
for interoperability across various systems.
IUs exist as objects implementing a D-Bus in-
terface, and are made available to other modules
by publishing them on the bus. Modules are ob-
jects comprising a main thread and right and left
buffers for holding own IUs and foreign IU proxies,
respectively. Modules can co-exist in one process
as threads or occupy one process each?even dis-
tributed across a network.
A dedicated Relay D-Bus object on the network
is responsible for module administration and up-
date notifications. At connection time, modules
register with the relay, providing a list of IU cat-
egories and/or module names they are interested
in. Category interests create loose functional links
while module interests produce more static ones.
Whenever a module chooses to publish informa-
tion, it places a new IU in its right buffer, while
removal of an IU from the right buffer corresponds
to retraction. The relay is notified of such changes
and in turn invokes a notification callback in all
interested modules synchronising their left buffers
by immediately and transparently creating or re-
moving proxies of those IUs.
IUs consist of the fields described in the abstract
model, and an additional category field which the
relay can use to identify the set of interested mod-
ules to notify. They furthermore feature an optional
custom lifetime, on the expiration of which they
are automatically retracted.
Incremental changes to IUs are simply realised
by changing their attributes: regardless of their lo-
cation in either a right or left buffer, the same setter
functions apply (e.g., set payload). These generate
relay-transported update messages which commu-
nicate the ID of the changed IU. Received update
messages concerning self-owned and remotely-
owned objects are discerned automatically to allow
for special treatment of own IUs. The complete
process is illustrated in Figure 1.
Current state and discussion. Our support for
bi-directional IU editing is an extension to the con-
cepts of the general model. It allows higher-level
modules with a better knowledge of context to re-
vise uncertain information offered by lower levels.
Information can flow both ways, bottom-up and
top-down, thus allowing for diagnostic and causal
networks linked through category interests.
Coming from the field of embodied conversa-
tional agents, and being especially interested in
modelling human-like communication, for exam-
A B
C
IU
IU proxy
Write access
Relay
Data access
Update notification
RBuf LBuf
Interest sets
Figure 1: Data access on the IU proxies is transparently dele-
gated over the D-Bus; module A has published an IU. B and C
are registered in the corresponding interest set, thus receiving
a proxy of this IU in their left buffer. When B changes the IU,
A and C receive update notifications.
ple for on-line production of listener backchannel
feedback, we constantly have to take incremen-
tally changing uncertain input into account. Using
the presented framework consistently as a network
communication layer, we are currently modelling
an entire cognitive architecture for virtual agents,
based on the principle of incremental processing.
The decision for D-Bus as the transportation
layer has enabled us to quickly develop ver-
sions for Python, C++ and Java, and produced
straightforward-to-use libraries for the creation of
IU-exchanging modules: the simplest fully-fledged
module might only consist of a periodically in-
voked main loop callback function and any subset
of the four handlers for IU events (added, removed,
updated, committed).
4 Inpro Toolkit
The InproTK developed at UP offers flexibility on
how tightly or loosely modules are coupled in a
system. It provides mechanisms for sending IU up-
dates between processes via a messaging protocol
(we have used OAA [Cheyer and Martin, 2001], but
other communication layers could also be used) as
well as for using shared memory within one (Java)
process. InproTK follows an event-based model,
where modules create events, for which other mod-
ules can register as Listeners. Module networks are
configured via a system configuration file which
specifies which modules listen to which.
Modules push information to their right, hence
the interface for inter-module communication is
called PushBuffer. (At the moment, InproTK only
implements left-to-right IU flow.) The PushBuffer
interface defines a hypothesis-change method
which a module will call for all its listening mod-
ules. A hypothesis change is (redundantly) charac-
terised by passing both the complete current buffer
state (a list of IUs) as well as the delta between
52
the previous and the current state, leaving listen-
ing modules a choice of how to implement their
internal update.
Modules can be fully event-driven, only trig-
gered into action by being notified of a hypothesis
change, or they can run persistently, in order to cre-
ate endogenous events like time-outs. Event-driven
modules can run concurrently in separate threads or
can be called sequentially by a push buffer (which
may seem to run counter the spirit of incremental
processing, but can be advantageous for very quick
computations for which the overhead of creating
threads should be avoided).
IUs are typed objects, where the base class IU
specifies the links (same-level, grounded-in) that
allow to create the IU network and handles the
assignment of unique IDs. The payload and addi-
tional properties of an IU are specified for the IU?s
type. A design principle here is to make all relevant
information available, while avoiding replication.
For instance, an IU holding a bit of semantic rep-
resentation can query which interval of input data
it is based on, where this information is retrieved
from the appropriate IUs by automatically follow-
ing the grounded-in links. IU networks ground out
in BaseData, which contains user-side input such
as speech from the microphone, derived ASR fea-
ture vectors, camera feeds from a webcam, derived
gaze information, etc., in several streams that can
be accessed based on their timing information.
Besides IU communication as described in the
abstract model, the toolkit also provides a separate
communication track along which signals, which
are any kind of information that is not seen as incre-
mental hypotheses about a larger whole but as infor-
mation about a single current event, can be passed
between modules. This communication track also
follows the observer/listener model, where proces-
sors define interfaces that listeners can implement.
Finally, InproTK also comes with an extensive
set of monitoring and profiling modules which can
be linked into the module network at any point and
allow to stream data to disk or to visualise it online
through a viewing tool (ANON 2009), as well as
different ways to simulate input (e.g., typed or read
from a file) for bulk testing.
Current state and discussion. InproTK is cur-
rently used in our development of an incremental
multimodal conversational system. It is usable in its
current state, but still evolves. We have built and in-
tegrated modules for various tasks (post-processing
of ASR output, symbolic and statistical natural lan-
guage understanding [ANON 2009a,b,c]). The con-
figuration system and the availability of monitoring
and visualisation tools enables us to quickly test
different setups and compare different implementa-
tions of the same tasks.
5 Jindigo
Jindigo is a Java-based framework for implement-
ing and experimenting with incremental dialogue
systems currently being developed at KTH. In
Jindigo, all modules run as separate threads within
a single Java process (although the modules them-
selves may of course communicate with external
processes). Similarly to InproTK, IUs are mod-
elled as typed objects. The modules in the system
are also typed objects, but buffers are not. Instead,
a buffer can be regarded as a set of IUs that are
connected by (typed) same-level links. Since all
modules have access to the same memory space,
they can follow the same-level links to examine
(and possibly alter) the buffer. Update messages
between modules are relayed based on a system
specification that defines which types of update
messages from a specific module go where. Since
the modules run asynchronously, update messages
do not directly invoke methods in other modules,
but are put on the input queues of the receiving
modules. The update messages are then processed
by each module in their own thread.
Jindigo implements a model for updating buffers
that is slightly different than the two previous ap-
proaches. In this approach, IUs are connected by
predecessor links, which gives each IU (words,
widest spanning phrases from the parser, commu-
nicative acts, etc), a position in a (chronologically)
ordered stream. Positional information is reified by
super-imposing a network of position nodes over
the IU network, with the IUs being associated with
edges in that network. These positional nodes then
give us names for certain update stages, and so
revisions can be efficiently encoded by reference
to these nodes. An example can make this clearer.
Figure 2 shows five update steps in the right buffer
of an incremental ASR module. By reference to po-
sitional nodes, we can communicate easily (a) what
the newest committed IU is (indicated in the figure
as a shaded node) and (b) what the newest non-
revoked or active IU is (i.e., the ?right edge? (RE);
indicated in the figure as a node with a dashed line).
So, the change between the state at time t1 and t2
is signalled by RE taking on a different value. This
53
Figure 2: The right buffer of an ASR module, and update
messages at different time-steps.
value (w3) has not been seen before, and so the
consuming module can infer that the network has
been extended; it can find out which IUs have been
added by going back from the new RE to the last
previously seen position (in this case, w2). At t3, a
retraction of a hypothesis is signalled by a return to
a previous state, w2. All consuming modules have
to do now is to return to an internal state linked
to this previous input state. Commitment is repre-
sented similarly through a pointer to the rightmost
committed node; in the figure, that is for example
w5 at t5.
Since information about whether an IU has been
revoked or committed is not stored in the IU it-
self, all IUs can (if desirable) be defined as im-
mutable objects. This way, the pitfalls of having
asynchronous processes altering and accessing the
state of the IUs may be avoided (while, however,
more new IUs have to be created, as compared to
altering old ones). Note also that this model sup-
ports parallel hypotheses as well, in which case the
positional network would turn into a lattice.
The framework supports different types of up-
date messages and buffers. For example, a parser
may incrementally send NPs to a reference reso-
lution (RR) module that has access to a domain
model, in order to prune the chart. Thus, informa-
tion may go both left-to-right and right-to-left. In
the buffer between these modules, the order be-
tween the NPs that are to be annotated is not im-
portant and there is no point in revoking such IUs
(since they do not affect the RR module?s state).
Current state and discussion. Jindigo uses con-
cepts from (Skantze, 2007), but has been rebuilt
from ground up to support incrementality. A range
of modules for ASR, semantic interpretation, TTS,
monitoring, etc., have been implemented within
the framework, allowing us to do experiments
with complete systems interacting with users. We
are currently using the framework to implement a
model of incremental speech production.
6 Discussion
The three implementations of the abstract IU model
presented above show that concrete requirements
and application areas result in different design de-
cisions and focal points.
While BF?s approach is loosely coupled and han-
dles exchange of IUs via shared objects and a me-
diating module, KTH?s implementation is rather
closely coupled and publishes IUs through a single
buffer that lies in shared memory. UP?s approach
is somewhat in between: it abstracts away from the
transportation layer and enables message passing-
based communication as well as shared memory
transparently through one interface.
The differences in the underlying module com-
munication infrastructure affect the way incremen-
tal IU updates are handled in the systems. In BF?s
framework modules holding an IU in one of their
buffers just get notified when one of the IU?s fields
changed. Conversely, KTH?s IUs are immutable
and new information always results in new IUs
being published and a change to the graph repre-
sentation of the buffer?but this allows an efficient
coupling of module states and cheap revoke op-
erations. Again, UP?s implementation lies in the
middle. Here both the whole new state and the delta
between the old and new buffer is communicated,
which leads to flexibility in how consumers can be
implemented, but also potentially to some commu-
nication overhead.
In future work, we will explore if further gener-
alisations can be extracted from the different im-
plementations presented here. For now, we hope
that the reference architectures presented here can
already be an inspiration for further work on incre-
mental conversational systems.
References
Adam Cheyer and David Martin. 2001. The open
agent architecture. Journal of Autonomous Agents
and Multi-Agent Systems, 4(1):143?148, March.
H. Pennington, A. Carlsson, and A. Larsson. 2007.
D-Bus Specification Version 0.12. http://dbus.free-
desktop.org/doc/dbus-specification.html.
David Schlangen and Gabriel Skantze. 2009. A Gen-
eral, Abstract Model of Incremental Dialogue Pro-
cessing. In Proceedings of EACL 2009, Athens,
Greece.
Gabriel Skantze. 2007. Error Handling in Spoken Dia-
logue Systems. Ph.D. thesis, KTH, Stockholm, Swe-
den, November.
54
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 233?236,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Collaborating on Utterances with a Spoken Dialogue System
Using an ISU-based Approach to Incremental Dialogue Management
Okko Bu?, Timo Baumann, David Schlangen
Department of Linguistics
University of Potsdam, Germany
{okko|timo|das}@ling.uni-potsdam.de
Abstract
When dialogue systems, through the
use of incremental processing, are
not bounded anymore by strict, non-
overlapping turn-taking, a whole range of
additional interactional devices becomes
available. We explore the use of one such
device, trial intonation. We elaborate
our approach to dialogue management
in incremental systems, based on the
Information-State-Update approach, and
discuss an implementation in a micro-
domain that lends itself to the use of
immediate feedback, trial intonations and
expansions. In an overhearer evaluation,
the incremental system was judged as sig-
nificantly more human-like and reactive
than a non-incremental version.
1 Introduction
In human?human dialogue, most utterances have
only one speaker.1 However, the shape that an
utterance ultimately takes on is often determined
not just by the one speaker, but also by her ad-
dressees. A speaker intending to refer to some-
thing may start with a description, monitor while
they go on whether the description appears to be
understood sufficiently well, and if not, possibly
extend it, rather than finishing the utterance in the
form that was initially planned. This monitoring
within the utterance is sometimes even made very
explicit, as in the following example from (Clark,
1996):
(1) A: A man called Annegra? -
B: yeah, Allegra
A: Allegra, uh, replied and, uh, . . .
In this example, A makes use of what Sacks and
Schegloff (1979) called a try marker, a ?question-
ing upward intonational contour, followed by a
1Though by far not all; see (Clark, 1996; Purver et al,
2009; Poesio and Rieser, 2010).
brief pause?. As discussed by Clark (1996), this
device is an efficient solution to the problem posed
by uncertainty on the side of the speaker whether
a reference is going to be understood, as it checks
for understanding in situ, and lets the conversation
partners collaborate on the utterance that is in pro-
duction.
Spoken dialogue systems (SDS) typically can-
not achieve the close coupling between produc-
tion and interpretation that is needed for this to
work, as normally the smallest unit on which they
operate is the full utterance (or, more precisely,
the turn). (For a discussion see e.g. (Skantze and
Schlangen, 2009).) We present here an approach
to managing dialogue in an incremental SDS that
can handle this phenomenon, explaining how it is
implemented in system (Section 4) that works in
a micro-domain (which is described in Section 3).
As we will discuss in the next section, this goes be-
yond earlier work on incremental SDS, combining
the production of multimodal feedback (as in (Aist
et al, 2007)) with fast interaction in a semantically
more complex domain (compared to (Skantze and
Schlangen, 2009)).
2 Related Work
Collaboration on utterances has not often been
modelled in SDS, as it presupposes fully incre-
mental processing, which itself is still something
of a rarity in such systems. (There is work on
collaborative reference (DeVault et al, 2005; Hee-
man and Hirst, 1995), but that focuses on written
input, and on collaboration over several utterances
and not within utterances.) There are two systems
that are directly relevant here.
The system described in (Aist et al, 2007) is
able to produce some of the phenomena that we
are interested in here. The set-up is a simple
reference game (as we will see, the domain we
have chosen is very similar), where users can re-
fer to objects shown on the screen, and the SDS
gives continuous feedback about its understand-
233
ing by performing on-screen actions. While we
do produce similar non-linguistic behaviour in our
system, we also go beyond this by producing
verbal feedback that responds to the certainty of
the speaker (expressed by the use of trial intona-
tion). Unfortunately, very little technical details
are given in that paper, so that we cannot compare
the approaches more fully.
Even more closely related is some of our own
previous work, (Skantze and Schlangen, 2009),
where we modeled fast system reactions to deliv-
ery of information in installments in a number se-
quence dictation domain. In a small corpus study,
we found a very pronounced use of trial or in-
stallment intonations, with the first installments of
numbers being bounded by rising intonation, and
the final installment of a sequence by falling into-
nation. We made use of this fact by letting the sys-
tem distinguish these situations based on prosody,
and giving it different reaction possibilities (back-
channel feedback vs. explicit confirmation).
The work reported here is a direct scaling up of
that work. For number sequences, the notion of
utterance is somewhat vague, as there are no syn-
tactic constraints that help demarcate its bound-
aries. Moreover, there is no semantics (beyond
the individual number) that could pose problems
? the main problem for the speaker in that do-
main is ensuring that the signal is correctly identi-
fied (as in, the string could be written down), and
the trial intonation is meant to provide opportuni-
ties for grounding whether that is the fact. Here,
we want to go beyond that and look at utterances
where it is the intended meaning whose recogni-
tion the speaker is unsure about (grounding at level
3 rather than (just) at level 2 in terms of (Clark,
1996).) This difference leads to differences in the
follow up potential: where in the numbers domain,
typical repair follow-ups were repetitions, in se-
mantically more complex domains we can expect
expansions or reformulations.
3 The Puzzle Micro-Domain
To investigate these issues in a controlled set-
ting, we chose a domain that makes complex and
possibly underspecified references likely, and that
also allows a combination of linguistic and non-
linguistic feedback. In this domain, the user?s goal
is to instruct the system to pick up and manipu-
late Tetris-like puzzle pieces, which are shown on
the screen. We recorded human?human as well
as human?(simulated) machine interactions in this
domain, and indeed found frequent use of ?pack-
aging? of instructions, and immediate feedback, as
in (2) (arrow indicating intonation).
(2) IG-1: The cross in the corner? ...
IF-2: erm
IG-3: the red one .. yeah
IF-4: [moves cursor]
IG-5: take that.
We chose these as our target phenomena for the
implementation: intra-utterance hesitations, possi-
bly with trial intonation (as in line 2);2 immediate
execution of actions (line 4), and their grounding
role as display of understanding (?yeah? in line 3).
The system controls the mouse cursor, e.g. moving
it over pieces once it has a good hypothesis about
a reference; other actions are visualised similarly.
4 Implementation
4.1 Overview
Our system is realised as a collection of incre-
mental processing modules in the InproToolKit
(Schlangen et al, 2010), a middle-ware pack-
age that implements some of the features of the
model of incremental processing of (Schlangen
and Skantze, 2009). The modules used in the im-
plementation will be described briefly below.
4.2 ASR, Prosody, Floor Tracker & NLU
For speech recognition, we use Sphinx-4 (Walker
et al, 2004), with our own extensions for incre-
mental speech recognition (Baumann et al, 2009),
and our own domain-specific acoustic model. For
the experiments described here, we used a recog-
nition grammar.
Another module performs online prosodic anal-
ysis, based on pitch change, which is measured in
semi-tone per second over the turn-final word, us-
ing a modified YIN (de Cheveigne? and Kawahara,
2002). Based on the slope of the f0 curve, we clas-
sify pitch as rising or falling.
This information is used by the floor track-
ing module, which notifies the dialogue manager
(DM) about changes in floor status. These sta-
tus changes are classified by simple rules: silence
following rising pitch leads to a timeout signal
2Although we chose to label this ?intra-utterance? here,
it doesn?t matter much for our approach whether one consid-
ers this example to consist of one or several utterances; what
matters is that differences in intonation and pragmatic com-
pleteness have an effect.
234
{< a ( 1 action=A=take; 2 prepare(A) ; 3 U),
( 4 tile=T ; 5 highlight(T) ; 6 U),
( 7 ; 8 execute(A,T) ; 9 U) >
< b (10 action=A=del ;11 prepare(A) ;12 U),
(13 tile=T ;14 highlight(T) ;15 U),
(16 ;17 execute(A,T) ;18 U) >}
Figure 1: Example iQUD
sent to the DM faster (200ms) than silence after
falling pitch (500ms). (Comparable to the rules in
(Skantze and Schlangen, 2009).)
Natural language understanding finally is per-
formed by a unification-based semantic composer,
which builds simple semantic representations out
of the lexical entries for the recognised words; and
a resolver, which matches these representations
against knowledge of the objects in the domain.
4.3 Dialogue Manager and Action Manager
The DM reacts to input from three sides: semantic
material coming from the NLU, floor state signals
from the floor tracker, and notifications about exe-
cution of actions from the action manager.
The central element of the information state
used in the dialogue manager is what we call the
iQUD (for incremental Question under Discus-
sion, as it?s a variant of the QUD of (Ginzburg,
1996)). Figure 1 gives an example. The iQUD
collects all relevant sub-questions into one struc-
ture, which also records what the relevant non-
linguistic actions are (RNLAs; more on this in a
second, but see also (Bu? and Schlangen, 2010),
where we?ve sketched this approach before), and
what the grounding status is of that sub-question.
Let?s go through example (2). The iQUD in
Figure 1 represents the state after the system has
asked ?what shall I do now??. The system an-
ticipates two alternative replies, a take request, or
a delete request; this is what the specification of
the slot value in 1 and 10 in the iQUD indicates.
Now the user starts to speak and produces what is
shown in line 1 in the example. The floor tracker
reacts to the rising pitch and to the silence of ap-
propriate length, and notifies the dialogue man-
ager. In the meantime, the DM has received up-
dates from the NLU module, has checked for each
update whether it is relevant to a sub-question on
the iQUD, and if so, whether it resolves it. In this
situation, the material was relevant to both 4 and
13, but did not resolve it. This is a precondition for
the continuer-questioning rule, which is triggered
by the signal from the floor tracker. The system
then back-channels as in the example, indicating
acoustic understanding (Clark?s level 2), but fail-
ure to operate on the understanding (level 3). (As
an aside, we found that it is far from trivial to find
the right wording for this prompt. We settled on
an ?erm? with level pitch.)
The user then indeed produces more material,
which together with the previously given informa-
tion resolves the question. This is where the RN-
LAs come in: when a sub-question is resolved, the
DM looks into the field for RNLAs, and if there
are any, puts them up for execution to the action
manager. In our case, slots 4 and 13 are both
applicable, but as they have compatible RNLAs,
this does not cause a conflict. When the action
has been performed, a new question is accommo-
dated (not shown here), which can be paraphrased
as ?was the understanding displayed through this
action correct??. This is what allows the user reply
in line 3 to be integrated, which otherwise would
need to be ignored, or even worse, would confuse
a dialogue system. A relevant continuation, on the
other hand, would also have resolved the question.
We consider this modelling of grounding effects
of actions an important feature of our approach.
Similar rules handle other floor tracker events;
not elaborated here for reasons of space. In
our current prototype the rules are hard-coded,
but we are preparing a version where rules and
information-states can be specified externally and
are read in by a rule-engine.
4.4 Overhearer Evaluation
Evaluating the contribution of one of the many
modules in an SDS is notoriously difficult (Walker
et al, 1998). To be able to focus on evaluation of
the incremental dialogue strategies and avoid in-
terference from ASR problems (and more techni-
cal problems; our system is still somewhat frag-
ile), we opted for an overhearer evaluation. (Such
a setting was also used for the test of the incremen-
tal system of (Aist et al, 2007).)
We implemented a non-incremental version of
the system that does not give non-linguistic feed-
back during user utterances and has only one,
fixed, timeout of 800ms (comparable to typical
settings in commercial dialogue systems). Two
of the authors then recorded 30 minutes of inter-
actions with the two versions of the system.We
then identified and discarded ?outlier? interac-
tions, i.e. those with technical problems, or where
235
recognition problems were so severe that a non-
understanding state was entered repeatedly. These
criteria were meant to be fair to both versions
of the system, and indeed we excluded similar
numbers of failed interactions from both versions
(around 10% of interactions in total).
We measured the length of interactions in the
two sets, and found that the interactions in the in-
cremental setting were significantly shorter (t-test,
p< 0.005). This was to be expected, of course,
as the incremental strategies allow faster reactions
(execution time can be folded into the user utter-
ance); other outcomes would have been possible,
though, if the incremental version had systemati-
cally more understanding problems.
We then had 8 subjects (university students,
not involved in the research) watch and directly
judge (questionnaire, Likert-scale replies to ques-
tions about human-likeness, helpfulness, and re-
activity) 34 randomly selected interactions from
either condition. Human-likeness and reactivity
were judged significantly higher for the incremen-
tal version (Wilcoxon rank-sum test; p< 0.05 and
p< 0.005, respectively), while there was no effect
for helpfulness (p= 0.06).
5 Conclusions
We described our incremental micro-domain dia-
logue system, which is capable of reacting to sub-
tle signals from the user about expected feedback,
and is able to produce overlapping non-linguistic
actions, modelling their effect as displays of un-
derstanding. Interactions with the system were
judged by overhearers to be more human-like and
reactive than with a non-incremental variant. We
are currently working on extending and generalis-
ing our approach to incremental dialogue manage-
ment, porting it to other domains.
Acknowledgments Funded by an ENP grant from DFG.
References
Gregory Aist, James Allen, Ellen Campana, Car-
los Gomez Gallo, Scott Stoness, Mary Swift, and
Michael K. Tanenhaus. 2007. Incremental under-
standing in human-computer dialogue and experi-
mental evidence for advantages over nonincremen-
tal methods. In Proceedings of Decalog (Semdial
2007), Trento, Italy.
Timo Baumann, Michaela Atterer, and David
Schlangen. 2009. Assessing and Improving the
Performance of Speech Recognition for Incremental
Systems. In Proceedings of NAACL-HLT 2009,
Boulder, USA.
Okko Bu? and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue sys-
tems. In Proceedings of Semdial 2010 (?Pozdial?),
pages 33?41, Poznan, Poland, June.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press, Cambridge.
Alain de Cheveigne? and Hideki Kawahara. 2002. YIN,
a fundamental frequency estimator for speech and
music. Journal of the Acoustical Society of America,
111(4):1917?1930.
David DeVault, Natalia Kariaeva, Anubha Kothari, Iris
Oved, and Matthew Stone. 2005. An information-
state approach to collaborative reference. In Short
Papers, ACL 2005, Michigan, USA, June.
Jonathan Ginzburg. 1996. Interrogatives: Ques-
tions, facts and dialogue. In Shalom Lappin, editor,
The Handbook of Contemporary Semantic Theory.
Blackwell, Oxford.
Peter A. Heeman and Graeme Hirst. 1995. Collabo-
rating on referring expressions. Computational Lin-
guistics, 21(3):351?382.
Massimo Poesio and Hannes Rieser. 2010. Comple-
tions, coordination, and alignment in dialogue. Dia-
logue and Discourse, 1(1):1?89.
Matthew Purver, Christine Howes, Eleni Gre-
goromichelaki, and Patrick Healey. 2009. Split
utterances in dialogue: a corpus study. In Proceed-
ings of the SIGDIAL 2009, pages 262?271, London,
UK, September.
Harvey Sacks and Emanuel A. Schegloff. 1979. Two
preferences in the organization of reference to per-
sons in conversation and their interaction. In George
Psathas, editor, Everyday Language: Studies in Eth-
nomethodology, pages 15?21. Irvington Publishers,
Inc., New York, NY, USA.
David Schlangen and Gabriel Skantze. 2009. A gen-
eral, abstract model of incremental dialogue pro-
cessing. In Proceedings of EACL 2009, pages 710?
718, Athens, Greece, March.
David Schlangen, Timo Baumann, Hendrik
Buschmeier, Okko Bu?, Stefan Kopp, Gabriel
Skantze, and Ramin Yaghoubzadeh. 2010. Middle-
ware for incremental processing in conversational
agents. In Proceedings of SIGDIAL 2010, Tokyo,
Japan.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of EACL 2009, pages 745?753, Athens,
Greece, March.
Marilyn A. Walker, Diane J. Litman, Candace A.
Kamm, and Alicia Abella. 1998. Evaluating spoken
dialogue agents with PARADISE: Two case studies.
Computer Speech and Language, 12(3).
Willie Walker, Paul Lamere, Philip Kwok, Bhiksha
Raj, Rita Singh, Evandro Gouvea, Peter Wolf, and
Joe Woelfel. 2004. Sphinx-4: A flexible open
source framework for speech recognition. Techni-
cal report, Sun Microsystems Inc.
236
