The FrameNet tagset for frame-semantic and syntactic coding of 
predicate-argument s ructure 
Christopher JOHNSON 
FrameNet Project, 
International Computer Science Institute 
currently: Soliloquy, Inc. 
255 Park Ave S 
New York NY 10010 
c johnson@soliloquy.corn 
Charles J. FILLMORE 
FrameNet Project, 
International Computer Science Institute 
1947 Center St., Suite 600 
Berkeley, CA, USA 94704 
fillmore@icsi.berkeley.edu 
Abstract 
This paper presents the syntactic and semantic 
tags used to annotate predicate-argument 
structure in the Berkeley FrameNet Project. It 
briefly explains the theory of frame semantics 
on which semantic annotation is based, 
discusses possible applications of FrameNet 
annotation, and compares FrameNet o other 
prominent iexical resources. 
Introduction 
This paper presents the tagset used to annotate 
the predicate-argument structures of English 
verbs, adjectives, and nouns in the Berkeley 
FrameNet Project (NSF IR\]-9618838, "Tools for 
Lexicon Building"), a corpus-based 
computational lexicography project based on the 
theory of frame semantics (see Fillmore 1982). 
It briefly explains the theoretical background and 
shows how frame-semantic annotation creates 
lexicographic generalizations that are not 
possible with more traditional linguistic 
approaches to argument structure based on 
thematic roles. 
1 The FrameNet Project 
1.1 What is frame semantics? 
Frame semantics characterizes the semantic and 
syntactic properties of predicating words by 
relating them to semantic frames. These are 
schematic representations of situations involving 
various participants, props, and other conceptual 
roles, each of which is a frame element (FE). 
The semantic arguments of a predicating word 
correspond to the FEs of the frame or frames 
associated with that word. 
Frames are organized in a structure that can 
be modeled by an inheritance lattice. They range 
from being very general, like case frames 
(Fillmore 1968) or other simple event schemas 
underlying thematic roles, to being lexically 
specific. The most interesting frames are those at 
an intermediate level of specificity which 
encapsulate generalizations about the semantic 
and syntactic properties of word classes that are 
overlooked by thematic role analyses. 
1.2 An example 
One example is the commercial transaction 
frame, which includes the following FEs: Buyer, 
Seller, Goods, and Money. The following 
sentence schemas show how these FEs are 
expressed ifferently by different Commercial 
Transaction words: 
Buyer bought Goods from Seller for Money 
Buyer paid Seller Money for Goods 
Buyer paid Money to Seller for Goods 
Seller sold goods to Buyer for Money 
Seller sold Buyer Goods for Money 
Buyer spent Money on Goods 
(Seller not expressed) 
Goods cost Buyer Money 
(Seller not expressed) 
Different words assign the Commercial 
Transaction FEs to different Phrase Types (PTs) 
and Grammatical Functions (GFs). For example, 
buy treats the Buyer as an NP subject (i.e. 
56
External Argument) and the Seller as a PP 
complement headed by from, while sell treats the 
Buyer as a direct object or a PP complement 
headed by to and the Seller as a subject. The 
purpose of FrameNet annotation is to gather 
information like this about the grammatical 
realization of FEs for various frames. 
1.2 Project goals 
The goals of the project are to create a database 
of information about English words and the 
frames they inherit, provide annotated corpus 
examples that illustrate how information about 
FEs is expressed by complements and modifiers 
of these words in attested sentences, and 
contribute to a suite of software tools to support 
annotation, database building, and database 
interface. 
An important part of FrameNet work is the 
annotation of corpus sentences with frame- 
semantic information. We use the British 
National Corpus (BNC), because no equally 
comprehensive corpus exists for American 
English (though efforts are underway to create a 
comparable American National Corpus--see 
Fillmore et al 1998). Each annotated example 
sentence shows argument-structure properties of 
one target verb, adjective or noun. The main 
task of annotation is to tag the arguments (and 
occasionally modifiers) of the target with the 
names of the FEs that they express. A secondary 
task is to mark other lexicographically relevant 
elements, uch as support verbs of target nouns, 
and certain non-meaningful elements that 
indicate lexicographically relevant grammatical 
constructions (e.g. extraposition and the 
existential construction). (See Fillmore & Atkins 
1998 on lexicographic relevance.) 
Here is an example sentence from the BNC 
showing the annotation properties of the 
complements of the target verb tell: 
(1) \[Maltravers (Speaker, NP, Ext)\] decided not 
to tell 
\[Stephen (Addressee, NP, Obj)\] 
\[about the inscription in the Le Carr6 book 
(Topic, PPabout, Comp)\]. 
The annotated constituents appear in brackets. 
Following each constituent is a set of 
parentheses containing the FE, PT and GF 
associated with that constituent (actual 
annotations consist of XML markup created 
using the Alembic Workbench software from the 
Mitre Corporation). PT and GF information is 
added by an automatic phrase labeler developed 
by the technical team. 
2 The FrameNet agset 
2.1 Phrase Types 
Below are the FrameNet Phrase Types. This is 
intended to be a comprehensive list of the types 
of syntactic onstituent that can express FEs of 
major predicating words of English (nouns, 
verbs and adjectives). These constituents occur 
either as arguments or as lexicographically 
relevant modifiers. In constructing this list, we 
made extensive reference to the Comlex syntax 
(Meyers et al 1995). 
2.1.1 Noun phrase types 
NP Noun phrase (the witness) 
N Non-maximal nominal (personal chat) 
Poss Possessive NP (the child's decision) 
There Expletive there (there was a fight) 
It Expletive it (it's nice that you came) 
2.1.2 Prepositional phrase types 
PP Prepositional phrase (look at me) 
Ping PP with gerundive object (keep from 
laughing) 
Part Particle(look it up) 
2.1.3 Verb phrase types 
VPfin Finite verb phrase (we atefish) 
VPbrst Bare stem VP (let us eatfish) 
VPto To-marked infinitive VP (we want to eat 
 sh) 
VPwh WH-VP (we know how to win) 
VPing Gerundive VP (we like winning) 
2.1.4 Complement clause types 
Sfin 
Swh 
Sif 
Sing 
Sto 
Sforto 
Sbrst 
Finite clause (it's nice thatyou came) 
WH-clause (ask who won) 
lflwhether clause (ask if we won) 
Gerundive clause (we saw them running) 
To-marked clause (we want them to win) 
For-to-marked clause (we would like for 
them to win) 
Bare stem clause (we insist that they 
win) 
57
In certain cases FrameNet marks as two 
constituents what are treated as "small clauses" 
in some analyses. For example, in the sentence I 
consider Pat a genius, Pat and a genius would 
be tagged separately. 
2.1.50therphrase types 
AjP Adjective phrase (an interesting idea) 
AdvP Adverb phrase (you put that nicely) 
Quo Quote ("Indeed, "she said) 
2.2 Grammatical Functions 
Below is a list of the FrameNet GFs. This list is 
intended to characterize all the grammatical 
contexts relative to English verbs, adjectives and 
nouns that are regularly occupied by FE- 
expressing constituents. In this list, we do not 
make the traditional distinction between obliques 
and arguments/complements (the former are 
simply PP complements). 
2.2.1 FrameNet grammatical functions 
Ext External Argument 
(Argument outside phrase headed by target verb, 
adjective or noun) 
Comp Complement 
(Argument inside phrase headed by target verb, 
adjective or noun) 
Mod Modifier 
(Non-argument expressing FE of target verb, 
adjective or noun) 
Xtrap Extraposed 
(Verbal or clausal complement extraposed toend 
of VP) 
Obj Object 
(Post-verbal argument; passivizable or does not 
alternate with PP) 
Pred Predicate 
(Secondary predicate complement of target verb 
or adjective) 
Head Head 
(Head nominal in attributive use of target 
adjective) 
Gen Genitive Determiner 
(Genitive Determiner of nominal headed by 
target) 
2.3 Nonexpression of FEs 
Besides being expressed by the PTs and GFs 
listed above, FEs may remain unexpressed under 
the different conditions discussed below (see 
Fillmore 1986). 
2.3.1 Indefinite Null lnstantiation 
In sentence (1), the FEs Message, Medium and 
Code are not expressed. It can however be 
inferred that there must be a Message, Medium 
and Code in a communicative event of the type 
described by this sentence. These FEs, while 
conceptually present in this sentence, are 
optionally expressed, and there are no particular 
restrictions on their nonexpression. This is called 
Indefinite Null Instantiation (INI). 
2.3.2 Definite Null Instantiation 
With some words, an FE may be unexpressed in 
a sentence only if it assumed that the person to 
whom the sentence is addressed has specific 
information about he frame element in question. 
This kind of non-expression is called Definite 
Null Instantiation (DNI). For example, the 
words tell, inform and notify allow a Message to 
be omitted when it is clear what the Message is, 
e.g. How did I know you won? Because Pat 
already tom me. 
2.3.3 Constructionally licensed null 
instantiation 
Certain grammatical constructions, such as 
Passive and Imperative, allow an External 
Argument FE to be unexpressed, e.g. Harsh 
things were said, Tell me about yourself. This is 
Constructionally Licensed Null Instantiation 
(CNI). 
FrameNet annotation marks prominent 
unexpressed FEs as well as FEs that are 
expressed overtly. In order to achieve this, we 
place the symbols INI, DNI and CNI 
immediately after the target word in every 
annotated sentence, and place the appropriate FE 
tag on the appropriate symbol. For example, the 
case of DNI discussed above would be annotated 
as follows: 
(2) \[Pat (Speaker)\] already told INI \[DNI 
(Message)\] CNI \[me (Addressee)\]. 
58
2.4 Frame Elements 
Frames are organized into the following 
domains: Body, Chance, Cognition, 
Communication, Emotion, Health, Life Stages, 
Motion, Perception, Society, Space, Time, 
Transaction, and a General domain. Each 
domain contains everal frames that characterize 
different word classes. Because there are many 
frames, it is not possible to give the complete list 
of FEs. The next section discusses FEs from the 
Communication domain. 
3 Communication frames 
It is typically the case that different frames in the 
same domain share FEs. For that reason, each 
domain can be characterized by a basic frame 
that defines its FEs in general terms, and more 
specific frames, corresponding to word classes, 
that are based on this basic frame through 
inheritance or some other principled relation. Let 
us consider the basic frame of verbal 
communication. 
3.1 Basic Verbal Communication frame 
The following FEs consistently appear in frames 
relating to verbal communication: 
Speaker 
(A person who performs an act of verbal 
communication) 
Addressee 
(An actual or intended recipient of a verbal 
message) 
Message 
(A communicated proposition) 
Topic 
(The subject matter of a message) 
Medium 
(A physical channel of communication) 
Code 
(The language or other code used to 
communicate) 
These FEs all derive their meaning from the 
concept of a basic communicative event. Clearly 
a true frame representation cannot just consist of 
a list of role names, but must characterize such 
events. Currently FrameNet frame descriptions 
exist only in text form, but the ultimate aim is to 
express them in a machine-readable format. An 
important component of such a representation 
will be feature structures that express relations 
between frames symbolically. These might be 
combined with computational event models that 
are able to generate inferences, such as the x- 
schemas developed by Bailey et al (1997) and 
Narayanan (1997). 
The FEs of the Basic Verbal Communication 
frame are relevant o sentence (1) above, in 
which the Speaker is expressed as an NP Ext, the 
Addressee is expressed as an NP Obj, and the 
Topic is expressed as a PP Comp headed by 
about. The other FEs are not expressed. 
We will examine how the FEs above are 
realized in different Communication frames, and 
in the process, will see some of the kinds of 
generalizations that can be expressed through 
frame-semantic lexical analysis. 
3.2 Other frames in the Communication domain 
The Basic Verbal Communication frame 
characterizes vents of verbal communication in 
the most general terms. Different 
Communication words represent different ypes 
of communicative event and different ways of 
construing such events. Generalizations over 
these words are captured by different frames in 
the domain. Some focus on, or profile, in 
Langacker's (1987) terminology, the relation 
between a Speaker and a propositional Message. 
These are grouped into frames characterizing 
different speech acts, e.g. asking (Questioning 
frame), requesting (Request frame), asserting 
(Statement frame), and promising (Commitment 
frame). A few words profile the relation between 
a Speaker and an act of speaking, but not the 
propositional Message communicated (talk, 
speak). Some denote events of reciprocal 
communication (e.g. discuss, argue, 
conversation, etc.). And so on. 
The following sections ummarize properties 
of specific frames, and discuss some 
assumptions about the ontology of the 
Communication domain that might account for 
these properties. 
3.3 The Statement frame 
Verbs and nouns in the Statement frame profile a 
relation between a Speaker and a propositional 
59
Message that has the speech act status of an 
assertion. Because of the importance of the 
Message FE, these words frequently occur with 
Sfin Comp (finite clausal complements): 
(3) \[Others (Speaker, NP, Ext)\] assert \[that 
anthropology is the tree and sociology the branch 
(Message, Sfin, Comp)\]. 
(4) \[Managers (Speaker, NP, Ext)\] claim \[there 
was no radiological hazzard to staff or the public 
(Message, Sfin, Comp)\]. 
(5) \[His (Speaker, Poss, Gen)\] claims \[to have 
more energy (Message, VPto, Comp)\] are simply 
laughable. 
Message can be expressed with different PPs as 
well. For example, with the target noun claim, it 
can be expressed as a to-marked infinitive VP, as 
in example (5). 
3.4 The Speaking frame 
Verbs and nouns in the Speaking frame profile a 
relation between a Speaker and an act of 
speaking, but do no allow a Message to be 
expressed: 
(6) \[She (Speaker, NP, Ext)\] never spoke \[about 
her feelings (Topic, PPabout, Comp)\]. 
This fact can be explained if we analyze the 
basic meaning of Speaking words as being 
something like 'X say something'. The Message 
role can be thought of as being incorporated 
into this meaning, with incorporation i this case 
being equivalent to obligatory INI. 
3.5 The Request frame 
Like words in the Statement frame, these words 
frequently occur with clausal Complements. 
However, because these Complements express 
requests rather that assertions, they often occur 
as bare stem clauses: 
(7) In all cases \[the respondent (Speaker, NP, 
Ext)\] may request \[in writing (Medium, PPin, 
Comp)\] \[that the disciplinary findings be 
published (Message, Sbrst, Comp)\]. 
3.6 The Conversation flame 
One class of words in the Communication 
domain does not use the FEs Speaker and 
Addressee as they occur in other frames. These 
are nouns and verbs or reciprocal 
communication, which are treated in the 
Conversation frame. In this frame, the human 
interlocutors can be expressed in separate 
constituents, assigned the roles Protagonist-I 
(Prot-1) and Protagonist-2 (Prot-2), or they can 
be expressed in a single conjoined or plural 
constituent, assigned the role Protagonists 
(Prots). 
This class of words demonstrates the 
complex interaction of frames. The FEs Prot-1, 
Prot-2 and Prots are not equivalent to any of the 
Basic Verbal Communication FEs, but do relate 
to them in a regular way. Each of these roles 
must be thought of as relating to two or more 
Communicative subevents, and as corresponding 
to a Speaker in some and an Addressee in others. 
This basic structure is taken not from any frame 
in the domain of Communication, but from a 
Reciprocity frame, which is in the General 
domain. The Reciprocity frame may be thought 
of as an Aktionsart frame that structures events 
and relations from other frames in a particular 
way, such that there are multiple subeventualities 
of the same type as that of the input frame, and 
the bindings or fillers of the roles are reversed 
from one subeventuality to the another. 
The complexity introduced by frames such 
as these points to the need to distinguish between 
conceptual roles and FEs in any given frame. 
While the Communication roles Speaker and 
Addressee are not FEs in the Conversation 
frame, they are conceptual roles, because the 
conceptual representation f Conversation makes 
reference to them. (In the Speaking frame 
discussed above, we can also think of the 
incorporated Message role as being a conceptual 
role rather than an FE.) FEs in any given frame 
should therefore be defined as those roles for 
which the frame specifies conventional means of 
syntactic expression, even if these means are not 
employed in all sentences. 
3.6.1 Disjoint expression: Prot-1 and Prot-2 
Here is a BNC example of argue with a disjoint 
expression of interlocutors: 
(8) "\[You (Prot-1, NP, Ext)\] can't argue 
\[politics (Topic, NP, Comp)\] \[with foreigners 
(Prot-2, PPwith, Comp)\]", sighed the policeman. 
Prot-2, the less prominent interlocutor, is 
regularly expressed in this frame by a PP Comp 
60
headed by with. This is consistent with the 
general behavior of the Reciprocity frame as it 
occurs in combination with other frames and 
domains (e.g. Pat had a 
collision/relationship/agreement with Kim). 
3. 6.2 Joint expression: Protagonists 
Here are BNC examples of the joint expression 
of interlocuters with argue: 
(9) \[They (Prots, NP, Ext)\] argued \[angrily 
(Manner, AdvP, Mod)\] \[over who was the real 
"Prince of Sleaze" (Topic, PPover, Comp)\]. 
(10) \[Mr. and Mrs. Popple (Prots, NP, Ext)\] 
always argued \[INI (Topic)\] at least once a 
week. 
3.7 FrameNet complements existing lexical 
resources 
FrameNet annotations provide more detail than 
existing lexical resources about he way in which 
particular semantic roles (i.e. FEs) are linked 
with particular means of syntactic expression. 
Since different senses of ambiguous words are 
defined relative to different frames, this linking 
information could potentially be used for lexical 
disambiguation. 
For example, consider the verb argue as it is 
treated in the WordNet database (Fellbaum 
1998). Below are the three WordNet senses of 
argue, and the sentence frames that are 
associated with each sense: 
Sense 1: argue, reason - -  (present reasons and 
arguments) 
EX: Sam and Sue argue 
EX: Sam wants to argue with Sue 
Sense 2: argue, contend, debate, fence - -  (have 
an argument about something) 
EX: Sam and Sue argue 
EX; Sam wants to argue with Sue 
Sense 3: argue, indicate - -  (give evidence of; 
"The evidence argues for your claim"; "The 
results indicate the need for more work") 
The three senses listed above correspond to three 
different frames: Sense 1 corresponds to the 
Statement frame, Sense 2 to the Conversation 
frame, and Sense 3 to the Evidence frame in the 
Cognition domain. However, the information 
about sentence frames provided in WordNet 
does not correspond to the generalizations that 
are apparent in FrameNet. For example, 
WordNet gives the same sentence frames for 
Senses 1 and 2, while in the FrameNet database, 
the senses of argue defined relative to the 
Statement and Conversation frames are 
characterized by different argument structures: 
only Statement argue allows finite clausal 
complements expressing Message; Conversation 
argue has the properties of other reciprocal 
communication words, which Statement argue 
lacks, and does not allow clausal Complements 
(or any other expression of Message). 
COMLEX (Meyers et al 1995) recognizes 
the syntactic frames in which argue occurs, but 
does not provide information about he linking of 
syntactic constituents with semantic roles, or 
about the different complementation properties 
of different senses of ambiguous words. 
Conclusion 
FrameNet semantic annotation captures human 
knowledge about the ways in which semantic 
roles (FEs) are conventionally expressed by 
different words in various word classes and 
domains. The kind of information in the 
FrameNet database is not expressed in the same 
level of depth in any existing print dictionary or 
computational lexical resource. While WordNet 
describes emantic relations between words, it 
does not recognize the conceptual schemas, i.e. 
frames, that mediate in these relations, and 
therefore does not have the means to link 
arguments of predicating words with the 
semantic roles they express. COMLEX and 
NOMLEX provide detailed information about 
the syntactic frames in which verbs and nouns 
occur, but also lack a means to link syntactic 
arguments with semantic roles. FrameNet 
therefore provides information that complements 
major existing lexical resources. 
Acknowledgements 
The authors would like to thank the National 
Science Foundation for supporting this project, 
and the International Computer Science Institute 
in Berkeley for giving it a home. Thanks also to 
Oxford University Press and Sue Atkins for 
61 61
making it possible for us to use the British 
National Corpus, and to IMS-Stuttgart and Uli 
Heid for providing us with the tagged version. 
We are also grateful to Catherine Macleod and 
Ralph Grishman of the NYU Proteus Project for 
allowing one of use to be a visitor, and various 
people in the Berkeley linguistics department 
and in the Neural Theory of Language project at 
ICSI for enlightening discussions. 
References 
Bailey, D., J. Feidman, S. Narayanan and G. Lakoff. 
(1997) Modeling embodied lexical semantics. In 
Proceedings of the 19th Annual Meeting of the 
Cognitive Science Society COGSCI-97. Stanford, 
CA: Stanford University Press. 
Baker, Collin F., Charles J. Fillmore, and John B. 
Lowe. (1998) The Berkeley FrameNet Project. In 
COLING-ACL '98 Proceedings of the Conference 
held August 10-14, 1998, in Montreal, Canada, 
pp.86-90. 
Fellbaum, Christiane (1987) WordNet: An electronic 
lexical database. Cambridge, MA: MIT Press. 
Fillmore, Charles J. (1968) The case for case. In E. 
Bach and R. Harms (eds.), Universals in Linguistic 
Theory. New York: Holt, Rinehart & Winston. 
Fillmore, Charles J. (1982) Frame semantics. In 
Linguistics in the Morning Calm, pp. 111-137. 
Seoul, South Korea: Hanshin Publishing Co. 
Fillmore, Charles J. (1986) Pragmatically Controlled 
Zero Anaphora. In Proceedings of the 12th annual 
meeting of the Berkeley Linguistics Society, pp. 
95-107. 
Fillmore, Charles J. and B. T. S. Atkins. (1999) 
Describing polysemy: the case of 'crawl'. In 
Polysemy: Linguistic and Computational 
Approaches, (eds.) Yael Ravin and Claudia 
Leacock. Oxford: Oxford University Press. 
Fillmore, Charles J. and B.T.S. Atkins. (1998) 
FrameNet and lexicographic relevance. In 
Proceedings of the First International Conference 
on Language Resources and Evaluation, Granada, 
Spain, 28-30 May 1998. 
Fillmore, Charles J., Nancy Ide, Daniel Jurafsky, and 
Catherine Macleod (May 1998) An American 
National Corpus: A Proposal. In Proceedings ofthe 
First International Conference on Language 
Resources and Evaluation (LREC); Granada, Spain 
28-30 May 1998. 
Gahl, Susanne (1998) Automatic extraction of 
Subcorpora based on Subcategorization Frames 
from a Part-of-Speech tagged Corpus. In COLING- 
ACL '98 Proceedings of the Conference held 
August 10-14, 1998, at the University of Montr6al, 
Canada, pp.428-32. 
Gahl, Susanne (1998) Automatic extraction of 
Subcorpora for Corpus-based Dictionary-building. 
In Thierry Fontenelle t al. (eds.), EURALEX '98 
Proceedings: Papers submitted to the Eighth 
EURALEX Conference, atthe University of Li6ge, 
Belgium, pp.445-452. 
J.B. Lowe, C.F. Baker, and C.J. Fillmore. (1997) A 
frame-semantic approach to semantic annotation. 
In Proceedings of the SIGLEX workshop "Tagging 
Text with Lexical Semantics: Why, What, and 
How?" held April 4-5, in Washington, D.C., USA 
in conjunction with ANLP-97. 
Johnson, Christopher (1999) Multiple frame 
inheritance in lexical descriptions. Annual 
Meeting of the Linguistic Society of America. Los 
Angeles, January 9. 
Johnson, Christopher. (1999) Syntactic and semantic 
principles of FrameNet annotation. TC-99-018, 
International Computer Science Institute, Berkeley, 
CA. 
Langacker, Ronald. (1987) Foundations of Cognit&e 
Grammar, Vol. 1: Theoretical Perspectives. 
Stanford, CA: Stanford University Press. 
Levin, Beth. (1993) English Verb Classes and 
Alternations. Chicago: University of Chicago Press. 
Meyers, Adam, Catherine Macleod, and Ralph 
Grishman. (1995) Comlex syntax 2.0 manual for 
tagged entries. Technical report, Proteus Project, 
New York University. 
Narayanan, S. (1997) KARMA: Knowledge-Based 
Active Representations for Metaphor and Aspect. 
Ph.D. Dissertation, Computer Science Division, 
University of California, Berkeley. 
~"\ ] t  62
The Descent of Hierarchy, and Selection in Relational Semantics  
Barbara Rosario
SIMS
UC Berkeley
Berkeley, CA 94720
rosario@sims.berkeley.edu
Marti A. Hearst
SIMS
UC Berkeley
Berkeley, CA 94720
hearst@sims.berkeley.edu
Charles Fillmore
ICSI
UC Berkeley
Berkeley, CA 94720
fillmore@icsi.berkeley.edu
Abstract
In many types of technical texts, meaning is
embedded in noun compounds. A language un-
derstanding program needs to be able to inter-
pret these in order to ascertain sentence mean-
ing. We explore the possibility of using an ex-
isting lexical hierarchy for the purpose of plac-
ing words from a noun compound into cate-
gories, and then using this category member-
ship to determine the relation that holds be-
tween the nouns. In this paper we present the
results of an analysis of this method on two-
word noun compounds from the biomedical do-
main, obtaining classification accuracy of ap-
proximately 90%. Since lexical hierarchies are
not necessarily ideally suited for this task, we
also pose the question: how far down the hi-
erarchy must the algorithm descend before all
the terms within the subhierarchy behave uni-
formly with respect to the semantic relation in
question? We find that the topmost levels of the
hierarchy yield an accurate classification, thus
providing an economic way of assigning rela-
tions to noun compounds.
1 Introduction
A major difficulty for the interpretation of sentences from
technical texts is the complex structure of noun phrases
and noun compounds. Consider, for example, this title,
taken from a biomedical journal abstract:
Open-labeled long-term study of the subcutaneous
sumatriptan efficacy and tolerability in acute mi-
graine treatment.
An important step towards being able to interpret such
technical sentences is to analyze the meaning of noun
compounds, and noun phrases more generally.

With apologies to Charles Darwin.
Interpretation of noun compounds (NCs) is highly de-
pendent on lexical information. Thus we explore the use
of a large corpus (Medline) and a large lexical hierarchy
(MeSH, Medical Subject Headings) to determine the re-
lations that hold between the words in noun compounds.
Surprisingly, we find that we can simply use the juxta-
position of category membership within the lexical hier-
archy to determine the relation that holds between pairs
of nouns. For example, for the NCs leg paresis, skin
numbness, and hip pain, the first word of the NC falls into
the MeSH A01 (Body Regions) category, and the second
word falls into the C10 (Nervous System Diseases) cat-
egory. From these we can declare that the relation that
holds between the words is ?located in?. Similarly, for
influenza patients and aids survivors, the first word falls
under C02 (Virus Diseases) and the second is found in
M01.643 (Patients), yielding the ?afflicted by? relation.
Using this technique on a subpart of the category space,
we obtain 90% accuracy overall.
In some sense, this is a very old idea, dating back to
the early days of semantic nets and semantic grammars.
The critical difference now is that large lexical resources
and corpora have become available, thus allowing some
of those old techniques to become feasible in terms of
coverage. However, the success of such an approach de-
pends on the structure and coverage of the underlying lex-
ical ontology.
In the following sections we discuss the linguistic mo-
tivations behind this approach, the characteristics of the
lexical ontology MeSH, the use of a corpus to examine
the problem space, the method of determining the rela-
tions, the accuracy of the results, and the problem of am-
biguity. The paper concludes with related work and a
discussion of future work.
2 Linguistic Motivation
One way to understand the relations between the words
in a two-word noun compound is to cast the words into
                Computational Linguistics (ACL), Philadelphia, July 2002, pp. 247-254.
                         Proceedings of the 40th Annual Meeting of the Association for
a head-modifier relationship, and assume that the head
noun has an argument structure, much the way verbs do,
as well as a qualia structure in the sense of Pustejovsky
(1995). Then the meaning of the head noun determines
what kinds of things can be done to it, what it is made of,
what it is a part of, and so on.
For example, consider the noun knife. Knives are cre-
ated for particular activities or settings, can be made of
various materials, and can be used for cutting or manip-
ulating various kinds of things. A set of relations for
knives, and example NCs exhibiting these relations is
shown below:
(Used-in): kitchen knife, hunting knife
(Made-of): steel knife, plastic knife
(Instrument-for): carving knife
(Used-on): meat knife, putty knife
(Used-by): chef?s knife, butcher?s knife
Some relationships apply to only certain classes of nouns;
the semantic structure of the head noun determines the
range of possibilities. Thus if we can capture regularities
about the behaviors of the constituent nouns, we should
also be able to predict which relations will hold between
them.
We propose using the categorization provided by a lex-
ical hierarchy for this purpose. Using a large collection
of noun compounds, we assign semantic descriptors from
the lexical hierarchy to the constituent nouns and deter-
mine the relations between them. This approach avoids
the need to enumerate in advance all of the relations that
may hold. Rather, the corpus determines which relations
occur.
3 The Lexical Hierarchy: MeSH
MeSH (Medical Subject Headings)1 is the National Li-
brary of Medicine?s controlled vocabulary thesaurus; it
consists of set of terms arranged in a hierarchical struc-
ture. There are 15 main sub-hierarchies (trees) in MeSH,
each corresponding to a major branch of medical termi-
nology. For example, tree A corresponds to Anatomy,
tree B to Organisms, tree C to Diseases and so on. Every
branch has several sub-branches; Anatomy, for example,
consists of Body Regions (A01), Musculoskeletal System
(A02), Digestive System (A03) etc. We refer to these as
?level 0? categories.
These nodes have children, for example, Abdomen
(A01.047) and Back (A01.176) are level 1 children
of Body Regions. The longer the ID of the MeSH
term, the longer the path from the root and the more
precise the description. For example migraine is
C10.228.140.546.800.525, that is, C (a disease), C10
(Nervous System Diseases), C10.228 (Central Nervous
1http://www.nlm.nih.gov/mesh/meshhome.html; the work
reported in this paper uses MeSH 2001.
System Diseases) and so on. There are over 35,000
unique IDs in MeSH 2001. Many words are assigned
more than one MeSH ID and so occur in more than one
location within the hierarchy; thus the structure of MeSH
can be interpreted as a network.
Some of the categories are more homogeneous than
others. The tree A (Anatomy) for example, seems to be
quite homogeneous; at level 0, the nodes are all part of
(meronymic to) Anatomy: the Digestive (A03), Respi-
ratory (A04) and the Urogenital (A05) Systems are all
part of anatomy; at level 1, the Biliary Tract (A03.159)
and the Esophagus (A03.365) are part of the Digestive
System (level 0) and so on. Thus we assume that every
node is a (body) part of the parent node (and all the nodes
above it).
Tree C for Diseases is also homogeneous; the child
nodes are a kind of (hyponym of) the disease at the par-
ent node: Neoplasms (C04) is a kind of Disease C and
Hamartoma (C04.445) is a kind of Neoplasms.
Other trees are more heterogeneous, in the sense that
the meanings among the nodes are more diverse. Infor-
mation Science (L01), for example, contains, among oth-
ers, Communications Media (L01.178), Computer Secu-
rity (L01.209) and Pattern Recognition (L01.725). An-
other heterogeneous sub-hierarchy is Natural Science
(H01). Among the children of H01 we find Chemistry
(parent of Biochemistry), Electronics (parent of Ampli-
fiers and Robotics), Mathematics (Fractals, Game The-
ory and Fourier Analysis). In other words, we find a wide
range of concepts that are not described by a simple rela-
tionship.
These observations suggest that once an algorithm de-
scends to a homogeneous level, words falling into the
subhierarchy at that level (and below it) behave similarly
with respect to relation assignment.
4 Counting Noun Compounds
In this and the next section, we describe how we investi-
gated the hypothesis:
For all two-word noun compounds (NCs) that
can be characterized by a category pair (CP), a
particular semantic relationship holds between
the nouns comprising those NCs.
The kinds of relations we found are similar to those
described in Section 2. Note that, in this analysis we fo-
cused on determining which sets of NCs fall into the same
relation, without explicitly assigning names to the rela-
tions themselves. Furthermore, the same relation may be
described by many different category pairs (see Section
5.5).
First, we extracted two-word noun compounds from
approximately 1M titles and abstracts from the Med-
line collection of biomedical journal articles, resulting
Figure 1: Distribution of Level 0 Category Pairs. Mark size
indicates the number of unique NCs that fall under the CP. Only
those for which  NCs occur are shown.
in about 1M NCs. The NCs were extracted by finding
adjacent word pairs in which both words are tagged as
nouns by a tagger and appear in the MeSH hierarchy, and
the words preceding and following the pair do not appear
in MeSH2 Of these two-word noun compounds, 79,677
were unique.
Next we used MeSH to characterize the NCs according
to semantic category(ies). For example, the NC fibroblast
growth was categorized into A11.329.228 (Fibroblasts)
and G07.553.481 (Growth).
Note that the same words can be represented at differ-
ent levels of description. For example, fibroblast growth
can be described by the MeSH descriptors A11.329.228
G07.553.481 (original level), but also by A11 G07 (Cell
and Physiological Processes) or A11.329 G07.553 (Con-
nective Tissue Cells and Growth and Embryonic Devel-
opment). If a noun fell under more than one MeSH ID,
we made multiple versions of this categorization. We re-
fer to the result of this renaming as a category pair (CP).
We placed these CPs into a two-dimensional table,
with the MeSH category for the first noun on the X axis,
and the MeSH category for the second noun on the Y
axis. Each intersection indicates the number of NCs that
are classified under the corresponding two MeSH cate-
gories.
A visualization tool (Ahlberg and Shneiderman, 1994)
allowed us to explore the dataset to see which areas of
the category space are most heavily populated, and to get
a feeling for whether the distribution is uniform or not
(see Figure 1). If our hypothesis holds (that NCs that fall
2Clearly, this simple approach results in some erroneous ex-
tractions.
within the same category pairs are assigned the same re-
lation), then if most of the NCs fall within only a few
category pairs then we only need to determine which re-
lations hold between a subset of the possible pairs. Thus,
the more clumped the distribution, the easier (potentially)
our task is. Figure 1 shows that some areas in the CP
space have a higher concentration of unique NCs (the
Anatomy, and the E through N sub-hierarchies, for ex-
ample), especially when we focus on those for which at
least 50 unique NCs are found.
5 Labeling NC Relations
Given the promising nature of the NC distributions, the
question remains as to whether or not the hypothesis
holds. To answer this, we examined a subset of the CPs to
see if we could find positions within the sub-hierarchies
for which the relation assignments for the member NCs
are always the same.
5.1 Method
We first selected a subset of the CPs to examine in detail.
For each of these we examined, by hand, 20% of the NCs
they cover, paraphrasing the relation between the nouns,
and seeing if that paraphrase was the same for all the NCs
in the group. If it was the same, then the current levels of
the CP were considered to be the correct levels of descrip-
tion. If, on the other hand, several different paraphrases
were found, then the analysis descended one level of the
hierarchy. This repeated until the resulting partition of
the NCs resulted in uniform relation assignments.
For example, all the following NCs were mapped to the
same CP, A01 (Body Regions) and A07 (Cardiovascular
System): scalp arteries, heel capillary, shoulder artery,
ankle artery, leg veins, limb vein, forearm arteries, fin-
ger capillary, eyelid capillary, forearm microcirculation,
hand vein, forearm veins, limb arteries, thigh vein, foot
vein. All these NCs are ?similar? in the sense that the
relationships between the two words are the same; there-
fore, we do not need to descend either hierarchy. We call
the pair (A01, A07) a ?rule?, where a rule is a CP for
which all the NCs under it have the same relationship. In
the future, when we see an NC mapped to this rule, we
will assign this semantic relationship to it.
On the other hand, the following NCs, having the CP
A01 (Body Regions) and M01 (Persons), do not have
the same relationship between the component words: ab-
domen patients, arm amputees, chest physicians, eye pa-
tients, skin donor. The relationships are different depend-
ing on whether the person is a patient, a physician or a
donor. We therefore descend the M01 sub-hierarchy, ob-
taining the following clusters of NCs:
A01 M01.643 (Patients): abdomen patients, ankle
inpatient, eye outpatient
A01 H01 (Natural Sciences):
A01 H01 abdomen x-ray, ankle motion
A01 H01.770 (Science): skin observation
A01 H01.548 (Mathematics): breast risk
A01 H01.939 (Weights and Measures): head calibration
A01 H01.181 (Chemistry): skin iontophoresis
A01 H01.671 (Physics)
A01 H01.671.538 (Motion): shoulder rotations
A01 H01.671.100 (Biophysics): shoulder biomechanics
A01 H01.671.691 (Pressure): eye pressures
A01 H01.671.868 (Temp.): forehead temperature
A01 H01.671.768 (Radiation): thorax x-ray
A01 H01.671.252 (Electricity): chest electrode
A01 H01.671.606 (Optics): skin color
Figure 2: Levels of descent needed for NCs classified un-
der A01 H01.
A01 M01.526 (Occupational Groups): chest physician,
eye nurse, eye physician
A01, M01.898 (Donors): eye donor, skin donor
A01, M01.150 (Disabled Persons): arm amputees, knee
amputees.
In other words, to correctly assign a relationship to
these NCs, we needed to descend one level for the second
word. The resulting rules in this case are (A01 M01.643),
(A01, M01.150) etc. Figure 2 shows one CP for which we
needed to descend 3 levels.
In our collection, a total of 2627 CPs at level 0 have at
least 10 unique NCs. Of these, 798 (30%) are classified
with A (Anatomy) for either the first or the second noun.
We randomly selected 250 of such CPs for analysis.
We also analyzed 21 of the 90 CPs for which the sec-
ond noun was H01 (Natural Sciences); we decided to ana-
lyze this portion of the MeSH hierarchy because the NCs
with H01 as second noun are frequent in our collection,
and because we wanted to test the hypothesis that we do
indeed need to descend farther for heterogeneous parts of
MeSH.
Finally, we analyzed three CPs in category C (Dis-
eases); the most frequent CP in terms of the total number
of non-unique NCs is C04 (Neoplasms) A11 (Cells), with
30606 NCs; the second CP was A10 C04 (27520 total
NCs) and the fifth most frequent, A01 C04, with 20617
total NCs; we analyzed these CPs.
We started with the CPs at level 0 for both words, de-
scending when the corresponding clusters of NCs were
not homogeneous and stopping when they were. We did
this for 20% of the NCs in each CP. The results were as
follows.
For 187 of 250 (74%) CPs with a noun in the Anatomy
category, the classification remained at level 0 for both
words (for example, A01 A07). For 55 (22%) of the CPs
we had to descend 1 level (e.g., A01 M01: A01 M01.898,
A01 M01.643) and for 7 CPs (2%) we descended two
levels. We descended one level most of the time for the
sub-hierarchies E (Analytical, Diagnostic and Therapeu-
tic Techniques), G (Biological Sciences) and N (Health
Care) (around 50% of the time for these categories com-
bined). We never descended for B (Organisms) and did
so only for A13 (Animal Structures) in A. This was to be
able to distinguish a few non-homogeneous subcategories
(e.g., milk appearing among body parts, thus forcing a
distinction between buffalo milk and cat forelimb).
For CPs with H01 as the second noun, of the 21
CPs analyzed, we observed the following (level number,
count) pairs: (0, 1) (1, 8) (2, 12).
In all but three cases, the descending was done for the
second noun only. This may be because the second noun
usually plays the role of the head noun in two-word noun
compounds in English, thus requiring more specificity.
Alternatively, it may reflect the fact that for the exam-
ples we have examined so far, the more heterogeneous
terms dominate the second noun. Further examination is
needed to answer this decisively.
5.2 Accuracy
We tested the resulting classifications by developing a
randomly chosen test set (20% of the NCs for each
CP), entirely distinct from the labeled set, and used the
classifications (rules) found above to automatically pre-
dict which relations should be assigned to the member
NCs. An independent evaluator with biomedical training
checked these results manually, and found high accura-
cies: For the CPs which contained a noun in the Anatomy
domain, the assignments of new NCs were 94.2% accu-
rate computed via intra-category averaging, and 91.3%
accurate with extra-category averaging. For the CPs in
the Natural Sciences (H01) we found 81.6% accuracy via
intra-category averaging, and 78.6% accuracy with extra-
category averaging. For the three CPs in the C04 category
we obtained 100% accuracy.
The total accuracy across the portions of the A, H01
and C04 hierarchies that we analyzed were 89.6% via
intra-category averaging, and 90.8% via extra-category
averaging.
The lower accuracy for the Natural Sciences category
illustrates the dependence of the results on the proper-
ties of the lexical hierarchy. We can generalize well if
the sub-hierarchies are in a well-defined semantic rela-
tion with their ancestors. If they are a list of ?unrelated?
topics, we cannot use the generalization of the higher lev-
els; most of the mistakes for the Natural Sciences CPs oc-
curred in fact when we failed to descend for broad terms
such as Physics. Performing this evaluation allowed us
to find such problems and update the rules; the resulting
categorization should now be more accurate.
5.3 Generalization
An important issue is whether this method is an economic
way of classifying the NCs. The advantage of the high
level description is, of course, that we need to assign by
hand many fewer relationships than if we used all CPs at
their most specific levels. Our approach provides gener-
alization over the ?training? examples in two ways. First,
we find that we can use the juxtaposition of categories
in a lexical hierarchy to identify semantic relationships.
Second, we find we can use the higher levels of these cat-
egories for the assignments of these relationships.
To assess the degree of this generalization we calcu-
lated how many CPs are accounted for by the classifica-
tion rules created above for the Anatomy categories. In
other words, if we know that A01 A07 unequivocally de-
termines a relationship, how many possible (i.e., present
in our collection) CPs are there that are ?covered by? A01
A07 and that we do not need to consider explicitly? It
turns out that our 415 classification rules cover 46001
possible CP pairs3.
This, and the fact that we achieve high accuracies with
these classification rules, show that we successfully use
MeSH to generalize over unique NCs.
5.4 Ambiguity
A common problem for NLP tasks is ambiguity. In this
work we observe two kinds: lexical and ?relationship?
ambiguity. As an example of the former, mortality can
refer to the state of being mortal or to death rate. As an
example of the latter, bacteria mortality can either mean
?death of bacteria? or ?death caused by bacteria?.
In some cases, the relationship assignment method de-
scribed here can help disambiguate the meaning of an
ambiguous lexical item. Milk for example, can be both
Animal Structures (A13) and Food and Beverages (J02).
Consider the NCs chocolate milk, coconut milk that fall
under the CPs (B06 -Plants-, J02) and (B06, A13). The
CP (B06, J02) contains 180 NCs (other examples are
berry wines, cocoa beverages) while (B06, A13) has
only 6 NCs (4 of which with milk). Assuming then that
(B06, A13) is ?wrong?, we will assign only (B06, J02)
to chocolate milk, coconut milk, therefore disambiguat-
ing the sense for milk in this context (Beverage). Anal-
ogously, for buffalo milk, caprine milk we also have two
CPs (B02, J02) (B02, A13). In this case, however, it is
easy to show that only (B02 -Vertebrates-, A13) is the
correct one (i.e. yielding the correct relationship) and we
then assign the MeSH sense A13 to milk.
Nevertheless, ambiguity may be a problem for this
method. We see five different cases:
3Although we began with 250 CPs in the A category, when a
descend operation is performed, the CP is split into two or more
CPs at the level below. Thus the total number of CPs after all
assignments are made was 415.
1) Single MeSH senses for the nouns in the NC (no lex-
ical ambiguity) and only one possible relationship which
can predicted by the CP; that is, no ambiguity. For in-
stance, in abdomen radiography, abdomen is classified
exclusively under Body Regions and radiography ex-
clusively under Diagnosis, and the relationship between
them is unambiguous. Other examples include aciclovir
treatment (Heterocyclic Compounds, Therapeutics) and
adenocarcinoma treatment (Neoplasms, Therapeutics).
2) Single MeSH senses (no lexical ambiguity) but mul-
tiple readings for the relationships that therefore cannot
be predicted by the CP. It was quite difficult to find exam-
ples of this case; disambiguating this kind of NC requires
looking at the context of use. The examples we did find
include hospital databases which can be databases re-
garding (topic) hospitals, databases found in (location)
or owned by hospitals. Education efforts can be efforts
done through (education) or done to achieve education.
Kidney metabolism can be metabolism happening in (lo-
cation) or done by the kidney. Immunoglobulin stain-
ing, (D12 -Amino Acids, Peptides-, and Proteins, E05 -
Investigative Techniques-) can mean either staining with
immunoglobulin or staining of immunoglobulin.
3) Multiple MeSH mappings but only one possible re-
lation. One example of this case is alcoholism treatment
where treatment is Therapeutics (E02) and alcoholism is
both Disorders of Environmental Origin (C21) and Men-
tal Disorders (F03). For this NC we have therefore 2 CPs:
(C21, E02) as in wound treatments, injury rehabilitation
and (F03, E02) as in delirium treatment, schizophrenia
therapeutics. The multiple mappings reflect the conflict-
ing views on how to classify the condition of alcoholism,
but the relationship does not change.
4) Multiple MeSH mappings and multiple relations
that can be predicted by the different CPs. For exam-
ple, Bread diet can mean either that a person usually eats
bread or that a physician prescribed bread to treat a con-
dition. This difference is reflected by the different map-
pings: diet is both Investigative Techniques (E05) and
Metabolism and Nutrition (G06), bread is Food and Bev-
erages (J02). In these cases, the category can help disam-
biguate the relation (as opposed to in case 5 below); word
sense disambiguation algorithms that use context may be
helpful.
5) Multiple MeSH mappings and multiple relations
that cannot be predicted by the different CPs. As an ex-
ample of this case, bacteria mortality can be both ?death
of bacteria? or ?death caused by bacteria?. The multiple
mapping for mortality (Public Health, Information Sci-
ence, Population Characteristics and Investigative Tech-
niques) does not account for this ambiguity. Similarly,
for inhibin immunization, the first noun falls under Hor-
mones and Amino Acids, while immunization falls under
Environment and Public Health and Investigative Tech-
niques. The meanings are immunization against inhibin
or immunization using inhibin, and they cannot be dis-
ambiguated using only the MeSH descriptors.
We currently do not have a way to determine how many
instances of each case occur. Cases 2 and 5 are the most
problematic; however, as it was quite difficult to find ex-
amples for these cases, we suspect they are relatively rare.
A question arises as to if representing nouns using the
topmost levels of the hierarchy causes a loss in informa-
tion about lexical ambiguity. In effect, when we represent
the terms at higher levels, we assume that words that have
multiple descriptors under the same level are very similar,
and that retaining the distinction would not be useful for
most computational tasks. For example, osteosarcoma
occurs twice in MeSH, as C04.557.450.565.575.650 and
C04.557.450.795.620. When described at level 0, both
descriptors reduce to C04, at level 1 to C04.557, remov-
ing the ambiguity. By contrast, microscopy also occurs
twice, but under E05.595 and H01.671.606.624. Reduc-
ing these descriptors to level 0 retains the two distinct
senses.
To determine how often different senses are grouped
together, we calculated the number of MeSH senses for
words at different levels of the hierarchy. Table 1 shows
a histogram of the number of senses for the first noun of
all the unique NCs in our collection, the average degree
of ambiguity and the average description lengths.4 The
average number of MeSH senses is always less than two,
and increases with length of description, as is to be ex-
pected.
We observe that 3.6% of the lexical ambiguity is at lev-
els higher that 2, 16% at L2, 21.4% at L1 and 59% at L0.
Level 1 and 2 combined account for more than 80% of the
lexical ambiguity. This means that when a noun has mul-
tiple senses, those senses are more likely to come from
different main subtrees of MeSH (A and B, for exam-
ple), than from different deeper nodes in the same subtree
(H01.671.538 vs. H01.671.252). This fits nicely with our
method of describing the NCs with the higher levels of
the hierarchy: if most of the ambiguity is at the highest
levels (as these results show), information about lexical
ambiguity is not lost when we describe the NCs using the
higher levels of MeSH. Ideally, however, we would like
to reduce the lexical ambiguity for similar senses and to
retain it when the senses are semantically distinct (like,
for example, for diet in case 4). In other words, ideally,
the ambiguity left at the levels of our rules accounts for
only (and for all) the semantically different senses. Fur-
ther analysis is needed, but the high accuracy we obtained
in the classification seems to indicate that this indeed is
what is happening.
4We obtained very similar results for the second noun.
# Senses Original L2 L1 L0
1 (Unambiguous) 51539 51766 54087 58763
2 18637 18611 18677 17373
3 5719 5816 4572 2177
4 2222 2048 1724 1075
5 831 827 418 289
6 223 262 167 0
7 384 254 32 0
8 2 2 0 0
9 61 91 0 0
10 59 0 0 0
Total(Ambiguous) 28138 27911 25590 20914
Avg # Senses 1.56 1.54 1.45 1.33
Avg Desc Len 3.71 2.79 1.97 1
Table 1: The number of MeSH senses for N1 when truncated
to different levels of MeSH. Original refers to the actual (non-
truncated) MeSH descriptor. Avg # Senses is the average num-
ber of senses computed for all first nouns in the collection. Avg
Desc Len is the average description length; the value for level 1
is less than 2 and for level 2 is less that 3, because some nouns
are always mapped to higher levels (for example, cell is always
mapped to A11).
5.5 Multiple Occurrences of Semantic Relations
Because we determine the possible relations in a data-
driven manner, the question arises of how often does the
same semantic relation occur for different category pairs.
To determine the answer, we could (i) look at all the CPs,
give a name to the relations and ?merge? the CPs that
have the same relationships; or (ii) draw a sample of NC
examples for a given relation, look at the CPs for those
examples and verify that all the NCs for those CPs are
indeed in the same relationship.
We may not be able to determine the total number of
relations, or how often they repeat across different CPs,
until we examine the full spectrum of CPs. However, we
did a preliminary analysis to attempt to find relation repe-
tition across category pairs. As one example, we hypoth-
esized a relation afflicted by and verified that it applies
to all the CPs of the form (Disease C, Patients M01.643),
e.g.: anorexia (C23) patients, cancer (C04) survivor, in-
fluenza (C02) patients. This relation also applies to some
of the F category (Psychiatry), as in delirium (F03) pa-
tients, anxiety (F01) patient.
It becomes a judgement call whether to also include
NCs such as eye (A01) patient, gallbladder (A03) pa-
tients, and more generally, all the (Anatomy, Patients)
pairs. The question is, is ?afflicted-by (unspecified) Dis-
ease in Anatomy Part? equivalent to ?afflicted by Dis-
ease?? The answer depends on one?s theory of rela-
tional semantics. Another quandary is illustrated by the
NCs adolescent cancer, child tumors, adult dementia (in
which adolescent, child and adult are Age Groups) and
the heads are Diseases. Should these fall under the af-
flicted by relation, given the references to entire groups?
6 Related Work
6.1 Noun Compound Relation Assignment
Several approaches have been proposed for empirical
noun compound interpretation. Lauer & Dras (1994)
point out that there are three components to the prob-
lem: identification of the compound from within the text,
syntactic analysis of the compound (left versus right as-
sociation), and the interpretation of the underlying se-
mantics. Several researchers have tackled the syntactic
analysis (Lauer, 1995), (Pustejovsky et al, 1993), (Liber-
man and Church, 1992), usually using a variation of the
idea of finding the subconstituents elsewhere in the cor-
pus and using those to predict how the larger compounds
are structured.
We are interested in the third task, interpretation of the
underlying semantics. Most related work relies on hand-
written rules of one kind or another. Finin (1980) exam-
ines the problem of noun compound interpretation in de-
tail, and constructs a complex set of rules. Vanderwende
(1994) uses a sophisticated system to extract semantic in-
formation automatically from an on-line dictionary, and
then manipulates a set of hand-written rules with hand-
assigned weights to create an interpretation. Rindflesch
et al (2000) use hand-coded rule-based systems to ex-
tract the factual assertions from biomedical text. Lapata
(2000) classifies nominalizations according to whether
the modifier is the subject or the object of the underly-
ing verb expressed by the head noun.
Barker & Szpakowicz (1998) describe noun com-
pounds as triplets of information: the first constituent, the
second constituent, and a marker that can indicate a num-
ber of syntactic clues. Relations are initially assigned by
hand, and then new ones are classified based on their sim-
ilarity to previously classified NCs. However, similarity
at the lexical level means only that the same word occurs;
no generalization over lexical items is made. The algo-
rithm is assessed in terms of how much it speeds up the
hand-labeling of relations. Barrett et al (2001) have a
somewhat similar approach, using WordNet and creating
heuristics about how to classify a new NC given its simi-
larity to one that has already been seen.
In previous work (Rosario and Hearst, 2001), we
demonstrated the utility of using a lexical hierarchy for
assigning relations to two-word noun compounds. We
use machine learning algorithms and MeSH to success-
fully generalize from training instances, achieving about
60% accuracy on an 18-way classification problem us-
ing a very small training set. That approach is bottom
up and requires good coverage in the training set; the ap-
proach described in this paper is top-down, characteriz-
ing the lexical hierarchies explicitly rather than implicitly
through machine learning algorithms.
6.2 Using Lexical Hierarchies
Many approaches attempt to automatically assign seman-
tic roles (such as case roles) by computing semantic
similarity measures across a large lexical hierarchy; pri-
marily using WordNet (Fellbaum, 1998). Budanitsky &
Hirst (2001) provide a comparative analysis of such algo-
rithms.
However, it is uncommon to simply use the hier-
archy directly for generalization purposes. Many re-
searchers have noted that WordNet?s words are classi-
fied into senses that are too fine-grained for standard NLP
tasks. For example, Buitelaar (1997) notes that the noun
book is assigned to seven different senses, including fact
and section, subdivision. Thus most users of WordNet
must contend with the sense disambiguation issue in or-
der to use the lexicon.
The most closely related use of a lexical hierarchy
that we know of is that of Li & Abe (1998), which uses
an information-theoretic measure to make a cut through
the top levels of the noun portion of WordNet. This is
then used to determine acceptable classes for verb argu-
ment structure, and for the prepositional phrase attach-
ment problem and is found to perform as well as or better
than existing algorithms.
Additionally, Boggess et al (1991) ?tag? veterinary
text using a small set of semantic labels, assigned in much
the same way a parser works, and describe this in the
context of prepositional phrase attachment.
7 Conclusions and Future Work
We have provided evidence that the upper levels of a lex-
ical hierarchy can be used to accurately classify the re-
lations that hold between two-word technical noun com-
pounds. In this paper we focus on biomedical terms us-
ing the biomedical lexical ontology MeSH. It may be that
such technical, domain-specific terminology is better be-
haved than NCs drawn from more general text; we will
have to assess the technique in other domains to fully as-
sess its applicability.
Several issues need to be explored further. First, we
need to ensure that this technique works across the full
spectrum of the lexical hierarchy. We have demonstrated
the likely usefulness of such an exercise, but all of our
analysis was done by hand. It may be useful enough to
simply complete the job manually; however, it would be
preferable to automate some or all of the analysis. There
are several ways to go about this. One approach would be
to use existing statistical similarity measures (Budanitsky
and Hirst, 2001) to attempt to identify which subhierar-
chies are homogeneous. Another approach would be to
see if, after analyzing more CPs, those categories found
to be heterogeneous should be assumed to be heteroge-
neous across classifications, and similarly for those that
seem to be homogeneous.
The second major issue to address is how to extend the
technique to multi-word noun compounds. We will need
to distinguish between NCs such as acute migraine treat-
ment and oral migraine treatment, and handle the case
when the relation must first be found between the left-
most words. Thus additional steps will be needed; one
approach is to compute statistics to indicate likelihood of
the various CPs.
Finding noun compound relations is part of our larger
effort to investigate what we call statistical semantic pars-
ing (as in (Burton and Brown, 1979); see Grishman
(1986) for a nice overview). For example, we would like
to be able to interpret titles in terms of semantic relations,
for example, transforming Congenital anomalies of tra-
cheobronchial branching patterns into a form that allows
questions to be answered such as ?What kinds of irreg-
ularities can occur in lung structure?? We hope that by
compositional application of relations to entities, such in-
ferences will be possible.
Acknowledgements We thank Kaichi Sung for her
work on the relation labeling, Steve Maiorano for his
support of this research, and the anonymous reviewers
for their comments on the paper. This research was sup-
ported by a grant from ARDA.
References
Christopher Ahlberg and Ben Shneiderman. 1994. Vi-
sual information seeking: Tight coupling of dynamic
query filters with starfield displays. In Proceedings of
ACM CHI?94, pages 313?317.
Ken Barker and Stan Szpakowicz. 1998. Semi-automatic
recognition of noun modifier relationships. In Pro-
ceedings of COLING-ACL ?98, Montreal, Canada.
Leslie Barrett, Anthony R. Davis, and Bonnie J. Dorr.
2001. Interpreting noun-noun compounds using word-
net. In Proceedings of 2001 CICLing Conference,
Mexico City.
Lois Boggess, Rajeev Agarwal, and Ron Davis. 1991.
Disambiguation of prepositional phrases in automati-
cally labelled technical text. In AAAI 91, pages 155?
159.
Alexander Budanitsky and Graeme Hirst. 2001. Seman-
tic distance in wordnet: an experimental, application-
oriented evaluation of five measures. In Proceedings
of the NAACL 2001 Workshop on WordNet and Other
Lexical Resources, Pittsburgh, PA, June.
P. Buitelaar. 1997. A lexicon for underspecified semantic
tagging. In Proceedings of ANLP 97, SIGLEX Work-
shop, Washington DC.
R. R. Burton and J. S. Brown. 1979. Toward a natural-
language capability for computer-assisted instruction.
In H. O?Neil, editor, Procedures for Instructional Sys-
tems Development, pages 273?313. Academic Press,
New York.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Timothy W. Finin. 1980. The Semantic Interpretation of
Compound Nominals. Ph.d. dissertation, University of
Illinois, Urbana, Illinois.
Ralph Grishman. 1986. Computational Linguistics.
Cambridge University Press, Cambridge.
Maria Lapata. 2000. The automatic interpretation of
nominalizations. In Proceedings of AAAI.
Mark Lauer and Mark Dras. 1994. A probabilistic model
of compound nouns. In Proceedings of the 7th Aus-
tralian Joint Conference on AI.
Mark Lauer. 1995. Corpus statistics meet the compound
noun. In Proceedings of the 33rd Meeting of the Asso-
ciation for Computational Linguistics, June.
Hang Li and Naoki Abe. 1998. Generalizing case frames
using a thesaurus and the MDI principle. Computa-
tional Linguistics, 24(2):217?244.
Mark Y. Liberman and Kenneth W. Church. 1992. Text
analysis and word pronunciation in text-to-speech syn-
thesis. In Sadaoki Furui and Man Mohan Sondhi, ed-
itors, Advances in Speech Signal Processing, pages
791?831. Marcel Dekker, Inc.
James Pustejovsky, Sabine Bergler, and Peter Anick.
1993. Lexical semantic techniques for corpus analy-
sis. Computational Linguistics, 19(2).
James Pustejovsky, editor. 1995. The Generative Lexi-
con. MIT Press.
Thomas Rindflesch, Lorraine Tanabe, John N. Weinstein,
and Lawrence Hunter. 2000. Extraction of drugs,
genes and relations from the biomedical literature. Pa-
cific Symposium on Biocomputing, 5(5).
Barbara Rosario and Marti A. Hearst. 2001. Classify-
ing the semantic relations in noun compounds via a
domain-specific lexical hierarchy. In Proceedings of
the 2001 Conference on Empirical Methods in Natural
Language Processing. ACL.
Lucy Vanderwende. 1994. Algorithm for automatic
interpretation of noun sequences. In Proceedings of
COLING-94, pages 782?788.
Putting FrameNet Data into the ISO Linguistic Annotation Framework
Srinivas Narayanan Miriam R. L. Petruck Collin F. Baker Charles J. Fillmore
 
snarayan, miriamp, collinb, fillmore@icsi.berkeley.edu
International Computer Science Institute
1947 Center St., Berkeley, California
1 Abstract
This paper describes FrameNet (Lowe et al, 1997; Baker
et al, 1998; Fillmore et al, 2002), an online lexical re-
source for English based on the principles of frame se-
mantics (Fillmore, 1977a; Fillmore, 1982; Fillmore and
Atkins, 1992), and considers the FrameNet database in
reference to the proposed ISO model for linguistic an-
notation of language resources (ISO TC37 SC4 )(ISO,
2002; Ide and Romary, 2001b). We provide a data cat-
egory specification for frame semantics and FrameNet
annotations in an RDF-based language. More specifi-
cally, we provide a DAML+OIL markup for lexical units,
defined as a relation between a lemma and a semantic
frame, and frame-to-frame relations, namely Inheritance
and Subframes. The paper includes simple examples of
FrameNet annotated sentences in an XML/RDF format
that references the project-specific data category specifi-
cation.
2 Frame Semantics and the FrameNet
Project
FrameNet?s goal is to provide, for a significant portion
of the vocabulary of contemporary English, a body of
semantically and syntactically annotated sentences from
which reliable information can be reported on the va-
lences or combinatorial possibilities of each item in-
cluded.
A semantic frame is a script-like structure of infer-
ences, which are linked to the meanings of linguistic
units (lexical items). Each frame identifies a set of
frame elements (FEs), which are frame-specific seman-
tic roles (participants, props, phases of a state of affairs).
Our description of each lexical item identifies the frames
which underlie a given meaning and the ways in which
the FEs are realized in structures headed by the word.
The FrameNet database documents the range of semantic
and syntactic combinatory possibilities (valences) of each
word in each of its senses, through manual annotation of
example sentences and automatic summarization of the
resulting annotations. FrameNet I focused on governors,
meaning that for the most part, annotation was done in re-
spect to verbs; in FrameNet II, we have been annotating
in respect to governed words as well.1 This paper will
explain the theory behind FrameNet, briefly discuss the
annotation process, and then describe how the FrameNet
data can be represented in RDF, using DAML+OIL, so
that researchers on the semantic web can use the data.
2.0.1 Frame Semantic Background
In Frame Semantics (Fillmore, 1976; Fillmore, 1977b;
Fillmore and Atkins, 1992; Petruck, 1996), a linguistic
unit, in our case, a word (in just one of its senses), evokes
a particular frame. An ?evoked? frame is the structure of
knowledge required for the understanding of a given lexi-
cal or phrasal item. The frames in question can be simple
? small static scenes or states of affairs, simple patterns
of contrast, relations between entities and the roles they
serve ? or possibly quite complex event types that pro-
vide the background for words that profile one or more of
their phases or participants.
For example, the word bartender evokes a scene of ser-
vice in a setting where alcoholic beverages are consumed,
and profiles the person whose role is to prepare and serve
these beverages. In a sentence like The bartender asked
for my ID, it is the individual who occupies that role that
we understand as making the request, and the request for
identification is understood against the set of assumptions
and practices of that frame.
1The National Science Foundation has provided funding for
FrameNet through two grants, IRI #9618838 ?Tools for Lex-
icon Building? (1997-2000, PI Charles Fillmore, Co-PI Dan
Jurafsky) and ITS/HCI #0086132 ?FrameNet++: An On-Line
Lexical Semantic Resource and its Application to Speech and
Language Technology? (PI Charles Fillmore, Co-PIs Dan Ju-
rafsky, Srini Narayanan, and Mark Gawron). We refer to the
two phases of the project as FrameNet I and FrameNet II.
2.0.2 Replacement: An Example Frame
A schematic description of the REPLACEMENT frame
will include an AGENT effecting a change in the relation-
ship between a PLACE (which can be a role, a function,
a location, a job, a status, etc.) and a THEME. For ex-
ample, in the sentence Sal replaced his cap on his bald
head, Sal fills the role of AGENT, his cap instantiates
the FE THEME, and on his bald head is the PLACE. The
words defined in terms of this frame include exchange.v,
interchange.v, replace.v, replacement.n, substitute.v, sub-
stitution.n, succeed.v, supplant.v, swap.v, switch.v, and
trade.v.
The REPLACEMENT frame involves states of affairs
and transitions between them such that other situations
are covered: an ?old theme?, which we refer to as OLD,
starts out at the PLACE and ends up not at the PLACE,
while a ?new theme?, which we call NEW, starts out not
at the PLACE and ends up at the PLACE (as in Factory
owners replaced workers by machines).
Syntactically, the role of AGENT can be expressed by
a simple NP (e.g. Margot switched her gaze to the floor,
a conjoined NP (e.g. Margot and her admirer exchanged
glances), or two separate constituents, an NP and a PP
(e.g. Margot exchanged glances with her admirer). Sim-
ilarly, PLACE may be expressed as one PP or two. Com-
pare Ginny switched the phone between hands and Ginny
switched the phone from one hand to the other. And, if
OLD and NEW are of the same type, they can be expressed
as a single FE (e.g. The photographer switched lenses).
2.1 The FrameNet Process
Using attested instances of contemporary English,
FrameNet documents the manner in which frame ele-
ments (for given words in given meanings) are grammat-
ically instantiated in English sentences and organizes and
exhibits the results of such findings in a systematic way.
For example, in causative uses of the words, an expres-
sion about replacing NP with NP takes the direct object
as the OLD and the oblique object as the NEW (e.g. Nancy
replaced her desktop computer with a laptop), whereas
substituting NP for NP does it the other way around (e.g.
Nancy substituted a laptop for her desktop computer).
A commitment to basing such generalizations on attes-
tations from a large corpus, however, has revealed that in
both UK and US English, the verb substitute also partic-
ipates in the valence pattern found with replace, i.e. we
find examples of substituting the OLD with the NEW (e.g.
Nancy subsitituted a laptop with her desktop computer).
In their daily work, FrameNet staff members record the
variety of combinatorial patterns found in the corpus for
each word in the FrameNet lexicon, present the results
as the valences of the words, create software capable of
deriving from the annotations as much other information
as possible about the words, and add manually only that
information which cannot ? or cannot easily ? be derived
automatically from the corpus or from the set of anno-
tated examples.
2.2 Frame-to-Frame Relations
The FrameNet database records information about sev-
eral different kinds of semantic relations, consisting
mostly of frame-to-frame relations which indicate seman-
tic relationships between collections of concepts. The
two that we consider here are Inheritance and Sub-
frames.
2.2.1 Inheritance
Frame Inheritance is a relationship by which a sin-
gle frame can be seen as an elaboration of one or more
other parent frames, with bindings between the inherited
semantic roles. In such cases, all of the frame elements,
subframes, and semantic types of the parent have equal
or more specific correspondents in the child frame. Con-
sider for example, the CHANGE OF LEADERSHIP frame,
which characterizes the appointment of a new leader or
removal from office of an old one, and whose FEs in-
clude: SELECTOR, the being or entity that brings about
the change in leadership (in the case of a democratic pro-
cess, the electorate); OLD LEADER, the person removed
from office; OLD ORDER, the political order that existed
before the change; NEW LEADER, the person appointed
to office; and ROLE, the position occupied by the new or
old leader. Some of the words that belong to this frame
describe the successful removal from office of a leader
(e.g. overthrow, oust, depose), others only the attempt
(e.g. uprising, rebellion). This frame inherits from the
more abstract REPLACEMENT frame described above,
with the following FEs further specified in the child: OLD
and NEW are narrowed to humans beings or political en-
tities, i.e. OLD LEADER and NEW LEADER, respectively;
and PLACE is an (abstract) position of political power, i.e.
ROLE.
2.2.2 Subframes
The other type of relation between frames which is cur-
rently represented in the FN database is between a com-
plex frame and several simpler frames which constitute
it. We call this relationship Subframes. In such cases,
frame elements of the complex frame may be identified
(mapped) to the frame elements of the subparts, although
not all frame elements of one need have any relation to
the other. Also, the ordering and other temporal rela-
tionships of the subframes can be specified using binary
precedence relations. To illustrate, consider the complex
CRIMINAL PROCESS frame, defined as follows: A Sus-
pect is arrested by an AUTHORITY on certain CHARGES,
then is arraigned as a DEFENDANT. If at any time the
DEFENDANT pleads guilty, then the DEFENDANT is sen-
tenced, otherwise the DEFENDANT first goes to trial. If
the VERDICT after the trial is guilty, then the DEFEN-
DANT is sentenced. In the end, the DEFENDANT is ei-
ther released or is given a SENTENCE by a JUDGE at
the sentencing. For each step in the process, there is a
separate frame in the database, including ARREST, AR-
RAIGNMENT, TRIAL, SENTENCING, and so on. Each of
these frames is related to the CRIMINAL PROCESS frame
via the SubFrame relation in the frame editor. Moreover,
subframes (of the same complex frame) are related to
each other through their ordering.
We have recognized the need to deal with other types
of relations among frames, and, so far, have identified
two, SeeAlso, and Using. Currently, many Using rela-
tions are indicated in the FrameNet database.
2.3 The FrameNet Product
The FrameNet database contains descriptions of more
than 7,000 lexical units based on more than 130,000 an-
notated sentences. This information is available for a
wide range of natural language processing applications,
including question answering, machine translation, and
information extraction.
The FN database can be seen both as a dictionary and
a thesaurus. As a dictionary, each lexical unit (LU)
(lemma in a given sense) is provided with (1) the name of
its frame, (2) a definition, (3) a valence description which
summarizes the attested combinatorial possibilities, and
(4) access to annotated examples. The FN database can
also be seen as a thesaurus, associating groups of lexical
units in frames and associating frames with each other
(see below). The FrameNet database differs from existing
lexical resources in the specificity of the frames and se-
mantic roles it defines, the information it provides about
relations between frames, and the degree of detail pro-
vided on the possible syntactic realizations of semantic
roles for each LU.
While Ide, et al, (2002)(Ide et al, 2002) offers a rep-
resentation scheme for dictionaries and other lexical data,
the kind of information in the FrameNet database is not
expressed in the same level of depth in any existing print
dictionary or computational lexical resource. For in-
stance, while WordNet describes semantic relations be-
tween words, it does not recognize conceptual schemas,
i.e. frames, that mediate in these relations, and therefore
does not have the means to link arguments of predicating
words with the semantic roles they express. FrameNet
also differs from WordNet in showing semantic relations
across parts of speech, and in providing contextual infor-
mation enriched with semantics (beyond the ?Someone
s something? format of WordNet argument-structure
representations). Thus, the complex relational structure
inherent in the FrameNet frame element and frame-to-
frame relations exercises and potentially extends the ISO
TC37 SC4 standard (ISO, 2002). The rest of this paper
describes our encoding of the FrameNet database in an
RDF-based environment.
3 A Data Category Specification for Frame
Semantics in RDF
The World Wide Web (WWW) contains a large amount
of information which is expanding at a rapid rate. Most
of that information is currently being represented using
the Hypertext Markup Language (HTML), which is de-
signed to allow web developers to display information in
a way that is accessible to humans for viewing via web
browsers. While HTML allows us to visualize the infor-
mation on the web, it doesn?t provide much capability to
describe the information in ways that facilitate the use
of software programs to find or interpret it. The World
Wide Web Consortium (W3C) has developed the Exten-
sible Markup Language (XML) which allows informa-
tion to be more accurately described using tags. As an
example, the word crawl on a web site might represent
an offline search process (as in web crawling) or an ex-
position of a type of animate motion. The use of XML to
provide metadata markup, such as for crawl, makes the
meaning of the word unambiguous. However, XML has
a limited capability to describe the relationships (schemas
or ontologies) with respect to objects. The use of ontolo-
gies provides a very powerful way to describe objects and
their relationships to other objects. The DAML language
was developed as an extension to XML and the Resource
Description Framework (RDF). The latest release of the
language (DAML+OIL) (http://www.daml.org) provides
a rich set of constructs with which to create ontologies
and to markup information so that it is machine readable
and understandable.
Framenet-1 has been translated into DAML+OIL.
We developed an automatic translator from FrameNet
to DAML+OIL which is being updated to reflect
FrameNet2 data. With periodic updates as the FrameNet
data increases, we expect it to become useful for var-
ious applications on the Semantic Web. DAML+OIL
is written in RDF (http://www.w3.org/TR/daml+oil-
walkthru/#RDF1), i.e., DAML+OIL markup is
a specific kind of RDF markup. RDF, in turn,
is written in XML, using XML Namespaces
(http://www.w3.org/TR/daml+oil-walkthru/#XMLNS),
and URIs. Thus, our framenet declaration begins with an
RDF start tag including several namespace declarations
of the form:
<?Xml version=?1.0? encoding=?ISO-8859-1??>
<!DOCTYPE uridef[
<!ENTITY rdf
"http://www.w3.org/1999/02/22-rdf-syntax-ns">
<!ENTITY rdfs
"http://www.w3.org/2000/01/rdf-schema">
<!ENTITY xsd
"http://www.w3.org/2000/10/XMLSchema">
<!ENTITY daml
"http://www.daml.org/2001/03/daml+oil">
<!ENTITY daml
"http://www.daml.org/services/daml-s/0.9/process">
]>
<rdf:RDF
xmlns:rdf = "&rdf;#"
xmlns:rdfs = "&rdfs;#"
xmlns:xsd = "&xsd;#"
xmlns:daml = "&daml;#"
xmlns:CYC = "&cyc;#"
>
So in this document, the rdf: prefix should be un-
derstood as referring to things drawn from the names-
pace called http://www.w3.org/1999/02/22-rdf-syntax-
ns#. This is a conventional RDF declaration appear-
ing verbatim at the beginning of almost every rdf doc-
ument. The second and third declarations make simi-
lar statements about the RDF Schema and XML Schema
datatype namespaces. The fourth declaration says that in
this document, elements prefixed with daml: should be
understood as referring to things drawn from the names-
pace called http://www.w3.org/2001/03/daml+oil#. This
again is a conventional DAML+OIL declaration. We
use the XML entity model to use shortcuts with re-
ferring to the URIs.2 The other DAML+OIL on-
tologies used in the FrameNet description include
the DAML-S (http://www.daml.org/services) service
ontologies, the OpenCYC DAML ontology (http://
www.cyc.com/2002/04/08/cyc.daml), and the SRI time
ontology (http:// www.ai.sri.com/ daml/ontologies/ sri-
basic/1-0/Time.daml) which is currently being re-
vised with the new DAML+OIL time ontology effort.
http://www.icsi.berkeley.edu/ snarayan/frame-2.daml has
a complete namespace and imported ontology list.
The most general object of interest is a frame. We de-
fine the FRAME class as a daml:class We then define a
bunch of bookkeeping properties on the FRAME class. An
example of the name property is shown below.
<daml:Class rdf:ID="Frame">
<rdfs:comment> The most general class </rdfs:comment>
</daml:Class>
<daml:ObjectProperty rdf:ID="Name">
<rdfs:domain rdf:resource="#Frame"/>
<rdfs:range rdf:resource="&rdf-schema;#Literal"/>
</daml:ObjectProperty>
In FrameNet, the basic relation between a word
(Lemma) and a frame is the Lexical Unit (LU). The do-
main of the Lexical Unit is a Lemma or word and its range
is a Frame. An LU is defined in DAML as a property.
<daml:ObjectProperty rdf:ID= "LU">
<rdfs:domain rdf:resource="#Lexeme"/>
<rdfs:range rdf:resource="#Frame"/>
</daml:ObjectProperty>
2Note that all URIs are globally scoped, so without this the
entire path has to be specified.
Roles are relations defined on frames ranging over the
specific type of the filler. We use daml:objectProperty
to define the roles of a frame. The domain of a role is
its frame. We leave the type of the filler unrestricted at
this level, allowing specific roles to specialize this fur-
ther. Note that we use the daml:samePropertyAs relation
to specify synonyms. The fragment below specifies that
Frame Element, Role, and FE are synonyms.
<daml:ObjectProperty rdf:ID= "role">
<rdfs:domain rdf:resource="#Frame"/>
<rdfs:range rdf:resource="&daml;#Thing"/>
</daml:ObjectProperty>
<daml:ObjectProperty rdf:ID="frameElement">
<daml:samePropertyAs rdf:resource="#role"/>
</daml:ObjectProperty>
<daml:ObjectProperty rdf:ID="FE">
<daml:samePropertyAs rdf:resource="#role"/>
</daml:ObjectProperty>
We use the various constructs daml:maxCardinality,
daml:minCardinality, daml:cardinalityQ, etc. from
DAML to specify cardinality restrictions on the fillers of
a role property. The markup fragment below shows the
specification of a single valued role.
<daml:ObjectProperty rdf:ID= "singleValuedRole">
<rdfs:domain rdf:resource="#Frame"/>
<rdfs:range>
<rdfs:subClassOf>
<daml:Restriction daml:maxCardinality="1">
<daml:onProperty rdf:resource="#Role"/>
</daml:Restriction>
</rdfs:subClassOf>
</daml:Class>
The relation between frames (such as ARREST) and
CRIMINAL PROCESS is often captured by a set of bind-
ings between frame elements (such as the arrested person
is the same individual as the person charged who is the
same individual as the defendant in a criminal process).
To capture such bindings, we introduce a special relation
called bindingRelation whose domain and range are roles
(either from the same or different frames).
<daml:ObjectProperty rdf:ID="bindingRelation">
<rdfs:domain rdf:resource="#Role"/>
<rdfs:range rdf:resource="#Role"/>
</daml:ObjectProperty>
By far the most important binding relation is the iden-
tification of roles (i.e. they refer to the same value (ob-
ject)). This can be specified through the relation identify
which is a subProperty of bindingRelation. Note that in
order to do this, we have to extend the DAML+OIL lan-
guage which does not allow properties to be defined over
other properties. We use the DAML-S ontology primitive
daml-s:sameValuesAs to specify the identify relations.
<daml:ObjectProperty rdf:ID="identify">
<rdfs:subPropertyOf rdf:resource="#bindingRelation"/>
<rdfs:domain rdf:resource="#Role"/>
<daml-s:sameValuesAs rdf:resource="#rdfs:range"/>
</daml:ObjectProperty>
In FrameNet, a frame may inherit (A ISA B) from
other frames or be composed of a set of subframes
(which are frames themselves). For instance, the frame
CRIMINAL PROCESS has subframes that correspond to
various stages (ARREST, ARRAIGNMENT, CHARGE,
etc.). Subframe relations are represented using the
daml:objectProperty.3
<daml:ObjectProperty rdf:ID="subFrameOf">
<rdfs:domain rdf:resource="#Frame"/>
<rdfs:range rdf:resource="#Frame"/>
</daml:ObjectProperty>
A central relation between subframes is one of tem-
poral ordering. We use precedes (in the sense of imme-
diately precedes)) to encode this relation between sub-
frames.
<daml:ObjectProperty rdf:ID="precedes">
<rdfs:domain rdf:resource="#subFrame"/>
<rdfs:range rdf:resource="#subFrame"/>
</daml:ObjectProperty>
We can define a property temporalOrdering that is the
transitive version of precedes.
daml:TransitiveProperty rdf:ID="TemporalOrdering">
<rdfs:label>TemporalOrdering</rdfs:label>
</daml:TransitiveProperty>
Note that the temporalOrdering property only says it is
transitive, not that it is a transitive version of precedes.
DAML+OIL does not currently allow us to express this
relation. (see http://www.daml.org/2001/03/daml+oil-
walkthru#properties).
Frame Elements may also inherit from each other. We
use the rdfs:subPropertyOf to specify this dependences.
For example, the following markup in DAML+OIL spec-
ifies that the role (Frame Element) MOTHER inherits from
the role (Frame Element) PARENT. Note we can add fur-
ther restrictions to the new role. For instance, we may
want to restrict the filler of the MOTHER to be female (as
opposed to animal for PARENT).
<daml:ObjectProperty rdf:ID="mother">
<rdfs:subPropertyOf rdf:resource="#parent"/>
<rdfs:range rdf:resource="#Female"/>
</daml:ObjectProperty>
With these basic frame primitives defined, we are ready
to look at an example using the Criminal Process frames.
3.1 An Example: The Criminal Process Frame
The basic frame is the CRIMINAL PROCESS Frame. It is
a type of background frame. CP is used as a shorthand
for this frame.
3The subFrameOf relation has a direct translation to a richer
semantic representation that is able to model and reason about
complex processes (such as buying, selling, reserving tickets)
and services on the web. While the details of the representation
are outside the scope of the this paper, the interested reader can
look at (Narayanan and McIlraith, 2002) for an exposition of
the markup language and its operational semantics.
<daml:Class rdf:ID="CriminalProcess">
<rdfs:subClassOf rdf:resource="#Frame"/>
</daml:Class>
<daml:Class rdf:ID="CP">
<daml:sameClassAs rdf:resource="#CriminalProcess"/>
</daml:Class>
The CRIMINALPROCESS frame has a set of associated
roles. These roles include that of COURT, DEFENDANT,
PROSECUTION, DEFENSE, JURY, and CHARGES. Each
of these roles may have a filler with a specific seman-
tic type restriction. FrameNet does not specify the world
knowledge and ontology required to reason about Frame
Element filler types. We believe that one of the possible
advantages in encoding FrameNet data in DAML+OIL is
that as and when ontologies become available on the web
(uch as OpenCYC), we can link to them for this purpose.
In the example fragment below we use the CYC Court-
Judicial collection to specify the type of the COURT and
the CYC Lawyer definition to specify the type restric-
tion on the frame element DEFENSE. For illustrative pur-
poses, the DAML+OIL markup below shows the use of
a different ontology (from CYC) to restrict the defendant
to be of type PERSON as defined in the example ontol-
ogy. This restriction uses the DAML+OIL example from
http://www.daml.org/2001/03/daml+oil-ex)
<daml:ObjectProperty rdf:ID="court">
<rdfs:subPropertyOf rdf:resource="#FE"/>
<rdfs:domain rdf:resource="#CriminalProcess"/>
<rdfs:range rdf:resource="&CYC;#Court-Judicial"/>
</daml:ObjectProperty>
<daml:ObjectProperty rdf:ID="defense">
<rdfs:subPropertyOf rdf:resource="#FE"/>
<rdfs:domain rdf:resource="#CriminalProcess"/>
<rdfs:range rdf:resource="&CYC;#Lawyer"/>
</daml:ObjectProperty>
<daml:ObjectProperty rdf:ID="defendant">
<rdfs:subPropertyOf rdf:resource="#FE"/>
<rdfs:domain rdf:resource="#CriminalProcess"/>
<rdfs:range rdf:resource="&daml-ex;Person"/>
</daml:ObjectProperty>
The set of binding relations involves a set of role
identification statements that specify that a role of a
frame (subframe) has the same value (bound to the
same object) as the role of a subframe (frame). We
could specify these constraints either a) as anonymous
subclass restrictions on the criminal process class (see
http://www.daml.org/2001/03/daml+oil-ex for examples)
or b) we could name each individual constraint (and
thus obtain a handle onto that property). We chose the
later method in our DAML+OIL encoding of FrameNet
to allow users/programs to query any specific con-
straint (or modify it). Note also that the use of the
dotting notation (A.b) to specify paths through sim-
ple and complex frames and is not fully supported
in DAML+OIL (see http://www.daml.org/services/daml-
s/2001/10/rationale.html and also (Narayanan and McIl-
raith, 2002) for more info).
<daml:ObjectProperty rdf:ID="prosecutionConstraint">
<rdfs:subPropertyOf rdf:resource="#identify"/>
<rdfs:domain rdf:resource="#CP.prosecution"/>
<rdfs:range rdf:resource="#Trial.prosecution"/>
</daml:ObjectProperty>
<daml:ObjectProperty rdf:ID="defendantConstraint">
<rdfs:subPropertyOf rdf:resource="#identify"/>
<rdfs:domain rdf:resource="#CP.defendant"/>
<rdfs:range rdf:resource="#Arrest.suspect"/>
</daml:ObjectProperty>
Subframes of the CRIMINALPROCESS frame are de-
fined by their type (LexicalFrame or a Background-
Frame). For example, ARREST and ARRAIGNMENT
are Lexical Frames while TRIAL is a BackgroundFrame
(all are subframes of CRIMINALPROCESS. We sub-
type the subFrameOf property to specify the individ-
ual subframe relations (shown below for the relation sub-
frameOf(Criminal Process, Arraignment)).
<daml:Class rdf:ID="Arrest">
<rdfs:comment> A subframe </rdfs:comment>
<rdfs:subClassOf rdf:resource="#LexicalFrame"/>
</daml:Class>
<daml:Class rdf:ID="Arraignment">
<rdfs:comment> A subframe </rdfs:comment>
<rdfs:subClassOf rdf:resource="#LexicalFrame"/>
</daml:Class>
<daml:Class rdf:ID="Trial">
<rdfs:comment> A subframe </rdfs:comment>
<rdfs:subClassOf rdf:resource="#BackgroundFrame"/>
</daml:Class>
<daml:ObjectProperty rdf:ID="arraignSubFrame">
<rdfs:subPropertyOf rdf:resource="#subFrameOf"/>
<rdfs:domain rdf:resource="#CP"/>
<rdfs:range rdf:resource="#Arraignment"/>
</daml:ObjectProperty>
To specify the the relation precedes(Arrest, Arraign-
ment) we restrict the property precedes within (the do-
main of) the ARREST frame to have as one of its range
values the frame (class) ARRAIGNMENT. This is done
using the property restriction feature with DAML+OIL
as follows.
<daml:Class rdf:about="#Arrest">
<rdfs:subClassOf>
<daml:Restriction>
<daml:onProperty rdf:resource="#precedes"/>
<daml:hasClass rdf:resource="#Arraignment"/>
</daml:Restriction>
</rdfs:subClassOf>
</daml:Class>
With this markup of the ontology, we can create anno-
tation instances for examples with targets that belong to
the CRIMINALPROCESS (or its associated) frames.
At the current stage, we have converted all of
FrameNet 1 data (annotations and frame descriptions)
to DAML+OIL. The translator has also been updated to
handle the more complex semantic relations (both frame
and frame element based) in FrameNet 2. We plan to
release both the XML and the RDF-based DAML+OIL
versions of all FrameNet 2 releases.
4 Examples of Annotated Sentences
4.1 Basic Annotation of Verb Arguments and
Complements as Triplets
Consider the following sentence, which is annotated for
the target nab, a verb in the ARREST frame; the frame
elements represented are the arresting AUTHORITIES, the
SUSPECT and the TIME when the event took place:
[ Authorities Police] nabbed [ Suspect the
man], who was out on licence from prison,
[ Time when he returned home].
The phrase who was out on licence from prison pro-
vides additional information about the SUSPECT, but it is
not syntactically an argument or complement of the tar-
get verb nab, nor semantically an element of the ARREST
frame, so it is not annotated.
How do we intend to represent this in XML conform-
ing to the proposed standards? The header of the file will
refer to the FrameNet Data Category specification dis-
cussed in the last section, but hereafter we will omit the
domain name space specifications and use a more human-
readable style of XML. The conversion to the full ISO
style should be straightforward.
1 <?xml version="1.0" encoding="UTF-8"?>
2 [DOCTYPE definitions like those shown in
the preceding section go here ]
3 <lexunit-annotation name="nab" frame="Arrest" pos="V">
4 <definition>COD: catch (someone) doing something
wrong. </definition>
5 <subcorpus name="V-001-all">
The entity <lexunit-annotation>, which com-
prises the rest of the file includes attributes giving the
name of the lexical unit (nab), the name of the frame
(ARREST), and the part of speech of the lemma (verb).
The first included element is a definition of the lemma
within the frame, seen on line 4.
The entities contained within the lexunit-annotation
are called subcorpora; each represents a particular syn-
tactic pattern, combination of collocates, etc. In the case
of nab, there are so few instances of the word that we
have lumped them all into one subcorpus as indicated by
the subcorpus name ?all? on line 5. It might seem logi-
cal that the entities within the subcorpus should be sen-
tences, but in fact, we recognize the possibility that one
sentence might be annotated several times, for several tar-
gets. There might even be several instances of the same
target lemma in the same sentence in the same frame
(e.g. The FBI nabbed Jones in NYC, while the Moun-
ties nabbed Smith in Toronto), each with its own set of
FEs. Therefore, the next smaller entity is the annotation
set (line 6).
The annotation set4, shown below, consists of the
<sentence>, which contains only the <text> of the
sentence, and a set of layers, each consisting of a set of
labels. Each label has attributes start and end, giving the
stating and ending position in the text to which it is ap-
plied. This sentence is typical of the basic FrameNet an-
notation style, in that there are three main layers, one for
frame elements (?FE?, line 8), one for the phrase type
(PT) of each FE (line 22), and one for the grammatical
function (GF) of each FE (line 15). In each case, there
are three coextensive labels; thus the word Police, in text
positions 0-5 expresses the FE AUTHORITIES (line 10),
has the phrase type ?NP? (line 24) and is the subject of the
verb nab, which we refer to as external argument ?Ext?
(line 17). The other two frame elements are shown by
similar triplets, SUSPECT-NP-Obj and TIME-Swh-Comp,
the latter meaning a complement of the verb consisting of
a clause (S-node) introduced by a WH-relative.
6 <annotationSet status="MANUAL">
7 <layers>
8 <layer name="FE">
9 <labels>
10 <label name="Authorities" start="0"
end="5" />
11 <label name="Suspect" start="14" end="20" />
12 <label name="Time" start="61" end="81" />
13 </labels>
14 </layer>
15 <layer name="GF">
16 <labels>
17 <label name="Ext" start="0" end="5" />
18 <label name="Obj" start="14" end="20" />
19 <label name="Comp" start="61" end="81" />
20 </labels>
21 </layer>
22 <layer name="PT">
23 <labels>
24 <label name="NP" start="0" end="5" />
25 <label name="NP" start="14" end="20" />
26 <label name="Swh" start="61" end="81" />
27 </labels>
28 </layer>
29 <layer name="Sent" />
30 <layer name="Other" />
31 <layer name="Target">
32 <labels>
33 <label name="Target" start="7" end="12" />
34 </labels>
35 </layer>
36 <layer name="Verb" />
37 </layers>
38 <sentence aPos="34400709">
39 <text>Police nabbed the man, who was out on
licence from prison, when he returned home.
</text>
40 </sentence>
41 </annotationSet>
4The XML shown here is somewhat simplified from the rep-
resentation being distributed by FrameNet, which includes at-
tributes on each label giving an ID number, the date and time
of creation, the name of the annotator, etc. In these examples,
we use several XML tags without defining them. Without go-
ing into unnecessary detail, we note here that they can be de-
fined in the DCS and the Dialect specification as described in
(Ide and Romary, 2001a). We are also using a condensed no-
tation with multiple attributes on entities for reasons of space,
although proper RDF requires that they be split out.
There are three other layers shown in the example,
none of which contain labels, called Sentence, Verb, and
Other. The layer Target contains the single label Target;
the fact that nab is the target word is indicated in the same
way as the information about FEs.
Note that this XML format is ?standoff? annotation in
the sense that the labels refer to text locations by charac-
ter positions (allowing any number of labels on various
layers, overlapping labels, etc.), but that the text and the
annotations appear in the same document. This is con-
trary to the general sense of the ISO standard, which uses
indirect pointers to an entirely separate document con-
taining the primary data. The indirect approach has cer-
tain advantages, and where the primary data is audio or
video, is virtually unavoidable. But in the case of the
current FrameNet data, where the annotations all apply
to individual sentences, there seem to be some advan-
tages, at least for human readers, of having the text of
the sentence and the annotation contained within a fairly
low-level XML entity, allowing the reader to glance back
and forth between them.5 In formulating standards for
linguistic annotation, it might be wise to take these ad-
vantages and disadvantages into consideration; perhaps
either situation might be allowable under the standard.
4.2 Other Types of Annotation
As the basic unit of annotation is the label, which can be
applied to anything ranging from a single character to an
entire sentence, and there are no a priori constraints on
labels overlapping, a great variety of information can be
represented in this way. We will not be able to demon-
strate all the possibilities here, but we will give a some
representative examples.
In FrameNet, event nouns are annotated in the same
frame (and hence with the same FEs) as the correspond-
ing verbs; the main differences are that the syntactic pat-
terns for the FEs of nouns are more varied, and (with
rare exceptions), no FEs of nouns are required to be ex-
pressed. Consider the noun arrest, also in the ARREST
frame, in the sentence:
Two witnesses have come forward with infor-
mation that could lead to [ Suspect the killer ?s]
arrest .
In this case the SUSPECT is expressed as a possessive (the
killer?s; it could equally well have been in a PP headed by
of (the arrest of the killer).
<annotationSet status="MANUAL">
5The location of the sentences in the original corpora is still
recoverable from the aPos attribute, which gives the absolute
position from which the sentence was abstracted. The name of
the corpus is given in another attribute which has been omitted
in the example.
<layers>
<layer name="FE">
<labels>
<label name="Suspect" start="68" end="80" />
</labels>
</layer>
<layer name="GF">
<labels>
<label name="Gen" start="68" end="80" />
</labels>
</layer>
<layer name="PT">
<labels>
<label name="Poss" start="68" end="80" />
</labels>
</layer>
<layer name="Sent" />
<layer name="Other" />
<layer name="Target">
<labels>
<label name="Target" start="82" end="87" />
</labels>
</layer>
<layer name="Noun" />
</layers>
<sentence aPos="102536044">
<text>Two witnesses have come forward with
information that could lead to the killer?s arrest.
</text>
</sentence>
</annotationSet>
In addition to marking the FE SUSPECT from ARREST,
we could also annotate the same sentence again in the
CAUSATION frame with the target lead, which would cre-
ate an annotation set listed under the the LU lead to:
Two witnesses have come forward with [ Cause
information that] could lead [ Effect to the
killer?s arrest].
The same sentence would be annotated in two differ-
ent frames, and the semantics of the two frames could
(in theory) be combined compositionally to get the se-
mantics of the phrase information that could lead to the
killer?s arrest. Similar processes of annotating in multi-
ple frames with targets come forward (and possibly wit-
ness as well) should yield a full semantics of the sentence.
6
References
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In ACL, ed-
itor, COLING-ACL ?98: Proceedings of the Confer-
ence, held at the University of Montre?al, pages 86?90.
Association for Computational Linguistics.
Charles J. Fillmore and B.T.S. Atkins. 1992. Towards
a frame-based lexicon: The semantics of RISK and its
6The qualification ?in theory? is included because the
present phase of the FrameNet project is not undertaking to im-
plement a system of semantic composition; we are just trying to
annotate enough examples in enough frames to provide a basis
for semantic parsing (in this context, automatic FE recognition)
and composition of annotation sets.
neighbors. In Adrienne Lehrer and Eva Feder Kittay,
editors, Frames, Fields and Contrasts. Lawrence Erl-
baum Associates.
Charles J. Fillmore, Collin F. Baker, and Hiroaki Sato.
2002. The framenet database and software tools. In
Proceedings of the Third International Conference on
Languag Resources and Evaluation, volume IV, Las
Palmas. LREC.
Charles J. Fillmore. 1976. Frame semantics and the na-
ture of language. In Annals of the New York Academy
of Sciences: Conference on the Origin and Develop-
ment of Language and Speech, volume 280, pages 20?
32.
Charles J. Fillmore. 1977a. The need for a frame seman-
tics in linguistics. In Hans Karlgren, editor, Statistical
Methods in Linguistics. Scriptor.
Charles J. Fillmore. 1977b. Scenes-and-frames seman-
tics. In Antonio Zampolli, editor, Linguistic Struc-
tures Processing, number 59 in Fundamental Studies
in Computer Science. North Holland Publishing.
Charles J. Fillmore. 1982. Frame semantics. In Lin-
guistics in the Morning Calm, pages 111?137. Hanshin
Publishing Co., Seoul, South Korea.
Nancy Ide and Laurent Romary. 2001a. A common
framework for syntactic annotation. In Proceedings of
ACL 2001, pages 298?305, Toulouse. ACL.
Nancy Ide and Laurent Romary. 2001b. Standards for
language resources. In Proceedings of the IRCS Work-
shop on Linguistic Databases, pages 141?149, Phi-
lapdelphia. IRCS.
Nancy Ide, Adam Kilgarriff, and Laurent Romary. 2002.
A formal model of dictionary structure and con-
tent. In Proceedings of Euralex 2000, pages 113?126,
Stuttgart. EURALEX.
ISO. 2002. Iso tc 37-4 n029: Linguistic annotation
framework. Internet. http:// www.tc37sc4.org/ docu-
ment.htm.
John B. Lowe, Collin F. Baker, and Charles J. Fillmore.
1997. A frame-semantic approach to semantic anno-
tation. In Marc Light, editor, Tagging Text with Lexi-
cal Semantics: Why, What and How? Special Interest
Group on the Lexicon, Association for Computational
Linguistics.
Srini Narayanan and Sheila McIlraith. 2002. Simula-
tion, verification and automated composition of web
services. In Proc. Eleventh International World Wide
Web Conference (WWW2002), May.
Miriam R. L. Petruck. 1996. Frame semantics. In
Jef Verschueren, Jan-Ola stman, Jan Blommaert, and
Chris Bulcaen, editors, Handbook of Pragmatics. John
Benjamins.
Encounters with Language
Charles J. Fillmore?
University of California, Berkeley, and
International Computer Science Institute
First of all, I am overwhelmed and humbled by the honor the ACL Executive Committee
has shown me, an honor that should be shared by the colleagues and students I?ve been
lucky enough to have around me this past decade-and-a-half while I?ve been engaged
in the FrameNet Project at the International Computer Science Institute in Berkeley.
I?ve been asked to say something about the evolution of the ideas behind the work
with which I?ve been associated, so my remarks will be a bit more autobiographical than
I might like. I?d like to comment on my changing views of what language is like, and
how the facts of language can be represented. As I am sure the ACL Executive Com-
mittee knows, I have never been a direct participant in efforts in language engineering,
but I have been a witness to, a neighbor of, and an indirect participant in some parts of
it, and I have been pleased to learn that some of the resources my colleagues and I are
building have been found by some researchers to be useful.
I offer a record of my encounters with language and my changing views of what
one ought to believe about language and how one might represent its properties. In
the course of the narrative I will take note of changes I have observed over the past
seven decades or so in both technical and conceptual tools in linguistics and language
engineering. One theme in this essay is how these tools, and the representations they
support, obscure or reveal the properties of language and therefore affect what one
might believe about language. The time frame my life occupies has presented many
opportunities to ponder this complex relationship.
1. Earliest Encounters
This story begins in the 1930s and 1940?s, in St. Paul, Minnesota. There was nothing
linguistically exotic about growing up there, except perhaps the Norwegian-accented
English of some of my mother?s older relatives. But during much of my childhood I
was convinced that I personally had difficulties with language: The symptomwas that I
could never think of anything to say. I was tongue-tied. I now suspect that it was mainly
a problem of the shyness and awkwardness that goes along with growing up confused,
and not an actual matter of language pathology. Nevertheless, it led me into my earliest
attempt to work with language data.
At around age 14, I presentedmy problem to a librarian in the St. Paul Public library,
and she foundme a book called 5000 Useful Phrases forWriters and Speakers. Amemorable
? International Computer Science Institute, 1947 Center St. Ste. 600, Berkeley, CA 94611, USA. E-mail:
fillmore@icsi.berkeley.edu. I am especially indebted to the three directors of the International Computer
Science Institute during the life of the FrameNet Project (Jerome Feldman, Nelson Morgan, and Roberto
Pieraccini) and to Collin Baker, FrameNet Project Manager, for keeping the project alive during the recent
years of my relative inactivity; to Mary Catherine O?Connor and Russell Lee Goldman for important
assistance in the preparation of the present document; and to Lily Wong Fillmore, videographer, editor,
and censor for the broadcast version of the acceptance speech.
? 2012 Association for Computational Linguistics
Computational Linguistics Volume 38, Number 4
example was ?With a haggard lift of the upper lip . . . ? I took the book home, cut sheets
of typewriter paper into eight pieces to make file slips, chose phrases I thought I should
memorize, and copied them onto these slips. I held them together with rubber bands,
and I kept them in a secret place in my room. Thus supported with the early 1940s
technologies of paper, scissors, pencil, and rubber bands, my earliest theory of language
began to develop: Linguistic competence is having access to a large repertory of ready-made
things to say.
I added to the collection over the years, as I came upon clever or wise expressions,
and consulted a selection of them every night, scheming to create situations in which I
could use them, in speaking or writing. In later years I held on to the suspicion that
much of ordinary conversation in real life involves calling on remembered phrases
rather than creating novel expressions from rules. Much later I learned that in many
Eastern European countries influenced by the Moscow School, the divisions of the field
of Linguistics were Phonology, Morphology, Lexicology, Phraseology, and Syntax. The
study of phraseological units?phraseologisms?was seen as central, not peripheral, to
linguistic inquiry.
My first exposure to the actual field of Linguistics came a year later, around age
15, when a missionary lady on leave, living on my block in St. Paul, gave me a copy of
Eugene Nida?s little book, Linguistic Interludes (Nida 1947). The text of this book takes
the form of conversations in a college campus co-op between a clever and wise linguist
and a caricatured collection of innocent and unsuspecting students and colleagues,
among them a classicist who strongly defended the logical perfection of the classical
languages Greek and Latin.
This book succeeded in conveying simply many of the things that linguists believe:
 Relevant linguistic generalizations are based on speech, not writing.
 Almost all concepts of ?correct grammar? are inventions, with no basis in
the history of the language.
 There may be primitive communities, but there are no primitive languages.
The minor protagonists in the conversation contested each of these principles, and the
linguist hero, from his vast knowledge of the most exotic of the world?s languages,
kept showing them how wrong they were. I liked the idea of knowing things that most
people, including college professors, had wrong opinions about. I also liked the idea of
being able to help them change their wrong opinions, so I decided to study Linguistics.
2. Formal Studies Begin
Before long I was enrolled in a fairly small linguistics program at the University of
Minnesota. I could live at home, take a streetcar to Minneapolis for classes, and take
another streetcar to Montgomery Wards in St. Paul, where I wrapped venetian blinds to
support my studies.
In those days there were no linguistics textbooks in the modern sense; we studied
two books titled Language?one by Edward Sapir (1921) and the other by Leonard
Bloomfield (1933)?and we read grammars and treatises. I took two years of Arabic. I
supplemented my training in linguistic methods through Summer Linguistic Institutes
put on by the Linguistic Society of America, one inMichigan and one in Berkeley, where
I learned about Thai, Sanskrit, and Navajo with Mary Haas, Franklin Edgerton, and
Harry Hoijer.
702
Fillmore Computational Linguistics
2.1 First Research Experience: Concordance-Building
One of my professors at the University Minnesota was building concordances of some
of theminor Late Latin texts, and he permitted the students in his class to workwith him
on these projects. For the advanced students this was a chance to get valuable hands-on
research experience; for the less advanced students it was an opportunity to get ?extra
credit.?
This was in a sense my first exposure to corpus-based linguistics. For any given
document, the professor would pass on the text to that year?s students. This ?first
generation? of students copied word tokens onto separate index cards, together with
each word?s ?parse? in the classical sense, and its location in the document.
Generation 2?the students in the next year?s class?alphabetized these cards and
typed up the concordances. Generation 3, in which I participated, took this same stack
of cards and reverse-alphabetized them, so they could be used for research on suffixes.
(Personal note: alphabetizing words from right to left is stressful at first, but you get
used to it.) So with the tools of pre-cut index cards, a pencil, and a typewriter, we
students constructed a concordance?we physically experienced that concordance.
So you can imagine my surprise when, thirty-some years later, I came upon UNIX
commands like sort, sort -r, and grep. I don?t remember if I actually wept. And
these were nothing compared to the marvels I experienced later still, with key-word-in-
context extraction, lemmatizers, morphological parsers, part-of-speech tagging, sorting
by right and left context, and the full toolkit of corpus processing tools that exist today.
In those days it took a lot of patience and physical effort to build a concordance.
But it also took a lot of patience and physical effort to use a concordance. A printed
concordance to the Shakespeare corpus was a vast index in which, for each word,
you could find every line it occurred in, and you learned where that line appeared in
Shakespeare?s writings. You would then go to the actual physical source text, look it
up, and see it in its context. For example, if, when studying the phrasal verb take upon I
want to find the full context of This way will I take upon me to wash your liver I only need
to open up As You Like It to Act 3, Scene 2, and hunt for it there. Compare that to the
fully-searchable Shakespeare app you can use while sitting on a bus holding your iPad.
3. Encounters Beyond College
President Truman?s Displaced Persons Act of 1948?1950 brought thousands of Eastern
European immigrants to Minnesota, enabling me to find work more satisfying than
venetian-blind-wrapping. I began to teach English to Russians, Poles, Ukrainians, and
Latvians. Depending onwhich of the daughters of the families inmy classes I was trying
to impress, I was motivated to learn something about Slavic and Baltic languages.
Soonmy student deferment would run out, and I had to decide between waiting for
the draft (two years) or enlisting (three years). A persuasive recruiting officer promised
me one year at the Army Language School inMonterey, CA, (now the Defense Language
Institute) for my first year. Shortly after that, my head got shaved and I was suddenly
a buck private. No one had any record of an offer to spend a year in sunny California
learning Polish. I was not allowed to examine my file.
So I took the U.S. Army Russian Language Proficiency Test instead. The questions
were in spoken Russian, played on a record player, and the answers were multiple
choice in English. In those days the art of designing guessproof multiple choice tests
had not yet been perfected. There was kind of a student sport to see howwell you could
do in choosing answers without looking at the questions (you could usually at least get
703
Computational Linguistics Volume 38, Number 4
a passing score); then you?d go back and read the questions to correct the choices that
weren?t obvious.
Although I didn?t fully understand any of the questions, my score came out as ?high
fluent? based in large part on acquired test-taking skills. After basic training, I was sent
to Arlington, VA, for a few months in radio training, after which I was assigned to
Kyoto, Japan, to a small field station of the Army Security Agency. My duty: ?listening
to Ivan.? The Ivans I listened to on short wave radio never had anything interesting to
say: They were Soviet Air Force men reading numbers, which I was supposed to write
down. Three days of the day shift, three days evening shift, three days night shift, three
days off. I quickly acquired an uncanny ability to detect Russian numbers against noise
and static. They were, of course, coded messages.
My job was to write the numbers down on the most modern typewriter of the day,
a model that had separate keys for zero and one! (The ordinary office typewriter at that
time had separate keys for only the numbers 2 through 9, since lower-case L could be
used for 1 and upper-case O could be used for zero.) For this work I needed a very
restricted vocabulary: the Russian long and short versions of the numbers 1?9,1 plus a
single version of zero, and the word for ?mistake.? If I had been permitted to say what
I was doing I would have said I was in cryptanalysis, but of course actually I was only
copying down the numbers I heard. Somebody smart, thousands of miles away, was
figuring out what they meant.
The limited demands on my time and intellect allowed me to wander around in
Kyoto, with notebooks and dictionaries, trying to learn something about Japanese. The
linguistic methods I had learned back home stopped at morphology, the structure of
words. I hadn?t had any training in ways of representing the structure of a sentence,
but I worked out a do-it-yourself style of sentence diagrams, for both Japanese and
English, and I was fascinated when I found the occasional sentence in Japanese which
could be translated into English word by word backwards, going from the end to the
beginning.
When it was time to be discharged, I believed?wrongly?that I was close to mas-
tering the language, and I wanted to stay another year or two, because I knew I couldn?t
afford to come back to Japan on my own. I managed, with the help of Senator Hubert
Humphrey, to be the first Army soldier to get a local discharge in Japan. As a civilian
there, I supported myself by teaching English. With two other visiting Americans I was
permitted to work at Kyoto University with the endlessly kind and patient Professor
Endo Yoshimoto ( ).
Professor Endo was the author of the main school grammar of Japanese and one
of the founders of an organization favoring Romanized spelling for Japanese. With his
help, my fellow students and I stumbled through old texts and became acquainted with
the categories and terminology of the Japanese grammatical tradition.
One of the themes weaving through this essay is the reality that it is not possible to
represent?in a writing system, in a parse, or in a grammar?every aspect of a language
worth noticing. My study of Japanese confronted me with the realization that for any
given representation system, it?s important to understand what it represents, and what
is missing. The Japanese kana syllabary presented me with an early experience of this.
The pronunciation of Japanese words is represented by the symbols of a syllabary, but
unfortunately the components of complex words in this language, in particular the
inflected verbs, are not segmented at syllable boundaries.
1 The long form numbers were presumably more distinct in a noisy background.
704
Fillmore Computational Linguistics
Some verbs have consonant-final stems followed by vowel-initial suffixes, but this
fact is not apparent in the written language. In the examples in Table 1, the verb stem
means ?move? and it ends in a consonant, /k/. The suffixes all begin with vowels, but
the red kana characters do not reveal the boundary between verb and suffix.
It struck me that the written form of a language should not prevent one from
discovering its boundaries. I later learned that in 1946 the American linguist Bernard
Bloch had published a ground-breaking description of Japanese verbmorphology based
on a phonemic transcription (collected and republished as Bloch [1970]) , allowing the
regularities in the system to become apparent.
Everyone knows that English spelling is a poor representation for English pronun-
ciation, but it?s also true that it is a fairly good representation for recognizing derivation-
ally related words. Consider the second syllable in the three words compete, competitive,
competition. If we had to write these words with different letters for the different vowels,
we?d be missing something.
Yet of course some important generalizations about English can?t be captured in
the analysis of written English alone. Numerous phonological generalizations require a
reduction to phonetic features of various kinds, but there are also grammatical general-
izations that are hiding from us because of things like (1)whose (not who?s), (2) another
(not an other), and the problems that text-to-speech researchers have to face related to the
pronunciation of large numbers and indications of currency, like the dollar sign. In post-
war Japan, the fact that the kana writing system obscured morphological boundaries
merely meant that linguists would use phonemic transcriptions. But as technology
has advanced beyond cards and typewriters, supporting efforts such as text-to-speech
and automatic speech recognition, we can see that written language obscurations (and
affordances) are ubiquitous.
4. Graduate Studies: Phonetics and Phonology
While living in Japan I had been keeping track of linguistics goings-on back home, and
had heard that one of the best graduate programs for linguistics was at the University of
Michigan in Ann Arbor. So when I finally came back to the States, that?s where I went.
There was a movement in linguistics in those days toward making linguistics more
?scientific? by designing so-called discovery procedures for linguistic analysis and I
wanted to participate in that work. The basic textbooks in beginning linguistics classes
at Michigan typically provided step-by-step procedures for going from data to units,
so this movement was well-supported there. Kenneth Pike?s Phonemics book had the
sub-title: A technique for reducing language to writing (Pike 1947).
I had noticed that there were alternative phonemic analyses for both English and
Japanese, analyses that resulted in different actual numbers of consonants and vowels.
If there?s no consistent way to do phonemic analysis, how can we compare different
languages with each other, or be confident in answering a simple question like, ?how
Table 1
Japanese kana and the obscuration of morpheme boundaries.
ugok-u move (plain form)
ugok-imasu move (polite form)
ugok-anai does not move
ugok-eru can move
705
Computational Linguistics Volume 38, Number 4
many vowels does this language have?? I resolved to help design the correct discovery
procedure for phonemic analysis, founded on the distribution of phonetic primes. For
that purpose I studied phonetics in the linguistics department and in the communica-
tion sciences program: practical phonetics for field linguistics, acoustic phonetics, and
physiological phonetics in the laboratory.
During those years I worked part-time on a Russian?English Machine Translation
(MT) project with Andreas Koutsoudas and met many MT researchers. I participated
in a memorable interview with Yehoshua Bar-Hillel (some of you will remember the
outcome of the nationwide tour that included this visit). I also worked with speech
researcher Gordon Peterson and mathematician Frank Harary on automatic discovery
procedures for phonemic analysis, a project that was eventually abandoned.
The speech lab was visited once by a group of engineers who proposed devising
automatic speech recognition by detecting the acoustic properties of individual phones
and mapping these to phonemes, and pairing phoneme sequences with English words.
Ilse Lehiste put a damper on their enthusiasm by asking them to try to consistently
distinguish acoustic traces of the two phonemically different English words, ?you? and
?ill.? They couldn?t do this (Figure 1). The properties of the representational system
for individual phones would not allow them to get to the second step in their plan.
This was obviously before anybody thought of large-vocabulary recognizers based on
Hidden Markov Models or statistics-based guesses derived from language models.
Figure 1
Unrevealing spectrograms: you and ill, spoken by Keith Johnson.
706
Fillmore Computational Linguistics
5. On to Syntax
Eventually it became necessary to take on syntax. At Michigan, sentences were spoken
of as having a horizontal (syntagmatic) and a vertical (paradigmatic) dimension. In its
horizontal aspect, a sentence could be seen as a sequence of positions. In its vertical
aspect, each position could be associated with a set of potential occupants of that
position.
In the English Department at Michigan, Charles Fries was constructing a grammar
of English that was liberated from traditional notions of nouns and verbs and adjectives,
counting on purely distributional facts to discover the relevant word classes. In the
Linguistics Department, Kenneth Pike was elaborating an extremely ambitious view
of language in which, at every level of structure, one could speak of linear sequences of
positions, labeled roles naming the functions served by the occupants of these positions,
and defined sets of the potential occupants (Pike?s preliminary manuscripts appeared
in the 1950s and were eventually published as Pike [1967]). Slots, roles, and fillers?it
was all very procedural.
In the midst of all this, something big happened, and suddenly everything changed.
I was among the first in Ann Arbor to read Syntactic Structures (Chomsky 1957). I
became an instant convert, and I gave up all ideas of procedural linguistics. The new
view was something like this:
 The grammar of sentences is more than a set of linear structures separately
learned.
 Sentences are generated by hierarchically organized phrase-defining rules.
 Regularities in the grammar are evidence for rules in the minds of the
speakers.
 The existence of a variety of sentence types is accounted for in terms of the
application of rules that move things within, add them to, or delete them
from, initial representations.
 There is no procedural way to learn how language is structured; the
linguist?s job is to figure out what rules reside in the minds of speakers.
 Therefore, linguistics is theory construction.
The Chomskyan view flourished; universities that didn?t have linguistics programs
wanted one. After I finished my degree I joined William S.-Y. Wang in the brand new
program at The Ohio State University in Columbus. During my decade at Ohio State I
was completely committed to the new paradigm. Robert Lees, Chomsky?s first student,
visited Ohio State for a time, and I spent lots of time talking to him, working on
questions of rule ordering and conjunction. While discussing things with him, I wrote a
paper on ?embedding rules in a transformational grammar? that was the first statement
of the transformational cycle (Fillmore 1963).
The view represented in Chomsky?s Aspects of the Theory of Syntax (Chomsky
1965), with its sharp separation of deep structure and surface structure, became the
mainstream, and I worked within it faithfully, participating eagerly in efforts to com-
bine all the rules the young syntacticians had been writing into a single coherent
grammar of English, an effort heavily supported, for some reason, by the U.S. Air
Force. During this period I felt I knew what to do, and I believed that I understood
707
Computational Linguistics Volume 38, Number 4
everything that everybody else in the framework was doing. That feeling didn?t last
very long.
At one point I did a seminar in which a small group of students and I worked our
way through Lucien Tesnie`re?s E?le?ments de Syntaxe Structurale (Tesnie`re 1959), without
necessarily understanding everything in it, and I became aware of a different way
of organizing and representing linguistic facts. Anyone who looks closely at syntax
knows that it becomes clear very quickly that you can never represent everything
about a sentence in a single diagram. Tesnie`re, my first exposure to what evolved
later on into dependency grammar, made me aware of the impossibility of displaying
simultaneously the functional relations connecting the words in the sentence, the left-
to-right sequence of words as the sentence is spoken, and the grouping of words into
phonologically integrated phrases.
As an extreme example of the kinds of information a Tesnie`re-style dependency tree
could contain, I offer you his analysis of a complex sentence from the Latin of Cicero.
I?m certain many of you will remember this from your high school studies. Est enim in
manibus laudatio quam cum legimus quem philosophum non contemnimus? (?There is in our
hands an oration, which when we read (it), which philosopher do we not despise??) It
has roughly the same structure as Here?s a sentence, while reading which, who wouldn?t get
confused? Figure 2 presents the diagram, but I?ll only point out the connections assigned
to one word in it, the relative pronoun quam.
Instead of having lines pointing to a single token of the word, Tesnie`re breaks the
word quam into two pieces connected by the broken line at the bottom. The word agrees
with laudatio in gender and number and that connection is indicated by the upper
broken line; it is the marker of the relative clause headed by contemnimus, as shown in
the horizontal structure it is hanging from, and it is the direct object of legimus, bottom
Figure 2
A Tesnie`re-style dependency tree.
708
Fillmore Computational Linguistics
right. This diagram shows more than simple dependency relations, and uses various
ingenious tricks and decorations to smuggle in other kinds of facts. The word-to-word
connections are shown, but it?s really clear that a system for projecting from such a
diagram to a linear string of words spread into phonologically separable phrases has to
be incredibly complex.
The fact that dependency diagrams do not show the linear organization of the con-
stituent words was presented by me as a representational problem, but in fact Tesnie`re
uses precisely this separation to propose a typology of languages according to whether
they tend to order dependents before heads or heads before dependents, and whether
within each language these tendencies vary within different kinds of constructions. In
a centripetal language the dependents precede the head, in a centrifugal language the
head precedes the dependents. There are extreme and moderated varieties of each of
these in his scheme.
Tesnie`re also described a number of conjoined structures in French for which he
used the terminology of embryological mistakes, one kind being monsters that have
one head and more than one tail. In general these correspond to Verb Gapping in our
terms (John likes apples and Mary oranges). Another kind of embryological mistake has
more than one head and a single tail, like Right Node Raising (John likes and Mary detests
anchovies), and the most monstrous of all are capital H-shaped monsters with two heads
and two tails, like the kinds of sentences Paul Kay and Mary Catherine O?Connor and
I played with in a paper (Fillmore, Kay, and O?Connor 1988) on ?let alne? (I wouldn?t
touch, let alne eat, shrimp, let alne squid). I think these phenomena have more to do
with sequencing patterns than with dependency relations, but I found it interesting that
Tesnie`re delighted in exploring these kinds of structural complexities. (My sensitivity
to tone in French prose isn?t good enough to know whether in these descriptions of
syntactic monsters Tesnie`re was having fun. I?m not helped in that uncertainty by
photographs I?ve seen of the man.)
I ended up favoring phrase structure representations, partly because dependency
representations have no easyway to identify a predicate or verb phrase (VP) constituent,
and I?d like to believe that the VP can in general be treated as naming a familiar
category (eating meat, parking a car, being breakable, etc.). But I mainly preferred
phrase-structural representations because they offer more material upon which to as-
sign intonational contours.
6. What About Meaning?
When linguists turned to the predicate calculus as a representation for sentence mean-
ing, many were interested mainly in quantification and negation, where it?s possible to
show how complex logical structures can be formulated in ways that pay no attention
to the actual meanings of the words that name either the predicates or the arguments. I,
however, was specifically interested in the inner structure of the predicates themselves.
So I encountered a representational problem when working with the notation that was
common at the time.
When working on meaning, linguists often used prefix notation, allowing the
ordered list of symbols following the name of the predicate to stand for the ?-arity??
the number of arguments?of the particular predicate. Thus P(a) could represent an
adjective like hungry or a verb like vanish; P(a,b), relating two things to each other,
could stand for an adjective like different or a verb like love; and P(a,b,c) with three
arguments could stand for an adjective like intermediate or a verb like give, show, or
709
Computational Linguistics Volume 38, Number 4
tell. This notation also allowed one to represent cases in which the arguments could
themselves be predications, permitting recursion.
While working with the prefix notation I was struck by the fact that although
this representation afforded one the chance to make claims across diverse classes of
predicates, it simultaneously obscured certain information about the arguments of those
predicates?important semantic commonalities about classes of arguments.
There are centuries-old traditions by which schoolteachers explain that the subject
names the agent in an event and the object tells us what is affected by the agent?s actions,
but it?s trivially easy to find examples that show that such generalizations don?t hold.
Similarly, in a predicate?argument formula, there is nothingmeaningful about being the
first or second or third item in a list. Does it make sense to let the position in an ordered
list represent the semantic role of an argument in a predication? Consider the following
examples in which arguments are interchanged:
(1) He blamed the accident on me.?? He blamedme for the accident.
(2) He strikesme as a fool.?? I regard him as a fool.
(3) Chuck bought a car from Jerry.?? Jerry sold a car to Chuck.
In Example (1) the second and third arguments of blame are interchanged in their
grammatical realization. In Example (2), with the pair strike and regard, the first and
second arguments are interchanged. And in Example (3), with buy and sell, the first and
the third are interchanged.
I felt that there ought to be some way of recognizing the sameness of the semantic
functions of these arguments independently of where they happen to be sitting in an
ordered list. An alternative was spelled out in a rambling paper called ?The Case for
Case? published in 1968 (Fillmore 1968). It proposed a universal list of semantic role
types (?cases?). Configurations of these cases could then characterize the semantic
structures of verb and adjective meanings. In this way, lexical predicates could be
shown as differing according to the collection of cases that they required (obligatory)
or welcomed (optional).
The theory embedded in this view is that semantic relations (?deep cases?) are
directly linked to argument meanings. (So in the sentence John gave Mary a rose, John
is the Agent, Mary is the Recipient, and a rose is the transmitted Object.) Grammatical
roles (subject, object) and markings (choice of preposition, etc.) are predicted from case
configurations. (So the Agent could be the subject, the Object could be the direct object,
and the Recipient could be introduced with the preposition to.) Generalizations are
formulated in terms of specific named cases, for which a hierarchy is defined, and the
list of cases is finite and universal.
The variable ?valences? (a term from Tesnie`re) of a single verb can be explained in
terms of the cases available to it. The starting examples in this discussion were with the
verb open. Its valences correlate with the cases available to it:
(4) Agent>Instrument>Object hierarchy illustrated with V open
O = The door opened
AO = I opened the door
IO = The key opened the door
AIO = I opened the door with the key
710
Fillmore Computational Linguistics
The occupants of nuclear syntactic slots (subject and object) are determined by the
hierarchy, the rest are marked by prepositions (or in the case of arguments whose shape
is a VP or a clause, various other markers or complementizers).
There was a time when Case Grammar, so-called, was very popular, and partly
because of that I ended up in Berkeley, California, and eventually participated in the
vibrant Cognitive Science Program there. When I first arrived, I continued to work on
Case Grammar and Transformational Grammar, disappointed that the former was not
accepted as a contribution to the latter.
Gradually, the theory and representation of Case Grammar revealed a way to define
entities at a different level: Given lists of cases, it was possible to define situation types
as assemblies of these. I referred to these assemblies as case frames. With a large number
of case or semantic role names, it should be possible to define a very large number of
situation types. For example, Agent-Instrument-Object is some kind of caused change.
Object-Path-Goal is some kind of motion event, and so on:
(5) Case Frame Situation Types exemplified
 Agent, Instrument, Object: I fixed it with a screwdriver.
 Object, Path, Goal: The water flowed through the crack in the floor into
the storage room.
 Experiencer, Content: I remember the accident.
 Stimulus, Experiencer: The noise scared me.
 Stimulus, Experiencer, Content: The noise reminded me of the accident.
Various proposals emerged (by John Sowa among others) that greatly increased
the number of cases, enabling descriptions of more and more kinds of situations and
events. Researchers working with semantic roles tend to think of them as identifying
the roles of participants in the event, in the case of verbs that describe events. But this
conceptualization shed light on some problematic (and eventually revealing) cases. One
of the first to hit me involved some uses of the verb replace. Consider this sentence: Today
I finally replaced that bicycle that got stolen a year ago.
Notice that the bicycle that got stolen a year ago was not a participant in the Re-
placement event that happened today, at least not in the usual sense that is intended in
work on semantic roles or cases. The bicycle can be mentioned in the sentence, given the
grammatical requirements of the verb replace, because the bicycle was a participant in
the narrative that defines a replacement event.
This led to a conceptualization that will be familiar to readers of this journal. Instead
of defining frames in terms of assemblies of roles, what aboutmaking frames primary, and
defining roles in terms of the frames? I then started thinking that the job of lexical semantics
is to characterize frames on their own, and work out the participant structures frame
by frame.
7. Beyond Syntax and Semantics
At some point I was invited to give some lectures at Roger Schank?s Artificial Intel-
ligence lab at Yale, where I witnessed work on information retrieval in the form of
a system that automatically collected information from newspaper accounts of traffic
accidents. My impression was that the system was given texts that were known to be
711
Computational Linguistics Volume 38, Number 4
about traffic accidents, and it was already provided with a checklist of information
to look for, based ultimately on the style sheets used by reporters working on traffic
accident assignments, or, really, ultimately, on the reporting traditions of the local police
departments.
The checklist included names, ages, and addresses of drivers, passengers, and
victims; the make, model, and year of the involved vehicles; location of the accident;
directions of moving vehicles; presence of injuries or fatalities; reports from police
authorities, and so forth. The system needed to recognize capital letters, punctuation,
numbers, and a set of words like driver, passenger, victim, ambulance, street, avenue,
highway, sheriff, officer, vehicle, and so on, so that when it came upon something like
the following it would know what to do:
Walter O. Magnusson, 23, of 79 W. Walnut St., Hartland, was westbound on 28th Street
near Blossom Road in a 1998 Chevrolet pickup when he and passenger, Wilma J. Alter,
27, same address, argued. According to Sheriff Deputy Carl Voegelin, Magnusson
grabbed the steering wheel, causing the vehicle to strike a tree on the south side of the
road. Magnusson was taken by private vehicle to Hartland Community Hospital with
possible injuries. The pickup was registered to Clarence Barker of 66 Larkin Rd.,
Jarviston.
I wondered if a kind of general purpose information extraction process could be
designed in which the system didn?t know in advance what the text was about, but in
which particular words in the text would evoke their own checklist?a list of things to look
for that come with the entry for the word. The presence in a text of a word like revenge, for
example, could initiate a search for the identity of the offender, the name of the injured
party and the avenger, the punishment inflicted or intended, and so forth, a checklist
that would also be evoked by a dozen other words in the same frame. In a case like
the given text, the heading of a newspaper article such as ?Fatal Accident on Highway
17? would get things started. That is, a word could evoke a frame, and the semantic
parser?s job would be to find the elements of that frame in the text, sometimes in the
same sentence, in positions determined by the grammar of the word, and sometimes in
neighboring sentences.
The idea behind frame semantics is that speakers are aware of possibly quite com-
plex situation types, packages of connected expectations, that go by various names?
frames, schemas, scenarios, scripts, cultural narratives, memes?and the words in our
language are understood with such frames as their presupposed background. Of course
these terms are used to designate concepts developed with slightly different meanings,
and for different purposes, in Artificial Intelligence, Cognitive Psychology, and Sociol-
ogy. I use the word ?frame? promiscuously to cover all of them. In ?frame semantics,?
however, I?m particularly concerned with those that are clearly linked to items of
linguistic form: words or constructions.
8. RISK: The Frame
In 1988, at a summer school in Pisa run by the late Antonio Zampolli, I met Sue Atkins,
the lexicographer. I was teaching a course on frame semantics, and she was teaching a
course on corpus-based lexicography that included an examination of concordance lines
for the verb risk. Sue and I decided to join forces and come up with a complete frame
description of risk, based on corpus evidence, that would show how the words that
belong to this framework. The title of the first paper that resulted from this research was
?Toward a frame-based lexicon: The semantics of RISK and its neighbors.?We presented
712
Fillmore Computational Linguistics
Figure 3
HyperCard: Representational breakthrough.
the main arguments, jointly, at the 1991 meeting of the ACL in Berkeley. The paper was
published as Fillmore and Atkins (1992).
9. The Gradual Birth of FrameNet
Along with some colleagues, I decided to seek funding to build a resource that would
feature a large number of frames, along with the words that belong to those frames.
In any such funding request, the authors are challenged to represent the project in
compelling detail so as to allow reviewers to envision the possibilities. Our first attempt,
created by John B. Lowe, made use of a demo created using the new tool HyperCard
(Figure 3). Sadly, the funders were not impressed.
Of course, all of this work was carried out against the backdrop of George Miller?s
ground-breaking project, WordNet2 (Miller 1995; Fellbaum 1998). By 1992 the creators of
WordNet had demonstrated the power and utility of a searchable and open database of
English words, organized around core semantic relations such as synonymy, meronymy
and holonymy, hypernymy and hyponymy, and so on. Although WordNet was an
inspiration to us, its purposes and structure are somewhat different from those of
FrameNet.
The goal of the FrameNet project3 (Fillmore, Johnson, and Petruck 2003) was to
create a database, to be used by humans and computers, that would include a list of all
2 http://wordnet.princeton.edu.
3 http://framenet.icsi.berkeley.edu.
713
Computational Linguistics Volume 38, Number 4
COMPLIANCE
Definition: This frame concerns Acts and States of Affairs for which Protagonists
are responsible and which either follow or violate some set of rules or Norms .
Figure 4
Definition of the Compliance frame.
of the Frames that we could possibly have time to describe. Frames are the cognitive
schemata that underlie the meanings of the words associated with that Frame. The
example of the frame Compliance is given in Figure 4. It begins with a definition of
the frame in terms of Frame Elements (FEs), which are the things worth talking about
when a given frame is relevant. (There are generally three to eight FEs per frame.)
We currently have about 1,200 Frames defined and described. A fragment of the
list of Frames alphabetically surrounding Compliance runs as follows: Compatibility,
Competition, Complaining, Completeness, Compliance, Concessive....
Next, we attempt to catalogue the Lexical Units (LUs) associated with the frame.
These are words which, when encountered in a written or spoken text, may ?evoke?
the frame. Currently, our total number of Lexical Units across all 1,200 Frames is about
13,000. Example (6) lists a sample of the LUs tied to the Compliance frame.
(6) (in/out) line.n, abide.v, adhere.v, adherence.n, breach.n, breach.v, break.v,
by-pass.v, circumvent.v, compliance.n, compliant.a, comply.v, conform.v,
conformity.n, contrary.a, contravene.v, contravention.n, disobey.v, flout.v,
follow.v, honor.v, in accordance.a, keep.v, lawless.a, noncompliance.n,
obedient.a, obey.v, observance.n, observant.a, observe.v, play by the
rules.v, submit.v, transgress.v, transgression.n, violate.v, violation.n
Not all LUs are simple words. Many are phrasal words, such as take off, talk down,
work out, pick up. Some are idiomatic phrases: of course, all of a sudden. Finally, some are
products of constructions: best friends, make one?s way.
Beyond the specification of cognitive and cultural frames, and their linguistic
triggers or anchors, FrameNet analyses endeavor to catalogue the ways that Frame
Elements of a Frame are linguistically expressed, specifically in terms of syntactic
structures. For example, in the Compliance frame, what are the possible forms in which
the FEs can be expressed?
To begin to answer this question, we compile for each Frame a set of Annotations.
Each includes sentences that exemplify the Frame and its FEs, and demonstrate the
use of the relevant Lexical Units. Examples (7)?(9) illustrate how the subject of a sen-
tence can instantiate three of the FEs in the Compliance frame, given the lexical items
used.
(7) The wiring in this room is in violation of the building code.
State of Affairs
(8) You have broken the rules.
Protagonist
(9) My action was in compliance with the school?s traditions.
Act
714
Fillmore Computational Linguistics
Figure 5
Compliance frame in a network of frames.
Finally, lexical entries summarize the mappings of individual FEs, Lexical Unit by
Lexical Unit. For example, for the FE Norm within the Compliance frame, we find the
following LUs, where ?X? is the variable whose value will be the Norm for each LU:
(10) Lexical Units linked to the Frame Element Norm within Compliance
complies [with X] conforms [to X]
is in breach [of X] abides [by X]
violates [X] adheres [to X]
Note that these Lexical Units (all of which would be linked to the Frame Element
NORM in the Compliance frame) include antonyms, and thus these sets of LUs differ
from synsets. Polysemous LUs can be linked to different frames. For example, adhere
belongs not only to the Compliance frame but also to the Attaching frame.
The frames themselves are organized in a network, linked by various kinds of
relations, including inheritance, part-of, presupposes,4 and so on. Figure 5 is a glimpse
of the place held by the Compliance frame in the network.
Compliance inherits from both the Social-Behavior-Evaluation frame and the
Satisfying frame. The Satisfying frame includes satisfying desires, fulfilling ambi-
tions, meeting one?s goals, and so forth. Compliance elaborates on that by specifying
that the Norm FE is some kind of institutionalized rule or law or principle or practice,
and that the words in this frame evaluate people and their acts with reference to such
norms.
Frame-to-Frame relations also include FE-to-FE relations: For example, the Buyer
FE of Commerce-buy is the Agent FE of Transfer. Linking generalizations familiar
4 Strictly speaking, the notion of frame presupposition is captured by several relations, including ?Using?
and ?Perspective on.?
715
Computational Linguistics Volume 38, Number 4
from ?standard? thematic roles can be captured by relating smaller frames to the more
schematic ones they inherit.
The FrameNet annotation sets include not only the ?lexicographic? annotations,
but also a number of ?full-text? annotations, where all words are annotated, that is,
annotation layers are provided for each frame-relevant word. In such examples, we
frequently encounter data that force us to expand and refine FrameNet.
In most examples we can see core FEs, those that are required by the frame, as
well as peripheral FEs, those that fill out the roles traditionally described as adjuncts
of time, place, manner, and so on. But as we expand our catch to include sentences
beyond those that simply provide good examples of the Frames, we encounter FEs
that we label as extrathematic. This name is given to expressions that are syntacti-
cally governed by a frame-bearing element, but convey information that is outside
of the Frame. As Example (11) indicates, extrathematic elements frequently introduce
a new Frame, and thus are crucial for the enterprise of automatic understanding of
connected text.
(11) Types of FEs in a sentence.
The army destroyed the village yesterday in retaliation
(CORE) [target] (CORE) (PERIPHERAL) (EXTRATHEMATIC)
In our annotation work it has become necessary to notice contexts in which the
semantic head of a phrase and the syntactic head of a phrase are not identical. Because
we are interested in positioning frame-relevant words in their contexts, we have recog-
nized support verbs, support prepositions, and transparent nouns. What we find with
support verbs and prepositions is that the governed noun is the LU that evokes the
frame. In expressions like take a turn, make a decision, wreak havoc, lodge a complaint, say a
prayer, and give advice, the frame is evoked by the noun. The same can be observed with
in trouble, at risk, under arrest, under consideration, and at rest. The verb or preposition
determines the grammatical functioning, but also (in the case of the verb) features of
aspect, tone, and voice.
Transparent nouns are nouns that intervene, in a [N1 of N2] structure, between the
frame context and the frame-relevant noun. That is, in examples like wreak this KIND of
havoc, drink a DROP of vodka, divorce that JERK of a husband, it is the second (underlined)
noun that matters in our understanding of the semantic nature of the Frame Element.
These grammatical types may also be helpful in the enterprise of automatic understand-
ing of connected text.
We have noticed regularities that may be useful to expand upon for FEs: They
can have ?semantic types? associated with them, intended to say something about the
types of entities, and thus phrases, that can serve in those roles. For example, Agents,
Experiences, and Recipients are of the semantic type ?sentient.? This dimension is not
well-developed, currently, consisting mostly of categories such as artifact, container,
factive (for verbs), and so on.
The FrameNet wordlist is mostly from the ?general vocabulary? and for the most
part ignores the tens of thousands of words that either lack frames of their own or
that have specialist frames for which ordinary lexicographic inquiry cannot help. These
include artifact names, natural kinds, terrain features, and so on. For these we would
like to make progress with what we call ?Gov-X annotation?: annotating words with
respect to the frames they belong comfortably in. For example, gunwould be annotated
in sentences where it is governed by brandish, fire, shoot, load, and so forth.
716
Fillmore Computational Linguistics
10. Constructions
In recent years we have added to the FrameNet database something we call the Con-
structicon, which is a list of grammatical constructions, descriptions of their compo-
nents, and descriptions of the properties and functions of the phrases or constituents
that they license (Fillmore, Lee-Goldman, and Rhodes 2012).
Some members of the team are participants in a movement called Construction
Grammar, supporting a view of grammar as a collection of constructions, where each
construction constitutes a way of assembling the meaning of the components into a
semantic whole, not obviously predictable, by familiar principles, from the meanings of
the parts.
This collection includes special constructions like the ones that license the bigger
they come the harder they fall, or rate expressions like twenty gallons an hour, or unusual
symmetric-relation expressions like I am friends with the President. The collection is
not limited to special-purpose or idiosyncratic constructions, but also includes major
constructions with broad semantic import and cross-linguistic relevance, such as
conditional sentences, exclamations, a large variety of coordinating constructions, and
comparative constructions.
The constructions bring frames of their own, and the analysis task is to integrate
the information from the LUs embedded within their Frames with those contributed by
the constructions. The Construction is linked to a set of sentences annotated according
to the properties of the construction being analyzed. Professor Hiroaki Sato of Senshu
University in Japan has designed a temporary tool for viewing the constructional
information.
11. Conclusion
The ultimate goal is to be able to understand everything that can be known about a
word, or a sentence, or a language, or speakers? knowledge of their language. This goal
can never be achieved, but one keeps trying, piece by piece. I recently came upon, in my
notes, a program from the 1988 Pisa Institute that showed I was on a panel one evening
addressing the question ?What would a linguist like to find in the Dictionary of 2001??
I don?t remember what I said, but I think that if everything could work the way we
planned it, and if the project ever gets the funds to complete the job, the ICSI FrameNet
database of 2020 will stand a chance of being close to that ideal dictionary of 2001. I want
to thank the ACL Executive Committee again for the recognition, and the conference
participants for listening.
References
Bloch, Bernard. 1970. Bernard Bloch
on Japanese. Yale University Press,
New Haven, CT.
Bloomfield, Leonard. 1933. Language.
Henry Holt, New York.
Chomsky, Noam. 1957. Syntactic Structures.
Mouton, The Hague.
Chomsky, Noam. 1965. Aspects of the Theory of
Syntax. The MIT Press, Cambridge, MA.
Fellbaum, Christiane. 1998.WordNet:
An Electronic Lexical Database.
The MIT Press, Cambridge, MA.
Fillmore, Charles J. 1963. The position of
embedding transformations in a grammar.
Word, 18:208?231.
Fillmore, Charles J. 1968. The case for case. In
Emmond Werner Bach and Robert Thomas
Harms, editors, Universals in Linguistic
Theory, Chapter 1. Holt, Rinehart, and
Winston, New York, pages 1?88.
Fillmore, Charles J. and Beryl T. S. Atkins.
1992. Towards a frame-based organization
of the lexicon: The semantics of RISK and
its neighbors. In A. Lehrer and E. Kitay,
editors, Frames, Fields, and Contrast: New
717
Computational Linguistics Volume 38, Number 4
Essays in Semantics and Lexical Organization.
Lawrence Erlbaum Associates, Hillsdale,
NJ, pages 75?102.
Fillmore, Charles J., Christopher R.
Johnson, and Miriam R. L. Petruck.
2003. Background to Framenet.
International Journal of Lexicography,
16(3):297?333.
Fillmore, Charles J., Paul Kay, and
Mary Catherine O?Connor. 1988.
Regularity and idiomaticity in
grammatical constructions:
The case of ?let alne?. Language,
64:501?538.
Fillmore, Charles J., Russell Lee-Goldman,
and Russell Rhodes. 2012. The FrameNet
constructicon. In Ivan A. Sag and Hans
C. Boas, editors, Sign-based Construction
Grammar. CSLI, Stanford, CA.
Miller, George A. 1995. WordNet: A lexical
database for English. Communications
of the ACM, 38(11):39?41.
Nida, Eugene. 1947. Linguistic Interludes.
Summer Institute of Linguistics,
Glendale, CA.
Pike, Kenneth L. 1947. Phonemics: A
Technique for Recuding Languages to Writing.
University of Michigan Publications
Linguistics 3, Ann Arbor, MI.
Pike, Kenneth L. 1967. Language in Relation to
a Unified Theory of the Structure of Human
Behavior. Janua Linguarum, series maior,
24. Mouton, The Hague.
Sapir, Edward. 1921. Language: An
Introduction to the Study of Speech.
Harcourt, Brace and Company, New York.
Tesnie`re, L. 1959. E?le?ments de Syntaxe
Structurale. Klincksieck, Paris.
718
