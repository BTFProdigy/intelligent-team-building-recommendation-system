Compiling French-Japanese Terminologies from the Web 
 
Xavier Robitaille?, Yasuhiro Sasaki?, Masatsugu Tonoike?,  
Satoshi Sato? and Takehito Utsuro? 
?Graduate School of Informatics, 
Kyoto University 
Yoshida-Honmachi, Sakyo-ku, 
Kyoto 606-8501 Japan 
?Graduate School of Engineering, 
Nagoya University 
Furo-cho, Chikusa-ku, 
Nagoya 464-8603 Japan 
{xavier, sasaki, tonoike, utsuro}@pine.kuee.kyoto-u.ac.jp, 
ssato@nuee.nagoya-u.ac.jp 
 
Abstract 
We propose a method for compiling bi-
lingual terminologies of multi-word 
terms (MWTs) for given translation pairs 
of seed terms. Traditional methods for bi-
lingual terminology compilation exploit 
parallel texts, while the more recent ones 
have focused on comparable corpora. We 
use bilingual corpora collected from the 
web and tailor made for the seed terms. 
For each language, we extract from the 
corpus a set of MWTs pertaining to the 
seed?s semantic domain, and use a com-
positional method to align MWTs from 
both sets. We increase the coverage of 
our system by using thesauri and by ap-
plying a bootstrap method. Experimental 
results show high precision and indicate 
promising prospects for future develop-
ments.  
1 Introduction 
Bilingual terminologies have been the center of 
much interest in computational linguistics. Their 
applications in machine translation have proven 
quite effective, and this has fuelled research aim-
ing at automating terminology compilation. Early 
developments focused on their extraction from 
parallel corpora (Daille et al (1994), Fung 
(1995)), which works well but is limited by the 
scarcity of such resources. Recently, the focus 
has changed to utilizing comparable corpora, 
which are easier to obtain in many domains. 
Most of the proposed methods use the fact that 
words have comparable contexts across lan-
guages. Fung (1998) and Rapp (1999) use so 
called context vector methods to extract transla-
tions of general words. Chiao and Zweigenbaum 
(2002) and D?jean and Gaussier (2002) apply 
similar methods to technical domains. Daille and 
Morin (2005) use specialized comparable cor-
pora to extract translations of multi-word terms 
(MWTs).  
These methods output a few thousand terms 
and yield a precision of more or less 80% on the 
first 10-20 candidates. We argue for the need for 
systems that output fewer terms, but with a 
higher precision. Moreover, all the above were 
conducted on language pairs including English. 
It would be possible, albeit more difficult, to ob-
tain comparable corpora for pairs such as 
French-Japanese. We will try to remove the need 
to gather corpora beforehand altogether. To 
achieve this, we use the web as our only source 
of data. This idea is not new, and has already 
been tried by Cao and Li (2002) for base noun 
phrase translation. They use a compositional 
method to generate a set of translation candidates 
from which they select the most likely translation 
by using empirical evidence from the web.  
The method we propose takes a translation 
pair of seed terms in input. First, we collect 
MWTs semantically similar to the seed in each 
language. Then, we work out the alignments be-
tween the MWTs in both sets. Our intuition is 
that both seeds have the same related terms 
across languages, and we believe that this will 
simplify the alignment process. The alignment is 
done by generating a set of translation candidates 
using a compositional method, and by selecting 
the most probable translation from that set. It is 
very similar to Cao and Li?s, except in two re-
spects. First, the generation makes use of 
thesauri to account for lexical divergence be-
tween MWTs in the source and target language. 
Second, we validate candidate translations using 
a set of terms collected from the web, rather than 
using empirical evidence from the web as a 
whole. Our research further differs from Cao and 
Li?s in that they focus only on finding valid 
translations for given base noun phrases. We at-
tempt to both collect appropriate sets of related 
MWTs and to find their respective translations. 
The initial output of the system contains 9.6 
pairs on average, and has a precision of 92%.  
We use this high precision as a bootstrap to 
augment the set of Japanese related terms, and 
obtain a final output of 19.6 pairs on average, 
with a precision of 81%. 
2 Related Term Collection 
Given a translation pair of seed terms (sf, sj), we 
use a search engine to gather a set F of French 
terms related to sf, and a set J of Japanese terms 
related to sj. The methods applied for both lan-
guages use the framework proposed by Sato and 
Sasaki (2003), outlined in Figure 1. We proceed 
in three steps: corpus collection, automatic term 
recognition (ATR), and filtering.   
2.1 Corpus Collection 
For each language, we collect a corpus C from 
web pages by selecting passages that contain the 
seed. 
Web page collection 
In French, we use Google to find relevant web 
pages by entering the following three queries: 
?sf?, ?sf est? (sf is), and ?sf sont? (sf are). In Japa-
nese, we do the same with queries ?sj?, ?sj???, 
?sj??, ?sj????, and ?sj??, where ?? toha, 
? ha, ??? toiu, and ? no are Japanese func-
tional words that are often used for defining or 
explaining a term. We retrieve the top pages for 
each query, and parse those pages looking for 
hyperlinks whose anchor text contain the seed. If 
such links exist, we retrieve the linked pages as 
well. 
Sentence extraction 
From the retrieved web pages, we remove html 
tags and other noise. Then, we keep only prop-
erly structured sentences containing the seed, as 
well as the preceding and following sentences ? 
that is, we use a window of three sentences 
around the seed. 
2.2 Automatic Term Recognition 
The next step is to extract candidate related terms 
from the corpus. Because the sentences compos-
ing the corpus are related to the seed, the same 
should be true for the terms they contain. The 
process of extracting terms is highly language 
dependent. 
French ATR 
We use the C-value method (Frantzi and 
Ananiadou (2003)), which extracts compound 
terms and ranks them according to their term-
hood. It consists of a linguistic part, followed by 
a statistical part. 
The linguistic part consists in applying a lin-
guistic filter to constrain the structure of terms 
extracted. We base our filter on a morphosyntac-
tic pattern for the French language proposed by 
Daille et al It defines the structure of multi-word 
units (MWUs) that are likely to be terms. Al-
though their work focused on MWUs limited to 
two content words (nouns, adjectives, verbs or 
adverbs), we extend our filter to MWUs of 
greater length. The pattern is defined as follows: 
( ) ( )( )+NumNounDetPrepAdjNumNoun ?  
The statistical part measures the termhood of 
each compound that matches the linguistic pat-
tern. It is given by the C-value:  
( )
( )
( )
( )
( )
??
??
?
??
??
?
?
??
?
?
?
??
?
?
?
?=?
?
?
otherwise
T
b
aaa
nestednotisaif
aa
a
a
Tb a
P
f
f)f(log
,
flog
valueC
2
2
 
where a is the candidate string, f(a) is its fre-
quency of occurrence in all the web pages re-
trieved, Ta is the set of extracted candidate terms 
that contain a, and P(Ta) is the number of these 
candidate terms. 
The nature of our variable length pattern is 
such that if a long compound matches the pat-
tern, all the shorter compounds it includes also 
match. For example, consider the N-Prep-N-
 
 
 
related term sets 
(F, J)
 the  Web ATR 
Filtering 
 
 Corpus collection 
corpora 
(Cf, Cj) 
 
term sets 
(Xf, Xj) 
seed terms
(sf, sj) 
Figure 1: Related term collection 
Prep-N structure in syst?me ? base de connais-
sances (knowledge based system). The shorter 
candidate syst?me ? base (based system) also 
matches, although we would prefer not to extract 
it. 
Fortunately, the strength of the C-value is the 
way it effectively handles nested MWTs. When 
we calculate the termhood of a string, we sub-
tract from its total frequency its frequency as a 
substring of longer candidate terms. In other 
words, a shorter compound that almost always 
appears nested in a longer compound will have a 
comparatively smaller C-value, even if its total 
frequency is higher than that of the longer com-
pound. Hence, we discard MWTs whose C-value 
is smaller than that of a longer candidate term in 
which it is nested. 
Japanese ATR 
Because compound nouns represent the bulk of 
Japanese technical MWTs, we extract them as 
candidate related terms. As opposed to Sato and 
Sasaki, we ignore single nouns. Also, we do not 
limit the number of candidates output by ATR as 
they did.  
2.3 Filtering 
Finally, from the output set of ATR, we select 
only the technical terms that are part of the 
seed?s semantic domain. Numerous measures 
have been proposed to gauge the semantic simi-
larity between two words (van Rijsbergen 
(1979)). We choose the Jaccard coefficient, 
which we calculate based on search engine hit 
counts. The similarity between a seed term s and 
a candidate term x is given by: ( )
( )xsH
xsHJac ?
?=  
where H(s ? x) is the hit count of pages contain-
ing both s and x, and H(s ? x) is the hit count of 
pages containing s or x. The latter can be calcu-
lated as follows: 
( ) ( ) ( )xsHxHsHxsH ??+=? )(  
Candidates that have a high enough coefficient 
are considered related terms of the seed.  
3 Term Alignment 
Once we have collected related terms in both 
French and Japanese, we must link the terms in 
the source language to the terms in the target 
language. Our alignment procedure is twofold. 
First, we first generate Japanese translation can-
didates for each collected French term. Second, 
we select the most likely translation(s) from the 
set of candidates. This is similar to the genera-
tion and selection procedures used in the litera-
ture (Baldwin and Tanaka (2004), Cao and Li, 
Langkilde and Knight (1998)). 
3.1 Translation Candidates Generation 
Translation candidates are generated using a 
compositional method, which can be divided in 
three steps. First, we decompose the French 
MWTs into combinations of shorter MWU ele-
ments. Second, we look up the elements in bilin-
gual dictionaries. Third, we recompose transla-
tion candidates by generating different combina-
tions of translated elements. 
Decomposition 
In accordance with Daille et al, we define the 
length of a MWU as the number of content 
words it contains. Let n be the length of the 
MWT to decompose. We produce all the combi-
nations of MWU elements of length less or equal 
to n. For example, consider the French transla-
tion of ?knowledge based system?: 
It has a length of three and yields the following 
four combinations1: 
Note the treatment given to the prepositions 
and determiners: we leave them in place when 
they are interposed between content words 
within elements, otherwise we remove them. 
Dictionary Lookup 
We look up each element in bilingual dictionar-
ies. Because some words appear in their inflected 
forms, we use their lemmata. In the example 
given above, we look up connaissance (lemma) 
rather than connaissances (inflected). Note that 
we do not lemmatize MWUs such as base de 
connaissances. This is due to the complexity of 
gender and number agreements of French com-
pounds. However, only a small part of the 
MWTs are collected in their inflected forms, and 
French-Japanese bilingual dictionaries do not 
contain that many MWTs to begin with. The per-
formance hit should therefore be minor.  
Already at this stage, we can anticipate prob-
lems arising from the insufficient coverage of 
                                                 
1 A MWT of length n produces 2n-1 combinations, 
including itself. 
syst?me ? base de connaissances
Noun Prep Noun Prep Noun 
[syst?me ? [base de [connaissances]
[syst?me]  [base de [connaissances]
[syst?me ? [base]  [connaissances]
[syst?me]  [base]  [connaissances]
French-Japanese lexicon resources. Bilingual 
dictionaries may not have enough entries, and  
existing entries may not include a great variety of 
translations for every sense. The former problem 
has no easy solution, and is one of the reasons 
we are conducting this research. The latter can be 
partially remedied by using thesauri ? we aug-
ment each element?s translation set by looking 
up in thesauri all the translations obtained with 
bilingual dictionaries. 
Recomposition 
To recompose the translation candidates, we 
simply generate all suitable combinations of 
translated elements for each decomposition. The 
word order is inverted to take into account the 
different constraints in French and Japanese. In 
the example above, if the lookup phase gave {?
? chishiki}, {?? dodai, ??? besu} and {?
? taikei, ???? shisutemu} as respective 
translation sets for syst?me, base and connais-
sance, the fourth decomposition given above 
would yield the following candidates: 
connaissance base syst?me 
?? ?? ?? 
?? ?? ????
?? ??? ?? 
?? ??? ????
If we do not find any translation for one of the 
elements, the generation fails. 
3.2 Translation Selection  
Selection consists of picking the most likely 
translation from the translation candidates we 
have generated. To discern the likely from the 
unlikely, we use the empirical evidence provided 
by the set of Japanese terms related to the seed. 
We believe that if a candidate is present in that 
set, it could well be a valid translation, as the 
French MWT in consideration is also related to 
the seed. Accordingly, our selection process con-
sists of picking those candidates for which we 
find a complete match among the related terms.  
3.3 Relevance of Compositional Methods 
The automatic translation of MWTs is no simple 
task, and it is worthwhile asking if it is best tack-
led with a compositional method. Intricate prob-
lems have been reported with the translations of 
compounds (Daille and Morin, Baldwin and Ta-
naka), notably:  
? fertility: source and target MWTs can be 
of different lengths. For example, table 
de v?rit? (truth table) contains two con-
tent words and translates into ??????
shinri ? chi ? hyo (lit. truth-value-table), 
which contains three. 
? variability of forms in the transla-
tions: MWTs can appear in many forms. 
For example, champ electromagn?tique 
(electromagnetic field) translates both 
into ???? denji? ba (lit. electromag-
netic field)???? denji?kai (lit. elec-
tromagnetic ?region?). 
? constructional variability in the trans-
lations: source and target MWTs have 
different morphological structures. For 
example, in the pair apprentissage auto-
matique??? ???  kikai ? gakushu 
(machine learning) we have (N-
Adj)?(N-N). In the pair programmation 
par contraintes???????? patan?
ninshiki (pattern recognition) we have 
(N-par-N)?(N-N). 
? non-compositional compounds: some 
compounds? meaning cannot be derived 
from the meaning of their components. 
For example, the Japanese term ???
aka?ten (failing grade, lit. ?red point?) 
translates into French as note d??chec (lit. 
failing grade) or simply ?chec (lit. fail-
ure).  
? lexical divergence: source and target 
MWTs can use different lexica to ex-
press a concept. For example, traduction 
automatique (machine translation, lit. 
?automatic translation?) translates as ?
???? kikai ? honyaku (lit. machine 
translation). 
It is hard to imagine any method that could ad-
dress all these problems accurately.  
Tanaka and Baldwin (2003) found that 48.7% 
of English-Japanese Noun-Noun compounds 
translate compositionality. In a preliminary ex-
periment, we found this to be the case for as 
much as 75.1% of the collected MWTs. If we are 
to maximize the coverage of our system, it is 
sensible to start with a compositional approach. 
We will not deal with the problem of fertility and 
non-compositional compounds in this paper. 
Nonetheless, lexical divergence and variability 
issues will be partly tackled by broader transla-
tions and related words given by thesauri. 
4 Evaluation 
4.1 Linguistic Resources 
The bilingual dictionaries used in the experi-
ments are the Crown French-Japanese Dictionary 
(Ohtsuki et al (1989)), and the French-Japanese 
Scientific Dictionary (French-Japanese Scientific 
Association (1989)). The former contains about 
50,000 entries of general usage single words. 
The latter contains about 50,000 entries of both 
single and multi-word scientific terms. These 
two complement each other, and by combining 
both entries we form our base dictionary to 
which we refer as DicFJ. 
The main thesaurus used is Bunrui Goi Hyo 
(National Institute for Japanese Language 
(2004)). It contains about 96,000 words, and 
each entry is organized in two levels: a list of 
synonyms and a list of more loosely related 
words. We augment the initial translation set by 
looking up the Japanese words given by DicFJ. 
The expanded bilingual dictionary comprised of 
the words from DicFJ combined with their syno-
nyms is denoted DicFJJ. The dictionary resulting 
of DicFJJ combined with the more loosely related 
words is denoted DicFJJ2. 
Finally, we build another thesaurus from a 
Japanese-English dictionary. We use Eijiro 
(Electronic Dictionary Project (2004)), which 
contains 1,290,000 entries. For a given Japanese 
entry, we look up its English translations. The 
Japanese translations of the English intermediar-
ies are used as synonyms/related words of the 
entry. The resulting thesaurus is expected to pro-
vide even more loosely related translations (and 
also many irrelevant ones). We denote it DicFJEJ. 
4.2 Notation 
Let F and J be the two sets of related terms col-
lected in French and Japanese. F? is the subset of 
F for which Jac?0.01: { }01.0)(' ??= fJacFfF  
F?* is the subset of valid related terms in F?, as 
determined by human evaluation. P is the set of 
all potential translation pairs among the collected 
terms (P=F?J). P? is the set of pairs containing 
either a French term or a Japanese term with 
Jac?0.01: 
( ){ }01.0)(01.0)(,' ?????= jJacfJacJjFfP  
P?* is the subset of valid translation pairs in P?, 
determined by human evaluation. These pairs 
need to respect three criteria: 1) contain valid 
terms, 2) be related to the seed, and 3) constitute 
a valid translation. M is the set of all translations 
selected by our system. M? is the subset of pairs 
in M with Jac?0.01 for either the French or the 
Japanese term. It is also the output of our system: { }01.0)(01.0)(),(' ????= jJacfJacMjfM  
M?* is the intersection of M? and P?*, or in other 
words, the subset of valid translation pairs output 
by our system. 
4.3 Baseline Method 
Our starting point is the simplest possible align-
ment, which we refer to as our baseline. It is 
worked out by using each of the aforementioned 
dictionaries independently. The output set ob-
tained using DicFJ is denoted FJ, the one using 
DicFJJ is denoted FJJ, and so on. The experiment 
is made using the eight seed pairs given in Table 
1. On average, we have |F'| =74.3, |F'*|=51.0 and 
|P'*|=24.0. Table 2 gives a summary of the key 
results. The precision and the recall are given by: 
'
'*
M
M
precision =  , 
'*
'*
P
M
recall =  
DicFJ contains only Japanese translations cor-
responding to the strict sense of French elements. 
Such a dictionary generates only a few transla-
tion candidates which tend to be correct when 
present in the target set. On the other hand, the 
lookup in DicFJJ2 and DicFJEJ interprets French 
Set |M'| |M'*| Prec. Recall 
FJ 10.5 9.6  92% 40% 
FJJ 15.3 12.6  83% 53% 
FJJ2 20.5 13.4  65% 56% 
FJEJ 30.9 14.1  46% 59% 
Table 2: Results for the baseline 
Id French Japanese (English)
1 analyse vectorielle ??????? bekutoru?kaiseki (vector analysis) 
2 circuit logique ????? ronri?kairo (logic circuit) 
3   intelligence artificielle          ????? jinko?chinou (artificial intelligence) 
4 linguistique informatique ?????? keisan?gengogaku (computational linguistics) 
5 reconnaissance des formes ??????? patan?ninshiki (pattern recognition) 
6 reconnaissance vocale ????? onsei?ninshiki (speech recognition) 
7 science cognitive ????? ninchi?kagaku (cognitive science) 
8 traduction automatique ????? kikai?honyaku (machine translation) 
Table 1: Seed pairs 
MWT elements with more laxity, generating 
more translations and thus more alignments, at 
the cost of some precision. 
4.4 Incremental Selection 
The progressive increase in recall given by the 
increasingly looser translations is in inverse pro-
portion to the decrease in precision, which hints 
that we should give precedence to the alignments 
obtained with the more accurate methods. Con-
sequently, we start by adding the alignments in 
FJ to the output set. Then, we augment it with 
the alignments from FJJ whose terms are not 
already in FJ. The resulting set is denoted FJJ'. 
We then augment FJJ' with the pairs from FJJ2 
whose terms are not in FJJ', and so on, until we 
exhaust the alignments in FJEJ.  
For instance, let FJ contain (synth?se de la 
parole? ? ? ? ? ? onsei ? gousei (speech 
synthesis)) and FJJ contain this pair plus 
(synth?se de la parole?????? onsei?kaiseki 
(speech analysis)). In the first iteration, the pair 
in FJ is added to the output set. In the second 
iteration, no pair is added because the output set 
already contains an alignment with synth?se de 
la parole. 
Table 3 gives the results for each incremental 
step. We can see an increase in precision for FJJ', 
FJJ2' and FJEJ' of respectively 5%, 9% and 8%, 
compared to FJJ, FJJ2 and FJEJ. We are effec-
tively filtering output pairs and, as expected, the 
increase in precision is accompanied by a slight 
decrease in recall.  Note that, because FJEJ is 
not a superset of FJJ2, we see an increase in both 
precision and recall in FJEJ' over FJEJ. None-
theless, the precision yielded by FJEJ' is not suf-
ficient, which is why DicFJEJ is left out in the 
next experiment. 
4.5 Bootstrapping 
The coverage of the system is still shy of the 20 
pairs/seed objective we gave ourselves. One 
cause for this is the small number of valid trans-
lation pairs available in the corpora. From an 
average of 51 valid related terms in the source 
set, only 24 have their translation in the target set. 
To counter that problem, we increase the cover-
age of Japanese related terms and hope that by 
doing so, we will also increase the coverage of 
the system as a whole.  
Once again, we utilize the high precision of 
the baseline method. The average 10.5 pairs in 
FJ include 92% of Japanese terms semantically 
similar to the seed. By inputting these terms in 
the term collection system, we collect many 
more terms, some of which are probably the 
translations of our French MWTs. 
The results for the baseline method with boot-
strapping are given in Table 4. The ones using 
incremental selection and bootstrapping are 
given in Table 5. FJ+ consists of the alignments 
given by a generation process using DicFJ and a 
selection performed on the augmented set of re-
lated terms. FJJ+ and FJJ2+ are obtained in the 
same way using DicFJJ and DicFJJ2. FJ+' contains 
the alignments from FJ, augmented with those 
from FJ+ whose terms are not in FJ. FJJ+' con-
tains FJ+', incremented with terms from FJJ. 
FJJ+'' contains FJJ+', incremented with terms 
from FJJ+, and so on.  
The bootstrap mechanism grows the target 
term set tenfold, making it very laborious to 
identify all the valid translation pairs manually. 
Consequently, we only evaluate the pairs output 
by the system, making it impossible to calculate 
recall. Instead, we use the number of valid trans-
lation pairs as a makeshift measure. 
Bootstrapping successfully allows for many 
more translation pairs to be found. FJ+, FJJ+, 
and FJJ2+ respectively contain 7.6, 8.7 and 8.5 
more valid alignments on average than FJ, FJJ 
and FJJ2. The augmented target term set is nois-
ier than the initial set, and it produces many more 
invalid alignments as well. Fortunately, the in-
cremental selection effectively filters out most of 
the unwanted, restoring the precision to accept-
able levels.  
Set |M'| |M'*| Prec. Recall 
FJJ' 14.0  12.3  88% 51% 
FJJ2' 16.1  12.8  79% 53% 
FJEJ' 29.1  15.5  53% 65% 
Table 3: Results for the incremental selection 
Set |M'| |M'*| Prec. 
FJ+' 19.5 16.1  83% 
FJJ+' 22.5 18.6  83% 
FJJ +'' 24.3 19.6  81% 
FJJ2+' 25.6 20.1  79% 
FJJ2+'' 28.6 20.6  72% 
Table 5: Results for the incremental 
selection with bootstrap expansion 
Set |M'| |M'*| Prec. 
FJ+ 20.9 16.8  80% 
FJJ+ 30.9 21.3  69% 
FJJ2+ 45.8 22.6  49% 
Table 4: Results for the baseline 
method with bootstrap expansion 
4.6 Analysis 
A comparison of all the methods is illustrated in 
the precision ? valid alignments curves of Figure 
2. The points on the four curves are taken from 
Tables 2 to 5. The gap between the dotted and 
filled curves clearly shows that bootstrapping 
increases coverage. The respective positions of 
the squares and crosses show that incremental 
selection effectively filters out erroneous align-
ments. FJJ+'', with 19.6 valid alignments and a 
precision of 81%, is at the rightmost and upper-
most position in the graph. The detailed results 
for each seed are presented in Table 6, and the 
complete output for the seed ?logic circuit? is 
given in Table 7.  
From the average 4.7 erroneous pairs/seed, 3.2 
(68%) were correct translations but were judged 
unrelated to the seed. This is not surprising, con-
sidering that our set of French related terms con-
tained only 69% (51/74.3) of valid related terms. 
Also note that, of the 24.3 pairs/seed output, 5.25 
are listed in the French-Japanese Scientific Dic-
tionary. However, only 3.9 of those pairs are in-
cluded in M'*. The others were deemed unrelated 
to the seed.  
In the output set of ?machine translation?, ?
??????? shizen ?gengo ?shori (natural lan-
guage processing) is aligned to both traitement 
du language naturel and traitement des langues 
naturelles. The system captures the term?s vari-
ability around langue/language. Lexical diver-
gence is also taken into account to some extent. 
The seed computational linguistics yields the 
alignment of langue maternelle (mother tongue) 
with ?? ?? bokoku ? go (literally [[mother-
country]-language]). The usage of thesauri en-
abled the system to include the concept of coun-
try in the translated MWT, even though it is not 
present in any of the French elements. 
5 Conclusion and future work 
We have proposed a method for compiling bilin-
gual terminologies of compositionally translated 
MWTs. As opposed to previous work, we use the 
web rather than comparable corpora as a source 
of bilingual data. Our main insight is to constrain 
source and target candidate MWTs to only those 
strongly related to the seed. This allows us to 
achieve term alignment with high precision. We 
showed that coverage reaches satisfactory levels 
by using thesauri and bootstrapping.  
Due to the difference in objectives and in cor-
pora, it is very hard to compare results: our 
method produces a rather small set of highly ac-
curate alignments, whereas extraction from com-
parable corpora generates much more candidates, 
but with an inferior precision. These two ap-
proaches have very different applications. Our 
method does however eliminate the requirement 
of comparable corpora, which means that we can 
use seeds from any domain, provided we have 
reasonably rich dictionaries and thesauri.  
Let us not forget that this article describes 
only a first attempt at compiling French-Japanese 
terminology, and that various sources of im-
provement have been left untapped. In particular, 
our alignment suffers from the fact that we do 
not discriminate between different candidate 
translations. This could be achieved by using any 
of the more sophisticated selection methods pro-
posed in the literature. Currently, corpus features 
are used solely for the collection of related terms. 
These could also be utilized in the translation 
selection, which Baldwin and Tanaka have 
shown to be quite effective. We could also make 
use of bilingual dictionary features as they did. 
Lexical context is another resource we have not 
exploited. Context vectors have successfully 
been applied in translation selection by Fung  as 
well as  Daille and Morin.  
On a different level, we could also apply the 
bootstrapping to expand the French set of related 
terms. Finally, we are investigating the possibil-
seed |F'| |F'*| |P'*| |M'| |M'*| Prec. 
1 89 40 14 26 13 50% 
2 64 55 24 14 14 100% 
3 72 59 38 40 33 83% 
4 67 49 22 23 18 78% 
5 85 70 22 21 17 81% 
6 67 50 27 22 21 95% 
7 36 27 16 20 17 85% 
8 114 58 29 28 24 86% 
avg 74.3 51.0 24.0  24.3  19.6  81% 
Table 6: Detailed results for  FJJ+'' 
70% 
80% 
90% 
100% 
25
Pr
ec
is
io
n 
0% 
10% 
20% 
30% 
40% 
50% 
60% 
0 5 10 15 20 
Baseline 
Baseline with bootstrap
Incremental 
Incremental with bootstrap
Number of Valid Alignments
Figure 2: Precision - Valid Alignments curves 
ity of resolving the alignments in the opposite 
direction: from Japanese to French. Surely the 
constructional variability of French MWTs 
would present some difficulties, but we are con-
fident that this could be tackled using translation 
templates, as proposed by Baldwin and Tanaka. 
References 
T. Baldwin and T. Tanaka. 2004. Translation by Ma-
chine of Complex Nominals: Getting it Right. In 
Proc. of the ACL 2004 Workshop on Multiword 
Expressions: Integrating Processing, pp. 24?31, 
Barcelona, Spain.  
Y. Cao and H. Li. 2002. Base Noun Phrase Transla-
tion Using Web Data and the EM Algorithm. In 
Proc. of COLING -02, Taipei, Taiwan. 
Y.C. Chiao and P. Zweigenbaum. 2002. Looking for 
Candidate Translational Equivalents in Specialized, 
Comparable Corpora. In Proc. of COLING-02, pp. 
1208?1212. Taipei, Taiwan. 
B. Daille, E. Gaussier, and J.M. Lange. 1994. To-
wards Automatic Extraction of Monolingual and 
Bilingual Terminology. In Proc. of COLING-94, 
pp. 515?521, Kyoto, Japan. 
B. Daille and E. Morin. 2005. French-English Termi-
nology Extraction from Comparable Corpora, In 
IJCNLP-05, pp. 707?718, Jeju Island, Korea. 
H. D?jean., E. Gaussier and F. Sadat. An Approach 
Based on Multilingual Thesauri and Model Com-
bination for Bilingual Lexicon Extraction. In Proc. 
of COLING-02, pp. 218?224. Taipei, Taiwan. 
Electronic Dictionary Project. 2004. Eijiro Japanese-
English Dictionary: version 79. EDP. 
K.T. Frantzi, and S. Ananiadou. 2003. The C-
Value/NC-Value Domain Independent Method for 
Multi-Word Term Extraction. Journal of Natural 
Language Processing, 6(3), pp. 145?179. 
French Japanese Scientific Association. 1989. French-
Japanese Scientific Dictionary: 4th edition. Haku-
suisha. 
P. Fung. 1995. A Pattern Matching Method for Find-
ing Noun and Proper Noun from Noisy Parallel 
Corpora. In Proc of the ACL-95, pp. 236?243, 
Cambridge, USA. 
P. Fung. 1998. A Statiscal View on Bilingual Lexicon 
Extraction: From Parallel Corpora to Non-parallel 
Corpora. In D. Farwell, L. Gerber and L. Hovy 
eds.: Proceedings of the AMTA-98, Springer, pp. 
1?16. 
I. Langkilde and K. Knight. 1998. Generation that 
exploits corpus-based statistical knowledge. In 
COLLING/ACL-98, pp. 704?710, Montreal, Can-
ada. 
National Institute for Japanese Language. 2004. Bun-
rui Goi Hyo: revised and enlarged edition Dainip-
pon Tosho. 
T. Ohtsuki et al 1989. Crown French-Japanese Dic-
tionary: 4th edition. Sanseido. 
R. Rapp. 1999. Automatic Identification of Word 
Translations from Unrelated English and German 
Corpora. In Proc. of the ACL-99. pp. 1?17. Col-
lege Park, USA. 
S. Sato and Y. Sasaki. 2003. Automatic Collection of 
Related Terms from the Web. In ACL-03 Compan-
ion Volume to the Proc. of the Conference, pp. 
121?124, Sapporo, Japan. 
T. Tanaka and T. Baldwin. 2003. Noun-Noun Com-
pound Machine Translation: A Feasibility Study on 
Shallow Processing. In Proc. of the ACL-2003 
Workshop on Multiword Expressions: Analysis, 
Acquisition and Treatment, pp. 17?24. Sapporo, 
Japan. 
van Rijsbergen, C.J. 1979. Information Retrieval. 
London: Butterworths. Second Edition. 
Jac (Fr.) French term Japanese term (English) eval? 
0.100  portes logiques ?????? ronri?geeto (logic gate) 2/2/2 
0.064  fonctions logiques ????? ronri?kansuu (logic function) 2/2/2 
0.064  fonctions logiques ????? ronri?kinou (logic function) 2/2/2 
0.048  registre ? d?calage ???????? shifuto?rejisuta (shift register) 2/2/2 
0.044  simulateur de circuit ????????? kairo?shimureeta (circuit simulator) 2/2/2 
0.040  circuit combinatoire ?????? kumiawase?kairo (combinatorial circuit) 2/2/2 
0.031  nombre binaire 2??? ni?shinsuu (binary number) 2/2/2 
0.024  niveaux logiques ?????? ronri?reberu (logical level) 2/2/2 
0.020  circuit logique combinatoire ????????? kumiawase?ronri?kairo (combinatorial logic circuit) 2/2/2 
0.017  valeur logique ???? ronri?chi (logical value) 2/2/2 
0.013  tension d' alimentation ????? dengen?denatsu (supply voltage) 2/2/2 
0.011  conception de circuits ????? kairo?sekkei (circuit design) 2/2/2 
0.007  conception d' un circuit logique ???????? ronri?kairo?sekkei (logic circuit design) 2/1/2 
0.005  nombre de portes ????? geeto?suu (number of gates) 2/1/2 
? relatedness / termhood / quality of the translation, on a scale of  0 to 2 
Table 7: System output for seed pair circuit logique ????? (logic circuit) 
Effect of Domain-Specific Corpus
in Compositional Translation Estimation for Technical Terms
Masatsugu Tonoike?, Mitsuhiro Kida?,
Takehito Utsuro?
?Graduate School of Informatics,
Kyoto University
Yoshida-Honmachi, Sakyo-ku,
Kyoto 606-8501 Japan
(tonoike,kida,takagi,sasaki,
utsuro)@pine.kuee.kyoto-u.ac.jp
Toshihiro Takagi?, Yasuhiro Sasaki?,
and Satoshi Sato?
?Graduate School of Engineering,
Nagoya University
Furo-cho, Chikusa-ku,
Nagoya 464-8603 JAPAN
ssato@nuee.nagoya-u.ac.jp
Abstract
This paper studies issues on compiling
a bilingual lexicon for technical terms.
In the task of estimating bilingual term
correspondences of technical terms, it
is usually quite difficult to find an exist-
ing corpus for the domain of such tech-
nical terms. In this paper, we take an
approach of collecting a corpus for the
domain of such technical terms from
the Web. As a method of translation
estimation for technical terms, we pro-
pose a compositional translation esti-
mation technique. Through experimen-
tal evaluation, we show that the do-
main/topic specific corpus contributes
to improving the performance of the
compositional translation estimation.
1 Introduction
This paper studies issues on compiling a bilingual
lexicon for technical terms. So far, several tech-
niques of estimating bilingual term correspon-
dences from a parallel/comparable corpus have
been studied (Matsumoto and Utsuro, 2000). For
example, in the case of estimation from compa-
rable corpora, (Fung and Yee, 1998; Rapp, 1999)
proposed standard techniques of estimating bilin-
gual term correspondences from comparable cor-
pora. In their techniques, contextual similarity
between a source language term and its transla-
tion candidate is measured across the languages,
and all the translation candidates are re-ranked ac-
cording to the contextual similarities. However,
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
Figure 1: Compilation of a Domain/Topic Spe-
cific Bilingual Lexicon
there are limited number of parallel/comparable
corpora that are available for the purpose of es-
timating bilingual term correspondences. There-
fore, even if one wants to apply those existing
techniques to the task of estimating bilingual term
correspondences of technical terms, it is usually
quite difficult to find an existing corpus for the
domain of such technical terms.
Considering such a situation, we take an ap-
proach of collecting a corpus for the domain of
such technical terms from the Web. In this ap-
proach, in order to compile a bilingual lexicon
for technical terms, the following two issues have
to be addressed: collecting technical terms to be
listed as the headwords of a bilingual lexicon, and
estimating translation of those technical terms.
Among those two issues, this paper focuses on the
second issue of translation estimation of technical
terms, and proposes a method for translation es-
timation for technical terms using a domain/topic
specific corpus collected from the Web.
More specifically, the overall framework of
114
compiling a bilingual lexicon from the Web can
be illustrated as in Figure 1. Suppose that we have
sample terms of a specific domain/topic, techni-
cal terms to be listed as the headwords of a bilin-
gual lexicon are collected from the Web by the re-
lated term collection method of (Sato and Sasaki,
2003). Those collected technical terms can be di-
vided into three subsets according to the number
of translation candidates they have in an existing
bilingual lexicon, i.e., the subset XUS of terms for
which the number of translations in the existing
bilingual lexicon is one, the subset XMS of terms
for which the number of translations is more than
one, and the subset YS of terms which are not
found in the existing bilingual lexicon. (Hence-
forth, the union XUS ? XMS is denoted as XS .)
The translation estimation task here is to estimate
translations for the terms of XMS and YS . For the
terms of XMS , it is required to select an appro-
priate translation from the translation candidates
found in the existing bilingual lexicon. For ex-
ample, as a translation of the Japanese technical
term ??????, which belongs to the logic cir-
cuit field, the term ?register? should be selected
but not the term ?regista? of the football field. On
the other hand, for the terms of YS , it is required
to generate and validate translation candidates. In
this paper, for the above two tasks, we use a do-
main/topic specific corpus. Each term of XUS has
the only one translation in the existing bilingual
lexicon. The set of the translations of terms of
XUS is denoted as XUT . Then, the domain/topic
specific corpus is collected from the Web using
the terms in the set XUT . A new bilingual lexicon
is compiled from the result of translation estima-
tion for the terms of XMS and YS , as well as the
translation pairs which consist of the terms of XUS
and their translations found in the existing bilin-
gual lexicon.
For each term of XMS , from the translation can-
didates found in the existing bilingual lexicon, we
select the one which appears most frequently in
the domain/topic specific corpus. The experimen-
tal result of this translation selection process is de-
scribed in Section 5.2.
As a method of translation genera-
tion/validation for technical terms, we propose a
compositional translation estimation technique.
Compositional translation estimation of a term
can be done through the process of composi-
tionally generating translation candidates of the
term by concatenating the translation of the
constituents of the term. Here, those translation
candidates are validated using the domain/topic
specific corpus.
In order to assess the applicability of the com-
positional translation estimation technique, we
randomly pick up 667 Japanese and English tech-
nical term translation pairs of 10 domains from
existing technical term bilingual lexicons. We
then manually examine their compositionality,
and find out that 88% of them are actually com-
positional, which is a very encouraging result.
Based on this assessment, this paper proposes a
method of compositional translation estimation
for technical terms, and through experimental
evaluation, shows that the domain/topic specific
corpus contributes to improving the performance
of compositional translation estimation.
2 Collecting a Domain/Topic Specific
Corpus
When collecting a domain/topic specific corpus of
the language T , for each technical term xUT in the
set XUT , we collect the top 100 pages with search
engine queries including xUT . Our search engine
queries are designed so that documents which de-
scribe the technical term xUT is to be ranked high.
For example, an online glossary is one of such
documents. Note that queries in English and those
in Japanese do not correspond. When collect-
ing a Japanese corpus, the search engine ?goo?1
is used. Specific queries used here are phrases
with topic-marking postpositional particles such
as ?xUT ???, ?xUT ????, ?xUT ??, and an ad-
nominal phrase ?xUT ??, and ?xUT ?. When col-
lecting a English corpus, the search engine ?Ya-
hoo!?2 is used. Specific queries used here are ?xUT
AND what?s?, ?xUT AND glossary?, and ?xUT ?.
3 Compositional Translation Estimation
for Technical Terms
3.1 Overview
An example of compositional translation estima-
tion for the Japanese technical term ??????
1http://www.goo.ne.jp/
2http://www.yahoo.com/
115
? application(1)
? practical(0.3)
? applied(1.6)
? action(1)
? activity(1)
? behavior(1)
? analysis(1)
? diagnosis(1)
? assay(0.3)
? behavior analysis(10)
??Compositional generation 
of translation candidate
? applied behavior analysis(17.6)
? application behavior analysis(11)
? applied behavior diagnosis(1)
??Decompose source term into constituents  
??Translate constituents into target language      process
?? ?? ??a
?? ????b
Generated translation candidates
?(1.6?1?1)+(1.6?10)
? application(1)
? practical(0.3)
? applied(1.6)
Figure 2: Compositional Translation Estimation
for the Japanese Technical Term ????????
?? is shown in Figure 2. First, the Japanese tech-
nical term ???????? is decomposed into
its constituents by consulting an existing bilin-
gual lexicon and retrieving Japanese headwords.3
In this case, the result of this decomposition can
be given as in the cases ?a? and ?b? (in Fig-
ure 2). Then, each constituent is translated into
the target language. A confidence score is as-
signed to the translation of each constituent. Fi-
nally, translation candidates are generated by con-
catenating the translation of those constituents
without changing word order. The confidence
score of translation candidates are defined as the
product of the confidence scores of each con-
stituent. Here, when validating those translation
candidates using the domain/topic specific cor-
pus, those which are not observed in the corpus
are not regarded as candidates.
3.2 Compiling Bilingual Constituents
Lexicons
This section describes how to compile bilingual
constituents lexicons from the translation pairs of
the existing bilingual lexicon Eijiro. The under-
lying idea of augmenting the existing bilingual
lexicon with bilingual constituents lexicons is il-
lustrated with the example of Figure 3. Suppose
that the existing bilingual lexicon does not in-
clude the translation pair ?applied :???, while
it includes many compound translation pairs with
the first English word as ?applied? and the first
3Here, as an existing bilingual lexicon, we use Ei-
jiro(http://www.alc.co.jp/) and bilingual constituents lexi-
cons compiled from the translation pairs of Eijiro (details
to be described in the next section).
 
applied mathematics : ?? ??
applied science : ?? ??
applied robot : ?? ????
.
.
. frequency
? ??
applied : ?? : 40
 
Figure 3: Example of Estimating Bilingual Con-
stituents Translation Pair (Prefix)
Table 1: Numbers of Entries and Translation Pairs
in the Lexicons
lexicon # of entries # of translationEnglish Japanese pairs
Eijiro 1,292,117 1,228,750 1,671,230
P
2
232,716 200,633 258,211
B
P
38,353 38,546 112,586
B
S
22,281 20,627 71,429
Eijiro : existing bilingual lexicon
P
2
: entries of Eijiro with two constituents
in both languages
B
P
: bilingual constituents lexicon (prefix)
B
S
: bilingual constituents lexicon (suffix)
Japanese word ????.4 In such a case, we align
those translation pairs and estimate a bilingual
constituent translation pair, which is to be col-
lected into a bilingual constituents lexicon.
More specifically, from the existing bilingual
lexicon, we first collect translation pairs whose
English terms and Japanese terms consist of two
constituents into another lexicon P
2
. We compile
?bilingual constituents lexicon (prefix)? from the
first constituents of the translation pairs in P
2
and
compile ?bilingual constituents lexicon (suffix)?
from their second constituents. The numbers of
entries in each language and those of translation
pairs in those lexicons are shown in Table 1.
In the result of our assessment, only 27% of the
667 translation pairs mentioned in Section 1 can
be compositionally generated using Eijiro, while
the rate increases up to 49% using both Eijiro and
?bilingual constituents lexicons?.5
4Japanese entries are supposed to be segmented into a
sequence of words by the morphological analyzer JUMAN
(http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html)
5In our rough estimation, the upper bound of this rate
is about 80%. Improvement from 49% to 80% could be
achieved by extending the bilingual constituents lexicons
and by introducing constituent reordering rules with preposi-
tions into the process of compositional translation candidate
generation.
116
3.3 Score of Translation Pairs in the
Lexicons
This section introduces a confidence score of
translation pairs in the various lexicons presented
in the previous section. Here, we suppose that
the translation pair ?s, t? of terms s and t is used
when estimating translation from the language of
the term s to that of the term t. First, in this pa-
per, we assume that translation pairs follow cer-
tain preference rules and can be ordered as below:
1. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of two or more constituents.
2. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are high.
3. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of exactly one constituent.
4. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are not
high.
As the definition of the confidence score
q(?s, t?) of a translation pair ?s, t?, in this paper,
we use the following:
q(?s, t?) =
?
?
?
?
?
10
(compo(s)?1) (?s, t? in Eijiro)
log
10
fp(?s, t?) (?s, t? in BP )
log
10
fs(?s, t?) (?s, t? in BS)
(1)
where compo(s) denotes the word (in English) or
morpheme (in Japanese) count of s, fp(?s, t?) the
frequency of ?s, t? as the first constituent in P
2
,
and fs(?s, t?) the frequency of ?s, t? as the second
constituent in P
2
.
6
3.4 Score of Translation Candidates
Suppose that a translation candidate yt is gener-
ated from translation pairs ?s
1
, t
1
?, ? ? ? , ?sn, tn?
by concatenating t
1
, ? ? ? , tn as yt = t1 ? ? ? tn.
Here, in this paper, we define the confidence score
of yt as the product of the confidence scores of the
6It is necessary to empirically examine whether this def-
inition of the confidence score is optimal or not. However,
according to our rough qualitative examination, the results
of the confidence scoring seem stable when without a do-
main/topic specific corpus, even with minor tuning by incor-
porating certain parameters into the score.
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
Figure 4: Experimental Evaluation of Translation
Estimation for Technical Terms with/without the
Domain/Topic Specific Corpus (taken from Fig-
ure 1)
constituent translation pairs ?s
1
, t
1
?, ? ? ? , ?sn, tn?.
Q(yt) =
n
?
i=1
q(?si, ti?) (2)
If a translation candidate is generated from
more than one sequence of translation pairs, the
score of the translation candidate is defined as the
sum of the score of each sequence.
4 Translation Candidate Validation
using a Domain/Topic Specific Corpus
It is not clear whether translation candidates
which are generated by the method described in
Section 3 are valid as English or Japanese terms,
and it is not also clear whether they belong to the
domain/topic. So using a domain/topic specific
corpus collected by the method described in Sec-
tion 2, we examine whether the translation candi-
dates are valid as English or Japanese terms and
whether they belong to the domain/topic. In our
validation method, given a ranked list of trans-
lation candidates, each translation candidate is
checked whether it is observed in the corpus, and
one which is not observed in the corpus is re-
moved from the list.
5 Experiments and Evaluation
5.1 Translation Pairs for Evaluation
In our experimental evaluation, within the frame-
work of compiling a bilingual lexicon for tech-
nical terms, we evaluate the translation estima-
tion part which is indicated with bold line in Fig-
117
Table 2: Number of Translation Pairs for Evaluation
dictionaries categories |X
S
| |Y
S
|
S = English S = Japanese
|X
U
S
| |X
M
S
| C(S) |X
U
S
| |X
M
S
| C(S)
Electromagnetics 58 33 36 22 82% 32 26 76%
McGraw-Hill Electrical engineering 52 45 34 18 67% 25 27 64%
Optics 54 31 42 12 65% 22 32 65%
Iwanami Programming language 55 29 37 18 86% 38 17 100%Programming 53 29 29 24 86% 29 24 79%
Dictionary of (Computer) 100 100 91 9 46% 69 31 56%Computer
Anatomical Terms 100 100 91 9 86% 33 67 39%
Dictionary of Disease 100 100 91 9 74% 53 47 51%
250,000 Chemicals and Drugs 100 100 94 6 58% 74 26 51%
medical terms Physical Science and Statistics 100 100 88 12 64% 58 42 55%
Total 772 667 633 139 68% 433 339 57%
McGraw-Hill : Dictionary of Scientific and Technical Terms
Iwanami : Encyclopedic Dictionary of Computer Science
C(S) : for Y
S
, the rate of including correct translations within the collected domain/topic specific corpus
ure 4. In the evaluation of this paper, we sim-
ply skip the evaluation of the process of collecting
technical terms to be listed as the headwords of a
bilingual lexicon. In order to evaluate the transla-
tion estimation part, from ten categories of exist-
ing Japanese-English technical term dictionaries
listed in Table 2, terms are randomly picked up
for each of the set XUS , XMS , and YS . (Here, as
the terms of YS , these which consist of the only
one word or morpheme are excluded.) As de-
scribed in Section 1, the terms of XUT (the set
of the translations for the terms of XUS ) is used
for collecting a domain/topic specific corpus from
the Web. Translation estimation evaluation is to
be done against the set XMS and YS . For each of
the ten categories, Table 2 shows the sizes of XUS ,
XMS and YS , and for YS , the rate of including cor-
rect translation within the collected domain/topic
specific corpus, respectively.
5.2 Translation Selection from Existing
Bilingual Lexicon
For the terms of XMS , the selected translations are
judged by a human. The correct rates are 69%
from English to Japanese on the average and 75%
from Japanese to English on the average.
5.3 Compositional Translation Estimation
for Technical Terms without the
Domain/Topic Specific Corpus
Without the domain specific corpus, the cor-
rect rate of the first ranked translation candidate
is 19% on the average (both from English to
Japanese and from Japanese to English). The
rate of including correct candidate within top 10
is 40% from English to Japanese and 43% from
Japanese to English on the average. The rate of
compositionally generating correct translation us-
ing both Eijiro and the bilingual constituents lex-
icons (n = ?) is about 50% on the average (both
from English to Japanese and from Japanese to
English).
5.4 Compositional Translation Estimation
for Technical Terms with the
Domain/Topic Specific Corpus
With domain specific corpus, on the average, the
correct rate of the first ranked translation candi-
date improved by 8% from English to Japanese
and by 2% from Japanese to English. However,
the rate of including correct candidate within top
10 decreased by 7% from English to Japanese,
and by 14% from Japanese to English. This is be-
cause correct translation does not exist in the cor-
pus for 32% (from English to Japanese) or 43%
(from Japanese to English) of the 667 translation
pairs for evaluation.
For about 35% (from English to Japanese) or
30% (from Japanese to English) of the 667 trans-
lation pairs for evaluation, correct translation does
exist in the corpus and can be generated through
the compositional translation estimation process.
For those 35% or 30% translation pairs, Fig-
ure 5 compares the correct rate of the first ranked
translation pairs between with/without the do-
main/topic specific corpus. The correct rates in-
crease by 34?37% with the domain/topic specific
corpus. This result supports the claim that the do-
118
??
???
???
???
???
???
???
???
???
???
????
???
???
??
??
??
???
?
???
???
???
???
??
???
???
??
??
???
?
??
??
???
??
??
???
??
??
??
??
??
???
??
??
??
??
???
?
??
???
??
??
???
???
?
???
??
??
??
??
???
???
??
???
???
?
??
??
???
???
???
??
?
??
???
??
??
??
??
??
??
??
??
???
???
??
??
??
??
??
??
??
??
???
?
??
??
??
??
??
??
?
??????????????
???????????
(a) English to Japanese
??
???
???
???
???
???
???
???
???
???
????
???
???
??
??
??
???
?
???
???
???
???
??
???
???
??
??
???
?
??
??
???
??
??
???
??
??
??
??
??
???
??
??
??
??
???
?
??
???
??
??
???
???
?
???
??
??
??
??
???
???
??
???
???
?
??
??
???
???
???
??
?
??
???
??
??
??
??
??
??
??
??
???
???
??
??
??
??
??
??
??
??
???
?
??
??
??
??
??
??
?
??????????????
???????????
(b) Japanese to English
Figure 5: Evaluation against the Translation Pairs
whose Correct Translation Exist in the Corpus
and can be Generated Compositionally
main/topic specific corpus is effective in transla-
tion estimation of technical terms.
6 Related Works
As a related work, (Fujii and Ishikawa, 2001)
proposed a technique of compositional estima-
tion of bilingual term correspondences for the
purpose of cross-language information retrieval.
In (Fujii and Ishikawa, 2001), a bilingual con-
stituents lexicon is compiled from the translation
pairs included in an existing bilingual lexicon in
the same way as our proposed method. One of the
major differences of the technique of (Fujii and
Ishikawa, 2001) and the one proposed in this pa-
per is that in (Fujii and Ishikawa, 2001), instead of
the domain/topic specific corpus, they use a cor-
pus of the collection of the technical papers, each
of which is published by one of the 65 Japanese
associations for various technical domains. An-
other important difference is that in (Fujii and
Ishikawa, 2001), they evaluate only the perfor-
mance of cross-language information retrieval but
not that of translation estimation.
(Cao and Li, 2002) proposed a method of com-
positional translation estimation for compounds.
In the proposed method of (Cao and Li, 2002),
translation candidates of a term are composition-
ally generated by concatenating the translation
of the constituents of the term and are re-ranked
by measuring contextual similarity against the
source language term. One of the major differ-
ences of the technique of (Cao and Li, 2002) and
the one proposed in this paper is that in (Cao and
Li, 2002), they do not use the domain/topic spe-
cific corpus.
7 Conclusion
This paper proposed a method of compositional
translation estimation for technical terms using
the domain/topic specific corpus, and through
the experimental evaluation, showed that the do-
main/topic specific corpus contributes to improv-
ing the performance of compositional translation
estimation.
Future works include the followings: first, in
order to improve the proposed method with re-
spect to its coverage, for example, it is desir-
able to extend the bilingual constituents lexicons
and to introduce constituent reordering rules with
prepositions into the process of compositional
translation candidate generation. Second, we are
planning to introduce a mechanism of re-ranking
translation candidates based on the frequencies of
technical terms in the domain/topic specific cor-
pus.
References
Y. Cao and H. Li. 2002. Base noun phrase translation using
Web data and the EM algorithm. In Proc. 19th COLING,
pages 127?133.
Atsushi Fujii and Tetsuya Ishikawa. 2001. Japanese/english
cross-language information retrieval: Exploration of
query translation and transliteration. Computers and the
Humanities, 35(4):389?420.
P. Fung and L. Y. Yee. 1998. An IR approach for translating
new words from nonparallel, comparable texts. In Proc.
17th COLING and 36th ACL, pages 414?420.
Y. Matsumoto and T. Utsuro. 2000. Lexical knowledge ac-
quisition. In R. Dale, H. Moisl, and H. Somers, editors,
Handbook of Natural Language Processing, chapter 24,
pages 563?610. Marcel Dekker Inc.
R. Rapp. 1999. Automatic identification of word transla-
tions from unrelated English and German corpora. In
Proc. 37th ACL, pages 519?526.
S. Sato and Y. Sasaki. 2003. Automatic collection of related
terms from the web. In Proc. 41st ACL, pages 121?124.
119
Automatic Collection of Related Terms from the Web
Satoshi Sato and Yasuhiro Sasaki
Graduate School of Informatics
Kyoto University
Sakyo, Kyoto, 606-8501
Japan
sato@i.kyoto-u.ac.jp, sasaki@pine.kuee.kyoto-u.ac.jp
Abstract
This paper proposes a method of collect-
ing a dozen terms that are closely re-
lated to a given seed term. The proposed
method consists of three steps. The first
step, compiling corpus step, collects texts
that contain the given seed term by us-
ing search engines. The second step, au-
tomatic term recognition, extracts impor-
tant terms from the corpus by using Naka-
gawa?s method. These extracted terms be-
come the candidates for the final step. The
final step, filtering step, removes inappro-
priate terms from the candidates based on
search engine hits. An evaluation result
shows that the precision of the method is
85%.
1 Introduction
This study aims to realize an automatic method of
collecting technical terms that are related to a given
seed term. In case ?natural language processing? is
given as a seed term, the method is expected to col-
lect technical terms that are related to natural lan-
guage processing, such as morphological analysis,
parsing, information retrieval, and machine transla-
tion. The target application of the method is auto-
matic or semi-automatic compilation of a glossary or
technical-term dictionary for a certain domain. Re-
cursive application of the method enables to collect a
list of terms that are used in a certain domain: the list
becomes a glossary of the domain. A technical-term
dictionary can be compiled by adding an explanation
for every term in the glossary, which is performed by
term explainer (Sato, 2001).

?
?
?
a seed term
s
?
Compiling
corpus
??
?

?
?
?
corpus
C
s
?
?
?
?
?
the Web
??
ATR
?

?
?
?
related terms
T
? Filtering ?

?
?
?
candidates
X
Figure 1: System configuration
Automatic acquisition of technical terms in a cer-
tain domain has been studied as automatic term
recognition (Kageura and Umino, 1996; Kageura
and Koyama, 2000), and the methods require a large
corpus that are manually prepared for a target do-
main. In contrast, our system, which is proposed in
this paper, requires only a seed word; from this seed
word, the system compiles a corpus from the Web by
using search engines and produces a dozen technical
terms that are closely related to the seed word.
2 System
Figure 1 shows the configuration of the system. The
system consists of three steps: compiling corpus, au-
tomatic term recognition (ATR), and filtering. This
system is implemented for Japanese language.
2.1 Compiling corpus
The first step, compiling corpus, produces a corpus
C
s
for a seed term s. In general, compiling corpus is
to select the appropriate passages from a document
set. We use the Web for the document set and se-
lect the passages that describe s for the corpus. The
actual procedure of compiling corpus is:
1. Web page collection
For a given seed term s, the system first makes
four queries: ?s toha?, ?s toiu?, ?s ha?, and
?s?, where toha, ha, and toiu are Japanese
functional words that are often used for defin-
ing or explaining a term. Then, the system col-
lects the top K (= 100) pages at maximum for
each query by using a search engine. If a col-
lected page has a link whose anchor string is s,
the system collects the linked page too.
2. Sentence extraction
The system decomposes each page into sen-
tences, and extracts the sentences that contain
the seed term s.
The reason why we use the additional three queries
is that they work efficiently for collecting web pages
that contain a definition or an explanation of s. We
use two search engines, Goo1 and Infoseek2. We
send all four queries to Goo but only the query ?s? to
Infoseek, because Infoseek usually returns the same
result for the four queries. A typical corpus size is
about 500 sentences.
2.2 Automatic term recognition
The second step, automatic term recognition (ATR),
extracts important terms from the compiled cor-
pus. We use Nakagawa?s ATR method (Nakagawa,
2000), which works well for Japanese text, with
some modifications. The procedure is as follows.
1. Generation of term list
To make the term list L by extracting every
term that is a noun or a compound noun from
the compiled corpus.
2. Selection by scoring
To select the top N (= 30) terms from the list L
by using a scoring function.
For the scoring function of a term x, we use
the following function, which is multiplying Nak-
agawa?s Imp
1
by a frequency factor F (x, L)?.
score(x, L) = Imp
1
(x, L)? F (x, L)?
F (x, L) =
{
1 if x is a single noun
?frequency of x in L? otherwise
1www.goo.ne.jp
2www.infoseek.co.jp
While Nakagawa?s Imp
1
does not consider term fre-
quency, this function does: ? is a parameter that con-
trols how strongly the frequency is considered. We
use ? = 0.5 in experiments.
The result of automatic term recognition for ???
???? (natural language processing)? is shown in
the column candidate in Table 1.
2.3 Filtering
The filtering step is necessary because the obtained
candidates are noisy due to the small corpus size.
This step consists of two tests: technical-term test
and relation test.
2.3.1 Technical-term test
The technical-term test removes the terms that do
not satisfy conditions of technical terms. We employ
the following four conditions that a technical term
should satisfy.
1. The term is sometimes or frequently used in a
certain domain.
2. The term is not a general term.
3. There is a definition or explanation of the term.
4. There are several technical terms that are re-
lated to the term.
We have implemented the checking program of the
first two conditions in the system: the third condition
can be checked by integrating the system with term
explainer (Sato, 2001), which produces a definition
or explanation of a given term; the fourth condition
can be checked by using the system recursively.
There are several choices for implementing the
checking program. Our choice is to use the Web via
a search engine. A search engine returns a number,
hit, which is an estimated number of pages that sat-
isfy a given query. In case the query is a term, its hit
is the number of pages that contain the term on the
Web. We use the following notation.
H(x) = ?the number of pages that contain
the term x?
The number H(x) can be used as an estimated
frequency of the term x on the Web, i.e., on the
hugest set of documents. Based on this number, we
can infer whether a term is a technical term or not:
in case the number is very small, the term is not a
Table 1: Result for ?natural language processing?
candidate Tech. Rel.
?????? (natural langauge pro-
cessing; NLP)
- -
???????? (NLP technology) ? ?
?????????? (NLP system) ? ?
???????? (NLP research)
??????? (NLP study) ? ?
?? (processing)
?????? (text processing) ?
???? (research and development)
?????? (Information Processing
Society of Japan; IPSJ)
? ?
???? (semantic processing) ? ?
???? (speech processing) ?
?????? (speech information pro-
cessing)
? ?
???? (information processing)
???????? (NLP domain)
???? (research field) ? ?*
???? (parsing) ? ?
???? (information retrieval) ? ?
????????? (SIGNLP) ? ?
???? (speech recognition) ? ?
???? (machine translation) ? ?
????? (morphological analysis) ? ?
???????? (information pro-
cessing system)
?
?? (research)
???? (semantic analysis) ? ?
????????? (chair of NLP) ? ?*
???????????? (NLP sym-
posium)
?????? (application system) ?
?????? (knowledge information
processing)
? ?
?? (language)
?? (information)
technical term because it does not satisfy the first
condition; in case the number is large enough, the
term is probably a general term so that it is not a
technical term. Two parameters, Min and Max, are
necessary here. We have decided that we use search
engine Goo for H(x), and determined Min = 100
and Max = 100, 000, based on preliminary experi-
ments.
In summary, our technical-term test is:
If 100 ? H(x) ? 100, 000
then x is a technical term.
2.3.2 Relation test
The relation test removes the terms that are not
closely related to the seed term from the candidates.
Our conditions of ?x is closely related to s? is: (1)
x is a broader or narrower term of s; or (2) relation
degree between x and s is high enough, i.e., above a
given threshold.
The candidate terms can be classified from the
viewpoint of term composition. Under a given seed
term, we introduce the following five types for clas-
sification.
Type 0 the given seed term s: e.g., ?? ?? ??
(natural language processing)
Type 1 a term that contains s: e.g., ???????
??? (natural language processing system)
Type 2 a term that is a subsequence of s: e.g., ??
?? (natural language)
Type 3 a term that contains at least a component of
s: e.g., ???? (language analysis)
Type 4 others: e.g., ???? (parsing)
The reason why we introduce these types is that
the following rules are true with a few exception: (1)
A type-1 term is a narrower term of the seed term
s; (2) A type-2 term is a broader term of the seed
term s. We assume that these rules are always true:
they are used to determine whether x is a broader or
narrower term of s.
To measure the relation degree, we use con-
ditional probabilities, which are calculated from
search engine hits.
P (s|x) =
H(s? x)
H(x)
P (x|s) =
H(s? x)
H(s)
where
H(s? x) = ?the number of pages that contain
both s and x?
One of two probabilities is equal to or greater than
a given threshold Z, the system decides that x is
closely related to s. We use Z = 0.05 as the thresh-
old.
In summary, our relation test is:
If x is type-1 or type-2; or
P (s|x) ? 0.05 or P (x|s) ? 0.05
then x is closely related to s.
The result of the filtering step for ??????
? (natural language processing)? is in Table 1; a
Table 2: Experimental Result
Evaluation I Evaluation II
domain correct incorrect total S F A C R total
natural language processing 101 (93%) 8 ( 7%) 109 6 3 14 11 8 43
Japanese language 71 (81%) 17(19%) 88 7 0 19 5 1 32
information technology 113 (88%) 15 (12%) 128 10 5 27 13 0 55
current topics 106 (91%) 10 ( 9%) 116 2 0 13 19 5 39
persons in Japanese history 128 (76%) 41 (24%) 169 18 0 23 1 0 42
Total 519 (85%) 91(15%) 610 43 8 96 49 14 210
check mark ?
?
? indidates that the term passed the
test. Twenty terms out of the thrity candidate terms
passed the first techinical-term test (Tech.) and six-
teen terms out of the twenty terms passed the second
relation test (Rel.). The final result includes two in-
appropriate terms, which are indicated by ?*?.
3 Experiments and Disucssion
First, we examined the precision of the system. We
prepared fifty seed terms in total: ten terms for
each of five genres; natural language processing,
Japanese language, information technology, current
topics, and persons in Japanese history. From these
fifty terms, the system collected 610 terms in total;
the average number of output terms per input is 12.2
terms. We checked whether each of the 610 terms
is a correct related term of the original seed term by
hand. The result is shown in the left half (Evaluation
I) of Table 2. In this evaluation, 519 terms out of 610
terms were correct: the precision is 85%. From this
high value, we conclude that the system can be used
as a tool that helps us compile a glossary.
Second, we tried to examine the recall of the
system. It is impossible to calculate the actual re-
call value, because the ideal output is not clear and
cannot be defined. To estimate the recall, we first
prepared three to five target terms that should be
collected from each seed word, and then checked
whether each of the target terms was included in
the system output. We counted the number of tar-
get terms in the following five cases. The right half
(Evaluation II) in Table 2 shows the result.
S: the target term was collected by the system.
F: the target term was removed in the filtering step.
A: the target term existed in the compiled corpus,
but was not extracted by automatic term extrac-
tion.
C: the target term existed in the collected web
pages, but did not exist in the compiled corpus.
R: the target term did not exist on the collected web
pages.
Only 43 terms (20%) out of 210 terms were col-
lected by the system. This low recall primarily
comes from the failure of automatic term recogni-
tion (case A in the above classification). Improve-
ment of this step is necessary.
We also examined whether each of the 210 target
terms passes the filtering step. The result was that
133 (63%) terms passed; 44 terms did not satisfy
the condition H(x) ? 100; 15 terms did not satisfy
the condition H(x) ? 100, 000; and 18 terms did
not pass the relation test. These experimental results
suggest that the ATR step may be replaced with a
simple and exhaustive term collector from a corpus.
We have a plan to examine this possibility next.
References
Kyo Kageura and Teruo Koyama. 2000. Special issue:
Japanese term extraction. Terminolgy, 6(2).
Kyo Kageura and Bin Umino. 1996. Methods of au-
tomatic term recognition: A review. Terminology,
3(2):259?289.
Hiroshi Nakagawa. 2000. Automatic term recognition
based on statistics of compound nouns. Terminology,
6(2):195?210.
Satoshi Sato. 2001. Automated editing of hypertext
re?sume? from the world wide web. In Proceedings
of 2001 Symposium on Applications and the Internet
(SAINT 2001), pages 15?22.
A Comparative Study on Compositional Translation Estimation
using a Domain/Topic-Specific Corpus collected from the Web
Masatsugu Tonoike?, Mitsuhiro Kida?, Toshihiro Takagi?, Yasuhiro Sasaki?,
Takehito Utsuro??, Satoshi Sato? ? ?
?Graduate School of Informatics, Kyoto University
Yoshida-Honmachi, Sakyo-ku, Kyoto 606-8501, Japan
??Graduate School of Systems and Information Engineering, University of Tsukuba
1-1-1, Tennodai, Tsukuba, 305-8573, Japan
? ? ?Graduate School of Engineering, Nagoya University
Furo-cho, Chikusa-ku, Nagoya 464-8603, Japan
Abstract
This paper studies issues related to the
compilation of a bilingual lexicon for tech-
nical terms. In the task of estimating bilin-
gual term correspondences of technical
terms, it is usually rather difficult to find
an existing corpus for the domain of such
technical terms. In this paper, we adopt
an approach of collecting a corpus for the
domain of such technical terms from the
Web. As a method of translation esti-
mation for technical terms, we employ a
compositional translation estimation tech-
nique. This paper focuses on quantita-
tively comparing variations of the compo-
nents in the scoring functions of composi-
tional translation estimation. Through ex-
perimental evaluation, we show that the
domain/topic-specific corpus contributes
toward improving the performance of the
compositional translation estimation.
1 Introduction
This paper studies issues related to the compilation
of a bilingual lexicon for technical terms. Thus
far, several techniques of estimating bilingual term
correspondences from a parallel/comparable cor-
pus have been studied (Matsumoto and Utsuro,
2000). For example, in the case of estimation from
comparable corpora, (Fung and Yee, 1998; Rapp,
1999) proposed standard techniques of estimating
bilingual term correspondences from comparable
corpora. In their techniques, contextual similarity
between a source language term and its translation
candidate is measured across the languages, and
all the translation candidates are re-ranked accord-
ing to their contextual similarities. However, there
are limited number of parallel/comparable corpora
that are available for the purpose of estimating
bilingual term correspondences. Therefore, even
if one wants to apply those existing techniques to
the task of estimating bilingual term correspon-
dences of technical terms, it is usually rather dif-
ficult to find an existing corpus for the domain of
such technical terms.
On the other hand, compositional translation es-
timation techniques that use a monolingual corpus
(Fujii and Ishikawa, 2001; Tanaka and Baldwin,
2003) are more practical. It is because collecting a
monolingual corpus is less expensive than collect-
ing a parallel/comparable corpus. Translation can-
didates of a term can be compositionally generated
by concatenating the translation of the constituents
of the term. Here, the generated translation candi-
dates are validated using the domain/topic-specific
corpus.
In order to assess the applicability of the com-
positional translation estimation technique, we
randomly pick up 667 Japanese and English tech-
nical term translation pairs of 10 domains from ex-
isting technical term bilingual lexicons. We then
manually examine their compositionality, and find
out that 88% of them are actually compositional,
which is a very encouraging result.
But still, it is expensive to collect a
domain/topic-specific corpus. Here, we adopt
an approach of using the Web, since documents
of various domains/topics are available on the
Web. When validating translation candidates
using the Web, roughly speaking, there exist the
following two approaches. In the first approach,
translation candidates are validated through
the search engine (Cao and Li, 2002). In the
second approach, a domain/topic-specific corpus
is collected from the Web in advance and fixed
11
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
web
(language T )
web
(language T )
Figure 1: Compilation of a Domain/Topic-
Specific Bilingual Lexicon using the Web
before translation estimation, then generated
translation candidates are validated against the
domain/topic-specific corpus (Tonoike et al,
2005). The first approach is preferable in terms of
coverage, while the second is preferable in terms
of computational efficiency. This paper mainly
focuses on quantitatively comparing the two
approaches in terms of coverage and precision of
compositional translation estimation.
More specifically, in compositional translation
estimation, we decompose the scoring function
of a translation candidate into two components:
bilingual lexicon score and corpus score. In this
paper, we examine variants for those components
and define 9 types of scoring functions in total.
Regarding the above mentioned two approaches
to validating translation candidates using the Web,
the experimental result shows that the second
approach outperforms the first when the correct
translation does exist in the corpus. Furthermore,
we examine the methods that combine two scor-
ing functions based on their agreement. The ex-
perimental result shows that it is quite possible to
achieve precision much higher than those of single
scoring functions.
2 Overall framework
The overall framework of compiling a bilingual
lexicon from the Web is illustrated as in Figure 1.
Suppose that we have sample terms of a specific
domain/topic, then the technical terms that are to
be listed as the headwords of a bilingual lexicon
are collected from the Web by the related term col-
lection method of (Sato and Sasaki, 2003). These
collected technical terms can be divided into three
subsets depending on the number of translation
candidates present in an existing bilingual lexicon,
i.e., the subset XUS of terms for which the number
of translations in the existing bilingual lexicon is
one, the subset XMS of terms for which the number
of translations is more than one, and the subset YS
of terms that are not found in the existing bilingual
lexicon (henceforth, the union XUS ? XMS will be
denoted as XS). Here, the translation estimation
task here is to estimate translations for the terms
of the subsets XMS and YS . A new bilingual lex-
icon is compiled from the result of the translation
estimation for the terms of the subsets XMS and
YS as well as the translation pairs that consist of
the terms of the subset XUS and their translations
found in the existing bilingual lexicon.
For the terms of the subset XMS , it is required
that an appropriate translation is selected from
among the translation candidates found in the ex-
isting bilingual lexicon. For example, as a trans-
lation of the Japanese technical term ?????,?
which belongs to the logic circuit domain, the term
?register? should be selected but not the term ?reg-
ista? of the football domain. On the other hand, for
the terms of YS , it is required that the translation
candidates are generated and validated. In this pa-
per, out of the above two tasks, we focus on the
latter of translation candidate generation and val-
idation using the Web. As we introduced in the
previous section, here we experimentally compare
the two approaches to validating translation candi-
dates. The first approach directly uses the search
engine, while the second uses the domain/topic-
specific corpus, which is collected in advance from
the Web. Here, in the second approach, we use the
term of XUS , which has only one translation in the
existing bilingual lexicon. The set of translations
of the terms of the subset XUS is denoted as XUT .
Then, in the second approach, the domain/topic-
specific corpus is collected from the Web using the
terms of the set XUT .
3 Compositional Translation Estimation
for Technical Terms
3.1 Overview
An example of compositional translation estima-
tion for the Japanese technical term ??????
?? is illustrated in Figure 2. First, the Japanese
technical term ???????? is decomposed
into its constituents by consulting an existing
bilingual lexicon and retrieving Japanese head-
12
? application(1)
? practical(0.3)
? applied(1.6)
? action(1)
? activity(1)
? behavior(1)
? analysis(1)
? diagnosis(1)
? assay(0.3)
? behavior analysis(10)
??Compositional generation 
of translation candidate
? applied behavior analysis(17.6)
? application behavior analysis(11)
? applied behavior diagnosis(1)
??Decompose source term into constituents  
??Translate constituents into target language      process
?? ?? ??a
?? ????b
Generated translation candidates
?(1.6?1?1)+(1.6?10)
? application(1)
? practical(0.3)
? applied(1.6)
Figure 2: Compositional Translation Estimation
for the Japanese Technical Term ????????
words.1 In this case, the result of this decompo-
sition can be given as in the cases ?a? and ?b?
(in Figure 2). Then, each constituent is translated
into the target language. A confidence score is as-
signed to the translation of each constituent. Fi-
nally, translation candidates are generated by con-
catenating the translation of those constituents ac-
cording to word ordering rules considering prepo-
sitional phrase construction.
3.2 Collecting a Domain/Topic-Specific
Corpus
When collecting a domain/topic-specific corpus of
the language T , for each technical term xUT in the
set XUT , we collect the top 100 pages obtained
from search engine queries that include the term
xUT . Our search engine queries are designed such
that documents that describe the technical term xUT
are ranked high. For example, an online glossary
is one such document. When collecting a Japanese
corpus, the search engine ?goo?2 is used. The spe-
cific queries that are used in this search engine
are phrases with topic-marking postpositional par-
ticles such as ?xUT ??,? ?xUT ???,? ?xUT ?,?
and an adnominal phrase ?xUT ?,? and ?xUT .?
3.3 Translation Estimation
3.3.1 Compiling Bilingual Constituents
Lexicons
This section describes how to compile bilingual
constituents lexicons from the translation pairs of
1Here, as an existing bilingual lexicon, we use Ei-
jiro(http://www.alc.co.jp/) and bilingual constituents lexicons
compiled from the translation pairs of Eijiro (details to be de-
scribed in the next section).
2http://www.goo.ne.jp/
 
applied mathematics : ?? ??
applied science : ?? ??
applied robot : ?? ????
.
.
. frequency
? ??
applied : ?? : 40
 
Figure 3: Example of Estimating Bilingual Con-
stituents Translation Pair (Prefix)
the existing bilingual lexicon Eijiro. The under-
lying idea of augmenting the existing bilingual
lexicon with bilingual constituents lexicons is il-
lustrated in Figure 3. Suppose that the existing
bilingual lexicon does not include the translation
pair ?applied : ??,? while it includes many
compound translation pairs with the first English
word ?applied? and the first Japanese word ??
?.?3 In such a case, we align those translation
pairs and estimate a bilingual constituent transla-
tion pair which is to be collected into a bilingual
constituents lexicon.
More specifically, from the existing bilingual
lexicon, we first collect translation pairs whose
English terms and Japanese terms consist of two
constituents into another lexicon P
2
. We com-
pile the ?bilingual constituents lexicon (prefix)?
from the first constituents of the translation pairs
in P
2
and compile the ?bilingual constituents lex-
icon (suffix)? from their second constituents. The
number of entries in each language and those of
the translation pairs in these lexicons are shown in
Table 1.
The result of our assessment reveals that only
48% of the 667 translation pairs mentioned in Sec-
tion 1 can be compositionally generated by using
Eijiro, while the rate increases up to 69% using
both Eijiro and ?bilingual constituents lexicons.?4
3.3.2 Score of Translation Candidates
This section gives the definition of the scores
of a translation candidate in compositional trans-
lation estimation.
First, let ys be a technical term whose transla-
tion is to be estimated. We assume that ys is de-
3Japanese entries are supposed to be segmented into a
sequence of words by the morphological analyzer JUMAN
(http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html).
4In our rough estimation, the upper bound of this rate
is approximately 80%. An improvement from 69% to 80%
could be achieved by extending the bilingual constituents lex-
icons.
13
Table 1: Numbers of Entries and Translation Pairs
in the Lexicons
lexicon # of entries # of translationEnglish Japanese pairs
Eijiro 1,292,117 1,228,750 1,671,230
P
2
217,861 186,823 235,979
B
P
37,090 34,048 95,568
B
S
20,315 19,345 62,419
B 48,000 42,796 147,848
Eijiro : existing bilingual lexicon
P
2
: entries of Eijiro with two constituents
in both languages
B
P
: bilingual constituents lexicon (prefix)
B
S
: bilingual constituents lexicon (suffix)
B : bilingual constituents lexicon (merged)
composed into their constituents as below:
ys = s1, s2, ? ? ? , sn (1)
where each si is a single word or a sequence of
words.5 For ys, we denote a generated translation
candidate as yt.
yt = t1, t2, ? ? ? , tn (2)
where each ti is a translation of si. Then the trans-
lation pair ?ys, yt? is represented as follows.
?ys, yt? = ?s1, t1?, ?s2, t2?, ? ? ? , ?sn, tn? (3)
The score of a generated translation candidate is
defined as the product of a bilingual lexicon score
and a corpus score as follows.
Q(ys, yt) = Qdict(ys, yt) ? Qcoprus(yt) (4)
Bilingual lexicon score measures appropriateness
of correspondence of ys and yt. Corpus score
measures appropriateness of the translation candi-
date yt based on the target language corpus. If a
translation candidate is generated from more than
one sequence of translation pairs, the score of the
translation candidate is defined as the sum of the
score of each sequence.
Bilingual Lexicon Score
In this paper, we compare two types of bilin-
gual lexicon scores. Both scores are defined as the
product of scores of translation pairs included in
the lexicons presented in the previous section as
follows.
5Eijiro has both single word entries and compound word
entries.
? Frequency-Length
Qdict(ys, yt) =
n
?
i=1
q(?si, ti?) (5)
The first type of bilingual lexicon scores is re-
ferred to as ?Frequency-Length.? This score is
based on the length of translation pairs and the fre-
quencies of translation pairs in the bilingual con-
stituent lexicons (prefix,suffix) BP , BS in Table 1.
In this paper, we first assume that the translation
pairs follow certain preference rules and that they
can be ordered as below:
1. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of two or more constituents.
2. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are high.
3. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of exactly one constituent.
4. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are not
high.
As the definition of the confidence score
q(?s, t?) of a translation pair ?s, t?, we use the fol-
lowing:
q(?s, t?) =
?
?
?
10
(compo(s)?1) (?s, t? in Eijiro)
log
10
fp(?s, t?) (?s, t? in BP )
log
10
fs(?s, t?) (?s, t? in BS)
(6)
, where compo(s) denotes the word count of s,
fp(?s, t?) represents the frequency of ?s, t? as the
first constituent in P
2
, and fs(?s, t?) represents the
frequency of ?s, t? as the second constituent in P
2
.
? Probability
Qdict(ys, yt) =
n
?
i=1
P (si|ti) (7)
The second type of bilingual lexicon scores is re-
ferred to as ?Probability.? This score is calcu-
lated as the product of the conditional probabili-
ties P (si|ti). P (s|t) is calculated using bilingual
lexicons in Table 1.
P (s|t) =
fprob(?s, t?)
?
s
j
fprob(?sj , t?)
(8)
14
Table 2: 9 Scoring Functions of Translation Candidates and their Components
bilingual lexicon score corpus score corpus
score ID freq-length probability probability frequency occurrence off-line on-line
(search engine)
A prune/final prune/final o
B prune/final prune/final o
C prune/final prune/final o
D prune/final prune o
E prune/final
F prune/final final prune o
G prune/final prune/final o
H prune/final final o
I prune/final final o
fprob(?s, t?) denotes the frequency of the transla-
tion pair ?s, t? in the bilingual lexicons as follows:
fprob(?s, t?) =
{
10 (?s, t? in Eijiro)
fB(?s, t?) (?s, t? in B)
(9)
Note that the frequency of a translation pair in Ei-
jiro is regarded as 106 and fB(?s, t?) denotes the
frequency of the translation pair ?s, t? in the bilin-
gual constituent lexicon B.
Corpus Score
We evaluate three types of corpus scores as fol-
lows.
? Probability: the occurrence probability of yt
estimated by the following bi-gram model
Qcorpus(yt) = P (t1) ?
n
?
i=1
P (ti+1|ti) (10)
? Frequency: the frequency of a translation
candidate in a target language corpus
Qcorpus(yt) = freq(yt) (11)
? Occurrence: whether a translation candidate
occurs in a target language corpus or not
Qcorpus(yt) =
?
?
?
?
?
1 yt occurs in a corpus
0 yt does not occur
in a corpus
(12)
6It is necessary to empirically examine whether or not the
definition of the frequency of a translation pair in Eijiro is
appropriate.
Variation of the total scoring functions
As shown in Table 2, in this paper, we examine
the 9 combinations of the bilingual lexicon scores
and the corpus scores. In the table, ?prune? indi-
cates that the score is used for ranking and pruning
sub-sequences of generated translation candidates
in the course of generating translation candidates
using a dynamic programming algorithm. ?Final?
indicates that the score is used for ranking the fi-
nal outputs of generating translation candidates.
In the column ?corpus?, ?off-line? indicates that
a domain/topic-specific corpus is collected from
the Web in advance and then generated transla-
tion candidates are validated against this corpus.
?On-line? indicates that translation candidates are
directly validated through the search engine.
Roughly speaking, the scoring function ?A? cor-
responds to a variant of the model proposed by
(Fujii and Ishikawa, 2001). The scoring func-
tion ?D? is a variant of the model proposed by
(Tonoike et al, 2005) and ?E? corresponds to the
bilingual lexicon score of the scoring function ?D?.
The scoring function ?I? is intended to evaluate the
approach proposed in (Cao and Li, 2002).
3.3.3 Combining Two Scoring Functions
based on their Agreement
In this section, we examine the method that
combines two scoring functions based on their
agreement. The two scoring functions are selected
out of the 9 functions introduced in the previous
section. In this method, first, confidence of trans-
lation candidates of a technical term are measured
by the two scoring functions. Then, if the first
ranked translation candidates of both scoring func-
tions agree, this method outputs the agreed trans-
lation candidate. The purpose of introducing this
method is to prefer precision to recall.
15
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
domain/topic
specific
corpus
(language T )
validating
translation
candidates
web
(language T )
web
(language T )
Figure 4: Experimental Evaluation of Translation
Estimation for Technical Terms with/without the
Domain/Topic-Specific Corpus (taken from Fig-
ure 1)
4 Experiments and Evaluation
4.1 Translation Pairs for Evaluation
In our experimental evaluation, within the frame-
work of compiling a bilingual lexicon for techni-
cal terms, we evaluate the translation estimation
portion that is indicated by the bold line in Fig-
ure 4. In this paper, we simply omit the evalua-
tion of the process of collecting technical terms to
be listed as the headwords of a bilingual lexicon.
In order to evaluate the translation estimation por-
tion, terms are randomly selected from the 10 cate-
gories of existing Japanese-English technical term
dictionaries listed in Table 3, for each of the sub-
sets XUS and YS (here, the terms of YS that consist
of only one word or morpheme are excluded). As
described in Section 1, the terms of the set XUT (the
set of translations for the terms of the subset XUS )
is used for collecting a domain/topic-specific cor-
pus from the Web. As shown in Table 3, size of the
collected corpora is 48MB on the average. Trans-
lation estimation evaluation is to be conducted for
the subset YS . For each of the 10 categories, Ta-
ble 3 shows the sizes of the subsets XUS and YS ,
and the rate of including correct translation within
the collected domain/topic-specific corpus for YS .
In the following, we show the evaluation results
with the source language S as English and the tar-
get language T as Japanese.
4.2 Evaluation of single scoring functions
This section gives the results of evaluating single
scoring functions A ? I listed in Table 2.
Table 4 shows three types of experimental re-
sults. The column ?the whole set YS? shows the
results against the whole set YS . The column
?generatable? shows the results against the trans-
lation pairs in YS that can be generated through
the compositional translation estimation process.
69% of the terms in ?the whole set YS? belongs
to the set ?generatable?. The column ?gene.-exist?
shows the result against the source terms whose
correct translations do exist in the corpus and that
can be generated through the compositional trans-
lation estimation process. 50% of the terms in ?the
whole set YS? belongs to the set ?gene.-exist?. The
column ?top 1? shows the correct rate of the first
ranked translation candidate. The column ?top 10?
shows the rate of including the correct candidate
within top 10.
First, in order to evaluate the effectiveness of
the approach of validating translation candidates
by using a target language corpus, we compare the
scoring functions ?D? and ?E?. The difference be-
tween them is whether or not they use a corpus
score. The results for the whole set YS show that
using a corpus score, the precision improves from
33.9% to 43.0%. This result supports the effec-
tiveness of the approach of validating translation
candidates using a target language corpus.
As can be seen from these results for the whole
set YS , the correct rate of the scoring function ?I?
that directly uses the web search engine in the cal-
culation of its corpus score is higher than those
of other scoring functions that use the collected
domain/topic-specific corpus. This is because,
for the whole set YS , the rate of including cor-
rect translation within the collected domain/topic-
specific corpus is 72% on the average, which is
not very high. On the other hand, the results of the
column ?gene.-exist? show that if the correct trans-
lation does exist in the corpus, most of the scor-
ing functions other than ?I? can achieve precisions
higher than that of the scoring function ?I?. This
result supports the effectiveness of the approach
of collecting a domain/topic-specific corpus from
the Web in advance and then validating generated
translation candidates against this corpus.
4.3 Evaluation of combining two scoring
functions based on their agreement
The result of evaluating the method that combines
two scoring functions based on their agreement is
shown in Table 5. This result indicates that com-
binations of scoring functions with ?off-line?/?on-
16
Table 3: Number of Translation Pairs for Evaluation (S=English)
dictionaries categories |Y
S
| |X
U
S
| corpus size C(S)
Electromagnetics 33 36 28MB 85%
McGraw-Hill Electrical engineering 45 34 21MB 71%
Optics 31 42 37MB 65%
Iwanami Programming language 29 37 34MB 93%Programming 29 29 33MB 97%
Dictionary of (Computer) 100 91 67MB 51%Computer
Anatomical Terms 100 91 73MB 86%
Dictionary of Disease 100 91 83MB 77%
250,000 Chemicals and Drugs 100 94 54MB 60%
medical terms Physical Science and Statistics 100 88 56MB 68%
Total 667 633 482MB 72%
McGraw-Hill : Dictionary of Scientific and Technical Terms
Iwanami : Encyclopedic Dictionary of Computer Science
C(S) : for Y
S
, the rate of including correct translations within the collected domain/topic-specific corpus
Table 4: Result of Evaluating single Scoring Functions
the whole set Y
S
(667 terms?100%) generatable (458 terms?69%) gene.-exist (333 terms?50%)
ID top 1 top 10 top 1 top 10 top 1 top 10
A 43.8% 52.9% 63.8% 77.1% 82.0% 98.5%
B 42.9% 50.7% 62.4% 73.8% 83.8% 99.4%
C 43.0% 58.0% 62.7% 84.5% 75.1% 94.6%
D 43.0% 47.4% 62.7% 69.0% 85.9% 94.6%
E 33.9% 57.3% 49.3% 83.4% 51.1% 84.1%
F 40.2% 47.4% 58.5% 69.0% 80.2% 94.6%
G 39.1% 46.8% 57.0% 68.1% 78.1% 93.4%
H 43.8% 57.3% 63.8% 83.4% 73.6% 84.1%
I 49.8% 57.3% 72.5% 83.4% 74.8% 84.1%
Table 5: Result of combining two scoring func-
tions based on their agreement
corpus combination precision recall F
?=1
A & I 88.0% 27.6% 0.420
off-line/ D & I 86.0% 29.5% 0.440
on-line F & I 85.1% 29.1% 0.434
H & I 58.7% 37.5% 0.457
A & H 86.0% 30.4% 0.450
F & H 80.6% 33.7% 0.476
off-line/ D & H 80.4% 32.7% 0.465
off-line A & D 79.0% 32.1% 0.456
A & F 74.6% 33.0% 0.457
D & F 68.2% 35.7% 0.469
line? corpus tend to achieve higher precisions than
those with ?off-line?/?off-line? corpus. This result
also shows that it is quite possible to achieve high
precisions even by combining scoring functions
with ?off-line?/?off-line? corpus (the pair ?A? and
?H?). Here, the two scoring functions ?A? and ?H?
are the one with frequency-based scoring func-
tions and that with probability-based scoring func-
tions, and hence, have quite different nature in the
design of their scoring functions.
5 Related Works
As a related work, (Fujii and Ishikawa, 2001) pro-
posed a technique for compositional estimation of
bilingual term correspondences for the purpose of
cross-language information retrieval. One of the
major differences between the technique of (Fu-
jii and Ishikawa, 2001) and the one proposed in
this paper is that in (Fujii and Ishikawa, 2001), in-
stead of a domain/topic-specific corpus, they use a
corpus containing the collection of technical pa-
pers, each of which is published by one of the
65 Japanese associations for various technical do-
mains. Another significant difference is that in
(Fujii and Ishikawa, 2001), they evaluate only the
performance of the cross-language information re-
trieval and not that of translation estimation.
(Cao and Li, 2002) also proposed a method
of compositional translation estimation for com-
pounds. In the method of (Cao and Li, 2002), the
translation candidates of a term are composition-
ally generated by concatenating the translation of
the constituents of the term and are validated di-
rectly through the search engine. In this paper,
we evaluate the approach proposed in (Cao and
Li, 2002) by introducing a total scoring function
17
that is based on validating translation candidates
directly through the search engine.
6 Conclusion
This paper studied issues related to the compila-
tion a bilingual lexicon for technical terms. In
the task of estimating bilingual term correspon-
dences of technical terms, it is usually rather dif-
ficult to find an existing corpus for the domain
of such technical terms. In this paper, we adopt
an approach of collecting a corpus for the do-
main of such technical terms from the Web. As
a method of translation estimation for technical
terms, we employed a compositional translation
estimation technique. This paper focused on quan-
titatively comparing variations of the components
in the scoring functions of compositional transla-
tion estimation. Through experimental evaluation,
we showed that the domain/topic specific corpus
contributes to improving the performance of the
compositional translation estimation.
Future work includes complementally integrat-
ing the proposed framework of compositional
translation estimation using the Web with other
translation estimation techniques. One of them is
that based on collecting partially bilingual texts
through the search engine (Nagata and others,
2001; Huang et al, 2005). Another technique
which seems to be useful is that of transliteration
of names (Knight and Graehl, 1998; Oh and Choi,
2005).
References
Y. Cao and H. Li. 2002. Base noun phrase translation using
Web data and the EM algorithm. In Proc. 19th COLING,
pages 127?133.
A. Fujii and T. Ishikawa. 2001. Japanese/english cross-
language information retrieval: Exploration of query
translation and transliteration. Computers and the Hu-
manities, 35(4):389?420.
P. Fung and L. Y. Yee. 1998. An IR approach for translating
new words from nonparallel, comparable texts. In Proc.
17th COLING and 36th ACL, pages 414?420.
F. Huang, Y. Zhang, and S. Vogel. 2005. Mining key phrase
translations from web corpora. In Proc. HLT/EMNLP,
pages 483?490.
K. Knight and J. Graehl. 1998. Machine transliteration.
Computational Linguistics, 24(4):599?612.
Y. Matsumoto and T. Utsuro. 2000. Lexical knowledge ac-
quisition. In R. Dale, H. Moisl, and H. Somers, editors,
Handbook of Natural Language Processing, chapter 24,
pages 563?610. Marcel Dekker Inc.
M. Nagata et al 2001. Using the Web as a bilingual dictio-
nary. In Proc. ACL-2001 Workshop on Data-driven Meth-
ods in Machine Translation, pages 95?102.
J. Oh and K. Choi. 2005. Automatic extraction of english-
korean translations for constituents of technical terms. In
Proc. 2nd IJCNLP, pages 450?461.
R. Rapp. 1999. Automatic identification of word translations
from unrelated English and German corpora. In Proc.
37th ACL, pages 519?526.
S. Sato and Y. Sasaki. 2003. Automatic collection of related
terms from the web. In Proc. 41st ACL, pages 121?124.
T. Tanaka and T. Baldwin. 2003. Translation selection for
japanese-english noun-noun compounds. In Proc. Ma-
chine Translation Summit IX, pages 378?85.
M. Tonoike, M. Kida, T. Takagi, Y. Sasaki, T. Utsuro, and
S. Sato. 2005. Effect of domain-specific corpus in com-
positional translation estimation for technical terms. In
Proc. 2nd IJCNLP, Companion Volume, pages 116?121.
18
