Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 24?31,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
 
 
Analysis and Development of Urdu POS Tagged Corpus 
 
Ahmed Muaz 
Center for Research in Urdu 
Language Processing 
NUCES, Pakistan 
ahmed.muaz@nu.edu.pk 
 
Aasim Ali 
Center for Research in Urdu 
Language Processing,  
NUCES, Pakistan 
aasim.ali@nu.edu.pk 
 
Sarmad Hussain 
Center for Research in Urdu 
Language Processing 
NUCES, Pakistan 
sarmad.hussain@nu.edu.pk
 
Abstract 
In this paper, two corpora of Urdu (with 110K 
and 120K words) tagged with different POS 
tagsets are used to train TnT and Tree taggers. 
Error analysis of both taggers is done to identi-
fy frequent confusions in tagging. Based on 
the analysis of tagging, and syntactic structure 
of Urdu, a more refined tagset is derived.  The 
existing tagged corpora are tagged with the 
new tagset to develop a single corpus of 230K 
words and the TnT tagger is retrained.  The re-
sults show improvement in tagging accuracy 
for individual corpora to 94.2% and also for 
the merged corpus to 91%.  Implications of 
these results are discussed.    
1 Introduction 
There is increasing amount of work on computa-
tional modeling of Urdu language.  As various 
groups work on the language, diversity in analy-
sis is also developed.  In this context, there has 
been some work on Urdu part of speech (POS) 
tagging, which has caused multiple tagsets to 
appear.  Thus, there is also need to converge 
these efforts.  
Current work compares the existing tag-
sets of Urdu being used for tagging corpora in an 
attempt to look at the differences, and understand 
the reasons for the variation.  The work then un-
dertakes experiments to develop a common tag-
set, which is syntactically and computationally 
coherent.  The aim is to make a robust tagset and 
then to port the differently tagged Urdu corpora 
onto the same tagset.  As Urdu already has very 
few annotated corpora, this will help consolidat-
ing them for better modeling. 
The next sections present the existing tag-
sets and accuracies of the POS taggers reported 
using them. Sections 4 and 5 present baseline 
experiment and the methodology used for the 
analysis for updating the tagset. Section 6 de-
scribes the proposed tagset. Section 7 reports 
experiments comparing the new tagset with ex-
isting ones. Section 8 discusses the results 
achieved and future directions. 
2 Relevant  Resources of Urdu 
2.1 Urdu Corpora  
Several annotated corpora have been built during 
last few years to facilitate computational 
processing for Urdu language.  The initial work 
was undertaken through EMILLE project to 
build multi-lingual corpora for South Asian lan-
guages (McEnery et al, 2000). They released 
200,000 words parallel corpus of English, Urdu, 
Bengali, Gujarati, Hindi and Punjabi. In addition, 
there are 1,640,000 words of Urdu text in this 
corpus. These text collections are also annotated 
with part of speech tags (Hardie 2003).  
Center for Research in Urdu Language 
Processing (CRULP1) gathered 18 million words 
corpus in order to build a lexicon. It has cleaned 
text from news websites from multiple domains 
(Ijaz et.al. 2007).  Following this work, a syntac-
tic tagset was developed based on work by exist-
ing grammarians and a corpus of 110,000 words 
was manually tagged. This annotated corpus is 
available through the center (Sajjad 2007, Hus-
sain 2008). 
Recently an English-Urdu parallel cor-
pus has also been developed by CRULP, by 
translating the first 140,000 words of PENN 
Treebank corpus. In addition, a tagset has also 
been designed following the PENN Treebank 
guidelines. These words have been tagged ma-
nually with this new tagset. This collection is 
also available from CRULP, and the tagset is still 
unpublished.  
2.2 Urdu Part of Speech tagsets 
Hardie (2003) developed the first POS tagset for 
Urdu using EAGLES guidelines for computa-
tional processing. The tagset contains 282 mor-
pho-syntactic tags, differentiating on the basis of 
number, gender and other morphological details 
                                                 
1 www.crulp.org  
24
 
 
in addition to the syntactic categories. Punctua-
tion marks are tagged as they are, and not in-
cluded in 282 tags. The tags include the gender 
and number agreement, in addition to syntactic 
information.  
The complications of Urdu tagset design 
are also discussed. One of these complexities is 
word segmentation issue of the language. Suffix-
es in Urdu are written with an orthographic 
space. Words are separated on the basis of space 
and so suffixes are treated same as lexical words. 
Hence it is hard to assign accurate tag for an au-
tomatic tagger. Although the tagset is designed 
considering details, but due to larger number of 
tags it is hard to get a high accuracy with a small 
sized corpus. Due to its morphological depen-
dence and its large size, this tagset is not consi-
dered in our analysis.   
Two much smaller tagsets are considered 
for this work.  They are compared in detail in 
Section 6.  The first tagset, containing 42 tags, is 
designed by Sajjad (2007), based on the work of 
Urdu grammarians (e.g. Schmidt 1999, Haq 
1987, Javed 1981, Platts 1909) and computation-
al work by Hardie (2003). The main features of 
the tagset include multiple pronouns (PP, KP, 
AKP, AP, RP, REP, G, and GR) and demonstra-
tives (PD, KD, AD, and RD). It has only one tag 
for all forms of verbs (VB), except for auxiliaries 
to show aspect (AA) and tense (TA) information 
about the verb. All noun types are assigned sin-
gle tag (NN) except for Proper Nouns (PN). It 
also has a special tag NEG to mark any occur-
rence negation words (?Yl? ?not? and ?? ?no? or 
?neither?) regardless of context. It also has a tag 
SE to mark every occurrence of ?5 (?from?) 
without considering the context. Another exam-
ple of such a context-free lexical tag is WALA to 
mark every occurrence (including all the inflec-
tions) of the word ???. This tagset is referred to as 
T1 subsequently in this paper.   
Recently Sajjad and Schmid (2009) used 
the tagged data of 107,514 words and carried out 
an experiment for tagger comparison.  A total of 
100,000 words are used as training set and rest as 
test data. Four taggers (TnT, Tree, RF and SVM) 
are trained using training corpus and then tested 
accordingly. Reported results of this work show 
that SVM tagger is the most accurate, showing 
94.15% correct prediction of tags. Remaining 
three taggers have accuracies of 93.02% (Tree 
tagger), 93.28% (RF tagger) and 93.40% (TnT 
tagger).   
 
Another tagset has recently been devel-
oped as a part of a project to develop English-
Urdu parallel corpus at CRULP, following the 
Penn Treebank guidelines (Santorini 1990).  It 
contains 46 tags, with fewer grades of pronouns 
(PR, PRP$, PRRF, PRRFP$, and PRRL) and 
demonstratives (DM and DMRL), as compared 
to T1. It has several tags for verbs on the basis of 
their forms and semantics (VB, VBI, VBL, 
VBLI, and VBT) in addition to the tags for aux-
iliaries showing aspect (AUXA) and tense 
(AUXT). The NN tag is assigned for both singu-
lar and plural nouns and includes adverbial kaf 
pronoun, kaf pronoun, and adverbial pronoun 
categories of T1. Yet, it has several other grades 
of common nouns (NNC, NNCR, NNCM). It 
also has two shades of Proper Nouns (NNP, 
NNPC), which are helpful in identifying phrase 
boundary of compound proper nouns. It also has 
a tag WALA that is assigned to every occurrence 
(and inflection) of word ??? )wala( . However, 
marking of token ?5 (?from?) is context depen-
dent: either it is CM when marking case or it is 
RBRP when occurring as an adverbial particle. 
This tagset is referred to as T2 subsequently in 
this paper. 
3 Tools and Resource Selection 
The decision of selecting the tagger, the tagset, 
and the data is the starting point for the task of 
POS tagging. This section gives details of the 
taggers chosen and the corpora used for the expe-
riments conducted.  
3.1 Selection of taggers 
There are a number of existing taggers available 
for tagging.  Two POS taggers are used in the 
initial step of this work to compare the initial 
tagging accuracies. 
 One of the selected taggers is Trigram-
and-Tag (TnT).  It is a trigram based HMM tag-
ger in which two preceding tags are used to find 
the transition probability of a tag. Brants (2000) 
tested PENN Treebank (English) and NEGRA 
(German) corpora and reported 96-97% accuracy 
of the tagger.  
Schmid (1994) proposed probabilistic 
POS tagger that uses decision trees to store the 
transition probabilities. The trained decision tree 
is used for identification of highest probable tags. 
Schmid reported an accuracy of 95-96% on 
PENN Treebank for this tagger. 
25
 
 
Both taggers give good accuracy for Ur-
du tagging, as reported by Sajjad and Schmid 
(2009). 
3.2 Data Used for Experimentation 
Corpora annotated with the different tagsets are 
acquired from CRULP. The corpus originally 
tagged with T1 tagset is referred to as C1 (news 
from non-business domain) and the corpus in-
itially annotated with T2 tagset is referred to as 
C2 (news from business domain), subsequently 
in the current work. Both C1 and C2 are taken 
and cleaned. The data is re-counted and approx-
imately 100,000 words are separated for training 
and rest are kept for testing.  The details of data 
are given in Tables 1 and 2 below. 
 
Table 1. Number of tokens in Urdu corpora 
 
Tokens C1 C2 
Training 101,428 102,454 
Testing 8,670 21,181 
Total 110,098 123,635 
 
Table 2. Number of sentences in Urdu corpora 
 
Sentences C1 C2 
Training 4,584 3,509 
Testing 404 755 
Total 4,988 4,264 
4 Baseline Estimation 
The comparison is initiated with training of ex-
isting tagsets on their respective annotated data 
(T1 on C1 and T2 on C2). Both corpora are 
tested on TnT and Tree Tagger to obtain the con-
fusion matrices for errors. These confusion ma-
trices are used to analyze misclassification of 
tags. TnT tagger shows that overall accuracy of 
using T1 with C1 is 93.01% and is significantly 
better than using T2 with C2, which gives 
88.13% accuracy.  Tree tagger is also trained on 
the corpora. The overall accuracy of T1 on C1 
(93.37%) is better than that of T2 on C2 
(90.49%).  The results are shown in Table 3. 
 
Table 3. Results of both tagsets on their respec-
tive corpora with TnT and Tree taggers 
 
  T1 on C1 T2 on C2 
TnT Tagger 93.01% 88.13% 
Tree Tagger 93.37% 90.49% 
 
The accuracies reported (for T1 on C1) by 
Sajjad and Schmid (2009) are comparable to 
these accuracies. They have reported 93.40% for 
TnT Tagger and 93.02% for Tree Tagger. 
Further experimentation is performed only 
using TnT tagger.  
5 Methodology 
The current work aims to build a larger corpus of 
around 230,000 manually tagged words for Urdu 
by combining C1 and C2. These collections are 
initially annotated with two different tagsets (T1 
and T2 respectively, and as described above). 
For this unification, it was necessary to indentify 
the differences in the tagsets on which these cor-
pora are annotated, analyzed the differences and 
then port them to unified tagset. 
The work starts with the baseline estimation 
(described in Section 4 above). The results of 
baseline estimation are used to derive a new tag-
set (detailed in Section 6 below), referred to as 
T3 in this paper. Then a series of experiments are 
executed to compare the performance of three 
tagsets (T1, T2, and T3) on data from two differ-
ent domains (C1 and C2), as reported in Section 
7 below and summarized in Table 4.  
 
Table 4. Summary of experiments conducted 
 
 Experiment Tagset Corpus
0 
Baseline Estimation: 
Original tagsets with 
respective corpora 
T1 C1 
T2 C2 
1 Experiment1: For 
comparison of results 
of T1 and T3 on C1 
T3 C1 
2 
Experiment2: For 
comparison of T1, T2 
and T3 on C2 
T3 C2 
T1 C2 
3 
Experiment3: Compar-
ison of T1 and T3 with 
no unknowns 
T3 C2 
T1 C2 
4 
Experiment4: Compar-
ison of T1 and T3 over 
complete corpus 
T3 C1+C2 
T1 C1+C2 
 
The performance of T1 on C1 is already 
better than T2 on C2, so the first comparison for 
the merged tagset T3 is with T1 on C1, which is 
the basis of the first experiment. Then the per-
formance of better performing tagsets (T1 and 
T3) are compared on the corpus C2 in the second 
26
 
 
experiment to compare them with T2. One possi-
ble reason of relatively better performance could 
be the difference in application of open classes 
for unknown words in the test data. Therefore, 
the third experiment is performed using the same 
data as in second experiment (i.e. corpus C2) 
with combined lexicon of training and test data 
(i.e. no unknown words). Finally, an experiment 
is conducted with the merged corpus. Following 
table summarizes these experiments. 
6 Tagset design 
After establishing the baseline, the existing tag-
sets are reviewed with the following guidelines: 
? Focus on the syntactic variation (instead of 
morphological or semantic motivation) to ei-
ther collapse existing tags or introduce new 
ones 
? Focus on word level tagging and not try to ac-
commodate phrase level tagging (e.g. to sup-
port chunking, compounding or other similar 
tasks) 
? Tag according to the syntactic role instead of 
having a fixed tag for a string, where possible 
? Use PENN Treebank nomenclature to keep the 
tagset easy to follow and share 
 
Comparison of T1 and T2 showed that there 
are 33 tags in both tagsets which represent same 
syntactic categories, as shown in Appendix A. 
The tag I (Intensifier) in T2 labels the words 
which are marked as ADV in T1. The words an-
notated as NNC, NNCR and NNCM (under T2) 
are all labeled as NN under T1. The words 
tagged as VBL, VBLI, VBI, and VBLI (under 
T2) are all labeled as VB under T1. Range of 
distinct tags for demonstratives of T1 are all 
mapped to DM in T2 except RD (of T1) which 
maps to DMRL (of T2). 
In order to identify the issues in tagging, a 
detailed error analysis of existing tagsets is per-
formed. Following tables represent the major tag 
confusions for tagging C2 with T2 using Tree 
and TnT taggers. 
 
Table 5. Major misclassifications in C2 with T2 
tagset using Tree tagger 
Tag 
Total 
tokens Errors  
Maximum  
misclassification
VB 888 214 183 VBL 
VBL 328 168 151 VB 
VBI 202 47 38 VBLI 
VBLI 173 52 46 VBI 
AUXT 806 145 121 VBT 
Table 6. Major misclassifications in C2 with T2 
tagset using TnT-tagger 
Tag 
Total 
tokens Error  
Maximum  
misclassification
VB 888 240 181 VBL 
VBL 328 154 135 VB 
VBI 202 46 34 VBLI 
VBLI 173 61 55 VBI 
AUXT 806 136 111 VBT 
 
The proposed tagset for Urdu part-of-
speech tagging contains 32 tags. The construc-
tion of new tagset (T3) is initiated by adopting 
T2 as the baseline, because T2 uses the tagging 
conventions of PENN Treebank. There are 17 
tags in T3 that are same as in T1 and T2. These 
tags (CC, CD, DM, DMRL, JJ, NN, OD, PM, 
PRP, PRP$, PRRF, PRRF$, PRRL, Q, RB, SM, 
SYM) are not discussed in detail. The complete 
tagset alng with short description and examples 
of each tag is given in Appendix B. 
RBRP (Adverbial Particle) and CM 
(Case Marker) are merged to make up a new tag 
PP (Postposition), so every postposition particle 
comes under this new tag ignoring semantic con-
text. I (Intensifier) is used to mark the intensifi-
cation of an adjective, which is a semantic grada-
tion, and syntactically merged with Q (Quantifi-
er). NNCM (Noun after Case Marker), NNC 
(Noun Continuation), NNCR (Continuing Noun 
Termination) are merged into NN (Noun) be-
cause syntactically they always behave similarly 
and the difference is motivated by phrase level 
marking.   U (Unit) is also merged with NN be-
cause the difference is semantically motivated.   
DATE is not syntactic, and may be either 
treated as NN (Noun) or CD (Cardinal), depend-
ing upon the context. Similarly, R (Reduplica-
tion), MOPE (Meaningless Pre-word), and MO-
PO (Meaningless Post-word) always occur in 
pair with NN, JJ, or another tag.  Thus they are 
phrasal level tags, and can be replaced by rele-
vant word level tag in context. NNPC (Proper 
Noun Continuation) tag identifies compounding 
but syntactically behaves as NNP (Proper Noun), 
and is not used.  
VBL (Light Verb) is used in complex predi-
cates (Butt 1995), but its syntactic similarity with 
VB (Verb) is a major source of confusion in au-
tomatic tagging.  It is collapsed with VB (Verb). 
Similarly, VBLI (Light Verb Infinitive) is 
merged with VBI (Verb Infinitive). AUXT 
(Tense Auxiliary) is highly misclassified as VBT 
(To be Verb) because both occur as last token in 
a clause or sentence, and both include tense in-
27
 
 
formation. The word is labeled as VBT only 
when there is no other verb in the sentence or 
clause, otherwise these words are tagged as 
AUXT. The syntactic similarity of both tags is 
also evident from statistically misclassifying 
AUXT as VBT.  Therefore both are collapsed 
into single tag VBT (Tense Verb). 
In T1, NEG (Negation) is used to mark all 
the negation words without context, but they 
mostly occur as adverbs.  Therefore, NEG tag is 
removed. Similarly, SE (Postposition ?5 , 
?from?) is not separated from postpositions and 
marked accordingly. PRT (Pre-Title) and POT 
(Post-Title) always occur before or after Proper 
Noun, respectively. Therefore, they behave as 
Proper Nouns, hence proposed to be labeled as 
NNP (Proper Noun). 
7 Experiments 
After designing a new tagset, a series of experi-
ments are conducted to investigate the proposed 
changes. The rationale of the sequence of expe-
riments has been discussed in Section 5 above, 
however the reasoning for each experiment is 
also given below. As T2 tags have much more 
semantic and phrasal information, and C2 tagged 
with T2 shows lower accuracy than T1 on C1, 
therefore further experiments are conducted to 
compare the performance of T1 and T3 only.  
Comparisons on C2 with T3 may also be drawn. 
7.1 Experiment 1 
As baseline estimation shows that T1 on C1 out-
performs T2 on C2, the first experiment is to 
compare the performance of T3 on C1. In this 
experiment C1 is semi-automatically tagged with 
T3. TnT tagger is then trained and tested. T3 
gives 93.44% accuracy, which is slightly better 
than the results already obtained for T1 
(93.01%). The results are summarized in Table 7. 
 
Table 7. Accuracies of T3 and T1 on C1  
 
Corpus Tagset Accuracy
C1 T3 93.44% 
C1 T1 93.01% 
7.2 Experiment 2 
Now to test the effect of change in domain of the 
corpus, the performance T1 and T3 on C2 is 
compared in this experiment. C2 is manually 
tagged with T3, then trained and tested using 
TnT tagger. The results obtained with T3 are 
91.98%, which are significantly better than the 
results already obtained for T2 on C2 (88.13%). 
C2 is also semi-automatically re-tagged 
with T1. T1 shows better performance (91.31%) 
than T2 (88.13%). However, the accuracy of us-
ing T3 (on C2) is still slightly higher.  The re-
sults are summarized in Table 8. 
 
Table 8. Accuracies of T3 on C1, and accura-
cies of T3 and T1 on C2 
 
Corpus Tagset Accuracy 
C2 T3 91.98% 
C2 T1 91.31% 
7.3 Experiment 3 
Due to the change in open class set there may be 
a difference of performance on unknown words, 
therefore in this experiment, all the unknown 
words of test set are also included in the vocabu-
lary. This experiment again involves T3 and T1 
with C2. Combined lexica are built using testing 
and training parts of the corpus, to eliminate the 
factor of unknown words. This experiment also 
shows that T3 performs better than T1, as shown 
in Table 9. 
 
Table 9. Accuracies of T3 and T1 with ALL 
known words in test data 
 
Corpus Tagset Accuracy 
C2 T3 94.21% 
C2 T1 93.47% 
7.4 Experiment 4 
Finally both corpora (C1 and C2) were com-
bined, forming a training set of 203,882 words 
and a test set of 29,851 words. The lexica are 
generated only from the training set. Then TnT 
tagger is trained separately for both T1 and T3 
tagsets and the accuracies are compared. The 
results show that T3 gives better tagging accura-
cy, as shown in Table 10. 
 
Table 10. Accuracies of T3 and T1 using 
combined C1 and C2 corpora 
 
Corpus Tagset Accuracy 
C1+C2 T3 90.99% 
C1+C2 T1 90.00% 
 
Partial confusion matrices for both the tag-
sets are given in Tables 11 and 12.   
28
 
 
The error analysis shows that the accuracy 
drops for both tagsets when trained on multi-
domain corpus, which is expected.  The highest 
error count is for the confusion between noun 
and adjective.  There is also confusion between 
proper and common nouns.  T3 also gives signif-
icant confusion between personal pronouns and 
demonstratives, as they represent the same lexi-
cal entries.   
 
Table 11. Major misclassifications in merged 
corpus with T1 using TnT tagger 
 
Tag 
Total 
tokens Error  
Maximum  
misclassification
A 18 5 3 ADJ 
AD 18 7 4 ADJ 
ADJ 2510 551 371 NN 
ADV 431 165 59 ADJ 
INT 8 6 6 ADV 
KD 16 9 6 Q 
KER 77 28 19 P 
NN 7642 548 218 PN 
OR 75 24 9 Q 
PD 205 55 12 PP 
PN 2246 385 264 NN 
PP 239 51 11 PD 
Q 324 119 53 ADJ 
QW 24 12 11 VB 
RD 71 62 61 RP 
RP 11 5 2 NN 
U 24 8 8 NN 
 
Table 12. Major misclassifications in merged 
corpus with T3 using TnT tagger 
 
Tag 
Total 
tokens Error  
Maximum  
misclassification
CVRP 77 24 15 PP 
DM 242 77 58 PRP 
DMRL 71 64 63 PRRL 
INJ 8 6 6 RB 
JJ 2510 547 376 NN 
JJRP 18 4 4 JJ 
NN 7830 589 234 NNP 
NNP 2339 390 267 NN 
OD 75 23 8 JJ 
PRP 642 119 33 DM 
 
8 Discussion and Conclusion 
The current work looks at the existing tagsets of 
Urdu being used for tagging corpora and analyz-
es them from two perspectives.  First, the tagsets 
are analyzed to see their linguistic level differ-
ences.  Second, they are compared based on their 
inter-tag confusion after training with two differ-
ent POS taggers.  These analyses are used to de-
rive a more robust tagset.   
The results show that collapsing categories 
which are not syntactically motivated improves 
the tagging accuracy in general.  Specifically, 
light and regular verbs are merged, because they 
may come in similar syntactic frames.  Redupli-
cated categories are given the same category tag 
(instead of a special repetition tag).  Units and 
dates are also not considered separately as the 
differences have been semantically motivated 
and they can be categorized with existing tags at 
syntactic level.   
Though, the measuring unit is currently 
treated as a noun, it could be collapsed as an ad-
jective as well.  The difference is sometimes lex-
ical, where kilogram is more adjectival, vs. 
minute is more nominal in nature in Urdu, 
though both are units.    
NNP (Proper Noun) tag could also have 
been collapsed with NN (Common Noun), as 
Urdu does not make clear between them at syn-
tactic level.  However, these two tags are kept 
separate due to their cross-linguistic importance.  
One may expect that extending the genre or 
domain of corpus reduces accuracy of tagging 
because of increase in the variety in the syntactic 
patterns and diverse use of lexical items. One 
may also expect more accuracy with increase in 
size.  The current results show that effect on ad-
ditional domain (when C1 and C2 are mixed) is 
more pronounced than the increase in size (from 
approximately 100k to 200k), reducing accuracy 
from 94.21% (T3 with C2) to 90.99% (T3 with 
C1 + C2).  The increase in accuracy for T3 vs. 
T1 may be caused by reduced size of T3.  How-
ever, the proposed reduction does not compro-
mise the syntactic word level information, as the 
collapsed categories are where they were either 
semantically motivated or motivated due to 
phrasal level tags. 
The work has been motivated to consolidate 
the existing Urdu corpora annotated with differ-
ent tagsets.  This consolidation will help build 
more robust computational models for Urdu.   
References 
Brants, T. 2000. TnT ? A statistical part-of-speech 
tagger. Proceedings of the Sixth Applied Natural 
Language Processing Conference ANLP-2000 
Seattle, WA, USA. 
29
 
 
Butt, M.  1995.  The structure of complex predicates 
in Urdu. CSLI, USA.  ISBN: 1881526585. 
Haq, A,. 1987. ?\?a ?a??Da ????  Amjuman-e-Taraqqi 
Urdu.   
Hardie, A. 2003. Developing a tag-set for automated 
part-of-speech tagging in Urdu. Archer, D, Rayson, 
P, Wilson, A, and McEnery, T (eds.) Proceedings 
of the Corpus Linguistics 2003 conference. UCREL 
Technical Papers Volume 16. Department of Lin-
guistics, Lancaster University, UK.  
Hussain, S. 2008. Resources for Urdu Language 
Processing.  The Proceedings of the 6th Workshop 
on Asian Language Resources, IJCNLP?08, IIIT 
Hyderabad, India. 
Ijaz, M. and Hussain, S. 2007. Corpus Based Urdu 
Lexicon Development. The Proceedings of Confe-
rence on Language Technology (CLT07), Universi-
ty of Peshawar, Pakistan. 
Javed, I.  1981.  ?<??Ka ????a t5?aTaraqqi Urdu Bureau, 
New Delhi, India. 
Platts, J. 1909. A grammar of the Hindustani or Urdu 
language.  Reprinted by Sang-e-Meel Publishers, 
Lahore, Pakistan. 
Sajjad, H.  2007.  Statistical Part of Speech Tagger for 
Urdu.  Unpublished MS Thesis, National Universi-
ty of Computer and Emerging Sciences, Lahore, 
Pakistan. 
Sajjad, H. and Schmid, H. 2009. Tagging Urdu Text 
with Parts Of Speech: A Tagger Comparison.12th 
conference of the European chapter of the associa-
tion for computational Linguistics 
Santorini, B. 1990. Part_of_Speech Tagging Guide-
lines for the Penn Treebank Project (3rd printing, 
2nd revision). Accessed from 
ftp://ftp.cis.upenn.edu/pub/treebank/doc/tagguide.ps.gz 
on 3rd May, 2009. 
Schmid, H. 1994.  Probabilistic part-of-speech tag-
ging using decision trees. Institut f?r Maschinelle 
Sprachverarbeitung, Universit?t Stuttgart, Germa-
ny. 
Schmidt, R. 1999. Urdu: an essential grammar. Rout-
ledge, London, UK. 
McEnery, A., Baker, J. Gaizauskas, R. and Cunning-
ham, H. 2000. EMILLE: towards a corpus of South 
Asian languages, British Computing Society Ma-
chine Translation Specialist Group, London, UK.  
 
 
 
 
 
 
Appendix A: Mappings of tags between Tag-
sets T1 and T2. 
 
 Tagset T1 Tagset T2 
1.  A JJRP 
2.  AA AUXA 
3.  ADJ JJ 
4.  ADV RB 
5.  CA CD 
6.  CC CC 
7.  DATE DATE 
8.  EXP SYM 
9.  FR FR 
10.  G PRP$ 
11.  GR PRRFP$ 
12.  I ITRP 
13.  INT INJ 
14.  KER KER 
15.  MUL MUL 
16.  NN NN 
17.  OR OD 
18.  P CM 
19.  PD DM 
20.  PM PM 
21.  PN NNP 
22.  PP PR 
23.  Q Q 
24.  QW QW 
25.  RD DMRL 
26.  REP PRRL 
27.  RP PRRF 
28.  SC SC 
29.  SE RBRP 
30.  SM SM 
31.  TA AUXT 
32.  U U 
33.  WALA WALA 
30
 
 
Appendix B: New Tagset T3. 
 
 Tag Meaning Example 
1. AUX Auxiliary a?La?gTWO?5hBa?P a May 
2. CC Coordinate Conjunction asYO??O??a?????a?5a?????a??lHat5O?h@ a Or 
3. CD Cardinal ???a?La??????a???>?O a One 
4. CVRP Conjunctive Verb Par-ticle 
avY?a??jKat?Y^???J?La??at5??a?7a?5?Q?6a??WJat?6aa After  
5. DM Demonstrative a???7????aa??a??dK??a?58a?6?6?a?5a?5?P a Like this 
6. DMRL Demonstrative Relative 
a?5a?????at5H?C?a???>aa23??aa?5?a??a?8a??B
a?Y?a
That 
7. FR Fraction ?5??a?YOa?5WmM a Half 
8. INJ Interjection ???a!?5a?6?a?YL a Hurrah 
9. ITRP Intensive Particle a??a?m8a??lMa??t5a???a?5??at5?6 a Too 
10. JJ Adjective ?8a?Wj6a?8?Ba?5a??TM? a Taller 
11. JJRP Adjective Particle apl6at5a?5??a???6t5a?Y?a?5hBa??Ba?La????>? a As 
12. MRP Multiplicative Particle at5M??K? a Double 
13. NN Noun ??Baa?5??I?aa?YO??P??J?a?7 a Year 
14. NNP Proper Noun a???6?a?lLa?5 a Robert 
15. OD Ordinal ?l7a?6?`WOaqWO?<?U?? a First 
16. PM Phrase Marker ?a , 
17. PP Postposition ?5?Pa?5?Q?6a?8a??apYWL?a?6??a To 
18. PRP Pronoun Personal 
??aa???La?W^7a???Pa???a?5a??kdTB?a?La???a???F
?5a
They 
19. PRP$ Pronoun Personal  Possessive 
??YOa?5at???a?WYMa?Y? a My 
20. PRRF Pronoun Reflexive a?5??a?5at5SkL??at5?]6a?L a Oneself 
21. PRRF$ Pronoun Reflexive  Possessive 
?5??a?8?J?at5?kT>? a Own 
22. PRRL Pronoun Relative 
a?5a?????at5H?C?a???>aa23??aa?5?a??a?8a??B
a?Y?a
That 
23. Q Quantitative ?W?a??N a Some 
24. QW Question Word a?W`Oa?????YLa??a??LasYg? a Why 
25. RB Adverb ?_YkPat5Mat5Y? a Always 
26. SC Subordinate Conjunction at5a?5L?a?WTL?h??YLa????L??a?[L a Because 
27. SM Sentence Marker ?a ? 
28. SYM any Symbol $a $ 
29. VB Verb a??SLa?5WlO?5???a?58 a Wanted 
30. VBI Verb Infinitive form a?5a?5?5??>a?5Na?5 a To go 
31. VBT Verb Tense `8a?kHa?6?Ka??5? a Is 
32. WALA Association Marking Morpheme 
a?5mL???5? a
a?5?La???<??? a
Associated 
Bearing 
 
31
Proceedings of the 8th Workshop on Asian Language Resources, pages 95?102,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
Dzongkha Word Segmentation
Sithar Norbu, Pema Choejey, Tenzin Dendup
Research Division
Department of Information Technology & 
Telecom
{snorbu, pchoejay, tdendup}@dit.gov.bt
Sarmad Hussain, Ahmed Mauz
   Center for Research in Urdu Language Processing
National University of Computer & Emerging 
Sciences
{sarmad.hussain, ahmed.mauz}@nu.edu.pk
Abstract
Dzongkha,  the  national  language  of 
Bhutan, is continuous in written form 
and it fails to mark the word boundary. 
Dzongkha word segmentation is one of 
the  fundamental  problems  and  a 
prerequisite  that  needs  to  be  solved 
before  more  advanced  Dzongkha  text 
processing and other natural  language 
processing  tools  can  be  developed. 
This paper presents our initial attempt 
at segmenting Dzongkha sentences into 
words.  The  paper  describes  the 
implementation of Maximal  Matching 
(Dictionary based Approach) followed 
by bigram techniques  (Non-dictionary 
based  Approach)  in  segmenting  the 
Dzongkha  scripts.  Although  the  used 
techniques  are  basic  and  naive,  it 
provides  a  baseline  of  the  Dzongkha 
word  segmentation  task.  Preliminary 
experimental  results  show  percentage 
of  segmentation  accuracy.  However, 
the segmentation accuracy is dependent 
on the  type  of  document  domain  and 
size and quality of the lexicon and the 
corpus. Some of the related issues for 
future directions are also discussed.
Keywords:  Dzongkha  script,  word 
segmentation,  maximal  matching,  bigram 
technique, smoothing technique.
1    Introduction
Segmentation of a sentence into word is one of 
the  necessary  preprocessing  tasks  and  is 
essential  in  the  analysis  of  natural  language 
processing.  This  is  because  word  is  both 
syntactically  and  semantically,  the 
fundamental  unit  for  analyzing  language 
structure.  Like  in  any  other  language 
processing task, Dzongkha word segmentation 
is also viewed as one of the fundamental and 
foremost  steps in Dzongkha related language 
processing tasks.
The most challenging features of Dzongkha 
script is the lack of word boundary separation 
between  the  words1.  So,  in  order  to  do  the 
further  linguistic  and  natural  language 
processing  tasks,  the  scripts  should  be 
transformed into a chain of words. Therefore, 
segmenting  a  word  is  an  essential  role  in 
Natural  Language  Processing.  Like  Chinese, 
Japanese  and  Korean  (CJK)  languages, 
Dzongkha  script  being  written  continuously 
without  any  word  delimiter  causes  a  major 
problem in natural language processing tasks. 
But,  in  case  of  CJK,  Thai,  and  Vietnamese 
languages,  many  solutions  have  been 
published  before.  For  Dzongkha,  this  is  the 
first  ever  word  segmentation  solution  to  be 
documented. 
In  this  paper,  we  describe  the  Dzongkha 
word segmentation, which is performed firstly 
using the Dictionary based approach where the 
principle  of  maximal  matching  algorithm  is 
applied  to  the  input  text.  Here,  given  the 
collection  of  lexicon,  the  maximal  matching 
algorithm selects the segmentation that yields 
the minimum number of words token from all 
possible segmentations of  the input  sentence. 
Then,  it  uses  non-dictionary  based  approach 
where  bigram  technique  is  applied.  The 
probabilistic  model  of  a  word  sequence  is 
1http://www.learntibetan.net/grammar/sentence.htm  
95
studied  using  the  Maximum  Likelihood 
Estimation  (MLE).  The  approach  using  the 
MLE has an obvious disadvantage because of 
the  unavoidably  limited  size  of  the  training 
corpora (Nuges, 2006). To this problem of data 
sparseness,  the  idea  of  Katz  back-off  model 
with  Good-Turing  smoothing  technique  is 
applied. 
2    Dzongkha Script
Dzongkha language is the official and national 
language of  Bhutan.  It  is  spoken as  the  first 
language  by  approximately  130,000  people 
and as the second language by about 470,000 
people (Van Driem and Tshering, 1998).
Dzongkha  is  very  much  related  to  Sino-
Tibetan  language  which  is  a  member  of 
Tibeto-Burmese  language  family.  It  is  an 
alphabetic  language,  with  phonetic 
characteristics  that  mirror  those  of  Sanskrit. 
Like many of the alphabets of India and South 
East  Asia,  the  Bhutanese  script  called 
Dzongkha script is also a syllabic2. A syllable 
can  contain  as  little  as  one  character  or  as 
many as six characters. And a word can be of 
one syllable, two syllable or multiple syllables. 
In the written form, Dzongkha script contains a 
dot, called Tsheg (  ? ) that serve as syllable and 
phrase delimiter, but words are not separated at 
all. 
For example,
Dzongkha Transliteration English Syllables
????? dmarpo red Single-syllabled
???????? slop-pon Teacher Two-syllabled
?????????? hjam-tog-to easy Three-syllabled
??????????? har-ri-hur-ri crowdedness/confusion Four-syllabled
Table 1: Different syllabled Dzongkha scripts. 
The  sentence  is  terminated  with  a  vertical 
stroke  called Shad (   ? ).  This  Shad acts  as  a 
full_stop.  The  frequent  appearance  of 
2http://omniglot.com/writing/tibetan.htm  
whitespace in the Dzongkha sentence serves as 
a phrase boundary or comma, and is a faithful 
representation  of  speech:  after  all  in  speech, 
we pause not between words, but either after 
certain phrases or at the end of sentence. 
The  sample  dzongkha  sentence  reads  as 
follows:
??????????????????????????? ????????????? ?????????
?????? ?????????????????????? ?????????????????????
??? ????????????????????????????? ?????????????????
????????? ???????????????? ????????????? ???????
??????????????????????????????? ?????????????????????
???????????????????????????????????? ?????? ???? ??
??????????????????????
(English Translation of example text)
[The  Dzongkha  Development  Commission  is 
the  leading  institute  in  the  country  for  the 
advancement  of  Dzongkha,  the  national 
language  of  Bhutan.  It  is  an  independent 
organization established by the Fourth King of 
Bhutan,  His  Majesty the  King  Jigme  Singye 
Wangchuck, in 1986.]
3    Materials and Methods
Since,  our  language  has  no  word  boundary 
delimiter,  the  major  resource  for  Dzongkha 
word segmentation  is  a  collection of  lexicon 
(dictionary).  For  such  languages,  dictionaries 
are  needed  to  segment  the  running  texts. 
Therefore, the coverage of a dictionary plays a 
significant  role  in  the  accuracy  of  word 
segmentation (Pong and Robert, 1994). 
The dictionary that we used contains 23,333 
word  lists/lexicons.  The  lexicons  were 
collected  from  ?Dzongkha  Dictionary?,  2nd 
Edition, Published by Dzongkha Development 
Authority,  Ministry  of  Education,  2005, 
(ddc@druknet.bt).  The  manually  segmented 
text corpus containing 41,739 tokens are also 
used  for  the  method.  The  text  corpora  were 
collected  from  different  sources  like 
newspaper articles, dictionaries, printed books, 
etc.  and  belong  to  domains  such  as  World 
Affairs,  Social  Sciences,  Arts,  Literatures, 
Adventures, Culture and History.  Some texts 
like poetry and songs were added manually. 
96
Table  below  gives  the  glimpse  of  textual 
domains contained in the text corpora used for 
the method (Chungku et al, 2010).
Domain Sub domain (%)
World Affairs Bilateral relations 12%
Social Science Political Science 2%
Arts Poetry/Songs/Ballad 9%
Literatures Essays/Letters/Dictionary 72%
Adventures Travel Adventures 1%
Culture Culture Heritage/Tradition 2%
History Myths/Architecture 2%
 
Table 2:  Textual domain contained in Corpus
Figure  1  below  shows  the  Dzongkha  Word 
Segmentation Process. 
Figure  1:  Dzongkha  Word  Segmentation 
Process. 
Dzongkha  word  segmentation  implements  a 
principle  of  maximal  matching  algorithm 
followed by statistical (bigram) method. It uses 
a word list/lexicon at first to segment the raw 
input sentences. It then uses MLE principles to 
estimate  the  bigram  probabilities  for  each 
segmented words.  All  possible segmentation 
of an input sentence by Maximal Matching are 
then  re-ranked  and  picked  the  mostly  likely 
segmentation  from  the  set  of  possible 
segmentations  using  a  statistical  approach 
(bigram technique). This is to decide the best 
possible  segmentation  among  all  the  words 
(Huor et al, 2007) generated by the maximal 
matching  algorithm.  These  mechanisms  are 
described in the following
3.1    Maximal Matching Algorithm
The basic idea of Maximal matching algorithm 
is, it first generates all possible segmentations 
for  an  input  sentence  and  then  selects  the 
segmentation  that  contains  the  minimum 
number  of  word  tokens.  It  uses  dictionary 
lookup. 
We used the following steps to segment the 
given input sentence.
1. Read  the  input  of  string  text.  If  an 
input  line  contains  more  than  one 
sentence,  a  sentence  separator  is 
applied  to  break  the  line  into 
individual sentences.
2. Split input string of text by Tsheg(   ? ) 
into syllables.
3. Taking the next syllables, generate all 
possible strings
4. If the number of string is greater than 
n for some value n3
? Look  up  the  series  of  string  in  the 
dictionary to find matches, and assign 
some weight-age4 accordingly.
? Sort the string on the given weight-age
? Delete  (number  of  strings  ?  n)  low 
count strings.
5. Repeat from Step 2 until all syllables 
are processed.
The  above  mentioned  steps  produced  all 
possible segmented words from the given input 
sentence based on the provided lexicon. Thus, 
the overall accuracy and performance depends 
on the coverage of lexicon (Pong and Robert, 
1994).
3The greater the value of n, the better the chances of 
selecting the sentence with the fewest words from 
the possible segmentation. 
4If the possible string is found in the dictionary 
entries, the number of syllable in the string is 
counted. Then, the weight-age for the string is 
calculated as (number of syllable)2 else it carries the 
weight-age 0
97
3.2    Bigram Method
(a)    Maximum Likelihood Estimation5
In the bigram method, we make the 
approximation that the probability of a word 
depends on identifying the immediately 
preceding word. That is, we calculate the 
probability of next word given the previous 
word, as follows:
P ?w1n?=? i=1n P ?wi/w i?1?
where
? P ?wi /wi?1?= count ?wi?1w i ?count ?wi?1 ?
where
? count ?wi?1wi ? is  a  total  occurrence 
of  a  word  sequence  w i?1wi in  the 
corpus, and
? count ?wi?1? is a total occurrence of a 
word w i?1 in the corpus.
To make  P ?wi /wi?1? meaningful  for  i=1 , 
we  use  the  distinguished  token  <s>  at  the 
beginning of the sentence; that is, we pretend 
w0 = <s>. In addition, to make the sum of the 
probabilities  of  all  strings  equal  1,  it  is 
necessary to place a distinguished token </s> 
at the end of the sentence.
One of the key problems with the MLE is 
insufficient  data.  That  is,  because  of  the 
unavoidably limited size of the training corpus, 
vast majority of the word are uncommon and 
some of the bigrams may not occur at all in the 
corpus, leading to zero probabilities. 
Therefore,  following  smoothing  techniques 
were used to count the probabilities of unseen 
bigram.  
(b)    Smoothing Bigram Probabilistic
The  above  problem  of  data  sparseness 
underestimates the probability of some of the 
sentences  that  are  in  the  test  set.  The 
smoothing technique helps to prevent errors by 
making  the  probabilities  more  uniform. 
Smoothing  is  the  process  of  flattening  a 
5P.M, Nugues. An Introduction to Language 
Processing with Perl and Prolog: An Outline of 
Theories, Implementation, and Application with 
Special Consideration of English, French, and 
German (Cognitive Technologies) (95 ? 104). 
probability distribution implied by a language 
model  so that  all  reasonable  word sequences 
can  occur  with  some  probability.  This  often 
involves  adjusting  zero  probabilities  upward 
and high probabilities  downwards.  This way, 
smoothing  technique  not  only  helps  prevent 
zero probabilities but  the overall  accuracy of 
the  model  are  also  significantly  improved 
(Chen and Goodman, 1998).
In Dzongkha word segmentation, Katz back-
off  model  based  on  Good-Turing  smoothing 
principle is applied to handle the issue of data 
sparseness.  The  basic  idea  of  Katz  back-off 
model is to use the frequency of n-grams and if 
no n-grams are available, to back off to  (n-1) 
grams,  and  then  to  (n-2) grams  and  so  on 
(Chen and Goodman, 1998).
The  summarized  procedure  of  Katz 
smoothing technique is given by the following 
algorithm:6
Pkatz ?wi?wi?1 ?={ C ?wi?1 /wi ? ifr>kdrC ?wi?1 /wi ? ifk?r>0? ?wi?1 ?P ?wi ? ifr=0 }
where
? r is the frequency of bigram counts
? k  is  taken  for  some  value  in  the 
range of  5  to  10,  other  counts  are 
not re-estimated. 
? dr =
r?
r ??k+1 ?
nK+1
n1
1? ?k+1 ? nk+1n1
?
? ?wi?1? =
1? ?
wi :r>0
PKatz ?wi?w i?1?
1? ?
wi :r>0
PKatz ?w i ?
With the above equations, bigrams with non-
zero count  r  are discounted according to the 
6X. Huang, A. Acero, H.-W.Hon, Spoken Language 
Processing: A Guide to Theory, Algorithm and 
System Development, (Prentice-Hall Inc., New 
Jersey 07458, 2001), 559 - 561.
98
discount  ratio  dr= r
?
r  i.e.,  the  count 
subtracted  from  the  non-zero  count  are 
redistributed  among  the  zero  count  bigrams 
according to the next lower-order distribution, 
the unigram model.
4    Evaluations and Results
Subjective evaluation has been performed by 
comparing  the  experimental  results  with  the 
manually segmented tokens. The method was 
evaluated  using  different  sets  of  test 
documents from various domains consisting of 
714  manually  segmented  words.  Table  3 
summarizes the evaluation results.
Document text Correct Detect
(Correctly segmented 
tokens / total no. of 
words)
Accuracy
Astrology.txt 102/116 87.9%
dzo_linux.txt 85/93 91.4%
movie_awards.txt 76/84 90.5%
News.txt 78/85 91.8%
Notice.txt 83/92 90.2%
Religious.txt 63/73 89.0%
Song.txt 57/60 95.0%
Tradition.txt 109/111 98.2%
Total 653/714 91.5%
Table 3: Evaluation Results
Accuracy in %age are measured as:
Accuracy(%) = NT?100
where
? N is  the  number  of  correctly 
segmented tokens
? T is  the  total  number  of  manually 
segmented tokens/ Total number of 
words. 
We have taken the extract of different test data 
hoping it may contain fair amount of general 
terms, technical terms and common nouns. The 
manually segmented corpus containing 41,739 
tokens are used for the method. 
In the sample comparison below, the symbol 
(   ? )  does  not  make  the  segmentation  unit's 
mark,  but  (   ? )  takes  the  segmentation  unit's 
mark,  despite  its  actual  mark  for  comma  or 
full_stop. The  whitespace in the sentence are 
phrase boundary or comma,  and is  a faithful 
representation of speech where we pause not 
between words, but either after certain phrases 
or at the end of sentence. 
Consider the sample input sentence:
?????????????????? ????????????????????????????????? ???
?????????????????????????? ??????????????? ?????????
??????????????? ??????????????????????????????????????
???????? ??????? ??????????????????????????????????????
????????????????????
Manually  segmented  sentence  of  the  sample 
input sentence:
?????????????????? ????????????????????????????????? 
????????????????????????????? ??????????????? ?????
??????????????????? ??????????????????????????????
???????????????? ??????? ???????????????????????????
???????????????????????????????
Using maximal matching algorithm:
??????  ???  ?????  ????  ??????  ????????  ???  ????? 
?????  ????  ??  ???????  ????  ??  ?????  ???  ????? 
???  ???????  ???  ?????  ?????????  ????????  ??????? 
???????  ???  ????????  ????  ????  ????  ????  ???? 
????????  ???  ????  ?????  ???  ???????  ????  ???? 
????  ???????  ????  ????  ???  ??  ??  ?????  ????
System segmented version of the sample input 
sentence: Underlined text shows the incorrect 
segmentation.
?????????????????? ????????????????????????????????? 
?????????????????????????????  ????????????????????
???????????????????  ??????????????????????????????
99
????????????????  ??????????????????????????????????
??????????????????????????? ????  
5    Discussions
During the process of word segmentation, it is 
understood  that  the  maximal  matching 
algorithm is simply effective and can produce 
accurate segmentation only if all the words are 
present  in  the  lexicon.  But  since  not  all  the 
word entry can be found in lexicon database in 
real  application,  the  performance  of  word 
segmentation  degrades  when  it  encounters 
words that are not in the lexicon (Chiang et al, 
1992).
Following are the significant problems with 
the  dictionary-based  maximal  matching 
method  because  of  the  coverage  of  lexicon 
(Emerson, 2000):
? incomplete and inconsistency of the 
lexicon database
? absence of technical domains in the 
lexicon
? transliterated foreign names
? some  of  the  common  nouns  not 
included in the lexicon
? lexicon/word  lists  do  not  contains 
genitive  endings  ??? (expresses  the 
genitive relationship as a quality or 
characteristic of the second element, 
for  example,  ????????? 'son  of  a 
pauper') and  ?? (first  singular 
possessive,  for  example,  ???????? 
which  actually  is ????????? 'my 
daughter') that  indicates  possession 
or a part-to-whole relationship, like 
English 'of'.  
A Dzongkha sentence like:
????????????? ??????????????? ????
may include the following ambiguous possible 
segmentation based on simple dictionary 
lookup:
1.???????????????????????????????
this | Dzongkha | of | research | written 
document | is
2.???????????????????????????????
this | Dzongkha | of | arrange together | search/
expose | written document | is
3.???????????????????????????????
this | fortress | mouth/surface | of | research | 
written document | is
These  problems  of  ambiguous  word 
divisions, unknown proper names, are lessened 
and solved partially when it is re-ranked using 
the bigram techniques. Still the solution to the 
following issues needs to be discussed in the 
future. Although the texts were collected from 
widest range of domains possible, the lack of 
available  electronic  resources  of  informative 
text adds to the following issues:
? small  number  of  corpus  were  not 
very impressive for the method
? ambiguity  and  inconsistent  of 
manual  segmentation of a token in 
the  corpus  resulting  in 
incompatibility  and  sometimes  in 
conflict.
Ambiguity  and  inconsistency  occurs 
because of  difficulties  in  identifying  a  word. 
Since the manual segmentation of corpus entry 
was  carried  out  by  humans  rather  than 
computer, such humans have to be well skilled 
in identifying or understanding what a word is. 
The problem with the Dzongkha scripts that 
also hampers the accuracy of dzongkha word 
segmentation  includes  the  issues  such  as 
ambiguous  use  of  Tsheg  (   ? ) in  different 
documents.  There  are  two  different  types  of 
Tsheg: Unicode 0F0B (  ? ) called Tibetan mark 
inter  syllabic  tsheg is  a  normal  tsheg that 
provides  a  break  opportunity.  Unicode  0F0C 
(  ? ) called Tibetan Mark Delimiter Tsheg Bstar 
is  a  non-breaking  tsheg and  it  inhibits  line 
breaking.
For example,
input sentence with Tsheg 0F0B: 
?????????????????????? ????????????????????? ??????
???????????????
achieves 100% segmentation as follow:
100
??????? ??? ??????? ????? ??????? ??? ???? ???? ??? 
?? ???? ??? ????? ???? ??? 
whereas  the  same input  sentence with Tsheg 
0F0C is incorrectly segmented as follows:
??????????????????????? ?????????????????????? 
?????????????????????
There are also cases like shortening of words, 
removing  of  inflectional  words  and 
abbreviating of words for the convenience of 
the writer.  But  this  is  not  so reflected in the 
dictionaries, thus affecting the accuracy of the 
segmentation. 
Following words has a special abbreviated way 
of writing a letter or sequence of letters at the 
end of a syllable as
?????    as ???
??????  as ??? 
etc..  
6    Conclusion and Future works
This  paper  describes  the  initial  effort  in 
segmenting  the  Dzongkha  scripts.  In  this 
preliminary  analysis  of  Dzongkha  word 
segmentation,  the  preprocessing  and 
normalizations are not dealt with. Numberings, 
special  symbols  and  characters  are  also  not 
included. These issues will have to be studied 
in the future.  A lot of discussions and works 
also  have  to  be  done  to  improve  the 
performance of word segmentation. Although 
the study was a success,  there are still  some 
obvious limitations, such as its dependency on 
dictionaries/lexicon, and the current Dzongkha 
lexicon  is  not  comprehensive.  Also,  there  is 
absence  of  large  corpus  collection  from 
various  domains.  Future  work  may  include 
overall improvement of the method for better 
efficiency,  effectiveness and functionality,  by 
exploring  different  algorithms.  Furthermore, 
the inclusion of POS Tag sets  applied on n-
gram techniques which is proven to be helpful 
in handling the unknown word problems might 
enhance  the  performance  and  accuracy. 
Increasing  corpus  size  might  also  help  to 
improve the results. 
Acknowledgment
This research work was carried out as a part of 
PAN  Localization  Project 
(http://www.PANL10n.net)  with  the  aid  of  a 
grant  from  the  International  Development 
Research  Centre  (IDRC),  Ottawa,  Canada, 
administered through the Center of Research in 
Urdu Language Processing (CRULP), National 
University  of  Computer  and  Emerging 
Sciences  (NUCES),  Pakistan.  The  research 
team would also like to express the gratitude to 
all the PAN Localization Project members of 
Bhutanese  team  based  at  Department  of 
Information  Technology  and  Telecom,  for 
their  efforts  in  collecting,  preparing  and 
providing  with  the  lexicon,  corpus,  useful 
training  and  testing  materials  and  finally  for 
the their valuable support and contribution that 
made this research successful. 
References
Chen,  Stanley  F.,  Joshua  Goodman,  1998.  An 
Empirical  Study  of  Smoothing  Techniques  for  
Language Modeling,  Computer  Science Group, 
Harvard University, Cambridge, Massachusetts
Chiang,  T-Hui., J-Shin Chang,,  M-Yu Lin,  K-Yih 
Su,  2007.  Statistical  models  for  word 
segmentation  and  unknown  word  resolution.  
Department of Electrical Engineering , National 
Tsing Hua University, Hsinchu, Taiwan.
Chungku.,  Jurmey  Rabgay,  Gertrud  Faa?,  2010. 
NLP  Resources  for  Dzongkha.  Department  of 
Information Technology & Telecom, Ministry of 
Information  &  Communications,  Thimphu, 
Bhutan.
Durrani,  Nadir  and  Sarmad Hussain,  2010.  Urdu 
Word  Segmentation.  Human  Language 
Technologies:  11th  Annual  Conference  of  the 
North American Chapter of the Association for 
Computational  Linguistics,  Los  Angeles,  June 
2010.
Emerson,  Thomas.  2000.  Segmenting  Chinese  in  
Unicode. 16th International Unicode conference, 
Amsterdam, The Netherlands, March 2000
Haizhou,  Li  and  Yuan  Baosheng,  1998.  Chinese 
Word Segmentation. Language, Information and 
Computation (PACLIC12), 1998.
Haruechaiyasak,  C.,  S  Kongyoung,  M.N.  Dailey, 
2008.  A  Comparative  Study  on  Thai  Word  
101
Segmentation  Approaches.  In  Proceedings  of 
ECTI-CON, 2008.
Huang,  X.,  A.  Acero,  H.-W.  Hon,  2001.  Spoken  
Language  Processing:  A  Guide  to  Theory,  
Algorithm and System Development (pp. 539 ?  
578). Prentice-Hall Inc., New Jersey 07458.
Huor,  C.S.,  T.  Rithy,   R.P.  Hemy,  V.  Navy,  C. 
Chanthirith,  C.  Tola,  2007.  Word  Bigram  Vs 
Orthographic Syllable Bigram in Khmer Word 
Segmentation.  PAN  Localization  Working 
Papers 2004 - 2007. PAN Localization Project, 
National University of Computer and Emerging 
Sciences, Lahore, Pakistan.
Jurafsky, D., A. Acero, H.-W. Hon, 1999.  Speech  
and  Language  Processing:  An  Introduction  to  
Natural  Language  Processing,  Computational 
Linguistics and Speech Recognition (pp. 189 ?  
230). Prentice-Hall Inc., New Jersey 07458.
Nugues,  P.M. 2006.  An Introduction to Language 
Processing with Perl and Prolog: An Outline of  
Theories, Implementation, and Application with 
Special  Consideration of  English,  French,  and  
German  (Cognitive  Technologies)  (pp.  87  ? 
104). Springer-Verlag Berlin Heidelberg 
Pong,  L.W.  and  Robert.  1994.  Chinese  word 
segmentation  based  on  maximal  matching and  
bigram  techniques.  Retrieved  from  The 
Association  for  Computational  Linguistics  and 
Chinese  Language  Processing.  On-line: 
http://www.aclclp.org.tw/rocling/1994/P04.pdf
Sunthi,  Thepchai.  2007.  Word  Segmentation  and 
POS  tagging.  ADD-2  Workshop,  SIIT, 
NECTEC, Thailand.
Van Driem, George. and Karma Tshering, (Collab), 
?Languages  of  Greater  Himalayan  Region?, 
1998.
102
