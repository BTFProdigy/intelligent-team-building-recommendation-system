Proceedings of ACL-08: HLT, pages 218?226,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Regular tree grammars as a formalism for scope underspecification
Alexander Koller?
a.koller@ed.ac.uk
? University of Edinburgh
Michaela Regneri? ?
regneri@coli.uni-sb.de
? University of Groningen
Stefan Thater?
stth@coli.uni-sb.de
? Saarland University
Abstract
We propose the use of regular tree grammars
(RTGs) as a formalism for the underspecified
processing of scope ambiguities. By applying
standard results on RTGs, we obtain a novel
algorithm for eliminating equivalent readings
and the first efficient algorithm for computing
the best reading of a scope ambiguity. We also
show how to derive RTGs from more tradi-
tional underspecified descriptions.
1 Introduction
Underspecification (Reyle, 1993; Copestake et al,
2005; Bos, 1996; Egg et al, 2001) has become the
standard approach to dealing with scope ambiguity
in large-scale hand-written grammars (see e.g. Cope-
stake and Flickinger (2000)). The key idea behind
underspecification is that the parser avoids comput-
ing all scope readings. Instead, it computes a single
compact underspecified description for each parse.
One can then strengthen the underspecified descrip-
tion to efficiently eliminate subsets of readings that
were not intended in the given context (Koller and
Niehren, 2000; Koller and Thater, 2006); so when
the individual readings are eventually computed, the
number of remaining readings is much smaller and
much closer to the actual perceived ambiguity of the
sentence.
In the past few years, a ?standard model? of scope
underspecification has emerged: A range of for-
malisms from Underspecified DRT (Reyle, 1993)
to dominance graphs (Althaus et al, 2003) have
offered mechanisms to specify the ?semantic mate-
rial? of which the semantic representations are built
up, plus dominance or outscoping relations between
these building blocks. This has been a very suc-
cessful approach, but recent algorithms for elimi-
nating subsets of readings have pushed the expres-
sive power of these formalisms to their limits; for
instance, Koller and Thater (2006) speculate that
further improvements over their (incomplete) redun-
dancy elimination algorithm require a more expres-
sive formalism than dominance graphs. On the theo-
retical side, Ebert (2005) has shown that none of
the major underspecification formalisms are expres-
sively complete, i.e. supports the description of an
arbitrary subset of readings. Furthermore, the some-
what implicit nature of dominance-based descrip-
tions makes it difficult to systematically associate
readings with probabilities or costs and then com-
pute a best reading.
In this paper, we address both of these shortcom-
ings by proposing regular tree grammars (RTGs)
as a novel underspecification formalism. Regular
tree grammars (Comon et al, 2007) are a standard
approach for specifying sets of trees in theoretical
computer science, and are closely related to regu-
lar tree transducers as used e.g. in recent work on
statistical MT (Knight and Graehl, 2005) and gram-
mar formalisms (Shieber, 2006). We show that the
?dominance charts? proposed by Koller and Thater
(2005b) can be naturally seen as regular tree gram-
mars; using their algorithm, classical underspecified
descriptions (dominance graphs) can be translated
into RTGs that describe the same sets of readings.
However, RTGs are trivially expressively complete
because every finite tree language is also regular. We
exploit this increase in expressive power in present-
ing a novel redundancy elimination algorithm that is
simpler and more powerful than the one by Koller
and Thater (2006); in our algorithm, redundancy
elimination amounts to intersection of regular tree
languages. Furthermore, we show how to define a
PCFG-style cost model on RTGs and compute best
readings of deterministic RTGs efficiently, and illus-
trate this model on a machine learning based model
218
of scope preferences (Higgins and Sadock, 2003).
To our knowledge, this is the first efficient algorithm
for computing best readings of a scope ambiguity in
the literature.
The paper is structured as follows. In Section 2,
we will first sketch the existing standard approach
to underspecification. We will then define regular
tree grammars and show how to see them as an un-
derspecification formalism in Section 3. We will
present the new redundancy elimination algorithm,
based on language intersection, in Section 4, and
show how to equip RTGs with weights and compute
best readings in Section 5. We conclude in Section 6.
2 Underspecification
The key idea behind scope underspecification is to
describe all readings of an ambiguous expression
with a single, compact underspecified representation
(USR). This simplifies semantics construction, and
current algorithms (Koller and Thater, 2005a) sup-
port the efficient enumeration of readings from an
USR when it is necessary. Furthermore, it is possible
to perform certain semantic processing tasks such
as eliminating redundant readings (see Section 4) di-
rectly on the level of underspecified representations
without explicitly enumerating individual readings.
Under the ?standard model? of scope underspeci-
fication, readings are considered as formulas or trees.
USRs specify the ?semantic material? common to
all readings, plus dominance or outscopes relations
between these building blocks. In this paper, we con-
sider dominance graphs (Egg et al, 2001; Althaus
et al, 2003) as one representative of this class. An
example dominance graph is shown on the left of
Fig. 1. It represents the five readings of the sentence
?a representative of a company saw every sample.?
The (directed, labelled) graph consists of seven sub-
trees, or fragments, plus dominance edges relating
nodes of these fragments. Each reading is encoded
as one configuration of the dominance graph, which
can be obtained by ?plugging? the tree fragments
into each other, in a way that respects the dominance
edges: The source node of each dominance edge
must dominate (i.e., be an ancestor of) the target
node in each configuration. The trees in Fig. 1a?e
are the five configurations of the example graph.
An important class of dominance graphs are hy-
pernormally connected dominance graphs, or dom-
inance nets (Niehren and Thater, 2003). The pre-
cise definition of dominance nets is not important
here, but note that virtually all underspecified de-
scriptions that are produced by current grammars are
nets (Flickinger et al, 2005). For the rest of the pa-
per, we restrict ourselves to dominance graphs that
are hypernormally connected.
3 Regular tree grammars
We will now recall the definition of regular tree
grammars and show how they can be used as an un-
derspecification formalism.
3.1 Definition
Let ? be an alphabet, or signature, of tree construc-
tors { f ,g,a, . . .}, each of which is equipped with an
arity ar( f )? 0. A finite constructor tree t is a finite
tree in which each node is labelled with a symbol of
?, and the number of children of the node is exactly
the arity of this symbol. For instance, the configura-
tions in Fig. 1a-e are finite constructor trees over the
signature {ax|2,ay|2,compz|0, . . .}. Finite construc-
tor trees can be seen as ground terms over ? that
respect the arities. We write T (?) for the finite con-
structor trees over ?.
A regular tree grammar (RTG) is a 4-tuple G =
(S,N,?,R) consisting of a nonterminal alphabet N,
a terminal alphabet ?, a start symbol S ? N, and a
finite set of production rules R of the form A? ? ,
where A ? N and ? ? T (??N); the nonterminals
count as zero-place constructors. Two finite con-
structor trees t, t ? ? T (? ? N) stand in the deriva-
tion relation, t ?G t ?, if t ? can be built from t by
replacing an occurrence of some nonterminal A by
the tree on the right-hand side of some production
for A. The language generated by G, L(G), is the set
{t ? T (?) | S??G t}, i.e. all terms of terminal sym-
bols that can be derived from the start symbol by a
sequence of rule applications. Note that L(G) is a
possibly infinite language of finite trees. As usual,
we write A? t1 | . . . | tn as shorthand for the n pro-
duction rules A? ti (1 ? i ? n). See Comon et al
(2007) for more details.
The languages that can be accepted by regular tree
grammars are called regular tree languages (RTLs),
and regular tree grammars are equivalent to regular
219
every
y
sample
y
see
x,y
a
x
repr-of
x,z
a
z
comp
z
12 3
4 5 6
7
every
y
a
x
sample
y
see
x,y
repr-of
x,z
a
z
comp
z
(a)
every
y
a
z
a
x
sample
y
see
x,y
comp
z
repr-of
x,z
(c)
every
y
a
z
a
x
sample
y
see
x,y
comp
z
repr-of
x,z
(d)(b)
every
y
sample
y
see
x,y
a
x
repr-of
x,z
a
z
comp
z
(e)
every
y
sample
y
a
x
repr-of
x,z
see
x,y
a
z
comp
z
Figure 1: A dominance graph (left) and its five configurations.
tree automata, which are defined essentially like the
well-known regular string automata, except that they
assign states to the nodes in a tree rather than the po-
sitions in a string. Tree automata are related to tree
transducers as used e.g. in statistical machine trans-
lation (Knight and Graehl, 2005) exactly like finite-
state string automata are related to finite-state string
transducers, i.e. they use identical mechanisms to ac-
cept rather than transduce languages. Many theoreti-
cal results carry over from regular string languages
to regular tree languages; for instance, membership
of a tree in a RTL can be decided in linear time,
RTLs are closed under intersection, union, and com-
plement, and so forth.
3.2 Regular tree grammars in
underspecification
We can now use regular tree grammars in underspeci-
fication by representing the semantic representations
as trees and taking an RTG G as an underspecified
description of the trees in L(G). For example, the
five configurations in Fig. 1 can be represented as
the tree language accepted by the following gram-
mar with start symbol S.
S ? ax(A1,A2) | az(B1,A3) | everyy(B3,A4)
A1 ? az(B1,B2)
A2 ? everyy(B3,B4)
A3 ? ax(B2,A2) | everyy(B3,A5)
A4 ? ax(A1,B4) | az(B1,A5)
A5 ? ax(B2,B4)
B1 ? compz B2 ? repr-ofx,z
B3 ? sampley B4 ? seex,y
More generally, every finite set of trees can be
written as the tree language accepted by a non-
recursive regular tree grammar such as this. This
grammar can be much smaller than the set of trees,
because nonterminal symbols (which stand for sets
of possibly many subtrees) can be used on the right-
hand sides of multiple rules. Thus an RTG is a com-
pact representation of a set of trees in the same way
that a parse chart is a compact representation of the
set of parse trees of a context-free string grammar.
Note that each tree can be enumerated from the RTG
in linear time.
3.3 From dominance graphs to tree grammars
Furthermore, regular tree grammars can be system-
atically computed from more traditional underspeci-
fied descriptions. Koller and Thater (2005b) demon-
strate how to compute a dominance chart from a
dominance graph D by tabulating how a subgraph
can be decomposed into smaller subgraphs by re-
moving what they call a ?free fragment?. If D is
hypernormally connected, this chart can be read as
a regular tree grammar whose nonterminal symbols
are subgraphs of the dominance graph, and whose
terminal symbols are names of fragments. For the
example graph in Fig. 1, it looks as follows.
{1,2,3,4,5,6,7} ? 1({2,4,5},{3,6,7})
{1,2,3,4,5,6,7} ? 2({4},{1,3,5,6,7})
{1,2,3,4,5,6,7} ? 3({6},{1,2,4,5,7})
{1,3,5,6,7} ? 1({5},{3,6,7}) | 3({6},{1,5,7})
{1,2,4,5,7} ? 1({2,4,5},{7}) | 2({4},{1,5,7})
{1,5,7} ? 1({5},{7})
{2,4,5} ? 2({4},{5}) {4} ? 4 {6}? 6
{3,6,7} ? 3({6},{7}) {5} ? 5 {7}? 7
This grammar accepts, again, five different trees,
whose labels are the node names of the dominance
graph, for instance 1(2(4,5),3(6,7)). If f : ?? ??
is a relabelling function from one terminal alpha-
bet to another, we can write f (G) for the grammar
(S,N,??,R?), where R? = {A ? f (a)(B1, . . . ,Bn) |
A? a(B1, . . . ,Bn) ? R}. Now if we choose f to be
the labelling function of D (which maps node names
to node labels) and G is the chart of D, then L( f (G))
will be the set of configurations of D. The grammar
in Section 3.2 is simply f (G) for the chart above (up
to consistent renaming of nonterminals).
In the worst case, the dominance chart of a dom-
inance graph with n fragments has O(2n) produc-
tion rules (Koller and Thater, 2005b), i.e. charts may
be exponential in size; but note that this is still an
220
1,0E+00
1,0E+04
1,0E+08
1,0E+12
1,0E+16
1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33
#fragments
#
c
o
n
f
i
g
u
r
a
t
i
o
n
s
/
r
u
l
e
s
0
10
20
30
40
50
60
70
80
#
s
e
n
t
e
n
c
e
s
#sentences
#production rules in chart
#configurations
Figure 2: Chart sizes in the Rondane corpus.
improvement over the n! configurations that these
worst-case examples have. In practice, RTGs that
are computed by converting the USR computed by a
grammar remain compact: Fig. 2 compares the aver-
age number of configurations and the average num-
ber of RTG production rules for USRs of increasing
sizes in the Rondane treebank (see Sect. 4.3); the
bars represent the number of sentences for USRs of a
certain size. Even for the most ambiguous sentence,
which has about 4.5?1012 scope readings, the domi-
nance chart has only about 75 000 rules, and it takes
only 15 seconds on a modern consumer PC (Intel
Core 2 Duo at 2 GHz) to compute the grammar from
the graph. Computing the charts for all 999 MRS-
nets in the treebank takes about 45 seconds.
4 Expressive completeness and
redundancy elimination
Because every finite tree language is regular, RTGs
constitute an expressively complete underspecifica-
tion formalism in the sense of Ebert (2005): They
can represent arbitrary subsets of the original set of
readings. Ebert shows that the classical dominance-
based underspecification formalisms, such as MRS,
Hole Semantics, and dominance graphs, are all
expressively incomplete, which Koller and Thater
(2006) speculate might be a practical problem for al-
gorithms that strengthen USRs to remove unwanted
readings. We will now show how both the expres-
sive completeness and the availability of standard
constructions for RTGs can be exploited to get an
improved redundancy elimination algorithm.
4.1 Redundancy elimination
Redundancy elimination (Vestre, 1991; Chaves,
2003; Koller and Thater, 2006) is the problem of de-
riving from an USR U another USR U ?, such that
the readings of U ? are a proper subset of the read-
ings of U , but every reading in U is semantically
equivalent to some reading in U ?. For instance, the
following sentence from the Rondane treebank is an-
alyzed as having six quantifiers and 480 readings by
the ERG grammar; these readings fall into just two
semantic equivalence classes, characterized by the
relative scope of ?the lee of? and ?a small hillside?.
A redundancy elimination would therefore ideally re-
duce the underspecified description to one that has
only two readings (one for each class).
(1) We quickly put up the tents in the lee of a
small hillside and cook for the first time in the
open. (Rondane 892)
Koller and Thater (2006) define semantic equiva-
lence in terms of a rewrite system that specifies un-
der what conditions two quantifiers may exchange
their positions without changing the meaning of the
semantic representation. For example, if we assume
the following rewrite system (with just a single rule),
the five configurations in Fig. 1a-e fall into three
equivalence classes ? indicated by the dotted boxes
around the names a-e ? because two pairs of read-
ings can be rewritten into each other.
(2) ax(az(P,Q),R)? az(P,ax(Q,R))
Based on this definition, Koller and Thater (2006)
present an algorithm (henceforth, KT06) that deletes
rules from a dominance chart and thus removes sub-
sets of readings from the USR. The KT06 algorithm
is fast and quite effective in practice. However, it es-
sentially predicts for each production rule of a dom-
inance chart whether each configuration that can be
built with this rule is equivalent to a configuration
that can be built with some other production for the
same subgraph, and is therefore rather complex.
4.2 Redundancy elimination as language
intersection
We now define a new algorithm for redundancy elim-
ination. It is based on the intersection of regular tree
languages, and will be much simpler and more pow-
erful than KT06.
Let G = (S,N,?,R) be an RTG with a linear or-
der on the terminals ?; for ease of presentation, we
assume ? ? N. Furthermore, let f : ?? ?? be a re-
labelling function into the signature ?? of the rewrite
221
system. For example, G could be the dominance
chart of some dominance graph D, and f could be
the labelling function of D.
We can then define a tree language LF as follows:
LF contains all trees over ? that do not contain a sub-
tree of the form q1(x1, . . . ,xi?1,q2(. . .),xi+1, . . . ,xk)
where q1 > q2 and the rewrite system contains a rule
that has f (q1)(X1, . . . ,Xi?1, f (q2)(. . .),Xi+1, . . . ,Xk)
on the left or right hand side. LF is a regular tree lan-
guage, and can be accepted by a regular tree gram-
mar GF with O(n) nonterminals and O(n2) rules,
where n = |??|. A filter grammar for Fig. 1 looks
as follows:
S ? 1(S,S) | 2(S,Q1) | 3(S,S) | 4 | . . . | 7
Q1 ? 2(S,Q1) | 3(S,S) | 4 | . . . | 7
This grammar accepts all trees over ? except ones
in which a node with label 2 is the parent of a node
with label 1, because such trees correspond to config-
urations in which a node with label az is the parent of
a node with label ax, az and ax are permutable, and
2 > 1. In particular, it will accept the configurations
(b), (c), and (e) in Fig. 1, but not (a) or (d).
Since regular tree languages are closed under in-
tersection, we can compute a grammar G? such that
L(G?) = L(G)?LF . This grammar has O(nk) nonter-
minals and O(n2k) productions, where k is the num-
ber of production rules in G, and can be computed
in time O(n2k). The relabelled grammar f (G?) ac-
cepts all trees in which adjacent occurrences of per-
mutable quantifiers are in a canonical order (sorted
from lowest to highest node name). For example, the
grammar G? for the example looks as follows; note
that the nonterminal alphabet of G? is the product of
the nonterminal alphabets of G and GF .
{1,2,3,4,5,6,7}S ? 1({2,4,5}S,{3,6,7}S)
{1,2,3,4,5,6,7}S ? 2({4}S,{1,3,5,6,7}Q1)
{1,2,3,4,5,6,7}S ? 3({6}S,{1,2,4,5,7}S)
{1,3,5,6,7}Q1 ? 3({6}S,{1,5,7}S)
{1,2,4,5,7}S ? 1({2,4,5}S,{7}S)
{1,2,4,5,7}S ? 2({4}S,{1,5,7}Q1)
{2,4,5}S ? 2({4}S,{5}Q1) {4}S ? 4
{3,6,7}S ? 3({6}S,{7}S) {5}S ? 5
{1,5,7}S ? 1({5}S,{7}S) {5}Q1 ? 5
{6}S ? 6 {7}S ? 7
Significantly, the grammar contains no produc-
tions for {1,3,5,6,7}Q1 with terminal symbol 1, and
no production for {1,5,7}Q1 . This reduces the tree
language accepted by f (G?) to just the configura-
tions (b), (c), and (e) in Fig. 1, i.e. exactly one
representative of every equivalence class. Notice
that there are two different nonterminals, {5}Q1 and
{5}S, corresponding to the subgraph {5}, so the in-
tersected RTG is not a dominance chart any more.
As we will see below, this increased expressivity in-
creases the power of the redundancy elimination al-
gorithm.
4.3 Evaluation
The algorithm presented here is not only more trans-
parent than KT06, but also more powerful; for exam-
ple, it will reduce the graph in Fig. 4 of Koller and
Thater (2006) completely, whereas KT06 won?t.
To measure the extent to which the new algo-
rithm improves upon KT06, we compare both algo-
rithms on the USRs in the Rondane treebank (ver-
sion of January 2006). The Rondane treebank is a
?Redwoods style? treebank (Oepen et al, 2002) con-
taining MRS-based underspecified representations
for sentences from the tourism domain, and is dis-
tributed together with the English Resource Gram-
mar (ERG) (Copestake and Flickinger, 2000).
The treebank contains 999 MRS-nets, which we
translate automatically into dominance graphs and
further into RTGs; the median number of scope read-
ings per sentence is 56. For our experiment, we con-
sider all 950 MRS-nets with less than 650 000 con-
figurations. We use a slightly weaker version of the
rewrite system that Koller and Thater (2006) used in
their evaluation.
It turns out that the median number of equivalence
classes, computed by pairwise comparison of all con-
figurations, is 8. The median number of configu-
rations that remain after running our algorithm is
also 8. By contrast, the median number after run-
ning KT06 is 11. For a more fine-grained compari-
son, Fig. 3 shows the percentage of USRs for which
the two algorithms achieve complete reduction, i.e.
retain only one reading per equivalence class. In the
diagram, we have grouped USRs according to the
natural logarithm of their numbers of configurations,
and report the percentage of USRs in this group on
which the algorithms were complete. The new algo-
rithm dramatically outperforms KT06: In total, it re-
duces 96% of all USRs completely, whereas KT06
was complete only for 40%. This increase in com-
pleteness is partially due to the new algorithm?s abil-
ity to use non-chart RTGs: For 28% of the sentences,
222
0%
20%
40%
60%
80%
100%
1 3 5 7 9 11 13
KT06 RTG
Figure 3: Percentage of USRs in Rondane for which the
algorithms achieve complete reduction.
it computes RTGs that are not dominance charts.
KT06 was only able to reduce 5 of these 263 graphs
completely.
The algorithm needs 25 seconds to run for the
entire corpus (old algorithm: 17 seconds), and it
would take 50 (38) more seconds to run on the 49
large USRs that we exclude from the experiment.
By contrast, it takes about 7 hours to compute the
equivalence classes by pairwise comparison, and it
would take an estimated several billion years to com-
pute the equivalence classes of the excluded USRs.
In short, the redundancy elimination algorithm pre-
sented here achieves nearly complete reduction at a
tiny fraction of the runtime, and makes a useful task
that was completely infeasible before possible.
4.4 Compactness
Finally, let us briefly consider the ramifications of
expressive completeness on efficiency. Ebert (2005)
proves that no expressively complete underspecifi-
cation formalism can be compact, i.e. in the worst
case, the USR of a set of readings become exponen-
tially large in the number of scope-bearing operators.
In the case of RTGs, this worst case is achieved by
grammars of the form S? t1 | . . . | tn, where t1, . . . , tn
are the trees we want to describe. This grammar is as
big as the number of readings, i.e. worst-case expo-
nential in the number n of scope-bearing operators,
and essentially amounts to a meta-level disjunction
over the readings.
Ebert takes the incompatibility between compact-
ness and expressive completeness as a fundamental
problem for underspecification. We don?t see things
quite as bleakly. Expressions of natural language it-
self are (extremely underspecified) descriptions of
sets of semantic representations, and so Ebert?s ar-
gument applies to NL expressions as well. This
means that describing a given set of readings may
require an exponentially long discourse. Ebert?s def-
inition of compactness may be too harsh: An USR,
although exponential-size in the number of quanti-
fiers, may still be polynomial-size in the length of
the discourse in the worst case.
Nevertheless, the tradeoff between compactness
and expressive power is important for the design
of underspecification formalisms, and RTGs offer a
unique answer. They are expressively complete; but
as we have seen in Fig. 2, the RTGs that are derived
by semantic construction are compact, and even in-
tersecting them with filter grammars for redundancy
elimination only blows up their sizes by a factor of
O(n2). As we add more and more information to
an RTG to reduce the set of readings, ultimately to
those readings that were meant in the actual context
of the utterance, the grammar will become less and
less compact; but this trend is counterbalanced by
the overall reduction in the number of readings. For
the USRs in Rondane, the intersected RTGs are, on
average, 6% smaller than the original charts. Only
30% are larger than the charts, by a maximal factor
of 3.66. Therefore we believe that the theoretical
non-compactness should not be a major problem in
a well-designed practical system.
5 Computing best configurations
A second advantage of using RTGs as an under-
specification formalism is that we can apply exist-
ing algorithms for computing the best derivations
of weighted regular tree grammars to compute best
(that is, cheapest or most probable) configurations.
This gives us the first efficient algorithm for comput-
ing the preferred reading of a scope ambiguity.
We define weighted dominance graphs and
weighted tree grammars, show how to translate the
former into the latter and discuss an example.
5.1 Weighted dominance graphs
A weighted dominance graph D = (V,ET unionmulti ED unionmulti
WDunionmultiWI) is a dominance graph with two new types
of edges ? soft dominance edges, WD, and soft dis-
jointness edges, WI ?, each of which is equipped
with a numeric weight. Soft dominance and dis-
jointness edges provide a mechanism for assigning
weights to configurations; a soft dominance edge ex-
223
every
y
sample
y
see
x,y
a
x
repr-of
x,z
a
z
comp
z
1
2
3
4 5 6
7
9
8
Figure 4: The graph of Fig. 1 with soft constraints
presses a preference that two nodes dominate each
other in a configuration, whereas a soft disjointness
edge expresses a preference that two nodes are dis-
joint, i.e. neither dominates the other.
We take the hard backbone of D to be the ordinary
dominance graph B(D) = (V,ET unionmultiED) obtained by
removing all soft edges. The set of configurations
of a weighted graph D is the set of configurations
of its hard backbone. For each configuration t of
D, we define the weight c(t) to be the product of
the weights of all soft dominance and disjointness
edges that are satisfied in t. We can then ask for
configurations of maximal weight.
Weighted dominance graphs can be used to en-
code the standard models of scope preferences
(Pafel, 1997; Higgins and Sadock, 2003). For exam-
ple, Higgins and Sadock (2003) present a machine
learning approach for determining pairwise prefer-
ences as to whether a quantifier Q1 dominates an-
other quantifier Q2, Q2 dominates Q1, or neither (i.e.
they are disjoint). We can represent these numbers
as the weights of soft dominance and disjointness
edges. An example (with artificial weights) is shown
in Fig. 4; we draw the soft dominance edges as
curved dotted arrows and the soft disjointness edges
as as angled double-headed arrows. Each soft edge
is annotated with its weight. The hard backbone
of this dominance graph is our example graph from
Fig. 1, so it has the same five configurations. The
weighted graph assigns a weight of 8 to configura-
tion (a), a weight of 1 to (d), and a weight of 9 to (e);
this is also the configuration of maximum weight.
5.2 Weighted tree grammars
In order to compute the maximal-weight configura-
tion of a weighted dominance graph, we will first
translate it into a weighted regular tree grammar. A
weighted regular tree grammar (wRTG) (Graehl and
Knight, 2004) is a 5-tuple G = (S,N,?,R,c) such
that G? = (S,N,?,R) is a regular tree grammar and
c : R? R is a function that assigns each production
rule a weight. G accepts the same language of trees
as G?. It assigns each derivation a cost equal to the
product of the costs of the production rules used in
this derivation, and it assigns each tree in the lan-
guage a cost equal to the sum of the costs of its
derivations. Thus wRTGs define weights in a way
that is extremely similar to PCFGs, except that we
don?t require any weights to sum to one.
Given a weighted, hypernormally connected dom-
inance graph D, we can extend the chart of B(D) to
a wRTG by assigning rule weights as follows: The
weight of a rule D0 ? i(D1, . . . ,Dn) is the product
over the weights of all soft dominance and disjoint-
ness edges that are established by this rule. We say
that a rule establishes a soft dominance edge from
u to v if u = i and v is in one of the subgraphs
D1, . . . ,Dn; we say that it establishes a soft disjoint-
ness edge between u and v if u and v are in different
subgraphs D j and Dk ( j 6= k). It can be shown that
the weight this grammar assigns to each derivation
is equal to the weight that the original dominance
graph assigns to the corresponding configuration.
If we apply this construction to the example graph
in Fig. 4, we obtain the following wRTG:
{1, ...,7} ? ax({2,4,5},{3,6,7}) [9]
{1, ...,7} ? az({4},{1,3,5,6,7}) [1]
{1, ...,7} ? everyy({6},{1,2,4,5,7}) [8]
{2,4,5} ? az({4},{5}) [1]
{3,6,7} ? everyy({6},{7}) [1]
{1,3,5,6,7} ? ax({5},{3,6,7}) [1]
{1,3,5,6,7} ? everyy({6},{1,5,7}) [8]
{1,2,4,5,7} ? ax({2,4,5},{7}) [1]
{1,2,4,5,7} ? az({4},{1,5,7}) [1]
{1,5,7} ? ax({5},{7}) [1]
{4} ? compz [1] {5} ? repr?o f x,z [1]
{6} ? sampley [1] {7} ? seex,y [1]
For example, picking ?az? as the root of a con-
figuration (Fig. 1 (c), (d)) of the entire graph has
a weight of 1, because this rule establishes no soft
edges. On the other hand, choosing ?ax? as the root
has a weight of 9, because this establishes the soft
disjointness edge (and in fact, leads to the derivation
of the maximum-weight configuration in Fig. 1 (e)).
5.3 Computing the best configuration
The problem of computing the best configuration of
a weighted dominance graph ? or equivalently, the
224
best derivation of a weighted tree grammar ? can
now be solved by standard algorithms for wRTGs.
For example, Knight and Graehl (2005) present an
algorithm to extract the best derivation of a wRTG in
time O(t + n logn) where n is the number of nonter-
minals and t is the number of rules. In practice, we
can extract the best reading of the most ambiguous
sentence in the Rondane treebank (4.5? 1012 read-
ings, 75 000 grammar rules) with random soft edges
in about a second.
However, notice that this is not the same problem
as computing the best tree in the language accepted
by a wRTG, as trees may have multiple deriva-
tions. The problem of computing the best tree is NP-
complete (Sima?an, 1996). However, if the weighted
regular tree automaton corresponding to the wRTG
is deterministic, every tree has only one derivation,
and thus computing best trees becomes easy again.
The tree automata for dominance charts are always
deterministic, and the automata for RTGs as in Sec-
tion 3.2 (whose terminals correspond to the graph?s
node labels) are also typically deterministic if the
variable names are part of the quantifier node labels.
Furthermore, there are algorithms for determinizing
weighted tree automata (Borchardt and Vogler, 2003;
May and Knight, 2006), which could be applied as
preprocessing steps for wRTGs.
6 Conclusion
In this paper, we have shown how regular tree gram-
mars can be used as a formalism for scope under-
specification, and have exploited the power of this
view in a novel, simpler, and more complete algo-
rithm for redundancy elimination and the first effi-
cient algorithm for computing the best reading of a
scope ambiguity. In both cases, we have adapted
standard algorithms for RTGs, which illustrates the
usefulness of using such a well-understood formal-
ism. In the worst case, the RTG for a scope ambigu-
ity is exponential in the number of scope bearers in
the sentence; this is a necessary consequence of their
expressive completeness. However, those RTGs that
are computed by semantic construction and redun-
dancy elimination remain compact.
Rather than showing how to do semantic construc-
tion for RTGs, we have presented an algorithm that
computes RTGs from more standard underspecifica-
tion formalisms. We see RTGs as an ?underspecifi-
cation assembly language? ? they support efficient
and useful algorithms, but direct semantic construc-
tion may be inconvenient, and RTGs will rather be
obtained by ?compiling? higher-level underspecified
representations such as dominance graphs or MRS.
This perspective also allows us to establish a
connection to approaches to semantic construc-
tion which use chart-based packing methods rather
than dominance-based underspecification to manage
scope ambiguities. For instance, both Combinatory
Categorial Grammars (Steedman, 2000) and syn-
chronous grammars (Nesson and Shieber, 2006) rep-
resent syntactic and semantic ambiguity as part of
the same parse chart. These parse charts can be
seen as regular tree grammars that accept the lan-
guage of parse trees, and conceivably an RTG that
describes only the semantic and not the syntactic
ambiguity could be automatically extracted. We
could thus reconcile these completely separate ap-
proaches to semantic construction within the same
formal framework, and RTG-based algorithms (e.g.,
for redundancy elimination) would apply equally to
dominance-based and chart-based approaches. In-
deed, for one particular grammar formalism it has
even been shown that the parse chart contains an
isomorphic image of a dominance chart (Koller and
Rambow, 2007).
Finally, we have only scratched the surface of
what can be be done with the computation of best
configurations in Section 5. The algorithms gen-
eralize easily to weights that are taken from an ar-
bitrary ordered semiring (Golan, 1999; Borchardt
and Vogler, 2003) and to computing minimal-weight
rather than maximal-weight configurations. It is also
useful in applications beyond semantic construction,
e.g. in discourse parsing (Regneri et al, 2008).
Acknowledgments. We have benefited greatly
from fruitful discussions on weighted tree grammars
with Kevin Knight and Jonathan Graehl, and on dis-
course underspecification with Markus Egg. We
also thank Christian Ebert, Marco Kuhlmann, Alex
Lascarides, and the reviewers for their comments on
the paper. Finally, we are deeply grateful to our for-
mer colleague Joachim Niehren, who was a great fan
of tree automata before we even knew what they are.
225
References
E. Althaus, D. Duchier, A. Koller, K. Mehlhorn,
J. Niehren, and S. Thiel. 2003. An efficient graph
algorithm for dominance constraints. J. Algorithms,
48:194?219.
B. Borchardt and H. Vogler. 2003. Determinization of
finite state weighted tree automata. Journal of Au-
tomata, Languages and Combinatorics, 8(3):417?463.
J. Bos. 1996. Predicate logic unplugged. In Proceedings
of the Tenth Amsterdam Colloquium, pages 133?143.
R. P. Chaves. 2003. Non-redundant scope disambigua-
tion in underspecified semantics. In Proceedings of
the 8th ESSLLI Student Session, pages 47?58, Vienna.
H. Comon, M. Dauchet, R. Gilleron, C. Lo?ding,
F. Jacquemard, D. Lugiez, S. Tison, and M. Tommasi.
2007. Tree automata techniques and applications.
Available on: http://www.grappa.univ-lille3.fr/tata.
A. Copestake and D. Flickinger. 2000. An open-
source grammar development environment and broad-
coverage English grammar using HPSG. In Confer-
ence on Language Resources and Evaluation.
A. Copestake, D. Flickinger, C. Pollard, and I. Sag. 2005.
Minimal recursion semantics: An introduction. Re-
search on Language and Computation, 3:281?332.
C. Ebert. 2005. Formal investigations of underspecified
representations. Ph.D. thesis, King?s College, Lon-
don.
M. Egg, A. Koller, and J. Niehren. 2001. The Constraint
Language for Lambda Structures. Logic, Language,
and Information, 10:457?485.
D. Flickinger, A. Koller, and S. Thater. 2005. A new
well-formedness criterion for semantics debugging. In
Proceedings of the 12th HPSG Conference, Lisbon.
J. S. Golan. 1999. Semirings and their applications.
Kluwer, Dordrecht.
J. Graehl and K. Knight. 2004. Training tree transducers.
In HLT-NAACL 2004, Boston.
D. Higgins and J. Sadock. 2003. A machine learning ap-
proach to modeling scope preferences. Computational
Linguistics, 29(1).
K. Knight and J. Graehl. 2005. An overview of proba-
bilistic tree transducers for natural language process-
ing. In Computational linguistics and intelligent text
processing, pages 1?24. Springer.
A. Koller and J. Niehren. 2000. On underspecified
processing of dynamic semantics. In Proceedings of
COLING-2000, Saarbru?cken.
A. Koller and O. Rambow. 2007. Relating dominance
formalisms. In Proceedings of the 12th Conference on
Formal Grammar, Dublin.
A. Koller and S. Thater. 2005a. Efficient solving and
exploration of scope ambiguities. Proceedings of the
ACL-05 Demo Session.
A. Koller and S. Thater. 2005b. The evolution of dom-
inance constraint solvers. In Proceedings of the ACL-
05 Workshop on Software.
A. Koller and S. Thater. 2006. An improved redundancy
elimination algorithm for underspecified descriptions.
In Proceedings of COLING/ACL-2006, Sydney.
J. May and K. Knight. 2006. A better n-best list: Prac-
tical determinization of weighted finite tree automata.
In Proceedings of HLT-NAACL.
R. Nesson and S. Shieber. 2006. Simpler TAG semantics
through synchronization. In Proceedings of the 11th
Conference on Formal Grammar.
J. Niehren and S. Thater. 2003. Bridging the gap be-
tween underspecification formalisms: Minimal recur-
sion semantics as dominance constraints. In Proceed-
ings of ACL 2003.
S. Oepen, K. Toutanova, S. Shieber, C. Manning,
D. Flickinger, and T. Brants. 2002. The LinGO Red-
woods treebank: Motivation and preliminary applica-
tions. In Proceedings of the 19th International Con-
ference on Computational Linguistics (COLING?02),
pages 1253?1257.
J. Pafel. 1997. Skopus und logische Struktur: Studien
zum Quantorenskopus im Deutschen. Habilitationss-
chrift, Eberhard-Karls-Universita?t Tu?bingen.
M. Regneri, M. Egg, and A. Koller. 2008. Efficient pro-
cessing of underspecified discourse representations. In
Proceedings of the 46th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (ACL-08: HLT) ? Short Papers,
Columbus, Ohio.
U. Reyle. 1993. Dealing with ambiguities by underspec-
ification: Construction, representation and deduction.
Journal of Semantics, 10(1).
S. Shieber. 2006. Unifying synchronous tree-adjoining
grammars and tree transducers via bimorphisms. In
Proceedings of the 11th Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL-06), Trento, Italy.
K. Sima?an. 1996. Computational complexity of proba-
bilistic disambiguation by means of tree-grammars. In
Proceedings of the 16th conference on Computational
linguistics, pages 1175?1180, Morristown, NJ, USA.
Association for Computational Linguistics.
M. Steedman. 2000. The syntactic process. MIT Press.
E. Vestre. 1991. An algorithm for generating non-
redundant quantifier scopings. In Proc. of EACL,
pages 251?256, Berlin.
226
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 245?248,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Efficient Processing of Underspecified Discourse Representations
Michaela Regneri? ?
regneri@coli.uni-sb.de
? Saarland University
Markus Egg?
egg@let.rug.nl
? University of Groningen
Alexander Koller?
a.koller@ed.ac.uk
? University of Edinburgh
Abstract
Underspecification-based algorithms for pro-
cessing partially disambiguated discourse
structure must cope with extremely high num-
bers of readings. Based on previous work on
dominance graphs and weighted tree gram-
mars, we provide the first possibility for com-
puting an underspecified discourse description
and a best discourse representation efficiently
enough to process even the longest discourses
in the RST Discourse Treebank.
1 Introduction
Discourse processing has emerged as a highly rele-
vant source of information for applications such as
information extraction and automatic summarisation
(Taboada and Mann (2006) outline this and further
applications). But discourse structures cannot al-
ways be described completely, either due to genuine
ambiguity (Stede, 2004) or to the limitations of a
discourse parser. In either case, only partial infor-
mation on discourse structure is available. To han-
dle such information, underspecification formalisms
can be used. Underspecification was originally in-
troduced in computational semantics to model struc-
tural ambiguity without disjunctively enumerating
the readings, and later applied to discourse parsing
(Gardent and Webber, 1998; Schilder, 2002).
However, while the existing algorithms for un-
derspecification processing work well for seman-
tic structures, they were not designed for discourse
structures, which can be much larger. Indeed, it
has never been shown that underspecified discourse
reprentations (UDRs) can be processed efficiently,
since the general-purpose implementations are too
slow for that task.
In this paper, we present a new way to imple-
ment and process discourse underspecification in
terms of regular tree grammars (RTGs). RTGs are
used as an underspecification formalism in seman-
tics (Koller et al, 2008). We show how to compute
RTGs for discourse from dominance-based under-
specified representations more efficiently (by a typ-
ical factor of 100) than before. Furthermore, we
show how weighted RTGs can be used to represent
constraints and preferences on the discourse struc-
ture. Taking all these results together, we show for
the first time how the globally optimal discourse rep-
resentation based on some preference model can be
computed efficiently from an UDR.
2 Underspecified Discourse Representation
Following annotation schemes like the one of Stede
(2004), we model discourse structures by binary
trees. Fig. (1b-f) represent the potential structures of
(1). We write each elementary discourse unit (EDU)
in square brackets.
(1) [C1 I try to read a novel] [C2 if I feel bored]
[C3 because the TV programs disappoint me]
[C4 but I can?t concentrate on anything.]
Underspecification formalisms such as domi-
nance graphs (Althaus et al, 2003) can model par-
tial information about such trees; see Fig. (1a) for
the underspecified discourse representation (UDR)
of (1). These graphs consist of labelled roots and
unlabelled holes; the solid edges indicate that a
node must be the parent of another, and the dashed
edges indicate (transitive) dominance requirements.
A configuration of a dominance graph is an arrange-
ment of the (labelled) graph nodes into a tree that
satisfies all (immediate and transitive) dominance
requirements. Subgraphs that are connected by solid
edges are called fragments and must be tree-shaped.
Using UDRs, discourse parsing can be modu-
larised into three separate steps. First, a discourse
parser segments the text and generates an UDR from
it. The node labels in the UDR aren?t necessarily
fully specified (Egg and Redeker, 2007; Schilder,
245
Cause
(2)
Contrast
C
1
C
2
C
3
C
4
C
1
C
2
C
3
C
4
C
2
C
3
C
4
C
1
C
4
C
1
C
2
C
3
Condition
(1)
Condition
(1)
Condition
(1)
Condition
(1)
Cause
(2)Cause
(2)
Cause
(2)
Contrast
C
1
C
2
C
3
C
4
Condition
(1)
Cause
(2)
Contrast
Contrast
Contrast
Condition
(1)
1
2
3 5
4
7
6
Cause
(2)
Contrast
C
1
C
2
C
3
C
4
(a) (b) (c) (d) (e) (f)
Figure 1: An underspecified discourse structure and its five configurations
2002); here we pretend that they are to simplify the
presentation, as nothing in this paper hinges on it.
Then weights are added to the UDR that incorporate
preferences for discourse structures based on lin-
guistic cues. Finally, the weighted UDR can either
be processed directly by other applications, or, if a
tree structure is required, we can compute the best
configuration. In this paper, we show how an UDR
dominance graph can be converted into a regular tree
grammar efficiently. This simplifies the specifica-
tion of weights in Step 2; we also show how to ef-
ficiently compute a best tree from a weighted RTG
(Step 3). We do not discuss Step 1 in this paper.
The dominance graphs used in discourse under-
specification are constrained chains. A constrained
chain of length n consists of n upper fragments with
two holes each and n+ 1 lower fragments with no
holes. There must also be a numbering 1, . . . ,2n+1
of the fragments such that for every 1? i? n, frag-
ment 2i is an upper fragment, fragments 2i? 1 and
2i+1 are lower fragments, and there are dominance
edges from the left hole of 2i to the root of 2i?1 and
from the right hole of 2i to the root of 2i+ 1 (and
possibly further dominance edges). These numbers
are shown in circles in Fig. (1a). In discourse dom-
inance graphs, upper fragments correspond to dis-
course relations, and lower fragments correspond to
EDUs; the EDUs are ordered according to their ap-
pearance in the text, and the upper fragments con-
nect the two text spans to which they are adjacent.
3 Underspecified Processing for Discourses
Recently, Koller et al (2008) showed how to pro-
cess dominance graphs with regular tree grammars
(Comon et al, 2007, RTGs). RTGs are a grammar
formalism that describes sets of trees using produc-
tion rules which rewrite non-terminal symbols (NTs)
into terms consisting of tree constructors and possi-
bly further NTs. A tree (without NTs) is accepted
by the grammar if it can be derived by a sequence
of rule applications from a given start symbol. An
example RTG is shown in Fig. 2; its start symbol
is {1;7}, and it describes exactly the five trees in
{1;7} ? Cond({1},{3;7}) [1] {5;7} ? Contr({5},{7}) [1]
{3;7} ? Contr({3;5},{7}) [1] {3;5} ? Cause({3},{5}) [1]
{1;7} ? Contr({1;5},{7}) [1] {1;3} ? Cond({1},{3}) [5]
{1;7} ? Cause({1;3},{5;7}) [1] {1;5} ? Cond({1},{3;5}) [3]
{1;5} ? Cause({1;3},{5}) [1] {3;7} ? Cause({3},{5;7}) [1]
{1} ? C1 [1] {3} ? C2 [1] {5} ? C3 [1] {7} ? C4 [1]
Figure 2: A wRTG modelling Fig. 1
Fig. (1b-f). For example, Fig. (1e) is derived by ex-
panding the start symbol with the first rule in Fig. 2.
This determines that the tree root is labelled with
Condition; we then derive the left subtree from the
NT {1} and the right subtree from the NT {3;7}.
The NTs in the grammar correspond to subgraphs
in the dominance graph: The NT {1;7} repre-
sents the subgraph {1,2,3,4,5,6,7} (i.e. the whole
graph); the NT {1} represents the subgraph contain-
ing only the fragment 1; and so forth. The trees that
can be derived from each nonterminal correspond
exactly to the configurations of the subgraph.
Koller and Thater (2005b) presented an algorithm
for generating, from a very general class of dom-
inance graphs, an RTG that describes exactly the
same trees. For each subgraph S that is to be the
LHS of a rule, the algorithm determines the free
fragments of S, i.e. the fragments that may serve
as the root of one of its configurations, by a certain
graph algorithm. For every free fragment in S with
n holes and a root label f , the algorithm generates a
new rule of the form S? f (S1, . . . ,Sn), where each
Si corresponds to the remaining subgraph under the
i-th hole. The procedure calls itself recursively on
the subgraphs until it reaches singleton subgraphs.
While this algorithm works well with underspec-
ified semantic representations in semantics, it is too
slow for the larger discourse graphs, as we will see in
Section 5. However, we will now optimise it for the
special case of constrained chains. First, we observe
that all subgraphs ever visited by the algorithm are
connected subchains. A subchain is uniquely identi-
fiable by the positions of the first and last fragment
in the left-to-right order of the chain; we can thus
read the nonterminal {i; j} simply as a pair of inte-
gers that identifies the subchain from the i-th to the
246
Algorithm 1: GenerateRules({i; j},G,C)
if G contains rules for {i; j} then return1
if i=j then G.add({ {i; j}? Label(i) } ) else2
/* Loop over upper fragments */
for k = i+1 to j-1 step 2 do3
if ?? edge=(s,t) ? C s.t. (i ? s < k ? t ? j) ? (i ? t4
? k < s ? j) then
lSub?{i;k-1}, rSub?{k+1; j}5
G.add({i; j}? Label(i)(lSub, rSub))6
GenerateRules(lSub, G, C)7
GenerateRules(rSub, G, C)8
j-th fragment (rather than an abbreviation for a set
of fragments). i and j will generally represent lower
fragments. In the grammar in Fig. 2, {i} is an abbre-
viation of {i; i}.
We can now rephrase the Koller & Thater algo-
rithm in our terms (Algorithm 1). The most impor-
tant change is that we can now test whether an up-
per fragment k in a subgraph {i; j} is free simply by
checking whether there is no dominance edge from
some upper fragment l to some upper fragment r
such that i? l < k ? r ? j, and no dominance edge
from r to l such that i? l ? k < r ? j. For instance,
if there was a dominance edge from the right hole of
2 to the root of 6 in Fig. (1a), then 4 and 6 would
not be free, but 2 would be; and indeed, all config-
urations of this graph would have to have 2 as their
roots. Hence we can replace the graph algorithm for
freeness by a simple comparison of integers. The
general structure of the algorithm remains the same
as in (Koller and Thater, 2005b): It takes a domi-
nance graphC as its input, and recursively calls itself
on pairs {i; j} representing subgraphs while adding
rules and NTs to an RTG G.
4 Soft Discourse Constraints
RTGs can be extended to weighted regular tree
grammars (Knight and Graehl, 2005, wRTGs) by
adding numeric weights to the rules. WRTG deriva-
tions assign weights to each tree: The weight of a
tree is the product of the weights of all rules that
were used in its derivation.
Egg and Regneri (2008) motivate the use of
wRTGs in discourse processing. They assign rule
weights based on corpus-extracted constraints which
express the interdependencies between discourse re-
lations and their surrounding tree structure. One
such constraint states that the right subtree of a Con-
1.00
15.65
244.95
3833.66
60000.00
0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230
new total utool total
Figure 3: Runtime Comparison
dition node should be of minimal size, which ranks
the readings of Fig. 1 (a): (b), (d) > (c) > (e), (f).
In order to state this constraint in a wRTG, we
annotate the grammar in Fig. 2 with the weights
shown in brackets. The Condition rules get higher
weights if the second NT on the RHS represents a
smaller subgraph. The grammar assigns the maxi-
mum weight of 5 to (b) and (d) (fragment 2 has a
leaf as right child), the medium weight 3 to (c) (the
right subgraph of fragment 2 contains two EDUs),
and the minimum weight 1 to (e) and (f). i.e. it ranks
the readings as intended.
Based on our implementation of nonterminals as
integer pairs, we can efficiently compute a con-
figuration with maximal weight using a version of
Knight and Graehl?s (2005) algorithm for comput-
ing the best derivation of a wRTG that is specialised
to the grammars we use.
5 Evaluation
We compare our runtimes with those of Utool
(Koller and Thater, 2005a), the fasted known solver
for general dominance graphs; it implements the
Koller & Thater algorithm. Utool runs very fast for
underspecified representations in semantics, but the
representations for discourse parsing are consider-
ably larger: The largest underspecified semantic rep-
resentation found in the Rondane treebank analysed
with the English Resource Grammar (Copestake and
Flickinger, 2000, ERG) has 4.5? 1012 structural
scope readings, but for 59% of the discourses in the
RST Discourse Treebank (Carlson et al, 2002, RST-
DT), there are more ways of configuring all EDUs
into a binary tree than that.
We evaluate the efficiency of our algorithm on 364
texts from the RST-DT, by converting each discourse
247
into a chain with one lower fragment for each EDU
and one upper fragment labelled with each anno-
tated discourse relation. We use our algorithm and
Utool to generate the RTG from the chain, assign
all soft constraints of Egg and Regneri (2008) to the
grammar, and finally compute the best configuration
according to this model. The evaluation results are
shown in Fig. 3. The horizontal axis shows the chain
length (= number of EDUs minus 1), rounded down
to multiples of ten; the (logarithmic) vertical axis
shows the average runtime in milliseconds for dis-
courses of that length. Both algorithms spend a bit
over half the runtime on computing the RTGs.
As the diagram shows, our algorithm is up to 100
times faster than Utool for the same discourses. It
is capable of computing the best configuration for
every tested discourse ? in less than one second for
86% of the texts. Utool exceeded the OS memory
limit on 77 discourses, and generally couldn?t pro-
cess any text with more than 100 EDUs. The longest
text in the RST-DT has 304 EDUs, so the UDR has
about 2.8?10178 different configurations. Our algo-
rithm computes the best configuration for this UDR
in about three minutes.
6 Conclusion
We presented the first solver for underspecified dis-
course representations that is efficient enough to
compute the globally best configurations of every
discourse in the RST discourse treebank, by exploit-
ing the fact that UDRs are very large but obey very
strong structural restrictions. Our solver converts
a dominance graph into an RTG, adds weights to
the RTG to represent discourse constraints, and then
computes the globally optimal configuration.
It takes about three minutes to compute a best
configuration with a given probability model for the
longest discourse in the treebank, out of 10178 pos-
sible configurations. For comparison, an algorithm
that enumerates a billion configurations per second
to find the best one could have inspected only about
1026 within the estimated age of the universe. So our
algorithm is useful and necessary to process real-
world underspecified discourse representations.
We have thus demonstrated that discourse pro-
cessing based on underspecification is computation-
ally feasible. Nothing in our algorithm hinges on
using RST in particular; it is compatible with any
approach that uses binary trees. In future research,
it would be interesting to complete our system into
a full-blown discourse parser by adding a module
that computes an UDR for a given text, and evaluate
whether its ability to delay decisions about discourse
structure would improve accuracy.
References
E. Althaus, D. Duchier, A. Koller, K. Mehlhorn,
J. Niehren, and S. Thiel. 2003. An efficient graph
algorithm for dominance constraints. Journal of Algo-
rithms, 48:194?219.
L. Carlson, D. Marcu, and M. E. Okurowski. 2002. RST
Discourse Treebank. LDC.
H. Comon, M. Dauchet, R. Gilleron, C. Lo?ding,
F. Jacquemard, D. Lugiez, S. Tison, and M. Tom-
masi. 2007. Tree Automata Techniques and Ap-
plications. Available on: http://www.grappa.
univ-lille3.fr/tata. Release 12-10-2007.
A. Copestake and D. Flickinger. 2000. An open-
source grammar development environment and broad-
coverage English grammar using HPSG. In Confer-
ence on Language Resources and Evaluation.
M. Egg and G. Redeker. 2007. Underspecified discourse
representation. In A. Benz and P. Ku?hnlein, editors,
Constraints in Discourse, Amsterdam. Benjamins.
M. Egg and M. Regneri. 2008. Underspecified Mod-
elling of Complex Discourse Constraints. Submitted.
C. Gardent and B. Webber. 1998. Describing Discourse
Semantics. In Proceedings of the 4th TAG+Workshop,
University of Pennsylvania, Philadelphia.
K. Knight and J. Graehl. 2005. An overview of proba-
bilistic tree transducers for natural language process-
ing. In Computational linguistics and intelligent text
processing, pages 1?24. Springer.
A. Koller and S. Thater. 2005a. Efficient solving and
exploration of scope ambiguities. Proceedings of the
ACL-05 Demo Session.
A. Koller and S. Thater. 2005b. The evolution of dom-
inance constraint solvers. In Proceedings of the ACL-
05 Workshop on Software, Ann Arbor.
A. Koller, M. Regneri, and S. Thater. 2008. Regular tree
grammars as a formalism for scope underspecification.
In Proceedings of ACL-08: HLT.
F. Schilder. 2002. Robust discourse parsing via discourse
markers, topicality and position. Natural Language
Engineering, 8:235?255.
M. Stede. 2004. The Potsdam Commentary Corpus. In
B. Webber and D. Byron, editors, ACL-04 Workshop
on Discourse Annotation.
M. Taboada andW.Mann. 2006. Applications of Rhetor-
ical Structure Theory. Discourse Studies, 8:567?588.
248
On Underspecif ied Processing of Dynamic Semantics 
Alexander Keller, Joachim Niehren 
University of the Saarland, Saarbriicken, Germany 
{koller@coli I niehren@ps}, uni-sb, de 
Abstract  
We propose a new inference system which oper- 
ales on underspecified semantic representations 
of scope and anaphora. This system exploits 
anaphoric accessibility conditions from dynamic 
selnantics to disambiguate scope ambiguities if
possible. The main feature of the system is 
that it deals with underspecified descriptions di- 
rectly, i.e. without enumeratlng readings. 
1 Introduction 
A particularly appealing aspect of lmdersl)eci- 
fication (van Deemter and Peters, 1996; Reyle, 
1993; Muskens, 1995; Pinkal, 1996; Bos, 1996) 
is that it can in principle deal very efficiently 
with local ambiguit ies - ambiguities which are 
only due to lack of inibrmation at an interme- 
diate stage of processing and go away by the 
end of the analysis. An example for this effect 
is (1): The scope ambiguity that is perceived 
alter processing the first sentence is no longer 
present after the second one. This effect can 
be explained in a framework of dynamic selnan- 
tics (Groelmndijk and Stokhof, 1991; Kamp and 
Reyle, 1993) by the fact that a wide-scope uni- 
versal quantifier would make the indefinite inac- 
cessible for anaphoric reference from the second 
sei/tence. 
(1) Every man loves a woman. 
Her nanle is Mary. 
In this paper, we show how this particular 
type of local ambiguity can be processed effi- 
ciently. The approach we propose mploys de- 
terministic inference rules that can exclude the 
readings which violate anaphoric accessibility 
conditions without enlnnerating them. These 
rules operate directly on underspecified descrip- 
tions and fully maintain underspecifiedness. We
also show how this behaviour Call be captured 
by constraint propagation i an existing imple- 
mentation of tree descriptions using finite set 
constraints (Duchier and Niehren, 2000; Keller 
and Niehren, 2000; Duchier and Gardent, 1999). 
More specifically, we introduce DPL struc- 
tuT"cs~ extended trce structures that encode for- 
mulas of dynamic predicate logic (DPL) in much 
the same way as Egg et al's (1998) lambda 
structnres encode A-terms. Then we define a 
constraint language tbr the description of DPL 
structures, called CL(DPL), in analogy to Egg 
et al's constraint langague for lambda struc- 
tures (CLLS). We characterize those DPL struc- 
tures in which all restrictions oil anaphoric ac- 
cessibility are obeyed by talking directly about 
the syntactic structure of a DPL formula. This 
is ill contrast o the standard procedure in dy- 
nanfic semantics, where the dynamic behaviour 
is produced by the semantics of the logic; we do 
not need to (and do not) talk about interpreta- 
tion of DPL structures and model accessibility 
by purely "static" means. 
The paper is structured as follows. In Sec- 
tion 2, we introduce DPL structures and tree 
descrit)tions in the language CL(DPL). In Sec- 
tion 3, we add syntactic restrictions on admis- 
sible variable bindings to DPL structures and 
present axioms that characterize these restric- 
tions. In Section 4:, we turn these axioms into 
deterministic nfhrence rules and combine them 
with deterministic inference rules known from 
an existing ilfference algorithm for dominance 
constraints. We obtain a procedure that can do 
the kind of underspccified reasoning described 
above without enmncrating readings. In Section 
5, we sketch all imtflelnentation f our inf'erence 
system based on finite set constraint prograln- 
ming. This implementation can be obtained by 
adapting an existing ilnI)lelnentation f a solver 
for dominance constraints. Finally, we conclude 
and point to further work in Section 6. 
2 Tree Descr ipt ions 
In this section, we define the Constraint Lan- 
guage tbr DPL structures, CL(DPL), a lan- 
guage of tree descriptions which conserw~tively 
extends donfinance constraints (Marcus et al, 
1983; Rainbow et al, 1995; Keller et al, 2000) 
by variable binding constraints. CL(DPL) is 
a close relative of the Constraint Language for 
460 
Lamb(la Structures (CLLS), 1)resented in (Egg 
et al, 1998). It; is interl)reted over DPL struc- 
tures - trees extended by a variable 1)inding 
function which can be used to encode tbrmulas 
of dynamic (or static) predicate logic. We will 
define DPL structures in two steps and then the 
language to talk al)out them. 
2.1 Tree St ruetures  
For the definitions below, we assulne a signature 
Y\] = {(~12, varl0,Vl~,~ll,Al.z, manll , likel2,... } of  
node labels, each of which is equipped with a 
fixed arity n _> 0. The labels A,_~,_V,... are the. 
tirst-order commctives. Node lal)els are. ranged 
over by f, g, a, b, and the arity of a lal)el f is 
denoted by ar(./'); i.e. if J'l,~ C E then ar(f) = n. 
Let N l)e the set; of natural numbers ~. > 1. 
As usual, we write N* tbr the set of words over 
N, C for the elnl)ty word, and 7r~-' for the con- 
catellatioll of two words 7r, 7r t C N*. A wor(t 7t is 
a prefiz of 7c' (written rc _< re') if there is a word 
7r u such  that  7rTr tt = 7r t. 
A node of a tree is the word rr E N* which 
addresses the node. The empty word e C N* 
is called the root node. A tree domain A is a 
nonempty, t)refixed-closed subset of N* which is 
closed under the left-sil)ling relation. 
Def in i t ion  2.1 A t ree s t r l l c t i l re  iS a t'a\])l(: 
(A,  c,) consisting of a finite, tree dmn, ain A and 
a total labeling t'unction co ? : A -+ E s'ach th, al, 
for all rr 6 A and i G N: 
c A 1 < i < 
We say that the nodes r 6 rcl , . . . ,  7c~ m'e in the 
labeling ,'elationsh/ip 7c: J' On , . . . ,  7r,~) ill! a (Tr) = J' 
and tbr each 1 < i < n, ~-i = ~-i. Similarly, we 
say that a node ~c properly dom, inatcs a node 
7c' and write 7r<\]+rc ' iffrr is a proper prefix of 
7c'. We take Ir and It' to be disjoint (~r J_ ~r') if 
ttley are different and neither node dominates 
the other. So any two nodes in a tree structure 
are in one of the four relations = (equality), <1 +, 
~>+ (the inverse of <1+), or _L. We shall ~lso t)e 
interested the coml)inations of these l"elatiolls by 
set operators: intersection, coml)lementation , 
union, and inversion. For instance, the dom- 
inance relation <~* is detined as the union of 
node equality and proper dominance = U<1 +. 
Finally, we detine the ternary non-intervention 
relation ~(Tr<l*Td<Frc") to hold ifl' it is not the 
case that 1)oth ~r < ~r' and ~r' < re". 
.' ~r 
var  a ~ 
ma0 \lo  
var  ? var  t r  var - .  
Figm'e 1: I)PL structure tbr the meaning of (1). 
2.2 DPL  s t ruc tures  
Now we extend tree structures by variable 
binding and obtain DPL structures. To this 
end, we I)artition E into three sets: connee- 
tive.s Econ = {V_,A,_%...}, predicate symbols 
Epred = {man, likes,...}, and tcr'm symbols 
Ere,., .  = {var, peter, mother_of,...} which sub- 
stone, the variable symbol var and fimction sym- 
1)ols. 
Def in i t ion  2.2 A DPL structure is a triple 
(A,c&A) con.~isting of a trcc structure. (A,c,) 
and a partial varial)le t)inding flmction A : A 
A which sati.sfies for all % ~r t ~ A:  
1. the .  < r.co,, u .fo,. 
all 7ci C A;  
2. < the,,,, fo,. 
all 7ci ~ A;  
I)PL structures can be used to re, present ibr- 
mulas of first-order predicate logic. For in- 
stance, the DPL structure in Fig. 1 represents 
the (unique) meaning of (1). So far, however, 
variables bound by a quantifier do not need to 
be in any special position in a DPL structure; in 
particular, not in its scope. To entbrce seeping 
as in static predicate logic, we could simpy add 
the condition ~c'<~*~r in condition 3 of Definition 
2.2. We will define an appropriate counterpart 
\]'or DPL in Section 3 (properness). 
Modeling variable binding with an explicit 
binding flmction instead of variable nmnes was 
first proposed in (Egg et al ,  1998) .  There, bind- 
ing flmctions heJp to avoid a capturing problem 
in the context of scope underspecitication which 
t)ecomes most ~q)l)arent in the presence of ellip- 
sis. Her(; the 1)inding flmction mainly gives us a 
different t)erspective on variable binding which 
461 
R : :=  <+1>+1 = I?  
I -* 
::= X: f (X \ ] , . . . ,X , , )  (fin C E) 
I xRz  
I 
I 
\[ ~A~'.  
Figure 2: Syntax of CL(DPL) 
is useflfl for defining properness of DPL struc- 
tures. 
2.3 The Constraint Language CL(DPL) 
The syntax of CL(DPL) is defined in Fig- 
ure 2. It provides constraints tbr all the 
relations discussed above. There are label- 
ing constraints X: . f (X~,. . . ,Xr~),  expressive 
combinations XRY of dominance constraints 
'with set operators (Dtu:hier and Niehren, 
200(}; Cornell, 1994), non-intervention con- 
straints ~( X <1* Y <~* Z), and binding constraints 
a(X)=Z.  
CL(DPL) is interpreted over DPL structures. 
A variable assignment into a DPL structure 54 
is a total flmction fi'om the set of variables of a 
constraint o the domain of 54. A pair (54, oz) 
of a DPL structure 54 and a variable assign- 
ment (t into 54 satisfies a constraint qo ifl' it 
satisfies all of its atomic constraints; that is, if 
the relation with the same sylnbol holds of the 
nodes assigned to their arguments. We also call 
the pair (54, oz) a solution and Ad a model of ~o. 
Only some of the atonfic constraints in 
CL(DPL) are used in mlderspecified escrip- 
tions in t)articular, labeling, dominance, and 
binding constraints; the other constraints are 
helpful in processing the others. These three 
types of constraints can be transparently dis- 
played in constraint graphs. For instance, the 
constraint graph ill Fig. 3 represents a con- 
straint describing the readings of example (1) 
including the scope ambiguity. The nodes of 
the graph stand for variables in tile constraint; 
labels and solid edges represent labeling COl> 
straints, dotted edges, donlinance constraints, 
and dashed arrows, binding constraints, hi ad- 
dition, the constraint graph represents an in- 
equality constraint X-~=Y between each two 
variables whose nodes carry a label. A con- 
straint with the latter property is called overlap- 
free. The intuition is that the solid-edge tree 
fragments in the constraint graph must never 
overlap properly in a solution. 
3 Dynamic Semantics in CL(DPL)  
The semantics of DPL is built in a way that 
allows quantifiers to bind only variables in cer- 
tain positions: inside their scopes and, if it is an 
existential quantifier, from the left-hand sides 
of conjunctions and implications into the right- 
hand sides. In CL(DPL), we model this as a 
purely syntactic restriction on the accessibility 
of binders which we define as a structural prop- 
erty of DPL structures. DPL structures which 
have this property will be called proper. 
A useflll auxiliary concept tbr the definition 
is that of an infimum of two nodes with respect 
to the dominance relation q*, which constitutes 
a lower senfilattice because of the underlying 
treeness of DPL structures. Furthermore, we 
will use the standard DPL notions of internally 
v@" = {A,~} and ex- dynamic COlUlectives ~con
te rna lh  d, static connect ives ~con'~stat = {2, V, __=::k, _V}. 
The semantics definition of DPL gives these two 
groups special relevance tbr variable binding. 
Now we can define pTvper \])PL structures as 
tbllows. 
Def in i t ion 3.1 A DPL structure 54 is called 
proper '~f or each, node ~r of 54 on which ~ is 
defined, one of th, e following cases holds true 
wh, ere p, is the i'nfimum of rc and A(TC). 
1.  ff = ;~(~), or 
2. )@r) is labeled 'with ~_, ttl<l*.~(Tr), p,2q*% I t 
is labeled with art internally dynamic con- 
nective, and no node between ttl and A(Tc), 
inclusively, is labeled with an externally 
static connective. 
Intuitively, the first branch of the definitiou 
corresponds to usual binding of variables inside 
tile scope of a quanfifer. In the second branch, 
the positions of the variable and the (existen- 
tial) quantifier in the DPL structure are dis- 
.joint, and the quantifier is dominated by tile 
left child of the infimum. Then the infimum 
must be labeled with an internally dynamic on- 
nective, and there must be no externally static 
connective between this node and the quantifier. 
This restriction is what we are going to exploit 
462 
, . . - ' '  
r ,  
/ 
? / 
womb2',1% ..)...':'- 
\ , , '  
\ 
vat 
Figure 3: Constraint graph for (1). 
to capture the influence 055 scope. There is 51o 
such restriction for the lmth 1)etwcen the inti- 
mmn and the w~riM)le. 
Sohll;ions of & constraint hnt violate the (ly- 
nmnie accessibility conditions are now excluded 
silnply by restricting the, class of ~utmissible so- 
lutions to i)roper ones. As exl)ected from the 
linguistic intuition, only one sohd;ion of the nm- 
ning exmnple (1) is proper: the one where "a 
woman" is assigned wide scope (Fig. 1). Tit(; 
other solution is not prot)er because the path 
Kern the infimum ((lellol;cd by Z0 in Fig. 3) to 
the antecedent contains ;~ mfiversal qu~mtiticl". 
Prot )erness  o f  ;~ I)PI, sl;ruct;u5"(' ('t~sl I)(; ~tx io ln-  
atized synta,ctically: A \])PL sl;rucl;urc is 1)rot)er 
iff the CI~(I)I'I~)~xioms ( l )y , , \ ] ) to  ( l )yn4) in  
Fig. 4 ~re, wflid over it. The rule (Dynl) threes 
universM qmmtifiers to bind only variM)les in 
their scopes, and the rules (l)yn2) to (Dyn4) 
enforce properness of binding when a wtrial)le 
is not in the scope of its binder. 
4 Underspec i f ied  Reason ing  
We next present a procedure for mMorspeci- 
tied reasoning with dynmnic semmltics. Th(' 
goal is to narrow an mMerst)ecified (les(;rit)tion 
such that improi)er DPL-structure, s are removed 
flom the solution set. Narrowing should apply 
as soon as possible, so unde, rspeciliedness (:~m be 
5naintmned and readings need not t)e enmner- 
ated. We present ml intb, rence procedure tlmt 
can do this and go through two exmnples. 
4.1 In fe rence  Procedure  
This infi;rence procedure ,s'atuvatt,.s a,constrMnt 
ttccording to the rules in Figures 4 and 5; that 
is, whenever a constraint conttdns the lefl;-hmM 
side of a rule,, i t  adds il;s right-hand side, until 
no new conjuncts ca, n 1)e ndded. Fig. 4 contains 
simply the prot)erness axioms from the, l)revi- 
ous sections, turned into deterministic proof 
rules. The rules in Pig. 5 are t)ropagation rules 
t'ronl Algorithm DO in (Duchier and Niehren, 
2000), plus new rules for non-intervention con- 
strainl;s. Algorithm DO contains some ~Mdi- 
tional rules, in I)ari;iculm' distribution rules that 
perform case distinctions, because DO is a com- 
plete solver tbr dominance constraints with set 
operators, wlfich improves on (Duchier and Oar- 
dent, 1999; Keller et M., 1998). We have omit- 
ted the (listril)ution rules here l)e,(;ause we do 
'not wmlt to perform case distinctions; l)y ndding 
1;\]1(;115 ~tg~l, i l~ WC COll\]d ellll511era, I;e all proper so- 
lutions, ~:ls Schiehlen (1997) does tbr UDI1T. 
The new rules (NonI1) ~md (NonI2) Mlow 
to derive dominan(:e infbrmation from non- 
intervention constraints. As we will see, the 
most interesting rule in Fig. 4 is (l)yn2), 
which derives explicit non-intervention i t'orma- 
lion fi'om the structurM t)roperLies of dynamic 
1)inding. Note that while the rules in Fig. 5 
are sound over ;my DPL strucl;ure, those in Fig. 
4 are only serum eve5" proper DPL structures. 
This is intended: Application of a prot)erness 
rule is s'upposcd to exclude (improper) solutions. 
4.2 Examples  
The inii;rence rules go a long w:ty towards mak- 
ink tile eft'cot of dynamic seminal;its on scope 
e, xt)lieit. Let us consider |;15(; running example 
in Figure 3 to see how this works; we show how 
to derive Y3<I*X, which specifies the relative 
quantifier scope. 
First of all, we need to make the information 
463 
(Dynl) 
(Dyn2) 
(Dyn3) 
(Dyn4) 
a(x)=Y A Y:V(z') Y<*X 
Z(X)=Y A Z:f(Zl, Z2) A ZI<1*Y A Z2<\]*X A W:g(W1,..., Wn) 
~dyn ~st~tt ( fe  or,, e 
~(X)=Y A Z:f (Z1, . . . ,  Zn) A Zi<:1*X A Zj<:\]*Y --+ false 
A(X)=Y A Z:f (Z1, . . . ,Zn)  A Zi<l*X A &<1*Y -~ false 
Figure 4: Properness axioms. 
(Trans) 
(Lab.Dom) 
(NegDisj) 
(Lab.Disj) 
(Inter) 
(Inv) 
(Child.down) 
(NegDom) 
(NonI1) 
(NonI2) 
X <a* Y A Y <q* Z -+ X <1* Z 
x: f ( . . . ,z , . . . )  x<+y 
X <1* Z A Y <F Z --+ X~ -L Y 
,xs,...) 
XR1Y A XR2Y -+ XRY 
XRY -+ YR-1X 
-+ -~(Z~ <*W<a*Y) 
v~dY'1 i ? j) (.fl,, ~ Econ - ,-,co,,, 
(.fl,, e E, i < j) 
Xi ? Xj where i < j 
if RINR2 C R 
X<:\]+Y A X:f(Xl,... ,Xn) A 
X-~ ? Y A X J_Z -+ Z-~<a*Y 
-~(X<*Y<1*Z) A X<*Y  --+ Y~<*Z 
~(X<\]*Y<I*Z) A Y<*Z --," X-~<1*Y 
---> X i <F Y 
Figure 5: Propagation rules for dominance and non-intervention constr~dnts. 
Z2<1*Za explicit by application of (Lab.Dom) 
and (Inter). In this instance, (Inter) is used as 
a rule of weakening. 
(Lab.Dom) Zg:A(Za, Z4) -~ Z,~<1+ Za 
(Inter) Z.~<Y'- Za --+ Z2<F Z3 
Now we can apply the rule (Dyn2) to the vari- 
able binding constraint A(Za) = Y (drawn in 
boldface in the graph) and the V labeling con- 
straint to derive a non-intervention constraint. 
(Dyn2) Z0:A(Z:j, Z2) A ZI<1*X1 A X:V_(X1) 
A Z2<q*Za A A(Z3) = 1/ 
All that is left to do is to make the positive 
dominance intbrmation contained in the new 
non-intervention constraint explicit. As the 
constraint also contains Zo<1*X, we can apply 
(NonI1) on the new non-intervention constraint 
and derive X~<FY. 
(NonIl) =(Zo<1*X<1*Y) A Zo<1*X --+ X~<1*Y 
On the other hand, we can derive non- 
disjointness of X and Y because (Trans), 
(Lab.Dom), and (Inter) allow the deriw~tion of 
X<FW and Y<1*W: 
(NegDisj) X<*W A Y<I*W ~ X= ? Y 
We can now combiue all of our constraints tbr 
X and Y with the intersection rule and obtain 
Y<1*X, which basically determines the order of 
the two quantifiers: 
(Inter) X~<*Y A X-~ ? Y ~ Y<*X 
By exploiting the fact that the constraint is 
overlap-ti'ee (i.e. contains an inequality cost- 
straint for each two labeled variables), we (:an 
even derive Y3<I*X by repeated application of 
the rules (Child.down), (Lab.Disj), (NegDisj), 
and (NegDom). This means that we have flflly 
disambiguated the scope ambiguity by saturn- 
tion with deterministic nference rules. 
Now let us consider a more complicated ex- 
ample. Fig. 6 is the underspecified description 
of the semantics of 
(2) Every visitor of a company saw one of its 
departments. 
The constraint graph has five solntions, three 
of which are proper. Unfortunately, the con- 
straint language is not expressive nough to 
describe these three solutions ill a single con- 
straint: Both X and Z can be either above or 
below Y, even in a proper solution, but if X is 
below Y, Z must be too, and i fX  is above Y, Z 
must be anywhere below X (but; may be above 
464 
? IX  V ,, Y " " " - -  q ,,,Z 
company ." " - 
x " .  ." i ". , "  " 
var " researcher i ". / o f~- - - -~  depar.tmen-gh'~ ; , 
"~". var \~! .." ' Var ~ var'~ .""" var ~"." ? i .." " 
", ".  L" i . " / 
v a r ' ~  vat ~ . . . . . . .  
Figure 6: Constraint graph for (2). 
YI). In other words, this constraint is an exam- 
pie where the inference procedure is not strong 
enough to narrow the description. In this case, 
we must still resort to pertbrming nondetermin- 
istic case distinctions; at worst, the rules will 
apply on solved forms of CL(1)PL) constraints. 
constraints over these set variables; examples 
for set constraints are V C V' and V = 
V~ U V.2. The new non-intervention constraint 
~(X<1*Y<1*Z) can be encoded as 
Y e <+(x)  u _L(Z) u >+(Z). 
5 Process ing  w i th  F in i te  Set  
Const ra in ts  
This inferen('e procedure fits nicely with all im- 
ph;mentation of (lominance constraints t)ased on 
constraint programming (Marriott and Stuckey, 
1.998; Koller and Niehren, 2000) with tinite 
set constraints (Miiller, 1999). Constraint pro- 
gramlning is a technology for solving combina- 
toric puzzles eificiently. The main idea is to 
replace "generate and test" by "propagate and 
distrilmt(f'. Constraint prot~agation t)eribrms 
deterministic nferences which prune the search 
space, whereas distribution tmrfonns (nondeter- 
rain|st|c) case distinctions. 
Duchier and Niehren (2000) show how to 
implenmnt a (lominance constraint solver by 
encoding donfinance constraints as finite set 
constraints and disjunctive propagators. This 
solver does not handle non-intervention con- 
strain|s, lint we show here that they can tm 
added very naturally. The (Dyn) rules still have 
to be implemented as saturation rules. 
The idea of this implementation is to encode 
a solution (Ad, ~) of a donfinance constraints by 
introducing for each variable X in the constraint 
and each relation symbol R C {<1 +, t> +, =, J_ } 
a finite set variable R(X). This w~riable is sup- 
posed to denote the set of all variables denoting 
nodes that are in tile relation R to ~(X): 
l~,(X) = {Y  e W(~o)I (M,  ~) b- YI~.X} 
Dominance constr~fints can now be stated as 
The bull| in t)rot)agation tbr set constraints au- 
tomatically implenmnts the rules (NonI1) and 
(NonI2). For instance, assume that X<1*Y t)e- 
longs to ~; then there will 1)e a set constraint 
Y ? <1 +(X), so set constraint propagation will 
derive Y ~ ~_(Z) U t>+(Z). This is the |mined|- 
at(; encoding of Y_L U t>+Z, which is equiwdent 
to Y~<1* Z. 
6 Conc lus ion  
In this paper, we have shown how a sl)ecific type 
of local anti)|gully, which is produced by the in- 
teraction of intersentential naphora nd scope 
ambiguities, can l)e processed ell|clearly ill the 
framework of underspecification. We h~ve de- 
fined \])PL structures, which can be used to 
model fonmflas of DPL, and proper DPL struc- 
tures, ill which w~riable binding must obey the 
accessibility conditions of DPL. Finally, we have 
shown how an underspecified description can be 
narrowed to a description of its proper solutions, 
sometimes without even partial enumeration of
readings, and integrated this operation into all 
implelnentation f dominance constraints which 
is based on tin|re set constraints. 
Se, en from the perspective of DPL, our defini- 
tion of tlrot)ern(;ss i tmrely syntactic and tech- 
nically has nothing to do with dynamic seman- 
tics. We could state such a definition t/ecause 
the expli(;it variable binding flmctions gave us a 
structure-in(let)endear h ndle on variable bind- 
ing that excluded all tbnns of capturing. This 
deviates from the standard perspective of indef- 
465 
inites changing the context, but has the advan- 
tage of being extremely modular in that the ac- 
cessibility conditions are factorized out explic- 
itly. For instance, it is simple to represent he 
meaning of "Bach-Peters entences" by relaxing 
these conditions; it should also be easy to adapt 
our tbrmalism to other frameworks of dynamic 
semantics. Of course, the question of how to 
interpret a DPL structure remains open. 
Another open question is how the approach 
presented here can be extended to higher-order 
systems of dynamic semantics (e.g. Dynanfic 
Lambda Calculus (Kuschert, 1999)). In this 
context, it could be worthwhile to restore tim 
distinction of variable binding and anaphoric 
linking from CLLS. 
Finally, it should be interesting to find other 
classes of local ambiguity that lend themselves 
to a treatment as presented here. So far, there 
are not many related examples; one is lexical 
ambiguity in parsing of dependency grammar, 
as presented in (Duchier, 1999). However, we 
believe that the work presented here provides 
further illustration that underspecified process- 
ing can go a long way towards efficient process- 
ing of local ambiguities. 
Acknowledgments .  This work was sup- 
ported by the l)eutsche Forschungsgemeinschaft 
in the SFB 378. As always, we thank all mem- 
bers of the SFB 378 project CHORUS at the 
University of the Saarland. We are also grateful 
to the participants at the Dagstuhl workshop on 
Dynamic Semantics in February 1999 for com- 
ments and discussions on an earlier version of 
this paper. 
References  
Johan Bos. 1996. Predicate logic unplugged. In 
Proceedings of the lOth Amsterdam Colloquium, 
pages 133-143. 
Thomas Cornell. 1994. On determining the consis- 
tency of partial descriptions of trees. In Proceed- 
ings of ACL. 
Denys Duchier and Claire Gardent. 1999. A 
constraint-based treatment of descriptions. In 2 d 
Int. Workshop on Comp. Semantics, pages 71-85. 
Denys Dnchier and Joachim Niehren. 2000. Domi- 
nance constraints with set operators. In 1st Int. 
Conf. on Computational Logic, LNCS, July. 
Denys Duchier. 1999. Axiomatizing dependency 
parsing using set constraints. In Prw:. of the 6 TM 
M. on Mathematics of Language, pages 115 126. 
Markus Egg, Joachim Niehren, Peter Ruhrberg, 
and t;'eiyn Xu. 1998. Constraints over lambda- 
strnctures in semantic umlerspecification. I  joint 
17 th Int. Conf. on Comp. Ling. and 3# t' Ann. 
Meet. of the ACL., pages 353 359. 
Jeroen Oroenendijk and Martin Stokhof. 1.991. Dy- 
namic predicate logic. Linguistics ~ Philosophy, 
14:39-100. 
Hans Kmnp and Uwe Reyle. 1993. From Discourse 
to Logic. Kluwer, Dordrecht. 
Alexander Koller and Joachim Niehren. 2000. Con- 
straint progrmnming in computational linguistics. 
In Proe. of the 8 th CSLI Workshop on Logic, Lan- 
guage, and Computation. CSLI Press. To appear. 
Alexander Koller, Joachim Niehren, and Ralf 
Treinen. 1998. Dominance constraints: Algo- 
rithms and complexity. In 2 d Conf. on Logical 
Asp. of Comp. Ling. To appear as LNCS in 2000. 
Alexander Koller, Kurt Mehlhorn, and Joachim 
Niehren. 2000. A polynomial-time fragment of 
dominance constraints. In P~vccedings of th, c 38th 
A CL. To appear. 
Susanna Kusclmrt. 1999. Dynamic Meaning and 
Accomodation. Ph.D. thesis, Dept. of Computer 
Science, University of the Saarland. 
Mitchell P. Marcus, Donald Hindle, and Mar- 
garet M. Fleck. 1983. D-theory: Talking about 
talking about trees. In 21 st Ann. Meet. of the 
ACL, pages 129 136. 
Kim Marriott and Peter ,l. Stuckey. 1998. Program- 
ruing with, Constraints: An Introduction. MIT 
Press. 
Tobias Mfiller. 1999. Problem solving with filfite set 
constraints in Oz. A Tutorial. Documentation of
the Mozart system of Oz. www.mozart-oz, org. 
R.A. Muskens. 1995. Order-Independence and Un- 
derspecification. In J. Oroenendijk, editor, Ellip- 
sis, Underspccification, Events and Morv in Dy- 
namic Semantics. DYANA Deliverable R.2.2.C. 
Manfred Pinkal. 1996. Radical underspeeification. 
In Prveeedings of the lOth Amsterdam Collo- 
quium, pages 587-606. 
Owen Rainbow, K. Vijay-Shanker, and David Weir. 
1995. D-Tree Grmnmars. In Proceedings of 
A CL '95. 
Uwe Reyle. 1993. Dealing with ambiguities by 
underspecification: construction, representation, 
and deduction. ,Iournal of Semantics, 10:123-179. 
Michael Schiehlen. 1997. Disambiguation of under- 
specified iscourse repesentation strnctnres Ul~(ter 
anaphoric onstraints. In 2 ~'d Int. Workshop. on 
Computational Semantics, Tilburg. 
Kees van Deemter and Stmfley Peters. 1996. Se- 
mantic Ambiguity and Underspecification. CSLI 
Press. 
466 
Natural Language and Inference in a Computer Game
Malte Gabsdil and Alexander Koller and Kristina Striegnitz
Dept. of Computational Linguistics
Saarland University, Saarbru?cken, Germany
{gabsdil|koller|kris}@coli.uni-sb.de
Abstract
We present an engine for text adventures ? computer
games with which the player interacts using natu-
ral language. The system employs current meth-
ods from computational linguistics and an efficient
inference system for description logic to make the
interaction more natural. The inference system is
especially useful in the linguistic modules dealing
with reference resolution and generation and we
show how we use it to rank different readings in
the case of referential and syntactic ambiguities. It
turns out that the player?s utterances are naturally
restricted in the game scenario, which simplifies the
language processing task.
1 Introduction
Text adventures are computer games with which
the player interacts via a natural language dialogue.
Texts describe the game world and how it evolves,
and the player can manipulate objects in this game
world by typing in commands; Fig. 1 shows a sam-
ple interaction. Text adventures were very popu-
lar and commercially successful in the eighties, but
have gone out of fashion since then ? mostly be-
cause the parsers were rather limited and forced the
user into very restricted forms of interaction.
We describe an engine for text adventures that
attempts to overcome these limitations by using
current methods from computational linguistics for
processing the natural language input and output,
and a state-of-the-art inference system based on de-
scription logic (DL) to represent the dynamic state
of the game world and what the player knows about
it. The DL prover is used in all language-processing
modules except for parsing and surface realization,
and supports the inferences we need very well.
This shows in particular in the modules for the
resolution and generation of referring expressions.
By keeping track of the true state of the world
and the player?s knowledge in separate knowledge
bases, we can evaluate definite descriptions with re-
spect to what the player knows. In generation, such
inferences allow us to produce smaller while still
sufficiently informative references.
Another interesting aspect which we discuss in
this paper is the treatment of syntactic and referen-
tial ambiguities that come up in understanding input
sentences. Here, too, the player knowledge restricts
the way in which the input should be interpreted and
guides the resolution process. We use inferences
about the player knowledge to rule out inconsistent
analyses and pragmatic heuristics to possibly select
the preferred one.
Players of a text adventure are effectively situ-
ated in a game world and have to accomplish a
specific task, which severely restricts the utterances
they will naturally produce. For example, they will
typically only refer to objects they could ?see? in
the simulated world. This simplifies the language
processing tasks tremendously. The scenario of the
game can be freely specified and tailored to different
applications and levels of complexity. Along with
the modularity of our implementation, this makes
our system an interesting testbed for evaluating
more sophisticated NLP modules, which also have
access to the inference infrastructure. The same rea-
son makes it useful as a teaching tool; in fact, our
implementation was created as an advanced project
for students.
Plan of the paper. We will start with an overview
over the architecture of our system in Section 2.
Section 3 will give a brief introduction to descrip-
tion logics, and then describes the knowledge bases
we use. We will discuss how they interact with the
linguistic modules in Section 4, which focuses on
the resolution and generation of referring expres-
sions. Section 5 deals with the resolution of am-
biguities in the player input. Finally, Section 6 con-
cludes and points to further research.
2 Architecture
The general architecture of the game engine, shown
in Fig. 2, consists of a number of language-
processing modules (drawn as ellipses), which in-
Observation Lounge
This is where the station staff and visitors come to relax. There are a lot of tables
and chairs here, a large observation window, and a plush carpet. In the corner you can
see an AstroCola dispenser. A tube leads up to the station?s main corridor.
> put my galakmid coin into the dispenser
Click.
The dispenser display now reads "Credit = 1.00".
> push diet astrocola button
You hear a rumbling noise in the dispenser, but nothing appears in the tray.
> kick dispenser
A can drops into the tray. Amazing! The oldest trick in the book, and it
actually worked.
Figure 1: An example interaction with a text adventure, taken from (Ledgard, 1999).
Content
Determination
Model
Discourse
Reference
Resolution
Reference
Generation
RealizationParsing
Actions
A-Box: User Knowledge
T-Box
A-Box: World Model
Figure 2: The architecture.
terface with knowledge bases and a discourse model
(drawn as rectangles). There are two separate
knowledge bases, which share a set of common def-
initions: One represents the true state of the world
in a world model, the other keeps track of what the
player knows about the world. Solid arrows indi-
cate the general flow of information, dashed arrows
indicate access to the knowledge bases.
The user?s input is first parsed using an efficient
parser for dependency grammar (Duchier and De-
busmann, 2001). Next, referring expressions are re-
solved to individuals in the game world. The result
is a ground term or a sequence of ground terms that
indicates the action(s) the user wants to take. The
Actions module looks up these actions in a database
(where they are specified in a STRIPS-like format),
checks whether the action?s preconditions are met in
the world, and, if yes, updates the world state with
the effects of the action.
The action can also specify effects on the user?s
knowledge. This information is further enriched
by the Content Determination module; for example,
this module computes detailed descriptions of ob-
jects the player wants to look at. The Reference
Generation module translates the internal names
of individuals into descriptions that can be verbal-
ized. In the last step, an efficient realization mod-
ule (Koller and Striegnitz, 2002) builds the output
sentences according to a TAG grammar. The player
knowledge is updated after Reference Generation
when the content of the game?s response, including
the new information carried e.g. by indefinite NPs,
is fully established.
If an error occurs at any stage, e.g. because a pre-
condition of the action fails, an error message spec-
ifying the reasons for the failure is generated by
using the normal generation track (Content Deter-
mination, Reference Generation, Realization) of the
game.
The system is implemented in the programming
language Mozart (Mozart Consortium, 1999) and
provides an interface to the DL reasoning system
RACER (Haarslev and Mo?ller, 2001), which is used
for mainting and accessing the knowledge bases.
3 The World Model
Now we will look at the way that the state of the
world is represented in the game, which will be
important in the language processing modules de-
scribed in Sections 4 and 5. We will first give a short
overview of description logic (DL) and the theorem
prover we use and then discuss some aspects of the
world model in more detail.
3.1 Description Logic
Description logic (DL) is a family of logics in the
tradition of knowledge representation formalisms
such as KL-ONE (Woods and Schmolze, 1992). DL
is a fragment of first-order logic which only allows
unary and binary predicates (concepts and roles)
and only very restricted quantification. A knowl-
edge base consists of a T-Box, which contains ax-
ioms relating the concepts and roles, and one or
more A-Boxes, which state that individuals belong
to certain concepts, or are related by certain roles.
Theorem provers for description logics support
a range of different reasoning tasks. Among the
most common are consistency checking, subsump-
tion checking, and instance and relation check-
ing. Consistency checks decide whether a combina-
tion of T-Box and A-Box can be satisfied by some
model, subsumption is to decide of two concepts
whether all individuals that belong to one concept
must necessarily belong to another, and instance and
relation checking test whether an individual belongs
to a certain concept and whether a certain relation
holds between a pair of individuals, respectively. In
addition to these basic reasoning tasks, description
logic systems usually also provide some retrieval
functionality which e.g. allows to compute all con-
cepts that a given individual belongs to or all indi-
viduals that belong to a given concept.
There is a wide range of different description log-
ics today which add different extensions to a com-
mon core. Of course, the more expressive these ex-
tensions become, the more complex the reasoning
problems are. ?Traditional? DL systems have con-
centrated on very weak logics with simple reasoning
tasks. In the last few years, however, new systems
such as FaCT (Horrocks et al, 1999) and RACER
(Haarslev and Mo?ller, 2001) have shown that it is
possible to achieve surprisingly good average-case
performance for very expressive (but still decidable)
logics. In this paper, we employ the RACER sys-
tem, mainly because it allows for A-Box inferences.
3.2 The World Model
The T-Box we use in the game specifies the con-
cepts and roles in the world and defines some useful
complex concepts, e.g. the concept of all objects the
player can see. This T-Box is shared by two differ-
ent A-Boxes representing the state of the world and
what the player knows about it respectively.
The player A-Box will typically be a sub-part of
the game A-Box because the player will not have
explored the world completely and will therefore
not have encountered all individuals or know about
all of their properties. Sometimes, however, it may
also be useful to deliberately hide effects of an ac-
tion from the user, e.g. if pushing a button has an
effect in a room that the player cannot see. In this
case, the player A-Box can contain information that
is inconsistent with the world A-Box.
A fragment of the A-Box describing the state of
the world is shown in Fig. 3; Fig. 4 gives a graphical
representation. The T-Box specifies that the world
is partitioned into three parts: rooms, objects, and
players. The individual ?myself? is the only instance
that we ever define of the concept ?player?. Indi-
viduals are connected to their locations (i.e. rooms,
container objects, or players) via the ?has-location?
role; the A-Box also specifies what kind of object
an individual is (e.g. ?apple?) and what properties it
has (?red?). The T-Box then contains axioms such
as ?apple  object?, ?red  colour?, etc., which es-
tablish a taxonomy among concepts.
These definitions allow us to add axioms to the
T-Box which define more complex concepts. One
is the concept ?here?, which contains the room in
which the player currently is ? that is, every indi-
vidual which can be reached over a ?has-location?
role from a player object.
here .= ?has-location?1.player
In this definition, ?has-location?1? is the inverse role
of the role ?has-location?, i.e. it links a and b iff
?has-location? links b and a. Inverse roles are one of
the constructions available in more expressive de-
scription logics. The quantification builds a more
complex concept from a concept and a role: ?R.C
is the concept containing all individuals which are
linked via an R role to some individual in C . In the
example in Fig. 3, ?here? denotes the singleton set
{kitchen}.
Another useful concept is ?accessible?, which
contains all individuals which the player can ma-
nipulate.
accessible .= ?has-location.here unionsq
?has-location.(accessible  open)
All objects in the same room as the player are
accessible; if such an object is an open container,
its contents are also accessible. The T-Box con-
tains axioms that express that some concepts (e.g.
?table?, ?bowl?, and ?player?) contain only ?open?
room(kitchen) player(myself)
table(t1) apple(a1)
apple(a2) worm(w1)
red(a1) green(a2)
bowl(b1) bowl(b2)
has-location(t1, kitchen) has-location(b1, t1)
has-location(b2, kitchen) has-location(a1, b2)
has-location(a2, kitchen) has-detail(a2,w1)
has-location(myself, kitchen) . . .
Figure 3: A fragment of a world A-Box.
objects. This permits access to the player?s inven-
tory. In the simple scenario above, ?accessible? de-
notes the set {myself, t1, a1, a2, b1, b2}. Finally,
we can define the concept ?visible? in a similar way
as ?accessible?. The definition is a bit more com-
plex, including more individuals, and is intended to
denote all individuals that the player can ?see? from
his position in the game world.1
4 Referring Expressions
The interaction between the game and the player re-
volves around performing actions on objects in the
game world and the effects that these actions have
on the objects. This means that the resolution and
generation of referring expressions, which identify
those objects to the user, are central tasks in our ap-
plication.
Our implementation illustrates how useful the
availability of an inference system as provided by
RACER to access the world model is, once such an
infrastructure is available. The inference engine is
complemented by a simple discourse model, which
keeps track of available referents.
4.1 The Discourse Model
Our discourse model (DM) is based on Strube?s
(1998) salience list approach, due to its simplic-
ity. The DM is a data structure that stores an or-
dered list of the most salient discourse entities ac-
cording to their ?information status? and text po-
sition and provides methods for retrieving and in-
serting elements. Following Strube, hearer-old dis-
course entities (which include definites) are ranked
1Remember that ?seeing? in our application does not in-
volve any graphical representations. The player acquires
knowledges about the world only through the textual output
generated by the game engine. This allows us to simplify the
DL modeling of the world because we don?t have to specify
all (e.g. spatial) relations that would implicitly be present in a
picture.
Figure 4: Example Scenario
higher in the DM (i.e. are more available for refer-
ence) than hearer-new discourse entities (including
indefinites). Within these categories, elements are
sorted according to their position in the currently
processed sentence. For example, the ranking of
discourse entities for the sentence take a banana,
the red apple, and the green apple would look as
follows:
[red apple ? green apple]old ? [banana]new
The DM is built incrementally and updated af-
ter each input sentence. Updating removes all dis-
course entities from the DM which are not realized
in the current utterance. That is, there is an assump-
tion that referents mentioned in the previous utter-
ance are much more salient than older ones.
4.2 Resolving Referring Expressions
The task of the resolution module is to map def-
inite and indefinite noun phrases and pronouns to
individuals in the world. This task is simplified in
the adventure setting by the fact that the commu-
nication is situated in a sense: Players will typi-
cally only refer to objects which they can ?see? in
the virtual environment, as modeled by the concept
?visible? above. Furthermore, they should not re-
fer to objects they haven?t seen yet. Hence, we
perform all RACER queries in this section on the
player knowledge A-Box, avoiding unintended am-
biguities when the player?s expression would e.g.
not refer uniquely with respect to the true state of
the world.
The resolution of a definite description means to
find a unique entity which, according to the player?s
knowledge, is visible and matches the description.
To compute such an entity, we construct a DL con-
cept expression corresponding to the description
and then send a query to RACER asking for all in-
stances of this concept. In the case of the apple,
for instance, we would retrieve all instances of the
concept
apple  visible
from the player A-Box. The query concept for the
apple with the worm would be
apple  (?has-detail.worm)  visible.
If this yields only one entity ({a2} for the apple with
the worm for the A-Box in Fig. 3), the reference
has been unambiguous and we are done. It may,
however, also be the case that more than one entity
is returned; e.g. the query for the apple would return
the set {a1,a2}. We will show in the next section
how we deal with this kind of ambiguity. We reject
input sentences with an error message indicating a
failed reference if we cannot resolve an expression
at all, i.e. when no object in the player knowledge
matches the description.
We resolve indefinite NPs, such as an apple, by
querying the player knowledge in the same way as
described above for definites. Unlike in the definite
case, however, we do not require unique reference.
Instead, we assume that the player did not have a
particular object in mind and arbitrarily choose one
of the possible referents. The reply of the game will
automatically inform the player which one was cho-
sen, as a unique definite reference will be generated
(see below).
Pronouns are simply resolved to the most salient
entity in the DM that matches their agreement con-
straints. The restrictions our grammar imposes
on the player input (no embeddings, no reflexive
pronouns) allow us to analyze sentences including
intra-sentential anaphora like take the apple and eat
it. The incremental construction of the DM ensures
that by the time we encounter the pronoun it, the
apple has already been processed and can serve as a
possible antecedent.
4.3 Generating Referring Expressions
The converse task occurs when we generate the
feedback to show to the player: It is necessary to
construct descriptions of individuals in the game
world that enable the player to identify these.
This task is quite simple for objects which are
new to the player. In this case, we generate an indef-
inite NP containing the type and (if it has one) color
of the object, as in the bowl contains a red apple.
We use RACER?s retrieval functionality to extract
this information from the knowledge base.
To refer to an object that the player already has
encountered, we try to construct a definite descrip-
tion that, given the player knowledge, uniquely
identifies this object. For this purpose we use a vari-
ant of Dale and Reiter?s (1995) incremental algo-
rithm, extended to deal with relations between ob-
jects (Dale and Haddock, 1991). The properties of
the target referent are looked at in some predefined
order (e.g. first its type, then its color, its location,
parts it may have, . . .). A property is added to the
description if at least one other object (a distrac-
tor) is excluded from it because it doesn?t share this
property. This is done until the description uniquely
identifies the target referent.
The algorithm uses RACER?s reasoning and re-
trieval functionality to access the relevant informa-
tion about the context, which included e.g. comput-
ing the properties of the target referent and find-
ing the distracting instances. Assuming we want to
refer to entity a1 in the A-Box in Fig. 3 e.g., we
first have to retrieve all concepts and roles of a1
from the player A-Box. This gives us {apple(a1),
red(a1), has-location(a1,b1)}. As we have to have at
least one property specifying the type of a1, we use
RACER?s subsumption checks to extract all those
properties that match this requirement; in this case,
?apple?. Then we retrieve all instances of the con-
cept ?apple? to determine the set of distractors which
is {a1, a2}. Hence, ?apple? alone is not enough to
uniquely identify a1. So, we consider the apple?s
color. Again using subsumption checks, we filter
the colors from the properties of a1 (i.e. ?red?) and
then retrieve all instances belonging to the concept
apple red to check whether and how the set of dis-
tractors gets reduced by adding this property. This
concept has only one member in the example, so we
generate the expression the red apple.
5 Ambiguity Resolution
The other aspect of the game engine which we want
to highlight here is how we deal with referential
and syntactic ambiguity. We handle the former by
a combination of inference and discourse informa-
tion, and the latter by taking psycholinguistically
motivated preferences into account.
5.1 Resolving Referential Ambiguities
When the techniques for reference resolution de-
scribed in the previous section are not able to map
a definite description to a single entity in the player
knowledge, the resolution module returns a set of
possible referents. We then try to narrow this set
down in two steps.
First, we filter out individuals which are com-
pletely unsalient according to the discourse model.
In our (simplified) model, these are all individuals
that haven?t been mentioned in the previous sen-
tence. This heuristic permits the game to deal with
the following dialogue, as the red but not the green
apple is still accessible in the final turn, and is there-
fore chosen as the patient of the ?eat? action.
Game: . . . red apple . . . green apple.
Player: Take the red apple.
Game: You have the red apple.
Player: Eat the apple.
Game: You eat the red apple.
If this narrows down the possible referents to just
one, we are done. Otherwise ? i.e. if several or none
of the referents were mentioned in the previous sen-
tence ?, we check whether the player?s knowledge
rules out some of them. The rationale is that an in-
telligent player would not try to perform an action
on an object on which she knows it cannot be per-
formed.
Assume, by way of example, that the player
knows about the worm in the green apple. This
violates a precondition of the ?eat? action for ap-
ples. Thus if both apples were equally salient, we
would read eat the apple as eat the red apple. We
can test if a combination of referents for the various
referring expressions of a sentence violates precon-
ditions by first instantiating the appropriate action
with these referents. Then we independently add
each instantiated precondition to fresh copies of the
player knowledge A-Box and test them for consis-
tency. If one of the A-Boxes becomes inconsistent,
we conclude that the player knows this precondition
would fail, and conclude that this is not the intended
combination of referents.
If neither of these heuristics manages to pick out
a unique entity, we consider the definite description
to be truly ambiguous and return an error message
to the user, indicating the ambiguity.
5.2 Resolving Syntactic Ambiguities
Another class of ambiguities which we consider are
syntactic ambiguities, especially of PP attachment.
We try to resolve them, too, by taking referential
information into account.
In the simplest case, the referring expressions in
some of the syntactic readings have no possible ref-
erent in the player A-Box at all. If this happens, we
filter these readings out and only continue with the
others (Schuler, 2001). For example, the sentence
unlock the toolbox with the key is ambiguous. In a
scenario where there is a toolbox and a key, but the
key is not attached to the toolbox, resolution fails for
one of the analyses and thereby resolves the syntac-
tic ambiguity.
If more than one syntactic reading survives this
first test, we perform the same computations as
above to filter out possible referents which are either
unsalient or violate the player?s knowledge. Some-
times, only one syntactic reading will have a refer-
ent in this narrower sense; in this case, we are done.
Otherwise, i.e. if more than one syntactic reading
has referents, we remove those readings which are
referentially ambiguous. Consider once more the
example scenario depicted in Fig. 4. The sentence
put the apple in the bowl on the table has two differ-
ent syntactic analyses: In the first, the bowl on the
table is the target of the put action whereas in the
second, in the bowl modifies the apple. Now, note
that in the first reading, we will get two possible ref-
erents for the apple, whereas in the second reading
the apple in the bowl is unique. In cases like this we
pick out the reading which only includes unique ref-
erences (reading 2 in the present example). This ap-
proach assumes that the players are cooperative and
try to refer unambiguously. It is furthermore similar
to what people seem to do. Psycholinguistic eye-
tracking studies (Chambers et al, 2000) indicate
that people prefer interpretations with unambiguous
references: subjects who are faced with scenarios
similar to Fig. 4 and hear the sentence put the ap-
ple in the bowl on the table do not look at the bowl
on the table at all but only at the apple in the bowl
(which is unique) and the table.
At this point, there can still be more than one syn-
tactic reading left; if so, all of these will have unam-
biguous, unique referents. In such a case we cannot
decide which syntactic reading the player meant,
and ask the player to give the game a less ambiguous
command.
6 Conclusion and Outlook
We have described an engine for text adventures
which uses techniques from computational linguis-
tics to make the interaction with the game more nat-
ural. The input is analyzed using a dependency
parser and a simple reference resolution module,
and the output is produced by a small generation
system. Information about the world and about
the player?s knowledge is represented in descrip-
tion logic knowledge bases, and accessed through
a state-of-the-art inference system. Most modules
use the inference component; to illustrate its useful-
ness, we have looked more closely at the resolution
and generation of referring expressions, and at the
resolution of referential and syntactic ambiguities.
Preliminary experiments indicate that the perfor-
mance of our game engine is good enough for flu-
ent gameplay. The constraint based dependency
parser we use for parsing and generation achieves
very good average case runtimes on the grammars
and inputs we use. More interestingly, the infer-
ence system also performs very well. With the cur-
rent knowledge bases, reasoning on the world model
and user knowledge takes 546ms per turn on aver-
age (with a mean of 39 queries per turn). How well
this performance scales to bigger game worlds re-
mains to be seen. One lesson we take from this is
that the recent progress in optimizing inference en-
gines for expressive description logics is beginning
to make them useful for applications.
All the language-processing modules in our sys-
tem are rather simplistic. We can get away with this
because the utterances that players seem to want to
produce in this setting are restricted, e.g. to objects
in the same simulated ?location? as the player. (The
precise extent of this, of course, remains to be eval-
uated.) The result is a system which exceeds tradi-
tional text adventures by far in the flexibility offered
to the user.
Unlike the input, the output that our game gen-
erates is far away from the quality of the com-
mercial text adventures of the eighties, which pro-
duced canned texts, sometimes written by profes-
sional book authors. A possible solution could be to
combine the full generation with a template based
approach, to which the TAG-based generation ap-
proach we take lends itself well. Another problem is
the generation of error messages asking the user to
resolve an ambiguous input. The game should ide-
ally generate and present the player with a choice
of possible (unambiguous) readings. So, the gen-
eration strategy would have to be augmented with
some kind of monitoring, such as the one proposed
by Neumann and van Noord (1994). Finally, we
want to come up with a way of synchronizing the
grammars for parsing and generation, in order to en-
sure that expressions used by the game can always
be used by the player as well.
The system is designed in a way that should make
it reasonably easy to replace our simple modules
by more sophisticated ones. We will shortly make
our adventure engine available over the web, and
want to invite colleagues and students to test their
own language processing modules within our sys-
tem. Generally, we believe that the prototype can
serve as a starting point for an almost unlimited
range of extensions.
References
C.G. Chambers, M.K. Tanenhaus, and J.S. Magnu-
son. 2000. Does real-world knowledge modulate
referential effects on PP-attachment? Evidence
from eye movements in spoken language compre-
hension. In 14th CUNY Conference on Human
Sentence Processing.
R. Dale and N. Haddock. 1991. Generating re-
ferring expressions involving relations. In EACL
?91.
R. Dale and E. Reiter. 1995. Computational inter-
pretations of the gricean maxims in the genera-
tion of referring expressions. Cognitive Science,
18.
D. Duchier and R. Debusmann. 2001. Topological
dependency trees: A constraint-based account of
linear precedence. In ACL ?01.
V. Haarslev and R. Mo?ller. 2001. RACER System
Description. In IJCAR ?01.
I. Horrocks, U. Sattler, and S. Tobies. 1999. Practi-
cal reasoning for expressive description logics. In
H. Ganzinger, D. McAllester, and A. Voronkov,
editors, LPAR?99.
A. Koller and K. Striegnitz. 2002. Generation as
dependency parsing. In ACL ?02.
D. Ledgard. 1999. Space Station. Text adventure,
modelled after a sample transcript of Infocom?s
Planetfall game. http://members.tripod.
com/?infoscripts/planetfa.htm.
Mozart Consortium. 1999. The Mozart Pro-
gramming System web pages. http://www.
mozart-oz.org/.
G. Neumann and G.-J. van Noord. 1994.
Self-monitoring with reversible grammars. In
T. Strzalkowski, editor, Reversible Grammar in
Natural Language Processing.
W. Schuler. 2001. Computational properties of
environment-based disambiguation. In ACL ?01.
M. Strube. 1998. Never Look Back: An Alternative
to Centering. In COLING-ACL ?98.
W. Woods and J. Schmolze. 1992. The KL-ONE
Family. Computer and Mathematics with Appli-
cations, 23(2?5).
A Relational Syntax-Semantics Interface Based on Dependency Grammar
Ralph Debusmann Denys Duchier? Alexander Koller Marco Kuhlmann Gert Smolka Stefan Thater
Saarland University, Saarbr?cken, Germany ?LORIA, Nancy, France
{rade|kuhlmann|smolka}@ps.uni-sb.de, duchier@loria.fr, {koller|stth}@coli.uni-sb.de
Abstract
We propose a syntax-semantics interface that
realises the mapping between syntax and se-
mantics as a relation and does not make func-
tionality assumptions in either direction. This
interface is stated in terms of Extensible De-
pendency Grammar (XDG), a grammar formal-
ism we newly specify. XDG?s constraint-based
parser supports the concurrent flow of informa-
tion between any two levels of linguistic rep-
resentation, even when only partial analyses are
available. This generalises the concept of under-
specification.
1 Introduction
A key assumption of traditional syntax-semantics
interfaces, starting with (Montague, 1974), is that
the mapping from syntax to semantics is functional,
i. e. that once we know the syntactic structure of a
sentence, we can deterministically compute its se-
mantics.
Unfortunately, this assumption is typically not
justified. Ambiguities such as of quantifier scope
or pronominal reference are genuine semantic am-
biguities; that is, even a syntactically unambigu-
ous sentence can have multiple semantic readings.
Conversely, a common situation in natural language
generation is that one semantic representation can
be verbalised in multiple ways. This means that the
relation between syntax and semantics is not func-
tional at all, but rather a true m-to-n relation.
There is a variety of approaches in the litera-
ture on syntax-semantics interfaces for coping with
this situation, but none of them is completely sat-
isfactory. One way is to recast semantic ambiguity
as syntactic ambiguity by compiling semantic dis-
tinctions into the syntax (Montague, 1974; Steed-
man, 1999; Moortgat, 2002). This restores function-
ality, but comes at the price of an artificial blow-
up of syntactic ambiguity. A second approach is to
assume a non-deterministic mapping from syntax
to semantics as in generative grammar (Chomsky,
1965), but it is not always obvious how to reverse
the relation, e. g. for generation. For LFG, the oper-
ation of functional uncertaintainty allows for a re-
stricted form of relationality (Kaplan and Maxwell
III, 1988). Finally, underspecification (Egg et al,
2001; Gupta and Lamping, 1998; Copestake et al,
2004) introduces a new level of representation,
which can be computed functionally from a syntac-
tic analysis and encapsulates semantic ambiguity in
a way that supports the enumeration of all semantic
readings by need.
In this paper, we introduce a completely rela-
tional syntax-semantics interface, building upon the
underspecification approach. We assume a set of
linguistic dimensions, such as (syntactic) immedi-
ate dominance and predicate-argument structure; a
grammatical analysis is a tuple with one component
for each dimension, and a grammar describes a set
of such tuples. While we make no a priori function-
ality assumptions about the relation of the linguistic
dimensions, functional mappings can be obtained
as a special case. We formalise our syntax-seman-
tics interface using Extensible Dependency Gram-
mar (XDG), a new grammar formalism which gen-
eralises earlier work on Topological Dependency
Grammar (Duchier and Debusmann, 2001).
The relational syntax-semantics interface is sup-
ported by a parser for XDG based on constraint pro-
gramming. The crucial feature of this parser is that
it supports the concurrent flow of possibly partial in-
formation between any two dimensions: once addi-
tional information becomes available on one dimen-
sion, it can be propagated to any other dimension.
Grammaticality conditions and preferences (e. g. se-
lectional restrictions) can be specified on their nat-
ural level of representation, and inferences on each
dimension can help reduce ambiguity on the oth-
ers. This generalises the idea of underspecifica-
tion, which aims to represent and reduce ambiguity
through inferences on a single dimension only.
The structure of this paper is as follows: in Sec-
tion 2, we give the general ideas behind XDG, its
formal definition, and an overview of the constraint-
based parser. In Section 3, we present the relational
syntax-semantics interface, and go through exam-
ples that illustrate its operation. Section 4 shows
how the semantics side of our syntax-semantics in-
terface can be precisely related to mainstream se-
mantics research. We summarise our results and
point to further work in Section 5.
2 Extensible Dependency Grammar
This section presents Extensible Dependency
Grammar (XDG), a description-based formalism
for dependency grammar. XDG generalizes previ-
ous work on Topological Dependency Grammar
(Duchier and Debusmann, 2001), which focussed
on word order phenomena in German.
2.1 XDG in a Nutshell
XDG is a description language over finite labelled
graphs. It is able to talk about two kinds of con-
straints on these structures: The lexicon of an XDG
grammar describes properties local to individual
nodes, such as valency. The grammar?s principles
express constraints global to the graph as a whole,
such as treeness. Well-formed analyses are graphs
that satisfy all constraints.
An XDG grammar allows the characterisation
of linguistic structure along several dimensions of
description. Each dimension contains a separate
graph, but all these graphs share the same set of
nodes. Lexicon entries synchronise dimensions by
specifying the properties of a node on all dimen-
sions at once. Principles can either apply to a single
dimension (one-dimensional), or constrain the rela-
tion of several dimensions (multi-dimensional).
Consider the example in Fig. 1, which shows an
analysis for a sentence of English along two dimen-
sions of description, immediate dominance (ID) and
linear precedence (LP). The principles of the under-
lying grammar require both dimensions to be trees,
and the LP tree to be a ?flattened? version of the ID
tree, in the sense that whenever a node v is a tran-
sitive successor of a node u in the LP tree, it must
also be a transitive successor of u in the ID tree. The
given lexicon specifies the potential incoming and
required outgoing edges for each word on both di-
mensions. The word does, for example, accepts no
incoming edges on either dimension and must there-
fore be at the root of both the ID and the LP tree. It is
required to have outgoing edges to a subject (subj)
and a verb base form (vbse) in the ID tree, needs
fillers for a subject (sf) and a verb complement field
(vcf) in the LP tree, and offers an optional field for
topicalised material (tf). All these constraints are
satisfied by the analysis, which is thus well-formed.
2.2 Formalisation
Formally, an XDG grammar is built up of dimen-
sions, principles, and a lexicon, and characterises a
set of well-formed analyses.
A dimension is a tuple D = (Lab,Fea,Val,Pri) of
a set Lab of edge labels, a set Fea of features, a set
Val of feature values, and a set of one-dimensional
s
u
b
j
v
b
s
e
o
b
j
what does John eat
s
f
v
c
f
what does John eat
t
f
word inID outID inLP outLP
what {obj?} {} {tf?} {}
does {} {subj,vbse} {} {tf?,sf,vcf}
John {subj?,obj?} {} {sf?,of?} {}
eat {vbse?} {obj} {vcf?} {}
Figure 1: XDG analysis of ?what does John eat?
principles Pri. A lexicon for the dimension D is a
set Lex ? Fea ? Val of total feature assignments (or
lexical entries). A D-structure, representing an anal-
ysis on dimension D, is a triple (V,E,F) of a set V
of nodes, a set E ?V ?V ?Lab of directed labelled
edges, and an assignment F : V ? (Fea ? Val) of
lexical entries to nodes. V and E form a graph. We
write StrD for the set of all possible D-structures.
The principles characterise subsets of StrD that have
further dimension-specific properties, such as being
a tree, satisfying assigned valencies, etc. We assume
that the elements of Pri are finite representations of
such subsets, but do not go into details here; some
examples are shown in Section 3.2.
An XDG grammar ((Labi,Feai,Vali,Prii)ni=1,Pri,
Lex) consists of n dimensions, multi-dimensional
principles Pri, and a lexicon Lex. An XDG analysis
(V,Ei,Fi)ni=1 is an element of Ana = Str1??? ??Strn
where all dimensions share the same set of nodes V .
Multi-dimensional principles work just like one-
dimensional principles, except that they specify
subsets of Ana, i. e. couplings between dimensions
(e. g. the flattening principle between ID and LP in
Section 2.1). The lexicon Lex ? Lex1 ? ?? ? ? Lexn
constrains all dimensions at once. An XDG analysis
is licenced by Lex iff (F1(w), . . . ,Fn(w)) ? Lex for
every node w ?V .
In order to compute analyses for a given input, we
model it as a set of input constraints (Inp), which
again specify a subset of Ana. The parsing prob-
lem for XDG is then to find elements of Ana that
are licenced by Lex and consistent with Inp and
Pri. Note that the term ?parsing problem? is tradi-
tionally used only for inputs that are sequences of
words, but we can easily represent surface realisa-
tion as a ?parsing? problem in which Inp specifies a
semantic dimension; in this case, a ?parser? would
compute analyses that contain syntactic dimensions
from which we can read off a surface sentence.
2.3 Constraint Solver
The parsing problem of XDG has a natural read-
ing as a constraint satisfaction problem (CSP) (Apt,
2003) on finite sets of integers; well-formed anal-
yses correspond to the solutions of this problem.
The transformation, whose details we omit due to
lack of space, closely follows previous work on ax-
iomatising dependency parsing (Duchier, 2003) and
includes the use of the selection constraint to effi-
ciently handle lexical ambiguity.
We have implemented a constraint solver for
this CSP using the Mozart/Oz programming system
(Smolka, 1995; Mozart Consortium, 2004). This
solver does a search for a satisfying variable assign-
ment. After each case distinction (distribution), it
performs simple inferences that restrict the ranges
of the finite set variables and thus reduce the size
of the search tree (propagation). The successful
leaves of the search tree correspond to XDG anal-
yses, whereas the inner nodes correspond to partial
analyses. In these cases, the current constraints are
too weak to specify a complete analysis, but they
already express that some edges or feature values
must be present, and that others are excluded. Partial
analyses will play an important role in Section 3.3.
Because propagation operates on all dimensions
concurrently, the constraint solver can frequently
infer information about one dimension from infor-
mation on another, if there is a multi-dimensional
principle linking the two dimensions. These infer-
ences take place while the constraint problem is be-
ing solved, and they can often be drawn before the
solver commits to any single solution.
Because XDG allows us to write grammars with
completely free word order, XDG solving is an NP-
complete problem (Koller and Striegnitz, 2002).
This means that the worst-case complexity of the
solver is exponential, but the average-case complex-
ity for the hand-crafted grammars we experimented
with is often better than this result suggests. We
hope there are useful fragments of XDG that would
guarantee polynomial worst-case complexity.
3 A Relational Syntax-Semantics Interface
Now that we have the formal and processing frame-
works in place, we can define a relational syntax-
semantics interface for XDG. We will first show
how we encode semantics within the XDG frame-
work. Then we will present an example grammar
(including some principle definitions), and finally
go through an example that shows how the rela-
tionality of the interface, combined with the con-
currency of the constraint solver, supports the flow
of information between different dimensions.
3.1 Representing Meaning
We represent meaning within XDG on two dimen-
sions: one for predicate-argument structure (PA),
every student reads a book
s
u
b
j
d
e
t
o
b
j
d
e
t
every student reads a book
a
g
a
r
g
p
a
t
a
r
g
i. ID-tree ii. PA-structure
s
every student reads a book
s
r
r
s
every student reads a book
s
r
r
iii. scope trees
Figure 2: Two analyses for the sentence ?every stu-
dent reads a book.?
and one for scope (SC). The function of the PA di-
mension is to abstract over syntactic idiosyncrasies
such as active-passive alternations or dative shifts,
and to make certain semantic dependencies e. g. in
control constructions explicit; it deals with concepts
such as agent and patient, rather than subject and ob-
ject. The purpose of the SC dimension is to reflect
the structure of a logical formula that would repre-
sent the semantics, in terms of scope and restriction.
We will make this connection explicit in Section 4.
In addition, we assume an ID dimension as above.
We do not include an LP dimension only for ease of
presentation; it could be added completely orthogo-
nally to the three dimensions we consider here.
While one ID structure will typically correspond
to one PA structure, each PA structure will typically
be consistent with multiple SC structures, because
of scope ambiguities. For instance, Fig. 2 shows the
unique ID and PA structures for the sentence ?Ev-
ery student reads a book.? These structures (and the
input sentence) are consistent with the two possi-
ble SC-structures shown in (iii). Assuming a David-
sonian event semantics, the two SC trees (together
with the PA-structure) represent the two readings of
the sentence:
? ?e.?x.student(x) ??y.book(y)? read(e,x,y)
? ?e.?y.book(y)??x.student(x) ? read(e,x,y)
3.2 A Grammar for a Fragment of English
The lexicon for an XDG grammar for a small frag-
ment of English using the ID, PA, and SC dimensions
is shown in Fig. 3. Each row in the table specifies a
(unique) lexical entry for each part of speech (deter-
miner, common noun, proper noun, transitive verb
and preposition); there is no lexical ambiguity in
this grammar. Each column specifies a feature. The
meaning of the features will be explained together
inID outID inPA outPA inSC outSC
DET {subj?,obj?,pcomp?} {det!} {ag?,pat?,arg?} {quant!} {r?,s?,a?} {r!,s!}
CN {det?} {prep?} {quant?} {mod?} {r?,s?,a?} {}
PN {subj?,obj?,pcomp?} {prep?} {ag?,pat?,arg?} {mod?} {r?,s?,a?} {r?,s!}
TV {} {subj!,obj!,prep?} {} {ag!,pat!, instr?} {r?,s?,a?} {}
PREP {prep?} {pcomp!} {mod?, instr?} {arg!} {r?,s?,a?} {a!}
link codom contradom
DET {quant 7? {det}} {quant 7? {r}} {}
CN,PN {mod 7? {prep}} {} {mod 7? {a}}
TV {ag 7? {subj},pat 7? {obj}, instr 7? {prep}} {} {ag 7? {s},pat 7? {s}, instr 7? {a}}
PREP {arg 7? {pcomp}} {} {arg 7? {s}}
Figure 3: The example grammar fragment
with the principles that use them.
The ID dimension uses the edge labels LabID =
{det,subj,obj,prep,pcomp} resp. for determined
common noun,1 subject, object, preposition, and
complement of a preposition. The PA dimension
uses LabPA = {ag,pat,arg,quant,mod, instr}, resp.
for agent, patient, argument of a modifier, common
noun pertaining to a quantifier, modifier, and instru-
ment; and SC uses LabSC = {r,s,a} resp. for restric-
tion and scope of a quantifier, and for an argument.
The grammar also contains three one-dimen-
sional principles (tree, dag, and valency), and
three multi-dimensional principles (linking, co-
dominance, and contra-dominance).
Tree and dag principles. The tree principle re-
stricts ID and SC structures to be trees, and the
dag principle restricts PA structures to be directed
acyclic graphs.
Valency principle. The valency principle, which
we use on all dimensions, states that the incom-
ing and outgoing edges of each node must obey the
specifications of the in and out features. The possi-
ble values for each feature ind and outd are subsets
of Labd ? {!,?,?}. `! specifies a mandatory edge
with label `, `? an optional one, and `? zero or more.
Linking principle. The linking principle for di-
mensions d1,d2 constrains how dependents on d1
may be realised on d2. It assumes a feature linkd1,d2
whose values are functions that map labels from
Labd1 to sets of labels from Labd2 , and is specified
by the following implication:
v
l
?d1 v
? ? ?l? ? linkd1,d2(v)(l) : v
l?
?d2 v
?
Our grammar uses this principle with the link fea-
ture to constrain the realisations of PA-dependents in
the ID dimension. In Fig. 2, the agent (ag) of reads
must be realised as the subject (subj), i. e.
1We assume on all dimensions that determiners are the
heads of common nouns. This makes for a simpler relationship
between the syntactic and semantic dimensions.
reads ag?PA every ? reads
subj
? ID every
Similarly for the patient and the object. There
is no instrument dependent in the example, so this
part of the link feature is not used. An ergative verb
would use a link feature where the subject realises
the patient; Control and raising phenomena can also
be modelled, but we cannot present this here.
Co-dominance principle. The co-dominance
principle for d1,d2 relates edges in d1 to dominance
relations in the same direction in d2. It assumes a
feature codomd1,d2 mapping labels in Labd1 to sets
of labels in Labd2 and is specified as
v
l
?d1 v
? ? ?l? ? codomd1,d2(v)(l) : v
l?
???d2v
?
Our grammar uses the co-dominance principle on
dimension PA and SC to express, e. g., that the
propositional contribution of a noun must end up in
the restriction of its determiner. For example, for the
determiner every of Fig. 2 we have:
every quant? PA student ? every
r
???SCstudent
Contra-dominance principle. The contra-domi-
nance principle is symmetric to the co-dominance
principle, and relates edges in d1 to dominance
edges into the opposite direction in d2. It assumes
a feature contradomd1,d2 mapping labels of Labd1 to
sets of labels from Labd2 and is specified as
v
l
?d1 v
? ?
?l? ? contradomd1,d2(v)(l) : v?
l?
???d2v
Our grammar uses the contra-dominance principle
on dimensions PA and SC to express, e. g., that pred-
icates must end up in the scope of the quantifiers
whose variables they refer to. Thus, for the transi-
tive verb reads of Fig. 2, we have:
reads ag?PA every ? every
s
???SCreads
reads pat?PA a ? a
s
???SCreads
Mary saw a student with a book
a
g
p
a
t
q
u
a
n
t
a
r
g
q
u
a
n
t
Mary saw a student with a book
s
s
r
s
r
Mary saw a student with a book
s
u
b
j
o
b
j
d
e
t
a
r
g
d
e
t
p
r
e
p
Mary saw a student with a book
a
g
p
a
t
q
u
a
n
t
a
r
g
q
u
a
n
t
Mary saw a student with a book
s
r
s
r
Mary saw a student with a book
s
u
b
j
o
b
j
d
e
t
a
r
g
d
e
t
i
n
s
t
r
a
s
Mary saw a student with a book
a
g
p
a
t
a
r
g
a
r
g
q
u
a
n
t
Mary saw a student with a book
s
s
r
s
r
Mary saw a student with a book
s
u
b
j
o
b
j
d
e
t
a
r
g
d
e
t
m
o
d
p
r
e
p
a
i. Partial analysis
ii. verb attachment
iii. noun attachment
ID
PA
SC
Figure 4: Partial description (left) and two solutions (right) for ?Mary saw a student with a book.?
3.3 Syntax-Semantics Interaction
It is important to note at this point that the syntax-
semantics interface we have defined is indeed re-
lational. Each principle declaratively specifies a set
of admissible analyses, i. e. a relation between the
structures for the different dimensions, and the anal-
yses that the complete grammar judges grammatical
are simply those that satisfy all principles. The role
of the lexicon is to provide the feature values which
parameterise the principles defined above.
The constraint solver complements this relation-
ality by supporting the use of the principles to move
information between any two dimensions. If, say,
the left-hand side of the linking principle is found to
be satisfied for dimension d1, a propagator will infer
the right-hand side and add it to dimension d2. Con-
versely, if the solver finds that the right-hand side
must be false for d2, the negation of the left-hand
side is inferred for d1. By letting principles interact
concurrently, we can make some very powerful in-
ferences, as we will demonstrate with the example
sentence ?Mary saw a student with a book,? some
partial analyses for which are shown in Fig. 4.
Column (i) in the figure shows the state after the
constraint solver finishes its initial propagation, at
the root of the search tree. Even at this point, the va-
lency and treeness principles have conspired to es-
tablish an almost complete ID-structure. By the link-
ing principle, the PA-structure has been determined
similarly closely. The SC-structure is still mostly un-
determined, but by the co- and contra-dominance
principles, the solver has already established that
some nodes must dominate others: A dotted edge
with label s in the picture means that the solver
knows there must be a path between these two nodes
which starts with an s-edge. In other words, the
solver has computed a large amount of semantic in-
formation from an incomplete syntactic analysis.
Now imagine some external source tells us that
with is a mod-child of student on PA, i. e. the anal-
ysis in (iii). This information could come e. g. from
a statistical model of selectional preferences, which
will judge this edge much more probable than an
instr-edge from the verb to the preposition (ii).
Adding this edge will trigger additional inferences
through the linking principle, which can now infer
that with is a prep-child of student on ID. In the other
direction, the solver will infer more dominances on
SC. This means that semantic information can be
used to disambiguate syntactic ambiguities, and se-
mantic information such as selectional preferences
can be stated on their natural level of representation,
rather than be forced into the ID dimension directly.
Similarly, the introduction of new edges on SC
could trigger a similar reasoning process which
would infer new PA-edges, and thus indirectly also
new ID-edges. Such new edges on SC could come
from inferences with world or discourse knowledge
(Koller and Niehren, 2000), scope preferences, or
interactions with information structure (Duchier and
Kruijff, 2003).
4 Traditional Semantics
Our syntax-semantics interface represents seman-
tic information as graphs on the PA and SC dimen-
sions. While this looks like a radical departure from
traditional semantic formalisms, we consider these
graphs simply an alternative way of presenting more
traditional representations. We devote the rest of the
paper to demonstrating that a pair of a PA and a SC
structure can be interpreted as a Montague-style for-
mula, and that a partial analysis on these two di-
mensions can be seen as an underspecified semantic
description.
4.1 Montague-style Interpretation
In order to extract a standard type-theoretic expres-
sion from an XDG analysis, we assign each node v
two semantic values: a lexical value L(v) represent-
ing the semantics of v itself, and a phrasal value
P(v) representing the semantics of the entire SC-
subtree rooted at v. We use the SC-structure to de-
termine functor-argument relationships, and the PA-
structure to establish variable binding.
We assume that nodes for determiners and proper
names introduce unique individual variables (?in-
dices?). Below we will write ??v?? to refer to the in-
dex of the node v, and we write ?` to refer to the
node which is the `-child of the current node in the
appropriate dimension (PA or SC). The semantic lex-
icon is defined as follows; ?L(w)? should be read as
?L(v), where v is a node for the word w?.
L(a) = ?P?Q?e.?x(P(x)?Q(x)(e))
L(book) = book?
L(with) = ?P?x.(with?(???arg??)(x)?P(x))
L(reads) = read?(???pat??)(???ag??)
Lexical values for other determiners, common
nouns, and proper names are defined analogously.
Note that we do not formally distinguish event
variables from individual variables. In particular,
L(with) can be applied to either nouns or verbs,
which both have type ?e, t?.
We assume that no node in the SC-tree has more
than one child with the same edge label (which our
grammar guarantees), and write n(`1, . . . , `k) to in-
dicate that the node n has SC-children over the edge
labels `1, . . . , `k. The phrasal value for n is defined
(in the most complex case) as follows:
P(n(r,s)) = L(n)(P(?r))(? ??n??.P(?s))
This rule implements Montague?s rule of quan-
tification (Montague, 1974); note that ? ??n?? is a
binder for the variable ??n??. Nodes that have no
s-children are simply functionally applied to the
phrasal semantics of their children (if any).
By way of example, consider the left-hand SC-
structure in Fig. 2. If we identify each node by the
word it stands for, we get the following phrasal
@
@
every
?
@
@
a
?
@
@
read var
var
student
book
r
s
s
r
every student reads a book
r
r
s
s
every student reads a book
a
g
a
r
g
p
a
t
a
r
g
Figure 5: A partial SC-structure and its correspond-
ing CLLS description.
value for the root of the tree:
L(a)(L(book))(?x.L(every)(L(student)
(?y.read?(y)(x)))),
where we write x for ??a?? and y for ??every??. The
arguments of read? are x and y because every and
a are the arg and pat children of reads on the PA-
structure. After replacing the lexical values by their
definitions and beta-reduction, we obtain the fa-
miliar representation for this semantic reading, as
shown in Section 3.1.
4.2 Underspecification
It is straightforward to extend this extraction of
type-theoretic formulas from fully specified XDG
analyses to an extraction of underspecified seman-
tic descriptions from partial XDG analyses. We will
briefly demonstrate this here for descriptions in the
CLLS framework (Egg et al, 2001), which sup-
ports this most easily. Other underspecification for-
malisms could be used too.
Consider the partial SC-structure in Fig. 5, which
could be derived by the constraint solver for the
sentence from Fig. 2. We can obtain a CLLS con-
straint from it by first assigning to each node of
the SC-structure a lexical value, which is now a part
of the CLLS constraint (indicated by the dotted el-
lipses). Because student and book are known to be r-
daughters of every and a on SC, we plug their CLLS
constraints into the r-holes of their mothers? con-
straints. Because we know that reads must be dom-
inated by the s-children of the determiners, we add
the two (dotted) dominance edges to the constraint.
Finally, variable binding is represented by the bind-
ing constraints drawn as dashed arrows, and can be
derived from PA exactly as above.
5 Conclusion
In this paper, we have shown how to build a fully re-
lational syntax-semantics interface based on XDG.
This new grammar formalism offers the grammar
developer the possibility to represent different kinds
of linguistic information on separate dimensions
that can be represented as graphs. Any two dimen-
sions can be linked by multi-dimensional principles,
which mutually constrain the graphs on the two di-
mensions. We have shown that a parser based on
concurrent constraint programming is capable of in-
ferences that restrict ambiguity on one dimension
based on newly available information on another.
Because the interface we have presented makes
no assumption that any dimension is more ?basic?
than another, there is no conceptual difference be-
tween parsing and generation. If the input is the sur-
face sentence, the solver will use this information
to compute the semantic dimensions; if the input is
the semantics, the solver will compute the syntactic
dimensions, and therefore a surface sentence. This
means that we get bidirectional grammars for free.
While the solver is reasonably efficient for many
(hand-crafted) grammars, it is an important goal
for the future to ensure that it can handle large-
scale grammars imported from e.g. XTAG (XTAG
Research Group, 2001) or induced from treebanks.
One way in which we hope to achieve this is to iden-
tify fragments of XDG with provably polynomial
parsing algorithms, and which contain most useful
grammars. Such grammars would probably have to
specify word orders that are not completely free,
and we would have to control the combinatorics
of the different dimensions (Maxwell and Kaplan,
1993). One interesting question is also whether dif-
ferent dimensions can be compiled into a single di-
mension, which might improve efficiency in some
cases, and also sidestep the monostratal vs. multi-
stratal distinction.
The crucial ingredient of XDG that make rela-
tional syntax-semantics processing possible are the
declaratively specified principles. So far, we have
only given some examples for principle specifi-
cations; while they could all be written as Horn
clauses, we have not committed to any particular
representation formalism. The development of such
a representation formalism will of course be ex-
tremely important once we have experimented with
more powerful grammars and have a stable intuition
about what principles are needed.
At that point, it would also be highly interest-
ing to define a (logic) formalism that generalises
both XDG and dominance constraints, a fragment of
CLLS. Such a formalism would make it possible to
take over the interface presented here, but use dom-
inance constraints directly on the semantics dimen-
sions, rather than via the encoding into PA and SC
dimensions. The extraction process of Section 4.2
could then be recast as a principle.
Acknowledgements
We thank Markus Egg for many fruitful discussions
about this paper.
References
K. Apt. 2003. Principles of Constraint Programming.
Cambridge University Press.
N. Chomsky. 1965. Aspects of the Theory of Syntax.
MIT Press, Cambridge, MA.
A. Copestake, D. Flickinger, C. Pollard, and I. Sag.
2004. Minimal recursion semantics. an introduction.
Journal of Language and Computation. To appear.
D. Duchier and R. Debusmann. 2001. Topological de-
pendency trees: A constraint-based account of linear
precedence. In ACL 2001, Toulouse.
D. Duchier and G.-J. M. Kruijff. 2003. Information
structure in topological dependency grammar. In
EACL 2003.
D. Duchier. 2003. Configuration of labeled trees un-
der lexicalized constraints and principles. Research
on Language and Computation, 1(3?4):307?336.
M. Egg, A. Koller, and J. Niehren. 2001. The Constraint
Language for Lambda Structures. Logic, Language,
and Information, 10:457?485.
V. Gupta and J. Lamping. 1998. Efficient linear logic
meaning assembly. In COLING/ACL 1998.
R. M. Kaplan and J. T. Maxwell III. 1988. An algorithm
for functional uncertainty. In COLING 1988, pages
297?302, Budapest/HUN.
A. Koller and J. Niehren. 2000. On underspecified
processing of dynamic semantics. In Proceedings of
COLING-2000, Saarbr?cken.
A. Koller and K. Striegnitz. 2002. Generation as depen-
dency parsing. In ACL 2002, Philadelphia/USA.
J. T. Maxwell and R. M. Kaplan. 1993. The interface
between phrasal and functional constraints. Compu-
tational Linguistics, 19(4):571?590.
R. Montague. 1974. The proper treatment of quantifica-
tion in ordinary english. In Richard Thomason, editor,
Formal Philosophy. Selected Papers of Richard Mon-
tague, pages 247?271. Yale University Press, New
Haven and London.
M. Moortgat. 2002. Categorial grammar and formal se-
mantics. In Encyclopedia of Cognitive Science. Na-
ture Publishing Group, MacMillan. To appear.
Mozart Consortium. 2004. The Mozart-Oz website.
http://www.mozart-oz.org/.
G. Smolka. 1995. The Oz Programming Model. In
Computer Science Today, Lecture Notes in Computer
Science, vol. 1000, pages 324?343. Springer-Verlag.
M. Steedman. 1999. Alternating quantifier scope in
CCG. In Proc. 37th ACL, pages 301?308.
XTAG Research Group. 2001. A lexicalized tree adjoin-
ing grammar for english. Technical Report IRCS-01-
03, IRCS, University of Pennsylvania.
Talking Robots With LEGO MindStorms
Alexander Koller
Saarland University
Saarbru?cken, Germany
koller@coli.uni-sb.de
Geert-Jan M. Kruijff
Saarland University
Saarbru?cken, Germany
gj@coli.uni-sb.de
Abstract
This paper shows how talking robots can be built
from off-the-shelf components, based on the Lego
MindStorms robotics platform. We present four
robots that students created as final projects in a
seminar we supervised. Because Lego robots are so
affordable, we argue that it is now feasible for any
dialogue researcher to tackle the interesting chal-
lenges at the robot-dialogue interface.
1 Introduction
Ever since Karel ?Capek introduced the word ?robot?
in his 1921 novel Rossum?s Universal Robots and
the subsequent popularisation through Issac Asi-
mov?s books, the idea of building autonomous
robots has captured people?s imagination. The cre-
ation of an intelligent, talking robot has been the ul-
timate dream of Artificial Intelligence from the very
start.
Yet, although there has been a tremendous
amount of AI research on topics such as control
and navigation for robots, the issue of integrat-
ing dialogue capabilities into a robot has only re-
cently started to receive attention. Early successes
were booked with Flakey (Konolige et al, 1993),
a voice-controlled robot which roamed the corri-
dors of SRI. Since then, the field of socially in-
teractive robots has established itself (see (Fong et
al., 2003)). Often-cited examples of such inter-
active robots that have a capability of communi-
cating in natural language are the humanoid robot
ROBOVIE (Kanda et al, 2002) and robotic mu-
seum tour guides like RHINO (Burgard et al, 1999)
(Deutsches Museum Bonn), its successor MINERVA
touring the Smithsonian in Washington (Thrun et
al., 2000), and ROBOX at the Swiss National Ex-
hibition Expo02 (Siegwart and et al 2003). How-
ever, dialogue systems used in robotics appear to
be mostly restricted to relatively simple finite-state,
query/response interaction. The only robots in-
volving dialogue systems that are state-of-the-art in
computational linguistics (and that we are aware of)
are those presented by Lemon et al (2001), Sidner
et al (2003) and Bos et al (2003), who equipped
a mobile robot with an information state based dia-
logue system.
There are two obvious reasons for this gap be-
tween research on dialogue systems in robotics on
the one hand, and computational linguistics on the
other hand. One is that the sheer cost involved
in buying or building a robot makes traditional
robotics research available to only a handful of re-
search sites. Another is that building a talking robot
combines the challenges presented by robotics and
natural language processing, which are further ex-
acerbated by the interactions of the two sides.
In this paper, we address at least the first prob-
lem by demonstrating how to build talking robots
from affordable, commercial off-the-shelf (COTS)
components. We present an approach, tested in a
seminar taught at the Saarland University in Win-
ter 2002/2003, in which we combine the Lego
MindStorms system with COTS software for speech
recognition/synthesis and dialogue modeling.
The Lego MindStorms1 system extends the tra-
ditional Lego bricks with a central control unit (the
RCX), as well as motors and various kinds of sen-
sors. It provides a severely limited computational
platform from a traditional robotics point of view,
but comes at a price of a few hundred, rather than
tens of thousands of Euros per kit. Because Mind-
Storms robots can be flexibly connected to a dia-
logue system running on a PC, this means that af-
fordable robots are now available to dialogue re-
searchers.
We present four systems that were built by teams
of three students each under our supervision, and
use off-the-shelf components such as the Mind-
Storms kits, a dialogue system, and a speech recog-
niser and synthesis system, in addition to commu-
nications software that we ourselves wrote to link
all the components together. It turns out that using
1LEGO and LEGO MindStorms are trademarks of the
LEGO Company.
this accessible technology, it is possible to create
basic but interesting talking robots in limited time
(7 weeks). This is relevant not only for future re-
search, but can also serve as a teaching device that
has shown to be extremely motivating for the stu-
dents. MindStorms are a staple in robotics educa-
tion (Yu, 2003; Gerovich et al, 2003; Lund, 1999),
but to our knowledge, they have never been used as
part of a language technology curriculum.
The paper is structured as follows. We first
present the basic setup of the MindStorms system
and the software architecture. Then we present the
four talking robots built by our students in some de-
tail. Finally, we discuss the most important chal-
lenges that had to be overcome in building them.
We conclude by speculating on further work in Sec-
tion 5.
2 Architecture
Lego MindStorms robots are built around a pro-
grammable microcontroller, the RCX. This unit,
which looks like an oversized yellow Lego brick,
has three ports each to attach sensors and motors,
an infrared sender/receiver for communication with
the PC, and 32 KB memory to store the operating
system, a programme, and data.
Figure 1: Architecture of a talking Lego robot.
Our architecture for talking robots (Fig. 1) con-
sists of four main modules: a dialogue system, a
speech client with speech recognition and synthesis
capabilities, a module for infrared communication
between the PC and the RCX, and the programme
that runs on the RCX itself. Each student team had
to specify a dialogue, a speech recognition gram-
mar, and the messages exchanged between PC and
RCX, as well as the RCX control programme. All
other components were off-the-shelf systems that
were combined into a larger system by us.
The centrepiece of the setup is the dialogue
system. We used the DiaWiz system by CLT
Figure 2: The dialogue system.
Sprachtechnologie GmbH2, a proprietary frame-
work for defining finite-state dialogues (McTear,
2002). It has a graphical interface (Fig. 2) that al-
lows the user to draw the dialogue states (shown
as rectangles in the picture) and connect them via
edges. The dialogue system connects to an arbitrary
number of ?clients? via sockets. It can send mes-
sages to and receive messages from clients in each
dialogue state, and thus handles the entire dialogue
management. While it was particularly convenient
for us to use the CLT system, it could probably re-
placed without much effort by a VoiceXML-based
dialogue manager.
The client that interacts most directly with the
user is a module for speech recognition and synthe-
sis. It parses spoken input by means of a recogni-
tion grammar written in the Java Speech Grammar
Format, 3 and sends an extremely shallow semantic
representation of the best recognition result to the
dialogue manager as a feature structure. The out-
put side can be configured to either use a speech
synthesiser, or play back recorded WAV files. Our
implementation assumes only that the recognition
and synthesis engines are compliant with the Java
Speech API 4.
The IR communication module has the task of
converting between high-level messages that the di-
2http://www.clt-st.de
3http://java.sun.com/products/java-
media/speech/forDevelopers/JSGF/
4http://java.sun.com/products/java-media/speech/
Figure 3: A robot playing chess.
alogue manager and the RCX programme exchange
and their low-level representations that are actually
sent over the IR link, in such a way that the user
need not think about the particular low-level details.
The RCX programme itself is again implemented in
Java, using the Lejos system (Bagnall, 2002). Such
a programme is typically small (to fit into the mem-
ory of the microcontroller), and reacts concurrently
to events such as changes in sensor values and mes-
sages received over the infrared link, mostly by con-
trolling the motors and sending messages back to
the PC.
3 Some Robots
3.1 Playing Chess
The first talking robot we present plays chess
against the user (Fig. 3). It moves chess pieces on
a board by means of a magnetic arm, which it can
move up and down in order to grab and release a
piece, and can place the arm under a certain posi-
tion by driving back and forth on wheels, and to the
right and left on a gear rod.
The dialogue between the human player and the
robot is centred around the chess game: The human
speaks the move he wants to make, and the robot
confirms the intended move, and announces check
and checkmate. In order to perform the moves for
the robot, the dialogue manager connects to a spe-
cialised client which encapsulates the GNU Chess
system.5 In addition to computing the moves that
the robot will perform, the chess programme is also
used in disambiguating elliptical player inputs.
Figure 4 shows the part of the chess dialogue
model that accepts a move as a spoken command
from the player. The Input node near the top waits
for the speech recognition client to report that it
5http://www.gnu.org/software/chess/chess.html
Figure 4: A small part of the Chess dialogue.
<cmd> = [<move>] <piece> <to> <squareTo>
| ...
<squareTo> = <colTo> <rowTo>
<colTo> = [a wie] anton {colTo:a} |
[b wie] berta {colTo:b} | ...
<rowTo> = eins {rowTo:1} |
zwei {rowTo:2} | ...
Figure 5: A small part of the Chess grammar.
understood a player utterance as a command. An
excerpt from the recogniser grammar is shown in
Fig. 5: The grammar is a context-free grammar in
JSGF format, whose production rules are annotated
with tags (in curly brackets) representing a very
shallow semantics. The tags for all production rules
used in a parse tree are collected into a table.
The dialogue manager then branches depend-
ing on the type of the command given by the
user. If the command specified the piece and target
square, e.g. ?move the pawn to e4?, the recogniser
will return a representation like {piece="pawn"
colTo="e" rowTo="4"}, and the dialogue will
continue in the centre branch. The user can also
specify the source and target square.
If the player confirms that the move command
was recognised correctly, the manager sends the
move description to the chess client (the ?send
move? input nodes near the bottom), which can dis-
ambiguate the move description if necessary, e.g.
by expanding moves of type ?move the pawn to
e4? to moves of type ?move from e2 to e4?. Note
that the reference ?the pawn? may not be globally
unique, but if there is only one possible referent that
could perform the requested move, the chess client
resolves this automatically.
The client then sends a message to the RCX,
which moves the piece using the robot arm. It up-
dates its internal data structures, as well as the GNU
Chess representations, computes a move for itself,
and sends this move as another message to the RCX.
While the dialogue system as it stands already of-
fers some degree of flexibility with regard to move
phrasings, there is still plenty of open room for im-
provements. One is to use even more context infor-
mation, in order to understand commands like ?take
it with the rook?. Another is to incorporate recent
work on improving recognition results in the chess
domain by certain plausibility inferences (Gabsdil,
2004).
3.2 Playing a Shell Game
Figure 6 introduces Luigi Legonelli. The robot rep-
resents a charismatic Italian shell-game player, and
engages a human player in style: Luigi speaks Ger-
man with a heavy Italian accent, lets the human
player win the first round, and then tries to pull sev-
eral tricks either to cheat or to keep the player inter-
ested in the game.
Figure 6: A robot playing a shell game.
Luigi?s Italian accent was obtained by feeding
transliterated German sentences to a speech synthe-
sizer with an Italian voice. Although the resulting
accent sounded authentic, listeners who were unfa-
miliar with the accent had trouble understanding it.
For demonstration purposes we therefore decided to
use recorded speech instead. To this end, the Italian
student on the team lent his voice for the different
sentences uttered by Luigi.
The core of Luigi?s dialogue model reflects the
progress of game play in a shell game. At the start,
Luigi and the player settle on a bet (between 1 and
10 euros), and Luigi shows under which shell the
coin is. Then, Luigi manipulates the shells (see
also below), moving them (and the coin) around the
board, and finally asks the player under which shell
the player believes the coin is. Upon the player?s
guess Luigi lifts the shell indicated by the player,
and either loudly exclaims the unfairness of life (if
he has lost) or kindly inquires after the player?s
visual capacities (in case the player has guessed
wrong). At the end of the turn, Luigi asks the player
whether he wants to play again. If the player would
like to stop, Luigi tries to persuade the player to
stay; only if the player is persistent, Luigi will end
the game and beat a hasty retreat.
(1) rob ?Ciao, my name is Luigi Legonelli.
Do you feel like a little game??
usr ?Yes ... ?
rob ?The rules are easy. I move da cuppa,
you know, cuppa? You look, say where
coin is. How much money you bet??
usr ?10 Euros.?
rob (Luigi moves the cups/shells)
rob ?So, where is the coin? What do you
think, where?s the coin??
usr ?Cup 1?
rob ?Mamma mia! You have won! Who
told you, where is coin?! Another
game? Another game!?
usr ?No.?
rob ?Come! Play another game!?
usr ?No.?
rob ?Okay, ciao signorina! Police, much
police! Bye bye!?
The shells used in the game are small cups with a
metal top (a nail), which enables Luigi to pick them
up using a ?hand? constructed around a magnet.
The magnet has a downward oriented, U-shaped
construction that enables Luigi to pick up two cups
at the same time. Cups then get moved around
the board by rotating the magnet. By magnetizing
the nail at the top of the cup, not only the cup but
also the coin (touched by the tip of the nail) can be
moved. When asked to show whether the coin is un-
der a particular shell, one of Luigi?s tricks is to keep
the nail magnetized when lifting a cup ? thus also
lifting the coin, giving off the impression that there
was no coin under the shell.
The Italian accent, the android shape of the robot,
and the ?authentic? behavior of Luigi all contributed
to players genuinely getting engaged in the game.
After the first turn, having won, most players ac-
knowledged that this is an amusing Lego construc-
tion; when they were tricked at the end of the sec-
ond turn, they expressed disbelief; and when we
showed them that Luigi had deliberately cheated
them, astonishment. At that point, Luigi had ceased
to be simply an amusing Lego construction and had
achieved its goal as an entertainment robot that can
immerse people into its game.
3.3 Exploring a pyramid
The robot in Figure 7, dubbed ?Indy?, is inspired
by the various robots that have been used to explore
the Great Pyramids in Egypt (e.g. Pyramid Rover6,
UPUAUT7). It has a digital videocamera (webcam)
and a lamp mounted on it, and continually transmits
images from inside the pyramid. The user, watch-
ing the images of the videocamera on a computer
screen, can control the robot?s movements and the
angle of the camera by voice.
Figure 7: A robot exploring a pyramid.
Human-robot interaction is crucial to the explo-
ration task, as neither user nor robot has a com-
plete picture of the environment. The robot is aware
of the environment through an (all-round) array of
touch-sensors, enabling it to detect e.g. openings in
walls; the user receives a more detailed picture, but
6http://www.newscientist.com/news/news.jsp?id=ns99992805
7http://www.cheops.org
only of the environment straight ahead of the robot
(due to the frontal orientation of the camera).
The dialogue model for Indy defines the possible
interaction that enables Indy and the user to jointly
explore the environment. The user can initiate a di-
alogue to control the camera and its orientation (by
letting the robot turn on the spot, in a particular di-
rection), or to instruct the robot to make particular
movements (i.e. turn left or right, stop).
3.4 Traversing a labyrinth
A variation on the theme of human-robot interaction
in navigation is the robot in Figure 8. Here, the user
needs to guide a robot through a labyrinth, specified
by thick black lines on a white background. The
task that the robot and the human must solve col-
laboratively is to pick up objects randomly strewn
about the maze. The robot is able to follow the black
lines lines (the ?path?) by means of an array of three
light sensors at its front.
Figure 8: A robot traversing a labyrinth.
Both the user and the robot can take the initia-
tive in the dialogue. The robot, capable of spotting
crossings (and the possibilities to go straight, left
and/or right), can initiate a dialogue asking for di-
rections if the user had not instructed the robot be-
forehand; see Example 2.
(2) rob (The robot arrives at a crossing; it
recognizes the possibility to go either
straight or left; there are no current in-
structions)
rob ?I can go left or straight ahead; which
way should I go??
usr ?Please go right.?
rob ?I cannot go right here.
usr ?Please go straight.?
rob ?Okay.?
The user can give the robot two different types of
directions: in-situ directions (as illustrated in Ex-
ample 2) or deictic directions (see Example 3 be-
low). This differentiates the labyrinth robot from
the pyramid robot described in ?3.3, as the latter
could only handle in-situ directions.
(3) usr ?Please turn left at the next crossing.?
rob ?Okay?
rob (The robot arrives at a crossing; it
recognizes the possibility to go either
straight or left; it was told to go left at
the next crossing)
rob (The robot recognizes it can go left
and does so, as instructed)
4 Discussion
The first lesson we can learn from the work de-
scribed above is that affordable COTS products in
dialogue and robotics have advanced to the point
that it is feasible to build simple but interesting talk-
ing robots with limited effort. The Lego Mind-
Storms platform, combined with the Lejos system,
turned out to be a flexible and affordable robotics
framework. More ?professional? robots have the
distinct advantage of more interesting sensors and
more powerful on-board computing equipment, and
are generally more physically robust, but Lego
MindStorms is more than suitable for robotics ex-
perimentation under controlled circumstances.
Each of the robots was designed, built, and pro-
grammed within twenty person-weeks, after an ini-
tial work phase in which we created the basic in-
frastructure shown in Figure 1. One prerequisite of
this rather efficient development process was that
the entire software was built on the Java platform,
and was kept highly modular. Speech software ad-
hering to the Java Speech API is becoming avail-
able, and plugging e.g. a different JSAPI-compliant
speech recogniser into our system is now a matter
of changing a line in a configuration file.
However, building talking robots is still a chal-
lenge that combines the particular problems of dia-
logue systems and robotics, both of which introduce
situations of incomplete information. The dialogue
side has to robustly cope with speech recognition er-
rors, and our setup inherits all limitations inherent in
finite-state dialogue; applications having to do e.g.
with information seeking dialogue would be better
served with a more complex dialogue model. On
the other hand, a robot lives in the real world, and
has to deal with imprecisions in measuring its po-
sition, unexpected obstacles, communications with
the PC breaking off, and extremely limited sensory
information about its surroundings.
5 Conclusion
The robots we developed together with our stu-
dents were toy robots, looked like toy robots, and
could (given the limited resources) only deal with
toy examples. However, they confirmed that there
are affordable COTS components on the market
with which we can, even in a limited amount of
time, build engaging talking robots that capture the
essence of various (potential) real-life applications.
The chess and shell game players could be used as
entertainment robots. The labyrinth and pyramid
robots could be extended into tackling real-world
exploration or rescue tasks, in which robots search
for disaster victims in environments that are too
dangerous for rescuers to venture into.8 Dialogue
capabilities are useful in such applications not just
to communicate with the human operator, but also
possibly with disaster victims, to check their condi-
tion.
Moreover, despite the small scale of these robots,
they show genuine issues that could provide in-
teresting lines of research at the interface between
robotics and computational linguistics, and in com-
putational linguistics as such. Each of our robots
could be improved dramatically on the dialogue side
in many ways. As we have demonstrated that the
equipment for building talking robots is affordable
today, we invite all dialogue researchers to join us
in making such improvements, and in investigat-
ing the specific challenges that the combination of
robotics and dialogue bring about. For instance, a
robot moves and acts in the real world (rather than
a carefully controlled computer system), and suffers
from uncertainty about its surroundings. This limits
the ways in which the dialogue designer can use vi-
sual context information to help with reference res-
olution.
Robots, being embodied agents, present a host
of new challenges beyond the challenges we face
in computational linguistics. The interpretation of
language needs to be grounded in a way that is
both based in perception, and on conceptual struc-
tures to allow for generalization over experiences.
Naturally, this problem extends to the acquisition
of language, where approaches such as (Nicolescu
and Mataric?, 2001; Carbonetto and Freitos, 2003;
Oates, 2003) have focused on basing understanding
entirely in sensory data.
Another interesting issue concerns the interpreta-
tion of deictic references. Research in multi-modal
8See also http://www.rescuesystem.org/robocuprescue/
interfaces has addressed the issue of deictic refer-
ence, notably in systems that allow for pen-input
(see (Oviatt, 2001)). Embodied agents raise the
complexity of the issues by offering a broader range
of sensory input that needs to be combined (cross-
modally) in order to establish possible referents.
Acknowledgments. The authors would like to
thank LEGO and CLT Sprachtechnologie for pro-
viding free components from which to build our
robot systems. We are deeply indebted to our stu-
dents, who put tremendous effort into designing and
building the presented robots. Further information
about the student projects (including a movie) is
available at the course website, http://www.coli.uni-
sb.de/cl/courses/lego-02.
References
Brian Bagnall. 2002. Core Lego Mindstorms Pro-
gramming. Prentice Hall, Upper Saddle River
NJ.
Johan Bos, Ewan Klein, and Tetsushi Oka. 2003.
Meaningful conversation with a mobile robot. In
Proceedings of the 10th EACL, Budapest.
W. Burgard, A.B. Cremers, D. Fox, D. Ha?hnel,
G. Lakemeyer, D. Schulz, W. Steiner, and
S. Thrun. 1999. Experiences with an interactive
museum tour-guide robot. Artificial Intelligence,
114(1-2):3?55.
Peter Carbonetto and Nando de Freitos. 2003. Why
can?t Jose? talk? the problem of learning se-
mantic associations in a robot environment. In
Proceedings of the HLT-NAACL 2003 Workshop
on Learning Word Meaning from Non-Linguistic
Data, pages 54?61, Edmonton, Canada.
Terrence W Fong, Illah Nourbakhsh, and Kerstin
Dautenhahn. 2003. A survey of socially interac-
tive robots. Robotics and Autonomous Systems,
42:143?166.
Malte Gabsdil. 2004. Combining acoustic confi-
dences and pragmatic plausibility for classifying
spoken chess move instructions. In Proceedings
of the 5th SIGdial Workshop on Discourse and
Dialogue.
Oleg Gerovich, Randal P. Goldberg, and Ian D.
Donn. 2003. From science projects to the en-
gineering bench. IEEE Robotics & Automation
Magazine, 10(3):9?12.
Takayuki Kanda, Hiroshi Ishiguro, Tetsuo Ono, Mi-
chita Imai, and Ryohei Nakatsu. 2002. Develop-
ment and evaluation of an interactive humanoid
robot ?robovie?. In Proceedings of the IEEE In-
ternational Conference on Robotics and Automa-
tion (ICRA 2002), pages 1848?1855.
Kurt Konolige, Karen Myers, Enrique Ruspini,
and Alessandro Saffiotti. 1993. Flakey in ac-
tion: The 1992 aaai robot competition. Techni-
cal Report 528, AI Center, SRI International, 333
Ravenswood Ave., Menlo Park, CA 94025, Apr.
Oliver Lemon, Anne Bracy, Alexander Gruenstein,
and Stanley Peters. 2001. A multi-modal dia-
logue system for human-robot conversation. In
Proceedings NAACL 2001.
Henrik Hautop Lund. 1999. AI in children?s play
with LEGO robots. In Proceedings of AAAI 1999
Spring Symposium Series, Menlo Park. AAAI
Press.
Michael McTear. 2002. Spoken dialogue technol-
ogy: enabling the conversational user interface.
ACM Computing Surveys, 34(1):90?169.
Monica N. Nicolescu and Maja J. Mataric?. 2001.
Learning and interacting in human-robot do-
mains. IEEE Transactions on Systems, Man and
Cybernetics, 31.
Tim Oates. 2003. Grounding word meanings
in sensor data: Dealing with referential un-
certainty. In Proceedings of the HLT-NAACL
2003 Workshop on Learning Word Meaning from
Non-Linguistic Data, pages 62?69, Edmonton,
Canada.
Sharon L. Oviatt. 2001. Advances in the robust
processing of multimodal speech and pen sys-
tems. In P. C. Yuen, Y.Y. Tang, and P.S. Wang,
editors, Multimodal InterfacesB for Human Ma-
chine Communication, Series on Machine Per-
ception and Artificial Intelligence, pages 203?
218. World Scientific Publisher, London, United
Kingdom.
Candace L. Sidner, Christopher Lee, and Neal Lesh.
2003. Engagement by looking: Behaviors for
robots when collaborating with people. In Pro-
ceedings of the 7th workshop on the semantics
and pragmatics of dialogue (DIABRUCK).
R. Siegwart and et al 2003. Robox at expo.02:
A large scale installation of personal robots.
Robotics and Autonomous Systems, 42:203?222.
S. Thrun, M. Beetz, M. Bennewitz, W. Burgard,
A.B. Cremers, F. Dellaert, D. Fox, D. Ha?hnel,
C. Rosenberg, N. Roy, J. Schulte, and D. Schulz.
2000. Probabilistic algorithms and the interactive
museum tour-guide robot minerva. International
Journal of Robotics Research, 19(11):972?999.
Xudong Yu. 2003. Robotics in education: New
platforms and environments. IEEE Robotics &
Automation Magazine, 10(3):3.
195
196
197
198
199
200
201
202
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 451?459,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
A Logic of Semantic Representations for Shallow Parsing
Alexander Koller
Saarland University
Saarbru?cken, Germany
koller@mmci.uni-saarland.de
Alex Lascarides
University of Edinburgh
Edinburgh, UK
alex@inf.ed.ac.uk
Abstract
One way to construct semantic represen-
tations in a robust manner is to enhance
shallow language processors with seman-
tic components. Here, we provide a model
theory for a semantic formalism that is de-
signed for this, namely Robust Minimal
Recursion Semantics (RMRS). We show
that RMRS supports a notion of entailment
that allows it to form the basis for compar-
ing the semantic output of different parses
of varying depth.
1 Introduction
Representing semantics as a logical form that sup-
ports automated inference and model construc-
tion is vital for deeper language engineering tasks,
such as dialogue systems. Logical forms can be
obtained from hand-crafted deep grammars (Butt
et al, 1999; Copestake and Flickinger, 2000) but
this lacks robustness: not all words and con-
structions are covered and by design ill-formed
phrases fail to parse. There has thus been a trend
recently towards robust wide-coverage semantic
construction (e.g., (Bos et al, 2004; Zettlemoyer
and Collins, 2007)). But there are certain seman-
tic phenomena that these robust approaches don?t
capture reliably, including quantifier scope, op-
tional arguments, and long-distance dependencies
(for instance, Clark et al (2004) report that the
parser used by Bos et al (2004) yields 63% ac-
curacy on object extraction; e.g., the man that I
met. . . ). Forcing a robust parser to make a de-
cision about these phenomena can therefore be
error-prone. Depending on the application, it may
be preferable to give the parser the option to leave
a semantic decision open when it?s not sufficiently
informed?i.e., to compute a partial semantic rep-
resentation and to complete it later, using informa-
tion extraneous to the parser.
In this paper, we focus on an approach to se-
mantic representation that supports this strategy:
Robust Minimal Recursion Semantics (RMRS,
Copestake (2007a)). RMRS is designed to support
underspecification of lexical information, scope,
and predicate-argument structure. It is an emerg-
ing standard for representing partial semantics,
and has been applied in several implemented sys-
tems. For instance, Copestake (2003) and Frank
(2004) use it to specify semantic components to
shallow parsers ranging in depth from POS tag-
gers to chunk parsers and intermediate parsers
such as RASP (Briscoe et al, 2006). MRS anal-
yses (Copestake et al, 2005) derived from deep
grammars, such as the English Resource Grammar
(ERG, (Copestake and Flickinger, 2000)) are spe-
cial cases of RMRS. But RMRS, unlike MRS and re-
lated formalisms like dominance constraints (Egg
et al, 2001), is able to express semantic infor-
mation in the absence of full predicate argument
structure and lexical subcategorisation.
The key contribution we make is to cast RMRS,
for the first time, as a logic with a well-defined
model theory. Previously, no such model theory
existed, and so RMRS had to be used in a some-
what ad-hoc manner that left open exactly what
any given RMRS representation actually means.
This has hindered practical progress, both in terms
of understanding the relationship of RMRS to other
frameworks such as MRS and predicate logic and
in terms of the development of efficient algo-
rithms. As one application of our formalisation,
we use entailment to propose a novel way of char-
acterising consistency of RMRS analyses across
different parsers.
Section 2 introduces RMRS informally and illus-
trates why it is necessary and useful for represent-
ing semantic information across deep and shallow
language processors. Section 3 defines the syntax
and model-theory of RMRS. We finish in Section 4
by pointing out some avenues for future research.
451
2 Deep and shallow semantic
construction
Consider the following (toy) sentence:
(1) Every fat cat chased some dog.
It exhibits several kinds of ambiguity, includ-
ing a quantifier scope ambiguity and lexical
ambiguities?e.g., the nouns ?cat? and ?dog? have
8 and 7 WordNet senses respectively. Simplifying
slightly by ignoring tense information, two of its
readings are shown as logical forms below; these
can be represented as trees as shown in Fig. 1.
(2) every q 1(x, fat j 1(e?, x) ? cat n 1(x),
some q 1(y, dog n 1(y),
chase v 1(e, x, y)))
(3) some q 1(y, dog n 2(y),
every q 1(x, fat j 1(e?, x) ? cat n 2(x),
chase v 1(e, x, y)))
Now imagine trying to extract semantic infor-
mation from the output of a part-of-speech (POS)
tagger by using the word lemmas as lexical pred-
icate symbols. Such a semantic representation
is highly partial. It will use predicate symbols
such as cat n, which might resolve to the pred-
icate symbols cat n 1 or cat n 2 in the com-
plete semantic representation. (Notice the dif-
ferent fonts for the ambiguous and unambiguous
predicate symbols.) But most underspecification
formalisms (e.g., MRS (Copestake et al, 2005) and
CLLS (Egg et al, 2001)) are unable to represent se-
mantic information that is as partial as what we get
from a POS tagger because they cannot underspec-
ify predicate-argument structure. RMRS (Copes-
take, 2007a) is designed to address this problem.
In RMRS, the information we get from the POS tag-
ger is as follows:
(4) l1 : a1 : every q(x1),
l41 : a41 : fat j(e?),
l42 : a42 : cat n(x3)
l5 : a5 : chase v(e),
l6 : a6 : some q(x6),
l9 : a9 : dog n(x7)
This RMRS expresses only that certain predica-
tions are present in the semantic representation?
it doesn?t say anything about semantic scope,
about most arguments of the predicates (e.g.,
chase v(e) doesn?t say who chases whom), or
about the coindexation of variables ( every q
_every_q_1
x
?
_fat_j_1
e' x
_cat_n_1
x
_some_q_1
y _dog_n_1
y
_chase_v_1
e x y
_every_q_1
x
?
_fat_j_1
e' x
_cat_n_2
x
_some_q_1
y _dog_n_2
y
_chase_v_1
e x y
Figure 1: Semantic representations (2) and (3) as
trees.
binds the variable x1, whereas cat n speaks about
x3), and it maintains the lexical ambiguities. Tech-
nically, it consists of six elementary predications
(EPs), one for each word lemma in the sentence;
each of them is prefixed by a label and an anchor,
which are essentially variables that refer to nodes
in the trees in Fig. 1. We can say that the two trees
satisfy this RMRS because it is possible to map the
labels and anchors in (4) into nodes in each tree
and variable names like x1 and x3 into variable
names in the tree in such a way that the predica-
tions of the nodes that labels and anchors denote
are consistent with those in the EPs of (4)?e.g., l1
and a1 can map to the root of the first tree in Fig. 1,
x1 to x, and the root label every q 1 is consistent
with the EP predicate every q.
There are of course many other trees (and thus,
fully specific semantic representations such as (2))
that are described equally well by the RMRS (4);
this is not surprising, given that the semantic out-
put from the POS tagger is so incomplete. If we
have information about subjects and objects from
a chunk parser like Cass (Abney, 1996), we can
represent it in a more detailed RMRS:
(5) l1 : a1 : every q(x1),
l41 : a41 : fat j(e?),
l42 : a42 : cat n(x3)
l5 : a5 : chase v(e),
ARG1(a5, x4),ARG2(a5, x5)
l6 : a6 : some q(x6),
l9 : a9 : dog n(x7)
x3 = x4, x5 = x7
This introduces two new types of atoms. x3 =
x4 means that x3 and x4 map to the same variable
in any fully specific logical form; e.g., both to the
variable x in Fig. 1. ARGi(a, z) (and ARGi(a, h))
452
express that the i-th child (counting from 0) of the
node to which the anchor a refers is the variable
name that z denotes (or the node that the hole h
denotes). So unlike earlier underspecification for-
malisms, RMRS can specify the predicate of an
atom separately from its arguments; this is nec-
essary for supporting parsers where information
about lexical subcategorisation is absent. If we
also allow atoms of the form ARG{2,3}(a, x) to ex-
press uncertainty as to whether x is the second or
third child of the anchor a, then RMRS can even
specify the arguments to a predicate while under-
specifying their position. This is useful for speci-
fying arguments to give v when a parser doesn?t
handle unbounded dependencies and is faced with
Which bone did you give the dog? vs. To which
dog did you give the bone?
Finally, the RMRS (6) is a notational variant of
the MRS derived by the ERG, a wide-coverage deep
grammar:
(6) l1 : a1: every q 1(x1),
RSTR(a1, h2),BODY(a1, h3)
l41 : a41: fat j 1(e?),ARG1(a41, x2)
l42 : a42: cat n 1(x3)
l5 : a5: chase v 1(e),
ARG1(a5, x4),ARG2(a5, x5)
l6 : a6: some q 1(x6),
RSTR(a6, h7),BODY(a6, h8)
l9 : a9: dog n 1(x7)
h2 =q l42, l41 = l42, h7 =q l9
x1 = x2, x2 = x3, x3 = x4,
x5 = x6, x5 = x7
RSTR and BODY are conventional names for
the ARG1 and ARG2 of a quantifier predicate sym-
bol. Atoms like h2 =q l42 (?qeq?) specify a cer-
tain kind of ?outscopes? relationship between the
hole and the label, and are used here to underspec-
ify the scope of the two quantifiers. Notice that the
labels of the EPs for ?fat? and ?cat? are stipulated
to be equal in (6), whereas the anchors are not. In
the tree, it is the anchors that are mapped to the
nodes with the labels fat j 1 and cat n 1; the la-
bel is mapped to the conjunction node just above
them. In other words, the role of the anchor in an
EP is to connect a predicate to its arguments, while
the role of the label is to connect the EP to the sur-
rounding formula. Representing conjunction with
label sharing stems from MRS and provides com-
pact representations.
Finally, (6) uses predicate symbols like
dog n 1 that are meant to be more specific than
symbols like dog n which the earlier RMRSs
used. This reflects the fact that the deep gram-
mar performs some lexical disambiguation that the
chunker and POS tagger don?t. The fact that the
former symbol should be more specific than the
latter can be represented using SPEC atoms like
dog n 1 " dog n. Note that even a deep gram-
mar will not fully disambiguate to semantic pred-
icate symbols, such as WordNet senses, and so
dog n 1 can still be consistent with multiple sym-
bols like dog n 1 and dog n 2 in the semantic
representation. However, unlike the output of a
POS tagger, an RMRS symbol that?s output by a
deep grammar is consistent with symbols that all
have the same arity, because a deep grammar fully
determines lexical subcategorisation.
In summary, RMRS allows us to represent in a
uniform way the (partial) semantics that can be
extracted from a wide range of NLP tools. This
is useful for hybrid systems which exploit shal-
lower analyses when deeper parsing fails, or which
try to match deeply parsed queries against shal-
low parses of large corpora; and in fact, RMRS is
gaining popularity as a practical interchange for-
mat for exactly these purposes (Copestake, 2003).
However, RMRS is still relatively ad-hoc in that its
formal semantics is not defined; we don?t know,
formally, what an RMRS means in terms of seman-
tic representations like (2) and (3), and this hin-
ders our ability to design efficient algorithms for
processing RMRS. The purpose of this paper is to
lay the groundwork for fixing this problem.
3 Robust Minimal Recursion Semantics
We will now make the basic ideas from Section
2 precise. We will first define the syntax of the
RMRS language; this is a notational variant of ear-
lier definitions in the literature. We will then de-
fine a model theory for our version of RMRS, and
conclude this section by carrying over the notion
of solved forms from CLLS (Egg et al, 2001).
3.1 RMRS Syntax
We define RMRS syntax in the style of CLLS (Egg
et al, 2001). We assume an infinite set of node
variables NVar = {X,Y,X1, . . .}, used as labels,
anchors, and holes; the distinction between these
will come from their position in the formulas. We
also assume an infinite set of base variables BVar,
consisting of individual variables {x, x1, y, . . .}
and event variables {e1, . . .}, and a vocabulary of
453
predicate symbols Pred = {P,Q, P1, . . .}. RMRS
formulas are defined as follows.
Definition 1. An RMRS is a finite set ? of atoms
of one of the following forms; S ? N is a set of
numbers that is either finite orN itself (throughout
the paper, we assume 0 ? N).
A ::= X:Y :P
| ARGS(X, v)
| ARGS(X,Y )
| X !? Y
| v1 = v2 | v1 %= v2
| X = Y | X %= Y
| P " Q
A node variable X is called a label iff ? con-
tains an atom of the form X:Y :P or Y !? X; it
is an anchor iff ? contains an atom of the form
Y :X:P or ARGS(X, i); and it is a hole iff ? con-
tains an atom of the form ARGS(Y,X) or X!?Y .
Def. 1 combines similarities to earlier presen-
tations of RMRS (Copestake, 2003; Copestake,
2007b) and to CLLS/dominance constraints (Egg
et al, 2001). For the most part, our syntax
generalises that of older versions of RMRS: We
use ARG{i} (with a singleton set S) instead of
ARGi and ARGN instead of ARGn, and the EP
l:a:P (v) (as in Section 2) is an abbreviation of
{l:a:P,ARG{0}(a, v)}. Similarly, we don?t as-
sume that labels, anchors, and holes are syntacti-
cally different objects; they receive their function
from their positions in the formula. One major dif-
ference is that we use dominance (!?) rather than
qeq; see Section 3.4 for a discussion. Compared
to dominance constraints, the primary difference
is that we now have a mechanism for representing
lexical ambiguity, and we can specify a predicate
and its arguments separately.
3.2 Model Theory
The model theory formalises the relationship be-
tween an RMRS and the fully specific, alternative
logical forms that it describes, expressed in the
base language. We represent such a logical form
as a tree ? , such as the ones in Fig. 1, and we can
then define satisfaction of formulas in the usual
way, by taking the tree as a model structure that
interprets all predicate symbols specified above.
In this paper, we assume for simplicity that the
base language is as in MRS; essentially, ? becomes
the structure tree of a formula of predicate logic.
We assume that ? is a ranked signature consist-
ing of the symbols of predicate logic: a unary con-
structor ? and binary constructors ?,?, etc.; a set
of 3-place quantifier symbols such as every q 1
and some q 1 (with the children being the bound
variable, the restrictor, and the scope); and con-
structors of various arities for the predicate sym-
bols; e.g., chase v 1 is of arity 3. Other base lan-
guages may require a different signature ? and/or
a different mapping between formulas and trees;
the only strict requirement we make is that the
signature contains a binary constructor ? to rep-
resent conjunction. We write ?i and ??i for the
set of all constructors in ? with arity i and at least
i, respectively. We will follow the typographical
convention that non-logical symbols in ? are writ-
ten in sans-serif, as opposed to the RMRS predicate
symbols like cat n and cat n 1.
The models of RMRS are then defined to be fi-
nite constructor trees (see also (Egg et al, 2001)):
Definition 2. A finite constructor tree ? is a func-
tion ? : D ? ? such that D is a tree domain (i.e.,
a subset ofN? which is closed under prefix and left
sibling) and the number of children of each node
u ? D is equal to the arity of ?(u).
We write D(?) for the tree domain of a con-
structor tree ? , and further define the following re-
lations between nodes in a finite constructor tree:
Definition 3. u !? v (dominance) iff u is a prefix
of v, i.e. the node u is equal to or above the node
v in the tree. u!?? v iff u!? v, and all symbols on
the path from u to v (not including v) are ?.
The satisfaction relation between an RMRS ?
and a finite constructor tree ? is defined in terms
of several assignment functions. First, a node
variable assignment function ? : NVar ? D(?)
maps the node variables in an RMRS to the nodes
of ? . Second, a base language assignment func-
tion g : BVar ? ?0 maps the base variables to
nullary constructors representing variables in the
base language. Finally, a function ? from Pred to
the power set of ??1 maps each RMRS predicate
symbol to a set of constructors from ?. As we?ll
see shortly, this function allows an RMRS to under-
specify lexical ambiguities.
Definition 4. Satisfaction of atoms is defined as
454
follows:
?,?, g,? |= X:Y :P iff
?(?(Y )) ? ?(P ) and ?(X)!?? ?(Y )
?,?, g,? |= ARGS(X, a) iff exists i ? S s.t.
?(X) ? i ? D(?) and ?(?(X) ? i) = g(a)
?,?, g,? |= ARGS(X,Y ) iff exists i ? S s.t.
?(X) ? i ? D(?),?(X) ? i = ?(Y )
?,?, g,? |= X !? Y iff ?(X)!? ?(Y )
?,?, g,? |= X =/%= Y iff ?(X) =/%= ?(Y )
?,?, g,? |= v1 =/%= v2 iff g(v1) =/%= g(v2)
?,?, g,? |= P " Q iff ?(P ) ? ?(Q)
A 4-tuple ?,?, g,? satisfies an RMRS ? (written
?,?, g,? |= ?) iff it satisfies all of its elements.
Notice that one RMRS may be satisfied by mul-
tiple trees; we can take the RMRS to be a par-
tial description of each of these trees. In partic-
ular, RMRSs may represent semantic scope ambi-
guities and/or missing information about seman-
tic dependencies, lexical subcategorisation and
lexical senses. For j = {1, 2}, suppose that
?j ,?j , gj ,? |= ?. Then ? exhibits a semantic
scope ambiguity if there are variables Y, Y ? ?
NVar such that ?1(Y ) !? ?1(Y ?) and ?2(Y ?) !?
?2(Y ). It exhibits missing information about se-
mantic dependencies if there are base-language
variables v, v? ? BVar such that g1(v) = g1(v?)
and g2(v) %= g2(v?). It exhibits missing lex-
ical subcategorisation information if there is a
Y ? NVar such that ?1(?1(Y )) is a construc-
tor of a different type from ?2(?2(Y )) (i.e., the
constructors are of a different arity or they dif-
fer in whether their arguments are scopal vs. non-
scopal). And it exhibits missing lexical sense in-
formation if ?1(?1(Y )) and ?2(?2(Y )) are differ-
ent base-language constructors, but of the same
type.
Let?s look again at the RMRS (4). This is sat-
isfied by the trees in Fig. 1 (among others) to-
gether with some particular ?, g, and ?. For in-
stance, consider the left-hand side tree in Fig. 1.
The RMRS (4) satisfies this tree with an assign-
ment function ? that maps the variables l1 and a1
to the root node, l41 and l42 to its second child
(labeled with ???), a41 to the first child of that
node (i.e. the node 21, labelled with ?fat?) and
a42 to the node 22, and so forth. g will map x1
and x3 to x, and x6 and x7 to y, and so on. And
? will map each RMRS predicate symbol (which
represents a word) to the set of its fully resolved
meanings, e.g. cat n to a set containing cat n 1
_every_q_1
x
?
_fat_j_1
e' x
_cat_n_1
x
_some_q_1
y _dog_n_1
y
_chase_v_1
e x y
?
?
_sleep_v_1
e''
x
_run_v_1
e''' y
Figure 2: Another tree which satisfies (6).
and possibly others. It is then easy to verify
that every single atom in the RMRS is satisfied?
most interestingly, the EPs l41:a41: fat j(e?) and
l42:a42: cat n(x3) are satisfied because ?(l41)!??
?(a41) and ?(l42)!?? ?(a42).
Truth, validity and entailment can now be de-
fined in terms of satisfiability in the usual way:
Definition 5. truth: ? |= ? iff ??, g,? such that
?,?, g,? |= ?
validity: |= ? iff ?? , ? |= ?.
entailment: ? |= ?? iff ?? , if ? |= ? then ? |= ??.
3.3 Solved Forms
One aspect in which our definition of RMRS is like
dominance constraints and unlike MRS is that any
satisfiable RMRS has an infinite number of mod-
els which only differ in the areas that the RMRS
didn?t ?talk about?. Reading (6) as an MRS or as
an RMRS of the previous literature, this formula
is an instruction to build a semantic representa-
tion out of the pieces for ?every fat cat?, ?some
dog?, and ?chased?; a semantic representation as
in Fig. 2 would not be taken as described by this
RMRS. However, under the semantics we proposed
above, this tree is a correct model of (6) because
all atoms are still satisfied; the RMRS didn?t say
anything about ?sleep? or ?run?, but it couldn?t en-
force that the tree shouldn?t contain those subfor-
mulas either.
In the context of robust semantic processing,
this is a desirable feature, because it means that
when we enrich an RMRS obtained from a shal-
low processor with more semantic information?
such as the relation symbols introduced by syntac-
tic constructions such as appositives, noun-noun
compounds and free adjuncts?we don?t change
the set of models; we only restrict the set of mod-
els further and further towards the semantic rep-
resentation we are trying to reconstruct. Further-
more, it has been shown in the literature that a
dominance-constraint style semantics for under-
specified representations gives us more room to
455
manoeuvre when developing efficient solvers than
an MRS-style semantics (Althaus et al, 2003).
However, enumerating an infinite number of
models is of course infeasible. For this reason,
we will now transfer the concept of solved forms
from dominance constraints to RMRS. An RMRS
in solved form is guaranteed to be satisfiable, and
thus each solved form represents an infinite class
of models. However, each satisfiable RMRS has
only a finite number of solved forms which parti-
tion the space of possible models into classes such
that models within a class differ only in ?irrele-
vant? details. A solver can then enumerate the
solved forms rather than all models.
Intuitively, an RMRS in solved form is fully
specified with respect to the predicate-argument
structure, all variable equalities and inequalities
and scope ambiguities have been resolved, and
only lexical sense ambiguities remain. This is
made precise below.
Definition 6. An RMRS ? is in solved form iff:
1. every variable in ? is either a hole, a label or
an anchor (but not two of these);
2. ? doesn?t contain equality, inequality, and
SPEC (") atoms;
3. if ARGS(Y, i) is in ?, then |S| = 1;
4. for any label Y and index set S, there are no
two atomsARGS(Y, i) andARGS(Y, i?) in?;
5. if Y is an anchor in some EP X:Y :P
and k is the maximum number such that
ARG{k}(X, i) is in ? for any i, then there is a
constructor p ? ?(P ) whose arity is at least
k;
6. no label occurs on the right-hand side of two
different !? atoms.
Because solved forms are so restricted, we can
?read off? at least one model from each solved
form:
Proposition 1. Every RMRS in solved form is sat-
isfiable.
Proof (sketch; see also (Duchier and Niehren, 2000)).
For each EP, we choose to label the anchor with
the constructor p of sufficiently high arity whose
existence we assumed; we determine the edges
between an anchor and its children from the
uniquely determined ARG atoms; plugging labels
into holes is straightforward because no label is
dominated by more than one hole; and spaces
between the labels and anchors are filled with
conjunctions.
We can now define the solved forms of an RMRS
?; these finitely many RMRSs in solved form parti-
tion the space of models of ? into classes of mod-
els with trivial differences.
Definition 7. The syntactic dominance relation
D(?) in an RMRS ? is the reflexive, transitive clo-
sure of the binary relation
{(X,Y ) | ? contains X !? Y or
ARGS(X,Y ) for some S}
An RMRS ?? is a solved form of the RMRS ? iff
?? is in solved form and there is a substitution s
that maps the node and base variables of ? to the
node and base variables of ?? such that
1. ?? contains the EP X ?:Y ?:P iff there are vari-
ables X,Y such that X:Y :P is in ?, X ? =
s(X), and Y ? = s(Y );
2. for every atom ARGS(X, i) in ?, there is
exactly one atom ARGS?(X ?, i?) in ?? with
X ? = s(X), i? = s(i), and S? ? S;
3. D(??) ? s(D(?)).
Proposition 2. For every tuple (?,?, g,?) that
satisfies some RMRS ?, there is a solved form ??
of ? such that (?,?, g,?) also satisfies ??.
Proof. We construct the substitution s from ? and
g. Then we add all dominance atoms that are satis-
fied by ? and restrict the ARG atoms to those child
indices that are actually used in ? . The result is in
solved form because ? is a tree; it is a solved form
of ? by construction.
Proposition 3. Every RMRS ? has only a finite
number of solved forms, up to renaming of vari-
ables.
Proof. Up to renaming of variables, there is only a
finite number of substitutions on the node and base
variables of ?. Let s be such a substitution. This
fixes the set of EPs of any solved form of ? that is
based on s uniquely. There is only a finite set of
choices for the subsets S? in condition 2 of Def. 7,
and there is only a finite set of choices of new dom-
inance atoms that satisfy condition 3. Therefore,
the set of solved forms of ? is finite.
456
Let?s look at an example for all these defini-
tions. All the RMRSs presented in Section 2 (re-
placing =q by !?) are in solved form; this is least
obvious for (6), but becomes clear once we notice
that no label is on the right-hand side of two dom-
inance atoms. However, the model constructed in
the proof of Prop. 1 looks a bit like Fig. 2; both
models are problematic in several ways and in par-
ticular contain an unbound variable y even though
they also contains a quantifier that binds y. If we
restrict the class of models to those in which such
variables are bound (as Copestake et al (2005)
do), we can enforce that the quantifiers outscope
their bound variables without changing models of
the RMRS further?i.e., we add the atoms h3!? l5
and h8!? l5. Fig. 2 is no longer a model for the ex-
tended RMRS, which in turn is no longer in solved
form because the label l5 is on the right-hand side
of two dominance atoms. Instead, it has the fol-
lowing two solved forms:
(7) l1:a1: every q 1(x1),
RSTR(a1, h2), BODY(a1, h3),
l41:a41: fat j 1(e?),ARG1(a41, x1),
l41:a42: cat n 1(x1),
l6:a6: some q 1(x6),
RSTR(a6, h7), BODY(a6, h8),
l9:a9: dog n 1(x6),
l5:a5: chase v 1(e),
ARG1(a5, x1), ARG2(a5, x6),
h2 !? l41, h3 !? l6, h7 !? l9, h8 !? l5
(8) l1:a1: every q 1(x1),
RSTR(a1, h2), BODY(a1, h3),
l41:a41: fat j 1(e?),ARG1(a41, x1),
l41:a42: cat n 1(x1),
l6:a6: some q 1(x6),
RSTR(a6, h7), BODY(a6, h8),
l9:a9: dog n 1(x6),
l5:a5: chase v 1(e),
ARG1(a5, x1), ARG2(a5, x6),
h2 !? l41, h3 !? l5, h7 !? l9, h8 !? l1
Notice that we have eliminated all equalities by
unifying the variable names, and we have fixed the
relative scope of the two quantifiers. Each of these
solved forms now stands for a separate class of
models; for instance, the first model in Fig. 1 is
a model of (7), whereas the second is a model of
(8).
3.4 Extensions
So far we have based the syntax and semantics of
RMRS on the dominance relation from Egg et al
(2001) rather than the qeq relation from Copestake
et al (2005). This is partly because dominance is
the weaker relation: If a dependency parser links a
determiner to a noun and this noun to a verb, then
we can use dominance but not qeq to represent that
the predicate introduced by the verb is outscoped
by the quantifier introduced by the determiner (see
earlier discussion). However, it is very straightfor-
ward to extend the syntax and semantics of the lan-
guage to include the qeq relation. This extension
adds a new atom X =q Y to Def. 1, and ?,?, g,?
will satisfy X =q Y iff ?(X)!??(Y ), each node
on the path is a quantifier, and each step in the path
goes to the rightmost child. All the above proposi-
tions about solved forms still hold if ?dominance?
is replaced with ?qeq?.
Furthermore, grammar developers such as those
in the DELPH-IN community typically adopt con-
ventions that restrict them to a fragment of the lan-
guage from Def. 1 (once qeq is added to it), or they
restrict attention to only a subset of the models
(e.g., ones with correctly bound variables, or ones
which don?t contain extra material like Fig. 2).
Our formalism provides a general framework into
which all these various fragments fit, and it?s a
matter of future work to explore these fragments
further.
Another feature of the existing RMRS literature
is that each term of an RMRS is equipped with a
sort. In particular, individual variables x, event
variables e and holes h are arranged together with
their subsorts (e.g., epast) and supersorts (e.g.,
sort i abstracts over x and e) into a sort hierar-
chy S. For simplicity we defined RMRS without
sorts, but it is straightforward to add them. For
this, one assumes that the signature? is sorted, i.e.
assigns a sort s1 ? . . . sn ? s to each constructor,
where n is the constructor?s arity (possibly zero)
and s, s1, . . . , sn ? S are atomic sorts. We restrict
the models of RMRS to trees that are well-sorted in
the usual sense, i.e. those in which we can infer a
sort for each subtree, and require that the variable
assignment functions likewise respect the sorts. If
we then modify Def. 6 such that the constructor p
of sufficiently high arity is also consistent with the
sorts of the known arguments?i.e., if p has sort
s1? . . .? sn ? s and the RMRS contains an atom
ARG{k}(Y, i) and i is of sort s?, then s? is a sub-
sort of sk?all the above propositions about solved
forms remain true.
457
4 Future work
The above definitions serve an important theoret-
ical purpose: they formally underpin the use of
RMRS in practical systems. Next to the peace of
mind that comes with the use of a well-understood
formalism, we hope that the work reported here
will serve as a starting point for future research.
One direction to pursue from this paper is the
development of efficient solvers for RMRS. As a
first step, it would be interesting to define a practi-
cally useful fragment of RMRS with polynomial-
time satisfiability. Our definition is sufficiently
close to that of dominance constraints that we ex-
pect that it should be feasible to carry over the def-
inition of normal dominance constraints (Althaus
et al, 2003) to RMRS; neither the lexical ambigu-
ity of the node labels nor the separate specification
of predicates and arguments should make satisfia-
bility harder.
Furthermore, the above definition of RMRS pro-
vides new concepts which can help us phrase ques-
tions of practical grammar engineering in well-
defined formal terms. For instance, one crucial is-
sue in developing a hybrid system that combines
or compares the outputs of deep and shallow pro-
cessors is to determine whether the RMRSs pro-
duced by the two systems are compatible. In the
new formal terms, we can characterise compati-
bility of a more detailed RMRS ? (perhaps from a
deep grammar) and a less detailed RMRS ?? sim-
ply as entailment ? |= ??. If entailment holds,
this tells us that all claims that ?? makes about the
semantic content of a sentence are consistent with
the claims that ? makes.
At this point, we cannot provide an efficient al-
gorithm for testing entailment of RMRS. However,
we propose the following novel syntactic charac-
terisation as a starting point for research along
those lines. We call an RMRS ?? an extension of
the RMRS ? if ?? contains all the EPs of ? and
D(??) ? D(?).
Proposition 4. Let ?,?? be two RMRSs. Then
? |= ?? iff for every solved form S of ?, there is a
solved form S? of ?? such that S is an extension of
S?.
Proof (sketch). ??? follows from Props. 1 and 2.
???: We construct a solved form for ?? by
choosing a solved form for ? and appropriate sub-
stitutions for mapping the variables of ? and ??
onto each other, and removing all atoms using
variables that don?t occur in ?? . The hard part
is the proof that the result is a solved form of ??;
this step involves proving that if ? |= ?? with the
same variable assignments, then all EPs in ?? also
occur in ?.
5 Conclusion
In this paper, we motivated and defined RMRS?a
semantic framework that has been used to repre-
sent, compare, and combine semantic information
computed from deep and shallow parsers. RMRS
is designed to be maximally flexible on the type
of semantic information that can be left under-
specified, so that the semantic output of a shallow
parser needn?t over-determine or under-determine
the semantics that can be extracted from the shal-
low syntactic analysis. Our key contribution was
to lay the formal foundations for a formalism that
is emerging as a standard in robust semantic pro-
cessing.
Although we have not directly provided new
tools for modelling or processing language, we
believe that a cleanly defined model theory for
RMRS is a crucial prerequisite for the future de-
velopment of such tools; this strategy was highly
successful for dominance constraints (Althaus et
al., 2003). We hope that future research will build
upon this paper to develop efficient algorithms and
implementations for solving RMRSs, performing
inferences that enrich RMRSs from shallow analy-
ses with deeper information, and checking consis-
tency of RMRSs that were obtained from different
parsers.
Acknowledgments. We thank Ann Copestake,
Dan Flickinger, and Stefan Thater for extremely
fruitful discussions and the reviewers for their
comments. The work of Alexander Koller was
funded by a DFG Research Fellowship and the
Cluster of Excellence ?Multimodal Computing
and Interaction?.
References
S. Abney. 1996. Partial parsing via finite-state cas-
cades. In John Carroll, editor, Workshop on Robust
Parsing (ESSLLI-96), pages 8?15, Prague.
E. Althaus, D. Duchier, A. Koller, K. Mehlhorn,
J. Niehren, and S. Thiel. 2003. An efficient graph
algorithm for dominance constraints. J. Algorithms,
48:194?219.
458
J. Bos, S. Clark, M. Steedman, J. Curran, and J. Hock-
enmaier. 2004. Wide coverage semantic representa-
tions from a CCG parser. In Proceedings of the Inter-
national Conference on Computational Linguistics
(COLING 2004), Geneva, Switzerland.
E.J. Briscoe, J. Carroll, and R. Watson. 2006. The
second release of the rasp system. In Proceedings
of the COLING/ACL 2006 Interaction Presentation
Sessions, Sydney, Australia.
M. Butt, T. Holloway King, M. Nin?o, and F. Segond.
1999. A Grammar Writer?s Cookbook. CSLI Publi-
cations.
S. Clark, M. Steedman, and J. Curran. 2004. Object
extraction and question parsing using CCG. In Pro-
ceedings from the Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
111?118, Barcelona.
A. Copestake and D. Flickinger. 2000. An open-
source grammar development environment and en-
glish grammar using HPSG. In Proceedings of
the Second Conference on Language Resources and
Evaluation (LREC 2000), pages 591?600, Athens.
A. Copestake, D. Flickinger, I. Sag, and C. Pollard.
2005. Minimal recursion semantics: An introduc-
tion. Research on Language and Computation, 3(2?
3):281?332.
A. Copestake. 2003. Report on the design of RMRS.
Technical Report EU Deliverable for Project num-
ber IST-2001-37836, WP1a, Computer Laboratory,
University of Cambridge.
A. Copestake. 2007a. Applying robust semantics.
In Proceedings of the 10th Conference of the Pa-
cific Assocation for Computational Linguistics (PA-
CLING), pages 1?12, Melbourne. Invited talk.
A. Copestake. 2007b. Semantic composition with
(robust) minimal recursion semantics. In ACL-07
workshop on Deep Linguistic Processing, pages 73?
80, Prague.
D. Duchier and J. Niehren. 2000. Dominance con-
straints with set operators. In In Proceedings of the
First International Conference on Computational
Logic (CL2000), LNCS, pages 326?341. Springer.
M. Egg, A. Koller, and J. Niehren. 2001. The con-
straint language for lambda structures. Journal of
Logic, Language, and Information, 10:457?485.
A. Frank. 2004. Constraint-based RMRS construc-
tion from shallow grammars. In Proceedings of the
International Conference in Computational Linguis-
tics (COLING 2004), Geneva, Switzerland.
L. Zettlemoyer and M. Collins. 2007. Online learn-
ing of relaxed CCG grammars for parsing to log-
ical form. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL), pages 678?687.
459
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 460?468,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Dependency trees and the strong generative capacity of CCG
Alexander Koller
Saarland University
Saarbr?cken, Germany
koller@mmci.uni-saarland.de
Marco Kuhlmann
Uppsala University
Uppsala, Sweden
marco.kuhlmann@lingfil.uu.se
Abstract
We propose a novel algorithm for extract-
ing dependencies from the derivations of
a large fragment of CCG. Unlike earlier
proposals, our dependency structures are
always tree-shaped. We then use these de-
pendency trees to compare the strong gen-
erative capacities of CCG and TAG and
obtain surprising results: Both formalisms
generate the same languages of derivation
trees ? but the mechanisms they use to
bring the words in these trees into a linear
order are incomparable.
1 Introduction
Combinatory Categorial Grammar (CCG; Steed-
man (2001)) is an increasingly popular grammar
formalism. Next to being theoretically well-mo-
tivated due to its links to combinatory logic and
categorial grammar, it is distinguished by the avail-
ability of efficient open-source parsers (Clark and
Curran, 2007), annotated corpora (Hockenmaier
and Steedman, 2007; Hockenmaier, 2006), and
mechanisms for wide-coverage semantic construc-
tion (Bos et al, 2004).
However, there are limits to our understanding
of the formal properties of CCG and its relation
to other grammar formalisms. In particular, while
it is well-known that CCG belongs to a family of
mildly context-sensitive formalisms that all gener-
ate the same string languages (Vijay-Shanker and
Weir, 1994), there are few results about the strong
generative capacity of CCG. This makes it difficult
to gauge the similarities and differences between
CCG and other formalisms in how they model lin-
guistic phenomena such as scrambling and relat-
ive clauses (Hockenmaier and Young, 2008), and
hampers the transfer of algorithms from one form-
alism to another.
In this paper, we propose a new method for deriv-
ing a dependency tree from a CCG derivation tree
for PF-CCG, a large fragment of CCG. We then
explore the strong generative capacity of PF-CCG
in terms of dependency trees. In particular, we cast
new light on the relationship between CCG and
other mildly context-sensitive formalisms such as
Tree-Adjoining Grammar (TAG; Joshi and Schabes
(1997)) and Linear Context-Free Rewrite Systems
(LCFRS; Vijay-Shanker et al (1987)). We show
that if we only look at valencies and ignore word
order, then the dependency trees induced by a PF-
CCG grammar form a regular tree language, just
as for TAG and LCFRS. To our knowledge, this is
the first time that the regularity of CCG?s deriva-
tional structures has been exposed. However, if we
take the word order into account, then the classes
of PF-CCG-induced and TAG-induced dependency
trees are incomparable; in particular, CCG-induced
dependency trees can be unboundedly non-project-
ive in a way that TAG-induced dependency trees
cannot.
The fact that all our dependency structures are
trees brings our approach in line with the emerging
mainstream in dependency parsing (McDonald et
al., 2005; Nivre et al, 2007) and TAG derivation
trees. The price we pay for restricting ourselves to
trees is that we derive fewer dependencies than the
more powerful approach by Clark et al (2002). In-
deed, we do not claim that our dependencies are lin-
guistically meaningful beyond recording the way in
which syntactic valencies are filled. However, we
show that our dependency trees are still informative
enough to reconstruct the semantic representations.
The paper is structured as follows. In Section 2,
we introduce CCG and the fragment PF-CCG that
we consider in this paper, and compare our contri-
bution to earlier research. In Section 3, we then
show how to read off a dependency tree from a
CCG derivation. Finally, we explore the strong
generative capacity of CCG in Section 4 and con-
clude with ideas for future work.
460
mer
np : we?
L
em Hans
np : Hans?
L
es huus
np : house?
L
h?lfed
((s\np)\np)/vp : help?
L
aastriche
vp\np : paint?
L
((s\np)\np)\np : ?x. help?(paint?(x))
F
(s\np)\np : help? (paint?(house?))
B
s\np : help? (paint?(house?)) Hans?
B
s : help? (paint?(house?)) Hans? we?
B
Figure 1: A PF-CCG derivation
2 Combinatory Categorial Grammars
We start by introducing the Combinatory Categorial
Grammar (CCG) formalism. Then we introduce
the fragment of CCG that we consider in this paper,
and discuss some related work.
2.1 CCG
Combinatory Categorial Grammar (Steedman,
2001) is a grammar formalism that assigns categor-
ies to substrings of an input sentence. There are
atomic categories such as s and np; and if A and B
are categories, then A\B and A/B are functional
categories representing a constituent that will have
category A once it is combined with another con-
stituent of type B to the left or right, respectively.
Each word is assigned a category by the lexicon;
adjacent substrings can then be combined by com-
binatory rules. As an example, Steedman and Bald-
ridge?s (2009) analysis of Shieber?s (1985) Swiss
German subordinate clause (das) mer em Hans es
huus h?lfed aastriiche (?(that) we help Hans paint
the house?) is shown in Figure 1.
Intuitively, the arguments of a functional cat-
egory can be thought of as the syntactic valencies
of the lexicon entry, or as arguments of a func-
tion that maps categories to categories. The core
combinatory mechanism underlying CCG is the
composition and application of these functions. In
their most general forms, the combinatory rules of
(forward and backward) application and compos-
ition can be written as in Figure 2. The symbol |
stands for an arbitrary (forward or backward) slash;
it is understood that the slash before each Bi above
the line is the same as below. The rules derive state-
ments about triples w ` A : f , expressing that the
substring w can be assigned the category A and the
semantic representation f ; an entire string counts
as grammatical if it can be assigned the start cat-
egory s. In parallel to the combination of substrings
by the combinatory rules, their semantic represent-
ations are combined by functional composition.
We have presented the composition rules of CCG
in their most general form. In the literature, the
special cases for n = 0 are called forward and
backward application; the cases for n > 0 where
the slash before Bn is the same as the slash be-
fore B are called composition of degree n; and
the cases where n > 0 and the slashes have dif-
ferent directions are called crossed composition of
degree n. For instance, the F application that com-
bines h?lfed and aastriche in Figure 1 is a forward
crossed composition of degree 1.
2.2 PF-CCG
In addition to the composition rules introduced
above, CCG also allows rules of substitution and
type-raising. Substitution is used to handle syn-
tactic phenomena such as parasitic gaps; type-rais-
ing allows a constituent to serve syntactically as a
functor, while being used semantically as an argu-
ment. Furthermore, it is possible in CCG to restrict
the instances of the rule schemata in Figure 2?for
instance, to say that the application rule may only
be used for the case A = s. We call a CCG gram-
mar pure if it does not use substitution, type-raising,
or restricted rule schemata. Finally, the argument
categories of a CCG category may themselves be
functional categories; for instance, the category of
a VP modifier like passionately is (s\np)\(s\np).
We call a category that is either atomic or only has
atomic arguments a first-order category, and call a
CCG grammar first-order if all categories that its
lexicon assigns to words are first-order.
In this paper, we only consider CCG grammars
that are pure and first-order. This fragment, which
we call PF-CCG, is less expressive than full CCG,
but it significantly simplifies the definitions in Sec-
tion 3. At the same time, many real-world CCG
grammars do not use the substitution rule, and type-
raising can be compiled into the grammar in the
sense that for any CCG grammar, there is an equi-
valent CCG grammar that does not use type-raising
and assigns the same semantic representations to
461
(a,A, f) is a lexical entry
a ` A : f
L
v ` A/B : ?x. f(x) w ` B |Bn | . . . |B1 : ?y1, . . . , yn. g(y1, . . . , yn)
vw ` A |Bn | . . . |B1 : ?y1, . . . , yn. f(g(y1, . . . , yn))
F
v ` B |Bn | . . . |B1 : ?y1, . . . , yn. g(y1, . . . , yn) w ` A\B : ?x. f(x)
vw ` A |Bn | . . . |B1 : ?y1, . . . , yn. f(g(y1, . . . , yn))
B
Figure 2: The generalized combinatory rules of CCG
each string. On the other hand, the restriction to
first-order grammars is indeed a limitation in prac-
tice. We take the work reported here as a first step
towards a full dependency-tree analysis of CCG,
and discuss ideas for generalization in the conclu-
sion.
2.3 Related work
The main objective of this paper is the definition
of a novel way in which dependency trees can
be extracted from CCG derivations. This is sim-
ilar to Clark et al (2002), who aim at capturing
?deep? dependencies, and encode these into annot-
ated lexical categories. For instance, they write
(npi\npi)/(s\npi) for subject relative pronouns to
express that the relative pronoun, the trace of the
relative clause, and the modified noun phrase are
all semantically the same. This means that the rel-
ative pronoun has multiple parents; in general, their
dependency structures are not necessarily trees. By
contrast, we aim to extract only dependency trees,
and achieve this by recording only the fillers of syn-
tactic valencies, rather than the semantic dependen-
cies: the relative pronoun gets two dependents and
one parent (the verb whose argument the modified
np is), just as the category specifies. So Clark et
al.?s and our dependency approach represent two
alternatives of dealing with the tradeoff between
simple and expressive dependency structures.
Our paper differs from the well-known results
of Vijay-Shanker and Weir (1994) in that they es-
tablish the weak equivalence of different grammar
formalisms, while we focus on comparing the deriv-
ational structures. Hockenmaier and Young (2008)
present linguistic motivations for comparing the
strong generative capacities of CCG and TAG, and
the beginnings of a formal comparison between
CCG and spinal TAG in terms of Linear Indexed
Grammars.
3 Induction of dependency trees
We now explain how to extract a dependency tree
from a PF-CCG derivation. The basic idea is to
associate, with every step of the derivation, a cor-
responding operation on dependency trees, in much
the same way as derivation steps can be associated
with operations on semantic representations.
3.1 Dependency trees
When talking about a dependency tree, it is usually
convenient to specify its tree structure and the lin-
ear order of its nodes separately. The tree structure
encodes the valency structure of the sentence (im-
mediate dominance), whereas the linear precedence
of the words is captured by the linear order.
For the purposes of this paper, we represent a
dependency tree as a pair d = (t, s), where t is a
ground term over some suitable alphabet, and s is
a linearization of the nodes (term addresses) of t,
where by a linearization of a set S we mean a list of
elements of S in which each element occurs exactly
once (see also Kuhlmann and M?hl (2007)). As
examples, consider
(f(a, b), [1, ?, 2]) and (f(g(a)), [1 ? 1, ?, 1]) .
These expressions represent the dependency trees
d1 =
a f b
and d2 =
a f g
.
Notice that it is because of the separate specifica-
tion of the tree and the order that dependency trees
can become non-projective; d2 is an example.
A partial dependency tree is a pair (t, s) where t
is a term that may contain variables, and s is a
linearization of those nodes of t that are not labelled
with variables. We restrict ourselves to terms in
which each variable appears exactly once, and will
also prefix partial dependency trees with ?-binders
to order the variables.
462
e = (a,A |Am ? ? ? |A1) is a lexical entry
a ` A |Am ? ? ? |A1 : ?x1, . . . , xm. (e(x1, . . . , xm), [?])
L
v ` A |Am ? ? ? |A1/B : ?x, x1, . . . , xm. d w ` B |Bn ? ? ? |B1 : ?y1, . . . , yn. d
?
vw ` A |Am ? ? ? |A1 |Bn ? ? ? |B1 : ?y1, . . . , yn, x1, . . . , xm. d[x := d
? ]F
F
w ` B |Bn ? ? ? |B1 : ?y1, . . . , yn. d
? v ` A |Am ? ? ? |A1\B : ?x, x1, . . . , xm. d
wv ` A |Am ? ? ? |A1 |Bn ? ? ? |B1 : ?y1, . . . , yn, x1, . . . , xm. d[x := d
? ]B
B
Figure 3: Computing dependency trees in CCG derivations
3.2 Operations on dependency trees
Let t be a term, and let x be a variable in t. The
result of the substitution of the term t? into t for x
is denoted by t[x := t? ]. We extend this opera-
tion to dependency trees as follows. Given a list
of addresses s, let xs be the list of addresses ob-
tained from s by prefixing every address with the
address of the (unique) node that is labelled with x
in t. Then the operations of forward and backward
concatenation are defined as
(t, s)[x := (t?, s?) ]F = (t[x := t
? ], s ? xs?) ,
(t, s)[x := (t?, s?) ]B = (t[x := t
? ], xs? ? s) .
The concatenation operations combine two given
dependency trees (t, s) and (t?, s?) into a new tree
by substituting t? into t for some variable x of t,
and adding the (appropriately prefixed) list s? of
nodes of t? either before or after the list s of nodes
of t. Using these two operations, the dependency
trees d1 and d2 from above can be written as fol-
lows. Let da = (a, [?]) and db = (b, [?]).
d1 = (f(x, y), [?])[x := da ]F [ y := db ]F
d2 = (f(x), [?])[x := (g(y), [?]) ]F [ y := da ]B
Here is an alternative graphical notation for the
composition of d2:
f g
y
2
6
4 y :=
a
3
7
5
B
=
a f g
In this notation, nodes that are not marked with
variables are positioned (indicated by the dotted
projection lines), while the (dashed) variable nodes
dangle unpositioned.
3.3 Dependency trees for CCG derivations
To encode CCG derivations as dependency trees,
we annotate each composition rule of PF-CCG with
instructions for combining the partial dependency
trees for the substrings into a partial dependency
tree for the larger string. Essentially, we now com-
bine partial dependency trees using forward and
backward concatenation rather than combining se-
mantic representations by functional composition
and application. From now on, we assume that the
node labels in the dependency trees are CCG lex-
icon entries, and represent these by just the word
in them.
The modified rules are shown in Figure 3. They
derive statements about triples w ` A : p, where w
is a substring, A is a category, and p is a lambda
expression over a partial dependency tree. Each
variable of p corresponds to an argument category
in A, and vice versa. Rule L covers the base case:
the dependency tree for a lexical entry e is a tree
with one node for the item itself, labelled with e,
and one node for each of its syntactic arguments,
labelled with a variable. Rule F captures forward
composition: given two dependency trees d and d?,
the new dependency tree is obtained by forward
concatenation, binding the outermost variable in d.
Rule B is the rule for backward composition. The
result of translating a complete PF-CCG derivation
? in this way is always a dependency tree without
variables; we call it d(?).
As an example, Figure 4 shows the construc-
tion for the derivation in Figure 1. The induced
dependency tree looks like this:
mer em Hans es huus h?lfed aastriche
For instance, the partial dependency tree for the
lexicon entry of aastriiche contains two nodes: the
root (with address ?) is labelled with the lexicon
entry, and its child (address 1) is labelled with the
463
mer
(mer, [?])
L
em Hans
(Hans, [?])
L
es huus
(huus, [?])
L
h?lfed
?x, y, z. (h?lfed(x, y, z), [?])
L
aastriiche
?w. (aastriiche(w), [?])
L
?w, y, z. (h?lfed(aastriiche(w), y, z), [?, 1])
F
?y, z. (h?lfed(aastriiche(huus), y, z), [11, ?, 1])
B
?z. (h?lfed(aastriiche(huus),Hans, z), [2, 11, ?, 1])
B
(h?lfed(aastriiche(huus),Hans,mer), [3, 2, 11, ?, 1])
B
Figure 4: Computing a dependency tree for the derivation in Figure 1
variable x. This tree is inserted into the tree from
h?lfed by forward concatenation. The variable w is
passed on into the new dependency tree, and later
filled by backward concatenation to huus. Passing
the argument slot of aastriiche to h?lfed to be filled
on its left creates a non-projectivity; it corresponds
to a crossed composition in CCG terms. Notice
that the categories derived in Figure 1 mirror the
functional structure of the partial dependency trees
at each step of the derivation.
3.4 Semantic equivalence
The mapping from derivations to dependency trees
loses some information: different derivations may
induce the same dependency tree. This is illus-
trated by Figure 5, which provides two possible
derivations for the phrase big white rabbit, both
of which induce the same dependency tree. Espe-
cially in light of the fact that our dependency trees
will typically contain fewer dependencies than the
DAGs derived by Clark et al (2002), one could ask
whether dependency trees are an appropriate way
of representing the structure of a CCG derivation.
However, at the end of the day, the most import-
ant information that can be extracted from a CCG
derivation is the semantic representation it com-
putes; and it is possible to reconstruct the semantic
representation of a derivation ? from d(?) alone. If
we forget the word order information in the depend-
ency trees, the rules F and B in Figure 3 are merely
?-expanded versions of the semantic construction
rules in Figure 2. This means that d(?) records
everything we need to know about constructing the
semantic representation: We can traverse it bottom-
up and apply the lexical semantic representation
of each node to those of its subterms. So while
the dependency trees obliterate some information
in the CCG derivations (particularly its associative
structure), they are indeed appropriate represent-
ations because they record all syntactic valencies
and encode enough information to recompute the
semantics.
4 Strong generative capacity
Now that we know how to see PF-CCG derivations
as dependency trees, we can ask what sets of such
trees can be generated by PF-CCG grammars. This
is the question about the strong generative capa-
city of PF-CCG, measured in terms of dependency
trees (Miller, 2000). In this section, we give a
partial answer to this question: We show that the
sets of PF-CCG-induced valency trees (dependency
trees without their linear order) form regular tree
languages, but that the sets of dependency trees
themselves are irregular. This is in contrast to other
prominent mildly context-sensitive grammar form-
alisms such as Tree Adjoining Grammar (TAG;
Joshi and Schabes (1997)) and Linear Context-
Free Rewrite Systems (LCFRS; Vijay-Shanker et
al. (1987)), in which both languages are regular.
4.1 CCG term languages
Formally, we define the language of all dependency
trees generated by a PF-CCG grammar G as the set
LD(G) = { d(?) | ? is a derivation of G } .
Furthermore, we define the set of valency trees to
be the set of just the term parts of each d(?):
LV (G) = { t | (t, s) ? LD(G) } .
By our previous assumption, the node labels of a
valency tree are CCG lexicon entries.
We will now show that the valency tree lan-
guages of PF-CCG grammars are regular tree lan-
guages (G?cseg and Steinby, 1997). Regular tree
languages are sets of trees that can be generated
by regular tree grammars. Formally, a regular tree
grammar (RTG) is a construct ? = (N,?, S, P ),
where N is an alphabet of non-terminal symbols,
? is an alphabet of ranked term constructors called
terminal symbols, S ? N is a distinguished start
symbol, and P is a finite set of production rules of
the form A ? ?, where A ? N and ? is a term
over ? and N , where the nonterminals can be used
464
big
np/np
white
np/np
np/np
rabbit
np
np big white rabbit
big
np/np
white
np/np
rabbit
np
np/np
np
Figure 5: Different derivations may induce the same dependency tree
as constants. The grammar ? generates trees from
the start symbol by successively expanding occur-
rences of nonterminals using production rules. For
instance, the grammar that contains the productions
S ? f(A,A), A ? g(A), and A ? a generates
the tree language { f(gm(a), gn(a)) | m,n ? 0 }.
We now construct an RTG ? (G) that generates
the set of valency trees of a PF-CCG G. For the
terminal alphabet, we choose the lexicon entries:
If e = (a,A | B1 . . . | Bn, f) is a lexicon entry of
G, we take e as an n-ary term constructor. We also
take the atomic categories of G as our nonterminal
symbols; the start category s of G counts as the
start symbol. Finally, we encode each lexicon entry
as a production rule: The lexicon entry e above
encodes to the rule A? e(Bn, . . . , B1).
Let us look at our running example to see how
this works. Representing the lexicon entries as just
the words for brevity, we can write the valency tree
corresponding to the CCG derivation in Figure 4
as t0 = h?lfed(aastriiche(huus),Hans,mer); here
h?lfed is a ternary constructor, aastriiche is unary,
and all others are constants. Taking the lexical
categories into account, we obtain the RTG with
s? h?lfed(vp, np, np)
vp? aastriiche(np)
np? huus | Hans | mer
This grammar indeed generates t0, and all other
valency trees induced by the sample grammar.
More generally, LV (G) ? L(? (G)) because
the construction rules in Figure 3 ensure that if
a node v becomes the i-th child of a node u in
the term, then the result category of v?s lexicon
entry equals the i-th argument category of u?s lex-
icon entry. This guarantees that the i-th nonter-
minal child introduced by the production for u can
be expanded by the production for v. The con-
verse inclusion can be shown by reconstructing,
for each valency tree t, a CCG derivation ? that
induces t. This construction can be done by ar-
ranging the nodes in t into an order that allows
us to combine every parent in t with its children
using only forward and backward application. The
CCG derivation we obtain for the example is shown
in Figure 6; it is a derivation for the sentence
das mer em Hans h?lfed es huus aastriiche, using
the same lexicon entries. Together, this shows that
L(? (G)) = LV (G). Thus:
Theorem 1 The sets of valency trees generated by
PF-CCG are regular tree languages. 2
By this result, CCG falls in line with context-free
grammars, TAG, and LCFRS, whose sets of deriva-
tional structures are all regular (Vijay-Shanker et
al., 1987). To our knowledge, this is the first time
the regular structure of CCG derivations has been
exposed. It is important to note that while CCG
derivations themselves can be seen as trees as well,
they do not always form regular tree languages
(Vijay-Shanker et al, 1987). Consider for instance
the CCG grammar from Vijay-Shanker and Weir?s
(1994) Example 2.4, which generates the string lan-
guage anbncndn; Figure 7 shows the derivation of
aabbccdd. If we follow this derivation bottom-up,
starting at the first c, the intermediate categories
collect an increasingly long tail of\a arguments; for
longer words from the language, this tail becomes
as long as the number of cs in the string. The in-
finite set of categories this produces translates into
the need for an infinite nonterminal alphabet in an
RTG, which is of course not allowed.
4.2 Comparison with TAG
If we now compare PF-CCG to its most promin-
ent mildly context-sensitive cousin, TAG, the reg-
ularity result above paints a suggestive picture: A
PF-CCG valency tree assigns a lexicon entry to
each word and says which other lexicon entry fills
each syntactic valency. In this respect, it is the
analogue of a TAG derivation tree (in which the
lexicon entries are elementary trees), and we just
saw that PF-CCG and TAG generate the same tree
languages. On the other hand, CCG and TAG are
weakly equivalent (Vijay-Shanker and Weir, 1994),
i.e. they generate the same linear word orders. So
one could expect that CCG and TAG also induce
the same dependency trees. Interestingly, this is
not the case.
465
mer
np
L
em Hans
np
L
h?lfed
s\np\np/vp
L
es huus
np
L
aastriiche
vp\np
L
vp
B
s\np\np
F
s\np
B
s
B
Figure 6: CCG derivation reconstructed from the dependency tree from Figure 4 using only applications
We know from the literature that those depend-
ency trees that can be constructed from TAG deriva-
tion trees are exactly those that are well-nested and
have a block-degree of at most 2 (Kuhlmann and
M?hl, 2007). The block-degree of a node u in a de-
pendency tree is the number of ?blocks? into which
the subtree below u is separated by intervening
nodes that are not below u, and the block-degree
of a dependency tree is the maximum block-degree
of its nodes. So for instance, the dependency tree
on the right-hand side of Figure 8 has block-degree
two. It is also well-nested, and can therefore be
induced by TAG derivations.
Things are different for the dependency trees that
can be induced by PF-CCG. Consider the left-hand
dependency tree in Figure 8, which is induced by
a PF-CCG derivation built from words with the
lexical categories a/a, b\a, b\b, and a. While
this dependency tree is well-nested, it has block-
degree three: The subtree below the leftmost node
consists of three parts. More generally, we can in-
sert more words with the categories a/a and b\b
in the middle of the sentence to obtain depend-
ency trees with arbitrarily high block-degrees from
this grammar. This means that unlike for TAG-
induced dependency trees, there is no upper bound
on the block-degree of dependency trees induced
by PF-CCG?as a consequence, there are CCG
dependency trees that cannot be induced by TAG.
On the other hand, there are also dependency
trees that can be induced by TAG, but not by PF-
CCG. The tree on the right-hand side of Figure 8
is an example. We have already argued that this
tree can be induced by a TAG. However, it con-
tains no two adjacent nodes that are connected by
a/a b\a a/a b\b a b\b 1 2 3 4
Figure 8: The divergence between CCG and TAG
an edge; and every nontrivial PF-CCG derivation
must combine two adjacent words at least at one
point during the derivation. Therefore, the tree
cannot be induced by a PF-CCG grammar. Further-
more, it is known that all dependency languages
that can be generated by TAG or even, more gener-
ally, by LCRFS, are regular in the sense of Kuhl-
mann and M?hl (2007). One crucial property of
regular dependency languages is that they have a
bounded block-degree; but as we have seen, there
are PF-CCG dependency languages with unboun-
ded block-degree. Therefore there are PF-CCG
dependency languages that are not regular. Hence:
Theorem 2 The sets of dependency trees gener-
ated by PF-CCG and TAG are incomparable. 2
We believe that these results will generalize to
full CCG. While we have not yet worked out the
induction of dependency trees from full CCG, the
basic rule that CCG combines adjacent substrings
should still hold; therefore, every CCG-induced
dependency tree will contain at least one edge
between adjacent nodes. We are thus left with
a very surprising result: TAG and CCG both gener-
ate the same string languages and the same sets of
valency trees, but they use incomparable mechan-
isms for linearizing valency trees into sentences.
4.3 A note on weak generative capacity
As a final aside, we note that the construction for
extracting purely applicative derivations from the
terms described by the RTG has interesting con-
sequences for the weak generative capacity of PF-
CCG. In particular, it has the corollary that for any
PF-CCG derivation ? over a string w, there is a per-
mutation of w that can be accepted by a PF-CCG
derivation that uses only application?that is, every
string language L that can be generated by a PF-
CCG grammar has a context-free sublanguage L?
such that all words in L are permutations of words
in L?.
This means that many string languages that we
commonly associate with CCG cannot be generated
466
aa/d
L
a
a/d
L
b
b
L
b
b
L
c
s\a/t\b
L
s\a/t
B
c
t\a\b
L
s\a\a\b
F
s\a\a
B
s\a/d
B
d
d
L
s\a
F
s/d
B
d
d
L
s
F
Figure 7: The CCG derivation of aabbccdd using Example 2.4 in Vijay-Shanker and Weir (1994)
by PF-CCG. One such language is anbncndn. This
language is not itself context-free, and therefore
any PF-CCG grammar whose language contains it
also contains permutations in which the order of
the symbols is mixed up. The culprit for this among
the restrictions that distinguish PF-CCG from full
CCG seems to be that PF-CCG grammars must
allow all instances of the application rules. This
would mean that the ability of CCG to generate non-
context-free languages (also linguistically relevant
ones) hinges crucially on its ability to restrict the
allowable instances of rule schemata, for instance,
using slash types (Baldridge and Kruijff, 2003).
5 Conclusion
In this paper, we have shown how to read deriva-
tions of PF-CCG as dependency trees. Unlike pre-
vious proposals, our view on CCG dependencies
is in line with the mainstream dependency parsing
literature, which assumes tree-shaped dependency
structures; while our dependency trees are less in-
formative than the CCG derivations themselves,
they contain sufficient information to reconstruct
the semantic representation. We used our new de-
pendency view to compare the strong generative
capacity of PF-CCG with other mildly context-
sensitive grammar formalisms. It turns out that
the valency trees generated by a PF-CCG grammar
form regular tree languages, as in TAG and LCFRS;
however, unlike these formalisms, the sets of de-
pendency trees including word order are not regular,
and in particular can be more non-projective than
the other formalisms permit. Finally, we found
new formal evidence for the importance of restrict-
ing rule schemata for describing non-context-free
languages in CCG.
All these results were technically restricted to
the fragment of PF-CCG, and one focus of future
work will be to extend them to as large a fragment
of CCG as possible. In particular, we plan to extend
the lambda notation used in Figure 3 to cover type-
raising and higher-order categories. We would then
be set to compare the behavior of wide-coverage
statistical parsers for CCG with statistical depend-
ency parsers.
We anticipate that our results about the strong
generative capacity of PF-CCG will be useful to
transfer algorithms and linguistic insights between
formalisms. For instance, the CRISP generation
algorithm (Koller and Stone, 2007), while specified
for TAG, could be generalized to arbitrary gram-
mar formalisms that use regular tree languages?
given our results, to CCG in particular. On the
other hand, we find it striking that CCG and TAG
generate the same string languages from the same
tree languages by incomparable mechanisms for
ordering the words in the tree. Indeed, the exact
characterization of the class of CCG-inducable de-
pendency languages is an open issue. This also
has consequences for parsing complexity: We can
understand why TAG and LCFRS can be parsed in
polynomial time from the bounded block-degree
of their dependency trees (Kuhlmann and M?hl,
2007), but CCG can be parsed in polynomial time
(Vijay-Shanker and Weir, 1990) without being re-
stricted in this way. This constitutes a most inter-
esting avenue of future research that is opened up
by our results.
Acknowledgments. We thank Mark Steedman,
Jason Baldridge, and Julia Hockenmaier for valu-
able discussions about CCG, and the reviewers for
their comments. The work of Alexander Koller
was funded by a DFG Research Fellowship and the
Cluster of Excellence ?Multimodal Computing and
Interaction?. The work of Marco Kuhlmann was
funded by the Swedish Research Council.
467
References
Jason Baldridge and Geert-Jan M. Kruijff. 2003.
Multi-modal Combinatory Categorial Grammar. In
Proceedings of the Tenth EACL, Budapest, Hungary.
Johan Bos, Stephen Clark, Mark Steedman, James R.
Curran, and Julia Hockenmaier. 2004. Wide-
coverage semantic representations from a CCG
parser. In Proceedings of the 20th COLING, Geneva,
Switzerland.
Stephen Clark and James Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4).
Stephen Clark, Julia Hockenmaier, and Mark Steed-
man. 2002. Building deep dependency structures
with a wide-coverage CCG parser. In Proceedings
of the 40th ACL, Philadelphia, USA.
Ferenc G?cseg and Magnus Steinby. 1997. Tree lan-
guages. In Rozenberg and Salomaa (Rozenberg and
Salomaa, 1997), pages 1?68.
Julia Hockenmaier and Mark Steedman. 2007. CCG-
bank: a corpus of CCG derivations and dependency
structures extracted from the Penn Treebank. Com-
putational Linguistics, 33(3):355?396.
Julia Hockenmaier and Peter Young. 2008. Non-local
scrambling: the equivalence of TAG and CCG re-
visited. In Proceedings of TAG+9, T?bingen, Ger-
many.
Julia Hockenmaier. 2006. Creating a CCGbank and
a wide-coverage CCG lexicon for German. In Pro-
ceedings of COLING/ACL, Sydney, Australia.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
Adjoining Grammars. In Rozenberg and Salomaa
(Rozenberg and Salomaa, 1997), pages 69?123.
Alexander Koller and Matthew Stone. 2007. Sentence
generation as planning. In Proceedings of the 45th
ACL, Prague, Czech Republic.
Marco Kuhlmann and Mathias M?hl. 2007. Mildly
context-sensitive dependency languages. In Pro-
ceedings of the 45th ACL, Prague, Czech Republic.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of HLT/EMNLP.
Philip H. Miller. 2000. Strong Generative Capacity:
The Semantics of Linguistic Formalism. University
of Chicago Press.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, G?lsen Eryigit, Sandra K?bler, Svetoslav
Marinov, and Erwin Marsi. 2007. MaltParser:
A language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13(2):95?135.
Grzegorz Rozenberg and Arto Salomaa, editors. 1997.
Handbook of Formal Languages. Springer.
Stuart Shieber. 1985. Evidence against the context-
freeness of natural language. Linguistics and Philo-
sophy, 8:333?343.
Mark Steedman and Jason Baldridge. 2009. Combin-
atory categorial grammar. In R. Borsley and K. Bor-
jars, editors, Non-Transformational Syntax. Black-
well. To appear.
Mark Steedman. 2001. The Syntactic Process. MIT
Press.
K. Vijay-Shanker and David Weir. 1990. Polynomial
time parsing of combinatory categorial grammars.
In Proceedings of the 28th ACL, Pittsburgh, USA.
K. Vijay-Shanker and David J. Weir. 1994. The equi-
valence of four extensions of context-free grammars.
Mathematical Systems Theory, 27(6):511?546.
K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi.
1987. Characterizing structural descriptions pro-
duced by various grammatical formalisms. In Pro-
ceedings of the 25th ACL, Stanford, CA, USA.
468
A Polynomial-Time Fragment of Dominance Constraints
Alexander Koller Kurt Mehlhorn? Joachim Niehren
koller@coli.uni-sb.de mehlhorn@mpi-sb.mpg.de niehren@ps.uni-sb.de
University of the Saarland / ?Max-Planck-Institute for Computer Science
Saarbru?cken, Germany
Abstract
Dominance constraints are logical
descriptions of trees that are widely
used in computational linguistics.
Their general satisfiability problem
is known to be NP-complete. Here
we identify the natural fragment of
normal dominance constraints and
show that its satisfiability problem
is in deterministic polynomial time.
1 Introduction
Dominance constraints are used as partial
descriptions of trees in problems through-
out computational linguistics. They have
been applied to incremental parsing (Mar-
cus et al, 1983), grammar formalisms (Vijay-
Shanker, 1992; Rambow et al, 1995; Duchier
and Thater, 1999; Perrier, 2000), discourse
(Gardent and Webber, 1998), and scope un-
derspecification (Muskens, 1995; Egg et al,
1998).
Logical properties of dominance constraints
have been studied e.g. in (Backofen et al,
1995), and computational properties have
been addressed in (Rogers and Vijay-Shanker,
1994; Duchier and Gardent, 1999). Here, the
two most important operations are satisfia-
bility testing ? does the constraint describe a
tree? ? and enumerating solutions, i.e. the
described trees. Unfortunately, even the sat-
isfiability problem has been shown to be NP-
complete (Koller et al, 1998). This has shed
doubt on their practical usefulness.
In this paper, we define normal domi-
nance constraints, a natural fragment of dom-
inance constraints whose restrictions should
be unproblematic for many applications. We
present a graph algorithm that decides sat-
isfiability of normal dominance constraints
in polynomial time. Then we show how to
use this algorithm to enumerate solutions ef-
ficiently.
An example for an application of normal
dominance constraints is scope underspecifi-
cation: Constraints as in Fig. 1 can serve
as underspecified descriptions of the semantic
readings of sentences such as (1), considered
as the structural trees of the first-order rep-
resentations. The dotted lines signify domi-
nance relations, which require the upper node
to be an ancestor of the lower one in any tree
that fits the description.
(1) Some representative of every
department in all companies saw a
sample of each product.
The sentence has 42 readings (Hobbs and
Shieber, 1987), and it is easy to imagine
how the number of readings grows exponen-
tially (or worse) in the length of the sen-
tence. Efficient enumeration of readings from
the description is a longstanding problem in
scope underspecification. Our polynomial
algorithm solves this problem. Moreover,
the investigation of graph problems that are
closely related to normal constraints allows us
to prove that many other underspecification
formalisms ? e.g. Minimal Recursion Seman-
tics (Copestake et al, 1997) and Hole Seman-
tics (Bos, 1996) ? have NP-hard satisfiability
problems. Our algorithm can still be used as
a preprocessing step for these approaches; in
fact, experience shows that it seems to solve
all encodings of descriptions in Hole Seman-
tics that actually occur.
?u ?
? ?
comp ?
u ?
?
?w ?
? ?
? ?
? dept ?
w ?
?
?x ?
? ?
? ?
? repr ?
x ?
?
?y ?
? ?
? ? ?
spl ?
y ?
?
?z ?
? ?
prod ?
z ?
?
in ?
w ? u ?
of ?
x ? w ?
see ?
x ? y ?
of ?
y ? z ?
Fig. 1: A dominance constraint (from scope underspecification).
2 Dominance Constraints
In this section, we define the syntax and se-
mantics of dominance constraints. The vari-
ant of dominance constraints we employ de-
scribes constructor trees ? ground terms over
a signature of function symbols ? rather than
feature trees.
f ?
g ?
a ? a ?
Fig. 2: f(g(a, a))
So we assume a signa-
ture ? function symbols
ranged over by f, g, . . .,
each of which is equipped
with an arity ar(f) ?
0. Constants ? function
symbols of arity 0 ? are ranged over by a, b.
We assume that ? contains at least one con-
stant and one symbol of arity at least 2.
Finally, let Vars be an infinite set of vari-
ables ranged over by X,Y,Z. The variables
will denote nodes of a constructor tree. We
will consider constructor trees as directed la-
beled graphs; for instance, the ground term
f(g(a, a)) can be seen as the graph in Fig. 2.
We define an (unlabeled) tree to be a fi-
nite directed graph (V,E). V is a finite set of
nodes ranged over by u, v, w, and E ? V ? V
is a set of edges denoted by e. The indegree of
each node is at most 1; each tree has exactly
one root, i.e. a node with indegree 0. We call
the nodes with outdegree 0 the leaves of the
tree.
A (finite) constructor tree ? is a pair (T,L)
consisting of a tree T = (V,E), a node labeling
L : V ? ?, and an edge labeling L : E ?
N, such that for each node u ? V and each
1 ? k ? ar(L(u)), there is exactly one edge
(u, v) ? E with L((u, v)) = k.1 We draw
1The symbol L is overloaded to serve both as a
node and an edge labeling.
constructor trees as in Fig. 2, by annotating
nodes with their labels and ordering the edges
along their labels from left to right. If ? =
((V,E), L), we write V? = V , E? = E, L? =
L. Now we are ready to define tree structures,
the models of dominance constraints:
Definition 2.1. The tree structure M? of
a constructor tree ? is a first-order structure
with domain V? which provides the dominance
relation ?? and a labeling relation for each
function symbol f ? ?.
Let u, v, v1, . . . vn ? V? be nodes of ? . The
dominance relationship u??v holds iff there
is a path from u to v in E? ; the labeling rela-
tionship u:f ? (v1, . . . , vn) holds iff u is labeled
by the n-ary symbol f and has the children
v1, . . . , vn in this order; that is, L? (u) = f ,
ar(f) = n, {(u, v1), . . . , (u, vn)} ? E? , and
L? ((u, vi)) = i for all 1 ? i ? n.
A dominance constraint ? is a conjunction
of dominance, inequality, and labeling literals
of the following form where ar(f) = n:
? ::= ? ? ?? | X?Y | X 6=Y
| X:f(X1, . . . , Xn)
X 1 X 2
Y
X f
Fig. 3: An unsat-
isfiable constraint
Let Var(?) be the set of
variables of ?. A pair of
a tree structure M? and
a variable assignment ? :
Var(?) ? V? satisfies ?
iff it satisfies each literal
in the obvious way. We
say that (M? , ?) is a solution of ? in this
case; ? is satisfiable if it has a solution.
We usually draw dominance constraints as
constraint graphs. For instance, the con-
straint graph for X:f(X1, X2) ? X1?Y ?
X2?Y is shown in Fig. 3. As for trees, we
annotate node labels to nodes and order tree
edges from left to right; dominance edges are
drawn dotted. The example happens to be
unsatisfiable because trees cannot branch up-
wards.
Definition 2.2. Let ? be a dominance con-
straint that does not contain two labeling con-
straints for the same variable.2 Then the con-
straint graph for ? is a directed labeled graph
G(?) = (Var(?), E, L). It contains a (par-
tial) node labeling L : Var(?)  ? and an
edge labeling L : E ? N ? {?}.
The sets of edges E and labels L of
the graph G(?) are defined in dependence
of the literals in ?: The labeling literal
X:f(X1, . . . , Xn) belongs to ? iff L(X) = f
and for each 1 ? i ? n, (X,Xi) ? E and
L((X,Xi)) = i. The dominance literal X?Y
is in ? iff (X,Y ) ? E and L((X,Y )) = ?.
Note that inequalities in constraints are not
represented by the corresponding constraint
graph. We define (solid) fragments of a con-
straint graph to be maximal sets of nodes that
are connected over tree edges.
3 Normal Dominance Constraints
Satisfiability of dominance constraints can be
decided easily in non-deterministic polyno-
mial time; in fact, it is NP-complete (Koller
et al, 1998).
X 1 X 2
f
Y f
Y 1 Y 2
X
Fig. 4: Overlap
The NP-hardness
proof relies on the
fact that solid frag-
ments can ?overlap?
properly. For illustra-
tion, consider the con-
straint X:f(X1, X2) ?
Y :f(Y1, Y2) ? Y ?X ? X?Y1, whose con-
straint graph is shown in Fig. 4. In a solu-
tion of this constraint, either Y or Y1 must be
mapped to the same node as X; if X = Y ,
the two fragments overlap properly. In the
applications in computational linguistics, we
typically don?t want proper overlap; X should
2Every constraint can be brought into this form by
introducing auxiliary variables and expressing X=Y
as X?Y ? Y ?X.
never be identified with Y , only with Y1. The
subclass of dominance constraints that ex-
cludes proper overlap (and fixes some minor
inconveniences) is the class of normal domi-
nance constraints.
Definition 3.1. A dominance constraint ?
is called normal iff for all variables X,Y,Z ?
Var(?),
1. X 6= Y in ? iff both X:f(. . .) and
Y :g(. . .) in ?, where f and g may be
equal (no overlap);3
2. X only appears once as a parent and
once as a child in a labeling literal (tree-
shaped fragments);
3. if X?Y in ?, neither X:f(. . .) nor
Z:f(. . . Y . . .) are (dominances go from
holes to roots);
4. if X?Y in ?, then there are Z, f such
that Z:f(. . . X . . .) in ? (no empty frag-
ments).
Fragments of normal constraints are tree-
shaped, so they have a unique root and leaves.
We call unlabeled leaves holes. If X is a vari-
able, we can define R?(X) to be the root of
the fragment containing X. Note that by
Condition 1 of the definition, the constraint
graph specifies all the inequality literals in a
normal constraint. All constraint graphs in
the rest of the paper will represent normal
constraints.
The main result of this paper, which we
prove in Section 4, is that the restriction to
normal constraints indeed makes satisfiability
polynomial:
Theorem 3.2. Satisfiability of normal domi-
nance constraints is O((k+1)3n2 log n), where
n is the number of variables in the constraint,
and k is the maximum number of dominance
edges into the same node in the constraint
graph.
In the applications, k will be small ? in
scope underspecification, for instance, it is
3Allowing more inequality literals does not make
satisfiability harder, but the pathological case X 6= X
invalidates the simple graph-theoretical characteriza-
tions below.
bounded by the maximum number of argu-
ments a verb can take in the language if we
disregard VP modification. So we can say
that satisfiability of the linguistically relevant
dominance constraints is O(n2 log n).
4 A Polynomial Satisfiability Test
Now we derive the satisfiability algorithm
that proves Theorem 3.2 and prove it correct.
In Section 5, we embed it into an enumera-
tion algorithm. An alternative proof of The-
orem 3.2 is by reduction to a graph problem
discussed in (Althaus et al, 2000); this more
indirect approach is sketched in Section 6.
Throughout this section and the next, we
will employ the following non-deterministic
choice rule (Distr), where X,Y are different
variables.
(Distr) ? ? X?Z ? Y ?Z
? ? ?X?R?(Y ) ? Y ?Z
? ? ? Y ?R?(X) ? X?Z
In each application, we can pick one of the
disjuncts on the right-hand side. For instance,
we get Fig. 5b by choosing the second disjunct
in a rule application to Fig. 5a.
The rule is sound if the left-hand side is nor-
mal: X?Z ? Y ?Z entails X?Y ? Y ?X,
which entails the right-hand side disjunction
because of conditions 1, 2, 4 of normality and
X 6= Y . Furthermore, it preserves normality:
If the left-hand side is normal, so are both
possible results.
Definition 4.1. A normal dominance con-
straint ? is in solved form iff (Distr) is not
applicable to ? and G(?) is cycle-free.
Constraints in solved form are satisfiable.
4.1 Characterizing Satisfiability
In a first step, we characterize the unsatisfia-
bility of a normal constraint by the existence
of certain cycles in the undirected version of
its graph (Proposition 4.4). Recall that a cy-
cle in a graph is simple if it does not contain
the same node twice.
Definition 4.2. A cycle in an undirected
constraint graph is called hypernormal if it
does not contain two adjacent dominance
edges that emanate from the same node.
f ?
? X
g ?
? Y ?
a ? Z b ?
g ?
? Y
f ?
? X
?
a ? Z b ?
(a) (b)
Fig. 5: (a) A constraint that entails X?Y ,
and (b) the result of trying to arrange Y
above X. The cycle in (b) is hypernormal,
the one in (a) is not.
For instance, the cycle in the left-hand
graph in Fig. 5 is not hypernormal, whereas
the cycle in the right-hand one is.
Lemma 4.3. A normal dominance constraint
whose undirected graph has a simple hyper-
normal cycle is unsatisfiable.
Proof. Let ? be a normal dominance con-
straint whose undirected graph contains a
simple hypernormal cycle. Assume first that
it contains a simple hypernormal cycle C that
is also a cycle in the directed graph. There is
at least one leaf of a fragment on C; let Y
be such a leaf. Because ? is normal, Y has
a mother X via a tree edge, and X is on C
as well. That is, X must dominate Y but is
properly dominated by Y in any solution of
?, so ? is unsatisfiable.
In particular, if an undirected constraint
graph has a simple hypernormal cycle C with
only one dominance edge, C is also a directed
cycle, so the constraint is unsatisfiable. Now
we can continue inductively. Let ? be a con-
straint with an undirected simple hypernor-
mal cycle C of length l, and suppose we know
that all constraints with cycles of length less
than l are unsatisfiable. If C is a directed
cycle, we are done (see above); otherwise,
the edges in C must change directions some-
where. Because ? is normal, this means that
there must be a node Z that has two incoming
dominance edges (X,Z), (Y,Z) which are ad-
jacent edges in C. If X and Y are in the same
fragment, ? is trivially unsatisfiable. Other-
wise, let ?1 and ?2 be the two constraints ob-
tained from ? by one application of (Distr) to
X,Y,Z. Let C1 be the sequence of edges we
obtain from C by replacing the path from X
to R?(Y ) via Z by the edge (X,R?(Y )). C
is hypernormal and simple, so no two dom-
inance edges in C emanate from the same
node; hence, the new edge is the only dom-
inance edge in C1 emanating from X, and
C1 is a hypernormal cycle in the undirected
graph of ?1. C1 is still simple, as we have
only removed nodes. But the length of C1
is strictly less than l, so ?1 is unsatisfiable
by induction hypothesis. An analogous ar-
gument shows unsatisfiability of ?2. But be-
cause (Distr) is sound, this means that ? is
unsatisfiable too.
Proposition 4.4. A normal dominance con-
straint is satisfiable iff its undirected con-
straint graph has no simple hypernormal cy-
cle.
Proof. The direction that a normal constraint
with a simple hypernormal cycle is unsatisfi-
able is shown in Lemma 4.3.
For the converse, we first define an ordering
?1 ? ?2 on normal dominance constraints: it
holds if both constraints have the same vari-
ables, labeling and inequality literals, and if
the reachability relation of G(?1) is a subset
of that of G(?2). If the subset inclusion is
proper, we write ?1 < ?2. We call a con-
straint ? irredundant if there is no normal
constraint ?? with fewer dominance literals
but ? ? ??. If ? is irredundant and G(?)
is acyclic, both results of applying (Distr) to
? are strictly greater than ?.
Now let ? be a constraint whose undirected
graph has no simple hypernormal cycle. We
can assume without loss of generality that
? is irredundant; otherwise we make it irre-
dundant by removing dominance edges, which
does not introduce new hypernormal cycles.
If (Distr) is not applicable to ?, ? is in
solved form and hence satisfiable. Otherwise,
we know that both results of applying the rule
are strictly greater than ?. It can be shown
that one of the results of an application of the
distribution rule contains no simple hypernor-
mal cycle. We omit this argument for lack of
space; details can be found in the proof of
Theorem 3 in (Althaus et al, 2000). Further-
more, the maximal length of a < increasing
chain of constraints is bounded by n2, where
n is the number of variables. Thus, appli-
cations of (Distr) can only be iterated a fi-
nite number of times on constraints without
simple hypernormal cycles (given redundancy
elimination), and it follows by induction that
? is satisfiable.
4.2 Testing for Simple Hypernormal
Cycles
We can test an undirected constraint graph
for the presence of simple hypernormal cycles
by solving a perfect weighted matching prob-
lem on an auxiliary graph A(G(?)). Perfect
weighted matching in an undirected graph
G = (V,E) with edge weights is the prob-
lem of selecting a subset E ? of edges such that
each node is adjacent to exactly one edge in
E?, and the sum of the weights of the edges
in E? is maximal.
The auxiliary graph A(G(?)) we consider is
an undirected graph with two types of edges.
For every edge e = (v, w) ? G(?) we have
two nodes ev, ew in A(G(?)). The edges are
as follows:
(Type A) For every edge e in G(?) we have
the edge {ev, ew}.
(Type B) For every node v and distinct
edges e, f which are both incident to v
in G(?), we have the edge {ev, fv} if ei-
ther v is not a leaf, or if v is a leaf and
either e or f is a tree edge.
We give type A edges weight zero and type B
edges weight one. Now it can be shown (Al-
thaus et al, 2000, Lemma 2) that A(G(?))
has a perfect matching of positive weight iff
the undirected version of G(?) contains a sim-
ple hypernormal cycle. The proof is by con-
structing positive matchings from cycles, and
vice versa.
Perfect weighted matching on a graph with
n nodes and m edges can be done in time
O(nm log n) (Galil et al, 1986). The match-
ing algorithm itself is beyond the scope of
this paper; for an implementation (in C++)
see e.g. (Mehlhorn and Na?her, 1999). Now
let?s say that k is the maximum number of
dominance edges into the same node in G(?),
then A(G(?)) has O((k + 1)n) nodes and
O((k + 1)2n) edges. This shows:
Proposition 4.5. A constraint graph can be
tested for simple hypernormal cycles in time
O((k + 1)3n2 log n), where n is the number of
variables and k is the maximum number of
dominance edges into the same node.
This completes the proof of Theorem 3.2:
We can test satisfiability of a normal con-
straint by first constructing the auxiliary
graph and then solving its weighted match-
ing problem, in the time claimed.
4.3 Hypernormal Constraints
It is even easier to test the satisfiability of
a hypernormal dominance constraint ? a nor-
mal dominance constraint in whose constraint
graph no node has two outgoing dominance
edges. A simple corollary of Prop. 4.4 for this
special case is:
Corollary 4.6. A hypernormal constraint is
satisfiable iff its undirected constraint graph is
acyclic.
This means that satisfiability of hypernor-
mal constraints can be tested in linear time
by a simple depth-first search.
5 Enumerating Solutions
Now we embed the satisfiability algorithms
from the previous section into an algorithm
for enumerating the irredundant solved forms
of constraints. A solved form of the normal
constraint ? is a normal constraint ?? which
is in solved form and ? ? ??, with respect to
the ? order from the proof of Prop. 4.4.4
Irredundant solved forms of a constraint
are very similar to its solutions: Their con-
straint graphs are tree-shaped, but may still
4In the literature, solved forms with respect to the
NP saturation algorithms can contain additional la-
beling literals. Our notion of an irredundant solved
form corresponds to a minimal solved form there.
1. Check satisfiability of ?. If it is unsatis-
fiable, terminate with failure.
2. Make ? irredundant.
3. If ? is in solved form, terminate with suc-
cess.
4. Otherwise, apply the distribution rule
and repeat the algorithm for both results.
Fig. 6: Algorithm for enumerating all irre-
dundant solved forms of a normal constraint.
contain dominance edges. Every solution of
a constraint is a solution of one of its irre-
dundant solved forms. However, the number
of irredundant solved forms is always finite,
whereas the number of solutions typically is
not: X:a?Y :b is in solved form, but each so-
lution must contain an additional node with
arbitrary label that combines X and Y into a
tree (e.g. f(a, b), g(a, b)). That is, we can ex-
tract a solution from a solved form by ?adding
material? if necessary.
The main workhorse of the enumeration al-
gorithm, shown in Fig. 6, is the distribution
rule (Distr) we have introduced in Section 4.
As we have already argued, (Distr) can be ap-
plied at most n2 times. Each end result is in
solved form and irredundant. On the other
hand, distribution is an equivalence transfor-
mation, which preserves the total set of solved
forms of the constraints after the same itera-
tion. Finally, the redundancy elimination in
Step 2 can be done in time O((k+1)n2) (Aho
et al, 1972). This proves:
Theorem 5.1. The algorithm in Fig. 6 enu-
merates exactly the irredundant solved forms
of a normal dominance constraint ? in time
O((k +1)4n4N log n), where N is the number
of irredundant solved forms, n is the number
of variables, and k is the maximum number
of dominance edges into the same node.
Of course, the number of irredundant
solved forms can still be exponential in the
size of the constraint. Note that for hypernor-
mal constraints, we can replace the quadratic
satisfiability test by the linear one, and we
can skip Step 2 of the enumeration algorithm
because hypernormal constraints are always
irredundant. This improves the runtime of
enumeration to O((k + 1)n3N).
6 Reductions
Instead of proving Theorem 4.4 directly as
we have done above, we can also reduce it to
a configuration problem of dominance graphs
(Althaus et al, 2000), which provides a more
general perspective on related problems as
well. Dominance graphs are unlabeled, di-
rected graphs G = (V,E unionmulti D) with tree edges
E and dominance edges D. Nodes with no in-
coming tree edges are called roots, and nodes
with no outgoing ones are called leaves; dom-
inance edges only go from leaves to roots. A
configuration of G is a graph G? = (V,E unionmulti E?)
such that every edge in D is realized by a path
in G?. The following results are proved in (Al-
thaus et al, 2000):
1. Configurability of dominance graphs is in
O((k + 1)3n2 log n), where k is the max-
imum number of dominance edges into
the same node.
2. If we specify a subset V ? ? V of closed
leaves (we call the others open) and re-
quire that only open leaves can have
outgoing edges in E ?, the configurability
problem becomes NP-complete. (This
is shown by encoding a strongly NP-
complete partitioning problem.)
3. If we require in addition that every open
leaf has an outgoing edge in E ?, the prob-
lem stays NP-complete.
Satisfiability of normal dominance constraints
can be reduced to the first problem in the
list by deleting all labels from the constraint
graph. The reduction can be shown to be
correct by encoding models as configurations
and vice versa.
On the other hand, the third problem can
be reduced to the problems of whether there
is a plugging for a description in Hole Seman-
tics (Bos, 1996), or whether a given MRS de-
scription can be resolved (Copestake et al,
1997), or whether a given normal dominance
constraints has a constructive solution.5 This
reduction is by deleting all labels and making
leaves that had nullary labels closed. This
means that (the equivalent of) deciding satis-
fiability in these approaches is NP-hard.
The crucial difference between e.g. satisfi-
ability and constructive satisfiability of nor-
mal dominance constraints is that it is pos-
sible that a solved form has no constructive
solutions. This happens e.g. in the example
from Section 5, X:a ? Y :b. The constraint,
which is in solved form, is satisfiable e.g. by
the tree f(a, b); but every solution must con-
tain an additional node with a binary label,
and hence cannot be constructive.
For practical purposes, however, it can still
make sense to enumerate the irredundant
solved forms of a normal constraint even if we
are interested only in constructive solution:
It is certainly cheaper to try to find construc-
tive solutions of solved forms than of arbitrary
constraints. In fact, experience indicates that
for those constraints we really need in scope
underspecification, all solved forms do have
constructive solutions ? although it is not yet
known why. This means that our enumera-
tion algorithm can in practice be used without
change to enumerate constructive solutions,
and it is straightforward to adapt it e.g. to
an enumeration algorithm for Hole Semantics.
7 Conclusion
We have investigated normal dominance con-
straints, a natural subclass of general dom-
inance constraints. We have given an
O(n2 log n) satisfiability algorithm for them
and integrated it into an algorithm that enu-
merates all irredundant solved forms in time
O(Nn4 log n), where N is the number of irre-
dundant solved forms.
5A constructive solution is one where every node
in the model is the image of a variable for which
a labeling literal is in the constraint. Informally,
this means that the solution only contains ?material?
?mentioned? in the constraint.
This eliminates any doubts about the
computational practicability of dominance
constraints which were raised by the NP-
completeness result for the general language
(Koller et al, 1998) and expressed e.g. in
(Willis and Manandhar, 1999). First experi-
ments confirm the efficiency of the new algo-
rithm ? it is superior to the NP algorithms
especially on larger constraints.
On the other hand, we have argued that
the problem of finding constructive solutions
even of a normal dominance constraint is NP-
complete. This result carries over to other
underspecification formalisms, such as Hole
Semantics and MRS. In practice, however, it
seems that the enumeration algorithm pre-
sented here can be adapted to those problems.
Acknowledgments. We would like to
thank Ernst Althaus, Denys Duchier, Gert
Smolka, Sven Thiel, all members of the SFB
378 project CHORUS at the University of the
Saarland, and our reviewers. This work was
supported by the DFG in the SFB 378.
References
A. V. Aho, M. R. Garey, and J. D. Ullman. 1972.
The transitive reduction of a directed graph.
SIAM Journal of Computing, 1:131?137.
E. Althaus, D. Duchier, A. Koller, K. Mehlhorn,
J. Niehren, and S. Thiel. 2000. An ef-
ficient algorithm for the configuration
problem of dominance graphs. Submit-
ted. http://www.ps.uni-sb.de/Papers/
abstracts/dom-graph.html.
R. Backofen, J. Rogers, and K. Vijay-Shanker.
1995. A first-order axiomatization of the the-
ory of finite trees. Journal of Logic, Language,
and Information, 4:5?39.
Johan Bos. 1996. Predicate logic unplugged. In
Proceedings of the 10th Amsterdam Colloquium.
A. Copestake, D. Flickinger, and I. Sag.
1997. Minimal Recursion Semantics. An In-
troduction. Manuscript, ftp://csli-ftp.
stanford.edu/linguistics/sag/mrs.ps.gz.
Denys Duchier and Claire Gardent. 1999. A
constraint-based treatment of descriptions. In
Proceedings of IWCS-3, Tilburg.
D. Duchier and S. Thater. 1999. Parsing with
tree descriptions: a constraint-based approach.
In Proc. NLULP?99, Las Cruces, New Mexico.
M. Egg, J. Niehren, P. Ruhrberg, and F. Xu.
1998. Constraints over Lambda-Structures in
Semantic Underspecification. In Proceedings
COLING/ACL?98, Montreal.
Z. Galil, S. Micali, and H. N. Gabow. 1986. An
O(EV log V ) algorithm for finding a maximal
weighted matching in general graphs. SIAM
Journal of Computing, 15:120?130.
Claire Gardent and Bonnie Webber. 1998. De-
scribing discourse semantics. In Proceedings of
the 4th TAG+ Workshop, Philadelphia.
Jerry R. Hobbs and Stuart M. Shieber. 1987.
An algorithm for generating quantifier scopings.
Computational Linguistics, 13:47?63.
A. Koller, J. Niehren, and R. Treinen. 1998. Dom-
inance constraints: Algorithms and complexity.
In Proceedings of the 3rd LACL, Grenoble. To
appear as LNCS.
M. P. Marcus, D. Hindle, and M. M. Fleck. 1983.
D-theory: Talking about talking about trees.
In Proceedings of the 21st ACL.
K. Mehlhorn and S. Na?her. 1999. The
LEDA Platform of Combinatorial and Geomet-
ric Computing. Cambridge University Press,
Cambridge. See also http://www.mpi-sb.
mpg.de/LEDA/.
R.A. Muskens. 1995. Order-independence and
underspecification. In J. Groenendijk, editor,
Ellipsis, Underspecification, Events and More
in Dynamic Semantics. DYANA Deliverable
R.2.2.C.
Guy Perrier. 2000. From intuitionistic proof nets
to interaction grammars. In Proceedings of the
5th TAG+ Workshop, Paris.
O. Rambow, K. Vijay-Shanker, and D. Weir.
1995. D-Tree grammars. In Proceedings of the
33rd ACL, pages 151?158.
J. Rogers and K. Vijay-Shanker. 1994. Obtaining
trees from their descriptions: An application to
tree-adjoining grammars. Computational Intel-
ligence, 10:401?421.
K. Vijay-Shanker. 1992. Using descriptions of
trees in a tree adjoining grammar. Computa-
tional Linguistics, 18:481?518.
A. Willis and S. Manandhar. 1999. Two accounts
of scope availability and semantic underspecifi-
cation. In Proceedings of the 37th ACL.
Underspecified Beta Reduction
Manuel Bodirsky
Katrin Erk
Joachim Niehren
Programming Systems Lab
Saarland University
D-66041 Saarbru?cken, Germany
{bodirsky|erk|niehren}@ps.uni-sb.de
Alexander Koller
Department of Computational Linguistics
Saarland University
D-66041 Saarbru?cken, Germany
koller@coli.uni-sb.de
Abstract
For ambiguous sentences, traditional
semantics construction produces large
numbers of higher-order formulas,
which must then be
 
-reduced individ-
ually. Underspecified versions can pro-
duce compact descriptions of all read-
ings, but it is not known how to perform
 
-reduction on these descriptions. We
show how to do this using
 
-reduction
constraints in the constraint language
for  -structures (CLLS).
1 Introduction
Traditional approaches to semantics construction
(Montague, 1974; Cooper, 1983) employ formu-
las of higher-order logic to derive semantic rep-
resentations compositionally; then
 
-reduction is
applied to simplify these representations. When
the input sentence is ambiguous, these approaches
require all readings to be enumerated and
 
-
reduced individually. For large numbers of read-
ings, this is both inefficient and unelegant.
Existing underspecification approaches (Reyle,
1993; van Deemter and Peters, 1996; Pinkal,
1996; Bos, 1996) provide a partial solution to this
problem. They delay the enumeration of the read-
ings and represent them all at once in a single,
compact description. An underspecification for-
malism that is particularly well suited for describ-
ing higher-order formulas is the Constraint Lan-
guage for Lambda Structures, CLLS (Egg et al,
2001; Erk et al, 2001). CLLS descriptions can
be derived compositionally and have been used
to deal with a rich class of linguistic phenomena
(Koller et al, 2000; Koller and Niehren, 2000).
They are based on dominance constraints (Mar-
cus et al, 1983; Rambow et al, 1995) and extend
them with parallelism (Erk and Niehren, 2000)
and binding constraints.
However, lifting
 
-reduction to an operation on
underspecified descriptions is not trivial, and to
our knowledge it is not known how this can be
done. Such an operation ? which we will call un-
derspecified   -reduction ? would essentially   -
reduce all described formulas at once by deriv-
ing a description of the reduced formulas. In this
paper, we show how underspecified
 
-reductions
can be performed in the framework of CLLS.
Our approach extends the work presented in
(Bodirsky et al, 2001), which defines   -reduction
constraints and shows how to obtain a complete
solution procedure by reducing them to paral-
lelism constraints in CLLS. The problem with
this previous work is that it is often necessary to
perform local disambiguations. Here we add a
new mechanism which, for a large class of de-
scriptions, permits us to perform underspecified
 
-reduction steps without disambiguating, and is
still complete for the general problem.
Plan. We start with a few examples to show
what underspecified
 
-reduction should do, and
why it is not trivial. We then introduce CLLS
and
 
-reduction constraints. In the core of the
paper we present a procedure for underspecified
 
-reduction and apply it to illustrative examples.
2 Examples
In this section, we show what underspecified
 
-
reduction should do, and why the task is nontriv-
ial. Consider first the ambiguous sentence Every
student didn?t pay attention. In first-order logic,
the two readings can be represented as
 



	
 






 





 



ffGeneration as Dependency Parsing
Alexander Koller and Kristina Striegnitz
Dept. of Computational Linguistics, Saarland University
{koller|kris}@coli.uni-sb.de
Abstract
Natural-Language Generation from flat
semantics is an NP-complete problem.
This makes it necessary to develop al-
gorithms that run with reasonable effi-
ciency in practice despite the high worst-
case complexity. We show how to con-
vert TAG generation problems into de-
pendency parsing problems, which is use-
ful because optimizations in recent de-
pendency parsers based on constraint pro-
gramming tackle exactly the combina-
torics that make generation hard. Indeed,
initial experiments display promising run-
times.
1 Introduction
Existing algorithms for realization from a flat input
semantics all have runtimes which are exponential in
the worst case. Several different approaches to im-
proving the runtime in practice have been suggested
in the literature ? e.g. heuristics (Brew, 1992) and
factorizations into smaller exponential subproblems
(Kay, 1996; Carroll et al, 1999). While these solu-
tions achieve some measure of success in making re-
alization efficient, the contrast in efficiency to pars-
ing is striking both in theory and in practice.
The problematic runtimes of generation algo-
rithms are explained by the fact that realization is an
NP-complete problem even using just context-free
grammars, as Brew (1992) showed in the context of
shake-and-bake generation. The first contribution of
our paper is a proof of a stronger NP-completeness
result: If we allow semantic indices in the grammar,
realization is NP-complete even if we fix a single
grammar. Our alternative proof shows clearly that
the combinatorics in generation come from essen-
tially the same sources as in parsing for free word
order languages. It has been noted in the literature
that this problem, too, becomes NP-complete very
easily (Barton et al, 1987).
The main point of this paper is to show how to
encode generation with a variant of tree-adjoining
grammars (TAG) as a parsing problem with depen-
dency grammars (DG). The particular variant of DG
we use, Topological Dependency Grammar (TDG)
(Duchier, 2002; Duchier and Debusmann, 2001),
was developed specifically with efficient parsing for
free word order languages in mind. The mere exis-
tence of this encoding proves TDG?s parsing prob-
lem NP-complete as well, a result which has been
conjectured but never formally shown so far. But it
turns out that the complexities that arise in gener-
ation problems in practice seem to be precisely of
the sort that the TDG parser can handle well. Initial
experiments with generating from the XTAG gram-
mar (XTAG Research Group, 2001) suggest that our
generation system is competitive with state-of-the-
art chart generators, and indeed seems to run in poly-
nomial time in practice.
Next to the attractive runtime behaviour, our ap-
proach to realization is interesting because it may
provide us with a different angle from which to
look for tractable fragments of the general realiza-
tion problem. As we will show, the computation that
takes place in our system is very different from that
in a chart generator, and may be more efficient in
some cases by taking into account global informa-
tion to guide local choices.
Plan of the Paper. We will define the problem we
want to tackle in Section 2, and then show that it is
NP-complete (Section 3). In Section 4, we sketch
the dependency grammar formalism we use. Sec-
tion 5 is the heart of the paper: We show how to
encode TAG generation as TDG parsing, and dis-
cuss some examples and runtimes. We compare our
approach to some others in Section 6, and conclude
and discuss future research in Section 7.
                  Computational Linguistics (ACL), Philadelphia, July 2002, pp. 17-24.
                         Proceedings of the 40th Annual Meeting of the Association for
2 The Realization Problem
In this paper, we deal with the subtask of natural
language generation known as surface realization:
given a grammar and a semantic representation, the
problem is to find a sentence which is grammatical
according to the grammar and expresses the content
of the semantic representation.
We represent the semantic input as a multiset
(bag) of ground atoms of predicate logic, such
as {buy(e,a,b), name(a,mary) car(b)}. To en-
code syntactic information, we use a tree-adjoining
grammar without feature structures (Joshi and Sch-
abes, 1997). Following Stone and Doran (1997) and
Kay (1996), we enhance this TAG grammar with
a syntax-semantics interface in which nonterminal
nodes of the elementary trees are equipped with in-
dex variables, which can be bound to individuals in
the semantic input. We assume that the root node,
all substitution nodes, and all nodes that admit ad-
junction carry such index variables. We also assign
a semantics to every elementary tree, so that lexi-
cal entries are pairs of the form (?, T ), where ? is
a multiset of semantic atoms, and T is an initial or
auxiliary tree, e.g.
( {buy(x,y,z)},
S:x
NP:y  VP:x
V:x
buys
NP:z 
)
When the lexicon is accessed, x, y, z get bound
to terms occurring in the semantic input, e.g. e, a, b
in our example. Since we furthermore assume that
every index variable that appears in T also appears
in ?, this means that all indices occurring in T get
bound at this stage.
The semantics of a complex tree is the multiset
union of the semantics of the elementary trees in-
volved. Now we say that the realization problem of
a grammar G is to decide for a given input semantics
S and an index i whether there is a derivation tree
which is grammatical according to G, is assigned
the semantics S, and has a root node with index i.
3 NP-Completeness of Realization
This definition is the simplest conceivable formal-
ization of problems occurring in surface realization
as a decision problem: It does not even require us
to compute a single actual realization, just to check
?1 B:i
N:i  E:k
e
B:k 
sem: edge(i,k)
?2 C
eating C 
sem: edge(i,k)
?3 N:i
n
sem: node(i)
?4 B:1
eat C 
sem: start-eating
?5 C
ate
sem: end-eating
Figure 1: The grammar G
ham
.
whether one exists. Every practical generation sys-
tem generating from flat semantics will have to ad-
dress this problem in one form or another.
Now we show that this problem is NP-complete.
A similar result was proved in the context of shake-
and-bake generation by Brew (1992), but he needed
to use the grammar in his encoding, which leaves
the possibility open that for every single grammar
G, there might be a realization algorithm tailored
specifically to G which still runs in polynomial time.
Our result is stronger in that we define a single
grammar G
ham
whose realization problem is NP-
complete in the above sense. Furthermore, we find
that our proof brings out the sources of the complex-
ity more clearly. G
ham
does not permit adjunction,
hence the result also holds for context-free gram-
mars with indices.
1
 
2
 3
It is clear that the problem is in
NP: We can simply guess the ele-
mentary trees we need and how to
combine them, and then check in
polynomial time whether they verbalize the seman-
tics. The NP-hardness proof is by reducing the well-
known HAMILTONIAN-PATH problem to the realiza-
tion problem. HAMILTONIAN-PATH is the problem
of deciding whether a directed graph has a cycle that
visits each node exactly once, e.g. (1,3,2,1) in the
graph shown above.
We will now construct an LTAG grammar G
ham
such that every graph G = (V,E) can be encoded
as a semantic input S for the realization problem of
G
ham
, which can be verbalized if and only if G has
a Hamiltonian cycle. S is defined as follows:
S = {node(i) | i ? V }
? {edge(i, k) | (i, k) ? E}
? {start-eating, end-eating}.
B:1
N:1 
N:1
n
E:3
e
B:3 
B:3
N:3 
N:3
n
E:2
e
B:2 
B:2
N:2 
N:2
n
E:1
e
B:1 
B:1
eat C 
C
eating C 
C
ate
Figure 2: A derivation with G
ham
corresponding to
a Hamiltonian cycle.
The grammar G
ham
is given in Fig. 1; the start
symbol is B, and we want the root to have index 1.
The tree ?
1
models an edge transition from node i
to the node k by consuming the semantic encodings
of this edge and (by way of a substitution of ?
3
) of
the node i. The second substitution node of ?
1
can
be filled either by another ?
1
, in which way a path
through the graph is modelled, or by an ?
4
, in which
case we switch to an ?edge eating mode?. In this
mode, we can arbitrarily consume edges using ?
2
,
and close the tree with ?
5
when we?re done. This
is illustrated in Fig. 2, the tree corresponding to the
cycle in the example graph above.
The Hamiltonian cycle of the graph, if one exists,
is represented in the indices of the B nodes. The list
of these indices is a path in the graph, as the ?
1
trees
model edge transitions; it is a cycle because it starts
in 1 and ends in 1; and it visits each node exactly
once, for we use exactly one ?
1
tree for each node
literal. The edges which weren?t used in the cycle
can be consumed in the edge eating mode.
The main source for the combinatorics of the re-
alization problem is thus the interaction of lexical
ambiguity and the completely free order in the flat
semantics. Once we have chosen between ?
1
and ?
2
in the realization of each edge literal, we have deter-
mined which edges should be part of the prospective
Hamiltonian cycle, and checking whether it really
is one can be done in linear time. If, on the other
hand, the order of the input placed restrictions on
the structure of the derivation tree, we would again
have information that told us when to switch into the
edge eating mode, i.e. which edges should be part
peter likes mary
subj obj
Figure 3: TDG parse tree for ?Peter likes Mary.?
of the cycle. A third source of combinatorics which
does not become so clear in this encoding is the con-
figuration of the elementary trees. Even when we
have committed to the lexical entries, it is conceiv-
able that only one particular way of plugging them
into each other is grammatical.
4 Topological Dependency Grammar
These factors are exactly the same that make depen-
dency parsing for free word order languages diffi-
cult, and it seems worthwhile to see whether op-
timized parsers for dependency grammars can also
contribute to making generation efficient. We now
sketch a dependency formalism which has an effi-
cient parser and then discuss some of the important
properties of this parser. In the next section, we will
see how to employ the parser for generation.
4.1 The Grammar Formalism
The parse trees of topological dependency grammar
(TDG) (Duchier and Debusmann, 2001; Duchier,
2002) are trees whose nodes correspond one-to-one
to the words of the sentence, and whose edges are la-
belled, e.g. with syntactic relations (see Fig. 3). The
trees are unordered, i.e. there is no intrinsic order
among the children of a node. Word order in TDG
is initially completely free, but there is a separate
mechanism to specify constraints on linear prece-
dence. Since completely free order is what we want
for the realization problem, we do not need these
mechanisms and do not go into them here.
The lexicon assigns to each word a set of lexical
entries; in a parse tree, one of these lexical entries
has to be picked for each node. The lexical entry
specifies what labels are allowed on the incoming
edge (the node?s labels) and the outgoing edges (the
node?s valency). Here are some examples:
word labels valency
likes ? {subj, obj, adv?}
Peter {subj, obj} ?
Mary {subj, obj} ?
The lexical entry for ?likes? specifies that the corre-
sponding node does not accept any incoming edges
(and hence must be the root), must have precisely
one subject and one object edge going out, and can
have arbitrarily many outgoing edges with label adv
(indicated by ?). The nodes for ?Peter? and ?Mary?
both require their incoming edge to be labelled with
either subj or obj and neither require nor allow any
outgoing edges.
A well-formed dependency tree for an input sen-
tence is simply a tree with the appropriate nodes,
whose edges obey the labels and valency restric-
tions specified by the lexical entries. So, the tree in
Fig. 3 is well-formed according to our lexicon.
4.2 TDG Parsing
The parsing problem of TDG can be seen as a search
problem: For each node, we must choose a lexi-
cal entry and the correct mother-daughter relations it
participates in. One strength of the TDG approach is
that it is amenable to strong syntactic inferences that
tackle specifically the three sources of complexity
mentioned above.
The parsing algorithm (Duchier, 2002) is stated
in the framework of constraint programming (Koller
and Niehren, 2000), a general approach to coping
with combinatorial problems. Before it explores all
choices that are possible in a certain state of the
search tree (distribution), it first tries to eliminate
some of the choices which definitely cannot lead to a
solution by simple inferences (propagations). ?Sim-
ple? means that propagations take only polynomial
time; the combinatorics is in the distribution steps
alone. That is, it can still happen that a search tree
of exponential size has to be explored, but the time
spent on propagation in each of its node is only poly-
nomial. Strong propagation can reduce the size of
the search tree, and it may even make the whole al-
gorithm run in polynomial time in practice.
The TDG parser translates the parsing prob-
lem into constraints over (variables denoting) fi-
nite sets of integers, as implemented efficiently in
the Mozart programming system (Oz Development
Team, 1999). This translation is complete: Solutions
of the set constraint can be translated back to cor-
rect dependency trees. But for efficiency, the parser
uses additional propagators tailored to the specific
inferences of the dependency problem. For instance,
in the ?Peter likes Mary? example above, one such
propagator could contribute the information that nei-
ther the ?Peter? nor the ?Mary? node can be an adv
child of ?likes?, because neither can accept an adv
edge. Once the choice has been made that ?Peter? is
the subj child of ?likes?, a propagator can contribute
that ?Mary? must be its obj child, as it is the only
possible candidate for the (obligatory) obj child.
Finally, lexical ambiguity is handled by selection
constraints. These constraints restrict which lexical
entry should be picked for a node. When all pos-
sible lexical entries have some information in com-
mon (e.g., that there must be an outgoing subj edge),
this information is automatically lifted to the node
and can be used by the other propagators. Thus it
is sometimes even possible to finish parsing without
committing to single lexical entries for some nodes.
5 Generation as Dependency Parsing
We will now show how TDG parsing can be used to
enumerate all sentences expressing a given input se-
mantics, thereby solving the realization problem in-
troduced in Section 2. We first define the encoding.
Then we give an example and discuss some runtime
results. Finally, we consider a particular restriction
of our encoding and ways of overcoming it.
5.1 The Encoding
Let G be a grammar as described in Section 2;
i.e. lexical entries are of the form (?, T ), where
? is a flat semantics and T is a TAG elementary
tree whose nodes are decorated with semantic in-
dices. We make the following simplifying assump-
tions. First, we assume that the nodes of the elemen-
tary trees of G are not labelled with feature struc-
tures. Next, we assume that whenever we can adjoin
an auxiliary tree at a node, we can adjoin arbitrarily
many trees at this node. The idea of multiple adjunc-
tion is not new (Schabes and Shieber, 1994), but it
is simplified here because we disregard complex ad-
junction constraints. We will discuss these two re-
strictions in the conclusion. Finally, we assume that
every lexical semantics ? has precisely one member;
this restriction will be lifted in Section 5.4.
Now let?s say we want to find the realizations of
the input semantics S = {?
1
, . . . , ?
n
}, using the
grammar G. The input ?sentence? of the parsing
start mary buy car indef red
sub
st NP,
m,1
substS,e,1
substN,c,1
substNP,c,1
adjN,c
Figure 4: Dependency tree for ?Mary buys a red
car.?
problem we construct is the sequence {start} ? S,
where start is a special start symbol. The parse
tree will correspond very closely to a TAG deriva-
tion tree, its nodes standing for the instantiated ele-
mentary trees that are used in the derivation.
To this end, we use two types of edge labels ?
substitution and adjunction labels. An edge with a
substitution label subst
A,i,p
from the node ? to the
node ? (both of which stand for elementary trees)
indicates that ? should be plugged into the p-th sub-
stitution node in ? that has label A and index i. We
write subst(A) for the maximum number of occur-
rences of A as the label of substitution nodes in any
elementary tree of G; this is the maximum value that
p can take.
An edge with an adjunction label adj
A,i
from ? to
? specifies that ? is adjoined at some node within ?
carrying label A and index i and admitting adjunc-
tion. It does not matter for our purposes to which
node in ? ? is adjoined exactly; the choice cannot af-
fect grammaticality because there is no feature uni-
fication involved.
The dependency grammar encodes how an ele-
mentary tree can be used in a TAG derivation by
restricting the labels of the incoming and outgoing
edges via labels and valency requirements in the lex-
icon. Let?s say that T is an elementary tree of G
which has been matched with the input atom ?
r
, in-
stantiating its index variables. Let A be the label
and i the index of the root of T . If T is an auxiliary
tree, it accepts incoming adjunction edges for A and
i, i.e. it gets the labels value {adj
A,i
}. If T is an
initial tree, it will accept arbitrary incoming substi-
tution edges for A and i, i.e. its labels value is
{subst
A,i,p
| 1 ? p ? subst(A)}
In either case, T will require precisely one out-
going substitution edge for each of its substitution
nodes, and it will allow arbitrary numbers of outgo-
ing adjunction edges for each node where we can
adjoin. That is, the valency value is as follows:
{subst
A,i,p
| ex. substitution node N in T s.t. A
is label, i is index of N , and N is
pth substitution node for A:i in T}
? {adj
A,i
? | ex. node with label A, index i
in T which admits adjunction}
We obtain the set of all lexicon entries for the
atom ?
r
by encoding all TAG lexicon entries which
match ?
r
as just specified. The start symbol, start,
gets a special lexicon entry: Its labels entry is the
empty set (i.e. it must be the root of the tree), and its
valency entry is the set {subst
S,k,1
}, where k is the
semantic index with which generation should start.
5.2 An Example
Now let us go through an example to make these def-
initions a bit clearer. Let?s say we want to verbalize
the semantics
{name(m, mary), buy(e,m, c),
car(c), indef(c), red(c)}
The LTAG grammar we use contains the elemen-
tary trees which are used in the tree in Fig. 5, along
with the obvious semantics; we want to generate a
sentence starting with the main event e. The encod-
ing produces the following dependency grammar;
the entries in the ?atom? column are to be read as
abbreviations of the actual atoms in the input seman-
tics.
atom labels valency
start ? {subst
S,e,1
}
buy {subst
S,e,1
} {subst
NP,c,1
, subst
NP,m,1
,
adj
V P,e
?, adj
V,e
?}
mary {subst
NP,m,1
, {adj
NP,1
?, adj
PN,m
?}
subst
NP,m,2
}
indef {subst
NP,c,1
, {adj
NP,c
?}
subst
NP,c,2
}
car {subst
N,c,1
} {adj
N,c
?}
red {adj
N,c
} ?
If we parse the ?sentence?
start mary buy car indef red
with this grammar, leaving the word order com-
pletely open, we obtain precisely one parse tree,
shown in Fig. 4. Reading this parse as a TAG
derivation tree, we can reconstruct the derived tree
in Fig. 5, which indeed produces the string ?Mary
buys a red car?.
S:e
NP:m 
NP:m
PN:m
Mary
VP:e
V:e
buys
NP:c 
NP:c
Detnoad j
a
N:c 
N:c
Adjnoad j
red
N:c
N:c
car
Figure 5: Derived tree for ?Mary buys a red car.?
5.3 Implementation and Experiments
The overall realization algorithm we propose en-
codes the input problem as a DG parsing problem
and then runs the parser described in Section 4.2,
which is freely available over the Web, as a black
box. Because the information lifted to the nodes by
the selection constraints may be strong enough to
compute the parse tree without ever committing to
unique lexical entries, the complete parse may still
contain some lexical ambiguity. This is no problem,
however, because the absence of features guarantees
that every combination of choices will be grammat-
ical. Similarly, a node can have multiple children
over adjunction edges with the same label, and there
may be more than one node in the upper elemen-
tary tree to which the lower tree could be adjoined.
Again, all remaining combinations are guaranteed to
be grammatical.
In order to get an idea of the performance of
our realization algorithm in comparison to the state
of the art, we have tried generating the following
sentences, which are examples from (Carroll et al,
1999):
(1) The manager in that office interviewed a new
consultant from Germany.
(2) Our manager organized an unusual additional
weekly departmental conference.
We have converted the XTAG grammar (XTAG
Research Group, 2001) into our grammar format,
automatically adding indices to the nodes of the el-
ementary trees, removing features, simplifying ad-
junction constraints, and adding artificial lexical se-
mantics that consists of the words at the lexical an-
chors and the indices used in the respective trees.
XTAG typically assigns quite a few elementary trees
to one lemma, and the same lexical semantics can of-
ten be verbalized by more than hundred elementary
trees in the converted grammar. It turns out that the
dependency parser scales very nicely to this degree
of lexical ambiguity: The sentence (1) is generated
in 470 milliseconds (as opposed to Carroll et al?s 1.8
seconds), whereas we generate (2) in about 170 mil-
liseconds (as opposed to 4.3 seconds).1 Although
these numbers are by no means a serious evaluation
of our system?s performance, they do present a first
proof of concept for our approach.
The most encouraging aspect of these results is
that despite the increased lexical ambiguity, the
parser gets by without ever making any wrong
choices, which means that it runs in polynomial
time, on all examples we have tried. This is possible
because on the one hand, the selection constraint au-
tomatically compresses the many different elemen-
tary trees that XTAG assigns to one lemma into very
few classes. On the other hand, the propagation that
rules out impossible edges is so strong that the free
input order does not make the configuration prob-
lem much harder in practice. Finally, our treatment
of modification allows us to multiply out the possi-
ble permutations in a postprocessing step, after the
parser has done the hard work. A particularly strik-
ing example is (2), where the parser gives us a single
solution, which multiplies out to 312 = 13 ? 4! dif-
ferent realizations. (The 13 basic realizations corre-
spond to different syntactic frames for the main verb
in the XTAG grammar, e.g. for topicalized or pas-
sive constructions.)
5.4 More Complex Semantics
So far, we have only considered TAG grammars in
which each elementary tree is assigned a semantics
that contains precisely one atom. However, there
are cases where an elementary tree either has an
empty semantics, or a semantics that contains mul-
tiple atoms. The first case can be avoided by ex-
ploiting TAG?s extended domain of locality, see e.g.
(Gardent and Thater, 2001).
The simplest possible way for dealing with the
second case is to preprocess the input into several
1A newer version of Carroll et al?s system generates (1) in
420 milliseconds (Copestake, p.c.). Our times were measured
on a 700 MHz Pentium-III PC.
different parsing problems. In a first step, we collect
all possible instantiations of LTAG lexical entries
matching subsets of the semantics. Then we con-
struct all partitions of the input semantics in which
each block in the partition is covered by a lexical en-
try, and build a parsing problem in which each block
is one symbol in the input to the parser.
This seems to work quite well in practice, as there
are usually not many possible partitions. In the worst
case, however, this approach produces an exponen-
tial number of parsing problems. Indeed, using a
variant of the grammar from Section 3, it is easy
to show that the problem of deciding whether there
is a partition whose parsing problem can be solved
is NP-complete as well. An alternative approach is
to push the partitioning process into the parser as
well. We expect this will not hurt the runtime all
that much, but the exact effect remains to be seen.
6 Comparison to Other Approaches
The perspective on realization that our system takes
is quite different from previous approaches. In this
section, we relate it to chart generation (Kay, 1996;
Carroll et al, 1999) and to another constraint-based
approach (Gardent and Thater, 2001).
In chart based approaches to realization, the main
idea is to minimize the necessary computation by
reusing partial results that have been computed be-
fore. In the setting of fixed word order parsing, this
brings an immense increase in efficiency. In genera-
tion, however, the NP-completeness manifests itself
in charts of worst-case exponential size. In addition,
it can happen that substructures are built which are
not used in the final realization, especially when pro-
cessing modifications.
By contrast, our system configures nodes into a
dependency tree. It solves a search problem, made
up by choices for mother-daughter relations in the
tree. Propagation, which runs in polynomial time,
has access to global information (illustrated in Sec-
tion 4.2) and can thus rule out impossible mother-
daughter relations efficiently; every propagation step
that takes place actually contributes to zooming in
on the possible realizations. Our system can show
exponential runtimes when the distributions span a
search tree of exponential size.
Gardent and Thater (2001) also propose a con-
straint based approach to generation working with
a variant of TAG. However, the performance of their
system decreases rapidly as the input gets larger
even when when working with a toy grammar. The
main difference between their approach and ours
seems to be that their algorithm tries to construct
a derived tree, while ours builds a derivation tree.
Our parser only has to deal with information that
is essential to solve the combinatorial problem, and
not e.g. with the internal structure of the elementary
trees. The reconstruction of the derived tree, which
is cheap once the derivation tree has been computed,
is delegated to a post-processing step. Working with
derived trees, Gardent and Thater (2001) cannot ig-
nore any information and have to keep track of the
relationships between nodes at points where they are
not relevant.
7 Conclusion
Generation from flat semantics is an NP-complete
problem. In this paper, we have first given an al-
ternative proof for this fact, which works even for
a fixed grammar and makes the connection to the
complexity of free word order parsing clearly visi-
ble. Then we have shown how to translate the re-
alization problem of TAG into parsing problems of
topological dependency grammar, and argued how
the optimizations in the dependency parser ? which
were originally developed for free word order pars-
ing ? help reduce the runtime for the generation sys-
tem. This reduction shows in passing that the pars-
ing problem for TDG is NP-complete as well, which
has been conjectured, but never proved.
The NP-completeness result for the realization
problem explains immediately why all existing com-
plete generation algorithms have exponential run-
times in the worst case. As our proof shows, the
main sources of the combinatorics are the interac-
tion of lexical ambiguity and tree configuration with
the completely unordered nature of the input. Mod-
ification is important and deserves careful treatment
(and indeed, our system deals very gracefully with
it), but it is not as intrinsically important as some
of the literature suggests; our proof gets by without
modification. If we allow the grammar to be part
of the input, we can even modify the proof to show
NP-hardness of the case where semantic atoms can
be verbalized more often than they appear in the in-
put, and of the case where they can be verbalized
less often. The case where every atom can be used
arbitrarily often remains open.
By using techniques from constraint program-
ming, the dependency parser seems to cope rather
well with the combinatorics of generation. Propaga-
tors can rule out impossible local structures on the
grounds of global information, and selection con-
straints greatly alleviate the proliferation of lexical
ambiguity in large TAG grammars by making shared
information available without having to commit to
specific lexical entries. Initial experiments with the
XTAG grammar indicate that we can generate prac-
tical examples in polynomial time, and may be com-
petitive with state-of-the-art realization systems in
terms of raw runtime.
In the future, it will first of all be necessary to lift
the restrictions we have placed on the TAG gram-
mar: So far, the nodes of the elementary trees are
only equipped with nonterminal labels and indices,
not with general feature structures, and we allow
only a restricted form of adjunction constraints. It
should be possible to either encode these construc-
tions directly in the dependency grammar (which al-
lows user-defined features too), or filter out wrong
realizations in a post-processing step. The effect of
such extensions on the runtime remains to be seen.
Finally, we expect that despite the general NP-
completeness, there are restricted generation prob-
lems which can be solved in polynomial time, but
still contain all problems that actually arise for nat-
ural language. The results of this paper open up a
new perspective from which such restrictions can be
sought, especially considering that all the natural-
language examples we tried are indeed processed
in polynomial time. Such a polynomial realiza-
tion algorithm would be the ideal starting point
for algorithms that compute not just any, but the
best possible realization ? a problem which e.g.
Bangalore and Rambow (2000) approximate using
stochastic methods.
Acknowledgments. We are grateful to Tilman
Becker, Chris Brew, Ann Copestake, Ralph Debus-
mann, Gerald Penn, Stefan Thater, and our reviewers
for helpful comments and discussions.
References
Srinivas Bangalore and Owen Rambow. 2000. Using
tags, a tree model, and a language model for genera-
tion. In Proc. of the TAG+5 Workshop, Paris.
G. Edward Barton, Robert C. Berwick, and Eric Sven
Ristad. 1987. Computational Complexity and Natu-
ral Language. MIT Press, Cambridge, Mass.
Chris Brew. 1992. Letting the cat out of the bag: Gen-
eration for Shake-and-Bake MT. In Proceedings of
COLING-92, pages 610?616, Nantes.
John Carroll, Ann Copestake, Dan Flickinger, and Vic-
tor Poznanski. 1999. An efficient chart generator for
(semi-)lexicalist grammars. In Proceedings of the 7th
European Workshop on NLG, pages 86?95, Toulouse.
Denys Duchier and Ralph Debusmann. 2001. Topolog-
ical dependency trees: A constraint-based account of
linear precedence. In Proceedings of the 39th ACL,
Toulouse, France.
Denys Duchier. 2002. Configuration of labeled trees un-
der lexicalized constraints and principles. Journal of
Language and Computation. To appear.
Claire Gardent and Stefan Thater. 2001. Generating with
a grammar based on tree descriptions: A constraint-
based approach. In Proceedings of the 39th ACL,
Toulouse.
Aravind Joshi and Yves Schabes. 1997. Tree-Adjoining
Grammars. In G. Rozenberg and A. Salomaa, editors,
Handbook of Formal Languages, chapter 2, pages 69?
123. Springer-Verlag, Berlin.
Martin Kay. 1996. Chart generation. In Proceedings of
the 34th Annual Meeting of the ACL, pages 200?204,
Santa Cruz.
Alexander Koller and Joachim Niehren. 2000. Con-
straint programming in computational linguistics. To
appear in Proceedings of LLC8, CSLI Press.
Oz Development Team. 1999. The Mozart Programming
System web pages. http://www.mozart-oz.
org/.
Yves Schabes and Stuart Shieber. 1994. An alterna-
tive conception of tree-adjoining derivation. Compu-
tational Linguistics, 20(1):91?124.
Matthew Stone and Christy Doran. 1997. Sentence plan-
ning as description using tree-adjoining grammar. In
Proceedings of the 35th ACL, pages 198?205.
XTAG Research Group. 2001. A lexicalized tree adjoin-
ing grammar for english. Technical Report IRCS-01-
03, IRCS, University of Pennsylvania.
Minimal Recursion Semantics as Dominance Constraints:
Translation, Evaluation, and Analysis
Ruth Fuchss,1 Alexander Koller,1 Joachim Niehren,2 and Stefan Thater1
1 Dept. of Computational Linguistics, Saarland University, Saarbr?cken, Germany ?
2 INRIA Futurs, Lille, France
{fuchss,koller,stth}@coli.uni-sb.de
Abstract
We show that a practical translation of MRS de-
scriptions into normal dominance constraints is fea-
sible. We start from a recent theoretical translation
and verify its assumptions on the outputs of the En-
glish Resource Grammar (ERG) on the Redwoods
corpus. The main assumption of the translation?
that all relevant underspecified descriptions are
nets?is validated for a large majority of cases; all
non-nets computed by the ERG seem to be system-
atically incomplete.
1 Introduction
Underspecification is the standard approach to deal-
ing with scope ambiguity (Alshawi and Crouch,
1992; Pinkal, 1996). The readings of underspecified
expressions are represented by compact and concise
descriptions, instead of being enumerated explic-
itly. Underspecified descriptions are easier to de-
rive in syntax-semantics interfaces (Egg et al, 2001;
Copestake et al, 2001), useful in applications such
as machine translation (Copestake et al, 1995), and
can be resolved by need.
Two important underspecification formalisms in
the recent literature are Minimal Recursion Seman-
tics (MRS) (Copestake et al, 2004) and dominance
constraints (Egg et al, 2001). MRS is the under-
specification language which is used in large-scale
HPSG grammars, such as the English Resource
Grammar (ERG) (Copestake and Flickinger, 2000).
The main advantage of dominance constraints is
that they can be solved very efficiently (Althaus et
al., 2003; Bodirsky et al, 2004).
Niehren and Thater (2003) defined, in a theo-
retical paper, a translation from MRS into normal
dominance constraints. This translation clarified the
precise relationship between these two related for-
malisms, and made the powerful meta-theory of
dominance constraints accessible to MRS. Their
goal was to also make the large grammars for MRS
? Supported by the CHORUS project of the SFB 378 of the
DFG.
and the efficient constraint solvers for dominance
constraints available to the other formalism.
However, Niehren and Thater made three techni-
cal assumptions:
1. that EP-conjunction can be resolved in a pre-
processing step;
2. that the qeq relation in MRS is simply domi-
nance;
3. and (most importantly) that all linguistically
correct and relevant MRS expressions belong
to a certain class of constraints called nets.
This means that it is not obvious whether their
result can be immediately applied to the output of
practical grammars like the ERG.
In this paper, we evaluate the truth of these as-
sumptions on the MRS expressions which the ERG
computes for the sentences in the Redwoods Tree-
bank (Oepen et al, 2002). The main result of our
evaluation is that 83% of the Redwoods sentences
are indeed nets, and 17% aren?t. A closer analysis
of the non-nets reveals that they seem to be sys-
tematically incomplete, i. e. they predict more read-
ings than the sentence actually has. This supports
the claim that all linguistically correct MRS expres-
sions are indeed nets. We also verify the other two
assumptions, one empirically and one by proof.
Our results are practically relevant because dom-
inance constraint solvers are much faster and have
more predictable runtimes when solving nets than
the LKB solver for MRS (Copestake, 2002), as we
also show here. In addition, nets might be useful as
a debugging tool to identify potentially problematic
semantic outputs when designing a grammar.
Plan of the Paper. We first recall the definitions
of MRS (?2) and dominance constraints (?3). We
present the translation from MRS-nets to domi-
nance constraints (?4) and prove that it can be ex-
tended to MRS-nets with EP-conjunction (?5). Fi-
nally we evaluate the net hypothesis and the qeq
assumption on the Redwoods corpus, and compare
runtimes (?6).
2 Minimal Recursion Semantics
This section presents a definition of Minimal Re-
cursion Semantics (MRS) (Copestake et al, 2004)
including EP-conjunctions with a merging seman-
tics. Full MRS with qeq-semantics, top handles, and
event variables will be discussed in the last para-
graph.
MRS Syntax. MRS constraints are conjunctive
formulas over the following vocabulary:
1. An infinite set of variables ranged over by h.
Variables are also called handles.
2. An infinite set of constants x,y,z denoting in-
divual variables of the object language.
3. A set of function symbols ranged over by P,
and a set of quantifier symbols ranged over by
Q. Pairs Qx are further function symbols.
4. The binary predicate symbol ?=q?.
MRS constraints have three kinds of literals, two
kinds of elementary predications (EPs) in the first
two lines and handle constraints in the third line:
1. h : P(x1, . . . ,xn,h1, . . . ,hm), where n,m ? 0
2. h : Qx(h1,h2)
3. h1 =q h2
In EPs, label positions are on the left of ?:? and argu-
ment positions on the right. Let M be a set of literals.
The label set lab(M) contains all handles of M that
occur in label but not in argument position, and the
argument handle set arg(M) contains all handles of
M that occur in argument but not in label position.
Definition 1 (MRS constraints). An MRS con-
straint (MRS for short) is a finite set M of MRS-
literals such that:
M1 every handle occurs at most once in argument
position in M,
M2 handle constraints h =q h? always relate argu-
ment handles h to labels h?, and
M3 for every constant (individual variable) x in ar-
gument position in M there is a unique literal
of the form h : Qx(h1,h2) in M.
We say that an MRS M is compact if every han-
dle h in M is either a label or an argument handle.
Compactness simplifies the following proofs, but it
is no serious restriction in practice.
We usually represent MRSs as directed graphs:
the nodes of the graph are the handles of the MRS,
EPs are represented as solid lines, and handle con-
straints are represented as dotted lines. For instance,
the following MRS is represented by the graph on
the left of Fig. 1.
{h5 : somey(h6,h8),h7 : book(y),h1 : everyx(h2,h4),
h3 : student(x),h9 : read(x,y),h2 =q h3,h6 =q h7}
everyx somey
studentx booky
readx,y
everyx
somey
studentx
booky
readx,y
everyx
someystudentx
booky readx,y
Figure 1: An MRS and its two configurations.
Note that the relation between bound variables
and their binders is made explicit by binding edges
drawn as dotted lines (cf. C2 below); transitively re-
dundand binding edges (e. g., from somey to booky)
however are omited.
MRS Semantics. Readings of underspecified rep-
resentations correspond to configurations of MRS
constraints. Intuitively, a configuration is an MRS
where all handle constraints have been resolved by
plugging the ?tree fragments? into each other.
Let M be an MRS and h,h? be handles in M. We
say that h immediately outscopes h? in M if there
is an EP in M with label h and argument handle h?,
and we say that h outscopes h? in M if the pair (h,h?)
belongs to the reflexive transitive closure of the im-
mediate outscope relation of M.
Definition 2 (MRS configurations). An MRS M is
a configuration if it satisfies conditions C1 and C2:
C1 The graph of M is a tree of solid edges: (i) all
handles are labels i. e., arg(M) = /0 and M con-
tains no handle constraints, (ii) handles don?t
properly outscope themselve, and (iii) all han-
dles are pairwise connected by EPs in M.
C2 If h : Qx(h1,h2) and h? : P(. . . ,x, . . .) belong to
M, then h outscopes h? in M i. e., binding edges
in the graph of M are transitively redundant.
We say that a configuration M is configuration of
an MRS M? if there exists a partial substitution ? :
lab(M?) arg(M?) that states how to identify labels
with argument handles of M? so that:
C3 M = {?(E) | E is an EP in M?}, and
C4 for all h =q h? in M?, h outscopes ?(h?) in M.
The value ?(E) is obtained by substituting all la-
bels in dom(?) in E while leaving all other handels
unchanged.
The MRS on the left of Fig. 1, for instance, has
two configurations given to the right.
EP-conjunctions. Definitions 1 and 2 generalize
the idealized definition of MRS of Niehren and
Thater (2003) by EP-conjunctions with a merging
semantics. An MRS M contains an EP-conjunction
if it contains different EPs with the same label h.The
intuition is that EP-conjunctions are interpreted by
object language conjunctions.
P1, P2
P3
{h1 : P1(h2),h1 : P2(h3),h4 : P3
h2 =q h4,h3 =q h4}
Figure 2: An unsolvable MRS with EP-conjunction
P1
P3P2
P1
P2, P3
configures
Figure 3: A solvable MRS without merging-free
configaration
Fig. 2 shows an MRSwith an EP-conjunction and
its graph. The function symbols of both EPs are con-
joined and their arguments are merged into a set.
The MRS does not have configurations since the ar-
gument handles of the merged EPs cannot jointly
outscope the node P4.
We call a configuration merging if it contains EP-
conjunctions, and merging-free otherwise. Merging
configurations are needed to solve EP-conjuctions
such as {h : P1, h : P2}. Unfortunately, they can also
solve MRSs without EP-conjunctions, such as the
MRS in Fig. 3. The unique configuration of this
MRS is a merging configuration: the labels of P1
and P2 must be identified with the only available ar-
gument handle. The admission of merging configu-
rations may thus have important consequences for
the solution space of arbitrary MRSs.
Standard MRS. Standard MRS requires three
further extensions: (i) qeq-semantics, (ii) top-
handles, and (iii) event variables. These extensions
are less relevant for our comparision.
The qeq-semantics restricts the interpretation of
handle constraints beyond dominance. Let M be an
MRS with handles h,h?. We say that h is qeq h? in M
if either h = h?, or there is an EP h : Qx(h0,h1) in M
and h1 is qeq h? in M. Every qeq-configuration is a
configuration as defined above, but not necessarily
vice versa. The qeq-restriction is relevant in theory
but will turn out unproblematic in practice (see ?6).
Standard MRS requires the existence of top
handles in all MRS constraints. This condition
doesn?t matter for MRSs with connected graphs (see
(Bodirsky et al, 2004) for the proof idea). MRSs
with unconnected graphs clearly do not play any
role in practical underspecified semantics.
Finally, MRSs permit events variables e,e? as a
second form of constants. They are treated equally
to individual variables except that they cannot be
bound by quantifiers.
3 Dominance Constraints
Dominance constraints are a general framework for
describing trees. For scope underspecification, they
are used to describe the syntax trees of object lan-
guage formulas. Dominance constraints are the core
language underlying CLLS (Egg et al, 2001) which
adds parallelism and binding constraints.
Syntax and semantics. We assume a possibly in-
finite signature ? = { f ,g, . . .} of function symbols
with fixed arities (written ar( f )) and an infinite set
of variables ranged over by X ,Y,Z.
A dominance constraint ? is a conjunction of
dominance, inequality, and labeling literals of the
following form, where ar( f ) = n:
? ::= X ? Y | X = Y | X : f (X1, . . . ,Xn) | ????
Dominance constraints are interpreted over fi-
nite constructor trees i. e., ground terms constructed
from the function symbols in ?. We identify ground
terms with trees that are rooted, ranked, edge-
ordered and labeled. A solution for a dominance
constraint ? consists of a tree ? and an assign-
ment ? that maps the variables in ? to nodes of ?
such that all constraints are satisfied: labeling lit-
erals X : f (X1, . . . ,Xn) are satisfied iff ?(X) is la-
beled with f and its daughters are ?(X1), . . . ,?(Xn)
in this order; dominance literals X ? Y are satisfied
iff ?(X) dominates ?(Y ) in ?; and inequality literals
X = Y are satisfied iff ?(X) and ?(Y ) are distinct
nodes.
Solved forms. Satisfiable dominance constraints
have infinitely many solutions. Constraint solvers
for dominance constraints therefore do not enumer-
ate solutions but solved forms i. e., ?tree shaped?
constraints. To this end, we consider (weakly) nor-
mal dominance constraints (Bodirsky et al, 2004).
We call a variable a hole of ? if it occurs in argu-
ment position in ? and a root of ? otherwise.
Definition 3. A dominance constraint ? is normal
if it satisfies the following conditions.
N1 (a) each variable of ? occurs at most once in
the labeling literals of ?.
(b) each variable of ? occurs at least once in
the labeling literals of ?.
N2 for distinct roots X and Y of ?, X =Y is in ?.
N3 (a) if X ? Y occurs in ?, Y is a root in ?.
(b) if X ? Y occurs in ?, X is a hole in ?.
We call ? weakly normal if it satisfies the above
properties except for N1 (b) and N3 (b).
Note that Definition 3 imposes compactness: the
height of tree fragments is always one. This is not
everyx somey
studentx booky
readx,y
everyx
someystudentx
booky readx,y
everyx
somey
studentx
booky
readx,y
Figure 4: A normal dominance constraint (left) and
its two solved forms (right).
a serious restriction, as weakly normal dominance
constraints can be compactified, provided that dom-
inance links relate either roots or holes with roots.
Weakly normal dominance constraints ? can be
represented by dominance graphs. The dominance
graph of ? is a directed graph G = (V,ET unionmultiED) de-
fined as follows. The nodes of G are the variables of
?. Labeling literals X : f (X1, . . . ,Xk) are represented
by tree edges (X ,Xi) ? ET , for 1? i? k, and domi-
nance literals X ? X ? are represented by dominance
edges (X ,X ?) ? ED. Inequality literals are not repre-
sented in the graph. In pictures, labeling literals are
drawn with solid lines and dominance edges with
dotted lines.
We say that a constraint ? is in solved form if its
graph is in solved form. A graph G is in solved form
iff it is a forest. The solved forms of G are solved
forms G? which are more specific than G i. e., they
differ only in their dominance edges and the reacha-
bility relation of G extends the reachability of G?. A
minimal solved form is a solved form which is min-
imal with respect to specificity. Simple solved forms
are solved forms where every hole has exactly one
outgoing dominance edge. Fig. 4 shows as a con-
crete example the translation of the MRS descrip-
tion in Fig. 1 together with its two minimal solved
forms. Both solved forms are simple.
4 Translating Merging-Free MRS-Nets
This section defines MRS-nets without EP-
conjunctions, and sketches their translation to
normal dominance constraints. We define nets
equally for MRSs and dominance constraints. The
key semantic property of nets is that different
notions of solutions coincide. In this section, we
show that merging-free configurations coincides
to minimal solved forms. ?5 generalizes the trans-
lation by adding EP-conjunctions and permitting
merging semantics.
Pre-translation. An MRS constraint M can be
represented as a corresponding dominance con-
straint ?M as follows: The variables of ?M are the
handles of M, and the literals of ?M correspond
... ... ...
... ...
(a) strong (b) weak (c) island
Figure 5: Fragment Schemata of Nets
those of M in the following sence:
h : P(x1, . . . ,xn,h1, . . . ,hk) 	? h : Px1,...,xn(h1, . . . ,hk)
h : Qx(h1,h2) 	? h : Qx(h1,h2)
h =q h
?
	? h ? h?
Additionally, dominance literals h ? h? are added to
?M for all h,h? s. t. h :Qx(h1,h2) and h? :P(. . . ,x, . . .)
belong to M (cf. C2), and literals h = h? are added
to ?M for all h,h? in distinct label position in M.
Lemma 1. If a compact MRS M does not contain
EP-conjunctions then ?M is weakly normal, and the
graph of M is the transitive reduction of the graph
of ?M.
Nets. A hypernormal path (Althaus et al, 2003)
in a constraint graph is a path in the undirected
graph that contains for every leaf X at most one in-
cident dominance edge.
Let ? be a weakly normal dominance constraint
and let G be the constraint graph of ?. We say that
? is a dominance net if the transitive reduction G?
of G is a net. G? is a net if every tree fragment F
of G? satisfies one of the following three conditions,
illustrated in Fig. 5:
Strong. Every hole of F has exactly one outgoing
dominance edge, and there is no weak root-to-root
dominance edge.
Weak. Every hole except for the last one has ex-
actly one outgoing dominance edge; the last hole
has no outgoing dominance edge, and there is ex-
actly one weak root-to-root dominance edge.
Island. The fragment has one hole X , and all vari-
ables which are connected to X by dominance edges
are connected by a hypernormal path in the graph
where F has been removed.
We say that an MRS M is an MRS-net if the pre-
translation of its literals results in a dominance net
?M. We say that an MRS-net M is connected if ?M
is connected; ?M is connected if the graph of ?M is
connected.
Note that this notion of MRS-nets implies that
MRS-nets cannot contain EP-conjunctions as other-
wise the resulting dominance constraint would not
be weakly normal. ?5 shows that EP-conjunctions
can be resolved i. e., MRSs with EP-conjunctions
can be mapped to corresponding MRSs without EP-
conjunctions.
If M is an MRS-net (without EP-conjunctions),
then M can be translated into a corresponding dom-
inance constraint ? by first pre-translating M into
a ?M and then normalizing ?M by replacing weak
root-to-root dominance edges in weak fragments by
dominance edges which start from the open last
hole.
Theorem 1 (Niehren and Thater, 2003). Let M be
an MRS and ?M be the translation of M. If M is a
connected MRS-net, then the merging-free configu-
rations of M bijectively correspond to the minimal
solved forms of the ?M.
The following section generalizes this result to
MRS-nets with a merging semantics.
5 Merging and EP-Conjunctions
We now show that if an MRS is a net, then all its
configurations are merging-free, which in particular
means that the translation can be applied to the more
general version of MRS with a merging semantics.
Lemma 2 (Niehren and Thater, 2003). All mini-
mal solved forms of a connected dominance net are
simple.
Lemma 3. If all solved forms of a normal domi-
nance constraint are simple, then all of its solved
forms are minimal.
Theorem 2. The configurations of an MRS-net M
are merging-free.
Proof. Let M? be a configuration of M and let ? be
the underlying substitution. We construct a solved
form ?M? as follows: the labeling literals of ?M? are
the pre-translations of the EPs in M, and ?M? has a
dominance literal h? ? h iff (h,h?) ? ?, and inequal-
ity literals X = Y for all distinct roots in ?M? .
By condition C1 in Def. 2, the graph of M? is a
tree, hence the graph of ?M? must also be a tree i. e.,
?M? is a solved form. ?M? must also be more spe-
cific than the graph of ?M because the graph of M?
satisfies all dominance requirements of the handle
constraints in M, hence ?M? is a solved form of ?M.
M clearly solved ?M? . By Lemmata 2 and 3, ?M?
must be simple and minimal because ?M is a net.
But then M? cannot contain EP-conjunctions i. e.,M?
is merging-free.
The merging semantics of MRS is needed to
solve EP-conjunctions. As we have seen, the merg-
ing semantics is not relevant for MRS constraints
which are nets. This also verifies Niehren and
Thater?s (2003) assumption that EP-conjunctions
are ?syntactic sugar? which can be resolved in a pre-
processing step: EP-conjunctions can be resolved
by exhaustively applying the following rule which
adds new literals to make the implicit conjunction
explicit:
h : E1(h1, . . . ,hn),h : E2(h
?
1, . . . ,h
?
m)?
h : ?E1&E2?(h1, . . . ,hn,h
?
1, . . . ,h
?
m),
where E(h1, . . . ,hn) stands for an EP with argument
handles h1, . . . ,hn, and where ?E1&E2? is a complex
function symbol. If this rule is applied exhaustively
to an MRS M, we obtain an MRS M? without EP-
conjunctions. It should be intuitively clear that the
configurations of M and M? correspond; Therefore,
the configurations of M also correspond to the min-
imal solved forms of the translation of M?.
6 Evaluation
The two remaining assumptions underlying the
translation are the ?net-hypothesis? that all lin-
guistically relevant MRS expressions are nets, and
the ?qeq-hypothesis? that handle constraints can be
given a dominance semantics practice. In this sec-
tion, we empirically show that both assumptions are
met in practice.
As an interesting side effect, we also compare the
run-times of the constraint-solvers we used, and we
find that the dominance constraint solver typically
outperforms the MRS solver, often by significant
margins.
Grammar and Resources. We use the English
Resource Grammar (ERG), a large-scale HPSG
grammar, in connection with the LKB system, a
grammar development environment for typed fea-
ture grammars (Copestake and Flickinger, 2000).
We use the system to parse sentences and output
MRS constraints which we then translate into domi-
nance constraints. As a test corpus, we use the Red-
woods Treebank (Oepen et al, 2002) which con-
tains 6612 sentences. We exclude the sentences that
cannot be parsed due to memory capacities or words
and grammatical structures that are not included in
the ERG, or which produce ill-formed MRS expres-
sions (typically violating M1) and thus base our
evaluation on a corpus containing 6242 sentences.
In case of syntactic ambiguity, we only use the first
reading output by the LKB system.
To enumerate the solutions of MRS constraints
and their translations, we use the MRS solver built
into the LKB system and a solver for weakly nor-
mal dominance constraints (Bodirsky et al, 2004),
...
(a) open hole (b) ill-formed island
Figure 6: Two classes of non-nets
which is implemented in C++ and uses LEDA, a
class library for efficient data types and algorithms
(Mehlhorn and N?her, 1999).
6.1 Relevant Constraints are Nets
We check for 6242 constraints whether they consti-
tute nets. It turns out that 5200 (83.31%) constitute
nets while 1042 (16.69%) violate one or more net-
conditions.
Non-nets. The evaluation shows that the hypoth-
esis that all relevant constraints are nets seems to
be falsified: there are constraints that are not nets.
However, a closer analysis suggests that these con-
straints are incomplete and predict more readings
than the sentence actually has. This can also be il-
lustrated with the average number of solutions: For
the Redwoods corpus in combination with the ERG,
nets have 1836 solutions on average, while non-nets
have 14039 solutions, which is a factor of 7.7. The
large number of solutions for non-nets is due to the
?structural weakness? of non-nets; often, non-nets
have only merging configurations.
Non-nets can be classified into two categories
(see Fig. 6): The first class are violated ?strong?
fragments which have holes without outgoing dom-
inance edge and without a corresponding root-to-
root dominance edge. The second class are violated
?island? fragments where several outgoing domi-
nance edges from one hole lead to nodes which
are not hypernormally connected. There are two
more possibilities for violated ?weak? fragments?
having more than one weak dominance edge or hav-
ing a weak dominance edge without empty hole?,
but they occur infrequently (4.4%). If those weak
fragments were normalized, they would constitute
violated island fragments, so we count them as such.
124 (11.9%) of the non-nets contain empty holes,
762 (73.13%) contain violated island fragments,
and 156 (14.97%) contain both. Those constraints
that contain only empty holes and no violated is-
land fragments cannot be configured, as in configu-
rations, all holes must be filled.
Fragments with open holes occur frequently, but
not in all contexts, for constraints representing for
example time specifications (e. g., ?from nine to
twelve? or ?a three o?clock flight?) or intensional
expressions (e. g., ?Is it?? or ?I suppose?). Ill-
availablee, ax
aycafeteriax
saunay ande,x,y
prop
ax
aycafeteriax
saunay, 
ande,x,y
availablee
prop
ax ay
cafeteriax saunay
ande,x,y
availablee
prop
?1 ?2
Figure 7: An MRS for ?A sauna and a cafeteria are
available? (top) and two of sixteen merging config-
urations (below).
ax ay
cafeteriax saunay
ande,x,y
availablee
prop
Figure 8: The ?repaired? MRS from Fig. 7
formed island fragments are often triggered by some
kind of coordination, like ?a restaurant and/or a
sauna? or ?a hundred and thirty Marks?, also im-
plicit ones like ?one hour thirty minutes? or ?one
thirty?. Constraints with both kinds of violated frag-
ments emerge when there is some input that yields
an open hole and another part of the input yields a
violated island fragment (for example in construc-
tions like ?from nine to eleven thirty? or ?the ten
o?clock flight Friday or Thursday?, but not neces-
sarily as obviously as in those examples).
The constraint on the left in Fig. 7 gives a con-
crete example for violated island fragments. The
topmost fragment has outgoing dominance edges
to otherwise unconnected subconstraints ?1 and ?2.
Under the merging-free semantics of the MRS di-
alect used in (Niehren and Thater, 2003) where ev-
ery hole has to be filled exactly once, this constraint
cannot be configured: there is no hole into which
?available? could be plugged. However, standard
MRS has merging configuration where holes can be
filled more than once. For the constraint in Fig. 7
this means that ?available? can be merged in almost
everywhere, only restricted by the ?qeq-semantics?
which forbids for instance ?available? to be merged
with ?sauna.? In fact, the MRS constraint solver de-
rives sixteen configurations for the constraint, two
of which are given in Fig. 7, although the sentence
has only two scope readings.
We conjecture that non-nets are semantically ?in-
complete? in the sense that certain constraints are
missing. For instance, an alternative analysis for the
above constraint is given in Fig. 8. The constraint
adds an additional argument handle to ?and? and
places a dominance edge from this handle to ?avail-
able.? In fact, the constraint is a net; it has exactly
two readings.
6.2 Qeq is dominance
For all nets, the dominance constraint solver cal-
culates the same number of solutions as the MRS
solver does, with 3 exceptions that hint at problems
in the syntax-semantics interface. As every config-
uration that satisfies proper qeq-constraints is also
a configuration if handle constraints are interpreted
under the weaker notion of dominance, the solutions
computed by the dominance constraint solver and
the MRS solver must be identical for every con-
straint. This means that the additional expressivity
of proper qeq-constraints is not used in practice,
which in turn means that in practice, the translation
is sound and correct even for the standard MRS no-
tion of solution, given the constraint is a net.
6.3 Comparison of Runtimes
The availability of a large body of underspecified
descriptions both in MRS and in dominance con-
straint format makes it possible to compare the
solvers for the two underspecification formalisms.
We measured the runtimes on all nets using a Pen-
tium III CPU at 1.3 GHz. The tests were run in a
multi-user environment, but as the MRS and domi-
nance measurements were conducted pairwise, con-
ditions were equal for every MRS constraint and
corresponding dominance constraint.
The measurements for all MRS-nets with less
than thirty dominance edges are plotted in Fig. 9.
Inputs are grouped according to the constraint size.
The filled circles indicate average runtimes within
each size group for enumerating all solutions us-
ing the dominance solver, and the empty circles in-
dicate the same for the LKB solver. The brackets
around each point indicate maximum and minimum
runtimes in that group. Note that the vertical axis is
logarithmic.
We excluded cases in which one or both of the
solvers did not return any results: There were 173
sentences (3.33% of all nets) on which the LKB
solver ran out of memory, and 1 sentence (0.02%)
that took the dominance solver more than two min-
utes to solve.
The graph shows that the dominance constraint
solver is generally much faster than the LKB solver:
The average runtime is less by a factor of 50 for
constraints of size 10, and this grows to a factor
of 500 for constraints of size 25. Our experiments
show that the dominance solver outperforms the
LKB solver on 98% the cases. In addition, its run-
times are much more predictable, as the brackets in
the graph are also shorter by two or three orders
of magnitude, and the standard deviation is much
smaller (not shown).
7 Conclusion
We developed Niehren and Thater?s (2003) theoret-
ical translation into a practical system for translat-
ing MRS into dominance constraints, applied it sys-
tematically to MRSs produced by English Resource
Grammar for the Redwoods treebank, and evaluated
the results. We showed that:
1. most ?real life? MRS expressions are MRS-
nets, which means that the translation is correct
in these cases;
2. for nets, merging is not necessary (or even pos-
sible);
3. the practical translation works perfectly for all
MRS-nets from the corpus; in particular, the
=q relation can be taken as synonymous with
dominance in practice.
Because the translation works so well in practice,
we were able to compare the runtimes of MRS and
dominance constraint solvers on the same inputs.
This evaluation shows that the dominance constraint
solver outperforms the MRS solver and displays
more predictable runtimes. A researcher working
with MRS can now solve MRS nets using the ef-
ficient dominance constraint solvers.
A small but significant number of the MRS con-
straints derived by the ERG are not nets. We have
argued that these constraints seem to be systemati-
cally incomplete, and their correct completions are
indeed nets. A more detailed evaluation is an impor-
tant task for future research, but if our ?net hypoth-
esis? is true, a system that tests whether all outputs
of a grammar are nets (or a formal ?safety criterion?
that would prove this theoretically) could be a use-
ful tool for developing and debugging grammars.
From a more abstract point of view, our evalua-
tion contributes to the fundamental question of what
expressive power an underspecification formalism
needs. It turned out that the distinction between qeq
 1
 10
 100
 1000
 10000
 100000
 1e+06
 0  5  10  15  20  25  30
T
i
m
e
 
(
m
s
)
Size (number of dominance edges)
DC solver (LEDA)
MRS solver
Figure 9: Comparison of runtimes for the MRS and dominance constraint solvers.
and dominance hardly plays a role in practice. If the
net hypothesis is true, it also follows that merging is
not necessary because EP-conjunctions can be con-
verted into ordinary conjunctions. More research
along these lines could help unify different under-
specification formalisms and the resources that are
available for them.
Acknowledgments We are grateful to Ann
Copestake for many fruitful discussions, and to our
reviewers for helpful comments.
References
H. Alshawi and R. Crouch. 1992. Monotonic se-
mantic interpretation. In Proc. 30th ACL, pages
32?39.
Ernst Althaus, Denys Duchier, Alexander Koller,
Kurt Mehlhorn, Joachim Niehren, and Sven
Thiel. 2003. An efficient graph algorithm for
dominance constraints. Journal of Algorithms,
48:194?219.
Manuel Bodirsky, Denys Duchier, Joachim Niehren,
and Sebastian Miele. 2004. An efficient algo-
rithm for weakly normal dominance constraints.
In ACM-SIAM Symposium on Discrete Algo-
rithms. The ACM Press.
Ann Copestake and Dan Flickinger. 2000. An
open-source grammar development environment
and broad-coverage english grammar using
HPSG. In Conference on Language Resources
and Evaluation.
Ann Copestake, Dan Flickinger, Rob Malouf, Su-
sanne Riehemann, and Ivan Sag. 1995. Transla-
tion using Minimal Recursion Semantics. Leu-
ven.
Ann Copestake, Alex Lascarides, and Dan
Flickinger. 2001. An algebra for semantic
construction in constraint-based grammars. In
Proceedings of the 39th Annual Meeting of the
Association for Computational Linguistics, pages
132?139, Toulouse, France.
Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan Sag. 2004. Minimal recursion semantics:
An introduction. Journal of Language and Com-
putation. To appear.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI Publications, Stan-
ford, CA.
Markus Egg, Alexander Koller, and Joachim
Niehren. 2001. The Constraint Language for
Lambda Structures. Logic, Language, and Infor-
mation, 10:457?485.
K. Mehlhorn and S. N?her. 1999. The LEDA Plat-
form of Combinatorial and Geometric Comput-
ing. Cambridge University Press, Cambridge.
See also http://www.mpi-sb.mpg.de/LEDA/.
Joachim Niehren and Stefan Thater. 2003. Bridg-
ing the gap between underspecification for-
malisms: Minimal recursion semantics as dom-
inance constraints. In Proceedings of the 41st
Annual Meeting of the Association for Computa-
tional Linguistics.
Stephan Oepen, Kristina Toutanova, Stuart Shieber,
Christopher Manning, Dan Flickinger, and
Thorsten Brants. 2002. The LinGO Redwoods
treebank: Motivation and preliminary applica-
tions. In Proceedings of the 19th International
Conference on Computational Linguistics
(COLING?02), pages 1253?1257.
Manfred Pinkal. 1996. Radical underspecification.
In 10th Amsterdam Colloquium, pages 587?606.
Computing Locally Coherent Discourses
Ernst Althaus
LORIA
Universite? Henri Poincare?
Vand?uvre-le`s-Nancy, France
althaus@loria.fr
Nikiforos Karamanis
School of Informatics
University of Edinburgh
Edinburgh, UK
N.Karamanis@sms.ed.ac.uk
Alexander Koller
Dept. of Computational Linguistics
Saarland University
Saarbru?cken, Germany
koller@coli.uni-sb.de
Abstract
We present the first algorithm that computes opti-
mal orderings of sentences into a locally coherent
discourse. The algorithm runs very efficiently on a
variety of coherence measures from the literature.
We also show that the discourse ordering problem
is NP-complete and cannot be approximated.
1 Introduction
One central problem in discourse generation and
summarisation is to structure the discourse in a
way that maximises coherence. Coherence is the
property of a good human-authored text that makes
it easier to read and understand than a randomly-
ordered collection of sentences.
Several papers in the recent literature (Mellish et
al., 1998; Barzilay et al, 2002; Karamanis and Ma-
nurung, 2002; Lapata, 2003; Karamanis et al, 2004)
have focused on defining local coherence, which
evaluates the quality of sentence-to-sentence transi-
tions. This is in contrast to theories of global coher-
ence, which can consider relations between larger
chunks of the discourse and e.g. structures them into
a tree (Mann and Thompson, 1988; Marcu, 1997;
Webber et al, 1999). Measures of local coherence
specify which ordering of the sentences makes for
the most coherent discourse, and can be based e.g.
on Centering Theory (Walker et al, 1998; Brennan
et al, 1987; Kibble and Power, 2000; Karamanis
and Manurung, 2002) or on statistical models (Lap-
ata, 2003).
But while formal models of local coherence have
made substantial progress over the past few years,
the question of how to efficiently compute an order-
ing of the sentences in a discourse that maximises
local coherence is still largely unsolved. The fun-
damental problem is that any of the factorial num-
ber of permutations of the sentences could be the
optimal discourse, which makes for a formidable
search space for nontrivial discourses. Mellish et
al. (1998) and Karamanis and Manurung (2002)
present algorithms based on genetic programming,
and Lapata (2003) uses a graph-based heuristic al-
gorithm, but none of them can give any guarantees
about the quality of the computed ordering.
This paper presents the first algorithm that com-
putes optimal locally coherent discourses, and es-
tablishes the complexity of the discourse ordering
problem. We first prove that the discourse order-
ing problem for local coherence measures is equiva-
lent to the Travelling Salesman Problem (TSP). This
means that discourse ordering is NP-complete, i.e.
there are probably no polynomial algorithms for it.
Worse, our result implies that the problem is not
even approximable; any polynomial algorithm will
compute arbitrarily bad solutions on unfortunate in-
puts. Note that all approximation algorithms for the
TSP assume that the underlying cost function is a
metric, which is not the case for the coherence mea-
sures we consider.
Despite this negative result, we show that by ap-
plying modern algorithms for TSP, the discourse or-
dering problem can be solved efficiently enough for
practical applications. We define a branch-and-cut
algorithm based on linear programming, and evalu-
ate it on discourse ordering problems based on the
GNOME corpus (Karamanis, 2003) and the BLLIP
corpus (Lapata, 2003). If the local coherence mea-
sure depends only on the adjacent pairs of sentences
in the discourse, we can order discourses of up to 50
sentences in under a second. If it is allowed to de-
pend on the left-hand context of the sentence pair,
computation is often still efficient, but can become
expensive.
The structure of the paper is as follows. We will
first formally define the discourse ordering problem
and relate our definition to the literature on local co-
herence measures in Section 2. Then we will prove
the equivalence of discourse ordering and TSP (Sec-
tion 3), and present algorithms for solving it in Sec-
tion 4. Section 5 evaluates our algorithms on exam-
ples from the literature. We compare our approach
to various others in Section 6, and then conclude in
Section 7.
2 The Discourse Ordering Problem
We will first give a formal definition of the prob-
lem of computing locally coherent discourses, and
demonstrate how some local coherence measures
from the literature fit into this framework.
2.1 Definitions
We assume that a discourse is made up of discourse
units (depending on the underlying theory, these
could be utterances, sentences, clauses, etc.), which
must be ordered to achieve maximum local coher-
ence. We call the problem of computing the optimal
ordering the discourse ordering problem.
We formalise the problem by assigning a cost to
each unit-to-unit transition, and a cost for the dis-
course to start with a certain unit. Transition costs
may depend on the local context, i.e. a fixed num-
ber of discourse units to the left may influence the
cost of a transition. The optimal ordering is the one
which minimises the sum of the costs.
Definition 1. A d-place transition cost function for
a set U of discourse units is a function cT : Ud ?
R. Intuitively, cT (un|u1, . . . , ud?1) is the cost of
the transition (ud?1, ud) given that the immediately
preceding units were u1, . . . , ud?2.
A d-place initial cost function for U is a function
cI : Ud ? R. Intuitively, cI(u1, . . . , ud) is the
cost for the fact that the discourse starts with the
sequence u1, . . . , ud.
The d-place discourse ordering problem is de-
fined as follows: Given a set U = {u1, . . . , un},
a d-place transition cost function cT and a (d ? 1)-
place initial cost function cI , compute a permutation
pi of {1, . . . , n} such that
cI(upi(1), . . . , upi(d?1))
+
n?d+1?
i=1
cT (upi(i+d?1)|upi(i), . . . , upi(i+d?2))
is minimal.
The notation for the cost functions is suggestive:
The transition cost function has the character of a
conditional probability, which specifies that the cost
of continuing the discourse with the unit ud depends
on the local context u1, . . . , ud?1. This local con-
text is not available for the first d ? 1 units of the
discourse, which is why their costs are summarily
covered by the initial function.
2.2 Centering-Based Cost Functions
One popular class of coherence measures is based
on Centering Theory (CT, (Walker et al, 1998)). We
will briefly sketch its basic notions and then show
how some CT-based coherence measures can be cast
into our framework.
The standard formulation of CT e.g. in (Walker et
al., 1998), calls the discourse units utterances, and
assigns to each utterance ui in the discourse a list
Cf(ui) of forward-looking centres. The members
of Cf(ui) correspond to the referents of the NPs
in ui and are ranked in order of prominence, the
first element being the preferred centre Cp(ui). The
backward-looking centre Cb(ui) of ui is defined as
the highest ranked element of Cf(ui) which also ap-
pears in Cf(ui?1), and serves as the link between
the two subsequent utterances ui?1 and ui. Each
utterance has at most one Cb. If ui and ui?1 have
no forward-looking centres in common, or if ui is
the first utterance in the discourse, then ui does not
have a Cb at all.
Based on these concepts, CT classifies the tran-
sitions between subsequent utterances into differ-
ent types. Table 1 shows the most common clas-
sification into the four types CONTINUE, RETAIN,
SMOOTH-SHIFT, and ROUGH-SHIFT, which are pre-
dicted to be less and less coherent in this order
(Brennan et al, 1987). Kibble and Power (2000)
define three further classes of transitions: COHER-
ENCE and SALIENCE, which are both defined in Ta-
ble 1 as well, and NOCB, the class of transitions
for which Cb(ui) is undefined. Finally, a transition
is considered to satisfy the CHEAPNESS constraint
(Strube and Hahn, 1999) if Cb(ui) = Cp(ui?1).
Table 2 summarises some cost functions from the
literature, in the reconstruction of Karamanis et al
(2004). Each line shows the name of the coherence
measure, the arity d from Definition 1, and the ini-
tial and transition cost functions. To fit the defini-
tions in one line, we use terms of the form fk, which
abbreviate applications of f to the last k arguments
of the cost functions, i.e. f(ud?k+1, . . . , ud).
The most basic coherence measure, M.NOCB
(Karamanis and Manurung, 2002), simply assigns
to each NOCB transition the cost 1 and to every other
transition the cost 0. The definition of cT (u2|u1),
which decodes to nocb(u1, u2), only looks at the
two units in the transition, and no further context.
The initial costs for this coherence measure are al-
ways zero.
The measure M.KP (Kibble and Power, 2000)
sums the value of nocb and the values of three func-
tions which evaluate to 0 if the transition is cheap,
salient, or coherent, and 1 otherwise. This is an in-
stance of the 3-place discourse ordering problem be-
cause COHERENCE depends on Cb(ui?1), which it-
self depends on Cf(ui?2); hence nocoh must take
COHERENCE: COHERENCE?:
Cb(ui) = Cb(ui?1) Cb(ui) 6= Cb(ui?1)
SALIENCE: Cb(ui) = Cp(ui) CONTINUE SMOOTH-SHIFT
SALIENCE?: Cb(ui) 6= Cp(ui) RETAIN ROUGH-SHIFT
Table 1: COHERENCE, SALIENCE and the table of standard transitions
d initial cost cI(u1, . . . , ud?1) transition cost cT (ud|u1, . . . , ud?1)
M.NOCB 2 0 nocb2
M.KP 3 nocb2 + nocheap2 + nosal2 nocb2 + nocheap2 + nosal2 + nocoh3
M.BFP 3 (1? nosal2, nosal2, 0, 0) (cont3, ret3, ss3, rs3)
M.LAPATA 2 ? logP (u1) ? logP (u2|u1)
Table 2: Some cost functions from the literature.
three arguments.
Finally, the measure M.BFP (Brennan et al,
1987) uses a lexicographic ordering on 4-tuples
which indicate whether the transition is a CON-
TINUE, RETAIN, SMOOTH-SHIFT, or ROUGH-
SHIFT. cT and all four functions it is computed from
take three arguments because the classification de-
pends on COHERENCE. As the first transition in the
discourse is coherent by default (it has no Cb), we
can compute cI by distinguishing RETAIN and CON-
TINUE via SALIENCE. The tuple-valued cost func-
tions can be converted to real-valued functions by
choosing a sufficiently large number M and using
the value M3 ? cont + M2 ? ret + M ? ss + rs.
2.3 Probability-Based Cost Functions
A fundamentally different approach to measure dis-
course coherence was proposed by Lapata (2003).
It uses a statistical bigram model that assigns each
pair ui, uk of utterances a probability P (uk|ui) of
appearing in subsequent positions, and each utter-
ance a probability P (ui) of appearing in the initial
position of the discourse. The probabilities are es-
timated on the grounds of syntactic features of the
discourse units. The probability of the entire dis-
course u1 . . . un is the product P (u1) ? P (u2|u1) ?
. . . ? P (un|un?1).
We can transform Lapata?s model straightfor-
wardly into our cost function framework, as shown
under M.LAPATA in Table 2. The discourse that
minimizes the sum of the negative logarithms will
also maximise the product of the probabilities. We
have d = 2 because it is a bigram model in which
the transition probability does not depend on the
previous discourse units.
3 Equivalence of Discourse Ordering and
TSP
Now we show that discourse ordering and the travel-
ling salesman problem are equivalent. In order to do
this, we first redefine discourse ordering as a graph
problem.
d-place discourse ordering problem (dPDOP):
Given a directed graph G = (V,E), a node
s ? V and a function c : V d ? R, compute a
simple directed path P = (s = v0, v1, . . . , vn)
from s through all vertices in V which min-
imises
?n?d+1
i=0 c(vi, vi+1, . . . , vi+d?1). We
write instances of dPDOP as (V,E, s, c).
The nodes v1, . . . , vn correspond to the discourse
units. The cost function c encodes both the initial
and the transition cost functions from Section 2 by
returning the initial cost if its first argument is the
(new) start node s.
Now let?s define the version of the travelling
salesman problem we will use below.
Generalised asymmetric TSP (GATSP): Given a
directed graph G = (V,E), edge weights c :
E ? R, and a partition (V1, . . . , Vk) of the
nodes V , compute the shortest directed cycle
that visits exactly one node of each Vi. We
call such a cycle a tour and write instances of
GATSP as ((V1, . . . , Vk), E, c).
The usual definition of the TSP, in which every
node must be visited exactly once, is the special
case of GATSP where each Vi contains exactly one
node. We call this case asymmetric travelling sales-
man problem, ATSP.
ATSP 2PDOP
 


 
 


Figure 1: Reduction of ATSP to 2PDOP
We will show that ATSP can be reduced to
2PDOP, and that any dPDOP can be reduced to
GATSP.
3.1 Reduction of ATSP to 2PDOP
First, we introduce the reduction of ATSP to
2PDOP, which establishes NP-completeness of
dPDOP for all d > 1. The reduction is approxi-
mation preserving, i.e. if we can find a solution of
2PDOP that is worse than the optimum only by a
factor of  (an -approximation), it translates to a
solution of ATSP that is also an -approximation.
Since it is known that there can be no polynomial al-
gorithms that compute -approximations for general
ATSP, for any  (Cormen et al, 1990), this means
that dPDOP cannot be approximated either (unless
P=NP): Any polynomial algorithm for dPDOP will
compute arbitrarily bad solutions on certain inputs.
The reduction works as follows. Let G =
((V1, . . . , Vk), E, c) be an instance of ATSP, and
V = V1 ? . . . ? Vk. We choose an arbitrary node
v ? V and split it into two nodes vs and vt. We as-
sign all edges with source node v to vs and all edges
with target node v to vt (compare Figure 1). Finally
we make vs the source node of our 2PDOP instance
G?.
For every tour in G, we have a path in G? starting
at vs visiting all other nodes (and ending in vt) with
the same cost by replacing the edge (v, u) out of
v by (vs, u) and the edge (w, v) into v by (w, vt).
Conversely, for every path starting at vs visiting all
nodes, we have an ATSP tour of the same cost, since
all such paths will end in vt (as vt has no outgoing
edges).
An example is shown in Fig. 1. The ATSP in-
stance on the left has the tour (1, 3, 2, 1), indicated
by the solid edges. The node 1 is split into the two
nodes 1s and 1t, and the tour translates to the path
(1s, 3, 2, 1t) in the 2PDOP instance.
3.2 Reduction of dPDOP to GATSP
Conversely, we can encode an instance G =
(V,E, s, c) of dPDOP as an instance G? =
3PDOP GATSP
 
 
 

	 

 

 
	
 

	 

 

 
  
Figure 2: Reduction of dPDOP to GATSP. Edges to
the source node [s, s] are not drawn.
((V ?u)u?V , E
?, c?) of GATSP, in such a way that the
optimal solutions correspond. The cost of traversing
an edge in dPDOP depends on the previous d ? 1
nodes; we compress these costs into ordinary costs
of single edges in the reduction to GATSP.
The GATSP instance has a node [u1, . . . , ud?1]
for every d ? 1-tuple of nodes of V . It has an edge
from [u1, . . . , ud?1] to [u2, . . . , ud?1, ud] iff there
is an edge from ud?1 to ud in G, and it has an edge
from each node into [s, . . . , s]. The idea is to en-
code a path P = (s = u0, u1, . . . , un) in G as
a tour TP in G? that successively visits the nodes
[ui?d+1, . . . ui], i = 0, . . . n, where we assume that
uj = s for all j ? 0 (compare Figure 2).
The cost of TP can be made equal to the cost of P
by making the cost of the edge from [u1, . . . , ud?1]
to [u2, . . . , ud] equal to c(u1, . . . ud). (We set c?(e)
to 0 for all edges e between nodes with first compo-
nent s and for the edges e with target node [sd?1].)
Finally, we define V ?u to be the set of all nodes in G?
with last component u. It is not hard to see that for
any simple path of length n in G, we find a tour TP
in G? with the same cost. Conversely, we can find
for every tour in G? a simple path of length n in G
with the same cost.
Note that the encoding G? will contain many un-
necessary nodes and edges. For instance, all nodes
that have no incoming edges can never be used in a
tour, and can be deleted. We can safely delete such
unnecessary nodes in a post-processing step.
An example is shown in Fig. 2. The 3PDOP
instance on the left has a path (s, 3, 1, 2), which
translates to the path ([s, s], [s, 3], [3, 1], [1, 2]) in
the GATSP instance shown on the right. This path
can be completed by a tour by adding the edge
([1, 2], [s, s]), of cost 0. The tour indeed visits each
V ?u (i.e., each column) exactly once. Nodes with last
component s which are not [s, s] are unreachable
and are not shown.
For the special case of d = 2, the GATSP is sim-
ply an ordinary ATSP. The graphs of both problems
look identical in this case, except that the GATSP
instance has edges of cost 0 from any node to the
source [s].
4 Computing Optimal Orderings
The equivalence of dPDOP and GATSP implies that
we can now bring algorithms from the vast litera-
ture on TSP to bear on the discourse ordering prob-
lem. One straightforward method is to reduce the
GATSP further to ATSP (Noon and Bean, 1993);
for the case d = 2, nothing has to be done. Then
one can solve the reduced ATSP instance; see (Fis-
chetti et al, 2001; Fischetti et al, 2002) for a recent
survey of exact methods.
We choose the alternative of developing a new
algorithm for solving GATSP directly, which uses
standard techniques from combinatorial optimisa-
tion, gives us a better handle on optimising the al-
gorithm for our problem instances, and runs more
efficiently in practice. Our algorithm translates
the GATSP instance into an integer linear pro-
gram (ILP) and uses the branch-and-cut method
(Nemhauser and Wolsey, 1988) to solve it. Integer
linear programs consist of a set of linear equations
and inequalities, and are solved by integer variable
assignments which maximise or minimise a goal
function while satisfying the other conditions.
Let G = (V,E) be a directed graph and S ? V .
We define ?+(S) = {(u, v) ? E | u ? S and v 6?
S} and ??(S) = {(u, v) ? E | u /? S and v ? S},
i.e. ?+(S) and ??(S) are the sets of all incoming
and outgoing edges of S, respectively. We assume
that the graph G has no edges within one partition
Vu, since such edges cannot be used by any solution.
With this assumption, GATSP can be phrased as an
ILP as follows (this formulation is similar to the one
proposed by Laporte et al (1987)):
min
?
e?E
cexe
s.t.
?
e??+(v)
xe =
?
e???(v)
xe ? v ? V (1)
?
e???(Vi)
xe = 1 1 ? i ? n (2)
?
e??+(?i?IVi)
xe ? 1 I ? {1, . . . , n} (3)
xe ? {0, 1}
We have a binary variable xe for each edge e of
the graph. The intention is that xe has value 1 if
e is used in the tour, and 0 otherwise. Thus the
cost of the tour can be written as
?
e?E cexe. The
three conditions enforce the variable assignment to
encode a valid GATSP tour. (1) ensures that all inte-
ger solutions encode a set of cycles. (2) guarantees
that every partition Vi is visited by exactly one cy-
cle. The inequalities (3) say that every subset of the
partitions has an outgoing edge; this makes sure a
solution encodes one cycle, rather than a set of mul-
tiple cycles.
To solve such an ILP using the branch-and-cut
method, we drop the integrality constraints (i.e. we
replace xe ? {0, 1} by 0 ? xe ? 1) and solve
the corresponding linear programming (LP) relax-
ation. If the solution of the LP is integral, we found
the optimal solution. Otherwise we pick a variable
with a fractional value and split the problem into
two subproblems by setting the variable to 0 and 1,
respectively. We solve the subproblems recursively
and disregard a subproblem if its LP bound is worse
than the best known solution.
Since our ILP contains an exponential number of
inequalities of type (3), solving the complete LPs
directly would be too expensive. Instead, we start
with a small subset of these inequalities, and test
(efficiently) whether a solution of the smaller LP
violates an inequality which is not in the current
LP. If so, we add the inequality to the LP, resolve
it, and iterate. Otherwise we found the solution of
the LP with the exponential number of inequalities.
The inequalities we add by need are called cutting
planes; algorithms that find violated cutting planes
are called separation algorithms.
To keep the size of the branch-and-cut tree small,
our algorithm employs some heuristics to find fur-
ther upper bounds. In addition, we improve lower
bound from the LP relaxations by adding further in-
equalities to the LP that are valid for all integral so-
lutions, but can be violated for optimal solutions of
the LP. One major challenge here was to find separa-
tion algorithms for these inequalities. We cannot go
into these details for lack of space, but will discuss
them in a separate paper.
5 Evaluation
We implemented the algorithm and ran it on some
examples to evaluate its practical efficiency. The
runtimes are shown in Tables 3 and 4 for an imple-
mentation using a branch-and-cut ILP solver which
is free for all academic purposes (ILP-FS) and a
commercial branch-and-cut ILP solver (ILP-CS).
Our implementations are based on LEDA 4.4.1
Instance Size ILP-FS ILP-CS
lapata-10 13 0.05 0.05
coffers1 M.NOCB 10 0.04 0.02
cabinet1 M.NOCB 15 0.07 0.01
random (avg) 20 0.09 0.07
random (avg) 40 0.28 0.17
random (avg) 60 1.39 0.40
random (avg) 100 6.17 1.97
Table 3: Some runtimes for d = 2 (in seconds).
(www.algorithmic-solutions.com) for
the data structures and the graph algorithms and
on SCIL 0.8 (www.mpi-sb.mpg.de/SCIL)
for implementing the ILP-based branch-and-cut
algorithm. SCIL can be used with different
branch-and-cut core codes. We used CPLEX
9.0 (www.ilog.com) as commercial core and
SCIP 0.68 (www.zib.de/Optimization/
Software/SCIP/) based on SOPLEX 1.2.2a
(www.zib.de/Optimization/Software/
Soplex/) as the free implementation. Note that
all our implementations are still preliminary. The
software is publicly available (www.mpi-sb.
mpg.de/?althaus/PDOP.html).
We evaluate the implementations on three classes
of inputs. First, we use two discourses from the
GNOME corpus, taken from (Karamanis, 2003), to-
gether with the centering-based cost functions from
Section 2: coffers1, containing 10 discourse units,
and cabinet1, containing 15 discourse units. Sec-
ond, we use twelve discourses from the BLLIP
corpus taken from (Lapata, 2003), together with
M.LAPATA. These discourses are 4 to 13 discourse
units long; the table only shows the instance with
the highest running time. Finally, we generate ran-
dom instances of 2PDOP of size 20?100, and of
3PDOP of size 10, 15, and 20. A random instance is
the complete graph, where c(u1, . . . , ud) is chosen
uniformly at random from {0, . . . , 999}.
The results for the 2-place instances are shown
in Table 3, and the results for the 3-place instances
are shown in Table 4. The numbers are runtimes in
seconds on a Pentium 4 (Xeon) processor with 3.06
GHz. Note that a hypothetical baseline implementa-
tion which naively generates and evaluates all per-
mutations would run over 77 years for a discourse
of length 20, even on a highly optimistic platform
that evaluates one billion permutations per second.
For d = 2, all real-life instances and all random
instances of size up to 50 can be solved in less than
one second, with either implementation. The prob-
lem becomes more challenging for d = 3. Here the
algorithm quickly establishes good LP bounds for
Instance Size ILP-FS ILP-CS
coffers1 M.KP 10 0.05 0.05
coffers1 M.BFP 10 0.08 0.06
cabinet1 M.KP 15 0.40 1.12
cabinet1 M.BFP 15 0.39 0.28
random (avg) 10 1.00 0.42
random (avg) 15 35.1 5.79
random (avg) 20 - 115.8
Table 4: Some runtimes for d = 3 (in seconds).
the real-life instances, and thus the branch-and-cut
trees remain small. The LP bounds for the random
instances are worse, in particular when the number
of units gets larger. In this case, the further opti-
misations in the commercial software make a big
difference in the size of the branch-and-cut tree and
thus in the solution time.
An example output for cabinet1 with M.NOCB
is shown in Fig. 3; we have modified referring ex-
pressions to make the text more readable, and have
marked discourse unit boundaries with ?/? and ex-
pressions that establish local coherence with square
brackets. This is one of many possible optimal so-
lutions, which have cost 2 because of the two NOCB
transitions at the very start of the discourse. Details
on the comparison of different centering-based co-
herence measures are discussed by Karamanis et al
(2004).
6 Comparison to Other Approaches
There are two approaches in the literature that are
similar enough to ours that a closer comparison is
in order.
The first is a family of algorithms for discourse
ordering based on genetic programming (Mellish et
al., 1998; Karamanis and Manurung, 2002). This is
a very flexible and powerful approach, which can be
applied to measures of local coherence that do not
seem to fit in our framework trivially. For exam-
ple, the measure from (Mellish et al, 1998) looks at
the entire discourse up to the current transition for
some of their cost factors. However, our algorithm
is several orders of magnitude faster where a direct
comparison is possible (Manurung, p.c.), and it is
guaranteed to find an optimal ordering. The non-
approximability result for TSP means that a genetic
(or any other) algorithm which is restricted to poly-
nomial runtime could theoretically deliver arbitrar-
ily bad solutions.
Second, the discourse ordering problem we have
discussed in this paper looks very similar to the Ma-
jority Ordering problem that arises in the context
of multi-document summarisation (Barzilay et al,
Both cabinets probably entered England in the early nineteenth century / after the French Revolution caused
the dispersal of so many French collections. / The pair to [this monumental cabinet] still exists in Scotland.
/ The fleurs-de-lis on the top two drawers indicate that [the cabinet] was made for the French King Louis
XIV. / [It] may have served as a royal gift, / as [it] does not appear in inventories of [his] possessions. /
Another medallion inside shows [him] a few years later. / The bronze medallion above [the central door]
was cast from a medal struck in 1661 which shows [the king] at the age of twenty-one. / A panel of marquetry
showing the cockerel of [France] standing triumphant over both the eagle of the Holy Roman Empire and the
lion of Spain and the Spanish Netherlands decorates [the central door]. / In [the Dutch Wars] of 1672 - 1678,
[France] fought simultaneously against the Dutch, Spanish, and Imperial armies, defeating them all. / [The
cabinet] celebrates the Treaty of Nijmegen, which concluded [the war]. / The Sun King?s portrait appears
twice on [this work]. / Two large figures from Greek mythology, Hercules and Hippolyta, Queen of the
Amazons, representatives of strength and bravery in war appear to support [the cabinet]. / The decoration on
[the cabinet] refers to [Louis XIV?s] military victories. / On the drawer above the door, gilt-bronze military
trophies flank a medallion portrait of [the king].
Figure 3: An example output based on M.NOCB.
2002). The difference between the two problems is
that Barzilay et al minimise the sum of all costs
Cij for any pair i, j of discourse units with i < j,
whereas we only sum over the Cij for i = j ? 1.
This makes their problem amenable to the approxi-
mation algorithm by Cohen et al (1999), which al-
lows them to compute a solution that is at least half
as good as the optimum, in polynomial time; i.e.
this problem is strictly easier than TSP or discourse
ordering. However, a Majority Ordering algorithm
is not guaranteed to compute good solutions to the
discourse ordering problem, as Lapata (2003) as-
sumes.
7 Conclusion
We have shown that the problem of ordering clauses
into a discourse that maximises local coherence is
equivalent to the travelling salesman problem: Even
the two-place discourse ordering problem can en-
code ATSP. This means that the problem is NP-
complete and doesn?t even admit polynomial ap-
proximation algorithms (unless P=NP).
On the other hand, we have shown how to encode
the discourse ordering problems of arbitrary arity
d into GATSP. We have demonstrated that mod-
ern branch-and-cut algorithms for GATSP can eas-
ily solve practical discourse ordering problems if
d = 2, and are still usable for many instances with
d = 3. As far as we are aware, this is the first al-
gorithm for discourse ordering that can make any
guarantees about the solution it computes.
Our efficient implementation can benefit genera-
tion and summarisation research in at least two re-
spects. First, we show that computing locally co-
herent orderings of clauses is feasible in practice,
as such coherence measures will probably be ap-
plied on sentences within the same paragraph, i.e.
on problem instances of limited size. Second, our
system should be a useful experimentation tool in
developing new measures of local coherence.
We have focused on local coherence in this paper,
but it seems clear that notions of global coherence,
which go beyond the level of sentence-to-sentence
transitions, capture important aspects of coherence
that a purely local model cannot. However, our al-
gorithm can still be useful as a subroutine in a more
complex system that deals with global coherence
(Marcu, 1997; Mellish et al, 1998). Whether our
methods can be directly applied to the tree struc-
tures that come up in theories of global coherence is
an interesting question for future research.
Acknowledgments. We would like to thank
Mirella Lapata for providing the experimental data
and Andrea Lodi for providing an efficiency base-
line by running his ATSP solver on our inputs. We
are grateful to Malte Gabsdil, Ruli Manurung, Chris
Mellish, Kristina Striegnitz, and our reviewers for
helpful comments and discussions.
References
R. Barzilay, N. Elhadad, and K. R. McKeown.
2002. Inferring strategies for sentence ordering
in multidocument news summarization. Journal
of Artificial Intelligence Research, 17:35?55.
S. Brennan, M. Walker Friedman, and C. Pollard.
1987. A centering approach to pronouns. In
Proc. 25th ACL, pages 155?162, Stanford.
W. Cohen, R. Schapire, and Y. Singer. 1999. Learn-
ing to order things. Journal of Artificial Intelli-
gence Research, 10:243?270.
T. H. Cormen, C. E. Leiserson, and R. L. Rivest.
1990. Introduction to Algorithms. MIT Press,
Cambridge.
M. Fischetti, A. Lodi, and P. Toth. 2001. Solv-
ing real-world ATSP instances by branch-and-
cut. Combinatorial Optimization.
M. Fischetti, A. Lodi, and P. Toth. 2002. Exact
methods for the asymmmetric traveling salesman
problem. In G. Gutin and A. Punnen, editors, The
Traveling Salesman Problem and its Variations.
Kluwer.
N. Karamanis and H. M. Manurung. 2002.
Stochastic text structuring using the principle of
continuity. In Proceedings of INLG-02, pages
81?88, New York.
N. Karamanis, M. Poesio, C. Mellish, and J. Ober-
lander. 2004. Evaluating centering-based met-
rics of coherence for text structuring using a re-
liably annotated corpus. In Proceedings of the
42nd ACL, Barcelona.
N. Karamanis. 2003. Entity Coherence for De-
scriptive Text Structuring. Ph.D. thesis, Division
of Informatics, University of Edinburgh.
R. Kibble and R. Power. 2000. An integrated
framework for text planning and pronominalisa-
tion. In Proc. INLG 2000, pages 77?84, Mitzpe
Ramon.
M. Lapata. 2003. Probabilistic text structuring: Ex-
periments with sentence ordering. In Proc. 41st
ACL, pages 545?552, Sapporo, Japan.
G. Laporte, H. Mercure, and Y. Nobert. 1987. Gen-
eralized travelling salesman problem through n
sets of nodes: the asymmetrical case. Discrete
Applied Mathematics, 18:185?197.
W. Mann and S. Thompson. 1988. Rhetorical struc-
ture theory: A theory of text organization. Text,
8(3):243?281.
D. Marcu. 1997. From local to global coherence:
A bottom-up approach to text planning. In Pro-
ceedings of the 14th AAAI, pages 629?635.
C. Mellish, A. Knott, J. Oberlander, and
M. O?Donnell. 1998. Experiments using
stochastic search for text planning. In Proc. 9th
INLG, pages 98?107, Niagara-on-the-Lake.
G.L. Nemhauser and L.A. Wolsey. 1988. Integer
and Combinatorial Optimization. John Wiley &
Sons.
C.E. Noon and J.C. Bean. 1993. An efficient trans-
formation of the generalized traveling salesman
problem. Information Systems and Operational
Research, 31(1).
M. Strube and U. Hahn. 1999. Functional center-
ing: Grounding referential coherence in informa-
tion structure. Computational Linguistics, 25(3).
M. Walker, A. Joshi, and E. Prince. 1998. Center-
ing in naturally occuring discourse: An overview.
In M. Walker, A. Joshi, and E. Prince, edi-
tors, Centering Theory in Discourse, pages 1?30.
Clarendon Press, Oxford.
B. Webber, A. Knott, M. Stone, and A. Joshi. 1999.
What are little trees made of: A structural and
presuppositional account using Lexicalized TAG.
In Proc. 36th ACL, pages 151?156, College Park.
Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 9?12, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Efficient solving and exploration of scope ambiguities
Alexander Koller and Stefan Thater
Department of Computational Linguistics
Saarland University, Saarbr?cken, Germany
{koller,stth}@coli.uni-sb.de
Abstract
We present the currently most efficient
solver for scope underspecification; it also
converts between different underspecifica-
tion formalisms and counts readings. Our
tool makes the practical use of large-scale
grammars with (underspecified) semantic
output more feasible, and can be used in
grammar debugging.
1 Introduction
One of the most exciting recent developments in
computational linguistics is that large-scale gram-
mars which compute semantic representations are
becoming available. Examples for such grammars
are the HPSG English Resource Grammar (ERG)
(Copestake and Flickinger, 2000) and the LFG Par-
Gram grammars (Butt et al, 2002); a similar re-
source is being developed for the XTAG grammar
(Kallmeyer and Romero, 2004).
But with the advent of such grammars, a phe-
nomenon that is sometimes considered a some-
what artificial toy problem of theoretical semanti-
cists becomes a very practical challenge: the pres-
ence of scope ambiguities. Because grammars of-
ten uniformly treat noun phrases as quantifiers, even
harmless-looking sentences can have surprisingly
many readings. The median number of scope read-
ings for the sentences in the Rondane Treebank (dis-
tributed with the ERG) is 55, but the treebank also
contains extreme cases such as (1) below, which ac-
cording to the ERG has about 2.4 trillion (1012) read-
ings:
(1) Myrdal is the mountain terminus of the Fl?m
rail line (or Fl?msbana) which makes its way
down the lovely Fl?m Valley (Fl?msdalen) to
its sea-level terminus at Fl?m. (Rondane 650)
In order to control such an explosion of readings
(and also to simplify the grammar design process),
the developers of large-scale grammars typically use
methods of packing or underspecification to spec-
ify the syntax-semantics interface. The general idea
is that the parser doesn?t compute all the individual
scope readings, but only a compact underspecified
description, from which the individual readings can
then be extracted at a later stage of processing ? but
the underspecified description could also be used as
a platform for the integration of lexical and context
information, so as to restrict the set of possible read-
ings without enumerating the wrong ones.
Such an approach is only feasible if we have ac-
cess to efficient tools that support the most impor-
tant operations on underspecified descriptions. We
present utool, the Swiss Army Knife of Underspec-
ification, which sets out to do exactly this. It sup-
ports the following operations:
1. enumerate all scope readings represented by an
underspecified description;
2. check whether a description has any readings,
and compute how many readings it has without
explicitly enumerating them;
3. convert underspecified descriptions between
different underspecification formalisms (at this
point, Minimal Recursion Semantics (Copes-
take et al, 2003), Hole Semantics (Bos, 1996),
and dominance constraints/graphs (Egg et al,
2001; Althaus et al, 2003)).
9
Our system is the fastest solver for underspecifi-
cied description available today; that is, it is fastest
at solving Task 1 above (about 100.000 readings per
second on a modern PC). It achieves this by im-
plementing an efficient algorithm for solving dom-
inance graphs (Bodirsky et al, 2004) and caching
intermediate results in a chart data structure. To our
knowledge, it is the only system that can do Tasks
2 and 3. It is only because utool can compute the
number of readings without enumerating them that
we even know that (1) has trillions of readings; even
utool would take about a year to enumerate and
count the readings individually.
utool is implemented in C++, efficient and
portable, open source, and freely downloadable from
http://utool.sourceforge.net.
2 Technical Description
2.1 Solving dominance graphs
At the core of utool is a solver for dominance
graphs (Bodirsky et al, 2004) ? graph represen-
tations of weakly normal dominance constraints,
which constitute one of the main formalisms used
in scope underspecification (Egg et al, 2001; Al-
thaus et al, 2003). Dominance graphs are directed
graphs with two kinds of edges, tree edges and dom-
inance edges. They can be used to describe the set
of all trees into which their tree edges can be embed-
ded, in such a way that every dominance edge in the
graph is realised as reachability in the tree. Domi-
nance graphs are used as underspecified descriptions
by describing sets of trees that are encodings of the
formulas of some language of semantic representa-
tions, such as predicate logic.
Fig. 1 shows an example of a constraint graph for
the sentence ?every student reads a book.? It con-
sists of five tree fragments ? sets of nodes that are
connected by (solid) tree edges ? which are con-
nected by dominance edges (dotted lines). Two of
the fragments have two holes each, into which other
fragments can be ?plugged?. The graph can be em-
bedded into the two trees shown in the middle of
Fig. 1, which correspond to the two readings of the
sentence. By contrast, the graph cannot be embed-
ded into the tree shown on the right: a dominance
edge stipulates that ?readx,y? must be reachable from
?somey?, but it is not reachable from ?somey? in the
tree. We call the two trees into which the graph can
be embedded its solutions.
The Bodirsky et al algorithm enumerates the so-
lutions of a dominance graph (technically, its solved
forms) by computing the set of its free fragments,
which are the fragments that can occur at the root of
some solution. Then it picks one of these fragments
as the root and removes it from the graph. This splits
the graph into several connected subgraphs, which
are then solved recursively.
This algorithm can call itself for the same sub-
graph several times, which can waste a lot of time
because the set of all solutions was already com-
puted for the subgraph on the first recursive call.
For this reason, our implementation caches interme-
diate results in a chart-like data structure. This data
structure maps each subgraph G to a set of splits,
each of which records which fragment of G should
be placed at the root of the solution, what the sub-
graphs after removal of this fragment are, and how
their solutions should be plugged into the holes of
the fragment. In the worst case, the chart can have
exponential size; but in practice, it is much smaller
than the set of all solutions. For example, the chart
for (1) contains 74.960 splits, which is a tiny num-
ber compared to the 2.4 trillion readings, and can be
computed in a few seconds.
Now solving becomes a two-phase process. In the
first phase, the chart data structure is filled by a run
of the algorithm. In the second phase, the complete
solutions are extracted from the chart. Although the
first phase is conceptually much more complex than
the second one because it involves interesting graph
algorithms whose correctness isn?t trivial to prove,
it takes only a small fraction of the entire runtime in
practice.
Instead of enumerating all readings from the
chart, we can also compute the number of solutions
represented by the chart. For each split, we compute
the numbers of solutions of the fragment sets in the
split. Then we multiply these numbers (choices for
the children can be combined freely). Finally, we
obtain the number of solutions for a subgraph by
adding the numbers of solutions of all its splits. This
computation takes linear time in the size of the chart.
10
every
x
some
y
book
y
student
x
read
x,y
every
x
some
y
book
y
student
x
read
x,y
every
x
some
y
book
y
student
x
read
x,y
every
x
some
y
book
y
student
x
read
x,y
? ? ?
Figure 1: A dominance graph (left), two solutions (middle) and a non-solution (right).
2.2 Translating between formalisms
One of the most significant obstacles in the develop-
ment of tools and resources for scope underspecifi-
cation is that different resources (such as grammars
and solvers) are built for different underspecification
formalisms. To help alleviate this problem, utool
can read and write underspecified descriptions and
write out solutions in a variety of different formats:
? dominance graphs;
? descriptions of Minimal Recursion Semantics;
? descriptions of Hole Semantics.
The input and output functionality is provided
by codecs, which translate between descriptions in
one of these formalisms and the internal dominance
graph format. The codecs for MRS and Hole Se-
mantics are based on the (non-trivial) translations
in (Koller et al, 2003; Niehren and Thater, 2003)
and are only defined on nets, i.e. constraints whose
graphs satisfy certain structural restrictions. This is
not a very limiting restriction in practice (Flickinger
et al, 2005). utool also allows the user to test effi-
ciently whether a description is a net.
In practice, utool can be used to convert de-
scriptions between the three underspecification for-
malisms. Because the codecs work with concrete
syntaxes that are used in existing systems, utool
can be used as a drop-in replacement e.g. in the
LKB grammar development system (Copestake and
Flickinger, 2000).
2.3 Runtime comparison
To illustrate utool?s performance, we compare its
runtimes for the enumeration task with the (already
quite efficient) MRS constraint solver of the LKB
system (Copestake and Flickinger, 2000). Our data
set consists of the 850 MRS-nets extracted from the
 0
 10
 20
 30
 40
 50
 60
 70
 0  5  10  15  20  25  30  35  40
"utool"
"MRS"
Figure 2: Distribution of constraints in Rondane over
different sizes. The solid line shows the constraints
in the data set, and the dashed line shows the con-
straints that the LKB solver could solve.
Rondane treebank which have less than one million
solutions (see Fig. 2). Fig. 3 displays the runtimes
for enumerating all solutions, divided by the num-
ber of solutions, for both solvers. The horizontal axis
shows the description sizes (number of tree frag-
ments), and the (logarithmic!) vertical axis shows
the average runtime per solution for descriptions of
this size.
Due to memory limitations, the LKB solver could
only solve descriptions with up to 21 tree fragments,
which account for 80% of the test data. utool solved
all descriptions in the test set. The evaluation was
done using a 1.2 GHz PC with 2 GB of memory.
The figure shows that utool is generally faster
than the LKB solver, up to a factor of approx. 1000.
We should note that the LKB solver displays a dra-
matically higher variation in runtimes for constraints
of the same size. Note that for small constraints, the
runtimes tend to be too small to measure them accu-
rately.
11
 0.01
 0.1
 1
 10
 100
 1000
 0  5  10  15  20  25  30  35  40
"utool"
"MRS"
Figure 3: Runtimes per solution (in ms) for the MRS
nets in the Rondane treebank for LKB and utool.
3 Conclusion
We have presented utool, a tool that supports a va-
riety of operations related to scope underspecifica-
tion. It is the most efficient solver for underspecifi-
cation available today, and provides functionality for
counting readings, testing whether a description is a
net, and converting between different underspecifi-
cation formalisms. It collects the results of several
years of formal and computational research on dom-
inance graphs into one convenient system.
The most obvious use of utool is the enumeration
of readings of underspecified descriptions produced
by large-scale grammars. This means that a user can
realistically map the semantic output of these gram-
mars into actual semantic representations. However,
the tool is also useful for developers of such gram-
mars. It can be used to count and explore the read-
ings of the underspecified descriptions the grammar
computes, and has already been used in the debug-
ging of the syntax-semantics interface of the ERG
(Flickinger et al, 2005).
From a more general perspective, the real ap-
peal of underspecification is that it could allow us
to eliminate readings that contradict the context or
our world knowledge, without having to enumerate
these readings first. Such inferences could already
take place on the level of the underspecified descrip-
tion (Koller and Niehren, 2000). But the new chart
data structure that utool computes is a more explicit
packed representation of the possible readings, and
still relatively small in practice. Thus it could open
up avenues for more theoretical future research as
well.
References
Ernst Althaus, Denys Duchier, Alexander Koller, Kurt
Mehlhorn, Joachim Niehren, and Sven Thiel. 2003.
An efficient graph algorithm for dominance con-
straints. Journal of Algorithms, 48:194?219.
Manuel Bodirsky, Denys Duchier, Joachim Niehren, and
Sebastian Miele. 2004. An efficient algorithm for
weakly normal dominance constraints. In ACM-SIAM
Symposium on Discrete Algorithms. The ACM Press.
Johan Bos. 1996. Predicate logic unplugged. In Pro-
ceedings of the Tenth Amsterdam Colloquium, pages
133?143.
Miriam Butt, Helge Dyvik, Tracey Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The par-
allel grammar project. In Proceedings of the COLING
2002 Workshop on Grammar engeneering and evalua-
tion.
Ann Copestake and Dan Flickinger. 2000. An open-
source grammar development environment and broad-
coverage English grammar using HPSG. In Confer-
ence on Language Resources and Evaluation.
Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan
Sag. 2003. Minimal recursion semantics: An in-
troduction. Available at http://lingo.stanford.
edu/sag/papers/copestake.pdf.
Markus Egg, Alexander Koller, and Joachim Niehren.
2001. The Constraint Language for Lambda Struc-
tures. Logic, Language, and Information, 10:457?485.
Dan Flickinger, Alexander Koller, and Stefan Thater.
2005. A new well-formedness criterion for semantics
debugging. In Proceedings of the 12th HPSG Confer-
ence, Lisbon.
Laura Kallmeyer and Maribel Romero. 2004. LTAG se-
mantics with semantic unification. In Proceedings of
the TAG+7 Workshop, Vancouver.
Alexander Koller and Joachim Niehren. 2000. On un-
derspecified processing of dynamic semantics. In Pro-
ceedings of COLING-2000, Saarbr?cken.
Alexander Koller, Joachim Niehren, and Stefan Thater.
2003. Bridging the gap between underspecification
formalisms: Hole semantics as dominance constraints.
In Proceedings of the 10th EACL, Budapest.
Joachim Niehren and Stefan Thater. 2003. Bridging the
gap between underspecification formalisms: Minimal
recursion semantics as dominance constraints. In Pro-
ceedings of the 41st Annual Meeting of the Association
for Computational Linguistics.
12
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 409?416,
Sydney, July 2006. c?2006 Association for Computational Linguistics
An Improved Redundancy Elimination Algorithm
for Underspecified Representations
Alexander Koller and Stefan Thater
Dept. of Computational Linguistics
Universit?t des Saarlandes, Saarbr?cken, Germany
{koller,stth}@coli.uni-sb.de
Abstract
We present an efficient algorithm for the
redundancy elimination problem: Given
an underspecified semantic representation
(USR) of a scope ambiguity, compute an
USR with fewer mutually equivalent read-
ings. The algorithm operates on underspec-
ified chart representations which are de-
rived from dominance graphs; it can be ap-
plied to the USRs computed by large-scale
grammars. We evaluate the algorithm on
a corpus, and show that it reduces the de-
gree of ambiguity significantly while tak-
ing negligible runtime.
1 Introduction
Underspecification is nowadays the standard ap-
proach to dealing with scope ambiguities in com-
putational semantics (van Deemter and Peters,
1996; Copestake et al, 2004; Egg et al, 2001;
Blackburn and Bos, 2005). The basic idea be-
hind it is to not enumerate all possible semantic
representations for each syntactic analysis, but to
derive a single compact underspecified represen-
tation (USR). This simplifies semantics construc-
tion, and current algorithms support the efficient
enumeration of the individual semantic representa-
tions from an USR (Koller and Thater, 2005b).
A major promise of underspecification is that it
makes it possible, in principle, to rule out entire
subsets of readings that we are not interested in
wholesale, without even enumerating them. For in-
stance, real-world sentences with scope ambigui-
ties often have many readings that are semantically
equivalent. Subsequent modules (e.g. for doing in-
ference) will typically only be interested in one
reading from each equivalence class, and all oth-
ers could be deleted. This situation is illustrated
by the following two (out of many) sentences from
the Rondane treebank, which is distributed with
the English Resource Grammar (ERG; Flickinger
(2002)), a large-scale HPSG grammar of English.
(1) For travellers going to Finnmark there is a
bus service from Oslo to Alta through Swe-
den. (Rondane 1262)
(2) We quickly put up the tents in the lee of a
small hillside and cook for the first time in
the open. (Rondane 892)
For the annotated syntactic analysis of (1), the
ERG derives an USR with eight scope bearing op-
erators, which results in a total of 3960 readings.
These readings are all semantically equivalent to
each other. On the other hand, the USR for (2) has
480 readings, which fall into two classes of mutu-
ally equivalent readings, characterised by the rela-
tive scope of ?the lee of? and ?a small hillside.?
In this paper, we present an algorithm for the
redundancy elimination problem: Given an USR,
compute an USR which has fewer readings, but
still describes at least one representative of each
equivalence class ? without enumerating any read-
ings. This algorithm makes it possible to compute
the one or two representatives of the semantic
equivalence classes in the examples, so subsequent
modules don?t have to deal with all the other equiv-
alent readings. It also closes the gap between the
large number of readings predicted by the gram-
mar and the intuitively perceived much lower de-
gree of ambiguity of these sentences. Finally, it
can be helpful for a grammar designer because it
is much more feasible to check whether two read-
ings are linguistically reasonable than 480. Our al-
gorithm is applicable to arbitrary USRs (not just
those computed by the ERG). While its effect is
particularly significant on the ERG, which uni-
formly treats all kinds of noun phrases, including
proper names and pronouns, as generalised quanti-
fiers, it will generally help deal with spurious ambi-
guities (such as scope ambiguities between indef-
409
inites), which have been a ubiquitous problem in
most theories of scope since Montague Grammar.
We model equivalence in terms of rewrite rules
that permute quantifiers without changing the se-
mantics of the readings. The particular USRs we
work with are underspecified chart representations,
which can be computed from dominance graphs
(or USRs in some other underspecification for-
malisms) efficiently (Koller and Thater, 2005b).
We evaluate the performance of the algorithm on
the Rondane treebank and show that it reduces the
median number of readings from 56 to 4, by up
to a factor of 666.240 for individual USRs, while
running in negligible time.
To our knowledge, our algorithm and its less
powerful predecessor (Koller and Thater, 2006)
are the first redundancy elimination algorithms in
the literature that operate on the level of USRs.
There has been previous research on enumerating
only some representatives of each equivalence
class (Vestre, 1991; Chaves, 2003), but these
approaches don?t maintain underspecification:
After running their algorithms, they are left with
a set of readings rather than an underspecified
representation, i.e. we could no longer run other
algorithms on an USR.
The paper is structured as follows. We will first de-
fine dominance graphs and review the necessary
background theory in Section 2. We will then intro-
duce our notion of equivalence in Section 3, and
present the redundancy elimination algorithm in
Section 4. In Section 5, we describe the evaluation
of the algorithm on the Rondane corpus. Finally,
Section 6 concludes and points to further work.
2 Dominance graphs
The basic underspecification formalism we as-
sume here is that of (labelled) dominance graphs
(Althaus et al, 2003). Dominance graphs are
equivalent to leaf-labelled normal dominance con-
straints (Egg et al, 2001), which have been dis-
cussed extensively in previous literature.
Definition 1. A (compact) dominance graph is a
directed graph (V,E unionmultiD) with two kinds of edges,
tree edges E and dominance edges D, such that:
1. The graph (V,E) defines a collection of node
disjoint trees of height 0 or 1. We call the
trees in (V,E) the fragments of the graph.
2. If (v,v?) is a dominance edge in D, then v is
a hole and v? is a root. A node v is a root if v
does not have incoming tree edges; otherwise,
v is a hole.
A labelled dominance graph over a ranked sig-
nature ? is a triple G = (V,E unionmultiD,L) such that
(V,E unionmultiD) is a dominance graph and L : V  ?
is a partial labelling function which assigns a node
v a label with arity n iff v is a root with n outgoing
tree edges. Nodes without labels (i.e. holes) must
have outgoing dominance edges.
We will write R(F) for the root of the fragment
F , and we will typically just say ?graph? instead
of ?labelled dominance graph?.
An example of a labelled dominance graph is
shown to the left of Fig. 1. Tree edges are drawn
as solid lines, and dominance edges as dotted lines,
directed from top to bottom. This graph can serve
as an USR for the sentence ?a representative of
a company saw a sample? if we demand that the
holes are ?plugged? by roots while realising the
dominance edges as dominance, as in the two con-
figurations (of five) shown to the right. These con-
figurations are trees that encode semantic represen-
tations of the sentence. We will freely read config-
urations as ground terms over the signature ?.
2.1 Hypernormally connected graphs
Throughout this paper, we will only consider hy-
pernormally connected (hnc) dominance graphs.
Hnc graphs are equivalent to chain-connected
dominance constraints (Koller et al, 2003), and
are closely related to dominance nets (Niehren and
Thater, 2003). Fuchss et al (2004) have presented
a corpus study that strongly suggests that all dom-
inance graphs that are generated by current large-
scale grammars are (or should be) hnc.
Technically, a graph G is hypernormally con-
nected iff each pair of nodes is connected by a sim-
ple hypernormal path in G. A hypernormal path
(Althaus et al, 2003) in G is a path in the undi-
rected version Gu of G that does not use two dom-
inance edges that are incident to the same hole.
Hnc graphs have a number of very useful struc-
tural properties on which this paper rests. One
which is particularly relevant here is that we can
predict in which way different fragments can dom-
inate each other.
Definition 2. Let G be a hnc dominance graph. A
fragment F1 in G is called a possible dominator
of another fragment F2 in G iff it has exactly one
hole h which is connected to R(F2) by a simple hy-
410
ay
sample
y
see
x,y
a
x
repr-of
x,z
a
z
comp
z
1 2 3
4 5 6
7
a
y
a
x
a
z
1
2
3
sample
y
see
x,y
repr-of
x,z
comp
z
a
y
a
x
sample
y
see
x,y
repr-of
x,z
a
z
comp
z
1
2
3
Figure 1: A dominance graph that represents the five readings of the sentence ?a representative of a
company saw a sample? (left) and two of its five configurations.
{1,2,3,4,5,6,7} :?1,h1 7? {4},h2 7? {2,3,5,6,7}?
?2,h3 7? {1,4,5},h4 7? {3,6,7}?
?3,h5 7? {5},h6 7? {1,2,4,5,7}?
{2,3,5,6,7} :?2,h3 7? {5},h4 7? {3,6,7}?
?3,h5 7? {6},h6 7? {2,5,7}?
{3,6,7} :?3,h5 7? {6},h6 7? {7}?
{2,5,7} :?2,h3 7? {5},h4 7? {7}?
{1,4,5} :?1,h1 7? {4},h2 7? {5}?
{1,2,4,5,7} :?1,h1 7? {4},h2 7? {2,5,7}?
?2,h3 7? {1,4,5},h4 7? {7}?
Figure 2: The chart for the graph in Fig. 1.
pernormal path which doesn?t use R(F1). We write
ch(F1,F2) for this unique h.
Lemma 1 (Koller and Thater (2006)). Let F1, F2
be fragments in a hnc dominance graph G. If there
is a configurationC ofG in which R(F1) dominates
R(F2), then F1 is a possible dominator of F2, and
in particular ch(F1,F2) dominates R(F2) inC.
By applying this rather abstract result, we can
derive a number of interesting facts about the ex-
ample graph in Fig. 1. The fragments 1, 2, and 3
are possible dominators of all other fragments (and
of each other), while the fragments 4 through 7
aren?t possible dominators of anything (they have
no holes); so 4 through 7 must be leaves in any con-
figuration of the graph. In addition, if fragment 2
dominates fragment 3 in any configuration, then in
particular the right hole of 2 will dominate the root
of 3; and so on.
2.2 Dominance charts
Below we will not work with dominance graphs
directly. Rather, we will use dominance charts
(Koller and Thater, 2005b) as our USRs: they are
more explicit USRs, which support a more fine-
grained deletion of reading sets than graphs.
A dominance chart for the graph G is a mapping
of weakly connected subgraphs of G to sets of
splits (see Fig. 2), which describe possible ways
of constructing configurations of the subgraph.
A subgraph G? is assigned one split for each
fragment F in G? which can be at the root of a
configuration of G?. If the graph is hnc, removing
F from the graph splits G? into a set of weakly
connected components (wccs), each of which is
connected to exactly one hole of F . We also record
the wccs, and the hole to which each wcc belongs,
in the split. In order to compute all configurations
represented by a split, we can first compute
recursively the configurations of each component;
then we plug each combination of these sub-
configurations into the appropriate holes of the
root fragment. We define the configurations asso-
ciated with a subgraph as the union over its splits,
and those of the entire chart as the configurations
associated with the complete graph.
Fig. 2 shows the dominance chart correspond-
ing to the graph in Fig. 1. The chart represents
exactly the configuration set of the graph, and is
minimal in the sense that every subgraph and ev-
ery split in the chart can be used in constructing
some configuration. Such charts can be computed
efficiently (Koller and Thater, 2005b) from a dom-
inance graph, and can also be used to compute the
configurations of a graph efficiently.
The example chart expresses that three frag-
ments can be at the root of a configuration of the
complete graph: 1, 2, and 3. The entry for the split
with root fragment 2 tells us that removing 2 splits
the graph into the subgraphs {1,4,5} and {3,6,7}
(see Fig. 3). If we configure these two subgraphs
recursively, we obtain the configurations shown in
the third column of Fig. 3; we can then plug these
sub-configurations into the appropriate holes of 2
and obtain a configuration for the entire graph.
Notice that charts can be exponentially larger
than the original graph, but they are still expo-
nentially smaller than the entire set of readings
because common subgraphs (such as the graph
{2,5,7} in the example) are represented only once,
411
1 2 3
4 5 6 7
h
2
h
1
h
4
h
3
h
6
h
5
1 3
4 5 6 7
h
2
h
1
h
6
h
5
? ?
1 3
4 5 6 7
2
1 3
4 5 6 7
?
Figure 3: Extracting a configuration from a chart.
and are small in practice (see (Koller and Thater,
2005b) for an analysis). Thus the chart can still
serve as an underspecified representation.
3 Equivalence
Now let?s define equivalence of readings more
precisely. Equivalence of semantic representations
is traditionally defined as the relation between
formulas (say, of first-order logic) which have
the same interpretation. However, even first-order
equivalence is an undecidable problem, and broad-
coverage semantic representations such as those
computed by the ERG usually have no well-
defined model-theoretic semantics and therefore
no concept of semantic equivalence.
On the other hand, we do not need to solve
the full semantic equivalence problem, as we only
want to compare formulas that are readings of the
same sentence, i.e. different configurations of the
same USR. Such formulas only differ in the way
that the fragments are combined. We can therefore
approximate equivalence by using a rewrite system
that permutes fragments and defining equivalence
of configurations as mutual rewritability as usual.
By way of example, consider again the two con-
figurations shown in Fig. 1. We can obtain the sec-
ond configuration from the (semantically equiva-
lent) first one by applying the following rewrite
rule, which rotates the fragments 1 and 2:
ax(az(P,Q),R)? az(P,ax(Q,R)) (3)
Thus we take these two configurations to be
equivalent with respect to the rewrite rule. (We
could also have argued that the second configura-
tion can be rewritten into the first by using the in-
verted rule.)
We formalise this rewriting-based notion of
equivalence as follows. The definition uses the ab-
breviation x[1,k) for the sequence x1, . . . ,xk?1, and
x(k,n] for xk+1, . . . ,xn.
Definition 3. A permutation system R is a system
of rewrite rules over the signature ? of the follow-
ing form:
f1(x[1,i), f2(y[1,k),z,y(k,m]),x(i,n])?
f2(y[1,k), f1(x[1,i),z,x(i,n]),y(k,m])
The permutability relation P(R) is the binary rela-
tion P(R) ? (??N)2 which contains exactly the
tuples (( f1, i),( f2,k)) and (( f2,k),( f1, i)) for each
such rewrite rule. Two terms are equivalent with re-
spect to R, s?R t, iff there is a sequence of rewrite
steps and inverse rewrite steps that rewrite s into t.
If G is a graph over ? and R a permutation sys-
tem, then we write SCR(G) for the set of equiva-
lence classes Conf(G)/?R, where Conf(G) is the
set of configurations of G.
The rewrite rule (3) above is an instance of this
schema, as are the other three permutations of ex-
istential quantifiers. These rules approximate clas-
sical semantic equivalence of first-order logic, as
they rewrite formulas into classically equivalent
ones. Indeed, all five configurations of the graph
in Fig. 1 are rewriting-equivalent to each other.
In the case of the semantic representations gen-
erated by the ERG, we don?t have access to an
underlying interpretation. But we can capture lin-
guistic intuitions about the equivalence of readings
in permutation rules. For instance, proper names
and pronouns (which the ERG analyses as scope-
bearers, although they can be reduced to constants
without scope) can be permuted with anything. In-
definites and definites permute with each other if
they occur in each other?s scope, but not if they
occur in each other?s restriction; and so on.
4 Redundancy elimination
Given a permutation system, we can now try to get
rid of readings that are equivalent to other readings.
One way to formalise this is to enumerate exactly
one representative of each equivalence class. How-
ever, after such a step we would be left with a col-
lection of semantic representations rather than an
USR, and could not use the USR for ruling out
further readings. Besides, a naive algorithm which
412
first enumerates all configurations would be pro-
hibitively slow.
We will instead tackle the following underspec-
ified redundancy elimination problem: Given an
USR G, compute an USR G? with Conf(G?) ?
Conf(G) and SCR(G) = SCR(G?). We want
Conf(G?) to be as small as possible. Ideally, it
would contain no two equivalent readings, but in
practice we won?t always achieve this kind of com-
pleteness. Our redundancy elimination algorithm
will operate on a dominance chart and successively
delete splits and subgraphs from the chart.
4.1 Permutable fragments
Because the algorithm must operate on USRs
rather than configurations, it needs a way to pre-
dict from the USR alone which fragments can be
permuted in configurations. This is not generally
possible in unrestricted graphs, but for hnc graphs
it is captured by the following criterion.
Definition 4. Let R be a permutation system. Two
fragments F1 and F2 with root labels f1 and f2
in a hnc graph G are called R-permutable iff
they are possible dominators of each other and
(( f1,ch(F1,F2)),( f2,ch(F2,F1))) ? P(R).
For example, in Fig. 1, the fragments 1 and 2
are permutable, and indeed they can be permuted
in any configuration in which one is the parent of
the other. This is true more generally:
Lemma 2 (Koller and Thater (2006)). Let G be a
hnc graph, F1 and F2 be R-permutable fragments
with root labels f1 and f2, and C1 any config-
uration of G of the form C( f1(. . . , f2(. . .), . . .))
(where C is the context of the subterm). Then
C1 can be R-rewritten into a tree C2 of the form
C( f2(. . . , f1(. . .), . . .)) which is also a configura-
tion of G.
The proof uses the hn connectedness ofG in two
ways: in order to ensure that C2 is still a configu-
ration of G, and to make sure that F2 is plugged
into the correct hole of F1 for a rule application
(cf. Lemma 1). Note thatC2 ?R C1 by definition.
4.2 The redundancy elimination algorithm
Now we can use permutability of fragments to
define eliminable splits. Intuitively, a split of a
subgraph G is eliminable if each of its configura-
tions is equivalent to a configuration of some other
split of G. Removing such a split from the chart
will rule out some configurations; but it does not
change the set of equivalence classes.
Definition 5. Let R be a permutation system. A
split S= (F, . . . ,hi 7?Gi, . . .) of a graph G is called
eliminable in a chartCh if some Gi contains a frag-
ment F ? such that (a) Ch contains a split S? of G
with root fragment F ?, and (b) F ? is R-permutable
with F and all possible dominators of F ? in Gi.
In Fig. 1, each of the three splits is eliminable.
For example, the split with root fragment 1 is elim-
inable because the fragment 3 permutes both with
2 (which is the only possible dominator of 3 in the
same wcc) and with 1 itself.
Proposition 3. Let Ch be a dominance chart, and
let S be an eliminable split of a hnc subgraph. Then
SC(Ch) = SC(Ch?S).
Proof. Let C be an arbitrary configuration of S =
(F,h1 7? G1, . . . ,hn 7? Gn), and let F ? ? Gi be the
root fragment of the assumed second split S?.
Let F1, . . . ,Fn be those fragments in C that are
properly dominated by F and properly dominate
F ?. All of these fragments must be possible domi-
nators of F ?, and all of them must be in Gi as well,
so F ? is permutable with each of them. F ? must
also be permutable with F . This means that we can
apply Lemma 2 repeatedly to move F ? to the root
of the configuration, obtaining a configuration of
S? which is equivalent toC.
Notice that we didn?t require that Ch must be
the complete chart of a dominance graph. This
means we can remove eliminable splits from a
chart repeatedly, i.e. we can apply the following
redundancy elimination algorithm:
REDUNDANCY-ELIMINATION(Ch,R)
1 for each split S inCh
2 do if S is eliminable with respect to R
3 then remove S fromCh
Prop. 3 shows that the algorithm is a correct
algorithm for the underspecified redundancy
elimination problem. The particular order in
which eliminable splits are removed doesn?t
affect the correctness of the algorithm, but it may
change the number of remaining configurations.
The algorithm generalises an earlier elimination
algorithm (Koller and Thater, 2006) in that the
earlier algorithm required the existence of a single
split which could be used to establish eliminability
of all other splits of the same subgraph.
We can further optimise this algorithm by keep-
ing track of how often each subgraph is referenced
413
every
z
D
x,y,z
a
y
a
x
1 2 3
A
x
B
y
C
z
4 5 6
7
Figure 4: A graph for which the algorithm is not
complete.
by the splits in the chart. Once a reference count
drops to zero, we can remove the entry for this
subgraph and all of its splits from the chart. This
doesn?t change the set of configurations of the
chart, but may further reduce the chart size. The
overall runtime for the algorithm is O(n2S), where
S is the number of splits in Ch and n is the num-
ber of nodes in the graph. This is asymptotically
not much slower than the runtime O((n+m)S) it
takes to compute the chart in the first place (where
m is the number of edges in the graph).
4.3 Examples and discussion
Let?s look at a run of the algorithm on the chart
in Fig. 2. The algorithm can first delete the elim-
inable split with root 1 for the entire graphG. After
this deletion, the splits for G with root fragments
2 and 3 are still eliminable; so we can e.g. delete
the split for 3. At this point, only one split is left
for G. The last split for a subgraph can never be
eliminable, so we are finished with the splits for
G. This reduces the reference count of some sub-
graphs (e.g. {2,3,5,6,7}) to 0, so we can remove
these subgraphs too. The output of the algorithm is
the chart shown below, which represents a single
configuration (the one shown in Fig. 3).
{1,2,3,4,5,6,7} :?2,h2 7? {1,4},h4 7? {3,6,7}?
{1,4} :?1,h1 7? {4}?
{3,6,7} :?3,h5 7? {6},h6 7? {7}?
In this case, the algorithm achieves complete re-
duction, in the sense that the final chart has no two
equivalent configurations. It remains complete for
all variations of the graph in Fig. 1 in which some
or all existential quantifiers are replaces by univer-
sal quantifiers. This is an improvement over our
earlier algorithm (Koller and Thater, 2006), which
computed a chart with four configurations for the
graph in which 1 and 2 are existential and 3 is uni-
versal, as opposed to the three equivalence classes
of this graph?s configurations.
However, the present algorithm still doesn?t
achieve complete reduction for all USRs. One ex-
ample is shown in Fig. 4. This graph has six config-
urations in four equivalence classes, but no split of
the whole graph is eliminable. The algorithm will
delete a split for the subgraph {1,2,4,5,7}, but the
final chart will still have five, rather than four, con-
figurations. A complete algorithm would have to
recognise that {1,3,4,6,7} and {2,3,5,6,7} have
splits (for 1 and 2, respectively) that lead to equiv-
alent configurations and delete one of them. But
it is far from obvious how such a non-local deci-
sion could be made efficiently, and we leave this
for future work.
5 Evaluation
In this final section, we evaluate the the effective-
ness and efficiency of the elimination algorithm:
We run it on USRs from a treebank and measure
how many readings are redundant, to what extent
the algorithm eliminates this redundancy, and how
much time it takes to do this.
Resources. The experiments are based on the
Rondane corpus, a Redwoods (Oepen et al, 2002)
style corpus which is distributed with the English
Resource Grammar (Flickinger, 2002). The cor-
pus contains analyses for 1076 sentences from the
tourism domain, which are associated with USRs
based upon Minimal Recursion Semantics (MRS).
The MRS representations are translated into dom-
inance graphs using the open-source utool tool
(Koller and Thater, 2005a), which is restricted to
MRS representations whose translations are hnc.
By restricting ourselves to such MRSs, we end up
with a data set of 999 dominance graphs. The aver-
age number of scope bearing operators in the data
set is 6.5, and the median number of readings is 56.
We then defined a (rather conservative) rewrite
system RERG for capturing the permutability rela-
tion of the quantifiers in the ERG. This amounted
to 34 rule schemata, which are automatically ex-
panded to 494 rewrite rules.
Experiment: Reduction. We first analysed the
extent to which our algorithm eliminated the re-
dundancy of the USRs in the corpus. We com-
puted dominance charts for all USRs, ran the al-
gorithm on them, and counted the number of con-
figurations of the reduced charts. We then com-
pared these numbers against a baseline and an up-
per bound. The upper bound is the true number of
414
110
100
1000
10000
100000
0 1 2 3 4 5 6 7 8 9 10 11 12 13
log(#configurations)
F
a
c
t
o
r
Algorithm Baseline Classes
Figure 5: Mean reduction factor on Rondane.
equivalence classes with respect to RERG; for effi-
ciency reasons we could only compute this num-
ber for USRs with up to 500.000 configurations
(95% of the data set). The baseline is given by
the number of readings that remain if we replace
proper names and pronouns by constants and vari-
ables, respectively. This simple heuristic is easy to
compute, and still achieves nontrivial redundancy
elimination because proper names and pronouns
are quite frequent (28% of the noun phrase occur-
rences in the data set). It also shows the degree of
non-trivial scope ambiguity in the corpus.
For each measurement, we sorted the USRs ac-
cording to the number N of configurations, and
grouped USRs according to the natural logarithm
of N (rounded down) to obtain a logarithmic scale.
First, we measured the mean reduction factor
for each log(N) class, i.e. the ratio of the num-
ber of all configurations to the number of remain-
ing configurations after redundancy elimination
(Fig. 5). The upper-bound line in the figure shows
that there is a great deal of redundancy in the USRs
in the data set. The average performance of our
algorithm is close to the upper bound and much
0%
20%
40%
60%
80%
100%
0 1 2 3 4 5 6 7 8 9 10 11 12 13
log(#configurations)
Algorithm Baseline
Figure 6: Percentage of USRs for which the algo-
rithm and the baseline achieve complete reduction.
0
1
10
100
1000
10000
0 1 2 3 4 5 6 7 8 9 10 11 12 13
log(#configurations)
t
i
m
e
 
(
m
s
)
Full Chart Reduced Chart Enumeration
Figure 7: Mean runtimes.
better than the baseline. For USRs with fewer than
e8 = 2980 configurations (83% of the data set), the
mean reduction factor of our algorithm is above
86% of the upper bound. The median number
of configurations for the USRs in the whole data
set is 56, and the median number of equivalence
classes is 3; again, the median number of config-
urations of the reduced charts is very close to the
upper bound, at 4 (baseline: 8). The highest reduc-
tion factor for an individual USR is 666.240.
We also measured the ratio of USRs for which
the algorithm achieves complete reduction (Fig. 6):
The algorithm is complete for 56% of the USRs
in the data set. It is complete for 78% of the USRs
with fewer than e5 = 148 configurations (64% of
the data set), and still complete for 66% of the
USRs with fewer than e8 configurations.
Experiment: Efficiency. Finally, we measured
the runtime of the elimination algorithm. The run-
time of the elimination algorithm is generally com-
parable to the runtime for computing the chart in
the first place. However, in our experiments we
used an optimised version of the elimination algo-
rithm, which computes the reduced chart directly
from a dominance graph by checking each split
for eliminability before it is added to the chart.
We compare the performance of this algorithm to
the baseline of computing the complete chart. For
comparison, we have also added the time it takes
to enumerate all configurations of the graph, as a
lower bound for any algorithm that computes the
equivalence classes based on the full set of config-
urations. Fig. 7 shows the mean runtimes for each
log(N) class, on the USRs with less than one mil-
lion configurations (958 USRs).
As the figure shows, the asymptotic runtimes
for computing the complete chart and the reduced
chart are about the same, whereas the time for
415
enumerating all configurations grows much faster.
(Note that the runtime is reported on a logarithmic
scale.) For USRs with many configurations, com-
puting the reduced chart actually takes less time
on average than computing the complete chart
because the chart-filling algorithm is called on
fewer subgraphs. While the reduced-chart algo-
rithm seems to be slower than the complete-chart
one for USRs with less than e5 configurations,
these runtimes remain below 20 milliseconds on
average, and the measurements are thus quite un-
reliable. In summary, we can say that there is no
overhead for redundancy elimination in practice.
6 Conclusion
We presented an algorithm for redundancy elimina-
tion on underspecified chart representations. This
algorithm successively deletes eliminable splits
from the chart, which reduces the set of described
readings while making sure that at least one rep-
resentative of each original equivalence class re-
mains. Equivalence is defined with respect to a cer-
tain class of rewriting systems; this definition ap-
proximates semantic equivalence of the described
formulas and fits well with the underspecification
setting. The algorithm runs in polynomial time in
the size of the chart.
We then evaluated the algorithm on the Ron-
dane corpus and showed that it is useful in practice:
the median number of readings drops from 56 to
4, and the maximum individual reduction factor is
666.240. The algorithm achieves complete reduc-
tion for 56% of all sentences. It does this in neg-
ligible runtime; even the most difficult sentences
in the corpus are reduced in a matter of seconds,
whereas the enumeration of all readings would
take about a year. This is the first corpus evalua-
tion of a redundancy elimination in the literature.
The algorithm improves upon previous work
(Koller and Thater, 2006) in that it eliminates more
splits from the chart. It is an improvement over ear-
lier algorithms for enumerating irredundant read-
ings (Vestre, 1991; Chaves, 2003) in that it main-
tains underspecifiedness; note that these earlier pa-
pers never made any claims with respect to, or eval-
uated, completeness.
There are a number of directions in which the
present algorithm could be improved. We are cur-
rently pursuing some ideas on how to improve the
completeness of the algorithm further. It would
also be worthwhile to explore heuristics for the or-
der in which splits of the same subgraph are elim-
inated. The present work could be extended to al-
low equivalence with respect to arbitrary rewrite
systems. Most generally, we hope that the methods
developed here will be useful for defining other
elimination algorithms, which take e.g. full world
knowledge into account.
References
E. Althaus, D. Duchier, A. Koller, K. Mehlhorn, J. Niehren,
and S. Thiel. 2003. An efficient graph algorithm for dom-
inance constraints. Journal of Algorithms, 48:194?219.
P. Blackburn and J. Bos. 2005. Representation and Inference
for Natural Language. A First Course in Computational
Semantics. CSLI Publications.
R. P. Chaves. 2003. Non-redundant scope disambiguation
in underspecified semantics. In Proc. 8th ESSLLI Student
Session.
A. Copestake, D. Flickinger, C. Pollard, and I. Sag. 2004.
Minimal recursion semantics: An introduction. Journal of
Language and Computation. To appear.
M. Egg, A. Koller, and J. Niehren. 2001. The Constraint
Language for Lambda Structures. Logic, Language, and
Information, 10.
D. Flickinger. 2002. On building a more efficient grammar
by exploiting types. In J. Tsujii S. Oepen, D. Flickinger
and H. Uszkoreit, editors, Collaborative Language Engi-
neering. CSLI Publications, Stanford.
R. Fuchss, A. Koller, J. Niehren, and S. Thater. 2004. Mini-
mal recursion semantics as dominance constraints: Trans-
lation, evaluation, and analysis. In Proc. of the 42nd ACL.
A. Koller and S. Thater. 2005a. Efficient solving and ex-
ploration of scope ambiguities. In ACL-05 Demonstration
Notes, Ann Arbor.
A. Koller and S. Thater. 2005b. The evolution of dominance
constraint solvers. In Proceedings of the ACL-05 Work-
shop on Software, Ann Arbor.
A. Koller and S. Thater. 2006. Towards a redundancy elimi-
nation algorithm for underspecified descriptions. In Proc.
5th Intl. Workshop on Inference in Computational Seman-
tics (ICoS-5).
A. Koller, J. Niehren, and S. Thater. 2003. Bridging the gap
between underspecification formalisms: Hole semantics as
dominance constraints. In Proc. 10th EACL.
J. Niehren and S. Thater. 2003. Bridging the gap between
underspecification formalisms: Minimal recursion seman-
tics as dominance constraints. In Proc. of the 41st ACL.
S. Oepen, K. Toutanova, S. Shieber, C. Manning,
D. Flickinger, and T. Brants. 2002. The LinGO Red-
woods treebank: Motivation and preliminary applications.
In Proceedings of COLING?02.
K. van Deemter and S. Peters. 1996. Semantic Ambiguity
and Underspecification. CSLI, Stanford.
E. Vestre. 1991. An algorithm for generating non-redundant
quantifier scopings. In Proc. of the Fifth EACL, Berlin.
416
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 301?304,
Suntec, Singapore, 4 August 2009.
c
?2009 ACL and AFNLP
Validating the web-based evaluation of NLG systems
Alexander Koller
Saarland U.
koller@mmci.uni-saarland.de
Kristina Striegnitz
Union College
striegnk@union.edu
Donna Byron
Northeastern U.
dbyron@ccs.neu.edu
Justine Cassell
Northwestern U.
justine@northwestern.edu
Robert Dale
Macquarie U.
Robert.Dale@mq.edu.au
Sara Dalzel-Job
U. of Edinburgh
S.Dalzel-Job@sms.ed.ac.uk
Jon Oberlander
U. of Edinburgh
Johanna Moore
U. of Edinburgh
{J.Oberlander|J.Moore}@ed.ac.uk
Abstract
The GIVE Challenge is a recent shared
task in which NLG systems are evaluated
over the Internet. In this paper, we validate
this novel NLG evaluation methodology by
comparing the Internet-based results with
results we collected in a lab experiment.
We find that the results delivered by both
methods are consistent, but the Internet-
based approach offers the statistical power
necessary for more fine-grained evaluations
and is cheaper to carry out.
1 Introduction
Recently, there has been an increased interest in
evaluating and comparing natural language gener-
ation (NLG) systems on shared tasks (Belz, 2009;
Dale and White, 2007; Gatt et al, 2008). However,
this is a notoriously hard problem (Scott and Moore,
2007): Task-based evaluations with human experi-
mental subjects are time-consuming and expensive,
and corpus-based evaluations of NLG systems are
problematic because a mismatch between human-
generated output and system-generated output does
not necessarily mean that the system?s output is
inferior (Belz and Gatt, 2008). This lack of evalua-
tion methods which are both effective and efficient
is a serious obstacle to progress in NLG research.
The GIVE Challenge (Byron et al, 2009) is a
recent shared task which takes a third approach to
NLG evaluation: By connecting NLG systems to
experimental subjects over the Internet, it achieves
a true task-based evaluation at a much lower cost.
Indeed, the first GIVE Challenge acquired data
from over 1100 experimental subjects online. How-
ever, it still remains to be shown that the results
that can be obtained in this way are in fact com-
parable to more established task-based evaluation
efforts, which are based on a carefully selected sub-
ject pool and carried out in a controlled laboratory
environment. By accepting connections from arbi-
trary subjects over the Internet, the evaluator gives
up control over the subjects? behavior, level of lan-
guage proficiency, cooperativeness, etc.; there is
also an issue of whether demographic factors such
as gender might skew the results.
In this paper, we provide the missing link by
repeating the GIVE evaluation in a laboratory en-
vironment and comparing the results. It turns out
that where the two experiments both find a signif-
icant difference between two NLG systems with
respect to a given evaluation measure, they always
agree. However, the Internet-based experiment
finds considerably more such differences, perhaps
because of the higher number of experimental sub-
jects (n = 374 vs. n = 91), and offers other oppor-
tunities for more fine-grained analysis as well. We
take this as an empirical validation of the Internet-
based evaluation of GIVE, and propose that it can
be applied to NLG more generally. Our findings
are in line with studies from psychology that indi-
cate that the results of web-based experiments are
typically consistent with the results of traditional
experiments (Gosling et al, 2004). Nevertheless,
we do find and discuss some effects of the uncon-
trolled subject pool that should be addressed in
future Internet-based NLG challenges.
2 The GIVE Challenge
In the GIVE scenario (Byron et al, 2009), users
try to solve a treasure hunt in a virtual 3D world
that they have not seen before. The computer has
complete information about the virtual world. The
challenge for the NLG system is to generate, in real
time, natural-language instructions that will guide
the users to the successful completion of their task.
From the perspective of the users, GIVE con-
sists in playing a 3D game which they start from
a website. The game displays a virtual world and
allows the user to move around in the world and
manipulate objects; it also displays the generated
301
instructions. The first room in each game is a tuto-
rial room in which users learn how to interact with
the system; they then enter one of three evaluation
worlds, where instructions for solving the treasure
hunt are generated by an NLG system. Players
can either finish a game successfully, lose it by
triggering an alarm, or cancel the game at any time.
When a user starts the game, they are randomly
connected to one of the three worlds and one of the
NLG systems. The GIVE-1 Challenge evaluated
five NLG systems, which we abbreviate as A, M,
T, U, and W below. A running GIVE NLG system
has access to the current state of the world and to
an automatically computed plan that tells it what
actions the user should perform to solve the task. It
is notified whenever the user performs some action,
and can generate an instruction and send it to the
client for display at any time.
3 The experiments
The web experiment. For the GIVE-1 challenge,
1143 valid games were collected over the Internet
over the course of three months. These were dis-
tributed over three evaluation worlds (World 1: 374,
World 2: 369, World 3: 400). A game was consid-
ered valid if the game client didn?t crash, the game
wasn?t marked as a test run by the developers, and
the player completed the tutorial.
Of these games, 80% were played by males and
10% by females (the remaining 10% of the partic-
ipants did not specify their gender). The players
were widely distributed over countries: 37% con-
nected from IP addresses in the US, 33% from
Germany, and 17% from China; the rest connected
from 45 further countries. About 34% of the par-
ticipants self-reported as native English speakers,
and 62% specified a language proficiency level of
at least ?expert? (3 on a 5-point scale).
The lab experiment. We repeated the GIVE-1
evaluation in a traditional laboratory setting with
91 participants recruited from a college campus.
In the lab, each participant played the GIVE game
once with each of the five NLG systems. To avoid
learning effects, we only used the first game run
from each subject in the comparison with the web
experiment; as a consequence, subjects were dis-
tributed evenly over the NLG systems. To accom-
modate for the much lower number of participants,
the laboratory experiment only used a single game
world ? World 1, which was known from the online
version to be the easiest world.
Among this group of subjects, 93% self-rated
their English proficiency as ?expert? or better; 81%
were native speakers. In contrast to the online ex-
periment, 31% of participants were male and 65%
were female (4% did not specify their gender).
Results: Objective measures. The GIVE soft-
ware automatically recorded data for five objec-
tive measures: the percentage of successfully com-
pleted games and, for the successfully completed
games, the number of instructions generated by
the NLG system, of actions performed by the user
(such as pushing buttons), of steps taken by the
user (i.e., actions plus movements), and the task
completion time (in seconds).
Fig. 1 shows the results for the objective mea-
sures collected in both experiments. To make the
results comparable, the table for the Internet ex-
periment only includes data for World 1. The task
success rate is only evaluated on games that were
completed successfully or lost, not cancelled, as
laboratory subjects were asked not to cancel. This
brings the number of Internet subjects to 322 for
the success rate, and to 227 (only successful games)
for the other measures.
Task success is the percentage of successfully
completed games; the other measures are reported
as means. The chart assigns systems to groups A
through C or D for each evaluation measure. Sys-
tems in group A are better than systems in group
B, and so on; if two systems have no letter in com-
mon, the difference between them is significant
with p < 0.05. Significance was tested using a ?
2
-
test for task success and ANOVAs for instructions,
steps, actions, and seconds. These were followed
by post hoc tests (pairwise ?
2
and Tukey) to com-
pare the NLG systems pairwise.
Results: Subjective measures. Users were
asked to fill in a questionnaire collecting subjec-
tive ratings of various aspects of the instructions.
For example, users were asked to rate the overall
quality of the direction giving system (on a 7-point
scale), the choice of words and the referring ex-
pressions (on 5-point scales), and they were asked
whether they thought the instructions came at the
right time. Overall, there were twelve subjective
measures (see (Byron et al, 2009)), of which we
only present four typical ones for space reasons.
For each question, the user could choose not to
answer. On the Internet, subjects made consider-
able use of this option: for instance, 32% of users
302
Objective Measures Subjective Measures
task
success
instructions steps actions seconds overall
choice
of words
referring
expressions
timing
A 91% A 83.4 B 99.8 A 9.4 A 123.9 A 4.7 A 4.7 A 4.7 A 81% A
M 76% B 68.1 A 145.1 B 10.0 AB 195.4 BC 3.8 AB 3.8 B 4.0 B 70% ABC
T 85% AB 97.8 C 142.1 B 9.7 AB 174.4 B 4.4 B 4.4 AB 4.3 AB 73% AB
U 93% AB 99.8 C 142.6 B 10.3 B 194.0 BC 4.0 B 4.0 B 4.0 B 51% C
W 24% C 159.7 D 256.0 C 9.6 AB 234.1 C 3.8 AB 3.8 B 4.2 AB 50% BC
A 100% A 78.2 AB 93.4 A 9.9 A 143.9 A 5.7 A 4.7 A 4.8 A 92% A B
M 95% A 66.3 A 141.8 B 10.5 A 211.8 B 5.4 A 3.8 B 4.3 A 95% A B
T 93% A 107.2 CD 134.6 B 9.6 A 205.6 B 4.9 A 4.5 A B 4.4 A 64% A B
U 100% A 88.8 BC 128.8 B 9.8 A 195.1 AB 5.7 A 4.7 A 4.3 A 100% A
W 17% B 134.5 D 213.5 C 10.0 A 252.5 B 5.0 A 4.5 A B 4.0 A 100% B
Figure 1: Objective and selected subjective measures on the web (top) and in the lab (bottom).
didn?t fill in the ?overall evaluation? field of the
questionnaire. In the laboratory experiment, the
subjects were asked to fill in the complete question-
naire and the response rate is close to 100%.
The results for the four selected subjective mea-
sures are summarized in Fig. 1 in the same way as
the objective measures. Also as above, the table
is based only on successfully completed games in
World 1. We will justify this latter choice below.
4 Discussion
The primary question that interests us in a compar-
ative evaluation is which NLG systems performed
significantly better or worse on any given evalua-
tion measure. In the experiments above, we find
that of the 170 possible significant differences (=
17 measures ? 10 pairs of NLG systems), the labo-
ratory experiment only found six that the Internet-
based experiment didn?t find. Conversely, there
are 26 significant differences that only the Internet-
based experiment found. But even more impor-
tantly, all pairwise rankings are consistent across
the two evaluations: Where both systems found a
significant difference between two systems, they al-
ways ranked them in the same order. We conclude
that the Internet experiment provides significance
judgments that are comparable to, and in fact more
precise than, the laboratory experiment.
Nevertheless, there are important differences be-
tween the laboratory and Internet-based results. For
instance, the success rates in the laboratory tend
to be higher, but so are the completion times. We
believe that these differences can be attributed to
the demographic characteristics of the participants.
To substantiate this claim, we looked in some detail
at differences in gender, language proficiency, and
questionnaire response rates.
First, the gender distribution differed greatly be-
Web
games reported mean
success 227 = 61% 93% 4.9
lost 92 = 24% 48% 3.4
cancelled 55 = 15% 16% 3.3
Lab
# games reported mean
success 73 = 80% 100% 5.4
lost 18 = 20% 94% 3.3
cancelled 0 ? ?
Figure 2: Skewed results for ?overall evaluation?.
tween the Internet experiment (10% female) and
the laboratory experiment (65% female). This is
relevant because gender had a significant effect
on task completion time (women took longer) and
on six subjective measures including ?overall eval-
uation? in the laboratory. We speculate that the
difference in task completion time may be related
to well-known gender differences in processing
navigation instructions (Moffat et al, 1998).
Second, the two experiments collected data from
subjects of different language proficiencies. While
93% of the participants in the laboratory experi-
ment self-rated their English proficiency as ?expert?
or better, only 62% of the Internet participants did.
This partially explains the lower task success rates
on the Internet, as Internet subjects with English
proficiencies of 3?5 performed significantly better
on ?task success? than the group with proficiencies
1?2. If we only look at the results of high-English-
proficiency subjects on the Internet, the success
rates for all NLG systems except W rise to at least
86%, and are thus close to the laboratory results.
Finally, the Internet data are skewed by the ten-
dency of unsuccessful participants to not fill in the
questionnaire. Fig. 2 summarizes some data about
the ?overall evaluation? question. Users who didn?t
complete the task successfully tended to judge the
303
systems much lower than successful users, but at
the same time tended not to answer the question
at all. This skew causes the mean subjective judg-
ments across all Internet subjects to be artificially
high. To avoid differences between the laboratory
and the Internet experiment due to this skew, Fig. 1
includes only judgments from successful games.
In summary, we find that while the two experi-
ments made consistent significance judgments, and
the Internet-based evaluation methodology thus
produces meaningful results, the absolute values
they find for the individual evaluation measures
differ due to the demographic characteristics of the
participants in the two studies. This could be taken
as a possible deficit of the Internet-based evalua-
tion. However, we believe that the opposite is true.
In many ways, an online user is in a much more
natural communicative situation than a laboratory
subject who is being discouraged from cancelling
a frustrating task. In addition, every experiment ?
whether in the laboratory or on the Internet ? suf-
fers from some skew in the subject population due
to sampling bias; for instance, one could argue that
an evaluation that is based almost exclusively on na-
tive speakers in universities leads to overly benign
judgments about the quality of NLG systems.
One advantage of the Internet-based approach
to data collection over the laboratory-based one is
that, due to the sheer number of subjects, we can de-
tect such skews and deal with them appropriately.
For instance, we might decide that we are only
interested in the results from proficient English
speakers and ignore the rest of the data; but we
retain the option to run the analysis over all partici-
pants, and to analyze how much each system relies
on the user?s language proficiency. The amount
of data also means that we can obtain much more
fine-grained comparisons between NLG systems.
For instance, the second and third evaluation world
specifically exercised an NLG system?s abilities to
generate referring expressions and navigation in-
structions, respectively, and there were significant
differences in the performance of some systems
across different worlds. Such data, which is highly
valuable for pinpointing specific weaknesses of a
system, would have been prohibitively costly and
time-consuming to collect with laboratory subjects.
5 Conclusion
In this paper, we have argued that carrying out task-
based evaluations of NLG systems over the Internet
is a valid alternative to more traditional laboratory-
based evaluations. Specifically, we have shown
that an Internet-based evaluation of systems in the
GIVE Challenge finds consistent significant differ-
ences as a lab-based evaluation. While the Internet-
based evaluation suffers from certain skews caused
by the lack of control over the subject pool, it does
find more differences than the lab-based evaluation
because much more data is available. The increased
amount of data also makes it possible to compare
the quality of NLG systems across different evalua-
tion worlds and users? language proficiency levels.
We believe that this type of evaluation effort
can be applied to other NLG and dialogue tasks
beyond GIVE. Nevertheless, our results also show
that an Internet-based evaluation risks certain kinds
of skew in the data. It is an interesting question for
the future how this skew can be reduced.
References
A. Belz and A. Gatt. 2008. Intrinsic vs. extrinsic eval-
uation measures for referring expression generation.
In Proceedings of ACL-08:HLT, Short Papers, pages
197?200, Columbus, Ohio.
A. Belz. 2009. That?s nice ... what can you do with it?
Computational Linguistics, 35(1):111?118.
D. Byron, A. Koller, K. Striegnitz, J. Cassell, R. Dale,
J. Moore, and J. Oberlander. 2009. Report on the
First NLG Challenge on Generating Instructions in
Virtual Environments (GIVE). In Proceedings of the
12th European Workshop on Natural Language Gen-
eration (Special session on Generation Challenges).
R. Dale and M. White, editors. 2007. Proceedings
of the NSF/SIGGEN Workshop for Shared Tasks and
Comparative Evaluation in NLG, Arlington, VA.
A. Gatt, A. Belz, and E. Kow. 2008. The TUNA
challenge 2008: Overview and evaluation results.
In Proceedings of the 5th International Natural
Language Generation Conference (INLG?08), pages
198?206.
S. D. Gosling, S. Vazire, S. Srivastava, and O. P. John.
2004. Should we trust Web-based studies? A com-
parative analysis of six preconceptions about Inter-
net questionnaires. American Psychologist, 59:93?
104.
S. Moffat, E. Hampson, and M. Hatzipantelis. 1998.
Navigation in a ?virtual? maze: Sex differences and
correlation with psychometric measures of spatial
ability in humans. Evolution and Human Behavior,
19(2):73?87.
D. Scott and J. Moore. 2007. An NLG evaluation com-
petition? Eight reasons to be cautious. In (Dale and
White, 2007).
304
The evolution of dominance constraint solvers
Alexander Koller and Stefan Thater
Dept. of Computational Linguistics
Saarland University, Saarbr?cken, Germany
{koller,stth}@coli.uni-sb.de
Abstract
We describe the evolution of solvers
for dominance constraints, a formalism
used in underspecified semantics, and
present a new graph-based solver using
charts. An evaluation on real-world data
shows that each solver (including the
new one) is significantly faster than its
predecessors. We believe that our strat-
egy of successively tailoring a powerful
formalism to the actual inputs is more
generally applicable.
1 Introduction
In many areas of computational linguistics, there is
a tension between a need for powerful formalisms
and the desire for efficient processing. Expressive
formalisms are useful because they allow us to
specify linguistic facts at the right level of abstrac-
tion, and in a way that supports the creation and
maintenance of large language resources. On the
other hand, by choosing a more powerful formal-
ism, we typically run the risk that our processing
tasks (say, parsing or inference) can no longer be
performed efficiently.
One way to address this tension is to switch to
simpler formalisms. This makes processing more
efficient, but sacrifices the benefits of expressive
formalisms in terms of modelling. Another com-
mon strategy is to simply use the powerful for-
malisms anyway. This sometimes works pretty
well in practice, but a system built in this way can-
not give any runtime guarantees, and may become
slow for certain inputs unpredictably.
In this paper, we advocate a third option: Use a
general, powerful formalism, analyse what makes
it complex and what inputs actually occur in prac-
tice, and then find a restricted fragment of the for-
malism that supports all practical inputs and can
be processed efficiently. We demonstrate this ap-
proach by describing the evolution of solvers for
dominance constraints (Egg et al, 2001), a certain
formalism used for the underspecified descrip-
tion of scope ambiguities in computational seman-
tics. General dominance constraints have an NP-
complete satisfiability problem, but normal dom-
inance constraints, which subsume all constraints
that are used in practice, have linear-time satisfia-
bility and can be solved extremely efficiently.
We describe a sequence of four solvers, rang-
ing from a purely logic-based saturation algorithm
(Koller et al, 1998) over a solver based on con-
straint programming (Duchier and Niehren, 2000)
to efficient solvers based on graph algorithms
(Bodirsky et al, 2004). The first three solvers have
been described in the literature before, but we also
present a new variant of the graph solver that uses
caching to obtain a considerable speedup. Finally
we present a new evaluation that compares all four
solvers with each other and with a different under-
specification solver from the LKB grammar devel-
opment system (Copestake and Flickinger, 2000).
The paper is structured as follows. We will first
sketch the problem that our algorithms solve (Sec-
tion 2). Then we present the solvers (Section 3)
and conclude with the evaluation (Section 4).
2 The Problem
The problem we use to illustrate the progress to-
wards efficient solvers is that of enumerating all
readings of an underspecified description. Under-
specification is a technique for dealing with the
combinatorial problems associated with quantifier
scope ambiguities, certain semantic ambiguities
that occur in sentences such as the following:
(1) Every student reads a book.
This sentence has two different readings. Read-
ing (2) expresses that each student reads a possibly
different book, while reading (3) claims that there
is a single book which is read by every student.
(2) ?x.student(x)? (?y.book(y)? read(x,y))
(3) ?y.book(y)? (?x.student(x)? read(x,y))
The number of readings can grow exponen-
tially in the number of quantifiers and other
scope-bearing operators occuring in the sentence.
A particularly extreme example is the follow-
ing sentence from the Rondane Treebank, which
the English Resource Grammar (Copestake and
Flickinger, 2000) claims to have about 2.4 trillion
readings.
(4) Myrdal is the mountain terminus of the Fl?m
rail line (or Fl?msbana) which makes its way
down the lovely Fl?m Valley (Fl?msdalen) to
its sea-level terminus at Fl?m.
(Rondane 650)
Of course, this huge number of readings results
not only from genuine meaning differences, but
from the (quite reasonable) decision of the ERG
developers to uniformly treat all noun phrases, in-
cluding proper names and definites, as quantifiers.
But a system that builds upon such a grammar still
has to deal with these readings in some way.
The key idea of underspecification is now to not
enumerate all these semantic readings from a syn-
tactic analysis during or after parsing, but to derive
from the syntactic analysis a single, compact un-
derspecified description. The individual readings
can be enumerated from the description if they are
needed, and this enumeration process should be
efficient; but it is also possible to eliminate read-
ings that are infelicitous given knowledge about
the world or the context on the level of underspec-
ified descriptions.
?x
?
stud
x
?y
?
book
y yx
read
?x
?y
?
stud
x
?
book
y
yx
read
Figure 1: Trees for the readings (2) and (3).
?x
?y
?
stud
x
?
book
y
yx
read
X1 : ?x(X2) ?
X2 :?(X3,X4) ?
X5 : stud(X6) ?
X6 : x ?
. . .
X4 /? X7 ?
X7 : read(X8,X9) ?
X8 : x ?X9 : y
Figure 2: A dominance constraint (right) and its
graphical representation (left); the solutions of the
constraint are the two trees in Fig. 1.
Dominance constraints. The particular under-
specification formalism whose enumeration prob-
lem we consider in this paper is the formalism
of dominance constraints (Egg et al, 2001). The
basic idea behind using dominance constraints in
underspecification is that the semantic representa-
tions (2) and (3) can be considered as trees (see
Fig. 1). Then a set of semantic representations can
be characterised as the set of models of a formula
in the following language:
? ::= X : f (X1, . . . ,Xn) | X /? Y | X 6= Y | ???
The labelling atom X : f (X1, . . . ,Xn) expresses
that the node in the tree which is denoted by the
variable X has the label f , and its children are de-
noted by the variables X1 to Xn. Dominance atoms
X /? Y say that there is a path (of length 0 or more)
from the node denoted by X to the node denoted
by Y ; and inequality atoms X 6= Y require that X
and Y denote different nodes.
Dominance constraints ? can be drawn infor-
mally as graphs, as shown in Fig. 2. Each node
of the graph stands for a variable; node labels and
solid edges stand for labelling atoms; and the dot-
ted edges represent dominance atoms. The con-
straint represented by the drawing in Fig. 2 is sat-
isfied by both trees shown in Fig. 1. Thus we can
use it as an underspecified description represent-
ing these two readings.
The two obvious processing problems con-
nected to dominance constraints are satisfiability
(is there a model that satisfies the constraint?)
and enumeration (compute all models of a con-
straint). Because every satisfiable dominance con-
straint technically has an infinite number of mod-
els, the algorithms below solve the enumeration
problem by computing solved forms of the con-
straint, which are finite characterisations of infinite
model sets.
3 The Solvers
We present four different solvers for dominance
constraints. As we go along, we analyse what
makes dominance constraint solving hard, and
what characterises the constraints that occur in
practice.
3.1 A saturation algorithm
The first dominance constraint solver (Koller et al,
1998; Duchier and Niehren, 2000) is an algorithm
that operates directly on the constraint as a logical
formula. It is a saturation algorithm, which suc-
cessively enriches the constraint using saturation
rules. The algorithm terminates if it either derives
a contradiction (marked by the special atom false),
or if no rule can contribute any new atoms. In the
first case, it claims that the constraint is unsatisfi-
able; in the second case, it reports the end result of
the computation as a solved form and claims that
it is satisfiable.
The saturation rules in the solver try to match
their preconditions to the constraint, and if they
do match, add their conclusions to the constraint.
For example, the following rules express that dom-
inance is a transitive relation, and that trees have
no cycles:
X /? Y ?Y /? Z ? X /? Z
X : f (. . . ,Y, . . .)?Y /? X ? false
Some rules have disjunctive right-hand sides; if
they are applicable, they perform a case distinction
and add one of the disjuncts. One example is the
Choice Rule, which looks as follows:
X /? Z?Y /? Z ? X /? Y ?Y /? X
This rule checks for the presence of two variables
X and Y that are known to both dominate the same
variable Z. Because models must be trees, this
means that X and Y must dominate each other in
some order; but we can?t know yet whether it is X
or Y that dominates the other one. Hence the solver
tries both choices. This makes it possible to derive
multiple solved forms (one for each reading of the
sentence), such as the two different trees in Fig. 1.
It can be shown that a dominance constraint is
satisfiable iff it is not possible to derive false from
it using the rules in the algorithm. In addition, ev-
ery model of the original constraint satisfies ex-
actly one solved form. So the saturation algorithm
can indeed be used to solve dominance constraints.
However, even checking satisfiability takes nonde-
terministic polynomial time. Because all choices
in the distribution rule applications have to be
checked, a deterministic program will take expo-
nential time to check satisfiability in the worst
case.
Indeed, satisfiability of dominance constraints
is an NP-complete problem (Koller et al, 1998),
and hence it is likely that any solver for dominance
constraints will take exponential worst-case run-
time. At first sight, it seems that we have fallen
into the expressivity trap: We have a formalism
that allows us to model scope underspecification
very cleanly, but actually computing with this for-
malism is expensive.
3.2 Reduction to Set Constraints
In reaction to this NP-completeness result,
Duchier and Niehren (2000) applied techniques
from constraint programming to the problem in or-
der to get a more efficient solver. Constraint pro-
gramming (Apt, 2003) is a standard approach to
solving NP-complete combinatorial problems. In
this paradigm, a problem is modelled as a for-
mula in a logical constraint language. The pro-
gram searches for values for the variables in the
formula that satisfy the formula. In order to reduce
the size of the search space, it performs cheap de-
terministic inferences that exclude some values of
the variables (propagation), and only after prop-
agation can supply no further information it per-
forms a non-deterministic case distinction (distri-
bution).
Side
x
Eq
x
Up
x
Down
x
Figure 3: The four node sets
Duchier and Niehren solved dominance con-
straints by encoding them as finite set constraints.
Finite set constraints (M?ller and M?ller, 1997)
are formulas that talk about relations between
(terms that denote) finite sets of integers, such
as inclusion X ? Y or equality X = Y . Efficient
solvers for set constraints are available, e.g. as part
of the Mozart/Oz programming system (Oz Devel-
opment Team, 2004).
Reduction to set constraints. The basic idea
underlying the reduction is that a tree can be rep-
resented by specifying for each node v of this tree
which nodes are dominated by v, which ones dom-
inate v, which ones are equal to v (i.e. just v it-
self), and which ones are ?disjoint? from v (Fig. 3).
These four node sets are a partition of the nodes in
the tree.
Now the solver introduces for each variable X
in a dominance constraint ? four variables EqX ,
UpX , DownX , SideX for the sets of node variables
that denote nodes in the respective region of the
tree, relative to X . The atoms in ? are translated
into constraints on these variables. For instance, a
dominance atom X /? Y is translated into
UpX ? UpY ?DownY ? DownX ?SideX ? SideY
This constraint encodes that all variables whose
denotation dominates the denotation of X (UpX )
must also dominate the denotation of Y (UpY ), and
the analogous statements for the dominated and
disjoint variables.
In addition, the constraint program contains var-
ious redundant constraints that improve propaga-
tion. Now the search for solutions consists in find-
ing satisfying assignments to the set variables. The
result is a search tree as shown in Fig. 4: The
blue circles represent case distinctions, whereas
each green diamond represents a solution of the
set constraint (and therefore, a solved form of
Figure 4: Search tree for constraint 42 from the
Rondane Treebank.
the dominance constraint). Interestingly, all leaves
of the search tree in Fig. 4 are solution nodes;
the search never runs into inconsistent constraints.
This seems to happen systematically when solving
any constraints that come from underspecification.
3.3 A graph-based solver
This behaviour of the set-constraint solver is ex-
tremely surprising: The key characteristic of an
NP-complete problem is that the search tree must
necessarily contain failed nodes on some inputs.
The fact that the solver never runs into failure is a
strong indication that there is a fragment of domi-
nance constraints that contains all constraints that
are used in practice, and that the solver automat-
ically exploits this fragment. This begs the ques-
tion: What is this fragment, and can we develop
even faster solvers that are specialised to it?
One such fragment is the fragment of normal
dominance constraints (Althaus et al, 2003). The
most important restriction that a normal domi-
nance constraint ? must satisfy is that it is overlap-
free: Whenever ? contains two labelling atoms
X : f (. . .) and Y :g(. . .) (where f and g may be
equal), it must also contain an inequality atom
X 6= Y . As a consequence, no two labelled vari-
ables in a normal constraint may be mapped to the
same node. This is acceptable or even desirable in
underspecification: We are not interested in solu-
tions of the constraint in Fig. 2 in which the quan-
tifier representations overlap. On the other hand,
the NP-completeness proof in (Koller et al, 1998)
is no longer applicable to overlap-free constraints.
Hence normal dominance constraints are a frag-
ment that is sufficient from a modelling perspec-
tive, and possibly admits polynomial-time solvers.
Indeed, it can be shown that the satisfiability
problem of normal dominance constraints can be
gf
a b
g
a b
g
f
a b
Figure 5: An example computation of the graph
solver.
decided in linear time (Thiel, 2004), and the lin-
ear algorithm can be used to enumerate N solved
forms of a constraint of size n in time O(n2N). We
now present the simpler O(n2N) enumeration al-
gorithm by Bodirsky et al (2004).1 Note that N
may still be exponential in n.
Dominance Graphs. The crucial insight under-
lying the fast solvers for normal dominance con-
straints is that such constraints can be seen as dom-
inance graphs, and can be processed using graph
algorithms. Dominance graphs are directed graphs
with two kinds of edges: tree edges and dominance
edges. The graph without the dominance edges
must be a forest; the trees of this forest are called
the fragments of the graph. In addition, the dom-
inance edges must go from holes (i.e., unlabelled
leaves) of fragments to roots of other fragments.
For instance, we can view the graph in Fig. 2,
which we introduced as an informal notation for
a dominance constraint, directly as a dominance
graph with three fragments and two (dotted) dom-
inance edges.
A dominance graph G which is a forest is called
in solved form. We say that G? is a solved form of
a graph G iff G? is in solved form, G and G? con-
tain the same tree edges, and the reachability rela-
tion of G? extends that of G. Using this definition,
it is possible to define a mapping between normal
dominance constraints and dominance graphs such
that the solved forms of the graph can serve as
solved forms of the constraint ? i.e., we can reduce
constraint solving to graph solving.
By way of example, consider Fig. 5. The dom-
inance graph on the left is not in solved form, be-
cause it contains nodes with more than one incom-
1The original paper defines the algorithm for weakly nor-
mal dominance constraints, a slight generalisation.
GRAPH-SOLVER(G?)
1 if G? is already in solved form
2 then return G?
3 free? FREE-FRAGMENTS(G?)
4 if free = /0
5 then fail
6 choose F ? free
7 G1, . . . ,Gk?WCCS(G??F)
8 for each Gi ? G1, . . . ,Gk
9 do Si? GRAPH-SOLVER(Gi)
10 S? Attach S1, . . . ,Sk under F
11 return S
Figure 6: The graph solver.
ing dominance edge. By contrast, the other two
dominance graphs are in solved form. Because the
graph on the right has the same tree edges as the
one on the left and extends its reachability relation,
it is also a solved form of the left-hand graph.
The algorithm. The graph-based enumeration
algorithm is a recursive procedure that succes-
sively splits a dominance graph into smaller parts,
solves them recursively, and combines them into
complete solved forms. In each step, the algo-
rithm identifies the free fragments of the domi-
nance (sub-)graph. A fragment is free if it has no
incoming dominance edges, and all of its holes are
in different biconnected components of the undi-
rected version of the dominance graph. It can be
shown (Bodirsky et al, 2004) that if a graph G has
any solved form and F is a free fragment of G,
then G has a solved form in which F is at the root.
The exact algorithm is shown in Fig. 6. It com-
putes the free fragments of a sub-dominance graph
G? in line 3. Then it chooses one of the free frag-
ments, removes it from the graph, and calls itself
recursively on the weakly connected components
G1, . . . ,Gk of the resulting graph. Each recursive
call will compute a solved form Si of the con-
nected component Gi. Now for each Gi there is
exactly one hole hi of F that is connected to some
node in Gi by a dominance edge. We can obtain a
solved form for G? by combining F and all the Si
with dominance edges from hi to the root of Si for
each i.
gf
a b
Figure 7: An unsolvable dominance graph.
The algorithm is written as a nondeterministic
procedure which makes a nondeterministic choice
in line 6, and can fail in line 5. We can turn it into a
deterministic algorithm by considering the nonde-
terministic choices as case distinctions in a search
tree, as in Fig. 4. However, if the input graph G
is solvable, we know that every single leaf of the
search tree must correspond to a (different) solved
form, because for every free fragment that can be
chosen in line 6, there is a solved form that has this
fragment as its root. Conversely, if G is unsolv-
able, every single branch of the search tree will
run into failure, because it would claim the exis-
tence of a solved form otherwise. So the algorithm
decides solvability in polynomial time.
An example computation of GRAPH-SOLVER
is shown in Fig. 5. The input graph is shown on
the left. It contains exactly one free fragment F ;
this is the fragment whose root is labelled with
f . (The single-node fragments both have incom-
ing dominance edges, and the two holes of the
fragment with label g are in the same biconnected
component.) So the algorithm removes F from the
graph, resulting in the graph in the middle. This
graph is in solved form (it is a tree), so we are fin-
ished. Finally the algorithm builds a solved form
for the whole graph by plugging the solved form
in the middle into the single hole of F ; the result is
shown on the right. By contrast, the graph in Fig. 7
has no solved forms. The solver will recognise this
immediately, because none of the fragments is free
(they either have incoming dominance edges, or
their holes are biconnected).
3.4 A graph solver with charts
The graph solver is a great step forward towards
efficient constraint solving, and towards an under-
standing of why (normal) dominance constraints
can be solved efficiently. But it wastes time when
it is called multiple times for the same subgraph,
f
1
f
2
f
3
f
4
a
5
a
6
a
7
h
1
h
21
h
22
h
31
h
32
h
4
1 2 3 4
5 6 7
Figure 8: The chain of length 4.
{1,2,3,4,5,6,7} : ?1,h1 7? {2,3,4,5,6,7}?
?2,h21 7? {1,5},h22 7? {3,4,6,7}?
?3,h31 7? {1,2,5,6},h32 7? {4,7}?
?4,h4 7? {1,2,3,5,6,7}?
{2,3,4,5,6,7} : ?2,h21 7? {5},h22 7? {3,4,6,7}?
?3,h31 7? {2,5,6},h32 7? {4,7}?
?4,h4 7? {2,3,5,6,7}?
{1,2,3,5,6,7} : ?1,h1 7? {2,3,5,6,7}?
?2,h21 7? {1,5},h22 7? {3,6,7}?
?3,h31 7? {1,2,5,6},h32 7? {7}?
{2,3,5,6,7} : ?2,h21 7? {5},h22 7? {3,6,7}?
?3,h31 7? {2,5,6},h32 7? {7}?
. . . . . .
Figure 9: A part of the chart computed for the con-
straint in Fig. 8.
because it will solve it anew each time. In solv-
ing, for instance, the graph shown in Fig. 8, it
will solve the subgraph consisting of the fragments
{2,3,5,6,7} twice, because it can pick the frag-
ments 1 and 4 in either order.
We will now present a previously unpublished
optimisation for the solver that uses caching to al-
leviate this problem. The data structure we use for
caching (we call it ?chart? below because of its
obvious parallels to charts in parsing) assigns each
subgraph of the original graph a set of splits. Splits
encode the splittings of the graph into weakly con-
nected components that take place when a free
fragment is removed. Formally, a split for the sub-
graph G? consists of a reference to a fragment F
that is free in G? and a partial function that maps
some nodes of F to subgraphs of G?. A split is de-
termined uniquely by G? and F .
Consider, by way of example, Fig. 9, which dis-
plays a part of the chart that we want to compute
for the constraint in Fig. 8. In the entire graph G
(represented by the set {1, . . . ,7} of fragments),
the fragments 1, 2, 3, and 4 are free. As a conse-
quence, the chart contains a split for each of these
four fragments. If we remove fragment 1 from G,
we end up with a weakly connected graph G1 con-
taining the fragments {2, . . . ,7}. There is a dom-
GRAPH-SOLVER-CHART(G?)
1 if there is an entry for G? in the chart
2 then return true
3 free? FREE-FRAGMENTS(G?)
4 if free = /0
5 then return false
6 if G? contains only one fragment
7 then return true
8
9 for each F ? free
10 do split? SPLIT(G?,F)
11 for each S ?WCCS(G??F)
12 do if GRAPH-SOLVER-CHART(S) = false
13 then return false
14 add (G?,split) to the chart
15 return true
Figure 10: The graph solver with charts
inance edge from the hole h1 into G1, so once
we have a solved form of G1, we will have to
plug it into h1 to get a solved form of G; there-
fore G1 is assigned to h1 in the split. On the other
hand, if we remove fragment 2 from G, G is split
into two weakly connected components {1,5} and
{3,4,6,7}, whose solved forms must be plugged
into h21 and h22 respectively.
We can compute a chart like this using the algo-
rithm shown in Fig. 10. This recursive algorithm
gets some subgraph G? of the original graph G as
its first argument. It returns true if G? is solvable,
and false if it isn?t. If an entry for its argument G?
was already computed and recorded in the chart,
the procedure returns immediately. Otherwise, it
computes the free fragments of G?. If there are no
free fragments, G was unsolvable, and thus the al-
gorithm returns false; on the other hand, if G? only
contains one fragment, it is solved and we can im-
mediately return true.
If none of these special cases apply, the algo-
rithm iterates over all free fragments F of G? and
computes the (unique) split that places F at the
root of the solved forms. If all weakly connected
components represented in the split are solvable, it
records the split as valid for G?, and returns true.
If the algorithm returns with value true, the
chart will be filled with splits for all subgraphs of
G that the GRAPH-SOLVER algorithm would have
visited. It is also guaranteed that every split in the
chart is used in a solved form of the graph. Ex-
tracting the actual solved forms from the chart is
straightforward, and can be done essentially like
for parse charts of context-free grammar.
Runtime analysis. The chart computed by the
chart solver for a dominance graph with n
nodes and m edges can grow to at most O(n ?
wcsg(G)) entries, where wcsg(G) is the number of
weakly connected subgraphs of G: All subgraphs
for which GRAPH-SOLVER-CHART is called are
weakly connected, and for each such subgraph
there can be at most n different splits. Because a
recursive call returns immediately if its argument
is already present in the chart, this means that at
most O(n ?wcsg(G)) calls spend more than the ex-
pected constant time that it takes to look up G? in
the chart. Each of these calls needs time O(m+n),
the cost of computing the free fragments.
As a consequence, the total time that GRAPH-
SOLVER-CHART takes to fill the chart is O(n(n+
m)wcsg(G)). Applied to a dominance constraint
with k atoms, the runtime is O(k2wcsg(G)). On
the other hand, if G has N solved forms, it takes
time O(N) to extract these solved forms from the
chart. This is a significant improvement over the
O(n(n + m)N) time that GRAPH-SOLVER takes
to enumerate all solved forms. A particularly dra-
matic case is that of chains ? graphs with a zig-zag
shape of n upper and n? 1 lower fragments such
as in Fig. 8, which occur frequently as part of un-
derspecified descriptions. A chain has only O(n2)
weakly connected subgraphs and O(n) edges, so
the chart can be filled in time O(n4), despite the
fact that the chain has 1
n+1
(2n
n
)
solved forms (this is
the n-th Catalan number, which grows faster than
n!). The worst case for the chart size is shown in
Fig. 11. If such a graph has n upper fragments,
it has O(2n) weakly connected subgraphs, so the
chart-filling phase takes time O(n22n). But this is
still dominated by the N = n! solved forms that
this graph has.
4 Evaluation
We conclude this paper with a comparative run-
time evaluation of the presented dominance con-
gf h
a
i
Figure 11: A worst-case graph for the chart solver.
constraints max. solved forms
Rondane 961 ?
Nets 879 2.4 ?1012
Nets < 106 solved forms 852 997920
Solver solvable max. solved forms
Saturation (?3.1) 757 10030
Set constraints (?3.2) 841 557472
Graph (?3.3) 850 768254
Chart (?3.4) 852 997920
LKB 682 17760
All 682 7742
Figure 12: Sizes of the data sets.
straint solvers. To put the results into context, we
also compare the runtimes with a solver for Min-
imal Recursion Semantics (MRS) (Copestake et
al., 2004), a different formalism for scope under-
specification.
Resources. As our test set we use constraints ex-
tracted from the Rondane treebank, which is dis-
tributed as part of the English Resource Grammar
(Copestake and Flickinger, 2000). The treebank
contains syntactic annotations for sentences from
the tourism domain such as (4) above, together
with corresponding semantic representations.
The semantics is represented using MRS de-
scriptions, which we convert into normal domi-
nance constraints using the translation specified by
Niehren and Thater (2003). The translation is re-
stricted to MRS constraints having certain struc-
tural properties (called nets). The treebank con-
tains 961 MRS constrains, 879 of which are nets.
For the runtime evaluation, we restricted the
test set to the 852 nets with less than one mil-
lion solved forms. The distribution of these con-
straints over the different constraint sizes (i.e.
number of fragments) is shown in Fig. 15. We
solved them using implementations of the pre-
sented dominance constraint solvers, as well as
with the MRS solver in the LKB system (Copes-
take and Flickinger, 2000).
Runtimes. As Fig. 12 shows, the chart solver
is the only solver that could solve all constraints
in the test set; all other solvers ran into memory
limitations on some inputs.2 The increased com-
plexity of constraints that each solver can handle
(given as the maximum number of solved forms of
a solvable constraint) is a first indication that the
repeated analysis and improvement of dominance
constraint solvers described earlier was successful.
Fig. 13 displays the result of the runtime com-
parison, taking into account only those 682 con-
straints that all solvers could solve. For each con-
straint size (counted in number of fragments), the
graph shows the mean quotient of the time to enu-
merate all solved forms by the number of solved
forms, averaged over all constraints of this size.
Note that the vertical axis is logarithmic, and that
the runtimes of the LKB and the chart solver for
constraints up to size 6 are too small for accurate
measurement.
The figure shows that each new generation of
dominance constraint solvers improves the perfor-
mance by an order of magnitude. Another differ-
ence is in the slopes of the graphs. While the sat-
uration solver takes increasingly more time per
solved form as the constraint grows, the set con-
straint and graph solvers remain mostly constant
for larger constraints, and the line for the chart
solver even goes down. This demonstrates an im-
proved management of the combinatorial explo-
sion. It is also interesting that the line of the set-
constraint solver is almost parallel to that of the
graph solver, which means that the solver really
does exploit a polynomial fragment on real-world
data.
The LKB solver performs very well for smaller
constraints (which make up about half of the data
set): Except for the chart algorithm introduced in
this paper, it outperforms all other solvers. For
larger constraints, however, the LKB solver gets
very slow. What isn?t visible in this graph is that
the LKB solver also exhibits a dramatically higher
variation in runtimes for constraints of the same
size, compared to the dominance solvers. We be-
lieve this is because the LKB solver has been op-
timised by hand to deal with certain classes of in-
2On a 1.2 GHz PC with 2 GB memory.
puts, but at its core is still an uncontrolled expo-
nential algorithm.
We should note that the chart-based solver is
implemented in C++, while the other dominance
solvers are implemented in Oz, and the MRS
solver is implemented in Common Lisp. This ac-
counts for some constant factor in the runtime, but
shouldn?t affect the differences in slope and vari-
ability.
Effect of the chart. Because the chart solver is
especially efficient if the chart remains small, we
have compared how the number of solved forms
and the chart size (i.e. number of splits) grow with
the constraint size (Fig. 14). The graph shows that
the chart size grows much more slowly than the
number of solved forms, which supports our intu-
ition that the runtime of the chart solver is asymp-
totically less than that of the graph solver by a sig-
nificant margin. The chart for the most ambigu-
ous sentence in the treebank (sentence (4) above)
contains 74.960 splits. It can be computed in less
than ten seconds. By comparison, enumerating all
solved forms of the constraint would take about a
year on a modern PC. Even determining the num-
ber of solved forms of this constraint is only pos-
sible based on the chart.
5 Conclusion
In this paper we described the evolution of solvers
for dominance constraints, a logical formalism
used for the underspecified processing of scope
ambiguities. We also presented a new solver,
which caches the intermediate results of a graph
solver in a chart. An empirical evaluation shows
that each solver is significantly faster than the pre-
vious one, and that the new chart-based solver
is the fastest underspecification solver available
today. It is available online at http://utool.
sourceforge.net.
Each new solver was based on an analysis of the
main sources of inefficiency in the previous solver,
as well as an increasingly good understanding of
the input data. The main breakthrough was the re-
alisation that normal dominance constraints have
polynomial satisfiability and can be solved using
graph algorithms. We believe that this strategy of
starting with a clean, powerful formalism and then
successively searching for a fragment that con-
tains all practically relevant inputs and excludes
the pathologically hard cases is applicable to other
problems in computational linguistics as well.
However, it is clear that the concept of ?all prac-
tically relevant inputs? is a moving target. In this
paper, we have equated it with ?all inputs that can
be generated by a specific large-scale grammar?,
but new grammars or different linguistic theories
may generate underspecified descriptions that no
longer fall into the efficient fragments. In our case,
it is hard to imagine what dominance constraint
used in scope underspecification wouldn?t be nor-
mal, and we have strong intuitions that all use-
ful constraints must be nets, but it is definitely an
interesting question how our algorithms could be
adapted to, say, the alternative scope theory advo-
cated by Joshi et al (2003).
An immediate line of future research is to ex-
plore uses of the chart data structure that go be-
yond pure caching. The general aim of underspec-
ification is not to simply enumerate all readings
of a sentence, but to use the underspecified de-
scription as a platform on which readings that are
theoretically possible, but infelicitous in the actual
context, can be eliminated. The chart may prove
to be an interesting platform for such operations,
which combines advantages of the underspecified
description (size) and the readings themselves (ex-
plicitness).
Acknowledgements. The work has been funded
by the DFG in the Collaborative Research Cen-
tre 378 Ressource-Adaptive Cognitive Processes,
project MI 2 (CHORUS).
We would like to thank Joachim Niehren and
Denys Duchier for the extremely fruitful col-
laboration on dominance constraint solving, Ann
Copestake and Dan Flickinger for helpful discus-
sions about the ERG and the LKB solver, and our
reviewers for their comments. The primary imple-
mentors of the various earlier constraint solvers
were Katrin Erk and Sebastian Pad? (?3.1), Denys
Duchier (?3.2), and Sebastian Miele (?3.3).
References
Ernst Althaus, Denys Duchier, Alexander Koller, Kurt
Mehlhorn, Joachim Niehren, and Sven Thiel. 2003.
An efficient graph algorithm for dominance con-
straints. Journal of Algorithms, 48:194?219.
Krzysztof R. Apt. 2003. Principles of Constraint Pro-
gramming. Cambridge University Press.
Manuel Bodirsky, Denys Duchier, Joachim Niehren,
and Sebastian Miele. 2004. An efficient algorithm
for weakly normal dominance constraints. In ACM-
SIAM Symposium on Discrete Algorithms. The ACM
Press.
Ann Copestake and Dan Flickinger. 2000. An
open-source grammar development environment
and broad-coverage english grammar using HPSG.
In Conference on Language Resources and Evalua-
tion. The LKB system is available at http://www.
delph-in.net/lkb/.
Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan
Sag. 2004. Minimal recursion semantics: An intro-
duction. Journal of Language and Computation. To
appear.
Denys Duchier and Joachim Niehren. 2000. Domi-
nance constraints with set operators. In Proceed-
ings of the First International Conference on Com-
putational Logic, number 1861 in Lecture Notes in
Computer Science, pages 326?341. Springer-Verlag,
Berlin.
Markus Egg, Alexander Koller, and Joachim Niehren.
2001. The Constraint Language for Lambda Struc-
tures. Logic, Language, and Information, 10:457?
485.
Aravind Joshi, Laura Kallmeyer, and Maribel Romero.
2003. Flexible composition in LTAG, quantifier
scope and inverse linking. In Harry Bunt, Ielka
van der Sluis, and Roser Morante, editors, Proceed-
ings of the Fifth International Workshop on Compu-
tational Semantics, pages 179?194, Tilburg.
Alexander Koller, Joachim Niehren, and Ralf Treinen.
1998. Dominance constraints: Algorithms and com-
plexity. In Proceedings of LACL, pages 106?
125. Appeared in 2001 as volume 2014 of LNAI,
Springer Verlag.
Tobias M?ller and Martin M?ller. 1997. Finite set con-
straints in Oz. In Fran?ois Bry, Burkhard Freitag,
and Dietmar Seipel, editors, 13. Workshop Logische
Programmierung, pages 104?115, Technische Uni-
versit?t M?nchen.
Joachim Niehren and Stefan Thater. 2003. Bridg-
ing the gap between underspecification formalisms:
Minimal recursion semantics as dominance con-
straints. In Proceedings of the 41st Annual Meeting
of the Association for Computational Linguistics.
Oz Development Team. 2004. The Mozart Pro-
gramming System. Web pages. http://www.
mozart-oz.org.
Sven Thiel. 2004. Efficient Algorithms for Con-
straint Propagation and for Processing Tree De-
scriptions. Ph.D. thesis, Department of Computer
Science, Saarland University.
 0.01
 0.1
 1
 10
 100
 1000
 0  2  4  6  8  10  12  14  16  18  20  22
R
u
n
t
i
m
e
 
p
e
r
 
s
o
l
u
t
i
o
n
 
(
i
n
 
m
s
)
Size of the constraint
"Section-3.1"
"Section-3.2"
"Section-3.3"
"Section-3.4"
"MRS"
Figure 13: Average runtimes per solved form, for each constraint size (number of fragments).
 1
 10
 100
 1000
 10000
 0  2  4  6  8  10  12  14  16  18  20  22
Nu
m
be
r
 
o
f
 
s
o
l
u
t
i
o
n
s
/S
i
z
e
 
o
f
 
t
h
e
 
c
h
a
r
t
Size of the constraint
"chart-size"
"solved-forms"
Figure 14: Average size of the chart compared to the average number of solved forms, for each constraint
size. Notice that the measurements are based upon the same set of constraints as in Fig. 13, which
contains very few constraints of size 20 or more.
 0
 10
 20
 30
 40
 50
 60
 70
 0  5  10  15  20  25  30  35  40
"rondane-nets"
"rondane-test-set"
Figure 15: Distribution of the constraints in Rondane over the different constraint sizes. The solid line in-
dicates the 852 nets with less than one million solved forms; the dashed line indicates the 682 constraints
that all solvers could solve.
Inference in Computational Semantics ICoS-5
Buxton, England
April 20?21, 2006
Workshop Proceedings
Johan Bos and Alexander Koller (Eds.)

About ICoS
Natural Language Processing has reached a stage where the exploration and development of
inference is one of its most pressing tasks. On the theoretical side, it is clear that inference
plays a key role in such areas as semantic construction and the management of discourse
and dialogue. On the practical side, the use of sophisticated inference methods is expected
to play a crucial role in such application areas as natural language generation, automatic
question answering, and spoken dialogue systems. At the same time, inference tools and
resources have matured to the point that they can become useful for actual applications.
Automated theorem provers and other inference tools are becoming increasingly robust and
efficient. And the world knowledge bottleneck is being addressed from different angles, by
the manual development of knowledge resources, the merging of existing such resources,
and the automated extraction of world knowledge from corpora.
The Inference in Computational Semantics (ICoS) workshops are intended to bring
together researchers from areas such as Computational Linguistics, Artificial Intelligence,
Computer Science, Formal Semantics, and Logic, to discuss approaches to, and applica-
tions of, inference in natural language semantics. ICoS-1 took place in Amsterdam, the
Netherlands, on August 15, 1999. ICoS-2 was organised in Dagstuhl Castle, Germany, on
July 29?30, 2000. ICoS-3 was co-located with the International Joint Conference on Au-
tomated Reasoning (IJCAR 2001), which took place on June 18?23, 2001 at Siena, Italy.
ICoS-4 took place in Nancy, France, on September 25?26, 2003.
Welcome to ICoS-5
ICoS-5 is organised as a two-day event at the University of Derby College, Buxton, Eng-
land, taking place on April 20?21. The programme features three invited presentations
(by Christian Ebert, Patrick Pantel, and Stephen Pulman). In addition, we have selected
twelve regular papers from 24 submissions, which span topics ranging from the use of infer-
ence techniques for formal and computational semantics, over new methods for knowledge
extraction from corpora, to NLP applications that use inference tools.
We have accepted six of the remaining submissions as ?short papers?. These papers
will be presented as posters and demos at the workshop, and we believe that this new
format will be a worthwhile experience both for authors and for participants.
We would like to thank the members of the programme committee, who produced highly
informative reviews and made it possible to set up the broad and strong program for ICoS-
5. Finally, we are very grateful to the local organisers, Ian Pratt-Hartmann and Allan
Ramsay, who did a flawless job of preparing what promises to be a wonderful workshop
location for us.
Rome and Saarbru?cken, March 2006
Johan Bos & Alexander Koller (co-chairs)
iii
iv
Workshop Organization
Programme Committee
Carlos Areces INRIA Lorraine
Peter Baumgartner National ICT Australia
Christoph Benzmueller University of the Saarland
Raffaella Bernardi Free University of Bozen-Bolzano
Patrick Blackburn INRIA Lorraine
Johan Bos (co-chair) University of Roma ?La Sapienza?
Harry Bunt Tilburg University
Ann Copestake University of Cambridge
Dick Crouch PARC
Ido Dagan Bar Ilan University
Kees van Deemter University of Aberdeen
Nissim Francez Technion
Claire Gardent CNRS/LORIA
Alexander Koller (co-chair) University of the Saarland
Shalom Lappin King?s College London
Alex Lascarides University of Edinburgh
Bernardo Magnini ITC-Irst
Katja Markert University of Leeds
Dan Moldovan University of Texas at Dallas
Jeff Pelletier Simon Fraser University
Maarten de Rijke University of Amsterdam
Michael Schiehlen University of Stuttgart
Matthew Stone Rutgers
Bonnie Webber University of Edinburgh
Local Organizers
Ian Pratt-Hartmann School of Computer Science, University of Manchester
Allan Ramsay School of Informatics, University of Manchester
v
vi
Table of Contents
Abstracts of Invited Talks
Expressive Power and Complexity of Underspecified Representations . . . . . . . . . . . . . . . . . . 1
Christian Ebert
Knowledge Harvesting and Fusion from Small and Large Corpora . . . . . . . . . . . . . . . . . . . . . 3
Patrick Pantel
Bridging the gap between formal and computational semantics . . . . . . . . . . . . . . . . . . . . . . . . 5
Stephen Pulman
Regular Papers
Anaphora Resolution and Minimal Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
Ariel Cohen
Extracting Formal Specifications from Natural Language Regulatory Documents . . . . . 17
Nikhil Dinesh, Aravind Joshi, Insup Lee and Bonnie Webber
How to change a person?s mind: Understanding the difference between the effects
and consequences of speech acts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
Debora Field and Allan Ramsay
Towards a redundancy elimination algorithm for underspecified descriptions . . . . . . . . . . 37
Alexander Koller and Stefan Thater
Quantifiers in Dependency Tree Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
Leonardo Lesmo, Livio Robaldo, and Jelle Gerbrandy
Controlled Language for Geographical Information System Queries . . . . . . . . . . . . . . . . . . . 57
Sela Mador-Haim, Yoad Winter and Anthony Braun
Computing relative polarity for textual inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen
Using Answer Set Programming in an inference-based approach to
Natural Language Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
Farid Nouioua and Pascal Nicolas
A Bootstrapping Algorithm for Automatically Harvesting Semantic Relations . . . . . . . . 87
Marco Pennacchiotti and Patrick Pantel
Concepts across categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
Hilke Reckman and Crit Cremers
Multi-dimensional Temporal Logic for Events and States . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
Satoshi Tojo
Considerations on the nature of metaphorical meaning arising from a computational
treatment of metaphor interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
A.M. Wallington, R. Agerri, J.A. Barnden, S.R. Glasbey, and M.G. Lee
vii
Short Papers
Supporting temporal question answering: strategies for offline data collection . . . . . . . . 127
David Ahn, Steven Schockaert, Martine De Cock, and Etienne Kerre
Formal semantics of verbs for knowledge inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .133
Igor Boyko
Ingredients of a first-order account of bridging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
Philipp Cimiano
A Computational Theory of Inference for Arithmetic Explanation . . . . . . . . . . . . . . . . . . . 145
Albert Goldfain
Towards a Logical Foundation of Semantic Networks - A Typology of
Descriptive Means for Semantic Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
Hermann Helbig and Ingo Glo?ckner
The Alligator theorem prover for dependent type systems:
Description and proof samples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
Paul Piwek
viii
Expressive Power and Complexity
of Underspecified Representations
Christian Ebert
Fakulta?t fu?r Linguistik und Literaturwissenschaft
Universita?t Bielefeld
My talk will be about two requirements on Underspecified Representation Formalisms in
the context of underspecification of scope. The requirement on partial disambiguation,
stating that partially disambiguated ambiguities need to be represented, does not carry
much content unless it has become clear, exactly what those ambiguities are. In line with
Ko?nig and Reyle [1999], I will argue that all theoretically possible patterns of ambiguity,
i.e. subsets of readings, can occur in natural language, in particular when underspeci-
fied representations are assumed to represent patterns of ambiguity that arise through
disambiguation by discourse or even by world knowledge. Therefore an underspecified
representation formalism can only be regarded as expressively complete, if it provides rep-
resentations for all potential subsets of readings. Taking a closer look at recent prominent
approaches to scope underspecification, namely Hole Semantics [Bos, 2002], Minimal Re-
cursion Semantics [Copestake et al, 1999], and Normal Dominance Constraints [Koller,
2004], it turns out that none of these formalisms is expressively complete. Furthermore,
these incompleteness results allow for a straightforward comparison of the discussed ap-
proaches with respect to expressive power.
The second requirement is the avoidance of combinatorial explosion. I will argue that
the decisive process that determines the efficiency of an underspecification approach is
the construction phase of the representations and not so much the check for satisfiability
or enumeration of readings. Thus the desired avoidance of combinatorial explosion comes
down to a requirement on a feasible construction procedure and hence to a requirement on
the maximal ?size? of the representations, which can only be fulfilled if the involved repre-
sentations are in some sense more compact than the mere listing of the available readings.
Unfortunately it turns out that due to the rapid growth of the number of potential patterns
of ambiguity, the two requirements of compactness and expressive completeness cannot be
fulfilled at the same time. In other words, I will show that any underspecified representa-
tion formalism must necessarily miss out on some of the potential patterns of ambiguity
or run into the combinatorial explosion problem [Ebert, 2005].
References
Johan Bos. Underspecification and Resolution in Discourse Semantics. PhD thesis, Uni-
versita?t des Saarlandes, 2002.
Ann Copestake, Dan Flickinger, and Ivan A. Sag. Minimal Recursion Semantics ? An
Introduction. Technical report, CSLI, Stanford University, 1999. (Draft).
Christian Ebert. Formal Investigations of Underspecified Representations. PhD thesis,
King?s College London, 2005.
Alexander Koller. Constrained-Based And Graph-Based Resolution of Ambiguities in Nat-
ural Language. PhD thesis, Universita?t des Saarlandes, July 2004.
Esther Ko?nig and Uwe Reyle. A General Reasoning Scheme for Underspecified Represen-
tations. In Logic, Language and Reasoning. Essays in Honour of Dov Gabbay., pages
251?277. Kluwer, 1999.
1
2
Knowledge Harvesting and Fusion from Small and Large CorporaPatrick PantelISI, University of Southern CaliforniaInferencing requires large collections of axioms and knowledge bases of interrelatedconcepts and instances. In the past decade, researchers have explored many approaches toautomatically learn such knowledge from textual corpora. In this two-part talk, we willdiscuss the challenges of harvesting knowledge from various corpus sizes and we willlook at some recent attempts at fusing the knowledge into a single semantic repository.On the harvesting front, we will focus on the challenges posed by three types of corpora:i) the Web (order of 1012 words) ? pattern learning algorithms, models of reliability, andscalable computing; ii) large corpora such as newswire collections (order of 109 words) ?amenable to complex natural language processing and clustering; and iii) small corporasuch as college textbooks (order of 105 words) ? in which low redundancy requiresleveraging external resources such as the Web and ontologies.This multitude of harvested knowledge inevitably overlaps and is partially inconsistentand incompatible since information can be expressed across data sources in so manyways. However, little effort has been spent on fusing such harvested knowledge into anoverarching consistent semantic repository. We will present a recent algorithm for linkingsemantic resources using grammatical templates. We will also present an algorithm toautomatically induce conceptual relations between mid-level ontological concepts andthen disambiguate instances with regard to the most appropriate senses in the ontology,using the induced conceptual relations.
3
4
Bridging the gap between formal and computational semantics
Stephen Pulman
Computational Linguistics Group, Oxford University.
The literature in formal linguistic semantics contains a wealth of fine grained
and detailed analyses of many linguistic phenomena. But very little of this work
has found its way into implementations, despite a widespread feeling (among
linguists at least) that this can?t be very difficult in principle: you just fix a
grammar to produce the right logical forms and hook them up to a theorem
prover, don?t you? In this talk I take a representative analysis of adjectival
comparatives and ask what steps one might actually have to go through so as to
use this analysis in a realistic question-answering setting. I then try to identify
some general conclusions that can be drawn from this exercise.
5
Towards a redundancy elimination algorithm
for underspecified descriptions
Alexander Koller and Stefan Thater
Department of Computational Linguistics
Universit?t des Saarlandes, Saarbr?cken, Germany
{koller,stth}@coli.uni-sb.de
Abstract
This paper proposes an efficient algorithm for the redundancy elimination problem: Given
an underspecified semantic representation (USR), compute an USR which has fewer read-
ings, but still describes at least one representative of each semantic equivalence class of the
original readings. The algorithm operates on underspecified chart representations which
are derived from dominance graphs; it can be applied to the USRs computed by large-
scale grammars. To our knowledge, it is the first redundancy elimination algorithm which
maintains underspecification, rather than just enumerating non-redundant readings.
1 Introduction
Underspecification is the standard approach to dealing with scope ambiguities in
computational semantics [12,6,7,2]. The basic idea is to not enumerate all possible
semantic representations for each syntactic analysis, but to derive a single compact
underspecified representation (USR). This simplifies semantics construction, and
current algorithms support the efficient enumeration of readings from an USR [10].
In addition, underspecification has the potential for eliminating incorrect or re-
dundant readings by inferences based on context or world knowledge, without even
enumerating them. For instance, sentences with scope ambiguities often have read-
ings which are semantically equivalent. In this case, we typically need to retain
only one reading from each equivalence class. This situation is illustrated by the
following two sentences from the Rondane treebank, which is distributed with the
English Resource Grammar (ERG; [5]), a broad-coverage HPSG grammar.
(1) For travellers going to Finnmark there is a bus service from Oslo to Alta
through Sweden. (Rondane 1262)
(2) We quickly put up the tents in the lee of a small hillside and cook for the first
time in the open. (Rondane 892)
For the two example sentences, the ERG (Version 01-2006) derives USRs with
seven and six quantifiers, respectively, that correspond to various types of noun
phrases (including proper names and pronouns). The USR for (1) describes 3960
readings, which are all semantically equivalent to each other. On the other hand, the
USR for (2) has 480 readings, which fall into two classes of mutually equivalent
readings, characterised by the relative scope of ?the lee of? and ?a small hillside.?
This paper presents an algorithm for the redundancy elimination problem: Given
an USR, compute an USR which has fewer readings, but still describes at least one
representative of each equivalence class ? without enumerating any readings. This
algorithm computes the one or two representatives of the semantic equivalence
classes in the above examples, so subsequent modules don?t have to deal with all
the other equivalent readings. It also closes the gap between the large number of
readings predicted by the grammar and the intuitively perceived much lower degree
of ambiguity of these sentences. Finally, it can be helpful for a grammar designer
because it is much more feasible to check whether two readings are linguistically
reasonable than 480.
We model equivalence in terms of rewrite rules that permute quantifiers without
changing the semantics of the readings. The particular USRs we work with are un-
derspecified chart representations, which can be computed from dominance graphs
(or USRs in some other underspecification formalisms) efficiently [10]. The algo-
rithm can deal with many interesting cases, but is incomplete in the sense that the
resulting USR may still describe multiple equivalent readings.
To our knowledge, this is the first algorithm in the literature for redundancy
elimination on the level of USRs. There has been previous research on enumerating
only some representatives of each equivalence class [13,4], but these approaches
don?t maintain underspecification: After running their algorithms, we have a set of
readings rather than an underspecified representation.
Plan of the paper. We will first define dominance graphs and review the necessary
background theory in Section 2. We will then give a formal definition of equiva-
lence and derive some first results in Section 3. Section 4 presents the redundancy
elimination algorithm. Finally, Section 5 concludes and points to further work.
2 Dominance Graphs
The basic underspecification formalism we assume here are labelled dominance
graphs [1]. Dominance graphs are equivalent to leaf-labelled normal dominance
constraints [7], which have been discussed extensively in previous literature.
Definition 2.1 A (compact) dominance graph is a directed graph (V,E unionmultiD) with
two kinds of edges, tree edges E and dominance edges D, such that:
(i) the graph (V,E) defines a collection of node disjoint trees of height 0 or 1. We
call the trees in (V,E) the fragments of the graph.
(ii) if (v,v?) is a dominance edge in D, then v is a hole and v? is a root in G. A node
v is a root (in G) if v does not have incoming tree edges; otherwise, v is a hole.
A labelled dominance graph over a ranked signature ? is a triple G = (V,E unionmultiD,L)
ay
sample
y
see
x,y
a
x
repr-of
x,z
a
z
comp
z
1 2 3
4 5 6
7
a
y
a
x
a
z
1
2
3
sample
y
see
x,y
repr-of
x,z
comp
z
a
y
a
x
sample
y
see
x,y
repr-of
x,z
a
z
comp
z
1
2
3
Fig. 1. A dominance graph that represents the five readings of the sentence ?a representative
of a company saw a sample? (left) and two (of five) configurations.
1 2 3
4 5 6
7
h
2
h
1
h
4
h
3
h
6
h
5
1 3
4 5 6
7
h
2
h
1
h
6
h
5
? ?
h
2
h
1
h
4
h
3
h
6
h
5
2
1 3
4 5 6 7
Fig. 2. An example computation of a solved form.
such that (V,E unionmultiD) is a dominance graph and L : V  ? is a partial labelling
function which assigns a node v a label with arity n iff v is a root with n outgoing
tree edges. Nodes without labels (i.e., holes) must have outgoing dominance edges.
We will write v: f (v1, . . . ,vk) for a fragment whose root v is labelled with f and
whose holes are v1, . . . ,vk. We will write R(F) for the root of the fragment F , and
we will typically just say graph instead of labelled dominance graph.
An example of a labelled dominance graph is shown to the left of Fig. 1. Tree
edges are drawn as solid lines, and dominance edges are drawn as dotted lines, di-
rected from top to bottom. This graph can serve as an USR for the sentence ?a repre-
sentative of a company saw a sample? if we demand that the holes are ?plugged? by
roots while realising the dominance edges as dominance, as in the two (of five) con-
figurations shown to the right [7]. Configurations encode semantic representations
of the sentence, and we freely read configurations as ground terms over ?.
2.1 Solving dominance graphs
Algorithms for solving a dominance graph in order to compute the readings it de-
scribes typically compute its minimal solved forms [1,3]. In this paper, we restrict
ourselves to hypernormally connected graphs (defined below), for which one can
show that all solved forms are minimal and bijectively correspond to configurations.
Let G,G? be dominance graphs. We say that G is in solved form iff it is a forest,
and G is a solved form of G? if G is in solved form and more specific than G? i.e., G
and G? have the same labels and tree fragments, and the reachability relation of G
extends that of G?. G? is solvable if it has a solved form G. If G? is hypernormally
connected, then each hole in G has exactly one outgoing dominance edge, and G
can be mapped to a configuration by identifying the two ends of each dominance
edge; conversely, we can find a unique solved form for each configuration. The
graph to the left of Fig. 2 shows one of the (minimal) solved forms of the example
graph, which corresponds to the configuration in the middle of Fig. 1.
Compute-Chart(G)
1 if there is an entry for G in the chart
2 then return true
3 free? Free-Fragments(G)
4 if free = /0
5 then return false
6 if G contains only one fragment
7 then return true
8 for each F ? free
9 do split? Split(G,F)
10 for each S ?Wccs(G?F)
11 do if Compute-Chart(S) = false
12 then return false
13 add (G,split) to the chart
14 return true
{1,2,3,4,5,6,7} :?1,h1 7? {4},h2 7? {2,3,5,6,7}?
?2,h3 7? {1,4,5},h4 7? {3,6,7}?
?3,h5 7? {5},h6 7? {1,2,4,5,7}?
{2,3,5,6,7} :?2,h3 7? {5},h4 7? {3,6,7}?
?3,h5 7? {6},h6 7? {2,5,7}?
{3,6,7} :?3,h5 7? {6},h6 7? {7}?
{2,5,7} :?2,h3 7? {5},h4 7? {7}?
{1,4,5} :?1,h1 7? {4},h2 7? {5}?
{1,2,4,5,7} :?1,h1 7? {4},h2 7? {2,5,7}?
?2,h3 7? {1,4,5},h4 7? {7}?
Fig. 3. The chart solver and an example chart computed for the dominance graph in Fig. 2.
The key concept of the solver we build upon is that of a free fragment [3]. A
fragment F in a solvable graph G is free iff there is a solved form in which F is at
the root. It can be shown that a fragment is free iff it has no incoming dominance
edges and its holes are in different biconnected components of the graph i.e., they
are disconnected if the root of the fragment is removed from the graph [3]. Remov-
ing a free fragment from a graph splits the graph into different weakly connected
components (wccs) ? one for each hole. Thus each free fragment F induces a split
of G, which consists of a reference to F and a mapping of the other fragments to the
hole to which they are connected. For instance, the example graph has three free
fragments: 1, 2, and 3. By removing fragment 2, the graph is decomposed into two
wccs, which are connected to the holes h3 and h4, respectively (see Fig. 2).
The solver [10] is shown in Fig. 3. It computes a chart-like data structure which
assigns sets of splits to subgraphs. For each subgraph it is called on, the solver
computes the free fragments, the splits they induce, and calls itself recursively on
the wccs of each split. It records subgraphs and splits in the chart, and will not
repeat work for a subgraph it has encountered before. The algorithm returns true iff
the original graph was solvable. The chart tells us how to build the minimal solved
forms of the graph: For each subgraphs, pick any split, compute a solved form for
each wcc recursively, and plug them into the given hole of the split?s root fragment.
As an example, the chart for the graph in Fig. 1 is shown to the right of Fig. 3.
Notice that the chart which the solver computes, while possibly exponentially
larger than the original graph, is still exponentially smaller than the entire set of
readings because common subgraphs (such as {2,5,7} in the example) are repre-
sented only once. Thus the chart can still serve as an underspecified representation.
2.2 Hypernormally connected dominance graphs
A hypernormal path [1] in a graph G is a path in the undirected version Gu of G that
does not use two dominance edges that are incident to the same hole. We say that
G is hypernormally connected (hnc) iff each pair of nodes is connected by a simple
hypernormal path in G. Hnc graphs are equivalent to chain-connected dominance
constraints [9], and are closely related to dominance nets [11]. The results in this
paper are restricted to hnc graphs, but this does not limit the applicability of our
results: an empirical study suggests that all dominance graphs that are generated by
current large-scale grammars are (or should be) hnc [8].
The key property of hnc dominance graphs is that their solved forms correspond
to configurations, and we will freely switch between solved forms and their corre-
sponding configurations. Another important property of hnc graphs which we will
use extensively in the proofs below is that it is possible to predict which holes of
fragments can dominate other fragments in a solved form.
Lemma 2.2 Let G be a hnc graph with free fragment F. Then all weakly connected
components of G?F are hnc.
Proposition 2.3 Let F1,F2 be fragments in a hnc dominance graph G. If there is a
solved form S of G in which R(F1) dominates R(F2), then there is exactly one hole
h of F1 which is connected to R(F2) by a simple hypernormal path which doesn?t
use R(F1). In particular, h dominates R(F2) in S.
Proof. Let?s say that F1 dominates F2 in some solved form S. There is a run of
the solver which computes S. This run chooses F1 as a free fragment before it
chooses F2. Let?s call the subgraph in which the split for F1 is chosen, G?. G? is hnc
(Lemma 2.2), so in particular there is a simple hypernormal path from the hole h
of F1 which is in the same wcc as F2 to R(F2); this path doesn?t use R(F1). On the
other hand, assume there were another hole h? of F1 which is connected to R(F2) by
a path that doesn?t use R(F1). Then the path via R(F2) would connect h and h? even
if R(F1) were removed, so h and h? would be in the same biconnected component
of G, in contradiction to the assumption that F1 is free in G?.
For the second result, note that F2 is assigned to the hole h in the split for F1.2
The following definition captures the complex condition in Prop. 2.3:
Definition 2.4 Let G be a hnc dominance graph. A fragment F1 in G is called a
possible dominator of another fragment F2 in G iff it has exactly one hole h which
is connected to R(F2) by a simple hypernormal path which doesn?t use R(F1). We
write ch(F1,F2) for this unique h.
3 Equivalence
Equivalence is traditionally defined as the relation between formulas which have
the same interpretation. However, even first-order equivalence is an undecidable
problem, thus an algorithm which checks for semantic equivalence of different con-
figurations of a graph can?t possibly be efficient. On the other hand, we do not need
to solve the full semantic equivalence problem, as we only want to compare formu-
las that are readings of the same sentence i.e., different configurations of the same
USR. Such formulas only differ in the way that the fragments are combined. We
can therefore approximate equivalence by using a rewrite system that permutes frag-
ments and defining equivalence of configurations as mutual rewritability as usual.
By way of example, consider again the two (equivalent) configurations shown
in Fig. 1. We can obtain the second configuration from the first one by applying the
following rewrite rule, which rotates the nodes 1 and 2:
ax(az(P,Q),R)? az(P,ax(Q,R)) (3)
The formulas on both sides of the arrow are semantically equivalent in first-order
logic for any choice of the subformulas P, Q, and R. Thus the equivalence of the
two configurations with respect to our one-rule rewrite system implies that they are
also semantically equivalent.
While we will require that the rewriting approximation is sound i.e., rewrites
formulas into equivalent formulas, we cannot usually hope to achieve completeness
i.e., there will be semantic equivalences that are not modelled by the rewriting
equivalence. However, we believe that the rewriting-based system will still prove
to be useful in practical applications, as the permutation of quantifiers is exactly the
kind of variability that an underspecified description allows.
We formalise this rewriting-based notion of equivalence as follows. The defini-
tion uses the abbreviation x[1,k) for x1, . . . ,xk?1, and x(k,n] for xk+1, . . . ,xn.
Definition 3.1 A permutation system R is a system of rewrite rules over a signature
? of the following form:
f1(x[1,i), f2(y[1,k),z,y(k,m]),x(i,n]) ? f2(y[1,k), f1(x[1,i),z,x(i,n]),y(k,m])
The permutability relation P(R) is the binary relation P(R)? (??N)2 which con-
tains exactly the pairs (( f1, i),( f2,k)) and (( f2,k),( f1, i)) for each such rewrite rule.
As usual, we say that two terms are equivalent with respect to R, s?R t, iff there
is a sequence of rewrite steps and inverse rewrite steps that rewrite s into t. We say
that R is sound with respect to a semantic notion of equivalence ? if ?R ??. If G
is a graph over ? and R a permutation system, then we write SCR(G) for the set of
equivalence classes Conf(G)/?R, where Conf(G) is the set of configurations of G.
A rewrite system (let?s call it Rfol) which is sound for the standard equivalence
relation of first-order logic could use rule (3) and the three other permutations of
two existential quantifiers, plus the following rule for universal quantifiers:
everyx(X ,everyy(Y,Z))? everyy(Y,everyx(X ,Z))
The other three permutations of universal quantifiers, as well as the permutations
of universal and existential quantifiers, are not sound.
It is possible to compute SCR(G) by solving G and using a theorem prover for
equational reasoning to compute the equivalence classes of the configurations, but
this is very inefficient. To replace this by a computation on the USR, we must be
able to recognise whether two fragments of a graph can be permuted in all config-
urations of the graph. This is not possible in general: If we don?t know in advance
xi+1
x
n
x
1
x
i-1
y
1
y
k-1
y
k+1
y
m
y
1
y
k-1
y
k+1
y
m
z
F
2
F
1
? ?
? ?
v
k
v = u
i
u
F
2
F
1
x
1
x
i-1
x
i+1
x
n
? ?
?
?
z
v
u
i
v
k
 = u
(a)
F
2
W
F
1
u
i
?
v
j
v
k
w
?
r
?
u
v
(b)
Fig. 4. Diagrams for the proof of Lemma 3.3
which hole of one fragment the other fragment can plug, we can?t know whether the
two fragments can be permuted. However, in a hnc graph, the hole of a fragment
which another fragment can plug is determined uniquely (because of Lemma 2.3),
and can be recognised without solving the graph.
Definition 3.2 Let R be a permutation system. Two fragments F1 and F2 with root
labels f1 and f2 in a graph G are called R-permutable iff they are possible domina-
tors of each other and (( f1,ch(F1,F2)),( f2,ch(F2,F1))) ? P(R).
Lemma 3.3 Let R be a permutation system, let F1 = u: f1(u1, . . . ,un) and F2 =
v: f2(v1, . . . ,vm) be R-permutable fragments in the hnc graph G, such that F2 is free,
and let C1 be a configuration of G in which u is the father of v. Then:
(a) It is possible to apply a R-rewrite step or an inverse R-rewrite step to C1 at u;
call the resulting tree C2.
(b) C2 is also a configuration of G.
(c) C2 ?R C1.
Proof. Let i = ch(F1,F2) and k = ch(F2,F1); we know that (( f1, i),( f2,k)) ? P(R).
(a) F1 is a possible dominator of F2, so ui is plugged with v in C1 (Lemma 2.3).
Thus the (possibly inverse) rule which justified the tuple (( f1, i),( f2,k)) is applica-
ble at u.
(b) We must verify that every dominance edge in G is realised byC2. As Fig. 4a
shows, all dominance edges that do not go out of a hole of F1 are still trivially
realised byC2. Now let?s consider dominances out of the holes of F1.
? Dominance edges out of any u j with j 6= i are still satisfied (see the figure).
? Dominance edges from ui to a node in z are still satisfied (see the figure).
? Dominance edges from ui to v: Such edges cannot exist in G as F2 is free.
? Dominance edges from ui to a node w in some y j with j 6= k: Such edges cannot
exist either. F2 is a possible dominator of the fragment W whose root w is, so
there is a simple hypernormal path piw from ch(F2,W ) to w which doesn?t use v;
ch(F2,W ) = v j because v j dominates w in C1 (Lemma 2.3). On the other hand,
F2 is a possible dominator of F1, so there is a simple hypernormal path piu from
vk to ui which doesn?t use v. Now if there were a dominance edge from ui to w
in G, then v j and vk would be in the same biconnected component (they would
be connected via piu ? (ui,w) ? pi?1w if v were removed), which contradicts the
freeness of F2 (see Fig. 4b).
4 Underspecified redundancy elimination
Now we can finally consider the problem of strengthening an USR in order to
remove redundant readings which are equivalent to other readings. We will define
an algorithm which gets as its input a graph G, a chart as computed by COMPUTE-
CHART, and a permutability relation P(R). It will then remove splits from the chart,
to the effect that the chart represents fewer solved forms of the original graph, but at
least one representative from each class in SCR(G) remains. The subgraph sharing
of the original chart will be retained, so the computed chart is still an USR.
The key concept in the redundancy elimination algorithm is that of a permutable
split. Intuitively, a split of G is called permutable if its root fragment F is per-
mutable with all other fragments in G which could end up above F . Because of
Lemma 3.3, we can then always pull F to the root by a sequence of rewrite steps.
This means that for any configuration of G, there is an equivalent configuration
whose root is F ? i.e., by choosing the split for F , we lose no equivalence classes.
Definition 4.1 Let R be a permutation system. A split S of a graph G is called R-
permutable iff the root fragment F of S is R-permutable with all other fragments in
G which are possible dominators of F in G.
In the graph of Fig. 1, all three splits are Rfol-permutable: For each of the upper
fragments, the other two upper fragments are possible dominators, but as all three
fragments are labelled with existential quantifiers and Rfol contains all permutations
of existential quantifiers, the fragments are permutable with each other. And indeed,
we can pick any of the three fragments as the root fragment, and the resulting split
will describe a representative of the single equivalence class of the graph.
Proposition 4.2 Let G be a hnc graph, and let S be a permutable split of G. Then
SC(S) = SC(G).
Proof. If G is unsolvable, the claim is trivially true. Otherwise, let C be an arbi-
trary configuration of G; we must show that S = (F,h1 7? G1, . . . ,hn 7? Gn) has a
configurationC? which is equivalent toC.
Let?s say that the fragments which properly dominate F in C are F1, . . . ,Fn
(n ? 0), ordered in such a way that Fi dominates Fj in C for all i < j. Each Fi is
a possible dominator of F , by Prop. 2.3. Because S is permutable, this means that
each Fi is permutable with F in G. By applying Lemma 3.3 n times (first to F and
Fn, then to F and Fn?1, and so on), we can compute a configuration C? of G in
which F is at the root and such that C? ?R C. But C is a configuration of S, which
proves the theorem. 2
This suggests the following redundancy elimination algorithm:
Redundancy-Elimination(Ch,G,R)
1 for each subgraph G? inCh
2 do if G? has an R-permutable split S
3 then remove all splits for G? except for S fromCh
Because of Prop. 4.2, the algorithm is correct in that for each configurationC of
G, the reduced chart still has a configurationC? withC?R C?. The particular choice
of S doesn?t affect the correctness of the algorithm (but may change the number
of remaining configurations). However, the algorithm is not complete in the sense
that the reduced chart can have no two equivalent configurations. We will illustrate
this below. We can further optimize the algorithm by deleting subgraphs (and their
splits) that are not referenced anymore by using reference counters. This doesn?t
change the set of solved forms of the chart, but may further reduce the chart size.
In the running example, we would run REDUNDANCY-ELIMINATION on the
chart in Fig. 3. As we have seen, all three splits of the entire graph are permutable,
so we can pick any of them e.g., the split with root fragment 2, and delete the splits
with root fragments 1 and 3. This reduces the reference count of some subgraphs
(e.g. {2,3,5,6,7}) to 0, so we can remove these subgraphs too. The resulting chart
is shown below, which represents a single solved form (the one shown in Fig. 2).
{1,2,3,4,5,6,7} : ?2,h2 7? {1,4},h4 7? {3,6,7}?
{1,4} : ?1,h1 7? {4}?
{3,6,7} : ?3,h5 7? {6},h6 7? {7}?
Now consider variations of the graph in Fig. 1 in which the quantifier labels are
different; these variant graphs have exactly the same chart, but fewer fragment pairs
will be permutable. If all three quantifiers are universal, then the configurations fall
into two equivalence classes which are distinguished by the relative scope of the
fragments 1 and 2. The algorithm will recognise that the split with root fragment 3
is permutable and delete the splits for 1 and 2. The resulting chart has two solved
forms. Thus the algorithm is still complete in this case. If, however, the fragments
1 and 2 are existential quantifiers and the fragment 3 is universal, there are three
equivalence classes, but the chart computed by the algorithm will have four solved
forms. The problem stems from the fact that neither of the existential quantifiers is
permutable as long as the universal quantifier is still in the same subgraph; but the
two configurations in which 2 dominates 3 are equivalent.
Runtime analysis. Given a graph G with n nodes and m edges, we can compute a
table which specifies for each pair u,v of root nodes whether there is a unique hole
of u from which v can be reached via a simple hypernormal path which doesn?t use
u, and which hole this is. A naive algorithm for doing this iterates over all u and v
and then performs a depth-first search through G, which takes time O(n2(n+m)),
which is a negligible runtime in practice.
Given this table, we can determine the possible dominators of each fragment
in time O(n) (because there are at most O(n) possible dominators). Thus it takes
time O(n) to decide whether a split is permutable, and time O(n ?S), where S is the
number of splits in the chart, to run the entire elimination algorithm. The reference
counting optimisation adds nothing to this asymptotic runtime, as each split may
trigger at most one reference count update for each hole of the split?s root fragment.
5 Conclusion
We have presented an algorithm for redundancy elimination on underspecified chart
representations. It checks for each subgraph in the chart whether it has a permutable
split; if yes, it removes all other splits for this subgraph. This reduces the set of
described readings, while making sure that at least one representative of each orig-
inal equivalence class remains while maintaining underspecification. Equivalence
is defined with respect to a certain class of rewriting systems which approximates
semantic equivalence of the described formulas and fits well with the underspecifi-
cation setting. The algorithm runs in polynomial time in the size of the chart.
The algorithm is useful in practice: it reduces the USRs for (1) and (2) from the
introduction to one and two solved forms, respectively. In fact, initial experiments
with the Rondane treebank suggest that it reduces the number of readings of a
typical sentence by an order of magnitude. It does this efficiently: Even on USRs
with billions of readings, for which the enumeration of readings would take about
a year, it finishes after a few seconds. However, the algorithm is not complete in
the sense that the computed chart has no more equivalent readings. We have some
ideas for achieving this kind of completeness, which we will explore in future work.
Another line in which the present work could be extended is to allow equivalence
with respect to arbitrary rewrite systems.
References
[1] Althaus, E., D. Duchier, A. Koller, K. Mehlhorn, J. Niehren and S. Thiel, An efficient graph
algorithm for dominance constraints, Journal of Algorithms 48 (2003), pp. 194?219.
[2] Blackburn, P. and J. Bos, ?Representation and Inference for Natural Language. A First Course
in Computational Semantics,? CSLI Publications, 2005.
[3] Bodirsky, M., D. Duchier, J. Niehren and S. Miele, An efficient algorithm for weakly normal
dominance constraints, in: ACM-SIAM Symposium on Discrete Algorithms (2004).
[4] Chaves, R. P., Non-redundant scope disambiguation in underspecified semantics, in:
Proceedings of the 8th ESSLLI Student Session, Vienna, 2003, pp. 47?58.
[5] Copestake, A. and D. Flickinger, An open-source grammar development environment and
broad-coverage english grammar using HPSG, in: Proc. of LREC, 2000.
[6] Copestake, A., D. Flickinger, C. Pollard and I. Sag, Minimal recursion semantics: An
introduction., Journal of Language and Computation (2004), to appear.
[7] Egg, M., A. Koller and J. Niehren, The Constraint Language for Lambda Structures, Logic,
Language, and Information 10 (2001), pp. 457?485.
[8] Fuchss, R., A. Koller, J. Niehren and S. Thater, Minimal recursion semantics as dominance
constraints: Translation, evaluation, and analysis, in: Proc. of ACL, Barcelona, 2004.
[9] Koller, A., J. Niehren and S. Thater, Bridging the gap between underspecification formalisms:
Hole semantics as dominance constraints, in: Proc. of EACL-03, 2003.
[10] Koller, A. and S. Thater, The evolution of dominance constraint solvers, in: Proc. of ACL-05
Workshop on Software, Ann Arbor, 2005.
[11] Niehren, J. and S. Thater, Bridging the gap between underspecification formalisms: Minimal
recursion semantics as dominance constraints, in: Proc. of ACL-03, 2003.
[12] van Deemter, K. and S. Peters, ?Semantic Ambiguity and Underspecification,? CSLI, 1996.
[13] Vestre, E., An algorithm for generating non-redundant quantifier scopings, in: Proc. of EACL,
Berlin, 1991, pp. 251?256.
Proceedings of the 12th European Workshop on Natural Language Generation, pages 165?173,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
Report on the First NLG Challenge on
Generating Instructions in Virtual Environments (GIVE)
Donna Byron
Northeastern University
dbyron@ccs.neu.edu
Alexander Koller
Saarland University
koller@mmci.uni-saarland.de
Kristina Striegnitz
Union College
striegnk@union.edu
Justine Cassell
Northwestern University
justine@northwestern.edu
Robert Dale
Macquarie University
Robert.Dale@mq.edu.au
Johanna Moore
University of Edinburgh
J.Moore@ed.ac.uk
Jon Oberlander
University of Edinburgh
J.Oberlander@ed.ac.uk
Abstract
We describe the first installment of the
Challenge on Generating Instructions in
Virtual Environments (GIVE), a new
shared task for the NLG community. We
motivate the design of the challenge, de-
scribe how we carried it out, and discuss
the results of the system evaluation.
1 Introduction
This paper reports on the methodology and results
of the First Challenge on Generating Instructions
in Virtual Environments (GIVE-1), which we ran
from March 2008 to February 2009. GIVE is a
new shared task for the NLG community. It pro-
vides an end-to-end evaluation methodology for
NLG systems that generate instructions which are
meant to help a user solve a treasure-hunt task in a
virtual 3D world. The most innovative aspect from
an NLG evaluation perspective is that the NLG
system and the user are connected over the Inter-
net. This makes it possible to cheaply collect large
amounts of evaluation data.
Five NLG systems were evaluated in GIVE-
1 over a period of three months from November
2008 to February 2009. During this time, we
collected 1143 games that were played by users
from 48 countries. As far as we know, this makes
GIVE-1 the largest evaluation effort in terms of
experimental subjects ever. We have evaluated the
five systems both on objective measures (success
rate, completion time, etc.) and subjective mea-
sures which were collected by asking the users to
fill in a questionnaire.
GIVE-1 was intended as a pilot experiment in
order to establish the validity of the evaluation
methodology and understand the challenges in-
volved in the instruction-giving task. We believe
that we have achieved these purposes. At the same
time, we provide evaluation results for the five
NLG systems which will help their developers im-
prove them for participation in a future challenge,
GIVE-2. GIVE-2 will retain the successful aspects
of GIVE-1, while refining the task to emphasize
aspects that we found to be challenging. We invite
the ENLG community to participate in designing
GIVE-2.
Plan of the paper. The paper is structured as
follows. In Section 2, we will describe and moti-
vate the GIVE Challenge. In Section 3, we will
then describe the evaluation method and infras-
tructure for the challenge. Section 4 reports on
the evaluation results. Finally, we conclude and
discuss future work in Section 5.
2 The GIVE Challenge
In the GIVE scenario, subjects try to solve a trea-
sure hunt in a virtual 3D world that they have not
seen before. The computer has a complete sym-
bolic representation of the virtual world. The chal-
lenge for the NLG system is to generate, in real
time, natural-language instructions that will guide
the users to the successful completion of their task.
Users participating in the GIVE evaluation
start the 3D game from our website at www.
give-challenge.org. They then see a 3D
game window as in Fig. 1, which displays instruc-
tions and allows them to move around in the world
and manipulate objects. The first room is a tuto-
rial room where users learn how to interact with
the system; they then enter one of three evaluation
worlds, where instructions for solving the treasure
hunt are generated by an NLG system. Users can
either finish a game successfully, lose it by trig-
gering an alarm, or cancel the game. This result is
stored in a database for later analysis, along with a
complete log of the game.
Complete maps of the game worlds used in the
evaluation are shown in Figs. 3?5: In these worlds,
players must pick up a trophy, which is in a wall
safe behind a picture. In order to access the tro-
165
Figure 1: What the user sees when playing with
the GIVE Challenge.
phy, they must first push a button to move the pic-
ture to the side, and then push another sequence of
buttons to open the safe. One floor tile is alarmed,
and players lose the game if they step on this tile
without deactivating the alarm first. There are also
a number of distractor buttons which either do
nothing when pressed or set off an alarm. These
distractor buttons are intended to make the game
harder and, more importantly, to require appropri-
ate reference to objects in the game world. Finally,
game worlds contained a number of objects such
as chairs and flowers that did not bear on the task,
but were available for use as landmarks in spatial
descriptions generated by the NLG systems.
2.1 Why a new NLG evaluation paradigm?
The GIVE Challenge addresses a need for a new
evaluation paradigm for natural language gener-
ation (NLG). NLG systems are notoriously hard
to evaluate. On the one hand, simply compar-
ing system outputs to a gold standard using auto-
matic comparison algorithms has limited value be-
cause there can be multiple generated outputs that
are equally good. Finding metrics that account
for this variability and produce results consistent
with human judgments and task performance mea-
sures is difficult (Belz and Gatt, 2008; Stent et
al., 2005; Foster, 2008). Human assessments of
system outputs are preferred, but lab-based eval-
uations that allow human subjects to assess each
aspect of the system?s functionality are expensive
and time-consuming, thereby favoring larger labs
with adequate resources to conduct human sub-
jects studies. Human assessment studies are also
difficult to replicate across sites, so system devel-
opers that are geographically separated find it dif-
ficult to compare different approaches to the same
problem, which in turn leads to an overall diffi-
culty in measuring progress in the field.
The GIVE-1 evaluation was conducted via a
client/server architecture which allows any user
with an Internet connection to provide system
evaluation data. Internet-based studies have been
shown to provide generous amounts of data in
other areas of AI (von Ahn and Dabbish, 2004;
Orkin and Roy, 2007). Our implementation allows
smaller teams to develop a system that will partici-
pate in the challenge, without taking on the burden
of running the human evaluation experiment, and
it provides a direct comparison of all participating
systems on the same evaluation data.
2.2 Why study instruction-giving?
Next to the Internet-based data collection method,
GIVE also differs from other NLG challenges by
its emphasis on generating instructions in a vir-
tual environment and in real time. This focus on
instruction giving is motivated by a growing in-
terest in dialogue-based agents for situated tasks
such as navigation and 3D animations. Due to its
appeal to younger students, the task can also be
used as a pedagogical exercise to stimulate interest
among secondary-school students in the research
challenges found in NLG or Computational Lin-
guistics more broadly.
Embedding the NLG task in a virtual world en-
courages the participating research teams to con-
sider communication in a situated setting. This
makes the NLG task quite different than in other
NLG challenges. For example, experiments have
shown that human instruction givers make the in-
struction follower move to a different location in
order to use a simpler referring expression (RE)
(Stoia et al, 2006). That is, RE generation be-
comes a very different problem than the classi-
cal non-situated Dale & Reiter style RE genera-
tion, which focuses on generating REs that are sin-
gle noun phrases in the context of an unchanging
world.
On the other hand, because the virtual environ-
ments scenario is so open-ended, it ? and specif-
ically the instruction-giving task ? can potentially
be of interest to a wide range of NLG researchers.
This is most obvious for research in sentence plan-
ning (GRE, aggregation, lexical choice) and real-
ization (the real-time nature of the task imposes
high demands on the system?s efficiency). But if
166
extended to two-way dialog, the task can also in-
volve issues of prosody generation (i.e., research
on text/concept-to-speech generation), discourse
generation, and human-robot interaction. Finally,
the game world can be scaled to focus on specific
issues in NLG, such as the generation of REs or
the generation of navigation instructions.
3 Evaluation Method and Logistics
Now we describe the method we applied to obtain
experimental data, and sketch the software infras-
tructure we developed for this purpose.
3.1 Software architecture
A crucial aspect of the GIVE evaluation methodol-
ogy is that it physically separates the user and the
NLG system and connects them over the Internet.
To achieve this, the GIVE software infrastructure
consists of three components (shown in Fig. 2):
1. the client, which displays the 3D world to
users and allows them to interact with it;
2. the NLG servers, which generate the natural-
language instructions; and
3. the Matchmaker, which establishes connec-
tions between clients and NLG servers.
These three components run on different ma-
chines. The client is downloaded by users from
our website and run on their local machine; each
NLG server is run on a server at the institution
that implemented it; and the Matchmaker runs on
a central server we provide. When a user starts the
client, it connects to the Matchmaker and is ran-
domly assigned an NLG server and a game world.
The client and NLG server then communicate over
the course of one game. At the end of the game,
the client displays a questionnaire to the user, and
the game log and questionnaire data are uploaded
to the Matchmaker and stored in a database. Note
that this division allows the challenge to be con-
ducted without making any assumptions about the
internal structure of an NLG system.
The GIVE software is implemented in Java and
available as an open-source Google Code project.
For more details about the software, see (Koller et
al., 2009).
3.2 Subjects
Participants were recruited using email distribu-
tion lists and press releases posted on the internet.
Game Client
Matchmaker
NLG Server
NLG Server
NLG Server
Figure 2: The GIVE architecture.
Collecting data from anonymous users over the
Internet presents a variety of issues that a lab-
based experiment does not. An Internet-based
evaluation skews the demographic of the subject
pool toward people who use the Internet, but prob-
ably no more so than if recruiting on a college
campus. More worrisome is that, without a face-
to-face meeting, the researcher has less confidence
in the veracity of self-reported demographic data
collected from the subject. For the purposes of
NLG software, the most important demographic
question is the subject?s fluency in English. Play-
ers of the GIVE 2009 challenge were asked to self-
report their command of English, age, and com-
puter experience. English proficiency did interact
with task completion, which leads us to conclude
that users were honest about their level of English
proficiency. See section 4.4 below for a discus-
sion of this interaction. All-in-all, we feel that the
advantage gained from the large increase in the
size of the subject pool offsets any disadvantage
accrued from the lack of accurate demographic in-
formation.
3.3 Materials
Figs. 3?5 show the layout of the three evaluation
worlds. The worlds were intended to provide vary-
ing levels of difficulty for the direction-giving sys-
tems and to focus on different aspects of the prob-
lem. World 1 is very similar to the development
world that the research teams were given to test
their system on. World 2 was intended to focus
on object descriptions - the world has only one
room which is full of objects and buttons, many of
which cannot be distinguished by simple descrip-
tions. World 3, on the other hand, puts more em-
phasis on navigation directions as the world has
many interconnected rooms and hallways.
The difference between the worlds clearly bears
out in the task completion rates reported below.
167
plant
chair
alarm
lamp
tutorial room
couch
safe
Figure 3: World 1
lamp
plant
chair
alarm
tutorial room
safe
Figure 4: World 2
plant
chair
lamp
safe
tutorial room
alarm
Figure 5: World 3
3.4 Timeline
After the GIVE Challenge was publicized in
March 2008, eight research teams signed up for
participation. We distributed an initial version of
the GIVE software and a development world to
these teams. In the end, four teams submitted
NLG systems. These were connected to a cen-
tral Matchmaker instance that ran for about three
months, from 7 November 2008 to 5 February
2009. During this time, we advertised participa-
tion in the GIVE Challenge to the public in order
to obtain experimental subjects.
3.5 NLG systems
Five NLG systems were evaluated in GIVE-1:
1. one system from the University of Texas at
Austin (?Austin? in the graphics below);
2. one system from Union College in Schenec-
tady, NY (?Union?);
3. one system from the Universidad Com-
plutense de Madrid (?Madrid?);
4. two systems from the University of Twente:
one serious contribution (?Twente?) and one
more playful one (?Warm-Cold?).
Of these systems, ?Austin? can serve as a base-
line: It computes a plan consisting of the actions
the user should take to achieve the goal, and at
each point in the game, it realizes the first step
in this plan as a single instruction. The ?Warm-
Cold? system generates very vague instructions
that only tell the user if they are getting closer
(?warmer?) to their next objective or if they are
moving away from it (?colder?). We included this
system in the evaluation to verify whether the eval-
uation methodology would be able to distinguish
such an obviously suboptimal instruction-giving
strategy from the others.
Detailed descriptions of these systems
as well as each team?s own analysis of
the evaluation results can be found at
http://www.give-challenge.org/
research/give-1.
4 Results
We now report on the results of GIVE-1. We start
with some basic demographics; then we discuss
objective and subjective evaluation measures.
Notice that some of our evaluation measures are
in tension with each other: For instance, a system
which gives very low-level instructions (?move
forward?; ?ok, now move forward?; ?ok, now turn
left?), such as the ?Austin? baseline, will lead the
user to completing the task in a minimum number
of steps; but it will require more instructions than
a system that aggregates these. This is intentional,
and emphasizes both the pilot experiment char-
acter of GIVE-1 and our desire to make GIVE a
friendly comparative challenge rather than a com-
petition with a clear winner.
4.1 Demographics
Over the course of three months, we collected
1143 valid games. A game counted as valid if the
game client didn?t crash, the game wasn?t marked
as a test game by the developers, and the player
completed the tutorial.
Of these games, 80.1% were played by males
and 9.9% by females; a further 10% didn?t specify
their gender. The players were widely distributed
over countries: 37% connected from an IP address
in the US, 33% from an IP address in Germany,
and 17% from China; Canada, the UK, and Aus-
tria also accounted for more than 2% of the partic-
168
037,5
75,0
112,5
150,0
N
o
v
 
7
D
e
c
 
1
J
a
n
 
1
F
e
b
 
1
F
e
b
 
5
# games per day
German
press release
US
press release
posted to
SIGGEN list
covered by
Chinese blog
Figure 6: Histogram of the connections per day.
ipants each, and the remaining 2% of participants
connected from 42 further countries. This imbal-
ance stems from very successful press releases that
were issued in Germany and the US and which
were further picked up by blogs, including one
in China. Nevertheless, over 90% of the partici-
pants who answered this question self-rated their
English proficiency as ?good? or better. About
75% of users connected with a client running on
Windows, with the rest split about evenly among
Linux and Mac OS X.
The effect of the press releases is also plainly
visible if we look at the distribution of the valid
games over the days from November 7 to Febru-
ary 5 (Fig. 6). There are huge peaks at the
very beginning of the evaluation period, coincid-
ing with press releases through Saarland Univer-
sity in Germany and Northwestern University in
the US, which were picked up by science and tech-
nology blogs on the Web. The US peak contains
a smaller peak of connections from China, which
were sparked by coverage in a Chinese blog.
4.2 Objective measures
We then extracted objective and subjective mea-
surements from the valid games. The objective
measures are summarized in Fig. 7. For each sys-
tem and game world, we measured the percent-
age of games which the users completed success-
fully. Furthermore, we counted the numbers of in-
structions the system sent to the user, measured
the time until task completion, and counted the
number of low-level steps executed by the user
(any key press, to either move or manipulate an
object) as well as the number of task-relevant ac-
tions (such as pushing a button to open a door).
? task success (Did the player get the trophy?)
? instructions (Number of instructions pro-
duced by the NLG system.?)
? steps (Number of all player actions.?)
? actions (Number of object manipulation
action.?)
? second (Time in seconds.?)
?
Measured from the end of the tutorial until the
end of the game.
Figure 7: Objective measurements
A
us
ti
n
M
ad
ri
d
Tw
en
te
U
ni
on
W
ar
m
-C
ol
d
task
success
40% 71% 35% 73% 18%
A A
B B
C
instructions
83.2 58.3 121.2 80.3 190.0
A
B B
C
D
steps
103.6 124.3 160.9 117.5 307.4
A A
B B
C
D
actions
11.2 8.7 14.3 9.0 14.3
A A
B
C C
seconds
129.3 174.8 207.0 175.2 312.2
A
B B
C
D
Figure 8: Objective measures by system. Task
success is reported as the percentage of suc-
cessfully completed games. The other measures
are reported as the mean number of instruc-
tions/steps/actions/seconds, respectively. Letters
group indistinguishable systems; systems that
don?t share a letter were found to be significantly
different with p < 0.05.
169
To ensure comparability, we only counted success-
fully completed games for all these measures, and
only started counting when the user left the tutorial
room. Crucially, all objective measures were col-
lected completely unobtrusively, without requiring
any action on the user?s part.
Fig. 8 shows the results of these objective mea-
sures. This figure assigns systems to groups A,
B, etc. for each evaluation measure. Systems in
group A are better than systems in group B, etc.;
if two systems don?t share the same letter, the dif-
ference between these two systems is significant
with p < 0.05. Significance was tested using a
?2-test for task success and ANOVAs for instruc-
tions, steps, actions, and seconds. These were fol-
lowed by post-hoc tests (pairwise ?2 and Tukey)
to compare the NLG systems pairwise.
Overall, there is a top group consisting of
the Austin, Madrid, and Union systems: While
Madrid and Union outperform Austin on task suc-
cess (with 70 to 80% of successfully completed
games, depending on the world), Austin signifi-
cantly outperforms all other systems in terms of
task completion time. As expected, the Warm-
Cold system performs significantly worse than all
others in almost all categories. This confirms the
ability of the GIVE evaluation method to distin-
guish between systems of very different qualities.
4.3 Subjective measures
The subjective measures, which were obtained by
asking the users to fill in a questionnaire after each
game, are shown in Fig. 9. Most of the questions
were answered on 5-point Likert scales (?overall?
on a 7-point scale); the ?informativity? and ?tim-
ing? questions had nominal answers. For each
question, the user could choose not to answer.
The results of the subjective measurements are
summarized in Fig. 10, in the same format as
above. We ran ?2-tests for the nominal variables
informativity and timing, and ANOVAs for the
scale data. Again, we used post-hoc pairwise ?2-
and Tukey-tests to compare the NLG systems to
each other one by one.
Here there are fewer significant differences be-
tween different groups than for the objective mea-
sures: For the ?play again? category, there is
no significant difference at all. Nevertheless,
?Austin? is shown to be particularly good at navi-
gation instructions and timing, whereas ?Madrid?
outperforms the rest of the field in ?informativ-
7-point scale items:
overall: What is your overall evaluation of the quality of the
direction-giving system? (very bad 1 . . . 7 very good)
5-point scale items:
task difficulty: How easy or difficult was the task for you to
solve? (very difficult 1 2 3 4 5 very easy)
goal clarity: How easy was it to understand what you were
supposed to do? (very difficult 1 2 3 4 5 very easy)
play again: Would you want to play this game again? (no
way! 1 2 3 4 5 yes please!)
instruction clarity: How clear were the directions? (totally
unclear 1 2 3 4 5 very clear)
instruction helpfulness: How effective were the directions at
helping you complete the task? (not effective 1 2 3 4 5
very effective)
choice of words: How easy to understand was the system?s
choice of wording in its directions to you? (totally un-
clear 1 2 3 4 5 very clear)
referring expressions: How easy was it to pick out which ob-
ject in the world the system was referring to? (very hard
1 2 3 4 5 very easy)
navigation instructions: How easy was it to navigate to a par-
ticular spot, based on the system?s directions? (very
hard 1 2 3 4 5 very easy)
friendliness: How would you rate the friendliness of the sys-
tem? (very unfriendly 1 2 3 4 5 very friendly)
Nominal items:
informativity: Did you feel the amount of information you
were given was: too little / just right / too much
timing: Did the directions come ... too early / just at the right
time / too late
Figure 9: Questionnaire items
ity?. In the overall subjective evaluation, the ear-
lier top group of Austin, Madrid, and Union is
confirmed, although the difference between Union
and Twente is not significant. However, ?Warm-
Cold? again performs significantly worse than all
other systems in most measures. Furthermore, al-
though most systems perform similarly on ?infor-
mativity? and ?timing? in terms of the number of
users who judged them as ?just right?, there are
differences in the tendencies: Twente and Union
tend to be overinformative, whereas Austin and
Warm-Cold tend to be underinformative; Twente
and Union tend to give their instructions too late,
whereas Madrid and Warm-Cold tend to give them
too early.
170
A
us
ti
n
M
ad
ri
d
Tw
en
te
U
ni
on
W
ar
m
-C
ol
d
task
difficulty
4.3 4.3 4.0 4.3 3.5
A A A A
B
goal clarity
4.0 3.7 3.9 3.7 3.3
A A A A
B
play again
2.8 2.6 2.4 2.9 2.5
A A A A A
instruction
clarity
4.0 3.6 3.8 3.6 3.0
A A A
B B B
C
instruction
helpfulness
3.8 3.9 3.6 3.7 2.9
A A A A
B
informativity
46% 68% 51% 56% 51%
A
B B B B
overall
4.9 4.9 4.3 4.6 3.6
A A A
B B
C
choice of
words
4.2 3.8 4.1 3.7 3.5
A A
B B
C C C
referring
expressions
3.4 3.9 3.7 3.7 3.5
A A A
B B B B
navigation
instructions
4.6 4.0 4.0 3.7 3.2
A
B B B
C
timing
78% 62% 60% 62% 49%
A
B B B
C C
friendliness
3.4 3.8 3.1 3.6 3.1
A A A
B B B
Figure 10: Subjective measures by system. Infor-
mativity and timing are reported as the percentage
of successfully completed games. The other mea-
sures are reported as the mean rating received by
the players. Letters group indistinguishable sys-
tems; systems that don?t share a letter were found
to be significantly different with p < 0.05.
4.4 Further analysis
In addition to the differences between NLG sys-
tems, there may be other factors which also influ-
ence the outcome of our objective and subjective
measures. We tested the following five factors:
evaluation world, gender, age, computer expertise,
and English proficiency (as reported by the users
on the questionnaire). We found that there is a sig-
nificant difference in task success rate for different
evaluation worlds and between users with different
levels of English proficiency.
The interaction graphs in Figs. 11 and 12 also
suggest that the NLG systems differ in their ro-
bustness with respect to these factors. ?2-tests
that compare the success rate of each system in
the three evaluation worlds show that while the
instructions of Union and Madrid seem to work
equally well in all three worlds, the performance
of the other three systems differs dramatically be-
tween the different worlds. Especially World 2
was challenging for some systems as it required
relational object descriptions, such as the blue but-
ton on the left of another blue button.
The players? English skills also affected the sys-
tems in different ways. While Austin, Madrid and
Warm Cold don?t manage to lead players with only
basic English skills to success as often as other
players, Union?s and Twente?s success rates do not
depend on the players? English skills (?2-tests do
not find significant differences in success rate be-
tween players with different levels of English pro-
ficiency for these two systems). However, if we
remove the players with the lowest level of En-
glish proficiency, language skills do not have an
effect on the task success rate anymore for any of
the systems.
5 Conclusion
In this document, we have described the first in-
stallment of the GIVE Challenge, our experimen-
tal methodology, and the results. Altogether, we
collected 1143 valid games for five NLG systems
over a period of three months. Given that this was
the first time we organized the challenge, that it
was meant as a pilot experiment from the begin-
ning, and that the number of games was sufficient
to get significant differences between systems on
a number of measures, we feel that GIVE-1 was a
success. We are in the process of preparing sev-
eral diagnostic utilities, such as heat maps and a
tool that lets the system developer replay an indi-
171
Figure 11: Effect of the evaluation worlds on the
success rate of the NLG systems.
vidual game, which will help the participants gain
further insight into their NLG systems.
Nevertheless, there are a number of improve-
ments we will make to GIVE for future install-
ments. For one thing, the timing of the challenge
was not optimal: A number of colleagues would
have been interested in participating, but the call
for participation came too late for them to acquire
funding or interest students in time for summer
projects or MSc theses. Secondly, although the
software performed very well in handling thou-
sands of user connections, there were still game-
invalidating issues with the 3D graphics and the
networking code that were individually rare, but
probably cost us several hundred games. These
should be fixed for GIVE-2. At the same time,
we are investigating ways in which the networking
and matchmaking core of GIVE can be factored
out into a separate, challenge-independent system
on which other Internet-based challenges can be
built. Among other things, it would be straightfor-
ward to use the GIVE platform to connect two hu-
man users and observe their dialogue while solv-
ing a problem. Judicious variation of parameters
(such as the familiarity of users or the visibility of
an instruction giving avatar) would allow the con-
struction of new dialogue corpora along such lines.
Finally, GIVE-1 focused on the generation of
navigation instructions and referring expressions,
in a relatively simple world, without giving the
Figure 12: Effect of the players? English skills on
the success rate of the NLG systems.
user a chance to talk back. The high success rate
of some systems in this challenge suggests that
we need to widen the focus for a future GIVE-
2 ? by allowing dialogue, by making the world
more complex (e.g., allowing continuous rather
than discrete movements and turns), by making the
communication multi-modal, etc. Such extensions
would require only rather limited changes to the
GIVE software infrastructure. We plan to come to
a decision about such future directions for GIVE
soon, and are looking forward to many fruitful dis-
cussions about this at ENLG.
Acknowledgments. We are grateful to the par-
ticipants of the 2007 NSF/SIGGEN Workshop on
Shared Tasks and Evaluation in NLG and many
other colleagues for fruitful discussions while we
were designing the GIVE Challenge, and to the
organizers of Generation Challenges 2009 and
ENLG 2009 for their support and the opportunity
to present the results at ENLG. We also thank the
four participating research teams for their contri-
butions and their patience while we were working
out bugs in the GIVE software. The creation of
the GIVE infrastructure was supported in part by
a Small Projects grant from the University of Ed-
inburgh.
172
References
A. Belz and A. Gatt. 2008. Intrinsic vs. extrinsic eval-
uation measures for referring expression generation.
In Proceedings of ACL-08:HLT, Short Papers, pages
197?200, Columbus, Ohio.
M. E. Foster. 2008. Automated metrics that agree
with human judgements on generated output for an
embodied conversational agent. In Proceedings of
INLG 2008, pages 95?103, Salt Fork, OH.
A. Koller, D. Byron, J. Cassell, R. Dale, J. Moore,
J. Oberlander, and K. Striegnitz. 2009. The soft-
ware architecture for the first challenge on generat-
ing instructions in virtual environments. In Proceed-
ings of the EACL-09 Demo Session.
J. Orkin and D. Roy. 2007. The restaurant game:
Learning social behavior and language from thou-
sands of players online. Journal of Game Develop-
ment, 3(1):39?60.
A. Stent, M. Marge, and M. Singhai. 2005. Evaluating
evaluation methods for generation in the presence of
variation. In Proceedings of CICLing 2005.
L. Stoia, D. M. Shockley, D. K. Byron, and E. Fosler-
Lussier. 2006. Noun phrase generation for situated
dialogs. In Proceedings of INLG, Sydney.
L. von Ahn and L. Dabbish. 2004. Labeling images
with a computer game. In Proceedings of the ACM
CHI Conference.
173
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 336?343,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Sentence generation as a planning problem
Alexander Koller
Center for Computational Learning Systems
Columbia University
koller@cs.columbia.edu
Matthew Stone
Computer Science
Rutgers University
Matthew.Stone@rutgers.edu
Abstract
We translate sentence generation from TAG
grammars with semantic and pragmatic in-
formation into a planning problem by encod-
ing the contribution of each word declara-
tively and explicitly. This allows us to ex-
ploit the performance of off-the-shelf plan-
ners. It also opens up new perspectives on
referring expression generation and the rela-
tionship between language and action.
1 Introduction
Systems that produce natural language must synthe-
size the primitives of linguistic structure into well-
formed utterances that make desired contributions to
discourse. This is fundamentally a planning prob-
lem: Each linguistic primitive makes certain con-
tributions while potentially introducing new goals.
In this paper, we make this perspective explicit by
translating the sentence generation problem of TAG
grammars with semantic and pragmatic information
into a planning problem stated in the widely used
Planning Domain Definition Language (PDDL, Mc-
Dermott (2000)). The encoding provides a clean
separation between computation and linguistic mod-
elling and is open to future extensions. It also allows
us to benefit from the past and ongoing advances in
the performance of off-the-shelf planners (Blum and
Furst, 1997; Kautz and Selman, 1998; Hoffmann
and Nebel, 2001).
While there have been previous systems that en-
code generation as planning (Cohen and Perrault,
1979; Appelt, 1985; Heeman and Hirst, 1995), our
approach is distinguished from these systems by its
focus on the grammatically specified contributions
of each individual word (and the TAG tree it an-
chors) to syntax, semantics, and local pragmatics
(Hobbs et al, 1993). For example, words directly
achieve content goals by adding a corresponding se-
mantic primitive to the conversational record. We
deliberately avoid reasoning about utterances as co-
ordinated rational behavior, as earlier systems did;
this allows us to get by with a much simpler logic.
The problem we solve encompasses the genera-
tion of referring expressions (REs) as a special case.
Unlike some approaches (Dale and Reiter, 1995;
Heeman and Hirst, 1995), we do not have to dis-
tinguish between generating NPs and expressions of
other syntactic categories. We develop a new per-
spective on the lifecycle of a distractor, which allows
us to generate more succinct REs by taking the rest
of the utterance into account. More generally, we do
not split the process of sentence generation into two
separate steps of sentence planning and realization,
as most other systems do, but solve the joint prob-
lem in a single integrated step. This can potentially
allow us to generate higher-quality sentences. We
share these advantages with systems such as SPUD
(Stone et al, 2003).
Crucially, however, our approach describes the
dynamics of interpretation explicitly and declara-
tively. We do not need to assume extra machin-
ery beyond the encoding of words as PDDL plan-
ning operators; for example, our planning opera-
tors give a self-contained description of how each
individual word contributes to resolving references.
This makes our encoding more direct and transpar-
ent than those in work like Thomason and Hobbs
(1997) and Stone et al (2003).
We present our encoding in a sequence of steps,
each of which adds more linguistic information to
336
the planning operators. After a brief review of LTAG
and PDDL, we first focus on syntax alone and show
how to cast the problem of generating grammatically
well-formed LTAG trees as a planning problem in
Section 2. In Section 3, we add semantics to the ele-
mentary trees and add goals to communicate specific
content (this corresponds to surface realization). We
complete the account by modeling referring expres-
sions and go through an example. Finally, we assess
the practical efficiency of our approach and discuss
future work in Section 4.
2 Grammaticality as planning
We start by reviewing the LTAG grammar formal-
ism and giving an intuition of how LTAG gen-
eration is planning. We then add semantic roles
to the LTAG elementary trees in order to distin-
guish different substitution nodes. Finally, we re-
view the PDDL planning specification language and
show how LTAG grammaticality can be encoded as
a PDDL problem and how we can reconstruct an
LTAG derivation from the plan.
2.1 Tree-adjoining grammars
The grammar formalism we use here is that of lex-
icalized tree-adjoining grammars (LTAG; Joshi and
Schabes (1997)). An LTAG grammar consists of a
finite set of lexicalized elementary trees as shown in
Fig. 1a. Each elementary tree contains exactly one
anchor node, which is labelled by a word. Elemen-
tary trees can contain substitution nodes, which are
marked by down arrows (?). Those elementary trees
that are auxiliary trees also contain exactly one foot
node, which is marked with an asterisk (?). Trees
that are not auxiliary trees are called initial trees.
Elementary trees can be combined by substitution
and adjunction to form larger trees. Substitution
is the operation of replacing a substitution node of
some tree by another initial tree with the same root
label. Adjunction is the operation of splicing an aux-
iliary tree into some node v of a tree, in such a way
that the root of the auxiliary tree becomes the child
of v?s parent, and the foot node becomes the parent
of v?s children. If a node carries a null adjunction
constraint (indicated by no-adjoin), no adjunction is
allowed at this node; if it carries an obligatory ad-
junction constraint (indicated by adjoin!), an auxil-
S
NP ? 
VP
V
likes
NP
the
NP * 
PN
Mary
N
white N * 
Mary
likes 
rabbit
white
(a)
(b)
(c)
NP ? 
N
rabbit
NP
adjoin!
NP
S
NP VP
V
likes
NP 
PN
Mary
NP
the
N
white N
rabbit
the
no-adjoin
Figure 1: Building a derived (b) and a derivation tree
(c) by combining elementary trees (a).
iary tree must be adjoined there.
In Fig. 1a, we have combined some ele-
mentary trees by substitution (indicated by the
dashed/magenta arrows) and adjunction (dotted/blue
arrows). The result of these operations is the derived
tree in Fig. 1b. The derivation tree in Fig. 1c rep-
resents the tree combination operations we used by
having one node per elementary tree and drawing a
solid edge if we combined the two trees by substitu-
tion, and a dashed edge for adjunctions.
2.2 The basic idea
Consider the process of constructing a derivation
tree top-down. To build the tree in Fig. 1c, say, we
start with the empty derivation tree and an obligation
to generate an expression of category S. We satisfy
this obligation by adding the tree for ?likes? as the
root of the derivation; but in doing so, we have in-
troduced new unfilled substitution nodes of category
NP, i.e. the derivation tree is not complete. We use
the NP tree for ?Mary? to fill one substitution node
and the NP tree for ?rabbit? to fill the other. This
fills both substitution nodes, but the ?rabbit? tree in-
troduces an obligatory adjunction constraint, which
we must satisfy by adjoining the auxiliary tree for
?the?. We now have a grammatical derivation tree,
but we are free to continue by adding more auxiliary
trees, such as the one for ?white?.
As we have just presented it, the generation of
derivation trees is essentially a planning problem.
A planning problem involves states and actions that
can move from one state to another. The task is to
find a sequence of actions that moves us from the
337
initial state to a state that satisfies all the goals. In
our case, the states are defined by the unfilled sub-
stitution nodes, the unsatisfied obligatory adjunction
constraints, and the nodes that are available for ad-
junction in some (possibly incomplete) derivation
tree. Each action adds a single elementary tree to the
derivation, removing some of these ?open nodes?
while introducing new ones. The initial state is asso-
ciated with the empty derivation tree and a require-
ment to generate an expression for the given root cat-
egory. The goal is for the current derivation tree to
be grammatically complete.
2.3 Semantic roles
Formalizing this intuition requires unique names for
each node in the derived tree. Such names are nec-
essary to distinguish the different open substitution
nodes that still need to be filled, or the different
available adjunction sites; in the example, the plan-
ner needed to be aware that ?likes? introduces two
separate NP substitution nodes to fill.
There are many ways to assign these names. One
that works particularly well in the context of PDDL
(as we will see below) is to assume that each node
in an elementary tree, except for ones with null ad-
junction constraints, is marked with a semantic role,
and that all substitution nodes are marked with dif-
ferent roles. Nothing hinges on the particular role in-
ventory; here we assume an inventory including the
roles ag for ?agent? and pat for ?patient?. We also
assume one special role self, which must be used for
the root of each elementary tree and must never be
used for substitution nodes.
We can now assign a unique name to every sub-
stitution node in a derived tree by assigning arbitrary
but distinct indices to each use of an elementary tree,
and giving the substitution node with role r in the el-
ementary tree with index i the identity i.r. In the ex-
ample, let?s say the ?likes? tree has index 1 and the
semantic roles for the substitution nodes were ag and
pat, respectively. The planner action that adds this
tree would then require substitution of one NP with
identity 1.ag and another NP with identity 1.pat; the
?Mary? tree would satisfy the first requirement and
the ?rabbit? tree the second. If we assume that no
elementary tree contains two internal nodes with the
same category and role, we can refer to adjunction
opportunities in a similar way.
Action S-likes-1(u). Precond: subst(S,u),step(1)
Effect: ?subst(S,u),subst(NP,1.ag),
subst(NP,1.pat),?step(1),step(2)
Action NP-Mary-2(u). Precond: subst(NP,u),step(2)
Effect: ?subst(NP,u),?step(2),step(3)
Action NP-rabbit-3(u). Precond: subst(NP,u),step(3)
Effect: ?subst(NP,u),canadjoin(NP,u),
mustadjoin(NP,u),?step(3),step(4)
Action NP-the-4(u). Precond: canadjoin(NP,u),step(4)
Effect: ?mustadjoin(NP,u),?step(4),step(5)
Figure 2: Some actions for the grammar in Fig. 1.
2.4 Encoding in PDDL
Now we are ready to encode the problem of generat-
ing grammatical LTAG derivation trees into PDDL.
PDDL (McDermott, 2000) is the standard input lan-
guage for modern planning systems. It is based on
the well-known STRIPS language (Fikes and Nils-
son, 1971). In this paradigm, a planning state is
defined as a finite set of ground atoms of predicate
logic that are true in this state; all other atoms are as-
sumed to be false. Actions have a number of param-
eters, as well as a precondition and effect, both of
which are logical formulas. When a planner tries to
apply an action, it will first create an action instance
by binding all parameters to constants from the do-
main. It must then verify that the precondition of the
action instance is satisfied in the current state. If so,
the action can be applied, in which case the effect is
processed in order to change the state. In STRIPS,
the precondition and effect both had to be conjunc-
tions of atoms or negated atoms; positive effects are
interpreted as making the atom true in the new state,
and negative ones as making it false. PDDL per-
mits numerous extensions to the formulas that can
be used as preconditions and effects.
Each action in our planning problem encodes the
effect of adding some elementary tree to the deriva-
tion tree. An initial tree with root category A trans-
lates to an action with a parameter u for the iden-
tity of the node that the current tree is substituted
into. The action carries the precondition subst(A,u),
and so can only be applied if u is an open substi-
tution node in the current derivation with the cor-
rect category A. Auxiliary trees are analogous, but
carry the precondition canadjoin(A,u). The effect
of an initial tree is to remove the subst condition
from the planning state (to record that the substitu-
338
S-likes-1
 (1.self)
subst(S,1.self)
subst(NP,1.ag)
NP-Mary-2
   (1.ag)
subst(NP,1.pat)
NP-rabbit-3
  (1.pat)
mustadjoin(NP,1.pat)
NP-the-4
(1.pat)
canadjoin(NP,1.pat)
subst(NP,1.pat)
canadjoin(NP,1.pat)
step(1)
step(2)
step(3)
step(4)
step(5)
Figure 3: A plan for the actions in Fig. 2.
tion node u is now filled); an auxiliary tree has an
effect ?mustadjoin(A,u) to indicate that any oblig-
atory adjunction constraint is satisfied but leaves the
canadjoin condition in place to allow multiple ad-
junctions into the same node. In both cases, effects
add subst, canadjoin and mustadjoin atoms repre-
senting the substitution nodes and adjunction sites
that are introduced by the new elementary tree.
One remaining complication is that an action must
assign new identities to the nodes it introduces; thus
it must have access to a tree index that was not used
in the derivation tree so far. We use the number of
the current plan step as the index. We add an atom
step(1) to the initial state of the planning problem,
and we introduce k different copies of the actions for
each elementary tree, where k is some upper limit
on the plan size. These actions are identical, except
that the i-th copy has an extra precondition step(i)
and effects ?step(i) and step(i+1). It is no restric-
tion to assume an upper limit on the plan size, as
most modern planners search for plans smaller than
a given maximum length anyway.
Fig. 2 shows some of the actions into which the
grammar in Fig. 1 translates. We display only one
copy of each action and have left out most of the
canadjoin effects. In addition, we use an initial state
containing the atoms subst(S,1.self) and step(1)
and a final state consisting of the following goal:
?A,u.?subst(A,u)??A,u.?mustadjoin(A,u).
We can then send the actions and the initial state
and goal specifications to any off-the-shelf planner
and obtain the plan in Fig. 3. The straight arrows in
the picture link the actions to their preconditions and
(positive) effects; the curved arrows indicate atoms
that carry over from one state to the next without
being changed by the action. Atoms are printed in
boldface iff they contradict the goal.
This plan can be read as a derivation tree that has
one node for each action instance in the plan, and an
edge from node u to node v if u establishes a subst
or canadjoin fact that is a precondition of v. These
causal links are drawn as bold edges in Fig. 3. The
mapping is unique for substitution edges because
subst atoms are removed by every action that has
them as their precondition. There may be multiple
action instances in the plan that introduce the same
atom canadjoin(A,u). In this case, we can freely
choose one of these instances as the parent.
3 Sentence generation as planning
Now we extend this encoding to deal with semantics
and referring expressions.
3.1 Communicative goals
In order to use the planner as a surface realiza-
tion algorithm for TAG along the lines of Koller
and Striegnitz (2002), we attach semantic content to
each elementary tree and require that the sentence
achieves a certain communicative goal. We also use
a knowledge base that specifies the speaker?s knowl-
edge, and require that we can only use trees that ex-
press information in this knowledge base.
We follow Stone et al (2003) in formalizing the
semantic content of a lexicalized elementary tree t as
a finite set of atoms; but unlike in earlier approaches,
we use the semantic roles in t as the arguments of
these atoms. For instance, the semantic content of
the ?likes? tree in Fig. 1 is {like(self,ag,pat)} (see
also the semcon entries in Fig. 4). The knowledge
base is some finite set of ground atoms; in the exam-
ple, it could contain such entries as like(e,m,r) and
rabbit(r). Finally, the communicative goal is some
subset of the knowledge base, such as {like(e,m,r)}.
We implement unsatisfied communicative goals
as flaws that the plan must remedy. To this end,
we add an atom cg(P,a1, . . . ,an) for each element
P(a1, . . . ,an) of the communicative goal to the ini-
tial state, and we add a corresponding conjunct
?P,x1, . . . ,xn.?cg(P,x1, . . . ,xn) to the goal. In ad-
dition, we add an atom skb(P,a1, . . . ,an) to the
initial state for each element P(a1, . . . ,an) of the
(speaker?s) knowledge base.
339
We then add parameters x1, . . . ,xn to each action
with n semantic roles (including self). These new
parameters are intended to be bound to individual
constants in the knowledge base by the planner. For
each elementary tree t and possible step index i, we
establish the relationship between these parameters
and the roles in two steps. First we fix a function id
that maps the semantic roles of t to node identities.
It maps self to u and each other role r to i.r. Second,
we fix a function ref that maps the outputs of id bi-
jectively to the parameters x1, . . . ,xn, in such a way
that ref(u) = x1.
We can then capture the contribution of the i-th
action for t to the communicative goal by giving it
an effect ?cg(P, ref(id(r1)), . . . , ref(id(rn))) for each
element P(r1, . . . ,rn) of the elementary tree?s seman-
tic content. We restrict ourselves to only expressing
true statements by giving the action a precondition
skb(P, ref(id(r1)), . . . , ref(id(rn))) for each element
of the semantic content.
In order to keep track of the connection between
node identities and individuals for future reference,
each action gets an effect referent(id(r), ref(id(r)))
for each semantic role r except self. We enforce the
connection between u and x1 by adding a precondi-
tion referent(u,x1).
In the example, the most interesting action in this
respect is the one for the elementary tree for ?likes?.
This action looks as follows:
Action S-likes-1(u,x1,x2,x3).
Precond: subst(S,u),step(1), referent(u,x1),
skb(like,x1,x2,x3)
Effect: ?subst(S,u),subst(NP,1.ag),subst(NP,1.pat),
?step(1),step(2),
referent(1.ag,x2), referent(1.pat,x3),
?cg(like,x1,x2,x3)
We can run a planner and interpret the plan as
above; the main difference is that complete plans not
only correspond to grammatical derivation trees, but
also express all communicative goals. Notice that
this encoding models some aspects of lexical choice:
The semantic content sets of the elementary trees
need not be singletons, and so there may be multiple
ways of partitioning the communicative goal into the
content sets of various elementary trees.
3.2 Referring expressions
Finally, we extend the system to deal with the gen-
eration of referring expressions. While this prob-
lem is typically taken to require the generation of a
noun phrase that refers uniquely to some individual,
we don?t need to make any assumptions about the
syntactic category here. Moreover, we consider the
problem in the wider context of generating referring
expressions within a sentence, which can allow us to
generate more succinct expressions.
Because a referring expression must allow the
hearer to identify the intended referent uniquely,
we keep track of the hearer?s knowledge base sep-
arately. We use atoms hkb(P,a1, . . . ,an), as with
skb above. In addition, we assume pragmatic
information of the form pkb(P,a1, . . . ,an). The
three pragmatic predicates that we will use here are
hearer-new, indicating that the hearer does not know
about the existence of an individual and can?t infer it
(Stone et al, 2003), hearer-old for the opposite, and
contextset. The context set of an intended referent is
the set of all individuals that the hearer might possi-
bly confuse it with (DeVault et al, 2004). It is empty
for hearer-new individuals. To say that b is in a?s
context set, we put the atom pkb(contextset,a,b)
into the initial state.
In addition to the semantic content, we equip ev-
ery elementary tree in the grammar with a seman-
tic requirement and a pragmatic condition (Stone
et al, 2003). The semantic requirement is a set of
atoms spelling out presuppositions of an elementary
tree that can help the hearer identify what its argu-
ments refer to. For instance, ?likes? has the selec-
tional restriction that its agent must be animate; thus
the hearer will not consider inanimate individuals as
distractors for the referring expression in agent posi-
tion. The pragmatic condition is a set of atoms over
the predicates in the pragmatic knowledge base.
In our setting, every substitution node that is in-
troduced during the derivation introduces a new re-
ferring expression. This means that we can dis-
tinguish the referring expressions by the identity
of the substitution node that introduced them. For
each referring expression u (where u is a node iden-
tity), we keep track of the distractors in atoms
of the form distractor(u,x). The presence of an
atom distractor(u,a) in some planning state repre-
sents the fact that the current derivation tree is not
yet informative enough to allow the hearer to iden-
tify the intended referent for u uniquely; a is an-
other individual that is not the intended referent,
340
but consistent with the partial referring expression
we have constructed so far. We enforce uniqueness
of all referring expressions by adding the conjunct
?u,x?distractor(u,x) to the planning goal.
Now whenever an action introduces a new substi-
tution node u, it will also introduce some distractor
atoms to record the initial distractors for the refer-
ring expression at u. An individual a is in the initial
distractor set for the substitution node with role r
if (a) it is not the intended referent, (b) it is in the
context set of the intended referent, and (c) there
is a choice of individuals for the other parameters
of the action that satisfies the semantic requirement
together with a. This is expressed by adding the
following effect for each substitution node; the con-
junction is over the elements P(r1, . . . ,rn) of the se-
mantic requirement, and there is one universal quan-
tifier for y and for each parameter x j of the action
except for ref(id(r)).
?y,x1, . . . ,xn
(y 6= ref(id(r))?pkb(contextset, ref(id(r)),y)?
V
hkb(P, ref(id(r1)), . . . , ref(id(rn)))[y/ref(id(r))])
? distractor(id(r),y)
On the other hand, a distractor a for a referring ex-
pression introduced at u is removed when we substi-
tute or adjoin an elementary tree into u which rules
a out. For instance, the elementary tree for ?rabbit?
will remove all non-rabbits from the distractor set of
the substitution node into which it is substituted. We
achieve this by adding the following effect to each
action; here the conjunction is over all elements of
the semantic content.
?y.(?
V
hkb(P, ref(id(r1)), . . . , ref(id(rn))))[y/x1]
??distractor(u,y),
Finally, each action gets its pragmatic condition
as a precondition.
3.3 The example
By way of example, Fig. 5 shows the full versions
of the actions from Fig. 2, for the extended gram-
mar in Fig. 4. Let?s say that the hearer knows
about two rabbits r (which is white) and r? (which
is not), about a person m with the name Mary, and
about an event e, and that the context set of r is
{r,r?,m,e}. Let?s also say that our communicative
goal is {like(e,m,r)}. In this case, the first action
instance in Fig. 3, S-likes-1(1.self,e,m,r), intro-
duces a substitution node with identity 1.pat. The
S:self
NP:ag ? 
VP:self
V:self
likes
NP:self 
the NP:self *
NP:self
a NP:self *
NP:self
PN:self
Mary
N:self
rabbit
N:self
white N:self * 
semcon: {like(self,ag,pat)}
semreq: {animate(ag)}
semcon: { }
semreq: { }
pragcon: {hearer-old(self)}
semcon: { }
semreq: { }
pragcon: {hearer-new(self)}
semcon: {white(self)}
semcon: {name(self, mary)}
semcon: {rabbit(self)}
NP:pat ? 
adjoin!
NP:self
Figure 4: The extended example grammar.
initial distractor set of this node is {r?,m} ? the set
of all individuals in r?s context set except for inan-
imate objects (which violate the semantic require-
ment) and r itself. The NP-rabbit-3 action removes
m from the distractor set, but at the end of the plan in
Fig. 3, r? is still a distractor, i.e. we have not reached
a goal state. We can complete the plan by perform-
ing a final action NP-white-5(1.pat,r), which will
remove this distractor and achieve the planning goal.
We can still reconstruct a derivation tree from the
complete plan literally as described in Section 2.
Now let?s say that the hearer did not know about
the existence of the individual r before the utterance
we are generating. We model this by marking r as
hearer-new in the pragmatic knowledge base and as-
signing it an empty context set. In this case, the re-
ferring expression 1.pat would be initialized with an
empty distractor set. This entitles us to use the action
NP-a-4 and generate the four-step plan correspond-
ing to the sentence ?Mary likes a rabbit.?
4 Discussion and future work
In conclusion, let?s look in more detail at computa-
tional issues and the role of mutually constraining
referring expressions.
341
Action S-likes-1(u,x1,x2,x3).
Precond: referent(u,x1),skb(like,x1,x2,x3),subst(S,u),step(1)
Effect: ?cg(like,x1,x2,x3),?subst(S,u),?step(1),step(2),subst(NP,1.ag),subst(NP,1.pat),
?y.?hkb(like,y,x2,x3) ??distractor(u,y),
?y,x1,x3.x2 6= y?pkb(contextset,x2,y)?animate(y) ? distractor(1.ag,y),
?y,x1,x2.x3 6= y?pkb(contextset,x3,y) ? distractor(1.pat,y)
Action NP-Mary-2(u,x1).
Precond: referent(u,x1),skb(name,x1,mary),
subst(NP,u),step(2)
Effect: ?cg(name,x1,mary),?subst(NP,u),
?step(2),step(3),
?y.?hkb(name,y,mary) ??distractor(u,y)
Action NP-rabbit-3(u,x1).
Precond: referent(u,x1),skb(rabbit,x1),
subst(N,u),step(3)
Effect: ?cg(rabbit,x1),?subst(N,u),?step(3),step(4),
canadjoin(NP,u),mustadjoin(NP,u),
?y.?hkb(rabbit,y) ??distractor(u,y)
Action NP-the-4(u,x1).
Precond: referent(u,x1),canadjoin(NP,u),step(4),
pkb(hearer-old,x1)
Effect: ?mustadjoin(NP,u),?step(4),step(5)
Action NP-a-4(u,x1).
Precond: referent(u,x1),canadjoin(NP,u),step(4),
pkb(hearer-new,x1)
Effect: ?mustadjoin(NP,u),?step(4),step(5)
Action NP-white-5(u,x1).
Precond: referent(u,x1),skb(white,x1),canadjoin(NP,u),step(5)
Effect: ?cg(white,x1),?mustadjoin(NP,u),?step(5),step(6),
?y.?hkb(white,y) ??distractor(u,y)
Figure 5: Some of the actions corresponding to the grammar in Fig. 4.
4.1 Computational issues
We lack the space to present the formal definition
of the sentence generation problem we encode into
PDDL. However, this problem is NP-complete, by
reduction of Hamiltonian Cycle ? unsurprisingly,
given that it encompasses realization, and the very
similar realization problem in Koller and Striegnitz
(2002) is NP-hard. So any algorithm for our prob-
lem must be prepared for exponential runtimes.
We have implemented the translation described in
this paper and experimented with a number of differ-
ent grammars, knowledge bases, and planners. The
FF planner (Hoffmann and Nebel, 2001) can com-
pute the plans in Section 3.3 in under 100 ms us-
ing the grammar in Fig. 4. If we add 10 more lex-
icon entries to the grammar, the runtime grows to
190 ms; and for 20 more entries, to 360 ms. The
runtime also grows with the plan length: It takes
410 ms to generate a sentence ?Mary likes the Adj
. . . Adj rabbit? with four adjectives and 890 ms for
six adjectives, corresponding to a plan length of 10.
We compared these results against a planning-based
reimplementation of SPUD?s greedy search heuris-
tic (Stone et al, 2003). This system is faster than FF
for small inputs (360 ms for four adjectives), but be-
comes slower as inputs grow larger (1000 ms for six
adjectives); but notice that while FF is also a heuris-
tic planner, it is guaranteed to find a solution if one
exists, unlike SPUD.
Planners have made tremendous progress in effi-
ciency in the past decade, and by encoding sentence
generation as a planning problem, we are set to profit
from any future improvements; it is an advantage
of the planning approach that we can compare very
different search strategies like FF?s and SPUD?s in
the same framework. However, our PDDL problems
are challenging for modern planners because most
planners start by computing all instances of atoms
and actions. In our experiments, FF generally spent
only about 10% of the runtime on search and the
rest on computing the instances; that is, there is a lot
of room for optimization. For larger grammars and
knowledge bases, the number of instances can easily
grow into the billions. In future work, we will there-
fore collaborate with experts on planning systems to
compute action instances only by need.
4.2 Referring expressions
In our analysis of referring expressions, the tree t
that introduces the new substitution nodes typically
initializes the distractor sets with proper subsets of
the entire domain. This allows us to generate suc-
cinct descriptions by encoding t?s presuppositions
as semantic requirements, and localizes the inter-
actions between the referring expressions generated
for different substitution nodes within t?s action.
342
However, an important detail in the encoding of
referring expressions above is that an individual a
counts as a distractor for the role r if there is any
tuple of values that satisfies the semantic require-
ment and has a in the r-component. This is correct,
but can sometimes lead to overly complicated refer-
ring expressions. An example is the construction ?X
takes Y from Z?, which presupposes that Y is in Z.
In a scenario that involves multiple rabbits, multiple
hats, and multiple individuals that are inside other
individuals, but only one pair of a rabbit r inside a
hat h, the expression ?X takes the rabbit from the
hat? is sufficient to refer uniquely to r and h (Stone
and Webber, 1998). Our system would try to gen-
erate an expression for Y that suffices by itself to
distinguish r from all distractors, and similarly for
Z. We will explore this issue further in future work.
5 Conclusion
In this paper, we have shown how sentence gener-
ation with TAG grammars and semantic and prag-
matic information can be encoded into PDDL. Our
encoding is declarative in that it can be used with
any correct planning algorithm, and explicit in that
the actions capture the complete effect of a word on
the syntactic, semantic, and local pragmatic goals.
In terms of expressive power, it captures the core of
SPUD, except for its inference capabilities.
This work is practically relevant because it opens
up the possibility of using efficient planners to make
generators faster and more flexible. Conversely, our
PDDL problems are a challenge for current plan-
ners and open up NLG as an application domain that
planning research itself can target.
Theoretically, our encoding provides a new
framework for understanding and exploring the gen-
eral relationships between language and action. It
suggests new ways of going beyond SPUD?s expres-
sive power, to formulate utterances that describe and
disambiguate concurrent real-world actions or ex-
ploit the dynamics of linguistic context within and
across sentences.
Acknowledgments. This work was funded by a DFG re-
search fellowship and the NSF grants HLC 0308121, IGERT
0549115, and HSD 0624191. We are indebted to Henry Kautz
for his advice on planning systems, and to Owen Rambow, Bon-
nie Webber, and the anonymous reviewers for feedback.
References
D. Appelt. 1985. Planning English Sentences. Cam-
bridge University Press, Cambridge England.
A. Blum and M. Furst. 1997. Fast planning through
graph analysis. Artificial Intelligence, 90:281?300.
P. R. Cohen and C. R. Perrault. 1979. Elements of a
plan-based theory of speech acts. Cognitive Science,
3(3):177?212.
R. Dale and E. Reiter. 1995. Computational interpreta-
tions of the Gricean maxims in the generation of refer-
ring expressions. Cognitive Science, 19.
D. DeVault, C. Rich, and C. Sidner. 2004. Natural lan-
guage generation and discourse context: Computing
distractor sets from the focus stack. In Proc. FLAIRS.
R. Fikes and N. Nilsson. 1971. STRIPS: A new approach
in the application of theorem proving to problem solv-
ing. Artificial Intelligence, 2:189?208.
P. Heeman and G. Hirst. 1995. Collaborating on
referring expressions. Computational Linguistics,
21(3):351?382.
J. Hobbs, M. Stickel, D. Appelt, and P. Martin. 1993.
Interpretation as abduction. Artificial Intelligence,
63:69?142.
J. Hoffmann and B. Nebel. 2001. The FF planning
system: Fast plan generation through heuristic search.
Journal of Artificial Intelligence Research, 14.
A. Joshi and Y. Schabes. 1997. Tree-Adjoining Gram-
mars. In G. Rozenberg and A. Salomaa, editors,
Handbook of Formal Languages, chapter 2, pages 69?
123. Springer-Verlag, Berlin.
H. Kautz and B. Selman. 1998. Blackbox: A new ap-
proach to the application of theorem proving to prob-
lem solving. In Workshop Planning as Combinatorial
Search, AIPS-98.
A. Koller and K. Striegnitz. 2002. Generation as depen-
dency parsing. In Proc. 40th ACL, Philadelphia.
D. V. McDermott. 2000. The 1998 AI Planning Systems
Competition. AI Magazine, 21(2):35?55.
M. Stone and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics. In
Proc. INLG.
M. Stone, C. Doran, B.Webber, T. Bleam, andM. Palmer.
2003. Microplanning with communicative inten-
tions: The SPUD system. Computational Intelligence,
19(4):311?381.
R. Thomason and J. Hobbs. 1997. Interrelating interpre-
tation and generation in an abductive framework. In
AAAI Fall Symposium on Communicative Action.
343
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1354?1359,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Predicting the resolution of referring expressions from user behavior
Nikos Engonopoulos1 Mart??n Villalba1 Ivan Titov2 Alexander Koller1
1University of Potsdam, Germany 2University of Amsterdam, Netherlands
{nikolaos.engonopoulos, martin.villalba}@uni-potsdam.de
titov@uva.nl, koller@ling.uni-potsdam.de
Abstract
We present a statistical model for predicting
how the user of an interactive, situated NLP
system resolved a referring expression. The
model makes an initial prediction based on the
meaning of the utterance, and revises it con-
tinuously based on the user?s behavior. The
combined model outperforms its components
in predicting reference resolution and when to
give feedback.
1 Introduction
Speakers and listeners in natural communication are
engaged in a highly interactive process. In order to
achieve some communicative goal, the speaker will
perform an utterance which they believe has a high
chance of achieving that goal. They will then moni-
tor the listener?s behavior to see whether this goal is
actually being achieved. This process is a core part
of what is commonly called grounding in the dia-
logue literature (see e.g. (Clark, 1996; Traum, 1994;
Paek and Horvitz, 1999; Hirst et al, 1994)). Inter-
active computer systems that are to carry out an ef-
fective and efficient conversation with a user must
model this grounding process, and should ideally re-
spond to the user?s observed behavior in real time.
For instance, if the user of a pedestrian navigation
system takes a wrong turn, the system should inter-
pret this as evidence of misunderstanding and bring
the user back on track.
We focus here on the problem of predicting how
the user has resolved a referring expression (RE) that
was generated by the system, i.e. a noun phrase that
is intended to identify some object uniquely to the
listener. A number of authors have recently offered
statistical models for parts of this problem. Golland
et al (2010) and Garoufi and Koller (2011) have
presented log-linear models for predicting how the
listener will resolve a given RE in a given scene;
however, these models do not update the probabil-
ity model based on observing the user?s reactions.
Nakano et al (2007), Buschmeier and Kopp (2012),
and Koller et al (2012) all predict what the listener
understood based on their behavior, but do not con-
sider the RE itself in the model. The models of
Frank and Goodman (2012) and Vogel et al (2013)
aim at explaining the effect of implicatures on the
listener?s RE resolution process in terms of hypothe-
sized interactions, but do not actually support a real-
time interaction between a system and a user.
In this paper, we show how to predict how the
listener has resolved an RE by combining a statis-
tical model of RE resolution based on the RE itself
with a statistical model of RE resolution based on
the listener?s behavior. To our knowledge, this is
the first approach to combine two such models ex-
plicitly. We consider the RE grounding problem in
the context of interactive, situated natural language
generation (NLG) for the GIVE Challenge (Koller et
al., 2010a), where NLG systems must generate real-
time instructions in virtual 3D environments. Our
evaluation is based on interaction corpora from the
GIVE-2 and GIVE-2.5 Challenges, which contain
the systems? utterances along with the behavior of
human hearers in response to these utterances. We
find that the combined model predicts RE resolu-
tion more accurately than each of the two compo-
nent models alone. We see this as a first step towards
implementing an actual interactive system that per-
forms human-like grounding based on our RE reso-
lution model.
1354
Figure 1: An example scene in the GIVE environment.
2 Problem definition
In the GIVE Challenge, an interactive NLG system
faces the task of guiding a human instruction fol-
lower (IF) through a treasure-hunt game in a vir-
tual 3D environment (see Fig. 1). To complete the
task, the IF must press a number of buttons in the
correct order; these buttons are the colored boxes in
Fig. 1, and are scattered all over the virtual environ-
ment. The IF can move around freely in the virtual
environment, but has no prior knowledge about the
world. The NLG system?s task is to guide the IF to-
wards the successful completion of the treasure-hunt
task. To this end, it is continuously being informed
about the IF?s movements and visual field, and can
generate written utterances at any time. As a com-
parative evaluation effort, the GIVE Challenges con-
nected NLG systems to thousands of users over the
Internet (see e.g. Koller et al (2010a) for details).
Many system utterances are manipulation instruc-
tions, such as ?press the blue button?, containing an
RE in the form of a definite NP. We call a given part
of an interaction between the system and the IF an
episode of that interaction if it starts with a manip-
ulation instruction, ends with the IF performing an
action (i.e., pressing a button), and contains only
IF movements and no further utterances in between.
Not all manipulation instructions initiate an episode,
because the system may decide to perform further
utterances (not containing REs) before the IF per-
forms their action. An NLG system will choose the
RE for an instruction at runtime out of potentially
many semantically valid alternatives (?the blue but-
ton?, ?the button next to the chair?, ?the button to
the right of the red button?, etc.). Ideally, it will pre-
dict which of these REs has the highest chance to be
understood by the IF, given the current scene, and
utter an instruction that uses this RE.
After uttering the manipulation instruction, the
system needs to ascertain whether the IF understood
the RE correctly, i.e. it must engage in grounding.
A naive grounding mechanism might wait until the
IF actually presses a button and check whether it was
the right one. This is what many NLG systems in the
GIVE Challenges actually did. However, this can
make the communication ineffective (IF performs
many useless actions) and risky (IF may press the
wrong button and lose). Thus, it is important that the
system updates its prediction of how the IF resolved
the RE continuously by observing the IF?s behavior,
before the actual button press. For instance, if the
IF walks towards the target, this might reinforce the
system?s belief in a correct understanding; turning
away or exiting the room could be strong evidence
of the opposite. The system can then exploit the up-
dated prediction to give the IF feedback (?no, the
blue button?) to prevent costly mistakes.
We address these challenges by estimating the
probability distribution over the possible objects to
which the IF may resolve the RE. We then update
this distribution in real time by observing the IF?s
movements. More specifically, assume that a sys-
tem tries to refer to some object a? among some set
A of available objects. Given an RE r generated for
a? at time t0, the state of the world s at t0, and the
observed behavior ?(t) of the user at t ? t0, we
estimate the probability p(a|r, s, ?(t)) that the user
resolved r to an object a ? A. When generating the
instruction, an optimal NLG system will use the RE
r that maximizes p(a?|r, s, ?(t0)). It can then track
p(a|r, s, ?(t)) for time points t > t0 throughout the
episode, and generate feedback when p(a?|r, s, ?(t))
exceeds p(a?|r, s, ?(t)) for some a? 6= a?; that is,
when the updated probability distribution predicts
that the IF resolved r to an incorrect button.
3 A model of RE resolution
In order to model the distribution over possible ob-
jects, we assume the following generative story:
when receiving an instruction containing an RE r at
a given world state s, the IF resolves it to an object
a; depending on the object a, the IF then moves to-
wards it, exhibiting behavior ?. These assumptions
correspond to the following factorization:
p(a, ?|r, s) = p(?|a)p(a|r, s)
1355
The posterior probability distribution over objects a
can be obtained by applying the Bayes rule and us-
ing the above assumptions:
p(a|r, s, ?) ? p(a|r, s)p(a|?)/p(a)
For simplicity, we assume a uniform p(a) over all
objects in a world. We can thus represent p(a|r, s, ?)
as the normalized product of a semantic model
psem(a|r, s) and an observational model pobs(a|?).
We use log-linear models for both, and train them
separately. The feature functions we use only con-
sider general properties of objects (such as color and
distance), and not the identity of the objects them-
selves. This means that we can train a model on one
virtual environment (containing a certain set of ob-
jects), and then apply the model to another virtual
environment, containing a different set of objects.
Semantic model The semantic model estimates
for each object a in the environment the initial prob-
ability psem(a|r, s) that the IF will understand a
given RE r uttered in a scene s as referring to a. It
represents the meaning of r, contextualized to s, and
is only ever evaluated at the time t0 of the utterance.
The features used by this model are:
? Semantic features aim to encode whether r
is a good description of a. IsColorModifying
evaluates to 1 if a?s color appears as an adjec-
tive modifying the head noun of r, e.g. ?the
blue button?. IsRelPosModifying evaluates to
1 if a?s relative position to the IF is mentioned
as an adjective in r, e.g. ?the left button?.
? Confusion features capture the hypothesis that
the IF may be confused by the description of a
landmark when resolving the RE; e.g. an RE
like ?the button next to the red button? might
confuse the IF into pressing a red button, rather
than the one meant by the system. These are
the same features as in the Semantic case, but
looking for modifier keywords in the entire RE,
including the head.
? Salience features account for the fact that an
IF is more likely to resolve r to a if a was visu-
ally salient in s. IsVisible evaluates to 1 if a is
visible to the IF in s. IsInRoom evaluates to 1
if the IF and a are in the same room. IsTarget-
InFront evaluates to 1 if the angular distance
towards a, i.e. the absolute angle between the
camera direction and the straight line from the
IF to a, is less than pi4 . VisualSalience approx-
imates the visual salience of Kelleher and van
Genabith (2004), a weighted count of the num-
ber of pixels on which a is rendered (pixels near
the center of the screen have higher weights).
Observational model The observational model
estimates for each object a the probability pobs(a|?)
that the IF will interact with a, given the IF?s recent
behavior ?(t) = (?1, . . . , ?n), where ?i is the state
of the world at time t? (i? 1) ? 500ms, and n ? 1
is the length of the observed behavior. pobs is con-
stantly re-evaluated for times t > t0 as the IF moves
around. pobs uses the following features:
? Linear distance features assume that the clos-
est button is also the one the IF understood. In-
Room returns the number of frames ?i in ? in
which the IF and a are in the same room. But-
tonDistance returns the distance between the IF
and a at ?1 divided by a constant such that the
result never exceeds 1. If a is neither in the
same room nor visible, the feature returns 1.
? Angular distance features analyze the direc-
tion in which the IF looks. TargetInFront re-
turns the angular distance towards a at ?1. An-
gleToTarget returns TargetInFront divided by
pi, or 1 if a is neither in the same room nor
visible. LinearRegAngleTo applies linear re-
gression to a list of observed angular distances
towards a over all frames ?i, and returns the
slope of the regression as a measure of varia-
tion. Negative values indicate that the IF turned
towards a, while positive values mean the op-
posite. If a is neither visible nor in the same
room as the IF at ?i, the angle is set to pi.
? Combined distance feature: a weighted sum
of linear and angular distance towards a, called
overall distance in Koller et al (2012).
? Salience features capture visual salience and
its change over time. Defining VSi as the result
of applying the psem feature VisualSalience to
?i and a, LastVisualSalience returns VSn. Lin-
earRegVisualSalience applies linear regression
to all values VSi and returns the slope as a mea-
sure of change in salience. VisualSalienceSum
returns (?ni=1VSi) ?VS1. This emphasizes the
contribution of VS1, which we assume is the
1356
most reliable predictor of the IF?s intentions.
? Binary features aim to detect concrete behav-
ior patterns: LastIsVisible applies the psem fea-
ture IsVisible to ?1, and IsClose evaluates to 1
if the IF is close enough and correctly oriented
to manipulate a in the GIVE environment at ?1.
4 Evaluation
Data We evaluated our model using data from the
GIVE-2 (Koller et al, 2010b) and the GIVE-2.5
Challenges (Striegnitz et al, 2011), obtained from
GIVE Organizers (2012). These datasets constitute
interaction corpora, in which the IF?s activities in
the virtual environment were recorded along with
the utterances automatically generated by the par-
ticipating NLG systems. The data consists of 1833
games for GIVE-2 and 687 games for GIVE-2.5.
To extract training data for our model from the
GIVE-2.5 data, we first identified moments in the
recorded data where the IF pressed a button. From
these, we discarded all instances from the tutorial
phase of the GIVE game and those that happened
within 200 ms after the previous utterance, as these
clearly didn?t happen in response to it. This yielded
6478 training instances for pobs, each consisting of
? at 1 second before the action, and the button a
which the IF pressed. We chose n = 4 for rep-
resenting ?, except to ensure that the features only
considered IF behavior that happened in response to
an utterance. We achieved this by reducing n for the
first few frames after each utterance, such that the
time of ?n was always after the time of the utter-
ance. Finally, we selected those instances which are
episodes in the sense of Section 2, i.e. those in which
the last utterance before the action contained an RE
r. This gave us 3414 training instances for psem,
each consisting of a, r, the time t0 of the utterance,
and the world state s at time t0.
We obtained test instances from the GIVE-2 data
in the same way. This yielded 5028 instances, each
representing an episode. We chose GIVE-2 for test-
ing because the mean episode length is higher (3.3s,
vs. 2.0s in GIVE-2.5), thus making the evaluation
more challenging. Feature selection was done using
the training data and a similar dataset from Koller et
al. (2012). Note that the test data and training data
are based on distinct sets of three virtual environ-
l
l l
l
0.0
0.2
0.4
0.6
Ac
cur
ac
y
l combined
semantic
observational
KGSC
random visible
(a)
l l
l l
?3 ?2 ?1 0
0.0
0.2
0.4
0.6
Time before action (sec)
Ac
cur
ac
y
l combined
semantic
observational
KGSC
random visible
(b)
Figure 2: Prediction accuracy for (a) all episodes, (b) un-
successful episodes as a function of time.
ments each, and were obtained with different NLG
systems and users. This demonstrates the ability of
our model to generalize to unseen environments.
An example video showing our models? predic-
tions on some training episodes can be found at
http://tinyurl.com/re-demo-v.
Prediction accuracy We first evaluated the abil-
ity of our model to predict the button to which
the IF resolved each RE. For each test instance
?r, s, ?, a?, we compare the object returned by
arg maxa p(a|r, s, ?(t)) to the one manipulated by
the IF. We call the proportion of correctly classified
instances the prediction accuracy.
Fig. 2a compares our model?s prediction accuracy
to that of several baselines. We plot prediction ac-
curacy as a function of the time at which the model
is queried for a prediction, by evaluating at 3s, 2s,
1s, and 0s before the button press. The graph is
based on the 2094 test instances with an episode
length of at least three seconds, to ensure that re-
sults for different prediction times are comparable.
As expected, prediction accuracy increases as we ap-
proach the time of the action. Furthermore, the com-
bined model outperforms both psem and pobs reli-
ably. This indicates that the component models pro-
1357
vide complementary useful information. Our model
also outperforms two more baselines: KGSC pre-
dicts that the IF will press the button with the min-
imal overall distance, which is the distance metric
used by the ?movement-based system? of Koller et
al. (2012); random visible selects a random button
from the ones that are currently visible to the IF.
The fact that this last baseline does not approach 1
at action time suggests that multiple buttons tend to
be visible when the IF presses one, confirming that
the prediction task is not trivial.
Correctly predicting the button that the IF will
press is especially useful, and challenging, in those
cases where the IF pressed a different button than
the one the NLG system intended. Fig. 2b shows
a closer look at the 125 unsuccessful episodes of at
least three seconds in the test data. These tend to
be hard instances, and thus as expected, prediction
accuracy drops for all systems. However, by inte-
grating semantic and observational information, the
combined model compensates better for this than all
other systems, with an accuracy of 37.6% against
31.2% for each individual component.
Feedback appropriateness Second, we evaluated
the ability of our model to predict whether the user
misunderstood the RE and requires feedback. For all
the above models, we assumed a simple feedback
mechanism which predicts that the user misunder-
stood the RE if p(a?) ? p(a?) > ? for some object
a? 6= a?, where ? is a confidence threshold; we used
? = 0.1 here. We can thus test on recorded data in
which no actual feedback can be given anymore.
We evaluated the models on the 848 test episodes
of at least 3s in which the NLG systems logged the
button they tried to refer to. The results are shown
in Fig. 3 in terms of F1 measure. Here precision is
the proportion of instances in which the IF pressed
the wrong button (i.e., where feedback should have
been given) among the instances where the model
actually suggested feedback. Recall is the propor-
tion of instances in which the model suggested feed-
back among the instances where the IF pressed the
wrong button. Again, the combined model outper-
forms its components and the baselines, primarily
due to increased recall. The difference is particu-
larly pronounced early on, which would be useful in
giving timely feedback in an actual real-time system.
l l
l l
?3 ?2 ?1 0
0.0
0.2
0.4
0.6
Time before action (s)
Fee
dba
ck 
F1
l combined
semantic
observational
KGSC
random visible
Figure 3: Feedback F1-measure as a function of time.
5 Conclusion and future work
We presented a statistical model for predicting how
a user will resolve the REs generated by an interac-
tive, situated NLG system. The model continuously
updates an initial estimate based on the meaning of
the RE with a model of the user?s behavior. It out-
performs its components and two baselines on pre-
diction and feedback accuracy.
Our model captures a real-time grounding process
on the part of the interactive system. We thus believe
that it provides a solid foundation for detecting mis-
understandings and generating suitable feedback in
an end-to-end dialogue system. We have presented
our model in terms of a situated dialogue setting,
where clues about what the hearer understood can be
observed directly. However, we believe that the fun-
damental mechanism should apply to other domains
as well. This would amount to finding observable
linguistic and non-linguistic clues of hearer under-
standing that can be used as features of pobs.
The immediate next step for future research is
to extend our model to an implemented end-to-end
situated NLG system for the GIVE Challenge, and
evaluate whether this actually improves task perfor-
mance. This requires, in particular, to compute the
RE that is optimal with respect to psem. We will fur-
thermore improve pobs by switching to a more tem-
porally dynamic probability model.
Acknowledgments. We thank Konstantina
Garoufi and the anonymous reviewers for their
insightful comments and suggestions. The first two
authors were supported by the SFB 632 ?Informa-
tion Structure?; Titov?s work was supported by the
Cluster of Excellence at Saarland University.
1358
References
Hendrik Buschmeier and Stefan Kopp. 2012. Adapting
language production to listener feedback behaviour.
In Proceedings of the Interdisciplinary Workshop on
Feedback Behaviors in Dialog.
Herbert C. Clark. 1996. Using Language. Cambridge
University Press.
Michael C. Frank and Noah D. Goodman. 2012. Predict-
ing pragmatic reasoning in language games. Science,
336(6084):998.
Konstantina Garoufi and Alexander Koller. 2011. Com-
bining symbolic and corpus-based approaches for the
generation of successful referring expressions. In Pro-
ceedings of the 13th European Workshop on Natural
Language Generation (ENLG).
GIVE Organizers. 2012. Give challenge web-
site: Corpora. http://give-challenge.org/
research/page.php?id=corpora.
Dave Golland, Percy Liang, and Dan Klein. 2010. A
game-theoretic approach to generating spatial descrip-
tions. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
Graeme Hirst, Susan McRoy, Peter Heeman, Philip Ed-
monds, and Diane Horton. 1994. Repairing conver-
sational misunderstandings and non-understandings.
Speech Communications, 15:213?229.
J. D. Kelleher and J. van Genabith. 2004. Visual salience
and reference resolution in simulated 3-D environ-
ments. Artificial Intelligence Review, 21(3).
Alexander Koller, Kristina Striegnitz, Donna Byron, Jus-
tine Cassell, Robert Dale, Johanna Moore, and Jon
Oberlander. 2010a. The First Challenge on Generat-
ing Instructions in Virtual Environments. In E. Krah-
mer and M. Theune, editors, Empirical Methods in
Natural Language Generation, number 5790 in LNCS,
pages 337?361. Springer.
Alexander Koller, Kristina Striegnitz, Andrew Gargett,
Donna Byron, Justine Cassell, Robert Dale, Johanna
Moore, and Jon Oberlander. 2010b. Report on the
Second NLG Challenge on Generating Instructions in
Virtual Environments (GIVE-2). In Proceedings of the
6th International Natural Language Generation Con-
ference (INLG).
Alexander Koller, Konstantina Garoufi, Maria Staudte,
and Matthew Crocker. 2012. Enhancing referential
success by tracking hearer gaze. In Proceedings of the
13th Annual SIGdial Meeting on Discourse and Dia-
logue (SIGDIAL), Seoul.
Yukiko Nakano, Kazuyoshi Murata, Mika Enomoto,
Yoshiko Arimoto, Yasuhiro Asa, and Hirohiko
Sagawa. 2007. Predicting evidence of understanding
by monitoring user?s task manipulation in multimodal
conversations. In Proceedings of the ACL 2007 Demo
and Poster Sessions.
Tim Paek and Eric Horvitz. 1999. Uncertainty, utility,
and misunderstanding: A decision-theoretic perspec-
tive on grounding in conversational systems. In AAAI
Fall Symposium on Psychological Models of Commu-
nication in Collaborative Systems.
Kristina Striegnitz, Alexandre Denis, Andrew Gargett,
Konstantina Garoufi, Alexander Koller, and Mariet
Theune. 2011. Report on the Second Second Chal-
lenge on Generating Instructions in Virtual Environ-
ments (GIVE-2.5). In Proceedings of the 13th Eu-
ropean Workshop on Natural Language Generation
(ENLG).
David Traum. 1994. A computational theory of ground-
ing in natural language conversation. Ph.D. thesis,
University of Rochester.
Adam Vogel, Christopher Potts, and Dan Jurafsky.
2013. Implicatures and nested beliefs in approximate
Decentralized-POMDPs. In Proceedings of ACL.
1359
Proceedings of the EACL 2009 Demonstrations Session, pages 33?36,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
The Software Architecture for the
First Challenge on Generating Instructions in Virtual Environments
Alexander Koller
Saarland University
koller@mmci.uni-saarland.de
Donna Byron
Northeastern University
dbyron@ccs.neu.edu
Justine Cassell
Northwestern University
justine@northwestern.edu
Robert Dale
Macquarie University
Robert.Dale@mq.edu.au
Johanna Moore
University of Edinburgh
J.Moore@ed.ac.uk
Jon Oberlander
University of Edinburgh
J.Oberlander@ed.ac.uk
Kristina Striegnitz
Union College
striegnk@union.edu
Abstract
The GIVE Challenge is a new Internet-
based evaluation effort for natural lan-
guage generation systems. In this paper,
we motivate and describe the software in-
frastructure that we developed to support
this challenge.
1 Introduction
Natural language generation (NLG) systems are
notoriously hard to evaluate. On the one hand,
simply comparing system outputs to a gold stan-
dard is not appropriate because there can be mul-
tiple generated outputs that are equally good, and
finding metrics that account for this variability and
produce results consistent with human judgments
and task performance measures is difficult (Belz
and Gatt, 2008; Stent et al, 2005; Foster, 2008).
On the other hand, lab-based evaluations with hu-
man subjects to assess each aspect of the system?s
functionality are expensive and time-consuming.
These characteristics make it hard to compare dif-
ferent systems and measure progress.
GIVE (?Generating Instructions in Virtual En-
vironments?) (Koller et al, 2007) is a research
challenge for the NLG community designed to
provide a new approach to NLG system evalua-
tion. In the GIVE scenario, users try to solve
a treasure hunt in a virtual 3D world that they
have not seen before. The computer has a com-
plete symbolic representation of the virtual envi-
ronment. The challenge for the NLG system is
to generate, in real time, natural-language instruc-
tions that will guide the users to the successful
completion of their task (see Fig. 1). One cru-
cial advantage of this generation task is that the
NLG system and the user can be physically sepa-
rated. This makes it possible to carry out a task-
based evaluation over the Internet ? an approach
that has been shown to provide generous amounts
Figure 1: The GIVE Challenge.
of data in earlier studies (von Ahn and Dabbish,
2004; Orkin and Roy, 2007).
In this paper, we describe the software archi-
tecture underlying the GIVE Challenge. The soft-
ware connects each player in a 3D game world
with an NLG system over the Internet. It is imple-
mented and open source, and can be a used online
during EACL at www.give-challenge.org.
In Section 2, we give an introduction to the GIVE
evaluation methodology by describing the experi-
ence of a user participating in the evaluation, the
nature of the data we collect, and our scientific
goals. Then we explain the software architecture
behind the scenes and sketch the API that concrete
NLG systems must implement in Section 3. In
Section 4, we present some preliminary evaluation
results, before we conclude in Section 5.
2 Evaluation method
Users participating in the GIVE evaluation
start the 3D game from our website at www.
give-challenge.org. They then see a 3D
game window as in Fig. 1, which displays instruc-
tions and allows them to move around in the world
and manipulate objects. The first room is a tuto-
rial room where users learn how to interact with
33
b2 b3b4 b5
b6
b7
b1
player
b8b9
b10
b11 b14b13b12
safe 
door
b1 opens doorto room 3
b9 moves picture to
b8: part of safe sequencereveal safe
? to win you have to retrieve the trophy from the safe in room 1? use button b9 to move the picture (and get access to the safe)
? if the alarm sounds, the game is over and you have lost
? press buttons b8, b6, b13, b13, b10 (in this order) to open the safe;if a button is pressed in the wrong order, the whole sequence is reset
b14 makes alarm soundb10, b13: part of safe sequence door to room 2b7 opens/closesstepping on this tiletriggers alarm
alarm
room 3
b2 turns off alarm tileb3 opens/closes door to room 2
b6: part of safe sequence
room 1
b5 makes alarm sound
room 2
door
door
lampcouch
chair
flower
pictu
retrophy
Figure 2: The map of a virtual world.
the system; they then enter one of three evaluation
worlds, where instructions for solving the treasure
hunt are generated by an NLG system.
The map of one of the game worlds is shown in
Fig. 2: In this world, players must pick up a trophy,
which is in a wall safe behind a picture. In order
to access the trophy, they must first push a button
to move the picture to the side, and then push an-
other sequence of buttons to open the safe. One
floor tile is alarmed, and players lose the game
if they step on this tile without deactivating the
alarm first. There are also a number of distrac-
tor buttons which either do nothing when pressed
or set off an alarm. These distractor buttons are in-
tended to make the game harder and, more impor-
tantly, to require appropriate reference to objects
in the game world. Finally, game worlds can con-
tain a number of objects such as chairs and flowers
which are irrelevant for the task, but can be used
as landmarks by a generation system.
Users are asked to fill out a before- and after-
game questionnaire that collects some demo-
graphic data and asks the user to rate various as-
pects of the instructions they received. Every ac-
tion that players take in a game world, and every
instruction that a generation system generates for
them, is recorded in a database. In addition to the
questionnaire data, we are thus able to compute a
number of objective measures such as:
? the percentage of users each system leads to
a successful completion of the task;
? the average time, the average number of in-
structions, and the average number of in-
game actions that this success requires;
? the percentage of generated referring expres-
sions that the user resolves correctly; and
? average reaction times to instructions.
It is important to note that we have designed
the GIVE Challenge not as a competition, but as
a friendly evaluation effort where people try to
learn from each other?s successes. This is reflected
in the evaluation measures above, which are in
tension with one another: For instance, a system
which gives very low-level instructions (?move
forward?; ?ok, now move forward?; ?ok, now turn
left?) will enjoy short reaction times, but it will re-
quire more instructions than a system that aggre-
gates these. To further emphasize this perspective,
we will also provide a number of diagnostic tools,
such as heat maps that show how much time users
spent on each tile, or a playback function which
displays an entire game run in real time.
In summary, the GIVE Challenge is a novel
evaluation effort for NLG systems. It is motivated
by real applications (such as pedestrian navigation
and the generation of task instructions), makes
no assumptions about the internal structure of an
NLG system, and emphasizes the situated genera-
tion of discourse in a simulated physical environ-
ment. The game world is scalable; it can be made
more complex and it can be adapted to focus on
specific issues in natural language generation.
3 Architecture
A crucial aspect of the GIVE evaluation methodol-
ogy is that it physically separates the user and the
NLG system and connects them over the Internet.
To achieve this, the GIVE software infrastructure
consists of three components:
1. the client, which displays the 3D world to
users and allows them to interact with it;
2. the NLG servers, which generate the natural-
language instructions; and
3. the Matchmaker, which establishes connec-
tions between clients and NLG servers.
These three components run on different ma-
chines. The client is downloaded by users from
our website and run on their local machine; each
NLG server is run on a server at the institution
that implemented it; and the Matchmaker runs on
a central server we provide.
34
Game Client
Matchmaker
NLG Server
NLG Server
NLG Server
Figure 3: The GIVE architecture.
When a user starts the client, it connects over
the Internet to the Matchmaker. The Matchmaker
then selects a game world and an NLG server at
random, and requests the NLG server to spawn
a new server instance. It then sends the game
world to the client and the server instance and dis-
connects from them, ready to handle new connec-
tions from other clients. The client and the server
instance play one game together: Whenever the
user does something, the client sends a message
about this to the server instance, and the server in-
stance can also send a message back to the client
at any time, which will then be displayed as an in-
struction. When the game ends, the client and the
server instance disconnect from each other. The
server instance sends a log of all game events to
the Matchmaker, and the client sends the ques-
tionnaire results to the Matchmaker; these then are
stored in the database for later analysis.
All of these components are implemented in
Java. This allows the client to be portable across
all major operating systems, and to be started di-
rectly from the website via Java Web Start without
the need for software installation. We felt it was
important to make startup of the client as effort-
less as possible, in order to maximize the num-
ber of users willing to play the game. Unsurpris-
ingly, we had to spend the majority of the pro-
gramming time on the 3D graphics (based on the
free jMonkeyEngine library) and the networking
code. We could have reduced the effort required
for these programming tasks by building upon an
existing virtual 3D world system such as Second
Life. However, we judged that the effort needed to
adapt such a system to our needs would have been
at least as high (in particular, we would have had
to ensure that the user could only move according
to the rules of the GIVE game and to instrument
the virtual world to obtain real-time updates about
events), and the result would have been less exten-
abstract class NlgSystem:
void connectionEstablished();
void connectionDisconnected();
void handleStatusInformation(Position playerPosition,
Orientation playerOrientation,
List?String? visibleObjects);
void handleAction(Atom actionInstance,
List?Formula? updates);
void handleDidNotUnderstand();
void handleMoveTurnAction(Direction direction);
. . .
Figure 4: The interface of an NLG system.
sible to future installments of the challenge.
Since we provided all the 3D, networking, and
database code, the research teams being evaluated
were able to concentrate on the development of
their NLG systems. Our only requirement was
that they implement a concrete subclass of the
class NlgSystem, shown in Fig. 4. This involves
overriding the six abstract callback methods in
this class with concrete implementations in
which the NLG system reacts to specific events.
The methods connectionEstablished
and connectionDisconnected are called
when users enter the game world and when
they disconnect from the game. The method
handleAction gets called whenever the user
performs some physical action, such as pushing a
button, and specifies what changed in the world
due to this action; handleMoveTurnAction
gets called whenever the user moves;
handleDidNotUnderstand gets called
whenever users press the H key to signal that
they didn?t understand the previous instruction;
and handleStatusInformation gets called
once per second and after each user action to
inform the server of the player?s position and
orientation and the visible objects. Ultimately,
each of these method calls gets triggered by a
message that the client sends over the network
in reaction to some event; but this is completely
hidden from the NLG system developer.
The NLG system can use the method send to
send a string to the client to be displayed. It also
has access to various methods querying the state of
the game world and to an interface to an external
planner which can compute a sequence of actions
leading to the goal.
4 First results
For this first installment of the GIVE Challenge,
four research teams from the US, the Netherlands,
35
and Spain provided generation systems, and a
number of other research groups expressed their
interest in participating, but weren?t able to partic-
ipate due to time constraints. Given that this was
the first time we organized this task, we find this
a very encouraging number. All four of the teams
consisted primarily of students who implemented
the NLG systems over the Northern-hemisphere
summer. This is in line with our goal of tak-
ing this first iteration as a ?dry run? in which we
could fine-tune the software, learn about the easy
and hard aspects of the challenge, and validate the
evaluation methodology.
Public involvement in the GIVE Challenge was
launched with a press release in early Novem-
ber 2008; the Matchmaker and the NLG servers
were then kept running until late January 2009.
During this time, online users played over 1100
games, which translates into roughly 75 game runs
for each experimental condition (i.e., five differ-
ent NLG systems paired with three different game
worlds). To our knowledge, this makes GIVE the
largest NLG evaluation effort yet in terms of ex-
perimental subjects.
While we have not yet carried out the detailed
evaluation, the preliminary results look promising:
a casual inspection shows that there are consider-
able differences in task success rate among the dif-
ferent systems.
While there is growing evidence from differ-
ent research areas that the results of Internet-based
evaluations are consistent with more traditional
lab-based experiments (e.g., (Keller et al, 2008;
Gosling et al, 2004)), the issue is not yet set-
tled. Therefore, we are currently conducting a lab-
based evaluation of the GIVE NLG systems, and
will compare those results to the qualitative and
quantitative data provided by the online subjects.
5 Conclusion
In this paper, we have sketched the GIVE Chal-
lenge and the software infrastructure we have de-
veloped for it. The GIVE Challenge is, to the
best of our knowledge, the largest-scale NLG eval-
uation effort with human experimental subjects.
This is made possible by connecting users and
NLG systems over the Internet; we collect eval-
uation data automatically and unobtrusively while
the user simply plays a 3D game. While we will
report on the results of the evaluation in more de-
tail at a later time, first results seem encouraging
in that the performance of different NLG systems
differs considerably.
In the future, we will extend the GIVE Chal-
lenge to harder tasks. Possibilities includ mak-
ing GIVE into a dialogue challenge by allowing
the user to speak as well as act in the world; run-
ning the challenge in a continuous world rather
than a world that only allows discrete movements;
or making it multimodal by allowing the NLG
system to generate arrows or virtual human ges-
tures. All these changes would only require lim-
ited changes to the GIVE software architecture.
However, the exact nature of future directions re-
mains to be discussed with the community.
References
A. Belz and A. Gatt. 2008. Intrinsic vs. extrinsic eval-
uation measures for referring expression generation.
In Proceedings of ACL-08:HLT, Short Papers, pages
197?200, Columbus, Ohio.
M. E. Foster. 2008. Automated metrics that agree
with human judgements on generated output for an
embodied conversational agent. In Proceedings of
INLG 2008, pages 95?103, Salt Fork, OH.
S. D. Gosling, S. Vazire, S. Srivastava, and O. P. John.
2004. Should we trust Web-based studies? A com-
parative analysis of six preconceptions about Inter-
net questionnaires. American Psychologist, 59:93?
104.
F. Keller, S. Gunasekharan, N. Mayo, and M. Corley.
2008. Timing accuracy of web experiments: A case
study using the WebExp software package. Behav-
ior Research Methods, to appear.
A. Koller, J. Moore, B. di Eugenio, J. Lester, L. Stoia,
D. Byron, J. Oberlander, and K. Striegnitz. 2007.
Shared task proposal: Instruction giving in virtual
worlds. In M. White and R. Dale, editors, Work-
ing group reports of the Workshop on Shared Tasks
and Comparative Evaluation in Natural Language
Generation. Available at http://www.ling.
ohio-state.edu/nlgeval07/report.html.
J. Orkin and D. Roy. 2007. The restaurant game:
Learning social behavior and language from thou-
sands of players online. Journal of Game Develop-
ment, 3(1):39?60.
A. Stent, M. Marge, and M. Singhai. 2005. Evaluating
evaluation methods for generation in the presence of
variation. In Proceedings of CICLing 2005.
L. von Ahn and L. Dabbish. 2004. Labeling images
with a computer game. In Proceedings of the ACM
CHI Conference.
36
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 757?766,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Generation of landmark-based navigation instructions
from open-source data
Markus Dra?ger
Dept. of Computational Linguistics
Saarland University
mdraeger@coli.uni-saarland.de
Alexander Koller
Dept. of Linguistics
University of Potsdam
koller@ling.uni-potsdam.de
Abstract
We present a system for the real-time gen-
eration of car navigation instructions with
landmarks. Our system relies exclusively
on freely available map data from Open-
StreetMap, organizes its output to fit into
the available time until the next driving ma-
neuver, and reacts in real time to driving er-
rors. We show that female users spend sig-
nificantly less time looking away from the
road when using our system compared to a
baseline system.
1 Introduction
Systems that generate route instructions are be-
coming an increasingly interesting application
area for natural language generation (NLG) sys-
tems. Car navigation systems are ubiquitous
already, and with the increased availability of
powerful mobile devices, the wide-spread use of
pedestrian navigation systems is on the horizon.
One area in which NLG systems could improve
existing navigation systems is in the use of land-
marks, which would enable them to generate in-
structions such as ?turn right after the church? in-
stead of ?after 300 meters?. It has been shown in
human-human studies that landmark-based route
instructions are easier to understand (Lovelace
et al 1999) than distance-based ones and re-
duce driver distraction in in-car settings (Bur-
nett, 2000), which is crucial for improved traffic
safety (Stutts et al 2001). From an NLG per-
spective, navigation systems are an obvious ap-
plication area for situated generation, for which
there has recently been increasing interest (see
e.g. (Lessmann et al 2006; Koller et al 2010;
Striegnitz and Majda, 2009)).
Current commercial navigation systems use
only trivial NLG technology, and in particular are
limited to distance-based route instructions. Even
in academic research, there has been remarkably
little work on NLG for landmark-based naviga-
tion systems. Some of these systems rely on map
resources that have been hand-crafted for a par-
ticular city (Malaka et al 2004), or on a com-
bination of multiple complex resources (Raubal
and Winter, 2002), which effectively limits their
coverage. Others, such as Dale et al(2003), fo-
cus on non-interactive one-shot instruction dis-
courses. However, commercially successful car
navigation systems continuously monitor whether
the driver is following the instructions and pro-
vide modified instructions in real time when nec-
essary. That is, two key problems in designing
NLG systems for car navigation instructions are
the availability of suitable map resources and the
ability of the NLG system to generate instructions
and react to driving errors in real time.
In this paper, we explore solutions to both of
these points. We present the Virtual Co-Pilot,
a system which generates route instructions for
car navigation using landmarks that are extracted
from the open-source OpenStreetMap resource.1
The system computes a route plan and splits it
into episodes that end in driving maneuvers. It
then selects landmarks that describe the locations
of these driving maneuvers, and aggregates in-
structions such that they can be presented (via
a TTS system) in the time available within the
episode. The system monitors the user?s position
and computes new, corrective instructions when
the user leaves the intended path. We evaluate
our system using a driving simulator, and com-
pare it to a baseline that is designed to replicate
a typical commercial navigation system. The Vir-
tual Co-Pilot performs comparably to the baseline
1http://www.openstreetmap.org/
757
on the number of driving errors and on user sat-
isfaction, and outperforms it significantly on the
time female users spend looking away from the
road. To our knowledge, this is the first time that
the generation of landmarks has been shown to
significantly improve the instructions of a wide-
coverage navigation system.
Plan of the paper. We start by reviewing ear-
lier literature on landmarks, route instructions,
and the use of NLG for route instructions in Sec-
tion 2. We then present the way in which we
extract information on potential landmarks from
OpenStreetMap in Section 3. Section 4 shows
how we generate route instructions, and Section 5
presents the evaluation. Section 6 concludes.
2 Related Work
What makes an object in the environment a good
landmark has been the topic of research in vari-
ous disciplines, including cognitive science, com-
puter science, and urban planning. Lynch (1960)
defines landmarks as physical entities that serve
as external points of reference that stand out from
their surroundings. Kaplan (1976) specified a
landmark as ?a known place for which the in-
dividual has a well-formed representation?. Al-
though there are different definitions of land-
marks, a common theme is that objects are con-
sidered landmarks if they have some kind of cog-
nitive salience (both in terms of visual distinctive-
ness and frequeny of interaction).
The usefulness of landmarks in route instruc-
tions has been shown in a number of different
human-human studies. Experimental results from
Lovelace et al(1999) show that people not only
use landmarks intuitively when giving directions,
but they also perceive instructions that are given to
them to be of higher quality when those instruc-
tions contain landmark information. Similar find-
ings have also been reported by Michon and Denis
(2001) and Tom and Denis (2003).
Regarding car navigation systems specifically,
Burnett (2000) reports on a road-based user study
which compared a landmark-based navigation
system to a conventional car navigation system.
Here the provision of landmark information in
route directions led to a decrease of navigational
errors. Furthermore, glances at the navigation
display were shorter and fewer, which indicates
less driver distraction in this particular experi-
mental condition. Minimizing driver distraction
is a crucial goal of improved navigation systems,
as driver inattention of various kinds is a lead-
ing cause of traffic accidents (25% of all police-
reported car crashes in the US in 2000, according
to Stutts et al(2001)). Another road-based study
conducted by May and Ross (2006) yielded simi-
lar results.
One recurring finding in studies on landmarks
in navigation is that some user groups are able
to benefit more from their inclusion than oth-
ers. This is particularly the case for female users.
While men tend to outperform women in wayfind-
ing tasks, completing them faster and with fewer
navigation errors (c.f. Allen (2000)), women are
likely to show improved wayfinding performance
when landmark information is given (e.g. Saucier
et al(2002)).
Despite all of this evidence from human-human
studies, there has been remarkably little research
on implemented navigation systems that use land-
marks. Commercial systems make virtually no
use of landmark information when giving direc-
tions, relying on metric representations instead
(e.g. ?Turn right in one hundred meters?). In aca-
demic research, there have only been a handful of
relevant systems. A notable example is the DEEP
MAP system, which was created in the SmartKom
project as a mobile tourist information system for
the city of Heidelberg (Malaka and Zipf, 2000;
Malaka et al 2004). DEEP MAP uses landmarks
as waypoints for the planning of touristic routes
for car drivers and pedestrians, while also making
use of landmark information in the generation of
route directions. Raubal and Winter (2002) com-
bine data from digital city maps, facade images,
cultural heritage information, and other sources
to compute landmark descriptions that could be
used in a pedestrian navigation system for the city
of Vienna.
The key to the richness of these systems is a
set of extensive, manually curated geographic and
landmark databases. However, creation and main-
tenance of such databases is expensive, which
makes it impractical to use these systems outside
of the limited environments for which they were
created. There have been a number of suggestions
for automatically acquiring landmark data from
existing electronic databases, for instance cadas-
tral data (Elias, 2003) and airborne laser scans
(Brenner and Elias, 2003). But the raw data for
these approaches is still hard to obtain; informa-
758
tion about landmarks is mostly limited to geomet-
ric data and does not specify the semantic type
of a landmark (such as ?church?); and updating
the landmark database frequently when the real
world changes (e.g., a shop closes down) remains
an open issue.
The closest system in the literature to the re-
search we present here is the CORAL system
(Dale et al 2003). CORAL generates a text of
driving instructions with landmarks out of the out-
put of a commercial web-based route planner. Un-
like CORAL, our system relies purely on open-
source map data. Also, our system generates driv-
ing instructions in real time (as opposed to a sin-
gle discourse before the user starts driving) and
reacts in real time to driving errors. Finally, we
evaluate our system thoroughly for driving errors,
user satisfaction, and driver distraction on an ac-
tual driving task, and find a significant improve-
ment over the baseline.
3 OpenStreetMap
A system that generates landmark-based route di-
rections requires two kinds of data. First, it must
plan routes between points in space, and therefore
needs data on the road network, i.e. the road seg-
ments that make up streets along with their con-
nections. Second, the system needs information
about the landmarks that are present in the envi-
ronment. This includes geographic information
such as position, but also semantic information
such as the landmark type.
We have argued above that the availability of
such data has been a major bottleneck in the
development of landmark-based navigation sys-
tems. In the Virtual Co-Pilot system, which
we present below, we solve this problem by us-
ing data from OpenStreetMap, an on-line map
resource that provides both types of informa-
tion mentioned above, in a unified data struc-
ture. The OpenStreetMap project is to maps what
Wikipedia is to encyclopedias: It is a map of
the entire world which can be edited by anyone
wishing to participate. New map data is usually
added by volunteers who measure streets using
GPS devices and annotate them via a Web inter-
face. The decentralized nature of the data entry
process means that when the world changes, the
map will be updated quickly. Existing map data
can be viewed as a zoomable map on the Open-
StreetMap website, or it can be downloaded in an
Figure 1: A graphical representation of some nodes
and ways in OpenStreetMap.
Landmark Type
Street Furniture stop sign
traffic lights
pedestrian crossing
Visual Landmarks church
certain video stores
certain supermarkets
gas station
pubs and bars
Figure 2: Landmarks used by the Virtual Co-Pilot.
XML format for offline use.
Geographical data in OpenStreetMap is repre-
sented in terms of nodes and ways. Nodes rep-
resent points in space, defined by their latitude
and longitude. Ways consist of sequences of
edges between adjacent nodes; we call the in-
dividual edges segments below. They are used
to represent streets (with curved streets consist-
ing of multiple straight segments approximating
their shape), but also a variety of other real-world
entities: buildings, rivers, trees, etc. Nodes and
ways can both be enriched with further infor-
mation by attaching tags. Tags encode a wide
range of additional information using a predefined
type ontology. Among other things, they specify
the types of buildings (church, cafe, supermarket,
etc.); where a shop or restaurant has a name, it too
is specified in a tag. Fig. 1 is a graphical represen-
tation of some OpenStreetMap data, consisting of
nodes and ways for two streets (with two and five
segments) and a building which has been tagged
as a gas station.
For the Virtual Co-Pilot system, we have cho-
sen a set of concrete landmark types that we con-
sider useful (Fig. 2). We operationalize the crite-
ria for good landmarks sketched in Section 2 by
requiring that a landmark should be easily visible,
and that it should be generic in that it is appli-
759
cable not just for one particular city, but for any
place for which OpenStreetMap data is available.
We end up with two classes of landmark types:
street furniture and visual landmarks. Street fur-
niture is a generic term for objects that are in-
stalled on streets. In this subset, we include stop
signs, traffic lights, and pedestrian crossings. Our
assumption is that these objects inherently pos-
sess a high salience, since they already require
particular attention from the driver. ?Visual land-
marks? encompass roadside buildings that are not
directly connected to the road infrastructure, but
draw the driver?s attention due to visual salience.
Churches are an obvious member of this group; in
addition, we include gas stations, pubs, and bars,
as well as certain supermarket and video store
chains (selected for wide distribution over differ-
ent cities and recognizable, colorful signs).
Given a certain location at which the Virtual
Co-Pilot is to be used, we automatically extract
suitable landmarks along with their types and lo-
cations from OpenStreetMap. We also gather
the road network information that is required
for route planning, and collect informations on
streets, such as their names, from the tags. We
then transform this information into a directed
street graph. The nodes of this graph are the
OpenStreetMap nodes that are part of streets; two
adjacent nodes are connected by a single directed
edge for segments of one-way streets and a di-
rected edge in each direction for ordinary street
segments. Each edge is weighted with the Eu-
clidean distance between the two nodes.
4 Generation of route directions
We will now describe how the Virtual Co-Pilot
generates route directions from OpenStreetMap
data. The system generates three types of mes-
sages (see Fig. 3). First, at every decision point,
i.e. at the intersection where a driving maneu-
ver such as turning left or right is required, the
user is told to turn immediately in the given di-
rection (?now turn right?). Second, if the driver
has followed an instruction correctly, we gener-
ate a confirmation message after the driver has
made the turn, letting them know they are still
on the right track. Finally, we generate preview
messages on the street leading up to the decision
point. These preview messages describe the loca-
tion of the next driving maneuver.
Of the three types, preview messages are the
Figure 3: Schematic representation of an episode
(dashed red line), with sample trigger positions of pre-
view, turn instruction, and confirmation messages.
most interesting. Our system avoids the genera-
tion of metric distance indicators, as in ?turn left
in 100 meters?. Instead, it tries to find landmarks
that describe the position of the decision point:
?Prepare to turn left after the church.? When no
landmark is available, the system tries to use street
intersections as secondary landmarks, as in ?Turn
right at the next/second/third intersection.? Metric
distances are only used when both of these strate-
gies fail.
In-car NLG takes place in a heavily real-time
setting, in which an utterance becomes uninter-
pretable or even misleading if it is given too late.
This problem is exacerbated for NLG of speech
because simply speaking the utterance takes time
as well. One consequence that our system ad-
dresses is the problem of planning preview mes-
sages in such a way that they can be spoken be-
fore the decision point without overlapping each
other. We handle this problem in the sentence
planner, which may aggregate utterances to fit
into the available time. A second problem is that
the user?s reactions to the generated utterances are
unpredictable; if the driver takes a wrong turn, the
system must generate updated instructions in real
time.
Below, we describe the individual components
of the system. We mostly follow a standard NLG
pipeline (Reiter and Dale, 2000), with a focus on
the sentence planner and an extension to interac-
tive real-time NLG.
760
Segment123
From: Node1
To: Node2
On: ?Main Street?
Segment124
From: Node2
To: Node3
On: ?Main Street?
Segment125
From: Node3
To: Node4
On: ?Park Street?
Segment126
From: Node4
To: Node5
On: ?Park Street?
Figure 4: A simple example of a route plan consisting
of four street segments.
4.1 Content determination and text planning
The first step in our system is to obtain a plan for
reaching the destination. To this end, we com-
pute a shortest path on the directed street graph
described in Section 3. The result is an ordered
list of street segments that need to be traversed in
the given order to successfully reach the destina-
tion; see Fig. 4 for an example.
To be suitable as the input for an NLG system,
this flat list of OpenStreetMap nodes needs to be
subdivided into smaller message chunks. In turn-
by-turn navigation, the general delimiter between
such chunks are the driving maneuvers that the
driver must execute at each decision point. We
call each span between two decision points an
episode. Episodes are not explicitly represented
in the original route plan: although every segment
has a street name associated with it, the name of
a street sometimes changes as we go along, and
because chains of segments are used to model
curved streets in OpenStreetMap, even segments
that are joined at an angle may be parts of the
same street. Thus, in Fig. 4 it is not apparent
which segment traversals require any navigational
maneuvers.
We identify episode boundaries with the fol-
lowing heuristic. We first assume that episode
boundaries occur when the street name changes
from one segment to the next. However, stay-
ing on the road may involve a driving maneu-
ver (and therefore a decision point) as well, e.g.
when the road makes a sharp turn where a minor
street forks off. To handle this case, we introduce
decision points at nodes with multiple adjacent
segments if the angle between the incoming and
outgoing segment of the street exceeds a certain
threshold. Conversely, our heuristic will some-
times end an episode where no driving maneuver
is necessary, e.g. when an ongoing street changes
its name. This is unproblematic in practice; the
system will simply generate an instruction to keep
driving straight ahead. Fig. 3 shows a graphical
representation of an episode, with the street seg-
ments belonging to it drawn as red dashed lines.
4.2 Aggregation
Because we generate spoken instructions that are
given to the user while they are driving, the timing
of the instructions becomes a crucial issue, espe-
cially because a driver moves faster than the user
of a pedestrian navigation system. It is undesir-
able for a second instruction to interrupt an ear-
lier one. On the other hand, the second instruc-
tion cannot be delayed because this might make
the user miss a turn or interpret the instruction in-
correctly.
We must therefore control at which points in-
structions are given and make sure that they do
not overlap. We do this by always presenting pre-
view messages at trigger positions at certain fixed
distances from the decision point. The sentence
planner calculates where these trigger positions
are located for each episode. In this way, we cre-
ate time frames during which there is enough time
for instructions to be presented.
However, some episodes are too short to ac-
commodate the three trigger positions for the con-
firmation message and the two preview messages.
In such episodes, we aggregate different mes-
sages. We remove the trigger positions for the two
preview messages from the episode, and instead
add the first preview message to the turn instruc-
tion message of the previous episode. This allows
our system to generate instructions like ?Now turn
right, and then turn left after the church.?
4.3 Generation of landmark descriptions
The Virtual Co-Pilot computes referring expres-
sions to decision points by selecting appropriate
landmarks. To this end, it first looks up landmark
candidates within a given range of the decision
point from the database created in Section 3. This
761
yields an initial list of landmark candidates.
Some of these landmark candidates may be un-
suitable for the given situation because of lack of
uniqueness. If there are several visual landmarks
of the same type along the course of an episode,
all of these landmark candidates are removed. For
episodes which contain multiple street furniture
landmarks of the same type, the first three in each
episode are retained; a referring expression for the
decision point might then be ?at the second traf-
fic light?. If the decision point is no more than
three intersections away, we also add a landmark
description of the form ?at the third intersection?.
Furthermore, a landmark must be visible from the
last segment of the current episode; we only retain
a candidate if it is either adjacent to a segment of
the current episode or if it is close to the end point
of the very last segment of the episode. Among
the landmarks that are left over, the system prefers
visual landmarks over street furniture, and street
furniture over intersections. If no landmark candi-
dates are left over, the system falls back to metric
distances.
Second, the Virtual Co-Pilot determines the
spatial relationship between the landmark and the
decision point so that an appropriate preposition
can be used in the referring expression. If the de-
cision point occurs before the landmark along the
course of the episode, we use the preposition ?in
front of?, otherwise, we use ?after?. Intersections
are always used with ?at? and metric distances
with ?in?.
Finally, the system decides how to refer to the
landmark objects themselves. Although it has ac-
cess to the names of all objects from the Open-
StreetMap data, the user may not know these
names. We therefore refer to churches, gas sta-
tions, and any street furniture simply as ?the
church?, ?the gas station?, etc. For supermar-
kets and bars, we assume that these buildings are
more saliently referred to by their names, which
are used in everyday language, and therefore use
the names to refer to them.
The result of the sentence planning stage is
a list of semantic representations, specifying the
individual instructions that are to be uttered in
each episode; an example is shown in Fig. 5.
For each type of instruction, we then use a sen-
tence template to generate linguistic surface forms
by inserting the information contained in those
plans into the slots provided by the templates (e.g.
Preview message p1:
Trigger position: Node3 ? 50m
Turn direction: right
Landmark: church
Preposition: after
Preview message p2 = p1, except:
Trigger position: Node3 ? 100m
Turn instruction t1:
Trigger position: Node3
Turn direction: right
Confirmation message c1:
Trigger position: Node3 + 50m
Figure 5: Semantic representations of the different
types of instructions in one episode.
?Turn direction preposition landmark?).
4.4 Interactive generation
As a final point, the NLG process of a car naviga-
tion system takes place in an interactive setting:
as the system generates and utters instructions, the
user may either follow them correctly, or they may
miss a turn or turn incorrectly because they mis-
understood the instruction or were forced to disre-
gard it by the traffic situation. The system must be
able to detect such problems, recover from them,
and generate new instructions in real time.
Our system receives a continuous stream of in-
formation about the position and direction of the
user. It performs execution monitoring to check
whether the user is still following the intended
route. If a trigger position is reached, we present
the instruction that we have generated for this po-
sition. If the user has left the route, the system
reacts by planning a new route starting from the
user?s current position and generating a new set of
instructions. We check whether the user is follow-
ing the intended route in the following way. The
system keeps track of the current episode of the
route plan, and monitors the distance of the car
to the final node of the episode. While the user
is following the route correctly, the distance be-
tween the car and the final node should decrease
or at least stay the same between two measure-
ments. To accommodate for occasional deviations
from the middle of the road, we allow five subse-
quent measurements to increase the distance; the
sixth increase of the distance triggers a recompu-
tation of the route plan and a freshly generated
instruction. On the other hand, when the distance
762
of the car to the final node falls below a certain
threshold, we assume that the end of the episode
has been reached, and activate the next episode.
By monitoring whether the user is now approach-
ing the final node of this new episode, we can in
particular detect wrong turns at intersections.
Because each instruction carries the risk that it
may not be followed correctly, there is a question
as to whether it is worth planning out all remain-
ing instructions for the complete route plan. After
all, if the user does not follow the first instruc-
tion, the computation of all remaining instructions
was a waste of time. We decided to compute all
future instructions anyway because the aggrega-
tion procedure described above requires them. In
practice, the NLG process is so efficient that all
instructions can be done in real time, but this de-
cision would have to be revisited for a slower sys-
tem.
5 Evaluation
We will now report on an experiment in which we
evaluated the performance of the Virtual Co-Pilot.
5.1 Experimental Method
5.1.1 Subjects
In total, 12 participants were recruited through
printed ads and mailing lists. All of them were
university students aged between 21 and 27 years.
Our experiment was balanced for gender, hence
we recruited 6 male and 6 female participants. All
participants were compensated for their effort.
5.1.2 Design
The driving simulator used in the experiment
replicates a real-world city center using a 3D
model that contains buildings and streets as they
can be perceived in reality. The street layout 3D
model used by the driving simulator is based on
OpenStreetMap data, and buildings were added to
the virtual environment based on cadastral data.
To increase the perceived realism of the model,
some buildings were manually enhanced with
photographic images of their real-world counter-
parts (see Fig. 7).
Figure 6 shows the set-up of the evaluation ex-
periment. The virtual driving simulator environ-
ment (main picture in Fig. 7) was presented to the
participants on a 20? computer screen (A). In ad-
dition, graphical navigation instructions (shown
in the lower right of Fig. 7) were displayed on
Figure 6: Experiment setup. A) Main screen B) Navi-
gation screen C) steering wheel D) eye tracker
a separate 7? monitor (B). The driving simula-
tor was controlled by means of a steering wheel
(C), along with a pair of brake and acceleration
pedals. We recorded user eye movements using
a Tobii IS-Z1 table-mounted eye tracker (D). The
generated instructions were converted to speech
using MARY, an open-source text-to-speech sys-
tem (Schro?der and Trouvain, 2003), and played
back on loudspeakers.
The task of the user was to drive the car in
the virtual environment towards a given destina-
tion; spoken instructions were presented to them
as they were driving, in real time. Using the
steering wheel and the pedals, users had full con-
trol over steering angles, acceleration and brak-
ing. The driving speed was limited to 30 km/h, but
there were no restrictions otherwise. The driving
simulator sent the NLG system a message with the
current position of the car (as GPS coordinates)
once per second.
Each user was asked to drive three short routes
in the driving simulator. Each route took about
four minutes to complete, and the travelled dis-
tance was about 1 km. The number of episodes
per route ranged from three to five. Landmark
candidates were sufficiently dense that the Virtual
Co-Pilot used landmarks to refer to all decision
points and never had to fall back to the metric dis-
tance strategy.
There were three experimental conditions,
which differed with respect to the spoken route
instructions and the use of the navigation screen.
In the baseline condition, designed to replicate the
behavior of an off-the-shelf commercial car nav-
763
All Users Males Females
B VCP B VCP B VCP
Total Fixation Duration (seconds) 4.9 3.5 2.7 4.1 7.0 2.9*
Total Fixation Count (N) 21.8 15.4 13.5 16.5 30.0 14.3*
?The system provided the right amount
of information at any time?
3.9 2.9 4.2* 3.3 3.5 2.5
?I was insecure at times about still be-
ing on the right track.?
2.3 3.2 1.9* 2.8 2.6 3.5
?It was important to have a visual rep-
resentation of route directions?
4.3 4.0 4.2 4.2 4.3 3.7
?I could trust the navigation system? 3.6 3.7 4.1 3.7 3.0 3.7
Figure 8: Mean values for gaze behavior and subjective evaluation, separated by user group and condition (B =
baseline, VCP = our system). Significant differences are indicated by *; better values are printed in boldface.
Figure 7: Screenshot of a scene in the driving simula-
tor. Lower right corner: matching screenshot of navi-
gation display.
igation system, participants were provided with
spoken metric distance-to-turn navigation instruc-
tions. The navigation screen showed arrows de-
picting the direction of the next turn, along with
the distance to the decision point (cf. Fig. 7). The
second condition replaced the spoken route in-
structions by those generated by the Virtual Co-
Pilot. In a third condition, the output of the nav-
igation screen was further changed to display an
icon for the next landmark along with the arrow
and distance indicator. The three routes were pre-
sented to the users in different orders, and com-
bined with the conditions in a Latin Squares de-
sign. In this paper, we focus on the first and sec-
ond condition, in order to contrast the two styles
of spoken instruction.
Participants were asked to answer two ques-
tionnaires after each trial run. The first was the
DALI questionnaire (Pauzie?, 2008), which asks
subjects to report how they perceived different
aspects of their cognitive workload (general, vi-
sual, auditive and temporal workload, as well as
perceived stress level). In the second question-
naire, participants were state to rate their agree-
ment with a number of statements about their sub-
jective impression of the system on a 5-point un-
labelled Likert scale, e.g. whether they had re-
ceived instructions at the right time or whether
they trusted the navigation system to give them
the right instructions during trials.
5.2 Results
There were no significant differences between the
Virtual Co-Pilot and the baseline system on task
completion time, rate of driving errors, or any of
the questions of the DALI questionnaire. Driv-
ing errors in particular were very rare: there were
only four driving errors in total, two of which
were due to problems with left/right coordination.
We then analyzed the gaze data collected by the
table-mounted eye tracker, which we set up such
that it recognized glances at the navigation screen.
In particular, we looked at the total fixation dura-
tion (TFD), i.e. the total amount of time that a user
spent looking at the navigation screen during a
given trial run. We also looked at the total fixation
count (TFC), i.e. the total number of times that a
user looked at the navigation screen in each run.
Mean values for both metrics are given in Fig. 8,
averaged over all subjects and only male and fe-
male subjects, respectively; the ?VCP? column is
for the Virtual Co-Pilot, whereas ?B? stands for
the baseline. We found that male users tended
to look more at the navigation screen in the VCP
condition than in B, although the difference is not
statistically significant. However, female users
looked at the navigation screen significantly fewer
764
times (t(5) = 3.2, p < 0.05, t-test for dependent
samples) and for significantly shorter amounts of
time (t(5) = 3.2, p < 0.05) in the VCP condition
than in B.
On the subjective questionnaire, most questions
yielded no significant differences (and are not re-
ported here). However, we found that female
users tended to rate the Virtual Co-Pilot more pos-
itively than the baseline on questions concerning
trust in the system and the need for the navigation
screen (but not significantly). Male users found
that the baseline significantly outperformed the
Virtual Co-Pilot on presenting instructions at the
right time (t(5) = 2.7, p < 0.05) and on giving
them a sense of security in still being on the right
track (t(5) = ?2.7, p < 0.05).
5.3 Discussion
The most striking result of the evaluation is that
there was a significant reduction of looks to the
navigation display, even if only for one group
of users. Female users looked at the navigation
screen less and more rarely with the Virtual Co-
Pilot compared to the baseline system. In a real
car navigation system, this translates into a driver
who spends less time looking away from the road,
i.e. a reduction in driver distraction and an in-
crease in traffic safety. This suggests that female
users learned to trust the landmark-based instruc-
tions, an interpretation that is further supported
by the trends we found in the subjective question-
naire.
We did not find these differences in the male
user group. Part of the reason may be the known
gender differences in landmark use we mentioned
in Section 2. But interestingly, the two signifi-
cantly worse ratings by male users concerned the
correct timing of instructions and the feedback for
driving errors, i.e. issues regarding the system?s
real-time capabilities. Although our system does
not yet perform ideally on these measures, this
confirms our initial hypothesis that the NLG sys-
tem must track the user?s behavior and schedule
its utterances appropriately. This means that ear-
lier systems such as CORAL, which only com-
pute a one-shot discourse of route instructions
without regard to the timing of the presentation,
miss a crucial part of the problem.
Apart from the exceptions we just discussed,
the landmark-based system tended to score com-
parably or a bit worse than the baseline on the
other subjective questions. This may partly be due
to the fact that the subjects were familiar with ex-
isting commercial car navigation systems and not
used to landmark-based instructions. On the other
hand, this finding is also consistent with results
of other evaluations of NLG systems, in which
an improvement in the objective task usefulness
of the system does not necessarily correlate with
improved scores from subjective questionnaires
(Gatt et al 2009).
6 Conclusion
In this paper, we have described a system for gen-
erating real-time car navigation instructions with
landmarks. Our system is distinguished from ear-
lier work in its reliance on open-source map data
from OpenStreetMap, from which we extract both
the street graph and the potential landmarks. This
demonstrates that open resources are now infor-
mative enough for use in wide-coverage naviga-
tion NLG systems. The system then chooses ap-
propriate landmarks at decision points, and con-
tinuously monitors the driver?s behavior to pro-
vide modified instructions in real time when driv-
ing errors occur.
We evaluated our system using a driving simu-
lator with respect to driving errors, user satisfac-
tion, and driver distraction. To our knowledge,
we have shown for the first time that a landmark-
based car navigation system outperforms a base-
line significantly; namely, in the amount of time
female users spend looking away from the road.
In many ways, the Virtual Co-Pilot is a very
simple system, which we see primarily as a start-
ing point for future research. The evaluation
confirmed the importance of interactive real-time
NLG for navigation, and we therefore see this as
a key direction of future work. On the other hand,
it would be desirable to generate more complex
referring expressions (?the tall church?). This
would require more informative map data, as well
as a formal model of visual salience (Kelleher and
van Genabith, 2004; Raubal and Winter, 2002).
Acknowledgments. We would like to thank the
DFKI CARMINA group for providing the driv-
ing simulator, as well as their support. We would
furthermore like to thank the DFKI Agents and
Simulated Reality group for providing the 3D city
model.
765
References
G. L. Allen. 2000. Principles and practices for com-
municating route knowledge. Applied Cognitive
Psychology, 14(4):333?359.
C. Brenner and B. Elias. 2003. Extracting land-
marks for car navigation systems using existing
gis databases and laser scanning. International
archives of photogrammetry remote sensing and
spatial information sciences, 34(3/W8):131?138.
G. Burnett. 2000. ?Turn right at the Traffic Lights?:
The Requirement for Landmarks in Vehicle Nav-
igation Systems. The Journal of Navigation,
53(03):499?510.
R. Dale, S. Geldof, and J. P. Prost. 2003. Using natural
language generation for navigational assistance. In
ACSC, pages 35?44.
B. Elias. 2003. Extracting landmarks with data min-
ing methods. Spatial information theory, pages
375?389.
A. Gatt, F. Portet, E. Reiter, J. Hunter, S. Mahamood,
W. Moncur, and S. Sripada. 2009. From data to text
in the neonatal intensive care unit: Using NLG tech-
nology for decision support and information man-
agement. AI Communications, 22:153?186.
S. Kaplan. 1976. Adaption, structure and knowledge.
In G. Moore and R. Golledge, editors, Environmen-
tal knowing: Theories, research and methods, pages
32?45. Dowden, Hutchinson and Ross.
J. D. Kelleher and J. van Genabith. 2004. Visual
salience and reference resolution in simulated 3-D
environments. Artificial Intelligence Review, 21(3).
A. Koller, K. Striegnitz, D. Byron, J. Cassell, R. Dale,
J. Moore, and J. Oberlander. 2010. The First Chal-
lenge on Generating Instructions in Virtual Environ-
ments. In E. Krahmer and M. Theune, editors, Em-
pirical Methods in Natural Language Generation.
Springer.
N. Lessmann, S. Kopp, and I. Wachsmuth. 2006. Sit-
uated interaction with a virtual human ? percep-
tion, action, and cognition. In G. Rickheit and
I. Wachsmuth, editors, Situated Communication,
pages 287?323. Mouton de Gruyter.
K. Lovelace, M. Hegarty, and D. Montello. 1999. El-
ements of good route directions in familiar and un-
familiar environments. Spatial information theory.
Cognitive and computational foundations of geo-
graphic information science, pages 751?751.
K. Lynch. 1960. The image of the city. MIT Press.
R. Malaka and A. Zipf. 2000. DEEP MAP ? Chal-
lenging IT research in the framework of a tourist in-
formation system. Information and communication
technologies in tourism, 7:15?27.
R. Malaka, J. Haeussler, and H. Aras. 2004.
SmartKom mobile: intelligent ubiquitous user in-
teraction. In Proceedings of the 9th International
Conference on Intelligent User Interfaces.
A. J. May and T. Ross. 2006. Presence and quality
of navigational landmarks: effect on driver perfor-
mance and implications for design. Human Fac-
tors: The Journal of the Human Factors and Er-
gonomics Society, 48(2):346.
P. E. Michon and M. Denis. 2001. When and why are
visual landmarks used in giving directions? Spatial
information theory, pages 292?305.
A. Pauzie?. 2008. Evaluating driver mental workload
using the driving activity load index (DALI). In
Proc. of European Conference on Human Interface
Design for Intelligent Transport Systems, pages 67?
77.
M. Raubal and S. Winter. 2002. Enriching wayfind-
ing instructions with local landmarks. Geographic
information science, pages 243?259.
E. Reiter and R. Dale. 2000. Building natural lan-
guage generation systems. Studies in natural lan-
guage processing. Cambridge University Press.
D. M. Saucier, S. M. Green, J. Leason, A. MacFadden,
S. Bell, and L. J. Elias. 2002. Are sex differences in
navigation caused by sexually dimorphic strategies
or by differences in the ability to use the strategies?.
Behavioral Neuroscience, 116(3):403.
M. Schro?der and J. Trouvain. 2003. The German
text-to-speech synthesis system MARY: A tool for
research, development and teaching. International
Journal of Speech Technology, 6(4):365?377.
K. Striegnitz and F. Majda. 2009. Landmarks in
navigation instructions for a virtual environment.
Online Proceedings of the First NLG Challenge
on Generating Instructions in Virtual Environments
(GIVE-1).
J. C. Stutts, D. W. Reinfurt, L. Staplin, and E. A. Rodg-
man. 2001. The role of driver distraction in traf-
fic crashes. Washington, DC: AAA Foundation for
Traffic Safety.
A. Tom and M. Denis. 2003. Referring to landmark
or street information in route directions: What dif-
ference does it make? Spatial information theory,
pages 362?374.
766
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 30?39,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Computing weakest readings
Alexander Koller
Cluster of Excellence
Saarland University
koller@mmci.uni-saarland.de
Stefan Thater
Dept. of Computational Linguistics
Saarland University
stth@coli.uni-saarland.de
Abstract
We present an efficient algorithm for com-
puting the weakest readings of semantically
ambiguous sentences. A corpus-based eval-
uation with a large-scale grammar shows
that our algorithm reduces over 80% of sen-
tences to one or two readings, in negligible
runtime, and thus makes it possible to work
with semantic representations derived by
deep large-scale grammars.
1 Introduction
Over the past few years, there has been consid-
erable progress in the ability of manually created
large-scale grammars, such as the English Resource
Grammar (ERG, Copestake and Flickinger (2000))
or the ParGram grammars (Butt et al, 2002), to
parse wide-coverage text and assign it deep seman-
tic representations. While applications should ben-
efit from these very precise semantic representa-
tions, their usefulness is limited by the presence
of semantic ambiguity: On the Rondane Treebank
(Oepen et al, 2002), the ERG computes an aver-
age of several million semantic representations for
each sentence, even when the syntactic analysis is
fixed. The problem of appropriately selecting one
of them to work with would ideally be solved by
statistical methods (Higgins and Sadock, 2003) or
knowledge-based inferences. However, no such
approach has been worked out in sufficient detail to
support the disambiguation of treebank sentences.
As an alternative, Bos (2008) proposes to com-
pute the weakest reading of each sentence and then
use it instead of the ?true? reading of the sentence.
This is based on the observation that the readings
of a semantically ambiguous sentence are partially
ordered with respect to logical entailment, and the
weakest readings ? the minimal (least informative)
readings with respect to this order ? only express
?safe? information that is common to all other read-
ings as well. However, when a sentence has mil-
lions of readings, finding the weakest reading is a
hard problem. It is of course completely infeasible
to compute all readings and compare all pairs for
entailment; but even the best known algorithm in
the literature (Gabsdil and Striegnitz, 1999) is only
an optimization of this basic strategy, and would
take months to compute the weakest readings for
the sentences in the Rondane Treebank.
In this paper, we propose a new, efficient ap-
proach to the problem of computing weakest read-
ings. We follow an underspecification approach
to managing ambiguity: Rather than deriving all
semantic representations from the syntactic analy-
sis, we work with a single, compact underspecified
semantic representation, from which the semantic
representations can then be extracted by need. We
then approximate entailment with a rewrite sys-
tem that rewrites readings into logically weaker
readings; the weakest readings are exactly those
readings that cannot be rewritten into some other
reading any more (the relative normal forms). We
present an algorithm that computes the relative nor-
mal forms, and evaluate it on the underspecified de-
scriptions that the ERG derives on a 624-sentence
subcorpus of the Rondane Treebank. While the
mean number of scope readings in the subcorpus
is in the millions, our system computes on average
4.5 weakest readings for each sentence, in less than
twenty milliseconds; over 80% of all sentences are
reduced to at most two weakest readings. In other
words, we make it feasible for the first time to build
an application that uses the individual (weakest)
semantic representations computed by the ERG,
both in terms of the remaining ambiguity and in
terms of performance. Our technique is not lim-
ited to the ERG, but should be applicable to other
underspecification-based grammars as well.
Technically, we use underspecified descriptions
that are regular tree grammars derived from dom-
inance graphs (Althaus et al, 2003; Koller et al,
30
2008). We compute the weakest readings by in-
tersecting these grammars with other grammars
representing the rewrite rules. This approach can
be used much more generally than just for the com-
putation of weakest readings; we illustrate this by
showing how a more general version of the redun-
dancy elimination algorithm by Koller et al (2008)
can be seen as a special case of our construction.
Thus our system can serve as a general framework
for removing unintended readings from an under-
specified representation.
The paper is structured as follows. Section 2
starts by reviewing related work. We recall domi-
nance graphs, regular tree grammars, and the basic
ideas of underspecification in Section 3, before we
show how to compute weakest readings (Section 4)
and logical equivalences (Section 5). In Section 6,
we define a weakening rewrite system for the ERG
and evaluate it on the Rondane Treebank. Section 7
concludes and points to future work.
2 Related work
The idea of deriving a single approximative seman-
tic representation for ambiguous sentences goes
back to Hobbs (1983); however, Hobbs only works
his algorithm out for a restricted class of quantifiers,
and his representations can be weaker than our
weakest readings. Rules that weaken one reading
into another were popular in the 1990s underspeci-
fication literature (Reyle, 1995; Monz and de Rijke,
2001; van Deemter, 1996) because they simplify
logical reasoning with underspecified representa-
tions. From a linguistic perspective, Kempson and
Cormack (1981) even go so far as to claim that
the weakest reading should be taken as the ?basic?
reading of a sentence, and the other readings only
seen as pragmatically licensed special cases.
The work presented here is related to other ap-
proaches that reduce the set of readings of an un-
derspecified semantic representation (USR). Koller
and Niehren (2000) showed how to strengthen
a dominance constraint using information about
anaphoric accessibility; later, Koller et al (2008)
presented and evaluated an algorithm for redun-
dancy elimination, which removes readings from
an USR based on logical equivalence. Our system
generalizes the latter approach and applies it to a
new inference problem (weakest readings) which
they could not solve.
This paper builds closely upon Koller and Thater
(2010), which lays the formal groundwork for the
?
x
sample
y
see
x,y
?
y
repr-of
x,z
?
z
comp
z
24 3
5 6 7
8
?
1
Figure 1: A dominance graph describing the five
readings of the sentence ?it is not the case that
every representative of a company saw a sample.?
work presented here. Here we go beyond that paper
by applying a concrete implementation of our RTG
construction for weakest readings to a real-world
grammar, evaluating the system on practical inputs,
and combining weakest readings with redundancy
elimination.
3 Underspecification
This section briefly reviews two formalisms for
specifying sets of trees: dominance graphs and
regular tree grammars. Both of these formalisms
can be used to model scope ambiguities compactly
by regarding the semantic representations of a sen-
tence as trees. Some example trees are shown in
Fig. 2. These trees can be read as simplified for-
mulas of predicate logic, or as formulas involv-
ing generalized quantifiers (Barwise and Cooper,
1981). Formally, we assume a ranked signature
? of tree constructors { f ,g,a, . . .}, each of which
is equipped with an arity ar( f ) ? 0. We take a
(finite constructor) tree t as a finite tree in which
each node is labelled with a symbol of ?, and the
number of children of the node is exactly the arity
of this symbol. For instance, the signature of the
trees in Fig. 1 is {?x|2,?y|2,compz|0, . . .}. Finite
constructor trees can be seen as ground terms over
? that respect the arities. We write T (?) for the
finite constructor trees over ?.
3.1 Dominance graphs
A (labelled) dominance graph D (Althaus et al,
2003) is a directed graph that consists of a col-
lection of trees called fragments, plus dominance
edges relating nodes in different fragments. We dis-
tinguish the roots WD of the fragments from their
holes, which are the unlabelled leaves. We write
LD : WD? ? for the labeling function of D.
The basic idea behind using dominance graphs
to model scope underspecification is to specify
31
(a) (b)
?
y
?
x
repr-of
x,z
comp
z
sample
y
see
x,y
?
repr-of
x,z
comp
z
see
x,y
sample
y
?
z
?
?
y
?
x
?
z
[+]
[-]
[-] [-]
[-] [-]
[-]
[-]
[+]
[+]
[-]
[-]
[-]
[+]
[+] [+]
(c)
comp
z
repr-of
x,z
see
x,y
sample
y
?
?
y
?
x
?
z
[+]
[-]
[-]
[-]
[-]
[-]
[-]
[+]
(e)
sample
y
see
x,y
repr-of
x,z
comp
z
?
?
y
?
x
?
z
[+]
[-]
[+]
[-]
[-][-][+][+]
(d)
comp
z
repr-of
x,z 
see
x,y 
sample
y
?
?
y
?
x
?
z
[+]
[-]
[-]
[-]
[-]
[-]
[-]
[+]
Figure 2: The five configurations of the dominance graph in Fig. 1.
the ?semantic material? common to all readings
as fragments, plus dominance relations between
these fragments. An example dominance graph
D is shown in Fig. 1. It represents the five read-
ings of the sentence ?it is not the case that every
representative of a company saw a sample.?
Each reading is encoded as a (labeled) configura-
tion of the dominance graph, which can be obtained
by ?plugging? the tree fragments into each other,
in a way that respects the dominance edges: The
source node of each dominance edge must dom-
inate (be an ancestor of) the target node in each
configuration. The trees in Fig. 2 are the five la-
beled configurations of the example graph.
3.2 Regular tree grammars
Regular tree grammars (RTGs) are a general gram-
mar formalism for describing languages of trees
(Comon et al, 2007). An RTG is a 4-tuple G =
(S,N,?,P), where N and ? are nonterminal and ter-
minal alphabets, S ? N is the start symbol, and
P is a finite set of production rules. Unlike in
context-free string grammars (which look super-
ficially the same), the terminal symbols are tree
constructors from ?. The production rules are of
the form A? t, where A is a nonterminal and t is a
tree from T (??N); nonterminals count as having
arity zero, i.e. they must label leaves. A derivation
starts with a tree containing a single node labeled
with S. Then in each step of the derivation, some
leaf u which is labelled with a nonterminal A is
expanded with a rule A? t; this results in a new
tree in which u has been replaced by t, and the
derivation proceeds with this new tree. The lan-
guage L(G) generated by the grammar is the set of
all trees in T (?) that can be derived in this way.
Fig. 3 shows an RTG as an example. This gram-
mar uses sets of root names from D as nonterminal
symbols, and generates exactly the five configura-
tions of the graph in Fig. 1.
The languages that can be accepted by regular
tree grammars are called regular tree languages
{1,2,3,4,5,6,7,8}? ?({2,3,4,5,6,7,8})
{2,3,4,5,6,7,8}? ?x({4,5,6},{3,7,8})
{2,3,4,5,6,7,8}? ?y({7},{2,4,5,6,8})
{2,3,4,5,6,7,8}? ?z({5},{2,3,6,7,8})
{2,4,5,6,8}? ?x({4,5,6},{8})
| ?z({5},{2,6,8})
{2,3,6,7,8}? ?x({6},{3,7,8})
| ?y({7},{2,6,8})
{2,6,8}? ?x({6},{8})
{3,7,8}? ?y({7},{8})
{4,5,6}? ?z({5},{6})
{5}? compz {7}? sampley
{6}? repr-ofx,z {8}? seex,y
Figure 3: A regular tree grammar that generates
the five trees in Fig. 2.
(RTLs), and regular tree grammars are equivalent
to finite tree automata, which are defined essen-
tially like the well-known finite string automata,
except that they assign states to the nodes in a tree
rather than the positions in a string. Regular tree
languages enjoy many of the closure properties of
regular string languages. In particular, we will later
exploit that RTLs are closed under intersection and
complement.
3.3 Dominance graphs as RTGs
An important class of dominance graphs are hy-
pernormally connected (hnc) dominance graphs
(Koller et al, 2003). The precise definition of hnc
graphs is not important here, but note that virtually
all underspecified descriptions that are produced
by current grammars are hypernormally connected
(Flickinger et al, 2005), and we will restrict our-
selves to hnc graphs for the rest of the paper.
Every hypernormally connected dominance
graph D can be automatically translated into an
equivalent RTG GD that generates exactly the same
configurations (Koller et al, 2008); the RTG in
Fig. 3 is an example. The nonterminals of GD are
32
always hnc subgraphs of D. In the worst case, GD
can be exponentially bigger than D, but in practice
it turns out that the grammar size remains manage-
able: even the RTG for the most ambiguous sen-
tence in the Rondane Treebank, which has about
4.5? 1012 scope readings, has only about 75 000
rules and can be computed in a few seconds.
4 Computing weakest readings
Now we are ready to talk about computing the
weakest readings of a hypernormally connected
dominance graph. We will first explain how we ap-
proximate logical weakening with rewrite systems.
We will then discuss how weakest readings can be
computed efficiently as the relative normal forms
of these rewrite systems.
4.1 Weakening rewrite systems
The different readings of a sentence with a scope
ambiguity are not a random collection of formulas;
they are partially ordered with respect to logical
entailment, and are structurally related in a way
that allows us to model this entailment relation
with simpler technical means.
To illustrate this, consider the five configurations
in Fig. 2. The formula represented by (d) logically
entails (c); we say that (c) is a weaker reading than
(d) because it is satisfied by more models. Similar
entailment relations hold between (d) and (e), (e)
and (b), and so on (see also Fig. 5). We can define
the weakest readings of the dominance graph as
the minimal elements of the entailment order; in
the example, these are (b) and (c). Weakest read-
ings capture ?safe? information in that whichever
reading of the sentence the speaker had in mind,
any model of this reading also satisfies at least one
weakest reading; in the absence of convincing dis-
ambiguation methods, they can therefore serve as
a practical approximation of the intended meaning
of the sentence.
A naive algorithm for computing weakest read-
ings would explicitly compute the entailment order,
by running a theorem prover on each pair of config-
urations, and then pick out the minimal elements.
But this algorithm is quadratic in the number of
configurations, and therefore impractically slow
for real-life sentences.
Here we develop a fast algorithm for this prob-
lem. The fundamental insight we exploit is that
entailment among the configurations of a domi-
nance graph can be approximated with rewriting
rules (Baader and Nipkow, 1999). Consider the re-
lation between (d) and (c). We can explain that (d)
entails (c) by observing that (c) can be built from
(d) by exchanging the positions of the adjacent
quantifiers ?x and ?y; more precisely, by applying
the following rewrite rule:
[?] ?x(Q,?y(P,R))??y(P,?x(Q,R)) (1)
The body of the rule specifies that an occurrence of
?x which is the direct parent of an occurrence of ?y
may change positions with it; the subformulas P,
Q, and R must be copied appropriately. The annota-
tion [?] specifies that we must only apply the rule
to subformulas in negative logical polarity: If the
quantifiers in (d) were not in the scope of a nega-
tion, then applying the rule would actually make
the formula stronger. We say that the rule (1) is
logically sound because applying it to a subformula
with the correct polarity of some configuration t
always makes the result t ? logically weaker than t.
We formalize these rewrite systems as follows.
We assume a finite annotation alphabet Ann with a
special starting annotation a0 ? Ann; in the exam-
ple, we had Ann = {+,?} and a0 = +. We also
assume an annotator function ann : Ann???N?
Ann. The function ann can be used to traverse a
tree top-down and compute the annotation of each
node from the annotation of its parent: Its first
argument is the annotation and its second argu-
ment the node label of the parent, and the third
argument is the position of the child among the par-
ent?s children. In our example, the annotator ann
models logical polarity by mapping, for instance,
ann(+,?z,1)= ann(+,?z,2)= ann(+,?y,2)=+,
ann(?,?z,1)= ann(?,?z,2)= ann(+,?x,1)=?,
etc. We have labelled each node of the configura-
tions in Fig. 1 with the annotations that are com-
puted in this way.
Now we can define an annotated rewrite system
R to be a finite set of pairs (a,r) where a is an anno-
tation and r is an ordinary rewrite rule. The rule (1)
above is an example of an annotated rewrite rule
with a =?. A rewrite rule (a,r) can be applied at
the node u of a tree t if ann assigns the annotation a
to u and r is applicable at u as usual. The rule then
rewrites t as described above. In other words, an-
notated rewrite systems are rewrite systems where
rule applications are restricted to subtrees with spe-
cific annotations. We write t?R t ? if some rule of
R can be applied at a node of t, and the result of
rewriting is t ?. The rewrite system R is called linear
33
if every variable that occurs on the left-hand side
of a rule occurs on its right-hand side exactly once.
4.2 Relative normal forms
The rewrite steps of a sound weakening rewrite sys-
tem are related to the entailment order: Because ev-
ery rewrite step transforms a reading into a weaker
reading, an actual weakest readings must be such
that there is no other configuration into which it
can be rewritten. The converse is not always true,
i.e. there can be non-rewritable configurations that
are not weakest readings, but we will see in Sec-
tion 6 that this approximation is good enough for
practical use. So one way to solve the problem of
computing weakest readings is to find readings that
cannot be rewritten further.
One class of configurations that ?cannot be
rewritten? with a rewrite system R is the set of nor-
mal forms of R, i.e. those configurations to which
no rule in R can be applied. In our example, (b)
and (c) are indeed normal forms with respect to
a rewrite system that consists only of the rule (1).
However, this is not exactly what we need here.
Consider a rewrite system that also contains the fol-
lowing annotated rewrite rule, which is also sound
for logical entailment:
[+] ?(?z(P,Q))??z(P,?(Q)), (2)
This rule would allow us to rewrite
the configuration (c) into the tree
?z(compz,?(?y(sampley,?x(repr?ofx,z,seex,y)))).
But this is no longer a configuration of the graph.
If we were to equate weakest readings with normal
forms, we would erroneously classify (c) as not
being a weakest reading. The correct concept
for characterizing weakest readings in terms of
rewriting is that of a relative normal form. We
define a configuration t of a dominance graph D to
be a R-relative normal form of (the configurations
of) D iff there is no other configuration t ? of D such
that t?R t ?. These are the configurations that can?t
be weakened further without obtaining a tree that
is no longer a configuration of D. In other words,
if R approximates entailment, then the R-relative
normal forms approximate the weakest readings.
4.3 Computing relative normal forms
We now show how the relative normal forms of a
dominance graph can be computed efficiently. For
lack of space, we only sketch the construction and
omit all proofs. Details can be found in Koller and
Thater (2010).
The key idea of the construction is to repre-
sent the relation ?R in terms of a context tree
transducer M, and characterize the relative nor-
mal forms of a tree language L in terms of the
pre-image of L under M. Like ordinary regular
tree transducers (Comon et al, 2007), context tree
transducers read an input tree, assigning states to
the nodes, while emitting an output tree. But while
ordinary transducers read the input tree symbol by
symbol, a context tree transducer can read multiple
symbols at once. In this way, they are equivalent to
the extended left-hand side transducers of Graehl
et al (2008).
We will now define context tree transducers. Let
? be a ranked signature, and let Xm be a set of m
variables. We write Con(m)(?) for the contexts with
m holes, i.e. those trees in T (??Xm) in which each
element of Xm occurs exactly once, and always
as a leaf. If C ? Con(m)(?), then C[t1, . . . , tm] =
C[t1/x1, . . . , tm/xm], where x1, . . . ,xm are the vari-
ables from left to right.
A (top-down) context tree transducer from ? to ?
is a 5-tuple M =(Q,?,?,q0,? ). ? and ? are ranked
signatures, Q is a finite set of states, and q0 ? Q is
the start state. ? is a finite set of transition rules of
the form q(C[x1, . . . ,xn])?D[q1(xi1), . . . ,qm(xim)],
where C ? Con(n)(?) and D ? Con(m)(?).
If t ? T (????Q), then we say that M derives
t ? in one step from t, t ?M t ?, if t is of the form
C?[q(C[t1, . . . , tn])] for some C? ? Con(1)(?), t ? is
of the form C?[D[q1(ti1), . . . ,qm(tim)]], and there is
a rule q(C[x1, . . . ,xn])? D[q1(xi1), . . . ,qm(xim)] in
? . The derivation relation ??M is the reflexive,
transitive closure of?M. The translation relation
?M of M is
?M = {(t, t ?) | t ?T (?) and t ? ?T (?) and q0(t)?? t ?}.
For each linear annotated rewrite system R, we
can now build a context tree transducer MR such
that t ?R t ? iff (t, t ?) ? ?MR . The idea is that MR
traverses t from the root to the leaves, keeping
track of the current annotation in its state. MR
can nondeterministically choose to either copy the
current symbol to the output tree unchanged, or to
apply a rewrite rule from R. The rules are built in
such a way that in each run, exactly one rewrite
rule must be applied.
We achieve this as follows. MR takes as its
states the set {q?}?{qa | a ? Ann} and as its start
state the state qa0 . If MR reads a node u in state
qa, this means that the annotator assigns annota-
tion a to u and MR will rewrite a subtree at or
34
below u. If MR reads u in state q?, this means
that MR will copy the subtree below u unchanged
because the rewriting has taken place elsewhere.
Thus MR has three types of rewrite rules. First,
for any f ? ?, we have a rule q?( f (x1, . . . ,xn))?
f (q?(x1), . . . , q?(xn)). Second, for any f and
1 ? i ? n, we have a rule qa( f (x1, . . . ,xn)) ?
f (q?(x1), . . . ,qann(a, f ,i)(xi), . . . , q?(xn)), which non-
deterministically chooses under which child the
rewriting should take place, and assigns it the
correct annotation. Finally, we have a rule
qa(C[x1, . . . ,xn])? C?[q?(xi1), . . . , q?(xin)] for every
rewrite rule C[x1, . . . ,xn]?C?[xi1 , . . . ,xin ] with an-
notation a in R.
Now let?s put the different parts together. We
know that for each hnc dominance graph D, there is
a regular tree grammar GD such that L(GD) is the
set of configurations of D. Furthermore, the pre-
image ??1M (L) = {t | exists t ? ? L with (t, t ?) ? ?M}
of a regular tree language L is also regular (Koller
and Thater, 2010) if M is linear, and regular tree
languages are closed under intersection and com-
plement (Comon et al, 2007). So we can compute
another RTG G? such that
L(G?) = L(GD)? ??1MR (L(GD)).
L(G?) consists of the members of L(GD) which
cannot be rewritten by MR into members of L(GD);
that is, L(G?) is exactly the set of R-relative normal
forms of D. In general, the complement construc-
tion requires exponential time in the size of MR and
GD. However, it can be shown that if the rules in
R have at most depth two and GD is deterministic,
then the entire above construction can be computed
in time O(|GD| ? |R|) (Koller and Thater, 2010).
In other words, we have shown how to compute
the weakest readings of a hypernormally connected
dominance graph D, as approximated by a weaken-
ing rewrite system R, in time linear in the size of
GD and linear in the size of R. This is a dramatic im-
provement over the best previous algorithm, which
was quadratic in |conf(D)|.
4.4 An example
Consider an annotated rewrite system that contains
rule (1) plus the following rewrite rule:
[?] ?z(P,?x(Q,R))??x(?z(P,Q),R) (3)
This rewrite system translates into a top-down
context tree transducer MR with the following tran-
sition rules, omitting most rules of the first two
{1,2,3,4,5,6,7,8}F ??({2,3,4,5,6,7,8}F )
{2,3,4,5,6,7,8}F ??y({7}{q?},{2,4,5,6,8}F )
| ?z({5}{q?},{2,3,6,7,8}F )
{2,3,6,7,8}F ??y({7}{q?},?x({6}{q?},{8}{q?}))
{2,4,5,6,8}F ??x({4,5,6}{q?},{8}{q?})
{4,5,6}{q?}??z({5}{q?},{6}{q?})
{5}{q?}? compz {6}{q?}? repr-ofx,z
{7}{q?}? sampley {8}{q?}? seex,y
Figure 4: RTG for the weakest readings of Fig. 1.
types for lack of space.
q?(?x(x1,?y(x2,x3)))??y(q?(x2),?x(q?(x1), q?(x3)))
q?(?y(x1,?x(x2,x3)))??x(?y(q?(x1), q?(x2)), q?(x3))
q?(?(x1))??(q?(x1))
q+(?(x1))??(q
?(x1))
q?(?x(x1,x2))??x(q?(x1), q?(x2))
q+(?x(x1,x2))??x(q?(x1),q
+(x2))
q+(?x(x1,x2))??x(q
?(x1), q?(x2)) . . .
The grammar G? for the relative normal forms
is shown in Fig. 4 (omitting rules that involve un-
productive nonterminals). We obtain it by starting
with the example grammar GD in Fig. 3; then com-
puting a deterministic RTG GR for ??1MR (L(GD));
and then intersecting the complement of GR with
GD. The nonterminals of G? are subgraphs of D,
marked either with a set of states of MR or the sym-
bol F , indicating that GR had no production rule
for a given left-hand side. The start symbol of G?
is marked with F because G? should only gener-
ate trees that GR cannot generate. As expected, G?
generates precisely two trees, namely (b) and (c).
5 Redundancy elimination, revisited
The construction we just carried out ? characterize
the configurations we find interesting as the rela-
tive normal forms of an annotated rewrite system
R, translate it into a transducer MR, and intersect
conf(D) with the complement of the pre-image un-
der MR ? is more generally useful than just for the
computation of weakest readings. We illustrate this
on the problem of redundancy elimination (Vestre,
1991; Chaves, 2003; Koller et al, 2008) by show-
ing how a variant of the algorithm of Koller et al
(2008) falls out of our technique as a special case.
Redundancy elimination is the problem of com-
puting, from a dominance graph D, another domi-
nance graph D? such that conf(D?)? conf(D) and
35
every formula in conf(D) is logically equivalent
to some formula in conf(D?). We can approximate
logical equivalence using a finite system of equa-
tions such as
?y(P,?z(Q,R)) = ?z(Q,?y(P,R)), (4)
indicating that ?y and ?z can be permuted without
changing the models of the formula.
Following the approach of Section 4, we can
solve the redundancy elimination problem by trans-
forming the equation system into a rewrite system
R such that t?R t ? implies that t and t ? are equiv-
alent. To this end, we assume an arbitrary linear
order < on ?, and orient all equations into rewrite
rules that respect this order. If we assume ?y < ?z,
the example rule (4) translates into the annotated
rewrite rules
[a] ?z(P,?y(Q,R))??y(Q,?z(P,R)) (5)
for all annotations a ? Ann; logical equivalence
is not sensitive to the annotation. Finally, we can
compute the relative normal forms of conf(D) un-
der this rewrite system as above. The result will be
an RTG G? describing a subset of conf(D). Every
tree t in conf(D) that is not in L(G?) is equivalent
to some tree t ? in L(G?), because if t could not be
rewritten into such a t ?, then t would be in rela-
tive normal form. That is, the algorithm solves the
redundancy elimination problem. Furthermore, if
the oriented rewrite system is confluent (Baader
and Nipkow, 1999), no two trees in L(G?) will be
equivalent to each other, i.e. we achieve complete
reduction in the sense of Koller et al (2008).
This solution shares much with that of Koller et
al. (2008), in that we perform redundancy elimina-
tion by intersecting tree grammars. However, the
construction we present here is much more general:
The algorithmic foundation for redundancy elim-
ination is now exactly the same as that for weak-
est readings, we only have to use an equivalence-
preserving rewrite system instead of a weakening
one. This new formal clarity also simplifies the
specification of certain equations, as we will see in
Section 6.
In addition, we can now combine the weakening
rules (1), (3), and (5) into a single rewrite system,
and then construct a tree grammar for the relative
normal forms of the combined system. This algo-
rithm performs redundancy elimination and com-
putes weakest readings at the same time, and in our
example retains only a single configuration, namely
(5)
(e) ??
x
(?
z
,?
y
) (a) ??
y
?
z
?
x
(3)(1)
(1)
(b) ??
y
?
x
?
z
(c) ??
z
?
y
?
x
(d) ??
z
?
x
?
y
(3)
Figure 5: Structure of the configuration set of Fig. 1
in terms of rewriting.
(b); the configuration (c) is rejected because it can
be rewritten to (a) with (5). The graph in Fig. 5 il-
lustrates how the equivalence and weakening rules
conspire to exclude all other configurations.
6 Evaluation
In this section, we evaluate the effectiveness and
efficiency of our weakest readings algorithm on
a treebank. We compute RTGs for all sentences
in the treebank and measure how many weakest
readings remain after the intersection, and how
much time this computation takes.
Resources. For our experiment, we use the Ron-
dane treebank (version of January 2006), a ?Red-
woods style? (Oepen et al, 2002) treebank con-
taining underspecified representations (USRs) in
the MRS formalism (Copestake et al, 2005) for
sentences from the tourism domain.
Our implementation of the relative normal forms
algorithm is based on Utool (Koller and Thater,
2005), which (among other things) can translate a
large class of MRS descriptions into hypernormally
connected dominance graphs and further into RTGs
as in Section 3. The implementation exploits cer-
tain properties of RTGs computed from dominance
graphs to maximize efficiency. We will make this
implementation publically available as part of the
next Utool release.
We use Utool to automatically translate the 999
MRS descriptions for which this is possible into
RTGs. To simplify the specification of the rewrite
systems, we restrict ourselves to the subcorpus in
which all scope-taking operators (labels with arity
> 0) occur at least ten times. This subset contains
624 dominance graphs. We refer to this subset as
?RON10.?
Signature and annotations. For each domi-
nance graph D that we obtain by converting an
MRS description, we take GD as a grammar over
the signature ?= { fu | u ?WD, f = LD(u)}. That
is, we distinguish possible different occurrences
of the same symbol in D by marking each occur-
36
rence with the name of the node. This makes GD a
deterministic grammar.
We then specify an annotator over ? that assigns
polarities for the weakening rewrite system. We
distinguish three polarities: + for positive occur-
rences, ? for negative occurrences (as in predicate
logic), and ? for contexts in which a weakening
rule neither weakens or strengthens the entire for-
mula. The starting annotation is +.
Finally, we need to decide upon each scope-
taking operator?s effects on these annotations. To
this end, we build upon Barwise and Cooper?s
(1981) classification of the monotonicity prop-
erties of determiners. A determiner is upward
(downward) monotonic if making the denotation of
the determiner?s argument bigger (smaller) makes
the sentence logically weaker. For instance, ev-
ery is downward monotonic in its first argument
and upward monotonic in its second argument,
i.e. every girl kissed a boy entails every blond
girl kissed someone. Thus ann(everyu,a,1) =?a
and ann(everyu,a,2) = a (where u is a node name
as above). There are also determiners with non-
monotonic argument positions, which assign the
annotation ? to this argument. Negation reverses
positive and negative polarity, and all other non-
quantifiers simply pass on their annotation to the
arguments.
Weakest readings. We use the following weak-
ening rewrite system for our experiment, where
i ? {1,2}:
1. [+] (E/i,D/1), (D/2,D/1)
2. [+] (E/i,P/1), (D/2,P/1)
3. [+] (E/i,A/2), (D/1,A/2)
4. [+] (A/2,N/1)
5. [+] (N/1,E/i), (N/1,D/2)
6. [+] (E/i,M/1), (D/1,M/1)
Here the symbols E, D, etc. stand for classes
of labels in ?, and a rule schema [a] (C/i,C?/k) is
to be read as shorthand for a set of rewrite rules
which rearrange a tree where the i-th child of a
symbol from C is a symbol from C? into a tree
where the symbol from C becomes the k-th child
of the symbol from C?. For example, because we
have allu ? A and notv ? N, Schema 4 licenses the
following annotated rewrite rule:
[+] allu(P,notv(Q))? notv(allu(P,Q)).
We write E and D for existential and definite
determiners. P stands for proper names and pro-
nouns, A stands for universal determiners like all
and each, N for the negation not, and M for modal
operators like can or would. M also includes in-
tensional verbs like have to and want. Notice that
while the reverse rules are applicable in negative
polarities, no rules are applicable in polarity ?.
Rule schema 1 states, for instance, that the spe-
cific (wide-scope) reading of the indefinite in the
president of a company is logically stronger than
the reading in which a company is within the re-
striction of the definite determiner. The schema is
intuitively plausible, and it can also be proved to be
logically sound if we make the standard assumption
that the definite determiner the means ?exactly one?
(Montague, 1974). A similar argument applies to
rule schema 2.
Rule schema 3 encodes the classical entailment
(1). Schema 4 is similar to the rule (2). Notice
that it is not, strictly speaking, logically sound;
however, because strong determiners like all or
every carry a presupposition that their restrictions
have a non-empty denotation (Lasersohn, 1993),
the schema becomes sound for all instances that
can be expressed in natural language. Similar ar-
guments apply to rule schemas 5 and 6, which are
potentially unsound for subtle reasons involving
the logical interpretation of intensional expressions.
However, these cases of unsoundness did not occur
in our test corpus.
Redundancy elimination. In addition, we as-
sume the following equation system for redundancy
elimination for i, j ? {1,2} and k ? N (again writ-
ten in an analogous shorthand as above):
7. E/i = E/ j
8. D/1 = E/i, E/i = D/1
9. D/1 = D/1
10. ?/k = P/2
These rule schemata state that permuting exis-
tential determiners with each other is an equiva-
lence transformation, and so is permuting definite
determiners with existential and definite determin-
ers if one determiner is the second argument (in
the scope) of a definite. Schema 10 states that
proper names and pronouns, which the ERG ana-
lyzes as scope-bearing operators, can permute with
any other label.
We orient these equalities into rewrite rules by
ordering symbols in P before symbols that are not
37
All KRT08 RE RE+WR
#conf = 1 8.5% 23.4% 34.9% 66.7%
#conf? 2 20.5% 40.9% 57.9% 80.6%
avg(#conf) 3.2M 7603.1 119.0 4.5
med(#conf) 25 4 2 1
runtime 8.1s 9.4s 8.7s 9.1s
Figure 6: Analysis of the numbers of configurations
in RON10.
in P, and otherwise ordering a symbol fu before a
symbol gv if u < v by comparison of the (arbitrary)
node names.
Results. We used these rewrite systems to com-
pute, for each USR in RON10, the number of all
configurations, the number of configurations that
remain after redundancy elimination, and the num-
ber of weakest readings (i.e., the relative normal
forms of the combined equivalence and weakening
rewrite systems). The results are summarized in
Fig. 6. By computing weakest readings (WR), we
reduce the ambiguity of over 80% of all sentences
to one or two readings; this is a clear improvement
even over the results of the redundancy elimina-
tion (RE). Computing weakest readings reduces
the mean number of readings from several million
to 4.5, and improves over the RE results by a factor
of 30. Notice that the RE algorithm from Section 5
is itself an improvement over Koller et al?s (2008)
system (?KRT08? in the table), which could not
process the rule schema 10.
Finally, computing the weakest readings takes
only a tiny amount of extra runtime compared to
the RE elimination or even the computation of the
RTGs (reported as the runtime for ?All?).1 This re-
mains true on the entire Rondane corpus (although
the reduction factor is lower because we have no
rules for the rare scope-bearers): RE+WR compu-
tation takes 32 seconds, compared to 30 seconds
for RE. In other words, our algorithm brings the
semantic ambiguity in the Rondane Treebank down
to practically useful levels at a mean runtime in-
vestment of a few milliseconds per sentence.
It is interesting to note how the different rule
schemas contribute to this reduction. While the
instances of Schemata 1 and 2 are applicable in 340
sentences, the other schemas 3?6 together are only
1Runtimes were measured on an Intel Core 2 Duo CPU
at 2.8 GHz, under MacOS X 10.5.6 and Apple Java 1.5.0_16,
after allowing the JVM to just-in-time compile the bytecode.
applicable in 44 sentences. Nevertheless, where
these rules do apply, they have a noticeable effect:
Without them, the mean number of configurations
in RON10 after RE+WR increases to 12.5.
7 Conclusion
In this paper, we have shown how to compute the
weakest readings of a dominance graph, charac-
terized by an annotated rewrite system. Evaluat-
ing our algorithm on a subcorpus of the Rondane
Treebank, we reduced the mean number of config-
urations of a sentence from several million to 4.5,
in negligible runtime. Our algorithm can be ap-
plied to other problems in which an underspecified
representation is to be disambiguated, as long as
the remaining readings can be characterized as the
relative normal forms of a linear annotated rewrite
system. We illustrated this for the case of redun-
dancy elimination.
The algorithm presented here makes it possible,
for the first time, to derive a single meaningful se-
mantic representation from the syntactic analysis
of a deep grammar on a large scale. In the future,
it will be interesting to explore how these semantic
representations can be used in applications. For in-
stance, it seems straightforward to adapt MacCart-
ney and Manning?s (2008) ?natural logic?-based
Textual Entailment system, because our annotator
already computes the polarities needed for their
monotonicity inferences. We could then perform
such inferences on (cleaner) semantic representa-
tions, rather than strings (as they do).
On the other hand, it may be possible to re-
duce the set of readings even further. We retain
more readings than necessary in many treebank sen-
tences because the combined weakening and equiv-
alence rewrite system is not confluent, and there-
fore may not recognize a logical relation between
two configurations. The rewrite system could be
made more powerful by running the Knuth-Bendix
completion algorithm (Knuth and Bendix, 1970).
Exploring the practical tradeoff between the further
reduction in the number of remaining configura-
tions and the increase in complexity of the rewrite
system and the RTG would be worthwhile.
Acknowledgments. We are indebted to Joachim
Niehren, who pointed out a crucial simplification
in the algorithm to us. We also thank our reviewers
for their constructive comments.
38
References
E. Althaus, D. Duchier, A. Koller, K. Mehlhorn,
J. Niehren, and S. Thiel. 2003. An efficient graph
algorithm for dominance constraints. Journal of Al-
gorithms, 48:194?219.
F. Baader and T. Nipkow. 1999. Term rewriting and all
that. Cambridge University Press.
J. Barwise and R. Cooper. 1981. Generalized quanti-
fiers and natural language. Linguistics and Philoso-
phy, 4:159?219.
J. Bos. 2008. Let?s not argue about semantics. In
Proceedings of the 6th international conference on
Language Resources and Evaluation (LREC 2008).
M. Butt, H. Dyvik, T. Holloway King, H. Masuichi,
and C. Rohrer. 2002. The parallel grammar
project. In Proceedings of COLING-2002 Workshop
on Grammar Engineering and Evaluation.
R. P. Chaves. 2003. Non-redundant scope disambigua-
tion in underspecified semantics. In Proceedings of
the 8th ESSLLI Student Session.
H. Comon, M. Dauchet, R. Gilleron, C. L?ding,
F. Jacquemard, D. Lugiez, S. Tison, and M. Tom-
masi. 2007. Tree automata techniques and appli-
cations. Available on: http://www.grappa.
univ-lille3.fr/tata.
A. Copestake and D. Flickinger. 2000. An open-
source grammar development environment and
broad-coverage english grammar using HPSG. In
Proceedings of the 2nd International Conference on
Language Resources and Evaluation (LREC).
A. Copestake, D. Flickinger, C. Pollard, and I. Sag.
2005. Minimal recursion semantics: An introduc-
tion. Journal of Language and Computation.
D. Flickinger, A. Koller, and S. Thater. 2005. A new
well-formedness criterion for semantics debugging.
In Proceedings of the 12th International Conference
on HPSG, Lisbon.
M. Gabsdil and K. Striegnitz. 1999. Classifying scope
ambiguities. In Proceedings of the First Intl. Work-
shop on Inference in Computational Semantics.
J. Graehl, K. Knight, and J. May. 2008. Training tree
transducers. Computational Linguistics, 34(3):391?
427.
D. Higgins and J. Sadock. 2003. A machine learning
approach to modeling scope preferences. Computa-
tional Linguistics, 29(1).
J. Hobbs. 1983. An improper treatment of quantifi-
cation in ordinary English. In Proceedings of the
21st Annual Meeting of the Association for Compu-
tational Linguistics (ACL?83).
R. Kempson and A. Cormack. 1981. Ambiguity and
quantification. Linguistics and Philosophy, 4:259?
309.
D. Knuth and P. Bendix. 1970. Simple word problems
in universal algebras. In J. Leech, editor, Computa-
tional Problems in Abstract Algebra, pages 263?297.
Pergamon Press, Oxford.
A. Koller and J. Niehren. 2000. On underspecified
processing of dynamic semantics. In Proceedings of
the 18th International Conference on Computational
Linguistics (COLING-2000).
A. Koller and S. Thater. 2005. Efficient solving and ex-
ploration of scope ambiguities. In ACL-05 Demon-
stration Notes, Ann Arbor.
A. Koller and S. Thater. 2010. Computing relative nor-
mal forms in regular tree languages. In Proceedings
of the 21st International Conference on Rewriting
Techniques and Applications (RTA).
A. Koller, J. Niehren, and S. Thater. 2003. Bridg-
ing the gap between underspecification formalisms:
Hole semantics as dominance constraints. In Pro-
ceedings of the 10th EACL.
A. Koller, M. Regneri, and S. Thater. 2008. Regular
tree grammars as a formalism for scope underspeci-
fication. In Proceedings of ACL-08: HLT.
P. Lasersohn. 1993. Existence presuppositions and
background knowledge. Journal of Semantics,
10:113?122.
B. MacCartney and C. Manning. 2008. Modeling
semantic containment and exclusion in natural lan-
guage inference. In Proceedings of the 22nd Inter-
national Conference on Computational Linguistics
(COLING).
R. Montague. 1974. The proper treatment of quantifi-
cation in ordinary English. In R. Thomason, editor,
Formal Philosophy. Selected Papers of Richard Mon-
tague. Yale University Press, New Haven.
C. Monz and M. de Rijke. 2001. Deductions with
meaning. In Michael Moortgat, editor, Logical As-
pects of Computational Linguistics, Third Interna-
tional Conference (LACL?98), volume 2014 of LNAI.
Springer-Verlag, Berlin/Heidelberg.
S. Oepen, K. Toutanova, S. Shieber, C. Manning,
D. Flickinger, and T. Brants. 2002. The LinGO
Redwoods treebank: Motivation and preliminary
applications. In Proceedings of the 19th Inter-
national Conference on Computational Linguistics
(COLING).
Uwe Reyle. 1995. On reasoning with ambiguities. In
Proceedings of the 7th Conference of the European
Chapter of the Association for Computational Lin-
guistics (EACL?95).
K. van Deemter. 1996. Towards a logic of ambiguous
expressions. In Semantic Ambiguity and Underspec-
ification. CSLI Publications, Stanford.
E. Vestre. 1991. An algorithm for generating non-
redundant quantifier scopings. In Proc. of EACL,
Berlin.
39
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 534?543,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
The Importance of Rule Restrictions in CCG
Marco Kuhlmann
Dept. of Linguistics and Philology
Uppsala University
Uppsala, Sweden
Alexander Koller
Cluster of Excellence
Saarland University
Saarbr?cken, Germany
Giorgio Satta
Dept. of Information Engineering
University of Padua
Padua, Italy
Abstract
Combinatory Categorial Grammar (CCG)
is generally construed as a fully lexicalized
formalism, where all grammars use one and
the same universal set of rules, and cross-
linguistic variation is isolated in the lexicon.
In this paper, we show that the weak gener-
ative capacity of this ?pure? form of CCG is
strictly smaller than that of CCG with gram-
mar-specific rules, and of other mildly con-
text-sensitive grammar formalisms, includ-
ing Tree Adjoining Grammar (TAG). Our
result also carries over to a multi-modal
extension of CCG.
1 Introduction
Combinatory Categorial Grammar (CCG) (Steed-
man, 2001; Steedman and Baldridge, 2010) is an
expressive grammar formalism with formal roots
in combinatory logic (Curry et al, 1958) and links
to the type-logical tradition of categorial grammar
(Moortgat, 1997). It has been successfully used for
a wide range of practical tasks, such as data-driven
parsing (Hockenmaier and Steedman, 2002; Clark
and Curran, 2007), wide-coverage semantic con-
struction (Bos et al, 2004), and the modelling of
syntactic priming (Reitter et al, 2006).
It is well-known that CCG can generate lan-
guages that are not context-free (which is neces-
sary to capture natural languages), but can still
be parsed in polynomial time. Specifically, Vijay-
Shanker and Weir (1994) identified a version of
CCG that is weakly equivalent to Tree Adjoining
Grammar (TAG) (Joshi and Schabes, 1997) and
other mildly context-sensitive grammar formalisms,
and can generate non-context-free languages such
as anbncn. The generative capacity of CCG is com-
monly attributed to its flexible composition rules,
which allow it to model more complex word orders
that context-free grammar can.
The discussion of the (weak and strong) gener-
ative capacity of CCG and TAG has recently been
revived (Hockenmaier and Young, 2008; Koller and
Kuhlmann, 2009). In particular, Koller and Kuhl-
mann (2009) have shown that CCGs that are pure
(i.e., they can only use generalized composition
rules, and there is no way to restrict the instances
of these rules that may be used) and first-order
(i.e., all argument categories are atomic) can not
generate anbncn. This shows that the generative
capacity of at least first-order CCG crucially relies
on its ability to restrict rule instantiations, and is at
odds with the general conception of CCG as a fully
lexicalized formalism, in which all grammars use
one and the same set of universal rules. A question
then is whether the result carries over to pure CCG
with higher-order categories.
In this paper, we answer this question to the pos-
itive: We show that the weak generative capacity of
general pure CCG is still strictly smaller than that
of the formalism considered by Vijay-Shanker and
Weir (1994); composition rules can only achieve
their full expressive potential if their use can be
restricted. Our technical result is that every lan-
guage L that can be generated by a pure CCG has
a context-free sublanguage L0  L such that every
string in L is a permutation of a string in L0, and
vice versa. This means that anbncn, for instance,
cannot be generated by pure CCG, as it does not
have any (non-trivial) permutation-equivalent sub-
languages. Conversely, we show that there are still
languages that can be generated by pure CCG but
not by context-free grammar.
We then show that our permutation language
lemma also holds for pure multi-modal CCG as
defined by Baldridge and Kruijff (2003), in which
the use of rules can be controlled through the lex-
icon entries by assigning types to slashes. Since
this extension was intended to do away with
the need for grammar-specific rule restrictions, it
comes as quite a surprise that pure multi-modal
534
CCG in the style of Baldridge and Kruijff (2003) is
still less expressive than the CCG formalism used
by Vijay-Shanker and Weir (1994). This means that
word order in CCG cannot be fully lexicalized with
the current formal tools; some ordering constraints
must be specified via language-specific combina-
tion rules and not in lexicon entries. On the other
hand, as pure multi-modal CCG has been success-
fully applied to model the syntax of a variety of
natural languages, another way to read our results
is as contributions to a discussion about the exact
expressiveness needed to model natural language.
The remainder of this paper is structured as fol-
lows. In Section 2, we introduce the formalism
of pure CCG that we consider in this paper, and
illustrate the relevance of rule restrictions. We then
study the generative capacity of pure CCG in Sec-
tion 3; this section also presents our main result. In
Section 4, we show that this result still holds for
multi-modal CCG. Section 5 concludes the paper
with a discussion of the relevance of our findings.
2 Combinatory Categorial Grammar
We start by providing formal definitions for cat-
egories, syntactic rules, and grammars, and then
discuss the relevance of rule restrictions for CCG.
2.1 Categories
Given a finite set A of atomic categories, the set of
categories over A is the smallest set C such that
A  C , and .x=y/; .xny/ 2 C whenever x; y 2 C .
A category x=y represents a function that seeks a
string with category y to the right (indicated by the
forward slash) and returns a new string with cat-
egory x; a category xny instead seeks its argument
to the left (indicated by the backward slash). In
the remainder of this paper, we use lowercase sans-
serif letters such as x; y; z as variables for categor-
ies, and the vertical bar j as a variable for slashes.
In order to save some parentheses, we understand
slashes as left-associative operators, and write a
category such as .x=y/nz as x=ynz.
The list of arguments of a category c is defined
recursively as follows: If c is atomic, then it has no
arguments. If c D xjy for some categories x and y,
then the arguments of c are the slashed category jy,
plus the arguments of x. We number the arguments
of a category from outermost to innermost. The
arity of a category is the number of its arguments.
The target of a category c is the atomic category
that remains when stripping c of its arguments.
x=y y ) x forward application >
y xny ) x backward application <
x=y y=z ) x=z forward harmonic composition >B
ynz xny ) xnz backward harmonic composition <B
x=y ynz ) xnz forward crossed composition >B
y=z xny ) x=z backward crossed composition <B
Figure 1: The core set of rules of CCG.
2.2 Rules
The syntactic rules of CCG are directed versions
of combinators in the sense of combinatory logic
(Curry et al, 1958). Figure 1 lists a core set of
commonly assumed rules, derived from functional
application and the B combinator, which models
functional composition. When talking about these
rules, we refer to the premise containing the argu-
ment jy as the primary premise, and to the other
premise as the secondary premise of the rule.
The rules in Figure 1 can be generalized into
composition rules of higher degrees. These are
defined as follows, where n  0 and ? is a variable
for a sequence of n arguments.
x=y y? ) x? generalized forward composition >n
y? xny ) x? generalized backward composition <n
We call the value n the degree of the composition
rule. Note that the rules in Figure 1 are the special
cases for n D 0 and n D 1.
Apart from the core rules given in Figure 1, some
versions of CCG also use rules derived from the S
and T combinators of combinatory logic, called
substitution and type-raising, the latter restricted
to the lexicon. However, since our main point of
reference in this paper, the CCG formalism defined
by Vijay-Shanker and Weir (1994), does not use
such rules, we will not consider them here, either.
2.3 Grammars and Derivations
With the set of rules in place, we can define a
pure combinatory categorial grammar (PCCG) as
a construct G D .A;?;L; s/, where A is an alpha-
bet of atomic categories, s 2 A is a distinguished
atomic category called the final category, ? is a
finite set of terminal symbols, and L is a finite rela-
tion between symbols in ? and categories over A,
called the lexicon. The elements of the lexicon L
are called lexicon entries, and we represent them
using the notation  ` x, where  2 ? and x
is a category over A. A category that occurs in a
lexicon entry is called a lexical category.
535
A derivation in a grammar G can be represen-
ted as a derivation tree as follows. Given a string
w 2 ?, we choose a lexicon entry for each oc-
currence of a symbol in w, line up the respective
lexical categories from left to right, and apply ad-
missible rules to adjacent pairs of categories. After
the application of a rule, only the conclusion is
available for future applications. We iterate this
process until we end up with a single category. The
string w is called the yield of the resulting deriva-
tion tree. A derivation tree is complete, if the last
category is the final category of G. The language
generated by G, denoted by L.G/, is formed by
the yields of all complete derivation trees.
2.4 Degree Restrictions
Work on CCG generally assumes an upper bound
on the degree of composition rules that can be used
in derivations. We also employ this restriction, and
only consider grammars with compositions of some
bounded (but arbitrary) degree n  0.1 CCG with
unbounded-degree compositions is more express-
ive than bounded-degree CCG or TAG (Weir and
Joshi, 1988).
Bounded-degree grammars have a number of
useful properties, one of which we mention here.
The following lemma rephrases Lemma 3.1 in
Vijay-Shanker and Weir (1994).
Lemma 1 For every grammar G, every argument
in a derivation ofG is the argument of some lexical
category of G.
As a consequence, there is only a finite number
of categories that can occur as arguments in some
derivation. In the presence of a bound on the degree
of composition rules, this implies the following:
Lemma 2 For every grammar G, there is a finite
number of categories that can occur as secondary
premises in derivations of G.
Proof. The arity of a secondary premise c can be
written as mC n, where m is the arity of the first
argument of the corresponding primary premise,
and n is the degree of the rule applied. Since each
argument is an argument of some lexical category
of G (Lemma 1), and since n is assumed to be
bounded, both m and n are bounded. Hence, there
is a bound on the number of choices for c. 
Note that the number of categories that can occur
as primary premises is generally unbounded even
in a grammar with bounded degree.
1For practical grammars, n  4.
2.5 Rule Restrictions
The rule set of pure CCG is universal: the differ-
ence between the grammars of different languages
should be restricted to different choices of categor-
ies in the lexicon. This is what makes pure CCG
a lexicalized grammar formalism (Steedman and
Baldridge, 2010). However, most practical CCG
grammars rely on the possibility to exclude or re-
strict certain rules. For example, Steedman (2001)
bans the rule of forward crossed composition from
his grammar of English, and stipulates that the rule
of backward crossed composition may be applied
only if both of its premises share the common tar-
get category s, representing sentences. Exclusions
and restrictions of rules are also assumed in much
of the language-theoretic work on CCG. In partic-
ular, they are essential for the formalism used in
the aforementioned equivalence proof for CCG and
TAG (Vijay-Shanker and Weir, 1994).
To illustrate the formal relevance of rule restric-
tions, suppose that we wanted to write a pure CCG
that generates the language
L3 D f anbncn j n  1 g ,
which is not context-free. An attempt could be
G1 D .f s; a; b; c g; f a; b; c g; L; s/ ,
where the lexicon L is given as follows:
a ` a , b ` s=cna , b ` b=cna ,
b ` s=c=bna , b ` s=c=bna , c ` c .
From a few sample derivations like the one given
in Figure 2a, we can convince ourselves that G1
generates all strings of the form anbncn, for any
n  1. However, a closer inspection reveals that it
also generates other, unwanted strings?in partic-
ular, strings of the form .ab/ncn, as witnessed by
the derivation given in Figure 2b.
Now suppose that we would have a way to only
allow those instances of generalized composition in
which the secondary premise has the form b=c=bna
or b=cna. Then the compositions
b=c=b b=c
b=c=c >
1 and s=c=b b=c
s=c=c >
1
would be disallowed, and it is not hard to see
that G1 would generate exactly anbncn.
As we will show in this paper, our attempt to
capture L3 with a pure CCG grammar failed not
only because we could not think of one: L3 cannot
be generated by any pure CCG.
536
a...................
a
a...........
a
a...
a
b...
s=c=bna
b.......
b=c=bna
b...............
b=cna
c.......................
c
c...........................
c
c...............................
c
<0
s=c=b
>3
s=c=c=bna
<0
s=c=c=b
>2
s=c=c=cna
<0
s=c=c=c
>0
s=c=c
>0
s=c
>0
s
(a) Derivation of the string aaabbbccc.
a...........
a
b...........
s=c=bna
a...
a
b...
b=c=bna
a...
a
b...
b=cna
c...........
c
c...................
c
c.......................
c
<0
s=c=b
<0
b=c=b
<0
b=c
>1
b=c=c
>0
b=c
>1
s=c=c
>0
s=c
>0
s
(b) Derivation of the string abababccc.
Figure 2: Two derivations of the grammar G1.
3 The Generative Capacity of Pure CCG
We will now develop a formal argument showing
that rule restrictions increase the weak generative
capacity of CCG. We will first prove that pure CCG
is still more expressive than context-free grammar.
We will then spend the rest of this section working
towards the result that pure CCG is strictly less
expressive than CCG with rule restrictions. Our
main technical result will be the following:
Theorem 1 Every language that can be generated
by a pure CCG has a Parikh-equivalent context-free
sublanguage.
Here, two languages L and L0 are called Parikh-
equivalent if every string in L is the permutation
of a string in L0 and vice versa.
3.1 CFG ? PCCG
Proposition 1 The class of languages generated
by pure CCG properly includes the class of context-
free languages.
Proof. To see the inclusion, it suffices to note that
pure CCG when restricted to application rules is
the same as AB-grammar, the classical categorial
formalism investigated by Ajdukiewicz and Bar-
Hillel (Bar-Hillel et al, 1964). This formalism is
weakly equivalent to context-free grammar.
To see that the inclusion is proper, we can go
back to the grammarG1 that we gave in Section 2.5.
We have already discussed that the language L3 is
included inL.G1/. We can also convince ourselves
that all strings generated by the grammar G1 have
an equal number of as, bs and cs. Consider now
the regular language R D abc. From our ob-
servations, it follows that L.G1/\R D L3. Since
context-free languages are closed under intersec-
tion with regular languages, we find that L.G1/
can be context-free only if L3 is. Since L3 is not
context-free, we therefore conclude that L.G1/ is
not context-free, either. 
Two things are worth noting. First, our result shows
that the ability of CCG to generate non-context-free
languages does not hinge on the availability of sub-
stitution and type-raising rules: The derivations
of G1 only use generalized compositions. Neither
does it require the use of functional argument cat-
egories: The grammarG1 is first-order in the sense
of Koller and Kuhlmann (2009).
Second, it is important to note that if the com-
position degree n is restricted to 0 or 1, pure CCG
actually collapses to context-free expressive power.
This is clear for n D 0 because of the equivalence
to AB grammar. For n D 1, observe that the arity
of the result of a composition is at most as high as
537
that of each premise. This means that the arity of
any derived category is bounded by the maximal
arity of lexical categories in the grammar, which
together with Lemma 1 implies that there is only
a finite set of derivable categories. The set of all
valid derivations can then be simulated by a con-
text-free grammar. In the presence of rules with
n  2, the arities of derived categories can grow
unboundedly.
3.2 Active and Inactive Arguments
In the remainder of this section, we will develop
the proof of Theorem 1, and use it to show that the
generative capacity of PCCG is strictly smaller than
that of CCG with rule restrictions. For the proof,
we adopt a certain way to view the information
flow in CCG derivations. Consider the following
instance of forward harmonic composition:
a=b b=c ) a=c
This rule should be understood as obtaining its con-
clusion a=c from the primary premise a=b by the
removal of the argument =b and the subsequent
transfer of the argument =c from the secondary
premise. With this picture in mind, we will view
the two occurrences of =c in the secondary premise
and in the conclusion as two occurrences of one
and the same argument. Under this perspective,
in a given derivation, an argument has a lifespan
that starts in a lexical category and ends in one
of two ways: either in the primary or in the sec-
ondary premise of a composition rule. If it ends
in a primary premise, it is because it is matched
against a subcategory of the corresponding second-
ary premise; this is the case for the argument =b
in the example above. We will refer to such argu-
ments as active. If an argument ends its life in a
secondary premise, it is because it is consumed as
part of a higher-order argument. This is the case
for the argument =c in the secondary premise of
the following rule instance:
a=.b=c/ b=c=d ) a=d
(Recall that we assume that slashes are left-associ-
ative.) We will refer to such arguments as inactive.
Note that the status of an argument as either active
or inactive is not determined by the grammar, but
depends on a concrete derivation.
The following lemma states an elementary prop-
erty in connection with active and inactive argu-
ments, which we will refer to as segmentation:
Lemma 3 Every category that occurs in a CCG
derivation has the general form a??, where a is an
atomic category, ? is a sequence of inactive argu-
ments, and ? is a sequence of active arguments.
Proof. The proof is by induction on the depth of a
node in the derivation. The property holds for the
root (which is labeled with the final category), and
is transferred from conclusions to premises. 
3.3 Transformation
The fundamental reason for why the example gram-
mar G1 from Section 2.5 overgenerates is that in
the absence of rule restrictions, we have no means
to control the point in a derivation at which a cat-
egory combines with its arguments. Consider the
examples in Figure 2: It is because we cannot en-
sure that the bs finish combining with the other bs
before combining with the cs that the undesirable
word order in Figure 2b has a derivation. To put
it as a slogan: Permuting the words allows us to
saturate arguments prematurely.
In this section, we show that this property applies
to all pure CCGs. More specifically, we show that,
in a derivation of a pure CCG, almost all active
arguments of a category can be saturated before
that category is used as a secondary premise; at
most one active argument must be transferred to
the conclusion of that premise. Conversely, any
derivation that still contains a category with at least
two active arguments can be transformed into a
new derivation that brings us closer to the special
property just characterized.
We formalize this transformation by means of a
system of rewriting rules in the sense of Baader and
Nipkow (1998). The rules are given in Figure 3. To
see how they work, let us consider the first rule, R1;
the other ones are symmetric. This rules states that,
whenever we see a derivation in which a category
of the form x=y (here marked as A) is combined
with a category of the form y?=z (marked as B),
and the result of this combination is combined with
a category of the form z (C), then the resulting
category can also be obtained by ?rotating? the de-
rivation to first saturate =z by combining B with C,
and only then do the combination with A. When ap-
plying these rotations exhaustively, we end up with
a derivation in which almost all active arguments of
a category are saturated before that category is used
as a secondary premise. Applying the transform-
ation to the derivation in Figure 2a, for instance,
yields the derivation in Figure 2b.
We need the following result for some of the
lemmas we prove below. We call a node in a deriv-
538
A x=y B y?=z
x?=z C z
x?
R1
H) x=y
y?=z z
y?
x?
B y?=z A xny
x?=z C z
x?
R2
H)
y?=z z
y? xny
x?
C z
A x=y B y?nz
x?nz
x?
R3
H) x=y
z y?nz
y?
x?
C z
B y?nz A xny
x?nz
x?
R4
H)
z y?nz
y? xny
x?
Figure 3: Rewriting rules used in the transformation. Here,  represents a (possibly empty) sequence of
arguments, and ? represents a sequence of arguments in which the first (outermost) argument is active.
ation critical if its corresponding category contains
more than one active argument and it is the second-
ary premise of a rule. We say that u is a highest
critical node if there is no other critical node whose
distance to the root is shorter.
Lemma 4 If u is a highest critical node, then we
can apply one of the transformation rules to the
grandparent of u.
Proof. Suppose that the category at u has the form
y?=z, where =z is an active argument, and the first
argument in ? is active as well. (The other possible
case, in which the relevant occurrence has the form
y?nz, can be treated symmetrically.) Since u is a
secondary premise, it is involved in an inference of
one of the following two forms:
x=y y?=z
x?=z
y?=z xny
x?=z
Since u is a highest critical node, the conclusion
of this inference is not a critical node itself; in
particular, it is not a secondary premise. Therefore,
the above inferences can be extended as follows:
x=y y?=z
x?=z z
x?
y?=z xny
x?=z z
x?
These partial derivations match the left-hand side of
the rewriting rules R1 and R2, respectively. Hence,
we can apply a rewriting rule to the derivation. 
We now show that the transformation is well-
defined, in the sense that it terminates and trans-
forms derivations of a grammar G into new deriva-
tions of G.
Lemma 5 The rewriting of a derivation tree ends
after a finite number of steps.
Proof. We assign natural numbers to the nodes
of a derivation tree as follows. Each leaf node
is assigned the number 0. For an inner node u,
which corresponds to the conclusion of a composi-
tion rule, let m; n be the numbers assigned to the
nodes corresponding to the primary and second-
ary premise, respectively. Then u is assigned the
number 1C 2mCn. Suppose now that we have as-
sociated premise A with the number x, premise B
with the number y, and premise C with the num-
ber z. It is then easy to verify that the conclusion
of the partial derivation on the left-hand side of
each rule has the value 3 C 4x C 2y C z, while
the conclusion of the right-hand side has the value
2C 2x C 2y C z. Thus, each step decreases the
value of a derivation tree under our assignment by
the amount 1C 2x. Since this value is positive for
all choices of x, the rewriting ends after a finite
number of steps. 
To convince ourselves that our transformation does
not create ill-formed derivations, we need to show
that none of the rewriting rules necessitates the use
of composition operations whose degree is higher
than the degree of the operations used in the ori-
ginal derivation.
Lemma 6 Applying the rewriting rules from the
top down does not increase the degree of the com-
position operations.
Proof. The first composition rule used in the left-
hand side of each rewriting rule has degree j?j C 1,
the second rule has degree j j; the first rule used in
the right-hand side has degree j j, the second rule
has degree j?jC j j. To prove the claim, it suffices
to show that j j  1. This is a consequence of the
following two observations.
1. In the category x? , the arguments in  occur
on top of the arguments in ?, the first of which is
active. Using the segmentation property stated in
Lemma 3, we can therefore infer that  does not
contain any inactive arguments.
539
2. Because we apply rules top-down, premise B
is a highest critical node in the derivation (by
Lemma 4). This means that the category at
premise C contains at most one active argument;
otherwise, premise C would be a critical node
closer to the root than premise B. 
We conclude that, if we rewrite a derivation d of G
top-down until exhaustion, then we obtain a new
valid derivation d 0. We call all derivations d 0 that
we can build in this way transformed. It is easy to
see that a derivation is transformed if and only if it
contains no critical nodes.
3.4 Properties of Transformed Derivations
The special property established by our transform-
ation has consequences for the generative capacity
of pure CCG. In particular, we will now show that
the set of all transformed derivations of a given
grammar yields a context-free language. The cru-
cial lemma is the following:
Lemma 7 For every grammar G, there is some
k  0 such that no category in a transformed
derivation of G has arity greater than k.
Proof. The number of inactive arguments in the
primary premise of a rule does not exceed the num-
ber of inactive arguments in the conclusion. In
a transformed derivation, a symmetric property
holds for active arguments: Since each second-
ary premise contains at most one active argument,
the number of active arguments in the conclusion
of a rule is not greater than the number of act-
ive arguments in its primary premise. Taken to-
gether, this implies that the arity of a category that
occurs in a transformed derivation is bounded by
the sum of the maximal arity of a lexical category
(which bounds the number of active arguments),
and the maximal arity of a secondary premise
(which bounds the number of inactive arguments).
Both of these values are bounded in G. 
Lemma 8 The yields corresponding to the set of
all transformed derivations of a pure CCG form a
context-free language.
Proof. Let G be a pure CCG. We construct a con-
text-free grammar GT that generates the yields of
the set of all transformed derivations of G.
As the set of terminals of GT , we use the set of
terminals ofG. To form the set of nonterminals, we
take all categories that can occur in a transformed
derivation of G, and mark each argument as either
?active? (C) or ?inactive? ( ), in all possible ways
that respect the segmentation property stated in
Lemma 3. Note that, because of Lemma 7 and
Lemma 1, the set of nonterminals is finite. As the
start symbol, we use s, the final category of G.
The set of productions of GT is constructed as
follows. For each lexicon entry  ` c of G, we in-
clude all productions of the form x !  , where x
is some marked version of c. These productions
represent all valid guesses about the activity of the
arguments of c during a derivation of G. The re-
maining productions encode all valid instantiations
of composition rules, keeping track of active and
inactive arguments to prevent derivations with crit-
ical nodes. More specifically, they have the form
x? ! x=yC y? or x? ! y? xnyC ,
where the arguments in the y-part of the secondary
premise are all marked as inactive, the sequence ?
contains at most one argument marked as active,
and the annotations of the left-hand side nonter-
minal are copied over from the corresponding an-
notations on the right-hand side.
The correctness of the construction ofGT can be
proved by induction on the length of a transformed
derivation of G on the one hand, and the length of
a derivation of GT on the other hand. 
3.5 PCCG ? CCG
We are now ready to prove our main result, repeated
here for convenience.
Theorem 1 Every language that can be generated
by a pure CCG grammar has a Parikh-equivalent
context-free sublanguage.
Proof. Let G be a pure CCG, and let LT be the
set of yields of the transformed derivations of G.
Inspecting the rewriting rules, it is clear that every
string of L.G/ is the permutation of a string in LT :
the transformation only rearranges the yields. By
Lemma 8, we also know that LT is context-free.
Since every transformed derivation is a valid deriv-
ation of G, we have LT  L.G/. 
As an immediate consequence, we find:
Proposition 2 The class of languages generated
by pure CCG cannot generate all languages that
can be generated by CCG with rule restrictions.
Proof. The CCG formalism considered by Vijay-
Shanker and Weir (1994) can generate the non-con-
text-free language L3. However, the only Parikh-
equivalent sublanguage of that language isL3 itself.
From Theorem 1, we therefore conclude that L3
cannot be generated by pure CCG. 
540
In the light of the equivalence result established
by Vijay-Shanker and Weir (1994), this means that
pure CCG cannot generate all languages that can
be generated by TAG.
4 Multi-Modal CCG
We now extend Theorem 1 to multi-modal CCG.
We will see that at least for a popular version
of multi-modal CCG, the B&K-CCG formalism
presented by Baldridge and Kruijff (2003), the
proof can be adapted quite straightforwardly. This
means that even B&K-CCG becomes less express-
ive when rule restrictions are disallowed.
4.1 Multi-Modal CCG
The term ?multi-modal CCG? (MM-CCG) refers to
a family of extensions to CCG which attempt to
bring some of the expressive power of Categorial
Type Logic (Moortgat, 1997) into CCG. Slashes in
MM-CCG have slash types, and rules can be restric-
ted to only apply to arguments that have slashes
of the correct type. The idea behind this extension
is that many constraints that in ordinary CCG can
only be expressed in terms of rule restrictions can
now be specified in the lexicon entries by giving
the slashes the appropriate types.
The most widely-known version of multi-modal
CCG is the formalism defined by Baldridge and
Kruijff (2003) and used by Steedman and Baldridge
(2010); we refer to it as B&K-CCG. This formalism
uses an inventory of four slash types, f?;;?;  g,
arranged in a simple type hierarchy: ? is the most
general type,  the most specific, and  and ? are
in between. Every slash in a B&K-CCG lexicon is
annotated with one of these slash types.
The combinatory rules in B&K-CCG, given in
Figure 4, are defined to be sensitive to the slash
types. In particular, slashes with the types ? and 
can only be eliminated by harmonic and crossed
compositions, respectively.2 Thus, a grammar
writer can constrain the application of harmonic
and crossed composition rules to certain categor-
ies by assigning appropriate types to the slashes
of this category in the lexicon. Application rules
apply to slashes of any type. As before, we call
an MM-CCG grammar pure if it only uses applic-
ation and generalized compositions, and does not
provide means to restrict rule applications.
2Our definitions of generalized harmonic and crossed com-
position are the same as the ones used by Hockenmaier and
Young (2008), but see the discussion in Section 4.3.
x=?y y ) x forward application
y xn?y ) x backward application
x=?y y=?z? ) x=?z? forward harmonic composition
x=y ynz? ) xnz? forward crossed composition
yn?z? xn?y ) xn?z? backward harmonic composition
y=z? xny ) x=z? backward crossed composition
Figure 4: Rules in B&K-CCG.
4.2 Rule Restrictions in B&K-CCG
We will now see what happens to the proof of The-
orem 1 in the context of pure B&K-CCG. There
is only one point in the entire proof that could be
damaged by the introduction of slash types, and
that is the result that if a transformation rule from
Figure 3 is applied to a correct derivation, then the
result is also grammatical. For this, it must not
only be the case that the degree on the composition
operations is preserved (Lemma 6), but also that
the transformed derivation remains consistent with
the slash types. Slash types make the derivation
process sensitive to word order by restricting the
use of compositions to categories with the appropri-
ate type, and the transformation rules permute the
order of the words in the string. There is a chance
therefore that a transformed derivation might not
be grammatical in B&K-CCG.
We now show that this does not actually happen,
for rule R3; the other three rules are analogous.
Using s1; s2; s3 as variables for the relevant slash
types, rule R3 appears in B&K-CCG as follows:
z
x=s1y yjs2w?ns3z
xjs2w?ns3z
xjs2w?
R3
H) x=s1y
z yjs2w?ns3z
yjs2w?
xjs2w?
Because the original derivation is correct, we know
that, if the slash of w is forward, then s1 and s2 are
subtypes of ?; if the slash is backward, they are
subtypes of . A similar condition holds for s3 and
the first slash in  ; if  is empty, then s3 can be
anything because the second rule is an application.
After the transformation, the argument =s1y is
used to compose with yjs2w? . The direction of
the slash in front of the w is the same as before,
so the (harmonic or crossed) composition is still
compatible with the slash types s1 and s2. An
analogous argument shows that the correctness of
combining ns3z with  carries over from the left to
the right-hand side. Thus the transformation maps
grammatical derivations into grammatical deriva-
tions. The rest of the proof in Section 3 continues
to work literally, so we have the following result:
541
Theorem 2 Every language that can be generated
by a pure B&K-CCG grammar contains a Parikh-
equivalent context-free sublanguage.
This means that pure B&K-CCG is just as unable
to generate L3 as pure CCG is. In other words,
the weak generative capacity of CCG with rule
restrictions, and in particular that of the formalism
considered by Vijay-Shanker and Weir (1994), is
strictly greater than the generative capacity of pure
B&K-CCG?although we conjecture (but cannot
prove) that pure B&K-CCG is still more expressive
than pure non-modal CCG.
4.3 Towards More Expressive MM-CCGs
To put the result of Theorem 2 into perspective, we
will now briefly consider ways in which B&K-CCG
might be modified in order to obtain a pure multi-
modal CCG that is weakly equivalent to CCG in
the style of Vijay-Shanker and Weir (1994). Such
a modification would have to break the proof in
Section 4.2, which is harder than it may seem at
first glance. For instance, simply assuming a more
complex type system will not do it, because the
arguments ns3z and =s1y are eliminated using the
same rules in the original and the transformed deriv-
ations, so if the derivation step was valid before, it
will still be valid after the transformation. Instead,
we believe that it is necessary to make the composi-
tion rules sensitive to the categories inside ? and 
instead of only the arguments ns3z and =s1y, and
we can see two ways how to do this.
First, one could imagine a version of multi-
modal CCG with unary modalities that can be used
to mark certain category occurrences. In such an
MM-CCG, the composition rules for a certain slash
type could be made sensitive to the presence or
absence of unary modalities in ?. Say for instance
that the slash type s1 in the modalized version of
R3 in Section 4.2 would require that no category in
the secondary argument is marked with the unary
modality ??, but ? contains a category marked
with ??. Then the transformed derivation would
be ungrammatical.
A second approach concerns the precise defin-
ition of the generalized composition rules, about
which there is a surprising degree of disagreement.
We have followed Hockenmaier and Young (2008)
in classifying instances of generalized forward
composition as harmonic if the innermost slash of
the secondary argument is forward and crossed if
it is backward. However, generalized forward com-
position is sometimes only accepted as harmonic
if all slashes of the secondary argument are for-
ward (see e.g. Baldridge (2002) (40, 41), Steedman
(2001) (19)). At the same time, based on the prin-
ciple that CCG rules should be derived from proofs
of Categorial Type Logic as Baldridge (2002) does,
it can be argued that generalized composition rules
of the form x=y y=znw ) x=znw, which we
have considered as harmonic, should actually be
classified as crossed, due to the presence of a slash
of opposite directionality in front of the w. This
definition would break our proof. Thus our res-
ult might motivate further research on the ?correct?
definition of generalized composition rules, which
might then strengthen the generative capacity of
pure MM-CCG.
5 Conclusion
In this paper, we have shown that the weak generat-
ive capacity of pure CCG and even pure B&K-CCG
crucially depends on the ability to restrict the ap-
plication of individual rules. This means that these
formalisms cannot be fully lexicalized, in the sense
that certain languages can only be described by
selecting language-specific rules.
Our result generalizes Koller and Kuhlmann?s
(2009) result for pure first-order CCG. Our proof
is not as different as it looks at first glance, as
their construction of mapping a CCG derivation to
a valency tree and back to a derivation provides a
different transformation on derivation trees. Our
transformation is also technically related to the nor-
mal form construction for CCG parsing presented
by Eisner (1996).
Of course, at the end of the day, the issue that is
more relevant to computational linguistics than a
formalism?s ability to generate artificial languages
such as L3 is how useful it is for modeling natural
languages. CCG, and multi-modal CCG in partic-
ular, has a very good track record for this. In this
sense, our formal result can also be understood as
a contribution to a discussion about the expressive
power that is needed to model natural languages.
Acknowledgments
We have profited enormously from discussions with
Jason Baldridge and Mark Steedman, and would
also like to thank the anonymous reviewers for their
detailed comments.
542
References
Franz Baader and Tobias Nipkow. 1998. Term Rewrit-
ing and All That. Cambridge University Press.
Jason Baldridge and Geert-Jan M. Kruijff. 2003.
Multi-modal Combinatory Categorial Grammar.
In Proceedings of the Tenth Conference of the
European Chapter of the Association for Compu-
tational Linguistics (EACL), pages 211?218, Bud-
apest, Hungary.
Jason Baldridge. 2002. Lexically Specified Deriva-
tional Control in Combinatory Categorial Grammar.
Ph.D. thesis, University of Edinburgh.
Yehoshua Bar-Hillel, Haim Gaifman, and Eli Shamir.
1964. On categorial and phrase structure gram-
mars. In Language and Information: Selected Es-
says on their Theory and Application, pages 99?115.
Addison-Wesley.
Johan Bos, Stephen Clark, Mark Steedman, James R.
Curran, and Julia Hockenmaier. 2004. Wide-
coverage semantic representations from a CCG
parser. In Proceedings of the 20th International
Conference on Computational Linguistics (COL-
ING), pages 176?182, Geneva, Switzerland.
Stephen Clark and James Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4).
Haskell B. Curry, Robert Feys, and William Craig.
1958. Combinatory Logic. Volume 1. Studies in
Logic and the Foundations of Mathematics. North-
Holland.
Jason Eisner. 1996. Efficient normal-form parsing
for combinatory categorial grammar. In Proceed-
ings of the 34th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 79?86,
Santa Cruz, CA, USA.
Julia Hockenmaier and Mark Steedman. 2002. Gen-
erative models for statistical parsing with Combin-
atory Categorial Grammar. In Proceedings of the
40th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 335?342, Phil-
adelphia, USA.
Julia Hockenmaier and Peter Young. 2008. Non-local
scrambling: the equivalence of TAG and CCG revis-
ited. In Proceedings of the 9th Internal Workshop on
Tree Adjoining Grammars and Related Formalisms
(TAG+9), T?bingen, Germany.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
Adjoining Grammars. In Grzegorz Rozenberg and
Arto Salomaa, editors, Handbook of Formal Lan-
guages, volume 3, pages 69?123. Springer.
Alexander Koller and Marco Kuhlmann. 2009. De-
pendency trees and the strong generative capacity of
CCG. In Proceedings of the Twelfth Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL), pages 460?468, Athens,
Greece.
Michael Moortgat. 1997. Categorial type logics. In
Handbook of Logic and Language, chapter 2, pages
93?177. Elsevier.
David Reitter, Julia Hockenmaier, and Frank Keller.
2006. Priming effects in combinatory categorial
grammar. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 308?316, Sydney, Australia.
Mark Steedman and Jason Baldridge. 2010. Combin-
atory categorial grammar. In R. Borsley and K. Bor-
jars, editors, Non-Transformational Syntax. Black-
well. Draft 7.0, to appear.
Mark Steedman. 2001. The Syntactic Process. MIT
Press.
K. Vijay-Shanker and David J. Weir. 1994. The equi-
valence of four extensions of context-free grammars.
Mathematical Systems Theory, 27(6):511?546.
David J. Weir and Aravind K. Joshi. 1988. Combinat-
ory categorial grammars: Generative power and rela-
tionship to linear context-free rewriting systems. In
Proceedings of the 26th Annual Meeting of the As-
sociation for Computational Linguistics, pages 278?
285, Buffalo, NY, USA.
543
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 979?988,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Learning Script Knowledge with Web Experiments
Michaela Regneri Alexander Koller
Department of Computational Linguistics and Cluster of Excellence
Saarland University, Saarbru?cken
{regneri|koller|pinkal}@coli.uni-saarland.de
Manfred Pinkal
Abstract
We describe a novel approach to unsuper-
vised learning of the events that make up
a script, along with constraints on their
temporal ordering. We collect natural-
language descriptions of script-specific
event sequences from volunteers over the
Internet. Then we compute a graph rep-
resentation of the script?s temporal struc-
ture using a multiple sequence alignment
algorithm. The evaluation of our system
shows that we outperform two informed
baselines.
1 Introduction
A script is ?a standardized sequence of events that
describes some stereotypical human activity such
as going to a restaurant or visiting a doctor? (Barr
and Feigenbaum, 1981). Scripts are fundamental
pieces of commonsense knowledge that are shared
between the different members of the same cul-
ture, and thus a speaker assumes them to be tac-
itly understood by a hearer when a scenario re-
lated to a script is evoked: When one person says
?I?m going shopping?, it is an acceptable reply
to say ?did you bring enough money??, because
the SHOPPING script involves a ?payment? event,
which again involves the transfer of money.
It has long been recognized that text under-
standing systems would benefit from the implicit
information represented by a script (Cullingford,
1977; Mueller, 2004; Miikkulainen, 1995). There
are many other potential applications, includ-
ing automated storytelling (Swanson and Gordon,
2008), anaphora resolution (McTear, 1987), and
information extraction (Rau et al, 1989).
However, it is also commonly accepted that the
large-scale manual formalization of scripts is in-
feasible. While there have been a few attempts at
doing this (Mueller, 1998; Gordon, 2001), efforts
in which expert annotators create script knowledge
bases clearly don?t scale. The same holds true of
the script-like structures called ?scenario frames?
in FrameNet (Baker et al, 1998).
There has recently been a surge of interest in
automatically learning script-like knowledge re-
sources from corpora (Chambers and Jurafsky,
2008b; Manshadi et al, 2008); but while these
efforts have achieved impressive results, they are
limited by the very fact that a lot of scripts ? such
as SHOPPING ? are shared implicit knowledge, and
their events are therefore rarely elaborated in text.
In this paper, we propose a different approach
to the unsupervised learning of script-like knowl-
edge. We focus on the temporal event structure of
scripts; that is, we aim to learn what phrases can
describe the same event in a script, and what con-
straints must hold on the temporal order in which
these events occur. We approach this problem by
asking non-experts to describe typical event se-
quences in a given scenario over the Internet. This
allows us to assemble large and varied collections
of event sequence descriptions (ESDs), which are
focused on a single scenario. We then compute a
temporal script graph for the scenario by identify-
ing corresponding event descriptions using a Mul-
tiple Sequence Alignment algorithm from bioin-
formatics, and converting the alignment into a
graph. This graph makes statements about what
phrases can describe the same event of a scenario,
and in what order these events can take place. Cru-
cially, our algorithm exploits the sequential struc-
ture of the ESDs to distinguish event descriptions
that occur at different points in the script storyline,
even when they are semantically similar. We eval-
uate our script graph algorithm on ten unseen sce-
narios, and show that it significantly outperforms
a clustering-based baseline.
The paper is structured as follows. We will
first position our research in the landscape of re-
lated work in Section 2. We will then define how
979
we understand scripts, and what aspect of scripts
we model here, in Section 3. Section 4 describes
our data collection method, and Section 5 explains
how we use Multiple Sequence Alignment to com-
pute a temporal script graph. We evaluate our sys-
tem in Section 6 and conclude in Section 7.
2 Related Work
Approaches to learning script-like knowledge are
not new. For instance, Mooney (1990) describes
an early attempt to acquire causal chains, and
Smith and Arnold (2009) use a graph-based algo-
rithm to learn temporal script structures. However,
to our knowledge, such approaches have never
been shown to generalize sufficiently for wide
coverage application, and none of them was rig-
orously evaluated.
More recently, there have been a number of ap-
proaches to automatically learning event chains
from corpora (Chambers and Jurafsky, 2008b;
Chambers and Jurafsky, 2009; Manshadi et al,
2008). These systems typically employ a method
for classifying temporal relations between given
event descriptions (Chambers et al, 2007; Cham-
bers and Jurafsky, 2008a; Mani et al, 2006).
They achieve impressive performance at extract-
ing high-level descriptions of procedures such as
a CRIMINAL PROCESS. Because our approach in-
volves directly asking people for event sequence
descriptions, it can focus on acquiring specific
scripts from arbitrary domains, and we can con-
trol the level of granularity at which scripts are
described. Furthermore, we believe that much
information about scripts is usually left implicit
in texts and is therefore easier to learn from our
more explicit data. Finally, our system automat-
ically learns different phrases which describe the
same event together with the temporal ordering
constraints.
Jones and Thompson (2003) describe an ap-
proach to identifying different natural language re-
alizations for the same event considering the tem-
poral structure of a scenario. However, they don?t
aim to acquire or represent the temporal structure
of the whole script in the end.
In its ability to learn paraphrases using Mul-
tiple Sequence Alignment, our system is related
to Barzilay and Lee (2003). Unlike Barzilay and
Lee, we do not tackle the general paraphrase prob-
lem, but only consider whether two phrases de-
scribe the same event in the context of the same
script. Furthermore, the atomic units of our align-
ment process are entire phrases, while in Barzilay
and Lee?s setting, the atomic units are words.
Finally, it is worth pointing out that our work
is placed in the growing landscape of research
that attempts to learn linguistic information out of
data directly collected from users over the Inter-
net. Some examples are the general acquisition of
commonsense knowledge (Singh et al, 2002), the
use of browser games for that purpose (von Ahn
and Dabbish, 2008), and the collaborative anno-
tation of anaphoric reference (Chamberlain et al,
2009). In particular, the use of the Amazon Me-
chanical Turk, which we use here, has been evalu-
ated and shown to be useful for language process-
ing tasks (Snow et al, 2008).
3 Scripts
Before we delve into the technical details, let us
establish some terminology. In this paper, we dis-
tinguish scenarios, as classes of human activities,
from scripts, which are stereotypical models of the
internal structure of these activities. Where EAT-
ING IN A RESTAURANT is a scenario, the script
describes a number of events, such as ordering and
leaving, that must occur in a certain order in order
to constitute an EATING IN A RESTAURANT activ-
ity. The classical perspective on scripts (Schank
and Abelson, 1977) has been that next to defin-
ing some events with temporal constraints, a script
also defines their participants and their causal con-
nections.
Here we focus on the narrower task of learning
the events that a script consists of, and of model-
ing and learning the temporal ordering constraints
that hold between them. Formally, we will spec-
ify a script (in this simplified sense) in terms of a
directed graph Gs = (Es, Ts), where Es is a set
of nodes representing the events of a scenario s,
and Ts is a set of edges (ei, ek) indicating that the
event ei typically happens before ek in s. We call
Gs the temporal script graph (TSG) for s.
Each event in a TSG can usually be expressed
with many different natural-language phrases. As
the TSG in Fig. 3 illustrates, the first event in the
script for EATING IN A FAST FOOD RESTAURANT
can be equivalently described as ?walk to the
counter? or ?walk up to the counter?; even phrases
like ?walk into restaurant?, which would not usu-
ally be taken as paraphrases of these, can be ac-
cepted as describing the same event in the context
980
  1. walk into restaurant
  2. find the end of the line
  3. stand in line
  4. look at menu board
  5. decide on food and drink
  6. tell cashier your order
  7. listen to cashier repeat order
  8. listen for total price
  9. swipe credit card in scanner
 10. put up credit card
 11. take receipt
 12. look at order number
 13. take your cup
 14. stand off to the side
 15. wait for number to be called
 16. get your drink
 1. look at menu
 2. decide what you want
 3. order at counter
 4. pay at counter
 5. receive food at counter 
 6. take food to table
 7. eat food
 1. walk to the counter
 2. place an order
 3. pay the bill
 4. wait for the ordered food
 5. get the food
 6. move to a table
 7. eat food
 8. exit the place
Figure 1: Three event sequence descriptions
of this scenario. We call a natural-language real-
ization of an individual event in the script an event
description, and we call a sequence of event de-
scriptions that form one particular instance of the
script an event sequence description (ESD). Ex-
amples of ESDs for the FAST FOOD RESTAURANT
script are shown in Fig. 1.
One way to look at a TSG is thus that its nodes
are equivalence classes of different phrases that
describe the same event; another is that valid ESDs
can be generated from a TSG by randomly select-
ing phrases from some nodes and arranging them
in an order that respects the temporal precedence
constraints in Ts. Our goal in this paper is to take
a set of ESDs for a given scenario as our input
and then compute a TSG that clusters different de-
scriptions of the same event into the same node,
and contains edges that generalize the temporal in-
formation encoded in the ESDs.
4 Data Acquisition
In order to automatically learn TSGs, we selected
22 scenarios for which we collect ESDs. We de-
liberately included scenarios of varying complex-
ity, including some that we considered hard to
describe (CHILDHOOD, CREATE A HOMEPAGE),
scenarios with highly variable orderings between
events (MAKING SCRAMBLED EGGS), and sce-
narios for which we expected cultural differences
(WEDDING).
We used the Amazon Mechanical Turk1 to col-
lect the data. For every scenario, we asked 25 peo-
ple to enter a typical sequence of events in this sce-
nario, in temporal order and in ?bullet point style?.
1http://www.mturk.com/
We required the annotators to enter at least 5 and
at most 16 events. Participants were allowed to
skip a scenario if they felt unable to enter events
for it, but had to indicate why. We did not restrict
the participants (e.g. to native speakers).
In this way, we collected 493 ESDs for the 22
scenarios. People used the possibility to skip a
form 57 times. The most frequent explanation for
this was that they didn?t know how a certain sce-
nario works: The scenario with the highest pro-
portion of skipped forms was CREATE A HOME-
PAGE, whereas MAKING SCRAMBLED EGGS was
the only one in which nobody skipped a form. Be-
cause we did not restrict the participants? inputs,
the data was fairly noisy. For the purpose of this
study, we manually corrected the data for orthog-
raphy and filtered out forms that were written in
broken English or did not comply with the task
(e.g. when users misunderstood the scenario, or
did not list the event descriptions in temporal or-
der). Overall we discarded 15% of the ESDs.
Fig. 1 shows three of the ESDs we collected
for EATING IN A FAST-FOOD RESTAURANT. As
the example illustrates, descriptions differ in their
starting points (?walk into restaurant? vs. ?walk to
counter?), the granularity of the descriptions (?pay
the bill? vs. event descriptions 8?11 in the third
sequence), and the events that are mentioned in
the sequence (not even ?eat food? is mentioned in
all ESDs). Overall, the ESDs we collected con-
sisted of 9 events on average, but their lengths var-
ied widely: For most scenarios, there were sig-
nificant numbers of ESDs both with the minimum
length of 5 and the maximum length of 16 and ev-
erything in between. Combined with the fact that
93% of all individual event descriptions occurred
only once, this makes it challenging to align the
different ESDs with each other.
5 Temporal Script Graphs
We will now describe how we compute a temporal
script graph out of the collected data. We proceed
in two steps. First, we identify phrases from dif-
ferent ESDs that describe the same event by com-
puting a Multiple Sequence Alignment (MSA) of
all ESDs for the same scenario. Then we postpro-
cess the MSA and convert it into a temporal script
graph, which encodes and generalizes the tempo-
ral information contained in the original ESDs.
981
row s1 s2 s3 s4
1  walk into restaurant  enter restaurant
2   walk to the counter go to counter
3  find the end of the line  
4  stand in line  
5 look at menu look at menu board  
6 decide what you want decide on food and drink  make selection
7 order at counter tell cashier your order place an order place order
8  listen to cashier repeat order  
9 pay at counter  pay the bill pay for food
10  listen for total price  
11  swipe credit card in scanner  
12  put up credit card  
13  take receipt  
14  look at order number  
15  take your cup  
16  stand off to the side  
17  wait for number to be called wait for the ordered food 
18 receive food at counter get your drink get the food pick up order
19    pick up condiments
20 take food to table  move to a table go to table
21 eat food  eat food consume food
22    clear tray
22   exit the place 
Figure 2: A MSA of four event sequence descriptions
5.1 Multiple Sequence Alignment
The problem of computing Multiple Sequence
Alignments comes from bioinformatics, where it
is typically used to find corresponding elements in
proteins or DNA (Durbin et al, 1998).
A sequence alignment algorithm takes as its in-
put some sequences s1, . . . , sn ? ?? over some al-
phabet ?, along with a cost function cm : ????
R for substitutions and gap costs cgap ? R for in-
sertions and deletions. In bioinformatics, the ele-
ments of ? could be nucleotides and a sequence
could be a DNA sequence; in our case, ? contains
the individual event descriptions in our data, and
the sequences are the ESDs.
A Multiple Sequence Alignment A of these se-
quences is then a matrix as in Fig. 2: The i-th col-
umn of A is the sequence si, possibly with some
gaps (??) interspersed between the symbols of
si, such that each row contains at least one non-
gap. If a row contains two non-gaps, we take these
symbols to be aligned; aligning a non-gap with a
gap can be thought of as an insertion or deletion.
Each sequence alignment A can be assigned a
cost c(A) in the following way:
c(A) = cgap ? ? +
n?
i=1
m?
j=1,
aji 6=
m?
k=j+1,
aki 6=
cm(aji, aki)
where ? is the number of gaps in A, n is the
number of rows and m the number of sequences.
In other words, we sum up the alignment cost for
any two symbols from ? that are aligned with
each other, and add the gap cost for each gap.
There is an algorithm that computes cheapest pair-
wise alignments (i.e. n = 2) in polynomial time
(Needleman and Wunsch, 1970). For n > 2, the
problem is NP-complete, but there are efficient al-
gorithms that approximate the cheapest MSAs by
aligning two sequences first, considering the result
as a single sequence whose elements are pairs, and
repeating this process until all sequences are incor-
porated in the MSA (Higgins and Sharp, 1988).
5.2 Semantic similarity
In order to apply MSA to the problem of aligning
ESDs, we choose ? to be the set of all individ-
ual event descriptions in a given scenario. Intu-
itively, we want the MSA to prefer the alignment
of two phrases if they are semantically similar, i.e.
it should cost more to align ?exit? with ?eat? than
?exit? with ?leave?. Thus we take a measure of se-
mantic (dis)similarity as the cost function cm.
The phrases to be compared are written in
bullet-point style. They are typically short and
elliptic (no overt subject), they lack determiners
and use infinitive or present progressive form for
the main verb. Also, the lexicon differs consider-
ably from usual newspaper corpora. For these rea-
sons, standard methods for similarity assessment
are not straightforwardly applicable: Simple bag-
of-words approaches do not provide sufficiently
good results, and standard taggers and parsers can-
not process our descriptions with sufficient accu-
racy.
We therefore employ a simple, robust heuristics,
which is tailored to our data and provides very
982
get in line
enter restaurant
stand in line
wait in line
look at menu board
wait in line to order my food
examine menu board
look at the menu
look at menu
go to cashier
go to ordering counter
go to counter
i decide what i want
decide what to eat
decide on food and drink
decide on what to order
make selection
decide what you want
order food
i order it
tell cashier your order
order items from wall menu
order my food
place an order
order at counter
place order
pay at counter
pay for the food
pay for food
give order to the employee
pay the bill
pay
pay for the food and drinks
pay for order
collect utensils
pay for order
pick up order
make payment
keep my receipt
take receipt
wait for my order
look at prices
wait
look at order number
wait for order to be done
wait for food to be ready
wait for order
wait for the ordered food
expect order
wait for food
pick up condiments
take your cup
receive food
take food to table
receive tray with order
get condiments
get the food
receive food at counter
pick up food when ready
get my order
get food
move to a table
sit down
wait for number to be called
seat at a table
sit down at table
leave
walk into the reasturant
walk up to the counter
walk into restaurant
go to restaurant
walk to the counter
Figure 3: An extract from the graph computed for EATING IN A FAST FOOD RESTAURANT
shallow dependency-style syntactic information.
We identify the first potential verb of the phrase
(according to the POS information provided by
WordNet) as the predicate, the preceding noun (if
any) as subject, and all following potential nouns
as objects. (With this fairly crude tagging method,
we also count nouns in prepositional phrases as
?objects?.)
On the basis of this pseudo-parse, we compute
the similarity measure sim:
sim = ? ? pred+ ? ? subj + ? ? obj
where pred, subj, and obj are the similarity val-
ues for predicates, subjects and objects respec-
tively, and ?, ?, ? are weights. If a constituent
is not present in one of the phrases to compare,
we set its weight to zero and redistribute it over
the other weights. We fix the individual simi-
larity scores pred, subj, and obj depending on
the WordNet relation between the most similar
WordNet senses of the respective lemmas (100 for
synonyms, 0 for lemmas without any relation, and
intermediate numbers for different kind of Word-
Net links).
We optimized the values for pred, subj, and
obj as well as the weights ?, ? and ? using a
held-out development set of scenarios. Our exper-
iments showed that in most cases, the verb con-
tributes the largest part to the similarity (accord-
ingly, ? needs to be higher than the other factors).
We achieved improved accuracy by distinguishing
a class of verbs that contribute little to the meaning
of the phrase (i.e., support verbs, verbs of move-
ment, and the verb ?get?), and assigning them a
separate, lower ?.
5.3 Building Temporal Script Graphs
We can now compute a low-cost MSA for each
scenario out of the ESDs. From this alignment, we
extract a temporal script graph, in the following
way. First, we construct an initial graph which has
one node for each row of the MSA as in Fig. 2. We
interpret each node of the graph as representing
a single event in the script, and the phrases that
are collected in the node as different descriptions
of this event; that is, we claim that these phrases
are paraphrases in the context of this scenario. We
then add an edge (u, v) to the graph iff (1) u 6=
v, (2) there was at least one ESD in the original
data in which some phrase in u directly preceded
some phrase in v, and (3) if a single ESD contains
a phrase from u and from v, the phrase from u
directly precedes the one from v. In terms of the
MSA, this means that if a phrase from u comes
from the same column as a phrase from v, there
are at most some gaps between them. This initial
graph represents exactly the same information as
the MSA, in a different notation.
The graph is automatically post-processed in
a second step to simplify it and eliminate noise
that caused MSA errors. At first we prune spu-
rious nodes which contain only one event descrip-
tion. Then we refine the graph by merging nodes
whose elements should have been aligned in the
first place but were missed by the MSA. We merge
two nodes if they satisfy certain structural and se-
mantic constraints.
The semantic constraints check whether the
event descriptions of the merged node would be
sufficiently consistent according to the similarity
measure from Section 5.2. To check whether we
can merge two nodes u and v, we use an unsuper-
vised clustering algorithm (Flake et al, 2004) to
983
first cluster the event descriptions in u and v sep-
arately. Then we combine the event descriptions
from u and v and cluster the resulting set. If the
union has more clusters than either u or v, we as-
sume the nodes to be too dissimilar for merging.
The structural constraints depend on the graph
structure. We only merge two nodes u and v if
their event descriptions come from different se-
quences and one of the following conditions holds:
? u and v have the same parent;
? u has only one parent, v is its only child;
? v has only one child and is the only child of
u;
? all children of u (except for v) are also chil-
dren of v.
These structural constraints prevent the merg-
ing algorithm from introducing new temporal re-
lations that are not supported by the input ESDs.
We take the output of this post-processing step
as the temporal script graph. An excerpt of the
graph we obtain for our running example is shown
in Fig. 3. One node created by the node merg-
ing step was the top left one, which combines one
original node containing ?walk into restaurant? and
another with ?go to restaurant?. The graph mostly
groups phrases together into event nodes quite
well, although there are some exceptions, such as
the ?collect utensils? node. Similarly, the tempo-
ral information in the graph is pretty accurate. But
perhaps most importantly, our MSA-based algo-
rithm manages to keep similar phrases like ?wait
in line? and ?wait for my order? apart by exploiting
the sequential structure of the input ESDs.
6 Evaluation
We evaluated the two core aspects of our sys-
tem: its ability to recognize descriptions of the
same event (paraphrases) and the resulting tem-
poral constraints it defines on the event descrip-
tions (happens-before relation). We compare our
approach to two baseline systems and show that
our system outperforms both baselines and some-
times even comes close to our upper bound.
6.1 Method
We selected ten scenarios which we did not use
for development purposes, five of them taken from
the corpus described in Section 4, the other five
from the OMICS corpus.2 The OMICS corpus is a
freely available, web-collected corpus by the Open
Mind Initiative (Singh et al, 2002). It contains
several stories (? scenarios) consisting of multi-
ple ESDs. The corpus strongly resembles ours in
language style and information provided, but is re-
stricted to ?indoor activities? and contains much
more data than our collection (175 scenarios with
more than 40 ESDs each).
For each scenario, we created a paraphrase set
out of 30 randomly selected pairs of event de-
scriptions which the system classified as para-
phrases and 30 completely random pairs. The
happens-before set consisted of 30 pairs classified
as happens-before, 30 random pairs and addition-
ally all 60 pairs in reverse order. We added the
reversed pairs to check whether the raters really
prefer one direction or whether they accept both
and were biased by the order of presentation.
We presented each pair to 5 non-experts, all
US residents, via Mechanical Turk. For the para-
phrase set, an exemplary question we asked the
rater looks as follows, instantiating the Scenario
and the two descriptions to compare appropriately:
Imagine two people, both telling a story
about SCENARIO. Could the first one
say event2 to describe the same part of
the story that the second one describes
with event1 ?
For the happens-before task, the question template
was the following:
Imagine somebody telling a story about
SCENARIO in which the events event1
and event2 occur. Would event1 nor-
mally happen before event2?
We constructed a gold standard by a majority deci-
sion of the raters. An expert rater adjudicated the
pairs with a 3:2 vote ratio.
6.2 Upper Bound and Baselines
To show the contributions of the different system
components, we implemented two baselines:
Clustering Baseline: We employed an unsu-
pervised clustering algorithm (Flake et al, 2004)
and fed it all event descriptions of a scenario. We
first created a similarity graph with one node per
event description. Each pair of nodes is connected
2http://openmind.hri-us.com/
984
SCENARIO
PRECISION RECALL F-SCORE
sys basecl baselev sys basecl baselev sys basecl baselev upper
M
T
U
R
K
pay with credit card 0.52 0.43 0.50 0.84 0.89 0.11 0.64 0.58 ? 0.17 0.60
eat in restaurant 0.70 0.42 0.75 0.88 1.00 0.25 0.78 ? 0.59 ? 0.38 ? 0.92
iron clothes I 0.52 0.32 1.00 0.94 1.00 0.12 0.67 ? 0.48 ? 0.21 ? 0.82
cook scrambled eggs 0.58 0.34 0.50 0.86 0.95 0.10 0.69 ? 0.50 ? 0.16 ? 0.91
take a bus 0.65 0.42 0.40 0.87 1.00 0.09 0.74 ? 0.59 ? 0.14 ? 0.88
O
M
IC
S
answer the phone 0.93 0.45 0.70 0.85 1.00 0.21 0.89 ? 0.71 ? 0.33 0.79
buy from vending machine 0.59 0.43 0.59 0.83 1.00 0.54 0.69 0.60 0.57 0.80
iron clothes II 0.57 0.30 0.33 0.94 1.00 0.22 0.71 ? 0.46 ? 0.27 0.77
make coffee 0.50 0.27 0.56 0.94 1.00 0.31 0.65 ? 0.42 ? 0.40 ? 0.82
make omelette 0.75 0.54 0.67 0.92 0.96 0.23 0.83 ? 0.69 ? 0.34 0.85
AVERAGE 0.63 0.40 0.60 0.89 0.98 0.22 0.73 0.56 0.30 0.82
Figure 4: Results for paraphrasing task; significance of difference to sys: ? : p ? 0.01, ? : p ? 0.1
with a weighted edge; the weight reflects the se-
mantic similarity of the nodes? event descriptions
as described in Section 5.2. To include all input in-
formation on inequality of events, we did not allow
for edges between nodes containing two descrip-
tions occurring together in one ESD. The underly-
ing assumption here is that two different event de-
scriptions of the same ESD always represent dis-
tinct events.
The clustering algorithm uses a parameter
which influences the cluster granularity, without
determining the exact number of clusters before-
hand. We optimized this parameter automatically
for each scenario: The system picks the value that
yields the optimal result with respect to density
and distance of the clusters (Flake et al, 2004),
i.e. the elements of each cluster are as similar as
possible to each other, and as dissimilar as possi-
ble to the elements of all other clusters.
The clustering baseline considers two phrases
as paraphrases if they are in the same cluster. It
claims a happens-before relation between phrases
e and f if some phrase in e?s cluster precedes
some phrase in f ?s cluster in the original ESDs.
With this baseline, we can show the contribution
of MSA.
Levenshtein Baseline: This system follows the
same steps as our system, but using Levenshtein
distance as the measure of semantic similarity for
MSA and for node merging (cf. Section 5.3). This
lets us measure the contribution of the more fine-
grained similarity function. We computed Leven-
shtein distance as the character-wise edit distance
on the phrases, divided by the phrases? character
length so as to get comparable values for shorter
and longer phrases. The gap costs for MSA with
Levenshtein were optimized on our development
set so as to produce the best possible alignment.
Upper bound: We also compared our system
to a human-performance upper bound. Because no
single annotator rated all pairs of ESDs, we con-
structed a ?virtual annotator? as a point of com-
parison, by randomly selecting one of the human
annotations for each pair.
6.3 Results
We calculated precision, recall, and f-score for our
system, the baselines, and the upper bound as fol-
lows, with allsystem being the number of pairs la-
belled as paraphrase or happens-before, allgold as
the respective number of pairs in the gold standard
and correct as the number of pairs labeled cor-
rectly by the system.precision = correctallsystem recall = correctallgold
f -score = 2 ? precision ? recallprecision+ recall
The tables in Fig. 4 and 5 show the results of our
system and the reference values; Fig. 4 describes
the paraphrasing task and Fig. 5 the happens-
before task. The upper half of the tables describes
the test sets from our own corpus, the remainder
refers to OMICS data. The columns labelled sys
contain the results of our system, basecl describes
the clustering baseline and baselev the Levenshtein
baseline. The f-score for the upper bound is in the
column upper. For the f-score values, we calcu-
lated the significance for the difference between
our system and the baselines as well as the upper
bound, using a resampling test (Edgington, 1986).
The values marked with ? differ from our system
significantly at a level of p ? 0.01, ?marks a level
of p ? 0.1. The remaining values are not signifi-
cant with p ? 0.1. (For the average values, no sig-
985
SCENARIO
PRECISION RECALL F-SCORE
sys basecl baselev sys basecl baselev sys basecl baselev upper
M
T
U
R
K
pay with credit card 0.86 0.49 0.65 0.84 0.74 0.45 0.85 ? 0.59 ? 0.53 0.92
eat in restaurant 0.78 0.48 0.68 0.84 0.98 0.75 0.81 ? 0.64 0.71 ? 0.95
iron clothes I 0.78 0.54 0.75 0.72 0.95 0.53 0.75 0.69 ? 0.62 ? 0.92
cook scrambled eggs 0.67 0.54 0.55 0.64 0.98 0.69 0.66 0.70 0.61 ? 0.88
take a bus 0.80 0.49 0.68 0.80 1.00 0.37 0.80 ? 0.66 ? 0.48 ? 0.96
O
M
IC
S
answer the phone 0.83 0.48 0.79 0.86 1.00 0.96 0.84 ? 0.64 0.87 0.90
buy from vending machine 0.84 0.51 0.69 0.85 0.90 0.75 0.84 ? 0.66 ? 0.71 0.83
iron clothes II 0.78 0.48 0.75 0.80 0.96 0.66 0.79 ? 0.64 0.70 0.84
make coffee 0.70 0.55 0.50 0.78 1.00 0.55 0.74 0.71 ? 0.53 ? 0.83
make omelette 0.70 0.55 0.79 0.83 0.93 0.82 0.76 ? 0.69 0.81 ? 0.92
AVERAGE 0.77 0.51 0.68 0.80 0.95 0.65 0.78 0.66 0.66 0.90
Figure 5: Results for happens-before task; significance of difference to sys: ? : p ? 0.01, ? : p ? 0.1
nificance is calculated because this does not make
sense for scenario-wise evaluation.)
Paraphrase task: Our system outperforms
both baselines clearly, reaching significantly
higher f-scores in 17 of 20 cases. Moreover, for
five scenarios, the upper bound does not differ sig-
nificantly from our system. For judging the pre-
cision, consider that the test set is slightly biased:
Labeling all pairs with the majority category (no
paraphrase) would result in a precision of 0.64.
However, recall and f-score for this trivial lower
bound would be 0.
The only scenario in which our system doesn?t
score very well is BUY FROM A VENDING MA-
CHINE, where the upper bound is not significantly
better either. The clustering system, which can?t
exploit the sequential information from the ESDs,
has trouble distinguishing semantically similar
phrases (high recall, low precision). The Leven-
shtein similarity measure, on the other hand, is too
restrictive and thus results in comparatively high
precisions, but very low recall.
Happens-before task: In most cases, and on
average, our system is superior to both base-
lines. Where a baseline system performs better
than ours, the differences are not significant. In
four cases, our system does not differ significantly
from the upper bound. Regarding precision, our
system outperforms both baselines in all scenarios
except one (MAKE OMELETTE).
Again the clustering baseline is not fine-grained
enough and suffers from poor precision, only
slightly better than the majority baseline. The Lev-
enshtein baseline gets mostly poor recall, except
for ANSWER THE PHONE: to describe this sce-
nario, people used very similar wording. In such a
scenario, adding lexical knowledge to the sequen-
tial information makes less of a difference.
On average, the baselines do much better here
than for the paraphrase task. This is because once
a system decides on paraphrase clusters that are
essentially correct, it can retrieve correct informa-
tion about the temporal order directly from the
original ESDs.
Both tables illustrate that the task complexity
strongly depends on the scenario: Scripts that al-
low for a lot of variation with respect to ordering
(such as COOK SCRAMBLED EGGS) are particu-
larly challenging for our system. This is due to the
fact that our current system can neither represent
nor find out that two events can happen in arbitrary
order (e.g., ?take out pan? and ?take out bowl?).
One striking difference between the perfor-
mance of our system on the OMICS data and on
our own dataset is the relation to the upper bound:
On our own data, the upper bound is almost al-
ways significantly better than our system, whereas
significant differences are rare on OMICS. This
difference bears further analysis; we speculate it
might be caused either by the increased amount of
training data in OMICS or by differences in lan-
guage (e.g., fewer anaphoric references).
7 Conclusion
We conclude with a summary of this paper and
some discussion along with hints to future work
in the last part.
7.1 Summary
In this paper, we have described a novel approach
to the unsupervised learning of temporal script in-
formation. Our approach differs from previous
work in that we collect training data by directly
asking non-expert users to describe a scenario, and
986
then apply a Multiple Sequence Alignment algo-
rithm to extract scenario-specific paraphrase and
temporal ordering information. We showed that
our system outperforms two baselines and some-
times approaches human-level performance, espe-
cially because it can exploit the sequential struc-
ture of the script descriptions to separate clusters
of semantically similar events.
7.2 Discussion and Future Work
We believe that we can scale this approach to
model a large numbers of scenarios represent-
ing implicit shared knowledge. To realize this
goal, we are going to automatize several process-
ing steps that were done manually for the cur-
rent study. We will restrict the user input to lex-
icon words to avoid manual orthography correc-
tion. Further, we will implement some heuristics
to filter unusable instances by matching them with
the remaining data. As far as the data collection is
concerned, we plan to replace the web form with a
browser game, following the example of von Ahn
and Dabbish (2008). This game will feature an
algorithm that can generate new candidate scenar-
ios without any supervision, for instance by identi-
fying suitable sub-events of collected scripts (e.g.
inducing data collection for PAY as sub-event se-
quence of GO SHOPPING)
On the technical side, we intend to address the
question of detecting participants of the scripts and
integrating them into the graphs, Further, we plan
to move on to more elaborate data structures than
our current TSGs, and then identify and repre-
sent script elements like optional events, alterna-
tive events for the same step, and events that can
occur in arbitrary order.
Because our approach gathers information from
volunteers on the Web, it is limited by the knowl-
edge of these volunteers. We expect it will per-
form best for general commonsense knowledge;
culture-specific knowledge or domain-specific ex-
pert knowledge will be hard for it to learn. This
limitation could be addressed by targeting spe-
cific groups of online users, or by complementing
our approach with corpus-based methods, which
might perform well exactly where ours does not.
Acknowledgements
We want to thank Dustin Smith for the OMICS
data, Alexis Palmer for her support with Amazon
Mechanical Turk, Nils Bendfeldt for the creation
of all web forms and Ines Rehbein for her effort
with several parsing experiments. In particular, we
thank the anonymous reviewers for their helpful
comments. ? This work was funded by the Cluster
of Excellence ?Multimodal Computing and Inter-
action? in the German Excellence Initiative.
References
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceed-
ings of the 17th international conference on Compu-
tational linguistics, pages 86?90, Morristown, NJ,
USA. Association for Computational Linguistics.
Avron Barr and Edward Feigenbaum. 1981. The
Handbook of Artificial Intelligence, Volume 1.
William Kaufman Inc., Los Altos, CA.
Regina Barzilay and Lillian Lee. 2003. Learn-
ing to paraphrase: An unsupervised approach us-
ing multiple-sequence alignment. In Proceedings of
HLT-NAACL 2003.
Jon Chamberlain, Massimo Poesio, and Udo Kru-
schwitz. 2009. A demonstration of human compu-
tation using the phrase detectives annotation game.
In KDD Workshop on Human Computation. ACM.
Nathanael Chambers and Dan Jurafsky. 2008a. Jointly
combining implicit constraints improves temporal
ordering. In Proceedings of EMNLP 2008.
Nathanael Chambers and Dan Jurafsky. 2008b. Unsu-
pervised learning of narrative event chains. In Pro-
ceedings of ACL-08: HLT.
Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
pervised learning of narrative schemas and their par-
ticipants. In Proceedings of ACL-IJCNLP 2009.
Nathanael Chambers, Shan Wang, and Dan Juraf-
sky. 2007. Classifying temporal relations between
events. In Proceedings of ACL-07: Interactive
Poster and Demonstration Sessions.
Richard Edward Cullingford. 1977. Script applica-
tion: computer understanding of newspaper stories.
Ph.D. thesis, Yale University, New Haven, CT, USA.
Richard Durbin, Sean Eddy, Anders Krogh, and
Graeme Mitchison. 1998. Biological Sequence
Analysis. Cambridge University Press.
Eugene S Edgington. 1986. Randomization tests.
Marcel Dekker, Inc., New York, NY, USA.
Gary W. Flake, Robert E. Tarjan, and Kostas Tsiout-
siouliklis. 2004. Graph clustering and minimum cut
trees. Internet Mathematics, 1(4).
Andrew S. Gordon. 2001. Browsing image collec-
tions with representations of common-sense activi-
ties. JASIST, 52(11).
987
Desmond G. Higgins and Paul M. Sharp. 1988.
Clustal: a package for performing multiple sequence
alignment on a microcomputer. Gene, 73(1).
Dominic R. Jones and Cynthia A. Thompson. 2003.
Identifying events using similarity and context. In
Proceedings of CoNNL-2003.
Inderjeet Mani, Marc Verhagen, Ben Wellner,
Chong Min Lee, and James Pustejovsky. 2006.
Machine learning of temporal relations. In
COLING/ACL-2006.
Mehdi Manshadi, Reid Swanson, and Andrew S. Gor-
don. 2008. Learning a probabilistic model of event
sequences from internet weblog stories. In Proceed-
ings of the 21st FLAIRS Conference.
Michael McTear. 1987. The Articulate Computer.
Blackwell Publishers, Inc., Cambridge, MA, USA.
Risto Miikkulainen. 1995. Script-based inference and
memory retrieval in subsymbolic story processing.
Applied Intelligence, 5(2), 04.
Raymond J. Mooney. 1990. Learning plan schemata
from observation: Explanation-based learning for
plan recognition. Cognitive Science, 14(4).
Erik T. Mueller. 1998. Natural Language Processing
with Thought Treasure. Signiform.
Erik T. Mueller. 2004. Understanding script-based sto-
ries using commonsense reasoning. Cognitive Sys-
tems Research, 5(4).
Saul B. Needleman and Christian D. Wunsch. 1970.
A general method applicable to the search for simi-
larities in the amino acid sequence of two proteins.
Journal of molecular biology, 48(3), March.
Lisa F. Rau, Paul S. Jacobs, and Uri Zernik. 1989. In-
formation extraction and text summarization using
linguistic knowledge acquisition. Information Pro-
cessing and Management, 25(4):419 ? 428.
Roger C. Schank and Robert P. Abelson. 1977. Scripts,
Plans, Goals and Understanding. Lawrence Erl-
baum, Hillsdale, NJ.
Push Singh, Thomas Lin, Erik T. Mueller, Grace Lim,
Travell Perkins, and Wan L. Zhu. 2002. Open
mind common sense: Knowledge acquisition from
the general public. In On the Move to Meaningful
Internet Systems - DOA, CoopIS and ODBASE 2002,
London, UK. Springer-Verlag.
Dustin Smith and Kenneth C. Arnold. 2009. Learning
hierarchical plans by reading simple english narra-
tives. In Proceedings of the Commonsense Work-
shop at IUI-09.
Rion Snow, Brendan O?Connor, Daniel Jurafsky, and
Andrew Y. Ng. 2008. Cheap and fast?but is it
good?: evaluating non-expert annotations for natu-
ral language tasks. In Proceedings of EMNLP 2008.
Reid Swanson and Andrew S. Gordon. 2008. Say any-
thing: A massively collaborative open domain story
writing companion. In Proceedings of ICIDS 2008.
Luis von Ahn and Laura Dabbish. 2008. Designing
games with a purpose. Commun. ACM, 51(8).
988
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1573?1582,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Automated planning for situated natural language generation
Konstantina Garoufi and Alexander Koller
Cluster of Excellence ?Multimodal Computing and Interaction?
Saarland University, Saarbru?cken, Germany
{garoufi,koller}@mmci.uni-saarland.de
Abstract
We present a natural language genera-
tion approach which models, exploits, and
manipulates the non-linguistic context in
situated communication, using techniques
from AI planning. We show how to gen-
erate instructions which deliberately guide
the hearer to a location that is convenient
for the generation of simple referring ex-
pressions, and how to generate referring
expressions with context-dependent adjec-
tives. We implement and evaluate our
approach in the framework of the Chal-
lenge on Generating Instructions in Vir-
tual Environments, finding that it performs
well even under the constraints of real-
time generation.
1 Introduction
The problem of situated natural language gen-
eration (NLG)?i.e., of generating natural lan-
guage in the context of a physical (or virtual)
environment?has received increasing attention in
the past few years. On the one hand, this is be-
cause it is the foundation of various emerging ap-
plications, including human-robot interaction and
mobile navigation systems, and is the focus of a
current evaluation effort, the Challenges on Gener-
ating Instructions in Virtual Environments (GIVE;
(Koller et al, 2010b)). On the other hand, situated
generation comes with interesting theoretical chal-
lenges: Compared to the generation of pure text,
the interpretation of expressions in situated com-
munication is sensitive to the non-linguistic con-
text, and this context can change as easily as the
user can move around in the environment.
One interesting aspect of situated communica-
tion from an NLG perspective is that this non-
linguistic context can be manipulated by the
speaker. Consider the following segment of dis-
course between an instruction giver (IG) and an
instruction follower (IF), which is adapted from
the SCARE corpus (Stoia et al, 2008):
(1) IG: Walk forward and then turn right.
IF: (walks and turns)
IG: OK. Now hit the button in the middle.
In this example, the IG plans to refer to an ob-
ject (here, a button); and in order to do so, gives a
navigation instruction to guide the IF to a conve-
nient location at which she can then use a simple
referring expression (RE). That is, there is an inter-
action between navigation instructions (intended
to manipulate the non-linguistic context in a cer-
tain way) and referring expressions (which exploit
the non-linguistic context). Although such subdi-
alogues are common in SCARE, we are not aware
of any previous research that can generate them in
a computationally feasible manner.
This paper presents an approach to generation
which is able to model the effect of an utter-
ance on the non-linguistic context, and to inten-
tionally generate utterances such as the above as
part of a process of referring to objects. Our ap-
proach builds upon the CRISP generation system
(Koller and Stone, 2007), which translates gener-
ation problems into planning problems and solves
these with an AI planner. We extend the CRISP
planning operators with the perlocutionary effects
that uttering a particular word has on the physi-
cal environment if it is understood correctly; more
specifically, on the position and orientation of the
hearer. This allows the planner to predict the non-
linguistic context in which a later part of the ut-
terance will be interpreted, and therefore to search
for contexts that allow the use of simple REs. As a
result, the work of referring to an object gets dis-
tributed over multiple utterances of low cognitive
load rather than a single complex noun phrase.
A second contribution of our paper is the gen-
eration of REs involving context-dependent adjec-
tives: A button can be described as ?the left blue
1573
button? even if there is a red button to its left. We
model adjectives whose interpretation depends on
the nominal phrases they modify, as well as on the
non-linguistic context, by keeping track of the dis-
tractors that remain after uttering a series of mod-
ifiers. Thus, unlike most other RE generation ap-
proaches, we are not restricted to building an RE
by simply intersecting lexically specified sets rep-
resenting the extensions of different attributes, but
can correctly generate expressions whose mean-
ing depends on the context in a number of ways.
In this way we are able to refer to objects earlier
and more flexibly.
We implement and evaluate our approach in
the context of a GIVE NLG system, by using
the GIVE-1 software infrastructure and a GIVE-1
evaluation world. This shows that our system gen-
erates an instruction-giving discourse as in (1) in
about a second. It outperforms a mostly non-
situated baseline significantly, and compares well
against a second baseline based on one of the
top-performing systems of the GIVE-1 Challenge.
Next to the practical usefulness this evaluation es-
tablishes, we argue that our approach to jointly
modeling the grammatical and physical effects of
a communicative action can also inform new mod-
els of the pragmatics of speech acts.
Plan of the paper. We discuss related work in
Section 2, and review the CRISP system, on which
our work is based, in Section 3. We then show
in Section 4 how we extend CRISP to generate
navigation-and-reference discourses as in (1), and
add context-dependent adjectives in Section 5. We
evaluate our system in Section 6; Section 7 con-
cludes and points to future work.
2 Related work
The research reported here can be seen in the
wider context of approaches to generating refer-
ring expressions. Since the foundational work of
Dale and Reiter (1995), there has been a consider-
able amount of literature on this topic. Our work
departs from the mainstream in two ways. First, it
exploits the situated communicative setting to de-
liberately modify the context in which an RE is
generated. Second, unlike most other RE genera-
tion systems, we allow the contribution of a modi-
fier to an RE to depend both on the context and on
the rest of the RE.
We are aware of only one earlier study on gen-
eration of REs with focus on interleaving naviga-
tion and referring (Stoia et al, 2006). In this ma-
chine learning approach, Stoia et al train classi-
fiers that signal when the context conditions (e.g.
visibility of target and distractors) are appropriate
for the generation of an RE. This method can be
then used as part of a content selection component
of an NLG system. Such a component, however,
can only inform a system on whether to choose
navigation over RE generation at a given point of
the discourse, and is not able to help it decide
what kind of navigational instructions to generate
so that subsequent REs become simple.
To our knowledge, the only previous research
on generating REs with context-dependent modi-
fiers is van Deemter?s (2006) algorithm for gener-
ating vague adjectives. Unlike van Deemter, we
integrate the RE generation process tightly with
the syntactic realization, which allows us to gen-
erate REs with more than one context-dependent
modifier and model the effect of their linear or-
der on the meaning of the phrase. In modeling
the context, we focus on the non-linguistic con-
text and the influence of each of the RE?s words;
this is in contrast to previous research on context-
sensitive generation of REs, which mainly focused
on the discourse context (Krahmer and Theune,
2002). Our interpretation of context-dependent
modifiers picks up ideas by Kamp and Partee
(1995) and implements them in a practical system,
while our method of ordering modifiers is linguis-
tically informed by the class-based paradigm (e.g.,
Mitchell (2009)).
On the other hand, our work also stands in a tra-
dition of NLG research that is based on AI plan-
ning. Early approaches (Perrault and Allen, 1980;
Appelt, 1985) provided compelling intuitions for
this connection, but were not computationally vi-
able. The research we report here can be seen
as combining Appelt?s idea of using planning for
sentence-level NLG with a computationally be-
nign variant of Perrault et al?s approach of model-
ing the intended perlocutionary effects of a speech
act as the effects of a planning operator. Our work
is linked to a growing body of very recent work
that applies modern planning research to various
problems in NLG (Steedman and Petrick, 2007;
Brenner and Kruijff-Korbayova?, 2008; Benotti,
2009). It is directly based on Koller and Stone?s
(2007) reimplementation of the SPUD generator
(Stone et al, 2003) with planning. As far as we
know, ours is the first system in the SPUD tradi-
1574
S:self
NP:subj ? 
VP:self
V:self
pushes
NP:obj ? 
semcontent: {push(self,subj,obj)}
John
NP:self
semcontent: {John(self)}
NP:self
the
N:self
button
semcontent: {button(self)}
N:self
red N * 
semcontent: {red(self)}
(a)
S:e
NP:j ? 
VP:e
V:e
pushes
NP:b
1
 ? 
(b)
John
NP:j
NP:b
1
the
N:b
1
button
N:b
1
red N * 
Figure 1: (a) An example grammar; (b) a derivation of ?John pushes the red button? using (a).
tion that explicitly models the context change ef-
fects of an utterance.
While nothing in our work directly hinges on
this, we implemented our approach in the context
of an NLG system for the GIVE Challenge (Koller
et al, 2010b), that is, as an instruction giving sys-
tem for virtual worlds. This makes our system
comparable with other approaches to instruction
giving implemented in the GIVE framework.
3 Sentence generation as planning
Our work is based on the CRISP system (Koller
and Stone, 2007), which encodes sentence gener-
ation with tree-adjoining grammars (TAG; (Joshi
and Schabes, 1997)) as an AI planning problem
and solves that using efficient planners. It then
decodes the resulting plan into a TAG derivation,
from which it can read off a sentence. In this sec-
tion, we briefly recall how this works. For space
reasons, we will present primarily examples in-
stead of definitions.
3.1 TAG sentence generation
The CRISP generation problem (like that of SPUD
(Stone et al, 2003)) assumes a lexicon of entries
consisting of a TAG elementary tree annotated
with semantic and pragmatic information. An ex-
ample is shown in Fig. 1a. In addition to the el-
ementary tree, each lexicon entry specifies its se-
mantic content and possibly a semantic require-
ment, which can express certain presuppositions
triggered by this entry. The nodes in the tree may
be labeled with argument names such as semantic
roles, which specify the participants in the rela-
tion expressed by the lexicon entry; in the exam-
ple, every entry uses the semantic role self repre-
senting the event or individual itself, and the en-
try for ?pushes? furthermore uses subj and obj for
the subject and object argument, respectively. We
combine here for simplicity the entries for ?the?
and ?button? into ?the button?.
For generation, we assume as input a knowl-
edge base and a communicative goal in addition to
the grammar. The goal is to compute a derivation
that expresses the communicative goal in a sen-
tence that is grammatically correct and complete;
whose meaning is justified by the knowledge base;
and in which all REs can be resolved to unique
individuals in the world by the hearer. Let?s say,
for example, that we have a knowledge base
{push(e, j, b1), John(j), button(b1), button(b2),
red(b1)}. Then we can combine instances of the
trees for ?John?, ?pushes?, and ?the button? into
a grammatically complete derivation. However,
because both b1 and b2 satisfy the semantic
content of ?the button?, we must adjoin ?red? into
the derivation to make the RE refer uniquely to
b1. The complete derivation is shown in Fig. 1b;
we can read off the output sentence ?John pushes
the red button? from the leaves of the derived tree
we build in this way.
3.2 TAG generation as planning
In the CRISP system, Koller and Stone (2007)
show how this generation problem can be solved
by converting it into a planning problem (Nau et
al., 2004). The basic idea is to encode the partial
derivation in the planning state, and to encode the
action of adding each elementary tree in the plan-
ning operators. The encoding of our example as a
planning problem is shown in Fig. 2.
In the example, we start with an initial state
which contains the entire knowledge base, plus
atoms subst(S, root) and ref(root, e) expressing
that we want to generate a sentence about the event
e. We can then apply the (instantiated) action
pushes(root, n1, n2, n3, e, j, b1), which models the
act of substituting the elementary tree for ?pushes?
1575
pushes(u, u1, u2, un, x, x1, x2):
Precond: subst(S, u), ref(u, x), push(x, x1, x2),
current(u1), next(u1, u2), next(u2, un)
Effect: ?subst(S, u), subst(NP, u1), subst(NP, u2),
ref(u1, x1), ref(u2, x2), ?y.distractor(u1, y),
?y.distractor(u2, y)
John(u, x):
Precond: subst(NP, u), ref(u, x), John(x)
Effect: ?subst(NP, u), ?y.?John(y) ? ?distractor(u, y)
the-button(u, x):
Precond: subst(NP, u), ref(u, x), button(x)
Effect: ?subst(NP, u), canadjoin(N, u),
?y.?button(y) ? ?distractor(u, y)
red(u, x):
Precond: canadjoin(N, u), ref(u, x), red(x)
Effect: ?y.?red(y) ? ?distractor(u, y)
Figure 2: CRISP planning operators for the ele-
mentary trees in Fig. 1.
into the substitution node root: It can only be
applied because root is an unfilled substitution
node (precondition subst(S, root)), and its effect
is to remove subst(S, root) from the planning state
while adding two new atoms subst(NP, n1) and
subst(NP, n2) for the substitution nodes of the
?pushes? tree. The planning state maintains in-
formation about which individual each node refers
to in the ref atoms. The current and next atoms
are needed to select unused names for newly in-
troduced syntax nodes.1 Finally, the action in-
troduces a number of distractor atoms including
distractor(n2, e) and distractor(n2, b2), express-
ing that the RE at n2 can still be misunderstood
by the hearer as e or b2.
In this new state, all subst and distractor
atoms for n1 can be eliminated with the ac-
tion John(n1, j). We can also apply the action
the-button(n2, b1) to eliminate subst(NP, n2)
and distractor(n2, e), since e is not a button.
However distractor(n2, b2) remains. Now be-
cause the action the-button also introduced the
atom canadjoin(N, n2), we can remove the fi-
nal distractor atom by applying red(n2, b1).
This brings us into a goal state, and we
are done. Goal states in CRISP planning
problems are characterized by axioms such as
?A?u.?subst(A, u) (encoding grammatical com-
pleteness) and ?u?x.?distractor(u, x) (requiring
unique reference).
1This is a different solution to the name-selection problem
than in Koller and Stone (2007). It is simpler and improves
computational efficiency.
1
2
3
4
1 2 3 4
b
1
b
2
b
3f
1
north
Figure 3: An example map for instruction giving.
3.3 Decoding the plan
An AI planner such as FF (Hoffmann and Nebel,
2001) can compute a plan for a planning problem
that consists of the planning operators in Fig. 2
and a specification of the initial state and the goal.
We can then decode this plan into the TAG deriva-
tion shown in Fig. 1b. The basic idea of this
decoding step is that an action with a precondi-
tion subst(A, u) fills the substitution node u, while
an action with a precondition canadjoin(A, u) ad-
joins into a node of category A in the elementary
tree that was substituted into u. CRISP allows
multiple trees to adjoin into the same node. In this
case, the decoder executes the adjunctions in the
order in which they occur in the plan.
4 Context manipulation
We are now ready to describe our NLG ap-
proach, SCRISP (?Situated CRISP?), which ex-
tends CRISP to take the non-linguistic context of
the generated utterance into account, and deliber-
ately manipulate it to simplify RE generation.
As a simplified version of our introductory in-
struction giving example (1), consider the map in
Fig. 3. The instruction follower (IF), who is lo-
cated on the map at position pos3,2 facing north,
sees the scene from the first-person perspective as
in Fig. 7. Now an instruction giver (IG) could in-
struct the IF to press the button b1 in this scene by
saying ?push the button on the wall to your left?.
Interpreting this instruction is difficult for the IF
because it requires her to either memorize the RE
until she has turned to see the button, or to per-
form a mental rotation task to visualize b1 inter-
nally. Alternatively, the IG can first instruct the
IF to ?turn left?; once the IF has done this, the IG
can then simply say ?now push the button in front
1576
S:self
V:self
push
NP:obj ? 
semreq: visible(p, o, obj)
nonlingcon: player?pos(p),
player?ori(o)
impeff: push(obj)
S:self
V:self
turn
Adv
left
nonlingcon: player?ori(o1),
next?ori?left(o1, o2)
nonlingeff: ?player?ori(o1),
player?ori(o2)
impeff: turnleft
S:self
S:self *
S:other ? 
and
Figure 4: An example SCRISP lexicon.
of you?. This lowers the cognitive load on the IF,
and presumably improves the rate of correctly in-
terpreted REs.
SCRISP is capable of deliberately generat-
ing such context-changing navigation instructions.
The key idea of our approach is to extend the
CRISP planning operators with preconditions and
effects that describe the (simulated) physical envi-
ronment: A ?turn left? action, for example, mod-
ifies the IF?s orientation in space and changes the
set of visible objects; a ?push? operator can then
pick up this changed set and restrict the distractors
of the forthcoming RE it introduces (i.e. ?the but-
ton?) to only objects that are visible in the changed
context. We also extend CRISP to generate imper-
ative rather than declarative sentences.
4.1 Situated CRISP
We define a lexicon for SCRISP to be a CRISP
lexicon in which every lexicon entry may also de-
scribe non-linguistic conditions, non-linguistic ef-
fects and imperative effects. Each of these is a
set of atoms over constants, semantic roles, and
possibly some free variables. Non-linguistic con-
ditions specify what must be true in the world
so a particular instance of a lexicon entry can be
uttered felicitously; non-linguistic effects specify
what changes uttering the word brings about in the
world; and imperative effects contribute to the IF?s
?to-do list? (Portner, 2007) by adding the proper-
ties they denote.
A small lexicon for our example is shown in
Fig. 4. This lexicon specifies that saying ?push
X? puts pushing X on the IF?s to-do list, and car-
ries the presupposition that X must be visible from
the location where ?push X? is uttered; this re-
flects our simplifying assumption that the IG can
turnleft(u, x, o1, o2):
Precond: subst(S, u), ref(u, x), player?ori(o1),
next?ori?left(o1, o2), . . .
Effect: ?subst(S, u),?player?ori(o1), player?ori(o2),
to?do(turnleft), . . .
push(u, u1, un, x, x1, p, o):
Precond: subst(S, u), ref(u, x), player?pos(p),
player?ori(o), visible(p, o, x1), . . .
Effect: ?subst(S, u), subst(NP, u1), ref(u1, x1),
?y.(y 6= x1 ? visible(p, o, y) ? distractor(u1, y)),
to?do(push(x1)), canadjoin(S, u), . . .
and(u, u1, un, e1, e2):
Precond: canadjoin(S, u), ref(u, e1), . . .
Effect: subst(S, u1), ref(u1, e2), . . .
Figure 5: SCRISP planning operators for the lexi-
con in Fig. 4.
only refer to objects that are currently visible.
Similarly, ?turn left? puts turning left on the IF?s
agenda. In addition, the lexicon entry for ?turn
left? specifies that, under the assumption that the
IF understands and follows the instruction, they
will turn 90 degrees to the left after hearing it. The
planning operators are written in a way that as-
sumes that the intended (perlocutionary) effects of
an utterance actually come true. This assumption
is crucial in connecting the non-linguistic effects
of one SCRISP action to the non-linguistic pre-
conditions of another, and generalizes to a scalable
model of planning perlocutionary acts. We discuss
this in more detail in Koller et al (2010a).
We then translate a SCRISP generation prob-
lem into a planning problem. In addition to what
CRISP does, we translate all non-linguistic condi-
tions into preconditions and all non-linguistic ef-
fects into effects of the planning operator, adding
any free variables to the operator?s parameters.
An imperative effect P is translated into an ef-
fect to?do(P ). The operators for the example lex-
icon of Fig. 4 are shown in Fig. 5. Finally, we
add information about the situated environment to
the initial state, and specify the planning goal by
adding to?do(P ) atoms for each atom P that is to
be placed on the IF?s agenda.
4.2 An example
Now let?s look at how this generates the appropri-
ate instructions for our example scene of Fig. 3.
We encode the state of the world as depicted
in the map in an initial state which contains,
among others, the atoms player?pos(pos3,2),
player?ori(north), next?ori?left(north,west),
1577
visible(pos3,2,west, b1), etc.
2 We want the IF to
press b1, so we add to?do(push(b1)) to the goal.
We can start by applying the action
turnleft(root, e, north,west) to the initial
state. Next to the ordinary grammatical effects
from CRISP, this action makes player?ori(west)
true. The new state does not contain any subst
atoms, but we can continue the sentence by
adjoining ?and?, i.e. by applying the action
and(root, n1, n2, e, e1). This produces a new
atom subst(S, e1), which satisfies one precon-
dition of push(n1, n2, n3, e1, b1, pos3,2,west).
Because turnleft changed the player orientation,
the visible precondition of push is now satisfied
too (unlike in the initial state, in which b1 was not
visible). Applying the action push now introduces
the need to substitute a noun phrase for the object,
which we can eliminate with an application of
the-button(n2, b1) as in Subsection 3.2.
Since there are no other visible buttons from
pos3,2 facing west, there are no remaining
distractor atoms at this point, and a goal state
has been reached. Together, this four-step plan
decodes into the sentence ?turn left and push
the button?. The final state contains the atoms
to?do(push(b1)) and to?do(turnleft), indicating
that an IF that understands and accepts this in-
struction also accepts these two commitments into
their to-do list.
5 Generating context-dependent
adjectives
Now consider if we wanted to instruct the IF to
press b2 in Fig. 3 instead of b1, say with the
instruction ?push the left button?. This is still
challenging, because (like most other approaches
to RE generation) CRISP interprets adjectives by
simply intersecting all their extensions. In the case
of ?left?, the most reasonable way to do this would
be to interpret it as ?leftmost among all visible ob-
jects?; but this is f1 in the example, and so there is
no distinguishing RE for b2.
In truth, spatial adjectives like ?left? and ?up-
per? depend on the context in two different ways.
On the one hand, they are interpreted with respect
to the current spatio-visual context, in that what is
on the left depends on the current position and ori-
entation of the hearer. On the other hand, they also
2In a more complex situation, it may be infeasible to ex-
haustively model visibility in this way. This could be fixed by
connecting the planner to an external spatial reasoner (Dorn-
hege et al, 2009).
left(u, x):
Precond: ?y.?(distractor(u, y) ? left?of(y, x)),
canadjoin(N, u), ref(u, x)
Effect: ?y.(left?of(x, y) ? ?distractor(u, y)),
premod?index(u, 2), . . .
red(u, x):
Precond: red(x), canadjoin(N, u), ref(u, x),
?premod?index(u, 2)
Effect: ?y.(?red(y) ? ?distractor(u, y)),
premod?index(u, 1), . . .
Figure 6: SCRISP operators for context-
dependent and context-independent adjectives.
depend on the meaning of the phrase they modify:
?the left button? is not necessarily both a button
and further to the left than all other objects, it is
only the leftmost object among the buttons.
We will now show how to extend SCRISP so it
can generate REs that use such context-dependent
adjectives.
5.1 Context-dependence of adjectives in
SCRISP
As a planning-based approach to NLG, SCRISP
is not limited to simply intersecting sets of po-
tential referents that only depend on the attributes
that contribute to an RE: Distractors are removed
by applying operators which may have context-
sensitive conditions depending on the referent and
the distractors that are still left.
Our encoding of context-dependent adjectives
as planning operators is shown in Fig. 6. We only
show the operators here for lack of space; they can
of course be computed automatically from lexicon
entries. In addition to the ordinary CRISP precon-
ditions, the left operator has a precondition requir-
ing that no current distractor for the RE u is to the
left of x, capturing a presupposition of the adjec-
tive. Its effect is that everything that is to the right
of x is no longer a distractor for u. Notice that we
allow that there may still be distractors after left
has been applied (above or below x); we only re-
quire unique reference in the goal state. (Ignore
the premod?index part of the effect for now; we
will get to that in a moment.)
Let?s say that we are computing a plan for re-
ferring to b2 in the example map of Fig. 3, starting
with push(root, n1, n2, e, b2, pos3,1, north) and
the-button(n1, b2). The state after these two ac-
tions is not a goal state, because it still contains
the atom distractor(n1, b3) (the plant f1 was re-
moved as a distractor by the action the-button).
1578
Now assume that we have modeled the spatial
relations between all objects in the initial state
in left?of and above atoms; in particular, we
have left?of(b2, b3). Then the action instance
left(n1, b2) is applicable in this state, as there is
no other object that is still a distractor in this state
and that is to the left of b2. Applying left removes
distractor(n1, b3) from the state. Thus we have
reached a goal state; the complete plan decodes to
the sentence ?push the left button?.
This system is sensitive to the order in which
operators for context-dependent adjectives are ap-
plied. To generate the RE ?the upper left but-
ton?, for instance, we first apply the left action and
then the upper action, and therefore upper only
needs to remove distractors in the leftmost posi-
tion. On the other hand, the RE ?the left upper
button? corresponds to first applying upper and
then left. These action sequences succeed in re-
moving all distractors for different context states,
which is consistent with the difference in meaning
between the two REs.
Furthermore, notice that the adjective operators
themselves do not interact directly with the en-
coding of the context in atoms like visible and
player?pos, just like the noun operators in Sec-
tion 4 didn?t. The REs to which the adjectives and
nouns contribute are introduced by verb operators;
it is these verb operators that inspect the current
context and initialize the distractor set for the new
RE appropriately. This makes the correctness of
the generated sentence independent of the order in
which noun and adjective operators occur in the
plan. We only need to ensure that the verbs are
ordered correctly, and the workload of modeling
interactions with the non-linguistic context is lim-
ited to a single place in the encoding.
5.2 Adjective word order
One final challenge that arises in our system is to
generate the adjectives in the correct order, which
on top of semantically valid must be linguisti-
cally acceptable. In particular, it is known that
some types of adjectives are limited with respect
to the word order in which they can occur in a
noun phrase. For instance, ?large foreign finan-
cial firms? sounds perfectly acceptable, but ?? for-
eign large financial firms? sounds odd (Shaw and
Hatzivassiloglou, 1999). In our setting, some ad-
jective orders are forbidden because only one or-
der produces a correct and distinguishing descrip-
Figure 7: The IF?s view of the scene in Fig. 3, as
rendered by the GIVE client.
tion of the target referent (cf. ?upper left? vs. ?left
upper? example above). However, there are also
other constraints at work: ?? the red left button? is
rather odd even when it is a semantically correct
description, whereas ?the left red button? is fine.
To ensure that SCRISP chooses to generate
these adjectives correctly, we follow a class-based
approach to the premodifier ordering problem
(Mitchell, 2009). In our lexicon we assign adjec-
tives denoting spatial relations (?left?) to one class
and adjectives denoting color (?red?) to another;
then we require that spatial adjectives must always
precede color adjectives. We enforce this by keep-
ing track of the current premodifier index of the RE
in atoms of the form premod?index. Any newly
generated RE node starts off with a premodifier
index of zero; adjoining an adjective of a certain
class then raises this number to the index for that
class. As the operators in Fig. 6 illustrate, color
adjectives such as ?red? have index one and can
only be used while the index is not higher; once
an adjective from a higher class (such as ?left?, of
a class with index two) is used, the premod?index
precondition of the ?red? operator will fail. For
this reason, we can generate a plan for ?the left
red button?, but not for ?? the red left button?, as
desired.
6 Evaluation
To establish the quality of the generated instruc-
tions, we implemented SCRISP as part of a gener-
ation system in the GIVE-1 framework, and eval-
uated it against two baselines. GIVE-1 was the
First Challenge on Generating Instructions in Vir-
tual Environments, which was completed in 2009
1579
SCRISP
1. Turn right and move one step.
2. Push the right red button.
Baseline A
1. Press the right red button on the
wall to your right.
Baseline B
1. Turn right.
2. Walk forward 3 steps.
3. Turn right.
4. Walk forward 1 step.
5. Turn left.
6. Good! Now press the left button.
Table 1: Example system instructions generated in
the same scene. REs for the target are typeset in
boldface.
(Koller et al, 2010b). In this challenge, sys-
tems must generate real-time instructions that help
users perform a task in a treasure-hunt virtual en-
vironment such as the one shown in Fig. 7.
We conducted our evaluation in World 2 from
GIVE-1, which was deliberately designed to be
challenging for RE generation. The world con-
sists of one room filled with several objects and
buttons, most of which cannot be distinguished by
simple descriptions. Moreover, some of those may
activate an alarm and cause the player to lose the
game. The player?s moves and turns are discrete
and the NLG system has complete and accurate
real-time information about the state of the world.
Instructions that each of the three systems under
comparison generated in an example scene of the
evaluation world are presented in Table 1.
The evaluation took place online via the Ama-
zon Mechanical Turk, where we collected 25
games for each system. We focus on four mea-
sures of evaluation: success rates for solving the
task and resolving the generated REs, average
task completion time (in seconds) for successful
games, and average distance (in steps) between the
IF and the referent at the time when the RE was
generated. As in the challenge, the task is consid-
ered as solved if the player has correctly been led
through manipulating all target objects required to
discover and collect the treasure; in World 2, the
minimum number of such targets is eight. An RE
is successfully resolved if it results in the manipu-
lation of the referent, whereas manipulation of an
alarm-triggering distractor ends the game unsuc-
cessfully.
6.1 The SCRISP system
Our system receives as input a plan for what the
IF should do to solve the task, and successively
takes object-manipulating actions as the commu-
success RE
rate time success distance
SCRISP 69% 306 71% 2.49
Baseline A 16%** 230 49%** 1.97*
Baseline B 84% 288 81%* 2.00*
Table 2: Evaluation results. Differences to
SCRISP are significant at *p < .05, **p < .005
(Pearson?s chi-square test for system success rates;
unpaired two-sample t-test for the rest).
nicative goals for SCRISP. Then, for each of the
communicative goals, it generates instructions us-
ing SCRISP, segments them into navigation and
action parts, and presents these to the user as sep-
arate instructions sequentially (see Table 1).
For each instruction, SCRISP thus draws from
a knowledge base of about 1500 facts and a gram-
mar of about 30 lexicon entries. We use the
FF planner (Hoffmann and Nebel, 2001; Koller
and Hoffmann, 2010) to solve the planning prob-
lems. The maximum planning time for any in-
struction is 1.03 seconds on a 3.06 GHz Intel Core
2 Duo CPU. So although our planning-based sys-
tem tackles a very difficult search problem, FF is
very good at solving it?fast enough to generate
instructions in real time.
6.2 Comparison with Baseline A
Baseline A is a very basic system designed to sim-
ulate the performance of a classical RE genera-
tion module which does not attempt to manipu-
late the visual context. We hand-coded a correct
distinguishing RE for each target button in the
world; the only way in which Baseline A reacts
to changes of the context is to describe on which
wall the button is with respect to the user?s current
orientation (e.g. ?Press the right red button on the
wall to your right?).
As Table 2 shows, our system guided 69% of
users to complete the task successfully, compared
to only 16% for Baseline A (difference is statis-
tically significant at p < .005; Pearson?s chi-
square test). This is primarily because only 49%
of the REs generated by Baseline A were success-
ful. This comparison illustrates the importance of
REs that minimize the cognitive load on the IF to
avoid misunderstandings.
6.3 Comparison with Baseline B
Baseline B is a corrected and improved version
of the ?Austin? system (Chen and Karpov, 2009),
1580
one of the best-performing systems of the GIVE-1
Challenge. Baseline B, like the original ?Austin?
system, issues navigation instructions by precom-
puting the shortest path from the IF?s current lo-
cation to the target, and generates REs using the
description logic based algorithm of Areces et al
(2008). Unlike the original system, which inflex-
ibly navigates the user all the way to the target,
Baseline B starts off with navigation, and oppor-
tunistically instructs the IF to push a button once it
has become visible and can be described by a dis-
tinguishing RE. We fixed bugs in the original im-
plementation of the RE generation module, so that
Baseline B generates only unambiguous REs. The
module nonetheless naively treats all adjectives as
intersective and is not sensitive to the context of
their comparison set. Specifically, a button can-
not be referred to as ?the right red button? if it is
not the rightmost of all visible objects?which ex-
plains the long chain of navigational instructions
the system produced in Table 1.
We did not find any significant differences in
the success rates or task completion times between
this system and SCRISP, but the former achieved
a higher RE success rate (see Table 2). However,
a closer analysis shows that SCRISP was able to
generate REs from significantly further away. This
means that SCRISP?s RE generator solves a harder
problem, as it typically has to deal with more vis-
ible distractors. Furthermore, because of the in-
creased distance, the system?s execution monitor-
ing strategies (e.g. for detection and repair of mis-
understandings) become increasingly important,
and this was not a focus of this work. In summary,
then, we take the results to mean that SCRISP per-
forms quite capably in comparison to a top-ranked
GIVE-1 system.
7 Conclusion
In this paper, we have shown how situated instruc-
tions can be generated using AI planning. We ex-
ploited the planner?s ability to model the perlocu-
tionary effects of communicative actions for effi-
cient generation. We showed how this made it pos-
sible to generate instructions that manipulate the
non-linguistic context in convenient ways, and to
generate correct REs with context-dependent ad-
jectives.
We believe that this illustrates the power of
a planning-based approach to NLG to flexibly
model very different phenomena. An interesting
topic for future work, for instance, is to expand our
notion of context by taking visual and discourse
salience into account when generating REs. In ad-
dition, we plan to experiment with assigning costs
to planning operators in a metric planning problem
(Hoffmann, 2002) in order to model the cognitive
cost of an RE (Krahmer et al, 2003) and compute
minimal-cost instruction sequences.
On a more theoretical level, the SCRISP actions
model the physical effects of a correctly under-
stood and grounded instruction directly as effects
of the planning operator. This is computationally
much less complex than classical speech act plan-
ning (Perrault and Allen, 1980), in which the in-
tended physical effect comes at the end of a long
chain of inferences. But our approach is also very
optimistic in estimating the perlocutionary effects
of an instruction, and must be complemented by an
appropriate model of execution monitoring. What
this means for a novel scalable approach to the
pragmatics of speech acts (Koller et al, 2010a)
is, we believe, an interesting avenue for future re-
search.
Acknowledgments. We are grateful to Jo?rg
Hoffmann for improving the efficiency of FF in the
SCRISP domain at a crucial time, and to Margaret
Mitchell, Matthew Stone and Kees van Deemter
for helping us expand our view of the context-
dependent adjective generation problem. We also
thank Ines Rehbein and Josef Ruppenhofer for
testing early implementations of our system, and
Andrew Gargett as well as the reviewers for their
helpful comments.
References
Douglas E. Appelt. 1985. Planning English sentences.
Cambridge University Press, Cambridge, England.
Carlos Areces, Alexander Koller, and Kristina Strieg-
nitz. 2008. Referring expressions as formulas of
description logic. In Proceedings of the 5th Inter-
national Natural Language Generation Conference,
pages 42?49, Salt Fork, Ohio, USA.
Luciana Benotti. 2009. Clarification potential of in-
structions. In Proceedings of the SIGDIAL 2009
Conference, pages 196?205, London, UK.
Michael Brenner and Ivana Kruijff-Korbayova?. 2008.
A continual multiagent planning approach to situ-
ated dialogue. In Proceedings of the 12th Workshop
on the Semantics and Pragmatics of Dialogue, Lon-
don, UK.
1581
David Chen and Igor Karpov. 2009. The
GIVE-1 Austin system. In The First
GIVE Challenge: System descriptions.
http://www.give-challenge.org/
research/files/GIVE-09-Austin.pdf.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean maxims in the genera-
tion of referring expressions. Cognitive Science, 19.
Christian Dornhege, Patrick Eyerich, Thomas Keller,
Sebastian Tru?g, Michael Brenner, and Bernhard
Nebel. 2009. Semantic attachments for domain-
independent planning systems. In Proceedings of
the 19th International Conference on Automated
Planning and Scheduling, pages 114?121.
Jo?rg Hoffmann and Bernhard Nebel. 2001. The
FF planning system: Fast plan generation through
heuristic search. Journal of Artificial Intelligence
Research, 14:253?302.
Jo?rg Hoffmann. 2002. Extending FF to numerical state
variables. In Proceedings of the 15th European Con-
ference on Artificial Intelligence, Lyon, France.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
Adjoining Grammars. In G. Rozenberg and A. Salo-
maa, editors, Handbook of Formal Languages, vol-
ume 3, pages 69?123. Springer-Verlag, Berlin, Ger-
many.
Hans Kamp and Barbara Partee. 1995. Prototype the-
ory and compositionality. Cognition, 57(2):129 ?
191.
Alexander Koller and Jo?rg Hoffmann. 2010. Waking
up a sleeping rabbit: On natural-language sentence
generation with FF. In Proceedings of the 20th In-
ternational Conference on Automated Planning and
Scheduling, Toronto, Canada.
Alexander Koller and Matthew Stone. 2007. Sentence
generation as planning. In Proceedings of the 45th
Annual Meeting of the Association of Computational
Linguistics, Prague, Czech Republic.
Alexander Koller, Andrew Gargett, and Konstantina
Garoufi. 2010a. A scalable model of planning per-
locutionary acts. In Proceedings of the 14th Work-
shop on the Semantics and Pragmatics of Dialogue,
Poznan, Poland.
Alexander Koller, Kristina Striegnitz, Donna Byron,
Justine Cassell, Robert Dale, Johanna Moore, and
Jon Oberlander. 2010b. The First Challenge on
Generating Instructions in Virtual Environments.
In M. Theune and E. Krahmer, editors, Empir-
ical Methods in Natural Language Generation,
volume 5790 of LNCS, pages 337?361. Springer,
Berlin/Heidelberg. To appear.
Emiel Krahmer and Mariet Theune. 2002. Effi-
cient context-sensitive generation of referring ex-
pressions. In Kees van Deemter and Rodger Kibble,
editors, Information Sharing: Reference and Pre-
supposition in Language Generation and Interpre-
tation, pages 223?264. CSLI Publications.
Emiel Krahmer, Sebastiaan van Erk, and Andre? Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
Margaret Mitchell. 2009. Class-based ordering of
prenominal modifiers. In Proceedings of the 12th
European Workshop on Natural Language Genera-
tion, pages 50?57, Athens, Greece.
Dana Nau, Malik Ghallab, and Paolo Traverso. 2004.
Automated Planning: Theory and Practice. Morgan
Kaufmann.
C. Raymond Perrault and James F. Allen. 1980. A
plan-based analysis of indirect speech acts. Amer-
ican Journal of Computational Linguistics, 6(3?
4):167?182.
Paul Portner. 2007. Imperatives and modals. Natural
Language Semantics, 15(4):351?383.
James Shaw and Vasileios Hatzivassiloglou. 1999. Or-
dering among premodifiers. In Proceedings of the
37th Annual Meeting of the Association for Compu-
tational Linguistics, pages 135?143, College Park,
Maryland, USA.
Mark Steedman and Ronald P. A. Petrick. 2007. Plan-
ning dialog actions. In Proceedings of the 8th SIG-
dial Workshop on Discourse and Dialogue, pages
265?272, Antwerp, Belgium.
Laura Stoia, Donna K. Byron, Darla Magdalene Shock-
ley, and Eric Fosler-Lussier. 2006. Sentence
planning for realtime navigational instructions. In
NAACL ?06: Proceedings of the Human Language
Technology Conference of the NAACL, pages 157?
160, Morristown, NJ, USA.
Laura Stoia, Darla M. Shockley, Donna K. Byron,
and Eric Fosler-Lussier. 2008. SCARE: A sit-
uated corpus with annotated referring expressions.
In Proceedings of the 6th International Conference
on Language Resources and Evaluation, Marrakech,
Morocco.
Matthew Stone, Christine Doran, Bonnie Webber, To-
nia Bleam, and Martha Palmer. 2003. Microplan-
ning with communicative intentions: The SPUD
system. Computational Intelligence, 19(4):311?
381.
Kees van Deemter. 2006. Generating referring ex-
pressions that involve gradable properties. Compu-
tational Linguistics, 32(2).
1582
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 145?154,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Generic binarization for parsing and translation
Matthias Bu?chse
Technische Universita?t Dresden
matthias.buechse@tu-dresden.de
Alexander Koller
University of Potsdam
koller@ling.uni-potsdam.de
Heiko Vogler
Technische Universita?t Dresden
heiko.vogler@tu-dresden.de
Abstract
Binarization of grammars is crucial for im-
proving the complexity and performance
of parsing and translation. We present a
versatile binarization algorithm that can
be tailored to a number of grammar for-
malisms by simply varying a formal pa-
rameter. We apply our algorithm to bi-
narizing tree-to-string transducers used in
syntax-based machine translation.
1 Introduction
Binarization amounts to transforming a given
grammar into an equivalent grammar of rank 2,
i.e., with at most two nonterminals on any right-
hand side. The ability to binarize grammars is
crucial for efficient parsing, because for many
grammar formalisms the parsing complexity de-
pends exponentially on the rank of the gram-
mar. It is also critically important for tractable
statistical machine translation (SMT). Syntax-
based SMT systems (Chiang, 2007; Graehl et
al., 2008) typically use some type of synchronous
grammar describing a binary translation rela-
tion between strings and/or trees, such as syn-
chronous context-free grammars (SCFGs) (Lewis
and Stearns, 1966; Chiang, 2007), synchronous
tree-substitution grammars (Eisner, 2003), syn-
chronous tree-adjoining grammars (Nesson et al,
2006; DeNeefe and Knight, 2009), and tree-to-
string transducers (Yamada and Knight, 2001;
Graehl et al, 2008). These grammars typically
have a large number of rules, many of which have
rank greater than two.
The classical approach to binarization, as
known from the Chomsky normal form transfor-
mation for context-free grammars (CFGs), pro-
ceeds rule by rule. It replaces each rule of rank
greater than 2 by an equivalent collection of rules
of rank 2. All CFGs can be binarized in this
way, which is why their recognition problem is
cubic. In the case of linear context-free rewriting
systems (LCFRSs, (Weir, 1988)) the rule-by-rule
technique also applies to every grammar, as long
as an increased fanout it permitted (Rambow and
Satta, 1999).
There are also grammar formalisms for which
the rule-by-rule technique is not complete. In the
case of SCFGs, not every grammar has an equiva-
lent representation of rank 2 in the first place (Aho
and Ullman, 1969). Even when such a represen-
tation exists, it is not always possible to compute
it rule by rule. Nevertheless, the rule-by-rule bi-
narization algorithm of Huang et al (2009) is very
useful in practice.
In this paper, we offer a generic approach
for transferring the rule-by-rule binarization tech-
nique to new grammar formalisms. At the core of
our approach is a binarization algorithm that can
be adapted to a new formalism by changing a pa-
rameter at runtime. Thus it only needs to be im-
plemented once, and can then be reused for a va-
riety of formalisms. More specifically, our algo-
rithm requires the user to (i) encode the grammar
formalism as a subclass of interpreted regular tree
grammars (IRTGs, (Koller and Kuhlmann, 2011))
and (ii) supply a collection of b-rules, which rep-
resent equivalence of grammars syntactically. Our
algorithm then replaces, in a given grammar, each
rule of rank greater than 2 by an equivalent collec-
tion of rules of rank 2, if such a collection is li-
censed by the b-rules. We define completeness of
b-rules in a way that ensures that if any equivalent
collection of rules of rank 2 exists, the algorithm
finds one. As a consequence, the algorithm bina-
rizes every grammar that can be binarized rule by
rule. Step (i) is possible for all the grammar for-
malisms mentioned above. We show Step (ii) for
SCFGs and tree-to-string transducers.
We will use SCFGs as our running example
throughout the paper. We will also apply the algo-
145
rithm to tree-to-string transducers (Graehl et al,
2008; Galley et al, 2004), which describe rela-
tions between strings in one language and parse
trees of another, which means that existing meth-
ods for binarizing SCFGs and LCFRSs cannot be
directly applied to these systems. To our knowl-
edge, our binarization algorithm is the first to bi-
narize such transducers. We illustrate the effec-
tiveness of our system by binarizing a large tree-
to-string transducer for English-German SMT.
Plan of the paper. We start by defining IRTGs
in Section 2. In Section 3, we define the gen-
eral outline of our approach to rule-by-rule bina-
rization for IRTGs, and then extend this to an ef-
ficient binarization algorithm based on b-rules in
Section 4. In Section 5 we show how to use the
algorithm to perform rule-by-rule binarization of
SCFGs and tree-to-string transducers, and relate
the results to existing work.
2 Interpreted regular tree grammars
Grammar formalisms employed in parsing and
SMT, such as those mentioned in the introduc-
tion, differ in the the derived objects?e.g., strings,
trees, and graphs?and the operations involved in
the derivation?e.g., concatenation, substitution,
and adjoining. Interpreted regular tree grammars
(IRTGs) permit a uniform treatment of many of
these formalisms. To this end, IRTGs combine
two ideas, which we explain here.
Algebras IRTGs represent the objects and op-
erations symbolically using terms; the object in
question is obtained by interpreting each symbol
in the term as a function. As an example, Table 1
shows terms for a string and a tree, together with
the denoted object. In the string case, we describe
complex strings as concatenation (con2) of ele-
mentary symbols (e.g., a, b); in the tree case, we
alternate the construction of a sequence of trees
(con2) with the construction of a single tree by
placing a symbol (e.g., ?, ?, ?) on top of a (pos-
sibly empty) sequence of trees. Whenever a term
contains variables, it does not denote an object,
but rather a function. In the parlance of universal-
algebra theory, we are employing initial-algebra
semantics (Goguen et al, 1977).
An alphabet is a nonempty finite set. Through-
out this paper, let X = {x1, x2, . . . } be a set,
whose elements we call variables. We let Xk de-
note the set {x1, . . . , xk} for every k ? 0. Let ?
be an alphabet and V ? X . We write T?(V ) for
the set of all terms over ? with variables V , i.e.,
the smallest set T such that (i) V ? T and (ii) for
every ? ? ?, k ? 0, and t1, . . . , tk ? T , we
have ?(t1, . . . , tk) ? T . Alternatively, we view
T?(V ) as the set of all (rooted, labeled, ordered,
unranked) trees over ? and V , and draw them
as usual. By T? we abbreviate T?(?). The set
C?(V ) of contexts over ? and V is the set of all
trees over ? and V in which each variable in V
occurs exactly once.
A signature is an alphabet ? where each symbol
is equipped with an arity. We write ?|k for the
subset of all k-ary symbols of ?, and ?|k to denote
? ? ?|k. We denote the signature by ? as well.
A signature is binary if the arities do not exceed 2.
Whenever we use T?(V ) with a signature ?, we
assume that the trees are ranked, i.e., each node
labeled by ? ? ?|k has exactly k children.
Let ? be a signature. A ?-algebra A consists
of a nonempty set A called the domain and, for
each symbol f ? ? with rank k, a total function
fA : Ak ? A, the operation associated with f .
We can evaluate any term t in T?(Xk) in A, to
obtain a k-ary operation tA over the domain. In
particular, terms in T? evaluate to elements of A.
For instance, in the string algebra shown in Ta-
ble 1, the term con2(a, b) evaluates to ab, and the
term con2(con2(x2, a), x1) evaluates to a binary
operation f such that, e.g., f(b, c) = cab.
Bimorphisms IRTGs separate the finite control
(state behavior) of a derivation from its derived
object (in its term representation; generational be-
havior); the former is captured by a regular tree
language, while the latter is obtained by applying
a tree homomorphism. This idea goes back to the
tree bimorphisms of Arnold and Dauchet (1976).
Let ? be a signature. A regular tree grammar
(RTG) G over ? is a triple (Q, q0, R) where Q
is a finite set (of states), q0 ? Q, and R is a fi-
nite set of rules of the form q ? ?(q1, . . . , qk),
where q ? Q, ? ? ?|k and q, q1, . . . , qk ? Q.
We call ? the terminal symbol and k the rank
of the rule. Rules of rank greater than two are
called suprabinary. For every q ? Q we de-
fine the language Lq(G) derived from q as the set
{?(t1, . . . , tk) | q ? ?(q1, . . . , qk) ? R, tj ?
Lqj (G)}. If q = q0, we drop the superscript and
write L(G) for the tree language of G. In the lit-
erature, there is a definition of RTG which also
permits more than one terminal symbol per rule,
146
strings over ? trees over ?
example term
and denoted object
con2
a b
7? ab
?
con2
?
con0
?
con0
7?
?
? ?
domain ?? T ?? (set of sequences of trees)
signature ? {a|0 | a ? ?} ? {?|1 | ? ? ?} ?
{conk|k | 0 ? k ? K, k 6= 1} {conk|k | 0 ? k ? K, k 6= 1}
operations a : () 7? a ? : x1 7? ?(x1)
conk : (x1, . . . , xk) 7? x1 ? ? ?xk conk : (x1, . . . , xk) 7? x1 ? ? ?xk
Table 1: Algebras for strings and trees, given an alphabet ? and a maximum arity K ? N.
or none. This does not increase the generative ca-
pacity (Brainerd, 1969).
A (linear, nondeleting) tree homomorphism is a
mapping h : T?(X) ? T?(X) that satisfies the
following condition: there is a mapping g : ? ?
T?(X) such that (i) g(?) ? C?(Xk) for every
? ? ?|k, (ii) h(?(t1, . . . , tk)) is the tree obtained
from g(?) by replacing the occurrence of xj by
h(tj), and (iii) h(xj) = xj . This extends the
usual definition of linear and nondeleting homo-
morphisms (Ge?cseg and Steinby, 1997) to trees
with variables. We abuse notation and write h(?)
for g(?) for every ? ? ?.
Let n ? 1 and ?1, . . . ,?n be signatures. A
(generalized) bimorphism over (?1, . . . ,?n) is a
tuple B = (G, h1, . . . , hn) where G is an RTG
over some signature ? and hi is a tree homo-
morphism from T?(X) into T?i(X). The lan-
guage L(B) induced by B is the tree relation
{(h1(t), . . . , hn(t)) | t ? L(G)}.
An IRTG is a bimorphism whose derived trees
are viewed as terms over algebras; see Fig. 1.
Formally, an IRTG G over (?1, . . . ,?n) is a
tuple (B,A1, . . . ,An) such that B is a bimor-
phism over (?1, . . . ,?n) and Ai is a ?i-algebra.
The language L(G) induced by G is the relation
{(tA11 , . . . , tAnn ) | (t1, . . . , tn) ? L(B)}. We call
the trees in L(G) derivation trees and the terms
in L(B) semantic terms. We say that two IRTGs
G and G? are equivalent if L(G) = L(G?). IRTGs
were first defined in (Koller and Kuhlmann, 2011).
For example, Fig. 2 is an IRTG that encodes
a synchronous context-free grammar (SCFG). It
contains a bimorphism B = (G, h1, h2) consist-
ing of an RTG G with four rules and homomor-
L(G)
T?1 ? ? ? T?n
A1 ? ? ? An
h1 hn
(.)A1 (.)An
? T?
bimorphism B = (G, h1, h2)
IRTG G = (B,A1,A2)
derivation
trees
semantic
terms
derived
objects
Figure 1: IRTG, bimorphism overview.
A? ?(B,C,D)
B ? ?1, C ? ?2, D ? ?3
con3
x1 x2 x3
h1?? [ ? h27?? con
4
x3 a x1 x2
b h1?? [ ?1 h27?? b
c h1?? [ ?2 h27?? c
d h1?? [ ?3 h27?? d
Figure 2: An IRTG encoding an SCFG.
phisms h1 and h2 which map derivation trees to
trees over the signature of the string algebra in Ta-
ble 1. By evaluating these trees in the algebra,
the symbols con3 and con4 are interpreted as con-
catenation, and we see that the first rule encodes
the SCFG rule A ? ?BCD,DaBC?. Figure 3
shows a derivation tree with its two homomorphic
images, which evaluate to the strings bcd and dabc.
IRTGs can be tailored to the expressive capacity
of specific grammar formalisms by selecting suit-
able algebras. The string algebra in Table 1 yields
context-free languages, more complex string al-
147
con3
b c d
h1?? [
?
?1 ?2 ?3
h27??
con4
d a b c
Figure 3: Derivation tree and semantic terms.
A? ??(A?, D)
A? ? ???(B,C)
con2
x1 x2
h?1?? [ ?? h
?
27??
con2
con2
x2 a
x1
con2
x1 x2
h?1?? [ ??? h
?
27??
con2
x1 x2
Figure 4: Binary rules corresponding to the ?-rule
in Fig. 2.
gebras yield tree-adjoining languages (Koller and
Kuhlmann, 2012), and algebras over other do-
mains can yield languages of trees, graphs, or
other objects. Furthermore, IRTGs with n = 1 de-
scribe languages that are subsets of the algebra?s
domain, n = 2 yields synchronous languages or
tree transductions, and so on.
3 IRTG binarization
We will now show how to apply the rule-by-rule
binarization technique to IRTGs. We start in this
section by defining the binarization of a rule in an
IRTG, and characterizing it in terms of binariza-
tion terms and variable trees. We derive the actual
binarization algorithm from this in Section 4.
For the remainder of this paper, let G =
(B,A1, . . . ,An) be an IRTG over (?1, . . . ,?n)
with B = (G, h1, . . . , hn).
3.1 An introductory example
We start with an example to give an intuition of
our approach. Consider the first rule in Fig. 2,
which has rank three. This rule derives (in one
step) the fragment ?(x1, x2, x3) of the derivation
tree in Fig. 3, which is mapped to the semantic
terms h1(?) and h2(?) shown in Fig. 2. Now con-
sider the rules in Fig. 4. These rules can be used to
derive (in two steps) the derivation tree fragment ?
in Fig. 5e. Note that the terms h?1(?) and h1(?)
are equivalent in that they denote the same func-
tion over the string algebra, and so are the terms
h?2(?) and h2(?). Thus, replacing the ?-rule by
the rules in Fig. 4 does not change the language of
the IRTG. However, since the new rules are binary,
(a) con3x1 x2 x3
con4
x3 a x1 x2
(b)
con2
x1 con2
x2 x3
con2
con2
x1 x2
x3
t1 : con2
con2
x3 a
con2
x1 x2
t2 : con
2
con2
x3 con2
a x1
x2
(c)
(d)
con2
x1 x2
x1 con
2
x1 x2
x1 x2
con2
con2
x2 a
x1
x1 con
2
x1 x2
x1 x2
(e)
h1?? [ ? h27??
{x1, x2, x3}
{x1} {x2, x3}
{x2} {x3}
{x1, x2, x3}
{x1, x2}
{x1} {x2}
{x3}
? : {x1, x2, x3}
{x1, x3}
{x1} {x3}
{x2}
con2
con2
x1 x2
x3
t1 :
h?1?? [
??
???
x1 x2
x3
? :
h?27??
con2
con2
x3 a
con2
x1 x2
t2 :
Figure 5: Outline of the binarization algorithm.
parsing and translation will be cheaper.
Now we want to construct the binary rules sys-
tematically. In the example, we proceed as fol-
lows (cf. Fig. 5). For each of the terms h1(?) and
h2(?) (Fig. 5a), we consider all terms that satisfy
two properties (Fig. 5b): (i) they are equivalent
to h1(?) and h2(?), respectively, and (ii) at each
node at most two subtrees contain variables. As
Fig. 5 suggests, there may be many different terms
of this kind. For each of these terms, we ana-
lyze the bracketing of variables, obtaining what we
call a variable tree (Fig. 5c). Now we pick terms
t1 and t2 corresponding to h1(?) and h2(?), re-
spectively, such that (iii) they have the same vari-
able tree, say ? . We construct a tree ? from ? by a
simple relabeling, and we read off the tree homo-
morphisms h?1 and h?2 from a decomposition we
perform on t1 and t2, respectively; see Fig. 5, dot-
ted arrows, and compare the boxes in Fig. 5d with
the homomorphisms in Fig. 4. Now the rules in
Fig. 4 are easily extracted from ?.
These rules are equivalent to r because of (i);
they are binary because ? is binary, which in turn
holds because of (ii); finally, the decompositions
of t1 and t2 are compatible with ? because of (iii).
We call terms t1 and t2 binarization terms if they
satisfy (i)?(iii). We will see below that we can con-
148
struct binary rules equivalent to r from any given
sequence of binarization terms t1, t2, and that bi-
narization terms exist whenever equivalent binary
rules exist. The majority of this paper revolves
around the question of finding binarization terms.
Rule-by-rule binarization of IRTGs follows the
intuition laid out in this example closely: it means
processing each suprabinary rule, attempting to
replace it with an equivalent collection of binary
rules.
3.2 Binarization terms
We will now make this intuition precise. To this
end, we assume that r = q ? ?(q1, . . . , qk) is a
suprabinary rule of G. As we have seen, binariz-
ing r boils down to constructing:
? a tree ? over some binary signature ?? and
? tree homomorphisms h?1, . . . , h?n of type
h?i : T??(X)? T?i(X),
such that h?i(?) and hi(?) are equivalent, i.e., they
denote the same function over Ai. We call such a
tuple (?, h?1, . . . , h?n) a binarization of the rule r.
Note that a binarization of r need not exist. The
problem of rule-by-rule binarization consists in
computing a binarization of each suprabinary rule
of a grammar. If such a binarization does not exist,
the problem does not have a solution.
In order to define variable trees, we assume a
mapping seq that maps each finite set U of pair-
wise disjoint variable sets to a sequence over U
which contains each element exactly once. Let
t ? C?(Xk). The variable set of t is the set of
all variables that occur in t. The set S(t) of sub-
tree variables of t consists of the nonempty vari-
able sets of all subtrees of t. We represent S(t)
as a tree v(t), which we call variable tree as fol-
lows. Any two elements of S(t) are either compa-
rable (with respect to the subset relation) or dis-
joint. We extend this ordering to a tree struc-
ture by ordering disjoint elements via seq. We let
v(L) = {v(t) | t ? L} for every L ? C?(Xk).
In the example of Fig. 5, t1 and t2 have the same
set of subtree variables; it is {{x1}, {x2}, {x3},
{x1, x2}, {x1, x2, x3}}. If we assume that seq or-
ders sets of variables according to the least vari-
able index, we arrive at the variable tree in the cen-
ter of Fig. 5.
Now let t1 ? T?1(Xk), . . . , tn ? T?n(Xk).
We call the tuple t1, . . . , tn binarization terms of
r if the following properties hold: (i) hi(?) and ti
are equivalent; (ii) at each node the tree ti contains
at most two subtrees with variables; and (iii) the
terms t1, . . . , tn have the same variable tree.
Assume for now that we have found binariza-
tion terms t1, . . . , tn. We show how to construct a
binarization (?, h?1, . . . , h?n) of r with ti = h?i(?).
First, we construct ?. Since t1, . . . , tn are bi-
narization terms, they have the same variable tree,
say, ? . We obtain ? from ? by replacing every la-
bel of the form {xj} with xj , and every other label
with a fresh symbol. Because of condition (ii) in
in the definition of binarization terms, ? is binary.
In order to construct h?i(?) for each symbol ?
in ?, we transform ti into a tree t?i with labels from
C?i(X) and the same structure as ?. Then we read
off h?i(?) from the node of t?i that corresponds to
the ?-labeled node of ?. The transformation pro-
ceeds as illustrated in Fig. 6: first, we apply the
maximal decomposition operation d; it replaces
every label f ? ?i|k by the tree f(x1, . . . , xk),
represented as a box. After that, we keep applying
the merge operation  m as often as possible; it
merges two boxes that are in a parent-child rela-
tion, given that one of them has at most one child.
Thus the number of variables in any box can only
decrease. Finally, the reorder operation o orders
the children of each box according to the seq of
their variable sets. These operations do not change
the variable tree; one can use this to show that t?i
has the same structure as ?.
Thus, if we can find binarization terms, we
can construct a binarization of r. Conversely, for
any given binarization (?, h?1, . . . , h?n) the seman-
tic terms h?1(?), . . . , h?n(?) are binarization terms.
This proves the following lemma.
Lemma 1 There is a binarization of r if and only
if there are binarization terms of r.
3.3 Finding binarization terms
It remains to show how we can find binarization
terms of r, if there are any.
Let bi : T?i(Xk) ? P(T?i(Xk)) the mapping
with bi(t) = {t? ? T?i(Xk) | t and t? are equiv-
alent, and at each node t? has at most two chil-
dren with variables}. Figure 5b shows some ele-
ments of b1(h1(?)) and b2(h2(?)) for our exam-
ple. Terms t1, . . . , tn are binarization terms pre-
cisely when ti ? bi(hi(?)) and t1, . . . , tn have the
same variable tree. Thus we can characterize bi-
narization terms as follows.
Lemma 2 There are binarization terms if and
only if?i v(bi(hi(?))) 6= ?.
149
con2
con2
x3 a
con2
x1 x2
 d
con2
x1 x2
con2
x1 x2
x3 a
con2
x1 x2
x1 x2
 m
con2
x1 x2
con2
x1 a
x3
con2
x1 x2
x1 x2
 m
con2
con2
x1 a
x2
x3 con
2
x1 x2
x1 x2
 o
con2
con2
x2 a
x1
con2
x1 x2
x1 x2
x3
Figure 6: Transforming t2 into t?2.
This result suggests the following procedure
for obtaining binarization terms. First, determine
whether the intersection in Lemma 2 is empty. If
it is, then there is no binarization of r. Otherwise,
select a variable tree ? from this set. We know that
there are trees t1, . . . , tn such that ti ? bi(hi(?))
and v(ti) = ? . We can therefore select arbitrary
concrete trees ti ? bi(hi(?))? v?1(?). The terms
t1, . . . , tn are then binarization terms.
4 Effective IRTG binarization
In this section we develop our binarization algo-
rithm. Its key task is finding binarization terms
t1, . . . , tn. This task involves deciding term equiv-
alence, as ti must be equivalent to hi(?). In gen-
eral, equivalence is undecidable, so the task can-
not be solved. We avoid deciding equivalence by
requiring the user to specify an explicit approxi-
mation of bi, which we call a b-rule. This param-
eter gives rise to a restricted version of the rule-
by-rule binarization problem, which is efficiently
computable while remaining practically relevant.
Let ? be a signature. A binarization rule (b-
rule) over ? is a mapping b : ? ? P(T?(X))
where for every f ? ?|k we have that b(f) ?
C?(Xk), at each node of a tree in b(f) only two
children contain variables, and b(f) is a regular
tree language. We extend b to T?(X) by setting
b(xj) = {xj} and b(f(t1, . . . , tk)) = {t[xj/t?j |
1 ? j ? k] | t ? b(f), t?j ? b(tj)}, where [xj/t?j ]
denotes substitution of xj by t?j . Given an alge-
bra A over ?, a b-rule b over ? is called a b-rule
over A if, for every t ? T?(Xk) and t? ? b(t),
t? and t are equivalent inA. Such a b-rule encodes
equivalence in A, and it does so in an explicit and
compact way: because b(f) is a regular tree lan-
guage, a b-rule can be specified by a finite collec-
tion of RTGs, one for each symbol f ? ?. We will
look at examples (for the string and tree algebras
shown earlier) in Section 5.
From now on, we assume that b1, . . . , bn are
b-rules over A1, . . . ,An, respectively. A bina-
rization (?, h?1, . . . , h?n) of r is a binarization of r
with respect to b1, . . . , bn if h?i(?) ? bi(hi(?)).
Likewise, binarization terms t1, . . . , tn are bi-
narization terms with respect to b1, . . . , bn if
ti ? bi(hi(?)). Lemmas 1 and 2 carry over to
the restricted notions. The problem of rule-by-
rule binarization with respect to b1, . . . , bn con-
sists in computing a binarization with respect to
b1, . . . , bn for each suprabinary rule.
By definition, every solution to this restricted
problem is also a solution to the general prob-
lem. The converse need not be true. However,
we can guarantee that the restricted problem has
at least one solution whenever the general problem
has one, by requiring v(bi(hi(?)) = v(b(hi(?)).
Then the intersection in Lemma 2 is empty in the
restricted case if and only if it is empty in the gen-
eral case. We call the b-rules b1, . . . , b1 complete
on G if the equation holds for every ? ? ?.
Now we show how to effectively compute bina-
rization terms with respect to b1, . . . , bn, along the
lines of Section 3.3. More specifically, we con-
struct an RTG for each of the sets (i) bi(hi(?)),
(ii) b?i = v(bi(hi(?))), (iii)
?
i b?i, and (iv) b??i =
bi(hi(?))?v?1(?) (given ? ). Then we can select ?
from (iii) and ti from (iv) using a standard algo-
rithm, such as the Viterbi algorithm or Knuth?s
algorithm (Knuth, 1977; Nederhof, 2003; Huang
and Chiang, 2005). The effectiveness of our pro-
cedure stems from the fact that we only manipulate
RTGs and never enumerate languages.
The construction for (i) is recursive, following
the definition of bi. The base case is a language
{xj}, for which the RTG is easy. For the recursive
case, we use the fact that regular tree languages
are closed under substitution (Ge?cseg and Steinby,
1997, Prop. 7.3). Thus we obtain an RTG Gi with
L(Gi) = bi(hi(?)).
For (ii) and (iv), we need the following auxiliary
150
construction. Let Gi = (P, p0, R). We define the
mapping vari : P ? P(Xk) such that for every
p ? P , every t ? Lp(Gi) contains exactly the vari-
ables in vari(p). We construct it as follows. We
initialize vari(p) to ?unknown? for every p. For
every rule p ? xj , we set vari(p) = {xj}. For
every rule p? ?(p1, . . . , pk) such that vari(pj) is
known, we set vari(p) = ?j vari(pj). This is iter-
ated; it can be shown that vari(p) is never assigned
two different values for the same p. Finally, we set
all remaining unknown entries to ?.
For (ii), we construct an RTG G?i with L(G?i) =
b?i as follows. We let G?i = ({?vari(p)? | p ?
P}, vari(p0), R?) where R? consists of the rules
?{xj}? ? {xj} if p? xi ? R ,
?vari(p)? ? vari(p)(?U1?, . . . , ?Ul??)
if p? ?(p1, . . . , pk) ? R,
V = {vari(pj) | 1 ? j ? k} \ {?},
|V | ? 2, seq(V ) = (U1, . . . , Ul) .
For (iii), we use the standard product construc-
tion (Ge?cseg and Steinby, 1997, Prop. 7.1).
For (iv), we construct an RTG G??i such that
L(G??i ) = b??i as follows. We let G??i = (P, p0, R??),
where R?? consists of the rules
p? ?(p1, . . . , pk)
if p? ?(p1, . . . , pk) ? R,
V = {vari(pj) | 1 ? j ? k} \ {?},
if |V | ? 2, then
(vari(p), seq(V )) is a fork in ? .
By a fork (u, u1 ? ? ?uk) in ? , we mean that there
is a node labeled u with k children labeled u1 up
to uk.
At this point we have all the ingredients for our
binarization algorithm, shown in Algorithm 1. It
operates directly on a bimorphism, because all the
relevant information about the algebras is captured
by the b-rules. The following theorem documents
the behavior of the algorithm. In short, it solves
the problem of rule-by-rule binarization with re-
spect to b-rules b1, . . . , bn.
Theorem 3 Let G = (B,A1, . . . ,An) be
an IRTG, and let b1, . . . , bn be b-rules over
A1, . . . ,An, respectively.
Algorithm 1 terminates. Let B? be the
bimorphism computed by Algorithm 1 on B
and b1, . . . , bn. Then G? = (B?,A1, . . . ,An) is
equivalent to G, and G? is of rank 2 if and only
Input: bimorphism B = (G, h1, . . . , hn),
b-rules b1, . . . , bn over ?1, . . . ,?n
Output: bimorphism B?
1: B? ? (G|?2, h1, . . . , hn)
2: for rule r : q ? ?(q1, . . . , qk) of G|>2 do
3: for i = 1, . . . , n do
4: compute RTG Gi for bi(hi(?))
5: compute RTG G?i for v(bi(hi(?)))
6: compute RTG Gv for ?i L(G?i)
7: if L(Gv) = ? then
8: add r to B?
9: else
10: select t? ? L(Gv)
11: for i = 1, . . . , n do
12: compute RTG G??i for
13: b??i = bi(hi(?)) ? v?1(t?)
14: select ti ? L(G??i )
15: construct binarization for t1, . . . , tn
16: add appropriate rules to B?
Algorithm 1: Complete binarization algorithm,
whereG|?2 andG|>2 isG restricted to binary and
suprabinary rules, respectively.
if every suprabinary rule of G has a binarization
with respect to b1, . . . , bn.
The runtime of Algorithm 1 is dominated by the
intersection construction in line 6, which isO(m1 ?
. . . ?mn) per rule, where mi is the size of G?i. The
quantity mi is linear in the size of the terms on the
right-hand side of hi, and in the number of rules in
the b-rule bi.
5 Applications
Algorithm 1 implements rule-by-rule binarization
with respect to given b-rules. If a rule of the given
IRTG does not have a binarization with respect to
these b-rules, it is simply carried over to the new
grammar, which then has a rank higher than 2. The
number of remaining suprabinary rules depends
on the b-rules (except for rules that have no bi-
narization at all). The user can thus engineer the
b-rules according to their current needs, trading off
completeness, runtime, and engineering effort.
By contrast, earlier binarization algorithms for
formalisms such as SCFG and LCFRS simply at-
tempt to find an equivalent grammar of rank 2;
there is no analogue of our b-rules. The problem
these algorithms solve corresponds to the general
rule-by-rule binarization problem from Section 3.
151
NP
NP
DT
the
x1:NNP POS
?s
x2:JJ x3:NN ?? das x2 x3 der x1
Figure 7: A rule of a tree-to-string transducer.
We show that under certain conditions, our algo-
rithm can be used to solve this problem as well.
In the following two subsections, we illustrate this
for SCFGs and tree-to-string transducers, respec-
tively. In the final subsection, we discuss how to
extend this approach to other grammar formalisms
as well.
5.1 Synchronous context-free grammars
We have used SCFGs as the running example in
this paper. SCFGs are IRTGs with two interpre-
tations into the string algebra of Table 1, as illus-
trated by the example in Fig. 2. In order to make
our algorithm ready to use, it remains to specify a
b-rule for the string algeba.
We use the following b-rule for both b1 and b2.
Each symbol a ? ?i|0 is mapped to the language
{a}. Each symbol conk, k ? 2, is mapped to
the language induced by the following RTG with
states of the form [j, j?] (where 0 ? j < j? ? k)
and final state [0, k]:
[j ? 1, j]? xj (1 ? j ? k)
[j, j?]? con2([j, j??], [j??, j?])
(0 ? j < j?? < j? ? k)
This language expresses all possible ways in
which conk can be written in terms of con2.
Our definition of rule-by-rule binarization with
respect to b1 and b2 coincides with that of Huang
et al (2009): any rule can be binarized by
both algorithms or neither. For instance, for the
SCFG rule A ? ?BCDE,CEBD?, the sets
v(b1(h1(?))) and v(b2(h2(?))) are disjoint, thus
no binarization exists. Two strings of length N
can be parsed with a binary IRTG that represents
an SCFG in time O(N6).
5.2 Tree-to-string transducers
Some approaches to SMT go beyond string-to-
string translation models such as SCFG by exploit-
ing known syntactic structures in the source or tar-
get language. This perspective on translation nat-
urally leads to the use of tree-to-string transducers
NP? ?(NNP, JJ,NN)
NP
con3
NP
con3
DT
the
con0
x1 POS
?s
con0
x2 x3
h1?? [ ? h27?? con
5
das x2 x3 der x1
Figure 8: An IRTG rule encoding the rule in Fig. 7.
(Yamada and Knight, 2001; Galley et al, 2004;
Huang et al, 2006; Graehl et al, 2008). Figure 7
shows an example of a tree-to-string rule. It might
be used to translate ?the Commission?s strategic
plan? into ?das langfristige Programm der Kom-
mission?.
Our algorithm can binarize tree-to-string trans-
ducers; to our knowledge, it is the first algorithm
to do so. We model the tree-to-string transducer
as an IRTG G = ((G, h1, h2),A1,A2), where
A2 is the string algebra, but this time A1 is the
tree algebra shown in Table 1. This algebra has
operations conk to concatenate sequences of trees
and unary ? that maps any sequence (t1, . . . , tl) of
trees to the tree ?(t1, . . . , tl), viewed as a sequence
of length 1. Note that we exclude the operation
con1 because it is the identity and thus unneces-
sary. Thus the rule in Fig. 7 translates to the IRTG
rule shown in Fig. 8.
For the string algebra, we reuse the b-rule from
Section 5.1; we call it b2 here. For the tree algebra,
we use the following b-rule b1. It maps con0 to
{con0} and each unary symbol ? to {?(x1)}. Each
symbol conk, k ? 2, is treated as in the string
case. Using these b-rules, we can binarize the rule
in Fig. 8 and obtain the rules in Fig. 9. Parsing
of a binary IRTG that represents a tree-to-string
transducer is O(N3 ?M) for a string of length N
and a tree with M nodes.
We have implemented our binarization algo-
rithm and the b-rules for the string and the tree
algebra. In order to test our implementation, we
extracted a tree-to-string transducer from about a
million parallel sentences of English-German Eu-
roparl data, using the GHKM rule extractor (Gal-
ley, 2010). Then we binarized the transducer. The
results are shown in Fig. 10. Of the 2.15 million
rules in the extracted transducer, 460,000 were
suprabinary, and 67 % of these could be binarized.
Binarization took 4.4 minutes on a single core of
an Intel Core i5 2520M processor.
152
NP? ??(NNP, A?)
A? ? ???(JJ,NN)
NP
con2
NP
con2
DT
the
con0
con2
x1 POS
?s
con0
x2
h?1?? [ ?? h
?
27??
con2
con2
das x2
con2
der x1
con2
x1 x2
h?1?? [ ??? h
?
27??
con2
x1 x2
Figure 9: Binarization of the rule in Fig. 8.
 1
 1.2
 1.4
 1.6
 1.8
 2
 2.2
 2.4
ext bin
# 
ru
le
s 
(m
ill
io
ns
) rank
0
1
2
3
4
5
6-7
8-10
Figure 10: Rules of a transducer extracted from
Europarl (ext) vs. its binarization (bin).
5.3 General approach
Our binarization algorithm can be used to solve
the general rule-by-rule binarization problem for
a specific grammar formalism, provided that one
can find appropriate b-rules. More precisely,
we need to devise a class C of IRTGs over the
same sequence A1, . . . ,An of algebras that en-
codes the grammar formalism, together with b-
rules b1, . . . , bn over A1, . . . ,An that are com-
plete on every grammar in C, as defined in Sec-
tion 4.
We have already seen the b-rules for SCFGs and
tree-to-string transducers in the preceding subsec-
tions; now we have a closer look at the class C
for SCFGs. We used the class of all IRTGs with
two string algebras and in which hi(?) contains
at most one occurrence of a symbol conk for ev-
ery ? ? ?. On such a grammar the b-rules are
complete. Note that this would not be the case
if we allowed several occurrences of conk, as in
con2(con2(x1, x2), x3). This term is equivalent
to itself and to con2(x1, con2(x2, x3)), but the b-
rules only cover the former. Thus they miss one
variable tree. For the term con3(x1, x2, x3), how-
ever, the b-rules cover both variable trees.
Generally speaking, given C and b-rules
b1, . . . , bn that are complete on every IRTG in C,
Algorithm 1 solves the general rule-by-rule bina-
rization problem on C. We can adapt Theorem 3 by
requiring that G must be in C, and replacing each
of the two occurrences of ?binarization with re-
spect to b1, . . . , bn? by simply ?binarization?. If C
is such that every grammar from a given grammar
formalism can be encoded as an IRTG in C, this
solves the general rule-by-rule binarization prob-
lem of that grammar formalism.
6 Conclusion
We have presented an algorithm for binarizing
IRTGs rule by rule, with respect to b-rules that
the user specifies for each algebra. This improves
the complexity of parsing and translation with any
monolingual or synchronous grammar that can be
represented as an IRTG. A novel algorithm for
binarizing tree-to-string transducers falls out as a
special case.
In this paper, we have taken the perspective that
the binarized IRTG uses the same algebras as the
original IRTG. Our algorithm extends to gram-
mars of arbitrary fanout (such as synchronous
tree-adjoining grammar (Koller and Kuhlmann,
2012)), but unlike LCFRS-based approaches to bi-
narization, it will not increase the fanout to en-
sure binarizability. In the future, we will ex-
plore IRTG binarization with fanout increase. This
could be done by binarizing into an IRTG with
a more complicated algebra (e.g., of string tu-
ples). We might compute binarizations that are
optimal with respect to some measure (e.g., fanout
(Gomez-Rodriguez et al, 2009) or parsing com-
plexity (Gildea, 2010)) by keeping track of this
measure in the b-rule and taking intersections of
weighted tree automata.
Acknowledgments
We thank the anonymous referees for their insight-
ful remarks, and Sarah Hemmen for implementing
an early version of the algorithm. Matthias Bu?chse
was financially supported by DFG VO 1011/6-1.
153
References
Alfred V. Aho and Jeffrey D. Ullman. 1969. Syntax
directed translations and the pushdown assembler.
Journal of Computer and System Sciences, 3:37?56.
Andre? Arnold and Max Dauchet. 1976. Bi-
transduction de fore?ts. In Proc. 3rd Int. Coll. Au-
tomata, Languages and Programming, pages 74?86.
Edinburgh University Press.
Walter S. Brainerd. 1969. Tree generating regular sys-
tems. Information and Control, 14(2):217?231.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201?228.
Steve DeNeefe and Kevin Knight. 2009. Synchronous
tree-adjoining machine translation. In Proceedings
of EMNLP, pages 727?736.
Jason Eisner. 2003. Learning non-isomorphic tree
mappings for machine translation. In Proceedings
of the 41st ACL, pages 205?208.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a translation rule?
In Proceedings of HLT/NAACL, pages 273?280.
Michael Galley. 2010. GHKM rule extractor. http:
//www-nlp.stanford.edu/?mgalley/
software/stanford-ghkm-latest.tar.
gz, retrieved on March 28, 2012.
Ferenc Ge?cseg and Magnus Steinby. 1997. Tree lan-
guages. In G. Rozenberg and A. Salomaa, editors,
Handbook of Formal Languages, volume 3, chap-
ter 1, pages 1?68. Springer-Verlag.
Daniel Gildea. 2010. Optimal parsing strategies for
linear context-free rewriting systems. In Proceed-
ings of NAACL HLT.
Joseph A. Goguen, Jim W. Thatcher, Eric G. Wagner,
and Jesse B. Wright. 1977. Initial algebra seman-
tics and continuous algebras. Journal of the ACM,
24:68?95.
Carlos Gomez-Rodriguez, Marco Kuhlmann, Giorgio
Satta, and David Weir. 2009. Optimal reduction of
rule length in linear context-free rewriting systems.
In Proceedings of NAACL HLT.
Jonathan Graehl, Kevin Knight, and Jonathan May.
2008. Training tree transducers. Computational
Linguistics, 34(3):391?427.
Liang Huang and David Chiang. 2005. Better k-best
parsing. In Proceedings of the 9th IWPT, pages 53?
64.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proceedings of the 7th AMTA,
pages 66?73.
Liang Huang, Hao Zhang, Daniel Gildea, and Kevin
Knight. 2009. Binarization of synchronous
context-free grammars. Computational Linguistics,
35(4):559?595.
Donald E. Knuth. 1977. A generalization of Dijkstra?s
algorithm. Information Processing Letters, 6(1):1?
5.
Alexander Koller and Marco Kuhlmann. 2011. A gen-
eralized view on parsing and translation. In Pro-
ceedings of the 12th IWPT, pages 2?13.
Alexander Koller and Marco Kuhlmann. 2012. De-
composing TAG algorithms using simple alge-
braizations. In Proceedings of the 11th TAG+ Work-
shop, pages 135?143.
Philip M. Lewis and Richard E. Stearns. 1966. Syn-
tax directed transduction. Foundations of Computer
Science, IEEE Annual Symposium on, 0:21?35.
Mark-Jan Nederhof. 2003. Weighted deductive pars-
ing and Knuth?s algorithm. Computational Linguis-
tics, 29(1):135?143.
Rebecca Nesson, Stuart M. Shieber, and Alexander
Rush. 2006. Induction of probabilistic synchronous
tree-insertion grammars for machine translation. In
Proceedings of the 7th AMTA.
Owen Rambow and Giorgio Satta. 1999. Independent
parallelism in finite copying parallel rewriting sys-
tems. Theoretical Computer Science, 223(1?2):87?
120.
David J. Weir. 1988. Characterizing Mildly Context-
Sensitive Grammar Formalisms. Ph.D. thesis, Uni-
versity of Pennsylvania.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceedings
of the 39th ACL, pages 523?530.
154
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 465?470,
Dublin, Ireland, August 23-24, 2014.
Potsdam: Semantic Dependency Parsing by Bidirectional Graph-Tree
Transformations and Syntactic Parsing
?
Zeljko Agi
?
c
University of Potsdam
zagic@uni-potsdam.de
Alexander Koller
University of Potsdam
koller@ling.uni-potsdam.de
Abstract
We present the Potsdam systems that par-
ticipated in the semantic dependency pars-
ing shared task of SemEval 2014. They
are based on linguistically motivated bidi-
rectional transformations between graphs
and trees and on utilization of syntactic de-
pendency parsing. They were entered in
both the closed track and the open track
of the challenge, recording a peak average
labeled F
1
score of 78.60.
1 Introduction
In the semantic dependency parsing (SDP) task of
SemEval 2014, the meaning of a sentence is repre-
sented in terms of binary head-argument relations
between the lexical units ? bi-lexical dependencies
(Oepen et al., 2014). Since words can be seman-
tic dependents of multiple other words, this frame-
work results in graph representations of sentence
meaning. For the SDP task, three such annotation
layers are provided on top of the WSJ text of the
Penn Treebank (PTB) (Marcus et al., 1993):
? DM: the reduction of DeepBank HPSG anno-
tation (Flickinger et al., 2012) into bi-lexical
dependencies following (Oepen and L?nning,
2006; Ivanova et al., 2012),
? PAS: the predicate-argument structures derived
from the training set of the Enju HPSG parser
(Miyao et al., 2004) and
? PCEDT: a subset of the tectogrammatical anno-
tation layer from the English side of the Prague
Czech-English Dependency Treebank (Cinkov?a
et al., 2009).
The three annotation schemes provide three di-
rected graph representations for each PTB sen-
This work is licenced under a Creative Commons Attribution
4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http:
//creativecommons.org/licenses/by/4.0/
tence, with word forms as nodes and labeled de-
pendency relations as edges pointing from func-
tors to arguments. The SDP-annotated PTB text is
split into training (sections 00?19), development
(sec. 20) and testing sets (sec. 21). This in turn
makes the SDP parsing task a problem of data-
driven graph parsing, in which systems are to be
trained for producing dependency graph represen-
tations of sentences respecting the three underly-
ing schemes.
While a number of theoretical and preliminary
contributions to data-driven graph parsing exist
(Sagae and Tsujii, 2008; Das et al., 2010; Jones
et al., 2013; Chiang et al., 2013; Henderson et
al., 2013), our goal here is to investigate the sim-
plest approach that can achieve competitive per-
formance. Our starting point is the observation
that the SDP graphs are relatively tree-like. On it,
we build a system for data-driven graph parsing by
(1) transforming dependency graphs into depen-
dency trees in preprocessing, (2) training and us-
ing syntactic dependency parsers over these trees
and (3) transforming their output back into graphs
in postprocessing. This way, we inherit the accu-
racy and speed of syntactic dependency parsers.
The secondary benefit is insight into the struc-
ture of the semantic representations, as graph-tree
transformations can make the phenomena that re-
quire non-tree-like structures more explicit.
2 Data and Systems
We present the basic statistics for the SDP train-
ing sets in Table 1. The graphs contain no cycles,
i.e., all SDP meaning representations are directed
acyclic graphs (DAGs). DM and PAS are auto-
matically derived from HPSG annotations, while
PCEDT is based on manual tectogrammatical an-
notation. This is reflected in more than half of the
PCEDT graphs being disjoint sets of dependency
trees, i.e., forests. The number of forests in DM
and PAS is negligible, on the other hand. The edge
465
Feature DM PAS PCEDT
Sentences 32,389 32,389 32,389
Tokens 742,736 742,736 742,736
Edge labels 52 43 71
Cyclic graphs 0 0 0
Forests 810 418 18,527
Treewidth (undirected) 1.30 1.71 1.45
Tree labels
LOCAL 79 77 124
DFS 79 81 133
Table 1: Basic statistics for the training sets.
label set of PCEDT is also substantially larger than
the label sets of DM and PAS.
2.1 Baseline
A directed acyclic graph is a dependency tree in
the sense of (Nivre, 2006) if any two nodes are
connected by exactly one simple path. In other
words, a DAG is a dependency tree if there are
no disconnected (singleton) nodes and if there are
no node reentrancies, i.e., all nodes have an in-
degree of 1. We calculate the average treewidth
of SDP graphs by converting them to undirected
graphs and applying the algorithm of (Gogate and
Dechter, 2004). As we show in Table 1, the
treewidth is low for all three representations. The
low treewidth indicates that, even if the SDP se-
mantic representations are graphs and not trees,
these graphs are very tree-like and, as such, easily
transformed into trees as there are not many edges
that would require deletion. Thus, one could per-
form a lossy graph-to-tree conversion by (a) de-
tecting singleton nodes and attaching them triv-
ially and (b) detecting reentrant nodes and deleting
all but one incoming edge.
The official SDP baseline system
1
(Oepen et al.,
2014) is based precisely on this principle: single-
tons are attached to their right neighbors, only the
edges to the closest predicates are kept for reen-
trant nodes, with a preference for leftward predi-
cates in ties, and all remaining nodes with an in-
degree of 0 are attached to the root. Two dummy
labels are introduced in the process: root for at-
tachments to root and null for the remaining new
attachments. The baseline is thus limited by the
lossy approach to graph-to-tree reductions and the
lack of linguistic motivation for these particular re-
duction operations. Here, we aim at introducing
1
http://alt.qcri.org/semeval2014/
task8/index.php?id=evaluation
Figure 1: Distributions of node indegrees for (a)
all nodes and (b) source nodes of edges participat-
ing in reentrancies.
Figure 2: Distributions of parts of speech for reen-
trancy source nodes with zero indegree. Ten most
frequent parts of speech are displayed.
less lossy and more linguistically motivated reduc-
tions.
2.2 Local Edge Flipping
Furthermore, inspecting the distribution of node
indegrees in the SDP data in Figure 1, we make
two important observations: (1) from its left his-
togram, that most of the nodes in all three annota-
tions have an indegree of 0 or 1, and (2) from its
right histogram, that most source nodes of edges
causing reentrancies themselves have an indegree
of 0. Figure 2 deepens this observation by provid-
ing a part-of-speech distribution of source nodes
in reentrancies. It shows that the edges in DM
and PAS are systematically pointed from modi-
466
System DM PAS PCEDT
BASELINE 66.19 57.66 90.70
LOCAL 89.93 88.73 91.86
DFS 95.52 93.98 92.85
Table 2: Upper bound LF scores on the develop-
ment set for LOCAL and DFS conversion compared
to the baseline. This score indicates the quality of
graph-tree transformation as no parsing is done.
Dataset P R F
1
DM 73.30 62.99 67.76
PAS 76.03 72.12 74.02
PCEDT 79.40 78.52 78.96
Table 3: Top node detection accuracy with CRFs
on the development set for the three annotations.
Precision (P), recall (R) and the F
1
scores relate to
marking tokens with the binary top node flag.
fiers to modifiees, while coordinating conjunctions
in PCEDT introduce the coordinated nodes. We
conclude that edges in reentrancies, for which the
source nodes have zero indegree, could be flipped
by changing places of their source and target nodes
and encoding the switch in the edge labels by ap-
pending the suffix flipped to the existing labels.
This is the basis for our first system: LOCAL.
In it, we locally flip all edges in reentrancies for
which the source node has zero indegree and run
the BASELINE conversion on the resulting graphs.
We apply this conversion on the training data, use
the converted training sets to train syntactic de-
pendency parsers (Bohnet, 2010) and utilize the
parsing models on the development and test data.
The parsing outputs are converted back to graphs
by simply re-flipping all the edges denoted as
flipped.
2.3 Depth-first Edge Flipping
Our second system, DFS, is based on depth-first
search graph traversal and edge flipping. In it, we
create a undirected copy of the input graph and
connect all nodes with zero indegree to the root us-
ing dummy edges. We do a depth-first traversal of
this graph, starting from the root, while perform-
ing edge lookup in the original DAG. For each DFS
edge traversal in the undirected copy, we check if
the direction of this edge in the original DAG is
identical or reversed to the traversal direction. If
it is identical, we keep the existing edge. If we
traverse the edge against its original direction, we
DM PAS PCEDT
closed LAS UAS LAS UAS LAS UAS
LOCAL 79.09 81.35 81.93 83.79 81.16 89.60
DFS 82.02 83.74 87.06 87.93 79.94 88.04
open
LOCAL 80.86 82.73 85.16 86.18 82.04 90.79
DFS 84.23 85.77 88.42 89.26 80.82 89.02
Table 4: Syntactic dependency parsing accuracy
of our systems before the tree-to-graph transfor-
mations, given as a set of labeled (LAS) and un-
labeled (UAS) attachment scores. The scores are
given for the development set.
reverse it. Finally, we delete the dummy edges and
convert the resulting graph to a dependency tree by
running the baseline, to connect the singletons to
their neighbors, and to attach predicates with zero
indegree and sentence-final nodes to the root.
We illustrate our graph-to-tree transformations
LOCAL and DFS on a gold standard graph from the
training data in Figure 3. It shows how DFS man-
ages to preserve more edges than LOCAL by per-
forming traversal flipping, while LOCAL flips only
the edges that have source nodes with zero inde-
gree. On the other hand, DFS performs more flip-
ping operations than LOCAL, but as Table 1 shows,
this does not result in substantial increase of the
label sets.
2.4 Parsing and Top Node Detection
The same syntactic parser and top node detector
are used in both LOCAL and DFS. Both systems
ran in the closed SDP track, with no additional
features for learning, and in the open track, where
they used the SDP companion data, i.e., the out-
puts of a syntactic dependency parser (Bohnet and
Nivre, 2012) and phrase-based parser (Petrov et
al., 2006) as additional features. Our choice of
parser was based on the high non-projectivity of
the resulting trees, while parsers of (Bohnet and
Nivre, 2012; Bohnet et al., 2013) could also be
used, among others. We use the parser out of
the box, i.e., without any parameter tuning or ad-
ditional features other than what was previously
listed for the open track.
Top node detection is implemented separately,
by training a sequence labeling model (Lafferty
et al., 2001; Kudo, 2005) on tokens and part-of-
speech tags from the training sets. Its accuracy
is given in Table 3. We use only the tokens and
parts of speech as features for these models, and
467
Figure 3: Illustration of graph-to-tree transformations of a gold standard graph for LOCAL and DFS. Edge
labels are omitted. The sentence (PAS, #20415005): Who that winner will be is highly uncertain.
we design our feature set by adapting the chunking
template from the CRF++ toolkit documentation.
2
We note that this model can be improved by, e.g.,
adding the open track companion features to the
feature set, but they were not used in the experi-
ments we present here.
3
Our graph-to-tree conversions expand the label
sets by appending the edge flip flag. The sizes of
the new label sets are given in Table 1 in compar-
ison to the original ones. The increase in size is
expected to affect the parsing accuracy. The pars-
ing accuracies on the development sets are given
in Table 4. The scores correlate with the label
set sizes, with a notable difference between the la-
beled (LAS) and unlabeled (UAS) attachment score
for PCEDT. The LOCAL approach tends to out-
perform DFS for PCEDT, while DFS parsers also
significantly outperform LOCAL for DM and PAS.
The open track parsers tend to perform a little bet-
ter as they make use of the additional features.
In Table 2, we measure the theoretical maxi-
mum accuracy for parsers based on our two con-
versions in comparison with the baseline. There,
we run BASELINE, LOCAL and DFS on the devel-
opment set and convert the trees back to graphs
right away, i.e., without the parsing step, so as
to observe the dissipation of the conversion. The
scores show that LOCAL and DFS outperform
BASELINE by a large margin, while the maximum
accuracy for DFS is larger than the one for LOCAL,
1 point for PCEDT and around 5 points for DM
and PAS. This is due to DFS performing non-local
edge flipping, thus preserving more edges. The
parsing scores from Table 4 and the maximum ac-
curacy from Table 2 show that our systems are not
2
http://crfpp.googlecode.com/svn/
trunk/doc/index.html
3
The recall would increase by 15 points, amounting to a
10 point increase in F
1
for top node detection in DM.
closed open
dev LF UF LF UF
LOCAL 76.70 82.01 77.87 83.19
DFS 78.49 83.78 80.03 85.31
test
LOCAL 75.94 81.58 76.79 82.52
DFS 77.34 82.99 78.60 84.32
Table 5: Overall accuracy for our LOCAL and DFS
systems, i.e., averaged labeled and unlabeled F
1
scores over the three annotations.
as lossy in graph-tree conversions as the baseline,
while they pay the price in the number of new la-
bels in actual parsing and, subsequently, in the ac-
curacy of the dependency parsers. Thus, LAS and
UAS for the baseline are 1-2 points higher than the
scores in Table 4 for DM and PCEDT, while our
scores are 3-4 points higher for PAS.
3 Results and Discussion
As in the official SDP scoring, we express the
results in terms of labeled and unlabeled preci-
sion (LP, UP) and recall (LR, UR), their harmonic
means, the F
1
scores (LF, UF), and sentence-level
exact matches (LM, UM). The official SDP scorer
reports on two variants of these scores: the one
taking into account the virtual edges to top nodes
and the one excluding those edges. The former is
less relaxed as it requires the top nodes to be pre-
dicted, and this is the only one we use in this re-
port. We note that for our systems, the scores with-
out the virtual edges are approximately 2 points
higher for all the metrics.
The overall scores are given in Table 5. There,
we provide the labeled and unlabeled F
1
scores on
the development and test data in the closed and
open track, averaged for all three annotations. The
open track systems consistently score approxi-
468
closed track DM PAS PCEDT
LP LR LF LM LP LR LF LM LP LR LF LM
LOCAL 83.39 72.88 77.78 4.53 88.18 74.00 80.47 2.00 72.25 67.10 69.58 6.38
DFS 79.36 79.34 79.35 9.05 88.15 81.60 84.75 7.72 69.68 66.25 67.92 5.86
?4.03 +6.46 +1.57 +4.52 ?0.03 +7.60 +4.28 +5.72 ?2.57 ?0.85 ?1.66 ?0.52
UP UR UF UM UP UR UF UM UP UR UF UM
LOCAL 85.47 74.70 79.72 5.04 89.70 75.28 81.86 2.23 86.36 80.21 83.17 19.44
DFS 81.56 81.54 81.55 10.31 89.62 82.96 86.16 7.86 83.37 79.27 81.27 17.51
?3.91 +6.84 +1.83 +5.27 ?0.08 +7.69 +4.30 +5.63 ?3.00 ?0.94 ?1.91 ?1.93
open track DM PAS PCEDT
LP LR LF LM LP LR LF LM LP LR LF LM
LOCAL 84.54 73.80 78.80 4.53 89.72 75.08 81.75 2.00 72.52 67.33 69.83 6.08
DFS 81.32 80.91 81.11 10.46 89.41 82.61 85.88 8.46 70.35 67.33 68.80 5.79
?3.22 +7.11 +2.31 +5.93 ?0.31 +7.53 +4.13 +6.46 ?2.17 +0.00 ?1.03 ?0.29
UP UR UF UM UP UR UF UM UP UR UF UM
LOCAL 86.43 75.45 80.57 5.49 90.99 76.14 82.91 2.30 87.32 81.07 84.08 19.73
DFS 83.37 82.95 83.16 11.94 90.78 83.87 87.19 8.75 84.46 80.83 82.60 18.47
?3.06 +7.50 +2.59 +6.45 ?0.22 +7.73 +4.28 +6.45 ?2.86 ?0.24 ?1.48 ?1.26
Table 6: Breakdown of the scores for our LOCAL and DFS systems on the test sets. We provide labeled
and unlabeled precision (LP, UP), recall (LR, UR), F
1
scores (LF, UF) and exact matches (LM, UM) for
all three annotations in both the closed and the open evaluation track.
mately 1 point higher than their closed track coun-
terparts, apparently taking advantage of the ad-
ditional features available in training and testing.
The DFS system is 2 points better than LOCAL in
all scenarios, owing to the higher maximum cover-
age of the original graphs in the conversions. The
large label sets amount to a difference of approxi-
mately 6 points between the labeled and unlabeled
accuracies in favor of the latter attachment.
Table 6 is a breakdown of the scores in Table 5
across the three annotations and the two tracks.
Here, we pair the F
1
scores with the correspond-
ing precision and recall scores. We also explicitly
denote the differences in scores between LOCAL
and DFS. For DM and PAS, the score patterns
are very similar: due to the larger label set and
less regular edge flipping, DFS has a 3-4 points
lower precision than LOCAL, while its recall is 6-8
points higher, amounting to the overall improve-
ment of approximately 4 points F
1
. In contrast, on
the PCEDT data, LOCAL outperforms DFS by ap-
proximately 1.5 points. We note that the label sets
for PCEDT are much larger than for DM and PAS
and that the favorable reentrancies in PCEDT are
much less frequent to begin with (see Table 1, Ta-
ble 2 and Figure 2). At 14 points F
1
, the discrep-
ancy between the labeled and unlabeled scores is
much higher for PCEDT than for DM and PAS,
for which we observe a 1-2 point difference.
The exact match scores (LM, UM) favor DFS
over LOCAL by approximately 5 points for DM
and PAS, while LOCAL is better than DFS for
PCEDT by 1-2 points. In absolute terms, the PAS
scores are higher than those for DM and PAS in
both our systems. This difference between the
token-level and the sentence-level scores stems
from the properties of our graph-tree transforma-
tions as, e.g., certain edges in undirected cycles
could not be addressed by our edge inversions.
At approximately 81, 86 and 70 points F
1
for
DM, PAS and PCEDT, in this contribution we
have shown that focusing on graph-tree transfor-
mations for the utilization of a syntactic depen-
dency parser lets us achieve good overall perfor-
mance in the semantic dependency parsing task. In
the future, we will further investigate what trans-
formations are appropriate for different styles of
graph-based semantic representations, and what
we can learn from this both for improving SDP
parser accuracy and for making linguistically mo-
tivated design choices for graph-based seman-
tic representations. Furthermore, we will extend
our system to cover inherently non-tree-like struc-
tures, such as those induced by control verbs.
Acknowledgements We are grateful to Stephan
Oepen for all the discussions on the properties of
the SDP datasets, and for providing the infrastruc-
ture for running the systems. We also thank the
anonymous reviewers for their valuable insight.
469
References
Bernd Bohnet and Joakim Nivre. 2012. A Transition-
Based System for Joint Part-of-Speech Tagging and
Labeled Non-Projective Dependency Parsing. In
Proc. EMNLP-CoNLL, pages 1455?1465.
Bernd Bohnet, Joakim Nivre, Igor Boguslavsky,
Rich?ard Farkas, Filip Ginter, and Jan Haji?c. 2013.
Joint Morphological and Syntactic Analysis for
Richly Inflected Languages. TACL, 1:415?428.
Bernd Bohnet. 2010. Top Accuracy and Fast Depen-
dency Parsing is not a Contradiction. In Proc. COL-
ING, pages 89?97.
David Chiang, Jacob Andreas, Daniel Bauer,
Karl Moritz Hermann, Bevan Jones, and Kevin
Knight. 2013. Parsing Graphs with Hyperedge
Replacement Grammars. In Proc. ACL, pages
924?932.
Silvie Cinkov?a, Josef Toman, Jan Haji?c, Krist?yna
?
Cerm?akov?a, V?aclav Klime?s, Lucie Mladov?a,
Jana
?
Sindlerov?a, Krist?yna Tom?s?u, and Zden?ek
?
Zabokrtsk?y. 2009. Tectogrammatical Annotation
of the Wall Street Journal. The Prague Bulletin of
Mathematical Linguistics, 92:85?104.
Dipanjan Das, Nathan Schneider, Desai Chen, and
Noah A. Smith. 2010. Probabilistic Frame-
Semantic Parsing. In Proc. NAACL, pages 948?956.
Dan Flickinger, Yi Zhang, and Valia Kordoni. 2012.
DeepBank: A Dynamically Annotated Treebank of
the Wall Street Journal. In Proc. TLT, pages 85?96.
Vibhav Gogate and Rina Dechter. 2004. A Complete
Anytime Algorithm for Treewidth. In Proc. UAI,
pages 201?208.
James Henderson, Paola Merlo, Ivan Titov, and
Gabriele Musillo. 2013. Multilingual Joint Pars-
ing of Syntactic and Semantic Dependencies with a
Latent Variable Model. Computational Linguistics,
39(4):949?998.
Angelina Ivanova, Stephan Oepen, Lilja ?vrelid, and
Dan Flickinger. 2012. Who Did What to Whom?
A Contrastive Study of Syntacto-Semantic Depen-
dencies. In Proc. Linguistic Annotation Workshop,
pages 2?11.
Bevan Keeley Jones, Sharon Goldwater, and Mark
Johnson. 2013. Modeling Graph Languages with
Grammars Extracted via Tree Decompositions. In
Proc. FSMNLP, pages 54?62.
Taku Kudo. 2005. CRF++: Yet another CRF
toolkit. Software available at http://crfpp.
sourceforge.net/.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional Random Fields: Prob-
abilistic Models for Segmenting and Labeling Se-
quence Data. In Proc. ICML, pages 282?289.
Mitchell Marcus, Mary Ann Marcinkiewicz, and Beat-
rice Santorini. 1993. Building a Large Annotated
Corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313?330.
Yusuke Miyao, Takashi Ninomiya, and Jun?ichi Tsujii.
2004. Corpus-oriented Grammar Development for
Acquiring a Head-Driven Phrase Structure Grammar
from the Penn Treebank. In Proc. IJCNLP, pages
684?693.
Joakim Nivre. 2006. Inductive Dependency Parsing.
Springer.
Stephan Oepen and Jan Tore L?nning. 2006.
Discriminant-Based MRS Banking. In Proc. LREC,
pages 1250?1255.
Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Dan Flickinger, Jan Haji?c, Angelina
Ivanova, and Yi Zhang. 2014. SemEval 2014 Task
8: Broad-Coverage Semantic Dependency Parsing.
In Proceedings of the 8th International Workshop on
Semantic Evaluation.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning Accurate, Compact, and
Interpretable Tree Annotation. In Proc. COLING-
ACL, pages 433?440.
Kenji Sagae and Jun?ichi Tsujii. 2008. Shift-Reduce
Dependency DAG Parsing. In Proc. COLING, pages
753?760.
470
Referring Expressions as Formulas of Description Logic
Carlos Areces
INRIA Nancy Grand Est
Nancy, France
areces@loria.fr
Alexander Koller
University of Edinburgh
Edinburgh, UK
a.koller@ed.ac.uk
Kristina Striegnitz
Union College
Schenectady, NY, US
striegnk@union.edu
Abstract
In this paper, we propose to reinterpret the
problem of generating referring expressions
(GRE) as the problem of computing a formula
in a description logic that is only satisfied by
the referent. This view offers a new unifying
perspective under which existing GRE algo-
rithms can be compared. We also show that
by applying existing algorithms for computing
simulation classes in description logic, we can
obtain extremely efficient algorithms for rela-
tional referring expressions without any dan-
ger of running into infinite regress.
1 Introduction
The generation of referring expressions (GRE) is
one of the most active and successful research ar-
eas in natural language generation. Building upon
Dale and Reiter?s work (Dale, 1989; Dale and Reiter,
1995), various researchers have added extensions
such as reference to sets (Stone, 2000), more expres-
sive logical connectives (van Deemter, 2002), and
relational expressions (Dale and Haddock, 1991).
Referring expressions (REs) involving relations,
in particular, have received increasing attention re-
cently; especially in the context of spatial refer-
ring expressions in situated generation (e.g. (Kelle-
her and Kruijff, 2006)), where it seems particularly
natural to use expressions such as ?the book on the
table?. However, the classical algorithm by Dale and
Haddock (1991) was recently shown to be unable
to generate satisfying REs in practice (Viethen and
Dale, 2006). Furthermore, the Dale and Haddock al-
gorithm and most of its successors (such as (Kelle-
her and Kruijff, 2006)) are vulnerable to the prob-
lem of ?infinite regress?, where the algorithm jumps
back and forth between generating descriptions for
two related individuals infinitely, as in ?the book on
the table which supports a book on the table . . . ?.
In this paper, we propose to view GRE as the
problem of computing a formula of description logic
(DL) that denotes exactly the set of individuals that
we want to refer to. This very natural idea has been
mentioned in passing before (Krahmer et al, 2003;
Gardent and Striegnitz, 2007); however, we take it
one step further by proposing DL as an interlingua
for comparing the REs produced by different ap-
proaches to GRE. In this way, we can organize ex-
isting GRE approaches in an expressiveness hierar-
chy. For instance, the classical Dale and Reiter al-
gorithms compute purely conjunctive formulas; van
Deemter (2002) extends this language by adding the
other propositional connectives, whereas Dale and
Haddock (1991) extends it by allowing existential
quantification.
Furthermore, the view of GRE as a problem of
computing DL formulas with a given extension al-
lows us to apply existing algorithms for the lat-
ter problem to obtain efficient algorithms for GRE.
We present algorithms that compute such formulas
for the description logics EL (which allows only
conjunction and existential quantification) andALC
(which also allows negation). These algorithms ef-
fectively compute REs for all individuals in the do-
main at the same time, which allows them to system-
atically avoid the infinite regress problem. The EL
algorithm is capable of generating 67% of the rela-
tional REs in the Viethen and Dale (2006) dataset, in
about 15 milliseconds. The ALC algorithm is even
faster; it computes relational REs for all 100 indi-
viduals in a random model in 140 milliseconds.
The paper is structured as follows. In Section 2,
42
we will first define description logics. We will then
show how to generate REs by computing DL sim-
ilarity sets for ALC and EL in Section 3. In Sec-
tion 4, we evaluate our algorithms and discuss our
results. Section 5 compares our approach to related
research; in particular, it shows how various promi-
nent GRE algorithms fit into the DL framework.
Section 6 concludes and points to future work.
2 Description logics and similarity
In this paper, we will represent referring expres-
sions as formulas of description logic (Baader et al,
2003). In order to make this point, we will now de-
fine the two description logics we will be working
with: ALC and EL.
Formulas (or concepts) ? of ALC are generated
by the following grammar:
?,?? ::= > | p | ?? | ? u ?? | ?R.?
where p is in the set of propositional symbols prop,
and R is in the set of relational symbols rel. EL is
the negation-free fragment of ALC.
Formulas of both ALC and EL are interpreted in
ordinary relational first-order modelsM = (?, || ? ||)
where ? is a non-empty set and || ? || is an interpreta-
tion function such that:
||p|| ? ? for p ? prop
||R|| ? ??? for R ? rel
||??|| = ?? ||?||
||? u ??|| = ||?|| ? ||??||
||?R.?|| = {i | for some i?, (i, i?) ? ||R||
and i? ? ||?||}.
Every formula of a description logic denotes a
set of individuals in the domain; thus we can use
such formulas to describe sets. For instance, in the
model in Fig. 1b, the formula flower denotes the set
{f1, f2}; the formula floweru?in.hat denotes {f2};
and the formula flower u ??in.hat denotes {f1}.
Different description logics differ in the inventory
of logical connectives they allow: While ALC per-
mits negation, EL doesn?t. There are many other
description logics in the literature; some that we
will get back to in Section 5 are CL (EL without
existential quantification, i.e., only conjunctions of
atoms); PL (ALC without existential quantification,
i.e., propositional logic); and ELU (?) (EL plus dis-
junction and atomic negation).
Below, we will use a key notion of formula preser-
vation that we call similarity. For any DL L, we
will say that an individual i is L-similar to i? in a
given modelM if for any formula ? ? L such that
i ? ||?||, we also have i? ? ||?||. Equivalently, there
is no L-formula that holds of i but not of i?. We say
that the L-similarity set of some individual i is the
set of all individuals to which i is L-similar.
Notice that similarity is not necessarily a symmet-
rical relation: For instance, f1 is EL-similar to f2 in
Fig. 1b, but f2 is not EL-similar to f1 (it satisfies the
formula ?in.hat and f1 doesn?t). However, ALC-
similarity is a symmetrical relation because the lan-
guage contains negation; and indeed, f1 is notALC-
similar to f2 either because it satisfies ??in.hat. Be-
causeALC is more expressive than EL, it is possible
for some individual a to be EL-similar but notALC-
similar to some individual b, but not vice versa.
3 Generating referring expressions
Now we apply description logic to GRE. The core
claim of this paper is that it is natural and useful to
view the GRE problem as the problem of computing
a formula of some description logic L whose exten-
sion is a given target set A of individuals.
L-GRE PROBLEM
Input: A modelM and a target set A ? ?.
Output: A formula ? ? L such that ||?|| = A
(if such a formula exists).
In the examples above, it is because flower u
?in.hat denotes exactly {f2} that we can say ?the
flower in the hat? to refer to f2. This perspective pro-
vides a general framework into which many existing
GRE approaches fit: Traditional attribute selection
(Dale and Reiter, 1995) corresponds to building DL
formulas that are conjunctions of atoms; relational
REs as in Dale and Haddock (1991) are formulas of
EL; and so on. We will further pursue the idea of or-
ganizing GRE approaches with respect to the variant
of DL they use in Section 5.
For the rest of this paper, we assume that we are
generating a singular RE, i.e., the target set A will
be a singleton. In this case, we will only be able
to generate a formula that denotes exactly A = {a}
(i.e., a RE that uniquely refers to a) if there is no
43
f1
floor
t
2
table
t
1
table
b
2
c
2
bowl
cup
b
1
bowl
c
1
cup
on
on
on
on
in
in
(a) (b)
r
1
rabbit
r
2
rabbit
r
3
rabbit
r
4
rabbith
1
hat
h
4
hat
h
2
hat
h
3
hat
f
1
flower
f
2
flower
b
1
bathtub
in
in
in
Figure 1: (a) The Dale and Haddock (1991) scenario; (b)
the Stone and Webber (1998) scenario.
other individual b to which a is similar; otherwise,
any formula that is satisfied by a is also satisfied by
b. Conversely, if we know that a is not similar to any
other individual, then there is a formula that is satis-
fied by a and not by anything else; this formula can
serve as a unique singular RE. In other words, we
can reduce the L-GRE problem for a given model
to the problem of computing the L-similarity sets of
this model. Notice that this use of similarity sets can
be seen as a generalization of van Deemter?s (2002)
?satellite sets? to relational descriptions.
In the rest of this section, we will present algo-
rithms that compute the similarity sets of a given
model for ALC and EL, together with characteris-
tic formulas that denote them. In the ALC case,
we adapt a standard algorithm from the literature
for computing simulation classes; we will then fur-
ther adapt this algorithm for EL. In effect, both al-
gorithms compute REs for all individuals in some
model at the same time ? very efficiently and with-
out any danger of infinite regress.
3.1 Computing similarity sets
It can be shown that for ALC, the similarity sets
of a finite model coincide exactly with the simu-
lation classes of this model. Simulation classes
have been studied extensively in the literature (see
e.g., Blackburn et al (2001); Kurtonina and de Ri-
jke (1998)), and there are several efficient algorithms
for computing ALC-simulation classes (Hopcroft,
1971; Paige and Tarjan, 1987; Dovier et al, 2004).
However, these algorithms will only compute the
simulation classes themselves. Here we extend the
Hopcroft (1971) algorithm such that it computes,
along with each set, also a formula that denotes ex-
actly this set. We can then use these formulas as
representations of the referring expressions.
The pseudocode for our ALC algorithm is shown
as Algorithm 1 (with L = ALC) and Algorithm 2.
Given a modelM = (?, || ? ||), the algorithm com-
putes a set RE of ALC formulas such that {||?|| |
? ? RE} is the set of ALC-similarity sets of
M. The algorithm starts with RE = {>} (where
||>|| = ?), and successively refines RE by mak-
ing its elements denote smaller and smaller sets. It
maintains the invariant that at the start and end of ev-
ery iteration, {||?|| | ? ? RE} is always a partition
of ?. The algorithm iterates over all propositional
and relational symbols in prop and rel to construct
new formulas until either all formulas in RE denote
singletons (i.e., there is only one individual that sat-
isfies them), or no progress has been made in the
previous iteration. In each iteration, it calls the pro-
cedure addALC(?, RE ), which intersects ? with any
formula ? ? RE which does not denote a singleton
and which is not equivalent to ? and to ??. In this
case, it replaces ? in RE by ? u ? and ? u ??.
TheALC algorithm computes theALC-similarity
sets of the model in timeO(n3), where n is the num-
ber of individuals in the domain. However, it will
freely introduce negations in the case distinctions,
which can make the resulting formula hard to realize
(see also Section 4.3). This is why we also present
an algorithm for the EL-similarity sets; EL corre-
sponds to positive relational REs, which are gener-
ally much easier to realize.
We obtain the EL algorithm by replacing the call
to addALC in Algorithm 1 by a call to addEL, which
is defined in Algorithm 3. As before, the algo-
rithm maintains a set RE = {?1, . . . , ?n} of for-
mulas (this time of EL) such that ||?1|| ? . . . ?
||?n|| = ?, and which it refines iteratively. However,
where the ALC algorithm maintains the invariant
that ||?1||, . . . , ||?n|| is a partition of ?, we weaken
this invariant to the requirement that there are no
m ? 2 pairwise different indices 1 ? i1, . . . , im ?
n such that ||?i1 || = ||?i2 || ? . . .? ||?im ||. We call ?i1
subsumed if such a decomposition exists.
Because it maintains a weaker invariant, the set
RE may contain more formulas at the same time in
the EL algorithm than in the ALC algorithm. Given
that ? has an exponential number of subsets, there is
a risk that the EL algorithm might have worst-case
44
Algorithm 1: Computing the L-similarity sets
Input: A modelM = (?, || ? ||)
Output: A set RE of formulas such that
{||?|| | ? ? RE} is the set of
L-similarity sets ofM.
RE ? {>}1
for p ? prop do2
addL(p,RE )3
while exists some ? ? RE , |||?|||M > 1 do4
for ? ? RE , R ? rel do5
addL(?R.?,RE )6
if made no changes to RE then7
exit8
exponential runtime (although we are not aware of
such worst-case examples). We leave a more careful
complexity analysis for future work.
We presented both algorithms as first refining RE
according to propositional symbols, and then by re-
lational expressions of increasing depth. But actu-
ally, propositional symbols can be encoded using
new relational symbols (e.g., we could represent that
f1 is a flower in Fig. 1 as a relation labeled flower
from f1 to an additional dummy element d). In this
way, we don?t need to distinguish between proposi-
tions and relations, and any arbitrary preference or-
dering of properties can be used.
3.2 Some examples
Let?s try our algorithms on some examples. We
first run the EL algorithm on the model shown in
Fig. 1a, which is taken from Dale and Haddock
(1991). The algorithm starts with RE = {>}. In
the first loop, it adds the formulas floor, bowl, cup,
and table, and then removes > because it is now
subsumed. Not all of these formulas denote single-
tons; for instance, ||cup|| contains two individuals.
So we iterate over the relations to refine our for-
mulas. After the first iteration over the relations,
we have RE = {floor, bowl u ?on.floor, bowl u
?on.table, cup, table}. Notice that bowl has become
subsumed, but we haven?t distinguished the cups
and tables further.
Now we can use the split between the bowls to
distinguish the cups in the second iteration. The re-
sult of this is RE = {floor, bowlu?on.floor, bowlu
Algorithm 2: addALC(?,RE )
for ? ? RE with |||?||| > 1 do1
if ||? u ?|| 6= ? and ||? u ??|| 6= ? then2
add ? u ? and ? u ?? to RE ;3
remove ? from RE ;4
Algorithm 3: addEL(?, RE )
for ? ? RE with |||?||| > 1 do1
if ? u ? is not subsumed in RE and2
||? u ?|| 6= ? and ||? u ?|| 6= ||?|| then
add ? u ? to RE3
remove subsumed formulas from RE4
?on.table, cup u ?in.(bowl u ?on.floor), cup u
?in.(bowl u ?on.table), table}. At this point, all
formulas except table denote singletons, and further
iterations don?t allow us to refine table; so the al-
gorithm terminates. Each formula with a singleton
extension {a} is a unique description of a; for in-
stance, cup u ?in.(bowl u ?on.table) is only satis-
fied by c2, so we may refer to c2 as ?the cup in the
bowl on the table?. Notice that the algorithm didn?t
focus on any particular individual; it simultaneously
generated REs for all individuals except for the two
tables (which are similar to each other).
The EL algorithm has a harder time with the ex-
ample in Fig. 1b (Stone and Webber, 1998). While
it will correctly identify r1 as ?the rabbit in the hat?
and f2 as ?the flower in the hat?, it will not be able to
compute a RE for f1 because f1 is EL-similar to f2.
Indeed, the algorithm terminates with RE contain-
ing both flower and floweru?in.hat. This is a typical
pattern for asymmetrical cases of similarity in EL: If
there are two formulas ?1 and ?2 in the output set
with ||?1|| ? ||?2||, then there is generally some in-
dividual b ? ||?2|| ? ||?1|| such that all individuals in
||?1|| are similar to b, but not vice versa. By contrast,
theALC algorithm can exploit the greater expressiv-
ity of ALC to split flower into the two new formulas
floweru?in.hat and floweru??in.hat, generating a
unique RE for f1 as well.
4 Discussion
We will now describe two experiments evaluating
the quality of the EL algorithm?s output and the effi-
45
Figure 2: A schematic view of the filing cabinets.
ciency of both of our algorithms, and we discuss the
interface between our algorithms and realization.
4.1 Evaluation: Output quality
To compare the descriptions generated by our al-
gorithm to those humans produce, we use a cor-
pus of human-generated referring expressions col-
lected and made available by Jette Viethen and
Robert Dale.1 They asked human subjects to de-
scribe one of 16 filing cabinet drawers. The draw-
ers had different colors and were arranged in a
four-by-four grid (see Fig. 2). The human subjects
used four non-relational properties (the drawer?s
color, its column and row number, and whether
it is in a corner) and five relational properties
(above, below, next to, left of, right of). Of the 118
referring expressions obtained in the experiment,
only 15 use relations.
Viethen and Dale (2006) describe the data in
more detail and present results of evaluating the Full
Brevity algorithm, the Incremental Algorithm (both
by Dale and Reiter (1995)), and the Relational Al-
gorithm (Dale and Haddock, 1991) on this corpus.
The Incremental Algorithm is dependent on a pre-
defined ordering in which properties are added to
the description. Viethen and Dale, therefore, try all
possible orderings and evaluate what percentage of
descriptions an algorithm can generate with any of
them. The Full Brevity and the Relational Algo-
rithms choose properties based on their discrimina-
tory power and only use the orderings as tie break-
ers. Viethen and Dale found that the Incremental
Algorithm is capable of generating 98 of the 103
non-relational descriptions. However, the Relational
Algorithm was unable to generate even a single one
of the human-generated relational descriptions.
We replicated Viethen and Dale?s experiment for
1http://www.ics.mq.edu.au/?jviethen/drawers
the EL algorithm presented above. In the non-
relational case, our results are the same as theirs for
the Incremental Algorithm: the EL algorithm gener-
ates 98 of the 103 non-relational descriptions, using
four (of the possible) orderings. This is because the
two algorithms perform essentially the same compu-
tations if there are no relations.
When we add relations, our algorithm is able to
generate 10 of the 15 human-produced relational
descriptions correctly (in addition to the 98 non-
relational descriptions). Fig. 3 gives example out-
puts of the EL algorithm for three different order-
ings, which together achieve this coverage. Of the
five human-produced descriptions that the EL algo-
rithm cannot generate, three involve references to
sets (the two blues ones in horizontal sequence/the
two yellow drawers), and two contain so much re-
dundant information that our algorithm cannot re-
produce them: Similarly to the Incremental Algo-
rithm, our algorithm allows for some redundancy,
but stops once it has found a distinguishing descrip-
tion. It does, however, generate other, simpler de-
scriptions for these referents.
4.2 Evaluation: Efficiency
Both the EL and the ALC algorithms took about 15
milliseconds to compute distinguishing formulas for
all 16 individuals in the Viethen and Dale dataset.2
In order to get a more comprehensive picture
of the algorithms? efficiency, we ran them on ran-
dom models with increasing numbers of individu-
als. Each model had random interpretations for ten
different propositional and four relational symbols;
each individual had a 10% chance to be in the exten-
sion of each propositional symbol, and each pair of
individuals had a 10% chance to be related by a re-
lational symbol. The results (averaged over 10 runs
for each model size) are shown in Fig. 4. The EL al-
gorithm takes about 350 ms on average to generate
relational REs for all individuals in the model of size
100, i.e., less than 4 ms on average for each individ-
ual. The ALC algorithm is even faster, at about 140
ms for the model of size 100. As far as we know,
these are by far the fastest published runtimes for
2Runtimes were measured on a MacBook Pro (Intel Core 2
Duo, 2.16 GHz) running Java 1.6 beta. We allowed the Java
VM to warm up, i.e., just-in-time compile all bytecode, before
taking the measurements.
46
id
human-produced description
output of the EL algorithm
2
the orange drawer above the blue drawer
orangeu ?above.blue / orange u ?above.(?below.(orange) u blue) / orange u ?next.(blue) u ?next.(pink)
4
the yellow drawer on the top of the pink one
yellow u ?above.pink / yellow u corner u ?above.pink / yellow u corner u ?above.(?next.(yellow) u pink)
5
? the pink drawer in the fourth column below the yellow one
pink u ?above.orange / pink u ?below.yellow / pink u ?next.(yellow) u ?above.(?next.(yellow) u orange)
6
the yellow drawer on top of the yellow drawer (2?) / ? the drawer after the two blue ones in horizontal sequence
yellow u ?above.yellow / yellow u ?below.pink / yellow u ?next.(blue) u ?next.(pink)
7
the blue drawer below the orange one / ? the blue drawer below the orange drawer in the second column
blueu?above.(blue)u?next.(?above.(orange)ublue) / blueu?below.(orange) / blueu?next.(blue)u?next.(yellow)
10
the blue drawer above the pink drawer (2?)
blueu ?above.(pink) / blue u ?above.(pink) u ?below.(blue) / blue u ?next.(orange) u ?next.(yellow)
11
the yellow drawer next to the orange drawer (2?)
yellow u ?above.orange / yellow u ?below.yellow / yellow u ?next.orange
12
the orange drawer below the pink drawer
orange u ?above.(pink u corner) / orangeu ?below.pink / orange u ?next.yellow
14
? the orange drawer below the two yellow drawers (2?)
orange u ?next.(pink u corner) u ?next.(pink) / orange u ?below.yellow / orange u ?next.(pink u corner)
Figure 3: The relational descriptions from Viethen and Dale (2006), annotated with the drawer id and the outputs of the
EL algorithm using three different orderings. Notice that four descriptions occurred twice in the corpus. Descriptions
that the EL algorithm cannot generate with any ordering are marked by ?. Generated descriptions that match one
produced by humans are in boldface.
any relational GRE algorithm in the literature.
4.3 Interface to realization
Our GRE algorithms do not guarantee that the for-
mula they compute can actually be realized in lan-
guage. For example, none of the formulas our al-
gorithms computed in the Viethen and Dale domain
contained an atom that would commonly be realized
as a noun; the property drawer is never used be-
cause it applies to all individuals in the domain. This
particular problem could easily be worked around
in a post-processing step. However, another prob-
lem arises from the massive use of negation in the
ALC algorithm; it will be hard for any realizer to
find a reasonable way of expressing a formula like
??R.(?Pu?Q) as a smooth noun phrase. Although
we agree with van Deemter (2002) and others that
the careful use of negation and disjunction can im-
prove REs, these connectives must not be overused.
Thus we consider the formulas computed by the EL
algorithm ?safer? with respect to realization.
Of course, we share the problem of interfacing
GRE and realization with every other approach that
separates these two modules, i.e., almost the en-
tire GRE literature (notable exceptions are, e.g., Ho-
racek (1997) and SPUD (Stone and Webber, 1998)).
0
100
200
300
400
10 20 30 40 50 60 70 80 90 100
EL ALC
Figure 4: Average runtimes (in ms) of the two algorithms
on random models with different numbers of individuals.
In principle, we believe that it is a good idea to
handle sentence planning and realization in a single
module; for instance, SPUD can use its awareness
of the syntactic context to generate succinct REs as
in ?take the rabbit from the hat?. We hope that the
ideas we have explored here for efficient and ex-
pressive RE generation can eventually be combined
with recent efficient algorithms for integrated sen-
tence planning and realization, such as in Koller and
Stone (2007).
One problem that arises in our approach is that
47
both algorithms derive some measure of efficiency
from their freedom to build formulas without hav-
ing to respect any linguistic constraints. It seems
straightforward, for instance, to extend Krahmer et
al.?s (2003) approach such that it only considers sub-
graphs that can actually be realized, because their al-
gorithm proceeds by a genuine search for uniquely
identifying subgraphs, and will simply take a differ-
ent branch of the search if some subgraph is useless.
This would be harder in our case. Our algorithms
don?t search in the same way; if we disallow certain
refinements of a partition, we have to allow the al-
gorithms to backtrack and thus jeopardize the worst-
case polynomial runtime. Investigating this inter-
play between efficiency and linguistic constraints is
an interesting avenue for future research.
5 A unified perspective on GRE
Viewing GRE as a problem of generating DL for-
mulas offers a unified perspective: It is the prob-
lem of computing a DL formula with a given exten-
sion. Many existing approaches can be subsumed
under this view; we have summarized this for some
of them in Fig. 5, along with the DL fragment they
use. We already discussed some of these approaches
in Section 3. Furthermore, the non-relational but
negative and disjunctive descriptions generated by
van Deemter (2002) are simply formulas of PL;
and Gardent (2002) generalizes this into generating
formulas of ELU (?), i.e., EL plus disjunction and
atomic negation. The approach presented here fits
well into this landscape, and it completes the pic-
ture by showing how to generate REs inALC, which
combines all connectives used in any of these previ-
ous approaches.
Where our approach breaks new ground is in the
way these formulas are computed: It successively
refines a decomposition of the domain into subsets.
In this way, it is reminiscent of the Incremental Al-
gorithm, which in fact can be seen as a special case
of the EL algorithm. However, unlike Dale and
Haddock (1991) and its successors, such as Kelle-
her and Kruijff (2006), we do not have to take spe-
cial precautions to avoid infinite regress. While Dale
and Haddock?s algorithm attempts to generate a RE
for a single individual, for successive individuals in
the model, our algorithms consider all individuals in
GRE algorithm DL variant
Dale and Reiter (1995) CL
van Deemter (2002) PL
Dale and Haddock (1991) EL
Kelleher and Kruijff (2006) EL
Gardent (2002) ELU (?)
Figure 5: DL variants used by different GRE algorithms.
parallel. It monotonically refines a partition of the
model and never needs to backtrack, and therefore
is always guaranteed to terminate.
Perhaps closest in spirit to our approach is Krah-
mer et al?s graph algorithm (2003), which also com-
putes REs by extending them successively. How-
ever, their subgraphs go beyond the expressive
power of ALC in that they can distinguish between
?the dog that bites a dog? and ?the dog that bites it-
self?. The price they pay for this increase in expres-
sive power is an NP-complete worst-case complex-
ity. Interestingly, Krahmer et al themselves discuss
the possibility of seeing their subgraphs as formu-
las of hybrid logic which are satisfied at the points
where the subgraph can be embedded; and hybrid
logics can be seen as very expressive description
logics (Areces and ten Cate, 2006).
6 Conclusion
In this paper, we have explored the idea of view-
ing the generation of singular REs as the problem
of computing a DL formula with a given extension.
We have shown how such formulas can be computed
efficiently (for ALC and EL) by adapting existing
algorithms from the literature. The EL algorithm
is able to generate 95% of the non-relational and
67% of the relational REs from Viethen and Dale
(2006). Both algorithms are extremely efficient (350
ms and 140 ms respectively to generate relational
REs for all individuals in a random model with 100
individuals); to our knowledge, these are by far the
fastest runtimes for relational GRE reported in the
literature. We have made our implementation avail-
able online at http://code.google.com/p/
crisp-nlg/wiki/DlGre.
Because they compute referring expressions for
all individuals in the domain at once, our algorithms
will perform especially strongly in static settings,
such as the generation of descriptions for museum
48
exhibits, in which the individuals and their proper-
ties don?t change much. However, even in more dy-
namic settings, our algorithms have a chance to out-
perform search algorithms like Dale and Haddock?s
in the average case because they can?t get stuck in
unproductive branches of the search space. Never-
theless, one interesting question for future research
is how to incrementally update simulation classes
when the model changes. Similarly, it would be
interesting to explore how different linguistic con-
straints and attribute orderings can be taken into ac-
count efficiently, how our algorithms could be in-
tegrated with more standard DL T-Box inferences,
and how they can be adapted to use inverse relations
or to compute REs for sets. In exploring these ex-
tensions we will be able to draw on a rich body of
literature that has already considered many variants
of simulation algorithms addressing similar issues.
In experimenting with the Viethen and Dale data,
we found that there is no single ordering that covers
all human-produced descriptions, which seems to be
in contrast to Dale and Reiter?s (1995) assumption
that there is only one ordering for each given do-
main. In fact, it is not even the case that each speaker
consistently uses just one ordering. An interesting
open research question is thus what factors deter-
mine which ordering is used. Unfortunately, both
in the Viethen and Dale dataset and in the TUNA
corpus (van Deemter et al, 2006), only a minor-
ity of referring expressions is relational, maybe be-
cause these domains lend themselves very well to
row/column style propositional REs. We are cur-
rently collecting REs in a domain in which propo-
sitional REs are less preferred.
Acknowledgments. We are grateful to Hector
Geffner (who independently suggested to view GRE as
computation of DL formulas), Kees van Deemter, and
Emiel Krahmer for interesting discussions. We also
thank Jette Viethen and Robert Dale for making their
corpus available, and the reviewers for their comments.
References
C. Areces and B. ten Cate. 2006. Hybrid logics. In
P. Blackburn, F. Wolter, and J. van Benthem, editors,
Handbook of Modal Logics. Elsevier.
F. Baader, D. McGuiness, D. Nardi, and P. Patel-
Schneider, editors. 2003. The Description Logic
Handbook: Theory, implementation and applications.
Cambridge University Press.
P. Blackburn, M. de Rijke, and Y. Venema. 2001. Modal
Logic. Cambridge University Press.
R. Dale and N. Haddock. 1991. Generating referring
expressions involving relations. In Proc. of the 5th
EACL.
R. Dale and E. Reiter. 1995. Computational interpreta-
tions of the Gricean maxims in the generation of refer-
ring expressions. Cognitive Science, 19.
R. Dale. 1989. Cooking up referring expressions. In
Proc. of the 27th ACL.
A. Dovier, C. Piazza, and A. Policriti. 2004. An ef-
ficient algorithm for computing bisimulation equiva-
lence. Theoretical Computer Science, 311(1?3).
C. Gardent and K. Striegnitz. 2007. Generating bridg-
ing definite descriptions. In H. Bunt and R. Muskens,
editors, Computing Meaning, Vol. 3. Springer.
C. Gardent. 2002. Generating minimal definite descrip-
tions. In Proc. of the 40th ACL.
J. Hopcroft. 1971. An n log(n) algorithm for minimizing
states in a finite automaton. In Z. Kohave, editor, The-
ory of Machines and computations. Academic Press.
H. Horacek. 1997. An algorithm for generating refer-
ential descriptions with flexible interfaces. In Proc. of
the 35th ACL.
J. Kelleher and G.-J. Kruijff. 2006. Incremental genera-
tion of spatial referring expressions in situated dialog.
In Proc. of COLING/ACL.
A. Koller and M. Stone. 2007. Sentence generation as
planning. In Proc. of the 45th ACL.
E. Krahmer, S. van Erk, and A. Verleg. 2003. Graph-
based generation of referring expressions. Computa-
tional Linguistics, 29(1).
N. Kurtonina and M. de Rijke. 1998. Expressiveness
of concept expressions in first-order description logics.
Artificial Intelligence, 107.
R. Paige and R. Tarjan. 1987. Three partition refinement
algorithms. SIAM Journal on Computing, 16(6).
M. Stone and B. Webber. 1998. Textual economy
through close coupling of syntax and semantics. In
Proc. of the 9th INLG workshop.
M. Stone. 2000. On identifying sets. In Proc. of the 1st
INLG.
K. van Deemter, I. van der Sluis, and A. Gatt. 2006.
Building a semantically transparent corpus for the gen-
eration of referring expressions. In Proc. of the 4th
INLG.
K. van Deemter. 2002. Generating referring expres-
sions: Boolean extensions of the incremental algo-
rithm. Computational Linguistics, 28(1):37?52.
J. Viethen and R. Dale. 2006. Algorithms for generating
referring expressions: Do they do what people do? In
Proc. of the 4th INLG.
49
Preface
Generation Challenges 2010 was the fourth round of shared-task evaluation compe-
titions (STECs) that involve the generation of natural language; it followed the Pilot
Attribute Selection for Generating Referring Expressions Challenge in 2007 (AS-
GRE?07) and Referring Expression Generation Challenges in 2008 (REG?08), and
Generation Challenges 2009 (GenChal?09). More information about all these NLG
STEC activities can be found via the links on the Generation Challenges homepage
(http://www.nltg.brighton.ac.uk/research/genchal10).
Generation Challenges 2010 brought together three sets of STECs: the three
GREC Challenges, GREC Named Entity Generation (GREC-NEG), Named Entity
Reference Detection (GREC-NER), and Named Entity Reference Regeneration
(GREC-Full), organised by Anja Belz and Eric Kow; the Challenge on Generat-
ing Instructions in Virtual Environments (GIVE) organised by Donna Byron, Jus-
tine Cassell, Robert Dale, Alexander Koller, Johanna Moore, Jon Oberlander, and
Kristina Striegnitz; and the new Question Generation (QG) tasks, organised by
Vasile Rus, Brendan Wyse, Mihai Lintean, Svetlana Stoyanchev and Paul Piwek.
In the GIVE Challenge, participating teams developed systems which gener-
ate natural-language instructions to users navigating a virtual 3D environment and
performing computer-game-like tasks. The seven participating systems were eval-
uated by measuring how quickly, accurately and efficiently users were able to per-
form tasks with a given system?s instructions, as well as on subjective measures.
Unlike the first GIVE Challenge, this year?s challenge allowed users to move and
turn freely in the virtual environment, rather than in discrete steps, making the NLG
task much harder. The evaluation report for the GIVE Challenge can be found in
this volume; the participants? reports will be made available on the GIVE website
(http://www.give-challenge.org/research) at a later stage.
The GREC Tasks used the GREC-People corpus of introductory sections from
Wikipedia articles on people. In GREC-NEG, the task was to select referring ex-
pressions for all mentions of all people in an article from given lists of alternatives
(this was the same task as at GenChal?09). The GREC-NER task combines named-
entity recognition and coreference resolution, restricted to people entities; the aim
for participating systems is to identify all those types of mentions of people that
are annotated in the GREC-People corpus. The aim for GREC-Full systems was to
improve the referential clarity and fluency of input texts. Participants were free to
do this in whichever way they chose. Participants were encouraged, though not
required, to create systems which replace referring expressions as and where nec-
essary to produce as clear and fluent a text as possible. This task could be viewed
as combining the GREC-NER and GREC-NEG tasks.
The first Question Generation challenge consisted of three tasks: Task A re-
quired questions to be generated from paragraphs of texts; Task B required systems
to generate questions from sentences, and Task C was an Open Task track in which
any QG research involving evaluation could be submitted. At the time of going to
press, the QG tasks are still running; this volume contains a preliminary report from
the organisers.
In addition to the four shared tasks, Generation Challenges 2010 offered (i) an
open submission track in which participants could submit any work involving the
data from any of the shared tasks, while opting out of the competetive element, (ii)
an evaluation track, in which proposals for new evaluation methods for the shared
task could be submitted, and (iii) a task proposal track in which proposals for new
shared tasks could be submitted. We believe that these types of open-access tracks
are important because they allow the wider research community to shape the focus
and methodologies of STECs directly.
We received three submissions in the Task Proposals track: an outline proposal
for tasks involving language generation under uncertainty (Lemon et al); a pro-
posal for a shared task on improving text written by non-native speakers (Dale and
Kilgarriff); and a proposal for a surface realisation task (White et al).
Once again, we successfully applied (with the help of support letters frommany
of last year?s participants and other HLT colleagues) for funding from the Engineer-
ing and Physical Sciences Research Council (EPSRC), the main funding body for
HLT in the UK. This support helped with all aspects of organising Generation Chal-
lenges 2010, and enabled us to create the new GREC-People corpus and to carry out
extensive human evaluations, as well as to employ a dedicated research fellow (Eric
Kow) to help with all aspects of Generation Challenges 2010.
Preparations are already underway for a fifth NLG shared-task evaluation event
next year, Generation Challenges 2011, which is likely to include a further run of
the GIVE Task, a second run of the QG Challenge, and a pilot surface realisation
task. We expect that results will be presented at ENLG?11.
Just like our previous STECs, Generation Challenges 2010 would not have been
possible without the contributions of many different people. Wewould like to thank
the students of Oxford University, KCL, UCL, Brighton and Sussex Universities
who participated in the evaluation experiments, as well as all other participants in
our online data elicitation and evaluation exercises; the INLG?10 organisers, Ielka
van der Sluis, John Kelleher and Brian MacNamee; the research support team at
Brighton University and the EPSRC for help with obtaining funding; and last but
not least, the participants in the shared tasks themselves.
July 2010 Anja Belz, Albert Gatt and Alexander Koller
Report on the Second NLG Challenge on
Generating Instructions in Virtual Environments (GIVE-2)
Alexander Koller
Saarland University
koller@mmci.uni-saarland.de
Kristina Striegnitz
Union College
striegnk@union.edu
Andrew Gargett
Saarland University
gargett@mmci.uni-saarland.de
Donna Byron
Northeastern University
dbyron@ccs.neu.edu
Justine Cassell
Northwestern University
justine@northwestern.edu
Robert Dale
Macquarie University
Robert.Dale@mq.edu.au
Johanna Moore
University of Edinburgh
J.Moore@ed.ac.uk
Jon Oberlander
University of Edinburgh
J.Oberlander@ed.ac.uk
Abstract
We describe the second installment of the
Challenge on Generating Instructions in
Virtual Environments (GIVE-2), a shared
task for the NLG community which took
place in 2009-10. We evaluated seven
NLG systems by connecting them to 1825
users over the Internet, and report the re-
sults of this evaluation in terms of objec-
tive and subjective measures.
1 Introduction
This paper reports on the methodology and results
of the Second Challenge on Generating Instruc-
tions in Virtual Environments (GIVE-2), which
we ran from August 2009 to May 2010. GIVE
is a shared task for the NLG community which
we ran for the first time in 2008-09 (Koller et al,
2010). An NLG system in this task must generate
instructions which guide a human user in solving
a treasure-hunt task in a virtual 3D world, in real
time. For the evaluation, we connect these NLG
systems to users over the Internet, which makes
it possible to collect large amounts of evaluation
data cheaply.
While the GIVE-1 challenge was a success, in
that it evaluated five NLG systems on data from
1143 game runs in the virtual environments, it
was limited in that users could only move and
turn in discrete steps in the virtual environments.
This made the NLG task easier than intended; one
of the best-performing GIVE-1 systems generated
instructions of the form ?move three steps for-
ward?. The primary change in GIVE-2 compared
to GIVE-1 is that users could now move and turn
freely, which makes expressions like ?three steps?
meaningless, and makes it hard to predict the pre-
cise effect of instructing a user to ?turn left?.
We evaluated seven NLG systems from six in-
stitutions in GIVE-2 over a period of three months
from February to May 2010. During this time,
we collected 1825 games that were played by
users from 39 countries, which is an increase of
over 50% over the data we collected in GIVE-
1. We evaluated each system both on objec-
tive measures (success rate, completion time, etc.)
and subjective measures which were collected by
asking the users to fill in a questionnaire. We
completely revised the questionnaire for the sec-
ond challenge, which now consists of relatively
fine-grained questions that can be combined into
more high-level groups for reporting. We also in-
troduced several new objective measures, includ-
ing the point in the game in which users lost
or cancelled, and an experimental ?back-to-base?
task intended to measure how much users learned
about the virtual world while interacting with the
NLG system.
Plan of the paper. The paper is structured as fol-
lows. In Section 2, we describe and motivate the
GIVE-2 Challenge. In section 3, we describe the
evaluation method and infrastructure. Section 4
reports on the evaluation results. Finally, we con-
clude and discuss future work in Section 5.
2 The GIVE Challenge
GIVE-2 is the second installment of the GIVE
Challenge (?Generating Instructions in Virtual En-
vironments?), which we ran for the first time in
2008-09. In the GIVE scenario, subjects try to
solve a treasure hunt in a virtual 3Dworld that they
have not seen before. The computer has a com-
plete symbolic representation of the virtual world.
The challenge for the NLG system is to gener-
ate, in real time, natural-language instructions that
will guide the users to the successful completion
of their task.
Users participating in the GIVE evaluation
start the 3D game from our website at www.
give-challenge.org. They then see a 3D
Figure 1: What the user sees when playing with
the GIVE Challenge.
game window as in Fig. 1, which displays instruc-
tions and allows them to move around in the world
and manipulate objects. The first room is a tuto-
rial room where users learn how to interact with
the system; they then enter one of three evaluation
worlds, where instructions for solving the treasure
hunt are generated by an NLG system. Users can
either finish a game successfully, lose it by trig-
gering an alarm, or cancel the game. This result is
stored in a database for later analysis, along with a
complete log of the game.
In each game world we used in GIVE-2, players
must pick up a trophy, which is in a wall safe be-
hind a picture. In order to access the trophy, they
must first push a button to move the picture to the
side, and then push another sequence of buttons to
open the safe. One floor tile is alarmed, and play-
ers lose the game if they step on this tile without
deactivating the alarm first. There are also a num-
ber of distractor buttons which either do nothing
when pressed or set off an alarm. These distractor
buttons are intended to make the game harder and,
more importantly, to require appropriate reference
to objects in the game world. Finally, game worlds
contained a number of objects such as chairs and
flowers that did not bear on the task, but were
available for use as landmarks in spatial descrip-
tions generated by the NLG systems.
The crucial difference between this task and
the (very similar) GIVE-1 task was that in GIVE-
2, players could move and turn freely in the vir-
tual world. This is in contrast to GIVE-1, where
players could only turn by 90 degree increments,
and jump forward and backward by discrete steps.
This feature of the way the game controls were set
up made it possible for some systems to do very
well in GIVE-1 with only minimal intelligence,
using exclusively instructions such as ?turn right?
and ?move three steps forward?. Such instructions
are unrealistic ? they could not be carried over to
instruction-giving in the real world ?, and our aim
was to make GIVE harder for systems that relied
on them.
3 Method
Following the approach from the GIVE-1 Chal-
lenge (Koller et al, 2010), we connected the NLG
systems to users over the Internet. In each game
run, one user and one NLG system were paired up,
with the system trying to guide the user to success
in a specific game world.
3.1 Software infrastructure
We adapted the GIVE-1 software to the GIVE-2
setting. The GIVE software infrastructure (Koller
et al, 2009a) consists of three different mod-
ules: The client, which is the program which the
user runs on their machine to interact with the
virtual world (see Fig. 1); a collection of NLG
servers, which generate instructions in real-time
and send them to the client; and a matchmaker,
which chooses a random NLG server and virtual
world for each incoming connection from a client
and stores the game results in a database.
The most visible change compared to GIVE-1
was to modify the client so it permitted free move-
ment in the virtual world. This change further ne-
cessitated a number of modifications to the inter-
nal representation of the world. To support the de-
velopment of virtual worlds for GIVE, we changed
the file format for world descriptions to be much
more readable, and provided an automatic tool
for displaying virtual worlds graphically (see the
screenshots in Fig. 2).
3.2 Recruiting subjects
Participants were recruited using email distribu-
tion lists and press releases posted on the Internet
and in traditional newspapers. We further adver-
tised GIVE at the Cebit computer expo as part of
the Saarland University booth. Recruiting anony-
mous experimental subjects over the Internet car-
ries known risks (Gosling et al, 2004), but we
showed in GIVE-1 that the results obtained for
the GIVE Challenge are comparable and more in-
formative than those obtained from a laboratory-
World 1 World 2 World 3
Figure 2: The three GIVE-2 evaluation worlds.
based experiment (Koller et al, 2009b).
We also tried to leverage social networks for re-
cruiting participants by implementing and adver-
tising a Facebook application. Because of a soft-
ware bug, only about 50 participants could be re-
cruited in this way. Thus tapping the true poten-
tial of social networks for recruiting participants
remains a task for the next installment of GIVE.
3.3 Evaluation worlds
Fig. 2 shows the three virtual worlds we used in the
GIVE-2 evaluation. Overall, the worlds were more
difficult than the worlds used in GIVE-1, where
some NLG-systems had success rates around 80%
in some of the worlds. As for GIVE-1, the three
worlds were designed to pose different challenges
to the NLG systems. World 1 was intended to be
more similar to the development world and last
year?s worlds. It did have rooms with more than
one button of the same color, however, these but-
tons were not located close together. World 2 con-
tained several situations which required more so-
phisticated referring expressions, such as rooms
with several buttons of the same color (some of
them close together) and a grid of buttons. Fi-
nally, World 3 was designed to exercise the sys-
tems? navigation instructions: one room contained
a ?maze? of alarm tiles, and another room two
long rows of buttons hidden in ?booths? so that
they were not all visible at the same time.
3.4 Timeline
After the GIVE-2 Challenge was publicized in
June 2009, fifteen researchers and research teams
declared their interest in participating. We dis-
tributed a first version of the software to these
teams in August 2009. In the end, six teams sub-
mitted NLG systems (two more than in GIVE-1);
one team submitted two independent NLG sys-
tems, bringing the total number of NLG systems
up to seven (two more than in GIVE-1). These
were connected to a central matchmaker that ran
for a bit under three months, from 23 February to
17 May 2010.
3.5 NLG systems
Seven NLG systems were evaluated in GIVE-2:
? one system from the Dublin Institute of Tech-
nology (?D? in the discussion below);
? one system from Trinity College Dublin
(?T?);
? one system from the Universidad Com-
plutense de Madrid (?M?);
? one system from the University of Heidelberg
(?H?);
? one system from Saarland University (?S?);
? and two systems from INRIA Grand-Est in
Nancy (?NA? and ?NM?).
Detailed descriptions of these systems as well
as each team?s own analysis of the evalua-
tion results can be found at http://www.
give-challenge.org/research.
4 Results
We now report the results of GIVE-2. We start
with some basic demographics; then we discuss
objective and subjective evaluation measures. The
data for the objective measures are extracted from
the logs of the interactions; whereas the data for
the subjective measures are obtained from a ques-
tionnaire which asked subjects to rate various as-
pects of the NLG system they interacted with.
Notice that some of our evaluation measures are
in tension with each other: For instance, a sys-
tem which gives very low-level instructions may
allow the user to complete the task more quickly
(there is less chance of user errors), but it will re-
quire more instructions than a system that aggre-
gates these. This is intentional, and emphasizes
our desire to make GIVE a friendly comparative
challenge rather than a competition with a clear
winner.
4.1 Demographics
Over the course of three months, we collected
1825 valid games. This is an increase of almost
60% over the number of valid games we collected
in GIVE-1. A game counted as valid if the game
client did not crash, the game was not marked as a
test game by the developers, and the player com-
pleted the tutorial.
Of these games, 79.0% were played by males
and 9.6% by females; a further 11.4% did not
specify their gender. These numbers are compa-
rable to GIVE-1. About 42% of users connected
from an IP address in Germany; 12% from the US,
8% from France, 6% from Great Britain, and the
rest from 35 further countries. About 91% of the
participants who answered the question self-rated
their English language proficiency as ?good? or
better. About 65% of users connected from vari-
ous versions of Windows, the rest were split about
evenly between Linux and MacOS.
4.2 Objective measures
The objective measures are summarize in Fig. 3.
In addition to calculating the percentage of games
users completed successfully when being guided
by the different systems, we measured the time
until task completion, the distance traveled until
task completion, and the number of actions (such
as pushing a button to open a door) executed. Fur-
thermore, we counted howmany instructions users
received from each system, and how many words
these instructions contained on average. All objec-
tive measures were collected completely unobtru-
sively, without requiring any action on the user?s
part. To ensure comparability, we only counted
successfully completed games.
task success: Did the player get the trophy?
duration: Time in seconds from the end of the tu-
torial until the retrieval of the trophy.
distance: Distance traveled (measured in distance
units of the virtual environment).
actions: Number of object manipulation actions.
instructions: Number of instructions produced
by the NLG system.
words per instruction: Average number of
words the NLG system used per instruction.
Figure 3: Objective measures.
Fig. 4 shows the results of these objective mea-
sures. Task success is reported as the percent-
age of successfully completed games. The other
measures are reported as the mean number of sec-
onds/distance units/actions/instructions/words per
instruction, respectively. The figure also assigns
systems to groups A, B, etc. for each evaluation
measure. For example, users interacting with sys-
tems in group A had a higher task success rate,
needed less time, etc. than users interacting with
systems in group B. If two systems do not share
the same letter, the difference between these two
systems is significant with p < 0.05. Significance
was tested using a ?2-test for task success and
ANOVAs for the other objective measures. These
were followed by post-hoc tests (pairwise ?2 and
Tukey) to compare the NLG systems pairwise.
In terms of task success, the systems fall pretty
neatly into four groups. Note that systems D and
T had very low task success rates. That means
that, for these systems, the results for the other ob-
jective measures may not be reliable because they
are based on just a handful of games. Another
aspect in which systems clearly differed is how
many words they used per instruction. Interest-
ingly, the three systems with the best task success
rates also produced the most succinct instructions.
The distinctions between systems in terms of the
other measures is less clear.
4.3 Subjective measures
The subjective measures were obtained from re-
sponses to a questionnaire that was presented to
users after each game. The questionnaire asked
users to rate different statements about the NLG
D H M NA NM S T
task
success
9% 11% 13% 47% 30% 40% 3%
A A
B
C C C
D D
duration
888 470 407 344 435 467 266
A A A A A
B B B B B
C
distance
231 164 126 162 167 150 89
A A A A A A
B B B B B
actions
25 22 17 17 18 17 14
A A A A A A A
instructions
349 209 463 224 244 244 78
A A A A A A
B B
words per
instruction
15 11 16 6 10 6 18
A A
B
C
D
E E
Figure 4: Results for the objective measures.
system using a continuous slider. The slider posi-
tion was translated to a number between -100 and
100. Figs. 7 and 6 show the statements that users
were asked to rate as well as the results. These
results are based on all games, independent of the
success. We report the mean rating for each item,
and, as before, systems that do not share a letter,
were found to be significantly different (p< 0.05).
We used ANOVAs and post-hoc Tukey tests to test
for significance. Note that some items make a pos-
itive statement about the NLG system (e.g., Q1)
and some make a negative statement (e.g., Q2).
For negative statements, we report the reversed
scores, so that in Figs. 7 and 6 greater numbers are
always better, and systems in group A are always
better than systems in group B.
In addition to the items Q1?Q22, the ques-
tionnaire contained a statement about the over-
all instruction quality: ?Overall, the system gave
me good directions.? Furthermore notice that the
other items fall into two categories: items that as-
sess the quality of the instructions (Q1?Q15) and
items that assess the emotional affect of the in-
teraction (Q16?Q22). The ratings in these cate-
D H M NA NM S T
overall
quality
question
-33 -18 -12 36 18 19 -25
A
B B
C C C C
quality
measures
(summed)
-183 -148 -18 373 239 206 -44
A A A
B B B B
emotional
affect
measures
(summed)
-130 -103 -90 20 -5 0 -88
A A A A
B B B B B
C C C C C
Figure 5: Results for item assessing overall in-
struction quality and the aggregated quality and
emotional affect measures.
gories can be aggregated into just two ratings by
summing over them. Fig. 5 shows the results for
the overall question and the aggregated ratings for
quality measures and emotional affect measures.
The three systems with the highest task success
rate get rated highest for overall instruction qual-
ity. The aggregated quality measure also singles
out the same group of three systems.
4.4 Further analysis
In addition to the differences between NLG sys-
tems, some other factors also influence the out-
comes of our objective and subjective measures.
As in GIVE-1, we find that there is a significant
difference in task success rate for different evalua-
tion worlds and between users with different levels
of English proficiency. Fig. 8 illustrates the effect
of the different evaluation worlds on the task suc-
cess rate for different systems, and Fig. 9 shows
the effect that a player?s English skills have on the
task success rate. As in GIVE-1, some systems
seem to be more robust than others with respect to
changes in these factors.
None of the other factors we looked at (gender,
age, and computer expertise) have a significant ef-
fect on the task success rate. With a few excep-
tions the other objective measures were not influ-
enced by these demographic factors either. How-
ever, we do find a significant effect of age on the
time and number of actions a player needs to re-
trieve the trophy: younger players are faster and
need fewer actions. And we find that women travel
a significantly shorter distance than men on their
way to the trophy. Interestingly, we do not find
D H M NA NM S T
Q1: The system used words and phrases
that were easy to understand.
45 26 41 62 54 58 46
A A A A
B B B B
C C C
Q2: I had to re-read instructions to under-
stand what I needed to do.
-26 -9 3 40 8 19 0
A
B B B B
C C C
D D
Q3: The system gave me useful feedback
about my progress.
-17 -30 -31 9 11 -13 -27
A A
B B B B
C C C C
Q4: I was confused about what to do next.
-35 -27 -18 29 9 5 -31
A
B B
C C C C
Q5: I was confused about which direction
to go in.
-32 -20 -16 21 8 3 -25
A A
B B
C C C C
Q6: I had no difficulty with identifying
the objects the system described for me.
-21 -11 -5 18 13 20 -21
A A A
B B
C C C C
Q7: The system gave me a lot of unnec-
essary information.
-22 -9 6 15 10 10 -6
A A A A
B B B B
C C C
D D D
D H M NA NM S T
Q8: The system gave me too much infor-
mation all at once.
-28 -8 9 31 8 21 15
A A A
B B B B
C C
Q9: The system immediately offered help
when I was in trouble.
-15 -13 -13 32 3 -5 -23
A
B B B B B
C C C C
Q10: The system sent instructions too
late.
15 15 9 38 39 14 8
A A
B B B B B
Q11: The system?s instructions were de-
livered too early.
15 5 21 39 12 30 28
A A A
B B B B
C C C C
D D D D
Q12: The system?s instructions were vis-
ible long enough for me to read them.
-67 -21 -19 6 -14 0 -18
A A
B B B
C C C C
D
Q13: The system?s instructions were
clearly worded.
-20 -9 1 32 23 26 6
A A A
B B B
C C C
D D
Q14: The system?s instructions sounded
robotic.
16 -6 8 -4 -1 5 1
A A A A A A
B B B B B B
Q15: The system?s instructions were
repetitive.
-28 -26 -11 -31 -28 -26 -23
A A A A A
B B B B B B
Figure 7: Results for the subjective measures assessing the quality of the instructions.
D H M NA NM S T
Q16: I really wanted to find that trophy.
-10 -13 -9 -11 -8 -7 -12
A A A A A A A
Q17: I lost track of time while solving the
overall task.
-13 -18 -21 -16 -18 -11 -20
A A A A A A A
Q18: I enjoyed solving the overall task.
-21 -23 -20 -8 -4 -5 -21
A A A A A A
B B B B B
Q19: Interacting with the system was re-
ally annoying.
-14 -20 -12 8 -2 -2 -14
A A A
B B B B B
C C C C
Q20: I would recommend this game to a
friend.
-36 -39 -31 -30 -25 -24 -31
A A A A A A A
Q21: The system was very friendly.
0 -1 5 30 20 19 5
A A A
B B B B
C C C C
D D D D
Q22: I felt I could trust the system?s in-
structions.
-21 -6 -3 37 23 21 -13
A A A
B B B B
Figure 6: Results for the subjective measures as-
sessing the emotional affect of the instructions.
Figure 8: Effect of the evaluation worlds on the
success rate of the NLG systems.
Figure 9: Effect of the players? English skills on
the success rate of the NLG systems.
a significant effect of gender on the time players
need to retrieve the trophy as in GIVE-1 (although
the mean duration is somewhat higher for female
than for male players; 481 vs. 438 seconds).
5 Conclusion
In this paper, we have described the setup and re-
sults of the Second GIVE Challenge. Altogether,
we collected 1825 valid games for seven NLG sys-
tems over a period of three months. Given that this
is a 50% increase over GIVE-1, we feel that this
further justifies our basic experimental methodol-
ogy. As we are writing this, we are preparing de-
tailed results and analyses for each participating
team, which we hope will help them understand
and improve the performance of their systems.
The success rate is substantially worse in GIVE-
2 than in GIVE-1. This is probably due to the
Figure 10: Points at which players lose/cancel.
harder task (free movement) explained in Sec-
tion 2 and to the more complex evaluation worlds
(see Section 3.3). It was our intention to make
GIVE-2 more difficult, although we did not antic-
ipate such a dramatic drop in performance. GIVE-
2.5 next year will use the same task as GIVE-2 and
we hope to see an increase in task success as the
participating research teams learn from this year?s
results.
It is also noticeable that players gave mostly
negative ratings in response to statements about
immersion and engagement (Q16-Q20). We dis-
cussed last year how to make the task more engag-
ing on the one hand and how to manage expecta-
tions on the other hand, but none of the suggested
solutions ended up being implemented. It seems
that we need to revisit this issue.
Another indication that the task may not be able
to capture participants is that the vast majority of
cancelled and lost games end in the very begin-
ning. To analyze at what point players lose or give
up, we divide the game into phases demarcated
by manipulations of buttons that belong to the 6-
button safe sequence. Fig. 10 illustrates in which
phase of the game players lose or cancel.
We are currently preparing the GIVE-2.5 Chal-
lenge, which will take place in 2010-11. GIVE-2.5
will be very similar to GIVE-2, so that GIVE-2
systems will be able to participate with only mi-
nor changes. In order to support the development
of GIVE-2.5 systems, we have collected a multi-
lingual corpus of written English and German in-
structions in the GIVE-2 environment (Gargett et
al., 2010). We expect that GIVE-3 will then extend
the GIVE task substantially, perhaps in the direc-
tion of full dialogue or of multimodal interaction.
Acknowledgments. GIVE-2 was only possible
through the support and hard work of a number of
colleagues, especially Konstantina Garoufi (who
handled the website and other publicity-related is-
sues), Ielka van der Sluis (who contributed to the
design of the GIVE-2 questionnaire), and several
student assistants who programmed parts of the
GIVE-2 system. We thank the press offices of
Saarland University, the University of Edinburgh,
and Macquarie University for their helpful press
releases. We also thank the organizers of Gener-
ation Challenges 2010 and INLG 2010 for their
support and the opportunity to present our results,
and the seven participating research teams for their
contributions.
References
Andrew Gargett, Konstantina Garoufi, Alexander
Koller, and Kristina Striegnitz. 2010. The GIVE-
2 corpus of giving instructions in virtual environ-
ments. In Proceedings of the 7th International
Conference on Language Resources and Evaluation
(LREC), Malta.
S. D. Gosling, S. Vazire, S. Srivastava, and O. P. John.
2004. Should we trust Web-based studies? A com-
parative analysis of six preconceptions about Inter-
net questionnaires. American Psychologist, 59:93?
104.
A. Koller, D. Byron, J. Cassell, R. Dale, J. Moore,
J. Oberlander, and K. Striegnitz. 2009a. The soft-
ware architecture for the first challenge on generat-
ing instructions in virtual environments. In Proceed-
ings of the EACL-09 Demo Session.
Alexander Koller, Kristina Striegnitz, Donna Byron,
Justine Cassell, Robert Dale, Sara Dalzel-Job, Jo-
hanna Moore, and Jon Oberlander. 2009b. Validat-
ing the web-based evaluation of NLG systems. In
Proceedings of ACL-IJCNLP 2009 (Short Papers),
Singapore.
Alexander Koller, Kristina Striegnitz, Donna Byron,
Justine Cassell, Robert Dale, Johanna Moore, and
Jon Oberlander. 2010. The first challenge on
generating instructions in virtual environments. In
E. Krahmer and M. Theune, editors, Empirical
Methods in Natural Language Generation, volume
5790 of LNCS, pages 337?361. Springer.
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 30?39,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Enhancing Referential Success by Tracking Hearer Gaze
Alexander Koller
University of Potsdam
koller@ling.uni-potsdam.de
Konstantina Garoufi
University of Potsdam
garoufi@uni-potsdam.de
Maria Staudte
Saarland University
masta@coli.uni-saarland.de
Matthew Crocker
Saarland University
crocker@coli.uni-saarland.de
Abstract
The ability to monitor the communicative suc-
cess of its utterances and, if necessary, provide
feedback and repair is useful for a dialog sys-
tem. We show that in situated communication,
eyetracking can be used to reliably and effi-
ciently monitor the hearer?s reference resolu-
tion process. An interactive system that draws
on hearer gaze to provide positive or nega-
tive feedback after referring to objects outper-
forms baseline systems on metrics of referen-
tial success and user confusion.
1 Introduction
Because dialog is interactive, interlocutors are con-
stantly engaged in a process of predicting and mon-
itoring the effects of their utterances. Typically, a
speaker produces an utterance with a specific com-
municative goal in mind?e.g., that the hearer will
perform an action or adopt a certain belief?, and
chooses one particular utterance because they pre-
dict that it will achieve this communicative goal.
They will then monitor the hearer?s reactions and
infer from their observations whether the prediction
actually came true. If they recognize that the hearer
misunderstood the utterance, they may repair the
problem by diagnosing what caused the misunder-
standing and giving the hearer feedback. In a task-
oriented dialog in which the hearer must perform a
part of the task, feedback is especially important to
inform the hearer when they made a mistake in the
task. Ideally, the speaker should even detect when
the hearer is about to make a mistake, and use feed-
back to keep them from making the mistake at all.
Many implemented dialog systems include a com-
ponent for monitoring and repair. For instance,
Traum (1994) presents a model for monitoring the
grounding status of utterances in the TRAINS sys-
tem; Young et al (1994) show how the student?s
utterances in a dialog system can be used to un-
cover mistaken assumptions about their mental state;
and Paek and Horvitz (1999) discuss an automated
helpdesk system that can track grounding under un-
certainty. However, most of these systems rely on
the user?s verbal utterances as their primary source
of information; monitoring thus presupposes an
(error-prone) language understanding module.
In the context of situated communication, where
the speaker and hearer share a physical (or virtual)
environment, one type of observation that can poten-
tially give us a very direct handle on the hearer?s un-
derstanding of an utterance is eye gaze. Eyetracking
studies in psycholinguistics have shown that when
listeners hear a referring expression, they tend to
rapidly attend to the object in a scene to which they
resolve this expression (Tanenhaus et al, 1995; Al-
lopenna et al, 1998). For utterances that involve ref-
erences to objects in the current environment, one
can therefore ask whether eyetracking can be used
to reliably judge the communicative success of the
utterance. This would be of practical interest for
implemented dialog systems once eyetracking be-
comes a mainstream technology; and even today, a
system that reliably monitors communicative suc-
cess using eyetracking could serve as a testbed for
exploring monitoring and repair strategies.
In this paper, we present an interactive natural-
language generation (NLG) system that uses eye-
30
tracking to monitor communicative success. Our
system gives real-time instructions that are designed
to help the user perform a treasure-hunt task in the
virtual 3D environments of the recent Challenges
on Generating Instructions in Virtual Environments
(GIVE; Koller et al (2010)). It monitors how the
user resolves referring expressions (REs) by map-
ping the user?s gaze to objects in the virtual environ-
ment. The system takes gaze to the intended referent
as evidence of successful understanding, and gives
the user positive feedback; by contrast, gaze to other
objects triggers negative feedback. Crucially, this
feedback comes before the user interacts with the
object in the virtual environment, keeping the user
from making mistakes before they happen.
We evaluate our system against one baseline that
gives no feedback, and another that bases its feed-
back on monitoring the user?s movements and their
field of view. We find that the eyetracking-based
system outperforms both on referential success, and
that users interacting with it show significantly fewer
signs of confusion about how to complete their task.
This demonstrates that eyetracking can serve as a
reliable source of evidence in monitoring commu-
nicative success. The system is, to our knowledge,
the first dialog or NLG system that uses the hearer?s
gaze to monitor understanding of REs.
Plan of the paper. The paper is structured as fol-
lows. We first discuss related work in Section 2. We
then describe our approach as well as the baselines
in Section 3, set up the evaluation in Section 4 and
present the results in Section 5. In Sections 6 and 7
we discuss our findings and conclude.
2 Related work
Dialog systems model a process of grounding, in
which they decide to what extent the user has under-
stood the utterance and the communicative goal has
been reached. Observing the user behavior to moni-
tor the state of understanding is a key component in
this process. A full solution may require plan recog-
nition or abductive or epistemic reasoning (see e.g.
Young et al (1994), Hirst et al (1994)); in practice,
many systems use more streamlined (Traum, 1994)
or statistical methods (Paek and Horvitz, 1999).
Most dialog systems focus on the verbal interaction
of the system and user, and the user?s utterances are
therefore the primary source of evidence in the mon-
itoring process. Some incremental dialog systems
can monitor the user?s verbal reactions to the sys-
tem?s utterances in real time, and continuously up-
date the grounding state while the system utterance
is still in progress (Skantze and Schlangen, 2009;
Buss and Schlangen, 2010).
In this paper, we focus on the generation side of a
dialog system?the user is the hearer?and on mon-
itoring the user?s extralinguistic reactions, in par-
ticular their gaze. Tanenhaus et al (1995) and Al-
lopenna et al (1998) showed that subjects in psy-
cholinguistic experiments who hear an RE visually
attend to the object to which they resolve the RE.
The ?visual world? experimental paradigm exploits
this by presenting objects on a computer screen and
using an eyetracker to monitor the subject?s gaze.
This research uses gaze only as an experimental tool
and not as part of an interactive dialog system, and
the visual worlds are usually limited to static 2D
scenes. Also, such setups cannot account for the re-
ciprocal nature of dialog and the consequences that
hearer gaze has for the speaker?s monitoring process.
In the context of situated dialog systems, previ-
ous studies have employed robots and virtual agents
as speakers to explore how and when speaker gaze
helps human hearers to ground referring expressions
(Foster, 2007). For instance, Staudte and Crocker
(2011) show that an agent can make it easier for the
(human) hearer to resolve a system-generated RE by
looking at the intended referent, using head and eye
movements. Conversely, the performance of a sys-
tem for resolving human-produced REs can be im-
proved by taking the (human) speaker?s gaze into ac-
count (Iida et al, 2011). Gaze has also been used to
track the general dynamics of a dialog, such as turn
taking (Jokinen et al, in press).
Here we are interested in monitoring the hearer?s
gaze in order to determine whether they have under-
stood an RE. To our knowledge, there has been no
research on this; in particular, not in dynamic 3D
environments. The closest earlier work of which we
are aware comes from the context of the GIVE Chal-
lenge, a shared task for interactive, situated natural
language generation systems. These systems typi-
cally approximate hearer gaze as visibility of objects
on the screen and monitor grounding based on this
(Denis, 2010; Racca et al, 2011).
31
Figure 1: A first-person view of a virtual 3D environment.
3 Interactive natural-language generation
in virtual environments
In this paper, we consider the communicative situ-
ation of the GIVE Challenge (Koller et al, 2010;
Striegnitz et al, 2011). In this task, a human user can
move about freely in a virtual indoor environment
featuring several interconnected rooms and corri-
dors. A 3D view of the environment is displayed on
a computer screen as in Fig. 1, and the user can walk
forward/backward and turn left/right, using the cur-
sor keys. They can also press buttons attached to the
walls, by clicking on them with the mouse once they
are close enough. The small and big white circles in
Fig. 1, which represent eyetracking information, are
not actually visible to the user.
The user interacts with a real-time NLG system in
the context of a treasure-hunt game, where their task
is to find a trophy hidden in a wall safe. They must
press certain buttons in the correct sequence in or-
der to open the safe; however, they do not have prior
knowledge of which buttons to press, so they rely
on instructions and REs generated by the system. A
room may contain several buttons other than the tar-
get, which is the button that the user must press next.
These other buttons are called distractors. Next to
buttons, rooms also contain a number of landmark
objects, such as chairs and plants, which cannot di-
rectly be interacted with, but may be used in REs
to nearby targets. Fig. 2 shows a top-down map of
the virtual environment in which the scene of Fig. 1
arose. We call an entire game up to the successful
discovery of the trophy, an interaction of the system
and the user.
Figure 2: A map of the environment in Fig. 1; note the
user in the upper right room.
3.1 Monitoring communicative success
NLG systems in the GIVE setting are in an interac-
tive communicative situation. This situation repre-
sents one complete half of a dialog situation: Only
the system gets to use language, but the user moves
and acts in response to the system?s utterances. As a
result, the system should continuously monitor and
react to what the user does, in real time. This is
most tangible in the system?s use of REs. When a
user misinterprets (or simply does not understand)
a system-generated RE, there is a high chance that
they will end up pressing the wrong button. This
will hinder the completion of the task. A system
that predicts how the user resolves the RE by mon-
itoring their movements and actions, and that can
proactively give the user feedback to keep them from
making a mistake, will therefore perform better than
one which cannot do this. Furthermore, if the sys-
tem can give positive feedback when it detects that
the user is about to do the right thing, this may in-
crease the user?s confidence.
Monitoring communicative success in GIVE in-
teractions and providing the right feedback can be
challenging. For example, in the original interaction
from which we took the screenshot of Fig. 1, the sys-
tem instructed the user to ?push the right button to
the right of the green button?, referring to the right-
most blue button in the scene. In response, the user
first walked hesitantly towards the far pair of buttons
(green and blue), and then turned to face the other
pair, as seen in Fig. 3. A typical NLG system used
32
Figure 3: The scene of Fig. 1, after the user moved and
turned in response to a referring expression.
in the GIVE Challenge (e.g., Dionne et al (2009),
Denis (2010), Racca et al (2011)) may try to predict
how the user might resolve the RE based on the vis-
ibility of objects, timing data, or distances. Relying
only on such data, however, even a human observer
could have difficulties in interpreting the user?s reac-
tion; the user in Fig. 3 ended up closer to the green
and blue buttons, but the other buttons (the two blue
ones) are, to similar degrees, visually in focus.
The contribution of this paper is to present a
method for monitoring the communicative success
of an RE based on eyetracking. We start from the
hypothesis that when the user resolves an RE to a
certain object, they will tend to gaze at this object.
In the scene of Fig. 3, the user was indeed looking
at the system?s intended referent, which they later
pressed; the small white circles indicate a trace of re-
cent fixations on the screen, and the big white circle
marks the object in the virtual environment to which
the system resolved these screen positions. Our sys-
tem takes this gaze information, which is available in
real time, as evidence for how the user has resolved
its RE, and generates positive or negative feedback
based on this.
3.2 NLG systems
To demonstrate the usefulness of the eyetracking-
based approach, we implemented and compared
three different NLG systems. All of these use
an identical module for generating navigation in-
structions, which guides the user to a specific lo-
cation, as well as object manipulation instructions
such as ?push the blue button?; ?the blue button?
is an RE that describes an object to the user. The
systems generate REs that are optimized for being
easy for the hearer to understand, according to a
corpus-based model of understandability (Garoufi
and Koller, 2011). The model was trained on human
instructions produced in a subset of the virtual envi-
ronments we use in this work. The resulting system
computes referring expressions that are correct and
uniquely describe the referent as seen by the hearer
at the moment in which generation starts.
Unlike in the original GIVE Challenge, the gen-
erated instructions are converted to speech by the
Mary text-to-speech system (Schro?der and Trouvain,
2003) and presented via loudspeaker. At any point,
the user may press the ?H? key on their keyboard to
indicate that they are confused and request a clari-
fication. This will cause the system to generate an
instruction newly; if it contains an RE, this RE may
or may not be the same as the one used in the origi-
nal utterance.
The difference between the three systems is in the
way they monitor communicative success and deter-
mine when to give feedback to the user.
The no-feedback system. As a baseline system,
we used a system which does not monitor success
at all, and therefore never gives feedback on its own
initiative. Notice that the system still re-generates an
RE when the user presses the ?H? key.
Movement-based monitoring. As a second base-
line, we implemented a system that attempts to mon-
itor whether a user understood an RE based on their
movements. This system is intended to represent
the user monitoring that can be implemented, with
a reasonable amount of effort, on the basis of imme-
diately available information in the GIVE setting.
The movement-based system gives no feedback
until only a single button in the current room is vis-
ible to the user, since it can be hard to make a re-
liable prediction if the user sees several buttons on
their screen. Then it tracks the user?s distance from
this button, where ?distance? is a weighted sum of
walking distance to the button and the angle the user
must turn to face the button. If, after hearing the RE,
the user has decreased the distance by more than a
given threshold, the system concludes that the hearer
has resolved the RE as this button. If that is the but-
ton the system intended to refer to, the system utters
33
the positive feedback ?yes, that one?. For incorrect
buttons, it utters the negative feedback ?no, not that
one?. Although the negative feedback is relatively
vague, it has the advantage of limiting the variability
of the system?s outputs, which facilitates evaluation.
Eyetracking-based monitoring. Finally, the
eyetracking-based system attempts to predict
whether the user will press the correct button
or not by monitoring their gaze. At intervals of
approximately 15 ms, the system determines the
(x,y) position on the screen that the user is looking
at. It then identifies the object in the environment
that corresponds to this position by casting a ray
from the (virtual) camera through the screen plane,
and picking the closest object lying within a small
range of this ray (Fig. 1; see Staudte et al (2012) for
details). If the user continously looks at the same
object for more than a certain amount of time, the
system counts this as an inspection of the object; for
our experiments, we chose a threshold of 300 ms.
Once the system detects an inspection to a button in
the room, it generates positive or negative feedback
utterances in exactly the same way as the movement
system does.
Both the movement-based and the eyetracking-
based model withhold their feedback until a first
full description of the referent (a first-mention RE)
has been spoken. Additionally, they only provide
feedback once for every newly approached or in-
spected button and will not repeat this feedback un-
less the user has approached or inspected another
button in the meantime. Example interactions of a
user with each of the three systems are presented in
Appendix A.
4 Evaluation
We set up a human evaluation study in order to as-
sess the performance of the eyetracking system as
compared against the two baselines on the situated
instruction giving task. For this, we record partic-
ipant interactions with the three systems employed
in three different virtual environments. These en-
vironments were taken from Gargett et al (2010);
they vary as to the visual and spatial properties of
the objects they contain. One of these environments
is shown in Fig. 2. Overall, 31 participants (12 fe-
males) were tested. All reported their English skills
as fluent, and all were capable of completing the
tasks. Their mean age was 27.6 years.
4.1 Task and procedure
A faceLAB eyetracking system (http://www.
seeingmachines.com/product/facelab)
remotely monitored participants? eye movements on
a 24-inch monitor, as in Fig. 4 and 5 of Appendix B.
Before the experiment, participants received written
instructions that described the task and explained
that they would be given instructions by an NLG
system. They were encouraged to request additional
help any time they felt that the instructions were not
sufficient (by pressing the ?H? key).
The eyetracker was calibrated using a nine-point
fixation stimulus. We disguised the importance of
gaze from the participants by telling them that we
videotaped them and that the camera needed calibra-
tion. Each participant started with a short practice
session to familiarize themselves with the interface
and to clarify remaining questions. We then col-
lected three complete interactions, each with a dif-
ferent virtual environment and NLG system (alter-
nated according to a Latin square design). Finally,
each participant received a questionnaire which was
aimed to reveal whether they noticed that they were
eyetracked and that one of the generation systems
made use of that, and how satisfied they were with
this interaction. The entire experiment lasted ap-
proximately 30 minutes.
4.2 Analysis
For the assessment of communicative success in
these interactions, we considered as referential
scenes the parts of the interaction between the onset
of a first-mention RE to a given referent and the par-
ticipant?s reaction (pressing a button or navigating
away to another room). To control for external fac-
tors that could have an impact on this, we discarded
individual scenes in which the systems rephrased
their first-mention REs (e.g. by adding further at-
tributes), as well as a few scenes which the partic-
ipants had to go through a second time due to tech-
nical glitches. To remove errors in eyetracker cali-
bration, we included interactions with the eyetrack-
ing NLG system in the analysis only when we were
able to record inspections (to the referent or any dis-
tractor) in at least 80% of all referential scenes. This
34
success success w/out confusion #scenes
system all easy hard all easy hard all easy hard
eyetracking 93.4 100.0 90.4 91.9 100.0 88.2 198 62 136
with feedback 94.3 100.0 91.7 92.8 100.0 89.4 194 62 132
without feedback 50.0 - 50.0 50.0 - 50.0 4 0 4
no-feedback 86.6* 100.0? 80.6* 83.5** 98.9? 76.5** 284 88 196
movement 89.8? 100.0? 85.2? 87.5? 97.8? 82.8? 295 92 203
with feedback 93.9 100.0 90.6 91.9 97.7 88.7 247 88 159
without feedback 68.8 100.0 65.9 64.6 100.0 61.4 48 4 44
Table 1: Mean referential success rate (%) and number of scenes for the systems, broken down by scene complexity
and presence of feedback. Differences of overall system performances to the eyetracking system are: significant at
** p < 0.01, * p < 0.05; ? not significant.
filtered out 9 interactions out of the 93 we collected.
Inferential statistics on this data were carried out
using mixed-effect models from the lme4 package
in R (Baayen et al, 2008). Specifically, we used
logistic regression for modeling binary data, Poisson
regression for count variables and linear regression
for continuous data.
5 Results
On evaluating the post-task questionnaires, we did
not find any significant preferences for a particular
NLG system. Roughly the same number of them
chose each of the systems on questions such as
?which system did you prefer??. When asked for
differences between the systems in free-form ques-
tions, no participant mentioned the system?s reaction
to their eye gaze?though some noticed the (lack of)
feedback. We take this to mean that the participants
did not realize they were being eyetracked.
Below, we report results on objective metrics that
do not depend on participants? judgments.
5.1 Confusion
A key goal of any RE generation system is that
the user understands the REs easily. One measure
of the ease of understanding is the frequency with
which participants pressed the ?H? key to indicate
their confusion and ask for help. The overall average
of ?H? keystrokes per interaction was 1.14 for the
eyetracking-based system, 1.77 for the movement-
based system, and 2.26 for the no-feedback system.
A model fitted to the keystroke distribution per sys-
tem shows significant differences both between the
eyetracking and the no-feedback system (Coeff. =
0.703, SE = 0.233, Wald?s Z = 3.012, p < .01) and
between the eyetracking and the movement-based
system (Coeff. = 0.475, SE = 0.241, Wald?s Z =
1.967, p < .05). In other words, the feedback
given by the eyetracking-based system significantly
reduces user confusion.
5.2 Referential success
An even more direct way to measure the interac-
tion quality is the ratio of generated REs that the
participants were able to resolve correctly. In our
evaluation, we looked at two different definitions
of success. First, an RE can count as success-
ful if the first button that the user pressed after
hearing the RE was the system?s intended referent.
The results of this evaluation are shown in the left-
most part of Table 1, under ?success?. A logis-
tic mixed-effects model fitted to the referential suc-
cess data revealed a marginal main effect of sys-
tem (?2(2) = 5.55, p = .062). Pairwise com-
parisons further show that the eyetracking system
performs significantly better than the no-feedback
system (Coeff. = ?0.765, SE = 0.342, Wald?s Z =
?2.24, p < .05); no significant difference was found
between the eyetracking-based and the movement-
based system.
Second, we can additionally require that an RE
only counts as successful if the user did not press
the ?H? key between hearing the first-mention RE
and pressing the correct button. This is a stricter
version of referential success, which requires that
the system recognized cases of potential confusion
35
and did not force the user to take the initiative in
case of difficulties. It is in line with Dethlefs et al?s
(2010) findings that metrics that penalize difficul-
ties the user encountered before successfully com-
pleting the task are better predictors of user satisfac-
tion than ones that only consider the eventual task
completion. Our results on this metric are shown
in the middle part of Table 1, under ?success with-
out confusion?. We observe again a main effect of
system (?2(2) = 7.78, p < .05); furthermore, the
eyetracking system elicited again more correct but-
tons than the no-feedback system (Coeff. = ?0.813,
SE = 0.306, Wald?s Z = ?2.66, p < 0.01).
To obtain a more detailed view of when and to
what extent the systems? behavior differed, we dis-
tinguished scenes according to their complexity. A
scene was classified as easy if a) there were no dis-
tractors in it, or b) all distractors had different colors
from the target, while the system included the color
attribute in its RE. All other scenes were considered
hard. Note that ?easy? and ?hard? are properties of
the scene and not of the system, because every sys-
tem generated the same REs in each scene.
In the experiments, we found essentially no differ-
ence between the success rates of different systems
on easy scenes (see the ?easy? columns of Table 1):
All systems were almost always successful. The
differences came almost exclusively from the hard
scenes, where the eyetracking system performed sig-
nificantly better than the no-feedback system (suc-
cess: Coeff. = ?0.793, SE = 0.348, Wald?s Z =
?2.28, p < 0.05; success without confusion: Coeff.
= ?0.833, SE = 0.315, Wald?s Z = ?2.64, p < 0.01)
and, at least numerically, also much better than the
movement system.
There was a particularly interesting difference in
the feedback behavior of the eyetracking and move-
ment systems on hard scenes (see the rightmost part
of Table 1, labeled ?#scenes?). In easy scenes,
both systems almost always gave feedback (62/62
= 100.0%; 88/92 = 95.6%); but for hard scenes,
the ratio of scenes in which the movement system
gave feedback at all dropped to 159/203 = 78.3%,
whereas the ratio for the eyetracking system re-
mained high. This may have contributed to the over-
all performance difference between the two systems.
#actions distance duration idle
system (norm.) (norm.) (norm.) (sec)
eyetracking 1.06 1.22 1.49 256.6
no-feedback 1.22* 1.27 1.59 272.5
movement 1.16 1.26 1.56 274.4
Table 2: Mean values of additional metrics. Differences
to the eyetracking system are significant at * p < 0.05.
5.3 Further performance metrics
Finally, we measured a number of other objective
metrics, including the number of actions (i.e., but-
ton presses), the distance the user traveled, the to-
tal duration of the interaction, and the mean time
a participant spent idle. Even though these mea-
sures only partly provide statistically significant re-
sults, they help to draw a clearer picture of how the
eyetracking-based feedback affects performance.
Because the three virtual environments were of
different complexity, we normalized the number of
actions, distance, and duration by dividing the value
for a given interaction by the minimum value for all
interactions of the same virtual environment. The re-
sulting measures are shown in Table 2. Participants
performed significantly fewer actions in the eye-
tracking system than in the no-feedback system (Co-
eff. = 0.174, SE = 0.067, t = 2.57, p(mcmc) < .05);
there were also trends that users of the eyetracking-
based system traveled the shortest distance, needed
the least overall time, and spent the least time idle.
The only measure deviating from this trend is
movement speed, i.e., the speed at which users re-
acted to the systems? instructions to press certain
buttons. For all successful scenes (without confu-
sion), we computed the speed by dividing the GIVE
distance (including turning distance) between the
target referent and the user?s location at the time of
the instruction containing the first-mention RE by
the time (in seconds) between hearing the instruc-
tion and pressing the target. The mean movement
speed is 0.518 for the no-feedback system, 0.493 for
the movement system, and 0.472 for the eyetracking
system. A marginal main effect of movement speed
confirms this trend (?2(2) = 5.58, p = .061) and
shows that participants moved more slowly when
getting eyetracking-based feedback than when get-
ting no feedback at all (Coeff. = 0.0352, SE =
36
0.0166, t = ?4.97, p(mcmc) < .05).
6 Discussion
The results in Section 5 demonstrate the usefulness
of eyetracking as a foundation for monitoring and
feedback. Compared to the no-feedback system, the
eyetracking-based system achieved a significantly
lower confusion rate and a significantly higher RE
success rate, especially on hard instances. The dif-
ference increases further if we discount scenes in
which the user had to ask for help, thus forcing the
system to give feedback anyway. In other words,
eyetracking provides reliable and direct access to the
hearer?s reference resolution process. Real-time di-
alog systems can use gaze information to monitor
the success of REs and generate feedback before the
user actually makes a mistake.
Monitoring and feedback could also be achieved
without using eyetracking. To explore this alterna-
tive, we compared eyetracking against a movement-
based system. We found that the former outper-
formed the latter on hearer confusion and (at least
numerically) on referential success, while not per-
forming worse on other measures. This means that
the improvement comes not merely from the fact
that feedback was given; it is also important when
and where feedback is given. The crucial weakness
of the movement-based system is that it gave feed-
back for hard instances much more rarely than the
eyetracking system. Increasing recall by lowering
the system?s confidence threshold would introduce
fresh errors. Further improvements must therefore
come at the cost of a more complex monitoring sys-
tem, both conceptually and in terms of implementa-
tion effort. From this perspective, eyetracking offers
good performance at low implementation cost.
One result that seems to go against the trend is that
users of the eyetracking system moved significantly
more slowly on their way to a target. We see two
possible explanations for this. First, it may be that
users needed some time to listen to the feedback, or
were encouraged by it to look at more objects. A
second explanation is that this is not really a differ-
ence in the quality of the systems? behavior, but a
difference in the populations over which the mean
speed was computed: The speed was only averaged
over scenes in which the users resolved the RE cor-
rectly, and the eyetracking system achieved commu-
nicative success in many cases in which the others
did not?presumably complex scenes in which the
user had to work harder to find the correct button.
This issue bears more careful analysis.
Finally, the eyetracking-based system could be
improved further in many ways. On the one hand,
it suffers from the fact that all objects in the 3D en-
vironment shift on the screen when the user turns
or moves. The user?s eyes will typically follow the
object they are currently inspecting, but lag behind
until the screen comes to a stop again. One topic
for future work would be to remove noise of this
kind from the eyetracker signal. On the other hand,
the negative feedback our system gave (?no, not that
one?) was quite unspecific. More specific feedback
(?no, the BLUE button?) might further improve the
system?s performance.
7 Conclusion
We described an interactive NLG system that uses
eyetracking to monitor the communicative success
of the REs it generates. The communication is sit-
uated in a virtual 3D environment in which the user
can move freely, and our system automatically maps
eyetracking screen coordinates to objects in the en-
vironment. A task-based evaluation found that the
eyetracking-based system outperforms both a no-
feedback system and a system whose feedback is
based on the user?s movements in the virtual envi-
ronment, along with their field of view.
Eyetracking is currently widely available in re-
search institutions, which should make our system
easy to reimplement in other situated domains. We
anticipate that eyetracking may become mainstream
technology in the not-too-distant future. But even
in a purely research context, we believe that the di-
rectness with which eyetracking allows us to observe
the hearer?s interpretation process may be useful as
a testbed for efficient theories of grounding.
Acknowledgments. This research was partly sup-
ported by the Cluster of Excellence ?Multimodal
Computing and Interaction? at Saarland University.
We are grateful to Irena Dotcheva for help with
data collection as well as to Alexandre Denis and
Christoph Clodo for software support, and to Kristi-
ina Jokinen for helpful comments.
37
Figure 4: A screenshot from the faceLAB software, including visualization of eye-gaze position in 3D space.
References
Paul Allopenna, James Magnuson, and Michael Tanen-
haus. 1998. Tracking the Time Course of Spoken
Word Recognition Using Eye Movements: Evidence
for Continuous Mapping Models. Journal of Memory
and Language, 38:419?439.
R.H. Baayen, D.J. Davidson, and D.M. Bates. 2008.
Mixed-effects modeling with crossed random effects
for subjects and items. Journal of Memory and Lan-
guage, 59:390?412.
Okko Buss and David Schlangen. 2010. Modelling
sub-utterance phenomena in spoken dialogue systems.
In Aspects of Semantics and Pragmatics of Dialogue.
SemDial 2010, 14th Workshop on the Semantics and
Pragmatics of Dialogue, pages 33?41.
Alexandre Denis. 2010. Generating referring expres-
sions with reference domain theory. In Proceedings
of the 6th International Natural Language Generation
Conference.
Nina Dethlefs, Heriberto Cuayahuitl, Kai-Florian
Richter, Elena Andonova, and John Bateman. 2010.
Evaluating task success in a dialogue system for
indoor navigation. In Aspects of Semantics and Prag-
matics of Dialogue. SemDial 2010, 14th Workshop
on the Semantics and Pragmatics of Dialogue, pages
143?146.
Daniel Dionne, Salvador de la Puente, Carlos Leo?n,
Pablo Gerva?s, and Raquel Herva?s. 2009. A model
for human readable instruction generation using level-
based discourse planning and dynamic inference of at-
tributes. In Proceedings of the 12th European Work-
shop on Natural Language Generation.
Mary Ellen Foster. 2007. Enhancing human-computer
interaction with embodied conversational agents. In
Proceedings of HCI International 2007.
Andrew Gargett, Konstantina Garoufi, Alexander Koller,
and Kristina Striegnitz. 2010. The GIVE-2 Corpus of
Giving Instructions in Virtual Environments. In Pro-
ceedings of the 7th Conference on International Lan-
guage Resources and Evaluation.
Konstantina Garoufi and Alexander Koller. 2011. The
Potsdam NLG systems at the GIVE-2.5 Challenge. In
Proceedings of the Generation Challenges Session at
the 13th European Workshop on Natural Language
Generation.
Graeme Hirst, Susan McRoy, Peter Heeman, Philip Ed-
monds, and Diane Horton. 1994. Repairing conver-
sational misunderstandings and non-understandings.
Speech Communications, 15:213?229.
Ryu Iida, Masaaki Yasuhara, and Takenobu Tokunaga.
2011. Multi-modal reference resolution in situated
dialogue by integrating linguistic and extra-linguistic
clues. In Proceedings of 5th International Joint Con-
ference on Natural Language Processing.
K. Jokinen, H. Furukawa, M. Nishida, and S. Yamamoto.
in press. Gaze and turn-taking behaviour in casual
conversational interactions. ACM Trans. Interactive
Intelligent Systems. Special Issue on Eye Gaze in In-
telligent Human-Machine Interaction.
Alexander Koller, Kristina Striegnitz, Donna Byron, Jus-
tine Cassell, Robert Dale, Johanna Moore, and Jon
38
Oberlander. 2010. The First Challenge on Generating
Instructions in Virtual Environments. In Emiel Krah-
mer and Mariet Theune, editors, Empirical Methods in
Natural Language Generation, number 5790 in LNCS,
pages 337?361. Springer.
Tim Paek and Eric Horvitz. 1999. Uncertainty, utility,
and misunderstanding: A decision-theoretic perspec-
tive on grounding in conversational systems. In AAAI
Fall Symposium on Psychological Models of Commu-
nication in Collaborative Systems.
David Nicola?s Racca, Luciana Benotti, and Pablo
Duboue. 2011. The GIVE-2.5 C Generation System.
In Proceedings of the Generation Challenges Session
at the 13th European Workshop on Natural Language
Generation.
Marc Schro?der and J. Trouvain. 2003. The German
Text-to-Speech Synthesis System MARY: A Tool for
Research, Development and Teaching. International
Journal of Speech Technology, 6:365?377.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics.
Maria Staudte and Matthew W. Crocker. 2011. Inves-
tigating joint attention mechanisms through human-
robot interaction. Cognition, 120(2):268?291.
Maria Staudte, Alexander Koller, Konstantina Garoufi,
and Matthew W. Crocker. 2012. Using listener gaze
to augment speech generation in a virtual 3D environ-
ment. In Proceedings of the 34th Annual Conference
of the Cognitive Science Society. To appear.
Kristina Striegnitz, Alexandre Denis, Andrew Gargett,
Konstantina Garoufi, Alexander Koller, and Mariet
Theune. 2011. Report on the Second Second Chal-
lenge on Generating Instructions in Virtual Environ-
ments (GIVE-2.5). In Proceedings of the Generation
Challenges Session at the 13th European Workshop on
Natural Language Generation.
Michael K. Tanenhaus, Michael J. Spivey-Knowlton,
Kathleen M. Eberhard, and Julie C. Sedivy. 1995. In-
tegration of visual and linguistic information in spoken
language comprehension. Science, 268:1632?1634.
David Traum. 1994. A computational theory of ground-
ing in natural language conversation. Ph.D. thesis,
University of Rochester.
Michael Young, Johanna Moore, and Martha Pollack.
1994. Towards a principled representation for dis-
course plans. In Proceedings of the Sixteenth Annual
Meeting of the Cognitive Science Society.
A Example interactions
The following interactions between a user (U) and
each of the three systems (S) were recorded during
the systems? attempts to instruct the user to press the
rightmost blue button shown in Fig. 1.
A.1 Eyetracking system
(1) S: Push the right button to the right of the green
button.
U: (approaches the pair of blue and green but-
ton and inspects one of them)
S: No, not that one!
. . . (U inspects other buttons in the scene, while
S provides appropriate feedback)
U: (inspects the correct target)
S: Yes, that one!
U: (presses the correct button)
A.2 Movement system
(2) S: Push the right button to the right of the green
button.
U: (approaches the pair of blue and green but-
tons; once the user is very close to the blue but-
ton, it happens to become the only button visi-
ble on screen)
U: (continues moving closer to the blue button)
S: No, not that one!
U: (has no time to react to the system?s feed-
back and presses the wrong blue button)
A.3 No-feedback system
(3) S: Push the right button to the right of the green
button.
U: (presses the wrong blue button)
B The experimental setup
Figure 5: A faceLAB eyetracking system monitored par-
ticipants? eye movements during the interactions.
39
Proceedings of the INLG and SIGDIAL 2014 Joint Session, pages 6?15,
Philadelphia, Pennsylvania, 19 June 2014. c 2014 Association for Computational Linguistics
Generating effective referring expressions using charts
Nikos Engonopoulos and Alexander Koller
University of Potsdam, Germany{engonopo|akoller}@uni-potsdam.de
Abstract
We present a novel approach for generat-
ing effective referring expressions (REs).
We define a synchronous grammar formal-
ism that relates surface strings with the
sets of objects they describe through an ab-
stract syntactic structure. The grammars
may choose to require or not that REs are
distinguishing. We then show how to com-
pute a chart that represents, in finite space,
the complete (possibly infinite) set of valid
REs for a target object. Finally, we pro-
pose a probability model that predicts how
the listener will understand the RE, and
show how to compute the most effective
RE according to this model from the chart.
1 Introduction
The fundamental challenge in the generation of re-
ferring expressions (REG) is to compute an RE
which is effective, i.e. understood as intended by
the listener. Throughout the history of REG, we
have approximated this as the problem of generat-
ing distinguishing REs, i.e. REs that are only satis-
fied by a unique individual in the domain. This has
been an eminently successful approach, as doc-
umented e.g. in the overview article of Krahmer
and van Deemter (2012) and a variety of recent
shared tasks involving RE generation (Gatt and
Belz, 2010; Belz et al., 2008; Koller et al., 2010).
Nonetheless, reducing effectiveness to unique-
ness is limiting in several ways. First, in complex,
real-world scenes it may not be feasible to gener-
ate fully distinguishing REs, or these may have to
be exceedingly complicated. It is also not neces-
sary to generate distinguishing REs in such situa-
tions, because listeners are very capable of taking
the discourse and task context into account to re-
solve even ambiguous REs. Conversely, listeners
can misunderstand even a distinguishing RE, so
uniqueness is no guarantee for success. We pro-
pose instead to define and train a probabilistic RE
resolution model P (a|t), which directly captures
the probability that the listener will resolve a given
RE t to some object a in the domain. An RE t will
then be ?good enough? if P (a?|t) is very high for
the intended target referent a?.
Second, in an interactive setting like the GIVE
Challenge (Koller et al., 2010), the listener may
behave in a way that offers further information on
how they resolved the generated RE. Engonopou-
los et al. (2013) showed how an initial estimate
of the distribution P (a|t) can be continuously up-
dated based on the listener?s behavior, and that this
can improve a system?s ability to detect misunder-
standings. It seems hard to achieve this in a prin-
cipled way without an explicit model of P (a|t).
In this paper, we present an algorithm that gen-
erates the RE t that maximizes P (a?|t), i.e. the
RE that has the highest chance to be understood
correctly by the listener according to the proba-
bilistic RE resolution model. This is a challeng-
ing problem, since the algorithm must identify that
RE from a potentially infinite set of valid alterna-
tives. We achieve this by using a chart-based al-
gorithm, a standard approach in parsing and real-
ization, which has (to our knowledge) never been
used in REG.
We start by defining a synchronous grammar
formalism that relates surface strings to their in-
terpretations as sets of objects in a given domain
(Section 3). This formalism integrates REG with
surface realization, and allows us to specify in the
grammar whether REs are required to be distin-
guishing. We then show how to compute a chart
for a given grammar and target referent in Sec-
tion 4. Section 5 defines a log-linear model for
P (a|t), and presents a Viterbi-style algorithm for
computing the RE t from the chart that maximizes
P (a?|t). Section 6 concludes by discussing how
to apply our algorithm to the state-of-the-art ap-
proaches of Krahmer et al. (2003) and Golland et
al. (2010), and how to address a particular chal-
lenge involving cycles that arises when dealing
6
with probabilistic listener models.
2 Related Work
RE generation is the task of generating a natural-
language expression that identifies an object to the
listener. Since the beginnings of modern REG
(Appelt, 1985; Dale and Reiter, 1995), this prob-
lem has been approximated as generating a dis-
tinguishing description, i.e. one which fits only
one object in the domain and not any of the oth-
ers. This perspective has made it possible to apply
search-based (Kelleher and Kruijff, 2006), logic-
based (Areces et al., 2008) and graph-based (Krah-
mer et al., 2003) methods to the problem, and
overall has been one of the success stories of NLG.
However, in practice, human speakers fre-
quently overspecify, i.e. they include information
in an RE beyond what is necessary to make it
distinguishing (Wardlow Lane and Ferreira, 2008;
Koolen et al., 2011). An NLG system, too, might
include redundant information in an RE to make it
easier to understand for the user. Conversely, an
RE that is produced by a human can often be eas-
ily resolved by the listener even if it is ambiguous.
Here we present an NLG system that directly uses
a probabilistic model of RE resolution, and is ca-
pable of generating ambiguous REs if it predicts
that the listener will understand them.
Most existing REG algorithms focus on gener-
ating distinguishing REs, and then select the one
that is best according to some criterion, e.g. most
human-like (Krahmer et al., 2003; FitzGerald et
al., 2013) or most likely to be understood (Garoufi
and Koller, 2013). By contrast, Mitchell et al.
(2013) describe a stochastic algorithm that com-
putes human-like, non-relational REs that may not
be distinguishing. Golland et al. (2010) are close
to our proposal in spirit, in that they use a log-
linear probability model of RE resolution to com-
pute a possibly non-distinguishing RE. However,
they use a trivial REG algorithm which is limited
to grammars that only permit a (small) finite set of
REs for each referent. This is in contrast to gen-
eral REG, where there is typically an infinite set
of valid REs, especially when relational REs (?the
button to the left of the plant?) are permitted.
Engonopoulos et al. (2013) describe how to up-
date an estimate for P (a|t) based on a log-linear
model based on observations of the listener?s be-
havior. They use a shallowmodel based on a string
t and not an RE derived from a grammar, and they
do not discuss how to generate the best t. The al-
gorithm we develop here fills this gap.
Our formalism for REG can be seen as a syn-
chronous grammar formalism; it simultaneously
derives strings and their interpretations, connect-
ing the two by an abstract syntactic representa-
tion. This allows performing REG and surface re-
alization with a single algorithm, along the lines
of SPUD (Stone et al., 2003) and its planning-
based implementation, CRISP (Koller and Stone,
2007). Probabilistic synchronous grammars are
widely used in statistical machine translation (Chi-
ang, 2007; Graehl et al., 2008; Jones et al., 2012)
and semantic parsing (Zettlemoyer and Collins,
2005; Wong and Mooney, 2007). Lu and Ng
(2011) have applied such grammars to surface re-
alization. Konstas and Lapata (2012) use related
techniques for content selection and surface real-
ization (with simple, non-recursive grammars).
Charts are standard tools for representing a
large space of possible linguistic analyses com-
pactly. Next to their use in parsing, they have also
been applied to surface realization (Kay, 1996;
Carroll et al., 1999; Kaplan and Wedekind, 2000).
To our knowledge, ours is the first work using
charts for REG. This is challenging because the
input to REG is much less structured than in pars-
ing or realization.
3 Grammars for RE generation
We define a new grammar formalism that we use
for REG, which we call semantically intepreted
grammar (SIG). SIG is a synchronous grammar
formalism that relates natural language strings
with the sets of objects in a given domain which
they describe. It uses regular tree grammars
(RTGs) to describe languages of derivation trees,
which then project to strings and sets.
3.1 Derivation trees
We describe the abstract syntax of an RE by its
derivation tree, which is a tree over some ranked
signature ? of symbols representing lexicon en-
tries and grammatical constructions. A (ranked)
signature is a finite set of symbols r 2 ?, each
of which is assigned an arity ar(r) 2 N0. A tree
over the signature ? is a term r(t1, . . . , tn), where
r 2 ?, n = ar(r), and t1, . . . , tn are trees over ?.
We write T? for the set of all trees over ?.
Fig. 1b shows an example derivation tree for
the RE ?the square button? over the signature
? = {def |1, square|1, button|0}, where r|n indi-
cates that the symbol r has arity n. In term nota-
7
(a) (b) (c){b2} IR        def
square
button
IS   ! ?the square button?
0
@
\1
square button
1
A
0
B
B
B
@
?
the ?
square button
1
C
C
C
A
Figure 1: A SIG derivation tree (b) with its inter-
pretations (a, c).
tion, it is def (square(button)).
String interpretation. We interpret derivation
trees simultaneously as strings and sets. First, let
  be a finite alphabet, and let  ? be the string al-
gebra over  . We define a string interpretation
over   as a function IS that maps each r|n 2 ?
to a function IS(r) : ( ?)n !  ?. For instance,
we can assign string interpretations to our exam-
ple signature ? as follows; we write w1 ? w2 for
the concatenation of the strings w1 and w2.IS(def )(w1) = the ? w1IS(square)(w1) = square ? w1IS(button) = button
Since the arity of IS(r) is the same as the ar-
ity of r for any r 2 ?, we can use IS to recur-
sively map derivation trees to strings. Starting at
the leaves, we map the tree r(t1, . . . , tn) to the
string IS(r)(IS(t1), . . . , IS(tn)), where IS(ti) is
the string that results from recursively applying IS
to the subtree ti. In the example, the subtree button
is mapped to the string ?button?. We then get
the string for the subtree square(button) by con-
catenating this with ?square?, obtaining the string
?square button? and so on, as shown in Fig. 1c.
Relational interpretation. We further define a
relational interpretation IR, which maps each
r|n 2 ? to a function IR(r) : R(U)n ! R(U),
where R(U) is a class of relations. We define IR
over some first-order model structureM = hU,Li,
where U is a finite universe U of individuals and L
interprets a finite set of predicate symbols as rela-
tions over U . We let R(U) be the set of all k-place
relations over U for all k   0. The subsets of U
are the special case of k = 1. We write k(R) for
the arity of a relation R 2 R(U).
For the purposes of this paper, we construct IR
by combining the following operations:? The denotations of the atomic predicate sym-
bols of M ; see Fig. 2 for an example.
U = {b1, b2, b3} button = {b1, b2, b3}
round = {b1, b3} square = {b2}
left of = {hb1, b2i, hb2, b3i}
right of = {hb2, b1i, hb3, b2i}
Figure 2: A simple model, illustrated as a graph.? proji(R) = {ai | ha1, . . . , ak(R)i 2 R} is
the projection to the i-th component; if i >
k(R), it evaluates to ;.? R1 \i R2 = {ha1, . . . , ak(R1)i 2 R1 | ai 2
R2} is the intersection on the i-th component
of R1; if i > k(R1), it evaluates to ;.? For any a 2 U , uniqa(R) evaluates to {a} if
R = {a}, and to ; otherwise.? For any a 2 U , membera(R) evaluates to{a} if a 2 R, and to ; otherwise.
For the example, we assume that we want to
generate REs over the scene shown in Fig. 2; it
consists of the universe U = {b1, b2, b3} and inter-
prets the atomic predicate symbols button, square,
round, left of, and right of. Given this, we can
assign a relational interpretation to the derivation
tree in Fig. 1b using the following mappings:IR(def )(R1) = R1IR(square)(R1) = square \1 R1IR(button) = button
We evaluate a derivation tree to a relation as we
did for strings (cf. Fig. 1a). The subtree button
maps to the denotation of the symbol button, i.e.{b1, b2, b3}. The subtree square(button) evaluates
to the intersection of this set with the set of square
individuals, i.e. {b2}; this is also the relational in-
terpretation of the entire derivation tree. We thus
see that ?the square button? is an RE that describes
the individual b2 uniquely.
3.2 Semantically interpreted grammars
Now we define grammars that describe relations
between strings and relations over U . We achieve
this by combining a regular tree grammar (RTG,
(Ge?cseg and Steinby, 1997; Comon et al., 2007)),
describing a language of derivation trees, with a
string interpretation and a relational interpretation.
An RTG G = (N,?, S, P ) consists of a finite
set N of nonterminal symbols, a ranked signa-
ture ?, a start symbol S 2 N , and a finite set
P of production rules A ! r(B1, ..., Bn), where
8
A,B1, . . . , Bn 2 N and r|n 2 ?. We say that
a tree t2 2 T? can be derived in one step from
t1 2 T?, t1 ) t2, if it can be obtained by replac-
ing an occurrence of B in t1 with t and P con-
tains the rule B ! t. A tree tn 2 T? can be
derived from t1, t1 )? tn, if there is a sequence
t1 ) . . . ) tn of length n   0. For any nontermi-
nal A, we write LA(G) for the set of trees t 2 T?
with A )? t. We simply write L(G) for LS(G)
and call it the language of G.
We define a semantically interpreted grammar
(SIG) as a triple G = (G, IS , IR) of an RTG G
over some signature?, together with a string inter-
pretation IS over some alphabet  and a relational
interpretation IR over some universe U , both of
which interpret the symbols in ?. We assume that
every terminal symbol r 2 ? occurs in at most
one rule, and that the nonterminals of G are pairs
Ab of a syntactic category A and a semantic index
b = ix(Ab). A semantic index indicates the indi-
vidual in U to which a given constituent is meant
to refer, see e.g. (Kay, 1996; Stone et al., 2003).
Note that SIGs can be seen as specific Interpreted
Regular Tree Grammars (Koller and Kuhlmann,
2011) with a set and a string interpretation.
We ignore the start symbol of G. Instead, we
say that given some individual b 2 U and syntactic
category A, the set of referring expressions for b is
REG(A, b) = {t 2 LAb(G) | IR(t) = {b}}, i.e.
we define an RE as a derivation tree that G can
derive from Ab and whose relational interpretation
is {b}. From t, we can read off the string IS(t).1
3.3 An example grammar
Consider the SIG G in Fig. 3 for example. The
grammar is written in template form. Each rule
is instantiated for all semantic indices specified
in the line above; e.g. the symbol round denotes
the set {b1, b3}, therefore there are rules Nb1 !
roundb1(Nb1) and Nb3 ! roundb3(Nb3). The val-
ues of IR and IS for each symbol are specified
below the RTG rule for that symbol.
We can use G to generate NPs that refer to the
target referent b2 given the model shown in Fig. 2
by finding trees in LNPb2 (G) that refer to {b2}.
One such tree is t1 = def b2(squareb2(buttonb2)),
a more detailed version of the tree in Fig. 1b.
It can be derived by NPb2 ) def b2(Nb2) )
def b2(squareb2(Nb2)) ) t1. Because IR(t1) ={b2}, we see that t1 2 REG(NP, b2); it represents
1Below, we will often write the RE as a string when the
derivation tree is clear.
for all a 2 U :
NPa ! defa(Na)
IS(defa)(w1) = the ? w1
IR(defa)(R1) = membera(R1)
for all a 2 button:
Na ! buttona
IS(buttona) = button
IR(buttona) = button
for all a 2 round:
Na ! rounda(Na)
IS(rounda)(w1) = round ? w1
IR(rounda)(R1) = round \1 R1
for all a 2 square:
Na ! squarea(Na)
IS(squarea)(w1) = square ? w1
IR(squarea)(R1) = square \1 R1
for all a, b 2 left of:
Na ! leftofa,b(Na,NPb)
IS(leftofa,b)(w1, w2) = w1 ? to ? the ? left ? of ? w2
IR(leftofa,b)(R1, R2) = proj1((left of \1 R1) \2 R2)
for all a, b 2 right of:
Na ! rightofa,b(Na,NPb)
IS(rightofa,b)(w1, w2) = w1 ? to ? the ? right ? of ? w2
IR(rightofa,b)(R1, R2) = proj1((right of \1 R1) \2 R2)
Figure 3: An example SIG grammar.
the string IS(t1) = ?the square button?.
A second derivation tree for b2 is t2 =
def b2(squareb2(squareb2(buttonb2))), correspond-
ing to IS(t2) = ?the square square button?. It de-
rives from NPb2 in four steps, and has IR(t2) ={b2}. Even the small grammar G licences an infi-
nite set of REs for b2, all of which are semantically
correct. Avoiding the generation of nonsensical
REs like ?the square square button? is a techni-
cal challenge to which we will return in Section 6.G can also derive relational REs; for instance, the
derivation tree in Fig. 6 for the string ?the button
to the left of the square button? is in REG(NP, b1).
Finally, G considers the non-distinguishing t3 =
def b2(buttonb2) (for ?the button?) a valid RE for
b2. This is because memberb2 will quietly project
the set {b1, b2, b3} (to which buttonb2 refers) to{b2}. As discussed in previous sections, we want
to allow such non-unique REs and delegate the
judgment about their quality to the probability
model. It would still be straightforward, however,
to impose a hard uniqueness constraint, by simply
changing IR(def a)(R1) to uniqa(R1) in Fig. 3.
This would yield IR(t3) = ;, i.e. t3 would no
longer be in REG(NP, b2).
4 Chart-based RE generation
We now present a chart-based algorithm for gener-
ating REs with SIG grammars. Charts allow us to
represent all REs for a target referent compactly,
and can be computed efficiently. We show in Sec-
tion 5 that charts also lend themselves well to com-
puting the most effective RE.
9
Nb1/{b1, b2, b3}! buttonb1
Nb2/{b1, b2, b3}! buttonb2
Nb3/{b1, b2, b3}! buttonb3
Nb1/{b1, b3}! roundb1 (Nb1/{b1, b2, b3})
Nb3/{b1, b3}! roundb3 (Nb3/{b1, b2, b3})
Nb1/{b1, b3}! roundb1 (Nb1/{b1, b3})
Nb3/{b1, b3}! roundb3 (Nb3/{b1, b3})
Nb2/{b2}! squareb2 (Nb2/{b1, b2, b3})
Nb2/{b2}! squareb2 (Nb2/{b2})
NPb2/{b2}! def b2 (Nb2/{b1, b2, b3})
NPb2/{b2}! def b2 (Nb2/{b2})
Nb1/{b1}! leftof b1,b2 (Nb1/{b1, b2, b3},NPb2/{b2})
Nb1/{b1}! leftof b1,b2 (Nb1/{b1, b3},NPb2/{b2})
Nb1/{b1}! leftof b1,b2 (Nb1/{b1},NPb2/{b2})
Nb1/{b1}! roundb1 (Nb1/{b1})
NPb1/{b1}! def b1 (Nb1/{b1, b2, b3})
NPb1/{b1}! def b1 (Nb1/{b1, b3})
NPb1/{b1}! def b1 (Nb1/{b1})
Nb3/{b3}! rightof b3,b2 (Nb3/{b1, b2, b3},NPb2/{b2})
Nb3/{b3}! rightof b3,b2 (Nb3/{b1, b3},NPb2/{b2})
Nb3/{b3}! rightof b3,b2 (Nb3/{b3},NPb2/{b2})
Nb3/{b3}! roundb3 (Nb3/{b3})
NPb3/{b3}! def b3 (Nb3/{b1, b2, b3})
NPb3/{b3}! def b3 (Nb3/{b1, b3})
NPb3/{b3}! def b3 (Nb3/{b3})
Nb2/{b2}! leftof b2,b3 (Nb2/{b1, b2, b3},NPb3/{b3})
Nb2/{b2}! rightof b2,b1 (Nb2/{b1, b2, b3},NPb1/{b1})
Nb2/{b2}! leftof b2,b3 (Nb2/{b2},NPb3/{b3})
Nb2/{b2}! rightof b2,b1 (Nb2/{b2},NPb1/{b1})
Figure 4: The chart for the grammar in Fig. 3.
4.1 RE generation charts
Generally speaking, a chart is a packed data struc-
ture which describes how larger syntactic repre-
sentations can be recursively built from smaller
ones. In applications such as parsing and sur-
face realization, the creation of a chart is driven
by the idea that we consume some input (words
or semantic atoms) as we build up larger struc-
tures. The parallel to this intuition in REG is that
?larger? chart entries are more precise descriptions
of the target, which is a weaker constraint than
input consumption. Nonetheless, we can define
REG charts whose entries are packed representa-
tions for large sets of possible REs, and compute
them in terms of these entries instead of RE sets.
Technically, we represent charts as RTGs over
an extended set of nonterminals. A chart for gener-
ating an RE of syntactic category A for an individ-
ual b 2 U is an RTG C = (N 0,?, S0, P 0), where
N 0 ? N ? R(U) and S0 = Ab/{b}. Intuitively,
the nonterminal Ab/{a1, . . . , an} expresses that
we intend to generate an RE for b fromA, but each
RE that we can derive from the nonterminal actu-
ally denotes the referent set {a1, . . . , an}.
A chart for the grammar in Fig. 3 is shown
in Fig. 4. To generate an NP for b2, we let
its start symbol be S0 = NPb2/{b2}. The rule
Nb2/{b1, b2, b3} ! buttonb2 says that we can gen-
erate an RE t with IR(t) = {b1, b2, b3} from the
nonterminal symbolNb2 by expanding this symbol
with the grammar rule Nb2 ! buttonb2 . Similarly,
A! r(B1, ..., Bn) in G
B01 = B1/R1, ..., B
0
n = Bn/Rn in N
0
Add A0 = A/IR(r)(R1, ..., Rn) to N 0
Add rule A0 ! r(B01, ..., B0n) to P 0
Figure 5: The chart computation algorithm.
the rule Nb2/{b2} ! squareb2(Nb2/{b1, b2, b3})
expresses that we can generate an RE withIR(t) = {b2} by expanding the nonterminal sym-
bol Nb2 into squareb2(t0), where t0 is any tree that
the chart can generate from Nb2/{b1, b2, b3}.
4.2 Computing a chart
Given a SIG G, a syntactic category A, and a
target referent b, we can compute a chart C for
REG(A, b) using the parsing schema in Fig. 5.
The schema assumes that we have a rule A !
r(B1, . . . , Bn) in G; in addition, for each 1 ?
i ? n it assumes that we have already added
the nonterminal B0i = Bi/Ri to the chart, in-
dicating that there is a tree ti with Bi )? ti
and IR(ti) = Ri. Then we know that t =
r(t1, . . . , tn) can be derived from A and that R0 =IR(t) = IR(r)(R1, . . . , Rn). We can therefore
add the nonterminal A0 = A/R0 and the produc-
tion rule A0 ! r(B01, . . . , B0n) to the chart; this
rule can be used as the first step in a derivation of t
fromA0. We can optimize the algorithm by adding
A0 and the rule only if R0 6= ;.
The algorithm terminates when it can add no
more rules to the chart. Because U is finite, this
always happens after a finite number of steps, even
if there is an infinite set of REs. For instance, the
chart in Fig. 4 describes an infinite language of
REs, including ?the square button?, ?the button to
the left of the round button?, ?the button to the left
of the button to the right of the square button?, etc.
Thus it represents relational REs that are nested
arbitrarily deeply through a finite number of rules.
After termination, the chart contains all rules by
which a nonterminal can be decomposed into other
(productive) nonterminals. As a result, L(C) con-
tains exactly the REs for b of category A:
Theorem 1 If C is a chart for the SIG G, the syn-
tactic category A, and the target referent b, then
L(C) = REG(A, b).
5 Computing best referring expressions
The chart algorithm allows us to compactly rep-
resent all REs for the target referent. We now
show how to compute the best RE from the chart.
We present a novel probability model P (b|t) for
RE resolution, and take the ?best? RE to be the
10
Figure 6: The derivation tree for ?the button to the
left of the square button?.
one with the highest chance to be understood as
intended. Next to the best RE itself, the algo-
rithm also computes the entire distribution P (b|t),
to support later updates in an interactive setting.
Nothing in our algorithm hinges on this par-
ticular model; it can also be used with any other
scoring model that satisfies a certain monotonicity
condition which we spell out in Section 5.2.
5.1 A log-linear model for effective REs
We model the probability P (b|t) that the listener
will resolve the RE t to the object b using a
log-linear model with a set of feature functions
f(a, t,M), where a is an object, t is a derivation
tree, and M is the relational interpretation model.
We focus on features that only look at informa-
tion that is local to a specific subtree of the RE,
such as the label at the root. For instance, a feature
fround(a, t0,M) might return 1 if the root label of
t0 is rounda and a is round in M , and 0 otherwise.
Another feature fdef (a, t0,M) might return 1/k if
t0 is of the form def b(t00), R = IR(t00) has k el-
ements, and a 2 R; and 0 otherwise. This fea-
ture counterbalances the ability of the grammar in
Fig. 3 to say ?the w? even when w is a non-unique
description by penalizing descriptions with many
possible referents through lower feature values.
When generating a relational RE, the derivation
tree naturally splits into separate regions, each of
which is meant to identify a specific object. These
regions are distinguished by the semantic indices
in the nonterminals that derive them; e.g., in Fig. 6,
the subtree for ?the square button? is an attempt to
refer to b2, whereas the RE as a whole is meant to
refer to b1. To find out how effective the RE is as
a description of b1, we evaluate the features at all
nodes in the region top(t) containing the root of t.
Each feature function fi is associated with a
weight wi. We obtain a score tuple sc(t0) for some
subtree t0 of an RE as follows:
sc(t0) = hs(a1, t0,M), . . . , s(am, t0,M)i,
t b1 b2 b3
?the button? 0.33 0.33 0.33
?the round button? 0.45 0.10 0.45
?the button to the left
of the square button? 0.74 0.14 0.12
Figure 7: Probability distributions for some REs t.
where U = {a1, . . . , am} and s(a, t0,M) =Pni=1 wi ? fi(a, t0,M). We then combine these
into a score tuple score(t) =
Pu2top(t) sc(t.u)
for the whole RE t, where t.u is the subtree of
t below the node u. Finally, given a score tuple
s = hs1, . . . , smi for t, we define the usual log-
linear probability distribution as
P (ai|t) = prob(ai, s) = esiPmj=1 esj .
The best RE for the target referent b is then
bestG(A, b) = argmaxt2REG(A,b) prob(b, sc(t)).
For illustration, we consider a number of REs
for b1 in our running example. We use fround and
fdef and let wround = wdef = 1. In this case, the
RE ?the button? has a score tuple h1/3, 1/3, 1/3i,
which is the sum of the tuple h0, 0, 0i for fround
(since the RE does not use the ?round? rule) and
the tuple h1/3, 1/3, 1/3i for fdef (since ?button?
is three-way ambiguous in M ). This yields a uni-
form probability distribution over U (see Fig. 7).
By contrast, ?the round button? gets h3/2, 0, 3/2i,
resulting in the distribution in the second line of
Fig. 7. This RE is judged better than ?the button?
because it assigns a higher probability to b1.
Relational REs involve derivation trees with
multiple regions, only the top one of which is di-
rectly counted for P (b|t) (see Fig. 6). We incorpo-
rate the quality of the other regions through appro-
priate features. In the example, we use a feature
fleftof (a, t0,M) = Pb:ha,bi2left of P (b|t00), where
t00 is the second subtree of t0. This feature com-
putes the probability that the referent to which the
listener resolves t00 is actually to the right of a,
and will thus take a high value if t00 is a good
RE for b2. Assuming a probability distribution of
P (b2|t0) = 0.78 and P (b1|t0) = P (b3|t0) = 0.11
for t0 =?the square button?, we get the tupleh0.78, 0.11, 0i for fleftof , yielding the third line
of Fig. 7 for wleftof = 1.
11
5.2 Computing the best RE
We compute bestG(A, b) from the chart by adapt-
ing the Viterbi algorithm. Our key data structure
assigns a score tuple is(A0) to each nonterminal
A0 in the chart. Intuitively, if the semantic index
of A0 is b, then is(A0) is the score tuple sc(t) for
the tree t 2 LA0(C) which maximizes P (b|t). We
also record this best tree as bt(A0). Thus the al-
gorithm is correct if, after running it, we obtain
bestG(A, b) = bt(Ab/{b}).
As is standard in chart algorithms, we limit our
attention to features whose values can be com-
puted bottom-up by local operations. Specifically,
we assume that if A0 ! r(B01, . . . , B0n) is a rule in
the chart and ti is the best RE for B0i for all i, then
the best RE for A0 that can be built using this rule
is r(t1, . . . , tn). This means that features must be
monotonic, i.e. that the RE that seemed locally
best for B0i leads to the best RE overall.
Under this assumption, we can compute is(A0)
and bt(A0) bottom-up as shown in Fig. 8. We it-
erate over all nonterminals A0 in the chart in a
fixed linear order, which we call the evaluation
order. Then we compute is(A0) and bt(A0) by
maximizing over the rules for A0. Assume that
the best RE for A0 can be constructed using the
rule A0 ! r(B01, . . . , B0n). Then if, at the time we
evaluate A0, we have fully evaluated all the B0i in
the sense that bt(B0i) is actually the best RE for
B0i, the algorithm will assign the best RE for A0
to bt(A0), and its score tuple to is(A0). Thus, if
we call an evaluation order exact if the nontermi-
nals on the right-hand side of each rule in the chart
come before the nonterminal on the left-hand side,
we can inductively prove the following theorem:
Theorem 2 If the evaluation order is exact, then
for every nonterminal A0 in the chart, we ob-
tain bt(A0) = argmaxt2LA0 (C) P (ix(A0)|t) and
is(A0) = sc(bt(A0)).
In other words, the algorithm is correct if the
evaluation order is exact. If it is not, we might
compute a sub-optimal RE as bt(A0), which un-
derestimates is(A0). The choice of evaluation or-
der is thus crucial.
6 Evaluating charts with cycles
It remains to show how we can determine an ex-
act evaluation order for a given chart. One way to
think about the problem is to consider the order-
ing graph O(C) of the chart C (see Fig. 9 for an
example). This is a directed graph whose nodes
1: for nonterminals A0 in evaluation order do
2: for rules r of the form A0 ! r(B01, . . . , B0n) do
3: a = ix(A0)
4: t0 = r(bt(B01), . . . , bt(B
0
n))
5: s = sc(t0) +
nX
i=1
ix(B0i)=a
is(B0i)
6: if prob(a, s) > prob(a, is(A0)) then
7: is(A0) = s
8: bt(A0) = t0
Figure 8: Computing the best RE.
are the nonterminals of the chart; for each rule
A0 ! r(B01, . . . , B0n) in C, it has an edge from
B0i to A0 for each i. If this graph is acyclic, we
can simply compute a topological sort of O(C)
to bring the nodes into a linear order in which
each B0i precedes A0. This is enough to evalu-
ate charts using certain simpler models. For in-
stance, we can apply our REG algorithm to the
log-linear model of Golland et al. (2010). Because
they only generate REs with a bounded number of
relations, their grammars effectively only describe
finite languages. In such a case, our charts are al-
ways acyclic, and therefore a topological sort of
O(C) yields an exact evaluation order.
This simple approach will not work with gram-
mars that allow arbitrary recursion, as they can
lead to charts with cycles (indicating an infinite
set of valid REs). E.g. the chart in Fig. 4 contains
a rule Nb2/{b2} ! squareb2(Nb2/{b2}) (shown
in Fig. 9), which can be used to construct the RE
t0 = ?the square square button? in addition to the
RE t = ?the square button?. Such cycles can be
increasing with respect to a log-linear probability
model, i.e. the model considers t0 a better RE than
t. Indeed, t has a score tuple of h0, 2, 0i, giving
P (b2|t) = 0.78. By contrast, t0 has a score tuple
of h0, 3, 0i, thus P (b2|t0) = 0.91. This can be con-
tinued indefinitely, with each addition of ?square?
increasing the probability of being resolved to b2.
Thus, there is no best RE for b2; every RE can be
improved by adding another copy of ?square?.
In such a situation, it is a challenge to even
compute any score for every nonterminal without
running into infinite loops. We can achieve this
by decomposing O(C) into its strongly connected
components (SCCs), i.e. the maximal subgraphs in
which each node is reachable from any other node.
We then consider the component graph O0(C); its
nodes are the SCCs of O(C), and it has an edge
from c1 to c2 if O(C) has an edge from some
node in c1 to some node in c2. O0(C) is acyclic
by construction, so we can compute a topological
12
Figure 9: A fragment of the ordering graph for the
chart in Fig. 4. Dotted boxes mark SCCs.
Figure 10: A fragment of a chart ordering graph
for a grammar with enriched nonterminals.
sort and order all nonterminals from earlier SCCs
before all nonterminals from later SCCs. Within
each SCC, we order the nonterminals in the order
in which they were discovered by the algorithm in
Fig. 5. This yields a linear order on nonterminals,
which at least ensures that by the time we evaluate
a nonterminal A0, there is at least one rule for A0
whose right-hand nonterminals have all been eval-
uated; so is(A0) gets at least some value.
In our example, we obtain the order
Nb2/{b1, b2, b3}, Nb2/{b2}, NPb2/{b2}. The
rule Nb2/{b2} ! squareb2(Nb2/{b2}) will thus
not be considered in the evaluation of Nb2/{b2},
and the algorithm returns ?the square button?.
The algorithm computes optimal REs for acyclic
charts, and also for charts where all cycles are
decreasing, i.e. using the rules in the cycle make
the RE worse. This enables us, for instance, to
encode the REG problem of Krahmer et al. (2003)
into ours by using a feature that evaluates the rule
for each attribute to its (negative) cost according
to the Krahmer model. Krahmer et al. assume that
every attribute has positive cost, and is only used
if it is necessary to make the RE distinguishing.
Thus all cycles in the chart are decreasing.
One limitation of the algorithm is that it does
not overspecify. Suppose that we extend the ex-
ample model in Fig. 2 with a color predicate
green = {b2}. We might then want to prefer
?the green square button? over ?the square but-
ton? because it is easier to understand. But since
all square objects (i.e. {b2}) are also green, using
?green? does not change the denotation of the RE,
i.e. it is represented by a loop from Nb2/{b2} to
Nb2/{b2}, which is skipped by the algorithm. One
idea could be to break such cycles by the careful
use of a richer set of nonterminals in the gram-
mar; e.g., they might record the set of all attributes
that were used in the RE. Our example rule would
then become Nb2/{b2}/{square, green} !
greenb2(Nb2/{b2}/{square}), which the algo-
rithm can make use of (see Fig. 10).
7 Conclusion
We have shown how to generate REs using charts.
Based on an algorithm for computing a chart of all
valid REs, we showed how to compute the RE that
maximizes the probability of being understood as
the target referent. Our algorithm integrates REG
with surface realization. It generates distinguish-
ing REs if this is specified in the grammar; oth-
erwise, it computes the best RE without regard to
uniqueness, using features that prefer unambigu-
ous REs as part of the probability model.
Our algorithm can be applied to earlier models
of REG, and in these cases is guaranteed to com-
pute optimal REs. The probability model we intro-
duced here is more powerful, and may not admit
?best? REs. We have shown how the algorithm
can still do something reasonable in such cases,
but this point deserves attention in future research,
especially with respect to overspecification.
We evaluated the performance of our chart al-
gorithm on a number of randomly sampled in-
put scenes from the GIVE Challenge, which con-
tained 24 objects on average. Our implementa-
tion is based on the IRTG tool available at irtg.googlecode.com. While in the worst case the
chart computation is exponential in the input size,
in practice runtimes did not exceed 60 ms for the
grammar shown in Fig. 3.
We have focused here on computing best REs
given a probability model. We have left train-
ing the model and evaluating it on real-world data
for future work. Because our probability model
focuses on effectiveness for the listener, rather
than human-likeness, our immediate next step is to
train it on an interaction corpus which records the
reactions of human listeners to system-generated
REs. A further avenue of research is to deliber-
ately generate succinct but ambiguous REs when
the model predicts them to be easily understood.
We will explore ways of achieving this by combin-
ing the effectiveness model presented here with a
language model that prefers succinct REs.
Acknowledgments. We thank Emiel Krahmer,
Stephan Oepen, Konstantina Garoufi, Mart??n Vil-
lalba and the anonymous reviewers for their useful
comments and discussions. The authors were sup-
ported by the SFB 632 ?Information Structure?.
13
References
Douglas E. Appelt. 1985. Planning English sentences.
Cambridge University Press.
Carlos Areces, Alexander Koller, and Kristina Strieg-
nitz. 2008. Referring expressions as formulas of
description logic. In Proceedings of the 5th Inter-
national Natural Language Generation Conference
(INLG).
Anja Belz, Eric Kow, Jette Viethen, and Albert Gatt.
2008. The GREC challenge 2008: Overview and
evaluation results. In Proceedings of the 5th Inter-
national Conference on Natural Language Genera-
tion (INLG).
John Carroll, Ann Copestake, Dan Flickinger, and Vic-
tor Poznanski. 1999. An efficient chart generator
for (semi-)lexicalist grammars. In Proceedings of
the 7th European Workshop on Natural Language
Generation.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201?228.
Hubert Comon, Max Dauchet, Re?mi Gilleron, Christof
Lo?ding, Florent Jacquemard, Denis Lugiez, Sophie
Tison, and Marc Tommasi. 2007. Tree automata
techniques and applications. Available on http://tata.gforge.inria.fr/.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean Maxims in the gener-
ation of referring expressions. Cognitive Science,
19(2):233?263.
Nikos Engonopoulos, Martin Villalba, Ivan Titov, and
Alexander Koller. 2013. Predicting the resolution
of referring expressions from user behavior. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP), Seattle.
Nicholas FitzGerald, Yoav Artzi, and Luke Zettle-
moyer. 2013. Learning distributions over logical
forms for referring expression generation. In Pro-
ceedings of the Conference on Empirical Methods
in Natural Language Processing.
Konstantina Garoufi and Alexander Koller. 2013.
Generation of effective referring expressions in situ-
ated context. Language and Cognitive Processes.
Albert Gatt and Anja Belz. 2010. Introducing shared
task evaluation to NLG: The TUNA shared task
evaluation challenges. In E. Krahmer and M. The-
une, editors, Empirical Methods in Natural Lan-
guage Generation, number 5790 in LNCS, pages
264?293. Springer.
Ferenc Ge?cseg and Magnus Steinby. 1997. Tree lan-
guages. In G. Rozenberg and A. Salomaa, editors,
Handbook of Formal Languages, volume 3, chap-
ter 1, pages 1?68. Springer-Verlag.
Dave Golland, Percy Liang, and Dan Klein. 2010.
A game-theoretic approach to generating spatial de-
scriptions. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP).
Jonathan Graehl, Kevin Knight, and Jonathan May.
2008. Training tree transducers. Computational
Linguistics, 34(3).
B. Jones, J. Andreas, D. Bauer, K.-M. Hermann, and
K. Knight. 2012. Semantics-based machine transla-
tion with hyperedge replacement grammars. In Pro-
ceedings of COLING.
Ron Kaplan and Ju?rgen Wedekind. 2000. LFG gener-
ation produces context-free languages. In Proceed-
ings of the 18th COLING.
Martin Kay. 1996. Chart generation. In Proceedings
of the 34th ACL.
John Kelleher and Geert-Jan Kruijff. 2006. Incremen-
tal generation of spatial referring expressions in situ-
ated dialogue. In In Proceedings of Coling-ACL ?06,
Sydney Australia.
Alexander Koller and Marco Kuhlmann. 2011. A gen-
eralized view on parsing and translation. In Pro-
ceedings of the 12th International Conference on
Parsing Technologies, pages 2?13. Association for
Computational Linguistics.
Alexander Koller and Matthew Stone. 2007. Sentence
generation as a planning problem. In Proceedings of
the 45th Annual Meeting of the Association of Com-
putational Linguistics (ACL).
Alexander Koller, Kristina Striegnitz, Donna Byron,
Justine Cassell, Robert Dale, Johanna Moore, and
Jon Oberlander. 2010. The First Challenge on
Generating Instructions in Virtual Environments.
In E. Krahmer and M. Theune, editors, Empirical
Methods in Natural Language Generation, number
5790 in LNAI, pages 337?361. Springer.
Yannis Konstas and Mirella Lapata. 2012. Concept-
to-text generation via discriminative reranking. In
Proceedings of the 50th ACL.
Ruud Koolen, Albert Gatt, Martijn Goudbeek, and
Emiel Krahmer. 2011. Factors causing overspec-
ification in definite descriptions. Journal of Prag-
matics, 43:3231?3250.
Emiel Krahmer and Kees van Deemter. 2012. Compu-
tational generation of referring expressions: A sur-
vey. Computational Linguistics, 38(1):173?218.
Emiel Krahmer, Sebastiaan van Erk, and Andre? Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53?72.
Wei Lu and Hwee Tou Ng. 2011. A probabilistic
forest-to-string model for language generation from
typed lambda calculus expressions. In Proceedings
of EMNLP.
14
Margaret Mitchell, Kees van Deemter, and Ehud Re-
iter. 2013. Generating expressions that refer to vis-
ible objects. In Proceedings of NAACL-HLT, pages
1174?1184.
Matthew Stone, Christine Doran, Bonnie Webber, To-
nia Bleam, and Martha Palmer. 2003. Microplan-
ning with communicative intentions: The SPUD
system. Computational Intelligence, 19(4):311?
381.
Liane Wardlow Lane and Victor Ferreira. 2008.
Speaker-external versus speaker-internal forces on
utterance form: Do cognitive demands override
threats to referential success? Journal of Experi-
mental Psychology: Learning, Memory, and Cogni-
tion, 34:1466?1481.
Yuk Wah Wong and Raymond J. Mooney. 2007.
Learning synchronous grammars for semantic pars-
ing with lambda calculus. In Proceedings of the 45th
ACL.
Luke S. Zettlemoyer and Michael Collins. 2005.
Learning to map sentences to logical form: Struc-
tured classification with probabilistic categorial
grammars. In Proceedings of the 21st Conference
on Uncertainty in Artificial Intelligence (UAI).
15
