243
244
245
246
247
248
249
250
Automatic Discovery of Term Similarities Using Pattern Mining
Goran NENADI?, Irena SPASI? and Sophia ANANIADOU
Computer Science, University of Salford
Salford, M5 4WT, UK
{G.Nenadic, I.Spasic, S.Ananiadou}@salford.ac.uk
Abstract
Term recognition and clustering are key topics in automatic knowledge acquisition and text mining. In
this paper we present a novel approach to the automatic discovery of term similarities, which serves as
a basis for both classification and clustering of domain-specific concepts represented by terms. The
method is based on automatic extraction of significant patterns in which terms tend to appear. The
approach is domain independent: it needs no manual description of domain-specific features and it is
based on knowledge-poor processing of specific term features. However, automatically collected
patterns are domain specific and identify significant contexts in which terms are used. Beside features
that represent contextual patterns, we use lexical and functional similarities between terms to define a
combined similarity measure. The approach has been tested and evaluated in the domain of molecular
biology, and preliminary results are presented.
Introduction
In a knowledge intensive discipline such as
molecular biology, the vast and constantly
increasing amount of information demands
innovative techniques to gather and systematically
structure knowledge, usually available only from
text/document resources. In order to discover new
knowledge, one has to identify main concepts,
which are linguistically represented by domain
specific terms (Maynard and Ananiadou (2000)).
There is an increased amount of new terms that
represent newly created concepts. Since existing
term dictionaries usually do not meet the needs of
specialists, automatic term extraction tools are
indispensable for efficient term discovery and
dynamic update of term dictionaries.
   However, automatic term recognition (ATR) is
not the ultimate aim: terms recognised should be
related to existing knowledge and/or to each other.
This entails the fact that terms should be classified
or clustered so that semantically similar terms are
grouped together. Classification and/or clustering
of terms are indispensable for improving
information extraction, knowledge acquisition, and
document categorisation. Classification can also be
used for efficient term management and populating
and updating existing ontologies in a consistent
manner. Both classification and clustering methods
are built on top of a specific similarity measure.
The notion of term similarity has been defined and
considered in different ways: terms can have
functional and/or structural similarities, though
they can be correlated by different relationships
(Grefenstette (1994), Maynard and Ananiadou
(2000)). In this paper we suggest a novel, domain-
independent method for the automatic discovery of
term similarities, which can serve as a basis for
both classification and clustering of terms. The
method is mainly based on the automatic discovery
of significant term features through pattern mining.
Automatically collected patterns are domain
dependent and they identify significant contexts in
which terms tend to appear. In addition, the
measure combines lexical and syntactical
similarities between terms.
   The paper is organised as follows. In Section 1
we overview term management approaches.
Section 2 introduces the term similarity measure
and Section 3 presents results and experiments.
1   Terminology Management
Since vast amount of knowledge still remains
unexplored, several systems have been proposed to
help scientists to acquire relevant knowledge from
scientific literature. For example, GENIES
(Friedman et al (2001)) uses a semantic grammar
and substantial syntactic knowledge in order to
extract comprehensive information about signal-
transduction pathways. Some of the systems are
terminology-based, since technical terms
semantically characterise documents and therefore
represent starting place for knowledge acquisition
tasks. For example, Mima et al (2002) introduce
TIMS, a terminology-based knowledge acquisition
system, which integrates automatic term
recognition, term variation management, context-
based automatic term clustering, ontology-based
inference, and intelligent tag information retrieval.
The system?s aim is to provide efficient access and
integration of heterogeneous biological textual data
and databases.
   There are numerous approaches to ATR. Some
methods (Bourigault (1992), Ananiadou (1994))
rely purely on linguistic information, namely
morpho-syntactic features of term candidates.
Recently, hybrid approaches combining linguistic
and statistical knowledge are becoming
increasingly used (Frantzi et al (2000), Nakagawa
et al (1998)).
   There is a range of clustering and classification
approaches that are based on statistical measures of
word co-occurrences (e.g. Ushioda (1996)), or
syntactic information derived from corpora (e.g.
Grefenstette  (1994)). However, few of them deal
with term clustering: Maynard and Ananiadou
(2000) present a method that uses manually
defined semantic frames for specific classes,
Hatzivassiloglou et al (2001) use machine learning
techniques to disambiguate names of proteins,
genes and RNAs, while Friedman et al (2001)
describe extraction of specific molecular pathways
from journal articles.
   In our previous work, an integrated knowledge
mining system in the domain of molecular biology,
ATRACT, has been developed (Mima et al
(2001)). ATRACT (Automatic Term Recognition
and Clustering for Terms) is a part of the ongoing
BioPath1 project, and its main aim is to facilitate an
efficient expert-computer interaction during term-
based knowledge acquisition. Term management is
based on integration of automatic term recognition
and automatic term clustering (ATC). ATR is
based on the C/NC-value method (Frantzi et al
                                                          
1 BioPath is a Eureka funded project, coordinated by
LION BioScience (http://www.lionbioscience.com) and
funded by the German Ministry of Research.
(2000)), a hybrid approach combining linguistic
knowledge (term formation patterns) and statistical
knowledge (term length, frequency of occurrence,
etc). The extension of the method handles
orthographic, morphological and syntactic term
variants and acronym recognition as an integral
part of the ATR process (Nenadi? et al (2002a)),
providing that all term occurrences of a term are
considered. The ATC method is based on the
Ushioda?s AMI (Average Mutual Information)
hierarchical clustering method (Ushioda (1996)).
Co-occurrence based term similarities are used as
input, and a dendrogram of terms is generated.2
2   Term Similarity Measures
In this section we introduce a novel hybrid method
to measure term similarity. Our method
incorporates three types of similarity measures,
namely contextual, lexical and syntactical
similarity. We use a linear combination of the three
similarities in order to estimate similarity between
terms. In the following subsections we describe
each of the three similarity measures.
2.1   Contextual Similarity
Determining the similarity of terms based on their
contexts is a standard approach based on the
hypothesis that similar terms tend to appear in
similar contexts. Contextual similarity, however,
may be determined in a number of ways depending
on the way in which the context is defined. For
example, some approaches consider only terms
that appear in a close proximity to each other
(Maynard and Ananiadou (2000)), while in other
approaches, grammatical roles such as object or
subject are taken into account (Grefenstette
(1994)).
   Our approach to contextual similarity is based on
automatic pattern mining. The aim is to
automatically identify and learn the most important
context patterns in which terms appear. Context
pattern (CP) is a generalised regular expression
that corresponds to either left or right context of a
term. 3 The following example shows a sample left
context pattern of the term high affinity:
                                                          
2 For the evaluation of the ATR and ATC methods
incorporated in ATRACT, see Mima et al (2001).
3 Left and right contexts are treated separately.
V:bind TERM:rxr_heterodimers PREP:with
   Let us now describe the process of constructing
CPs and determining their importance. First, we
collect concordances for all automatically
recognised terms. Context constituents, which we
consider important for discriminating terms (e.g.
noun and verb phrases, prepositions, and terms
themselves) are identified by a tagger and by
appropriate local grammars, which define syntactic
phrases (e.g. NPs, VPs). The grammatical and
lexical information attached to the context
constituents is used to construct CPs.  In the
simplest case, contexts are mapped into the
syntactic categories of their constituents. However,
the lemmatised form for each of the syntactic
categories can be used as well. For example, when
encountered in a context, the preposition with can
be either mapped to its POS tag, i.e. PREP, or
instead, the lemma can be added, in which case we
have an instantiated chunk: PREP:with.  Further,
some of the syntactic categories can be removed
from the context patterns, as not all syntactic
categories are equally significant in providing
useful contextual information (Maynard and
Ananiadou (2000)). Such CPs will be regarded as
normalised CPs. In our approach, one can define
which categories to instantiate and which to
remove. In the examples provided later in the
paper (Section 3) we decided to remove the
following categories: adjectives (that are not part
of a term), adverbs, determiners and so-called
linking words (e.g. however, moreover, etc.).
Also, we instantiated terms and either verbs or
prepositions, as these categories are significant for
discriminating terms.
   Once we have normalised CPs, we calculate the
values of a measure called CP-value in order to
estimate the importance of the CPs. CP-value is
defined similarly to the C/NC-value for terms
(Frantzi et al (2000)). It assesses a CP (p)
according to its total frequency (f(p)), its length
(|p|, as the number of constituents) and the
frequency of its occurrence within other CPs (|Tp|,
where Tp is a set of all CPs that contain p):
The CPs whose CP-value is above a chosen
threshold are deemed important. Note that these
patterns are domain-specific and that they are
automatically extracted from a domain specific
corpus. Tables 1 and 2 show samples of significant
left context patterns extracted from a MEDLINE
corpus (MEDLINE (2002)).
CPs CP-value
PREP   NP 272.65
PREP   NP   PREP 186.47
.   .   . .   .   .
PREP  NP   V:stimulate 9.32
V:indicate   NP 5.00
PREP   NP   PREP   V:involve NP 4.64
PREP   TERM:transcriptional_activity 4.47
V:require   NP   PREP 4.38
PREP TERM:nuclear_receptor PREP 4.00
Table 1: Sample of left CPs
(only terms and most frequent verbs are instantiated)
CPs CP-value
PREP:of   NP 121.49
V  NP 71.42
PREP:of   NP   V 62.83
NP   PREP:of   NP 59.72
PREP:in   NP 59.55
NP   PREP:of 43.37
PREP:of   NP  V   NP 37.64
PREP:of  TERM:transcriptional_activity 36.60
Table 2: Sample of left CPs
(only terms and prepositions are instantiated)
   At this point, each term is associated with a set of
the most characteristic patterns in which it occurs.
We treat CPs as term features, and we use a feature
contrast model (Santini and Jain (1999)) to
calculate similarity between terms as a function of
both common and distinctive features. Let us now
formally define the contextual similarity measure.
Let C1 and C2 be two sets of CPs associated with
terms t1 and t2 respectively. Then, the contextual
similarity (CS) between t1 and t2 corresponds to the
ratio between the number of common and
distinctive contexts:
2.2   Lexical Similarity
We also examine the lexical similarity between
words that constitute terms. For example, if terms
share the same head, they are assumed to have the













	


??
?
=

?
; otherwise
nestedis not
)(||
1)(log
);(log
)(
2
2
Tpbp
bfTpfp
ppfp
pCP
|\||\|||2
||2),(
212121
21
21 CCCCCC
CCttCS
++?
?
=
same concept as an (in)direct hypernym (e.g.
progesterone receptor and oestrogen
receptor). Further, if one of such terms has
additional modifiers, this may indicate concept
specialisation (e.g. nuclear receptor and
orphan nuclear receptor). Bearing that in
mind, we base the definition of lexical similarity
on having a common head and/or modifier(s).
Formally, if t1 and t2 are terms, H1 and H2 their
heads, and M1 and M2 the sets of the stems of their
modifiers, then their lexical similarity (LS) is
calculated according to the following formula:
where a and b are weights such that a > b, since we
give higher priority to shared heads over shared
modifiers.
   Note that the lexical similarity between two
different terms can have a positive value only if at
least one of them is a multiword term. Also, when
calculating lexical similarity between terms that
are represented by corresponding acronyms, we
use normalised expanded forms. 4
2.3   Syntactical Similarity
By analysing the distribution of similar terms in
corpora, we observed that some general (i.e.
domain independent) lexico-syntactic patterns
indicate functional similarity between terms. For
instance, the following example:
... steroid receptors such as
estrogen receptor, glucocorticoid
receptor,and progesterone receptor.
suggests that all the terms involved are highly
correlated, since they appear in an enumeration
(represented by the such-as pattern) which
indicates their similarity (based on the is_a
relationship). Some of these patterns have been
previously used to discover hyponym relations
between words (Hearst (1992)). We generalised
                                                          
4 For our approach to acronym acquisition and term
normalisation, see Nenadic et al (2002).
the approach by taking into account patterns in
which the terms are used concurrently within the
same context. We hypothesise that the parallel
usage of terms within the same context, as a
specific type of co-occurrence, shows their
functional similarity. Namely, all the terms within
a parallel structure have the same syntactic
function within the sentence (e.g. object or subject)
and are used in combination with the same verb or
preposition. This fact is used as an indicator of
their semantic similarity.
   In our approach, several types of lexico-
syntactical patterns are considered: enumeration
expressions, coordination, apposition, and
anaphora. However, currently we do not
discriminate between different similarity
relationships among terms (which are represented
by different patterns), but instead, we consider
terms appearing in the same syntactical roles as
highly semantically correlated.
   A sample of enumeration patterns is shown in
Table 3. 5 Manually defined patterns are applied as
syntactic filters in order to retrieve sets of similar
terms. These patterns provide relatively good recall
and precision. We also used coordination patterns
(Klavans et al (1997)) as another type of parallel
syntactic structure. Two types of argument
coordination and two types of head coordination
patterns were considered (see Table 4). However,
not all the sequences that match the coordination
patterns are coordinated structures (see Table 5).
Therefore, these patterns provide relatively good
recall, but not high precision if one wants to
retrieve terms involved in such expression.6
However, both term coordination and (nominal)
conjunction of terms indicate their similarity.
   Based on co-occurrence of terms in these parallel
lexico-syntactical patterns, we define the
syntactical similarity (SS) measure for a pair of
terms as 1 if the two terms appear together in any
of the patterns, and 0 otherwise.
                                                          
5 Non-terminal syntactic categories are given in angle
brackets. Non-terminal <&> denotes a conjunctive word
sequence, i.e. the following regular expression: (as
well as)| (and[/or])|(or[/and]). Special
characters (, ), [, ], |, and * have the usual
interpretation in regular expression notation.
6 In the experiments that we have performed, the
precision of expanding terms from coordinated
structures was 70%.
( +?
+
= ||1),( 21*21 HHabattLS
)|\||\|||2
||2
212121
21* MMMMMM
MMb
++?
?
+
<TERM>([(](such as)|like|(e.g.[,])) <TERM> (,<TERM>)* [[,] <&> <TERM>] [)]
<TERM> (,<TERM>)* [,] <&> other <TERM>
<TERM> [,] (including|especially) <TERM> (,<TERM>)* [[,] <&> <TERM>]
both <TERM> and <TERM>
either <TERM> or <TERM>
neither <TERM> nor <TERM>
Table 3: Sample of enumeration lexico-syntactic patterns
(<N>|<Adj>) (,(<N>|<Adj>))* [,] <&> (<N>|<Adj>) <TERM>
(<N>|<Adj>)/(<N>|<Adj>) <TERM>
(<N>|<Adj>) <TERM> (,<TERM>)* [,] <&> <TERM>
(<N>|<Adj>) <TERM>/<TERM>
Table 4: Sample of coordination patterns
head coordination [adrenal [glands and gonads]]
term conjunction [adrenal glands] and [gonads]
Table 5: Ambiguities of coordinated structures
2.4   Hybrid CLS Similarity
None of the similarities introduced so far is
sufficient on its own to reliably estimate similarity
between two arbitrary terms. For example, if a
term appears infrequently or within very specific
CPs, the number of its significant CPs will
influence its contextual similarity to other terms.
Further, there are concepts that have idiosyncratic
names (e.g. a protein named Bride of
sevenless), which thus cannot be classified
relying exclusively on lexical similarity. Our
experiments also show that syntactical similarity
provides high precision, but low recall when used
on its own, as not all terms appear in a parallel
lexico-syntactical expression.
   Therefore, we introduce a hybrid term similarity
measure, called the CLS similarity, as a linear
combination of the three similarity measures:
CLS(t1, t2) = ? CS(t1, t2) + ? LS(t1, t2) + ? SS(t1, t2)
The choice of the weights ?, ?, and ? in the
previous formula is not a trivial problem. In our
preliminary experiments (Section 3) we used
manually chosen values. However, the parameters
have also been fine-tuned automatically by
supervised learning method based on a genetic
algorithm approach (Spasi? et al (2002)). A
domain specific ontology has been used to evaluate
the generated similarity measures and to set the
direction of their convergence. The differences
between results based on the various parameters
are presented in the following section.
3   Results, Evaluation and Discussion
The CLS measure was tested on a corpus of 2008
abstracts retrieved from MEDLINE database
(MEDLINE (2002)) with manually chosen values
0.3, 0.3 and 0.4 for ?, ?, and ? respectively.
Random samples of results have been evaluated by
a domain expert, and the combined measure
proved to be a good indicator of semantic
similarity. Table 6 shows the similarity of term
retinoic acid receptor to a number of
terms. The examples point out the importance of
combining different types of term similarities. For
instance, the low value of contextual similarity7 for
retinoid X receptor is balanced out by the
other two similarity values, thus correctly
indicating it as a term similar to term retinoic
acid receptor. Similarly, the high value of the
contextual similarity for signal transduction
pathway is neutralised by the other two similarity
                                                          
7 The low value is caused by relatively low frequency of
the term?s occurrences in the corpus.
values, hence preventing it as being labelled as
similar to retinoic acid receptor.
Term CS SS LS CLS
nuclear receptor 0.58 1.00 0.50 0.72
retinoid X receptor 0.32 1.00 0.33 0.60
retinoic acid 0.31 0.00 1.00 0.39
receptor complex 0.52 0.00 0.50 0.31
progesteron receptor 0.35 0.00 0.50 0.25
signal transduction
pathway
0.75 0.00 0.00 0.22
Table 6: Similarity values between retinoic
acid receptor and other terms
   The combined measure also proved to be
consistent in the sense that similar terms share the
same "friends" (Maynard and Ananiadou (2000)).
For example, the similarity values of two similar
terms glucocorticoid receptor and
estrogen receptor (the value of their
similarity is 0.68) with respect to other terms are
mainly approximate (Table 7).
Term glucocotricoid
receptor
estrogen
receptor
steroid receptor 0.66 0.64
progesterone receptor 0.55 0.59
human estrogen
t
0.28 0.37
retinoid x receptor 0.27 0.36
nuclear receptor 0.30 0.33
receptor complex 0.31 0.33
retinoic acid receptor 0.27 0.28
retinoid nuclear
t
0.26 0.26
Table 7: Similarity values for glucocorticoid
receptor and estrogen receptor
  The supervised learning of parameters resulted in
the values 0.13, 0.81 and 0.06 for ?, ?, and ?
respectively (see Spasi? et al (2002)). The
measure with these values showed a higher degree
of stability relative to the ontology-based similarity
measure. Note that the lexical similarity appears to
be the most important and the syntactical similarity
to be insignificant. The ontology used as a seed for
learning term similarities contained well-
structured, standardised and preferred terms which
resulted in promoting the lexical similarity as the
most significant. On the other hand, the SS
similarity is corpus-dependent: the size of the
corpus and the frequency with which the
concurrent lexico-syntactic patterns are realised in
it, affect the syntactical similarity. In the training
corpus such patterns occurred infrequently relative
to the number of terms, which indicates that a
bigger corpus is needed in the training phase. In
order to increase the number of concurrent
patterns, we also aim at including additional
patterns that describe appositions and
implementing procedures for resolution of co-
referring terms. We also plan to experiment with
parametrising the values of syntactical similarity
depending on the number and type of patterns in
which two terms appear simultaneously.
   The main purpose of discovering term
similarities is to produce a similarity matrix to
identify term clusters. In Nenadi? et al (2002b) we
present some preliminary results on term clustering
using the CLS hybrid term similarity measure. Two
different methods (namely the nearest neighbour
and the Ward?s method) have been used, and both
achieved around 70% precision in clustering
semantically similar terms.
Conclusions and Further Research
In this paper we have presented a novel method for
the automatic discovery of term similarities. The
method is based on the combination of contextual,
lexical and syntactical similarities between terms.
Lexical similarity exposes the resemblance
between the words that constitute terms, while
syntactical similarity is based on mutual co-
occurrence in parallel lexico-syntactic patterns.
Contextual similarity is based on the automatic
discovery of significant contexts through
contextual pattern mining.   Although the approach
is domain independent and knowledge-poor,
automatically collected patterns are domain
specific and they identify significant contexts in
which terms tend to appear. However, in order to
learn domain-appropriate term similarity
parameters, we need to customise the method by
incorporating domain-specific knowledge. For
example, we have used an ontology to represent
such knowledge.
   The preliminary results in the domain of
molecular biology have shown that the measure
proves to be a good indicator of semantic similarity
between terms. Furthermore, the similarity
measure is consistent at assigning weights: similar
terms tend to share the same ?friends?, i.e. there is
a significant degree of overlapping between terms
that are similar. These results are encouraging, as
terms are grouped reliably according to their
contextual, syntactical and lexical similarities.
   Besides term clustering (presented in Nenadi? et
al. (2002b)), the similarity measure can be used for
several term-oriented knowledge management
tasks.  Our future work will focus on the term
classification and the consistent population and
update of ontologies. However, specific term
relationship identification that will direct placing
terms in a hierarchy is needed. Further, term
similarities can be used for term sense
disambiguation as well, which is essential for
resolving terminological confusion occurring in
many domains.
Acknowledgement
We would like to thank Dr. Sylvie Albert and Dr.
Dietrich Schuhmann from LION Bioscience for the
evaluation of the results.
References
Ananiadou S. (1994): A Methodology for Automatic
Term Recognition. Proceedings of COLING-94,
Kyoto, Japan.
Bourigault D. (1992): Surface Grammatical Analysis for
the Extraction of Terminological Noun Phrases.
Proceedings of 14th International Conference on
Computational Linguistics, Nantes, France, pp. 977-
981.
Frantzi K.T., Ananiadou S. and Mima H. (2000):
Automatic Recognition of Multi-Word Terms: the C-
value/NC-value method. International Journal on
Digital Libraries, 3/2, pp. 115-130.
Friedman C., Kra P., Yu H., Krauthammer M. and
Rzhetsky A. (2001): GENIES: A Natural Language
Processing System for the Extraction of Molecular
Pathways from Journal Articles. Bioinformatics, 17/1,
pp. S74-S82.
Grefenstette G. (1994): Exploration in Automatic
Thesaurus Discovery. Kluwer Academic Publishers,
Massachusetts, p. 302.
Hatzivassiloglou V., Duboue P. and Rzetsky A. (2001):
Disambiguating Proteins, Genes, and RNA in Text: A
Machine Learning Approach. Bioinformatics, 17/1,
pp. S97-S106
Hearst M.A. (1992): Automatic acquisition of hyponyms
from large text corpora. Proceedings of the 14th
International Conference on Computational
Linguistics, Nantes, France.
Klavans J. L., Tzoukermann E. and Jacquemin C.
(1997): A Natural Language Approach to Multi-Word
Term Conflation. Proceedings of Workshop DELOS,
Zurich, pp. 33-40.
Maynard D. and Ananiadou S. (2000): Identifying
Terms by Their Family and Friends.  Proceedings of
COLING 2000, Luxembourg, pp.530-536.
MEDLINE (2002): National Library of Medicine.
http://www.ncbi.nlm.nih.gov/PubMed/
Mima H., Ananiadou S. and Nenadi? G. (2001):
ATRACT Workbench: An Automatic Term
Recognition and Clustering of Terms. Text, Speech
and Dialogue - TSD 2001, LNAI 2166, Springer-
Verlag, Berlin, pp. 126-133.
Mima H., Ananiadou S., Nenadi? G. and Tsujii J.
(2002): A Methodology for Terminology-based
Knowledge Acquisition and Integration. Proceedings
of COLING 2002, Taiwan
Nakagawa H. and Mori, T. (2000): Nested Collocation
and Compound Noun for Term Recognition.
Proceedings of the First Workshop on Computational
Terminology COMPUTERM 98, pp. 64-70.
Nenadi? G., Spasi? I. and Ananiadou S. (2002a):
Automatic Acronym Acquisition and Term Variation
Management within Domain-specific Texts.
Proceedings of LREC 2002, Las Palmas, Spain, pp.
2155-2162.
Nenadi? G., Spasi? I. and Ananiadou S. (2002b): Term
Clustering using a Corpus-Based Similarity Measure.
Text, Speech and Dialogue - TSD 2002, LNAI series,
Springer-Verlag, Berlin
Santini S. and Jain R. (1999): Similarity Measures.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 21/9, pp. 871-88
Spasi? I., Nenadi? G. and Ananiadou S. (2002):
Supervised Learning of Term Similarities. IDEAL
2002, LNAI series, Springer-Verlag, Berlin
Ushioda A. (1996): Hierarchical Clustering of Words.
Proceedings of COLING ?96, Copenhagen, pp. 1159-
1162.
Using Domain-Specific Verbs for Term Classification 
 
Irena Spasi? 
Computer Science 
University of Salford, UK 
I.Spasic@salford.ac.uk
Goran Nenadi? 
Department of Computing 
UMIST, UK 
G.Nenadic@umist.ac.uk
Sophia Ananiadou 
Computer Science  
University of Salford, UK 
S.Ananiadou@salford.ac.uk
 
Abstract 
In this paper we present an approach to 
term classification based on verb com-
plementation patterns. The complementa-
tion patterns have been automatically 
learnt by combining information found in 
a corpus and an ontology, both belonging 
to the biomedical domain. The learning 
process is unsupervised and has been im-
plemented as an iterative reasoning pro-
cedure based on a partial order relation 
induced by the domain-specific ontology. 
First, term recognition was performed by 
both looking up the dictionary of terms 
listed in the ontology and applying the 
C/NC-value method. Subsequently, do-
main-specific verbs were automatically 
identified in the corpus. Finally, the 
classes of terms typically selected as ar-
guments for the considered verbs were in-
duced from the corpus and the ontology. 
This information was used to classify 
newly recognised terms. The precision of 
the classification method reached 64%. 
1 Introduction 
Basic notions used when describing a specific 
problem domain are concepts, classes and attrib-
utes (or features). The identification of concepts, 
linguistically represented by domain-specific terms 
(Maynard and Ananiadou, 2000), is a basic step in 
the automated acquisition of knowledge from tex-
tual documents. Textual documents describing new 
knowledge in an intensively expanding domain are 
swamped by new terms representing newly identi-
fied or created concepts. Dynamic domains, such 
as biomedicine, cannot be represented by static 
models, since new discoveries give rise to the ap-
pearance of new terms. This makes the automatic 
term recognition (ATR) tools essential assets for 
efficient knowledge acquisition.  
However, ATR itself is not sufficient when it 
comes to organizing newly acquired knowledge. 
Concepts are natively assorted into groups and a 
well-formed model of a domain, represented 
through terms and their relations, needs to reflect 
this property consistently. Dynamic domain mod-
els should be able to adapt to the advent of new 
terms representing newly discovered or identified 
concepts. In other words, newly extracted terms 
need to be incorporated into an existing model by 
associating them with one another and with already 
established terms preferably in an automated man-
ner. This goal may be achieved by relying on term 
clustering (the process of linking semantically 
similar terms together) and term classification (the 
process of assigning terms to classes from a pre-
defined classification scheme). In particular, classi-
fication results can be used for efficient and consis-
tent term management through populating and 
updating existing ontologies in expanding domains 
such as biomedicine. In this paper, we compare 
some of the term classification approaches and in-
troduce another approach to this problem.  
The paper is organised as follows. In Section 2 
we provide a brief overview of the existing term 
classification approaches and suggest the main idea 
of our approach to this problem. Section 3 de-
scribes the learning phase of our classification 
method. Further, Section 4 provides details on the 
classification algorithm. Finally, in Section 5 we 
describe the evaluation strategy and provide the 
results, after which we conclude the paper. 
2 Term Classification Approaches 
Similarly to general classification algorithms, the 
existing term classification approaches typically 
rely on learning techniques. These techniques are 
most often statistically based (e.g. hidden Markov 
models, naive Bayesian learning, etc.). Other tech-
niques include decision trees, inductive rule learn-
ing, support-vector machines (SVMs), etc. We, on 
the other hand, suggest the use of a genetic algo-
rithm as a learning engine for the classification 
task. Let us now discuss some approaches to the 
automatic classification of biomedical terms. 
Nobata et al (2000) implemented a statistical 
method for term classification. In their approach, 
each class was represented by a list of (single) 
words. The first step was to estimate the condi-
tional probability P(c | w) of each word w being 
assigned to a specific class c, based on the assump-
tion that each word occurrence is independent of 
its context and position in the text. Further, yet an-
other strong restriction was made by assuming that 
there was one-to-one correspondence between 
terms and their classes. In addition, this approach 
is not applicable to ?unknown? terms, i.e. terms 
containing words for which no classification prob-
abilities had been determined. A special class, re-
ferring to ?other?, was introduced to cover such 
words. Bearing in mind the increasing number of 
new terms, such an approach is bound to produce 
skewed results, where many of the terms would 
simply be classified as ?other?. 
While Nobata et al (2000) statistically proc-
essed the information found inside the terms, Col-
lier et al (2001) applied statistical techniques to 
the information found outside the terms. A hidden 
Markov model based on n-grams (assuming that a 
term?s class may be induced from the previous n-1 
lexical items and their classes) was used as a theo-
retical basis for their classification method. The 
method relied on the orthographic features includ-
ing numerals, capital and Greek letters, special 
characters (such as `-`, `/`, `+`, etc.), parenthesis, 
etc. In the biomedical domain, such features often 
provide hints regarding the class of a specific term. 
Each unclassified term was assigned a class of the 
most similar (with respect to the orthographic fea-
tures) term from the training set. This approach 
encountered the minority class prediction problem. 
Namely, the best classification results in terms of 
recall and precision were achieved for the most 
frequent class of terms in their training corpus, 
while the worst results were those achieved for the 
least frequent class. 
Hatzivassiloglou et al (2001) proposed a 
method for unsupervised learning of weights for 
context elements (including words as context con-
stituents and the corresponding positional and 
morphological information) of known terms and 
using these weights for term classification. Three 
well-known learning techniques were used: naive 
Bayesian learning, decision trees, and inductive 
rule learning. Simplified classification experiments 
in which a classification algorithm was choosing 
between two or three options respectively were 
conducted. The precision of binary classification 
was around 76% for all three learning algorithms, 
and the precision dropped to approximately 67% 
when choosing between three options. If the pro-
posed techniques were to be applied for general 
classification where the number of options is arbi-
trary, the precision is expected to decrease even 
further. 
Nenadic et al (2003b) conducted a series of 
large-scale experiments with different types of fea-
tures for a multi-class SVM. These features in-
cluded document identifiers, single words, their 
lemmas and stems, and automatically recognised 
terms. The results indicated that the performance 
was approximately the same (around 60% in the 
best case) when using single words, lemmas or 
stems. On the other side, terms proved to be better 
(more than 90% precision) than single words at 
lower recall points (less than 10%), which means 
that terms as features can improve the precision for 
minority classes. The best results were achieved 
with document identifiers, but such features cannot 
be used on the fly in new documents.  
Spasic et al (2002) used a genetic algorithm 
(GA) based on a specific crossover operator to ex-
plore the relationships between verbs and the terms 
complementing them. The GA performed reason-
ing about term classes allowed to be combined 
with specific verbs by using an existing ontology 
as a seed for learning. In this paper, we use the re-
sults of the proposed methodology as a platform 
for term classification. In the following section we 
briefly overview the method for the acquisition of 
verb complementation patterns. 
3 Verb Complementation Patterns 
By looking at the context of an isolated verb occur-
rence it is difficult to predict all term classes that 
can be combined with the given verb. On the other 
hand, the whole ?population? of terms comple-
menting a specific verb is likely to provide a cer-
tain conclusion about that verb with respect to its 
complementation patterns. This was a primary mo-
tivation for Spasic et al (2002) to use a GA as it 
operates on a population of individuals as opposed 
to a single individual. This fact also makes the ap-
proach robust, since it does not rely on every spe-
cific instance of verb-term combination to be 
correctly recognised.  
As not all verbs are equally important for the 
term classification task, we are primarily interested 
in domain-specific verb complementation patterns. 
In our approach, a complementation pattern of a 
domain-specific verb is defined as a disjunction of 
terms and/or their classes that are used in combina-
tion with the given verb. The automatic acquisition 
of these patterns is performed in the following 
steps: term recognition, domain-specific verb ex-
traction, and the learning of complementation pat-
terns. Let us describe each of these steps in more 
detail. 
 
3.1   Term Recognition 
 
First, a corpus is terminologically processed: both 
terms present in the ontology and the terms recog-
nised automatically are tagged. Terms already 
classified in the ontology are used to learn the 
classes allowed by the domain-specific verbs, 
while the new terms are yet to be classified based 
on the learnt classes. New terms are recognized by 
the C/NC-value method (Frantzi et al, 2000), 
which extracts multi-word terms. This method rec-
ognises terms by combining linguistic knowledge 
and statistical analysis. Linguistic knowledge is 
used to propose term candidates through general 
term formation patterns. Each term candidate t is 
then quantified by its termhood C-value(t) calcu-
lated as a combination of its numerical characteris-
tics: length |t| as the number of words, absolute 
frequency f(t) and two types of frequency relative 
to the set S(t) of candidate terms containing a 
nested candidate term t (frequency of occurrence 
nested inside other candidate terms and the number 
of different term candidates containing a nested 
candidate term): 
 
??
??
?
????
?=?
=? ?
?
)( if  ,))(|)(|
1)((||ln
)( if  ),(||ln
)(
)(
tSsftStft
tStft
tvalueC
tSs
 
 
Obviously, the higher the frequency of a candi-
date term the greater its termhood. The same holds 
for its length. On the other side, the more fre-
quently the candidate term is nested in other term 
candidates, the more its termhood is reduced. 
However, this reduction decreases with the in-
crease in the number of different host candidate 
terms as it is hypothesised that the candidate term 
is more independent if the set of its host terms is 
more versatile. 
Term distribution in top-ranked candidate terms 
is further improved by taking into account their 
context. The relevant context words, including 
nouns, verbs and adjectives, are extracted and as-
signed weights based on how frequently they co-
occur with top-ranked term candidates. Subse-
quently, context factors are assigned to candidate 
terms according to their co-occurrence with top-
ranked context words. Finally, new termhood esti-
mations (NC-values) are calculated as a linear 
combination of the C-values and context factors.  
Nenadic et al (2003a) modified the C/NC-value 
to recognise acronyms as a special type of single-
word terms, and, thus, enhanced the recall of the 
method. On the other hand, the modified version 
incorporates the unification of term variants into 
the linguistic part of the method, which also im-
proved the precision, since the statistical analysis is 
more reliable when performed over classes of 
equivalent term variants instead of separate terms. 
 
3.2   Domain-Specific Verb Recognition 
 
Verbs are extracted from the corpus and ranked 
based on the frequency of occurrence and the fre-
quency of their co-occurrence with terms. A stop 
list of general verbs frequently mentioned in scien-
tific papers independently of the domain (e.g. ob-
serve, explain, etc.) was used to filter out such 
verbs. The top ranked verbs are selected and 
considered to be domain-specific. Moreover, these 
verbs are also corpus-specific (e.g. activate, 
bind, etc.). Table 3 provides a list of such verbs, 
which were used in the experiments. 
 
3.3   Complementation Pattern Learning 
 
In order to learn a verb complementation pattern 
for each of the selected verbs separately, terms are 
collected from the corpus by using these verbs as 
anchors. A GA has been implemented as an itera-
tive reasoning procedure based on a partial order 
relation induced by the domain-specific ontology.1 
In each iteration pairs of verb complementation 
patterns represented as sets of terms and term 
classes are merged. This operation involves the 
substitution of less general terms/classes by their 
more general counterparts, if there is a path in the 
ontology connecting them. Otherwise, the disjunc-
tion of the terms is formed and passed to the next 
iteration. Figure 1 depicts the process of learning a 
verb complementation pattern. 
Since the partial order relation induced by the 
ontology is transitive, the order in which terms are 
processed is of no importance. The final verb com-
plementation patterns are minimal in the sense that 
the number of terms in a verb complementation 
pattern and the depth of each individual term in the 
ontology are minimised. 
 
 
Figure 1. Learning the complementation pattern 
                    for the verb bind 
4 Term Classification Method 
The verb complementation patterns have been ob-
tained by running the GA on a set of terms some of 
which were present in an ontology, which is used 
                                                           
1 The partial order relation is based on the hierarchy of 
terms/classes: term/class t1 is in relation with t2, if there is a 
path in the ontology from t2 to t1. In that case, we say that t2  is 
more general than t1. 
during the learning process. The newly recognised 
terms (i.e. the ones not found in the ontology) will 
remain included in the final verb complementation 
patterns as non-classified terms, since at this point 
it is not known which classes could replace them. 
All elements of the final verb complementation 
patterns can be thus divided into two groups based 
on the criterion of their (non)existence in the on-
tology. The elements already present in the ontol-
ogy are candidate classes for the newly recognised 
terms. Let us now describe the classification 
method in more detail. 
Let V = {v1, v2, ... , vn} be a set of automatically 
identified domain-specific verbs. During the phase 
of learning verb complementation patterns, each of 
these verbs is associated with a set of classes and 
terms it co-occurs with. Let Ci = {ci,1, ci,2, ... , ci,mi} 
denote a set of classes assigned automatically to 
the verb vi (1 ? i ? n) by a learning algorithm based 
on the information found in the corpus and the 
training ontology. As indicated earlier, we define 
such set to be a verb complementation pattern for 
the given verb.  
 
4.1   Statistical Analysis 
 
As we planned to use verb complementation pat-
terns for term classification, we modified the origi-
nal learning algorithm (Spasic et al, 2002) by 
attaching the frequency information to terms and 
their classes. When substituting a less general class 
by its more general counterpart, 2  the frequency 
information is updated by summing the two 
respective frequencies of occurrence. In the final 
verb complementation pattern, each class ci,j has 
the frequency feature fi,j, which aggregates the fre-
quency of co-occurrence with vi (1 ? i ? n; 1 ? j ?  
mi) for the given class and its subclasses. The fre-
quency information is used to estimate the class 
probabilities given a verb, P(ci,j | vi): 
 
?
=
=
lm
l
li
ji
ji
f
fp
1
,
,
,  
                                                           
2 The ontology used for learning allowed multiple inheritance 
only at the leaf level, that way incurring no ambiguities when 
substituting subclass by its superclass. The multiple inheri-
tance at the leaf level was resolved by mapping each term to 
all its classes, which were then processed by a GA. 
Unclassified terms remain present in the final 
verb complementation patterns, and, like classes, 
they are also assigned the information on the fre-
quency of co-occurrence with the given verb. 
When classifying a specific term, this information 
is used to select the verb based on whose pattern 
the term will be classified. Precisely, the verb the 
given term most frequently co-occurs with is cho-
sen, as it is believed to be the most indicative one 
for the classification purpose. 
 
4.2   Term Similarity Measure 
 
A complementation pattern associated with the 
chosen verb typically contain several classes. In 
order to link the newly recognised terms to specific 
candidate classes, we used a hybrid term similarity 
measure, called the CLS similarity measure. It 
combines contextual, lexical and syntactic proper-
ties of terms in order to estimate their similarity 
(Nenadic et al, 2002).  
Lexical properties used in the CLS measure re-
fer to constituents shared by the compared terms. 
The rationale behind the lexical term similarity 
involves the following hypotheses: (1) Terms shar-
ing a head are likely to be hyponyms of the same 
term (e.g. progesterone receptor and oes-
trogen receptor). (2) A term derived by modi-
fying another term is likely to be its hyponym (e.g. 
nuclear receptor and orphan nuclear re-
ceptor). Counting the number of common con-
stituents is a simple and straightforward approach 
to measuring term similarity, but it falls short when 
it comes to single-word terms and those introduced 
in an ad-hoc manner. Thus, properties other than 
lexical need to be included.  
We use syntactic properties in the form of spe-
cific lexico-syntactical patterns indicating parallel 
usage of terms (e.g. both Term and Term). All 
terms used within a parallel structure have identi-
cal syntactic features and are used in combination 
with the same verb, preposition, etc., and, hence, 
can be regarded as similar with high precision. 
However, patterns used as syntactic properties of 
terms have relatively low frequency of occurrence 
compared to the total number of terms, and in or-
der to have a good recall, a large-size corpus is 
needed. In order to remedy for small-size corpora, 
other contextual features are exploited.  
Context patterns (CPs) in which terms appear 
are used as additional features for term compari-
son. CPs consist of the syntactic categories and 
other grammatical and lexical information (e.g. 
PREP NP V:stimulate). They are ranked ac-
cording to a measure called CP-value  (analogue to 
C-value for ATR). The ones whose CP-value is 
above a chosen threshold are deemed significant 
and are used to compare terms. Each term is asso-
ciated with a set of its CPs, and contextual similar-
ity between terms is then measured by comparing 
the corresponding sets. Automatically collected 
CPs are indeed domain-specific, but the method for 
their extraction is domain independent. 
 
4.3   Term-Class Similarity 
 
The CLS similarity measure applies to pairs of 
terms. However, in case of multiple choices pro-
vided by the verb complementation patterns, we 
need to compare terms to classes. In order to do so, 
we use the similarity between the given term and 
the terms belonging to the classes. The selection of 
terms to be compared is another issue. One possi-
bility is to use the full or random set of terms (be-
longing to the given class) that occur in the corpus. 
Alternatively, some ontologies provide a set of 
prototypical instances for each class, which can be 
used for comparison of terms and classes.3 More 
formally, if c is a class, e1, e2,..., ek are terms repre-
senting the class, and t is a term, then the similarity 
between the term t and the class c is calculated in 
the following way: 
?
=
?
=
k
j
j
i
ki
etCLS
etCLSctEx
1
2
},...,1{
),(
),(max),(  
 
This example-based similarity measure maxi-
mises the value of the CLS measure between the 
term and the instances representing the class. In 
addition, the values of the CLS measure are 
mapped into the interval (0,1) by performing vec-
tor normalisation in order to make them compara-
ble to the class probability estimations.  
 
4.4   Term Classification 
 
Finally, given the term t and the verb vi it most  
frequently co-occurs with, a score is calculated for 
                                                           
3 For example, in the UMLS ontology each class is assigned a 
number of its prototypical examples represented by terms. 
each class ci,j from the set Ci according to the fol-
lowing formula: 
 
),()1(),( ,,, jijiji ctExapactC ??+?=    (1) 
 
where a (0 ? a ? 1) is a parameter, which balances 
the impact of the class probabilities and the simi-
larity measure.4 A class with the highest C(t, ci,j) 
score is used to classify the term t. Alternatively, 
multiple classes may be suggested by setting a 
threshold for C(t, ci,j). 
At this point, let us reiterate that the final verb 
complementation patterns are minimal in the sense 
that the number of terms in a verb complementa-
tion pattern and the depth of each individual term 
in the ontology are minimised. The latter condition 
may cause the classification to be crude, that is ? 
new terms will be assigned to classes close to the 
root of the ontology. For more fine-grained classi-
fication results, the classes placed close to the root 
of the ontology should be either removed from the 
initial verb complementation patterns, thus being 
unable to override the classes found lower in the 
hierarchy or in other way prevented from substitut-
ing less general terms. The depth up to which the 
terms are to be blocked may be empirically deter-
mined. 
5 Experiments and Evaluation 
5.1   Resources 
 
The resources used for the experiments include an 
ontology and a corpus, both belonging to the do-
main of biomedicine. We used an ontology, which 
is a part of the UMLS (Unified Medical Language 
System) knowledge sources (UMLS, 2002). 
UMLS integrates biomedical information from a 
variety of sources and is regularly updated. 
Knowledge sources maintained under the UMLS 
project include: METATHESAURUS linking term 
variants referring to the same concepts; 
SPECIALIST LEXICON providing syntactic informa-
tion for terms, their component words, and general 
                                                           
4 Note that when a = 0, the classification method resembles 
the nearest neighbour classification method, where the exam-
ples are used as a training set. On the other hand, when a = 1, 
the method is similar to naive Bayesian learning. However, in 
both cases the method represents a modification of the men-
tioned approaches, as the classes used in formula (1) are not 
all classes, but the ones learned by the GA. 
English words; and SEMANTIC NETWORK contain-
ing information about the classes to which all 
METATHESAURUS concepts have been assigned. 
The knowledge sources used in our term classi-
fication experiments include METATHESAURUS 
and SEMANTIC NETWORK. As the number of terms 
in  METATHESAURUS was too large (2.10 million 
terms) and the classification scheme too broad 
(135 classes) for the preliminary experiments, we 
made a decision to focus only on terms belonging 
to a subtree of the global hierarchy of the 
SEMANTIC NETWORK. The root of this subtree re-
fers to substances, and it contains 28 classes. 
The corpus used in conjunction with the above 
ontology consisted of 2082 abstracts on nuclear 
receptors retrieved from the MEDLINE database 
(MEDLINE, 2003). The majority of terms found in 
the corpus were related to nuclear receptors and 
other types of biological substances, as well as the 
domain-specific verbs extracted automatically 
from the corpus in the way described in Section 3.  
 
5.2   Evaluation Framework 
 
When retrieving terms found in the context of do-
main-specific verbs (see Section 3 for details) both 
terms found in the ontology and terms recognised 
on the fly by the C/NC-value method should be 
extracted. However, for the purpose of evaluation, 
only terms classified in the ontology were used. In 
that case, it was possible to automatically verify 
whether such terms were correctly classified by 
comparing the classes suggested by the classifica-
tion method to the original classification informa-
tion found in the ontology. 
During the phase of retrieving the verb-term 
combinations, some of the terms were singled out 
for testing. Namely, for each verb, 10% of the re-
trieved terms were randomly selected for testing, 
and the union of all such terms formed a testing set 
(138 terms) for the classification task. The remain-
ing terms constituted a training set (1618 terms) 
and were used for the learning of complementation 
patterns.  
 
5.3   Results 
 
Based on the training set, domain-specific verbs 
were associated with the complementation patterns 
given (see Table 1 for examples). Then, each term 
from the training set was associated with the verb 
it most frequently co-occurred with. The comple-
mentation pattern learnt for that verb was used to 
classify the term in question.  
 
Verb Complementation pattern 
activate
bind
Immunologic Factor 
Receptor   
Enzyme 
Hormone 
Organic Chemical 
Hazardous or Poisonous Substance 
Pharmacologic Substance 
Table 1. Learnt verb complementation patterns 
 
Since the UMLS ontology contains a number of 
prototypical examples for each class, we have used 
these class representatives to compare unclassified 
terms to their potential classes as indicated in Sec-
tion 4. Table 2 shows the results for some of the 
terms from the testing set and compares them to 
the correct classifications obtained from the ontol-
ogy. 
  
Term Suggested 
class 
Correct classes 
4 hydroxy-
tamoxifen
Organic   
   chemical Organic chemical 
benzoic
acid
Organic  
   chemical 
Organic chemical 
Pharmacologic      
   substance 
testoster-
one
Pharmacologic 
   substance 
Steroid  
Pharmacologic 
   substance 
Hormone 
Table 2. Examples of the classification results 
 
Note that in UMLS one term can be assigned to 
multiple classes. We regarded a testing term to be 
correctly classified if the automatically suggested 
class was among these classes. Table 3 provides 
information on the performance of the classifica-
tion method for each of the considered verbs sepa-
rately and for the combined approach in which the 
verb most frequently co-occurring with a given 
term was used for its classification. The combined 
approach provided considerably higher recall 
(around 50%) and a slight improvement in preci-
sion (around 64%) compared to average values 
obtained with the same method for each of the 
verbs separately. The classification precision did 
not tend to very considerably, and was not affected 
by the recall values. The recall could be improved 
by taking into account more domain-specific verbs, 
while the improvement of precision depends on 
proper tuning of: (1) the module for learning the 
verb complementation patterns, and (2) the similar-
ity measure used for the classification. Another 
possibility is to generalize the classification 
method by relying on domain-specific lexico-
syntactic patterns instead of verbs. Such patterns 
would have higher discriminative power than verbs 
alone. Moreover, they could be acquired automati-
cally. For instance, the CP-value method can be 
used for their extraction from a corpus (Nenadic et 
al., 2003a). 
 
Verb Recall Precision F-measure 
activate 19.28 66.59 29.90 
bind 29.30 66.53 40.68 
compete   3.58 63.16   6.78 
conserve   2.41 61.82   4.64 
inhibit 16.62 62.81 26.28 
interact 13.16 64.31 21.85 
mediate 11.68 62.75 19.69 
modulate 10.44 64.13 17.96 
repress   6.18 62.91 11.25 
stimulate   9.39 63.25 16.35 
Average: 12.20 63.83 20.48 
Combined: 49.88 64.18 56.13 
Table 3. The performance of the classification  
                  method 
 
The values for precision and recall provided in 
Table 3 refer to the classification method itself. If 
it were to be used for the automatic ontology up-
date, then the success rate of such update would 
also depend on the performance of the term recog-
nition method, as the classification module would 
operate on its output. We used the C/NC-value 
method for ATR; still any other method may be 
used for this purpose. We have chosen the C/NC-
value method because it is constantly improving 
and is currently performing around 72% recall and 
98% precision (Nenadic et al, 2002). 
6 Conclusion 
Efficient update of the existing knowledge re-
positories in many rapidly expanding domains is a 
burning issue. Due to an enormous number of 
terms and the complex structure of the terminol-
ogy, manual update approaches are prone to be 
both inefficient and inconsistent. Thus, it has be-
come absolutely essential to implement efficient 
and reliable term recognition and term classifica-
tion methods as means of maintaining the knowl-
edge repositories. In this paper, we have suggested 
a domain independent classification method as a 
way of incorporating automatically recognised 
terms into an existing ontology. For the prelimi-
nary experiments, we used the UMLS ontology in 
the domain of biomedicine, but the method can be 
easily adapted to use other ontologies in any other 
domain.  
The classification method makes use of the 
contextual information. Not all word types found 
in the context are of equal importance in the 
process of reasoning about the terms: the most in-
formative are verbs, noun phrases (especially 
terms) and adjectives. The presented term 
classification approach revolves around domain-
specific verbs. These verbs are used to collect 
unclassified terms and to suggest their potential 
classes based on the automatically learnt verb 
complementation patterns.  
Note that not every term appearing in a corpus 
is guaranteed to be classified by the proposed clas-
sification method due to the fact that a term need 
not occur as a complement of a domain-specific 
verb. Still, for a large number of terms the classifi-
cation method is expected to obtain the classifica-
tion information, as it is highly probable (though 
not certain) for a term to occur in a context of a 
domain-specific verb. The main goal of the method 
is to provide aid for the automatic ontology update 
by populating newly recognised terms into an ex-
isting ontology, rather than classifying arbitrary 
term occurrences in the corpus.  
The presented classification method can be eas-
ily modified to use lexical classes other than verbs 
as a criterion for classification. Even more, it can 
be further generalised to use a combination of lexi-
cal classes, which can be specified as a set of 
lexico-syntactic patterns. Further experiments with 
the generalisation of the classification method by 
basing it on a set of domain-specific lexico-
syntactic patterns instead of domain-specific verbs 
are expected to demonstrate better performance in 
terms of recall and precision. These facts suggest 
that our classification approach, in combination 
with the C/NC-value method, could be reliably 
used as a (semi)automatic ontology maintenance 
procedure.  
References 
Nigel Collier, Chikashi Nobata and Junichi Tsujii. 2001. 
Automatic Acquisition and Classification of Termi-
nology Using a Tagged Corpus in the Molecular Bi-
ology Domain. Journal of Terminology, John 
Benjamins. 
Katerina Frantzi, Sophia Ananiadou and Hideki Mima. 
2000. Automatic Recognition of Multi-Word Terms: 
the C-value/NC-value Method. International Journal 
on Digital Libraries 3(2):115-130. 
Vasileios Hatzivassiloglou, Pablo Duboue and Andrey 
Rzhetsky. 2001. Disambiguating Proteins, Genes, 
and RNA in Text: A Machine Learning Approach. 
Bioinformatics, 1(1):1-10. 
Diana Maynard and Sophia Ananiadou. 2000. Identify-
ing Terms by their Family and Friends. Proceedings 
of COLING 2000, Saarbrucken, Germany, 530-536.  
MEDLINE. 2003. National Library of Medicine. Avail-
able at: http://www.ncbi.nlm.nih.gov/PubMed/ 
Goran Nenadic, Irena Spasic and Sophia Ananiadou. 
2002. Automatic Acronym Acquisition and Term 
Variation Management within Domain-Specific 
Texts. Proceedings of LREC-3, Las Palmas, Spain, 
2155-2162.  
Goran Nenadic, Irena Spasic and Sophia Ananiadou. 
2003a. Automatic Discovery of Term Similarities Us-
ing Pattern Mining. To appear in Terminology. 
Goran Nenadic, Simon Rice, Irena Spasic, Sophia 
Ananiadou and Benjamin Stapley. 2003b. Selecting 
Features for Text-Based Classification: from Docu-
ments to Terms. Proceedings of ACL Workshop on 
Natural Language Processing in Biomedicine, 
Sapporo, Japan. 
Chikashi Nobata, Nigel Collier and Junichi Tsujii. 2000. 
Automatic Term Identification and Classification in 
Biology Texts. Proceedings of the Natural Language 
Pacific Rim Symposium (NLPRS?2000), 369-375. 
Irena Spasic, Goran Nenadic and Sophia Ananiadou. 
2002. Tuning Context Features with Genetic Algo-
rithms. Proceedings of 3rd International Conference 
on Language,  Resources and Evaluation, Las Pal-
mas, Spain, 2048-2054. 
UMLS. 2002. UMLS Knowledge Sources. National 
Library of Medicine, 13th edition.  
 
Selecting Text Features for Gene Name Classification:  
from Documents to Terms 
 
Goran Nenadi?1,2, Simon Rice2, Irena Spasi?3, Sophia Ananiadou3, Benjamin Stapley2 
 
1Dept. of Computation 
UMIST 
Manchester, M60 1QD 
 
2Dept. of BioMolecular Sciences 
UMIST 
Manchester, M60 1QD 
 
3Computer Science 
University of Salford 
Salford, M5 4WT 
Abstract 
In this paper we discuss the performance 
of a text-based classification approach by 
comparing different types of features. We 
consider the automatic classification of 
gene names from the molecular biology 
literature, by using a support-vector ma-
chine method. Classification features 
range from words, lemmas and stems, to 
automatically extracted terms. Also, sim-
ple co-occurrences of genes within docu-
ments are considered. The preliminary 
experiments performed on a set of 3,000 
S. cerevisiae gene names and 53,000 
Medline abstracts have shown that using 
domain-specific terms can improve the 
performance compared to the standard 
bag-of-words approach, in particular for 
genes classified with higher confidence, 
and for under-represented classes.  
1 Introduction 
Dynamic development and new discoveries in the 
domain of biomedicine have resulted in the huge 
volume of the domain literature, which is con-
stantly expanding both in the size and thematic 
coverage (Blaschke et al, 2002). The literature, 
which is still the most relevant and the most useful 
knowledge source, is swamped by newly coined 
terms and relationships representing and linking 
newly identified or created compounds, genes, 
drugs, reactions, etc., which makes the existing 
terminological resources rarely up-to-date. There-
fore, domain knowledge sources need to frequently 
adapt to the advent of such terms by assorting them 
into appropriate classes, in order to allow biolo-
gists to rapidly acquire, analyse and visualise enti-
ties or group of entities (Stapley et al, 2002).  
Naming conventions solely cannot be used as 
reliable classification criteria, since they typically 
do not systematically reflect any particular func-
tional property or relatedness between biological 
entities. On the other hand, it has proved surpris-
ingly difficult to automatically predict classes for 
some types of biological entities based solely on 
experimental data (e.g. the prediction of protein 
cellular locations from sequences (Eisenhaber and 
Bork, 1998) or the amino acid composition of pro-
teins (Nishikawa and Ooi, 1982)).  
In order to overcome this problem, several lit-
erature-based classification methods have been 
developed (Collier et al 2001; Hatzivassiloglou et 
al., 2001). Classification methods typically rely on 
supervised machine learning techniques that ex-
amine the wider context in which terms are used. 
For example, Raychaudhuri et al (2002) used 
document-based word counts and naive Bayesian 
classification, maximum entropy modelling and 
nearest-neighbour classification to assign the GO 
ontology codes to a set of genes. Recently, sup-
port-vector machines (SVMs, (Vapnik, 1995)) 
have been widely used as fast, effective and reli-
able means for text-based classification, both for 
document classification (Joachims, 1998) and clas-
sification of specific named entities (Stapley et al, 
2002; Kazama et al, 2002). 
Regardless of the learning approach and target 
entities (documents or terms), different types of 
text features have been employed for the classifica-
tion task. For example, a bag-of-words approach 
was used by Stapley et al (2002) to classify pro-
teins, while Collier et al (2001) used orthographic 
features to classify different biological entities. On 
the other hand, Hatzivassiloglou et al (2001) ex-
perimented with morphological, distributional and 
shallow-syntactic information to discriminate be-
tween proteins, genes and RNAs.  
In this paper we analyse the impact of different 
types of features on the performance of an SVM-
based classifier. More precisely, we discuss the 
multi-class SVM performance with respect to the 
type of features used, ranging from document iden-
tifiers, through words, lemmas and stems, to auto-
matically extracted terms.   
The paper is organised as follows. After pre-
senting the related work on feature selection in 
Section 2, the methods used for engineering fea-
tures in our approach are explained in Section 3. 
Section 4 discusses the experiments and results. 
2 Related work 
An SVM is a binary classification method that 
combines statistical learning and optimisation tech-
niques with kernel mapping (Vapnik, 1995). The 
main idea of the method is to automatically learn a 
separation hyperplane from a set of training 
examples, which splits classified entities into two 
subsets according to a certain classification prop-
erty. The optimisation part is used to maximise the 
distance (called the margin) of each of the two 
subsets from the hyperplane.     
The SVM approach has been used for different 
classification tasks quite successfully, in particular 
for document classification, where the method out-
performed many alternative approaches (Joachims, 
1998). Similarly, SVMs have been used for term 
classification. For example, a bag-of-simple-words 
approach with idf-like weights was used to learn a 
multi-class SVM classifier for protein cellular lo-
cation classification (Stapley et al, 2002). Proteins 
were represented by feature vectors consisting of 
simple words co-occurring with them in a set of 
relevant Medline abstracts. The precision of the 
method was better than that of a classification 
method based on experimental data, and similar to 
a rule-based classifier.  
Unlike many other classification methods that 
have difficulties coping with huge dimensions, one 
of the main advantages of the SVM approach is 
that its performance does not depend on the dimen-
sionality of the space where the hyperplane separa-
tion takes place. This fact has been exploited in the 
way that many authors have suggested that ?there 
are few irrelevant features? and that ?SVMs elimi-
nate the need for feature selection? (Joachims, 
1998). It has been shown that even the removal of 
stop-words is not necessary (Leopold and Kinder-
mann, 2002). 
Few approaches have been undertaken only re-
cently to tune the original SVM approach by se-
lecting different features, or by using different 
feature weights and kernels, mostly for the docu-
ment classification task. For example, Leopold and 
Kindermann (2002) have discussed the impact of 
different feature weights on the performance of 
SVMs in the case of document classification in 
English and German. They have reported that an 
entropy-like weight was generally performing bet-
ter than idf, in particular for larger documents. 
Also, they suggested that, if using single words as 
features, the lemmatisation was not necessary, as it 
had no significant impact on the performance.   
Lodhi et al (2002) have experimented with dif-
ferent kernels for document classification. They 
have shown that a string kernel (which generates 
all sub-sequences of a certain number of charac-
ters) could be an effective alternative to linear ker-
nel SVMs, in particular in the sense of efficiency.  
In the case of term classification, Kazama et al 
(2002) used a more exhaustive feature set contain-
ing lexical information, POS tags, affixes and their 
combinations in order to recognise and classify 
terms into a set of general biological classes used 
within the GENIA project (GENIA, 2003). They 
investigated the influence of these features on the 
performance. For example, they claimed that suffix 
information was helpful, while POS and prefix 
features did not have clear or stable influence.  
While each of these studies used some kind of 
orthographical and/or lexical indicators to generate 
relevant features, we wanted to investigate the us-
age of semantic indicators (such as domain-
specific terms) as classification features, and to 
compare their performance with the classic lexi-
cally-based features. 
3 Feature selection and engineering 
The main aim while selecting classification fea-
tures is to find (and use) textual attributes that can 
improve the classification accuracy and accelerate 
the learning phase. In our experiments we exam-
ined the impact of different types of features on the 
performance of an SVM-based gene name classifi-
cation task. The main objective was to investigate 
whether additional linguistic pre-processing of 
documents could improve the SVM results, and, in 
particular, whether semantic processing (such as 
terminological analysis) was beneficial for the 
classification task. In other words, we wanted to 
see which textual units should be generated as in-
put feature vectors, and what level of pre-
processing was appropriate in order to produce 
more accurate predictions. 
We have experimented with two types of tex-
tual features: in the first case, we have used a clas-
sic bag-of-single-words approach, with different 
levels of lexical pre-processing (i.e. single words, 
lemmas, and stems). In the second case, features 
related to semantic pre-processing of documents 
have been generated: a set of automatically ex-
tracted multi-word terms (other than gene names to 
be classified) has been used as a feature set. Addi-
tionally, we have experimented with features 
reflecting simple gene-gene co-occurrences within 
the same documents.  
3.1 Single words as features 
The first set of experiments included a classic bag-
of-single-words approach. All abstracts (from a 
larger collection, see Section 4) that contained at 
least one occurrence of a given gene or its aliases 
have been selected as documents relevant for that 
gene. These documents have been treated as a sin-
gle virtual document pertinent to the given gene. 
All words co-occurring with a given gene in any of 
the abstracts were used as its features.  
A word has been defined as an alphanumeric 
sequence between two standard separators, with all 
numeric expressions that were not part of other 
words filtered out. In addition, a standard list of 
around 300 stop-words has been used to exclude 
some frequent non-content words. 
An idf-like measure has been used for feature 
weights: the weight of a word w for gene g is given 
by 
(1)                        |)|1(
)(1
log
gw
Rj
j
RN
wf
g
+
+ ?
?
 
where Rg  is a set of relevant documents for the 
gene g,  fj(w) is the frequency of w in document j, 
and Nw is the global frequency of w. Gene vectors, 
containing weights for all co-occurring words, 
have been used as input for the SVM. 
It is widely accepted that rare words do not 
have any significant influence on accuracy (cf. 
(Leopold and Kindermann, 2002)), neither do 
words appearing only in few documents. In our 
experiments (demonstrated in Section 4), we com-
pared the performance between the ?all-words ap-
proach? and an approach featuring words appearing 
in at least two documents. In the latter case, the 
dimension of the problem (expressed as the num-
ber of features) was significantly reduced (with 
factor 3), and consequently the training time was 
shortened (see Section 4). 
Since many authors claimed that the biomedical 
literature contained considerably more linguistic 
variations than text in general (cf. Yakushiji et al, 
2001), we applied two standard transformations in 
order to reduce the level of lexical variability. In 
the first case, we used the EngCG POS tagger 
(Voutilainen and Heikkila, 1993) to generate lem-
mas, so that lemmatised words were used as fea-
tures, while, in the second case, we generated 
stems by the Porter?s algorithm (Porter, 1980). 
Analogously to words, the same idf-based measure 
was used for weights, and experiments were also 
performed with all features and with the features 
appearing in no less than two documents. 
3.2 Terms as features 
Many literature-mining techniques rely heavily on 
the identification of main concepts, linguistically 
represented by domain specific terms (Nenadic et 
al., 2002b). Terms represent the most important 
concepts in a domain and have been used to char-
acterise documents semantically (Maynard and 
Ananiadou, 2002). Since terms are semantic indi-
cators used in scientific discourse, we hypothesised 
that they might be useful classification features.  
The high neology rate for terms makes existing 
glossaries incomplete for active and time-limited 
research, and thus automatic term extraction tools 
are needed for efficient terminological processing. 
In order to automatically generate term as features, 
we have used an enhanced version of the C-value 
method (Frantzi et al, 2000), which assigns term-
hoods to automatically extracted multi-word term 
candidates. The method combines linguistic forma-
tion patterns and statistical analysis. The linguistic 
part includes part-of-speech tagging, syntactic pat-
tern matching and the use of a stop list to eliminate 
frequent non-terms, while statistical termhoods 
amalgamate four numerical characteristic of a can-
didate term, namely: the frequency of occurrence, 
the frequency of occurrence as a nested element, 
the number of candidate terms containing it as a 
nested element, and term?s length.   
Due to the extensive term variability in the do-
main, the same concept may be designated by 
more than one term. Therefore, term variants con-
flation rules have been added to the linguistic part 
of the C-value method, in order to enhance the re-
sults of the statistical part. When term variants are 
processed separately by the statistical module, their 
termhoods are distributed across different variants 
providing separate frequencies for individual vari-
ants instead of a single frequency calculated for a 
term candidate unifying all of its variants. Hence, 
in order to make the most of the statistical part of 
the C-value method, all variants of the candidate 
terms are matched to their normalised forms by 
applying rule-based transformations and treated 
jointly as a term candidate  (Nenadic et al, 2002a). 
In addition, acronyms are acquired prior to the se-
lection of the term candidates and also mapped to 
their expanded forms, which are normalised in the 
same manner as other term candidates.  
Once a corpus has been terminologically proc-
essed, each target gene is assigned a set of terms 
appearing in the corresponding set of documents 
relevant to the given gene. Thus, in this case, gene 
vectors used in the SVM classifier contain co-
occurring terms, rather than single words. As term 
weights, we have used a formula analogous to (1). 
Also, similarly to single-word features, we have 
experimented with terms appearing in at least two 
documents. 
3.3 Combining word and term features 
The C-value method extracts only multi-word 
terms, which may be enriched during the normali-
sation process with some single-word terms, sourc-
ing from e.g. acronyms or orthographic variations. 
In order to assess impact of both single and multi-
word terms as features, we experimented with 
combining single-word based features with multi-
word terms by using a simple kernel modification 
that concatenates the corresponding feature vec-
tors. Thus, gene vectors used in this case contain 
both words and terms that genes co-occur with. 
3.4 Document identifiers as features 
Term co-occurrences have been traditionally used 
as an indication of their similarity (Ushioda, 1986), 
with documents considered as bags of words in the 
majority of approaches. For example, Stapley et al 
(2000) used document co-occurrence statistics of 
gene names in Medline abstracts to predict their 
connections. The co-occurrence statistics were rep-
resented by the reciprocal Dice coefficient. Similar 
approach has been undertaken by Jenssen et al 
(2001): they identified co-occurrences of gene 
names within abstracts, and assigned weights to 
their ?relationship? based on frequency of co-
occurrence.  
In our experiments, abstract identifiers (Pub-
Med identifiers, PMIDs) have been used as fea-
tures for classification, where the dimensionality of 
the feature space was equal to the number of 
documents in the document set. As feature 
weights, binary values (i.e. a gene is present/absent 
in a document) were used.  
We would like to point out that ? contrary to 
other features ? this approach is not a general 
learning approach, as document identifiers are not 
classification attributes that can be learnt and used 
against other corpora. Instead, this approach can be 
only used to classify new terms that appear in a 
closed corpus used for training. 
4 Experiments and discussions 
An experimental environment was set up by using 
the following resources:  
a) corpus: a set of documents has been ob-
tained by collecting Medline abstracts (NLM, 
2003) related to the baker?s yeast (S. cerevisiae), 
resulting in 52,845 abstracts; this set, containing 
almost 5 million word occurrences, was used as 
both training and testing corpus. 
b) classification entities: a set of 5007 S. cere-
visiae gene names has been retrieved from the 
SGD (Saccharomyces Genome Database) gene 
registry1, which also provided synonyms and ali-
ases of genes; 2975 gene names appearing in the 
corpus have been used for the classification task. 
c) classification scheme: each gene name has 
been classified according to a classification scheme 
based on eleven categories (see Table 1) of the up-
                                                           
1 http://genome-www.stanford.edu/Saccharomyces/registry.html  
per part of the GO ontology (Ashburner et al, 
2000)2. 
d) training and testing sets: positive examples 
for each class were split evenly between the train-
ing and testing sets, and, also, the number of nega-
tive examples in the training set was set equal to 
the number of positive examples within each class. 
The only exception was the metabolism class, 
which had far more positive than negatives exam-
ples. Therefore, in this case, we have evenly split 
negative examples between the training and testing 
sets. Table 1 presents the distribution of positive 
and negative examples for each class. 
d) SVM engine: for training the multi-class 
SVM, we used SVM Light package v3.50 
(Joachims, 1998) with a linear kernel function with 
the regulation parameter calculated as avg(<x,x>)-1.  
  
 
examples Category 
(GO code) training testing 1 testing 2 
autophagy 
(GO:0006914) 12/12 11/2940 11/11 
cell organisation 
(GO:0016043) 379/379 378/1839 378/378 
cell cycle 
(GO:0007049) 226/226 225/2298 225/225 
intracellular 
protein transport 
(GO:0006886) 
135/135 134/2571 134/134 
ion homeostasis 
(GO:0006873) 37/37 37/2864 37/37 
meiosis 
(GO:0007126) 45/45 44/2841 44/44 
metabolism 
(GO:0008152) 1118/370 1117/370 370/370 
signal  
transduction 
(GO:0007165) 
68/68 68/2771 68/68 
sporulation (sc) 
(GO:0007151) 27/27 27/2894 27/27 
response to 
stress 
(GO:0006950) 
91/91 91/2702 91/91 
transport 
(GO:0006810) 284/284 284/2123 284/284 
  
Table 1. Classification categories and the number 
of examples in the training and the testing sets 
                                                           
2 The January 2003 release of the GO ontology was used. A 
similar classification scheme was used in (Raychaudhuri et al, 
2002). 
Features have been generated according to the 
methods explained in Section 3 (Table 2 shows the 
number of features generated). As indicated earlier, 
the experiments have been performed by using ei-
ther all features or by selecting only those that ap-
peared in at least two documents. As a rule, there 
were no significant differences in the classification 
performance between the two.  
 
feature no. of all features 
no. of features 
appearing in >1 docs 
words 160k 60k 
lemmas 150k 54k 
stems 140k 50k 
terms 127k 62k 
  
Table 2. The number of features generated 
 
To evaluate the classification performance we 
have firstly generated precision/recall plots for 
each class. In the majority of classes, terms have 
demonstrated the best performance (cf. Figures 1 
and 2). However, the results have shown a wide 
disparity in performance across the classes, de-
pending on the size of the training set. The classes 
with fairly large number of training entities (e.g. 
metabolism) have been predicted quite accurately 
(regardless of the features used), while, on the 
other hand, under-represented classes (e.g. sporu-
lation) performed quite modestly (cf. Figure 1).   
 
 
Figure 1. Precision/recall plots for some classes  
using words and terms  
 
Comparison between performances on different 
classes is difficult if the classes contain fairly dif-
ferent ratios of positive/negative examples in the 
testing sets, as it was the case in our experiments 
(see Table 1, column testing 1). Therefore, we re-
evaluated the results by selecting ? for each class ? 
the same number of positive and negative exam-
ples (see Table 1, column testing 2), so that we 
could compare relative performance across classes. 
The results shown in Figure 2 actually indicate 
which classes are ?easier? to learn (only the per-
formance of single-words and terms are presented). 
To assess the global performance of classifica-
tion methods, we employed micro-averaging of the 
precision/recall data presented in Figure 2. In mi-
cro-averaging (Yang, 1997), the precision and re-
call are averaged over the number of entities that 
are classified (giving, thus, an equal weight to the 
performance on each gene). In other words, micro-
average shows the performance of the classifica-
tion system on a gene selected randomly from the 
testing set. 
The comparison of micro-averaging results for 
words, lemmas and stems has shown that there was 
no significant difference among them. This out-
come matches the results previously reported for 
the document classification task (Leopold and 
Kindermann, 2002), which means that there is no 
need to pre-process documents. 
Figure 3 shows the comparison of micro-
averaging plots for terms and lemmas. Terms per-
form generally much better at lower recall points, 
while there is just marginal difference between the 
two at the higher recall points. Very high precision 
points at lower recall mean that terms may be use-
ful classification features for precise predictions 
for genes classified with the highest confidence. 
 
 
 
Figure 2. Precision/recall plots for the 11 classes using words and terms  
(horizontal lines indicate the performance of a random classifier) 
 
Figure 3. Micro-averaging plot for 11 classes using 
lemmas and terms 
 
The results obtained by combining terms and 
words have not shown any improvements over us-
ing only terms as classification features. We be-
lieve that adding more features has introduced 
additional noise that derogated the overall per-
formance of terms. 
Finally, Figure 4 presents the comparison of 
classification results using terms and abstract iden-
tifiers. Although PMIDs outperformed terms, we 
reiterate that ? while other features allow learning 
more general properties that can be applied on 
other corpora ? PMIDs can be only used to classify 
new terms that appear in a closed training/testing 
corpus. 
 
 
 
Figure 4. Micro-averaging plot for 11 classes using 
PMIDs and terms 
 
 
5 Conclusion 
Due to an enormous number of terms and the 
complex and inconsistent structure of the biomedi-
cal terminology, manual update of knowledge re-
positories are prone to be both inefficient and 
inconsistent (Nenadic et al, 2002b; Stapley et al, 
2002). Therefore, automatic text-based classifica-
tion of biological entities (such as gene and protein 
names) is essential for efficient knowledge man-
agement and systematic approach that can cope 
with huge volume of the biomedical literature. Fur-
thermore, classified terms irrefutably have a posi-
tive impact on improving the results of IE/IR, 
knowledge acquisition, document classification 
and terminology management (Blaschke et al, 
2002).  
In this paper we have examined the procedures 
for engineering text-based features at various lev-
els of linguistic pre-processing, and considered 
their impacts on the performance of an SVM-based 
gene name classifier. The experiments have shown 
that simple linguistic pre-processing (such as lem-
matisation and stemming) does not have significant 
influence on the performance, i.e. there is no need 
to pre-process documents. Also, reducing the fea-
ture space by selecting only features that appear in 
more documents does not result in decrease of the 
performance, but can significantly reduce the time 
needed for training. PMID-based classification has 
shown very good performance, but a PMID-based 
classifier can be applied only on the training set of 
documents. 
The experiments have also shown that using 
semantic indicators (represented by dynamically 
extracted domain-specific terms) can improve the 
performance compared to the standard bag-of-
words approach, in particular at lower recall 
points, and for rare classes. This means that terms 
can be used as reliable features for classifying 
genes with higher confidence, and for under-
represented classes. However, terminological 
analysis requires considerable pre-processing time.  
Our further research will focus on generating 
the biological interpretation and justification of the 
classification results by using terms (that have 
been used as key distinguishing features for classi-
fication) as semantic indicators of the correspond-
ing classes.  
 
References 
 
M. Ashburner, et al. 2000. Gene Ontology: Tool for the 
Unification of Biology. Nature, 25:25-29.  
C. Blaschke, L. Hirschman and A. Valencia. 2002. In-
formation Extraction in Molecular Biology. Briefings 
in Bioinformatics, 3(2):154-165. 
N. Collier, C. Nobata and J. Tsujii. 2001. Automatic 
Acquisition and Classification of Terminology Using 
a Tagged Corpus in the Molecular Biology Domain. 
Journal of Terminology, John Benjamins. 
F. Eisenhaber and P. Bork. 1998. Wanted: Subcellular 
Localization of Proteins Based on Sequences. Trends 
Cell Biology, 8(4):169-170. 
K. Frantzi, S. Ananiadou and H. Mima. 2000. Automatic 
Recognition of Multi-Word Terms: the C-value/NC-
value Method. International Journal on Digital Li-
braries 3(2):115-130. 
GENIA project. 2003. GENIA resources. Available at:  
http://www-tsujii.is.s.u-tokyo.ac.jp/~genia/ 
V. Hatzivassiloglou, P. Duboue and A. Rzhetsky. 2001. 
Disambiguating Proteins, Genes, and RNA in Text: A 
Machine Learning Approach. Bioinformatics, 1(1):1-
10. 
T. Jenssen, A. Laegreid, J. Komorowski and E. Hovig. 
2001. A literature Network of Human Genes for 
High-throughput Analysis of Gene Expressions. Na-
ture Genetics, 28: 21-28. 
T. Joachims. 1998. Text Categorization with Support 
Vector Machines: Learning Many Relevant Features. 
Proceedings of 10th European Conference on Ma-
chine Learning, Springer-Verlag, Heidelberg, 137-
142. 
J. Kazama, T. Makino, Y. Ohta and J. Tsujii. 2002. Tun-
ing Support Vector Machines for Biomedical Named 
Entity Recognition. Proceedings of the Workshop 
NLP in Biomedicine, ACL 2002. 
E. Leopold and J. Kindermann. 2002. Text Categoriza-
tion with Support Vector Machines. How to Repre-
sent Texts in Input Space? Machine Learning, 
46:423-444. 
H. Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianini 
and C. Watkins. 2002. Text Classification using 
String Kernels. Journal of Machine Learning Re-
search, 2:419-444. 
D. Maynard and S. Ananiadou. 2000. Identifying Terms 
by their Family and Friends. Proceedings of 
COLING 2000, Saarbrucken, Germany, 530-536.  
 
 
K. Nishikawa and T. Ooi. 1982. Correlation of the 
Amino Acid Composition of a Protein to its Struc-
tural and Biological Characters. Journal of Bio-
chemistry (Tokyo), 91(5):1281-1824. 
G. Nenadic, I. Spasic and S. Ananiadou. 2002a. Auto-
matic Acronym Acquisition and Term Variation 
Management within Domain-Specific Texts. Proceed-
ings of LREC-3, Las Palmas, Spain, 2155-2162.  
G. Nenadic, H. Mima, I. Spasic, S. Ananiadou and J. 
Tsujii. 2002b. Terminology-based Literature Mining 
and Knowledge Acquisition in Biomedicine. Interna-
tional Journal of Medical Informatics, 67(1-3):33-48. 
NLM, National Library of Medicine. 2003. Medline. 
Available at http://www.ncbi.nlm.nih.gov/PubMed/ 
M. Porter. 1980: An Algorithm for Suffix Stripping. Pro-
gram, 14(1):130-137. 
S. Raychaudhuri, J. Chang, P. Sutphin and R. Altman. 
2002. Associating Genes with Gene Ontology Codes 
Using a Maximum Entropy Analysis of Biomedical 
Literature. Genome Research, 12:203-214. 
B. Stapley and G. Benoit. 2000. Bibliometrics: Informa-
tion Retrieval and Visualization from Co-occurrence 
of Gene Names in Medline Abstracts. Proceedings of 
the Pacific Symposium on Bio-computing, PSB 2000 
B. Stapley, L. Kelley and M. Sternberg. 2002. Predict-
ing the Sub-Cellular Location of Proteins from Text 
Using Support Vector Machines. Proceedings of the 
Pacific Symposium on Bio-computing, PSB 2002. 
A. Ushioda. 1996. Hierarchical Clustering of Words. 
Proceedings of COLING 96. 
V. Vapnik. 1995. The Nature of Statistical Learning 
Theory. Springer Verlag, Heidelberg. 
A. Voutilainen and J. Heikkila. 1993. An English Con-
straint Grammar (ENGCG) a Surface-Syntactic 
Parser of English. In Fries, U et al (Eds.): Creating 
and Using English Language Corpora, Rodopi, Am-
sterdam/Atlanta, 189-199. 
A. Yakushiji, Y. Tateisi, Y. Miyao and J. Tsujii. 2001. 
Event Extraction From Biomedical Papers Using a 
Full Parser. Proceedings PSB 2001, Hawaii, USA, 
408-419. 
Y. Yang. 1997. An Evaluation of Statistical Approaches 
to Text Categorization. Information Retrieval, 
1(1/2):69-90. 
Morpho-syntactic Clues for Terminological Processing in Serbian 
Goran Nenadi? 
Department of Computing 
UMIST, UK 
G.Nenadic@umist.ac.uk
Irena Spasi? 
Computer Science 
University of Salford, UK 
I.Spasic@salford.ac.uk
Sophia Ananiadou 
Computer Science  
University of Salford, UK 
S.Ananiadou@salford.ac.uk
 
 
Abstract 
In this paper we discuss morpho-syntactic 
clues that can be used to facilitate termi-
nological processing in Serbian. A 
method (called SRCE) for automatic ex-
traction of multiword terms is presented. 
The approach incorporates a set of ge-
neric morpho-syntactic filters for recogni-
tion of term candidates, a method for 
conflation of morphological variants and 
a module for foreign word recognition. 
Morpho-syntactic filters describe general 
term formation patterns, and are imple-
mented as generic regular expressions. 
The inner structure together with the 
agreements within term candidates are 
used as clues to discover the boundaries 
of nested terms. The results of the termi-
nological processing of a textbook corpus 
in the domains of mathematics and com-
puter science are presented.  
1 Introduction 
An overwhelming amount of textual information 
presented in newswire, scientific literature, legal 
texts, etc., makes it difficult for a human to effi-
ciently localise the information of interest. In 
particular, it is doubtful that anybody could proc-
ess such huge amount of information without an 
automated help, especially when the information 
content spans across domains. The amount of e-
documents and their fuzzy structure require 
effective tools that can help users to 
systematically gather and make use of the 
information encoded in text documents. For these 
reasons, different text and/or literature mining 
techniques have been developed recently (e.g. 
(Hearst et al, 2000; Grobelnik et al, 2000)) in 
order to facilitate efficient discovery of knowl-
cient discovery of knowledge contained in large 
scientific or legal text collections. The main goal 
is to retrieve the knowledge ?buried? in a text 
and to present it to users in a digested form.  
The discovery (and transfer) of knowledge re-
lies heavily on the identification of relevant con-
cepts, which are linguistically represented by 
domain specific terms. Terms represent the most 
important notions in a domain and characterise 
documents semantically, and thus should be used 
as a basis for sophisticated knowledge acquisi-
tion. Still, few text-mining systems incorporate 
deep and dynamic terminology processing, al-
though there is an increasing amount of new 
terms that represent newly created concepts in 
rapidly developing fields. Existing term diction-
aries and standardised terminologies offer only a 
partial solution, as they are almost never up-to-
date. Although naming conventions do exist for 
some types of concepts (e.g. gene and protein 
names in biomedicine), these are only guidelines 
and as such do not impose restrictions to domain 
experts, who frequently introduce ad-hoc terms. 
Thus, the lack of clear naming conventions 
makes the automatic term recognition (ATR) task 
difficult even for languages that are not morpho-
logically and derivationally rich.  
ATR tools have been developed for English 
(Frantzi et al, 2000), French (Jacquemin, 2001), 
Japanese (Nakagawa and Mori, 2000), etc. Some 
methods rely purely on linguistic information, 
namely morpho-syntactic features of term candi-
dates (Ananiadou, 1994). Hybrid approaches 
combining linguistic patterns and statistical 
measures (e.g. (Frantzi et al, 2000)) and ma-
chine-learning techniques (e.g. (Hatzivassiloglou 
et al, 2001)) have been also used.  
However, few studies have been done for 
morphologically rich Slavic languages. For ex-
ample, Vintar (2000) presented two methods for 
extraction of terminological collocations in order 
to assist the translation process in Slovene. The 
statistical approach was based on the mutual ex-
pectation and LocalMax measures, and involved 
collocation extraction from raw text. The ex-
tracted collocations were filtered with a stop-
word list, and only collocations containing sin-
gle-word terms (devised previously by bilingual 
alignment) were accepted as relevant. In another 
approach, she used regular expression patterns to 
extract term collocations from a morpho-
syntactically tagged corpus. However, these pat-
terns are too general, and consequently not all 
extracted phrases were terminologically relevant.  
In this paper we discuss automatic terminology 
recognition in Serbian, in particular, the extrac-
tion of multiword terms, which are very frequent1 
in certain domains (e.g. natural sciences, mathe-
matics, etc.). Since Serbian is a highly inflective 
and morphologically and derivationally rich lan-
guage, morpho-syntactic clues are indispensable 
in the ATR process. Our hybrid approach (called 
SRCE ? Serbian C-value) combines morpho-
syntactic features of term candidates and statisti-
cal analysis of their occurrences in text. In addi-
tion, since terms appear in texts in many different 
forms due to their morphological and derivational 
variations, the necessity of taking these variations 
into account becomes particularly apparent. 
Therefore, the SRCE method incorporates generic 
morpho-syntactic patterns, a term normalisation 
approach and a foreign word detection method.  
The paper is organised as follows: in Section 2 
we present an overview of the core term extrac-
tion method, called the C-value method. In Sec-
tion 3 we discuss morpho-syntactic clues, the 
normalisation approach and the foreign word 
recognition that are used for singling out terms in 
Serbian. The experiments and evaluation are de-
scribed in Section 4. 
 
2 Automatic Term Recognition: the core 
C-value method 
Our approach to ATR is based on the C-value 
method (Frantzi et al, 2000), which extracts 
multi-word terms. It is a general term recognition 
approach in the sense that it is not limited to spe-
cific classes of concepts. The approach is hybrid: 
the method combines linguistic knowledge (term 
                                                           
1 In English, more than 85% of domain-specific terms are 
multi-words (Nakagawa and Mori, 2000).  
formation patterns) and statistical analysis. Lin-
guistic knowledge is used to single out term can-
didates, while their statistical features are used to 
measure the likelihood of term candidates being 
?real? terms. The method uses a POS tagged text 
as input, and outputs a list of extracted terms 
ranked according to their termhoods. Termhood 
is a numeric estimation of the degree to which a 
given linguistic unit (a multiword compound) is 
related to a domain-specific concept. However, 
the values are not normalised in the sense that a 
multiword, having a termhood value 10, is 10 
times more likely to be a term than a term candi-
date with a termhood value 1.  
In general, the C-value method enhances the 
commonly used baseline method that extracts 
most frequent term candidates (assuming that 
termhoods directly correspond to frequencies of 
occurrence) by making it sensitive to a particular 
type of terms ? nested terms2.   
The method is implemented as a two-step pro-
cedure. In the first step, term candidates are ex-
tracted using a set of morpho-syntactic filters, 
which describe general term formation patterns in 
a given language. As a rule, terms form a proper 
subset of noun phrases (NPs). For example, a set 
of general filters for English may include the fol-
lowing patterns:3 
 
Noun+ Noun  
(Adj | Noun)+ Noun  
(Adj | Noun)+| ((Adj | Noun)* Prep?) (Adj | Noun)* Noun  
 
Although these patterns are regular expressions, 
the filters are implemented as unification-like 
LR(1) rules (Mima et al, 1995) in order to facili-
tate processing of grammatical agreements (if 
any) within term candidates.  
For each term candidate extracted by a filter, a 
set of nested term candidates is generated (see 
Table 1 for an example in English). The proce-
dure for the generation of nested term candidates 
is implemented via transformation rules for each 
morpho-syntactic filter that is used to extract 
                                                           
2 For example, nuclear receptor is a nested term in hormone 
nuclear receptor. Similarly, baza podataka (Engl. database) 
is a nested term in a?uriranje baze podataka (Engl. update of 
database).  
3 Noun, Adj and Prep denote POS tags that correspond to 
nouns, adjectives and prepositions respectively. These filters 
were used for ATR from newswire corpora and in biomedi-
cine (Frantzi et al, 2000; Nenadi? et al, 2002).  
term candidates. The main indicator that a nested 
term candidate might be a real term is that it also 
appears on its own in the corpus. 
 
Term Term candidate: 
      steroid hormone receptor factor + 
Nested term candidates: 
steroid hormone receptor 
hormone receptor factor 
steroid hormone 
hormone receptor  
receptor factor 
 
+ 
- 
+ 
+ 
- 
Table 1: Nested term candidates 
 
In the second step, the term candidates are as-
signed termhoods (referred to as C-values) ac-
cording to a statistical measure. The measure 
amalgamates four numerical corpus-based char-
acteristic of a candidate term, namely the fre-
quency of occurrence, the frequency of occurring 
as nested within other candidate terms, the num-
ber of candidate terms inside which the given 
candidate term is nested, and the number of 
words contained in the candidate term. Formally,  
where a denotes a term candidate, f(a) corre-
sponds to its frequency, |a| denotes the number of 
words in a, and Ta is a set of terms that contain 
term a as a nested term. Term candidates are 
ranked according to their C-values, and terms 
whose C-values are higher than a chosen thresh-
old are presented as terms. 
Evaluation of the C-value method for English 
has shown that using additional statistical infor-
mation (frequency of ?nestedness?) improves the 
precision with slight loss on recall (Frantzi et al, 
2000). Also, systematic term normalisation may 
further improve precision and recall of the 
method (Nenadi? et al, 2002). 
3 Morpho-syntactic clues for extraction 
of terms in Serbian 
In order to adjust the core C-value method for 
Serbian, we have defined an appropriate set of 
morpho-syntactic filters and rules for inflectional 
normalisation of term candidates, and, addition-
ally, a module for foreign word recognition.  
3.1 Term formation patterns 
As a rule, the vast majority of multiword terms in 
Serbian match the following general formation 
pattern:4 
 
(1)           (Adj | ProAdj | Num | Noun )+ Noun 
 
which has been used for recognition of NPs in 
Serbian (Nenadi? and Vitas, 1998a). Of course, 
not all NPs that follow this pattern are terms.5 
Moreover, when applied to an initially POS 
tagged text6, this pattern may be too general even 
for description of NPs, as not all word sequences 
in a text that match this pattern are valid NPs. For 
example, in a sequence koji se naziva relacioni 
model (Engl. which is called the relational 
model), a word naziva can be initially tagged ei-
ther as a noun naziv (Engl. name) or a verb na-
zivati (Engl. call), although, in this sentence, only 
the latter is correct. Thus, without further POS 
disambiguation, the string naziva relacioni model 
follows the pattern (1), although it is not a valid 
NP. This means that classical regular expressions 
are not sufficient for the representation of such 
constraints, and that we need more expressive 
means to model constraints related to the NP 
structure and agreements of multiword constitu-
ents on case, number and gender. We used the 
notion of generic patterns as an extension of 
regular expressions (Nenadi? and Vitas, 1998b). 
For example, a generic pattern 
 
(2)      Adj.x1y1z1  Noun.x1y1z1   Adj.x2y2g   Noun.x2y2g 
 
models obligatory agreements that each NP from 
a specific class has to fulfil: both first and second 
pairs of adjectives and nouns must have the same 
values for certain morphological features (i.e. 
values for gender, number and case denoted by xi, 
                                                           
4 ProAdj and Num denote possessive adjectives and numbers 
respectively. 
5 For example, ovaj na?in (Engl. this way), veliki deo (Engl. 
large part), etc. This is a reason why we need additional 
processing to recognise semantically relevant NPs. 
6 Initially (or lexically) tagged POS text is a text in which 
every word occurrence is associated with all of its possible 
lexical and grammatical interpretations. The initial POS 
tagging is intrinsically ambiguous as each word is analysed 
separately, without considering neighbouring words (Ne-
nadi? and Vitas, 1998a). Thus, as a result of initial tagging, a 
lot of lexical ambiguities arise resulting in highly ambiguous 
word sequences. See Section 4 for further discussion. 
? ? ? 
? ? ? 
? 
? 
? 
= ? ? ?
otherwise                                   
        )), ( | | 
1 )( ( | | log 
nested, not   is                ), ( | | log 
) ( 2 
2 
a a Tb b fT a f a
a af a
a value C 
yi and zi respectively), while these values may be 
different for each respective pair. The last adjec-
tive and noun are ?frozen? in the genitive case 
(g), while the case (z1) in the first pair is ?free?. 
By defining generic patterns one can model the 
agreements within various lexical structures in a 
highly inflective language such as Serbian (Ne-
nadi? and Vitas, 1998b). As a result, these 
agreements can be used to detect the boundaries 
of the structures in questions. 
A set of generic patterns has been used to 
model the most frequent term formation patterns 
in Serbian. The set is mainly based on patterns 
used to model NPs in Serbian. Table 2 presents 
some of them. First four patterns describe NPs 
containing a nested NP whose lexical properties 
(such as case and/or number) are invariant in all 
inflected forms of the host NP. As a rule, the fro-
zen part is in genitive. Depending on NP con-
stituents, some agreements are obligatory within 
frozen part (see, for example, the third pattern ? 
agreements between an adjective and the corre-
sponding noun), or not (see the fourth pattern ? 
no necessary agreement between the last two 
nouns in gender, number). The fifth pattern (Ta-
ble 2) corresponds to NPs that do not have in-
variant parts. 
 
Generic patterns Examples 
1 N1   N gen baza podataka nejednakost trougla 
2 A1   N1   N gen manipulativni aspekt modela grani?na vrednost niza 
3 N1   A gen  N gen operacija prirodnog spajanja niz realnih brojeva 
4 N1   N 2;gen N gen integritet baze podataka kriterijum konvergencije niza 
5 A1+  N1 pro?ireni relacioni model  kompletan metri?ki  prostor 
Table 2: Frequent term formation patterns7 
 
While these patterns are used to single out 
term candidates from an initially tagged text, 
agreements within NPs are used to generate pos-
sible nested structures. While the rules for nested 
structures are more ?blurred? in English (since 
                                                           
7 In order to improve readability of filters, the generic pat-
terns in this table are encoded using the following syntax: A 
and N stand for Adj and Noun respectively, while X1 stands 
for X.x1y1z1 , Xgen stands for X.xyg and X2;gen stands for 
X.x2y2g (for X ? {A, N}). Also, invariant parts are underlined 
in the given examples. 
 
nouns are usually used as modifiers), ?nested-
ness? in Serbian has to preserve the necessary 
structure and inner agreements, which are spe-
cific for the NP class in question. Therefore, gen-
eration of nested term candidates depends on the 
type of host term candidates (consider examples 
in Table 3). Nested structures that are not them-
selves NPs are not considered as term candidates. 
 
     Nested term candidates  NP Term 
 
2 
 
manipulativni aspekt modela 
   manipulativni aspekt  
   aspekt modela 
+ 
+ 
+ 
+ 
- 
- 
 
3 
 
operacija prirodnog spajanja  
   operacija prirodnog 
   prirodnog spajanja 
+ 
- 
+ 
+ 
- 
+ 
 
4 
 
integritet baze podataka 
 integritet baze  
 baze podataka 
+ 
+ 
+ 
+ 
- 
+ 
 
5 
 
kompletan metri?ki prostor 
  kompletan metri?ki  
  metri?ki prostor 
+ 
- 
+ 
+ 
- 
+ 
Table 3: Nested term candidates (in Serbian) 
3.2 Conflating morphological variants 
If we aim at systematic recognition of terms, then 
handling term variation has to be treated as an 
essential part of terminology retrieval. Term 
variation ranges from simple orthographic (e.g. 
oestrogen ? estrogen, vitamin ? vitamine) and 
morphological variants (e.g. clone ? clones) to 
more complex semantic variation (e.g. eye sur-
gery ? ophthalmologic surgery).  
Several methods for term variation manage-
ment have been developed. For example, the 
BLAST system (Krauthammer et al, 2000) used 
approximate text string matching techniques and 
dictionaries to recognise spelling variations in 
gene and protein names. FASTR (Jacquemin, 
2001) handles morphological and syntactic varia-
tions by means of meta-rules used to describe 
term normalisation, while semantic variants are 
handled via WordNet.  
The necessity of taking term variants into ac-
count as part of ATR process becomes particu-
larly apparent in highly inflective languages. In 
Serbian, for example, the simplest morphological 
variations generally give rise to 14 possible vari-
ants of a single term (seven cases and two num-
bers (singular and plural) ? see Table 4). If the 
core C-value method were to be applied without 
conflating morphological variants, then term-
hoods would be distributed across different mor-
phological variants providing separate 
frequencies for individual variants instead of a 
single frequency calculated for a term candidate 
unifying all of its variants. In addition, the ?nest-
ing? factor of the C-value method would cause 
skewed results, since the case property of nested 
terms does not have normal distribution. Namely, 
as indicated previously (see Table 2), the major-
ity of nested terms in Serbian are in genitive case, 
which means that the termhood for a term candi-
date in genitive case would differ significantly 
from its counterparts in other cases. Moreover, 
this deviation cannot be remedied later by sum-
ming up individual termhoods, since C-value is 
not an additive measure. Hence, in order for the 
C-value method to be applied correctly in a 
highly inflective language, term candidates must 
be (at least inflectionally) normalised prior to the 
calculation of termhoods.  
 
Canonical form: 
operacija prirodnog spajanja (nom. sing. = ns) 
 
Morphological variants: 
operacija prirodnog spajanja (ns;gp) 
operacije prirodnog spajanja (gs;np;ap;vp) 
operaciji  prirodnog spajanja (ds;ls) 
operaciju prirodnog spajanja (as) 
operacijo prirodnog spajanja (vs) 
operacijom prirodnog spajanja (is) 
operacijama prirodnog spajanja (dp;ip;lp) 
Normalised form: 
    operacija (ns) prirodno (nsm) spajanje (ns)  
 
Table 4: Variants and normalisation of term 
candidates ? an example for term operacija prirod-
nog spajanja (Engl. natural join operation) 
 
Our approach to morphological normalisation 
of term variants is based on the normalisation of 
individual term constituents. Namely, each word 
that is a part of a term candidate is mapped onto 
its lemma, and term candidates are treated as se-
quences of lemmas. At the end of the ATR proc-
ess, terms are converted into their canonical form 
(singular, nominative case), which is not neces-
sarily identical to the normalised form (the se-
quence of the corresponding singular words in 
singular, nominative case). The normalisation 
process is illustrated in Table 4. 
At this point, the usage of generic patterns in 
order to check the agreements in case, number 
and gender during the phase of filtering of term 
candidates might seem unnecessary, since all 
these features are subsequently normalised. How-
ever, in order to enhance the precision of the 
SRCE method, it is important for term candidates 
to be correctly recognised prior to the statistical 
analysis. This means that the necessary agree-
ments between NP constituents have to be 
checked. Once the term candidates are identified, 
they are normalised in order to make the most of 
the statistical part of the method.   
3.3 Foreign word detection 
Despite the efforts to rely mostly on Serbian vo-
cabulary when building a terminology, many of 
the terms used in specific scientific domains bor-
row some of their building blocks from lan-
guages other than Serbian at various levels. For 
example, at morphological level, foreign suffixes, 
mostly originating from Latin and Greek, are of-
ten ?preferred? to their Serbian counterparts in, 
for example, the biomedical domain, even when 
they are used to modify a root that is in fact Ser-
bian (e.g. amino-kiselina (Engl. amino acid)). 
Similarly, at lexical level, words of foreign origin 
are used to form multi-word terms (e.g. redun-
dantan atribut (Engl. redundant attribute)). This 
is particularly obvious in fairly recently expanded 
disciplines such as computer science, where, for 
many of the original terms used in English, it has 
not been simple to adapt new terms in Serbian. 
Consequently, many of the terms have been sim-
ply transcribed into Serbian or, even worse, they 
are still used in their original form. Not only do 
foreign words appear as ?valid? parts of terms, 
but they have also proved to be good indicators 
of terms. It is, thus, necessary to develop proce-
dures for their detection.  
In our approach, the recognition of foreign 
words has been integrated into the ATR process 
for Serbian. The following morphological fea-
tures are used to indicate occurrences of potential 
foreign words (Spasi?, 1996): 
 
? characters (e.g. x, y, q) that do not belong to 
Serbian graphemic system, 
? successive vowel occurrences, 
? exception to the palatalisation rule,   
? exception to the assimilation rules, 
? occurrence of atypical consonant bi/tri-grams  
? occurrence of bi-grams or tri-grams typical 
for other languages (especially Latin and 
English), and 
? foreign affixes. 
 
The words satisfying some of the above crite-
ria are not necessarily foreign words. The preci-
sion of these rules varies from one to another. For 
example, the first rule is the strongest indicator of 
the presence of foreign words, since the alpha-
betical system used is not Serbian. Other rules 
may be tuned to a certain extent in order to in-
crease their precision.  
Let us, for instance, consider the second rule. 
The successive usage of vowels is fairly frequent 
in Serbian, but the majority of such cases follow 
certain restrictions8 under which they can occur. 
Moreover, these restrictions can be described by 
regular expressions. Any other occurrence of 
successive vowels can be used to indicate a po-
tential foreign word. 
Foreign word detection has been incorporated 
into the ATR process in two ways: during the 
selection of term candidates and for the calcula-
tion of termhoods. First, it is used before the ini-
tial POS tagging process in order to locate 
foreign words, which are tagged accordingly. 
Otherwise, foreign words would be typically 
considered as unknown. As explained earlier, it is 
very likely for foreign words in Serbian scientific 
and technical texts to be related to domain-
specific concepts, and their mishandling would 
significantly decrease the recall of the ATR 
method. This information is used by the linguistic 
part of the SRCE-method, where we introduced a 
special category corresponding to foreign words.  
In the second step, that is - once the term can-
didates have been selected - the information 
about foreign origin is used to increase the term-
hood of term candidates containing such words. 
This time, foreign word recognition is used to 
improve the precision of the ATR method. 
                                                           
8 For example, verbs in the paste tense, masculine gender 
always end with a pair of vowels (e.g. ispitivao (Engl. exam-
ined)). Further, some adjectives in masculine gender (e.g. 
beo (Engl. white)), as well as some nouns in masculine gen-
der (e.g. smisao (Engl. sense)) also end with a pair of vow-
els. The usage of prefixes is another example where vowels 
may occur successively (e.g. za+ustaviti (Engl. to stop)). 
4 Experiments and discussion 
The preliminary ATR experiments were con-
ducted using the SRCE system on a corpus con-
taining samples from university textbooks in 
mathematics9 and computer science10 (altogether 
120k words). 
Texts were pre-processed, i.e. initially tagged, 
by a system of electronic dictionaries (e-
dictionaries) containing simple nominal words 
for Serbian (Vitas, 1993). E-dictionaries contain 
exhaustive description of morpho-syntactic 
characteristics and are used for lexical 
recognition and initial lemmatisation of words 
that occur in a text.  This process is realised by e-
dictionary look-up, which results in an initially 
tagged text: each textual word is associated with 
its lemma(s) and corresponding morpho-syntactic 
categories (tags) retrieved from the  
e-dictionary. In general, e-dictionaries cannot 
resolve lexical ambiguities that result from the 
fact that there is no one-to-one correspondence 
between word forms and their morpho-syntactic 
features. There are different methods to resolve 
ambiguities (e.g. cache-dictionaries or local 
grammars), but in our experiments no disam-
biguation techniques were applied.  
In order to extract a list of term candidates, the 
set of morpho-syntactic filters described in 3.1 
was applied to the initially tagged corpus. We 
performed two sets of experiments. 
In the first experiment, we did not use any 
stoplist to discard unwanted constituents of term 
candidates. For each term candidate, we gener-
ated a canonical form (nominative, singular), a 
morphologically normalised form (list of normal-
ised words comprising the term candidate) and a 
list of nested term candidates (see Table 3 for 
examples).  In the next step, C-values for term 
candidates were calculated using statistics based 
on occurrences of normalised forms, and all term 
candidates with C-values above an empirically 
chosen threshold were selected as terms.  
Table 5 gives some examples of the recognised 
terms. In order to calculate the precision, we ex-
                                                           
9 N. La?eti?, Matematika II/1, Nau?na knjiga, Beograd, 
1994 
10 G. Pavlovi?-La?eti?, Osnove relacionih baza podataka, 
Vesta - Matemati?ki fakultet, Beograd, 1996. We would like 
to thank the authors of both textbooks for giving us permis-
sion to use their texts for experiments. 
amined separately interval precisions in sub-
corpora in mathematical analysis and computer 
science (see Table 6). Intervals are sets of recog-
nised terms that are placed at certain positions 
within the list. For example, interval 1-50 con-
tains top 50 terms, while the interval over 150 
contains all terms whose positions in the list are 
above 150. Terms have been inspected by the 
first two authors, who are Serbian native speakers 
and are specialists in both computer science and 
mathematics. 
 
Term  C-value 
metri?ki prostor   
topolo?ki prostor 
otvoren skup      
normiran prostor  
Ko?ijev niz 
zatvoren skup  
vektorski prostor  
prirodan broj 
nejednakost trougla    
neprekidnost preslikavanja 
Hausdorfov topolo?ki prostor     
633.55 
175.13 
93.20 
88.00 
68.11 
59.20 
53.13 
44.41 
33.98 
28.02 
19.43 
Table 5: Top ranked terms in the domain of  
mathematical analysis 
 
Interval Mathematical analysis 
Computer 
science 
1 ? 50 98% 90% 
50 ? 100 88% 70% 
100 ? 150 52% 58% 
> 150 69% 68% 
Table 6: Precision of the ATR method  
(without the usage of a stoplist) 
 
In the first 50 terms for the domain of mathe-
matical analysis, there was only one false term 
candidate (specijalna klasa neprekidnih pres-
likavanja), which contained an ?unwanted? adjec-
tive specijalna (Engl. special). The reason for the 
significant drop in the precision in the second and 
third intervals is mainly the same: apart from few 
true negatives11, the majority of false term candi-
dates contained common ?unwanted? constitu-
ents, which are sampled in Table 7. The results 
for the computer science sub-corpus were slightly 
worse since the mathematical language seems to 
be more consistent and restricted. 
                                                           
11 Such as: toplo?ka ta?ka gledi?ta, kompletnost prostora igra, 
kod preslikavnja. 
In the second experiment, we used a stoplist 
containing the words detected as frequent 
?wrong? constituents in the previous experi-
ments. The results are summarised in Table 8. 
 
prozvoljan 
tra?en 
specijalan 
va?an 
odgovaraju?i 
definisan 
op?ti 
dokazan 
globalan 
jedinstven 
poznat 
veliki 
pojam 
specifi?nost 
svojstvo 
slu?aj 
posledica 
gledi?te 
Table 7: A sample of normalised stop-words 
 
Interval Mathematical analysis 
Computer 
science 
1 ? 50 100% 94% 
50 ? 100 92% 92% 
100 ? 150 80% 74% 
> 150 74% 70% 
Table 8: Precision of the ATR method 
 (with the usage of a stoplist) 
 
The majority of remaining errors originate 
from the ambiguous POS tagging (more than 
50%, problematic words being naziv(a), igra, 
kod, etc.). Since no further processing of text has 
been performed, another source of problems is 
the detection of boundaries of frozen parts in 
prepositional phrases (e.g. na osnovu (Engl. 
based on), u slu?aju (Engl. in the case of)), 
which may be resolved by using a set of corre-
sponding local grammars (Nenadi? and Vitas, 
1998b). In addition, for the computer science 
domain, some of the false terms were related to a 
specific application area (the text intensively 
used examples from a university information sys-
tem, so candidates such as zvanje nastavnika 
(Engl. lecturer position), godina studija (Engl. 
year of study), etc. were wrongly suggested as 
computer science terms). 
5 Conclusion 
In this paper we have presented an approach to 
automatic extraction of terminology in a morpho-
logically rich language, such as Serbian. Terms 
extracted automatically may be used as semantic 
indicators for a range of classic IR/IE tasks. 
The approach is hybrid: it combines morpho-
syntactic filters for extraction of term candidates, 
and statistical analysis that ranks term candidates 
according to their termhood.  
Extraction of term candidates is based on the 
recognition of proper NPs. In order to enhance 
both the precision and recall of the ATR method, 
it is inevitable to incorporate significant linguistic 
knowledge. Since describing NPs by means of 
regular expressions is not sufficient for modelling 
agreements between NP constituents, we have 
used generic morpho-syntactic patterns. Further, 
since not all NPs are terms that semantically 
characterise documents, we have used a statisti-
cal measure in order to estimate semantic signifi-
cance of term candidates. Also, once the term 
candidates are correctly identified, they are nor-
malised in order to make the most of the statisti-
cal part of the method. Term candidates 
suggested as terms by the statistical part of the 
SRCE method are finally mapped into the canoni-
cal form of the original term. 
The preliminary experiments show that the 
precision is in line with the results for English, 
and that for the top ranked terms the precision is 
well above 90%. The analysis of errors shows 
that the majority of them appear due to lexical 
ambiguity of the input text. Certainly, if the cor-
pora were lexically disambiguated, we would 
have better precision.  
In order to improve the recall, additional mor-
pho-syntactic filters need to be identified. In par-
ticular, we plan to study terms that contain 
prepositions, as this is a common formation pat-
tern in many domains. Further, the broader han-
dling of term variants (e.g. dialectic variants, 
acronyms, derivational variants) may also im-
prove both precision and recall. Currently we 
deal only with inflectional variants by mapping 
them to a canonical form. Term variants unifica-
tion and normalisation also provide a broader 
basis for further IR and IE tasks, as queries can 
be expanded by referring to a class of synony-
mous terms as opposed to a single term.  
 
References  
Ananiadou S. 1994.  Methodology for Automatic Term 
Recognition. In Proceedings of COLING-94, 
Kyoto, Japan 
Frantzi K.T., Ananiadou S. and Mima H. 2000. Auto-
matic Recognition of Multi-word Terms: the C-
value/NC-value Method. Int. J. on Digital Libraries, 
3/2, pp. 115-130. 
Grobelnik M., Mladeni? D. and Mili?-Frayling N. 
2000. Text Mining as Integration of Several Re-
lated Research Areas, KDD 2000 Workshop on 
Text Mining, Boston, USA 
Hatzivassiloglou V., Duboue P. and Rzetsky A. 2001. 
Disambiguating Proteins, Genes, and RNA in Text: 
A Machine Learning Approach. Bioinformatics, 
17/1, pp. S97-S106 
Hearst M. 2000. Text Mining Tools: Instruments for 
Scientific Discovery, in IMA Text Mining Work-
shop, Institute for Mathematics and its Applica-
tions, Minneapolis, USA, 2000 
Jacquemin C. 2001. Spotting and discovering terms 
through NLP. MIT Press, Cambridge MA, 378 p. 
Krauthammer M., Rzhetsky A., Morozov P. and 
Friedman C. 2000. Using BLAST for identifying 
gene and protein names in journal articles. Gene, 
259, pp. 245-252. 
Mima H., Ando K. and Aoe J. 1995: Incremental 
Generation of LR(1) Parse Tables. In Proceedings 
of NLPRS?95, Pacific-Rim Symp., Seoul, Korea 
Nakagawa H. and Mori T. 2000. Nested Collocation 
and Compound Noun for Term Recognition. Proc. 
of COMPUTERM 98, pp. 64?70 
Nenadi? G. and Vitas D. 1998a. Formal Model of 
Noun Phrases in Serbo-Croatian. BULAG 23, 
Universite Franche-Compte, Besan?on, France. 
Nenadi? G. and Vitas D. 1998b. Using Local Gram-
mars for Agreement Modelling in Highly Inflective 
Languages. In Proceedings of TSD 98. Masaryk 
University, Brno, pp. 91-96. 
Nenadi? G., Mima H., Spasi? I., Ananiadou S. and 
Tsujii J. 2002. Terminology-driven Literature Min-
ing and Knowledge Acquisition in Biomedicine. In-
ternational Journal of Medical Informatics, 1-16. 
Spasi? I. 1996. Automatic Foreign Words Recognition 
in a Serbian Scientific or Technical Text. In Pro-
ceedings of Standardisation of Terminology, Bel-
grade, Yugoslavia, 1996 
Vintar ?. 2000. Extracting Terms and Terminological 
Collocations from the ELAN Slovene-English Par-
allel Corpus. In Proceedings of the 5th EAMT 
Workshop, Ljubljana, Slovenia, 2000 
Vitas D. 1993. Mathematical Model of Serbo-
Croatian Morphology (Nominal Inflection). PhD 
thesis. Faculty of Mathematics, Belgrade. 
 
