Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 998?1008,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Cross-narrative temporal ordering of medical events
Preethi Raghavan
?
, Eric Fosler-Lussier
?
, No
?
emie Elhadad
?
and Albert M. Lai
?
?
The Ohio State University, Columbus, Ohio
?
Columbia University, New York, NY
{raghavap, fosler}@cse.ohio-state.edu
noemie.elhadad@columbia.edu, albert.lai@osumc.edu
Abstract
Cross-narrative temporal ordering of med-
ical events is essential to the task of gen-
erating a comprehensive timeline over a
patient?s history. We address the prob-
lem of aligning multiple medical event se-
quences, corresponding to different clin-
ical narratives, comparing the following
approaches: (1) A novel weighted finite
state transducer representation of medi-
cal event sequences that enables compo-
sition and search for decoding, and (2)
Dynamic programming with iterative pair-
wise alignment of multiple sequences us-
ing global and local alignment algorithms.
The cross-narrative coreference and tem-
poral relation weights used in both these
approaches are learned from a corpus of
clinical narratives. We present results us-
ing both approaches and observe that the
finite state transducer approach performs
performs significantly better than the dy-
namic programming one by 6.8% for the
problem of multiple-sequence alignment.
1 Introduction
Discourse structure, logical flow of sentences, and
context play a large part in ordering medical events
based on temporal relations within a clinical nar-
rative. However, cross-narrative temporal rela-
tion ordering is a challenging task as it is dif-
ficult to learn temporal relations among medical
events which are not part of the logically coherent
discourse of a single narrative. Resolving cross-
narrative temporal relationships between medical
events is essential to the task of generating an
event timeline from across unstructured clinical
narratives such as admission notes, radiology re-
ports, history and physical reports and discharge
summaries. Such a timeline has multiple applica-
tions in clinical trial recruitment (Luo et al, 2011),
medical document summarization (Bramsen et al,
2006, Reichert et al, 2010) and clinical decision
making (Demner-Fushman et al, 2009).
Given multiple temporally ordered medical
event sequences generated from each clinical nar-
rative in a patient record, how can we combine
the events to create a timeline across all the nar-
ratives? The tendency to copy-paste text and
summarize past information in newly generated
clinical narratives leads to multiple mentions of
the same medical event across narratives (Cohen
et al, 2013). These cross-narrative coreferences
act as important anchors for reasoning with in-
formation across narratives. We leverage cross-
narrative coreference information along with con-
fident cross-narrative temporal relation predictions
and learn to align and temporally order medical
event sequences across longitudinal clinical nar-
ratives. We model the problem as a sequence
alignment task and propose solving this using two
approaches. First, we use weighted finite state
machines to represent medical events sequences,
thus enabling composition and search to obtain
the most probable combined sequence of medical
events. As a contrast, we adapt dynamic program-
ming algorithms (Needleman et al, 1970, Smith
and Waterman, 1981) used to produce global and
local alignments for aligning sequences of med-
ical events across narratives. We also compare
the proposed methods with an Integer Linear Pro-
gramming (ILP) based method for timeline con-
struction (Do et al, 2012). The cross-narrative
coreference and temporal relation scores used in
both these approaches are learned from a corpus
of patient narratives from The Ohio State Univer-
sity Wexner Medical Center.
The main contribution of this paper is a general
framework that allows aligning multiple event se-
quences using cascaded weighted finite state trans-
ducers (WFSTs) with the help of efficient compo-
sition and decoding. Moreover, we demonstrate
that this method can be used for more accurate
multiple sequence alignment when compared to
998
dynamic programming or other ILP-based meth-
ods proposed in literature.
2 Related Work
In the areas of summarization and text-to-text gen-
eration, there has been prior work on several order-
ing strategies to order pieces of information ex-
tracted from different input documents (Barzilay
et al, 2002, Lapata, 2003, Bollegala et al, 2010).
In this paper, we focus on temporal ordering of in-
formation, as discussed next.
Recent state-of-the art research has focused on
the problem of temporal relation learning within
the same document, and in many cases within the
same sentence (Mani et al, 2006, Verhagen et al,
2009, Lapata and Lascarides, 2011). Chambers
and Jurafsky (2009) describe a process to induce
a partially ordered set of events related by a com-
mon protagonist by using an unsupervised distri-
butional method to learn relations between events
sharing coreferring arguments, followed by tem-
poral classification to induce partial order. The
task was carried out on the Timebank newswire
corpus, but was limited to an intra-document set-
ting. More recently, (Do et al, 2012) proposed
an ILP-based method to combine the outputs of
an event-interval and an event-event classifier for
timeline construction on the ACE 2005 corpus.
However, this approach is also restricted to events
within documents and requires annotations for
event intervals. We empirically compare our meth-
ods for timeline creation from longitudinal clinical
narratives to such an ILP-based approach in Sec-
tion 7. While a lot of this work has been done in
the news domain, there is also some recent work
in rule-based algorithms (Zhou et al, 2006) and
machine learning (Roberts et al, 2008) applied
to temporal relations between medical events in
clinical text. Clinical narratives are written in a
distinct sub-language with domain specific termi-
nology and temporal characteristics, making them
markedly different from newswire text.
There is limited prior work in learning re-
lations across documents. Ji and Grishman
(2008) extended the one sense per discourse idea
(Yarowsky, 1995) to multiple topically related
documents and propagate consistent event argu-
ments across sentences and documents. Barzi-
lay and McKeown (2005) propose a text-to-text
generation technique for synthesizing common in-
formation across documents using sentence fu-
sion. This involves multisequence dependency
tree alignment to identify phrases conveying sim-
ilar information and statistical generation to com-
bine common phrases into a sentence. Along with
syntactic features, they combine knowledge from
resources like WordNet to find similar sentences.
In case of clinical narratives and medical event
alignment, the objective is to identify a unique se-
quence of temporally ordered medical events from
across longitudinal clinical data.
To the best of our knowledge, there is no
prior work on cross-document alignment of event
sequences. Multiple sequence alignment is a
problem that arises in a variety of domains in-
cluding gene/protein alignments in bioinformat-
ics (Notredame, 2002), word alignments in ma-
chine translation (Kumar and Byrne, 2003), and
sentence alignments for summarization (Lacatusu
et al, 2004). Dynamic programming algorithms
have been popularly leveraged to produce pair-
wise and global genetic alignments, where edit
distance based metrics are used to compute the
cost of insertions, deletions and substitutions.
We use dynamic programming to compute the
best alignment, given the temporal and corefer-
ence information between medical events across
these sequences. More importantly, we propose
a cascaded WFST-based framework for cross-
document temporal ordering of medical event se-
quences. Composition and search operations can
be used to build a single transducer that inte-
grates these components, directly mapping from
input states to desired outputs, and obtain the best
alignment (Mohri et al, 2000). In natural lan-
guage processing, WFSTs have seen varied appli-
cations in machine translation (Kumar and Byrne,
2003), morphology (Sproat, 2006), named en-
tity recognition (Krstev et al, 2011) and biolog-
ical sequence alignment / generation (Whelan et
al., 2010) among others. We demonstrate that
the WFST-based approach outperforms popularly
used dynamic programming algorithms for multi-
ple sequence alignment.
3 Problem Description
Medical events are temporally-associated con-
cepts in clinical text that describe a medical con-
dition affecting the patient?s health, or procedures
performed on a patient. We represent medical
events by splitting each event into a start and a
stop. When there is insufficient information to dis-
cern the start or stop of an event, it is represented
as a single concept. If only the start is known then
the stop is set to +?, whereas when only the stop
is known , the start is set to the date of birth of the
999
e1 before e2 
e1 overlaps e2 
e1 during e2 
e1 starts with e2 
e1 finishes with e2 
e1 equals e2 
< e1.start e1.stop e2.start e2.stop 
e1.start e1.stop e2.start e2.stop 
e1.start e1.stop e2.start e2.stop 
e1.start e2.start e2.stop e1.stop 
e1.start e1.stop e2.stop e2.start 
e1.start e2.start e2.stop e1.stop 
< < 
< < < 
< < < 
< < ~ 
~ < < 
~ ~ < 
< denotes before   > denotes after ~ denotes simultaneous 
Temporal Relation Event Ordering 
Figure 1: Medical event start / stop representa-
tion mapped to Allen?s temporal relations (Allen,
1981). Temporal ordering of event starts and stops
using {before, after, simultaenous} (shown on the
right) allows us learn temporal relations between
the medical events (shown on the left). e1
start
=
e2
start
and e1
stop
= e2
stop
, when e1 and e2 core-
fer.
patient.
1
Often, for chronic ailments like hyper-
tension, we would only associate a start with the
medical event and set the stop to +?. The start of
hypertension may be associated with the temporal
expression history of in the narrative. This, when
considered along with the admission date, allows
us to relatively order hypertension with respect to
other medical events. A medical event occurrence
like chest pain may be associated with a start and
a stop, where the start may be determined by the
mention of ?patient was complaining of chest pain
yesterday? in the narrative text. Further, the nar-
rative may state that ?he continued to have chest
pain on admission, but currently he is chest pain
free?; this may be used to infer the relative stop of
chest pain. Medical events may also be instan-
taneous, for e.g., injected with antibiotic. Such
events are represented with the start and stop as
being the same. Temporal relations exist between
the start and stop of events as shown in Figure 1.
Learning temporal relations before, after and si-
multaneous between the medical event starts and
stops corresponds to learning all of Allen?s tem-
poral relations (Allen, 1981) between the medical
events. Following our previous work (Raghavan
et al, 2012c), such a representation allows us to
temporally order the event starts and stops within
each clinical narrative by learning to rank them in
relative order of time. The problem definition is as
follows:
1
Patient date of birth, admission/ discharge date are usu-
ally available in the metadata associated with a clinical nar-
rative.
dob +? 
dob 
+? 
hypertensionstart admission1 chest painstart chest painstop 
palpitationsstart myocardial infarctionstart  
MRSAstart admission2 
hypertensionstart 
heart attackstart 
dob +? cocaine usestart infectionstart  woundsstart admission3 
N1 
N2 
N3 
episodestart 
Figure 2: Given temporally ordered medical event
sequences, N
1
, N
2
, N
3
, we address the task of
combining events across these sequences by merg-
ing or ordering them to create a single comprehen-
sive timeline.
Input: Sequences of temporally ordered med-
ical event starts and stops. This corresponds to
N
1
, N
2
, and N
3
in Figure 2. Each sequence cor-
responds to a clinical narrative. The total number
of sequences correspond to the number of clinical
narratives for a patient.
Problem: Combine medical events across these
sequences to generate a timeline i.e., a single com-
prehensive sequence of medical events over all
clinical narratives of the patient.
Expected Output: In the example shown
in Figure 2, the output would be as follows:
Timeline (N
1
, N
2
, N
3
)= {cocaine use
start
<
hypertension
start
= hypertension
start
< admis-
sion1 < chest pain
start
? palpitations
start
<
chest pain
stop
< heart attack
start
= myocardial
infarction
start
< admission2 < infection
start
<
MRSA
start
< admission3 < wounds
start
}.
The goal of multiple sequence alignment is to
find an alignment that maximizes some overall
alignment score. Thus, in order to align event se-
quences, we need to compute scores correspond-
ing to cross-narrative medical event coreference
resolution and cross-narrative temporal relations.
4 Cross-Narrative Coreference
Resolution and Temporal Relation
Learning
The first approach to learning a temporal order-
ing of medical events across all clinical narratives
is to consider all pairs of events across all narra-
tives and learn to classify them as sharing one of
Allen?s temporal relations (Allen, 1981) using a
single learning model. Alternatively, a ranking ap-
1000
proach, similar to the one used to generate intra-
narrative temporal ordering, can also be extended
to the cross-narrative case. However, the features
related to narrative structure and relative and im-
plicit temporal expressions used for temporal or-
dering within a clinical narrative may not be ap-
plicable across narratives. For instance, a history
and physical report may have sections like ?past
medical history?, ?history of present illness?, ?as-
sessment and plan?, and a certain logical pattern
to the flow of text within and across these sec-
tions. Further, temporal cues like ?thereafter?,
?subsequently?, follow from the context around an
event mention. The absence of such features in the
cross-narrative case does not allow such a model
to generate accurate temporal relation predictions.
Thus, for use in our sequence alignment models,
we learn two independent classifiers for medical
event coreference and temporal relation learning
across narratives. We train a classifier to resolve
cross-narrative coreferences by extracting seman-
tic and temporal relatedness feature sets for each
pair of medical concepts. Extracting these fea-
ture sets helps us train a classifier to predict med-
ical event coreferences (Raghavan et al, 2012a).
Another classifier is then trained to classify pairs
of medical event starts and stops across narratives
as sharing temporal relations {before, after, over-
laps}. The learned cross-narrative coreference
predictions can then be used along with confi-
dent temporal relation predictions to derive a joint
probability to enable cross-narrative temporal or-
dering.
5 Narrative Sequence Alignment for
Cross-narrative Temporal Ordering
Sequence alignment algorithms have been de-
veloped and popularly used in bioinformatics.
However, multiple sequence alignment (MSA)
has been shown to be NP complete (Wang and
Jiang, 1994) and various heuristic algorithms have
been proposed to solve this problem (Notredame,
2002). We propose a novel WFST-based repre-
sentation that enables accurate decoding for MSA
when compared to popularly used dynamic pro-
gramming algorithms (Needleman et al, 1970,
Smith and Waterman, 1981) or other state of the
art methods (Do et al, 2012).
In the problem of aligning events across mul-
tiple narrative sequences, we want to align tem-
porally ordered medical events corresponding to
clinical narratives of a patient. Unlike problems
in biological sequence alignment where the sym-
chest painstart 
episodestart 
chest painstop 
episodestop 
< 
< 
a = x                             
a b 
x  y < b = y                             Score = P(a simult x | a coref x) P(a coref x )  
Figure 3: Score computation for aligning events
across temporally ordered event sequences chest
pain
start
= episode
start
< chest pain
stop
=
episode
stop
, where events across the sequences oc-
cur simultaneously and corefer.
chest painstart 
palpitationsstart 
chest painstop 
palpitationsstop 
< 
< 
a b 
x  y a ~  x                             < b   <     y                             
Score = P( a simult x | a no - coref x ) ?                     P( x before b | a no - coref x ) ?                                  P( b before  y | a no - coref x ) P( a no- coref x )   
Figure 4: Score computation for aligning events
across temporally ordered event sequences chest
pain
start
? palpitations
stop
< chest pain
stop
<
palpitations
stop
, where some events across the se-
quences occur simultaneously but do not corefer.
bols to be aligned across sequences are restricted
to a fixed set, our symbol set is not fixed or cer-
tain because the symbols correspond to medical
events in clinical narratives. Moreover, we can-
not have fixed scores for symbol transformations
since our transformations correspond to corefer-
ence and temporal relations between the medical
events across sequences. The computation of these
scores is described next.
5.1 Scoring Scheme
Let us assume a, b are medical events in the first
clinical narrative and have been temporally or-
dered so a < b. Similarly, x, y are medical events
in the second clinical narrative such that x < y.
There exists a match or an alignment between a
pair of medical events, across the sequences, in the
following cases:
1. If the medical events are simultaneous and
coreferring, denoted as a = x.
2. If the medical events are simultaneous and
non-coreferring, denoted as a ? x.
1001
hypertensionstart palpitationsstart < a b 
x  y a    <     x                             < b   <        y                              Score = P(a before  x |a no - coref x) P(a no - coref x) ?  P(x before  b | x no - coref b) P(x no - coref b) ?  P(b before  y | b no - coref y) P(b no - coref y)  
infectionstart MRSAtart < < 
Figure 5: Score computation for aligning
events across temporally ordered event se-
quences hypertension
start
< palpitations
start
<
infection
start
< MRSA
start
, where events across
the sequences do not occur simultaneously and do
not corefer.
3. If the a medical event from one sequence
is before a medical event from another se-
quence, denoted as a < x.
4. If the a medical event from one sequence is
after a medical event from another sequence,
denoted as a > x.
We now illustrate how the scores for candidate
aligned sequences are computed using the learned
cross-narrative coreference and temporal probabil-
ities for the following three scenarios:
? The medical events across sequences are si-
multaneous and corefer as illustrated in Fig-
ure 3. The joint score considers the probabil-
ity of event temporal relations simultaneous
conditioned on coreference.
? Some medical events across sequences are si-
multaneous but do not corefer as illustrated in
Figure 4. Here, the joint score considers the
joint probability of temporal relations simul-
taneous or before and no-coreference.
? The medical events across sequences are not
simultaneous and do not corefer as illustrated
in Figure 5. In this case, the joint score con-
siders the probability of the temporal relation
before and no coreference.
Thus, the coreference and temporal relation scores
can be leveraged for aligning sequences of medical
events. These scores are used in both the WFST-
based representation and decoding, as well as for
dynamic programming.
5.2 Alignment using a Weighted Finite State
Representation
A weighted finite-state transducer (WFST) is an
automaton in which each transition between states
is associated with an input symbol, an output sym-
bol, and a weight (Mohri et al, 2005). WFSTs can
be used to efficiently represent and combine se-
quences of medical events based coreference and
temporal relation information. The WFST rep-
resentation gives us the ability to talk about the
global joint probability derived from coreference
and temporal relation scores described in Section
5.1. It allows us to build a weighted lattice of se-
quences that can be searched for the most probable
sequence of medical events from across all clin-
ical narratives of a patient. We use unweighted
FSAs to represent the input described in Section
3, i.e. temporally ordered sequences of medical
events corresponding to clinical narratives. This
corresponds to N
1
and N
2
in Figure 6.
Based on whether we want to align the se-
quences purely based on coreference scores or
both coreference and temporal relation scores, the
arc weights for the WFST can be determined. M
c
12
is a WFST that maps input symbols from N
1
to
output symbols inN
2
and is weighted by the prob-
ability of coreference or no-coreference between
medical events across N
1
and N
2
. The represen-
tation in WFST M
c+t
12
shown in Figure 7 allows
us to align N
1
and N
2
based on both coreference
as well as temporal relation probabilities. The
WFST has  transitions to accommodate insertion
and deletion of medical events when combining
the sequences. Deletions correspond to the case
when an event in the first sequence does not map
to any event in the second sequence; similarly in-
sertions correspond to the case where an event in
the second sequence does not map to any event in
the first sequence. The WFST composition opera-
tion allows the outputs of one WFST to be fed to
the inputs of a second WFST or FSA. Thus, we
build our final machine by composing the three
sub-machines as,
D = N
1
?M
i
12
?N
2
. (1)
where i = c or i = c + t. This gives us a com-
bined weighted graph by mapping the output sym-
bols of the first medical event sequence to the in-
put symbols of the second medical event sequence.
The scores on the decoding graph are derived from
only the coreference probabilities if i = c and both
coreference and temporal relation probabilities if
i = c+ t.
In the medical event sequence alignment prob-
lem, we want to align multiple sequences of medi-
cal events that correspond to multiple clinical nar-
ratives of a patient. Since we want to now combine
1002
N1 
N2 
M12 
Figure 6: N
1
and N
2
are medical event sequences represented using FSAs. M
c
12
maps medical events
across N
1
and N
2
and is weighted only by the probability of coreference between events across N
1
and
N
2
.
0
c
o
c
a
in
eu
se
:-
/0
.1
3
hy
pe
rt
en
si
on
:-
/0
.2
7
c
he
st
pa
in
:-
/0
.2
3
1
-
:c
o
c
a
in
ea
bu
se
/0
.1
c
o
c
a
in
eu
se
:c
oc
ai
ne
ab
us
e/
0.
9
hy
pe
rt
en
si
on
:c
oc
ai
ne
ab
us
e/
0.
4
c
he
st
pa
in
:c
oc
ai
ne
ab
us
e/
0.
3
c
o
c
a
in
eu
se
:-
/0
.1
3
hy
pe
rt
en
si
on
:-
/0
.2
4
c
he
st
pa
in
:-
/0
.2
3
2
-
:a
dm
is
si
on
/0
.1
c
o
c
a
in
eu
se
:a
dm
is
si
on
/0
.1
hy
pe
rt
en
si
on
:a
dm
is
si
on
/0
.1
c
he
st
pa
in
:a
dm
is
si
on
/0
.1
c
o
c
a
in
eu
se
:-
/0
.1
3
hy
pe
rt
en
si
on
:-
/0
.2
4
c
he
st
pa
in
:-
/0
.2
3
3
-
:c
he
st
pa
in
/0
.1
c
o
c
a
in
eu
se
:c
he
st
pa
in
/0
.1
7
hy
pe
rt
en
si
on
:c
he
st
pa
in
/0
.2
3
c
he
st
pa
in
:c
he
st
pa
in
/0
.8
6
c
o
c
a
in
eu
se
:-
/0
.1
3
hy
pe
rt
en
si
on
:-
/0
.2
4
c
he
st
pa
in
:-
/0
.2
3
4
/4
-
:m
y
o
ca
rd
ia
li
nf
ar
ct
io
n/
0.
1
c
o
c
a
in
eu
se
:m
yo
ca
rd
ia
li
nf
ar
ct
io
n/
0.
2
hy
pe
rt
en
si
on
:m
yo
ca
rd
ia
li
nf
ar
ct
io
n/
0.
1
c
he
st
pa
in
:m
yo
ca
rd
ia
li
nf
ar
ct
io
n/
0.
1
c
o
c
a
in
eu
se
:-
/0
.1
3
hy
pe
rt
en
si
on
:-
/0
.2
4
c
he
st
pa
in
:-
/0
.2
3
Figure 7: M
c+t
12
is a WFST representation used for mapping medical events between N
1
and N
2
(from
Figure 2) and is weighted by both the coreference and temporal relation probabilities
all narrative chains belonging to the same patient,
the composition cascade to build the final com-
bined sequence will be as,
D
f
= N
1
?M
i
12
?N
2
?M
i
23
?N
3
?M
i
34
...?N
n
(2)
where i = c or i = c + t and n is the number
of medical event sequences corresponding to clin-
ical narratives for a patient. During composition
we retain intermediate paths like M
i
23
utilizing the
ability to do lazy composition (Mohri and Pereira,
1998) in order to facilitate beam search through
the multi-alignment. The best hypothesis corre-
sponds to the highest scoring path which can be
obtained using shortest path algorithms like Djik-
stra?s algorithm. The best path corresponds to the
best alignment across all medical event sequences
based on the joint probability of cross-narrative
medical event coreferences and temporal relations
across the narrative sequences.
The complexity of decoding increases exponen-
tially with the number of narrative sequences in
the composition, and exact decoding becomes in-
feasible. One solution to this problem is to do
the alignment greedily pairwise, starting from the
most recent medical event sequences, finding the
best path, and iteratively moving on to the next
sequence, and proceeding until the oldest medi-
cal event sequence. The disadvantage of such a
method is that it does not take into account con-
straints between medical events across multiple
event sequences and may lead to a less accurate
solution.
An alternative method is to use lazy compo-
sition to perform more efficient composition as
it allows practical memory usage. We also use
beam search to make for an efficient approxima-
tion to the best-path computation (Mohri et al,
2005). This allows accommodating constraints
from across multiple sequences and generates a
more accurate best path. Thus, this method gener-
ates more accurate alignments when we have more
than two sequences to be aligned.
1003
For instance, instance say a, b ? N
1
, x, y ? N
2
,
and m,n ? N
3
are temporally medical event se-
quences corresponding to narratives N
1
, N
2
and
N
3
. Based on the learned pairwise temporal rela-
tions, if we have the following constraints a < x,
m > x, m < a. Aligning N
1
and N
2
greedily
pairwise may give us the best combined sequence
as a, x, b, y ? N
12
. Now in aligning N
12
with
N
3
, we won?t be able to accommodate m > x and
m < a. However, performing a beam search over
the composed WFST in equation 2 allows us to
accommodate such constraints across multiple se-
quences. The complexity of composing two trans-
ducers is O(V
1
V
2
D
1
(logD
2
+ M
2
)) where each
edge from the first sequence matches every edge in
the second sequence and V
i
is the number of states,
D
i
is the maximum out-degree and M
i
maximum
multiplicity for the i
th
FST (Mohri et al, 2005).
We also use popular dynamic programming al-
gorithms (Needleman et al, 1970, Smith and Wa-
terman, 1981) for sequence alignment of medi-
cal events across narratives and compare it to the
WFST-based representation and decoding.
5.3 Pairwise Alignment using Dynamic
Programming
As a contrast, we adapt two dynamic program-
ming algorithms for sequence alignment: global
alignment using the Needleman Wunsch algo-
rithm (NW) (Needleman et al, 1970) and local
alignment using the Smith-Waterman algorithm
(SW) (Smith and Waterman, 1981). NW allows
us to align all events in one sequence with all
events in another sequence. A drawback of NW
is that short and highly similar sequences maybe
missed because they get overweighted by the rest
of the sequence. NW is suitable when the two se-
quences are of similar length with significant de-
gree of similarity throughout. On the other hand,
SW gives the longest sub-sequence pair that yields
maximum degree of similarity between the two
original sequences. It does not force all events
in a sequence to align with another sequence.
SW is useful in aligning sequences that differ in
length and have short patches of similarity. The
time complexity of these methods for sequences
of length m and n are O(mn).
The scoring scheme described earlier is used to
update the scoring matrix for dynamic program-
ming. In order to accommodate the temporal re-
lations before and after, we insert a null symbol
after every medical event in each sequence in the
scoring matrix. A vertical or horizontal gap arises
when cases 1, 2, 3 and 4 in Section 5.1 mentioned
above are not true. If the medical events are not
simultaneous, not before or not after, the medical
events will not align. Thus, the value of each cell
in the scoring matrix is determined by computing
the maximum score at each position C(i, j) as,
max{(C(i?1, j?1)+S
ij
), (C(i, j?1)+w),
(C(i? 1, j) + w)} (3)
where, S
ij
= max{P (i = j), P (i < j), P (i >
j)}, and w = max{(1 ? P (i = j)), (1 ? P (i <
j)), (1 ? P (i > j))}. Here, C(i ? 1, j ? 1)
corresponds to a match, whereas C(i, j ? 1) and
C(i ? 1, j) correspond to a gaps in sequence one
and two.
In case of the SW algorithm, the negative scor-
ing matrix cells are set to zero, thus making the
positively scoring local alignments visible. Back-
tracking starts at the highest scoring matrix cell
and proceeds until a cell with score zero is encoun-
tered, yielding the highest scoring local alignment.
The time and space complexity grows exponen-
tially with the number of sequences to be aligned
and finding the global optimum has been shown to
be a NP-complete problem. The time complexity
of aligning N sequences of length L is O(2
N
L
N
)
(Wang and Jiang, 1994). Thus, for MSA using
dynamic programming, we use a heuristic method
where we combine pairwise alignments iteratively
starting with the latest narrative and progressing
towards the oldest narrative.
6 Experiments and Evaluation
Corpus Description. The corpus consists of a
dataset of clinical narratives obtained from the
[redacted] medical center. The corpus has a total
of 2060 patients, and 100704 clinical narratives.
We gathered a gold standard set of seven patients
(80 clinical narratives overall) with manual anno-
tation of all medical events mentioned in the nar-
ratives, coreferences, and medical event sequence
information. The annotation agreement across
annotators is high, with 89.5% agreement corre-
sponding to inter-annotator Cohen?s kappa statis-
tic of 0.86 (Raghavan et al, 2012b). The types
of clinical narratives included 27 discharge sum-
maries, 30 history and physical reports, 15 radiol-
ogy reports and 8 pathology reports. The distribu-
tion of the number of medical event sequences and
unique medical events across patients is shown in
Table 1. The annotated dataset is used to cross-
validate and train our coreference and temporal re-
lation learning models and to evaluate our cross-
narrative medical event timeline.
1004
p1 p2 p3 p4 p5 p6 p7
No. of Narrative Sequences 5 9 20 13 8 10 15
No. of Medical events 68 90 119 82 79 72 95
% Accuracy % Avg.
WFST-framework (lazy composition and beam search)[c+t] 76.1 73.2 81.2 83.5 76.4 82.5 79.7 78.9
WFST-framework (Iterative pairwise)[c+t] 70.4 67.1 73.5 74.1 61.8 75.5 62.9 69.3
Smith Waterman (Iterative pairwise)[c+t] 71.2 69.7 75.5 75.6 66.3 77.4 68.3 72.1
Needleman-Wunsch (Iterative pairwise)[c+t] 68.1 66.3 72.1 74.4 61.1 75.5 63.6 68.7
WFST-framework (lazy composition and beam search)[c] 68.5 65.3 72.3 74.4 67.2 71.3 69.1 69.7
WFST-framework (Iterative pairwise)[c] 61.2 63.3 61.9 60.4 59.8 64.8 60.5 61.7
Smith Waterman (Iterative pairwise)[c] 60.3 63.7 68.2 62.3 58.6 66.7 60.2 62.8
Needleman-Wunsch (Iterative pairwise)[c] 56.6 60.1 59.3 65.6 54.7 63.1 58.2 59.6
Table 1: The distribution of medical events across narrative sequences and sequences across patients and
multiple sequence alignment results for the WFST-based framework, and dynamic programming using
just coreference scores [c] and using coreference as well as temporal relation scores [c+t].
Evaluation Metric. For each patient and each
method (WFST or dynamic programming), the
output timeline to evaluate is the highest scoring
candidate hypothesis derived as described above.
Accuracy of the timeline is calculated as the num-
ber of transformations required to obtain the refer-
ence sequence in the annotated gold-standard from
the one generated by our system. Transformations
are measured in terms of the minimum edit dis-
tance, insertions, deletions, and substitutions of
medical events.
Experiments and Results. We first temporally
order medical events within each clinical narrative
by learning to rank them in relative order of oc-
curence as described in our previous work (Ragha-
van et al, 2012c). The overall accuracy of rank-
ing medical events using leave-one-out cross val-
idation is 82.1%. The resulting medical event se-
quences serve as the input to the problem of cross-
narrative sequence alignment.
The cross-narrative coreference and temporal
relation pairwise classification models described
in Section 4 are trained using a Maximum en-
tropy classifier. The coreference resolution per-
forms with 71.5% precision and 82.3% recall. The
temporal relation classifier performs with 60.2%
precision and 76.3% recall. The learned pairwise
coreference and temporal relation probabilities are
now used to derive the score for the WFST and dy-
namic programming approaches.
WFST representation and decoding. We
build finite-state machines using the open source
OpenFST library.
2
We use a tropical semi-ring
weighted using the negative log-likelihood of the
computed scores. OpenFST provides tools that
can search for the highest scoring sequences ac-
cepted by the machine, and can sample from high-
scoring sequences probabilistically, by treating the
2
www.openfst.org
scores of each transition within the machine as a
negative log probability. The decoding process to
compute the most likely combined medical event
sequence can be defined as searching for the best
path in the combined graph representation (Equa-
tion 2). The best path is the one that minimizes
the total weight on a path (since the arcs are neg-
ative log probabilities). In searching for the best
path, the beam size is set to 5. The accuracy of
the WFST-based representation and beam search
across all sequences using the coreference and
temporal relation scores to obtain the combined
aligned sequence is 78.9%.
Dynamic Programming. We use the NW and
SW algorithms described in Section 5.3 to pro-
duce local and global alignments respectively. We
use the scoring scheme described in Section 5.1 to
update the cost matrix for dynamic programming
and implement the algorithms as described in Sec-
tion 5.3. The overall accuracy of sequence align-
ment with both coreference and temporal relation
scores using NW is 68.7% whereas SW gives an
accuracy of 72.1%. In case of aligning just two
sequences, both methods yield the same results.
The accuracy of cross-narrative MSA for each pa-
tient, for each method, using cross validation, is
shown in Table 1. Results indicate that the WFST-
based method outperforms the dynamic program-
ming approach for multi-sequence alignment (sta-
tistical significance p<0.05). Morever, the re-
sults using both coreference and temporal realtion
scores for alignment outperform using only coref-
erence scores for alignment using all approaches.
This indicates that cross-narrative temporal rela-
tions are important for accurately aligning medical
event sequences across narratives.
7 Discussion
We propose and evaluate different approaches to
multiple sequence alignment of medical events.
1005
Approaches to multi-alignment. We address
the problem of aligning medical event sequences
using a novel WFST-based framework and empiri-
cally demonstrate that it outperforms pairwise pro-
gressive alignment using dynamic programming.
This is mainly because the WFST-based allows us
to consider temporal constraints from across mul-
tiple sequences when performing the alignment.
Moreover, it also outperforms the integer lin-
ear programming (ILP) method for timeline con-
struction proposed in (Do et al, 2012). We im-
plemented the proposed method that also allows
combining the output of classifiers subject to some
constraints. We derive intervals from event starts
and stops and learn two perceptron classifiers for
classifying the temporal relations between events
and assigning events to intervals. The classifier
probabilities are then used to solve the optimiza-
tion problem using the lpsolve solver.
3
We also
use intra-document coreference information to re-
solve coreference before performing the global op-
timization. We observe that in case of MSA, the
optimal solution using ILP is still intractable as
the number of constraints increases exponentially
with the number of sequences. Aligning pair-
wise iteratively gives us an overall average accu-
racy of 68.2% similar to dynamic programming.
While this is comparable to the dynamic pro-
gramming performance, the WFST-based method
significantly outperforms this in case of multi-
alignments for cross-narrative temporal ordering.
Performance and error analysis. We perform
multi-alignments over medical event sequences
for a patient, where each sequence corresponds
to temporally ordered medical events in a clinical
narrative generated using the ranking model de-
scribed in (Raghavan et al, 2012c). The accuracy
of intra-narrative temporal ordering is 82.1%. The
errors in performing this intra-narrative ordering
may propagate to the cross-narrative model result-
ing in reduced accuracy. This may be addressed
by considering n-best temporally ordered medi-
cal event sequences, generated by the ranking pro-
cess, and aligning the n-best sequences using the
WFST-based framework. This could be feasible
as, practically, the WFST-based method for multi-
alignment takes only a few secs to align a pair of
medical event sequences with average length 40.
The accuracy of alignments across multiple
medical event sequences is also affected by the er-
ror induced by the coreference and temporal rela-
tion scores. Often, insufficient temporal cues leads
3
http://lpsolve.sourceforge.net/5.5/
to misclassification of events incorrectly as shar-
ing the ?simultaneous? temporal relation and often
as coreferring. This induces errors in the score cal-
culation and hence the alignments. Better meth-
ods to address the challenging problem of cross-
document temporal relation learning, perhaps with
the help of structured data from the patient record,
could improve the accuracy of alignments.
There is no clear trend with respect to the num-
ber of medical events and narratives for a patient
(Table 1.), and the alignment accuracy. In fu-
ture work, it would be interesting to examine any
such correlation and also study the scalability of
the WFST-based method for sequence alignment
on longer medical event sequences and a larger
dataset of patients. Further, the WFST-based
method may be used to model multi-alignment
tasks in other speech and language problems as
well.
8 Conclusion
We propose a novel framework for aligning med-
ical event sequences across clinical narratives
based on coreference and temporal relation infor-
mation using cascaded WFSTs. FSTs provide a
convenient and flexible framework to model se-
quences of temporally ordered medical events and
compose them into a combined graph represen-
tation. Decoding this graph allows us to jointly
maximize coreference as well as temporal relation
probabilities to derive a timeline of the most likely
temporal ordering of medical events. This ap-
proach to aligning multiple sequences of medical
events significantly outperforms other approaches
such as dynamic programming. Moreover, we
demonstrate the importance of learning tempo-
ral relations for the task timeline generation from
across multiple clinical narratives by empirically
proving that decoding using both coreference and
temporal relation scores is far more accurate than
decoding with only coreference scores.
Acknowledgments
The project was supported by Award Number
Grant R01LM011116 from the National Library
of Medicine. The content is solely the responsibil-
ity of the authors and does not necessarily repre-
sent the official views of the National Library of
Medicine or the National Institutes of Health. The
authors would like to thank Yanzhang He for his
input on the WFST-based model.
1006
References
James F. Allen. 1981. An interval-based representa-
tion of temporal knowledge. In IJCAI, pages 221?
226.
Regina Barzilay and Kathleen R. McKeown. 2005.
Sentence fusion for multidocument news sum-
marization. Comput. Linguist., 31(3):297?328,
September.
Regina Barzilay, Noemie Elhadad, and Kathleen McK-
eown. 2002. Inferring strategies for sentence or-
dering in multidocument summarization. Journal of
Artificial Intelligence Research (JAIR), 17:35?55.
Danushka Bollegala, Naoaki Okazaki, and Mitsuru
Ishizuka. 2010. A bottom-up approach to sentence
ordering for multi-document summarization. Infor-
mation processing & management, 46(1):89?109.
Philip Bramsen, Pawan Deshpande, Yoong Keok Lee,
and Regina Barzilay. 2006. Inducing temporal
graphs. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ?06, pages 189?198.
Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
pervised learning of narrative schemas and their par-
ticipants. In ACL/AFNLP, pages 602?610.
Raphael Cohen, Michael Elhadad, and No?emie El-
hadad. 2013. Redundancy in electronic health
record corpora: analysis, impact on text mining per-
formance and mitigation strategies. BMC bioinfor-
matics, 14(1):10.
Dina Demner-Fushman, Wendy Webber Chapman, and
Clement J. McDonald. 2009. What can natural lan-
guage processing do for clinical decision support?
Journal of Biomedical Informatics, 42(5):760?772.
Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint
inference for event timeline construction. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, EMNLP-
CoNLL ?12, pages 677?687. Association for Com-
putational Linguistics.
Heng Ji and Ralph Grishman. 2008. Refining event
extraction through cross-document inference. In As-
sociation for Computational Linguistics.
Cvetana Krstev, Du?sko Vitas, Ivan Obradovi?c, and
Milo?s Utvi?c. 2011. E-dictionaries and Finite-state
automata for the recognition of named entities. In
Proceedings of the 9th International Workshop on
Finite State Methods and Natural Language Pro-
cessing, pages 48?56.
Shankar Kumar and William Byrne. 2003. A weighted
finite state transducer implementation of the align-
ment template model for statistical machine trans-
lation. In Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology - Volume 1, pages 63?70.
V Finley Lacatusu, Steven J Maiorano, and Sanda M
Harabagiu. 2004. Multi-document summarization
using multiple-sequence alignment. In LREC.
Mirella Lapata and Alex Lascarides. 2011. Learn-
ing sentence-internal temporal relations. CoRR,
abs/1110.1394.
Mirella Lapata. 2003. Probabilistic text structuring:
Experiments with sentence ordering. In Proceed-
ings of the 41st Annual Meeting on Association for
Computational Linguistics-Volume 1, pages 545?
552. Association for Computational Linguistics.
Zhihui Luo, Stephen B. Johnson, Albert M. Lai, and
Chunhua Weng. 2011. Extracting temporal con-
straints from clinical research eligibility criteria us-
ing conditional random fields. In Proc of AMIA
Symposium.
Inderjeet Mani, Marc Verhagen, Ben Wellner,
Chong Min Lee, and James Pustejovsky. 2006.
Machine learning of temporal relations. In ACL.
Mehryar Mohri and Fernando CN Pereira. 1998. Dy-
namic compilation of weighted context-free gram-
mars. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Compu-
tational Linguistics-Volume 2, pages 891?897. As-
sociation for Computational Linguistics.
Mehryar Mohri, Fernando C. N. Pereira, and Michael
Riley. 2000. The design principles of a weighted
finite-state transducer library. Theoretical Computer
Science, 231(1):17?32.
Mehryar Mohri, Fernando Pereira, and Michael Riley.
2005. Weighted automata in text and speech pro-
cessing. CoRR, abs/cs/0503077.
S.B. Needleman, C.D. Wunsch, et al 1970. A general
method applicable to the search for similarities in
the amino acid sequence of two proteins. Journal of
molecular biology, 48(3):443?453.
C?edric Notredame. 2002. Recent progress in multiple
sequence alignment: a survey. Pharmacogenomics,
3(1):131?144.
Preethi Raghavan, Eric Fosler-Lussier, and Albert M.
Lai. 2012a. Exploring semi-supervised coreference
resolution of medical concepts using semantic and
temporal features. In North American Association
for Computational Linguistics Annual Meeting - Hu-
man Language Technologies Conference. Associa-
tion for Computational Linguistics.
Preethi Raghavan, Eric Fosler-Lussier, and Albert M.
Lai. 2012b. Inter-annotator reliability of medi-
cal events, coreferences and temporal relations in
clinical narratives by annotators with varying levels
of clinical expertise. In To appear in Proceedings
1007
of the American Medical Informatics Association.
American Medical Informatics Association.
Preethi Raghavan, Eric Fosler-Lussier, and Albert M.
Lai. 2012c. Learning to temporally order medical
events in clinical text. In ACL short paper. Associa-
tion for Computational Linguistics.
Daniel Reichert, David Kaufman, Benjamin Bloxham,
Herbert Chase, and No?emie Elhadad. 2010. Cog-
nitive analysis of the summarization of longitudinal
patient records. In AMIA Annual Symposium Pro-
ceedings, volume 2010, page 667. American Medi-
cal Informatics Association.
A. Roberts, R. Gaizauskas, M. Hepple, G. Demetriou,
Y. Guo, and A. Setzer. 2008. Semantic Annotation
of Clinical Text: The CLEF Corpus. In Proceedings
of the LREC 2008 Workshop on Building and Eval-
uating Resources for Biomedical Text Mining, pages
19?26.
T.F. Smith and M.S. Waterman. 1981. Identifica-
tion of common molecular subsequences. Journal
of molecular biology, 147(1).
Richard Sproat. 2006. A Computational Theory of
Writing Systems (Studies in Natural Language Pro-
cessing). Cambridge University Press.
Marc Verhagen, Robert J. Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James
Pustejovsky. 2009. The tempeval challenge: iden-
tifying temporal relations in text. Language Re-
sources and Evaluation, 43(2):161?179.
Lusheng Wang and Tao Jiang. 1994. On the complex-
ity of multiple sequence alignment. Journal of com-
putational biology, 1(4):337?348.
Christopher Whelan, Brian Roark, and Kemal Son-
mez. 2010. Designing antimicrobial peptides with
weighted finite-state transducers. In Proceedings of
IEEE Engineering in Medical Biology Society, page
764.
David Yarowsky. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. In Asso-
ciation for Computational Linguistics, pages 189?
196.
Li Zhou, Genevieve B. Melton, Simon Parsons, and
George Hripcsak. 2006. A temporal constraint
structure for extracting temporal information from
clinical narrative. Journal of Biomedical Informat-
ics, pages 424?439.
1008
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 54?62,
Dublin, Ireland, August 23-24, 2014.
SemEval-2014 Task 7: Analysis of Clinical Text
Sameer Pradhan
1
, No
?
emie Elhadad
2
, Wendy Chapman
3
,
Suresh Manandhar
4
and Guergana Savova
1
1
Harvard University, Boston, MA,
2
Columbia University, New York, NY
3
University of Utah, Salt Lake City, UT,
4
University of York, York, UK
{sameer.pradhan,guergana.savova}@childrens.harvard.edu, noemie.elhadad@columbia.edu,
wendy.chapman@utah.edu, suresh@cs.york.ac.uk
Abstract
This paper describes the SemEval-2014,
Task 7 on the Analysis of Clinical Text
and presents the evaluation results. It fo-
cused on two subtasks: (i) identification
(Task A) and (ii) normalization (Task B)
of diseases and disorders in clinical reports
as annotated in the Shared Annotated Re-
sources (ShARe)
1
corpus. This task was
a follow-up to the ShARe/CLEF eHealth
2013 shared task, subtasks 1a and 1b,
2
but
using a larger test set. A total of 21 teams
competed in Task A, and 18 of those also
participated in Task B. For Task A, the
best system had a strict F
1
-score of 81.3,
with a precision of 84.3 and recall of 78.6.
For Task B, the same group had the best
strict accuracy of 74.1. The organizers
have made the text corpora, annotations,
and evaluation tools available for future re-
search and development at the shared task
website.
3
1 Introduction
A large amount of very useful information?both
for medical researchers and patients?is present
in the form of unstructured text within the clin-
ical notes and discharge summaries that form a
patient?s medical history. Adapting and extend-
ing natural language processing (NLP) techniques
to mine this information can open doors to bet-
ter, novel, clinical studies on one hand, and help
patients understand the contents of their clini-
cal records on the other. Organization of this
1
http://share.healthnlp.org
2
https://sites.google.com/site/shareclefehealth/
evaluation
3
http://alt.qcri.org/semeval2014/task7/
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
shared task helps establish state-of-the-art bench-
marks and paves the way for further explorations.
It tackles two important sub-problems in NLP?
named entity recognition and word sense disam-
biguation. Neither of these problems are new to
NLP. Research in general-domain NLP goes back
to about two decades. For an overview of the
development in the field through roughly 2009,
we refer the refer to Nadeau and Sekine (2007).
NLP has also penetrated the field of bimedical
informatics and has been particularly focused on
biomedical literature for over the past decade. Ad-
vances in that sub-field has also been documented
in surveys such as one by Leaman and Gonza-
lez (2008). Word sense disambiguation also has
a long history in the general NLP domain (Nav-
igli, 2009). In spite of word sense annotations in
the biomedical literature, recent work by Savova
et al. (2008) highlights the importance of annotat-
ing them in clinical notes. This is true for many
other clinical and linguistic phenomena as the var-
ious characteristics of the clinical narrative present
a unique challenge to NLP. Recently various ini-
tiatives have led to annotated corpora for clini-
cal NLP research. Probably the first comprehen-
sive annotation performed on a clinical corpora
was by Roberts et al. (2009), but unfortunately
that corpus is not publicly available owing to pri-
vacy regulations. The i2b2 initiative
4
challenges
have focused on such topics as concept recog-
nition (Uzuner et al., 2011), coreference resolu-
tion (Uzuner et al., 2012), temporal relations (Sun
et al., 2013) and their datasets are available to the
community. More recently, the Shared Annotated
Resources (ShARe)
1
project has created a corpus
annotated with disease/disorder mentions in clini-
cal notes as well as normalized them to a concept
unique identifier (CUI) within the SNOMED-CT
subset of the Unified Medical Language System
5
4
http://www.i2b2.org
5
https://uts.nlm.nih.gov/home.html
54
Train Development Test
Notes 199 99 133
Words 94K 88K 153K
Disorder mentions 5,816 5,351 7,998
CUI-less mentions 1,639 (28%) 1,750 (32%) 1,930 (24%)
CUI-ied mentions 4,117 (72%) 3,601 (67%) 6,068 (76%)
Contiguous mentions 5,165 (89%) 4,912 (92%) 7,374 (92%)
Discontiguous mentions 651 (11%) 439 (8%) 6,24 (8%)
Table 1: Distribution of data in terms of notes and disorder mentions across the training, development
and test sets. The disorders are further split according to two criteria ? whether they map to a CUI or
whether they are contiguous.
(UMLS) (Campbell et al., 1998). The task of nor-
malization is a combination of word/phrase sense
disambiguation and semantic similarity where a
phrase is mapped to a unique concept in an on-
tology (based on the description of that concept in
the ontology) after disambiguating potential am-
biguous surface words, or phrases. This is espe-
cially true with abbreviations and acronyms which
are much more common in clinical text (Moon et
al., 2012). The SemEval-2014 task 7 was one of
nine shared tasks organized at the SemEval-2014.
It was designed as a follow up to the shared tasks
organized during the ShARe/CLEF eHealth 2013
evaluation (Suominen et al., 2013; Pradhan et al.,
2013; Pradhan et al., 2014). Like the previous
shared task, we relied on the ShARe corpus, but
with more data for training and a new test set. Fur-
thermore, in this task, we provided the options to
participants to utilize a large corpus of unlabeled
clinical notes. The rest of the paper is organized as
follows. Section 2 describes the characteristics of
the data used in the task. Section 3 describes the
tasks in more detail. Section 4 explains the evalu-
ation criteria for the two tasks. Section 5 lists the
participants of the task. Section 6 discusses the re-
sults on this task and also compares them with the
ShARe/CLEF eHealth 2013 results, and Section 7
concludes.
2 Data
The ShARe corpus comprises annotations over
de-identified clinical reports from a US intensive
care department (version 2.5 of the MIMIC II
database
6
) (Saeed et al., 2002). It consists of
discharge summaries, electrocardiogram, echocar-
diogram, and radiology reports. Access to data
was carried out following MIMIC user agreement
requirements for access to de-identified medical
6
http://mimic.physionet.org ? Multiparameter Intelligent
Monitoring in Intensive Care
data. Hence, all participants were required to reg-
ister for the evaluation, obtain a US human sub-
jects training certificate
7
, create an account to the
password-protected MIMIC site, specify the pur-
pose of data usage, accept the data use agree-
ment, and get their account approved. The anno-
tation focus was on disorder mentions, their var-
ious attributes and normalizations to an UMLS
CUI. As such, there were two parts to the annota-
tion: identifying a span of text as a disorder men-
tion and normalizing (or mapping) the span to a
UMLS CUI. The UMLS represents over 130 lex-
icons/thesauri with terms from a variety of lan-
guages and integrates resources used world-wide
in clinical care, public health, and epidemiology.
A disorder mention was defined as any span of text
which can be mapped to a concept in SNOMED-
CT and which belongs to the Disorder semantic
group
8
. It also provided a semantic network in
which every concept is represented by its CUI
and is semantically typed (Bodenreider and Mc-
Cray, 2003). A concept was in the Disorder se-
mantic group if it belonged to one of the follow-
ing UMLS semantic types: Congenital Abnormal-
ity; Acquired Abnormality; Injury or Poisoning;
Pathologic Function; Disease or Syndrome; Men-
tal or Behavioral Dysfunction; Cell or Molecu-
lar Dysfunction; Experimental Model of Disease;
Anatomical Abnormality; Neoplastic Process; and
Signs and Symptoms. The Finding semantic type
was left out as it is very noisy and our pilot study
showed lower annotation agreement on it. Follow-
ing are the salient aspects of the guidelines used to
7
The course was available free of charge on the Internet, for example,
via the CITI Collaborative Institutional Training Initiative at
https://www.citiprogram.org/Default.asp
or, the US National Institutes of Health (NIH) at
http://phrp.nihtraining.com/users.
8
Note that this definition of Disorder semantic group did not include the
Findings semantic type, and as such differed from the one of UMLS Seman-
tic Groups, available at http://semanticnetwork.nlm.nih.gov/
SemGroups
55
annotate the data.
? Annotations represent the most specific dis-
order span. For example, small bowel ob-
struction is preferred over bowel obstruction.
? A disorder mention is a concept in the
SNOMED-CT portion of the Disorder se-
mantic group.
? Negation and temporal modifiers are not con-
sidered part of the disorder mention span.
? All disorder mentions are annotated?even
the ones related to a person other than the pa-
tient and including acronyms and abbrevia-
tions.
? Mentions of disorders that are coreferen-
tial/anaphoric are also annotated.
Following are a few examples of disorder men-
tions from the data.
Patient found to have lower extremity DVT. (E1)
In example (E1), lower extremity DVT is marked
as the disorder. It corresponds to CUI C0340708
(preferred term: Deep vein thrombosis of lower
limb). The span DVT can be mapped to CUI
C0149871 (preferred term: Deep Vein Thrombo-
sis), but this mapping would be incorrect because
it is part of a more specific disorder in the sen-
tence, namely lower extremity DVT.
A tumor was found in the left ovary. (E2)
In example (E2), tumor ... ovary is annotated as a
discontiguous disorder mention. This is the best
method of capturing the exact disorder mention
in clinical notes and its novelty is in the fact that
either such phenomena have not been seen fre-
quently enough in the general domain to gather
particular attention, or the lack of a manually
curated general domain ontology parallel to the
UMLS.
Patient admitted with low blood pressure. (E3)
There are some disorders that do not have a rep-
resentation to a CUI as part of the SNOMED CT
within the UMLS. However, if they were deemed
important by the annotators then they were anno-
tated as CUI-less mentions. In example (E3), low
blood pressure is a finding and is normalized as
a CUI-less disorder. We constructed the annota-
tion guidelines to require that the disorder be a
reasonable synonym of the lexical description of a
SNOMED-CT disorder. There are a few instances
where the disorders are abbreviated or shortened
in the clinical note. One example is w/r/r, which
is an abbreviation for concepts wheezing (CUI
C0043144), rales (CUI C0034642), and ronchi
(CUI C0035508). This abbreviation is also some-
times written as r/w/r and r/r/w. Another is gsw for
gunshot wound and tachy for tachycardia. More
details on the annotation scheme is detailed in the
guidelines
9
and in a forthcoming manuscript. The
annotations covered about 336K words. Table 1
shows the quantity of the data and the split across
the training, development and test sets as well as
in terms of the number of notes and the number of
words.
2.1 Annotation Quality
Each note in the training and development set was
annotated by two professional coders trained for
this task, followed by an open adjudication step.
By the time we reached annotating the test data,
the annotators were quite familiar with the anno-
tation and so, in order to save time, we decided
to perform a single annotation pass using a senior
annotator. This was followed by a correction pass
by the same annotator using a checklist of frequent
annotation issues faced earlier. Table 2 shows the
inter-annotator agreement (IAA) statistics for the
adjudicated data. For the disorders we measure the
agreement in terms of the F
1
-score as traditional
agreement measures such as Cohen?s kappa and
Krippendorf?s alpha are not applicable for measur-
ing agreement for entity mention annotation. We
computed agreements between the two annotators
as well as between each annotator and the final ad-
judicated gold standard. The latter is to give a
sense of the fraction of corrections made in the
process of adjudication. The strict criterion con-
siders two mentions correct if they agree in terms
of the class and the exact string, whereas the re-
laxed criteria considers overlapping strings of the
9
http://goo.gl/vU8KdW
Disorder CUI
Relaxed Strict Relaxed Strict
F
1
F
1
Acc. Acc.
A1-A2 90.9 76.9 77.6 84.6
A1-GS 96.8 93.2 95.4 97.3
A2-GS 93.7 82.6 80.6 86.3
Table 2: Inter-annotator (A1 and A2) and gold
standard (GS) agreement as F
1
-score for the Dis-
order mentions and their normalization to the
UMLS CUI.
56
Institution User ID Team ID
University of Pisa, Italy attardi UniPI
University of Lisbon, Portugal francisco ULisboa
University of Wisconsin, Milwaukee, USA ghiasvand UWM
University of Colorado, Boulder, USA gung CLEAR
University of Guadalajara, Mexico herrera UG
Taipei Medical University, Taiwan hjdai TMU
University of Turku, Finland kaewphan UTU
University of Szeged, Hungary katona SZTE-NLP
Queensland University of Queensland, Australia kholghi QUT AEHRC
KU Leuven, Belgium kolomiyets KUL
Universidade de Aveiro, Portugal nunes BioinformaticsUA
University of the Basque Country, Spain oronoz IxaMed
IBM, India parikh ThinkMiners
easy data intelligence, India pathak ezDI
RelAgent Tech Pvt. Ltd., India ramanan RelAgent
Universidad Nacional de Colombia, Colombia riveros MindLab-UNAL
IIT Patna, India sikdar IITP
University of North Texas, USA solomon UNT
University of Illinois at Urbana Champaign, USA upadhya CogComp
The University of Texas Health Science Center at Houston, USA wu UTH CCB
East China Normal University, China yi ECNU
Table 3: Participant organization and the respective User IDs and Team IDs.
same class as correct. The reason for checking
the class is as follows. Although we only use the
disorder mention in this task, the corpus has been
annotated with some other UMLS types as well
and therefore there are instances where a differ-
ent UMLS type is assigned to the same character
span in the text by the second annotator. If exact
boundaries are not taken into account then the IAA
agreement score is in the mid-90s. For the task of
normalization to CUIs, we used accuracy to assess
agreement. For the relaxed criterion, all overlap-
ping disorder spans with the same CUI were con-
sidered correct. For the strict criterion, only disor-
der spans with identical spans and the same CUI
were considered correct.
3 Task Description
The participants were evaluated on the following
two tasks:
? Task A ? Identification of the character spans
of disorder mentions.
? Task B ? Normalizing disorder mentions to
SNOMED-CT subset of UMLS CUIs.
For Task A, participants were instructed to develop
a system that predicts the spans for disorder men-
tions. For Tasks B, participants were instructed
to develop a system that predicts the UMLS CUI
within the SNOMED-CT vocabulary. The input to
Task B were the disorder mention predictions from
Task A. Task B was optional. System outputs ad-
hered to the annotation format. Each participant
was allowed to submit up to three runs. The en-
tire set of unlabeled MIMIC clinical notes (exclud-
ing the test notes) were made available to the par-
ticipants for potential unsupervised approaches to
enhance the performance of their systems. They
were allowed to use additional annotations in their
systems, but this counted towards the total allow-
able runs; systems that used annotations outside
of those provided were evaluated separately. The
evaluation for all tasks was conducted using the
blind, withheld test data. The participants were
provided a training set containing clinical text as
well as pre-annotated spans and named entities for
disorders (Tasks A and B).
4 Evaluation Criteria
The following evaluation criteria were used:
? Task A ? The system performance was eval-
uated against the gold standard using the
F
1
-score of the Precision and Recall values.
There were two variations: (i) Strict; and (ii)
Relaxed. The formulae for computing these
metrics are mentioned below.
Precision = P =
D
tp
D
tp
+ D
fp
(1)
Recall = R =
D
tp
D
tp
+ D
fn
(2)
Where, D
tp
= Number of true positives dis-
order mentions; D
fp
= Number of false pos-
itives disorder mentions; D
fn
= Number of
false negative disorder mentions. In the strict
case, a span was counted as correct if it was
identical to the gold standard span, whereas
57
Task A
Strict Relaxed
Team ID User ID Run P R F
1
P R F
1
Data
(%) (%) (%) (%) (%) (%)
UTH CCB wu 0 84.3 78.6 81.3 93.6 86.6 90.0 T+D
UTH CCB wu 1 80.8 80.5 80.6 91.6 90.7 91.1 T+D
UTU kaewphan 1 76.5 76.7 76.6 88.6 89.9 89.3 T+D
UWM ghiasvand 0 78.7 72.6 75.5 91.1 85.6 88.3 T+D
UTH CCB wu 2 68.0 84.9 75.5 83.8 93.5 88.4 T+D
UTU kaewphan 0 77.3 72.4 74.8 90.1 85.6 87.8 T
IxaMed oronoz 1 68.1 78.6 73.0 87.2 89.0 88.1 T+D
UWM ghiasvand 0 77.5 67.9 72.4 90.9 81.2 85.8 T
RelAgent ramanan 0 74.1 70.1 72.0 89.5 84.0 86.7 T+D
IxaMed oronoz 0 72.9 70.1 71.5 88.5 80.8 84.5 T+D
ezDI pathak 1 75.0 68.2 71.4 91.5 82.7 86.9 T
CLEAR gung 0 80.7 63.6 71.2 92.0 72.3 81.0 T
ezDI pathak 0 75.0 67.7 71.2 91.4 81.9 86.4 T
ULisboa francisco 0 75.3 66.3 70.5 91.4 81.5 86.2 T
ULisboa francisco 1 75.2 66.0 70.3 90.9 80.6 85.5 T
ULisboa francisco 2 75.2 66.0 70.3 90.9 80.6 85.5 T
BioinformaticsUA nunes 0 81.3 60.5 69.4 92.9 69.3 79.4 T+D
ThinkMiners parikh 0 73.4 65.0 68.9 89.2 80.2 84.4 T
ThinkMiners parikh 1 74.9 61.7 67.7 90.7 75.8 82.6 T
ECNU yi 0 75.4 61.1 67.5 89.8 72.2 80.0 T+D
UniPI attardi 2 71.2 60.1 65.2 89.7 76.6 82.6 T+D
UNT solomon 0 64.7 62.8 63.8 81.5 79.9 80.7 T+D
UniPI attardi 1 65.9 61.2 63.5 90.2 77.5 83.4 T+D
BioinformaticsUA nunes 2 75.3 53.8 62.8 86.5 62.1 72.3 T+D
BioinformaticsUA nunes 1 60.0 62.1 61.0 69.8 72.3 71.0 T+D
UniPI attardi 0 53.9 68.4 60.2 77.8 88.5 82.8 T+D
CogComp upadhya 1 63.9 52.9 57.9 82.3 68.3 74.6 T+D
CogComp upadhya 2 64.1 52.0 57.4 82.9 67.5 74.4 T+D
CogComp upadhya 0 63.6 51.5 56.9 81.9 66.5 73.4 T+D
TMU hjdai 0 52.4 57.6 54.9 91.4 76.5 83.3 T+D
MindLab-UNAL riveros 2 56.1 53.4 54.7 76.9 67.7 72.0 T
MindLab-UNAL riveros 1 57.8 51.5 54.5 77.7 65.4 71.0 T
TMU hjdai 1 62.2 42.9 50.8 89.9 65.2 75.6 T+D
IITP sikdar 0 50.0 47.9 48.9 81.5 79.7 80.6 T+D
IITP sikdar 1 47.3 45.8 46.5 78.9 77.6 78.2 T+D
IITP sikdar 2 45.0 48.1 46.5 76.9 82.6 79.6 T+D
MindLab-UNAL riveros 0 32.1 56.5 40.9 43.9 72.5 54.7 T
SZTE-NLP katona 1 54.7 25.2 34.5 88.4 40.1 55.1 T
SZTE-NLP katona 2 54.7 25.2 34.5 88.4 40.1 55.1 T
QUT AEHRC kholghi 0 38.7 29.8 33.7 90.6 70.9 79.5 T+D
SZTE-NLP katona 0 57.1 20.5 30.2 91.8 32.5 48.0 T
KUL kolomiyets 0 65.5 17.8 28.0 72.1 19.6 30.8 P
UG herrera 0 11.4 23.4 15.3 25.9 49.0 33.9 P
Table 4: Performance on test data for participating systems on Task A ? Identification of disorder men-
tions.
Task A
Strict Relaxed
Team ID User ID Run P R F
1
P R F
1
Data
(%) (%) (%) (%) (%) (%)
hjdai TMU 1 0.687 0.922 0.787 0.952 1.000 0.975 T
wu UTH CCB 0 0.877 0.710 0.785 0.962 0.789 0.867 T
wu UTH CCB 1 0.828 0.747 0.785 0.941 0.853 0.895 T
Best ShARe/CLEF-2013 performance 0.800 0.706 0.750 0.925 0.827 0.873 T
ghiasvand UWM 0 0.827 0.675 0.743 0.958 0.799 0.871 T
pathak ezDI 0 0.813 0.670 0.734 0.954 0.800 0.870 T
pathak ezDI 1 0.809 0.667 0.732 0.954 0.801 0.871 T
wu UTH CCB 2 0.657 0.790 0.717 0.806 0.893 0.847 T
francisco ULisboa 1 0.803 0.646 0.716 0.954 0.781 0.858 T
francisco ULisboa 2 0.803 0.646 0.716 0.954 0.781 0.858 T
francisco ULisboa 0 0.796 0.642 0.711 0.959 0.793 0.868 T
oronoz IxaMed 0 0.766 0.650 0.703 0.936 0.752 0.834 T
oronoz IxaMed 1 0.660 0.721 0.689 0.899 0.842 0.870 T
hjdai TMU 0 0.667 0.414 0.511 0.912 0.591 0.717 T
sikdar IITP 0 0.525 0.430 0.473 0.862 0.726 0.788 T
sikdar IITP 2 0.467 0.440 0.453 0.812 0.775 0.793 T
sikdar IITP 1 0.493 0.410 0.448 0.828 0.706 0.762 T
Table 5: Performance on development data for participating systems on Task A ? Identification of disor-
der mentions.
58
in the relaxed case, a span overlapping with
the gold standard span was also considered
correct.
? Task B ? Accuracy was used as the perfor-
mance measure for Task 1b. It was defined as
follows:
Accuracy
strict
=
D
tp
?N
correct
T
g
(3)
Accuracy
relaxed
=
D
tp
?N
correct
D
tp
(4)
Where, D
tp
= Number of true positive disor-
der mentions with identical spans as in the
gold standard; N
correct
= Number of cor-
rectly normalized disorder mentions; and T
g
= Total number of disorder mentions in the
gold standard. For Task B, the systems were
only evaluated on annotations they identified
in Task A. Relaxed accuracy only measured
the ability to normalize correct spans. There-
fore, it was possible to obtain very high val-
ues for this measure by simply dropping any
mention with a low confidence span.
5 Participants
A total of 21 participants from across the world
participated in Task A and out of them 18 also par-
ticipated in Task B. Unfortunately, although inter-
ested, the ThinkMiners team (Parikh et al., 2014)
could not participate in Task B owing to some
UMLS licensing issues. The participating organi-
zations along with the contact user?s User ID and
their chosen Team ID are mentioned in Table 3.
Eight teams submitted three runs, six submitted
two runs and seven submitted just one run. Out
of these, only 13 submitted system description pa-
pers. We based our analysis on those system de-
scriptions.
6 System Results
Tables 4 and 6 show the performance of the sys-
tems on Tasks A and B. None of the systems used
any additional annotated data so we did not have
to compare them separately. Both tables mention
performance of all the different runs that the sys-
tems submitted. Given the many variables, we de-
liberately left the decision on how many and how
to define these runs to the individual participant.
They used various different ways to differentiate
their runs. Some, for example, UTU (Kaewphan et
al., 2014), did it based on the composition of train-
ing data, i.e., whether they used just the training
data or both the training and the development data
for training the final system, which highlighted
the fact that adding development data to training
bumped the F
1
-score on Task A by about 2 percent
points. Some participants, however, did not make
use of the development data in training their sys-
tems. This was partially due to the fact that we had
not explicitly mentioned in the task description
that participants were allowed to use the develop-
ment data for training their final models. In order
to be fair, we allowed some users an opportunity
to submit runs post evaluation where they used the
exact same system that they used for evaluation
but used the development data as well. We added
a column to the results tables showing whether the
participant used only the training data (T) or both
training and development data (T+D) for training
their system. It can be seen that even though the
addition of development data helps, there are still
systems that perform in the lower percentile who
have used both training and development data for
training, indicating that both the features and the
machine learning classifier contribute to the mod-
els. A novel aspect of the SemEval-2014 shared
task that differentiates it from the ShARE/CLEF
task?other than the fact that it used more data and
a new test set?is the fact that SemEval-2014 al-
lowed the use of a much larger set of unlabeled
MIMIC notes to inform the models. Surprisingly,
only two of the systems (ULisboa (Leal et al.,
2014) and UniPi (Attardi et al., 2014)) used the
unlabeled MIMIC corpus to generalize the lexical
features. Another team?UTH CCB(Zhang et al.,
2014)?used off-the-shelf Brown clusters
10
as op-
posed to training them on the unlabeled MIMIC
II data. For Task B, the accuracy of a system
using the strict metric was positively correlated
with its recall on the disorder mentions that were
input to it (i.e., recall for Task A), and did not
get penalized for lower precision. Therefore one
could essentially gain higher accuracy in Task B
by tuning a system to provide the highest men-
tion recall in Task A potentially at the cost of pre-
cision and the overall F
1
-score and using those
mentions as input for Task B. This can be seen
from the fact that the run 2 for UTH CCB (Zhang
et al., 2014) system with the lowest F
1
-score has
10
Personal conversation with the participants as it was not
very clear in the system description paper.
59
Task B
Strict Relaxed
Team ID User ID Run Acc. Acc. Data
(%) (%)
UTH CCB wu 2 74.1 87.3 T+D
UTH CCB wu 1 70.8 88.0 T+D
UTH CCB wu 0 69.4 88.3 T+D
UWM ghiasvand 0 66.0 90.9 T+D
RelAgent ramanan 0 63.9 91.2 T+D
UWM ghiasvand 0 61.7 90.8 T
IxaMed oronoz 0 60.4 86.2 T+D
UTU kaewphan 1 60.1 78.3 T+D
ezDI pathak 1 59.9 87.8 T
ezDI pathak 0 59.2 87.4 T
UTU kaewphan 0 57.7 79.7 T
BioinformaticsUA nunes 1 53.1 85.5 T+D
BioinformaticsUA nunes 0 52.7 87.0 T+D
CLEAR gung 0 52.5 82.5 T
TMU hjdai 0 48.9 84.9 T+D
UNT solomon 0 47.0 74.8 T+D
UniPI attardi 0 46.7 68.3 T+D
BioinformaticsUA nunes 2 46.3 86.1 T+D
MindLab-UNAL riveros 2 46.1 86.3 T
IxaMed oronoz 1 43.9 55.8 T+D
MindLab-UNAL riveros 0 43.5 77.1 T
UniPI attardi 1 42.8 69.9 T+D
UniPI attardi 2 41.7 69.3 T+D
MindLab-UNAL riveros 1 41.1 79.7 T
ULisboa francisco 2 40.5 61.5 T
ULisboa francisco 1 40.4 61.2 T
ULisboa francisco 0 40.2 60.6 T
ECNU yi 0 36.4 59.5 T+D
TMU hjdai 1 35.8 83.4 T+D
IITP sikdar 0 33.3 69.6 T+D
IITP sikdar 2 33.2 69.1 T+D
IITP sikdar 1 31.9 69.6 T+D
CogComp upadhya 1 25.3 47.9 T+D
CogComp upadhya 2 24.8 47.7 T+D
CogComp upadhya 0 24.4 47.3 T+D
KUL kolomiyets 0 16.5 92.8 P
UG herrera 0 12.5 53.4 P
Table 6: Performance on test data for participat-
ing systems on Task B ? Normalization of disorder
mentions to UMLS (SNOMED-CT subset) CUIs.
Task B
Strict Relaxed
Team ID User ID Run Acc. Acc. Data
(%) (%)
TMU hjdai 0 0.716 0.777 T
TMU hjdai 1 0.716 0.777 T
UTH CCB wu 2 0.713 0.903 T
UTH CCB wu 1 0.680 0.910 T
UTH CCB wu 0 0.647 0.910 T
UWM ghiasvand 0 0.623 0.923 T
ezDI pathak 0 0.603 0.900 T
ezDI pathak 1 0.600 0.899 T
Best ShARe/CLEF-2013 performance 0.589 0.895 T
IxaMed oronoz 0 0.556 0.855 T
IxaMed oronoz 1 0.421 0.584 T
ULisboa francisco 2 0.388 0.601 T
ULisboa francisco 1 0.385 0.596 T
ULisboa francisco 0 0.377 0.588 T
IITP sikdar 2 0.318 0.724 T
IITP sikdar 0 0.312 0.725 T
IITP sikdar 1 0.299 0.730 T
Table 7: Performance on development data
for some participating systems on Task B ?
Normalization of disorder mentions to UMLS
(SNOMED-CT subset) CUIs.
the best accuracy for Task B and vice-versa for
run 0 with run 1 in between the two. In order to
fairly compare the performance between two sys-
tems one would have to provide perfect mentions
as input to Task B. One of the systems?UWM
Ghiasvand and Kate (2014)?did run some abla-
tion experiments using gold standard mentions as
input to Task B and obtained a best performance
of 89.5F
1
-score (Table 5 of Ghiasvand and Kate
(2014)) as opposed to 62.3 F
1
-score (Table 7) in
the more realistic setting which is a huge differ-
ence. In the upcoming SemEval-2014 where this
same evaluation is going to carried out under Task
14, we plan to perform supplementary evaluation
where gold disorder mentions would be input to
the system while attempting Task B. An inter-
esting outcome of planning a follow-on evalua-
tion to the ShARe/CLEF eHealth 2013 task was
that we could, and did, use the test data from the
ShARe/CLEF eHealth 2013 task as the develop-
ment set for this evaluation. After the main eval-
uation we asked participants to provide the sys-
tem performance on the development set using the
same number and run convention that they submit-
ted for the main evaluation. These results are pre-
sented in Tables 5 and 7. We have inserted the best
performing system score from the ShARe/CLEF
eHealth 2013 task in these tables. For Task A, re-
ferring to Tables 4 and 5, there is a boost of 3.7
absolute percent points for the F
1
-score over the
same task (Task 1a) in the ShARe/CLEF eHealth
2013. For Task B, referring to Tables 6 and 7, there
is a boost of 13.7 percent points for the F
1
-score
over the same task (Task 1b) in the ShARe/CLEF
eHealth 2013 evaluation. The participants used
various approaches for tackling the tasks, rang-
ing from purely rule-based/unsupervised (RelA-
gent (Ramanan and Nathan, 2014), (Matos et
al., 2014), KUL
11
) to a hybrid of rules and ma-
chine learning classifiers. The top performing sys-
tems typically used the latter. Various versions
of the IOB formulation were used for tagging the
disorder mentions. None of the standard varia-
tions on the IOB formulation were explicitly de-
signed or used to handle discontiguous mentions.
Some systems used novel variations on this ap-
proach. Probably the simplest variation was ap-
plied by the UWM team (Ghiasvand and Kate,
2014). In this formulation the following labeled
sequence ?the/O left/B atrium/I is/O moderately/O
11
Personal communication with participant.
60
dilated/I? can be used to represent the discontigu-
ous mention left atrium...dilated, and can be con-
structed as such from the output of the classifica-
tion. The most complex variation was the one used
by the UTH CCB team (Zhang et al., 2014) where
they used the following set of tags?B, I, O, DB,
DI, HB, HI. This variation encodes discontiguous
mentions by adding four more tags to the I, O and
B tags. These are variations of the B and I tags
with either a D or a H prefix. The prefix H indi-
cates that the word or word sequence is the shared
head, and the prefix D indicates otherwise. An-
other intermediate approach used by the ULisboa
team (Leal et al., 2014) with the tagset?S, B, I,
O, E and N. Here, S represents the single token
entity to be recognized, E represents the end of an
entity (which is part of one of the prior IOB vari-
ations) and an N tag to identify non-contiguous
mentions. They don?t provide an explicit exam-
ple usage of this tag set in their paper. Yet another
variation was used by the SZTE-NLP team (Ka-
tona and Farkas, 2014). This used tags B, I, L, O
and U. Here, L is used for the last token similar to
E earlier, and U is used for a unit-token mention,
similar to S earlier. We believe that the only ap-
proach that can distinguish between discontiguous
disorders that share the same head word/phrase is
the one used by the UTH CCB team (Zhang et
al., 2014). The participants used various machine
learning classifiers such as MaxEnt, SVM, CRF in
combination with rich syntactic and semantic fea-
tures to capture the disorder mentions. As men-
tioned earlier, a few participants used the avail-
able unlabeled data and also off-the-shelf clusters
to better generalize features. The use of vector
space models such as cosine similarities as well
as continuous distributed word vector representa-
tions was useful in the normalization task. They
also availed of tools such as MetaMap and cTakes
to generate features as well as candidate CUIs dur-
ing normalizations.
7 Conclusion
We have created a reference standard with high
inter-annotator agreement and evaluated systems
on the task of identification and normalization
of diseases and disorders appearing in clinical
reports. The results have demonstrated that an
NLP system can complete this task with reason-
ably high accuracy. We plan to annotate another
evaluation using the same data as part of the in
the SemEval-2015, Task 14
12
adding another task
of template filling where the systems will iden-
tify and normalize ten attributes the identified dis-
ease/disorder mentions.
Acknowledgments
We greatly appreciate the hard work and feed-
back of our program committee members and an-
notators David Harris, Jennifer Green and Glenn
Zaramba. Danielle Mowery, Sumithra Velupillai
and Brett South for helping prepare the manuscript
by summarizing the approaches used by various
systems. This shared task was partially sup-
ported by Shared Annotated Resources (ShARe)
project NIH 5R01GM090187 and Temporal His-
tories of Your Medical Events (THYME) project
(NIH R01LM010090 and U54LM008748).
References
Giuseppe Attardi, Vitoria Cozza, and Daniele Sartiano.
2014. UniPi: Recognition of mentions of disorders
in clinical text. In Proceedings of the International
Workshop on Semantic Evaluations, Dublin, Ireland,
August.
Olivier Bodenreider and Alexa McCray. 2003. Ex-
ploring semantic groups through visual approaches.
Journal of Biomedical Informatics, 36:414?432.
Keith E. Campbell, Diane E. Oliver, and Edward H.
Shortliffe. 1998. The Unified Medical Language
System: Towards a collaborative approach for solv-
ing terminologic problems. J Am Med Inform Assoc,
5(1):12?16.
Omid Ghiasvand and Rohit J. Kate. 2014. UWM: Dis-
order mention extraction from clinical text using crfs
and normalization using learned edit distance pat-
terns. In Proceedings of the International Workshop
on Semantic Evaluations, Dublin, Ireland, August.
Suwisa Kaewphan, Kai Hakaka1, and Filip Ginter.
2014. UTU: Disease mention recognition and nor-
malization with crfs and vector space representa-
tions. In Proceedings of the International Workshop
on Semantic Evaluations, Dublin, Ireland, August.
Melinda Katona and Rich?ard Farkas. 2014. SZTE-
NLP: Clinical text analysis with named entity recog-
nition. In Proceedings of the International Work-
shop on Semantic Evaluations, Dublin, Ireland, Au-
gust.
Andr?e Leal, Diogo Gonc?alves, Bruno Martins, and
Francisco M. Couto. 2014. ULisboa: Identifica-
tion and classification of medical concepts. In Pro-
ceedings of the International Workshop on Semantic
Evaluations, Dublin, Ireland, August.
12
http://alt.qcri.org/semeval2015/task14
61
Robert Leaman and Graciela Gonzalez. 2008. Ban-
ner: an executable survey of advances in biomedical
named entity recognition. In Pacific Symposium on
Biocomputing, volume 13, pages 652?663.
S?ergio Matos, Tiago Nunes, and Jos?e Lu??s Oliveira.
2014. BioinformaticsUA: Concept recognition in
clinical narratives using a modular and highly ef-
ficient text processing framework. In Proceedings
of the International Workshop on Semantic Evalua-
tions, Dublin, Ireland, August.
Sungrim Moon, Serguei Pakhomov, and Genevieve B
Melton. 2012. Automated disambiguation of
acronyms and abbreviations in clinical texts: Win-
dow and training size considerations. In AMIA Annu
Symp Proc, pages 1310?1319.
David Nadeau and Satoshi Sekine. 2007. A sur-
vey of named entity recognition and classification.
Lingvisticae Investigationes, 30(1):3?26.
Roberto Navigli. 2009. Word sense disambiguation.
ACM Computing Surveys, 41(2):1?69, February.
Ankur Parikh, Avinesh PVS, Joy Mustafi, Lalit Agar-
walla, and Ashish Mungi. 2014. ThinkMiners:
SemEval-2014 task 7: Analysis of clinical text. In
Proceedings of the International Workshop on Se-
mantic Evaluations, Dublin, Ireland, August.
Sameer Pradhan, No?emie Elhadad, Brett South, David
Martinez, Lee Christensen, Amy Vogel, Hanna
Suominen, Wendy W. Chapman, and Guergana
Savova. 2013. Task 1: ShARe/CLEF eHealth
Evaluation Lab 2013. In Working Notes of CLEF
eHealth Evaluation Labs.
Sameer Pradhan, No?emie Elhadad, Brett South, David
Martinez, Lee Christensen, Amy Vogel, Hanna
Suominen, Wendy W. Chapman, and Guergana
Savova. 2014. Evaluating the state of the art in
disorder recognition and normalization of the clin-
ical narrative. In Journal of the American Medical
Informatics Association (to appear).
S. V. Ramanan and P. Senthil Nathan. 2014. RelA-
gent: Entity detection and normalization for diseases
in clinical records: a linguistically driven approach.
In Proceedings of the International Workshop on Se-
mantic Evaluations, Dublin, Ireland, August.
Angus Roberts, Robert Gaizauskas, Mark Hepple,
George Demetriou, Yikun Guo, Ian Roberts, and
Andrea Setzer. 2009. Building a semantically an-
notated corpus of clinical texts. J Biomed Inform,
42(5):950?66.
Mohammed Saeed, C. Lieu, G. Raber, and R.G. Mark.
2002. MIMIC II: a massive temporal ICU patient
database to support research in intelligent patient
monitoring. Comput Cardiol, 29.
Guergana K. Savova, A. R. Coden, I. L. Sominsky,
R. Johnson, P. V. Ogren, P. C. de Groen, and C. G.
Chute. 2008. Word sense disambiguation across
two domains: Biomedical literature and clinical
notes. J Biomed Inform, 41(6):1088?1100, Decem-
ber.
Weiyi Sun, Anna Rumshisky, and
?
Ozlem Uzuner.
2013. Evaluating temporal relations in clinical text:
2012 i2b2 Challenge. Journal of the American Med-
ical Informatics Association, 20(5):806?13.
Hanna Suominen, Sanna Salanter?a, Sumithra Velupil-
lai, Wendy W. Chapman, Guergana Savova,
Noemie Elhadad, Sameer Pradhan, Brett R. South,
Danielle L. Mowery, Gareth J. F. Jones, Johannes
Leveling, Liadh Kelly, Lorraine Goeuriot, David
Martinez, and Guido Zuccon. 2013. Overview of
the ShARe/CLEF eHealth evaluation lab 2013. In
Working Notes of CLEF eHealth Evaluation Labs.
?
Ozlem Uzuner, Brett R South, Shuying Shen, and
Scott L DuVall. 2011. 2010 i2b2/VA challenge on
concepts, assertions, and relations in clinical text.
Journal of the American Medical Informatics Asso-
ciation, 18(5):552?556.
?
Ozlem Uzuner, Andreea Bodnari, Shuying Shen, Tyler
Forbush, John Pestian, and Brett R South. 2012.
Evaluating the state of the art in coreference res-
olution for electronic medical records. Jour-
nal of American Medical Informatics Association,
19(5):786?791, September.
Yaoyun Zhang, Jingqi Wang, Buzhou Tang, Yonghui
Wu, Min Jiang, Yukun Chen, and Hua Xu. 2014.
UTH CCB: A report for SemEval 2014 task 7 anal-
ysis of clinical text. In Proceedings of the Interna-
tional Workshop on Semantic Evaluations, Dublin,
Ireland, August.
62
Proceedings of the 4th International Workshop on Computational Terminology, page 32,
Dublin, Ireland, August 23 2014.
Terminology questions in texts authored by patients
Noemie Elhadad
Department of Biomedical Informatics
Columbia University, USA
noemie@dbmi.columbia.edu
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
32
