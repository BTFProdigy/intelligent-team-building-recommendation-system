Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 190?194,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Analysis and Prediction of Unalignable Words in Parallel Text
Frances Yung Kevin Duh
Nara Institute of Science and Technology
8916-5 Takayama, Ikoma, Nara, 630-0192 Japan
pikyufrances-y|kevinduh|matsu@is.naist.jp
Yuji Matsumoto
Abstract
Professional human translators usually do
not employ the concept of word align-
ments, producing translations ?sense-for-
sense? instead of ?word-for-word?. This
suggests that unalignable words may be
prevalent in the parallel text used for ma-
chine translation (MT). We analyze this
phenomenon in-depth for Chinese-English
translation. We further propose a sim-
ple and effective method to improve au-
tomatic word alignment by pre-removing
unalignable words, and show improve-
ments on hierarchical MT systems in both
translation directions.
1 Motivation
It is generally acknowledged that absolute equiva-
lence between two languages is impossible, since
concept lexicalization varies across languages.
Major translation theories thus argue that texts
should be translated ?sense-for-sense? instead of
?word-for-word? (Nida, 1964). This suggests that
unalignable words may be an issue for the parallel
text used to train current statistical machine trans-
lation (SMT) systems. Although existing auto-
matic word alignment methods have some mech-
anism to handle the lack of exact word-for-word
alignment (e.g. null probabilities, fertility in the
IBM models (Brown et al., 1993)), they may be
too coarse-grained to model the ?sense-for-sense?
translations created by professional human trans-
lators.
For example, the Chinese term ?tai-yang? liter-
ally means ?sun?, yet the concept it represents is
equivalent to the English term ?the sun?. Since the
concept of a definite article is not incorporated in
the morphology of ?tai yang?, the added ?the? is
not aligned to any Chinese word. Yet in another
context like ?the man?, ?the? can be the translation
of the Chinese demonstrative pronoun ?na?, liter-
ally means ?that?. A potential misunderstanding is
that unalignable words are simply function words;
but from the above example, we see that whether a
word is alignable depends very much on the con-
cept and the linguistic context.
As the quantity and quality of professionally-
created parallel text increase, we believe there is a
need to examine the question of unalignable words
in-depth. Our goal is to gain a better understand-
ing of what makes a fluent human translation and
use this insight to build better word aligners and
MT systems. Our contributions are two-fold:
1) We analyze 13000 sentences of manually word-
aligned Chinese-English parallel text, quantifying
the characteristics of unalignable words.
2) We propose a simple and effective way to im-
prove automatic word alignment, based on pre-
dicting unalignable words and temporarily remov-
ing them during the alignment training procedure.
2 Analysis of Unalignable Words
Our manually-aligned data, which we call OR-
ACLE data, is a Chinese-to-English corpus re-
leased by the LDC (Li et al., 2010)
1
. It con-
sists of ?13000 Chinese sentences from news and
blog domains and their English translation . En-
glish words are manually aligned with the Chinese
characters. Characters without an exact counter-
part are annotated with categories that state the
functions of the words. These characters are ei-
ther aligned to ?NULL?, or attached to their depen-
dency heads, if any, and aligned together to form
a multi-word alignment. For example, ?the? is an-
notated as [DET], for ?determiner?, and aligned to
?tai-yang? together with ?sun?.
In this work, any English word or Chinese char-
acter without an exact counterpart are called un-
alignable words, since they are not core to the
1
LDC2012T16, LDC2012T20 and LDC2012T24
190
word unalignable core
types tokens tokens
core or 3581 146,693 562,801
unalignable (12%) (17%) (66%)
always 25320 / 147,373
core (88%) (17%)
Table 1: Number of core and unalignable words in
hand aligned ORACLE corpus
multi-word alignment. All other English words or
Chinese characters are referred to as core words.
2.1 What kind of words are unalignable?
Analyzing the hand aligned corpus, we find that
words annotated as unalignable do not come from
a distinct list. Table 1 reveals that 88% of the
word types are unambiguously core words. Yet
these word types, including singletons, account
for only 17% of the word tokens. On the other
hand, another 17% of the total word tokens are
annotated as unalignable. So, most word types are
possibly unalignable but only in a small portion of
their occurrence, such as the following examples:
(1a) Chi: yi ge di fang
one (measure word) place
Eng: one place
(1b) Chi: ge ren
personal
Eng: personal
(2a) Chi: ming tian zhong wu
(tomorrow) (midday)
Eng: tomorrow at midday
(2b) Chi: zai jia
at/in/on home
Eng: at home
In example (1a), ?ge? is a measure word that is
exclusive in Chinese, but in (1b), it is part of the
multiword unit ?ge-ren? for ?personal?. Similarly,
prepositions, such as ?at?, can either be omitted or
translated depending on context.
Nonetheless, unalignable words are by no
means evenly distributed among word types. Ta-
ble 2 shows that the top 100 most frequent un-
alignable word types already covers 78% and 94%
of all Chinese and English unalignable instances,
respectively. Word type is thus an important clue.
Intuitively, words with POS defined only in one
of the languages are likely to be unalignable. To
examine this, we automatically tagged the ORA-
CLE data using the Standford Tagger (Toutanova
Most frequent Token count
unalignable word types Chinese English
Top 50 34,987 83,905
(68%) (88%)
Top 100 40,121 89,609
(78%) (94%)
Table 2: Count of unalignable words by types
et al., 2003). We find that the unalignable words
include all POS categories of either language,
though indeed some POS are more frequent. Ta-
ble 3 lists the top 5 POS categories that most un-
alignable words belong to and the percentage they
are annotated as unalignable. Some POS cate-
gories like DEG are mostly unalignable regardless
of context, but other POS tags such as DT and IN
depend on context.
Chi. No. and % of Eng. No. and % of
POS unalign. POS unalign.
DEG 7411(97%) DT 27715 (75%)
NN 6138 (4%) IN 19303 (47%)
AD 6068 (17%) PRP 5780 (56%)
DEC 5572 (97%) TO 5407 (62%)
VV 4950 (6%) CC 4145 (36%)
Table 3: Top 5 POS categories of Chinese and En-
glish unalignable words
Note also that many Chinese unalignable words
are nouns (NN) and verbs (VV). Clearly we cannot
indiscriminately consider all nouns as unalignable.
Some examples of unalignable content words in
Chinese are:
(3) Chi: can jia hui jian huo dong
participate meeting activity
Eng: participate in the meeting
(4) Chi: hui yi de yuan man ju xing
meeting ?s successful take place
Eng: success of the meeting
English verbs and adjectives are often nomi-
nalized to abstract nouns (such as ?meeting? from
?meet?, or ?success? from ?succeed?), but such
derivation is rare in Chinese morphology. Since
POS is not morphologically marked in Chinese,
?meeting? and?meet? are the same word. To reduce
the processing ambiguity and produce more nat-
ural translation, extra content words are added to
mark the nominalization of abstract concepts. For
example, ?hui jian? is originally ?to meet?. Adding
?huo dong?(activity) transforms it to a noun phrase
191
(example 3), similar to the the addition of ?ju
sing?(take place) to the adjective ?yuan man? (ex-
ample 4). These unalignable words are not lexi-
cally dependent but are inferred from the context,
and thus do not align to any source words.
To summarize, a small number of word types
cover 17% of word tokens that are unalignable,
but whether these words are unalignable depends
significantly on context. Although there is no list
of ?always unalignable? words types or POS cat-
egories, our analysis shows there are regularities
that may be exploited by an automatic classifier.
3 Improved Automatic Word Alignment
We first propose a classifier for predicting whether
a word is unalignable. Let (e
J
1
, f
K
1
) be a pair of
sentence with length J and K. For each word in
(e
J
1
, f
K
1
) that belongs to a predefined list
2
of po-
tentially unalignable words, we run a binary clas-
sifier. A separate classifier is built for each word
type in the list, and an additional classifier for all
the remaining words in each language.
We train an SVM classifier based on the fol-
lowing features: Local context: Unigrams and
POS in window sizes of 1, 3, 5, 7 around the
word in question. Top token-POS pairs: This
feature is defined by whether the token in ques-
tion and its POS tag is within the top n frequent
token-POS pairs annotated as unalignable like in
Tables 2 and 3. Four features are defined with n =
10, 30, 50, 100. Since the top frequent unalignable
words cover most of the counts as shown in the
previous analysis, being in the top n list is a strong
positive features. Number of likely unalignable
words per sentence: We hypothesize that the
translator will not add too many tokens to the
translation and delete too many from the source
sentence. In the ORACLE data, 68% sentences
have more than 2 unalignable words. We approx-
imate the number of likely unalignable words in
the sentence by counting the number of words
within the top 100 token-POS pairs annotated as
unalignable. Sentence length and ratio: Longer
sentences are more likely to contain unalignable
words than shorter sentences. Also sentence ra-
tios that deviate significantly from the mean are
likely to contain unalignable words. Presence of
alignment candidate: This is a negative feature
defined by whether there is an alignment candi-
2
We define the list as the top 100 word types with the
highest count of unalignable words per language according
to the hand annotated data.
date in the target sentence for the source word in
question, or vice versa. The candidates are ex-
tracted from the top n frequent words aligned to
a particular word according to the manual align-
ments of the ORACLE data. Five features are de-
fined with n = 5, 10, 20, 50, 100 and one ?without
limit?, such that a more possible candidate will be
detected by more features.
Next, we propose a simple yet effective mod-
ification to the word alignment training pipeline:
1. Predict unalignable words by the classifier
2. Remove these words from the training corpus
3. Train word alignment model (e.g. GIZA++)
3
4. Combine the word alignments in both direc-
tions with heuristics (grow-diag-final-and)
5. Restore unaligned words to original position
6. Continue with rule extraction and the rest of
the MT pipeline.
The idea is to reduce the difficulty for the word
alignment model by removing unaligned words.
4 End-to-End Translation Experiments
In our experiments, we first show that removing
manually-annotated unaligned words in ORACLE
data leads to improvements in MT of both trans-
lation directions. Next, we show how a classifier
trained on ORACLE data can be used to improve
MT in another large-scale un-annotated dataset.
4
4.1 Experiments on ORACLE data
We first performed an ORACLE experiment us-
ing gold standard unaligned word labels. Follow-
ing the training pipeline in Section 3, we removed
gold unalignable words before running GIZA++
and restore them afterwards. 90% of the data is
used for alignment and MT training, while 10% of
the data is reserved for testing.
The upper half of Table 4 list the alignment
precision, recall and F1 of the resulting align-
ments, and quality of the final MT outputs. Base-
line is the standard MT training pipeline with-
out removal of unaligned words. Our Proposed
approach performs better in alignment, phrase-
based (PBMT) and hierarchical (Hiero) systems.
The results, evaluated by BLEU, METEOR and
TER, support our hypothesis that removing gold
unalignable words helps improve word alignment
and the resulting SMT.
3
We can suppress the NULL probabilities of the model.
4
All experiments are done using standard settings for
Moses PBMT and Hiero with 4-gram LM and mslr-
bidirectional-fe reordering (Koehn et al., 2007). The clas-
sifier is trained using LIBSVM (Chang and Lin, 2011).
192
Align PBMT Hiero
acc. C-E E-C C-E E-C
ORACLE P .711 B 11.4 17.4 10.3 15.8
Baseline R .488 T 70.9 69.0 75.9 72.3
F1.579 M 21.8 23.9 21.08 23.7
ORACLE P .802 B 11.8
+
18.3
+
11.0
+
17.2
+
Proposed R .509 T 71.4
?
65.7
+
74.7
+
68.7
+
(gold) F1.623 M 22.1
+
24.1
+
22.0
+
24.0
+
REAL B 18.2 18.5 17.0 17.2
Baseline T 63.4 67.2 68.0 71.4
M 22.9 24.6 22.9 24.8
REAL B 18.6 18.5 17.6
+
18.1
+
Proposed T 63.8
?
66.5
+
67.6 69.7
+
(predict) M 23.2
+
24.5 23.4
+
24.7
Table 4: MT results of ORACLE and REAL ex-
periments. Highest score per metric is bolded.
{
+
/
?
} indicates statistically significant improve-
ment/degradation, p < 0.05. (P: precision; R: re-
call; B: BLEU; M: METEOR; T:TER)
For comparison, a naive classifier that labels
all top-30 token-POS combinations as unalignable
performs poorly as expected (PBMT BLEU: 9.87
in C-E direction). We also evaluated our proposed
classifier on this task: the accuracy is 92% and it
achieves BLEU of 11.55 for PBMT and 10.84 for
Hiero in C-E direction, which is between the re-
sults of gold-unalign and baseline.
4.2 Experiments on large-scale REAL data
We next performed a more realistic experiment:
the classifier trained on ORACLE data is used to
automatically label a large data, which is then used
to train a MT system. This REAL data consists of
parallel text from the NIST OpenMT2008.
5
MT
experiments are performed in both directions.
The lower half of Table 4 shows the perfor-
mance of the resulting MT systems. We observe
that our proposed approach is still able to improve
over the baseline. In particular, Hiero achieved
statistical significant improvements in BLEU and
METEOR.
6
Comparing to the results of PBMT,
this suggests our method may be most effective in
improving systems where rule extraction is sen-
5
We use the standard MT08 test sets; the training
data includes LDC2004T08, 2005E47, 2005T06, 2007T23,
2008T06, 2008T08, 2008T18, 2009T02, 2009T06, 2009T15,
and 2010T03 (34M English words and 1.1M sentences).
Since we do not have access to all OpenMT data, e.g. FBIS,
our results may not be directly comparable to other systems
in the evaluation.
6
Interestingly, PBMT did better than Hiero in this setup.
Chinese English lexical translation
word Baseline only Propose only
xie (bring) him bringing
xing (form) and model
dan (but) it, the, they yet, nevertheless
pa (scare) that, are, be fears, worried
Table 5: Examples of translations exclusively
found in the top 15 lexical translation.
Figure 1: Classifier accuracy and MT results V.S.
proportion of ORACLE data
sitive to the underlying alignments, such as Hi-
ero and Syntax-based MT. Table 5 shows the lex-
ical translations for some rare Chinese words: the
baseline tends to incorrectly align these to func-
tion words (garbage collection), while the pro-
posed method?s translations are more reasonable.
To evaluate how much annotation is needed for
the classifier, we repeat experiments using differ-
ent proportions of the ORACLE data. Figure 1
shows training by 20% of the data (2600 sents.)
already leads to significant improvements (p <
0.05), which is a reasonable annotation effort.
5 Conclusion
We analyzed in-depth the phenomenon of un-
alignable words in parallel text, and show that
what is unalignable depends on the word?s concept
and context. We argue that this is not a trivial prob-
lem, but with an unalignable word classifier and
a simple modified MT training pipeline, we can
achieve small but significant gains in end-to-end
translation. In related work, the issue of dropped
pronouns (Chung and Gildea, 2010) and function
words (Setiawan et al., 2010; Nakazawa and Kuro-
hashi, 2012) have been found important in word
alignment, and (Fossum et al., 2008) showed that
syntax features are helpful for fixing alignments.
An interesting avenue of future work is to integrate
these ideas with ours, in particular by exploiting
syntax and viewing unalignable words as aligned
at a structure above the lexical level.
193
References
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics,
19(2).
Chih-Chung Chang and Chih-Jen Lin. 2011. Lib-
svm : a library for support vector machines. ACM
Transactions on Intelligent Systems and Technology,
2(27).
Tagyoung Chung and Daniel Gildea. 2010. Effects
of empty categories on machine translation. Pro-
ceedings of the Conference on Empirical Methods
on Natural Language Processing.
Victoria Fossum, Kevin Knight, and Steven Abney.
2008. Using syntax to improve word alignment pre-
cision for syntax-based machine translation. Pro-
ceedings of the Workshop on Statistical Machine
Translation.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. Proceedings of the Annual Meeting of the As-
sociation for Computational Linguistics.
Xuansong Li, Niyu Ge, Stephen Grimes, Stephanie M.
Strassel, and Kazuaki Maeda. 2010. Enriching
word alignment with linguistic tags. Proceedings
of International Conference on Language Resources
and Evaluation.
Toshiaki Nakazawa and Sado Kurohashi. 2012.
Alignment by bilingual generation and monolingual
derivation. Proceedings of the International Confer-
ence on Computational Linguistics.
Eugene A Nida. 1964. Toward a Science of Translat-
ing: with Special Reference to Principles and Pro-
cedures Involved in Bible Translating. BRILL.
Hendra Setiawan, Chris Dyer, and Philip Resnik. 2010.
Discriminative word alignment with a function word
reordering model. Proceedings of the Conference on
Empirical Methods on Natural Language Process-
ing.
Kristina Toutanova, Dan Klein, Christopher Manning,
and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
Proceedings of the Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies.
194
Proceedings of the ACL 2014 Student Research Workshop, pages 18?25,
Baltimore, Maryland USA, June 22-27 2014.
c?2014 Association for Computational Linguistics
Towards a Discourse Relation-aware Approach
for Chinese-English Machine Translation
Frances Yung
Nara Institute of Science and Technology
8916-5 Takayama, Ikoma, Nara, 630-0192 Japan
pikyufrances-y@is.naist.jp
Abstract
Translation of discourse relations is one
of the recent efforts of incorporating dis-
course information to statistical machine
translation (SMT). While existing works
focus on disambiguation of ambiguous
discourse connectives, or transformation
of discourse trees, only explicit discourse
relations are tackled. A greater challenge
exists in machine translation of Chinese,
since implicit discourse relations are abun-
dant and occur both inside and outside a
sentence. This thesis proposal describes
ongoing work on bilingual discourse anno-
tation and plans towards incorporating dis-
course relation knowledge to a Chinese-
English SMT system with consideration of
implicit discourse relations. The final goal
is a discourse-unit-based translation model
unbounded by the traditional assumption
of sentence-to-sentence translation.
1 Introduction
Human translation is created at document level,
suggesting that translation of a particular sentence
depends also on the ?discourse structure?. Re-
cently, some MT researchers have started to ex-
plore the possibility to incorporate linguistic in-
formation outside the sentence boundary for MT,
such as topical structure, coreference chains, and
lexical coherence. Among various discourse struc-
tures, discourse relations, also known as coher-
ence relations, are meaningful relations connect-
ing text segments and are crucial to the human
cognitive processing as well as memory of texts
(Sanders and Noordman, 2000). These relations
can be explicitly marked in a text by signaling
phrases or implicitly implied. Even when they
are explicit, some markers are ambiguous and
do not always signal the same relation. In ad-
dition, strategies to represent discourse relations
vary across languages. It is thus a challenging task
to correctly translate discourse relations.
This thesis proposal presents my plan to-
wards building a discourse-relation-aware ma-
chine translation system translating from Chinese
to English. In particular, I would like to focus on
modeling the translation of implicit discourse re-
lations, which has not yet been exploited to date
to my knowledge, but is yet a noticeable problem
since implicit discourse relations are abundant in
Chinese. According to the statistics of the bilin-
gual discourse annotation in progress, about 1/4 of
the Chinese implicit DCs are translated to explicit
DCs in English.
A reasonable initial attempt to learn discourse-
relation-aware translation rules is a knowledge-
based approach based on an annotated corpus.
This proposal describes my ongoing work on an-
notating and cross-lingually aligning discourse re-
lations in a Chinese-English translation corpus, as
well as my plans to incorporate the resulting lin-
guistic markup into an SMT system. Motivated by
the characteristics of long Chinese sentences with
multiple discourse segments, a further direction of
the research is to translate in units of discourse
segments instead of sentences.
Section 2 gives an overview of existing litera-
ture. Section 3 explains the motivations behind my
research on discourse relations for MT. Section 4
describes my ongoing work of bilingual discourse
annotation, followed by statistics to date . Section
5 present my plans for next steps. Finally, a con-
clusion is drawn in Section 6.
2 Survey
2.1 English discourse processing
There are a number of discourse-annotated En-
glish resources, including the ?RST Treebank?
(Carlson et al, 2001) and the ?Discourse Graph-
Bank? (Wolf and Gibson, 2005), which consist
18
of 385 and 135 articles respectively. Recent dis-
course research often make use of the large-scaled
Penn Discourse Treebank (PDTB) (Prasad et
al., 2008). Departed from annotation using pre-
defined discourse relations, such as ?Rhetorical
Structure Theory? (Mann and Thompson, 1988),
PDTB introduces a lexically-ground formalism
to annotate discourse relations by identifying
the discourse connectives (DCs). An example is
shown in the following.
Example 1: Since McDonald?s menu prices
rose this year, the actual decline may have been
more. (PDTB 1280)
?Since? is an explicit DC taking the italic seg-
ment as the first argument (Arg1), and the bolded
segment as the second argument (Arg2), which is
syntactically attached to the DC. Implicit DCs are
inserted by annotators between adjacent sentences
of the same paragraph to represent inferred dis-
course relations. Each DC is annotated with de-
fined senses classified into 3 levels of granularity.
PDTB allows evaluation of English discourse
parsing tasks and disambiguation tasks (Pitler and
Nenkova, 2009; Lin et al, 2010), which reveal
that implicit discourse relations are much harder to
learn than explicit discourse relations (Pitler et al,
2009; Zhou et al, 2010). For example, classifica-
tion of the 4 main relation senses (temporal, con-
tingency, comparison, expansion) reaches 94% ac-
curacy for explicit relations (Pitler and Nenkova,
2009), but only range from F-scores of 20% for
?temporal? to 76% for ?expansion? relations, pos-
sibly due to unbalanced number of training in-
stances (Pitler et al, 2009; Zhou et al, 2010).
2.2 Chinese discourse processing
Schemes for Chinese discourse annotation have
been proposed in the existing literature (Xue,
2005; Zhou and Xue, 2012) but the corresponding
resource is not yet available. Zhou et al (2012)
proposed to project English discourse annotation
and classification algorithms to Chinese data, but
the transfer was based on automatic word align-
ment and machine translation results. Works in
Chinese discourse parsing report F-scores of 64%
in classification of inter-sentence discourse rela-
tions and 71% in 2-way classification of intra-
sentence contingency and comparison relations
(Huang and Chen, 2011; Huang and Chen, 2012),
training on a moderately sized (81 articles) corpus
and considering explicit and implicit relations col-
lectively. Corelation between discourse relation
and sentiment was also explored based on anno-
tated data (Huang et al, 2013).
2.3 Discourse relations in SMT
Earlier studies of discourse relations in MT in-
cludes Marcu et al (2000), which proposed a
discourse transfer model to re-construct the tar-
get discourse tree from the source discourse tree,
parsed by the (RST). However, incorporation to
an SMT system was not discussed in the work.
Recent works focus on the translation of ambigu-
ous DCs, such as ?since? in the temporal sense vs.
?since? in the reason sense. This is achieved by
annotating the DCs in the training data by ?trans-
lation spotting?, which is to manually align the
DCs of the source text to their translation in the
target text, either occurring as DCs or other ex-
pressions (Meyer et al, 2011; Popescu-Belis et al,
2012; Meyer et al, 2012; Meyer and Polakova,
2013; Cartoni et al, 2013). Experiments of these
works have been conducted in English-to-French,
Czech and German translation and only explicit
DCs were considered.
Tu et al (2013) proposed a framework for
Chinese-to-English translation, in which the
source text is automatically parsed by an RST
parser and translation rules are extracted from
the source discourse trees aligned with the target
strings. An improvement of 1.16 BLEU point is
reported, considering only intra-sentential explicit
relations.
Meyer et al (2012) found that the translation of
DC improves by up to 10% disregarded of BLEU,
which stays around the baseline system score.
To detect the improvement, they used a metric
known as ACT (Accuracy of Connective Transla-
tion) (Hajlaoui and Popescu-Belis, 2012; Hajlaoui
and Popescu-Belis, 2013), which relies on bilin-
gual word alignment and a dictionary of DCs. In
the setting, missing/additional DC (i.e. potential
implicitation/explicitation of discourse relations)
are to be checked manually for the validity.
3 Motivation
The motivation behind a discourse-relation-aware
translation model for Chinese is two-fold. First
of all, on top of ambiguous discourse connectives
as in other languages, Chinese documents contain
19
abundant implicit connectives (Xue, 2005). In par-
ticular, complex sentences often occur in the form
of ?running sentences?, in which loose clauses run
in a sequence separated by commas yet without
explicit connectives. Such sentence structures are
used to represent the temporal or reasoning or-
der or related events, or simply to achieve con-
sistent rhythmic patterns. In contrast, syntactical
constraint is prominent in English and this kind
of ?paratactic? structures only occur as occasional
rhetorical measures. In other cases, relations be-
tween clauses within a sentence are marked by co-
ordinating or subordinating conjunctions in order
to maintain an intact sentence structure.
Another motivation is that translation in
units of sentences is not always preferable in
Chinese-English translation. In fact, each comma-
separated segment of a ?running sentence? can
be considered as an elementary discourse units
(EDU) (Yang and Xue, 2012; Zhou and Xue,
2012) and aligned across the two languages.
In current SMT models, sentence splitting is
the result of the language model or translation
rules containing periods or sentence initial
markers. A long Chinese ?running sentence?
is typically translated to one English sentence
with ?comma splices? (ungrammatical commas
between complete sentences without connecting
by conjunctions). On the other hand, discourse
structure provides clues to split the source sen-
tence. It is because some DCs only relate EDUs
within the same sentences (e.g. ?but?, ?because?)
while some only relate with the previous sentence
(e.g. ?however?, ?in addition?)(Stepanov and
Riccardi, 2013).
Example 2 shows two versions of English trans-
lation of a Chinese sentence as output by Google
Translate. Note that in the original Chinese
sentence, all the DCs are omitted to achieve a
quadruplet pattern. Implicit DCs, represented by
glossed words in brackets, can be inserted to each
comma-separated clause to signal the discourse
relations. Without explicit DCs, the MT output
(MT original) results in a sequence of broken
clauses, whereas with inserted DCs (MT w/DC),
the clauses are joined by the translated DCs to
a complete sentence. In addition, the dropped
pronoun ?you? is properly generated, potentially
due to improvement in syntactical parsing of the
source sentence.
Example 2
Source: (??-if)?????????(?-
then)??????(??-but)?????(??-
furthermore)?????(?-and)?????
MT original: Difficult to pay taxes, may suspend
arrears, the new tex is not owed, penalties linked
tax free, paid annually.
MTw/DC: If you have difficulty to pay taxes, you
can suspend the arrears, but the new tax is not
owed and taxes linked to impunity and paid an-
nually.
Ref: Those having difficulty paying taxes can tem-
porarily postponing old debt but not owing on new
taxes, and suspending taxes and waiving fines,
and paying off year by year.
(adapted from Chinese Tree Bank Art.89)
4 Work in progress: Cross-lingual
annotation of discourse relations
Towards building a statistical machine translation
system that tackles discourse relations specifically,
I started manually annotating a Chinese-English
translation corpus with discourse relations. The
purpose of annotation is not only to create data but
also to understand the problems in Chinese dis-
course processing and translation. The completed
annotation is planned to be released.
Comparing with representation of discourse re-
lations by analytical definitions, the PDTB-styled
association of discourse relations to lexical con-
nectives is more compatible to the procedures
of statistical machine translation. Therefore, the
PDTB convention is adopted for the annotation of
connectives on both sides of the parallel corpus.
Instead of sense annotation, the DCs are aligned
in similar manner as the ?translation spotting? ap-
proach (Meyer et al, 2011; Popescu-Belis et al,
2012; Cartoni et al, 2013). In other words, the
?senses? are disambiguated by the translation of
the DCs. The data used is the English Chinese
Translation Treebank (Bies et al, 2007), which
consists of 325 Chinese news stories translated
into 146,300 words of English. Adaptations made
to capture the cross-lingual difference in discourse
relations are explained in the following.
4.1 EDU segmented by punctuations
In the PDTB, the span of each EDU (Arg1 or
Arg2), which can range from a single noun to mul-
tiple sentences, are manually annotated. While
20
each WSJ paragraph
1
contains three sentences on
average, the typical ?running sentences? in Chi-
nese are exceptionally long. It is hard for an-
notators to agree on an EDU span, and neither
does it have direct effect on the DC translation.
Therefore, I follow previous works (Yang and
Xue, 2012; Zhou and Xue, 2012) and consider a
segment separated by Chinese punctuations, espe-
cially commas, as the span of an EDU.
Nonetheless, there are exceptions since Chinese
commas are used arbitrarily to signify ?pauses? in
the sentence. Three original tags are defined to an-
notate the exceptions: ?ATTribution? , ?initialized
ADVerbial?, and ?OPTional comma? (refer to Ta-
ble 1). These are designed for training of auto-
matic EDU segmentation.
4.2 Explicit DCs
After recognizing a valid EDU on the source
text, explicit DC(s) in the EDU are tagged ?EXP?
and aligned to their translation on the target side,
which are not necessarily explicit DCs. In con-
trast with the defined list of subordinating con-
junctions, coordinating conjunctions and adver-
bials, DCs are not limited to any syntactical cat-
egories in this scheme so as to improve the cover-
age of cross-lingual annotation. For example, ?at
the same time? and ?in spite of the fact that? are an-
notated as DC instances, since they function as the
DCs ?simultaneously? and ?although? respectively,
independent of context.
In addition, conjunctions between VP construc-
tions, which are not annotated in the PDTB, are
also annotated as explicit DCs. It is because sub-
jects are often dropped in Chinese and many EDUs
will be ignored if VP constructions are excluded.
4.3 Discourse markers alternative to DCs
Discourse relations can be explicitly marked by
non-DC expressions that are context dependent.
Following the PDTB scheme, the ?ALTLex? tag
is used to annotate such alternative lexicalization
of discourse relations. However, with a loose defi-
nition of DC, few alternative expressions are iden-
tified. Therefore, the ?ALT? tag is defined only
on the English side, which particularly serves to
mark non-DC translation of Chinese DCs. Typi-
cally, English prepositions are tagged ?ALT? and
aligned to Chinese DCs that do not correspond
with any English DCs. For example, ? ??? is
1
A paragraph is considered an independent document in
the PDTB. This annotation scheme follows this assumption.
a common DC for the ?method? relation, yet there
is not a DC for this relation in English and thus it
is often translated to ?by? or ?through?.
4.4 Categorization of DCs
It is observed that subtly different DCs need not
be distinguished for translation, thus they are an-
notated as variations of a same DC. For exam-
ple, explicit occurrences of ?in addition?, ?addi-
tionally?, ?moreover?, ?furthermore? and ?besides?,
all listed as distinct DCs in PDTB, are annotated
as instances of ?in addition?, and ????, ????,
? ???, ? ??? as instances of ? ??? (literally
?but?). An unambiguous DC is used to represent
the DC type, such as ?since? as an instance of ?be-
cause? but not the reverse.
Assigning DCs variations to an unambiguous
type can serve as sense annotation without an ab-
stract taxonomy of senses. External DC lexicon
can also be flexibly added by registering new DC
entries to existing categories. On the other hand,
DCs that are not interchangeable in the syntactical
context, such as ?but? and ?however?, are treated as
distinct DC types in order to deduce discriminative
translation rules.
4.5 Implicit DCs
In order to produce translation rules for all dis-
course relations, including the unmarked ones, im-
plicit DCs (IMP) are inserted after all explicit DCs
are identified in the Chinese EDU. A correspond-
ing implicit DC is also inserted, if possible, as
translation of a Chinese DC (explicit or implicit)
when explicit translation is not identified. Note
that implicit DCs are always annotated by a DC
type instead of a variation to avoid ambiguity.
The IMP tag is used to annotate parallel DC
structures in Chinese. Most Chinese discourse re-
lations are marked by ?parallel DCs?, which are
similar to English patterns such as ?either...or?,
?if...then?, ?not only...but also?. However, one or
both DCs in the parallel structure can be dropped
in Chinese. The dropped DCs are inserted as IMP
and aligned to the English side.
After the first round of the annotation, another
annotator is to repeat the annotation with the set of
DCs recognized by the first annotator. Since im-
plicit discourse relations lack lexical signals, the
annotator agreement is lower (72% for English
(Miltsakaki et al, 2004)). I plan to include im-
plicit DC annotations of both annotators as multi-
ple readings or coexisting DCs of the implicit re-
lations, thus multiplying the training instances.
21
4.6 Redundancy
Usually, two EDUs are related by one DC in En-
glish, thus only one of the Chinese parallel DCs
is translated to explicitly. To learn this transla-
tion rule, the untranslated DC is thus aligned to
a?REDundant? tag attached to the corresponding
English EDU. To mark Chinese DCs that always
occur independently rather than in parallel struc-
ture, the EDU without a DC is also annotated as
?RED?. The various types of tags for DC annota-
tion are summarized in Table 1.
Tags for aligned ?DC?
Chinese English
EXP EXP explicit DC identified
IMP IMP implicit DC insertable
- ALT expressions alternative to DC
RED RED ungrammatical to insert DC
Tags for Non-EDU Chinese segments
ATT source of attribution
ADV adverbial initialized
OPT optional comma for a rhythmic pause
Table 1: Tags for Chi-Eng DC annotations
4.7 Primary analysis of the annotation
To date, 82 articles (about 33000 English words,
about 1/3 of the complete dataset) have been an-
notated, giving rise to 2050 aligned discourse rela-
tions. In addition, 486 punctuation-separated seg-
ments on the Chinese side have been identified as
non-EDU segments. 59 DC types for Chinese and
47 for English have been identified.
Chi -/- Eng EXP. ALT. IMP. RED. Total
EXP. 291 68 23 49 431
IMP. 396 144 770 261 1561
RED. 6 0 0 52 58
Total 693 212 783 362 2050
attribute - - - - 211
optional - - - - 89
adverbial - - - - 186
Total - - - - 486
Table 2: Distribution of alignment between differ-
ent ?DC? types
The distribution of alignments between these
types is shown in Table 2. Although the statis-
tics are not directly comparable to other existing
data due to difference in definitions, it agrees with
previous findings that implicit DCs are abundant
in Chinese (Zhou and Xue, 2012). According to
the present data, about 1/4 of the implicit DCs are
translated to explicit DCs in English. However,
more than half are not explicitly translated (im-
plicit or redundant). This suggests that implicit
DC recovery can be focused on the those that are
likely to be translated explicitly.
It is also observable that explicit Chinese DCs
are mostly translated to an explicit DC in English,
while about 1/6 of them are translated to non-
DC expressions. As mentioned, these are mostly
prepositions corresponding to discourse relations
that are not defined by any DCs in English. This
suggests that bilingual discourse annotation can
recover a larger variation of universal discourse
relations than monolingual annotation. Further ex-
ploratory analysis will be conducted to investigate
the tendency in discourse relation markedness and
alignment, so as to define informative linguistic
features for model training.
Currently, I am using the MAE annotation
tool(Stubbs, 2011). The annotation effort can be
lightened by developing an interface that assists
the multilingual annotation task by, for example,
automatic EDU segmentation (to be reviewed by
annotators) and automatic identification and pre-
alignment of DCs based on a DC dictionary.
5 Future plans
The key of this research is to integrate the an-
notated discourse knowledge into an SMT sys-
tem. Integration of document level parse to MT,
as described in Marcu et al (2000) for Japanese-
to-English translation, is complicated. In addi-
tion, comparing with Japanese, the word order in
Chinese and English are not drastically different.
Therefore, I plan to make use of information from
DC-based shallow discourse parse. My main tasks
towards this system include:
1. Cross-lingual DC annotation
2. EDU segmentation
3. Prediction of source implicit DCs
4. Integration to SMT system
5. DC-aware MT evaluation
A flowchart of these tasks is shown in Figure 1 and
explained in the following.
5.1 EDU segmentation
Discourse parsing can be divided to the tasks
of DC identification and argument identification,
22
Figure 1: Main tasks for proposed DC-aware SMT system.
where the latter can be further divided into argu-
ment position and argument span identification. In
Chinese, a punctuation-separated segment is ba-
sically considered an EDU, so the span is fixed.
The exceptional cases of commas not segmenting
an EDU are annotated in the dataset and can be
predicted in a binary classification task using lex-
ical and syntactical features, as in Yang and Xue
(2012). On the other hand, a text segment can
contain more than one EDU when there are mul-
tiple DCs, thus further segmentation is necessary
depending on DC identification.
5.2 Prediction of source implicit DCs
One focus of this research is to explicitize implicit
Chinese DCs when translating to English. I plan to
construct a model to predict implicit discourse re-
lations in the Chinese source text. Previous works
on Chinese discourse relation recognitions (Yue,
2006; Huang and Chen, 2011) provide insights on
the prediction task and the DC annotated corpus
provides data for supervised training. Although
state-of-the-art implicit discourse parsing is still
of low accuracy, the preciseness can be adjusted
to suit the goal of machine translation. As in other
joint tasks with MT, such as Bouamor et al (2013),
features of whether the implicit DC can be trans-
lated explicitly, or correctly, can in incorporated
to the prediction task, so as to predict translatable
implicit DCs in particular.
5.3 Integration to SMT system
One way to exploit discourse knowledge into an
SMT system is to incorporate the predicted dis-
course features, such as implicit DC, DC sequence
or DC type, into a factored translation model
(Koehn and Hoang, 2007). Another approach is to
decorate identified and predicted DCs in a syntac-
tical parsed tree, so as to enrich the tree-to-string
rules with DC markedness features. Moreover,
when a source DC is translated to a sentence initial
DC, a source sentence is potentially split to mul-
tiple target sentences. A document level decoder
(Hardmeier et al, 2012) that searches beyond the
sentence boundary is thus preferred.
5.4 DC-aware MT evaluation
Comparable evaluation is essential for MT re-
search, yet conventional MT metrics, such as
BLEU, is not effective in detecting improvement
in discourse relation translation (Meyer et al,
2012). One direction is to extend the ACT metrics
(Hajlaoui and Popescu-Belis, 2013) to access also
translation of implicit DCs. Another direction is to
define a measure that is not reference-dependent,
since implicit relations can be translated in various
ways. Moreover, conventional MT metrics, which
compare a candidate with the reference sentence-
by-sentence, have to be modified when used to ac-
cess the overall MT performance of the proposed
system, since the output sentences may not align
with the reference sentences one-by-one.
6 Conclusion
In this thesis proposal, ongoing work and future
plans have been presented towards a discourse-
relation-aware SMT system. The research can
serve as basis for the goal of a document-level MT
system that considers various discourse structures.
Acknowledgement
I would like to thank Baidu for travel and confer-
ence support for this paper.
23
References
Ann Bies, Martha Palmer, Justin Mott, and Colin
Warner. 2007. English chinese translation treebank
v 1.0. Linguistic Data Consortium LDC2007T02,
January.
Houda Bouamor, Behrang Mohit, and Kemal Oflazer.
2013. Sumt: A framework of summarization and
mt. Proceedings of the International Conference on
Natural Language Processing.
Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2001. Building a discourse-tagged cor-
pus in the framework of rhetorical structure theory.
Proceedings of the SIGdial Workshop on Discourse
and Dialogue.
Bruno Cartoni, Sandrine Zufferey, and Thomas Meyer.
2013. Annotating the meaning of discourse connec-
tives by looking at their translation: The translation-
spotting technique. Dialogue and Discourse, 4(2).
Najeh Hajlaoui and Andrei Popescu-Belis. 2012.
Translating english discourse connectives into ara-
bic: a corpus-based analysis and an evaluation met-
ric. Proceedings of the Workshop on Computational
Approaches to Arabic Script-based Languages.
Najeh Hajlaoui and Andrei Popescu-Belis. 2013. As-
sessing the accuracy of discourse connective trans-
lations: Validation of an automatic metric. Compu-
tational LInguistics and Intelligent Text Processing,
7617.
Christian Hardmeier, Joakim Nivre, and J?org Tiede-
mann. 2012. Document-wide decoding for phrase-
based statistical machine translation. Proceedings of
the Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Nat-
ural Language Learning.
Hen-Hsen Huang and Hsin-Hsi Chen. 2011. Chinese
discourse relation recognition. Proceedings of the
International Conference on Natural Language Pro-
cessing.
Hen-Hsen Huang and Hsin-Hsi Chen. 2012. Contin-
gency and comparison relation labelling and struc-
ture prediction in chinese sentences. Proceedings of
the Annual Meeting of the Special Interest Group on
Discourse and Dialogue.
Hen-Hsen Huang, Chi-Hsin Yu, Tai-Wei Chang, Cong-
Kai lin, and Hsin-Hsi Chen. 2013. Analyses of
the association between discourse relation and sen-
timent polarity with a chinese human-annotated cor-
pus. Proceedings of the Linguistic Annotation Work-
shop and Interperability with Discourse.
Philipp Koehn and Hieu Hoang. 2007. Factored trans-
lation models. Proceedings of the Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning.
Ziheng Lin, Hwee Tou Ng, and Min Yen Kan. 2010. A
pdtb-styled end-to-end discourse parser. Technical
report, National University of Singapore.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text.
Daniel Marcu, Lynn Carlson, and Maki Watanabe.
2000. The automatic translation of discourse struc-
tures. Proceedings of the North American Chapter
of the Association for Computational Linguistics.
Thomas Meyer and Lucie Polakova. 2013. Machine
translation with many manually labeled discourse
connectives. Proceedings of the Discourse in Ma-
chine Translation Workshop.
Thomas Meyer, Andrei Popescu-Belis, Sandrine Zuf-
ferey, and Bruno Cartoni. 2011. Multilingual anno-
tation and disambiguation of discourse connectives
for machine translation. Proceedings of the Annual
Meeting of the Special Interest Group on Discourse
and Dialogue.
Thomas Meyer, Andrei Popescu-Belis, and Najeh Ha-
jlaoui. 2012. Machine translation of labeled dis-
course connectives. Proceedings of the Biennial
Conference of the Association for Machine Trans-
lation in the Americas.
Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and
Bonnie Webber. 2004. Annotating discourse con-
nectives and their arguments. Proceedings of the
Workshop on Frontiers in Corpus Annotations.
Emily Pitler and Ani Nenkova. 2009. Using syntax to
disambiguate explicit discourse connectives in text.
Proceedings of the Annual Meeting of the Associa-
tion for Computational Linguistics and the Interna-
tional Joint Conference on Natural Language Pro-
cessing.
Emily Pitler, Annie Louis, and Ani Nenkova. 2009.
Automatic sense prediction for implicit discourse re-
lations in text. Proceedings of the Annual Meeting of
the Association for Computational Linguistics and
the International Joint Conference on Natural Lan-
guage Processing.
Andrei Popescu-Belis, Thomas Meyer, Jeevanthi
Liyanapathirana, Bruno Cartoni, and Sandrine Zuf-
ferey. 2012. Discourse-level annotation over eu-
roparl for machine translation: Connectives and pro-
nouns. Proceedings of the Language Resource and
Evaluation Conference.
Rashmi Prasad, Nikhit Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The penn discourse treebank 2.0.
Proceedings of the Language Resource and Evalua-
tion Conference.
Ted Sanders and Leo Noordman. 2000. The role of
coherence relations and their linguistic markers in
text processing. Discourse Processes, 1.
24
Evgeny A. Stepanov and Giuseppe Riccardi. 2013.
Comparative evaluation of argument extraction al-
gorithms in discourse relation parsing. Proceedings
of the International Conference on Parsing Tech-
nologies.
Amber Stubbs. 2011. Mae and mai: lightweight an-
notation and adjudication tools. Proceedings of the
Linguistic Annotation Workshop.
Mei Tu, Yu Zhou, and Chengqing Zong. 2013. A novel
translation framework based on rhetorical structure
theory. Proceedings of the Annual Meeting of the
Association for Computational Linguistics.
Florian Wolf and Edward Gibson. 2005. Representing
discourse coherence: a corpus-based analysis. Com-
putational Linguistics.
Nianwen Xue. 2005. Annotating discourse connec-
tives in the chinese treebank. Proceedings of the
Workshop on Frontiers in Corpus Annotations.
Yaqin Yang and Nianwen Xue. 2012. Chinese comma
disambiguation for discourse analysis. Proceedings
of the Annual Meeting of the Association for Com-
putational Linguistics.
Ming Yue. 2006. Discursive usage of six chinese punc-
tuation marks. Proceedings of the Annual Meet-
ing of the Association for Computational Linguis-
tics and International Conference on Computational
Linguistics.
Yuping Zhou and Nianwen Xue. 2012. Pdtb-style dis-
course annotation of chinese text. Proceedings of
the Annual Meeting of the Association for Computa-
tional Linguistics.
Zhi-Min Zhou, Yu Xu, Zheng-Yu Niu, Man Lan, Jian
Su, and Chew Lim Tan. 2010. Predicting discourse
connectives for implicit discourse relation recogni-
tion. Proceedings of the International Conference
on Computational Linguistics.
Lan Jun Zhou, Wei Gao, Binyang Li, Zhongyu Wei,
and Kam-Fat Wong. 2012. Cross-lingual iden-
tification of ambiguous discourse connectives for
resource-poor language. Proceedings of the Inter-
national Conference on Computational Linguistics.
25
Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pages 139?144,
Atlanta, Georgia, 13-14 June 2013. c?2013 Association for Computational Linguistics
Construction of English MWE Dictionary and
its Application to POS Tagging
Yutaro Shigeto, Ai Azuma, Sorami Hisamoto, Shuhei Kondo, Tomoya Kose,
Keisuke Sakaguchi, Akifumi Yoshimoto, Frances Yung, Yuji Matsumoto
Nara Institute Science of Technology (NAIST)
Ikoma, Nara 630-0192 Japan
yutaro-s@is.naist.jp
Abstract
This paper reports our ongoing project for
constructing an English multiword expression
(MWE) dictionary and NLP tools based on
the developed dictionary. We extracted func-
tional MWEs from the English part of Wik-
tionary, annotated the Penn Treebank (PTB)
with MWE information, and conducted POS
tagging experiments. We report how the
MWE annotation is done on PTB and the re-
sults of POS and MWE tagging experiments.
1 Introduction
While there have been a great progress in POS
tagging and parsing of natural language sentences
thanks to the advancement of statistical and corpus-
based methods, there still remains difficulty in sen-
tence processing stemming from syntactic discrep-
ancies. One of such discrepancies is caused by mul-
tiword expressions (MWEs), which are known and
defined as expressions having ?idiosyncratic inter-
pretations that cross word boundaries (or spaces)?
(Sag et al, 2002).
Sag et al (2002) classifies MWEs largely into the
following categories:
? Lexicalized phrases
? fixed expressions: Those having fixed
word order and form (e.g. by and large).
? semi-fixed expressions: Those having
fixed word order with lexical variation
such as inflection, determiner selection,
etc. (e.g. come up with).
? syntactically flexible expressions: Those
having a wide range of syntactic variabil-
ity (e.g. phrasal verbs that take an NP ar-
gument between or following the verb and
the particle).
? Institutionalized phrases
? Phrases that are semantically and syntac-
tically compositional, such as collocations
(e.g. traffic light).
This paper reports our ongoing project for devel-
oping an English MWE dictionary of a broad cov-
erage and MWE-aware natural language processing
tools. The main contributions of this paper are as
follows:
1. Construction of an English MWE dictionary
(mainly consisting of functional expressions)
through extraction from Wiktionary1.
2. Annotation of MWEs in the Penn Treebank
(PTB).
3. Implementation of an MWE-aware POS tagger
and evaluation of its performance.
2 Related work
While there is a variety of MWE researches only a
few of them focus on MWE lexicon construction.
Though some examples, such as French adverb dic-
tionaries (Laporte and Voyatzi, 2008; Laporte et al,
2008), a Dutch MWE dictionary (Gre?goire, 2007)
and a Japanese MWE dictionary (Shudo et al, 2011)
have been constructed, there is no freely available
English MWE dictionary with a broad coverage.
Moreover, MWE-annotated corpora are only
available for a few languages, including French and
1https://en.wiktionary.org
139
Swedish. While the British National Corpus is anno-
tated with MWEs, its coverage is far from complete.
Considering this situation, we started construction
of an English MWE dictionary (with functional ex-
pressions first) and classified their occurrences in
PTB into MWE or literal usage, obtaining MWE-
annotated version of PTB.
The effect of MWE dictionaries have been re-
ported for various NLP tasks. Nivre and Nilsson
(2004) investigated the effect of recognizing MWEs
in syntactic dependency parsing of Swedish. Ko-
rkontzelos and Manandhar (2010) showed perfor-
mance improvement of base phrase chunking by an-
notating compound and proper nouns. Finlayson
and Kulkarni (2011) reported the effect of recogniz-
ing MWEs on word sense disambiguation.
Most of the previous approaches to MWE recog-
nition are based on frequency or collocation mea-
sures of words in large scale corpora. On the other
hand, some previous approaches tried to recognize
new MWEs using an MWE lexicon and MWE-
annotated corpora. Constant and Sigogne (2011)
presented MWE recognition using a Conditional
Random Fields (CRFs)-based tagger with the BIO
schema. Green et al (2011) proposed an MWE
recognition method using Tree Substitution Gram-
mars. Constant et al (2012) compared two phrase
structure analysis methods, one that uses MWE
recognition as preprocessing and the other that uses
a reranking method.
Although MWEs show a variety of flexibilities
in their appearance, most of the linguistic analyses
consider the fixed type of MWEs. For example, the
experiments by Nivre and Nilsson (2004) focus on
fixed expressions that fall into the following cate-
gories:
1. Multiword names
2. Numerical expressions
3. Compound function words
(a) Adverbs
(b) Prepositions
(c) Subordinating conjunctions
(d) Determiners
(e) Pronouns
Multiword names and numerical expressions be-
have as noun phrases and have limited syntactic
functionalities. On the other hand, compound func-
tion words have a variety of functionalities that may
affect language analyses such as POS tagging and
parsing. In this work, we extract compound func-
tional expressions from the English part of Wik-
tionary, and classify their occurrences in PTB into
either literal or MWE usages. We then build a POS
tagger that takes MWEs into account. In implement-
ing this, we use CRFs that can handle a sequence of
tokens as a single item (Kudo et al, 2004). We eval-
uate the performance of the tagger and compare it
with the method that uses the BIO schema for iden-
tifying MWE usages (Constant and Sigogne, 2011).
3 MWEs Extraction from Wiktionary
To construct an English MWE dictionary, we extract
entries from the English part of Wiktionary (as of
July 14, 2012) that include white spaces. We ex-
tract only fixed expressions that are categorized ei-
ther as adverbs, conjunctions, determiners, prepo-
sitions, prepositional phrases or pronouns. We ex-
clude compound nouns and phrasal verbs since the
former are easily recognized by an existing method
such as chunking and the latter need more sophis-
ticated analyzing methods because of their syntac-
tic flexibility. We also exclude multiword adjec-
tives since many of them are semi-fixed and behave
differently from lexical adjective, having predica-
tive usage only. Table 1 summarizes the numbers
of MWE entries in Wiktionary and the numbers of
them that appear at least once in PTB.
4 Annotation of MWEs in PTB
While it is usually not easy to identify the usage of
an MWE as either an MWE or a literal usage, we
initially thought that the phrase structure tree an-
notations in PTB would have enough information
to identify their usages. This assumption is cor-
rect in many cases (Figures 1(a) and 1(b)). The
MWE usage of ?a bit? in Figure 1(a) is analyzed as
?NP-ADV?, suggesting it is used as an adverb, and
the literal usage of ?a bit? in Figure 1(b) is labeled
as ?NP?, suggesting it is used literally. However,
there are a number of examples that are annotated
differently while their usages are the same. For ex-
ample, Figures 1(c), 1(d) and 1(e) all show RB us-
140
Table 1: Number of MWE types in Wiktionary and Penn Treebank
Adverb Conjunction Determiner Preposition Prepositional Phrase Pronoun
Wiktionary 1501 49 15 110 165 83
PTB 468 35 9 77 66 18
Examples after all as wll as a number of according to against the law no one
VP
VB
heat
PRT
up
NP-ADV
DT
a
NN
bit
(a) MWE usage as RB
ADVP
NP
DT
a
NN
bit
PP
IN
of
NP
NN
chromosome
CD
13
(b) Literal usage as NP
ADVP
NP-ADV
DT
a
RB
bit
JJR
smaller
(c) MWE usage as RB
ADVP
NP
DT
a
NN
bit
RBR
better
(d) MWE usage as RB
ADJP-PRD
NP
DT
a
RB
bit
JJR
isolated
(e) MWE usage as RB
Figure 1: Examples of phrase structures annotated to ?a bit?
age of ?a bit? while they are annotated differently 2.
Sometimes, the same structure tree is annotated to
instances of different usages (Figures 1(b) and 1(d)).
Therefore, for eachMWE candidate, we first clus-
ter its occurrences in PTB according to their phrase
tree structures. Some of the clusters clearly indi-
cate MWE usages (such as ?NP-ADV? trees in Fig-
ures 1(a) and 1(c)). In such cases, we regarded all in-
stances as MWE usages and annotated them as such.
For inconsistent or ambiguous cases (such as ?NP?
trees in Figures 1(b), 1(d) and 1(e)), we manually
classify each of them into either MWE or literal us-
age (some MWEs have multiple MWE usages). We
find a number of inconsistent POS annotations on
some internal words of MWEs (e.g. ?bit? in Fig-
ures 1(c) and 1(e) are annotated as RB while they
should be NN). We correct such inconsistent cases
(correction is only done on internal words of MWEs,
selecting the majority POS tags as correct). The total
number of POS tag corrections made on PTB (chap-
ter 00-24) was 1084.
2The POS tags in the trees are: RB(adverb), IN(preposition),
DT(determiner), NN(common noun) ...
5 Experiments of POS tagging and MWE
recognition
5.1 Experiment Setting
We conduct POS tagging experiments on the MWE-
annotated PTB, using sections 0-18 for training and
sections 22-24 for test as usual.
For the experiments, we use four versions of PTB
with the following POS annotations.
(a) Original: PTB with the original POS annota-
tion
(b) Revised: PTB with correction of inconsistent
POS tags
(c) BIO MWE: MWEs are annotated with the BIO
schema
(d) MWE: MWEs are annotated as single words
Concerning the MWE annotation in (c) and (d),
the total number of MWE tokens in PTB is 12131
(9417 in the training chapters, 1396 in the test
chapters, and 1319 for the remaining (development)
chapters).
Each word is annotated with the following in-
141
Figure 2: Example of lattice containing MWE (?about to/RB?) (correct path is marked with bold boxes.)
Table 2: Examples of MWE annotations in four versions
Version Word/POS
(a) Original about/RB to/TO
(b) Revised about/IN to/TO
(c) BIO MWE about/RB-B to/RB-I
(d) MWE about to/RB
formation: coarse-grained POS tag (CPOS), fine-
grained POS tag (FPOS) and surface form. Each
MWE is further annotated with its POS tag, surface
form, its internal words with their POS tags.
Table 2 shows sample annotations of MWE
?about to? in each of the four versions of PTB. In
(a), ?about/RB? is annotated incorrectly, which is
corrected in (b). In (c), ?-B? indicates the beginning
token of an MWE and ?-I? indicates an inside posi-
tion of an MWE. In (d), ?about to? is annotated as
an RB (we omit the POS tags for its internal words,
which are IN and TO).
We use a CRF-based tagger for training and test
on all the four PTB versions. Our CRF can han-
dle ?words with spaces? (e.g. ?about to? as a single
token as well as separated tokens) as shown in Fig-
ure 2. This extension is only relevant to the case of
the (d) MWE version.
Table 3 summarizes the set of feature templates
used in the experiments. In Table 3, ?Head POS?
means the POS tag of the beginning token of an
MWE. In the same way, ?Tail POS? means the POS
tag of the last token of an MWE. For example, for
?a lot of /DT?, its Head POS is DT and its Tail POS
is IN.
We evaluate POS tagging accuracy and MWE
recognition accuracy. In POS evaluation, each to-
ken receives a tag in the cases of (a), (b) and (c), so
the tagging accuracy is straightforwardly calculated.
Table 3: Feature templates used in CRF training
Unigram features
Surface form
FPOS, Surface form
CPOS, Surface form
Bigram features (left context / right context)
Surface form / FPOS, Surface form
FPOS, Surface form / Surface form
Tail POS, Surface form / Head POS, Surface form
Surface form / Head POS
Tail POS / Head POS
Tail POS / Surface form
In the case of (d), since MWEs are analyzed as sin-
gle words, they are expanded into the internal words
with their POS tags and the evaluated on the token
basis.
MWE recognition accuracy is evaluated for the
cases of (c) and (d). For the purpose of comparison,
we employ a simple baseline as well. This baseline
assigns each occurrence of an MWE its most fre-
quent usage in the training part of PTB. Evaluation
of MWE recognition accuracy is shown in precision,
recall and F-measure.
We use the standard set of features based on uni-
gram/bi-gram of words/POS. For our MWE version,
we add the word forms and POS tags of the first and
the last internal words of MWEs as shown in Ta-
ble 3.
5.2 Experimental Results
Table 4 shows the results of POS tagging. A slight
improvement is observed in (b) compared with (a)
because some of inconsistent tags are corrected.
Further improvement is achieved in (d). The exper-
iment on (c) does not show improvement even over
142
Figure 3: Example of errors: ?after all /RB? and ?a /DT bit /JJ.?
Table 4: Per token accuracy (precision)
Version Accuracy
(a) Original 97.54
(b) Revised 97.56
(c) BIO MWE 97.32
(d) split MWE 97.62
Table 5: Recognition performance of MWEs
Precision Recall F-measure
Baseline 78.79 80.26 79.51
(c) BIO 92.81 90.90 90.18
(d) MWE 95.75 97.16 96.45
(a). The reason may attribute to the data sparseness
caused by the increased size of POS tags.
Table 5 shows the results of MWE recognition.
Our MWE-aware CRF model (d) shows the best re-
sults. While the BIO model (c) significantly outper-
forms the baseline, it gives significantly lower re-
sults than our model.
We investigated errors in (d) and categorized them
into three types.
? False Positive: System finds an MWE, while it
is actually literal.
? False Negative: System misses to identify an
MWE.
? Misrecognition: System finds an MWE
wrongly (correct answer is another MWE).
Table 6 shows number of recognition errors of
MWEs.
An example of the False Positive is ?a bit /RB? in
Figure 3, which actually is a literal usage and should
be tagged as ?a /DT, bit /NN?.
An example of the False Negative is ?in black and
white /RB?, which is not recognized as an MWE.
One reason of this type of errors is low or zero fre-
quency of such MWEs in training data. ?after all
/RB? (in Figure 3) is another False Negative exam-
ple.
Table 6: Recognition error of MWEs
Error types # of errors
False Positives 33
False Negatives 19
Misrecognition 17
One example of Misrecognition errors stems from
ambiguous MWEs. For example, while ?how much?
only has MWE usages as RB, there are two RB
usages of ?how much? that have different POS
tag sequences for the internal words. Other ex-
amples of Misrecognition are due to zero or low
frequency MWEs, whose substrings also matches
shorter MWEs: ?quite/RB, a few/PRP? while cor-
rect analysis is ?quite a few/RB?, and ?the hell /RB,
out of /IN? while the correct analysis is ?the hell out
of /RB?.
6 Conclusion and Future work
This paper presented our ongoing project for con-
struction of an English MWE dictionary, and its ap-
plication to MWE-aware POS tagging. The exper-
imental results show that the MWE-aware tagger
achieved better performance on POS tagging and
MWE recognition. Although our current MWE dic-
tionary only covers fixed types of functional MWEs,
this dictionary and MWE annotation information on
PTB will be made publicly available.
We plan to handle a wider range of MWEs such as
phrasal verbs and other semi-fixed and syntactically
flexible MWEs, and to develop a POS tagger and a
syntactic parser on top of them.
References
Matthieu Constant and Anthony Sigogne. 2011. MWU-
Aware Part-of-Speech Tagging with a CRF Model and
Lexical Resources. In Proceedings of the Workshop on
Multiword Expressions: from Parsing and Generation
to the Real World, MWE ?11, pages 49?56.
143
Matthieu Constant, Anthony Sigogne, and Patrick Wa-
trin. 2012. Discriminative Strategies to Integrate Mul-
tiword Expression Recognition and Parsing. In Pro-
ceedings of the 50th Annual Meeting of the Association
for Computational Linguistics, ACL ?12, pages 204?
212.
Mark Alan Finlayson and Nidhi Kulkarni. 2011. De-
tecting Multi-Word Expressions improves Word Sense
Disambiguation. In Proceedings of the Workshop on
Multiword Expressions: from Parsing and Generation
to the Real World, MWE ?11, pages 20?24.
Spence Green, Marie-Catherine deMarneffe, John Bauer,
and Christopher D Manning. 2011. Multiword Ex-
pression Identification with Tree Substitution Gram-
mars: A Parsing tour de force with French. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, EMNLP ?11, pages
725?735.
Nicole Gre?goire. 2007. Design and Implementation of
a Lexicon of Dutch Multiword Expressions. In Pro-
ceedings of the Workshop on a Broader Perspective on
Multiword Expressions, MWE ?07, pages 17?24.
Ioannis Korkontzelos and Suresh Manandhar. 2010. Can
Recognising Multiword Expressions Improve Shallow
Parsing? In Human Language Technologies: The
2010 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
HLT ?10, pages 636?644.
Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.
2004. Applying conditional random fields to japanese
morphological analysis. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, EMNLP ?04, pages 230?237.
Eric Laporte and Stavroula Voyatzi. 2008. An Electronic
Dictionary of French Multiword Adverbs. In Lan-
guage Resources and Evaluation Conference. Work-
shop Towards a Shared Task for Multiword Expres-
sions, MWE ?08, pages 31?34.
Eric Laporte, Takuya Nakamura, and Stavroula Voy-
atzi. 2008. A French Corpus Annotated for Mul-
tiword Nouns. In Proceedings of the Language Re-
sources and Evaluation Conference. Workshop To-
wards a Shared Task on Multiword Expressions, MWE
?08, pages 27?30.
Joakim Nivre and Jens Nilsson. 2004. Multiword Units
in Syntactic Parsing. In Workshop on Methodologies
and Evaluation of Multiword Units in Real-World Ap-
plications, MEMURA ?04, pages 39?46.
Ivan A Sag, Timothy Baldwin, Francis Bond, Ann A
Copestake, and Dan Flickinger. 2002. Multiword Ex-
pressions: A Pain in the Neck for NLP. In Proceed-
ings of the Third International Conference on Com-
putational Linguistics and Intelligent Text Processing,
CICLing ?02, pages 1?15.
Kosho Shudo, Akira Kurahone, and Toshifumi Tanabe.
2011. A Comprehensive Dictionary of Multiword Ex-
pressions. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, HLT ?11, pages 161?
170.
144
