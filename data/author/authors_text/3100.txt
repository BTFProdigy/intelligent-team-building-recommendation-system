Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 945?952
Manchester, August 2008
A Fluid Knowledge Representation for Understanding and Generating
Creative Metaphors
Tony Veale
School of Computer Science
University College Dublin
Ireland
tony.veale@ucd.ie
Yanfen Hao
School of Computer Science
University College Dublin
Ireland
yanfen.hao@ucd.ie
Abstract
Creative metaphor is a phenomenon that
stretches and bends the conventions of se-
mantic description, often to humorous and
poetic extremes. The computational mod-
eling of metaphor thus requires a knowl-
edge representation that is just as stretch-
able and semantically accommodating. We
present here a flexible knowledge repre-
sentation for metaphor interpretation and
generation, called Talking Points, and de-
scribe how talking points can be acquired
on a large scale from WordNet (Fellbaum,
1998) and from the web. We show how
talking points can be fluidly connected to
form a slipnet, and demonstrate that talk-
ing points provide an especially concise
representation for concepts in general.
1 Introduction
Metaphor serves two important roles in language.
The first of these is to make the unfamiliar and the
strange seem more familiar and understandable
(Indurkhya, 1992). For instance, one might
describe a burqa (a full body covering for Muslim
women) as a suit of armor, as a shield against
prying eyes or, depending on one?s communi-
cation goal, as a wearable cage. The other role
of metaphor is most often associated with the
poetic and fanciful use of language, but is no less
important: to make the familiar and mundane
seem strange and unfamiliar. In this latter guise,
metaphor allows us to view a commonplace idea
from a new and revealing category perspective
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
(Camac and Glucksberg, 1984). For instance,
one might describe makeup as ?the Western
burqa?, to communicate not just the idea that each
involves a covering of the female form, but that
each reflects a society-imposed expectation on
the public presentation of women. Each of these
roles is a manifestation of the same underlying
mechanism for combining concepts, for under-
standing how they interact (Black, 1962) and for
determining how they are connected (Fauconnier
and Turner, 1998), even if those connections are
tenuous, hidden or not always obvious (Collins
and Loftus, 1975). For example, consider the
connections needed to make and understand the
above metaphors:
Burqa ?
? for concealing a Muslim woman
? for protecting a Muslim woman
? protecting a woman
? for protecting a person
Armor ?
Make-up ?
? typically worn by women
? expected to be worn by women
? must be worn by women
? must be worn by Muslim women
Burqa ?
In each case we see how metaphor draws out
and highlights, in a modified or exaggerated form,
an existing aspect of each target concept. In
other words, metaphor does not indiscriminately
transplant arbitrary aspects of a source concept
onto a target, but accommodates a selective
graft of the most salient aspects of this source
concept onto those aspects of the target that can
945
be highlighted by the comparison (Ortony, 1979).
This connection between concepts requires a
flexible knowledge representation, one that allows
the connections between non-identical source and
target aspects to be recognized, reconciled and
even compressed (Fauconnier and Turner, 1998).
This fluid representation (Hofstadter et al, 1995)
defines the search space in which the processes of
metaphor generation and metaphor understanding
are cognitively situated (Veale and O?Donoghue,
2000): for generation, fluid connectivity allows a
system to search outwards from a given target to
find those potential source concepts that offer a
new yet appropriate perspective; for understanding
purposes, connectivity allows an agent to focus
on those key aspects of a source concept that are
most apt for a target because they can be linked to
that target.
In this paper we describe the construction
of a fluid knowledge representation for creative
metaphor processing, one that is acquired automat-
ically from WordNet (Fellbaum, 1998) and from
the texts of the web. In section 2 we summarize
related work in the field of metaphor as it pertains
to flexible knowledge representation. In section 3
we describe two complementary means of acquir-
ing the basic elements of this representation, from
WordNet and from the web, before describing how
these elements can be placed into a fluid network
of connections - what Hofstadter (ibid) calls a slip-
net - in section 4. We then present in section 5
some empirical evaluation of the acquired repre-
sentation on an objective test of term categoriza-
tion, before concluding with some consideration of
future work in section 6.
2 Related Work
Since metaphor can be viewed as a stretching
of linguistic conventions to cover new conceptual
ground, the interpretation of metaphor crucially
hinges on a systems ability to recognize these con-
ventions and accommodate the exceptional mean-
ing conveyed by each figurative expression. In-
deed, most computational approaches embody a
sense of what it means to be literal, and accom-
modate metaphoric meanings within this conven-
tional scheme through a form of relaxation, map-
ping or translation. Wilks (1978) advocates that
the typically hard constraints that define a literal
semantics should instead be modeled as soft pref-
erences that can accommodate the violations that
arise in metaphoric utterances, while Fass (1991)
builds on this view to show how these violations
can be repaired to thus capture the literal intent be-
hind each metaphor. This repair process in turn
relies on the availability of a concept taxonomy
through which metaphoric uses can be mapped
onto their literal counterparts; a car that ?drinks
gasoline? would thus be understood as a car that
?consumes gasoline?. Way (1991) emphasizes
the importance of this taxonomy by positing a
central role for a dynamic type hierarchy (DTH)
in metaphor, one that can create new and com-
plex taxonyms on the fly. For instance, Way?s
DTH would understand the ?make-up as Western
burqa? metaphor via a dynamically created tax-
onym like things-women-are-expected-to-wear-in-
public, though Way offers no algorithmic basis
for the workings of such a remarkable taxonomy.
Another family of computational approaches com-
bines explicit knowledge about certain metaphors
with knowledge about the domains connected by
these metaphors. Martin?s (1990) Midas sys-
tem encodes schematic knowledge about conven-
tionalized metaphors such as ?to kill a process?
and ?to open a program?, and uses this knowl-
edge to fit novel variations of these metaphors
into the most appropriate schemas. Barnden and
Lee (2002) focus on the role of inference in a
metaphorically-structured domain, and describe a
system called ATTMeta that contains sufficient
knowledge about e.g., conventional metaphors of
mind to reason about the mental states implied by
these metaphors. Each of these approaches sees
metaphor interpretation as a process of fitting what
is said to what can meaningfully be represented
and reasoned about. This fitting process is most ex-
plicitly modelled by Hofstadter et al (1995), who
focus on the slippage processes that are required to
understand analogies in abstract domains that e.g.,
involve the mapping of letter sequences or the mir-
roring of actions in a highly stylized tabletop en-
vironment. Though simplified and toy-like, these
are non-deterministic problem domains that are
nonetheless shaped by a wide range of pragmatic
pressures. Hofstadter and Mitchell (1994) model
these pressures using a slipnet, a probabilistic net-
work in which concepts are linked to others into
which they can slip or be substituted with. In this
view, deeply embedded concepts that are further
removed from direct observation are less likely to
engage in slippage than more superficial concepts.
946
To take a linguistic example, word choice in natu-
ral language generation is more susceptible to slip-
page (as influenced by synonym availability) than
the concepts underlying the meaning of a sentence.
Slippage can be seen as a lossy form of con-
ceptual re-representation: the greater the slippage,
the more dramatic the re-representation and the
greater the potential for loss of accuracy. For
instance, a recent magazine cover proclaims the
governor of California, Arnold Schwarzenegger,
as ?president of 12% of the United States?. This
conceptualization can be viewed as an interme-
diate stage in a slippage path from Governor to
President as follows:
Governor of California ?
? governor of 12% of the United States
? leader of 12% of the United States
? president of 12% of the United States
? president of 100% of the United States
President of the U.S. ?
This labeling is creative enough to grace a
magazine cover because it involves an ambitious
level of re-conceptualization, at least from a
computational perspective. The pivotal insight
comes from California = 12% of the United
States, an ad-hoc synonym that one is unlikely to
find in a dictionary or general-purpose resource
like WordNet. While ultimately aiming for this
kind of creative transformation, our goal in this
paper is more modest: to build a slippage network
of concepts that are connected via their most
salient features, one that combines the principled
flexibility of a Hofstadter-style slipnet with the
comprehensive scale of a resource like WordNet.
3 Acquiring Conceptual Talking Points
We refer to the knowledge elements connected
by this slipnet as conceptual talking points. We
first describe the form of these talking points
and how they are acquired, before describing in
section 4 how slippage operates between these
talking points. We discuss two complementary
kinds of talking point here: objective descriptions,
extracted from WordNet glosses, and informal,
stereotypical descriptions, harvested from the text
of the web via a search engine like Google.
3.1 Objective Talking Points
Objective talking points are aspects of conceptual
description that contribute to the consensus defini-
tional view of a concept. Though WordNet does
not provide explicit semantic criteria for the defi-
nition of each lexical concept, many of these cri-
teria can be gleaned from a shallow parse of the
pithy dictionary gloss it associates with each (e.g.,
see Ahlswede and Evans, 1988). Thus, whenever
the head phrase of a concept?s gloss has the form
?ADJ
+
NOUN? where NOUN can denote a hyper-
nym of the concept, we can associate the talking
point is ADJ:NOUN with that concept. For exam-
ple, the gloss of {Hamas} is ?a militant Islamic
fundamentalist political movement that ...?, which
yields the talking points is militant:movement,
is islamic:movement, is fundamentalist:movement
and is political:movement for Hamas. When a
WordNet concept has a hypernym of the form
{ADJ NOUN}, where NOUN can denote a hy-
pernym of this concept, we likewise associate
the talking point is ADJ:NOUN with that con-
cept. For example, {Taliban, Taleban} has
{religious movement} as a hypernym, which
yields is religious:movement as a talking point for
Taliban.
Objective talking points can also be gleaned
from the subject-verb-object structure of a Word-
Net gloss. For instance, the gloss for synset
{conductor, music director} is ?the person who
leads a musical group?, which yields the talking
point leads:musical group. The hypernym of
this concept, {musician}, has the gloss ?artist
who composes or conducts music ...?, which
yields the talking points composes:music and con-
ducts:music that are then inherited by {conductor,
...} and other sub-types of musician in WordNet.
A shallow parse will generally not lead to a
complete understanding of a concept, but will
typically produce some interesting talking points
of the predicate:object variety that can be used
to relate a concept to others that are analogically
or metaphorically similar. Using WordNet?s
noun and verb taxonomies, we can identify the
following slippage paths between talking points:
composes:music ? composes:speech ?
writes:speech ? writes:oration ? writes:sermon
? writes:law ? writes:philosophy ?
writes:theorem ? writes:plan ? ...
947
In all, we extract talking points of the form
is adj:noun for over 40,000 WordNet concepts,
and talking points of the form verb:noun for over
50,000 concepts. However, the real power of
talking points emerges when they are connected to
form a slipnet, as we discuss in section 4.
3.2 Stereotypical Talking Points
The talking points we harvest from the web do not
have the authoritative, definitional character we
find in hand-crafted resources like WordNet, but
they do reflect how people typically speak of (and,
perhaps, actually think of) the world. Veale and
Hao (2007) argue that similes present the clear-
est window into the stereotypical talking points
that underpin everyday conversations, and collect
from the web instances of the pattern ?as ADJ as a
*? for thousands of WordNet adjectives. Though
the simile frame is somewhat leaky in English,
and prone to subversion by irony, Veale and Hao
construct a comprehensive database of more than
12,000 highly stereotypical adjective:noun asso-
ciations, such as precise:surgeon, straight:arrow,
balanced:pyramid and sharp:knife. We use their
data here, as the basis of an additional web harvest-
ing process to gather stereotypical talking points
of the form has ADJ:facet. For every stereotypi-
cal association ADJ:NOUN in their database, we
send the query ?the ADJ * of a|an|the NOUN? to
Google and collect noun values for the wildcard *
from the first 200 hits returned for each query.
This pattern allows us to determine the con-
ceptual attributes that are implicit in each stereo-
typical adjective:noun pairing. For instance, ?the
delicate hands of a surgeon? and ?the inspiring
voice of a preacher? reveal that hand is a salient
attribute of surgeons while voice is a salient at-
tribute of preachers. The frequency with which
we find these attributes on the web also allows
us to build a textured representation for each con-
cept. So while these expanded web patterns also
reveal that surgeons have a thorough eye and
steady nerves, ?the hands of a surgeon? are men-
tioned far more frequently and are thus far more
salient to our understanding of surgeons. To avoid
noise, the set of allowable attribute nouns, such
as hands, soul, heart, voice, etc., is limited to the
nouns in WordNet that denote a kind of trait, body
part, quality, activity, ability or faculty. This al-
lows us to acquire meaningful talking points like
has magical:skill for Wizard, has brave:spirit for
Lion and has enduring:beauty for Diamond, while
avoiding dubious or misleading talking points like
has proud:owner for Peacock that lack either rep-
resentational value or insight. In all, this pro-
cess acquires 18,794 stereotypical talking points
for 2032 different WordNet noun senses, for an av-
erage of 9 facet:feature pairs per sense. Specific
senses are identified automatically, by exploiting
WordNet?s network of hypernymy and synonymy
relations to connect talking points that describe
variations of the same concept.
4 Building a Slipnet of Talking Points
To construct a slipnet in the style of Hofstadter
and Mitchell (1994), but on the scale of WordNet,
we need to connect those talking points that ex-
press similar but different meanings, and to quan-
tify the difference between these meanings. Is-
sues of scale mean that we need only connect
talking points that are close in meaning, since
greater slippage can be achieved by following
longer paths through the slipnet. This slippage can
be based on semantic or pragmatic criteria. Thus,
the talking points has sacred:authority (for Pope)
and has sacred:power (for God) are semantically
similar since the potency sense of ?authority? is
a specialization of the control sense of ?power?
in WordNet. Likewise, writes:speech and com-
poses:speech are similar because ?compose? and
?write? are synonymous in the context of literary
creation, and it is this particular linkage that sup-
ports a slippage pathway from composes:music to
writes:poetry. In contrast, is political:movement
(for Hamas) and is religious:movement (for Tal-
iban) are pragmatically similar since movements
that are religious often have a political agenda also.
We can use WordNet to construct the semantic
links of the slipnet, but pragmatic links like these
require not just word senses but a sense of the
world, of a kind we can distil from the text of the
web.
Two talking points is ADJ
1
:OBJ
1
and
is ADJ
2
:OBJ
2
should be connected in the
slipnet if: OBJ
1
and OBJ
2
are semantically close
(i.e., synonymous, or semantic siblings in Word-
Net); and ADJ
1
and ADJ
2
are synonymous, or
ADJ
1
frequently implies ADJ
2
or ADJ
2
frequently
implies ADJ
1
. These implications are recog-
nized and quantified using another web trawling
process, in which the query ?as * and * as? is
used to harvest pairs of adjectives that are seen to
948
mutually reinforce each other in web comparisons.
This search reveals that ?religious? reinforces
?superstitious? (5 times), ?moral? (4), ?political?
(3), ?conservative? (3), ?intolerant? (2) and
?irrational? (1). These slippage connections link
is religious:movement to is political:movement
(pragmatic) to is political:campaign (semantic)
to is military:campaign (pragmatic), thereby
connecting Taliban (is religious:movement) to
Crusade (is military:campaign).
4.1 The Slipnet in Action
Slippage is a phenomenon best explained with an
example, so consider again the task of creating
metaphors for the concept Pope. We have al-
ready seen that slippage among talking points al-
lows Pope to be linked to the concept God via Pope
? has sacred:authority ? has sacred:power ?
God. Pope can also be linked to Rabbi via the
path Pope ? has sacred:words ? has wise:words
? Rabbi and to Judge by extending this pathway:
Pope ? has sacred:words ? has wise:words ?
has solemn:words ? Judge. Black (1962) saw
metaphor as an interaction between concepts, in
which the interpretation of a particular source con-
cept depends crucially on how it is able to inter-
act with a specific target concept. This concept-
sensitive interplay is clearly on display here. The
Pope can be metaphorically viewed as a warrior
not by considering what it means for a generic
person to be a warrior, but by considering how
the concept Pope actually interacts with the con-
cept Warrior, e.g., Pope ? has infallible:voice ?
has powerful:voice ? Warrior.
Consider the potential for slippage between ob-
jective talking points from WordNet:
Pope ?
? leads:Roman Catholic Church
? leads:congregation
? leads:flock
? leads:mob
? leads:organized crime
Don (Crime Father) ?
Pope ?
? leads:Roman Catholic Church
? leads:congregation
? leads:political movement
? leads:gang
? leads:military force
Warlord (Military Leader) ?
One can typically terminate a slippage path at
any point, to produce different metaphors with
varying semantic similarity to the starting con-
cept. Thus, at leads:flock one can reach Shepherd,
and from leads:political movement, one can reach
Civil rights leader.
A lexicon alone, like WordNet, is generally in-
sufficient for metaphor processing, but such a re-
source can still reveal useful lexical resonances
that may enrich an interpretation. In the exam-
ple above, we see a resonance between the Pope,
which WordNet alo lexicalizes as ?holy father?,
and a mafia Don, which WordNet alo lexicalizes
as ?father?. Indeed, since WordNet conceptualizes
Roman Catholic Church as a specialization of Or-
ganized religion, the metaphor establishes a par-
allelism between crime and religion as organized
activities.
5 Empirical Evaluation
To understand whether talking points are suffi-
ciently descriptive of the concepts they are ac-
quired for, we replicate here the clustering ex-
periments of Almuhareb and Poesio (2004, 2005)
which are designed to measure the effectiveness of
web-acquired conceptual descriptions. Since Al-
muhareb and Poesio use WordNet as a semantic
gold-standard, we consider here the effectiveness
of stereotypical talking points alone; it would be
circular to consider objective talking points, since
these are extracted from WordNet.
Almuhareb and Poesio describe two different
clustering experiments. In the first, they choose
214 English nouns from 13 of WordNet?s upper-
level semantic categories, and proceed to harvest
property values for these concepts from the web
using the pattern ?a|an|the * C is|was?. This pat-
tern yields a combined total of 51,045 values for
all 214 nouns; these values are primarily adjec-
tives, such as hot, black, etc., but noun-modifiers
of C are also allowed, such as fruit for cake. They
also harvest 8934 attribute nouns, such as temper-
ature and color, using the query pattern ?the * of
the C is|was?. These values and attributes are then
used as the basis of a clustering algorithm to parti-
tion the 214 nouns back into their original 13 cate-
gories. Comparing these clusters with the original
WordNet-based groupings, Almuhareb and Poesio
report a cluster accuracy of 71.96% using just val-
ues like hot (all 51,045), an accuracy of 64.02% us-
ing just attributes like temperature (all 8934), and
949
Table 1: Experiment 1, accuracy for 214 nouns
Approach Values Attr?s All
only only (V + A)
Almu. + Poesio 71.96% 64.02% 85.51%
(51045 (8934 (59979
vals) attr) v+a)
Talking Points 70.2% 78.7% 90.2%
(2209 (4974 (7183
vals) attr) v+a)
an accuracy of 85.5% using both together (59979
features).
In a second, larger experiment, Almuhareb and
Poesio select 402 nouns from 21 different seman-
tic classes in WordNet, and proceed to harvest
94,989 property values (again mostly adjectives)
and 24,178 attribute nouns from the web using
the same retrieval patterns. They then applied
the repeated bisections clustering algorithm to this
larger data set, and report an initial cluster purity
measure of 56.7% using only property values like
hot, 65.7% using only attributes like temperature,
and 67.7% using both together. Suspecting that
noisy features contribute to the perceived drop in
performance, those authors then applied a variety
of noise filters to reduce the value set to just 51,345
values and the attribute set to just 12,345 attributes,
for a size reduction of about 50% in each case.
This in turn leads to an improved cluster purity
measure of 62.7% using property values only and
70.9% using attributes only. Surprisingly, filtering
actually appears to reduce the clustering perfor-
mance of both data-sets used together, to 66.4%.
We replicate here both of these experiments us-
ing the same data-sets of 214 and 402 nouns re-
spectively. For fairness, we collect raw descrip-
tions for each of these nouns directly from the web,
and use no filtering (manual or otherwise) to re-
move poor or ill-formed descriptions. We thus use
the pattern ?as * as a|an|the C? to collect 2209 raw
adjectival values for the 214 nouns of experiment
1, and 5547 raw adjectival values for the 402 nouns
of experiment 2. We then use the pattern ?the ADJ
* of a|an|the C? to collect 4974 attributes for the
214 nouns of experiment 1, and 3952 for the 402
nouns of experiment 2; in each case, ADJ is bound
to the raw adjectival values that were acquired us-
ing ?as * as a|an|the C?. A comparison of cluster-
ing results is given in Tables 1 and 2. These tables
illustrate that clustering is most effective when it
Table 2: Experiment 2, accuracy for 402 nouns
Approach Values Attr?s All
only only (V + A)
Almu. + Poesio 56.7% 65.7% 67.7%
(no filtering) (94989 (24178 (119167
vals) attr) v+a)
Almu. + Poesio 62.7% 70.9% 66.4%
(with filtering) (51345 (12345 (63690
vals) attr) v+a)
Talking Points 64.3% 54.7% 69.85%
(5547 (3952 (9499
vals) attr) v+a)
is performed on the basis of both values and at-
tributes (yielding the highest scores, 90.2% and
69.85%, in each experiment respectively). These
results thus support the combination of conceptual
attributes with specific adjectival values into inte-
grated talking points which reflect how people ac-
tually talk about the concepts concerned.
6 Conclusions
Metaphor is a knowledge-hungry phenomenon, so
any computational treatment of metaphor will only
be as good as the knowledge representation that
supports it. Moreover, from a computational per-
spective, any theory of metaphor ? cognitive, lin-
guistic, or otherwise ? is only as good as the al-
gorithmic and representational insights that it pro-
vides, and the scale of the implementation that it
ultimately allows us to realize. In this paper we
have given computational form to some of the key
insights in the metaphor literature, from the in-
teraction theory of Black (1962) to the salience
imbalance theory of Ortony (1979) to the theory
of conceptual blending of Fauconnier and Turner
(1998). We also employ a key insight from the
work of Hofstadter and his fluid analogies group
(1995), that robust reasoning on a conceptual level
requires a degree of slippage that must be sup-
ported by the underlying knowledge representa-
tion.
Our knowledge base of talking points is derived
from two complementary information sources: the
objective definitions contained in WordNet (Fell-
baum, 1998) and the stereotypical comparisons
that pepper the texts of the web. These sources
yield a knowledge-base that is neither small nor
hand-crafted. While the knowledge-base needs
to grow by at least an order of magnitude, slip-
950
page means that non-identical talking points can
be treated as equivalent for purposes of robust
processing, which in turn extends the halo of
talking points that surrounds each concept in the
knowledge-base (Hofstadter et al, 1995). The
experiments of section 5 also indicate that, in a
pinch, new talking points for a previously under-
represented concept can be acquired dynamically
from the web with reasonable accuracy. As it
currently stands, the talking points approach to
metaphor is robust enough and scalable enough to
generate simple but imaginative metaphors on de-
mand for a wide range of user inputs.
But what does it mean to state, at a knowledge-
representation level, that lions and knights both
have a brave heart, that wolves and tyrants both
have a cruel face, or that eagles and warriors
have a fierce expression? Stereotypical talking
points such as these can be poetic or metaphor-
ical, and may express a viewpoint that is overly
simplistic, subjective or even technically inaccu-
rate. Nonetheless, our experiments suggest that
the linguistic insights we acquire from non-literal
descriptions strongly reflect our ontological intu-
itions about concepts and are more than mere lin-
guistic decorations. Most significantly, we see
from these experiments that stereotypical talking
points yield an especially concise representation,
since with no filtering of any kind, this approach
achieves comparable clustering results with feature
sets that are many times smaller than those used in
previous work. We anticipate therefore that stereo-
typical descriptions will be a key growth area for
the development of the talking points knowledge-
base.
The Pope examples of section 4.1. exem-
plify the competence of the system as it is cur-
rently implemented, while the Burqa and Gover-
nor/President examples of sections 1 and 2 mark
out our future directions. The Burqa examples
demonstrate the need for a more complex repre-
sentation of talking points that can accommodate
nested propositions, while the Governor example
demonstrates the need for more radical and ad-hoc
slippage patterns in creative metaphors. Rather
than add special rules to handle such individual
cases (which are creative because of their one-
off disposal nature), our ambition is to develop a
general corpus-grounded mechanism for explain-
ing all metaphor-related slippage. We remain a
considerable distance from this goal, yet believe
it is best attained using the kind of robust and scal-
able approach described here.
References
Almuhareb, A. and M. Poesio. 2004. Attribute-
Based and Value-Based Clustering: An Evaluation
In proceedings of EMNLP, the Conference on Em-
pirical Methods on Natural Language Processing.
Barcelona.
Almuhareb, A. and M. Poesio. 2005. Concept Learn-
ing and Categorization from the Web. In proceed-
ings of the annual meeting of the Cognitive Science
society. Italy.
Ahlswede, T. and M. Evans. 1998. Parsing vs. Text
Processing in the analysis of dictionary definitions.
In proceedings of the 26th Annual Meeting of the As-
sociation for Computational Linguistics, 217?224.
Barnden, J. A. and M. G. Lee. 2002. An Artificial
Intelligence Approach to Metaphor Understanding.
Theoria et Historia Scientiarum, 6(1):399?412.
Black, M. 1962. Models and Metaphor: studies in
language and philosophy. Ithaca, NY: Cornell Uni-
versity Press.
Camac, K. and S. Glucksberg. 1984. Metaphors
do not use associations between concepts, they are
used to create them. Journal of Psycholinguistic Re-
search,13(6).
Collins, A. and E. F. Loftus. 1975. A Spreading-
Activation Theory of Semantic Processing. Psycho-
logical Review 82, 407?428.
Fauconnier, G. and M. Turner. 1998. Conceptual In-
tegration Networks. Cognitive Science, 22(2):133?
187.
Fellbaum, C. (ed.). 1998. WordNet: An electronic lex-
ical database. The MIT Press. 1985 A comprehen-
sive grammar of the English.
Hofstadter, D. R. and M. Mitchell. 1994. The Copy-
cat Project: A model of mental fluidity and analogy-
making. In Holyoak, K.J. & Barnden, J. A. (Eds.)
Advances in Connectionist and Neural Computation
Theory, Vol. 2. Norwood, NJ: Ablex.
Hofstadter, D. R. and the Fluid Analogy Research
Group. 1995. Fluid Concepts and Creative Analo-
gies: Computer Models of the Fundamental Mecha-
nisms of Thought. NY: Basic Books.
Fass, D. 1991. Met*: a method for discriminating
metonymy and metaphor by computer. Computa-
tional Linguistics, 17(1):49?90.
Indurkhya, B. 1992. Metaphor and Cognition: Studies
in Cognitive Systems. Kluwer Academic Publishers,
Dordrecht: The Netherlands.
951
Martin, J. H. 1990. A Computational Model of
Metaphor Interpretation. NY: Academic Press.
Ortony, A. 1979. Beyond literal similarity. Psycholog-
ical Review, 86, 161?180.
Veale, T. and Y. Hao. 2007. Making WordNet Func-
tional and Context-Sensitive. In proceedings of the
45th Annual Meeting of the Association for Compu-
tational Linguistics. Czech Republic.
Veale, T. and O?Donoghue. 2000. Computation and
Blending. Cognitive Linguistics, 11(3?4), special is-
sue on Conceptual Blending.
Way, E. C. 1991. Knowledge Representation and
Metaphor. Studies in Cognitive systems. Holland:
Kluwer.
Wilks, Y. 1978. Making Preferences More Active,
Studies in Cognitive systems. Artificial Intelligence
11(3), 197?223.
952
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 835?842,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Growing Finely-Discriminating Taxonomies from Seeds
of Varying Quality and Size 
Tony Veale
School of Computer Science
University College Dublin
Ireland
tony.veale@ucd.ie
Guofu Li
School of Computer Science
University College Dublin
Ireland
guofu.li@ucd.ie
Yanfen Hao
School of Computer Science
University College Dublin
Ireland
yanfen.hao@ucd.ie
Abstract
Concept taxonomies offer a powerful means 
for organizing knowledge, but this organiza-
tion  must  allow  for  many  overlapping  and 
fine-grained perspectives if a general-purpose 
taxonomy is  to  reflect  concepts  as  they are 
actually employed and reasoned about in ev-
eryday  usage.  We present  here  a  means  of 
bootstrapping  finely-discriminating  tax-
onomies from a variety of different  starting 
points, or seeds, that are acquired from three 
different sources: WordNet, ConceptNet and 
the web at large.  
1 Introduction
Taxonomies  provide  a  natural  and  intuitive 
means of organizing information, from the bio-
logical taxonomies of the Linnaean system to the 
layout of supermarkets and bookstores to the or-
ganizational structure of companies. Taxonomies 
also provide the structural backbone for ontolo-
gies  in  computer  science,  from common-sense 
ontologies like Cyc (Lenat and Guha, 1990) and 
SUMO (Niles and Pease, 2001) to lexical ontolo-
gies like WordNet (Miller  et al, 1990). Each of 
these uses is based on the same root-branch-leaf 
metaphor:  the  broadest  terms  with  the  widest 
scope occupy the highest positions of a taxono-
my, near the root, while specific terms with the 
most local concerns are located lower in the hier-
archy,  nearest  the  leaves.  The  more  interior 
nodes that  a taxonomy possesses,  the finer  the 
conceptual distinctions and the more gradated the 
similarity judgments it can make (e.g., Budanit-
sky and Hirst, 2006).
General-purpose  computational  taxonomies 
are called upon to perform both coarse-grained 
and  fine-grained  judgments.  In  NLP,  for  in-
stance,  the  semantics  of  ?eat?  requires  just 
enough  knowledge  to  discriminate  foods  like 
tofu and cheese from non-foods like  wool  and 
steel, while specific applications in the domain of 
cooking  and  recipes  (e.g.,  Hammond?s  (1986) 
CHEF)  require  enough  discrimination  to  know 
that tofu can be replaced with clotted cheese in 
many recipes because each is a soft, white and 
bland food.  
So while much depends on the domain of us-
age, it remains an open question as to how many 
nodes a good taxonomy should possess. Prince-
ton WordNet,  for  instance,  strives for  as many 
nodes as there are word senses in English, yet it 
also contains a substantial number of composite 
nodes  that  are  lexicalized not  as  single  words, 
but as complex phrases. Print dictionaries intend-
ed for human consumption aim for some econo-
my of structure, and typically do not include the 
meaning  of  phrases  that  can  be  understood  as 
straightforward compositions of the meaning of 
their  parts  (Hanks,  2004).  But  WordNet  also 
serves another purpose, as a lexical knowledge-
base  for  computers,  not  humans,  a  context  in 
which concerns about space seem quaint. When 
space is not a issue, there seems no good reason 
to exclude nodes from a concept taxonomy mere-
ly for being composites of other ideas; the real 
test of entry is whether a given node adds value 
to a taxonomy, by increasing its level of internal 
organization through the systematic dissection of 
overly broad categories into finer, more intuitive 
and manageable clusters.
In this paper we describe a means by which 
finely-discriminating  taxonomies  can  be  grown 
from  a  variety  of  different  knowledge  seeds. 
These taxonomies comprise composite categories 
that  can  be  lexicalized  as  phrases  of  the  form 
?ADJ NOUN?, such as Sharp-Instrument, which 
represents the set of all instruments that are typi-
cally considered sharp, such as knives, scissors, 
chisels and can-openers. While WordNet aleady 
contains  an  equivalent  category,  named  Edge-
835
Tool, which it defines with the gloss ?any cutting 
tool  with a sharp cutting edge?,  it  provides  no 
structural basis for inferring that any member of 
this  category can be considered  sharp.  For  the 
most part, if two ideas (word senses) belong to 
the same semantic category X in WordNet, the 
most we can infer is that both possess the trivial 
property  X-ness.  Our  goal  here  is  to  construct 
taxonomies whose form makes explicit the actual 
properties that accrue from membership in a cat-
egory. 
Past work on related approaches to taxonomy 
creation are discussed in section 2, while section 
3  describes  the  different  knowledge  seeds  that 
serve as the starting point for our bootstrapping 
process. In section 4 we describe the bootstrap-
ping process in more detail;  such processes are 
prone to noise, so we also discuss how the ac-
quired categorizations are validated and filtered 
after each bootstrapping cycle. An evaluation of 
the key ideas is then presented in section 5, to 
determine which seed yields the highest quality 
taxonomy once bootstrapping is completed. The 
paper then concludes with some final remarks in 
section 6.
2 Related Work
Simple pattern-matching techniques can be sur-
prisingly effective for the extraction of lexico-se-
mantic relations from text when those relations 
are expressed using relatively stable and unam-
biguous  syntagmatic  patterns  (Ahlswede  and 
Evens, 1988). For instance, the work of Hearst 
(1992) typifies this surgical approach to relation 
extraction,  in  which a system fishes in  a large 
text for particular word sequences that strongly 
suggest  a  semantic  relationship  such  as  hyper-
nymy  or,  in  the  case  of  Charniak and Berland 
(1999), the part-whole relation. Such efforts offer 
high precision but can exhibit low recall on mod-
erate-sized corpora, and extract just a tiny (but 
very useful) subset of the semantic content of a 
text.  The  KnowItAll system  of  Etzioni  et  al. 
(2004)  employs  the  same  generic  patterns  as 
Hearst (e.g., ?NPs such as NP1, NP2, ??),  and 
more besides, to extract a whole range of facts 
that can be exploited for web-based question-an-
swering.  Cimiano  and  Wenderoth  (2007)  also 
use a range of Hearst-like patterns to find text se-
quences in web-text that are indicative of the lex-
ico-semantic  properties  of  words;  in  particular, 
these  authors  use  phrases  like  ?to  *  a  new 
NOUN? and ?the purpose of NOUN is to *? to 
identify the formal (isa), agentive (made by) and 
telic (used for) roles of nouns.
Snow, Jurafsky and Ng (2004) use supervised 
learning techniques to acquire those syntagmatic 
patterns that prove most useful for extracting hy-
pernym relations from text. They train their sys-
tem using pairs of WordNet terms that exemplify 
the hypernym relation; these are used to identify 
specific sentences in corpora that are most likely 
to express the relation in lexical terms. A binary 
classifier is then trained on lexico-syntactic fea-
tures that are extracted from a dependency-struc-
ture  parse  of  these  sentences.  Kashyap  et  al., 
(2005) experiment with a bootstrapping approach 
to  growing concept  taxonomies  in  the  medical 
domain.  A  gold  standard  taxonomy  provides 
terms that are used to retrieve documents which 
are  then  hierarchically  clustered;  cohesiveness 
measures are used to yield a taxonomy of terms 
that can then further drive the retrieval and clus-
tering cycle. Kozareva  et al (2008) use a boot-
strapping approach that extends the fixed-pattern 
approach  of  Hearst  (1992)  in  two  intriguing 
ways. First, they use a doubly-anchored retrieval 
pattern of the form ?NOUNcat such as NOUNexam-
ple and  *?  to  ground the  retrieval  relative  to  a 
known example of hypernymy,  so that any val-
ues extracted for the wildcard * are likely to be 
coordinate terms of  NOUNexample and even more 
likely to be good examples of NOUNcat. Second-
ly, they construct a graph of terms that co-occur 
within this pattern to determine which terms are 
supported by others,  and by how much.  These 
authors also use two kinds of bootstrapping: the 
first  variation,  dubbed  reckless,  uses the candi-
dates extracted from the double-anchored pattern 
(via *) as exemplars (NOUNexample) for successive 
retrieval cycles; the second variation first checks 
whether a candidate is sufficiently supported to 
be used as an exemplar in future retrieval cycles.
The approach we describe here is most similar 
to that of Kozareva  et al (2008). We too use a 
double-anchored pattern, but place the anchors in 
different  places  to  obtain  the  query  patterns 
?ADJcat NOUNcat such as *? and ?ADJcat * such 
as NOUNexample?. As a result, we obtain a finely-
discriminating  taxonomy  based  on  categories 
that are explicitly annotated with the properties 
(ADJcat)  that  they  bequeath  to  their  members. 
These categories have an obvious descriptive and 
organizational  utility,  but  of  a kind that  one is 
unlikely  to  find  in  conventional  resources  like 
WordNet and Wikipedia. Kozareva et al (2008) 
test their approach on relatively simple and ob-
jective  categories  like  states,  countries (both 
836
closed sets), singers and fish (both open, the for-
mer more so than the latter), but not on complex 
categories in which members are tied both to a 
general category, like food, and to a stereotypical 
property, like  sweet (Veale and Hao, 2007). By 
validating  membership  in  these  complex  cate-
gories  using WordNet-based heuristics,  we  can 
hang these categories and members  on specific 
WordNet senses, and thus enrich WordNet with 
this additional taxonomic structure.
3 Seeds for Taxonomic Growth 
A fine-grained taxonomy can be viewed as a set 
of triples Tijk = <Ci, Dj, Pk>, where Ci denotes a child of the parent term Pk that possesses the dis-
criminating  property  Dj;  in  effect,  each  such 
triple expresses that Ci is a specialization of the 
complex  taxonym  Dj-Pk.  Thus,  the  belief  that 
cola  is  a  carbonated-drink  is  expressed  by the 
triple <cola, carbonated, drink>. From this triple 
we  can  identify  other  categorizations  of  cola 
(such as treat and refreshment) via the web query 
?carbonated * such as cola?, or we can identify 
other similarly fizzy drinks via the query ?car-
bonated  drinks  such  as  *?.  So  this  web-based 
bootstrapping  of  fine-grained  category  hierar-
chies requires that we already possess a collec-
tion  of  fine-grained  distinctions  of  a  relatively 
high-quality.  We  now  consider  three  different 
starting points for this bootstrapping process, as 
extracted from three different resources:  Word-
Net, ConceptNet and the web at large.
3.1 WordNet 
The noun-sense taxonomy of WordNet makes a 
number  of  fine-grained  distinctions  that  prove 
useful in clustering entities into smaller and more 
natural groupings. For instance, WordNet differ-
entiates  {feline,  felid} into  the  sub-categories 
{true_cat,  cat} and  {big_cat,  cat},  the  former 
serving  to  group  domesticated  cats  with  other 
cats of a similar size, the latter serving to cluster 
cats  that  are  larger,  wilder  and  more  exotic. 
However, such fine-grained distinctions are the 
exception rather than the norm in WordNet, and 
not  one of  the  60+ words  of  the  form  Xess in 
WordNet that denote a person (such as huntress,  
waitress, Jewess, etc.) express the defining prop-
erty  female in  explicit  taxonomic  terms. 
Nonetheless, the free-text glosses associated with 
WordNet sense-entries often do state the kind of 
distinctions we would wish to find expressed as 
explicit  taxonyms.  A  shallow  parse  of  these 
glosses  thus  yields  a  sizable  number  of  fine-
grained  distinctions,  such  as  <lioness,  female,  
lion>,   <espresso,  strong,  coffee>  and  both 
<messiah, awaited, king> and <messiah, expect-
ed, deliverer>. 
3.2 ConceptNet 
Despite  its  taxonomic  organization,  WordNet 
owes much to the centralized and authority-pre-
serving  craft  of  traditional  lexicography.  Con-
ceptNet (Liu and Singh, 2004), in contrast, is a 
far less authoritative knowledge-source, one that 
owes more to the workings of the WWW than to 
conventional print dictionaries. Comprising fac-
toids culled from the template-structured contri-
butions of thousands of web users,  ConceptNet 
expresses many relationships that accurately re-
flect  a  public,  common-sense  view on a  given 
topic (from vampires to dentists) and many more 
that are simply bizarre or ill-formed. Looking to 
the relation that interests us here, the IsA rela-
tion,  ConceptNet  tells  us  that  an  espresso is  a 
strong coffee (correctly, like WordNet) but that a 
bagel is a Jewish word (confusing use with men-
tion). Likewise, we find that expressionism is an 
artistic style (correct, though WordNet deems it 
an  artistic movement) but that an  explosion is a 
suicide attack (confusing formal and telic roles). 
Since we cannot trust the content of ConceptNet 
directly, lest we bootstrap from a highly unreli-
able starting point, we use WordNet as a simple 
filter.  While  the  concise  form  of  ConceptNet 
contains over 30,000 IsA propositions, we con-
sider as our seed collection only those that define 
a noun concept (such as ?espresso?) in terms of a 
binary  compound  (e.g.,  ?strong coffee?)  where 
the head of the latter (e.g.,  ?coffee?) denotes a 
WordNet hypernym of some sense of the former. 
This  yields  triples  such  as  <Wyoming,  great,  
state>,  <wreck,  serious,  accident>  and  <wolf,  
wild, animal>.
3.3 Web-derived Stereotypes 
Veale and Hao (2007) also use the observations 
of web-users to acquire common perceptions of 
oft-mentioned ideas, but do so by harvesting sim-
ile expressions of the form ?as ADJ as a NOUN? 
directly from the web.  Their approach hinges on 
the fact that similes exploit stereotypes to draw 
out the salient properties of a target, thereby al-
lowing rich  descriptions of those stereotypes to 
be easily acquired, e.g., that snowflakes are pure 
and unique, acrobats are agile and nimble, knifes 
are  sharp and dangerous,  viruses  are  malicious 
and infectious, and so on. However, because they 
find that almost 15% of their web-harvested sim-
837
iles are ironic (e.g., ?as subtle as a rock?, ?as bul-
letproof as a sponge-cake?, etc.), they filter irony 
from these associations by hand, to yield a siz-
able  database  of  stereotypical  attributions  that 
describes over 6000 noun concepts in terms of 
over  2000  adjectival  properties.  However,  be-
cause Veale and Hao?s data directly maps stereo-
typical properties to simile vehicles, it does not 
provide  a  parent  category  for  these  vehicles. 
Thus, the seed triples derived from this data are 
only partially instantiated;  for  instance,  we ob-
tain <surgeon, skilful, ?>, <virus, malicious, ?> 
and <dog, loyal, ?>.  This does not prove to be a 
serious  impediment,  however,  as  the  missing 
field  of  each triple  is  quickly identified during 
the first cycle of bootstrapping.
3.4 Overview of Seed Resources 
Neither of these three seeds is an entirely useful 
knowledge-base in its own right. The WordNet-
based seed is clearly a representation of conve-
nience,  since  it  contains  only  those  properties 
that can be acquired from the glosses that happen 
to be amenable  to a simple  shallow-parse.  The 
ConceptNet seed is likewise a small collection of 
low-hanging fruit, made smaller still by the use 
of WordNet as a coarse but very necessary noise-
filter.  And while the simile-derived distinctions 
obtained from Veale and Hao paint a richly de-
tailed  picture  of  the  most  frequent  objects  of 
comparison, this seed offers no coverage for the 
majority of concepts that are insufficiently note-
worthy to be found in web similes. A quantita-
tive comparison of all three seeds is provided in 
Table 1 below.
WordNet ConceptNet Simile
# terms 
in total 12,227 1,133 6512
# triples 
in total 51,314 1808 16,688
# triples 
per term 4.12 1.6 2.56
# fea-
tures 2305 550 1172
Table 1:  The size of seed collections yielded from 
different sources. 
We can see that WordNet-derived seed is clearly 
the largest and apparently the most comprehen-
sive knowledge-source of the  three:  it  contains 
the most terms (concepts), the most features (dis-
criminating properties of those concepts), and the 
most triples (which situate those concepts in par-
ent  categories  that  are  further  specialized  by 
these  discriminating  features).  But  size  is  only 
weakly suggestive of quality, and as we shall see 
in  the  next  section,  even such  dramatic  differ-
ences in scale can disappear after several cycles 
of bootstrapping. In section 5 we will then con-
sider  which  of  these  seeds  yields  the  highest 
quality taxonomies after bootstrapping has been 
applied. 
4 Bootstrapping from Seeds
The seeds of the previous section each represent 
a different starting collection of triples. It is the 
goal of the bootstrapping process to grow these 
collections  of  triples,  to  capture  more  of  the 
terms ? and more of the distinctions ? that a tax-
onomy is expected to know about. The expansion 
set  of  a  triple  Tijk =  <Ci,  Dj,  Pk> is  the  set  of 
triples that can be acquired from the web using 
the  following  query  expansions  (*  is  a  search 
wildcard):
1. ?Dj * such as Ci?
2. ?Dj Pk such as *?
In the first query, a noun is sought to yield anoth-
er categorization of Ci, while in the second, other 
members of the fine-grained category Dj-Pk are 
sought to accompany Ci. In parsing the text snip-
pets  returned by these  queries,  we also exploit 
text sequences that match the following patterns:
3. ?* and Dj Pk such as *?
4. ?* and Dj * such as Ci?
These last two patterns allow us to learn new dis-
criminating  features  by  noting  how  these  dis-
criminators are combined to reinforce each other 
in  some  ad-hoc  category  formulations.  For  in-
stance, the phrase ?cold and refreshing beverages 
such  as  lemonade?  allows  us  to  acquire  the 
triples <lemonade, cold, beverage> and <lemon-
ade, refreshing, beverage>. This pattern is neces-
sary if the bootstrapping process is to expand be-
yond  the  limited  vocabulary  of  discriminating 
features  (Dj)  found in  the  original  seed collec-
tions of triples.
We denote the mapping from a triple T to the 
set of additional triples that can be acquired from 
the web using the above queries/patterns as  ex-
pand(T').  We currently implement this function 
using  the  Google  search  API.  Our  experiences 
with each query suggest  that  200 snippets is  a 
good search range for the first query, while 50 is 
usually more than adequate for the second. 
838
We can now denote the knowledge that is ac-
quired when starting from a given seed collection 
S after t cycles of bootstrapping as KtS. Thus, 
K 0S=S
K 1S=K 0S ?
{T ? T '?S ? T?expand ?T ' ?}
K t?1S =K tS ?
{T ? T '?K tS ? T?expand ?T ' ?}
Web queries, and the small snippets of text that 
they return, offer just a keyhole view of language 
as it is used in real documents.  Unsurprisingly, 
the  new triples  acquired from the  web via  ex-
pand(T') are likely to be very noisy indeed. Fol-
lowing Kozareva et al (2008), we can either in-
dulge  in  reckless  bootstrapping,  which  ignores 
the  question  of  noise  until  all  bootstrapping  is 
finished, or we can apply a noise filter after each 
incremental step.  The latter approach has the ad-
ditional advantage of keeping the search-space as 
small as possible, which is a major consideration 
when bootstrapping from sizable seeds. We use a 
simple WordNet-based filter called near-miss:  a 
new triple <Ci,  Dj,  Pk> is accepted if WordNet 
contains  a  sense  of  Ci that  is  a  descendant  of 
some sense of Pk (a hit), or a sense of Ci that is a 
descendant of the direct hypernym of some sense 
of Pk (a near-miss). This allows the bootstrapping 
process to acquire structures that are not simply a 
decorated version of the basic WordNet taxono-
my,  but  to acquire hierarchical  relations whose 
undifferentiated forms are not in WordNet (yet 
are largely compatible with WordNet). This non-
reckless bootstrapping process can be expressed 
as follows:
K t?1S =K tS ? {T ? T '?K tS ?
T? filter near?miss?expand ?T ' ??}
Figure 1 and figure 2 below illustrate the rate of 
growth  of  triple-sets  from  each  of  our  three 
seeds.
Referring again to table 1, we note that while 
the ConceptNet collection is by far the smallest 
of  the three seeds ? more  that  7 times smaller 
than the simile-derived seed, and almost 40 times 
smaller than the WordNet seed ? this difference 
is  size  shrinks  considerably over  the  course  of 
five  bootstrapping  cycles.  The  WordNet  near-
miss filter ensures that the large body of triples 
grown from each  seed  are  broadly  sound,  and 
that  we  are  not  simply  generating  comparable 
quantities of nonsense in each case.
Figure 1: Growth in the number of acquired triples, 
over 5 cycles of bootstrapping from different seeds.
Figure 2: Growth in the number of terms described by 
the acquired triples, over 5 cycles of bootstrapping 
from different seeds.
4.1 An  Example
Consider cola, for which the simile seed has one 
triple: <cola, refreshing, beverage>. After a sin-
gle cycle of bootstrapping, we find that cola can 
now be described as an effervescent beverage, a 
sweet  beverage,  a  nonalcoholic  beverage and 
more. After a second cycle, we find it described 
as a sugary food, a fizzy drink and a dark mixer. 
After a third cycle, it is found to be a  sensitive 
beverage, an  everyday beverage and a  common 
drink. After a fourth cycle, it is also found to be 
an  irritating food and an  unhealthy drink. After 
the  fifth  cycle,  it  is  found to  be  a  stimulating 
drink, a toxic food and a corrosive substance. In 
all, the single cola triple in the simile seed yields 
14 triples after 1 cycle, 43 triples after 2 cycles, 
72 after 3 cycles, 93 after 4 cycles, and 102 after 
5 cycles. During these bootstrapping cycles, the 
description  refreshing beverage additionally be-
comes  associated  with  the  terms  champagne, 
lemonade and beer. 
0 1 2 3 4 5
0
200000
400000
600000
800000
1000000
1200000
1400000
1600000
1800000 WordNet
Simile
ConceptNet
Bootstrapping Cycle
# 
Tri
ple
s
0 1 2 3 4 5
0
50000
100000
150000
200000
250000
300000
350000
WordNet
Simile
ConceptNet
Bootstrapping Cycle
# 
Te
rm
s
839
5 Empirical Evaluation
The WordNet  near-miss filter thus ensures that 
the parent field (Pk) of every triple contains a val-
ue  that  is  sensible  for  the  given  child  concept 
(Ci), but does not ensure that the discriminating 
property  (Dj)  in  each  triple  is  equally  sensible 
and apropos.  To see  whether the bootstrapping 
process  is  simply  padding  the  seed  taxonomy 
with large quantities of noise,  or whether the ac-
quired Dj values do indeed mark out the implicit 
essence of the Ci terms they describe, we need an 
evaluation framework that can quantify the onto-
logical usefulness of these Dj values. For this, we 
use  the  experimental  setup  of  Almuhareb  and 
Poesio  (2005),  who  use  information  extraction 
from the web to acquire attribute values for dif-
ferent terms/concepts, and who then compare the 
taxonomy that can be induced by clustering these 
values  with the  taxonomic  backbone  of  Word-
Net. 
Almuhareb and Poesio first created a balanced 
set  of  402  nouns  from  21  different  semantic 
classes in WordNet. They then acquired attested 
attribute values for these nouns (such as  hot for 
coffee,  red for car, etc.) using the query "(a|an|
the) * Ci  (is|was)" to find corresponding Dj val-
ues for each Ci. Unlike our work, these authors 
did  not seek to acquire hypernyms  for each Ci 
during this search, and did not try to link the ac-
quired attribute values to a particular branching 
point  (Pk) in the taxonomy (they did,  however, 
seek matching attributes for these values, such as 
Temperature for  hot, but that aspect is not rele-
vant here). They acquired 94,989 attribute values 
in all for the 402 test nouns. These values were 
then used as features of the corresponding nouns 
in  a  clustering  experiment,  using  the  CLUTO 
system of Karypis (2002). By using attribute val-
ues  as  a  basis  for  partitioning  the  set  of  402 
nouns  into  21  different  categories,  Almuhareb 
and Poesio attempted to reconstruct the original 
21  WordNet  categories  from which  the  nouns 
were drawn. The more accurate the match to the 
original WordNet clustering, the more these at-
tribute values can be seen (and used) as a repre-
sentation of conceptual structure. In their first at-
tempt, they achieved just a 56.7% clustering ac-
curacy against the original human-assigned cate-
gories of WordNet. But after using a noise-filter 
to remove almost  half of the web-harvested at-
tribute values, they achieve a higher cluster accu-
racy of 62.7%. More specifically, Poesio and Al-
muhareb achieve a cluster purity of 0.627 and a 
cluster entropy of 0.338 using 51,345 features to 
describe and cluster the 402 nouns.1
We?replicate?the?above?experiments?using?the?
same?402?nouns,?and?assess?the?clustering?accur?
acy ? (again ?using ?WordNet ? as ? a ? gold?standard)?
after?each?bootstrapping?cycle.?Recall?that?we?use?
only?the?Dj?fields?of?each?triple?as?features?for?the?
clustering ?process, ? so ? the ?comparison ?with ? the?
WordNet?gold?standard?is?still?a?fair?one.?Once?
again,?the?goal?is?to?determine?how?much?like?the?
human?crafted ? WordNet ? taxonomy ? is ? the ? tax?
onomy? that ? is ?clustered?automatically ?from?the?
discriminating?words?Dj?only.?The?clustering?ac?
curacy?for?all?three?seeds?are?shown?in?Tables?2,?
3?and?4.
Cycle  E  P # Features Coverage
1st .327 .629 907 66%
2nd .253 .712 1,482 77%
3rd .272 .717 2,114 82%
4th .312 .640 2,473 83%
5th .289 .684 2,752 83%
Table 2: Clustering accuracy using the WordNet seed 
collection (E denotes Entropy and P stands for Purity)
Cycle E P # Features Coverage
1st .115 .842 363 41%
2nd .255 .724 787 59%
3rd .286 .694 1,362 74%
4th .279 .694 1,853 79%
5th .299 .673 2,274 82%
Table 3: Clustering accuracy using the ConceptNet 
seed collection
Cycle E P # Features Coverage
1st .254 .716 837 59%
2nd .280 .712 1,338 73%
3rd .289 .693 1,944 79%
4th .313 .660 2,312 82%
5th .157 .843 2,614 82%
Table 4: Clustering accuracy using the Simile seed 
collection
The test-set of 402 nouns contains some low-fre-
quency words, such as casuarina,  cinchona,  do-
decahedron, and  concavity, and Almuhareb and 
1 We use cluster purity as a reflection of clustering accu-
racy. We express accuracy as a percentage; hence a pu-
rity of 0.627 is seen as an accuracy of 62.7%. 
840
Poesio note that one third of their data-set has a 
low-frequency of between 5-100 occurrences in 
the British National Corpus. Looking to the cov-
erage  column  of  each  table,  we  thus  see  that 
there  are  words  in  the  Poesio  and  Almuhareb 
data set for which no triples can be acquired in 5 
cycles  of  bootstrapping.  Interestingly,  though 
each seed is quite different in origin and size (see 
again Table 1), all reach similar levels of cover-
age (~82%) after  5 bootstrapping cycles.   Test 
nouns for which all three seeds fail to reach a de-
scription  include  yesteryear,  nonce (very rare), 
salient (more typically an adjective), jag, droop,  
fluting,  fete,  throb,  poundage,  stinging,  rouble,  
rupee,  riel,  drachma,  escudo,  dinar,  dirham,  
lira, dispensation,  hoard,  airstream (not typical-
ly a solid compound), riverside and curling. Fig-
ures 3 and 4 summarize the key findings in the 
above tables: while bootstrapping from all three 
seeds converges to the same level of coverage, 
the simile seed clearly produces the highest qual-
ity taxonomy. 
Figure 3: Growth in the coverage from different 
seed sources. 
Figure 4: Divergence in the clustering Purity 
achieved using different seed sources. The results of 
Poesio and Almuhareb are shown as the straight line: 
y = 0.627.
Both  the  WordNet  and  ConceptNet  seeds 
achieve comparable accuracies of 68% and 67% 
respectively  after  5  cycles  of  bootstrapping, 
which compares well with the accuracy of 62.7% 
achieved  by  Poesio  and  Almuhareb.  However, 
the simile seed clearly yields the best accuracy of 
84.3%,  which  also  exceeds  the  accuracy  of 
66.4% achieved by Poesio and Almuhareb when 
using both values  and attributes (such as  Tem-
perature, Color, etc.) for clustering, or the accu-
racy of 70.9% they achieve when using attributes 
alone. Furthermore, bootstrapping from the simi-
le seed yields higher cluster accuracy on the 402-
noun data-set than Veale and Hao (2008) them-
selves achieve with their simile data on the same 
test-set (69.85%). 
But most striking of all is the concision of the 
representations that are acquired using bootstrap-
ping. The simile seed yields a high cluster accu-
racy using a pool of just 2,614 fine discrimina-
tors,  while  Poesio  and  Almuhareb  use  51,345 
features even after their feature-set has been fil-
tered  for  noise.  Though starting  from different 
initial scales, each seed converges toward a fea-
ture-set that is roughly twenty times smaller than 
that used by Poesio and Almuhareb. 
6 Conclusions
These experiments reveal that seed knowledge of 
different authoritativeness, quality and size will 
tend to converge toward roughly the same num-
ber  of  finely  discriminating  properties  and  to-
ward much the same coverage after 5 or so cy-
cles of bootstrapping. Nonetheless, quality wins 
out,  and  the  simile-derived  seed  knowledge 
shows itself to be a clearly superior basis for rea-
soning  about  the  structure  and  organization  of 
conceptual  categories.  Bootstrapping  from  the 
simile  seed yields  a slightly smaller  set of  dis-
criminating features than bootstrapping from the 
WordNet  seed,  one that  is  many times  smaller 
than the Poesio and Almuhareb feature set. What 
matters is that they are the right features to dis-
criminate with. 
There appears to be a number of reasons for 
this  significant  difference  in  quality.  For  one, 
Veale and Hao (2007) show that similes express 
highly  stereotypical  beliefs  that  strongly  influ-
ence the affective disposition of a term/concept; 
negatively  perceived  concepts  are  commonly 
used to exemplify negative properties in similes, 
while  positively perceived  concepts  are  widely 
used to exemplify positive properties. Veale and 
Hao (2008) go on to argue that similes offer a 
very concise snapshot of those widely-held be-
liefs that are the cornerstone of everyday reason-
1 2 3 4 5
0.40
0.45
0.50
0.55
0.60
0.65
0.70
0.75
0.80
0.85
0.90
WordNet
Simile
ConceptNet
Bootstrapping Cycle
Co
ve
rag
e
1 2 3 4 5
0.40
0.50
0.60
0.70
0.80
0.90
1.00
WordNet
Simile
ConceptNet
Poesio & Alm.
Bootstrapping Cycle
Pu
rity
841
ing, and which should thus be the corner-stone of 
any general-purpose taxonomy.  In addition, be-
liefs expressed via the ?as Dj as Ci? form of simi-
les  appear  to  lend  themselves  to  re-expression 
via the ?Dj Pk such as  Ci? form; in each case, a 
concept Ci is held up as an exemplar of a salient 
property  Dj.  Since  the  ?such  as?  bootstrapping 
pattern seeks out  expressions of  prototypicality 
on the web, a simile-derived seed set is likely the 
best starting point for this search.
All three seeds appear to suffer the same cov-
erage limitations,  topping out  at  about  82% of 
the words in the Poesio and Almuhareb data-set. 
Indeed,  after  5  bootstrapping  cycles,  all  three 
seeds give rise to taxonomies that overlap on 328 
words from the 402-noun test-set, accounting for 
81.59% of the test-set. In effect then, bootstrap-
ping stumbles over the same core of hard words 
in each case, no matter the seed that is used. As 
such, the problem of coverage lies not in the seed 
collection, but in the queries used to perform the 
bootstrapping.  The  same  coverage  limitations 
will thus apply to other bootstrapping approaches 
to  knowledge acquisition,  such as  Kozareva  et  
al. (2008), which rely on much the same stock 
patterns.  So  while  bootstrapping may not  be  a 
general  solution  for  acquiring  all  aspects  of  a 
general-purpose taxonomy, it is clearly useful in 
acquiring large swathes  of  such a  taxonomy if 
given  a  sufficiently  high-quality  seed  to  start 
from.
References
Ahlswede, T. and Evans, M. (1988). Parsing vs. Text 
Processing in the analysis of dictionary definitions. 
In Proc. of the 26th Annual Meeting of the ACL, pp 
217-224.
Almuhareb,  A.  and  Poesio,  M.  (2005).  Concept 
Learning  and  Categorization  from  the  Web.  In 
Proc. of the annual meeting of the Cognitive  Sci-
ence Society, Italy, July. 
Budanitsky,  A.  and  Hirst,  G. (2006).   Evaluating 
WordNet-based Measures of Lexical Semantic Re-
latedness. Computational Linguistics, 32(1):13-47.
Cimiano, P. and Wenderoth, J. (2007). Automatic Ac-
quisition  of  Ranked  Qualia  Structures  from  the 
Web.  In Proc. of  the 45th Annual Meeting of  the  
ACL, pp 888-895.
Charniak, E. and Berland, M. (1999). Finding parts in 
very  large  corpora.  In  Proc.  of  the  37th Annual  
Meeting of the ACL, pp 57?64.
Etzioni,  O.,  Kok,  S.,  Soderland,  S.,  Cafarella,  M., 
Popescu, A-M., Weld, D., Downey, D., Shaked, T. 
and Yates,  A. (2004).  Web-scale information ex-
traction  in  KnowItAll  (preliminary  results).  In  
Proc. of the 13th WWW Conference, pp 100?109.
Hammond, K. J. (1986). CHEF : A Model of Case--
based Planning.  In Proc. of the 5th National Con-
ference  on  Artificial  Intelligence,  pp  267--271, 
Philadelphia, Pennsylvania.  American Association 
for Artificial Intelligence. 
Hanks, P. (2004). WordNet: What is to be done? In 
Proc. of GWC?2004, the 2nd Global WordNet con-
ference, Masaryk University, Brno.
Hearst,  M. (1992).  Automatic  acquisition  of  hy-
ponyms  from large  text  corpora.  In  Proc.  of  the 
14th Int.  Conf.  on  Computational  Linguistics,  pp 
539?545.
Kashyap,  V.  Ramakrishnan,  C.  and  Sheth,  T.  A. 
(2005). TaxaMiner: an experimentation framework 
for automated taxonomy bootstrapping.  Int. Jour-
nal of Web and Grid Services 1(2), pp 240-266.
Karypis,  G. (2002).  CLUTO:  A  clustering  toolkit. 
Technical Report 02-017, University of Minnesota. 
http://www-users.cs.umn.edu/~karypis/cluto/.
Kozareva, Z., Riloff, E. and Hovy, E. (2008). Seman-
tic  Class  Learning from the Web with Hyponym 
Pattern Linkage Graphs. In Proc. of the 46th Annu-
al Meeting of the ACL.
Lenat, D. B. and Guha, R. V. (1990). Building large 
knowledge-based  systems:  representation  and  in-
ference in the Cyc project. NY: Addison-Wesley.
Liu, H. and Singh, P. (2004), ConceptNet: A Practical 
Commonsense Reasoning Toolkit.  BT Technology 
Journal, 22(4):211-226.
Miller, G., Beckwith,R., Fellbaum, C., Gross, D. and 
Miller,  K.J.  (1990).  Introduction  to  WordNet:  an 
on-line lexical database. Int. Journal of Lexicogra-
phy, 3(4):235 ? 244.
Niles, I. and Pease, A. (2001). Toward a standard up-
per ontology. In Proc. of the 2nd International Con-
ference  on Formal  Ontology  in  Information  Sys-
tems (FOIS-2001).
Snow, R., Jurafsky, D. and Ng, A. Y. (2004). Learn-
ing syntactic patterns for automatic hypernym dis-
covery.  Advances  in Neural Information Process-
ing Systems 17.
Veale,  T.  and Hao,  Y. (2007).  Making Lexical  On-
tologies Functional and Context-Sensitive. In Proc.  
of the 45th Annual Meeting of the ACL, pp 57?64.
Veale, T. and  Hao, Y. (2008).  A Fluid Knowledge 
Representation for  Understanding and Generating 
Creative Metaphors.  In Proc. of Coling 2008, The  
22nd International  Conference  on  Computational  
Linguistics, Manchester.
842
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 57?64,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Making Lexical Ontologies Functional and Context-Sensitive
Tony Veale
Computer Science and Informatics
University College Dublin
Ireland
tony.veale@ucd.ie
Yanfen Hao
Computer Science and Informatics
University College Dublin
Ireland
yanfen.hao@ucd.ie
Abstract
Human categorization is neither a binary nor
a context-free process. Rather, some con-
cepts are better examples of a category than
others, while the criteria for category mem-
bership may be satisfied to different degrees
by different concepts in different contexts.
In light of these empirical facts, WordNet?s
static category structure appears both exces-
sively rigid and unduly fragile for process-
ing real texts. In this paper we describe a
syntagmatic, corpus-based approach to re-
defining WordNet?s categories in a func-
tional, gradable and context-sensitive fash-
ion. We describe how the diagnostic prop-
erties for these definitions are automati-
cally acquired from the web, and how the
increased flexibility in categorization that
arises from these redefinitions offers a ro-
bust account of metaphor comprehension
in the mold of Glucksberg?s (2001) the-
ory of category-inclusion. Furthermore, we
demonstrate how this competence with figu-
rative categorization can effectively be gov-
erned by automatically-generated ontologi-
cal constraints, also acquired from the web.
1 Introduction
Linguistic variation across contexts is often symp-
tomatic of ontological differences between contexts.
These observable variations can serve as valuable
clues not just to the specific senses of words in con-
text (e.g., see Pustejovsky, Hanks and Rumshisky,
2004) but to the underlying ontological structure it-
self (see Cimiano, Hotho and Staab, 2005). The
most revealing variations are syntagmatic in nature,
which is to say, they look beyond individual word
forms to larger patterns of contiguous usage (Hanks,
2004). In most contexts, the similarity between
chocolate, say, and a narcotic like heroin will mea-
gerly reflect the simple ontological fact that both are
kinds of substances; certainly, taxonomic measures
of similarity as discussed in Budanitsky and Hirst
(2006) will capture little more than this common-
ality. However, in a context in which the addictive
properties of chocolate are very salient (e.g., an on-
line dieting forum), chocolate is more likely to be
categorized as a drug and thus be considered more
similar to heroin. Look, for instance, at the simi-
lar ways in which these words can be used: one can
be ?chocolate-crazed? or ?chocolate-addicted? and
suffer ?chocolate-induced? symptoms (e.g., each of
these uses can be found in the pages of Wikipedia).
In a context that gives rise to these expressions, it is
unsurprising that chocolate should appear altogether
more similar to a harmful narcotic.
In this paper we computationally model this idea
that language use reflects category structure. As
noted by De Leenheer and de Moor (2005), ontolo-
gies are lexical representations of concepts, so we
can expect the effects of context on language use
to closely reflect the effects of context on ontolog-
ical structure. An understanding of the linguistic ef-
fects of context, as expressed through syntagmatic
patterns of word usage, should lead therefore to the
design of more flexible lexical ontologies that natu-
rally adapt to their contexts of use. WordNet (Fell-
57
baum, 1998) is just one such lexical ontology that
can benefit greatly from the added flexibility that
context-sensitivity can bring. Though comprehen-
sive in scale and widely used, WordNet suffers from
an obvious structural rigidity in which concepts are
either entirely within a category or entirely outside
a category: no gradation of category membership
is allowed, and no contextual factors are brought to
bear on criteria for membership. Thus, a gun is al-
ways a weapon in WordNet while an axe is never so,
despite the uses (sporting or murderous) to which
each can be put.
In section two we describe a computational
framework for giving WordNet senses a functional,
context-sensitive form. These functional forms si-
multaneously represent i) an intensional definition
for each word sense; ii) a structured query capable
of retrieving instances of the corresponding category
from a context-specific corpus; and iii) a member-
ship function that assigns gradated scores to these
instances based on available syntagmatic evidence.
In section three we describe how the knowledge re-
quired to automate this functional re-definition is ac-
quired from the web and linked to WordNet. In sec-
tion four we describe how these re-definitions can
produce a robust model of metaphor, before we eval-
uate the descriptive sufficiency of this approach in
section five, comparing it to the knowledge already
available within WordNet. We conclude with some
final remarks in section six.
2 Functional Context-Sensitive Categories
We take a wholly textual view of context and as-
sume that a given context can be implicitly charac-
terized by a representative text corpus. This corpus
can be as large as a text archive or an encyclopedia
(e.g., the complete text of Wikipedia), or as small
as a single document, a sentence or even a single
noun-phrase. For instance, the micro-context ?alco-
holic apple-juice? is enough to implicate the cate-
gory Liquor, rather than Juice, as a semantic head,
while ?lovable snake? can be enough of a context to
locally categorize Snake as a kind of Pet. There is a
range of syntagmatic patterns that one can exploit to
glean category insights from a text. For instance, the
?X kills? pattern is enough to categorize X as a kind
of Killer, ?hunts X? is enough to categorize X as
a kind of Prey, while ?X-covered?, ?X-dipped? and
?X-frosted? all indicate that X is a kind of Covering.
Likewise, ?army of X? suggests that a context views
X as a kind of Soldier, while ?barrage of X? suggests
that X should be seen as a kind of Projectile.
We operationalize the collocation-type of adjec-
tive and noun via the function (attr ADJ NOUN),
which returns a number in the range 0...1; this
represents the extent to which ADJ is used to
modify NOUN in the context-defining corpus.
Dice?s coefficient (e.g., see Cimiano et al, 2005) is
used to implement this measure. A context-sensitive
category membership function can be defined, as in
that for Fundamentalist in Figure 1:
(define Fundamentalist.0 (arg
0
)
(* (max
(%isa arg
0
Person.0)
(%isa arg
0
Group.0))
(min
(max
(attr political arg
0
)
(attr religious arg
0
))
(max
(attr extreme arg
0
)
(attr violent arg
0
)
(attr radical arg
0
)))))
Figure 1. A functional re-definition of the cat-
egory Fundamentalist.
The function of Figure 1 takes, as a single ar-
gument arg
0
, a putative member of the category
Fundamentalist.0 (note how the sense tag, 0, is
used to identify a specific WordNet sense of ?fun-
damentalist?), and returns a membership score in
the range 0...1 for this term. This score reflects the
syntagmatic evidence for considering arg
0
to be
political or religious, as well as extreme or violent
or radical. The function (%isa arg
0
CAT) returns a
value of 1.0 if some sense of arg
0
is a descendent
of CAT (here Person.0 or Group.0), otherwise 0.
This safeguards ontological coherence and ensures
that only kinds of people or groups can ever be
considered as fundamentalists.
The example of Figure 1 is hand-crafted, but a
functional form can be assigned automatically to
many of the synsets in WordNet by heuristic means.
58
For instance, those of Figure 2 are automatically
derived from WordNet?s morpho-semantic links:
(define Fraternity.0 (arg
0
)
(* (%sim arg
0
Fraternity.0)
(max
(attr fraternal arg
0
)
(attr brotherly arg
0
))))
(define Orgasm.0 (arg
0
)
(* (%sim arg
0
Orgasm.0)
(max
(attr climactic arg
0
)
(attr orgasmic arg
0
))))
Figure 2. Exploiting the WordNet links be-
tween nouns and their adjectival forms.
The function (%sim arg
0
CAT) reflects the
perceived similarity between the putative member
arg
0
and a synset CAT in WordNet, using one of
the standard formulations described in Budanitsky
and Hirst (2006). Thus, any kind of group (e.g., a
glee club, a Masonic lodge, or a barbershop quartet)
described in a text as ?fraternal? or ?brotherly?
(both occupy the same WordNet synset) can be
considered a Fraternity to the corresponding degree,
tempered by its a priori similarity to a Fraternity;
likewise, any climactic event can be categorized as
an Orgasm to a more or less degree.
Alternately, the function of Figure 3 is automat-
ically obtained for the lexical concept Espresso by
shallow parsing its WordNet gloss: ?strong black
coffee brewed by forcing steam under pressure
through powdered coffee beans?.
(define Espresso.0 (arg
0
)
(* (%sim arg
0
Espresso.0)
(min
(attr strong arg
0
)
(attr black arg
0
))))
Figure 3. A functional re-definition of the cat-
egory Espresso based on its WordNet gloss.
It follows that any substance (e.g., oil or tea)
described locally as ?black? and ?strong? with a
non-zero taxonomic similarity to coffee can be
considered a kind of Espresso.
Combining the contents of WordNet 1.6 and
WordNet 2.1, 27,732 different glosses (shared by
51,035 unique word senses) can be shallow parsed to
yield a definition of the kind shown in Figure 3. Of
these, 4525 glosses yield two or more properties that
can be given functional form via attr. However, one
can question whether these features are sufficient,
and more importantly, whether they are truly diag-
nostic of the categories they are used to define. In
the next section we consider another source of diag-
nostic properties, explicit similes on the web, before,
in section 5, comparing the quality of these proper-
ties to those available from WordNet.
3 Diagnostic Properties on the Web
We employ the Google search engine as a retrieval
mechanism for acquiring the diagnostic properties
of categories from the web, since the Google API
and its support for the wildcard term * allows this
process to be fully automated. The guiding intu-
ition here is that looking for explicit similes of the
form ?X is as P as Y? is the surest way of finding
the most salient properties of a term Y; with other
syntagmatic patterns, such as adjective:noun collo-
cations, one cannot be sure that the adjective is cen-
tral to the noun.
Since we expect that explicit similes will tend to
exploit properties that occupy an exemplary point on
a scale, we first extract a list of antonymous adjec-
tives, such as ?hot? or ?cold?, from WordNet. For
every adjective ADJ on this list, we send the query
?as ADJ as *? to Google and scan the first 200 snip-
pets returned to extract different noun values for the
wildcard *. From each set of snippets we can also
ascertain the relative frequencies of different noun
values for ADJ. The complete set of nouns extracted
in this way is then used to drive a second phase of
the search, in which the query template ?as * as a
NOUN? is used to acquire similes that may have
lain beyond the 200-snippet horizon of the original
search, or that may hinge on adjectives not included
on the original list. Together, both phases collect
a wide-ranging series of core samples (of 200 hits
each) from across the web, yielding a set of 74,704
simile instances (of 42,618 unique types) relating
59
3769 different adjectives to 9286 different nouns
3.1 Property Filtering
Unfortunately, many of these similes are not suffi-
ciently well-formed to identify salient properties. In
many cases, the noun value forms part of a larger
noun phrase: it may be the modifier of a compound
noun (as in ?bread lover?), or the head of complex
noun phrase (such as ?gang of thieves? or ?wound
that refuses to heal?). In the former case, the com-
pound is used if it corresponds to a compound term
in WordNet and thus constitutes a single lexical unit;
if not, or if the latter case, the simile is rejected.
Other similes are simply too contextual or under-
specified to function well in a null context, so if one
must read the original document to make sense of
the simile, it is rejected. More surprisingly, per-
haps, a substantial number of the retrieved simi-
les are ironic, in which the literal meaning of the
simile is contrary to the meaning dictated by com-
mon sense. For instance, ?as hairy as a bowling
ball? (found once) is an ironic way of saying ?as
hairless as a bowling ball? (also found just once).
Many ironies can only be recognized using world
knowledge, such as ?as sober as a Kennedy? and ?as
tanned as an Irishman?.
Given the creativity involved in these construc-
tions, one cannot imagine a reliable automatic fil-
ter to safely identify bona-fide similes. For this
reason, the filtering task is performed by a human
judge, who annotated 30,991 of these simile in-
stances (for 12,259 unique adjective/noun pairings)
as non-ironic and meaningful in a null context; these
similes relate a set of 2635 adjectives to a set of
4061 different nouns. In addition, the judge also
annotated 4685 simile instances (of 2798 types) as
ironic; these similes relate a set of 936 adjectives
to a set of 1417 nouns. Perhaps surprisingly, ironic
pairings account for over 13% of all annotated sim-
ile instances and over 20% of all annotated types.
3.2 Linking to WordNet Senses
To create functional WordNet definitions from these
adjective:noun pairings, we first need to identify the
WordNet sense of each noun. For instance, ?as stiff
as a zombie? might refer either to a re-animated
corpse or to an alcoholic cocktail (both are senses
of ?zombie? in WordNet, and drinks can be ?stiff?
too). Disambiguation is trivial for nouns with just
a single sense in WordNet. For nouns with two or
more fine-grained senses that are all taxonomically
close, such as ?gladiator? (two senses: a boxer and a
combatant), we consider each sense to be a suitable
target. In some cases, the WordNet gloss for as par-
ticular sense will literally mention the adjective of
the simile, and so this sense is chosen. In all other
cases, we employ a strategy of mutual disambigua-
tion to relate the noun vehicle in each simile to a spe-
cific sense in WordNet. Two similes ?as A as N
1
?
and ?as A as N
2
? are mutually disambiguating if N
1
and N
2
are synonyms in WordNet, or if some sense
of N
1
is a hypernym or hyponym of some sense of
N
2
in WordNet. For instance, the adjective ?scary?
is used to describe both the noun ?rattler? and the
noun ?rattlesnake? in bona-fide (non-ironic) similes;
since these nouns share a sense, we can assume that
the intended sense of ?rattler? is that of a danger-
ous snake rather than a child?s toy. Similarly, the
adjective ?brittle? is used to describe both saltines
and crackers, suggesting that it is the bread sense of
?cracker? rather than the hacker, firework or hillbilly
senses (all in WordNet) that is intended.
These heuristics allow us to automatically disam-
biguate 10,378 bona-fide simile types (85%), yield-
ing a mapping of 2124 adjectives to 3778 different
WordNet senses. Likewise, 77% (or 2164) of the
simile types annotated as ironic are disambiguated
automatically. A remarkable stability is observed in
the alignment of noun vehicles to WordNet senses:
100% of the ironic vehicles always denote the same
sense, no matter the adjective involved, while 96%
of bona-fide vehicles always denote the same sense.
This stability suggests two conclusions: the dis-
ambiguation process is consistent and accurate; but
more intriguingly, only one coarse-grained sense of
any word is likely to be sufficiently exemplary of
some property to be useful in a simile.
4 From Similes to Category Functions
As noted in section 3, the filtered web data yields
12,259 bona-fide similes describing 4061 target
nouns in terms of 2635 different adjectival prop-
erties. Word-sense disambiguation allows 3778
synsets in WordNet to be given a functional re-
definition in terms of 2124 diagnostic properties, as
60
in the definition of Gladiator in Figure 4:
(define Gladiator.0 (arg
0
)
(* (%isa arg
0
Person.0)
(* (%sim arg
0
Gladiator.0)
(combine
(attr strong arg
0
)
(attr violent arg
0
)
(attr manly arg
0
)))))
Figure 4. Aweb-based definition of Gladiator.
Since we cannot ascertain from the web data
which properties are necessary and which are
collectively sufficient, we use the function combine
to aggregate the available evidence. This function
implements a na??ve probabilistic or, in which each
piece of syntagmatic evidence is naively assumed to
be independent, as follows:
(combine e
0
e
1
) = e
0
+ e
1
(1 ? e
0
)
(combine e
0
e
1
...e
n
) = (combine e
0
(combine e
1
...e
n
))
Thus, any combatant or competitor (such as a
sportsman) that is described as strong, violent or
manly in a corpus can be categorized as a Gladiator
in that context; the more properties that hold, and
the greater the degree to which they hold, the greater
the membership score that is assigned.
The source of the hard taxonomic constraint
(%isa arg
0
Person.0) is explained in the next sec-
tion. For now, note how the use of %sim in the
functions of Figures 2, 3 and 4 means that these
membership functions readily admit both literal and
metaphoric members. Since the line between lit-
eral and metaphoric uses of a category is often im-
possible to draw, the best one can do is to accept
metaphor as a gradable phenomenon (see Hanks,
2006). The incorporation of taxonomic similarity
via %sim ensures that literal members will tend to
receive higher membership scores, and that the most
tenuous metaphors will receive the lowest member-
ship scores (close to 0.0).
4.1 Constrained Category Inclusion
Simile and metaphor involve quite different con-
ceptual mechanisms. For instance, anything that
is particularly strong or black might meaningfully
be called ?as black as espresso? or ?as strong
as espresso?, yet few such things can meaning-
fully be called just ?espresso?. While simile is a
mechanism for highlighting inter-concept similarity,
metaphor is at heart a mechanism of category inclu-
sion (see Glucksberg, 2001). As the espresso exam-
ple demonstrates, category inclusion is more than a
matter of shared properties: humans have strong in-
tuitions about the structure of categories and the ex-
tent to which they can be stretched to include new
members. So while it is sensible to apply the cat-
egory Espresso to other substances, preferably liq-
uids, it seems nonsensical to apply the category to
animals, artifacts, places and so on.
Much as the salient properties of categories can
be acquired form the web (see section 3), so too
can the intuitions governing inclusion amongst cat-
egories. For instance, an attested web-usage of the
phrase ?Espresso-like CAT? tells us that sub-types
of CAT are allowable targets of categorization by the
category Espresso. Thus, since the query ?espresso-
like substance? returns 3 hits via Google, types of
substance (oil, etc.) can be described as Espresso if
they are contextually strong and black. In contrast,
the query ?espresso-like person? returns 0 hits, so
no instance of person can be described as Espresso,
no matter how black or how strong. While this is
clearly a heuristic approach to a complex cognitive
problem, it does allow us to tap into the tacit knowl-
edge that humans employ in categorization. More
generally, a concept X can be included in a category
C if X exhibits salient properties of C and, for some
hypernym H of X in WordNet, we can find an at-
tested use of ?C-like H? on the web.
If we can pre-fetch all possible ?C-like H?
from the web, this will allow comprehension to
proceed without having to resort to web analysis
in mid-categorization. While there are too many
possible values of H to make full pre-fetching a
practical reality, we can generalize the problem
somewhat, by selecting a range of values for H
from the middle-layer of WordNet, such as Person,
Substance, Animal, Tool, Plant, Structure, Event,
Vehicle, Idea and Place, and by pre-fetching the
query ?C-like H? for all 4061 nouns collected in
section 3, combined with this limited set of H
values. For every noun in our database then, we pre-
compile a vector of possible category inclusions.
61
For instance, ?lattice? yields the following vector:
{structure(1620), substance(8), container(1),
vehicle(1)}
where numbers in parentheses indicate the web-
frequency of the corresponding ?Lattice-like H?
query. Thus, the category Lattice can be used to
describe (and metaphorically include) other kinds
of structure (like crystals), types of substance (e.g.,
crystalline substances), containers (like honey-
combs) and even vehicles (e.g., those with many
compartments). Likewise, the noun ?snake? yields
the following vector of possibilities:
{structure(125), animal(122), person(56), ve-
hicle(17), tool(9)}
(note, the frequency for ?person? includes the
frequency for ?man? and ?woman?). The category
Snake can also be used to describe and include
structures (like tunnels), other animals (like eels),
people (e.g., the dishonest variety), vehicles (e.g.,
articulated trucks, trains) and tools (e.g., hoses). The
noun ?gladiator? yields a vector of just one element,
{person(1)}, from which the simple constraint
(%isa arg
0
Person.0) in Figure 4 is derived. In con-
trast, ?snake? is now given the definition of Figure 5:
(define Snake.0 (arg
0
)
(* (max
(%isa arg
0
Structure.0)
(%isa arg
0
Animal.0)
(%isa arg
0
Person.0)
(%isa arg
0
Vehicle.0))
(* (%sim arg
0
Snake.0)
(combine
(attr cunning arg
0
)
(attr slippery arg
0
)
(attr flexible arg
0
)
(attr slim arg
0
)
(attr sinuous arg
0
)
(attr crooked arg
0
)
(attr deadly arg
0
)
(attr poised arg
0
)))))
Figure 5. A membership function for Snake
using web-derived category-inclusion constraints.
Glucksberg (2001) notes that the same category,
used figuratively, can exhibit different qualities in
different metaphors. For instance, Snake might
describe a kind of crooked person in one metaphor,
a poised killer in another metaphor, and a kind of
flexible tool in yet another. The use of combine
in Figure 5 means that a single category definition
can give rise to each of these perspectives in the
appropriate contexts. We therefore do not need a
different category definition for each metaphoric
use of Snake.
To illustrate the high-level workings of category-
inclusion, Table 1 generalizes over the set of 3778
disambiguated nouns from section 3 to estimate the
propensity for one semantic category, like Person, to
include members of another category, like Animal,
in X-like Y constructs.
X-like Y P A Sub T Str
(P)erson .66 .05 .03 .04 .09
(A)nimal .36 .27 .04 .05 .15
(Sub)stance .14 .03 .37 .05 .32
(T)ool .08 .03 .07 .22 .34
(Str)ucture .04 .03 .03 .03 .43
Table 1. The Likelihood of a category X accommo-
dating a category Y.
Table 1 reveals that 36% of ?ANIMAL-like?
patterns on the web describe a kind of Person,
while only 5% of ?PERSON-like? patterns on the
web describe a kind of Animal. Category inclusion
appears here to be a conservative mechanism, with
like describing like in most cases; thus, types of
Person are most often used to describe other kinds
of Person (comprising 66% of ?PERSON-like?
patterns), types of substance to describe other sub-
stances, and so on. The clear exception is Animal,
with ?ANIMAL-like? phrases more often used to
describe people (36%) than other kinds of animal
(27%). The anthropomorphic uses of this category
demonstrate the importance of folk-knowledge in
figurative categorization, of the kind one is more
likely to find in real text, and on the web (as in
section 3), rather than in resources like WordNet.
62
5 Empirical Evaluation
The simile gathering process of section 3, abetted
by Google?s practice of ranking pages according to
popularity, should reveal the most frequently-used
comparative nouns, and thus, the most useful cat-
egories to capture in a general-purpose ontology
like WordNet. But the descriptive sufficiency of
these categories is not guaranteed unless the defin-
ing properties ascribed to each can be shown to
be collectively rich enough, and individually salient
enough, to predict how each category is perceived
and applied by a language user.
If similes are indeed a good basis for mining
the most salient and diagnostic properties of cate-
gories, we should expect the set of properties for
each category to accurately predict how the cate-
gory is perceived as a whole. For instance, humans
? unlike computers ? do not generally adopt a dis-
passionate view of ideas, but rather tend to asso-
ciate certain positive or negative feelings, or affec-
tive values, with particular ideas. Unsavoury activi-
ties, people and substances generally possess a nega-
tive affect, while pleasant activities and people pos-
sess a positive affect. Whissell (1989) reduces the
notion of affect to a single numeric dimension, to
produce a dictionary of affect that associates a nu-
meric value in the range 1.0 (most unpleasant) to 3.0
(most pleasant) with over 8000 words in a range of
syntactic categories (including adjectives, verbs and
nouns). So to the extent that the adjectival proper-
ties yielded by processing similes paint an accurate
picture of each category / noun-sense, we should be
able to predict the affective rating of each vehicle
via a weighted average of the affective ratings of
the adjectival properties ascribed to these nouns (i.e.,
where the affect rating of each adjective contributes
to the estimated rating of a noun in proportion to
its frequency of co-occurrence with that noun in our
simile data). More specifically, we should expect
that ratings estimated via these simile-derived prop-
erties should correlate well with the independent rat-
ings contained in Whissell?s dictionary.
To determine whether similes do offer the clearest
perspective on a category?s most salient properties,
we calculate and compare this correlation using the
following data sets:
A. Adjectives derived from annotated bona-fide
(non-ironic) similes only.
B. Adjectives derived from all annotated similes
(both ironic and non-ironic).
C. Adjectives derived from ironic similes only.
D. All adjectives used to modify a given noun in
a large corpus. We use over 2-gigabytes of
text from the online encyclopaedia Wikipedia
as our corpus.
E. The set of 63,935 unique property-of-noun
pairings extracted via shallow-parsing from
WordNet glosses in section 2, e.g., strong and
black for Espresso.
Predictions of affective rating were made from each
of these data sources and then correlated with the
ratings reported in Whissell?s dictionary of affect
using a two-tailed Pearson test (p < 0.01). As ex-
pected, property sets derived from bona-fide simi-
les only (A) yielded the best correlation (+0.514)
while properties derived from ironic similes only
(C) yielded the worst (-0.243); a middling corre-
lation coefficient of 0.347 was found for all simi-
les together, demonstrating the fact that bona-fide
similes outnumber ironic similes by a ratio of 4
to 1. A weaker correlation of 0.15 was found us-
ing the corpus-derived adjectival modifiers for each
noun (D); while this data provides quite large prop-
erty sets for each noun, these properties merely re-
flect potential rather than intrinsic properties of each
noun and so do not reveal what is most diagnostic
about a category. More surprisingly, property sets
derived from WordNet glosses (E) are also poorly
predictive, yielding a correlation with Whissell?s af-
fect ratings of just 0.278. This suggests that the
properties used to define categories in hand-crafted
resources like WordNet are not always those that ac-
tually reflect how humans think of these categories.
6 Concluding Remarks
Much of what we understand about different cate-
gories is based on tacit and defeasible knowledge of
the outside world, knowledge that cannot easily be
shoe-horned into the rigid is-a structure of an on-
tology like WordNet. This already-complex picture
63
is complicated even further by the often metaphoric
relationship between words and the categories they
denote, and by the fact that the metaphor/literal dis-
tinction is not binary but gradable. Furthermore, the
gradability of category membership is clearly influ-
enced by context: in a corpus describing the exploits
of Vikings, an axe will most likely be seen as a kind
of weapon, but in a corpus dedicated to forestry, it
will likely describe a tool. A resource like WordNet,
in which is-a links are reserved for category relation-
ships that are always true, in any context, is going to
be inherently limited when dealing with real text.
We have described an approach that can be seen as
a functional equivalent to the CPA (Corpus Pattern
Analysis) approach of Pustejovsky et al (2004), in
which our goal is not that of automated induction of
word senses in context (as it is in CPA) but the au-
tomated induction of flexible, context-sensitive cat-
egory structures. As such, our goal is primarily on-
tological rather than lexicographic, though both ap-
proaches are complementary since each views syn-
tagmatic evidence as the key to understanding the
use of lexical concepts in context. By defining cat-
egory membership in terms of syntagmatic expec-
tations, we establish a functional and gradable ba-
sis for determining whether one lexical concept (or
synset) in WordNet deserves to be seen as a de-
scendant of another in a particular corpus and con-
text. Augmented with ontological constraints de-
rived from the usage of ?X-like Y? patterns on the
web, we also show how these membership functions
can implement Glucksberg?s (2001) theory of cate-
gory inclusion.
We have focused on just one syntagmatic pattern
here ? adjectival modification of nouns ? but cate-
gorization can be inferred from a wide range of pro-
ductive patterns in text, particularly those concern-
ing verbs and their case-fillers. For instance, verb-
centred similes of the form ?to V+inf like a|an N?
and ?to be V+past like a|an N? reveal insights into
the diagnostic behaviour of entities (e.g., that preda-
tors hunt, that prey is hunted, that eagles soar and
bombs explode). Taken together, adjective-based
properties and verb-based behaviours can paint an
even more comprehensive picture of each lexical
concept, so that e.g., political agents that kill can
be categorized as assassins, loyal entities that fight
can be categorized as soldiers, and so on. An im-
portant next step, then, is to mine these behaviours
from the web and incorporate the corresponding
syntagmatic expectations into our category defini-
tions. The symbolic nature of the resulting defini-
tions means these can serve not just as mathematical
membership functions, but as ?active glosses?, capa-
ble of recruiting their own members in a particular
context while demonstrating a flexibility with cate-
gorization and a genuine competence with metaphor.
References
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating WordNet-based Measures of Lexical Semantic
Relatedness. Computational Linguistics, 32(1), pp 13-
47.
Christiane Fellbaum (ed.). 1998. WordNet: An Elec-
tronic Lexical Database. The MIT Press, Cambridge,
MA.
Cynthia Whissell. 1989. The dictionary of affect in lan-
guage. In R. Plutchnik & H. Kellerman (Eds.). Emo-
tion: Theory and research. New York, Harcourt
Brace, 113-131.
James Pustejovsky, Patrick Hanks and Anna Rumshisky.
2004. Automated Induction of Sense in Context. In
Proceedings of COLING 2004, Geneva, pp 924-931.
Patrick Hanks. 2006. Metaphoricity is a Gradable. In A.
Stefanowitsch and S. Gries (eds.). Corpora in Cog-
nitive Linguistics. Vol. 1: Metaphor and Metonymy.
Berlin: Mouton.
Patrick Hanks. 2004. The syntagmatics of metaphor and
idiom. International Journal of Lexicography, 17(3).
Philipp Cimiano, Andreas Hotho, and Steffen Staab.
2005. Learning Concept Hierarchies from Text Cor-
pora using Formal Concept Analysis. Journal of AI
Research, 24: 305-339.
Pieter De Leenheer and Aldo de Moor. 2005. Context-
driven Disambiguation in Ontology Elicitation. In
Shvaiko P. & Euzenat J. (eds.), Context and Ontolo-
gies: Theory, Practice and Applications, AAAI Tech
Report WS-05-01. AAAI Press, pp 17-24.
Sam Glucksberg. 2001. Understanding figurative lan-
guage: From metaphors to idioms. Oxford: Oxford
University Press.
64
Proceedings of ACL-08: HLT, pages 523?531,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Multilingual Harvesting of Cross-Cultural Stereotypes
Tony Veale
School of Computer Science
University College Dublin
Belfield, Dublin 4, Ireland
tony.veale@ucd.ie
Yanfen Hao
School of Computer Science
University College Dublin
Belfield, Dublin 4, Ireland
yanfen.hao@ucd.ie
Guofu Li
School of Computer Science
University College Dublin
Belfield, Dublin 4, Ireland
li.guofu.l@gmail.com
Abstract
People rarely articulate explicitly what a na-
tive speaker of a language is already assumed
to know. So to acquire the stereotypical
knowledge that underpins much of what is
said in a given culture, one must look to what
is implied by language rather than what is
overtly stated. Similes are a convenient ve-
hicle for this kind of knowledge, insofar as
they mark out the most salient aspects of the
most frequently evoked concepts. In this pa-
per we perform a multilingual exploration of
the space of common-place similes, by min-
ing a large body of Chinese similes from the
web and comparing these to the English sim-
iles harvested by Veale and Hao (2007). We
demonstrate that while the simile-frame is in-
herently leaky in both languages, a multilin-
gual analysis allows us to filter much of the
noise that otherwise hinders the knowledge
extraction process. In doing so, we can also
identify a core set of stereotypical descrip-
tions that exist in both languages and accu-
rately map these descriptions onto a multilin-
gual lexical ontology like HowNet. Finally,
we demonstrate that conceptual descriptions
that are derived from common-place similes
are extremely compact and predictive of onto-
logical structure.
1 Introduction
Direct perception of our environment is just one
of the ways we can acquire knowledge of the
world. Another, more distinctly human approach,
is through the comprehension of linguistic descrip-
tions of another person?s perceptions and beliefs.
Since computers have limited means of human-like
perception, the latter approach is also very much
suited to the automatic acquisition of world knowl-
edge by a computer (see Hearst, 1992; Charniak and
Berland, 1999; Etzioni et al, 2004; Vo?lker et al,
2005; Almuhareb and Poesio, 2005; Cimiano and
Wenderoth, 2007; Veale and Hao, 2007). Thus, by
using the web as a distributed text corpus (see Keller
et al, 2002), a multitude of facts and beliefs can
be extracted, for purposes ranging from question-
answering to ontology population.
The possible configurations of different concepts
can also be learned from how the words denoting
these concepts are distributed; thus, a computer can
learn that coffee is a beverage that can be served hot
or cold, white or black, strong or weak and sweet
or bitter (see Almuhareb and Poesio, 2005). But it
is difficult to discern from these facts the idealized
or stereotypical states of the world, e.g., that one ex-
pects coffee to be hot and beer to be cold, so that if
one spills coffee, we naturally infer the possibilities
of scalding and staining without having to be told
that the coffee was hot or black; the assumptions
of hotness and blackness are just two stereotypical
facts about coffee that we readily take for granted.
Lenat and Guha (1990) describe these assumed facts
as residing in the white space of a text, in the body
of common-sense assumptions that are rarely articu-
lated as explicit statements. These culturally-shared
common-sense beliefs cannot be harvested directly
from a single web resource or document set, but
must be gleaned indirectly, from telling phrases that
are scattered across the many texts of the web.
Veale and Hao (2007) argue that the most pivotal
523
reference points of this world-view can be detected
in common-place similes like ?as lazy as a dog?, ?as
fat as a hippo? or ?as chaste as a nun?. To the extent
that this world-view is ingrained in and influenced
by how we speak, it can differ from culture to cul-
ture and language to language. In English texts, for
example, the concept Tortoise is stereotypically as-
sociated with the properties slowness, patience and
wrinkled, but in Chinese texts, we find that the same
animal is a model of slowness, ugliness, and nutri-
tional value. Likewise, because Chinese ?wine? has
a high alcohol content, the dimension of Strength is
much more salient to a Chinese speaker than an En-
glish speaker, as reflected in how the word? is used
in statements such as??????, which means
?as strong as wine?, or literally, ?as wine equally
strong?.
In this paper, we compare the same web-based
approach to acquiring stereotypical concept descrip-
tions from text using two very different languages,
English and Chinese, to determine the extent to
which the same cross-cultural knowledge is un-
earthed for each. In other words, we treat the web as
a large parallel corpus (e.g., see Resnick and Smith,
2003), though not of parallel documents in dif-
ferent languages, but of corresponding translation-
equivalent phrases. By seeking translation equiva-
lence between different pieces of textually-derived
knowledge, this paper addresses the following ques-
tions: if a particular syntagmatic pattern is useful for
mining knowledge in English, can its translated form
be equally useful for Chinese? To what extent does
the knowledge acquired using different source lan-
guages overlap, and to what extent is this knowledge
language- (and culture-) specific? Given that the
syntagmatic patterns used in each language are not
wholly unambiguous or immune to noise, to what
extent should finding the same beliefs expressed in
two different languages increase our confidence in
the acquired knowledge? Finally, what representa-
tional synergies arise from finding these same facts
expressed in two different languages?
Given these goals, the rest of the paper as-
sumes the following structure: in section 2, we
summarize related work on syntagmatic approaches
to knowledge-acquisition; in section 3, we de-
scribe our multilingual efforts in English and Chi-
nese to acquire stereotypical or generic-level facts
from the web, by using corresponding translations
of the commonplace stereotype-establishing pattern
?as ADJ as a NOUN?; and in section 4, we describe
how these English and Chinese data-sets can be uni-
fied using the bilingual ontology HowNet (Dong and
Dong, 2006). This mapping allows us to determine
the meaning overlap in both data sets, the amount
of noise in each data set, and the degree to which
this noise is reduced when parallel translations can
be identified. In section 5 we demonstrate the
overall usefulness of stereotype-based knowledge-
representation by replicating the clustering experi-
ments of Almuhareb and Poesio (2004, 2005) and
showing that stereotype-based representations are
both compact and predictive of ontological classi-
fication. We conclude the paper with some final re-
marks in section 6.
2 Related Work
Text-based approaches to knowledge acquisition
range from the ambitiously comprehensive, in which
an entire text or resource is fully parsed and ana-
lyzed in depth, to the surgically precise, in which
highly-specific text patterns are used to eke out cor-
respondingly specific relationships from a large cor-
pus. Endeavors such as that of Harabagiu et al
(1999), in which each of the textual glosses in Word-
Net (Fellbaum, 1998) is linguistically analyzed to
yield a sense-tagged logical form, is an example of
the former approach. In contrast, foundational ef-
forts such as that of Hearst (1992) typify the latter
surgical approach, in which one fishes in a large text
for word sequences that strongly suggest a particu-
lar semantic relationship, such as hypernymy or, in
the case of Charniak and Berland (1999), the part-
whole relation. Such efforts offer high precision but
low recall, and extract just a tiny (but very useful)
subset of the semantic content of a text. The Know-
ItAll system of Etzioni et al (2004) employs the
same generic patterns as Hearst ( e.g., ?NPs such
as NP1, NP2, ...?), and more besides, to extract a
whole range of facts that can be exploited for web-
based question-answering. Cimiano and Wenderoth
(2007) also use a range of Hearst-like patterns to
find text sequences in web-text that are indicative
of the lexico-semantic properties of words; in par-
ticular, these authors use phrases like ?to * a new
524
NOUN? and ?the purpose of NOUN is to *? to
identify the agentive and telic roles of given nouns,
thereby fleshing out the noun?s qualia structure as
posited by Pustejovsky?s (1990) theory of the gener-
ative lexicon.
The basic Hearst approach has even proven use-
ful for identifying the meta-properties of concepts
in a formal ontology. Vo?lker et al (2005) show
that patterns like ?is no longer a|an NOUN? can
identify, with reasonable accuracy, those concepts
in an ontology that are not rigid, which is to say,
concepts like Teacher and Student whose instances
may at any point stop being instances of these con-
cepts. Almuhareb and Poesio (2005) use patterns
like ?a|an|the * C is|was? and ?the * of the C is|was?
to find the actual properties of concepts as they are
used in web texts; the former pattern is used to iden-
tify value features like hot, red, large, etc., while
the latter is used to identify the attribute features
that correspond to these values, such as tempera-
ture, color and size. Almuhareb and Poesio go on
to demonstrate that the values and attributes that are
found for word-concepts on the web yield a suffi-
ciently rich representation for these word-concepts
to be automatically clustered into a form resembling
that assigned by WordNet (see Fellbaum, 1998).
Veale and Hao (2007) show that the pattern ?as ADJ
as a|an NOUN? can also be used to identify the
value feature associated with a given concept, and
argue that because this pattern corresponds to that
of the simile frame in English, the adjectival fea-
tures that are retrieved are much more likely to be
highly salient of the noun-concept (the simile ve-
hicle) that is used. Whereas Almuhareb and Poe-
sio succeed in identifying the range of potential at-
tributes and values that may be possessed by a par-
ticular concept, Veale and Hao succeed in identi-
fying the generic properties of a concept as it is
conceived in its stereotypical form. As noted by
the latter authors, this results in a much smaller yet
more diagnostic feature set for each concept. How-
ever, because the simile frame is often exploited for
ironic purposes in web texts (e.g., ?as meaty as a
skeleton?), and because irony is so hard to detect,
Veale and Hao suggest that the adjective:noun pair-
ings found on the web should be hand-filtered to re-
move such examples. Given this onerous require-
ment for hand-filtering, and the unique, culturally-
loaded nature of the noise involved, we use the work
of Veale and Hao as the basis for the cross-cultural
investigation in this paper.
3 Harvesting Knowledge from Similes:
English and Chinese
Because similes are containers of culturally-
received knowledge, we can reasonably expect the
most commonly used similes to vary significantly
from language to language, especially when those
languages correspond to very different cultures.
These similes form part of the linguistic currency of
a culture which must be learned by a speaker, and
indeed, some remain opaque even to the most edu-
cated native speakers. In ?A Christmas Carol?, for
instance, Dickens (1943/1984) questions the mean-
ing of ?as dead as a doornail?, and notes: ?I might
have been inclined, myself, to regard a coffin-nail as
the deadest piece of ironmongery in the trade. But
the wisdom of our ancestors is in the simile?.
Notwithstanding the opacity of some instances of
the simile form, similes are very revealing about the
concepts one most encounters in everyday language.
In section 5 we demonstrate that concept descrip-
tions which are harvested from similes are both ex-
tremely compact and highly predictive of ontolog-
ical structure. For now, we turn to the process by
which similes can be harvested from the text of the
web. In section 3.1 we summarize the efforts of
Veale and Hao, whose database of English similes
drives part of our current investigation. In section
3.2 we describe how a comparable database of Chi-
nese similes can be harvested from the web.
3.1 Harvesting English Similes
Veale and Hao (2007) use the Google API in con-
junction with Princeton WordNet (Fellbaum, 1998)
as the basis of their harvesting system. They first
extracted a list of antonymous adjectives, such as
?hot? or ?cold?, from WordNet, the intuition being
that explicit similes will tend to exploit properties
that occupy an exemplary point on a scale. For ev-
ery adjective ADJ on this list, they then sent the
query ?as ADJ as *? to Google and scanned the
first 200 snippets returned for different noun val-
ues for the wildcard *. The complete set of nouns
extracted in this way was then used to drive a sec-
525
ond harvesting phase, in which the query ?as * as
a NOUN? was used to collect similes that employ
different adjectives or which lie beyond the 200-
snippet horizon of the original search. Based on
this wide-ranging series of core samples (of 200 hits
each) from across the web, Veale and Hao report
that both phases together yielded 74,704 simile in-
stances (of 42,618 unique types, or unique adjec-
tive:noun pairings), relating 3769 different adjec-
tives to 9286 different nouns. As often noted by
other authors, such as Vo?lker et al (2005), a pattern-
oriented approach to knowledge mining is prone to
noise, not least because the patterns used are rarely
leak-free (inasmuch as they admit word sequences
that do not exhibit the desired relationship), and be-
cause these patterns look at small text sequences in
isolation from their narrative contexts. Veale and
Hao (2007) report that when the above 42,618 simile
types are hand-annotated by a native speaker, only
12,259 were judged as non-ironic and meaningful
in a null context. In other words, just 29% of the
retrieved pairings conform to what one would con-
sider a well-formed and reusable simile that conveys
some generic aspect of cultural knowledge. Of those
deemed invalid, 2798 unique pairings were tagged
as ironic, insofar as they stated precisely the oppo-
site of what is stereotypically believed to be true.
3.2 Harvesting Chinese Similes
To harvest a comparable body of Chinese similes
from the web, we also use the Google API, in con-
junction with both WordNet and HowNet (Dong and
Dong, 2006). HowNet is a bilingual lexical ontol-
ogy that associates English and Chinese word labels
with an underlying set of approximately 100,000
lexical concepts. While each lexical concept is de-
fined using a unique numeric identifier, almost all of
HowNet?s concepts can be uniquely identified by a
pairing of English and Chinese labels. For instance,
the word ???? can mean both Tortoise and Cuck-
old in Chinese, but the combined label tortoise|??
uniquely picks out the first sense while cuckold|?
? uniquely picks out the second. Though Chi-
nese has a large number of figurative expressions,
the yoking of English to Chinese labels still serves
to identify the correct sense in almost every case.
For instance, ????? is another word for Cuck-
old in Chinese, but it can also translate as ?green
hat? and ?green scarf?. Nonetheless, green hat|?
?? uniquely identifies the literal sense of ???
?? (a green covering) while green scarf|???
and cuckold|??? both identify the same human
sense, the former being a distinctly culture-specific
metaphor for cuckolded males (in English, a dispos-
sessed lover ?wears the cuckold?s horns?; in Chi-
nese, one apparently ?wears a green scarf?).
We employ the same two-phase design as Veale
and Hao: an initial set of Chinese adjectives are
extracted from HowNet, with the stipulation that
their English translations (as given by HowNet) are
also categorized as adjectives in WordNet. We
then use the Chinese equivalent of the English sim-
ile frame ??* ??ADJ? (literally, ?as-NOUN-
equally-ADJ?) to retrieve a set of noun values that
stereotypically embody these adjectival features.
Again, a set of 200 snippets is analyzed for each
query, and only those values of the Google * wild-
card that HowNet categorizes as nouns are accepted.
In a second phase, these nouns are used to create
new queries of the form ??Noun??*? and the re-
sulting Google snippets are now scanned for adjec-
tival values of *.
In all, 25,585 unique Chinese similes (i.e., pair-
ings of an adjective to a noun) are harvested, link-
ing 3080 different Chinese adjectives to 4162 Chi-
nese nouns. When hand-annotated by a native Chi-
nese speaker, the Chinese simile frame reveals it-
self to be considerably less leaky than the corre-
sponding English frame. Over 58% of these pairings
(14,867) are tagged as well-formed and meaning-
ful similes that convey some stereotypical element
of world knowledge. The Chinese pattern ??*?
?*? is thus almost twice as reliable as the English
?as * as a *? pattern. In addition, Chinese speak-
ers exploit the simile frame much less frequently for
ironic purposes, since just 185 of the retrieved sim-
iles (or 0.7%) are tagged as ironic, compared with
ten times as many (or 7%) retrieved English similes.
In the next section we consider the extent to which
these English and Chinese similes convey the same
information.
4 Tagging and Mapping of Similes
In each case, the harvesting processes for English
and for Chinese allow us to acquire stereotypi-
526
cal associations between words, not word senses.
Nonetheless, the frequent use of synonymous terms
introduces a substantial degree of redundancy in
these associations, and this redundancy can be used
to perform sense discrimination. In the case of En-
glish similes, Veale and Hao (2007) describe how
two English similes ?as A as N1? and ?as A as
N2? will be mutually disambiguating if N1 and
N2 are synonyms in WordNet, or if some sense
of N1 is a hypernym or hyponym of some sense
of N2 in WordNet. This heuristic allows Veale
and Hao to automatically sense-tag 85%, or 10,378,
of the unique similes that are annotated as valid.
We apply a similar intuition to the disambiguation
of Chinese similes: though HowNet does not sup-
port the notion of a synset, different word-senses
that have the same meaning will be associated with
the same logical definition. Thus, the Chinese
word ???? can translate as ?celebrated?, ?fa-
mous?, ?well-known? and ?reputable?, but all four
of these possible senses, given by celebrated|??,
famous|??, well-known|?? and reputable|?
?, are associated with the same logical form in
HowNet, which defines them as a specialization of
ReputationValue|???. This allows us to safely
identify ???? with this logical form. Overall, 69%
of Chinese similes can have both their adjective and
noun assigned to specific HowNet meanings in this
way.
4.1 Translation Equivalence Among Similes
Since HowNet represents an integration of English
and Chinese lexicons, it can easily be used to con-
nect the English and Chinese data-sets. For while
the words used in any given simile are likely to
be ambiguous (in the case of one-character Chinese
words, highly so), it would seem unlikely that an
incorrect translation of a web simile would also be
found on the web. This is an intuition that we can
now use the annotated data-sets to evaluate.
For every English simile of the form <Ae as
Ne>, we use HowNet to generate a range of possible
Chinese variations <Ac0 as Nc0>, <Ac1 as Nc0>,
<Ac0 as Nc1>, <Ac1 as Nc1>, ... by using the
HowNet lexical entries Ae|Ac0, Ae|Ac1, ..., Ne|Nc0,
Ne|Nc1, ... as a translation bridge. If the variation
<Aci as Ncj> is found in the Chinese data-set, then
translation equivalence is assumed between <Ae as
Language Precision Recall F1
English 0.76 0.25 0.38
Chinese 0.82 0.27 0.41
Table 1: Automatic filtering of similes using Translation
Equivalence.
Ne> and <Aci as Ncj>; furthermore, Ae|Aci is as-
sumed to be the HowNet sense of the adjectives Ae
and Aci while Ncj is assumed to be the HowNet
sense of the nouns Ne and Ncj . Sense-tagging is
thus a useful side-effect of simile-mapping with a
bilingual lexicon.
We attempt to find Chinese translation equiva-
lences for all 42,618 of the English adjective:noun
pairings harvested by Veale and Hao; this includes
both the 12,259 pairings that were hand-annotated as
valid stereotypical facts, and the remaining 30,359
that were dismissed as noisy or ironic. Using
HowNet, we can establish equivalences from 4177
English similes to 4867 Chinese similes. In those
mapped, we find 3194 English similes and 4019
Chinese similes that were hand-annotated as valid
by their respective native-speaker judges. In other
words, translation equivalence can be used to sep-
arate well-formed stereotypical beliefs from ill-
formed or ironic beliefs with approximately 80%
precision. The precise situation is summarized in
Table 1.
As noted in section 3, just 29% of raw English
similes and 58% of raw Chinese similes that are har-
vested from web-text are judged as valid stereotyp-
ical statements by a native-speaking judge. For the
task of filtering irony and noise from raw data sets,
translation equivalence thus offers good precision
but poor recall, since most English similes appear
not to have a corresponding Chinese variant on the
web. Nonetheless, this heuristic allows us to reliably
identify a sizeable body of cross-cultural stereotypes
that hold in both languages.
4.1.1 Error Analysis
Noisy propositions may add little but empty con-
tent to a representation, but ironic propositions will
actively undermine a representation from within,
leading to inferences that are not just unlikely, but
patently false (as is generally the intention of irony).
Since Veale and Hao (2007) annotate their data-
527
set for irony, this allows us to measure the number
of egregious mistakes made when using translation
equivalence as a simile filter. Overall, we see that
1% of Chinese similes that are accepted via transla-
tion equivalence are ironic, accounting for 9% of all
errors made when filtering Chinese similes. Like-
wise, 1% of the English similes that are accepted are
ironic, accounting for 5% of all errors made when
filtering English similes.
4.2 Representational Synergies
By mapping WordNet-tagged English similes onto
HowNet-tagged Chinese similes, we effectively ob-
tain two representational viewpoints onto the same
shared data set. For instance, though HowNet
has a much shallower hierarchical organization
than WordNet, it compensates by encapsulating the
meaning of different word senses using simple log-
ical formulae of semantic primitives, or sememes,
that are derived from the meaning of common Chi-
nese characters. WordNet and HowNet thus offer
two complementary levels or granularities of gen-
eralization that can be exploited as the context de-
mands.
4.2.1 Adjective Organization
Unlike WordNet, HowNet organizes its adjec-
tival senses hierarchically, allowing one to obtain
a weaker form of a given description by climb-
ing the hierarchy, or to obtain a stronger form by
descending the hierarchy from a particular sense.
Thus, one can go up from kaleidoscopic|???
? to colored|?, or down from colored|? to
any of motley|??, dappled|??, prismatic|??
?? and even gorgeous|??. Once stereotypi-
cal descriptions have been sense-tagged relative to
HowNet, they can easily be further enhanced or
bleached to suit the context of their use. For exam-
ple, by allowing a Chinese adjective to denote any
of the senses above it or below in the HowNet hi-
erarchy, we can extend the mapping of English to
Chinese similes so as to achieve an improved recall
of .36 (though we note that this technique reduces
the precision of the translation-equivalence heuristic
to .75).
As demonstrated by Almuhareb and Poesio
(2004), the best conceptual descriptions combine
adjectival values with the attributes that they fill.
Because adjectival senses hook into HowNet?s up-
per ontology via a series of abstract taxonyms like
TasteValue|???, ReputationValue|??? and
AmountValue|???, a taxonym of the form At-
tributeValue can be identified for every adjective
sense in HowNet. For example, the English ad-
jective ?beautiful? can denote either beautiful|?,
organized by HowNet under BeautyValue|??
?, or beautiful|?, organized by HowNet un-
der gracious|? which in turn is organized under
GraceValue|???. The adjective ?beautiful? can
therefore specify either the Grace or Beauty at-
tributes of a concept. Once similes have been sense-
tagged, we can build up a picture of most salient at-
tributes of our stereotypical concepts. For instance,
?peacock? similes yield the following attributes via
HowNet: Beauty, Appearance, Color, Pride, Be-
havior, Resplendence, Bearing and Grace; likewise
?demon? similes yield the following: Morality, Be-
havior, Temperament, Ability and Competence.
4.2.2 Orthographic Form
The Chinese data-set lacks counterparts to many
similes that one would not think of as culturally-
determined, such ?as red as a ruby?, ?as cruel as
a tyrant? and ?as smelly as a skunk?. One signifi-
cant reason for this kind of omission is not cultural
difference, but obviousness: many Chinese words
are multi-character gestalts of different ideas (see
Packard, 2000), so that these ideas form an explicit
part of the orthography of a lexical concept. For in-
stance, using HowNet, we can see that skunk|??
is actually a gestalt of the concepts smelly|? and
weasel|?, so the simile ?as smelly as a skunk? is
already somewhat redundant in Chinese (somewhat
akin to the English similes ?as hot as a hotdog? or
?as hard as a hardhat?).
Such decomposition can allow us to find those
English similes that are already orthographically ex-
plicit in Chinese word-forms. We simply look for
pairs of HowNet senses of the form Noun|XYZ and
Adj|X, where X and XYZ are Chinese words and the
simile ?as Adj as a|an Noun? is found in the English
simile set. When we do so, we find that 648 English
similes, from ?as meaty as a steak? to ?as resonant
as a cello?, are already fossilized in the orthographic
realization of the corresponding Chinese concepts.
When fossilized similes are uncovered in this way,
528
the recall of translation equivalence as a noise filter
rises to .29, while its precision rises to .84 (see Table
1)
5 Empirical Evaluation: Simile-derived
Representations
Stereotypes persist in language and culture because
they are, more often than not, cognitively useful:
by emphasizing the most salient aspects of a con-
cept, a stereotype acts as a dense conceptual descrip-
tion that is easily communicated, widely shared,
and which supports rapid inference. To demonstrate
the usefulness of stereotype-based concept descrip-
tions, we replicate here the clustering experiments
of Almuhareb and Poesio (2004, 2005), who in turn
demonstrated that conceptual features that are mined
from specific textual patterns can be used to con-
struct WordNet-like ontological structures. These
authors used different text patterns for mining fea-
ture values (like hot) and attributes (like tempera-
ture), and their experiments evaluated the relative ef-
fectiveness of each as a means of ontological cluster-
ing. Since our focus in this paper is on the harvesting
of feature values, we replicate here only their exper-
iments with values.
Almuhareb and Poesio (2004) used as their ex-
perimental basis a sampling of 214 English nouns
from 13 of WordNet?s upper-level semantic cate-
gories, and proceeded to harvest adjectival features
for these noun-concepts from the web using the tex-
tual pattern ?[a | an | the] * C [is |was]?. This pattern
yielded a combined total of 51,045 value features
for these 214 nouns, such as hot, black, etc., which
were then used as the basis of a clustering algorithm
in an attempt to reconstruct the WordNet classifica-
tions for all 214 nouns. Clustering was performed
by the CLUTO-2.1 package (Karypis, 2003), which
partitioned the 214 nouns in 13 categories on the ba-
sis of their 51,045 web-derived features. Compar-
ing these clusters with the original WordNet-based
groupings, Almuhareb and Poesio report a cluster-
ing accuracy of 71.96%. In a second, larger exper-
iment, Almuhareb and Poesio (2005) sampled 402
nouns from 21 different semantic classes in Word-
Net, and harvested 94,989 feature values from the
web using the same textual pattern. They then ap-
plied the repeated bisections clustering algorithm to
Approach accuracy features
Almuhareb + Poesio 71.96% 51,045
Simile-derived stereotypes 70.2% 2,209
Table 2: Results for experiment 1 (214 nouns, 13 WN
categories).
Approach Cluster Cluster features
purity entropy
Almu. + Poesio
(no filtering) 56.7% 38.4% 94,989
Almu. + Poesio
(with filtering) 62.7% 33.8% 51345
Simile-derived
stereotypes
(no filtering) 64.3% 33% 5,547
Table 3: Results for experiment 2 (402 nouns, 21 WN
categories).
this larger data set, and report an initial cluster purity
measure of 56.7%. Suspecting that a noisy feature
set had contributed to the apparent drop in perfor-
mance, these authors then proceed to apply a variety
of noise filters to reduce the set of feature values to
51,345, which in turn leads to an improved cluster
purity measure of 62.7%.
We replicated both of Almuhareb and Poesio?s
experiments on the same experimental data-sets (of
214 and 402 nouns respectively), using instead the
English simile pattern ?as * as a NOUN? to harvest
features for these nouns from the web. Note that
in keeping with the original experiments, no hand-
tagging or filtering of these features is performed, so
that every raw match with the simile pattern is used.
Overall, we harvest just 2209 feature values for the
214 nouns of experiment 1, and 5547 features for the
402 nouns of experiment 2. A comparison of both
sets of results for experiment 1 is shown is Table 2,
while a comparison based on experiment 2 is shown
is Table 3.
While Almuhareb and Poesio achieve marginally
higher clustering on the 214 nouns of experiment 1,
they do so by using over 20 times as many features.
529
In experiment 2, we see a similar ratio of feature
quantities before filtering; after some initial filtering,
Almuhareb and Poesio reduce their feature set to just
under 10 times the size of the simile-derived feature
set.
These experiments demonstrate two key points
about stereotype-based representations. First, the
feature representations do not need to be hand-
filtered and noise-free to be effective; we see from
the above results that the raw values extracted
from the simile pattern prove slightly more effec-
tive than filtered feature sets used by Almuhareb and
Poesio. Secondly, and perhaps more importantly,
stereotype-based representations prove themselves a
much more compact means (by factor of 10 to 20
times) of achieving the same clustering goals.
6 Conclusions
Knowledge-acquisition from texts can be a process
fraught with complexity: such texts - especially
web-based texts - are frequently under-determined
and vague; highly ambiguous, both lexically and
structurally; and dense with figures of speech, hy-
perbolae and irony. None of the syntagmatic frames
surveyed in section 2, from the ?NP such as NP1,
NP2 ...? pattern of Hearst (1992) and Etzioni et al
(2004) to the ?no longer NOUN? pattern of Vo?lker
et al (2005), are leak-free and immune to noise.
Cimiano and Wenderoth (2007) mitigate this prob-
lem somewhat by performing part-of-speech anal-
ysis on all extracted text sequences, but the prob-
lem remains: the surgical, pattern-based approach
offers an efficient and targeted means of knowledge-
acquisition from corpora because it largely ignores
the context in which these patterns occur; yet one
requires this context to determine if a given text se-
quence really is a good exemplar of the semantic re-
lationship that is sought.
In this paper we have described how stereotyp-
ical associations between adjectival properties and
noun concepts can be mined from similes in web
text. When harvested in both English and Chi-
nese, these associations exhibit two kinds of re-
dundancy that can mitigate the problem of noise.
The first kind, within-language redundancy, allows
us to perform sense-tagging of the adjectives and
nouns that are used in similes, by exploiting the
fact that the same stereotypical association can oc-
cur in a variety of synonymous forms. By recog-
nizing synonymy between the elements of different
similes, we can thus identify the underlying senses
(or WordNet synsets) in these similes. The sec-
ond kind, between-language redundancy, exploits
the fact that the same associations can occur in dif-
ferent languages, allowing us to exploit translation-
equivalence to pin these associations to particular
lexical concepts in a multilingual lexical ontology
like HowNet. While between-language redundancy
is a limited phenomenon, with just 26% of Veale
and Hao?s annotated English similes having Chinese
translations on the web, this phenomenon does allow
us to identify a significant core of shared stereotyp-
ical knowledge across these two very different lan-
guages.
Overall, our analysis suggests that a comparable
number of well-formed Chinese and English similes
can be mined from the web (our exploration finds
approx. 12,000 unique examples of each). This
demonstrates that harvesting stereotypical knowl-
edge from similes is a workable strategy in both lan-
guages. Moreover, Chinese simile usage is charac-
terized by two interesting facts that are of some prac-
tical import: the simile frame ??NOUN??ADJ?
is a good deal less leaky and prone to noise than the
equivalent English frame, ?as ADJ as a NOUN?; and
Chinese speakers appear less willing to subvert the
stereotypical norms of similes for ironic purposes.
Further research is needed to determine whether
these observations generalize to other knowledge-
mining patterns.
References
A. Almuhareb and M. Poesio. 2004. Attribute-Based and
Value-Based Clustering: An Evaluation. In proceed-
ings of EMNLP 2004, pp 158?165. Barcelona, Spain.
A. Almuhareb and M. Poesio. 2005. Concept Learning
and Categorization from the Web. In proceedings of
CogSci 2005, the 27th Annual Conference of the Cog-
nitive Science Society. New Jersey: Lawrence Erl-
baum.
C. Dickens. 1843/1981. A Christmas Carol. Puffin
Books, Middlesex, UK.
C. Fellbaum. 1998. WordNet, an electronic lexical
database. MIT Press.
E. Charniak and M. Berland. 1999. Finding parts in
530
very large corpora. In proceedings of the 37th Annual
Meeting of the ACL, pp 57-64.
F. Keller, M. Lapata, and O. Ourioupina. 2002. Using
the web to overcome data sparseness. In proceedings
of EMNLP-02, pp 230-237.
F. Keller, M. Lapata, and O. Ourioupina. 1990. Building
large knowledge-based systems: representation and
inference in the Cyc project. Addison-Wesley.
G. Karypis. 2003. CLUTO: A clustering toolkit. Univer-
sity of Minnesota.
J. L. Packard. 2000. The Morphology of Chinese: A
Linguistic and Cognitive Approach. Cambridge Uni-
versity Press, UK.
J. Pustejovsky. 1991. The generative lexicon. Computa-
tional Linguistics 17(4), pp 209-441.
J. Vo?lker, D. Vrandecic and Y. Sure. 2005. Automatic
Evaluation of Ontologies (AEON). In Y. Gil, E. Motta,
V. R. Benjamins, M. A. Musen, Proceedings of the 4th
International Semantic Web Conference (ISWC2005),
volume 3729 of LNCS, pp. 716-731. Springer Verlag
Berlin-Heidelberg.
M. Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In proceedings of the 14th
intenatinal conference on Computational Linguistics,
pp 539-545.
O. Etzioni, S. Kok, S. Soderland, M. Cafarella, A-M.
Popescu, D. Weld, D. Downey, T. Shaked and A.
Yates. 2004. Web-scale information extraction in
KnowItAll (preliminary results). In proceedings of the
13th WWW Conference, pp 100-109.
P. Cimiano and J. Wenderoth. 2007. Automatic Acqui-
sition of Ranked Qualia Structures from the Web. In
proceedings of the 45th Annual Meeting of the ACL,
pp 888?895.
P. Resnik and N. A. Smith. 2003. The Web as a parallel
corpus. Computational Linguistics, 29(3),pp 349-380.
S. Harabagiu, G. Miller and D. Moldovan. 1999. Word-
Net2 - a morphologically and semantically enhanced
resource. In proceedings of SIGLEX-99, pp 1-8, Uni-
versity of Maryland.
T. Veale and Y. Hao. 2007. Making Lexical Ontologies
Functional and Context-Sensitive. In proceedings of
the 45th Annual Meeting of the ACL, pp 57-64.
Z. Dong and Q. Dong. 2006. HowNet and the Computa-
tion of Meaning. World Scientific: Singapore.
531
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 14?19,
Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational Linguistics
Exploiting Readymades in Linguistic Creativity:
A System Demonstration of the Jigsaw Bard
Tony Veale
Yanfen Hao
School of Computer Science and Informatics, School of Computer Science and Informatics,
University College Dublin, University College Dublin,
Belfield, Dublin D4, Ireland. Belfield, Dublin D4, Ireland.
Tony.Veale@UCD.ie Yanfen.Hao@UCD.ie
Demonstration System can be viewed at: http://www.educatedinsolence.com/jigsaw
Abstract
Large lexical resources, such as corpora
and databases of Web ngrams, are a rich
source of pre-fabricated phrases that can be
reused in many different contexts. How-
ever, one must be careful in how these re-
sources are used, and noted writers such as
George Orwell have argued that the use of
canned phrases encourages sloppy thinking
and results in poor communication. None-
theless, while Orwell prized home-made
phrases over the readymade variety, there
is a vibrant movement in modern art which
shifts artistic creation from the production
of novel artifacts to the clever reuse of
readymades or objets trouv?s. We describe
here a system that makes creative reuse of
the linguistic readymades in the Google
ngrams. Our system, the Jigsaw Bard, thus
owes more to Marcel Duchamp than to
George Orwell. We demonstrate how tex-
tual readymades can be identified and har-
vested on a large scale, and used to drive a
modest form of linguistic creativity.
1 Introduction
In a much-quoted essay from 1946 entitled Politics
and the English Language, the writer and thinker
George Orwell outlines his prescription for halting
a perceived decline in the English language. He
argues that language and thought form a tight
feedback cycle that can be either virtuous or vi-
cious. Lazy language can thus promote lazy think-
ing, and vice versa. Orwell pours scorn on two
particular forms of lazy language: the expedient
use of overly familiar metaphors merely because
they come quickly to mind, even though they have
lost their power to evoke vivid images,; and the use
of readymade turns of phrase as substitutes for in-
dividually crafted expressions. While a good writer
bends words to his meaning, Orwell worries that a
lazy writer bends his meaning to convenient words.
Orwell is especially scornful about readymade
phrases which, when over-used, ?are tacked to-
gether like the sections of a prefabricated hen-
house.? A writer who operates by ?mechanically
repeating the familiar phrases? and ?gumming to-
gether long strips of words which have already
been set in order by someone else? has, he argues,
?gone some distance toward turning himself into a
machine.? Given his derogatory mechanistic view
of the use of readymade phrases, Orwell would not
be surprised to learn that computers are highly pro-
ficient in the large-scale use of familiar phrases,
whether acquired from large text corpora or from
the Google ngrams (see Brants and Franz, 2006).
Though argued with passion, there are serious
holes in Orwell?s logic. If one should ?never  use a
metaphor, simile or other figure of speech which
you are used to seeing in print?, how then are fa-
miliar metaphors ever to become dead metaphors
and thereby enrich the language with new terms
and new senses? And if one cannot use familiar
readymade phrases, how can one make playful ?
and creative ? allusions to the writings of others, or
14
mischievously subvert the conventional wisdom of
platitudes and clich?s? Orwell?s use of the term
readymade is entirely negative, yet the term is al-
together more respectable in the world of modern
art, thanks to its use by artists such as Marcel
Duchamp. For many artists, a readymade object is
not a substitute, but a starting point, for creativity.
Also called an objet trouv? or found object, a
readymade emerges from an artist?s encounter with
an object whose aesthetic merits are overlooked in
its banal, everyday contexts of use; when this ob-
ject is moved to an explicitly artistic context, such
as an art gallery, viewers are better able to appreci-
ate these merits. The artist?s insight is to recognize
the transformational power of this non-obvious
context switch. Perhaps the most famous (and no-
torious) readymade in the world of art is Marcel
Duchamp?s Fountain, a humble urinal that be-
comes an elegantly curved piece of sculpture when
viewed with the right mindset. Duchamp referred
to his objets trouv?s as ?assisted readymades? be-
cause they allow an artist to remake the act of
creation as one of pure insight and inspired recog-
nition rather than one of manual craftsmanship (see
Taylor, 2009). In computational terms, the
Duchampian notion of a readymade allows crea-
tivity to be modeled not as a construction problem
but as a decision problem. A computational
Duchamp need not explore an abstract conceptual
space of potential ideas, as in Boden (1994). How-
ever, a Duchampian agent must instead be exposed
to the multitude of potentially inspiring real-world
stimuli that a human artist encounters everyday.
Readymades represent a serendipitous form of
creativity that is poorly served by exploratory
models of creativity, such as that of Boden (1994),
and better served by the investment models such as
the buy-low-sell-high theory of Sternberg and Lu-
bart (1995). In this view, creators and artists find
unexpected or untapped value in unfashionable
objects or ideas that already exist, and quickly
move their gaze elsewhere once the public at large
come to recognize this value. Duchampian creators
invest in everyday objects, just as Duchamp found
artistic merit in urinals, bottles and combs. From a
linguistic perspective, these everyday objects are
commonplace words and phrases which, when
wrenched from their conventional contexts of use,
are free to take on enhanced meanings and provide
additional returns to the investor. The realm in
which a maker of linguistic readymades operates is
not the real world, and not an abstract conceptual
space, but the realm of texts: large corpora become
rich hunting grounds for investors in linguistic ob-
jets trouv?s.
This proposal is demonstrated in computa-
tional form in the following sections. We show
how a rich vocabulary of cultural stereotypes can
be acquired from the Web, and how this vocabu-
lary facilitates the implementation of a decision
procedure for recognizing potential readymades in
large corpora ? in this case, the Google database of
Web ngrams (Brants and Franz, 2006). This deci-
sion procedure provides a robust basis for a simile-
generation system called The Jigsaw Bard. The
cognitive / linguistic intuitions that underpin the
Bard?s concept of textual readymades are put to
the empirical test in section 5. While readymades
remain a contentious notion in the public?s appre-
ciation of artistic creativity ? despite Duchamp?s
Fountain being considered one of the most influ-
ential artworks of the 20
th
 century ? we shall show
that the notion of a linguistic readymade has sig-
nificant practical merit in the realms of text gen-
eration and computational creativity.
2 Linguistic Readymades
Readymades are the result of artistic appropria-
tion, in which an object with cultural resonance ?
an image, a phrase, a quote, a name, a thing ? is re-
used in a new context with a new meaning. As a
fertile source of cultural reference points, language
is an equally fertile medium for appropriation.
Thus, in the constant swirl of language and culture,
movie quotes suggest song lyrics, which in turn
suggest movie titles, which suggest book titles, or
restaurant names, or the names of racehorses, and
so on, and on. The 1996 movie The Usual Suspects
takes its name from a memorable scene in 1942?s
Casablanca, as does the Woody Allen play and
movie Play it Again Sam. The 2010 art documen-
tary Exit Through the Gift Shop, by graffiti artist
Banksy, takes its name from a banal sign some-
times seen in museums and galleries: the sign,
suggestive as it is of creeping commercialism,
makes the perfect readymade for a film that la-
ments the mediocrity of commercialized art.
Appropriations can also be combined to pro-
duce novel mashups; consider, for instance, the use
of tweets from rapper Kanye West as alternate
15
captions for cartoon images from the New Yorker
magazine (see hashtag #KanyeNew-YorkerTweets).
Hashtags can themselves be linguistic readymades.
When free-speech advocates use the hashtag
#IAMSpartacus  to show solidarity with users
whose tweets have incurred the wrath of the law,
they are appropriating an emotional line from the
1960 film Spartacus. Linguistic readymades, then,
are well-formed text fragments that are often
highly quotable because they carry some figurative
content which can be reused in different contexts.
A quote like ?round up the usual suspects? or
?I am Spartacus? requires a great deal of cultural
knowledge to appreciate. Since literal semantics
only provides a small part of their meaning, a
computer?s ability to recognize linguistic ready-
mades is only as good as the cultural knowledge at
its disposal. We thus explore here a more modest
form of readymade ? phrases that can be used as
evocative image builders in similes ? as in:
a wet haddock
snow in January
a robot fish
a bullet-ridden corpse
Each phrase can be found in the Google 1T data-
base of Web ngrams ? snippets of Web text (of one
to five words) that occur on the web with a fre-
quency of 40 or higher (Brants and Franz, 2006).
Each is likely a literal description of a real object
or event ? even ?robot fish?, which describes an
autonomous marine vehicle whose movements
mimic real fish. But each exhibits figurative po-
tential as well, providing a memorable description
of physical or emotional coldness. Whether or not
each was ever used in a figurative sense before is
not the point: once this potential is recognized,
each phrase becomes a reusable linguistic ready-
made for the construction of a vivid figurative
comparison, as in ?as cold as a robot fish?. We
now consider the building blocks from which these
comparisons can be ready-made..
3 A Vocabulary of Cultural Stereotypes
How does a computer acquire the knowledge that
fish, snow, January, bullets and corpses are cultural
signifiers of coldness? Much the same way that
humans acquire this knowledge: by attending to
the way these signifiers are used by others, espe-
cially when they are used in cultural clich?s like
proverbial similes (e.g., ?as cold as a fish?).
In fact, folk similes are an important vector in
the transmission of cultural knowledge: they point
to, and exploit, the shared cultural touchstones that
speakers and listeners alike can use to construct
and intuit meanings. Taylor (1954) catalogued
thousands of proverbial comparisons and similes
from California, identifying just as many building
blocks in the construction of new phrases and figu-
rative meanings. Only the most common similes
can be found in dictionaries, as shown by Norrick
(1986), while Moon (2008) demonstrates that
large-scale corpus analysis is needed to identify
folk similes with a breadth approaching that of
Taylor?s study. However, Veale and Hao (2007)
show that the World-Wide Web is the ultimate re-
source for harvesting similes.
Veale and Hao use the Google API to find many
instances of the pattern ?as ADJ as a|an *? on the
web, where ADJ is an adjectival property and * is
the Google wildcard. WordNet (Fellbaum, 1998) is
used to provide a set of over 2,000 different values
for ADJ, and the text snippets returned by Google
are parsed to extract the basic simile bindings.
Once the bindings are annotated to remove noise,
as well as frequent uses of irony, this Web harvest
produces over 12,000 cultural bindings between a
noun (such as fish, or robot) and its most stereo-
typical properties (such as cold, wet, stiff, logical,
heartless, etc.). Stereotypical properties are ac-
quired for approx. 4,000 common English nouns.
This is a set of building blocks on a larger scale
than even that of Taylor, allowing us to build on
Veale and Hao (2007) to identify readymades in
their hundreds of thousands in the Google ngrams.
However, to identify readymades as resonant
variations on cultural stereotypes, we need a cer-
tain fluidity in our treatment of adjectival proper-
ties. The phrase ?wet haddock?  is a readymade for
coldness because ?wet? accentuates the ?cold? that
we associate with ?haddock? (via the web simile
?as cold as a haddock?). In the words of Hofstad-
ter (1995), we need to build a SlipNet of properties
whose structure captures the propensity of proper-
ties to mutually and coherently reinforce each
other, so that phrases which subtly accentuate an
unstated property can be recognized. In the vein of
Veale and Hao (2007), we use the Google API to
harvest the elements of this SlipNet.
16
We hypothesize that the construction ?as ADJ
1
and ADJ
2
 as? shows ADJ
1 
and ADJ
2
 to be mutu-
ally reinforcing properties, since they can be seen
to work together as a single complex property in a
single comparison. Thus, using the full comple-
ment of adjectival properties used by Veale and
Hao (2007), we harvest all instances of the patterns
?as ADJ and * as? and ?as * and ADJ as? from
Google, noting the combinations that are found and
their frequencies. These frequencies provide link
weights for the Hofstadter-style SlipNet that is
then constructed. In all, over 180,000 links are
harvested, connecting over 2,500 adjectival prop-
erties to one other. We put the intuitions behind
this SlipNet to the empirical test in section five.
4 Harvesting Readymades from Corpora
In the course of an average day, a creative writer is
exposed to a constant barrage of linguistic stimuli,
any small portion of which can strike a chord as a
potential readymade. In this casual inspiration
phase, the observant writer recognizes that a cer-
tain combination of words may produce, in another
context, a meaning that is more than the sum of its
parts. Later, when an apposite phrase is needed to
strike a particular note, this combination may be
retrieved from memory (or from a trusty note-
book), if it has been recorded and suitably indexed.
Ironically, Orwell (1946) suggests that lazy
writers ?shirk? their responsibility to be ?scrupu-
lous? in their use of language by ?simply throwing
[their] mind open and letting the ready-made
phrases come crowding in?. For Orwell, words just
get in the way, and should be kept at arm?s length
until the writer has first allowed a clear meaning to
crystallize. This is dubious advice, as one expects a
creative writer to keep an open mind when consid-
ering all the possibilities that present themselves.
Yet Orwell?s proscription suggests how a computer
should go about the task of harvesting readymades
from corpora: by throwing its mind open to the
possibility that a given ngram may one day have a
second life as a creative readymade in another
context, the computer allows the phrases that
match some simple image-building criteria to come
crowding in, so they can be stored in a database.
Given a rich vocabulary of cultural stereo-
types and their properties, computers are capable
of indexing and recalling a considerably larger
body of resonant combinations than the average
human. The necessary barrage of linguistic stimuli
can be provided by the Google 1T database of Web
ngrams (Brants and Franz, 2006). Trawling these
ngrams, a modestly creative computer can recog-
nize well-formed combinations of cultural ele-
ments that might serve as a vivid vehicle of
description in a future comparison. For every
phrase P in the ngrams, where P combines stereo-
type nouns and/or adjectival modifiers, the com-
puter simply poses the following question: is there
an unstated property A such that the simile ?as A
as P? is a meaningful and memorable comparison?
The property A can be simple, as in ?as dark as a
chocolate espresso?, or complex, as in ?as dark
and sophisticated as a chocolate martini?. In either
case, the phrase P is tucked away, and indexed un-
der the property A until such time as the computer
needs to produce a vivid evocation of A.
The following patterns are used to identify
potential readymades in the Web ngrams:
(1) Noun
S1
 Noun
S2
where both nouns denote stereotypes that
share an unstated property Adj
A
. The prop-
erty Adj
A
 serves to index this combination.
Example: ?as cold as a robot fish?.
(2) Noun
S1
 Noun
S2
where both nouns denote stereotypes with
salient properties Adj
A
1 
and Adj
A
2 
respec-
tively, such that Adj
A
1 
and Adj
A
2 
are mutu-
ally reinforcing. The combination is indexed
on Adj
A
1
+Adj
A2
. Example: ?as dark and
sophisticated as a chocolate martini?.
(3)  Adj
A
  Noun
S
where Noun
S
 denotes a cultural stereotype,
and the adjective Adj
A
 
denotes a property
that mutually reinforces an unstated but sali-
ent property Adj
SA
 
of the stereotype. Exam-
ple: ?as cold as a wet haddock?. The
combination is indexed on Adj
SA
.
More complex structures for P are also possible, as
in the phrases ?a lake of tears? (a melancholy way
to accentuate the property ?wet?) and ?a statue in a
library? (for ?silent? and ?quiet?). In this current
description, we focus on 2-gram phrases only.
17
Figure 1. Screenshot of The Jigsaw Bard, retrieving
linguistic readymades for the input property ?cold?. See
http://www.educatedinsolence.com/jigsaw
Using these patterns, our application ? the Jigsaw
Bard (see Figure 1) ? pre-builds a vast collection
of figurative similes well in advance of the time it
is asked to use or suggest any of them. Each phrase
P is syntactically well-formed, and because P oc-
curs relatively frequently on the Web, it is likely to
be semantically well-formed as well. Just as
Duchamp side-stepped the need to physically
originate anything, but instead appropriated pre-
fabricated artifacts, the Bard likewise side-steps
the need for natural-language generation. Each
phrase it proposes has the ring of linguistic
authenticity; because this authenticity is rooted in
another, more literal context, the Bard also exhibits
its own Duchamp-like (if Duchamp-lite) creativity.
We now consider the scale of the Bard?s genera-
tivity, and the quality of its insights.
5 Empirical Evaluation
The vastness of the web, captured in the large-
scale sample that is the Google ngrams, means the
Jigsaw Bard finds considerable grist for its mill in
the phrases that match (1)?(3). Thus, the most
restrictive pattern, pattern (1), harvests approx.
20,000 phrases from the Google 2-grams, for al-
most a thousand simple properties (indexing an
average of 29 phrases under each property, such as
?swan song? for ?beautiful?). Pattern (2) ? which
allows a blend of stereotypes to be indexed under a
complex property ? harvests approx. 170,000
phrases from the 2-grams, for approx. 70,000 com-
plex properties (indexing an average of 12 phrases
under each, such as ?hospital bed? for ?comfort-
able and safe?). Pattern (3) ? which pairs a stereo-
type noun with an adjective that draws out a salient
property of the stereotype ? is similarly productive:
it harvests approx. 150,000 readymade 2-grams for
over 2,000 simple properties (indexing an average
of 125 phrases per property, as in ?youthful knight?
for ?heroic? and ?zealous convert? for ?devout?).
The Jigsaw Bard is best understood as a crea-
tive thesaurus: for any given property (or blend of
properties) selected by the user, the Bard presents
a range of apt similes constructed from linguistic
readymades. The numbers above show that, recall-
wise, the Bard has sufficient coverage to work
robustly as a thesaurus. Quality-wise, users must
make their own determinations as to which similes
are most suited to their descriptive purposes, yet it
is important that suggestions provided by the Bard
are sensible and well-motivated. As such, we must
be empirically satisfied about two key intuitions:
first, that salient properties are indeed acquired
from the Web for our vocabulary of stereotypes
(this point relates to the aptness of the similes sug-
gested by the Bard); and second, that the adjectives
connected by the SlipNet really do mutually rein-
force each other (this point relates to the coherence
of complex properties, and to the ability of ready-
mades to accentuate unstated properties).
Both intuitions can be tested using Whissell?s
(1989) dictionary of affect, a psycholinguistic re-
source used for sentiment analysis that assigns a
pleasantness score of between 1.0 (least pleasant)
and 3.0 (most pleasant) to over 8,000 common-
place words. We should thus be able to predict the
pleasantness of a stereotype noun (like fish) using a
weighted average of the pleasantness of its salient
properties (like cold, slippery). We should also be
able to predict the pleasantness of an adjective us-
ing a weighted average of the pleasantness of its
adjacent adjectives in the SlipNet. (In each case,
weights are provided by relevant web frequencies.)
We can use a two-tailed Pearson test (p <
0.05) to compare the predictions made in each case
to the actual pleasantness scores provided by
Whissell?s dictionary, and thereby assess the qual-
ity of the knowledge used to make the predictions.
In the first case, predictions of the pleasantness of
stereotype nouns based on the pleasantness of their
salient properties (i.e., predicting the pleasantness
of Y from the Xs in ?as X as Y?) have a positive
18
correlation of 0.5 with Whissell; conversely, ironic
properties yield a negative correlation of ?0.2. In
the second, predictions of the pleasantness of ad-
jectives based on their relations in the SlipNet (i.e.,
predicting the pleasantness of X from the Ys in ?as
X and Y as?) have a positive correlation of 0.7.
Though pleasantness is just one dimension of lexi-
cal affect, it is one that requires a broad knowledge
of a word, its usage and its denotations to accu-
rately estimate. In this respect, the Bard is well
served by a large stock of stereotypes and a coher-
ent network of informative properties.
6 Conclusions
Fishlov (1992) has argued that poetic similes rep-
resent a conscious deviation from the norms of
non-poetic comparison. His analysis shows that
poetic similes are longer and more elaborate, and
are more likely to be figurative and to flirt with
incongruity. Creative similes do not necessarily
use words that are longer, or rarer, or fancier, but
use many of the same cultural building blocks as
non-creative similes. Armed with a rich vocabulary
of building blocks, the Jigsaw Bard harvests a
great many readymade phrases from the Google
ngrams ? from the evocative ?chocolate martini? to
the seemingly incongruous ?robot fish? ? that can
be used to evoke an wide range of properties.
This generativity makes the Bard scalable and
robust. However, any creativity we may attribute
to it comes not from the phrases themselves ? they
are readymades, after all ? but from the recognition
of the subtle and often complex properties they
evoke. The Bard exploits a sweet-spot in our un-
derstanding of linguistic creativity, and so, as pre-
sented here, is merely a starting point for our
continued exploitation of linguistic readymades,
rather than an end in itself. By harvesting more
complex syntactic structures, and using more so-
phisticated techniques for analyzing the figurative
potential of these phrases, the Bard and its ilk may
gradually approach the levels of poeticity dis-
cussed by Fishlov. For now, it is sufficient that
even simple techniques serve as the basis of a ro-
bust and practical thesaurus application.
7 Hardware Requirements
The Jigsaw Bard is designed to be a lightweight
application that compiles its comprehensive data-
base of readymades in advance. It?s run-time de-
mands are low, it has no special hardware
requirements, and runs in a standard Web browser.
Acknowledgments
This work was funded in part by Science Founda-
tion Ireland (SFI), via the Centre for Next Genera-
tion Localization (CNGL).
References
Margaret Boden, 1994. Creativity: A Framework for
Research, Behavioural and Brain Sciences 17(3),
558-568.
Thorsten Brants. and Alex Franz. 2006. Web 1T 5-gram
Version 1. Linguistic Data Consortium.
Christiane Fellbaum. (ed.) 2008. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge.
David Fishlov. 1992. Poetic and Non-Poetic Simile:
Structure, Semantics, Rhetoric. Poetics Today, 14(1).
Douglas R Hofstadter. 1995. Fluid Concepts and Crea-
tive Analogies: Computer Models of the Fundamen-
tal Mechanisms of Thought. Basic Books, NY.
Rosamund Moon. 2008.  Conventionalized as-similes in
English: A problem case. International Journal of
Corpus Linguistics 13(1), 3-37.
Neal Norrick,. 1986.  Stock Similes. Journal of Literary
Semantics XV(1), 39-52.
George Orwell. 1946. Politics And The English Lan-
guage. Horizon 13(76), 252-265.
Robert J Sternberg. and T. Ivan Lubart, 1995. Defying
the crowd: Cultivating creativity in a culture of con-
formity. Free Press, New York.
Archer Taylor. 1954. Proverbial Comparisons and
Similes from California. Folklore Studies 3. Ber-
keley: University of California Press.
Michael R. Taylor. (2009). Marcel Duchamp: ?tant
donn?s (Philadelphia Museum of Art). Yale Univer-
sity Press.
Tony Veale and Yanfen Hao. 2007. Making Lexical
Ontologies Functional and Context-Sensitive. In
Proceedings of the 46
th
 Annual Meeting of the Asso-
ciation of Computational Linguistics.
Cynthia Whissell. 1989. The dictionary of affect in lan-
guage. In R. Plutchnik & H. Kellerman (eds.) Emo-
tion: Theory and research. New York: Harcourt
Brace, 113-131.
19
