Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 116?117,
New York City, June 2006. c?2006 Association for Computational Linguistics
Refactoring Corpora
Helen L. Johnson
Center for Computational Pharmacology
U. of Colorado School of Medicine
helen.johnson@uchsc.edu
William A. Baumgartner, Jr.
Center for Computational Pharmacology
U. of Colorado School of Medicine
william.baumgartner@uchsc.edu
Martin Krallinger
Protein Design Group
Universidad Auto?noma de Madrid
martink@cnb.uam.es
K. Bretonnel Cohen
Center for Computational Pharmacology
U. of Colorado School of Medicine
kevin.cohen@gmail.com
Lawrence Hunter
Center for Computational Pharmacology
U. of Colorado School of Medicine
larry.hunter@uchsc.edu
Abstract
We describe a pilot project in semi-
automatically refactoring a biomedical
corpus. The total time expended was just
over three person-weeks, suggesting that
this is a cost-efficient process. The refac-
tored corpus is available for download at
http://bionlp.sourceforge.net.
1 Introduction
Cohen et al (2005) surveyed the usage rates of a
number of biomedical corpora, and found that most
biomedical corpora have not been used outside of
the lab that created them. Empirical data on corpus
design and usage suggests that one major factor af-
fecting usage is the format in which it is distributed.
These findings suggest that there would be a large
benefit to the community in refactoring these cor-
pora. Refactoring is defined in the software en-
gineering community as altering the internal struc-
ture of code without altering its external behav-
ior (Fowler et al, 1999). We suggest that in the con-
text of corpus linguistics, refactoring means chang-
ing the format of a corpus without altering its con-
tents, i.e. its annotations and the text that they de-
scribe. The significance of being able to refactor a
large number of corpora should be self-evident: a
likely increase in the use of the already extant pub-
licly available data for evaluating biomedical lan-
guage processing systems, without the attendant cost
of repeating their annotation.
We examined the question of whether corpus
refactoring is practical by attempting a proof-of-
concept application: modifying the format of the
Protein Design Group (PDG) corpus described in
Blaschke et al (1999) from its current idiosyncratic
format to a stand-off annotation format (WordF-
reak1) and a GPML-like (Kim et al, 2001) embed-
ded XML format.
2 Methods
The target WordFreak and XML-embedded formats
were chosen for two reasons. First, there is some
evidence suggesting that standoff annotation and
embedded XML are the two most highly preferred
corpus annotation formats, and second, these for-
mats are employed by the two largest extant curated
biomedical corpora, GENIA (Kim et al, 2001) and
BioIE (Kulick et al, 2004).
The PDG corpus we refactored was originally
constructed by automatically detecting protein-
protein interactions using the system described in
Blaschke et al (1999), and then manually review-
ing the output. We selected it for our pilot project
because it was the smallest publicly available cor-
pus of which we were aware. Each block of text has
a deprecated MEDLINE ID, a list of actions, a list of
proteins and a string of text in which the actions and
proteins are mentioned. The structure and contents
of the original corpus dictate the logical steps of the
refactoring process:
1. Determine the current PubMed identifier, given
the deprecated MEDLINE ID. Use the PubMed
identifier to retrieve the original abstract.
1http://venom.ldc.upenn.edu/
resources/info/wordfreak ann.html
116
2. Locate the original source sentence in the title
or abstract.
3. Locate the ?action? keywords and the entities
(i.e., proteins) in the text.
4. Produce output in the new formats.
Between each file creation step above, human cu-
rators verify the data. The creation and curation pro-
cess is structured this way so that from one step to
the next we are assured that all data is valid, thereby
giving the automation the best chance of performing
well on the subsequent step.
3 Results
The refactored PDG corpus is publicly available at
http://bionlp.sourceforge.net. Total time expended
to refactor the PDG corpus was 122 hours and 25
minutes, or approximately three person-weeks. Just
over 80% of the time was spent on the programming
portion. Much of that programming can be directly
applied to the next refactoring project. The remain-
ing 20% of the time was spent curating the program-
matic outputs.
Mapping IDs and obtaining the correct abstract
returned near-perfect results and required very little
curation. For the sentence extraction step, 33% of
the corpus blocks needed manual correction, which
required 4 hours of curation. (Here and below, ?cu-
ration? time includes both visual inspection of out-
puts, and correction of any errors detected.) The
source of error was largely due to the fact that the
sentence extractor returned the best sentence from
the abstract, but the original corpus text was some-
times more or less than one sentence.
For the protein and action mapping step, about
40% of the corpus segments required manual cor-
rection. In total, this required about 16 hours of cu-
ration time. Distinct sources of error included par-
tial entity extraction, incorrect entity extraction, and
incorrect entity annotation in the original corpus ma-
terial. Each of these types of errors were corrected.
4 Conclusion
The underlying motivation for this paper is the hy-
pothesis that corpus refactoring is practical, eco-
nomical, and useful. Erjavec (2003) converted the
GENIA corpus from its native format to a TEI P4
format. They noted that the translation process
brought to light some previously covert problems
with the GENIA format. Similarly, in the process of
the refactoring we discovered and repaired a number
of erroneous entity boundaries and spurious entities.
A number of enhancements to the corpus are now
possible that in its previous form would have been
difficult at best. These include but are not limited
to performing syntactic and semantic annotation and
adding negative examples, which would expand the
usefulness of the corpus. Using revisioning soft-
ware, the distribution of iterative feature additions
becomes simple.
We found that this corpus could be refactored with
about 3 person-weeks? worth of time. Users can take
advantage of the corrections that we made to the en-
tity component of the data to evaluate novel named
entity recognition techniques or information extrac-
tion approaches.
5 Acknowledgments
The authors thank the Protein Design Group at the Universidad
Auto?noma de Madrid for providing the original PDG protein-
protein interaction corpus, Christian Blaschke and Alfonso Va-
lencia for assistance and support, and Andrew Roberts for mod-
ifying his jTokeniser package for us.
References
Christian Blaschke, Miguel A. Andrade, and Christos Ouzou-
nis. 1999. Automatic extraction of biological information
from scientific text: Protein-protein interactions.
K. Bretonnel Cohen, Lynne Fox, Philip Ogren, and Lawrence
Hunter. 2005. Empirical data on corpus design and usage in
biomedical natural language processing. AMIA 2005 Sym-
posium Proceedings, pages 156?160.
Tomaz Erjavec, Yuka Tateisi, Jin-Dong Kim, and Tomoko Ohta.
2003. Encoding biomedical resources in TEI: the case of the
GENIA corpus.
Martin Fowler, Kent Beck, John Brant, William Opdyke, and
Don Roberts. 1999. Refactoring: improving the design of
existing code. Addison-Wesley.
Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, Hideki Mima, and
Jun?ichi Tsujii. 2001. Xml-based linguistic annotation of
corpus. In Proceedings of The First NLP and XML Work-
shop, pages 47?53.
S. Kulick, A. Bies, M. Liberman, M. Mandel, R. McDonald,
M. Palmer, A. Schein, and L. Ungar. 2004. Integrated anno-
tation for biomedical information extraction. Proceedings of
the HLT/NAACL.
117
Assessing the correlation between contextual patterns and
biological entity tagging.
M.KRALLINGER, M.PADRO?N, C.BLASCHKE, A.VALENCIA
Protein Design Group,
National Center of Biotechnology (CNB-CSIC),
Cantoblanco,
E-28049 Madrid,
martink, mpadron, blaschke, valencia@cnb.uam.es
Abstract
The tagging of biological entities, and in partic-
ular gene and protein names, is an essential step
in the analysis of textual information in Molec-
ular Biology and Biomedicine. The problem is
harder than was originally thought because of
the highly dynamic nature of the research area,
in which new genes and their functions are con-
stantly being discovered, and because of the lack
of commonly accepted standards. An impres-
sive collection of techniques has been used to
detect protein and gene names in the last four-
five years, ranging from typical NLP to purely
bioinformatics approaches. We explore here the
relationship between protein/gene names and
expressions used to characterize protein/gene
function. These expressions are captured in a
collection of patterns derived from an original
set of manually derived expressions, extended
to cover lexical variants and filtered with known
cases of association patterns/ names. Apply-
ing these patterns to a large collection of cu-
rated sentences, we found a significant number
of patterns with a very strong tendency to ap-
pear only in sentences in which a protein/gene
name is simultaneously present. This approach
is part of a larger effort to incorporate contex-
tual information so as to make biological infor-
mation less ambiguous.
1 Introduction
Molecular Biology and biomedical research cov-
ers a broad variety of research topics, connected
to the function of genes and proteins. The infor-
mation on the experimental characterization of
essential functional aspects of these genes and
proteins is manually extracted from primary sci-
entific publications by field-specific databases.
This process requires highly specialist person-
nel, and is costly and time-consuming. Indeed,
only a small number of genes and proteins have
been annotated with information directly re-
lated to experiments, whereas in the immense
majority of cases the annotations are trans-
ferred from other similar entries. The anno-
tations provided by the databases are a valu-
able source for large-scale analysis, but are in-
evitably incomplete at the level of detailed func-
tion and experimental results.
It is in the context of fast-growing biblio-
graphic information (over 12 million references
are collected in the PubMed database, with an
average of 500,000 new references added every
year) and annotation of the function of genes
and proteins that Text Mining and Information
Extraction systems become important tools
for biological research (Blaschke and Valencia,
2001).
Since the first papers were published in
this field in the late 90?s, it has become clear
that the detection of gene and protein names
(gene tagging) is a key first step towards Text
Mining systems becoming really useful.
The detection of names is particularly com-
plex in the domain of Molecular Biology, for a
number of reasons:
(1) Sociological, since names are perceived as
associated with the recognition of the groups
that first discovered them.
(2) As biologists tend not to adopt available
naming standards, often the disease related
to a gene disorder has the same name as the
gene itself (homonyms). This can be only be
addressed using context based sense disam-
biguation procedures.
(3) Gene names or symbols are often the same
as common English terms. For instance, many
D. melanogaster gene names, such as ?hedge-
hog?, lead to lexical ambiguity. (4) Symbols
and abbreviations are commonly used without
any control. This gives rise to the problems of
acronym disambiguation and expansion. There
is no high-quality gene acronym dictionary.
(5) Proteins are related by a process of evalua-
tion, which creates ontological associations that
36
are mixed with the various levels of knowledge
for different members of the protein families.
(6) The field itself is still evolving, and the
catalogue of genes even for the genomes already
sequenced, such as the Human one, is still
incomplete.
Our own assessment of the evolution of
gene names shows that names evolve over
time into a complex system with scale-free
behavior, with the presence of a few very
oft-quoted names (attractors) and many very
seldom quoted ones. The system itself is in a
critical state and the fate of current names is
unpredictable (Hoffmann and Valencia, 2003).
A significant number of applications have
been developed to identify gene names and sym-
bols in the biomedical literature (see (Tanabe
and Wilbur, 2002; Yu et al, 2002; Proux et al,
1998; Krauthammer et al, 2000) for four dif-
ferent methodological approaches). In order to
assess the performance of different approaches
the BioCreative challenge was carried out. The
recent BioCreative challenge showed that gene
and protein names can be detected by several
techniques, with a significant success that can
be as high as 80% for the best-performing sys-
tems (Blaschke et al in preparation; and special
issue of BMC Bioinformatics on the BioCreative
challenge cup, in preparation). However, detec-
tion of the remaining 20% of names is really im-
portant for many operations. Therefore, there
is significant room for improvement, and a clear
need for new approaches able to use alternative
sources of information.
We explore here a new avenue for the detec-
tion of gene and protein names by using con-
textual information, since in many cases gene
tagging requires knowledge of context (context-
based approach for disambiguation). We pre-
viously explored relevant information by cre-
ating context-based sentence sliding windows
for entity-relation extraction (Krallinger and
Padron, 2004).
We propose here to detect those sentences de-
scribing the function of genes and proteins in
the literature that are good candidates for con-
taining unambiguous information about corre-
sponding gene and protein names.
To detect these sentences, we relied on the
identification of typical expressions (patterns)
associated with the description of protein func-
tion in the literature. Context information in
the form of heuristically extracted sentence pat-
terns, known as frames, proved useful in the
past for deriving protein interactions automat-
ically (Blaschke et al, 1999; Blaschke and Va-
lencia, 2001) from protein co-occurrences.
The approach proposed here is based on the
extension of heuristically derived trigger words
(Riloff, 1993; Agichtein and Gravano, 2000) and
the filtering of patterns using previously gene-
indexed sentences. The extraction patterns ob-
tained were then ranked, using a validation set
of gene-indexed sentences and sentences lacking
the gene symbols. Precision-ranked extraction
patterns and indexing of sentences using those
patterns allowed ranking of these sentences ac-
cording to whether they contained relevant in-
formation for protein indexing and annotation.
2 Methods
In the case of complex domains, such as Molec-
ular Biology and Biomedicine, a prohibitively
large training set is generally required in order
to mine scientific literature. Often inter-domain
portable methods do not perform well enough.
Nevertheless, within relevant sentences contain-
ing protein or gene names, commonly used pat-
terns often describe or define relevant aspects of
those entities.
Figure 1: Flow chart of the main steps for constructing
the extraction pattern set.
Therefore, a list or dictionary of such ex-
traction patterns was developed, starting with
a small list of trigger words which, after sev-
37
eral processing and filtering steps, resulted in
a ranked list of protein-specific extraction pat-
terns (see Figure 1).
2.1 Set of trigger words
First, a domain expert manually analyzed gene-
indexed sentences to extract key words that
could trigger potential extraction patterns. The
expert used heuristics based on background
knowledge of the domain. These trigger words
(Riloff, 1993; Agichtein and Gravano, 2000)
constituted frequent word types which, in the
context of other word types (often prepositions
or articles), displayed a strong association with
the given gene or protein entity. Trigger words
thus made up a sort of concept node 1 by scan-
ning through gene-indexed sentences. Most of
these trigger words were in fact verbal phrases
(e.g. transitive verbs), which were often encoun-
tered in sentences defining or describing relevant
features of genes and gene products. There-
fore, only trigger words which helped describe
or define relevant aspects of the protein were ex-
tracted. These trigger words are also useful for
computerized annotation of extraction of pro-
teins. Among the trigger words were 507 verbs,
127 adjectives and 265 nouns.
2.2 Heuristic trigger word extension
The trigger words were then extended and com-
bined by the domain expert using context-
based heuristics to extract a seed set of ini-
tial extraction patterns and a set of regular
extraction expressions. An example (1) of
the heuristic trigger words used was ?encod-
ing?. Among the resulting expert-derived ex-
traction patterns were: ?, encoding a?, ?, encod-
ing the?, ?encoding a?,?encoding the?,?encoding
a <PROT>?,?gene , encoding? and ?protein, en-
coding?. Here <PROT> represents a previously
gene tagged word type.
2.3 Automatic extension of seed
extraction patterns
To extend the set of extraction patterns and to
expand the regular expressions to obtain defined
patterns, a rule-based system was used. Among
the extension rules for these seed patterns were
preposition substitutions, comma addition be-
fore verbs, article insertion before certain nouns
and pattern fusions. Some of the patterns gen-
erated were revised manually and inconsisten-
1Concept nodes are essentially case frames which are
triggered through a lexical item and its corresponding
linguistic context (Riloff, 1993)
cies were removed. Examples of the extraction
patterns based on the seed patterns provided in
example (1) were ?the gene encoding the? , ?, a
gene encoding?, ?, a gene encoding the?,?, gene
encoding a?,?, the gene encoding?,?, the gene en-
coding a?,?the gene encoding the?. Some of the
extensions did not correspond to natural lan-
guage and some were too long. Thus, in a sec-
ond step, those patterns not encountered in free
text, namely the initial set of gene-indexed sen-
tences, were removed.
Figure 2: Emprirical and random distribution of the
pattern to gene name average offsets.
2.4 Temporary extraction pattern
filtering.
The extended set of extraction patterns had to
be analyzed as to whether they really corre-
sponded to patterns encountered in sentences
in which gene and protein names or symbols
were found. Therefore we tagged, using exact
pattern matching, the temporary set of extrac-
tion patterns to a set of previously gene-indexed
sentences.
These sentences contained gene symbols of
the yeast S. cerevisiae provided by the SGD
database. A total of 36,543 sentences were gen-
erated with the use of a refined gene tagger. In
general, as yeast genes are easier to tag and on
the whole do not correspond to common En-
glish word types, they became a high-quality
gene-indexed data set for further analysis using
offset statistics.
A total of 769 patterns were matched to these
sentences and the rest of the patterns were dis-
38
carded. To determine whether those matched
patterns had a distance association to the gene
names, we calculated the empirical average off-
set of each pattern. The distances used for the
offset calculation were measured in word tokens.
Thus average empirical offset d?e was calcu-
lated by
d?e =
?n
i=1 di
n (1)
where n is the number of occurrences of the
given pattern in the gene indexed sentences and
di is the observed offset.
Taking into account the sentence length, the
individual pattern length and the gene posi-
tion within the pattern matching sentences also
a random offset was calculated for each pat-
tern occurrence and the average random offset
for each pattern, d?r was calculated (see Fig-
ure 2). In order to determine whether the aver-
age empirical distance of the patterns were sig-
nificantly different from the corresponding ran-
dom offsets, the distributions were further an-
alyzed. A chi-square test was applied to verify
that both, the empirical and the random offset
distributions were normally distributed. Then
we used the Kullback-Leibler divergence to mea-
sure how different the two probability distribu-
tions were :
D(p?q) =
?
i
pilog2(pi/qi) (2)
where p corresponds to the normal distribution
of the empirical average offset and q to the nor-
mal distribution of the random average offset.
In our case the distributions showed a large KL
divergence. This means that d?e is significantly
smaller when compared to d?r (i.e. the patterns
are closer to the gene names).
To be able to use the average offset differ-
ences of the patterns as a filtering criterion we
calculated the distribution of the differences ?i
between d?r and the corresponding d?e (see Fig-
ure 3). Only patterns with ?i > 0 passed the
selection filter.
2.5 Permanent extraction pattern
ranking.
After the filtering of the temporary extrac-
tion patterns using gene/protein indexed sen-
tences, it was important to determine the preci-
sion of the extraction patterns for gene-indexed
sentences, compared with sentences without
mentions of genes. Therefore, two validation
sets were constructed: one containing a set of
Figure 3: Difference between the average random and
average empirical offset. The extraction patterns which
did not pass the filtering step (difference > 0 are dis-
played in red. The remaining pattern set (blue) consti-
tuted the permanent pattern set which was used for the
f-score ranking.
Data set Total
Initial trigger words 899
Seed heuristic patterns 472,427
Extended heuristic patterns 525,408
Filtered heuristic patterns 53,185
Temporary patterns 769
Permanent patterns 655
Gene indexed sentences 36,543
Validation sentences (+)) 45,119
Validation sentences (-) 45,119
Table 1: Overview of the used dataset of pat-
terns and sentences.
gene indexed sentences using gene names con-
tained in the SwissProt database, and the other
consisting of the remaining sentences, without
those symbols. The sets were used to calculate
recall and precision:
R = TPTP + FN (3)
P = TPTP + FP (4)
The corresponding f-score is given by
F ? score = 1
? 1P + (1 ? ?) 1P
(5)
Where P is precision, R is recall and ?, which
consists in a weighting factor for precision and
39
recall, here ? = 0.5, were both precision and
recall had the same weight. Regarding the ob-
tained f-score or the precision we could rank the
permanent extraction patterns.
Figure 4: F-score plot for the extraction patterns in
the validation set: f-score for each pattern (numbered)
3 Results
The total number of initial patterns was
472,427, the extended version included more
than 525,408 patterns and the reduced filtered
final set included 655 patterns. Even though
these patterns clearly do not include all pos-
sible mentions of functions in texts, it is also
clear that they provide a good statistical base
(32,641 sentences detected in a corpus of 36,543
sentences) for screening the sentences to search
for protein names.
To assess the relationship between patterns
and names, we compared the frequency of the
patterns in two sets of sentences, one containing
and one not containing gene names. A highly
relevant number of patterns appears more fre-
quently in sentences containing names (324 of
the 518 patterns). A subset of these, 202, ap-
pears only in sentences where a gene or protein
name is present. This subset is an ideal candi-
date for enhancing the discriminative power of
gene/protein detection systems.
The permanent extraction patterns displayed
in general a very high precision (see Figure 5),
but the recall for an individual pattern was
relatively low. Nevertheless, most of the pat-
terns were matched to the validation sentences
(79.08%) and 13,799 sentences of the gene in-
dexed validation set had at least one pattern.
There were a total of 59.82% of high precision
patterns, i.e. with a precision greater then 0.8,
of which 64.86% had a precision of 1. Thus
the patterns are in general very specific for gene
containing sentences.
Figure 5: Precision plot for the extraction patterns in
the validation set: PRECISION for each pattern (num-
bered)
Patterns P R F-score
protein is required 1 5.73E-05 1.15E-04
was localized on 1 5.73E-05 1.15E-04
gene is essential for 1 1.15E-04 2.29E-04
located in the 0.93 3.26E-03 6.51E-03
Table 2: Sample of high precision patterns.
In table 2 some of the top scoring precision
patterns can be seen. Most of them contained
a verb as trigger word, in contrast to the lower
scoring precision patterns (table 3), which often
corresponded to patterns were the trigger word
corresponded to a noun.
Patterns P R F-score
the human 0.544 0.015 0.029
, acts as 0.5 5.72E-05 0.0001
is associated with 0.494 0.005 0.010
role for 0.463 0.003 0.006
Table 3: Sample of low precision patterns.
Moreover most of the high scoring patterns
had a difference between the random and the
empirical average offset greater then 8, while in
cases of low scoring precision if was mainly be-
40
low 2.5. Therefore, the use of offset calculation
as a filtering step to extract co-occurrences of
gene-indexed sentences is seen as promising.
For sample sentences of true pattern-matching
cases, see:
(a)Although generally involved with detoxi-
fication, overexpression of one family mem-
ber, cytochrome P450 1B1 (CYP1B1),
has been associated with human epithelial
tumors [PMID:12813131]
(b) For example, we have identified a novel
gene called mta1 (rat) or MTA1 (human)
that appears to be involved in mammary cell
motility and growth regulation [PMID:9891220]
(c) PEX13 protein has an SH3 docking site that
binds to the PTS-1 receptor [PMID:11405337]
(d) We have previously reported the identifica-
tion of human PEX13, the gene encoding the
docking factor for the PTS1 receptor, or PEX5
protein [PMID:9878256]
The above examples show correctly identi-
fied gene containing sentences using extraction
patterns. The extraction patterns are un-
derlined, while the relevant gene symbols are
displayed in bold.
After detailed analysis of the positive
matched patterns, we found that certain pat-
terns were more suited to annotating functional
implications of disease-related features of genes
or proteins (see example a). Other patterns
were more suited to extracting descriptions of
the participation of proteins in distinct biolog-
ical processes (example b). In addition, func-
tional descriptions and protein-protein interac-
tion information, useful for deriving functional
annotation data and protein definitions, were
associated with certain patterns (see c and d).
4 Conclusions
We have described here a new approach for the
identification of sentences containing informa-
tion relating to gene and protein names in bio-
logical literature. Our proposal is based on the
detection of sentences that contain information
relating to protein (or gene) function as an in-
dicator of the presence of protein/gene names.
To identify these sentences, we used a
pattern-based approach that encapsulates the
characteristic ways in which function is de-
scribed in text. To generate the set of pat-
terns describing functions, we started with an
initial set of manually derived patterns, which
was extended to cover a number of lexical varia-
tions. This larger set was filtered by matching of
the patterns using previously gene-indexed sen-
tences. The trigger word extension idea is based
on the proposal by (Riloff, 1993; Agichtein and
Gravano, 2000). Among the extraction patterns
with high precision, a significant number con-
tained verbs as trigger words. This corroborates
previous studies that used verbs to extract bio-
logical interactions (Hatzivassiloglou and Weng,
2002; Sekimizu et al, 1998).
We plan to analyze further the patterns used
in the study in order to explore the differen-
tial behavior of verb-containing patterns and
noun-containing patterns for protein annota-
tion extractions. The use of verbs to trigger
extraction patterns for biological interactions
have already been explored (Hatzivassiloglou
and Weng, 2002; Sekimizu et al, 1998), but
their use for protein indexing and annotation
extraction was not previously studied in detail.
The overall performance of extraction patterns
for interactions and for annotation extraction
seems to be similar.
Most of the extraction patterns used showed
no dependency on the organism that was the
source of the genes, with the exceptions of the
patterns containing the trigger words human,
yeast, mammalian and mouse. Therefore, the
majority of the extraction patterns could be
used for extraction of genes from a broad range
of organisms, and especially aid in disambigua-
tion of fly genes. As the extraction patterns
can be applied without prior gene indexing, they
could be used to enhance compound gene-name
indexing, to extract rare typographical variants
of existing gene names (not deposited in anno-
tation databases) or even to mine the literature
to discover new genes not yet described in cur-
rent annotation databases.
The main focus in extraction patterns was pre-
cision, which was attained through a pipeline of
filtering steps. The use of a larger set of ini-
tial trigger words might further increase recall
in some cases.
We also plan to explore the use of the infor-
mation of the patterns to improve the capac-
ity of our current entity recognition systems.
In particular, we would like to do this in the
context of our system for detecting associations
41
between proteins and their functions. In the
recent BioCreative challenge, it was clear that
our system could be substantially improved by
enhancing its name recognition capacity. This
could be done by incorporating the frames as
additional context information into the previ-
ously developed subset strategy (Krallinger and
Padron, 2004).
Finally, we also plan to compare extraction pat-
terns with automatically derived n-grams from
previously gene-indexed sentences, in order to
find which features are best suited for itera-
tive bootstrapping to create new extraction pat-
terns.
5 Acknowledgements
This research was sponsored by DOC, doctoral
scholarship of the Austrian Academy of Sciences
and the ORIEL (IST-2001-32688) and TEM-
BLOR (QLRT-2001-00015) projects. We are
grateful to R. Hoffmann for providing the fil-
tering set of gene-indexed sentences.
References
E. Agichtein and L. Gravano. 2000. Snowball:
Extracting relations from large plain-text col-
lections. Proc. 5th ACM International Con-
ference on Digital Libraries., pages 85?94.
C. Blaschke and A. Valencia. 2001. The poten-
tial use of SUISEKI as a protein interaction
discovery tool. Genome Inform Ser Work-
shop Genome Inform., 12:123?134.
C. Blaschke, A. Andrade, M, C. Ouzounis,
and A. Valencia. 1999. Automatic extrac-
tion of biological information from scientific
text: protein-protein interactions. Proc Int
Conf Intell Syst Mol Biol., pages 60?67.
V. Hatzivassiloglou and W. Weng. 2002. Learn-
ing anchor verbs for biological interaction
patterns from published text articles. Int J
Med Inf., 67:19?32.
R. Hoffmann and A. Valencia. 2003. Life cycles
of successful genes. Trends Genet, 19:79?81.
M. Krallinger and M. Padron. 2004. Prediction
of GO annotation by combining entity spe-
cific sentence sliding window profiles. Proc.
BioCreative Challenge Evaluation Workshop
2004.
M. Krauthammer, A. Rzhetsky, P. Morozov,
and C. Friedman. 2000. Using BLAST for
identifying gene and protein names in journal
articles. Gene, 259:245?252.
D. Proux, F. Rechenmann, L. Julliard, V.V. Pil-
let, and B. Jacq. 1998. Detecting Gene Sym-
bols and Names in Biological Texts: A First
Step toward Pertinent Information Extrac-
tion. Genome Inform Ser Workshop Genome
Inform, 9:72?80.
E. Riloff. 1993. Automatically Constructing a
Dictionary for Information Extraction Tasks.
Proceedings of the Eleventh National Confer-
ence on Artificial Intelligence., pages 811?
816.
T. Sekimizu, H.S. Park, and J. Tsujii. 1998.
Identifying the Interaction between Genes
and Gene Products Based on Frequently Seen
Verbs in Medline Abstracts. Genome Inform
Ser Workshop Genome Inform., 9:62?71.
L. Tanabe and W.J. Wilbur. 2002. Tagging
gene and protein names in biomedical text.
Bioinformatics, 18:1124?1132.
H. Yu, V. Hatzivassiloglou, C. Friedman,
A. Rzhetsky, and W.J. Wilbur. 2002. Au-
tomatic Extraction of Gene and Protein Syn-
onyms from MEDLINE and Journal Articles.
Proc AMIA Symp., pages 919?23.
42
Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 46?49,
Uppsala, July 2010.
Importance of negations and experimental qualifiers in biomedical
literature
Martin Krallinger
Struct. Biol. and Biocomp. Prog.
Spanish National Cancer Center, Madrid, Spain.
mkrallinger@cnio.es
Abstract
A general characteristic of most biomed-
ical disciplines is their primarily experi-
mental character. Discoveries are obtained
through molecular biology and biochemi-
cal techniques that allow understanding of
biological processes at the molecular level.
To qualify biological events, it is of practi-
cal significance to detect specific types of
negations that can imply either that a given
event is not observed under specific con-
ditions or even the opposite, that a given
event is true by altering the bio-entities
studied (e.g. introducing specific modifi-
cations like mutations). Of special interest
is also to determine if a detected assertion
is linked to experimental support provided
by the authors. Finding experimental qual-
ifier cues and detecting experimental tech-
nique mentions is of great interest to the
biological community in general and par-
ticularly for annotation databases. A short
overview of different types of negations
and biological qualifiers of practical rele-
vance will be provided.
1 Biological Annotations
In line with the rapid accumulation of biological
literature and the growing number of large-scale
experiments in biomedicine, it is becoming more
important to capture essential facts contained in
the literature and storing them in form of biolog-
ical annotations. Such annotations usually con-
sist in structured database records, where biologi-
cal entities of relevance, like genes or proteins are
associated to controlled vocabularies that are use-
ful to describe the most relevant aspects of these
entities (their function, localization, processes or
pathways they participate in or implications in dis-
eases). Also specific types of relations between
bio-entities (e.g. physical or regulatory interac-
tions) are manually extracted from the literature.
For biological interpretation and to determine the
reliability of annotations it is crucial to capture
both negative annotations, whether a given rela-
tion has been studied experimentally and does not
occur, as well as to determine the experimental
method used to study the bio-entity of interest. For
instance, the value of in vitro generated results, or
those obtained by large-scale experiments have a
different significance compared to those generated
in vivo. The most relevant biological annotations
contained in databases and constructed manually
by expert curators are linked to experimental qual-
ifiers. Such experimental qualifiers can range from
simple method terms to more sophisticated ontolo-
gies or hierarchical terminologies. Experimental
qualifiers used to annotate biological entities are
for instance provided by the Proteomics Standards
Initiative Molecular Interaction (PSI-MI) ontol-
ogy, (Orchard S, Kerrien S., 2010) the Evidence
Codes of Gene Ontology (GO) (Rogers MF, Ben-
Hur A, 2010) or the Open REGulatory ANNOta-
tion (ORegAnno) database Evidence Types.
2 Importance of Negations in
Biomedicine
There is an increasing interest to extract from
the literature negative associations. For instance,
one of the most popular biological annotation ef-
forts, Gene Ontology Annotation (GOA), also sup-
ports the annotation of
?
NOT
?
relations (associa-
tion.is not) to be able to represent these types of
relations in their annotation data. In GO, such re-
lations are labeled using
?
NOT
?
in the qualifier
column for a particular annotation. This negation
qualifier is applied to provide an explicit note that
the bio-entity is not associated with a given GO
term. This is important when a GO term might
otherwise be expected to apply to a bio-entity, but
an experiment proves otherwise. Negative asso-
46
ciations are also used when a cited reference ex-
plicitly states a negation event, e.g. in the form
of: bio-entity X is not found in the location Y. In
addition to annotation efforts there are a range of
scenarios where extraction of negative events are
of practical importance, these are described in the
following subsections.
2.1 Negations and Negative Controls
A common setting in experimental biology is to
use controls to avoid alternative explanations of
results and to minimize experimental artifacts.
Negative controls corroborate that the experimen-
tal outcome is not due to some sort of unrelated ef-
fect; it serves to minimize false positives and can
serve as a background observation. The underly-
ing assumption of negative controls is that one as-
sumes in advance that the result should be nega-
tive, i.e. no significant effect should be obtained.
Such negative controls are mainly expressed in the
literature using negations. For instance in case of
protein-protein interaction experiments, a negative
control could be to demonstrate that a signal is
only obtained when the two interactor proteins are
present, and not when the label (tag-protein) alone
is given to each interactor individually. To illus-
trate this aspect consider the example sentences
provided below:
? Our results show that, when AGG1 is present
in the matrix, it shows a strong ability to bind
35S-labeled AGB1, whereas GST alone is not
able to bind any detectable AGB1.
? GST alone did not interact with FKHR even
in the presence of E2 (Fig. 2B, lane 5), in-
dicating the specific interaction between ER
and FKHR.
? 35S-labeled in vitrotranslated FBXO11
bound to immobilized GST-p53 (lane 3) but
not GST alone (lane 2).
? PKC bound to GST-RINCK1 (lane 2) but not
to GST alone (lane 1), revealing that PKC
binds to RINCK directly.
In those example cases, GST (alone) would rep-
resent the negative control. Only in presence of the
interactor proteins a signal should be observed, if
GST alone is present the assumption is that no sig-
nal should be obtained. Negative controls are cru-
cial for interpretation of the actual experimental
outcome.
2.2 Negative associations in medical and
population genetics
A considerable effort is being made to detect genes
and mutations in genes that have implications in
the susceptibility of complex disorders. Naturally
occurring variations in the sequence of genes, of-
ten called polymorphisms might have a deleteri-
ous, protective or no associations at all to a patho-
logic condition. Not only to capture deleterious
and protective mutations, but also those that do not
have any effect is important to aid in the interpre-
tation of mutations observed in patients. This is
especially true taking into account the increasing
use of molecular screening technologies and per-
sonalized medicine in the clinical domain. Exam-
ple cases of negative associations between genes
and mutations to disease conditions derived from
PubMed abstracts can be seen below:
? CC16 gene may be not a susceptibility gene
of asthmatic patients of Han population in
southwest China.
? The FZD3 gene might not play a role in con-
ferring susceptibility to major psychosis in
our sample.
? Apolipoprotein E gene polymorphism is not
a strong risk factor for diabetic nephropa-
thy and retinopathy in Type I diabetes: case-
control study.
? In view of this evidence, it is likely that the
SIGMAR1 gene does not confer susceptibility
to schizophrenia.
? Thus, this SNP in the PGIS gene is not asso-
ciated with EH.
? The gene encoding GABBR1 is not associ-
ated with childhood absence epilepsy in the
Chinese Han population.
? We did not find an association between OCD,
family history for OCD, and the COMT gene
polymorphism.
Such negative associations can be useful for
the interpretation of relevance of genes for certain
conditions, enabling filtering un-relevant genes
and improving target selection for more detailed
molecular examinations.
47
2.3 Toxicology and negations
A simplified view of toxicology experiments is
to distinguish, given the administration of differ-
ent amounts of a specific compound or drug (e.g.
low, medium and high dosage) during predefined
time spans, between toxic and non-toxic effects.
Such effects can be examined in animal models
like rats or mini-pigs by examining a series of
aspects, such as hematological parameters, organ
histological properties (tissue alterations and size
of organs), biochemical parameters, and changes
in food/water consumption or fertility. Usually an-
imals to which specific amounts of the compound
has been administered are compared to control
cases. Here it is important to determine also three
kinds of negative associations: (1) under which
conditions a given parameter or tissue has not been
negatively affected (save dosage, non-toxic), (2)
which compound did not show the desired bene-
ficial effect (e.g. was not effective in treating the
pathologic condition) and (3) under which admin-
istration conditions a compound was not save. Ex-
ample sentences illustrating these negative associ-
ations are:
? Morphological evaluation showed that 1-BP
did not cause morphological changes in sem-
iniferous epithelium, but 2-BP treatment re-
sulted in the disappearance of spermatogo-
nia, atrophy of the seminiferous tubules and
degeneration of germ cells..
? This is an indication that the extracts may not
be completely safe in male rats when contin-
uously administered for 14days.
? Histopathologic analysis of the vital organs
revealed no significant lesions in the brain,
liver, kidney, heart, spleen, ovary, and testis.
? The extract did not produce any significant
(P>0.05) changes in the mean concentra-
tions of urea, creatinine, Na+, K+, and Cl-
ions of rats in the extract treated groups com-
pared to that of control.
2.4 Experimentally altered bio-entities and
negations
In order to characterize certain biological associa-
tions, it is a common practice to alter the bio-entity
of interest, with the assumption that a given ob-
servation should change upon alteration. This is
the case of mutations or deletions experimentally
introduced to gene or protein sequences, with the
underlying assumption that the mutated or trun-
cated protein/gene should loose it ability to bind
or regulate another bio-entity, or even be non-
functional. Such mutations are useful to pin down
the actual biologically relevant functional parts of
bio-entities, which are usually of great therapeutic
importance (as target sites to inhibit certain bio-
entities or interactions). Such cases can be seen in
the example sentences provided below:
? Accordingly, this p73 N-terminal deletion
was unable to activate transcription or to in-
duce apoptosis.
? The G62D mutant did not bind AMP at all.
? The resulting mutant SOS3 protein was not
able to interact with the SOS2 protein kinase
and was less capable of activating it.
? MYB4 did not localize to the nucleus in the
sad2 mutant, suggesting that SAD2 is re-
quired for MYB4 nuclear trafficking.
In these example cases, altered bio-entities did not
display the biological function of their wild type
(unaltered) counterparts.
3 Experimental qualifiers
Biological annotation efforts are primarily con-
cerned about experimentally confirmed events.
Despite the importance of experimental qualifiers,
only limited effort has been made to construct
comprehensive resources to retrieve assertions that
have experimental support and to construct useful
lexical resources and thesauri of experimental evi-
dence techniques. To detect novel protein interac-
tions that have been experimentally characterized
in the biomedical literature was one of the tasks
posed in the BioCreative challenge, a community
effort to assess text-mining tools developed for the
biomedical domain (Krallinger M, et al 2008).
Also some systems to detect technical term men-
tions have been developed such as Termine. A
range of recurrent cues relevant for experimental
qualifiers can be observed in the literature, some
of the most relevant ones are summarized in the
table 1.
Using such experimental evidence cues together
with linguistic patterns and NLP techniques it is
feasible to determine whether a given event de-
scribed in the literature has some sort of experi-
48
Cue Pattern PMID
reveal METHOD revealed that EVENT 12506203
show METHOD showed that EVENT 17189287
demonstrate METHOD demonstrated that EVENT 18466309
study EVENT was studied by METHOD 15147239
identify EVENT identified in METHOD 10905349
prove EVENT proved by METHOD 16354655
analyze EVENT analyzed by METHOD 9477575
determine EVENT determined by METHOD 12006647
confirm EVENT confirmed using METHOD 10788494
obtain EVENT obtained by METHOD 16582012
support EVENT supported by METHOD 18156215
corroborate EVENT corroborated using METHOD 15757661
validate EVENT validated by METHOD 17287294
verify EVENT verified by METHOD 18296724
detect EVENT detected with METHOD 14581623
discover EVENT discovered by METHOD 11251078
observe EVENT observed using METHOD 16778013
test EVENTwas tested using METHOD 14646219
Table 1: Experimental evidence cue terms.
mental qualifier associated to it. The simplest pat-
terns of this sort would be for instance:
? METHOD cue (a|that|novel|the|this)
? METHOD cue that
? as cue by METHOD
? was cue by METHOD
? cue (in|by|here by|using|via|with) METHOD
Applying such patterns can be useful to con-
struct automatically an experimental technique
dictionary that can be handcrafted to enrich ex-
isting evidential qualifier resources. Nevertheless,
linking automatically extracted experiment terms
to controlled vocabularies used for annotation in
biology is still a challenging task that need more
manually labeled textual data. Some example sen-
tences illustrating the usefulness of experimental
evidence cues can be seen below:
? Gel-shift and co-immunoprecipitation assays
have revealed that GT-1 can interact with and
stabilize the TFIIA-TBP-TATA complex.
? By yeast two-hybrid assays, we demonstrate
an interaction of APC2 with two other APC/C
subunits.
? The specificity of interaction of VIRP1 with
viroid RNA was studied by different method-
ologies, which included Northwestern blot-
ting, plaque lift, and electrophoretic mobility
shift assays.
? A complex containing Mus81p and Rad54p
was identified in immunoprecipitation exper-
iments.
? In addition, we proved by affinity chromatog-
raphy that NaTrxh specifically interacts with
S-RNase.
Acknowledgments
I would like to thank Yasmin Alam-Farugue (GOA
team at EBI) for useful information on the anno-
tation of negative associations in GOA and Roser
Morante for important feedback and suggestions
on this topic.
References
MF. Rogers and A. Ben-Hur. 2010. The use of gene
ontology evidence codes in preventing classifier as-
sessment bias., Bioinformatics, 25(9):1173-1177.
M. Krallinger and F. Leitner and C. Rodriguez-Penagos
and A. Valencia 2008. Overview of the protein-
protein interaction annotation extraction task of
BioCreative II., Genome Biol., Suppl 2:S1.
S. Orchard and S. Kerrien 2010. Molecular interac-
tions and data standardisation., Methods Mol Biol.,
604:309-318
49
