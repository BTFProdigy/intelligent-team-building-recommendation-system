Proceedings of NAACL HLT 2009: Short Papers, pages 181?184,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Improving SCL Model for Sentiment-Transfer Learning 
 
Songbo Tan 
Institute of Computing Technology 
Beijing, China 
tansongbo@software.ict.ac.cn
Xueqi Cheng 
Institute of Computing Technology 
Beijing, China 
cxq@ict.ac.cn 
 
ABSTRACT 
In recent years, Structural Correspondence 
Learning (SCL) is becoming one of the most 
promising techniques for sentiment-transfer 
learning. However, SCL model treats each 
feature as well as each instance by an 
equivalent-weight strategy. To address the two 
issues effectively, we proposed a weighted 
SCL model (W-SCL), which weights the 
features as well as the instances. More 
specifically, W-SCL assigns a smaller weight 
to high-frequency domain-specific (HFDS) 
features and assigns a larger weight to 
instances with the same label as the involved 
pivot feature. The experimental results 
indicate that proposed W-SCL model could 
overcome the adverse influence of HFDS 
features, and leverage knowledge from labels 
of instances and pivot features. 
 
1   Introduction 
In the community of sentiment analysis (Turney 
2002; Pang et al, 2002; Tang et al, 2009), 
transferring a sentiment classifier from one source 
domain to another target domain is still far from a 
trivial work, because sentiment expression often 
behaves with strong domain-specific nature.  
Up to this time, many researchers have 
proposed techniques to address this problem, such 
as classifiers adaptation, generalizable features 
detection and so on (DaumeIII et al, 2006; Jiang 
et al, 2007; Tan et al, 2007; Tan et al, 2008; Tan 
et al, 2009). Among these techniques, SCL 
(Structural Correspondence Learning) (Blitzer et 
al., 2006) is regarded as a promising method to 
tackle transfer-learning problem. The main idea 
behind SCL model is to identify correspondences 
among features from different domains by 
modeling their correlations with pivot features (or 
generalizable features). Pivot features behave 
similarly in both domains. If non-pivot features 
from different domains are correlated with many 
of the same pivot features, then we assume them 
to be corresponded with each other, and treat them 
similarly when training a sentiment classifier. 
However, SCL model treats each feature as well 
as each instance by an equivalent-weight strategy. 
From the perspective of feature, this strategy fails 
to overcome the adverse influence of high-
frequency domain-specific (HFDS) features. For 
example, the words ?stock? or ?market? occurs 
frequently in most of stock reviews, so these non-
sentiment features tend to have a strong 
correspondence with pivot features. As a result, 
the representative ability of the other sentiment 
features will inevitably be weakened to some 
degree.  
To address this issue, we proposed Frequently 
Exclusively-occurring Entropy (FEE) to pick out 
HFDS features, and proposed a feature-weighted 
SCL model (FW-SCL) to adjust the influence of 
HFDS features in building correspondence. The 
main idea of FW-SCL is to assign a smaller 
weight to HFDS features so that the adverse 
influence of HFDS features can be decreased. 
From the other perspective, the equivalent-
weight strategy of SCL model ignores the labels 
(?positive? or ?negative?) of labeled instances. 
Obviously, this is not a good idea. In fact, positive 
pivot features tend to occur in positive instances, 
so the correlations built on positive instances are 
more reliable than that built on negative instances; 
and vice versa. Consequently, utilization of labels 
of instances and pivot features can decrease the 
adverse influence of some co-occurrences, such as 
co-occurrences involved with positive pivot 
features and negative instances, or involved with 
negative pivot features and positive instances.  
In order to take into account the labels of 
labeled instances, we proposed an instance-
weighted SCL model (IW-SCL), which assigns a 
larger weight to instances with the same label as 
the involved pivot feature. In this time, we obtain 
a combined model: feature-weighted and instance-
weighted SCL model (FWIW-SCL). For the sake 
181
of convenience, we simplify ?FWIW-SCL? as 
?W-SCL? in the rest of this paper. 
2   Structural Correspondence Learning 
In the section, we provide the detailed procedures 
for SCL model. 
First we need to pick out pivot features. Pivot 
features occur frequently in both the source and 
the target domain. In the community of sentiment 
analysis, generalizable sentiment words are good 
candidates for pivot features, such as ?good? and 
?excellent?. In the rest of this paper, we use K to 
stand for the number of pivot features.  
Second, we need to compute the pivot 
predictors (or mapping vectors) using selected 
pivot features. The pivot predictors are the key job, 
because they directly decide the performance of 
SCL. For each pivot feature k, we use a loss 
function Lk, ( ) 21)( wxwxpL
i i
T
ikk ?+?=?        (1) 
where the function pk(xi) indicates whether the 
pivot feature k occurs in the instance xi, 
otherwise
xif
xp ikik
0 
1
1
)(
>
??
?
?= , 
where the weight vector w encodes the 
correspondence of the non-pivot features with the 
pivot feature k (Blitzer et al, 2006). 
Finally we use the augmented space [xT, xTW]T to 
train the classifier on the source labeled data and 
predict the examples on the target domain, where 
W=[w1,w2, ?, wK].  
3   Feature-Weighted SCL Model 
3.1 Measure to pick out HFDS features 
In order to pick out HFDS features, we proposed 
Frequently Exclusively-occurring Entropy (FEE). 
Our measure includes two criteria: occur in one 
domain as frequently as possible, while occur on 
another domain as rarely as possible. To satisfy 
this requirement, we proposed the following 
formula: 
( )( ) ( )( ) ???
?
???
?+=
)(),(min
)(),(max
log)(),(maxlog
wPwP
wPwP
wPwPf
no
no
now
(2) 
where Po(w) and Pn(w) indicate the probability of 
word w in the source domain and the target 
domain respectively: 
 ( )( )?
?
?+
+=
2
)(
)(
o
o
o N
wN
wP                     (3) 
( )
( )?
?
?+
+=
2
)(
)(
n
n
n N
wN
wP                     (4) 
where No(w) and Nn(w) is the number of examples 
with word w in the source domain and the target 
domain respectively; No and Nn is the number of 
examples in the source domain and the target 
domain respectively. In order to overcome 
overflow, we set ?=0.0001 in our experiment 
reported in section 5. 
To better understand this measure, let?s take a 
simple example (see Table 1). Given a source 
dataset with 1000 documents and a target dataset 
with 1000 documents, 12 candidate features, and a 
task to pick out 2 HFDS features. According to 
our understanding, the best choice is to pick out 
w4 and w8.  According to formula (2), fortunately, 
we successfully pick out w4, and w8. This simple 
example validates the effectiveness of proposed 
FEE formula. 
Table 1: A simple example for FEE 
FEE 
Words No(w) Nn(w) Score Rank
w1 100 100 -2.3025 6 
w2 100 90 -2.1971 4 
w3 100 45 -1.5040 3 
w4 100 4 0.9163 1 
w5 50 50 -2.9956 8 
w6 50 45 -2.8903 7 
w7 50 23 -2.2192 5 
w8 50 2 0.2231 2 
w9 4 4 -5.5214 11 
w10 4 3 -5.2337 10 
w11 4 2 -4.8283 9 
w12 1 1 -6.9077 12 
3.2 Feature-Weighted SCL model 
To adjust the influence of HFDS features in 
building correspondence, we proposed feature-
weighted SCL model (FW-SCL), ( ) 21)( wxwxpL
i ill llikk
?? +?=? ?    (5) 
where the function pk(xi) indicates whether the 
pivot feature k occurs in the instance xi; 
otherwise
xif
xp ikik
0 
1
1
)(
>
??
?
?= , 
and ?l is the parameter to control the weight of the 
HFDS feature l, 
182
 otherwise
Zlif HFDS
l
?
??
?=   
1
??  
where ZHFDS indicates the HFDS feature set and ? 
is located in the range [0,1]. When ??=0?, it 
indicates that no HFDS features are used to build 
the correspondence vectors; while ??=1? indicates 
that all features are equally used to build the 
correspondence vectors, that is to say, proposed 
FW-SCL algorithm is simplified as traditional 
SCL algorithm. Consequently, proposed FW-SCL 
algorithm could be regarded as a generalized 
version of traditional SCL algorithm. 
4 Instance-Weighted SCL Model 
The traditional SCL model does not take into 
account the labels (?positive? or ?negative?) of 
instances on the source domain and pivot features. 
Although the labels of pivot features are not given 
at first, it is very easy to obtain these labels 
because the number of pivot features is typically 
very small. 
Obviously, positive pivot features tend to occur 
in positive instances, so the correlations built on 
positive instances are more reliable than the 
correlations built on negative instances; and vice 
versa. As a result, the ideal choice is to assign a 
larger weight to the instances with the same label 
as the involved pivot feature, while assign a 
smaller weight to the instances with the different 
label as the involved pivot feature. This strategy 
can make correlations more reliable. This is the 
key idea of instance-weighted SCL model (IW-
SCL). Combining the idea of feature-weighted 
SCL model (FW-SCL), we obtain the feature-
weighted and instance-weighted SCL model 
(FWIW-SCL), 
( )( ) ( )( )
( ) ( )( )( ) ( )( )? ?
? ?
????
++??=
1),(11
1),(
2
jll lljkj
ill llikik
xwxpxk
wxwxpxkL
?????
??????
(6) 
where ? is the instance weight and the function 
pk(xi) indicates whether the pivot feature k occurs 
in the instance xi; 
otherwise
xif
xp ikik
0 
1
1
)(
>
??
?
?=  
and ?l is the parameter to control the weight of the 
HFDS feature l, 
 otherwise
Zlif HFDS
l
?
??
?=   
1
?? , 
where ZHFDS indicates the HFDS feature set and ? 
is located in the range [0,1]. 
In equation (6), the function ?(z,y) indicates 
whether the two variables z and y have the same 
non-zero value, 
( )
otherwise
0y and zzif
z,y
?=
??
?=   
0
1? ; 
and the function ?(z) is a hinge function, whose 
variables are either pivot features or instances, 
labelnegativez has aif
unknown
labelpositivez has aif
z
      
      
1
0
1
)(
??
??
?
?
=? . 
For the sake of convenience, we simplify 
?FWIW-SCL? as ?W-SCL?.  
5   Experimental Results 
5.1 Datasets 
We collected three Chinese domain-specific 
datasets: Education Reviews (Edu, from 
http://blog.sohu.com/learning/), Stock Reviews (Sto, 
from http://blog.sohu.com/stock/) and Computer 
Reviews (Comp, from http://detail.zol.com.cn/). All of 
these datasets are annotated by three linguists. We 
use ICTCLAS (a Chinese text POS tool, 
http://ictclas.org/) to parse Chinese words. 
The dataset Edu includes 1,012 negative 
reviews and 254 positive reviews. The average 
size of reviews is about 600 words. The dataset 
Sto consists of 683 negative reviews and 364 
positive reviews. The average length of reviews is 
about 460 terms. The dataset Comp contains 390 
negative reviews and 544 positive reviews. The 
average length of reviews is about 120 words. 
5.2 Comparison Methods 
In our experiments, we run one supervised 
baseline, i.e., Na?ve Bayes (NB), which only uses 
one source-domain labeled data as training data. 
For transfer-learning baseline, we implement 
traditional SCL model (T-SCL) (Blitzer et al, 
2006). Like TSVM, it makes use of the source-
domain labeled data as well as the target-domain 
unlabeled data. 
5.3 Does proposed method work? 
To conduct our experiments, we use source-
domain data as unlabeled set or labeled training 
set, and use target-domain data as unlabeled set or 
testing set. Note that we use 100 manual-
annotated pivot features for T-SCL, FW-SCL and 
W-SCL in the following experiments. We select 
183
pivot features use three criteria: a) is a sentiment 
word; b) occurs frequently in both domains; c) has 
similar occurring probability. For T-SCL, FW-
SCL and W-SCL, we use prototype classifier 
(Sebastiani, 2002) to train the final model. 
Table 2 shows the results of experiments 
comparing proposed method with supervised 
learning, transductive learning and T-SCL. For 
FW-SCL, the ZHFDS is set to 200 and ? is set to 0.1; 
For W-SCL, the ZHFDS is set to 200, ? is set to 0.1, 
and ? is set to 0.9. 
As expected, proposed method FW-SCL does 
indeed provide much better performance than 
supervised baselines, TSVM and T-SCL model. 
For example, the average accuracy of FW-SCL 
beats supervised baselines by about 12 percents, 
beats TSVM by about 11 percents and beats T-
SCL by about 10 percents. This result indicates 
that proposed FW-SCL model could overcome the 
shortcomings of HFDS features in building 
correspondence vectors. 
More surprisingly, instance-weighting strategy 
can further boost the performance of FW-SCL by 
about 4 percents. This result indicates that the 
labels of instances and pivot features are very 
useful in building the correlation vectors. This 
result also verifies our analysis in section 4: 
positive pivot features tend to occur in positive 
instances, so the correlations built on positive 
instances are more reliable than the correlations 
built on negative instances, and vice versa. 
Table 2: Accuracy of different methods 
 NB T-SCL FW-SCL W-SCL 
Edu->Sto 0.6704 0.7965 0.7917 0.8108
Edu->Comp 0.5085 0.8019 0.8993 0.9025
Sto->Edu 0.6824 0.7712 0.9072 0.9368
Sto->Comp 0.5053 0.8126 0.8126 0.8693
Comp->Sto 0.6580 0.6523 0.7010 0.7717
Comp->Edu 0.6114 0.5976 0.9112 0.9408
Average 0.6060 0.7387 0.8372 0.8720
Although SCL is a method designed for transfer 
learning, but it cannot provide better performance 
than TSVM. This result verifies the analysis in 
section 3: a small amount of HFDS features 
occupy a large amount of weight in classification 
model, but hardly carry corresponding sentiment. 
In another word, very few top-frequency words 
degrade the representative ability of SCL model 
for sentiment classification. 
6 Conclusion Remarks 
In this paper, we proposed a weighted SCL 
model (W-SCL) for domain adaptation in the 
context of sentiment analysis. On six domain-
transfer tasks, W-SCL consistently produces much 
better performance than the supervised, semi-
supervised and transfer-learning baselines. As a 
result, we can say that proposed W-SCL model 
offers a better choice for sentiment-analysis 
applications that require high-precision 
classification but hardly have any labeled training 
data.  
7 Acknowledgments 
This work was mainly supported by two funds, 
i.e., 0704021000 and 60803085, and one another 
project, i.e., 2004CB318109. 
References 
Blitzer, J. and McDonald, R. and Fernando Pereira. 
Domain adaptation with structural correspondence 
learning. EMNLP 2006. 
DaumeIII, H. and Marcu, D. Domain adaptation for 
statistical classifiers. Journal of Artificial 
Intelligence Research, 2006, 26: 101-126. 
Jiang, J., Zhai, C. A Two-Stage Approach to Domain 
Adaptation for Statistical Classifiers. CIKM 2007. 
Pang, B., Lee, L. and Vaithyanathan, S. Thumbs up? 
Sentiment classification using machine learning 
techniques. EMNLP 2002. 
Sebastiani, F. Machine learning in automated text 
categorization. ACM Computing Surveys. 2002, 
34(1): 1-47. 
S. Tan, G. Wu, H. Tang and X. Cheng. A novel 
scheme for domain-transfer problem in the context 
of sentiment analysis. CIKM 2007. 
S. Tan, Y. Wang, G. Wu and X. Cheng. Using 
unlabeled data to handle domain-transfer problem of 
semantic detection. SAC 2008. 
S. Tan, X. Cheng, Y. Wang and H. Xu. Adapting 
Naive Bayes to Domain Adaptation for Sentiment 
Analysis. ECIR 2009. 
H. Tang, S. Tan, and X. Cheng. A Survey on 
Sentiment Detection of Reviews. Expert Systems 
with Applications. Elsevier. 2009, 
doi:10.1016/j.eswa.2009.02.063. 
Turney, P. D. Thumbs Up or Thumbs Down? Semantic 
Orientation Applied to Unsupervised Classification 
of Reviews. ACL 2002. 
 
184
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 317?320,
Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLP
Graph Ranking for Sentiment Transfer 
 
Qiong Wu1,2, Songbo Tan1 and Xueqi Cheng1 
1Institute of Computing Technology, Chinese Academy of Sciences, China 
2 Graduate University of Chinese Academy of Sciences, China 
{wuqiong,tansongbo}@software.ict.ac.cn, cxq@ict.ac.cn 
 
Abstract 
With the aim to deal with sentiment-transfer 
problem, we proposed a novel approach, 
which integrates the sentiment orientations of 
documents into the graph-ranking algorithm. 
We apply the graph-ranking algorithm using 
the accurate labels of old-domain documents 
as well as the ?pseudo? labels of new-domain 
documents. Experimental results show that 
proposed algorithm could improve the per-
formance of baseline methods dramatically for 
sentiment transfer. 
1 Introduction 
With the rapid growth of reviewing pages, sen-
timent classification is drawing more and more 
attention (Bai et al, 2005; Pang and Lee, 2008). 
Generally speaking, sentiment classification can 
be considered as a special kind of traditional text 
classification (Tan et al, 2005; Tan, 2006). In 
most cases, supervised learning methods can per-
form well (Pang et al, 2002). But when training 
data and test data are drawn from different do-
mains, supervised learning methods always pro-
duce disappointing results. This is so-called 
cross-domain sentiment classification problem 
(or sentiment-transfer problem). 
Sentiment transfer is a new study field. In re-
cent years, only a few works are conducted on 
this field. They are generally divided into two 
categories. The first one needs a small amount of 
labeled training data for the new domain (Aue 
and Gamon, 2005). The second one needs no 
labeled data for the new domain (Blitzer et al, 
2007; Tan et al, 2007; Andreevskaia and Bergler, 
2008; Tan et al, 2008; Tan et al, 2009). In this 
paper, we concentrate on the second category 
which proves to be used more widely. 
Graph-ranking algorithm has been success-
fully used in many fields (Wan et al, 2006; Esuli 
and Sebastiani, 2007), whose idea is to give a 
node high score if it is strongly linked with other 
high-score nodes. In this work, we extend the 
graph-ranking algorithm for sentiment transfer 
by integrating the sentiment orientations of the 
documents, which could be considered as a sen-
timent-transfer version of the graph-ranking al-
gorithm. In this algorithm, we assign a score for 
every unlabelled document to denote its extent to 
?negative? or ?positive?, then we iteratively cal-
culate the score by making use of the accurate 
labels of old-domain data as well as the ?pseudo? 
labels of new-domain data, and the final score 
for sentiment classification is achieved when the 
algorithm converges, so we can label the new-
domain data based on these scores. 
2 The Proposed Approach 
2.1 Overview 
In this paper, we have two document sets: the 
test data DU = {d1,?,dn} where di is the term 
vector of the ith text document and each di?DU(i 
= 1,?,n) is unlabeled; the training data DL = 
{dn+1,?dn+m} where dj represents the term vector 
of the jth text document and each dj?DL(j = 
n+1,?,n+m) should have a label from a category 
set C = {negative, positive}. We assume the 
training dataset DL is from the related but differ-
ent domain with the test dataset DU. Our objec-
tive is to maximize the accuracy of assigning a 
label in C to di?DU (i = 1,?,n) utilizing the 
training data DL in another domain. 
The proposed algorithm is based on the fol-
lowing presumptions: 
   (1) Let WL denote the word space of old do-
main, WU denote the word space of new domain. 
WL?WU??. 
   (2) The labels of documents appear both in the 
training data and the test data should be the same.  
Based on graph-ranking algorithm, it is 
thought that if a document is strongly linked with 
positive (negative) documents, it is probably 
positive (negative). And this is the basic idea of 
learning from a document?s neighbors. 
Our algorithm integrates the sentiment orienta-
tions of the documents into the graph-ranking 
algorithm. In our algorithm, we build a graph 
317
whose nodes denote documents and edges denote 
the content similarities between documents. We 
initialize every document a score (?1? denotes 
positive, and ?-1? denotes negative) to represent 
its degree of sentiment orientation, and we call it 
sentiment score. The proposed algorithm calcu-
lates the sentiment score of every unlabelled 
document by learning from its neighbors in both 
old domain and new domain, and then iteratively 
calculates the scores with a unified formula. Fi-
nally, the algorithm converges and each docu-
ment gets its sentiment score. When its sentiment 
score falls in the range [0, 1] (or [-1, 0]], the 
document should be classified as ?positive (or 
negative)?. The closer its sentiment score is near 
1 (or -1), the higher the ?positive (or negative)? 
degree is.  
2.2 Score Documents  
Score Documents Using Old-domain Informa-
tion 
We build a graph whose nodes denote documents 
in both DL and DU and edges denote the content 
similarities between documents. If the content 
similarity between two documents is 0, there is 
no edge between the two nodes. Otherwise, there 
is an edge between the two nodes whose weight 
is the content similarity. The content similarity 
between two documents is computed with the 
cosine measure. We use an adjacency matrix U 
to denote the similarity matrix between DU and 
DL. U=[Uij]nxm is defined as follows: 
mnnjni
dd
dd
U
ji
ji
ij ++==?
?= ,...,1,,...,1,    (1) 
The weight associated with term t is computed 
with tftidft where tft is the frequency of term t in 
the document and idft is the inverse document 
frequency of term t, i.e. 1+log(N/nt), where N is 
the total number of documents and nt is the num-
ber of documents containing term t in a data set.   
In consideration of convergence, we normal-
ize U to U? by making the sum of each row equal 
to 1: 
1 1
, 0?
0,
m m
ij ij ij
j jij
U U if U
U
otherwise
= =
? ??= ???
? ?
        (2) 
In order to find the neighbors (in another word, 
the nearest documents) of a document, we sort 
every row of U?  to U% in descending order. That is: 
U% ij? U% ik (i = 1,?n; j,k = 1,?m; k?j). 
Then for di?DU (i = 1,?,n), U% ij (j = 1,?,K ) 
corresponds to K neighbors in DL. So we can get 
its K neighbors. We use a matrix [ ]ij n KN N ?=  
to denote the neighbors of DU in old domain, 
with Nij corresponding to the jth nearest neighbor 
of di. 
At last, we can calculate sentiment score si (i 
= 1,?,n) using the scores of the di?s neighbors as 
follows: 
nisUs
i
j
Nj
k
ij
k
i ,...,1,)?(
)1()( =?= ?
??
?        (3) 
where ?i means the ith row of a matrix and 
)(k
is denotes the is at the k
th iteration. 
Score Documents Using New-domain Infor-
mation 
Similarly, a graph is built, in which each node 
corresponds to a document in DU and the weight 
of the edge between any different documents is 
computed by the cosine measure. We use an ad-
jacency matrix V=[Vij]nxn to describe the similar-
ity matrix. And V is similarly normalized to V? to 
make the sum of each row equal to 1. Then we 
sort every row of V?  to V% in descending order, 
thus we can get K neighbors of di?DU (i = 
1,?,n) from V% ij (j = 1,?K), and we use a matrix 
[ ]ij n KM M ?=  to denote the neighbors of DU in 
the new domain. Finally, we can calculate si us-
ing the sentiment scores of the di?s neighbors as 
follows: 
?
??
? =?=
i
ji
Mj
k
ij
k nisVs ,...,1),?( )1()(          (4) 
2.3 Sentiment Transfer Algorithm 
Initialization 
Firstly, we classify the test data DU to get their 
initial labels using a traditional classifier. For 
simplicity, we use prototype classification algo-
rithm (Tan et al, 2005) in this work. 
Then, we give ?-1? to si(0) if di?s label is 
?negative?, and ?1? if ?positive?. So we obtain 
the initial sentiment score vector S(0) for both 
domain data. 
At last, si(0) (i = 1,?,n) is normalized as fol-
lows to make the sum of positive scores of DU 
equal to 1, and the sum of negative scores of DU 
equal to -1: 
ni
sifss
sifss
s
i
Dj
ji
i
Dj
ji
U
pos
U
neg
i
,...,1
0,
0,)(
)0()0()0(
)0()0()0(
)0( =
???
???
?
>
<?
= ?
?
?
?   (5) 
318
where U
negD and
U
posD denote the negative and 
positive document set of DU respectively. The 
same as (5), sj (0) (j =n+1,?,n+m) is normalized. 
Algorithm Introduction 
In our algorithm, we label DU by making use of 
information of both old domain and new domain. 
We fuse equations (3) and (4), and get the itera-
tive equation as follows: 
nisVsUs
i
h
i
ji
Mh
k
ih
Nj
k
ij
k ,...,1,)?()?( )1()1()( =?+?= ??
?? ?
?
?
? ?? (6) 
where 1? ?+ = , and ? and? show the relative 
importance of old domain and new domain to the 
final sentiment scores. In consideration of the 
convergence, S(k) (S at the kth iteration) is normal-
ized after each iteration. 
Here is the complete algorithm: 
1. Classify DU with a traditional classifier. 
Initialize the sentiment score si of di?DU
?DL (i = 1,?n+m) and normalize it. 
2. Iteratively calculate the S(k) of DU and 
normalize it until it achieves the conver-
gence: 
nisVsUs
i
h
i
ji
Mh
k
ih
Nj
k
ij
k ,...,1,)?()?( )1()1()( =?+?= ??
?? ?
?
?
? ??
ni
sifss
sifss
s
k
i
Dj
k
j
k
i
k
i
Dj
k
j
k
i
k
i
U
pos
U
neg ,...,1
0,
0,)(
)()()(
)()()(
)( =
???
???
?
>
<?
= ?
?
?
?
 
3. According to si? S (i = 1,?,n), assign 
each di?DU (i = 1,?n) a label. If si is be-
tween -1 and 0, assign di the label ?nega-
tive?; if si is between 0 and 1, assign di the 
label ?positive?. 
3 EXPERIMENTS 
3.1 Data Preparation 
We prepare three Chinese domain-specific data 
sets from on-line reviews, which are: Electronics 
Reviews (Elec, from http://detail.zol.com.cn/), 
Stock Reviews (Stock, from http://blog.sohu.com 
/stock/) and Hotel Reviews (Hotel, from  
http://www.ctrip.com/). And then we manually 
label the reviews as ?negative? or ?positive?. 
The detailed composition of the data sets are 
shown in Table 1, which shows the name of the 
data set (DataSet), the number of negative re-
views (Neg), the number of positive reviews 
(Pos), the average length of reviews (Length), 
the number of different words (Vocabulary) in 
this data set. 
DataSet Neg Pos Length Vocabulary
Elec 554 1,054 121 6,200 
Stock 683 364 460 13,012 
Hotel 2,000 2,000 181 11,336 
Table 1. Data sets composition 
We make some preprocessing on the datasets. 
First, we use ICTCLAS (http://ictclas.org/), a 
Chinese text POS tool, to segment these Chinese 
reviews. Second, the documents are represented 
by vector space model.  
3.2 Evaluation Setup 
In our experiment, we use prototype classifica-
tion algorithm (Tan et al, 2005) and Support 
Vector Machine experimenting on the three data 
sets as our baselines separately. The Support 
Vector Machine is a state-of-the-art supervised 
learning algorithm. In our experiment, we use 
LibSVM (www.csie.ntu.edu.tw/~cjlin/libsvm/) with a 
linear kernel and set al options by default.  
We also compare our algorithm to Structural 
Correspondence Learning (SCL) (Blitzer et al, 
2007). SCL is a state-of-the-art sentiment-
transfer algorithm which automatically induces 
correspondences among features from different 
domains. It identifies correspondences among 
features from different domains by modeling 
their correlations with pivot features, which are 
features that behave in the same way for dis-
criminative learning in both domains. In our ex-
periment, we use 100 pivot features.  
3.3 Overall Performance 
In this section, we conduct two groups of ex-
periments where we separately initialize the sen-
timent scores in our algorithm by prototype clas-
sifier and Support Vector Machine.  
There are two parameters in our algorithm, K 
and ? ( ? can be calculated by 1-? ). We set the 
parameters K and ? with 150 and 0.7 respec-
tively, which indicates we use 150 neighbors and 
the contribution from old domain is a little more 
important than that from new domain. It is 
thought that the algorithm achieves the conver-
gence when the changing between the sentiment 
score si computed at two successive iterations for 
any di?DU (i = 1,?n) falls below a given 
threshold, and we set the threshold 0.00001 in 
this work.  
Table 2 shows the accuracy of Prototype, 
LibSVM, SCL and our algorithm when training 
data and test data belong to different domains. 
319
Our algorithm is separately initialized by Proto-
type and LibSVM. 
Baseline Proposed Algorithm 
 
Prototype LibSVM 
SCL Prototype+ 
OurApproach
LibSVM+
OurApproach
Elec->Stock 0.6652 0.6478 0.7507 0.7326 0.7304 
Elec->Hotel 0.7304 0.7522 0.7750 0.7543 0.7543 
Stock->Hotel 0.6848 0.6957 0.7683 0.7435 0.7457 
Stock->Elec 0.7043 0.6696 0.8340 0.8457 0.8435 
Hotel->Stock 0.6196 0.5978 0.6571 0.7848 0.7848 
Hotel->Elec 0.6674 0.6413 0.7270 0.8609 0.8609 
Average 0.6786 0.6674 0.7520 0.7870 0.7866 
Table 2. Accuracy comparison of different methods 
As we can observe from Table 2, our algo-
rithm can dramatically increase the accuracy of 
sentiment-transfer. Seen from the 2nd column and 
the 5th column, every accuracy of the proposed 
algorithm is increased comparing to Prototype. 
The average increase of accuracy over all the 6 
problems is 10.8%. Similarly, the accuracy of 
our algorithm is higher than LibSVM in every 
problem and the average increase of accuracy is 
11.9%. The great improvement comparing with 
the baselines indicates that the proposed algo-
rithm performs very effectively and robustly. 
Seen from Table 2, our result about SCL is in 
accord with that in (Blitzer et al, 2007) on the 
whole. The average accuracy of SCL is higher 
than both baselines, which convinces that SCL is 
effective for sentiment-transfer. However, our 
approach outperforms SCL: the average accuracy 
of our algorithm is about 3.5 % higher than SCL. 
This is caused by two reasons. First, SCL is es-
sentially based on co-occurrence of words (the 
window size is the whole document), so it is eas-
ily affected by low frequency words and the size 
of data set. Second, the pivot features of SCL are 
totally dependent on experts in the field, so the 
quality of pivot features will seriously affect the 
performance of SCL. This improvement con-
vinces us of the effectiveness of our algorithm.  
4 Conclusion and Future Work 
In this paper, we propose a novel sentiment-
transfer algorithm. It integrates the sentiment 
orientations of the documents into the graph-
ranking based method for sentiment-transfer 
problem. The algorithm assigns a score for every 
document being predicted, and it iteratively cal-
culates the score making use of the accurate la-
bels of old-domain data, as well as the ?pseudo? 
labels of new-domain data, finally it labels the 
new-domain data as ?negative? or ?positive? bas-
ing on this score. The experiment results show 
that the proposed approach can dramatically im-
prove the accuracy when transferred to a new 
domain.  
In this study, we find the neighbors of a given 
document using cosine similarity. This is too 
general, and perhaps not so proper for sentiment 
classification. In the next step, we will try other 
methods to calculate the similarity. Also, our 
approach can be applied to multi-task learning. 
5 Acknowledgments 
This work was mainly supported by two funds, i.e., 
0704021000 and 60803085, and one another project, 
i.e., 2004CB318109. 
References 
B. Pang and L. Lee. 2008. Opinion mining and senti-
ment analysis. Foundations and Trends in Infor-
mation Retrieval, 2008 
S. Tan, X. Cheng, M. Ghanem, B. Wang and H. Xu. 
2005. A Novel Refinement Approach for Text 
Categorization. In Proceedings of CIKM 2005. 
S. Tan. 2006. An Effective Refinement Strategy for 
KNN Text Classifier. Expert Systems With Appli-
cations. Elsevier. 30(2): 290-298. 
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs 
up? Sentiment classification using machine learn-
ing techniques. In Proceedings of EMNLP, 2002. 
X. Bai, R. Padman and E. Airoldi. 2005. On learning 
parsimonious models for extracting consumer 
opinions. In Proceedings of HICSS 2005. 
A. Aue and M. Gamon. 2005. Customizing sentiment 
classifiers to new domains: a case study. In 
Proceedings of RANLP 2005. 
J. Blitzer, M. Dredze, and F. Pereira. 2007. Biogra-
phies, Bollywood, Boom-boxes and Blenders: 
Domain adaptation for sentiment classification. In 
Proceedings of ACL 2007. 
S. Tan, G. Wu, H. Tang and X. Cheng. 2007. A novel 
scheme for domain-transfer problem in the context 
of sentiment analysis. In Proceedings of CIKM 
2007. 
S. Tan, Y. Wang, G. Wu and X. Cheng. 2008. Using 
unlabeled data to handle domain-transfer problem 
of semantic detection. In Proceedings of SAC 2008. 
S. Tan, X. Cheng, Y. Wang, H. Xu. 2009. Adapting 
Naive Bayes to Domain Adaptation for Sentiment 
Analysis. In Proceedings of ECIR 2009. 
A. Esuli, F. Sebastiani. 2007. Random-walk models 
of term semantics: An application to opinion-
related properties. In Proceedings of LTC 2007. 
X. Wan, J. Yang and J. Xiao. 2006. Using Cross-
Document Random Walks for Topic-Focused 
Multi-Document Summarization. In Proceedings 
of WI 2006. 
A. Andreevskaia and S. Bergler. 2008. When Special-
ists and Generalists Work Together: Overcoming 
Domain Dependence in Sentiment Tagging. In 
Proceedings of ACL 2008. 
320
Automatic Recognition of Chinese Unknown Words1 Based on Roles Tagging2 
 
Kevin Zhang (Hua-Ping ZHANG)  Qun LIU   Hao ZHANG    Xue-Qi CHENG 
Software Division, Institute of Computing Technology, Chinese Academy of Sciences 
NO. 6, South Road, Kexueyuan, Zhongguancun, Haidian Dist. P.O. BOX 2704, Beijing, P.R. China, 100080 
Email: {zhanghp,liuqun, zhanghao,cxq}@software.ict.ac.cn 
 
Abstract 
This paper presents a unified solution, which 
is based on the idea of ?roles tagging?, to the 
complicated problems of Chinese unknown words 
recognition. In our approach, an unknown word is 
identified according to its component tokens and 
context tokens. In order to capture the functions of 
tokens, we use the concept of roles. Roles are 
tagged through applying the Viterbi algorithm in 
the fashion of a POS tagger. In the resulted most 
probable roles sequence, all the eligible unknown 
words are recognized through a maximum patterns 
matching. We have got excellent precision and 
recalling rates, especially for person names and 
transliterations. The result and experiments in our 
system ICTCLAS shows that our approach based 
on roles tagging is simple yet effective. 
Keywords: Chinese unknown words recognition, 
roles tagging, word segmentation, Viterbi 
algorithm. 
Introduction 
It is well known that word segmentation is a 
prerequisite to Chinese information processing. 
Previous research and work in word segmentation 
have made great progresses. However, cases with 
unknown words are not satisfactory. In general, 
any lexicon is limited and unable to cover all the 
words in real texts or speeches. According to our 
statistics on a 2,305,896-character news corpus 
from the People's Daily, there are about 1.19% 
unknown words. But they are difficult to be 
recalled and often greatly reduce the recognition 
rate of known words close to them. For example, 
the sentence ? ? ? ? ? ? ? ? ? ? ? 
(Pronunciation: ?Bu Zhang Sun Jia Zheng Zai 
Gong Zuo.?)  has two valid segmentations:  ??
?/???/?/??? (The minister Sun Jiazheng is 
at work) and ??? /?? /?? /?? ? (The 
minister Sun Jia now is at work). ????? is a 
person name in the first, while ???? is another 
name in the latter. Meanwhile, the string ????
?? will lead to overlapping ambiguity and bring a 
collision between the unknown word ???
?? (Sun Jiazheng) and ????(zheng zai; now). 
What?s more, the recognizing precision rates of 
person names, place names, and transliterations are 
91.26%, 69.12%, and 82.83%, respectively, while 
the recalling rates of them are just 68.77%, 60.47%, 
and 78.29%, respectively. (Data from official 
testing in 1999) [Liu (1999)] In a word, unknown 
words recognition has become one of the biggest 
stumbling blocks on the way of Chinese lexical 
analysis. A proper solution is important and 
urgent.  
Various approaches are taken in Chinese 
unknown words recognition. They can be broadly 
categorized into ?one-for-one?, ?one-for-several? 
and ?one-for-all? based on the number of 
categories of unknown words, which can be 
recognized. One-for-one solutions solve a 
particular problem, such as person name 
recognition [Song (1993); Ji (2001)], place name 
recognition [Tan (1999)] and transliteration 
recognition [Sun (1993)]. Similarly, 
one-for-several approaches provide one solution 
for several specific categories of unknown words 
[Lv (2001); Luo (2001)]. One-for-all solutions, as 
far as we know, have not been applicable yet 
[Chen (1999); He (2001)].  
Although currently practicable methods could 
achieve great precision or recalling rates in some 
special cases, they have their inherent deficiencies. 
First of all, rules applied are mostly summarized 
by linguists through painful study of all kinds of 
huge ?special name libraries? [Luo (2001)]. It?s 
time-consuming, expensive and inflexible. The 
categories of unknown words are diverse and the 
amount of such words is huge. With the rapid 
development of the Internet, this situation is 
becoming more and more serious. Therefore, it?s 
very difficult to summarize simple yet thorough 
rules about their compositions and contexts. 
Secondly, the recognition process cannot be 
activated until some ?indicator? tokens are 
scanned in. For instance, possible surnames or 
titles often trigger person name recognition on the 
following 2 or more characters. In the case of 
place name recognition, the postfixes such as 
? ? ?(county), ? ? ?(city) will activate the 
recognition on the previous characters. What?s 
more, these methods tend to work only on the 
monosyllabic tokens, which are obvious fragments 
after tokenization [Luo (2001); Lv (2001)]. It takes 
the risk of losing lots of unknown words without 
any explicit features. Furthermore, this trigger 
mechanism cannot resolve the ambiguity. For 
example, unknown word ????? (Fang Lin Shan) 
maybe a person name ??/???(Fang Linshan) or 
a place name ???/??(Fanglin Mountain). 
This paper presents a one-for-all approach 
based on roles tagging to avoid such problems. 
The process is: tagging tokens after word 
segmentation with the most probable roles and 
making unknown words recognition based on roles 
sequence. The mechanism of roles tagging is just 
like that of a small and simple Part-Of-Speech 
tagger.  
The paper is organized as follows: In section 
2, we will describe the approach in general. 
Following that, we will present the solution in 
practice. In the final part, we provide recognition 
experiments using roles-tagging methods. The 
result and possible problems are discussed as well. 
1 Unknown words recognition based on roles 
tagging  
1.1 Lexical roles of unknown words 
Unknown words are often made up of 
distinctive components, most of which are 
monosyllabic characters or short words; in 
addition, there are some regular relations between 
unknown words and their locality, especially with 
their left and right context. As we often write or 
speak, a Chinese person name is usually comprised 
of a one-or-two-character surname and a following 
given name of one or two characters, like ???
??(Xiao Jianqun) and ?????(Zhu-Ge Liang). 
The  previous words are mostly titles, 
occupations or some conjunctive words, such as 
????(Manager), ????(Driver) and ???(To). 
The following words tend to be verbs such as ??? 
(to say) , ????(to express). Similar components, 
contexts and relations can be discovered in place 
name, transliteration, organization name, or other 
types of unknown words.   
We define unknown word roles with respect 
to varied internal components, previous and 
succeeding contexts and other tokens in a 
particular sentence. Various roles are extracted 
according to their functions in the forming of 
different unknown words. Person names roles and 
transliterations roles set are shown in table 1a and 
1b respectively. Using the roles set of person name, 
the tokens sequence ??/?/??/?/?/?/?/?/
?/??/?/??/?/?/??/? (What Zhou Enlai 
and Deng Yunchao used before death are 
presented in the museum) will be tagged as ??/A 
?/A ??/K ?/B ?/C ?/D ?/M ?/B ?/C 
??/V ?/A ??/A ?/A ?/A??/A?. 
Role Significance Examples 
B Surname or family 
name. 
?/?/?/???
??/? 
C First Chinese char in 
the 2-char given name 
?/?/?/?? 
D Last Chinese char in 
the 2-char given name. 
?/?/?/?? 
E Given name with a 
single Chinese char. 
?/? 
F Prefix in the name. ?/???/? 
G Postfix in the name. ?/???/???/? 
K Previous context before 
person name. 
?/??/?/?/
?/?/? 
L Succeeding context 
following person name. 
???/???
?/? 
M Parts between two 
person names. 
??/?/?/?/
?/?/?/?/?
U Known words 
generated by previous 
context and the first 
component of name. 
?? /?? /? /
?/?/??/??
? /?? /?? /
?/?/?/ 
V Known words 
generated by the last 
component and next 
context. 
? /? /?? /?
? /, ? /? /?
?/? 
..... 
A Others tokens not 
mentioned above. 
??/??/??/
??/?/?/?/ 
Table 1a: Roles set of Chinese person names 
 
Role Significance Examples 
B The first 
component of 
transliteration 
?/?/? 
C Middle component ?/?/?/?/?/?
/?/?/? 
D Last component  ?/?/? 
..... 
  
Table 1b: Roles set of transliterations 
1.2 Roles tagging and unknown words recognition 
On the one hand, the sentence include words 
with different roles for a particular category of 
unknown words, on the other hand, such words 
can be recognized after identifying their roles 
sequence. That is: tagging tokens after word 
segmentation with the most probable roles 
sequence, then recognizing unknown words by 
maximum patterns matching on the final roles 
sequence. 
Roles tagging is similar to Part-Of-Speech 
tagging. Our tagging process is based on Viterbi 
Algorithm [Rabiner and Juang (1989)], which is to 
select the optimum with maximum probability 
from all possible tag sequences. The methodology 
and its deduction is given as below: 
Suppose that T is the tokens sequence after 
word segmentation and R is the roles sequence for 
T. We take the role sequence R# with the 
maximum probability as the best choice. That is: 
T=(t1, t 2, ? , t m), 
R=(r1, r2, ? , rm), m>0, 
R#= arg P(R|T)...................?........E1    
R
max
According to the Bayes equation, we can get: 
P(R|T)= P(R)P(T|R)/P(T) ...................E2 
For a particular token sequence, P(T) is a 
constant. So, We can get E3 based on E1 and E2: 
R#= arg P(R)P(T|R) ......................E3 
R
max
We may consider T as the observation value 
sequence while R as the state sequence hidden 
behind the observation. Now we introduce Hidden 
Markov Model [Rabiner and Juang (1986)] to 
resolve such a typical problem:  
P(R) P(T|R)?  ?
=
?
m
i
iiii rrprtp
0
1 )|()|(
?R#? .......E4 
R
maxarg ?
=
?
m
i
iiii rrprtp
0
1 )|()|(
?R#? 
? ......E5 
R
minarg ?
=
?+
m
i
iiii rrprtp
0
1)}|(ln)|({ln
E5 is simpler for computation than E4. 
Now, we can find the most possible token 
sequence with equation E5. It?s a simple 
application of Viterbi Algorithm. 
The final recognition through maximum pattern 
matching is not performed on the original texts but 
performed on roles sequence. The person patterns 
are {BBCD, BBE, BBZ, BCD, BE, BG, BXD, BZ, CD, FB, 
Y, XD}. Before matching, we should split the 
tokens whose roles are like ?U? or ?V?(which 
indicate that the related token is generated by 
internal components and the outside contexts of 
unknown words) into two proper parts. Such a 
processing can recall more unknown words and 
reduce the overlapping collision. As for the above 
sample sentence, the final roles sequence after 
splitting is ?AAKBCDMBCDLAAAAAA?. Therefore, 
we can identify the possible person names ???
?? and ????? according to the recognition 
pattern ?BCD?. 
1.3  Automatic acquisition of roles knowledge 
 As described in E5, the tag sequence R#  is 
decided by two kinds of factors: and 
.  is the probability of a 
token t
)|( ii rtp
)|( 1?ii rrp )|( ii rtp
( irp
i given the condition of being tagged with 
role ri, while  is the transitive 
probability from role r
)| 1?ir
i-1 to role ri. Both factors are 
useful lexical knowledge for tagging and final 
recognition. According to laws of large numbers, if 
the training corpus is large enough, we can acquire 
the roles knowledge as following: 
)|( ii rtp ?C(ti,ri)/C(ri) ................??......... E6 
Where C(ti, ri) is the count of token ti  being role ri; 
and C(ri) is the count of role ri. 
)|( 1?ii rrp ?C(ri-1,ri)/C(ri-1) ........?.?.....?E7 
Where C(ri-1,ri) is the count of role ri-1  followed 
by role ri. 
 C(ti,ri), C(ri) and C(ri-1,ri) are extracted from 
corpus through a training process. The training 
corpus came from one-month news from the 
People?s Daily with 2,305,896 Chinese characters, 
which are manually checked after word 
segmentation and POS tagging (It can be 
downloaded at icl.pku.edu.cn, the homepage of the 
Institute of Computational Linguistics, Peking 
University).  
However, the corpus is tagged with the 
Part-Of-Speech set. Before training, the original 
POS tags should be converted to the proper roles 
by analysing every token in the sentence.  
2 Algorithm and implementation 
The unknown words recognition based on 
roles tagging has three main steps: automatic 
acquisition of roles knowledge from the corpus; 
roles tagging with Viterbi algorithm and unknown 
words recognition through maximum pattern 
matching. 
  Viterbi algorithm is a classic approach in 
statistics. It aims to select the optimum roles 
sequence with maximum possibility from all 
possible results. Our evaluation function for 
decision-making is E5 given in sub-section 1.2. 
Considering the length limitation of this paper, we 
skip the details.  
Therefore, we only provide algorithms for 
roles knowledge learning. In the last part, the 
entire process of unknown words recognition will 
be listed. 
2.1 Roles knowledge learning 
Input: Corpus which is segmented and POS 
tagged 
T: the type of unknown words; 
R: Roles set of T 
Output: C(ti,ri), C(ri) and C(ri-1,ri) 
Algorithm: 
(1) Get one sentence S from corpus C;  
(2) Extract all tokens and POS tags from S; 
(3) Convert all POS tags to roles in T after role 
analysis.  
(4) Store the tokens whose role is not ?A? into the 
recognition lexicons of unknown words T, where 
?A? is not internal components nor context role.  
(5) Calculate the total number C(ti,ri) of token ti  
being role ri. At the same time, count C(ri), which is 
the number of role ri appearances. 
(6) Sum C(ri-1,ri) which is the times of role ri-1 
followed by role ri. 
(7) If no more sentences in the corpus C, exit; else 
go to (1)  
   First of all, we must explain step (3). Our 
corpus is tagged with POS and person, place or 
organization name are tagged with ?nr?, ?ns? or ?nt? 
respectively; Such POS are unique and different 
from noun. Transliterations can be extracted from 
words tagged with ?nr? or ?ns? and through 
analysing its component chars. So we can easily 
locate such kinds of words. Meanwhile, we can 
judge whether a word is unknown by looking it up 
in the core lexicon. Then we can identify roles of 
words according to their locality, which are before 
or following a particular unknown word. 
Here we provide a sample sentence from our 
corpus like ???/r  ??/ns  ??/t  ??/t  
?/n  ??/n  ?/nr  ??/nr  ?/w  ?/nr  ?
?/nr  ??/v?. In step (2), we can extract tokens 
and tags like ????/ ?r?; ????/ ?ns? and so on. 
When we train person recognition roles, firstly, we 
locate person name ??/nr  ??/nr? and ??/nr  
??/nr? just by searching POS ?nr?; Secondly, 
judge whether they are unknown after looking 
them up in the core lexicon; At last we can tag 
unknown words component and their context near 
their locality. So the final roles after conversion 
are ???/A  ??/A ??/A 1?/A ?/A ??
/K ?/B  ?/C?/D ?/M ?/B ?/C?/D ??
/L?. Then we can train the parameters based on 
new segmentation and person recognition roles 
sequence.  
In addition, we train every different kind of 
unknown word on the same corpus individually. 
That is: person roles, place roles and other roles 
are acquired respectively. Therefore, the unknown 
place recognition roles sequence of the above 
sentence may like ???/K  ?/B?/D  ??/L  
??/A  ?/A  ??/K  ?/A ??/A  ?/A  
?/A ??/A  ??/A?. Such a mechanism can 
greatly reduce the problem of sparse data. 
2.2 The entire process of Unknown words 
recognition 
Input: Original sentence S; 
R: the roles set of unknown words; 
P: pattern sets for recognition. 
Output: Possible unknown words of type T. 
Algorithm: 
(1) Word segmentation (we segment words on 
sentence S with N-shortest paths method 
[Hua-Ping ZHANG, Qun LIU (2002)]); 
(2) Tag tokens sequence with roles in set R using 
Viterbi algorithm. Get the roles sequence R# 
with maximum possibility. 
(3) Split tokens whose role is like ?U? or ?V? in the 
person roles. These roles indicate that the 
internal components glue together with their 
context. 
(4) Maximum match final roles sequence to the 
recognition patterns P and record their 
position. 
(5) Generate the candidate unknown words 
according to the result of pattern matching. 
(6) Exclude those candidates which are fit for the 
exclusive rules.(For example, Chinese person 
name can not include non-Chinese chars. ) 
(7) Output the possible unknown words. 
Now, we take person recognition on the 
sentence ?????????????????
????? as exemplification. In the first place, 
we can get the sequence ???/??/??/??/?
/??/?/?/?/?/?/?/?/??/? after rough 
word segmentation; Then we tag it with Viterbi 
algorithm using person recognition roles lexicon 
and transitive array. So, the most probable roles 
sequence is ?AAAAAKBCDMBCDL?.Therefore, 
candidate perosn names ????? and ????? 
can be recognized after maximum string matching. 
3 Experiments and Discussions 
Both close and open recognition test were 
conducted. In the close test, we tested our system 
within the training corpus, which is the knowledge 
base for recognition. Open test, however, is more 
realistic, because it is performed on arbitrary real 
texts outside the training corpus. The corpus in our 
experiments is from 2-months news in 1998 from 
the People?s Daily. 
In this paper, we only provide the recognition 
results of Chinese person and transliterations. The 
recognition of place names and other kind of 
unknown words can get similar performance. 
3.1 Recognition experiment of Chinese person name  
Test Type Close Open 
Corpus (news date) 1.1-2.20 2.20-2.28
Corpus Size  14,446K 2,605K 
Num of Chinese 
person names 
21,256 3,149 
Num of recognized 
person names 
27,813 4,130 
Num of correctly 20,865 2,886 
recognized names 
Precision rate 75.02% 69.88% 
Recalling rate 98.17% 91.65% 
F-measurement  85.05% 79.30% 
Table 2 Experiment results of Chinese person 
names recognition 
In Tables 2, precision rate and recalling rate are 
defined as equations E6 and E7 respectively. In 
addition, F-measurement is a uniformly weighted 
harmonic mean of precision rate and recalling rate 
as shown in E8. 
Precision rate=  
 wordsrecognized of num
 wordsrecognizedcorrectly  of num
??..E6 
Recalling rate=  
wordsunknown   totalofnum
 wordsrecognizedcorrectly  of num
??..E7 
F-measurement = 
ratePrecision rate Recalling
2ratePrecision rate Recalling
+
??
...?.E8 
3.2 Recognition Experiments of transliterations 
Test Type Close Open 
Corpus (news date) 1.1-2.20 2.20-2.28 
Corpus Size  14,446K 2,605K 
Num of 
transliterations  
9,059 1,592 
Num of recognized 
transliterations 
10,013 1,930 
Num of correctly 
recognized 
transliterations 
8,946 1,496 
Precision rate 89.35% 77.52% 
Recalling rate 98.75% 93.97% 
F-measurement  93.85% 84.96% 
Table 3 Results of transliterations recognition 
3.3 Discussions 
The traditional ways to test unknown words 
recognition is to collect sentences including 
unknown words and to make recognition 
experiments. Those sentences that haven?t the type 
of unknown words will be excluded from 
experiments in the pre-processing. In our 
experiments, we just take the realistic corpus and 
make no filtering. Therefore, the precision rates 
may be lower but closer to the realistic linguistic 
environment than previous tests. We have made 
experiments in the traditional way and the 
precision rate can be improved by less than 15%. 
In a word, there is no comparable with precision 
rates of previous unknown words recognition 
experiment. 
  In addition, our experiments show that the 
unknown words recognition based on role tagging 
can achieve very high recalling rates. For such a 
problem, recalling is more essential than precision. 
Low recalling rate means that we have no chance 
to recognize many unknown words through any 
efforts in the following steps, although words 
recognized are mostly valid; However, precision 
rate can be greatly improved in other processes, 
such as POS tagging or sentence simple parsing. In 
our system ICTCLAS (Institute of Computing 
Technology, Chinese Lexical System), we can 
exclude most invalid unknown words during POS 
tagging. The precision rate of Chinese person 
names recognition can achieve over 95% after 
POS tagging while the recalling rate is not 
reduced. 
  Our approach is purely corpus-based. We all 
know that, in any usual corpus, unknown words 
are sparsely distributed. If we depend totally on the 
corpus, the problem of sparse data is inevitable. 
But in the fine-tuning of our system, we found 
some countermeasures and successfully solved the 
problem. 
Lexical knowledge from linguists can be 
incorporated into the system. This does not mean 
that we fall back to the old ways. We just demand 
for those general rules about name formation to 
avoid apparent mistakes. As to person name 
recognition, there are several strict restrictions, 
such as the length of name, the order between 
surname and given name. 
Except for enlarging the training corpus, we 
provide two more counteractions: 
Firstly, a ?best n? approach [Hua-Ping ZHANG, 
Qun LIU (2002)], which provides n (n>1) possible 
tag sequences with leading probabilities, is feasible. 
Usually the desired tag sequence could be 
re-targeted or constructed from the best n 
sequences. In this way, we improved the recalling 
rate at the cost of precision rate. But given a better 
recalling, we could remedy in latter stages of 
language processing. When 3 most probable 
sequences are employed, the recalling and 
precision of unknown words in ICTCLAS can be 
enhanced obviously. 
The second resolution is training on a name 
library in addition to training on a corpus. As we 
all know, it?s easier and cheaper to get a person 
name library or other special name libraries than to 
segment and tag a corpus. We could extract the 
inner components relations from the unknown 
words libraries, and then merge these data into the 
roles information from the original corpus. When 
the special name libraries were introduced, both 
precision and recalling rates can be improved. 
Conclusion 
The paper presents a one-for-all approach for 
Chinese unknown words recognition based on 
roles tagging. At first, we define roles set for every 
category of unknown words according to the 
function of tokens, such as internal component or 
contexts. Unknown words are recognized on roles 
sequence, tagged with the roles set using Viterbi 
algorithm. The knowledge about roles is extracted 
from the learning on corpus. Experiments on large 
size corpus verify that the approach based on role 
tagging is simple and applicable. 
Acknowledgements 
First of all, our thanks go to the Institute of 
Computational Linguistics, Peking University for 
providing the corpus. And we owe lots of thanks to 
our colleagues: Zougang, Li Jifeng, Li Sujian,Li 
Shengtao, Zhu Hailong, Zhao Hongchao, Wang 
Shuxi and Dr. Zhou Lixin. We would especially 
express gratitude to the chief scientist Bai Shuo. 
References  
K.Y. Liu (1999)  The Assessment to Automatic Word 
Segmentation and POS Tagging Software. 
Proceedings of the 4th Conference on Chinese 
Computer Intelligent Interface and Application, 
Beijing. 
Z. Luo and R. Song (2001)  Integrated and Fast 
Recognition of Proper Noun in Modern Chinese Word 
Segmentation.  Proceedings of International 
Conference on Chinese Computing 2001, Singapore, 
pp. 323-328. 
H. Luo and Z. Ji (2001)  Inverse Name Frequency 
Model and Rules Based on Chinese Name Identifying.  
In "Natural Language Understanding and Machine 
Translation", C. N. Huang & P. Zhang, ed., Tsinghua 
Univ. Press, Beijing, China, pp. 123-128. 
R. Song (1993)  Person Name Recognition Method 
Based on Corpus and Rule.  In ?Computational 
Language Research and Development", L. W. Chen 
& Q. Yuan, ed., Beijing Institute of Linguistic Press. 
H. Y. Tan (1999)  Chinese Place Automatic 
Recognition Research.  In "Proceedings of 
Computational Language ", C. N. Huang & Z.D. 
Dong, ed., Tsinghua Univ. Press, Beijing, China. 
M.S. Sun (1993)  English Transliteration Automatic 
Recognition.  In "Computational Language 
Research and Development", L. W. Chen & Q. Yuan, 
ed., Beijing Institute of Linguistic Press. 
Y.J. Lv, T. J. Zhao (2001)  Levelled Unknown Chinese 
Words Resolution by Dynamic Programming.  
Journal of Chinese Information Processing. 15, 1, pp. 
28-33. 
X. H. Chen (1999)  One-for-all Solution for Unknown 
Word in Chinese Segmentation. Application of 
Language and Character, 3. 
Y. He (2001)  Identification of Unlisted Words on 
Transitive Probability of Monosyllabic Words.  In 
"Natural Language Understanding and Machine 
Translation", C. N. Huang & P. Zhang, ed., Tsinghua 
Univ. Press, Beijing, China, pp. 123-128. 
Hua-Ping  ZHANG, Qun LIU (2002)  Model of 
Chinese Words Rough Segmentation Based on 
N-Shortest-Paths Method.  Journal of Chinese 
Information Processing. 16, 5, pp. 77-83. 
L. R.Rabiner (1989)  A Tutorial on Hidden Markov 
Models and Selected Applications in Speech 
Recognition.  Proceedings of IEEE 77(2): 
pp.257-286. 
L.R. Rabiner and B.H. Juang, (Jun. 1986) An 
Introduction to Hidden Markov Models.  IEEE 
ASSP Mag., Pp.4-166. 
???????????????????3 
???   ? ?   ? ?   ??? 
Email : zhanghp@software.ict.ac.cn 
??????????????? 
?? 2704????????????? 6?, ??  
??: ?????????????????
?????????????????????
?????????????????????
?????????????????????
?? Viterbi??????? Token?????
?????????????????????
?????????????????????
?????????????????????
?????????????????????
?????????????????????
?????????????????????
????????????????????
????? ICTCLAS????????????
?????????????????????
????????????? 
???:?????????????????
Viterbi?? 
                                                        
1 We define unknown words to be those not included in 
the core lexicon and unable to be generated by FSA, 
such as person name, place name. But numeric or 
common time word is not unknown because they can 
generate by a simple FSA. 
2 Related research in this paper is supported by 
Foundation of National Key Basic Research Project (ID: 
G1998030507-4 and G1998030510). 
3 ??????????????????(???
G1998030507-4?G1998030510)??? 
	



Coling 2010: Poster Volume, pages 1327?1335,
Beijing, August 2010
MIEA: a Mutual Iterative Enhancement Approach for Cross-Domain  
Sentiment Classification 
 
Qiong Wu1,2, Songbo Tan1, Xueqi Cheng1 and Miyi Duan1 
1Institute of Computing Technology, Chinese Academy of Sciences 
2 Graduate University of Chinese Academy of Sciences 
{wuqiong,tansongbo}@software.ict.ac.cn 
 
Abstract 
Recent years have witnessed a large body of 
research works on cross-domain sentiment 
classification problem, where most of the re-
search endeavors were based on a supervised 
learning strategy which builds models from 
only the labeled documents or only the labeled 
sentiment words. Unfortunately, such kind of 
supervised learning method usually fails to 
uncover the full knowledge between docu-
ments and sentiment words. Taking account of 
this limitation, in this paper, we propose an it-
erative reinforcement learning approach for 
cross-domain sentiment classification by si-
multaneously utilizing documents and words 
from both source domain and target domain. 
Our new method can make full use of the rein-
forcement between documents and words by 
fusing four kinds of relationships between 
documents and words. Experimental results 
indicate that our new method can improve the 
performance of cross-domain sentiment classi-
fication dramatically. 
1 Introduction 
Sentiment classification is the task of determin-
ing the opinion (e.g., negative or positive) of a 
given document. In recent years, it has drawn 
much attention with the increasing reviewing 
pages and blogs etc., and it is very important for 
many applications, such as opinion mining and 
summarization (e.g., (Ku et al, 2006; McDonald 
et al, 2007)). 
In most cases, a variety of supervised classifi-
cation methods can perform well in sentiment 
classification. This kind of methods requires a 
condition to guarantee the accuracy of classifica-
tion: training data should have the same distribu-
tion with test data so that test data could share 
the information got from training data. So the 
labeled data in the same domain with test data is 
considered as the most valuable resources for the 
sentiment classification. However, such re-
sources in different domains are very imbalanced. 
In some traditional domains or domains of con-
cern, many labeled sentiment data are freely 
available on the web, but in other domains, la-
beled sentiment data are scarce and it involves 
much human labor to manually label reliable 
sentiment data. The challenge is how to utilize 
labeled sentiment data in one domain (that is, 
source domain) for sentiment classification in 
another domain (that is, target domain). This 
raises an interesting task, cross-domain sentiment 
classification (or sentiment transfer). In this work, 
we focus on one typical kind of sentiment trans-
fer problem, which utilizes only training data 
from source domain to improve sentiment 
classification performance for target domain, 
without any labeled data for the target domain 
(e.g., (Andreevskaia and Bergler, 2008)). 
In recent years, some studies have been con-
ducted to deal with sentiment transfer problems. 
However, most of the attempts rely on only the 
labeled documents (Aue and Gamon, 2005; Tan 
et al, 2007; Tan et al, 2009; Wu et al, 2009) or 
the labeled sentiment words (Gamon and Aue, 
2005) to improve the performance of sentiment 
transfer, so this kind of methods fails to uncover 
the full knowledge between the documents and 
the sentiment words. 
In fact, the opinion of a document can be de-
termined by the interrelated documents as well as 
by the interrelated words, and this rule is also 
tenable when determining the opinion of a sen-
timent word. This rule is based on the following 
intuitive observations:  
(1)  A document strongly linked with other posi-
tive (negative) documents could be consid-
ered as positive (negative); in the same way, 
a word strongly linked with other positive 
(negative) words could be considered as 
positive (negative). 
1327
(2)  A document containing many positive (nega-
tive) words could be considered as positive 
(negative); similarly, a word appearing in 
many positive (negative) documents could 
be considered as positive (negative). 
Inspired by these observations, we aim to take 
into account all the four kinds of relationships 
among documents and words (i.e. the relation-
ships between documents, the relationships be-
tween words, the relationships between words 
and documents, and the relationships between 
documents and words) in both source domain 
and target domain under a unified framework for 
sentiment transfer.  
In this work, we propose an iterative rein-
forcement approach to implement the above idea. 
The proposed approach makes full use of all the 
relationships among documents and words from 
both source domain and target domain to transfer 
information between domains. In our approach, 
the opinion of a document (word) is reinforced 
by the opinion of all its interrelated documents 
and words; and the updated opinion of the docu-
ment (word) will conversely reinforce the opin-
ions of its interrelated documents and words. 
That is to say, it is an iterative reinforcement 
process until it converges to a final result.  
The contribution of our work is twofold. First, 
we extend the traditional sentiment-transfer 
methods by utilizing the full knowledge between 
interrelated documents and words. Second, we 
present a reinforcement approach to get the opin-
ions of documents by making use of graph-
ranking algorithm.  
The proposed approach is evaluated on three 
domain-specific sentiment data sets. The experi-
mental results show that our approach can dra-
matically improve the accuracy when transferred 
to another target domain. And we also conduct 
extensive experiments to investigate the parame-
ters sensitivity. The results show that our algo-
rithm is not sensitive to these parameters. 
2 Proposed Methods 
2.1 Problem Definition 
In this paper, we have two document sets: the 
test documents DU = {d1,?,dnd} where di is the 
term vector of the ith text document and each 
di?DU(i = 1,?,nd) is unlabeled; the training 
documents DL = {dnd+1,?,dnd+md} where dj repre-
sents the term vector of the jth text document and 
each dj?DL(j = nd+1,?,nd+md) should have a 
label from a category set C = {negative, posi-
tive}. We assume the training dataset DL is from 
the interrelated but different domain with the test 
dataset DU. Also, we have two word sets: WU = 
{w1,?,wnw} is the word set of DU and each 
wi?WU (i = 1,?,nw) is unlabeled; WL = 
{wnw+1,?,wnw+mw} is the word set of DL and each 
wj?WL(j = nw+1,?,nw+mw) has a label from C. 
Our objective is to maximize the accuracy of as-
signing a label in C to di?DU (i = 1,?,nd) utiliz-
ing the training data DL and WL in another do-
main. 
The proposed algorithm is based on the fol-
lowing presumptions: 
   (1) WL?WU??. 
   (2) The labels of documents appear both in the 
training data and the test data should be the same. 
2.2 Overview 
The proposed approach is inspired by graph-
ranking algorithm whose idea is to give a node 
high score if it is strongly linked with other high-
score nodes. Graph-ranking algorithm has been 
successfully used in many fields (e.g. PageRank 
(Brin et al 1999), LexRank (Erkan and Radev, 
2004)). We can get the following thoughts based 
on the ideas of PageRank and HITS (Kleinberg, 
1998): 
(1)   If a document is strongly linked with other 
positive (negative) documents, it tends to be 
positive (negative); and if a word is strongly 
linked with other positive (negative) words, 
it tends to be positive (negative). 
(2)  If a document contains many positive (nega-
tive) words, it tends to be positive (nega-
tive); and if a word appears in many posi-
tive (negative) documents, it tends to be 
positive (negative). 
Given the data points of documents and words, 
there are four kinds of relationships in our prob-
lem: 
z DD-Relationship: It denotes the relation-
ships between documents, usually computed 
by their content similarity. 
z WW-Relationship: It denotes the relation-
ships between words, usually computed by 
knowledge-based approach or corpus-based 
approach. 
z DW-Relationship: It denotes the relation-
ships between documents and words, usu-
1328
ally computed by the relative importance of 
a word in a document. 
z WD-Relationship: It denotes the relation-
ships between words and documents, usu-
ally computed by the relative importance of 
a document to a word. 
Meanwhile, our problem refers to both source 
domain and target domain, so our approach con-
siders eight relationships altogether: DDO-
Relationship (the relationships between DU and 
DL), DDN-Relationship (the relationships be-
tween DU), WWO-Relationship (the relationships 
between WU and WL), WWN-Relationship (the 
relationships between WU and WU), DWO-
Relationship (the relationships between DU and 
WL), DWN-Relationship (the relationships be-
tween DU and WU), WDO-Relationship (the rela-
tionships between WU and DL), WDN-
Relationship (the relationships between WU and 
DU). The first four relationships are used to com-
pute the sentiment scores of the documents, and 
the others are used to compute the sentiment 
scores of the words. 
The iterative reinforcement approach could 
make full use of all the relationships in a unified 
framework. The framework of the proposed ap-
proach is illustrated in Figure 1.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Framework of the proposed approach 
 
The framework consists of a graph-building 
phase and an iterative reinforcement phase. In 
the graph-building phase, the input includes both 
the labeled data from source domain and the 
unlabeled data from target domain. The proposed 
approach builds four graphs based on these data 
to reflect the above relationships respectively. 
For source-domain data, we initialize every 
document and word a score (?1? denotes positive, 
and ?-1? denotes negative) to represent its degree 
of sentiment orientation, and we call it sentiment 
score; for target-domain data, we set the initial 
sentiment scores to 0.  
In the iterative reinforcement phase, our ap-
proach iteratively computes the sentiment scores 
of the documents and words based on the graphs. 
When the algorithm converges, all the documents 
get their sentiment scores. If its sentiment score 
is between 0 and 1, the document should be clas-
sified as ?positive?. The closer its sentiment 
score is near 1, the higher the ?positive? degree 
is. Otherwise, if its sentiment score is between 0 
and -1, the document should be classified as 
?negative?. The closer its sentiment score is near 
-1, the higher the ?negative? degree is. 
The algorithms of sentiment graph building 
and iterative reinforcement are described in de-
tails in the next sections, respectively. 
2.3 Sentiment-Graph Building 
Symbol Definition 
In this section, we build four graphs to reflect 
eight relationships, and the meanings of symbols 
are shown in Table 1.  
Rela-
tionship
Similarity ma-
trix 
Normal-
ized form Neighbor matrix
DDO UL=[ULij]ndxmd LU?  Kndij
LL UnUn ?= ][
DDN UU=[UU ij]ndxnd UU?  Kndij
UU UnUn ?= ][
WWO VL=[VLij]nwxmw LV?  Knwij
LL VnVn ?= ][
WWN VU=[VU ij]nwxnw UV?  Knwij
UU VnVn ?= ][
DWO ML=[MLij]ndxmw LM?  Kndij
LL MnMn ?= ][
DWN MU=[MUij]ndxnw UM?  Kndij
UU MnMn ?= ][
WDO NL=[NLij]nwxmd LN?  Knwij
LL NnNn ?= ][
WDN NU=[NUij]nwxnd UN?  Knwij
UU NnNn ?= ][
Table 1: Symbol definition 
In this table, the first column denotes the name 
of the relationship; the second column denotes 
1329
the similarity matrix to reflect the corresponding 
relationship; in consideration of convergence, we 
normalize the similarity matrix, and the normal-
ized form is listed in the third column; in order to 
compute sentiment scores, we find the neighbors 
of a document or a word and the neighbor matrix 
is listed in the fourth column. 
Document-to-Document Graph  
We build an undirected graph whose nodes de-
note documents in both DL and DU and edges 
denote the content similarities between docu-
ments. If the content similarity between two 
documents is 0, there is no edge between the two 
nodes. Otherwise, there is an edge between the 
two nodes whose weight is the content similarity. 
The edges in this graph are divided into two parts: 
edges between DU and DL; edges between DU 
itself, so we build the graph in two steps. 
(1) Create DU and DL Edges  
The content similarity between two documents is 
computed with the cosine measure. We use an 
adjacency matrix UL to denote the similarity ma-
trix between DU and DL. UL=[ULij]ndxmd is defined 
as follows: 
mdjndi
dd
dd
U
ndji
ndjiL
ij ,...,1,,...,1, ==?
?=
+
+          (1) 
The weight associated with word w is com-
puted with tfwidfw where tfw is the frequency of 
word w in the document and idfw is the inverse 
document frequency of word w, i.e. 1+log(N/nw), 
where N is the total number of documents and nw 
is the number of documents containing word w in 
a data set.   
In consideration of convergence, we normalize 
UL to LU? by making the sum of each row equal to 
1: 
??
??
? ?= ?? ==
otherwise
UifUU
U
md
j
L
ij
md
j
L
ij
L
ijL
ij
,0
0,?
11              (2) 
In order to find the neighbors (in another word, 
the nearest documents) of a document, we sort 
every row of LU?  to LU~ in descending order. That 
is: ijLU~ ? ikLU~  (i = 1,?,nd; j,k = 1,?,md; k?j). 
Then for di?DU (i = 1,?,nd), ijLU~ (j = 1,?,K ) 
corresponds to K neighbors in DL. We use a ma-
trix 
Kndij
LL UnUn ?= ][  to denote the neighbors of DU 
in source domain, with ijLUn  corresponding to the 
jth nearest neighbor of di. 
(2) Create DU and DU Edges  
Similarly, the edge weight between DU itself is 
computed by the cosine measure. We get the 
similarity matrix UU=[UUij]ndxnd, the normalized 
similarity matrix UU? , and the neighbors of  DU in 
target domain: 
Kndij
UU UnUn ?= ][ . 
Word-to-Word Graph 
Similar to the Document-to-Document Graph, 
we build an undirected graph to reflect the rela-
tionship between words in WL and WU, in which 
each node corresponds to a word and the edge 
weight between any different words corresponds 
to their semantic similarity. The edges in this 
graph are divided into two parts: edges between 
WU and WL; edges between WU itself, so we also 
build the graph in two steps. 
(1) Create WU and WL Edges 
We compute the semantic similarity using cor-
pus-based approach which computes the similar-
ity between words utilizing information from 
large corpora. There are many measures to iden-
tify word semantic similarity, such as mutual 
information (Turney, 2001), latent semantic 
analysis (Landauer et al, 1998) etc. In this study, 
we compute word semantic similarity based on 
the sliding window measure, that is, two words 
are semantically similar if they co-occur at least 
once within a window of maximum Kwin words, 
where Kwin is the window size. We use an adja-
cency matrix VL to denote the similarity matrix 
between WU and WL. VL=[VLij]nwxmw is defined as 
follows: 
??
??
? ??
?
= ++
+
otherwise
wwif
wpwp
wwpN
V nwjinwji
nwji
ij
L
,0
,
)()(
),(
log        
(3) 
where N is the total number of words in DU; p(wi, 
wj) is the probability of the co-occurrence of wi 
and wj within a window, i.e. num(wi, wj)/N, 
where num(wi, wj) is the number of the times wi 
and wj co-occur within the window; p(wi) and 
p(wj) are the probabilities of the occurrences of 
wi and wj respectively, i.e. num(wi)/N and 
num(wj)/N, where num(wi) and num(wj) are the 
1330
numbers of the times wi and wj occur. We nor-
malize VL to LV? to make the sum of each row 
equal to 1. Then we sort every row of LV?  to LV~ in 
descending order, and we use a matrix 
Knwij
LL VnVn ?= ][  to denote the neighbors of WU in 
source domain. 
(2) Create WU and WU Edges 
Then we also compute the edge weight between 
any different nodes which denote words in WU 
by the sliding window measure. We get the simi-
larity matrix VU=[VUij]nwxnw, the normalized simi-
larity matrix UV? , and the neighbors of  WU in 
target domain: 
Knwij
UU VnVn ?= ][ . 
Document-to-Word Graph 
We can build a weighted directed bipartite graph 
from documents in DU and words in WL and WU 
in the following way: each node in the graph cor-
responds to a document in DU or a word in WL 
and WU; if word wj appears in document di, we 
create an edge from di to wj. The edges in this 
graph are divided into two parts: edges from DU 
to WL; edges from DU to WU, so we also build the 
graph in two steps. 
(1) Create DU to WL Edges 
The edge weight from a document in DU to a 
word in WL is proportional to the importance of 
word wj in document di. We use an adjacency 
matrix ML to denote the similarity matrix from 
DU to WL. ML=[MLij]ndxmw is defined as follows: 
?
?
?
?= ++
i
nwjnwj
dw
ww
wwL
ij idftf
idftf
M                          (4) 
where w represents a unique word in di and tfw, 
idfw are respectively the term frequency in the 
document and the inverse document frequency. 
We normalize ML to LM?  to make the sum of each 
row equal to 1. Then we sort every row of LM?  to 
LM
~ in descending order, and we use a matrix 
Kndij
LL MnMn ?= ][  to denote the neighbors of D
U in 
WL. 
(2) Create DU to WU Edges 
Similarly, we can also compute the edge weight 
from a document in DU to a word in WU in the 
same way. We get the similarity matrix 
MU=[MUij]ndxnw, the normalized similarity matrix 
UM? , and the neighbors of  DU in WU: 
Kndij
UU MnMn ?= ][ . 
Word-to-Document Graph 
In this section, we build a weighted directed 
bipartite graph from words in WU and documents 
in DL and DU in which each node in the graph 
corresponds to a word in WU and a document in 
DL or DU; if word wj appears in document di, we 
create an edge from wj to di. The edges in this 
graph are also divided into two parts: edges from 
WU to DL; edges from WU to DU. 
(1) Create WU to DL Edges 
Similar to 3.3.4, the edge weight from a word in 
WU to a document in DL is proportional to the 
importance of word wi in document dj. We use an 
adjacency matrix NL=[NLij]nwxmd to denote the 
similarity matrix from WU to DL. We normalize 
NL to LN?  to make the sum of each row equal to 1. 
Then we sort every row of LN?  to LN~ in descend-
ing order, and we use a matrix 
Knwij
LL NnNn ?= ][  to 
denote the neighbors of WU in DL. 
(2) Create WU to DU Edges 
We can also compute the edge weight from a 
word in WU to a document in DU in the same way. 
We get the similarity matrix NU=[NUij]nwxnd, the 
normalized similarity matrix UN? , and the 
neighbors of  WU in DU: 
Knwij
UU NnNn ?= ][ . 
2.4 Proposed Method 
Based on the two thoughts introduced in Sec-
tion 2.2, we fuse the eight relationships ab-
stracted from the four graphs together to itera-
tively reinforce sentiment scores, and we can 
obtain the iterative equation as follows: 
??
??
??
??
??
??
?+?+
?+?=
i
U
i
L
i
U
i
L
Mnr
rir
U
Mnl
lil
L
Unh
hih
U
Ung
gig
L
i
wsMwsM
dsUdsUds
)?()?(
)?()?(
??
??
   (5) 
??
??
??
??
??
??
?+?+
?+?=
j
U
j
L
j
U
j
L
Nnr
rjr
U
Nnl
ljl
L
Vnh
hjh
U
Vng
gjg
L
j
dsNdsN
wsVwsVws
)?()?(
)?()?(
??
??
    (6) 
where ?i  means the ith row of a matrix; Ds = 
{ds1,?,dsnd, dsnd+1,?, dsnd+md} represents the 
sentiment scores of DU and DL; Ws = 
{ws1,?,wsnw, wsnw+1,?, wsnw+mw} represents the 
sentiment scores of WU and WL; ?  and ?  show 
1331
the relative contributions to the final sentiment 
scores from source domain and target domain 
when calculating DD-Relationship and WW-
Relationship, and ?  + ? =1; ? and?show the 
relative contributions to the final sentiment 
scores from source domain and target domain 
when calculating DW-Relationship and WD-
Relationship, and ? +?=1. 
For simplicity, we merge the relationships 
from source domain and target domain. That is, 
for formula (5), we merge the first two items into 
one, the last two items into one; for formula (6), 
we merge its first two items into one, its last two 
items into one. Thus, (5) and (6) are transformed 
into (7) and (8) as follows: 
??
?? ??
??+??=
ii Mnl
lil
Ung
gigi wsMdsUds )?()?( ??           (7) 
??
?? ??
??+??=
jj Vnl
ljl
Nng
gjgj wsVdsNws )?()?( ??    (8) 
where  ? and ? show the relative contributions 
to the final sentiment scores from document sets 
and word sets, and ?+?=1. 
In consideration of the convergence, Ds and 
Ws are normalized separately after each iteration 
as follows to make the sum of positive scores 
equal to 1, and the sum of negative scores equal 
to -1: 
???
???
?
>
<?
= ?
?
?
?
0,
0,)(
i
Dj
ji
i
Dj
ji
dsifdsds
dsifdsds
ds
U
pos
U
neg
i
                (9) 
???
???
?
>
<?
= ?
?
?
?
0,
0,)(
j
Wi
ij
j
Wi
ij
j
wsifwsws
wsifwsws
ws
U
pos
U
neg              (10) 
where U
negD and
U
posD denote the negative and 
positive document set of DU respectively; 
U
negW and 
U
posW denote the negative and positive 
word set of WU respectively.  
Here is the complete algorithm: 
1. Initialize the sentiment score vector dsi 
of di?DL (i = nd+1,?, nd+md) with 1 when 
di is labeled ?positive?, and with -1 when di 
is labeled ?negative?, and initialize the sen-
timent score vector wsi of wi?WL (i = 
nw+1,?, nw+mw) with 1 when wi is labeled 
?positive?, and with -1 when wi is labeled 
?negative?. And we normalize dsi (i = 
nd+1,?, nd+md) (wsi (i = nw+1,?, 
nw+mw)) to make the sum of positive scores 
of DL (WL) equal to 1, and the sum of nega-
tive scores of DL (WL) equal to -1. Also, the 
initial sentiment scores of DU and WU are set 
to 0. 
2. Alternate the following two steps until 
convergence: 
2.1.Compute and normalize dsi (i = 1,?, 
nd) using formula (7) and (9): 
2.2.Compute and normalize wsj (j=1,?,nw) 
using formula (8) and (10): 
where )(kids and
)(k
jws denote the ids and wsj 
at the kth iteration. 
3. According to dsi?Ds (i = 1,?,nd), as-
sign each di?DU (i = 1,?,nd) a label. If dsi 
falls in the range [-1,0], assign di the label 
?negative?; if dsi falls in the range [0,1], as-
sign di the label ?positive?. 
3 Experiments 
In this section, we evaluate our approach on 
three different domains and compare it with 
some state-of-the-art algorithms, and also evalu-
ate the approach?s sensitivity to its parameters. 
Note that we conduct experiments on Chinese 
data, but the main idea in the proposed approach 
is language-independent in essence. 
3.1 Data Preparation 
We use three Chinese domain-specific data sets 
from on-line reviews, which are: Book Reviews1 
(B, www.dangdang.com/), Hotel Reviews 2  (H, 
www.ctrip.com/) and Notebook Reviews 3  (N, 
www.360buy.com/). Each dataset has 4000 la-
beled reviews (2000 positives and 2000 nega-
tives).  
We use ICTCLAS (http://ictclas.org/), a Chi-
nese text POS tool, to segment these Chinese 
reviews. Then, utilizing the part-of-speech tag-
ging function provided by ICTCLAS, we take all 
adjectives, adverbs and adjective-noun phrases as 
candidate sentiment words. After removing the 
repeated words and ambiguous words, we get a 
list of words in each domain.  
For the list of words in each domain, we 
manually label every word as ?negative?, ?posi-
                                                 
1www.searchforum.org.cn/tansongbo/corpus/Dangdang_Book_4000.rar 
2www.searchforum.org.cn/tansongbo/corpus/Ctrip_htl_4000.rar 
3www.searchforum.org.cn/tansongbo/corpus/Jingdong_NB_4000.rar 
1332
tive? or ?neutral?, and we take those ?negative? 
and ?positive? words as a sentiment word set.  
Note that we use the sentiment word set only 
for source domain, while using the candidate 
sentiment words for target domain.  
Lastly, the documents are represented by vec-
tor space model. In this model, each document is 
converted into bag-of-words presentation in the 
remaining term space. We compute term weight 
with the frequency of the term in the document. 
We choose one of the three data sets as 
source-domain data DL, and its corresponding 
sentiment word set as WL; we choose another 
data set as target-domain data DU, and its corre-
sponding candidate sentiment words as WU. 
3.2 Baseline Methods 
In this paper we compare our approach with the 
following baseline methods:  
Proto: This method applies a traditional super-
vised classifier, prototype classifier (Tan et al, 
2005), for the sentiment transfer. And it only 
uses source domain documents as training data. 
LibSVM: This method applies a state-of-the-
art supervised learning algorithm, Support Vec-
tor Machine, for the sentiment transfer. In detail, 
we use LibSVM (Chang and Lin, 2001) with a 
linear kernel and set al options as default. This 
method only uses source domain documents as 
training data. 
TSVM:  This method applies transductive 
SVM (Joachims, 1999) for the sentiment transfer 
which is a widely used method for improving the 
classification accuracy. In our experiment, we 
use Joachims?s SVM-light package 
(http://svmlight.joachims.org/) for TSVM. We 
use a linear kernel and set al parameters as de-
fault. This method uses both source domain data 
and target domain data. 
3.3 Overall Performance 
In this section, we compare proposed approach 
with the three baseline methods. There are three 
parameters in our algorithm, K, Kwin, ? (?can be 
calculated by 1-?). We set K to 50, and Kwin to 10 
respectively. With different ?, our approach can 
be considered as utilizing different relative con-
tributions from document sets and word sets. In 
order to identify the importance of both docu-
ment sets and word sets for sentiment transfer, 
we separately set ? to 0, 1, 0.5 to show the accu-
racy of utilizing only word sets (referred to as 
WORD), only document sets (referred to as 
DOC), and both the document and word sets (re-
ferred to as ALL). It is thought that the algorithm 
achieves the convergence when the changing 
between the sentiment score dsi computed at two 
successive iterations for any di?DU (i = 1,?,nd) 
falls below a given threshold, and we set the 
threshold 0.00001 in this work. The parameters 
will be studied in parameters sensitivity section. 
Table 2 shows the accuracy of Prototype, 
LibSVM, TSVM and our algorithm when train-
ing data and test data belong to different domains.  
As we can observe from Table 2, our algo-
rithm produces much better performance than 
supervised baseline methods. Compared with the 
traditional classifiers, our approach outperforms 
them by a wide margin on all the six transfer 
tasks. The great improvement compared with the 
baselines indicates that our approach performs 
very effectively and robustly. 
 Traditional Classifier Our Approach  
 Proto LibSVM
TSVM 
DOC WORD ALL
B->H 0.735 0.747 0.749 0.772 0.734 0.763
B->N 0.651 0.652 0.769 0.714 0.785 0.795
H->B 0.645 0.675 0.614 0.671 0.668 0.703
H->N 0.729 0.669 0.726 0.749 0.727 0.734
N->B 0.612 0.608 0.622 0.638 0.667 0.726
N->H 0.724 0.711 0.772 0.764 0.740 0.792
Aver-
age 0.683 0.677 0.709 0.718 0.720 0.752
Table 2: Accuracy comparison of different methods 
Table 2 shows the average accuracy of TSVM 
is higher than both traditional classifiers, since it 
utilizes the information of both source domain 
and target domain. However, the proposed ap-
proach outperforms TSVM: the average accuracy 
of the proposed approach is about 4.3% higher 
than TSVM. This is caused by two reasons. First, 
TSVM is not dedicated for sentiment-transfer 
learning. Second, TSVM requires the ratio be-
tween positive and negative examples in the test 
data to be close to the ratio in the training data, 
so its performance will be affected if this re-
quirement is not met. 
Results of ?DOC? and ?WORD? are shown in 
column 4 and 5 of Table 2. As we can observe, 
they produce better performance than all the 
baselines. This is caused by two reasons. First, 
?DOC? and ?WORD? separately utilize the sen-
1333
timent information of documents and words. 
Second, both ?DOC? and ?WORD? involve an 
iterative reinforcement process to improve their 
performance. The great improvement indicates 
that the iterative reinforcement approach is effec-
tive for sentiment transfer. 
Besides, Table 2 also shows both document 
sets and word sets are important for sentiment 
transfer. The approach ?ALL? outperforms the 
approaches ?DOC? and ?WORD? on almost all 
the six transfer tasks except ?B->H? and ?H->N?. 
The average increase of accuracy over all the six 
tasks is 3.4% and 3.2% respectively. The reason 
is: at every iteration, the classification accuracy 
of documents and words is improved by each 
other, and then the accuracy of sentiment transfer 
is improved by the documents and words that are 
classified more accurately. As for ?B->H? and 
?H->N?, the performance of utilizing only 
document sets is so good that the word sets 
couldn?t improve the performance any more. The 
improvement of the approach ?ALL? convinces 
us that not a single one of the four relationships 
can be omitted.  
3.4 Parameters Sensitivity 
The proposed algorithm has an important pa-
rameter, ? (?can be calculated by 1-?). In this 
section, we conduct experiments to show that our 
algorithm is not sensitive to this parameter. 
To investigate the sensitivity of proposed 
method involved with the parameter ?, we set K 
to 50, and Kwin to 10. And we change ? from 0 to 
1, an increase of 0.1 each. We also evaluate ? on 
the six tasks mentioned in section 3.1, and the 
results are shown in figure 2.  
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?
Ac
cu
ra
cy
B->H B->N H->B H->N N->B N->H
 
Figure 2:  Accuracy for Different ? 
We can observe from Figure 2 that the accu-
racy first increases and then decreases when ? is 
increased from 0 to 1. The accuracy changes 
gradually when ? is near 0 or 1, and it changes 
less when ? is between 0.2 and 0.8. It is easy to 
explain this phenomenon. When ? is set to 0, this 
indicates our algorithm only uses word sets to aid 
classification, without the information of docu-
ment sets. And if ? is set to 1, our algorithm only 
uses document sets to calculate sentiment score, 
without the help of word sets. Both cases above 
don?t use all information of four relationships, so 
their accuracies are worse than to equal the con-
tributions of both document and word sets. This 
experiment shows that the proposed algorithm is 
not sensitive to the parameter ? as long as ? is 
not 0 or 1. We set ? to 0.5 in our overall-
performance experiment. 
3.5 Convergence 
Our algorithm is an iterative process that will 
converge to a local optimum. We evaluate its 
convergence on the six tasks mentioned above. 
Figure 3 shows the change of accuracy with re-
spect to the number of iterations. We can observe 
from figure 3 that the curve rises sharply during 
the first 6 iterations, and it is very stable after 10 
iterations are performed. This experiment indi-
cates that our algorithm could converge very 
quickly to get a local optimum. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1 4 7 10 13 16 19 22 25 28 31 34 37 40Iteration
Ac
cu
ra
cy
B->H B->N H->B H->N N->B N->H
 
Figure 3:  Performance for Iteration 
4 Conclusions 
In this paper, we propose a novel cross-domain 
sentiment classification approach, which is an 
iterative reinforcement approach for sentiment 
transfer by utilizing all the relationships among 
documents and words from both source domain 
and target domain to transfer information be-
tween domains. First, we build three graphs to 
reflect the above relationships respectively. Then, 
1334
we assign a score for every unlabelled document 
to denote its extent to ?negative? or ?positive?. 
We then iteratively calculate the score by making 
use of the graphs. Finally, the final score for sen-
timent classification is achieved when the algo-
rithm converges, so we can label the target-
domain data based on these scores.  
We conduct experiments on three domain-
specific sentiment data sets. The experimental 
results show that the proposed approach could 
dramatically improve the accuracy when trans-
ferred to a target domain. To investigate the pa-
rameter sensitivity, we conduct experiments on 
the same data sets. It is observed that our ap-
proach is not very sensitive to its four parameters, 
and could converge very quickly to get a local 
optimum.  
In this study, we employ only cosine measure, 
sliding window measure and vector measure to 
compute similarity. These are too general, and 
perhaps not so suitable for sentiment classifica-
tion. In the future, we will try other methods to 
calculate the similarity. Furthermore, we experi-
ment our approach on only three domains, and 
we will apply our approach to many more do-
mains. 
5 Acknowledgments 
This work was mainly supported by two funds, 
i.e., 60933005 & 60803085, and two another pro-
jects, i.e., 2007CB311100 & 2007AA01Z441. 
References 
Alina Andreevskaia and Sabine Bergler. 2008. When 
Specialists and Generalists Work Together: Over-
coming Domain Dependence in Sentiment Tagging. 
In Proceedings of ACL: 290-298. 
Anthony Aue and Michael Gamon. 2005. Customiz-
ing sentiment classifiers to new domains: a case 
study. In Proceedings of RANLP. 
Sergey Brin, Lawrence Page, Rajeev Motwami, and 
Terry Winograd. 1999. The PageRank citation 
ranking: bringing order to the web. Technical Re-
port 1999-0120, Stanford, CA. 
Chinchung Chang and Chinjen Lin. 2001. LIBSVM: a 
library for support vector machines. 
http://www.csie.ntu.edu.tw/~cjlin/libsvm. 
Gunes Erkan and Dragomir Radev. 2004. LexRank: 
Graph-based Centrality as Salience in Text Sum-
marization. Journal of Artificial Intelligence Re-
search, 22 (2004): 457-479. 
Michael Gamon and Anthony Aue. 2005. Automatic 
identification of sentiment vocabulary: exploiting 
low association with known sentiment terms. In 
Proceedings of the ACL Workshop on Feature En-
gineering for Machine Learning in NLP: 57-64. 
Songbo Tan, Xueqi Cheng, Moustafa Ghanem, Bin 
Wang, Hongbo Xu. 2005. A novel refinement ap-
proach for text categorization. In Proceedings of 
CIKM 2005: 469-476 
Thorsten Joachims. 1999. Transductive inference for 
text classification using support vector machines. 
In Proceedings of ICML. 
Jon Kleinberg. 1998. Authoritative sources in a hyper-
linked environment. Journal of the ACM, 46(5): 
604-632. 
Lunwei Ku, Yuting Liang, and Hsinhsi Chen. 2006. 
Opinion extraction, summarization and tracking in 
news and blog corpora. In Proceedings of AAAI. 
Thomas Landauer, Peter Foltz, and Darrell Laham. 
1998. Introduction to latent semantic analysis. Dis-
course Processes 25: 259-284. 
Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike 
Wells, and Jeff Reynar. 2007. Structured models 
for fine-to-coarse sentiment analysis. In Proceed-
ings of ACL. 
Songbo Tan, Yuefen Wang, Gaowei Wu, and Xueqi 
Cheng. 2007. A novel scheme for domain-transfer 
problem in the context of sentiment analysis. In 
Proceedings of CIKM. 
Songbo Tan, Xueqi Cheng, Yuefen Wang, and 
Hongbo Xu. 2009. Adapting Na?ve Bayes to Do-
main Adaptation for Sentiment Analysis. In Pro-
ceedings of ECIR. 
Qiong Wu, Songbo Tan and Xueqi Cheng. 2009. 
Graph Ranking for Sentiment Transfer. In Proceed-
ings of ACL-IJCNLP. 
Peter Turney. 2001. Mining the web for synonyms: 
PMI-IR versus LSA on TOEFL. In Proceedings of 
ECML: 491-502. 
 
1335
