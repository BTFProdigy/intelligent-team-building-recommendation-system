  
CRF-based Hybrid Model for Word Segmentation, NER and even 
POS Tagging 
Zhiting Xu, Xian Qian, Yuejie Zhang,  Yaqian Zhou 
Department of Computer Science & Engineering, 
Shanghai Key Laboratory of Intelligent Information Processing, 
Fudan University, Shanghai 200433, P. R. China 
 {zhiting, qianxian, yjzhang, zhouyaqian}@fudan.edu.cn 
 
  
Abstract 
This paper presents systems submitted to 
the close track of Fourth SIGHAN Bakeoff. 
We built up three systems based on Condi-
tional Random Field for Chinese Word 
Segmentation, Named Entity Recognition 
and Part-Of-Speech Tagging respectively. 
Our systems employed basic features as 
well as a large number of linguistic features. 
For segmentation task, we adjusted the BIO 
tags according to confidence of each char-
acter. Our final system achieve a F-score of 
94.18 at CTB, 92.86 at NCC, 94.59 at SXU 
on Segmentation, 85.26 at MSRA on 
Named Entity Recognition, and 90.65 at 
PKU on Part-Of-Speech Tagging. 
1 Introduction 
Fourth SIGHAN Bakeoff includes three tasks, that 
is, Word Segmentation, Named Entity Recognition 
(NER) and Part-Of-Speech (POS) Tagging. In the 
POS Tagging task, the testing corpora are pre-
segmented. Word Segmentation, NER and POS 
Tagging could be viewed as classification prob-
lems. In a Segmentation task, each character 
should be classified into three classes, B, I, O, in-
dicating whether this character is the Beginning of 
a word, In a word or Out of a word. For NER, each 
character is assigned a tag indicating what kind of 
Named Entity (NE) this character is (Beginning of 
a Person Name (PN), In a PN, Beginning of a Lo-
cation Name (LN), In a LN, Beginning of an Or-
ganization Name (ON), In an ON or not-a-NE). In 
POS tagging task defined by Fourth SIGHAN Ba-
keoff, we only need to give a POS tag for each 
given word in a context. 
We attended the close track of CTB, NCC, SXU 
on Segmentation, MSRA on NER and PKU on 
POS Tagging. In the close track, we cannot use 
any external resource, and thus we extracted sev-
eral word lists from training corpora to form multi-
ple features beside basic features. Then we trained 
CRF models based on these feature sets. In CRF 
models, a margin of each character can be gotten, 
and the margin could be considered as the confi-
dence of that character. For the Segmentation task, 
we performed the Maximum Probability Segmen-
tation first, through which each character is as-
signed a BIO tag (B represents the Beginning of a 
word, I represents In a word and O represents Out 
of a word). If the confidence of a character is lower 
than the threshold, the tag of that character will be 
adjusted to the tag assigned by the Maximum 
Probability Segmentation (R. Zhang et al, 2006). 
2 Conditional Random Fields 
Conditional Random Fields (CRFs) are a class of 
undirected graphical models with exponent distri-
bution (Lafferty et al, 2001). A common used spe-
cial case of CRFs is linear chain, which has a dis-
tribution of: 
)),,,(exp(1)|(
1
1??
=
?? =
T
t k
ttkk
x
txyyf
Z
xyP rrr
r
?  (1) 
where ),,( 1 txyyf ttk
r
? is a function which is usu-
ally an indicator function; k?  is the learned weight 
of feature kf ; and xZ r is the normalization factor. 
The feature function actually consists of two kinds 
of features, that is, the feature of single state and 
the feature of transferring between states. Features 
will be discussed in section 3. 
167
Sixth SIGHAN Workshop on Chinese Language Processing
  
Several methods (e.g. GIS, IIS, L-BFGS) could 
be used to estimate k? , and L-BFGS has been 
showed to converge faster than GIS and IIS. To 
build up our system, we used Pocket CRF1. 
3 Feature Representation 
We used three feature sets for three tasks respec-
tively, and will describe them respectively. 
3.1 Word Segmentation 
We mainly adopted features from (H. T. Ng et al, 
2004, Y. Shi et al, 2007), as following: 
a) Cn(n=-2, -1, 0, 1, 2) 
b) CnCn+1(n=-2,-1,0,1) 
c) C-1C1 
d) CnCn+1Cn+2 (n=-1, 0, 1) 
e) Pu(C0) 
f) T(C-2)T(C-1)T(C0)T(C1)T(C2) 
g) LBegin(C0), Lend(C0) 
h) Single(C0) 
where C0 represents the current character and Cn 
represents the nst character from the current charac-
ter. Pu(C0) indicates whether current word is a 
punctuation. this feature template helps to indicate 
the end of a sentence. T(C) represents the type of 
character C. There are four types we used: (1) Chi-
nese Number (??/one?, ??/two?, ??/ten?); (2) 
Chinese Dates (??/day?, ??/month?, ??/year?); 
(3) English letters; and (4) other characters. The (f) 
feature template is used to recognize the Chinese 
dates for the construction of Chinese dates may 
cause the sparseness problem. LBegin(C0) represents 
the maximum length of the word beginning with 
the character C0, and Lend(C0) presents the maxi-
mum length of the word ending with the character 
C0. The (g) feature template is used to decide the 
boundary of a word. Single(C0) shows whether cur-
rent character can form a word solely. 
3.2 Named Entity Recognition 
Most features described in (Y. Wu et al, 2005) are 
used in our systems. Specifically, the following is 
the feature templates we used: 
a) Surname(C0): Whether current character is in 
a Surname List, which includes all first char-
acters of PNs in the training corpora. 
                                                 
1 
http://sourceforge.net/project/showfiles.php?group_id=201943 
b) PersonName(C0C1C2, C0C1): Whether C0C1C2, 
C0C1 is in the Person Name List, which con-
tains all PNs in the training corpora. 
c) PersonTitle(C-2C-1): Whether C-2C-1 is in the 
Person Title List, which is extracted from the 
previous two characters of each PN in the 
training corpora. 
d) LocationName(C0C1,C0C1C2,C0C1C2C3): 
Whether C0C1,C0C1C2,C0C1C2C3 is in the Lo-
cation Name List, which includes all LNs in 
the training corpora. 
e) LocationSuffix(C0): Whether current character 
is in the Location Suffix List, which is con-
structed using the last character of each LN in 
the training corpora. 
f) OrgSuffix(C0): Whether current character is in 
the Organization Suffix List, which contains 
the last-two-character of each ON in the train-
ing corpora. 
3.3 Part-Of-Speech Tagging 
We employed part of feature templates described 
in (H. T. Ng et al, 2004, Y. Shi et al, 2007). Since 
we are in the close track, we cannot use morpho-
logical features from external resources such as 
HowNet, and we used features that are available 
just from the training corpora. 
a) Wn, (n=-2,-1,0,1,2) 
b) WnWn+1, (n=-2,-1,0,1) 
c) W-1W1 
d) Wn-1WnWn+1 (n=-1, 1) 
e) Cn(W0) (n=0,1,2,3) 
f) Length(W0) 
where Cn represents the nth character of the current 
word, and Length(W0) indicates the length of the 
current word. 
4 Reliability Evaluation 
In the task of Word Segmentation, the label of each 
character is adjusted according to their reliability. 
For each sentence, we perform Maximum Prob-
ability Segmentation first, through which we can 
get a BIO tagging for each character in the sen-
tence. 
After that, the features are extracted according 
to the feature templates, and the weight of each 
feature has already been estimated in the step of 
training. Then marginal probability for each char-
acter can be computed as follows: 
168
Sixth SIGHAN Workshop on Chinese Language Processing
  
)),(exp(
)(
1)|( yxf
xZ
xyp ii
rr ?=     (2) 
The value of )|( xyp
r
 becomes the original re-
liability value of BIO label y for the current char-
acter under the current contexts. If the probability 
of y  with the largest probability is lower than 0.75, 
which is decided according to the experiment re-
sults, the tag given by Maximum Probability Seg-
mentation will be used instead of tag given by CRF. 
The motivation of this method is to use the Maxi-
mum Probability method to enhance the F-measure 
of In-Vocabulary (IV) Words. According to the 
results reported in (R. Zhang et al, 2006), CRF 
performs relatively better on Out-of-Vocabulary 
(OOV) words while Maximum Probability per-
forms well on IV words, so a model combining the 
advantages of these two methods is appealing. One 
simplest way to combine them is the method we 
described. Besides, there are some complex meth-
ods, such as estimation using Support Vector Ma-
chine (SVM) for CRF, CRF combining boosting 
and combining Margin Infused Relaxed Algorithm 
(MIRA) with CRF, that might perform better. 
However, we did not have enough time to imple-
ment these methods, and we will compare them 
detailedly in the future work. 
5 Experiments 
5.1 Results on Fourth SIGHAN Bakeoff 
We participated in the close track on Word Seg-
mentation on CTB, NCC and SXU corpora, NER 
on MSRA corpora and POS Tagging on PKU cor-
pora. 
For Word Segmentation and NER, our memory 
was enough to use all features. However, for POS 
tagging, we did not have enough memory to use all 
features, and we set a frequency cutoff of 10; that 
is, we could only estimate variables for those fea-
tures that occurred more than ten times. 
Our results of Segmentation are listed in the Ta-
bel 1, the results of NER are listed in the Tabel 2, 
and the results of POS Tagging are listed in the 
Tabel 3. 
 R P F Roov Riv 
CTB 0.9459 0.9418 0.9439 0.6589 0.9628 
NCC 0.9396 0.9286 0.9341 0.5007 0.9614 
SXU 0.9554 0.9459 0.9507 0.6206 0.9735 
Tabel 1. Results of Word Segmentation 
MSRA P R F 
PER 0.8084 0.8557 0.8314 
LOC 0.9138 0.8576 0.8848 
ORG 0.8666 0.773 0.8171 
Overall 0.873 0.8331 0.8526 
Tabel 2. Results of NER 
 
 Total-A IV-R OOV-R MT-R 
PKU 0.9065 0.9259 0.5836 0.8903 
Tabel 3. Results of POS Tagging 
5.2 Errors Analysis 
Observing our results of Word Segmentation and 
POS Tagging, we found that the recall of OOV is 
relatively low, this may be improved through in-
troducing features aiming to enhance the perform-
ance of OOV.  
On NER task, we noticed that precision of PN 
recognition is relative low, and we found that our 
system may classify some ONs as PNs, such as ??
??(Guinness)/ORG? and ?????(World Re-
cord)/)?. Besides, the bound of PN is sometimes 
confusing and may cause problems. For example, 
???/PER ?/ ?/ ??? may be segmented as 
????/PER ?/ ???. Further, some words be-
ginning with Chinese surname, such as ????
??, may be classified as PN.  
For List may not be the real suffix. For example, 
?????? should be a LN, but it is very likely 
that ????? is recognized as a LN for its suffix 
???.  Another problem involves the characters in 
the Location Name list may not a LN all the time. 
In the context ???/ ??/?, for example, ??? 
means Chinese rather than China.  
For ONs, the correlative dictionary also exists. 
Consider sequence ??????, which should be a 
single word, ???? is in the Organization Name 
List and thus it is recognized as an ON in our sys-
tem. Another involves the subsequence of a word. 
For example, the sequence ?????????
??, which should be a person title, but ?????
????? is an ON. Besides, our recall of ON is 
low for the length of an ON could be very long. 
6 Conclusions and Future Works 
We built up our systems based on the CRF model 
and employed multiple linguistics features based 
on the knowledge extracted from training corpora. 
169
Sixth SIGHAN Workshop on Chinese Language Processing
  
We found that these features could greatly improve 
the performance of all tasks. Besides, we adjusted 
the tag of segmentation result according to the reli-
ability of each character, which also helped to en-
hance the performance of segmentation.  
As many other NLP applications, feature plays a 
very important role in sequential labeling tasks. In 
our POS tagging task, we could only use features 
with high frequency, but some low-frequency fea-
tures may also play a vital role in the task; good 
non-redundant features could greatly improve clas-
sification performance while save memory re-
quirement of classifiers. In our further research, we 
will focus on feature selection on CRFs. 
Acknowledgement 
This research was sponsored by National Natural 
Science Foundation of China (No. 60773124, No. 
60503070). 
References 
O. Bender, F. J. Och, and H. Ney. 2003. Maximum En-
tropy Models for Named Entity Recognition. Pro-
ceeding of CoNLL-2003. 
A. L. Berger, S. A. Della Pietra, and V. J. Della Pietra. 
1996. A Maximum Entropy Approach to Natural 
Language Processing. Computational Linguistics, 
22(1). 
H. L. Chieu, H. T. Ng. 2002. Named Entity Recognition: 
A Maximum Entropy Approach Using Global Infor-
mation. International Conference on Computational 
Linguistics (COLING). 
J. N. Darroch and D. Ratcliff. 1972. Generalized Itera-
tive Scaling for Log-Linear Models. The Annals of 
Mathematical Statistics, 43(5). 
J. Lafferty, A McCallum, and F. Pereira..2001. Condi-
tional Random Fields: Probabilistic Models for Seg-
menting and Labeling Sequence Data. In Proceed-
ings of the 18th International Conf. on Machine 
Learning (ICML). 
R. Li, J. Wang, X. Chen, X. Tao, and Y. Hu. 2004. Us-
ing Maximum Entropy Model for Chinese Text 
Categorization. Computer Research and Develop-
ment, 41(4). 
H. T. Ng and J. K. Low. 2004. Chinese Part-Of-Speech 
Tagging: One-at-a-Time or All-at-Once? Word-Base 
or Character-Based? Proceedings of Conference on 
Empirical Methods in Natural Language Processing 
(EMNLP). 
A. Ratnaparkhi. 1997. A Simple Introduction to Maxi-
mum Entropy Models for Natural Language Process-
ing. Institute for Research in Cognitive Science Re-
port, 97(8). 
F. Sha and F.Pereira. 2003. Shallow parsing with condi-
tional random fields. In Proceedings of HLT-NAACL. 
Y. Shi and M. Wang. 2007. A Dual-Layer CRFs Based 
Joint Decoding Method for Cascaded Segmentation 
and Labeling Tasks. In International Joint Confer-
ences on Artificial Intelligence (IJCAI). 
C. A. Sutton, K. Rohanimanesh, A. McCallum. 2004. 
Dynamic conditional random fields: factorized prob-
abilistic models for labeling and segmenting se-
quence data. In International Conference on Machine 
Learning (ICML). 
M. Volk, and S. Clematide. 2001. Learn - Filter - Apply 
-- Forget Mixed Approaches to Named Entity Rec-
ognition. Proceeding of the 6th International Work-
shop on Applications of Natural Language for Infor-
mation Systems. 
Y. Wu, J. Zhao, B. Xu and H. Yu. 2005. Chinese 
Named Entity Recognition Based on Multiple Fea-
tures. Proceedings of Human Language Technology 
Conference and Conference on Empirical Methods in 
Natural Language Processing (HLT/EMNLP). 
H. Zhang, Q. Liu, H. Zhang, and X. Cheng. 2002. Au-
tomatic Recognition of Chinese Unknown Words 
Based on Roles Tagging. Proceeding of the 19th In-
ternational Conference on Computational Linguistics. 
R. Zhang, G. Kikui and E. Sumita. 2006. Subword-
based tagging by conditional random fields for Chi-
neseword segmentation. Companion volume to the-
proceedings of the North American chapter of the 
Association for Computational Linguistics (NAACL). 
Y. Zhou, Y. Guo, X. Huang, and L. Wu. 2003. Chinese 
and English BaseNP Recognition Based on a Maxi-
mum Entropy Model. Journal of Computer Research 
and Development, 40(3). 
 
170
Sixth SIGHAN Workshop on Chinese Language Processing
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 129?132,
Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLP
English-Chinese Bi-Directional OOV Translation                            
based on Web Mining and Supervised Learning 
 
Yuejie Zhang, Yang Wang and Xiangyang Xue 
School of Computer Science 
Shanghai Key Laboratory of Intelligent Information Processing 
Fudan University, Shanghai 200433, P.R. China 
{yjzhang,072021176,xyxue}@fudan.edu.cn 
 
Abstract 
In Cross-Language Information Retrieval 
(CLIR), Out-of-Vocabulary (OOV) detection 
and translation pair relevance evaluation still 
remain as key problems. In this paper, an Eng-
lish-Chinese Bi-Directional OOV translation 
model is presented, which utilizes Web mining 
as the corpus source to collect translation pairs 
and combines supervised learning to evaluate 
their association degree. The experimental re-
sults show that the proposed model can suc-
cessfully filter the most possible translation 
candidate with the lower computational cost, 
and improve the OOV translation ranking ef-
fect, especially for popular new words. 
1 Introduction 
In Cross-Language Information Retrieval (CLIR), 
most of queries are generally composed of short 
terms, in which there are many Out-of-
Vocabulary (OOV) terms like named entities, 
new words, terminologies and so on. The transla-
tion quality of OOVs directly influences the pre-
cision of querying relevant multilingual informa-
tion. Therefore, OOV translation has become a 
very important and challenging issue in CLIR. 
The translation of OOVs can either be ac-
quired from parallel or comparable corpus (Lee, 
2006) or mining from Web (Lu, 2004). However, 
how to evaluate the degree of association be-
tween source query term and its target translation 
is quite important. In this paper, an OOV transla-
tion model is established based on the combina-
tion pattern of Web mining and translation rank-
ing. Given an OOV, its related information are 
gotten from search results by search engine, from 
which the possible translation terms in target 
language can be extracted and then ranked 
through supervised learning such as Support 
Vector Machine (SVM) and Ranking-SVM (Cao, 
2006). The basic framework of the translation 
model is shown in Figure 1. 
 
Figure 1. The basic framework of English-
Chinese Bi-Directional OOV translation model. 
2 Related Research Work 
With the rapid growth of Web information, in-
creasing new terms and terminologies cannot be 
found in bilingual dictionaries. The state-of-art 
OOV translation strategies tend to use Web itself 
as a big corpus (Wang, 2004; Zhang, 2004). The 
quick and direct way of getting required informa-
tion from Web pages is to use search engines, 
such as Google, Altavista or Yahoo. Therefore, 
many OOV translation models based on Web 
mining are proposed by researchers (Fang, 2006; 
Wu, 2007). 
By introducing supervised learning mechan-
ism, the relevance between original OOV term 
and extracted candidate translation can be accu-
rately evaluated. Meanwhile, the model proposed 
exhibits better applicability and can also be ap-
plied in processing OOVs with different classes. 
3 Chinese OOV Extraction based on 
PAT-Tree 
For a language that has no words boundary like 
Chinese, PAT-Tree data structure is adopted to 
extract OOV terms (Chien, 1997). The most out-
standing property of this structure is its Semi 
Infinite String, which can store all the semi-
strings of whole corpus in a binary tree. In this 
tree, branch nodes indicate direction of search 
129
and child nodes store information about index 
and frequency of semi infinite strings. With 
common strings being extracted, large amounts 
of noisy terms and fragments are also extracted. 
For example, when searching for the translation 
of English abbreviation term ?FDA?, some noisy 
Chinese terms are extracted, such as ????? 
(17 times), ?????? (16 times), ?????
?? (9 times). In order to filter noisy fragments, 
the simplified Local-Maxima algorithm is used 
(Wang, 2004). 
4 Translation Ranking based on Super-
vised Learning 
4.1 Ranking by Classification and Ordinal 
Regression 
Based on the extracted terms, the correct transla-
tion can be chosen further. A direct option is to 
rank them by their frequency or length. It works 
well when the OOV term has a unique meaning 
and all the Web snippets are about the same topic. 
However, in much more cases only the highly 
related fragments of OOV terms can be found, 
rather than their correct translations. To evaluate 
the relevance of translation pair precisely, SVM 
and Ranking-SVM are employed as classifier 
and ordinal regression model respectively. 
4.2 Feature Representation 
The same feature set is utilized by SVM and 
Ranking-SVM. 
(1) Term frequency: fq denotes the frequency of 
OOV to be translated in all the Web snippets 
of search results. tfi indicates the number of 
the translation candidate in all the snippets. 
dfi represents the number of Web snippets 
that contains the candidate. dft means the 
number of snippets that contains both OOV 
to be translated and the candidate. 
(2) Term length: Len( ) is the length of the can-
didate. 
(3) Cooccurrence Distance: C-Dist is the aver-
age distance between the OOV query and the 
translation candidate, computed as follows. 
( )
-
t
Sum Dist
C Dist
df
=            (1) 
where Sum(Dist) is the sum of distance in 
each translation pair of every snippet. 
(4) Length Ratio: This is the ratio of OOV query 
length and translation candidate length. 
(5) Rank Value: 
i. Top Rank (T-Rank): The rank of snippet 
that first contains the candidate. This 
value indicates the rank given by search 
engine. 
ii. Average_Rank (A-Rank): It is the aver-
age position of candidate in snippets of 
search results, shown as follows. ( )
idf
RankSum
RankA =?                  (2) 
where Sum(Rank) denotes the sum of 
every single rank value of snippets that 
contains the candidate. 
iii. Simple_Rank (S-Rank): It is computed 
based on Rank(i)=tfi*Len(i), which aims 
at investigating the impact of these two 
features on ranking translation. 
iv. R-Rank: This rank method is utilized as a 
comparison basis, computed as follows. 
( )
OOV
nn
f
f
L
S
RankR ??+?=? ?? 1            (3) 
where ? is set as 0.25 empirically, |Sn| 
represents the length of candidate term, 
L is the largest length of candidate terms, 
fn is tfi, and foov is fq in Feature (1). 
v. Df_Rank (D-Rank): It is similar to S-
Rank and computed based on Rank(i)= 
dfi *Len(i). 
(6) Mark feature: Within a certain distance 
(usually less than 10 characters) between the 
original OOV and candidate, if there is such 
a term like ????, ?????, ??????, 
??????, ??????, ?????, ???
??, ?????, ??????, this feature will 
be labeled as ?+1?, else ?-1? instead. 
Among these features above, some features 
come from search engine like (1) and (5) and 
some ones from heuristic rules like (3) and (6).  
Through the establishment of feature set, the 
translation candidate can be optimized efficiently 
and the noisy information can also be filtered. 
5 Experiment and Analysis 
5.1 Data Set 
For the performance evaluation of Chinese-
English OOV translation, the corpus of NER task 
in SIGHAN 2008 provided by Peking University 
is used. The whole corpus contains 19,866 per-
son names, 22,212 location names and 7,837 or-
ganization names, from which 100 person names, 
100 location names and 100 organization names 
are selected for testing. Meanwhile, 300 English 
named entities are chosen randomly from the 
terms of 9 categories, which include movie name, 
book title, organization name, brand name, ter-
minology, idiom, rare animal name, person name 
130
and so on. These new terms are used as the test-
ing data for English-Chinese OOV translation. 
5.2 Evaluation Metrics 
Three parameters are used for the evaluation of 
translation and ranking candidates. 
translatedbetotermsOOVofnumbertotal
nstranslatioNtopinntranslatiocorrectofnumber
RateInclusionN
=
??          (4) 
( )
translatedbetotermfornstranslatiocorrectofnumber
nstranslatioRtopinntransaltiocorrectofnumber
termecisionPrR
i
i
=
?     (5) 
( )
translatedbetotermsOOVofnumbertotal
termecisionPrR
ecisionPrR
T
i
i?
=
?
=
?
1
                    (6) 
where T denotes the number of testing entities. 
The first one is a measurement for translation 
and the others are used for ranking measurement. 
5.3 Experiment on Parameter Setting 
Frequency and length are two crucial features for 
translation candidates. To get the most related 
terms into top 10 before the final ranking, a pre-
rank testing is performed based on S-Rank, R-
Rank and D-Rank. It can be seen from Figure 2 
that the pre-rank by D-Rank exhibits better per-
formance in translation experiment. 
 
Figure 2. The impact of different Pre-Rank man-
ners on English-Chinese OOV translation. 
In search results, for some English OOV terms 
such as ?BYOB(????)?, there are few candi-
dates with better quality in top 20 snippets. 
Therefore, in order to find how many snippets 
are suitable in translation, the experiment on 
snippet number is performed. It can be observed 
from Figure 3 that the best performance can be 
obtained by utilizing 200 snippets. 
 
Figure 3. The impact of different snippet number 
on English-Chinese OOV translation. 
5.4 Experiment On English-Chinese Bi-
Directional OOV Translation 
The experimental results on 300 English new 
terms are shown in Table 1. 
N-Inclusion-Rate English-Chinese OOV Translation 
Top-1 0.313 
Top-3 0.587 
Top-5 0.627 
Top-7 0.707 
Top-9 0.763 
Table 1. The experimental results on English-
Chinese OOV translation. 
The experimental results on 300 Chinese 
named entities are shown in Table 2. 
N-Inclusion-
Rate
Person 
Name 
Location 
Name 
Organization 
Name 
 Top-1  0.210   0.510   0.110 
Top-3 0.390 0.800 0.280 
Top-5 0.490 0.900 0.400 
Top-7 0.530 0.920 0.480 
Top-9 0.540 0.930 0.630 
Table 2. The experimental results on Chinese-
English OOV translation. 
It can be observed from Table 2 that the per-
formance of Chinese location name translation is 
much higher than the other two categories. This 
is because most of the location names are famous 
cities or countries. The experimental results 
above demonstrate that the proposed model can 
be applicable in all kinds of OOV terms. 
5.5 Experiment on Ranking 
In SVM-based and Ranking-SVM-based ranking 
experiment, the statistics on training data are 
shown in Table 3. For SVM training data, the 
?Related? candidates are neglected. The experi-
mental results on ranking in English-Chinese and 
Chinese-English OOV translation are shown in 
Table 4 and 5 respectively. 
Number of   
Candidates Correct Related Indifferent
English-
Chinese 234 141 250 
Chinese-
English 240 144 373 
Table 3. Statistics of training data for ranking. 
English-
Chinese 
Top-1 
Inclusion
Top-3 
Inclusion 
R-
Precision
D-Rank 0.313 0.587 0.417 
T-Rank 0.217 0.430 0.217 
SVM 0.530 0.687 0.533 
Ranking-SVM 0.550 0.687 0.547 
Table 4. The experimental results on ranking in 
English-Chinese OOV translation. 
131
Chinese-
English 
Top-1 
Inclusion
Top-3 
Inclusion 
R-
Precision
TF-Rank 0.277 0.490 0.287 
T-Rank 0.197 0.387 0.207 
SVM 0.347 0.587 0.347 
Ranking-SVM 0.357 0.613 0.387 
Table 5. The experimental results on ranking in 
Chinese-English OOV translation. 
From the experiments above, it can be con-
cluded that the supervised learning significantly 
outperform the conventional ranking strategies. 
5.6 Analysis and Discussion 
Through analysis about the experimental results 
in extraction and ranking, it can be observed that 
the OOV translation quality is highly related to 
the following aspects. 
(1) The translation results are related to the 
search engine used, especially for some spe-
cific OOV terms. For example, given a query 
OOV term ??????, the mining result 
based on Google in China is ?three direct 
links?, while some meaningless information 
is mined by the other engines like Live Trans. 
(2) Some terms are conventional terminologies 
and cannot be translated literally. For exam-
ple, ?woman pace-setter?, a proper name with 
the particular Chinese characteristic, should 
be translated into ???????, rather than 
??????? or ????. 
(3) The proposed model is sensitive to the nota-
bility degree of OOV term. For famous per-
son name and book title, the translation per-
formance is very promising. However, for 
other OOV terms with lower notability, such 
as ?????? and ?????, the correct 
translation cannot even be retrieved by 
search engine. 
(4) Word Sense Disambiguation (WSD) should 
be added to improve the whole translation 
performance. Although most of OOVs have 
unique semantic definition, there are still a 
few OOVs with ambiguity. For example, 
?Rice? can either be a person name or a kind 
of food. Another example is ?AARP?, which 
also has two kinds of meaning, that is, ???
?????? and ????????. 
6 Conclusions and Future Work 
In this paper, the proposed model improves the 
acquirement ability for OOV translation through 
Web mining and solves the translation pair eval-
uation problem in a novel way by introducing 
supervised learning in translation ranking. In ad-
dition, it is very significant to apply the key 
techniques in traditional machine translation into 
OOV translation, such as OOV recognition, sta-
tistical machine learning, alignment of sentence 
and phoneme, and WSD. The merits of these 
techniques should be integrated. All these as-
pects above will become the research focus in 
our future work. 
 
Acknowledgments 
This paper is supported by National Natural 
Science Foundation of China (No. 60773124), 
National Science and Technology Pillar Program 
of China (No. 2007BAH09B03) and Shanghai 
Municipal R&D Foundation (No. 08dz1500109). 
Yang Wang is the corresponding author. 
References 
Chun-Jen Lee, Jason S. Chang, and Jyh-Shing R. Jang. 
2006. Alignment of Bilingual Named Entities in 
Parallel Corpora Using Statistical Models and 
Multiple Knowledge Sources. ACM Transactions 
on Asian Language Processing, 5(2):121-145. 
Gaolin Fang, Hao Yu, and Fumihito Nishino. 2006. 
Chinese-English Term Translation Mining Based 
on Semantic Prediction. In Proceedings of the 
COLING/ACL on Main Conference Poster Ses-
sions, pp.199-206. 
Jenq-Haur Wang, Jei-Wen Teng, Pu-Jen Cheng, Wen-
Hsiang Lu, and Lee-Feng Chien. 2004. Translating 
Unknown Cross-Lingual Queries in Digital Libra-
ries Using a Web-based Approach. In Proceedings 
of the 4th ACM/IEEE-CS Joint Conference on Dig-
ital Libraries, pp.108-116. 
Jian-Cheng Wu and Jason S. Chang. 2007. Learning 
to Find English to Chinese Transliterations on the 
Web. In Proceedings of the 2007 Joint Conference 
on Empirical Methods in Natural Language 
Processing and Computational Natural Language 
Learning, pp.996-1004. 
L. F. Chien. 1997. PAT-Tree-Based Keyword Extrac-
tion for Chinese Information Retrieval. In Proceed-
ings of SIGIR?97, pp.50-58. 
Wen-Hsiang Lu and Lee-Feng Chien. 2004. Anchor 
Text Mining for Translation of Web Queries: A 
Transitive Translation Approach. ACM Transac-
tions on Information Systems, 22(2): 242-269. 
Ying Zhang and Phil Vines. 2004. Detection and 
Translation of OOV Terms Prior to Query Time. In 
Proceedings of SIGIR?04, pp.524-525. 
Yunbo Cao, Jun Xu, Tie-Yan LIU, Hang Li, Yalou 
HUANG, and Hsiao-Wuen HON. 2006. Adapting 
Ranking SVM to Document Retrieval. In Proceed-
ings of SIGIR?06, pp.186-193. 
 
132
Coling 2010: Poster Volume, pages 1435?1443,
Beijing, August 2010
Fusion of Multiple Features and Ranking SVM for             
Web-based English-Chinese OOV Term Translation 
Yuejie Zhang, Yang Wang, Lei Cen, 
Yanxia Su, Cheng Jin, Xiangyang Xue 
School of Computer Science, Shanghai Key La-
boratory of Intelligent Information Processing, 
Fudan University 
{yjzhang,072021176,082024072, 
09210240074,jc,xyxue}@fudan.edu.cn
Jianping Fan 
Department of Computer 
Science, 
The University of North 
Carolina at Charlotte 
jfan@uncc.edu 
 
Abstract 
This paper focuses on the Web-based 
English-Chinese OOV term translation 
pattern, and emphasizes particularly on 
the translation selection strategy based 
on the fusion of multiple features and 
the ranking mechanism based on Rank-
ing Support Vector Machine (Ranking 
SVM). By utilizing the CoNLL2003 
corpus for the English Named Entity 
Recognition (NER) task and selected 
new terms, the experiments based on 
different data sources show the consis-
tent results. Our OOV term translation 
model can ?filter? the most possible 
translation candidates with better abili-
ty. From the experimental results for 
combining our OOV term translation 
model with English-Chinese Cross-
Language Information Retrieval (CLIR) 
on the data sets of Text Retrieval Eval-
uation Conference (TREC), it can be 
found that the obvious performance 
improvement for both query translation 
and retrieval can also be obtained. 
1 Introduction 
In Cross-Language Information Retrieval 
(CLIR), most of users? queries are generally 
composed of short terms, in which there are 
many Out-of-Vocabulary (OOV) terms like 
Named Entities (NEs), new words, terminolo-
gies and so on. The translation quality of OOV 
term directly influences the precision of query-
ing relevant multilingual information. There-
fore, OOV term translation has become a very 
important and challenging issue in CLIR. 
With the increasing growth of Web informa-
tion which includes multilingual hypertext re-
sources with abundant topics, it appears that 
Web information can mitigate the problem of 
the restricted OOV term translation accuracy 
(Lu and Chien, 2002). However, how to select 
the correct translations from Web information 
and locate the appropriate translation resources 
rapidly is still the main goal for OOV term 
translation. Hence, finding the effective feature 
representation and the optimal ranking pattern 
for translation candidates is the core part for 
the Web-based OOV term translation. 
This paper focuses on the Web-based Eng-
lish-Chinese OOV term translation pattern, and 
emphasizes particularly on the translation se-
lection strategy based on the fusion of multiple 
features and the translation ranking mechanism 
based on Ranking Support Vector Machine 
(Ranking SVM). By utilizing the CoNLL2003 
corpus for the English Named Entity Recogni-
tion (NER) task and manually selected new 
terms in various fields, the established OOV 
term translation model can ?filter? the most 
possible translation candidates with better abil-
ity. This paper also attempts to apply the OOV 
term translation mechanism above in English-
Chinese CLIR. It can be observed from the 
experimental results on the data sets of Text 
Retrieval Evaluation Conference (TREC) that 
the obvious performance improvement for 
query translation can be obtained, which is 
very beneficial to CLIR and can improve the 
whole retrieval performance. 
2 Related Work 
At present, the methods for OOV term transla-
tion have changed from the basic pattern based 
on bilingual dictionary, transliteration or paral-
lel corpus to the intermediate pattern based on 
comparable corpus (Lee et al, 2006; Shao and 
Ng, 2004; Virga and Khudanpur, 2003), and 
1435
then become a new pattern based on Web min-
ing (Fang et al, 2006; Sproat et al, 2006). 
In recent years, many researchers have uti-
lized Web to find the translation candidates on 
webpages (Wu and Chang, 2007). Al-Onaizan 
and Knight (2002) used Web statistics infor-
mation to validate the translation candidates 
generated by language model, and obtained the 
accuracy of 72.6% in Arabic-English OOV 
word translation. Lu and Chien (2004) utilized 
the statistics information about the anchor texts 
in Web search results to recognize the transla-
tion candidates, and got the accuracy of 63.6% 
in English-Chinese title query term translation. 
Zhang and Vines (2004) extracted the transla-
tion candidates for OOV query terms in CLIR 
from Web, and improved the performance of 
English-Chinese/Chinese-English CLIR to 
some extent. Zhang et al (2005) searched the 
translation candidates by using cross-language 
query expansion and Web, and obtained the 
Top-1 accuracy of 81.0% in Chinese-English 
OOV word translation. Chen and Chen (2006) 
used the combination of Web statistics and the 
vocabulary, and acquired the Top-1 accuracy 
of 87.6% in Chinese-English OOV word trans-
lation. Jiang et al (2007) utilized the combina-
tion of Web mining, transliteration and ranking 
based on Maximum Entropy (ME), only fo-
cused on English-Chinese person name transla-
tion and got the Top-1 accuracy of 47.5%. 
Although the methods above can improve 
the translation performance for OOV term to a 
certain degree, there are still three common 
problems in the OOV term translation based on 
Web mining. (1) Chinese key term extraction 
pattern from Web documents is over com-
plex and the complexity is always higher. 
Because of the inherent property of having no 
segmentation delimitation in Chinese, it?s very 
difficult for English-Chinese OOV term trans-
lation to extract Chinese key terms from Web 
documents. The cost for the extraction compu-
tation is generally overlarge (Wang et al, 2004; 
Zhang and Vines, 2004). (2) The feature in-
formation for the evaluation of translation 
candidates is not enough and comprehensive. 
Most of OOV term translation methods im-
plement the evaluation for candidates through 
mining simple local and Boolean features, that 
is, inherent features in candidates and their 
surrounding context features. However, if only 
a certain Web document that an OOV term 
appears is explored, the global information 
contained in the whole Web document set will 
be ignored, and the inconsistency and polyse-
my of candidates cannot be considered. (3) 
The relevance measurement for translation 
pairs is very simple, or the computation cost 
is too high. For ranking candidates, most of 
OOV term translation approaches adopt the 
simple combination computation of the feature 
values used, or get assessment based on classi-
fication models. Hence, the feature weights are 
determined according to the corresponding 
induction and suitable for some specific fields, 
but cannot guarantee the accuracy of the final 
translation ranking results. However, the Rank-
ing SVM model can effectively express mul-
tiple ranking constraints, and has better univer-
sality and applicability (Cao et al, 2006; Joa-
chimes, 2002; Vapnik, 1995). 
3 Our Solutions 
To support more precise English-Chinese 
OOV term translation, we establish a multiple-
feature-based translation pattern based on Web 
mining and Ranking SVM. On the one hand, a 
Chinese key term extraction strategy is built on 
the simplified extraction computation for PAT-
Tree, in which the optimization processing for 
the confidence of word building is improved to 
a certain extent. On the other hand, translation 
candidates are chosen by the fusion of multiple 
features. The representation forms of local, 
global and Boolean feature are constructed 
under the consideration of the complex charac-
teristics of English/Chinese OOV term and 
Web information. Moreover, for the relevance 
measurement between an OOV term to be 
translated and its translation candidates, the 
supervised learning based on Ranking SVM is 
introduced to rank candidates precisely. 
At first, given an OOV term to be translated 
as a query, it is input into the Google search 
engine to acquire the returned webpage snippet 
set. Next, Chinese key terms are extracted 
from the PAT-Tree built on the snippet set to 
determine the translation candidates. Subse-
quently, local, global and Boolean features are 
extracted from the candidates based on the fu-
sion of multiple features. Finally, the candi-
dates are filtered and ranked through the su-
pervised learning based on Ranking SVM. 
1436
4 Chinese Key Term Extraction 
In Web mining of English-Chinese OOV term 
translation, an important problem is to extract 
the target translation candidates from the re-
turned Chinese Web documents, which can be 
considered as a key term extraction task. 
The PAT-Tree structure is an efficient in-
dexing method in both IR and Information Ex-
traction (IE) domains (Chien, 1997; Gonnet et 
al., 1992). Its superior feature is the Semi Infi-
nite String, which can store all the strings from 
the whole corpus (i.e., the returned snippet set 
in this paper) in a binary tree. The branch node 
indicates the search direction and the leaf node 
stores the index and frequency for a string. 
Generally, a Chinese character corresponds 
to a binary-coded form with 2 bytes (16 bits). 
Chinese strings can be transformed into binary 
strings. There is an ending tag for each string 
and its binary form is ?00000000?. Take ???
????? (Chinese IE) and ?????? (IR) 
as an example, the binary strings for them are 
described in Figure 1. Thus a PAT-Tree can be 
built based on these strings, as shown in Figure 
2. The branch node stands for the comparison 
bit (Comp-bit), which represents the position 
of different bit in binary strings. Some binary 
strings have the value of 0 in such a bit and are 
classified into the left branch, while others 
have 1 and turn to the right branch. 
 Figure  1. Binary string representation instantiation. 
 
Figure 2. PAT-Tree Instantiation for Figure 1. 
In the extraction process, the PAT-tree is 
traversed first, and the branch nodes with the 
Comp-bit values larger than 32 are selected. 
This is because the minimum length of a Chi-
nese common string is 2 characters and each 
has 16 binary bits. Next, the frequency values 
of both two child nodes are added as the fre-
quency of the common string (i.e., the parent 
branch node). At last, the common strings with 
the frequency values larger than 2 are extracted 
as the key terms. For the PAT-Tree in Figure 2, 
there is a branch node with the Comp-bit value 
of 37, which indicates that at least the prefixes 
of two strings contain two identical characters. 
It can be known from the leaf nodes that two 
strings are ?????? (IE) and ?????? 
(IR). Hence, the prefix substring ???? (in-
formation) with the frequency of 2 is extracted 
as the common string. Thus the key terms with 
the arbitrary lengths and frequency values can 
be retrieved from the built PAT-Tree. 
However, with the common strings being 
extracted, large amounts of noisy terms and 
fragments are also extracted. To filter noisy 
fragments, Wang et al (2004) used SPDCD 
and the Local-Maxima algorithm, but the com-
putation cost was too expensive. Therefore, the 
simplified filtering manner is adopted here: 
( ) ( ) ( )( ) )1(
1
ji
nji
ji
ccf
ccfccf
cc L
LLL ?=?
 
where c1?cn is a n-gram that contains the sub-
string ci?cj; ci?cj is the n-1-gram to be esti-
mated, i.e., ci?cj=c1?cn-1 or ci?cj=c2?cn; f( ) 
denotes the string frequency; ? represents the 
cohesion factor of the n-1-gram string, that is, 
the ability of independent word building. The 
closer to 1 the value of ? is, the more possible 
meaningful key term ci?cj is. 
5 Multiple Feature Representation 
Local Feature (LF) is constructed based on 
neighboring tokens and the token itself. There 
are two types of contextual information to be 
considered when extracting LFs, namely inter-
nal lexical and external contextual information. 
(1) Term length (Len) ? Aims to consider the 
length of the translation candidate. 
(2) Phonetic Value (PV) ? Aims to investigate 
the phonetic similarity between an OOV term 
and its translation candidates. Because the as-
sociated syllabification representations can 
often be found between Chinese and English 
syllables with fewer ambiguities, the syllabifi-
cation has become an effective channel in pho-
netic feature expression. PV means that for 
measuring the edit distance similarity between 
the syllabification sequences of an OOV term 
1437
and its candidates, the processing is executed 
according to the specific linguistic rules. 
( ) ( )( ) ( ) )2(''
','
1,
OOVOOV
OOVOOV
OOVOOV TLenSLen
TSEditDist
TSPV +?=
 
where SOOV and TOOV denote the OOV term in 
the source language and its translation candi-
date in the target language respectively, SOOV? 
and TOOV? are the character strings after the 
syllabification and removing the vowels, 
EditDist( , ) indicates the edit distance between 
two strings, and Len( ) is the string length. 
(3) Length Ratio of OOV Term and Its 
Translation Candidate (LR) ? Aims to ex-
plore the composition possibility that the ex-
tracted key term can be regarded as the transla-
tion for an OOV term. An OOV term and its 
translation should have the similar length, so 
the LR value is close to 1 as possible. A Chi-
nese term is segmented into significant pieces 
first, and the number of pieces is taken as its 
length. For example, ??????? (SARS) is 
segmented into ??? (non), ???? (typical) 
and ???? (pneumonia), and its length is 3. 
For an English term, the number of words is 
counted as the length. If there is only one word 
composed of capital letters, its length is de-
fined as the number of letters, e.g., ?SARS? has 
the length of 4. Thus the LR value of ?SARS? 
and its candidate ??????? is 4/3=1.3. 
(4) Phonetic and Semantic Integration Fea-
ture (P&S_IF) ? Aims to consider the phonet-
ic information and senses of an OOV term and 
its candidates synthetically. It is set up for mul-
ti-word OOV terms, especially for NEs and 
new terms. Each constituent can be translated 
by the phonetic information or senses. ( )
( ) ( )
( ) )3(1,
'','',
,_&
+
+=
OOVOOV
OOVOOVOOVOOV
OOVOOV
TSLScore
TSPVTSLScore
TSIFSP
 
where LScore( , ) is the matching word number 
of non-transliteration words in SOOV and TOOV, 
while SOOV?? and TOOV?? are the remaining 
strings of SOOV and TOOV after computing 
LScore. For example, given SOOV ?Capitoline 
Museum? and its TOOV ?????????? 
(Capitoline Museum), the non-transliteration 
words ?Museum? and ????? (museum) are 
matched, then LScore(SOOV, TOOV)=1; the PV 
value between the remaining strings ?Capito-
line? and ??????? (Capitoline) is 0.8, so 
the final P&S_IF value is 1.8/2=0.9. 
Global Feature (GF) is extracted from other 
occurrences of the same or similar tokens in 
the Web document set. The common case in 
the Web-based OOV term translation is that 
the translation candidates in the previous parts 
of Web documents will often occur with the 
same or similar forms in the latter parts. The 
contextual information from the same and oth-
er Web documents may play an important role 
in determining the final translation. To utilize 
such global information, GFs are constructed 
based on the characteristics of Web documents. 
(1) Global Term Frequency (G_Freq) ? 
Aims to utilize the frequency information that 
an OOV term and its translation candidates 
appear in the Web document set. It is always 
the most important feature and includes four 
parameters. FreqSOOV denotes the frequency of 
SOOV in all the returned webpage snippets. 
TFTOOV indicates the number of TOOVs in all the 
snippets. DFTOOV represents the number of 
snippets that contain TOOV. CO_Freq means 
the number of snippets that contain both SOOV 
and TOOV, i.e, co-occurrence frequency. 
(2) Chi-Square (?2) Feature Value (CV) ? 
Aims to evaluate the semantic similarity be-
tween an OOV term and its translation candi-
dates by their occurrence in Web documents. 
( ) ( )( ) ( ) ( ) ( ) )4(,
2
2
dcdbcaba
cbdaN
TSCV OOVOOV +?+?+?+
????=?  
where a is the number of snippets that contain 
both SOOV and TOOV, b is the number of snippets 
that contain SOOV but do not contain TOOV, c is 
the number of snippets that do not contain SOOV 
but contain TOOV, d is the number of snippets 
that do not contain neither of SOOV and TOOV, 
and N=a+b+c+d. 
(3) Co-occurrence Distance (CO_Dist) ? 
Aims to investigate the distance between an 
OOV term and its candidates in Web docu-
ments. This distance is often very closer. 
For each snippet that contains both SOOV and 
TOOV, three positions are considered, that is, the 
first position that SOOV and TOOV appear (p1), 
the second position (p2) and the last one (p3). 
In the following snippet, SOOV is ?AARP? and 
TOOV is ????????? (America Associa-
tion of Retired Persons, AARP). 
 
p1SOOV=6, p2SOOV=62, p3SOOV=97; 
p1TOOV=54, p2TOOV=-1, p3TOOV=54. 
1438
The position is indexed from 0 and p2TOOV=-1 
means only one candidate exists in the snippet. 
Then the nearest position pair p2SOOV and p1TOOV 
can be found for this example. The distance 
Dist between SOOV and TOOV is computed as: 
( ) ( )( ) )5(,
,
,
??
?
<??
>??=
OOVOOVOOVOOV
OOVOOVOOVOOV
TSOOVST
TSOOVTS
OOVOOV pjpiSLenpipj
pjpiTLenpjpi
TSDist
Given the example above, Dist=p2SOOV-p1TOOV-7 
=62-54-7=1, that is, SOOV and TOOV are a left 
bracket ?(? apart. Finally, the average distance 
CO-Dist in the snippet set can be computed as: ( ) ( )
( )
( ) )6(,_
,_,_
OOVOOV
OOVOOVOOVOOV
TSFreqCO
DistSum
TSDistAVGTSDistCO
=
=
 
where Sum( ) is the sum of Dist in each snippet. 
(4) Rank Value (RV) ? Aims to consider the 
rank for translation candidates in the Web doc-
ument set. It includes five parameters. 
Top_Rank (T_Rank) is the rank of the snippet 
that first contains TOOV and given by the search 
engine. Average_Rank (A_Rank) is the aver-
age position of TOOV in the returned snippets. 
( ) ( )( ) )7(_ OOVTOOV TDF
RankSum
TRankA
OOV
=  
where Sum( ) denotes the rank sum of each 
snippet. Simple_Rank (S_Rank) is computed 
as S_Rank(TOOV)=TFTOOV(TOOV)*Len(TOOV), 
which aims at investigating the impact of the 
frequency and length of TOOV on ranking. 
R_Rank is utilized as a comparison basis. 
( ) ( ) ( )( ) )8(1__ OOVS
OOVTOOV
OOV SFreq
TTF
WLMAX
T
TRankR
OOV
OOV??+?= ??  
where ? is set as 0.25 empirically, |TOOV| is the 
length of TOOV, and MAX_WL denotes the max-
imum length of candidate terms. DF_Rank 
(D_Rank) is similar to S_Rank and computed 
as D_Rank(TOOV)=DFTOOV(TOOV)*Len(TOOV). 
Boolean Feature (BF) is a binary feature and 
equivalent to a heuristic rule designed for the 
particular relationship between an OOV term 
and its translation candidates. BFs are used to 
explore the different occurrence forms with 
higher possibility for the translation candidates 
in Web documents. (1) Position Distance with 
OOV Term (PD_SOOV) ? If TOOV occurs close 
to SOOV (within 10 characters), then this feature 
is set as 1, else -1. (2) Neighbor Relationship 
with OOV Term (NR_SOOV) ? If TOOV occurs 
prior or next to SOOV, then this feature is set as 
1. (3) Bracket Neighbor Relationship with 
OOV Term (BNR_SOOV) ? If TOOV locates 
prior or next to SOOV and occurs with the form 
?TOOV (SOOV)? or ?SOOV (TOOV)?, then this fea-
ture is set as 1. (4) Special Mark Word (SMW) 
? This is an intuitive feature. Within a certain 
co-occurrence distance (usually less than 10 
characters) between an OOV term and its can-
didates, if there is such a term like ???? (full 
name), ??? (be named as), ???? (be trans-
lated as ?), ???? (name), or ?(?/?)??? 
((or/also) be called as ?), or within 5 charac-
ters if there are some punctuations like ?( )?, 
?[ ]? and ????, then this feature is set as 1. 
6 Ranking based on Ranking SVM 
For the OOV term translation based on Web 
mining, another difficulty is how to evaluate 
the relevance between an OOV term and its 
translation candidates, that is, how to rank the 
translation candidates from ?best? to ?worst?. 
The candidate ranking can be regarded as a 
binary classification problem. However, 
usually only highly related fragments of OOV 
terms can be found, rather than their correct 
translations. Instead of regarding the candidate 
ranking as binary classification, it is solved as 
an Ordinal Regression problem. Ranking 
SVM maps different objects into a certain kind 
of order relation. The key is modeling the 
judgements for user?s preferences, and then the 
constraint relations for ranking can be derived 
(Herbrich et al, 1999; Xu et al, 2005). 
For a given OOV term SOOV, if there are two 
translation candidates TOOVi and TOOVj, the pre-
ference judgement can be formulated as     
TOOVi>SOOVTOOVj. Thus more training samples are 
constructed, which contain multiple constraint 
features. The preference judgement can be 
transformed into the feature function as: ( ) ( ) )9(,,,, OOVjOOVSOOViOOV STwfSTwf OOV>  
where w is a parameter and represented as a n-
dimensional vector w={w1, w2, ?, wn}. This 
feature function can also be expressed as: 
( ) ( )
( ) ( ) )10(,,
,,,
11
1
??
?
+=+=
=
+
+=
n
qm
OOVOOVmm
q
pl
OOVOOVll
p
k
OOVOOVkkOOVOOV
STBFwSTGFw
STLFwSTwf  
where LFk( , ), GFl( , ) and BFm( , ) are  the 
local, global and Boolean feature representa-
tion respectively. These three kinds of feature 
representation are incorporated as a whole and 
represented as a feature function family with 
the multi-dimensional feature vector in (11). ( ) ( ) )11(,,, OOVOOVOOVOOV SThwSTwf ?=  
1439
That is the ranking results for candidates. Thus 
the relevance for each feature vector x (transla-
tion candidate) containing a group of features 
can be evaluated through Ranking SVM. 
7 Experiment and Analysis 
7.1 Data Set and Evaluation Metrics 
For the performance evaluation, 4,593 English 
NEs are selected from the English corpus of 
the NER task in CoNLL2003. The test set con-
tains 446 Person Names (PRNs), 329 Location 
Names (LCNs) and 455 Organization Names 
(OGNs), and the remaining is taken as the 
training set (including 1,137 PRNs, 1,152 
LCNs and 1,074 OGNs) through manually 
tagging. Additionally, 300 English new terms 
are chosen randomly from 9 categories, includ-
ing movie name, book title, brand name, ter-
minology, idiom, rare animal name, rare PRN 
and OGN. Such terms are used to investigate 
the generalization ability of our model. 
Top-N-Inclusion-Rate is used as a measure-
ment for the translation performance. For a set 
of OOV terms to be translated, its Top-N-
Inclusion-Rate is defined as the percentage of 
the OOV terms whose translations could be 
found in the first N extracted translations. 
7.2 Experiment on Parameter Setting 
For Chinese key term extraction, the test on the 
threshold ? is performed. As shown in Figure 3, 
when the lower bound of ? is set as 0.4, the 
best performance can be achieved. 
 
Figure 3. Results for ? value setting. 
To get the most relevant candidates into top-
10 before the final ranking, an initial ranking 
test is performed on S_Rank, R_Rank and 
D_Rank. It can be seen from Figure 4 that 
D_Rank exhibits the better performance. 
 
Figure 4. Results for initial ranking manner. 
To find how many returned webpage snip-
pets are suitable for the translation acquisition, 
the test on the snippet number is performed. As 
shown in Figure 5, the best performance can be 
obtained by using 200 snippets. 
 
Figure 5. Results for webpage snippet number. 
7.3  Experiment on Multiple Feature Fusion 
To verify the effectiveness for multiple feature 
fusion, the test on the feature combination for 
OOV term translation is implemented. As 
shown in Table 1, the highest accuracy (the 
percentage of the correct translations in all the 
extracted translations) of 83.1367% can be ac-
quired by using all the features. 
Feature Accuracy Reduction
All Features 83.1367% ?
Numerical 
Feature
Local 
Numerical 
Feature
-Len 81.7355% -1.4012%
-PV 77.4494% -5.6873%
-LR 81.4231% -1.7136%
-P&S_IF 79.9002% -3.2365%
Global 
Numerical 
Feature
Global 
Frequency
-TFTOOV 82.9877% -0.1490%
-DFTOOV 83.2112% +0.0745%
-CO_Freq 83.0870% -0.0497%
-CV 82.3125% -0.8242%
-CO_Dist 81.8577% -1.2790%
RV -T_Rank 83.0125% -0.1242%
Boolean Feature 
-PD_SOOV 82.1806% -0.9561%
-NR_SOOV 82.2923% -0.8444%
-BNR_SOOV 80.7525% -2.3842%
-SMW 83.1740% +0.0373%
Table 1. Results for feature combination. 
In Table 1, ?-? before the specific feature 
denotes that the OOV term is translated by 
combining all the other features except this 
feature; ?Reduction? represents the difference 
value between the translation accuracy ob-
tained by using all the features and that by re-
moving a specific feature. The positive ?Re-
duction? indicates that the accuracy is im-
proved after removing a specific feature, while 
the negative shows the accuracy is decreased. 
It can be seen from Table 1 that for mining 
the translations for OOV terms, the most im-
portant three features are PV, P&S_IF and 
BNR, then LR, Len and CO_Dist. As for the 
frequency feature, its contribution is limited, 
because many translation candidates with 
higher PV or P&S_IF values are the terms with 
low frequency. It shows that PV and P&S_IF 
play a very crucial role in mining the transla-
tion candidates with low frequency. In addition, 
1440
the contribution degree of CV is also positive. 
However, when training based on only the fea-
tures that are beneficial to the whole transla-
tion performance, the best translation accuracy 
is 83.1243%, which is worse than that by com-
bining all the features. From a view of the ef-
fect of the single feature on the whole transla-
tion performance, some features may have 
slightly negative impact. Nevertheless, through 
combining all the features, the multiple feature 
fusion mechanism can indeed efficiently im-
prove the translation accuracy. 
7.4   Experiment on OOV Term Translation 
Some translation examples based on different 
ranking patterns are given in Table 2, in which 
the score represents the correlation degree be-
tween the translation pair. The closer to -1 the 
score is, the more irrelevant the translation pair 
is; while the closer to 3 the score is, the more 
relevant the translation pair is. 
PRN -- ?Santamaria? 
Candidates (Top-5) SVM Score Ranking SVM Score
????? 1.1746 3.17754
????? 0.7087 2.81014
????? 0.9326 2.68914
??? 0.2879 2.26468
??????? 0.2051 2.1525
LCN -- ?Gettysburg National Military Park?
Candidates (Top-5) SVM Score Ranking SVM Score
?????????? 0.7500 2.4998
??????? 0.6666 2.4159
?????? 0.3973 1.8539
????????? 0.2877 1.5172
?????????????? -0.3407 0.8019
OGN -- ?Federal Reserve Board? 
Candidates (Top-5) SVM Score Ranking SVM Score
????? 0.9784 2.7435
????????? 0.9483 2.7314
???????? 0.5387 2.7178
????????? 1.2031 2.6684
??????? 0.7425 2.6003
Table 2. OOV term translation examples. 
Furthermore, Jiang et al (2007) utilized the 
combination of Web mining, transliteration 
and ME-based ranking to implement English-
Chinese PRN translation, which is very similar 
to our approach. To make a contrast with it, we 
accomplished this method on the same data set. 
The comparison results are shown in Table 3. 
Ranking Pattern Category Top-1 Top-2 Top-3
based on SVM 
(Multiple Features) 
PRN 64.44% 85.07% 91.42%
LCN 53.93% 73.33% 81.82%
OGN 49.68% 70.70% 82.16%
All 56.10% 76.59% 85.45%
based on Ranking-SVM 
(Multiple Features) 
PRN 77.14% 89.20% 93.96%
LCN 64.24% 75.15% 85.45%
OGN 63.05% 79.61% 89.17%
All 68.46% 81.87% 89.92%
[Jiang et al, 2007] 
 based on ME 
(PV+CV+NR_SOOV+BNR_SOOV) 
PRN 
(Only) 49.07% 57.33% 60.43%
Table 3. Performance comparison results. 
From the experimental results above, it can 
be concluded that the ranking based on the su-
pervised learning significantly outperforms the 
conventional ranking strategies, and Ranking 
SVM is superior to SVM and ME for transla-
tion candidate ranking. From the contrast be-
tween our model and Jiang?s method, it can be 
found that our approach is superior to Jiang?s 
and the better performance can be achieved 
based on the fusion of multiple features pro-
posed in this paper. Meanwhile, it can also be 
observed from Table 3 that the performance 
for LCN and OGN translation is better, while 
the best performance is obtained for PRN 
translation. It shows that our translation model 
is sensitive to the category and the popularity 
degree of OOV term to some extent. 
In order to test the translation performance 
for the other kinds of English OOV term, 
another test is performed based on the OOV 
new terms selected randomly from 9 categories. 
The experimental results are shown in Table 4. 
Top-N-Inclusion-Rate Top-1 Top-3 Top-5 Top-7 Top-9
Other OOV Terms 49.41% 71.02% 72.46% 81.51% 84.30%
Table 4. Results for other OOV terms. 
Furthermore, the translations for some OOV 
terms based on different translation manners 
are compared, including our proposed model, 
Google Translate and the Live Trans transla-
tion model developed by WKD Lab at Nation-
al Taiwan University, as shown in Table 5. 
OOV Terms Translation fromOur Model 
Translation from 
Google Translate 
Translation from
Live Trans 
Forrest Gump ????/?? ???? 
????/     
??????
Estee Lauder ????/      ??? ???? 
????/??
/???
Arteriosclerosis ???? ?????? ??/????
Woman
Pace-Setter ?????
?????/ 
?? ?????
Dream of
the Red Mansion ??/??? ??? 
???/       
????
SARS ?????/  ??
??????
????? 
??/         
?????
NASA ????? ????? ??????
Table 5. Comparison for different translation manners. 
The results above demonstrate that our 
model can be applicable to all kinds of OOV 
terms and has better translation performance. 
7.5 Experiment on English-Chinese CLIR 
To explore the applicability and usefulness of 
our OOV term translation model in English-
Chinese CLIR, four CLIR runs based on long 
query (terms in both title and description fields) 
and short query (only terms in the title field) 
are carried out on the English topic set (25 top-
ics) and Chinese corpus (127,938 documents) 
from TREC-9. (1) E-C_LongCLIR1 ? using 
long query and the bilingual-dictionary-based 
query translation; (2) E-C_LongCLIR2 ? using 
long query, the bilingual-dictionary-based 
1441
query translation and our OOV term transla-
tion; (3) E-C_ShortCLIR1 ? using short query 
and the bilingual-dictionary-based query trans-
lation; (4) E-C_ShortCLIR2 ? using short 
query, the bilingual-dictionary-based query 
translation  and our OOV term translation. The 
Precision-Recall curves and Median Average 
Precision (MAP) values are shown in Figure 6. 
 
Figure 6. Results for English-Chinese CLIR com-
bining our OOV term translation model. 
It can be seen from Figure 6 that the best run 
is E-C_LongCLIR2, and its results exceed 
those by another run E-C_LongCLIR1 based 
on long query. By adopting both query transla-
tion based on bilingual dictionary and OOV 
term translation, the English-Chinese CLIR for 
long query has gained the significant im-
provement on the whole retrieval performance. 
Compared with the traditional query transla-
tion based on bilingual dictionary, such a com-
bination manner is exactly a better way for 
query translation from the source language to 
the target language. Additionally, through 
comparing the results for the other two runs E-
C_ShortCLIR1 and E-C_ShortCLIR2 based on 
short query, it can also be further confirmed 
that our OOV term translation mechanism can 
also support CLIR for short query effectively. 
7.6 Analysis and Discussion 
Through analyzing the results for translation 
extraction and ranking, it can be found that the 
translation quality is highly related to the fol-
lowing aspects. (1) The translation results 
are associated with the search engine used, 
especially for some specific OOV terms. For 
example, given an OOV term ?Cross-Strait 
Three-links?, the mining result based on 
Google in China is ???????, while some 
meaningless information is mined by Live 
Trans. (2) Some terms are conventional ter-
minologies and cannot be translated literally. 
For example, ?Woman Pace-Setter?, a proper 
noun with the Chinese characteristic, should be 
translated into ???????, rather than ??
????? (women?s pace) or ???? (estab-
lishment) given by Google Translate. (3) The 
proposed model is sensitive to the notability 
degree of OOV term. This phenomenon is the 
main reason why there is obvious difference 
among the translation performance for PRN, 
LCN and OGN. (4) There is a ?fragment ef-
fect? in PAT-Tree-based Chinese key term 
extraction. The fragments of Chinese terms 
have become the main noisy data. Such a prob-
lem should be solved by setting the specific 
threshold for additional features like heuristic 
rules and occurrence distance. (5) Word Sense 
Disambiguation (WSD) should be added to 
improve the translation performance. Al-
though most of OOV terms have a unique se-
mantic definition, there are still a few OOV 
terms with ambiguity, e.g., ?AARP? (American 
Association of Retired Persons or AppleTalk 
Address Resolution Protocol). (6) The rank-
ing pattern based on the supervised learning 
is able to synthesize various feature repre-
sentations for translation candidates. Thus 
the rank for a candidate can be precisely pre-
dicted through tagging and training. 
8 Conclusions 
In this paper, the proposed model improves the 
acquirement ability for OOV term translation 
through Web mining, and solves the translation 
pair selection and evaluation in a novel way by 
fusing multiple features and introducing the 
supervised learning based on Ranking SVM. 
Furthermore, it is significant to apply the key 
techniques in machine translation into OOV 
term translation, such as OOV term recogni-
tion, statistical machine learning, alignment of 
sentence and phoneme, and WSD. All these 
aspects will be our research focus in the future. 
Acknowledgements 
This work is supported by National Natural 
Science Fund of China (No. 60773124), 
Shanghai Natural Science Fund (No. 
09ZR1403000), National Science and Tech-
nology Pillar Program of China (No. 
2007BAH09B03), 973 Program of China (No. 
2010CB327906), Shanghai Municipal R&D 
Foundation (No. 08dz1500109) and Shanghai 
Key Laboratory of Intelligent Information 
Processing. Cheng Jin from Fudan University 
is the corresponding author. 
1442
References 
Y. Al-Onaizan, K. Knight. 2002. Translating 
Named Entities using Monolingual and Bilingual 
Resources. In: The 30th Meeting of the Associa-
tion for Computational Linguistics (ACL 2002), 
400-408. 
Y.B. Cao, J. Xu, T.Y. Liu, H. Li, Y.L. Huang, and 
H.W. Hon. 2006. Adapting Ranking-SVM to 
Document Retrieval. In: The 29th Annual Inter-
national ACM SIGIR Conference on Research 
and Development in Information Retrieval (SI-
GIR 2006), 186-193. 
C. Chen, H.H. Chen. 2006. A High-Accurate Chi-
nese-English NE Backward Translation System 
Combining Both Lexical Information and Web 
Statistics. In: The Joint Conference of the 
International Committee on Computational 
Linguistics and the Association for 
Computational Linguistics (COLING-ACL 
2006), 81-88. 
L.F. Chien. 1997. PAT-Tree-based Keyword Ex-
traction for Chinese Information Retrieval. In: 
The 20th Annual International ACM SIGIR Con-
ference on Research and Development in Infor-
mation Retrieval (SIGIR 1997), 50-58. 
G.L. Fang, H. Yu, and F. Nishino. 2006. Chinese-
English Term Translation Mining Based on Se-
mantic Prediction. In: The Joint Conference of 
the International Committee on Computational 
Linguistics and the Association for 
Computational Linguistics (COLING-ACL 
2006), 199-206. 
G.H. Gonnet, R.A. Baeza-Yates, and T. Sinder. 
1992. New Indices for Text: PAT Trees and PAT 
Arrays. Information Retrieval Data Structures & 
Algorithms, 66-82. 
R. Herbrich, T. Graepel, and K. Obermayer. 1999. 
Support Vector Learning for Ordinal Regression. 
In: The 9th International Conference on Neural 
Networks (ICANN 1999), 97-102. 
L. Jiang, M. Zhou, L.F. Chien, and C. Niu. 2007. 
Named Entity Translation with Web Mining and 
Transliteration. In: The 20th International Joint 
Conference on Artificial Intelligence (IJCAI 
2007), 1629-1634. 
T. Joachimes. 2002. Optimizing Search Engines 
using Click through Data. In: The 8th ACM 
SIGKDD International Conference on Know-
ledge Discovery and Data Mining (SIGKDD 
2002), 133-142. 
C.J. Lee, J.S. Chang, and J.R. Jang. 2006. Align-
ment of Bilingual Named Entities in Parallel 
Corpora Using Statistical Models and Multiple 
Knowledge Sources. ACM Transactions on 
Asian Language Processing, 5(2):121-145. 
W.H. Lu, L.F. Chien. 2002. Translation of Web 
Queries using Anchor Text Mining. ACM Trans-
actions on Asian Language Information 
Processing, 1(2):159-172. 
W.H. Lu, L.F. Chien. 2004. Anchor Text Mining for 
Translation of Web Queries: A Transitive Trans-
lation Approach. ACM Transactions on Informa-
tion Systems, 22(2):242-269. 
L. Shao, H.T. Ng. 2004. Mining New Word Trans-
lations from Comparable Corpora. In: The 20th 
International Conference on Computational Lin-
guistics (COLING 2004), 618-624. 
R. Sproat, T. Tao, and C.X. Zhai. 2006. Named 
Entity Transliteration with Comparable Corpora. 
In: The Joint Conference of the International 
Committee on Computational Linguistics and 
the Association for Computational Linguistics 
(COLING-ACL 2006), 73-80. 
V.N. Vapnik. 1995. The Nature of Statistical 
Learning Theory. Springer-Verlag New York, 
Inc., New York, NY. 
P. Virga, S. Khudanpur. 2003. Transliteration of 
Proper Names in Cross-Language Applications. 
In: The 26th Annual International ACM SIGIR 
Conference on Research and Development in In-
formation Retrieval (SIGIR 2003), 365-366. 
J.H. Wang, J.W. Teng, P.J. Cheng, W.H. Lu, and 
L.F. Chien. 2004. Translating Unknown Cross-
Lingual Queries in Digital Libraries using a 
Web-based Approach. In: The Joint Conference 
on Digital Libraries (JCDL 2004), 108-116. 
J.C. Wu, J.S. Chang. 2007. Learning to Find Eng-
lish to Chinese Transliterations on the Web. In: 
The Joint Meeting of the Conference on Empiri-
cal Methods in Natural Language Processing and 
the Conference on Computational Natural Lan-
guage Learning (EMNLP-CoNLL 2007), 996-
1004. 
J. Xu, Y.B. Cao, H. Li, and M. Zhao. 2005. Rank-
ing Definitions with Supervised Learning Me-
thods. In: The 14th International World Wide 
Web Conference (WWW 2005), 811-819. 
Y. Zhang, P. Vines. 2004. Using the Web for Auto-
mated Translation Extraction in Cross-
Language Information Retrieval. In: The 27th 
Annual International ACM SIGIR Conference 
on Research and Development in Information 
Retrieval (SIGIR 2004), 162-169. 
Y. Zhang, P. Vines. 2004. Detection and Transla-
tion of OOV Terms Prior to Query Time. In: The 
27th Annual International ACM SIGIR Confe-
rence on Research and Development in Informa-
tion Retrieval (SIGIR 2004), 524-525. 
Y. Zhang, F. Huang, and S. Vogel. 2005. Mining 
Translations of OOV Terms from the Web 
through Cross-Lingual Query Expansion. In: 
The 28th Annual International ACM SIGIR Con-
ference on Research and Development in Infor-
mation Retrieval (SIGIR 2005), 669-670. 
1443
