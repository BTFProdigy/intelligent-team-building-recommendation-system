Unscrambl ing  Engl ish word order 
Allan Ramsay L: Helen Seville 
Centre for Computational Linguistics 
UMIST, PO Box 88, Manchester M60 1QD, England 
allan/he:teng@cc:t, umist, ac. uk 
Abstract 
We propose a treatment of 'extraposition' which 
allows items to be assimilated irectly even when 
they at)pear far from their canonical positions. This 
treatnmnt supports analyses of a number of phenom- 
ena which are otherwise hard to describe. The ap- 
1)roach requires a generalisation of standard chart 
i)arsing techniques. 
1 Extraposition in English 
It is widely accei)ted that sentences such as 
1 I saw the girl wh, o your tnvther said h,e fancied. 
2 The soup was OK, but th, e main course I th, ought 
was awful. 
involvc items ('who', 'the mai'a, eoursc') being found 
far away from their normal i)ositions (as the com- 
plement of 'fancied' and the subject of 'was a@d' ) .  
It seems likely that; the modifiers 'in the parle' and 
"with, all my heart' in 
3 l>n the park I met Arthur. 
4 I bclievcd with, all my heart th, at sh, c loved me. 
arc also 'out of position', since you would normally 
expect VP-modi(ying PPs of this kind to appear im- 
mediately to the right of the modified VP (so that 
the canonical versions of these sentences would have 
been '1 met Arthur in the park' and 'I believed that 
site loved me with all my heart.'). There arc vari- 
ous reasons for moving things around in this way- 
moving 'who' to the left; in (1) provides an easy way 
of l)icking out the boundary of the relative clause; 
moving 'the main course' and 'in the park' in (2) 
and (3) puts them into tlmmatically/informationally 
more prominent positions; and moving the senten- 
tial complement 'that she lovcd me'  to the right in 
(4) reduces the attachment ambiguity that arises in 
the alternative form. 
This is all well-known, and is treated in most 
grammatical frameworks by hallucinating an item in 
the canonical position, and then rememl)ering that 
halhlcination uI) to (;tie 1)oint at which the out-of- 
place item is encountered. Exactly how the halhlci- 
nation is remelnbered varies fron~ one framework to 
another, with Ulfification grammars generally carry- 
ing intbrmation about it on a category-valued fea- 
ture (usually called slash,). The main problem with 
this al)l)roach is that it is difficult to control the sit- 
uations in which 'traces' of this kind get proposed. 
(Johnson and Kay, 1994) suggest using ~sponsors' in
order to license the introduction of traces, where a 
st)onsor is some item of the required kind that has 
already 1)een found, and which is hence potentially 
going to cancel with the trace. 
If your parser works ti'om le f t , r ight  then this 
will work for items which have been left-shifted, but 
clearly it cmmot work for right-shifted items, since 
the sI)onsor will not have t)een found at the time 
when it is needed. Thus we cannot use a sI)onsor to 
justify hallucinatillg an S-comp ti)r 'believed' in (4), 
or for the heavy-NP-shifts in
5 He 
6 Ite 
h, ouse. 
gave up his job. 
built on that .spot th, e most appallingly ugly 
In any casc, the notion that some item has been 
left- or right-shifted fails to account for cases of 'in- 
traposition': 
7 I bclievc Betty is a fool. 
8 Betty, I belicvc, is a fool. 
9 Betty is, I believe, a fool. 
It is at least 1)lausible that (8) and (9) are variants 
oil (7). They're made out of the same words, they 
have the same truth conditions: the only trouble is 
that part of the sentence seems to be in the wrong 
t)laee. 
This is analogous to the situation in (2) and (3), 
where items were moved to the fi'ont to make them 
more prominent. It seems as though in (;tie current 
case the words 'I believe' have been shifted into the 
middle, and 1)arcnthesised, to nmke them less promi- 
nent. We will show how to deal with this by adal)ting 
663 
13 Charles danced with Eliza, but Diana he kissed. 
mid when we say that tim PP that results from satu- 
rating 'on' modifies a VP to its left we are referring 
to cases like (12), not to 
14 On the mat the cat sat. 
(or even 'On the mat sat the cat. ', where tile expec- 
tation that the subject will appear to the left of the 
verb has also been violated.) 
It seems as though we need the standard FRCP to 
cope with the canonical cases; the weakened FRCP'  
to cope with cases where the phrase occurs in some 
unexpected position; and something else to constrain 
the unexpected positions which are actually possible. 
Tile constraints on what can be moved around 
take two tbrnls. Firstly, we have say whether some- 
thing can be nloved at all, which we do by intro- 
ducing a polar-valued feature called moved: items 
which appear away from their canonical positions 
are marked moved(rioht) or moved(left), depend- 
ing on the direction in which they have been shifted. 
Arguments and targets which aren't allowed to move 
will be marked -moved by tile item that subcate- 
gorises for them. 
Secondly, we have to specify where those items 
that can move are allowed to get to. We do this 
by using linear precedence rules (LP-rules), most of 
which place constraints on immediate local subtrees. 
Thus we can say things like 
{A, B, C} : +wh@A&-wh.@B 
-+ start@A < start@B 
to capture tile fact that if A and B are local subtrees 
of C, then if A is WH-marked and B is not then 
A must precede B (A's start must be before B's). 
Note that the signature of the rule mentions C, even 
though in this case the body does not. 
The facts about extraposition are captured by 
rules which specify the circumstances under which a 
local subtree can (or must)be +moved. Tile key con- 
straints for trees representing structures with verbal 
heads are as follow: 
{ A, B, C} : -wh@A& -aux@C&A = snbject@C 
- moved@A 
(if A is the subject of C, where A is not WH-marked 
and C is not mi auxiliary, then A may not be moved) 
{A, B, C} : movcd@A = right 
~X(X  E dtrs@C 
& start@core@C < start@X) 
start@X < start(~A) 
(if A has been right-shifted, then C had better have 
some other daughter X between C's head and A. 
Tile flfll rule says that C must be heavier than X, 
where we take 'C is heavier than X'  to mean that C 
covers more words than X, so that tlfis rule covers 
(4), (5) and (6)). 
There are a nmnber of other such rules, of which the 
most complex relates to 'ttmt'-clauses (denoted by 
-~cornp). The description of such clauses comes in 
two parts, one to say that -~vh phrases may not be 
extracted and one to say that +wh phrases must be 
extracted. 
(i) {A, B, C} :C C clause 
& +comp@C & +compact@C 
---} - wh@B 
(ii) {A, B, C} : C C clause 
& +cornp@C & -compact@C 
--~ + wh@B 
The first part of this says that if combining A and 
B produces a 'that'-clause C, then if C is +compact 
(so nothing has been extracted from it) then it, had 
better be -wh  (in other words, nothing properly 
inside it can be +wh). If on tile other hand C is 
-compact hen there must be solnething extracted 
from it, in which case the item which has been ex- 
tracted must mark it as +wh,. These rules cover the 
(un)aeceptability of 
15 I know that she loves me. 
16 ~ I know me that she loves. 
17 who I know that sh, e loves. 
18 * I know that who she loves. 
5 I n t rapos i t ion  
The rules in Section 4 provide a reasonable account 
of simple extraposition (both left and right) from 
clauses. We now return to 
7 I believe Betty is a fool. 
8 Betty, I believe, is a fool. 
9 Betty is, I believe, a fool. 
Suppose we use FRCP' ,  with no LP-rules, to analyse 
(8). We will get, mnong other things, the phrases 
and part phrases shown in Fig. 1 (tile commas are 
treated as lexical items, so that 'Betty' starts at 0, 
the first comma at 1, and 'I' at 2, and so on). 
The first couple of steps are straightforward: 'a 
fool' results fl'om combining 'a' and 'fool'. It; has no 
holes in it, its extreme start and end are the stone as 
its compact start and end. Then 'is a fool' results 
froin combining 'is' and 'a fool', and again all the 
pieces are in the right place, so the extreme start 
and end are the santo as the compact start and end 
and the phrase is +compact. 
At step 3, 'Betty' is integrated as the subject of 
'is a fool'. The result starts at 0, since that's where 
666 
l)hrase start end xstart xend 
1 a fool 6 8 6 8 
2 is n tbol 5 8 5 8 
3 Betty is a. fool 5 8 0 8 
4 believe Betty is a fool 3 4 0 8 
5 I 1)elieve Betty is a %ol 2 4 0 8 
6 ,I believe Betty is a tbol 0 4 0 8 
7 ,I believe Betty is a fool, 0 8 0 8 
Figure 1: Analysis of (8) 
(:Oral)act 
+ 
+ 
+ 
'Betty' starts, and is -compact ,  since it does not 
include all the intervening words. 
At 4 this -compact  sentence l)ecomes the com- 
plement of 'believe'. The result is again -compact ,  
since it fails to include the word q'  or the two com- 
mas which at)pear 1)etween its start and end l)oints. 
The compact core is now the word 'believe', so the 
comi)act start and en(t are 3 and d. 
.At; 5, the VP 'believe Betty is a fool' combines 
with 'I' to produce 'I believe Betty is a fool'. The 
two commas then combine with this phrase, mark- 
ing it as being parenthe.tieal nd, when the second 
comma is included, finally marking it as +compact. 
Similar structures would be created during the 
t)rocessing of (9), with the only difl'erence l)eing that 
'is a fool' would 1)e the first -corn, pact phrase found. 
Apart fl:om that the analysis of (9) would tm identi- 
cal to the analysis of (8). 
'i~hcre m'e two problems with this ai)l)roa(:h to sen- 
Ix'ames of this kind: (i) 1)ecause we obtain identical 
syntact i c  ana lyses  o f  (7),  (8) mid  (9),  then  any  (:Oln- 
t)ositional semantics will assign all three the same 
interpretation. This is not entirely wrong: I cannot 
fairly say a.ny of these sentences unless I do believe 
that Betty is a tbol. But it is also clearly not entirely 
right, since it misses the diflbrence in emi)hasis. We 
will not discuss this any further here. (ii) be(:mlse we 
are not applying the LP-rules, we get rather a large 
number of mmlyses. Without LP-rules, we gel; a sin- 
gle analysis of '1 believe Bctty is a fool', having con- 
structed 23 t)artial and complete, edges. 1,br 'Betty, 
I believe, is a fool' we get three analyses (including 
the correct one) having constructed 1.01 edges. Most 
of t, hese m'ise fl'om the t)resence of the commas, since 
we have to allow for the possibility that each of these 
(:ommas is either an ot)ening or closing l)racket, or a 
conjmmtion in a comma-sei)arated list of co l t iunets .  
Others arise fl'om the fact that we have removed 
all the LP-rules, so that we are treating English as 
having completely Dee word order. Case marking 
still provides ome constraints on what can combine 
with what, so that in the current case 'I' is the only 
possible sul)ject for 'believe' and 'Betty' is the only 
possible subject for 'is'. If we had been dealing with 
19 Betty, Fred believes, is a fool 
then we would have had six analyses froln 107 edges, 
with the new ones arising because we had assigne(1 
~Fred' as the subject of %" and 'Betty' as the sul)- 
jec~ of 'believes'. 
Clearly we need to reinstate the general LP-rule.% 
whilst allowing for the cases we are interested in. 
These cases are characterised in two ways: (i) some 
word that requires a sentence has oc(-urre(1 in ~ con- 
text where a :st)lit' sentence is available, and (ii) this 
word  is ad jaee i l t  to  a 1 )arenthet i ca l  comlna .  The  
statement of this rule is rather long-winded, but the 
result is to provide a single analysis of (8) from 66 
edges, and a single analysis of (9) from 70 edges. 
6 ~more X than Y'  
Most (:ases of extral)osition in English involve sen- 
tences, lint there are a numl)er of other 1)henomena 
where items seem to have 1)een shifted around. Con- 
sider for instance the following examples: 
20 Geo~ye ate more than six peaches. 
21 Harriet ate more peaches than pears. 
22 \[a'n, ate more pcaehcs than ,\]ulia.n. 
In (20), "more' than si:r' looks like a complex deter- 
miner. How many peaches did George eat? More 
than six. The easiest way to analyse this is by 
assmning theft 'more' subcategoriscs for a ' than-  
phrase'. 
In (21) and (22), however, the than-phrase seems 
to have become di@)inted. It still seems as though 
'more.' heads a complex determiner, since (22) would 
support the answer 'more than Julian' to the ques- 
tion 'How many peachcs did Ian cat?' a 
We therefore introduce lexical entries tbr 'more' 
and 'tha'n' which look roughly as follows: 
athough (21) does not seem to support  ~morc than pears' 
as an mmwer to 'How many peaches did Harriet cal'?'. The 
problem seems l;o be that NP complements  o 'than' are actu- 
ally elliptical (see below), and it seems to be harder to recover 
the elllpsed sentence 'More than she ate pears' than to recover 
~More than Julian ate peaches' or era, ore than Julian ate'. 
667 
sign 
/ n?m??,' / fl J J / 
sy'l / L J i l l  Lfoo Iwh< JM 
subcat / \ [ in  \[phon ' than ' \ ] l \  II 
semantics. . .  
sign 
phon 'than' 
I onfoot 
syn \[ \ [ . . .  
\[foot\[wit <>\] 
subcat (X} 
semantics. . .  
The entry for 'more' says that it will make a specifier 
if it finds a satmated phrase headed by 'than'. The 
entry for 'than' says that it will make a phrase of 
the required type so long as it finds sonm argument 
X. We know very little about X. In (20) it is a 
number, in (21) and (22) it appears to be an NP. In 
fact, as (Puhnan, 1987) has shown, the best way to 
tlfink about these examples is by regarding them as 
elliptical fbr the sentences 
23 Harriet ate more peaches than site ate pears. 
24 1an ate more peaches than Julian ate peach, es. 
Other kinds of elliptical phrase are permitted, as in 
25 Keith ate more peaches than Lucy did. 
or  even  
26 Martha ate more ripe titan unripe pcach, es. 4 
We theretbre allow arbitrary phrases as tile argu- 
ment to 'than'. All we need now are the LP-rules 
describing when arguments of 'than' should be ex- 
traposed. These simply say that if you are combin- 
ing the determiner 'more' with a 'than'-phrase, then 
if the sole daughter of the 'than'-phrase is a nmnber 
then it must not be shifted, and if it is not then it 
must be right-shifted. 
(i) {d, B, C} : A E det&phon@A = 'more' 
& cat@B = than& dtrs@B = <D> 
& (DEnnmorDead j )  
4Note that  in this case the argument  of ' than'  is not  dis- 
placed. 
--> - moved@ B
(ii) {A, B, C} :A  E det&phon@A = 'more' 
cat?}B = than 
& not(dtrs@B = <D> 
& (D < . :am or D < adj)) 
--~ moved@B = right 
With these LP-rules, we get approl)riate structural 
analyses for (20) (25). We do not, however, cur- 
rently have a treatment of ellipsis. We therefore 
cannot provide sensible semantic analyses of (21) 
and (22), since we cannot determine what sentences 
'peaches' and 'Julian' are elliptical for (imagine, for 
instance, trying to decide whether 'Eagles eat more 
spar~vws than crows' meant 'Eagles eat more spar- 
rvws than crows cats sparrows' or 'Eagles eat more 
sparrows than eagles eat crows'). 
If the structure of 'more peaches th, an pears' in- 
volves a displaced 'than'-phrase, then it seems very 
plausible that the stone is true for 
27 Nick wrote a more elegant program th, an Olive. 
28 Peter wrote a more elegant prvgram th, an th, at. 
This is given further supt)ort by the acceptability of 
examples like 
29 A progrum more elegant han that would be hard 
to find. 
where tile 'than'-I)hrase is adjacent o the modified 
adjective 'elegant' rather than to the noun 'program' 
which is modified by the whole phrase 'more elegant 
than that'. 
Frustratingly, it just does not seem possible to 
reuse the lexical entry above for 'more' to cope with 
these cases. In (20) (25), 'more' made a deternfiner 
when supplied with an apl)ropriate 'than'-phrase. 
For (27)-(29) it needs to make somettfing whicll will 
combine with an adjective/adverb to produce an in- 
tensified version of the original. We therefore need 
tile tbllowing entry: 
) l ion ~more  ~ 
subcat sign < > J| 
semantics. . .  
668 
This needs a 'than'-phrase to saturate it, and once it 
is saturated it will combine with an adj (adjective or 
a(tverb) to nmke a new adj. There are two questions 
to be answered: should such a complex adj attpear to 
the left; or right of its target, and should the 'than'- 
phrase be extraposed or not? 
(28) and (29) show that these questions are in- 
timately connected. If the 'than'-phrase is right- 
shifted, then the resulting modifier aptmars to the 
left of its target (28); if it is not, then the moditier 
appears to the right (29). This is exactly what is pre- 
dicte(1 by (Willimns, 1981)'s suggestion that head- 
final moditiers generally appear to the left of their 
targets ( 'a quietly sleeping man') whereas non-head- 
final ones apt)ear to the right ( 'a 'llt(t'lt sleeping qui- 
etly'). All we need to do is to make right-shifting of 
the 'than'-l)hrase optional, and to invoke Williams' 
rule., using the coral)act core of the modifier. Thus 
the compact modifier 'more elegant h, an thai,' fl'om 
(2{I) is not head final, since the whole thing is cora- 
l)act but the head, 'elwant' , is i1ot; the last word; the 
non-colnt)aet one 'move ch;gant .. .  than that' from 
(28) is head final, since this time 'elegant' is the 
last, word in the (:ompact core 'more elwant'. Hetme 
'more clegant h, an that' tbllows its targe, t a.nd 'more 
clwant . . .  than th, at' precedes it. No new LP-rules 
are required, and 110 challg(}s 1;(1 th(} gellel:al rllle for 
locating moditiers are required. 
7 Conc lus ions  
\?e have shown how retrieving disl)laeed items di- 
rectly, rather than t)ositing a trace of some kind 
and then eancellillg it against an appriate iteln 
when one turns up, can I)rovide treatlllellts of left- 
and right-extraposition which display the advan- 
tages that (Johnson and Kay, 1994) obtain for left- 
extraposition. This approach to extraposition can 
be extended to deal with 'intraposition' and to cases 
where items have been extracted ti'om non-clausal 
items. In order to avoid overgeneration, we needed 
to introduce a set of LP-rules which are applied 
as phrases are constructed in order to ensure, that 
items have not been shifted to unacceptable posi- 
tions. The extra computation required for checking 
the LP-rules has no effect on l;he comI)lexity of the 
parsing process, since they simply add a constant 
(and t~irly small) extra set of steps each time a new 
edge is proposed. As a rough tmrformance guide, the 
gralnInar generates five analyses for 
30 Ite built on that site a more unattractive house 
than the eric which he built in Greenwich. 
on the basis of 237 edges (the different global anal- 
yses m'ise from the attachment ambiguities for the 
wn:ious modifiers), and takes 4.1 seconds to <1o so 
(compiled Sicstus on a Pentiunl 350). This sentence 
contains a right-shifted NP, which itself contains a 
'more ... than ...' construction and also a relative 
clause with a left-shifted WII-pronoun, and hence 
could be expected to cause problems for al)l)roaches 
using si)onsors , while 
8 Betty, I believe, is a fool. 
takes 0.27 seconds. Tit('. worst case comple?ity 
analysis for this kind of approach is fairly awflfl 
(O(l y) X 22(N-I)) where 1 ~ is the number of unsatu- 
rated edges in the initial chart and N is the length 
of the sentence (Ramsay, in press)). In practice the 
LP-rules provide sufficient constraints on the gener- 
ation of non-coral)act phrases for pertbrmalme to be 
generally acceptable on sentences of about twenty 
words. 
Re ferences  
M Johnson and M Kay. 1994. Parsing and empty 
nodes. Computational Linguistics, 20(2):289 300. 
R M Kal)lan. 1973. A general syntactic processor. 
In R.. Rustin, editor, Natural language proeessin.q, 
pages 193 241, New York. Algorithmics Press. 
M Kay. 1973. The MINI) system. In R. Rustin, 
editor, Naturnl Language Processing, pages 155 
188, New York. Algorithmics Press. 
C J Pollard and I A Sag. 1988. An I'nfovmation 
Based Approach to Syntax and Semantics: Vol 
1 Fundamentals. CSLI lecture notes 113, Chicago 
University Press, Chi(:ago. 
C J l?ollard and I A Sag. 1994. Head-driven Ph~nsc 
Str'uct'nre G~nmmar. (~hi(',ago University Press, 
Chicago. 
S G l 'uhnan. 1987. l~vents and VP-modifiers. in 
B.G.T. Lowden, editor, Proceedings of the Alvcy 
Sponsored Workshop On Formal Semantics in 
Natural Languagc P'roecssiug, Colchester. Univer- 
sity of Essex. 
A M Ramsay. in press. Parsing with discontinuous 
phrases. Nat'mnl Language Engincering. 
I A Sag and T Wasow. 1999. Syntactic theory: a 
formal introduction. CSLI, Stratford, Ca. 
E Williams. 1981. On the notions 'lexically related' 
att(t 'head of a word'. Ling'uistic Inquiry, 12:254 
274. 
M M Wood. 1993. Categorial Grammars. Rout- 
ledge, London. 
669 
Making  Sense  of Re ference  to the  Unfami l ia r  
Helen Seville and Allan Ramsay* 
Centre for Computational Linguistics 
UMIST, PO Box 88, Manchester M60 1QD, England 
heleng/allan@ccl, umist, ac. uk 
Abstract 
C, omi)utational ai)proaches to reference resolu- 
tion, like Centering Theory, are best at resolv- 
ing referring expressions which denote familiar 
reD.rents. We demonstrate how, by t~king a 
proof-theoretic approach to reference resolution 
within a Centering-type framework, we are able 
to make sense of reti;rring expressions tbr un- 
familiar referents. These include, in addition 
to bridging descriptions, definite descripl;ions 
like "the first man" and "the first snowdrops of 
Spring". We claim that the first of these denotes 
a unique subset of a iflural discourse antecedent. 
While the second has no discourse antecedent, 
we similarly treat it as denoting a mfi(lue subset 
of a t'~nniliar eferent. 
1. I n t roduct ion  
Itow do reti;rring exl)ressions denote? Accord- 
ing to II.ussell, a definite description such as 
%he King of France", denotes a mfique individ- 
ual by virtue of its meaning. But, according to 
Familiarity Theory (Helm, 1.983), reti;rring ex- 
pressions need not denote mfiquely by virtue of 
their meaning as they refer to individuals made 
familiar by the discourse or other context. This 
observation plays a key role in Centering The- 
ory (Grosz and Sidner, 1986; Grosz et al, 1995) 
and other computational al)t)roaches in which 
rethrring expressions are resolved by locating 
their antecedents in the discourse. The refer- 
ence of pronouns like "he", definite descriptions 
like "the woman", and referential tenses like 
"had" clearly has more to do with salience ill 
context thml with uniqueness of meaning. Sim- 
ilarly, while names like "Mary" need not denote 
individuals prominent in the discourse context, 
* \Ve would like to thank the anonymous reviewers for 
their detailed and helpful comments. 
they must nevertheless denote individuals famil- 
iar to conversants if they are successflflly to re- 
fer. However, there is another (:lass of referring 
expressions in relation to which we believe the 
concept of uniqueness of meaning does have an 
essential role to plt~y. These include such def- 
inite descrit)tions as "the first man" and "the 
first snowdrop of Spring", along with such vari- 
ations on these as "the first three men" and "the 
first snowdrops of Spring". 
In implementing a system of retL, renee resolu- 
tion, we have attemt)ted to reconcile the notions 
of familiarity mM uniqueness. This enables us 
to dereli;rence xl)ressions like "the first snow- 
drop of Spring" in a unified framework alongside 
anal)hers ~, pron(mns, retbrential tenses, names, 
and other definite descriptions like "the nlall". 
(1) Two men nrrive(t. 
(2) The .fir.st 'm,a'H, spoke. 
In the case of a referring expression like "the 
first mini", there may be an antecedent of sorts 
in the discourse, trot it is not the individual re- 
ferred to (or indeed ml individual at all). We 
will say that the antecedent "two men" intro- 
duces a set, and that the referring expression 
"the first man" denotes, by virtue of the mean- 
ing of.first, a unique subset of this familiar set. 
(1) Mary saw th, e first snowd,vp of 
Spring. 
In the case of "tile first snowdrop of Spring", 
there need be no explicit antecedent in the dis- 
course. We will s~w that, in the same way 
that "Mary" denotes a familiar individual, "the 
snowdrops of Spring" denotes a t'~nniliar set, or 
>vVe use this term to distinguish reflexives like "her- 
self" from t)ronouns like "he" and "hiln". 
775 
property. Again, by virtue of tile meaning of 
first, "tile first snowdrop of Spring" can be said 
to denote a unique subset of the familiar set. We 
will not claim that it denotes a unique individ- 
ual, but that rather it denotes a unique subset 
of the specified cardinality, i.e., 1. This treat- 
ment has tile advantage that it extends to plural 
referring expressions. 
Below we outline the approach we have de- 
veloped to the representation a d resolution of 
referring expressions, betbre discussing in more 
detail its extension to deal with unfamiliar ef- 
erents. 
2 A F ramework  for Re ference  
Reso lu t ion  
Our framework for reference resolution has been 
implemented in the system of language under- 
standing described in (Ramsay, 1999). The 
starting point tbr reference resolution is the log- 
ical tbrm we obtain fl'om parsing. For example, 
the tbllowing is the logical tbrm we get for the 
utterance "Mary slept." 
~A : { A is interval $~ 
f o,'e(,'e f ( aB ( V ech,_ti e( B , 1))), A ) } 
3C : {aspect(simple, A, C)} 
0 (C, agen.t, ref  (,kD (,,.amed(D, Mary) 
g card(D, 1)))) 
sleep(C) 
C is event 
We use tile inference engine described in 
(Ramsay and Seville, 2000) to update the dis- 
course model with a new discourse state con- 
taining the intbrmation explicitly represented in 
tile logical tbrm together with any further infer- 
ences which are licensed given the existing dis- 
course model. Reference resolution, which in- 
volves carrying out a proof that a retbrring ex- 
pression denotes, is implemented as part of the 
update step. We anchor a referring expression 
like ref()~D(named(D, Marg)&card(D, 1))) in 
tile discourse model by proving the existence of 
an entity in the model which satisfies the prop- 
erties specified by the referring expression, in 
this case aD(na,~ed(D, Mary)~ea,'d(D, 1)) 2. 
2Strictly speaking, it is a set which is denoted. For 
readability, our referring expressions conflate tim prop- 
erties of sets and their members. In this case, the car- 
dinality is a property of the set denoted, but the nmne 
Mary is a property of its member. 
Given that many referring expressions do not in 
themselves denote uniquely, however, we need 
a theory of reference resolution to enable us 
to obtain the appropriate (i.e., intended) ret- 
erent for any referring expression. We incorpo- 
rate our theory of reference resolution into the 
actual representation of referring expressions; 
for example, we label anaphors with the prop- 
erty "salient" and pronouns (and also referential 
tenses) with the property "centred"3: 
"himself" 
re f ( AX (salient (X, re f ( AD ( eds (D)))$~m (X))) 
"she  ~, 
ref (),X (ee..tred(X, reZ (),D(e&(D)  )~Z(X) ) 
Retbrence resolntion relies on maintaining, as 
in Centering Theory, a list of tbrward-looking 
centres for each discourse state (corresponding 
to an utterance) in the discourse. Furthermore, 
for the purposes of reference resolution, the dis- 
course states themselves are organized into a 
discourse tree, which is constructed automati- 
cally based on referential cues 4, as described in 
(Seville, 1999). 
0 
I 
1 
/ \  
2 3 
/1\  
456 
(1) a mani diedj in a park/~. 
(2) hei hadj been sleeping ther%. 
(3) a womanl lovedm him/. 
(4) shez had,~ hated him/. 
(5) he/ hadm hated himself/. 
(6) he~: hadm loved herl. 
The nodes in such a tree correspond to dis- 
course states. Those oll tile right-hand frontier 
are open, which essentially means that tile enti- 
ties mentioned in them are available to pronom- 
inal reference. 
The process of reference resolution for tile 
various referring expressions can be briefly de- 
scribed as tbllows. Anaphors, characterised as 
salient, are resolved to a less oblique argument 
of the same verb (Pollard and Sag, 1994) within 
the current discourse state, which is constructed 
aHere rcf(AD(cds(D)) is a reference to the current 
discourse state and the properties m and f refer to male 
and female gender espectively. 
4The tree illustrated was constructed using pronomi- 
nal cues. Each discourse state was attached as a daugh- 
ter of the highest node in the discourse tree to which all 
pronouns and referential tenses (like had) mentioned in
it could be anchored. 
776 
incrementally. We also st;art our sere'oh tbr the 
referents of prononns and other centred enti- 
ties in the current disconrse state, which is nec- 
essary if we are to resolw; such referring ex- 
pressions as "her" in "Mary took John with 
her." However, referring expressions contain- 
ing the property centred are prevented front 
1)eing dereferenced to salient entities, thus en- 
suring that the constraint of disjoint reference 
is met. If we fail to tind the centred en- 
tity in the current discourse state, we search 
the previous open node and, if necessary, fllr- 
ther open nodes in the discourse tree, in order 
to deal with long-distance pronominalisation. 
The dereferencing of other referring expressions 
like ref(AD(named(D, Mary)gcard(D, 1))) is 
similar but less constrained in that we con- 
sider entities mentioned in all nodes mentioned 
in the discourse, tree, whether open or closed, 
in order of recency. This means that, essen- 
tially, names and definite descriptions are deref- 
created to the most recently mentioned refer- 
ent which is appropriate. Unlike in the case of 
pronouns, we also consider Discourse State 0, 
which doesn't correspond to an utterance but, 
rather, contains the background knowledge as- 
stoned in the model. This is how we are able 
to deal with the first mention of a familiar 
referent like Mary (assmning that the proper- 
ties kD(na, m(:d( D, Mary)gcard( D, 1)) sumce 
to distinguish a particular entity in Discourse, 
State 0 from all the others). 
Our approach extends naturally to cases like 
%he first snowdrop of Spring" because it; is 
proof-theoretic and so able to exploit back- 
ground knowledge in reference resolution. This 
can be illustrated, in the first instance., by exam- 
thing the backgrmmd knowledge which is used 
in updating the utterance "Mary slept." The 
update step for this utterance yields Discourse 
State 1, contailfing (amongst others) the tbllow- 
ing facts: 
Discourse State 1 
,s/eep(#134) 
0(#134, agent, #94) 
ends_before(#4(1), #133) 
aspect(simple, #13a, #134) 
We were able to prove named(#94, Mary) 
and card(#94, 1) and so dereference 
rcf(,\D(namcd(D, Mary)&card(D, 1))) as 
the tbllowing were amongst he t~cts contained 
in Discourse State 0: 
Discourse State 0 
female(#94) 
named(#94, Mary) 
woman(#94) 
f(#.94) 
card(#94, 1) 
adult(#94) 
These were generated from the lexical memfing 
1)ostulates we stipulated for "Mary", "woman", 
and " fo lna le"  :
3X (namcd( X, Mary)&woman( X)&card( X, 1)) 
VX(woman(X) 
VX(.fcmalc(X) -4 f(X)) 
3 Unfami l ia r  Re ferents  
In this section we show how, within the frame- 
work above, we are able to make sense of a vari- 
ety of referring expressions denoting unfamiliar 
referents. The most straighttbrward of these are 
bridging descriptions, so we start with these. 
3.1 Br idging Descr ip t ions  
(1) Mary loves her" moth, or. 
In this first case, "her mother", contains a refer- 
ring expression ested within it;. Having deref- 
erenced this, the knowledge that moth, er of is a 
fllnction enables us to obtain a unique reli;renl;. 
Our representation of the referring expression 
to be derelbrenced is as follows: 
"her mother" 
ref(AB(of(B, 
,.e f ( a, 1) 
$~ f(G)))) 
ca .d( B, 1))) 
Tile first step involves anchoring tile referring 
expression by dereferencing its nested rethrring 
expression for "her ''5. 
'SThe referent for this is characterised as 
salient_or_centred as we allow I)ossessivc pronouns 
to be dereferenced as anal)hers or, failing that, as 
pronouns. 
777 
Current Model 
ends_at_or_after(#4(1), #135) 
aspect(simple, #135, #136) 
0(#136, agent, #94) 
Zove(#la6) 
Tile partially constructed current discourse 
state we have when we do our dereferencing is as 
shown. "Mary" has already been dereferenced 
to #94 and this has been entered into the list 
of forward-looking centres fbr the current utter- 
ance. We are able to prove both salient(#94) 
and f (#94) ,  and so our nested referring expres- 
sion is dereibrenced to this entity. 
ref(kB(of(B, 
, F(,,,other( F) ), 
#94) 
card(m1))) 
It is then a straighttbrward matter to derefer- 
ence the anchored referring expression, given 
the tbllowing facts in Discourse State 0: 
Discourse State 0 
mother (#60 (#94)) 
o f (#60(#94) ,  ;~A(moth.cr(A)), #94) 
f (#60(#94)) 
card(#60(#94), 1  
These derive from our nmaning postulates fbr 
"mother ''6 and "of": 
VX( (X  is a,~i.,o,O~card(X , 1) --~ 
~Y (o.f (Y, kZ (rnother( Z) ), X) 
&card(Y, l)&f(Y))) 
VXVYVZ(of(X, Y, Z) -+ Y.X) 
Dealing with other bridging descrit)tions is 
more complicated: 
(1) Mary saw a house. 
(2) She tbund the door. 
In order to give an analogous treatment to the 
referring expression "the door", we have to treat 
it as elliptical tbr an exl)ression containing a 
nested referring expression, i.e., "the door of the 
house". In the same way that we have a mean- 
ing postulate for the relation mother of, we have 
one for the relation door of: 
aSkolemization preserves dm dependency of Y on X, 
i.e., #94 is present in #60(#94). 
vx((ho,, e(x) v car(X)) 
qY (of (Y, AZ(door( Z) ), X)~eard(Y, 1))) 
This means that, having used utterance (1) 
above to update the discourse model, we have 
the fbllowing amongst the facts in Discourse 
State 1: 
Discourse State 1 
seel(#138) 
0(#138, agent, #94) 
0(#138, object, #139) 
card(#139, 1)
house( #139) 
ends_be for'e(#4(1), #sat )  
door(#46(#139)) 
entrance( #46( #139 ) ) 
of(#46(#139),  ~d(door'(A)), #139) 
card(#46(#139),  1  
aspect(simple, #137, #138) 
In updating utterance (2), the bridging descrip- 
tion which needs to be dereDrenced has the tbl- 
lowing representation: 
ref(AE(door(E) g~ card(E, 1))) 
Since we caimot guarantee that there will only 
be a single entity in our model satisfying the 
t)roperties kE(door(E) & card(E, 1)), we want 
to ensure that the referent we obtain is either 
the most recently mentioned or that with the 
most recently mentioned antecedent, i.e., in this 
case, the house #139. Our ret>rence resolu- 
tion t)rocedure xploits the fact that the house, 
#139, is explicitly represented in the forward 
looking centres of Discourse State 1 and that 
the intended referent, #46(#139), is clearly a 
flmction of this (its dependency having been 
preserved by Skolemization). In considering the 
potential refbrents for our referring expression ill
order of recency, we attempt o prove, not sim- 
ply, ibr each referent, X, whether door(X) and 
car'd(X, 1), but door(V) and card(Z, 1) where 
Y is a function of X. Since #46(#139) is 
a function of the antecedent #139, we obtain 
the appropriate referent in this case by proving 
door(#46(#139)) and card(#46(#139), 1 . 
3.2 Superlatives 
We are now in a I)osition to describe our treat- 
ment of the superlatives discussed in the intro- 
duction. First, we consider a case in which there 
is a discourse antecedent of sorts: 
778 
(1) Two men arrived. 
(2) The first man spoke. 
Discom:se State 1 contains the tbllowing facts: 
Discourse State 1 
arrive( #107) 
0(#107, agent, #1.08) 
card(#108, 2)
man(#108) 
male(#108) 
.~(#108) 
adult(#108) 
~n&_b<l'o,'d #4(1), #106) 
a.s'pect(.simplc, #106, #107) 
Our representation of the referring exi)ression 
"the first man" is as follows: 
rcf(k\]3('mo,st(B, 
~C(early( C, AD(man(D)))), 
,.~f (~E(,,,o,,,,(~)))) 
x~ ,-..,.d(u. 1)))) 
The nested referring expression 
ref(AE('m,a,'n.(E)))) ('m~ be straightforwardly 
dereferenced in this case to give the anchored 
refi;rring exl)ression: 
rcf(A\]3(mo,st(B, 
ac(,.~,,+.,j( c, .xu(,..,.~(J))))), 
#108) 
g ,..,,,,,.d(J3, ~)))) 
Dereferencing this then involves our meaning 
postulate fi)r superlatives: 
VXVZVC(,-,,,,.d(Z, C)~(Z - X)~(~C = 1),~ 
V NV P (-wnosl.( X, P, _) -+ 
~Y (mosl,(Y, P, X)&card(Y, N)))) 
This siml)ly says that tbr any severalton set X, 
any property 1 ) and any N, there is some set Y 
containing the N "most P" members of X. This 
meaning postulate does not translate into any 
facts in Discourse State 0, lint remains as a rule. 
When we have a particular eferring expression 
to derefhrence, this rule enables us to prove that: 
most(#81(kA(early(A,...)), 1, 2, #108, #108), 
,x ( c ( ~,~,.ly( c, ~D ( .,,,,,.,( D ) ) ) ), 
#108) 
card(#81 (AA(c'arly (A, . . . ) ) ,  1, 2, @ 108, @ 108), 
1) 
In this way, we prove that the referring ex- 
pression makes sense, i.e., denotes. However, 
unlike in the previous cases, we do not deret- 
erence to a familiar referent. There are no 
existing facts in the database about the ref- 
erent #81(AA(early(A,...)), 1, 2, @108, #108). 
Instead, in this case, we have to add to Dis- 
course State 2 the facts we have proved. 
Discourse state 2 
? . _ _  
spcalv( #112) 
th, cta( #112, agent, 
#81(AA(early(A,...)), 1, 2, #108, #108)) 
end.s_before(#4(2), #11.1) 
.spcech, A.imc( #4(2), 2) 
aspcct(.simplc, #111, #112) 
mo.st(#81(AA(early(A,...)), 1, 2, #108, #108), 
~ c ( ~o,,.z..,j( c, ~ D (,~o,,4 D ) ) ) ), 
#108) 
~,,~.d(#Sl(~A(~o,,@(A,...)), 1, 2, #108, #108), 
1) 
~,,@(#81(~A(eo,,@(A,...)), 1, 2  #108, #108), 
:~c(,,,a,~( c)  ) ) 
,,,,,,,,,(#81(~A(,,,,,,.ly(A, . . .)), 1, 2, #108, #*O8)) 
mah' (#Sl (AA(ear ly (A , . . . ) ) ,  1, 2, #108, #108)) 
m(#Sl (AA(ear ly (A , . . . ) ) ,  1, 2, #108, #108)) 
,,d,,,U,(#Sl(~A(~,,@(A,...)), 1, 2,#108, #108)) 
The fln:ther facts we. prove, about our refe.rent 
being e~rly, male, etc., are required if we are to 
be aMe to subsequently retb.r to it using referring 
expressions such as "he". The.se are generated 
from a set of associated memfing postulates: 
VXVYVP((ordered(P)~most(Y, P, X)) -+ P.Y) 
V A ( ordered( AB (early( B, A)))) 
vxvP(,.~o,,.1,,(x, 1,) -~ p.x) 
VX ('m, an( X) 
(X is h, uman)~male(X)&adult(X)) 
vx(mde(x)  -~ re(x)) 
In addition to these, we have two further mean- 
ing postulates for superlatives: 
vxvYvevcvz( , , .o~t(Y ,  1; X),~a,.d(Y, C) 
g,,,os~,(Z, P, X)*~a,.d(Z, C) 
-~z=Y) 
VXVI'VYVNVC(most( X, P, Z)& 
card(X, N)~card(V, C) 
-~ ~,~o,.~( N, C) ) 
779 
The first of these, the uniqueness meaning pos- 
tulate, states that if there are two subsets of of 
a set which share the same cardinality mid the 
same superlative property, such as first, then 
they must be regarded as identical 7. The sec- 
ond simply ensures that any mffamiliar ret5r- 
ent which we obtain via our meaning postu- 
lates can sensibly regarded as a proper subset 
of its antecedent; hat is, it prevents us regard- 
ing "two men" as a potential antecedent of "the 
first men": 
(1) Two meni arrived. 
(2) The first men,f(i) spoke. 
Our treatment of superlatives without dis- 
course antecedents is similar to that above. 
(1) Mary saw th, c first snow&vps of 
Spring. 
There is just one major difference. 
r' I( E 
AF(carly(F, 
: a(of(a, 
,\It(snowdrop(It)), 
re f ( ),I(named( I, 
@ri..o) 
g  rd(Z, 1))))))), 
ref(),J(of(J, 
( s o.odrop( K) ), 
re f ( kL(named( L, Spring) 
&card(L, 1))))))) 
E, VO ) ) ) 
The representation we obtain for the referring 
expression "the first snowdrops of Spring" is 
shown above. Like that for "the first man", this 
contains a nested referring expression: 
ref(),g(of(J, 
AK ( snowdrop( K) ), 
~card(L, 1))))))) 
The difference is that, in this case, there is 
no discourse antecedent for the nested refer- 
ring expression. This means that, in order to 
7practicaUy, this meaning postulate seems to be re- 
dundant. Our meaning postulates generate for us only 
one such subset and it is impossible for another to be 
introduced through the discourse as "a first man" is un- 
grammatical. 
anchor our referring expression by dereferenc- 
ing the referring expression ested within it, we 
need to introduce a meaning postulate for the 
nested referent (and one for its nested referent, 
Spring): 
3X ( X, rd( X, 1)) 
qX(of(X, 
) ) ) 
&card(X, pl) ) 
These meaning postulates simply introduce into 
Discourse State 0 the fact that there are snow- 
drops of Spring, in the same way that the mean- 
ing postulate for "Mary" introduced the fact 
that there is a singleton set containing an in- 
dividual so named. 
Discourse state 0 
season(#98) 
named(#98, Spring) 
card(#98, 1) 
extended(#98) 
snowdrop(#101) 
of(#101, A(A, snowdrop(A)), #98) 
..(#101) 
card(#101, pl) 
Given the above facts in Discom'se State O, an- 
choring our referring expression is straighttbr- 
ward. 
f ( E(. ost( E, 
1F(early(F, 
 C(of(a, 
Mt (.snowdrop( H) ), 
#98)))), 
#101) 
* car'd(E, P0))) 
From this point onwards, the proof that this 
referring expression denotes proeeeeds in the 
same way as in the previous example. Given 
the meaning postulates for superlatives, we are 
able to prove: 
most(#81(),A(early(A,...)),pl,pl, #101, #101), 
~D(early(D, 
)~E (o f ( E, )~F (snowdroI,( F) ) , #98)))), 
#101) 
card(#81(~A(ear' ly(A, . . . ) ) ,p l ,pl ,  #101, #101), 
pl) 
780 
Again, as in the example above, the facts we 
have proved concern an nut~miliar referent, and 
so have to 1)e added to the current discourse 
state. 
Discourse state 1 
.seel(#107) 
theta(#107, agent, #94) 
tit, eta(# 107, 
object, 
#81(),(A, . . . ) ,  #98)))),pl,p/,  #101, #101)) 
ends_before(#4(1), #106) 
aspect(simple, #106, #107) 
most(#81(AA(...), #98)))),pl,pl, #101, #101), 
AD(early(D, 
AE(o f ( E, AF(.snow&'op( F) ), #98)))), 
#1Ol) 
card( #Sl(AA(. .), #98) ) ),pl,pl, #101, #101), 
pl) 
carly(#S1(AA(...), #g8)))),pl,pl, #101, #101), 
D ( o f ( D , z ( op ( Z ) ) , 
#gs))) 
oI(#81(AA(...), #98)))),pl,pl, #101, #-101), 
)~O( ~',,,ow&'op( D )), 
#9s) 
snowdrop(#S1(kA(...), #98))) ) , . . . ) )  
n(#81(kA( . . . ) ,  #-98)))),pl,pl, #101~ #-101)) 
4 Conc lus ion  
We have shown how, l)y taking a t)root:theoretie 
approach to reference resolution, we can extend 
a Centering-tyt)e framework to make sense of 
tel!erring expressions for a w~riety of unfamiliar 
referents. Having made sense of such referring 
ext)ressions, we add their referents to our dis- 
course model. This is how we would normally 
deal with indefinites rather than definites. How- 
ever, this al)t)roach makes t)erfect sense, given 
our treatment of su('h referring exl)ressions as 
denoting unfamiliar subsets of familiar referents 
(regarded as sets). We claim that we are able 
to use definite descriptions to refer to the ref- 
erents in question, despite their unfamiliarity, 
SO long as we Call prove that, by virtue of their 
meaning, they denote uniqnely. 
Having imt)lemented our approach in a sys- 
tem of language understanding which already 
deals with a wide variety of referring expres- 
sions, we have demonstrated its practicality. 
It also has interesting theoretical implications, 
since it suggests a way in which pragmatic theo- 
ries of reference resolution, like Familiarity The- 
ory, and semantic theories, like Russell's, may 
be reconciled. However, it is fair to say that 
the success of the approach is not yet proven. 
This is because we have yet to show that we 
can deal with a set of related referring expres- 
sions within a single fi'amework. The following 
example illustrates the kinds of cases we have 
in mind: 
(1) Three meni ate. 
(2) Two menj slept. 
(3) The first meni died. 
Here, "first" in "the first men" is clearly per- 
tbrming a dit\[erent, discourse-related flmction 
from that it p lws in the cases we have been 
considering. We have yet to tackle such difficult 
cases but, since they seem to require reasoning 
about sets, we believe that our inference-based 
approach to reference resolution is a good place 
to start. 
Re ferences  
B. J. Grosz and C. L. Sidner. 1986. Attention, 
intentions, and the structure of discourse. 
Computational Linguistics, 12(3):175-204. 
B. J. Grosz, A. K. Joshi, and S. Weinstein. 
1995. Centering: A framework ibr modeling 
the local coherence of discourse. Computa- 
tional Linguistics, 21 (2):203--225. 
I. Helm. 1983. File change semantics and 
the familiarity theory of definiteness. In 
R. Bauerle, C. Schwarze, and A. von Stechow, 
editors, Meaning, Use, and Interpretation of 
Language, pages 164-189. de Gruyter, Berlin. 
C. Pollard and i. A. Sag. 1994. Head-Driven 
Phrase Structure Grammar. University of 
Chicago Press, London. 
A. Ramsay and Helen Seville. 2000. Models and 
discourse models, dournal of Language and 
Computation, 1(2):159-174. forthcoming. 
A. Ramsay. 1999. Does it make any sense? up- 
dating = consistency checking. In K. Tunmr, 
editor, The Semantics//Pragmatics Interface 
firm Different Points of View. Elsevier Sci- 
ence B.V. 
H. Seville. 1999. Experiments with discourse 
structure. In Th, ird International Workshop 
on Computational Semantics, pages 233-246, 
Tilburg. 
781 
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 337?344,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Local constraints on sentence markers and focus in Somali
Katherine Hargreaves
School of Informatics
University of Manchester
Manchester M60 1QD, UK
kat@evilution.co.uk
Allan Ramsay
School of Informatics
University of Manchester
Manchester M60 1QD, UK
Allan.Ramsay@manchester.ac.uk
Abstract
We present a computationally tractable ac-
count of the interactions between sentence
markers and focus marking in Somali. So-
mali, as a Cushitic language, has a ba-
sic pattern wherein a small ?core? clause
is preceded, and in some cases followed
by, a set of ?topics?, which provide scene-
seting information against which the core
is interpreted. Some topics appear to carry
a ?focus marker?, indicating that they are
particularly salient. We will outline a com-
putationally tractable grammar for Somali
in which focus marking emerges naturally
from a consideration of the use of a range
of sentence markers.
1 Introduction
This paper presents a computationally tractable
account of a number of phenomena in Somali. So-
mali displays a number of properties which dis-
tinguish it from most languages for which com-
putational treatments are available, and which are
potentially problematic. We therefore start with
a brief introduction to the major properties of the
language, together with a description of how we
cover the key phenomena within a general purpose
NLP framework.
2 Morphology
Somali has a fairly standard set of inflectional af-
fixes for nouns and verbs, as outlined below. In
addition, there are a substantial set of ?spelling
rules? which insert and delete graphemes at the
boundaries between roots and suffixes (and cli-
tics). There is not that much to be said about the
spelling rules ? Fig. 1 shows the format of a typi-
cal rule, which we compile into an FST to be used
during the process of lexical lookup.
[q/x/c/h,?,v0] ==> [+, k, v0]
Figure 1: Insert ?k? and a morpheme boundary be-
tween ?q/x/c/h? and a following vowel
The rule in Fig. 1 would, for instance, say
that the surface form ?saca? might correspond to
the underlying form ?sac+ka?, with a morpheme
boundary and a ?k? inserted after the ?c?. These
rules, of which we currently employ about 30, can
be efficiently implemented using the standard ma-
chinery of cascaded FSTs (Koskiennemi, 1985)
interwoven with the general lookup process.
2.1 Noun morphology
In general, a noun consists of a root and a single
affix, which provides a combination of gender and
number marking. The main complication is that
there are several declension classes, with specific
singular and plural suffixes for groups of classes
(e.g. the plural ending for declensions 1 and 3 is
?o?) (Saeed, 1999; Lecarme, 2002). Some plural
forms involve reduplication of some part of the
word ending, e.g. declension 4 nouns form their
plural by adding ?aC? where ?C? is the final conso-
nant of the root, but this can easily be handled by
using spelling rules.
2.2 Verb morphology
Verb morphology is slightly more complex.
Again, a typical verb consists of a root plus a num-
ber of affixes. These include derivational affixes
(Somali includes a passivising form which can
only be applied to verbs which have a ?causative?
argument, and a causative affix which adds such
337
an argument) and a set of inflectional affixes which
mark aspect, tense and agreement (Andrzejewski,
1968).
The forms of the tense and agreement mark-
ers vary depending on whether the clause con-
taining the verb is the main clause or is a sub-
ordinate clause (either a relative clause or a sen-
tential complement), marked by ?main and on
whether it is in a context where the subject is re-
quired to be a zero item, marked by?fullForm.
Note that the situation here is fairly complicated:
-fullForm versions are required in situations
where the subject is forced by local syntactic con-
straints to be a zero. There are also situations
where the subject is omitted for discourse rea-
sons, and here the +fullForm version is used
((Lecarme, 1995) uses the terms ?restrictive? and
?extensive? for -fullForm and +fullForm re-
spectively).
2.3 Cliticisation
There are a number of Somali morphemes which
can appear either bound to an adjacent word (usu-
ally the preceding word) or as free-standing lexi-
cal items. The sentence marker ?waa? and the pro-
noun ?uu?, for instance, combine to produce the
form ?wuu? when they are adjacent to one another.
In several cases, there are quite dramatic morpho-
phonemic alterations at the boundary, so that it is
extremely important to ensure that the processes of
applying spelling rules and inspecting the lexicon
are appropriately interwoven. The definite articles,
in particular, require considerable care. There are
a number of forms of the definite article, as in
Fig. 2:
masculine feminine
the-acc ka ta
the-nom ku tu
?remote? (nom or acc) kii tii
this-acc tan kan
this-nom tanu kanu
that-acc taas kaas
that-nom taasu kaasu
Figure 2: Definite articles
We deal with this by assuming that determiners
have the form gender-root-case, where the gender
markers are ?k-? (masculine) and ?t-? (feminine),
and the case markers are ?-? (accusative) and ?-
u? (nominative), with spelling rules that collapse
?kau? to ?ku? and ?kiiu? to ?kii?.
The definite articles, however, cliticise onto
the preceding word, with consequential spelling
changes. It is again important to ensure that the
spelling changes are applied at the right time to
ensure that we can recognise ?barahu? as ?bare?
plus ?k+a+u?, with appropriate changes to the ?e?
at the end of the root ?bare? and the ?k? at the start
of the determiner ?ku?.
3 Syntax
3.1 Framework
The syntactic description is couched in a frame-
work which provides a skeletal version of the
HPSG schemas, supplemented by a variant on the
well-known distinction between internal and ex-
ternal syntax.
3.1.1 Lexical heads and their arguments
We assume that lexical items specify a (pos-
sibly empty) list of required arguments, together
with a description of whether these arguments are
normally expected to appear to the left or right.
The direction in which the arguments are expected
is language dependent, as shown in Fig. 3. Note
that the description of where the arguments are to
be found specifies the order of combination, very
much like categorial descriptions. The descrip-
tion of an English transitive verb, for instance,
is like the categorial description (S\NP)/NP,
which corresponds to an SVO surface order.
English transitive verb(SOV)
{syn(nonfoot(head(cat(xbar(+v, -n)))),
subcat(args([????????NP?(obj), ?????????NP?(subj)])))}
Persian transitive verb (SOV)
{syn(nonfoot(head(cat(xbar(+v, -n)))),
subcat(args([????????NP?(obj), ?????????NP?(subj)])))}
Arabic transitive verb (VSO)
{syn(nonfoot(head(cat(xbar(+v, -n)))),
subcat(args([?????????NP?(subj), ????????NP?(obj)])))}
Figure 3: Subcat frames
3.1.2 Adjuncts and modifiers
Items such as adjectival phrases, PPs and rela-
tive clauses which add information about some tar-
get item combine via a principle captured in Fig. 4
R =? {syntax(target=??T , result=R)}, T
R =? T, {syntax(target=??T , result=R)}
Figure 4: Modifiers and targets
338
Then if we said that an English adjec-
tive was of type {syntax(target=????NN?,
result="NN") the first rule in Fig. 4 would
allow it to combine with an NN to its right
to form an NN, and likewise saying that a
PP was of type {syntax(target=????VP?,
result="VP")would allow it to combine with
a VP to its left to form a VP.
3.1.3 Non-canonical order
The patterns and principles outlined in ?3.1.1
and ?3.1.2 specify the unmarked orders for the rel-
evant phenomena. Other orders are often permit-
ted, sometimes for discourse reasons (particularly
in free word order languages such as Arabic and
Persian) and sometimes for structural reasons (e.g.
the left shifting of the WH-pronoun in ?I distrust
the man whoi she wants to marry ?i.?).
We take the view that rather than introducing
explicit rules to allow for various non-canonical
orders, we will simply allow all possible or-
ders subject to the application of penalties. This
approach has affinities with optimality theory
(Grimshaw, 1997), save that our penalties are
treated cumulatively rather than being applied
once and for all to competing local analyses. The
algorithm we use for parsing withing this frame-
work is very similar to the algorithm described by
(Foth et al, 2005), though we use the scores asso-
ciated with partial analyses to guide the search for
a complete analysis, whereas Foth et al use them
to choose a complete but flawed analysis to be re-
constructed. We have described the application of
this algorithm to a variety of languages (includ-
ing Greek, Spanish, German, Persian and Arabic)
elsewhere (Ramsay and Scha?ler, 1997; Ramsay
and Mansour, 2003; Ramsay et al, 2005): space
precludes a detailed discussion here.
3.1.4 Internal:external syntax
In certain circumstances a phrase that looks as
though it belongs to category A is used in circum-
stances where you would normally expect an item
belonging to category B. The phrase ?eating the
owl? in ?He concluded the banquet by eating the
owl.?, for instance, has the internal structure of a
VP, but is being used as the complement of the
preposition ?by? where you would normally expect
an NP. This notion has been around for too long
for its origin to be easily traced, but has been used
more recently in (Malouf, 1996)?s addition of ?lex-
ical rules? to HPSG for treating English nominal
gerunds, and in (Sadler, 1996)?s description of the
possibility of allowing a single c-structure to map
to multiple f-structures in LFG. We write ?equiva-
lence rules? of the kind given in Fig. 5 to deal with
such phenomena:
{syn(head(cat(xbar(-v, +n))),
+specified)}
<==>{syn(head(cat(xbar(+v, -n)),
vform(participle,present)),
subcat(args([{struct(B)}])))}
Figure 5: External and internal views of English
verbal gerund
The rule in Fig. 5 says that if you have a
present participle VP (something of type +v, -n
which has vform participle, present and
which needs one more argument) then you can use
whereever you need an NP (type -v, +n with a
specifier +specified).
3.2 Somali syntax
As noted earlier, the framework outlined in ?3.1
has been used to provide accounts of a number of
languages. In the current section we will sketch
some of the major properties of Somali syntax and
show how they can be captured within this frame-
work.
3.2.1 The ?core & topic? structure
Every Somali sentence has a ?core?, or ?verbal
complex? (Svolacchia et al, 1995), consisting of
the verb and a number of pronominal elements.
The structure of the core can be fairly easily de-
scribed by the rule in Fig. 6:
CORE ==> SUBJ,(OBJ1),(ADP*),(OBJ2),VERB
Figure 6: The structure of the core
The situation is not, in fact, quite as simple as
suggested by Fig. 6. The major complications are
outlined below:
1. the third person object pronouns are never ac-
tually written, so that in many cases what you
see has the form SUBJ, VERB, as in (1a),
rather than the full form given in (1b) (we will
write ?(him)? to denote zero pronouns):
(1) a. uu sugayhe (him) waited for
b. uu i sugayhe me waited for
2. The second complication arises with ditran-
sitive verbs. The distinction between OBJ1
339
and OBJ2 in Fig. 6 simply corresponds to
the surface order of the two pronouns, and
has very little connection with their semantic
roles (Saeed, 1999). Thus each of the sen-
tences in (2a) could mean ?He gave me to
you?, and neither of the sentences in (2b) is
grammatical.
(2) a. i. uu i kaa siiyeyhe me1 you2 gave
ii. uu ku kay siiyeyhe you1 me2 gave
b. i. uu kay ku siiyeyhe me2 you1 gave
ii. uu kaa i siiyeyhe you2 me1 gave
3. The next problem is that subject pronouns are
also sometimes omitted. There are two cases:
(i) in certain circumstances, the subject pro-
noun must be omitted, and when this happens
the verb takes a form which indicates that
this has happened. (ii) in situations where the
subject is normally present, and hence where
the verb has its standard form, the subject
may nonetheless be omitted (usually for dis-
course reasons) (Gebert, 1986).
4. There are a small number of preposition-like
items, referred to as adpositions in Fig. 6,
which can occur between the two objects, and
which cliticise onto the preceding pronoun if
there is one. The major complication here
is that just like prepositions, these require an
NP as a complement: but unlike prepositions,
they can combine either with the preceding
pronoun or the following one, or with a zero
pronoun. Thus a core like (3) has two analy-
ses, as shown in Fig. 7:
(3)
uu ika sugaa
uu i ka sugaa
he me at (it) waits-for
sug++++aa
uu
agent
i
object
ka
mod
0
sug++++aa
uu
agent
0
object
ka
mod
i
Figure 7: Analyses for (3) (0.010 secs)
The second analysis in Fig. 7, ?he waits for
it at me?, doesn?t make much sense, but it is
nonetheless perfectly grammatical.
5. Finally, there are a number of other minor el-
ements that can occur in the core. We do not
have space to discuss these here, and their
presence or absence does not affect the dis-
cussion in ?3.3 and ?3.4.
To capture these phenomena within the frame-
work outlined in ?3.1, we assign Somali transitive
verbs a subcat frame like the one in Fig. 8 (the pat-
terns for intransitive and ditransitive verbs differ
from this in the obvious ways).
{syn(nonfoot(head(cat(xbar(+v, -n)))),
subcat(args([????????????????NP?(obj, +clitic),?????????????????NP?(subj, +clitic)])),
foot(...))}
Figure 8: Somali transitive verb
Fig. 8 says that the core of a Somali sentence
is a clause of the form S-O-V, where S and O are
both clitic pronouns.
The canonical position of S and O is as given.
They can appear further to the left than that to al-
low for clitic modifiers: exactly where they can
go is specified by requiring the clitic modifiers to
appear adjacent to the verb (subject to further lo-
cal constraints on their positions relative to one
another), and requiring S and O to fall inside the
scope of the ?sentence markers?.
3.3 Sentence markers
A core by itself cannot be uttered as a free standing
sentence. At the very least, it has to include a ?sen-
tence marker?. The simplest of these is the word
?waa?. (4), for instance, is a well-formed sentence,
with the structure shown in Fig. 9.
(4)
wuu sugaa.
waa uu sugaa.
s-marker he (it) waits-for
sug++ay++aa
waa
comp(waa)
uu
agent
0
object
Figure 9: Analysis for (4) (0.01 secs)
Note that the pronoun ?uu? cliticises onto the
end of the sentence marker ?waa?, producing the
written form ?wuu?, as discussed above.
In general, however, the situation is not quite
as simple as in (4). Most sentences contain NPs
other than the pronouns in the core. The first such
examples involve introducing ?topics? in front of
the sentence marker.
Topics are normally definite NPs or PPs which
set the scene for the interpretation of the core. A
typical example is given in (5):
340
(5)
ninka wuu sugaa.
nim ka waa uu sugaa.
man the S-marker he (him) waits-for
0
baabuur+
predication
k+a
det
0
topic
waa
comp(waa)
somaliTopic
wax+
k+a
det
Figure 10: Sentence with topic
The analysis in Fig. 10 was obtained by exploit-
ing an equivalence rule which says that an item
which has the internal properties of a -clitic
NP can be used as a ?topic?, which we take to be a
sentence modifier.
Topics set the scene for the interpretation of
the core by providing potential referents for the
pronominal elements in the core. There are no
very strong syntactic links between the topics and
the clitic pronouns ? if a topic is +nom then it will
provide the referent for the subject, but in some
(focused) contexts subject referents are not explic-
itly marked as +nom. The situation is rather like
saying ?You know that man we were talking about,
and you know the girl we were talking about. Well,
she?s waiting for him.?.
topical(ref(?B(NIM(B))))
&claim(?C : {aspect(now, simple,C)}
?(C, agent, ref(?Dfemale(D)))
&?(C, object, ref(?Fthing(F )))
&SUG(C))
Figure 11: Interpretation of (5)
The logical form given in Fig. 11, which
was constructed using using standard compo-
sitional techniques (Dowty et al, 1981), says
the speaker is marking some known man
ref(?B(NIM(B))) as being topical, and is then
making a claim about the existence of a waiting
event SUG(C) involving some known female as
its agent and some other known entity as its object.
Note that we include discourse related information
? that the speaker is first marking something as be-
ing topical and then making a claim ? in the log-
ical form. This seems like a sensible thing to do,
since this information is encoded by lexical and
syntactic choices in the same way as the proposi-
tional content itself, and hence it makes sense to
extract it compositionally at the same time and in
the same way as we do the propositional content.
Somali provides a number of such sentence
markers. ?in? is used for marking sentential com-
plements, in much the same way as the English
complementiser ?that? is used to mark the start
of a sentential clause in ?I know that she like
strawberry icecream.? (Lecarme, 1984). There
is, however, an alternative form for main clauses,
where one of the topics is marked as being par-
ticularly interesting by the sentence markers ?baa?
or ?ayaa? (?baa? and ?ayaa? seem to be virtually
equivalent, with the choice between them being
driven by stylistic/phonological considerations):
(6) baraha baa ninka sugaa.
?baa?/?ayaa? and ?waa? are in complementary
distribution: every main clause has to have a sen-
tence marker, which is nearly always one of these
two, and they never occur in the same sentence.
The key difference is that ?baa? marks the item
to its left as being particularly significant. Ordi-
nary topics introduce an item into the context, to
be picked up by one of the core pronouns, with-
out marking any of them as being more prominent
than the others. The item to the left of ?baa? is
indeed available as an anchor for a core pronoun,
but it is also marked as being more important than
the other topics.
We deal with this by assuming that ?baa? sub-
categorises for an NP to its left, and then forms a
sentence marker looking to modify a sentence to
its right. The resulting parse tree for (6) is given
in Fig. 12, with the interpretation that arises from
this tree in Fig. 13.
sug++++aa
0
object
0
agent
somaliTopic
nim+
k+a
det
baa
comp(baa)
somaliTopic
focus
bare+
k+a
det
Figure 12: Parse tree for (6)
topical(ref(?C(NIM(C))))
&focus(ref(?D(BARE(D))))
&claim(?B : {aspect(now, simple, B)}
?(B, object, ref(?Ething(E)))
&?(B, agent, ref(?Gspeaker(G)))
&SUG(B))
Figure 13: Interpretation for (6)
Treating ?baa? as an item which looks first to its
left for an NP and then acts as a sentence modi-
fier gives us a fairly simple analysis of (6), ensur-
ing that when we have ?baa? we do indeed have a
341
focused item, and also accounting for its comple-
mentary distribution with ?waa?. The fact that the
combination of ?baa? and the focussed NP can be
either preceded or followed by other topics means
that we have to put very careful constraints on
where it can appear. This is made more complex
by the fact that the subject of the core sentence can
cliticise onto ?baa?, despite the fact that there may
be a subsequent topic, as in (7).
(7) baraha buu ninku sugaa.
sug++++aa
0
object
uu
agent
baa
comp(baa)
somaliTopic
bare+
k+a
det
somaliTopic
nim+
k+a
det
i
caseMarker
Figure 14: Parse tree for (7)
To ensure that we get the right analyses, we
have to put the following constraints on ?baa? and
?waa?:
1. if the subject of the core is realised as an ex-
plicit short pronoun, it cliticises onto the sen-
tence marker
2. the sentence marker attaches to the sentence
before any topics (note that this is a con-
straint on the order of combination, not on the
left?right surface order: the tree in Fig. 14
shows that ?baraha baa? was attached to
the tree before ?ninka?, despite the fact that
?ninka? is nearer to the core than ?baraha
baa?.
Between them, these two ensure that we get
unique analyses for sentences involving a sentence
marker and a number of topics, despite the wide
range of potential surface orders.
3.4 Relative clauses & ?waxa?-clefts
We noted above that in general Somali clauses
contain a sentence marker ? generally one of
?waa?, ?baa? and ?ayaa? for main clauses, or one
of ?in? for subordinate clauses. There are two
linked exceptions to this rule: relative clauses, and
?waxa?-clefts.
Somali does not possess distinct WH-pronouns
(Saeed, 1999). Instead, the clitic pronouns (in-
cluding the zero third-person pronoun) can act as
WH-markers.
This is a bit awkward for any parsing algo-
rithm which depends propagating the WH-marker
up the parse tree until a complete clause has been
analysed, and then using it to decide whether that
clause is a relative clause or not. We do not want
to introduce two versions of each pronoun, one
with a WH-marker and the other without, and then
produce alternative analyses for each. Doing this
would produce very large numbers of alternative
analyses, since each core item is can be viewed ei-
ther way, so that a simple clause involving a transi-
tive clause would produce three analyses (one with
the subject WH-marked, one with the object WH-
marked, and one with neither).
We therefore leave the WH-marking on the
clitic pronouns open until we have an analysis of
the clause containing them. If we need to con-
sider using this clause in a context where a relative
clause is required, we inspect the clitic pronouns
and decide which ones, if any are suitable for use
as the pivot (i.e. the WH-pronoun which links to
the modified analysis).
Relative clauses do not require a sentence
marker. We thus get analyses of relative clauses
as shown in Fig. 15 for (8).
(8)
ninka wadaya wuu shaqeeyayaa
nim ka wadaya waa uu shaqeeyaa
man the is-driving s-marker he is-working
The man who is driving it: he?s working
shaqee++ay++aa
uu
agent
waa
comp(waa)
somaliTopic
nim+
k+a
det
headless
whmod
wad++ay++a
0
object
0
agent
Figure 15: Parse tree for (8)
Note the reduced form of ?wadaya? in (8). The
key here is that the subject of ?wadaya? is the
?pivot? of the relative clause (the item linking the
clause to the modified nominal). When the subject
plays this role it is forced to be a zero item, and it
is this that makes the verb take the -fullForm
versions of the agreement and tense markers.
Apart from the fact that you can?t tell whether
a clitic pronoun is acting as a WH-marker or not
until you see the context, and the requirement for
342
reduced form verbs with zero subjects, Somali rel-
ative clauses are not all that different from relative
clauses in other languages. They are, however, re-
lated to a phenomenon which is rather less com-
mon.
We start by considering nominal sentences. So-
mali allows for scarenominal sentences consisting
of just a pair of NPs. This is a fairly common
phenomenon, where the overall semantic effect is
as though there were an invisible copula linking
them (see Arabic, malay, English ?small clauses?,
. . . ). We deal with this by assuming that any ac-
cusative NP could be the predication in a zero sen-
tence. The only complication is that in ordinary
Somali sentences the only items which follow the
sentence marker are clitic pronouns and modifiers.
For nominal sentences, the predicative NP, and
nothing else, follows the sentence marker.
For uniformity we assume that there is in fact a
zero subject, with the +nom NP that appears be-
fore the sentence marker acting as a topic.
(9)
waxu waa baabuurka.
wax ka I waa baabuur ka
thing the +NOM s-marker truck the
Any normal NP can appear as the topic of such
a sentence. In particular, the noun ?wax?, which
means ?thing?, can appear in this position:
0
baabuur+
predication
k+a
det
0
topic
waa
comp(waa)
somaliTopic
wax
k+a
det
i
caseMarker
Figure 16: ?the thing: it?s the truck?
The analysis in Fig. 16 corresponds to an inter-
pretation something like ?The thing we were talk-
ing about, well it?s the truck?. Note the analysis of
?waxu? here as the noun ?wax? followed by the def-
inite article ?ka? and the nominative case marker
?I?.
There is no reason why the topic in such a sen-
tence should not contain a relative clause. In (10),
for instance, the topic is ?waxaan doonayo I? ? ?the
thing which I want?.
(10)
waxaan doonayaa waa lacag.
wax ka aan doonayo I waa lacag
thing the I want +NOM s-marker money
Note that ?doonayaa? here is being read as
the {+fullForm,-main} version of the verb
?doonayo? followed by a cliticised nominative
marker ?I?. The choice of +fullForm this time
arises because the subject pronoun is not WH-
marked, which means that it is not forced to be
zero: remember that -fullForm is used if the
local constraints require the subject to be zero, not
just if it happens to be omitted for discourse or
stylistic reasons. Then in the analysis in Fig. 17
?wax ka aan doonayo I? is a +nom NP functioning
as the topic of a nominal sentence.
0
lacag+
predication
0
topic
waa
comp(waa)
somaliTopic
wax
k+a
det
headless
whmod
doon++ay++o
0
patient
aan
agent
I
caseMarker
Figure 17: (10) the thing I want: it?s some money
So far so simple. ?waxa?, however, also takes
part in a rather more complex construction.
In general, the items that occur as topics in So-
mali are definite NPs (Saeed, 1984). In all the
examples above, we have used definite NPs in
the topic positions, because that it is what nor-
mally happens. If you want to introduce some-
thing into the conversation it is more usual to use a
?waxa-cleft?, or ?heralding sentence? (Andrzejew-
ski, 1975).
The typical surface form of such a construction
is shown in (11):
(11)
waxaan doonayaa lacag.
waxa aan doonayaa lacag
waxa I want money
The key things to note about (11) are as follow:
? There is no sentence marker. Or at any
rate, the standard sentence markers ?waa? and
?baa? are missing.
? The subject pronoun ?aan? has cliticised onto
the word ?waxa? to form ?waxaan?.
? The verb ?doonayaa? is +fullForm
? The noun ?lacag? follows the verb. This is
unusual, since generally NPs are used as top-
ics preceding the core and, generally, the sen-
tence marker.
343
These facts are very suggestive: (i) the lack
of any other item acting as sentence marker sug-
gests that ?waxa? is playing this role. (ii) the fact
that ?uu? has cliticised onto this item supports this
claim, since subject pronouns typically cliticise
onto sentence markers rather than onto topic NPs.
We therefore suggest that ?waxa? here is func-
tioning as sentence marker. Like ?baa?, it focuses
attention on some particular NP, but in this case
the NP follows the core.
doon++ay++aa
0
patient
aan
agent
waxa
comp(waxa)
lacag+
focus
Figure 18: Parse tree for (11)
Thus ?waxa?, as a sentence marker, is just like
?baa? except that ?baa? expects its focused NP to
follow it immediately, with the core following that,
whereas the order is reversed for ?waxa? (Andrze-
jewski, 1975).
It seems extremely likely that ?waxa?-clefts are
historically related to sentences like (10). The sub-
tle differences in the surface forms (presence or
absence of ?waa? and form of the verb), however,
lead to radically different analyses. How simple
nominal sentences with topics including ?waxa?
and a relative clause turned into ?waxa?-clefts is
beyond the scope of this paper. The key obser-
vation here is that ?waxa?-clefts can be given a
straightforward analysis by assuming that ?waxa?
can function as a sentence-marker that focuses at-
tention on a topical NP that ?follows? the core of
the sentence.
4 Conclusions
We have outlined a computational treatment of
Somali that runs right through from morphology
and morphographemics to logical forms. The con-
struction of logical forms is a fairly routine activ-
ity, given that we have carried out this work within
a framework that has already been used for a num-
ber of other languages, and hence the machinery
for deriving logical forms from semantically an-
notated parse trees is already available. The most
notable point about Somali semantics within this
framework is the inclusion of the basic illocution-
ary force within the logic form, which allows us to
also treat topic and focus as discourse phenomena
within the logical form.
References
B W Andrzejewski. 1968. Inflectional characteristics
of the so-called weak verbs in Somali. African Lan-
guage Studies, 9:1?51.
B W Andrzejewski. 1975. The role of indicator par-
ticles in Somali. Afroasiatic Linguistics, 1(6):123?
191.
D R Dowty, R E Wall, and S Peters. 1981. Introduction
to Montague Semantics. D. Reidel, Dordrecht.
Killian Foth, Wolfgang Menzel, and Ingo Schro?der.
2005. Robust parsing with weighted constraints.
Natural Language Engineering, 11(1):1?25.
L Gebert. 1986. Focus and word order in Somali.
Afrikanistische Arbeitspapiere, 5:43?69.
J Grimshaw. 1997. Projection, heads, and optimality.
Linguistic Inquiry, 28:373?422.
K Koskiennemi. 1985. A general two-level computa-
tional model for word-form recognition and produc-
tion. In COLING-84, pages 178?181.
J Lecarme. 1984. On Somali complement construc-
tions. In T Labahn, editor, Proceedings of the Sec-
ond International Congress of Somali Studies, 1:
Linguistics and Literature, pages 37?54, Hamburg.
Helmut Buske.
J Lecarme. 1995. L?accord restrictif en Somali.
Langues Orientals Anciennes Philologie et Linguis-
tique, 5-6:133?152.
J Lecarme. 2002. Gender polarity: Theoreti-
cal aspects of Somali nominal morphology. In
P Boucher, editor, Many Morphologies, pages 109?
141, Somerville. Cascadilla Press.
Robert Malouf. 1996. A constructional approach
to english verbal gerunds. In Proceedings of the
Twenty-second Annual Meeting of the Berkeley Lin-
guistics Society, Marseille.
A M Ramsay and H Mansour. 2003. Arabic morpho-
syntax for text-to-speech. In Recent advance in nat-
ural language processing, Sofia.
A M Ramsay and R Scha?ler. 1997. Case and word or-
der in English and German. In R Mitkov and N Ni-
colo, editors, Recent Advances in Natural Language
Processing. John Benjamin.
A M Ramsay, Najmeh Ahmed, and Vahid Mirzaiean.
2005. Persian word-order is free but not (quite)
discontinuous. In 5th International Conference on
Recent Advances in Natural Language Processing
(RANLP-05), pages 412?418, Borovets, Bulgaria.
Louisa Sadler. 1996. New developments in LFG. In
Keith Brown and Jim Miller, editors, Concise En-
cyclopedia of Syntactic Theories. Elsevier Science,
Oxford.
J I Saeed. 1984. The Syntax of Focus and Topic in
Somali. Helmut Buske Verlag, Hamburg.
J I Saeed. 1999. Somali. John Benjamins Publishing
Co, Amsterdam.
M Svolacchia, L Mereu, and A. Puglielli. 1995. As-
pects of discourse configurationality in Somali. In
K E Kiss, editor, Discourse Configurational Lan-
guages, pages 65?98, New York. Oxford University
Press.
344
How to change a person?s mind:
Understanding the difference between
the effects and consequences of speech acts
Debora Field and Allan Ramsay
Computer Science, Univ. of Liverpool, L69 3BX, UK
Informatics, Univ. of Manchester, PO Box 88, M60 1QD, UK
debora@ csc. liv. ac. uk,allan. ramsay@ manchester. ac. uk
Abstract
This paper discusses a planner of the semantics of utterances, whose essential
design is an epistemic theorem prover. The planner was designed for the purpose
of planning communicative actions, whose effects are famously unknowable and
unobservable by the doer/speaker, and depend on the beliefs of and inferences made
by the recipient/hearer. The fully implemented model can achieve goals that do
not match action effects, but that are rather entailed by them, which it does by
reasoning about how to act: state-space planning is interwoven with theorem proving
in such a way that a theorem prover uses the effects of actions as hypotheses. The
planner is able to model problematic conversational situations, including felicitous
and infelicitous instances of bluffing, lying, sarcasm, and stating the obvious. 1
1 Introduction
The motivation for this research was the problem of planning the semantics
of communicative actions: given that I want you to believe P, how do I choose
what meaning to express to you? The well-documented, considerable difficul-
ties involved in this problem include this: a key player in the ensuing evolution
of the post-utterance environment is the hearer of the utterance.
First, consider an imaginary robot Rob, designed not for communication,
but for making tea. Whenever he is in use, Rob?s top-level goal is to attain a
state in which there is a certain configuration of cups, saucers, hot tea, cold
milk, etc. Rob?s plans for making tea are made on the strong assumption that
at plan execution time, the cups (and other items) will have no desires and
opinions of their own concerning which positions they should take up?Rob
expects to be the author of the effects of his actions. 2
1 Initially funded by the EPSRC. Recent partial funding under EU-grant FP6/IST No.
507019 (PIPS: Personalised Information Platform for Health and Life Services).
2 notwithstanding impeding concurrent events, sensor failures, motor failures, etc.
In contrast, consider the human John, designed for doing all sorts of
things besides making tea, including communicating messages to other hu-
mans. Imagine John?s current goal is to get human Sally to believe the propo-
sition John is kind. In some respects, John has a harder problem than Rob.
Unlike Rob, John has no direct access to the environment he wishes to affect?
he cannot simply implant John is kind into Sally?s belief state. John knows
that Sally has desires and opinions of her own, and that he will have to plan
something that he considers might well lead Sally to infer John is kind. This
means that when John is planning his action?whether to give her some choco-
late, pay her a compliment, tell her he is kind, lend her his credit card?he
has to consider the many different messages Sally might infer from the one
thing John chooses to say or do. Unfortunately, there is no STRIPS operator
[13] John can choose that will have his desired effect; he has to plan an action
that he expects will entail the state he desires.
We considered ?reasoning-centred? planning of actions that entailed goals
to be an approach that would enable this difficult predicament to be managed,
and implemented a model accordingly. Our planner is, in essence, an epistemic
theorem prover that hypothesises desirable actions, and is able to plan to
achieve goals that do not match action effects, but that are entailed by the
final state. Like John, the planner can have particular communicative goals in
mind, and knows that the execution of any single plan could have a myriad
different effects on H ?s belief state, depending on what H chooses to infer.
1.1 Bucking the trend
The main focus of current research in AI planning is on how to reduce the
search space required for making plans, and thus, for example, to get Rob the
tea-making robot to be able to make his plans fast enough to be of practical
use in the real world. Many planners use heuristics, either to constrain the
generation of a search space, or to prune and guide the search through the state
space for a solution, or both [4,5,18,25]. All such planners succeed by relying
on the static effects of actions?on the fact that you can tell by inspection
what the effects of an action will be in any situation?which limits their scope
in a particular way [4, p. 299]:
?. . . if one of the actions allows the planner to dig a hole of an arbitrary inte-
gral depth, then there are potentially infinitely many objects that can be cre-
ated. . . The effect of this action cannot be determined statically . . . ?
The class of problems that these planners do not attempt to solve?the ability
to plan actions whose effects are not determined statically?was the class that
particularly interested us.
2 Planning the semantics of utterances
With our attention firmly fixed on the myriad different effects a single commu-
nicative act can have on a hearer?s belief state, we concentrated on a (logically)
very simple utterance:
?There?s a/an [some object]!?
We devised situations culminating in this utterance which illustrate sarcasm,
stating the obvious, bluffing, and lying, and developed a planner which
could use these tactics. Here is a much-shortened example of a scenario from
the model, which leads to the planning of an instance of sarcasm: 3 4
Initial state John has been bird-watching with Sally for hours, and so far,
they have only seen pigeons. John thinks Sally is feeling bored
and fed up. John has some chocolate in his bag. John thinks
Sally likes chocolate. John knows lots of rules about how con-
versation works, and what one can expect a hearer to infer
under given conditions.
Goal condition John wants to cheer Sally up.
Solutions John is just thinking about getting out some chocolate to give
her, when yet another pigeon lands in a nearby tree. John sees
an opportunity to make Sally laugh by means of a bit of sar-
casm, and so plans to say to her,
?There?s an albatross!?
John plans (the semantics of) his utterance, expecting that the utterance
will have particular ?effects? on Sally?s belief state; if John were to perform
the utterance, he would not be certain that it had achieved his intention, but
he would expect that it probably had. Whether John?s intention would be
achieved by this utterance depends on Sally having the ?right? set of beliefs
(the ones John thinks she has) and making the ?right? inferences (the ones
John expects her to make).
For example, if John?s utterance ?There?s an albatross!? is to be felicitous,
the following must happen. Sally must first believe that John has said some-
thing that Sally thinks John and Sally mutually believe is false. From this, she
must infer that John has flouted a conversational maxim, and consequently
that John has attempted to implicate a meaning which is not expressed by the
semantics of ?There?s an albatross!?. Sally must then infer that the implica-
ture John intends is of humour. Whether or not any of this happens depends
on Sally?s beliefs, which John cannot observe, but about which he has beliefs.
The formal version of this example contains all the necessary information
about the beliefs of John and Sally in this situation for the planner: (i) to be
able to plan John?s utterance; and (ii) to additionally deduce whether John?s
utterance would be felicitous or infelicitous, if he performed it.
3 The example is an English paraphrase of a task, written in the model in Prolog code.
4 An albatross (Diomedea exulans) is a huge sea-faring bird, rarely seen from the land.
2.1 Linguistic motivations
Our approach to planning the semantics of utterances was to build on seminal
work in speech acts [3,28] and pragmatics [29,15,21]. In contrast to the ?speech
acts with STRIPS? approach [6,11,1,2], which is fraught with well-documented
difficulties [9,16,26,7,27], we aimed to develop a small set of linguistic acts that
were unambiguously identifiable purely by surface linguistic form (after [7]),
including ?declare?, ?request?, and perhaps others?a set of acts with negligible
effects (after [27]), and minimal preconditions. We in fact developed a single
linguistic act for all contexts.
2.2 Planner design
The planner is essentially an epistemic theorem prover which employs some
planning search. The development process we undertook is helpful in under-
standing the planner?s design:
? A state-space search was implemented that searches backwards in hypothetical
time from the goal via STRIPS operators (based on foundational work in classical
planning [23,24,14,22,13]);
? A theorem prover for FOL was implemented that constructively proves conjunc-
tions, disjunctions, implications, and negations, and employs modus ponens and
unit resolution;
? State-space search and theorem proving were interwoven in such a way that:
? not only can disjunctions, implications and negations be proved true, they can
also be achieved;
? not only can a goal Q be proved true by proving (P ? Q) ? P, but Q can
also be achieved by proving P ? Q and achieving P ;
? a goal can be achieved by reasoning with recursive domain-specific rules?thus
the planner is able to plan to ?dig holes of arbitrary depths?.
? The theorem prover was transformed into an epistemic theorem prover by incor-
porating a theory of knowledge and belief suitable for human reasoning about
action, so agents make plans according to their beliefs about the world, including
their beliefs about others? beliefs.
A goal is proved by assuming the effect of some action is true, on the
grounds that the goal would be true in the situation that resulted from per-
forming that action. Hence, a set of actions is computed that might be useful
for achieving a goal by carrying out hypothetical proofs, where the hypotheses
are the actions whose effects have been exploited.
Here is a simple, non-dialogue example to aid explanation. Consider the
achievement of the goal above(e,f) and on(e,d), where above is the transitive
closure of on. First, it is not possible to judge whether the first goal above(e,f)
is true by inspecting the current state (which contains on( , ) facts but no
above( , ) facts), so reasoning is carried out to find out whether it is false.
Secondly, in order to achieve above(e,f), something different from an action
with an above( , ) expression in its add list is needed. Placing e onto f, for
example, will make above(e,f) proveable, but it will also make the achievement
of on(e,d) impossible. By reasoning with rules that describe the meaning of
above as the transitive closure of on, the planner hypothesises that on(d,f)
might enable the proof of above(e,f) to be completed, and also knows that
on(d,f) is an effect of action stack(d,f). A proof of the preconditions of action
stack(d,f) is carried out, and the process continues (with backtracking), until
a solution is found.
The preference for a backwards planning search was motivated by a defin-
ing quality of the communication problem, as epitomised by utterance plan-
ning: there are too many applicable actions to make a forwards search feasible.
People generally have the physical and mental capabilities to say whatever
they want at any moment. This means that the answer to the question ?What
can I say in the current state?? is something like ?Anything, I just have to
decide what I want to say?. A backwards search is far more suitable than a
forwards search under conditions like these.
With this ?reasoning-centred? design, the planner is able to plan an utter-
ance to achieve a goal, ?knowing? that the utterance may or may not achieve
the desired effects on H, and that the same utterance can have many different
effects, depending on H ?s belief state.
3 Modelling problematic conversations
In the model, utterances are planned according to Grice?s Cooperative Prin-
ciple [15]. Here is an extract from the CP (ibid p. 308):
?[Quantity]
(i) Make your contribution as informative as is required (for the current purposes
of the exchange).
(ii) Do not make your contribution more informative than is required. . .
[Quality]
(i) Do not say what you believe to be false.
(ii) Do not say that for which you lack adequate evidence.?
Grice?s maxims prescribe a standard for speaker behaviour which S can bla-
tantly contravene (?flout?), thus signalling to H that there is an implicature
to be recovered. For instance, in our ?sarcasm? scenario, John?s utterance is
planned using the following maxim, derived from Grice?s first Quality maxim. 5
The first line means, ?If S addresses H by putting Q into the conversational
minutes?:
(1) minute([S], [H], Q)
and believes(S, believes(H, mutuallybelieve(([H, S]), not(Q))))
==> believes(S, believes(H, griceuncoop(S, [H], Q)))
5 The model embodies a ?deduction? model of belief [19], rather than a ?possible worlds?
model [17,20]. Thus agents are not required to draw all logically possible inferences, and
are therefore not required to infer an infinite number of propositions from a mutual belief.
Using this maxim, John reasons that he can get Sally to realise he is flouting
a maxim in order to generate an implicature (that he is being ?Grice uncoop-
erative with respect to Q ?). But what is the nature of the implicature? This
is dealt with by two additional rules: (2), which describes what John thinks
Sally believes about the meaning of this kind of maxim-flouting; and (3), a
?general knowledge? rule:
(2) believes(john,
believes(sally,
(griceuncoop(PERSON2, _PERSON1, Q)
and mutuallybelieve(([sally,john]), not(Q)))
==> funny(PERSON2, re(Q))))
(3) believes(john,
believes(sally,
(funny(PERSON2, re(Q))
==> happy(sally))))
With these three rules, John can reason that saying something he thinks
he and Sally mutually disbelieve will make her laugh, and thus cheer her up,
thus achieving his goal. Here is a second maxim from the model, also derived
from Grice?s CP:
(4) minute([S], [H], Q)
and believes(S, believes(H, mutuallybelieve(([H, S]), Q)))
==> believes(S, believes(H, griceuncoop(S, [H], Q)))
Using this maxim, and some additional rules, John can plan to flout Quan-
tity maxim 2, and generate an implicature by ?stating the obvious?.
3.1 Modelling deception
Grice?s CP seems an excellent formalism for planning and understanding ut-
terances, so long as everyone is committed to obeying it. We know, however,
that people violate the CP maxims?S contravenes maxims without wanting
H to know. For example, lying violates Quality maxim (1) , bluffing violates
Quality maxim (2) , and being economical with the truth violates Quantity
maxim (1) . However, there is nothing in Grice?s maxims to help H deal with
the possibility that S may be trying to deceive her. Our solution is to give S
and H some further maxims which legislate for the fact that speakers do not
necessarily always adhere to the CP, and which enable S to plan to deceive,
and H to detect intended deceptions.
3.1.1 Hearer violation maxims
Given that H admits the possibility that S might be trying to deceive her
with his utterance, we consider that there are three strong predictors of how
H ?s belief state will change in response to S ?s utterance of the proposition P :
(5) i What is H ?s view of the proposition P?
ii What is H ?s view concerning the goodwill of S?
iii What is H ?s view of the reliability of S ?s testimony?
Consider, for example, an attempt at bluffing: 6
Initial state John has gone bird-watching with Sally. John is wearing a warm
coat, and he thinks that Sally looks cold. John thinks Sally will be
impressed by a chivalrous gesture. John thinks Sally is new to bird-
watching, and that she is keen to learn about birds. John knows lots
of rules about how conversation works, and what one can expect a
hearer to infer under given conditions.
Goal condition John wants Sally to be impressed by him.
Solutions John is just thinking of offering Sally his coat to wear, when a huge
bird lands in a nearby tree. John isn?t quite sure what species the
bird is, nevertheless, he decides to try and impress Sally with his
bird expertise, and plans to say to her,
?There?s a dodo!?
Let us imagine that Sally?s answers to three above questions are as follows.
Before John performed his utterance:
(6) i Sally believed that the proposition P (?There?s a dodo!?) was false (because
she knew the bird was a buzzard).
Additionally, she did not believe that John thought that they mutually be-
lieved P was false.
ii She believed that John was well-disposed towards her.
iii She didn?t know whether John was a reliable source of information or not.
After John has said ?There?s a dodo!?, Sally derives the following new set of
beliefs from the above set:
(7) i? Sally still believes that the proposition P (?There?s a dodo!?) is false.
She now believes that John thinks that they mutually believe P is true.
ii? She still believes that John is well-disposed towards her.
iii? She now believes John is an unreliable source of information.
The mapping of belief set (6) into belief set (7) is determined in the model
by a ?hearer violation (HV) maxim?. We call this maxim the ?infelicitous bluff?
HV maxim. We have so far implemented eight HV maxims, however, there is
clearly scope for many more permutations of all the different possible answers
to (6). There are obvious additional refinements that should be made, for
example, people do not normally consider others to be reliable sources of
information on all subjects.
3.1.2 Speaker violation maxims
If S is to succeed in his attempt to deceive H, he will have to take into account
how H is going to try and detect his deception. To represent this in the model,
S has his own ?speaker violation (SV) maxims?, which concern the same issues
as the HV maxims, but from the other side of the table, as it were. What S
plans to say will depend on which answer he selects from each of these four
categories:
6 A dodo is a large flightless bird that is famously extinct.
(8) i What is S ?s view of H ?s view of various different propositions?
ii What is S ?s own view of the same propositions?
iii What is S ?s view of H ?s view of the goodwill of S?
iv What is S ?s view of H ?s view of the reliability of S as a source?
Here is an example of an SV maxim from the model:
(9) minute([S], [H], Q)
and believes(S, believes(H, reliable(S)))
and believes(S, believes(H, well_disposed_towards(S, [H])))
and believes(S, believes(H, Q or not(Q)))
==> believes(S, believes(H, gricecoop(S, [H], Q)))
Using this maxim, John can reason that Sally will believe he is being Grice-
cooperative, which means Sally will believe that what he is saying is true, even
if John does not believe it himself. Thus John is able to plan to lie to Sally by
using tactics he hopes will prevent Sally from detecting his attempt to deceive.
4 Epistemic theorem prover
The planner?s theorem prover embodies a constructive/intuitionist logic and
it proves theorems by natural deduction, chosen in preference to classical logic
and its inferencing methods. The way humans do every-day inferencing is, we
consider, quite different from the way inferencing is handled under classical
logic. In classical logic, for example, and using our general knowledge, we judge
the following formulae to be true:
(10) Earth has one moon ? Elvis is dead
(11) Earth has two moons ? Elvis is alive
(12) Earth has two moons ? Elvis is dead
(10) is true simply because antecedent and consequent are both true formulae.
We find this truth odd, however, because of the absence of any discernible
relationship between antecedent and consequent. (11) and (12) are true sim-
ply because the antecedent is false, which seems very counter-intuitive. Even
more peculiarly, the following formula is provable in classical logic in all cir-
cumstances:
(13) (Earth has one moon ? Elvis is dead) or
(Elvis is dead ? Earth has one moon)
but it feels very uncomfortable to say that it must be the case that one of
these implies the other.
In order to avoid having to admit proofs like this, and to be able to do
reasoning in a more human-like way, we opted for constructive logic and natu-
ral deduction. In order to prove P ? Q by natural deduction, one must show
that Q is true when P is true; if P is not true, constructive logic does not
infer P ? Q. This treatment of implication hints at a relationship between P
and Q which is absent from material implication.
4.1 Constructive logic and belief
Taking a constructive view allows us to simplify our reasoning about when the
hearer believes something of the form P ? Q, and hence (because of the con-
structive interpretation of ?P as P ? ?) about whether she believes ?P . We
will assume that believes(H,P ) means that H could infer P on the basis of
her belief set, not that she already does believe P , and we will examine the rela-
tionship between believes(H,P ? Q) and believes(H,P ) ? believes(H,Q).
Consider first believes(H,P ) ? believes(H,Q). Under what circumstances
could you convince yourself that this held?
For a constructive proof, you would have to assume that believes(H,P )
held, and try to prove believes(H,Q). So you would say to yourself ?Suppose
I were H, and I believed P . Would I believe Q?? The obvious way to answer
this would be to try to prove Q, using what you believe to be H?s rules of
inference. If you could do this, you could assume thatH could construct a proof
of P ? Q, and hence it would be reasonable to conclude believes(H,P ? Q).
Suppose, on the other hand, that you believed believes(H,P ? Q), and
that you also believed believes(H,P ). This would mean that you thought that
H had both P ? Q and P available to her. But if you had these two available
to you, you would be able to infer Q, so since H is very similar to you she
should also be able to infer Q. So from believes(H,P ? Q) and believes(H,P )
we can infer believes(H,Q), or in other words (believes(H,P ? Q)) ?
(believes(H,P ) ? believes(H,Q)).
We thus see that if we take believes(H,P ) to mean ?If I were H I would
be able to prove P ?, then (believes(H,P ? Q)) and (believes(H,P ) ?
believes(H,Q)) are equivalent. This has considerable advantages in terms of
theorem proving, since it means that much of the time we can do our reasoning
by switching to the believer?s point of view and doing perfectly ordinary first-
order reasoning. If, in addition, we treat ?P as a shorthand for P ? ?, we
see that believes(H,?P ) is equivalent to believes(H,P ) ? believes(H,?). If
we take the further step of assuming that nobody believes ?, we can see
that believes(H,?P ) ? ?believes(H,P ) (though not ?believes(H,P ) ?
believes(H,?P )). We cannot, however, always assume that everyone?s beliefs
are consistent, so we may not always want to take this further step (note
that in possible worlds treatments, we are forced to assume that everyone?s
beliefs are consistent), but it is useful to be able to use it as a default rule,
particularly once we understand the assumptions that lie behind it.
References
[1] Allen, J. F. and C. R. Perrault, Analyzing intention in utterances (1980), AI
15: 143?78.
[2] Appelt, D. E., Planning English referring expressions (1985), AI 26: 1?33.
[3] Austin, J. L., How to do things with words (1962), Oxford: OUP, 2nd edition.
[4] Blum, A. L. and M. L. Furst, Fast planning through planning graph analysis
(1995), in Proc. 14th IJCAI, pp. 1636?1642.
[5] Bonet, B. and H. Geffner, Heuristic Search Planner (2000), AI Magazine 21(2).
[6] Bruce, B. C., Generation as a social action (1975), in B. L. Nash-Webber and
R. C. Schank (eds), Theoretical issues in natural language processing, pp. 74?7.
Cambridge, Massachusetts: ACL.
[7] Bunt, H., Dialogue pragmatics and context specification (2000), [8], pp. 81?150.
[8] Bunt, H. and W. Black, (eds), Abduction, belief and context in dialogue: studies
in computational pragmatics (2000), Philadelphia: John Benjamins.
[9] Cohen, P. R. and H. J. Levesque, Rational interaction as the basis for
communication (1990), [10], pp. 221?55.
[10] Cohen, P. R., J. Morgan and M. E. Pollack, (eds), Intentions in communication
(1990), Cambridge, Massachusetts: MIT.
[11] Cohen, P. R. and C. R. Perrault, Elements of a plan-based theory of speech
acts (1979), Cognitive Science 3: 177?212.
[12] Feigenbaum, E. A. and J. Feldman, Editors, Computers and thought (1995),
Cambridge, Massachusetts: MIT Press. First published 1963 by McGraw-Hill.
[13] Fikes, R. E. and N. J. Nilsson, STRIPS: A new approach to the application of
theorem proving to problem solving (1971), AI 2: 189?208.
[14] Green, C., Application of theorem proving to problem solving (1969), in Proc.
1st IJCAI, pp. 219?39.
[15] Grice, H. P., Logic and conversation (1975), in P. Cole and J. Morgan, (eds),
Syntax and semantics 3: Speech acts, pp. 41?58. New York: Academic Press.
[16] Grosz, B. J. and C. L. Sidner, Plans for discourse (1990), [10], pp. 416?44.
[17] Hintikka, J., Knowledge and belief: An introduction to the two notions (1962),
New York: Cornell University Press.
[18] Hoffmann, J. and B. Nebel, The FF planning system: Fast plan generation
through heuristic search (2001), Journal of AI Research 14: 253?302.
[19] Konolige, K., A deduction model of belief (1986), London: Pitman.
[20] Kripke, S., Semantical considerations on modal logic (1963), in Acta
Philosophica Fennica 16: 83?94.
[21] Lewis, D., Scorekeeping in a language game (1979), J. Phil. Logic 8: 339?59.
[22] McCarthy, J. and P. J. Hayes, Some philosophical problems from the standpoint
of artificial intelligence (1969), Machine Intelligence 4: 463?502.
[23] Newell, A., J. C. Shaw and H. A. Simon, Empirical explorations with the logic
theory machine (1957), Proc. Western Joint Computer Conference, 15: 218?239.
[24] Newell, A. and H. A. Simon, GPS, a program that simulates human thought
(1963), [12], pp. 279?93.
[25] Nguyen, X. and S. Kambhampati, Reviving partial order planning (2001), in
Proc. IJCAI, pp. 459?66.
[26] Pollack, M. E., Plans as complex mental attitudes (1990), [10], pp. 77?103.
[27] Ramsay, A., Speech act theory and epistemic planning (2000), [8], pp. 293?310.
[28] Searle, J. R., What is a speech act? (1965), in M. Black, (ed), Philosophy in
America, pp. 221?39. Allen and Unwin.
[29] Stalnaker, R., Pragmatics (1972), in D. Davidson and G. Harman, (eds),
Semantics of natural language (Synthese Library, Vol. 40), pp. 380?97.
Dordrecht, Holland: D. Reidel.
Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 94?101,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
?Sorry? seems to be the hardest word
Allan Ramsay Debora Field
School of Computer Science Dept of Computer Science
Univ of Manchester Univ of Sheffield
Manchester M60 1QD, UK Sheffield S1 4DP, UK
Abstract
We are interested in the ways that language
is used to achieve a variety of goals, where
the same utterance may have vastly different
consequences in different situations. This is
closely related to the topic of creativity in lan-
guage. The fact that the same utterance can
be used to achieve a variety of goals opens up
the possibility of using it to achieve new goals.
The current paper concentrates largely on an
implemented system for exploring how the ef-
fects of an utterance depend on the situation
in which it is produced, but we will end with
some speculations about how how utterances
can come to have new kinds of uses.
1 Introduction
We are interested in the ways that language is used to
achieve a variety of goals, where the same utterance
may have vastly different consequences in different
situations. We will take, as a running example, the
use of the single word ?Sorry?.
We will look at a number of situations in which
this word may be uttered, and investigate the ways
in which its consequences may be determined by
considering the goals and belief states of the partic-
ipants. The kinds of reasoning that lie behind the
various uses of this word are, we believe, typical of
the way that utterances can be used to achieve novel
aims. ?Sorry? is perhaps a fairly extreme case: very
simple indeed on the surface, very complex indeed
in terms of its uses. Any account of how this specific
word gets used will have lessons for other kinds of
novel action.
As with many common but slippery words, dic-
tionary definitions are not much help when trying to
work out what ?sorry? means: Merriam-Webster, for
instance, has ?feeling sorrow, regret, or penitence?
as the primary definition, and the free dictionary
(www.thefreedictionary.com has ?Feeling
or expressing sympathy, pity, or regret?. These def-
initions are, as is common for words whose mean-
ings are highly context dependent, essentially circu-
lar. How much do we gain from knowing that ?sorry?
is a word that is used to express sorrow, or from the
free dictionary?s definition of ?sympathy? as a ?feel-
ing or an expression of pity or sorrow for the distress
of another??
Perhaps, then, considering a set of examples of
situations where someone utters this word is a better
way of getting at what it means. The following is a
rather long list, but then there are a very wide set of
situations in which people say ?sorry?. That is, after
all, the problem:
(1) a. EXPRESSION OF DISAPPOINT-
MENT
I?m sorry I missed your talk. I forgot
to set my alarm. I?d really been
looking forward to seeing your demo.
b. APOLOGY FOR OWN ACTION
WHILE NOT TAKING FULL PER-
SONAL RESPONSIBILITY
I?m sorry I missed your talk. My flight
was delayed. [situation: S & H mutu-
ally knew that S was counting on H to
help with a demo during the talk.]
94
c. APOLOGY FOR OWN ACTION
WHILE ALSO TAKING FULL PER-
SONAL RESPONSIBILITY
I?m sorry I missed your talk. I forgot
to set my alarm. [situation: S & H mu-
tually knew that S was counting on H
to help with a demo during the talk.]
(2) a. EXPRESSION OF EMPATHY
I?m sorry that this situation is so awful
for you. I would not be coping if I were
in your shoes.
b. APOLOGY FOR A 3RD PARTY?S
ACTION WHILE NOT TAKING
FULL PERSONAL RESPONSIBIL-
ITY
I?m sorry that this situation is so
awful for you. My parents have
really excelled themselves this time
[sarcasm].
c. APOLOGY FOR A 3RD PARTY?S
ACTION WHILE ALSO TAKING
FULL PERSONAL RESPONSIBIL-
ITY
I?m sorry that this situation is so awful
for you. As head of the division I take
full responsibility, and I am submitting
my resignation.
d. APOLOGY FOR OWN ACTION
WHILE ALSO TAKING FULL PER-
SONAL RESPONSIBILITY
I?m sorry that this situation is so aw-
ful for you. I should have been more
careful.
e. EXPRESSION OF EMPATHY
I?m sorry that this situation is so awful
for you. I?m not sorry for causing the
situation, because I didn?t cause it. But
I am sorry it is so awful.
(3) a. EXPRESSION OF DISDAIN+PITY
I?m sorry they?re not good enough. It?s
your loss.
b. APOLOGY FOR OWN ACTION
WHILE ALSO TAKING FULL PER-
SONAL RESPONSIBILITY
I?m sorry they?re not good enough. I
tried very hard, but I couldn?t get them
quite right.
(4) a. EXPRESSION OF EMPATHY
I?m sorry, Dave, I?m afraid I can?t do
that. All the pod locks are jammed
shut. I have tried everything I can think
of, but I can?t get them open.
b. APOLOGY FOR OWN ACTION
WHILE ALSO TAKING FULL PER-
SONAL RESPONSIBILITY
I?m sorry, Dave, I?m afraid I can?t do
that. I have turned the tables and you
are my prisoner now.
(5) a. EXPRESSION OF REGRET
I?m sorry I told him. Things would be
much simpler for me now if I?d kept
quiet.
b. APOLOGY FOR OWN ACTION
WHILE ALSO TAKING FULL PER-
SONAL RESPONSIBILITY
I?m sorry I told him. I know I promised
you I wouldn?t but it just slipped out.
(6) a. EXPRESSION OF REGRET
I?m sorry I killed their daughter. She
was in the wrong place at the wrong
time. [Speaker feels no remorse for
killing, only regret for killing the
wrong person.]
b. APOLOGY FOR OWN ACTION
WHILE ALSO TAKING FULL PER-
SONAL RESPONSIBILITY
I?m sorry I killed their daughter. It was
a terrible thing I did.
If nothing else, these examples show how flexible
the word ?sorry? is. About all they have in common
is that the speaker is referring to some action or state
of affairs which is disadvantageous to someone (usu-
ally, but not necessarily, either the speaker or hearer:
see (6) for a counter-example). The follow-up sen-
tences then say something more about the speaker?s
attitude to this action or state of affairs (we will
use the generic term ?event? to cover both of these).
Just what the speaker?s attitude to the event is varies
wildly: the glosses in the examples use terms like
95
?empathy?, ?apology?, ?regret?, but these are almost
as slippery as ?sorry? itself.
2 Literal uses of ?sorry?
The idea that ?sorry? is ambiguous, with fifteen dif-
ferent senses, is ludicrous. Apart from anything else,
we have another dozen examples up our sleeves that
do not fit any of the patterns above, and it would be
easy to find yet further uses. It seems more plausi-
ble that it has a single meaning, which can be used
as the trigger for a variety of ideas depending on the
the nature of the event and the beliefs of the speaker
and hearer. The task of determining what a speaker
meant by using this word in a given utterance then
devolves to epistemic inference. This does not actu-
ally make it very easy; but it does at least put it in
the right place.
We will take it, then, that ?sorry? is an adjective
that takes a sentential complement, and that the in-
terpretation of a sentence involving it is something
like Fig. 11. In other words, (1a) says that right now
the relation sorry holds between me and the fact that
I missed your talk.
That seems fair enough, but it also seems rather
weak. We cannot do anything with it unless we
know what follows from saying that the relation
sorry holds between a person and a proposition. In
other words, we need to start writing axioms (mean-
ing postulates, rules, definitions, . . . ) to link this re-
lation with other concepts.
The first thing we note is that any such axioms
will be inherently intensional: sorry is a relationship
between a person and a proposition (a description
of a state of affairs). We will therefore have to use
1We use the ?restricted quantifiers? ?X :: {P}Q and ?X ::
{P}Q as shorthand for ?X(P ? Q) and ?X(P&Q)
?Lat(L,
sorry(ref (?M(speaker(M))),
?N: {past(now,N)}
?Oevent(miss,O,P,Q)
&?(O,object,ref (?R(own(ref (?S(hearer(S))),R) & sort(talk,R,T,U))))
&?(O,agent,ref (?V (speaker(V)))) & aspect(N,simplePast,O)))
&aspect(now,simple,L)
Figure 1: Logical form for (1a)
some kind of intensional logic for writing our ax-
ioms. We follow (Chierchia and Turner, 1987; Fox
and Lappin, 2005) in using a variant on ?property
theory? (Turner, 1987) for this purpose. Property
theory has the required expressive power for writ-
ing rules that discuss propositions, and it has an ax-
iomatisation which allows the implementation of a
practical theorem prover (Ramsay, 2001).
So what do we want to say about sorry? The very
first observation is that it is factive: if I am sorry
about something, then it must have happened. I can-
not (sensibly) say that I am sorry that the moon is
made of green cheese, because it isn?t. Our first ax-
iom, then, says that anything that anyone is sorry
about is indeed true (A1):
(A1)
?B?C(sorry(B,C) ? C)
The only other thing that all the examples above
have in common is that the speaker wishes that the
proposition she is sorry about were not true (A2):
(A2)
?B?C(sorry(B,C) ? C & wish(B,?(C)))
There are, indeed, cases where absolutely nothing
more follows from the use of ?Sorry?:
(7) My dear Pandora, you?re going to be sorry
you opened that.
In (7), the speaker is simply telling their hearer
that she is going to wish she hadn?t opened it, what-
ever it is. No hint of apology or remorse or empathy.
Just a plain a statement of fact: at some time in the
future the hearer is going to wish that she?d left the
box closed.
It is hard to find a distinction between the set of
propositions that follow from every use of a term and
its meaning. We will therefore take it that (A1) and
(A2) characterise the meaning of ?sorry?: that the
proposition in question is true, and that the person
who is sorry about it wishes that it wasn?t.
96
How, then, do all the other examples get their
force? The key is that once you have said that you
wish something were not true, two questions arise:
why do you wish it were not so, and why are you
telling me that you wish it were not so. To answer
these two questions you have to think harder about
what the proposition in question is like.
There are two particularly interesting issues.
Who, if anyone, was responsible for the proposition
being true; and who, if anyone, is affected by it. In
particular, if the speaker is the person who was re-
sponsible for it then wishing that it were not now
true entails wishing that they had not earlier per-
formed the action that led to it; and if the person
who is affected by it is the hearer, and the effect
is adverse, then the fact that the speaker wishes it
were not true establishes some degree of empathy
between the two.
Before we can start formalising these notions we
need to introduce rules that specify responsibility
and affectedness.
The simplest rules for these notions are centred
around the roles that individuals play in events.
What, for instance, is the difference between (8a)
and (8b)?
(8) a. I saw him fall off a cliff.
b. I watched him fall off a cliff.
They both refer to the same set of events: he fell
off a cliff, and I had my eyes open and looking in
that direction at the time (and I was awake, and var-
ious other routine side-conditions). The difference
is that (8b) implies a degree of control: that I was
aware that he was falling, and I deliberately kept my
attention on what I was seeing.
One way of capturing this distinction concisely is
by using names for thematic roles which reflect the
way that the individuals concerned are involved: if,
for instance, we say that the speaker was the patient
of the seeing event in (8a), but was the agent in (8b),
then we can use rules like (A3) and (A4) to distin-
guish between cases where someone was just acci-
dentally involved in an event from ones where they
caused it or where they intentionally caused it.
(A3)
?B?C: {?(C,actor,B) ? ?(C,agent,B)}
cause(B,C)
(A4)
?B?C: {?(C,agent,B)}intended(B,C)
We can use (A3) and (A4) to pick out cases where
the person who is sorry for some state of affairs is in
fact the person who caused it to come about. We will
not yet say much about what follows from recognis-
ing these cases. For the moment we will just label
them as cases where the person regrets the event in
question.
(A5)
?B?C : {wish(B,?(C))}
?D : {C ? cause(B,D)}
regret(B,D))
Note that what the person is sorry about is a
proposition, but what they regret is an event (in a
classical Davidsonian treatment of events (David-
son, 1980)). The key question here is whether the
description of the state of affairs entails the existence
of an event for which they are responsible. The rules
in (A3) and (A4) provide the relevant support in very
many cases: just using a verb whose set of thematic
roles includes one with connotations of causality is a
shorthand for making a statement about responsibil-
ity. There are, of course, other more complex cases,
but in many such cases the key lies in spotting se-
quences of causally related events where the start of
the sequence involves the person in a causal role.
Given these rules, we can distinguish between the
cases in (9):
(9) a. I?m sorry I saw him fall off a cliff.
b. I?m sorry I watched him fall off a cliff.
If we assume that the hearer believes what the
speaker tells them, then following (9)b we can ask
who believes that someone regrets something:
| ?- prove(bel(X, regret(A, B))).
A = ?#speaker?,
B = ?#166?,
X = ?#hearer? ?
yes
The hearer believes that the speaker regrets some-
thing, namely the action of watching someone fall
of a cliff (represent here by a Skolem constant #166,
introduced by the existential quantifier for the event
in the logical form for (9b), shown in Fig. 2.
97
sorry(#user,
?O: {past(now,O)}
?Pevent(watch,P,Q,R)
&?(P,
-event,
?S: {sort(cliff ,S,T,U)}
?Vevent(fall,V,W,X) & ?(V,agent,#171) & off (V,S) & aspect(now,simple,V))
&?(P,agent,#user) & aspect(O,simplePast,P))
Figure 2: Logical form for (9b)
Although the speaker regrets watching this unfor-
tunate event, he cannot be seen as apologising for it.
An apology expresses regret that the speaker caused
something unfortunate to happen to the hearer. We
need the axiom A6 below to describe this situation:
(A6)
?B?C: {regret(B,C)}
?D?E: {want(D,?(E))
& E ? event(F,C,G,H)}
apologise(B,D,C)
In other words, if B regrets performing the action
C then if C is part of some situation which D re-
gards as undesirable, the B can be seen as apologis-
ing to D.
We also need, of course, descriptions of situations
which people might find undesirable. A typical rule
might be as in (A7), which simply says that people
do not want to be hurt (any individual B wants the
proposition event(hurt,D,E,F)&?(D,object,B) to be
false for all D,E and F ):
(A7)
?B?C?Dwant(B,
?(event(hurt,D,E,F)&?(D,object,B)))
Given A6 and A7, we can see that saying ?I am
sorry I hurt you? would be an apology: the speaker
is saying that he wishes that ?I hurt you? was not
true, and since this is something which was under
the speaker?s control (so he regrets it), then since
it also something that the hearer did not want then
the speaker?s utterance of this sentence is indeed an
apology.
Clearly this approach to the problem requires a
great deal of general knowledge. There is nothing
esoteric about A7. On the contrary, it as about as
obvious a fact of life as it is possible to imagine.
Collecting a large enough body of such rules to
cope with everyday language is, indeed, a daunt-
ing task, but it is the sheer number of such rules
that make it problematic, not the nature of the rules
themselves.
Once we have this background knowledge, how-
ever, we can see that various rather subtle differ-
ences between the basic uses of ?Sorry? emerge quite
straightforwardly from rules like the ones above.
Many of these rules are inherently intensional, as
noted above, so for a program to be able to work out
whether someone is actually apologising for some
action it will have to have access to a theorem prover
for an intensional logic. Fortunately such theorem
provers exist (see e.g. (Ramsay, 2001) for an exam-
ple).
3 Indirect uses
The axioms in Section 2 let us distinguish between
some of the examples in (1)?(6). We are faced
with two remaining questions. What do we gain
by labelling some examples as instances of regret or
apology, and what do we do about the less obvious
cases?
The key to both these questions is that linguistic
acts are inherently epistemic. They are concerned
with conveying information about what the speaker
S believes, including what she believes about the
hearer H?s beliefs, with the intention of changing
H?s beliefs.
We will consider, in particular, the cases that we
have labelled as apologies. What is the point of an
apology? What does S want to achieve by making
an apology?
We have characterised apologising above as the
act of saying that S wishes some proposition P were
98
not true, in a situation where S is responsible for P
being true and is something that H would like to be
untrue. Note that all that S actually did was to say
that she wished P were not true. There is nothing
in the form of the utterance ?I am sorry that I didn?t
do the washing up? that makes it obviously different
from ?I am sorry that you didn?t do the washing up?.
The two utterances do, of course, feel very different?
one is an apology, the other is something more like
a threat or an admonition?but their structural prop-
erties are very similar. They are both, essentially,
simple declarative sentences.
To get a closer grip on why they convey such radi-
cally different underlying consequences, we will re-
visit the idea that linguistic actions are just actions,
to be dealt with by specifying their preconditions
and effects, to be linked together by some planning
algorithm so that they lead to outcomes that are de-
sirable for the speaker.
We have argued elsewhere for a very sparse treat-
ment of speech acts (Field and Ramsay, 2004; Field
and Ramsay, 2007; Ramsay and Field, 2008). The
argument starts by considering the classical use of
AI planning theory in domains such as the blocks
world, where the preconditions of an action are a
set of propositions that must hold before that action
can be performed, and the effects are a set of actions
that will definitely hold after it has been performed.
If preconditions and effects were not entirely rigid
in this way then planning algorithms, from the origi-
nal means-end analysis of (Fikes and Nilsson, 1971)
through more modern approaches that involve static
analysis of the relationships between different types
of action (Kambhampati, 1997; Nguyen and Kamb-
hampati, 2001; Blum and Furst, 1997) would just
not work.
Suppose, however, that we try to give this kind of
description of the linguistic act of stating something.
What should the preconditions and effects of the act
of stating something be?
There seem to be very few limits on the situations
in which you can state something. Consider (3) (re-
peated here).
(3) a. EXPRESSION OF DISDAIN+PITY
I?m sorry they?re not good enough. It?s
your loss.
b. APOLOGY FOR OWN ACTION
WHILE ALSO TAKING FULL PER-
SONAL RESPONSIBILITY
I?m sorry they?re not good enough. I
tried very hard, but I couldn?t get them
quite right.
It is very hard to say that the speaker is performing
two different actions when she utters the words ?I?m
sorry they?re not good enough? in these two exam-
ples. She is, clearly, intending to achieve different
outcomes in the two cases, but they are, surely, the
same action, in the same way that getting the milk
out of the fridge in order to make custard and get-
ting the milk out of the fridge in order to in order
to make space for the orange juice are the same ac-
tion. In both (3a) and (3b) S is claiming to be sorry
that they (whatever they are) are not good enough.
In (3a), of course, it is clear that she does not believe
that this is true. Nonetheless, the form of the utter-
ance makes it clear that she is making a statement.
This is typical of linguistic actions. It is possible
to state things that you do not believe, or to ask ques-
tions where you already know the answer, or to issue
commands which you do not want to have carried
out. Unless we want to have as many sub-types of
the action ?statement? as there are examples in (1)?
(6) (and then the dozen other examples that we did
not include, and then all the ones we haven?t thought
of) then we have to see whether we can make a sin-
gle, rather simple, act cover all these cases.
What are the preconditions and effects of this act?
The only completely essential precondition for mak-
ing a statement is that you have the proposition in
question in mind, and the only thing that you can
be sure that your hearer will believe is that you had
it in mind. When S states a proposition P , S may
believe it (3a); or she may disbelieve it (3b); or she
may be unsure about it (there are no examples of this
in (1)?(6), but situations where a speaker makes a
statement despite not having an opinion on whether
it is true or not can occur). The situation for H is
even less clear: H may or may not believe that S
is being honest, and he may or may not believe that
S is reliable. Hence, H may decide that although S
has claimed P she does not actually believe it; and
even if he does decide that she believes it, he may
regard her being unreliable (on, at least, the topic of
99
P ) so he may decide not to believe it anyway. And
as for what S believes that H will believe after she
has uttered P , the possibilities are almost boundless
. . . The only thing you can be reasonably sure of is
that so long as H was paying attention and the ut-
terance was not ambiguous then H will know that
a claim was made, and hence that its preconditions
must have held (because that is what preconditions
are: a set of propositions that must held in order for
the action to be performable).
The only safe characterisation of a claim seems to
be as in Fig. 3
claim(S, H, P)
pre: bel(S, P) or bel(S, ?P) or bel(S, P or ?P)
effects:
Figure 3: Preconditions and effects of ?claim?
The preconditions will hold so long as S has
thought about P (and so long as P is not something
paradoxical like the Liar Paradox). They do not hold
at all times for all speakers. Until you read the sen-
tence ?Dan Holden hit some good first serves last
night? it was not the case that you believed that this
sentence was either true or false, because you had
never thought about it before. Thus the precondi-
tions of this action are roughly equivalent to saying
that S has the proposition P in her mind.
Given the extremely wide range of conclusions
that H can come to, it seems safest not to say any-
thing about the effects of a claim. It would be fairly
pointless to say that the effects of a claim are either
H believes S believes P or H believes that S does
not believe P or H believes that S believes that P is
false, and that either H believes P or H is agnostic
about P or H believes P is false. What we can say
is that if H realises that S has claimed P then he
will be recognise that S deliberately raised the topic
of P ?s truth value. In order to come to a conclusion
about why S should do this, he will have to come
to some view on S?s opinion of P . In other words,
a claim is an invitation to verify bel(S, P) or bel(S,
?P) or bel(S, P or ?P).
This will, of course, always be verifiable unless
P is a paradox, but the process of verification will
typically have side-effects. In particular, bel(S, P)
or bel(S, ?P) or bel(S, P or ?P) can be verified
by showing that bel(S, P) holds, or by showing that
bel(S, ?P) holds. H?s first move, then, will be to
investigate bel(S, P). S will know this, so if S does
believe P then if she also thinks that H has a reason-
able model of her beliefs then she will conclude that
H will shortly have the proposition bel(S, P) avail-
able to him.
If, on the other hand, S believes that P is false
then again assuming that H has a reasonable model
of her beliefs she can assume that he will shortly
have bel(S, ?P) available to him. In other words, if S
believes that H?s picture of her beliefs is reasonably
complete and reasonably accurate then by claiming
P she can bring either P or ?P to H?s attention.
Given that linguistic acts are public, in the sense
that all the participants are aware that they have
taken place and that all the other participants are
aware of this, both S and H will be aware that
H knows that one of bel(S,P ), bel(S,?P ) and
bel(S,Por?P ) is true. However, this disjunction is
so uninformative that it amounts to an invitation to
H to try to work out which disjunct actually holds.
Furthermore, S knows that it is tantamount to such
an invitation, and H knows that S knows this. Thus
the simple act of producing a highly uninformative
utterance in a public situation will lead both S and
H to expect that they will both believe that H will
try find out which of the disjuncts actually holds.
This allows S to say ?I?m sorry they?re not good
enough? in a situation where both parties know that
S actually believes they are good enough. H will
try to check the preconditions of S?s act of claiming
to be sorry about the situation. He will not man-
age to verify that S is sorry about, but he can show
that she is not: the fact that she believes they are
good enough will clash with (A1), which says that
you can only actually be sorry about things that are
true. Thus S has brought to the fact that she does
not believe they are not good enough, whilst also
raising the possibility that she might have been, but
is not, sorry about something. She has done so in a
way that has forced H to think about it, and to arrive
at these conclusions for himself, which is likely to
be more forceful and indeed more convincing than
if she had just asserted it. In other words, by saying
that she has sorry about something she has conveyed
the complex message that the proposition in ques-
tion is not true, and that she is not apologising for
100
H?s disappointment with the situation.
4 Conclusions
In the first part of the paper we explored the way
that the consequences of direct uses of a word like
?Sorry? can vary, depending on aspects of the propo-
sition under consideration. Saying that you wish
some state of affairs for which you are responsi-
ble and which adversely affects your hearer did not
hold has different consequences from saying that
you wish that some more neutral proposition were
true. The degree of (admitted) responsibility of the
speaker for the situation affects these consequences
? ?I?m sorry I shrank your favourite jumper? carries
a different message from ?I?m sorry your favourite
jumper shrank when I did the washing yesterday? be-
cause of the indirectness of the causal link between
me and the shrinking in the second example. We
have all the machinery for accounting for examples
like these implemented, via a theorem prover which
can handle intensionality and which can effectively
ascribe beliefs to individuals. Clearly this relies on
background knowledge about everyday facts such as
the obsvervation that people generally dislike being
hurt (A7). We do not have a massive repository of
such general knowledge, and inspection of publicly
available sources such as CYC and ConceptNet sug-
gests that they generally omit such very basic facts,
presumably because they are so self-evident that the
are below the radar of the compilers. Nonethe-
less, there is nothing about such rules that makes
them particularly difficult to express, and we have no
doubt that if we had more general-knowledge of this
kind then we would be able to determine the conse-
quences of a wide range of literal uses of ?Sorry?.
The later discussion of indirect uses of ?sorry?
is more speculative: we have an implementation
of a planner which can use very underspecified ac-
tions descriptions of the kind in Fig. 3 by look-
ing for instantiations of such an action which en-
tail some proposition in a particular situation, rather
than simply looking for actions whose effects match
the user?s goals, and we have used this to explore a
number of examples of ?indirect speech acts?. There
is more work to be done here, but the kind of anal-
ysis we are looking at has the potential for handling
entirely novel uses of linguistic acts that approaches
that enumerate a fixed set of acts (e.g. (Austin, 1962;
Searle, 1969; Cohen and Perrault, 1979; Allen and
Perrault, 1980; Cohen et al, 1990) with detailed pre-
conditions and effects, would find more difficult. In
the same way that having a very simple definition of
?sorry? and allowing the different consequences to
emerge in the light of other information that is avail-
able in the situation lets us treat an open-ended set
of literal uses of this word, using a very simple no-
tion of linguistic act and allowing the different con-
sequences to emerge in different situations leads to
the possibility of accounting for entirely novel uses.
References
J F Allen and C R Perrault. 1980. Analysing intention in utter-
ances. Artificial Intelligence, 15:148?178.
J Austin. 1962. How to Do Things with Words. Oxford Univer-
sity Press, Oxford.
A Blum and M L Furst. 1997. Fast planning through planning
graph analysis. Artificial Intelligence, 90(1-2).
G Chierchia and R Turner. 1987. Semantics and property the-
ory. Linguistics and Philosophy, 11(3).
P R Cohen and C R Perrault. 1979. Elements of a plan-based
theory of speech acts. Cognitive Science, 7(2):171?190.
P R Cohen, J Morgan, and M E Pollack. 1990. Intentions in
Communication. Bradford Books, Cambridge, Mass.
D Davidson. 1980. Essays on actions and events. Clarendon
Press, Oxford.
D G Field and A M Ramsay. 2004. Sarcasm, deception, and
stating the obvious: Planning dialogue without speech acts.
Artificial Intelligence Review, 22:149?171.
D G Field and A M Ramsay. 2007. Minimal sets of minimal
speech acts. In Recent Advances in Natural Language Pro-
cessing (RANLP?07), pages 193?199, Borovets, Bulgaria.
R E Fikes and N J Nilsson. 1971. Strips: a new approach to the
application of theorem proving to problem solving. Artificial
Intelligence, 3(4):251?288.
C Fox and S Lappin. 2005. Foundations of Intensional Seman-
tics. Blackwell.
S Kambhampati. 1997. Refinement planning as a unifiying
framework for plan synthesis. AI Magazine, 18(2):67?97.
X Nguyen and S Kambhampati. 2001. Reviving partial order
planning. In IJCAI, pages 459?466.
A M Ramsay and D G Field. 2008. Speech acts, epistemic
planning and Grice?s maxims. Logic and Computation,
18:431?457.
A M Ramsay. 2001. Theorem proving for untyped constructive
?-calculus: implementation and application. Logic Journal
of the Interest Group in Pure and Applied Logics, 9(1):89?
106.
J R Searle. 1969. Speech Acts: an Essay in the Philosophy of
Language. Cambridge University Press, Cambridge.
R Turner. 1987. A theory of properties. Journal of Symbolic
Logic, 52(2):455?472.
101
Proceedings of the 8th International Conference on Computational Semantics, pages 181?194,
Tilburg, January 2009. c?2009 International Conference on Computational Semantics
Using English for commonsense knowledge
Allan Ramsay Debora Field
School of Computer Science Dept of Computer Science
Univ of Manchester Univ of Sheffield
Manchester M60 1QD, UK Sheffield S1 4DP, UK
Abstract
The work reported here arises from an attempt to provide a body
of simple information about diet and its effect on various common
medical conditions. Expressing this knowledge in natural language
has a number of advantages. It also raises a number of difficult issues.
We will consider solutions, and partial solutions, to these issues below.
1 Commonse knowledge
Suppose you wanted to have a system that could provide advice about what
you should and should not eat if you suffer from various common medical
conditions. You might expect, at the very least, to be able to have dialogues
like (1).
(1) a. User: I am allergic to eggs.
Computer: OK
User: Should I eat pancakes
Computer: No, because pancakes contain eggs, and eating things which
contain eggs will make you ill if you are allergic to eggs.
b. User: My son is very fat.
Computer: OK
User: Should he go swimming.
Computer: Yes, because swimming is a form of exercise, and exercise is
good for people who are overweight.
c. User: I have scurvy.
Computer: OK
User: Is eating berries good for me?
Computer: Yes, because berries contain vitamin C and eating fruit which
contains vitamin C is good for people who scurvy.
181
These are comparatively simple dialogues, requiring a very limited
amount of knowledge about foods and medical conditions. As we will see,
however, dealing with them does require a remarkable amount of knowledge
about language.
The framework we are using makes a number of very basic assumptions
about how you design a system to deal with such dialogues.
? To give appropriate answers to these questions you have to consider
whether the available information supports or contradicts the queried
proposition.
? In order to see whether the available information supports or contra-
dicts a proposition you need a body of domain knowledge, and you
need to be able to reason with it.
? Natural languages provide numerous ways of saying almost identical
things. There is, for instance, almost no difference between ?I am
allergic to eggs? and ?I have an allergy to eggs? . You therefore have to
have a way of dealing with paraphrases.
We will explore each of these issues in turn below.
2 Answering questions
We will concentrate here on polar (YES/NO) questions. We also take the
very simple view that when someone asks a polar question it is because they
want to know whether the proposition encoded in the question is true or
not. Someone who asks ?Is it safe for me to eggs?? wants to be told ?Yes?
if it is and ?No? if it is not. We have explored the nature of WH-questions
elsewhere (Ramsay & Seville, 2001), and we have discussed situations where
people use language in indirect ways (Ramsay & Field, 2008), but for the
moment just trying to answer polar questions will pose enough problems to
keep us occupied.
In order to answer such a question by saying ?Yes? you have to see
whether ?It is safe for the speaker to eat eggs? follows from what you know
about the speaker and your general knowledge. You cannot, however, say
?No? simply because your attempted proof that it is safe failed. If you failed
to prove that it is safe you should then see whether you can prove that it is
not. If, and only if, you can then you should say ?no? .
In general, then, answering a polar question may involve two attempted
proofs?one aimed at showing that the proposition under discussion is true
182
and then possibly a second aimed at showing that it is false. If you are
lucky you might discover evidence that the proposition is false while you are
trying to show that it is true, but in general you may have to attempt two
proofs.
In order to carry out proofs you need an inference engine. Inference
engines come in all sorts of shapes and sizes?fast or slow, sound or unsound,
complete or incomplete?and they can be applied to a variety of knowledge
representation schemes. The choice of representation scheme, and of the
inference engine that you apply to it, will depend on what you want to do
with it. For our current task we assume that soundness is crucial, since
you really would not want a medical advice system to give wrong advice;
and that the representation scheme has to be highly expressive, since the
relations involved are subtle and need to be represented very carefully.
This leads us to a very classical architecture: we construct formal para-
phrases (logical forms, LFs) of the user?s statements and questions, and we
use a theorem prover to investigate the status of the propositions encoded in
the user?s questions. We are, in particular, not following the pattern match-
ing path taken in most ?textual entailment? systems, since the informal rules
used in such systems are not guaranteed to be sound.
We use ?property theory? (Turner, 1987; Chierchia & Turner, 1987) as our
formal language. There are very strong grounds for believing that natural
language is inherently intensional (we will see some examples below, but
the simple presence of verbs of propositional attitude is hard to cope with
unless you allow some degree of intensionality). There are a number of
logics which allow for a degree of intensionality?the typed logic used by
Montague (Montague, 1974; Dowty et al, 1981), the notion of non-well-
founded sets (Aczel, 1988) used in situation semantics (Barwise & Perry,
1983), Bealer (1989)?s intensional logic, and so on. We choose property
theory because one of Turner?s axiomatisations draws a very strong analogy
with modal logic which in turn suggests ways of adapting standard first-order
theorem proving techniques for it. We have developed a theorem prover for
a constructive version of property theory along these lines (Ramsay, 1995;
Cryan & Ramsay, 1997), and have shown that it is sound (Ramsay, 2001).
No theorem prover for a logic with this degree of expressive power can be
complete?property theory, like default logic, is worse than first-order logic
in this respect, in that it is not even recursively enumerable. Practical
systems for first-order logic, however, do not proceed by enumerating all the
theorems. They do their best, and if they cannot find an answer within a
reasonable period of time then they give up. This the only sensible thing to
do, and it is just as sensible when reasoning with more expressive languages.
183
We do not, however, just want to find out whether the answer to the
user?s question is ?Yes? or ?No? . We would also like to provide them with
some explanation of how we arrived at our conclusion. It is much better to
answer ?Should I eat pancakes?? with ?No, because pancakes contain eggs,
and eating things which contain eggs will make you ill if you are allergic
to eggs.? than just by saying ?No? . The user will be more likely to accept
the system?s answer if it comes with some supporting explanation, and they
may also be able to generalise from the explanation to cover other cases.
Where might we get such explanatory material from? The obvious place
to look is in the trace of the proof that led to the conclusion. The proof
tree contains the facts and rules that the system used in arriving at its
conclusion. Showing these facts and rules to the user would let them see
why the system believes that the queried proposition is true or false, and
lets them judge the trustworthiness of what the system says.
There are two difficult problems to be addressed here. The first is that
the proof tree will contain a mixture of things that the user themselves
said, things are blindingly obvious and things that the system suspects that
the user might not know. The explanation should probably concentrate on
things that the user might not have been aware of, so we should be looking
for items in the proof tree that the system believes the user may not know.
In other words, we need an epistemic version of property theory, and we
need to be able to inspect facts and rules to see who has access to them.
We will not discuss this further here, except to note that in the concrete
examples below we are not doing this, so that the support for the system?s
conclusions currently includes material that the user would actually already
be aware of.
The second problem is that it is extremely difficult to generate natural
language text from arbitrary logical expressions. We use standard composi-
tional techniques to build our logical forms on the basis of the form of the
input text (van Genabith & Crouch, 1997; Konrad et al, 1996). However,
as with virtually any practical theorem prover, we then perform a number of
transformations (Skolemisation, distribution of negation, splitting rules with
conjunctive heads) to our logical forms in order to make them amenable to
the theorem prover. By the time we have done this there is very little hope
of using the compositional semantics in reverse to generate natural language
text from elements of the proof tree. There is, in particular, no chance of
using head-driven generation (Shieber et al, 1990) to produce text from el-
ements of the logical form, since this approach requires that the elements of
the logical form be unifiable with the meanings of lexical items in order to
drive the selection and combination of words. This is just not feasible with
184
the elements of a proof tree.
Where do the facts and rules that appear in the proof tree come from?
We clearly have to specify them in advance in some form. Some of this
information comes from the user, in the form of statements about their
conditions, but most of it will have to provided explicitly.
We can do this in a variety of ways. We could try to use some existing
resource?WordNet, CYC, some medical ontology. It turns out that these re-
sources, or at least the publicly available ones, lack a great deal of what we
need. Very few such resources contain the kind of rules you need for answer-
ing questions such as the ones in (1). Lexical resources contain information
about relations between words. WordNet, for instance, provides hypersensi-
tivity reaction, hypersensitivity, sensitivity, susceptibility, condition, state,
attribute, abstraction, entity as hypernyms of ?allergy??all perfectly sensi-
ble hypernyms, but not all that useful for answering (1a). Likewise the
only mention of allergy or allergic in the ontology in OpenGalen (version
7, downloaded 09/10/08) says that an allergy is a kind of pathology, and
SnoMed has ?propensity to adverse reactions? and disease as hypernyms, and
a variety of links to special types of allergies and other related conditions.
This is not, of course, an exhaustive search of all potentially relevant
ontologies, but it does suggest that the kind of information stored in a typical
ontology is not what we require for answering our questions. It is, however,
extremely interesting to note that WordNet contains an English gloss for
?allergy? as ?hypersensitivity reaction to a particular allergen; symptoms can
vary greatly in intensity? , OpenGalen contains the text ?Hypersensitivity
caused by exposure to a particular antigen (allergen) resulting in a marked
increase in reactivity to that antigen upon subsequent exposure sometimes
resulting in harmful immunologic consequences.? and SnoMed provides very
brief English glosses. It seems as though when ontology designers want to
say what a term really means, they resort to natural language.
It also seems as though this kind of ontology fails to include ?common-
sense? knowledge, e.g. that if you are allergic to a foodstuff then you should
not eat it. We need this kind of information in order to answer questions.
The prevalence of natural language glosses in ontological resources of this
kind, suggests that expressing it in natural language might be a good idea.
Using natural language to express the knowledge that we need has a
number of advantages:
? It is comparatively easy. Most people (even logicians and semanti-
cists!) generally find it easiest to express themselves in their native
language. It is much easier to write ?If you are allergic to something
185
then eating it will make you ill? than to express the same rule in some
formal language.
? Linking knowledge that has been expressed in natural language with
facts and queries that have been expressed in natural language obvi-
ates the need for a set of terminological mappings between domain
knowledge and natural language. The vocabularies used in termino-
logical databases tend to have a superfical resemblance to words in
natural languages, but the mapping is seldom exact, and indeed the
types associated with such terms are often quite different. If all your
knowledge is expressed in natural language then this kind of problem
can be avoided.
? Finally, it makes it much easier to generate answers. If we keep a link
between surface text and logic we can retrieve the surface text from
the proof tree. This does not entirely solve the problem of producing
coherent natural language answers, but it does make it much simpler.
3 English with variables
We therefore want to try writing down various commonsense rules in English.
To make it slightly easier to write rules, we allow variables in various places.
Thus we write (2b) rather than (2a).
(2) a. Eating fruit which contains vitamin C is good for you if you have
scurvy
b. Eating fruit which contains vitamin C is good for X if X has scurvy
This is helpful here simply to get around the fact that ?you? is normally
taken to be a reference to the hearer, whereas in (2a) it is being used in a
rather generic way. Rather than allowing ?you? to be ambiguous in this way,
we simply allow variables to be used in natural language.
The logical form we obtain for (2b) is shown in Fig. 1. There are a
number of things to note about Fig. 1:
? It?s enormous. Reading it you can see how it relates to (2b) itself,
but producing something like this by hand would certainly be a major
challenge. However, if we have a set of rules that explain the relation-
ship between structural (lexical and syntactic) choices and semantics
then we can obtain Fig. 1 directly from the parse tree of (2b). This and
186
?X?Bevent(B ,have)
&?C : {scurvy(C , D)}?(B ,object ,C )
&?(B ,agent ,X )
&aspect(now ,simple,B)
? ?Estate(E,
?F (?Gevent(G,eat)
& ?H : {fruit(H , I)
& ?Jevent(J ,contain)
& ?(J ,
object,
ref (?K(vitamin(K )
& ?(K ,
type,
ref (?L(named(L,C )))))))
& ?(J ,agent ,H )
& aspect(now ,simple,J )}
?(G,object ,H )
& ?(G, agent, F )),
?M(?N(good(N ,M ,normal))))
&for(E ,X )
&aspect(now ,simple,E )
Figure 1: Logical form for (2b)
all other logical forms in this paper were produced by applying compo-
sitional rules to the first parse we obtained from the relevant texts. So
although it is indeed enormous, and complicated, all we have to do is
write the rule in English and the system will take care of the rest.
? The analysis of ?eating fruit which contains vitamin C is good for you?
introduces a relationship between two intensional objects, namely ?the
kind of event where someone eats fruit which contains vitamin C? and
?the property of being good?. This has significant consequences for the
kind of inference that is required. We will explore this further below.
Once we allow variables in places where you might expect an NP, it
becomes tempting to introduce them in other places. The consequences of
doing this are interesting:
(3) a. Eating something will make you ill if you are allergic to it
b. Eating P will make X ill if X is allergic to P
187
Again the second version of the rule sidesteps some tricky details to do
with pronouns, but the formal paraphrase throws up some awkward issues.
?X?P?Cstate(C ,X , ?D(?E(allergic(E ,D ,normal)))) &to(C ,P)
&aspect(now ,simple,C )
? ?F : {future(now ,F )}
?Bevent(B ,make)
&?(B ,object ,X )
&?(B ,object1 , ?G(?H(ill(H ,G,normal))))
&?(B,
agent,
?I ?Jevent(J ,eat)
&?K : {P : K}?(J ,object ,K )
&?(J ,agent ,I ))
&aspect(F ,simple,B)
Figure 2: Logical form for (3b)
The new problem in Fig. 2 is the paraphrase of ?eating P will make X ill? ,
where ?P? stands for something like ?something of type P? . In other words,
P here is a variable noun rather than a variable NP.
Under almost any analysis, nouns denote kinds rather than individuals.
But that means that (3b) involves quantification over kinds, which is again
very intensional.
4 Inference
Constructing LFs which involve relations between intensional entities is not
problematic. As noted above, we know there are formal languages which al-
low for intensionality, so all we have to do is choose one of these for our LFs.
Indeed, most approaches to compositionality exploit ?-abstraction and ?-
reduction, so the intermediate objects that are constructed are inherently in-
tensional anyway. Anyone who takes the interpretation of ?man in a park? to
be something like ?A(?B : {park(B , C)}?D(man(D , E) & in(D ,B))&(A :
D)) (i.e. the standard Montague representation) is using an intensional
language as an intermediate representation.
Problems only arise when we try to reason with representations of this
kind. There is, however, very little point in making LFs if you are not going
to reason with them, so we do have to worry about it. To see a concrete
example, reconsider (1c), repeated as (4):
188
(4) [ User: I have scurvy.
Computer: OK
User: Is eating berries good for me?
Computer: Yes, because berries contain vitamin C and eating fruit which
contains vitamin C is good for people who scurvy.
Our rule about scurvy says that events of a certain kind are good for
people who have scurvy. The description of these events occupies an argu-
ment position in the LF, as one of the terms describing the general state of
affairs that holds if someone has scurvy.
In Prolog-based first-order theorem provers, you determine whether you
can use a rule to prove a goal by unifying the arguments of the goal with
the arguments of the consequent of the rule
1
. In the current case, this would
mean unifying the terms describing ?eating fruit which contains vitamin C?-
events and ?eating berries?-events.
Clearly these descriptions will not unify. What we have to do is to accept
that the rule can be used with terms that describe subsets of the classes that
appear in argument positions.
We do not want to do this everywhere. This is a characteristic of the rule
about the link between vitamin C and scurvy, not a general characteristic
of all rules. When we want to allow for this, we have to say so explicitly.
We therefore include a rule which says that the idea that events of some
kind are good or bad or safe or . . . for you is ?downward entailing?: if eating
fruit which contains vitamin C is good for you then eating berries is good
for you, because the set of ?eating berries?-events is a subset of the set of
?eating fruit which contains vitamin C?-events. This rule is given in Fig. 3.
?B?C?D : {?F : {state(B ,F ,E ,for(C ))&(?G(D:G) ? (F:G))}
state(B ,D ,E ,for(C ))
Figure 3: Downward entailment for states
Fig. 3 says that if events that satisfy the description F satisfy the property
E for the individual C, then so do all events whose description G entails F .
We need a similar rule to say that this kind of relationship is upward
entailing in the third argument?that anything which is good for you, for
1
Prolog-based theorem proving is a special case of resolution theorem proving. In
general resolution theorem provers you have to unify some positive literal in one clause with
a negative one in another. For simplicity we will talk in terms of goals and consequents,
but the analysis would apply to other resolution-based engines.
189
instance, is also safe for you. Rules like these exploit a notion of ?guarded
intensionality?, in that they are only applicable when you already know what
properties you are interested in. They thus essentially act as schemas for
first-order rules. If we only use them backwards, in situations where we
know what properties we are interested in, they can be applied in a fairly
controlled way, and hence do not introduce wild combinatorial problems.
This is not the only kind of intensional rule that we need, but it does
cover a substantial number of interesting cases. The theorem prover de-
scribed in (Ramsay, 2001) can cope with more general intensional rules, but
guarded rules of this kind can be dealt with more efficiently than general
rules, and they are particularly useful for axiomatising the phenomena that
interest us.
5 Paraphrases and other lexical relations
It is clear that we need to treat with a variety of relations between everyday
terms. We will return, as an example, to (1b), repeated here as (5).
(5) User: My son is very fat.
Computer: OK
User: Should he go swimming.
Computer: Yes, because swimming is a form of exercise, and exercise is good
for people who are overweight.
The computer?s answer to the user?s question clearly depends on an
understanding that if something is good for you then you should do it.
To say this is not, of course, to provide a complete characterisation of the
meaning of ?should? . It is just a piece of commonsense. Nonetheless, for a
system to be able to cope with (1b) it has to have access to this piece of
commonsense. Fig. 4 shows the axiomatisation of this notion: if events of
the kind described by B are good C, then if I describes an action whose
performance entailed that B held for C then I should happen.
?B?C?D : {state(D ,B , ?E(?F (good(E ,F ,G))),for(C ))
&(?H(I:H )) ? (B:C ))}
?J : {aspect(now ,simple,J )}should(J ,I )
Figure 4: If something?s good for you then you should do it
190
There are a variety of other very basic elements of commonsense which
have to be captured, and which are not generally included in formal ontolo-
gies. We need to know, for instance, that something cannot be both good
and bad, and that dangerous things are bad, and so on. Some of these can
only be axiomatised manually, but the aim is to keep things that have to
be encoded manually to a minimum. As noted earlier, writing axioms in
English is generally easier and it also makes them easily available for use
in explanations. Very basic things like the fact that things cannot be both
good and bad are unlikely to be required for explanations, even if they do
take part in proofs, so the fact that they are unavailable for this purpose
does not matter.
Some of these basic relations turn out to be bi-equivalences, or as near to
bi-equivalences as makes no difference. It is extremely difficult, for instance,
to articulate any difference between (6a) and (6b).
(6) a. I have an allergy to eggs.
b. I am allergic to eggs.
We could take account of this by introducing a pair of implications: ?X
has an allergy to P if X is allergic to P? and ?X is allergic to P if X has
an allergy to P? . This would work, in the sense that we would be able to
use these two constructions interchangeably, but it would slow the inference
engine down considerably. The presence of any pair of rules of the form
P ? Q and Q ? P will inevitably slow any theorem prover down, since any
attempt to prove Q is likely to lead to an attempt to prove P , which will in
turn lead to an attempt to prove Q. It is not difficult to catch simple loops
of this kind, but it is better to avoid them in the first place if possible.
We therefore use rules like this as part of the normal-forming pro-
cess. Construction of normal forms generally involves application of bi-
equivalences where one side has a form which is particularly well-suited to
the needs of a particular theorem proving algorithm. In resolution, for in-
stance, the rules ?(P&Q) ? (?P ? ?Q) and ?(P ? Q) ? (?P&?Q) are
used during the construction of the normal form because resolution looks
for matching positive and negative literals, so axioms that can be used to
ensure that the only negation signs appear at the lowest possible level are
useful.
The point of normal-forming, then, is to ensure that bi-equivalences are
applied just once, and in just one direction. We thus apply bi-equivalences
like the one between (6a) and (6b) during the construction the construction
of logical forms. This lets us cope with the fact that natural languages
191
typically provide a range of ways of saying virtually the same thing without
incurring the expense of applying rules which potentially lead to loops when
we are carrying out inferences.
There is a complication here. The system needs to realise that (7a) and
(7b) are also the same (and likewise for other variations).
(7) a. I have a severe allergy to eggs.
b. I am severely allergic to eggs.
Dealing with this requires considerable care in the design of logical forms.
Space precludes a deeper discussion of this issue, but this is something we
have to take care over.
6 Conclusions
The work described here covers very similar ground to work in textual en-
tailment (Dagan et al, 2005), in that we want to draw inferences based
on facts and rules expressed in natural language. Producing logical forms
and then using a theorem prover to carry out the required inference leads
to more reliable conclusions, since we can check that the theorem prover is
sound, and hence we can rely on the conclusions that it draws. It also leads
to deeper chains of inference, since the pattern matching algorithms gen-
erally employed for textual entailment do not lend themselves to repeated
application.
The approach outlined here does involve a number of risks. We might
not be able to express all the knowledge we want in natural language; we
might not be able to produce logical forms from our natural language rules;
when we have more rules the theorem prover might not be able to cope.
The last of these is the most dangerous. If there are rules which we
cannot express in natural language, or where we cannot convert the natural
language into a logical form, we can always express them directly in property
theory (or property theory with procedural attachment of appropriate, e.g.
mathematical, rules (Steels, 1979)). How long will it take when there are
large numbers of rules? The proofs for the examples here take around 0.1
sec. Most of this time is spent investigating intensional rules. Most of the
commonsense knowledge, however, is represented as Horn clauses. Indeed it
is represented as pure Prolog. The speed of Prolog programs is not affected
by the number of clauses that are present, so we are confident that adding
more rules will have very little effect on the performance so long as they
can be represented as Horn clauses. The key issue, then, is how many new
192
intensional rules we will need. Only time will tell, but we are hopeful that
we will retain a reasonable level of performance even when we have a more
substantial set of rules. If not, we will just have to make the theorem prover
faster.
References
P. Aczel (1988). Non-Well-Founded-Sets. CSLI Publications, Stanford.
J. Barwise & J. Perry (1983). Situations and Attitudes. Bradford Books, Cambridge,
MA.
G. Bealer (1989). ?Fine-grained type-free intensionality?. In G. Chierchia, B. H.
Partee, & R. Turner (eds.), Properties, types and meaning: vol I, foundational
issues. Kluwer Academic Publishers, Dordrecht/Boston/London.
G. Chierchia & R. Turner (1987). ?Semantics and Property Theory?. Linguistics
and Philosophy 11(3).
M. Cryan & A. M. Ramsay (1997). ?A Normal Form for Property Theory?. In Pro-
ceedings of the 14th International Conference on Automated Deduction (CADE-
14), vol. 1249 of Lecture Notes in Artificial Intelligence, pp. 237?251, Berlin.
Springer-Verlag.
I. Dagan, et al (2005). ?The PASCAL Recognising Textual Entailment Challenge?.
In Proceedings of Pascal Challenge Workshop on Recognizing Textual Entailment.
D. R. Dowty, et al (1981). Introduction to Montague Semantics. D. Reidel, Dor-
drecht.
K. Konrad, et al (1996). ?An education and research tool for computational se-
mantics?. In Proceedings of the 16th International Conference on Computational
Linguistics (COLING-96), pp. 1098?1102, Copenhagen.
R. Montague (1974). ?The proper treatment of quantification in ordinary English?.
In R. Thomason (ed.), Formal Philosophy: Selected Papers of Richard Montague,
New Haven. Yale University Press.
A. M. Ramsay (1995). ?A Theorem Prover for an Intensional Logic?. Journal of
Automated Reasoning 14:237?255.
A. M. Ramsay (2001). ?Theorem proving for untyped constructive ?-calculus: im-
plementation and application?. Logic Journal of the Interest Group in Pure and
Applied Logics 9(1):89?106.
A. M. Ramsay & D. G. Field (2008). ?Speech acts, epistemic planning and Grice?s
maxims?. Logic and Computation 18:431?457.
A. M. Ramsay & H. L. Seville (2001). ?Relevant Answers to WH-questions?. In 3rd
International Conference on Inference in Computational Semantics, pp. 73?86,
Siena.
193
S. M. Shieber, et al (1990). ?Semantic-Head-Driven Generation?. Computational
Linguistics 16(1):30?42.
L. Steels (1979). ?Procedural attachment?. Tech. rep., MIT.
R. Turner (1987). ?A Theory of Properties?. Journal of Symbolic Logic 52(2):455?
472.
J. van Genabith & R. Crouch (1997). ?How to glue a donkey to an f-structure?.
In H. C. Bunt, L. Kievit, R. Muskens, & M. Verlinden (eds.), 2nd International
Workshop on Computational Semantics, pp. 52?65, University of Tilburg.
Appendix: commonsense rules
(8) a. eating P will make X ill if X is allergic to P.
b. exercise is good for X if X is overweight.
c. swimming is good for X if exercise is good for X.
d. walking is good for X if exercise is good for X.
e. eating fruit which contains vitamin C is good for X if X has scurvy.
f. X eats P if X eats something which contains P.
g. X is dangerous for Y if X will make Y ill.
194
Everyday Language is Highly
Intensional
Allan Ramsay
University of Manchester (UK)
email: allan.ramsay@manchester.ac.uk
Debora Field
University of Sheffield (UK)
email: D.Field@sheffield.ac.uk
Abstract
There has recently been a great deal of work aimed at trying to extract
information from substantial texts for tasks such as question answering.
Much of this work has dealt with texts which are reasonably large, but
which are known to contain reliable relevant information, e.g. FAQ lists,
on-line encyclopaedias, rather than looking at huge unorganised resources
such as the web. We believe, however, that even this work underestimates
the complexity and subtlety of language, and hence will inevitably be
restricted in what it can cope with. In particular, everyday use of lan-
guage involves considerable amounts of reasoning over intensional ob-
jects (properties and propositions). In order to respond appropriately to
simple-seeming questions such as ?Is going for a walk good for me??, for
instance, you have to be able to talk about event-types, which are intrinsi-
cally intensional. We discuss the issues involved in handling such items,
and shows the kind of background knowledge that is required for drawing
the appropriate conclusions about them.
193
194 Ramsay and Field
1 Introduction
The work reported here aims to allow users to interact with a health information sys-
tem via natural language. In this context, allowing a user to make simple statements
about their condition and then ask questions about what they can or should do, as in
(1), seems to be a minimal requirement.
(1) My doctor says I am allergic to eggs. Is it safe for me to eat cake?
Understanding such utterances requires the use of a highly intensional representa-
tion language, and responding to them requires a surprising amount of background
knowledge. We will consider below the problems that such everyday utterances bring
for formal paraphrases of natural language, and we will look at the kind of back-
ground knowledge that is required for producing the right kinds of response. In order
to produce a system that carries out the required inference we need access to an in-
ference engine for carrying out proofs in a representation language with the required
expressive power. The details of the engine we use are beyond the scope of this paper.
(Ramsay, 2001; Ramsay and Field, 2008). For the purposes of the current paper we
will simply show the results that can be obtained by using it.
The work reported here is complementary to work on corpus-based approaches
such as textual entailment: approaches that ignore the intensionality of everyday lan-
guage will inevitably fail to capture important inference patterns, but on the other hand
the work reported here cannot deal with large amounts of information provided as free
text. Ideally, the two approaches will be combined. The aim of the current paper is
to provide a reminder of the prevalence of intensionality in everyday language, and
to demonstrate that modern theorem proving techniques can cope with this kind of
knowledge without introducing undue processing delays.
2 Background
The general idea behind the work reported here is that users will input statements
about their health, either spontaneously or in response to prompts from the system,
and will ask questions about what they can and should do, and the system will provide
them with appropriate guidance. The overall architecture is completely classical:
1. The user?s input is translated into a meaning representation (logical form, LF)
in some suitable representation language.
2. This LF contains a specification of the illocutionary force of the input (is it a
statement, or a question, or a command, or . . . ?).
3. If the utterance is classified as a statement, its propositional content is added to
the system?s view of the user?s beliefs, and if it is classified as a question, the
system will attempt to use its background knowledge of the domain to answer
it. We are not currently attempting to make the system do anything in response
to a command from the user, since users do not generally issue commands in
our chosen domain, but clearly if this did happen then we would want to make
the system construct a plan to carry out the required action.
Everyday Language is Highly Intensional 195
This part of the system?s activity requires it be able to access and exploit relevant
background knowledge. This is obvious in the case of questions, but in the given
domain it is also important to be able to spot situations where the user?s beliefs
are incomplete or are in conflict with the system?s beliefs, since most people?s
understanding about medical topics is flawed. The ability to reason about what
has been said, then, is crucial to the construction of appropriate responses.
This architecture is entirely orthodox. What is unusual about the current work is
the emphasis on intensionality, so the first thing to do is examine why we believe that
this is such a significant problem.
1. Doctors and patients make extensive use of generic NPs and bare plurals: ?If
you follow this diet you should manage to control them without drugs?, ?Do you
normally have snacks??, ?When I started chemotherapy, on the 2nd of August,
glycaemia was still rather high? . . .
Such NPs are not, in fact, all that much more prevalent in this domain than in
general language. Across the BNC, for instance, it turns out that 27% of NPs
have ?the? as their determiner, 19% are bare plurals, 29% are bare singulars,
11% have ?a? or ?an? as their determiner, and the remainder have a variety of
other determiners1.
Thus bare plural and generic singular NPs occur about as frequently as ?the? and
?a?, and substantially more freqently than ?some?, ?all? and ?every? (less than
1% each). They have, however, been much less widely discussed by formal
semanticists, and there are a number of serious problems with the analyses that
have been proposed (Carlson, 1989; Ramsay, 1992; Cohen, 1994).
2. Everyday language is littered with words that can be used either as nouns or
verbs, and many of the apparently verbal uses of such words occur in essentially
nominal contexts. Table 1 shows the pattern of usage for three common words2,
but it should be noted that about 25% of the instances that are classified as
verbs are present participle forms, many of which are actually nominal or verbal
gerunds and hence should be regarded as nouns.
Table 1: Uses of common words in the BNC
Verb Noun Other
walk 75% 22% 3%
run 70% 24% 6%
kick 63% 35% 2%
Axiomatisation of the semantics of such words requires considerable care, since
we need to ensure that all the examples in (2) have very similar consequences.
(2) a. Swimming is good for you.
1The count of bare singulars is in fact a slight overestimate, since it includes some uses of singular nouns
as modifiers.
2The classification is taken directly from the BNC tags.
196 Ramsay and Field
b. Going for a swim is good for you.
c. It is good for you to go swimming.
3. The goal of the project is to produce appropriate responses to simple statements
and queries about a patient?s health. To do this, we need to be able to specify
a body of background knowledge in this area. We believe that for applications
such as medical information provision it is important that the information pro-
vided be as accurate as possible, and hence that it may be necessary to provide
the required background knowledge from scratch. This is, of course, a very
time-consuming and challenging activity, and it would be nice to be able to
side-step it by extracting the required information from existing texts. Unfortu-
nately, it seems likely that any such existing text will contain gaps which will
lead to the generation of partial, or wrong, answers. As noted above, ideally we
would want to link special purpose knowledge of the kind outlined here with
information extracted from existing texts, but for the current paper we are just
looking at what is involved in providing the required knowledge from scratch.
It turns out, as will be seen below, that much of this knowledge involves quantifica-
tion over situation types (of roughly the kind discussed by (Barwise and Perry, 1983)),
and in particular it involves statements about whether one situation type is a subset of
another, or is incompatible with it. This kind of knowledge is intrinsically intensional,
but it is hard to see how it can be avoided in this domain.
3 Logical forms
The logical forms that we use are fairly orthodox.
? We assume that events are first-class objects, as suggested by Davidson David-
son (1967, 1980).
? We allow other entities to play named roles with respect to these events, where
we denote that some item X is, for instance, the agent of some event E by writing
?(E,agent,X): using this notation, rather than writing agent(E,X), allows us
to quantify over thematic roles, which in turn allows us to state generalisations
that would otherwise be awkward.
? We treat tense as a relation between speech time and ?reference time?, and aspect
as a relation between reference time and event time, as suggested by Reichen-
bach Reichenbach (1947, 1956).
? We use ?reference terms? to denote referring expressions, so that re f (?Xman(X))
is used to denote ?the man?. Reference terms are similar to ?anchors? from (Bar-
wise and Perry, 1983), though the treatment is essentially proof-theoretic (sim-
ilar to the discussion of presupposition in (Gazdar, 1979; van der Sandt, 1992))
rather than model theoretic.
? Given that we are particularly concerned with the intensional nature of natural
language, we need to use a formal language that supports intensionaly. The
Everyday Language is Highly Intensional 197
language we choose is a constructive version of property theory (Turner, 1987;
Ramsay, 2001). We have extended the theorem prover described in (Ramsay,
2001) to cope with reasoning about knowledge and belief, and we have shown
how this can be used to carry out interesting inferences in cooperative and non-
cooperative situations (Ramsay and Field, 2008).
We also include the surface illocutionary force in the LF, since this is part of the
meaning of the utterance and hence it seems sensible to include it in the LF. In partic-
ular, there are interactions between surface illocutionary force and other aspects of the
meaning which are hard to capture if you treat them independently. This is slightly
less standard than the other aspects of our LFs, but it does have the advantage that
these LFs keep all the information that we can obtain by inspecting the form of the
utterance in one place.
A typical example of an LF for a simple sentence is given in Figure 13.
(3) The man loves a woman.
claim(?B : {woman(B)}
?C : {past(now,C)}
?D : {aspect(C,simplePast,D)}
?(D, agent, ref (?E(man(E))))
&?(D,object,B)
&event(D, love))
Figure 1: Logical form for (3)
If you want to reason about utterances in natural language, e.g. in order to answer
questions on the basis of things you have been told, then there seems to be no alterna-
tive to constructing LFs of the kind in Figure 1, axiomatising the relevant background
knowledge, and then invoking your favourite theorem prover. Shallow semantic anal-
ysis simply does not provide the necessary detail, and it is very hard to link textual
entailment algorithms (Dagan et al, 2005) to complex domain knowledge. The crit-
ical issue in connecting NLP systems to rich axiomatisations of domain knowledge
seems likely to be that existing frameworks for constructing meaning representations
are not rich enough, not that they are too rich. In the remainder of this paper we will
explore three specific issues that have arisen in our attempt to use natural language
as a means for accessing medical knowledge. We have beoome sensitised to these
issues because of their importance for our application, but we believe that they are ac-
tually widespread, and they will need to be solved for any system which links natural
language to complex domain knowledge.
4 Bare NPs
Consider (4):
3All the formal paraphrases in this paper are obtained from the target sentences by parsing the text and
using the standard techniques of compositional semantics.
198 Ramsay and Field
(4) a. I am eating eggs.
b. I eat eggs.
c. I am allergic to eggs.
What is the status of ?eggs? in these sentences?
It is clear that in (4a) there are some eggs that I am eating, so that (4a) means some-
thing quite like ?I am eating some eggs.?. (4b), on the other hand, means something
fairly different from ?There are some eggs that I eat?, since it does not seem to commit
the speaker to the existence of any specific set of eggs. The use of the simple aspect
with a non-stative verb gives (4b) a habitual/repeated interpretation, saying that there
are numerous eating events, each of which involves at least one egg.
It seems, then, that it is possible to treat ?eggs? in (4a) and (4b) as a narrow scope
existential, with the simple aspect introducing a set of eating events of the required
kind.
You would not, however, want to paraphrase (4c) by saying that there are some eggs
to which I am allergic. (4b) says that there is a relationship between me and situations
where there is an egg present, namely that if I eat something which has been made
out of some part of an egg then I am likely to have an allergic reaction. The bare
plural ?eggs? in (4c) seems to have some of the force of a universal quantifier. This is
problematic: does the bare plural ?eggs? induce an existential or a universal reading,
or something entirely different?
Note that the word ?eggs? can appear as a free-standingNP (as in (4a)) or as the head
noun of an NP with an explicit determiner (as in ?He was cooking some eggs.?). In the
latter context, the meaning of ?eggs? is normally taken be the property ?X(egg(X)),
to be combined with the determiner ?some? to produce an existentially quantified ex-
pression which can be used as part of the interpretation of the entire sentence.
It is clear that there are constructions that involve allowing prepositions to take
nouns rather than NPs as their complements, in examples like ?For example, cockerels
generally have more decorative plumage than hens?, where ?example? is evidently a
noun rather than an NP. If we allow the adjective ?allergic? to select for a PP with a
noun complement rather than an NP complement, we can obtain an interpretation of
(4c) which says that my allergy is a relation between me and the property of being an
egg (= the set of eggs) (Figure 2).
utt(claim,
?Bstate(B,allergic(to,
?C(egg(C))),
ref (?D(speaker(D)))!0)
&aspect(now,simple,B))
Figure 2: Logical form for (4c)
Thus we can distinguish between cases where ?eggs? is being used as an NP, where
it introduces a narrow scope existential quantifier, and ones where it is being used as
an NN, where it denotes, as usual, the property ?(X ,egg(X)). We still have to work
Everyday Language is Highly Intensional 199
out saying that the relationship ?allergic? holds between me and the property of being
an egg, but at least we have escaped the trap of saying that it holds between me and
some eggs (or indeed all eggs). We will return ton this in ?6
5 Nominalisations and paraphrases
As noted above, there are often numerous ways of saying very much the same thing,
and these often involve using combinations of nominal and verbal forms of the same
root. To cope with these, we have to do two things: we have to construct appropriate
logical forms, and we have to spot cases where we believe that there is no significant
difference between the various natural language forms and introduce appropriate rules
for treating one as canonical.
Gerunds and gerundives occur in very much the same places as bare NPs, and have
very much the same feeling of being about types of entity.
(5) a. Exercise is good for you.
b. Swimming is good for you.
(6) a. I like watching old movies.
b. I like old movies.
It therefore seems natural to treat them in much the same way, as descriptions of
event types, as in Figure 3
utt(claim,
?Bstate(B,
?C(?Devent(D,swim) & ?(D,agent,C)),
?E(good(E)))
&for(B,ref (?F(hearer(F)))!4)
&aspect(now,simple,B))
Figure 3: Logical form for (5b)
The logical form in Figure 3 says that there is a state of affairs relating events where
someone does some swimming and the property of being good, and that this state of
affairs concerns the speaker. This does at least have the benefit of exposing the key
concepts mentioned in (5b), and of doing so in such a way that it is possible to write
rules that support appropriate chains of inference.
The kind of inferencewe are interested in concerns patterns like the ones in Figure 4
Exercise is good for you if you are overweight
Swimming is a form of exercise
I am obese
Should I go swimming?
Figure 4: A simple(!) pattern of natural reasoning
200 Ramsay and Field
We will discuss the rules and inference engine that are required in order to support
this kind of reasoning in ?6 and ?7. For now we are concerned with the fact that the
last line in Figure 4 could have been replaced by a number of alternative forms such
as ?Is swimming good for me?? or ?Is it good for me to go swimming? without any
substantial change of meaning.
In general, we believe that determining the relationships between sentences re-
quires inference based on background rules which describe the relationships between
terms. However, when we have forms which are essentially paraphrases of one an-
other, these rules will tend to be bi-equivalences?rules of the form P ? Q. Such rules
are awkward for any theorem prover, since they potentially introduce infinite loops:
in order to prove P you can try proving Q, where one of the possible ways of proving
Q is by proving P, . . . It is possible to catch such loops, and our inference engine does
monitor for various straightforward loops of this kind, but they do introduce an extra
overhead. Equivalences of this kind are, in any case, not really facts about the world so
much as facts about the way natural language describes the world. It seems therefore
more sensible to capture them at the point when we construct our logical forms, when
they can be dealt with by straightforward pattern matching and substitution on logical
forms, rather than by embodying them as bi-directional rules to be used as required by
the inference engine. We use rules of the kind given in Figure 5 to canonical versions
of logical forms for sentences which we regard as mutual paraphrases. These rules
are matched against elements of the logical form, and the required substitutions are
made. This process is applied iteratively, so that multiple rules can be applied when
necessary.
?B : {allergy(B,C)}
?Devent(D,have) & ?(D,object,B)
& ?(D,agent,E) & aspect(X,Y ,D)
? ?Fstate(F,E,?G(allergic(G)),to(C))
& aspect(X,Y ,F)
event(B,go)
&?(B,event,?C(event(C,D)))
&?(B,agent,E)
? event(B,D) &?(B,agent,E)
Figure 5: Canonical form rules
The first of the rules in Figure 5 captures the equivalences between ?I have an al-
lergy to eggs? and ?I am allergic to eggs?, ?having an allergy to milk is bad news? and
?being allergic to milk is bad news?, and so on, and the second captures the equiv-
alences between ?I like walking? and ?I like going walking?, ?Swimming is good for
you? and ?Going for a swim is good for you?, and so on. These equivalences have to
be captured somewhere, and we believe that canonical forms of this kind arte a good
way to do it. We will return to where the rules in Figure 5 come from in ?8.
Everyday Language is Highly Intensional 201
6 Intensional predicates
The material we are interested in, like all natural language, makes extensive use of
intensional predicates. The adjective ?good? in ?Going swimming is good for you? ex-
presses a relationship between an event type (?going swimming?) and an individual;
the verb ?make? in ?Eating raw meat will make you feel sick? expresses a relation-
ship between an event type (?eating raw meat?) and a state of affairs (?you are ill?).
Constructions like these are widespread, and are inherently intensional. To draw con-
clusions about sentences involving them, you have to be able to reason about whether
one event type or one parameterised state of affairs is a subset of another, which is the
essence of intensionality.
Once you recognise that examples like these involve event types and propositions,
it is fairly straightforward to construct appropriate logical forms. We simply use the
notation of the ?-calculus to depict abstractions (e.g. event types), and we allow propo-
sitions to appear in argument positions, and standard techniques from comppsitional
semantics do the rest.
?C : {future(now,C)}
?Bevent(B,make)
&?(B,
scomp,
?D(event(D,feel)
& ?(D,object,?E(sick(E)))
& ?(D,agent,ref (?F(hearer(F)))!5)))
&?(B,
cause,
?G ?Hevent(H,eat)
&?I : {raw(I) & meat(I)}?(H,object,I)
&?(H,agent,G))
&aspect(C,simple,B)
Figure 6: Eating raw meat will make you feel sick
Figure 6 describes a relationship between situations where you eat raw meat and
ones where you feel sick. This is entirely correct: what else could this sentence de-
note?
Constructing formal paraphrases for sentences involving intensional predicates is
thus both straightforward (so long as you can parse them) and essential. Formal lan-
guages that support such paraphrases are, however, potentially problematic. The key
problem is that such languages tend to permit paradoxical constructions such as the
Liar Paradox and Ruessll?s set which introduce sentences which are true if and only if
they are false. It is difficult to provide semantics for languages which allow paradoxes
to be stated, but there are a number of ways out of this dilemma, either by putting
syntactic restrictions on what can be said (Whitehead and Russell, 1925; Jech, 1971)
or by devising appropriate interpretations (Turner, 1987; Aczel, 1988). We choose to
employ a constructive variant of property theory, because it allows us a comparatively
straightforward and implemetable proof theory, but it does not really matter what you
choose. What does matter is that if you choose a language with less expressive power
202 Ramsay and Field
than natural language, such as description logic, your paraphrases must fail to support
some of the distinctions that are expressible in natural language, and as a consequence
you will inevitably draw incorrect conclusions from the texts you are processing.
7 Inference
Consider (7):
(7) a. Eating eggs will make you ill if you are allergic to eggs.
b. I am allergic to eggs.
c. Will eating fried-egg sandwiches make me ill?
It is pretty obvious that the answer to (7c), given (7a) and (7b), must be ?Yes?. The
reasoning that is required to arrive at this answer turns out to be suprisingly complex.
The problem is, as noted above, that we need to reason about relationships between
event types. We need to be able to spot that events where someone eats a fried-egg
sandwich involve situations where they eat an egg. It is clearly quite easy, if tedious,
to write rules that say that if someone eats something which contains an egg then they
must eat an egg, and that fried-egg sandwiches contain eggs. The trouble is that we
have to be able invoke this rule in order to determine whether the arguments of ?make?
are of the right kind. Because we are (correctly) allowing event types as arguments
in intensional predicates, we have to be able to invoke arbitrary and unpredictable
amounts of inference even to determine whether the arguments of a predicate are ad-
missible. Roughly speaking, we have to be prepared to carry out arbitrary amounts of
inference at the point where first-order theorem provers invoke unification.
There is nothing to stop us doing this. Sorted logics, for instance, use an extended
notion of unification to try to ensure that items that are being considered as arguments
have specific properties (Cohn, 1987). We can, indeed, do any computation we like in
order to verify the suitability of arguments. The more complex the computations we
perform, of course, the longer it may take to come to a decision. The key is thus to
try to bound the potential costs without compromising what we can do too much. We
exploit a notion of ?guarded? axioms, where we allow arbitrary amounts of reasoning
to be performed to verify that some item fits a fully specified description, but we do
not allow such reasoning to be used for generating candidates. We do, of course, have
to put a bound on the amount of work that will be done at any point, as indeed any
inference engine for a language as expressive as first-order logic must do. In general,
however, using guarded intensionality in this way allows us to cover a wide range
of cases which are simply inexpressible using first-order logic (or any fragment of
first-order logic, such as description logic) comparatively inexpensively.
8 Conclusions
We have argued that in order to cope properly with even quite straightforward uses
of language, you need large amounts of background knowledge, much of which has
to be couched in some highly intensional framework, and you need inference engines
which can manipulate this knowledge. In the body of the paper we have shown a
number of examples which we believe illustrate this argument, and have looked at the
representations and rules that we employ for dealing with these cases. The natural
Everyday Language is Highly Intensional 203
question that arises at this point is: that?s all very well, but can the approach outlined
here be extended to cover a more substantial set of cases?
There are two key issues here. How difficult is it to capture a reasonably substantial
body of knowledge within the framework we have outlined, and what will happen to
the inference engine when we do?
Writing rules in property theory is very hard work. Writing rules in property theory
which will mesh nicely with logical forms obtained from natural language sentences
is extremely hard work. If we had to hand-code the rules we want directly in property
theory (or indeed in any formal language) then the approach discussed here would,
clearly, be impossible to extend to cover more than a handful of cases. Fortunately,
however, we have a much easier way of constructing rules. We have, after all, a
mechanism for converting natural language sentences into logical forms. So if we
state the rules we want in natural language we will obtain logical forms of those rules,
and furthermore those paraphrases will automatically be couched in terms which mesh
nicely with logical forms obtained from other natural language sentences. Thus (8)
produces the rule in Figure 7
(8) Eating Y will make X ill if X is allergic to Y.
?C?D?Estate(E,C,?F(allergic(F))) & to(E,D)
& aspect(now,simple,E)
? ?G : {future(now,G)}
?Bevent(B,make)
&?(B,object,C)
&?(B,object1,?H(ill(H)))
&?(B,
agent,
?I ?Jevent(J,eat)
& ?(J,object,D)
& ?(J,agent,I))
&aspect(G,simple,B)
Figure 7: Logical form for (8)
Writing rules like (8) is clearly easier than producing formulae like Figure 7 by
hand. Writing down all the knowledge you need in order to cope with a non-trivial
domain is still a very substantial task, but doing it in English is at least feasible in a
way that doing it directly in a formal language is not.
How will the inference engine cope when confronted with thousands of rules? Very
large parts of everyday knowledge can, in fact, be expressed pretty much as Horn
clauses. Our inference engine converts Horn clauses into (almost) pure Prolog, and
there is certainly no problem in using very large sets of Horn clauses converted to
this form (a modern Prolog system will cope comfortably with sets of several hun-
dred thousand Horn clauses, and will carry out substantial inference chains involving
such sets in small fractions of a second). The only concern here relates to non-Horn
clauses (which do not tend to occur all that frequently in rules explaining the rela-
tionships between natural language terms) and intensional rules. The fact that most
204 Ramsay and Field
intensional rules are guarded has certainly meant that so far we have not encountered
any problems when using them, and we are hopeful that this will remain the case.
In any case, there is an alternative question to be answered: what will happen if
you don?t take the approach outlined here? All the phenomena we have discussed are
widespread?bare plurals, mutual paraphrases, intensional attitudes all occur all over
the place. It is extremely hard to see that systems that rely on surface patterns (either
directly, as in textual entailment, or indirectly through shallow parsing/information
extraction) can support the kind of reasoning required for getting from ?I have an
allergy to eggs.? to ?It is dangerous for me to eat pancakes?, so at some point inference
based on background knowledgewill have to be invoked. There seems little alternative
to constructing formal paraphrases that capture the subtleties of natural language in all
its glory. If you don?t, then you will by definition lose some of the information that
was expressed in the text, and that will inevitably mean that you get things wrong.
There is no way round it: either you bite the bullet, construct formal paraphrases that
capture the content of the input and use them to carry out inference, or you will get
some things wrong.
References
Aczel, P. (1988). Non-Well-Founded-Sets. Stanford: CSLI Publications.
Barwise, J. and J. Perry (1983). Situations and Attitudes. Cambridge, MA: Bradford
Books.
Carlson, G. (1989). On the semantic composition of English generic sentences. In
G. Chierchia, B. H. Partee, and R. Turner (Eds.), Properties, Types and Meaning
II: Semantic Issues, Dordrecht, pp. 167?192. Kluwer Academic Press.
Cohen, A. (1994). Reasoning with generics. In H. C. Bunt (Ed.), 1st International
Workshop on Computational Semantics, University of Tilburg, pp. 263?270.
Cohn, A. G. (1987). A more expressive formulation of many sorted logic. Journal of
Automated Reasoning 3, 113?200.
Dagan, I., B. Magnini, and O. Glickman (2005). The PASCAL recognising textual en-
tailment challenge. In Proceedings of Pascal Challenge Workshop on Recognizing
Textual Entailment.
Davidson, D. (1967). The logical form of action sentences. In N. Rescher (Ed.), The
Logic of Decision and Action, Pittsburgh. University of Pittsburgh Press.
Davidson, D. (1980). Essays on actions and events. Oxford: Clarendon Press.
Gazdar, G. (1979). Pragmatics: Implicature, Presupposition and Logical Form. New
York: Academic Press.
Jech, T. J. (1971). Lectures in Set Theory, with Particular Emphasis on the Method of
Forcing. Berlin: Springer Verlag (Lecture Notes in Mathematics 217).
Everyday Language is Highly Intensional 205
Ramsay, A. M. (1992). Bare plural NPs and habitual VPs. In Proceedings of the 14th
International Conference on Computational Linguistics (COLING-92), Nantes, pp.
226?231.
Ramsay, A. M. (2001). Theorem proving for untyped constructive ?-calculus: imple-
mentation and application. Logic Journal of the Interest Group in Pure and Applied
Logics 9(1), 89?106.
Ramsay, A. M. and D. G. Field (2008). Speech acts, epistemic planning and Grice?s
maxims. Journal of Logic and Computation 18(3), 431?457.
Reichenbach, H. (1947). Elements of Symbolic Logic. New York: The Free Press.
Reichenbach, H. (1956). The Direction of Time. Berkeley: University of California
Press.
Turner, R. (1987). A theory of properties. Journal of Symbolic Logic 52(2), 455?472.
van der Sandt, R. (1992). Presupposition projection as anaphora resolution. Journal
of Semantics 9, 333?377.
Whitehead, A. N. and B. Russell (1925). Principia Mathematica. Cambridge: Cam-
bridge University Press.
Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 73?77,
October 25, 2014, Doha, Qatar. c?2014 Association for Computational Linguistics
Combining strategies for tagging and parsing Arabic
Maytham Alabbas
Department of Computer Science
University of Basrah
Basrah, Iraq
maytham.alabbas@gmail.com
Allan Ramsay
School of Computer Science
University of Manchester
Manchester M13 9PL, UK
Allan.Ramsay@manchester.ac.uk
We describe a simple method for com-
bining taggers which produces substan-
tially better performance than any of the
contributing tools. The method is very
simple, but it leads to considerable im-
provements in performance: given three
taggers for Arabic whose individual ac-
curacies range from 0.956 to 0.967, the
combined tagger scores 0.995?a seven-
fold reduction in the error rate when
compared to the best of the contributing
tools.
Given the effectiveness of this approach
to combining taggers, we have investi-
gated its applicability to parsing. For
parsing, it seems better to take pairs of
similar parsers and back off to a third if
they disagree.
1 Introduction
If you have several systems that perform the same
task, it seems reasonable to suppose that you can
obtain better performance by using some judicious
combination of them than can be obtained by any
of them in isolation. A large number of combin-
ing strategies have been proposed, with majority
voting being particularly popular (Stefano et al.,
2002). We have investigated a range of such strate-
gies for combining taggers and parsers for Ara-
bic: the best strategy we have found for tagging
involves asking each of the contributing taggers
how confident it is, and accepting the answer given
by the most confident one. We hypothesise that
the reason for the effectiveness of this strategy for
tagging arises from the fact that the contributing
taggers work in essentially different ways (differ-
ent training data, different underlying algorithms),
and hence if they make systematic mistakes these
will tend to be different. This means, in turn, that
the places where they don?t make mistakes will be
different.
This strategy is less effective for parsing. We
have tried combining two members of the MALT-
Parser family (Nivre et al., 2006; Nivre et al.,
2007; Nivre et al., 2010) with MSTParser (Mc-
Donald et al., 2006a; McDonald et al., 2006b).
The best strategy here seems to be to accept the
output of the two versions of MALTParser when
they agree, but to switch to MSTParser if the
MALTParser versions disagree. It may be that this
is because the MALTParser versions are very sim-
ilar, so that when they disagree this suggests that
there is something anomalous about the input text,
and that neither of them can be trusted at this point.
2 Tagging
We present a very simple strategy for combin-
ing part-of-speech (POS) taggers which leads to
substantial improvements in accuracy. A num-
ber of combination strategies have been proposed
in the literature (Zeman and ?Zabokrtsky`, 2005).
In experiments with combining three Arabic tag-
gers (AMIRA (Diab, 2009), MADA (Habash et
al., 2009) and a simple affix-based maximum-
likelihood Arabic tagger (MXL) (Ramsay and
Sabtan, 2009)) the current strategy significantly
outperformed voting-based strategies.
We used the Penn Arabic Treebank (PATB) Part
1 v3.0 as a resource for our experiments. The
words in the PATB are already tagged, which thus
provides us with a widely-accepted Gold standard.
Even PATB tagging is not guaranteed to be 100%
accurate, but it nonetheless provides as good a ref-
erence set as can be found.1
The PATB uses the tags provided by the Buck-
walter morphological analyser (Buckwalter, 2004;
Buckwalter, 2007), which carry a great deal
1The PATB is the largest easily available tagged Arabic
corpus, with about 165K words in the section we are us-
ing. Thus for each fold of our 10-fold testing regime we are
training on 150K words and testing on 15K, which should be
enough to provide robust results.
73
of syntactically relevant information (particularly
case-marking). This tagset contains 305 tags, with
for instance 47 tags for different kinds of verb
and 44 for different kinds of noun. The very fine
distinctions between different kinds of nouns and
verbs (e.g. between subject and object case nouns)
in the absence of visible markers make this an ex-
tremely difficult tagset to work with. It is in gen-
eral virtually impossible to decide the case of an
Arabic noun until its overall syntactic role is de-
termined, and it is similarly difficult to decide the
form of a verb until the overall syntactic structure
of the sentence is determined. For this reason tag-
gers often work with a coarser set of tags, of which
the ?Bies tagset? (Maamouri and Bies, 2004) is
widely used (see for instance the Stanford Arabic
parser (Green and Manning, 2010)). We carried
out our experiments with a variant of the origi-
nal fine-grained tagset, and also with a variant of
the coarser-grained Bies set obtained by deleting
details such as case- and agreement-markers. We
carried out two sets of experiments, with a coarse-
grained set of tags (a superset of the Bies tagset
with 39 tags, shown in Figure 1) and the original
fine-grained one with 305 tags.
ABBREV
ADJ
ADV
CONJ
CV
CVSUFF DO
DEM PRON
DET
DET+ADJ
DET+NOUN
DET+NOUN PROP
DET+NUM
EMPH PART
EXCEPT PART
FOCUS PART
FUT+IV
INTERJ
INTERROG PART
IV
IVSUFF DO
LATIN
NEG PART
NOUN
NOUN PROP
NO FUNC
NUM
PART
POSS PRON
PREP
PRON
PUNC
PV
PVSUFF DO
RC PART
REL ADV
REL PRON
SUB
SUB CONJ
VERB PART
Table 1: Coarse-grained tagset
The accuracy of a tagger clearly depends on
the granularity of the tagset: the contributing tag-
gers produced scores from 0.955 to 0.967 on the
coarse-grained tagset, and from 0.888 to 0.936 on
the fine-grained one. We applied transformation-
based retagging (TBR) (Brill, 1995; Lager, 1999)
to the output of the basic taggers, which produced
a small improvement in the results for MADA
and MXL and a more substantial improvement
for AMIRA. Table 2 shows the performance of
the three taggers using the two tagsets with and
without TBR. The improvement obtained by using
POS TBR AMIRA MXL MADA
Coarse ? 0.896 0.952 0.941? 0.953 0.956 0.967
Fine ? 0.843 0.897 0.917? 0.888 0.912 0.936
Table 2: Tagger accuracies in isolation, with and
without TBR
TBR for AMIRA arises largely from the fact that
in some cases AMIRA uses tags similar to those
used in the English Penn Treebank rather than the
ones in the the tags in the PATB, e.g. JJ for
adjectives where the PATB uses ADJ. TBR pro-
vides a simple and reliable mechanism for discov-
ering and patching systematic renamings of this
kind, and hence is extremely useful when working
with different tagsets. A significant component of
the remaining errors produced by AMIRA arise
because AMIRA has a much coarser classifica-
tion of particles than the classification provided by
the Buckwalter tagset. Since AMIRA assigns the
same tag to a variety of different particles, TBR
cannot easily recover the correct fine-grained tags,
and hence AMIRA makes a substantial number of
errors on these items.
The key to the proposed combining strategy is
that each of the contributing taggers is likely to
make systematic mistakes; and that if they are
based on different principles they are likely to
make different systematic mistakes. If we clas-
sify the mistakes that a tagger makes, we should be
able to avoid believing it in cases where it is likely
to be wrong. So long as the taggers are based
on sufficiently different principles, they should be
wrong in different places.
We therefore collected confusion matrices for
each of the individual taggers showing how likely
they were to be right for each category of item?
how likely, for instance, was MADA to be right
when it proposed to tag some item as a noun (very
likely?accuracy of MADA when it proposes NN
is 0.98), how likely was AMIRA to be right when
it proposed the tag RP (very unlikely?accuracy of
0.08 in this case)? Given these tables, we simply
took the tagger whose prediction was most likely
to be right.2
Table 3 shows an excerpt from the output of the
2All the tagging results reported below were obtained by
using 10-fold cross validation, i.e. carrying out 10 experi-
ments each of which involved removing 10% of the data for
testing and training on the remaining 90%.
74
Word Gold standard MADA MXL AMIRA TAG
. . . . . . . . . . . . . . . . . .
gyr NEG PART NOUN (0.979) NEG PART (0.982) RP (0.081) NEG PART
<lA EXCEPT PART EXCEPT PART (1.00) SUB CONJ (0.965) RP (0.790) EXCEPT PART
. . . . . . . . . . . . . . . . . .
Table 3: Confidence levels for individual tags
three individual taggers looking at a string con-
taining the two words gyr and <lA, with the tags
annotated with the accuracy of each tagger on the
given tag, e.g. in this sequence MADA has tagged
gyr as a noun, and MXL has tagged it as a neg-
ative particle and AMIRA has tagged it as RP;
and when MADA suggests NOUN as the tag it is
right 97.9% of the time, whereas when MXL sug-
gests NEG PART it is right 98.2% of the time and
AMIRA is right just 8.1% of the time when it sug-
gests RP. It is important to note that the tags are
assigned to words in context, but the confidence
levels are calculated across the entire training data.
The fact that MADA is right 97.9% of the time
when it assigns the tag NOUN is not restricted to
the word gyr, and certainly not to this occurrence
of this word.
We compared the results of this simple strategy,
which is similar to a strategy proposed for image
classification by Woods at el. (1997), with a strat-
egy proposed by (2005), in which you accept the
majority view if at least two of the taggers agree,
and you back off to one of them if they all dis-
agree, and with a variation on that where you ac-
cept the majority view if two agree and back off to
the most confident if they all disagree. The results
are given in Table 4.
All four strategies produce an improvement
over the individual taggers. The fact that ma-
jority voting works better when backing off to
MXL than to MADA, despite the fact that MADA
works better in isolation, is thought-provoking. It
seems likely to be that this arises from the fact that
MADA and AMIRA are based on similar princi-
ples, and hence are likely to agree even when they
are wrong. This hypothesis suggested that looking
at the likely accuracy of each tagger on each case
might be a good backoff strategy. It turns out that
it is not just a good backoff strategy, as shown in
the third column of Table 4: it is even better when
used as the main strategy (column 5). The differ-
ences between columns 4 and 5 are not huge,3 but
that should not be too surprising, since these two
strategies will agree in every case where all three
of the contributing taggers agree, so the only place
where these two will disagree is when one of the
taggers disagrees with the others and the isolated
tagger is more confident than either of the others.
The idea reported here is very simple, but it is
also very effective. We have reduced the error in
tagging with fairly coarse-grained tags to 0.05%,
and we have also produced a substantial improve-
ment for the fine grained tags, from 0.936 for the
best of the individual taggers to 0.96 for the com-
bination.
3 Parsing
Given the success of the approach outlined above
for tagging, it seemed worth investigating whether
the same idea could be applied to parsing. We
therefore tried using it with a combination of de-
pendency parsers, for which we used MSTParser
(McDonald et al., 2006a; McDonald et al., 2006b)
and two variants from the MALTParser family
(Nivre et al., 2006; Nivre et al., 2007; Nivre et
al., 2010), namely Nivre arc-eager, which we will
refer to as MALTParser
1
, and stack-eager, which
we will refer to as MALTParser
2
. The results in
Table 5 include (i) the three parsers in isolation;
(ii) a strategy in which we select a pair and trust
their proposals wherever they agree, and back-off
3In terms of error rate the difference looks more substan-
tial, since the error rate, 0.005, for column 5 for the fine-
grained set is 62.5% of that for column 4, 0.008; and for the
coarse-grained set the error rate for column 5, 0.04, is 73%
of that for column 4, 0.055
Tagset
Majority voting Majority voting Majority voting Majority voting Just most
(back off to MXL) (back off to MADA) (back off to AMIRA) (most confident) confident
Coarse-grained 0.982 0.979 0.975 0.992 0.995
Fine-grained 0.918 0.915 0.906 0.945 0.96
Table 4: Modified majority voting vs proposed strategy
75
Parser LA
(i)
MSTParser 0.816
MALTParser
1
0.797
MALTParser
2
0.796
(ii)
Use MSTParser & MALTParser
1
if they agree, backoff to MALTParser
2
0.838
Use MSTParser & MALTParser
2
if they agree, backoff to MALTParser
2
0.837
Use MALTParser
1
& MALTParser
2
if they agree, backoff to MSTParser 0.848
(iii)
Use MSTParse & MALTParser
1
if they agree, backoff to most confident 0.801
Use MSTParser & MALTParser
2
if they agree, backoff to most confident 0.799
Use MALTParser
1
& MALTParser
2
if they agree, backoff to most confident 0.814
(iv)
If at least two agree use their proposal, backoff to most confident 0.819
If all three agree use their proposal, backoff to most confident 0.797
Most confident parser only 0.789
Table 5: Labelled accuracy (LA) for various combinations of MSTParser, MALTParser
1
and
MALTParser
2
five fold cross-validation with 4000 training sentences and 1000 testing
to the other one when they do not; (iii) a strategy
in which we select a pair and trust them whenever
they agree and backoff to the parser which is most
confident (which may be one of these or may be
the other one) when they do not; (iv) strategies
where we either just use the most confident one,
or where we take either a unanimous vote or a ma-
jority vote and backoff to the most confident one
if this is inconclusive. All these experiments were
carried using fivefold cross-validation over a set of
5000 sentences from the PATB (i.e. each fold has
4000 sentences for training and 1000 for testing).
These results indicate that for parsing, simply
relying on the parser which is most likely to be
right when choosing the head for a specific depen-
dent in isolation does not produce the best over-
all result, and indeed does not even surpass the
individual parsers in isolation. For these exper-
iments, the best results were obtained by asking
a predefined pair of parsers whether they agree
on the head for a given item, and backing off to
the other one when they do not. This fits with
Henderson and Brill (2000)?s observations about
a similar strategy for dependency parsing for En-
glish. It seems likely that the problem with rely-
ing on the most confident parser for each individ-
ual daughter-head relation is that this will tend to
ignore the big picture, so that a collection of rela-
tions that are individually plausible, but which do
not add up to a coherent overall analysis, will be
picked.
4 Conclusions
It seems that the success of the proposed method
for tagging depends crucially on having taggers
that exploit different principles, since under those
circumstances the systematic errors that the dif-
ferent taggers make will be different; and on the
fact that POS tags can be assigned largely inde-
pendently (though of course each of the individual
taggers makes use of information about the local
context, and in particular about the tags that have
been assigned to neighbouring items). The rea-
son why simply taking the most likely proposals
in isolation is ineffective when parsing may be that
global constraints such as Henderson and Brill?s
?no crossing brackets? requirement are likely to
be violated. Interestingly, the most effective of
our strategies for combining parsers takes two that
use the same learning algorithm and same feature
sets but different parsing strategies (MALTParser
1
and MALTParser
2
), and relies on them when they
agree; and backs off to MSTParser, which ex-
ploits fundamentally different machinery, when
these two disagree. In other words, it makes use
of two parsers that depend on very similar under-
lying principles, and hence are likely to make the
same systematic errors, and backs off to one that
exploits different principles when they disagree.
We have not carried out a parallel set of exper-
iments on taggers for languages other than Arabic
because we do not have access to taggers where
we have reason to believe that the underlying prin-
ciples are different for anything other than Ara-
bic. In situations where three (or more) distinct
approaches to a problem of this kind are available,
76
it seems at least worthwhile investigating whether
the proposed method of combination will work.
Acknowledgements
Maytham Alabbas owes his deepest gratitude to
Iraqi Ministry of Higher Education and Scientific
Research for financial support in his PhD study.
Allan Ramsay?s contribution to this work was par-
tially supported by the Qatar National Research
Fund (grant NPRP 09-046-6-001).
References
E Brill. 1995. Transformation-based error-driven
learning and natural language processing: a case
study in part of speech tagging. Computational Lin-
guistics, 23(4):543?565.
T Buckwalter. 2004. Buckwalter Arabic morpholog-
ical analyzer version 2.0. Linguistic Data Consor-
tium.
T Buckwalter. 2007. Issues in Arabic morphological
analysis. ARabic computational morphology, pages
23?41.
M. Diab. 2009. Second Generation Tools (AMIRA
2.0): Fast and Robust Tokenization, POS Tagging,
and Base Phrase Chunking. In Proceedings of the
Second International Conference on Arabic Lan-
guage Resources and Tools, pages 285?288, Cairo,
Eygpt, April. The MEDAR Consortium.
S Green and C D Manning. 2010. Better arabic
parsing: Baselines, evaluations, and analysis. In
Proceedings of the 23rd International Conference
on Computational Linguistics, COLING ?10, pages
394?402, Stroudsburg, PA, USA. Association for
Computational Linguistics.
N. Habash, O. Rambow, and R. Roth. 2009.
MADA+TOKAN: A Toolkit for Arabic Tokeniza-
tion, Diacritization, Morphological Disambiguation,
POS Tagging, Stemming and Lemmatization. In
Proceedings of the Second International Conference
on Arabic Language Resources and Tools, Cairo.
The MEDAR Consortium.
J C Henderson and E Brill. 2000. Exploiting diversity
in natural language processing: Combining parsers.
CoRR, cs.CL/0006003.
T Lager. 1999. ?-tbl lite: a small, extendible
transformation-based learner. In Proceedings of the
9th European Conference on Computational Lin-
guistics (EACL-99), pages 279?280, Bergen. Asso-
ciation for Computational Linguistics.
M Maamouri and A Bies. 2004. Developing an Ara-
bic treebank: methods, guidelines, procedures, and
tools. In Proceedings of the Workshop on Com-
putational Approaches to Arabic Script-based Lan-
guages, pages 2?9, Geneva.
R McDonald, K Lerman, and F Pereira. 2006a. Mul-
tilingual dependency parsing with a two-stage dis-
criminative parser. In Tenth Conference on Com-
putational Natural Language Learning (CoNLL-X),
New York.
R McDonald, K Lerman, and F Pereira. 2006b. Mul-
tilingual dependency parsing with a two-stage dis-
criminative parser. In Tenth Conference on Com-
putational Natural Language Learning (CoNLL-X),
New York.
J. Nivre, J. Hall, and J. Nilsson. 2006. MaltParser:
A data-driven parser-generator for dependency pars-
ing. In Proceedings of the International Conference
on Language Resources and Evaluation (LREC),
volume 6, pages 2216?2219.
J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit,
S. Ku?bler, S. Marinov, and E. Marsi. 2007. Malt-
Parser: A language-independent system for data-
driven dependency parsing. Natural Language En-
gineering, 13(02):95?135.
J Nivre, L Rimell, R McDonald, and C Go?mez-
Rodr??guez. 2010. Evaluation of dependency parsers
on unbounded dependencies. In Proceedings of the
23rd International Conference on Computational
Linguistics, COLING ?10, pages 833?841, Beijing.
A. Ramsay and Y. Sabtan. 2009. Bootstrapping a
lexicon-free tagger for Arabic. In Proceedings of
the 9th Conference on Language Engineering, pages
202?215, Cairo, Egypt, December.
Claudio De Stefano, Antonio Della Cioppa, and An-
gelo Marcelli. 2002. An adaptive weighted major-
ity vote rule for combining multiple classifiers. In
ICPR (2), pages 192?195.
Kevin Woods, W. Philip Kegelmeyer, Jr., and Kevin
Bowyer. 1997. Combination of multiple classifiers
using local accuracy estimates. IEEE Trans. Pattern
Anal. Mach. Intell., 19(4):405?410, April.
D. Zeman and Z. ?Zabokrtsky`. 2005. Improving
parsing accuracy by combining diverse dependency
parsers. In Proceedings of the Ninth International
Workshop on Parsing Technology, pages 171?178.
Association for Computational Linguistics.
77
