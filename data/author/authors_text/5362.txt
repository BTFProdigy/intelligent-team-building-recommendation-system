Partially Saturated Referents 
as a Source of Complexity in Semantic Interpretation 
David D. McDonald 
Department of Computer Science, Brandeis University 
davidmcdonal d @ alum.mit.edu 
A significant factor in the complexity of the compressed, complex prose style used by 
journalists in short, targeted commercial reports (Who's News, joint ventures, earnings reports, 
etc.) is the fact that many of the phrases are semantically incomplete, i.e. their interpretation is 
dependent on information i  other parts of the sentence or the in discourse context. We propose 
that the complexity that such partially saturated referents contribute to the overall process of 
semantic interpretation can be characterized by two factors we will call displacement and 
unpacking. This complexity source can be quantified by counting the distance, in nodes, between 
each phrase that has a locally incomplete interpretation a d the phrase(s) that supply the terms 
that complete them. 
In this paper we will define this phenomenon and illustrate its impact on interpretation by 
examining short texts excerpted from the Tipster corpus and other online sources. 
1. The Problem 
The goal of this paper is to precisely 
characterize the intuitive observation that the 
A sentences below are more complex than 
their B counterparts. (Examplela. is from 
article 231 of the Tipster joint venture corpus; 
2a is from article 2279.) The B examples were 
corn-posed by the author. The task is 
information extraction, where the goal is to 
determine the amount hat each partner in the 
joint venture is contributing to the venture's 
total capital-ization. 
la. It will be capitalized at 130 million ringgit, 
which the three companies will equally 
shoulder. 
lb The three companies will shoulder equal 
amounts of the venture's capitalization of 
130 million ringgit. 
2a .... the joint firm, capitalized at one billion 
yen, will be 60 pct owned by P.T. Astra 
International, Inc., and 40 pct by Daihatsu. 
2b .... P.T. Astra will own 60 pct of the joint 
firm's capitalization of one billion yen and 
Daihatsu will own 40 pct. 
We are trying to quantify an aspect of the 
semantic interpretation process--the process 
by which the lexical and syntactic elements of 
51 
a text are mapped to a collection of typed, 
structured objects with respect o some model 
(broadly speaking, a collection of individuals 
and relations over them). 
We presume (a) that interpretations are 
formed compositionally following the paths 
provided by the syntax; (b) that they come into 
existence incrementally phrase by phrase, 
object by object as the parser moves left to 
right through the text. This implies that most 
relations will initially be only partially satur- 
ated. And (c) that the mapping from lexico- 
syntactic objects to semantic objects is a 
matter of recognizing function-argument 
patterns that are indicated structurally or 
morphologically and ultimately driven by 
information provided by the lexical sources of 
the predicates. 
Given this background, the question is what 
makes the A sentences more complex than the 
B sentences even though both convey 
essentially the same information, l The answer, 
Information, albeit of a different kind, is also 
conveyed by ordenng, choice of cohesive 
devices, or even just following the stylistic 
conventions ofthe genre (which the B 
sentences do not). Quantifying the impact of 
as we see it, lies in the nature of the path that 
that terms must take through the text's phrase 
structure as they are composed to form 
relations: the farther the distance the greater 
the complexity. 
Compositional complexity, as we propose 
to call this phenomenon, is a problem that 
arises because speakers establish their 
relationship with their audience by producing 
texts (in the formal sense) rather than a 
jumbled salad of independent phrases. To this 
end, speakers have at their disposal a large 
battery of linguistic devices that give texts 
their cohesion by omitting information that 
their audience must now infer, thereby 
inducing the audience's attention (Halliday & 
Hasan 1976). 
One of these devices is the use of phrases 
whose interpretations are locally incomplete: 
partially saturated. To understand such 
phrases, the audience (natural language under- 
standing system) must search through the 
context and identify the terms that are needed 
to fully populate (saturate) the model-level 
relations these phrases denote. 
We call this aspect of the semantic 
interpretation process 'compositional' com- 
plexity because we assume that the bulk of the 
organization on the context hat is searched is 
provided by the text's syntactic structure, and 
that the interpretation process overall is 
organized compositionally as a walk over the 
phrase structure the syntax defines (for us a 
bottom up and left to right traversal in lock- 
step with the parser as it establishes phrasal 
boundaries). 
These assumptions suggest hat a text will 
be harder to understand the greater the 
separation between the partially-saturated 
relations and their missing terms (i.e. the 
process of its interpretation will require more 
effort in terms of larger working state, using a 
richer type system, deploying a more complex 
this information structure, however, is beyond 
our present abilities. 52 
control structure, inviting a greater chance of 
error, etc.). As a first approximation we will 
measure this complexity by counting the 
number of intervening syntactic nodes. 
2. An Example 
We will explore this notion of 
compositional complexity by first looking in 
some detail at the structure and interpretation 
of example la, "It \[the joint venture\] will be 
capitalized at 130 million ringgit, which the 
three companies will equally shoulder", which 
we take to have the following syntactic 
structure. 2 
s 
i~pp 
vg at " ~  
will be 
NP 
130mil. ringgit ~ N ~  
the three vg 
vg 
will equa l~ 
v 
shoulder 
The first clause, "it wilt be capitalized at 
130 million ringgif', illustrates the simplest 
case of compositional complexity, where terms 
are adjacent to their targets. We assume that 
We are agnostic about what the 'true' choice of 
labelings and other theory-governed particulars 
should be; what is important isthe overall 
shape of the tree. 
the word capitalize in the sense used here 3 
denotes a function of two arguments, where J
is restricted to (can only be bound to) objects 
of type joint venture and $ to objects of type 
amount of money. 
J,$ . capital izat ion(J ,  $) 
In this base case the two needed terms are not 
separated by any intermediary syntactic nodes 
and we say that the text has a compositional 
complexity of zero. 
The result of binding these two terms is the 
instantiation of the fully saturated relation (i) 
below. What is shown is an expression but it 
intended just as a gloss of a typed structured 
object. Here and the examples to follow we 
will abbreviate freely in the interests of space, 
e.g. jv indicates the object that represents the 
joint venture, 130-million-ringget the object 
rep-resenting the instance of that amount of 
money that is being invested in the venture, 
and so on. We have given expression (i) a 
label, Cap- l ,  to emphasize its status as an 
object and to provide a simple means of 
indicating references to it in other relations. 
(i) Cap-l: capita l izat ion( J ,  130- 
mi l l ion-r inggit)  
Adopting an operational perspective, we 
can identify two different aspects of 
compositional complexity: displacement and 
unpacking. Displacement is simply the separ- 
ation between a term and its binding site given 
their relative depths in the tree. 
The need for unpacking follows from our 
assumption that a text is interpreted 
incrementally, with relations (or partial rela- 
tions) forming as soon as possible in the 
parser's progress through the text. We also 
assume that the individual elements of the text 
become unavailable at that moment except 
with respect o their configuration within the 
relation they have become part of. 
This is the sense of capitalize where it does not 
have an agent; cf. "Oracle lost $3.9 billion in 
market capitalization" \[Wired 8.03, pg. 272\]. 
53 
In our experience this is a valuable 
property. Consider the partially saturated rela- 
tion below that is the denotation of the relative 
clause of la at the point when the downstairs S
has been parsed ("which the three companies 
will equally shoulder"). We assume for present 
purposes that shoulder denotes a model-level 
category we can gloss as contributes-to-capita- 
lization. The objects representing the three 
companies are glossed as just C 1, C2, C3. 
( ii ) ~ amount contributes-to- 
capitalization( col lection(Cl,  C2, 
C3 ), amount) 
The agent of this relation is plain enough 
(those three particular companies), but what 
about he 'amount' that they contribute? 
Syntactically, the relative clause is of 
course open in its direct object, which the 
parser will associate with the np 130 million 
ringgit. But how is this syntactic open variable 
mirrored semantically? When thought of as a 
contri-bution to capitalization, the denotation 
of 130 million ringgit is not simply an amount 
of money in Indonesian currency, which would 
be meaningless. The np's denotation should 
instead provide a link though which we can 
determine that the money constitutes the fund- 
ing of some particular venture. This can be 
reflected in the restriction we place on the 
amount variable. 
This is where unpacking comes in. We have 
the option to view (i) as a composite object 
with a first class object representing each of its 
variable bindings in its own right, as in (iii) 
which is the unreduced binding of the amount 
of money to the amount variable of the object 
we named Cap-1 in (i). 
(iii) Amt- 1: 
((~ amount . Cap-l) 
130 -mil I ion- r inggit  ) 
Under this view we can unpack Cap- i  into 
its constituent elements and make this binding 
object accessible to be bound to amount, 
giving us: 
(iv) contr ibutes- to-capi ta l i zat lon ( 
col lect ion(Cl,  C2, C3), Amt~l) 
3. Measurements 
Now that we have illustrated the character 
of the complexity involved, what kind of 
numbers hould be put to this so that we can 
compare different ext quantitatively? With no 
literature to guide us here we should start with 
a simple calculuS. We will add one 'point' for 
each node that intervenes between the partial 
relation and each term that it is missing, and 
one for each variable binding that must be 
unpacked from an already formed relation. 
Under this analysis, the displacement of the 
'amount' term contributes two points for the 
two nodes that intervene between the location 
of the verb and the relative pronoun. 4 We add 
another point for unpacking given that the 
amount of money per se does not fit the 
restrictions we imposed on the AMT of a 
contributes-to-capitalization and we need to 
unpack the denotation of the upper clause to 
get at the binding we need. This gives us a 
total of three points of compositional 
complexity for saturating the relation created 
by shoulder. 
What other kinds of costs have we ignored 
so far? One definite cost is establishing what 
category (function, predicate) shoulder actual- 
ly denotes ince unless that is known the type 
constraints on its variable bindings will be 
untenably vague. (Consider that in this domain 
it will be quite common to see the phrase to 
shoulder debt.) 
Another, possibly debatable, cost is whether 
to distribute the denotation of the "the three 
companies" across the capitalization to create 
three individual relations. Just like one could 
elect to ignore the fact that a multi-term 
relation can be seen as a set of individual 
variable bindings until one of those bindings is 
We assume the parser carries the denotation of 
? the relativized np down to the spec posi-tion; 
doing that certainly permits an easier analysis 
of the relative clause since it allows it to take on 
the surface pattern of, e.g., topicalization. 
54 
needed to do work in another part of the text's 
interpretation, the distribution of this 
conjunction could remain a latent option until 
it was needed to make explicit some other 
semantic relation. 
We do need to distribute the companies 
conjunction in example 1 a because of the other 
relation-generating lexical head that we have 
yet to consider: equally. (Recall that the text of 
la is "It will be capitalized at 130 million 
ringgit, which the three companies will equally 
shoulder".) In isolation (before being specia- 
lized to the situation of joint venture capital- 
ization, another cost), equal denotes a com- 
pletely unsaturated relation: 
k co l lec t ion  ( par t i t ion  (measurable-  
stuff) ) . equal  ( e lements -o f  ( 
co l lec t ion  ( par t i t ion  
(measurable-stuf f )  ) ) ) 
Admittedly this choice of semantics may 
already be biased to the joint ventures 
problem, but it's thrust is to say that there must 
be some stuff that has been partitioned into 
some indeterminate number 
aggregate these portions form 
that all of these portions are 
equal. 
of portions; in 
a collection; and 
in some respect 
Here equal is predicated of whatever the 
shoulder clause denotes so the process of 
forming its interpretation must meet and 
follow the process of forming that clause's 
interpretation as it percolates up the headline 
of the relative clause and into the main clause. 
Equal is open in something of type 
collection where that collection is a partition of 
something. The first collection to be seen mov- 
ing up the headline at a remove of two nodes 
(the main verb and the vp) is the conjunction 
of companies. Because (a) equal is predicating 
the equality of some aspect of each of the 
elements of the collection and (b) the 
companies per se do not have textually 
obvious things that might be partitioned, we 
can make sense of this only by distributing not 
just the companies but the companies qua their 
participation in the contribution-to-capitaliza- 
tion relation. 
This gives us the three latent contribution- 
to-capitalization relations (at only the cost of 
the distribution construction, which is 
probably cheap). As part of that distribution 
construction we must also partition the amount 
of the contribution (object (iii)) into three 
parts. This entails unpacking those relations to 
expose their amount bindings. The equals 
relation then boils to down to a predication 5 
over those three binding objects, viz. 
(v) Contrib-l: contributes-to-capital- 
ization (Cl, Cap-l, Amt-2) 
(vi) Contrib-2 : contributes-to-capi- 
talization (C2, Cap-l, Amt-3) 
(vii) Contrib-3 : contributes-to-cap- 
italization (C3, Cap-l, Amt-4) 
(viii) Amt-2: ~ amount . contributes- 
to-capitalization (Cl, Cap-l, 
amount) 
(ix) Amt-3: ~ amount contributes- 
to-capitalization (C2, Cap-l, 
amount) 
(x) Amt-4: ~ amount contrlbutes-to- 
capital ization (C3, Cap-l, amount) 
(xi) equal (Amt-2, Amt-3, Amt-4) 
In terms of our computational complexity 
metric, the interpretation of the equally 
modifier has contributed two points for the 
displacement between it and the conjunction of 
companies and then (modulo the distribution 
cost) one point for unpacking the relation the 
companies are participating it to isolate the 
amount  binding(s). 
This gives example 1 a a total compositional 
complexity of 6: its three relation sources, 
capitalized, shoulder, and equally contributing 
zero, three, and three counts respectively; four 
of the counts reflecting the distance that dis- 
placed elements from their binding sites, and 
two reflecting the effort to dip into, or 
'unpack', already created relations in order to 
select or reify one of the elements within them. 
The amounts of money that he companies are 
contributing is given abstractly rather than 
calculated out since that appears to be the 
preferred level at which it should be represented 
for reasoning inthis domain 
55 
Contrast la, with its complexity of six, with 
lb, which has a compositional complexity of 
zero (though the rather severe departure of this 
artificially constructed sentence from the 
normal stylistic patterning must have a cost to 
human readers). 
lb The three companies will shoulder equal 
amounts of the venture's capitalization of 
130 million ringgit. 
lb garners this minimal cost by placing 
each contributing term right next the partial 
relation that provides its binding site, notably 
pushing the capitalization clause of 1 a down to 
the rightmost and lowest position in the sen- 
tence's phrase structure. 
Example two presents a challenge to a 
standard compositional model of interpretation 
that assumes that the denotation of the syn- 
tactic head provides the basis for interpreting 
the head's yntactic arguments. 
2a .... the joint firm, capital&ed at one billion 
yen, will be 60 pet owned by P.T. Astra 
International, Inc., and 40 pct by Daihatsu. 
The syntactic head of the conjunct "40 pct 
by Daihatsu'" has to be the percentage, yet 
there is no way to fashion a plausible rule of 
interpretation that binds a company to a 
percentage. Instead, both terms must be passed 
up through the conjunction node to the 
ownership clause (1 count) and then unpack 
the interpretation f that clause to extract he 
capitalization value and the joint venture (2 
counts, one for each term). Given that the 
capitalization of the joint venture was given in 
an appositive off the subject, the ownership 
clause itself required two extra counts for its 
construction, one to unpack the capitalization 
and a second for the displacement of the first 
parent company (P.T. Astra) away from the 
verb in its agentive by-phrase (though that 
count is debatable since the grammar might 
explicitly subcategorize for it). 
Complexity of this kind is ubiquitous in 
business reporting. Consider this excerpt from 
the beginning of a quarterly earnings report 
(PRNewsWire 1/21/00 5:21 p.m.): 
3. Gensym Corp. < descriptive appositives> 
today reported that revenues for its fourth 
quarter ended December 31, 1999 were $9.1 
million . . . .  The net loss for the fourth 
quarter of 1999 was. . .  
The sentence that reports the loss does not 
say what company lost the money--to do so 
would be unnecessarily redundant and reduce 
the text's cohesion. Yet the increased tightness 
of the text leaves us with an partially saturated 
relation as the immediate referent of that 
sentence, open in its company variable, which 
must be actively filled in from context. 
Moreover this example is somewhat unusual in 
that it provides a syntax-supported xplicit 
indicator of whose fourth quarter reporting 
period it is in the first of the two sentences; 
usually it would be stated ".for the fourth qua- 
r ter . . . "  and the reporting-period bject would 
also have been left with an unbound variable. 
4. Modeling 
Up to this point we have deliberately not 
discussed the question of how one would 
actually derive these compositional complexity 
counts automatically. We have instead 
provided a prose description of the process for 
a very few examples and many questions of 
just what constitutes a displacement or how 
one might know that a relation reached in the 
traversal Should be unpacked remain 
unanswered. 
The glib answer is that you fire up your 
natural language understanding system, add 
some reporting facilities to it, and apply it to 
the texts in question. Today at least that 
procedure is unlikely to work since texts of the 
sort we have been discussing are largely 
beyond the state of the art for information 
extraction engines without some deliberate, 
do-main-specific engineering. 
A more germane answer would look to. 
some resource of hand-annotated texts and 
then provide suitable definitions for displace- 
ment and unpacking that, given some 
debugging, could then be applied 
automatically even if there was not system that 
could as yet replace the knowledge of the 
human annotator. 
But this answer too is not available to us 
simply because such resources do not yet exist. 
Besides the obvious fact that efforts at 
providing semantic annotations of corpora are 
only just now getting underway, an additional 
problem is that the study of the semantic 
phenomenon that is the focus of this paper, 
unsaturated, model-level relations, is uncom- 
mon in the field and for good reason. 
An examination of the full text of the 
articles in, e.g., the Tipster Joint Ventures 
corpus will show that full phrases (maximal 
projections) that are unsaturated atthe moment 
they are delimited by the parser and then given 
a semantic interpretation are unusual. A casual 
examination of the text in this section did not 
turn any up. In the full text from which 
example l a was taken (which appears at the 
end of this paper) turns up only two more 
instances (reductions around the word sales). It 
is also worth noting that the original Tipster 
effort elected to drop attempts to extract 
capitalization i formation, as, indeed, these are 
among the more linguistically complex 
constructions in the corpus. 
Partially saturated relations abound in 
financial texts such as quarterly earnings 
reports or stock market reports. Our own 
interest in this phenomena stems from our 
recent focus on such texts as well as the utility 
of the perspective shifts this kind of semantic 
object provides for work in the tactics of 
natural language generation (i.e. 
microplanning). 
Without further, collective study of this 
class of semantic onstructions any annotation 
effort would have a considerable startup cost 
as it arrived at candidate representations for its 
annotators to use as well as a subjective cost in 
convincing the rest of the community that they 
had made reasonable, practical choices that 
56 
other project could adapt to their own 
purposes. 
Barring a well-financed project to supply a 
suitably annotated corpus, we think that the 
proper way to proceed towards the goal of a 
suitable formalization is along the lines of the 
original, glib answer to this problem, namely 
to build a parser and interpretation system that 
operates at a sufficient level of generalization 
that it would require only a minimal effort to 
provide the lexicon and conceptual model 
needed to examine texts in a given domain. 
We have been personally engaged in such a 
project over the last few years, albeit at a very 
slow pace given the constraints we are 
working under, and have made a fair amount 
of progress, some of which is described in 
McDonald (in press). 
5. Final Observations 
That texts with partially saturated relations 
are more complex to process is, we think, 
undeniable. It also seems to us a simple matter 
of examination to conclude that the cost is 
proportional to the factors we have identified: 
the distance by which relation elements have 
been displaced from each other and the cost of 
unpacking already completed relations to find 
needed terms that those relations have already 
in some sense consumed. On the other hand, 
that this cost is measured in integer values 
based on simple phrase node counts is entirely 
debatable. As other aspects of the semantic 
interpretation process are quantified this 
component of the total measure will at least 
need to be combined with some proportion- 
ality constant o make all the numbers com- 
parable. 
More interesting is the fact that some node 
transitions will certainly be different from 
others in their practical implementation and 
this should probably be factored into the cost 
calculation. Consider this sentence from article 
1271 of the Tipster joint venture corpus. 
57 
4. Inoda Cement Co . . . . . .  said Tuesday its U.S. 
subsidiary has formed an equally owned 
cement joint venture . . . with Lone Star 
Industries Inc. . .  
The process that completes the 'equal 
ownership' relation will have to reach up 
through three nodes to get to the first of the 
two owner companies. But it will certainly be 
different (more elaborate) to pass this partial 
relation through a node that is itself creating a 
relation (the vp headed by form) as compared 
with passing it through report verbs like said 
or raising verbs like expects to that add 
relatively little information. 
What the composition cost comes to in 
practice is, of course, a matter of the 
architecture of the parser and semantic 
interpretation engine that is being deployed. 
For some it may be a matter of adding 
additional mapping patterns that recognize the 
specific local configurations that denote 
partially saturated relations ('the <ordinal> 
quarter') and having heuristics for searching 
the discourse context for their missing 
elements. 
Systems with rich descriptive resources for 
lexicalized grammars such as TAGs could 
define specific auxiliary trees for relational 
heads that can appear in non-standard locations 
(e.g. equally) and tie them into map-ping rules 
that might try to do the work over the 
derivation trees that these parsers produce. The 
conjunction problem presented by example 
two would be amenable to a syntactic 
treatment in a categorial grammar, though the 
range of semantic types that can be combined 
in this arbitrary way might make that quite 
difficult in general. 
Finally, we must say that for us this whole 
idea of viewing the local interpretation of the 
interior phrases of a sentence as partially 
saturated relations and viewing their 
completion as a matter of passing these partial 
interpretations through the tree is the result of 
many years of research and development on a 
system where such relations are first class 
objects with the same ontological status as 
conventional individuals. In our system (see 
McDonald in press) the goal is to keep the 
syntactic processing simple and to move the 
onus of the interpretation effort onto to the 
semantic level by having more than one 
referent move up the headline as the phrase 
structure is created. The partially saturated 
relations are given an active role in seeking the 
arguments that they need. This introduces a
bias into our observations in this paper and 
could, possibly, be creating a mountain where 
systems with quite different architectures 
might only see a molehill. 
References: 
Halliday, Michael A. K., and Ruqaiya Hasan 
(1976) Cohesion in English, Longman, London. 
McDonald, David D. (in press) "Issues in the 
Representation of Real Texts: The Design of 
Krisp", in Iwanska and Shapiro (eds.) Natural 
Language Processing and Knowledge 
Representation: Language for Knowledge and 
Knowledge for Language, AAAI Press, pgs 71- 
104. 
500 will kick off production by June 1992, 
with sales expected to reach some 10 billion 
Yen. By the mid-1990s, it will increase the 
number of employees to 2,000 and sales to 30 
billion Yen. Output at the Malaysian company 
will be supplied to the three companies. Mazda 
will use the products for its cars to produced in 
and after the second half of next year, while 
Ford will mount them on its cars for sales in 
the Far East. Sanyo plans to sell Malaysian -
made products in Japan and other countries. 
</TXT> 
</doc> 
Appendix: The complete text of example la 
<doc> 
<docno> 0231 </docno> 
<DD> August 9, 1990, Thursday </DD> 
<SO> Copyright ? 1990 Jiji Press Ltd.; 
</SO> 
<TXT> 
Mazda Motor Corp. and Sanyo Electric 
Co. of Japan and Ford Motor Co. of the United 
States have agreed to set up a joint venture by 
the end of this year to produce car audio 
equipment in Malaysia, they said Thursday. 
The new company, whose name is not decided 
yet, will produce radios, stereos, compact disc 
players and tuners used for cars. It will be 
capitalized at 130 million ringgit, which the 
three companies will equally shoulder. The 
three plan to construct a 21,000-square-meter 
plant in the Prai Industrial Estate of Penang. 
The joint venture with a startup workforce of 
58 
  
?If you?ve heard it, you can say it? - Towards an Account of Expressibility 
 David D. McDonald Raytheon BBN Technologies Cambridge, MA USA dmcdonald@bbn.com 
Charles F. Greenbacker  University of Delaware Newark, DE, USA charlieg@cis.udel.edu    Abstract 
We have begun a project to automatically cre-ate the lexico-syntactic resources for a mi-croplanner as a side-effect of running a do-main-specific language understanding system. The resources are parameterized synchronous TAG Derivation Trees. Since the KB is as-sembled from the information in the texts that these resources are abstracted from, it will de-compose along those same lines when used for generation. As all possible ways of expressing each concept are pre-organized into general patterns known to be linguistically-valid (they were observed in natural text), we obtain an architectural account for expressibility. 1. Expressibility People speak grammatically. They may stutter, restart, or make the occasional speech error, but all in all they are faithful to the grammar of the language dialects they use. One of the ways that a language generation system can account for this is through the use of grammar that defines all of the possible lexico-syntactic elements from which a text can be constructed and defines all their rules of composition, such as lexicalized Tree Adjoining Grammar (TAG). Without the ability to even formulate an ungrammatical text, such a generator provides an account for human grammaticality based on its architecture rather than its programmer.  We propose a similar kind of accounting for the problem of expressibility: one based on architecture rather than accident. Expressibility, as defined by Meteer (1992), is an issue for microplanners as they decide on which lexical and syntactic resources to employ. Not all of the options they might want to use are available in the language ? they are not expressible. Consider the examples in Figure 1, adapted from Meteer 1992 pg. 50.  
Expression Construction (?decide?) ?quick decision? <result> + <quick> ?decide quickly? <action> + <quick> ?important decision? <result> + <important> * ?decide importantly? <action> + <important> Figure 1: Constraints on expressibility: To say that there was a decision and it was important, you are forced to use the noun form because there is no adverbial form for important as there is for quick  In this short paper, we discuss our approach to expressibility. We describe in detail our novel method centered on how to use parser observa-tions to guide generator decisions, and we pro-vide a snapshot of the current status of our system implementation. 2. Related Work Natural language generation (NLG) systems must have some way of making sure that the messages they build are actually expressible. Template-based generators avoid problems with expressibility largely by anticipating all of the wording that will be needed and packaging it in chunks that are guaranteed to compose correctly. Becker (2006), for example, does this via fully lexicalized TAG trees.   Among more general-purpose generators, one approach to expressibility is to look ahead into the lexicon, avoiding constructions that are lexically incompatible. Look-ahead is expensive, however, and is only practical at small abstrac-tion distances such as Shaw?s re-writing sentence planner (1998). Meteer?s own approach to expressibility started by interposing another level of represen-tation between the microplanner and the surface realizer, an ?abstract syntactic representation? in the sense of RAGS (Cahill et al 1999), that employed functional relationships (head, argu-ment, matrix, adjunct) over semantically typed, 
  
lexicalized constituents. This blocks *decide importantly because ?important? only has a realization as a property and her composition rules prohibit using a property to modify an action (?decide?). Shifting the perspective from the action to its result allows the composition to go through. We are in sympathy with this approach ? a microplanner needs its own representational level to serve as a scratch pad (if using a revi-sion-based approach) or just as a scaffold to hold intermediate results. However, Meteer?s seman-tic and lexical constraints do require operating with fine-grain details. We believe that we can work with larger chunks that have already been vetted for expressibility because we?ve observed someone use them, either in writing or speech.  3. Method Our approach is similar to that of Zhong  & Stent (2005) in that we use the analysis of a corpus as the basis for creating the resources for the reali-zation component. Several differences stand out. For one, we are working in specific domains rather than generic corpora like the WSJ. This enables the biggest difference: our analysis is performed by a completely accurate,1 domain-specific NLU system (?parser?)2 based on a semantic grammar (McDonald 1993). It is read-ing for the benefit of a knowledge base, adding specific facts within instances of a highly struc-tured, predefined prototypes. Such instances are used as the starting point for the generation process. On the KB side, our present focus happens to be on hurricanes and the process they go through as they evolve. We have developed a semantic grammar for this domain, and it lets us analyze texts like these:3 (1) ?Later that day it made landfall near the Haitian town of Jacmel.?                                                            1 Parse accuracy and correct word sense interpretation is only possible if the semantic domain under analysis is restricted by topic and sublanguage.  2 Most systems referred to as ?parsers? stop at a structural description. Ours stops at the level of a disambiguated conceptual model and is more integrated than most. 3 #1 and 2 are from the Wikipedia article on Hurricane Gustav. #3 is from a New York Times article. 
(2) ?? and remained at that intensity until landfall on the morning of September 1 near Cocodrie, Louisiana.? (3) ?By landfall on Monday morning ?? Such texts tell us how people talk about hurri-canes, specifically here about landfall events. They tell us what combinations of entities are reasonable to include within single clauses (intensity, time, location), and they tell us which particular realizations of the landfall concept have been used in which larger linguistic con-texts. They also indicate what information can be left out under the discourse conditions defined by the larger texts they appear in.4 As different texts are read, we accumulate dif-ferent realization forms for the same content. In example #1, landfall is expressed via the idiom make landfall, the time is given in an initial adverbial, and the location as a trailing adjunct. In #2, the landfall stands by itself as the head of a time-adverbial and the time and location are adjuncts off of it. This set of alternative phras-ings provides the raw material for the microplan-ner to work with ? a natural set of paraphrases. 3.1 Derivation Trees as templates As shown in Figure 3, to create resources for the microplanner, we start with the semantic analysis that the parser anchors to its referent when it instantiates the appropriate event type within the prototypical model of what hurricanes do, here a ?landfall event?, noting the specific time and location. Following Bateman (e.g. 2007) and Meteer (1992), we work with typed, structured objects organized under a foundational ontol-ogy.5 Figure 2 shows the current definition of the landfall class in a local notation for OWL Full. (Class HurricaneLandfall   (restrict hurricane - Hurricane)   (restrict intensity ? Saffir-Simpson)   (restrict location ? PhysEndurant)   (restrict time ? Date&Time)) Figure 2. The Landfall class                                                             4 For example, in #1 and #3 the precise date had been given already in earlier sentences. 5 An extension of Dolce (Gangemi et al 2002). 
  
Figure 3. Overview The semantic analysis recursively maps con-stituents? referents to properties of a class in-stance. Accompanying it is a syntactic analysis in the form of a TAG Derivation Tree6 (DT) where each of its nodes (initial trees, insertions or adjunctions) points both to its lexical anchor and its specific correspondence in the domain model. To create a reusable resource, we abstract away from the lexicalization in these DT/model-anchored pairs, and replace it with the corre-sponding model classes as determined by the restrictions on the properties. For example, the day of the week in #3, lexically given as Monday morning and then dereferenced to an object with the meaning ?9/1/2008 before noon? is replaced in the resource with that object?s type. The result is a set of templates associated with the combination of types that corresponds to the participants in its source text ? the more com-posed the type, the more insertions / adjunctions in the template derivation tree.   3.2 Synchronous TAGS This combination of derived trees and model-levels classes and properties where the nodes of the two structures are linked is a synchronous TAG (ST). As observed by Shieber and Schabes (1991) who introduced this notion, ?[STs] make the fine-grained correspondences between ex-pressions of natural language and their meanings explicit by ? node linking?.                                                             6 The primary analysis is phrase structure in a chart, but since every rule in the grammar corresponds to either a lexicalized insertion or adjunction, the pattern of rule application is read out as a TAG derivation tree. 
pp("by")
   insert: prep-comp("landfall")
   adjoin: pp ("on")
              insert: prep-comp("Monday")
(Individual HurricaneLandfall new-instance
 (hurricane #<>)
 (intensity #<>)
 (location #<>)
 (time #<DayOfWeek Monday>))
 
 
 
  Figure 4. Synchronous TAG In particular, they observe that STs solve an otherwise arbitrary problem of ?where does one start? when faced with a bag of content to be realized as a text. Our STs identify natural ?slices? of the content ? those parts that have already been observed to have been realized together in a naturally occurring text. Because we have the luxury to be creating the knowledge base of our hurricane model by the accretion of relationships among individually small chunks of information (a triple store), we can take synchronous TAGS a step further and allow them to dictate the permitted ways that information can be delimited within the KB for purposes of generation following the ideas in (Stone 2002). If we can surmount the issues described be-low, this stricture ? that one can only select for generation units of content of the types that have been observed to be used together (the model side of the STs) ? is a clean architectural expla-nation of how it is that the generator?s messages are always expressible.  4. State of Development We are at an early stage in our work. Everything we have described is implemented, but only on a 
  
?thin slice? to establish that our ideas were credi-ble. There are many issues to work out as we ?bulk up? the system and begin to actually inte-grate it in a in ?tactical? microplanner and begin to actually do the style of macro-planning (de-termining the relevant portions of the domain model to use as content given the intent and affect) that our use of synchronous TAGS should allow. The most salient issues are how broadly we should generalize when we substitute domain types for lexicalizations in the templates, and what contextual information must be kept with the templates.  The type generalizations need to be broad enough to encompass as many substitutions as possible, while being strict enough to ensure that when the template is applied to those objects the realizations available to them permit them to be expressed in that linguistic context.7 The examples all have specific contexts in the sentences and recent discourse. Two of them (#2, #3) are using the landfall event as a time phrase. Can we move them and still retain the natural-ness of the original (e.g. from sentence initial to sentence final), or does this sort of information need to be encoded? Another issue is how to evaluate a system like this. Given the accuracy of the analysis, recreat-ing the source text is trivial, so comparison to the source of the resources as a gold standard is meaningless. Some alternative must be found. While we work out these issues, we are ex-tending the NLU domain model and grammar to cover more cases and thence create more syn-chronized TAG templates. We then manually identify alternative domain content to app hly to them to in order to explore the space of realiza-tions and identify unforeseen interactions. Our short-term goals are to vastly increase the grammar coverage for our motivating examples and to hand over all microplanning decisions to the system itself. Long-term goals include broad-ening the coverage further still, to as open a domain as is feasible, as well as testing different macroplanners and applications with which to drive the entire process. Among several possi-bilities are automatic merged-and-modified summarization and a query-based discourse system.                                                            7 In our example, substituting different days and times is obvious (by landfall on the afternoon of August 22), but as we move away from that precise set of types (general-time-of-day + date) we see that what had been lexically fixed in the derivation tree (by landfall on) has to shift: ? at 2:00 on August 22.  
5. Discussion Because the phrasal patterns observed in the corpus act as templates guiding the generation process, and as the underlying NLU system and generator (McDonald 1993, Meteer et al 1987) are mature and grounded in linguistic principles, our system combines template-based and theory-based approaches.  Van Deemter et al (2005) outlined three crite-ria for judging template-driven applications against "standard" (non-template) NLG systems. (1) Maintainability is addressed by the fact that our templates aren't hand-made. To extend the set of available realization forms we expose the NLU system to more text. The subject domain has to be one that has already been modeled, but we are operating from the premise that a NLG component would only bother to speak about things that the system as a whole understands. (2) Output quality and variability are determined by the corpus; using corpora containing high quality and varied constructions will enable similar output from the generator. (3) Most crucially, our parser and generator components are linguistically well-founded. Composition into our ?templates? is smoothly accommodated (extra modifiers, shifts in tense or aspect, appli-cation of transformations over the DT to form questions, relative clauses, dropped constituents under conjunction). The fully-articulated syntac-tic structure can be automatically annotated to facilitate prosody or to take information structure markup on the DT. The closest system to ours may be Marciniak & Strube (2005) who also use an annotated corpus as a knowledge source for generation, getting their annotations via ?a simple rule-based system tuned to the given types of text?. As far as we can tell, they are more concerned with discourse while we focus on the integration with the underlying knowledge base and how that KB is extended over time. Like them, we believe that one of the most promising aspects of this work going forward is that the use of a parser provides us with ?self-labeling data? to draw on for statistical analysis. Such training material would reduce the effort required to adapt a generator to a new domain, while simultaneously improving its output.  Acknowledgments This work was supported in part by the BBN POIROT project: DARPA IPTO contract FA865 0-06-C-7606. 
  
References  John Bateman, Thora Tenbrink, and Scott Farrar. 2007. The Role of Conceptual and Linguistic On-tologies in Interpreting Spatial Discourse. Dis-course Processes, 44(3):175?213. Tilman Becker. 2006. Natural Language Generation with Fully Specified Templates. In W. Wahlster (Ed.), SmartKom: Foundations of Multimodal Dia-log Systems, 401?410. Springer, Berlin Heidelberg. Lynne Cahill, Christy Doran, Roger Evans, Chris Mellish, Daniel Paiva, Mike Reape, Donia Scott, & Neil Tipper. 1999. Towards a Reference Architec-ture for Natural Language Generation Systems, The RAGS project. ITRI technical report number ITRI-99-14, University of Brighton, March. Aldo Gangemi, Nicola Guarino, Claudio Masolo, Alessandro Oltramari, & Luc Schneider. 2002. Sweetening Ontologies with DOLCE. In Proceed-ings of the 13th International Conference on Knowledge Acquisition, Modeling and Manage-ment (EKAW), pages 166?181, Sig?enza, Spain, October 1?4. Tomasz Marciniak & Michael Strube. 2005. Using an Annotated Corpus As a Knowledge Source For Language Generation. In Proceedings of the Cor-pus Linguistics 2005 Workshop on Using Corpora for Natural Language Generation (UCNLG), pages 19?24, Birmingham, UK, July 14. David McDonald. 2003. The Interplay of Syntactic and Semantic Node Labels in Partial Parsing, in the proceedings of the Third International Workshop on Parsing Technologies, August 10-13, 1993 Til-burg, The Netherlands, pp. 171-186; revised ver-sion in Bunt and Tomita (eds), Recent Advances in Parsing Technology, Kluwer Academic Publishers, pgs. 295-323. Marie W. Meteer. 1992. Expressibility and the Prob-lem of Efficient Text Planning. Pinter, London.  Marie Meteer, David McDonald, Scott Anderson, David Forster, Linda Gay, Alison Huettner & Penelope Sibun. 1987. Mumble-86: Design and Implementation, TR #87-87 Dept. Computer & Information Science, UMass., September 1987, 174 pgs. James Shaw. 1998. Clause Aggregation Using Lin-guistic Knowledge. In Proceedings of the 9th In-ternational Workshop on Natural Language Gen-eration, pages 138?147, Niagara-on-the-Lake, On-tario, August 5?7.  Stuart Shieber & Yves Schabes. 1991. Generation and synchronous tree-adjoining grammar. Computa-tional Intelligence, 7(4):220?228. Matthew Stone. 2003. Specifying Generation of Referring Expressions by Example. In Proceedings 
of the AAAI Spring Symposium on Natural Lan-guage Generation in Spoken and Written Dialogue, pages 133?140, Stanford, March. Kees van Deemter, Emiel Krahmer, & Mari?t Theune. 2005. Real versus Template-Based Natural Lan-guage Generation: A False Opposition? Computa-tional Linguistics, 31(1):15?24. Huvava Zhong & Amada Stent. 2005. Building Surface Realizers Automatically From Corpora. In Proceedings of the Corpus Linguistics 2005 Work-shop on Using Corpora for Natural Language Generation (UCNLG), pages 49?54, Birmingham, UK, July 14. 
Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 52?62,
Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational Linguistics
Improving the Accessibility of Line Graphs in Multimodal Documents
Charles F. Greenbacker Peng Wu Sandra Carberry Kathleen F. McCoy
Stephanie Elzer* David D. McDonald? Daniel Chester Seniz Demir?
Dept. of Computer & Information Sciences, University of Delaware, USA
[charlieg|pwu|carberry|mccoy|chester]@cis.udel.edu
*Dept. of Computer Science, Millersville University, USA elzer@cs.millersville.edu
?SIFT LLC., Boston, Massachusetts, USA dmcdonald@sift.info
?TU?BI?TAK BI?LGEM, Gebze, Kocaeli, Turkey senizd@uekae.tubitak.gov.tr
Abstract
This paper describes our work on improv-
ing access to the content of multimodal docu-
ments containing line graphs in popular media
for people with visual impairments. We pro-
vide an overview of our implemented system,
including our method for recognizing and con-
veying the intended message of a line graph.
The textual description of the graphic gener-
ated by our system is presented at the most rel-
evant point in the document. We also describe
ongoing work into obtaining additional propo-
sitions that elaborate on the intended message,
and examine the potential benefits of analyz-
ing the text and graphical content together in
order to extend our system to produce sum-
maries of entire multimodal documents.
1 Introduction
Individuals with visual impairments have difficulty
accessing the information contained in multimodal
documents. Although screen-reading software can
render the text of the document as speech, the graph-
ical content is largely inaccessible. Here we con-
sider information graphics (e.g., bar charts, line
graphs) often found in popular media sources such
as Time magazine, Businessweek, and USA Today.
These graphics are typically intended to convey a
message that is an important part of the overall story,
yet this message is generally not repeated in the ar-
ticle text (Carberry et al, 2006). People who are
unable to see and assimilate the graphical material
will be left with only partial information.
While some work has addressed the accessibility
of scientific graphics through alternative means like
touch or sound (see Section 7), such graphs are de-
signed for an audience of experts trained to use them
for data visualization. In contrast, graphs in popular
media are constructed to make a point which should
be obvious without complicated scientific reasoning.
We are thus interested in generating a textual pre-
sentation of the content of graphs in popular media.
Other research has focused on textual descriptions
(e.g., Ferres et al (2007)); however in that work the
same information is included in the textual summary
for each instance of a graph type (i.e., all summaries
of line graphs contain the same sorts of informa-
tion), and the summary does not attempt to present
the overall intended message of the graph.
SIGHT (Demir et al, 2008; Elzer et al, 2011) is
a natural language system whose overall goal is pro-
viding blind users with interactive access to multi-
modal documents from electronically-available pop-
ular media sources. To date, the SIGHT project
has concentrated on simple bar charts. Its user in-
terface is implemented as a browser helper object
within Internet Explorer that works with the JAWS
screen reader. When the system detects a bar chart
in a document being read by the user, it prompts the
user to use keystrokes to request a brief summary of
the graphic capturing its primary contribution to the
overall communicative goal of the document. The
summary text can either be read to the user with
JAWS or read by the user with a screen magnifier
tool. The interface also enables the user to request
further information about the graphic, if desired.
However, SIGHT is limited to bar charts only.
In this work, we follow the methodology put forth
by SIGHT, but investigate producing a summary of
52
?
102468 1900?10
?20
?50?60
?70?80
?90?
03
?30?40
2000
10
8.9
1.979 inches over t
he past centu
ry. Annual d
ifference fro
m Seattle?s
In the seattl
e area, for e
xample, the
 Pacific Oce
an has risen
 nearly 
they are risi
ng about 0.0
4?0.09 of an
 inch each y
ear.
Sea levels fl
uctuate arou
nd the globe
, but oceano
graphers bel
ieve
Ocean level
s rising
1899 sea lev
el, in inches
:
Figure 1: From ?Worry flows from Arctic ice to tropical
waters? in USA Today, May 31, 2006.
line graphs. Line graphs have different discourse
goals and communicative signals than bar charts,1
and thus require significantly different processing.
In addition, our work addresses the issue of coher-
ent placement of a graphic?s summary when reading
the text to the user and considers the summarization
of entire documents ? not just their graphics.
2 Message Recognition for Line Graphs
This section provides an overview of our imple-
mented method for identifying the intended message
of a line graph. In processing a line graph, a vi-
sual extraction module first analyzes the image file
and produces an XML representation which fully
specifies the graphic (including the beginning and
ending points of each segment, any annotations on
points, axis labels, the caption, etc.). To identify
the intended message of a line graph consisting of
many short, jagged segments, we must generalize
it into a sequence of visually-distinguishable trends.
This is performed by a graph segmentation module
which uses a support vector machine and a variety
of attributes (including statistical tests) to produce a
model that transforms the graphic into a sequence of
straight lines representing visually-distinguishable
trends. For example, the line graph in Figure 1 is
divided into a stable trend from 1900 to 1930 and a
rising trend from 1930 to 2003. Similarly, the line
graph in Figure 2 is divided into a rising trend from
1Bar charts present data as discrete bars and are often used
to compare entities, while line graphs contain continuous data
series and are designed to portray longer trend relationships.
20062005200420032002
19971998
1999
20012000
200,000 150,0001999
: 189,840
70,6062006:
50,000100,000Declining Dur
ango sales
0
Figure 2: From ?Chrysler: Plant had $800 million im-
pact? in The (Wilmington) News Journal, Feb 15, 2007.
1997 to 1999 and a falling trend from 1999 to 2006.
In analyzing a corpus of around 100 line graphs
collected from several popular media sources, we
identified 10 intended message categories (includ-
ing rising-trend, change-trend, change-trend-return,
and big-jump, etc.), that seem to capture the kinds
of high-level messages conveyed by line graphs. A
suggestion generation module uses the sequence of
trends identified in the line graph to construct all
of its possible candidate messages in these message
categories. For example, if a graph contains three
trends, several candidate messages are constructed,
including two change-trend messages (one for each
adjacent pair of trends), a change-trend-return mes-
sage if the first and third trends are of the same type
(rising, falling, or stable), as well as a rising, falling,
or stable trend message for each individual trend.
Next, various communicative signals are ex-
tracted from the graphic, including visual features
(such as a point annotated with its value) that draw
attention to a particular part of the line graph, and
linguistic clues (such as the presence of certain
words in the caption) that suggest a particular in-
tended message category. Figure 2 contains several
such signals, including two annotated points and the
word declining in its caption. Next, a Bayesian net-
work is built to estimate the probability of the can-
didate messages; the extracted communicative sig-
nals serve as evidence for or against each candidate
message. For Figure 2, our system produces change-
trend(1997, rise, 1999, fall, 2006) as the logical rep-
resentation of the most probable intended message.
Since the dependent axis is often not explicitly la-
beled, a series of heuristics are used to identify an
appropriate referent, which we term the measure-
ment axis descriptor. In Figure 2, the measurement
axis descriptor is identified as durango sales. The
53
intended message and measurement axis descriptor
are then passed to a realization component which
uses FUF/SURGE (Elhadad and Robin, 1996) to
generate the following initial description:
This graphic conveys a changing trend in
durango sales, rising from 1997 to 1999
and then falling to 2006.
3 Identifying a Relevant Paragraph
In presenting a multimodal document to a user via a
screen reader, if the author does not specify a read-
ing order in the accessibility preferences, it is not
entirely clear where the description of the graph-
ical content should be given. The text of scien-
tific articles normally makes explicit references to
any graphs contained in the document; in this case,
it makes sense to insert the graphical description
alongside the first such reference. However, popular
media articles rarely contain explicit references to
graphics. We hypothesize that describing the graphi-
cal content together with the most relevant portion of
the article text will result in a more coherent presen-
tation. Results of an experiment described in Sec-
tion 3.3 suggest the paragraph which is geograph-
ically closest to the graphic is very often not rele-
vant. Thus, our task becomes identifying the portion
of the text that is most relevant to the graph.
We have developed a method for identifying the
most relevant paragraph by measuring the similarity
between the graphic?s textual components and the
content of each individual paragraph in the docu-
ment. An information graphic?s textual components
may consist of a title, caption, and any additional
descriptions it contains (e.g., the five lines of text in
Figure 1 beneath the caption Ocean levels rising).
An initial method (P-KL) based on KL divergence
measures the similarity between a paragraph and the
graphic?s textual component; a second method (P-
KLA) is an extension of the first that incorporates
an augmented version of the textual component.
3.1 Method P-KL: KL Divergence
Kullback-Leibler (KL) divergence (Kullback, 1968)
is widely used to measure the similarity between two
language models. It can be expressed as:
DKL(p||q) =
?
i?V
p(i)log
p(i)
q(i)
where i is the index of a word in vocabulary V , and
p and q are two distributions of words. Liu et al
(Liu and Croft, 2002) applied KL divergence to text
passages in order to improve the accuracy of docu-
ment retrieval. For our task, p is a smoothed word
distribution built from the line graph?s textual com-
ponent, and q is another smoothed word distribution
built from a paragraph in the article text. Smoothing
addresses the problem of zero occurrences of a word
in the distributions. We rank the paragraphs by their
KL divergence scores from lowest to highest, since
lower scores indicate a higher similarity.
3.2 Method P-KLA: Using Augmented Text
In analyzing paragraphs relevant to the graphics, we
realized that they included words that were germane
to describing information graphics in general, but
not related to the domains of individual graphs. This
led us to build a set of ?expansion words? that tend to
appear in paragraphs relevant to information graph-
ics. If we could identify domain-independent terms
that were correlated with information graphics in
general, these expansion words could then be added
to the textual component of a graphic when measur-
ing its similarity to a paragraph in the article text.
We constructed the expansion word set using an
iterative process. The first step is to use P-KL to
identify m pseudo-relevant paragraphs in the cor-
responding document for each graphic in the train-
ing set (the current implementation uses m = 3).
This is similar to pseudo-relevance feedback used in
IR (Zhai, 2008), except only a single query is used
in the IR application, whereas we consider many
pairs of graphics and documents to obtain an ex-
pansion set applicable to any subsequent informa-
tion graphic. Given n graphics in the training set,
we identify (up to) m ? n relevant paragraphs.
The second step is to extract a set of words re-
lated to information graphics from these m ?n para-
graphs. We assume the collection of pseudo-relevant
paragraphs was generated by two models, one pro-
ducing words relevant to the information graphics
and another producing words relevant to the topics
of the individual documents. Let Wg represent the
word frequency vector yielding words relevant to
the graphics, Wa represent the word frequency vec-
tor yielding words relevant to the document topics,
and Wp represent the word frequency vector of the
54
pseudo-relevant paragraphs. We compute Wp from
the pseudo-relevant paragraphs themselves, and we
estimate Wa using the word frequencies from the
article text in the documents. Finally, we compute
Wg by filtering-out the components ofWa fromWp.
This process is related to the work by Widdows
(2003) on orthogonal negation of vector spaces.
The task can be formulated as follows:
1. Wp = ?Wa + ?Wg where ? > 0 and ? > 0,
which means the word frequency vector for
the pseudo-relevant paragraphs is a linear com-
bination of the background (topic) word fre-
quency vector and the graphic word vector.
2. < Wa,Wg >= 0 which means the background
word vector is orthogonal to the graph descrip-
tion word vector, under the assumption that the
graph description word vector is independent of
the background word vector and that these two
share minimal information.
3. Wg is assumed to be a unit vector, since we are
only interested in the relative rank of the word
frequencies, not their actual values.
Solving the above equations, we obtain:
? =
< Wp,Wa >
< Wa,Wa >
Wg = normalized
(
Wp ?
< Wp,Wa >
< Wa,Wa >
?Wa
)
After computing Wg, we use WordNet to filter-
out words having a predominant sense other than
verb or adjective, under the assumption that nouns
will be mainly relevant to the domains or topics
of the graphs (and are thus ?noise?) whereas we
want a general set of words (e.g., ?increasing?)
that are typically used when describing the data in
any graph. As a rough estimate of whether a word
is predominantly a verb or adjective, we determine
whether there are more verb and adjective senses of
the word in WordNet than there are noun senses.
Next, we rank the words in the filteredWg accord-
ing to frequency and select the k most frequent as
our expansion word list (we used k = 25 in our ex-
periments). The two steps (identifyingm?n pseudo-
relevant paragraphs and then extracting a word list of
size k to expand the graphics? textual components)
are applied iteratively until convergence occurs or
minimal changes are observed between iterations.
In addition, parameters of the intended message
that represent points on the x-axis capture domain-
specific content of the graphic?s communicative
goal. For example, the intended message of the line
graph in Figure 1 conveys a changing trend from
1900 to 2003 with the change occurring in 1930. To
help identify relevant paragraphs mentioning these
years, we also add these parameters of the intended
message to the augmented word list.
The result of this process is the final expansion
word list used in method P-KLA. Because the tex-
tual component may be even shorter than the expan-
sion word list, we do not add a word from the expan-
sion word list to the textual component unless the
paragraph being compared also contains this word.
3.3 Results of P-KL and P-KLA
334 training graphs with their accompanying articles
were used to build the expansion word set. A sepa-
rate set of 66 test graphs and articles was analyzed
by two human annotators who identified the para-
graphs in each document that were most relevant to
its associated information graphic, ranking them in
terms of relevance. On average, annotator 1 selected
2.00 paragraphs and annotator 2 selected 1.71 para-
graphs. The annotators agreed on the top ranked
paragraph for only 63.6% of the graphs. Consid-
ering the agreement by chance, we can calculate the
kappa statistic as 0.594. This fact shows that the
most relevant paragraph is not necessarily obvious
and multiple plausible options may exist.
We applied both P-KL and P-KLA to the test set,
with each method producing a list of the paragraphs
ranked by relevance. Since our goal is to provide
the summary of the graphic at a suitable point in the
article text, two evaluation criteria are appropriate:
1. TOP: the method?s success rate in selecting
the most relevant paragraph, measured as how
often it chooses the paragraph ranked highest
by either of the annotators
2. COVERED: the method?s success rate in se-
lecting a relevant paragraph, measured as how
often it chooses one of the relevant paragraphs
identified by the annotators
Table 1 provides the success rates of both of our
methods for the TOP and COVERED criteria, along
with a simple baseline that selected the paragraph
55
geographically-closest to the graphic. These results
show that both methods outperform the baseline,
and that P-KLA further improves on P-KL. P-KLA
selects the best paragraph in 60.6% of test cases,
and selects a relevant paragraph in 71.2% of the
cases. For both TOP and COVERED, P-KLA nearly
doubles the baseline success rate. The improve-
ment of P-KLA over P-KL suggests that our expan-
sion set successfully adds salient words to the tex-
tual component. A one-sided Z-test for proportion
based on binomial distribution is shown in Table 1
and indicates that the improvements of P-KL over
the baseline and P-KLA over P-KL are statistically-
significant at the 0.05 level across both criteria. The
Z-test is calculated as:
p? p0
?
p0(1?p0)
n
where p0 is the lower result and p is the improved
result. The null hypothesis is H0 : p = p0 and the
alternative hypothesis is H1 : p > p0.
3.4 Using relevant paragraph identification to
improve the accessibility of line graphs
Our system improves on SIGHT by using method
P-KLA to identify the paragraph that is most rele-
vant to an information graphic. When this paragraph
is encountered, the user is asked whether he or she
would like to access the content of the graphic. For
example, our system identifies the following para-
graph as most relevant to Figure 2:
Doing so likely would require the com-
pany to bring in a new model. Sales of
the Durango and other gas-guzzling SUVs
have slumped in recent years as prices at
the pump spiked.
In contrast, the geographically-closest paragraph has
little relevance to the graphic:
?We have three years to prove to them
we need to stay open,? said Sam Latham,
president of the AFL-CIO in Delaware,
who retired from Chrysler after 39 years.
4 Identifying Additional Propositions
After the intended message has been identified, the
system next looks to identify elaborative informa-
tional propositions that are salient in the graphic.
These additional propositions expand on the initial
description of the graph by filling-in details about
the knowledge being conveyed (e.g., noteworthy
points, properties of trends, visual features) in order
to round-out a summary of the graphic.
We collected a corpus of 965 human-written sum-
maries for 23 different line graphs to discover which
propositions were deemed most salient under varied
conditions.2 Subjects received an initial description
of the graph?s intended message, and were asked to
write additional sentences capturing the most impor-
tant information conveyed by the graph. The propo-
sitions appearing in each summary were manually
coded by an annotator to determine which were most
prevalent. From this data, we developed rules to
identify important propositions in new graphs. The
rules assign weights to propositions indicating their
importance, and the weights can be compared to de-
cide which propositions to include in a summary.
Three types of rules were built. Type-1 (message
category-only) rules were created when a plurality
of summaries for all graphs having a given intended
message contained the same proposition (e.g., pro-
vide the final value for all rising-trend and falling-
trend graphs). Weights for type-1 rules were based
on the frequency with which the proposition ap-
peared in summaries for graphs in this category.
Type-2 (visual feature-only) rules were built when
there was a correlation between a visual feature and
the use of a proposition describing that feature, re-
gardless of the graph?s message category (e.g., men-
tion whether the graph is highly volatile). Type-2
rule weights are a function of the covariance be-
tween the magnitude of the visual feature (e.g., de-
gree of volatility) and the proportion of summaries
mentioning this proposition for each graph.
For propositions associated with visual features
linked to a particular message category (e.g., de-
scribe the trend immediately following a big-jump
or big-fall when it terminates prior to the end of the
graph), we constructed Type-3 (message category
+ visual feature) rules. Type-3 weights were cal-
culated just like Type-2 weights, except the graphs
were limited to the given category.
As an example of identifying additional proposi-
2This corpus is described in greater detail by Greenbacker et
al. (2011) and is available at www.cis.udel.edu/~mccoy/corpora
56
closest P-KL significance level over closest P-KLA significance level over P-KL
TOP 0.272 0.469 (z = 3.5966, p < 0.01) 0.606 (z = 2.2303, p < 0.025)
COVERED 0.378 0.606 (z = 3.8200, p < 0.01) 0.712 (z = 1.7624, p < 0.05)
Table 1: Success rates for baseline method (?closest?), P-KL, and P-KLA using the TOP and COVERED criteria.
tions, consider Figures 1 and 2. Both line graphs
belong to the same intended message category:
change-trend. However, the graph in Figure 1 is far
more volatile than Figure 2, and thus it is likely that
we would want to mention this proposition (i.e., ?the
graph shows a high degree of volatility...?) in a sum-
mary of Figure 1. By finding the covariance between
the visual feature (i.e., volatility) and the frequency
with which a corresponding proposition was anno-
tated in the corpus summaries, a Type-2 rule assigns
a weight to this proposition based on the magnitude
of the visual feature. Thus, the volatility proposi-
tion will be weighted strongly for Figure 1, and will
likely be selected to appear in the initial summary,
while the weight for Figure 2 will be very low.
5 Integrating Text and Graphics
Until now, our system has only produced summaries
for the graphical content of multimodal documents.
However, a user might prefer a summary of the en-
tire document. Possible use cases include examining
this summary to decide whether to invest the time re-
quired to read a lengthy article with a screen reader,
or simply addressing the common problem of having
too much material to review in too little time (i.e.,
information overload). We are developing a system
extension that will allow users to request summaries
of arbitrary length that cover both the text and graph-
ical content of a multimodal document.
Graphics in popular media convey a message that
is generally not repeated in the article text. For ex-
ample, the March 3, 2003 issue of Newsweek con-
tained an article entitled, ?The Black Gender Gap,?
which described the professional achievements of
black women. It included a line graph (Figure 3)
showing that the historical gap in income equality
between white women and black women had been
closed, yet this important message appears nowhere
in the article text. Other work in multimodal doc-
ument summarization has relied on image captions
and direct references to the graphic in the text (Bha-
tia et al, 2009); however, these textual elements do
Figure 3: From ?The Black Gender Gap? in Newsweek,
Mar 3, 2003.
not necessarily capture the message conveyed by in-
formation graphics in popular media. Thus, the user
may miss out on an essential component of the over-
all communicative goal of the document if the sum-
mary covers only material presented in the text.
One approach to producing a summary of the en-
tire multimodal document might be to ?concatenate?
a traditional extraction-based summary of the text
(Kupiec et al, 1995; Witbrock and Mittal, 1999)
with the description generated for the graphics by
our existing system. The summary of the graphi-
cal content could be simply inserted wherever it is
deemed most relevant in the text summary. How-
ever, such an approach would overlook the relation-
ships and interactions between the text and graphical
content. The information graphics may make certain
concepts mentioned in the text more salient, and vice
versa. Unless we consider the contributions of both
the text and graphics together during the content se-
lection phase, the most important information might
not appear in the summary of the document.
Instead, we must produce a summary that inte-
grates the content conveyed by the text and graphics.
We contend that this integration must occur at the se-
mantic level if it is to take into account the influence
of the graphic?s content on the salience of concepts
in the text and vice versa. Our tack is to first build
a single semantic model of the concepts expressed
in both the article text and information graphics, and
then use this model as the basis for generating an
abstractive summary of the multimodal document.
57
Drawing from a model of the semantic content of the
document, we select as many or as few concepts as
we wish, at any level of detail, to produce summaries
of arbitrary length. This will permit the user to re-
quest a quick overview in order to decide whether to
read the original document, or a more comprehen-
sive synopsis to obtain the most important content
without having to read the entire article.
5.1 Semantic Modeling of Multimodal
Documents
Content gathered from the article text by a seman-
tic parser and from the information graphics by
our graph understanding system is combined into
a single semantic model based on typed, struc-
tured objects organized under a foundational ontol-
ogy (McDonald, 2000a). For the semantic pars-
ing of text, we use Sparser (McDonald, 1992), a
bottom-up, phrase-structure-based chart parser, op-
timized for semantic grammars and partial parsing.3
Using a built-in model of core English grammar
plus domain-specific grammars, Sparser extracts in-
formation from the text and produces categorized
objects as a semantic representation (McDonald,
2000b). The intended message and salient additional
propositions identified by our system for the infor-
mation graphics are decomposed and added to the
model constructed by Sparser.4
Model entries contain slots for attributes in the
concept category?s ontology definition (fillable by
other concepts or symbols), the original phrasings
mentioning this concept in the text (represented as
parameterized synchronous TAG derivation trees),
and markers recording document structure (i.e.,
where in the text [including title, headings, etc.] or
graphic the concept appeared). Figure 4 shows some
of the information contained in a small portion of
the semantic model built for an article entitled ?Will
Medtronic?s Pulse Quicken?? from the May 29,
2006 edition of Businessweek magazine5, which in-
cluded a line graph. Nodes correspond to concepts
3https://github.com/charlieg/Sparser
4Although the framework is general enough to accommo-
date any modality (e.g., images, video) given suitable seman-
tic analysis tools, our prototype implementation focuses on bar
charts and line graphs analyzed by SIGHT.
5http://www.businessweek.com/magazine/
content/06_22/b3986120.htm
and edges denote relationships between concepts;
dashed lines indicate links to concepts not shown in
this figure. Nodes are labelled with the name of the
conceptual category they instantiate, and a number
to distinguish between individuals. The middle of
each box displays the attributes of the concept, while
the bottom portion shows some of the original text
phrasings. Angle brackets (<>) note references to
other concepts, and hash marks (#) indicate a sym-
bol that has not been instantiated as a concept.
P1S1: "medical device
    giant Medtronic"
P1S5: "Medtronic"
Name: "Medtronic"
Stock: "MDT"
Industry: (#pacemakers,
    #defibrillators,
    #medical devices)
Company1
P1S4: "Joanne
    Wuensch"
P1S7: "Wuensch"
FirstName: "Joanne"
LastName: "Wuensch"
Person1
P1S4: "a 12-month
    target of 62"
Person: <Person 1>
Company: <Company 1>
Price: $62.00
Horizon: #12_months
TargetStockPrice1
Figure 4: Detail of model for Businessweek article.
5.2 Rating Content in Semantic Models
The model is then rated to determine which items are
most salient. The concepts conveying the most in-
formation and having the most connections to other
important concepts in the model are the ones that
should be chosen for the summary. The importance
of each concept is rated according to a measure of
information density (ID) involving several factors:6
Saturation Level Completeness of attributes in
model entry: a concept?s filled-in slots (f ) vs. its
total slots (s), and the importance of the concepts
(ci) filling those slots:
f
s ? log(s) ?
?f
i=1 ID(ci)
Connectedness Number of connections (n) with
other concepts (cj), and the importance of these con-
nected concepts:
?n
j=1 ID(cj)
Frequency Number of observed phrasings (e) re-
alizing the concept in text of the current document
Prominence in Text Prominence based on docu-
ment structure (WD) and rhetorical devices (WR)
Graph Salience Salience assessed by the graph
understanding system (WG) ? only applies to con-
cepts appearing in the graphics
6The first three factors are similar to the dominant slot
fillers, connectivity patterns, and frequency criteria described
by Reimer and Hahn (1988).
58
Saturation corresponds to the completeness of the
concept in the model. The more attribute slots that
are filled, the more we know about a particular con-
cept instance. However, this measure is highly sen-
sitive to the degree of detail provided in the seman-
tic grammar and ontology class definition (whether
created by hand or automatically). A concept having
two slots, both of which are filled-out, is not neces-
sarily more important than a concept with only 12
of its 15 slots filled. The more important a concept
category is in a given domain, the more detailed its
ontology class definition will likely be. Thus, we
can assume that a concept definition having a dozen
or more slots is, broadly speaking, more important
in the domain than a less well-defined concept hav-
ing only one or two slots. This insight is the basis of
a normalization factor (log(s)) used in ID.
Saturation differs somewhat from repetition in
that it attempts to measure the amount of informa-
tion associated with a concept, rather than simply
the number of times a concept is mentioned in the
text. For example, a news article about a proposed
law might mention ?Washington? several times, but
the fact that the debate took place in Washington,
D.C. is unlikely to be an important part of the article.
However, the key provisions of the bill, which may
individually be mentioned only once, are likely more
important as a greater amount of detail is provided
concerning them. Simple repetition is not necessar-
ily indicative of the importance of a concept, but if a
large amount of information is provided for a given
concept, it is safe to assume the concept is important
in the context of that document.
Document structure (WD) is another important
clue in determining which elements of a text are
important enough to include in a summary (Marcu,
1997). If a concept is featured prominently in the
title, or appears in the first or final paragraphs, it is
likely more important than a concept buried in the
middle of the document. Importance is also affected
by certain rhetorical devices (WR) which serve to
highlight particular concepts. Being used in an id-
iom, or compared to another concept by means of
juxtaposition suggests that a given concept may hold
special significance. Finally, the weights assigned
by our graph understanding system for the additional
propositions identified in the graphics are incorpo-
rated into the ID of the concepts involved as WG.
5.3 Selecting Content for a Summary
To select concepts for inclusion in the summary,
the model will then be passed to a discourse-aware
graph-based content selection framework (Demir et
al., 2010), which selects concepts one at a time
and iteratively re-weights the remaining items so
as to include related concepts and avoid redun-
dancy. This algorithm incorporates PageRank (Page
et al, 1999), but with several modifications. In ad-
dition to centrality assessment based on relation-
ships between concepts, it includes apriori impor-
tance nodes enabling us to incorporate concept com-
pleteness, number of expressions, document struc-
ture, and rhetorical devices. More importantly from
a summary generation perspective, the algorithm it-
eratively picks concepts one at a time, and re-ranks
the remaining entries by increasing the weight of re-
lated items and discounting redundant ones. This
allows us to select concepts that complement each
other while simultaneously avoiding redundancy.
6 Generating an Abstractive Summary of
a Multimodal Document
Figure 4 shows the two most important concepts
(Company1 & Person1) selected from the Medtronic
article in Section 5.1. Following McDonald and
Greenbacker (2010), we use the phrasings observed
by the parser as the ?raw material? for expressing
these selected concepts. Reusing the original phras-
ings reduces the reliance on built-in or ?canned?
constructions, and allows the summary to reflect the
style of the original text. The derivation trees stored
in the model to realize a particular concept may use
different syntactic constituents (e.g., noun phrases,
verb phrases). Multiple trees are often available for
each concept, and we must select particular trees that
fit together to form a complete sentence.
The semantic model also contains concepts rep-
resenting propositions extracted from the graphics,
as well as relationships connecting these graphical
concepts with those derived from the text, and there
are no existing phrasings in the original document
that can be reused to convey this graphical content.
However, the set of proposition types that can be ex-
tracted from the graphics is finite. To ensure that we
have realizations for every concept in our model, we
create TAG derivation trees for each type of graphi-
59
cal proposition. As long as realizations are supplied
for every proposition that can be decomposed in the
model, our system will never be stuck with a concept
without the means to express it.
The set of expressions is augmented by many
built-in realizations for common semantic relation-
ships (e.g., ?is-a,? ?has-a?), as well as expressions
inherited from other conceptual categories in the hi-
erarchy. If the observed expressions are retained as
the system analyzes multiple documents over time,
making these realizations available for later use by
concepts in the same category, the variety of utter-
ances we can generate is increased greatly.
By using synchronous TAG trees, we know that
the syntactic realizations of two semantically-related
concepts will fit together syntactically (via substitu-
tion or adjunction). However, the concepts selected
for the summary of the Medtronic article (Com-
pany1 & Person1), are not directly connected in the
model. To produce a single summary sentence for
these two concepts, we must find a way of express-
ing them together with the available phrasings. This
can be accomplished by using an intermediary con-
cept that connects both of the selected items in the
semantic model, in order to ?bridge the gap? be-
tween them. In this example, a reasonable option
would be TargetStockPrice1, one of the many con-
cepts linking Company1 and Person1. Combining
original phrasings from all three concepts (via sub-
stitution and adjunction operations on the underly-
ing TAG trees), along with a ?built-in? realization
inherited by the TargetStockPrice category (a sub-
type of Expectation), yields this surface form:
Wuensch expects a 12-month target of 62
for medical device giant Medtronic.
7 Related Work
Research into providing alternative access to graph-
ics has taken both verbal and non-verbal approaches.
Kurze (1995) presented a verbal description of the
properties (e.g., diagram style, number of data sets,
range and labels of axes) of business graphics. Fer-
res et al (2007) produced short descriptions of the
information in graphs using template-driven genera-
tion based on the graph type. The SIGHT project
(Demir et al, 2008; Elzer et al, 2011) generated
summaries of the high-level message content con-
veyed by simple bar charts. Other modalities, like
sound (Meijer, 1992; Alty and Rigas, 1998; Choi
and Walker, 2010) and touch (Ina, 1996; Krufka et
al., 2007), have been used to impart graphics via a
substitute medium. Yu et al (2002) and Abu Doush
et al (2010) combined haptic and aural feedback,
enabling users to navigate and explore a chart.
8 Discussion
This paper presented our system for providing ac-
cess to the full content of multimodal documents
with line graphs in popular media. Such graph-
ics generally have a high-level communicative goal
which should constitute the core of a graphic?s sum-
mary. Rather than providing this summary at the
point where the graphic is first encountered, our sys-
tem identifies the most relevant paragraph in the
article and relays the graphic?s summary at this
point, thus increasing the presentation?s coherence.
System extensions currently in development will
provide a more integrative and accessible way for
visually-impaired readers to experience multimodal
documents. By producing abstractive summaries of
the entire document, we reduce the amount of time
and effort required to assimiliate the information
conveyed by such documents in popular media.
Several tasks remain as future work. The intended
message descriptions generated by our system need
to be evaluated by both sighted and non-sighted hu-
man subjects for clarity and accuracy. We intend
to test our hypothesis that graphics ought to be de-
scribed alongside the most relevant part of the text
by performing an experiment designed to determine
the presentation order preferred by people who are
blind. The rules developed to identify elaborative
propositions also must be validated by a corpus or
user study. Finally, once the system is fully imple-
mented, the abstractive summaries generated for en-
tire multimodal documents will need to be evaluated
by both sighted and sight-impaired judges.
Acknowledgments
This work was supported in part by the by the Na-
tional Institute on Disability and Rehabilitation Re-
search under grant H133G080047 and by the Na-
tional Science Foundation under grant IIS-0534948.
60
References
Iyad Abu Doush, Enrico Pontelli, Tran Cao Son, Dominic
Simon, and Ou Ma. 2010. Multimodal presenta-
tion of two-dimensional charts: An investigation using
Open Office XML and Microsoft Excel. ACM Trans-
actions on Accessible Computing (TACCESS), 3:8:1?
8:50, November.
James L. Alty and Dimitrios I. Rigas. 1998. Communi-
cating graphical information to blind users using mu-
sic: the role of context. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems,
CHI ?98, pages 574?581, Los Angeles, April. ACM.
Sumit Bhatia, Shibamouli Lahiri, and Prasenjit Mitra.
2009. Generating synopses for document-element
search. In Proceeding of the 18th ACM Conference
on Information and Knowledge Management, CIKM
?09, pages 2003?2006, Hong Kong, November. ACM.
Sandra Carberry, Stephanie Elzer, and Seniz Demir.
2006. Information graphics: an untapped resource for
digital libraries. In Proceedings of the 29th Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval, SIGIR ?06,
pages 581?588, Seattle, August. ACM.
Stephen H. Choi and Bruce N. Walker. 2010. Digitizer
auditory graph: making graphs accessible to the visu-
ally impaired. In Proceedings of the 28th International
Conference on Human Factors in Computing Systems,
CHI ?10, pages 3445?3450, Atlanta, April. ACM.
Seniz Demir, Sandra Carberry, and Kathleen F. McCoy.
2008. Generating textual summaries of bar charts.
In Proceedings of the 5th International Natural Lan-
guage Generation Conference, INLG 2008, pages 7?
15, Salt Fork, Ohio, June. ACL.
Seniz Demir, Sandra Carberry, and Kathleen F. Mc-
Coy. 2010. A discourse-aware graph-based content-
selection framework. In Proceedings of the 6th In-
ternational Natural Language Generation Conference,
INLG 2010, pages 17?26, Trim, Ireland, July. ACL.
Michael Elhadad and Jacques Robin. 1996. An overview
of SURGE: a re-usable comprehensive syntactic re-
alization component. In Proceedings of the 8th In-
ternational Natural Language Generation Workshop
(Posters and Demonstrations), Sussex, UK, June.
ACL.
Stephanie Elzer, Sandra Carberry, and Ingrid Zukerman.
2011. The automated understanding of simple bar
charts. Artificial Intelligence, 175:526?555, February.
Leo Ferres, Petro Verkhogliad, Gitte Lindgaard, Louis
Boucher, Antoine Chretien, and Martin Lachance.
2007. Improving accessibility to statistical graphs: the
iGraph-Lite system. In Proceedings of the 9th Inter-
national ACM SIGACCESS Conference on Computers
and Accessibility, ASSETS ?07, pages 67?74, Tempe,
October. ACM.
Charles F. Greenbacker, Sandra Carberry, and Kathleen F.
McCoy. 2011. A corpus of human-written summaries
of line graphs. In Proceedings of the EMNLP 2011
Workshop on Language Generation and Evaluation,
UCNLG+Eval, Edinburgh, July. ACL. (to appear).
Satoshi Ina. 1996. Computer graphics for the blind. SIG-
CAPH Newsletter on Computers and the Physically
Handicapped, pages 16?23, June. Issue 55.
Stephen E. Krufka, Kenneth E. Barner, and Tuncer Can
Aysal. 2007. Visual to tactile conversion of vector
graphics. IEEE Transactions on Neural Systems and
Rehabilitation Engineering, 15(2):310?321, June.
Solomon Kullback. 1968. Information Theory and
Statistics. Dover, revised 2nd edition.
Julian Kupiec, Jan Pedersen, and Francine Chen. 1995.
A trainable document summarizer. In Proceedings
of the 18th Annual International ACM SIGIR Confer-
ence on Research and Development in Information Re-
trieval, SIGIR ?95, pages 68?73, Seattle, July. ACM.
Martin Kurze. 1995. Giving blind people access
to graphics (example: Business graphics). In Pro-
ceedings of the Software-Ergonomie ?95 Workshop
on Nicht-visuelle graphische Benutzungsoberfla?chen
(Non-visual Graphical User Interfaces), Darmstadt,
Germany, February.
Xiaoyong Liu and W. Bruce Croft. 2002. Passage re-
trieval based on language models. In Proceedings of
the eleventh international conference on Information
and knowledge management, CIKM ?02, pages 375?
382.
Daniel C. Marcu. 1997. The Rhetorical Parsing, Summa-
rization, and Generation of Natural Language Texts.
Ph.D. thesis, University of Toronto, December.
David D. McDonald and Charles F. Greenbacker. 2010.
?If you?ve heard it, you can say it? - towards an ac-
count of expressibility. In Proceedings of the 6th In-
ternational Natural Language Generation Conference,
INLG 2010, pages 185?190, Trim, Ireland, July. ACL.
David D. McDonald. 1992. An efficient chart-based
algorithm for partial-parsing of unrestricted texts. In
Proceedings of the 3rd Conference on Applied Natural
Language Processing, pages 193?200, Trento, March.
ACL.
David D. McDonald. 2000a. Issues in the repre-
sentation of real texts: the design of KRISP. In
Lucja M. Iwan?ska and Stuart C. Shapiro, editors, Nat-
ural Language Processing and Knowledge Represen-
tation, pages 77?110. MIT Press, Cambridge, MA.
David D. McDonald. 2000b. Partially saturated refer-
ents as a source of complexity in semantic interpreta-
tion. In Proceedings of the NAACL-ANLP 2000 Work-
shop on Syntactic and Semantic Complexity in Natural
61
Language Processing Systems, pages 51?58, Seattle,
April. ACL.
Peter B.L. Meijer. 1992. An experimental system for
auditory image representations. IEEE Transactions on
Biomedical Engineering, 39(2):112?121, February.
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry
Winograd. 1999. The pagerank citation ranking:
Bringing order to the web. Technical Report 1999-
66, Stanford InfoLab, November. Previous number:
SIDL-WP-1999-0120.
Ulrich Reimer and Udo Hahn. 1988. Text condensation
as knowledge base abstraction. In Proceedings of the
4th Conference on Artificial Intelligence Applications,
CAIA ?88, pages 338?344, San Diego, March. IEEE.
Dominic Widdows. 2003. Orthogonal negation in vector
spaces for modelling word-meanings and document
retrieval. In Proceedings of the 41st Annual Meeting
on Association for Computational Linguistics - Volume
1, ACL ?03, pages 136?143, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Michael J. Witbrock and Vibhu O. Mittal. 1999. Ultra-
summarization: a statistical approach to generating
highly condensed non-extractive summaries. In Pro-
ceedings of the 22nd Annual International ACM SIGIR
Conference on Research and Development in Informa-
tion Retrieval, SIGIR ?99, pages 315?316, Berkeley,
August. ACM.
Wai Yu, Douglas Reid, and Stephen Brewster. 2002.
Web-based multimodal graphs for visually impaired
people. In Proceedings of the 1st Cambridge Work-
shop on Universal Access and Assistive Technology,
CWUAAT ?02, pages 97?108, Cambridge, March.
Chengxiang Zhai. 2008. Statistical Language Models
for Information Retrieval. Morgan and Claypool Pub-
lishers, December.
62
