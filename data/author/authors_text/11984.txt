Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 19?27,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
A Comparative Study on Generalization of Semantic Roles in FrameNet
Yuichiroh Matsubayashi? Naoaki Okazaki? Jun?ichi Tsujii???
?Department of Computer Science, University of Tokyo, Japan
?School of Computer Science, University of Manchester, UK
?National Centre for Text Mining, UK
{y-matsu,okazaki,tsujii}@is.s.u-tokyo.ac.jp
Abstract
A number of studies have presented
machine-learning approaches to semantic
role labeling with availability of corpora
such as FrameNet and PropBank. These
corpora define the semantic roles of predi-
cates for each frame independently. Thus,
it is crucial for the machine-learning ap-
proach to generalize semantic roles across
different frames, and to increase the size
of training instances. This paper ex-
plores several criteria for generalizing se-
mantic roles in FrameNet: role hierar-
chy, human-understandable descriptors of
roles, semantic types of filler phrases, and
mappings from FrameNet roles to the-
matic roles of VerbNet. We also pro-
pose feature functions that naturally com-
bine and weight these criteria, based on
the training data. The experimental result
of the role classification shows 19.16%
and 7.42% improvements in error reduc-
tion rate and macro-averaged F1 score, re-
spectively. We also provide in-depth anal-
yses of the proposed criteria.
1 Introduction
Semantic Role Labeling (SRL) is a task of analyz-
ing predicate-argument structures in texts. More
specifically, SRL identifies predicates and their
arguments with appropriate semantic roles. Re-
solving surface divergence of texts (e.g., voice
of verbs and nominalizations) into unified seman-
tic representations, SRL has attracted much at-
tention from researchers into various NLP appli-
cations including question answering (Narayanan
and Harabagiu, 2004; Shen and Lapata, 2007;
buy.v PropBank FrameNet
Frame buy.01 Commerce buy
Roles ARG0: buyer Buyer
ARG1: thing bought Goods
ARG2: seller Seller
ARG3: paid Money
ARG4: benefactive Recipient
... ...
Figure 1: A comparison of frames for buy.v de-
fined in PropBank and FrameNet
Moschitti et al, 2007), and information extrac-
tion (Surdeanu et al, 2003).
In recent years, with the wide availability of cor-
pora such as PropBank (Palmer et al, 2005) and
FrameNet (Baker et al, 1998), a number of stud-
ies have presented statistical approaches to SRL
(Ma`rquez et al, 2008). Figure 1 shows an exam-
ple of the frame definitions for a verb buy in Prop-
Bank and FrameNet. These corpora define a large
number of frames and define the semantic roles for
each frame independently. This fact is problem-
atic in terms of the performance of the machine-
learning approach, because these definitions pro-
duce many roles that have few training instances.
PropBank defines a frame for each sense of
predicates (e.g., buy.01), and semantic roles are
defined in a frame-specific manner (e.g., buyer and
seller for buy.01). In addition, these roles are asso-
ciated with tags such as ARG0-5 and AM-*, which
are commonly used in different frames. Most
SRL studies on PropBank have used these tags
in order to gather a sufficient amount of training
data, and to generalize semantic-role classifiers
across different frames. However, Yi et al (2007)
reported that tags ARG2?ARG5 were inconsis-
tent and not that suitable as training instances.
Some recent studies have addressed alternative ap-
proaches to generalizing semantic roles across dif-
ferent frames (Gordon and Swanson, 2007; Zapi-
19
Transfer::RecipientGiving::Recipient Commerce_buy::BuyerCommerce_sell::Buyer Commerce_buy::SellerCommerce_sell::SellerGiving::Donor
Transfer::Donor
Buyer SellerAgent role-to-role relationhierarchical classthematic rolerole descriptor
Recipient Donor
Figure 2: An example of role groupings using different criteria.
rain et al, 2008).
FrameNet designs semantic roles as frame spe-
cific, but also defines hierarchical relations of se-
mantic roles among frames. Figure 2 illustrates
an excerpt of the role hierarchy in FrameNet; this
figure indicates that the Buyer role for the Com-
merce buy frame (Commerce buy::Buyer here-
after) and the Commerce sell::Buyer role are in-
herited from the Transfer::Recipient role. Al-
though the role hierarchy was expected to gener-
alize semantic roles, no positive results for role
classification have been reported (Baldewein et al,
2004). Therefore, the generalization of semantic
roles across different frames has been brought up
as a critical issue for FrameNet (Gildea and Juraf-
sky, 2002; Shi and Mihalcea, 2005; Giuglea and
Moschitti, 2006)
In this paper, we explore several criteria for gen-
eralizing semantic roles in FrameNet. In addi-
tion to the FrameNet hierarchy, we use various
pieces of information: human-understandable de-
scriptors of roles, semantic types of filler phrases,
and mappings from FrameNet roles to the thematic
roles of VerbNet. We also propose feature func-
tions that naturally combines these criteria in a
machine-learning framework. Using the proposed
method, the experimental result of the role classi-
fication shows 19.16% and 7.42% improvements
in error reduction rate and macro-averaged F1, re-
spectively. We provide in-depth analyses with re-
spect to these criteria, and state our conclusions.
2 Related Work
Moschitti et al (2005) first classified roles by us-
ing four coarse-grained classes (Core Roles, Ad-
juncts, Continuation Arguments and Co-referring
Arguments), and built a classifier for each coarse-
grained class to tag PropBank ARG tags. Even
though the initial classifiers could perform rough
estimations of semantic roles, this step was not
able to solve the ambiguity problem in PropBank
ARG2-5. When training a classifier for a seman-
tic role, Baldewein et al (2004) re-used the train-
ing instances of other roles that were similar to the
target role. As similarity measures, they used the
FrameNet hierarchy, peripheral roles of FrameNet,
and clusters constructed by a EM-based method.
Gordon and Swanson (2007) proposed a general-
ization method for the PropBank roles based on
syntactic similarity in frames.
Many previous studies assumed that thematic
roles bridged semantic roles in different frames.
Gildea and Jurafsky (2002) showed that classifica-
tion accuracy was improved by manually replac-
ing FrameNet roles into 18 thematic roles. Shi
and Mihalcea (2005) and Giuglea and Moschitti
(2006) employed VerbNet thematic roles as the
target of mappings from the roles defined by the
different semantic corpora. Using the thematic
roles as alternatives of ARG tags, Loper et al
(2007) and Yi et al (2007) demonstrated that the
classification accuracy of PropBank roles was im-
proved for ARG2 roles, but that it was diminished
for ARG1. Yi et al (2007) also described that
ARG2?5 were mapped to a variety of thematic
roles. Zapirain et al (2008) evaluated PropBank
ARG tags and VerbNet thematic roles in a state-of-
the-art SRL system, and concluded that PropBank
ARG tags achieved a more robust generalization of
the roles than did VerbNet thematic roles.
3 Role Classification
SRL is a complex task wherein several problems
are intertwined: frame-evoking word identifica-
tion, frame disambiguation (selecting a correct
frame from candidates for the evoking word), role-
phrase identification (identifying phrases that fill
semantic roles), and role classification (assigning
correct roles to the phrases). In this paper, we fo-
cus on role classification, in which the role gen-
eralization is particularly critical to the machine
learning approach.
In the role classification task, we are given a
sentence, a frame evoking word, a frame, and
20
member roles 
Commerce_pay::Buyer
Intentionall_act::Agent
Giving::Donor
Getting::Recipient
Giving::Recipient
Sending::Recipient
Giving::Time
Placing::Time
Event::Time
Commerce_pay::Buyer
Commerce_buy::Buyer
Commerce_sell::Buyer
Buyer
Recipient Time
C_pay::Buyer
GIVING::Donor
Intentionally_ACT::Agent
Avoiding::Agent
Evading::Evader
Evading::Evader
Avoiding::Agent
Getting::Recipient
Evading::Evader
St::Sentient St::Physical_Obj
Giving::Theme
Placing::Theme
St::State_of_affairs
Giving::Reason   Evading::Reason
Giving::Means    Evading::Purpose
Theme::Agent
Theme::Theme
Commerce_buy::Goods
Getting::Theme
Evading:: Pursuer
Commerce_buy::Buyer
Commerce_sell::Seller
Evading::Evader
Role-descriptor groupsHierarchical-relation groups Semantic-type groupsThematic-role groups
Group name
legend
Figure 4: Examples for each type of role group.
INPUT:frame = Commerce_sell
candidate   roles ={Seller, Buyer, Goods, Reason, Time, ... , Place}
sentence = Can't [you] [sell Commerce_sell] [the factory] [to some other company]? 
OUTPUT:  
sentence = Can't [you Seller] [sell Commerce_sell] [the factory Goods][to some other company Buyer] ?
Figure 3: An example of input and output of role
classification.
phrases that take semantic roles. We are inter-
ested in choosing the correct role from the can-
didate roles for each phrase in the frame. Figure 3
shows a concrete example of input and output; the
semantic roles for the phrases are chosen from the
candidate roles: Seller, Buyer, Goods, Reason,
... , and Place.
4 Design of Role Groups
We formalize the generalization of semantic roles
as the act of grouping several roles into a
class. We define a role group as a set of
role labels grouped by a criterion. Figure 4
shows examples of role groups; a group Giv-
ing::Donor (in the hierarchical-relation groups)
contains the roles Giving::Donor and Com-
merce pay::Buyer. The remainder of this section
describes the grouping criteria in detail.
4.1 Hierarchical relations among roles
FrameNet defines hierarchical relations among
frames (frame-to-frame relations). Each relation
is assigned one of the seven types of directional
relationships (Inheritance, Using, Perspective on,
Causative of, Inchoative of, Subframe, and Pre-
cedes). Some roles in two related frames are also
connected with role-to-role relations. We assume
that this hierarchy is a promising resource for gen-
eralizing the semantic roles; the idea is that the
role at a node in the hierarchy inherits the char-
acteristics of the roles of its ancestor nodes. For
example, Commerce sell::Seller in Figure 2 in-
herits the property of Giving::Donor.
For Inheritance, Using, Perspective on, and
Subframe relations, we assume that descendant
roles in these relations have the same or special-
ized properties of their ancestors. Hence, for each
role yi, we define the following two role groups,
Hchildyi = {y|y = yi ? y is a child of yi},
Hdescyi = {y|y = yi ? y is a descendant of yi}.
The hierarchical-relation groups in Figure 4 are
the illustrations of Hdescyi .
For the relation types Inchoative of and
Causative of, we define role groups in the oppo-
site direction of the hierarchy,
Hparentyi = {y|y = yi ? y is a parent of yi},
Hanceyi = {y|y = yi ? y is an ancestor of yi}.
This is because lower roles of Inchoative of
and Causative of relations represent more neu-
tral stances or consequential states; for example,
Killing::Victim is a parent of Death::Protagonist
in the Causative of relation.
Finally, the Precedes relation describes the se-
quence of states and events, but does not spec-
ify the direction of semantic inclusion relations.
Therefore, we simply try Hchildyi , H
desc
yi , H
parent
yi ,
and Hanceyi for this relation type.
4.2 Human-understandable role descriptor
FrameNet defines each role as frame-specific; in
other words, the same identifier does not appear
in different frames. However, in FrameNet,
human experts assign a human-understandable
name to each role in a rather systematic man-
ner. Some names are shared by the roles in
different frames, whose identifiers are dif-
ferent. Therefore, we examine the semantic
21
commonality of these names; we construct an
equivalence class of the roles sharing the same
name. We call these human-understandable
names role descriptors. In Figure 4, the role-
descriptor group Buyer collects the roles Com-
merce pay::Buyer, Commerce buy::Buyer,
and Commerce sell::Buyer.
This criterion may be effective in collecting
similar roles since the descriptors have been anno-
tated by intuition of human experts. As illustrated
in Figure 2, the role descriptors group the seman-
tic roles which are similar to the roles that the
FrameNet hierarchy connects as sister or parent-
child relations. However, role-descriptor groups
cannot express the relations between the roles
as inclusions since they are equivalence classes.
For example, the roles Commerce sell::Buyer
and Commerce buy::Buyer are included in the
role descriptor group Buyer in Figure 2; how-
ever, it is difficult to merge Giving::Recipient
and Commerce sell::Buyer because the Com-
merce sell::Buyer has the extra property that one
gives something of value in exchange and a hu-
man assigns different descriptors to them. We ex-
pect that the most effective weighting of these two
criteria will be determined from the training data.
4.3 Semantic type of phrases
We consider that the selectional restriction is help-
ful in detecting the semantic roles. FrameNet pro-
vides information concerning the semantic types
of role phrases (fillers); phrases that play spe-
cific roles in a sentence should fulfill the se-
mantic constraint from this information. For
instance, FrameNet specifies the constraint that
Self motion::Area should be filled by phrases
whose semantic type is Location. Since these
types suggest a coarse-grained categorization of
semantic roles, we construct role groups that con-
tain roles whose semantic types are identical.
4.4 Thematic roles of VerbNet
VerbNet thematic roles are 23 frame-independent
semantic categories for arguments of verbs,
such as Agent, Patient, Theme and Source.
These categories have been used as consis-
tent labels across verbs. We use a partial
mapping between FrameNet roles and Verb-
Net thematic roles provided by SemLink. 1
Each group is constructed as a set Tti =
1http://verbs.colorado.edu/semlink/
{y|SemLink maps y into the thematic role ti}.
SemLink currently maps 1,726 FrameNet roles
into VerbNet thematic roles, which are 37.61% of
roles appearing at least once in the FrameNet cor-
pus. This may diminish the effect of thematic-role
groups than its potential.
5 Role classification method
5.1 Traditional approach
We are given a frame-evoking word e, a frame f
and a role phrase x detected by a human or some
automatic process in a sentence s. Let Yf be the
set of semantic roles that FrameNet defines as be-
ing possible role assignments for the frame f , and
let x = {x1, . . . , xn} be observed features for x
from s, e and f . The task of semantic role classifi-
cation can be formalized as the problem of choos-
ing the most suitable role y? from Yf . Suppose we
have a model P (y|f,x) which yields the condi-
tional probability of the semantic role y for given
f and x. Then we can choose y? as follows:
y? = argmax
y?Yf
P (y|f,x). (1)
A traditional way to incorporate role groups
into this formalization is to overwrite each role
y in the training and test data with its role
group m(y) according to the memberships of
the group. For example, semantic roles Com-
merce sell::Seller and Giving::Donor can be re-
placed by their thematic-role group Theme::Agent
in this approach. We determine the most suitable
role group c? as follows:
c? = argmax
c?{m(y)|y?Yf}
Pm(c|f,x). (2)
Here, Pm(c|f,x) presents the probability of the
role group c for f and x. The role y? is determined
uniquely iff a single role y ? Yf is associated
with c?. Some previous studies have employed this
idea to remedy the data sparseness problem in the
training data (Gildea and Jurafsky, 2002). How-
ever, we cannot apply this approach when multi-
ple roles in Yf are contained in the same class. For
example, we can construct a semantic-type group
St::State of affairs in which Giving::Reason and
Giving::Means are included, as illustrated in Fig-
ure 4. If c? = St::State of affairs, we cannot dis-
ambiguate which original role is correct. In ad-
dition, it may be more effective to use various
22
groupings of roles together in the model. For in-
stance, the model could predict the correct role
Commerce sell::Seller for the phrase ?you? in
Figure 3 more confidently, if it could infer its
thematic-role group as Theme::Agent and its par-
ent group Giving::Donor correctly. Although the
ensemble of various groupings seems promising,
we need an additional procedure to prioritize the
groupings for the case where the models for mul-
tiple role groupings disagree; for example, it is un-
satisfactory if two models assign the groups Giv-
ing::Theme and Theme::Agent to the same phrase.
5.2 Role groups as feature functions
We thus propose another approach that incorpo-
rates group information as feature functions. We
model the conditional probability P (y|f,x) by us-
ing the maximum entropy framework,
p(y|f,x) = exp(
?
i ?igi(x, y))
?
y?Yf exp(
?
i ?igi(x, y))
. (3)
Here, G = {gi} denotes a set of n feature func-
tions, and ? = {?i} denotes a weight vector for
the feature functions.
In general, feature functions for the maximum
entropy model are designed as indicator functions
for possible pairs of xj and y. For example, the
event where the head word of x is ?you? (x1 = 1)
and x plays the role Commerce sell::Seller in a
sentence is expressed by the indicator function,
grole1 (x, y) =
?
?
?
?
?
1 (x1 = 1 ?
y = Commerce sell::Seller)
0 (otherwise)
.
(4)
We call this kind of feature function an x-role.
In order to incorporate role groups into the
model, we also include all feature functions for
possible pairs of xj and role groups. Equation 5
is an example of a feature function for instances
where the head word of x is ?you? and y is in the
role group Theme::Agent,
gtheme2 (x, y) =
?
?
?
?
?
1 (x1 = 1 ?
y ? Theme::Agent)
0 (otherwise)
. (5)
Thus, this feature function fires for the roles wher-
ever the head word ?you? plays Agent (e.g., Com-
merce sell::Seller, Commerce buy::Buyer and
Giving::Donor). We call this kind of feature func-
tion an x-group function.
In this way, we obtain x-group functions for
all grouping methods, e.g., gthemek , g
hierarchy
k .
The role-group features will receive more training
instances by collecting instances for fine-grained
roles. Thus, semantic roles with few training in-
stances are expected to receive additional clues
from other training instances via role-group fea-
tures. Another advantage of this approach is that
the usefulness of the different role groups is de-
termined by the training processes in terms of
weights of feature functions. Thus, we do not need
to assume that we have found the best criterion for
grouping roles; we can allow a training process to
choose the criterion. We will discuss the contribu-
tions of different groupings in the experiments.
5.3 Comparison with related work
Baldewein et al (2004) suggested an approach
that uses role descriptors and hierarchical rela-
tions as criteria for generalizing semantic roles
in FrameNet. They created a classifier for each
frame, additionally using training instances for the
role A to train the classifier for the role B, if the
roles A and B were judged as similar by a crite-
rion. This approach performs similarly to the over-
writing approach, and it may obscure the differ-
ences among roles. Therefore, they only re-used
the descriptors as a similarity measure for the roles
whose coreness was peripheral. 2
In contrast, we use all kinds of role descriptors
to construct groups. Since we use the feature func-
tions for both the original roles and their groups,
appropriate units for classification are determined
automatically in the training process.
6 Experiment and Discussion
We used the training set of the Semeval-2007
Shared task (Baker et al, 2007) in order to ascer-
tain the contributions of role groups. This dataset
consists of the corpus of FrameNet release 1.3
(containing roughly 150,000 annotations), and an
additional full-text annotation dataset. We ran-
domly extracted 10% of the dataset for testing, and
used the remainder (90%) for training.
Performance was measured by micro- and
macro-averaged F1 (Chang and Zheng, 2008) with
respect to a variety of roles. The micro average bi-
ases each F1 score by the frequencies of the roles,
2In FrameNet, each role is assigned one of four different
types of coreness (core, core-unexpressed, peripheral, extra-
thematic) It represents the conceptual necessity of the roles
in the frame to which it belongs.
23
and the average is equal to the classification accu-
racy when we calculate it with all of the roles in
the test set. In contrast, the macro average does
not bias the scores, thus the roles having a small
number of instances affect the average more than
the micro average.
6.1 Experimental settings
We constructed a baseline classifier that uses
only the x-role features. The feature de-
sign is similar to that of the previous stud-
ies (Ma`rquez et al, 2008). The characteristics
of x are: frame, frame evoking word, head
word, content word (Surdeanu et al, 2003),
first/last word, head word of left/right sister,
phrase type, position, voice, syntactic path (di-
rected/undirected/partial), governing category
(Gildea and Jurafsky, 2002), WordNet super-
sense in the phrase, combination features of
frame evoking word & headword, combination
features of frame evoking word & phrase type,
and combination features of voice & phrase type.
We also used PoS tags and stem forms as extra
features of any word-features.
We employed Charniak and Johnson?s rerank-
ing parser (Charniak and Johnson, 2005) to an-
alyze syntactic trees. As an alternative for the
traditional named-entity features, we used Word-
Net supersenses: 41 coarse-grained semantic cate-
gories of words such as person, plant, state, event,
time, location. We used Ciaramita and Altun?s Su-
per Sense Tagger (Ciaramita and Altun, 2006) to
tag the supersenses. The baseline system achieved
89.00% with respect to the micro-averaged F1.
The x-group features were instantiated similarly
to the x-role features; the x-group features com-
bined the characteristics of x with the role groups
presented in this paper. The total number of fea-
tures generated for all x-roles and x-groups was
74,873,602. The optimal weights ? of the fea-
tures were obtained by the maximum a poste-
rior (MAP) estimation. We maximized an L2-
regularized log-likelihood of the training set us-
ing the Limited-memory BFGS (L-BFGS) method
(Nocedal, 1980).
6.2 Effect of role groups
Table 1 shows the micro and macro averages of F1
scores. Each role group type improved the micro
average by 0.5 to 1.7 points. The best result was
obtained by using all types of groups together. The
result indicates that different kinds of group com-
Feature Micro Macro ?Err.
Baseline 89.00 68.50 0.00
role descriptor 90.78 76.58 16.17
role descriptor (replace) 90.23 76.19 11.23
hierarchical relation 90.25 72.41 11.40
semantic type 90.36 74.51 12.38
VN thematic role 89.50 69.21 4.52
All 91.10 75.92 19.16
Table 1: The accuracy and error reduction rate of
role classification for each type of role group.
Feature #instances Pre. Rec. Micro
baseline ? 10 63.89 38.00 47.66
? 20 69.01 51.26 58.83
? 50 75.84 65.85 70.50
+ all groups ? 10 72.57 55.85 63.12
? 20 76.30 65.41 70.43
? 50 80.86 74.59 77.60
Table 2: The effect of role groups on the roles with
few instances.
plement each other with respect to semantic role
generalization. Baldewein et al (2004) reported
that hierarchical relations did not perform well for
their method and experimental setting; however,
we found that significant improvements could also
be achieved with hierarchical relations. We also
tried a traditional label-replacing approach with
role descriptors (in the third row of Table 1). The
comparison between the second and third rows in-
dicates that mixing the original fine-grained roles
and the role groups does result in a more accurate
classification.
By using all types of groups together, the
model reduced 19.16 % of the classification errors
from the baseline. Moreover, the macro-averaged
F1 scores clearly showed improvements resulting
from using role groups. In order to determine
the reason for the improvements, we measured
the precision, recall, and F1-scores with respect
to roles for which the number of training instances
was at most 10, 20, and 50. In Table 2, we show
that the micro-averaged F1 score for roles hav-
ing 10 instances or less was improved (by 15.46
points) when all role groups were used. This result
suggests the reason for the effect of role groups; by
bridging similar semantic roles, they supply roles
having a small number of instances with the infor-
mation from other roles.
6.3 Analyses of role descriptors
In Table 1, the largest improvement was obtained
by the use of role descriptors. We analyze the ef-
fect of role descriptors in detail in Tables 3 and 4.
Table 3 shows the micro-averaged F1 scores of all
24
Coreness #roles #instances/#role #groups #instances/#group #roles/#group
Core 1902 122.06 655 354.4 2.9
Peripheral 1924 25.24 250 194.3 7.7
Extra-thematic 763 13.90 171 62.02 4.5
Table 4: The analysis of the numbers of roles, instances, and role-descriptor groups, for each type of
coreness.
Coreness Micro
Baseline 89.00
Core 89.51
Peripheral 90.12
Extra-thematic 89.09
All 90.77
Table 3: The effect of employing role-descriptor
groups of each type of coreness.
semantic roles when we use role-descriptor groups
constructed from each type of coreness (core3, pe-
ripheral, and extra-thematic) individually. The pe-
ripheral type generated the largest improvements.
Table 4 shows the number of roles associated
with each type of coreness (#roles), the number of
instances for the original roles (#instances/#role),
the number of groups for each type of coreness
(#groups), the number of instances for each group
(#instances/#group), and the number of roles per
each group (#roles/#group). In the peripheral
type, the role descriptors subdivided 1,924 distinct
roles into 250 groups, each of which contained 7.7
roles on average. The peripheral type included
semantic roles such as place, time, reason, dura-
tion. These semantic roles appear in many frames,
because they have general meanings that can be
shared by different frames. Moreover, the seman-
tic roles of peripheral type originally occurred in
only a small number (25.24) of training instances
on average. Thus, we infer that the peripheral
type generated the largest improvement because
semantic roles in this type acquired the greatest
benefit from the generalization.
6.4 Hierarchical relations and relation types
We analyzed the contributions of the FrameNet hi-
erarchy for each type of role-to-role relations and
for different depths of grouping. Table 5 shows
the micro-averaged F1 scores obtained from var-
ious relation types and depths. The Inheritance
and Using relations resulted in a slightly better ac-
curacy than the other types. We did not observe
any real differences among the remaining five re-
lation types, possibly because there were few se-
3We include Core-unexpressed in core, because it has a
property of core inside one frame.
No. Relation Type Micro
- baseline 89.00
1 + Inheritance (children) 89.52
2 + Inheritance (descendants) 89.70
3 + Using (children) 89.35
4 + Using (descendants) 89.37
5 + Perspective on (children) 89.01
6 + Perspective on (descendants) 89.01
7 + Subframe (children) 89.04
8 + Subframe (descendants) 89.05
9 + Causative of (parents) 89.03
10 + Causative of (ancestors) 89.03
11 + Inchoative of (parents) 89.02
12 + Inchoative of (ancestors) 89.02
13 + Precedes (children) 89.01
14 + Precedes (descendants) 89.03
15 + Precedes (parents) 89.00
16 + Precedes (ancestors) 89.00
18 + all relations (2,4,6,8,10,12,14) 90.25
Table 5: Comparison of the accuracy with differ-
ent types of hierarchical relations.
mantic roles associated with these types. We ob-
tained better results by using not only groups for
parent roles, but also groups for all ancestors. The
best result was obtained by using all relations in
the hierarchy.
6.5 Analyses of different grouping criteria
Table 6 reports the precision, recall, and micro-
averaged F1 scores of semantic roles with respect
to each coreness type.4 In general, semantic roles
of the core coreness were easily identified by all
of the grouping criteria; even the baseline system
obtained an F1 score of 91.93. For identifying se-
mantic roles of the peripheral and extra-thematic
types of coreness, the simplest solution, the de-
scriptor criterion, outperformed other criteria.
In Table 7, we categorize feature functions
whose weights are in the top 1000 in terms of
greatest absolute value. The behaviors of the role
groups can be distinguished by the following two
characteristics. Groups of role descriptors and se-
mantic types have large weight values for the first
word and supersense features, which capture the
characteristics of adjunctive phrases. The original
roles and hierarchical-relation groups have strong
4The figures of role descriptors in Tables 4 and 6 differ.
In Table 4, we measured the performance when we used one
or all types of coreness for training. In contrast, in Table 6,
we used all types of coreness for training, but computed the
performance of semantic roles for each coreness separately.
25
Feature Type Pre. Rec. Micro
baseline c 91.07 92.83 91.93
p 81.05 76.03 78.46
e 78.17 66.51 71.87
+ descriptor group c 92.50 93.41 92.95
p 84.32 82.72 83.51
e 80.91 69.59 74.82
+ hierarchical c 92.10 93.28 92.68
relation p 82.23 79.84 81.01
class e 77.94 65.58 71.23
+ semantic c 92.23 93.31 92.77
type group p 83.66 81.76 82.70
e 80.29 67.26 73.20
+ VN thematic c 91.57 93.06 92.31
role group p 80.66 76.95 78.76
e 78.12 66.60 71.90
+ all group c 92.66 93.61 93.13
p 84.13 82.51 83.31
e 80.77 68.56 74.17
Table 6: The precision and recall of each type of
coreness with role groups. Type represents the
type of coreness; c denotes core, p denotes periph-
eral, and e denotes extra-thematic.
associations with lexical and structural character-
istics such as the syntactic path, content word, and
head word. Table 7 suggests that role-descriptor
groups and semantic-type groups are effective for
peripheral or adjunctive roles, and hierarchical re-
lation groups are effective for core roles.
7 Conclusion
We have described different criteria for general-
izing semantic roles in FrameNet. They were:
role hierarchy, human-understandable descriptors
of roles, semantic types of filler phrases, and
mappings from FrameNet roles to thematic roles
of VerbNet. We also proposed a feature design
that combines and weights these criteria using the
training data. The experimental result of the role
classification task showed a 19.16% of the error
reduction and a 7.42% improvement in the macro-
averaged F1 score. In particular, the method we
have presented was able to classify roles having
few instances. We confirmed that modeling the
role generalization at feature level was better than
the conventional approach that replaces semantic
role labels.
Each criterion presented in this paper improved
the accuracy of classification. The most success-
ful criterion was the use of human-understandable
role descriptors. Unfortunately, the FrameNet hi-
erarchy did not outperform the role descriptors,
contrary to our expectations. A future direction
of this study would be to analyze the weakness of
the FrameNet hierarchy in order to discuss possi-
ble improvement of the usage and annotations of
features of x class type
or hr rl st vn
frame 0 4 0 1 0
evoking word 3 4 7 3 0
ew & hw stem 9 34 20 8 0
ew & phrase type 11 7 11 3 1
head word 13 19 8 3 1
hw stem 11 17 8 8 1
content word 7 19 12 3 0
cw stem 11 26 13 5 0
cw PoS 4 5 14 15 2
directed path 19 27 24 6 7
undirected path 21 35 17 2 6
partial path 15 18 16 13 5
last word 15 18 12 3 2
first word 11 23 53 26 10
supersense 7 7 35 25 4
position 4 6 30 9 5
others 27 29 33 19 6
total 188 298 313 152 50
Table 7: The analysis of the top 1000 feature func-
tions. Each number denotes the number of feature
functions categorized in the corresponding cell.
Notations for the columns are as follows. ?or?:
original role, ?hr?: hierarchical relation, ?rd?: role
descriptor, ?st?: semantic type, and ?vn?: VerbNet
thematic role.
the hierarchy.
Since we used the latest release of FrameNet
in order to use a greater number of hierarchical
role-to-role relations, we could not make a direct
comparison of performance with that of existing
systems; however we may say that the 89.00% F1
micro-average of our baseline system is roughly
comparable to the 88.93% value of Bejan and
Hathaway (2007) for SemEval-2007 (Baker et al,
2007). 5 In addition, the methodology presented in
this paper applies generally to any SRL resources;
we are planning to determine several grouping cri-
teria from existing linguistic resources and to ap-
ply the methodology to the PropBank corpus.
Acknowledgments
The authors thank Sebastian Riedel for his useful
comments on our work. This work was partially
supported by Grant-in-Aid for Specially Promoted
Research (MEXT, Japan).
References
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceed-
ings of Coling-ACL 1998, pages 86?90.
Collin Baker, Michael Ellsworth, and Katrin Erk.
2007. Semeval-2007 task 19: Frame semantic struc-
5There were two participants that performed whole SRL
in SemEval-2007. Bejan and Hathaway (2007) evaluated role
classification accuracy separately for the training data.
26
ture extraction. In Proceedings of SemEval-2007,
pages 99?104.
Ulrike Baldewein, Katrin Erk, Sebastian Pado?, and
Detlef Prescher. 2004. Semantic role labeling
with similarity based generalization using EM-based
clustering. In Proceedings of Senseval-3, pages 64?
68.
Cosmin Adrian Bejan and Chris Hathaway. 2007.
UTD-SRL: A Pipeline Architecture for Extract-
ing Frame Semantic Structures. In Proceedings
of SemEval-2007, pages 460?463. Association for
Computational Linguistics.
X. Chang and Q. Zheng. 2008. Knowledge Ele-
ment Extraction for Knowledge-Based Learning Re-
sources Organization. Lecture Notes in Computer
Science, 4823:102?113.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEnt discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
pages 173?180.
Massimiliano Ciaramita and Yasemin Altun. 2006.
Broad-coverage sense disambiguation and informa-
tion extraction with a supersense sequence tagger. In
Proceedings of EMNLP-2006, pages 594?602.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245?288.
Ana-Maria Giuglea and Alessandro Moschitti. 2006.
Semantic role labeling via FrameNet, VerbNet and
PropBank. In Proceedings of the 21st International
Conference on Computational Linguistics and the
44th Annual Meeting of the ACL, pages 929?936.
Andrew Gordon and Reid Swanson. 2007. General-
izing semantic role annotations across syntactically
similar verbs. In Proceedings of ACL-2007, pages
192?199.
Edward Loper, Szu-ting Yi, and Martha Palmer. 2007.
Combining lexical resources: Mapping between
propbank and verbnet. In Proceedings of the 7th In-
ternational Workshop on Computational Semantics,
pages 118?128.
Llu??s Ma`rquez, Xavier Carreras, Kenneth C.
Litkowski, and Suzanne Stevenson. 2008. Se-
mantic role labeling: an introduction to the special
issue. Computational linguistics, 34(2):145?159.
Alessandro Moschitti, Ana-Maria Giuglea, Bonaven-
tura Coppola, and Roberto Basili. 2005. Hierar-
chical semantic role labeling. In Proceedings of
CoNLL-2005, pages 201?204.
Alessandro Moschitti, Silvia Quarteroni, Roberto
Basili, and Suresh Manandhar. 2007. Exploiting
syntactic and shallow semantic kernels for question
answer classification. In Proceedings of ACL-07,
pages 776?783.
Srini Narayanan and Sanda Harabagiu. 2004. Ques-
tion answering based on semantic structures. In Pro-
ceedings of Coling-2004, pages 693?701.
Jorge Nocedal. 1980. Updating quasi-newton matrices
with limited storage. Mathematics of Computation,
35(151):773?782.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71?106.
Dan Shen and Mirella Lapata. 2007. Using semantic
roles to improve question answering. In Proceed-
ings of EMNLP-CoNLL 2007, pages 12?21.
Lei Shi and Rada Mihalcea. 2005. Putting Pieces To-
gether: Combining FrameNet, VerbNet and Word-
Net for Robust Semantic Parsing. In Proceedings of
CICLing-2005, pages 100?111.
Mihai Surdeanu, Sanda Harabagiu, John Williams, and
Paul Aarseth. 2003. Using predicate-argument
structures for information extraction. In Proceed-
ings of ACL-2003, pages 8?15.
Szu-ting Yi, Edward Loper, and Martha Palmer. 2007.
Can semantic roles generalize across genres? In
Proceedings of HLT-NAACL 2007, pages 548?555.
Ben?at Zapirain, Eneko Agirre, and Llu??s Ma`rquez.
2008. Robustness and generalization of role sets:
PropBank vs. VerbNet. In Proceedings of ACL-08:
HLT, pages 550?558.
27
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 686?695,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Framework of Semantic Role Assignment based on Extended Lexical
Conceptual Structure: Comparison with VerbNet and FrameNet
Yuichiroh Matsubayashi? Yusuke Miyao? Akiko Aizawa?
?, National Institute of Informatics, Japan
{y-matsu,yusuke,aizawa}@nii.ac.jp
Abstract
Widely accepted resources for semantic
parsing, such as PropBank and FrameNet,
are not perfect as a semantic role label-
ing framework. Their semantic roles are
not strictly defined; therefore, their mean-
ings and semantic characteristics are un-
clear. In addition, it is presupposed that
a single semantic role is assigned to each
syntactic argument. This is not necessarily
true when we consider internal structures of
verb semantics. We propose a new frame-
work for semantic role annotation which
solves these problems by extending the the-
ory of lexical conceptual structure (LCS).
By comparing our framework with that of
existing resources, including VerbNet and
FrameNet, we demonstrate that our ex-
tended LCS framework can give a formal
definition of semantic role labels, and that
multiple roles of arguments can be repre-
sented strictly and naturally.
1 Introduction
Recent developments of large semantic resources
have accelerated empirical research on seman-
tic processing (Ma`rquez et al 2008). Specif-
ically, corpora with semantic role annotations,
such as PropBank (Kingsbury and Palmer, 2002)
and FrameNet (Ruppenhofer et al 2006), are in-
dispensable resources for semantic role labeling.
However, there are two topics we have to carefully
take into consideration regarding role assignment
frameworks: (1) clarity of semantic role meanings
and (2) the constraint that a single semantic role
is assigned to each syntactic argument.
While these resources are undoubtedly invalu-
able for empirical research on semantic process-
Sentence [John] threw [a ball] [from the window] .
Affection Agent Patient
Movement Source Theme Source/Path
PropBank Arg0 Arg1 Arg2
VerbNet Agent Theme Source
FrameNet Agent Theme Source
Table 1: Examples of single role assignments with ex-
isting resources.
ing, current usage of semantic labels for SRL sys-
tems is questionable from a theoretical viewpoint.
For example, most of the works on SRL have
used PropBank?s numerical role labels (Arg0 to
Arg5). However, the meanings of these numbers
depend on each verb in principle and PropBank
does not expect semantic consistency, namely on
Arg2 to Arg5. Moreover, Yi et al(2007) explic-
itly showed that Arg2 to Arg5 are semantically
inconsistent. The reason why such labels have
been used in SRL systems is that verb-specific
roles generally have a small number of instances
and are not suitable for learning. However, it is
necessary to avoid using inconsistent labels since
those labels confuse machine learners and can be
a cause of low accuracy in automatic process-
ing. In addition, clarity of the definition of roles
are particularly important for users to rationally
know how to use each role in their applications.
For this reasons, well-organized and generalized
labels grounded in linguistic characteristics are
needed in practice. Semantic roles of FrameNet
and VerbNet (Kipper et al 2000) are used more
consistently to some extent, but the definition of
the roles is not given in a formal manner and their
semantic characteristics are unclear.
Another somewhat related problem of existing
annotation frameworks is that it is presupposed
686
that a single semantic role is assigned to each syn-
tactic argument.1In fact, one syntactic argument
can play multiple roles in the event (or events) ex-
pressed by a verb. For example, Table 1 shows a
sentence containing the verb ?throw? and seman-
tic roles assigned to its arguments in each frame-
work. The table shows that each framework as-
signs a single role, such as Arg0 and Agent, to
each syntactic argument. However, we can ac-
quire information from this sentence that John
is an agent of the throwing event (the ?Affec-
tion? row), as well as a source of the movement
event of the ball (the ?Movement? row). Existing
frameworks of assigning single roles simply ig-
nore such information that verbs inherently have
in their semantics. We believe that giving a clear
definition of multiple argument roles would be
beneficial not only as a theoretical framework but
also for practical applications that require detailed
meanings derived from secondary roles.
This issue is also related to fragmentation and
the unclear definition of semantic roles in these
frameworks. As we exemplify in this paper, mul-
tiple semantic characteristics are conflated in a
single role label in these resources due to the man-
ner of single-role assignment. This means that se-
mantic roles of existing resources are not mono-
lithic and inherently not mutually independent,
but they share some semantic characteristics.
The aim of this paper is more on theoreti-
cal discussion for role-labeling frameworks rather
than introducing a new resource. We developed
a framework of verb lexical semantics, which is
an extension of the lexical conceptual structure
(LCS) theory, and compare it with other exist-
ing frameworks which are used in VerbNet and
FrameNet, as an annotation scheme of SRL. LCS
is a decomposition-based approach to verb se-
mantics and describes a meaning by composing
a set of primitive predicates. The advantage of
this approach is that primitive predicates and their
compositions are formally defined. As a result,
we can give a strict definition of semantic roles
by grounding them to lexical semantic structures
of verbs. In fact, we define semantic roles as ar-
gument slots in primitive predicates. With this ap-
1To be precise, FrameNet permits multiple-role assign-
ment, while it does not perform this systematically as we
show in Table 1. It mostly defines a single role label for a
corresponding syntactic argument, that plays multiple roles
in several sub-events in a verb.
proach, we demonstrate that some sort of seman-
tic characteristics that VerbNet and FrameNet in-
formally/implicitly describe in their roles can be
given formal definitions and that multiple argu-
ment roles can be represented strictly and natu-
rally by extending the LCS theory.
In the first half of this paper, we define our ex-
tended LCS framework and describe how it gives
a formal definition of roles and solves the problem
of multiple roles. In the latter half, we discuss
the analysis of the empirical data we collected
for 60 Japanese verbs and also discuss theoreti-
cal relationships with the frameworks of existing
resources. We discuss in detail the relationships
between our role labels and VerbNet?s thematic
roles. We also describe the relationship between
our framework and FrameNet, with regards to the
definitions of the relationships between semantic
frames.
2 Related works
There have been several attempts in linguistics
to assign multiple semantic properties to one ar-
gument. Gruber (1965) demonstrated the dis-
pensability of the constraint that an argument
takes only one semantic role, with some concrete
examples. Rozwadowska (1988) suggested an
approach of feature decomposition for semantic
roles using her three features of change, cause,
and sentient, and defined typical thematic roles
by combining these features. This approach made
it possible for us to classify semantic properties
across thematic roles. However, Levin and Rap-
paport Hovav (2005) argued that the number of
combinations using defined features is usually
larger than the actual number of possible com-
binations; therefore, feature decomposition ap-
proaches should predict possible feature combi-
nations.
Culicover and Wilkins (1984) divided their
roles into two groups, action and perceptional
roles, and explained that dual assignment of roles
always involves one role from each set. Jackend-
off (1990) proposed an LCS framework for rep-
resenting the meaning of a verb by using several
primitive predicates. Jackendoff also stated that
an LCS represents two tiers in its structure, action
tier and thematic tier, which are similar to Culi-
cover and Wilkins?s two sets. Essentially, these
two approaches distinguished roles related to ac-
tion and change, and successfully restricted com-
687
26
6
4
cause(affect(i,j), go(j,
2
6
4
from(locate(in(i)))
fromward(locate(at(k)))
toward(locate(at(l)))
3
7
5
))
3
7
7
5
Figure 1: LCS of the verb throw.
binations of roles by taking a role from each set.
Dorr (1997) created an LCS-based lexical re-
source as an interlingual representation for ma-
chine translation. This framework was also used
for text generation (Habash et al 2003). How-
ever, the problem of multiple-role assignment was
not completely solved on the resource. As a
comparison of different semantic structures, Dorr
(2001) and Hajic?ova? and Kuc?erova? (2002) ana-
lyzed the connection between LCS and PropBank
roles, and showed that the mapping between LCS
and PropBank roles was many to many correspon-
dence and roles can map only by comparing a
whole argument structure of a verb. Habash and
Dorr (2001) tried to map LCS structures into the-
matic roles by using their thematic hierarchy.
3 Multiple role expression using lexical
conceptual structure
Lexical conceptual structure is an approach to de-
scribe a generalized structure of an event or state
represented by a verb. A meaning of a verb is rep-
resented as a structure composed of several prim-
itive predicates. For example, the LCS structure
for the verb ?throw? is shown in Figure 1 and
includes the predicates cause, affect, go, from,
fromward, toward, locate, in, and at. The argu-
ments of primitive predicates are filled by core ar-
guments of the verb. This type of decomposition
approach enables us to represent a case that one
syntactic argument fills multiple slots in the struc-
ture. In Figure 1, the argument i appears twice in
the structure: as the first argument of affect and
the argument in from.
The primitives are designed to represent a full
or partial action-change-state chain, which con-
sists of a state, a change in or maintaining of a
state, or an action that changes/maintains a state.
Table 2 shows primitives that play important roles
to represent that chain. Some primitives embed
other primitives as their arguments and the seman-
tics of the entire structure of an LCS structure
is calculated according to the definition of each
primitive. For instance, the LCS structure in Fig-
Predicates Semantic Functions
state(x, y) First argument is in state specified by
second argument.
cause(x, y) Action in first argument causes change
specified in second argument.
act(x) First argument affects itself.
affect(x, y) First argument affects second argument.
react(x, y) First argument affects itself, due to the
effect from second argument.
go(x, y) First argument changes according to the
path described in the second argument.
from(x) Starting point of certain change event.
fromward(x) Direction of starting point.
via(x) Pass point of certain change event.
toward(x) Direction of end point.
to(x) End point of certain change event.
along(x) Linear-shaped path of change event.
Table 2: Major primitive predicates and their semantic
functions.
ure 1 represents the action changing the state of j.
The inner structure of the second argument of go
represents the path of the change.
The overall definition of our extended LCS
framework is shown in Figure 2.2 Basically, our
definition is based on Jackendoff?s LCS frame-
work (1990), but performed some simplifications
and added extensions. The modification is per-
formed in order to increase strictness and gen-
erality of representation and also a coverage for
various verbs appearing in a corpus. The main
differences between the two LCS frameworks are
as follows. In our extended LCS framework, (i)
the possible combinations of cause, act, affect,
react, and go are clearly restricted, (ii) multiple
actions or changes in an event can be described
by introducing a combination function (comb for
short), (iii) GO, STAY and INCH in Jackendoff?s
theory are incorporated into one function go, and
(iv) most of the change-of-state events are repre-
sented as a metaphor using a spatial transition.
The idea of a comb function comes from a nat-
ural extension of Jackendoff?s EXCH function.
In our case, comb is not limited to describing
a counter-transfer of the main event but can de-
scribe subordinate events occurring in relation to
the main event.3 We can also describe multiple
2Here we omitted the attributes taken by each predicate,
in order to simplify the explanation. We also omitted an
explanation for lower level primitives, such as STATE and
PLACE groups, which are not necessarily important for the
topic of this paper.
3In our extended LCS theory, we can describe multiple
688
LCS =
2
4
EVENT+
comb
h
EVENT
i
*
3
5
STATE =
8
>
>
>
<
>
>
>
:
be
locate(PLACE)
orient(PLACE)
extent(PLACE)
connect(arg)
9
>
>
>
=
>
>
>
;
EVENT =
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
8
>
>
>
<
>
>
>
:
state(arg, STATE)
go(arg, PATH)
cause(act(arg1), go(arg1, PATH))
cause(affect(arg1, arg2), go(arg2, PATH))
cause(react(arg1, arg2), go(arg1, PATH))
9
>
>
>
=
>
>
>
;
manner(constant)?
mean(constant)?
instrument(constant)?
purpose(EVENT)*
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
PLACE =
8
>
>
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
>
>
:
in(arg)
on(arg)
cover(arg)
fit(arg)
inscribed(arg)
beside(arg)
around(arg)
near(arg)
inside(arg)
at(arg)
9
>
>
>
>
>
>
>
>
>
=
>
>
>
>
>
>
>
>
>
;
PATH=
2
6
6
6
6
6
6
6
6
4
from(STATE)?
fromward(STATE)?
via(STATE)?
toward(STATE)?
to(STATE)?
along(arg)?
3
7
7
7
7
7
7
7
7
5
Figure 2: Description system of our LCS. Operators
+, ?, ? follow the basic regular expression syntax. {}
represents a choice of the elements.
main events if the agent does more than two ac-
tions simultaneously and all the actions are the
focus (e.g., John exchanges A with B). This ex-
tension is simple, but essential for creating LCS
structures of predicates appearing in actual data.
In our development of 60 Japanese predicates
(verb and verbal noun) frequently appearing in
Kyoto University Text Corpus (KTC) (Kurohashi
and Nagao, 1997) , 37.6% of the frames included
multiple events. By using the comb function, we
can express complicated events with predicate de-
composition and prevent missing (multiple) roles.
A key point for associating LCS framework
with the existing frameworks of semantic roles is
that each primitive predicate of LCS represents
a fundamental function in semantics. The func-
events in the semantic structure of a verb. However, gener-
ally, a verb focuses on one of those events and this makes
a semantic variation among verbs such as buy, sell, and pay
as well as difference of syntactic behavior of the arguments.
Therefore, focused event should be distinguished from the
others as lexical information. We expressed focused events
as main formulae (formulae that are not surrounded by a
comb function).
Role Description
Protagonist Entity which is viewpoint of verb.
Theme Entity in which its state or change of state
is mentioned.
State Current state of certain entity.
Actor Entity which performs action that
changes/maintains its state.
Effector Entity which performs action that
changes/maintains a state of another entity.
Patient Entity which is changed/maintained its
state by another entity.
Stimulus Entity which is cause of the action.
Source Starting point of certain change event.
Source dir Direction of starting point.
Middle Pass point of certain change event.
Goal End point of certain change event.
Goal dir Direction of end point.
Route Linear-shaped path of certain change event.
Table 3: Semantic role list for proposing extended LCS
framework.
tions of the arguments of the primitive predicates
can be explained using generalized semantic roles
such as typical thematic roles. In order to sim-
ply represent the semantic functions of the ar-
guments in the LCS primitives or make it eas-
ier to compare our extended LCS framework with
other SRL frameworks, we define a semantic role
set that corresponds to the semantic functions of
the primitive predicates in the LCS structure (Ta-
ble 3). We employed role names similarly to typ-
ical thematic roles in order to easily compare the
role sets, but the definition is different. Also, due
to the increase of the generality of LCS represen-
tation, we obtained clearer definition to explain a
correspondence between LCS primitives and typ-
ical thematic roles than the Jackendoff?s predi-
cates. Note that the core semantic information of
a verb represented by a LCS framework is em-
bodied directly in its LCS structure and the in-
formation decreases if the structure is mapped to
the semantic roles. The mapping is just for con-
trasting thematic roles. Each role is given an ob-
vious meaning and designed to fit to the upper-
level primitives of the LCS structure, which are
the arguments of EVENT and PATH functions. In
Table 4, we can see that these roles correspond al-
most one-to-one to the primitive arguments. One
special role is Protagonist, which does not match
an argument of a specific primitive. The Pro-
tagonist is assigned to the first argument in the
main formula to distinguish that formula from the
sub formulae. There are 13 defined roles, and
689
Predicate 1st arg 2nd arg
state Theme State
act Actor ?
affect Effector Patient
react Actor Stimulus
go Theme PATH
from Source ?
fromward Source dir ?
via Middle ?
toward Goal dir ?
to Goal ?
along Route ?
Table 4: Correspondence between semantic roles and
arguments of LCS primitives
this number is comparatively smaller than that in
VerbNet. The discussion with regard to this num-
ber is described in the next section.
Essentially, the semantic functions of the ar-
guments in LCS primitives are similar to those
of traditional, or basic, thematic roles. However,
there are two important differences. Our extended
LCS framework principally guarantees that the
primitive predicates do not contain any informa-
tion concerning (i) selectional preference and (ii)
complex structural relation of arguments. Primi-
tives are designed to purely represent a function
in an action-change-state chain, thus the informa-
tion of selectional preference is annotated to a dif-
ferent layer; specifically, it is directly annotated to
core arguments (e.g., we can annotate i with sel-
Pref(animate ? organization) in Figure 1). Also,
the semantic function is already decomposed and
the structural relation among the arguments is rep-
resented as a structure of primitives in LCS rep-
resentation. Therefore, each argument slot of
the primitive predicates does not include compli-
cated meanings and represents a primitive seman-
tic property which is highly functional. These
characteristics are necessary to ensure clarity of
the semantic role meanings. We believe that even
though there surely exists a certain type of com-
plex semantic role, it is reasonable to represent
that role based on decomposed properties.
In order to show an instance of our extended
LCS theory, we constructed a dictionary of LCS
structures for 60 Japanese verbs (including event
nouns) using our extended LCS framework. The
60 verbs were the most frequent verbs in KTC af-
ter excluding 100 most frequent ones.4 We cre-
4We omitted top 100 verbs since these most frequent ones
Role Single Multiple Grow (%)
Theme 21 108 414
State 1 1 0
Actor 12 13 8.3
Effector 73 92 26
Patient 77 79 2.5
Stimulus 0 0 0
Source 11 44 300
Source dir 4 4 0
Middle 1 8 700
Goal 42 81 93
Goal dir 2 3 50
Route 2 2 0
w/o Theme 225 327 45
Total 246 435 77
Table 5: Number of appearances of each role
ated the dictionary looking at the instances of
the target verbs in KTC. To increase the cover-
age of senses and case frames, we also consulted
the online Japanese dictionary Digital Daijisen5
and Kyoto university case frames (Kawahara and
Kurohashi, 2006) which is a compilation of case
frames automatically acquired from a huge web
corpus. There were 97 constructed frames in the
dictionary.
Then we analyzed how many roles are addi-
tionally assigned by permitting multiple role as-
signment (see Table 5). The numbers of assigned
roles for single role are calculated by counting
roles that appear first for each target argument in
the structure. Table 5 shows that the total number
of assigned roles is 1.77 times larger than single-
role assignment. The main reason is an increase in
Theme. For single-role assignment, Theme, in our
sense, in action verbs is always duplicated with
Actor/Patient. On the other hand, LCS strictly
divides a function for action and change; there-
fore the duplicated Theme is correctly annotated.
Moreover, we obtained a 45% increase even when
we did not count duplicated Theme. Most of in-
crease are a result from the increase in Source
and Goal. For example, Effectors of transmission
verbs are also annotated with a Source, and Effec-
tors of movement verbs are sometimes annotated
with Source or Goal.
contain a phonogram form (Hiragana form) of a certain verb
written with Kanji characters, and that phonogram form gen-
erally has a huge ambiguity because many different verbs
have same pronunciation in Japanese.
5Available at http://dictionary.goo.ne.jp/jn/.
690
Resource Frame-independent # of roles
LCS yes 13
VerbNet (v3.1) yes 30
FrameNet (r1.4) no 8884
Table 6: Number of roles in each resource.
4 Comparison with other resources
4.1 Number of semantic roles
The number of roles is related to the number of se-
mantic properties represented in a framework and
to the generality of that property. Table 6 lists the
number of semantic roles defined in our extended
LCS framework, VerbNet and FrameNet.
There are two ways to define semantic roles.
One is frame specific, where the definition of each
role depends on a specific lexical entry and such
a role is never used in the other frames. The other
is frame independent, which is to construct roles
whose semantic function is generalized across
all verbs. The number of roles in FrameNet is
comparatively large because it defines roles in a
frame-specific way. FrameNet respects individual
meanings of arguments rather than generality of
roles.
Compared with VerbNet, the number of roles
defined in our extended LCS framework is less
than half. However, this fact does not mean
that the representation ability of our framework is
lower than VerbNet. We manually checked and
listed a corresponding representation in our ex-
tended LCS framework for each thematic role in
VerbNet in Table 6. This table does not provide a
perfect or complete mapping between the roles in
these two frameworks because the mappings are
not based on annotated data. However, we can
roughly say that the VerbNet roles combine three
types of information, a function of the argument
in the action-change-state chain, selectional pref-
erence, and structural information of arguments,
which are in different layers in LCS representa-
tion. VerbNet has many roles whose functions in
the action-change-state chain are duplicated. For
example, Destination, Recipient, and Beneficiary
have the same property end-state (Goal in LCS)
of a changing event. The difference between such
roles comes from a specific sub-type of a chang-
ing event (possession), selectional preference, and
structural information among the arguments. By
distinguishing such roles, VerbNet roles may take
into account specific syntactic behaviors of cer-
tain semantic roles. Packing such complex infor-
mation to semantic roles is useful for analyzing
argument realization. However, from the view-
point of semantic representation, the clarity for
semantic properties provided using a predicate de-
composition approach is beneficial. The 13 roles
for the LCS approach is sufficient for obtaining
a function in the action-change-state chain. In
our LCS framework, selectional preference can
be assigned to arguments in an individual verb or
verb class level instead of role labels themselves
to maintain generality of semantic functions. In
addition, our extended LCS framework can easily
separate complex structural information from role
labels because LCS directly represents a structure
among the arguments. We can calculate the infor-
mation from the LCS structure instead of coding
it into role labels. As a result, our extended LCS
framework maintains generality of roles and the
number of roles is smaller than other frameworks.
4.2 Clarity of role meanings
We showed that an approach of predicate decom-
position used in LCS theory clarified role mean-
ings assigned to syntactic arguments. Moreover,
LCS achieves high generality of roles by separat-
ing selectional preference or structural informa-
tion from role labels. The complex meaning of
one syntactic argument is represented by multi-
ple appearances of the argument in an LCS struc-
ture. For example, we show an LCS structure
and a frame in VerbNet with regard to the verb
?buy? in Figure 3. The LCS structure consists
of four formulae. The first one is the main for-
mula and the others are sub-formulae that rep-
resent co-occurring actions. The semantic-role-
like representation of the structure is given in Ta-
ble 4: i = {Protagonist, Effector, Source, Goal},
j = {Patient,Theme}, k = {Effector, Source,
Goal}, and l = {Patient,Theme}. Selectional
preference is annotated to each argument as i:
selPref(animate ? organization), j: selPref(any),
k: selPref(animate ? organization), and l: sel-
Pref(valuable entity). If we want to represent the
information, such as ?Source of what??, then we
can extend the notation as Source(j) to refer to a
changing object.
On the other hand, VerbNet combines mul-
tiple types of information into a single role as
mentioned above. Also, the meaning of some
691
VerbNet role (# of uses) Representation in LCS
Actor (9), Actor1 (9), Actor2 (9) Actor or Effector in symmetric formulas in the structure
Agent (212) (Actor ? Effector) ? Protagonist
Asset (6) Theme ? Source of the change is (locate(in()) ? Protagonist) ?
selPref(valuable entity)
Beneficiary (9) (peripheral role ? (Goal ? locate(in()))) ? selPref(animate ? organization)
? ?(Actor ? Effector) ? a transferred entity is something beneficial
Cause (21) ((Effector ? selPref(?animate ? ?organization)) ? Stimulus ? peripheral role)
Destination (32) Goal
Experiencer (24) Actor of react()
Instrument (25) ((Effector ? selPref(?animate ? ?organization)) ? peripheral role)
Location (45) (Theme ? PATH roles ? peripheral role) ? selPref(location)
Material (6) Theme ? Source of a change ? The Goal of the change is locate(fit()) ?
the Goal fullfills selPref(physical object)
Patient (59), Patient 1(11) Patient ? Theme
Patient2 (11) (Source ? Goal) ? connect()
Predicate (23) Theme ? (Goal ? locate(fit())) ? peripheral role
Product (7) Theme ? (Goal ? locate(fit()) ? selPref(physical object))
Proposition (11) Theme
Recipient (33) Goal ? locate(in()) ? selPref(animate ? organization)
Source (34) Source
Theme (162) Theme
Theme1 (13), Theme2 (13) Both of the two is Theme ? Theme1 is Theme and Theme2 is State
Topic (18) Theme ? selPref(knowledge ? infromation)
Table 7: Relationship of roles between VerbNet and our LCS framework. VerbNet roles that appears more than
five times in frame definition are analyzed. Each relationship shown here is only a partial and consistent part of
the complete correspondence table. Note that complete table of mapping highly depends on each lexical entry
(or verb class). Here, locate(in()) generally means possession or recognizing.
roles depends more on selectional preference or
the structure of the arguments than a primitive
function in the action-change-state chain. Such
VerbNet roles are used for several different func-
tions depending on verbs and their alternations,
and it is therefore difficult to capture decomposed
properties from the role label without having spe-
cific lexical knowledge. Moreover, some seman-
tic functions, such as Mary is a Goal of the money
in Figure 3, are completely discarded from the
representation at the level of role labels.
There is another representation related to the
argument meanings in VerbNet. This representa-
tion is a type of predicate decomposition using its
original set of predicates, which are referred to as
semantic predicates. For example, the verb ?buy?
in Figure 3 has the predicates has possession,
transfer and cost for composing the meaning of
its event structure. The thematic roles are fillers
of the predicates? arguments, thus the semantic
predicates may implicitly provide additional func-
tions to the roles and possibly represent multiple
roles. Unfortunately, we cannot discover what
each argument of the semantic predicates exactly
means since the definition of each predicate is not
Example: ?John bought a book from Mary for $10.?
VerbNet: Agent V Theme {from} Source {for} Asset.
has possession(start(E), Source, Theme),
has possession(end(E), Agent, Theme),
transfer(during(E), Theme), cost(E, Asset)
LCS:
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
cause(aff(i:John, j:a book), go(j,
h
to(loc(in(i)))
i
))
comb
2
4cause(aff(i,l:$10), go(l,
"
from(loc(in(i)))
to(loc(at(k:Mary)))
#
))
3
5
comb
2
4cause(aff(k,j), go(j,
"
from(loc(in(k)))
to(loc(at(i)))
#
))
3
5
comb
?
cause(aff(k,l), go(l,
h
to(loc(in(k)))
i
))
?
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
Figure 3: Comparison between the semantic predicate
representation and the LCS structure of the verb buy.
publicly available. A requirement for obtaining
implicit semantic functions from these semantic
predicates is clearly defining how the roles (or
functions) are calculated from these complex re-
lations of semantic predicates.
FrameNet does not use semantic roles general-
ized among all verbs or does not represent seman-
692
i: selPref(animate ? organization), j: selPref(any), k: selPref(animate ? organization), l:
selPref(valuable entity)
Figure 4: LCS of the verbs get, buy, sell, pay, and collect and their relationships calculated from the structures.
tic properties of roles using a predicate decom-
position approach, but defines specific roles for
each conceptual event/state to represent a specific
background of the roles in the event/state. How-
ever, at the same time, FrameNet defines several
types of parent-child relations between most of
the frames and between their roles; therefore, we
may say FrameNet implicitly describes a sort of
decomposed property using roles in highly gen-
eral or abstract frames and represents the inher-
itance of these semantic properties. One advan-
tage of this approach is that the inheritance of a
meaning between roles is controlled through the
relations, which are carefully maintained by hu-
man efforts, and is not restricted by the represen-
tation ability of the decomposition system. On the
other hand, the only way to represent generalized
properties of a certain semantic role is enumerat-
ing all inherited roles by tracing ancestors. Also,
a semantic relation between arguments in a cer-
tain frame, which is given by LCS structure and
semantic predicates of VerbNet, is only defined
by a natural language description for each frame
in FrameNet. From a CL point of view, we con-
sider that, at least, a certain level of formalization
of semantic relation of arguments is important for
utilize this information for application. LCS ap-
proach, or an approach using a well-defined pred-
icate decomposition, can explicitly describe se-
mantic properties and relationships between argu-
Figure 5: The frame relations among the verbs get,
buy, sell, pay, and collect in FrameNet.
ments in a lexical structure. The primitive proper-
ties can be clearly defined, even though the repre-
sentation ability is restricted under the generality
of roles.
In addition, the frame-to-frame relations in
FrameNet may be a useful resource for some ap-
plication tasks such as paraphrasing and entail-
ment. We argue that some types of relationships
between frames are automatically calculated us-
ing the LCS approach. For example, one of the
relations is based on an inclusion relation of two
LCS structures. Figure 4 shows automatically
calculated relations surrounding the verb ?buy?.
Note that we chose a sense related to a com-
mercial transaction, which means a exchange of
a goods and money, for each word in order to
compare the resulted relation graph with that of
FrameNet. We call relations among ?buy?, ?sell?,
?pay? and ?collect? as different viewpoints since
693
they contain exactly the same formulae, and the
only difference is the main formula. The rela-
tion between ?buy? and ?get? is defined as in-
heritance; a part of the child structure exactly
equals the parent structure. Interestingly, the re-
lations surrounding the ?buy? are similar to those
in FrameNet (see Figure 5). We cannot describe
all types of the relations we considered due to
space limitations. However, the point is that these
relationships are represented as rewriting rules
between the two LCS representations and thus
they are automatically calculated. Moreover, the
grounds for relations maintain clarity based on
concrete structural relations. A semantic relation
construction of frames based on structural rela-
tionships is another possible application of LCS
approaches that connects traditional LCS theo-
ries with resources representing a lexical network
such as FrameNet.
4.3 Consistency on semantic structures
Constructing a LCS dictionary is generally a dif-
ficult work since LCS has a high flexibility for
describing structures and different people tend to
write different structures for a single verb. We
maintained consistency of the dictionary by tak-
ing into account a similarity of the structures be-
tween the verbs that are in paraphrasing or entail-
ment relations. This idea was inspired by auto-
matic calculation of semantic relations of lexicon
as we mentioned above. We created a LCS struc-
ture for each lexical entry as we can calculate se-
mantic relations between related verbs and main-
tained high-level consistency among the verbs.
Using our extended LCS theory, we success-
fully created 97 frames for 60 predicates without
any extra modification. From this result, we be-
lieve that our extended theory is stable to some
extent. On the other hand, we found that an extra
extension of the LCS theory is needed for some
verbs to explain the different syntactic behaviors
of one verb. For example, a condition for a cer-
tain syntactic behavior of a verb related to re-
ciprocal alteration (see class 2.5 of Levin (Levin,
1993)) such as???? (connect) and?? (in-
tegrate) cannot be explained without considering
the number of entities in some arguments. Also,
some verbs need to define an order of the internal
events. For example, the Japanese verb ???
? (shuttle) means that going is a first action and
coming back is a second action. These are not
the problems that are directly related to a seman-
tic role annotation on that we focus in this paper,
but we plan to solve these problems with further
extensions.
5 Conclusion
We discussed the two problems in current labeling
approaches for argument-structure analysis: the
problems in clarity of role meanings and multiple-
role assignment. By focusing on the fact that an
approach of predicate decomposition is suitable
for solving these problems, we proposed a new
framework for semantic role assignment by ex-
tending Jackendoff?s LCS framework. The statis-
tics of our LCS dictionary for 60 Japanese verbs
showed that 37.6% of the created frames included
multiple events and the number of assigned roles
for one syntactic argument increased 77% from
that in single-role assignment.
Compared to the other resources such as Verb-
Net and FrameNet, the role definitions in our ex-
tended LCS framework are clearer since the prim-
itive predicates limit the meaning of each role to
a function in the action-change-state chain. We
also showed that LCS can separate three types of
information, the functions represented by primi-
tives, the selectional preference and structural re-
lation of arguments, which are conflated in role la-
bels in existing resources. As a potential of LCS,
we demonstrated that several types of frame re-
lations, which are similar to those in FrameNet,
are automatically calculated using the structural
relations between LCSs. We still must perform a
thorough investigation for enumerating relations
which can be represented in terms of rewriting
rules for LCS structures. However, automatic
construction of a consistent relation graph of se-
mantic frames may be possible based on lexical
structures.
We believe that this kind of decomposed analy-
sis will accelerate both fundamental and applica-
tion research on argument-structure analysis. As a
future work, we plan to expand the dictionary and
construct a corpus based on our LCS dictionary.
Acknowledgment
This work was partially supported by JSPS Grant-
in-Aid for Scientific Research #22800078.
694
References
P.W. Culicover and W.K. Wilkins. 1984. Locality in
linguistic theory. Academic Press.
Bonnie J. Dorr. 1997. Large-scale dictionary con-
struction for foreign language tutoring and inter-
lingual machine translation. Machine Translation,
12(4):271?322.
Bonnie J. Dorr. 2001. Lcs database. http://www.
umiacs.umd.edu/?bonnie/LCS Database Document
ation.html.
Jeffrey S Gruber. 1965. Studies in lexical relations.
Ph.D. thesis, MIT.
N. Habash and B. Dorr. 2001. Large scale language
independent generation using thematic hierarchies.
In Proceedings of MT summit VIII.
N. Habash, B. Dorr, and D. Traum. 2003. Hybrid
natural language generation from lexical conceptual
structures. Machine Translation, 18(2):81?128.
Eva Hajic?ova? and Ivona Kuc?erova?. 2002. Argu-
ment/valency structure in propbank, lcs database
and prague dependency treebank: A comparative
pilot study. In Proceedings of the Third Inter-
national Conference on Language Resources and
Evaluation (LREC 2002), pages 846?851.
Ray Jackendoff. 1990. Semantic Structures. The MIT
Press.
D. Kawahara and S. Kurohashi. 2006. Case frame
compilation from the web using high-performance
computing. In Proceedings of LREC-2006, pages
1344?1347.
Paul Kingsbury and Martha Palmer. 2002. From Tree-
bank to PropBank. In Proceedings of LREC-2002,
pages 1989?1993.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-based construction of a verb lexicon.
In Proceedings of the National Conference on Arti-
ficial Intelligence, pages 691?696. Menlo Park, CA;
Cambridge, MA; London; AAAI Press; MIT Press;
1999.
Sadao Kurohashi and Makoto Nagao. 1997. Kyoto
university text corpus project. Proceedings of the
Annual Conference of JSAI, 11:58?61.
Beth Levin and Malka Rappaport Hovav. 2005. Argu-
ment realization. Cambridge University Press.
Beth Levin. 1993. English verb classes and alter-
nations: A preliminary investigation. University of
Chicago Press.
Llu??s Ma`rquez, Xavier Carreras, Kenneth C.
Litkowski, and Suzanne Stevenson. 2008. Se-
mantic role labeling: an introduction to the special
issue. Computational linguistics, 34(2):145?159.
B. Rozwadowska. 1988. Thematic restrictions on de-
rived nominals. In W Wlikins, editor, Syntax and
Semantics, volume 21, pages 147?165. Academic
Press.
J. Ruppenhofer, M. Ellsworth, M.R.L. Petruck, C.R.
Johnson, and J. Scheffczyk. 2006. FrameNet II:
Extended Theory and Practice. Berkeley FrameNet
Release, 1.
Szu-ting Yi, Edward Loper, and Martha Palmer. 2007.
Can semantic roles generalize across genres? In
Proceedings of HLT-NAACL 2007, pages 548?555.
695
Proceedings of the Second Workshop on NLP Challenges in the Information Explosion Era (NLPIX 2010), pages 69?74,
Beijing, August 2010
Mining coreference relations between formulas and text using Wikipedia
Minh Nghiem Quoc 1, Keisuke Yokoi 2, Yuichiroh Matsubayashi 3 Akiko Aizawa 1 2 3
1 Department of Informatics, The Graduate University for Advanced Studies
2 Department of Computer Science, University of Tokyo
3 National Institute of Informatics
{nqminh, kei-yoko, y-matsu, aizawa}@nii.ac.jp
Abstract
In this paper, we address the problem of
discovering coreference relations between
formulas and the surrounding text. The
task is different from traditional coref-
erence resolution because of the unique
structure of the formulas. In this paper, we
present an approach, which we call ?CDF
(Concept Description Formula)?, for min-
ing coreference relations between formu-
las and the concepts that refer to them.
Using Wikipedia articles as a target cor-
pus, our approach is based on surface level
text matching between formulas and text,
as well as patterns that represent relation-
ships between them. The results showed
the potential of our approach for formulas
and text coreference mining.
1 Introduction
1.1 Motivation
Mathematical content is a valuable information
source for many users: teachers, students, re-
searchers need access to mathematical resources
for teaching, studying, or obtaining updated infor-
mation for research and development. Although
more and more mathematical content is becom-
ing available on the Web nowadays, conventional
search engines do not provide direct search of
mathematical formulas. As such, retrieving math-
ematical content remains an open issue.
Some recent studies proposed mathematical re-
trieval systems that were based on structural sim-
ilarity of equations (Adeel and Khiyal, 2008;
Yokoi and Aizawa, 2009; Nghiem et al, 2009).
However, in these studies, the semantics of the
equations is still not taken into account. As
mathematical equations follow highly abstract and
also rewritable representations, structural similar-
ity alone is insufficient as a metric for semantic
similarity.
Based on this observation, the primary goal of
this paper is to establish a method for extracting
implicit connections between mathematical for-
mulas and their names together with the descrip-
tions written in natural language text. This en-
ables keywords to be associated with the formu-
las and makes mathematical search more power-
ful. For example, it is easier for people searching
and retrieving mathematical concepts if they know
the name of the equation ?a2 + b2 = c2? is
the ?Pythagorean Theorem?. It could also make
mathematics more understandable and usable for
users.
While many studies have presented corefer-
ence relations among texts (Ponzetto and Poesio,
2009), no work has ever considered the corefer-
ence relations between formulas and texts. In this
paper, we use Wikipedia articles as a target cor-
pus. We chose Wikipedia for these reasons: (1)
Wikipedia uses a subset of TEX markup for math-
ematical formulas. That way, we can analyze the
content of these formulas using TEX expressions
rather than analyzing the images. (2) Wikipedia
provides a wealth of knowledge and the content
of Wikipedia is much cleaner than typical Web
pages, as explained in Giles (2005).
69
1.2 Related Work
Ponzetto and Poesio (2006) attempted to include
semantic information extracted from WordNet
and Wikipedia into their coreference resolution
model. Shnarch et al (2009) presented the ex-
traction of a large-scale rule base from Wikipedia
designed to cover a wide scope of the lexical
reference relations. Their rule base has compa-
rable performance with WordNet while provid-
ing largely complementary information. Yan et
al. (2009) proposed an unsupervised relation ex-
traction method for discovering and enhancing
relations associated with a specified concept in
Wikipedia. Their work combined deep linguis-
tic patterns extracted from Wikipedia with surface
patterns obtained from the Web to generate vari-
ous relations. The results of these studies showed
that Wikipedia is a knowledge-rich and promising
resource for extracting relations between repre-
sentative terms in text. However, these techniques
are not directly applicable to the coreference res-
olution between formulas and texts as we mention
in the next section.
1.3 Challenges
There are two key challenges in solving the coref-
erence relations between formulas and texts using
Wikipedia articles.
? First, formulas have unique structures such
as prior operators and nested functions. In
addition, features such as gender, plural, part
of speech, and proper name, are unavail-
able with formulas for coreference resolu-
tion. Therefore, we cannot apply standard
natural language processing methods to for-
mulas.
? Second, no labeled data are available for
the coreference relations between formu-
las and texts. This means we cannot ap-
ply commonly used machine learning-based
techniques without expensive human annota-
tions.
1.4 Our Approach and Key Contributions
In this paper, we present an approach, which
we call CDF (Concept Description Formula), for
mining coreference relations between mathemat-
ical Formulas and Concepts using Wikipedia ar-
ticles. In order to address the previously men-
tioned challenges, the proposed CDF approach is
featured as follows:
? First, we consider not only the concept-
formula pairs but extend the relation with de-
scriptions of the concept. Note that a ?con-
cept? in our study corresponds to a ?name? or
a ?title? of a formula, which is usually quite
short. By additionally considering words ex-
tracted from the descriptions, we have a bet-
ter chance of detecting keywords, such as
mathematical symbols, and function or vari-
able names, used in the equations.
? Second, we apply an unsupervised frame-
work in our approach. Initially, we extract
highly confident coreference pairs using sur-
face level text matching. Next, we collect
promising syntactic patterns from the de-
scriptions and then use the patterns to extract
coreference pairs. The process enables us to
deal with cases where there exist no common
words between the concepts and the formu-
las.
The remainder of this paper is organized as fol-
lows: In section 2, we present our method. We
then describe the experiments and results in sec-
tion 3. Section 4 concludes the paper and gives
avenues for future work.
2 Method
2.1 Overview of the Method
In this section, we first explain the terms used in
our approach. We then provide a framework of
our method and the functions of the main mod-
ules.
Given a set of Wikipedia articles as input, our
system outputs a list of formulas along with their
names and descriptions. Herein
? Concept: A concept C is a phrase that repre-
sents a name of a mathematical formula. In
Wikipedia, we extract candidate concepts as
noun phrases (NPs) that are either the titles of
70
Wikipedia articles, section headings, or writ-
ten in bold or italic. Additional NPs that con-
tain at least one content word are also consid-
ered.
? Description: A description D is a phrase
that describes the concept. In Wikipedia, de-
scriptions often follow a concept after the
verb ?be?.
? Formula: A formula F is a mathematical
formula. In Wikipedia extracted XML files,
formulas occur between the < math > and
< /math > tags. They are encoded in TEX
format.
? Candidate: A candidate is a triple of con-
cept, description and formula. Our system
will judge if the candidate is qualified, which
means the concept is related to the formula.
Figure 1 shows a section of a Wikipedia article
and the concepts, descriptions and formulas in this
section. Table 1 shows the extracted candidates.
Details of how to extract the concepts, descrip-
tions and formulas and how to form candidates are
described in the next sections.
Sine, cosine and tangent
The sine of an angle is the ratio of the length of the opposite side to the length of the hypotenuse. In our case
sin A= oppositehypotenuse=ah
Note that this ratio does not depend on size of the particular right triangle chosen, as long as it contains the angle A, since all such triangles are similar.
The cosine of an angle is the ratio of the length of the adjacent side to the length of the hypotenuse. In our case
cos A= adjacenthypotenuse=bh
The tangent of an angle is the ratio of the length of the opposite side to the length of the adjacent side (called so because it can be represented as a line segment tangent to the circle). In our case
tan A= oppositeadjacent =ab
The acronym "SOHCAHTOA" is a useful mnemonic for these ratios.
TITLE
PARAGRAPH
PARAGRAPH
PARAGRAPH
FORMULA
FORMULA
FORMULA
CONCEPT DESCRIPTION
DESCRIPTIONCONCEPT
DESCRIPTION
CONCEPT
Figure 1: Examples of extracted paragraphs
The framework of the system is shown in Fig-
ure 2. The system has four main modules.
? Text Preprocessor: processes Wikipedia ar-
ticles to extract CDF (Concept Description
Formula) candidates.
Input: Wikipedia articles
Preprocessor
Pattern Matching Text Matching
Output: equation's references
Pattern Generation
Concept Description FormulaThe sine of an angle the ratio of the length of the opposite side to the length of the hypotenuse a quadratic equation a polynomial equation of the second degree
sin A= oppositehypotenuse=ahax2?bx?c=0
Figure 2: Framework of the proposed approach
? Text Matching: extracts reliable and qual-
ified candidates using surface level text
matching.
? Pattern Generation: generates patterns
from qualified candidates.
? Pattern Matching: extends the candidate
list using the generated patterns.
2.2 Text Preprocessor
This module preprocesses the text of the
Wikipedia article to extract CDF candidates.
Based on the assumption that concepts, their de-
scriptions and formulas are in the same paragraph,
we split the text into paragraphs and select para-
graphs that contain at least one formula.
On these selected paragraphs, we run Sentence
Boundary Detector, Tokenizer and Parser from
OpenNLP tools. 1 Based on the parse trees, we
extract the noun phrases (NPs) and identify NPs
representing concepts or descriptions using the
definitions in Section 2.1.
Following the general idea in Shnarch et al
(2009), we use the ?Be-Comp? rule to identify the
description of a concept in the definition sentence.
In a sentence, we extract nominal complements of
the verb ?to be?, assign the NP that occurs after
the verb ?to be? as the description of the NP that
occurs before the verb. Note that some concepts
have descriptions while others do not.
1http://opennlp.sourceforge.net/
71
Table 1: Examples of candidates
Concept Description Formula
the sine of an angle the ratio of the length of the opposite side to sinA = oppositehypotenuse = ah
the length of the hypotenuse
the cosine of an angle the ratio of the length of the adjacent side to cosA = adjacenthypotenuse = bh
the length of the hypotenuse
a quadratic equation a polynomial equation of the second degree ax2 + bx+ c = 0
the quadratic formula x = ?b?
?
b2?4ac
2a
the complex number i i2 = ?1
the Cahen?Mellin integral e?y = 12pii
? c+i?
c?i? ?(s)y?s ds
The ?Be-Comp? rule can also identify if a for-
mula is related to the concept.
After that, we group each formula F in the
same paragraph with concept C and its descrip-
tion D to form a candidate (C, D, F ). Table 1
presents candidate examples. Because we only
choose paragraphs that contain at least one for-
mula, every concept has a formula attached to it.
In order to judge the correctness of candidates,
we use the text-matching module, described in the
next section.
2.3 Text Matching
In this step, we classify candidates using surface
text. Given a list of candidates of the form (C, D,
F ), this module judges if a candidate is qualified
by using the surface text in concept, description
and formula. Because many formulas share the
same variable names or function names (or part of
these names) with their concepts (e.g. the first two
candidates in Table 1), we filter these candidates
using surface text matching.
We define the similarity between concept C,
description D and formula F by the number of
overlapped words, as in Eq. 1.
sim(F,CD) = |TF ? TC|min{|TC|, |TF|}
+ |TF ? TD|min{|TD|, |TF|}(1)
TF , TC and TD are sets of words extracted from
F , C and D, respectively.
Candidates with sim(F,CD) no larger than a
threshold ?1 (1/3 in this study) are grouped into
the group Ctrue. The rest are filtered and stored in
C0. In this step, function words such as articles,
pronouns, conjunctions and so on in concepts and
descriptions are ignored. Common operators in
formulas are also converted to text, such as ?+?
?plus?, ??? ?minus?, ?\frac? ?divide?.
Using only concepts for text matching with for-
mulas might leave out various important relations.
For example, from the description of the first and
second formula in Table 1, we could extract the
variable names ?opposite?, ?adjacent? and ?hy-
potenuse?.
By adding the description, we could get a more
accurate judgment of whether the concept and
the formula are coreferent. In this case, we can
consider the concept, description and the formula
form a coreference chain.
After this step, we have two categories, Ctrue
and C0. Ctrue contains qualified candidates while
C0 contains candidates that cannot be determined
by text matching. The formulas in C0 have little
or no text relation with their concepts and descrip-
tions. Thus, we can only judge the correctness of
these candidates by using the text around the con-
cepts, descriptions and formulas. The surrounding
text can be formed into patterns and are generated
in the next step.
2.4 Pattern Generation
One difficulty in judging the correctness of a can-
didate is that the formula does not share any re-
lation with its concept and description. The third
candidate in Fig. 1 is an example. It should be
classified as a qualified instance but is left behind
in C0 after the ?text matching? step.
72
In this step, we use the qualified instances in
Ctrue to generate patterns. These patterns are used
in the next step to judge the candidates in C0. Pat-
terns are generated as follows. First, the concept,
description and formula are replaced by CONC,
DESC and FORM, respectively. We then simply
take the entire string between the first and the last
appearance of CONC, DESC and FORM.
Table 2 presents examples of patterns extracted
from group Ctrue.
Table 2: Examples of extracted patterns
Pattern
CONC is DESC: FORM
CONC is DESC. In our case FORM
CONC is DESC. So, ..., FORM
CONC FORM
CONC is denoted by FORM
CONC is given by ... FORM
CONC can be written as ... : FORM
FORM where CONC is DESC
FORM satisfies CONC
Using a window surrounding the concepts and
formulas often leads to exponential growth in pat-
terns, so we limit our patterns to those between
any concept C, description D or formula F .
The patterns we obtained above are exactly the
shortest paths from the C nodes to their F node in
the parse tree. Figure 3 presents examples of these
patterns in parse trees.
I
np
u
tp
: W
ikke
np
u
tp
: np
W d a
ikke
pp
rc np
kls Po M a
Figure 3: Examples of extracted patterns
2.5 Pattern Matching
In this step, we use patterns obtained from the
previous step to classify more candidates in C0.
We use the string distance between the patterns,
where candidates? patterns having a string dis-
tance to any of the patterns extracted in the previ-
ous step no larger than the threshold ?2 are added
into Ctrue.
3 Experiments
3.1 Data
We collected a total of 16,406 mathematical doc-
uments from the Wikipedia Mathematics Portal.
After the preprocessing step, we selected 72,084
paragraphs that contain at least one formula. From
these paragraphs, we extracted 931,716 candi-
dates.
Because no labeled data are available for use
in this task, we randomly chose 100 candidates:
60 candidates from Ctrue after the text matching
step, 20 candidates added to Ctrue after pattern
matching with ?2 = 0, and 20 candidates added
to Ctrue after pattern matching with ?2 = 0.25 for
our evaluation. These candidates were annotated
manually. The sizes of the sample sets for human
judgment (60, 20 and 20) were selected approx-
imately proportional to the sizes of the obtained
candidate sets.
3.2 Results
After the text matching step, we obtained 138,285
qualified candidates in the Ctrue group and
793,431 candidates in C0. In Ctrue, we had 6,129
different patterns. Applying these patterns to C0
by exact pattern matching (?2 = 0), we obtained a
further 34,148 qualified candidates. We obtained
an additional 30,337 qualified candidates when
we increased the threshold ?2 to 0.25.
For comparison, we built a baseline system.
The baseline automatically groups nearest for-
mula and concept. It had 51 correctly qualified
candidates. The results?displayed in Table 3
and depicted in Figure 4?show that our proposed
method is significantly better than the baseline in
terms of accuracy.
As we can see from the results, when we lower
the threshold, more candidates are added to Ctrue,
which means we get more formulas and formula
names; but it also lowers the accuracy. Although
the performance is not as high as other existing
coreference resolution techniques, the proposed
73
Table 3: Results of the system
Module No. correct/ No. of
total CDF found
Text Matching 41 / 60 138,285
Pattern Matching 52 / 80 172,433
?2 = 0
Pattern Matching 56 / 100 202,270
?2 = 0.25
method is a promising starting point for solving
coreference relations between formulas and sur-
rounding text.
4 Conclusions
In this paper, we discuss the problem of discov-
ering coreference relations between formulas and
the surrounding texts. Although we could only
use a small number of annotated data for the eval-
uation in this paper, our preliminary experimental
results showed that our approach based on sur-
face text-based matching between formulas and
text, as well as patterns representing relationships
between them showed promise for mining math-
ematical knowledge from Wikipedia. Since this
is the first attempt to extract coreference rela-
tions between formulas and texts, there is room
for further improvement. Possible improvements
include: (1) using advanced technology for pat-
tern matching to improve the coverage of the re-
sult and (2) expanding the work by mining knowl-
edge from the Web.
References
Eyal Shnarch, Libby Barak and Ido Dagan. 2009.
Extracting Lexical Reference Rules from Wikipedia
Proceedings of the 47th Annual Meeting of the ACL
and the 4th IJCNLP of the AFNLP, pages 450?458
Yulan Yan, Naoaki Okazaki, Yutaka Matsuo, Zhenglu
Yang and Mitsuru Ishizuka. 2009. Unsupervised
Relation Extraction by Mining Wikipedia Texts Us-
ing Information from the Web Proceedings of the
47th Annual Meeting of the ACL and the 4th IJC-
NLP of the AFNLP, pages 1021?1029
Simone Paolo Ponzetto and Massimo Poesio. 2009.
State-of-the-art NLP Approaches to Coreference
Input: uWiked
a uunret: uWikedtc
a uunret: uWikedtclsP
oc
oP
Pc
PP
Mc
MP
hc gWWTr Wx
Input: uWiked
a uunret: uWikedtc
a uunret: uWikedtclsP
Occccc
Oscccc
Oocccc
OMcccc
Oqcccc
sccccc
sscccc
'fltfGt???t
GfTe?
? ?n?ken
Figure 4: Results of the system
Resolution: Theory and Practical Recipes Tutorial
Abstracts of ACL-IJCNLP 2009, page 6
Minh Nghiem, Keisuke Yokoi and Akiko Aizawa.
2009. Enhancing Mathematical Search with Names
of Formulas The Workshop on E-Inclusion in Math-
ematics and Science 2009, pages 22?25
Keisuke Yokoi and Akiko Aizawa. 2009. An Ap-
proach to Similarity Search for Mathematical Ex-
pressions using MathML 2nd workshop Towards a
Digital Mathematics Library, pages 27?35
Hui Siu Cheung Muhammad Adeel and Sikandar
Hayat Khiyal. 2008. Math Go! Prototype of a
Content Based Mathematical Formula Search En-
gine Journal of Theoretical and Applied Informa-
tion Technology, Vol. 4, No. 10, pages 1002?1012
Simone Paolo Ponzetto and Michael Strube. 2006.
Exploiting Semantic Role Labeling, WordNet and
Wikipedia for Coreference Resolution In Proceed-
ings of HLT-NAACL-06, pages 192?199
Jim Giles. 2005. Internet Encyclopaedias Go Head
to Head Nature Volume: 438, Issue: 7070, pages
900?901
World Wide Web Consortium. Mathematical Markup
Language (MathML) version 2.0 (second edition)
http://www.w3.org/TR/MathML2/
74
