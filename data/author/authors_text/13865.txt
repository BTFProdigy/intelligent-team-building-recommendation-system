Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 311?321,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Exploring Representations from Unlabeled Data with Co-training
for Chinese Word Segmentation
Longkai Zhang Houfeng Wang? Xu Sun Mairgup Mansur
Key Laboratory of Computational Linguistics (Peking University) Ministry of Education, China
zhlongk@qq.com, wanghf@pku.edu.cn, xusun@pku.edu.cn, mairgup@gmail.com,
Abstract
Nowadays supervised sequence labeling
models can reach competitive performance
on the task of Chinese word segmenta-
tion. However, the ability of these mod-
els is restricted by the availability of an-
notated data and the design of features.
We propose a scalable semi-supervised fea-
ture engineering approach. In contrast
to previous works using pre-defined task-
specific features with fixed values, we dy-
namically extract representations of label
distributions from both an in-domain cor-
pus and an out-of-domain corpus. We
update the representation values with a
semi-supervised approach. Experiments
on the benchmark datasets show that our
approach achieve good results and reach
an f-score of 0.961. The feature engineer-
ing approach proposed here is a general
iterative semi-supervised method and not
limited to the word segmentation task.
1 Introduction
Chinese is a language without natural word
delimiters. Therefore, Chinese Word Segmen-
tation (CWS) is an essential task required by
further language processing. Previous research
shows that sequence labeling models trained on
labeled data can reach competitive accuracy on
the CWS task, and supervised models are more
accurate than unsupervised models (Xue, 2003;
Low et al, 2005). However, the resource of man-
ually labeled training corpora is limited. There-
fore, semi-supervised learning has become one
?Corresponding author
of the most natural forms of training for CWS.
Traditional semi-supervised methods focus on
adding new unlabeled instances to the training
set by a given criterion. The possible mislabeled
instances, which are introduced from the auto-
matically labeled raw data, can hurt the per-
formance and not easy to exclude by setting a
sound selecting criterion.
In this paper, we propose a simple and scal-
able semi-supervised strategy that works by pro-
viding semi-supervision at the level of represen-
tation. Previous works mainly assume that con-
text features are helpful to decide the potential
label of a character. However, when some of the
context features do not appear in the training
corpus, this assumption may fail. An example is
shown in table 1. Although the context of ???
and ??? is totally different, they share a homo-
geneous structure as ?verb-noun?. Therefore. A
much better way is to map the context informa-
tion to a kind of representation. More precisely,
the mapping should let the similar contexts map
to similar representations, while let the distinct
contexts map to distinct representations.
??? ???
Label B B
Character ? ? ? ? ? ?
Context C-1= ? C-1= ?
Features C0= ? C0= ?
C1= ? C1= ?
Table 1: Example of the context of ??? in ???
? (Eat fruits)? and the context of ??? in ????
(Play basketball)?
We use the label distribution information that
311
is extracted from the unlabeled corpus as this
representation to enhance the supervised model.
We add ?pseudo-labels? by tagging the unla-
beled data with the trained model on the train-
ing corpus. These ?pseudo-labels? are not accu-
rate enough. Therefore, we use the label distri-
bution, which is much more accurate.
To accurately calculate the precise label dis-
tribution, we use a framework similar to the co-
training algorithm to adjust the feature values
iteratively. Generally speaking, unlabeled data
can be classified as in-domain data and out-of-
domain data. In previous works these two kinds
of unlabeled data are used separately for differ-
ent purposes. In-domain data is mainly used to
solve the problem of data sparseness (Sun and
Xu, 2011). On the other hand, out-of domain
data is used for domain adaptation (Chang and
Han, 2010). In our work, we use in-domain and
out-of-domain data together to adjust the labels
of the unlabeled corpus.
We evaluate the performance of CWS on the
benchmark dataset of Peking University in the
second International Chinese Word Segmenta-
tion Bakeoff. Experiment results show that our
approach yields improvements compared with
the state-of-art systems. Even when the la-
beled data is insufficient, our methods can still
work better than traditional methods. Com-
pared to the baseline CWS model, which has
already achieved an f-score above 0.95, we fur-
ther reduce the error rate by 15%.
Our method is not limited to word segmen-
tation. It is also applicable to other problems
which can be solved by sequence labeling mod-
els. We also applied our method to the Chi-
nese Named Entity Recognition task, and also
achieved better results compared to traditional
methods.
The main contributions of our work are as fol-
lows:
? We proposed a general method to utilize
the label distribution given text contexts as
representations in a semi-supervised frame-
work. We let the co-training process ad-
just the representation values from label
distribution instead of using manually pre-
defined feature templates.
? Compared with previous work, our method
achieved a new state-of-art accuracy on the
CWS task as well as on the NER task.
The remaining part of this paper is organized
as follows. Section 2 describes the details of the
problem and our algorithm. Section 3 describes
the experiment and presents the results. Section
4 reviews the related work. Section 5 concludes
this paper.
2 System Architecture
2.1 Sequence Labeling
Nowadays the character-based sequence label-
ing approach is widely used for the Chinese word
segmentation problem. It was first proposed in
Xue (2003), which assigns each character a label
to indicate its position in the word. The most
prevalent tag set is the BMES tag set, which
uses 4 tags to carry word boundary information.
This tag set uses B, M, E and S to represent the
Beginning, the Middle, the End of a word and
a Single character forming a word respectively.
We use this tag set in our method. An example
of the ?BMES? representation is shown in table
2.
Character: ? ? ? ? ? ? ?
Tag: S S B E B M E
Table 2: An example for the ?BMES? representa-
tion. The sentence is ????????? (I love Bei-
jing Tian-an-men square), which consists of 4 Chi-
nese words: ??? (I), ??? (love), ???? (Beijing),
and ????? (Tian-an-men square).
2.2 Unlabeled Data
Unlabeled data can be divided into in-domain
data and out-of-domain data. In previous works,
these two kinds of unlabeled data are used sep-
arately for different purposes. In-domain data
only solves the problem of data sparseness (Sun
and Xu, 2011). Out-of domain data is used
only for domain adaptation (Chang and Han,
2010). These two functionalities are not contra-
dictory but complementary. Our study shows
312
that by correctly designing features and algo-
rithms, both in-domain unlabeled data and out-
of-domain unlabeled data can work together to
help enhancing the segmentation model. In our
algorithm, the dynamic features learned from
one corpus can be adjusted incrementally with
the dynamic features learned from the other cor-
pus.
As for the out-of-domain data, it will be even
better if the corpus is not limited to a specific
domain. We choose a Chinese encyclopedia cor-
pus which meets exactly this requirement. We
use the corpus to learn a large set of informative
features. In our experiment, two different views
of features on unlabeled data are considered:
Static Statistical Features (SSFs): These
features capture statistical information of char-
acters and character n-grams from the unlabeled
corpus. The values of these features are fixed
during the training process once the unlabeled
corpus is given.
Dynamic Statistical Features (DSFs):
These features capture label distribution infor-
mation from the unlabeled corpus given fixed
text contexts. As the training process proceeds,
the value of these features will change, since the
trained tagger at each training iteration may as-
sign different labels to the unlabeled data.
2.3 Framework
Suppose we have labeled data L, two unla-
beled corpora Ua and Ub (one is an in-domain
corpus and the other is an out-of-domain cor-
pus). Our algorithm is shown in Table 3.
During each iteration, we tag the unlabeled
corpus Ua using Tb to get pseudo-labels. Then
we extract features from the pseudo-labels. We
use the label distribution information as dy-
namic features. We add these features to the
training data to train a new tagger Ta. To adjust
the feature values, we extract features from one
corpus and then apply the statistics to the other
corpus. This is similar to the principle of co-
training (Yarowsky, 1995; Blum and Mitchell,
1998; Dasgupta et al, 2002). The difference is
that there are not different views of features, but
different kinds of unlabeled data. Detailed de-
scription of features is given in the next section.
Algorithm
Init:
Using baseline features only:
Train an initial tagger T0 based on L ()
Label Ua and Ub individually using T0
BEGIN LOOP:
Generate DSFs from tagged Ua
Augment L with DSFs to get La
Generate DSFs from tagged Ub
Augment L with DSFs to get Lb
Using baseline features, SSFs and DSFs:
Train new tagger Ta using La
Train new tagger Tb using Lb
Label Ua using Tb
Label Ub using Ta
LOOP until performance does not improve
RETURN the tagger which is trained with
in-domain features.
Table 3: Algorithm description
2.4 Features
2.4.1 Baseline Features
Our baseline feature templates include the
features described in previous works (Sun and
Xu, 2011; Sun et al, 2012). These features are
widely used in the CWS task. To be convenient,
for a character ci with context . . . ci?1cici+1 . . .,
its baseline features are listed below:
? Character uni-grams: ck (i? 3 < k < i+3)
? Character bi-grams: ckck+1 (i ? 3 < k <
i+ 2)
? Whether ck and ck+1 are identical (i? 2 <
k < i + 2)
? Whether ck and ck+2 are identical (i? 4 <
k < i + 2)
The last two feature templates are designed to
detect character reduplication, which is a mor-
phological phenomenon in Chinese language.
An example is ?????? (Perfect), which is
a Chinese idiom with structure ?ABAC?.
313
2.4.2 Static statistical features
Statistical features are statistics that distilled
from the large unlabeled corpus. They are
proved useful in the Chinese word segmenta-
tion task. We define Static Statistical Features
(SSFs) as features whose value do not change
during the training process. The SSFs in our
approach includes Mutual information, Punctu-
ation information and Accessor variety. Previ-
ous works have already explored the functions
of the three static statistics in the Chinese word
segmentation task, e.g. Feng et al (2004); Sun
and Xu (2011). We mainly follow their defini-
tions while considering more details and giving
some modification.
Mutual information
Mutual information (MI) is a quantity that
measures the mutual dependence of two random
variables. Previous works showed that larger MI
of two strings claims higher probability that the
two strings should be combined. Therefore, MI
can show the tendency of two strings forming
one word. However, previous works mainly fo-
cused on the balanced case, i.e., the MI of strings
with the same length. In our study we find that,
in Chinese, there remains large amount of imbal-
anced cases, like a string with length 1 followed
by a string with length 2, and vice versa. We
further considered the MI of these string pairs
to capture more information.
Punctuation information
Punctuations can provide implicit labels for
the characters before and after them. The char-
acter after punctuations must be the first char-
acter of a word. The character before punctua-
tions must be the last character of a word. When
a string appears frequently after punctuations,
it tends to be the beginning of a word. The situ-
ation is similar when a string appears frequently
preceding punctuations. Besides, the probabil-
ity of a string appears in the corpus also affects
this tendency. Considering all these factors,
we propose ?punctuation rate? (PR) to capture
this information. For a string with length len
and probability p in the corpus, we define the
left punctuation rate LPRlen as the number of
times the string appears after punctuations, di-
vided by p. Similarly, the right punctuation
rate RPRlen is defines as the number of times
it appears preceding punctuations divided by its
probability p. The length of string we consider
is from 1 to 4.
Accessor variety
Accessor variety (AV) is also known as letter
successor variety (LSV) (Harris, 1955; Hafer and
Weiss, 1974). If a string appears after or pre-
ceding many different characters, this may pro-
vide some information of the string itself. Pre-
vious work of Feng et al (2004), Sun and Xu
(2011) used AV to represent this statistic. Sim-
ilar to punctuation rate, we also consider both
left AV and right AV. For a string s with length
l, we define the left accessor variety (LAV) as
the types of distinct characters preceding s in
the corpus, and the right accessor variety (RAV)
as the types of distinct characters after s in the
corpus. The length of string we consider is also
from 1 to 4.
2.4.3 Dynamic statistical features
The unlabeled corpus lacks precise labels. We
can use the trained tagger to give the unla-
beled data ?pseudo-labels?. These labels can-
not guarantee an acceptable precision. How-
ever, the label distribution will not be largely
affected by small mistakes. Using the label dis-
tribution information is more accurate than us-
ing the pseudo-labels directly.
Based on this assumption, we propose ?dy-
namic statistical features? (DSFs). The DSFs
are intended to capture label distribution infor-
mation given a text context. The word ?Dy-
namic? is in accordance with the fact that these
feature values will change during the training
process.
We give a formal description of DSFs. Sup-
pose there are K labels in our task. For example,
K = 4 if we take BMES labeling method. We
define the whole character sequence with length
n as X = (x1, x2 ? ? ?xj ? ? ?xn). Given a text con-
text Ci, where i is current character position,
the DSFs can be represented as a list,
DSF (Ci) = (DSF (Ci)1, ? ? ? , DSF (Ci)K)
314
Each element in the list represents the proba-
bility of the corresponding label in the distribu-
tion.
For convenience, we further define function
?count(condition)? as the total number of times
a ?condition? is true in the unlabeled corpus.
For example, count (current=?a?) represents the
times the current character equals ?a?, which is
exactly the number of times character ?a? ap-
pears in the unlabeled corpus.
According to different types of text context
Ci, we can divide DSFs into 3 types:
1.Basic DSF
For Basic DSF of Ci, we define D(Ci):
D(Ci) = (D(Ci)1, . . . , D(Ci)K)
We define Basic DSF with current character po-
sition i, text context Ci and label l (the lth di-
mension in the list) as:
D(Ci)l = P (y = l|Ci = xi)
= count(Ci = xi ? y = l)count(Ci = xi)
In this equation, the numerator counts the num-
ber of times current character is xi with label l.
The denominator counts the number of times
current character is xi.
We use the term ?Basic? because this kind of
DSFs only considers the character of position i
as its context. The text context refers to the cur-
rent character itself. This feature captures the
label distribution information given the charac-
ter itself.
2.BigramDSF
Basic DSF is simple and very easy to imple-
ment. The weakness is that it is less power-
ful to describe word-building features. Although
characters convey context information, charac-
ters themselves in Chinese is sometimes mean-
ingless. Character bi-grams can carry more con-
text information than uni-grams. We modify
Basic DSFs to bi-gram level and propose Bigram
DSFs.
For Bigram DSF of Ci, we define B(Ci):
B(Ci) = (B(Ci)1, . . . , B(Ci)K)
We define Bigram DSF with current character
position i, text context Ci and label l (the lth
dimension in the list) as:
B(Ci)l = P (y = l|Ci = xi?jxi?j+1)
= count(Ci = xi?jxi?j+1 ? y = l)count(Ci = xi?jxi?j+1)
j can take value 0 and 1.
In this equation, the numerator counts the
number of times current context is xi?jxi?j+1
with label l. The denominator counts the num-
ber of times current context is xi?jxi?j+1.
3.WindowDSF
Considering Basic DSF and Bigram DSF only
might cause the over-fitting problem, therefore
we introduce another kind of DSF. We call it
Window DSF, which considers the surrounding
context of a character and omits the character
itself.
For Window DSF, we define W (Ci):
W (Ci) = (W (Ci)1, . . . ,W (Ci)K)
We define Window DSF with current character
position i, text context Ci and label l (the lth
dimension in the list) as:
W (Ci)l = P (y = l|Ci = xi?1xi+1)
= count(Ci = xi?1xi+1 ? y = l)count(Ci = xi?1xi+1)
In this equation, the numerator counts the
number of times current context is xi?1xi+1
with label l. The denominator counts the num-
ber of times current context is xi?1xi+1.
2.4.4 Discrete features VS. Continuous
features
The statistical features may be expressed as
real values. A more natural way is to use dis-
crete values to incorporate them into the se-
quence labeling models . Previous works like
Sun and Xu (2011) solve this problem by set-
ting thresholds and converting the real value
into boolean values. We use a different method
to solve this, which does not need to consider
tuning thresholds. In our method, we process
static and dynamic statistical features using dif-
ferent strategies.
315
For static statistical value:
For mutual information, we round the real
value to their nearest integer. For punctuation
rate and accessor variety, as the values tend to
be large, we first get the log value of the feature
and then use the nearest integer as the corre-
sponding discrete value.
For dynamic statistical value:
Dynamic statistical features are distributions
of a label. The values of DSFs are all percentage
values. We can solve this by multiply the proba-
bility by an integer N and then take the integer
part as the final feature value. We set the value
of N by cross-validation..
2.5 Conditional Random Fields
Our algorithm is not necessarily limited to
a specific baseline tagger. For simplicity and
reliability, we use a simple Conditional Ran-
dom Field (CRF) tagger, although other se-
quence labeling models like Semi-Markov CRF
Gao et al (2007) and Latent-variable CRF Sun
et al (2009) may provide better results than
a single CRF. Detailed definition of CRF can
be found in Lafferty et al (2001); McCallum
(2002); Pinto et al (2003).
3 Experiment
3.1 Data and metrics
We used the benchmark datasets provided by
the second International Chinese Word Segmen-
tation Bakeoff1 to test our approach. We chose
the Peking University (PKU) data in our exper-
iment. Although the benchmark provides an-
other three data sets, two of them are data of
traditional Chinese, which is quite different from
simplified Chinese. Another is the data from Mi-
crosoft Research (MSR). We experimented on
this data and got 97.45% in f-score compared
to the state-of-art 97.4% reported in Sun et al
(2012). However, this corpus is much larger
than the PKU corpus. Using the labeled data
alone can get a relatively good tagger and the
unlabeled data contributes little to the perfor-
mance. For simplicity and efficiency, our further
1http://www.sighan.org/bakeoff2005/
experiments are all conducted on the PKU data.
Details of the PKU data are listed in table 4.
We also used two un-segmented corpora as
unlabeled data. The first one is Chinese Giga-
word2 corpus. It is a comprehensive archive of
newswire data. The second one is articles from
Baike3 of baidu.com. It is a Chinese encyclope-
dia similar to Wikipedia but contains more Chi-
nese items and their descriptions. In the exper-
iment we used about 5 million characters from
each corpus for efficiency. Details of unlabeled
data can be found in table 5.
In our experiment, we did not use any ex-
tra resources such as common surnames, part-
of-speech or other dictionaries.
F-score is used as the accuracy measure. We
define precision P as the percentage of words
in the output that are segmented correctly. We
define recall R as the percentage of the words
in reference that are correctly segmented. Then
F-score is as follows:
F = 2 ? P ?RP +R
The recall of out-of-vocabulary is also taken into
consideration, which measures the ability of the
model to correctly segment out of vocabulary
words.
3.2 Main Results
Table 6 summarizes the segmentation results
on test data with different feature combinations.
We performed incremental evaluation. In this
table, we first present the results of the tagger
only using baseline features. Then we show the
results of adding SSF and DSF individually. In
the end we compare the results of combining
SSF and DSF with baseline features.
Because the baseline features is strong to
reach a relative good result, it is not easy to
largely enhance the performance. Neverthe-
less, there are significant increases in f-score and
OOV-Recall when adding these features. From
table 6 we can see that by adding SSF and DSF
individually, the F-score is improved by +1.1%
2http://www.ldc.upenn.edu/Catalog/
catalogEntry.jsp?catalogId=LDC2003T09
3http://baike.baidu.com/
316
Identical words Total word Identical Character Total character
5.5 ? 104 1.1 ? 106 5 ? 103 1.8 ? 106
Table 4: Details of the PKU data
Corpus Character used
Gigaword 5000193
Baike 5000147
Table 5: Details of the unlabeled data.
P R F OOV
Baseline 0.950 0.943 0.946 0.676
+SSF 0.961 0.953 0.957 0.728
+DSF 0.958 0.953 0.955 0.678
+SSF+DSF 0.965 0.958 0.961 0.731
Table 6: Segmentation results on test data with
different feature combinations. The symbol ?+?
means this feature configuration contains features set
containing the baseline features and all features after
?+?. The size of unlabeled data is fixed as 5 million
characters.
and +0.9%. The OOV-Recall is also improved,
especially after adding SSFs. When considering
SSF and DSF together, the f-score is improved
by +1.5% while the OOV-Recall is improved by
+5.5%.
To compare the contribution of unlabeled
data, we conduct experiments of using differ-
ent sizes of unlabeled data. Note that the SSFs
are still calculated using all the unlabeled data.
However, each iteration in the algorithm uses
unlabeled data with different sizes.
Table 7 shows the results when changing the
size of unlabeled data. We experimented on
three different sizes: 0.5 million, 1 million and 5
million characters.
P R F OOV
DSF(0.5M) 0.962 0.954 0.958 0.727
DSF(1M) 0.963 0.955 0.959 0.728
DSF(5M) 0.965 0.958 0.961 0.731
Table 7: Comparison of results when changing the
size of unlabeled data. (0.5 million, 1 million and 5
million characters).
We further experimented on unlabeled corpus
with larger size (up to 100 million characters).
However the performance did not change signif-
icantly. Besides, because the number of features
in our method is very large, using too large un-
labeled corpus is intractable in real applications
due to the limitation of memory.
Our method can keep working well even when
the labeled data are insufficient. Table 8 shows
the comparison of f-scores when changing the
size of labeled data. We compared the results
of using all labeled data with 3 different situa-
tions: using 1/10, 1/2 and 1/4 of all the labeled
data. In fact, the best system on the Second In-
ternational Chinese Word Segmentation bakeoff
reached 0.95 in f-score by using all labeled data.
From table 8 we can see that our algorithm only
needs 1/4 of all labeled data to achieve the same
f-score.
Baseline +SSF+DSF Improve
1/10 0.934 0.943 +0.96%
1/4 0.946 0.951 +0.53%
1/2 0.952 0.956 +0.42%
All 0.957 0.961 +0.42%
Table 8: Comparison of f-scores when changing the
size of labeled data. (1/10, 1/4, 1/2 and all labeled
data. The size of unlabeled data is fixed as 5 million
characters.)
We also explored how the performance
changes as iteration increases. Figure 1 shows
the change of F-score during the first 10 itera-
tions. From figure 1 we find that f-score has a
fast improvement in the first few iterations, and
then stables at a fixed point. Besides, as the size
of labeled data increases, it converges faster.
Using an in-domain corpus and an out-of-
domain corpus is better than use one corpus
alone. We compared our approach with the
method which uses only one unlabeled corpus.
To use only one corpus, we modify our algorithm
to extract DSFs from the Chinese Giga word
corpus and apply the learned features to itself.
317
Figure 1: Learning curve of using different size of
labeled data
Table 9 shows the result. We can see that our
method outperforms by +0.2% in f-score and
+0.7% in OOV-Recall.
Finally, we compared our method with the
state-of-art systems reported in the previous pa-
pers. Table 10 listed the results. Best05 repre-
sents the best system reported on the Second In-
ternational Chinese Word Segmentation Bake-
off. CRF + Rule system represents a combina-
tion of CRF model and rule based model pre-
sented in Zhang et al (2006). Other three sys-
tems all represent the methods using their cor-
responding model in the corresponding papers.
Note that these state-of-art systems are either
using complicated models with semi-Markov re-
laxations or latent variables, or modifying mod-
els to fit special conditions. Our system uses a
single CRF model. As we can see in table 10,
our method achieved higher F-scores than the
previous best systems.
3.3 Results on NER task
Our method is not limited to the CWS prob-
lem. It is applicable to all sequence labeling
problems. We applied our method on the Chi-
nese NER task. We used the MSR corpus of
the sixth SIGHAN Workshop on Chinese Lan-
guage Processing. It is the only NER corpus
using simplified Chinese in that workshop. We
compared our method with the pure sequence la-
beling approach in He and Wang (2008). We re-
implemented their method to eliminate the dif-
ference of various CRFs implementations. Ex-
periment results are shown in table 11. We can
see that our methods works better, especially
when handling the out-of-vocabulary named en-
tities;
4 Related work
Recent studies show that character sequence
labeling is an effective method of Chinese word
segmentation for machine learning (Xue, 2003;
Low et al, 2005; Zhao et al, 2006a,b). These su-
pervised methods show good results. Unsuper-
vised word segmentation (Maosong et al, 1998;
Peng and Schuurmans, 2001; Feng et al, 2004;
Goldwater et al, 2006; Jin and Tanaka-Ishii,
2006) takes advantage of the huge amount of raw
text to solve Chinese word segmentation prob-
lems. These methods need no annotated corpus,
and most of them use statistics to help model
the problem. However, they usually are less ac-
curate than supervised ones.
Currently ?feature-engineering? methods
have been successfully applied into NLP ap-
plications. Miller et al (2004) applied this
method to named entity recognition. Koo et al
(2008) applied this method to dependency pars-
ing. Turian et al (2010) applied this method to
both named entity recognition and text chunk-
ing. These papers shared the same concept of
word clustering. However, we cannot simply
equal Chinese character to English word because
characters in Chinese carry much less informa-
tion than words in English and the clustering
results is less meaningful.
Features extracted from large unlabeled cor-
pus in previous works mainly focus on statisti-
cal information of characters. Feng et al (2004)
used the accessor variety criterion to extract
word types. Li and Sun (2009) used punctua-
tion information in Chinese word segmentation
by introducing extra labels ?L? and ?R?. Chang
and Han (2010), Sun and Xu (2011) used rich
statistical information as discrete features in
a sequence labeling framework. All these ap-
proaches can be viewed as using static statistics
features in a supervised approach. Our method
is different from theirs. For the static statistics
features in our approach, we not only consider
richer string pairs with the different lengths, but
also consider term frequency when processing
318
P R F OOV
Using one corpus 0.963 0.955 0.959 0.724
Our method 0.965 0.958 0.961 0.731
Table 9: Comparison of our approach with using only the Gigaword corpus
Method P R F-score
Best05 (Chen et al (2005)) 0.953 0.946 0.950
CRF + rule-system (Zhang et al (2006)) 0.947 0.955 0.951
Semi-perceptron (Zhang and Clark (2007)) N/A N/A 0.945
Latent-variable CRF (Sun et al (2009)) 0.956 0.948 0.952
ADF-CRF (Sun et al (2012)) 0.958 0.949 0.954
Our method 0.965 0.958 0.961
Table 10: Comparison of our approach with the state-of-art systems
P R F OOV
Traditional 0.925 0.872 0.898 0.712
Our method 0.916 0.887 0.902 0.737
Table 11: Comparison of our approach with tradi-
tional NER systems
punctuation features.
There are previous works using features ex-
tracted from label distribution of unlabeled cor-
pus in NLP tasks. Schapire et al (2002) use a
set of features annotated with majority labels
to boost a logistic regression model. We are
different from their approach because there is
no pseudo-example labeling process in our ap-
proach. Qi et al (2009) investigated on large
set of distribution features and used these fea-
tures in a self-training way. They applied the
method on three tasks: named entity recogni-
tion, POS tagging and gene name recognition
and got relatively good results. Our approach is
different from theirs. Although we all consider
label distribution, the way we use features are
different. Besides, our approach uses two unla-
beled corpora which can mutually enhancing to
get better result.
5 Conclusion and Perspectives
In this paper, we presented a semi-supervised
method for Chinese word segmentation. Two
kinds of new features are used for the itera-
tive modeling: static statistical features and dy-
namic statistical features. The dynamic statis-
tical features use label distribution information
for text contexts, and can be adjusted automat-
ically during the co-training process. Experi-
mental results show that the new features can
improve the performance on the Chinese word
segmentation task. We further conducted exper-
iments to show that the performance is largely
improved, especially when the labeled data is
insufficient.
The proposed iterative semi-supervised
method is not limited to the Chinese word
segmentation task. It can be easily extended
to any sequence labeling task. For example, it
works well on the NER task as well. As our
future work, we plan to apply our method to
other natural language processing tasks, such
as text chunking.
Acknowledgments
This research was partly supported by Ma-
jor National Social Science Fund of China(No.
12&ZD227),National High Technology Research
and Development Program of China (863 Pro-
gram) (No. 2012AA011101) and National Natu-
ral Science Foundation of China (No.91024009).
We also thank Xu Sun and Qiuye Zhao for proof-
reading the paper.
319
References
Blum, A. and Mitchell, T. (1998). Combining
labeled and unlabeled data with co-training.
In Proceedings of the eleventh annual confer-
ence on Computational learning theory, pages
92?100. ACM.
Chang, B. and Han, D. (2010). Enhancing
domain portability of chinese segmentation
model using chi-square statistics and boot-
strapping. In Proceedings of the 2010 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 789?798. Association
for Computational Linguistics.
Chen, A., Zhou, Y., Zhang, A., and Sun, G.
(2005). Unigram language model for chinese
word segmentation. In Proceedings of the
4th SIGHAN Workshop on Chinese Language
Processing, pages 138?141. Association for
Computational Linguistics Jeju Island, Korea.
Dasgupta, S., Littman, M. L., and McAllester,
D. (2002). Pac generalization bounds for co-
training. Advances in neural information pro-
cessing systems, 1:375?382.
Feng, H., Chen, K., Deng, X., and Zheng, W.
(2004). Accessor variety criteria for chinese
word extraction. Computational Linguistics,
30(1):75?93.
Gao, J., Andrew, G., Johnson, M., and
Toutanova, K. (2007). A comparative study
of parameter estimation methods for statisti-
cal natural language processing. In ANNUAL
MEETING-ASSOCIATION FOR COMPU-
TATIONAL LINGUISTICS, volume 45, page
824.
Goldwater, S., Griffiths, T., and Johnson, M.
(2006). Contextual dependencies in unsuper-
vised word segmentation. In Proceedings of
the 21st International Conference on Compu-
tational Linguistics and the 44th annual meet-
ing of the Association for Computational Lin-
guistics, pages 673?680. Association for Com-
putational Linguistics.
Hafer, M. A. and Weiss, S. F. (1974). Word seg-
mentation by letter successor varieties. Infor-
mation storage and retrieval, 10(11):371?385.
Harris, Z. S. (1955). From phoneme to mor-
pheme. Language, 31(2):190?222.
He, J. and Wang, H. (2008). Chinese named en-
tity recognition and word segmentation based
on character. In Sixth SIGHAN Workshop on
Chinese Language Processing, page 128.
Jin, Z. and Tanaka-Ishii, K. (2006). Unsu-
pervised segmentation of chinese text by use
of branching entropy. In Proceedings of the
COLING/ACL on Main conference poster
sessions, pages 428?435. Association for Com-
putational Linguistics.
Koo, T., Carreras, X., and Collins, M. (2008).
Simple semi-supervised dependency parsing.
Lafferty, J., McCallum, A., and Pereira, F.
(2001). Conditional random fields: Proba-
bilistic models for segmenting and labeling se-
quence data.
Li, Z. and Sun, M. (2009). Punctuation
as implicit annotations for chinese word
segmentation. Computational Linguistics,
35(4):505?512.
Low, J., Ng, H., and Guo, W. (2005). A
maximum entropy approach to chinese word
segmentation. In Proceedings of the Fourth
SIGHAN Workshop on Chinese Language
Processing, volume 164. Jeju Island, Korea.
Maosong, S., Dayang, S., and Tsou, B. (1998).
Chinese word segmentation without using lex-
icon and hand-crafted training data. In Pro-
ceedings of the 17th international confer-
ence on Computational linguistics-Volume 2,
pages 1265?1271. Association for Computa-
tional Linguistics.
McCallum, A. (2002). Efficiently inducing fea-
tures of conditional random fields. In Proceed-
ings of the Nineteenth Conference on Uncer-
tainty in Artificial Intelligence, pages 403?410.
Morgan Kaufmann Publishers Inc.
Miller, S., Guinness, J., and Zamanian, A.
(2004). Name tagging with word clusters
and discriminative training. In Proceedings of
HLT-NAACL, volume 4.
Peng, F. and Schuurmans, D. (2001). Self-
supervised chinese word segmentation. Ad-
320
vances in Intelligent Data Analysis, pages
238?247.
Pinto, D., McCallum, A., Wei, X., and Croft,
W. (2003). Table extraction using conditional
random fields. In Proceedings of the 26th an-
nual international ACM SIGIR conference on
Research and development in informaion re-
trieval, pages 235?242. ACM.
Qi, Y., Kuksa, P., Collobert, R., Sadamasa,
K., Kavukcuoglu, K., and Weston, J. (2009).
Semi-supervised sequence labeling with self-
learned features. In Data Mining, 2009.
ICDM?09. Ninth IEEE International Confer-
ence on, pages 428?437. IEEE.
Schapire, R., Rochery, M., Rahim, M., and
Gupta, N. (2002). Incorporating prior
knowledge into boosting. In MACHINE
LEARNING-INTERNATIONAL WORK-
SHOP THEN CONFERENCE-, pages
538?545.
Sun, W. and Xu, J. (2011). Enhancing chi-
nese word segmentation using unlabeled data.
In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing,
pages 970?979. Association for Computational
Linguistics.
Sun, X., Wang, H., and Li, W. (2012). Fast on-
line training with frequency-adaptive learning
rates for chinese word segmentation and new
word detection. In Proceedings of the 50th An-
nual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers),
pages 253?262, Jeju Island, Korea. Associa-
tion for Computational Linguistics.
Sun, X., Zhang, Y., Matsuzaki, T., Tsuruoka,
Y., and Tsujii, J. (2009). A discriminative
latent variable chinese segmenter with hybrid
word/character information. In Proceedings of
Human Language Technologies: The 2009 An-
nual Conference of the North American Chap-
ter of the Association for Computational Lin-
guistics, pages 56?64. Association for Compu-
tational Linguistics.
Turian, J., Ratinov, L., and Bengio, Y. (2010).
Word representations: a simple and gen-
eral method for semi-supervised learning. In
Proceedings of the 48th Annual Meeting of
the Association for Computational Linguis-
tics, pages 384?394. Association for Compu-
tational Linguistics.
Xue, N. (2003). Chinese word segmentation as
character tagging. Computational Linguistics
and Chinese Language Processing, 8(1):29?48.
Yarowsky, D. (1995). Unsupervised word sense
disambiguation rivaling supervised methods.
In Proceedings of the 33rd annual meeting
on Association for Computational Linguistics,
pages 189?196. Association for Computational
Linguistics.
Zhang, R., Kikui, G., and Sumita, E. (2006).
Subword-based tagging by conditional ran-
dom fields for chinese word segmentation. In
Proceedings of the Human Language Technol-
ogy Conference of the NAACL, Companion
Volume: Short Papers, pages 193?196. Asso-
ciation for Computational Linguistics.
Zhang, Y. and Clark, S. (2007). Chi-
nese segmentation with a word-based percep-
tron algorithm. In ANNUAL MEETING-
ASSOCIATION FOR COMPUTATIONAL
LINGUISTICS, volume 45, page 840.
Zhao, H., Huang, C., and Li, M. (2006a). An
improved chinese word segmentation system
with conditional random field. In Proceed-
ings of the Fifth SIGHAN Workshop on Chi-
nese Language Processing, volume 117. Syd-
ney: July.
Zhao, H., Huang, C., Li, M., and Lu, B. (2006b).
Effective tag set selection in chinese word seg-
mentation via conditional random field mod-
eling. In Proceedings of PACLIC, volume 20,
pages 87?94.
321
Chinese word segmentation model using bootstrapping 
Baobao Chang and Mairgup Mansur 
Institute of Computational Linguistics, Peking University 
Key Laboratory of Computational Linguistics(Peking University),  
Ministry Education, China 
chbb@pku.edu.cn, mairgup@yahoo.com.cn 
 
Abstract 
We participate in the CIPS-SIGHAN-
2010 bake-off task of Chinese word 
segmentation. Unlike the previous 
bakeoff series, the purpose of the 
bakeoff 2010 is to test the cross-
domain performance of Chinese seg-
mentation model. This paper summa-
rizes our approach and our bakeoff re-
sults. We mainly propose to use ?2 sta-
tistics to increase the OOV recall and 
use bootstrapping strategy to increase 
the overall F score. As the results 
shows, the approach proposed in the 
paper does help, both of the OOV re-
call and the overall F score are im-
proved. 
1 Introduction 
After more than twenty years of intensive re-
searches, considerable progress has been made 
in improving the performance of Chinese word 
segmentation. The bakeoff series hosted by the 
ACL SIGHAN shows that high F scores can be 
achieved in the closed test tracks, in which 
only specified training materials can be used in 
learning segmentation models. 
Instead of using lexicon-driven approaches, 
state-of-art Chinese word segmenter now use 
character tagging model as Xue(2003) firstly 
proposed. In character tagging model, no pre-
defined Chinese lexicons are required; a tag-
ging model is learned using manually seg-
mented training texts. The model is then used 
to assign each character a tag indicating the 
position of this character within word. Xue?s 
approach has been become the most popular 
approach to Chinese word segmentation for its 
high performance and unified way to deal with 
OOV issues. Most of the segmentation works 
since then follow this approach. Major im-
provements in this line of research including: 1) 
More sophisticated learning models were in-
troduced instead of the maximum entropy 
model that Xue used, like conditional random 
fields (CRFs) model which fit the sequence 
tagging tasks much better than maximum en-
tropy model (Tseng et al,2005). 2) More tags 
were introduced, as Zhao et al (2006) shows 6 
tags are superior to 4 tags in achieving high 
performance. 3) New feature templates were 
added, such as templates used in representing 
numbers, dates, letters etc. (Low et al, 2005)  
Usually, the performance of segmentation 
model is evaluated on a test set from the same 
domain as the training set. Such evaluation 
does not reveal its ability to deal with domain 
variation. It is believed that, when test set is 
from other domains than the domain where 
training set is from, the learned model nor-
mally underperforms substantially.  
The CIPS-SIGHAN-2010 bake-off task of 
Chinese word segmentation is set to focus on 
the cross-domain performance of Chinese 
word segmentation model.  
We participate in the closed test track for 
simplified Chinese. Different with the previous 
bakeoffs, CIPS-SIGHAN-2010 bake-off pro-
vides both label corpus and unlabeled corpora. 
The labeled corpus is composed of texts from 
newspaper and has about 1.1 million words in 
total. The two unlabeled corpora cover two 
domains: literature and computer science, and 
each domain have about 100K characters in 
size. The test corpora cover four domains, two 
of which are literature and computer science, 
and the other two domains are unknown before 
releasing. 
We build the Chinese word segmenter fol-
lowing the character tagging model. Instead of 
using CRF model, we use the hidden Markov 
support vector machines (Altun et al, 2003), 
which is also a sequence labeling model like 
CRF. We just show it can also be used to 
model Chinese segmentation tasks as an alter-
native other than CRF. To increase the ability 
of the model to recall OOV words, we propose 
to use ?2 statistics and bootstrapping strategy 
to the overall performance of the model to out-
of-domain texts.  
2 The hidden Markov support vector 
machines 
The hidden Markov support vector machine 
(SVM-HMM) is actually a special case of the 
structural support vector machines proposed by 
Tsochantaridis et al(2005) which is a powerful 
model to structure predication problem. It dif-
fers from support vector machine in its ability 
to model complex structured problems and 
shares the max-margin training principles with 
support vector machines. The hidden Markov 
support vector machine model is inspired by 
the hidden Markov model and is an instance of 
structural support vector machine dedicated to 
solve sequence labeling learning, a problem 
that CRF model is assumed to solve. In the 
SVM-HMM model, the sequence labeling 
problems is modeled by learning a discrimi-
nant function F: X?Y?R over the input se-
quence and the label sequence pairs, thus pre-
diction of label sequence can be derived by 
maximizing F over all possible label sequences 
for a specific given input sequence x.  
);,(maxarg);( wyxwx
y
Ff
Y?
=  
In the structural SVMs, F is assumed to be lin-
ear in some combined feature representation of 
the input sequence and the label sequence 
?(x,y), i.e. 
),(,);,( yx?wwyx =F  
where w denotes a parameter vector. For the 
SVM-HMMs, the discriminant function is de-
fined as follows.  
? ??
??
?=
=
?? ??
+
??
+
=
1..1
..1
'
1
', )',(),(?
),()(,);,(
Tt
Tt
y y
tt
yy
y
tt
y
yyyy
yyyxF
???
?
w
x?ww
 
Here )?,( www = , ?(xt) is the vector of fea-
tures of the input sequence.  
Like SVMs, parameter vector w is learned 
with maximum margin principle using training 
data. To control the complexity of the training 
problem, cutting plane method is proposed to 
solve the resulted constrained optimization 
problem. Thus only small subset of constraints 
from the full-sized optimization is checked to 
ensure a sufficiently accurate solution. 
Roughly speaking, SVM-HMM differs with 
CRF in its principle of training, both of them 
could be used to deal with sequence labeling 
problem like Chinese word segmentation. 
3 The tag set and the basic feature 
templates 
As most of other works on segmentation, we 
use a 4-tag tagset, that is S for character being 
a single-character-word by itself, B for charac-
ter beginning a multi-character-word, E for 
character ending a multi-character-word and M 
for a character occurring in the middle of a 
multi-character-word. 
We use the following feature template, like 
most of segmentation works widely used: 
(a) Cn (n = -2, -1, 0, 1, 2) 
(b) CnCn+1 (n = -2, -1, 0, 1) 
(c) C-1C+1  
Here C refers to character; n refers to the posi-
tion index relative to the current character. By 
setting the above feature templates, we actually 
set a 5-character window to extract features, 
the current character, 2 characters to its left 
and 2 characters to its right.   
In addition, we also use the following fea-
ture templates to extract features representing 
character type. The closed test track of CIPS-
SIGHAN-2010 bake-off allows participants to 
use four character types, which are Chinese 
Character, English Letter, digits and punctua-
tions: 
(d) Tn (n = -2, -1, 0, 1, 2) 
(e) TnTn+1 (n = -2, -1, 0, 1) 
(f) T-1T+1 
Here T refers to character type, its value can be 
digit, letter, punctuation or Chinese character.  
4 The ?2 statistic features 
One of reasons of the performance degrada-
tion lies in the model?s ability to cope with 
OOV words while working with the out-of-
domain texts. Aiming at preventing the OOV 
recall from dropping sharply, we propose to 
use ?2 statistics as features to the segmentation 
model. 
?2 test is one of hypothesis test methods, 
which can be used to test if two events co-
occur just by chance or not. A lower ?2 score 
normally means the two co-occurred events are 
independent; otherwise they are dependent on 
each other. Hence, ?2 statistics could also be 
used to deal with the OOV issue in segmenta-
tion models. The idea is very straightforward. 
If two adjacent characters in the test set have a 
higher ?2 score, it is highly likely they form a 
word or are part of a word even they are not 
seen in the training set.  
We only compute ?2 score for character bi-
grams in the training texts and test texts. The 
?2 score of a bigram  C1C2 can be computed by 
the following way. 
)()()()(
)(),(
2
21
2
dcdbcaba
cbdanCC +?+?+?+
????=?
Here,  
a refers to all counts of bigram C1C2 in the 
text; 
b refers to all counts of bigrams that C1 oc-
curs but C2 does not; 
c refers to all counts of bigrams that C1 does 
not occur but C2 occurs; 
d refers to all counts of bigrams that both C1 
and C2 do not occur.  
n refers to total counts of all bigrams in the 
text, apparently, n=a+b+c+d. 
We do the ?2 statistics computation to the 
training texts and the test texts respectively. To 
make the ?2 statistics from the training texts 
and test texts comparable, we normalize the ?2 
score by the following formula.  
??
???
? ??
?= 10),(),( 2
min
2
max
2
min21
2
21
2
??
??? CCCCnorm  
Then we incorporate the normalized ?2 statis-
tics into the SVM-HMM model by adding two 
more feature templates as follows: 
(g) XnXn+1 (n = -2, -1, 0, 1) 
(h) X-1X+1 
The value of the feature XnXn+1 is the normal-
ized ?2 score of the bigram CnCn+1. Note we 
also compute the normalized ?2 score to bi-
gram C-1C+1. 
Because the normalized ?2 score is one of 
11 possible values 0, 1, 2, ?, 10,  templates 
(g)-(h) generate 55 features in total.   
All features generated from the templates 
(a)-(f) together with the 55 ?2 features form the 
whole feature set. The training texts and test 
texts are then converted into their feature rep-
resentations. The feature representation of the 
training texts is then used to learn the model 
and the feature representation of the test texts 
is used for segmentation. By this way, we ex-
pect that an OOV word in the test texts might 
be found by the segmentation model if the bi-
grams extracted from this word take higher ?2 
scores.  
5 the bootstrapping strategy 
The addition of the ?2 features can be also 
harmful. Even though it could increase the 
OOV recall, it also leads to drops in IV recall 
as we found. To keep the IV recall from falling 
down, we propose to use bootstrapping strat-
egy. Specifically, we choose to use both mod-
els with ?2 features and without ?2 features. 
We train two models firstly, one is ?2-based 
and another not. Then we do the segmentation 
to the test text with the two models simultane-
ously. Two segmentation results can be ob-
tained. One result is produced by the ?2-based 
model and has a high OOV recall. The other 
result is produced by the non-?2-based model 
and has higher IV recall. Then we do intersec-
tion operation to the two results. It is not diffi-
cult to understand that the intersection of the 
two results has both high OOV recall and high 
IV recall. We then put the intersection results 
into the training texts to form a new training 
set. By this new training set, we train again to 
get two new models, one ?2-based and another 
not. Then the two new models are used to 
segment the test texts. Then we do again inter-
section to the two results and the common 
parts are again put into the training texts. We 
repeat this process until a plausible result is 
obtained. 
The whole process can be informally de-
scribed as the following algorithm: 
1. let training set T to be the original 
training set; 
2. for I = 0 to K 
1) train a ?2-based model and a non-
?2-base model separately using 
training set T; 
2) use both models to segment test 
texts; 
3) do intersection to the two segmen-
tation results 
4) put the intersection results into the 
training set and get the enlarged 
training set T 
3. train the non-?2-based model using 
training set T, and take the output of 
this model as the final output; 
4. end. 
6 The evaluation results 
The labeled training texts released by the 
bakeoff are mainly composed of texts from 
newspaper. A peculiarity of the training data is 
that all Arabic numbers, Latin letters and punc-
tuations in the data are double-byte codes. As 
in Chinese texts, there are actually two ver-
sions of codes for Arabic numbers, Latin let-
ters and punctuations: one is single-byte codes 
defined by the western character encoding 
standard; another is double-byte codes defined 
by the Chinese character encoding standards. 
Chinese normally use both versions without 
distinguishing them strictly. 
The four final test sets released by the bake-
off cover four domains, the statistics of the test 
sets are shown in table-1. (the size is measured 
in characters)  
 
 
 
Table-1. Test sets statistics 
test set domain  size  OOV rate
A Literature 51K 0.069
B Computer 64K 0.152
C Medicines 52K 0.110
D Finance 56K 0.087
 
We train all models using SVM-HMMs1, we 
set ? to 0.25. This is a parameter to control the 
accuracy of the solution of the optimization 
problem. We set C to half of the number of the 
sentences in the training data. The C parameter 
is set to trade off the margin size and training 
error. We also set a cutoff frequency to feature 
extraction. Only features are seen more than 
three times in training data are actually used in 
the models. We set K = 3 and run the algo-
rithm shown in section 5. This gives our final 
bakeoff results shown in Table-2. 
To illustrate whether the ?2 statistics and 
bootstrapping strategy help or not, we also 
show two intermediate results using the online 
scoring system provided by the bakeoff2.Table-
3 shows the results of the initial non-?2-based 
model using feature template (a)-(f), table-4 
shows results of the initial ?2-based model us-
ing feature template (a)-(h). 
As we see from the table-1, table-3 and ta-
ble-4, the approach present in this paper does 
improve both the overall performance and the 
OOV recalls in all four domains.  
 
Table-3 Results of initial non-?2-based model 
test set R P F Roov
A 0.921 0.924 0.923 0.632
B 0.930 0.904 0.917 0.758
C 0.919 0.906 0.913 0.687
D 0.946 0.924 0.935 0.750
 
                                                 
1http://www.cs.cornell.edu/People/tj/svm_light/svm_hm
m.html 
2 http://nlp.ict.ac.cn/demo/CIPS-SIGHAN2010/# 
Table-2. The bakeoff results 
test set R P F Riv Roov
A 0.925 0.931 0.928 0.944 0.667
B 0.941 0.916 0.928 0.967 0.796
C 0.928 0.918 0.923 0.953 0.730
D 0.948 0.928 0.937 0.965 0.761
 
Table-4 Results of initial ?2-based model 
test set R P F Roov
A 0.898 0.921 0.910 0.673
B 0.925 0.914 0.920 0.801
C 0.916 0.922 0.919 0.764
D 0.931 0.937 0.934 0.821
 
We also do a rapid manual check to the final 
results; one of the main sources of errors lies in 
the approach failing to recall numbers encoded 
by one-byte codes digits. For the labeled train-
ing corpus provided by the bakeoff almost do 
not use one-byte codes for digits, and the type 
feature seems do not help too much. Actually, 
such numbers can be recalled by simple heuris-
tics using regular expressions. We do a simple 
number recognition to the test set of domain D. 
this will increase the F score from 0.937 to 
0.957.  
  
7 Conclusions 
This paper introduces the approach we used 
in the CIPS-SIGHAN-2010 bake-off task of 
Chinese word segmentation. We propose to 
use ?2 statistics to increase OOV recall and use 
bootstrapping strategy to increase the overall 
performance. As our final results shows, the 
approach works in increasing both of the OOV 
recall and overall F-score.    
We also show in this paper that hidden 
Markov support vector machine can be used to 
model the Chinese word segmentation problem, 
by which high f-score results can be obtained 
like CRF model. 
Acknowledgements 
This work was supported by National Natu-
ral Science Foundation of China under Grant 
No. 60975054 and National Social Science 
Foundation of China under Grant No. 
06BYY048. 
We want to thank Professor Duan Huiming 
and Mr. Han Dongxu for their generous help at 
the data preprocessing works. 
References 
Liang, Nanyuan, 1987. ??written Cinese text seg-
mentation system--cdws?. Journal of Chinese In-
formation Processing, Vol.2, NO.2,pp44?52.(in 
Chinese) 
Gao, Jianfeng et al, 2005, Chinese Word Segmen-
tation and Named Entity Recognition: A Prag-
matic Approach, Computational Linguis-
tics,Vol.31, No.4, pp531-574. 
Huang, Changning et al 2007, Chinese word seg-
mentation: a decade review. Journal of Chinese 
Information Processing, Vol.21, NO.3,pp8?
19.(in Chinese) 
Tseng, Huihsin et al, 2005, A conditional random 
field word segmenter for SIGHAN 2005, Pro-
ceedings of the fourth SIGHAN workshop on 
Chinese language processing. Jeju Island, Korea. 
pp168-171 
Xue, Nianwen, 2003, Chinese Word Segmentation 
as Character Tagging, Computational Linguistics 
and Chinese Language Processing. Vol.8, No.1, 
pp29-48. 
Zhao, Hai et al, 2006, Effective tag set selection in 
Chinese word segmentation via conditional ran-
dom field modeling, Proceedings of the 20th Pa-
cific Asia Conference on language, Information 
and Computation (PACLIC-20), Wuhan, China, 
pp87-94  
Tsochantaridis,Ioannis et al, 2005, Large Margin 
Methods for Structured and Interdependent Out-
put Variables, Journal of Machine Learning Re-
search (JMLR), No.6, pp1453-1484.  
Altun,Yasemin et al,2003, Hidden Markov Support 
Vector Machines. Proceedings of the Twentieth 
International Conference on Machine Learning 
(ICML-2003), Washington DC, 2003. 
Low, Jin Kiat et al,2005, A Maximum Entropy 
Approach to Chinese Word Segmentation. Pro-
ceedings of the Fourth SIGHAN Workshop on 
Chinese Language Processing, Jeju Island, Ko-
rea,. pp161-164 
 
