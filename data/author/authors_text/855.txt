27
28
29
30
31
32
33
34
Proceedings of the Fourth International Natural Language Generation Conference, pages 25?32,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Individuality and Alignment in Generated Dialogues
Amy Isard and Carsten Brockmann and Jon Oberlander
School of Informatics, University of Edinburgh
2 Buccleuch Place
Edinburgh EH8 9LW, UK
{Amy.Isard, Carsten.Brockmann, J.Oberlander}@ed.ac.uk
Abstract
It would be useful to enable dialogue
agents to project, through linguistic
means, their individuality or personality.
Equally, each member of a pair of agents
ought to adjust its language (to a greater or
lesser extent) to match that of its interlocu-
tor. We describe CRAG, which generates
dialogues between pairs of agents, who are
linguistically distinguishable, but able to
align. CRAG-2 makes use of OPENCCG
and an over-generation and ranking ap-
proach, guided by a set of language mod-
els covering both personality and align-
ment. We illustrate with examples of out-
put, and briefly note results from user stud-
ies with the earlier CRAG-1, indicating
how CRAG-2 will be further evaluated.
Related work is discussed, along with cur-
rent limitations and future directions.
1 Introduction
A computer agent should be individual. Nass
and collaborators find that users? responses
to computer-agents are influenced by whether
the agent?s linguistic personality matches?or
mismatches?the personality of the user (Moon
and Nass, 1996; Nass and Lee, 2000). Similarly,
characters in virtual environments should be dis-
tinctive (Ball and Breese, 2000; Rist et al, 2003).
But an aspect of personality is how well you adjust
to other people (and their language use): align-
ment. Pickering and Garrod?s Interactive Align-
ment Model suggests that people tend to automat-
ically converge on lexical and syntactic choices,
via a low-level mechanism of interpersonal prim-
ing (Pickering and Garrod, 2004), and Brennan
has shown that people will align their language to-
wards that of computer agents (Brennan, 1996).
But it is an open issue as to whether some peo-
ple are better ?aligners? than others. Conversely,
alignment is only visible and interesting (among
computer agents) if they start out being individual.
We therefore set out to simulate both individ-
uality and alignment. The paper briefly surveys
the evidence for linguistic personality, for inter-
personal alignment, and for interaction between
them. It then sketches the current version of
CRAG. CRAG-2 makes use of OPENCCG and
an over-generation and ranking approach, guided
by a set of language models for personality and
alignment. We illustrate the differing linguis-
tic behaviours that it generates, and briefly note
promising results from user studies with the ear-
lier CRAG-1 system, indicating how CRAG-2 will
be further evaluated. Related work is discussed,
along with possible directions for future work.
2 Background
2.1 Personality and Language
Current work on personality traits is dominated by
Costa and McCrae?s five-factor model (Costa and
McCrae, 1992). The five factors, or dimensions,
are: Extraversion; Neuroticism; Openness; Agree-
ableness; and Conscientiousness (Matthews et al,
2003). It has been shown that scores on these di-
mensions correlate with some aspects of language
use (Scherer, 1979; Dewaele and Furnham, 1999).
In studies of text, the focus has been on lexical
choice, and Pennebaker and colleagues have anal-
ysed relative frequencies of use of word-stems in
a dictionary structured into semantic and syntac-
tic categories (Pennebaker et al, 2001). Amongst
other results, they have shown that High Extraverts
25
use: more social process talk, positive emotion
words and inclusives; and fewer negations, ten-
tative words, exclusives, causation words, nega-
tive emotion words, and articles (Pennebaker and
King, 1999; Pennebaker et al, 2002).
Computational linguistic exploitation of such
empirically-derived features has been limited. On
the one hand, in generation, there has been work
on personality-based generation. For instance, in
developing embodied conversational agents, re-
searchers have designed agents or teams of agents
with distinguishable linguistic personalities (Ball
and Breese, 2000; Rist et al, 2003; Piwek and
van Deemter, 2003; Gebhard, 2005). However,
the linguistic behaviour is usually informed by
rules based on personality stereotypes, rather than
on language statistics themselves. On the other
hand, in interpretation, more empirical work has
recently been carried out, to enable text classifi-
cation. Argamon et al (2005) attempted to clas-
sify authors as High or Low Extravert and High
or Low Neurotic, using Pennebaker and King?s
(1999) data. They report classification accuracies
of around 58% (with a 50% baseline). Oberlander
and Nowson (2006) undertake a comparable task,
using weblog data. They report classification ac-
curacies of roughly 85% (Neuroticism) and 94%
(Extraversion), and comparable figures for Agree-
ableness and Conscientiousness. Such studies can
provide ordered lists of linguistic features which
are useful for distinguishing language producers,
and we will return to this, below.
2.2 Alignment and Language
People converge with their interlocutors in linguis-
tic choices at a number of levels (Pickering and
Garrod, 2004). The phenomena can be seen in
both social and cognitive terms. On the social side,
co-operative processes such as audience design
are usually considered to be conscious, at least in
part (Bell, 1984). But on the cognitive side, co-
ordinative processes such as alignment are usu-
ally considered to be largely automatic (Garrod
and Doherty, 1994). Alignment can be probed
by psycholinguistic tests for interpersonal prim-
ing, establishing the extent to which participants
are more likely to use a lexical item or syntac-
tic construction after hearing their conversational
partner use it. Syntactic priming experiments in-
volve constructions such as passives, and ditransi-
tives (Pickering and Branigan, 1998).
It is possible that some people are stronger
aligners than others. Gill et al (2004) probed
syntactic priming for passives, and investigated
whether levels of Extraversion or Neuroticism
would affect the strength of priming effects. It
was found that Extraversion has no effect, but that
Neuroticism has a non-linear effect: both High and
Low levels of Neuroticism led to weaker priming;
Mid levels led to significantly stronger priming.
Given this, if a generation system is going to simu-
late alignment, it is probably worth designing it so
that it can simulate agents with differing propensi-
ties to align.
3 The CRAG System Overview
The system described in the following sections
(CRAG-2) is the successor to CRAG-1 which is
detailed in Isard et al (2005). The system gener-
ates a dialogue between two computer agents on
the subject of opinions about a film. CRAG-2 uses
the OPENCCG parsing and generation framework
(White, 2004; White, 2006). The realiser com-
ponent takes a logical form as input and outputs
a list of candidate sentences ranked using one or
more language models. In CRAG-2, we use the
OPENCCG generator to massively over-generate
paraphrases, and the combination of n-gram mod-
els described in Section 4 to choose the best ut-
terance according to a character?s personality and
agenda, and the dialogue history.
4 N-Grams: Personality and Alignment
Modelling
4.1 N-Gram Language Models
The basic assumption underlying CRAG-2 is that
personality, as well as alignment behaviour, can
be modelled by the combination of a variety of n-
gram language models.
Language models are trained on a corpus and
subsequently used to compute probability scores
of word sequences. An n-gram language model
approximates the probability of a word given its
history of the preceding n? 1 words. According
to the chain rule, probabilities are then combined
by multiplication. Equation (1) shows a trigram
model that takes into account two words of context
to predict the probability of a word sequence wn1:
(1) P(wn1)?
n
?
i=1
P(wi|wi?1i?2)
26
4.2 Avoiding the Length Effect
Because word probabilities are always less than 1
and therefore each multiplication decreases the to-
tal, if we use this standard model, longer sentences
will always receive lower scores (this is known as
the length effect). We therefore calculate the prob-
ability of a sentence as the geometric mean of the
probability of each word in the sentence as shown
in (2):
(2) P(wn1)?
n
?
i=1
P(wi|wi?1i?2)
1/n
4.3 Linear Combination of Language Models
OPENCCG supports the linear combination of
language models, where each model is assigned a
weight. For uniform interpolation of two language
models Pa and Pb, each receives equal weight:
(3) P(wi|wi?1i?2) =
Pa(wi|wi?1i?2)+Pb(wi|w
i?1
i?2)
2
In the more general case, the language models
are assigned weights ?i, the sum of which has to
be 1:
(4) P(wi|wi?1i?2) = ?1Pa(wi|wi?1i?2)+?2Pb(wi|wi?1i?2)
For example, setting ?1 = 0.9 and ?2 = 0.1 assigns
a high weight to the first language model.
4.4 OPENCCG N-Gram Ranking
In the OPENCCG framework, language models
can be used to influence the chart-based realisation
process. The agenda of edges is re-sorted accord-
ing to the score an edge receives with respect to a
language model. For CRAG-2, many paraphrases
are generated from a given logical form, and they
are then ranked in order of probability according
to the combination of n-gram models appropriate
for the character and stage of the dialogue.
5 CRAG-2 Personality and Alignment
Models
We use the SRILM toolkit (Stolcke, 2002) to com-
pute our language models. All models (except
for the cache language model described in Sec-
tion 5.4) are trigram models with backoff to bi-
grams and unigrams.
We have experimented with two strategies for
creating personality models. Since we want to
study the effects of alignment as well as person-
ality, it is essential that the two characters in a di-
alogue be distinct from one another, so that the ef-
fects of alignment can be seen. The first strategy
involves using typical language for each personal-
ity trait, and the second uses the language of one
individual. In both cases, the language models de-
scribed in the following sections are combined as
described in Section 5.5.
5.1 Building a Personality
Nowson (2006) performed a study on language
use in weblogs. The weblog authors were asked to
complete personality questionnaires based on the
five-factor model (see Section 2.1). All weblog au-
thors scored High or Medium on the Openness di-
mension, so we have no data for typical Low Open
language.
We divided the data into High, Medium and
Low for each personality dimension, and trained
language models so that we would be able to as-
sess the probability of a word sequence given a
personality type. This means that each individual
weblog is used 5 times, once for each dimension.
For each personality dimension, the system sim-
plifies a character?s personality setting x by assign-
ing a value of High (x > 70), Medium (30 < x ?
70) or Low (x ? 30). The five models correspond-
ing to the character?s assigned personality are uni-
formly interpolated to give the final personality
model. If the character has been given a low Open-
ness score, since we do not have a model for this
personality type, we simply interpolate the other
four models.
5.2 Borrowing a Personality
Our second strategy was to train n-gram models
on language of the individuals from the CRAG-1
corpus (Isard et al, 2005) and to use one of these
models for each character in the dialogue.
5.3 Base Language Model
In the case of building a personality, a base lan-
guage model is obtained by combining a language
model computed from the corpus collected for the
CRAG-1 system and a general language model
based on data from the Switchboard corpus (Stol-
cke et al, 2000). The combined base model alone
would rank the utterances without any bias for per-
sonality or alignment. When we are borrowing a
personality, the base model is calculated from the
Switchboard corpus alone.
27
5.4 Cache Language Model
We simulate alignment by computing a cache lan-
guage model based on the utterance that was gen-
erated immediately before. This dialogue history
cache model is the uniform interpolation of word-
and class-based n-gram models, where classes act
as a backoff mechanism when there is no exact
word match. Classes group together lexical items
with similar semantic properties, e.g.:
? good, bad: quality-adjective
? loved, hated: opinion-verb
Details of this approach can be found in Brock-
mann et al (2005).
5.5 Combining the Language Models
The system uses weights to combine all the mod-
els described above. First the base and person-
ality models are interpolated to produce a base-
personality model, and finally the cache model is
introduced to add alignment effects.
6 Dialogue and Utterance Specifications
6.1 Character Specification
Two computer characters are parameterised for
their personality by specifying values (on a scale
from 0 to 100) for the five dimensions: Extraver-
sion (E), Neuroticism (N), Openness (O), Agree-
ableness (A), and Conscientiousness (C). Their
alignment behaviour is set to a value between 0
(low propensity to align) and 1 (high propensity
to align). Also, each character receives an agenda
of topics they wish to discuss, along with polari-
ties (positive/negative) that indicate their opinion
on the respective topic.
6.2 Utterance Design
The character with the higher Extraversion score
begins the dialogue, and their first topic is se-
lected. Once an utterance has been generated, the
other character is selected, and the system applies
the algorithm shown in (5) to decide which topic
should come next. This process continues until
there are no topics left on the agenda of the cur-
rent speaker.
(5) if (A < 46) or (C < 46) or
(no. of utts about this topic = 2)
then take next topic from own agenda
else continue on same topic
The system creates a simple XML representa-
tion of the character?s utterance, using the speci-
fied topic and polarity. An example using the topic
music and polarity negative is shown in Figure 1.
At this point the system also decides which dis-
course connectives may be appropriate, based on
the previous topic and polarity.
<utterance>
<utt topic="music" polarity="dislike"
opp-polarity="like" so="no" right="no"
also="no" well="yes" and="no" but="no">
<pred adj="bad"/>
<opp-pred adj="good"/>
</utt>
</utterance>
Figure 1: Simple Utterance Specification
6.3 OPENCCG Logical Forms
Following the method described in Foster and
White (2004), the basic utterance specification is
transformed, using stylesheets written in the XSL
transformation language, into an OPENCCG log-
ical form. We make use of the facility for defin-
ing optional and alternative inputs and underspec-
ified semantics to massively over-generate candi-
date utterances. A fragment of the logical form
which results from the transformation of Figure 1
is shown in Figure 2. We also include some frag-
ments of canned text from the CRAG corpus in our
OPENCCG lexicon.
We also add optional interjections (i mean, you
know, sort of ) and conversational markers (right,
but, and, well) where appropriate given the dis-
course history.
When the full logical form is processed by the
OPENCCG system, the output consists of sen-
tences of the types shown below:
(I think) the music was bad.
(I think) the music was not (wasn?t)
good.
I did not (didn?t) like the music.
I hated the music.
One thing I did not (didn?t) like was the
music.
One thing I hated was the music.
The fragmentary logical form in Figure 2 would
create all possible paraphrases from:
(well) (you know) I (kind of) [liked/loved] the
[music/score]
By using synonyms (e.g., plot=story, com-
edy=humour) and combining the sentence types
28
<node id="l1:opinion" pred="like" tense="past">
<rel name="Speaker">
<node id="p1:person" pred="pro1" num="sg"/>
</rel>
<rel name="Content">
<node id="f1:cragtopic" pred="music"
det="the" num="sg"/>
</rel>
<opt>
<rel name="Modifier">
<node id="w1:adv" pred="well"/>
</rel>
<opt>
<opt>
<rel name="HasProp">
<node id="a2:proposition" pred="kind-of"/>
</rel>
</opt>
<opt>
<rel name="Modifier">
<node id="a1:adv" pred="you-know"/>
</rel>
</opt>
</node>
Figure 2: Fragment of Logical Form
Stan: E:53 N:48 A:57 C:46 O:65
agenda: film(neg), dialogue(neg),
music(pos)
other opinions: plot(neg), comedy(neg)
Eddie: E:51 N:43 A:57 C:41 O:65
agenda: plot(neg), comedy(neg),
dialogue(neg)
other opinions: music(pos), film(neg)
Figure 3: Stan and Eddie
and optional expressions, we create up to 3000
possibilities per utterance, and the best candidate
is chosen by the specific combination of n-gram
models appropriate for the given personality and
dialogue history, as described in Section 4.
Our OPENCCG lexicon is based on the core
English lexicon included with the system and we
have added vocabulary appropriate to the movie
domain, and extended the range of grammatical
constructions where necessary.
7 Output and Evaluation
7.1 Output
In this section, we provide some example out-
puts from the CRAG-2 system, using characters
based on participants from our corpus (see Sec-
tion 5.2). Stan is higher on the Extraversion, Neu-
roticism, and Conscientiousness scales than Ed-
die. The characters? personalities and agendas are
summarised in Figure 3.
We show three example dialogues between Stan
and Eddie. In the first (Figure 4) neither charac-
ter aligns with the other at all, while in the sec-
ond (Figure 5) Stan has a slight tendency towards
alignment and in the third (Figure 6) a more pro-
nounced tendency. In system terms, this means
that in the first dialogue the cache model was given
weight 0, while in the second and third the cache
model was given weights 0.05 and 0.1 respectively
for Stan?s utterances. It can be seen that in the
first dialogue, Eddie?s use of humour in utterance
4 is followed by Stan?s comedy, and dialogue in
utterance 6 is followed by script. In the second
dialogue, Stan aligns his first lexical choice with
Eddie?s but not his second, while in the third di-
alogue he aligns both. The syntactic structures of
Stan?s utterances in the second and third dialogue
also mirror Eddie?s progressively more closely.
1. Stan: I didn?t think much of the film you know.
2. Eddie: I mean I didn?t like kind of like the story.
3. Stan: Yeah there were so many little pathways that they
didn?t take you know.
4. Eddie: I mean I didn?t think the humour was really funny.
5. Stan: Yeah you know the comedy was a bit dull.
6. Eddie: I mean I didn?t like kind of like the dialogue.
7. Stan: I mean the script was a bit dull.
Figure 4: Zero Alignment
1. Stan: I didn?t think much of the film you know.
2. Eddie: I mean I didn?t like kind of like the story.
3. Stan: Yeah there were so many little pathways that they
didn?t take you know.
4. Eddie: I mean I didn?t think the humour was really funny.
5. Stan: I mean the humour was a bit dull.
6. Eddie: I mean I didn?t like kind of like the dialogue.
7. Stan: I mean the script was a bit dull.
Figure 5: Little Alignment from Stan
1. Stan: I didn?t think much of the film you know.
2. Eddie: I mean I didn?t like kind of like the story.
3. Stan: I mean the story was a bit dull.
4. Eddie: I mean I didn?t think the humour was really funny.
5. Stan: I mean the humour was a bit dull.
6. Eddie: I mean I didn?t like kind of like the dialogue.
7. Stan: I mean the dialogue was a bit dull.
Figure 6: More Alignment from Stan
To further illustrate the differences between the
dialogues with and without alignment, we provide
some utterance rankings. We show candidates
for the fifth utterance in each dialogue. Table 1
shows sentences from the example generated with-
out alignment, corresponding to utterance 5 (Stan)
29
1 .03317 Yeah you know the comedy was a
bit dull.
3 .03210 Yeah you know the humour was a bit
dull.
6 .03083 Yeah to be honest I didn?t think that
the comedy was very good either.
15 .02938 I didn?t think much of the comedy
either.
24 .02861 I thought that the comedy was a bit
dull too you know.
Table 1: Ranked Sentences with Zero Alignment
1 .05384 I mean the humour was a bit dull.
8 .05239 The humour wasn?t really funny you
know.
15 .04748 I mean I didn?t think that the humour
was very good either.
19 .04518 I didn?t think much of the humour
either you know.
21 .04478 I thought the humour was a bit dull
too you know.
Table 2: Ranked Sentences with Little Alignment
from Stan
from Figure 4. We show the first five occurrences
of different sentence structures (see Section 6.3),
with their rank and their geometric mean adjusted
scores.
Table 2 shows the the top five sentences from
the fifth utterance from Figure 5 (little alignment),
and Table 3 those from Figure 6 (more align-
ment). It can be seen that when more alignment
is present, the syntactic structure used by the pre-
vious speaker rises higher in the rankings.
7.2 Evaluation
We have not evaluated CRAG-2. However, we
have evaluated CRAG-1. The method was to gen-
erate a set of dialogues, systematically contrasting
characters with extreme settings for the personal-
ity dimensions (High/Low Extraversion, Neuroti-
cism, and Psychoticism1).
1CRAG-1 used the simpler PEN three factor personality
model.
1 .07081 I mean the humour was a bit dull.
2 .06432 The humour wasn?t really funny you
know.
15 .05516 I mean I didn?t think that the humour
was really funny either.
27 .05000 I thought the humour was a bit dull
too you know.
36 .04884 I mean I didn?t think much of the hu-
mour either.
Table 3: Ranked Sentences with More Alignment
from Stan
Human subjects were asked to fill in a question-
naire to determine their personality. They were
then given a selection of dialogues to read. After
each dialogue, they were asked to rate their per-
ception of the interaction and of the characters in-
volved by assigning scores to a number of adjec-
tives related to the personality dimensions.
It was found that subjects could recognise dif-
ferences in the Extraversion level of the language.
Also, the personality setting of a character influ-
enced the perception of its and its dialogue part-
ner?s personality (Kahn, 2006).
We plan a similar evaluation for CRAG-2 to be
able to compare human raters? impressions of di-
alogues generated by the two systems. We also
plan to evaluate CRAG-2 internally by varying the
weight given to the underlying language models,
and observing the effects this has on the resulting
ranking of the generated utterances.
8 Related Work
Related work in NLG involves either personality
or alignment. So far as we can tell, there is little
work on the latter. Varges (2005) suggests that ?a
word similarity-based ranker could align the gen-
eration output (i.e. the highest-ranked candidate)
with previous utterances in the discourse context?,
but there is no report yet on an implementation of
this proposal. A rather different approach is sug-
gested by Bateman and Paris (2005), who discuss
initial work on alignment, mediated by a process
of register-recognition. Regarding generation with
personality, the most influential work is probably
Hovy?s PAULINE system, which varies both con-
tent selection and realisation according to an indi-
vidual speaker?s goals and attitudes (Hovy, 1990).
In her extremely useful survey of work on affective
(particularly, emotional) natural language gener-
ation, Belz (2003) notes that the complexity of
PAULINE?s rule system means that numerous rule
interactions can lead to unpredictable side effects.
In response, Paiva and Evans (2004) take a more
empirical line on style generation, which is closer
to that pursued here. Other relevant work includes
Loyall and Bates (1997), who explicitly propose
that personality and emotion could be used in
generation, but Belz observes that technical de-
scriptions of Hap and the Oz project suggest that
the proposals were not implemented. Walker et
al.?s (1997) system produces linguistic behaviour
which is much more varied than our current sys-
30
tem is capable of; but there, variation is driven by
a model of social relations (based on Brown and
Levinson), rather than on personality. The NECA
project subsequently developed methods for gen-
erating scripts for pairs of dialogue agents (Piwek
and van Deemter, 2003), supported by the MIAU
platform (Rist et al, 2003). The VIRTUALHU-
MAN project is a logical successor to this work,
and its ALMA platform provides an integrated ap-
proach to affective generation, covering emotion,
mood and personality (Gebhard, 2005).
9 Conclusion and Next Steps
Our current system takes a much coarser-grained
approach to semantics and discourse goals than
the recent projects described above, in order to
take advantage of empirically-derived relations
between language and personality. It should be
feasible in principle to move to a more sophisti-
cated semantics, but still retain the massive over-
generation and ranking method. However, to
support more perceptible variation, we need to
exploit much larger personality-corpus resources
than have been available up to now, and our cur-
rent priority is to obtain a corpus at least an order
of magnitude larger than what is currently avail-
able. This interest in individual differences and
what corpora can (and cannot) tell us about them
is one we share with Reiter and colleagues (Reiter
and Sripada, 2004).
We also plan to integrate techniques from
CRAG-1 and CRAG-2, by passing the ranked out-
put of CRAG-2 through further processing and
ranking stages. Furthermore, we intend to inves-
tigate longer-ranging alignment processes, taking
into account more than one previous utterance,
with reduced weight by distance, to emulate mem-
ory effects.
With these enhancements, we will take further
steps towards our goal of simulating both individu-
ality and alignment in believable computer agents.
10 Acknowledgements
This research has been funded by Scottish Enter-
prise through the Edinburgh-Stanford Link project
?Critical Agent Dialogue? (CRAG). We would
like to thank Michael White and Scott Nowson for
their assistance and our anonymous reviewers for
their helpful comments.
References
Shlomo Argamon, Sushant Dhawle, Moshe Koppel,
and James W. Pennebaker. 2005. Lexical predic-
tors of personality type. In Proceedings of the 2005
Joint Annual Meeting of the Interface and the Clas-
sification Society of North America.
Gene Ball and Jack Breese. 2000. Emotion and per-
sonality in a conversational agent. In J. Cassell,
J. Sullivan, S. Prevost, and E. Churchill, editors, Em-
bodied Conversational Agents, pages 189?219. MIT
Press, Cambridge, MA, USA.
John A. Bateman and Ce?cile L. Paris. 2005. Adap-
tation to affective factors: architectural impacts for
natural language generation and dialogue. In Pro-
ceedings of the Workshop on Adapting the Interac-
tion Style to Affective Factors at the 10th Interna-
tional Conference on User Modeling (UM-05), Ed-
inburgh, UK.
Allan Bell. 1984. Language style as audience design.
Language in Society, 13(2):145?204.
Anja Belz. 2003. And now with feeling: Develop-
ments in emotional language generation. Techni-
cal Report ITRI-03-21, Information Technology Re-
search Institute, University of Brighton, Brighton.
Susan E. Brennan. 1996. Lexical entrainment in spon-
taneous dialog. In Proceedings of the 1996 Inter-
national Symposium on Spoken Dialogue (ISSD-96),
pages 41?44, Philadelphia, PA.
Carsten Brockmann, Amy Isard, Jon Oberlander, and
Michael White. 2005. Modelling alignment for af-
fective dialogue. In Proceedings of the Workshop on
Adapting the Interaction Style to Affective Factors at
the 10th International Conference on User Modeling
(UM-05), Edinburgh, UK.
Paul T. Costa and Robert R. McCrae, 1992. Re-
vised NEO Personality Inventory (NEO-PI-R) and
NEO Five-Factor Inventory (NEO-FFI): Profes-
sional Manual. Odessa, FL: Psychological Assess-
ment Resources.
Jean-Marc Dewaele and Adrian Furnham. 1999. Ex-
traversion: The unloved variable in applied linguis-
tic research. Language Learning, 49:509?544.
Mary Ellen Foster and Michael White. 2004. Tech-
niques for Text Planning with XSLT. In Proc. of the
4th NLPXML Workshop.
Simon Garrod and Gwyneth Doherty. 1994. Conver-
sation, co-ordination and convention: an empirical
investigation of how groups establish linguistic con-
ventions. Cognition, 53(3):181?215.
Patrick Gebhard. 2005. Alma: a layered model of af-
fect. In AAMAS ?05: Proceedings of the Fourth In-
ternational Joint Conference on Autonomous Agents
and Multiagent Systems, pages 29?36, New York,
NY, USA. ACM Press.
31
Alastair J. Gill, Annabel J. Harrison, and Jon Ober-
lander. 2004. Interpersonality: Individual differ-
ences and interpersonal priming. In Proceedings of
the 26th Annual Conference of the Cognitive Science
Society, pages 464?469.
Eduard Hovy. 1990. Pragmatics and natural language
generation. Artificial Intelligence, 43.
Amy Isard, Carsten Brockmann, and Jon Oberlander.
2005. Re-creating dialogues from a corpus. In
Proceedings of the Workshop on Using Corpora for
Natural Language Generation at Corpus Linguistics
2005 (CL-05), pages 7?12, Birmingham, UK.
Adam S. Kahn. 2006. Master?s thesis, Stanford Uni-
versity.
A. Bryan Loyall and Joseph Bates. 1997. Personality-
rich believable agents that use language. In J. Lewis
and B. Hayes-Roth, editors, Proceedings of the
1st International Conference on Autonomous Agents
(Agents?97). ACM Press.
Gerald Matthews, Ian J. Deary, and Martha C. White-
man. 2003. Personality Traits. Cambridge Univer-
sity Press, Cambridge, 2nd edition.
Youngme Moon and Clifford Nass. 1996. How ?real?
are computer personalities? Communication Re-
search, 23:651?674.
Clifford Nass and Kwan Min Lee. 2000. Does
computer-generated speech manifest personality?
an experimental test of similarity-attraction. In
Proceedings of CHI 2000, The Hague, Amsterdam,
2000, pages 329?336.
Scott Nowson. 2006. The Language of Weblogs: A
study of genre and individual differences. Ph.D. the-
sis, University of Edinburgh.
Jon Oberlander and Scott Nowson. 2006. Whose
thumb is it anyway? Classifying author personality
from weblog text. In Proceedings of COLING/ACL-
06: 44th Annual Meeting of the Association for
Computational Linguistics and 21st International
Conference on Computational Linguistics, Sydney.
Daniel S. Paiva and Roger Evans. 2004. A framework
for stylistically controlled generation. In Proceed-
ings of the 3rd International Conference on Natural
Language Generation, pages 120?129.
James W. Pennebaker and Laura King. 1999. Lin-
guistic styles: Language use as an individual differ-
ence. Journal of Personality and Social Psychology,
77:1296?1312.
James W. Pennebaker, Martha E. Francis, and Roger J.
Booth. 2001. Linguistic Inquiry and Word Count
2001. Lawrence Erlbaum Associates, Mahwah, NJ.
James W. Pennebaker, Matthias R. Mehl, and Kate G.
Neiderhoffer. 2002. Psychological aspects of nat-
ural language use: Our words, our selves. Annual
Review of Psychology, 54:547?577.
Martin J. Pickering and Holly P. Branigan. 1998. The
representation of verbs: Evidence from syntactic
priming in language production. Journal of Mem-
ory and Language, 39(4):633?651.
Martin J. Pickering and Simon Garrod. 2004. Towards
a mechanistic psychology of dialogue. Behavioral
and Brain Sciences, 27:169?225.
Paul Piwek and Kees van Deemter. 2003. Dialogue as
discourse: Controlling global properties of scripted
dialogue. In Proceedings of the AAAI Spring Sym-
posium on Natural Language Generation in Spoken
and Written Dialogue.
Ehud Reiter and Somayajulu Sripada. 2004. Contex-
tual influences on near-synonym choice. In Pro-
ceedings of the Third International Conference on
Natural Language Generation, pages 161?170.
Thomas Rist, Elisabeth Andre?, and Stephan Baldes.
2003. A flexible platform for building applications
with life-like characters. In IUI ?03: Proceedings of
the 8th International Conference on Intelligent User
Interfaces, pages 158?165, New York, NY, USA.
ACM Press.
Klaus Scherer. 1979. Personality markers in speech.
In K. R. Scherer and H. Giles, editors, Social Mark-
ers in Speech, pages 147?209. Cambridge Univer-
sity Press, Cambridge.
Andreas Stolcke, Harry Bratt, John Butzberger, Hora-
cio Franco, Venkata Ramana Rao Gadde, Madelaine
Plauche?, Colleen Richey, Elizabeth Shriberg, Kemal
So?nmez, Fuliang Weng, and Jing Zheng. 2000. The
SRI March 2000 Hub-5 conversational speech tran-
scription system. In Proceedings of the 2000 Speech
Transcription Workshop, College Park, MD.
Andreas Stolcke. 2002. SRILM ? an extensible lan-
guage modeling toolkit. In Proceedings of the 7th
International Conference on Spoken Language Pro-
cessing (ICSLP-02), pages 901?904, Denver, CO.
Sebastian Varges. 2005. Spatial descriptions as refer-
ring expressions in the MapTask domain. In Pro-
ceedings of the 10th European Workshop on Natural
Language Generation.
Marilyn A. Walker, Janet E. Cahn, and Steve J. Whit-
taker. 1997. Improvising linguistic style: So-
cial and affective bases for agent personality. In
J. Lewis and B. Hayes-Roth, editors, Proceedings
of the 1st International Conference on Autonomous
Agents (Agents?97), pages 96?105. ACM Press.
Michael White. 2004. Reining in CCG Chart Re-
alization. In Proceedings of the 3rd International
Conference on Natural Language Generation, pages
182?191.
Michael White. 2006. Efficient Realization of Coor-
dinate Structures in Combinatory Categorial Gram-
mar. Research on Language & Computation, on-
line first, March.
32
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 40?48,
Utica, May 2012. c?2012 Association for Computational Linguistics
Perceptions of Alignment and Personality in Generated Dialogue
Alastair J. Gill
University of Surrey
Guildford GU2 7XH, UK
A.Gill@surrey.ac.uk
Carsten Brockmann and Jon Oberlander
University of Edinburgh
Edinburgh EH8 9AB, UK
Carsten.Brockmann@gmx.net
J.Oberlander@ed.ac.uk
Abstract
Variation in language style can lead to differ-
ent perceptions of the interaction, and differ-
ent behaviour outcomes. Using the CRAG 2
language generation system we examine how
accurately judges can perceive character per-
sonality from short, automatically generated
dialogues, and how alignment (similarity be-
tween speakers) alters judge perceptions of the
characters? relationship. Whilst personality
perception of our dialogues is consistent with
perceptions of human behaviour, we find that
the introduction of alignment leads to nega-
tive perceptions of the dialogues and the inter-
locutors? relationship. A follow up evaluation
study of the perceptions of different forms of
alignment in the dialogues reveals that while
similarity at polarity, topic and construction
levels is viewed positively, similarity at the
word level is regarded negatively. We discuss
our findings in relation to the literature and in
the context of dialogue systems.
1 Introduction
Personality describes characteristics which are cen-
tral to human behaviour, and has implications for
social interactions: It can affect performance on col-
laborative processes, and can increase engagement
when incorporated within virtual agents (Hernault
et al, 2008). In addition, personality has also been
shown to influence linguistic style, both in written
and spoken language (Pennebaker and King, 1999;
Gill and Oberlander, 2002). Whilst individuals of-
ten possess individual styles of self-expression, such
as those influenced by personality, in a conversation
they may align or match the linguistic style of their
partner: For example, by entraining, or converging,
on a mutual vocabulary. Such alignment is associ-
ated with increased familiarity, trust, and task suc-
cess (Shepard et al, 2001). People also adjust their
linguistic styles when interacting with computers,
and this affects their perceptions of the interaction
(Porzel et al, 2006). However, when humans ? or
machines ? are faced with a choice of matching the
language of their conversational partner, this often
raises a conflict: matching the language of an in-
terlocutor may mean subduing one?s own linguistic
style. Better understanding these processes relating
to language choice and interpersonal perception can
inform our knowledge of human behaviour, but also
have important implications for the design of dia-
logue systems and user interfaces.
In this paper, we present and evaluate novel
automated natural language generation techniques,
via the Critical Agent Dialogue system version 2
(CRAG 2), which enable us to generate dynamic,
short-term alignment effects along with stable, long-
term personality effects. We use it to investigate
the following questions: Can personality be accu-
rately judged from short, automatically generated di-
alogues? What are the effects of alignment between
characters? How is the quality of the characters? re-
lationship perceived? Additionally, in our evaluation
study we examine perceptions of the different forms
of alignment present in the dialogues, for example at
the word, phrase or polarity levels. In the following
we review relevant literature, before describing the
CRAG 2 system and experimental method, and then
presenting our results and discussion.
40
2 Background
Researchers from several traditions have studied as-
pects of similarity in dialogue, naming it: entrain-
ment, alignment, priming, accommodation, coordi-
nation or convergence. For current purposes, we
gloss over some important differences, and borrow
the term ?alignment?, because we will go on to adopt
Pickering and Garrod?s theoretical mechanisms in
our system. Alignment usually means that if some-
thing has happened once in a dialogue (for instance,
referring to an object as a vase), it is likely to happen
again?and hence, alternatives become less likely
(for instance, referring to the same object as a jug)
(Pickering and Garrod, 2004). From this view, inter-
locutors align the representations they use in produc-
tion and comprehension and the process is an auto-
matic, labour-saving device, but there are of course
limits to periods over which alignment processes op-
erate; in corpus studies long-term adaptation pre-
dicts communicative success (Reitter, 2008). Al-
ternative approaches view similarity as a process of
negotiation leading to the establishment of common
ground (Brennan and Clark, 1996), or a relatively
conscious process resulting from attraction (Shepard
et al, 2001). Although increased similarity (conver-
gence) is generally regarded positively, it can some-
times arise during disagreement (Niederhoffer and
Pennebaker, 2002), with cultural differences influ-
encing both convergence and perceptions of others
(Bortfeld and Brennan, 1997). Wizard-of-Oz stud-
ies have also shown convergence with a natural lan-
guage interface (Brennan, 1996; Porzel et al, 2006).
Embodied conversational agents (Cassell et al,
2000) are implemented computer characters that ex-
hibit multimodal behaviour; the technology can be
exploited to give life to automatically generated
scripted dialogues and to make them more engag-
ing (van Deemter et al, 2008; Hernault et al, 2008).
Aspects of the agents? personalities and their inter-
ests can be pre-configured and affect their dialogue
strategies; the generation is template-based. A com-
mon way to describe personality is using the Big
Five traits: Extraversion (preference for, and behav-
ior in, social situations); Neuroticism (tendency to
experience negative thoughts and feelings); Open-
ness (reflects openness to new ideas); Agreeableness
(how we tend to interact with others); and Consci-
entiousness (how organised and persistent we are in
pursuing our goals). Relationships between person-
ality dimensions and language use appear to be ro-
bust: For instance, in monological writing (essays
and e-mails) high Extraverts use more social words,
positive emotion words, and express more certainty;
high Agreeableness scorers use more first person
singular and positive emotion words, and fewer ar-
ticles and negative emotion words (Pennebaker and
King, 1999; Gill and Oberlander, 2002).
Personality can not only be projected through, but
also perceived from, asynchronous textual commu-
nication. The extraversion dimension is generally
perceived most accurately in a variety of contexts,
while it was more difficult for raters to recognise
neuroticism (Gill et al, 2006; Li and Chignell, 2010)
Taking into account the difference between the lan-
guage actually used by people with certain person-
ality, and the language which others expect them
to use, natural language generation (NLG) systems
can exploit either to project personality. Perhaps the
closest previous work to what we present here is the
Personality Generator (PERSONAGE) (Mairesse and
Walker, 2010) which mapped psychological find-
ings relating to the personality to the components
of the NLG system (e.g., content planning, sen-
tence planning and realisation). Evaluation by hu-
man raters showed similar accuracy in perception
of extraversion in the generated language compared
with human-authored texts. There is evidence that
computer users attribute personality to interfaces,
and rate more highly those interfaces that exploit
language associated with the user?s own personal-
ity, and become more similar to the user over time
(Isbister and Nass, 2000).
We now turn to describing our automated natu-
ral language generation techniques, implemented in
CRAG 2, followed by a description of our experi-
mental method and evaluation.
3 Generation Method
Dialogues are composed by CRAG 2, a Java pro-
gram that provides a framework for generating dia-
logues between two computer characters discussing
a movie. For more details of this system, see Brock-
mann (2009). Within CRAG 2, linguistic personal-
ity and alignment are modelled using the OPENNLP
41
CCG Library (OPENCCG) natural language realiser
(White, 2006b). The realiser consults a grammar
adapted to the movie review domain to allow the
generation of utterances about the following top-
ics: Action scenes, characters, dialogue, film, music,
plot or special effects. The realiser also has access
to a set of n-gram language models, used to com-
pute probability scores of word sequences. The gen-
eral conversational language model (LM) is based
on data from the SWITCHBOARD corpus and a small
corpus of movie reviews. The general LM is used for
fallback probabilities, and is integrated with the per-
sonality and alignment language models (described
below) using linear interpolation.
3.1 Personality Models
Language models were trained on a corpus of web-
logs from authors of known personality (Nowson et
al., 2005). For each personality dimension, the lan-
guage data were divided up into high, medium and
low bands so that the probability of a word sequence
given a personality type could be derived; see Now-
son et al (2005) for further discussion of the pos-
itively skewed distribution of the openness dimen-
sion in bloggers. Each individual weblog was used
5 times, once for each dimension. The five models
corresponding to the character?s assigned personal-
ity are uniformly interpolated to give the final per-
sonality model, which is then combined with the
general model (respective weights, 0.7 and 0.3).
3.2 Alignment via Cache Language Models
Meanwhile, alignment is modelled via cache lan-
guage models (CLMs). For each utterance to be
generated, a language model is computed based on
the utterance that was generated immediately before
it. This CLM is then combined with the personality
LM. A character?s propensity to align corresponds
to the weight given to the CLM during this combi-
nation, and can be set to a value between 0 and 1.
3.3 Character Specification and Dialogue
Generation
The characters are parameterised for their per-
sonality by specifying values (on a scale from
0 to 100) for the five dimensions: extraver-
sion (E), neuroticism (N), agreeableness (A),
conscientiousness (C) and openness (O). This pa-
rameterisation determines the extent to which utter-
ances are weighted for their overlap with the per-
sonality generation model for each trait. Also, each
character receives an agenda of topics they wish
to discuss, along with polarities (POSITIVE/NEGA-
TIVE) that indicate their opinion on each topic.
The character with the higher E score begins the
dialogue, and their first topic is selected. Once
an utterance has been generated, the other charac-
ter is selected, and the system selects which topic
should come next. This process continues until
there are no topics left on the agenda of the cur-
rent speaker. The system creates a simple XML
representation of the character?s utterance, using
the specified topic and polarity. Following the
method described in Foster and White (2004), the
basic utterance specification is transformed, using
stylesheets written in the Extensible Stylesheet Lan-
guage Transformations (XSLT) language, into an
OPENCCG logical form. We make use of the fa-
cility for defining optional and alternative inputs
(White, 2006a) and underspecified semantics to
mildly overgenerate candidate utterances.
Optional interjections (I mean, you know, sort of )
and conversational markers (right, but, and, well)
are added where appropriate given the discourse his-
tory. Using synonyms (e.g., plot = story, comedy =
humour) and combining sentence types and optional
expressions, up to 3000 possibilities are created per
utterance, and the best candidate is chosen by the
specific combination of n-gram models appropriate
for dialogue history, personality and alignment.
4 Experimental Method
4.1 Participants
Data were collected from 80 participants with a va-
riety of educational and occupational backgrounds
using an online study (via the Language Experi-
ments Portal; www.language-experiments.org). To
ensure integrity of responses, submissions taking
less than five minutes (five cases), or more than 45
minutes (one case) were examined in relation to the
other responses before being included in the analy-
sis. The demographics were as follows: 43 partici-
pants (54%) were native, and 37 (46%) non-native,
speakers of English; 34 (42%) male, 46 (58%) fe-
42
Personality Par- Propen-
Dialogue ameter Setting sity to
Type Character E N A C O Align
1) High E I 75 50 25 25 50 0
vs. Low E II 25 50 75 75 50 0 or 0.7
2) Low E I 25 50 25 25 50 0
vs. High E II 75 50 75 75 50 0 or 0.7
3) High N I 50 75 25 25 50 0
vs. Low N II 50 25 75 75 50 0 or 0.7
4) Low N I 50 25 25 25 50 0
vs. High N II 50 75 75 75 50 0 or 0.7
Table 1: Dialogue type parameter settings.
male. Median age range was 25?29 (mode = 20?
24). Other demographic information (right/left-
handedness, area of upbringing, occupation) were
collected, but are not considered here.
4.2 Materials
To be able to compare human judges? perceptions
of characters demonstrating different personalities,
and dialogues without and with alignment, dialogues
were generated in four different dialogue types, as
shown in Table 1. Each dialogue type sets the two
computer characters to opposing extremes on either
the E or the N dimension, while keeping the respec-
tive other dimension at a middle, or neutral, level
(for example, in Dialogue Type 1, Character I is
High E, Character II is Low E, and both charac-
ters are Mid N). Furthermore, Character I is always
Low A and C, and Character II is always High A and
C. All characters are set to Mid O.
Two dialogues were generated per type, giving a
total of 8 dialogues, with aligning versions of each of
these dialogues subsequently generated (giving 16
dialogues in total). The movie under discussion and
the characters? respective agendas and their opinions
about the topics were randomly assigned. Each dia-
logue was eight utterances long, with characters tak-
ing turns, each of them producing four utterances
altogether. In each alignment dialogue, the High
A/High C Character II aligned. The weight for the
cache language model was set to 0.7. In both align-
ing and non-aligning versions of the dialogues, ut-
terances for the non-aligning speaker were the same.
The generation of utterances for the aligning speaker
was seeded with the respective previous utterance
functioning as the dialogue history. From the list
of generated possible utterances, the top-ranked ut-
terance was chosen.
4.2.1 Example Dialogue
To give an impression of the generated dialogues,
Table 2 shows an example of Dialogue Type 1
(High E versus Low E) where the characters dis-
cuss the movie Mystic River (the first row of Ta-
ble 1 gives the full parameter settings). The other
generation parameters are (valence of opinions fol-
lows each topic): Character I, agenda (PLOT/?,
CHARACTERS/?, MUSIC/?, FILM/?); further opin-
ions (SPECIAL EFFECTS/?, ACTION SCENES/+,
DIALOGUE/?); Character II, agenda (ACTION
SCENES/+, SPECIAL EFFECTS/+, PLOT/?, DI-
ALOGUE/?); further opinions (CHARACTERS/?,
FILM/?, MUSIC/?).
Alignment is switched on for Character II, with
examples of their utterances from the non-aligning
dialogues included beneath. As can be seen, the
aligned utterances closely match the surface form
of their primes. The personality language models?
influence on language choice can be seen when the
High E Character I uses the phrase I mean I didn?t
think, while the (non-aligning) Low E Character II
prefers I (kind of) thought throughout. Finally, the
Low A/Low C Character I has a strategy of switch-
ing topics in order to follow his own agenda.
4.3 Procedure
An introductory web page explained the task and de-
scribed the four personality dimensions of interest
(E, N, A and C; adjectives relating to each personal-
ity type were included for reference after each dia-
logue). The first page also contained an example di-
alogue similar to those that would be displayed dur-
ing the experiment. The participants were then pre-
sented with eight dialogues (two per type; one with,
one without alignment). The dialogues were pre-
sented in random order and randomly chosen from
the pool of available dialogues. One complete di-
alogue was shown at a time, and the participants
were asked to judge which of the two characters
scored higher on the E, N, A and C dimensions (us-
ing the previous personality descriptions and adjec-
tives). They also answered questions probing their
43
PLOT:
I ?I mean I didn?t think that the story was great.?
II ?I mean the story wasn?t great.?
Without alignment:
?Yes I mean I thought that it wasn?t nicely tied up.?
CHARACTERS:
I ?And I mean I thought there was no characterization at all.?
II ?I mean I thought there was no characterization at all.?
Without alignment:
?Yeah there was no characterization at all I mean.?
MUSIC:
I ?I mean I didn?t think that the music was great.?
II ?I mean the music wasn?t great.?
Without alignment:
?Yeah I kind of thought that the music was also very bad
you know.?
FILM:
I ?I mean I didn?t think the film was good.?
II ?I mean the film wasn?t good.?
Without alignment:
?I mean I kind of thought that it was a bit dull.?
Table 2: Example Dialogue.
perceptions of the characters? relationship. They as-
sessed on a seven-point Likert scale how well the
characters ?got on? with each other (very badly?very
well), interpreted as indicating positivity or rapport
between characters, and how smoothly the conver-
sation went (not at all smoothly?very smoothly), in-
dicating how natural and coherent the interactions
were. The participants were asked to rate each dia-
logue independently from the others.The experiment
was open to both native and non-native speakers of
English; upon supplying an email address, partici-
pants were entered into a draw for an Amazon gift
token. All data were analysed anonymously. Note
that this is a further evaluation of data previously
presented in Brockmann (2009).
5 Experimental Results
5.1 Personality perception
To study the perception of personality in our di-
alogues, a nominal logistic regression was run on
the perception ratings obtained from the judges.
Here agreement between generated personality and
rater judgements was coded as a binary value
(agreement=1; disagreement=0), and entered into
the regression model as the dependent variable
(DV). The following independent variables (IVs)
were entered into the model: Dialogue Alignment as
a binary variable (alignment=1; no alignment=0);
Personality Trait judged as a categorical variable
(?Extraversion?, ?Neuroticism??, ?Agreeableness?,
?Conscientiousness?). We also included an inter-
action variable, Generated Alignment ? Personality
Trait Rated. We ran this model in order to under-
stand how each of the independent variables, such
as Personality Trait judged, or combinations of vari-
ables (in the case of the interactions) best explain the
accuracy of the personality perception judgements
relative to our generated personality language (the
DV). Throughout this section we report the parame-
ter estimates and corresponding one degree of free-
dom for the more conservative Likelihood Ratio Chi
Square effect tests for N=1920 (with the exception
of the four-level variable, Personality Trait DF=3,
and Participant ID DF=79).
The whole model is significant (?2 = 128.22,
p < .0041, R Square (U)= .05; although note that
R Square (U) is not comparable to regular R Square,
and therefore cannot be interpreted as a percentage
of variance explained; model DF= 89). To investi-
gate effects of native/non-native speaker effects on
personality judgement accuracy, this variable was
included in earlier models as a binary variable (Na-
tive Speaker: native=1; non-native=0), but no sig-
nificant effect was found (?2 = 0.98, p = .3228).
Therefore data from all participants are included in
the analyses here, and the native/non-native variable
is not included in the model. For the interactions,
there is a significant relationship between Dialogue
Alignment and accuracy in judgement of Personal-
ity Trait (?2 = 13.67, p = .0034). Further exami-
nation of this relationship shows that in the case of
Agreeableness, accuracy decreases when alignment
is present in the dialogue (?2 = 10.90, p = .0010),
whereas in the case of Conscientiousness, percep-
tion accuracy significantly increases with alignment
(?2 = 4.38, p= .0364). This is shown in Figure 1.
There is a significant main effect for Personal-
ity Trait judged (?2 = 17.04, p = .0007): param-
eter estimates show that accuracy of judgement is
significantly more accurate for Extraversion (?2 =
7.21, p = .0073), but less accurate for Agreeable-
ness (?2 = 5.54, p = .0186) and Conscientiousness
(?2 = 8.09, p = .0044). No main effect was found
for Dialogue Alignment relative to accuracy of per-
sonality judgement (?2 = 2.16, p= .1420).
44
A C E N
Personality Trait
Agr
eem
ent 
(Ge
ner
ated
 Pe
rson
ality
 vs.
 Ra
ter 
Jud
gem
ents
)
0.0
0.2
0.4
0.6
0.8
1.0 ?
?
No AlignmentAlignment
Figure 1: Accuracy of personality judgements.
5.2 Ratings of ?Getting on? and ?Smoothness?
In the following we are interested in examining what
dialogue characteristics lead to the rater judgements
of ?getting on?. Using an ordinal logistic regression
(DV: how well the characters were judged to ?get
on?, seven point scale from ?very badly? to ?very
well?) the following independent variables, coded as
described in the previous section, were entered into
the model: Dialogue Alignment and Native Speaker
(Personality Trait was also entered into the model,
but did not reach significance). Participant ID was
included in the model to account for the repeated
measures design. Again, we use likelihood ratio
effect tests and note parameter estimates for one
degree of freedom (N=2560). The whole model
is significant (?2 = 1396.75, p < .0001, R Square
(U)= .15; model DF=89): A main effect for Dia-
logue Alignment (?2 = 244.94, p < .0001), shows
alignment decreased perceptions of ?getting on?.
Similarly, ordinal logistic regressions were used
to probe influencing factors in decisions of rating
dialogue smoothness (DV: smoothness rated on a
seven point scale from ?not at all smoothly? to ?very
smoothly?). The following independent variables,
coded as described in the previous section, were en-
tered into the model: Dialogue Alignment and Na-
tive Speaker (again Personality Trait did not reach
significance for inclusion). Again, Participant ID
was included in the model to account for the re-
peated measures design (parameter estimates and
likelihood ratio effect tests are for one degree of
freedom, N=2560, Condition, DF=3; Participant
ID, DF=78). The whole model is significant (?2 =
1291.28, p < .0001), with an R Square (U) of 0.13
(model DF=89). There are strong main effects for
Dialogue Alignment (?2 = 188.27, p < .0001), and
Native Speaker (?2= 110.00, p< .0001). Examina-
tion of the parameter estimates reveals negative rela-
tionships between ratings of smoothness and Native
Speaker, and Dialogue Alignment, implying that na-
tive speakers significantly rated the dialogues as be-
ing less smooth than the non-native speakers, and
also that dialogues with alignment were rated sig-
nificantly less smooth than those without alignment.
6 Evaluation Method
To better understand the linguistic alignment pro-
cesses which drive the participants? judgements in
the previous experiment, we performed further anal-
ysis. In particular, we coded the forms of alignment
present in each utterance of each dialogue, relative
to the previous utterance. The forms of alignment
were coded as follows: Polarity (matching a posi-
tive or negative opinion), Topic (whether the topic is
the same or shifts), Word (instances of alignment of
individual words of the previous utterance), Phrase
(alignment of phrases), Construction (alignment at
a grammatical construction level). Each instance of
alignment for a given utterance was counted, with
an overall score generated for the whole dialogue.
This coding procedure was performed by one re-
searcher and subsequently evaluated by a second,
with disputes resolved by mutual agreement. In the
following analysis we do not distinguish between di-
alogues intentionally generated with alignment and
those without, but instead include all dialogues in
the analysis to examine which objectively measured
forms of alignment relate to the judges? perceptions
for personality, ?getting on? and ?smoothness?.
7 Evaluation Results
7.1 Alignment Forms and Personality
Accuracy of judgements of personality ratings and
dialogue alignment was analysed for each of the four
45
personality traits (A, C, E, N) independently using
nominal logistic regression (DV: rater vs. gener-
ated personality agreement coded 0 or 1; IVs: occur-
rence scores for Polarity, Topic, Word, Phrase, and
Construction). For Agreeableness the whole model
is significant (?2 = 85.74, p < .0001, R Square
(U)= .10; model DF=5, N=640), with Topic align-
ment (?2 = 16.68, p < .0001), followed by Polar-
ity (?2 = 10.13, p= .0015) and Construction (?2 =
6.19, p = .0128) alignment all positively related to
perceptions of Agreeableness. For Conscientious-
ness (whole model ?2 = 11.26, p= .0465, R Square
(U)= .01; DF=5, N=640), Polarity alignment is in-
versely related to perceptions of Conscientiousness
(?2 = 5.12, p = .0236). In the case of Neuroti-
cism and Extraversion, the models are not significant
(?2 = 5.37, p = .3719, and ?2 = 1.49, p = .2226,
respectively; both DF=5, N=320).
7.2 Alignment Forms and ?Getting On? and
?Smoothness?
The relationship between the different forms of
alignment present in the dialogues and the judges?
ratings of ?getting on? and ?smoothness? were eval-
uated in two separate ordinal logistic models, in
which they were entered as the dependent variable.
The five alignment types (Polarity, Topic, Word,
Phrase, and Construction) were entered as indepen-
dent variables. Participant ID was also entered into
the model as an independent variable, since multiple
responses were collected from each participant.
Ratings of ?getting on? (whole model ?2 =
1595.10, p < .0001, R Square (U)= .17; DF=84,
N=2560) show that Polarity (?2 = 385.45, p <
.0001), Construction (?2 = 72.30, p < .0001) and
Topic (?2= 16.68, p= .0014) alignment all relate to
greater scores of perceived getting on. Conversely,
Word alignment leads to reduced scores of perceived
getting on (?2 = 14.13, p = .0002). For ratings of
dialogue ?smoothness? (?2 = 1519.31, p= .0014, R
Square (U)= .16; DF=84, N=2560), again Polarity
(?2 = 209.55, p < .0001), Topic (?2 = 39.39, p <
.0001) and Construction (?2 = 28.01, p < .0001)
alignment all lead to increased ratings of ?smooth-
ness?. Similarly, Word alignment has a negative
impact upon perceptions of dialogue ?smoothness?
(?2 = 29.24, p < .0001).
8 Discussion
We now discuss the perception and evaluation re-
sults of the CRAG 2 system in greater detail. In
terms of personality perception, extraversion is ac-
curately perceived, with agreeableness and consci-
entiousness less so, which matches findings from
personality perception studies in other contexts, in-
cluding text based computer-mediated communica-
tion (Li and Chignell, 2010; Gill et al, 2006). It
is interesting to note, however, that alignment helps
perception of conscientiousness, but hurts ratings of
agreeableness. Reduced accuracy in perception of
agreeableness, which is important to relationships,
may have a negative impact on the use of dialogues
in collaborative settings (Rammstedt and Schupp,
2008). Further work could usefully examine ways in
which these characteristics can be generated in more
readily perceptible ways. Interestingly, personality
perception is unaffected by whether the judges are
native English speakers or not. This is a notable
finding, and apparently implies that the social infor-
mation relating to personality is available in the text
only environment, or through the generation pro-
cess, it is equally accessible to native and non-native
English speakers. Native speaking judges were more
critical in rating dialogue smoothness and characters
getting on, perhaps indicating a finer-grained aware-
ness of linguistic cues in interpersonal interaction,
or else just greater confidence in making negative
judgements of their native language.
Our finding that our generated alignment actually
decreases the perceived positivity of the relationship
is contrary to what is generally predicted by the lit-
erature (Brennan and Clark, 1996; Shepard et al,
2001; Pickering and Garrod, 2004); but cf. Nieder-
hoffer and Pennebaker (2002). Likewise, we would
also have expected the dialogues with alignment to
have been perceived to have gone more smoothly.
However, in our evaluation of the different types
of alignment, we note that alignment per se is not
necessarily a bad thing: Generally alignment of Po-
larity, Topic, and Construction are seen positively
leading to higher ratings of ?getting on?, ?smooth-
ness?, and increased accurate perception of Agree-
ableness; repetition of individual words is however
viewed negatively, and leads to lower ratings of ?get-
ting on? and ?smoothness?.
46
There are a number of possible explanations for
these negative responses to our generated dialogue
alignment. They hinge on understanding what is
involved in generating alignment, or similar be-
haviour, in dialogue participants. First, it could be
that our dialogues encode the ?wrong? type of simi-
larity. For example, the alignment and entrainment
approaches to similarity usually study task-based di-
alogues, which often focus on establishing a shared
vocabulary for referencing objects (i.e., at the word
level). In such cases, the similarity arises either
through priming mechanisms, or the establishment
of common ground. Given that we used an align-
ment model to generate similarity in our dialogues,
this kind of repetition or similarity may seem incon-
gruent or out of place in dialogues that are not task-
based (cf. negative impact of word-level alignment).
A second explanation might be that similarity re-
lates to positive outcomes when it occurs over a
longer, rather than shorter, period of time (Reit-
ter, 2008). In the current study the dialogues con-
sisted of eight turns, thus similarity was not gener-
ated over a long period. Indeed, linguistic similarity
over a longer period of time may be more consis-
tent with perceptions of social similarity, such as in-
group, rather than outgroup, membership (Shepard
et al, 2001). Indeed, in such contexts word choice
is an important feature in dialogue and would be use-
ful to incorporate into a dialogue model to simulate
ingroup membership.
Third, in communication accommodation theory
it is ?convergence? ? the process of increasing sim-
ilarity between interlocutors ? which is important,
rather than similarity alone. In the current study,
convergence was not examined since the dialogues
were generated with static levels of alignment.
So how do these findings relate back to the area of
dialogue generation for applied contexts? Similarly
to findings for the PERSONAGE system (Mairesse
and Walker, 2010), personality in our generated di-
alogues is perceived with similar accuracy to the
way humans perceive personality of other humans.
This suggests that our CRAG 2 system can create
believable characters to whom the user can poten-
tially relate while auditing the dialogues, or using a
dialogue-based interface. That alignment can have
negative effects on dialogue perception we propose
is due to the form of alignment depicted in these gen-
erated dialogues (i.e., task-based nature emphasising
similarity at the word level), rather than alignment in
general. We do not take this result to necessarily in-
dicate that alignment in generated dialogues should
be avoided. Rather, its implementation should be
carefully considered, especially to ensure that the
form of similarity achieved makes sense in the com-
municative context. Indeed, as we show in the eval-
uation of the generated dialogues, alignment at the
Polarity, Topic, and Construction levels is gener-
ally viewed positively, however in contrast align-
ment at the Word level tends to be viewed more neg-
atively. One of the key suggestions arising from this
study is that the different forms of dialogue simi-
larity cannot simply be used interchangeably, with
alignment found in task-based dialogues which may
include many instances of word-level repetition and
alignment not necessarily appropriate in non-task
dialogues, and thus not automatically resulting in
perceptions of positivity. We note that non-native
speakers were more forgiving in their ratings of the
dialogues containing alignment. Given that they
were equally able to perceive the personality of the
characters, this may be due to non-native speakers
having fewer expectations of alignment behaviour
in dialogue. Indeed in some contexts, greater align-
ment, and thus repetition, may be beneficial for non-
native speakers auditing dialogues.
To conclude, personality in our generated dia-
logues was perceived with comparable accuracy to
human texts, but alignment or similarity between
speakers ? especially at the word level ? regarded
negatively. We would like to see future work exam-
ine further the responses to different forms of align-
ment, including convergence, in generated dialogue.
9 Acknowledgements
We acknowledge Edinburgh-Stanford Link funding,
and the partial support of the Future and Emerging
Technologies programme FP7-COSI-ICT of the Eu-
ropean Commission (project QLectives, grant no.:
231200). We thank Amy Isard, Scott Nowson and
Michael White for their assistance in this work. A
version of the paper was presented at the Twentieth
Society for Text and Discourse conference; thanks
to Herb Clark, Max Louwerse and Michael Schober
for their insights regarding linguistic similarity.
47
References
[Bortfeld and Brennan1997] H. Bortfeld and S. E. Bren-
nan. 1997. Use and acquisition of idiomatic expres-
sions in referring by native and non-native speakers.
Discourse Processes, 23:119?147.
[Brennan and Clark1996] Susan E. Brennan and Her-
bert H. Clark. 1996. Conceptual pacts and lexi-
cal choice in conversation. Journal of Experimen-
tal Psychology: Learning, Memory, and Cognition,
22(6):1482?1493, November.
[Brennan1996] Susan E. Brennan. 1996. Lexical entrain-
ment in spontaneous dialog. In International Sympo-
sium on Spoken Dialog, pages 41?44.
[Brockmann2009] Carsten Brockmann. 2009. Personal-
ity and Alignment Processes in Dialogue: Towards a
Lexically-Based Unified Model. Ph.D. thesis, Univer-
sity of Edinburgh, UK.
[Cassell et al2000] Justine Cassell, Joseph Sullivan, Scott
Prevost, and Elizabeth Churchill, editors. 2000. Em-
bodied Conversational Agents. MIT Press, Cam-
bridge, MA, USA.
[Foster and White2004] Mary Ellen Foster and Michael
White. 2004. Techniques for text planning with
XSLT. In Proceedings of the 4th Workshop on NLP
and XML (NLPXML-04) at the 42nd Annual Meet-
ing of the Association for Computational Linguistics
(ACL-04), pages 1?8, Barcelona, Spain.
[Gill and Oberlander2002] Alastair J. Gill and Jon Ober-
lander. 2002. Taking care of the linguistic features of
extraversion. In Proceedings of the 24th Annual Con-
ference of the Cognitive Science Society (CogSci2002),
pages 363?368, Fairfax, VA, USA.
[Gill et al2006] Alastair J. Gill, Jon Oberlander, and Eliz-
abeth Austin. 2006. Rating e-mail personality at zero
acquaintance. Personality and Individual Differences,
40(3):497?507.
[Hernault et al2008] Hugo Hernault, Paul Piwek, Helmut
Prendinger, and Mitsuru Ishizuka. 2008. Generating
dialogues for virtual agents using nested textual coher-
ence relations. In Proceedings of Intelligent Virtual
Agents, pages 139?145.
[Isbister and Nass2000] Katherine Isbister and Clifford
Nass. 2000. Consistency of personality in inter-
active characters: verbal cues, non-verbal cues, and
user characteristics. International Journal of Human?
Computer Studies, 53(2):251?267.
[Li and Chignell2010] J. Li and M. Chignell. 2010. Birds
of a feather: How personality influences blog writ-
ing and reading. Int. J. Human-Computer Studies,
68:589?602.
[Mairesse and Walker2010] Franc?ois Mairesse and Mari-
lyn Walker. 2010. Towards personality-based user
adaptation: Psychologically informed stylistic lan-
guage generation. User Modeling and User-Adapted
Interaction, 20(3):227?278.
[Niederhoffer and Pennebaker2002] Kate G. Niederhof-
fer and James W. Pennebaker. 2002. Linguistic style
matching in social interaction. Journal of Language
and Social Psychology, 21(4):337?360.
[Nowson et al2005] S. Nowson, J. Oberlander, and A.J.
Gill. 2005. Weblogs, genres and individual differ-
ences. In Proceedings of the 27th Annual Conference
of the Cognitive Science Society, pages 1666?1671.
[Pennebaker and King1999] James W. Pennebaker and
Laura A. King. 1999. Linguistic styles: Language
use as an individual difference. Journal of Personality
and Social Psychology, 77(6):1296?1312.
[Pickering and Garrod2004] Martin J. Pickering and Si-
mon Garrod. 2004. Toward a mechanistic psychol-
ogy of dialogue. Behavioral and Brain Sciences,
27(2):169?225.
[Porzel et al2006] Robert Porzel, Annika Scheffler, and
Rainer Malaka. 2006. How entrainment increases di-
alogical efficiency. In Proceedings of Workshop on on
Effective Multimodal Dialogue Interfaces.
[Rammstedt and Schupp2008] Beatrice Rammstedt and
Ju?rgen Schupp. 2008. Only the congruent survive ?
personality similarities in couples. Personality and In-
dividual Differences, 45(6):533?535.
[Reitter2008] David Reitter. 2008. Context Effects in
Language Production: Models of Syntactic Priming in
Dialogue Corpora. Ph.D. thesis, University of Edin-
burgh, UK.
[Shepard et al2001] Carolyn A. Shepard, Howard Giles,
and Beth A. Le Poire. 2001. Communication accom-
modation theory. In W. Peter Robinson and Howard
Giles, editors, The New Handbook of Language and
Social Psychology, chapter 1.2, pages 33?56. JohnWi-
ley & Sons, Chichester, UK.
[van Deemter et al2008] Kees van Deemter, Brigitte
Krenn, Paul Piwek, Martin Klesen, Marc Schro?der,
and Stefan Baumann. 2008. Fully generated scripted
dialogue for embodied agents. Artificial Intelligence,
172(10):1219?1244.
[White2006a] Michael White. 2006a. CCG chart real-
ization from disjunctive inputs. In Proceedings of the
4th International Natural Language Generation Con-
ference (INLG-06), pages 9?16, Sydney, Australia.
[White2006b] Michael White. 2006b. Efficient realiza-
tion of coordinate structures in Combinatory Catego-
rial Grammar. Research on Language and Computa-
tion, 4(1):39?75.
48
