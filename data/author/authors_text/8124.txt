Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 9?12,
Sydney, July 2006. c?2006 Association for Computational Linguistics
LeXFlow: a System for Cross-fertilization of Computational Lexicons 
Maurizio Tesconi and Andrea Marchetti 
CNR-IIT 
Via Moruzzi 1, 56024 Pisa, Italy 
{maurizio.tesconi,andrea.marchetti}@iit.cnr.it 
Francesca Bertagna and Monica Monachini and Claudia Soria and Nicoletta Calzolari 
CNR-ILC 
Via Moruzzi 1, 56024 Pisa, Italy 
{francesca.bertagna,monica.monachini, 
claudia.soria,nicoletta.calzolari}@ilc.cnr.it 
 
  
Abstract 
This demo presents LeXFlow, a work-
flow management system for cross-
fertilization of computational lexicons. 
Borrowing from techniques used in the 
domain of document workflows, we 
model the activity of lexicon manage-
ment as a set of workflow types, where 
lexical entries move across agents in the 
process of being dynamically updated. A 
prototype of LeXFlow has been imple-
mented with extensive use of XML tech-
nologies (XSLT, XPath, XForms, SVG) 
and open-source tools (Cocoon, Tomcat, 
MySQL). LeXFlow is a web-based ap-
plication that enables the cooperative and 
distributed management of computational 
lexicons. 
1 Introduction 
LeXFlow is a workflow management system 
aimed at enabling the semi-automatic manage-
ment of computational lexicons. By management 
we mean not only creation, population and vali-
dation of lexical entries but also integration and 
enrichment of different lexicons.  
A lexicon can be enriched by resorting to 
automatically acquired information, for instance 
by means of an application extracting informa-
tion from corpora. But a lexicon can be enriched 
also by resorting to the information available in 
another lexicon, which can happen to encode 
different types of information, or at different lev-
els of granularity. LeXFlow intends to address 
the request by the computational lexicon com-
munity for a change in perspective on computa-
tional lexicons: from static resources towards 
dynamically configurable multi-source entities, 
where the content of lexical entries is dynami-
cally modified and updated on the basis of the 
integration of knowledge coming from different 
sources (indifferently represented by human ac-
tors, other lexical resources, or applications for 
the automatic extraction of lexical information 
from texts). 
This scenario has at least two strictly related 
prerequisites: i) existing lexicons have to be 
available in or be mappable to a standard form 
enabling the overcoming of their respective dif-
ferences and idiosyncrasies, thus making their 
mutual comprehensibility a reality; ii) an archi-
tectural framework should be used for the effec-
tive and practical management of lexicons, by 
providing the communicative channel through 
which lexicons can really communicate and 
share the information encoded therein. 
For the first point, standardization issues obvi-
ously play the central role. Important and exten-
sive efforts have been and are being made to-
wards the extension and integration of existing 
and emerging open lexical and terminological 
standards and best practices, such as EAGLES, 
ISLE, TEI, OLIF, Martif (ISO 12200), Data 
Categories (ISO 12620), ISO/TC37/SC4, and 
LIRICS. An important achievement in this re-
spect is the MILE, a meta-entry for the encoding 
of multilingual lexical information (Calzolari et 
al., 2003); in our approach we have embraced the 
MILE model.  
As far as the second point is concerned, some 
initial steps have been made to realize frame-
works enabling inter-lexica access, search, inte-
gration and operability. Nevertheless, the general 
impression is that little has been made towards 
the development of new methods and techniques 
9
for the concrete interoperability among lexical 
and textual resources. The intent of LeXFlow is 
to fill in this gap.  
2 LeXFlow Design and Application 
LeXFlow is conceived as a metaphoric extension 
and adaptation to computational lexicons of 
XFlow, a framework for the management of 
document workflows (DW, Marchetti et al, 
2005).  
A DW can be seen as a process of cooperative 
authoring where the document can be the goal of 
the process or just a side effect of the coopera-
tion. Through a DW, a document life-cycle is 
tracked and supervised, continually providing 
control over the actions leading to document 
compilation In this environment a document 
travels among agents who essentially carry out 
the pipeline receive-process-send activity.  
Each lexical entry can be modelled as a docu-
ment instance (formally represented as an XML 
representation of the MILE lexical entry), whose 
behaviour can be formally specified by means of 
a document workflow type (DWT) where differ-
ent agents, with clear-cut roles and responsibili-
ties, act over different portions of the same entry 
by performing different tasks.  
Two types of agents are envisaged: external 
agents are human or software actors which per-
form activities dependent from the particular 
DWT, and internal agents are software actors 
providing general-purpose activities useful for 
any DWT and, for this reason, implemented di-
rectly into the system. Internal agents perform 
general functionalities such as creat-
ing/converting a document belonging to a par-
ticular DWT, populating it with some initial data, 
duplicating a document to be sent to multiple 
agents, splitting a document and sending portions 
of information to different agents, merging du-
plicated documents coming from multiple agents, 
aggregating fragments, and finally terminating 
operations over the document. An external agent 
executes some processing using the document 
content and possibly other data, e.g. updates the 
document inserting the results of the preceding 
processing, signs the updating and finally sends 
the document to the next agent(s). 
The state diagram in Figure 1 describes the 
different states of the document instances. At the 
starting point of the document life cycle there is 
a creation phase, in which the system raises a 
new instance of a document with information 
attached.  
Figure 1. Document State Diagram. 
 
The document instance goes into pending 
state. When an agent gets the document, it goes 
into processing state in which the agent compiles 
the parts under his/her responsibility. If the 
agent, for some reason, doesn?t complete the in-
stance elaboration, he can save the work per-
formed until that moment and the document in-
stance goes into freezing state. If the elaboration 
is completed (submitted), or cancelled, the in-
stance goes back into pending state, waiting for a 
new elaboration. 
Borrowing from techniques used in DWs, we 
have modelled the activity of lexicon manage-
ment as a set of DWT, where lexical entries 
move across agents and become dynamically 
updated.  
3 Lexical Workflow General Architec-
ture 
As already written, LeXFlow is based on XFlow 
which is composed of three parts: i) the Agent 
Environment, i.e. the agents participating to all 
DWs; ii) the Data, i.e. the DW descriptions plus 
the documents created by the DW and iii) the 
Engine. Figure 2 illustrates the architecture of the 
framework. 
Figure 2. General Architecture. 
 
The DW environment is the set of human and 
software agents participating to at least one DW. 
10
The description of a DW can be seen as an ex-
tension of the XML document class. A class of 
documents, created in a DW, shares the schema 
of their structure, as well as the definition of the 
procedural rules driving the DWT and the list of 
the agents attending to it. Therefore, in order to 
describe a DWT, we need four components:  
? a schema of the documents involved in the 
DWT; 
? the agent roles chart, i.e. the set of the ex-
ternal and internal agents, operating on the 
document flow. Inside the role chart these 
agents are organized in roles and groups in 
order to define who has access to the 
document. This component constitutes the 
DW environment; 
? a document interface description used by 
external agents to access the documents. 
This component also allows checking ac-
cess permissions to the document; 
? a document workflow description defining 
all the paths that a document can follow in 
its life-cycle, the activities and policies for 
each role.  
The document workflow engine constitutes the 
run-time support for the DW, it implements the 
internal agents, the support for agents? activities, 
and some system modules that the external agents 
have to use to interact with the DW system. 
Also, the engine is responsible for two kinds of 
documents useful for each document flow: the 
documents system logs and the documents system 
metadata. 
4 The lexicon Augmentation Workflow 
Type 
In this section we present a first DWT, called 
?lexicon augmentation?, for dynamic augmenta-
tion of semantic MILE-compliant lexicons. This 
DWT corresponds to the scenario where an entry 
of a lexicon A becomes enriched via basically 
two steps. First, by virtue of being mapped onto 
a corresponding entry belonging to a lexicon B, 
the entry(A) inherits the semantic relations avail-
able in the mapped entry(B). Second, by resorting 
to an automatic application that acquires infor-
mation about semantic relations from corpora, 
the acquired relations are integrated into the en-
try and proposed to the human encoder. 
In order to test the system we considered the 
Simple/Clips (Ruimy et al, 2003) and ItalWord-
Net (Roventini et al, 2003) lexicons.  
An overall picture of the flow is shown in Fig-
ure 3, illustrating the different agents participat-
ing to the flow. Rectangles represent human ac-
tors over the entries, while the other figures 
symbolize software agents: ovals are internal 
agents and octagons external ones. The function-
ality offered to human agents are: display of 
MILE-encoded lexical entries, selection of lexi-
cal entries, mapping between lexical entries be-
longing to different lexicons1, automatic calcula-
tions of new semantic relations (either automati-
cally derived from corpora and mutually inferred 
from the mapping) and manual verification of the 
newly proposed semantic relations.  
5 Implementation Overview 
Our system is currently implemented as a web-
based application where the human external 
agents interact with system through a web 
browser. All the human external agents attending 
the different document workflows are the users 
of system. Once authenticated through username 
and password the user accesses his workload 
area where the system lists all his pending docu-
ments (i.e. entries) sorted by type of flow. 
The system shows only the flows to which the 
user has access. From the workload area the user 
                                                 
1 We hypothesize a human agent, but the same role could be 
performed by a software agent. To this end, we are investi-
gating the possibility of automatically exploiting the proce-
dure described in (Ruimy and Roventini, 2005). 
Figure 3. Lexicon Augmentation Workflow. 
 
11
can browse his documents and select some op-
erations  
 
Figure 4. LeXFlow User Activity State Diagram. 
 
such as: selecting and processing pending docu-
ment; creating a new document; displaying a 
graph representing a DW of a previously created 
document; highlighting the current position of 
the document. This information is rendered as an 
SVG (Scalable Vector Graphics) image. Figure 5 
illustrates the overall implementation of the sys-
tem. 
5.1 The Client Side: External Agent Inter-
action 
The form used to process the documents is ren-
dered with XForms. Using XForms, a browser 
can communicate with the server through XML 
documents and is capable of displaying the 
document with a user interface that can be de-
fined for each type of document. A browser with 
XForms capabilities will receive an XML docu-
ment that will be displayed according to the 
specified template, then it will let the user edit 
the document and finally it will send the modi-
fied document to the server. 
5.2 The Server Side 
The server-side is implemented with Apache 
Tomcat, Apache Cocoon and MySQL. Tomcat is 
used as the web server, authentication module 
(when the communication between the server 
and the client needs to be encrypted) and servlet 
container. Cocoon is a publishing framework that 
uses the power of XML. The entire functioning 
of Cocoon is based on one key concept: compo-
nent pipelines. The pipeline connotes a series of 
events, which consists of taking a request as in-
put, processing and transforming it, and then giv-
ing the desired response. MySQL is used for 
storing and retrieving the documents and the 
status of the documents. 
Each software agent is implemented as a web-
service and the WSDL language is used to define 
its interface.  
References 
Nicoletta Calzolari, Francesca Bertagna, Alessandro 
Lenci and Monica Monachini, editors. 2003. Stan-
dards and Best Practice for Multilingual Computa-
tional Lexicons. MILE (the Multilingual ISLE 
Lexical Entry). ISLE Deliverable D2.2 & 3.2. Pisa. 
Andrea Marchetti, Maurizio Tesconi, and Salvatore 
Minutoli. 2005. XFlow: An XML-Based Docu-
ment-Centric Workflow. In Proceedings of WI-
SE?05, pages 290- 303, New York, NY, USA. 
Adriana Roventini, Antonietta Alonge, Francesca 
Bertagna, Nicoletta Calzolari, Christian Girardi, 
Bernardo Magnini, Rita Marinelli, and Antonio 
Zampolli. 2003. ItalWordNet: Building a Large 
Semantic Database for the Automatic Treatment of 
Italian. In Antonio Zampolli, Nicoletta Calzolari, 
and Laura Cignoni, editors, Computational Lingui-
stics in Pisa, Istituto Editoriale e Poligrafico Inter-
nazionale, Pisa-Roma, pages 745-791. 
Nilda Ruimy, Monica Monachini, Elisabetta Gola, 
Nicoletta Calzolari, Cristina Del Fiorentino, Marisa 
Ulivieri, and Sergio Rossi. 2003. A Computational 
Semantic Lexicon of Italian: SIMPLE. In Antonio 
Zampolli, Nicoletta Calzolari, and Laura Cignoni, 
editors, Computational Linguistics in Pisa, Istituto 
Editoriale e Poligrafico Internazionale, Pisa-Roma, 
pages 821-864. 
Nilda Ruimy and Adriana Roventini. 2005. Towards 
the linking of two electronic lexical databases of 
Italian. In  Proceedings of L&T'05 - Language 
Technologies as a Challenge for Computer Science 
and Linguistics, pages 230-234, Poznan, Poland.
Figure 5. Overall System Implementation. 
12
Proceedings of the Workshop on Multilingual Language Resources and Interoperability, pages 17?24,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Towards Agent-based Cross-lingual Interoperability of Distributed    
Lexical Resources 
Claudia Soria* Maurizio Tesconi? Andrea Marchetti?
Francesca Bertagna* Monica Monachini*
Chu-Ren Huang?    Nicoletta Calzolari*
*CNR-ILC and ?CNR-IIT 
Via Moruzzi 1, 56024 Pisa 
Italy 
{firstname.lastname@ilc.cnr.it} 
{firstname.lastname@iit.cnr.it} 
?Academia Sinica  
Nankang, Taipei  
Taiwan 
churen@gate.sinica.edu.tw 
 
  
 
Abstract 
In this paper we present an application 
fostering the integration and interopera-
bility of computational lexicons, focusing 
on the particular case of mutual linking 
and cross-lingual enrichment of two wor-
dnets, the ItalWordNet and Sinica BOW 
lexicons. This is intended as a case-study 
investigating the needs and requirements 
of semi-automatic integration and inter-
operability of lexical resources. 
1 Introduction 
In this paper we present an application fostering 
the integration and interoperability of computa-
tional lexicons, focusing on the particular case of 
mutual linking and cross-lingual enrichment of 
two wordnets. The development of this applica-
tion is intended as a case-study and a test-bed for 
trying out needs and requirements posed by the 
challenge of semi-automatic integration and en-
richment of practical, large-scale multilingual 
lexicons for use in computer applications. While 
a number of lexicons already exist, few of them 
are practically useful, either since they are not 
sufficiently broad or because they don?t cover 
the necessary level of detailed information. 
Moreover, multilingual language resources are 
not as widely available and are very costly to 
construct: the work process for manual develop-
ment of new lexical resources or for tailoring 
existing ones is too expensive in terms of effort 
and time to be practically attractive.  
The need of ever growing lexical resources for 
effective multilingual content processing has 
urged the language resource community to call 
for a radical change in the perspective of lan-
guage resource creation and maintenance and the 
design of a ?new generation? of LRs: from static, 
closed and locally developed resources to shared 
and distributed language services, based on open 
content interoperability standards. This has often 
been called a ?change in paradigm? (in the sense 
of Kuhn, see Calzolari and Soria, 2005; Calzolari 
2006). Leaving aside the tantalizing task of 
building on-site resources, the new paradigm 
depicts a scenario where lexical resources are 
cooperatively built as the result of controlled co-
operation of different agents, adopting the para-
digm of accumulation of knowledge so success-
ful in more mature disciplines, such as biology 
and physics (Calzolari, 2006).  
According to this view (or, better, this vision), 
different lexical resources reside over distributed 
places and can not only be accessed but choreo-
graphed by agents presiding the actions that can 
be executed over them. This implies the ability to 
build on each other achievements, to merge re-
sults, and to have them accessible to various sys-
tems and applications. 
At the same time, there is another argument in 
favor of distributed lexical resources: language 
resources, lexicons included, are inherently dis-
tributed because of the diversity of languages 
distributed over the world. It is not only natural 
that language resources to be developed and 
maintained in their native environment. Since 
language evolves and changes over time, it is not 
possible to describe the current state of the lan-
17
guage away from where the language is spoken. 
Lastly, the vast range of diversity of languages 
also makes it impossible to have one single uni-
versal centralized resource, or even a centralized 
repository of resources. 
Although the paradigm of distributed and in-
teroperable lexical resources has largely been 
discussed and invoked, very little has been made 
in comparison for the development of new meth-
ods and techniques for its practical realization. 
Some initial steps are made to design frame-
works enabling inter-lexica access, search, inte-
gration and operability. An example is the Lexus 
tool (Kemps-Snijders et al, 2006), based on the 
Lexical Markup Framework (Romary et al, 
2006), that goes in the direction of managing the 
exchange of data among large-scale lexical re-
sources. A similar tool, but more tailored to the 
collaborative creation of lexicons for endangered 
language, is SHAWEL (Gulrajani and Harrison, 
2002). However, the general impression is that 
little has been made towards the development of 
new methods and techniques for attaining a con-
crete interoperability among lexical resources. 
Admittedly, this is a long-term scenario requiring 
the contribution of many different actors and ini-
tiatives (among which we only mention stan-
dardisation, distribution and international coop-
eration).  
Nevertheless, the intent of our project is to 
contribute to fill in this gap, by exploring in a 
controlled way the requirement and implications 
posed by new generation multilingual lexical 
resources. The paper is organized as follows: 
section 2 describes the general architectural de-
sign of our project; section 3 describes the mod-
ule taking care of cross-lingual integration of 
lexical resources, by also presenting a case-study 
involving an Italian and Chinese lexicons. Fi-
nally, section 4 presents our considerations and 
lessons learned on the basis of this exploratory 
testing. 
2 An Architecture for Integrating Lexi-
cal Resources 
 LeXFlow (Soria et al, 2006) was developed 
having in mind the long-term goal of lexical re-
source interoperability. In a sense, LeXFlow is 
intended as a proof of concept attempting to 
make the vision of an infrastructure for access 
and sharing of linguistic resources more tangible. 
LeXFlow is an adaptation to computational 
lexicons of XFlow, a cooperative web applica-
tion for the management of document workflows 
(DW, Marchetti et al, 2005). A DW can be seen 
as a process of cooperative authoring where a 
document can be the goal of the process or just a 
side effect of the cooperation. Through a DW, a 
document life-cycle is tracked and supervised, 
continually providing control over the actions 
leading to document compilation. In this envi-
ronment a document travels among agents who 
essentially carry out the pipeline receive-process-
send activity.  
There are two types of agents: external agents 
are human or software actors performing activi-
ties dependent from the particular Document 
Workflow Type; internal agents are software 
actors providing general-purpose activities useful 
for many DWTs and, for this reason, imple-
mented directly into the system. Internal agents 
perform general functionalities such as creat-
ing/converting a document belonging to a par-
ticular DW, populating it with some initial data, 
duplicating a document to be sent to multiple 
agents, splitting a document and sending portions 
of information to different agents, merging du-
plicated documents coming from multiple agents, 
aggregating fragments, and finally terminating 
operations over the document. External agents 
basically execute some processing using the 
document content and possibly other data; for 
instance, accessing an external database or 
launching an application.  
LeXFlow was born by tailoring XFlow to 
management of lexical entries; in doing so, we 
have assumed that each lexical entry can be 
modelled as a document instance, whose behav-
iour can be formally specified by means of a 
lexical workflow type (LWT). A LWT describes 
the life-cycle of a lexical entry, the agents al-
lowed to act over it, the actions to be performed 
by the agents, and the order in which the actions 
are to be executed. Embracing the view of coop-
erative workflows, agents can have different 
rights or views over the same entry: this nicely 
suits the needs of lexicographic work, where we 
can define different roles (such as encoder, anno-
tator, validator) that can be played by either hu-
man or software agents. Other software modules 
can be inserted in the flow, such as an automatic 
acquirer of information from corpora or from the 
web. Moreover, deriving from a tool designed 
for the cooperation of agents, LeXFlow allows to 
manage workflows where the different agents 
can reside over distributed places.  
LeXFlow thus inherits from XFlow the gen-
eral design and architecture, and can be consid-
ered as a specialized version of it through design 
18
of specific Lexical Workflow Types and plug-in 
of dedicated external software agents. In the next 
section we briefly illustrate a particular Lexical 
Workflow Type and the external software agents 
developed for the purpose of integrating different 
lexicons belonging to the same language. Since it 
allows the independent and coordinated sharing 
of actions over portions of lexicons, LeXFlow 
naturally lends itself as a tool for the manage-
ment of distributed lexical resources. 
Due to its versatility, LeXFlow is both a gen-
eral framework where ideas on automatic lexical 
resource integration can be tested and an infra-
structure for proving new methods for coopera-
tion among lexicon experts. 
2.1 Using LeXFlow for Lexicon Enrichment 
In previous work (Soria et al, 2006),  the LeX-
Flow framework has been tested for integration 
of lexicons with differently conceived lexical 
architectures and diverging formats. It was 
shown how interoperability is possible between 
two Italian lexicons from the SIMPLE and 
WordNet families, respectively, namely the 
SIMPLE/CLIPS (Ruimy et al, 2003) and Ital-
WordNet (Roventini et al, 2003) lexicons.  
In particular, a Lexical Workflow Type was 
designed where the two different monolingual 
semantic lexicons interact by reciprocally enrich-
ing themselves and moreover integrate informa-
tion coming from corpora. This LWT, called 
?lexicon augmentation?, explicitly addresses dy-
namic augmentation of semantic lexicons. In this 
scenario, an entry of a lexicon A becomes en-
riched via basically two steps. First, by virtue of 
being mapped onto a corresponding entry be-
longing to a lexicon B, the entryA inherits the 
semantic relations available in the mapped en-
tryB. Second, by resorting to an automatic appli-
cation that acquires information about semantic 
relations from corpora, the acquired relations are 
integrated into the entry and proposed to the hu-
man encoder. 
B
An overall picture of the flow is shown in 
Figure 1, illustrating the different agents partici-
pating in the flow. Rectangles represent human 
actors over the entries, while the other figures 
symbolize software agents: ovals are internal 
agents and octagons external ones. The two ex-
ternal agents involved in this flow are the ?rela-
tion calculator? and the ?corpora extractor?. The 
first is responsible for the mapping between the 
sets of semantic relations used by the different 
lexicons. The ?corpora extractor? module in-
vokes an application that acquires information 
about part-of relations by identifying syntactic 
constructions in a vast Italian corpus. It then 
takes care of creating the appropriate candidate 
semantic relations for each lemma that is pro-
posed by the application. 
Figure 1. Lexicons Augmentation Workflow 
Type. 
A prototype of LeXFlow has been imple-
mented with an extensive use of XML technolo-
gies (XML Schema, XSLT, XPath, XForms, 
SVG) and open-source tools (Cocoon, Tomcat, 
mySQL). It is a web-based application where 
human agents interact with the system through 
an XForms browser that displays the document 
to process as a web form whereas software 
agents interact with the system via web services. 
3 Multilingual WN Service 
In the Section above we have illustrated the gen-
eral architecture of LeXFlow and showed how a 
Lexical Workflow Type can be implemented in 
order to enrich already existing lexicons belong-
ing to the same language but realizing different 
models of lexicon encoding. In this section we 
move to a cross-lingual perspective of lexicon 
integration. We present a module that similarly 
addresses the issue of lexicon augmentation or 
enrichment focusing on mutual enrichment of 
two wordnets in different languages and residing 
at different sites. 
This module, named ?multilingual WN Ser-
vice? is responsible for the automatic cross-
lingual fertilization of lexicons having a Word-
19
Net-like structure. Put it very simply, the idea 
behind this module is that a monolingual word-
net can be enriched by accessing the semantic 
information encoded in corresponding entries of 
other monolingual wordnets.  
Since each entry in the monolingual lexicons 
is linked to the Interlingual Index (ILI, cf. Sec-
tion 3.1), a synset of a WN(A) is indirectly 
linked to another synset in another WN(B). On 
the basis of this correspondence, a synset(A) can 
be enriched by importing the relations that the 
corresponding synset(B) holds with other syn-
sets(B), and vice-versa. Moreover, the enrich-
ment of WN(A) will not only import the relations 
found in WN(B), but it will also propose target 
synsets in the language(A) on the basis of those 
found in language(B). 
The various WN lexicons reside over distrib-
uted servers and can be queried through web ser-
vice interfaces. The overall architecture for mul-
tilingual wordnet service is depicted in Figure 2. 
 
 
Figure 2. Multilingual Wordnet Service Archi-
tecture. 
 
Put in the framework of the general LeXFlow 
architecture, the Multilingual wordnet Service 
can be seen as an additional external software 
agent that can be added to the augmentation 
workflow or included in other types of lexical 
flows. For instance, it can be used not only to 
enrich a monolingual lexicon but to bootstrap a 
bilingual lexicon. 
3.1 Linking Lexicons through the ILI  
The entire mechanism of the Multilingual WN 
Service is based on the exploitation of Interlin-
gual Index (Peters et al, 1998), an unstructured 
version of WordNet used in EuroWordNet 
(Vossen et al, 1998) to link wordnets of different 
languages; each synset in the language-specific 
wordnet is linked to at least one record of the ILI 
by means of a set of equivalence relations 
(among which the most important is the 
EQ_SYNONYM, that expresses a total, perfect 
equivalence between two synsets).  
Figure 6 describes the schema of a WN lexical 
entry. Under the root ?synset? we find both in-
ternal relations (?synset relations?) and ILI Rela-
tions, which link to ILI synsets. 
Figure 3 shows the role played by the ILI as 
set of pivot nodes allowing the linkage between 
concepts belonging to different wordnets.  
 
 
Figure 3. Interlingual Linking of Language-
specific Synsets. 
 
In the Multilingual WN Service, only equiva-
lence relations of type EQ_SYNONYM and 
EQ_NEAR_SYNONYM have been taken into ac-
count, being them the ones used to represent a 
translation of concepts and also because they are 
the most exploited (for example, in IWN, they 
cover about the 60% of the encoded equivalence 
relations). The EQ_SYNONYM relation is used to 
realize the one-to-one mapping between the lan-
guage-specific synset and the ILI, while multiple 
EQ_NEAR_SYNONYM relations (because of their 
nature) might be encoded to link a single lan-
guage-specific synset to more than one ILI re-
cord. In Figure 4 we represented the possible 
relevant combinations of equivalence relations 
that can realize the mapping between synsets 
belonging to two languages. In all the four cases, 
a synset ?a? is linked via the ILI record to a syn-
set ?b? but a specific procedure has been fore-
seen in order to calculate different ?plausibility 
scores? to each situation. The procedure relies on 
different rates assigned to the two equivalence 
relations (rate ?1? to EQ_NEAR_SYNONYM rela-
tion and rate ?0? to the EQ_SYNONYM). In this 
way we can distinguish the four cases by assign-
ing respectively a weight of ?0?, ?1?, ?1? and 
?2?. 
20
  
Figure 4. Possible Combinations of Relations 
between two Lexicons A and B and the ILI. 
 
The ILI is a quite powerful yet simple method 
to link concepts across the many lexicons be-
longing to the WordNet-family. Unfortunately, 
no version of the ILI can be considered a stan-
dard and often the various lexicons exploit dif-
ferent version of WordNet as ILI 1 . This is a 
problem that is handled at web-service level, by 
incorporating the conversion tables provided by 
(Daud? et al, 2001). In this way, the use of dif-
ferent versions of WN does not have to be taken 
into consideration by the user who accesses the 
system but it is something that is resolved by the 
system itself2. This is why the version of the ILI 
is a parameter of the query to web service (see 
Section below). 
3.2 Description of the Procedure 
On the basis of ILI linking, a synset can be en-
riched by importing the relations contained in the 
corresponding synsets belonging to another 
wordnet. 
In the procedure adopted, the enrichment is 
performed on a synset-by-synset basis. In other 
words, a certain synset is selected from a word-
net resource, say WN(A). The cross-lingual mod-
ule identifies the corresponding ILI synset, on 
the basis of the information encoded in the syn-
set. It then sends a query to the WN(B) web ser-
vice providing the ID of ILI synset together with 
the ILI version of the starting WN. The WN(B) 
web service returns the synset(s) corresponding 
to the WN(A) synset, together with reliability 
scores. If WN(B) is based on a different ILI ver-
sion, it can carry out the mapping between ILI 
versions (for instance by querying the ILI map-
ping web service). The cross-lingual module then 
analyzes the synset relations encoded in the 
                                                 
1 For example, the Chinese and the Italian wordnets consid-
ered as our case-study use respectively versions 1.6 and 1.5. 
2 It should be noted, however, that the conversion between 
different WN versions could not be accurate so the mapping 
is always proposed with a probability score.
WN(B) synset and for each of them creates a 
new synset relation for the WN(A) synset. 
If the queried wordnets do not use the same set 
of synset relations, the module must take care of 
the mapping between different relation sets. In  
our case-study no mapping was needed, since the 
two sets were completely equivalent.   
Each new relation is obtained by substituting 
the target WN(B)  synset  with the corresponding 
synset WN(A), which again is found by querying 
back the WN(A) web service (all these steps 
through the ILI). The procedure is formally de-
fined by the following formula: 
 
 
 
 
 
Figure 5. Finding New Relations. 
 
Every local wordnet has to provide a web ser-
vice API  with the following methods: 
 
1. GetWeightedSynsetsByIli(ILIid, ILIversion) 
2. GetSynsetById(sysnsetID) 
3. GetSynsetsByLemma(lemma) 
 
21
The returned synsets of each method must be 
formatted in XML following the schema de-
picted in Figure 6: 
 
Figure 6. Schema of Wordnet Synsets Returned 
by WN Web Services. 
 
The scores returned by the method ?Get-
WeightedSynsetsByIli? are used by our module 
to calculate the reliability rating for each new 
proposed relation. 
3.3 A Case Study: Cross-fertilization be-
tween Italian and Chinese Wordnets. 
We explore this idea with a case-study involving 
the ItalianWordNet (Roventini et al, 2003) and 
the Academia Sinica Bilingual Ontological 
Wordnet (Sinica BOW, Huang et al, 2004).  
The BOW integrates three resources: Word-
Net, English-Chinese Translation Equivalents 
Database (ECTED), and SUMO (Suggested Up-
per Merged Ontology). With the integration of 
these three key resources, Sinica BOW functions 
both as an English-Chinese bilingual wordnet 
and a bilingual lexical access to SUMO. Sinica 
Bow currently has two bilingual versions, corre-
sponding to WordNet 1.6. and 1.7. Based on 
these bootstrapped versions, a Chinese Wordnet 
(CWN, Huang et al 2005) is under construction 
with handcrafted senses and lexical semantic re-
lations. For the current experiment, we have used 
the version linking to WordNet 1.6. 
ItalWordNet was realized as an extension of 
the Italian component of EuroWordNet. It com-
prises a general component consisting of about 
50,000 synsets and terminological wordnets 
linked to the generic wordnet by means of a spe-
cific set of relations. Each synset of ItalWordNet 
is linked to the Interlingual-Index (ILI). 
The two lexicons refer to different versions of 
the ILI (1.5 for IWN and 1.6 for BOW), thus 
making it necessary to provide a mapping be-
tween the two versions. On the other hand, no 
mapping is necessary for the set of synset rela-
tions used, since both of them adopt the same set. 
For the purposes of evaluating the cross-
lingual module, we have developed two web-
services for managing a subset of the two re-
sources.  
The following Figure shows a very simple ex-
ample where our procedure discovers and pro-
poses a new meronymy relation for the Italian 
synset {passaggio,strada,via}. This synset is 
equivalent to the ILI ?road,route? that is ILI-
connected with BOW synset ???,? ,?? (da-
o_lu, dao, lu) (Figure 7, A) . The Chinese synset 
has a meronymy relation with the synset ???
??? (wan) (B). This last  synset is equivalent 
to the ILI ?bend, crook, turn? that is ILI-
connected with Italian WordNet synset ?curva-
tura, svolta, curva? (C). Therefore the procedure 
will propose a new candidate meronymy relation 
between the two Italian WordNet synsets (D). 
 
 
Figure 7. Example of a New Proposed Mero-
nymy Relation for Italian. 
3.4 Considerations and Lessons Learned 
Given the diversity of the languages for which 
wordnets exist, we note that it is difficult to im-
plement an operational standard across all typo-
logically different languages. Work on enriching 
and merging multilingual resources presupposes 
that the resources involved are all encoded with 
the same standard. However, even with the best 
efforts of the NLP community, there are only a 
small number of language resources encoded in 
any given standard. In the current work, we pre-
suppose a de-facto standard, i.e. a shared and 
conventionalized architecture, the WordNet one. 
Since the WordNet framework is both conven-
tionalized and widely followed, our system is 
22
able to rely on it without resorting to a more sub-
stantial and comprehensive standard. In the case, 
for instance, of integration of lexicons with dif-
ferent underlying linguistic models, the availabil-
ity of the MILE (Calzolari et al, 2003) was an 
essential prerequisite of our work. Nevertheless, 
even from the perspective of the same model, a 
certain degree of standardization is required, at 
least at the format level. 
From a more general point of view, and even 
from the perspective of a limited experiment 
such as the one described in this paper, we must 
note that the realization of the new vision of dis-
tributed and interoperable language resources is 
strictly intertwined with at least two prerequi-
sites. On the one side, the language resources 
need to be available over the web; on the other, 
the language resource community will have to 
reconsider current distribution policies, and to 
investigate the possibility of developing an 
?Open Source? concept for LRs. 
4 Conclusion 
Our proposal to make distributed wordnets inter-
operable has the following applications in proc-
essing of lexical resources: 
 
? Enriching existing resources: informa-
tion is often not complete in any given 
wordnet: by making two wordnets inter-
operable, we can bootstrap semantic rela-
tions and other information from other 
wordnets. 
? Creation of new resources: multilingual 
lexicons can be bootstrapped by linking 
different language wordnets through ILI. 
? Validation of existing resources: seman-
tic relation information and other synset 
assignments can be validated when it is re-
inforced by data from a different wordnet. 
In particular, our work can be proposed as a 
prototype of a web application that would sup-
port the Global WordNet Grid initiative 
(www.globalwordnet.org/gwa/gwa_grid.htm).  
Any multilingual process, such as cross-
lingual information retrieval, must involve both 
resources and tools in a specific language and 
language pairs. For instance, a multilingual query 
given in Italian but intended for querying Eng-
lish, Chinese, French, German, and Russian 
texts, can be send to five different nodes on the 
Grid for query expansion, as well as performing 
the query itself. In this way, language specific 
query techniques can be applied in parallel to 
achieve best results that can be integrated in the 
future. As multilingualism clearly becomes one 
of the major challenges of the future of web-
based knowledge engineering, WordNet emerges 
as one leading candidate for a shared platform 
for representing a lexical knowledge model for 
different languages of the world. This is true 
even if it has to be recognized that the wordnet 
model is lacking in some important semantic in-
formation (like, for instance, a way to represent 
the semantic predicate). However, such knowl-
edge and resources are distributed. In order to 
create a shared multi-lingual knowledge base for 
cross-lingual processing based on these distrib-
uted resources, an initiative to create a grid-like 
structure has been recently proposed and pro-
moted by the Global WordNet Association, but 
until now has remained a wishful thinking. The 
success of this initiative will depend on whether 
there will be tools to access and manipulate the 
rich internal semantic structure of distributed 
multi-lingual WordNets. We believe that our 
work on LeXFlow offers such a tool to provide 
inter-operable web-services to access distributed 
multilingual WordNets on the grid. 
This allows us to exploit in a cross-lingual 
framework the wealth of monolingual lexical 
information built in the last decade. 
5 References 
Nicoletta Calzolari, Francesca Bertagna, Alessandro 
Lenci and Monica Monachini, editors. 2003. Stan-
dards and Best Practice for Multilingual Computa-
tional Lexicons. MILE (the Multilingual ISLE 
Lexical Entry). ISLE CLWG Deliverable D2.2 & 
3.2. Pisa. 
Nicoletta Calzolari and Claudia Soria. 2005. A New 
Paradigm for an Open Distributed Language Re-
source Infrastructure: the Case of Computational 
Lexicons. In Proceedings of the AAAI Spring Sym-
posium ?Knowledge Collection from Volunteer 
Contributors (KCVC05)?, pages 110-114, Stan-
ford, CA. 
Nicoletta Calzolari. 2006. Technical and Strategic 
issues on Language Resources for a Research In-
frastructure In Proceedings of the International 
Symposium on Large-scale Knowledge Resources 
(LKR2006), pages 53-58, Tokyo, Tokyo Institute 
of Technology. 
Jordi Daud?, Lluis Padr? and German Rigau. 2001. A 
Complete WN1.5 to WN1.6 Mapping. In Proceed-
ings of NAACL Workshop "WordNet and Other 
Lexical Resources: Applications, Extensions and 
23
Customizations", pages 83-88, Pittsburg, PA, USA, 
Association for Computational Linguistics.  
Greg Gulrajani and David Harrison. 2002. SHAWEL: 
Sharable and Interactive Web-Lexicons. In Pro-
ceedings of the LREC2002 Workshop on Tools and 
Resources in Field Linguistics, pages 1-4, Las 
Palmas, Canary Islands, Spain. 
Chu-Ren Huang, Ru-Yng Chang,  and Shiang-Bin 
Lee. 2004. Sinica BOW (Bilingual Ontological 
Wordnet): Integration of Bilingual WordNet and 
SUMO. In Proceedings of LREC2004, pages 1553-
1556, Lisbon, Portugal. 
Chu-Ren Huang, Chun-Ling Chen, Cui-Xia Weng, 
Hsiang-Ping Lee, Yong-Xiang Chen and Keh-jiann 
Chen. 2005. The Sinica Sense Management Sys-
tem: Design and Implementation. Computational 
Linguistics and Chinese Language Processing. 
10(4): 417-430. 
Marc Kemps-Snijders, Mark-Jan Nederhof, and Peter 
Wittenburg. 2006. LEXUS, a web-based tool for 
manipulating lexical resources. Accepted for publi-
cation in Proceedings of LREC2006, Genoa, Italy. 
Andrea Marchetti, Maurizio Tesconi, and Salvatore 
Minutoli. 2005. XFlow: An XML-Based Docu-
ment-Centric Workflow. In Proceedings of 
WISE?05, pages 290-303, New York, NY, USA. 
Wim Peters, Piek Vossen, Pedro Diez-Orzas, and 
Geert Adriaens. 1998. Cross-linguistic Alignment 
of Wordnets with an Inter-Lingual-Index. In Nancy 
Ide, Daniel Greenstein, and Piek Vossen, editors, 
Special Issue on EuroWordNet, Computers and the 
Humanities, 32(2-3): 221-251. 
Laurent Romary, Gil Francopoulo, Monica Monachi-
ni, and Susanne Salmon-Alt 2006. Lexical Markup 
Framework (LMF): working to reach a consensual 
ISO standard on lexicons. Accepted for publication 
in Proceedings of LREC2006, Genoa, Italy. 
Adriana Roventini, Antonietta Alonge, Francesca 
Bertagna, Nicoletta Calzolari, Christian Girardi, 
Bernardo Magnini, Rita Marinelli, and Antonio 
Zampolli. 2003. ItalWordNet: Building a Large 
Semantic Database for the Automatic Treatment of 
Italian. In Antonio Zampolli, Nicoletta Calzolari, 
and Laura Cignoni, editors, Computational Lingui-
stics in Pisa, IEPI, Pisa-Roma, pages 745-791. 
Nilda Ruimy, Monica Monachini, Elisabetta Gola, 
Nicoletta Calzolari, Cristina Del Fiorentino, Marisa 
Ulivieri, and Sergio Rossi. 2003. A Computational 
Semantic Lexicon of Italian: SIMPLE. In Antonio 
Zampolli, Nicoletta Calzolari, and Laura Cignoni, 
editors, Computational Linguistics in Pisa, IEPI, 
Pisa-Roma, pages 821-864. 
Claudia Soria, Maurizio Tesconi, Francesca Bertagna, 
Nicoletta Calzolari, Andrea Marchetti, and Monica 
Monachini. 2006. Moving to Dynamic Computa-
tional Lexicons with LeXFlow. Accepted for pu-
blication in Proceedings of LREC2006, Genova, I-
taly.  
Piek Vossen. 1998. Introduction to EuroWordNet. In 
Nancy Ide, Daniel Greenstein, and Piek Vossen, 
editors, Special Issue on EuroWordNet, Computers 
and the Humanities, 32(2-3): 73-89. 
 
 
 
 
24
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 75?80,
Uppsala, Sweden, 15-16 July 2010.
c
?2010 Association for Computational Linguistics
SemEval-2010 Task 17: All-words Word Sense Disambiguation
on a Specific Domain
Eneko Agirre, Oier Lopez de Lacalle
IXA NLP group
UBC
Donostia, Basque Country
{e.agirre,oier.lopezdelacalle}@ehu.es
Christiane Fellbaum
Department of Computer Science
Princeton University
Princeton, USA
fellbaum@princeton.edu
Shu-Kai Hsieh
Department of English
National Taiwan Normal University
Taipei, Taiwan
shukai@ntnu.edu.tw
Maurizio Tesconi
IIT
CNR
Pisa, Italy
maurizio.tesconi@iit.cnr.it
Monica Monachini
ILC
CNR
Pisa, Italy
monica.monachini@ilc.cnr.it
Piek Vossen, Roxanne Segers
Faculteit der Letteren
Vrije Universiteit Amsterdam
Amsterdam, Netherlands
p.vossen@let.vu.nl,roxane.segers@gmail.com
Abstract
Domain portability and adaptation of NLP
components and Word Sense Disambigua-
tion systems present new challenges. The
difficulties found by supervised systems to
adapt might change the way we assess the
strengths and weaknesses of supervised
and knowledge-based WSD systems. Un-
fortunately, all existing evaluation datasets
for specific domains are lexical-sample
corpora. This task presented all-words
datasets on the environment domain for
WSD in four languages (Chinese, Dutch,
English, Italian). 11 teams participated,
with supervised and knowledge-based sys-
tems, mainly in the English dataset. The
results show that in all languages the par-
ticipants where able to beat the most fre-
quent sense heuristic as estimated from
general corpora. The most successful ap-
proaches used some sort of supervision in
the form of hand-tagged examples from
the domain.
1 Introduction
Word Sense Disambiguation (WSD) competitions
have focused on general domain texts, as attested
in previous Senseval and SemEval competitions
(Kilgarriff, 2001; Mihalcea et al, 2004; Snyder
and Palmer, 2004; Pradhan et al, 2007). Spe-
cific domains pose fresh challenges to WSD sys-
tems: the context in which the senses occur might
change, different domains involve different sense
distributions and predominant senses, some words
tend to occur in fewer senses in specific domains,
the context of the senses might change, and new
senses and terms might be involved. Both super-
vised and knowledge-based systems are affected
by these issues: while the first suffer from differ-
ent context and sense priors, the later suffer from
lack of coverage of domain-related words and in-
formation.
The main goal of this task is to provide a mul-
tilingual testbed to evaluate WSD systems when
faced with full-texts from a specific domain. All
datasets and related information are publicly avail-
able from the task websites
1
.
This task was designed in the context of Ky-
oto (Vossen et al, 2008)
2
, an Asian-European
project that develops a community platform for
modeling knowledge and finding facts across lan-
guages and cultures. The platform operates as a
Wiki system with an ontological support that so-
cial communities can use to agree on the mean-
ing of terms in specific domains of their interest.
Kyoto focuses on the environmental domain be-
cause it poses interesting challenges for informa-
tion sharing, but the techniques and platforms are
1
http://xmlgroup.iit.cnr.it/SemEval2010/
and http://semeval2.fbk.eu/
2
http://www.kyoto-project.eu/
75
independent of the application domain.
The paper is structured as follows. We first
present the preparation of the data. Section 3 re-
views participant systems and Section 4 the re-
sults. Finally, Section 5 presents the conclusions.
2 Data preparation
The data made available to the participants in-
cluded the test set proper, and background texts.
Participants had one week to work on the test set,
but the background texts where provided months
earlier.
2.1 Test datasets
The WSD-domain comprises comparable all-
words test corpora on the environment domain.
Three texts were compiled for each language by
the European Center for Nature Conservation
3
and
Worldwide Wildlife Forum
4
. They are documents
written for a general but interested public and in-
volve specific terms from the domain. The docu-
ment content is comparable across languages. Ta-
ble 1 shows the numbers for the datasets.
Although the original plan was to annotate mul-
tiword terms, and domain terminology, due to time
constraints we focused on single-word nouns and
verbs. The test set clearly marked which were
the words to be annotated. In the case of Dutch,
we also marked components of single-word com-
pounds. The format of the test set followed that of
previous all-word exercises, which we extended to
accommodate Dutch compounds. For further de-
tails check the datasets in the task website.
The sense inventory was based on publicly
available wordnets of the respective languages
(see task website for details). The annotation pro-
cedure involved double-blind annotation by ex-
perts plus adjudication, which allowed us to also
provide Inter Annotator Agreement (IAA) figures
for the dataset. The procedure was carried out us-
ing KAFnotator tool (Tesconi et al, 2010). Due
to limitations in resources and time, the English
dataset was annotated by a single expert annota-
tor. For the rest of languages, the agreement was
very good, as reported in Table 1.
Table 1 includes the results of the random base-
line, as an indication of the polysemy in each
dataset. Average polysemy is highest for English,
and lowest for Dutch.
3
http://www.ecnc.org
4
http://www.wwf.org
Total Noun Verb IAA Random
Chinese 3989 754 450 0.96 0.321
Dutch 8157 997 635 0.90 0.328
English 5342 1032 366 n/a 0.232
Italian 8560 1340 513 0.72 0.294
Table 1: Dataset numbers, including number of
tokens, nouns and verbs to be tagged, Inter-
Annotator Agreement (IAA) and precision of ran-
dom baseline.
Documents Words
Chinese 58 455359
Dutch 98 21089
English 113 2737202
Italian 27 240158
Table 2: Size of the background data.
2.2 Background data
In addition to the test datasets proper, we also pro-
vided additional documents on related subjects,
kindly provided by ECNC and WWF. Table 2
shows the number of documents and words made
available for each language. The full list with the
urls of the documents are available from the task
website, together with the background documents.
3 Participants
Eleven participants submitted more than thirty
runs (cf. Table 3). The authors classified their runs
into supervised (S in the tables, three runs), weakly
supervised (WS, four runs), unsupervised (no runs)
and knowledge-based (KB, the rest of runs)
5
. Only
one group used hand-tagged data from the domain,
which they produced on their own. We will briefly
review each of the participant groups, ordered fol-
lowing the rank obtained for English. They all par-
ticipated on the English task, with one exception
as noted below, so we report their rank in the En-
glish task. Please refer to their respective paper in
these proceedings for more details.
CFILT: They participated with a domain-
specific knowledge-based method based on Hop-
field networks (Khapra et al, 2010). They first
identify domain-dependant words using the back-
ground texts, use a graph based on hyponyms in
WordNet, and a breadth-first search to select the
most representative synsets within domain. In ad-
dition they added manually disambiguated around
one hundred examples from the domain as seeds.
5
Note that boundaries are slippery. We show the classifi-
cations as reported by the authors.
76
English
Rank Participant System ID Type P R R nouns R verbs
1 Anup Kulkarni CFILT-2 WS 0.570 0.555 ?0.024 0.594 ?0.028 0.445 ?0.047
2 Anup Kulkarni CFILT-1 WS 0.554 0.540 ?0.021 0.580 ?0.025 0.426 ?0.043
3 Siva Reddy IIITH1-d.l.ppr.05 WS 0.534 0.528 ?0.027 0.553 ?0.023 0.456 ?0.041
4 Abhilash Inumella IIITH2-d.r.l.ppr.05 WS 0.522 0.516 ?0.023 0.529 ?0.027 0.478 ?0.041
5 Ruben Izquierdo BLC20SemcorBackground S 0.513 0.513 ?0.022 0.534 ?0.026 0.454 ?0.044
- - Most Frequent Sense - 0.505 0.505 ?0.023 0.519 ?0.026 0.464 ?0.043
6 Ruben Izquierdo BLC20Semcor S 0.505 0.505 ?0.025 0.527 ?0.031 0.443 ?0.045
7 Anup Kulkarni CFILT-3 KB 0.512 0.495 ?0.023 0.516 ?0.027 0.434 ?0.048
8 Andrew Tran Treematch KB 0.506 0.493 ?0.021 0.516 ?0.028 0.426 ?0.046
9 Andrew Tran Treematch-2 KB 0.504 0.491 ?0.021 0.515 ?0.030 0.425 ?0.044
10 Aitor Soroa kyoto-2 KB 0.481 0.481 ?0.022 0.487 ?0.025 0.462 ?0.039
11 Andrew Tran Treematch-3 KB 0.492 0.479 ?0.022 0.494 ?0.028 0.434 ?0.039
12 Radu Ion RACAI-MFS KB 0.461 0.460 ?0.022 0.458 ?0.025 0.464 ?0.046
13 Hansen A. Schwartz UCF-WS KB 0.447 0.441 ?0.022 0.440 ?0.025 0.445 ?0.043
14 Yuhang Guo HIT-CIR-DMFS-1.ans KB 0.436 0.435 ?0.023 0.428 ?0.027 0.454 ?0.043
15 Hansen A. Schwartz UCF-WS-domain KB 0.440 0.434 ?0.024 0.434 ?0.029 0.434 ?0.044
16 Abhilash Inumella IIITH2-d.r.l.baseline.05 KB 0.496 0.433 ?0.024 0.452 ?0.023 0.390 ?0.044
17 Siva Reddy IIITH1-d.l.baseline.05 KB 0.498 0.432 ?0.021 0.463 ?0.026 0.344 ?0.038
18 Radu Ion RACAI-2MFS KB 0.433 0.431 ?0.022 0.434 ?0.027 0.399 ?0.049
19 Siva Reddy IIITH1-d.l.ppv.05 KB 0.426 0.425 ?0.026 0.434 ?0.028 0.399 ?0.043
20 Abhilash Inumella IIITH2-d.r.l.ppv.05 KB 0.424 0.422 ?0.023 0.456 ?0.025 0.325 ?0.044
21 Hansen A. Schwartz UCF-WS-domain.noPropers KB 0.437 0.392 ?0.025 0.377 ?0.025 0.434 ?0.043
22 Aitor Soroa kyoto-1 KB 0.384 0.384 ?0.022 0.382 ?0.024 0.391 ?0.047
23 Ruben Izquierdo BLC20Background S 0.380 0.380 ?0.022 0.385 ?0.026 0.366 ?0.037
24 Davide Buscaldi NLEL-WSD-PDB WS 0.381 0.356 ?0.022 0.357 ?0.027 0.352 ?0.049
25 Radu Ion RACAI-Lexical-Chains KB 0.351 0.350 ?0.015 0.344 ?0.017 0.368 ?0.030
26 Davide Buscaldi NLEL-WSD WS 0.370 0.345 ?0.022 0.352 ?0.027 0.328 ?0.037
27 Yoan Gutierrez Relevant Semantic Trees KB 0.328 0.322 ?0.022 0.335 ?0.026 0.284 ?0.044
28 Yoan Gutierrez Relevant Semantic Trees-2 KB 0.321 0.315 ?0.022 0.327 ?0.024 0.281 ?0.040
29 Yoan Gutierrez Relevant Cliques KB 0.312 0.303 ?0.021 0.304 ?0.024 0.301 ?0.041
- - Random baseline - 0.232 0.232 0.253 0.172
Chinese
Rank Participant System ID Type P R R nouns R verbs
- - Most Frequent Sense - 0.562 0.562 ?0.026 0.589 ?0.027 0.518 ?0.039
1 Meng-Hsien Shih HR KB 0.559 0.559 ?0.024 0.615 ?0.026 0.464 ?0.039
2 Meng-Hsien Shih GHR KB 0.517 0.517 ?0.024 0.533 ?0.035 0.491 ?0.038
- - Random baseline - 0.321 0.321 0.326 0.312
4 Aitor Soroa kyoto-3 KB 0.322 0.296 ?0.022 0.257 ?0.027 0.360 ?0.038
3 Aitor Soroa kyoto-2 KB 0.342 0.285 ?0.021 0.251 ?0.026 0.342 ?0.040
5 Aitor Soroa kyoto-1 KB 0.310 0.258 ?0.023 0.256 ?0.029 0.261 ?0.031
Dutch
Rank Participant System ID Type P R R nouns R verbs
1 Aitor Soroa kyoto-3 KB 0.526 0.526 ?0.022 0.575 ?0.029 0.450 ?0.034
2 Aitor Soroa kyoto-2 KB 0.519 0.519 ?0.022 0.561 ?0.027 0.454 ?0.034
- - Most Frequent Sense - 0.480 0.480 ?0.022 0.600 ?0.027 0.291 ?0.025
3 Aitor Soroa kyoto-1 KB 0.465 0.465 ?0.021 0.505 ?0.026 0.403 ?0.033
- - Random baseline - 0.328 0.328 0.350 0.293
Italian
Rank Participant System ID Type P R R nouns R verbs
1 Aitor Soroa kyoto-3 KB 0.529 0.529 ?0.021 0.530 ?0.024 0.528 ?0.038
2 Aitor Soroa kyoto-2 KB 0.521 0.521 ?0.018 0.522 ?0.023 0.519 ?0.035
3 Aitor Soroa kyoto-1 KB 0.496 0.496 ?0.019 0.507 ?0.020 0.468 ?0.037
- - Most Frequent Sense - 0.462 0.462 ?0.020 0.472 ?0.024 0.437 ?0.035
- - Random baseline - 0.294 0.294 0.308 0.257
Table 3: Overall results for the domain WSD datasets, ordered by recall.
This is the only group using hand-tagged data
from the target domain. Their best run ranked 1st.
IIITTH: They presented a personalized PageR-
ank algorithm over a graph constructed from
WordNet similar to (Agirre and Soroa, 2009),
with two variants. In the first (IIITH1), the vertices
of the graph are initialized following the rank-
ing scores obtained from predominant senses as in
(McCarthy et al, 2007). In the second (IIITH2),
the graph is initialized with keyness values as in
77
0.3 0.35 0.4 0.45 0.5 0.55
Rel. Cliques
Rel. Sem. Trees-2
Rel. Sem. Trees
NLEL-WSD
RACAI-Lexical-Chains
NLEL-WSD-PDB
BLC20BG
Kyoto-1
UCF-WS-domain.noPropers
IIITH2-d.r.l.ppv.05
IIITH1-d.l.ppv.05
RACAI-2MFS-BOW
IIITH1-d.l.baseline.05
IIITH2-d.r.l.baseline.05
UCF-WS-domain
HIT-CIR-DMFS
UCF-WS
RACAI-MFS
Treematch-3
Kyoto-2
Treematch-2
Treematch
CFILT-3
BLC20SC
BLC20SCBG
IIITH2-d.l.ppr.05
IIITH1-d.l.ppr.05
CFILT-1
CFILT-2
MFS
Figure 1: Plot for all the systems which participated in English domain WSD. Each point correspond
to one system (denoted in axis Y) according each recall and confidence interval (axis X ). Systems are
ordered depending on their rank.
(Rayson and Garside, 2000). Some of the runs
use sense statistics from SemCor, and have been
classified as weakly supervised. They submitted a
total of six runs, with the best run ranking 3rd.
BLC20(SC/BG/SCBG): This system is super-
vised. A Support Vector Machine was trained us-
ing the usual set of features extracted from con-
text and the most frequent class of the target word.
Semantic class-based classifiers were built from
SemCor (Izquierdo et al, 2009), where the classes
were automatically obtained exploiting the struc-
tural properties of WordNet. Their best run ranked
5th.
Treematch: This system uses a knowledge-
based disambiguation method that requires a dic-
tionary and untagged text as input. A previously
developed system (Chen et al, 2009) was adapted
to handle domain specific WSD. They built a
domain-specific corpus using words mined from
relevant web sites (e.g. WWF and ECNC) as
seeds. Once parsed the corpus, the used the de-
pendency knowledge to build a nodeset that was
used for WSD. The background documents pro-
vided by the organizers were only used to test how
exhaustive the initial seeds were. Their best run
ranked 8th.
Kyoto: This system participated in all four
languages, with a free reimplementation of
the domain-specific knowledge-based method for
WSD presented in (Agirre et al, 2009). It
uses a module to construct a distributional the-
saurus, which was run on the background text, and
a disambiguation module based on Personalized
PageRank over wordnet graphs. Different Word-
Net were used as the LKB depending on the lan-
guage. Their best run ranked 10th. Note that this
team includes some of the organizers of the task.
A strict separation was kept, in order to keep the
test dataset hidden from the actual developers of
the system.
RACAI: This participant submitted three differ-
ent knowledge-based systems. In the first, they use
the mapping to domains of WordNet (version 2.0)
in order to constraint the domains of the content
words of the test text. In the second, they choose
among senses using lexical chains (Ion and Ste-
fanescu, 2009). The third system combines the
previous two. Their best system ranked 12th.
HIT-CIR: They presented a knowledge-based
system which estimates predominant sense from
raw test. The predominant senses were calculated
with the frequency information in the provided
background text, and automatically constructed
78
thesauri from bilingual parallel corpora. The sys-
tem ranked 14.
UCFWS: This knowledge-based WSD system
was based on an algorithm originally described in
(Schwartz and Gomez, 2008), in which selectors
are acquired from the Web via searching with lo-
cal context of a given word. The sense is cho-
sen based on the similarity or relatedness between
the senses of the target word and various types
of selectors. In some runs they include predom-
inant senses(McCarthy et al, 2007). The best run
ranked 13th.
NLEL-WSD(-PDB): The system used for the
participation is based on an ensemble of different
methods using fuzzy-Borda voting. A similar sys-
tem was proposed in SemEval-2007 task-7 (Bus-
caldi and Rosso, 2007). In this case, the com-
ponent method used where the following ones:
1) Most Frequent Sense from SemCor; 2) Con-
ceptual Density ; 3) Supervised Domain Relative
Entropy classifier based on WordNet Domains;
4) Supervised Bayesian classifier based on Word-
Net Domains probabilities; and 5) Unsupervised
Knownet-20 classifiers. The best run ranked 24th.
UMCC-DLSI (Relevant): The team submitted
three different runs using a knowledge-based sys-
tem. The first two runs use domain vectors and
the third is based on cliques, which measure how
much a concept is correlated to the sentence by
obtaining Relevant Semantic Trees. Their best run
ranked 27th.
(G)HR: They presented a Knowledge-based
WSD system, which make use of two heuristic
rules (Li et al, 1995). The system enriched the
Chinese WordNet by adding semantic relations for
English domain specific words (e.g. ecology, en-
vironment). When in-domain senses are not avail-
able, the system relies on the first sense in the Chi-
nese WordNet. In addition, they also use sense
definitions. They only participated in the Chinese
task, with their best system ranking 1st.
4 Results
The evaluation has been carried out using the stan-
dard Senseval/SemEval scorer scorer2 as in-
cluded in the trial dataset, which computes preci-
sion and recall. Table 3 shows the results in each
dataset. Note that the main evaluation measure is
recall (R). In addition we also report precision (P)
and the recall for nouns and verbs. Recall mea-
sures are accompanied by a 95% confidence in-
terval calculated using bootstrap resampling pro-
cedure (Noreen, 1989). The difference between
two systems is deemed to be statistically signifi-
cant if there is no overlap between the confidence
intervals. We show graphically the results in Fig-
ure 1. For instance, the differences between the
highest scoring system and the following four sys-
tems are not statistically significant. Note that this
method of estimating statistical significance might
be more strict than other pairwise methods.
We also include the results of two baselines.
The random baseline was calculated analytically.
The first sense baseline for each language was
taken from each wordnet. The first sense baseline
in English and Chinese corresponds to the most
frequent sense, as estimated from out-of-domain
corpora. In Dutch and Italian, it followed the in-
tuitions of the lexicographer. Note that we don?t
have the most frequent sense baseline from the do-
main texts, which would surely show higher re-
sults (Koeling et al, 2005).
5 Conclusions
Domain portability and adaptation of NLP com-
ponents and Word Sense Disambiguation systems
present new challenges. The difficulties found by
supervised systems to adapt might change the way
we assess the strengths and weaknesses of super-
vised and knowledge-based WSD systems. With
this paper we have motivated the creation of an
all-words test dataset for WSD on the environ-
ment domain in several languages, and presented
the overall design of this SemEval task.
One of the goals of the exercise was to show
that WSD systems could make use of unannotated
background corpora to adapt to the domain and
improve their results. Although it?s early to reach
hard conclusions, the results show that in each of
the datasets, knowledge-based systems are able to
improve their results using background text, and
in two datasets the adaptation of knowledge-based
systems leads to results over the MFS baseline.
The evidence of domain adaptation of supervised
systems is weaker, as only one team tried, and the
differences with respect to MFS are very small.
The best results for English are obtained by a sys-
tem that combines a knowledge-based system with
some targeted hand-tagging. Regarding the tech-
niques used, graph-based methods over WordNet
and distributional thesaurus acquisition methods
have been used by several teams.
79
All datasets and related information are publicly
available from the task websites
6
.
Acknowledgments
We thank the collaboration of Lawrence Jones-Walters, Amor
Torre-Marin (ECNC) and Karin de Boom (WWF), com-
piling the test and background documents. This work
task is partially funded by the European Commission (KY-
OTO ICT-2007-211423), the Spanish Research Department
(KNOW-2 TIN2009-14715-C04-01) and the Basque Govern-
ment (BERBATEK IE09-262).
References
Eneko Agirre and Aitor Soroa. 2009. Personalizing pager-
ank for word sense disambiguation. In Proceedings of the
12th Conference of the European Chapter of the Associa-
tion for Computational Linguistics (EACL09), pages 33?
41. Association for Computational Linguistics.
Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa. 2009.
Knowledge-based wsd on specific domains: Performing
better than generic supervised wsd. In Proceedigns of IJ-
CAI. pp. 1501-1506.?.
Davide Buscaldi and Paolo Rosso. 2007. Upv-wsd : Com-
bining different wsd methods by means of fuzzy borda
voting. In Proceedings of the Fourth International Work-
shop on Semantic Evaluations (SemEval-2007), pages
434?437.
P. Chen, W. Ding, and D. Brown. 2009. A fully unsupervised
word sense disambiguation method and its evaluation on
coarse-grained all-words task. In Proceeding of the North
American Chapter of the Association for Computational
Linguistics (NAACL09).
Radu Ion and Dan Stefanescu. 2009. Unsupervised word
sense disambiguation with lexical chains and graph-based
context formalization. In Proceedings of the 4th Language
and Technology Conference: Human Language Technolo-
gies as a Challenge for Computer Science and Linguistics,
pages 190?194.
Rub?en Izquierdo, Armando Su?arez, and German Rigau.
2009. An empirical study on class-based word sense dis-
ambiguation. In EACL ?09: Proceedings of the 12th Con-
ference of the European Chapter of the Association for
Computational Linguistics, pages 389?397, Morristown,
NJ, USA. Association for Computational Linguistics.
Mitesh Khapra, Sapan Shah, Piyush Kedia, and Pushpak
Bhattacharyya. 2010. Domain-specific word sense dis-
ambiguation combining corpus based and wordnet based
parameters. In Proceedings of the 5th International Con-
ference on Global Wordnet (GWC2010).
A. Kilgarriff. 2001. English Lexical Sample Task Descrip-
tion. In Proceedings of the Second International Work-
shop on evaluating Word Sense Disambiguation Systems,
Toulouse, France.
R. Koeling, D. McCarthy, and J. Carroll. 2005. Domain-
specific sense distributions and predominant sense acqui-
sition. In Proceedings of the Human Language Technol-
ogy Conference and Conference on Empirical Methods in
6
http://xmlgroup.iit.cnr.it/SemEval2010/
and http://semeval2.fbk.eu/
Natural Language Processing. HLT/EMNLP, pages 419?
426, Ann Arbor, Michigan.
Xiaobin Li, Stan Szpakowicz, and Stan Matwin. 1995. A
wordnet-based algorithm for word sense disambiguation.
In Proceedings of The 14th International Joint Conference
on Artificial Intelligence (IJCAI95).
Diana McCarthy, Rob Koeling, Julie Weeds, and John Car-
roll. 2007. Unsupervised acquisition of predominant
word senses. Computational Linguistics, 33(4).
R. Mihalcea, T. Chklovski, and Adam Killgariff. 2004. The
Senseval-3 English lexical sample task. In Proceedings of
the 3rd ACL workshop on the Evaluation of Systems for the
Semantic Analysis of Text (SENSEVAL), Barcelona, Spain.
Eric W. Noreen. 1989. Computer-Intensive Methods for Test-
ing Hypotheses. John Wiley & Sons.
Sameer Pradhan, Edward Loper, Dmitriy Dligach, and
Martha Palmer. 2007. Semeval-2007 task-17: English
lexical sample, srl and all words. In Proceedings of the
Fourth International Workshop on Semantic Evaluations
(SemEval-2007), pages 87?92, Prague, Czech Republic.
Paul Rayson and Roger Garside. 2000. Comparing corpora
using frequency profiling. In Proceedings of the workshop
on Comparing corpora, pages 1?6.
Hansen A. Schwartz and Fernando Gomez. 2008. Acquir-
ing knowledge from the web to be used as selectors for
noun sense disambiguation. In Proceedings of the Twelfth
Conference on Computational Natural Language Learn-
ing (CONLL08).
B. Snyder and M. Palmer. 2004. The English all-words task.
In Proceedings of the 3rd ACL workshop on the Evalua-
tion of Systems for the Semantic Analysis of Text (SENSE-
VAL), Barcelona, Spain.
M. Tesconi, F. Ronzano, S. Minutoli, C. Aliprandi, and
A. Marchetti. 2010. Kafnotator: a multilingual seman-
tic text annotation tool. In In Proceedings of the Second
International Conference on Global Interoperability for
Language Resources.
Piek Vossen, Eneko Agirre, Nicoletta Calzolari, Christiane
Fellbaum, Shu kai Hsieh, Chu-Ren Huang, Hitoshi Isa-
hara, Kyoko Kanzaki, Andrea Marchetti, Monica Mona-
chini, Federico Neri, Remo Raffaelli, German Rigau,
Maurizio Tescon, and Joop VanGent. 2008. Kyoto: a
system for mining, structuring and distributing knowl-
edge across languages and cultures. In Proceedings of the
Sixth International Language Resources and Evaluation
(LREC?08), Marrakech, Morocco, may. European Lan-
guage Resources Association (ELRA). http://www.lrec-
conf.org/proceedings/lrec2008/.
80
