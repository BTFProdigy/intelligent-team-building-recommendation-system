BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 100?101,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
A preliminary approach to recognize generic drug names by combining 
UMLS resources and USAN naming conventions 
 
Isabel Segura-Bedmar Paloma Mart?nez Doaa Samy 
Computer Sciences Department Computer Sciences Department Linguistic Department 
Carlos III University of Madrid Carlos III University of Madrid Cairo University 
Avd. Universidad, 30, Legan?s, 
28911, Madrid, Spain 
Avd. Universidad, 30, Legan?s, 
28911, Madrid, Spain 
Egypt 
isegura@inf.uc3m.es pmf@inf.uc3m.es dsamy@cu.edu.eg 
  
 
Abstract 
This paper presents a system1 for drug name 
identification and classification in biomedical 
texts.  
1 Introduction 
Numerous studies have tackled gene and protein 
names recognition (Collier et al 2002), (Tanabe 
and Wilbur, 2002). Nevertheless, drug names have 
not been widely addressed (Rindflesch et al, 
2000). 
Automating the process of new drugs recognition 
and classification is a challenging task. With the 
rapidly changing vocabulary, new drugs are 
introduced while old ones are made obsolete. 
Though the terminological resources are frequently 
updated, they can not follow the accelerated pace 
of the changing terminology. 
Drug receives three distinct names: the chemical 
name, the generic (or nonproprietary) name, and 
the brand (or trademark) name. The U.S. Adopted 
Name (USAN) Council establishes specific 
nomenclature rules for naming generic drugs. 
These rules rely on the use of affixes that classify 
drugs according to their chemical structure, 
indication or mechanism of action. For example, 
analgesics substances can receive affixes such as  
-adol-, -butazone, -fenine, -eridine and ?fentanil. 
In the present work, we focus, particulary, on the 
implementation of a set of 531 affixes approved by 
                                                           
1 This work has been partially supported by the projects: FIT-
350300-2007-75 (Semantic Interoperability in Electronic 
Health Care) and TIN2007-67407-C03-01 (BRAVO: 
Advanced Multimodal and Multilingual Question Answering). 
the USAN Council and published in 20072. The 
affixes allow a specific classification of drugs on 
pharmacological families, which ULMS Semantic 
NetWork is unable to provide. 
2 The System 
The system consists of four main modules: a basic 
text processing module, WordNet look-up module, 
UMLS look-up module and the USAN rules 
module, as shown in Figure 1.  
A corpus of 90 medical abstracts was compiled for 
the experiment. For the basic processing of the 
abstracts, GATE3 architecture is used. This text 
processing provides sentence segmentation, 
tokenization and POS tagging. Tokens which 
receive a noun or proper noun POS tag are 
extracted. 
The nouns found on WordNet are discarded and 
those which are not found in WordNet are looked 
up in the UMLS Metathesaurus. If a noun is found 
in UMLS, it is tagged with its corresponding 
semantic types as assigned by UMLS. A subset of 
these nouns is tagged as ?drug? if their semantic 
types are ?Pharmacological Substance? or 
?Antibiotic?. Finally, nouns which have not been 
found in UMLS are tagged as ?unknown?. 
The list of nouns tagged as ?drug? is passed to the 
rule module to detect their pharmacological 
families according to the affixes. In addition, the 
rule module processes the list of ?unknown? nouns 
which are not found in UMLS to check the 
presence of affixes, and thereby, of possible drugs. 
3 Preliminary results 
                                                           
2 http://www.ama-
assn.org/ama1/pub/upload/mm/365/usan_stem_list.pdf 
Accessed January 2008 
3 http://www.gate.ac.uk/ 
100
A manual evaluation by a domain4 expert was 
carried out. The list of nouns not found in 
WordNet contained 1885 initial candidates. This 
initial list is looked up in UMLS and 93.4% of 
them (1761) is linked with some concepts of 
UMLS. The UMLS module recognized 1400 
nouns as pharmacological substances or 
antibiotics. The rest of nouns, 361, are detected by 
UMLS but neither as pharmacological substance 
nor as antibiotics.  
The expert manually evaluated the set of nouns 
detected by UMLS as pharmacological substances 
or antibiotics (1400). Evaluation showed that only 
1100 were valid drugs.  
 
Figure 1 System Architecture 
The list of nouns (124) which have not been found 
in UMLS are processed by the rule module to 
detect new candidate drugs not included in UMLS. 
This module only detects 17 candidate drugs. The 
manual evaluation showed that 7 of them were 
valid drugs and the rest of nouns are biomedical 
concepts not included in UMLS. Some of these 
drugs are Mideplanin, Tomopenem, Elvitegravir, 
and so on. The rest of nouns neither detected by 
the UMLS module nor by the rules module, 106, 
were also validated by the expert in order to 
estimate the overall coverage of our approach. The 
evaluation of these nouns shows that only 7 of 
them are valid drugs, however, the rest of the 
nouns are named entities of the general domain 
(organization, person names or cities) or 
biomedical concepts. Introducing a module of 
generic NER should decrease the noise caused by 
such entities.  
                                                           
4 The authors are grateful to Maria Bedmar Segura, Manager 
of the Drug Information Center, Mostoles University Hospital, 
for her valuable assistance in the evaluation of the system. 
Finally, precision and recall of the overall system 
combining UMLS and rules were calculated. The 
system achieved 78% of precision and 99.3% of 
recall  
3.1 The classification in pharmacological 
families 
Once processed by the rule module, 73.8% of the 
candidate drugs recognised by UMLS were also 
classified in pharmacological families by the 
USAN naming rules. Expert?s evaluation of the 
rule-based classification showed that rules 
achieved 89% precision. Short affixes such as ?ol, 
?pin and -ox are responsible of the wrong 
classifications. Thus, additional clues are necessary 
to detect these drug families. 
4 Some Conclusions  
As a preliminary approach, it is a first step towards 
a useful Information Extraction System in the field 
of Pharmacology. Though evaluation reveals that 
rules alone are not feasible enough in detecting 
drugs, but they help to improve the coverage. In 
addition, rules provide a drug classification in 
pharmacological families. Such classification is an 
added value in the development of NLP 
applications within the pharmacological domain.  
For future work, the approach will be extended to 
address additional information about 
pharmacologic classes included in many 
biomedical terminologies integrated in the UMLS 
such as MeSH or SNOMED. 
Future work will also target a wider coverage and a 
bigger set of drug types through including more 
affixes, detecting complex entities (multi-words), 
detecting synonyms, resolving acronyms and 
ambiguities as well as using contextual information 
to disambiguate the correct semantic type of each 
term occurring in the texts.  
References  
Collier N, Takeuchi K. 2004. Comparison of characterlevel 
and part of speech features for name recognition in bio-
medical texts:423? 35. 
Rindflesch, T.C., Tanabe,L., Weinstein,J.N. and Hunter,L. 
2000. EDGAR: extraction of drugs, genes and relations 
from the biomedical literature. Pac. Symp. Biocomput. 5, 
517?528 
Tanabe, L. y Wilbur, W.J. 2002. Tagging gene and protein 
names in biomedical text. Bioinformatics 18, 1124?1132 
101
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 382?385,
Prague, June 2007. c?2007 Association for Computational Linguistics
UC3M: Classification of Semantic Relations between Nominals using 
Sequential Minimal Optimization  
Isabel Segura Bedmar 
Computer Science Department 
University Carlos III of Madrid 
isegura@inf.uc3m.es 
Doaa Samy 
Computer Science Department 
University Carlos III of Madrid 
dsamy@inf.uc3m.es 
Jose L. Martinez 
Computer Science Department 
University Carlos III of Madrid 
jlmartinez@inf.uc3m.es 
 
Abstract 
This paper presents a method for auto-
matic classification of semantic relations 
between nominals using Sequential 
Minimal Optimization. We participated 
in the four categories of SEMEVAL task 
4 (A: No Query, No Wordnet; B: Word-
Net, No Query; C: Query, No WordNet; 
D: WordNet and Query) and for all train-
ing datasets. Best scores were achieved 
in category B using a set of feature vec-
tors including lexical file numbers of 
nominals obtained from WordNet and a 
new feature WordNet Vector designed 
for the task1. 
1 Introduction 
The survey of the state-of-art reveals an increas-
ing interest in automatically discovering the un-
derlying semantics in natural language. In this 
interdisciplinary field, the growing interest is 
justified by the number of applications which 
can directly benefit from introducing semantic 
information. Question Answering, Information 
Retrieval and Text Summarization are examples 
of these applications (Turney and Littman, 2005; 
Girju et al, 2005).  
In the present work and for the purpose of the 
SEMEVAL task 4, our scope is limited to the 
semantic relationships between nominals. By 
this definition, we understand it is the process of 
discovering the underlying relations between 
two concepts expressed by two nominals.  
                                                 
1 This work has been partially supported by the Re-
gional Government of Madrid Ander the Research 
Network MAVIR (S-0505/TIC-0267) 
Within the framework of SEMEVAL, nomi-
nals can occur either on the phrase, clause or the 
sentence level. This fact constitutes the major 
challenge in this task since most of the previous 
research limited their approaches to certain types 
of nominals mainly the ?compound nomi-
nals?(Girju et al 2005). 
The paper is divided as follows; section 2 is a 
brief introduction to SMO used as the classifier 
for the task. Section 3 is dedicated to the de-
scription of the set of features applied in our ex-
periments. In section 4, we discuss the experi-
ment?s results compared to the baselines of the 
SEMEVAL task and the top scores. Finally, we 
summarize our approach, pointing out conclu-
sions and future directions of our work. 
2 Sequential Minimal Optimization 
We decided to use Support Vector Machine 
(SVM), as one of the most successful Machine 
Learning techniques, achieving the best per-
formances for many classification tasks. Algo-
rithm performance and time efficiency are key 
issues in our task, considering that our final goal 
is to apply this classification in a Question An-
swering System.  
Sequential Minimal Optimization (SMO) is a 
fast method to train SVM. SMO breaks the large 
quadratic programming (QP) optimization prob-
lem needed to be resolved in SVM into a series 
of smallest possible QP problems. These small 
QP problems are analytically solved, avoiding, 
in this way, a time-consuming numerical QP 
optimization as an inner loop. We used Weka 
(Witten and Frank, 2005) an implementation of 
the SMO (Platt, 1998). 
382
3 Features 
Prior to the classification of semantic rela-
tions, characteristics of each sentence are auto-
matically extracted using GATE (Cunningham 
et al, 2002). GATE is an infrastructure for de-
veloping and deploying software components for 
Language Engineering. We used the following 
GATE components: English Tokenizer, Part-Of-
Speech (POS) tagger and Morphological ana-
lyser. 
The set of features used for the classification 
of semantic relations includes information from 
different levels: word tokens, POS tags, verb 
lemmas, semantic information from WordNet, 
etc. Semantic features are only applied in cate-
gories B and D.  
On the lexical level, the set of word features 
include the two nominals, their heads in case one 
of the nominals in question or both are com-
pound nominals ( e.g. the relation between 
<e1>tumor shrinkage</e1> and <e2>radiation 
therapy </e2> is actually between the head of 
the first ?shrinkage? and ?radiation_therapy?). 
More features include: the two words before the 
first nominal, the two words after the second 
nominal, and the word list in-between (Wang et 
al., 2006).  
On the POS level, we opted for using a set of 
POS features since word features are often too 
sparse. This set includes POS tags of the two 
words occurring before the first nominal and the 
two words occurring after the second nominal 
together with the tag list of the words in-
between (Wang et al, 2006). POS tags of nomi-
nals are considered redundant information.  
Information regarding verbs and prepositions, 
occurring in-between the two nominals, is highly 
considered. In case of the verb, the system takes 
into account the verb token and the information 
concerning the voice and lemma. In the same 
way, the system keeps track of the prepositions 
occurring between both nominals. In addition, a 
feature, called numinter, indicating the number 
of words between nominals is considered. 
Other important feature is the path from the 
first nominal to the second nominal. This feature 
is built by the concatenation of the POS tags be-
tween both nominals.  
The feature related to the query provided for 
each sentence is only considered in the catego-
ries C and D according to the SEMEVAL re-
strictions. 
On the semantic level, we used features ob-
tained from WordNet.  In addition to the Word-
Net sense keys, provided for each nominal, we 
extracted its synset number and its lexical file 
number.  
Based on the work of Rosario, Hearst and 
Fillmore (2002), we suppose that these lexical 
file numbers can help to determine if the nomi-
nals satisfy the restrictions for each relation. For 
example, in the relation Theme-Tool, the theme 
should be an object, an event, a state of being, an 
agent, or a substance. Else, it is possible to af-
firm that the relation is false.  
For the Part-Whole relation and due to its 
relevance in this classification task, a feature 
indicating metonymy relation in WordNet was 
taken into account. 
Furthermore, we designed a new feature, 
called WordNet vector. For constructing this 
vector, we selected the synsets of the third level 
of depth in WordNet and we detected if each is 
ancestor or not of the nominal. It is a binary vec-
tor, i.e. if the synset is ancestor of the nominal it 
is assigned the value 1, else it is assigned the 
value 0. In this way, we worked with two vec-
tors, one for each nominal. Each vector has a 
dimension of 13 coordinates. Each coordinate 
represents one of the 13 nodes in the third level 
of depth in WordNet. Our initial hypothesis con-
siders that this representation for the nominals 
could perform well on unseen data.  
4 Experiment Results 
Cross validation is a way to test the ability of 
the model to classify unseen examples. We 
trained the system using 10-fold cross-
validation; the fold number recommended for 
small training datasets. For each relation and for 
each category (A, B, C, D) we selected the set of 
features that obtained the best results using the 
indicated cross validation.  
We submitted 16 sets of results as we partici-
pated in the four categories (A, B, C, D). We 
also used all the possible sizes of the training 
dataset (1: 1 to 35, 2:1 to 70, 3:1 to 106, 4:1 to 
140). 
383
 A: No Query, No 
WordNet 
B: No Query, 
WordNet 
C: No Query, No 
WordNet 
D: Query, Word-
Net 
 Prec Rec F Prec Rec F Prec Rec F Prec Rec F 
Cause-Effect 50.0 51.2 50.6 66.7   73.2 69.8 42.9   36.6   39.5   59.0   56.1   57.5   
Instrument-Agency 47.5 50.0 48.7 73.7   73.7   73.7   51.4   50.0   50.7   67.5   71.1   69.2   
Product-Producer 65.3 51.6 57.7 83.7   66.1   73.9   67.4   50.0   57.4   74.5   61.3   67.3   
Origin-Entity 50.0 27.8 35.7 63.0   47.2   54.0   54.5   33.3   41.4   63.3   52.8   57.6   
Theme-Tool 50.0 27.6 35.6 50.0   48.3   49.1   47.4   31.0   37.5   40.9   31.0   35.3   
Part-Whole 26.5 34,6 30.0 72.4   80.8   76.4   34.0   61.5   43.8   57.1   76.9   65.6   
Content-Container 48.4 39.5 43.5 57.6   50.0   53.5   48.6   44.7   46.6   63.6   55.3   59.2   
Avg for UC3M 48.2 40.3   43.1   66.7 62.8  64.3  49.4   43.9   45.3   60.9   57.8   58.8   
Avg for all systems 59.2 58.7 58.0 65.3 64.4 63.6 59.9 59.0 58.4 64.9 60.4 60.6 
Max Avg F   64.8   72.4   65.1   62.6 
Table  1 Scores for A4, B4, C4 and D4
For some learning algorithms such as decision 
trees and rule learning, appropriate selection of 
features is crucial. For the SVM model, this is 
not so important due to its learning mechanism, 
where irrelevant features are usually balanced 
between positive and negative examples for a 
given binary classification problem. However, in 
the experiments we observed that certain fea-
tures have strong influence on the results, and its 
inclusion or elimination from the vector, influ-
enced remarkably the outcomes. 
In this section, we will briefly discuss the ex-
periments in the four categories highlighting the 
most relevant observations. 
In category A, we expected to obtain better 
results, but the overall performance of the sys-
tem has decreased in the seven relations. This 
shows that our system has over-fitted the train-
ing set. The contrast between the F score values 
in the cross-validation and the final test results 
demonstrates this fact. For all the relations in the 
category A4, we obtained an average of 
F=43.1% [average score of all participating 
teams: F=58.0% and top average score: 
F=64.8%].  
In Product-Producer relation, only two fea-
tures were used: the two heads of the nominals. 
In training, we obtained an average F= 60% us-
ing cross-validation, while in the final test data, 
we achieved an average score F=57.7%. For the 
relation Theme-Tool, other set of features was 
employed: nominals, their heads, verb, preposi-
tion and the list of word between both nominals. 
Based on the results of the 10-fold cross valida-
tion, we expected to obtain an average of the 
F=70%. Nevertheless, the score obtained is F 
=30%.   
In category B, our system has achieved better 
scores. Our average score F is 64.3% and it is 
above the average of participating teams 
(F=63.6%) and the baseline.  
Best results in this category were achieved in 
the relations: Instrument-Agency (F=73.7%), 
Product-Producer (F=73.9%), Part-Whole 
(F=76.4%). However, for the relation Theme-
Tool the system obtained lower scores 
(F=49.1%). 
It is obvious that introducing WordNet infor-
mation has improved notably the results com-
pared with the results obtained in the category 
A.  
In categories C and D, only three groups have 
participated. In category C (as in category A), 
the system results have decreased obviously 
(F=45.3%) with respect to the expected scores in 
the 10-fold cross validation. Moreover, the score 
obtained is lower than the average score of all 
participants (F=58.4%) and the best score 
(F=65.1%). For example, in training the Instru-
ment-Agent relation, the system achieved an 
average F=78% using 10-fold cross-validation, 
while for the final score it only obtained 
F=50.7%.  
Results reveal that the main reason behind the 
low scores in A and C, is the absence of infor-
mation from WordNet. Hence, the vector design 
needs further consideration in case no semantic 
information is provided. 
In category D, both WordNet senses and 
query were used, we achieved an average score 
F=58.8%. The average score for all participants 
is F=60.6% and the best system achieved 
F=62.6%. However, the slight difference shows 
that our system worked relatively well in this 
category.  
384
Both run time and accuracy depend critically 
on the values given to two parameters: the upper 
bound on the coefficient?s values in the equation 
for the hyperplane (-C), and the degree of the 
polynomials in the non-linear mapping (-E) 
(Witten and Frank, 2005). Both are set to 1 by 
default. The best settings for a particular dataset 
can be found only by experimentation.  
We made numerous experiments to find the 
best value for the parameter C (C=1, C=10, 
C=100, C=1000, C=10000), but the results were 
not remarkably affected. Probably, this is due to 
the small size of the training set. 
5 Conclusions and Future Work  
In our first approach to automatic classifica-
tion of semantic relations between nominals and 
as expected from the training phase, our system 
achieved its best performance using WordNet 
information. In general, we obtained better 
scores in category 4 (size of training: 1 to 140), 
i.e., when all the training examples are used.  
On the other hand, overfitting the training 
data (most probably due to the small size of 
training dataset) is the main reason behind the 
low scores obtained by our system. 
These facts lead us to the conclusion that se-
mantic features from WordNet, in general, play 
a key role in the classification task. However, 
the relevance of WordNet-related features var-
ies. For example, lexical file numbers proved to 
be highly effective, while the use of the Word-
Net Vector did not improve significantly the re-
sults. Thus, we consider that a level 3 WordNet 
Vector is rather abstract to represent each nomi-
nal. Developing a WordNet Vector with a deeper 
level (> 3) could be more effective as the repre-
sentation of nouns is more descriptive. 
Query features, on the other hand, did not im-
prove the performance of the system. This is due 
to the fact that the same query could represent 
both positive and negative examples of the rela-
tion. However, to improve results in categories 
A and C, more features need to introduced, es-
pecially context and syntactic information such 
as chunks or dependency relations. 
To improve results across the whole dataset, 
wider use of semantic information is necessary. 
For example, the immediate hypernym for each 
synset obtained from WordNet could help in 
improving the system performance (Nastase et 
al., 2006). Besides, information regarding the 
entity features could help in the classification of 
some relations like Origin-Entity or Product-
Producer. Other semantic resources such as 
VerbNet, FrameNet, PropBank, etc. could also 
be used. 
Furthermore, we consider introducing a Word 
Sense Disambiguation module to obtain the cor-
responding synsets of the nominals. Also, in-
formation concerning the synsets of the list of 
the context words could be of great value for the 
classification task (Wang et al, 2006). 
References 
Hamish Cunningham, Diana Maynard and Kalina 
Bontcheva, Valentin Tablan, Cristian Ursu. 2002. The 
GATE User Guide. http://gate.ac.uk/ 
Roxana Girju, Dan Moldovan, Marta Tatu and Daniel An-
tohe. 2005. On the semantics of noun compunds. Com-
puter Speech and Language 19 pp. 479-496. 
Vivi Nastase, Jelber Sayyad-Shirbad, Marina Sokolova and 
Stan Szpakowicz. 2006. Learning noun-modifier seman-
tic relations with corpus-based and WordNet-based fea-
tures. In Proc. of the 21st National Conference on Artifi-
cial Intelligence (AAAI 2006). Boston, MA. 
John C. Platt. 1998. Sequential Minimal Optimization: A 
Fast Algorithm for Training Support Vector Machines, 
Microsoft Research Technical Report MSR-TR-98-14. 
Barbara Rosario, Marti A. Hearst, and Charles Fillmore. 
2002. ?The descent of hierarchy, and selection in rela-
tions semantics?. In Proceedings of the 40 th Annual 
Meeting of the Association for Computacional Linguis-
tics (ACL?02), Philadelphia, PA, pages 417-424. 
Ian H. Witten, Eibe Frank. 2005. Data Mining: Practical 
machine learning tools and techniques. Morgan Kauf-
mann.  
Peter D. Turney and Michael L. Littman. 2005. Corpus-
based learning of analogies and semantic rela-tions. Ma-
chine Learning, in press. 
Ting Wang, Yaoyong Li, Kalina Bontcheva, Hamish Cun-
ningham and Ji Wang. 2006. Automatic Extraction of 
Hierarchical Relations from Text. In Proceedings of the 
Third European Semantic Web Conference (ESWC 
2006), Lecture Notes in Computer Science 4011, 
Springer, 2006. 
385
