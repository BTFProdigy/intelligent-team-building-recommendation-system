Building a Bilingual WordNet-Like Lexicon: 
the New Approach and Algorithms 
Yang Liu, Shiwen Yu, Jiangsheng Yu 
Institute of Computaitional Linguistics, Peking Unviersity 
Beijing, 100871, China 
{liuyang, yusw, yujs} @ pku.edu.cn 
 
 
Abstract 
A bilingual concept MRD is of significance for 
IE, MT, WSD and the like. However, it is 
reasonably difficult to build such a lexicon for 
there exist two ontologies, also, the evolution of 
such a lexicon is quite challenging. In this 
paper, we would like to put forth the new 
approach to building a bilingual WordNet-like 
lexicon and to dwell on some of the pivotal 
algorithms. 
A characteristic of this new approach is to 
emphasize the inheritance and transformation 
of the existent monolingual lexicon.  On the one 
hand, we have extracted all the common 
knowledge in WordNet as the semantic basis 
for further use. On the other hand, we have 
developed a visualized developing tool for the 
lexicographers to interactively operate on to 
express the bilingual semantics. The bilingual 
lexicon has thus gradually come into being in 
this natural process. 
ICL now has benefited a lot by employing 
this new approach to build CCD (Chinese 
Concept Dictionary), a bilingual WordNet-like 
lexicon, in Peking University. 
1 Introduction 
As the processing of content information has 
nowadays become the center of NLP, a 
bilingual concept MRD is of increasingly great 
significance for IE, MT, WSD and the like. And 
it is for sure that the computational linguists 
would find such a lexicon indispensable and 
useful as semantic information when facing 
ambiguities in languages in their applications. 
At the same time, Princeton University?s 
WordNet, after so many years? development, 
has exerted a profound influence on semantic 
lexicons [Vossen, 1998]. 
      When building a Chinese-English bilingual 
concept MRD, we must take the issue of 
compatibility with WordNet into account. In 
other words, for each English concept in 
WordNet, there should exist a corresponding 
Chinese concept in the bilingual lexicon and 
vice versa. Such a bilingual lexicon can offer 
better reusability and openness. 
The Institute of Computational Linguistics 
(ICL), Peking University, with this point of 
view, has launched the Project CCD (Chinese 
Concept Dictionary). 
The expectant CCD might be described as 
follows [Yu et al 2001]: it should carry the 
main relations already defined in WordNet with 
more or less updates to reflect the reality of 
contemporary Chinese, and it should be a 
bilingual concept lexicon with the parallel 
Chinese-English concepts to be simultaneously 
included. 
      Such a bilingual WordNet-like lexicon of 
Chinese-English concepts can largely meet our 
need of applications. 
However, it is by no means easy to build 
such a lexicon. It is quite obvious that there 
synchronously exist two ontologies in the same 
lexicon. One is in the English culture and the 
other is in the Chinese culture. As there might 
be different concepts and relations in each 
language, the mapping of the relevant concepts 
in different languages is inevitable. Also, the 
evolution of such a lexicon with passing of 
time, an issue linked closely to the mapping 
issue, is quite challenging. 
In conclusion, it?s a quite demanding job to 
build such a lexicon, especially for the design of 
the approach and the realization of the 
developing tool. Any fruitful solution should 
give enough consideration to the complexity of 
these issues. 
2 The New Approach to Building a Bilingual 
WordNet-Like Lexicon 
The distinct principles of organization of 
WordNet can be described below: concepts, 
viz. synsets, act as the basic units of lexical 
semantics, and the hyponymy of the concepts 
acts as the basic relation among others. Upon 
this tree structure of hyponymy, there also exist 
some other semantic relations like holonymy, 
antonymy, attribute, entailment, cause, etc., 
which further interweave all the concepts in the 
lexicon into a huge semantic network, say 
99,643 synset nodes all told in WordNet 1.6. 
      What really counts and takes a lot of trouble 
in building WordNet itself is how to set up all 
these synsets and relations properly, and, how 
to maintain the semantic consistencies in case 
of frequent occurrences of modifications during 
the revision [Beckwith et al 1993]. As the 
desirable developing tool based directly on a 
large-scale network has not yet appeared, due to 
the connatural complexity of net structure, this 
problem is all the way a Gordian knot for the 
lexicographers. 
      To build a Chinese WordNet in the same 
route just as Princeton had taken and then to 
construct the mapping between these two 
WordNets may be not a satisfying idea. 
So, it is crucial that we had better find an 
approach to reusing the English common 
knowledge already described in WordNet as the 
semantic basis for Chinese when building the 
bilingual lexicon. And this kind of reusing 
should contain some capabilities of adjustments 
to the bilingual concepts besides word-for-word 
translations. If we can manage it, not only the 
building of the monolingual Chinese lexicon 
benefits but also the mapping between 
Chinese-English [Liu et al 2002]. Actually, the 
practice of mapping has now become a direct 
and dynamic process and the evolution of the 
bilingual lexicon is no longer a problem. A 
comparatively high efficiency may be achieved. 
Such are the essential ideas of the new 
solution.  A characteristic of this approach is to 
emphasize the inheritance and transformation 
of the already existent monolingual lexicon.  
Accordingly, it deals with 2 processes. The 
first process simply gets the semantic basis for 
further use and the lexicographers? work always 
focuses on the second. In fact, the bilingual 
lexicon has just gradually come into being in 
this more natural process. 
2.1 The Inheritance Process of WordNet 
This process is intended to extract the common 
hyponymy information in WordNet as the 
semantic basis for future use. 
      However, to extract the full hyponyms for a 
certain concept is by no means easy. As we 
have examined, the number of hyponyms for a 
synset ranges from 0 to 499 with a maximal 
hyponymy depth of 15 levels in WordNet. This 
shows the structure of the potential hyponymy 
tree is quite unbalanced. Due to this high 
complexity, the ordinary searching algorithm 
can hardly do. If one inputs the word entity as 
entry in WordNet 1.6 and tries to search its full 
hyponyms, he will get nothing but a note of 
failure. Sure enough, if the entry is not entity 
but another word, say entrance, the searching 
will probably do. The cases actually depend on 
the location of the entry word in the potential 
hyponymy tree in WordNet. The higher the 
level of the entry word, the less possibility of 
success the searching will have. 
      By now, we have got a refined searching 
algorithm for getting the full hyponymy 
information in WordNet [Liu et al 2002]. 
By and large, it involves a series of Two 
Way Scanning action and of Gathering/Sieving 
and Encoding action, with each round of the 
series intending to get information of nodes on 
one same level in the hyponymy tree. 
      By this special algorithm, the complexity of 
searching is greatly reduced. We can even get 
all the 45,148 hyponyms for the topmost entry 
word entity, in 100 or so seconds, on an 
ordinary PC. People who are interested in it can 
find more details about the algorithm in [Liu et 
al, 2002]. 
2.2 The Transformation Process of WordNet 
This process is for the lexicographers to 
interactively operate on the hyponymy tree to 
express the bilingual semantics. The bilingual 
lexicon will gradually come into being in this 
process. 
      For this task, we have designed and realized 
a visualized and data-sensitive tree control with 
8 well-defined operations on it, some of the 
pivotal algorithms for which will be discussed 
later. 
      After extracting the hyponymy information 
for each initial semantic unit in WordNet 
respectively, we then organize the information 
into a hyponymy tree by using the above tree 
control. Every tree node, viz. synset, still carries 
all other semantic relations already described in 
WordNet. The lexicographers can now operate 
on the tree interactively. 
The actual practices of the lexicographers 
are as follows: 
      (i) For each tree node in English, if there 
exists a corresponding Chinese concept, the 
lexicographers simply translate the English 
concept into Chinese. 
      (ii) If there does not, cases may be that the 
English concept is either too general or too 
specific for Chinese. 
      (ii1) For the former case, the lexicographers 
can create new hyponyms in Chinese for the 
English concept and link all these new 
hyponyms in Chinese with the English concept. 
(ii2) For the latter case, the lexicographers 
just delete the English concept in a special way, 
which means the English concept has no 
equivalent in Chinese and only links the 
English concept with its hypernym. 
In fact, all the above-mentioned semantic 
manipulations concerning hyponymy relation  
have already been encoded into the 8 visualized 
operations on the hyponymy tree. In addition, in 
the 8 operations, some other semantic relations 
already described in the synsets in WordNet are 
all properly dealt with through systematic and 
reasonable calculations. 
      We can see these adjustments clearly in the 
description of the algorithms. 
      Now, it is of much significance that the 
lexicographers need simply operate on the 
hyponymy tree to express their semantic 
intention and no longer care for lots of details 
about the background database, for the 
foreground operations have already fulfilled all 
the automatic modifications of the database. 
      In this way, the problems of mapping 
between the bilingual concepts and evolution of 
the bilingual lexicon are dynamically resolved. 
Our developing tool for building the 
bilingual WordNet-like lexicon has come out as 
below. 
 
 
 
 
 
 
 
 
 
 
 
The interface view shows the hyponymy 
tree for the entry food, which is one of the 25 
initial semantic units of noun in WordNet with 
the category value of 13. For the currently 
chosen node, the lexicographers can further 
adopt a proper operation on it when needed. 
This new kind of Visualized Auxiliary 
Construction of Lexicon is characteristic of the 
inheritance and transformation of the existent 
monolingual lexicon.  We call it Vacol model 
for short. 
      As we see, the new approach, in fact, is 
independent of any specific languages and 
actually offers a general solution for building a 
bilingual WordNet-like lexicon. 
3 Tree Operations and their Algorithms 
As the lexicographers always work on the tool, 
the visualized, data-sensitive tree control with 
operations on it is the key to the new approach. 
By now, we?ve schemed a set of algorithms 
based on the Treeview control in the Microsoft 
Visual Studio 6.0 and eventually implemented a 
data-sensitive tree control with operations on it. 
3.1 Tree Operations 
The 8 operations that we have semantically well 
defined are listed as follows. When choosing a 
synset node in the hyponymy tree, these are the 
operations from which the lexicographers can 
further adopt one. 
 
      [1] To add a synset as brother node; 
      [2] To add a synset as child node; 
      [3] To delete the synset node (not including 
its descendants if exist); 
[4] To delete the synset node (including all 
its descendants if exist); 
      [5] To cut the subtree; 
      [6] To copy the subtree; 
      [7] To paste the subtree as brother node; 
[8] To paste the subtree as child node. 
 
      These operations are all to edit the tree, with 
respectively No. 1, 2 for addition, No. 3, 4 for 
deletion, and No. 5, 6, 7, 8 for batch movement. 
      In fact, all these operations have been 
carefully decided on to make them concise 
enough, capable enough and semantically 
meaningful enough. 
      It is easy to prove that any facultative tree 
form can be attained by iterative practices of 
these 8 operations. 
3.2 Algorithms for the Tree Operations 
The data structure of a hyponymy tree with n 
nodes can be illustrated by the following table: 
 
Pos1 Ptr11 Ptr12 ? Ptr1m BasicInfo1 
Pos2 Ptr21 Ptr22 ? Ptr2m BasicInfo2 
? ? ? ? ? ? 
Posn Ptrn1 Ptrn2 ? Ptrnm BasicInfon 
 
      There are 3 parts of information in each 
record: the structural information {Posi}, the 
relation information {Ptri1 (viz. hyponymy), 
Ptri2, ? , Ptrim} and all other pieces of basic 
information {BasicInfoi} which are relevant 
only to the concept proper. 
      Among these 3 parts of information, {Posi} 
is used for the tree structure whereas both {Ptri1, 
Ptri2, ? , Ptrim} and {BasicInfoi} for lexical 
semantics. It should be noticed that Posi only 
stands for a special encoding for the tree in the 
foreground and is somewhat different from 
Ptri1, a relational pointer of hyponymy, which 
represents its specific semantics in the 
background database. And it is the relations in 
{Ptri2, ? , Ptrim} that have highly contributed to 
the dense net structure of WordNet. 
      After these analyses, we find that each 
operation should just properly deal with these 3 
parts of information. First, it is crucial that two 
sorts of consistencies should be maintained. 
One is that of the structural information {Posi} 
of the tree and the other is that of the relation 
information {Ptri1, Ptri2, ? , Ptrim} of the 
lexicon. Following that, the cases of the basic 
information {BasicInfoi} are comparatively 
simple for only English-Chinese translations 
are involved. 
      Before we can go on to dwell on the 
algorithms, we still need a little while to touch 
on the structural information {Posi}. When we 
say a position Posi, we actually mean the 
location of a certain node in the tree and it 
serves to organize the tree. For example, a Posi 
by the value ?005001002? is to represent such a 
location of a node in a tree: at the 1st level, its 
ancestor being the 5th; at the 2nd level, its 
ancestor being the 1st; and at the 3rd level, its 
ancestor viz. itself now being the 2nd. In fact, 
such an encoding onto a linear string does fully 
express the structural information in a tree and 
makes all the tree operations algorithms 
feasible by direct and systematic calculations of 
the new position. 
      If we don?t want to badger with much of the 
details, the algorithms for tree operations can be 
described in a general way. Although for each 
line of the pseudocode, there indeed are lots of 
jobs to do for the programmer. 
The algorithms described below are suitable 
for the non-batch-movement operations, viz. 
operations [1, 2, 3, 4]. And the batch-movement 
operations, viz. operations [5, 6, 7, 8], can be 
regarded as their iterative practices. 
 
The lexicographers trigger an action on nodei; 
IF the action is in operations [1, 2, 3, 4] 
    CASE the action 
       Operations [1]: 
           Add a node with its Pos = NewBrother (Posi); 
       Operations [2]: 
           Add a node with its Pos = NewChild (Posi); 
       Operations [3]: 
           Delete the node with Pos = Posi; 
       Operations [4]: 
    Delete all the nodes with their Pos satisfying 
conditions of being descendants of nodei; 
    END CASE 
    Recalculate Pos of the rest nodes in the table 
according to the operation and current Posi; 
    Replace all relevant Ptrj1, Ptrj2 , ? , Ptrjm with new 
ones according to the operation and current nodei; 
    Refresh the tree; 
ELSE IF 
The lexicographers translate current BasicInfoi from 
English to Chinese; 
END IF 
 
      The algorithms have some nice features. 
      Since the structural information {Pos}, 
defined as the primary key of the table, is kept 
in order, the maintenance of tree structure can 
always be completed in a single pass. 
      The maintenance of consistencies of the 
relation information {Ptrj1, Ptrj2, ? , Ptrjm} in 
the lexicon is also limited to a local section of 
the table. 
4 Conclusions 
ICL, Peking University has launched the 
Project CCD since Sept., 2000. Due to the nice 
features of the new approach, we do have 
benefited a lot by employing it to build CCD. 
By now, we have fulfilled more than 32,000 
Chinese-English concept pairs in noun. 
      In the near future, ICL wants to come to a 
total amount of 100,000 or so bilingual 
concepts, which might largely meet our need of 
applications. 
What is more, as the byproducts of the new 
approach and experiences, we have even found 
some errors and faults of semantic expressing 
with WordNet 1.6. 
For example, in the lexicon there are many 
occurrences of a node with multiple-father in 
the identical category (772 times in noun, e.g. 
{radish}) or a node with single-father in the 
other category (2,172 times in noun, e.g. 
{prayer_wheel}). 
In verb, there even exists a node with father 
being oneself (e.g. {reserve, hold, book}). 
      These phenomena are quite abnormal and 
puzzling according to the specification of 
WordNet.  Something may have gone wrong 
with the classification or implementation. 
      There are also many undisciplined locations 
of relational pointers (e.g. ?@? and ?~?, 
respectively 7 and 451 times in noun) in DAT 
files and some other problems. 
Acknowledgements 
This work is a component of researches on 
Chinese Information Extraction funded by 
National Foundation of Natural Science No. 
69973005 and Project 985 in Peking Univ. 
We are especially grateful to Prof. WANG 
Fengxin and Prof. LU Chuan, our linguistics 
advisors, for their unforgettable discussion and 
support. Many thanks go to the fellows who 
have participated in and collaborated on the 
work, among whom we would like to mention 
Mr. ZHANG Huarui, Ms. SONG Chunyan, Dr. 
LI Zuowen, Ms. ZAN Hongying and others. 
Thanks also to the participants to the 1st Global 
WordNet Conference 2002, Mysore, India, for 
their valuable advice and comment. 
References 
Beckwith, R., Miller, G. A. and Tengi, R. (1993) 
Design and Implementation of the WordNet Lexical 
Database and Searching Software. Description of 
WordNet. 
 
Carpuat, M. and Ngai, G. et al (2002) Creating a 
Bilingual Ontology: A Corpus-Based Approach for 
Aligning WordNet and HowNet. GWC2002, India, 
pp 284-292. 
 
Chang, J. S. and You, G. N. et al (2002) Building a 
Bilingual Wordnet and Semantic Concordance from 
Corpus and MRD. WCLS2002, Taipei, China, pp 
209-224. 
 
Cook, G. and Barbara, S. (1995) Principles & 
Practice in Applied Linguistics. Oxford: Oxford 
University Press. 
 
Fellbaum, C. (1993) English Verbs as a Semantic 
Net. Description of WordNet. 
 
Fellbaum, C. (1999) WordNet: an Electronic Lexical 
Database. Cambridge, Mass.: MIT Press. 
 
Kamps, J. (2002) Visualizing WordNet Structure. 
GWC2002, India, pp 182-186. 
 
Keil, F. C. (1979) Smantic and Conceptual 
Development: an Ontological Perspective. 
Cambridge, Mass.: Harvard University Press. 
 
Liu, Y., Yu, J. S., Yu, S. W. (2002)  A Tree-Structure 
Solution for the Development of ChineseNet. 
GWC2002, India, pp 51-56. 
 
Miller, G. A. (1993) Noun in WordNet: a Lexical 
Inheritance System. Description of WordNet. 
 
Miller, G. A. et al (1993) Introduction to WordNet: 
An On-line Lexical Database. Description of 
WordNet. 
 
Pavelek, P., Pala, K. (2002) VisDic ? a New Tool for 
WordNet Editing. GWC2002, India, pp 192-195. 
 
Touretzky, D. S. (1986) The Mathematics of 
Inheritance Systems. Los Altos, Calif.: Morgan 
Kaufmann. 
 
Vossen, P. (1998) EuroWordNet: a Multilingual 
Database with Lexical Semantic Networks. 
Dordrecht: Kluwer. 
 
Wong, S. H. S. and Pala, K. (2002) Chinese 
Characters and Top Ontology in EuroWordNet. 
GWC2002, India, pp 122-133. 
 
Yu, J. S. (2002) Evolution of WordNet-Like Lexicon. 
GWC2002, India, pp 134-142. 
 
Yu, J. S. and Yu, S. W. et al (2001) Introduction to 
CCD. ICCC2001, Singapore, pp 361-366. 
WSD and Closed Semantic Constraint
Jiangsheng Yu?
Institute of Computational Linguistics
Peking University, Beijing, China, 100871
Abstract The application-driven construction
of lexicon has been emphasized as a methodology
of Computational Lexicology recently. We focus on
the closed semantic constraint of the argument(s)
of any verb concept by the noun concepts in a
WordNet-like lexicon, which theoretically is related
to Word Sense Disambiguation (WSD) at differ-
ent levels. From the viewpoint of Dynamic Lexi-
con, WSD provides a way of automatic construc-
tion for the closed semantic constraints and also
benefits from the semantic descriptions.
Keywords dynamic lexicon, evolution, WSD,
WordNet-like lexicon, closed semantic constraint
1 Introduction
As the underlying resource of semantic analysis,
the most important descriptions in a semantic lexi-
con are the relationships between verbs and nouns,
which usually comes down to the closed semantic
constraint of each argument of any verb. Once the
structure of the semantic lexicon is determined,
the closed semantic constraint becomes a well-
defined problem.
Example 1.1 The verb da? has many mean-
ings in Chinese, which differ in da? ha?izi (pun-
ish the child), da? ma?oyi? (weaver the sweater),
da? jia`ngyo?u (buy the soy), etc. Actually, the se-
mantics of da? is distinguished by the semantics of
its arguments.
Different from the traditional lexicon, we advo-
cate the conception of dynamic lexicon ([15]) and
its evolution oriented to some particular applica-
tion, which will be mentioned in Section 2. The
WordNet-like lexicon is treated as a dynamic one,
which means that the structures representing se-
mantic knowledge could be changed according to
some empirical standards. In the next section,
we?ll define the WSD based on the WordNet-like
lexicon, and then discuss the training of concept
TagSet and the statistical model of WSD. By the
statistical WSD, in Section 4, we introduce an ap-
proach to the automatic construction of the closed
?This paper is supported by National Foundation of Nat-
ural Science (Research on Chinese Information Extraction),
No. 69483003 and Project 985 in Peking University.
semantic constraints in a WordNet-like lexicon.
The last section is the conclusion.
2 Dynamic Lexicon and Its
Structural Evolution
Definition 2.1 A dynamic lexicon is a triple
Lex = ?S,R, T ? in which
1. S is a well-structured set with a type1 t,
2. R is the set of deductive rules on S, and
3. T is the set of all structural transformations
of S, keeping the type t.
Definition 2.2 Lexicon ?S?, R, T ? is called the
evolution result of the lexicon ?S,R, T ? if ?t ? T ?
such that S
t
? S? (or briefly S  S?). The pro-
cess of a dynamic lexicon to its evolution result is
called an evolution. Obviously, T is a group with
the operation of composition.
Definition 2.3 ?S,R, T ? is called simple struc-
tured if T is a commutative group, otherwise com-
plex structured.
The more complex is the structure of S, the more
difficult are the applications of R and T . Since
some part of semantic knowledge is represented
by the structure, the complexity balance between
the structure and R (or T ) is one of the serious
problems in Computational Lexicology.
Definition 2.4 Let ?(S) denote the least number
of operations constructing S, and ?(S  S?) the
least number of operations from S to S?. It?s easy
to verify that
Theorem 2.1 ?(?) is a distance, i.e., it satisfies
that ?S, S?, S??,
1. ?(S  S?) ? 0
2. ?(S  S?) = 0 ? S = S?
3. ?(S  S?) = ?(S?  S)
4. ?(S  S??) ? ?(S  S?) + ?(S?  S??)
1For instance, labeled tree or complete lattice.
Corollary 2.1 ?(S?) ? ?(S) + ?(S  S?)
Definition 2.5 The degree of structural destruc-
tion from S to S?, is defined by
?(S  S?) = 1?
?(S?)
?(S) + ?(S  S?)
(1)
Property 2.1 0 ? ?(S  S?) ? 1
Definition 2.6 Let S  S1  ? ? ?  Sn  ? ? ?
be a sequence of evolution, the sequence is called
convergent if there exists a constant A s.t. 0 ?
A ? 1 and lim
n??
?(S  Sn) = A.
It?s easy to see that a local evolution of the lex-
icon may not be an optimization even for a spe-
cific application. The index ? indicates the con-
vergence of lexical structure, guaranteeing a stable
machine learning of the dynamic lexicon. Actually,
the structure of the so-called common knowledge
is nothing but a statistical distribution, which is
effected by the cultures and personal experiences.
Oriented to a particular application, such as IE,
IR, MT, etc, the appropriate semantic descriptions
in a WordNet-like lexicon seem necessary.
Example 2.1 C = {earthquake, quake, tem-
blor, seism} is not only a kind of C ? =
{geological phenomenon}, but also a kind of C ?? =
{natural disaster}.
3 WSD based on WordNet-
like Lexicon
What does it mean that a machine could under-
stand a given sentence S or a text T? As we
know, Turing Test of NLU includes at least the
meaning of any word w in S or T . Thus, the pre-
requisite WSD is to tag the semantic information
of w automatically. WordNet2 in Princeton Uni-
versity, in despite of its disputed quality, provides
an approach to the formalization of concepts in
natural language, in which a concept is defined by
a synonym set (SynSet). A more important work
in WordNet is the construction of a well-structured
concept network based on the hypernymy relation
(the main framework) and other accessorial rela-
tions, such as, the opposite relation, the holonymy
relation, entailment, cause, etc.
Definition 3.1 A WordNet-like lexicon is a dy-
namic lexicon with the type of WordNet:
1. restricted to each category, S is a labeled tree
from the viewpoint of the hypernymy relation
for both noun concepts and verb concepts,
2The specification of WordNet could be found in [3], [4],
[5], [9], [10], [11], etc.
2. some accessorial relations between the noun
(or verb) concepts, and
3. closed semantic constraint of the argument(s)
of each verb concept from the noun concepts.
The WordNet-like lexicon is complex structured, it
may not have the same ontology of WordNet, nei-
ther the semantic knowledge representations. But
the description method seems a general format for
all languages from the fact of EuroWordNet (see
[12]), Chinese Concept Dictionary (CCD, see [7],
[13], [14] and [15]), Korean WordNet, Tamil Word-
Net, etc.
Definition 3.2 Let ? be the set of all words,
then ?, the set of all concepts (or SynSets) in a
WordNet-like lexicon, is a subset of 2?. The set
of all SynSets containing w is denoted by ?(w), in
which each element is called a sense of w.
Definition 3.3 Given a well-defined sentence
S = w1w2 ? ? ?wn, WSD is the computable pro-
cessing which tags wi a unique sense si =
{wi, wi1 , ? ? ? , wik} such that each derived combi-
natorial path is a well-defined sentence with the
semantics of S. The Principle of Substitution pro-
vides a corpus-based empirical approach to test
a SynSet well-defined or not. The SynSet is the
smallest unit in a WordNet-like lexicon, which is
the underlying of the structural descriptions be-
tween the concepts.
The training of concept TagSet and the statistical
model of WSD are interactional, which is the main
idea of our approach to WSD based on a WordNet-
like lexicon.
3.1 The Training of TagSet
The traditional semantic tags are from some on-
tology, the apriority of which is often criticized
by computational linguists. For us, the empiri-
cal method must impenetrate each step of WSD
because of the complexity of language knowledge.
The statistical approach to WSD needs a well
concept-tagged corpus as the training set for the
concept TagSet and the statistical data in the Hid-
den Markov Model (HMM). To avoid the sparse
data problem, only a few real subsets of ? could
act as the TagSet in the statistical model (see [15]
and [16]). The first step leads to a set of structured
TagSets {T1,T2, ? ? ? ,Tm}, then the second step is
to choose the most efficient one which makes the
best accuracy of the statistical concept tagging.
Different from those unframed tags, the deductive
rule along the hypernymy trees works out the sense
of w by the following property:
Property 3.1 Suppose that the TagSet is T =
{C1, C2, ? ? ? , Ck}, and the word w in a given sen-
tence is tagged by Ci, then the sense of w here
is the SynSet C which satisfies that Ci  C and
w ? C, where  is the partial ordering of the nodes
in the hypernymy tree.
3.2 Statistical Model of WSD
In some sense, WSD is the kernel problem of both
NLU and NLP ([1], [6], [8]). POS and concept tag
are two random variables in the HMM of WSD.
Sometimes POS of w determines its sense, some-
times not. But in most cases, a sense of w implies
a unique POS. The distribution of w?s senses with
the POS, P , is important in the (POS, concept)-
tagging. A Hidden Markov Model with two pa-
rameters will be adopted as the main statistical
model for WSD, and the Statistical Decision The-
ory and Bayesian Analysis, which are good at an-
alyzing the small samples, conducted as a com-
parison. The training corpus, T , is done by hand,
where the cursor sensitive display of the senses pro-
vides the help information.
Definition 3.4 Consider the well-defined sen-
tence S = w1w2 ? ? ?wn. By the lexicon, let
S = w1/P (i)1
w2/P (i)2
? ? ?wn/P (i)n be a possible POS
tagged result, where i ? I. Define
f(i) = argmax
j?J
P(C(i,j)1 ? ? ?C
(i,j)
n |P
(i)
1 ? ? ?P
(i)
n )
= argmax
j?J
P(C(i,j)1 ? ? ?C
(i,j)
n , P
(i)
1 ? ? ?P
(i)
n )
= argmax
j?J
P(C(i,j)1 ? ? ?C
(i,j)
n )
(2)
The HMM of concept can simulate the HMM with
two parameters of (POS, concept). f(i) in (2) is
predigested to
f(i) = argmax
j?J
P(C(i,j)1 )
n?
k=2
P(C(i,j)k |C
(i,j)
k?1 ) (3)
Property 3.2 There exists a unique map g from
the set of {P (i)1 P
(i)
2 ? ? ?P
(i)
n |i ? I} to the set of
{C(i,j)1 C
(i,j)
2 ? ? ?C
(i,j)
n |(i, j) ? I?J}, which satisfies
that
g(P (i)1 ? ? ?P
(i)
n ) = C
(i,f(i))
1 ? ? ?C
(i,f(i))
n (4)
where ?i, k,?C ? ?(wk) s.t. C
(i,f(i))
k  C. If
there is C ? 6= C satisfying C ? ? ?(wk) and
C(i,f(i))k  C
?, then the one with more distribu-
tion is the selected sense of wk.
Property 3.3 Let s = w1w2 ? ? ?wn be any pos-
sible segmented sequence of S, corresponding
a set of probabilities of POS sequences As =
{P(P (i)1 P
(i)
2 ? ? ?P
(i)
n )|i ? I}. Each P
(i)
1 P
(i)
2 ? ? ?P
(i)
n
corresponds a set of probabilities of concept se-
quences B(i)s = {P(C
(i,j)
1 C
(i,j)
2 ? ? ?C
(i,j)
n )|j ? J},
where C(i,j)k has the POS of P
(i)
k , then
argmax
s
(a ?max
s
(As) + b ?max
i,s
(B(i)s )) (5)
is the choice of segmentation, where a > 0, b > 0
and a+ b = 1. More precisely, (5) is rewritten by
argmax
s
{max
i
{a ? P(P (i)s ) + b ? P(g(P
(i)
s ))}} (6)
where P (i)s = P
(i)
1 P
(i)
2 ? ? ?P
(i)
n .
4 WSD driven Closed Seman-
tic Constraint
From the corpus and the statistical WSD, we can
make an induction of the arguments along the hy-
pernymy tree, which leads to the closed semantic
constraints automatically. At the same time, the
closed semantic constraints also provide a possible
approach to the empirical optimization of ?N and
?V . While the total optimization of a WordNet-
like lexicon is still an open problem.
4.1 Similarity between Concepts
Definition 4.1 A labeled tree is a 5-tuple T =
?N,Q,D, P, L? satisfying that:
1. N is a finite set of nodes
2. Q is a finite set of labels
3. D is a partial ordering on N , called domi-
nance relation
4. P is a strict partial ordering on N , called
precedence relation
5. (?x ? N)(?y ? N)[(x, y) ? D]
6. (?x, y ? N)[[(x, y) ? P ? (y, x) ? P ] ?
[(x, y) /? D ? (y, x) /? D]]
7. (?x, y, z, w ? N)[[(w, x) ? P ? (w, y) ? D ?
(x, z) ? D] ? (y, z) ? P ]
8. L : N ? Q is a label map
Definition 4.2 A hypernymy tree is a labeled
tree, in which the label map is one-to-one. Al-
ways, we presume that the hypernymy tree is not
degenerative.
In a hypernymy tree of a WordNet-like lexi-
con, a node is a code and a label is a SynSet.
Since the label map is injective, without gen-
erality, a SynSet is usually denoted by a node.
We assume that the precedence relation between
the brother nodes always implies an ordering of
time, usage, frequency, mood, etc. For instance,
{spring, springtime} ? {summer, summertime} ?
{fall, autumn} ? {winter,wintertime} as the hy-
ponyms of {season, time of year}.
Definition 4.3 Let f, b and B denote father, the
nearest younger-brother and the nearest elder-
brother respectively, satisfying that f = fb, f =
fB and Bb = bB = 1.
Definition 4.4 ?x, y ? N , let z ? N be their
nearest ancestor satisfying z = fm(x) and z =
fn(y), D(x, y)
def
= m + n. k ? N is called the
offset of x from its eldest brother if ?Bk(x) and
@Bk+1(x). Let the offset of y is l, the similarity
between x and y is:
? If mn = 1, S(x, y)
def
= ?0, |k ? l|?
? If mn 6= 1, S(x, y)
def
= ?m+ n, 0?
Definition 4.5 Suppose that S(x1, y1) = ?a1, b1?
and S(x2, y2) = ?a2, b2?, the comparison of simi-
larities is defined as follows:
1. a1 = a2
? S(x1, y1)  S(x2, y2) ? b1 ? b2
2. a1 6= a2
? If a1 < a2, then S(x1, y1) ? S(x2, y2)
? If a1 > a2, then S(x2, y2) ? S(x1, y1)
Theorem 4.1 ?{S(x, y)|x, y ? N},? is a totally
ordered set.
The elementary structural transformations in a
WordNet-like lexicon include:
1. insert a non-root brother-node;
2. collapse a non-root node to its father-node;
3. root is adding a new root;
4. add a link between two labeled trees;
5. delete a link between two labeled trees.
4.2 Induction of Constraints
?N (or ?V ) denotes the set of noun (or verb) con-
cepts. Let C ? ?V be a verb concept with one
argument. Suppose that we have gotten the ini-
tial closed semantic constraint of its argument,
C ? ? ?N , from a concept-tagged sentence. A
link from C ? to C is added between ?N and ?V .
If C ?? from another sentence is also a close se-
mantic constraint of C?s argument, then the in-
fimum of C ? and C ??, inf(C ?, C ??), is the new C ?.
?x ? ?, C ?  x, if the substitution from C to x still
induces well-formed sentences, then the induction
succeeds. Otherwise, the disjointed union C ??C ??
is the closed semantic constraint.
Definition 4.6 The induction of the closed
semantic constraints of C,D ? ? is defined by
CuD =
?
?
?
inf(C,D) if ?x[inf(C,D)  x]
succeeds in the substitution
C ?D otherwise
Definition 4.7 By Theorem 4.1, the induction
between C ?D and E ? ? is defined by
(C ?D) u E =
{
(C u E) ?D if S(C,E)  S(D,E)
C ? (D u E) otherwise
Theoretically, if C1?C2?? ? ??Cn is the closed se-
mantic constraint of the argument of C ? ?V , then
?i, ?x[Ci  x] succeeds in the substitution. Thus,
in the WordNet-like lexicon, there are n links from
?N to ?V for C, where n is called the length of the
constraint. The approach to the closed semantic
constraints of the verb concepts with two argu-
ments is similar.
4.3 Clustering of Constraints
Definition 4.8 Suppose that there are N argu-
ments for all verb concepts and the length of the
i-th constraint is li, then l? =
N?
i=1
li/N is called the
average length of the constraints.
l? indicates the rationality of the concept classifi-
cation in a WordNet-like lexicon, which also acts
as an index of the evolution. Our presupposition
is that the optimization of the lexicon must have
the least average length of the constraints. The
clustering of noun concepts constrained by the ar-
guments of the verb concepts should be a standard
of the classification of ?N .
Definition 4.9 S  S1  ? ? ?  Sn  ? ? ? is
Cauchy sequence of evolution iff ? > 0,?N ?
N,?i, j > N, ?(Si  Sj) < .
Theorem 4.2 The Cauchy sequence of evolution
is convergent. And ? > 0,?i, j ? N s.t. |l?(Si) ?
l?(Sj)| < .
?N is structured by not only the hypernymy rela-
tion but also the closed semantic constraints. Of
course, the hypernymy relation in ?N is princi-
pal, but not necessarily unique. As described in
Example 2.1, the distinct angles of view provide
enough space for the evolution. By the hypernymy
relation in ?V , we have
Property 4.1 ?C,C ? ? ?V , C  C ?, if the closed
semantic constraint of C ? is C1 ? C2 ? ? ? ? ? Cn,
then ?Cn+1, ? ? ? , Cm ? ?N such that (((C1 ?C2 ?
? ? ??Cn)uCn+1)u? ? ?uCm) is the closed semantic
constraint of C.
This property provides an approach to the empiri-
cal testing of the concept classification of ?V if ?N
is fixed. Separately, ?N (or ?V ) can be evaluated
by some indexes and evolves to a satisfiable result.
A little more complicated, the closed semantic con-
straints destroy the independent evolution of ?N
and ?V . If ?V is fixed, then the optimization of
?N may be implemented (but not completely re-
liable) and vice versa. While it is still an open
problem to define a numerical measure that could
formalize the optimization of the total structures
in a WordNet-like lexicon, especially ?N and ?V .
5 Conclusion
A scheme of the closed semantic constraint in a
WordNet-like lexicon based on WSD has been de-
scribed as an application driven construction of
a dynamic lexicon. At the same time, the fur-
ther topic leads to how the rule-based concept
tagging benefits from the descriptions of seman-
tic constraint. The empirical method is much em-
phasized in the WSD and the development of the
dynamic lexicon, such as the TagSet training, the
SynSet testing and the evolution of a WordNet-like
lexicon (see [15], [16] and [17]). The author be-
lieves that the computable part in Computational
Lexicology is nothing but the evolution of the dy-
namic lexicon oriented to a particular application,
which is actually the optimization of the language
knowledge base.
Acknowledgement
I appreciate all my colleagues participating in the
CCD project, the blithesome collaboration with
them is always memorable for me. Many thanks to
my friends in the Second and the Third Workshop
on Chinese Lexical Semantics for their kindly dis-
cussion with the author. Lastly, the most thankful
words are given to my wife for her longtime toler-
ance to my weaselling from the housework under
the false pretense of research.
References
[1] ALPAC 1966 Language and Machine: Com-
puters in Translation and Linguistics, Na-
tional Research Council Automatic Language
Processing Advisory Committee, Washing-
ton, D.C.
[2] Aristotle 1941 Categoriae, in The Basic
Works of Aristotle, R. McKeon (ed). Random
House, New York.
[3] Beckwith R. 1998 Design and Implementation
of the WordNet Lexical Database and Search-
ing Software, in [5], pp105-127.
[4] Fellbaum C. 1998 A Semantic Net of English
Verbs, in [5], pp69-104.
[5] Fellbaum C. (ed) 1999 WordNet: An Elec-
tronic Lexical Database, The MIT Press.
[6] Ide N. and Ve?ronis J. 1998 Introduction to
Special Issue on Word Sense Disambiguation:
The State of Art, Computational Linguistics,
Vol. 24, No. 1, pp1-40.
[7] Liu Y, Yu S.W. and Yu J.S. Building a Bilin-
gual WordNet: New Approaches and algo-
rithms, accepted by COLING2002.
[8] Manning C.D. and Schu?tze H. 1999, Founda-
tions of Statistical Natural Language Process-
ing, The MIT Press.
[9] Miller G.A. et al1993 Introduction to Word-
Net: An On-line Lexical Database, in the at-
tached specification of WordNet 1.6.
[10] Miller G.A. 1998 Nouns in WordNet, in [5],
pp23-46.
[11] Priss U. 1999 The Formalization of WordNet
by Methods of Relational Concept Analysis, in
[5], pp179-196.
[12] Vossen P. (ed.) 1998 EuroWordNet: A Multi-
linugual Database with Lexical Semantic Net-
works. Dordrecht: Kluwer.
[13] Yu J.S. and Yu S.W. et al2001 Introduc-
tion to Chinese Concept Dictionary, in Inter-
national Conference on Chinese Computing
(ICCC2001), pp361-367.
[14] Yu J.S. 2001 The Structure of Chinese Con-
cept Dictionary, accepted by Journal of Chi-
nese Information Processing, 2001.
[15] Yu J.S. 2001 Evolution of WordNet-like Lexi-
con, in The First International Conference of
Global WordNet, Mysore, India, 2002.
[16] Yu J.S. and Yu S.W. 2002 Word Sense Dis-
ambiguation based on Integrated Language
Knowledge Base, in The 2nd International
Conference on East-Asian Language Pro-
cessing and Internet Information Technology
(EALPIIT?2002).
[17] Yu J.S. 2002 Statistical Methods in Word
Sense Disambiguation, draft (can be down-
loaded from http://icl.pku.edu.cn/yujs/) of
seminar at the Institute of Computational
Linguistics, Peking Univ..
