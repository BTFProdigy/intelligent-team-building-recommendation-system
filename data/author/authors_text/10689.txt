Proceedings of the Third Workshop on Statistical Machine Translation, pages 163?166,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Statistical Transfer Systems for French?English
and German?English Machine Translation
Greg Hanneman and Edmund Huber and Abhaya Agarwal and Vamshi Ambati
and Alok Parlikar and Erik Peterson and Alon Lavie
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213 USA
{ghannema, ehuber, abhayaa, vamshi, aup, eepeter, alavie}@cs.cmu.edu
Abstract
We apply the Stat-XFER statistical transfer
machine translation framework to the task of
translating from French and German into En-
glish. We introduce statistical methods within
our framework that allow for the principled
extraction of syntax-based transfer rules from
parallel corpora given word alignments and
constituency parses. Performance is evaluated
on test sets from the 2007 WMT shared task.
1 Introduction
The Carnegie Mellon University statistical trans-
fer (Stat-XFER) framework is a general search-
based and syntax-driven framework for develop-
ing MT systems under a variety of data condi-
tions (Lavie, 2008). At its core is a transfer en-
gine using two language-pair-dependent resources:
a grammar of weighted synchronous context-free
rules (possibly augmented with unification-style fea-
ture constraints), and a probabilistic bilingual lexi-
con of syntax-based word- and phrase-level transla-
tions. The Stat-XFER framework has been used to
develop research MT systems for a number of lan-
guage pairs, including Chinese?English, Hebrew?
English, Urdu?English, and Hindi?English.
In this paper, we describe our use of the frame-
work to create new French?English and German?
English MT systems for the 2008 Workshop on Sta-
tistical Machine Translation shared translation task.
We first describe the acquisition and processing of
resources for each language pair and the roles of
those resources within the Stat-XFER system (Sec-
tion 2); we then report results on common test sets
(Section 3) and share some early analysis and future
directions (Section 4).
2 System Description
Building a new machine translation system under
the Stat-XFER framework involves constructing a
bilingual translation lexicon and a transfer gram-
mar. Over the past six months, we have developed
new methods for extracting syntax-based translation
lexicons and transfer rules fully automatically from
parsed and word-aligned parallel corpora. These
new methods are described in detail by Lavie et
al. (2008). Below, we detail the statistical meth-
ods by which these resources were extracted for our
French?English and German?English systems.
2.1 Lexicon
The bilingual lexicon is automatically extracted
from automatically parsed and word-aligned paral-
lel corpora. To obtain high-quality statistical word
alignments, we run GIZA++ (Och and Ney, 2003)
in both the source-to-target and target-to-source di-
rections, then combine the resulting alignments with
the Sym2 symmetric alignment heuristic of Ortiz-
Mart??nez et al (2005)1. From this data, we extract a
lexicon of both word-to-word and syntactic phrase-
to-phrase translation equivalents.
The word-level correspondences are extracted di-
rectly from the word alignments: parts of speech for
these lexical entries are obtained from the preter-
1We use Sym2 over more well-known heuristics such as
?grow-diag-final? because Sym2 has been shown to give the
best results for the node-alignment subtask that is part of our
processing chain.
163
ws cs wt ct r
paru V appeared V 0.2054
paru V seemed V 0.1429
paru V found V 0.0893
paru V published V 0.0804
paru V felt V 0.0714
.
.
.
.
.
.
.
.
.
paru V already ADV 0.0089
paru V appear V 0.0089
paru V authoritative ADJ 0.0089
Table 1: Part of the lexical entry distribution for the
French (source) word paru.
minal nodes of parse trees of the source and target
sentences. If parsers are unavailable for either lan-
guage, we have also experimented with determin-
ing parts of speech with independent taggers such
as TreeTagger (Schmid, 1995). Alternatively, parts
of speech may be projected through the word align-
ments from one language to the other if the infor-
mation is available on at least one side. Syntactic
phrase-level correspondences are extracted from the
parallel data by applying the PFA node alignment
algorithm described by Lavie et al (2008). The
yields of the aligned parse tree nodes are extracted
as constituent-level translation equivalents.
Each entry in the lexicon is assigned a rule score,
r, based on its source-side part of speech cs, source-
side text ws, target-side part of speech ct, and target-
side text wt. The score is a maximum-likelihood es-
timate of the distribution of target-language transla-
tion and source- and target-language parts of speech,
given the source word or phrase.
r = p(wt, ct, cs |ws) (1)
? #(wt, ct, ws, cs)#(ws) + 1
(2)
We employ add-one smoothing in the denominator
of Equation 2 to counteract overestimation in the
case that #(ws) is small. Rule scores provide a way
to promote the more likely translation alternatives
while still retaining a high degree of diversity in the
lexicon. Table 1 shows part of the lexical distribu-
tion for the French (source) word paru.
The result of the statistical word alignment pro-
cess and lexical extraction is a bilingual lexicon con-
taining 1,064,755 entries for French?English and
1,111,510 entries for German?English. Sample lex-
ical entries are shown in Figure 1.
2.2 Grammar
Transfer grammars for our earlier statistical transfer
systems were manually created by in-house experts
of the languages involved and were therefore small.
The Stat-XFER framework has since been extended
with procedures for automatic grammar acquisition
from a parallel corpus, given constituency parses for
source or target data or both. Our French and Ger-
man systems used the context-free grammar rule ex-
traction process described by Lavie et al (2008).
For French, we used 300,000 parallel sentences from
the Europarl training data parsed on the English side
with the Stanford parser (Klein and Manning, 2003)
and on the French side with the Xerox XIP parser
(A??t-Mokhtar et al, 2001). For German, we used
300,000 Europarl sentence pairs parsed with the En-
glish and German versions of the Stanford parser2.
The set of rules extracted from the parsed corpora
was filtered down after scoring to improve system
performance and run time. The final French rule set
was comprised of the 1500 most frequently occur-
ring rules. For German, rules that occurred less than
twice were filtered out, leaving a total of 16,469. In
each system, rule scores were again calculated by
Equation 2, with ws and wt representing the full
right-hand sides of the source and target grammar
rules.
A secondary version of our French system used a
word-level lexicon extracted from the intersection,
rather than the symmetricization, of the GIZA++
alignments in each direction; we hypothesize that
this tends to improve precision at the expense of re-
call. The word-level lexicon was supplemented with
syntax-based phrase-level entries obtained from the
PFA node alignment algorithm. The grammar
contained the 700 highest-frequency and the 500
highest-scoring rules extracted from the parallel
parsed corpus. This version had a total lexicon size
of 2,023,531 entries and a total grammar of 1034
rules after duplicates were removed. Figure 2 shows
2Due to a combination of time constraints and paucity of
computational resources, only a portion of the Europarl parallel
corpus was utilized, and none of the supplementary news com-
mentary training data was integrated.
164
)(
{VS,248840}
V::V |: ["paru"] ?> ["appeared"]
  (*score* 0.205357142857143)
)
  (*score* 0.763636363636364)
{NP,2000012}
NP::NP |: ["ein" "Beispiel"] ?> ["an" "example"]
(
Figure 1: Sample lexical entries for French and German.
sample grammar rules automatically learned by the
process described above.
2.3 Transfer Engine
The Stat-XFER transfer engine runs in a two-stage
process, first applying the grammar and lexicon
to an input sentence, then running a decoder over
the resulting lattice of scored translation pieces.
Scores for each translation piece are based on a
log-linear combination of several features: language
model probability, rule scores, source-given-target
and target-given-source lexical probabilities, parse
fragmentation, and length. For more details, see
Lavie (2008). The use of a German transfer gram-
mar an order of magnitude larger than the corre-
sponding French grammar was made possible due to
a recent optimization made in the engine. When en-
abled, it constrains the search of translation hypothe-
ses to the space of hypotheses whose structure satis-
fies the consituent structure of a source-side parse.
3 Evaluation
We trained our model parameters on a subset of
the provided ?dev2006? development set, optimiz-
ing for case-insensitive IBM-style BLEU (Papineni
et al, 2002) with several iterations of minimum error
rate training on n-best lists. In each iteration?s list,
we also included the lists from previous iterations in
order to maintain a diversity of hypothesis types and
scores. The provided ?test2007? and ?nc-test2007?
data sets, identical with the test data from the 2007
Workshop on Statistical Machine Translation shared
task, were used as internal development tests.
Tables 2, 3, and 4 report scores on these data sets
for our primary French, secondary French, and Ger-
man systems. We report case-insensitive scores for
version 0.6 of METEOR (Lavie and Agarwal, 2007)
with all modules enabled, version 1.04 of IBM-style
BLEU (Papineni et al, 2002), and version 5 of TER
(Snover et al, 2006).
Data Set METEOR BLEU TER
dev2006 0.5332 0.2063 64.81
test2007 0.5358 0.2078 64.75
nc-test2007 0.5369 0.1719 69.83
Table 2: Results for the primary French?English system
on provided development and development test sets.
Data Set METEOR BLEU TER
dev2006 0.5330 0.2086 65.02
test2007 0.5386 0.2129 64.29
nc-test2007 0.5311 0.1680 70.90
Table 3: Results for the secondary French?English sys-
tem on provided development and development test sets.
4 Analysis and Conclusions
From the development test results in Section 3, we
note that the Stat-XFER systems? performance cur-
rently lags behind the state-of-the-art scores on the
2007 test data3. This may be in part due to the low
volume of training data used for rule learning. A key
research question in our approach is how to distin-
guish low-frequency correct and useful transfer rules
from ?noisy? rules that are due to parser errors and
incorrect word alignments. We believe that learning
rules from more data will help alleviate this prob-
lem by proportionally increasing the counts of good
rules compared to incorrect ones. We also plan to
study methods for more effective rule set pruning,
regardless of the volume of training data used.
The difference in metric scores between in-
domain and out-of-domain data is partly due to ef-
fects of reference length on the metrics used. De-
tailed output from METEOR and BLEU shows that
the reference translations for the test2007 set are
about 94% as long as the primary French?English
3Top scores on the 2007 test data are approximately 0.60
METEOR, 0.33 BLEU, and 57.6 TER. See Callison-Burch et
al. (2007) for full results.
165
(
  (*score* 0.866050808314088
)
{PP,1627955}
PP:PP [PRE "d?" "autres" N] ?> [PRE "other" N]
  (X1::Y1)
  (X4::Y3)
)
(
{PP,3000085}
PP:ADVP ["vor" CARD "Monaten"] ?> [NUM "months" "ago"]
  (*score* 0.9375)
  (X2::Y1)
)
Figure 2: Sample grammar rules for French and German.
Data Set METEOR BLEU TER
dev2006 0.4967 0.1794 68.68
test2007 0.5052 0.1878 67.94
nc-test2007 0.4939 0.1347 74.38
Table 4: Results for the German?English system on pro-
vided development and development test sets.
system?s translations. On this set, our system has
approximately balanced precision (0.62) and recall
(0.66). However, the nc-test2007 references are only
84% as long as our output, a situation that hurts our
system?s precision (0.57) but boosts its recall (0.68).
METEOR, as a metric that favors recall, shows a
negligible increase in score between these two test
sets, while BLEU and TER report significant relative
drops of 17.3% and 7.8%. This behavior appears to
be consistent on the test2007 and nc-test2007 data
sets across systems (Callison-Burch et al, 2007).
Acknowledgments
This research was supported in part by NSF grants
IIS-0121631 (AVENUE) and IIS-0534217 (LE-
TRAS), and by the DARPA GALE program. We
thank the members of the Parsing and Semantics
group at Xerox Research Centre Europe for assisting
in parsing the French data using their XIP parser.
References
Salah A??t-Mokhtar, Jean-Pierre Chanod, and Claude
Roux. 2001. A multi-input dependency parser. In
Proceedings of the Seventh International Workshop on
Parsing Technologies, Beijing, China, October.
Chris Callison-Burch, Cameron Fordyce, Philipp Koehn,
Christof Monz, and Josh Schroeder. 2007. (Meta-)
evaluation of machine translation. In Proceedings of
the Second Workshop on Statistical Machine Transla-
tion, pages 136?158, Prague, Czech Republic, June.
Dan Klein and Christopher D. Manning. 2003. Fast exact
inference with a factored model for natural language
parsing. In Advances in Neural Information Process-
ing Systems 15, pages 3?10. MIT Press, Cambridge,
MA.
Alon Lavie and Abhaya Agarwal. 2007. METEOR: An
automatic metric for MT evaluation with high levels of
correlation with human judgments. In Proceedings of
the Second Workshop on Statistical Machine Transla-
tion, pages 228?231, Prague, Czech Republic, June.
Alon Lavie, Alok Parlikar, and Vamshi Ambati. 2008.
Syntax-driven learning of sub-sentential translation
equivalents and translation rules from parsed paral-
lel corpora. In Proceedings of the Second Work-
shop on Syntax and Structure in Statistical Transla-
tion, Columbus, OH, June. To appear.
Alon Lavie. 2008. Stat-XFER: A general search-based
syntax-driven framework for machine translation. In
Computational Linguistics and Intelligent Text Pro-
cessing, Lecture Notes in Computer Science, pages
362?375. Springer.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Daniel Ortiz-Mart??nez, Ismael Garc??a-Varea, and Fran-
cisco Casacuberta. 2005. Thot: A toolkit to train
phrase-based models for statistical machine transla-
tion. In Proceedings of the 10th Machine Translation
Summit, pages 141?148, Phuket, Thailand, September.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic eva-
lution of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311?318, Philadelphia, PA,
July.
Helmut Schmid. 1995. Improvements in part-of-speech
tagging with an application to German. In Proceed-
ings of the ACL SIGDAT Workshop.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea
Micciulla, and John Makhoul. 2006. A study of trans-
lation edit rate with targeted human annotation. In
Proceedings of the Seventh Conference of the Associ-
ation for Machine Translation in the Americas, pages
223?231, Cambridge, MA, August.
166
Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 87?95,
ACL-08: HLT, Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Syntax-driven Learning of Sub-sentential Translation Equivalents and
Translation Rules from Parsed Parallel Corpora
Alon Lavie
alavie@cs.cmu.edu
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
Alok Parlikar
aup@cs.cmu.edu
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
Vamshi Ambati
vambati@cs.cmu.edu
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
Abstract
We describe a multi-step process for automati-
cally learning reliable sub-sentential syntactic
phrases that are translation equivalents of each
other and syntactic translation rules between
two languages. The input to the process is a
corpus of parallel sentences, word-aligned and
annotated with phrase-structure parse trees.
We first apply a newly developed algorithm
for aligning parse-tree nodes between the two
parallel trees. Next, we extract all aligned
sub-sentential syntactic constituents from the
parallel sentences, and create a syntax-based
phrase-table. Finally, we treat the node align-
ments as tree decomposition points and extract
from the corpus all possible synchronous par-
allel tree fragments. These are then converted
into synchronous context-free rules. We de-
scribe the approach and analyze its application
to Chinese-English parallel data.
1 Introduction
Phrase-based Statistical MT (PB-SMT) (Koehn et
al., 2003) has become the predominant approach to
Machine Translation in recent years. PB-SMT re-
quires broad-coverage databases of phrase-to-phrase
translation equivalents. These are commonly ac-
quired from large volumes of automatically word-
aligned sentence-parallel text corpora. Accurate
identification of sub-sentential translation equiva-
lents, however, is a critical process in all data-driven
MT approaches, including a variety of data-driven
syntax-based approaches that have been developed
in recent years. (Chiang, 2005) (Imamura et al,
2004) (Galley et al, 2004).
In this paper, we describe a multi-step process for
automatically learning reliable sub-sentential syn-
tactic phrases that are translation equivalents of each
other and syntactic translation rules between two
languages. The input to the process is a corpus of
parallel sentences, word-aligned and annotated with
phrase-structure parse trees for both languages. Our
method consists of three steps. In the first step,
we apply a newly developed algorithm for aligning
parse-tree nodes between the two parallel trees. In
the second step, we extract all aligned sub-sentential
syntactic constituents from the parallel sentences,
and create a syntax-based phrase-table. Our syn-
tactic phrases come with constituent ?labels? which
can guide their syntactic function during decoding.
In the final step, we treat the node alignments as
tree decomposition points and extract from the cor-
pus all possible synchronous parallel tree fragments.
These are then converted into synchronous context-
free rules. Our methods do not depend on any spe-
cific properties of the underlying phrase-structure
representations or the parsers used, and were de-
signed to be applicable even when these represen-
tations are quite different for the two languages.
The approach described is used to acquire the re-
sources for a statistical syntax-based MT approach
that we have developed (Stat-XFER), briefly de-
scribed below. The resulting resources can, how-
ever, be used in any syntax-based data-driven MT
approach other than our own. The focus of this pa-
per is on our syntax-driven process for extracting
phrases and rules from data. We describe the ap-
proach and analyze its effectiveness when applied to
large-volumes of Chinese-English parallel data.
87
1.1 The Stat-XFER MT Framework
Stat-XFER is a search-based syntax-driven frame-
work for building MT systems. The underlying for-
malism is based on synchronous context-free gram-
mars. The synchronous rules can optionally be aug-
mented by unification-style feature constraints. The
synchronous grammars can be acquired automati-
cally from data, but also manually developed by ex-
perts. A simple example transfer-rule (for Chinese-
to-English) can be seen below:
{NP,1062753}
NP::NP [DNP NP] -> [NP PP]
(
(*score* 0.946640316205534)
(X2::Y1)
(X1::Y2)
)
Each rule has a unique identifier followed by a
synchronous rule for both source and target sides.
The alignment of source-to-target constituents is ex-
plicitly represented using ?X? indices for the source
side, and ?Y? indices for the target side. Rules can
also have lexical items on either side, in which case
no alignment information is required for these ele-
ments. Feature constraints can optionally be speci-
fied for both source and target elements of the rule.
We do not address the learning of feature constraints
in the work described here, and concentrate only
on the acquisition of the synchronous CFG rules.
The rules can be modeled statistically and assigned
scores, which can then be used as decoding features.
The Stat-XFER framework also includes a fully-
implemented transfer engine that applies the trans-
fer grammar to a source-language input sentence at
runtime, and produces collections of scored word
and phrase-level translations according to the gram-
mar. These are collected into a lattice data-structure.
Scores are based on a log-linear combination of sev-
eral features, and a beam-search controls the un-
derlying parsing and transfer process. A second-
stage monotonic decoder is responsible for combin-
ing translation fragments into complete translation
hypotheses (Lavie, 2008)
2 PFA Algorithm for Node Aligment
2.1 Objectives of the Algorithm
Our objective of the first stage of our approach is to
detect sub-sentential constituent correspondences in
parallel sentences, based on phrase-structure parses
for the two corresponding sentences. Given a pair
of parallel sentences and their corresponding parse
trees, our goal is to find pairings of nodes in the
source and target trees whose yields are translation
equivalents of each other. Our current approach only
considers complete constituents and their contigious
yields, and will therefore not align discontiguous
phrases or partial constituents. Similar to phrase ex-
traction methods in PB-SMT, we rely on word-level
alignments (derived manually or automatically) as
indicators for translation equivalence. The assump-
tion applied is that if two words are aligned with
each other, they carry the same meaning and can be
treated as translation equivalents. Constituents are
treated as compositional units of meaning and trans-
lation equivalence.
2.2 Related Work
Aligning nodes in parallel trees has been in-
vestigated by a number of previous researchers.
(Samuelsson and Volk, 2007) describe a process for
manual alignment of nodes in parallel trees. This
approach is well suited for generating reliable par-
allel treebanks, but is impractical for accumulating
resources from large parallel data. (Tinsley et al,
2007) use statistical lexicons derived from automatic
statistical word alignment for aligning nodes in par-
allel trees. In our approach, we use the word align-
ment information directly, which we believe may be
more reliable than the statistical lexicon. (Groves et
al., 2004) propose a method of aligning nodes be-
tween parallel trees automatically, based on word
alignments. In addition to the word alignment in-
formation, their approach uses the constituent labels
of nodes in the trees, and the general structure of the
tree. Our approach is more general in the sense that
we only consider the word alignments, thereby mak-
ing the approach applicable to any parser or phrase-
structure representation, even ones that are quite dif-
ferent for the two languages involved.
88
2.3 Unaligned Words and Contiguity
Word-level alignment of phrase-level translation
equivalents often leaves some words unaligned. For
example, some languages have articles, while oth-
ers do not. It is thus reasonable to expect that con-
stituent pairs in parallel trees that are good transla-
tion equivalents of each other may contain some un-
aligned words. Our PFA node-alignment algorithm
allows for such constituents to be matched.
Different languages have different word orders. In
English, an adjective always comes before a noun,
while in French, in most cases, the adjective fol-
lows its noun. Our node alignment algorithm allows
aligning of constituents regardless of the word order
expressed by the linear precedence relation of their
sub-constituents. As long as one piece of contiguous
text dominated by a node covers the same word-level
alignments as the yield of a node in the parallel tree,
the two nodes can be aligned.
2.4 Wellformedness constraints
Given a pair of word-aligned sentences and their
corresponding parse trees S and T , represented as
sets of constituent nodes, our PFA node alignment
algorithm produces a collection of aligned node-
pairs (Si, Tj). The underlying assumptions of com-
positionality in meaning and word-level alignments
being indicative of translation equivalence lead di-
rectly to the following node alignment wellformed-
ness criteria:
1. If a node Si is linked to a node Tj , then any
node within the subtree of node Si can only be
linked to nodes within the subtree of node Tj .
2. If a node Si is linked to a node Tj , then any
node that dominates the node Si can only be
linked to nodes that dominate the node Tj .
3. If a node Si is linked to a node Tj , then the
word alignments of the yields of the two con-
stituents must satisfy the following:
(a) Every word in the yield of the node Si
must be aligned to one or more words in
the yield of the node Tj , or it should be
unaligned.
(b) Every word in the yield of the node Tj
must be aligned to one or more words in
the yield of the node Si, or it should be
unaligned.
(c) There should be at least one alignment be-
tween the yields of nodes Si and Tj . Thus,
the words in the yields can not all be un-
aligned.
2.5 Arithmetic Representation
Our PFA algorithm uses a arithmetic mapping that
elegently carries over the constraints characterized
by the wellformedness constraints elaborated above.
This mapping is designed to ensure that each aligned
word, which carries a distinct ?piece of meaning?
can be uniquely identified, and also inherently re-
flects the compositional properties of constituent
translation equivalence. This is accomplished by
assigning numerical values to the nodes of the two
parse trees being aligned, in a bottom-up fashion,
starting from the leaf nodes of the trees. Leaf nodes
that correspond to words that are aligned are each
assigned a unique prime number. Unaligned leaf
nodes are assigned a value of ?1?. Constituent nodes
in the parse trees are then assigned a value that is
the product of all its sub-constituent nodes. Because
of the arithmetic property that any composite num-
ber can be uniquely factored into primes, it should
be evident that the value of every constituent node
uniquely identifies the aligned words that are cov-
ered by its yield. Consequently, by assigning the
same prime values to the aligned words of both trees,
retrieving aligned constituent nodes is as simple as
finding the set of nodes in the two trees that carry the
same numerical value. Note that by assigning values
of ?1? to unaligned words, these unaligned words
do not influence the numerical values assigned to
constituent nodes, thus reflecting their treatment as
?don?t cares? with respect to the translation equiva-
lence of constituent nodes.
2.6 Description of the PFA Algorithm
The PFA algorithm uses the concept of ?composite
meaning as prime factorization?, and hence the name
(Prime Factorization and Alignments). The algo-
rithm assigns values to the leaf nodes, propogates
the values up the tree, and then compares the node
values across the trees to align the nodes. As de-
scribed above, leaf nodes which have word align-
ments are assigned unique prime numbers, and the
89
Figure 1: Node-Aligned Parallel Sentences
same prime is assigned to the corresponding aligned
words in the parallel sentences. Leaf nodes corre-
sponding to unaligned words are assigned the value
?1?. The treatment of ?one-to-many? word align-
ments is a special case. Such alignments are con-
sidered to carry the same meaning, and should thus
be assigned the same value. To accomplish this, if a
single word is aligned to multiple words in the other
language, we assign the same prime number to all
words on the ?multiple? side, and assign the product
of these to the single word equivalent.
Another special case is when the parse trees con-
tain unary productions. In this case, the values of
both nodes involved in this production are the same.
Our node alignment algorithm breaks this ?tie? by
selecting the node that is ?lower? in the tree (the
daughter node of the unary production). A simi-
lar situation with two nodes being assigned identical
values can arise when one or more unaligned words
are attached directly to the parent node. Here too,
our algorithm aligns the ?lower? node and leaves
the ?higher? node unaligned. These decisions reflect
our desire to be conservative with respect to such
ambiguous cases, and their implications on the no-
tion of translational equivalence. This also provides
some robustness against noisy alignments.
It is straightfoward to verify that the PFA algo-
rithm satisfies the wellformedness constraints de-
scribed above. Also, since multiplication is com-
mutative, the algorithm is not effected by differing
word orders within parallel constituent structures.
The PFA algorithm run on a sample Chinese-
English parallel sentence is shown in Figure 1. The
value of each node as shown as a part of its label.
The aligned nodes are marked by shapes. A triangle
aligns to a triangle, and squares to squares.
3 Syntax-based Sub-sentential Phrase
Extraction
The alignment of nodes as described in the previous
section allows us to build a comprehensive syntax-
based phrase-to-phrase translation lexicon from a
parallel corpus. To build a syntax-based ?phrase
table?, we simply extract all aligned constituent
nodes along with their yields and enter them into
a database, while accumulating frequency counts.
In addition to the source-to-target phrase corre-
spondences, we record the constituent labels of the
aligned constituent nodes on both the source and tar-
get sides (which may be different). These labels
?connect? the phrases with synatactic transfer rules
during decoding. The set of phrases extracted from
the example sentence in Figure 1 is shown in Fig-
ure 2.
90
Figure 2: Phrases extracted from Aligned Nodes
The process of building syntax-based ?phrase ta-
bles? from large corpora of sentence-parallel data is
quite similar to the corresponding process in phrase-
based SMT systems. Our phrase correspondences,
however, only reflect contiguous and complete con-
stituent correspondences. We also note that the ex-
tracted phrase tables in both approaches can be mod-
eled statistically in similar ways. Similar to common
practice in PB-SMT, we currently use the frequency
counts of the phrases to calculate relative likelihood
estimates and use these as features in our Stat-XFER
decoder.
4 Evaluation of the PFA algorithm
The accuracy of our node alignment algorithm de-
pends on both the quality of the word alignments
as well as the accuracy of the parse trees. We per-
formed several experiments to assess the effects of
these underlying resources on the accuracy of our
approach. The most accurate condition is when the
parallel sentences are manually word-aligned, and
when verified correct parse trees are available for
both source and target sentences. Performance is
expected to degrade when word alignments are pro-
duced using automatic methods, and when correct
parse trees are replaced with automatic parser out-
put. In these experiments, we used a manually word-
aligned parallel Chinese-English TreeBank consist-
ing of 3342 parallel sentences.
4.1 Manual Constituent Node Alignments
We first investigated the accuracy of our approach
under the most accurate condition. We sampled 30
sentences from the Chinese-English treebank cor-
pus. A bilingual expert from our group then man-
ually aligned the nodes in these trees. These node
Precision Recall F-1 F-0.5
0.8129 0.7325 0.7705 0.7841
Table 1: Accuracy of PFA Node Alignments against
Manual Node Alignments
alignments were then used as a ?gold standard?. We
then used the accurate parse trees and the manually
created word alignments for these sentence pairs,
and ran the PFA node algorithm, and compared the
resulting node alignments with the gold standard
alignments. The Precision, Recall, F-1 and F-0.5 re-
sults are reported in Table 1.
We manually inspected cases where there was a
mismatch between the manual and automatic node
alignments, and found several trends. Many of
the alignment differences were the result of one-to-
many or many-to-many word alignemnts. For ex-
ample, in some cases a verb in Chinese was word-
aligned to an auxiliary and a head verb on the en-
glish side (e.g. have and put). The PFA algorithm
in this case node-aligns the VP that governs the Chi-
nese verb to the VP that contains both auxiliary and
head verbs on the English side. The gold standard
human alignments, however, in some cases, aligned
the VP of the Chinese verb to the English VP that
governs just the main verb. Other mismatches were
attributed to errors or inconsistencies in the manual
word alignment and to the treatment of traces and
fillers in the parse trees.
4.2 Effect of Using Automatic Word
Alignments
We next tested how sensitive the PFA algorithm is
to errors in automatic word alignment. We use the
entire 3342 sentences in the parallel treebank for
this experiment. We first ran the algorithm with
the correct parse trees and manual word-alignments
as input. We use the resulting node alignments
as the gold standard in this case. We then used
GIZA++ to get bidirectional word alignments, and
combined them using various strategies. In this sce-
nario, the trees are high-quality (from the treebank),
but the alignments are noisy. The results obtained
are shown in Table 2. Unsurprisingly, the ?Union?
combination method has the best precision but worst
recall, while the ?Intersection? combination method
has the best recall but worst precision. The four
91
Comb Method Prec Rec F-1 F-0.5
Intersection 0.6382 0.5395 0.5846 0.6014
Union 0.8114 0.2915 0.4288 0.5087
Sym1 0.7142 0.4534 0.5546 0.5992
Sym2 0.7135 0.4631 0.5616 0.6045
Grow-Diag-Final 0.7777 0.3462 0.4790 0.5493
Grw-Diag-Fin-And 0.6988 0.4700 0.5619 0.6011
Table 2: Manual Trees, Automatic Node Alignments
other methods for combining word alignments fall
in between. Three of the four (all except ?grow-
diag-final?) behave quite similarly. We generally be-
lieve that precision is somewhat more important than
recall for this task, and have thus used the ?sym2?
method (Ortiz-Mart??nez et al, 2005) (which has the
best F-0.5 score) for our translation experiments.
4.3 Effect of Using Automatic Parses
We evaluated the effect of parsing errors (as re-
flected in automatically derived parse trees) on the
quality of the node alignments. We parsed the tree-
bank corpus on both English and Chinese using the
Stanford parser, and extracted phrases using manual
word alignments. Compared to the phrases extracted
from the manual trees, we obtained a precision of
0.8749, and a recall of 0.7227, that is, an F-0.5 mea-
sure of 0.8174. We then evaluated the most ?noisy?
condition that involves both automatic word align-
ments and automatic parse trees. We evaluated the
phrase extraction with different Viterbi combination
strategies. The ?sym2? combination gave the best
results, with a precision of 0.6251, recall of 0.3566,
thus an F-0.5 measure of 0.4996.
5 Synchronous Tree Fragment and CFG
Rule Extraction
5.1 Related Work
Syntax-based reordering rules can be used as a pre-
processing step for PB-SMT (and other approaches),
to decrease the word-order and syntactic distor-
tion between the source and target languages (Xia
and McCord, 2004). A variety of hierarchical and
syntax-based models, which are applied during de-
coding, have also been developed. Many of these
approaches involve automatic learning and extrac-
tion of the underlying syntax-based rules from data.
The underlying formalisms used has been quite
broad and include simple formalisms such as ITGs
(Wu, 1997), hierarchical synchronous rules (Chiang,
2005), string to tree models by (Galley et al, 2004)
and (Galley et al, 2006), synchronous CFG models
such (Xia and McCord, 2004) (Yamada and Knight,
2001), synchronous Lexical Functional Grammar
inspired approaches (Probst et al, 2002) and others.
Most of the previous approaches for acquiring
syntactic transfer or reordering rules from paral-
lel corpora use syntactic information from only one
side of the parallel corpus, typically the target side.
(Hearne and Way, 2003) describes an approach that
uses syntactic information from the source side to
derive reordering subtrees, which can then be used
within a ?data-oriented translation? (DOT) MT sys-
tem, similar in framework to (Poutsma, 2000). Our
work is different from the above in that we use syn-
tactic trees for both source and target sides to infer
constituent node alignments, from which we then
learn synchronous trees and rules. Our process of
extraction of rules as synchronous trees and then
converting them to synchronous CFG rules is most
similar to that of (Galley et al, 2004).
5.2 Synchronous Tree Fragment Pair
Extraction
The main concept underlying our syntactic rule ex-
traction process is that we treat the node alignments
discovered by the PFA algorithm (described in pre-
vious sections) as synchronous tree decomposition
points. This reflects the fact that these nodes denote
points in the synchronous parse trees where transla-
tion correspondences can be put together composi-
tionally. Using the aligned nodes as decomposition
points, we break apart the synchronous trees into
collections of minimal synchronous tree fragments.
Finally, the synchronous fragments are also con-
verted into synchronous context-free rules. These
are then collected into a database of synchronous
rules.
The input to our rule extraction process consists of
the parallel parse trees along with their node align-
ment information. The constituent nodes in the par-
allel trees that were aligned by the PFA node align-
ment algorithm are treated as tree decomposition
points. At each such decomposition point, spliting
the two parallel trees results in two partial trees or
tree fragments. One synchronous pair consists of
92
the subtrees that are headed by the aligned nodes
where the decomposition took place. Since the sub-
trees are rooted at aligned nodes, their yields are
translation equivalents of each other. The other syn-
chronous tree fragment pair consists of the remain-
ing portions of the trees. The translation equivalence
of the complete tree (or subtree) prior to decomposi-
tion implies that these tree fragments (which exclude
the detached subtrees) also correspond to translation
equivalents. The tree fragments that are obtained by
decomposing the synchronous trees in this fashion
are similar to the Synchronous Tree Insertion Gram-
mar of (Shieber and Schabes, 1990).
We developed a tree traversal algorithm that de-
composes parallel trees into all minimal tree frag-
ments. Given two synchronous trees and their node
alignment decomposition information, our tree frag-
ment extraction algorithm operates by an ?in-order?
traversal of the trees top down, starting from the root
nodes. The traversal can be guided by either the
source or target parse tree. Each node in the tree
that is marked as an aligned node triggers a decom-
position. The subtree that is rooted at this node is
removed from the currently traversed tree. A copy
of the removed subtree is then recursively processed
for top-down decomposition. If the current tree node
being explored is not an aligned node (and thus is not
a decomposition point), the traversal continues down
the tree, possibly all the way to the leaves of the tree.
Decomposition is performed on the corresponding
parallel tree at the same time. We apply this pro-
cess on all the aligned constituent nodes (decompo-
sition points) to obtain all possible decomposed syn-
chronous tree fragment pairs from the original par-
allel parse trees. This results in a collection of all
minimal synchronous subtree fragments. These syn-
chronous subtree fragments are minimal in the sense
that they do not contain any internal aligned nodes.
Another property of the synchronous subtree frag-
ments is that their frontier nodes are either aligned
nodes from the original tree or leaf nodes (corre-
sponding to lexical items). Figure 3 shows some
sample tree fragment pairs that were obtained from
the example discussed earlier in Figure 1.
5.3 Synchronous Transfer Rule Creation
In the last step, we convert the synchronous tree
fragment pairs obtained as described above into syn-
Figure 3: Tree Fragment Pairs Extracted from Aligned
Nodes
chronous context-free rules. This creates rules in a
format that is compatible with the Stat-XFER for-
malism that was described in Section 1. Our system
currently does not use the internal tree structure in-
formation that is contained in the synchronous tree
fragments. Therefore, only the syntactic category la-
bels of the roots of the tree fragments, and the nodes
on the fragment frontier are relevant to decoding.
This in essense corresponds to a ?flattening? of the
synchronous tree fragment into a synchronous con-
text free style rule.
The flattening of the tree fragments is accom-
plished by an ?in-order? traversal on each of the tree
fragments to produce a string representation. Fron-
tier nodes in the fragment are either labeled con-
stituent nodes or leaf nodes of the original parse tree.
These form the right-hand sides of the flattened rule.
The positions of the constituent nodes in the output
string are numbered to keep track of alignment of the
nodes, which is often non-monotonic due to reorder-
ing between the source and target languages. Finally
the root constituent label of the source tree fragment
becomes the source-side parent category of the rule,
while the root label of the target tree fragment be-
comes the target side parent category.
Accurate automatic transfer rule learning re-
quires accurate word alignments and parse struc-
tures. Thus, to favor high precision (at the expense
of some loss of recall), in our work to date on Chi-
nese and other languages, while we extract syntactic
phrases from all available parallel data, we extract
93
rules only from manually word-aligned parsed par-
allel data. To compensate for the limited amount of
data, we generalize the rules as much as possible.
Elements in the rules that originate from leaf nodes
in the parse trees are generalized to their part-of-
speech categories, if the corresponding words were
one-to-one aligned in the parallel sentences. Un-
aligned words and words that are part of one-to-
many alignments are not generalized to the POS
level and remain lexicalized in the final rule.
The phrase table extracted from the corpus and the
rules are scored together to ensure that they are con-
sistent when used in our translation system. For all
Stat-XFER experiments to date, we have used just
the source side conditionig with a constant smooth-
ing factor for robustness to noise.
6 Extraction Applied to Chinese-English
Parallel Data
We used the pipeline of PFA node alignment fol-
lowed by rule extraction to build resources for a
Stat-XFER Chinese-to-English MT system. The
syntax-based phrase table was constructed from
two large parallel corpora released by LDC for the
DARPA/GALE program. The parallel sentences for
both English and Chinese were parsed using the
Stanford parser. The first corpus consists of about
1.2 million sentence pairs. Our extraction process
applied to this corpus resulted in a syntax-based
phrase table of about 9.2 million entries. The other
data source used was a parallel corpus of about 2.6
million sentences, but many of its entries were from
a Chinese-English lexicon. From this corpus, we ex-
tracted 8.75 million phrases.
Rule learning was performed on a 10K-sentence
parallel corpus that was manually word-aligned, re-
leased by LDC for the DARPA/GALE program.
This manually word-aligned corpus includes the par-
allel Chinese-English treebank of 3,343 sentence
pairs. The treebank sentences come with verified
correct parse trees for English and Chinese. The rest
of the 10K corpus was parsed by the Stanford parser.
The complete 10K parallel corpus was node aligned
and rules were extracted as described in Section 5.
Figure 3 shows two synchronous tree fragments that
were extracted from the example node-aligned sen-
tence pair in Figure 1. After generalization and flat-
Figure 4: Rules Extracted from Tree Pairs
Table 3: Statistics for Chinese-English Rules
tening, we obtain rules such as those shown in Fig-
ure 4. The above process resulted in a collection
of almost 100K rules. Some statistics on this rule
set are shown in Table 3. Analysis of this rule set
indicates that only about 4% of these rules were ob-
served more than once in the data. These include
the most general and useful rules for mapping Chi-
nese syntactic structures to their corresponding En-
glish structures. Most of the ?singleton? rules are
highly lexicalized. A large portion of the singleton
rules are noisy rules, but many of them are good and
useful rules. Experiments indicate that removing all
singleton rules hurts translation performance.
7 Conclusions
The process described in this paper provides a fully
automated solution for extracting large collection
of reliable syntax-based phrase tables and syntac-
tic synchronous transfer rules from large volumes
of parsed parallel corpora. In conjunction with the
Stat-XFER syntax-based framework, this provides a
fully automated solution for building syntax-based
MT systems. The current performance of this ap-
proach still lags behind state-of-the-art phrase-based
systems when trained on the same parallel data but is
showing encouraging improvements. Furthermore,
the resources extracted by our process can be used
by various other syntax-based MT approaches.
94
References
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In ACL ?05: Pro-
ceedings of the 43rd Annual Meeting on Association
for Computational Linguistics, pages 263?270, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What?s in a translation rule? In Su-
san Dumais; Daniel Marcu and Salim Roukos, editors,
HLT-NAACL 2004: Main Proceedings, pages 273?
280, Boston, Massachusetts, USA, May 2 - May 7.
Association for Computational Linguistics.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In ACL ?06:
Proceedings of the 21st International Conference on
Computational Linguistics and the 44th annual meet-
ing of the ACL, pages 961?968, Morristown, NJ, USA.
Association for Computational Linguistics.
Declan Groves, Mary Hearne, and Andy Way. 2004. Ro-
bust sub-sentential alignment of phrase-structure trees.
In COLING ?04: Proceedings of the 20th international
conference on Computational Linguistics, page 1072,
Morristown, NJ, USA. Association for Computational
Linguistics.
M. Hearne and A. Way. 2003. Seeing the wood for the
trees: Data-oriented translation.
Kenji Imamura, Hideo Okuma, Taro Watanabe, and Ei-
ichiro Sumita. 2004. Example-based machine transla-
tion based on syntactic transfer with statistical mod-
els. In COLING ?04: Proceedings of the 20th in-
ternational conference on Computational Linguistics,
page 99, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In NAACL
?03: Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology,
pages 48?54, Morristown, NJ, USA. Association for
Computational Linguistics.
Alon Lavie. 2008. A general search-based syntax-driven
framework for machine translation. In Invited paper in
Proceedings of CICLing-2008, pages 362?375. Com-
putational Linguistics and Intelligent Text Processing,
LNCS 4919,Springer.
D. Ortiz-Mart??nez, I. Garc??a-Varea, and F. Casacuberta.
2005. Thot: a toolkit to train phrase-based statisti-
cal translation models. In Tenth Machine Translation
Summit. AAMT, Phuket, Thailand, September.
Arjen Poutsma. 2000. Data-oriented translation. In Pro-
ceedings of the 18th conference on Computational lin-
guistics, pages 635?641, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Katharina Probst, Lori Levin, Erik Peterson, Alon Lavie,
and Jaime Carbonell. 2002. Mt for minority lan-
guages usingelicitation-based learning of syntactic-
transfer rules. Machine Translation, 17(4):245?270.
Yvonne Samuelsson and Martin Volk. 2007. Alignment
tools for Parallel Treebanks. In Proceedings of the
GLDV Fruhjahrstagung.
Stuart M. Shieber and Yves Schabes. 1990. Synchronous
tree-adjoining grammars. In Proceedings of the 13th
Conference on Computational Linguistics, pages 253?
258, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
John Tinsley, Mary Hearne, and Andy Way. 2007. Ex-
ploiting Parallel Treebanks to Improve Phrase-Based
Statistical Machine Translation. In Proceedings of
the Sixth International Workshop on Treebanks and
Linguistic Theories (TLT-07), pages 175?187, Bergen,
Norway.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?403.
Fei Xia and Michael McCord. 2004. Improving a sta-
tistical machine translation system with automatically
learned rewrite patterns. In COLING ?04: Proceed-
ings of the 20th International Conference on Compu-
tational Linguistics, page 508, Morristown, NJ, USA.
Association for Computational Linguistics.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In ACL ?01: Proceedings
of the 39th Annual Meeting on Association for Compu-
tational Linguistics, pages 523?530, Morristown, NJ,
USA. Association for Computational Linguistics.
95
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 140?144,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
An Improved Statistical Transfer System for French?English
Machine Translation
Greg Hanneman, Vamshi Ambati, Jonathan H. Clark, Alok Parlikar, Alon Lavie
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213 USA
{ghannema,vamshi,jhclark,aup,alavie}@cs.cmu.edu
Abstract
This paper presents the Carnegie Mellon
University statistical transfer MT system
submitted to the 2009 WMT shared task
in French-to-English translation. We de-
scribe a syntax-based approach that incor-
porates both syntactic and non-syntactic
phrase pairs in addition to a syntactic
grammar. After reporting development
test results, we conduct a preliminary anal-
ysis of the coverage and effectiveness of
the system?s components.
1 Introduction
The statistical transfer machine translation group
at Carnegie Mellon University has been devel-
oping a hybrid approach combining a traditional
rule-based MT system and its linguistically ex-
pressive formalism with more modern techniques
of statistical data processing and search-based de-
coding. The Stat-XFER framework (Lavie, 2008)
provides a general environment for building new
MT systems of this kind. For a given language
pair or data condition, the framework depends on
two main resources extracted from parallel data: a
probabilistic bilingual lexicon, and a grammar of
probabilistic synchronous context-free grammar
rules. Additional monolingual data, in the form of
an n-gram language model in the target language,
is also used. The statistical transfer framework op-
erates in two stages. First, the lexicon and gram-
mar are applied to synchronously parse and trans-
late an input sentence; all reordering is applied
during this stage, driven by the syntactic grammar.
Second, a monotonic decoder runs over the lat-
tice of scored translation pieces produced during
parsing and assembles the highest-scoring overall
translation according to a log-linear feature model.
Since our submission to last year?s Workshop
on Machine Translation shared translation task
(Hanneman et al, 2008), we have made numerous
improvements and extensions to our resource ex-
traction and processing methods, resulting in sig-
nificantly improved translation scores. In Section
2 of this paper, we trace our current methods for
data resource management for the Stat-XFER sub-
mission to the 2009 WMT shared French?English
translation task. Section 3 explains our tuning pro-
cedure, and Section 4 gives our experimental re-
sults on various development sets and offers some
preliminary analysis.
2 System Construction
Because of the additional data resources provided
for the 2009 French?English task, our system this
year is trained on nearly eight times as much
data as last year?s. We used three officially pro-
vided data sets to make up a parallel corpus for
system training: version 4 of the Europarl cor-
pus (1.43 million sentence pairs), the News Com-
mentary corpus (0.06 million sentence pairs), and
the pre-release version of the new Giga-FrEn cor-
pus (8.60 million sentence pairs)1. The combined
corpus of 10.09 million sentence pairs was pre-
processed to remove blank lines, sentences of 80
words or more, and sentence pairs where the ra-
tio between the number of English and French
words was larger than 5 to 1 in either direction.
These steps removed approximately 3% of the cor-
pus. Given the filtered corpus, our data prepara-
tion pipeline proceeded according to the descrip-
tions below.
1Because of data processing time, we were unable to use
the larger verions 1 or 2 of Giga-FrEn released later in the
evaluation period.
140
2.1 Parsing and Word Alignment
We parsed both sides of our parallel corpus with
independent automatic constituency parsers. We
used the Berkeley parser (Petrov and Klein, 2007)
for both English and French, although we obtained
better results for French by tokenizing the data
with our own script as a preprocessing step and
not allowing the parser to change it. There were
approximately 220,000 English sentences that did
not return a parse, which further reduced the size
of our training corpus by 2%.
After parsing, we re-extracted the leaf nodes
of the parse trees and statistically word-aligned
the corpus using a multi-threaded implementa-
tion (Gao and Vogel, 2008) of the GIZA++ pro-
gram (Och and Ney, 2003). Unidirectional align-
ments were symmetrized with the ?grow-diag-
final? heuristic (Koehn et al, 2005).
2.2 Phrase Extraction and Combination
Phrase extraction for last year?s statistical transfer
system used automatically generated parse trees
on both sides of the corpus as absolute constraints:
a syntactic phrase pair was extracted from a given
sentence only when a contiguous sequence of En-
glish words exactly made up a syntactic con-
stituent in the English parse tree and could also
be traced though symmetric word alignments to a
constituent in the French parse tree. While this
?tree-to-tree? extraction method is precise, it suf-
fers from low recall and results in a low-coverage
syntactic phrase table. Our 2009 system uses an
extended ?tree-to-tree-string? extraction process
(Ambati and Lavie, 2008) in which, if no suit-
able equivalent is found in the French parse tree
for an English node, a copy of the English node is
projected into the French tree, where it spans the
French words aligned to the yield of the English
node. This method can result in a 50% increase
in the number of extracted syntactic phrase pairs.
Each extracted phrase pair retains a syntactic cat-
egory label; in our current system, the node label
in the English parse tree is used as the category for
both sides of the bilingual phrase pair, although we
subsequently map the full set of labels used by the
Berkeley parser down to a more general set of 19
syntactic categories.
We also ran ?standard? phrase extraction on the
same corpus using Steps 4 and 5 of the Moses sta-
tistical machine translation training script (Koehn
et al, 2007). The two types of phrases were then
merged in a syntax-prioritized combination that
removes all Moses-extracted phrase pairs that have
source sides already covered by the tree-to-tree-
string syntactic phrase extraction. The syntax pri-
oritization has the advantage of still including a se-
lection of non-syntactic phrases while producing a
much smaller phrase table than a direct combina-
tion of all phrase pairs of both types. Previous ex-
periments we conducted indicated that this comes
with only a minor drop in automatic metric scores.
In our current submission, we modify the proce-
dure slightly by removing singleton phrase pairs
from the syntactic table before the combination
with Moses phrases. The coverage of the com-
bined table is not affected ? our syntactic phrase
extraction algorithm produces a subset of the non-
syntactic phrase pairs extracted from Moses, up to
phrase length constraints ? but the removal al-
lows Moses-extracted versions of some phrases to
survive syntax prioritization. In effect, we are lim-
iting the set of category-labeled syntactic transla-
tions we trust to those that have been seen more
than once in our training data. For a given syn-
tactic phrase pair, we also remove all but the most
frequent syntactic category label for the pair; this
removes a small number of entries from our lexi-
con in order to limit label ambiguity, but does not
affect coverage.
From our training data, we extracted 27.6 mil-
lion unique syntactic phrase pairs after single-
ton removal, reducing this set to 27.0 million en-
tries after filtering for category label ambiguity.
Some 488.7 million unique phrase pairs extracted
from Moses were reduced to 424.0 million after
syntax prioritization. (The remaining 64.7 mil-
lion phrase pairs had source sides already covered
by the 27.0 million syntactically extracted phrase
pairs, so they were thrown out.) This means non-
syntactic phrases outnumber syntactic phrases by
nearly 16 to 1. However, when filtering the phrase
table to a particular development or test set, we
find the syntactic phrases play a larger role, as this
ratio drops to approximately 3 to 1.
Sample phrase pairs from our system are shown
in Figure 1. Each pair includes two rule scores,
which we calculate from the source-side syntac-
tic category (cs), source-side text (ws), target-side
category (ct), and target-side text (wt). In the
case of Moses-extracted phrase pairs, we use the
?dummy? syntactic category PHR. Rule score rt|s
is a maximum likelihood estimate of the distri-
141
cs ct ws wt rt|s rs|t
ADJ ADJ espagnols Spanish 0.8278 0.1141
N N repre?sentants officials 0.0653 0.1919
NP NP repre?sentants de la Commission Commission officials 0.0312 0.0345
PHR PHR haute importance a` very important to 0.0357 0.0008
PHR PHR est charge? de has responsibility for 0.0094 0.0760
Figure 1: Sample lexical entries, including non-syntactic phrases, with rule scores (Equations 1 and 2).
bution of target-language translations and source-
and target-language syntactic categories given the
source string (Equation 1). The rs|t score is simi-
lar, but calculated in the reverse direction to give a
source-given-target probability (Equation 2).
rt|s =
#(wt, ct, ws, cs)
#(ws) + 1
(1)
rs|t =
#(wt, ct, ws, cs)
#(wt) + 1
(2)
Add-one smoothing in the denominators counter-
acts overestimation of the rule scores of lexical en-
tries with very infrequent source or target sides.
2.3 Syntactic Grammar
Syntactic phrase extraction specifies a node-to-
node alignment across parallel parse trees. If these
aligned nodes are used as decomposition points,
a set of synchronous context-free rules that pro-
duced the trees can be collected. This is our pro-
cess of syntactic grammar extraction (Lavie et al,
2008). For our 2009 WMT submission, we ex-
tracted 11.0 million unique grammar rules, 9.1
million of which were singletons, from our paral-
lel parsed corpus. These rules operate on our syn-
tactically extracted phrase pairs, which have cat-
egory labels, but they may also be partially lexi-
calized with explicit source or target word strings.
Each extracted grammar rule is scored according
to Equations 1 and 2, where now the right-hand
sides of the rule are used as ws and wt.
As yet, we have made only minimal use of the
Stat-XFER framework?s grammar capabilities, es-
pecially for large-scale MT systems. For the cur-
rent submission, the syntactic grammar consisted
of 26 manually chosen high-frequency grammar
rules that carry out some reordering between En-
glish and French. Since rules for high-level re-
ordering (near the top of the parse tree) are un-
likely to be useful unless a large amount of parse
structure can first be built, we concentrate our
rules on low-level reorderings taking place within
or around small constituents. Our focus for this
selection is the well-known repositioning of adjec-
tives and adjective phrases when translating from
French to English, such as from le Parlement eu-
rope?en to the European Parliament or from l? in-
tervention forte et substantielle to the strong and
substantial intervention. Our grammar thus con-
sists of 23 rules for building noun phrases, two
rules for building adjective phrases, and one rule
for building verb phrases.
2.4 English Language Model
We built a suffix-array language model (Zhang and
Vogel, 2006) on approximately 700 million words
of monolingual data: the unfiltered English side of
our parallel training corpus, plus the 438 million
words of English monolingual news data provided
for the WMT 2009 shared task. With the relatively
large amount of data available, we made the some-
what unusual decision of building our language
model (and all other data resources for our system)
in mixed case, which adds approximately 12.3%
to our vocabulary size. This saves us the need to
build and run a recaser as a postprocessing step
on our output. Our mixed-case decision may also
be validated by preliminary test set results, which
show that our submission has the smallest drop in
BLEU score (0.0074) between uncased and cased
evaluation of any system in the French?English
translation task.
3 System Tuning
Stat-XFER uses a log-linear combination of seven
features in its scoring of translation fragments:
language model probability, source-given-target
and target-given-source rule probabilities, source-
given-target and target-given-source lexical prob-
abilities, a length score, and a fragmentation score
based on the number of parsed translation frag-
ments that make up the output sentence. We tune
the weights for these features with several rounds
of minimum error rate training, optimizing to-
142
Primary Contrastive
Data Set METEOR BLEU TER METEOR BLEU TER
news-dev2009a-425 0.5437 0.2299 60.45 ? ? ?
news-dev2009a-600 ? ? ? 0.5134 0.2055 63.46
news-dev2009b 0.5263 0.2073 61.96 0.5303 0.2104 61.74
nc-test2007 0.6194 0.3282 51.17 0.6195 0.3226 51.49
Figure 2: Primary and contrastive system results on tuning and development test sets.
wards the BLEU metric. For each tuning itera-
tion, we save the n-best lists output by the sys-
tem from previous iterations and concatenate them
onto the current n-best list in order to present the
optimizer with a larger variety of translation out-
puts and score values.
From the provided ?news-dev2009a? develop-
ment set we create two tuning sets: one using the
first 600 sentences of the data, and a second using
the remaining 425 sentences. We tuned our sys-
tem separately on each set, saving the additional
?news-dev2009b? set as a final development test to
choose our primary and contrastive submissions2.
At run time, our full system takes on average be-
tween four and seven seconds to translate each in-
put sentence, depending on the size of the final
bilingual lexicon.
4 Evaluation and Analysis
Figure 2 shows the results of our primary and con-
trastive systems on four data sets. First, we report
final (tuned) performance on our two tuning sets
? the last 425 sentences of news-dev2009a for the
primary system, and the first 600 sentences of the
same set for the contrastive. We also include our
development test (news-dev2009b) and, for addi-
tional comparison, the ?nc-test2007? news com-
mentary test set from the 2007 WMT shared task.
For each, we give case-insensitive scores on ver-
sion 0.6 of METEOR (Lavie and Agarwal, 2007)
with all modules enabled, version 1.04 of IBM-
style BLEU (Papineni et al, 2002), and version 5
of TER (Snover et al, 2006).
From these results, we highlight two interest-
ing areas of analysis. First, the low tuning and
development test set scores bring up questions
about system coverage, given that the news do-
main was not strongly represented in our system?s
2Due to a data processing error, the choice of the primary
submission was based on incorrectly computed scores. In
fact, the contrastive system has better performance on our de-
velopment test set.
training data. We indeed find a significantly larger
proportion of out-of-vocabulary (OOV) words in
news-domain sets: the news-dev2009b set is trans-
lated by our primary submission with 402 of 6263
word types (6.42%) or 601 of 27,821 word tokens
(2.16%) unknown. The same system running on
the 2007 WMT ?test2007? set of Europarl-derived
data records an OOV rate of only 87 of 7514
word types (1.16%) or 105 of 63,741 word tokens
(0.16%).
Second, we turn our attention to the usefulness
of the syntactic grammar. Though small, we find
it to be both beneficial and precise. In the 1026-
sentence news-dev2009b set, for example, we find
351 rule applications ? the vast majority of them
(337) building noun phrases. The three most fre-
quently occurring rules are those for reordering the
sequence [DET N ADJ] to [DET ADJ N] (52 oc-
currences), the sequence [N ADJ] to [ADJ N] (51
occurrences), and the sequence [N1 de N2] to [N2
N1] (45 occurrences). We checked precision by
manually reviewing the 52 rule applications in the
first 150 sentences of news-dev2009b. There, 41
of the occurrences (79%) were judged to be cor-
rect and beneficial to translation output. Of the
remainder, seven were judged incorrect or detri-
mental and four were judged either neutral or of
unclear benefit.
We expect to continue to analyze the output and
effectiveness of our system in the coming months.
In particular, we would like to learn more about
the usefulness of our 26-rule grammar with the
view of using significantly larger grammars in fu-
ture versions of our system.
Acknowledgments
This research was supported in part by NSF grants
IIS-0121631 (AVENUE) and IIS-0534217 (LE-
TRAS), and by the DARPA GALE program. We
thank Yahoo! for the use of theM45 research com-
puting cluster, where we ran the parsing stage of
our data processing.
143
References
Vamshi Ambati and Alon Lavie. 2008. Improving
syntax driven translation models by re-structuring
divergent and non-isomorphic parse tree structures.
In Proceedings of the Eighth Conference of the As-
sociation for Machine Translation in the Americas,
pages 235?244, Waikiki, HI, October.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, pages 49?57, Columbus, OH,
June.
Greg Hanneman, Edmund Huber, Abhaya Agarwal,
Vamshi Ambati, Alok Parlikar, Erik Peterson, and
Alon Lavie. 2008. Statistical transfer systems
for French?English and German?English machine
translation. In Proceedings of the Third Workshop
on Statistical Machine Translation, pages 163?166,
Columbus, OH, June.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh system description
for the 2005 IWSLT speech translation evaluation.
In Proceedings of IWSLT 2005, Pittsburgh, PA, Oc-
tober.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proceedings of the ACL 2007 Demo and
Poster Sessions, pages 177?180, Prague, Czech Re-
public, June.
Alon Lavie and Abhaya Agarwal. 2007. METEOR:
An automatic metric for MT evaluation with high
levels of correlation with human judgments. In Pro-
ceedings of the Second Workshop on Statistical Ma-
chine Translation, pages 228?231, Prague, Czech
Republic, June.
Alon Lavie, Alok Parlikar, and Vamshi Ambati. 2008.
Syntax-driven learning of sub-sentential translation
equivalents and translation rules from parsed parallel
corpora. In Proceedings of the Second ACL Work-
shop on Syntax and Structure in Statistical Transla-
tion, pages 87?95, Columbus, OH, June.
Alon Lavie. 2008. Stat-XFER: A general search-based
syntax-driven framework for machine translation. In
Computational Linguistics and Intelligent Text Pro-
cessing, Lecture Notes in Computer Science, pages
362?375. Springer.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic
evalution of machine translation. In Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311?318, Philadelphia,
PA, July.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of NAACL
HLT 2007, pages 404?411, Rochester, NY, April.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings of the Seventh Conference of the As-
sociation for Machine Translation in the Americas,
pages 223?231, Cambridge, MA, August.
Ying Zhang and Stephan Vogel. 2006. Suffix array
and its applications in empirical natural language
processing. Technical Report CMU-LTI-06-010,
Carnegie Mellon University, Pittsburgh, PA, Decem-
ber.
144
