Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1311?1321, Dublin, Ireland, August 23-29 2014.
Group based Self Training for E-Commerce Product Record Linkage
Wayne Xin Zhao
1,2
, Yuexin Wu
2
, Hongfei Yan
2
and Xiaoming Li
2
1
School of Information, Renmin University of China, China
2
School of Electronic Engineering and Computer Science, Peking University, China
batmanfly@gmail.com, wuyuexin@gmail.com,
yhf1029@gmail.com, lxm@pku.edu.cn
Abstract
In this paper, we study the task of product record linkage across multiple e-commerce web-
sites. We solve this task via a semi-supervised approach and adopt the self-training algorithm for
learning with little labeled data. In previous self-training algorithms, the learner tries to convert
the most confidently predicted unlabeled examples of each class into labeled training examples.
However, they evaluate the confidence of an instance only based on the individual evidence from
the instance. The correlation among data instances is rarely considered.
To address it, we develop a novel variant of the self-training algorithm by leveraging the data
characteristics for the task of product record linkage. We joint consider a candidate linked pair
and its corresponding correlated pairs as a group at the selection of pseudo labeled data. We
propose a novel confidence evaluation method for a group of instances, and incorporate it as a
re-ranking step in the self-training algorithm. We evaluate the novel self-training algorithm on
two large datasets constructed based on real e-commerce Websites. We adopt several competitive
methods as comparisons and perform extensive experiments. The results show that our method
outperforms these baselines that do not consider data correlation.
1 Introduction
Recent years have witnessed the rapid development of online e-commerce business, e.g. Amazon and
eBay, which raises the need for better storing, organizing and analyzing the large amount of product
records. An important task is how to effectively link product records across multiple databases or web-
sites. This task serves as a fundamental step for many applications. For example, it will be useful to
provide entity-oriented search and product comparison analysis in eBay, where record linkage can help
to unify the corresponding records (i.e. records from different sellers) given a product. Record linkage has
been shown to be important in many fields, including biology (Needleman and Wunsch, 1970), database
(Neiling, 2006) and text mining (Goiser and Christen, 2006; Bilenko and Mooney, 2003). In this paper,
we mainly focus on the task of product record linkage for online e-commerce websites, but our method
is easy to be extended to other data sources and tasks.
Early studies on record linkage were mainly based on the classical probabilistic approach develope-
d by Fellegi and Sunter (1969), furthermore it was improved by the application of the expectation-
maximization (EM) algorithm (Winkler, 1988) and the use of approximate string comparison algorithms
(Christen, 2006; Winkler, 2006). The early work was not flexible to incorporate rich information. The
development of machine learning techniques in the late 1990s provides a new approach for record link-
age, and it has become the mainstream methodology for this task. The task of record linkage is usually
re-casted as the record pair classification problem, i.e. whether a record pair refers to the same entity or
not (Elfeky et al., 2002; Neiling, 2006; Tejada et al., 2002; Nahm et al., 2002). Supervised methods can
also be used to learn distance measures for approximate string comparisons (Bilenko and Mooney, 2003;
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1311
Cohen et al., 2003). Although supervised techniques often achieve good linkage quality, they are largely
limited by the availability of the training data.
To address this problem, semi-supervised learning approaches aim to make good use of a small portion
of labeled and a large amount of unlabeled data to build a better classifier (Yarowsky, 1995). Self-training
is a commonly used algorithm for semi-supervised learning, where in each iteration the learner converts
the most confidently predicted unlabeled examples of each class into labeled training examples. It has
been successfully applied to many tasks, such as sentiment analysis (He and Zhou, 2011; Riloff et al.,
2003) and object detection from images (Rosenberg et al., 2005).
In this paper, we solve the task of product record linkage via a semi-supervised approach and adopt
the flexible self-training framework for learning with little labeled data. We propose a novel variant of
the self-training algorithm by incorporating the correlation existing in the data instances, which is rarely
studied in previous studies. To introduce our idea, we first present an illustrative example in Figure 1.
There are two databases D and D
?
, and we have three records r
1
, r
2
, r
3
? D and another three records
r
?
1
, r
?
2
, r
?
3
? D
?
. Furthermore, we assume r
1
and r
?
1
refer to the same product. We can see that r
1
is
involved in three candidate pairs, i.e. (r
1
, r
?
1
), (r
1
, r
?
2
) and (r
1
, r
?
3
). Similarly, r
?
1
is involved in three
candidate pairs, i.e. (r
?
1
, r
1
), (r
?
1
, r
2
) and (r
?
1
, r
3
). Usually, each individual database does not contain
duplicate records, once we know r
1
is linked to r
?
1
, we can infer the rest candidate pairs should not be
linked. In other words, only if we are confident that no pair in the set {(r
1
, r
?
2
), (r
1
, r
?
3
), (r
2
, r
?
1
), (r
3
, r
?
1
)}
is not linked, r
1
is likely to be linked with r
?
1
.
?
?
?
?
?
?
Figure 1: An illustrative example for correlation among record pairs. The real line denotes the real linkage
relation and the dash line denotes the candidate linkage relation.
For the task of record linkage, the number of positive instances (i.e. linked record pairs) are usually
much less than that of negative instances. We mainly consider the confidence evaluation of the candidate
positive instance. By following the above idea, given a candidate linked pair, we treat all the correlated
record pairs together as a group and evaluate the linkage confidence based on the evidence of all record
pairs in this group, i.e. group confidence evaluation. We incorporate the group confidence evaluation
into the self-training algorithm as a re-ranking step. Interestingly, once we have identified a linked pair,
the rest correlated record pairs can be naturally judged as negative instances. We evaluate the novel
self-training algorithm on two large datasets constructed based on real e-commerce Websites. We adopt
several competitive methods as comparisons and perform extensive experiments. The results show that
our method outperforms these baselines that do not consider data correlation.
2 Related Work
We have briefly described the supervised approaches for record linkage in the introduction. Now we
discuss other related studies, including unsupervised clustering techniques, genetic programming based
approaches and linking based on more complex constraints.
Unsupervised clustering techniques have been investigated both for improved blocking (Cohen and
Richman, 2002; McCallum et al., 2000) and for automatic record pair classification (Elfeky et al., 2002).
Usually, such techniques do not perform not as well as supervised approaches.
Most recently, genetic programming (GP) (Koza et al., 1999) has also been utilized to the task of
record linkage. GenLink (Isele and Bizer, 2012) is a GP-based supervised learning algorithm in order
to learn linkage rules from a set of existing reference links, which also suffers from the problem of
lack of labeled data. Ngomo and Lyko (2013) evaluated linear and boolean classifiers against classifiers
1312
computed by using genetic programming for the record linkage problem. Their experiments showed that
both approaches did not perform well on real data.
Some other studies exploit more complex constraints that include relationships between different entity
types to link all types of entities in coordination (Bhattacharya and Getoor, 2007; Dong et al., 2005; On
et al., 2007). The usage of such constraints can indeed help to get better linkage results, but is in many
cases domain-dependent. We try to develop an approach which can be applicable across domains.
In order to address the problem of limited labeled data, we mainly consider the semi-supervised ap-
proaches. There are rarely semi-supervised approaches specially for the record linkage problem. Some
studies on improving self-training algorithms are related to our work. Self-training with editing (Li and
Zhou, 2005) can help to reduce mislabeled pseudo training examples, and reserved self-training (Guan
and Yang, 2013) is designed for handling imbalanced data. We have very different focus with theirs, i.e.
incorporating the instance correlations into learning algorithms, which can applied to other self-training
variants.
3 Problem Definition
In this section, we first introduce the preliminary related to our task. Then we formally define our studied
task.
Product record. A product record r is characterized by a referred product entity e and a set of attribute
values V = {(v
i
)}
i
, where v
i
denotes the value of the ith attribute in r. We use r.e and r.V to index
the product entity and attribute value set of the record r respectively. A product record corresponds to a
unique product entity but a product entity can map to multiple product records across multiple databases.
Attribute values are represented as strings, i.e. a sequence of characters. An attribute of a product might
correspond to different descriptive text across websites.
Product record linkage. The task of product record linkage is to judge whether two product records refer
to the same product entity. Given two product records r and r
?
, we aim to judge whether r.e is the same
to r
?
.e. Usually, r and r
?
come from different product databases. Although different product databases
can have different attributes for the same product and different attribute names for the same attribute, we
make an assumption about the task: candidate record pairs share the same set of attributes. It is relatively
easy to automatically identify common attributes and align attributes (H?arder et al., 1999; Rundensteiner,
1999; Hassanzadeh et al., 2013), which is not our focus in this paper. We mainly study product record
linkage under the same set of attributes, and this assumption makes our study more focused. If r and r
?
refer to the same product entity, denoted by r ? r
?
; otherwise, we denote it by r 6? r
?
.
4 A General Machine Learning based Approach
Given a product type, as we mentioned above, we assume that it corresponds to a specific set of attributes,
and all the product records share the same set of attributes but possibly with different descriptive text for
attribute values. In this section, we further present a general supervised approach with similarity features.
4.1 Defining the similarity function
Given two product records r and r
?
, we can obtain the similarity between their descriptive text of an at-
tribute by using a similarity function. The major intuition is that if two records refer to the same product,
they should have similar text for the same attribute, i.e. the similarity function should return a large sim-
ilarity value. Let f(?, ?) denote a similarity function, which takes two text strings and returns a similarity
value within the interval [0, 1] for these two strings. As revealed in (Bilenko and Mooney, 2003), differ-
ent attributes or fields may need different similarity functions to achieve best similarity evaluation. Thus,
instead of fixing a single similarity function, we consider using the following widely used similarity
functions: 1) Exact match; 2) Cosine similarity; 3) Jaccard coefficient; 4) K-Gram similarity (Kondrak,
2005); 5) Levenshtein similarity (Levenshtein, 1966); 6) Affine Gap similarity (Needleman and Wunsch,
1970).
1313
4.2 The learning framework
Based on these similarity functions, we propose a general learning framework for product record linkage
by using similarity values of different fields as features.
Given a product type, we assume that there are A attributes and K similarity functions. For two records
r and r
?
, we can obtain a similarity feature vector x = [x
a,k
]
A
i=1
,
K
k=1
, which is indexed by an attribute and
a similarity function: x
a,k
denotes the similarity of the ath attribute between r and r
?
by using the kth
similarity function. Furthermore, each feature vector x will correspond to a unique binary label y which
indicates that r and r
?
refer to the same product entity. Given a set of record pairs and their linkage labels
{(x, y)}, we can learn a classifier which is able to predict the linkage label given the similarity feature
vector of two records. To this end, we have reformulated the task of product record linkage as a binary
classification problem. Any classifiers can be used for this task. In what follows, we will use instances
and candidate pairs alternatively.
5 Group based Self-Training
In the above, we have presented a supervised learning approach for product record linkage. The approach
is easy to apply in practice, however, the performance is largely limited by the availability of training
data. For our current task, i.e. product record linkage, the generation of labeled data becomes even much
harder: there are usually many product types and it is infeasible to create a large amount of labeled data
for each type. Although it is difficult to obtain labeled data, we can easily obtain sufficient unlabeled data.
Thus, in this paper, we study the task of product record linkage in a semi-supervised setting by leveraging
both the learning ability of the classifiers and the usefulness of the large amount of unlabeled data. We
propose a novel group based self-training algorithm for product record linkage. Before introducing our
method, we first introduce the general self-training algorithm.
5.1 The general self-training algorithm
Self-training is a semi-supervised learning algorithm. It starts training on labeled data only, after each
iteration, the most confidently predicted unlabeled samples would be incorporated as new labeled data,
i.e. pseudo labeled data, decided by confidence scores from the classifier. After several iterations, it is
expected to get a better classifier trained with both labeled data and pseudo labeled data. The general
procedure of self-training algorithm is summarized in Algorithm 1.
Algorithm 1: The general procedure of the self-training algorithm.
1 Input: labeled dataset L, unlabeled dataset U , the classifier C.
2 U
?
? S randomly selected examples from U , S is usually set to 0.5 ? |U|;
3 repeat
4 Training the classifier: Use L to train C, and label the examples in U
?
;
5 Selecting pseudo labeled data: Select T most confidently classified examples from U
?
and add them to L;
6 Filling unlabeled data: Refill U
?
with examples from U , to keep U
?
at a constant size of S examples.
7 until I iterations or U = ?;
8 return The extended labeled dataset L and the trained classifier C.
We can see that self-training is a wrapper algorithm by taking a classifier as the learning component,
and it has three major steps in an iteration: 1) training classifier; 2) selecting pseudo labeled data; and
3) filling unlabeled data. Among the three steps, the most important step is the pseudo labeled data
selection. Previously, the most commonly used method is to select the top confident instances of the
classifier, and it is easy to see that the performance of self-training relies on the learning ability of the
embedded classifier.
5.2 Group confidence evaluation
Recall that each instance is a pair of product records (r, r
?
) and their label indicates whether they should
be linked or not. Let P
L
(r, r
?
) denote the confidence that r and r
?
refer to the same product entity (linked
1314
confidence), and P
N
(r, r
?
) denote the confidence that r and r
?
refer to different product entities (non-
linked confidence). P
L
(r, r
?
) and P
N
(r, r
?
) can be estimated by the confidence scores from the classifier.
In the task of product record linkage, there are usually more negative instances, i.e. the number of non-
linked pairs is much more than that of linked pairs. Thus, we mainly study the confidence of a candidate
positive instance. The standard self-training algorithm selects top ranked positive instances according
to the confidence scores estimated by the classifier, i.e. we select the instances with large linked con-
fidence P
L
(?, ?). However, when applied to product record linkage, it ignores important characteristics
underlying the data, which will be potentially helpful to the task.
Let us examine the illustrative example in Figure 1. Recall that r
1
and r
?
1
refer to the same product,
i.e. r
1
? r
?
1
. We can see that r
1
is involved in three candidate pairs, i.e. (r
1
, r
?
1
), (r
1
, r
?
2
) and (r
1
, r
?
3
).
Similarly, r
?
1
is involved in three candidate pairs, i.e. (r
?
1
, r
1
), (r
?
1
, r
2
) and (r
?
1
, r
3
). We totally have a set
of five candidate pairs, i.e. {(r
1
, r
?
1
), (r
1
, r
?
2
), (r
1
, r
?
3
), (r
2
, r
?
1
), (r
3
, r
?
1
)}. Here we follow the assumption
of the one-to-one mapping, i.e. given two databases, a product record can link to at most one record in
the other database. By leveraging the correlation among candidate pairs, with r
1
? r
?
1
, we can infer the
rest four candidate pairs must not be linked, i.e. r
1
6? r
?
2
, r
1
6? r
?
3
, r
2
6? r
?
1
, r
3
6? r
?
1
. Next, we formally
characterize the above idea and present the algorithm. Given two databases D and D
?
, let C ? D ? D
?
denote the candidate pair set where two product records in a pair come from D and D
?
respectively.
Consider a candidate pair (r, r
?
) ? C, where r ? D, r
?
? D
?
. We consider the following two sets:
S
r
= {(r, b)|(r, b) ? C, b ? D
?
and b 6= r
?
} and S
r
?
= {(a, r
?
)|(a, r
?
) ? C, a ? D and a 6= r}.
Intuitively, if we know r ? r
?
, then all the pairs in both S
r
and S
r
?
must not be linked. Thus, we define
the conflicting set of pair (r, r
?
) as S
r,r
?
cfl
= S
r
? S
r
?
.
With the definition of the conflicting set, let us reconsider the pseudo labeled data selection. The
straightforward way is to evaluate each instance with their linked confidence P
L
() from the classifier.
However, it oversimplifies the data dependence and does not make use of the correlated characteristics.
Consider an instance, which is a record pair (r, r
?
), we can have the following two properties:
? If r ? r
?
, then ?(a, b) ? S
r,r
?
cfl
, we have a 6? b;
? If ?(a, b) ? S
r,r
?
cfl
and a ? b, then we have r 6? r
?
.
The above properties suggest that it should be helpful to consider the correlation among instances
when evaluating the confidence of a positive instance, i.e. a candidate linked record pair. Intuitively, if
two records refer to the same product entity, they should have large linked confidence and their conflicting
pairs should have large non-linked confidence. We propose to use the following method to evaluate the
linkage confidence between r and r
?
Conf(r, r
?
) = P
L
(r, r
?
)
(
?
(a,b)?S
r,r
?
cfl
P
N
(a, b)
)
1/M
, (1)
where M = |S
r,r
?
cfl
|, P
L
(?, ?) and P
N
(?, ?) are positive and negative confidence scores estimated by
the classifier respectively. Note that we take the geometric mean of the non-linked confidence of these
conflicting pairs, which is to reduce the affect of large outlier values and the varying size of the conflict
sets. We treat a candidate linked pair and all the candidate pairs in its conflicting set as a group. The group
confidence evaluation consists of two intuitions: 1) the confidence that two records should be linked; 2)
the confidence that any pair of records in the conflicting set must not be linked. We have taken these two
aspects into a unified evaluation score.
5.3 The proposed self-training algorithm
In this part, we present the novel self-training algorithm based on the group confidence evaluation. We
have the similar steps with the general self-training algorithm in Algorithm 1. The major focus is to mod-
ify the step of pseudo labeled data selection. As mentioned above, we mainly consider the confidence
evaluation of positive instances. Our method for pseudo labeled data selection is three-step process:
1315
? Select top T
?
most confidently classified positive examples by the classifier;
? Rerank these T
?
examples by the group confidence scores defined in Equation 1;
? Select top T examples from the reranked T
?
examples (T ? T
?
) as pseudo positive instances and
their corresponding conflicting instances in the conflicting sets as pseudo negative instances.
We select positive instances not only based on the instance itself but also their corresponding conflict-
ing instances: if we have high confidence about a positive instance, then the confidence of their conflict-
ing instances being negative should be high, too. Next, we present the detailed group based self-training
algorithm in Algorithm 2.
Algorithm 2: The procedure of the group based self-training algorithm.
1 Input: labeled dataset L, unlabeled dataset U , the classifier C.
2 U
?
? S randomly selected examples from U ;
3 repeat
4 Training the classifier: Use L to train C, and label the examples in U
?
;
5 Selecting pseudo labeled data selection:
? Select T
?
most confident positive examples from U
?
and add them to L;
? Calculate the group confidence scores for the T
?
examples according to Equation 1.
? Rerank these T
?
examples by their group confidence scores and add top T examples to L as the pseudo positive
instances.
? For each of the T examples, add their conflicting instances to L into as the pseudo negative instances.
Filling unlabeled data: Refill U
?
with examples from U , to keep U
?
at a constant size of S examples.
6 until I iterations or U = ?;
7 return The extended labeled dataset L and the trained classifier C.
On one hand, our group based self-training algorithm naturally exploits the correlation among data
instances and evaluate the confidence scores in a broader view, which avoids the decision conflicts caused
by the data dependence. On the other hand, we focus on evaluating the confidence of being a positive
instance, which further reduces the bias from imbalanced data distribution. Thus, it is expected to achieve
better performance in the task of product record linkage.
Most classifiers can provide the estimated confidence scores P
L
() (i.e. for a positive instance) and
P
N
() (i.e. for a negative instance): Maximum-Entropy models output the conditional probabilities of an
instance for each class (Berger et al., 1996); the Decision Tree C4.5 algorithm is also able to compute
the probability distribution over different classes for each instance (Quinlan, 1993).
6 Experiments
6.1 Construction of the test collection
We test our method on two real e-commerce datasets respectively from Jingdong
1
and eTao
2
. Jingdong is
the largest B2C e-commerce company and eTao is one of the largest product search portals in China. Due
to the extremely large product databases, it is infeasible to generate training data on each product type
for these two product databases. We consider two popular kinds of products: laptop and camera. These
two kinds of products cover a considerable amount of brands and models, especially suitable for the test
of record linkage. Both Jindong and eTao have set up specific categories for these two kinds of products
respectively, thus we can easily crawl the product records under the corresponding category label. To
generate linked record datasets, we first manually align attributes (i.e. fields) for these two kinds between
Jindong and eTao. We summarize the numbers of aligned fields and some example fields in Table 1. Not
all the records contain the information for all the fields, we set the value of the empty field to a ?NULL?
string.
1
http://www.jd.com
2
http://www.etao.com
1316
We adopt a blocking approach (Baxter et al., 2003) to automatically generate a set of candidate pairs,
i.e. a record in Jindong is to be linked with a record in eTao. This approach consider all pairwise links
between Jindong records and eTao records for the same kind of product. If there exists at least one com-
mon word in the field of brand or model between a record pair, we consider it to be a candidate pair. The
automatic method generates 20,094 candidate pairs and 12,157 candidate pairs respectively for LAPTOP
and CAMERA. Then we invite professional workers from an e-commerce company to link records across
these two product databases. Instead of examining all the candidate pairs, the labeling process adopts a
product-oriented way to generate the gold standard. Given a product record of a database, the annotator
first identifies the product entity that the record refers to, then she looks for the corresponding record in
another database. In the annotation process, Web access is available all the time. Annotators can make
use of the search engines of Jindong and eTao to accelerate the product lookup. A linked record pair is
treated as a positive instance. Finally, we identify 501 linkable products (i.e. 501 positive instances) in
LAPTOP dataset, and 478 linkable products (i.e. 478 positive instances) in CAMERA dataset. All the
other candidate pairs are automatically labeled as negative. We present the the data statistics in Table 1.
Dataset
# positive # negative
# fields Example fields
instances instances
LAPTOP 501 19593 10 OS, screen size, CPU type, ram size
CAMERA 478 11679 11 lens type, sensor type, focal length, aperture size
Table 1: Basic statistics of datasets.
6.2 Experimental setup
For each kind of product, we divide the dataset into two parts, i.e. a training set and a test set. In order
to examine different methods in a semi-supervised setting, we keep a small amount of instances in the
training set, and we assume all the methods can use of the data (without labels) in the test set. There are
more negative instances, we mainly consider the amount of positive instances, and the number of positive
instances is called as the number of seeds. We randomly generate the training set with the given number
of seeds. Once we add one positive instance into the training set, we add all the its conflicting instances
into the training set. This is to reduce the correlation between training instances and testing instances for
a fair comparison. In later experiments, given the seed number, we will generate ten random training sets
and take the average of ten runs as the final performance. In later experiments, we do not explicitly report
the number of negative instances unless needed.
We adopt three widely used evaluation metrics for the classification task: Precision, Recall and the
F-measure
3
.
We compare the following methods for the task of product record linkage:
? Supervised Classifier (SC): the standard supervised classifier, which does not consider the unlabeled
data at all.
? Traditional Self-Training (t-ST): the traditional self-training method in Algorithm 1 which adds an
equal amount of samples of each class in pseudo labeled selection at each iteration.
? Proportional Self-Training (p-ST): the traditional self-training method in Algorithm 1 but add sam-
ples according to the class distribution at each iteration.
? Simple Group Based Self-Training (s-ST): a simplified version of our approach without the group
confidence valuation, which directly selects samples of high confidence scores estimated from the
classifier together with their conflicting pairs as negative samples at each iteration.
? Group Based Self-Training (g-ST): the proposed group based self-training algorithm in Algorithm 2,
which uses the group confidence evaluation method to select pseudo positive instances.
3
http:/en.wikipedia.org/wiki/Precision and recall
1317
Recall all the methods rely on the wrapped classifier. We select two classic but very different classi-
fiers: the Maximum Entropy model (MaxEnt) and the Decision Tree C4.5 (Tree). We implement these
two classifiers using the machine learning toolkit Weka
4
. We use the six similarity functions to obtain
similarity values between two records on each field as features. All the self-training based methods run
ten iterations and at each iteration they add the same number of positive instances, i.e. 30. Differen-
t methods select pseudo negative instances differently. t-ST does not consider the correlation between
data instances, and it adds top 30 confident negative instances. p-ST adds top 30 ?
#negative instances
#positive instances
con-
fident negative instances. Both p-ST and g-ST take all the conflicting instances of the selected pseudo
positive instances as the negative instances. We present the average numbers of pseudo negative instances
at an iteration in Table 2. As will be revealed later, although p-ST adds more negative instances, g-ST
performs much better than p-ST, which indicates simply adding more negative instances might not lead
to better performance. We do not perform specific preprocessing steps to make the data balanced (e.g.
under-sampling or over-sampling), and we find the data distribution does not significantly affect the
performance of the classifiers on our dataset.
Dataset t-ST p-ST s-ST g-ST
LAPTOP 30 950 845 854
CAMERA 30 655 569 584
Table 2: Average numbers of pseudo negative instances selected at each iteration.
6.3 Results and analysis
Overall performance comparison. To test the performance under weak supervision, we first set the
seed number to 30, which nearly takes up a proportion of 5% of the labeled data. We present the results
of different methods in Table 3 and Table 4. We first examine the performance of the baselines. We can
see that semi-supervised learning is very effective to improve over the the supervised classifier when the
amount of training data is small. It is interesting to see that s-ST performs best among all the baselines.
Recall that the major difference between s-ST and other baselines is that it select the conflicting pairs
of the pseudo positive instances as the negative instances. It indicates that it is important to consider the
correlation among the data instances. In addition, Decision Tree seems to be more competitive than Max-
imum Entropy Model for product record linkage. Then we take our group based self-training algorithm
into comparison. In terms of F1 measure, we can see that it is consistently better than all the baselines
on two datasets respectively by using two different classifiers. It is worth looking into the performance
comparison on precision and recall. We can see that (1) s-ST and g-ST yield better results in terms of
precision while the other baselines yield better results in terms of recall; (2) our method g-ST largely
improves over the best baseline s-ST. It is not surprising to have these observations since that our group
evaluation method is more careful at the selection of pseudo positive instance: it considers the evidence
from the conflicting instances.
Methods MaxEnt Decision Tree
P R F1 P R F1
SC 0.246 0.910 0.382 0.301 0.931 0.454
t-ST 0.264 0.925 0.411 0.328 0.921 0.484
p-ST 0.350 0.831 0.487 0.412 0.887 0.539
s-ST 0.979 0.632 0.767 0.909 0.754 0.823
g-ST 0.936 0.742 0.826 0.912 0.843 0.876
Table 3: Results on LAPTOP dataset.
Parameter tuning. In the above, we have shown the results of different methods with 30 positive in-
stances. The number of seeds is particularly important for self-training algorithms, and we want to ex-
4
http://www.cs.waikato.ac.nz/ml/weka
1318
Methods MaxEnt Decision Tree
P R F1 P R F1
SC 0.387 0.891 0.540 0.493 0.965 0.652
t-ST 0.352 0.892 0.504 0.537 0.963 0.677
p-ST 0.501 0.871 0.626 0.573 0.942 0.700
s-ST 0.931 0.479 0.632 0.962 0.570 0.716
g-ST 0.917 0.574 0.706 0.965 0.588 0.731
Table 4: Results on CAMERA dataset.
amine how it affects the performance of these methods. By varying the number of seeds from 10 to 50
with a step of 10, we present the F1 results in Figure 2 on two datasets by using two classifiers. We can
see that our method is consistently better than baselines with the varying of the seed number. Especially,
our method still works well when there is little labeled data, i.e. #seeds = 10. With a weaker classifier,
i.e. MaxEnt, our method yields more improvement than that with Tree. Besides the seed number, there
are another two factors which potentially affect the performance: (1) the iteration number and (2) the
number of pseudo positive instances selected at each iteration. We also examine the tuning results of
these two parameters and find our method is consistently better than s-ST with the varying of these two
factors. These results show that our method is very effective and it is of high stability and practicability.
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 10  15  20  25  30  35  40  45  50
F1
# of Labeled Seeds
SC
t-ST
p-ST
s-ST
g-ST
(a) LAPTOP, MaxEnt
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 10  15  20  25  30  35  40  45  50
F1
# of Labeled Seeds
SC
t-ST
p-ST
s-ST
g-ST
(b) LAPTOP, Tree
 0.4
 0.45
 0.5
 0.55
 0.6
 0.65
 0.7
 0.75
 0.8
 10  15  20  25  30  35  40  45  50
F1
# of Labeled Seeds
SC
t-ST
p-ST
s-ST
g-ST
(c) CAMERA, MaxEnt
 0.35
 0.4
 0.45
 0.5
 0.55
 0.6
 0.65
 0.7
 0.75
 0.8
 0.85
 10  15  20  25  30  35  40  45  50
F1
# of Labeled Seeds
SC
t-ST
p-ST
s-ST
g-ST
(d) CAMERA, Tree
Figure 2: Performance comparison with varying seed numbers (i.e. # of positive instances).
1319
7 Conclusion
In this paper, we develop a novel variant of the self-training algorithm by leveraging the data characteris-
tic for the task of product record linkage. We joint consider a candidate linked pair and its corresponding
correlated pairs as a group, at the selection of pseudo labeled data. We propose a confidence evaluation
method for a group of instances, and incorporate it as a re-ranking step in the self-training algorithm. We
evaluate the novel self-training algorithm on two large datasets constructed based on real e-commerce
Websites. We adopt several competitive methods as comparisons and perform extensive experiments.
The results show that our method outperforms these baselines that do not consider data correlation. We
also carefully examine the affects of various parameters, and the tuning results indicate the stability and
robustness of our method.
The major contribution and novelty of this paper is the novel group confidence evaluation to model
the correlation existing in data. Although we develop the idea in the setting of self-training algorithms,
it will be promising to be applied in other learning algorithms, i.e. active learning.
Acknowledgements
We thank the anonymous reviewers for his/her thorough review and highly appreciate the comments.
This work was partially supported by the National Key Basic Research Program (973 Program) of China
under grant No. 2014CB340403, 2014CB340405 and NSFC Grant 61272340. Xin Zhao was supported
by MSRA PhD fellowship. Xin Zhao and Yuexin Wu contributed equally to this work and should be
considered as joint first authors. Xin Zhao is the corresponding author.
References
Rohan Baxter, Peter Christen, and Tim Churches. 2003. A comparison of fast blocking methods for record linkage.
In ACM SIGKDD, volume 3, pages 25?27. Citeseer.
Adam L Berger, Vincent J Della Pietra, and Stephen A Della Pietra. 1996. A maximum entropy approach to
natural language processing. Computational linguistics, 22(1):39?71.
Indrajit Bhattacharya and Lise Getoor. 2007. Collective entity resolution in relational data. ACM Transactions on
Knowledge Discovery from Data (TKDD), 1(1):5.
Mikhail Bilenko and Raymond J Mooney. 2003. Adaptive duplicate detection using learnable string similarity
measures. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and
data mining, pages 39?48. ACM.
Peter Christen. 2006. A comparison of personal name matching: Techniques and practical issues. In Data Mining
Workshops, 2006. ICDM Workshops 2006. Sixth IEEE International Conference on, pages 290?294. IEEE.
William W Cohen and Jacob Richman. 2002. Learning to match and cluster large high-dimensional data sets for
data integration. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery
and data mining, pages 475?480. ACM.
William W Cohen, Pradeep D Ravikumar, Stephen E Fienberg, et al. 2003. A comparison of string distance
metrics for name-matching tasks. In IIWeb, volume 2003, pages 73?78.
Xin Dong, Alon Halevy, and Jayant Madhavan. 2005. Reference reconciliation in complex information spaces. In
Proceedings of the 2005 ACM SIGMOD international conference on Management of data, pages 85?96. ACM.
Mohamed G Elfeky, Vassilios S Verykios, and Ahmed K Elmagarmid. 2002. Tailor: A record linkage toolbox. In
Data Engineering, 2002. Proceedings. 18th International Conference on, pages 17?28. IEEE.
Ivan P Fellegi and Alan B Sunter. 1969. A theory for record linkage. Journal of the American Statistical Associa-
tion, 64(328):1183?1210.
Karl Goiser and Peter Christen. 2006. Towards automated record linkage. In Proceedings of the fifth Australasian
conference on Data mining and analystics-Volume 61, pages 23?31. Australian Computer Society, Inc.
Zhiguang Liu Xishuang Dong Yi Guan and Jinfeng Yang. 2013. Reserved self-training: A semi-supervised senti-
ment classification method for chinese microblogs.
1320
Theo H?arder, G?unter Sauter, and Joachim Thomas. 1999. The intrinsic problems of structural heterogeneity and
an approach to their solution. The VLDB Journal, 8(1):25?43.
Oktie Hassanzadeh, Ken Q Pu, Soheil Hassas Yeganeh, Ren?ee J Miller, Lucian Popa, Mauricio A Hern?andez,
and Howard Ho. 2013. Discovering linkage points over web data. Proceedings of the VLDB Endowment,
6(6):445?456.
Yulan He and Deyu Zhou. 2011. Self-training from labeled features for sentiment analysis. Information Process-
ing & Management, 47(4):606?616.
Robert Isele and Christian Bizer. 2012. Learning expressive linkage rules using genetic programming. Proceed-
ings of the VLDB Endowment, 5(11):1638?1649.
Grzegorz Kondrak. 2005. N-gram similarity and distance. In String Processing and Information Retrieval, pages
115?126. Springer.
John R Koza, Forrest H Bennett III, and Oscar Stiffelman. 1999. Genetic programming as a Darwinian invention
machine. Springer.
Vladimir I Levenshtein. 1966. Binary codes capable of correcting deletions, insertions and reversals. In Soviet
physics doklady, volume 10, page 707.
Ming Li and Zhi-Hua Zhou. 2005. Setred: Self-training with editing. In Advances in Knowledge Discovery and
Data Mining, pages 611?621. Springer.
Andrew McCallum, Kamal Nigam, and Lyle H Ungar. 2000. Efficient clustering of high-dimensional data sets
with application to reference matching. In Proceedings of the sixth ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 169?178. ACM.
Un Yong Nahm, Mikhail Bilenko, and Raymond J Mooney. 2002. Two approaches to handling noisy variation in
text mining. In Proceedings of the ICML-2002 workshop on text learning (TextML2002), pages 18?27. Citeseer.
Saul B Needleman and Christian D Wunsch. 1970. A general method applicable to the search for similarities in
the amino acid sequence of two proteins. Journal of molecular biology, 48(3):443?453.
Mattis Neiling. 2006. Identification of real-world objects in multiple databases. In From Data and Information
Analysis to Knowledge Engineering, pages 63?74. Springer.
Axel-Cyrille Ngonga Ngomo and Klaus Lyko. 2013. Unsupervised learning of link specifications: Deterministic
vs. non-deterministic. Ontology Matching, page 25.
Byung-Won On, Nick Koudas, Dongwon Lee, and Divesh Srivastava. 2007. Group linkage. In Data Engineering,
2007. ICDE 2007. IEEE 23rd International Conference on, pages 496?505. IEEE.
John Ross Quinlan. 1993. C4. 5: programs for machine learning, volume 1. Morgan kaufmann.
Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003. Learning subjective nouns using extraction pattern boot-
strapping. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume
4, pages 25?32. Association for Computational Linguistics.
Chuck Rosenberg, Martial Hebert, and Henry Schneiderman. 2005. Semi-supervised self-training of object detec-
tion models.
Elke Rundensteiner. 1999. Special issue on data transformation. IEEE Techn. Bull. Data Engineering, 22(1).
Sheila Tejada, Craig A Knoblock, and Steven Minton. 2002. Learning domain-independent string transformation
weights for high accuracy object identification. In Proceedings of the eighth ACM SIGKDD international
conference on Knowledge discovery and data mining, pages 350?359. ACM.
William E Winkler. 1988. Using the em algorithm for weight computation in the fellegi-sunter model of record
linkage. In Proceedings of the Section on Survey Research Methods, American Statistical Association, volume
667, page 671.
William E Winkler. 2006. Overview of record linkage and current research directions. In Bureau of the Census.
Citeseer.
David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of
the 33rd annual meeting on Association for Computational Linguistics, pages 189?196. Association for Com-
putational Linguistics.
1321
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 800?809, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
SSHLDA: A Semi-Supervised Hierarchical Topic Model
Xian-Ling Mao??, Zhao-Yan Ming?, Tat-Seng Chua?, Si Li?, Hongfei Yan??, Xiaoming Li?
?Department of Computer Science and Technology, Peking University, China
?School of Computing, National University of Singapore, Singapore
?School of ICE, Beijing University of Posts and Telecommunications, China
{xianlingmao,lxm}@pku.edu.cn, yhf@net.pku.edu.cn
{chuats,mingzhaoyan}@nus.edu.sg, lisi@bupt.edu.cn
Abstract
Supervised hierarchical topic modeling and
unsupervised hierarchical topic modeling are
usually used to obtain hierarchical topics, such
as hLLDA and hLDA. Supervised hierarchi-
cal topic modeling makes heavy use of the in-
formation from observed hierarchical labels,
but cannot explore new topics; while unsu-
pervised hierarchical topic modeling is able
to detect automatically new topics in the data
space, but does not make use of any informa-
tion from hierarchical labels. In this paper, we
propose a semi-supervised hierarchical topic
model which aims to explore new topics auto-
matically in the data space while incorporating
the information from observed hierarchical la-
bels into the modeling process, called Semi-
Supervised Hierarchical Latent Dirichlet Al-
location (SSHLDA). We also prove that hLDA
and hLLDA are special cases of SSHLDA.We
conduct experiments on Yahoo! Answers and
ODP datasets, and assess the performance in
terms of perplexity and clustering. The ex-
perimental results show that predictive ability
of SSHLDA is better than that of baselines,
and SSHLDA can also achieve significant im-
provement over baselines for clustering on the
FScore measure.
1 Introduction
Topic models, such as latent Dirichlet alation
(LDA), are useful NLP tools for the statistical anal-
ysis of document collections and other discrete data.
?This work was done in National University of Singapore.
?Corresponding author.
Furthermore, hierarchical topic modeling is able to
obtain the relations between topics ? parent-child
and sibling relations. Unsupervised hierarchical
topic modeling is able to detect automatically new
topics in the data space, such as hierarchical La-
tent Dirichlet Allocation (hLDA) (Blei et al2004).
hLDAmakes use of nested Dirichlet Process to auto-
matically obtain a L-level hierarchy of topics. Mod-
ern Web documents, however, are not merely col-
lections of words. They are usually documents with
hierarchical labels ? such as Web pages and their
placement in hierarchical directories (Ming et al
2010). Unsupervised hierarchical topic modeling
cannot make use of any information from hierarchi-
cal labels, thus supervised hierarchical topic models,
such as hierarchical Labeled Latent Dirichlet Allo-
cation (hLLDA) (Petinot et al2011), are proposed
to tackle this problem. hLLDA uses hierarchical la-
bels to automatically build corresponding topic for
each label, but it cannot find new latent topics in the
data space, only depending on hierarchy of labels.
As we know that only about 10% of an iceberg?s
mass is seen outside while about 90% of it is unseen,
deep down in water. We think that a corpus with hi-
erarchical labels should include not only observed
topics of labels, but also there are more latent top-
ics, just like icebergs. hLLDA can make use of the
information from labels; while hLDA can explore
latent topics. How can we combine the merits of the
two types of models into one model?
An intuitive and simple combinational method is
like this: first, we use hierarchy of labels as basic hi-
erarchy, called Base Tree (BT); then we use hLDA
to build automatically topic hierarchy for each leaf
800
node in BT, called Leaf Topic Hierarchy (LTH); fi-
nally, we add each LTH to corresponding leaf in the
BT and obtain a hierarchy for the entire dataset. We
refer the method as Simp-hLDA. The performance
of the Simp-hLDA is not so good, as can be seen
from the example in Figure 3 (b). The drawbacks
are: (i) the leaves in BT do not obtain reasonable
and right words distribution, such as ?Computers &
Internet? node in Figure 3 (b), its topical words, ?the
to you and a?, is not about ?Computers & Internet?;
(ii) the non-leaf nodes in BT cannot obtain words
distribution, such as ?Health? node in Figure 3 (b);
(iii) it is a heuristic method, and thus Simp-hLDA
has no solid theoretical basis.
To tackle the above drawbacks, we explore the
use of probabilistic models for such a task where
the hierarchical labels are merely viewed as a part
of a hierarchy of topics, and the topics of a path in
the whole hierarchy generate a corresponding doc-
ument. Our proposed generative model learns both
the latent topics of the underlying data and the la-
beling strategies in a joint model, by leveraging on
the hierarchical structure of labels and Hierarchical
Dirichlet Process.
We demonstrate the effectiveness of the proposed
model on large, real-world datasets in the question
answering and website category domains on two
tasks: the topic modeling of documents, and the use
of the generated topics for document clustering. Our
results show that our joint, semi-hierarchical model
outperforms the state-of-the-art supervised and un-
supervised hierarchical algorithms. The contribu-
tions of this paper are threefold: (1) We propose a
joint, generative semi-supervised hierarchical topic
model, i.e. Semi-Supervised Hierarchical Latent
Dirichlet Allocation (SSHLDA), to overcome the
defects of hLDA and hLLDA while combining the
their merits. SSHLDA is able to not only explore
new latent topics in the data space, but also makes
use of the information from the hierarchy of ob-
served labels; (2) We prove that hLDA and hLLDA
are special cases of SSHLDA; (3) We develop a
gibbs sampling inference algorithm for the proposed
model.
The remainder of this paper is organized as fol-
lows. We review related work in Section 2. In Sec-
tion 3, we introduce some preliminaries; while we
introduce SSHLDA in Section 4. Section 5 details
a gibbs sampling inference algorithm for SSHLDA;
while Section 6 presents the experimental results.
Finally, we conclude the paper and suggest direc-
tions for future research in Section 7.
2 Related Work
There have been many variations of topic mod-
els. The existing topic models can be divided
into four categories: Unsupervised non-hierarchical
topic models, Unsupervised hierarchical topic mod-
els, and their corresponding supervised counter-
parts.
Unsupervised non-hierarchical topic models are
widely studied, such as LSA (Deerwester et al
1990), pLSA (Hofmann, 1999), LDA (Blei et al
2003), Hierarchical-concept TM (Chemudugunta et
al., 2008c; Chemudugunta et al2008b), Corre-
lated TM (Blei and Lafferty, 2006) and Concept TM
(Chemudugunta et al2008a; Chemudugunta et al
2008b) etc. The most famous one is Latent Dirichlet
Allocation (LDA). LDA is similar to pLSA, except
that in LDA the topic distribution is assumed to have
a Dirichlet prior. LDA is a completely unsupervised
algorithm that models each document as a mixture
of topics. Another famous model that not only rep-
resents topic correlations, but also learns them, is
the Correlated Topic Model (CTM). Topics in CTM
are not independent; however it is noted that only
pairwise correlations are modeled, and the number
of parameters in the covariance matrix grows as the
square of the number of topics.
However, the above models cannot capture the
relation between super and sub topics. To address
this problem, many models have been proposed
to model the relations, such as Hierarchical LDA
(HLDA) (Blei et al2004), Hierarchical Dirichlet
processes (HDP) (Teh et al2006), Pachinko Allo-
cation Model (PAM) (Li and McCallum, 2006) and
Hierarchical PAM (HPAM) (Mimno et al2007)
etc. The relations are usually in the form of a hi-
erarchy, such as the tree or Directed Acyclic Graph
(DAG). Blei et al2004) proposed the hLDA model
that simultaneously learns the structure of a topic
hierarchy and the topics that are contained within
that hierarchy. This algorithm can be used to extract
topic hierarchies from large document collections.
Although unsupervised topic models are suffi-
801
ciently expressive to model multiple topics per doc-
ument, they are inappropriate for labeled corpora be-
cause they are unable to incorporate the observed la-
bels into their learning procedure. Several modifica-
tions of LDA to incorporate supervision have been
proposed in the literature. Two such models, Su-
pervised LDA (Blei and McAuliffe, 2007; Blei and
McAuliffe, 2010) and DiscLDA (Lacoste-Julien et
al., 2008) are first proposed to model documents as-
sociated only with a single label. Another category
of models, such as the MM-LDA (Ramage et al
2009b), Author TM (Rosen-Zvi et al2004), Flat-
LDA (Rubin et al2011), Prior-LDA (Rubin et al
2011), Dependency-LDA (Rubin et al2011) and
Partially LDA (PLDA) (Ramage et al2011) etc.,
are not constrained to one label per document be-
cause they model each document as a bag of words
with a bag of labels. However, these models obtain
topics that do not correspond directly with the la-
bels. Labeled LDA (LLDA) (Ramage et al2009a)
can be used to solve this problem.
None of these non-hierarchical supervised mod-
els, however, leverage on dependency structure,
such as parent-child relation, in the label space. For
hierarchical labeled data, there are also few models
that are able to handle the label relations in data.
To the best of our knowledge, only hLLDA (Petinot
et al2011) and HSLDA (Perotte et al2011) are
proposed for this kind of data. HSLDA cannot ob-
tain a probability distribution for a label. Although
hLLDA can obtain a distribution over words for each
label, hLLDA is unable to capture the relations be-
tween parent and child node using parameters, and it
also cannot detect automatically latent topics in the
data space. In this paper, we will propose a genera-
tive topic model to tackle these problems of hLLDA.
3 Preliminaries
The nested Chinese restaurant process (nCRP) is a
distribution over hierarchical partitions (Blei et al
2004). It generalizes the Chinese restaurant process
(CRP), which is a distribution over partitions. The
CRP can be described by the following metaphor.
Imagine a restaurant with an infinite number of ta-
bles, and imagine customers entering the restaurant
in sequence. The dth customer sits at a table accord-
Table 1: Notations used in the paper.
Sym Description
V Vocabulary (word set), w is a word in V
D Document collection
Tj
The set of paths in the sub-tree whose root is the
jth leaf node in the hierarchy of observed topics
m A document m that consists of words and labels
wm The text of document m, wi is ith words in w
cm The topic set of document m
com The set of topics with observed labels for document m
cem The set of topics without labels for document m
ce?m The set of latent topics for all documents other than m
zem
The assignment of the words in the mth document
to one of the latent topics
wem
The set of the words belonging to one of the latent
topics in the the mth document
zm,n
The assignment of the nth word in the mth document
to one of the L available topics
z The set of zm,n for all words in all documents
ci A topic in the ith level in the hierarchy
? The word distribution set for Z, i.e., {?}z?c
? Dirichlet prior of ?
?ci The multinomial distribution over the sub-topics of ci?1
?ci Dirichlet prior of ?ci
? Dirichlet prior of ?
? The multinomial distribution of words
?m The distributions over topics for document m
? The set for ?m, m ? {1, ..., D}
ing to the following distribution,
p(cd = k|c1:(d?1)) ?
{ mk if k is previous occupied
? if k is a new tabel, (1)
where mk is the number of previous customers sit-
ting at table k and ? is a positive scalar. AfterD cus-
tomers have sat down, their seating plan describes a
partition of D items.
In the nested CRP, imagine now that tables are or-
ganized in a hierarchy: there is one table at the first
level; it is associated with an infinite number of ta-
bles at the second level; each second-level table is
associated with an infinite number of tables at the
third level; and so on until the Lth level. Each cus-
tomer enters at the first level and comes out at the
Lth level, generating a path with L tables as she sits
in each restaurant. Moving from a table at level l to
one of its subtables at level l+1, the customer draws
following the CRP using Formula (1). In this paper,
we will make use of nested CRP to explore latent
topics in data space.
To elaborate our model, we first define two con-
cepts. If a model can learn a distribution over words
for a label, we refer the topic with a corresponding
label as a labeled topic. If a model can learn an un-
seen and latent topic without a label, we refer the
802
Figure 1: The graphical model of SSHLDA.
topic as a latent topic.
4 The Semi-Supervised Hierarchical Topic
Model
In this section, we will introduce a semi-
supervised hierarchical topic model, i.e., the Semi-
Supervised Hierarchical Latent Dirichlet Allocation
(SSHLDA). SSHLDA is a probabilistic graphical
model that describes a process for generating a hi-
erarchical labeled document collection. Like hi-
erarchical Labeled LDA (hLLDA) (Petinot et al
2011), SSHLDA can incorporate labeled topics into
the generative process of documents. On the other
hand, like hierarchical Latent Dirichlet Allocation
(hLDA) (Blei et al2004), SSHLDA can automat-
ically explore latent topic in data space, and extend
the existing hierarchy of observed topics. SSHLDA
makes use of not only observed topics, but also la-
tent topics.
The graphical model of SSHLDA is illustrated in
Figure 1. In the model, N is the number of words in
a document, D is the total number of documents in
a collection, M is the number of leaf nodes in hier-
archical observed nodes, ci is a node in the ith level
in the hierarchical tree, ?, ? and ?ci are dirichlet
prior parameters, ?k is a distribution over words, ?
is a document-specific distribution over topics, ?ci is
a multinomial distribution over observed sub-topics
of topic ci, w is an observed word, z is the topic
assigned to w, Dirk(.) is a k-dimensional Dirichlet
distribution, Tj is a set of paths in the hierarchy of
latent topics for jth leaf node in the hierarchy of ob-
Figure 2: One illustration of SSHLDA. The tree has 5
levels. The shaded nodes are observed topics, and circled
nodes are latent topics. The latent topics are generated
automatically by SSHLDA model. After learning, each
node in this tree will obtain a corresponding probability
distribution over words, i.e. a topic.
served topics, ? is a Multi-nomial distribution over
paths in the tree. All notations used in this paper are
listed in Table 1.
SSHLDA, as shown in Figure 1, assumes the fol-
lowing generative process:
(1) For each table k ? T in the infinite tree,
(a) Draw a topic ?k ? Dir(?).
(2) For each document, m ? {1, 2, ..., D}
(a) Let c1 be the root node.
(b) For each level l ? {2, ..., L}:
(i) If nodes in this level have been observed,
draw a node cl from Mult(?cl?1 |?cl?1).
(ii) Otherwise, draw a table cl from restaurant
cl?1 using Formula (1).
(c) Draw an L-dimensional topic proportion vec-
tor ?m from Dir(?).
(d) For each word n ? {1, ..., N}:
(i) Draw z ? {1, ..., L} from Mult(?).
(ii) Draw wn from the topic associated with
restaurant cz .
As the example showed in Figure 2, we assume
that we have known a hierarchy of observed top-
ics: {A1,A2,A17,A3,A4}, and assume the height
of the desired topical tree is L = 5. All circled
nodes are latent topics, and shaded nodes are ob-
served topics. A possible generative process for a
document m can be: It starts from A1, and chooses
node A17 at level 2, and then chooses A18, A20 and
A25 in the following levels. Thus we obtain a path:
cm = {A1, A17, A18, A20, A25}. After getting the
path for m, SSHLDA generates each word from one
of topics in this set of topics cm.
803
5 Probabilistic Inference
In this section, we describe a Gibbs sampling al-
gorithm for sampling from the posterior and corre-
sponding topics in the SSHLDA model. The Gibbs
sampler provides a method for simultaneously ex-
ploring the model parameter space (the latent topics
of the whole corpus) and the model structure space
(L-level trees).
In SSHLDA, we sample the paths cm for docu-
ment m and the per-word level allocations to topics
in those paths zm,n. Thus, we approximate the pos-
terior p(cm, zm|?, ?,w,?). The hyper-parameter ?
reflects the tendency of the customers in each restau-
rant to share tables, ? denotes the expected variance
of the underlying topics (e.g., ?  1 will tend to
choose topics with fewer high-probability words),
?ci is the dirichlet prior of ?ci , and ? is the set of
?ci . wm,n denotes the nth word in the mth docu-
ment; and cm,l represents the restaurant correspond-
ing to the lth-level topic in document m; and zm,n,
the assignment of the nth word in the mth document
to one of the L available topics. All other variables
in the model, ? and ?, are integrated out. The Gibbs
sampler thus assesses the values of zm,n and cm,l.
The Gibbs sampler can be divided into two main
steps: the sampling of level allocations and the sam-
pling of path assignments.
First, given the values of the SSHLDA hidden
variables, we sample the cm,l variables which are as-
sociated with the CRP prior. Noting that cm is com-
posed of com and cem , com is the set of observed
topics for document m, and cem is the set of latent
topics for document m. The conditional distribution
for cm, the L topics associated with documentm, is:
p(cm|z,w, c?m,?)
=p(com |?)p(cem |zem ,wem , ce?m)
?p(com |?)p(wem |cem ,we?m , zem)
p(cem |ce?m) (2)
where
p(com |?) =
|com |?1
?
i=0
p(ci,m|?ci) (3)
and
p(wem |cem ,we?m , zem)
=
|cem |
?
l=1
(
?(n.cem,l,?m + |V |?)
?
w ?(nwcem,l,?m + ?)
?
?
w ?(nwcem,l,?m + n
w
cem,l,m + ?)
?(n.cem,l,?m + n
?
cem,l,m + |V |?)
)
(4)
ce?m is the set of latent topics for all documents
other than m, zem is the assignment of the words
in the mth document to one of the latent topics, and
wem is the set of the words belonging to one of the
latent topics in the the mth document. nwcem,l,?m is
the number of instances of word w that have been
assigned to the topic indexed by cem,l, not including
those in the document m.
Second, given the current state of the SSHLDA,
we sample the zm,n variables of the underlying
SSHLDA model as follows:
p(zm,n = j|z?(m,n),w, cm,?)
?
nm?n,j + ?
nm?n,. + |cm|
?
nwm,n?n,j + ?wm,n
n.?(m,n) + |V |
(5)
Having obtained the full conditional distribution,
the Gibbs sampling algorithm is then straightfor-
ward. The zm,n variables are initialized to determine
the initial state of the Markov chain. The chain is
then run for a number of iterations, each time find-
ing a new state by sampling each zm,n from the dis-
tribution specified by Equation (5). After obtain-
ing individual word assignments z, we can estimate
the topic multinomials and the per-document mixing
proportions. Specifically, the topic multinomials are
estimated as:
?cm,j,i = p(wi|zcm,j) =
? + nzwicm,j
|V |? +
?
n.zcm,j
(6)
while the per-document mixing proportions fixed
can be estimated as:
?m,j =
?+ nm.,j
|cm|?+ nm.,.
, j ? 1, ..., |cm| (7)
5.1 Relation to Existing Models
In this section, we draw comparisons with the cur-
rent state-of-the-art models for hierarchical topic
804
modeling (Blei et al2004; Petinot et al2011) and
show that at certain choices of the parameters of our
model, these methods fall out as special cases.
Our method generalises not only hierarchi-
cal Latent Dirichlet Allocation (hLDA), but also
Hierarchical Labeled Latent Dirichlet Allocation
(hLLDA). Our proposed model provides a unified
framework allowing us to model hierarchical labels
while to explore new latent topics.
Equivalence to hLDA As introduced in Section 2,
hLDA is a unsupervised hierarchical topic model. In
this case, there are no observed nodes, that is, the
corpus has no hierarchical labels. This means cm is
equal to cem,m; meanwhile the factor p(com,m|?) is
always equal to one because each document has root
node, and this allows us to rewrite Formula (2) as:
p(cm|z,w, c?m,?)
?p(wcm |c,w?m, z)p(cm|c?m) (8)
which is exactly the same as the conditional distribu-
tion for cm, the L topics associated with document
m in hLDA model. In this case, our model becomes
equivalent to the hLDA model.
Equivalence to hLLDA hLLDA is a supervised hi-
erarchical topic model, which means all nodes in hi-
erarchy are observed. In this case, cm is equal to
com,m, and this allows us to rewrite Formula (2) as:
p(cm|z,w, c?m,?) = p(cm|?) ? p(com |?) (9)
which is exactly the same as the step ? Draw a
random path assignment cm? in the generative pro-
cess for hLLDA. Consequentially, in this sense our
model is equivalent to hLLDA.
6 Experiments
We demonstrate the effectiveness of the proposed
model on large, real-world datasets in the question
answering and website category domains on two
tasks: the topic modeling of documents, and the use
of the generated topics for document clustering.
6.1 Datasets
To construct comprehensive datasets for our ex-
periments, we crawled data from two websites.
First, we crawled nearly all the questions and as-
sociated answer pairs (QA pairs) of two top cat-
Table 2: The statistics of the datasets.
Datasets #labels #paths Max level #docs
Y Ans 46 35 4 6,345,786
O Hlth 6695 6505 10 54939
O Home 2432 2364 9 24254
egories of Yahoo! Answers: Computers & Inter-
net and Health. This produced forty-three sub-
categories from 2005.11 to 2008.11, and an archive
of 6,345,786 QA documents. We refer the Yahoo!
Answer data as Y Ans.
In addition, we first crawled two categories of
Open Directory Project (ODP)?: Home and Health.
Then, we removed all categories whose number of
Web sites is less than 3. Finally, for each of Web
sites in categories, we submited the url of each Web
site to Google and used the words in the snippet and
title of the first returned result to extend the sum-
mary of the Web site. We denote the data from the
category Home as O Home, and the data from the
category Health as O Hlth.
The statistics of all datasets are summarized in Ta-
ble 2. From this table, we can see that these datasets
are very diverse: Y Ans has much fewer labels than
O Hlth and O Home, but have much more docu-
ments for each label; meanwhile the depth of hierar-
chical tree for O Hlth and O Home can reach level
9 or above.
All experiments are based on the results of models
with a burn-in of 10000 Gibbs sampling iterations,
symmetric priors ? = 0.1 and free parameter ? = 1.0;
and for ?, we can obtain the estimation of ?ci by
fixed-point iteration (Minka, 2003).
6.2 Case Study
With topic modeling, the top associated words of
topics can be used as good descriptors for topics in
a hierarchy (Blei et al2003; Blei and McAuliffe,
2010). We show in Figure 3 a pair of compara-
tive example of the proposed model and a baseline
model over Y Ans dataset. The tree-based topic vi-
sualizations of Figure 3 (a) and (b) are the results of
SSHLDA and Simp-hLDA.
We have three major observations from the exam-
ple: (i) SSHLDA is a unified and generative model,
after learning, it can obtain a hierarchy of topics;
?http://dmoz.org/
805
Figure 3: (a) A sub network discovered on Y Ans dataset using SSHLDA, and the whole tree has 74 nodes; (b) A sub
network discovered on Y Ans dataset using Simp-hLDA algorithm, and the whole tree has 89 nodes. In both figures,
the shaded and squared nodes are observed labels, not topics; the shaded and round nodes are topics with observed
labels; blue nodes are topics but without labels and the yellow node is one of leaves in hierarchy of labels. Each topic
represented by top 5 terms.
while Simp-hLDA is a heuristic method, and its re-
sult is a mixture of label nodes and topical nodes.
For example, Figure 3 (b) shows that the hierarchy
includes label nodes and topic nodes, and each of la-
beled nodes just has a label, but label nodes in Fig-
ure 3 (a) have their corresponding topics. (ii) Dur-
ing obtaining a hierarchy, SSHLDAmakes use of the
information from observed labels, thus it can gener-
ate a logical, structual hierarchy with parent-child
relations; while Simp-hLDA does not incorporate
prior information of labels into its generation pro-
cess, thus although it can obtain a hierarchy, many
parent-child pairs have not parent-child relation. For
example, in Figure 3 (b), although label ?root? is
a parent of label ?Computers & Internet?, the topi-
cal words of label ?Computers & Internet? show the
topical node is not a child of label ?root?. How-
ever, in Figure 3 (a), label ?root? and ?Computers
& Internet? has corresponding parent-child relation
between their topical words. (iii) In a hierarchy of
topics, if a topical node has correspending label, the
label can help people understand descendant topi-
cal nodes. For example, when we know node ?er-
ror files click screen virus? in Figure 3 (a) has its
label ?Computers & Internet?, we can understand
the child topic ?hard screen usb power dell? is about
?computer hardware?. However, in Figure 3 (b), the
labels in parent nodes cannot provide much informa-
tion to understand descendant topical nodes because
many label nodes have not corresponding right topi-
cal words, such as label ?Computers & Internet?, its
topical words, ?the to you and a?, do not reflect the
connotation of the label.
These observations further confirm that SSHLDA
is better than the baseline model.
6.3 Perplexity Comparison
A good topic model should be able to generalize to
unseen data. To measure the prediction ability of
our model and baselines, we compute the perplex-
ity for each document d in the test sets. Perplex-
ity, which is widely used in the language modeling
and topic modeling community, is equivalent alge-
braically to the inverse of the geometric mean per-
word likelihood (Blei et al2003). Lower perplexity
scores mean better. Our model, SSHLDA, will com-
pare with three state-of-the-art models, i.e. Simp-
hLDA, hLDA and hLLDA. Simp-hLDA has been
introduced in Section 1, and hLDA and hLLDA has
been reviewed in Section 2. We keep 80% of the data
collection as the training set and use the remaining
collection as the held-out test set. We build the mod-
806
els based on the train set and compute the preplexity
of the test set to evaluate the models. Thus, our goal
is to achieve lower perplexity score on a held-out test
set. The perplexity of M test documents is calculated
as:
perplexity(Dtest) = exp
{
?
?M
d=1
?Nd
m=1 log p(wdm)
?M
d=1 Nd
}
(10)
where Dtest is the test collection of M documents,
Nd is document length of document d and wdm is
mth word in document d.
We present the results over the O Hlth dataset in
Figure 4. We choose top 3-level labels as observed,
and assume other labels are not observed, i.e. l = 3.
From the figure, we can see that the perplexities of
SSHLDA, are lower than that of Simp-hLDA, hLDA
and hLLDA at different value of the tree height pa-
rameter, i.e. L ? {5, 6, 7, 8}. It shows that the
performance of SSHLDA is always better than the
state-of-the-art baselines, and means that our pro-
posed model can model the hierarchical labeled data
better than the state-of-the-art models. We can also
obtain similar experimental results over Y Ans and
O Home datasets, and their detailed description is
not included in this paper due to the limitation of
space.
6.4 Clustering performance
To evaluate indirectly the performance of the pro-
posed model, we compare the clustering perfor-
mance of following systems: 1) the proposed model;
2) Simp-hLDA; 3) hLDA; 4) agglomerative cluster-
ing algorithm. There are many agglomerative clus-
tering algorithms, and in this paper, we make use
of the single-linkage method in a software package
called CLUTO (Karypis, 2005) to obtain hierarchies
of clusters over our datasets, with words as features.
We refer the method as h-clustering.
Given a document collectionDSwith aH-level hi-
erarchy of labels, each label in the hierarchy and cor-
responding documents will be taken as the ground
truth of clustering algorithms. The hierarchy of la-
bels denoted as GT-tree. The process of evaluation
is as follows. First, we choose top l-level labels
in GT-tree as an observed hierarchy, i.e. Base Tree
(BT), and we need to construct a L-level hierarchy
(l < L <= H) over the documents DS using a
Figure 4: Perplexities of hLLDA, hLDA, Simp-hLDA
and SSHLDA. The results are run over the O Hlth
dataset, with the height of the hierarchy of observed la-
bels l = 3. The X-axis is the height of the whole topical
tree (L), and Y-axis is the perplexity.
model. The remaining labels in GT-tree and cor-
responding documents are the ground truth classes,
each class denoted as Ci. Then, (i) for h-clustering,
we run single-linkage method over the documents
DS. (ii) for Simp-hLDA, hLDA runs on the doc-
uments in each leaf-node in BT, and the height pa-
rameter is (L ? l) for each hLDA. After training,
each document is assigned to top-1 topic accord-
ing to the distribution over topics for the document.
Each topic and corresponding documents forms a
new cluster. (iii) for hLDA, hLDA runs on all docu-
ments in DS, and the height parameter is L. Similar
to Simp-hLDA, each document is assigned to top-
1 topic. Each topic and corresponding documents
forms a new cluster. (iv) for SSHLDA, we set height
parameter as L. After training, each document is
also assigned to top-1 topic. Topics and their cor-
responding documents form a hierarchy of clusters.
6.4.1 Evaluation Metrics
For each dataset we obtain corresponding clusters
using the various models described in previous sec-
tions. Thus we can use clustering metrics to measure
the quality of various algorithms by using a measure
that takes into account the overall set of clusters that
are represented in the new generated part of a hier-
archical tree.
One such measure is the FScore measure, intro-
807
duced by (Manning et al2008). Given a particular
class Cr of size nr and a particular cluster Si of size
ni, suppose nri documents in the cluster Si belong
to Cr, then the FScore of this class and cluster is
defined to be
F (Cr, Si) =
2?R(Cr, Si)? P (Cr, Si)
R(Cr, Si) + P (Cr, Si)
(11)
where R(Cr, Si) is the recall value defined as
nri/nr, and P (Cr, Si) is the precision value defined
as nri/ni for the classCr and the cluster Si. The FS-
core of the class Cr, is the maximum FScore value
attained at any node in the hierarchical clustering
tree T . That is,
F (Cr) = max
Si?T
F (Cr, Si). (12)
The FScore of the entire clustering solution is then
defined to be the sum of the individual class FScore
weighted according to the class size.
FScore =
c
?
r=1
nr
n
F (Cr), (13)
where c is the total number of classes. In general, the
higher the FScore values, the better the clustering
solution is.
6.4.2 Experimental Results
Each of hLDA, Simp-hLDA and SSHLDA needs
a parameter?the height of the topical tree, i.e. L;
and for Simp-hLDA and SSHLDA, they need an-
other parameter?the height of the hierarchical ob-
served labels, i.e l. The h-clustering does not have
any height parameters, thus its FScore will keep the
same values at different height of the topical tree.
With choosing the height of hierarchical labels for
O Home as 4, i.e. l = 4, the results of our model
and baselines with respect to the height of a hierar-
chy are shown in Figure 5.
From the figure, we can see that our proposed
model can achieve consistent improvement over
the baseline models at different height, i.e. L ?
{5, 6, 7, 8}. For example, the performance of
SSHLDA can reach 0.396 at height 5 while the h-
clustering, hLDA and hLLDA only achieve 0.295,
0.328 and 0.349 at the same height. The result shows
that our model can achieve about 34.2%, 20.7% and
13.5% improvements over h-clustering, hLDA and
Figure 5: FScore measures of h-clustering, hLDA,
Simp-hLDA and SSHLDA. The results are run over the
O Home dataset, with the height of the hierarchy of ob-
served labels l = 3. The X-axis is the height of the whole
topical tree (L), and Y-axis is the FScore measure.
hLLDA at height 5. The improvements are signifi-
cant by t-test at the 95% significance level. We can
also obtain similar experimental results over Y Ans
and O Hlth. However, for the same reason of limita-
tion of space, their detailed descriptions are skipped
in this paper.
7 Conclusion and Future work
In this paper, we have proposed a semi-supervised
hierarchical topic models, i.e. SSHLDA, which aims
to solve the drawbacks of hLDA and hLLDA while
combine their merits. Specially, SSHLDA incorpo-
rates the information of labels into generative pro-
cess of topic modeling while exploring latent topics
in data space. In addition, we have also proved that
hLDA and hLLDA are special cases of SSHLDA.
We have conducted experiments on the Yahoo! An-
swers and ODP datasets, and assessed the perfor-
mance in terms of Perplexity and FScore measure.
The experimental results show that the prediction
ability of SSHLDA is the best, and SSHLDA can
also achieve significant improvement over the base-
lines on Fscore measure.
In the future, we will continue to explore novel
topic models for hierarchical labeled data to further
improve the effectiveness; meanwhile we will also
apply SSHLDA to other media forms, such as im-
age, to solve related problems in these areas.
808
Acknowledgments
This work was partially supported by NSFC with Grant
No.61073082, 60933004, 70903008 and NExT Search
Centre, which is supported by the Singapore National Re-
search Foundation & Interactive Digital Media R&D Pro-
gram Office, MDA under research grant (WBS:R-252-
300-001-490).
References
D. Blei and J. Lafferty. 2006. Correlated topic mod-
els. Advances in neural information processing sys-
tems, 18:147.
D.M. Blei and J.D. McAuliffe. 2007. Supervised topic
models. In Proceeding of the Neural Information Pro-
cessing Systems(nips).
D.M. Blei and J.D. McAuliffe. 2010. Supervised topic
models. Arxiv preprint arXiv:1003.0783.
D.M. Blei, A.Y. Ng, and M.I. Jordan. 2003. Latent
dirichlet alation. The Journal of Machine Learning
Research, 3:993?1022.
D. Blei, T.L. Griffiths, M.I. Jordan, and J.B. Tenenbaum.
2004. Hierarchical topic models and the nested chi-
nese restaurant process. Advances in neural informa-
tion processing systems, 16:106.
C. Chemudugunta, A. Holloway, P. Smyth, and
M. Steyvers. 2008a. Modeling documents by com-
bining semantic concepts with unsupervised statistical
learning. The Semantic Web-ISWC 2008, pages 229?
244.
C. Chemudugunta, P. Smyth, and M. Steyvers. 2008b.
Combining concept hierarchies and statistical topic
models. In Proceeding of the 17th ACM conference on
Information and knowledge management, pages 1469?
1470. ACM.
C. Chemudugunta, P. Smyth, and M. Steyvers. 2008c.
Text modeling using unsupervised topic models and
concept hierarchies. Arxiv preprint arXiv:0808.0973.
S. Deerwester, S.T. Dumais, G.W. Furnas, T.K. Landauer,
and R. Harshman. 1990. Indexing by latent semantic
analysis. Journal of the American society for informa-
tion science, 41(6):391?407.
T. Hofmann. 1999. Probabilistic latent semantic analy-
sis. In Proc. of Uncertainty in Artificial Intelligence,
UAI?99, page 21. Citeseer.
G. Karypis. 2005. Cluto: Software for
clustering high dimensional datasets. In-
ternet Website (last accessed, June 2008),
http://glaros.dtc.umn.edu/gkhome/cluto/cluto/overview.
S. Lacoste-Julien, F. Sha, and M.I. Jordan. 2008. ndis-
clda: Discriminative learning for dimensionality re-
duction and classification. Advances in Neural Infor-
mation Processing Systems, 21.
W. Li and A. McCallum. 2006. Pachinko allocation:
Dag-structured mixture models of topic correlations.
In Proceedings of the 23rd international conference on
Machine learning, pages 577?584. ACM.
C.D. Manning, P. Raghavan, and H. Schutze. 2008. In-
troduction to information retrieval, volume 1. Cam-
bridge University Press Cambridge.
D. Mimno, W. Li, and A. McCallum. 2007. Mixtures of
hierarchical topics with pachinko allocation. In Pro-
ceedings of the 24th international conference on Ma-
chine learning, pages 633?640. ACM.
Z.Y. Ming, K. Wang, and T.S. Chua. 2010. Prototype
hierarchy based clustering for the categorization and
navigation of web collections. In Proceeding of the
33rd international ACM SIGIR, pages 2?9. ACM.
T.P. Minka. 2003. Estimating a dirichlet distribution.
Annals of Physics, 2000(8):1?13.
A. Perotte, N. Bartlett, N. Elhadad, and F. Wood. 2011.
Hierarchically supervised latent dirichlet alation.
Neural Information Processing Systems (to appear).
Y. Petinot, K. McKeown, and K. Thadani. 2011. A
hierarchical model of web summaries. In Proceed-
ings of the 49th Annual Meeting of the ACL: Human
Language Technologies: short papers-Volume 2, pages
670?675. ACL.
D. Ramage, D. Hall, R. Nallapati, and C.D. Manning.
2009a. Labeled lda: A supervised topic model for
credit attribution in multi-labeled corpora. In Proceed-
ings of the 2009 Conference on Empirical Methods in
Natural Language Processing: Volume 1-Volume 1,
pages 248?256. Association for Computational Lin-
guistics.
D. Ramage, P. Heymann, C.D. Manning, and H. Garcia-
Molina. 2009b. Clustering the tagged web. In Pro-
ceedings of the Second ACM International Conference
on Web Search and Data Mining, pages 54?63. ACM.
D. Ramage, C.D. Manning, and S. Dumais. 2011. Par-
tially labeled topic models for interpretable text min-
ing. In Proceedings of the 17th ACM SIGKDD inter-
national conference on Knowledge discovery and data
mining, pages 457?465. ACM.
M. Rosen-Zvi, T. Griffiths, M. Steyvers, and P. Smyth.
2004. The author-topic model for authors and doc-
uments. In Proceedings of the 20th conference on
Uncertainty in artificial intelligence, pages 487?494.
AUAI Press.
T.N. Rubin, A. Chambers, P. Smyth, and M. Steyvers.
2011. Statistical topic models for multi-label docu-
ment classification. Arxiv preprint arXiv:1107.2462.
Y.W. Teh, M.I. Jordan, M.J. Beal, and D.M. Blei. 2006.
Hierarchical dirichlet processes. Journal of the Amer-
ican Statistical Association, 101(476):1566?1581.
809
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1466?1477, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
Identifying Event-related Bursts via Social Media Activities
Wayne Xin Zhao?, Baihan Shu?, Jing Jiang?, Yang Song?, Hongfei Yan?? and Xiaoming Li?
?School of Electronics Engineering and Computer Science, Peking University
?School of Information Systems, Singapore Management University
{batmanfly,baihan.shu,yhf1029}@gmail.com,ysong@pku.edu.cn
jingjiang@smu.edu.sg, lxm@pku.edu.cn
Abstract
Activities on social media increase at a dra-
matic rate. When an external event happens,
there is a surge in the degree of activities re-
lated to the event. These activities may be
temporally correlated with one another, but
they may also capture different aspects of an
event and therefore exhibit different bursty
patterns. In this paper, we propose to iden-
tify event-related bursts via social media activ-
ities. We study how to correlate multiple types
of activities to derive a global bursty pattern.
To model smoothness of one state sequence,
we propose a novel function which can cap-
ture the state context. The experiments on a
large Twitter dataset shows our methods are
very effective.
1 Introduction
Online social networks (e.g., Twitter, Facebook,
Myspace) significantly influence the way we live.
Activities on social media increase at a dramatic
rate. Millions of users engage in a diverse range
of routine activities on social media such as posting
blog messages, images, videos or status messages,
as well as interacting with items generated by oth-
ers such as forwarding messages. When an event
interesting to a certain group of individuals takes
place, there is usually a surge in the degree of ac-
tivities related to the event (e.g., a sudden explosion
of tweets). Since social media activities may indi-
cate the happenings of external events, can we lever-
age on the rich social media activities to help iden-
tify meaningful external events? This is the research
problem we study in this paper. By external events,
we refer to real-world events that happen external to
the online space.
?Corresponding author.
2 4 6 8 100
2040
6080
100120
140
Time index 
 all?tweetsretweetsurl?embeddedtweetsNoise
(a) Query=?Amazon.?
2 4 6 8 100
50
100
150
Time index 
 all?tweetsretweetsurl?embeddedtweetsNoise
(b) Query=?Eclipse?.
Figure 1: The amount of activities within a 10-hour
window for two queries. Three types of activities
are considered: (1) posting a tweet (upward triangle),
(2) retweet (downward triangle), (3) posting a URL-
embedded tweet (excluding retweet) (filled circle). As
explained in Table 1, both bursts above are noisy.
Mining events from text streams is usually
achieved by detecting bursty patterns (Swan and Al-
lan, 2000; Kleinberg, 2003; Fung et al 2005). How-
ever, previous work has mostly focused on tradi-
tional text streams such as scientific publications and
news articles. There is still a lack of systematic in-
vestigations into the problem of identifying event-
related bursty patterns via social media activities.
There are at least two basic characteristics of social
media that make the problem more interesting and
challenging.
First, social media involve various types of activ-
ities taking place in real time. These activities may
be temporally correlated with one another, but they
may also capture different aspects of an event and
therefore exhibit different bursty patterns. Most of
previous methods (Swan and Allan, 2000; Klein-
berg, 2003; Fung et al 2005) deal with a single type
of textual activities. When applied to social media,
they oversimplify the complex nature of online so-
1466
Bursty Activity Time # in Sr # in Su # in St Noisy?
Sr,St 23:00?23:59, Nov. 23, 2009 108 5 147 Y
See Fig. 1(b) [Query=eclipse] major bursty reason: The tweet from Robert Pattinson ?@twilight: from rob cont .
- i hope you are looking forward to eclipse as much as i am .? has been retweeted many times.
Su,St 07:00?07:59, Jul. 25, 2009 6 122 133 Y
See Fig. 1(a) [Query=Amazon] major bursty reason: Advertisement tweets like ?@fitnessjunkies amazon.com deals
: http://tinyurl.com/lakz3h.? have been posted many times.
St,Su,Sr 09:00?9:59, Oct. 9, 2009 1562 423 2848 N
[Query=Nobel] major bursty reason: The news ?Obama won Nobel Peace Prize? flood Twitter.
Table 1: Examples of bursts. The first two bursts are judged as noise since they do not correspond to any meaningful
external events. In fact, the reasons why a burst appears in social media can be quite diverse. In this paper, we only
focus on event-related bursts. St denotes posting a tweet, Su denotes posting a url-embedded tweet, and Sr denotes
retweet.
cial activities, and therefore they may not be well
suitable to social media. Let us consider a moti-
vating example. Figure 1 shows the change of the
amount of activities of three different types over a
10-hour time window for two queries. If we consider
only the total number of tweets, we can see that for
both queries there is a burst. However, neither of the
two bursts corresponds to a real-world event. The
first burst was caused by the broadcast of an adver-
tisement from several Twitter bots, and the second
burst was caused by numerous retweets of a status
update of a movie star1. The detailed explanations
of why the two bursts are noisy are also shown in
Table 1. On the other hand, interestingly, we can see
that not all the activity streams display noisy bursty
patterns at the same time. It indicates that we may
make use of multiple views of different activities
to detect event-related bursts. The intuition is that
using multiple types of activities may help learn a
better global picture of event-related bursty patterns.
Learning may also be more resistant to noisy bursts.
Second, in social media, burst detection is chal-
lenged by irregular, unpredictable and spurious
noisy bursts. To overcome this challenge, a reason-
able assumption is that a burst corresponding to a
real event should not fluctuate too much within a
relatively short time window. To illustrate it, we
present an example in Figure 2, in which we first
use a simple threshold method to detect bursts and
then analyze the effect of local smoothness. In par-
ticular, if the amount of activities at a certain time
is above a pre-defined threshold, we set its state to
1, which indicates a bursty state. Otherwise, we set
the state to 0. Figure 2(a) shows that for the query
?Eclipse,? with a threshold of 50, the state sequence
for the time window we consider is ?0000100000.?
1The reasons for these bursts were revealed by manually
checking the tweets during the corresponding periods.
1 2 3 4 5 6 7 8 9 100
50
100
150 Correct0000000000Threshold0000100000
(a) Query=?Eclipse?.
1 2 3 4 5 6 7 8 9 100
5001000
15002000
25003000 Correct0000011111Threshold0000011111
(b) Query=?Nobel?.
Figure 2: Analysis of the effect of local smoothness on
threshold method. It shows two examples of threshold
methods for burst detection in a 10-hour window. The
red line denotes the bursty threshold. If the number of
activities is above the threshold in one time interval, the
state of this time interval is judge as bursty. Detailed de-
scriptions of these cases are shown in Table 1.
Although there is a burst in this sequence, its dura-
tion is very short. In fact, this is the first example
shown in Table 1, which is a noisy burst. In con-
trast, in Figure 2(b), the state sequence for the query
?Nobel? is ?0000011111,? in which the longer and
smoother burst corresponds to a true event. A good
function for evaluating the smoothness of a state se-
quence should be able to discriminate these cases
and model the context of state sequences effectively.
With its unique characteristics and challenges,
there is an emergent need to deeply study the prob-
lem of event-related burst detection via social me-
dia activities. In this paper, we conduct a system-
atic investigation on this problem. We formulate
this problem as burst detection from time series of
social media activities. We develop an optimiza-
tion model to learn bursty patterns based on multiple
types of activities. We propose to detect bursts by
considering both local state smoothness and correla-
tion across multiple streams. We define a function to
1467
quantitatively measure local smoothness of one sin-
gle state sequence. We systematically evaluate three
types of activities for burst detection on a large Twit-
ter dataset and analyze different properties of these
three streams for burst detection.
2 Problem Definition
Before formally introducing our problems, we first
define some basic concepts.
Activity: An activity refers to some type of action
that users perform when they are interested in some
topic or event.
Activity Stream: An activity stream of length
N and type m is a sequence of numbers
(nm1 , n
m
2 , ..., n
m
N ), where each n
m
i denotes the
amount of activities of type m that occur during the
ith time interval.
Query: A queryQ is a sequence of terms q1, ..., q|Q|
which can represent the information needs of users.
For example, an example query related to President
Obama is ?barack obama.?
Event-related Burst: Given a query Q, an event-
related burst is defined as a period [ts, te] in which
some event related with Q takes place, where ts and
te are the start timestamp and end timestamp of the
event period respectively. During the event period
the amount of activities is significantly higher than
average.
Based on these definitions, our task is to try to
identify event-related bursts via multiple social me-
dia activity streams.
3 Identifying Event-related Bursts from
Social Media
In this section, we discuss how to identify event-
related bursts via social media activities. For-
mally, given a query Q, we first build M ac-
tivity streams related with Q on T timestamps:
{(nm1 , ..., n
m
T )}
M
m=1. The definition of activity in our
methods is very general; it includes various types of
social media activities, including textual and non-
textual activities, e.g., a click on a shared photo and
a link formation between two users.
Given the input, we try to infer a state sequence
over these T timestamps: z = (z1, ..., zT ), where
zi is 1 or 0. 1 indicates a time point within a burst
while 0 indicates a non-bursty time point.
3.1 Modeling a Single Activity Stream
3.1.1 Generation function
In probability theory and statistics, the Poisson
distribution2 is a discrete probability distribution
that can measure the probability of a given number
of ?activities? occurring in a fixed time interval. We
use the Poisson distribution to study the probability
of observing the number of social media activities,
and we treat one hour as one time interval in this
paper.
Homogeneous Poisson Distribution The genera-
tive probability of the ith number in one activity
stream of type m is defined as f(nmi , i, z
m
i ) =
(?zmi
)n
m
i exp(??zmi
)
nmi !
, where ?0 is the (normal) expec-
tation of the number of activities in one time inter-
val. If one state is bursty, it would emit activities
with a faster rate and result in a larger expectation
?1. We can set ?1 = ?0 ? ?, where ? > 1.
Heterogeneous Poisson Distribution The two-state
machine in (Kleinberg, 2003) used two global refer-
ences for all the time intervals: one for bursty and
the other for non-bursty. In our experiments, we ob-
serve temporal patterns of user behaviors, i.e., activ-
ities in some hours are significantly more than those
in the others. Instead of using fixed global rates ?0
and ?1, we try to model temporal patterns of user
behaviors by parameterizing ?(?) with the time in-
dex. By following (Ihler et al 2006), we use a
set of hour-specific rates {?1,h}24h=1 and {?0,h}
24
h=1.
3
Given a time index h, we set ?0,h to be the expecta-
tion of the number of activities in hth time interval
every day, then we have ?1,h = ?0,h ? ?. In this
paper, ? is empirally set as 1.5.
3.1.2 Smoothness of a State Sequence
For burst detection, the major aim is to identify
steady and meaningful bursts and to discard tran-
sient and spurious bursts. Given a state sequence
z1z2...zT , to quantitatively measure the smoothness
and compactness of it, we introduce some measures.
One simple method is to count the number of
change in the state sequence. Formally, we use the
following formula:
g1(z) = T ?
T?1?
i=1
I(zi 6= zi+1), (1)
2http://en.wikipedia.org/wiki/Poisson distribution
3We can also make the rates both day-specific and hour-
specific, i.e., {?(?),d,h}h?{1,...,24},d?{1,...,7}.
1468
where T is length of the state sequence and I(?)
is an indicator function which returns 1 only if the
statement is true. Let us take the state sequence
?0000100000? (shown in Figure 2(a)) as an example
to see how g1 works. State changes 0pos=4 ? 1pos=5
and 1pos=5 ? 0pos=6 each incur a cost of 1, there-
fore g1(0000100000) = 10 ? 2 = 8. Similarly, we
can get g1(0000000000) = 10. There is a cost dif-
ference between these two sequences, i.e., ?g1 = 2.
Kleinberg (2003) uses state transition probabilities
to model the smoothness of state sequences. With
simple derivations, we can show that Kleinberg?s
model essentially also uses a cost function that is
linear in terms of the number of state changes in a
sequence, and therefore similar to g1.
In social media, very short noisy bursts like
?0000100000? are very frequent. To discard such
noises, we may multiply g1 by a big cost factor to
punish short-term fluctuations. However, it is not
sensitive to the state context4 and may affect the
detection of meaningful bursts. For example, state
change 0pos=4 ? 1pos=5 in ?0000111100? would
receive the same cost as that of 0pos=4 ? 1pos=5
in ?0000100000? although the later is more like a
noise.
To better measure the smoothness of a state se-
quence , we propose a novel context-sensitive func-
tion, which sums the square of the length of the max-
imum subsequences in which all states are the same.
Formally, we have
g2(z1, z2, ..., zT ) =
?
si<ei
(ei ? si + 1)
2, (2)
where si and ei are the start index and end in-
dex of the ith subsequence respectively. To define
?maximum?, we have the constraints zsi = zsi+1 =
... = zei , zsi?1 6= zsi , zei 6= zei+1. For example,
g2(0000000000)= 102 = 100, g2(0000100000)=
42 + 12 + 52 = 42, we can see that ?g2 =
100 ? 42 = 58, which is significantly larger than
?g1(= 2). g2 rewards the continunity of state se-
quences while punish the fluctuating changes, and it
is context-sensitive. State change 0pos=4 ? 1pos=5
in ?0000111100? receives a cost of 4,5 which is
4Here context refers to the window of hidden state se-
quences.
5Indeed, g2 is not designed for a single state change but for
the overall smoothness patterns, so we choose a referring se-
quence generated by making the corresponding state negative to
compute the cost, i.e., |g2(0000011110)?g2(0000001110)| =
4.
much smaller than that of 0pos=4 ? 1pos=5 in
?0000100000?. g2 is also sensitive to the po-
sition of state changes, e.g., g2(0000100000) 6=
g2(0100000000).
3.2 Burst Detection from a Single Activity
Stream
Given an activity stream (nm1 , ..., n
m
T ), we would
like to infer a state sequence over these T times-
tamps, i.e., to find out the most possible state se-
quence z = (zm1 , ..., z
m
T ) based on the data, where
zmi = 1 or 0. We formulate this problem as
an optimization problem. The cost of a state se-
quence includes two parts: generation of activities
and smoothness of the state sequence. The objective
function is to find a state sequence which incurs the
minimum cost. Formally, we define the total cost
function as
Cost(z) = ?
T?
i=1
log f(nmi , i, z
m
i )
? ?? ?
generating cost
+
(
? ?(zm1 , ..., z
m
T ) ? ?1
)
? ?? ?
smoothness cost
,
(3)
where ?1 > 0 is a scaling factor which balance these
two parts. ?(?) function is the smoothness function,
and we can set it as either g1(?) or g2(?).
To seek the optimal state sequence, we can min-
imize Equation 3. However, exact inference is hard
due to the exponential search space. Instead of ex-
amining the smoothness of the whole state sequence,
we propose to measure the smoothness of all the L-
length subsequences, so called ?local smoothness?.
The assumption is that the states in a relatively short
time window should not change too much. The new
objective function is defined as
Cost(z) = ?
T?
i=1
log f(nmi , i, z
m
i ) (4)
?
(
?
i?L
?(zmi , ..., z
m
i+L?1)
)
? ?1.
The objective function in Equation 4 can be
solved efficiently by a dynamic programming algo-
rithm shown in Algorithm 1. The time complexity
of this algorithm is O(T ? 2L). Note that the meth-
ods we present in Equation 4 and Algorithm 1 are
quite general. They are independent of the concrete
forms of f(?) and ?(?), which leaves room for flexi-
ble adaptation or extension in specific tasks. In pre-
vious methods (Kleinberg, 2003), L is often fixed as
1469
2. Indeed, as shown in Figure 2, in some cases, we
may need a longer window to infer the global pat-
terns. In our model, L can be tuned based on real
datasets. We can seek a trade-off between efficiency
and length of context windows.
Algorithm 1: Dynamic Programming for Equation 4.
d[i][s][zi...zi?L+1] denotes the minimum cost of the first1
i timestamps with the state subsequence: zi...zi?L+1 and
zi = s;
set d[0][?][?] = 0;2
set c1[i] = log f(nmi , i, z
m
i );3
set c2[i] = ?(zi, ..., zi?L+1);4
b, b?: previous and current state window are represented as5
L-bit binary numbers;
for i = 1 to T do6
for s = 0 to 1 do7
for b = 0 to 2L ? 1 do8
b? = (b << 1|s)&(1 << L? 1);9
d[i][s][b?]??10
min(d[i][s][b?], d[i?1][s][b]+c1[i]+c2[i]);
end11
end12
end13
3.3 Correlating Multiple Activity Streams
In this section, we discuss how to correlate multi-
ple activity streams to learn a global bursty patterns.
The hidden state sequences corresponding to these
activity streams are not fully independent. An ex-
ternal event may intricate surges in multiple activity
streams simultaneously.
We propose to correlate multiple activity streams
in an optimization model. The idea is that activ-
ity streams related with one query might be depen-
dent, i.e., the states of multiple activity streams on
the same timestamp tend to be the same6; if not,
it would incur a cost. To implement this idea, we
develop an optimization model. For convenience,
we call the states of each activity stream as ?local
states? while the overall states learnt from multiple
activity streams as ?global states?.
The idea is that although various activity streams
are different in the scale of frequencies, they tend to
share similar trend patterns. We incorporate the cor-
relation between local states on the same timestamp.
6In our experiments, we compute the cross correlation be-
tween different streams with a lag factor ?, we find the cross
correlation achieves maximum consistantly when ? = 0.
Formally, we have
Cost(Z) =
M?
m=1
{
?
T?
i=1
log f(nmi , i, z
m
i )
?
?
i?L
?(zmi , ..., z
m
i+L?1) ? ?1
}
+
T?
i=1
?
m1,m2
I(zm1i 6= z
m2
i ) ? ?2, (5)
where I(?) is indicator function, and ?2 is the cost
when a pair of states are different across multiple
streams on the same timestamp.
The objective function in Equation 5 can be
solved by a dynamic programming algorithm pre-
sented in Algorithm 2. The time complexity of this
algorithm is O(T ? 2M ?L+M ). Generally, L can be
set as one small value, e.g., L =2 to 6, and we can
select just a few representative activity streams, i.e.,
M =2 to 6. In this case, the algorithm can be effi-
cient.
Algorithm 2: Dynamic Programming for Equation 5.
d[i][z1i ...z
1
i?L+1; ...; z
M
i ...z
M
i?L+1] denotes the minimum1
cost of the first i timestamps with the local state
subsequence zmi ...z
m
i?L+1 in the mth stream;
set d[0][...] = 0;2
bl, bl
?
: previous and current state windows represented as3
M ? L-bit binary numbers;
c[i, bl, bl
?
] denotes all the cost in the tth timestamp;4
for i = 1 to T do5
for bl = 0 to 2M?L ? 1 do6
deriving current local state sequences bl
?
from bl;7
d[i][b?l]??8
min(d[i][bl
?
], d[i? 1][bl] + c[i, bl, bl
?
]);
end9
end10
Given M types of activity streams, we can get
M (local) state sequences {(zm1 , ..., z
m
T )}
M
m=1. The
next question is how to learn a global state sequence
(zG1 , ..., z
G
T ) based on local state sequences. Here we
give a few options:
CONJUNCT: we set a global state zi as bursty if
all local states are bursty, i.e., zGi = ?
M
m=1z
m
i .
DISJUNCT: we set a global state zi as bursty if
one of the local states is bursty, i.e., zGi = ?
M
m=1z
m
i .
BELIEF: we set a global state zi as the most con-
fident local state, i.e., zGi = argmaxmbelief(z
m
i ).
The belief(?) function can be defined as the ratio be-
tween generating costs from states zmi and 1 ? z
m
i :
belief(zmi ) =
f(nmi ,i,z
m
i )
f(nmi ,i,1?z
m
i )
.
1470
Table 2: Basic statistics of our golden test collection.
# of queries 17
Aver. # of event-related bursts per query 19
Min. bursty interval 3 hours
Max. bursty interval 163 hours
Aver. bursty interval 17.8 hours
L2G: we treat the states of one local stream as the
global states.
4 Experiments
4.1 Construction of Test Collection
We test our algorithms on a large Twitter dataset,
which contains about 200 million tweets and ranges
from July, 2009 to December 2009. We manually
constructed a list of 17 queries that have high vol-
umes of relevant tweets during this period. These
queries have a very broad coverage of topics. Exam-
ple queries are ?Barack Obama?, ?Apple?, ?Earth-
quake?, ?F1? and ?Nobel Prize?. For each query, we
invite two senior graduate students to manually iden-
tify their golden bursty intervals, and each bursty in-
terval is represented as a pair of timestamps in terms
of hours. Specifically, to generate the golden stan-
dard, given a query, the judges first manually gen-
erate a candidate list of external events7; then for
each event, they look into the tweets within the cor-
responding period and check whether there is a surge
on the frequency of tweets. If so, the judges fur-
ther determine the start timepoint and end timepoint
of it. If there is a conflict, a third judge will make
the final decision. We used Cohen?s kappa coeffi-
cient to measure the agreement of between the first
two judges, which turned out to be 0.67, indicating a
good level of agreement8. We present basic statistics
of the test collection in Table 2.
4.2 Evaluation Metrics
Before introducing our evaluation metrics, we first
define the Bursty Interval Overlap Ratio (BIOR)
BIOR(f,X ) =
?
f ??X ?l(f, f
?)
L(f)
,
f is a bursty interval, ?l(f, f ?) is the length of
overlap between f ? and f , L(f) is the length of
7We refer to some gold news resources, e.g., Google News
and Yahoo! News.
8http://en.wikipedia.org/wiki/Cohen?s kappa
Figure 3: Examples to illustrate BIOR. X0, X1
and X2 are three sets of bursty intervals. X0
and X2 consist of one interval, and X1 consists of
two intervals. BIOR(f,X0)=1, BIOR(f,X1)=0.5 and
BIOR(f,X2)=0.5.
bursty period of f . X is a set of bursty intervals,
BIOR measures the proportion of the timestamps in
f which are covered by one of bursty intervals in
X . We use BIOR to measure partial match of inter-
vals, because a system may not return all the exact
bursty intervals9. We show some examples of BIOR
in Figure 3.
We use modified Precision, Recall and F as ba-
sic measures. Given one query, P, R and F can be
defined as follows
R =
?
f?B I
(
1
|Mf |
BIOR(f,M) > 0.5
)
|B|
,
P =
1
|M|
?
f ??M
(BIOR(f ?,B)),
F =
2? P ?R
P + R
,
where M is the set of bursty intervals identified
by one candidate method, B is the set of bursty in-
tervals in golden standards, and Mf is the set of in-
tervals which overlap with f in M. We incorporate
the factor 1|Mf | in Recall to penalize the incontin-
uous coverage of the golden interval, and we also
require that the overlap ratio with penalized factor
is higher than a threshold of 0.5. Given two sets of
bursty intervals which have the same value of BIOR,
we prefer the one with fewer intervals. In Figure 3,
we can easily derive X1 and X2 have the same value
9A simple evaluation method is that we label each one hour
time slot as being part of a burst or not and compare with the
gold standard. However, in our experiments, we find that some
methods tend to break one meaningful burst into small parts and
easier to be affected by small fluctuations although they may
have a good coverage of bursty points. This is why we adopt a
different evaluation approach.
1471
Table 3: Average cross-correlation between different
streams.
St Sr Su
St 1 0.830235 0.851514
Sr 0.830235 1 0.59905
Su 0.851514 0.59905 1
of BIOR, when computing Recall, we prefer X2 to
X1 since X2 consists of only one complete inter-
val whileX1 consists of two inconsecutive intervals.
I(?) is an indicator function which returns 1 only if
the statement if true. In our experiments, we use the
average of R, P and F over all test queries.
4.3 Experiment Setup
Selecting activity streams
We consider three types of activity streams in
Twitter: 1) posting a tweet, denoted as St; 2) for-
warding a tweet (retweet), denoted as Sr; 3) post-
ing a URL-embedded tweet, denoted as Su. It is
natural to test the performance of St in discover-
ing bursty patterns, while Su and Sr measure the
influence of external events on users in Twitter in
two different aspects. Sr: An important convention
in Twitter is the ?retweeting? mechanism, through
which users can actively spread the news or related
information; Su: Another characteristic of Twitter is
that the length of tweets is limited to 140 characters,
which constrains the capacity of information. Users
often embed a URL link in the tweets to help others
know more about the corresponding information.
We compute the average cross correlation be-
tween different activity streams for these 17 queries
in our test collection, and we summarize the results
in Table 3. We can see that both Sr and Su have a
high correlation with St, and Sr has a relatively low
correlation with Su. 10
Methods for comparisons
S(?): using Equation 4 and considers a single ac-
tivity stream, namely St, Su and Sr.
MBurst(?): using Equation 5 and considers mul-
tiple activity streams.
To compare our methods with previous methods,
we adopt the following baselines:
StateMachine: This is the method proposed
in (Kleinberg, 2003). We use heterogeneous Poisson
10We also consider the frequencies of unique users by hours,
however, we find it has a extremely high correlation coefficient
with St, about 0.99, so we do not incorporate it.
function as generating functions instead of binomial
function Cnk because sometimes it is difficult to get
the exact total number n in social media.
Threshold: If we find that the count in one time
interval is higher than a predefined threshold, it is
treated as a burst. The threshold is set as 1.5 times
of the average number.
PeakFinding: This is the method proposed
in (Marcus et al 2011), which aims to automatically
discover peaks from tweets.
Binomial: This is the method proposed in (Fung et
al., 2007a), which uses a cumulative binomial distri-
bution with a base probability estimated by remov-
ing abnormal frequencies.
As for multiple-stream burst detection, to the best
of our knowledge, the only existing work is pro-
posed by (Yao et al 2010), which is supervised and
requires a considerable amount of training time, so
we do not compare our work with it. We compare
our method with the following heuristic baselines:
SimpleConjunct: we first find the optimal state se-
quences for each single activity stream. We then de-
rive a global state sequence by taking the conjunc-
tion of all local states.
SimpleDisjunct: we first find the optimal state se-
quences for each single activity stream, and then we
derive a global state sequence by take the disjunction
of all local states.
Another possible baseline is that we first merge
all the activities, then apply the single-stream algo-
rithm. However, in our data set, we find that the
number of activities in St is significantly larger than
that of the two types. St dominantly determines the
final performance, so we do not incorporate it here
as a comparison.
4.4 Experimental Results
Preliminary results on a single stream
We first examine the performance of our proposed
method on a single stream. Note that, our method
in Equation 4 has two merits: 1) the length of lo-
cal window can be tuned on different datasets; 2) a
novel state smoothness function is adopted.
We set the ? function in Equation 4 respectively
as g1 and g2, and apply our proposed methods to
three streams (St,Sr,Su) mentioned above. Note
that, when L = 2 and ? = g1, our method becomes
the algorithm in (Kleinberg, 2003). We tune the pa-
rameter ?1 in Equation 4 from 2 to 20 with a step of
2. We record the best F performance and compute
1472
the corresponding standard deviation. In Table 5, we
can observe that 1) streams St and Sr perform better
than Su; 2) the length of local window significantly
affects the performance; 3) g2 is much better than g1
in our proposed burst detection algorithm; 4) gen-
erally speaking, a longer window size (L = 3, 4)
performs better than the most common used size 2
in (Kleinberg, 2003).
We can see that our proposed method is more ef-
fective than the other baselines. The major reason is
that none of these methods consider state smooth-
ness in a systematic way. In our preliminary ex-
periments, we find that these baselines usually out-
put a lot of bursts, most of which are broken mean-
ingful bursts. To overcome this, baseline method
StateMachine (g1 + L = 2) requires larger ? and
?1, which may discard relatively small meaningful
bursts; while our proposed single stream method
(g2 + L = 3, 4) tends to identify steady and con-
secutive bursts through the help of longer context
window and context sensitive smoothness function
g2, it is more suitable to be applied to social media
for burst detection.
Compared with the other baselines, (Kleinberg,
2003) is still one good and robust baseline since it
models the state smoothness partially. These prelim-
inary findings indicate that state smoothness is very
important for burst detection, and the length of state
context window will affect the performance signifi-
cantly.
To get a deep analysis of the performance of dif-
ferent streams, we set up three classes, and each
class corresponds to a single stream. Since for each
query, we can obtain multiple results in different ac-
tivity streams, we further categorize the 17 anno-
tated queries to the stream which leads to the opti-
mal performance on that query. Interestingly, we can
see: 1) the url stream gives better performance on
queries about big companies because users in Twit-
ter usually talk about the release of new products
or important evolutionary news via url-embedded
tweets; 2) the retweet stream gives better perfor-
mance on queries which correspond to unexpected
or significant events, e.g., diasters. It is consistent
with our intuitions that users in Twitter do actively
spread such information. Combining previous anal-
ysis of Table 5, overall we find the retweet stream is
more capable to identify bursts which correspond to
significant events.
Table 4: Categorization of 17 queries according to the
optimal performance.
Streams Queries
url Apple,Microsoft,Nokia, climate
retweet bomb,crash,earthquake,typhoon,
F1,Google,Olympics
all tweet Amazon, eclipse, Lakers,
NASA, Nobel Prize, Barack Obama
Table 5: Performance (average F) on a single stream.
???? indicates that the improvement our proposed single-
stream methodg2,L=4 over all the other baselines is ac-
cepted at the confidence level of 0.95, i.e., StateMachine,
PeakingFinding, Binomial and Threshold.
? L St Sr Su
4 0.545/0.015 0.543/0.037 0.451/0.036
g2 3 0.536/0.013 0.549??/0.019 0.464/0.025
2 0.468/0.055 0.542/0.071 0.455/0.045
4 0.513/0.059 0.546/0.058 0.465/0.047
g1 3 0.469/0.055 0.542/0.071 0.455/0.045
2 0.396/0.043 0.489/0.074 0.374/0.035
StateMachine 0.396 0.489 0.374
PeakFinding 0.410 0.356 0.302
Binomial 0.315 0.420 0.341
Threshold 0.195 0.181 0.175
Preliminary results on multiple streams
After examining the basic results on a single
stream, we continue to evaluate the performance of
our proposed models on multiple activity streams.
For MBurst in Equation 5, we have three parame-
ters to set, namely L, ?1 and ?2. We do a grid search
for both ?1 and ?2 from 1 to 12 with a step of 1, and
we also examine the performance when L = 2, 3, 4.
We can see that MBurst has four candidate meth-
ods to derive global states from local states; for L2G,
we use the states of St as the final states, and we em-
pirically find that it performs best compared with the
other two streams in L2G.
Recall that our proposed single-stream method
is better than all the other single-stream baselines,
so here single-best denotes our method in Equa-
tion 4 (? = g2, L = 4) on Sr. For SimpleConjunct
and SimpleDisjunct, we first find the optimal state
sequences for each single activity stream using our
proposed method in Equation 4 (? = g2, L = 4),
and then we derive a global state sequence by take
the conjunction or disjunction of all local states re-
spectively.
Besides the best performance, we further compute
the average of the top 10 results of each method
by tuning parameters to check the average perfor-
1473
Table 6: Performance (average F) on multiple streams.
??? indicates that the improvement our proposed
multiple-stream method over our proposed single-stream
method at the confidence level of 0.9 in terms of average
performance.
Methods best average
single-best (g2 + Sr) 0.549 0.526
SimpleConjunct 0.548 -
SimpleDisjunct 0.465 -
MBurst+CONJUNCTr,t,u 0.555 0.548
MBurst+DISJUNCTr,t,u 0.576 0.570?
MBurst+BELIEFr,t,u 0.568 0.561
MBurst+L2Gr,t,u(t) 0.574 0.567
MBurst+L2Gr,t,u(r) 0.560 0.558
mance. The average performance can show the sta-
bility of models in some degree. If one model out-
puts the maximum in a very limited set of parame-
ters, it may not work well in real data, especially in
social media.
In Table 6, we can seeMBurst+DISJUNCTr,t,u
gives the best performance. MBurst performs
consistently better than single-best which is a very
strong single-stream method, especially for average
performance. MBurst+DISJUNCTr,t,u has an im-
provement of average performance over single-best
by 8.4%. And simply combining three different
streams may hit results (SimpleConjunct and Sim-
pleDisjunct). It indicates that MBurst is more sta-
ble and shows a higher performance.
For different methods to derive global bursty pat-
terns, we can see that MBurst+DISJUNCT per-
forms best while MBurst+CONJUNCT performs
worst. Interestingly, however, SimpleConjunct is
better than SimpleDisjunct, the major reason is that
MBurst performs a local-state correlation of mul-
tiple activity streams to correct possible noisy fluc-
tuations from single streams before the conjunction
or disjunction of local states. After such correlation,
the performance of each activity stream should im-
prove. To see this, we present the optimal results of a
single stream without/with local-state correlation in
Table 7. Local-state correlation significantly boosts
the performance of a single stream. Indeed, we find
that the step of local-state correlation is more impor-
tant for our multiple stream algorithm than the step
of how to derive global states based on local states.
We test our MBurst algorithm with the setting:
T = 4416, L = 4 and M = 3, and for all the test
Table 7: Comparison between the optimal results of a
single stream with/without local-state correlation.
all retweet retweet url
without 0.536 0.549 0.464
with 0.574 0.560 0.547
2 4 6 8 10 120.54
0.550.56
0.570.58
0.590.6
?1
Average
 F
 
 MBurst+orsingle?best
(a) ?2 = 4, varying ?1.
2 4 6 8 10 120.54
0.550.56
0.570.58
0.590.6
?2
Average
 F
 
 MBurst+orsingle?best
(b) ?1 = 11, varying ?2.
Figure 4: Parameter sensitivity of MBurst + DIS-
JUNCT.
queries, our algorithm can respond in 2 seconds 11,
which is efficient to be deployed in social media.
Parameter sensitivity
We have shown the performance of different pa-
rameter settings for single stream algorithm in Ta-
ble 5. Next, we check parameter sensitivity in
MBurst. In our experiments, we find a longer lo-
cal window (L = 3, 4) is better than L = 2, so
we first set L = 4, then we select parameter set-
tings of ?2 = 4 and ?1 = 11, which give best per-
formance for MBurst+DISJUNCT. We vary one
with the other fixed to see how one single parame-
ter affects the performance. The results are shown in
Figure 4, and we can see MBurst+DISJUNCT is
consistently better than single-best.
5 Related Work
Our work is related to burst detection from text
streams. Pioneered by the automaton model pro-
posed in (Kleinberg, 2003), many techniques have
been proposed for burst detection such as the ?2-
test based method (Swan and Allan, 2000), the
parameter-free method (Fung et al 2005) and mov-
ing average method (Vlachos et al 2004). Our work
is related to the applications of these burst detection
algorithms for event detection (He et al 2007; Fung
et al 2007b; Shan et al 2012; Zhao et al 2012).
11All experiments are tested in a Mac PC, 2.4GHz Intel Core
2 Duo.
1474
Some recent work try to identify hot trends (Math-
ioudakis and Koudas, 2010; Zubiaga et al 2011;
Budak et al 2011; Naaman et al 2011) or make
use of the burstiness (Sakaki et al 2010; Aramki
et al 2011; Marcus et al 2011) in social media.
However, few of these methods consider modeling
the local smoothness of one state sequence in a sys-
tematic way and often use a fixed window length of
2.
Little work considers making use of different
types of social media activities for burst detection.
(Yao et al 2010; Kotov et al 2011; Wang et al
2007; Wang et al 2009) conducted some prelim-
inary studies of mining correlated bursty patterns
from multiple sources. However, they either highly
relies on high-quality training datasets or require a
considerable amount of training time. Online social
activities are dynamic, with a large number of new
items generated continuously. In such a dynamic
setting, burst detection algorithms should effectively
collect evidence, efficiently adjust prediction models
and respond to the users as social media activities
evolve. Therefore it is not suitable to deploy such
algorithms in social media.
Our work is also similar to studies which aim
to mine and leverage knowledge from social me-
dia (Mathioudakis et al 2010; Ruiz et al 2012;
Morales et al 2012). We share the common point
with these studies that we try to utilize the under-
lying rich knowledge in social media, while our fo-
cus of this work is quite different from theirs, i.e., to
identify event-related bursts.
Another line of related research is Twitter related
studies (Kwak et al 2010; Sakaki et al 2010). Our
proposed methods can provide event-related bursts
for downstream applications.
6 Conclusion
In this paper, we propose to identify event-related
bursts via social media activities. We propose one
optimization model to correlate multiple activity
streams to learn the bursty patterns. To better mea-
sure local smoothness of the state sequence, we pro-
pose a novel state cost function. We test our meth-
ods in a large Twitter dataset. The experiment re-
sults show that our methods are both effective and
efficient. Our work can provide a preliminary un-
derstanding of the correlation between the happen-
ings of events and the degree of online social media
activities.
Finally, we present a few promising directions
which may potentially improve or enrich current
work.
1) Variable-length context. In this paper, L is a
pre-determined parameter which controls the size of
context window. It cannot be modified when the al-
gorithm runs. A large L will significantly increases
the algorithm complexity, and we may not need a
large L for all the states in a Markov chain. This
problem can be addressed by using the variable-
length hidden Markov model (Wang et al 2006),
which is able to learn the ?minimum? context length
for accurately determining each state.
2) Incorporation of more useful features. Our
current model mainly considers temporal variations
of streaming data and searches the surge patterns ex-
isting in it. In some cases, simple frequency infor-
mation may not be capable to identify all the mean-
ingful bursts. It can be potentially useful to leverage
up more features to help filter out noisy bursts, e.g.,
semantic information (Zhao et al 2010).
3) Modeling multi-modality data. We have ex-
amined our multi-stream algorithm by using three
different activity streams. These streams are textual-
based. It will be interesting to check our algorithm in
multi-modality data streams. E.g., in Facebook, we
may collect a stream consisting of the daily frequen-
cies of photo sharing and another stream consisting
of the daily frequencies of text status updates.
4) Evaluation of the identified bursts. In most
of previous work, they seldom construct a gold stan-
dard for quantitative test, instead they qualitatively
evaluate their methods. In our work, we invite hu-
man judges to generate the gold standard. It is time-
consuming, and the bias from human judges cannot
be completely eliminated although more judges can
be invited. A possible evaluation method is to exam-
ine the identified bursts in downstream applications,
e.g., event detection.
Acknowledgement
This work is partially supported by NSFC Grant
61073082, 60933004 and 70903008. Xin Zhao is
supported by Google PhD Fellowship (China). We
thank the insightful comments from Junjie Yao and
the anonymous reviewers.
1475
References
Eiji Aramki, Sachiko Maskawa, and Mizuki Morita.
2011. Twitter catches the flu: Detecting influenza epi-
demics using twitter. In Proceedings of the 2011 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1568?1576, Edinburgh, Scotland,
UK., July. Association for Computational Linguistics.
Ceren Budak, Divyakant Agrawal, and Amr El Abbadi.
2011. Structural trend analysis for online social net-
works. Proc. VLDB Endow., 4, July.
Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Philip S. Yu,
and Hongjun Lu. 2005. Parameter free bursty events
detection in text streams. In VLDB.
Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Huan Liu, and
Philip S. Yu. 2007a. Time-dependent event hierar-
chy construction. In Proceedings of the 13th ACM
SIGKDD international conference on Knowledge dis-
covery and data mining, KDD ?07.
Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Huan Liu, and
Philip S. Yu. 2007b. Time-dependent event hierarchy
construction. In SIGKDD.
Qi He, Kuiyu Chang, and Ee-Peng Lim. 2007. Analyz-
ing feature trajectories for event detection. In SIGIR.
Alexander Ihler, Jon Hutchins, and Padhraic Smyth.
2006. Adaptive event detection with time-varying
poisson processes. In Proceedings of the 12th ACM
SIGKDD international conference on Knowledge dis-
covery and data mining, KDD, pages 207?216, New
York, NY, USA. ACM.
J. Kleinberg. 2003. Bursty and hierarchical structure in
streams. Data Mining and Knowledge Discovery.
Alexander Kotov, ChengXiang Zhai, and Richard Sproat.
2011. Mining named entities with temporally corre-
lated bursts from multilingual web news streams. In
Proceedings of the fourth ACM international confer-
ence on Web search and data mining, WSDM, pages
237?246.
Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue
Moon. 2010. What is Twitter, a social network or a
news media? In WWW ?10: Proceedings of the 19th
international conference on World wide web, pages
591?600.
Adam Marcus, Michael S. Bernstein, Osama Badar,
David R. Karger, Samuel Madden, and Robert C.
Miller. 2011. Twitinfo: aggregating and visualizing
microblogs for event exploration. In Proceedings of
the 2011 annual conference on Human factors in com-
puting systems, CHI ?11.
Michael Mathioudakis and Nick Koudas. 2010. Twit-
termonitor: trend detection over the twitter stream.
In Proceedings of the 2010 international conference
on Management of data, SIGMOD ?10, pages 1155?
1158.
Michael Mathioudakis, Nick Koudas, and Peter Marbach.
2010. Early online identification of attention gather-
ing items in social media. In Proceedings of the third
ACM international conference on Web search and data
mining, WSDM ?10, pages 301?310, New York, NY,
USA. ACM.
Gianmarco De Francisci Morales, Aristides Gionis, and
Claudio Lucchese. 2012. From chatter to headlines:
harnessing the real-time web for personalized news
recommendation. In WSDM, pages 153?162.
Mor Naaman, Hila Becker, and Luis Gravano. 2011. Hip
and trendy: Characterizing emerging trends on twitter.
JASIST, 62(5):902?918.
Eduardo J. Ruiz, Vagelis Hristidis, Carlos Castillo, Aris-
tides Gionis, and Alejandro Jaimes. 2012. Correlat-
ing financial time series with micro-blogging activity.
pages 513?522.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes twitter users: real-time event
detection by social sensors. WWW, pages 851?860,
New York, NY, USA. ACM.
Dongdong Shan, Wayne Xin Zhao, Rishan Chen, Shu
Baihan, Hongfei Yan, and Xiaoming Li. 2012.
Eventsearch: A system for event discovery and re-
trieval on multi-type historical data. In KDD?12, De-
mostration.
Russell Swan and James Allan. 2000. Automatic gener-
ation of overview timelines. In SIGIR.
Michail Vlachos, Christopher Meek, Zografoula Vagena,
and Dimitrios Gunopulos. 2004. Identifying similari-
ties, periodicities and bursts for online search queries.
In SIGMOD.
Yi Wang, Lizhu Zhou, Jianhua Feng, JianyongWang, and
Zhi-Qiang Liu. 2006. Mining complex time-series
data by learning markovian models. In Proceedings
of the Sixth International Conference on Data Min-
ing, ICDM, pages 1136?1140, Washington, DC, USA.
IEEE Computer Society.
Xuanhui Wang, ChengXiang Zhai, Xiao Hu, and Richard
Sproat. 2007. Mining correlated bursty topic pat-
terns from coordinated text streams. In Proceedings
of the 13th ACM SIGKDD international conference on
Knowledge discovery and data mining.
Xiang Wang, Kai Zhang, Xiaoming Jin, and Dou Shen.
2009. Mining common topics from multiple asyn-
chronous text streams. In Proceedings of the Second
ACM International Conference on Web Search and
Data Mining, WSDM, pages 192?201.
Junjie Yao, Bin Cui, Yuxin Huang, and Xin Jin. 2010.
Temporal and social context based burst detection
from folksonomies. In AAAI.
Wayne Xin Zhao, Jing Jiang, Jing He, Dongdong Shan,
Hongfei Yan, and Xiaoming Li. 2010. Context mod-
eling for ranking and tagging bursty features in text
1476
streams. In Proceedings of the 19th ACM interna-
tional conference on Information and knowledge man-
agement, CIKM ?10.
Wayne Xin Zhao, Rishan Chen, Kai Fan, Hongfei Yan,
and Xiaoming Li. 2012. A novel burst-based text
representation model for scalable event detection. In
ACL?12.
Arkaitz Zubiaga, Damiano Spina, V??ctor Fresno, and
Raquel Mart??nez. 2011. Classifying trending topics:
a typology of conversation triggers on twitter. In Pro-
ceedings of the 20th ACM international conference on
Information and knowledge management, CIKM.
1477
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1337?1347,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Mining New Business Opportunities: Identifying Trend related Products by
Leveraging Commercial Intents from Microblogs
Jinpeng Wang1, Wayne Xin Zhao1, Haitian Wei2, Hongfei Yan1 and Xiaoming Li1
1School of Electronic Engineering and Computer Science, Peking University, China
2Daton Securities Co., Ltd., No.93 Jianguo Rd, Chaoyang District, Beijing, China
JooPoo@pku.edu.cn, {batmanfly,haataa.wei,yhf1029}@gmail.com, lxm@pku.edu.cn
Abstract
Hot trends are likely to bring new business
opportunities. For example, ?Air Pollution?
might lead to a significant increase of the sales
of related products, e.g., mouth mask. For e-
commerce companies, it is very important to
make rapid and correct response to these hot
trends in order to improve product sales. In
this paper, we take the initiative to study the
task of how to identify trend related products.
The major novelty of our work is that we au-
tomatically learn commercial intents revealed
from microblogs. We carefully construct a da-
ta collection for this task and present quite a
few insightful findings. In order to solve this
problem, we further propose a graph based
method, which jointly models relevance and
associativity. We perform extensive experi-
ments and the results showed that our methods
are very effective.
1 Introduction
A trend is a hot topic (e.g., the release of a popular
movie) which is being widely discussed by the pub-
lic. Hot trends usually attract much attention from
the public, and they are likely to bring new business
opportunities. Consider the following e-shopping s-
cenario. A user in Beijing would like to buy some-
thing to reduce the health impacts of Beijing air pol-
lution1. Different from traditional e-shopping sto-
ries, in this case the user may not have a clear idea of
what she should buy, and cannot even formulate the
1See http://www.nytimes.com/2013/04/04/world/asia/two-major-
air-pollutants-increase-in-china.html to find more details about the
trending topic ?Beijing Air Pollution?.
purchase needs into a clear query. Faced with trend-
driven business opportunities, e-commerce compa-
nies typically ask workers to manually identify relat-
ed products and make heuristic rules to match user
queries (e.g., incorporating trending keywords into
related product titles).
To improve trend-driven e-commerce, in this pa-
per, we propose to study the novel task of automat-
ically identifying trend related products. Why is
it compelling to understand and study trend-driven
product purchase? Because hot trends are closely
related to business opportunities directly or indirect-
ly. As a case of direct causal relationship, the world-
wide popularity of the movie series ?Harry Potter?
created the great success of the original novels of
?Harry Potter?. As a case of indirect causal rela-
tionship, the stock rise or salary increase might exert
positive effects on product sale. Based on our empir-
ical analysis (See Section 3), a considerable propor-
tion, i.e. 50%, of hot trends discussed on the largest
Chinese microblog (i.e. Sina Weibo) indeed have
corresponding product entries in the largest Chinese
C2C e-commerce website (i.e. Taobao), which in-
dicates a strong correlation between hot trends and
product sale.
Although the task is important and emergent, it
has at least two major challenges. First of all, how to
infer users? trend-driven purchase intents promptly.
A trend usually happens unexpectedly. Without pri-
or knowledge and experiences, it is particularly diffi-
cult to make rapid response to relate the trend to can-
didate products. Our solution is to leverage trend-
related commercial intents from microblogs by min-
ing users? real-time response to a trending topic. We
adopt the solution based on two key considerations:
(1) Microblogs are fast. As previous studies showed,
1337
the first story of a trending topic indeed was usu-
ally reported in microblogs rather than traditional
news media (Sakaki et al, 2010; Kwak et al, 2010;
Leskovec et al, 2009). (2) Microblogs contain user-
s? commercial intents. The microblogging service
has become one of the most popular social network
platforms, where users may tweet about their needs
and desires (Hollerit et al, 2013). E.g., a microblog
user may complain about the air quality and evince
the desire to buy a mouth mask in a tweet. The ex-
ample indicates we can make use of tweet-level re-
latedness to capture the correlation between trends
and products.
Second, how to achieve a comprehensive cover-
age of related products but not hurting precision.
The above solution will miss the related products
which have not been discussed in microblogs. Our
idea is to take the associativity between products in-
to consideration. Our definition about associativity
is very general and can have different instantiation-
s in specific settings. For example, we can define
product associativity to be the similarity between
product descriptions, or the ratio of historical pur-
chase records in e-commerce companies. Howev-
er, one-step associativity may not fully discover the
underlying relatedness between products due to the
fact that the product associativity is indeed transi-
tive. Thus, a transitable associativity model is need-
ed.
To address these two challenges, we propose a u-
nified graph based ranking algorithm which jointly
models the above two aspects, i.e., relevance and
associativity. Given a trend, the algorithm runs in
an iterative way and seeks a trade-off between rel-
evance and associativity by propagating the scores
on the product graph. Our contribution can be sum-
marized as follows: (1) we introduce the novel task
of identifying trend related products, most of all, we
propose to leverage trend-related commercial intents
from microblogs; (2) we present insightful empiri-
cal analysis to illustrate the correlation between hot
trends and product sale (See Section 3); (3) we pro-
pose a novel graph based ranking algorithm which
jointly considers relevance and associativity; (4) we
carefully construct the test collection based on re-
al data of the largest microblog and the largest C2C
e-commerce website in China. (5) we perform ex-
tensive experiments and present some important im-
plications for practice.
To the best of our knowledge, our work was the
first to consider identifying trend related products by
leveraging commercial intents from microblogs. We
believe the current work will have important impact
on industry and inspire more follow-up research s-
tudies. The rest of this paper is organized as fol-
lows. We present the data collection and empiri-
cal analysis of the impact of hot trends on product
sale in Section 3. We present a novel graph-based
method in Section 4. Experimental setup and result-
s are discussed in Section 5 and Section 6. Finally,
the related work is discussed in Section 7. And the
conclusions and future work are given in Section 8.
2 Problem Definition
A trend is a hot topic widely discussed by the public,
e.g., the release of a hot movie. Usually, a trend e
can be described by a small set of keywords denoted
by Ke and a corresponding time span Te.
Trend-related Products Identification: Given a
trend e, we assume that the following inputs are
available: 1) tweets that contain trend keywords Ke
and 2) a product database which provides a set of
candidate products P = {p1, p2, ..., pn} with nec-
essary detailed information, e.g., titles and descrip-
tions. The objective of trend-related products iden-
tification is to identify products in P that are related
to trend e within the time span Te, denoted by PR.
For convenience, we will not explicitly mention the
time span unless needed.
To better understand the problem, we first present
an illustrative example in Table 1, which will be dis-
cussed as the running case throughout the paper. In
this example, we can see that a few users tweet their
product needs related to the trend ?Air Pollution?.
We take Taobao as the product database and present
a few related products in it.
Table 1: An illustrative example for the studied task.
Trend keywords: Air Pollution
Tweets:
What bad air! We need to buy masks ASAP!!!
I am planing to buy an air purifier. Hoping it can defend air pollution.
#air pollution I will recommend to keep some houseplants at home.
Product database: Taobao2
Related products: Mouth Mask, Air Purifier, Houseplant
2The biggest C2C e-commerce site in China, similar to eBay.
1338
3 Data and Observations
As discussed earlier, hot trends may exert positive
effects on the sale of related products. In this sec-
tion, we will construct a deep analysis on this point
by presenting quantitative answers to the following
two problems:
? Q1: What is the proportion of hot trends that
potentially lead to business opportunities, and
how is their impact on related products?
? Q2: How is the associativity between related
products?
These findings are key and fundamental to develop
our models.
3.1 Data Collection
To perform the above analysis, the key is how to con-
struct an experimental data collection which relates
hot trends to corresponding related products. We
jointly consider microblogs and e-commerce plat-
forms: we obtain hot trends in microblogs and man-
ually identify trend-related products in e-commerce
websites. In this paper, we adopt Sina Weibo3
as the microbloging platform and Taobao4 as the
e-commerce platform, which are the biggest mi-
croblogging service and the largest C2C company in
China respectively. The analysis method is general
and can equally apply to other platforms. For both t-
wo data signals, we consider a two-month time span,
i.e. from May 2013 to June 2013.
Trend detection. Since trend detection is not our
focus, we directly obtained trends from ?trending
topics? provided by the microblog platform. Our
work can be easily extended to incorporate a trend
detection component. Similar to ?trending topic-
s? in Twitter, Sina Weibo provides a public list of
top searched keywords which can be obtained by
the Weibo search API5. In the list, top 50 keyword-
s are presented and ordered by the number of be-
ing searched. Weibo classifies these keywords in-
to five categories: China, movie, business, person
and sports. We consider these keywords to be trend
keywords. These keywords are dynamically updated
and we monitor the trend lists in the considered time
3http://www.weibo.com/
4http://www.taobao.com/
5http://s.weibo.com/top/summary
span. We define the start and end time of a trend to
be the first day and the last day on the trend list re-
spectively, which spans the active interval of a trend.
We only keep the trend which has an active interval
with more than one day. For each trend, we use the
trend keywords to retrieve all related tweets in the
active interval, and use the pattern based method in
(Hollerit et al, 2013) to extract all mentioned prod-
uct keywords. We present a few example patterns
used for extracting product keywords in Table 2. Af-
ter that we can obtain a set of product keywords for
each trend.
Table 2: Example patterns for extracting product key-
words.
Patterns Example segments of tweets
?(buy) ?
?|?SLxI?
bought father a Philips PT720 (Electric Razor).
?^(use) ?^N95???$?/
use N95 (mouth mask) to reduce the impact of bad air
? ?Galaxy S4
(recommend) recommend Galaxy S4 (cell phone)
Related product identification and annotation.
For each trend, we have the product keyword set to-
gether with the trend keywords as described above.
We use these keywords to retrieve candidate prod-
ucts in the product search engine of Taobao with-
in the active interval of the trend. For each can-
didate product, we further crawl its product page
and obtain corresponding related products suggest-
ed by Taobao, which are treated as candidate, too.
We invite two senior post-graduate students major
in economics as human judges. The judge is re-
quired to make a binary decision whether a product
is related to a trend by following a detailed guide-
line compiled by a senior officer of an e-commerce
company in Beijing. For each trend, we provide the
trend keywords, product keywords in tweets, relat-
ed tweets, related news articles from China Daily6.
Web access is available during the annotation pro-
cess. Due to space limit, we do not present the an-
notation guideline here. We use Cohen?s kappa to
measure the agreement of these two judges, which
has a high value of 0.75. To speed up the work,
we further group all products which have the same
lowest categorial label (e.g., leaf label) 7, and we
6http://www.chinadaily.com.cn
7Taobao has provided a category tree for products:
http://list.taobao.com/browse/cat-0.htm).
1339
will treat a group as a product in later experiments.
We only keep the products with the same judgments
and the trends with at least one related product. We
present the statistics of data set in Table 3 8. Since
current e-commerce search engines mainly adop-
t keyword matching based retrieval method, we fur-
ther examine the performance of simply using trend
keywords as queries. We compute the percentage
of related/unrelated products with at least one trend
keyword in their description. We can see that on-
ly 29.7% related products can be found on average.
These statistics indicate that more effective methods
are needed for the current task.
Table 3: Statitics of the data set.
# business-related trends 113
average candidate products per trend 55.1
average related products per trend 7.3
average perc. of rel. prod. with trend keywords 29.7%
average perc. of unrel. prod. with trend keywords 6.3%
3.2 Observations
Now we analyze the data collection and present our
observations.
A1: First of all, it is important to find out the pro-
portion of hot trends that potentially leads to busi-
ness opportunities. Recall that each trend has a cat-
egory label and possibly a set of related products i-
dentified by the judges. We refer to a trend with
related products as a business-related trend. We
present the statistics in Fig. 1. We can see that
about 36% of all trends have corresponding relat-
ed products in Taobao, which indicates that these
trends highly relate to business. Movies and Sport-
s have higher proportions of business-related trend-
s, i.e. 81% and 52% respectively, while the other
categories have lower proportions but still with a
substantial number of business related trends. It is
noteworthy that Business has the lowest proportion,
the major reason is that trends in Business are usual-
ly general events, i.e., the release of new economic
policy, which do not directly correspond to related
products. As we discussed earlier, these trends may
have indirect impact on product sales. Currently,
we only focus on direct impact, and indirect impacts
will be considered in future work.
8The data set can be downloaded at http://sewm.pku.
edu.cn/?wjp.
Next we continue to examine the impact of hot
trends on the sale of related products. We obtain
product sales from Taobao product pages. As we can
see in Fig. 2, the average sale of related products in
all categories gradually increased with trends going
on. Interestingly, we can see that categories Movies
and China achieved very significant increase. Prod-
ucts related to Movies trends are usually related to
the movie itself, e.g., movie tickets; while prod-
ucts related to China tend to be commodities (e.g.,
the mouth masks for the trend of ?Air Pollution?)
or trending products (e.g., Shenzhou-10 Spacecraft
Model for the trend of ?the launch of Shenzhou-
10?).
business person sports China movie
# tr
end
s
0
20
40
60
80
100
120
140
160
% b
usin
ess
-rea
ted 
tren
ds
0%
20%
40%
60%
80%
100%
busi.-related trends
other trend% busi.-reated trends
Figure 1: The proportion and volume of business-related
trends in five categories.
A2: Recall we have discussed that product asso-
ciativity is useful for improving the coverage of re-
lated products. Here we would like to quantitatively
examine the associativity between related products
given a trend. For a trend, we first compute the av-
erage pairwise similarity between related products
in terms of their descriptive texts (e.g. title and de-
scription). Since there are more unrelated products,
we randomly sample an equal number of unrelated
products from the candidate products we previously
generated. Then we compute the average similarity
between a related product and an unrelated product.
We further average these values over all the trends
of each category. The average similarity of related-
related product pairs is 0.112, while the average sim-
ilarities of unrelated-unrelated and related-unrelated
1340
Days0 1 2 3 4 5 6
Gro
wth
 rat
e of
 sal
es v
olum
e
1.00
1.02
1.04
1.06
1.08
1.10
1.12
1.14
1.16
1.18
businessperson
sportsChina
movie
Figure 2: An illustrative analysis of the impact on related
products in five categories. We measure the impact by
computing the average growth ratio of sale in Taobao.
product pairs are 0.039 and 0.058 respectively.9
In summary, A1 indicates that a large proportion
of hot trends are potentially related to products and
will exert positive effects on product sale; A2 in-
dicates that there is a strong associativity between
related products, which can be utilized to improve
both precision and recall of the algorithm.
4 The Proposed Method
In this section, we present a graph based ranking al-
gorithm jointly models the relevance of a product
and the associativity between products. Recall that
we have collected a set of product keywords and a
set of candidate products for each trend. Our aim is
to re-rank these candidate products to obtain a better
ranking of related products. We adopt a biased ran-
dom walk algorithm: 1) relevance is modeled as bi-
ased restart probability and 2) associativity is mod-
eled through random walk on the product graph.
4.1 Modeling the Product Relevance
Recall that in Section 2 we use the pattern based
method to extract product keywords from tweets re-
lated to a trend. However, to stimulate the real sce-
nario that we want to identify the related products at
the beginning of a trend, we only keep the keyword-
s which were contained in tweets published in the
first three days when a trend began. These extracted
9The difference was tested to be statistically significant.
product keywords directly reveal users? commercial
intents on the trends. Instead of modeling person-
alized intents, we consider learning a unified trend-
driven intent by representing the intent as a weighted
vector over these product keywords. And the key is
how to set the keyword weight.
Keyword weighting. A good weighting method
should be able to leverage commercial interest-
s/intents of users well and emphasize the keyword-
s users really focus on. Thus we consider making
use of the retweeting (a.k.a. forwarding) mechanis-
m in microblogs. Retweet links are shown to be bet-
ter in revealing relevance and interests (Welch et al,
2011). Formally, we use the following weighting
formula for a keyword k:
Weight(k) =
?
t?Ck
log10 (#rtt + 1), (1)
where Ck is the set of all originally-written tweets
(i.e., not a retweet) that contain the keyword k in
the considered time span, and #rtt is the retweet
number of a tweet t. We further normalize and build
the weight vector over all the considered keywords,
called as intent vector. We denote the intent vector
of a trend e by ~e.
Product relevance. Having the intent vector, now
we discuss about how to define the product rele-
vance. Given a product p, we extract all the words in
the title and description parts of a product. We rep-
resent it as a vector using the widely tf-idf weighting
method. We denote the weight vector of product p
by ~p. We measure the product relevance between e
and p as rel(e, p) = ~e?~p|~e||~p| .
4.2 Modeling the Associativity between
Products
To start this part, we first present an illustrative ex-
ample in Fig. 3. We can see there are four relat-
ed products for the trend ?Air Pollution?. We as-
sume that only ?mouth mask? was mentioned in mi-
croblogs. Now we expect to mine more related prod-
ucts with ?mouth mask? as a known related produc-
t. We can compute the similarity between a pair of
products. Intuitively, if the similarity between a can-
didate product and ?mouth mask? is higher than a
predefined threshold, we can consider it to be relat-
ed, too. In this example, ?air detector? and ?air pu-
rifier? are similar to ?mouth mask? in terms of prod-
1341
Figure 3: An example to illustrate the importance of as-
sociativity. Products which were mentioned in tweets related to ?Air
Pollution? are marked in red circles while the others are marked in blue
circles. The link between products indicate the similarity between two
products. Links with weights lower than a predefined threshold are not
considered. Although ?green plants? is related to this trend, it was not
mentioned in tweets and did not have a direct link to ?mouth mask?.
uct descriptions and considered to be related, while
?Green plants? is determined to be unrelated since
it has very little overlap words with ?mouth mask?
in the description. It indicates one-step similarity
method is not able to fully capture the real associa-
tivity between products.
Thus, we propose to use the random walk method
to propagate the relatedness score on the produc-
t graph. Let P denote the number of all the can-
didate products, and rP?1 denote the relatedness s-
core vector where ri denote the relatedness score of
product pi.
We first construct the product graph. We repre-
sent each candidate product as a vertex in the graph
and built the link with the cosine similarity between
the descriptive texts of two products as the link
weight.10 We denote the similarity matrix byMP?P
and Mi,j denotes the similarity between products pi
and pj . Formally, we formulate the problem in a s-
tandard PageRank form
r(n+1) = ? ? r(n) ?M+ (1? ?) ? y, (2)
where y is the restart probability vector usually
set to be uniform. With this method, it is easy to
see that relatedness score can be propagated on the
product graph, which better captures underlying as-
sociativity between products.
10Other similarity methods can be used, e.g., co-purse history
record.
4.3 Jointly Modeling Relevance and
Associativity
Having discussed about how to model both rele-
vance and associativity, now we are ready to present
a joint model to capture these two factors. By fol-
lowing (Zhao et al, 2013), the main idea is that in-
stead of using a uniform restart distribution y, we
use an relevance biased restart distribution in E-
q. 2. We set the restart probability of a produc-
t to its corresponding relevance. Formally, we set
yi = rel(e, pi). Let us further explain the idea. At
the beginning of each iteration, each product is first
assigned to its relevance score: the more relevant it
is, the larger score it has. During the iteration, each
product begins to collect relevance evidence from its
neighbors on the product graph: the more relevan-
t neighbors it has, the larger score it obtains. And
the final score is indeed a trade-off between its own
relevance score and neighboring relevance scores it
receives. In order to obtain an ergodic walk, we add
a small value, i.e. 1e ? 4, to each entry of y and
then normalize this vector. We denote our algorithm
as JMRA (Jointly Modeling Relevance and Associa-
tivity).
To have an intuitive understanding of our algo-
rithm, let us turn to the example in Fig. 3 again. At
the beginning, only ?mouth mask? has a large rele-
vance score, with the iteration going on, the related-
ness score will be propagated between products on
the graph. Although ?green plants? has not a direct
link with ?mouth mask?, it can obtain relatedness s-
core from its neighbors, i.e. ?air detector? and ?air
purifier?. JMRA is able to discover such latent asso-
ciativity between products.
5 Experimental Setup
We use the test collection which have been described
in Section 3. The statistics of the data set is shown
in Table 3.
5.1 Evaluation Metrics
For a real product search engine, top results are par-
ticularly important, thus we adopt precision@5 and
precision@10 as the evaluation metrics. Similar to
Information Retrieval, we also consider using Mean
Average Precision (MAP) as metrics to measure the
overall quality of retrieved products.
1342
5.2 Methods to Compare
We compare the following methods for inferring re-
lating products:
SALES: we rank the candidate products by their
historical sales volume descendingly.
TREND: we use trend keywords as queries and rank
the products by their relevance.
TREND+fb: based on TREND, we further incorpo-
rate pseudo-relevance feedback (Salton, 1971;
Salton and Buckley, 1997). After some tun-
ing (See Section 6.5), top 3 search results were
used to update the query.
JMRAr: it is our method which only considers
product relevance in Section 4.1.
JMRAr + fb: we further apply pseudo-relevance
feedback to JMRAr.
JMRAr+a: it is our method which considers both
relevance and associativity in Section 4.3.
JMRAr+a+fb: we further apply pseudo-relevance
feedback to JMRAr+a.
6 Experimental Results and Analysis
In this section, we first evaluate the performance of
the proposed approach and the comparison method-
s. Next, we analyze a problem in real e-commerce
search engines, i.e., the cold start. Then, we give
a qualitative case study to further demonstrate the
effectiveness of the proposed approach. Finally,
we examine the parameter sensitivity to the perfor-
mance.
6.1 Comparison of Performance
We present the results of various methods in Table
4. We first examine the performance of baselines
SALES, TREND and TREND+fb. First, SALES has
the worst performance due to the fact that a trend
usually happen unexpectedly and historical records
may not predict it well. The second observation is
that the improvement of TREND+fb over TREND is
little. This is mainly because that very few related
products can be identified only based on trend key-
words so feedback method does not work very well
on it.
Then we compare our relevance based method-
s with the above three baselines. Note that the
major difference between JMRAr and TREND is
that JMRAr makes uses of both trend keywords
and product keywords extracted from microblogs.
We can see that JMRAr performs better than al-
l three baselines. It proves the effectiveness of lever-
aging commercial intents from microblogs. An-
other interesting point is that the relative improve-
ment JMRAr+fb over JMRAr is larger than that
TREND+fb over TREND. The reason is that pseudo
relevance feedback relies highly on top results and a
system with better search quality will benefit more
from it.
Finally, we consider evaluating our full models
which jointly consider relevance and associativity. It
is easy to see JMRAr+a yields a significant improve-
ment over JMRAr and even outperforms JMRAr+fb.
This observation supports our assumption that prod-
uct associativity is very important in this task. A-
gain, pseudo relevance feedback has also improved
JMRAr+a.
In summary, our results have shown some impor-
tant implications for trend-related product retrieval
on e-commerce search engines: 1) microblogs are
very good signals to learn users? commercial intents;
2) product associativity is particularly important; 3)
other advanced retrieval methods are potentially use-
ful, e.g., pseudo relevance feedback.
Table 4: The overall performance of all the methods.
Models P@5 P@10 MAP
SALES 0.345 0.379 0.225
TREND 0.543 0.325 0.327
TREND+fb 0.550 0.325 0.328
JMRAr 0.611 0.527 0.336
JMRAr+fb 0.661 0.552 0.348
JMRAr+a 0.733 0.609 0.392
JMRAr+a+fb 0.734 0.624 0.404
6.2 Cold Start
It is noteworthy that we have considered all the can-
didate products within the entire active interval of a
trend when constructing the test collection. This is
mainly to obtain a good coverage of related product-
s since some e-commerce companies might release
new products as the response to a trend. During the
active interval of a trend, the e-commerce companies
may make some heuristic rules to enhance the re-
trieval of related products, e.g., incorporating trend
keywords into product titles and descriptions. In the
1343
real application scenario, an effective method is ex-
pected to identify related products at the beginning
of a trend when the e-commerce workers may not
make any response to the trend. How would it be
if we do not have the manually generated trend key-
words from workers in product titles and descrip-
tions?
To answer the question, in this part, we contin-
ue to examine the impact of cold start on different
methods. We select three methods as comparisons,
i.e., TREND+fb, JMRAr + fb and JMRAr+a + fb.
We first use keyword matching methods to obtain
all the products that related to trend keywords. The
descriptive text (i.e., title and description) of these
products has been refined to match trend queries by
sellers in e-commerce websites. We further removed
all the trend keywords in the desriptive text of these
products, and gradually add the trend keywords back
to original products. In such a process, we would
like to examine how cold start affects the perfor-
mance of different methods.
0% 20% 40% 60% 80% 100%
P@
10
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
JMRAr + fbJMRAr+a + fbTREND + fb
Figure 4: The impact of cold start for different meth-
ods.
We present the results in Fig. 4. First, per-
formance of all these methods improve with the
increase of products with trend keywords. Sec-
ond, cold start does not affect the relative perfor-
mance order of different methods, i.e., TREND+fb
< JMRAr + fb < JMRAr+a + fb. Finally, all the
methods display similar impact patterns: ?signifi-
cantli increasing? ? ?stable?. An interesting ob-
servation is that JMRAr + fb and JMRAr+a + fb
have much more stable performance compared to
TREND+fb. It indicates that our methods are very
robust to the cold start, and potentially applicable in
real e-commerce search engines.
6.3 Case Study
In order to have a intuitive understanding of how
different method perform, we present a case study
in this part. We select JMRAr, JMRAr+fb and
JMRAr+a+fb as comparisons. The results are shown
in Table 5. We can see that JMRAr+a+fb have iden-
tified the most related products. We further analyze
the contribution of different factors. Compared with
JMRAr, JMRAr+fb has got one more related prod-
uct ?Houseplant? due to the reason pseudo feedback
can make use of top related search results to im-
prove the queries. In this case, ?Houseplant? is i-
dentified to be related because it is very similar to
?Air Detector? (We have presented the correspond-
ing most associative products in brackets in Table 5).
Similarly, the comparison between JMRAr+fb and
JMRAr+a+fb shows the effectiveness of product as-
sociativity.
6.4 Error Analysis
To further understand the shortcomings of the pro-
posed methods, we use the example in Table 5 for er-
ror analysis. Based on our manual inspection, errors
may arise from two major sources for our method:
? Product keyword extraction errors: we use
a pattern-based product keyword extraction
method, and it tends to incorporate some irrel-
evant words. For example, given the topic ?air
pollution?, users would talk about the impact
of ?car exhaust? on air quality and advocate to
reduce automobile usage and sale. The current
keyword extraction method might mistake the
word ?car? for a product related keyword.
? Search engine retrieval errors: in this paper,
we rely on the Taobao product search engine
for candidate product generation. It is high-
ly based on surface-form matching to retrieve
related products. Therefore, given a query
?mouth mask?, it might return some irrelevant
products, e.g., ?party mask?. Clearly, pseudo-
relevance feedback will also bring additional ir-
relevant products if top search results contain
irrelevant ones.
1344
Table 5: A qualitative comparison of three methods on the topic of ?Air Pollution?. We mark related products in bold.
Sample keywords learnt from microblogs:
air pollution, mouth mask, air, air purifier, respirator, house, mask,
warm, bus, car, purified water
JMRAr JMRAr+fb JMRAr+a+fb
Mouth Mask Mouth Mask Mouth Mask
Air Detector Air Detector Air Purifier
Air Purifier Air Purifier Air Detector
Toy House Humidifier Respirator
Respirator Respirator Oxygen Bag (Mouth Mask)
Toy Car Party Mask Humidifier
Environment-friendly Bags Toy Car Houseplant (Air Detector)
Humidifier Houseplant (Air Detector) Anti-pollution Medicine (Oxygen Bag)
Purified Water Environment-friendly bags Purified Water
Warmer Purified Water Party Mask
(a)
0 2 4 6 8 10
P@10
0.54
0.56
0.58
0.60
0.62
0.64 JMRAr + fbJMRAr+a + fb
(b)
Figure 5: Parameter sensitivity. a) The impact of the
damping factor ? and b) the impact of the number of top
products used for pseudo feedback.
To solve these problems, one promising way is to
leverage more context information about the candi-
date products and construct deep semantic analysis.
We will leave it as future work.
6.5 Parameter Sensitivity
The only parameter for JMRA is the damping fac-
tor in the random walk model, i.e., ?. Intuitively,
a larger value of ? emphasize the associativity more
while a smaller value emphasize the relevance more.
We tune this parameter at a step of 0.1 and present
the results in Fig. 5(a). We can see the performance
of JMRAr+a+fb is consistently better than that of
JMRAr+fb and peaks at around ?0.8?. It indicates
the robustness of JMRAr+a+fb and the importance
of product associtivity.
We further examine the impact of the num-
ber of top products used for pseudo feedback for
JMRAr+fb and JMRAr+a+fb. In Fig. 5(b), we can
see that both JMRAr+a+fb and JMRAr+fb achieved
their best at ?3?. It indicates that we only need to
consider very top results for pseudo feedback.
6.6 Title or Description?
In previous experiments, for each product, we used
the descriptive text in both title and description. In
this part, we consider examining the individual ef-
fect of title and description. We use JMRAr+a+fb as
the examined method since both relevance and asso-
ciativity relies on the text information.
Table 6: Evaluating the performance of JMRAr+a+fb
with different text sources.
sources P@5 P@10 MAP
title 0.690 0.591 0.364
description 0.711 0.602 0.387
title+description 0.734 0.624 0.404
As shown in Table 6, we can see that the perfor-
mance of only using description is better than that
of only using title and a combination of both parts
achieve the best. title is usually carefully compiled
by e-commerce sellers, thus it reveals the most high-
lights of the products but very short; while descrip-
tion contains more informative text but tends to in-
corporate noise. In future work, we will consider a
more principled way to combine title and descrip-
tion, e.g., weighted combination.
1345
6.7 Efficiency
Finally, we present a few discussions about the issue
of efficiency. All codes were implemented in Python
2.7, and all experiments were performed on a PC
with Intel(R) Core(TM)i5 CPU 760 @ 2.8GHz and
8GB memory.
Sicne we group products by the categorial label,
the number of candidate products is usually very s-
mall. Thus, our method JMRA runs very efficiently.
Even on an extremely large set of candidate product-
s, the iterative random walk algorithm can be easily
implemented in a distributed way (Bahmani et al,
2011) and would have very good efficiency.
7 Related Work
Our work is mainly related to the following lines:
Mining the microblogs. Microblogs have been
one of the most popular social networking platform-
s, and they have recently attracted much attention
from research communities. The studies on trend
(or event) detection (Benson et al, 2011; Weng and
Lee, 2011; Sakaki et al, 2010; Zhao et al, 2012)
tried to make use of the rapid response of microblogs
users as the signal to automatically identify exter-
nal events. Another important aspect is the content
analysis of tweets, including the recommendation of
real-time topical news (Phelan et al, 2009), senti-
ment or opinions analysis (Meng et al, 2012), event
summarization using tweets (Chakrabarti and Puner-
a, 2011; Lin et al, 2012; Zhao et al, 2013), etc. Our
work do not explicitly incorporate a trend detection
component, instead we make use of the trending top-
ics provided by the microblogs platforms. It will be
easy to incorporate other trend detection methods as
our input.
Identifying online users? commercial intents.
The identification of online users? commercial in-
tents has been quite an important research prob-
lem in the past. Most researches focus on captur-
ing commercial intention from search queries (Dai
et al, 2006; Strohmaier and Kro?ll, 2012), click-
through behaviors (Ashkan and Clarke, 2009), user-
s? mouse movements or scrolling behaviors (Guo
and Agichtein, 2010) and search logs (Strohmaier
and Kro?ll, 2012). The most related to our work is
the work in (Hollerit et al, 2013), which attempts to
detect commercial intent on twitter. But we have
very different focus. They aim to identify tweet-
level commercial intents while ours aim to identify
trend-driven commercial intents. In addition, we al-
so present how to make use of these identified intents
and our paper focuses on how to identify trend relat-
ed products for e-commerce companies to improve
service when faced with hot trends.
8 Conclusions
In this paper, we make the first attempt to identify
trend related products by leveraging commercial in-
tents from microblogs. We propose a way to con-
struct the evaluation set for this task and present
some insightful findings. We propose a graph based
method to joint model relevance and associativity.
We perform extensive experiments, including quan-
titative and qualitative analysis.
Currently, our approach is indeed a framework
to solve this task, and we may consider improving
the individual components in it, e.g. consider non-
product keywords in tweets. For future work, we
will consider incorporating a trend detection com-
ponent into our method, which can be more flexible
to adapt to various trend signals. We can also refine
the method of the product keyword extraction by us-
ing more principled solutions.
Acknowledgments
We thank the anonymous reviewers for the construc-
tive comments. The work was partially supported by
NSFC Grant 60933004, 61073082 and 61272340.
Jinpeng Wang was supported by the Singapore Na-
tional Research Foundation under its IDM Futures
Funding Initiative and administered by the Interac-
tive & Digital Media Programme Office, Media De-
velopment Authority. We thank Taobao for the ac-
cess to the product data and all Taobao data in this
paper will be only used for research purpose.
References
Azin Ashkan and Charles LA Clarke. 2009. Term-
based commercial intent analysis. In Proceedings
of the 32nd international ACM SIGIR conference on
Research and development in information retrieval,
pages 800?801. ACM.
Bahman Bahmani, Kaushik Chakrabarti, and Dong Xin.
2011. Fast personalized pagerank on mapreduce. In
1346
Proceedings of the 2011 ACM SIGMOD Internation-
al Conference on Management of data, SIGMOD ?11,
pages 973?984, New York, NY, USA. ACM.
Edward Benson, Aria Haghighi, and Regina Barzilay.
2011. Event discovery in social media feeds. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies-Volume 1, pages 389?398. Association
for Computational Linguistics.
Deepayan Chakrabarti and Kunal Punera. 2011. Event
summarization using tweets. In Proceedings of the 5th
Int?l AAAI Conference on Weblogs and Social Media
(ICWSM), July.
Honghua Kathy Dai, Lingzhi Zhao, Zaiqing Nie, Ji-Rong
Wen, Lee Wang, and Ying Li. 2006. Detecting online
commercial intention (oci). In Proceedings of the 15th
international conference on World Wide Web, pages
829?837. ACM.
Qi Guo and Eugene Agichtein. 2010. Ready to buy or
just browsing?: detecting web searcher goals from in-
teraction data. In Proceedings of the 33rd internation-
al ACM SIGIR conference on Research and develop-
ment in information retrieval, pages 130?137. ACM.
Bernd Hollerit, Mark Kro?ll, and Markus Strohmaier.
2013. Towards linking buyers and sellers: detect-
ing commercial intent on twitter. In Proceedings of
the 22nd international conference on World Wide Web
companion, pages 629?632. International World Wide
Web Conferences Steering Committee.
Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue
Moon. 2010. What is Twitter, a social network or a
news media? In WWW ?10: Proceedings of the 19th
international conference on World wide web, pages
591?600. ACM.
Jure Leskovec, Lars Backstrom, and Jon Kleinberg.
2009. Meme-tracking and the dynamics of the news
cycle. In Proceedings of the 15th ACM SIGKDD inter-
national conference on Knowledge discovery and data
mining, KDD ?09, pages 497?506, New York, NY, US-
A. ACM.
Chen Lin, Chun Lin, Jingxuan Li, Dingding Wang, Yang
Chen, and Tao Li. 2012. Generating event storylines
from microblogs. In Proceedings of the 21st ACM in-
ternational conference on Information and knowledge
management, pages 175?184. ACM.
Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou, Sujian
Li, and Houfeng Wang. 2012. Entity-centric topic-
oriented opinion summarization in twitter. In Proceed-
ings of the 18th ACM SIGKDD international confer-
ence on Knowledge discovery and data mining, pages
379?387. ACM.
Owen Phelan, Kevin McCarthy, and Barry Smyth. 2009.
Using twitter to recommend real-time topical news. In
Proceedings of the third ACM conference on Recom-
mender systems, pages 385?388. ACM.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes twitter users: real-time event
detection by social sensors. In Proceedings of the 19th
international conference on World wide web, WWW
?10, pages 851?860, New York, NY, USA. ACM.
Gerard Salton and Chris Buckley. 1997. Readings in
information retrieval. chapter Improving retrieval per-
formance by relevance feedback, pages 355?364. Mor-
gan Kaufmann Publishers Inc., San Francisco, CA,
USA.
Gerard Salton, editor. 1971. The SMART Retrieval Sys-
tem - Experiments in Automatic Document Processing.
Prentice Hall, Englewood, Cliffs, New Jersey.
Markus Strohmaier and Mark Kro?ll. 2012. Acquiring
knowledge about human goals from search query logs.
Information Processing & Management, 48(1):63?82.
Michael J. Welch, Uri Schonfeld, Dan He, and Junghoo
Cho. 2011. Topical semantics of twitter links. In Pro-
ceedings of the fourth ACM international conference
on Web search and data mining, WSDM ?11, pages
327?336, New York, NY, USA. ACM.
Jianshu Weng and Bu-Sung Lee. 2011. Event detection
in Twitter. In Proceedings of the Fifth International
Conference on Weblogs and Social Media (ICWSM),
Menlo Park, CA, USA. AAAI.
Wayne Xin Zhao, Baihan Shu, Jing Jiang, Yang Song,
Hongfei Yan, and Xiaoming Li. 2012. Identifying
event-related bursts via social media activities. In
EMNLP-CoNLL, pages 1466?1477.
Wayne Xin Zhao, Yanwei Guo, Rui Yan, Yulan He, and
Xiaoming Li. 2013. Timeline generation with so-
cial attention. In Proceedings of the 36th international
ACM SIGIR conference on Research and development
in information retrieval, SIGIR ?13, pages 1061?1064.
1347
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 43?47,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
A Novel Burst-based Text Representation Model
for Scalable Event Detection
Wayne Xin Zhao?, Rishan Chen?, Kai Fan?, Hongfei Yan?? and Xiaoming Li??
?School of Electronics Engineering and Computer Science, Peking University, China
?State Key Laboratory of Software, Beihang University, China
{batmanfly,tsunamicrs,fankaicn,yhf1029}@gmail.com, lxm@pku.edu.cn
Abstract
Mining retrospective events from text streams
has been an important research topic. Classic
text representation model (i.e., vector space
model) cannot model temporal aspects of doc-
uments. To address it, we proposed a novel
burst-based text representation model, de-
noted as BurstVSM. BurstVSM corresponds
dimensions to bursty features instead of terms,
which can capture semantic and temporal in-
formation. Meanwhile, it significantly reduces
the number of non-zero entries in the repre-
sentation. We test it via scalable event de-
tection, and experiments in a 10-year news
archive show that our methods are both effec-
tive and efficient.
1 Introduction
Mining retrospective events (Yang et al, 1998; Fung
et al, 2007; Allan et al, 2000) has been quite an im-
portant research topic in text mining. One standard
way for that is to cluster news articles as events by
following a two-step approach (Yang et al, 1998):
1) represent document as vectors and calculate simi-
larities between documents; 2) run the clustering al-
gorithm to obtain document clusters as events.1 Un-
derlying text representation often plays a critical role
in this approach, especially for long text streams. In
this paper, our focus is to study how to represent
temporal documents effectively for event detection.
Classical text representation methods, i.e., Vector
SpaceModel (VSM), have a few shortcomings when
dealing with temporal documents. The major one is
that it maps one dimension to one term, which com-
pletely ignores temporal information, and therefore
VSM can never capture the evolving trends in text
streams. See the example in Figure 1, D1 and D2
?Corresponding author.
1Post-processing may be also needed on the preliminary
document clusters to refine the results.
!" !#
$%&'
()*+*
,-./01#223 ,-./01#224
Figure 1: A motivating example. D1 and D2 are news
articles about U.S. presidential election respectively in
years 2004 and 2008.
may have a high similarity based on VSM due to the
presence of some general terms (e.g., ?election?) re-
lated to U.S. presidential election, although general
terms correspond to events in different periods (i.e.,
November 2004 and November 2008). Temporal
information has to be taken into consideration for
event detection. Another important issue is scala-
bility, with the increasing of the number in the text
stream, the size of the vocabulary, i.e., the number
of dimensions in VSM, can be very large, which re-
quires a considerable amount of space for storage
and time for downstream processing.
To address these difficulties, in this paper, we pro-
pose a burst based text representation method for
scalable event detection. The major novelty is to nat-
urally incorporate temporal information into dimen-
sions themselves instead of using external time de-
caying functions (Yang et al, 1998). We instantiate
this idea by using bursty features as basic representa-
tion units of documents. In this paper, bursty feature
refers to a sudden surge of the frequency of a single
term in a text stream, and it is represented as the term
itself together with the time interval during which
the burst takes place. For example, (Olympic,
Aug-08-2008, Aug-24-2008)
2 can be regarded
as a bursty feature. We also call the term in a bursty
2Beijing 2008 Olympic Games
43
feature its bursty term. In our model, each dimen-
sion corresponds to a bursty feature, which contains
both temporal and semantic information. Bursty fea-
tures capture and reflect the evolving topic trends,
which can be learnt by searching surge patterns in
stream data (Kleinberg, 2003). Built on bursty fea-
tures, our representation model can well adapt to text
streams with complex trends, and therefore provides
a more reasonable temporal document representa-
tion. We further propose a split-cluster-merge algo-
rithm to generate clusters as events. This algorithm
can run a mutli-thread mode to speed up processing.
Our contribution can be summarized as two as-
pects: 1) we propose a novel burst-based text rep-
resentation model, to our best knowledge, it is the
first work which explicitly incorporates temporal in-
formation into dimensions themselves; 2) we test
this representation model via scalable event detec-
tion task on a very large news corpus, and extensive
experiments show the proposed methods are both ef-
fective and efficient.
2 Burst-based Text Representation
In this section, we describe the proposed burst-based
text representation model, denoted as BurstVSM. In
BurstVSM, each document is represented as one
vector as in VSM, while the major novelty is that one
dimension is mapped to one bursty feature instead
of one term. In this paper, we define a bursty fea-
ture f as a triplet (wf , tfs , t
f
e ), where w is the bursty
term and ts and te are the start and end timestamps
of the bursty interval (period). Before introducting
BurstVSM, we first discuss how to identify bursty
features from text streams.
2.1 Burst Detection Algorithm
We follow the batch mode two-state automaton
method from (Kleinberg, 2003) for bursty feature
detection.3 In this model, a stream of documents
containing a term w are assumed to be generated
from a two-state automaton with a low frequency
state q0 and a high frequency state q1. Each state
has its own emission rate (p0 and p1 respectively),
and there is a probability for changing state. If an
interval of high states appears in the optimal state
sequence of some term, this term together with this
interval is detected as a bursty feature. To obtain
all bursty features in text streams, we can perform
burst detection on each term in the vocabulary. In-
stead of using a fixed p0 and p1 in (Kleinberg, 2003),
by following the moving average method (Vlachos
3The news articles in one day is treated as a batch.
et al, 2004) ,we parameterize p0 and p1 with the
time index for each batch, formally, we have p0(t)
and p1(t) for the tth batch. Given a term w, we
use a sliding window of length L to estimate p0(t)
and p1(t) for the tth batch as follows: p0(t) =?
j?Wt
Nj,w?
j?Wt
Nj
and p1(t) = p0(t) ? s, where Nj,w and
Nj are w ?s document frequency and the total num-
ber of documents in jth batch respectively. s is a
scaling factor lager than 1.0, indicating state q1 has
a faster rate, and it is empirically set as 1.5. Wt is a
time interval [max(t?L/2, 0), min(t+L/2, N)], and
the length of moving window L is set as 180 days.
All the other parts remain the same as in (Kleinberg,
2003). Our detection method is denoted as TVBurst.
2.2 Burst based text representation models
We apply TVBurst to all the terms in our vocabu-
lary to identify a set of bursty features, denoted as
B. Given B, a document di(t) with timestamp t is
represented as a vector of weights in bursty feature
dimensions:
di(t) = (di,1(t), di,2(t), ..., di,|B|(t)).
We define the jth weight of di as follows
di,j =
?
tf-idfi,wBj , if t ? [t
Bj
s , t
Bj
e ] ,
0, otherwise.
When the timestamp of di is in the bursty inter-
val of Bj and contains bursty term wBj , we set up
the weight using common used tf-idf method. In
BurstVSM, each dimension is mapped to one bursty
feature, and it considers both semantic and temporal
information. One dimension is active only when the
document falls in the corresponding bursty interval.
Usually, a document vector in BurstVSM has only
a few non-zero entries, which makes computation of
document similarities more efficient in large datasets
compared with traditional VSM.
The most related work to ours is the boostVSM
introduced by (He et al, 2007b), it proposes to
weight different term dimensions with correspond-
ing bursty scores. However, it is still based on term
dimensions and fails to deal with terms with mul-
tiple bursts. Suppose that we are dealing with a
text collection related with U.S. presidential elec-
tions, Fig. 2 show sample dimensions for these three
methods. In BurstVSM, one term with multiple
bursts will be naturally mapped to different dimen-
sions. For example, two bursty features ( presiden-
tial, Nov., 2004) and ( presidential, Nov., 2008 ) cor-
respond to different dimensions in BurstVSM, while
44
Figure 2: One example for comparisons of different rep-
resentation methods. Terms in red box correspond to
multiple bursty periods.
Table 1: Summary of different representation models.
Here dimension reduction refers to the reduction of non-
zero entries in representation vector.
semantic temporal dimension trend
information information reduction modeling
VSM ? ? ? bad
boostVSM ? partially ? moderate
BurstVSM ? ? ? good
VSM and boostVSM cannot capture such temporal
differences. Some methods try to design time de-
caying functions (Yang et al, 1998), which decay
the similarity with the increasing of time gap be-
tween two documents. However, it requires efforts
for function selection and parameters tuning. We
summarize these discussions in Table 1.
3 split-cluster-merge algorithm for event
detection
In this section, we discuss how to cluster documents
as events. Since each document can be represented
as a burst-based vector, we use cosine function to
compute document similarities. Due to the large size
of our news corpus, it is infeasible to cluster all the
documents straightforward. We develop a heuristic
clustering algorithm for event detection, denoted as
split-cluster-merge, which includes three main steps,
namely split, cluster and merge. The idea is that we
first split the dataset into small parts, then cluster
the documents of each part independently and finally
merge similar clusters from two consecutive parts.
In our dataset, we find that most events last no more
than one month, so we split the dataset into parts by
months. After splitting, clustering can run in paral-
lel for different parts (we useCLUTO4 as the cluster-
ing tool), which significantly reduces total time cost.
For merge, we merge clusters in consecutive months
with an empirical threshold of 0.5. The final clusters
4www.cs.umn.edu/k?arypis/cluto
are returned as identified events.
4 Evaluation
4.1 Experiment Setup
We used a subset of 68 millon deduplicated
timestamped web pages generated from this
archive (Huang et al, 2008). Since our major focus
is to detect events from news articles, we only keep
the web pages with keyword ?news? in URL field.
The final collection contains 11, 218, 581 articles
with total 1, 730, 984, 304 tokens ranging from 2000
to 2009. We run all the experiments on a 64-bit linux
server with four Quad-Core AMD Opteron(tm) Pro-
cessors and 64GB of RAM. For split-cluster-merge
algorithm, we implement the cluster step in a multi-
thread mode, so that different parts can be processed
in parallel.
4.2 Construction of test collection
We manually construct the test collection for event
detection. To examine the effectiveness of event de-
tection methods in different grains, we consider two
type of events in terms of the number of relevant
documents, namely significant events and moder-
ate events. A significant event is required to have
at least 300 relevant docs, and a moderate event is
required to have 10 ? 100 relevant docs. 14 grad-
uate students are invited to generate the test collec-
tion, starting with a list of 100 candidate seed events
by referring to Xinhua News.5 For one target event,
the judges first construct queries with temporal con-
straints to retrieve candidate documents and then
judge wether they are relevant or not. Each doc-
ument is assigned to three students, and we adopt
the majority-win strategy for the final judgment. Fi-
nally, by removing all candidate seed events which
neither belong to significant events nor moderate
events, we derive a test collection consisting of 24
significant events and 40 moderate events.6
4.3 Evaluation metrics and baselines
Similar to the evaluation in information retrieval ,
given a target event, we evaluate the quality of the
returned ?relevant? documents by systems. We use
average precision, average recall and mean average
precision(MAP) as evaluation metrics. A difference
is that we do not have queries, and the output of a
system is a set of document clusters. So for a sys-
tem, given an event in golden standard, we first se-
lect the cluster (the system generates) which has the
5http://news.xinhuanet.com/english
6For access to the code and test collection, contact Xin Zhao
via batmanfly@gmail.com.
45
Table 2: Results of event detection. Our proposed method is better than all the other baselines at confidence level 0.9.
Signifcant Events Moderate Events
P R F MAP P R F MAP
timemines-?2(nouns) 0.52 0.2 0.29 0.11 0.22 0.27 0.24 0.09
timemines-?2(NE) 0.61 0.18 0.28 0.08 0.27 0.25 0.26 0.13
TVBurst+boostVSM 0.67 0.44 0.53 0.31 0.22 0.39 0.28 0.13
swan+BurstVSM 0.74 0.56 0.64 0.48 0.39 0.54 0.45 0.38
kleiberg+BurstVSM 0.68 0.63 0.65 0.52 0.35 0.53 0.42 0.36
TVBurst+BurstVSM 0.78 0.69 0.73 0.63 0.4 0.61 0.48 0.39
Table 3: Comparisons of average intra-class and inter-
class similarity.
Significant Events Moderate Events
Methods Intra Inter Intra Inter
TVBurst+boostVSM 0.234 0.132 0.295 0.007
TVBurst+BurstVSM 0.328 0.014 0.480 0.004
most relevant documents, then sort the documents
in the descending order of similarities with the clus-
ter centroid and finally compute P, R ,F and MAP in
this cluster. We perform Wilcoxon signed-rank test
for significance testing.
We used the event detection method in (Swan
and Allan, 2000) as baseline, denoted as timemines-
?2. As (Swan and Allan, 2000) suggested, we
tried two versions: 1) using all nouns and 2) us-
ing all named entities. Recall that BurstVSM re-
lies on bursty features as dimensions, we tested dif-
ferent burst detection algorithms in our proposed
BurstVSM model, including swan (Swan and Al-
lan, 2000), kleinberg (Kleinberg, 2003) and our pro-
posed TVBurst algorithm.
4.4 Experiment results
Preliminary results. In Table 2, we can see that 1)
BurstVSM with any of these three burst detection al-
gorithms is significantly better than timemines-?2,
suggesting our event detection method is very ef-
fective; 2) TVBurst with BurstVSM gives the best
performance, which suggests using moving average
base probability will improve the performance of
burst detection. We use TVBurst as the default burst
detection algorithm in later experiments.
Then we compare the performance of differ-
ent text representation models for event detection,
namely BurstVSM and boostVSM (He et al, 2007b;
He et al, 2007a).7 For different representation mod-
els, we use split-cluster-merge as clustering algo-
rithm. Table 2 shows that BurstVSM is much ef-
fecitve than boostVSM for event detection. In fact,
we empirically find boostVSM is appropriate for
7We use the same parameter settings in the original paper.
Table 4: Comparisons of observed runtime and storage.
boostVSM BurstVSM
Aver. # of non-zero entries per doc 149 14
File size for storing vectors (gigabytes) 3.74 0.571
Total # of merge 10,265,335 9,801,962
Aver. cluster cost per month (sec.) 355 55
Total merge cost (sec.) 2,441 875
Total time cost (sec.) 192,051 4,851
clustering documents in a coarse grain (e.g., in topic
level) but not for event detection.
Intra-class and inter-class similarities. In our
methods, event detection is treated as document
clustering. It is very important to study how similari-
ties affect the performance of clustering. To see why
our proposed representation methods are better than
boostVSM, we present the average intra-class simi-
larity and inter-class similarity for different events in
Table 3.8 We can see BurstVSM results in a larger
intra-class similarity and a smaller inter-class simi-
larity than boostVSM.
Analysis of the space/time complexity. We fur-
ther analyze the space/time complexity of different
representation models. In Table 4. We can see that
BurstVSM has much smaller space/time cost com-
pared with boostVSM, and meanwhile it has a better
performance for event detection (See Table 2). In
burst-based representation, one document has fewer
non-zero entries.
Acknowledgement. The core idea of this work
is initialized and developped by Kai Fan. This
work is partially supported by HGJ 2010 Grant
2011ZX01042-001-001, NSFC Grant 61073082 and
60933004. Xin Zhao is supported by Google PhD
Fellowship (China). We thank the insightful com-
ments from Junjie Yao, Jing Liu and the anony-
mous reviewers. We have developped an online Chi-
nese large-scale event search engine based on this
work, visit http://sewm.pku.edu.cn/eventsearch for
more details.
8For each event in our golden standard, we have two clus-
ters: relevant documents and non-relevant documents(within
the event period).
46
References
James Allan, Victor Lavrenko, and Hubert Jin. 2000.
First story detection in TDT is hard. In Proceedings
of the ninth international conference on Information
and knowledge management.
Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Huan Liu, and
Philip S. Yu. 2007. Time-dependent event hierarchy
construction. In SIGKDD.
Q. He, K. Chang, and E. P. Lim. 2007a. Using burstiness
to improve clustering of topics in news streams. In
ICDM.
Qi He, Kuiyu Chang, Ee-Peng Lim, and Jun Zhang.
2007b. Bursty feature representation for clustering
text streams. In SDM.
L. Huang, L. Wang, and X. Li. 2008. Achieving both
high precision and high recall in near-duplicate detec-
tion. In CIKM.
J. Kleinberg. 2003. Bursty and hierarchical structure in
streams. Data Mining and Knowledge Discovery.
Russell Swan and James Allan. 2000. Automatic gener-
ation of overview timelines. In SIGIR.
Michail Vlachos, Christopher Meek, Zografoula Vagena,
and Dimitrios Gunopulos. 2004. Identifying similari-
ties, periodicities and bursts for online search queries.
In SIGMOD.
Yiming Yang, Tom Pierce, and Jaime Carbonell. 1998.
A study of retrospective and on-line event detection.
In SIGIR.
47
