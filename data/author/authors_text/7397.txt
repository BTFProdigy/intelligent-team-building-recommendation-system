Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 45?48, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Multimodal Generation in the COMIC Dialogue System
Mary Ellen Foster and Michael White
Institute for Communicating and Collaborative Systems
School of Informatics, University of Edinburgh
{M.E.Foster,Michael.White}@ed.ac.uk
Andrea Setzer and Roberta Catizone
Natural Language Processing Group
Department of Computer Science, University of Sheffield
{A.Setzer,R.Catizone}@dcs.shef.ac.uk
Abstract
We describe how context-sensitive, user-
tailored output is specified and produced
in the COMIC multimodal dialogue sys-
tem. At the conference, we will demon-
strate the user-adapted features of the dia-
logue manager and text planner.
1 Introduction
COMIC1 is an EU IST 5th Framework project com-
bining fundamental research on human-human inter-
action with advanced technology development for
multimodal conversational systems. The project
demonstrator system adds a dialogue interface to a
CAD-like application used in bathroom sales situa-
tions to help clients redesign their rooms. The input
to the system includes speech, handwriting, and pen
gestures; the output combines synthesised speech, a
talking head, and control of the underlying applica-
tion. Figure 1 shows screen shots of the COMIC
interface.
There are four main phases in the demonstra-
tor. First, the user specifies the shape of their
own bathroom, using a combination of speech in-
put, pen-gesture recognition and handwriting recog-
nition. Next, the user chooses a layout for the sani-
tary ware in the room. After that, the system guides
the user in browsing through a range of tiling op-
tions for the bathroom. Finally, the user is given a
1COnversational Multimodal Interaction with Computers;
http://www.hcrc.ed.ac.uk/comic/.
three-dimensional walkthrough of the finished bath-
room. We will focus on how context-sensitive, user-
tailored output is generated in the third, guided-
browsing phase of the interaction. Figure 2 shows
a typical user request and response from COMIC in
this phase. The pitch accents and multimodal ac-
tions are indicated; there is also facial emphasis cor-
responding to the accented words.
The primary goal of COMIC?s guided-browsing
phase is to help users become better informed about
the range of tiling options for their bathroom. In
this regard, it is similar to the web-based system
M-PIRO (Isard et al, 2003), which generates per-
sonalised descriptions of museum objects, and con-
trasts with task-oriented embodied dialogue systems
such as SmartKom (Wahlster, 2003). Since guided
browsing requires extended descriptions, in COMIC
we have placed greater emphasis on producing high-
quality adaptive output than have previous embodied
dialogue projects such as August (Gustafson et al,
1999) and Rea (Cassell et al, 1999). To generate
its adaptive output, COMIC uses information from
the dialogue history and the user model throughout
the generation process, as in FLIGHTS (Moore et
al., 2004); both systems build upon earlier work on
adaptive content planning (Carenini, 2000; Walker
et al, 2002). An experimental study (Foster and
White, 2005) has shown that this adaptation is per-
ceptible to users of COMIC.
2 Dialogue Management
The task of the Dialogue and Action Manager
(DAM) is to decide what the system will show and
say in response to user input. The input to the
45
(a) Bathroom-design application (b) Talking head
Figure 1: Components of the COMIC interface
User Tell me about this design [click on Alt Mettlach]
COMIC [Look at screen]
THIS DESIGN is in the CLASSIC style.
[circle tiles]
As you can see, the colours are DARK RED and OFF WHITE.
[point at tiles]
The tiles are from the ALT METTLACH collection by VILLEROY AND BOCH.
[point at design name]
Figure 2: Sample COMIC input and output
DAM consists of multiple scored hypotheses con-
taining high-level, modality-independent specifica-
tions of the user input; the output is a similar high-
level specification of the system action. The DAM
itself is modality-independent. For example, the in-
put in Figure 2 could equally well have been the user
simply pointing to a design on the screen, with no
speech at all. This would have resulted in the same
abstract DAM input, and thus in the same output: a
request to show and describe the given design.
The COMIC DAM (Catizone et al, 2003) is
a general-purpose dialogue manager which can
handle different dialogue management styles such
as system-driven, user-driven or mixed-initiative.
The general-purpose part of the DAM is a sim-
ple stack architecture with a control structure;
all the application-dependent information is stored
in a variation of Augmented Transition Networks
(ATNs) called Dialogue Action Forms (DAFs).
These DAFs represent general dialogue moves, as
well as sub-tasks or topics, and are pushed onto and
popped off of the stack as the dialogue proceeds.
When processing a user input, the control struc-
ture decides whether the DAM can stay within the
current topic (and thus the current DAF), or whether
a topic shift has occurred. In the latter case, a new
DAF is pushed onto the stack and executed. After
that topic has been exhausted, the DAM returns to
the previous topic automatically. The same princi-
ple holds for error handling, which is implemented
at different levels in our approach.
In the guided-browsing phase of the COMIC sys-
tem, the user may browse tiling designs by colour,
style or manufacturer, look at designs in detail, or
change the amount of border and decoration tiles.
The DAM uses the system ontology to retrieve de-
signs according to the chosen feature, and consults
the user model and dialogue history to narrow down
the resulting designs to a small set to be shown and
described to the user.
46
3 Presentation Planning
The COMIC fission module processes high-level
system-output specifications generated by the DAM.
For the example in Figure 2, the DAM output indi-
cates that the given tile design should be shown and
described, and that the description must mention the
style. The fission module fleshes out such specifica-
tions by selecting and structuring content, planning
the surface form of the text to realise that content,
choosing multimodal behaviours to accompany the
text, and controlling the output of the whole sched-
ule. In this section, we describe the planning pro-
cess; output coordination is dealt with in Section 6.
Full technical details of the fission module are given
in (Foster, 2005).
To create the textual content of a description, the
fission module proceeds as follows. First, it gath-
ers all of the properties of the specified design from
the system ontology. Next, it selects the properties
to include in the description, using information from
the dialogue history and the user model, along with
any properties specifically requested by the dialogue
manager. It then creates a structure for the selected
properties and creates logical forms as input for the
OpenCCG surface realiser. The logical forms may
include explicit alternatives in cases where there are
multiple ways of expressing a property; for exam-
ple, it could say either This design is in the classic
style or This design is classic. OpenCCG makes use
of statistical language models to choose among such
alternatives. This process is described in detail in
(Foster and White, 2004; Foster and White, 2005).
In addition to text, the output of COMIC
also incorporates multimodal behaviours including
prosodic specifications for the speech synthesiser
(pitch accents and boundary tones), facial behaviour
specifications (expressions and gaze shifts), and de-
ictic gestures at objects on the application screen us-
ing a simulated pointer. Pitch accents and bound-
ary tones are selected by the realiser based on the
context-sensitive information-structure annotations
(theme/rheme; marked/unmarked) included in the
logical forms. At the moment, the other multimodal
coarticulations are specified directly by the fission
module, but we are currently experimenting with
using the OpenCCG realiser?s language models to
choose them, using example-driven techniques.
4 Surface Realisation
Surface realisation in COMIC is performed by the
OpenCCG2 realiser, a practical, open-source realiser
based on Combinatory Categorial Grammar (CCG)
(Steedman, 2000b). It employs a novel ensemble of
methods for improving the efficiency of CCG reali-
sation, and in particular, makes integrated use of n-
gram scoring of possible realisations in its chart re-
alisation algorithm (White, 2004; White, 2005). The
n-gram scoring allows the realiser to work in ?any-
time? mode?able at any time to return the highest-
scoring complete realisation?and ensures that a
good realisation can be found reasonably quickly
even when the number of possibilities is exponen-
tial. This makes it particularly suited for use in an
interactive dialogue system such as COMIC.
In COMIC, the OpenCCG realiser uses factored
language models (Bilmes and Kirchhoff, 2003) over
words and multimodal coarticulations to select the
highest-scoring realisation licensed by the grammar
that satisfies the specification given by the fission
module. Steedman?s (Steedman, 2000a) theory of
information structure and intonation is used to con-
strain the choice of pitch accents and boundary tones
for the speech synthesiser.
5 Speech Synthesis
The COMIC speech-synthesis module is imple-
mented as a client to the Festival speech-synthesis
system.3 We take advantage of recent advances in
version 2 of Festival (Clark et al, 2004) by using
a custom-built unit-selection voice with support for
APML prosodic annotation (de Carolis et al, 2004).
Experiments have shown that synthesised speech
with contextually appropriate prosodic features can
be perceptibly more natural (Baker et al, 2004).
Because the fission module needs the timing in-
formation from the speech synthesiser to finalise the
schedules for the other modalities, the synthesiser
first prepares and stores the waveform for its input
text; the sound is then played at a later time, when
the fission module indicates that it is required.
2http://openccg.sourceforge.net/
3http://www.cstr.ed.ac.uk/projects/festival/
47
6 Output Coordination
In addition to planning the presentation content as
described earlier, the fission module also controls
the system output to ensure that all parts of the pre-
sentation are properly coordinated, using the tim-
ing information returned by the speech synthesiser
to create a full schedule for the turn to be generated.
As described in (Foster, 2005), the fission module
allows multiple segments to be prepared in advance,
even while the preceding segments are being played.
This serves to minimise the output delay, as there is
no need to wait until a whole turn is fully prepared
before output begins, and the time taken to speak the
earlier parts of the turn can also be used to prepare
the later parts.
7 Acknowledgements
This work was supported by the COMIC project
(IST-2001-32311). This paper describes only part
of the work done in the project; please see http://
www.hcrc.ed.ac.uk/comic/ for full details. We
thank the other members of COMIC for their col-
laboration during the course of the project.
References
Rachel Baker, Robert A.J. Clark, and Michael White.
2004. Synthesizing contextually appropriate intona-
tion in limited domains. In Proceedings of 5th ISCA
workshop on speech synthesis.
Jeff Bilmes and Katrin Kirchhoff. 2003. Factored lan-
guage models and general parallelized backoff. In
Proceedings of HLT-03.
Giuseppe Carenini. 2000. Generating and Evaluating
Evaluative Arguments. Ph.D. thesis, Intelligent Sys-
tems Program, University of Pittsburgh.
Justine Cassell, Timothy Bickmore, Mark Billinghurst,
Lee Campbell, Kenny Chang, Hannes Vilhja?lmsson,
and Hao Yan. 1999. Embodiment in conversational
interfaces: Rea. In Proceedings of CHI99.
Roberta Catizone, Andrea Setzer, and Yorick Wilks.
2003. Multimodal dialogue management in the
COMIC project. In Proceedings of EACL 2003 Work-
shop on Dialogue Systems: Interaction, adaptation,
and styles of management.
Robert A.J. Clark, Korin Richmond, and Simon King.
2004. Festival 2 ? build your own general purpose
unit selection speech synthesiser. In Proceedings of
5th ISCA workshop on speech synthesis.
Berardina de Carolis, Catherine Pelachaud, Isabella
Poggi, and Mark Steedman. 2004. APML, a
mark-up language for believable behaviour generation.
In H Prendinger, editor, Life-like Characters, Tools,
Affective Functions and Applications, pages 65?85.
Springer.
Mary Ellen Foster and Michael White. 2004. Tech-
niques for text planning with XSLT. In Proceedings
of NLPXML-2004.
Mary Ellen Foster and Michael White. 2005. Assessing
the impact of adaptive generation in the COMIC multi-
modal dialogue system. In Proceedings of IJCAI-2005
Workshop on Knowledge and Reasoning in Practical
Dialogue Systems. To appear.
Mary Ellen Foster. 2005. Interleaved planning and out-
put in the COMIC fission module. Submitted.
Joakim Gustafson, Nikolaj Lindberg, and Magnus Lun-
deberg. 1999. The August spoken dialogue system.
In Proceedings of Eurospeech 1999.
Amy Isard, Jon Oberlander, Ion Androtsopoulos, and
Colin Matheson. 2003. Speaking the users? lan-
guages. IEEE Intelligent Systems, 18(1):40?45.
Johanna Moore, Mary Ellen Foster, Oliver Lemon, and
Michael White. 2004. Generating tailored, compara-
tive descriptions in spoken dialogue. In Proceedings
of FLAIRS 2004.
Mark Steedman. 2000a. Information structure and
the syntax-phonology interface. Linguistic Inquiry,
31(4):649?689.
Mark Steedman. 2000b. The Syntactic Process. MIT
Press.
Wolfgang Wahlster. 2003. SmartKom: Symmetric mul-
timodality in an adaptive and reusable dialogue shell.
In Proceedings of the Human Computer Interaction
Status Conference 2003.
M.A. Walker, S. Whittaker, A. Stent, P. Maloor, J.D.
Moore, M. Johnston, and G. Vasireddy. 2002. Speech-
plans: Generating evaluative responses in spoken dia-
logue. In Proceedings of INLG 2002.
Michael White. 2004. Reining in CCG chart realization.
In Proceedings of INLG 2004.
Michael White. 2005. Efficient realization of coordinate
structures in Combinatory Categorial Grammar. Re-
search on Language and Computation. To appear.
48
Multilingual Authoring: the NAMIC approach
R. Basili, M.T. Pazienza
F. Zanzotto
Dept. of Computer Science
University of Rome, Tor Vergata
Via di Tor Vergata,
00133 Roma
Italy
basili@info.uniroma2.it
pazienza@info.uniroma2.it
zanzotto@info.uniroma2.it
R. Catizone, A. Setzer
N. Webb, Y. Wilks
Department of Computer Science
University of Sheffield
Regent Court
211 Portobello Street,
Sheffield S1 4DP, UK
R.Catizone@dcs.shef.ac.uk
A.Setzer@dcs.shef.ac.uk
N.Webb@dcs.shef.ac.uk
Y.Wilks@dcs.shef.ac.uk
L. Padro?, G. Rigau
Dept. Llenguatges i Sistemes Informa`tics
Universitat Polite`cnica de Catalunya
Centre de Recerca TALP
Jordi Girona Salgado 1-3,
08034 Barcelona
Spain
padro@lsi.upc.es
g.rigau@lsi.upc.es
Abstract
With increasing amounts of elec-
tronic information available, and the
increase in the variety of languages
used to produce documents of the
same type, the problem of how to
manage similar documents in dif-
ferent languages arises. This pa-
per proposes an approach to process-
ing/structuring text so that Multi-
lingual Authoring (creating hyper-
text links) can be effectively car-
ried out. This work, funded by
the European Union, is applied to
the Multilingual Authoring of news
agency text. We have applied meth-
ods from Natural Language Process-
ing, especially Information Extrac-
tion technology, to both monolingual
and Multilingual Authoring.
1 Introduction
Modern Information Technologies are faced
with the problem of selecting, filtering and
managing growing amounts of multilingual
information to which access is usually criti-
cal. Traditional Information Retrieval (IR)
approaches are too general in their selection
of relevant documents where as traditional
Information Extraction (IE) (Gaizauskas and
Wilks, 1998; Pazienza, 1997) approaches are
too specific and inflexible. Automatic Au-
thoring is a good example of how these two
methods can be improved and used to cre-
ate a hypertextual organisation of (multilin-
gual) information. This kind of information
is ?added value? to the information embodied
in the text and is not in contrast with other
retrieval paradigms. Automatic Authoring
is the activity of processing news items in
streams, detecting and extracting relevant in-
formation from them and, accordingly, organ-
ising texts in a non-linear fashion.
While IE systems like the ones participat-
ing in the Message Understanding Conference
(MUC, 1998) are oriented towards specific
phenomena (e.g. joint ventures) in restricted
domains, the scope of Automatic Authoring
is wider. In Automatic Authoring, the hy-
pertextual structure has to provide naviga-
tion guidelines to the final user which can also
refuse the system suggestions.
In this paper an architecture for Automatic
Multilingual Authoring is presented based on
knowledge-intensive and large-scale Informa-
tion Extraction. The general architecture
is presented capitalising robust methods of
Information Extraction (Cunningham et al,
1999) and large-scale multilingual resources
(e.g. EuroWordNet). The system is de-
veloped within a European project in the
Human Language Technologies area, called
NAMIC (News Agencies Multilingual Infor-
mation Categorisation)1. It aims to extract
relevant facts from the news streams of large
European news agencies and newspaper pro-
ducers2, to provide hypertextual structures
within each (monolingual) stream and then
produce cross-lingual links between streams.
2 Authoring
2.1 Automatic Authoring
As Automatic Authoring is the task of au-
tomatically deriving a hypertextual structure
from a set of available news articles (in three
different languages English, Spanish and Ital-
ian in our case), the complexity of the overall
framework requires a suitable decomposition:
Text processing requires at least the de-
tection of morphosyntactic information char-
acterising the source texts: recognition, nor-
malisation, and assignment of roles is required
for the main participants for the different
events/facts described.
Event Matching is then the activity of
selecting the relevant facts of a news arti-
cle, in terms of their general type (e.g. sell-
ing or buying companies, winning a football
match), their participants and their related
roles (e.g. the company sold or the winning
football team).
Authoring is thus the activity of gener-
ating links between news articles according
to relationships established among facts de-
tected in the previous phase.
For instance, a company acquisition can be
referred to in one (or more) news items as:
? Intel, the world?s largest chipmaker,
bought a unit of Danish cable maker NKT
that designs high-speed computer chips ...
1See http://namic.itaca.it.
2EFE and ANSA, the major news agencies in Spain
and Italy respectively, and the Financial Times are all
members of the NAMIC consortium.
? The giant chip maker Intel said it ac-
quired the closely held ICP Vortex Com-
putersysteme, a German maker of sys-
tems ...
? Intel ha acquistato Xircom inc. per 748
milioni di dollari.
The hypothesis underlying Authoring is
that all the above news items deal with facts
in the same area of interest to a potential class
of readers. They should be thus linked and
links should suggest to the user that the un-
derlying motivation (used to decide whether
or not to follow an available link) is that they
all refer to Intel acquisitions.
Notice that a link generation process based
only upon words would fail in the above case
as the common word (that could play the role
of anchor in linking) is the proper noun Intel.
As no other information is available, the re-
sulting set of potential matches can be huge
and the connectivity too high.
In order to get the suitable links the equiv-
alence between the senses of bought and ac-
quired in the first two news items must be
known. Although such a relation can be
drawn by mechanisms like query expansion or
thesauri of synonyms (e.g. WordNet (Miller,
1990)), word polysemy and noise may re-
sult in an inherent proliferation of irrelevant
matches. Contextual information is critical
here. Notice that the senses of ?buy? and ?ac-
quire? are constrained by the role played by
Intel as ?agent ? and NKT or ICP Vortex be-
ing the sold companies. In fact, Intel buys
silicon represents an unwanted sense of the
verb and should be distinguished.
The relevant information concerning Intel
should be thus limited to:
? Intel buys a unit of NKT
? Intel acquires ICP Vortex.
These descriptions provide the core infor-
mation able to establish equivalence among
the underlying events. Whenever base event
descriptions are available the linking process
can be carried out via simpler equivalence in-
ferences. The Authoring problem is thus a
side effect of the overall language-processing
task.
According to the suggested decomposition
all the above steps are mandatory. First text
processing is responsible for morpho-syntactic
recognition. Morphological units and syntac-
tic relations are produced for each sentence at
this stage. However, syntactic relations (e.g.
among subjects and verbs) are not sufficient
for proper event characterisation. In the ex-
ample(s), the subject of the verb acquire is
a pronoun only anaphorically referring to In-
tel. Co-reference resolution is usually applied
to this kind of mismatch at the surface level.
This capability is under the responsibility of
the event matching phase. Moreover, in or-
der to keep track of events over syntactic rep-
resentations, references to a target ontology
are required. In such an ontology, equiva-
lence among facts (e.g. buying companies) is
represented. For instance, the relation among
buy and acquire can be encoded under a more
general notion of financial acquisition. On-
tologies also define the set of relevant facts of
the target domain. A financial acquisition is
a perfect example of what is needed in cor-
porate industrial news but is less important,
for example, in sports news, where hiring of
players seems a more relevant event class.
Conceptual differences among facts (de-
tected during event matching) motivate a se-
lective notion of hyperlinking. These links
can be thus generated during the automatic
authoring phase. They are ontologically jus-
tified as their conceptual representation is al-
ready available at this stage. Types as same
acquisition fact, same person, or company can
be used to distinguish links and make expla-
nations available to the user.
2.2 Multilingual Automatic
Authoring
?From a multilingual perspective, the prob-
lem is to establish links among news in dif-
ferent languages. Full-text approaches can
rely only on language independent phenom-
ena (e.g. proper nouns like Intel) that are
very limited in texts. Most of the above-
mentioned inferences require language neu-
tral information (i.e. conceptual and not lexi-
cal constraints). The inherent overgeneration
related to word polysemy affects the results
of translation-based approaches. Again prin-
cipled representations made available by IE
processes (i.e. templates) provide a viable
solution. The different event realisations (in
the different languages) can be handled dur-
ing the overall event matching. A lexical in-
terface to the ontology is able to factor the
language specific information. As syntactic
differences are handled during text process-
ing, the result is a common domain model for
IE plus independent lexical interfaces. The
unified representation of the set of facts ac-
tivates multilingual linking at a conceptual
level, thus making the Authoring a language
independent process. Some challenges of such
a framework are:
? the size of the ontological resources re-
quired in terms of taxonomic (i.e. IS A
relations) and conceptual information
(i.e. classes of events and implied
participant-event relations)
? the size of the lexical interfaces to the
ontology available for the different lan-
guages
? the amount of task dependent knowledge.
For example the definition of the set of
events useful for the target application is
underspecified.
In the following, we propose a complex ar-
chitecture where the above problems are
approached according to well-assessed tech-
niques presented elsewhere. Robust Informa-
tion Extraction is adopted (Humphreys et al,
1998) as an overall method for text process-
ing and event matching. Target events are
semiautomatically derived from domain texts
and represented in the IE engine ontology. Fi-
nally, multilinguality is realised by assuming a
large-scale multilingual lexical hierarchy as a
reference ontology for nominal concepts. The
resulting architecture for Multilingual Auto-
matic Authoring is presented in Section 3.4.
3 The NAMIC system
3.1 Large scale IE for Automatic
Authoring
Information Extraction is a very good ap-
proach to Automatic Authoring for a num-
ber of reasons. The key components of an IE
system are events and objects - the kind of
components that trigger hyperlinks in an Au-
thoring system. Coreference is a significant
part of Information Extraction and indeed a
necessary component in Authoring. Named
Entities - people, places, and organisations,
etc. - play an important part in Authoring
and again are firmly addressed in Information
Extraction systems.
The role of a world model as a method
for event matching and coreferencing
The world model is an ontological represen-
tation of events and objects for a particular
domain or set of domains. The world model
is made up of a set of event and object types,
with attributes. The event types characterise
a set of events in a particular domain and
are usually represented in a text by verbs.
Object Types on the other hand, are best
thought of as characterising a set of people,
places or things and are usually represented
in a text by nouns (both proper and com-
mon). When used as part of an Information
Extraction system, the instances of each type
are inserted/added to the world model. Once
the instances have been added, a procedure
is carried out to link those instances that re-
fer to the same thing - achieving coreference
resolution.
In NAMIC, the world model is created
using the XI cross-classification hierarchy
(Gaizauskas and Humphreys, 1996). The def-
inition of a XI cross-classification hierarchy is
referred to as an ontology, and this together
with an association of attributes with nodes
in the ontology forms the world model. Pro-
cessing a text acts to populate this initially
bare world model with the various instances
and relations mentioned in the text, convert-
ing it into a discourse model specific to the
particular text.
The attributes associated with nodes in
the ontology are simple attribute:value pairs
where the value may either be fixed, as in
the attribute animate:yes which is associ-
ated with the person node, or where the value
may be dependent on various conditions, the
evaluation of which makes reference to other
information in the model.
3.1.1 The Description of LaSIE
LaSIE is a Large-scale Information Ex-
traction system, developed for MUC (Mes-
sage Understanding Conference) competi-
tions, comprised of a variety of modules, see
(Humphreys et al, 1998; MUC, 1998). Al-
though we are not using the complete LaSIE
system in NAMIC, we are using 2 of the key
modules - the Named Entity Matcher and the
Discourse Processor. Below is a description of
each of these modules.
Named Entity Matcher The Named En-
tity Matcher finds named entities through
a secondary phase of parsing which uses a
named entity grammar and a set of gazetteer
lists. It takes as input parsed text from the
first phase of parsing and the named entity
grammar which contains rules for finding a
predefined set of named entities and a set of
gazetteer lists containing proper nouns. The
Name Entity Matcher returns the text with
the Named Entities marked. The Named En-
tities in NAMIC are PERSONS, ORGANI-
SATIONS, LOCATIONS, and DATES. The
Named Entity grammar contains rules for
coreferring abbreviations as well as different
ways of expressing the same named entity
such as Dr. Smith, John Smith and Mr.
Smith occurring in the same article.
Discourse Processor The Discourse Pro-
cessor module translates the semantic rep-
resentation produced by the parser into a
representation of instances, their ontolog-
ical classes and their attributes, in the
XI knowledge representation language (see
Gaizauskas(1996)). XI allows a straightfor-
ward definition of cross-classification hierar-
chies, the association of arbitrary attributes
with classes or instances, and a simple mech-
anism to inherit attributes from classes or in-
stances higher in the hierarchy.
The semantic representation produced by
the parser for a single sentence is processed
by adding its instances, together with their
attributes, to the discourse model which has
been constructed so far for the text.
Following the addition of the instances
mentioned in the current sentence, together
with any presuppositions that they inherit,
the coreference algorithm is applied to at-
tempt to resolve, or in fact merge, each of
the newly added instances with instances cur-
rently in the discourse model.
The merging of instances involves the re-
moval of the least specific instance (i.e. the
highest in the ontology) and the addition of
all its attributes to the other instance. This
results in a single instance with more than one
realisation attribute, which corresponds to a
single entity mentioned more than once in the
text, i.e. a coreference.
3.2 Ontological Modeling
As we have seen in section 3.1, some critical
issues of the NAMIC project rely on the per-
formance of the lexical and conceptual compo-
nents of all linguistic processors. As NAMIC
faces large-scale coverage of news in several
languages we decided to adopt EuroWordNet
(Vossen, 1998) as a common semantic formal-
ism to support:
? lexical semantic inferences (e.g. general-
isation, disambiguation)
? broad coverage (e.g. lexical and semanti-
cal) and
? a common interlingual platform for link-
ing events from different documents.
The NAMIC ontology consists of 40 prede-
fined object classes and 46 attribute types re-
lated to Name Entity objects and nearly 1000
objects relating to EuroWordNet base con-
cepts.
3.2.1 EuroWordNet as a Multilingual
Lexical Knowledge Base
Since the world model aims to describe the
language used in a given domain via events
and objects, the accuracy and breadth of the
model will impact how well the information
extraction works.
EuroWordNet (Vossen, 1998) is a multilin-
gual lexical knowledge base (LKB) with word-
nets for several European languages (Dutch,
Italian, Spanish, German, French, Czech and
Estonian). The wordnets are structured
in the same way as the American wordnet
for English developed at Princeton (Miller,
1990) containing synsets (sets of synonymous
words) with basic semantic relations between
them.
Each wordnet represents a unique
language-internal system of lexicalisa-
tions. In addition, the wordnets are linked
to an Inter-Lingual-Index (ILI), based on
the Princeton WordNet 1.5. WordNet 1.6 is
also connected to the ILI as another English
WordNet (Daude et al, 2000). Via this
index, the languages are interconnected so
that it is possible to go from the words in
one language to words in any other language
having similar meaning. The index also
gives access to a shared top-ontology and
a subset of 1024 Base Concepts (BC). The
Base Concepts provide a common seman-
tic framework for all the languages, while
language specific properties are maintained
in the individual wordnets. The LKB can
be used, among others, for monolingual and
cross-lingual information retrieval, which
has been demonstrated in other projects
(Gonzalo et al, 1998).
3.3 Multilingual Event description
The traditional limitations of a knowledge-
based information extraction system such as
LaSIE have been the need to hand-code in-
formation for the world model - specifically
relating to the event structure of the domain.
For the NAMIC project, we have decided
to semi-automate the process of adding new
?event descriptions? to the World Model. To
us, event descriptions can be categorised as a
set of regularly occurring verbs within our do-
main, complete with their subcategorisation
information.
These verbs can be extracted with simple
statistical techniques and are, for the moment
subjected to hand pruning. Once a list of
verbs has been extracted, subcategorisation
patterns can be generated automatically using
a Galois lattice (as described in (Basili et al,
2000b)). These frames can then be uploaded
into the event hierarchy of the discourse in-
terpreter world model.
The world model can have a structure
which is essentially language independent in
all but the lowest level - at which stage lexi-
calisations relating to each representative lan-
guage are required. Associated with these lex-
icalisations are language dependent scenario
rules which control the behaviour of instances
of these events with a Discourse Model. These
rules are expected to differ across languages in
the way they control coreference for languages
which are constrained to lesser or greater de-
gree.
The lattice generates patterns which refer
to synsets in the WordNet hierarchy. For
our purposes, we will use patterns referring to
Base Concepts in the EuroWordNet hierarchy
- which allows us to exploit the Inter-Lingual-
Index as described in the previous section.
These Base Concepts serve as a level of mul-
tilingual abstraction for the conceptual con-
straints of our events, and allow us to extend
the number of semantic classes from seven
(the MUC Named Entity classifications) to
1024 - the number of base concepts in EWN.
3.4 The NAMIC Architecture
The complexity of the overall NAMIC sys-
tem required the adoption of a distributed
computing paradigm in the design. The sys-
tem is a distributed object oriented system
where services (like text processing or Multi-
lingual Authoring) are provided by indepen-
dent components and asynchronous communi-
cation is allowed. Independent news streams
for the different languages (English, Spanish,
and Italian) are assumed. Language specific
processors (LPs) are thus responsible for text
processing and event matching in indepen-
dent text units in each stream. LPs com-
pile an objective representation (see Fig. 1)
for each source texts, including the detected
morphosyntactic information, categorisation
in news standards (IPTC classes) and descrip-
tion of the relevant events. Any later Au-
thoring activity is based on this canonical
representation of the news. In particular a
monolingual process is carried out within any
stream by the three monolingual Authoring
Engines (English AE, Spanish AE, and Ital-
ian AE). A second phase is foreseen to take
into account links across streams, i.e. multi-
lingual hyper-linking: a Multilingual Author-
ing Engine (M-AE) is here foreseen. Figure
1 represents the overall flow of information.
The Language Processors are composed of a
morphosyntactic (Eng, Ita and Spa MS) and
an event-matching component (EM). The lex-
ical interfaces (ELI, SLI and ItLI) to the uni-
fied Domain model are also used during event
matching.
The linguistic processors are in charge of
producing the objective representation of in-
coming news. This task is performed during
MS analysis by two main subprocessors:
? a modular and lexicalised shallow
morpho-syntactic parser (Basili et al,
2000c), providing name entity match-
ing and extracting dependency graphs
from source sentences. Ambiguity is
controlled by part-of-speech tagging and
domain verb-subcategorisation frames
that guide the dependency recognition
phase.
? a statistical linear text classifier based
upon some of the derived linguistic fea-
tures (Basili et al, 2000a) (lemmas, POS
tags and proper nouns)
The results are then input to the event
matcher that by means of the discourse in-
terpreter (Humphreys et al, 1998) derive the
objective representation. As discussed in sec-
tion 3.1, coreferencing is a side effect of the
discourse interpretation (Humphreys et al,
1998). It is based on the multilingual domain
model where relevant events are described and
nominal concepts represented.
The overall architecture is highly modular
and open to load balancing activity as well as
to adaptation and porting. The communica-
tion interfaces among the MS and EM com-
ponents as well as among the AEs and the M-
AE processors are specified via XML DTDs.
This allows for user-friendly uploading of a
back-end database with the detected material
as well as the easy design and management of
the front-end databases (available for tempo-
rary tasks, like event matching after MS). All
the servers are objects in a distributed archi-
tecture within a CORBA environment. The
current version includes the linguistic proces-
sors (MS and EM) for all the three languages.
The English and Italian linguistic processors
are fully object oriented modules based on
EnglishMS
SpanishMS
ItalianMS
EnglishAE
SpanishAE
ItalianAE
news ObjectiveRepresentation Monolingual Links
Multilingual Links
EnglishEM
SpanishEM
ItalianEM
DomainModel
ELI
SLI
ItLI
Multi-LingualAuthoringEngine
Language Processors
Figure 1: Namic Architecture
Java. They integrate libraries written in C,
C++, Prolog, and Perl for specific functional-
ities (e.g. parsing) running under a Windows
NT platform. The Spanish linguistic proces-
sor shares the discourse interpreter and the
text classifier with the other modules, while
the morpho syntactic component is currently
a Unix server based on Perl. The use of a dis-
tributed architecture under CORBA allowed
a flexible solution to its integration into the
overall architecture. The servers can be in-
stantiated in multiple copies throughout the
network if the amount of required computa-
tion exceeds the capability of a current con-
figuration. As the workload of a news stream
is not easily predictable, distribution and dy-
namic load balancing is the only realistic ap-
proach.
4 Discussion and Future Work
The above sections have provided the out-
line of a general NLP-based approach to auto-
matic authoring. The emphasis given to tra-
ditional capabilities of Information Extraction
depends on the relevance of news content in
the target Web service scenarios as well as
on their inherent multilinguality. The bet-
ter is the generalisation provided by the IE
component, the higher is the independence
from the text source language. As a result,
IE is here seen as a natural approach to cross-
lingual hypertextual authoring. Other works
in this area make extensive use of traditional
IR techniques (e.g. full text search) or rely
on already traced (i.e. manually coded) hy-
perlinks (e.g. (Chakrabarti et al, 1998; Klein-
berg, 1999)). The suggested NAMIC architec-
ture exploits linguistic capabilities for deriv-
ing entirely original (ex novo) resources, over
dynamic, previously unreleased, streams of in-
formation.
The result is a large-scale multilingual NLP
application capitalising existing methods and
resources within an advanced software engi-
neering process. The use of a distributed
Java/CORBA architecture makes the system
very attractive for its scalability and adaptiv-
ity. It results in a very complex (but realis-
tic) NLP architecture. Its organisation (lexi-
cal interfaces with respect to the multilingual
ontology) makes it very well suited for cus-
tomisation and porting to large domains. Al-
though the current version is a prototype, it
realises the complete set of core functionali-
ties, including the main IE steps and the dis-
tributed Java/CORBA layer.
It is worth noticing that a set of extensions
are made viable within the proposed architec-
ture. A first line is the extension of the avail-
able multilingual lexical knowledge. The Dis-
course Model can be used to better reflect on-
tological relationships within a particular do-
main. These relationships could be examined
to confirm known word sense usage as well
as to postulate/propose novel word sense us-
age. Using the mechanism for the addition of
events (as categorised by verbs) to the world
model, users can specify new events which can
be added to the IE system, to achieve User
Driven IE, and deliver a form of adaptive in-
formation extraction.
The instantiated domain models can be
thus used as a basis for ontological resource
expansion as a form of adaptive process.
For example, the stored instantiations of dis-
course models within a specific domain can be
compared: it may be thus possible to recog-
nise new sets of events or objects which are
not currently utilised within the system.
The evaluation strategy that is made possi-
ble within the NAMIC consortium will make
use of the current users (i.e. news agencies)
expertise. The agreed evaluation methods
will provide evidence about the viability of
the proposed large-scale IE-based approach to
authoring, as a valuable paradigm for infor-
mation access.
Acknowledgements
This research is funded by the European
Union, grant number IST-1999-12392. We
would also like to thank all of the partners
in the NAMIC consortium.
References
R. Basili, A. Moschitti, and M.T. Pazienza. 2000a.
Language sensitive text classification. In In
proceeding of 6th RIAO Conference (RIAO
2000), Content-Based Multimedia Information
Access, Coll ge de France, Paris, France.
R. Basili, M.T. Pazienza, and M. Vindigni. 2000b.
Corpus-driven learning of event recognition
rules. In Proc. of Machine Learning for Infor-
mation Extraction workshop, held jointly with
the ECAI2000, Berlin, Germany.
R. Basili, M.T. Pazienza, and F.M. Zanzotto.
2000c. Customizable modular lexicalized pars-
ing. In Proc. of the 6th International Workshop
on Parsing Technology, IWPT2000, Trento,
Italy.
S. Chakrabarti, B. Dom, D. Gibson, J. Kleinberg,
P. Raghavan, and S. Rajagopalan. 1998. Auto-
matic resource compilation by analysing hyper-
link structure and associated text. In Proceed-
ings of the 7th International World Wide Web
Conference, Brisbane, Australia.
C. Cunningham, R. Gaizauskas, K. Humphreys,
and Y. Wilks. 1999. Experience with a lan-
guage engineering architecture: 3 years of gate.
In Proceedings of the AISB?99 Workshop on
Reference Architectures and Data Standards for
NLP, Edinburgh, UK.
J. Daude, L. Padro, and G. Rigau. 2000. Map-
ping wordnets using structural information.
In Proceedings of the 38th Annual Meeting of
the Association for Computational Linguistics
ACL?00, Hong Kong, China.
R. Gaizauskas and K. Humphreys. 1996. Xi:
A simple prolog-based language for cross-
classification and inheritance. In Proceedings of
the 6th International Conference on Artificial
Intelligence: Methodologies, Systems, Applica-
tions (AIMSA96), pages 86?95.
R. Gaizauskas and Y. Wilks. 1998. Information
Extraction: Beyond Document Retrieval. Jour-
nal of Documentation, 54(1):70?105.
J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigar-
ran. 1998. Indexing with wordnet synsets
can improve text retrieval. In Proceedings of
the COLING/ACL?98 Workshop on Usage of
WordNet for NLP, Montreal, Canada.
K. Humphreys, R. Gaizauskas, S. Azzam,
C. Huyck, B. Mitchell, H. Cunningham, and
Y. Wilks. 1998. University of sheffield: De-
scription of the lasie-ii system as used for muc-7.
In Proceedings of the Seventh Message Under-
standing Conferences (MUC-7). Morgan Kauf-
man. Available at http://www.saic.com.
Jon M. Kleinberg. 1999. Authoritative sources
in a hyperlinked environment. Journal of the
ACM, 46(5):604?632.
G. Miller. 1990. Five papers on wordnet. Inter-
national Journal of Lexicography, 4(3).
1998. Proceedings of the Seventh Message Under-
standing Conference (MUC-7). Morgan Kauf-
man. Available at http://www.saic.com.
M.T. Pazienza, editor. 1997. Information Ex-
traction. A Multidisciplinary Approach to an
Emerging Information Technology. Number
1299 in LNAI. Springer-Verlag, Heidelberg,
Germany.
P. Vossen. 1998. EuroWordNet: A Multilin-
gual Database with Lexical Semantic Networks.
Kluwer Academic Publishers, Dordrecht.
  	
 Knowledge-Based Multilingual Document Analysis
R. Basili
 
and R. Catizone  and L. Padro  and M.T. Pazienza  
G. Rigau  and A. Setzer  and N. Webb 
F. Zanzotto
 
 
Dept. of Computer Science, Systems and Production
University of Rome, Tor Vergata
Via di Tor Vergata
00133 Roma, Italy
basili, pazienza, zanzotto@info.uniroma2.it
 Department of Computer Science
University of Sheffield
Regent Court, 211 Portobello Street
Sheffield S1 4DP, UK
R.Catizone, A.Setzer, N.Webb@dcs.shef.ac.uk
 Departament de Llenguatges i Sistemes Informatics
Universitat Politecnica de Catalunya
Centre de Recerca TALP
Jordi Girona Salgado 1-3
08034 Barcelona, Spain
l.padro, g.rigau@lsi.upc.es
Abstract
The growing availability of multilingual resources,
like EuroWordnet, has recently inspired the develop-
ment of large scale linguistic technologies, e.g. mul-
tilingual IE and Q&A, that were considered infeasi-
ble until a few years ago. In this paper a system
for categorisation and automatic authoring of news
streams in different languages is presented. In our
system, a knowledge-based approach to Information
Extraction is adopted as a support for hyperlinking.
Authoring across documents in different languages
is triggered by Named Entities and event recogni-
tion. The matching of events in texts is carried out
by discourse processing driven by a large scale world
model. This kind of multilingual analysis relies on a
lexical knowledge base of nouns(i.e. the EuroWord-
net Base Concepts) shared among English, Spanish
and Italian lexicons. The impact of the design choices
on the language independence and the possibilities it
opens for automatic learning of the event hierarchy
will be discussed.
1 Introduction
Modern information technologies are faced with the
problem of selecting, filtering, linking and manag-
ing growing amounts of multilingual information to
which access is usually critical. Our work is moti-
vated by the linking of multilingual information in a
wide range of domains. Although this problem ap-
pears to be directly related to the Information Re-
trieval task, we aimed to link articles, not in the broad
sense of clustering documents related to the same
topic, but rather more specifically linking particular
pieces of information together from different docu-
ments. Furthermore, we found that IE research, al-
though appropriate for our task, was not designed for
the scale/variety of different domains that we needed
to process. In general, creating the world model nec-
essary for the addition of a new domain to an IE sys-
tem is a time-consuming process. As such, we de-
signed an IE system that could be semi-automatically
and easily adapted to new domains - a process we will
refer to as large scale IE. The key to creating new
world models relied on incorporating large amounts
of domain knowledge. As a result we selected Eu-
roWordnet as our base knowledge source. EuroWord-
net has the advantages of 1) providing the foundation
for broad knowledge across many domains and 2) is
multilingual in nature. In this paper, we will explain
how our system works, how the knowledge base was
incorporated and a discussion of other applications
that could make use of the same technology.
2 The Application
In the 5th Framework NAMIC Project (News Agen-
cies Multilingual Information Categorisation), the de-
fined task of the system was to support the automatic
authoring of multilingual news agencies texts where
the chosen languages were English, Italian and Span-
ish. The goal was the Hypertextual linking of related
articles in one language as well as related articles in
the other project languages. One of the intermediate
goals of NAMIC was to categorise incoming news ar-
ticles, in one of the three target languages and use
Natural Language Technology to derive an ?objec-
tive representation? of the events and agents contained
within the news. This representation which is ini-
tially created once using representative news corpora
is stored in a repository and accessed in the authoring
process.
2.1 Automatic Authoring
Automatic Authoring is the task of automatically de-
riving a hypertextual structure from a set of available
news articles (in three different languages English,
Spanish and Italian in our case). This relies on the ac-
tivity of event matching. Event matching is the pro-
cess of selecting the relevant facts in a news article
in terms of their general type (e.g. selling or buying
companies, winning a football match), their partici-
pants and their related roles (e.g. the company sold or
the winning football team) Authoring is the activity
of generating links between news articles according
to relationships established among facts detected in
the previous phase.
For instance, a company acquisition can be referred
to in one (or more) news items as:
 Intel, the world?s largest chipmaker, bought a
unit of Danish cable maker NKT that designs
high-speed computer chips used in products that
direct traffic across the internet and corporate
networks.
 The giant chip maker Intel said it acquired the
closely held ICP Vortex Computersysteme, a
German maker of systems for storing data on
computer networks, to enhance its array of data-
storage products.
 Intel ha acquistato Xircom inc. per 748 milioni
di dollari.
 Le dichiarazioni della Microsoft, infatti, sono
state precedute da un certo fermento, dovuto
all?interesse verso Linux di grandi ditte quali
Corel, Compaq e non ultima Intel (che ha ac-
quistato quote della Red Hat) ...
The hypothesis underlying Authoring is that all the
above news items deal with facts in the same area of
interest to a potential class of readers. They should be
thus linked and links should suggest to the user that
the underlying motivation is that they all refer to Intel
acquisitions.
3 The NAMIC Architecture
The NAMIC system uses a modularised IE architec-
ture whose principal components, used to create the
IE repository, are morpho-syntactic analysis, cate-
gorisation and semantic analysis. During Morpho-
Syntactic analysis, a modular and lexicalised shal-
low morpho-syntactic parser (Basili et al, 2000b),
provides the extraction of dependency graphs from
source sentences. Ambiguity is controlled by part-
of-speech tagging and domain verb-subcategorisation
frames that guide the dependency recognition phase.
It is within the semantic analysis, which relies on the
output of this parser, that objects in the text, and their
relationships to key events are captured. This process
is explained in more detail in 4. In the next two sec-
tions, we will elaborate on the IE engine. For a full
description of the NAMIC Architecture see (Basili et
al., 2001).
3.1 LaSIE
In NAMIC, we have integrated a key part of the Infor-
mation Extraction system called LaSIE (Large-scale
Information Extraction system, (Humphreys et al,
1998)). Specifically, we have taken the Named Entity
Matcher and the Discourse Processor from the over-
all architecture of LaSIE. The roles of each of these
modules is outlined below.
3.1.1 Named Entity Matcher
The Named Entity (NE) Matcher finds named enti-
ties (persons, organisations, locations, and dates, in
our case) through a secondary phase of parsing which
uses a NE grammar and a set of gazetteer lists. It takes
as input parsed text from the first phase of parsing and
the NE grammar which contains rules for finding a
predefined set of named entities and a set of gazetteer
lists containing proper nouns. The NE Matcher re-
turns the text with the Named Entities marked. The
NE grammar contains rules for coreferring abbrevia-
tions as well as different ways of expressing the same
named entity such as Dr. Smith, John Smith and Mr.
Smith occurring in the same article.
3.1.2 Discourse Processor
The Discourse Processor module translates the se-
mantic representation produced by the parser into a
representation of instances, their ontological classes
and their attributes, in the XI knowledge representa-
tion language (Gaizauskas and Humphreys, 1996).
XI allows a straightforward definition of cross-
classification hierarchies, the association of arbitrary
attributes with classes or instances, and a simple
mechanism to inherit attributes from classes or in-
stances higher in the hierarchy.
The semantic representation produced by the
parser for a single sentence is processed by adding
its instances, together with their attributes, to the dis-
course model which has been constructed for a text.
Following the addition of the instances mentioned
in the current sentence, together with any presuppo-
sitions that they inherit, the coreference algorithm is
applied to attempt to resolve, or in fact merge, each
of the newly added instances with instances currently
in the discourse model.
The merging of instances involves the removal of
the least specific instance (i.e. the highest in the on-
tology) and the addition of all its attributes to the other
instance. This results in a single instance with more
than one realisation attribute, which corresponds to a
single entity mentioned more than once in the text,
i.e. a coreference.
The mechanism described here is an extremely
powerful tool for accomplishing the IE task, however,
in common with all knowledge-based approaches,
and as highlighted in the introduction to this paper,
the significant overhead in terms of development and
deployment is in the creation of the world model rep-
resentation.
4 Large-Scale World Model Acquisition
The traditional limitations of a knowledge-based in-
formation extraction system such as LaSIE have been
the need to hand-code information for the world
model - specifically relating to the event structure of
the domain. This is also valid for NAMIC. To aid the
development of the world model, a semi-automatic
boot-strapping process has been developed, which
creates the event type component of the world model.
To us, event descriptions can be categorised as a set
of regularly occurring verbs within our domain, com-
plete with their subcategorisation information.
4.1 Event Hierarchy
The domain verbs can be selected according to sta-
tistical techniques and are, for the moment, subjected
to hand pruning. Once a list of verbs has been ex-
tracted, subcategorisation patterns can be generated
automatically using a combination of weakly super-
vised example-driven machine learning algorithms.
There are mainly three induction steps. First, syn-
tactic properties are derived for each verb, express-
ing the major subcategorisation information under-
lying those verbal senses which are more important
in the domain. Then, in a second phase, verb usage
examples are used to induce the semantic properties
of nouns in argumental positions. This information
relates to selectional constraints, independently as-
signed to each verb subcategorisation pattern. Thus,
different verb senses are derived, able to describe the
main properties of the domain events (e.g. Compa-
nies acquire companies). In a third and final phase
event types are derived by grouping verbs accord-
ing to their syntactic-semantic similarities. Here,
shared properties are used to generalise from the lex-
ical level, and generate verbal groups expressing spe-
cific semantic (and thus conceptual) aspects. These
types are then fed into the event hierarchy as required
for their straightforward application within the target
IE scenario.
4.1.1 Acquisition of Subcategorisation Patterns
Each verb  is separately processed. First, each local
context (extracted from sentences in the source cor-
pus) is mapped into a feature vector describing:
 the verb  of each vector (i.e. the lexical head of
the source clause);
 the different grammatical relationships (e.g.
Subj and Obj for grammatical subject and ob-
jects respectively) as observed in the clause;
 the lexical items, usually nouns, occurring in
specific grammatical positions, e.g. the subject
Named Entity, in the clause.
Then, vectors are clustered according to the set of
shared grammatical (not lexical) properties: Only the
clauses showing the same relationships (e.g. all the
Subj- 
	 -Obj triples) enter in the same subset  .
Each cluster thus expresses a specific grammatical be-
haviour shared by several contexts (i.e. clauses) in the
corpus. The shared properties in  characterise the
cluster, as they are necessary and sufficient member-
ship conditions for the grouped contexts.
As one context can enter in more than one cluster
(as it can share all (or part) of its relations with the
others), the inclusion property establishes a natural
partial order among clusters. A cluster  is included
in another cluster  if its set of properties is larger
(i.e.  ) but it is shown only by a subset of the
contexts of the latter   . The larger the set of mem-
bership constraints is, the smaller the resulting cluster
is. In this way, clusters are naturally organised into
a lattice (called Galois lattice). Complete properties
express for each cluster candidate subcategorisation
patterns for the target verb  .
Finally, the lattice is traversed top-down and the
search stops at the more important clusters (i.e. those
showing a large set of members and characterised
by linguistically appealing properties): they are re-
tained and a lexicon of subcategorisation structures
(i.e. grammatical patterns describing different us-
ages of the same verb) is compiled for the target verb
 . For example, (buy, [Subj:X, Obj:Y]) can
be used to describe the transitive usage of the verb
	 . More details can be found in (Basili et al, 1997).
4.1.2 Corpus-driven Induction of Verb
Selectional Restrictions
The lattice can be further refined to express seman-
tic constraints over the syntactic patterns specified at
the previous stage. A technique proposed in (Basili
et al, 2000a) is adopted by deriving semantic con-
straints via synsets (i.e. synonymy sets) in the Word-
Net 1.6 base concepts (part of EuroWordNet). When
a given lattice node expresses a set of syntactic prop-
erties, then this suggests:
 a set of grammatical relations necessary to ex-
press a given verb meaning, Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 438?441,
Prague, June 2007. c?2007 Association for Computational Linguistics
USFD: Preliminary Exploration of Features
and Classifiers for the TempEval-2007 Tasks
Mark Hepple
Dept of Computer Science
University of Sheffield
Regent Court
211 Portobello Street
Sheffield S1 4DP, UK
hepple@dcs.shef.ac.uk
Andrea Setzer
Dept of Computer Science
University of Sheffield
Regent Court
211 Portobello Street
Sheffield S1 4DP, UK
andrea@dcs.shef.ac.uk
Rob Gaizauskas
Dept of Computer Science
University of Sheffield
Regent Court
211 Portobello Street
Sheffield S1 4DP, UK
robertg@dcs.shef.ac.uk
Abstract
We describe the Sheffield system used
in TempEval-2007. Our system takes
a machine-learning (ML) based approach,
treating temporal relation assignment as a
simple classification task and using features
easily derived from the TempEval data, i.e.
which do not require ?deeper? NLP analy-
sis. We aimed to explore three questions:
(1) How well would a ?lite? approach of
this kind perform? (2) Which features con-
tribute positively to system performance?
(3) Which ML algorithm is better suited for
the TempEval tasks? We used the Weka
ML workbench to facilitate experimenting
with different ML algorithms. The paper de-
scribes our system and supplies preliminary
answers to the above questions.
1 Introduction
The Sheffield team were involved in TempEval as
co-proposers/co-organisers of the task.1 For our par-
ticipation in the task, we decided to pursue an ML-
based approach, the benefits of which have been ex-
plored elsewhere (Boguraev and Ando, 2005; Mani
et al, 2006). For the TempEval tasks, this is easily
done by treating the assignment of temporal relation
types as a simple classification task, using readily
available information for the instance features. More
specifically, the features used were ones provided as
1We maintained a strict separation between persons assisting
in annotation of the test corpus and those involved in system
development.
attributes in the TempEval data annotation for the
events/times being related, plus some additional fea-
tures that could be straightforwardly computed from
documents, i.e. without the use of more heavily ?en-
gineered? NLP components. The aims of this work
were three-fold. First, we wanted to see whether a
?lite? approach of this kind could yield reasonable
performance, before pursuing possibilities that re-
lied on using ?deeper? NLP analysis methods. Sec-
ondly, we were interested to see which of the fea-
tures considered would contribute positively to sys-
tem performance. Thirdly, rather than selecting a
single ML approach (e.g. one of those currently in
vogue within NLP), we wanted to look across ML
algorithms to see if any approach was better suited
to the TempEval tasks than any other, and conse-
quently we used the Weka workbench (Witten and
Frank, 2005) in our ML experiments.
In what follows, we will first describe how our
system was constructed, before going on to discuss
our main observations around the key aims men-
tioned above. For example, in regard to our ?lite? ap-
proach, we would observe (c.f. the results reported
in the Task Description paper) that although some
other systems scored more highly, the score differ-
ences were relatively small. Regarding features, we
found for example that the system performed better
for Task A when, surprisingly, the tense attribute
of EVENTs was excluded. Regarding ML algo-
rithms, we found not only that there was substantial
variation between the effectiveness of different algo-
rithms for assigning relations (as one might expect),
but also that there was considerable differences in
the relative effectiveness of algorithms across tasks,
438
i.e. so that an algorithm performing well on one task
(compared to the alternatives), might perform rather
poorly on another task. The paper closes with some
comments about future research directions.
2 System Description
The TempEval training and test data is marked up
to identify all event and time expressions occurring
within documents, and also to record the TLINK re-
lations that are relevant for each task (except that
TLINK relation types are absent in the test data).
These annotations provide additional information
about these entities in the form of XML attributes,
e.g. for EVENT annotations we find attributes such
as tense, aspect, part-of-speech and so on.
Our system consists of a suite of Perl scripts
that create the input files required for Weka, and
handle its output. These include firstly an ?ex-
traction? script, which extracts information about
EVENT, TIMEXs and TLINKs from the data files, and
secondly a ?feature selection/reformatting? script,
which allows the information that is to be supplied
to Weka to be selected, and recasts it into the format
that Weka requires for its training/test files. A final
script takes Weka?s output over the test files and con-
nects it back to the original test documents to pro-
duce the final output files required for scoring.
The information that the first extraction script ex-
tracts for each EVENT, TIMEX and TLINK largely
corresponds to attributes/values associated with the
annotations of these items in the initial data files
(although not all such attributes are of use for ma-
chine learning purposes). In addition, the script de-
termines for each EVENT expression whether it is
one deemed relevant by the Event Target List (ETL)
for Tasks A and B. This script also maps EVENTs
and TIMEXs into sequential order ? intra-sentential
order for task A and inter-sentential order for task
C. This information can be used to compute various
?order? features, such as:
event-first: do a related EVENT and TIMEX
(for Task A) appear with the EVENT before or after
the TIMEX?
adjacent: do a related EVENT and TIMEX (again
for Task A) appear adjacently in the sequence of
temporal entities or not? (Note that this allows an
EVENT and TIMEX to be adjacent if there tokens
Task
Type Attribute A B C
EVENT aspect X X X
EVENT polarity X X ?
EVENT POS X X X
EVENT stem X ? ?
EVENT string ? ? ?
EVENT class ? X X
EVENT tense ? X X
ORDER adjacent X N/A N/A
ORDER event-first X N/A N/A
ORDER event-between ? N/A N/A
ORDER timex-between ? N/A N/A
TIMEX3 mod X ? N/A
TIMEX3 type X ? N/A
TLINK reltype X X X
Table 1: Features
that intervene, but not any other temporal entities.)
event-between: for a related EVENT/TIMEX
pair, do any other events appear between them?
timex-between: for a related EVENT/TIMEX
pair, do any other timexes appear between them?
Table 1 lists all the features that we tried using
for any of the three tasks. Aside from the OR-
DER features (as designated in the leftmost col-
umn), which were computed as just described, and
the EVENT string feature (which is the literal
tagged expression from the text), all other features
correspond to annotation attributes. Note that the
TLINKreltype is extracted from the training data
to provide the target attribute for training (a dummy
value is provided for this in test data).
The output of the extraction script is converted to
a format suitable for use by Weka by a second script.
This script also allows a manual selection to be made
as to the features that are included. For each of the
three tasks, a rough-and-ready process was followed
to find a ?good? set of features for use with that
task, which proceeded as follows. Firstly, the maxi-
mal set of features considered for the task was tried
with a few ML algorithms in Weka (using a 10-fold
cross-validation over the training data) to find one
that seemed to work quite well for the task. Then
using only that algorithm, we checked whether the
string feature could be dropped (since this fea-
439
ture?s value set was always of quite high cardinality),
i.e. if its omission improved performance, which for
all three tasks was the case. Next, we tried dropping
each of the remaining features in turn, to identify
those whose exclusion improved performance, and
then for those features so identified, tried dropping
them in combination to arrive at a final ?optimal? fea-
ture set. Table 1 shows for each of the tasks which
of the features were considered for inclusion (those
marked N/A were not), and which of these remained
in the final optimal feature set (X).
Having determined the set of features for use with
each task, we tried out a range of ML algorithms
(again with a 10-fold cross-validation over the train-
ing data), to arrive at the final feature-set/ML algo-
rithm combination that was used for the task in the
competitive evaluation. This was trained over the
entire training data and applied to the test data to
produce the final submitted results.
3 Discussion
Looking to Table 1, and the features that were con-
sidered for each task and then included in the final
set, various observations can be made. First, note
that the string feature was omitted for all tasks,
which is perhaps not surprising, since its values will
be sparsely distributed, so that there will be very few
training instances for most of its individual values.
However, the stem feature was found to be use-
ful for Task A, which can be interpreted as evidence
for a ?lexical effect? on local event-timex relations,
e.g. perhaps with different verbs displaying different
trends in how they relate to timexes. No correspond-
ing effects were observed for Tasks B and C.
The use of ORDER features for Task A was found
to be useful ? specifically the features indicating
whether the event or timex appeared linearly first in
the sentence and whether the two were adjacent or
not. The more elaborate ORDER features, address-
ing more specific cases of what might intervene be-
tween the related timex and event expression, were
not found to be helpful.
Perhaps the most striking observation to be made
regarding the table is that it was found beneficial to
exclude the feature tense for Task A, whilst the
feature aspect was retained. We have no expla-
nation to offer for this result. Likewise, the event
Task
Algorithm A B C
baseline 49.8 62.1 42.0
lazy.KStar 58.2 76.7 54.0
rules.DecisionTable 53.3 79.0 52.9
functions.SMO (svm) 55.1 78.1 55.5
rules.JRip 50.7 78.6 53.4
bayes.NaiveBayes 56.3 76.2 50.7
Table 2: Comparing different algorithms (%-acc.
scores, from cross-validation over training data)
class feature, which distinguishes e.g. perception
vs. reporting vs. aspectual etc verbs, was excluded
for Task A, although it was retained for Task B.
In regard to the use of different ML algorithms for
the classification tasks addressed in TempEval, we
observed considerable variation between algorithms
as to their performance, and this was not unexpected.
However, given the seemingly high similarity of the
three tasks, we were rather more surprised to see that
there was considerable variation between the perfor-
mance of algorithms across tasks, i.e. so that an al-
gorithm performing well on one task (compared to
the alternatives), might perform rather poorly on an-
other task. This is illustrated by the results in Table 2
for a selected subset of the algorithms considered,
which shows %-accuracy scores that were computed
by cross-validation over the training data, using the
feature set chosen as ?optimal? for each task.2 The
algorithm names in the left-hand column are the
ones used in WEKA (of which functions.SMO
is the WEKA implementation of support-vector ma-
chines or SVM). The first row of results give a ?base-
line? for performance, corresponding to the assign-
ment of the most common label for the task. (These
were produced using WEKA?s rules.ZeroR al-
gorithm, which does exactly that.)
The best results observed for each task are shown
in bold in the table. These best performing al-
gorithms were used for the corresponding tasks in
the competition. Observe that the lazy.KStar
2These scores are computed under the ?strict? requirement
that key and response labels should be identical. The TempE-
val competition also uses a ?relaxed? metric which gives par-
tial credit when one (or both) label is disjunctive and there is a
partial match, e.g. between labels AFTER and OVERLAP-OR-
AFTER. See (Verhagen et al, 2007) for details.
440
Task A Task B Task C
FS FR FS FR FS FR
USFD 0.59 0.60 0.73 0.74 0.54 0.59
ave. 0.56 0.59 0.74 0.75 0.51 0.60
max. 0.62 0.64 0.80 0.81 0.55 0.66
Table 3: Competition task scores for Sheffield sys-
tem (USFD), plus average/max scores across all
competing systems
method, which gives the best performance for Task
A, gives a rather ?middling? performance for Task
B. Similarly, the SVM method that gives the best
results for Task C falls quite a way below the per-
formance of KStar on Task A. A more extreme
case is seen with the results for rules.JRip
(Weka?s implementation of the RIPPER algorithm),
whose score for Task B is close to that of the best-
performing system, but which scores only slightly
above baseline on Task A.
The competition scores for our system are given
in Table 3, shown as (harmonic) F-measures under
both strict (FS) and relaxed (FR) metrics (see foot-
note 2). The table also shows the average score for
each task/metric across all systems taking part in the
competition, as well as the maximum score returned
by any system. See (Verhagen et al, 2007) for a full
tabulation of results for all systems.3
4 Future Directions
SIGNALs and SLINKs are possible candidates as
additional features ? signals obviously so, whereas
the benefits of exploiting subordination information
are less clear. Our initial exploratory efforts in
this direction involved pulling information regard-
ing SIGNALs and SLINKs across from TimeBank4
(Pustejovsky et al, 2003) so as to make this avail-
3The TempEval test data identifies precisely the temporal
entity pairs to which a relation label must be assigned. When
a fixed set of items is classified, the scores for precision, recall
and F-measure will be identical, being the same as the score for
simple accuracy. However, not all the participating systems fol-
low this pattern of assigning labels to ?all and only? the entity
pairs identified in the test data, i.e. some systems decide which
entity pairs to label, as well as which label to assign. Accord-
ingly, the performance results given in (Verhagen et al, 2007)
are reported using metrics of precision, recall and F-measure.
4This was possible because both the trial and training data
were derived from TimeBank.
able for use with the TempEval tasks, in the hope
that this would allow us to determine if this informa-
tion would be useful without first facing the cost of
developing SIGNAL and SLINK recognisers. Re-
garding SIGNALs, however, we ran into the prob-
lem that there are many TLINKs in the TempEval
data for which no corresponding TLINK appears
in TimeBank, and hence for which SIGNAL infor-
mation could not be imported. We were unable to
progress this work sufficiently in the time available
for there to be any useful results to report here.
5 Conclusion
We have explored using a ML-based approach to
the TempEval tasks, which does not rely on the use
of deeper NLP-analysis components. We observe
that although some other systems in the competi-
tion have produced higher scores for the tasks, the
score differences are relatively small. In the course
of this work, we have made some interesting ob-
servations regarding the performance variability of
different ML algorithms when applied to the diffent
TempEval tasks, and regarding the features that con-
tribute to the system?s performance.
References
B. Boguraev and R. Kubota Ando. 2005. TimeML-
Compliant Text Analysis for Temporal Reasoning. In
Proceedings of IJCAI-05, pages 997?1003.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min
Lee, and James Pustejovsky. 2006. Machine Learning
of Temporal Relations. In ACL ?06: Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the ACL,
pages 753?760, Morristown, NJ, USA. Association for
Computational Linguistics.
J. Pustejovsky, D. Day, L. Ferro, R. Gaizauskas, P. Hanks,
M. Lazo, D. Radev, R. Saur??, A. See, A. Setzer, and
B. Sundheim. 2003. The TIMEBANK Corpus. In
Proceedings of Corpus Linguistics 2003, pages 647?
656, Lancaster, March.
M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple,
G. Katz, and J. Pustejovsky. 2007. SemEval-2007
Task 15: TempEval Temporal Relation Identification.
In Proceedings of SemEval-2007: 4th International
Workshop on Semantic Evaluations.
I.H. Witten and E. Frank, editors. 2005. Data Mining:
Practical Machine Learning Tools and Techniques.
Morgan Kaufmann, San Francisco, second edition.
441
