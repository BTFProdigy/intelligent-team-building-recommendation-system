Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,
pages 15?23, Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Variable-Length Markov Models and Ambiguous Words in Portuguese?
Fabio Natanael Kepler
Institute of Mathematics and Statistics
University of Sao Paulo
Sao Paulo, SP, Brazil
kepler@ime.usp.br
Marcelo Finger
Institute of Mathematics and Statistics
University of Sao Paulo
Sao Paulo, SP, Brazil
mfinger@ime.usp.br
Abstract
Variable-Length Markov Chains (VLMCs) of-
fer a way of modeling contexts longer than
trigrams without suffering from data sparsity
and state space complexity. However, in His-
torical Portuguese, two words show a high de-
gree of ambiguity: que and a. The number
of errors tagging these words corresponds to a
quarter of the total errors made by a VLMC-
based tagger. Moreover, these words seem to
show two different types of ambiguity: one
depending on non-local context and another
on right context. We searched ways of ex-
panding the VLMC-based tagger with a num-
ber of different models and methods in order
to tackle these issues. The methods showed
variable degrees of success, with one particu-
lar method solving much of the ambiguity of
a. We explore reasons why this happened, and
how everything we tried fails to improve the
precision of que.
1 Introduction
In the Computational Linguistics area, the task of
part-of-speech tagging (POS tagging) consists in as-
signing to words in a text the grammatical class they
belong. Since the same word may belong to more
than one class, models for POS tagging have to look
at the context where each word occurs to try to solve
the ambiguity.
Previous and current work have developed a wide
range of models and methods for tagging. The vast
majority uses supervised learning methods, which
?During the course of this work Fabio received support from
Brazilian funding agencies CAPES and CNPq.
need an already tagged corpus as input in order to
train the model, calculating relations, weights, prob-
abilities etc.
Among the various models for tagging, there are
Maximum Entropy models (dos Santos et al, 2008;
de Almeida Filho, 2002; Ratnaparkhi, 1996), Hid-
den Markov Models (HMMs) (Brants, 2000), Trans-
formation Based Learning (Brill, 1993), and other
succesful approaches (Toutanova et al, 2003; Tsu-
ruoka and Tsujii, 2005; Shen et al, 2007).
Current state-of-the-art precision in tagging is
achieved by supervised methods. Although preci-
sion is pretty high ? less than 3% error rate for
English ? the disavantage is exactly the need of a
tagged corpus, usually built manually. This is a very
restrictive issue for languages with lack of resources
such as linguistic especialists, corpora projects etc.
The Portuguese language falls in between re-
sourceful languages, such as English, and languages
with restricted resources. There have been initia-
tives both in Brazil and in Portugal, which include
modern Brazilian Portuguese corpora (ICMC-USP,
2010), European Portuguese corpora (Flo, 2008),
and historical Portuguese corpora (IEL-UNICAMP
and IME-USP, 2010). Also, some supervised POS
taggers have already been developed for Portuguese
(dos Santos et al, 2008; Kepler and Finger, 2006;
Aires, 2000) with a good degree of success. And fi-
nally, there has also been increasing effort and in-
terest in Portuguese annotation tools, such as E-
Dictor1 (de Sousa et al, 2009).
Despite these advances, there is still lack of mate-
rial and resources for Portuguese, as well as research
1See http://purl.org/edictor.
15
in unsupervised methods to bootstrap text annota-
tion.
Our work focuses on further improvement of the
current state-of-the-art in Portuguese tagging. For
this, we focus on the Tycho Brahe (IEL-UNICAMP
and IME-USP, 2010) corpus for testing and bench-
marking, because of its great collaboration potential:
it is easily accessible2; is under continuous develop-
ment; and has recently started using E-Dictor, which
also offers a great collaboration potential.
1.1 Previous Works
One popular approach to tagging is to use HMMs
of order 2. Order 2, or trigram, means the tagger
considers the previous two words/tags when tagging
a word. This adds context to help disambiguation.
The drawback is that this context may not be suf-
ficient. Increasing the order does not help, since
this incurs in too many model parameters and suf-
fers from the data sparsity problem.
In (Kepler and Finger, 2006), we developed a tag-
ger for Portuguese that uses Markov chains of vari-
able length, that is, orders greater than 2 can be
used conditioned on certain tags and sequences of
tags. This approach is better at avoiding the spar-
sity and complexity problems, while being able to
model longer contexts. However, one interesting
conclusion from that work is that, even using longer
contexts, some words stay extremely hard to disam-
biguate. Apparently, those words rely on flexible
contexts not captured by pure VLMCs.
Motivated by this problem, we improve over the
previous work, and developed a set of tagger models
based on Variable-Length Markov Chains (VLMCs)
extended with various other approaches in order to
try to tackle the problem.
In the next section we describe the VLMC theory,
the results it achieves, and the problems with two
common words. Then, in Section 3, we explain in
summary the set of models and approaches we tried
to mix with VLMCs, and the different types of re-
sults they give. Conclusions are drawn in Section 4.
Finally, Section 5 describes how this work can be in-
corporated in other projects, and Section 6 presents
ideas for future work.
2More information at http://www.tycho.iel.
unicamp.br/~tycho/corpus/en/index.html.
2 Variable-Length Markov Chains
The idea is to allow the memory of a Markov chain
to have variable length, depending on the observed
past values. (B?hlmann and Wyner, 1999) give a
formal description of VLMCs, while here we will
explain them in terms of the POS-tagging task.
Consider a Markov chain with a finite, large order
k. Let ti be a tag, and ti?k,i?1 be the k tags preced-
ing ti. Variable length memory can be seen as a cut
of irrelevant states from the ti?k,i?1 history. We call
the set of these states the context of ti. Given a tag
ti, its context ti?h,i?1, h ? k, is given by the context
function c(ti?k,i?1).
A context tree is a tree in which each internal node
has at most |T | children, where T is the tagset. Each
value of a context function c(?) is represented as a
branch of such tree. For example, the context given
by c(ti?k,i?1) is represented as a branch whose sub-
branch at the top is determined by ti?1, the next sub-
branch by ti?2, and so on, until the leaf, determined
by ti?h.
The parameters of a VLMC are the underlying
functions c(?) and their probabilities. To obtain these
parameters we use a version of the context algorithm
of (Rissanen, 1983). First, it builds a big context
tree, using a training corpus. For a tag ti, its maxi-
mal history ti?k,i?1 is placed as a branch in the tree.
Then, the algorithm uses a pruning function consid-
ering a local decision criterion. This pruning cuts
off the irrelevant states from the tags? histories. For
each leaf u in the context tree, and branch v that goes
from the root to the parent node of u, u is pruned
from the tree if
?vu =
?
t?L
P (t|vu) log
(
P (t|vu)
P (l|v)
)
C(vu) < K,
whereC(vu) is the number of occurrences of the se-
quence vu in the training corpus, and K is a thresh-
old value, called the cut value of the context tree,
If the probability of a tag does not change much
between considering the entire branch together with
the leaf (all past history) and considering only the
branch (the history without the furthest tag), then the
leaf does not need to be considered, and can be re-
moved from the tree.
We want to find the best sequence of tags t1 . . . tn
for a given sequence of words w1 . . . wn of size n,
16
that is,
arg max
t1...tn
[
n?
i=1
P (ti|c(ti?k,i?1))P (wi|ti)
]
.
Probabilities are computed from a tagged training
corpus using maximum likelihood estimation from
the relative frequencies of words and sequences of
tags. The context tree is built with sequences of tags
of maximum length k and then pruned, thus defin-
ing the context functions. For decoding, the Viterbi
Algorithm is used (Viterbi, 1967).
2.1 Initial Results
We used the tagged texts available by the Ty-
cho Brahe Corpus of Historical Portuguese (IEL-
UNICAMP and IME-USP, 2010). The Tycho Brahe
project uses 377 POS and inflectional tags, and con-
tains annotated texts written by authors born be-
tween 1380 and 1845. We have selected 19 texts
for composing our corpus, which contains 1035593
tagged words and has 262 different tags. This cor-
pus was then randomly divided into 75% of the sen-
tences for generating a training corpus and 25% for
a testing corpus. The training corpus has 775602
tagged words, while the testing corpus has 259991
tagged words. The Tycho Brahe project is under-
going rapid development, so as for today there are
more texts available which are not present in the cor-
pus we used3.
Because of some of the approaches explained be-
low, we also created a new training corpus and a new
testing corpus by segmenting contracted words from
the original corpus. Contracted words are words like
da, which has the tag P+D-F and is a contraction of
the preposition de (P) with the feminine determiner
a (D-F).
Using the original corpus, our VLMC implemen-
tation, which we will call VLMM TAGGER4 (from
Variable Length Markov Model), and which better
implements under- and overflow control, achieves
3We can provide the training and testing corpus if requested
by email.
4A package containing the VLMM TAGGER will be
available at http://www.ime.usp.br/~kepler/
vlmmtagger/, but requests for the raw source code can be
made by email. Currently, there is only an automake bundle
ready for download containing the VLMC TAGGER.
96.29% of precision5, while the VLMC TAGGER
from (Kepler and Finger, 2006) achieves 95.51%.
Table 1 shows the numbers for both taggers, where P
and E means Precision and Error, respectively. The
difference in precision is mainly due to a 21.64%
error reduction in known words tagging6. That,
combined with 6.82% error reduction in unknown
words, results in 17.50% total error reduction. With
the segmented corpus the VLMM TAGGER achieved
96.54% of precision.
TAGGER WORDS P (%) ERR. / OCURR.
VLMC
Unknown 69.53 2713 / 8904
Known 96.39 9065 / 251087
Total 95.51 11674 / 259991
VLMM
Unknown 71.60 2528 / 8904
Known 97.17 7102 / 251087
Total 96.29 9630 / 259991
Table 1: Precision of VLMC-based taggers.
Table 2 shows numbers for the two words that
present the most number of errors made by the
VLMM TAGGER. Note that they are not necessarily
the words with the highest error percentage, since
there are known words that appear only a couple of
times in the testing corpus and may get wrong tags
half of this times, for example.
WORDS P (%) E (%) ERR. / OCURR.
que 84.7413 15.2586 1687 / 11056
a 90.9452 9.0547 661 / 7300
Table 2: Results for words with the most number of errors
using the VLMM TAGGER with the normal corpus.
These two words draw attention because together
they correspond to almost 25% of the errors made by
the tagger, where most confusion for each of these
words is between two different tags:
? The word que is, most of the times, either a rel-
ative pronoun ? denoted by the tag WPRO and
5Precision is given by the number of correctly assigned tags
to the words in the testing corpus over the total number of words
in the testing corpus.
6Known words are words that appear both in the training and
the testing corpus.
17
equivalent to the word which in English ?, or a
subordinating conjunction ? denoted by the tag
C and equivalent, in English, to the words that
or than;
? The word a is, usually, either a feminine deter-
miner (tag D-F), or a preposition (tag P).
As a baseline, assigning the most common tag to que
yields a precision of 55.64%, while a gets a preci-
sion of 58.09%. Also, these words seem to show two
different types of ambiguity: one that needs con-
text to the right, and one that needs non-local con-
text. The VLMM model does not have parameters
for these contexts, since it tags from left to right us-
ing context immediately to the left.
2.2 Objectives
It seems that a could be better disambiguated by
looking at words or tags following it: for example,
if followed by a verb, a is much more likely to be a
preposition. For que, it seems that words occuring
not immediately before may add important informa-
tion. For example, if que follows mais (more than,
in English), it is more likely that que has tag C. How-
ever, like in the English expression, it is possible to
have various different words in between mais and
que, as for example: ?mais prov?vel que? (?more
likely than?); ?mais caro e complexo que? (?more
expensive and complex than?); and so on. Thus, it
may yield better results if non-local context could
be efficiently modeled.
In order to develop these ideas about que and a
and prove them right or wrong, we searched ways of
expanding the VLMM tagger with a number of dif-
ferent models and methods that could help solving
these two issues. Those models are described next.
3 Auxiliary Approaches
3.1 Syntactic Structure
The first idea we had was to generalize nodes in the
VLMM?s context tree, that is, to model a way of ab-
stracting different sequences of tags into the same
node. This could make it possible to have branches
in the context tree like ADV * C, that could be used
for mais * que.
One way of doing this is to use sequences of tags
that form phrases, like noun phrases (NP), preposi-
tional phrases (PP), and verbal phrases (VP), and use
them in the context tree in place of the sequences
of tags they cover. The context tree will then have
branches like, say, P VP N.
In order to train this mixed model we need a tree-
bank, preferably from the texts in the Tycho Brahe
corpus. However, it does not have a sufficiently large
set of parsed texts to allow efficient supervised learn-
ing. Moreover there is not much Portuguese tree-
banks available, so we were motivated to implement
an unsupervised parsed for Portuguese.
Based on the work of (Klein, 2005), we imple-
mented his CCM model, and used it over the Ty-
cho Brahe corpus. The CCM model tries to learn
constituents based on the contexts they have in com-
mon. We achieved 60% of f-measure over a set of
texts from the Tycho Brahe project that were already
parsed.
Using the CCM constituents learned, we ex-
tended the VLMM TAGGER to use this extra infor-
mation. It yielded worse results, so we restricted the
use of constituents to que (the VLMM+SPANS-QUE
TAGGER). This yielded a precision of 96.56%, with
a que precision increase of 3.73% and an a precision
reduction of 0.67%. A comparison with the plain
VLMM TAGGER over the segmented corpus can be
seen in Table 3. We use the segmented corpus for
comparison because the constituents only use seg-
mented tags. Even after many tries and variations in
WORDS P (%) ERR. / OCURR.
que
84 .50 1715 / 11063
85.18 1651 / 11063
a
94 .52 745 / 13597
94.49 750 / 13597
Total
96 .5433 9559 / 276541
96.5636 9503 / 276541
Table 3: Comparison of precision using the VLMM TAG-
GER (in italics) and the VLMM+SPANS-QUE TAGGER
(upcase) with the segmented corpus.
the way the VLMM TAGGER could use constituents,
the result did not improve. This led us to a new ap-
proach, shown in the next section.
18
3.2 Chunks
Since induced syntactic structure did not help, a new
idea was to, this time, begin with the already parsed
and revised texts from the Tycho Brahe, even with
they summing only a little more than 300 thousand
words. To ease the problem of sparsity, the trees
were flattened and merged in such a way that only
NPs, PPs and VPs remained. Then the bracketed no-
tation was converted to the IOB notation, now form-
ing a chunked corpus.
Chunking, or shallow parsing, divides a sen-
tence into non-overlapping phrases (Manning and
Sch?tze, 1999). It is used in information extraction
and in applications where full parsing is not nec-
essary, offering the advantage of being simpler and
faster.
We made a small experiment with the chunked
corpus: divided the sentences randomly into 90%
and 10% sets, the former for training and the later
for testing. Then we ran the VLMM TAGGER with
these chunked sets, and got a precision in chunking
of 79%.
A model for chunks processing was mixed into
the VLMM model, similar but not equal to the mixed
model with CCM. The chunked corpus uses seg-
mented words, because the parsed texts available in
Tycho Brahe only use segmented words. Thus, we
ran the VLMM TAGGER with the segmented training
corpus and the chunked corpus, testing over the seg-
mented test corpus. The precision yielded with this
VLMM+CHUNKS TAGGER was 96.55%.
Table 4 shows the results for the segmented
corpus with the VLMM TAGGER and the
VLMM+CHUNKS TAGGER. Interestingly, results did
not change much, in spite of the VLMM+CHUNKS
TAGGER achieving a higher precision. Interestingly,
the word a error rate is reduced by around 13%
with the help of chunks, while the que error rate
increases almost 3%.
3.3 Bidirectional
Another approach was to follow the intuition about
a: that the right context should help solving some
ambiguities. The problem that makes this approach
non trivial is that a right tag context is not yet avail-
able when tagging a word, due to the natural left-to-
right order the tagger follows when tagging a sen-
WORDS P (%) ERR. / OCURR.
que
84 .50 1715 / 11063
84.05 1764 / 11063
a
94 .52 745 / 13597
95.26 644 / 13597
Total
96 .5433 9559 / 276541
96.5506 9539 / 276541
Table 4: Comparison of precision using the VLMM TAG-
GER (in italics) and the VLMM+CHUNKS TAGGER (up-
case) with the segmented corpus.
tence. A right context that is available is the context
of words to the right, but this presents the problem
of sparsity and will probably not yield good results.
Our approach was then to model a right context of
tags when the words to the right were not ambigu-
ous, that is, if they could be assigned only one spe-
cific tag. During training, a new context tree is built
for the right context, where, for each word in a sen-
tence, a continuous but variable-length sequence of
tags from unambiguous words to the right is added
as a branch to the right context tree. That is, if k
words to right of a given word are not ambiguous,
then the sequence of the k tags these words will have
is added to the right tree. The right context tree is
also prunned like the left context tree and the Viterbi
algorithm for tagging is adapted to consider these
new parameters.
WORDS P (%) ERR. / OCURR.
que
84 .74 1687 / 11056
84.80 1680 / 11056
a
90 .94 661 / 7300
92.15 573 / 7300
Total
96 .29 9630 / 259991
96.33 9544 / 259991
Table 5: Comparison of precision using the VLMM TAG-
GER (in italics) and the VLMM+A-RIGHT TAGGER (up-
case) with the normal corpus.
After various tests with different options for the
right context tree, the result over the original VLMM
tagger did not improve. We then experimented
building the right context tree only for the word a,
19
resulting in the VLMM+RIGHT-A TAGGER. Table 5
shows what happens with the normal corpus.The er-
ror rate of a is decreased almost 5% with this bidi-
rectional approach.
3.4 Perceptron
The Perceptron algorithm was first applied to POS-
tagging by (Collins, 2002). It is an algorithm for
supervised learning that resembles Reinforcement
Learning, but is simpler and easier to implement.
(Collins, 2002) describes the algorithm for tri-
gram HMM taggers. Here, we will describe it for
the VLMM tagger, adapting the notation and expla-
nation.
Instead of using maximum-likelihood estimation
for the model parameters, the perceptron algorithm
works as follows. First, the model parameters are
initialized to zero. Then, the algorithm iterates a
given number of times over the sentences of the
training corpus. For each sentence s, formed by a
sequence of wordsws paired with a sequence of tags
ts, the Viterbi decoding is ran over ws, returning zs,
the predicted sequence of tags. Then, for each se-
quence of tags o of length at most k, k the maximum
order of the VLMC, seen c1 times in ts and c2 times
in zs, we make ?c(o) = ?c(o) + c1 ? c2. c(o) is the
context function defined in Section 2 applied to the
tag sequence o, which returns the maximum subse-
quence of o found in the context tree. ?c(o) repre-
sents the parameters of the model associated to c(o),
that is, the branch of the context tree that contains
c(o).
The above procedure effectively means that pa-
rameters which contributed to errors in zs are penal-
ized, while parameters that were not used to predict
zs are promoted. If ts = zs then no parameter is
modified. See (Collins, 2002) for the proof of con-
vergence.
Implementing the perceptron algorithm into the
VLMM tagger resulted in the VLMM+PERCEPTRON
TAGGER. Table 6 shows the results obtained. Note
that no prunning is made to the context tree, because
doing so led to worse results. Training and predict-
ing with a full context tree of height 10 achieved bet-
ter precision. The numbers reported were obtained
after 25 iterations of perceptron training. The total
precision is lower than the VLMM TAGGER?s preci-
sion, but it is interesting to note that the precision for
que and a actually increased.
WORDS P (%) ERR. / OCURR.
que
84 .74 1687 / 11056
85.15 1641 / 11056
a
90 .94 661 / 7300
92.41 554 / 7300
Total
96 .29 9630 / 259991
95.98 10464 / 259991
Table 6: Comparison of precision using the VLMM TAG-
GER (in italics) and the VLMM+PERCEPTRON TAGGER
(upcase) with the normal corpus.
3.5 Guided Learning
(Shen et al, 2007) developed new algorithms based
on the easiest-first strategy (Tsuruoka and Tsujii,
2005) and the perceptron algorithm. The strategy is
to first tag words that show less ambiguity, and then
use the tags already available as context for the more
difficult words. That means the order of tagging is
not necessarily from left to right.
The inference algorithm works by maintaining
hypotheses of tags for spans over a sequence of
words, and two queues, one for accepted spans and
one for candidate spans. Beam search is used for
keeping only a fixed number of candidate hypothe-
ses for each accepted span. New words from the
queue of candidates are tagged based on their scores,
computed by considering every possible tag for the
word combined with all the available hypotheses on
the left context and on the right context. The high-
est scoring word is selected, the top hypotheses are
kept, and the two queues are updated. At each step
one word from the queue of candidates is selected
and inserted in the queue of accepted spans.
The core idea of Guided Learning (GL) training is
to model, besides word, tag, and context parameters,
also the order of inference. This is done by defin-
ing scores for hypotheses and for actions of tagging
(actions of assigning a hypothesis). The score of a
tagging action if computed by a linear combination
of a weight vector and a feature vector of the action,
which also dependes on the context hypotheses. The
score of a given span?s hypothesis is the sum of the
scores of the top hypothesis of the left and right con-
20
texts (if available) plus the score of the action that
led to this hypothesis.
The GL algorithm estimates the values of the
weight vector. The procedure is similar to the in-
ference algorithm. The top scoring span is selected
from the queue of candidate spans and, if its top
hipothesis matches the gold standard (the tags from
the training corpus), the queues of accepted and can-
didate spans are updated as in the inference algo-
rithm. Otherwise, the weight vector is updated in
a perceptron style by promoting the features of the
gold standard action and demoting the features of
the top hypothesis? action. Then the queue of can-
didate spans is regenerated based on the accepted
spans.
This model uses trigrams for the left and right
contexts, and so it could be potentially extended by
the use of VLMCs. It is our aim to develop a tagger
combining the VLMM and the GL models. But as
for today, we have not yet finished a succesful imple-
mentation of the GL model in C++, in order to com-
bine it with the VLMM TAGGER?s code (current code
is crashing during training). Original GL?s code is
written in Java, which we had access and were able
to run over our training and testing corpora.
Table 7 shows the result over the normal corpus.
The first thing to note is that the GL model does a
pretty good job at tagging. The precision means a
10% error reduction. However, the most interesting
thing happens with our two words, que and a. The
precision of que is not significantly higher. How-
ever, the error rate of a is reduced by half. Such per-
formance shows that the thought about needing the
right context to correctly tag a seems correct. Ta-
ble 8 shows the confusion matrix of the most com-
mon tags for a.
4 Conclusions
In almost all extended versions of the VLMM TAG-
GER, que and a did not suffer a great increase in
precision. With the approaches that tried to gener-
alize context ? by using syntactic structure ? and
capture longer dependencies for que, the results did
not change much. We could see, however, that the
right context does not help disambiguating que at
all. Training the VLMM model with a long context
(order 10) helped a little with a, but showed over-
WORDS P (%) ERR. / OCURR.
que
84 .74 1687 / 11056
84.90 1670 / 11056
a
90 .94 661 / 7300
95.49 329 / 7300
Total
96 .29 9630 / 259991
96.67 8650 / 259991
Table 7: Comparison of precision using the VLMM TAG-
GER (in italics) and the GUIDED LEARNING TAGGER (up-
case) with the normal corpus.
D-F P CL
D-F <4144> 92 5
P 189 <2528> 2
CL 26 9 <294>
Table 8: Confusion matrix for a with the most common
tags in the normal corpus (line: reference; column: pre-
dicted).
all worse results. Modeling a right context for a in
a simple manner did also help a little, but not sig-
nificantly. The model that gave good results for a
was the one we still have not finished extending with
VLMM. It looks promising, but a way of better dis-
ambiguating que was not found. A better approach
to generalize contexts and to try to capture non-local
dependencies is needed. Some further ideas for fu-
ture work or work in progress are presented in Sec-
tion 6.
5 Oportunities for Collaboration
Tycho Brahe is a corpus project undergoing contin-
uous development. Since there is already a good
amount of resource for supervised tagging, our tag-
ger can be used for boosting new texts annotation.
Furthermore, the project has started using E-Dictor,
an integrated annotation tool. E-Dictor offers a
range of easy to use tools for corpora creators: from
transcription, philological edition, and text normati-
zation, to morphosyntactic annotation. This last tool
needs an integrated POS-tagger to further ease the
human task of annotation. Besides, an increasing
number of projects is starting and willing to start us-
ing E-Dictor, so the need for an automatic tagger
21
is getting urgent. We have already been contacted
by the E-Dictor developers for further collaboration,
and should integrate effors during this year.
Another project that can benefit from a good POS-
tagger is the Brasiliana Digital Library, from the
University of Sao Paulo7. It started last year digi-
talizing books (and other pieces of literature) about
Brazil from the 16th to the 19th century, mak-
ing them available online. Many books have been
OCRed, and a side project is already studying ways
of improving the results. Since the library is an
evolving project, the texts will soon be of reason-
able size, and will be able to form another corpus of
historical Portuguese A POS-tagger will be of great
help in making it a new resource for Computational
Linguistics research. We are already negotiating a
project for this with the Brasiliana directors.
There is a tagger for Portuguese embedded in
the CoGrOO8 gramatical corrector for Open Of-
fice. They seem to implement some interesting rules
for common use Portuguese that maybe would help
some of our disambigation problems. Besides in-
specting the available open source code, we have
contacted the current maintainer for further conver-
sation. A possibility that has appeared is to integrate
the VLMM TAGGER with CoGrOO.
Using different data would be interesting in or-
der to check if the exactly same problems arise, or
if other languages show the same kind of problems.
We will try to get in contact with other projects hav-
ing annotated resources available, and seek for fur-
ther collaboration. Currently, we got in touch with
people working on another corpus of Portuguese9.
Both sides are hoping to form a partnership, with us
providing a POS tagger and them the annotated cor-
pora.
6 Future Work
Short term future work includes implementing
Guided Learning in C++ and mixing it with VLMCs.
This looks promising since the current GL imple-
mentation uses a fixed trigram for contexts to the
left and to the right. Also, there is a need for fast
execution in case our tagger is really integrated into
7http://www.brasiliana.usp.br/bbd
8http://cogroo.sf.net/.
9History of Portuguese spoken in S?o Paulo (caipira
Project).
E-Dictor, so converting GL to C++ seems more nat-
ural than implementing the VLMM TAGGER in Java.
To try to tackle the difficulty in tagging que there
are some ideas about using context trees of non-
local tags. It seems a potentialy good model could
be achieved by mixing such context trees with the
Guided Learning approach, making a hypothesis
consider non adjacent accepted spans. This is still
a fresh idea, so further investigation on maybe other
approaches should be done first.
Further investigation involves analyzing errors
made by POS taggers over modern Portuguese and
other romance languages like Spanish in order to
verify if que and a continue to have the same de-
gree of ambiguity or, in case of Spanish, if there are
similar words which show similar issues. This also
involves testing other taggers with our training and
testing sets, to check if they get the same errors over
que and a as we did.
References
Rachel Virg?nia Xavier Aires. 2000. Implementa??o,
adapta??o, combina??o e avalia??o de etiquetadores
para o portugu?s do brasil. mathesis, Instituto de Ci?n-
cias Matem?ticas e Computa??o, Universidade de S?o
Paulo - Campus S?o Carlos, Oct.
Thorsten Brants. 2000. Tnt ? a statistical part-of-speech
tagger. In Proceedings of the Sixth Applied Natural
Language Processing Conference (ANLP-2000), Seat-
tle, WA.
Eric Brill. 1993. Automatic grammar induction and pars-
ing free text: A transformation-based approach. In
Proceedings of the 21st Annual Meeting of the Asso-
ciation for Computational Linguistics.
Peter B?hlmann and Abraham J. Wyner. 1999. Variable
length markov chains. Annals of Statistics, 27(2):480?
513.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: theory and experi-
ments with perceptron algorithms. In EMNLP ?02:
Proceedings of the ACL-02 conference on Empirical
methods in natural language processing, pages 1?8,
Morristown, NJ, USA. Association for Computational
Linguistics.
Archias Alves de Almeida Filho. 2002. Maximiza??o
de entropia em ling??stica computacional para a l?ngua
portuguesa, 12.
Maria Clara Paix?o de Sousa, F?bio Natanael Kepler, and
Pablo Picasso Feliciano de Faria. 2009. E-Dictor: No-
vas perspectivas na codifica??o e edi??o de corpora de
22
textos hist?ricos. In Lingu?stica de Corpus: S?nteses
e Avan?os. Anais do VIII Encontro de Lingu?stica de
Corpus, UERJ, Rio de Janeiro, RJ, Brasil, 11. Shep-
herd, T. and Berber Sardinha, T. and Veirano Pinto, M.
To be published.
C?cero Nogueira dos Santos, Ruy L. Milidi?, and Ra?l P.
Renter?a. 2008. Portuguese part-of-speech tagging us-
ing entropy guided transformation learning. In PRO-
POR - 8th Workshop on Computational Processing of
Written and Spoken Portuguese, volume 5190 of Lec-
ture Notes in Artificial Intelligence, pages 143?152,
Vit?ria, ES, Brazil. Springer-Verlag Berlin Heidelberg.
Linguateca.pt, 2008. The Floresta Sint?(c)tica project.
ICMC-USP, 2010. NILC?s Corpora. ICMC-USP.
IEL-UNICAMP and IME-USP, 2010. C?rpus Hist?rico
do Portugu?s Anotado Tycho Brahe. IEL-UNICAMP
and IME-USP.
F?bio Natanael Kepler and Marcelo Finger. 2006.
Comparing two markov methods for part-of-speech
tagging of portuguese. In Jaime Sim?o Sichman,
Helder Coelho, and Solange Oliveira Rezende, editors,
IBERAMIA-SBIA, volume 4140 of Lecture Notes in
Artificial Intelligence, pages 482?491, Ribeir?o Preto,
Brazil, 10. Springer Berlin / Heidelberg.
Dan Klein. 2005. The Unsupervised Learning of Natural
Language Structure. phdthesis, Stanford University.
Christopher D. Manning and Hinrich Sch?tze. 1999.
Foundations Of Statistical Natural Language Process-
ing. MIT Press, Cambridge, MA, USA.
Adwait Ratnaparkhi. 1996. A maximum entropy model
for part-of-speech tagging. In Conference on Empiri-
cal Methods in Natural Language Processing, Univer-
sity of Pennsylvania, 5.
Jorma Rissanen. 1983. A universal data compression
system. IEEE Trans. Inform. Theory, IT-29:656 ? 664.
Libin Shen, Giorgio Satta, and Aravind Joshi. 2007.
Guided learning for bidirectional sequence classifica-
tion. In Proceedings of the 45th Annual Meeting of the
Association of Computational Linguistics, pages 760?
767, Prague, Czech Republic, 6. Association for Com-
putational Linguistics.
Kristina Toutanova, Dan Klein, Christopher D. Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In NAACL
?03: Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology,
pages 173?180, Morristown, NJ, USA. Association for
Computational Linguistics.
Yoshimasa Tsuruoka and Jun?ichi Tsujii. 2005. Bidi-
rectional inference with the easiest-first strategy for
tagging sequence data. In HLT ?05: Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Processing,
pages 467?474, Morristown, NJ, USA. Association for
Computational Linguistics.
Andrew James Viterbi. 1967. Error bounds for convolu-
tional codes and an asymptotically optimal deconding
algorithm. IEEE Transactions on Information Theory,
pages 260 ? 269, 4.
23
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 217?221,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
An integrated tool for annotating historical corpora
Pablo Picasso Feliciano de Faria?
University of Campinas
Campinas, Brazil
pablofaria@gmail.com
Fabio Natanael Kepler?
University of Sao Paulo
Sao Paulo, Brazil
kepler@ime.usp.br
Maria Clara Paix?o de Sousa
University of Sao Paulo
Sao Paulo, Brazil
mclara.ps@gmail.com
Abstract
E-Dictor is a tool for encoding, applying
levels of editions, and assigning part-of-
speech tags to ancient texts. In short, it
works as a WYSIWYG interface to en-
code text in XML format. It comes from
the experience during the building of the
Tycho Brahe Parsed Corpus of Historical
Portuguese and from consortium activities
with other research groups. Preliminary
results show a decrease of at least 50% on
the overall time taken on the editing pro-
cess.
1 Introduction
The Tycho Brahe Parsed Corpus of Historical Por-
tuguese (CTB) (Cor, 2010) consists of Portuguese
texts written by authors born between 1380 and
1845. Been one of the forefront works among
projects dedicated to investigate the history of Por-
tuguese language, it contributed to the renovation
of the theoretical relevance of studies about the
linguistic change in different frameworks (Mat-
tos e Silva, 1988; Kato and Roberts, 1993; de
Castilho, 1998).
This resulted in crescent work with ancient texts
in the country (Megale and Cambraia, 1999), and,
by the end of the 1990s, the work on Corpus Lin-
guistics has given rise to a confluence between
philology and computer science, a relationship not
so ease to equate.
1.1 Philological and computational needs
In studies based on ancient texts, above all, one
has to guarantees fidelity to the original forms of
the texts. Starting with a fac-simile, a first op-
tion would be the automatic systems of character
?Thanks to FAPESP, n. 2008/04312-9, for funding part
of the development of E-Dictor.
? Thanks to CAPES for the scholarship granted during
the initial part of this work.
recognition (OCR). For the older texts, however,
the current recognition technologies have proven
inefficient and quite inadequate for handwritten
documents (Paix?o de Sousa, 2009). Anyway one
cannot totally avoid manual transcription.
There are different degrees of fidelity between
the transcription and the original text. In prac-
tice, one often prepares a ?semi-diplomatic? edi-
tion, in which a slightly greater degree of interfer-
ence is considered acceptable ? eg., typographical
or graphematic modernization. A central goal of
the philological edition is to make the text accessi-
ble to the specialist reader, with maximum preser-
vation of its original features.
However, it needs to be integrated with compu-
tational and linguistic requirements: the need for
quantity, agility and automation in the statistical
work of selecting data. The original spelling and
graphematic characteristics of older texts, for ex-
ample, may hinder the subsequent automatic pro-
cessing, such as morphological annotation. Thus,
the original text needs to be prepared, or edited,
with a degree of interference higher than that ac-
ceptable for a semi-diplomatic edition and that is
where the conflict emerges.
1.2 Background
The modernization of spellings and standardiza-
tion of graphematic aspects, during the first years
of CTB, made texts suitable for automated pro-
cessing, but caused the loss of important features
from the original text for the historical study of
language. This tension has led to the project
?Memories of the Text? (Paix?o de Sousa, 2004),
which sought to restructure the Corpus, based
on the development of XML annotations (W3C,
2009), and to take advantage of the core features of
this type of encoding, for example, XSLT (W3C,
1999) processing.
A annotation system was conceived and applied
to 48 Portuguese texts (2, 279, 455 words), which
217
allowed keeping philological informations while
making the texts capable of being computationally
treated in large-scale. Since 2006, the system has
been being tested by other research groups, no-
tably the Program for the History of Portuguese
Language (PROHPOR-UFBA). The system, then,
met its initial objectives, but it had serious issues
with respect to reliability and, especially, ease of
use.
We noted that manual text markup in XML
was challenging to some and laborious for every-
one. The basic edition process was: transcription
in a text editor, application of the XML markup
(tags plus philological edition), generation of a
standardized plain text version to submit to auto-
matic part-of-speech tagging, revision of both files
(XML and tagged). All in this process, except for
text tagging, been manually done, was too subject
to failures and demanded constant and extensive
revision of the encoding. The need for an alter-
native, to make the task more friendly, reliable,
and productive, became clear. In short, two things
were needed: a friendly interface (WYSIWYG),
to prevent the user from dealing with XML code,
and a way to tighten the whole process (transcrip-
tion, encode/edition, POS tagging and revision).
1.3 Available tools
A search for available options in the market (free
and non-free) led to some very interesting tools,
which may be worth trying:
? Multext1: a series of projects for corpora en-
coding as well as developing tools and lin-
guistic resources. Not all tools seem to have
been finished, and the projects seems to be
outdated and no longer being maintained.
? CLaRK2: a system for corpora development
based on XML and implemented in Java. It
does not provide a WYSIWYG interface.
? Xopus3: an XML editor, which offers a
WYSIWYG interface. Some of its funcional-
ities can be extended (customized) throught a
Javascript API.
? <oXygen/> XML Editor4: a complete XML
development platform with support for all
1http://aune.lpl.univ-aix.fr/projects/
multext/.
2http://www.bultreebank.org/clark.
3http://xopus.com/.
4http://www.oxygenxml.com/.
major XML related standards. An XML
file can be edited in the following perspec-
tives: XML text editor, WYSIWYG-like edi-
tor, XML grid editor, tree editor.
Unfortunately, all the cited tools lack the ca-
pability of dealing proper with levels of edition
for tokens (words and punctuations) and an inte-
grated environment for the whole process of edi-
tion. Thus, in spite of their amazing features, none
of them was sufficiently suitable, specially con-
cerning spelling modernization and normalization
of graphematic aspects. In fact, this is expected
for the tools are intended to broader purposes.
1.4 Solution
Conception and development of a tool, E-Dictor,
where the need for a WYSIWYG interface joined
a second goal, ie., integrating the tasks of the
whole process, which would then be performed
inside the same environment, with any necessary
external tools being called by the system, trans-
parently.
2 Integrated annotation tool
2.1 General features
E-Dictor has been developed in Python5 and, to-
day, has versions for both Linux and Windows
(XP/Vista/7) platforms. A version for MacOS is
planned for the future. It is currently at 1.0 beta
version (not stable).
2.2 General interface features
As shown in Figure 1, the main interface has an
application menu, a toolbar, a content area (di-
vided into tabs: Transcription, Edition, and Mor-
phology), and buttons to navigate throught pages.
The tabs are in accordance with the flow of the en-
coding process. Many aspects of the functioning
described in what follows are determined by the
application preferences.
In the ?Transcription? tab, the original text
is transcribed ?as is? (the user can view the
fac-simile image, while transcribing the text).
Throught a menu option, E-Dictor will automat-
ically apply an XML structure to the text, ?guess-
ing? its internal structure as best as it can. Then,
in the ?Edition? tab, the user can edit any token or
5Available on internet at http://www.python.
org/, last access on Jan, 21th, 2010. Python has been used
in a number of computational linguistics applications, e.g.,
the Natural Language Toolkit (Bird et al, 2009).
218
Figure 1: E-Dictor GUI.
structural element (eg., paragraph). Finally, in the
?Morphology? tab, tokens and part-of-speech tags
are displayed in token/TAG format, so they can be
revised6.
2.3 The XML structure
The XML structure specified meets two main
goals: (i) be as neutral as possible (in relation to
the textual content encoded) and (ii) suit philolog-
ical and linguistic needs, i.e., edition must be sim-
ple and efficient without losing information rele-
vant to philological studies. In the context of CTB,
it was initially established a structure to encode the
following information:
? Metadata: information about the source text,
e.g., author information, state of processing,
etc.
? Delimitation of sections, pages, paragraphs,
sentences, headers and footers, and tokens.
? Class of tokens (part-of-speech tags) and
phonological form for some tokens.
? Types (levels) of edition for each token.
? Comments of the editor.
? Subtypes for some text elements, like sec-
tions, paragraphs, sentences and tokens (eg.,
a section of type ?prologue?).
6The current version of E-Dictor comes with a POS tag-
ger, developed by Fabio Kepler, accessed by a menu option.
2.4 Encoding flexibility
A key goal of E-Dictor is to be flexible enough so
as to be useful in other contexts of corpora build-
ing. To achieve this, the user can customize the
?preferences? of the application. The most promi-
nent options are the levels of edition for tokens; the
subtypes for the elements ?section?, ?paragraph?,
?sentence?, and ?token?; and the list of POS tags to
be used in the morphological analysis. Finally, in
the ?Metadata? tab, the user can create the suitable
metadata fields needed by his/her project.
2.5 Features
Throught its menu, E-Dictor provides some com-
mon options (eg., Save As, Search & Replace,
Copy & Paste, and many others) as well as those
particular options intended for the encoding pro-
cess (XML structure generation, POS automatic
tagging, etc.). E-Dictor provides also an option
for exporting the encoded text and the lexicon
of editions7 in two different formats (HTML and
TXT/CSV).
2.6 Edition
To conclude this section, a brief comment about
token (words and punctuation) edition, which is
the main feature of E-Dictor. The respective in-
terface is shown in Figure 2. When a token is se-
7The actual editions applied to words and punctuations of
the original text.
219
Figure 2: Details of the token edition interface.
lected, the user can: (i) in the ?Properties? panel,
specify the type of the token (according to the sub-
types defined by the preferences), its foreign lan-
guage, and format (bold, italic, and underlined);
(ii) in the ?Edition? panel, specify some other
properties (eg., phonological form) of the token
and include edition levels (according to the levels
defined by the preferences).
To each token, the user must click on ?Apply
changes? to effectivate (all) the editions made to it.
The option ?Replace all? tells E-Dictor to repeat
the operation over all identical tokens in the re-
maining of the text (a similar functionality is avail-
able for POS tags revision).
3 Discussion
The dificulties of encoding ancient texts in XML,
using common text editors, had shown that a tool
was necessary to make the process efficient and
friendly. This led to the development of E-Dictor,
which, since its earlier usage, has shown promis-
ing results. Now, the user does not even have to
know that the underlying encoding is XML. It is
only necessary for him/her to know the (philolog-
ical and linguistics) aspects of text edition.
E-Dictor led to a decrease of about 50% in the
time required for encoding and editing texts. The
improvement may be even higher if we consider
the revision time. One of the factors for this im-
provement is the better legibility the tool provides.
The XML code is hidden, allowing one to prac-
tically read the text without any encoding. To il-
lustrate the opposite, Figure 3 shows the common
edition ?interface?, before E-Dictor. Note that the
content being edited is just ?Ex.mo Sr. Duque?.
Finally, the integration of the whole process into
one and only environment is a second factor for the
overall improvement, for it allows the user to move
freely and quickly between ?representations? and
Figure 3: Example of XML textual encoding.
to access external tools transparently.
3.1 Improvements
E-Dictor is always under development, as we dis-
cuss its characteristics and receive feedback from
users. There is already a list of future improve-
ments that are being developed, such as extending
the exporting routines, for example. A bigger goal
is to incorporate an edition lexicon, which would
be used by the tool for making suggestions during
the edition process, or even to develop an ?auto-
matic token edition? system for later revision by
the user.
3.2 Perspectives
Besides CTB, E-Dictor is being used by the BBD
project (BBD, 2010), and, recently, by various
subgroups of the PHPB project (For a History of
Portuguese in Brazil). These groups have large
experience in philological edition of handwritten
documents, and we hope their use of E-Dictor will
help us improve it. The ideal goal of E-Dictor is to
be capable of handling the whole flow of linguistic
and philological tasks: transcription, edition, tag-
ging, and parsing.
220
References
[BBD2010] BBD. 2010. Biblioteca Brasiliana Digital.
[Bird et al2009] Steven Bird, E. Klein, and E. Loper.
2009. Natural Language Processing with Python.
O?Reilly.
[Cor2010] IEL-UNICAMP and IME-USP, 2010. C?r-
pus Hist?rico do Portugu?s Anotado Tycho Brahe.
[de Castilho1998] Ataliba Teixeira de Castilho. 1998.
Para a hist?ria do portugu?s brasileiro, volume Vol
I: Primeiras id?ias. Humanitas, S?o Paulo.
[Kato and Roberts1993] Mary A. Kato and Ian Roberts.
1993. Portugu?s brasileiro: uma viagem Di-
acr?nica. Editora da Unicamp, Campinas.
[Mattos e Silva1988] Rosa Virg?nia Mattos e Silva.
1988. Fluxo e refluxo: uma retrospectiva da ling??s-
tica hist?rica no brasil. D.E.L.T.A., 4(1):85?113.
[Megale and Cambraia1999] Heitor Megale and C?sar
Cambraia. 1999. Filologia portuguesa no brasil.
D.E.L.T.A., 15(1:22).
[Paix?o de Sousa2004] Maria Clara Paix?o de Sousa.
2004. Mem?rias do texto: Aspectos tecnol?gicos
na constru??o de um corpus hist?rico do portugu?s.
Projeto de p?s-doutorado ? fapesp, Unicamp.
[Paix?o de Sousa2009] Maria Clara Paix?o de Sousa.
2009. Desafios do processamento de textos anti-
gos: primeiros experimentos na brasiliana digital. In
I Workshop de Lingu?stica Computacional da USP,
S?o Paulo, 11.
[W3C1999] W3C. 1999. Extensible stylesheet lan-
guage transformation.
[W3C2009] W3C. 2009. Extensible markup language.
221
