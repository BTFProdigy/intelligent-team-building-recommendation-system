Proceedings of the ACL 2010 Conference Short Papers, pages 120?125,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Event-based Hyperspace Analogue to Language for Query Expansion
Tingxu Yan
Tianjin University
Tianjin, China
sunriser2008@gmail.com
Tamsin Maxwell
University of Edinburgh
Edinburgh, United Kingdom
t.maxwell@ed.ac.uk
Dawei Song
Robert Gordon University
Aberdeen, United Kingdom
d.song@rgu.ac.uk
Yuexian Hou
Tianjin University
Tianjin, China
yxhou@tju.edu.cn
Peng Zhang
Robert Gordon University
Aberdeen, United Kingdom.
p.zhang1@rgu.ac.uk
Abstract
Bag-of-words approaches to information
retrieval (IR) are effective but assume in-
dependence between words. The Hy-
perspace Analogue to Language (HAL)
is a cognitively motivated and validated
semantic space model that captures sta-
tistical dependencies between words by
considering their co-occurrences in a sur-
rounding window of text. HAL has been
successfully applied to query expansion in
IR, but has several limitations, including
high processing cost and use of distribu-
tional statistics that do not exploit syn-
tax. In this paper, we pursue two methods
for incorporating syntactic-semantic infor-
mation from textual ?events? into HAL.
We build the HAL space directly from
events to investigate whether processing
costs can be reduced through more careful
definition of word co-occurrence, and im-
prove the quality of the pseudo-relevance
feedback by applying event information
as a constraint during HAL construction.
Both methods significantly improve per-
formance results in comparison with orig-
inal HAL, and interpolation of HAL and
relevance model expansion outperforms
either method alone.
1 Introduction
Despite its intuitive appeal, the incorporation of
linguistic and semantic word dependencies in IR
has not been shown to significantly improve over
a bigram language modeling approach (Song and
Croft, 1999) that encodes word dependencies as-
sumed from mere syntactic adjacency. Both the
dependence language model for IR (Gao et al,
2004), which incorporates linguistic relations be-
tween non-adjacent words while limiting the gen-
eration of meaningless phrases, and the Markov
Random Field (MRF) model, which captures short
and long range term dependencies (Metzler and
Croft, 2005; Metzler and Croft, 2007), con-
sistently outperform a unigram language mod-
elling approach but are closely approximated by
a bigram language model that uses no linguis-
tic knowledge. Improving retrieval performance
through application of semantic and syntactic in-
formation beyond proximity and co-occurrence
features is a difficult task but remains a tantalising
prospect.
Our approach is like that of Gao et al (2004)
in that it considers semantic-syntactically deter-
mined relationships between words at the sentence
level, but allows words to have more than one
role, such as predicate and argument for differ-
ent events, while link grammar (Sleator and Tem-
perley, 1991) dictates that a word can only sat-
isfy one connector in a disjunctive set. Compared
to the MRF model, our approach is unsupervised
where MRFs require the training of parameters us-
ing relevance judgments that are often unavailable
in practical conditions.
Other work incorporating syntactic and linguis-
tic information into IR includes early research by
(Smeaton, O?Donnell and Kelledy, 1995), who
employed tree structured analytics (TSAs) resem-
bling dependency trees, the use of syntax to de-
tect paraphrases for question answering (QA) (Lin
and Pantel, 2001), and semantic role labelling in
QA (Shen and Lapata, 2007).
Independent from IR, Pado and Lapata (2007)
proposed a general framework for the construc-
tion of a semantic space endowed with syntactic
120
information. This was represented by an undi-
rected graph, where nodes stood for words, de-
pendency edges stood for syntactical relations, and
sequences of dependency edges formed paths that
were weighted for each target word. Our work is
in line with Pado and Lapata (2007) in construct-
ing a semantic space with syntactic information,
but builds our space from events, states and attri-
butions as defined linguistically by Bach (1986).
We call these simply events, and extract them auto-
matically from predicate-argument structures and
a dependency parse. We will use this space to per-
form query expansion in IR, a task that aims to find
additional words related to original query terms,
such that an expanded query including these words
better expresses the information need. To our
knowledge, the notion of events has not been ap-
plied to query expansion before.
This paper will outline the original HAL al-
gorithm which serves as our baseline, and the
event extraction process. We then propose two
methods to arm HAL with event information: di-
rect construction of HAL from events (eHAL-1),
and treating events as constraints on HAL con-
struction from the corpus (eHAL-2). Evaluation
will compare results using original HAL, eHAL-
1 and eHAL-2 with a widely used unigram lan-
guage model (LM) for IR and a state of the art
query expansion method, namely the Relevance
Model (RM) (Lavrenko and Croft, 2001). We also
explore whether a complementary effect can be
achieved by combining HAL-based dependency
modelling with the unigram-based RM.
2 HAL Construction
Semantic space models aim to capture the mean-
ings of words using co-occurrence information
in a text corpus. Two examples are the Hyper-
space Analogue to Language (HAL) (Lund and
Burgess, 1996), in which a word is represented
by a vector of other words co-occurring with it
in a sliding window, and Latent Semantic Anal-
ysis (LSA) (Deerwester, Dumais, Furnas, Lan-
dauer and Harshman, 1990; Landauer, Foltz and
Laham, 1998), in which a word is expressed as
a vector of documents (or any other syntacti-
cal units such as sentences) containing the word.
In these semantic spaces, vector-based represen-
tations facilitate measurement of similarities be-
tween words. Semantic space models have been
validated through various studies and demonstrate
compatibility with human information processing.
Recently, they have also been applied in IR, such
as LSA for latent semantic indexing, and HAL for
query expansion. For the purpose of this paper, we
focus on HAL, which encodes word co-occurrence
information explicitly and thus can be applied to
query expansion in a straightforward way.
HAL is premised on context surrounding a word
providing important information about its mean-
ing (Harris, 1968). To be specific, an L-size
sliding window moves across a large text corpus
word-by-word. Any two words in the same win-
dow are treated as co-occurring with each other
with a weight that is inversely proportional to their
separation distance in the text. By accumulating
co-occurrence information over a corpus, a word-
by-word matrix is constructed, a simple illustra-
tion of which is given in Table 1. A single word is
represented by a row vector and a column vector
that capture the information before and after the
word, respectively. In some applications, direc-
tion sensitivity is ignored to obtain a single vector
representation of a word by adding corresponding
row and column vectors (Bai et al, 2005).
w1 w2 w3 w4 w5 w6
w1
w2 5
w3 4 5
w4 3 4 5
w5 2 3 4 5
w6 2 3 4 5
Table 1: A HAL space for the text ?w1 w2 w3 w4
w5 w6? using a 5-word sliding window (L = 5).
HAL has been successfully applied to query ex-
pansion and can be incorporated into this task di-
rectly (Bai et al, 2005) or indirectly, as with the
Information Flow method based on HAL (Bruza
and Song, 2002). However, to date it has used
only statistical information from co-occurrence
patterns. We extend HAL to incorporate syntactic-
semantic information.
3 Event Extraction
Prior to event extraction, predicates, arguments,
part of speech (POS) information and syntac-
tic dependencies are annotated using the best-
performing joint syntactic-semantic parser from
the CoNNL 2008 Shared Task (Johansson and
121
Nugues, 2008), trained on PropBank and Nom-
Bank data. The event extraction algorithm then
instantiates the template REL [modREL] Arg0
[modArg0] ...ArgN [modArgN], where REL is the
predicate relation (or root verb if no predicates
are identified), and Arg0...ArgN are its arguments.
Modifiers (mod) are identified by tracing from
predicate and argument heads along the depen-
dency tree. All predicates are associated with at
least one event unless both Arg0 and Arg1 are not
identified, or the only argument is not a noun.
The algorithm checks for modifiers based on
POS tag1, tracing up and down the dependency
tree, skipping over prepositions, coordinating con-
junctions and words indicating apportionment,
such as ?sample (of)?. However, to constrain out-
put the search is limited to a depth of one (with
the exception of skipping). For example, given
the phrase ?apples from the store nearby? and an
argument head apples, the first dependent, store,
will be extracted but not nearby, which is the de-
pendent of store. This can be detrimental when
encountering compound nouns but does focus on
core information. For verbs, modal dependents are
not included in output.
Available paths up and down the dependency
tree are followed until all branches are exhausted,
given the rules outlined above. Tracing can re-
sult in multiple extracted events for one predicate
and predicates may also appear as arguments in
a different event, or be part of argument phrases.
For this reason, events are constrained to cover
only detail appearing above subsequent predicates
in the tree, which simplifies the event structure.
For example, the sentence ?Baghdad already has
the facilities to continue producing massive quan-
tities of its own biological and chemical weapons?
results in the event output: (1) has Baghdad al-
ready facilities continue producing; (2) continue
quantities producing massive; (3) producing quan-
tities massive weapons biological; (4) quantities
weapons biological massive.
4 HAL With Events
4.1 eHAL-1: Construction From Events
Since events are extracted from documents, they
form a reduced text corpus from which HAL can
1To be specific, the modifiers include negation, as well as
adverbs or particles for verbal heads, adjectives and nominal
modifiers for nominal heads, and verbal or nominal depen-
dents of modifiers, provided modifiers are not also identified
as arguments elsewhere in the event.
be built in a similar manner to the original HAL.
We ignore the parameter of window length (L)
and treat every event as a single window of length
equal to the number of words in the event. Every
pair of words in an event is considered to be co-
occurrent with each other. The weight assigned to
the association between each pair is simply set to
one. With this scheme, all the events are traversed
and the event-based HAL is constructed.
The advantage of this method is that it sub-
stantially reduces the processing time during HAL
construction because only events are involved and
there is no need to calculate weights per occur-
rence. Additional processing time is incurred in
semantic role labelling (SRL) during event iden-
tification. However, the naive approach to extrac-
tion might be simulated with a combination of less
costly chunking and dependency parsing, given
that the word ordering information available with
SRL is not utilised.
eHAL-1 combines syntactical and statistical in-
formation, but has a potential drawback in that
only events are used during construction so some
information existing in the co-occurrence patterns
of the original text may be lost. This motivates the
second method.
4.2 eHAL-2: Event-Based Filtering
This method attempts to include more statistical
information in eHAL construction. The key idea
is to decide whether a text segment in a corpus
should be used for the HAL construction, based
on how much event information it covers. Given a
corpus of text and the events extracted from it, the
eHAL-2 method runs as follows:
1. Select the events of length M or more and
discard the others for efficiency;
2. Set an ?inclusion criterion?, which decides if
a text segment, defined as a word sequence
within an L-size sliding window, contains an
event. For example, if 80% of the words in an
event are contained in a text segment, it could
be considered to ?include? the event;
3. Move across the whole corpus word-by-word
with an L-size sliding window. For each win-
dow, complete Steps 4-7;
4. For the current L-size text segment, check
whether it includes an event according to the
?inclusion criterion? (Step 2);
122
5. If an event is included in the current text
segment, check the following segments for
a consecutive sequence of segments that also
include this event. If the current segment in-
cludes more than one event, find the longest
sequence of related text segments. An illus-
tration is given in Figure 1 in which dark
nodes stand for the words in a specific event
and an 80% inclusion criterion is used.
TextSegment KSegment K+1Segment K+2Segment K+3
Figure 1: Consecutive segments for an event
6. Extract the full span of consecutive segments
just identified and go to the next available text
segment. Repeat Step 3;
7. When the scanning is done, construct HAL
using the original HAL method over all ex-
tracted sequences.
With the guidance of event information, the pro-
cedure above keeps only those segments of text
that include at least one event and discards the rest.
It makes use of more statistical co-occurrence in-
formation than eHAL-1 by applying weights that
are proportional to word separation distance. It
also alleviates the identified drawback of eHAL-1
by using the full text surrounding events. A trade-
off is that not all the events are included by the
selected text segments, and thus some syntactical
information may be lost. In addition, the paramet-
ric complexity and computational complexity are
also higher than eHAL-1.
5 Evaluation
We empirically test whether our event-based
HALs perform better than the original HAL, and
standard LM and RM, using three TREC2 col-
lections: AP89 with Topics 1-50 (title field),
AP8889 with Topics 101-150 (title field) and
WSJ9092 with Topics 201-250 (description field).
All the collections are stemmed, and stop words
are removed, prior to retrieval using the Lemur
Toolkit Version 4.113. Initial retrieval is iden-
tical for all models evaluated: KL-divergence
2TREC stands for the Text REtrieval Conference series
run by NIST. Please refer to http://trec.nist.gov/ for details.
3Available at http://www.lemurproject.org/
based LM smoothed using Dirichlet prior with ?
set to 1000 as appropriate for TREC style title
queries (Lavrenko, 2004). The top 50 returned
documents form the basis for all pseudo-relevance
feedback, with other parameters tuned separately
for the RM and HAL methods.
For each dataset, the number of feedback terms
for each method is selected optimally among 20,
40, 60, 804 and the interpolation and smoothing
coefficient is set to be optimal in [0,1] with in-
terval 0.1. For RM, we choose the first relevance
model in Lavrenko and Croft (2001) with the doc-
ument model smoothing parameter optimally set
at 0.8. The number of feedback terms is fixed at
60 (for AP89 and WSJ9092) and 80 (for AP8889),
and interpolation between the query and relevance
models is set at 0.7 (for WSJ9092) and 0.9 (for
AP89 and AP8889). The HAL-based query ex-
pansion methods add the top 80 expansion terms
to the query with interpolation coefficient 0.9 for
WSJ9092 and 1 (that is, no interpolation) for AP89
and AP8889. The other HAL-based parameters
are set as follows: shortest event length M = 5,
for eHAL-2 the ?inclusion criterion? is 75% of
words in an event, and for HAL and eHAL-2, win-
dow size L = 8. Top expansion terms are selected
according to the formula:
PHAL(tj | ? t) = HAL(tj | ? q)?
ti
HAL(ti| ? q)
where HAL(tj |?q) is the weight of tj in the com-
bined HAL vector ?q (Bruza and Song, 2002)
of original query terms. Mean Average Precision
(MAP) is the performance indicator, and t-test (at
the level of 0.05) is performed to measure the sta-
tistical significance of results.
Table 2 lists the experimental results5. It can
be observed that all the three HAL-based query
expansion methods improve performance over the
LM and both eHALs achieve better performance
than original HAL, indicating that the incorpora-
tion of event information is beneficial. In addition,
eHAL-2 leads to better performance than eHAL-
1, suggesting that use of linguistic information as
a constraint on statistical processing, rather than
the focus of extraction, is a more effective strat-
egy. The results are still short of those achieved
4For RM, feedback terms were also tested on larger num-
bers up to 1000 but only comparable result was observed.
5In Table 2, brackets show percent improvement of
eHALs / RM over HAL / eHAL-2 respectively and * and #
indicate the corresponding statistical significance.
123
Method AP89 AP8889 WSJ9092
LM 0.2015 0.2290 0.2242
HAL 0.2299 0.2738 0.2346
eHAL-1 0.2364 0.2829 0.2409
(+2.83%) (+3.32%*) (+2.69%)
eHAL-2 0.2427 0.2850 0.2460
(+5.57%*) (+4.09%*) (+4.86%*)
RM 0.2611 0.3178 0.2676
(+7.58%#) (+11.5%#) (+8.78%#)
Table 2: Performance (MAP) comparison of query
expansion using different HALs
with RM, but the gap is significantly reduced by
incorporating event information here, suggesting
this is a promising line of work. In addition, as
shown in (Bai et al, 2005), the Information Flow
method built upon the original HAL largely out-
performed RM. We expect that eHAL would pro-
vide an even better basis for Information Flow, but
this possibility is yet to be explored.
As is known, RM is a pure unigram model while
HAL methods are dependency-based. They cap-
ture different information, hence it is natural to
consider if their strengths might complement each
other in a combined model. For this purpose, we
design the following two schemes:
1. Apply RM to the feedback documents (orig-
inal RM), the events extracted from these
documents (eRM-1), and the text segments
around each event (eRM-2), where the three
sources are the same as used to produce HAL,
eHAL-1 and eHAL-2 respectively;
2. Interpolate the expanded query model by
RM with the ones generated by each HAL,
represented by HAL+RM, eHAL-1+RM and
eHAL-2+RM. The interpolation coefficient is
again selected to achieve the optimal MAP.
The MAP comparison between the original RM
and these new models are demonstrated in Ta-
ble 36. From the first three lines (Scheme 1), we
can observe that in most cases the performance
generally deteriorates when RM is directly run
over the events and the text segments. The event
information is more effective to express the infor-
mation about the term dependencies while the un-
igram RM ignores this information and only takes
6For rows in Table 3, brackets show percent difference
from original RM.
Method AP89 AP8889 WSJ9092
RM 0.2611 0.3178 0.2676
eRM-1 0.2554 0.3150 0.2555
(-2.18%) (-0.88%) (-4.52%)
eRM-2 0.2605 0.3167 0.2626
(-0.23%) (-0.35%) (-1.87%)
HAL 0.2640 0.3186 0.2727
+RM (+1.11%) (+0.25%) (+1.19%)
eHAL-1 0.2600 0.3210 0.2734
+RM (-0.42%) (+1.01%) (+2.17%)
eHAL-2 0.2636 0.3191 0.2735
+RM (+0.96%) (+0.41%) (+2.20%)
Table 3: Performance (MAP) comparison of query
expansion using the combination of RM and term
dependencies
the occurrence frequencies of individual words
into account, which is not well-captured by the
events. In contrast, the performance of Scheme 2
is more promising. The three methods outperform
the original RM in most cases, but the improve-
ment is not significant and it is also observed that
there is little difference shown between RM with
HAL and eHALs. The phenomenon implies more
effective methods may be invented to complement
the unigram models with the syntactical and sta-
tistical dependency information.
6 Conclusions
The application of original HAL to query expan-
sion attempted to incorporate statistical word as-
sociation information, but did not take into ac-
count the syntactical dependencies and had a
high processing cost. By utilising syntactic-
semantic knowledge from event modelling of
pseudo-relevance feedback documents prior to
computing the HAL space, we showed that pro-
cessing costs might be reduced through more care-
ful selection of word co-occurrences and that per-
formance may be enhanced by effectively improv-
ing the quality of pseudo-relevance feedback doc-
uments. Both methods improved over original
HAL query expansion. In addition, interpolation
of HAL and RM expansion improved results over
those achieved by either method alone.
Acknowledgments
This research is funded in part by the UK?s Engi-
neering and Physical Sciences Research Council,
grant number: EP/F014708/2.
124
References
Bach E. The Algebra of Events. 1986. Linguistics and
Philosophy, 9(1): pp. 5?16.
Bai J. and Song D. and Bruza P. and Nie J.-Y. and Cao
G. Query Expansion using Term Relationships in
Language Models for Information Retrieval 2005.
In: Proceedings of the 14th International ACM Con-
ference on Information and Knowledge Manage-
ment, pp. 688?695.
Bruza P. and Song D. Inferring Query Models by Com-
puting Information Flow. 2002. In: Proceedings of
the 11th International ACM Conference on Informa-
tion and Knowledge Management, pp. 206?269.
Deerwester S., Dumais S., Furnas G., Landauer T. and
Harshman R. Indexing by latent semantic analysis.
1990. Journal of the American Sociaty for Informa-
tion Science, 41(6): pp. 391?407.
Gao J. and Nie J. and Wu G. and Cao G. Dependence
Language Model for Information Retrieval. 2004.
In: Proceedings of the 27th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, pp. 170?177.
Harris Z. 1968. Mathematical Structures of Lan-
guage.. Wiley, New York.
Johansson R. and Nugues P. Dependency-based
Syntactic-semantic Analysis with PropBank and
NomBank. 2008. In: CoNLL ?08: Proceedings of
the Twelfth Conference on Computational Natural
Language Learning, pp. 183?187.
Landauer T., Foltz P. and Laham D. Introduction to La-
tent Semantic Analysis. 1998. Discourse Processes,
25: pp. 259?284.
Lavrenko V. 2004. A Generative Theory of Relevance,
PhD thesis, University of Massachusetts, Amherst.
Lavrenko V. and Croft W. B. Relevance Based Lan-
guage Models. 2001. In: SIGIR ?01: Proceedings
of the 24th Annual International ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval, pp. 120?127, New York, NY, USA,
2001. ACM.
Lin D. and Pantel P. DIRT - Discovery of Inference
Rules from Text. 2001. In: KDD ?01: Proceedings
of the Seventh ACM SIGKDD International Confer-
ence on Knowledge Discovery and Data Mining, pp.
323?328, New York, NY, USA.
Lund K. and Burgess C. Producing High-dimensional
Semantic Spaces from Lexical Co-occurrence.
1996. Behavior Research Methods, Instruments &
Computers, 28: pp. 203?208. Prentice-Hall, Engle-
wood Cliffs, NJ.
Metzler D. and Bruce W. B. A Markov Random Field
Model for Term Dependencies 2005. In: SIGIR ?05:
Proceedings of the 28th annual international ACM
SIGIR conference on Research and development in
information retrieval, pp. 472?479, New York, NY,
USA. ACM.
Metzler D. and Bruce W. B. Latent Concept Expan-
sion using Markov Random Fields 2007. In: SIGIR
?07: Proceedings of the 30th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval, pp. 311?318, ACM,
New York, NY, USA.
Pado S. and Lapata M. Dependency-Based Construc-
tion of Semantic Space Models. 2007. Computa-
tional Linguistics, 33: pp. 161?199.
Shen D. and Lapata M. Using Semantic Roles to Im-
prove Question Answering. 2007. In: Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pp. 12?21.
Sleator D. D. and Temperley D. Parsing English with
a Link Grammar 1991. Technical Report CMU-CS-
91-196, Department of Computer Science, Carnegie
Mellon University.
Smeaton A. F., O?Donnell R. and Kelledy F. Indexing
Structures Derived from Syntax in TREC-3: System
Description. 1995. In: The Third Text REtrieval
Conference (TREC-3), pp. 55?67.
Song F. and Croft W. B. A General Language Model
for Information Retrieval. 1999. In: CIKM ?99:
Proceedings of the Eighth International Confer-
ence on Information and Knowledge Management,
pp. 316?321, New York, NY, USA, ACM.
125
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 507?516,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Feature-Based Selection of Dependency Paths
in Ad Hoc Information Retrieval
K. Tamsin Maxwell
School of Informatics
University of Edinburgh
Edinburgh EH8 9AB, UK
t.maxwell@ed.ac.uk
Jon Oberlander
School of Informatics
University of Edinburgh
Edinburgh EH8 9AB, UK
j.oberlander@ed.ac.uk
W. Bruce Croft
Dept. of Computer Science
University of Massachusetts
Amherst, MA 01003, USA
croft@cs.umass.edu
Abstract
Techniques that compare short text seg-
ments using dependency paths (or simply,
paths) appear in a wide range of automated
language processing applications including
question answering (QA). However, few
models in ad hoc information retrieval (IR)
use paths for document ranking due to
the prohibitive cost of parsing a retrieval
collection. In this paper, we introduce a
flexible notion of paths that describe chains
of words on a dependency path. These
chains, or catenae, are readily applied in
standard IR models. Informative catenae
are selected using supervised machine
learning with linguistically informed fea-
tures and compared to both non-linguistic
terms and catenae selected heuristically
with filters derived from work on paths.
Automatically selected catenae of 1-2
words deliver significant performance
gains on three TREC collections.
1 Introduction
In the past decade, an increasing number of
techniques have used complex and effective
syntactic and semantic features to determine the
similarity, entailment or alignment between short
texts. These approaches are motivated by the idea
that sentence meaning can be flexibly captured by
the syntactic and semantic relations between words,
and encoded in dependency parse tree fragments.
Dependency paths (or simply, paths) are compared
using techniques such as tree edit distance (Pun-
yakanok et al, 2004; Heilman and Smith, 2010),
relation probability (Gao et al, 2004) and parse tree
alignment (Wang et al, 2007; Park et al, 2011).
Much work on sentence similarity using
dependency paths focuses on question answering
(QA) where textual inference requires attention
to linguistic detail. Dependency-based techniques
can also be highly effective for ad hoc information
retrieval (IR) (Park et al, 2011). However, few
path-based methods have been explored for ad
hoc IR, largely because parsing large document
collections is computationally prohibitive.
In this paper, we explore a flexible application
of dependency paths that overcomes this difficulty.
We reduce paths to chains of words called catenae
(Osborne and Gro?, 2012) that capture salient
semantic content in an underspecified manner.
Catenae can be used as lexical units in a reformu-
lated query to explicitly indicate important word
relationships while retaining efficient and flexible
proximity matching. Crucially, this does not
require parsing documents. Moreover, catenae are
compatible with a variety of existing IR models.
We hypothesize that catenae identify most units
of salient knowledge in text. This is because
they are a condition for ellipsis, in which salient
knowledge can be successfully omitted from text
(Osborne and Gro?, 2012). To our knowledge, this
paper is the first time that catenae are proposed
as a means for term selection in IR, and where
ellipsis is considered as a means for identification
of semantic units.
We also extend previous work with development
of a linguistically informed, supervised machine
learning technique for selection of informative
catenae. Previous heuristic filters for dependency
paths (Lin and Pantel, 2001; Shen et al, 2005;
Cui et al, 2005) can exclude informative relations.
Alternatively, treating all paths as equally infor-
mative (Punyakanok et al, 2004; Park et al, 2011;
Moschitti, 2008) can generate noisy word relations
and is computationally intensive.
The challenge of path selection is that no
explicit information in text indicates which paths
are relevant. Consider the catenae captured by
heuristic filters for the TREC1 query, ?What
role does blood-alcohol level play in automobile
accident fatalities? (#358, Table 1). It may appear
obvious that the component words of ?role play?
1Text REtrieval Conference, see http://trec.nist.gov/
507
blood alcohol
level play
auto accident
accident fatal
role play
play fatal
blood alcohol play
play accident fatal
auto accident fatal
level play fatal
role play fatal
role level play
blood alcohol
level play
auto accident
accident fatal
role blood
alcohol level
play auto
blood alcohol
level play
auto accident
accident fatal
role play
play fatal
Catenae Sequential dependenceGovernor?ependent
Query: What role does blood-alcohol level play in automobile* accident fatalities*?    (*abbreviated to `auto', `fatal')
auto accident
accident fatal
play fatal
play accident fatal
auto accident fatal
Predicate?rgument
auto accident
accident fatal
auto accident fatal
level play fatal
role play fatal
Nominal end slots
Table 1: Catenae derived from dependency paths, as selected by heuristic methods. Selections are
compared to sequential bigrams that use no linguistic knowledge.
and ?level play? do not have an important semantic
relationship relative to the query, yet these catenae
are described by parent-child relations that are
commonly used to filter paths in text processing
applications. Alternative filters that avoid such
trivial word combinations also omit descriptions of
key entities such as ?blood alcohol?, and identify
longer catenae that may be overly restrictive.
These shortcomings suggest that an optimized
selection process may improve performance of
techniques that use dependency paths in ad hoc IR.
We identify three previously proposed selection
methods, and compare them on the task of catenae
selection for ad hoc IR. Selections are tested
using three TREC collections: Robust04, WT10G,
and GOV2. This provides a diverse platform for
experiments. We also develop a linguistically
informed machine learning technique for catenae
selection that captures both key aspects of heuristic
filters, and novel characteristics of catenae and
paths. The basic idea is that selection, or weighting,
of catenae can be improved by features that are
specific to paths, rather than generic for all terms.
Results show that our selection method is more
effective in identifying key catenae compared
to previously proposed filters. Integration of the
identified catenae in queries also improves IR ef-
fectiveness compared to a highly effective baseline
that uses sequential bigrams with no linguistic
knowledge. This model represents the obvious
alternative to catenae for term selection in IR.
The rest of this paper is organised as follows.
?2 reviews related work, ?3 describes catenae
and their linguistic motivation and ?4 describes
our selection method. ?5 evaluates classification
experiments using the supervised filter. ?6 presents
the results of experiments in ad hoc IR. Finally, ?7
concludes the paper.
2 Related work
Techniques that compare short text segments
using dependency paths are applied to a wide range
of automated language processing tasks, including
paraphrasing, summarization, entailment detection,
QA, machine translation and the evaluation of
word, phrase and sentence similarity. A generic
approach uses a matching function to compare a
dependency path between any two stemmed terms
x and y in a sentence A with any dependency path
between x and y in sentence B. The match score
for A and B is computed over all dependency
paths in A.
In QA this approach improves question repre-
sentation, answer selection and answer ranking
compared to methods that use bag-of-words
and ngram features (Surdeanu et al, 2011). For
example, Lin and Pantel (2001) present a method
to derive paraphrasing rules for QA using analysis
of paths that connect two nouns; Echihabi and
Marcu (2003) align all paths in questions with
trees for heuristically pruned answers; Cui et
al. (2005) score answers using a variation of the
IBM translation model 1; Wang et al (2007)
use quasi-synchronous translation to map all
parent-child paths in a question to any path in an
answer; and Moschitti (2008) explores syntactic
and semantic kernels for QA classification.
In ad hoc IR, most models of term dependence
use word co-occurrence and proximity (Song and
Croft, 1999; Metzler and Croft, 2005; Srikanth and
Srihari, 2002; van Rijsbergen, 1993). Syntactic
language models for IR are a significant departure
from this trend (Gao et al, 2004; Lee et al, 2006;
Cai et al, 2007; Maisonnasse et al, 2007) that
use dependency paths to address long-distance
dependencies and normalize spurious differences
in surface text. Paths are constrained in both
508
prd loc pmod loc pmod
Is    polio under control  in   China ?
X1 X2 X3 X4 X5 X6
poliopolio controlcontrolcontrol ChinaChinapolio control China
polio       under        control
control       in       China
polio       under        control       in        China 
loc pmod
loc pmod
loc pmod loc pmod
Catenae ?toplisted? Dependency paths
Figure 1: Catenae are an economical and intuitive
representation of dependency paths.
queries and documents to parent-child relations.
In contrast, (Park et al, 2011) present a quasi-
synchronous translation model for IR that does not
limit paths. This is based on the observation that
semantically related words have a variety of direct
and indirect relations. All of these models require
parsing of an entire document collection.
Techniques using dependency paths in both QA
and ad hoc IR show promising results, but there
is no clear understanding of which path constraints
result in the greatest IR effectiveness. We directly
compare selections of catenae as a simplified
representation of paths.
In addition, a vast number of methods have
been presented for term weighting and selection
in ad hoc IR. Our supervised selection extends the
successful method presented by Bendersky and
Croft (2008) for selection and weighting of query
noun phrases (NPs). It also extends work for deter-
mining the variability of governor-dependent pairs
(Song et al, 2008). In contrast to this work, we
apply linguistic features that are specific to catenae
and dependency paths, and select among units
containing more than two content-bearing words.
3 Catenae as semantic units
Catenae (Latin for ?chain?, singular catena) are
dependency-based syntactic units. This section
outlines their unique semantic properties.
A catena is defined on a dependency graph that
has lexical nodes (or words) linked by binary asym-
metrical relations called dependencies. Depen-
dencies hold between a governor and a dependent
and may be syntactic or semantic in nature (Nivre,
2005). A dependency graph is usually acyclic such
that each node has only one governor, and one root
node of the tree does not depend on any other node.
A catena is a word, or sequence of words that are
continuous with respect to a walk on a dependency
Is polio under control in China, and is polio under control in India?
Antecedent
First conjunct:Antecedent clause Second conjunct:Elliptical/target clause
Elided text Remnant
Figure 2: Ellipsis in a coordinated construct.
graph. For example, Fig. 1 shows a dependency
parse that generates 21 catenae in total: (using
i for Xi) 1, 2, 3, 4, 5, 6, 12, 23, 34, 45, 56, 123,
234, 345, 456, 1234, 2345, 3456, 12345, 23456,
123456. We process catenae to remove stop words
on the INQUERY stoplist (Allan et al, 2000) and
lexical units containing 18 TREC description stop
words such as ?describe?. This results in a reduced
set of catenae as shown in Fig. 1.
A dependency path is ordered and includes both
word tokens and the relations between them. In
contrast, a catena is a set of word types that may
be ordered or partially ordered. A catena is an
economical, intuitive lexical unit that corresponds
to a dependency path and is argued to play an
important role in syntax (Osborne et al, 2012).
In this paper, we explore catenae instead of paths
for ad hoc IR due to their suitability for efficient IR
models and flexible representation of language se-
mantics. Specifically, we note that catenae identify
words that can be omitted in elliptical constructions
(Osborne et al, 2012). They thus represent salient
semantic information in text. To clarify this insight,
we briefly review catenae in ellipsis.
3.1 Semantic units in ellipsis
Fig. 2 shows terminology for the phenomenon
of ellipsis. The omitted words are called elided
text, and words that could be omitted, but are not,
we call elliptical candidates.
Ellipsis relies on the logical structure of a
coordinated construction in which two or more
elements, such as sentences, are joined by a
conjunctive word or phrase such as ?and? or
?more than?. A coordinated structure is required
because the omitted words are ?filled in? by
assuming a parallel relation p between the first
and second conjunct. In ellipsis, p is omitted and
its arguments are retained in text. In order for
ellipsis to be successful and grammatically correct,
p must be salient shared knowledge at the time of
communication (Prince, 1986; Steedman, 1990). If
p is salient then the omitted text can be inferred. If
p is not salient then the omission of words merely
results in ungrammatical, or incoherent, sentences.
This framework is practically illustrated in Fig.
509
   Is polio under control in China, and ?is polio under control? in India ?   Is polio under control in China, and is cancer under observation ?in China? ?* Is polio under control in China, and ?is? cancer ?nder? observation ?in China? ?* Is polio under control in China, and ?is polio? under ?ontrol in? India ?
Caatentn ?optpslin ds?ip to tlsat?c lyih s?i ?liosi
a?                                         in India    ?b?   is cancer under observation        ?c? *    cancer            observation        ?d? *                under                 India   ?
Is polio under control in China, and...
Caatpip niolio?in
Figure 3: For ellipsis to be successful, elided words must be catenae. Ellipsis candidates are catenae2.
Is    polio under control  in   China ?
X1 X2
X3 X4
X5 X6
Figure 4: A parse in which ?polio China? is a
catena.
3 for the query, ?Is polio under control in China??.
Sentences marked by * are incoherent, and it is
evident that the omitted words do not form a salient
semantic unit. They also do not form catenae. In
contrast, the omitted words in successful ellipsis
do form catenae, and they represent informative
word combinations with respect to the query. This
observation leads us to an ellipsis hypothesis:
Ellipsis hypothesis: For queries formulated
into coordinated structures, the subset of
catenae that are elliptical candidates identify
the salient semantic units in the query.
3.2 Limitations of paths and catenae
The prediction of salient semantic units by cate-
nae is quite robust. However, there are two prob-
lems that can limit the effectiveness of any tech-
nique that uses catenae or dependency paths in IR.
1) Syntactic ambiguity: We make the simpli-
fying assumption that the most probable parse of
a query is accurate and sufficient for the extraction
of relevant catenae. However, this is not always
true. For example, the sentence ?Is polio under
control in China, and under observation ??
constitutes successful ellipsis. The elided words
?polio in china? are relevant to a base query, ?Is
polio under control in China??. Unfortunately,
in Fig. 1 the elided text does not qualify as a
catena. A parse with alternative prepositional
phrase attachment is shown in Fig. 4. Here, the
successfully elided text does qualify as a catena.
This highlights the fact that a single dependency
parse may only partially represent the ambiguous
semantics of a query. More accurate parsing does
not address this problem.
2) Rising: Automatic extraction of catenae is
limited by the phenomenon of rising. Let the
Is poolooiundeoer cdeltoolsooolooC lhua
X4X3X2
X1
X5
X6 X7
Standard structure
?ooiundeoer cdeltoIs poolsooolooC lhua
X3X2X1 X4g X5
X6 X7
Rising structure
Figure 5: A parse with and without rising. The
dashed dependency edge marks where a head is
not also the governor and the g-script marks the
governor of the risen catena.
governor of a catena be the word that licenses
it (in Fig. 5 ?used? licenses ?a toxic chemical?
e.g. ?used what??). Let the head of a catena be
its parent in a dependency tree. Rising occurs
when the head is not the same as the governor.
This is frequently seen with wh-fronting questions
that start who, what etc., as well as with many
other syntactic discontinuities (Osborne and Gro?,
2012). More specifically, rising occurs when a
catena is separated from its governor by words
that its governor does not dominate, or the catena
dominates the governor, as in Fig. 5. Note that
in the risen structure, the words for the catena
?chemical as a weapon? are discontinuous on the
surface, interrupted by the word ?used?.
4 Selection method for catenae
Catenae describe relatively few of the possible
word combinations in a sentence, but still include
many combinations that do not result in successful
ellipsis and are not informative for IR.
This section describes our supervised method
for selection of informative catenae. Candidate
catenae are identified using two constraints that
enable more efficient extraction: stopwords are
removed, and stopped catenae must contain fewer
than four words (single words are permitted). We
use a pseudo-projective joint dependency parse
and semantic role labelling system (Johansson and
510
Nugues, 2008) to generate the dependency parse.
This enables us to explore semantic classification
features and is highly accurate. However, any
dependency parser may be applied instead. For
comparison, catenae extracted from 500 queries
using the Stanford dependency parser (de Marneffe
et al, 2006) overlap with 77% of catenae extracted
from the same queries using the applied parser.
4.1 Feature Classes
Four feature classes are presented in Table 2:
Ellipsis candidates: The ellipsis hypothesis
suggests that informative catenae are elliptical
candidates. However, queries are not in the
coordinated structures required for ellipsis. To
enable extraction of characteristic features we (a)
construct a coordinated query by adding the query
to itself; and (b) elide catenae from the second
conjunct. For example, for the query, Is polio
under control in China? we have:
(a) Is polio under control in China, and is
polio under control in China?
(b) Is polio under control in China, and is
polio in China?
We refer to the words in (b) as the query remainder
and use this to identify features detailed in Table 2.
Dependency path features: Part-of-speech
tags and semantic roles have been used to filter
dependency paths. We identify several features that
use these characteristics from prior work (Table 2).
In addition, variability in the separation distance
in documents observed for words that have
governor-dependent relations in queries has been
proposed for identification of promising paths
(Song et al, 2008). We also observe that due to the
phenomenon of rising, words that form catenae can
be discontinuous in text, and the ability of catenae
to match similar word combinations is limited by
variability of how they appear in documents. Thus,
we propose features for separation distance, but use
efficient collection statistics rather than summing
statistics for every document in a collection.
Co-occurrence features: A governor w1 tends
to subcategorize for its dependents wn. This
means that w1 often determines the choice of wn.
We conclude that co-occurrence is an important
feature of dependency relations (Mel?c?uk, 2003).
In addition, term frequencies and inverse document
frequencies calculated using word co-occurrence
measures are commonly used in IR. We use
features previously proposed for filtering terms in
IR (Bendersky and Croft, 2008) with two methods
to normalize co-occurrence counts for catenae of
different lengths: a factor |c||c|, where |c| is the
number of words in catena c (Hagen et al, 2011),
and the average score for a feature type over all
pairwise word combinations in c.
IR performance predictors: Catenae take the
same form as typical IR search terms. For this
reason, we also use predictors of IR effectiveness
previously applied to IR terms.
In general, path and co-occurrence features are
similar to those applied by Surdeanu et al (2011)
but we do not parse documents. Path features
are also similar to Song et al (2008), but more
efficient and suited to units of variable length.
Ellipsis features have not been used before.
5 Experimental setup
5.1 Classification
Catenae selection is framed as a supervised
classification problem trained on binary human
judgments of informativeness: how well catenae
represent a query and discriminate between
relevant and non-relevant documents in a col-
lection. Kappa for two annotators on catenae
in 100 sample queries was 0.63, and test-retest
reliability for individual judges was similar (0.62)3.
Although this is low, human annotations produced
consistently better classification accuracy than
other labelling methods explored.
We use the Weka (Hall et al, 2009) Ad-
aBoost.M1 meta-classifier (Freund and Schapire,
1996) with unpruned C4.5 decision trees as base
learners to classify catenae as informative or
not. Adaboost.M1 boosts decisions over T weak
learners for T features using weighted majority
voting. At each round, predictions of a new learner
are focused on incorrectly classified examples
from the previous round. Adaboost.M1 was
selected in preference to other algorithms because
it performed better in preliminary experiments,
leverages many weak features to advantage, and
usually does not overfit (Schapire et al, 1997).
Predictions are made using 10-fold cross-
validation. There are roughly three times the
number of uninformative catenae compared to
informative catenae. In addition, the number of
training examples is small (1295 to 5163 per collec-
tion). To improve classifier accuracy, the training
data for each collection is supplemented and
balanced by generating examples from queries for
3Catenae, judgments and annotation details available at
ciir.cs.umass.edu/?tmaxwell
511
isSeq
Minimum perplexity of ngrams with length 2, 3, and 4 in a window of up to a 3 words around the site of catenae omission. This is the area where ungrammaticality may be introduced. For the remainder R=`ABCDE&ABE' we compute ppl1 for ?ABE, &AB, ABE, &A, AB, BE?
R_ppl1
R_strict
Compliance with strict hand?oded rules for grammaticality of a remainder. Rules include unlikely orderings of punctuation and part?f?speech ?OS? tags ?.g. ,, ?, poor placement of determiners and punctuation, and orphaned words, such as adjectives without the nouns they modify.
R_relax
A relaxed version of hand?oded rules for R_strict. Some rules were observed to be overly aggressive in detection of ungrammatical remainders.
Ellipsis candidate features (E)
Co-occurrence features (C)
IR performance prediction features (I)
c_ppl1
Dependency path features (D) (continued)
Dependency paths traverse nodes including stopwords and may be filtered based on POS tags. We use perplexity for the sequence of POS tags in catenae before removing stopwords. This is computed using a POS language model built on ukWaC parsed wikipedia data ?aroni et al, 2009?.
phClass
Phrasal class for a catena, with options NP, VP and Other. A catena has a NP or VP class if it is, or is entirely contained by, an NP or VP ?ong et al, 2008?.
NP_split
Unsuccessful ellipsis often results if elided words only partly describe a base NP. Boolean feature for presence of a partial NP in the remainder. NPs ?nd PPs? are identified using the MontyLingua toolkit.
PP_split As for NP_split, defined for prepositional phrases (PP). 
F_split As for NP_split, defined for finite clauses.
semRole
Boolean feature indicating whether a catena describes all, or part of, a predicate?rgument structure ?AS?. Previous work approximated PAS by using paths between head nouns and verbs, and all paths excluding those within base chunks.
c_len Length of a stopped catenae. Longer terms tend to reduce IR recall.
Boolean indicating if catena words are sequential in stoplisted surface text. 
cf_ow
Frequency of a catena in the retrieval collection, words appearing ordered in a window the length of the catena. 
cf_uw As for cf_ow, but words may appear unordered.
cf_uw8 As for cf_uw, but the window has a length of 8 words.
idf_ow
Inverse document frequency ?idf? where document 
frequency ?df? of a catena is calculated using cf_ow 
windows. Let N  be the number of documents in the retrieval collection, then:
                      idf(Ci) = log2
N
df(Ci)
and idf(Ci) = N  if df(Ci) = 0.
idf_uw As for idf_ow, but words may appear unordered.
idf_uw8 As for idf_uw, but the window has a length of 8 words.
gf
Google ngrams frequency ?rants and Franz, 2006? from a web crawl of approximately one trillion English word tokens. Counts from a large collection are expected to be more reliable than those from 
smaller test collections.
WIG
Normalized Weighted Information Gain ?WIG? is the change in information over top ranked documents between a random ranked list and an actual ranked list retrieved with a catena c ?hou and Croft, 2007?. 
    wig(c) =
1k
?
d?Dk(c) log p(c|d) ? log p(c|C)?log p(c|C)
where Dk are the top k=50 documents retrieved 
with catena c from collection C, and p(c|?) are maximum likelihood estimates. A second feature uses the average WIG score for all pairwise word combinations in c.
qf_in
Frequency of appearance in queries from the Live Search 2006 search query log ?pproximately 15 million queries?. Query log frequencies are a measure of the likelihood that a catena will appear in any query. 
wf_in As for qf_in, but using frequency counts in Wikipedia titles instead of queries.
sepMode
Most frequent separation distance of words in catena c in the retrieval collection, with possible 
values S = ?1, 2, 3, long?. 1 means that all words are 
adjacent, 2 means separation by 0-1 words, and long 
means containment in a window of size 4 ? |c|.
H_c
Entropy for separation distance s of words in catena 
c in the retrieval collection.fs is the frequency of c 
in window size s, and fS is the frequency of c in a 
window of size 4 ? |c| . All f are normalized for 
catena length using |c||c| ?agen et al, 2011?.
              Hc =
?
s?S
fs + 0.5fS + 0.5 log2
fs + 0.5fS + 0.5
sepRatio
Where fs and fS are defined as for H_c:
                        sepRatioc =
fs>2 + 0.5fS + 0.5
wRatio
For words w in catena c; fS is defined as for H_c.
                   wRatioc =
0.5 + 1|c|?w?c fw
fS + 0.5
nomEnd
Boolean indicating whether the words at each end of the catena are nouns ?r the catena is a single noun?.
Dependency path features (D)
Table 2: Classifier features.
512
Feature Classes
Pr
 
ROB04
WT10G
GOV2
 
D-CIE-CIE-DE-D-CI
R
86.2 72.8
79.3 67.1
77.0 68.0
Pr R
83.5 67.5
76.9 59.7
70.9 61.8
Pr R
86.2 71.7
77.2 65.6
72.8 63.9
Pr R
86.2 72.0
79.6 66.1
75.5 67.2
 
Table 3: Average classifier precision (Pr) and recall
(R) over 10 folds. Pr is % positive predictions
that are correct. R is % positive labeled instances
predicted as positive. A combination of all classes
marginally performs best.
other collections used in this paper, plus TREC8-
QA. For example, training data for Robust04
includes data from WT10G, GOV2 and TREC8-
QA. Any examples that replicate catenae in the test
collection are excluded. For Robust04, WT10G
and GOV2 respectively, 30%, 82% and 69% of the
training data is derived from other collections.
5.2 Classification results
Average classification precision and recall is
shown in Table 3. Co-occurrence and IR effective-
ness prediction features (CI) was the most influen-
tial class, and accounted for 70% of all features in
the model. Performance is marginally better using
all features (E-D-CI) with a moderate improvement
over human agreement on the annotation task. The
E-D-CI filter is used in subsequent experiments.
Catenae were predicted for all queries. Predic-
tions were more accurate for Robust04 than the
other two collections. One potential explanation
is that Robust04 queries are longer on average
(up to 32 content words per query, compared to
up to 16 words) so they generate a more diverse
set of catenae that are more easily distinguished
with respect to informativeness. The proportion
of training data specific to the retrieval collection
may also be a factor. Longer queries produce a
greater number of catenae, so less training data
from other collections is required.
6 Evaluation framework
6.1 Baseline IR models
Baselines are a unigram query likelihood (QL)
model (bag of words) and a highly effective
sequential dependence (SD) variant of the Markov
random field (MRF) model (Metzler and Croft,
2005). SD uses a linear combination of three
cliques of terms, where each clique is prioritized
by a weight ?c. The first clique contains individual
words (query likelihood QL), ?1 = 0.85. The
second clique contains query bigrams that match
document bigrams in 2-word ordered windows
(?#1?), ?2 = 0.1. The third clique uses the same
bigrams as clique 2 with an 8-word unordered
window (?#uw8?), ?3 = 0.05. For example, the
query new york city in Indri4 query language is:
#weight(
?1 #combine(new york city)
?2 #combine(#1(new york) #1(york city))
?3 #combine(#uw8(new york) #uw8(york city)))
SD is a competitive baseline in IR (Bendersky
and Croft, 2008; Park et al, 2011; Xue et al,
2010). Our reformulated model uses the same
query format as SD, but the second and third
cliques contain filtered catenae instead of query
bigrams. In addition, because catenae may be
multi-word units, we adjust the unordered window
size to 4 ? |c|. So, if two catenae ?york? and ?new
york city? are selected, the last clique has the form:
?3 #combine( york #uw12(new york city))
This query representation enables word relations
to be explicitly indicated while maintaining
efficient and flexible matching of catenae in
documents. Moreover, it does not use dependency
relations between words during retrieval, so there
is no need to parse a collection.
6.2 Baseline catenae selection
We explore four filters for catenae. Three are
based on previous work and describe heuristic
features of promising catenae. The fourth is our
novel supervised classifier.
NomEnd: Catenae starting and ending with
nouns, or containing only one word that is a noun.
Paths between nouns are used by Lin and Pantel
(2001).
SemRol: Catenae in which all component
words are either predicates or argument heads.
This is based on work that uses paths between head
nouns and verbs (Shen et al, 2005), semantic roles
(Moschitti, 2008), and all dependency paths except
those that occur between words in the same base
chunk (e.g. noun / verb phrase) (Cui et al, 2005).
GovDep: Cantenae containing words with a
governor-dependent relation. Many IR models
use this form of path filtering e.g. (Gao et al,
2004; Wang et al, 2007). Relations are ?collapsed?
by removing stopwords to reduce the distance
between content nodes in a dependency graph.
4http://www.lemurproject.org/
513
ROBUST04 WT10G GOV2MAP R-Pr MAP R-Pr MAP R-PrQL 25.25 28.69 19.55 22.77 25.77 31.26SD 26.57? 30.02? 20.63 24.31? 28.00? 33.30?NomEnd 25.91? 29.35? 20.81? 24.27? 27.41? 32.94?GovDep 26.26? 29.63? 21.06 24.23? 27.87? 33.51?SemRol 25.70? 29.06 19.78 22.93 26.76 32.49?SFeat 27.04? 30.11? 20.84? 24.31? 28.43? 33.84?SF-12 27.03? 30.20? 21.62? 24.81? 28.57? 34.01?
Table 4: IR results using filtered catenae consistently improve over non-linguistic methods.
Significance(p < .05) shown compared to QL (?) and SD (?).
ROBUST04 WT10G GOV2MAP R-Pr MAP R-Pr MAP R-PrSF-12 27.03 30.20 21.62 24.81 28.57 34.01SF-123 26.83 30.34 21.34 24.64 28.77 34.24SF-NE 26.51 29.86 21.42 24.55 27.96 33.26SF-GD 26.22 29.48 20.33 23.72 28.30 33.83Gold 27.92 31.15 22.56 25.69 29.65 35.08
Table 5: Results with supervised selection of catenae with specified length (SF-12, SF-123) are more
effective than combinations of SFeat with heuristic NomEnd (SF-NE) or GovDep (SF-GD).
6.3 Experiments
Experiments compare queries reformulated
using catenae selected by baseline filters and our
supervised selection method (SFeat) to SD and
a bag-of-words model (QL). We also compare IR
effectiveness of all catenae filtered using SFeat
with approaches that combine SFeat with baseline
filters. All models are implemented using the Indri
retrieval engine version 4.12.
6.4 Results
Results in Table 4 show significant improvement
in mean average precision (MAP) of queries using
catenae compared to QL. Consistent improvements
over SD are also demonstrated for supervised
selection applied to all catenae (SFeat) and catenae
with only 1-2 words (SF-12) across all collections
(Table 5). Overall, changes are small and fairly
robust, with one half to two thirds of all queries
showing less than 10% change in MAP.
Unlike sFeat, other filters tend to decrease per-
formance compared to SD. Governor-dependent
relations for WT10G are an exception and we spec-
ulate that this is due to a negative influence of 3-
word catenae for this collection. Manual inspection
suggests that WT10G queries are short and have
relatively simple syntactic structure (e.g. few PP
attachment ambiguities). This means that 3-word
catenae (in all models except GovDep) tend to in-
clude uninformative words, such as ?reasons? in
?fasting religious reasons?. In contrast, 3-word cate-
nae in other collections tend to identify query sub-
concepts or phrases, such as ?science plants water?.
Classification results for catenae separated by
length, such that the classifier for catenae with a
specific length are trained on examples of catenae
with the same length, confirm this intuition. The
rejection rate for 3-word catenae is twice as high
for WT10G as for other collections. It is also
more difficult to distinguish informative 3-word
catenae compared to catenae with 1-2 words. To
assess the impact of classification accuracy on IR
effectiveness, Table 5 shows results with oracle
knowledge of annotator judgments.
The SF-12 model combines catenae predicted for
lengths 1 and 2. Its strong performance across all
collections suggests that most of the benefit derived
from catenae in IR is found in governor-dependent
and single word units, where single words are
important (GovDep uses only 2-word catenae).
Another major observation (Table 5) is that mixing
baseline heuristic filters with a supervised ap-
proach is not as successful as supervised selection
alone. In particular, performance decreases for
filtered governor-dependent pairs. This suggests
that some important word relations in GovDep and
NomEnd are captured by triangulation.
Finally, we review selected catenae for queries
that perform significantly better or worse than SD
(> 75% change in MAP). The best IR effectiveness
occurs when selected catenae clearly focus on the
most important aspect of a query. Poor perfor-
514
mance is caused by a lack of focus in a catenae set,
even though selected catenae are reasonable, or an
emphasis on words that are not central to the query.
The latter can occur when words that are not es-
sential to query semantics appear in many catenae
due to their position in the dependency graph.
7 Conclusion
We presented a flexible implementation of
dependency paths for long queries in ad hoc IR that
does not require dependency parsing a collection.
Our supervised selection technique for catenae
addresses the need to balance a representation of
language expressiveness with effective, efficient
statistical methods. This is a core challenge in
computational linguistics.
It is not possible to directly compare perfor-
mance of our approach with ad hoc techniques in
IR that parse a retrieval collection. However, we
note that a recent result using query translation
based on dependency paths (Park et al, 2011)
reports 14% improvement over query likelihood
(QL). Our approach achieves 7% improvement
over QL on the same collection. We conclude that
catenae do not replace path-based techniques, but
may offer some insight into their application, and
have particular value when it is not practical to
parse target documents to determine text similarity.
Acknowledgments
This work was supported in part by the Center
for Intelligent Information Retrieval. Any opinions,
findings and conclusions or recommendations
expressed in this material are those of the authors
and do not necessarily reflect those of the sponsor.
References
James Allan, Margaret E. Connell, W. Bruce Croft,
Fang-Fang Feng, David Fisher, and Xiaoyan Li.
2000. INQUERY and TREC-9. In Proceedings of
TREC-9, pages 551?562.
Michael Bendersky and W. Bruce Croft. 2008.
Discovering key concepts in verbose queries. In
Proceedings of the 31st annual international ACM
SIGIR conference on Research and development in
information retrieval, SIGIR ?08, pages 491?498,
New York, NY, USA. ACM.
Keke Cai, Jiajun Bu, Chun Chen, and Guang Qiu.
2007. A novel dependency language model for in-
formation retrieval. Journal of Zhejiang University
SCIENCE A, 8(6):871?882.
Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan,
and Tat-Seng Chua. 2005. Question answering
passage retrieval using dependency relations. In
Proceedings of the 28th annual international ACM
SIGIR conference on Research and development in
information retrieval, SIGIR ?05, pages 400?407,
New York, NY, USA. ACM.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of LREC-2006.
Abdessamad Echihabi and Daniel Marcu. 2003. A
noisy-channel approach to question answering.
In Proceedings of the 41st Annual Meeting on
Association for Computational Linguistics - Volume
1, ACL ?03, pages 16?23, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Yoav Freund and Robert E. Schapire. 1996. Experi-
ments with a new boosting algorithm. In ICML?96,
pages 148?156.
Jianfeng Gao, Jian-Yun Nie, Guangyuan Wu, and
Guihong Cao. 2004. Dependence language model
for information retrieval. In Proceedings of the 27th
annual international ACM SIGIR conference on
Research and development in information retrieval,
SIGIR ?04, pages 170?177, New York, NY, USA.
ACM.
Matthias Hagen, Martin Potthast, Benno Stein, and
Christof Bra?utigam. 2011. Query segmentation
revisited. In Proceedings of the 20th international
conference on World wide web, WWW ?11, pages
97?106, New York, NY, USA. ACM.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: an up-
date. SIGKDD Explorations Newsletter, 11:10?18,
November.
Michael Heilman and Noah A. Smith. 2010. Tree
edit models for recognizing textual entailments,
paraphrases, and answers to questions. In Hu-
man Language Technologies: The 2010 Annual
Conference of the North American Chapter of the
Association for Computational Linguistics, HLT
?10, pages 1011?1019, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based syntactic?semantic analysis
with PropBank and NomBank. In Proceedings of
CoNNL 2008, pages 183?187.
Changki Lee, Gary Geunbae Lee, and Myung-Gil
Jang. 2006. Dependency structure language model
for information retrieval. In In ETRI journal,
volume 28, pages 337?346.
Dekang Lin and Patrick Pantel. 2001. DIRT - discov-
ery of inference rules from text. In Proceedings
of ACM Conference on Knowledge Discovery
and Data Mining (KDD-01), pages 323?328, San
Francisco, CA.
515
Lo??c Maisonnasse, Eric Gaussier, and Jean-Pierre
Chevallet. 2007. Revisiting the dependence
language model for information retrieval. In
Proceedings of the 30th annual international ACM
SIGIR conference on Research and development in
information retrieval, SIGIR ?07, pages 695?696,
New York, NY, USA. ACM.
Igor A. Mel?c?uk. 2003. Levels of dependency in
linguistic description: Concepts and problems. In
V. Agel, L. Eichinger, H.-W. Eroms, P. Hellwig,
H. J. Herringer, and H. Lobin, editors, Dependency
and Valency. An International Handbook of Contem-
porary Research, volume 1, pages 188?229. Walter
De Gruyter, Berlin?New York.
Donald Metzler and W. Bruce Croft. 2005. A Markov
random field model for term dependencies. In
Proceedings of the 28th annual international ACM
SIGIR conference on Research and development in
information retrieval, SIGIR ?05, pages 472?479,
New York, NY, USA. ACM.
Alessandro Moschitti. 2008. Kernel methods, syntax
and semantics for relational text categorization.
In Proceeding of the 17th ACM conference on
Information and knowledge management, CIKM
?08, pages 253?262, New York, NY, USA. ACM.
Joakim Nivre. 2005. Dependency grammar and depen-
dency parsing. Technical report, Va?xjo? University:
School of Mathematics and Systems Engineering.
Timothy Osborne and Thomas Gro?. 2012. Con-
structions are catenae: Construction grammar
meets dependency grammar. Cognitive Linguistics,
23(1):165?216.
Timothy Osborne, Michael Putnam, and Gro?. 2012.
Catenae: Introducing a novel unit of syntactic
analysis. Syntax, 15(4):354?396, December.
Jae Hyun Park, W. Bruce Croft, and David A. Smith.
2011. A quasi-synchronous dependence model for
information retrieval. In Proceedings of the 20th
ACM international conference on Information and
knowledge management, CIKM ?11, pages 17?26,
New York, NY, USA. ACM.
Ellen F. Prince. 1986. On the syntactic marking of
presupposed open propositions. In Proceedings of
the 22nd Annual Meeting of the Chicago Linguistic
Society, pages 208?222.
V. Punyakanok, D. Roth, and W. Yih. 2004. Mapping
dependencies trees: An application to question
answering. In Proceedings of AI and MATH
Symposium 2004 (Special session: Intelligent Text
Processing).
Robert E. Schapire, Yoav Freund, Peter Bartlett, and
Wee Sun Lee. 1997. Boosting the margin: A new
explanation for the effectiveness of voting methods.
In Proceedings of ICML, pages 322?330.
Dan Shen, Geert-Jan M. Kruijff, and Dietrich Klakow.
2005. Exploring syntactic relation patterns for
question answering. In Proceedings of the Second
international joint conference on Natural Language
Processing, IJCNLP?05, pages 507?518, Berlin,
Heidelberg. Springer-Verlag.
Fei Song and W. Bruce Croft. 1999. A general
language model for information retrieval. In Pro-
ceedings of the 8th ACM international conference
on Information and knowledge management, CIKM
?99, pages 316?321, New York, NY, USA. ACM.
Young-In Song, Kyoung-Soo Han, Sang-Bum Kim,
So-Young Park, and Hae-Chang Rim. 2008. A
novel retrieval approach reflecting variability of syn-
tactic phrase representation. Journal of Intelligent
Information Systems, 31(3):265?286, December.
Munirathnam Srikanth and Rohini Srihari. 2002.
Biterm language models for document retrieval. In
Proceedings of the 25th annual international ACM
SIGIR conference on Research and development in
information retrieval, SIGIR ?02, pages 425?426,
New York, NY, USA. ACM.
Mark J. Steedman. 1990. Gapping as Constituent Co-
ordination. Linguistics and Philosophy, 13(2):207?
263, April.
Mihai Surdeanu, Massimiliano Ciaramita, and Hugo
Zaragoza. 2011. Learning to rank answers
to non-factoid questions from web collections.
Computational Linguistics, 37(2):351?383, June.
C. J. van Rijsbergen. 1993. A theoretical basis for the
use of co-occurrence data in information retrieval.
Journal of Documentation, 33(2):106?119.
Mengqiu Wang, Noah A. Smith, and Teruko Mitamura.
2007. What is the Jeopardy model? a quasi-
synchronous grammar for QA. In Proceedings of
the 2007 Joint Conference on Empirical Methods in
Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL),
pages 22?32, Prague, Czech Republic, June.
Association for Computational Linguistics.
Xiaobing Xue, Samuel Huston, and W. Bruce Croft.
2010. Improving verbose queries using subset
distribution. In Proceedings of the 19th ACM inter-
national conference on Information and knowledge
management, CIKM ?10, pages 1059?1068, New
York, NY, USA. ACM.
516
