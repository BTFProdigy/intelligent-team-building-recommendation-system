Proceedings of the ACL-HLT 2011 System Demonstrations, pages 80?85,
Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational Linguistics
A Speech-based Just-in-Time Retrieval System using Semantic Search
Andrei Popescu-Belis, Majid Yazdani, Alexandre Nanchen, and Philip N. Garner
Idiap Research Institute
Rue Marconi 19, CP 592
1920 Martigny, Switzerland
{apbelis,myazdani,ananchen,pgarner}@idiap.ch
Abstract
The Automatic Content Linking Device is a
just-in-time document retrieval system which
monitors an ongoing conversation or a mono-
logue and enriches it with potentially related
documents, including multimedia ones, from
local repositories or from the Internet. The
documents are found using keyword-based
search or using a semantic similarity measure
between documents and the words obtained
from automatic speech recognition. Results
are displayed in real time to meeting partici-
pants, or to users watching a recorded lecture
or conversation.
1 Introduction
Enriching a monologue or a conversation with re-
lated content, such as textual or audio-visual docu-
ments on the same topic, is a task with multiple ap-
plications in the field of computer-mediated human-
human communication. In this paper, we describe
the Automatic Content Linking Device (ACLD), a
system that analyzes spoken input from one or more
speakers using automatic speech recognition (ASR),
in order to retrieve related content, in real-time, from
a variety of repositories. These include local doc-
ument databases or archives of multimedia record-
ings, as well as websites. Local repositories are
queried using a keyword-based search engine, or us-
ing a semantic similarity measure, while websites
are queried using commercial search engines.
We will first describe the scenarios of use of the
ACLD in Section 2, and review previous systems for
just-in-time retrieval in Section 3. The ACLD com-
ponents will be outlined in Sections 4.1 to 4.5. Four
types of evaluation results obtained with our system
will finally be summarized in Sections 5.1 to 5.4.
2 Content Linking: Scenarios of Use
Just-in-time information retrieval, i.e. finding useful
documents without the need for a user to initiate a di-
rect search for them, is one of the ways in which the
large quantity of knowledge that is available in net-
worked environments can be efficiently put to use.
To perform this task, a system must consider ex-
plicit and implicit input from users, mainly speech
or typed input, and attempt to model their context,
in order to provide recommendations, which users
are free to consult if they feel the need for additional
information.
One of the main scenarios of use for the ACLD
involves people taking part in meetings, who often
mention documents containing facts under discus-
sion, but do not have the time to search for them
without interrupting the discussion flow. The ACLD
performs this search for them. Moreover, as the
ACLD was developed on meetings from the AMI
Corpus, it can also perform the same operations on
a replayed meeting, as a complement to a meet-
ing browser, for development or demonstration pur-
poses.
In a second scenario, content linking is performed
over live or recorded lectures, for instance in a
computer-assisted learning environment for individ-
ual students. The ACLD enriches the lectures with
related material drawn from various repositories,
through a search process that can be guided in real
80
time by its user. The advantage of real-time con-
tent linking over a more static enrichment, such as
the Feynman lectures at Microsoft Research,1 is that
users can tune search parameters at will while view-
ing the lecture.
3 Just-in-Time Retrieval Systems
The first precursors to the ACLD were the Fixit
query-free search system (Hart and Graham, 1997),
the Remembrance Agent for just-in-time retrieval
(Rhodes and Maes, 2000), and the Implicit Queries
(IQ) system (Dumais et al, 2004). Fixit monitored
the state of a user?s interaction with a diagnostic
system, and excerpts from maintenance manuals de-
pending on the interaction state. The Remembrance
Agent was integrated to the Emacs text editor, and
ran searches over emails or notes at regular time in-
tervals (every few seconds) using the latest 20?500
words typed by the user. The IQ system generated
context-sensitive searches based on a user?s ongoing
activities on their computer, such as writing email.
A version of the Remembrance Agent called Jim-
miny was conceived as a wearable assistant for tak-
ing notes, but ASR was only simulated for evalua-
tion (Rhodes, 1997).
The Watson system (Budzik and Hammond,
2000) monitored the user?s operations in a text ed-
itor, but proposed a more complex mechanism than
the Remembrance Agent for selecting terms for
queries, which were directed to a web search engine.
Another assistant for an authoring environment was
developed in the A-Propos project (Puerta Melguizo
et al, 2008). A query-free system was designed for
enriching television news with articles from the Web
(Henziker et al, 2005).
The FAME interactive space (Metze and al.,
2006), which provides multi-modal access to record-
ings of lectures via a table top interface, bears many
similarities to the ACLD. However, it requires the
use of specific voice commands by one user only,
and does not spontaneously follow a conversation.
More recently, several speech-based search en-
gines have become available, including as smart
phone applications. Conversely, many systems al-
low searching of spoken document archives.2 Inspi-
1See http://research.microsoft.com/apps/tools/tuva/.
2See workshops at http://www.searchingspeech.org.
ration from these approaches, which are not query-
free, can nevertheless be useful to just-in-time re-
trieval. Other related systems are the Speech Spot-
ter (Goto et al, 2004) and a personal assistant using
dual-purpose speech (Lyons et al, 2004), which en-
able users to search for information using commands
that are identified in the speech flow.
The ACLD improves over numerous past ones by
giving access to indexed multimedia recordings as
well as websites, with fully operational ASR and se-
mantic search, as we now explain.
4 Description of the ACLD
The architecture of the ACLD comprises the follow-
ing functions: document preparation, text extraction
and indexing; input sensing and query preparation;
search and integration of results; user interface to
display the results.
4.1 Document Preparation and Indexing
The preparation of the local database of documents
for content linking involves mainly the extraction of
text, and then the indexing of the documents, which
is done using Apache Lucene software. Text can be
extracted from a large variety of formats (includ-
ing MS Office, PDF, and HTML) and hierarchies
of directories are recursively scanned. The docu-
ment repository is generally prepared before using
the ACLD, but users can also add files at will. Be-
cause past discussions are relevant to subsequent
ones, they are passed through offline ASR and then
chunked into smaller units (e.g. of fixed length, or
based on a homogeneous topic). The resulting texts
are indexed along with the other documents.
The ACLD uses external search engines to search
in external repositories, for instance the Google Web
search API or the Google Desktop application to
search the user?s local drives.
4.2 Sensing the User?s Information Needs
We believe that the most useful cues about the in-
formation needs of participants in a conversation,
or of people viewing a lecture, are the words that
are spoken during the conversation or the lecture.
For the ACLD, we use the AMI real-time ASR sys-
tem (Garner et al, 2009). One of its main features
is the use of a pre-compiled grammar, which al-
lows it to retain accuracy even when running in real-
81
time on a low resource machine. Of course, when
content linking is done over past meetings, or for
text extraction from past recordings, the ASR sys-
tem runs slower than real-time to maximize accuracy
of recognition. However, the accuracy of real-time
ASR is only about 1% lower than the unconstrained
mode which takes several times real-time.
For the RT07 meeting data, when using signals
from individual headset microphones, the AMI ASR
system reaches about 38% word error rate. With
a microphone array, this increases to about 41%.
These values indicate that enough correct words are
sensed by the real-time ASR to make it applicable
to the ACLD, and that a robust search mechanism
could help avoiding retrieval errors due to spurious
words.
The words obtained from the ASR are filtered for
stopwords, so that only content words are used for
search; our list has about 80 words. Furthermore,
we believe that existing knowledge about the impor-
tant terminology of a domain or project can be used
to increase the impact of specific words on search. A
list of pre-specified keywords can be defined based
on such knowledge and can be modified while run-
ning the ACLD. For instance, for remote control de-
sign as in the AMI Corpus scenario, this list includes
about 30 words such as ?chip?, ?button?, or ?mate-
rial?. If any of them is detected in the ASR output,
then their importance is increased for searching, but
otherwise all the other words from the ASR (minus
the stopwords) are used for constructing the query.
4.3 Querying the Document Database
The Query Aggregator (QA) uses the ASR words
to retrieve the most relevant documents from one or
more databases. The current version of the ACLD
makes use of semantic search (see next subsection),
while previous versions used word-based search
from Apache Lucene for local documents, or from
the Google Web or Google Desktop APIs. ASR
words from the latest time frame are put together
(minus the stopwords) to form queries, and recog-
nized keywords are boosted in the Lucene query.
Queries are formulated at regular time intervals, typ-
ically every 15-30 seconds, or on demand. This du-
ration is a compromise between the need to gather
enough words for search, and the need to refresh the
search results reasonably often.
The results are integrated with those from the
previous time frame, using a persistence model to
smooth variations over time. The model keeps track
of the salience of each result, initialized from their
ranking among the search results, then decreasing
in time unless the document is again retrieved. The
rate of decrease (or its inverse, persistence) can be
tuned by the user, but in any case, all past results are
saved by the user interface and can be consulted at
any time.
4.4 Semantic Search over Wikipedia
The goal of our method for semantic search is to
improve the relevance of the retrieved documents,
and to make the mechanism more robust to noise
from the ASR. We have applied to document re-
trieval the graph-based model of semantic rela-
tedness that we recently developed (Yazdani and
Popescu-Belis, 2010), which is also related to other
proposals (Strube and Ponzetto, 2006; Gabrilovich
and Markovitch, 2007; Yeh et al, 2009).
The model is grounded in a measure of seman-
tic relatedness between text fragments, which is
computed using random walk over the network of
Wikipedia articles ? about 1.2 million articles from
the WEX data set (Metaweb Technologies, 2010).
The articles are linked through hyperlinks, and also
through lexical similarity links that are constructed
upon initialization. The random walk model allows
the computation of a visiting probability (VP) from
one article to another, and then a VP between sets of
articles, which has been shown to function as a mea-
sure of semantic relatedness, and has been applied
to various NLP problems. To compute relatedness
between two text fragments, these are first projected
represented into the network by the ten closest arti-
cles in terms of lexical similarity.
For the ACLD, the use of semantic relatedness for
document retrieval amounts to searching, in a very
large collection, the documents that are the most
closely related to the words from the ASR in a given
timeframe. Here, the document collection is (again)
the set of Wikipedia articles from WEX, and the goal
is to return the eight most related articles. Such a
search is hard to perform in real time; hence, the so-
lution that was found makes use of several approx-
imations to compute average VP between the ASR
fragment and all articles in the Wikipedia network.
82
Figure 1: Unobtrusive UI displaying document results.
Hovering the mouse over a result (here, the most relevant
one) displays a pop-up window with more information
about it.
4.5 The User Interface (UI)
The main goal of the UI is to make available all
information produced by the system, in a config-
urable way, allowing users to see a larger or smaller
amount of information according to their needs. A
modular architecture with a flexible layout has been
implemented, maximizing the accessibility but also
the understandability of the results, and displaying
also intermediary data such as ASR words and found
keywords. The UI displays up to five widgets, which
can be arranged at will:
1. ASR results with highlighted keywords.
2. Tag-cloud of keywords, coding for recency and
frequency of keywords.
3. Names of documents and past meeting snippets
found by the QA.
4. Names of web pages found via the Google API.
5. Names of local files found via the Google
Desktop API.
Two main arrangements are intended, though
many others are possible: an informative full-screen
UI, shown in Figure 2 with widgets 1?4; and an un-
obtrusive widget UI, with superposed tabs, shown in
Figure 1 with widget 3.
The document names displayed in widgets 3?5
function as hyperlinks to the documents, launching
appropriate external viewers when the user clicks on
them. Moreover, when hovering over a document
name, a pop-up window displays metadata and doc-
ument excerpts that match words from the query, as
an explanation of why the document was retrieved.
5 Evaluation Experiments
Four types of evidence for the relevance and utility
of the ACLD are summarized in this section.
5.1 Feedback from Potential Users
The ACLD was demonstrated to about 50 potential
users (industrial partners, focus groups, etc.) in a
series of sessions of about 30 minutes, starting with
a presentation of the ACLD and continuing with a
discussion and elicitation of feedback. The overall
concept was generally found useful, with positive
verbal evaluations. Feedback for smaller and larger
improvements was collected: e.g. the importance of
matching context, linking on demand, and the UI un-
obtrusive mode.
5.2 Pilot Task-based Experiments
A pilot experiment was conducted by a team at the
University of Edinburgh with an earlier version of
the unobtrusive UI. Four subjects had to complete a
task that was started in previous meetings (ES2008a-
b-c from the AMI Corpus). The goal was to compare
two conditions, with vs. without the ACLD, in terms
of satisfied constraints, overall efficiency, and satis-
faction. Two pilot runs have shown that the ACLD
was being consulted about five times per meeting.
Therefore, many more runs are required to reach sta-
tistical significance of observations, and remain to
be executed depending on future resources.
5.3 Usability Evaluation of the UI
The UI was submitted to a usability evaluation ex-
periment with nine non-technical subjects. The
subjects used the ACLD over a replayed meeting
recording, and were asked to perform several tasks
with it, such as adding a keyword to monitor, search-
ing for a word, or changing the layout. The subjects
then rated usability-related statements, leading to an
assessment on the System Usability Scale (Brooke,
1996).
The overall usability score was 68% (SD: 10),
which is considered as ?acceptable usability? for the
SUS. The average task-completion time was 45?
75 seconds. In free-form feedback, subjects found
the system helpful to review meetings but also lec-
tures, appreciated the availability of documents, but
also noted that search results (with keyword-based
83
Figure 2: Full screen UI with four widgets: ASR, keywords, document and website results.
search) were often irrelevant. They also suggested
simplifying the UI (menus, layout) and embedding
a media player for use in the meeting or lecture re-
play scenario.
5.4 Comparing the Relevance of
Keyword-based vs. Semantic Search
We compared the output of semantic search with
that of keyword-based search. The ASR transcript
of one AMI meeting (ES2008d) was passed to both
search methods, and ?evaluation snippets? contain-
ing the manual transcript for one-minute excerpts,
accompanied by the 8-best Wikipedia articles found
by each method were produced. Overall, 36 snip-
pets were generated. The manual transcript shown to
subjects was enriched with punctuation and speak-
ers? names, and the names of the Wikipedia pages
were placed on each side of the transcript frame.
Subjects were then asked to read each snippet,
and decide which of the two document sets was the
most relevant to the discussion taking place, i.e. the
most useful as a suggestion to the participants. They
could also answer ?none?, and could consult the re-
sult if necessary.
Results were obtained from 8 subjects, each see-
ing 9 snippets out of 36. Every snippet was thus
seen by two subjects. The subjects agreed on 23
(64%) snippets and disagreed on 13 (36%). In fact,
the number of true disagreements not including the
answer ?none? was only 7 out of 36.
Over the 23 snippets on which subjects agreed,
the result of semantic search was judged more rel-
evant than that of keyword search for 19 snippets
(53% of the total), and the reverse for 4 snippets
only (11%). Alternatively, if one counts the votes
cast by subjects in favor of each system, regardless
of agreement, then semantic search received 72%
of the votes and keyword-based only 28%. These
numbers show that semantic search quite clearly im-
proves relevance in comparison to keyword-based
one, but there is still room for improvement.
6 Conclusion
The ACLD is, to the best of our knowledge, the
first just-in-time retrieval system to use spontaneous
speech and to support access to multimedia docu-
ments and web pages, using a robust semantic search
method. Future work will aim at improving the rel-
evance of semantic search, at modeling context to
84
improve timing of results, and at inferring relevance
feedback from users. The ACLD should also be ap-
plied to specific use cases, and an experiment with
group work in a learning environment is under way.
Acknowledgments
The authors gratefully acknowledge the support
of the EU AMI and AMIDA Integrated Projects
(http://www.amiproject.org) and of the Swiss IM2
NCCR on Interactive Multimodal Information Man-
agement (http://www.im2.ch).
References
John Brooke. 1996. SUS: A ?quick and dirty? us-
ability scale. In Patrick W. Jordan, Bruce Thomas,
Bernard A. Weerdmeester, and Ian L. McClelland, ed-
itors, Usability evaluation in industry, pages 189?194.
Taylor and Francis, London, UK.
Jay Budzik and Kristian J. Hammond. 2000. User inter-
actions with everyday applications as context for just-
in-time information access. In IUI 2000 (5th Interna-
tional Conference on Intelligent User Interfaces), New
Orleans, LA.
Susan Dumais, Edward Cutrell, Raman Sarin, and Eric
Horvitz. 2004. Implicit Queries (IQ) for contextual-
ized search. In SIGIR 2004 (27th ACM SIGIR Confer-
ence) Demonstrations, page 534, Sheffield, UK.
Evgeniy Gabrilovich and Shaul Markovitch. 2007. Com-
puting semantic relatedness using Wikipedia-based
explicit semantic analysis. In IJCAI 2007 (20th Inter-
national Joint Conference on Artificial Intelligence),
pages 6?12, Hyderabad, India.
Philip N. Garner, John Dines, Thomas Hain, Asmaa
El Hannani, Martin Karafiat, Danil Korchagin, Mike
Lincoln, Vincent Wan, and Le Zhang. 2009. Real-
time ASR from meetings. In Interspeech 2009 (10th
Annual Conference of the Intl. Speech Communication
Association), pages 2119?2122, Brighton, UK.
Masataka Goto, Koji Kitayama, Katsunobu Itou, and Tet-
sunori Kobayashi. 2004. Speech Spotter: On-demand
speech recognition in human-human conversation on
the telephone or in face-to-face situations. In ICSLP
2004 (8th International Conference on Spoken Lan-
guage Processing), pages 1533?1536, Jeju Island.
Peter E. Hart and Jamey Graham. 1997. Query-free in-
formation retrieval. IEEE Expert: Intelligent Systems
and Their Applications, 12(5):32?37.
Monika Henziker, Bay-Wei Chang, Brian Milch, and
Sergey Brin. 2005. Query-free news search. World
Wide Web: Internet and Web Information Systems,
8:101?126.
Kent Lyons, Christopher Skeels, Thad Starner, Cor-
nelis M. Snoeck, Benjamin A. Wong, and Daniel Ash-
brook. 2004. Augmenting conversations using dual-
purpose speech. In UIST 2004 (17th Annual ACM
Symposium on User Interface Software and Technol-
ogy), pages 237?246, Santa Fe, NM.
Metaweb Technologies. 2010. Freebase Wikipedia Ex-
traction (WEX). http://download.freebase.com/wex/.
Florian Metze and al. 2006. The ?Fame? interactive
space. In Machine Learning for Multimodal Interac-
tion II, LNCS 3869, pages 126?137. Springer, Berlin.
Maria Carmen Puerta Melguizo, Olga Monoz Ramos,
Lou Boves, Toine Bogers, and Antal van den Bosch.
2008. A personalized recommender system for writ-
ing in the Internet age. In LREC 2008 Workshop on
NLP Resources, Algorithms, and Tools for Authoring
Aids, pages 21?26, Marrakech, Morocco.
Bradley J. Rhodes and Pattie Maes. 2000. Just-in-time
information retrieval agents. IBM Systems Journal,
39(3-4):685?704.
Bradley J. Rhodes. 1997. The Wearable Remembrance
Agent: A system for augmented memory. Personal
Technologies: Special Issue on Wearable Computing,
1:218?224.
Michael Strube and Simone Paolo Ponzetto. 2006.
Wikirelate! Computing semantic relatedness using
Wikipedia. In AAAI 2006 (21st National Conference
on Artificial Intelligence), pages 1419?1424, Boston,
MA.
Majid Yazdani and Andrei Popescu-Belis. 2010. A ran-
dom walk framework to compute textual semantic sim-
ilarity: A unified model for three benchmark tasks. In
ICSC 2010 (4th IEEE International Conference on Se-
mantic Computing), pages 424?429, Pittsburgh, PA.
Eric Yeh, Daniel Ramage, Christopher D. Manning,
Eneko Agirre, and Aitor Soroa. 2009. WikiWalk: ran-
dom walks on Wikipedia for semantic relatedness. In
TextGraphs-4 (4th Workshop on Graph-based Methods
for NLP), pages 41?49, Singapore.
85
Proceedings of the TextGraphs-6 Workshop, pages 29?36,
Portland, Oregon, USA, 19-24 June 2011. c?2011 Association for Computational Linguistics
Using a Wikipedia-based Semantic Relatedness Measure for Document
Clustering
Majid Yazdani
Idiap Research Institute and EPFL
Centre du Parc, Rue Marconi 19
1920 Martigny, Switzerland
majid.yazdani@idiap.ch
Andrei Popescu-Belis
Idiap Research Institute
Centre du Parc, Rue Marconi 19
1920 Martigny, Switzerland
andrei.popescu-belis@idiap.ch
Abstract
A graph-based distance between Wikipedia ar-
ticles is defined using a random walk model,
which estimates visiting probability (VP) be-
tween articles using two types of links: hy-
perlinks and lexical similarity relations. The
VP to and from a set of articles is then com-
puted, and approximations are proposed to
make tractable the computation of semantic
relatedness between every two texts in a large
data set. The model is applied to document
clustering on the 20 Newsgroups data set. Pre-
cision and recall are improved in comparison
with previous textual distance algorithms.
1 Introduction
Many approaches have been proposed to compute
similarity between texts, from lexical overlap mea-
sures to statistical topic models that are learned from
large corpora. In this paper, we propose a method for
using knowledge from a structured, collaborative re-
source ? the Wikipedia hypertext encyclopedia ? in
order to build a measure of semantic relatedness that
we test on a text clustering task.
The paper first describes the document graph de-
rived from Wikipedia (Section 2), and then defines
a network-based distance using visiting probability
(Section 3), along with algorithms for its applica-
tion to text clustering (Section 4). Results over the
20 Newsgroups dataset are shown to be competitive
(Section 5), and the relative contributions of cosine
lexical similarity and visiting probability are ana-
lyzed. Our proposal is discussed in the light of pre-
vious work in Section 6.
2 The Document Network
In the present proposal, knowledge about seman-
tic relatedness is embodied into a document net-
work, whose nodes are intended to represent con-
cepts, while the links between nodes stand for var-
ious relations between concepts. The nodes of the
network correspond to articles from the Wikipedia
hypertext encyclopedia, and are derived as follows.
The network was built from Wikipedia, using the
WEX dataset (Metaweb Technologies, 2010). All
articles from the following categories were removed,
as they do not correspond to proper concepts: Talk,
File, Image, Template, Category, Portal, and List.
Moreover, disambiguation pages and articles shorter
than 100 non-stopwords were filtered out as well.
Out of 4,327,482 articles in WEX, 1,264,611 articles
were kept, forming the nodes of our network.
The first type of links in our document network
are the hyperlinks between articles, because, in prin-
ciple, each link between two articles indicates some
form of relatedness between them. There are more
than 35 million such links in our network.
The second type of links is derived from the sim-
ilarity of lexical content between articles. This is
computed using cosine similarity between the lexi-
cal vectors corresponding to the articles? texts, after
stopword removal and stemming. Then, links are
created by connecting every article to the 10 arti-
cles that are most similar to it, each link receiving
a weight which is the normalized lexical similarity
score. The number 10 was chosen to ensure compu-
tational tractability, and is in the same range as the
average number of hyperlinks per node (30).
29
Computing semantic relatedness between two
texts requires: (1) to estimate relatedness between
two sets of nodes in the network, as described in
Sections 3 and 4; and (2) to project each text onto
a set of nodes, as we briefly explain here. The pro-
jection of a text onto the network is found by com-
puting the text?s lexical similarity with all articles,
again using cosine distance over stemmed words,
without stopwords. The text is mapped to the 10
closest articles, resulting in a probability distribution
over the 10 corresponding nodes. Again, this value
was chosen to be similar to the number of hyperlinks
and content links per node, and to keep computation
tractable. In fact, the numerous Wikipedia articles
are scattered in the space of words, therefore tuning
these values does not seem to bring crucial changes.
3 Computing Relatedness in the Network
Using Visiting Probability (VP)
We have previously defined a random walk model
(Yazdani and Popescu-Belis, 2010) to compute re-
latedness of sets of nodes as the visiting probability
(VP ) of a random walker from one set to another
one, and we will review the model in this section. In
the next section, we will explain how the model was
extended for application to document clustering.
3.1 Notations
Let S = {si|1 ? i ? n} be the set of n nodes
in the graph. Any two nodes si and sj can be con-
nected by one or more directed and weighted links,
which can be of L different types (L = 2 in our
case: hyperlinks and lexical similarity links). Links
between nodes can thus be represented by L matri-
ces Al (1 ? l ? L) of size n ? n, where Al(i, j)
is the weight of the link of type l between si and sj .
The transition matrix Cl gives the probability of a
direct transition between nodes si and sj , using only
links of type l. This matrix can be built from the Al
matrix as follows:
Cl(i, j) =
Al(i, j)
?n
k=1Al(i, k)
.
In the random walk process using all link types
(1 ? l ? L), let the weight wl denote the impor-
tance of link type l. Then, the overall transition ma-
trix C giving the transition probability Ci,j between
nodes si and sj is : C =
?L
l=1wlCl.
One of the main parameters in this computation
is the relative weight of the two types of links (lex-
ical similarity and hyperlinks) in the random walk
over the network. The settings for the experiments
on document clustering (0.6 vs. 0.4) are explained in
Section 5.1 below.
3.2 VP from a Set of Nodes to a Node
Let us consider a probability distribution ~r over
nodes, corresponding to the projection of a text frag-
ment onto the network of articles (Section 2). Given
a new node sj in the network, our model first esti-
mates the probability of visiting sj for the first time
when a random walker starts from ~r in the graph.
The model considers the state St of the random
walker (its position node) and provides a procedure
which, executed until termination, yields the value
of VP . Namely, the initial state is chosen at random
with probability P (S0 = si|~r) = ri (where the ri
are the components of ~r). Then, from state St?1, ei-
ther St?1 = sj and the procedure is finished, or the
next node is chosen using the transition matrix C.
Moreover, it is also possible to ?fail? the walk with
a small probability, called ?absorption probability?,
which makes longer paths less probable.
3.3 Differences between VP and PageRank or
Hitting Time
The VP of sj starting from the distribution ~r, as
computed here, is different from the probability as-
signed to sj after running Personalized PageRank
(Haveliwala, 2003) with a teleport vector equal to ~r.
In the computation of VP , the loops starting from sj
and ending to the same sj do not have any effect on
the final score, unlike for PPR, for which such loops
boost the probability of sj . If some pages have this
type of loops (typically, very ?popular? pages), then
after using PPR they will have high probability al-
though they might not be very close to the teleport
vector ~r.
The VP of sj is also different from the hitting
time to sj , defined as the average number of steps
a random walker would take to visit sj for the first
time in the graph starting from ~r. Hitting time is
more sensitive to long paths in comparison to VP ,
a fact that might introduce more noise.The perfor-
mance of these three algorithms in computing se-
30
mantic similarity has been compared in (Yazdani
and Popescu-Belis, 2010).
3.4 VP between Sets of Nodes
Generalizing now to the computation of VP from
a weighted set of nodes ~r1 (a probability distribu-
tion) to another set ~r2, the model first constructs a
virtual node representing ~r2 in the network, named
by convention sR, and then connects all nodes si to
sR according to their weights in ~r2. The transition
matrix for the random walk is updated accordingly.
To compute relatedness of two texts projected
onto the network as ~r1 and ~r2, the VP of ~r1 given
~r2 is averaged with the converse probability, of ~r2
given ~r1 ? a larger probability indicating closer se-
mantic relatedness.
3.5 Truncated VP
The computation of VP can be done iteratively and
can be truncated after a number of steps, as the im-
portance of longer paths grows smaller due to the
absorption probability, leading thus to a T -truncated
visiting probability noted VPT . Besides making
computation more tractable, truncation reduces the
effect of longer paths, which seem to be less reliable
indicators of relatedness.
We have computed an upper bound on the trun-
cation error, which helps to control and minimize
the number of steps actually computed in a random
walk. To compute the upper bound of the truncation
error we compute the probability of returning neither
success (reaching sj) nor failure (absorption) in first
t steps, which can be computed as
?n
i 6=j ?
t(~rC ?t)i.
This is in fact the probability mass at time t at all
nodes except sj , the targeted node. C ? is the transi-
tion matrix that gives the probability of a transition
between two nodes, modified to include the virtual
node sR in the network, and 1? ? is the absorption
probability.
If pt(success) denotes the probability of success
(reaching sj) considering paths of length at most t,
and ?t the error made by truncating after step t, then
we have:
?t = p(success)? pt(success) ?
?n
i 6=j ?
t(~rC ?t)i
So, if pt(success) is used as an approximation for
p(success) then an upper bound for this approxima-
tion error ?t is the right term of the above inequality.
4 Application of VP to Text Clustering
In this section, we describe the additional modeling
that was done so that semantic relatedness based on
VP could be applied efficiently to text clustering.
Indeed, it is not tractable to individually compute
the average VP between any two texts in the set of
documents to be clustered, because the numbers of
pairs is very large ? e.g., 20,000 documents in the
experiments in Section 5. Instead, we propose two
solutions for computing, respectively, VP to a set of
nodes (from all documents in the network), and re-
spectively VP from a set of nodes to all documents.
4.1 Computing VP from All Nodes to a Subset
To compute the T -truncated visiting probability
(noted VPT ) from all nodes in the network to a node
sR at the same time, the following recursive pro-
cedure is defined. Here, T is the number of steps
before truncation, and sR is a virtual node repre-
senting a probability distribution ~r from a text. The
procedure is based on the definition of VP between
nodes in Section 3 and uses the transition matrix C ?
that gives the probability of a transition between two
nodes, modified to include the virtual node sR in the
network. If 1? ? is the absorption probability, then
the recursive definition of VPT from a node si to
the virtual node sR is:
VPT (si, sR) = ?
?
k C
?(si, sk)VPT?1(sk, sR)
Using dynamic programming, it is possible to
compute VPT from all nodes to sR inO(ET ) steps,
where E is the number of links in the network.
The initialization of the procedure is done using
VPT (sR, sR) = 1 and VP0(si, sR) = 0 for any
i 6= R.
4.2 Computing VP from a Subset to All Nodes
To compute the truncated VP from ~r to all nodes
in the network, the total computation time using
the definition of VPT from Section 3 is O(ETN ),
where N is the number of nodes in the network, be-
cause VPT must be computed for each node sepa-
rately. For a large data set, this is not tractable.
The proposed solution is based on a sampling
method over the random walks to approximate
VPT . The sampling involves running M indepen-
dent random walks of length T from ~r. For a given
31
node sj and a sample walk m, the first time (if any)
when sj is visited on each random walk starting
from ~r is noted tjm . Then, VP
T can be estimated
by the following average over sample walks, where
1? ? is again the absorption probability:
?VPT (~r, sj) = (
?
m ?
tjm )/M.
As a result, the estimate of VPT can be computed
in O(MT ) steps, where M is the number of sample
paths.
Moreover, it is possible to compute a bound on the
error of the estimation, |VPT? ?VPT |, depending on
the number of sample paths M . It can be shown that
the error is lower than ?, with a probability larger
than 1 ? ?, on condition that the number of sample
paths is greater than ?2 ln(2/?)/2?2.
To prove this bound, we use inspiration from a
proof by Sarkar et al (2008). If the estimation of a
variableX is noted X? , let us suppose that concept sj
has been visited for the first time at {tj1 , ? ? ? , tjm}
time steps in the M sample walks. We define the
random variable X l by ?tjl/M , where tjl indicates
the time step at which sj was visited for the first
time in lth sampling. If sj was not visited at all,
then X l = 0 by convention. The l random variables
X l (j1 ? l ? jm) are independent and bounded by
0 and 1 (0 ? X l ? 1). We have:
?VPT (~r, sj) =
?
lX
l = (
?
l ?
tjl )/M and
E( ?VPT (~r, sj)) = VPT (~r, sj).
So, by applying Hoeffding?s inequality, we have:
P (| ?VPT ? E( ?VPT )| ? ) ? 2exp(?2M
2
?2 ).
If the probability of error must be at most ?, then
setting the right side lower than ? gives the bound
for M that is stated in our theorem.
As a consequence, we have the following lower
bound forM if we want ?-approximation for all pos-
sible sj with probability at least 1? ?. We use union
bound and Hoeffding?s inequality:
P (?j ? {1, . . . , n}, | ?VPT ? E( ?VPT )| ? ) ? 2n?
exp(?2M
2
?2 )
which gives the lower bound M ? ?
2 ln(2n/?)
22 .
5 Document Clustering
This section describes the experimental setting and
the results of applying the text relatedness measure
defined above to the problem of document cluster-
ing over the 20 Newsgroups dataset.1 The dataset
contains about 20,000 postings to 20 news groups,
hence 20 document classes, with about 1,000 docu-
ments per class. We aim here at finding these classes
automatically, using for testing the entire data set
without using any part of it as a training set. The
knowledge of our system comes entirely from the
document network and the techniques for comput-
ing distances between two texts projected onto it.
5.1 Setup of the Experiment
We first compute a similarity matrix for the entire 20
Newsgroups data set, with the relatedness score be-
tween any two documents being VPT . For tractabil-
ity, we fixed T = 5 that gives sufficient precision; a
larger value only increased computation time. In-
stead of computing VPT between all possible pairs
separately, we fill one row of the matrix at a time
using the approximations above.
We set the absorption probability of the random
walk 1 ? ? = 0.2 for this experiment. Given ?
and T by using the formula in section 3.5, it is pos-
sible to compute the error bound of the truncation,
and noting that for a smaller ?, fewer steps (T ) are
needed to achieve the same approximation precision
because of the penalty set to longer paths. Con-
versely, a larger ? decreases the penalty for longer
paths and requires more computation.2
For comparison purposes, four similarity matri-
ces were computed. Indeed, the theoretical appara-
tus described above can be applied to various types
of links in the document network. In Section 2, we
introduced two types of links, namely lexical simi-
larity and actual hyperlinks, and these can be used
separately in the model, or as a weighted combina-
tion. The following similarities will be compared:
1. VP over hyperlinks only (noted VPHyp);
2. VP over lexical similarity links (VPLex);
1Distributed at http://www.cs.cmu.edu/afs/cs.
cmu.edu/project/theo-20/www/data/news20.
html, see also (Mitchell, 1997, Chapter 6).
2Note that in the extreme case when ? = 0, similarity to all
nodes except the node itself is zero.
32
3. VP over a combination of hyperlinks (0.4) and
lexical links (0.6) (noted VPComb) ? these val-
ues gave the best results in our previous appli-
cations to word and document similarity tasks
(Yazdani and Popescu-Belis, 2010);
4. no random walk, only cosine similarity be-
tween the tf-idf vectors of the documents to be
clustered (noted LS , for lexical similarity).
5.2 Clustering Performance
Clustering is performed using a k-means algorithm
over each of the four similarity matrices.3 The qual-
ity of the clustering is first measured using the Rand
Index (RI), which counts the proportion of pairs of
documents that are similarly grouped, i.e. either in
the same, or in different clusters, in the reference
vs. candidate clusterings. Other methods exist (Pan-
tel and Lin, 2002), including a Rand Index adjusted
for chance (Vinh et al, 2009), but the RI suffices
for comparative judgments in this subsection. How-
ever, in Subsection 5.3, we will also look at preci-
sion and recall, and in Subsection 5.4 we will use
purity. As the clustering is performed over the entire
data set, because there is no training vs. test data,
confidence intervals are not available, though they
could be computed by splitting the data. As a result,
comparison with other scores on the same test set is
absolute.
The scores in terms of Rand Index are, in decreas-
ing order:
1. 90.8% for VPComb
2. 90.6% for VPHyp
3. 90.4% for VPLex
4. and only 86.1% for the LS cosine similarity.
The random walk model thus clearly outperforms
the baseline LS approach. If counting only wrongly
clustered document pairs, VPComb has 6.6% of such
pairs, while VPLex has 8.4%, confirming the lower
performance of the model using only lexical similar-
ity links, i.e. the utility of hyperlinks.
3The semantic relatedness measure proposed here could be
used with other clustering algorithms, such as the committee-
based method proposed by Pantel and Lin (2002).
5.3 Comparison to Other Methods
To obtain a better understanding of the performance
of the proposed method, we computed the clustering
precision and recall of several well-known methods
for statistical text representation, shown in Table 1.
For Latent Dirichlet Allocation (LDA) (Blei et al,
2003) and Latent Semantic Analysis (LSA) (Deer-
wester et al, 1990), we first mapped the documents
in the latent space and then computed the cosine
similarity between the documents in the latent space.
The number of topics for LSA and LDA is set to 100
to make the computation tractable. Precision and re-
call are used, rather than the Rand Index, to show in
more detail the performance of each method. The
use of VP over our document network clearly in-
creases both precision and recall in comparison to
other tested approaches.
Similarity method Precision Recall
LS 7.50 18.38
LSA 8.63 9.99
LDA 19.93 31.50
VPComb 23.81 35.32
Table 1: Precision and Recall for k-means clustering over
the 20 Newsgroups using several well-known methods to
compute text similarity, in comparison to the present pro-
posal.
5.4 Analysis of the Impact of VP with Respect
to Cosine Similarity
To find out in which cases the proposed method im-
proves over a simple cosine similarity measure, we
considered a linear combination of the cosine simi-
larity and VP , noted w?VPComb+(1?w)?LS ,
and varied the weight w from 0 to 1. Considering
the k-nearest neighbors of every document accord-
ing to this combined similarity, we define k-purity
as the number of documents with the correct label
over the total number of documents k in the com-
puted neighborhood. The variation of k-purity with
w, for several values of k, is shown in Figure 1.
The best purity appears to be obtained for a com-
bination of the two methods, for all values of k that
were tested. This shows that VPComb brings valu-
able additional information about document relat-
edness that cannot be found in LS only. Further-
33
Figure 1: Values of k-purity (vertical axis) averaged over all documents, for neighborhoods of different sizes k. The
horizontal axis indicates the weightw of visiting probability vs. cosine lexical similarity in the formula: w?VPComb+
(1? w)? LS .
more, when the size of the examined neighborhood
k increases (lower curves in Figure 1), the effect of
VPComb becomes more important, i.e. its weight in
the optimal combination increases. For very small
neighborhoods, LS is almost sufficient to ensure op-
timal purity, but for larger ones (k = 10 or 15),
VPComb used alone (w = 1) outperforms LS used
alone (w = 0). Their optimal combination leads to
scores that are higher than those obtained for each
of them used separately, and, as noted, the weight of
VPComb in the optimal combination increases for
larger neighborhoods.
These results can be explained as follows. For
very small neighborhoods, the cosine lexical simi-
larity score with the nearest 1?5 documents is very
high, as they have many words in common, so LS is
a good measure of text relatedness. However, when
looking at larger neighborhoods, for which related-
ness is less based on identical words, then VPComb
becomes more effective, and LS performs poorly.
Therefore, we can predict that VPComb will be most
relevant when looking for larger neighborhoods, or
in order to increase recall. VPComb should also be
relevant when there is low diversity among docu-
ment words, for instance when all documents are
very short.
6 Related Work
Many attempts have been made to improve the
overlap-based lexical similarity distance, for various
applications to HLT. One approach is to construct
a taxonomy of concepts and relations (manually or
automatically) and to map the text fragments to be
compared onto the taxonomy. For instance, Word-
net (Fellbaum, 1998) and Cyc (Lenat, 1995) are two
well-known knowledge bases that can be used for
enriching pure lexical matching. However, building
and maintaining such resources requires consider-
able effort, and they might cover only a fraction of
the vocabulary of a language, as they usually include
few proper names or technical terminology.
Another approach makes use of unsupervised
methods to construct a semantic representation of
34
documents by analyzing mainly co-occurrence rela-
tionships between words in a corpus. Latent Seman-
tic Analysis (Deerwester et al, 1990), Probabilistic
LSA (Hofmann, 1999) and Latent Dirichlet Alloca-
tion (Blei et al, 2003) are unsupervised methods that
construct a low-dimensional feature representation
or concept space, in which words are no longer sup-
posed to be independent.
Mihalcea et al (2006) compared knowledge-
based and corpus-based methods, using word sim-
ilarity and word specificity to define one general
measure of text semantic similarity. Because it com-
putes word similarity values between all word pairs,
the proposed method appears to be suitable mainly
to compute similarity between short fragments, oth-
erwise the computation becomes intractable.
WikiRelate! (Strube and Ponzetto, 2006) com-
putes semantic relatedness between two words by
using Wikipedia. Each word is mapped to the corre-
sponding Wikipedia article by using article titles. To
compute relatedness, several methods are proposed,
namely, using paths in the Wikipedia category struc-
ture or the articles? content. Our method, by compar-
ison, also uses the knowledge embedded in the hy-
perlinks between articles, as well as the entire con-
tents of articles, but unlike WikiRelate! it has been
extended to texts of arbitrary lengths.
Explicit Semantic Analysis (Gabrilovich and
Markovitch, 2007), instead of mapping a text to a
node or a small group of nodes in a taxonomy, maps
the text to the entire collection of available con-
cepts, by computing the degree of affinity of each
concept to the input text. Similarity is measured
in the new concept space. ESA does not use the
link structure or other structured knowledge from
Wikipedia. Moreover, by walking over a content
similarity graph, our method benefits from a non-
linear distance measure according to the paths con-
sisting of small neighborhoods.
In the work of Yeh et al (2009), a graph of docu-
ments and hyperlinks is computed from Wikipedia,
then a Personalized PageRank (Haveliwala, 2003) is
computed for each text fragment, with the teleport
vector being the one resulting from the ESA algo-
rithm cited above. To compute semantic relatedness
between two texts, Yeh et al (2009) simply compare
their personalized page rank vectors. By compari-
son, in our method, we also consider in addition to
hyperlinks the effect of word co-occurrence between
article contents. The use of visiting probability also
gives different results over personalized page rank,
as it measures different properties of the network.
There are many studies on measuring distances
between vertices in a graph. Two measures that are
close to the visiting probability proposed here are
hitting time and Personalized PageRank mentioned
in Section 3.3. Hitting time has been used in var-
ious studies as a distance measure in graphs, e.g.
for dimensionality reduction (Saerens et al, 2004)
or for collaborative filtering in a recommender sys-
tem (Brand, 2005). Hitting time was also used for
link prediction in social networks along with other
distances (Liben-Nowell and Kleinberg, 2003), or
for semantic query suggestion using a query/URL
bipartite graph (Mei et al, 2008). As for Personal-
ized PageRank, it was used for word sense disam-
biguation (Agirre and Soroa, 2009), and for measur-
ing lexical relatedness of words in a graph built from
WordNet (Hughes and Ramage, 2007).
7 Conclusion
We proposed a model for measuring text seman-
tic relatedness based on knowledge embodied in
Wikipedia, seen here as document network with two
types of links ? hyperlinks and lexical similarity
ones. We have used visiting probability to mea-
sure proximity between weighted sets of nodes, and
have proposed approximation algorithms to make
computation efficient for large graphs (more than
one million nodes and 40 million links) and large
text clustering datasets (20,000 documents in 20
Newsgroups). Results on the document clustering
task showed an improvement using both word co-
occurrence information and user-defined hyperlinks
between articles over other methods for text repre-
sentation.
Acknowledgments
The work presented in this paper has been supported
by the IM2 NCCR (Interactive Multimodal Infor-
mation Management) of the Swiss National Science
Foundation (http://www.im2.ch).
35
References
Eneko Agirre and Aitor Soroa. 2009. Personalizing
pagerank for word sense disambiguation. In Proceed-
ings of EACL 2009 (12th Conference of the European
Chapter of the Association for Computational Linguis-
tics), pages 33?41, Athens, Greece.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet Allocation. Journal of Ma-
chine Learning Research, 3:993?1022.
Matthew Brand. 2005. A random walks perspective on
maximizing satisfaction and profit. In Proceedings of
the 2005 SIAM International Conference on Data Min-
ing, Newport Beach, CA.
Scott Deerwester, Susan T. Dumais, George W. Furnas,
Thomas K. Landauer, and Richard Harshman. 1990.
Indexing by Latent Semantic Analysis. Journal of the
American Society for Information Science, 41(6):391?
407.
Christiane Fellbaum, editor. 1998. WordNet: An elec-
tronic lexical database. MIT Press, Cambridge, MA.
Evgeniy Gabrilovich and Shaul Markovitch. 2007. Com-
puting semantic relatedness using Wikipedia-based
explicit semantic analysis. In Proceedings of IJCAI
2007 (20th International Joint Conference on Artifi-
cial Intelligence), pages 6?12, Hyderabad.
Taher H. Haveliwala. 2003. Topic-sensitive pagerank:
A context-sensitive ranking algorithm for web search.
IEEE Transactions on Knowledge and Data Engineer-
ing, 15:784?796.
Thomas Hofmann. 1999. Probabilistic Latent Semantic
Indexing. In Proceedings of SIGIR 1999 (22nd ACM
SIGIR Conference on Research and Development in
Information Retrieval), pages 50?57, Berkeley, CA.
Thad Hughes and Daniel Ramage. 2007. Lexical se-
mantic relatedness with random graph walks. In
Proceedings of EMNLP-CoNLL 2007 (Conference on
Empirical Methods in Natural Language Processing
and Conference on Computational Natural Language
Learning), pages 581?589, Prague.
Douglas B. Lenat. 1995. CYC: A large-scale investment
in knowledge infrastructure. Communications of the
ACM, 38(11):33?38.
David Liben-Nowell and Jon Kleinberg. 2003. The link
prediction problem for social networks. In Proceed-
ings of CIKM 2003 (12th ACM International Confer-
ence on Information and Knowledge Management),
pages 556?559, New Orleans, LA.
Qiaozhu Mei, Dengyong Zhou, and Kenneth Church.
2008. Query suggestion using hitting time. In Pro-
ceeding of CIKM 2008 (17th ACM International Con-
ference on Information and Knowledge Management),
pages 469?478, Napa Valley, CA.
Metaweb Technologies. 2010. Freebase Wikipedia Ex-
traction (WEX). http://download.freebase.com/wex/.
Rada Mihalcea, Courtney Corley, and Carlo Strapparava.
2006. Corpus-based and knowledge-based measures
of text semantic similarity. In Proceedings of AAAI
2006 (21st National Conference on Artificial Intelli-
gence), pages 775?782, Boston, MA.
Tom M. Mitchell. 1997. Machine Learning. McGraw-
Hill, New York.
Patrick Pantel and Dekang Lin. 2002. Document cluster-
ing with committees. In Proceedings of SIGIR 2002
(25th Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval),
pages 199?206, Tampere.
Marco Saerens, Franois Fouss, Luh Yen, and Pierre
Dupont. 2004. The principal components analysis of
a graph, and its relationships to spectral clustering. In
Proceedings of ECML 2004 (15th European Confer-
ence on Machine Learning), pages 371?383, Pisa.
Purnamrita Sarkar, Andrew W. Moore, and Amit Prakash.
2008. Fast incremental proximity search in large
graphs. In Proceedings of ICML 2008 (25th Interna-
tional Conference on Machine Learning), pages 896?
903, Helsinki.
Michael Strube and Simone Paolo Ponzetto. 2006.
Wikirelate! Computing semantic relatedness using
Wikipedia. In Proceedings of AAAI 2006 (21st Na-
tional Conference on Artificial Intelligence), pages
1419?1424.
Nguyen Xuan Vinh, Julien Epps, and James Bailey.
2009. Information theoretic measures for clusterings
comparison: Is a correction for chance necessary? In
Proceedings of ICML 2009 (26th International Con-
ference on Machine Learning), Montreal.
Majid Yazdani and Andrei Popescu-Belis. 2010. A ran-
dom walk framework to compute textual semantic sim-
ilarity: a unified model for three benchmark tasks.
In Proceedings of IEEE ICSC 2010 (4th IEEE Inter-
national Conference on Semantic Computing), Pitts-
burgh, PA.
Eric Yeh, Daniel Ramage, Christopher D. Manning,
Eneko Agirre, and Aitor Soroa. 2009. WikiWalk:
random walks on Wikipedia for semantic relatedness.
In Proceedings of TextGraphs-4 (4th Workshop on
Graph-based Methods for Natural Language Process-
ing), pages 41?49, Singapore.
36
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 350?352,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
A Just-in-Time Document Retrieval System for Dialogues or Monologues
Andrei Popescu-Belis, Majid Yazdani, Alexandre Nanchen, and Philip N. Garner
Idiap Research Institute
Rue Marconi 19, Case Postale 592
1920 Martigny, Switzerland
{apbelis,myazdani,ananchen,pgarner}@idiap.ch
Abstract
The Automatic Content Linking Device is a
just-in-time document retrieval system that
monitors an ongoing dialogue or monologue
and enriches it with potentially related docu-
ments from local repositories or from the Web.
The documents are found using queries that
are built from the dialogue words, obtained
through automatic speech recognition. Re-
sults are displayed in real time to the dialogue
participants, or to people watching a recorded
dialogue or a talk. The system can be demon-
strated in both settings.
1 Introduction
The Automatic Content Linking Device (ACLD) is
a system that analyzes speech input from one or
more speakers using automatic speech recognition
(ASR), in order to retrieve related content, in real
time, from a variety of repositories. This paper de-
scribes the main components of the system and sum-
marizes evaluation results. The remainder of this
section introduces scenarios of use and previous sys-
tems with similar goals.
The first scenario of use involves people taking
part in meetings, who often mention documents con-
taining facts that are relevant to the current discus-
sion, but cannot search for them without interrupt-
ing the discussion flow. Our goal is to perform such
searches automatically. In a second scenario, search
is performed for live or recorded lectures, for in-
stance in a computer-assisted learning environment.
The ACLD enriches the lectures with related course
material, receiving real-time feedback from the user.
The ACLD improves over past systems by using
speech, by giving access to multimedia documents,
and by using semantic search. Its first precursors
were the Fixit query-free search system (Hart and
Graham, 1997), the Remembrance Agent for just-
in-time retrieval (Rhodes and Maes, 2000), and the
Implicit Queries system (Dumais et al, 2004). A
version of the Remembrance Agent called Jimminy
was conceived as a wearable assistant for taking
notes, but ASR was only simulated (Rhodes, 1997).
Watson monitored the user?s operations in a text
editor, and selected terms for web search (Budzik
and Hammond, 2000). Another authoring assistant
was developed in the A-Propos project (Puerta Mel-
guizo and al., 2008). Recently, several speech-
based search engines have been proposed, as well as
systems for searching spoken documents. For hu-
man dialogues in meetings, the FAME interactive
space (Metze and al., 2006) provided multi-modal
access to recordings of lectures via a table top in-
terface, but required specific voice commands from
one user only, and did not spontaneously follow a
conversation as the ACLD does.
2 Description of the ACLD
The architecture of the ACLD comprises modules
for: (1) document preparation and indexing; (2) in-
put sensing and query construction; (3) search and
integration of results; (4) user interaction.
2.1 Document Preparation and Indexing
The preparation of the local database of documents
available for search requires text extraction from
various file formats (like MS Office or PDF), and
350
document indexing, here using Apache Lucene. Past
meetings, when available, are automatically tran-
scribed, then chunked into smaller units, and in-
dexed along with the other documents. For search-
ing the Web, the system does not build indexes but
uses the Google Search API.
2.2 Sensing the User?s Information Needs
The ACLD uses the AMI real-time ASR system for
English (Garner and al., 2009), which has an ac-
ceptable accuracy for use with conversational speech
in the ACLD. When processing past recordings, the
ASR system can run slower than real-time to maxi-
mize its accuracy. If one or more pre-specified key-
words (based on domain knowledge) are detected in
the ASR output, then their importance is increased
for searching. Otherwise, all the words from the
ASR (except stopwords) are used for constructing
the query.
2.3 Querying the Document Database
The Query Aggregator component uses the ASR
words in order to retrieve the most relevant docu-
ments from a given database. The latest version
of the ACLD makes use of semantic search (see
below), but earlier versions used keyword-based
search from Apache Lucene for local documents.
Queries are formulated and launched at regular time
intervals, typically every 15-30 seconds, or on de-
mand. The search results are integrated with previ-
ous ones, using a persistence model that smoothes
variations in time by keeping track of the salience of
each result. Salience is initialized from the ranking
of search results, then decreases in time, or increases
if the document appears again among results. A his-
tory of all results is also accessible.
2.4 Semantic Search over Wikipedia
The goal of semantic search is to improve the rel-
evance of results with respect to the spoken words,
and to make search more robust to noise from ASR.
The method used here is adapted from a graph-based
measure of semantic relatedness between text frag-
ments (Yazdani and Popescu-Belis, 2010). Related-
ness is computed using random walk in a large net-
work of documents, here about 1.2 milion Wikipedia
articles from the WEX data set (Metaweb Technolo-
gies, 2010). These are linked by directional hy-
Figure 1: Unobtrusive UI of the ACLD displaying docu-
ment results. The pop-up window shows more details for
the first results.
perlinks, and also by lexical similarity links that
we construct upon initialization. The random walk
model allows the computation of the visiting proba-
bility (VP) from one document to another, and then
of the VP between sets of documents. This functions
as a measure of semantic relatedness, and has been
applied to several NLP problems by projecting the
text fragments to be compared onto the documents
in the network (Yazdani and Popescu-Belis, 2010).
For the ACLD, the use of semantic relatedness for
document retrieval amounts to searching, in a very
large collection, the documents that are the most
closely related to the words obtained from the ASR
in a given time frame. Here, we set the document
collection to Wikipedia (WEX). As the search is
hard to perform in real time, we made a series of
justified approximations to make it tractable.
2.5 The User Interface
The goal of the UI is to make ACLD information
available in a configurable way, allowing users to
see more or less information according to their own
needs. The UI displays up to four widgets, which
can be arranged at will, and contain: (1) ASR words
with highlighted keywords; (2) tag-cloud of key-
words, coding for recency and frequency; (3) links
to the current results from the local repository; (4)
links to the current Web search results.
Two main arrangements are intended: an infor-
mative full-screen UI (not shown here from lack of
space) and an unobtrusive UI, with superposed tabs,
shown in Figure 1 with the document result widget.
When hovering over a document name, a pop-up
window displays metadata and document excerpts
that match words from the query, as an explanation
for why the document was retrieved.
351
3 Evaluation of the ACLD
Four types of evidence for the relevance and util-
ity of the ACLD are summarized here. Firstly, the
ACLD was demonstrated to about 50 potential users
(industrial partners, focus groups, etc.), who found
the concept useful, and offered positive verbal eval-
uation, along with suggestions for smaller and larger
improvements.
Secondly, a pilot experiment was conducted with
a group using an earlier version of the UI. Two pilot
runs have shown that the ACLD was consulted about
five times per meeting, but many more runs are (still)
needed for statistical significance of observations.
Thirdly, the UI was tested in a usability evaluation
experiment with nine non-technical subjects, who
rated it as ?acceptable? (68%) on the System Usabil-
ity Scale, following a series of tasks they had to per-
form using it. Additional suggestions for changes
were received.
Finally, we compared offline the results of seman-
tic search with the keyword-based ones. We asked
eight subjects to read a series of nine meeting frag-
ments, and to decide which of the two results was
the most useful one (they could also answer ?none?).
Of a total of 36 snippets, each seen by two subjects,
there was agreement on 23 (64%) snippets and dis-
agreement on 13 (36%). In fact, if ?none? is ex-
cluded, there were only 7 true disagreements. Over
the 23 snippets on which the subjects agreed, the
result of semantic search was judged more relevant
than that of keyword search for 19 (53% of the to-
tal), and the reverse for 4 only (11%). Alternatively,
if one counts the votes cast by subjects in favor of
each system, regardless of agreement, then semantic
search received 72% of the votes and keyword-based
only 28%. Hence, semantic search already outper-
forms keyword based one.
4 Conclusion
The ACLD is, to the best of our knowledge, the
first just-in-time retrieval system to use spontaneous
speech and to support access to multimedia doc-
uments and to websites, using a robust semantic
search method. Future work should aim at improv-
ing the relevance of semantic search, at modeling
context to improve the timing of results, and at in-
ferring relevance feedback from users. The ACLD
should also be applied to specific use cases, and an
experiment with group discussions in a learning en-
vironment is under way.
Acknowledgments
We are grateful to the EU AMI and AMIDA Inte-
grated Projects and to the Swiss IM2 NCCR (In-
teractive Multimodal Information Management) for
supporting the development of the ACLD.
References
Jay Budzik and Kristian J. Hammond. 2000. User inter-
actions with everyday applications as context for just-
in-time information access. In IUI 2000 (5th Interna-
tional Conference on Intelligent User Interfaces), New
Orleans, LA.
Susan Dumais, Edward Cutrell, Raman Sarin, and Eric
Horvitz. 2004. Implicit Queries (IQ) for contextual-
ized search. In SIGIR 2004 (27th Annual ACM SIGIR
Conference) Demonstrations, page 534, Sheffield.
Philip N. Garner and al. 2009. Real-time ASR from
meetings. In Interspeech 2009 (10th Annual Confer-
ence of the International Speech Communication As-
sociation), pages 2119?2122, Brighton.
Peter E. Hart and Jamey Graham. 1997. Query-free in-
formation retrieval. IEEE Expert: Intelligent Systems
and Their Applications, 12(5):32?37.
Metaweb Technologies. 2010. Freebase Wikipedia Ex-
traction (WEX). http://download.freebase.com/wex/.
Florian Metze and al. 2006. The ?Fame? interactive
space. In Machine Learning for Multimodal Interac-
tion II, LNCS 3869, pages 126?137. Springer, Berlin.
Maria Carmen Puerta Melguizo and al. 2008. A person-
alized recommender system for writing in the Internet
age. In LREC 2008 Workshop on NLP Resources, Al-
gorithms, and Tools for Authoring Aids, pages 21?26,
Marrakech.
Bradley J. Rhodes and Pattie Maes. 2000. Just-in-time
information retrieval agents. IBM Systems Journal,
39(3-4):685?704.
Bradley J. Rhodes. 1997. The Wearable Remembrance
Agent: A system for augmented memory. Personal
Technologies: Special Issue on Wearable Computing,
1:218?224.
Majid Yazdani and Andrei Popescu-Belis. 2010. A ran-
dom walk framework to compute textual semantic sim-
ilarity: a unified model for three benchmark tasks. In
ICSC 2010 (4th IEEE International Conference on Se-
mantic Computing), pages 424?429, Pittsburgh, PA.
352
Proceedings of the SIGDIAL 2014 Conference, pages 260?262,
Philadelphia, U.S.A., 18-20 June 2014. c?2014 Association for Computational Linguistics
The Parlance Mobile Application for Interactive Search in
English and Mandarin
Helen Hastie, Marie-Aude Aufaure?, Panos Alexopoulos,
Hugues Bouchard, Catherine Breslin, Heriberto Cuay?huitl, Nina Dethlefs,
Milica Ga?i?, James Henderson, Oliver Lemon, Xingkun Liu, Peter Mika, Nesrine Ben Mustapha,
Tim Potter, Verena Rieser, Blaise Thomson, Pirros Tsiakoulis, Yves Vanrompay,
Boris Villazon-Terrazas, Majid Yazdani, Steve Young and Yanchao Yu
email: h.hastie@hw.ac.uk. See http://parlance-project.eu for full list of affiliations
Abstract
We demonstrate a mobile application in
English and Mandarin to test and eval-
uate components of the Parlance di-
alogue system for interactive search un-
der real-world conditions.
1 Introduction
With the advent of evaluations ?in the wild?,
emphasis is being put on converting re-
search prototypes into mobile applications that
can be used for evaluation and data col-
lection by real users downloading the ap-
plication from the market place. This is
the motivation behind the work demonstrated
here where we present a modular framework
whereby research components from the Par-
lance project (Hastie et al., 2013) can be
plugged in, tested and evaluated in a mobile
environment.
The goal of Parlance is to perform inter-
active search through speech in multiple lan-
guages. The domain for the demonstration
system is interactive search for restaurants in
Cambridge, UK for Mandarin and San Fran-
cisco, USA for English. The scenario is that
Mandarin speaking tourists would be able to
download the application and use it to learn
about restaurants in English speaking towns
and cities.
2 System Architecture
Here, we adopt a client-server approach as il-
lustrated in Figure 1 for Mandarin and Figure
2 for English. The front end of the demon-
stration system is an Android application that
calls the Google Automatic Speech Recogni-
tion (ASR) API and sends the recognized user
utterance to a server running the Interaction
?Authors are in alphabetical order
Manager (IM), Spoken Language Understand-
ing (SLU) and Natural Language Generation
(NLG) components.
Figure 1: Overview of the Parlance Man-
darin mobile application system architecture
Figure 2: Overview of the Parlance En-
glish mobile application system architecture
extended to use the Yahoo API to populate
the application with additional restaurant in-
formation
When the user clicks the Start button, a di-
alogue session starts. The phone application
first connects to the Parlance server (via
the Java Socket Server) to get the initial sys-
tem greeting which it speaks via the Google
260
Text-To-Speech (TTS) API. After the system
utterance finishes the recognizer starts to lis-
ten for user input to send to the SLU compo-
nent. The SLU converts text into a semantic
interpretation consisting of a set of triples of
communicative function, attribute, and (op-
tionally) value1. Probabilities can be associ-
ated with candidate interpretations to reflect
uncertainty in either the ASR or SLU. The
SLU then passes the semantic interpretation
to the IM within the same server.
Chinese sentences are composed of strings of
characters without any space to mark words as
other languages do, for example:
In order to correctly parse and understand
Chinese sentences, Chinese word segmenta-
tions must be performed. To do this segmen-
tation, we use the Stanford Chinese word seg-
mentor2, which relies on a linear-chain condi-
tional random field (CRF) model and treats
word segmentation as a binary decision task.
The Java Socket Server then sends the seg-
mented Chinese sentence to the SLU on the
server.
The IM then selects a dialogue act, accesses
the database and in the case of English passes
back the list of restaurant identification num-
bers (ids) associated with the relevant restau-
rants. For the English demonstration system,
these restaurants are displayed on the smart
phone as seen in Figures 4 and 5. Finally,
the NLG component decides how best to re-
alise the restaurant descriptions and sends the
string back to the phone application for the
TTS to realise. The example output is illus-
trated in Figure 3 for Mandarin and Figure 4
for English.
As discussed above, the Parlance mobile
application can be used as a test-bed for com-
paring alternative techniques for various com-
ponents. Here we discuss two such compo-
nents: IM and NLG.
1This has been implemented for English; Mandarin
uses the rule-based Phoenix parser.
2http://nlp.stanford.edu/projects/chinese-
nlp.shtml
Figure 3: Screenshot and translation of the
Mandarin system
Figure 4: Screenshot of dialogue and the list
of recommended restaurants shown on a map
and in a list for English
2.1 Interaction Management
The Parlance Interaction Manager is based
on the partially observable Markov decision
process (POMDP) framework, where the sys-
tem?s decisions can be optimised via reinforce-
ment learning. The model adopted for Par-
lance is the Bayesian Update of Dialogue
State (BUDS) manager (Thomson and Young,
2010). This POMDP-based IM factors the di-
alogue state into conditionally dependent ele-
ments. Dependencies between these elements
can be derived directly from the dialogue on-
tology. These elements are arranged into a dy-
namic Bayesian network which allows for their
marginal probabilities to be updated during
the dialogue, comprising the belief state. The
belief state is then mapped into a smaller-scale
summary space and the decisions are optimised
using the natural actor critic algorithm. In the
Parlance application, hand-crafted policies
261
Figure 5: Screenshot of the recommended
restaurant for the English application
can be compared to learned ones.
2.2 Natural Language Generation
As mentioned above, the server returns the
string to be synthesised by the Google TTS
API. This mobile framework allows for testing
of alternative approaches to NLG. In particu-
lar, we are interested in comparing a surface re-
aliser that uses CRFs against a template-based
baseline. The CRFs take semantically anno-
tated phrase structure trees as input, which it
uses to keep track of rich linguistic contexts.
Our approach has been compared with a num-
ber of competitive state-of-the art surface real-
izers (Dethlefs et al., 2013), and can be trained
from example sentences with annotations of se-
mantic slots.
2.3 Local Search and Knowledge Base
For the English system, the domain database is
populated by the search Yahoo API (Bouchard
and Mika, 2013) with restaurants in San Fran-
sisco. These restaurant search results are
returned based on their longitude and lati-
tude within San Francisco for 5 main areas, 3
price categories and 52 cuisine types contain-
ing around 1,600 individual restaurants.
The Chinese database has been partially
translated from an English database for restau-
rants in Cambridge, UK and search is based
on 3 price categories, 5 areas and 35 cuisine
types having a total of 157 restaurants. Due
to the language-agnostic nature of the Par-
lance system, only the name and address
fields needed to be translated.
3 Future Work
Investigating application side audio compres-
sion and audio streaming over a mobile in-
ternet connection would enable further assess-
ment of the ASR and TTS components used
in the original Parlance system (Hastie et
al., 2013). This would allow for entire research
systems to be plugged directly into the mobile
interface without the use of third party ASR
and TTS.
Future work also involves developing a feed-
back mechanism for evaluation purposes that
does not put undue effort on the user and put
them off using the application. In addition,
this framework can be extended to leverage
hyperlocal and social information of the user
when displaying items of interest.
Acknowledgements
The research leading to this work was funded
by the EC FP7 programme FP7/2011-14
under grant agreement no. 287615 (PAR-
LANCE).
References
H. Bouchard and P. Mika. 2013. Interactive hy-
perlocal search API. Technical report, Yahoo
Iberia, August.
N. Dethlefs, H. Hastie, H. Cuay?huitl, and
O. Lemon. 2013. Conditional Random Fields
for Responsive Surface Realisation Using Global
Features. In Proceedings of the 51st Annual
Meeting of the Association for Computational
Linguistics (ACL), Sofia, Bulgaria.
H. Hastie, M.A. Aufaure, P. Alexopoulos,
H. Cuay?huitl, N. Dethlefs, M. Gasic,
J. Henderson, O. Lemon, X. Liu, P. Mika,
N. Ben Mustapha, V. Rieser, B. Thomson,
P. Tsiakoulis, Y. Vanrompay, B. Villazon-
Terrazas, and S. Young. 2013. Demonstration
of the PARLANCE system: a data-driven
incremental, spoken dialogue system for in-
teractive search. In Proceedings of the 14th
Annual Meeting of the Special Interest Group
on Discourse and Dialogue (SIGDIAL), Metz,
France, August.
B. Thomson and S. Young. 2010. Bayesian up-
date of dialogue state: A POMDP framework
for spoken dialogue systems. Computer Speech
and Language, 24(4):562?588.
262
