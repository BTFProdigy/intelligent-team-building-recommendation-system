Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 67?72,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
PAL: A Chatterbot System for Answering Domain-specific Questions 
Yuanchao Liu1 Ming Liu1 Xiaolong Wang1 Limin Wang2 Jingjing Li1 
 
1 School of Computer Science and Technology, Harbin Institute of Technology, 
Harbin, China 
2. School of public health, Harbin Medical University, Harbin, China 
{lyc,mliu,wangxl,jjl}@insun.hit.edu.cn, wanglimin2008@163.com 
 
Abstract 
In this paper, we propose PAL, a prototype 
chatterbot for answering non-obstructive 
psychological domain-specific questions. This 
system focuses on providing primary 
suggestions or helping people relieve pressure 
by extracting knowledge from online forums, 
based on which the chatterbot system is 
constructed. The strategies used by PAL, 
including semantic-extension-based question 
matching, solution management with personal 
information consideration, and XML-based 
knowledge pattern construction, are described 
and discussed. We also conduct a primary test 
for the feasibility of our system. 
1 Introduction 
A wide variety of chatterbots and 
question-and-answer (Q&A) systems have been 
proposed over the past decades, each with 
strengths that make them appropriate for 
particular applications. With numerous advances 
in information construction, people increasingly 
aim to communicate with computers using natural 
language. For example, chatterbots in some 
e-commerce Web sites can interact with 
customers and provide help similar to a real-life 
secretary (DeeAnna Merz Nagel, 2011; Yvette 
Col?n, 2011). 
  In this paper, we propose PAL (Psychologist of 
Artificial Language), a chatterbot system for 
answering non-obstructive psychological 
questions. Non-obstructive questions refer to 
problems on family, human relationships, 
marriage, life pressure, learning, work and so on. 
In these cases, we expect the chatterbot to play an 
active role by providing tutoring, solution, 
support, advice, or even sympathy depending on 
the help needed by its users.  
  The difference of PAL from existing 
chatterbots lies not only in the specific research 
focus of this paper but also in the strategies we 
designed, such as P-XML templates for storing a 
knowledge base, comprehensive question 
matching method by considering both index and 
semantic similarities, and solution management 
by considering personal information. In the 
following sections, we will briefly discuss related 
work and then introduce our system and its main 
features. 
2 Related Work 
A number of research work on chatterbots 
(Rafael E. Banchs, Haizhou Li, 2012; Ai Ti Aw 
and Lian Hau Lee, 2012), Q&A systems (Shilin 
Ding, Gao Cong, Chin-Yew Lin, 2008; Leila 
Kosseim, 2008; Tiphaine Dalmas, 2007), and 
related natural language understanding 
technologies have recently been conducted 
(Walid S. Saba, 2007; Jing dong, 2009). Several 
studies on the application of natural language 
processing technologies for non-obstructive 
psychological Q&A systems have also been 
published (Hai-hu Shi, 2005).  
Several online psychology counselling Web 
sites with service provided by human experts have 
also been established recently (DeeAnna Merz 
Nagel, 2011; Yvette Col?n, 2011). For these Web 
sites, when the visitors ask similar questions, the 
expert may provide the same or very similar 
answers repeatedly. Based on this observation and 
consideration, we collected a large number of 
counselling Q&A pairs to extract common 
knowledge for the construction of a chatterbot 
system. Advances in automatic language analysis 
and processing are used as the bases for the 
emergence of a complex, task-oriented chatterbot 
system. 
67
3 Basic Framework of PAL 
A running screenshot of PAL is shown in Figure 
1, and its basic system structure is demonstrated 
in Figure 2. As shown in Figure 2, the basic 
principles of PAL are as follows: 
1) All interactions between system and users are 
scheduled by control logic; 
2) When the user inputs a question, the system 
will search through its knowledge base for 
the matching entry, and then 
3) The system will respond with an appropriate 
answer by analysing both the matched entry 
and the dialogue history. 
Figure 1. Running Screenshot of PAL 
 
Lexicon analysis
 &extracting 
features
Knowledge
 base
Dialog control 
logic
XML knowledge Engine
(Running in background)
User
Index 
generation
Semantic 
extension
Keyword 
extraction
Response
Question
Answer 
generation
Crawing Q&A pairs 
from on-line forums
 
Solution 
management
Dialog history 
analysis
 Figure 2. Basic Framework of PAL 
4 Conversation Control Strategy of PAL 
The Q&A process of the PAL system is 
coordinated by control logic to communicate with 
users effectively. The basic control logic strategy 
is shown in Figure 3.  
  
Figure 3. Basic Control Logic of PAL 
68
As shown in Figure 3, the initial state is set to 
welcome mode, and the system can select a 
sentence from the ?sign on? list, which will then 
provide a response. When users enter a question, 
the system will conduct the necessary analysis. 
The system?s knowledge base is indexed by 
Clucene1 beforehand. Thus, the knowledge index 
will be used to search the matched records quickly. 
If the system can find the matched patterns 
directly and the answer is suitable for the current 
user, one answer will be randomly selected to 
generate the response. Historical information and 
personal information will be analysed when 
necessary. We mainly adopted the method of 
ELIZA2
5 Knowledge Construction and 
Question Matching Method 
, which is an open-source program, to 
consider the historical information. A ?not found? 
response list is also set to deal with situations 
when no suitable answers can be identified. Both 
system utterance and user input will be pushed 
into the stack as historical information. Given that 
user questions are at times very simple, the 
combination with historical input may also be 
required to determine its meaning. This step can 
also avoid the duplication of utterances. 
We design P-XML to store the knowledge base 
for PAL, as shown in Figure 4. The knowledge 
base for PAL is mainly derived from the Q&A 
pairs in the BAIDU ZHIDAO community3
<?xml version="1.0" encoding="GB2312"?> 
. One 
question usually has many corresponding 
answers. 
<domain name="*"> <qapair speaker="*">        
<zhidao_question_title>*</zhidao_question_t
itle> 
<zhidao_question_content>*</zhidao_question
_content><zhidao_other_answer 
intersection_number="4">* 
<entity_and_problemword>*</entity_and_probl
emword> <peopleword>*</peopleword>          
</zhidao_other_answer>    
<title_extension>*</title_extension>   
</qapair> 
? 
</domain> 
Figure 4. The Structure of P-XML 
                                                          
1 http://sourceforge.net/projects/clucene/ 
2 http://www.codeforge.cn/article/191554 
3 http://Zhidao.baidu.com 
 
An effective method of capturing the user?s 
meaning accurately is to create an extension for 
questions in the knowledge base. In this paper, the 
extension is primarily a synonym expansion of the 
keywords of questions, with CILIN (Wanxiang 
Che, 2010) as extension knowledge source.  
The questions are indexed by Clucene to 
improve the retrieval efficiency of the search for a 
matched entry in the knowledge base. During the 
knowledge base searching step, both the index of 
the original form and the extension form of the 
problem are used to find the most possible 
matched record for the user?s question, as shown 
in algorithm 1. Algorithm 1 is used to examine the 
similarity between user input and the record 
returned by Clucene, including traditional and 
extension similarities.   
Algorithm 1. Problem-matching method 
Begin  
1) User inputs question Q; 
2) Search from the index of original questions and 
obtain the returned record set RS1; 
3) For the highest ranked record R1 in RS1, 
a) compute the similarity sim1 between 
question R1 and Q; 
b) compute the extension similarity sim2 
between the question extensions of R1 and 
Q;  
4) If sim1 is greater than the threshold value T1 or 
sim2 is greater than the threshold value T2, go to 
the solution management stage and obtain the 
answers of R1, and then find the candidate 
answer using algorithm 2; 
5) Otherwise, a ?not found? prompt is given.  
End 
6 Response Management Method 
 One question usually has many corresponding 
answers in the knowledge base, and these 
answers differ in explanation quality. Thus, the 
basic strategy employed by solution management 
is to select a reliable answer from the matched 
record as response, as shown in algorithm 2. 
Personalised information includes name entity, 
gender, marital status and age information. PAL 
maintains some heuristics rules to help recognize 
such information. Based on these rules, if one 
answer contains personal information, it will be 
selected as the candidate answer only when the 
personal information is consistent with that of the 
current user. Very concise answers that do not 
69
contain personal information can generally be 
selected as a candidate answer. 
 
Algorithm 2.  Answer-selection method 
Begin 
1) User inputs one question Q; 
2) The system extracts the speaker role S and 
personal information from Q; 
3) Use Q as query to conduct information retrieval 
from the index and knowledge base and obtain 
the top matched record set R; 
4) For each matched question Q? in R, test the 
following conditions: 
a) (condition 1) extract the speaker role S? 
in Q?, and examine if S? is equal to S; 
b) (condition 2) extract personal 
information in Q?, and examine if they 
are equal to that of in Q? 
c) For each answer A? of Q? 
i. If no personal information is found 
in A?, A? will be pushed into 
response list; 
ii. If personal information is contained 
in A? and if both conditions 1 and 2 
are true, A? will be pushed into 
response list; 
d) End for 
5) End for 
End 
7 Experiments 
For the current implementation of PAL, the size of 
the knowledge base is approximately 1.2G and 
contains six different topics: ?Husband and 
wife?, ?Family relations?, ?Love affairs?, 
?Adolescence?, ?Feeling and Mood?, and 
?Mental tutors?. Dialogue data collection used in 
PAL is mainly crawled from 
http://zhidao.baidu.com, which is one of the 
largest Chinese online communities. The 
criterion for choosing these six categories is also 
because they are the main topics in BAIDU 
communities about psychological problems. 
Some information on the knowledge base is 
given in Table 1, in which ?Percent of questions 
matched? denotes the number of similar 
questions found when 100 open questions are 
input (we suppose that if the similarity threshold 
is bigger than 0.5, then a similar question will be 
deemed as ?hit? in the knowledge base). 
In 7.1, we examine the feasibility of using 
downloaded dialogue collection for constructing 
the knowledge base. Some dialogue examples are 
given in 7.2.  
 
Domain Avg. ques. 
 length 
Num. of unique 
 Terms in ques. 
Avg. ans. 
 length 
Num. of unique 
terms in ans. 
Percent of questions 
matched (similarity threshold: 0.5) 
Size(MB) 
QS1 58.69 11571 64.13 27312 25 125 
QS2 54.96 10918 64.92 25185 24 292 
QS3 59.66 13530 49.52 13664 15 53 
QS4 42.41 8607 47.11 23492 22 224 
QS5 63.57 11915 48.86 26860 26 276 
QS6 31.82 10009 98.55 20896 25 216 
Table 1. Information of the knowledge base 
 
7.1 System Performance Evaluation 
Additional questions and their corresponding 
answers beyond the knowledge base are also used 
as a test set to evaluate system performance. 
Concretely, suppose question Q has |A| answers in 
the test set. Q is then input into the system. 
Suppose the system output is O, we examine if 
one best answer exists among |A| answers that are 
very similar to O (the similarity is greater than 
threshold T3). If yes, we then assume that one 
suitable answer has been found. In this way, 
precision can be calculated as the number of 
questions that have very similar answers in the 
system divided by the number of all input 
questions.  
The performance evaluation results are shown 
in Figure 5. The horizon axis denotes the 
similarity threshold (T1 for sim1 and T2 for sim2) 
between a user?s input and the questions in the 
knowledge base. Sim1 is the original similarity, 
whereas sim2 is the semantic extension similarity. 
Different thresholds were used (0.5 to 0.9). The 
similarity threshold T3 denotes the similarity 
70
between the answer in the test set and system 
output O. From Figures 5 (A) and (B), different 
T3 values were used (0.5 to 0.8).  
Some observations can be made from Figure 5. 
The average system precision is approximately 
0.5, and the range is from 0.2 to 0.9. Basically, 
when T3 is bigger, the system?s performance 
tends to decrease because a high T3 value denotes 
a strict evaluation standard. Performance also 
differs between different areas, such that D4, D5 
and D6 outperform than D1, D2 and D3.  
When only index is used and both sim1 and 
sim2 are below the corresponding threshold T1 or 
T2, the system can still return record set RS2, but 
the returned answer may be inconsistent with 
user?s question. Thus, incorporating semantic 
search shown in algorithm 1 is necessary. 
  
  
?A?(Sim. Thres. T3=0.5) ?B?(Sim. Thres. T3=0.6) 
  
(C) (Sim. Thres. T3=0.7) (D) (Sim. Thres. T3=0.8) 
Figure 5. Precision of PAL with different similarity thresholds T3 (The X axis denotes different thresholds 
for sim1 (T1) and sim2 (T2). For example, 0.5(sim1) indicates that the threshold for sim1 is 0.5, whereas 
0.5(sim2) suggests that the threshold for sim2 is 0.5. The Y axis stands for the precision value of different 
T1, T2 and T3 values for different areas). 
7.2?Some Interaction Examples 
Table 2 provides an interaction example of PAL in 
English. As users input their questions, the system 
can output the corresponding responses. The entire 
dialogue history can also be displayed. Basically, 
when users describe their troubles, PAL can 
provide some explanation or even try to console the 
user.  
Compared to other chatterbots like Eliza, PAL 
is domain-specific and may provide help to some 
extent. Many different answers can usually be 
identified. Thus, the user could input the same 
question many times, with the system providing 
suggestions from different angles. PAL can also 
output voice by using Xiao-kun and Microsoft 
Anna as the text-to-speech (TTS) engine. The 
speed, volume and echo properties of the voice can 
be adjusted.  
 
Dialog for Figure 1 (in English) 
PAL> Hello, you are welcome to communicate with 
me! You can input from the left side and press enter to 
get answer! 
I> How do I deal with the children who like to 
complain very frequently?  
PAL>Very simple. Don't? let him experience the 
benefits of complaining very frequently. 
I> Why do parents give children so much pressure  
PAL> Children have pressure indeed; but parents also 
have a lot of pressure.  
I> Why am I unable to control my emotions, and often 
quarrel with my parents?  
PAL.> Now you may be in the stage of treason. And 
have your own uncertain plan for the future, want to be 
yourself, and do not want to be disturbed. So when 
parents criticize, you will be unhappy. 
I> How to solve the gap problem?  
PAL.> Communication, and listening . 
Table 2. Example of an interaction with PAL (in English) 
 
71
8 Conclusions 
In this paper, we introduce a simple chatterbot for 
answering non-obstructive psychological 
questions. The knowledge behind the chatterbot is 
learned from the Q&A pairs derived from an 
online forum using several extraction strategies. 
The historical and personal information from the 
dialogues are also incorporated to output an 
appropriate answer. 
For future work, we expect to add more features 
to PAL, e.g., enabling the system to ask questions 
actively and further improving P-XML to form 
richer patterns for storing Q&A knowledge. 
Another interesting aspect would be to add speech 
input as well as TTS and to transform PAL into a 
mobile platform for widespread use.  
Acknowledgments 
This research was supported by the project of The 
National High Technology Research and 
Development Program (863 program) of PR China 
under a research Grant No.2007AA01Z172?
Youth Funds of China social & humanity science 
(10YJCZH099), and Key Laboratory Opening 
Funding of China MOE?MS Key Laboratory of 
Natural Language Processing and Speech 
(HIT.KLOF.2009022). 
References  
Ai Ti Aw and Lian Hau Lee. Personalized 
Normalization for a Multilingual Chat System. 
Proceedings of the 50th Annual Meeting of the 
Association for Computational Linguistics, Jeju, 
Republic of Korea, 8-14 July 2012, pages 31?36, 
DeeAnna Merz Nagel, Kate Anthony. Text-based 
Online Counseling Chat. Online Counseling 
(Second Edition), 2011, Pages 169-182 
Hai-hu Shi, Yan Feng, LI Dong-mei, HU Ying-fei. 
Research on on-line psychology consultation expert 
system based on man-machine interaction technique. 
Computer Engineering and Design. 2005, 
26(12):3307-3309 
Jing dong. Research of sentiment model based on 
HMM and its application in psychological 
consulting expert system. Master?s thesis. Capital 
normal university (china), 2009. 
Leila Kosseim, Jamileh Yousefi. Improving the 
performance of question answering with 
semantically equivalent answer patterns. Data & 
Knowledge Engineering, 2008, 66(1):53-67 
Rafael E. Banchs, Haizhou Li. IRIS: a Chat-oriented 
Dialogue System based on the Vector Space Model. 
Proceedings of the 50th Annual Meeting of the 
Association for Computational Linguistics, Jeju, 
Republic of Korea, 8-14 July 2012. pages 37?42 
Shilin Ding, Gao Cong, Chin-Yew Lin, Xiaoyan Zhu. 
Using Conditional Random Fields to Extract 
Contexts and Answers of Questions from Online 
Forums. Proceedings of 2008 Association for 
Computational Linguistics, Columbus, Ohio, 
USA, June 2008. pages 710?718 
Tiphaine Dalmas, Bonnie Webber. Answer comparison 
in automated question answering. Journal of 
Applied Logic, Volume 5, Issue 1, March 2007, 
Pages 104-120 
Walid S. Saba. Language, logic and ontology: 
Uncovering the structure of commonsense 
knowledge. International Journal of 
Human-Computer Studies, Volume 65, Issue 7, 
July 2007, Pages 610-623 
Wanxiang Che, Zhenghua Li, Ting Liu. LTP: A 
Chinese Language Technology Platform. In 
Proceedings of the Coling 
2010:Demonstrations. August 2010, pp13-16, 
Beijing, China. 
Yvette Col?n, Stephanie Stern. Counseling Groups 
Online: Theory and Framework. Online 
Counseling (Second Edition), 2011, Pages 
183-202. 
 
 
72
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 25?30,
Baltimore, Maryland USA, June 23-24, 2014. c?2014 Association for Computational Linguistics
WINGS: Writing with Intelligent Guidance and Suggestions 
 
Xianjun Dai, Yuanchao Liu*, Xiaolong Wang, Bingquan Liu 
School of Computer Science and Technology 
Harbin Institute of Technology, China 
{xjdai, lyc, wangxl, liubq}@insun.hit.edu.cn 
 
 
 
Abstract 
Without inspirations, writing may be a 
frustrating task for most people. In this study, 
we designed and implemented WINGS, a 
Chinese input method extended on 
IBus-Pinyin with intelligent writing assistance. 
In addition to supporting common Chinese 
input, WINGS mainly attempts to spark users? 
inspirations by recommending both word 
level and sentence level writing suggestions. 
The main strategies used by WINGS, 
including providing syntactically and 
semantically related words based on word 
vector representation and recommending 
contextually related sentences based on LDA, 
are discussed and described. Experimental 
results suggest that WINGS can facilitate 
Chinese writing in an effective and creative 
manner. 
1 Introduction 
Writing articles may be a challenging task, as we 
usually have trouble in finding the suitable words 
or suffer from lack of ideas. Thus it may be very 
helpful if some writing reference information, 
e.g., words or sentences, can be recommended 
while we are composing an article. 
On the one hand, for non-english users, e.g., 
Chinese, the Chinese input method is our first 
tool for interacting with a computer. Nowadays, 
the most popular Chinese input methods are 
Pinyin-based ones, such as Sougou Pinyin1 and 
Google Pinyin 2 . These systems only present 
accurate results of Pinyin-to-Character 
conversion. Considering these systems? lack of 
suggestions for related words, they hardly 
provide writers with substantial help in writing. 
On the other hand, try to meet the need of writing 
assistance, more and more systems facilitating 
Chinese writing have been available to the public, 
                                                          
* Corresponding author 
1 http://pinyin.sogou.com 
2 http://www.google.com/intl/zh-CN/ime/pinyin 
such as WenXin Super Writing Assistant3 and 
BigWriter4, and among others. However, due to 
their shortcomings of building examples library 
manually and lack of corpus mining techniques, 
most of the time the suggestions made by these 
systems are not creative or contextual. 
  Thus, in this paper, we present Writing with 
INtelligent Guidance and Suggestions (WINGS)5, 
a Chinese input method extended with intelligent 
writing assistance. Through WINGS, users can 
receive intelligent, real-time writing suggestions, 
including both word level and sentence level. 
Different from existing Chinese writing assistants, 
WINGS mainly attempts to spark users? writing 
inspirations from two aspects: providing diverse 
related words to expand users? minds and 
recommending contextual sentences according to 
their writing intentions. Based on corpus mining 
with Natural Language Processing techniques, 
e.g., word vector representation and LDA model, 
WINGS aims to facilitate Chinese writing in an 
effective and creative manner. 
  For example, when using WINGS to type 
?xuxurusheng?, a sequence of Chinese Pinyin 
characters for ?????? (vivid/vividly), the 
Pinyin-to-Character Module will generate ???
??? and some other candidate Chinese words. 
Then the Words Recommending Module 
generates word recommendations for ????
? ?. The recommended words are obtained 
through calculating word similarities based on 
word vector representations as well as rule-based 
strategy (POS patterns). 
In the Sentences Recommending Module, we 
first use ????? ? to retrieve example 
sentences from sentences library. Then the topic 
similarities between the local context and the 
candidate sentences are evaluated for contextual 
                                                          
3 http://www.xiesky.com 
4 http://www.zidongxiezuo.com/bigwriter_intro.php 
5 The DEB package for Ubuntu 64 and recorded video of 
our system demonstration can be accessed at this URL: 
http://yunpan.cn/Qp4gM3HW446Rx (password:63b3) 
25
Chinese Pinyin Sequence
Recommended Words
Recommended Sentences
Pinyin-to-Character results (Original Words)
 
Figure 1. Screenshot of WINGS.  
 
sentence recommendations. 
At last in consideration of users? feedback, we 
introduce a User Feedback Module to our system. 
The recorded feedback data will in turn influence 
the scores of words and sentences in 
Recommending Modules above. 
Figure 1 shows a screenshot of WINGS. 
2 Related Work 
2.1 Input Method 
Chinese input method is one of the most 
important tools for Chinese PC users. Nowadays, 
Pinyin-based input method is the most popular 
one. The main strategy that Pinyin-based input 
method uses is automatically converting Pinyin 
to Chinese characters (Chen and Lee, 2000).  
In recent years, more and more intelligent 
strategies have been adopted by different input 
methods, such as Triivi 6 , an English input 
method that attempts to increase writing speed 
by suggesting words and phrases, and PRIME 
(Komatsu et al., 2005), an English/Japanese 
input system that utilizes visited documents to 
predict the user?s next word to be input. 
In our system the basic process was Pinyin ? 
Characters (words) ? Writing Suggestions 
(including words and sentences). We mainly 
focused on writing suggestions from Characters 
(words) in this paper. As the Pinyin-to-Character 
was the underlining work, we developed our 
system directly on the open source framework of 
the IBus (an intelligent input Bus for Linux and 
Unix OS) and IBus-Pinyin7 input method. 
2.2 Writing Assistant 
As previously mentioned, several systems are 
available in supporting Chinese writing, such as 
WenXin Super Writing Assistant and Big Writer. 
                                                          
6 http://baike.baidu.com/view/4849876.htm 
7 https://code.google.com/p/ibus 
These systems are examples of a retrieval-based 
writing assistant, which is primarily based on a 
large examples library and provides users with a 
search function. 
In contrast, other writing assistants employ 
special NLP strategies. Liu et al. (2011, 2012) 
proposed two computer writing assistants: one 
for writing love letters and the other for blog 
writing. In these two systems, some special 
techniques were used, including text generation, 
synonym substitution, and concept expansion. 
PENS (Liu et al., 2000) and FLOW (Chen et al., 
2012) are two writing assistants designed for 
students of English as a Foreign Language (EFL) 
practicing writing, which are mainly based on 
Statistical Machine Translation (SMT) strategies. 
Compared with the above mentioned systems, 
WINGS is closer to retrieval-based writing 
assistants in terms of function. However, WINGS 
can provide more intelligent suggestions because 
of the introduction of NLP techniques, e.g., word 
vector representation and topic model. 
2.3 Word Representations in Vector Space 
Recently, Mikolov et al. (2013) proposed novel 
model architectures to compute continuous 
vector representations of words obtained from 
very large data sets. The quality of these 
representations was assessed through a word 
similarity task, and according to their report, the 
word vectors provided state-of-the-art 
performance for measuring syntactic and 
semantic word similarities in their test set. Their 
research produced the open source tool 
word2vec8. 
In our system, we used word2vec to train the 
word vectors from a corpus we processed 
beforehand. For the Words Recommending 
Module, these vectors were used to determine the 
similarity among different words. 
                                                          
8 https://code.google.com/p/word2vec 
26
2.4 Latent Dirichlet Allocation 
The topic model Latent Dirichlet Allocation 
(LDA) is a generative probabilistic model of a 
corpus. In this model, documents are represented 
as random mixtures of latent topics, where each 
topic is characterized by the distribution of 
words (Blei et al., 2003). Each document can 
thus be represented as a distribution of topics. 
Gibbs Sampling is a popular and efficient 
strategy used for LDA parameter estimation and 
inference. This technique is used in 
implementing several open sourcing LDA tools, 
such as GibbsLDA++9 (Phan and Nguyen, 2007), 
which was used in this paper. 
In order to generate contextual sentence 
suggestions, we ensured that the sentences 
recommended to the user were topic related to 
the local context (5-10 words previously input) 
based on the LDA model.  
3 Overview of WINGS 
Figure 2 illustrates the overall architecture of 
WINGS.  
Start
Pinyin to Character
Convert pinyin to Chinese words 
(Original words)
Words Recommending 1
1. Calculate similarity between focused 
original word and the rest words in the 
dictionary
2. Get top 200 most similar words as 
the candidate words
Words and word 
vectors
Sentences 
index
Sentences Recommending 1
Use the focused original or 
recommended word to retrieve at most  
200 sentences by Clucene from 
sentences index.
S ntenc s and 
their 
topic vector 
Sentences Recommending 2
1. Infer the topic vector of the local 
context by Gibbs Sammpling. Calculate 
the KL divergence between the local 
context and candidate sentences.
2. The sentence has been used before 
will get a boost in score.
1. Select word or sentence as input
2. Save feedback(User Feedback)
LDA train result 
for inference
Input Pinyin
Pinyin-Character 
mapping data,etc.
Words and 
s ntences 
selected info
YES
End
Continue
NO
Words Recommending 2
1.Boost in score: 1).Whether the 
original and recommended word 
match one of the specified patterns, 
such as A-N, V-N and etc. 2). Whether 
The word has been used before
2. Re-rank candidate words.
 
Figure 2. Overall architecture of WINGS. 
3.1 System Architecture 
Our system is composed of four different 
                                                          
9 http://gibbslda.sourceforge.net 
modules: Pinyin-to-Character Module, Words 
Recommending Module, Sentences 
Recommending Module, and User Feedback 
Module. The following sub-sections discuss 
these modules in detail. 
3.2 Pinyin-to-Character Module 
Our system is based on the open sourcing input 
framework IBus and extended on the 
IBus-Pinyin input method. Thus, the 
Pinyin-to-Character module is adopted from the 
original IBus-Pinyin system. This module 
converts the input Chinese Pinyin sequence into 
a list of candidate Chinese words, which we refer 
to as original words. 
3.3 Words Recommending Module 
? Words vector representations 
In this preparatory step for word 
recommendation, words vector representations 
are obtained using the word2vec tool. This will 
be described in detail in Section 4. 
? Obtain the most related words 
Our system will obtain the focused original 
word and calculate the cosine similarities 
between this word and the rest of the words in 
the dictionary. Thus, we can obtain the top 200 
most similar words according to their cosine 
values. These words are referred to as 
recommended words. According to Mikolov et 
al. (2013), these words are syntactically and 
semantically similar to the original word. 
? Re-rank the recommended words 
In order to further improve word recommending, 
we introduce several special POS patterns (Table 
1). If the POS of the original word and the 
recommended word satisfy one of the POS 
patterns we specified, the score (based on the 
cosine similarity) of the recommended word will 
be boosted. In addition, the score of the word 
selected by the user before will also be boosted. 
Therefore, these words will be ranked higher in 
the recommended words list. 
POS of  
original word 
POS of  
recommended word 
N (noun) A (adjective) 
A (adjective) N (noun) 
N (noun) V (verb) 
Any POS Same with the original word 
Any POS L (idiom) 
Table 1. Special POS patterns. 
3.4 Sentences Recommending Module 
? Sentences topic distribution 
In this preparatory step for sentence 
27
recommendation, sentences topic distribution 
vectors and other parameters are trained using 
the GibbsLDA++. This step will be discussed in 
Section 4. 
? Retrieve relative sentences via CLucene 
The focused original or recommended word will 
be used to search the most related sentences in 
the sentences index via CLucene10. At most 200 
sentences will be taken as candidates, which will 
be called recommended sentences. 
? Re-rank the recommended sentences 
To ensure that the recommended sentences are 
topic related to our local input context (5-10 
words previously input), we use Gibbs Sampling 
to infer the topic vector of the local context, and 
calculate the KL divergence between the local 
context and each recommended sentence. Finally, 
the recommended sentences will be re-ranked 
based on their KL divergences value with respect 
to the local context and the boost score derived 
from the feedback information. 
3.5 User Feedback Module 
This module saves the users? feedback 
information, particularly the number of times 
when users select the recommended words and 
sentences. This information will be used as a 
boost factor for the Words and Sentences 
Recommending Modules. Our reasons for 
introducing this module are two-fold: the users? 
feedback reflects their preference, and at the 
same time, this information can somewhat 
indicate the quality of the words and sentences. 
4 Data Pre-processing 
In this section, the procedure of our data 
pre-processing is discussed in detail. Firstly, our 
raw corpus was crawled from DiYiFanWen11, a 
Chinese writing website that includes all types of 
writing materials. After extracting useful 
composition examples from each raw html file, 
we merged all articles into a single file named 
large corpus. Finally, a total of 324,302 articles 
were merged into the large corpus (with a total 
size of 320 MB). 
For words recommending, each of the articles 
in our large corpus was segmented into words by 
ICTCLAS 12  with POS tags. Subsequently, 
word2vec tool was used on the words sequence 
(with useless symbols filtered). Finally, the 
words, their respective vector representations and 
                                                          
10 http://sourceforge.net/projects/clucene 
11 http://www.diyifanwen.com 
12 http://ictclas.nlpir.org 
main POS tags were combined, and we built 
these data into one binary file. 
For sentences recommending, the large corpus 
was segmented into sentences based on special 
punctuations. Sentences that were either too long 
or too short were discarded. Finally, 2,567,948 
sentences were left, which we called original 
sentences. An index was created on these 
sentences using CLucene. Moreover, we 
segmented these original sentences and filtered 
the punctuations and stop words. Accordingly, 
these new sentences were named segmented 
sentences. We then ran GibbsLDA++ on the 
segmented sentences, and the Gibbs sampling 
result and topic vector of each sentence were 
thus obtained. Finally, we built the original 
sentence and their topic vectors into a binary file. 
The Gibbs sampling data used for inference was 
likewise saved into a binary file. 
  Table 2 lists all information on the resources 
of WINGS.  
Items Information 
Articles corpus size 320 MB 
Articles total count 324,302 
Words total count 101,188 
Sentences total count 2,567,948 
Table 2. Resources information. 
5 Experimental Results 
This section discusses the experimental results of 
WINGS. 
5.1 Words Recommending 
The top 20 recommended words for the sample 
word ???? (teacher) are listed in Table 3. 
Compared with traditional methods (using Cilin, 
Hownet, and so forth.), using the word vectors to 
determine related words will identify more 
diverse and meaningful related words and this 
quality of WINGS is shown in Table 4. With the 
diversity of recommended words, writers? minds 
can be expanded easily.  
1-10: ??(student), ??(conduct class), ??
?(Chinese class), ????(with sincere words 
and earnest wishes), ????(affability), ??
(guide), ?? (lecture), ?? (dais), ????
(patient), ??(the whole class) 
11-20: ??(finish class), ???(remarks), ?
??(math class), ???(be absent-minded), ?
? (ferule), ??? (class adviser), ????
(restless), ??(remember), ????????
(excel one?s master), ??(listen to) 
Table 3. Top 20 recommended words for ???? 
(teacher). 
28
Words about Words 
Person ??, ???, ?? 
Quality ????, ????, ?
??? 
Course ???, ??? 
Teaching ??, ??, ??, ?? 
Teaching facility ??, ?? 
Student behaviour ??, ???, ???? 
Special idiom ???????? 
Others ??, ??? 
Table 4. Diversity of recommended words for 
???? (teacher). 
5.2 Sentences Recommending 
By introducing the topic model LDA, the 
sentences recommended by WINGS are related to 
the topic of the local context. Table 5 presents 
the top 5 recommended sentences for the word 
?????? (vivid/vividly) in two different local 
contexts: one refers to characters in books; the 
other refers to statues and sculptures. Most 
sentences in the first group are related to the first 
context, and most from the second group are 
related to the second context. 
In order to assess the performance of WINGS 
in sentence recommendation, the following 
evaluation was implemented. A total of 10 
Chinese words were randomly selected, and each 
word was given two or three different local 
contexts as above (contexts varied for different 
words). Finally, we obtained a total of 24 groups 
of data, each of which included an original word, 
a local context, and the top 10 sentences 
recommended by WINGS. To avoid the influence 
of personal preferences, 12 students were invited 
to judge whether each sentence in the 24 
different groups was related to their respective 
local context. We believed that a sentence was 
related to its context only when at least 70% of 
the evaluators agreed. The Precision@10 
measure in Information Retrieval was used, and 
the total average was 0.76, as shown in Table 6. 
Additionally, when we checked the sentences 
which were judged not related to their respective 
local context, we found that these sentences were 
generally too short after stop words removal, and 
as a result the topic distributions inferred from 
Gibbs Sampling were not that reliable. 
Context 1 is about characters in books:  
?? (story), ?? (character), ?? (image), 
??(works) 
1??????????????? 
(The characters of this book are depicted 
vividly) 
2???????????????????
?  
(The characters of this book are depicted vividly 
and the story is impressive narrative) 
3????????????  
(The characters of this story are depicted 
vividly) 
4???????????????????
??? 
(His works are full of plot twists, vivid 
characters, and surprising endings) 
5??????????????????  
(The characters in the book are depicted vividly 
by Jing Zhuge) 
Context 2 is about statues and sculptures:  
?? (statue), ?? (sculpture), ?? (stone 
inscription), ??(temple) 
1??????????????  
(The walls are painted with mighty and vivid 
dragons) 
2????????????????  
(On both sides there are standing 18 vivid Arhats 
with different manners) 
3?????????????????  
(the Great Buddha Hall is grand and the statues 
there are vivid) 
4????????????  
(Each statue is vivid and lifelike) 
5???????????????????
??????  
(On each of the eave angles there are 7 vivid 
statues of animals and birds with special 
meanings) 
Table 5. Top 5 recommended sentences for ??
???? (vivid/vividly) in two different local 
contexts.  
 
 
Local 
Context 
word 
1 
word 
2 
word 
3 
word 
4 
word 
5 
word 
6 
word 
7 
word 
8 
word 
9 
word 
10 
1 0.9 0.3 0.9 0.6 0.7 0.8 0.6 0.8 1.0 0.9 
2 0.4 0.7 1.0 0.9 0.9 0.7 1.0 0.5 0.9 0.5 
3 0.9 N/A N/A N/A N/A 0.9 0.8 N/A N/A 0.7 
Average Precision@10 value of the 24 groups data                0.76 
Table 6. Precision@10 value of each word under their respective context and the total average. 
29
5.3 Real Time Performance 
In order to ensure the real time process for each 
recommendation, we used CLucene to index and 
retrieve sentences and memory cache strategy to 
reduce the time cost of fetching sentences? 
information. Table 7 shows the average and max 
responding time of each recommendation of 
randomly selected 200 different words (Our test 
environment is 64-bit Ubuntu 12.04 LTS OS on 
PC with 4GB memory and 3.10GHz Dual-Core 
CPU). 
 
Item Responding time 
Average 154 ms 
Max 181 ms 
Table 7. The average and max responding time 
of 200 different words? recommending process 
6 Conclusion and Future Work 
In this paper, we presented WINGS, a Chinese 
input method extended with writing assistance 
that provides intelligent, real-time suggestions 
for writers. Overall, our system provides 
syntactically and semantically related words, as 
well as recommends contextually related 
sentences to users. As for the large corpus, on 
which the recommended words and sentences are 
based, and the corpus mining based on NLP 
techniques (e.g., word vector representation and 
topic model LDA), experimental results show 
that our system is both helpful and meaningful. 
In addition, given that the writers? feedback is 
recorded, WINGS will become increasingly 
effective for users while in use. Thus, we believe 
that WINGS will considerably benefit writers. 
  In future work, we will conduct more user 
experiments to understand the benefits of our 
system to their writing. For example, we can 
integrate WINGS into a crowdsourcing system 
and analyze the improvement in our users? 
writing. Moreover, our system may still be 
improved further. For example, we are interested 
in adding a function similar to Google Suggest, 
which is based on the query log of the search 
engine, in order to provide more valuable 
suggestions for users. 
 
 
 
 
 
 
 
 
References 
David M. Blei, Andrew Y. Ng and Michael I. Jordan. 
2003. Latent dirichlet allocation. the Journal of 
machine Learning research, 3, pages 993-1022. 
Mei-Hua Chen, Shih-Ting Huang, Hung-Ting Hsieh, 
Ting-Hui Kao and Jason S. Chang. 2012. FLOW: a 
first-language-oriented writing assistant system. In 
Proceedings of the ACL 2012 System 
Demonstrations, pages 157-162. 
Zheng Chen and Kai-Fu Lee. 2000. A new statistical 
approach to Chinese Pinyin input. In Proceedings 
of the 38th annual meeting on association for 
computational linguistics, pages 241-247. 
Hiroyuki Komatsu, Satoru Takabayash and Toshiyuki 
Masui. 2005. Corpus-based predictive text input. In 
Proceedings of the 2005 international conference 
on active media technology, pages 75?80. 
Chien-Liang Liu, Chia-Hoang Lee, Ssu-Han Yu and 
Chih-Wei Chen. 2011. Computer assisted writing 
system. Expert Systems with Applications, 38(1), 
pages 804-811. 
Chien-Liang Liu, Chia-Hoang Lee and Bo-Yuan Ding. 
2012. Intelligent computer assisted blog writing 
system. Expert Systems with Applications, 39(4), 
pages 4496-4504. 
Ting Liu, Ming Zhou, Jianfeng Gao, Endong Xun and 
Changning Huang. 2000. PENS: A machine-aided 
English writing system for Chinese users. In 
Proceedings of the 38th Annual Meeting on 
Association for Computational Linguistics, pages 
529-536. 
Tomas Mikolov, Kai Chen, Greg Corrado and Jeffrey 
Dean. 2013. Efficient estimation of word 
representations in vector space. arXiv:1301.3781. 
Xuan-Hieu Phan and Cam-Tu Nguyen. 2007. 
GibbsLDA++: A C/C++ implementation of latent 
Dirichlet allocation (LDA). 
30
 Research of People Disambiguation by Combining  
Multiple knowledges 
Erlei Ma 
 School of computer science and 
technology, harbin institute of tech-
nology  
elma@insun.hit.edu.cn 
Yuanchao Liu 
 School of computer science and technology, 
harbin institute of technology  
ycliu@hit.edu.cn 
 
Abstract 
With the rapid development of Internet 
and many related technology, Web has 
become the main source of information. 
For many search engines, there are 
many different identities in the returned 
results of character information query. 
Thus the Research of People disambig-
uation is important. In this paper we at-
tempt to solve this problem by combing 
different knowledge.  As people usually 
have different kind of careers, so we first 
utilize this knowledge to classify people 
roughly. Then we use social context of 
people to identify different person. The 
experimental results show that these 
knowledge are helpful for people disam-
biguation. 
1 Introduction 
For the real world, many people share one 
name; this is a very common phenomenon. Ac-
cording to the third national census sample sur-
vey conducted by the State Language Commit-
tee in 1989, the duplicate names rate for single 
name was 67.7%, whereas that of double name 
was 32.4%. 
There are two commonly used name disam-
biguation approach, one is based on the vector 
space model, and the other is based on so-
cial networks.  
The first is text-based vector space clustering 
approach. An entity can be expressed as one 
vector which is formed according to the content 
word of the original document. And then the si-
milarity is used to merge documents or classify 
documents. 
The second method is based on social net-
works. The first step of the method is to build 
social networks, by analyze the relationship of 
different people. Generally if two people?s name 
always occurs in same document or very near  
context ,they will have close relations, one of 
them will be helpful for disambiguate the other. 
In this paper, we first use the domain of cha-
racter?s document to classify roughly, and then 
context information using social networking is 
considered again to disambiguate person?s 
name again. 
2 the principle of our system 
   Fig.1. shows the basic principle of our system. 
The basic steps are: 
 
 
Fig.1. the general framework of our approach 
 
1? documents with same people?s name 
are input; 
2? classify these documents into seven ca-
reers which include Cultural, adminis-
trative, military, science, education, 
sports, health, economic and etc; 
3? Judge if the people are reporter in doc-
ument, if yes; separate them according 
to their address. 
4? Separate documents by using social 
networks. This is because different 
people usually have different social re-
lations. Different social relations usual-
ly means different people and different 
identity. The social network of one 
people is gained by counting its co-
occur frequency with other peoples.  
 
3 experimental results  
3.1 evaluation method 
Here are the evaluation formula provided by SIG-
HAN 2010: 
j i 
i 
i j
RS
i
S
| S R |
Precision
|S |
max RS
i
S
??
?
?= ? ?         ?1?                              
j i 
i 
i j
SR
i
R
| R S |
Recall
|R |
max SR
i
R
??
?
?= ? ?           ?2?                                   
B-Cubed ?
j ji i
i 
i j
S ; SR R
i
i
R
|R S |
|R |Recall = 
|R |
max S dR d
i
R
? ?? ?
?
?? ?
?    
?3?                          
j ji i
i 
i j
R ; RS S
i
i
S
|S R |
|S | Pr ecision =
|S |
max R dS d
i
S
? ?? ?
?
?? ?
? ?4?                      
2 Pr Re
Pr Re
i i
i
i i
ecision call
F measure
ecision call
? ?? = +      ?5?                          
The overall precision and recall is as follows: 
1
1
Pr Pr
n
i
i
ecision ecision
n =
= ?                ?6?                               
1
1
Re Re
n
i
i
call call
n =
= ?
                     ?7?                      
1
1 n
i
i
F measure F measure
n =
? = ??
  ?8?                         
3.2 The performance of our system 
By only utilizing the career domain know-
ledge, the performance is shown in table 1. Ob-
viously the people in this division of the seven 
categories, the accuracy is low and the recall 
rates were high. The reasons include the follow-
ing: 
First, in he document pre-classification 
processing, the named entity recognition has not 
been carried out in the text dealing with the clas-
sification of the document. Some of them are not 
the people?s name. 
Second, different people may have same do-
main, thus the accuracy is adversely affected. 
Table 1 . The performance after the first-step classification  
 precision recall Fmeasure
B-Cube 28.78 99.97 44.69 
P_I
P 
42.82 99.97 59.96 
 
By adding the knowledge of social networks, 
the performance is shown in Fig.2-Fig.3. 
 
 
Fig.2 result of B-Cubed 
Fig.3. result of P_IP 
Clearly the experiment showed that after 
matching character society attribute information, 
the recall rate increased significantly, and the F 
value also have increased. . 
4 Summaries 
In this paper, we utilize two kind of knowledges: 
1) people always have his own career; 2) people 
have his own social circle.  We think these in-
formation will be more helpful for disambiguation. 
Thus we attempt to solve this problem by com-
bing different knowledge.  As people usually 
0
10
20
30
40
50
60
70
80
90
100
??-2 ??-3 ??-4
???
???
F_score
0
10
20
30
40
50
60
70
80
90
100
??-2 ??-3 ??-4
???
???
F_score
have different kind of careers, so we first utilize 
this knowledge to classify people roughly. Then 
we use social context of people to identify differ-
ent person.  In the future we wish to address the 
following aspects: 1) add and improve name 
recognition accuracy; 2) extract and select the 
useful context of person?s name, which is the 
problem of information extraction; 3) recognize 
some kind of public people such as political 
leaders, famous singers and etc. to improve the 
effect of social networks.  
References 
[1]Amit Bagga and Breck Baldwin.Entity Based 
Cross-Document Coreferencing Using the Vector 
Space Model In Proceedings of the 36th Annual 
Meeting of the Association for Computational 
Linguistics and the 17th International Conference 
on Computational Linguistics(COLING-
ACL?98),1998 :79-85. 
[2] Gideon S. Mann and David Yarowsky. Unsuper-
vised Personal Name Disambiguation In Proceed-
ings of the seventh conference on Natural lan-
guage learning at HLT-NAACL, 2003: 33-40. 
[3] Bollegala, D., Y. Matsuo, M. Ishizuka. Disambi-
guating Personal Names on the Web Using Auto-
matically Extracted Key Phrases. In: Gerhard 
Brewka, Silvia Coradeschi, Anna Perini, Paolo 
Traverso, eds. Proc. of the 17th European Confe-
rence on Artificial Intelligence. Riva del Garda, It-
aly: IOS Press, 2006:553-557 
 [4] Bekkerman, Ron, Andrew McCallum. Disambi-
guating Web Appearances of People in a Social 
Network. In: Allan Ellis, Tatsuya Hagino , eds. 
Proc. of the 14th international conference on 
World Wide Web. Chiba, Japan: ACM Press, 
2005:463-470 
[5] Javier Artiles, Julio Gonzalo, Satoshi Sekine. The 
SemEval-2007 WePS Evaluation: Establishing a 
benchmark for the Web People Search Task. IN: 
Proceedings of the 4th International Workshop on 
Semantic Evaluations (SemEval-2007),2007: 64?
69 
[6] Malin, Bradley. Unsupervised Name Disambigua-
tion via Social Network Similarity. In: Hillol Kar-
gupta, Jaideep Srivastava, Chandrika Kamath, Ar-
nold Goodman, eds. Proc. of the Workshop on 
Link Analysis, Counterterrorism, and Security, in 
conjunction with the SIAM International Confe-
rence on Data Mining. Newport Beach, California, 
USA: SIAM, 2005:93-102 
 [7 ?] Nahm, U. Y. and Mooney, R. J. Text Mining 
with Information Extraction. In Proceedings of the 
AAAI 2002 Spring Symposium on Mining An-
swers from Texts and Knowledge Bases, Stanford, 
CA, March 2002: 60-67. 
[8] Yang, Y., and Jan O. Pedersen. A comparative 
study on Feature Selection in Text Categorization. 
Proceedings of the Fourteenth International Confe-
rence on Machine Learning Table of Contents, 
1997: 412-420. 
 
