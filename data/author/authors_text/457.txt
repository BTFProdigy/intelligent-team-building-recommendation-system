Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 601?608
Manchester, August 2008
Modeling the Structure and Dynamics of the
Consonant Inventories: A Complex Network Approach
Animesh Mukherjee1, Monojit Choudhury2, Anupam Basu1, Niloy Ganguly1
1Department of Computer Science and Engineering,
Indian Institute of Technology, Kharagpur, India ? 721302
2Microsoft Research India, Bangalore, India ? 560080
{animeshm,anupam,niloy}@cse.iitkgp.ernet.in,
monojitc@microsoft.com
Abstract
We study the self-organization of the con-
sonant inventories through a complex net-
work approach. We observe that the dis-
tribution of occurrence as well as co-
occurrence of the consonants across lan-
guages follow a power-law behavior. The
co-occurrence network of consonants ex-
hibits a high clustering coefficient. We
propose four novel synthesis models for
these networks (each of which is a refine-
ment of the earlier) so as to successively
match with higher accuracy (a) the above
mentioned topological properties as well
as (b) the linguistic property of feature
economy exhibited by the consonant inven-
tories. We conclude by arguing that a pos-
sible interpretation of this mechanism of
network growth is the process of child lan-
guage acquisition. Such models essentially
increase our understanding of the struc-
ture of languages that is influenced by their
evolutionary dynamics and this, in turn,
can be extremely useful for building future
NLP applications.
1 Introduction
A large number of regular patterns are observed
across the sound inventories of human languages.
These regularities are arguably a consequence of
the self-organization that is instrumental in the
emergence of these inventories (de Boer, 2000).
Many attempts have been made by functional pho-
nologists for explaining this self-organizing behav-
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
ior through certain general principles such as max-
imal perceptual contrast (Liljencrants and Lind-
blom, 1972), ease of articulation (Lindblom and
Maddieson, 1988; de Boer, 2000), and ease of
learnability (de Boer, 2000). In fact, there are a
lot of studies that attempt to explain the emergence
of the vowel inventories through the application of
one or more of the above principles (Liljencrants
and Lindblom, 1972; de Boer, 2000). Some studies
have also been carried out in the area of linguistics
that seek to reason the observed patterns in the con-
sonant inventories (Trubetzkoy, 1939; Lindblom
and Maddieson, 1988; Boersma, 1998; Clements,
2008). Nevertheless, most of these works are con-
fined to certain individual principles rather than
formulating a general theory describing the emer-
gence of these regular patterns across the conso-
nant inventories.
The self-organization of the consonant inven-
tories emerges due to an interaction of different
forces acting upon them. In order to identify the
nature of these interactions one has to understand
the growth dynamics of these inventories. The the-
ories of complex networks provide a number of
growth models that have proved to be extremely
successful in explaining the evolutionary dynam-
ics of various social (Newman, 2001; Ramasco et
al., 2004), biological (Jeong et al, 2000) and other
natural systems. The basic framework for the cur-
rent study develops around two such complex net-
works namely, the Phoneme-Language Network
or PlaNet (Choudhury et al, 2006) and its one-
mode projection, the Phoneme-Phoneme Network
or PhoNet (Mukherjee et al2007a). We begin by
analyzing some of the structural properties (Sec. 2)
of the networks and observe that the consonant
nodes in both PlaNet and PhoNet follow a power-
law-like degree distribution. Moreover, PhoNet
601
is characterized by a high clustering coefficient,
a property that has been found to be prevalent in
many other social networks (Newman, 2001; Ra-
masco et al, 2004).
We propose four synthesis models for PlaNet
(Sec. 3), each of which employ a variant of a pref-
erential attachment (Baraba?si and Albert, 1999)
based growth kernel1. While the first two mod-
els are independent of the characteristic proper-
ties of the (consonant) nodes, the following two
use them. These models are successively refined
not only to reproduce the topological properties of
PlaNet and PhoNet, but also to match the linguis-
tic property of feature economy (Boersma, 1998;
Clements, 2008) that is observed across the conso-
nant inventories. The underlying growth rules for
each of these individual models helps us to inter-
pret the cause of the emergence of at least one (or
more) of the aforementioned properties. We con-
clude (Sec. 4) by providing a possible interpreta-
tion of the proposed mathematical model that we
finally develop in terms of child language acquisi-
tion.
There are three major contributions of this work.
Firstly, it provides a fascinating account of the
structure and the evolution of the human speech
sound systems. Furthermore, the introduction of
the node property based synthesis model is a sig-
nificant contribution to the field of complex net-
works. On a broader perspective, this work shows
how statistical mechanics can be applied in under-
standing the structure of a linguistic system, which
in turn can be extremely useful in developing fu-
ture NLP applications.
2 Properties of the Consonant
Inventories
In this section, we briefly recapitulate the defi-
nitions of PlaNet and PhoNet, the data source,
construction procedure for the networks and some
of their important structural properties. We also
revisit the concept of feature economy and the
method used for its quantification.
2.1 Structural Properties of the Consonant
Networks
PlaNet is a bipartite graph G = ? V
L
, V
C
, E
pl
? con-
sisting of two sets of nodes namely, V
L
(labeled by
the languages) and V
C
(labeled by the consonants);
1The word kernel here refers to the function or mathemat-
ical formula that drives the growth of the network.
Figure 1: Illustration of the nodes and edges of
PlaNet and PhoNet.
E
pl
is the set of edges running between V
L
and V
C
.
There is an edge e ? E
pl
from a node v
l
? V
L
to a
node v
c
? V
C
iff the consonant c is present in the
inventory of language l.
PhoNet is the one-mode projection of PlaNet
onto the consonant nodes i.e., a network of con-
sonants in which two nodes are linked by an edge
with weight as many times as they co-occur across
languages. Hence, it can be represented by a graph
G = ? V
C
, E
ph
?, where V
C
is the set of conso-
nant nodes and E
ph
is the set of edges connecting
these nodes in G. There is an edge e ? E
ph
if the
two nodes (read consonants) that are connected by
e co-occur in at least one language and the number
of languages they co-occur in defines the weight of
the edge e. Figure 1 shows the nodes and the edges
of PlaNet and PhoNet.
Data Source and Network Construction: Like
many other earlier studies (Liljencrants and Lind-
blom, 1972; Lindblom and Maddieson, 1988; de
Boer, 2000; Hinskens and Weijer, 2003), we use
the UCLA Phonological Segment Inventory Data-
base (UPSID) (Maddieson, 1984) as the source of
our data. There are 317 languages in the data-
base with a total of 541 consonants found across
them. Each consonant is characterized by a set of
phonological features (Trubetzkoy, 1931), which
distinguishes it from others. UPSID uses articula-
tory features to describe the consonants, which can
be broadly categorized into three different types
namely the manner of articulation, the place of
articulation and phonation. Manner of articu-
lation specifies how the flow of air takes place
in the vocal tract during articulation of a conso-
nant, whereas place of articulation specifies the
active speech organ and also the place where it
acts. Phonation describes the vibration of the vo-
602
Manner of Articulation Place of Articulation Phonation
tap velar voiced
flap uvular voiceless
trill dental
click palatal
nasal glottal
plosive bilabial
r-sound alveolar
fricative retroflex
affricate pharyngeal
implosive labial-velar
approximant labio-dental
ejective stop labial-palatal
affricated click dental-palatal
ejective affricate dental-alveolar
ejective fricative palato-alveolar
lateral approximant
Table 1: The table shows some of the important
features listed in UPSID. Over 99% of the UPSID
languages have bilabial, dental-alveolar and velar
plosives. Furthermore, voiceless plosives outnum-
ber the voiced ones (92% vs. 67%). 93% of the
languages have at least one fricative, 97% have at
least one nasal and 96% have at least one liquid.
Approximants occur in fewer than 95% of the lan-
guages.
cal cords during the articulation of a consonant.
Apart from these three major classes there are also
some secondary articulatory features found in cer-
tain languages. There are around 52 features listed
in UPSID; the important ones are noted in Table 1.
Note that in UPSID the features are assumed to be
binary-valued and therefore, each consonant can
be represented by a binary vector.
We have used UPSID in order to construct
PlaNet and PhoNet. Consequently, |V
L
| = 317 (in
PlaNet) and |V
C
| = 541. The number of edges in
PlaNet and PhoNet are 7022 and 30412 respec-
tively.
Degree Distributions of PlaNet and PhoNet:
The degree distribution is the fraction of nodes, de-
noted by P
k
, which have a degree2 greater than or
equal to k (Newman, 2003). The degree distribu-
tion of the consonant nodes in PlaNet and PhoNet
are shown in Figure 2 in the log-log scale. Both the
plots show a power-law behavior (P
k
? k
??) with
exponential cut-offs towards the ends. The value
of ? is 0.71 for PlaNet and 0.89 for PhoNet.
Clustering Coefficient of PhoNet: The clus-
tering coefficient for a node i is the proportion of
links between the nodes that are the neighbors of
i divided by the number of links that could pos-
sibly exist between them (Newman, 2003). Since
PhoNet is a weighted graph the above definition is
2For a weighted graph like PhoNet, the degree of a node i
is the sum of weights on the edges that are incident on i.
suitably modified by the one presented in (Barrat
et al, 2004). According to this definition, the clus-
tering coefficient for a node i is,
c
i
=
1
(
?
?j
w
ij
)
(k
i
? 1)
?
?j,l
(w
ij
+ w
il
)
2
a
ij
a
il
a
jl
(1)
where j and l are neighbors of i; k
i
represents the
plain degree of the node i; w
ij
, w
jl
and w
il
de-
note the weights of the edges connecting nodes i
and j, j and l, and i and l respectively; a
ij
, a
il
,
a
jl
are boolean variables, which are true iff there
is an edge between the nodes i and j, i and l, and j
and l respectively. The clustering coefficient of the
network (c
av
) is equal to the average clustering co-
efficient of the nodes. The value of c
av
for PhoNet
is 0.89, which is significantly higher than that of a
random graph with the same number of nodes and
edges (0.08).
2.2 Linguistic Properties: Feature Economy
and its Quantification
The principle of feature economy states that lan-
guages tend to use a small number of distinctive
features and maximize their combinatorial pos-
sibilities to generate a large number of conso-
nants (Boersma, 1998; Clements, 2008). Stated
differently, a given consonant will have a higher
than expected chance of occurrence in invento-
ries in which all of its features have already dis-
tinctively occurred in the other consonants. This
principle immediately implies that the consonants
chosen by a language should share a considerable
number of features among them. The quantifica-
tion process, which is a refinement of the idea pre-
sented in (Mukherjee et al2007b), is as follows.
Feature Entropy: For an inventory of size N ,
let there be p
f
consonants for which a particular
feature f (recall that we assume f to be binary-
valued) is present and q
f
other consonants for
which the same is absent. Therefore, the proba-
bility that a consonant (chosen uniformly at ran-
dom from this inventory) contains the feature f is
p
f
N
and the probability that it does not contain the
feature is qf
N
(=1?pf
N
). One can think of f as an in-
dependent random variable, which can take values
1 and 0, and pf
N
and qf
N
define the probability dis-
tribution of f . Therefore, for any given inventory,
we can define the binary entropy H
f
(Shannon and
Weaver, 1949) for the feature f as
H
f
= ?
p
f
N
log
2
p
f
N
?
q
f
N
log
2
q
f
N
(2)
603
Figure 2: Degree distribution (DD) of PlaNet alng with that of PlaNet
syn
obtained from Model I and II
respectively; (b) DD of PhoNet alng with that of PhoNet
syn
obtained from Model I and II respectively.
Both the plots are in log-log scale.
If F is the set of all features present in the conso-
nants forming the inventory, then feature entropy
F
E
is the sum of the binary entropies with respect
to all the features, that is
F
E
=
?
f?F
H
f
=
?
f?F
(?
p
f
N
log
2
p
f
N
?
q
f
N
log
2
q
f
N
)
(3)
Since we have assumed that f is an independent
random variable, F
E
is the joint entropy of the
system. In other words, F
E
provides an estimate
of the number of discriminative features present
in the consonants of an inventory that a speaker
(e.g., parent) has to communicate to a learner (e.g.,
child) during language transmission. The lower the
value of F
E
the higher is the feature economy. The
curve marked as (R) in Figure 3 shows the average
feature entropy of the consonant inventories of a
particular size3 (y-axis) versus the inventory size
(x-axis).
3 Synthesis Models
In this section, we describe four synthesis mod-
els that incrementally attempt to explain the emer-
gence of the structural properties of PlaNet and
PhoNet as well as the feature entropy exhibited by
the consonant inventories. In all these models, we
assume that the distribution of the consonant in-
ventory size, i.e., the degrees of the language nodes
in PlaNet, are known a priori.
3Let there be n inventories of a particular size k. The
average feature entropy of the inventories of size k is
1
n
?
n
i=1
F
E
i
, where F
E
i
signifies the feature entropy of the
i
th inventory of size k.
3.1 Model I: Preferential Attachment Kernel
This model employs a modified version of the ker-
nel described in (Choudhury et al, 2006), which is
the only work in literature that attempts to explain
the emergence of the consonant inventories in the
framework of complex networks.
Let us assume that a language node L
i
? V
L
has a degree k
i
. The consonant nodes in V
C
are
assumed to be unlabeled, i.e, they are not marked
by the distinctive features that characterize them.
We first sort the nodes L
1
through L
317
in the as-
cending order of their degrees. At each time step a
node L
j
, chosen in order, preferentially attaches it-
self with k
j
distinct nodes (call each such node C
i
)
of the set V
C
. The probability Pr(C
i
) with which
the node L
j
attaches itself to the node C
i
is given
by,
Pr(C
i
) =
d
i
?
+ ?
?
i
?
?V
?
C
(d
i
?
?
+ ?)
(4)
where, d
i
is the current degree of the node C
i
,
V
?
C
is the set of nodes in V
C
that are not already
connected to L
j
, ? is the smoothing parameter
that facilitates random attachments and ? indi-
cates whether the attachment kernel is sub-linear
(? < 1), linear (? = 1) or super-linear (? > 1).
Note that the modification from the earlier ker-
nel (Choudhury et al, 2006) is brought about by
the introduction of ?. The above process is re-
peated until all the language nodes L
j
? V
L
get
connected to k
j
consonant nodes (refer to Figure.
6 of (Choudhury et al, 2006) for an illustration of
the steps of the synthesis process). Thus, we have
604
the synthesized version of PlaNet, which we shall
call PlaNet
syn
henceforth.
The Simulation Results: We simulate the
above model to obtain PlaNet
syn
for 100 differ-
ent runs and average the results over all of them.
We find that the degree distributions that emerge
fit the empirical data well for ? ? [1.4,1.5] and
? ? [0.4,0.6], the best being at ? = 1.44 and ? = 0.5
(shown in Figure 2). In fact, the mean error4 be-
tween the real and the synthesized distributions for
the best choice of parameters is as small as 0.01.
Note that this error in case of the model presented
in (Choudhury et al, 2006) was 0.03. Furthermore,
as we shall see shortly, a super-linear kernel can
explain various other topological properties more
accurately than a linear kernel.
In absence of preferential attachment i.e., when
all the connections to the consonant nodes are
equiprobable, the mean error rises to 0.35.
A possible reason behind the success of this
model is the fact that language is a constantly
changing system and preferential attachment plays
a significant role in this change. For instance, dur-
ing the change those consonants that belong to lan-
guages that are more prevalent among the speak-
ers of a generation have higher chances of being
transmitted to the speakers of the subsequent gen-
erations (Blevins, 2004). This heterogeneity in the
choice of the consonants manifests itself as pref-
erential attachment. We conjecture that the value
of ? is a function of the societal structure and the
cognitive capabilities of human beings. The exact
nature of this function is currently not known and
a topic for future research. The parameter ? in this
case may be thought of as modeling the random-
ness of the system.
Nevertheless, the degree distribution of
PhoNet
syn
, which is the one-mode projection
of PlaNet
syn
, does not match the real data well
(see Figure 2). The mean error between the two
distributions is 0.45. Furthermore, the clustering
coefficient of PhoNet
syn
is 0.55 and differs largely
from that of PhoNet. The primary reason for this
deviation in the results is that PhoNet exhibits
strong patterns of co-occurrences (Mukherjee et
al.2007a) and this fact is not taken into account
by Model I. In order to circumvent the above
4Mean error is defined as the average difference between
the ordinate pairs (say y and y? ) where the abscissas are equal.
In other words, if there are N such ordinate pairs then the
mean error can be expressed as
?
|y?y
?
|
N
.
problem, we introduce the concept of triad (i.e.,
fully connected triplet) formation and thereby
refine the model in the following section.
3.2 Model II: Kernel based on Triad
Formation
The triad model (Peltoma?ki and Alava, 2006)
builds up on the concept of neighborhood forma-
tion. Two consonant nodes C
1
and C
2
become
neighbors if a language node at any step of the
synthesis process attaches itself to both C
1
and
C
2
. Let the probability of triad formation be de-
noted by p
t
. At each time step a language node
L
j
(chosen from the set of language nodes sorted
in ascending order of their degrees) makes the first
connection preferentially to a consonant node C
i
? V
C
to which L
j
is not already connected fol-
lowing the distribution Pr(C
i
). For the rest of the
(k
j
-1) connections L
j
attaches itself preferentially
to only the neighbors of C
i
to which L
j
is not yet
connected with a probability p
t
. Consequently, L
j
connects itself preferentially to the non-neighbors
of C
i
to which L
j
is not yet connected with a prob-
ability (1 ? p
t
). The neighbor set of C
i
gets up-
dated accordingly. Note that every time the node
C
i
and its neighbors are chosen they together im-
pose a clique on the one-mode projection. This
phenomenon leads to the formation of a large num-
ber of triangles in the one-mode projection thereby
increasing the clustering coefficient of the resultant
network.
The Simulation Results: We carry out 100 dif-
ferent simulation runs of the above model for a par-
ticular set of parameter values to obtain PlaNet
syn
and average the results over all of them. We ex-
plore several parameter settings in the range as fol-
lows: ? ? [1,1.5] (in steps of 0.1), ? ? [0.2,0.4]
(in steps of 0.1) and p
t
? [0.70,0.95] (in steps of
0.05). We also observe that if we traverse any fur-
ther along one or more of the dimensions of the pa-
rameter space then the results get worse. The best
result emerges for ? = 1.3, ? = 0.3 and p
t
= 0.8.
Figure 2 shows the degree distribution of the
consonant nodes of PlaNet
syn
and PlaNet. The
mean error between the two distributions is 0.04
approximately and is therefore worse than the re-
sult obtained from Model I. Nevertheless, the aver-
age clustering coefficient of PhoNet
syn
in this case
is 0.85, which is within 4.5% of that of PhoNet.
Moreover, in this process the mean error between
the degree distribution of PhoNet
syn
and PhoNet
605
(as illustrated in Figure 2) has got reduced drasti-
cally from 0.45 to 0.03.
One can again find a possible association of this
model with the phenomena of language change. If
a group of consonants largely co-occur in the lan-
guages of a generation of speakers then it is very
likely that all of them get transmitted together in
the subsequent generations (Blevins, 2004). The
triad formation probability ensures that if a pair of
consonant nodes become neighbors of each other
in a particular step of the synthesis process then
the choice of such a pair should be highly pre-
ferred in the subsequent steps of the process. This
is coherent with the aforementioned phenomenon
of transmission of consonants in groups over lin-
guistic generations. Since the value of p
t
that we
obtain is quite high, it may be argued that such
transmissions are largely prevalent in nature.
Although Model II reproduces the structural
properties of PlaNet and PhoNet quite accurately,
as we shall see shortly, it fails to generate inven-
tories that closely match the real ones in terms
of feature entropy. However, at this point, recall
that Model II assumes that the consonant nodes are
unlabeled; therefore, the inventories that are pro-
duced as a result of the synthesis are composed of
consonants, which unlike the real inventories, are
not marked by their distinctive features. In order
to label them we perform the following,
The Labeling Scheme:
1. Sort the consonants of UPSID in the decreasing
order of their frequency of occurrence and call this
list of consonants ListC[1 ? ? ? 541],
2. Sort the V
C
nodes of PlaNet
syn
in decreasing
order of their degree and call this list of nodes
ListN [1 ? ? ? 541],
3. ?
1?i?541
ListN [i] ?? ListC[i]
The Figure 3 indicates that the curve for the real
inventories (R) and those obtained from Model II
(M2) are significantly different from each other.
This difference arises due to the fact that in Model
II, the choice of a consonant from the set of neigh-
bors is solely degree-dependent, where the rela-
tionships between the features are not taken into
consideration. Therefore, in order to eliminate this
problem, we introduce the model using the feature-
based kernel in the next section.
3.3 Model III: Feature-based Kernel
In this model, we assume that each of the conso-
nant nodes are labeled, that is each of them are
Figure 3: Average feature entropy of the invento-
ries of a particular size (y-axis) versus the inven-
tory size (x-axis).
marked by a set of distinctive features. The attach-
ment kernel in this case has two components one
of which is preferential while the other favors the
choice of those consonants that are at a low fea-
ture distance (the number of feature positions they
differ at) from the already chosen ones. Let us de-
note the feature distance between two consonants
C
i
and C ?
i
by D(C
i
, C
?
i
). We define the affinity,
A(C
i
, C
?
i
), between C
i
and C ?
i
as
A(C
i
, C
?
i
) =
1
D(C
i
, C
?
i
)
(5)
Therefore, the lower the feature distance between
C
i
and C ?
i
the higher is the affinity between them.
At each time step a language node estab-
lishes the first connection with a consonant node
(say C
i
) preferentially following the distribution
Pr(C
i
) like the previous models. The rest of
the connections to any arbitrary consonant node
C
?
i
(not yet connected to the language node) are
made following the distribution (1?w)Pr(C ?
i
) +
wPr
aff
(C
i
, C
?
i
), where
Pr
aff
(C
i
, C
?
i
) =
A(C
i
, C
?
i
)
?
?C
?
i
A(C
i
, C
?
i
)
(6)
and 0 < w < 1.
Simulation Results: We perform 100 different
simulation runs of the above model for a particular
set of parameter values to obtain PlaNet
syn
and av-
erage the results over all of them. We explore dif-
ferent parameter settings in the range as follows:
? ? [1,2] (in steps of 0.1), ? ? [0.1,1] (in steps
of 0.1) and w ? [0.1,0.5] (in steps of 0.05). The
606
best result in terms of the structural properties of
PlaNet and PhoNet emerges for ? = 1.6, ? = 0.3
and w = 0.2.
In this case, the mean error between the de-
gree distribution curves for PlaNet
syn
and PlaNet
is 0.05 and that between of PhoNet
syn
and PhoNet
is 0.02. Furthermore, the clustering coefficient of
PhoNet
syn
in this case is 0.84, which is within
5.6% of that of PhoNet. The above results show
that the structural properties of the synthesized
networks in this case are quite similar to those
obtained through the triad model. Nevertheless,
the average feature entropy of the inventories pro-
duced (see curve M3 in Figure 3) are more close to
that of the real ones now (for quantitative compar-
ison see Table 2).
Therefore, it turns out that the groups of con-
sonants that largely co-occur in the languages
of a linguistic generation are actually driven by
the principle of feature economy (see (Clements,
2008; Mukherjee et al2007a) for details).
However, note that even for Model III the nodes
that are chosen for attachment in the initial stages
of the synthesis process are arbitrary and conse-
quently, the labels of the nodes of PlaNet
syn
do
not have a one-to-one correspondence with that of
PlaNet, which is the main reason behind the differ-
ence in the result between them. In order to over-
come this problem we can make use of a small set
of real inventories to bootstrap the model.
3.4 Model IV: Feature-based Kernel and
Bootstrapping
In order to create a bias towards the labeling
scheme prevalent in PlaNet, we use 30 (around
10% of the) real languages as a seed (chosen ran-
domly) for Model III; i.e., they are used by the
model for bootstrapping. The idea is summarized
below.
1. Select 30 real inventories at random and con-
struct a PlaNet from them. Call this network the
initial PlaNet
syn
.
2. The rest of the language nodes are incrementally
added to this initial PlaNet
syn
using Model III.
Simulation Results: The best fit now emerges
at ? = 1.35, ? = 0.3 and w = 0.15. The mean er-
ror between the degree distribution of PlaNet and
PlaNet
syn
is 0.05 and that between PhoNet and
PhoNet
syn
is 0.02. The clustering coefficient of
PhoNet
syn
is 0.83 in this case (within 6.7% of that
of PhoNet).
Results Model I Model II Model III Model IV
ME: DD of PlaNet & PlaNet
syn
0.01 0.04 0.05 0.05
ME: DD of PhoNet & PhoNet
syn
0.45 0.03 0.02 0.02
% Err: Clustering Coefficient 38.2 04.5 05.6 06.7
ME: Avg. F
E
of Real & Synth. Inv. 3.40 3.00 2.10 0.93
? 1.44 1.30 1.60 1.35
? 0.5 0.3 0.3 0.3
p
t
? 0.8 ? ?
w ? ? 0.20 0.15
Table 2: Important results obtained from each of
the models. ME: Mean Error, DD: Degree Distri-
bution.
The inventories that are produced as a result of
the bootstrapping have an average feature entropy
closer to the real inventories (see curve M4 in Fig-
ure 3) than the earlier models. Hence, we find
that this improved labeling strategy brings about
a global betterment in our results unlike in the pre-
vious cases. The larger the number of languages
used for the purpose of bootstrapping the better are
the results mainly in terms of the match in the fea-
ture entropy curves.
4 Conclusion
We dedicated the preceding sections of this article
to analyze and synthesize the consonant invento-
ries of the world?s languages in the framework of a
complex network. Table 2 summarizes the results
obtained from the four models so that the reader
can easily compare them. Some of our important
observations are
? The distribution of occurrence and co-occurrence
of consonants across languages roughly follow a
power law,
? The co-occurrence network of consonants has a
large clustering coefficient,
? Groups of consonants that largely co-occur
across languages are driven by feature economy
(which can be expressed through feature entropy),
? Each of the above properties emerges due to dif-
ferent reasons, which are successively unfurled by
our models.
So far, we have tried to explain the physical sig-
nificance of our models in terms of the process
of language change. Language change is a col-
lective phenomenon that functions at the level of
a population of speakers (Steels, 2000). Never-
theless, it is also possible to explain the signif-
icance of the models at the level of an individ-
ual, primarily in terms of the process of language
acquisition, which largely governs the course of
language change. In the initial years of language
development every child passes through a stage
607
called babbling during which he/she learns to pro-
duce non-meaningful sequences of consonants and
vowels, some of which are not even used in the
language to which they are exposed (Jakobson,
1968; Locke, 1983). Clear preferences can be
observed for learning certain sounds such as plo-
sives and nasals, whereas fricatives and liquids are
avoided. In fact, this hierarchy of preference dur-
ing the babbling stage follows the cross-linguistic
frequency distribution of the consonants. This in-
nate frequency dependent preference towards cer-
tain phonemes might be because of phonetic rea-
sons (i.e., for articulatory/perceptual benefits). In
all our models, this innate preference gets cap-
tured through the process of preferential attach-
ment. However, at the same time, in the context of
learning a particular inventory the ease of learning
the individual consonants also plays an important
role. The lower the number of new feature distinc-
tions to be learnt, the higher the ease of learning
the consonant. Therefore, there are two orthogonal
preferences: (a) the occurrence frequency depen-
dent preference (that is innate), and (b) the feature-
dependent preference (that increases the ease of
learning), which are instrumental in the acquisi-
tion of the inventories. The feature-based kernel is
essentially a linear combination of these two mu-
tually orthogonal factors.
References
A.-L. Baraba?si and R. Albert. 1999. Emergence of
scaling in random networks. Science 286, 509-512.
A. Barrat, M. Barthe?lemy, R. Pastor-Satorras and A.
Vespignani. 2004. The architecture of complex
weighted networks. PNAS 101, 3747?3752.
J. Blevins. 2004. Evolutionary Phonology: The
Emergence of Sound Patterns, Cambridge University
Press, Cambridge.
B. de Boer. 2000. Self-organisation in vowel systems.
Journal of Phonetics 28(4), 441?465.
P. Boersma. 1998. Functional Phonology, The Hague:
Holland Academic Graphics.
M. Choudhury, A. Mukherjee, A. Basu and N. Ganguly.
2006. Analysis and synthesis of the distribution of
consonants over languages: A complex network ap-
proach. Proceedings of COLING-ACL06, 128?135.
G. N. Clements. 2008. The role of features in speech
sound inventories. In Eric Raimy & Charles Cairns,
eds.,Contemporary Views on Architecture and Rep-
resentations in Phonological Theory, Cambridge,
MA: MIT Press.
F. Hinskens and J. Weijer. 2003. Patterns of segmen-
tal modification in consonant inventories: A cross-
linguistic study. Linguistics 41(6), 1041?1084.
R. Jakobson. 1968. Child Language, Aphasia and
Phonological Universals. The Hague: Mouton.
H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai and A.
L. Baraba?si. 2000. The large-scale organization of
metabolic networks. Nature 406 651-654.
J. Liljencrants and B. Lindblom. 1972. Numerical sim-
ulation of vowel quality systems: the role of percep-
tual contrast. Language 48, 839?862.
B. Lindblom and I. Maddieson. 1988. Phonetic univer-
sals in consonant systems. Language, Speech, and
Mind, 62?78, Routledge, London.
J. L. Locke. 1983. Phonological Acquisition and
Change. Academic Press New York.
I. Maddieson. 1984. Patterns of Sounds, Cambridge
University Press, Cambridge.
A. Mukherjee, M. Choudhury, A. Basu and N. Gan-
guly. 2007a. Modeling the co-occurrence principles
of the consonant inventories: A complex network ap-
proach. Int. Jour. of Mod. Phys. C 18(2), 281?295.
A. Mukherjee, M. Choudhury, A. Basu and N. Ganguly.
2007b. Redundancy ratio: An invariant property of
the consonant inventories of the world?s languages
Proceedings of ACL07, 104?111.
M. E. J. Newman. 2001. Scientific collaboration net-
works. Physical Review E 64, 016131.
M. E. J. Newman. 2003. The structure and function of
complex networks. SIAM Review 45, 167?256.
M. Peltoma?ki and M. Alava. 2006. Correlations in bi-
partite collaboration networks. Journal of Statistical
Mechanics: Theory and Experiment, P01010.
J. J. Ramasco, S. N. Dorogovtsev and R. Pastor-
Satorras. 2004. Self-organization of collaboration
networks. Physical Review E 70, 036106.
C. E. Shannon and W. Weaver. 1949. The Mathe-
matical Theory of Information. University of Illinois
Press, Urbana.
L. Steels. 2000. Language as a complex adaptive
system. In: Schoenauer, M., editor, Proceedings of
PPSN VI, LNCS, 17?26.
N. Trubetzkoy. 1931. Die phonologischen systeme.
TCLP 4, 96?116.
N. Trubetzkoy. 1969. Principles of Phonology. Eng-
lish translation of Grundzu?ge der Phonologie, 1939,
University of California Press, Berkeley.
608
Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 19?26,
Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language Processing
Prototype Machine Translation System From Text-To-Indian Sign 
Language 
Tirthankar Dasgupta 
IIT, Kharagpur 
tirtha@ 
cse.iitkgp.ernet.in 
Sandipan Dandpat 
IIT, Kharagpur 
sandipan@
cse.iitkgp.ernet.in 
Anupam Basu 
IIT, Kharagpur 
anupambas@ 
gmail.com 
Abstract 
This paper presents a prototype Text-To-
Indian Sign Language (ISL) translation 
system. The system will help dissemination 
of information to the deaf people in India. 
The current system takes English sentence 
as input, performs syntactic analysis, and 
generates the corresponding ISL structure. 
Since ISL does not have any written form, 
the output is represented in terms of pre-
recorded video streams. The system uses 
Lexical Functional Grammar (LFG) for-
malism for representing ISL syntax.   
1 Introduction 
The All India Federation of the deaf estimates 
around 4 million deaf people and more than 10 
million hard of hearing people in India (Zeshan et 
al, 2004). Studies revealed that, one out of every 
five deaf people in the world is from India. More 
than 1 million deaf adults and around 0.5 million 
deaf children in India uses Indian Sign Language 
(henceforth called ISL) as a mode of communica-
tion (Zeshan et al 2004). ISL is not only used by 
the deaf people but also by the hearing parents of 
the deaf children, the hearing children of deaf  
adults and hearing deaf educators (Zeshan et al 
2004).  
Due to their inability in accessing information 
through common broadcast modes like television, 
radio etc., and communication for the deaf com-
munity in common places like railway, bank, and 
hospitals is difficult.  
Efforts to extend the existing means of commu-
nication for the hearing impaired include close cir-
cuit captioning in television and communication 
through interpreter. The first approach assumes a 
good knowledge in written languages like English, 
Hindi, or Bengali. The second approach is not al-
ways practically feasible.  
A large section of the hearing impaired in India 
uses ISL as their mode of communication. How-
ever, due to the inherent difficulty in their written 
texts, an automatic Text-to-ISL translation system 
could help to make more information and services 
accessible to the hearing impaired. Moreover, the 
system will not only improve information access, 
but it can also be used as an educational tool to 
learn ISL.  
Though some work has been done on machine 
translation (MT) from English to American or Brit-
ish Sign Language (SL) (Huenerfauth, 2003), but 
for ISL, MT systems are still in its infancy. The 
underlying architecture for most of the systems are 
based on:  
 
I. Direct translation: This requires knowledge 
of both the source and the target language. 
Moreover, word order of the output may not 
be the desired one.  
II. Statistical MT: It requires large parallel cor-
pora    which is very difficult to collect. 
III. Transfer based architecture. As ISL does not   
relate to other SLs of either Asia or Europe 
(Zeshan, 2003), the existing systems transfer 
grammar rules cannot be applied to translate 
English to ISL.  
 
Further, some of the systems are domain specific 
in nature, and cannot be used to generic systems. 
Hence, most of the above systems remain unusable 
for the deaf community of India. This is the prime 
motivation behind building a generic English Text-
to-ISL translation system. 
The objective of this paper is to present a proto-
type English-to-ISL generic machine translation 
19
system. Currently the system takes simple English 
sentences as input and generates ISL-gloss which 
may then be converted into the Hamburg Notation 
System (HamNoSys)1 (Prillwitz et. al, 1989). The 
HamNoSys representation will provide signing 
instructions to the sign synthesis module, to gener-
ate an animated representation of ISL to the user. 
Lexical Functional grammar (LFG) f-structure is 
used to represent ISL syntax.  
The paper is organized as follows: Section 2 
presents linguistic issues related to ISL. Section 3 
presents a brief summery of the related works. Sec-
tion 4 presents the overall system architecture. Sec-
tion 5 presents system evaluation and results. Sec-
tion 6 presents the sign synthesis via HamNoSys, 
and Section 7 presents conclusion and future work.  
2 ISL Linguistic Issues 
Indian Sign Language (ISL) is a visual-spatial lan-
guage which provides linguistic information using 
hands, arms, face, and head/body postures. A sign 
is a sequential or parallel construction of its man-
ual and non-manual components. A manual com-
ponent can be defined by several parameters like 
hand shape, orientation, position, and movements 
where as non-manual components are defined by 
facial expressions, eye gaze, and head/body pos-
ture (Zeshan, 2003). However, there exist some 
signs which may contain only manual or non-
manual components. For example the sign ?Yes? is 
signed by vertical head nod and it has no manual 
component.  
ISL lexicon is categorized according to the spa-
tial behavior of the signs (Zeshan, 2003). There are 
three open lexical classes: i) Signs whose place of 
articulation are fixed, like, ?hand?, ?teeth?, ?eye?, 
?me?, and ?you? as shown in Fig. 1. ii) Signs 
whose place of articulation can change, like, 
?good,? ?friend,? and ?marry? as shown in Fig. 2. 
iii) Directional signs are those where there is a 
movement between two points in space. For exam-
ple, in the sentence ?I help him? the head word is 
?help? and direction of the sign is from subject ?I? 
to the object ?him? (Fig. 3). Directional signs gen-
erally show verbal property (Zeshan, 2003). Apart 
from the directional signs, ISL morphology is 
mostly derivational in nature and there are no af-
fixes in signs. The closed lexical class contains 
                                                 
1 www.sign-lang.uni-hamburg.de/Projekte/HamNoSys 
classifier hand shapes, discourse markers, and non-
manual signs (Zeshan, 2003). A classifier hand 
shape contains specification related to hand con-
figuration that represents the characteristics of a 
referent. For example, consider the sentence ?Put 
the cup on the table?. Here the hand configuration 
will contain shape of a ?cup? added with a move-
ment to express the event ?put?.  
ISL discourse structure is classified into manual 
and non-manual markers. Manual discourse mark-
ers can occur either in clause final position (as in, 
?it?s over, what else we can do??) or in clause ini-
tial position (like, ?well, I have nothing to say?). 
The non-manual marker like ?head nodding? oc-
curs only in clause final position after the last 
manual sign of the clause.  
 
             
Me Eye 
 
Fig.1: Signs whose place of articulation is fixed 
(Vasistha et. al 1998) 
 
 
 
 
Friend
 
 
 
 
Fig. 2: Signs whose place of ar-
ticulation can change (Vasistha 
et. al 1998)
 
 
Fig. 3:  Directional Sign, ?I help you?. Taken 
from AYJNIHH workbook video CD.  
3 The State-of-Art for Text-to-Sign Lan-
guage 
In spite of the advancements in modern computer 
science technology, there is a paucity of research 
in developing machine translation (MT) system on 
sign language particularly in India (Zeshan et al 
2004). Some of the MT systems for other sign lan-
20
guage are briefly described below. The underlying 
MT architecture can be classified into i) Direct 
translation system, ii) Transfer based architecture 
and iii) Statistical MT. 
The direct translation approach generates the SL 
by direct replacement of the words of input English 
sentence. Generally the word order of the SL re-
mains the same as that of the English text. How-
ever, as in the case of English to ISL, the target SL 
may not allow the same word order. Also, the sys-
tem assumes a strong knowledge of both the Eng-
lish as well as the target SL. 
Some of the direct translation systems include:  
 
? TESSA: A Speech-To-British Sign Language 
(BSL) translation system that aims to provide a 
communication aid between a deaf person and a 
Post Office clerk. The system uses formulaic 
grammar approach where a set of pre-defined 
phrases are stored and translation is done by us-
ing a phrase lookup table. However, the use of 
small set of sentences as templates makes 
TESSA a very domain specific system. It as-
sumes a very restricted discourse between the 
participants (Cox, 2002). 
? The SignSynth project (Grieve- smith 1998; 
Grieve-smith, 1999) uses ASCII-Stokoe model 
for the representation of Signs. The animated 
output is generated by converting ASCII-Stokoe 
into VRML (Virtual Reality Modeling Lan-
guage). In his another project Grieve-Smith pro-
posed a Text to American Sign Language (ASL) 
machine translation system. The system has been 
evaluated in the weather information domain. 
 
In a transfer architecture system, the source lan-
guage representation is transformed into a suitable 
syntactically/semantically correct target language 
form by applying proper transfer grammar rules. 
These rules are dependent upon both the source 
and the target language. However, as the 
source/target language changes new rules are need 
to be added. The transfer grammar approach is not 
only used in text to SL MT systems but also in 
text-to-text MT systems, like the Shakti MT sys-
tem which is used to translate English text to Hindi 
(Bharati et. al., 2001; Bharati et. al., 2003). The 
transfer architecture systems include: 
 
? The ViSiCAST translator, which is a English to 
British Sign Language (BSL) translation tool 
(Marshall & S?f?r, 2001; Bangham et al, 2000). 
The system uses HPSG (Pollard and Sag, 1994) 
formalism to represent source text into BSL and 
the grammar is implemented using a Prolog based 
system ALE. The system handles discourse phe-
nomena by using Discourse Representation Struc-
ture (DRS) (Bos et. al, 1994) and the phonology is 
represented in HamNoSys. This is one of the most 
successful system developed so far (Huenerfauth, 
2003). 
? The ASL workbench (Speers, 2001) is a Text-
To-ASL MT system which uses Lexical Functional 
Grammar (LFG) (Kaplan, 1989) formalism to rep-
resent English f-structure into ASL. The system 
uses a very sophisticated phonological model 
which is based on Movement-Hold principle of 
ASL phonology (Lidell & Johnson 1989). 
? The TEAM project is a Text-To-ASL translation 
system where, the STAG (Synchronous Tree Ad-
joining Grammar) formalism is used to represent 
source text into ASL syntactic structure (Zhao et 
al, 2000). The system maintains a bilingual lexicon 
to identify the valid word-sign pair. The output of 
the linguistic module was a written ASL gloss no-
tation. The manual and non-manual information, 
including the morphological variation, are embed-
ded with in the ASL gloss notation. The output of 
the synthesis module uses animated human models 
(Avatar). 
 
In addition, An Example based MT system for 
English-Dutch sign language was proposed by 
(Morrissey and Way, 2005). Stein et.al. (2006) has 
proposed a statistical MT system which uses Hid-
den Markov Model and IBM models for training 
the data. However, due to paucity of well anno-
tated corpora, the system has been evaluated using 
a very small set of data. 
3.1 Indian Scenario 
INGIT is a Hindi-To-Indian Sign Language (ISL) 
Machine Translation system has been built for the 
railway reservation domain (Kar et. al, 2006). The 
system takes input from the reservation clerk and 
translates into ISL. The output of the system is an 
animated representation of the ISL-gloss strings 
via HamNoSys. INGIT is based on Hybrid-
formulaic grammar approach unlike TESSA which 
uses purely formulaic approach. Here, Fluid Con-
struction Grammar (FCG) (Steels and Beule, 2006) 
21
is used to implement the Formulaic grammar. This 
is the only Hindi text-to-ISL machine translation 
tool encountered by us so far. However, the system 
is domain specific in nature and cannot be used for 
generic purpose. Further, the system does not have 
to handle any structural divergence between the 
source and the target language, as in most of the 
cases both Hindi and ISL show the same word or-
der. 
4 ISL MT Architecture 
In order to overcome the above mentioned prob-
lem, we initially developed a direct translation sys-
tem, however due to its inherent drawbacks, as 
mentioned in section 3, we need some other ap-
proach. One of the most popular techniques is to 
use statistical or case based MT system. However 
ISL does not have any written form, so it is very 
difficult to find any natural source of parallel cor-
pora. Niedle et al (2000) have proposed an ap-
proach to collect corpus for statistical MT research, 
in his approach first, annotation standard for the 
various hand shape movements was developed, 
then the Sign Language performances were re-
corded, and finally the recorded videos were 
manually transcribed. This is a very slow and ex-
pensive process. Due to the difficulty in obtaining 
parallel corpora of ISL, the statistical MT ap-
proaches may not be a feasible solution to our 
problem. Hence we decided to build a rule based 
transfer grammar MT system discussed in this sec-
tion. 
The system architecture of the proposed English 
Text-To-ISL MT system is composed of the fol-
lowing four essential modules (see Fig. 4): 
 
1. Input text preprocessor and parser 
2. LFG f-structure representation 
3. Transfer Grammar Rules 
4. ISL Sentence Generation 
5. ISL  synthesis 
4.1 Text Analysis & Syntactic Parsing 
The current Text-To-ISL translator takes simple 
English sentence as an input to the parser. We de-
fine simple sentence as, a sentence containing only 
one main verb. The input sentence is then parsed 
using the Minipar parser (Lin, 1998) and a depend-
ency structure is constructed from the parse tree. 
However, before parsing, the input text is passed to 
the preprocessing unit, where we try to identify the 
frozen phrases2 and temporal expressions3 which 
the syntactic parser is unable to identify. We pre-
pare a phrase lookup table consisting of 350 frozen 
phrases and temporal expressions which are identi-
fied before the input text is parsed. The parsing 
stage also includes classification of plural nouns. 
The plurality is identified using an English mor-
phological analyzer. 
 
 
 
Fig. 4: Architecture of the Text-to-ISL MT system 
4.2 LFG Representation 
The Minipar generated dependency structure is 
more akin towards the LFG functional structure (f-
structure). The f-structure encodes grammatical 
relation (like subject, object, and tense) of the input 
sentence. It represents the internal structure of a 
sentence. This includes the representation of the 
higher syntactic and functional information of a 
sentence. This higher syntactic and functional in-
formation of a sentence is represented as a set of 
attribute-value pairs. In an attribute-value pair, the 
attribute corresponds to the name of a grammatical 
symbol (e.g. NUM, TENSE) or a syntactic function 
(e.g. SUBJ, OBJ) and the value is the corresponding 
feature possessed by the concerning constituent. 
For example, Fig. 5 shows the attribute-value pair 
for the sentence ?John Played Cricket?. The main 
advantage of f-structure is in its abstract represen-
tation of syntactic and grammatical information of 
a sentence. 
 
                                                 
2 Phrases that are composed of Idioms, and Metaphor 
3 Temporal Expressions contains Time, Day and Date. 
22
 
 
 
 
 
 
 
 
 F
4.3 ISL Generation 
In the generation stage, English f-structure is con-
verted to ISL f-structure by applying proper trans-
fer grammar rules. Two main operations are per-
formed during the generation phase: a) Lexical 
selection and b) Word order correspondence. 
Lexical selection is done using an English-ISL bi-
lingual lexicon. For example word like ?Dinner? in 
English is replaced by ?NIGHT FOOD? in ISL and 
?Mumbai? is replaced by the sign of ?BOMBAY?. 
 
(1) English: ?I had dinner with Sita? 
      ISL: ?I SITA WITH NIGHT FOOD FINISH? 
 
ISL has essentially a Subject-Object-Verb word 
order (unlike English which is Subject-Verb-
Object). For Example, (2) shows the change in 
word order from English to ISL.  
 
(2)  English: ?I have a computer? 
 ISL: ?I COMPUTER HAVE?. 
 
However, in some cases the sign sentence de-
pends upon the directionality of the verb as in (3). 
 
(3) English: ?I help you? 
 ISL: ?HELP + < hand movement from I-
            to-YOU>?. 
 
For sentences having only a subject and a verb, 
the subject always precedes the verb. Like: 
 
(4) English: ?The woman is deaf? 
 ISL:  ?WOMAN DEAF?. 
 
However, if the sentence contains a dummy sub-
ject (5), then the subject is removed from the out-
put. 
 
 (5) English: ?It is raining outside? 
 ISL: ?OUTSIDE RAINING? 
For negative sentences, a negation mark is used 
after the verb (6). The second bracket indicates a 
parallel non-manual component is attached with 
the sign ?LATE?.  
 
 (6) English: ?I am not late?  
 ISL: ?I {LATE + NOT}?. 
 
ig. 5: Attribute-Value pair for the sentence ISL has separate rules to handle adjectives oc-
curring before a noun. In most of the cases an ad-
jective must occur after the noun. However, if the 
adjective specifies a color then it should precede 
the noun (see (7) & (8)).  
?John Played Cricket? 
 
(7) English: ?The beautiful girl is playing?  
 ISL: ?GIRL BEAUTIFUL PLAY?  
 
(8) English: ?I see a black cat?  
 ISL: ?I BLACK CAT SEE?. 
 
WH-Interrogative markers (like who, what, 
when, and why) always occur at the end of the sen-
tence.  
 
 (9) English: ?When is your birthday?? 
 ISL: ?YOUR BIRTHDAY TIME+  
            QUESTION?. 
 
In case of yes/no type of questions, the sentence 
is followed by a non-manual yes-no marker 
(Zeshan, 2004). 
 
(10) English: ?Is the man deaf?? 
 ISL: ?MAN {DEAF} yes-no? 
 
Since ISL does not have any articles or conjunc-
tions, they are removed from the generated output 
as shown in example (2)-(10). 
5 System Evaluation  
Evaluating a Text-to-ISL MT system is difficult 
due to the absence of ISL written orthography. 
Hence, standard techniques for evaluating Text-
Text MT systems are not applicable for Text-to-
ISL systems. However, we have evaluated the sys-
tem based on the feedbacks of the ISL experts. The 
generated outputs of the system are shown to the 
ISL experts and are classified as either valid or 
invalid according to their understandability and 
quality. The system was evaluated on a set of 208 
23
sentences4. Table 1.1 summarizes the performance 
of the system. The overall system performance is 
around 90%. Most of the errors are due to com-
pound sentences and directional verbs5. To under-
stand the relative performance of the system on the 
simple sentences, we conducted two experiments 
removing compound construction and directional 
verbs. From the current experimental set up, 7% 
errors are propagated due to directional verbs and 
around 4% errors are due to compound construc-
tions.  
 
 No. of Sentences 
Accuracy 
(%) 
Overall Corpus size 208 89.4 
Sentences without di-
rectional verbs 193 96.37 
Sentences without 
compound construc-
tions 
201 92.53 
 
6 ISL Synthesis 
The ISL sentences thus generated are displayed via 
a stream of pre recorded videos or icons. However, 
it has been observed that the current approach of 
ISL synthesis is highly criticized (Grieve-Smith, 
1999). As, representing ISL signs by pre-recorded 
video will result in loss of information related to 
discourse, classifier predicate, and directionality of 
sign. Also, storing sign video takes a lot of mem-
ory overhead. To overcome this crisis further de-
velopments are in progress. We represent ISL signs 
by HamNoSys and the generated HamNoSys string 
will be passed to the signing avatar.  
6.1 HamNoSys 
Sign language does not have any written form. In 
order to define a sign we need a notation system. 
The Hamburg sign language Notation system 
(HamNoSys) is a phonetic transcription system 
used to transcribe signing gestures. It is a syntactic 
representation of a sign to facilitate computer 
processing. HamNoSys is composed of several 
parameters by which a signing gesture can be de-
fined like: 
                                                 
4  Corpus collected from ??A? level Introductory course in 
Indian Sign Language? Work Book AYJNIHH. 
5 Verbs corresponding to directional signs.
 
? Dominant hand?s shape. 
? Hand location with respect to the body. 
? Extended finger orientation. 
? Palm orientation 
? Movements (straight, circular or curved) 
? Non-manual signs. 
 
Fig. 9 shows an example where HamNoSys 
representation of the word ?WOMAN? is ex-
plained.  
 
 
 
 
 
 
In this example, the parameters like movement 
and non-manual signs are not present, as the sign 
?WOMAN? in ISL does not have these expres-
sions. Fig. 10 shows the ISL representation of 
?WOMAN?. 
 
 
 
 
7 Conclusion and Future works 
The paper presents a prototype text to ISL transla-
tion system. Our approach uses LFG f-structure to 
represent ISL syntax. As ISL does not have any 
written form, there is no standard source of ISL 
corpus. Hence, statistical MT methods are not fea-
sible under such a condition. Our system is still 
under development stage. The sign synthesis mod-
ule using an animated avatar has not been devel-
oped yet. We generate ISL output using pre-
recorded ISL videos. Further morphological func-
tionalities like, discourse, directionality, and classi-
fier predicates are handled minimally 
Table1.1: Evaluation Results 
Fig. 9: HamNoSys representation of ?WOMAN? 
Fig. 10: Sign of  ?WOMAN? 
(Vashista et.al, 1998) 
Extended Finger orientation
Handshape
Location
Palm
?? \  ???  
24
In the next stage of our work, we will try to 
handle directional sign, discourse, and classifiers. 
The sign representation should be done using an 
animated avatar via HamNoSys notation. We will 
also develop the sign annotation tool and finally, a 
larger corpus will be built for a better evaluation 
and results. 
References 
N. Badler, R. Bindiganavale, J. Allbeck, W. Schuler, L. 
Zhao, S. Lee, H. Shin, and M. Palmer 2000. Param-
eterized Action Representation and Natural Language 
Instructions for Dynamic Behavior Modification of 
Embodied Agents. AAAI Spring Symposium.  
J. A. Bangham, S. J. Cox, R. Elliot, J. R. W. Glauert, I. 
Marshall, S. Rankov, and M. Wells. 2000. Virtual 
signing: Capture, animation, storage and transmission 
? An overview of the ViSiCAST project. IEEE Semi-
nar on Speech and language processing for disabled 
and elderly people. 
A. Bharati, D. M. Sharma, R. Sangal. 2001. AnnCorra : 
An Introduction, Technical Report no: TR-LTRC-
014, LTRC, IIIT Hyderabad, Mar 2001, 
http://www.iiit.net/ltrc/ Publications/Techreports/TR-
LTRC-14 
A. Bharati, R. Moona, P. Reddy, B. Sankar, D.M. 
Sharma, R. Sangal, Machine Translation: The Shakti 
Approach, Pre-Conference Tutorial at ICON-2003. 
J. Bos, E. Mastenbroek, S. McGlashan, S. Millies, M. 
Pinkal. 1994. A Compositional DRS-based Formal-
ism for NLP Applications. Report 59. Universitaet 
des Saarlandes.  
S. Cox, M. Lincoln, J. Tryggvason, M. Nakisa, M . 
Wells, M. Tutt, S. Abbott. 2002. Tessa, a system to 
aid communication with deaf people. Fifth interna-
tional ACM conference on Assistive technologies. 
M. Huenerfauth. 2003. A Survey and Critique of 
American Sign Language Natural Language Genera-
tion and Machine Translation Systems. Technical Re-
port MS-CIS-03-32, Computer and Information Sci-
ence, University of Pennsylvania. 
A. Joshi, L. Levy and M. Takahashi. 1975. Tree Ad-
junct Grammar. Journal of computer and system sci-
ences. 
P. Kar, M. Reddy, A. Mukherjee, A. M. Raina. 2007. 
INGIT: Limited Domain Formulaic Translation from 
Hindi Strings to Indian Sign Language. ICON. 
Ronald M. Kaplan. 1989. The formal architecture of 
lexical-functional grammar. Journal of Information-
Science and Engineering 5: 305-322.  
Scott Liddell and R. E. Johnson. 1989. American Sign 
Language: The phonological base. Sign Language 
Studies 64: 195-277. 
D. Lin. 1998. Dependency-based evaluation of MINI-
PAR. In Workshop on the Evaluation of Parsing Sys-
tems, Granada, Spain,  
I. Marshall and ?. S?f?r. 2001. Extraction of semantic 
representations from syntactic SMU link grammar 
linkages.. In G. Angelova, editor, Proceedings of Re-
cent Advances in Natural Lanugage Processing, pp: 
154-159, Tzigov Chark, Bulgaria, September. 
S. Morrissey and A. Way. 2005. An Example-Based 
Approach to Translating Sign Language. In Proceed-
ings of Workshop Example-Based Machine Transla-
tion (MT X -05), Phuket, Thailand. 
C. Neidle, J. Kegl, D. MacLaughlin, B. Bahan, and R. 
G. Lee. 2000. The Syntax of American Sign Lan-
guage: Functional Categories and Hierarchical 
Structure. Cambridge, MA: The MIT Press. 
C. J. Pollard, and I. A. Sag. 1994. Head-driven Phrase 
Structure Grammar. University of Chicago Press, 
Chicago, IL. 
S. Prillwitz, R. Leven, H. Zienert, T. Hamke, and J. 
Henning. 1989. HamNoSys Version 2.0: Hamburg 
Notation System for Sign Languages: An Introduc-
tory Guide, volume 5 of International Studies on Sign 
Language and Communication of the Deaf. Signum 
Press, Hamburg, Germany,  
?. S?f?r and I. Marshall. 2001. .The architecture of an 
English-text-to-Sign-Languages translation system.. 
In G. Angelova, editor, Recent Advances in Natural 
Language Processing (RANLP), pp: 223-228. Tzigov 
Chark, Bulgaria. 
G. Angus Smith. 1998. Sign synthesis and sign phonol-
ogy. Proceedings of the First High Desert  Student 
Conference in Linguistics. 
G. Angus Smith. 1999. English to American Sign Lan-
guage machine translation of weather reports. Pro-
ceedings of the Second High Desert Student Confer-
ence in Linguistics. 
A. Speers. 1995. SL-Corpus: A computer tool for sign 
language corpora. Georgetown University.  
A. Speers. 2001. Representation of American Sign Lan-
guage for Machine Translation. PhD Dissertation, 
Department of Linguistics, Georgetown University. 
L. Steels and J. Beule. 2006, Unify and Merge in Fluid 
Construction Grammar, In: Lyon C., Nehaniv, L. & 
A. Cangelosi, Emergence and Evolution of Linguistic 
Communication, Lecture Notes in Computer Science. 
Springe-Verlag: Berlin,. 
25
D. Stein, J. Bungeroth and H. Ney. 2006. Morpho-
Syntax Based Statistical Methods for Sign Language 
Translation. In Proceedings of the 11th Annual 
conference of the European Association for Machine 
Translation. Oslo, Norway. 
M. Vasishta, J. Woodward and S. DeSantis. 1998. An 
Introduction to Indian Sign Language. All India Fed-
eration of the Deaf  (Third Edition). 
Elizabeth Winston. 1993. Spatial mapping in compara-
tive discourse frames in an American Sign Language 
lecture. Doctor of Philosophy in Linguistics diss., 
Georgetown University. 
L. Zhao, K. Kipper, W. Schuler, C. Vogler, N. Badler, 
and M. Palmer. 2000. A Machine Translation System 
from English to American Sign Language. Associa-
tion for Machine Translation in the Americas. 
U. Zeshan. 2003. Indo-Pakistani Sign Language Gram-
mar: A Typological Outline. Sign Language Studies - 
Volume 3, Number 2 , pp. 157-212. 
U. Zeshan. 2004. Interrogative Constructions in Signed 
Languages. Crosslinguistic Perspectives Language - 
Volume 80, Number 1, pp. 7-39. 
U. Zeshan, M. Vasishta, M. Sethna. 2004. Implementa-
tion of Indian sign language in educational settings- 
Volume 15, Number 2, Asia Pacific Disability Reha-
bilitation Journal, pp. 15-35 
26
A Multilingual Multimedia Indian Sign Language Dictionary Tool 
Tirthankar 
Dasgupta 
IIT, Kharagpur 
tirtha@iitkgp
.ernet.in 
Sambit 
Shukla 
NIT, Rourkela 
sks.at.nit
r@gmail.co
m 
Sandeep 
Kumar 
NIT, Allahabad. 
mnnit.sand
eep@gmail.
com 
Synny Diwakar 
NIT, Suratkal 
sunny.diwaka
rnitk@gmail.
com 
Anupam Basu 
IIT, Kharagpur 
Anupam-
bas@gmail.
com 
 
Abstract 
This paper presents a cross platform multi-
lingual multimedia Indian Sign Language 
(ISL) dictionary building tool. ISL is a lin-
guistically under-investigated language 
with no source of well documented elec-
tronic data. Research on ISL linguistics 
also gets hindered due to a lack of ISL 
knowledge and the unavailability of any 
educational tools. Our system can be used 
to associate signs corresponding to a given 
text. The current system also facilitates the 
phonological annotation of Indian signs in 
the form of HamNoSys structure. The gen-
erated HamNoSys string can be given as 
input to an avatar module to produce an 
animated sign representation.  
1 Introduction 
A sign language is a visual-gesture language that 
uses hand, arm, body, and face to convey thoughts 
and meanings. It is a language that is commonly 
developed in deaf communities, which includes 
deaf people, their friends and families as well as 
people who are hard of hearing. Despite common 
misconceptions, sign languages are complete natu-
ral languages, with their own syntax and grammar. 
However, sign languages are not universal. As is 
the case in spoken language, every country has got 
its own sign language with high degree of gram-
matical variations.  
 The sign language used in India is com-
monly known as Indian Sign Language (hence-
forth called ISL). However, it has been argued that 
possibly the same SL is used in Nepal, Sri Lanka, 
Bangladesh, and border regions of Pakistan 
(Zeshan et al, 2004). Different dialects of ISL 
with broad lexical variation are found in different 
parts of the Indian subcontinent. However, the 
grammatical structure is same for all dialects 
(Zeshan, 2003).  
The All India Federation of the Deaf estimates 
around 4 million deaf people and more than 10 
million hard of hearing people in India (Zeshan et 
al, 2004). Studies revealed that, one out of every 
five deaf people in the world are from India. More 
than 1 million deaf adults and around 0.5 million 
deaf children uses Indian Sign Language as a 
mode of communication (Zeshan et al 2004). 
However, an UNESCO report (1980) found that 
only 5% of the deaf get any education in India. 
The reason behind such a low literacy rate can be 
due to the following reasons: a) Till the early 20th 
century, deafness in India, is considered as a pun-
ishment for sins and signing is strictly discouraged 
(Zeshan et. al, 2004). b) Until the late 1970?s, it 
has been believed that, there were no such lan-
guage called ISL. c) Lack of research in ISL lin-
guistics. d) Unavailability of well documented and 
annotated ISL lexicon. e) Unavailability of any 
ISL learning tool. f) Difficulties in getting sign 
language interpreters. 
 Linguistic studies on ISL were started 
around 1978 and it has been found that ISL is a 
complete natural language, instigated in India, 
having its own morphology, phonology, syntax, 
and grammar (Vasishta et. al, 1978; Zeshan et.al, 
2004). The research on ISL linguistics and phono-
logical studies get hindered due to lack of linguis-
tically annotated and well documented ISL data. A 
dictionary of around 1000 signs in four different 
regional varieties was released (Vasishta et.al, 
The 6th Workshop on Asian Languae Resources, 2008
57
1978). However, these signs are based on graphi-
cal icons which are not only difficult to understand 
but also lack phonological features like move-
ments and non-manual expressions.  
As it has been specified above,  ISL is not only 
used by the deaf people but also by the hearing 
parents of the deaf children, the hearing children 
of deaf  adults and hearing deaf educators (Zeshan 
et al 2004). Therefore the need to build a system 
that can associate signs to the words of spoken 
language, and which can further be used to learn 
ISL, is significant. Further associating signs of 
different SL (like ASL1 , BSL2 and ISL) to a word 
will help the user to learn foreign SLs simultane-
ously. 
 Several works have been done on building 
multimedia-based foreign SL dictionaries as dis-
cussed in (Buttussi et. al., 2007). However no such 
system is currently available for ISL. moreover, 
most of the current systems suffer from the follow-
ing limitations:  
? Most of the systems are native language specific 
and hence, cannot be used for ISL.  
? Most of the systems provide a word-sign search 
but very few systems provide a sign-word or 
sign-sign search. 
? Very few systems are cross platform. 
? Systems lack sophisticated phonological infor-
mation like hand-shape, orientations, move-
ments, and non-manual signs.  
In order to overcome the above mentioned crisis, 
and based on the limitations of the current sys-
tems, our objective is to: 
? Build a cross platform multilingual multimedia 
SL-Dictionary tool which can be used to create a 
large SL lexicon.  
? This tool can be used to associate signs to the 
words, phrases, or sentences of a spoken lan-
guage text.  
? The sign associated with each word is composed 
of its related part-of-speech and semantic senses.  
? The input text (word, phrase, or a sentence) may 
be in any language (like English or Hindi) and 
the associated sign can be in any standard sign 
language (ASL or ISL).  
? This tool can also be used to associate complex 
SL phonological features like hand shape, palm 
                                                 
                                                
1 ASL: American Sign Language. 
2 BSL: British Sign Language. 
orientation, locations, movements, and non-
manual expressions.  
? The phonological features are expressed in terms 
of HamNoSys (Prillwitz et. al, 1989). 
? Facilitate search options like word-sign and 
search by HamNoSys. 
? The generated lexicon is exported in XML file 
format and the sign is stored in the form of digi-
tal videos.  
? The video segments are captured using webcams 
connected with the system. It is possible to at-
tach multiple webcams to the system to capture 
video segments from multiple angles. This fea-
ture enables a user to better understand some of 
the complex sign language attributes. 
 
The organization of the paper is as follows: Sec-
tion 2 gives a brief introduction to ISL phonology. 
Section 3 presents related works on ISL Diction-
ary. Section 4 presents the overall system architec-
ture of the SL-dictionary tool. Section 5 and 6 pre-
sents a brief discussion related HamNoSys repre-
sentation, and the HamNoSys editor. Section 7 
presents conclusion and future work. 
2 ISL Phonology 
Indian Sign Language (ISL) is a visual-spatial lan-
guage which provides linguistic information using 
hands, arms, face, and head/body postures. The 
signer often uses the 3D space around his body to 
describe an event (Zeshan, 2003). Unlike spoken 
languages where the communication medium is 
dependent on sound, in sign language, the com-
munication medium depends upon the visual 
channel. In spoken language, a word is composed 
of phonemes. Two words can be distinguished by 
at least one phoneme. In SL, a sign is composed of 
cheremes3 and similarly two signs can differ by at 
least one chereme (Stokoe, 1978). A sign is a se-
quential or parallel construction of its manual and 
non-manual cheremes. A manual chereme can be 
defined by several parameters like: 
? Hand shape. 
? Hand location 
? Orientation. 
? Movements (straight, circular or curved) 
 
3 The term chereme (originally proposed by William 
Stokoe (Stokoe, 1978)) in Greek means ?hand?. It is 
equivalent to the phonemes of spoken languages.   
The 6th Workshop on Asian Languae Resources, 2008
58
Non-manual cheremes are defined by: 
? Facial expressions. 
? Eye gaze and Head/body posture (Zeshan, 
2003). 
However, there exist some signs which may con-
tain only manual or non-manual components. For 
example the sign ?Yes? is signed by vertical head 
nod and it has no manual component. 
ISL signs can be generally classified into three 
classes: One handed, two handed, and non-manual 
signs. Fig. 1 shows the overall Indian sign hierar-
chy. 
 
Fig. 1: ISL Type Hierarchy 
 
One handed signs: the one handed signs are repre-
sented by a single dominating hand. One handed 
signs can be either static or movement related. 
Each of the static and movement signs is further 
classified into manual and non-manual signs. Fig. 
2 shows examples of one handed static signs with 
non-manual and manual components.  
                 
Fig. 2: One Handed static manual sign (Ear) and 
non-manual sign (Headache).   
      
Two hand signs: As in the case of one hand signs, 
similar classification can be applied to two handed 
signs. However, two handed signs with move-
ments can be further distinguished as:  
Type0: Signs where both hands are active (see Fig 
3). 
Type1: Signs where one hand (dominant) is more 
active compared to the other hand (non-dominant) 
as shown in Fig 3. 
 
           
Flag 
Long 
Fig.3 : Two handed sign "long"(both the hands are 
moving) and ?Flag? (only the dominant right hand 
is moving) 
3 Related works on ISL dictionary 
Linguistic studies on ISL are in their infancy as 
compared to other natural languages like English, 
Hindi, or Bengali and also to other SLs. Linguistic 
work on ISL began during late 1970?s. Before that, 
the existence of ISL was not acknowledged. In 
1977 a survey was conducted (see Vasistha et. al., 
1998 for documentation) and it was revealed that 
ISL is a complete natural language instigated at 
the Indian subcontinent. Vasistha collected signs 
from four major states of India (Delhi, Mumbai, 
Kolkata, and Bangalore) and released four diction-
aries of ISL regional varieties. The Ramkrishna 
Mission vidyalaya, Coimbatore has published an-
other ISL dictionary in 2001. However, all these 
dictionaries are based on iconic representations of 
signs. As a result some of the important phono-
logical information like, movements and non-
manual expression gets lost. No other work of its 
kind has so far been reported (Zeshan, 2004).  
 Several works have been done in building 
ASL and BSL dictionary tools. Some of the sys-
tems are briefly discussed below: 
Headache Ear 
? (Wilcox et. al, 1994) developed a multimedia 
ASL dictionary tool, which prerecorded digital 
video frames. 
? (Geitz et.al, 1996) developed a VRML based 
ASL finger spelled system, which ran on inter-
net. 
? Sign Smith (VCOM3D, 2004) is a 3D illustrated 
dictionary of ASL. It is also used as educational 
software as well as an authoring tool to create 
ASL content.  
? (Buttussi et. al, 2007) proposes an Italian Sign 
Language dictionary tool. This tool uses H-
animator to generate signing avatar. This tool 
provides multiple search functionality like word-
sign, sign-word, and sign-sign search. This tool 
also facilitates association of one or more SL for 
a given input word.     
The 6th Workshop on Asian Languae Resources, 2008
59
4 SL-Dictionary 
The primary objective of the SL-dictionary tool is 
to provide an easy to use GUI to create a multilin-
gual multimedia SL dictionary by which a user can 
associate signs as well as the parameters defining a 
sign, corresponding to a given text. The overall 
architecture of the system is shown in Fig. 4. The 
system has been divided into two modules: a) Ex-
pert module and b) User Module.  
 The expert module has got three main 
units: a) Input Text Processing Unit b) Visual Data 
Capture Unit (VDCU) c) Sign Storage Unit and d) 
HamNoSys Editor.  
Input Text Processing Unit: In this unit a SL ex-
pert chooses the input spoken language (like, Eng-
lish, or Hindi) and the target sign language (like, 
ISL, or ASL) and then enters a text. The input to 
the system may be word, phrase, or sentences. If 
the text is a word the system generates all possible 
meanings, with the help of WordNet4, along with 
the part of speech (POS)5 of that particular word. 
In order to get the exact part-of-speech of a word, 
the SL expert has to enter an example sentence 
corresponding to that word. This sentence is given 
as an input to the POS-tagger to get the correct 
POS of the word. A word may have multiple 
senses as returned by WordNet. The user can se-
lect one or more senses from the list. 
Visual Data Capture Unit: Sign corresponding to a 
word sense is signed by the user which is captured 
by the Visual Data Capture Unit (VDCU). The 
VDCU is connected through multiple webcams, 
placed at different angular positions with respect 
to the signer. As a result different articulation 
points of a signs are getting stored with in the da-
tabase. This will enable the SL learner to under-
stand a particular sign easily. Fig.5 shows how a 
sign from multiple angles is getting captured. 
Storage Unit: The input text along with its anno-
tated information, the digital video sign, and the 
phonological parameters defining the sign are 
stored with in a database which is further exported 
into an XML formatted file (see Fig. 6). The pho-
nological parameters are expressed in the form of 
HamNoSys (discussed in section 5). 
                                                 
4 wordnet.princeton.edu/ 
5 We have used the Stanford Part-of-Speech tagger 
(nlp.stanford.edu/software/tagger.shtml) 
 
Fig. 4: System Architecture of ISL-Dictionary 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.5: capturing video signs from multiple angle 
 
 
Fig.6: The ISL-dictionary XML Format 
 
Searching: The search engine of the current sys-
tem takes a spoken language text as input parses 
the XML formatted dictionary and sequentially 
searches the dictionary. If a match is found, then 
The 6th Workshop on Asian Languae Resources, 2008
60
the sign corresponding to the lexical entry is being 
displayed. 
5 Sign language notation systems 
As it has been mentioned above, Sign language 
does not have any written form. Hence, In order to 
define a sign we need some notation system. There 
are a number of phonological notation systems for 
the representation of SL as discussed in (Smith 
et.al, 2003). One of the popular among them is 
Stokoe notation (Stokoe, 2003; Smith et.al, 2003). 
Stokoe defines a sign by three parameters: a) 
Hand-shape or designator (dez) b) location or 
place of articulation with respect to the body (tab) 
and c) movements or signation (sig). 
 HamNoSys (Prillwitz et. al, 1989) is a 
phonetic transcription system, based on Stokoe 
notation, used to transcribe signing gestures. It is a 
syntactic representation of a sign to facilitate com-
puter processing. HamNoSys extends the tradi-
tional Stokoe based notation system by further 
expanding sign representation by some more pa-
rameters. These parameters can be defined as: 
? Dominant hand?s shape. 
? Location of the dominant and the non-dominant 
hand with respect to the body. 
? Extended finger orientation of both dominant 
and non-dominant hand. 
? Palm orientation of both hands. 
? Movements (straight, circular, or curved) 
? Non-manual signs. 
Fig. 7 shows examples of different HamNoSys 
symbols and their descriptions. 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
Fig. 8 shows an example where HamNoSys repre-
sentation of the word ?WOMAN? is explained. 
Here, the parameters like movement and non-
manual signs are not present, as the sign 
?WOMAN? in ISL does not have these expres-
sions. Fig.9 shows the ISL representation of 
?WOMAN?.  
 
 
             
 
 
 
 
Fig. 8: HamNoSys representation of ?WOMAN? 
                            
 
 
 
  
           
6 HamNoSys Editor 
Transcribing a sign by HamNoSys is not a trivial 
task. A user who is transcribing a sign should be 
an expert in both HamNoSys as well as ISL. 
Moreover he has to remember all the HamNoSys 
symbols and their corresponding meanings in or-
der to define a sign. In India it is very difficult to 
find such a person. Hence our main goal behind 
building a HamNoSys editor is that, it can be used 
by an ISL expert with little or no knowledge in 
HamNoSys. The tool should provide an easy to 
use GUI that can be used to transcribe 
phonological information of a sign. 
 The HamNoSys editor provides a set of 
graphical images (most of the images are collected 
from www.sign-lang.uni-amburg.de/Projekte/ 
HamNoSys) for most of the phonological parame-
ters of a sign, like, Hand-shape, orientation, loca-
tion and movements. Based on the parameters, an 
ISL expert can choose a set of images and the sys-
tem will automatically generate the corresponding 
HamNoSys of the sign. This HamNoSys string can 
be given as an input to a signing avatar module to 
generate animated sign representation. 
 A signing avatar is a virtual human char-
acter that performs sign language. However, this 
character needs a set of instructions which will 
guide its movement. These instructions can be 
provided in the form of HamNoSys (Marshall and 
S?f?r, 2001). 
Fig.7: HamNoSys symbols and there descriptions
Palm 
Extended Finger orientation 
?? \  ???  H   f  v?? 
Handshape 
Location 
Fig.9: Sign of ?WOMAN? 
The 6th Workshop on Asian Languae Resources, 2008
61
   
 
Fig, 11: Twelve basic hand-shape classes 
 
Fig.10: HamNoSys Parameters
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.12: GUI to express finger and palm orientations 
Fig.13: GUI to choose various hand locations     
near the human face 
The 6th Workshop on Asian Languae Resources, 2008
62
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 14: GUI showing various straight movement parameters
 
Fig.10 shows the five basic parameters of Ham-
NoSys. For each of these parameters there exist 
interfaces through which a SL expert can choose 
the desired parameters to define a sign. For exam-
ple, the right hand side of Fig.11 shows the twelve 
basic hand-shape classes. Each of these base hand-
shapes may contain several derived hand-shapes as 
defined in HamNoSys (version 4.0). If a particular 
hand-shape is selected, then the HamNoSys sym-
bol corresponding to the hand-shape gets stored in 
the XML database (see Fig.6). Similarly, separate 
interfaces have been provided to identify palm 
orientation (see Fig,12), hand location (see 
Fig.13), movements (see Fig.14), and non-manual 
signs.   
 Due to its symbolic structure, HamNoSys 
is fairly easy to write, and understand. However, 
there are some drawbacks on this notation system 
that make it difficult to be used universally for all 
sign languages (Smith and Edmondson, 2004). For 
example, HamNoSys uses some fixed set of sym-
bols to define a sign however it is possible that a 
particular sign in any sign language may not be 
defined by 'the fixed set of symbols. For example 
HamNoSys does not have well defined symbols 
for non-manual expressions. Consider the sign 
?BITTER?, in ISL the representation is shown in 
Fig.15. It can be observed that it is very difficult to 
represent the facial expressions like eyebrow by 
HamNoSys. Currently we have a collection of 
around 979 sign icons (published by Vasistha et. al 
1998), which we are trying to transcribe in Ham-
NoSys. Out of these, 16% of the signs contain 
non-manual features which we are unable to repre-
sent in HamNoSys.  
 
  
Fig.15: ISL representation of 
"BITTER" 
 
7 Conclusion and Future works 
The paper presents an approach towards building a 
multimedia SL dictionary tool. This tool can be 
used to prepare a well documented ISL dictionary. 
The system is intended to take any Indian lan-
guage text as input and can store signs in any SL. 
Currently the system takes English, Hindi and 
Bengali texts as input and can store signs in ISL 
only. The system also provides an easy to use GUI 
The 6th Workshop on Asian Languae Resources, 2008
63
to include phonological information of a sign in 
the form of HamNoSys string. The generated 
HamNoSys string can then be used as an input to 
the signing avatar module to produce animated 
sign output. 
 In the next phase of our work we will im-
prove the system so that it can associate signs in 
any other SL (like, ASL and BSL). Further, 
WordNet as well as POS Tagger corresponding to 
Hindi and Bengali languages should also be inte-
grated with the system. Also, support has to be 
built so that system can perform sign-to-word and 
sign to sign search.  We will also perform proper 
evaluation of the HamNoSys editor in order to 
understand its utility to the SL user. 
References 
Buttussi F., Chittaro L., Coppo M. 2007. Using Web3D 
technologies for visualization and search of signs in 
an international sign language dictionary. Proceed-
ings of the twelfth international conference on 3D 
web technology. Perugia, Italy Pages: 61 ? 70 Year 
of Publication: 2007 ISBN:978-1-59593-652-3  
Geitz, S., Hanson, T., Maher, S. 1996. Computer gener-
ated 3-dimensional models of manual alphabet hand-
shapes for the World Wide Web. In Assets ?96: 
Proceedings of the second annual ACM confer-
ence on Assistive technologies, ACM Press, New 
York, NY, USA, 27?31. 
Marshall I. and S?f?r ?. 2001.Extraction of semantic 
representations from syntactic SMU link grammar 
linkages.. In G. Angelova, editor, Proceedings of 
Recent Advances in Natural Lanugage Processing, 
pp: 154-159, Tzigov Chark, Bulgaria, September. 
Prillwitz P., Regina Leven, Heiko Zienert, Thomas 
Hamke, and Jan Henning. 1989. HamNoSys Version 
2.0: Hamburg Notation System for Sign Languages: 
An Introductory Guide, volume 5 of International 
Studies on Sign Language and Communication of 
the Deaf. Signum Press, Hamburg, Germany,  
Smith G., Angus. 1999. English to American Sign Lan-
guage machine translation of weather reports. Pro-
ceedings of the Second High Desert Student Confer-
ence in Linguistics. 
Smith,K.C., Edmondson, W. 2004. The Development 
of a Computational Notation for Synthesis of Sign 
and Gesture, GW03(312-323). 
Speers, A. 1995. SL-Corpus: A computer tool for sign 
language corpora., Georgetown University.  
Stokoe W. C., 1960. Sign language structure: an out-
line of the visual communication systems of the 
American deaf. 2nd edition, 1978. Silver Spring, 
MD: Linstok Press. 
VCOM3D,2004. Sign smith products. 
http://www.vcom3d.com. 
Wilcox, S., Scheibman, J., Wood, D., Cokely, D., and 
stokoe, w. c. 1994. Multimedia dictionary of Ameri-
can Sign Language. In Assets ?94: Proceedings of 
the first annual ACM conference on Assistive tech-
nologies, ACM Press, New York, NY, USA, 9?16. 
Vasishta M., Woodward J., DeSantis S. 1998, ?An In-
troduction to Indian Sign Language?, All India Fed-
eration of the Deaf (Third Edition). 
Zeshan U., 2003,?Indo-Pakistani Sign Language 
Grammar: A Typological Outline?, Sign Language 
Studies - Volume 3, Number 2, , pp. 157-212  
Zeshan U., Madan M. Vasishta, Sethna M. 2004, ?im-
plementation of indian sign language in educational 
settings?- Volume 15, Number 2, Asia Pacific Dis-
ability Rehabilitation Journal, , pp. 15-35 
 
The 6th Workshop on Asian Languae Resources, 2008
64
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 128?135,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Analysis and Synthesis of the Distribution of Consonants over Languages:
A Complex Network Approach
Monojit Choudhury and Animesh Mukherjee and Anupam Basu and Niloy Ganguly
Department of Computer Science and Engineering,
Indian Institute of Technology Kharagpur
{monojit,animeshm,anupam,niloy}@cse.iitkgp.ernet.in
Abstract
Cross-linguistic similarities are reflected
by the speech sound systems of languages
all over the world. In this work we try
to model such similarities observed in the
consonant inventories, through a complex
bipartite network. We present a systematic
study of some of the appealing features of
these inventories with the help of the bi-
partite network. An important observation
is that the occurrence of consonants fol-
lows a two regime power law distribution.
We find that the consonant inventory size
distribution together with the principle of
preferential attachment are the main rea-
sons behind the emergence of such a two
regime behavior. In order to further sup-
port our explanation we present a synthe-
sis model for this network based on the
general theory of preferential attachment.
1 Introduction
Sound systems of the world?s languages show re-
markable regularities. Any arbitrary set of conso-
nants and vowels does not make up the sound sys-
tem of a particular language. Several lines of re-
search suggest that cross-linguistic similarities get
reflected in the consonant and vowel inventories
of the languages all over the world (Greenberg,
1966; Pinker, 1994; Ladefoged and Maddieson,
1996). Previously it has been argued that these
similarities are the results of certain general prin-
ciples like maximal perceptual contrast (Lindblom
and Maddieson, 1988), feature economy (Mar-
tinet, 1968; Boersma, 1998; Clements, 2004) and
robustness (Jakobson and Halle, 1956; Chomsky
and Halle, 1968). Maximal perceptual contrast
between the phonemes of a language is desir-
able for proper perception in a noisy environment.
In fact the organization of the vowel inventories
across languages has been satisfactorily explained
in terms of the single principle of maximal percep-
tual contrast (Jakobson, 1941; Wang, 1968).
There have been several attempts to reason
the observed patterns in consonant inventories
since 1930s (Trubetzkoy, 1969/1939; Lindblom
and Maddieson, 1988; Boersma, 1998; Flemming,
2002; Clements, 2004), but unlike the case of vow-
els, the structure of consonant inventories lacks a
complete and holistic explanation (de Boer, 2000).
Most of the works are confined to certain indi-
vidual principles (Abry, 2003; Hinskens and Wei-
jer, 2003) rather than formulating a general the-
ory describing the structural patterns and/or their
stability. Thus, the structure of the consonant in-
ventories continues to be a complex jigsaw puzzle,
though the parts and pieces are known.
In this work we attempt to represent the cross-
linguistic similarities that exist in the consonant
inventories of the world?s languages through a
bipartite network named PlaNet (the Phoneme
Language Network). PlaNet has two different sets
of nodes, one labeled by the languages while the
other labeled by the consonants. Edges run be-
tween these two sets depending on whether or not
a particular consonant occurs in a particular lan-
guage. This representation is motivated by similar
modeling of certain complex phenomena observed
in nature and society, such as,
? Movie-actor network, where movies and ac-
tors constitute the two partitions and an edge
between them signifies that a particular actor
acted in a particular movie (Ramasco et al,
2004).
128
? Article-author network, where the edges de-
note which person has authored which arti-
cles (Newman, 2001b).
? Metabolic network of organisms, where the
corresponding partitions are chemical com-
pounds and metabolic reactions. Edges run
between partitions depending on whether a
particular compound is a substrate or result
of a reaction (Jeong et al, 2000).
Modeling of complex systems as networks has
proved to be a comprehensive and emerging way
of capturing the underlying generating mecha-
nism of such systems (for a review on complex
networks and their generation see (Albert and
Baraba?si, 2002; Newman, 2003)). There have
been some attempts as well to model the intri-
cacies of human languages through complex net-
works. Word networks based on synonymy (Yook
et al, 2001b), co-occurrence (Cancho et al, 2001),
and phonemic edit-distance (Vitevitch, 2005) are
examples of such attempts. The present work also
uses the concept of complex networks to develop
a platform for a holistic analysis as well as synthe-
sis of the distribution of the consonants across the
languages.
In the current work, with the help of PlaNet we
provide a systematic study of certain interesting
features of the consonant inventories. An impor-
tant property that we observe is the two regime
power law degree distribution1 of the nodes la-
beled by the consonants. We try to explain this
property in the light of the size of the consonant
inventories coupled with the principle of preferen-
tial attachment (Baraba?si and Albert, 1999). Next
we present a simplified mathematical model ex-
plaining the emergence of the two regimes. In or-
der to support our analytical explanations, we also
provide a synthesis model for PlaNet.
The rest of the paper is organized into five sec-
tions. In section 2 we formally define PlaNet, out-
line its construction procedure and present some
studies on its degree distribution. We dedicate sec-
tion 3 to state and explain the inferences that can
be drawn from the degree distribution studies of
PlaNet. In section 4 we provide a simplified the-
oretical explanation of the analytical results ob-
1Two regime power law distributions have also been
observed in syntactic networks of words (Cancho et al,
2001), network of mathematics collaborators (Grossman et
al., 1995), and language diversity over countries (Gomes et
al., 1999).
Figure 1: Illustration of the nodes and edges of
PlaNet
tained. In section 5 we present a synthesis model
for PlaNet to hold up the inferences that we draw
in section 3. Finally we conclude in section 6 by
summarizing our contributions, pointing out some
of the implications of the current work and indi-
cating the possible future directions.
2 PlaNet: The Phoneme-Language
Network
We define the network of consonants and lan-
guages, PlaNet, as a bipartite graph represented as
G = ?VL, VC , E? where VL is the set of nodes la-
beled by the languages and VC is the set of nodes
labeled by the consonants. E is the set of edges
that run between VL and VC . There is an edge e ?
E between two nodes vl ? VL and vc ? VC if and
only if the consonant c occurs in the language l.
Figure 1 illustrates the nodes and edges of PlaNet.
2.1 Construction of PlaNet
Many typological studies (Lindblom and Mad-
dieson, 1988; Ladefoged and Maddieson, 1996;
Hinskens and Weijer, 2003) of segmental inven-
tories have been carried out in past on the UCLA
Phonological Segment Inventory Database (UP-
SID) (Maddieson, 1984). UPSID initially had 317
languages and was later extended to include 451
languages covering all the major language families
of the world. In this work we have used the older
version of UPSID comprising of 317 languages
and 541 consonants (henceforth UPSID317), for
constructing PlaNet. Consequently, there are 317
elements (nodes) in the set VL and 541 elements
129
(nodes) in the set VC . The number of elements
(edges) in the set E as computed from PlaNet is
7022. At this point it is important to mention that
in order to avoid any confusion in the construc-
tion of PlaNet we have appropriately filtered out
the anomalous and the ambiguous segments (Mad-
dieson, 1984) from it. We have completely ig-
nored the anomalous segments from the data set
(since the existence of such segments is doubtful),
and included the ambiguous ones as separate seg-
ments because there are no descriptive sources ex-
plaining how such ambiguities might be resolved.
A similar approach has also been described in Per-
icliev and Valde?s-Pe?rez (2002).
2.2 Degree Distribution of PlaNet
The degree of a node u, denoted by ku is defined as
the number of edges connected to u. The term de-
gree distribution is used to denote the way degrees
(ku) are distributed over the nodes (u). The de-
gree distribution studies find a lot of importance in
understanding the complex topology of any large
network, which is very difficult to visualize oth-
erwise. Since PlaNet is bipartite in nature it has
two degree distribution curves one corresponding
to the nodes in the set VL and the other corre-
sponding to the nodes in the set VC .
Degree distribution of the nodes in VL: Fig-
ure 2 shows the degree distribution of the nodes
in VL where the x-axis denotes the degree of each
node expressed as a fraction of the maximum de-
gree and the y-axis denotes the number of nodes
having a given degree expressed as a fraction of
the total number of nodes in VL .
It is evident from Figure 2 that the number of
consonants appearing in different languages fol-
low a ?-distribution 2 (see (Bulmer, 1979) for ref-
erence). The figure shows an asymmetric right
skewed distribution with the values of ? and ?
equal to 7.06 and 47.64 (obtained using maximum
likelihood estimation method) respectively. The
asymmetry points to the fact that languages usu-
ally tend to have smaller consonant inventory size,
2A random variable is said to have a ?-distribution with
parameters ?> 0 and ? > 0 if and only if its probability mass
function is given by
f(x) =
?(?+ ?)
?(?)?(?)
x??1(1 ? x)??1
for 0 < x < 1 and f(x) = 0 otherwise. ?(?) is the Euler?s
gamma function.
Figure 2: Degree distribution of PlaNet for the set
VL. The figure in the inner box is a magnified
version of a portion of the original figure.
the best value being somewhere between 10 and
30. The distribution peaks roughly at 21 indicating
that majority of the languages in UPSID317 have a
consonant inventory size of around 21 consonants.
Degree distribution of the nodes in VC: Fig-
ure 3 illustrates two different types of degree dis-
tribution plots for the nodes in VC ; Figure 3(a)
corresponding to the rank, i.e., the sorted order of
degrees, (x-axis) versus degree (y-axis) and Fig-
ure 3(b) corresponding to the degree (k) (x-axis)
versus Pk (y-axis) where Pk is the fraction of
nodes having degree greater than or equal to k.
Figure 3 clearly shows that both the curves have
two distinct regimes and the distribution is scale-
free. Regime 1 in Figure 3(a) consists of 21 con-
sonants which have a very high frequency (i.e.,
the degree k) of occurrence. Regime 2 of Fig-
ure 3(b) also correspond to these 21 consonants.
On the other hand Regime 2 of Figure 3(a) as well
as Regime 1 of Figure 3(b) comprises of the rest
of the consonants. The point marked as x in both
the figures indicates the breakpoint. Each of the
regime in both Figure 3(a) and (b) exhibit a power
law of the form
y = Ax??
In Figure 3(a) y represents the degree k of a node
corresponding to its rank x whereas in Figure 3(b)
y corresponds to Pk and x, the degree k. The val-
ues of the parameters A and ?, for Regime 1 and
Regime 2 in both the figures, as computed by the
least square error method, are shown in Table 1.
130
Regime Figure 3(a) Figure 3(b)
Regime 1 A = 368.70 ? = 0.4 A = 1.040 ? = 0.71
Regime 2 A = 12456.5 ? = 1.54 A = 2326.2 ? = 2.36
Table 1: The values of the parameters A and ?
Figure 3: Degree distribution of PlaNet for the set
VC in a log-log scale
It becomes necessary to mention here that such
power law distributions, known variously as Zipf?s
law (Zipf, 1949), are also observed in an extra-
ordinarily diverse range of phenomena including
the frequency of the use of words in human lan-
guage (Zipf, 1949), the number of papers scien-
tists write (Lotka, 1926), the number of hits on
web pages (Adamic and Huberman, 2000) and so
on. Thus our inferences, detailed out in the next
section, mainly centers around this power law be-
havior.
3 Inferences Drawn from the Analysis of
PlaNet
In most of the networked systems like the society,
the Internet, the World Wide Web, and many oth-
ers, power law degree distribution emerges for the
phenomenon of preferential attachment, i.e., when
?the rich get richer? (Simon, 1955). With refer-
ence to PlaNet this preferential attachment can be
interpreted as the tendency of a language to choose
a consonant that has been already chosen by a
large number of other languages. We posit that it is
this preferential property of languages that results
in the power law degree distributions observed in
Figure 3(a) and (b).
Nevertheless there is one question that still re-
mains unanswered. Whereas the power law distri-
bution is well understood, the reason for the two
distinct regimes (with a sharp break) still remains
unexplored. We hypothesize that,
Hypothesis The typical distribution of the conso-
nant inventory size over languages coupled with
the principle of preferential attachment enforces
the two distinct regimes to appear in the power
law curves.
As the average consonant inventory size in
UPSID317 is 21, so following the principle of
preferential attachment, on an average, the first
21 most frequent consonants are much more pre-
ferred than the rest. Consequently, the nature of
the frequency distribution for the highly frequent
consonants is different from the less frequent ones,
and hence there is a transition from Regime 1 to
Regime 2 in the Figure 3(a) and (b).
Support Experiment: In order to establish that
the consonant inventory size plays an important
role in giving rise to the two regimes discussed
above we present a support experiment in which
we try to observe whether the breakpoint x shifts
as we shift the average consonant inventory size.
Experiment: In order to shift the average con-
sonant inventory size from 21 to 25, 30 and 38
we neglected the contribution of the languages
with consonant inventory size less than n where
n is 15, 20 and 25 respectively and subsequently
recorded the degree distributions obtained each
time. We did not carry out our experiments for
average consonant inventory size more than 38 be-
cause the number of such languages are very rare
in UPSID317.
Observations: Figure 4 shows the effect of this
shifting of the average consonant inventory size on
the rank versus degree distribution curves. Table 2
presents the results observed from these curves
with the left column indicating the average inven-
tory size and the right column the breakpoint x.
131
Figure 4: Degree distributions at different average
consonant inventory sizes
Avg. consonant inv. size Transition
25 25
30 30
38 37
Table 2: The transition points for different average
consonant inventory size
The table clearly indicates that the transition oc-
curs at values corresponding to the average conso-
nant inventory size in each of the three cases.
Inferences: It is quite evident from our observa-
tions that the breakpoint x has a strong correlation
with the average consonant inventory size, which
therefore plays a key role in the emergence of the
two regime degree distribution curves.
In the next section we provide a simplistic math-
ematical model for explaining the two regime
power law with a breakpoint corresponding to the
average consonant inventory size.
4 Theoretical Explanation for the Two
Regimes
Let us assume that the inventory of all the lan-
guages comprises of 21 consonants. We further as-
sume that the consonants are arranged in their hier-
archy of preference. A language traverses the hier-
archy of consonants and at every step decides with
a probability p to choose the current consonant. It
stops as soon as it has chosen all the 21 conso-
nants. Since languages must traverse through the
first 21 consonants regardless of whether the pre-
vious consonants are chosen or not, the probability
of choosing any one of these 21 consonants must
be p. But the case is different for the 22nd conso-
nant, which is chosen by a language if it has pre-
viously chosen zero, one, two, or at most 20, but
not all of the first 21 consonants. Therefore, the
probability of the 22nd consonant being chosen is,
P (22) = p
20?
i=0
(
21
i
)
pi(1? p)21?i
where (
21
i
)
pi(1? p)21?i
denotes the probability of choosing i consonants
from the first 21. In general the probability of
choosing the n+1th consonant from the hierarchy
is given by,
P (n+ 1) = p
20?
i=0
(
n
i
)
pi(1? p)n?i
Figure 5 shows the plot of the function P (n) for
various values of p which are 0.99, 0.95, 0.9, 0.85,
0.75 and 0.7 respectively in log-log scale. All the
curves, for different values of p, have a nature sim-
ilar to that of the degree distribution plot we ob-
tained for PlaNet. This is indicative of the fact that
languages choose consonants from the hierarchy
with a probability function comparable to P (n).
Owing to the simplified assumption that all
the languages have only 21 consonants, the first
regime is a straight line; however we believe a
more rigorous mathematical model can be built
taking into consideration the ?-distribution rather
than just the mean value of the inventory size that
can explain the negative slope of the first regime.
We look forward to do the same as a part of our fu-
ture work. Rather, here we try to investigate the ef-
fect of the exact distribution of the language inven-
tory size on the nature of the degree distribution of
the consonants through a synthetic approach based
on the principle of preferential attachment, which
is described in the subsequent section.
5 The Synthesis Model based on
Preferential Attachment
Albert and Baraba?si (1999) observed that a com-
mon property of many large networks is that the
vertex connectivities follow a scale-free power
law distribution. They remarked that two generic
mechanisms can be considered to be the cause
of this observation: (i) networks expand contin-
uously by the addition of new vertices, and (ii)
new vertices attach preferentially to sites (vertices)
that are already well connected. They found that
132
Figure 5: Plot of the function P (n) in log-log
scale
a model based on these two ingredients repro-
duces the observed stationary scale-free distrib-
utions, which in turn indicates that the develop-
ment of large networks is governed by robust self-
organizing phenomena that go beyond the particu-
lars of the individual systems.
Inspired by their work and the empirical as well
as the mathematical analysis presented above, we
propose a preferential attachment model for syn-
thesizing PlaNet (PlaNetsyn henceforth) in which
the degree distribution of the nodes in VL is
known. Hence VL={L1, L2, . . ., L317} have
degrees (consonant inventory size) {k1, k2, . . .,
k317} respectively. We assume that the nodes in
the set VC are unlabeled. At each time step, a
node Lj (j = 1 to 317) from VL tries to attach itself
with a new node i ? VC to which it is not already
connected. The probability Pr(i) with which the
node Lj gets attached to i depends on the current
degree of i and is given by
Pr(i) =
ki + 
?
i??Vj
(ki? + )
where ki is the current degree of the node i, Vj
is the set of nodes in VC to which Lj is not al-
ready connected and  is the smoothing parameter
which is used to reduce bias and favor at least a
few attachments with nodes in Vj that do not have
a high Pr(i). The above process is repeated un-
til all Lj ? VL get connected to exactly kj nodes
in VC . The entire idea is summarized in Algo-
rithm 1. Figure 6 shows a partial step of the syn-
thesis process illustrated in Algorithm 1.
Simulation Results: Simulations reveal that for
PlaNetsyn the degree distribution of the nodes be-
longing to VC fit well with the analytical results
we obtained earlier in section 2. Good fits emerge
repeat
for j = 1 to 317 do
if there is a node Lj ? VL with at least
one or more consonants to be chosen
from VC then
Compute Vj = VC-V (Lj), where
V (Lj) is the set of nodes in VC to
which Lj is already connected;
end
for each node i ? Vj do
Pr(i) =
ki + 
?
i??Vj
(ki? + )
where ki is the current degree of
the node i and  is the model
parameter. Pr(i) is the
probability of connecting Lj to i.
end
Connect Lj to a node i ? Vj
following the distribution Pr(i);
end
until all languages complete their inventory
quota ;
Algorithm 1: Algorithm for synthesis of
PlaNet based on preferential attachment
Figure 6: A partial step of the synthesis process.
When the language L4 has to connect itself with
one of the nodes in the set VC it does so with the
one having the highest degree (=3) rather than with
others in order to achieve preferential attachment
which is the working principle of our algorithm
for the range 0.06 ?  ? 0.08 with the best being
at  = 0.0701. Figure 7 shows the degree k versus
133
Figure 7: Degree distribution of the nodes in
VC for both PlaNetsyn, PlaNet, and when the
model incorporates no preferential attachment; for
PlaNetsyn,  = 0.0701 and the results are averaged
over 100 simulation runs
Pk plots for  = 0.0701 averaged over 100 simula-
tion runs.
The mean error3 between the degree distribu-
tion plots of PlaNet and PlaNetsyn is 0.03 which
intuitively signifies that on an average the varia-
tion in the two curves is 3%. On the contrary, if
there were no preferential attachment incorporated
in the model (i.e., all connections were equiprob-
able) then the mean error would have been 0.35
(35% variation on an average).
6 Conclusions, Discussion and Future
Work
In this paper, we have analyzed and synthesized
the consonant inventories of the world?s languages
in terms of a complex network. We dedicated the
preceding sections essentially to,
? Represent the consonant inventories through
a bipartite network called PlaNet,
? Provide a systematic study of certain impor-
tant properties of the consonant inventories
with the help of PlaNet,
? Propose analytical explanations for the two
regime power law curves (obtained from
PlaNet) on the basis of the distribution of the
consonant inventory size over languages to-
gether with the principle of preferential at-
tachment,
3Mean error is defined as the average difference between
the ordinate pairs where the abscissas are equal.
? Provide a simplified mathematical model to
support our analytical explanations, and
? Develop a synthesis model for PlaNet based
on preferential attachment where the conso-
nant inventory size distribution is known a
priori.
We believe that the general explanation pro-
vided here for the two regime power law is a fun-
damental result, and can have a far reaching im-
pact, because two regime behavior is observed in
many other networked systems.
Until now we have been mainly dealing with the
computational aspects of the distribution of conso-
nants over the languages rather than exploring the
real world dynamics that gives rise to such a distri-
bution. An issue that draws immediate attention is
that how preferential attachment, which is a gen-
eral phenomenon associated with network evolu-
tion, can play a prime role in shaping the conso-
nant inventories of the world?s languages. The an-
swer perhaps is hidden in the fact that language is
an evolving system and its present structure is de-
termined by its past evolutionary history. Indeed
an explanation based on this evolutionary model,
with an initial disparity in the distribution of con-
sonants over languages, can be intuitively verified
as follows ? let there be a language community
of N speakers communicating among themselves
by means of only two consonants say /k/ and /g/.
If we assume that every speaker has l descendants
and language inventories are transmitted with high
fidelity, then after i generations it is expected that
the community will consist of mli /k/ speakers and
nli /g/ speakers. Now if m > n and l > 1, then for
sufficiently large i, mli  nli. Stated differently,
the /k/ speakers by far outnumbers the /g/ speak-
ers even if initially the number of /k/ speakers is
only slightly higher than that of the /g/ speakers.
This phenomenon is similar to that of preferen-
tial attachment where language communities get
attached to, i.e., select, consonants that are already
highly preferred. Nevertheless, it remains to be
seen where from such an initial disparity in the dis-
tribution of the consonants over languages might
have originated.
In this paper, we mainly dealt with the occur-
rence principles of the consonants in the invento-
ries of the world?s languages. The work can be fur-
ther extended to identify the co-occurrence likeli-
hood of the consonants in the language inventories
134
and subsequently identify the groups or commu-
nities within them. Information about such com-
munities can then help in providing an improved
insight about the organizing principles of the con-
sonant inventories.
References
C. Abry. 2003. [b]-[d]-[g] as a universal triangle as
acoustically optimal as [i]-[a]-[u]. 15th Int. Congr.
Phonetics Sciences ICPhS, 727?730.
L. A. Adamic and B. A. Huberman. 2000. The na-
ture of markets in the World Wide Web. Quarterly
Journal of Electronic Commerce 1, 512.
R. Albert and A.-L. Baraba?si. 2002. Statistical me-
chanics of complex networks. Reviews of Modern
Physics 74, 47?97.
A.-L. Baraba?si and R. Albert. 1999. Emergence of
scaling in random networks. Science 286, 509-512.
Bart de Boer. 2000. Self-Organisation in Vowel Sys-
tems. Journal of Phonetics, Elsevier.
P. Boersma. 1998. Functional Phonology. (Doctoral
thesis, University of Amsterdam), The Hague: Hol-
land Academic Graphics.
M. G. Bulmer. 1979. Principles of Statistics, Mathe-
matics.
Ferrer i Cancho and R. V. Sole?. 2001. Santa Fe work-
ing paper 01-03-016.
N. Chomsky and M. Halle. 1968. The Sound Pattern
of English, New York: Harper and Row.
N. Clements. 2004. Features and Sound Inventories.
Symposium on Phonological Theory: Representa-
tions and Architecture, CUNY.
E. Flemming. 2002. Auditory Representations in
Phonology, New York and London: Routledge.
M. A. F. Gomes, G. L. Vasconcelos, I. J. Tsang, and I.
R. Tsang. 1999. Scaling relations for diversity of
languages. Physica A, 271, 489.
J. H. Greenberg. 1966. Language Universals with Spe-
cial Reference to Feature Hierarchies, The Hague
Mouton.
J. W. Grossman and P. D. F. Ion. 1995. On a portion
of the well-known collaboration graph. Congressus
Numerantium, 108, 129-131.
F. Hinskens and J. Weijer. 2003. Patterns of segmen-
tal modification in consonant inventories: a cross-
linguistic study. Linguistics.
R. Jakobson. 1941. Kindersprache, Aphasie und allge-
meine Lautgesetze, Uppsala, Reprinted in Selected
Writings I. Mouton, The Hague, 1962, pages 328-
401.
H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai, and A.
L. Baraba?si. 2000. The large-scale organization of
metabolic networks. Nature, 406:651-654.
R. Jakobson and M. Halle. 1956. Fundamentals of
Language, The Hague: Mouton and Co.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
Worlds Languages, Oxford: Blackwell.
B. Lindblom and I. Maddieson. 1988. Phonetic Uni-
versals in Consonant Systems. In L.M. Hyman and
C.N. Li, eds., Language, Speech, and Mind, Rout-
ledge, London, 62?78.
A. J. Lotka. 1926. The frequency distribution of scien-
tific production. J. Wash. Acad. Sci. 16, 317-323.
I. Maddieson. 1984. Patterns of Sounds, Cambridge
University Press, Cambridge.
A. Martinet. 1968. Phonetics and linguistic evolu-
tion. In Bertil Malmberg (ed.), Manual of phonetics,
revised and extended edition, Amsterdam: North-
Holland Publishing Co. 464?487.
M. E. J. Newman. 2001b. Scientific collaboration net-
works. I and II. Phys. Rev., E 64.
M. E. J. Newman. 2003. The structure and function of
complex networks. SIAM Review 45, 167?256.
V. Pericliev, R. E. Valde?s-Pe?rez. 2002. Differentiating
451 languages in terms of their segment inventories.
Studia Linguistica, Blackwell Publishing.
S. Pinker. 1994. The Language Instinct, New York:
Morrowo.
Jose? J. Ramasco, S. N. Dorogovtsev, and Romualdo
Pastor-Satorras. 2004. Self-organization of collabo-
ration networks. Physical Review E, 70, 036106.
H. A. Simon. 1955. On a class of skew distribution
functions. Biometrika 42, 425-440.
N. Trubetzkoy. 1969. Principles of phonology.
(English translation of Grundzu?ge der Phonologie,
1939), Berkeley: University of California Press.
M. S. Vitevitch. 2005. Phonological neighbors in a
small world: What can graph theory tell us about
word learning? Spring 2005 Talk Series on Networks
and Complex Systems, Indiana University, Bloom-
ington.
William S.-Y. Wang. 1968. The basis of speech,
Project on Linguistic Analysis Reports, University
of California at Berkeley. Reprinted in The Learning
of Language, ed. by C. E. Reed, 1971.
S. Yook, H. Jeong and A.-L. Baraba?si. 2001b. preprint.
G. K. Zipf. 1949. Human Behaviour and the Principle
of Least Effort, Addison-Wesley, Reading, MA.
135
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 104?111,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Redundancy Ratio: An Invariant Property of the
Consonant Inventories of the World?s Languages
Animesh Mukherjee, Monojit Choudhury, Anupam Basu, Niloy Ganguly
Department of Computer Science and Engineering,
Indian Institute of Technology, Kharagpur
{animeshm,monojit,anupam,niloy}@cse.iitkgp.ernet.in
Abstract
In this paper, we put forward an information
theoretic definition of the redundancy that is
observed across the sound inventories of the
world?s languages. Through rigorous statis-
tical analysis, we find that this redundancy
is an invariant property of the consonant in-
ventories. The statistical analysis further un-
folds that the vowel inventories do not ex-
hibit any such property, which in turn points
to the fact that the organizing principles of
the vowel and the consonant inventories are
quite different in nature.
1 Introduction
Redundancy is a strikingly common phenomenon
that is observed across many natural systems. This
redundancy is present mainly to reduce the risk
of the complete loss of information that might oc-
cur due to accidental errors (Krakauer and Plotkin,
2002). Moreover, redundancy is found in every level
of granularity of a system. For instance, in biologi-
cal systems we find redundancy in the codons (Lesk,
2002), in the genes (Woollard, 2005) and as well in
the proteins (Gatlin, 1974). A linguistic system is
also not an exception. There is for example, a num-
ber of words with the same meaning (synonyms) in
almost every language of the world. Similarly, the
basic unit of language, the human speech sounds or
the phonemes, is also expected to exhibit some sort
of a redundancy in the information that it encodes.
In this work, we attempt to mathematically cap-
ture the redundancy observed across the sound
(more specifically the consonant) inventories of
the world?s languages. For this purpose, we
present an information theoretic definition of redun-
dancy, which is calculated based on the set of fea-
tures1 (Trubetzkoy, 1931) that are used to express
the consonants. An interesting observation is that
this quantitative feature-based measure of redun-
dancy is almost an invariance over the consonant
inventories of the world?s languages. The observa-
tion is important since it can shed enough light on
the organization of the consonant inventories, which
unlike the vowel inventories, lack a complete and
holistic explanation. The invariance of our measure
implies that every inventory tries to be similar in
terms of the measure, which leads us to argue that
redundancy plays a very important role in shaping
the structure of the consonant inventories. In order
to validate this argument we determine the possibil-
ity of observing such an invariance if the consonant
inventories had evolved by random chance. We find
that the redundancy observed across the randomly
generated inventories is substantially different from
their real counterparts, which leads us to conclude
that the invariance is not just ?by-chance? and the
measure that we define, indeed, largely governs the
organizing principles of the consonant inventories.
1In phonology, features are the elements, which distin-
guish one phoneme from another. The features that distinguish
the consonants can be broadly categorized into three different
classes namely the manner of articulation, the place of articu-
lation and phonation. Manner of articulation specifies how the
flow of air takes place in the vocal tract during articulation of
a consonant, whereas place of articulation specifies the active
speech organ and also the place where it acts. Phonation de-
scribes the activity regarding the vibration of the vocal cords
during the articulation of a consonant.
104
Interestingly, this redundancy, when measured for
the vowel inventories, does not exhibit any similar
invariance. This immediately reveals that the prin-
ciples that govern the formation of these two types
of inventories are quite different in nature. Such
an observation is significant since whether or not
these principles are similar/different for the two in-
ventories had been a question giving rise to peren-
nial debate among the past researchers (Trubet-
zkoy, 1969/1939; Lindblom and Maddieson, 1988;
Boersma, 1998; Clements, 2004). A possible rea-
son for the observed dichotomy in the behavior of
the vowel and consonant inventories with respect to
redundancy can be as follows: while the organiza-
tion of the vowel inventories is known to be gov-
erned by a single force - the maximal perceptual
contrast (Jakobson, 1941; Liljencrants and Lind-
blom, 1972; de Boer, 2000)), consonant invento-
ries are shaped by a complex interplay of several
forces (Mukherjee et al, 2006). The invariance of
redundancy, perhaps, reflects some sort of an equi-
librium that arises from the interaction of these di-
vergent forces.
The rest of the paper is structured as follows. In
section 2 we briefly discuss the earlier works in con-
nection to the sound inventories and then systemat-
ically build up the quantitative definition of redun-
dancy from the linguistic theories that are already
available in the literature. Section 3 details out the
data source necessary for the experiments, describes
the baseline for the experiments, reports the exper-
iments performed, and presents the results obtained
each time comparing the same with the baseline re-
sults. Finally we conclude in section 4 by summa-
rizing our contributions, pointing out some of the
implications of the current work and indicating the
possible future directions.
2 Formulation of Redundancy
Linguistic research has documented a wide range of
regularities across the sound systems of the world?s
languages. It has been postulated earlier by func-
tional phonologists that such regularities are the con-
sequences of certain general principles like maxi-
mal perceptual contrast (Liljencrants and Lindblom,
1972), which is desirable between the phonemes of
a language for proper perception of each individ-
ual phoneme in a noisy environment, ease of artic-
ulation (Lindblom and Maddieson, 1988; de Boer,
2000), which requires that the sound systems of
all languages are formed of certain universal (and
highly frequent) sounds, and ease of learnability (de
Boer, 2000), which is necessary for a speaker to
learn the sounds of a language with minimum ef-
fort. In fact, the organization of the vowel inven-
tories (especially those with a smaller size) across
languages has been satisfactorily explained in terms
of the single principle of maximal perceptual con-
trast (Jakobson, 1941; Liljencrants and Lindblom,
1972; de Boer, 2000).
On the other hand, in spite of several at-
tempts (Lindblom and Maddieson, 1988; Boersma,
1998; Clements, 2004) the organization of the con-
sonant inventories lacks a satisfactory explanation.
However, one of the earliest observations about the
consonant inventories has been that consonants tend
to occur in pairs that exhibit strong correlation in
terms of their features (Trubetzkoy, 1931). In or-
der to explain these trends, feature economy was
proposed as the organizing principle of the con-
sonant inventories (Martinet, 1955). According to
this principle, languages tend to maximize the com-
binatorial possibilities of a few distinctive features
to generate a large number of consonants. Stated
differently, a given consonant will have a higher
than expected chance of occurrence in inventories in
which all of its features have distinctively occurred
in other consonants. The idea is illustrated, with an
example, through Table 1. Various attempts have
been made in the past to explain the aforementioned
trends through linguistic insights (Boersma, 1998;
Clements, 2004) mainly establishing their statistical
significance. On the contrary, there has been very
little work pertaining to the quantification of feature
economy except in (Clements, 2004), where the au-
thor defines economy index, which is the ratio of the
size of an inventory to the number of features that
characterizes the inventory. However, this definition
does not take into account the complexity that is in-
volved in communicating the information about the
inventory in terms of its constituent features.
Inspired by the aforementioned studies and
the concepts of information theory (Shannon and
Weaver, 1949) we try to quantitatively capture the
amount of redundancy found across the consonant
105
plosive voiced voiceless
dental /d/ /t/
bilabial /b/ /p/
Table 1: The table shows four plosives. If a language
has in its consonant inventory any three of the four
phonemes listed in this table, then there is a higher
than average chance that it will also have the fourth
phoneme of the table in its inventory.
inventories in terms of their constituent features. Let
us assume that we want to communicate the infor-
mation about an inventory of size N over a transmis-
sion channel. Ideally, one should require logN bits
to do the same (where the logarithm is with respect
to base 2). However, since every natural system is
to some extent redundant and languages are no ex-
ceptions, the number of bits actually used to encode
the information is more than logN . If we assume
that the features are boolean in nature, then we can
compute the number of bits used by a language to
encode the information about its inventory by mea-
suring the entropy as follows. For an inventory of
size N let there be pf consonants for which a partic-
ular feature f (where f is assumed to be boolean in
nature) is present and qf other consonants for which
the same is absent. Thus the probability that a par-
ticular consonant chosen uniformly at random from
this inventory has the feature f is pfN and the prob-
ability that the consonant lacks the feature f is qfN
(=1?pfN ). If F is the set of all features present in
the consonants forming the inventory, then feature
entropy FE can be expressed as
FE =
?
f?F
(?
pf
N
log
pf
N
?
qf
N
log
qf
N
) (1)
FE is therefore the measure of the minimum number
of bits that is required to communicate the informa-
tion about the entire inventory through the transmis-
sion channel. The lower the value of FE the better
it is in terms of the information transmission over-
head. In order to capture the redundancy involved in
the encoding we define the term redundancy ratio as
follows,
RR =
FE
logN
(2)
which expresses the excess number of bits that is
used by the constituent consonants of the inventory
Figure 1: The process of computing RR for a hypo-
thetical inventory.
in terms of a ratio. The process of computing the
value of RR for a hypothetical consonant inventory
is illustrated in Figure 1.
In the following section, we present the experi-
mental setup and also report the experiments which
we perform based on the above definition of redun-
dancy. We subsequently show that redundancy ratio
is invariant across the consonant inventories whereas
the same is not true in the case of the vowel invento-
ries.
3 Experiments and Results
In this section we discuss the data source necessary
for the experiments, describe the baseline for the
experiments, report the experiments performed, and
present the results obtained each time comparing the
same with the baseline results.
3.1 Data Source
Many typological studies (Ladefoged and Mad-
dieson, 1996; Lindblom and Maddieson, 1988)
of segmental inventories have been carried out in
past on the UCLA Phonological Segment Inven-
tory Database (UPSID) (Maddieson, 1984). UPSID
gathers phonological systems of languages from all
over the world, sampling more or less uniformly all
the linguistic families. In this work we have used
UPSID comprising of 317 languages and 541 con-
sonants found across them, for our experiments.
106
3.2 Redundancy Ratio across the Consonant
Inventories
In this section we measure the redundancy ratio (de-
scribed earlier) of the consonant inventories of the
languages recorded in UPSID. Figure 2 shows the
scatter-plot of the redundancy ratio RR of each of
the consonant inventories (y-axis) versus the inven-
tory size (x-axis). The plot immediately reveals that
the measure (i.e., RR) is almost invariant across the
consonant inventories with respect to the inventory
size. In fact, we can fit the scatter-plot with a straight
line (by means of least square regression), which as
depicted in Figure 2, has a negligible slope (m = ?
0.018) and this in turn further confirms the above
fact that RR is an invariant property of the conso-
nant inventories with regard to their size. It is im-
portant to mention here that in this experiment we
report the redundancy ratio of all the inventories of
size less than or equal to 40. We neglect the inven-
tories of the size greater than 40 since they are ex-
tremely rare (less than 0.5% of the languages of UP-
SID), and therefore, cannot provide us with statis-
tically meaningful estimates. The same convention
has been followed in all the subsequent experiments.
Nevertheless, we have also computed the values of
RR for larger inventories, whereby we have found
that for an inventory size ? 60 the results are sim-
ilar to those reported here. It is interesting to note
that the largest of the consonant inventories Ga (size
= 173) has an RR = 1.9, which is lower than all the
other inventories.
The aforementioned claim that RR is an invari-
ant across consonant inventories can be validated by
performing a standard test of hypothesis. For this
purpose, we randomly construct language invento-
ries, as discussed later, and formulate a null hypoth-
esis based on them.
Null Hypothesis: The invariance in the distribution
of RRs observed across the real consonant invento-
ries is also prevalent across the randomly generated
inventories.
Having formulated the null hypothesis we now
systematically attempt to reject the same with a very
high probability. For this purpose we first construct
random inventories and then perform a two sample
t-test (Cohen, 1995) comparing the RRs of the real
and the random inventories. The results show that
Figure 2: The scatter-plot of the redundancy ratio
RR of each of the consonant inventories (y-axis)
versus the inventory size (x-axis). The straight line-
fit is also depicted by the bold line in the figure.
indeed the null hypothesis can be rejected with a
very high probability. We proceed as follows.
3.2.1 Construction of Random Inventories
We employ two different models to generate the
random inventories. In the first model the invento-
ries are filled uniformly at random from the pool of
541 consonants. In the second model we assume
that the distribution of the occurrence of the conso-
nants over languages is known a priori. Note that
in both of these cases, the size of the random in-
ventories is same as its real counterpart. The results
show that the distribution of RRs obtained from the
second model has a closer match with the real in-
ventories than that of the first model. This indicates
that the occurrence frequency to some extent gov-
erns the law of organization of the consonant inven-
tories. The detail of each of the models follow.
Model I ? Purely Random Model: In this model
we assume that the distribution of the consonant in-
ventory size is known a priori. For each language
inventory L let the size recorded in UPSID be de-
noted by sL. Let there be 317 bins corresponding to
each consonant inventory L. A bin corresponding to
an inventory L is packed with sL consonants chosen
uniformly at random (without repetition) from the
pool of 541 available consonants. Thus the conso-
nant inventories of the 317 languages corresponding
to the bins are generated. The method is summarized
107
in Algorithm 1.
for I = 1 to 317 do
for size = 1 to sL do
Choose a consonant c uniformly at
random (without repetition) from the
pool of 541 available consonants;
Pack the consonant c in the bin
corresponding to the inventory L;
end
end
Algorithm 1: Algorithm to construct random in-
ventories using Model I
Model II ? Occurrence Frequency based Random
Model: For each consonant c let the frequency of
occurrence in UPSID be denoted by fc. Let there be
317 bins each corresponding to a language in UP-
SID. fc bins are then chosen uniformly at random
and the consonant c is packed into these bins. Thus
the consonant inventories of the 317 languages cor-
responding to the bins are generated. The entire idea
is summarized in Algorithm 2.
for each consonant c do
for i = 1 to fc do
Choose one of the 317 bins,
corresponding to the languages in
UPSID, uniformly at random;
Pack the consonant c into the bin so
chosen if it has not been already packed
into this bin earlier;
end
end
Algorithm 2: Algorithm to construct random in-
ventories using Model II
3.2.2 Results Obtained from the Random
Models
In this section we enumerate the results obtained
by computing the RRs of the randomly generated
inventories using Model I and Model II respectively.
We compare the results with those of the real inven-
Parameters Real Inv. Random Inv.
Mean 2.51177 3.59331
SDV 0.209531 0.475072
Parameters Values
t 12.15
DF 66
p ? 9.289e-17
Table 2: The results of the t-test comparing the dis-
tribution of RRs for the real and the random invento-
ries (obtained through Model I). SDV: standard devi-
ation, t: t-value of the test, DF: degrees of freedom,
p: residual uncertainty.
tories and in each case show that the null hypothesis
can be rejected with a significantly high probability.
Results from Model I: Figure 3 illustrates, for all
the inventories obtained from 100 different simula-
tion runs of Algorithm 1, the average redundancy
ratio exhibited by the inventories of a particular size
(y-axis), versus the inventory size (x-axis). The
term ?redundancy ratio exhibited by the inventories
of a particular size? actually means the following.
Let there be n consonant inventories of a particu-
lar inventory-size k. The average redundancy ra-
tio of the inventories of size k is therefore given by
1
n
?n
i=1 RRi where RRi signifies the redundancy ra-
tio of the ith inventory of size k. In Figure 3 we also
present the same curve for the real consonant inven-
tories appearing in UPSID. In these curves we fur-
ther depict the error bars spanning the entire range of
values starting from the minimum RR to the max-
imum RR for a given inventory size. The curves
show that in case of real inventories the error bars
span a very small range as compared to that of the
randomly constructed ones. Moreover, the slopes of
the curves are also significantly different. In order
to test whether this difference is significant, we per-
form a t-test comparing the distribution of the val-
ues of RR that gives rise to such curves for the real
and the random inventories. The results of the test
are noted in Table 2. These statistics clearly shows
that the distribution of RRs for the real and the ran-
dom inventories are significantly different in nature.
Stated differently, we can reject the null hypothesis
with (100 - 9.29e-15)% confidence.
Results from Model II: Figure 4 illustrates, for
all the inventories obtained from 100 different simu-
108
Figure 3: Curves showing the average redundancy
ratio exhibited by the real as well as the random in-
ventories (obtained through Model I) of a particular
size (y-axis), versus the inventory size (x-axis).
lation runs of Algorithm 2, the average redundancy
ratio exhibited by the inventories of a particular size
(y-axis), versus the inventory size (x-axis). The fig-
ure shows the same curve for the real consonant in-
ventories also. For each of the curve, the error bars
span the entire range of values starting from the min-
imum RR to the maximum RR for a given inventory
size. It is quite evident from the figure that the error
bars for the curve representing the real inventories
are smaller than those of the random ones. The na-
ture of the two curves are also different though the
difference is not as pronounced as in case of Model I.
This is indicative of the fact that it is not only the oc-
currence frequency that governs the organization of
the consonant inventories and there is a more com-
plex phenomenon that results in such an invariant
property. In fact, in this case also, the t-test statistics
comparing the distribution of RRs for the real and
the random inventories, reported in Table 3, allows
us to reject the null hypothesis with (100?2.55e?3)%
confidence.
3.3 Comparison with Vowel Inventories
Until now we have been looking into the organiza-
tional aspects of the consonant inventories. In this
section we show that this organization is largely dif-
ferent from that of the vowel inventories in the sense
that there is no such invariance observed across the
vowel inventories unlike that of consonants. For
this reason we start by computing the RRs of all
Figure 4: Curves showing the average redundancy
ratio exhibited by the real as well as the random in-
ventories (obtained through Model II) of a particular
size (y-axis), versus the inventory size (x-axis).
Parameters Real Inv. Random Inv.
Mean 2.51177 2.76679
SDV 0.209531 0.228017
Parameters Values
t 4.583
DF 60
p ? 2.552e-05
Table 3: The results of the t-test comparing the dis-
tribution of RRs for the real and the random inven-
tories (obtained through Model II).
the vowel inventories appearing in UPSID. Figure 5
shows the scatter plot of the redundancy ratio of each
of the vowel inventories (y-axis) versus the inven-
tory size (x-axis). The plot clearly indicates that the
measure (i.e., RR) is not invariant across the vowel
inventories and in fact, the straight line that fits the
distribution has a slope of ?0.14, which is around 10
times higher than that of the consonant inventories.
Figure 6 illustrates the average redundancy ratio
exhibited by the vowel and the consonant inventories
of a particular size (y-axis), versus the inventory size
(x-axis). The error bars indicating the variability of
RR among the inventories of a fixed size also span a
much larger range for the vowel inventories than for
the consonant inventories.
The significance of the difference in the nature of
the distribution of RRs for the vowel and the conso-
nant inventories can be again estimated by perform-
ing a t-test. The null hypothesis in this case is as
follows.
109
Figure 5: The scatter-plot of the redundancy ratio
RR of each of the vowel inventories (y-axis) versus
the inventory size (x-axis). The straight line-fit is
depicted by the bold line in the figure.
Figure 6: Curves showing the average redundancy
ratio exhibited by the vowel as well as the consonant
inventories of a particular size (y-axis), versus the
inventory size (x-axis).
Null Hypothesis: The nature of the distribution of
RRs for the vowel and the consonant inventories is
same.
We can now perform the t-test to verify whether
we can reject the above hypothesis. Table 4 presents
the results of the test. The statistics immediately
confirms that the null hypothesis can be rejected
with 99.932% confidence.
Parameters Consonant Inv. Vowel Inv.
Mean 2.51177 2.98797
SDV 0.209531 0.726547
Parameters Values
t 3.612
DF 54
p ? 0.000683
Table 4: The results of the t-test comparing the dis-
tribution of RRs for the consonant and the vowel
inventories.
4 Conclusions, Discussion and Future
Work
In this paper we have mathematically captured the
redundancy observed across the sound inventories of
the world?s languages. We started by systematically
defining the term redundancy ratio and measuring
the value of the same for the inventories. Some of
our important findings are,
1. Redundancy ratio is an invariant property of the
consonant inventories with respect to the inventory
size.
2. A more complex phenomenon than merely the
occurrence frequency results in such an invariance.
3. Unlike the consonant inventories, the vowel in-
ventories are not indicative of such an invariance.
Until now we have concentrated on establishing
the invariance of the redundancy ratio across the
consonant inventories rather than reasoning why it
could have emerged. One possible way to answer
this question is to look for the error correcting ca-
pability of the encoding scheme that nature had em-
ployed for characterization of the consonants. Ide-
ally, if redundancy has to be invariant, then this ca-
pability should be almost constant. As a proof of
concept we randomly select a consonant from in-
ventories of different size and compute its hamming
distance from the rest of the consonants in the inven-
tory. Figure 7 shows for a randomly chosen conso-
nant c from an inventory of size 10, 15, 20 and 30
respectively, the number of the consonants at a par-
ticular hamming distance from c (y-axis) versus the
hamming distance (x-axis). The curve clearly indi-
cates that majority of the consonants are at a ham-
ming distance of 4 from c, which in turn implies that
the encoding scheme has almost a fixed error cor-
recting capability of 1 bit. This can be the precise
reason behind the invariance of the redundancy ra-
110
Figure 7: Histograms showing the the number of consonants at a particular hamming distance (y-axis), from
a randomly chosen consonant c, versus the hamming distance (x-axis).
tio. Initial studies into the vowel inventories show
that for a randomly chosen vowel, its hamming dis-
tance from the other vowels in the same inventory
varies with the inventory size. In other words, the er-
ror correcting capability of a vowel inventory seems
to be dependent on the size of the inventory.
We believe that these results are significant as well
as insightful. Nevertheless, one should be aware of
the fact that the formulation of RR heavily banks
on the set of features that are used to represent the
phonemes. Unfortunately, there is no consensus on
the set of representative features, even though there
are numerous suggestions available in the literature.
However, the basic concept of RR and the process of
analysis presented here is independent of the choice
of the feature set. In the current study we have used
the binary features provided in UPSID, which could
be very well replaced by other representations, in-
cluding multi-valued feature systems; we look for-
ward to do the same as a part of our future work.
References
B. de Boer. 2000. Self-organisation in vowel systems.
Journal of Phonetics, 28(4), 441?465.
P. Boersma. 1998. Functional phonology, Doctoral the-
sis, University of Amsterdam, The Hague: Holland
Academic Graphics.
N. Clements. 2004. Features and sound inventories.
Symposium on Phonological Theory: Representations
and Architecture, CUNY.
P. R. Cohen. 1995. Empirical methods for artificial in-
telligence, MIT Press, Cambridge.
L. L. Gatlin. 1974. Conservation of Shannon?s redun-
dancy for proteins Jour. Mol. Evol., 3, 189?208.
R. Jakobson. 1941. Kindersprache, aphasie und all-
gemeine lautgesetze, Uppsala, Reprinted in Selected
Writings I. Mouton, The Hague, 1962, 328-401.
D. C. Krakauer and J. B. Plotkin. 2002. Redundancy,
antiredundancy, and the robustness of genomes. PNAS,
99(3), 1405-1409.
A. M. Lesk. 2002. Introduction to bioinformatics, Ox-
ford University Press, New York.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
world?s languages, Oxford: Blackwell.
J. Liljencrants and B. Lindblom. 1972. Numerical simu-
lation of vowel quality systems: the role of perceptual
contrast. Language, 48, 839?862.
B. Lindblom and I. Maddieson. 1988. Phonetic uni-
versals in consonant systems. Language, Speech, and
Mind, 62?78.
I. Maddieson. 1984. Patterns of sounds, Cambridge Uni-
versity Press, Cambridge.
A. Martinet 1955. `Economie des changements
phone?tiques, Berne: A. Francke.
A. Mukherjee, M. Choudhury, A. Basu and N. Ganguly.
2006. Modeling the co-occurrence principles of the
consonant inventories: A complex network approach.
arXiv:physics/0606132 (preprint).
C. E. Shannon and W. Weaver. 1949. The mathematical
theory of information, Urbana: University of Illinois
Press.
N. Trubetzkoy. 1931. Die phonologischen systeme.
TCLP, 4, 96?116.
N. Trubetzkoy. 1969. Principles of phonology, Berkeley:
University of California Press.
A. Woollard. 2005. Gene duplications and genetic re-
dundancy in C. elegans, WormBook.
111
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 221?224,
Prague, June 2007. c?2007 Association for Computational Linguistics 
Automatic Part-of-Speech Tagging for Bengali: An Approach for 
Morphologically Rich Languages in a Poor Resource Scenario 
Sandipan Dandapat, Sudeshna Sarkar, Anupam Basu 
Department of Computer Science and Engineering 
Indian Institute of Technology Kharagpur 
India 721302 
{sandipan,sudeshna,anupam.basu}@cse.iitkgp.ernet.in 
 
Abstract 
This paper describes our work on build-
ing Part-of-Speech (POS) tagger for 
Bengali. We have use Hidden Markov 
Model (HMM) and Maximum Entropy 
(ME) based stochastic taggers. Bengali is 
a morphologically rich language and our 
taggers make use of morphological and 
contextual information of the words.  
Since only a small labeled training set is 
available (45,000 words), simple stochas-
tic approach does not yield very good re-
sults. In this work, we have studied the 
effect of using a morphological analyzer 
to improve the performance of the tagger. 
We find that the use of morphology helps 
improve the accuracy of the tagger espe-
cially when less amount of tagged cor-
pora are available. 
1 Introduction 
Part-of-Speech (POS) taggers for natural lan-
guage texts have been developed using linguistic 
rules, stochastic models as well as a combination 
of both (hybrid taggers). Stochastic models (Cut-
ting et al, 1992; Dermatas et al, 1995; Brants, 
2000) have been widely used in POS tagging for 
simplicity and language independence of the 
models. Among stochastic models, bi-gram and 
tri-gram Hidden Markov Model (HMM) are 
quite popular. Development of a high accuracy 
stochastic tagger requires a large amount of an-
notated text. Stochastic taggers with more than 
95% word-level accuracy have been developed 
for English, German and other European Lan-
guages, for which large labeled data is available. 
Our aim here is to develop a stochastic POS tag-
ger for Bengali but we are limited by lack of a 
large annotated corpus for Bengali. Simple 
HMM models do not achieve high accuracy 
when the training set is small. In such cases, ad-
ditional information may be coded into the 
HMM model to achieve higher accuracy (Cutting 
et al, 1992). The semi-supervised model de-
scribed in Cutting et al (1992), makes use of 
both labeled training text and some amount of 
unlabeled text. Incorporating a diverse set of 
overlapping features in a HMM-based tagger is 
difficult and complicates the smoothing typically 
used for such taggers. In contrast, methods based 
on Maximum Entropy (Ratnaparkhi, 1996), 
Conditional Random Field (Shrivastav, 2006) 
etc. can deal with diverse, overlapping features. 
1.1 Previous Work on Indian Language 
POS Tagging 
Although some work has been done on POS tag-
ging of different Indian languages, the systems 
are still in their infancy due to resource poverty. 
Very little work has been done previously on 
POS tagging of Bengali. Bengali is the main 
language spoken in Bangladesh, the second most 
commonly spoken language in India, and the 
fourth most commonly spoken language in the 
world. Ray et al (2003) describes a morphology-
based disambiguation for Hindi POS tagging. 
System using a decision tree based learning algo-
rithm (CN2) has been developed for statistical 
Hindi POS tagging (Singh et al, 2006). A rea-
sonably good accuracy POS tagger for Hindi has 
been developed using Maximum Entropy 
Markov Model (Dalal et al, 2007). The system 
uses linguistic suffix and POS categories of a 
word along with other contextual features. 
2 Our Approach 
The problem of POS tagging can be formally 
stated as follows. Given a sequence of words w1 
? wn, we want to find the corresponding se-
quence of tags t1 ? tn, drawn from a set of tags T. 
We use a tagset of 40 tags1. In this work, we ex-
plore supervised and semi-supervised bi-gram 
                                                 
1 http://www.mla.iitkgp.ernet.in/Tag.html 
221
 HMM and a ME based model. The bi-gram as-
sumption states that the POS-tag of a word de-
pends on the current word and the POS tag of the 
previous word. An ME model estimates the prob-
abilities based on the imposed constraints. Such 
constraints are derived from the training data, 
maintaining some relationship between features 
and outcomes. The most probable tag sequence 
for a given word sequence satisfies equation (1) 
and (2) respectively for HMM and ME model: 
1
1
... 1,
( | ) ( | )arg max i i i i
t tn i n
S P w t P t t ?
=
= ?      (1) 
1 1
1,
( ... | ... ) ( | )n n i i
i n
p t t w w p t h
=
= ?       (2) 
Here, hi is the context for word wi. Since the ba-
sic bigram model of HMM as well as the equiva-
lent ME models do not yield satisfactory accu-
racy, we wish to explore whether other available 
resources like a morphological analyzer can be 
used appropriately for better accuracy.  
2.1 HMM and ME based Taggers 
Three taggers have been implemented based on 
bigram HMM and ME model. The first tagger 
(we shall call it HMM-S) makes use of the su-
pervised HMM model parameters, whereas the 
second tagger (we shall call it HMM-SS) uses 
the semi supervised model parameters. The third 
tagger uses ME based model to find the most 
probable tag sequence for a given sequence of 
words.  
 
In order to further improve the tagging accuracy, 
we use a Morphological Analyzer (MA) and in-
tegrate morphological information with the mod-
els. We assume that the POS-tag of a word w can 
take values from the set TMA(w), where TMA(w) is 
computed by the Morphological Analyzer. Note 
that the size of TMA(w) is much smaller than T. 
Thus, we have a restricted choice of tags as well 
as tag sequences for a given sentence. Since the 
correct tag t for w is always in TMA(w) (assuming 
that the morphological analyzer is complete), it is 
always possible to find out the correct tag se-
quence for a sentence even after applying the 
morphological restriction. Due to a much re-
duced set of possibilities, this model is expected 
to perform better for both the HMM (HMM-S 
and HMM-SS) and ME models even when only a 
small amount of labeled training text is available. 
We shall call these new models HMM-S+MA, 
HMM-SS+ MA and ME+MA.  
 
Our MA has high accuracy and coverage but it 
still has some missing words and a few errors. 
For the purpose of these experiments we have 
made sure that all words of the test set are pre-
sent in the root dictionary that an MA uses. 
 
While MA helps us to restrict the possible choice 
of tags for a given word, one can also use suffix 
information (i.e., the sequence of last few charac-
ters of a word) to further improve the models. 
For HMM models, suffix information has been 
used during smoothing of emission probabilities, 
whereas for ME models, suffix information is 
used as another type of feature. We shall denote 
the models with suffix information with a ?+suf? 
marker. Thus, we have ? HMM-S+suf, HMM-
S+suf+MA, HMM-SS+suf etc. 
2.1.1 Unknown Word Hypothesis in HMM 
The transition probabilities are estimated by lin-
ear interpolation of unigrams and bigrams. For 
the estimation of emission probabilities add-one 
smoothing or suffix information is used for the 
unknown words. If the word is unknown to the 
morphological analyzer, we assume that the 
POS-tag of that word belongs to any of the open 
class grammatical categories (all classes of 
Noun, Verb, Adjective, Adverb and Interjection). 
2.1.2 Features of the ME Model 
Experiments were carried out to find out the 
most suitable binary valued features for the POS 
tagging in the ME model. The main features for 
the POS tagging task have been identified based 
on the different possible combination of the 
available word and tag context. The features also 
include prefix and suffix up to length four. We 
considered different combinations from the fol-
lowing set for obtaining the best feature set for 
the POS tagging task with the data we have. 
 { }11 2 2 1 2, , , , , , , 4, 4ii i i i i iF w w w w w t t pre suf+? ? + ? ?= ? ?  
 
Forty different experiments were conducted tak-
ing several combinations from set ?F? to identify 
the best suited feature set for the POS tagging 
task. From our empirical analysis we found that 
the combination of contextual features (current 
word and previous tag), prefixes and suffixes of 
length ? 4 gives the best performance for the ME 
model. It is interesting to note that the inclusion 
of prefix and suffix for all words gives better 
result instead of using only for rare words as is 
described in Ratnaparkhi (1996). This can be 
explained by the fact that due to small amount of 
annotated data, a significant number of instances 
222
 are not found for most of the word of the 
language vocabulary.   
3 Experiments 
We have a total of 12 models as described in 
subsection 2.1 under different stochastic tagging 
schemes. The same training text has been used to 
estimate the parameters for all the models. The 
model parameters for supervised HMM and ME 
models are estimated from the annotated text 
corpus. For semi-supervised learning, the HMM 
learned through supervised training is considered 
as the initial model. Further, a larger unlabelled 
training data has been used to re-estimate the 
model parameters of the semi-supervised HMM. 
The experiments were conducted with three dif-
ferent sizes (10K, 20K and 40K words) of the 
training data to understand the relative perform-
ance of the models as we keep on increasing the 
size of the annotated data.   
3.1 Training Data 
The training data includes manually annotated 
3625 sentences (approximately 40,000 words) 
for both supervised HMM and ME model. A 
fixed set of 11,000 unlabeled sentences (ap-
proximately 100,000 words) taken from CIIL 
corpus 2  are used to re-estimate the model pa-
rameter during semi-supervised learning. It has 
been observed that the corpus ambiguity (mean 
number of possible tags for each word) in the 
training text is 1.77 which is much larger com-
pared to the European languages (Dermatas et 
al., 1995).  
3.2 Test Data 
All the models have been tested on a set of ran-
domly drawn 400 sentences (5000 words) dis-
joint from the training corpus. It has been noted 
that 14% words in the open testing text are un-
known with respect to the training set, which is 
also a little higher compared to the European 
languages (Dermatas et al, 1995) 
3.3 Results 
We define the tagging accuracy as the ratio of 
the correctly tagged words to the total number of 
words. Table 1 summarizes the final accuracies 
achieved by different learning methods with the 
varying size of the training data. Note that the 
baseline model (i.e., the tag probabilities depends 
                                                 
2 A part of the EMILE/CIIL corpus developed at Cen-
tral Institute of Indian Languages (CIIL), Mysore. 
only on the current word) has an accuracy of 
76.8%.  
 
Accuracy Method 
10K 20K 40K 
HMM-S 57.53 70.61 77.29 
HMM-S+suf 75.12 79.76 83.85 
HMM-S+MA 82.39 84.06 86.64 
HMM-S+suf+MA 84.73 87.35 88.75 
HMM-SS 63.40 70.67 77.16 
HMM-SS+suf 75.08 79.31 83.76 
HMM-SS+MA 83.04 84.47 86.41 
HMM-SS+suf+MA 84.41 87.16 87.95 
ME 74.37 79.50 84.56 
ME+suf 77.38 82.63 86.78 
ME+MA 82.34 84.97 87.38 
ME+suf+MA 84.13 87.07 88.41 
Table 1: Tagging accuracies (in %) of different 
models with 10K, 20K and 40K training data. 
3.4 Observations 
We find that in both the HMM based models 
(HMM-S and HMM-SS), the use of suffix in-
formation as well as the use of a morphological 
analyzer improves the accuracy of POS tagging 
with respect to the base models. The use of MA 
gives better results than the use of suffix infor-
mation. When we use both suffix information as 
well as MA, the results is even better. 
 
HMM-SS does better than HMM-S when very 
little tagged data is available, for example, when 
we use 10K training corpus. However, the accu-
racy of the semi-supervised HMM models are 
slightly poorer than that of the supervised HMM 
models for moderate size training data and use of 
suffix information. This discrepancy arises due 
to the over-fitting of the supervised models in the 
case of small training data; the problem is allevi-
ated with the increase in the annotated data. 
 
As we have noted already the use of MA and/or 
suffix information improves the accuracy of the 
POS tagger. But what is significant to note is that 
the percentage of improvement is higher when 
the amount of training data is less. The HMM-
S+suf model gives an improvement of around 
18%, 9% and 6% over the HMM-S model for 
10K, 20K and 40K training data respectively. 
Similar trends are observed in the case of the 
semi-supervised HMM and the ME models. The 
use of morphological restriction (HMM-S+MA) 
gives an improvement of 25%, 14% and 9% re-
spectively over the HMM-S in case of 10K, 20K 
223
 and 40K training data. As the improvement due 
to MA decreases with increasing data, it might 
be concluded that the use of morphological re-
striction may not improve the accuracy when a 
large amount of training data is available. From 
our empirical observations we found that both 
suffix and morphological restriction (HMM-
S+suf+MA) gives an improvement of 27%, 17% 
and 12% over the HMM-S model respectively 
for the three different sizes of training data. 
 
The Maximum Entropy model does better than 
the HMM models for smaller training data. But 
with higher amount of training data the perform-
ance of the HMM and ME model are compara-
ble. Here also we observe that suffix information 
and MA have positive effect, and the effect is 
higher with poor resources.  
 
Furthermore, in order to estimate the relative per-
formance of the models, experiments were car-
ried out with two existing taggers: TnT (Brants, 
2000) and ACOPOST3. The accuracy achieved 
using TnT are 87.44% and 87.36% respectively 
with bigram and trigram model for 40K training 
data. The accuracy with ACOPOST is 86.3%.  
This reflects that the higher order Markov mod-
els do not work well under the current experi-
mental setup.  
3.5 Assessment of Error Types 
Table 2 shows the top five confusion classes for 
HMM-S+MA model. The most common types of 
errors are the confusion between proper noun 
and common noun and the confusion between 
adjective and common noun. This results from 
the fact that most of the proper nouns can be 
used as common nouns and most of the adjec-
tives can be used as common nouns in Bengali.  
 
Actual 
Class 
(frequency) 
Predicted 
Class 
% of total 
errors 
% of 
class 
errors 
NP(251) NN 21.03 43.82 
JJ(311) NN 5.16 8.68 
NN(1483) JJ 4.78 1.68 
DTA(100) PP 2.87 15.0 
NN(1483) VN 2.29 0.81 
Table 2: Five most common types of errors  
Almost all the confusions are wrong assignment 
due to less number of instances in the training 
corpora, including errors due to long distance 
phenomena. 
                                                 
3 http://maxent.sourceforge.net 
4 Conclusion 
In this paper we have described an approach for 
automatic stochastic tagging of natural language 
text for Bengali. The models described here are 
very simple and efficient for automatic tagging 
even when the amount of available annotated 
text is small. The models have a much higher 
accuracy than the na?ve baseline model. How-
ever, the performance of the current system is 
not as good as that of the contemporary POS-
taggers available for English and other European 
languages. The best performance is achieved for 
the supervised learning model along with suffix 
information and morphological restriction on the 
possible grammatical categories of a word. In 
fact, the use of MA in any of the models dis-
cussed above enhances the performance of the 
POS tagger significantly. We conclude that the 
use of morphological features is especially help-
ful to develop a reasonable POS tagger when 
tagged resources are limited.  
References 
A. Dalal, K. Nagaraj, U. Swant, S. Shelke and P. 
Bhattacharyya. 2007. Building Feature Rich POS 
Tagger for Morphologically Rich Languages: Ex-
perience in Hindi. ICON, 2007. 
A. Ratnaparkhi, 1996. A maximum entropy part-of-
speech tagger. EMNLP 1996. pp. 133-142. 
D. Cutting, J. Kupiec, J. Pederson and P. Sibun. 1992. 
A practical part-of-speech tagger. In Proc. of the 
3rd Conference on Applied NLP, pp. 133-140.  
E. Dermatas and K. George. 1995. Automatic stochas-
tic tagging of natural language texts. Computa-
tional Linguistics, 21(2): 137-163. 
M. Shrivastav, R. Melz, S. Singh, K. Gupta and 
P. Bhattacharyya, 2006. Conditional Random 
Field Based POS Tagger for Hindi. In Pro-
ceedings of the MSPIL, pp. 63-68. 
P. R. Ray, V. Harish, A. Basu and S. Sarkar, 2003. 
Part of Speech Tagging and Local Word Grouping 
Techniques for Natural Language Processing.  
ICON 2003. 
S. Singh, K. Gupta, M. Shrivastav and P. Bhat-
tacharyya, 2006. Morphological Richness Offset 
Resource Demand ? Experience in constructing a 
POS Tagger for Hindi. COLING/ACL 2006, pp. 
779-786. 
T. Brants. 2000. TnT ? A statistical part-of-sppech 
tagger. In Proc. of the 6th Applied NLP Conference, 
pp. 224-231.  
224
A Diachronic Approach for Schwa Deletion in Indo Aryan Languages 
Monojit CHOUDHURY, Anupam BASU and Sudeshna SARKAR 
Dept.. of Computer Science & Engineering, 
Indian Institute of Technology, Kharagpur 
INDIA, PIN-721302 
{ monojit, anupam, sudeshna } @cse.iitkgp.ernet.in  
 
 
Abstract 
Schwa deletion is an important issue in 
grapheme-to-phoneme conversion for Indo-
Aryan languages (IAL). In this paper, we 
describe a syllable minimization based 
algorithm for dealing with this that 
outperforms the existing methods in terms of 
efficiency and accuracy. The algorithm is 
motivated by the fact that deletion of schwa is 
a diachronic and sociolinguistic phenomenon 
that facilitates faster communication through 
syllable economy. The contribution of the 
paper is not just a better algorithm for schwa 
deletion; rather we describe here a constrained 
optimization based framework that can partly 
model the evolution of languages, and hence, 
can be used for solving many problems in 
computational linguistics that call for 
diachronic explanations. 
 
1 Introduction 
Linguists propose new models for languages 
in order to explain language acquisition and 
processing by humans. Irregularities and 
exceptions to the theories are often explained by 
evidence from diachronic linguistics and other 
social and external phenomena. Absence of 
diachronic analysis in computational modelling of 
languages results in a large number of exceptions, 
which are commonly handled by ad hoc rules or 
exhaustive enumeration. These techniques lead to 
poor scalability and lack of graceful degradation of 
the systems along with increased complexity. 
Although complete modelling of the evolution of 
language is impossible due to the involvement of 
myriads of socio-political and cultural factors, it is 
definitely possible to model certain basic 
principles of language change. 
In this paper we describe an algorithm for 
schwa deletion in Indo-Aryan Languages (IAL) 
that is motivated by the diachronic evolution of the 
languages. The proposed computational framework 
models languages as a constrained optimization 
system, where a language evolves by optimizing 
the rate of communication, subjected to a set of 
constraints such as ease of articulation and 
learning, and acoustic distinctiveness. A syllable 
minimization based optimization function fitted to 
the aforementioned model has been used for 
solving the problem of schwa deletion with 
considerable success.  
The paper is organized as follows: Section 2 
defines the problem and discusses some of the 
previous works. Section 3 describes the current 
models of language evolution, which has been 
used to develop a computational framework 
described in the next section. Section 5 and 6 
presents the algorithm and its experimental 
analysis respectively. Section 7 concludes the 
paper summarizing our contributions. 
2 The Problem  
Schwa is defined as the mid-central vowel that 
occurs in unstressed syllables. The first vowel of 
the IAL alphabet {a}1 is the schwa. Normally, it is 
pronounced as /?/ in Hindi and Sanskrit, and as /?/ 
in Bengali. Schwa deletion is a phonological 
phenomenon where schwa is absent in the 
pronunciation of a particular word, although 
ideally it should have been pronounced (Ohala, 
1983).  
Sanskrit and some of the modern IAL that have 
evolved from it (e.g. Hindi and Bengali), are 
written from left to right using Brahmi-derived 
scripts. All the vowels are explicitly represented 
using diacritical or non-diacritical marks around 
the consonant except for the schwa, which is the 
inherent vowel. Unlike Sanskrit, many modern 
IAL like Hindi and Bengali allow deletion of 
schwa in certain contexts. Table I illustrates this 
phenomenon for the three languages. In order to 
determine the proper pronunciation of the words, it 
is necessary to predict which schwas are deleted 
and which are not. Thus, schwa deletion is an 
                                                     
1 The graphemes for Indo-Aryan languages are written within ?{? and ?}? 
according to the scheme adopted by the International Congress of Orientalists at 
Athens in 1992. The phonetic transcriptions are written within two ?/? using the 
IPA symbols. 
                                                                  Barcelona, July 2004
                                              Association for Computations Linguistics
                       ACL Special Interest Group on Computational Phonology (SIGPHON)
                                                    Proceedings of the Workshop of the
important issue for grapheme-to-phoneme 
conversion of IAL, which in turn is required for a 
good Text-to-Speech synthesizer (Narasimhan et 
al, 2001).  
 
Pronunciation   The  
Spelling Sanskri
t 
Hind
i 
Bengali 
s?phaly
a 
(succes
s) 
sa??ly
? 
(3) 
sa??
lj? 
(3) 
?a?ol lo 
(3) 
racan? 
(creati
on) 
r?c?na 
(3) 
r?cn
a 
(2) 
r?cona 
(3) 
veda 
(Veda) 
ved? 
(2) 
ved 
(1) 
bed 
(1) 
 
Table 1. Pronunciation of three different words 
in three different IAL. The number of syllables is 
denoted within parenthesis below the 
pronunciations. In Bengali {a} can also be 
pronounced as /o/ in certain contexts. 
 
Several theories have been proposed on the 
linguistic aspects of schwa deletion in Hindi (Pray, 
1970; Kaira 1976; Ohala, 1977, 1983) and its 
diachronic evolution (Misra, 1967). Ohala (1983) 
has summarized the rule for schwa deletion in 
Hindi as  
? ?   ? / VC __ CV 
Condition 1: There may be no morpheme 
boundary in the environment to the left. 
Condition 2: The output of the rule should not 
violate the phonotactic constraints of Hindi 
Convention: The rule applies from right to left 
 
The explanation of the rule was based on 
psycholinguistic evidence; diachronic facts were 
used only to explain the exceptions. Narsimhan et 
al (2001) designed an algorithm for schwa deletion 
in Hindi based on this work. The reported accuracy 
of the algorithm is 89%. Some rules for word final 
schwa deletion in Bengali have been proposed by 
Chatterji (1926), but we do not know of any work 
on computational modelling. 
 
3 Factors governing language change 
The fact that schwa deletion in IAL is a diachronic 
phenomenon has been substantiated by Misra 
(1967). According to Ohala (1983) the deletion of 
schwas is more frequent in casual and fast speech 
compared to formal and slower ones. It can be 
inferred from these facts that the motivation behind 
schwa deletion is faster communication through 
minimization of syllables (Tranel 1999).  
 Some recent works on mathematical and 
simulation based modelling of language evolution 
(Boer, 2000; Cangelosi and Parisi, 2002; Nowak et 
al, 2002) suggests that several features of 
languages emerge due to some basic cognitive and 
articulatory factors. These models assume a) ease 
of articulation, b) ease of learning, and c) acoustic 
distinctiveness as the primary driving forces 
behind language evolution. The three forces 
operate simultaneously over the language in order 
to maximize the rate of successful communication 
in terms of time and effort spent by the language 
users to generate, understand and learn the 
language. Thus, language can be modelled as a 
multi-objective optimization system, where the 
optimization criteria are 
 
? Minimization of effort (in terms of energy and 
time spent while conveying a piece of 
information)  
? Minimization of learning time and effort 
? Minimization of probability of 
misunderstanding (in the sense of confusing 
one word with another) 
 
These three criteria are mutually contradictory and 
therefore there exists no global optimum. Let us 
examine the phenomenon of schwa deletion under 
this multi-objective optimization model for 
language evolution. When a vowel is deleted from 
a word the number of syllables reduces by one. For 
example, in Table 1, for the second word, Sanskrit 
and Bengali have three syllables, whereas due to 
the deletion of a schwa, the Hindi pronunciation 
has only two syllables. Reduction of syllables 
implies shorter time for pronunciation of a word, 
and hence faster communication. However, 
deletion of schwas in certain contexts might result 
in a consonant cluster which the native speakers 
find very difficult or impossible to pronounce. This 
beats the very purpose of schwa deletion, i.e. the 
minimization of effort of articulation and therefore, 
is unacceptable. The second condition for the rule 
proposed by Ohala (section 2) refers to this 
constraint. 
 There are contexts where deletion of schwa 
would not give rise to inadmissible consonant 
clusters. For example, in the Hindi/Bengali word 
pari (fairy, /p?ri/ in Hindi), if the first schwa is 
deleted, the pronunciation would be /pri/, which 
does not violate the phonotactic constraints of the 
languages. The schwa, however, is not deleted, 
because /p?ri/ and /pri/ are too distinct from each 
other to be interpreted as the same word. 
Moreover, /pri/ is closer to other Hindi words like 
priya (favorite, /prij?/). In this case, the deletion of 
schwa reduces the acoustic distinctiveness of the 
word from other words in the lexicon, which 
increases the probability of misunderstanding, and 
hence the schwa might not be deleted in such a 
context. 
4 Computational framework 
We propose the following diachronic 
explanation for schwa deletion in IAL.  
In old IAL none of the schwas are deleted. The 
modern IAL use the script and spelling 
conventions similar to Sanskrit. Due to a higher 
evolutionary pressure on the spoken forms of the 
languages than on the written forms, schwas are 
deleted in the pronunciation, but are still present in 
the graphemic forms. The deletion is a slow 
diachronic phenomenon, where in order to 
communicate faster, initially the speakers 
unintentionally deleted the schwas. Only those 
deletions were acceptable that did not lead to a 
syllable structure which was too difficult to 
pronounce, learn or understand for the native 
speakers. Gradually, the pattern of deletion spread 
across the population and over the different items 
in the lexicon. 
In this section, we describe a computational 
framework for modelling the aforementioned 
hypothesis based on the three optimization criteria 
stated in the last section. The aim of the proposed 
framework is not to validate the hypothesis 
through micro-simulation (Cangelosi and Parisi, 
2002); rather it tries to predict the schwa deletion 
pattern based on the optimizations that might have 
affected the deletion of schwas diachronically. In 
the next section, we present an efficient algorithm 
for schwa deletion in IAL, which can be 
automatically constructed from this model, without 
the help of any other evidence. 
 
4.1 Basic definitions 
 All the unexplained symbols used below stand 
for their usual meaning in the context of formal 
language theory. Please refer to (Hopcroft and 
Ullman, 1979) for details. 
 
?g (?p): A finite set of the graphemes 2 
(phonemes) in the language  
?g = Vg ? Cg,  ?p = Vp  ? Cp  
                                                     
2  Graphemes here do not refer to glyphs. Free vowels and their 
corresponding diacritical marks are considered to be the same symbol 
Where 
Vg (Vp): Finite set of graphemes (phonemes), 
which are vowels 
Cg (Cp): Finite set of graphemes (phonemes), 
which are consonants. Semivowels are also 
considered as consonants. 
 
? ? Vg is a special symbol that represents schwa. 
We define, 
fg2p: ?g ? ?p 
fg2p is the default mapping of the graphemes to 
the phonemes. This oversimplification is made 
here for two reasons. First, since IAL use a 
phonetic script, this in general is true3 and second, 
this assumption does not have any affect on the 
schwa deletion algorithm.  
 
A word w is defined as a 2-tuple <wg, wp>, 
where  
wg ? ?g+ and wp? ?p+ 
 
A lexicon ? is the union of all the valid words w 
of a language. A grapheme-to-phoneme converter 
is defined as a function Fg2p: ?g+? ?p+, such that 
?w < wg, wp >? ?, Fg2p(wg) = wp 
 
4.2 Phonotactic constraints 
In order to model the ease of articulation, we 
start with the modelling of phonotactic constraints. 
A consonant cluster is a string of the form CpCp+. 
Phonotactic constraints restrict the presence of 
some of the consonant clusters in the phonetic 
representation of a word (wp). At the most generic 
level we can think of a consonant cluster ranking 
(CCR) function, where ? is the set of natural 
numbers       
                 
CCR: Cp+ ? ? 
 
The function CCR is independent of any 
language and every language has a threshold ?CCR, 
such that a consonant cluster x ? Cp+ is allowed in 
the language if and only if    
           
CCR (x) ? ?CCR 
 
We define two special variants of CCR, O_CCR 
and C_CCR, which ranks the admissibility of the 
consonant clusters at the onset and coda positions 
respectively. The definition is similar to that of 
CCR, and ?OCCR and ?CCCR are the corresponding 
threshold values.  
                                                     
3 This assumption is not strictly valid since a cluster of consonant might be 
mapped to a single consonant or a different cluster.    
The sonority hierarchy (Vennemann, 1988) and 
markedness conditions (Kager, 1999) along with 
the physiology of the articulatory mechanism point 
towards the existence of a language independent 
ranking function as hypothesized above. However, 
there might be accidental gaps in the list of 
admissible consonant clusters of a language 
(Ohala, 1983), which can not be explained on the 
basis of CCR alone. Therefore, we define a 
Boolean function ADM that tell us about the 
admissibility of consonant clusters in a language. 
 
ADM: Cp+ ? {0, 1}, such that for s ? Cp+ 
 (ADM (s) = 1) ?  (s is an admissible cluster) 
 
In general, we can derive this function from 
CCR as 
ADM (s) = sign (?CCR    ? CCR (s)) 
 
However, we might have to forcefully convert 
some values to 0 due to accidental gaps.   
 
4.3 Syllable and Syllabification 
We define a syllable ? as a regular expression, 
with the assumption that the nucleus contains a 
single vowel. Thus, 
? ? Cp* Vp Cp* 
 
The syllabification function SYL maps the 
phonetic representation wp of a word w to a string 
of syllables ?1?2??m such that the effort of 
articulation and learning are minimum. 
 
We model the effort of articulation using a 
syllable ranking function SR, which is similar to 
CCR. 
 SR : Cp*VpCp* ? ? 
 
SR is mainly dependent on the structure of the 
syllable. We enumerate the first few terms of the 
function SR.          
 
SR (Vp) = 1,  SR (CpVp) = 2   
SR (CpVpCp) = 3, SR (VpCp) = 4 
SR (CpCpVp) = 5,  SR (CpCpVpCp) = 6 
SR (CpCpCpVp) = 7,  SR (CpVpCpCp) = 8 
 
For all other possible syllable structures ??,  
SR (??) > 8 
 
Also, for any syllable ?,    
[O_CCR (onset(?)) >  ?OCCR] ? 
[C_CCR (coda(?)) >  ?CCCR] ? (SR (?) = ? ) 
 
This means that if either the coda or the onset of 
a syllable is inadmissible, then the ranking 
function maps the syllable to the highest possible 
rank, represented symbolically by the infinity (?). 
onset and coda are projection functions that project 
the longest valid prefix and suffix of a syllable 
respectively that are elements of  Cp*. 
 
We define a syllabification to be valid if all the 
syllables are valid (i.e. strings of the form 
Cp*VpCp*) and every symbol in the word is a part 
of one and only one syllable in the syllabification. 
We can define a partial ordering, ??, among the 
possible valid syllabifications of a given word 
based on SRp such that the syllabification with 
smaller number of high ranked syllables is 
preferred to one that has more hard (high ranked) 
syllables. Now we define SYL (wp) as the set of all 
possible syllabifications ?1?2??m such that (i) 
?1?2??m is a valid syllabification of  wp and (ii) 
there exist no other valid syllabification v of wp 
such that v ?? ?1?2??m.  
 
The definitions of syllable and syllabification are 
motivated by the markedness conditions (Kager, 
1999) and experimental results on child language 
acquisition (MacNeilage and Davis, 2000), that 
show that some syllables and syllabifications are 
easier to learn and pronounce than others. 
 
4.4 Acoustic distinctiveness constraints 
Perceptual experiments show that speakers 
always articulate the onset of the syllables more 
clearly and correctly compared to the articulations 
of the vowel and the coda (Fosler-Lussier et al 
1999; Greenberg, 1999). Therefore, it is likely that 
the hearer distinguish between syllables by paying 
more weight to the onset than to the coda. A 
continuous distance metric D? might be defined 
based on these experimental results, such that the 
probability of confusion (interpreting one syllable 
as another) between two syllables ? and ?? 
increases as the value of D?(? , ??) decreases. We 
can further define an acoustic distance function Dw 
using the function D? , which measures the 
probability of confusion between two arbitrary 
words in the phonetic domain. 
In the case of schwa deletion, however, we want 
the acoustic distance between the ideal 
pronunciation (without any schwa deletion) and 
the normal pronunciation (with schwa deletion) to 
be smaller, so that the word is not confused with 
other words in the lexicon. Formally, for the 
graphemic representation of a word wg = x1x2 ? 
xn, 
Dw(fg2p (x1).fg2p (x2)? fg2p (xn), Fg2p(wg)) < 
?critical, where ?critical is the maximum allowable 
distance and ?.? is the concatenation operator. 
Rather than modelling this as an optimization 
criterion, we reformulate this as a constraint. The 
simplification in this case serves our purpose. 
 
We define, where x ? Cp   
D?(x. fg2p(?), ?) = 0                  (4a) 
 D?(?, ?.x) = 0          (4b) 
For all other cases D?  is infinity (?), unless the 
two syllables are identical.             (4c) 
 
(4a) allows the deletion of a schwa from an open 
syllable; (4b) allows the concatenation of a 
consonant at the coda position. This is motivated 
by the fact that coda has least distinctiveness 
(Greenberg, 1999). (4c) restricts any change at the 
onset of a syllable or the vowels other than schwa.  
 
On the basis of D? we can define  Dw(wp1, wp2) = 
0 if and only if there exists an alignment between 
the sequences SYL (wp1) and SYL (wp2), with 
possible gaps (? or null syllables) such that for all 
the corresponding pairs of syllable taken from the 
two sequences, the acoustic distinctiveness (D?) 
between them is 0. Thus, only operations allowed 
are deletion of a schwa and addition of a consonant 
at the coda position. Anything else is forbidden for 
the sake of acoustic distinctiveness.  
 
We conclude this section by summarizing below 
the salient features of the model by comparing it 
with the optimization criteria stated in section 3. 
 
? The functions SR, CCR and its variants 
that rank the phonotactic constraints is a measure 
of the effort of articulation, learning and the 
probability of misunderstanding. Therefore we 
want to minimize it. However, it has been 
modelled as a constraint (ADM). 
? The function SYL is so defined that the 
efforts of articulation and learning are minimized. 
? Dw models the acoustic distinctiveness i.e. 
the criterion 3c, but it has been reformulated as a 
constraint as well.  
5 The algorithm 
We want to define Fg2p for a language given 
ADM and Dw. Fg2p should be such that it enables 
faster communication by minimization of syllables 
by deletion of schwa. 
 
5.1 Formal definition 
Let wg be an input sequence of graphemes to the 
function Fg2p. Let wp ? ?p* be obtained by 
replacing all graphemes x in wg by fg2p(x). Let wp? 
be obtained by deletion of some (possibly all or 
none) of the schwas (fg2p(?)) in wp. Fg2p(wg) = wp?, 
if and only if Dw(wp, wp?) = 0  and (? vp)[( vp can 
be obtained by deleting schwas from  wp) ? 
(Dw(wp, vp) = 0) ? |SYLg(wp?)| ? |SYLg(vp)| ] 
 
In words it means that among all wp? obtainable 
by deletion of some of the schwas from wp, that 
respects both the ADM (phonotactic) and Dw 
(acoustic distinctiveness) constraints, the one with 
the minimum number of syllables is chosen as the 
output of Fg2p.  
 
procedure SYL : 
input: wp, O_CCR, C_CCR 
output:  ?1?2??m  //The syllabification 
 
1. Include up to the first vowel in wp in ?1 
2. If there are 2 consonants c1c2 between the 
current vowel and the next vowel, include c1 in the 
current syllable and c2 in the next syllable. 
3. If there are 3 consonants c1c2c3 between the 
current vowel and the next vowel,  
     3.1 if O_CCRp(c2c3)? ?OCCR , include c1 in the 
current syllable and c2c3 in the next syllable  
     3.2 else if C_CCRp(c1c2)? ?CCCR include c1c2 in the 
current syllable and c3 in the next syllable 
     3.3 else NO syllabification is possible 
4. If there is one or no consonant between the 
current vowel and the next vowel, terminate the 
current syllable and begin the next syllable 
5. Continue from step 2 till there are symbols not 
included in any syllable.  
end procedure 
 
 
Figure 1. Algorithm for syllabification 
 
5.2 A greedy strategy  
Figure 1 describes a linear time algorithm for 
syllabification (SYL) that conforms to the 
definition provided in section 4.3. This uses the 
fact that the maximum length of allowable 
consonant clusters for IAL is three. After 
syllabification of wp, we try to greedily delete the 
schwas so that the constraints specified by 4a, 4b 
and 4c are not violated. 4a states that only a schwa 
which is a part of an open syllable (c?, where c ? 
Cp) can be deleted and 4b states that after schwa 
deletion, 
the consonant c is appended to the coda of the 
previous syllable. Therefore, both of them together 
imply schwas in two consecutive syllables cannot 
be deleted. Along with that, the following 
constraints can also be derived from the Dw 
constraints (the reasons are omitted due to space 
constraints): 
R1. Schwa of the first syllable cannot be deleted 
R2. Schwa cannot be deleted before a consonant 
cluster. 
R3. The word final schwa can always be deleted 
unless the appending of the penultimate 
consonant to the previous syllable results in an 
inadmissible cluster. 
R4. For Bengali, which does not allow complex 
codas, schwas cannot be deleted after 
consonant clusters. 
R5. A schwa followed by a vowel cannot be 
deleted. 
 
procedure Fg2p: 
input: wg , ADM 
output:  wp  //The pronunciation 
 
1. wp?  = fg2p(x1).fg2p (x2)? fg2p (xn), where wg is 
<x1x2 ? xn > 
2. Syllabify wp?  using procedure SYL 
3. Using rules R1 to R6 and ADM constraints mark 
the schwas which cannot be deleted as F 
4.  While traversing the word from right to left 
         4.1 Delete a schwa if it is not marked F 
         4.2 Appended the dangling consonant to the 
coda of the adjacent syllable (to the left) 
         4.3 If the adjacent syllable (to the left) has a 
schwa which is unmarked, mark it F 
         4.4 Go to 4.1 if there are more schwas to the left 
of the current position. 
5. At the end of step 4 we get the syllabified string of 
phonemes <x?1x?2 ? x?m >, which is the required 
output 
end procedure 
 
Figure 2. Algorithm for schwa deletion 
 
 We have the following rule that cannot be 
captured by the constraints: 
R6. Schwa following a y (pronounced as /j/) 
cannot be deleted if it is preceded by a high 
vowel because /j/ is a glide from high vowel to 
a low/medium vowel (schwa), deletion of 
schwa would make the presence of the glide 
imperceptible. 
This rule could have been captured by the D? 
constraints but we state it here as a separate rule 
for the sake of simplicity. Figure 2 describes an 
algorithm for schwa deletion using the rules above. 
It is easy to see that the time complexity of the 
algorithm is O(|wg|). Due to limited space, we omit 
the proof that the algorithm for Fg2p indeed 
minimizes the number of syllables without 
violating the constraints specified by ADM and Dw. 
However, there might be more than one (precisely 
2) possible solutions and in that case the algorithm 
chooses one of the solutions on the basis of the 
direction of traversal at step 4. The right to left 
traversal gives better results (as has been 
confirmed by Ohala, 1983) because the duration of 
syllables reduces towards the end of the word and 
hence the tendency to delete schwas at the word 
final position increases. 
6 Experimental Results and Discussions 
The algorithm was implemented for Bengali and 
Hindi and tested on a set of words. Table 2 
summarizes the results for Hindi (tested on the 
words in a pocket dictionary (Hindi-Bangla-
English, 2001)). The algorithm for Bengali was 
tested on 1000 randomly selected words from a 
corpus and found to be around 85% accurate.  
Some of the important features of the algorithm 
are as follows. 
? Efficiency: The algorithm runs in linear time 
on the input word length. It scans the whole 
word just twice. Thus, the hidden constant is 
also very small. 
? Polymorphemic Words: The algorithm can 
handle polymorphemic words, if the 
morphological information about the word is 
provided. This is because schwa deletion is not 
carried across morpheme boundaries. 
Morphological analyzer for Hindi and Bengali 
were implemented and integrated with the 
algorithm. For Hindi, the results were nearly 
perfect (99.89%) 
Exceptions: For Hindi there was hardly any 
exception to the algorithm. For Bengali, the types 
of words that were incorrectly processed by the 
algorithm include a class of very frequently used, 
disyllabic modifier adjectives, certain suffixes, 
borrowed words from Sanskrit and compound 
words. In Bengali, the schwa which is retained (as 
opposed to the predictions by the algorithm) are 
pronounced as /o/ and not as / ?/. Since, /o/ is not a 
central vowel, deletion of /o/ is marked as 
compared to deletion of / ?/ which is unmarked. 
Transformation of schwa to some non-neutral 
vowel in Hindi is unknown and therefore, the 
algorithm works perfectly for Hindi. 
 
Experiment
al results for 
Hindi 
Test 
Size 
(No. of 
words) 
Incorre
ct results 
Accurac
y 
Without 
MA 
1109
5 
431 96.12% 
With MA 1109
5 
12 99.89% 
 
Table 2. Experimental results for Hindi schwa 
deletion. The results are for individual words. MA 
stands for Morphological Analysis 
7 Conclusion 
In this paper, we have described the 
phenomenon of schwa deletion in the IAL and 
proposed a diachronic explanation for it. In order 
to model the diachronic evolution, we used the 
concepts of ease of articulation, ease of learning 
and acoustic distinctiveness. We developed a 
computational framework, where we reformulated 
some of the optimization criteria as constraints and 
one of them (the syllable minimization) as the 
basic optimization function. The outcome of this is 
an efficient and accurate algorithm for solving 
schwa deletion in IAL. 
The contribution of this paper is not just a 
better algorithm for schwa deletion, which is 
necessary for developing Text-to-speech 
synthesizers for IAL, but a new approach based on 
a constrained optimization framework, motivated 
by the diachronic evolution of languages. A closer 
look at the algorithm will reveal that it is not much 
different from the schwa deletion rule proposed by 
Ohala (1983). However, Ohala?s rule was based on 
psycholinguistic and empirical observations, 
whereas we have derived the rule from a set of 
very basic assumptions (minimization of syllables 
and certain constraints). The algorithm itself can 
provide an explanation for the phenomenon. 
It must be mentioned that neither the aim nor 
the findings of this work are meant to propose a 
new model of language change. The models and 
concepts used here were all present previously and 
we have assumed and included some of them 
directly in our model. Our finding is not a proof of 
those models and can be considered only as a 
further validation. Our only claim here is that 
diachronic clues can help solve important 
problems in computational linguistics and for this 
we provide a computational framework and a 
specific example. 
 Some of the questions that we would like to 
address in the future include modelling of optional 
schwa deletion in Bengali compound words, 
evolution of morpho-phonology for Bengali verb 
systems, and modelling of dialect diversity using 
diachronic clues. More realistic, yet manageable 
computational frameworks for holistic or detailed 
modelling of language evolution can also be an 
interesting area of future research. 
References  
Bart de Boer 2000. Self Organization in Vowel 
Systems. Journal of Phonetics, 28:441-465 
Angelo Cangelosi and Domenico Parisi (Eds) 
2002. Simulating the Evolution of Language. 
Springer-Verlag, London  
Suniti K. Chatterji 1926. The Origin and 
Development of the Bengali Language. Rupa and 
Co. 
Eric Fosler-Lussier, Steven Greenberg and N 
Morgan  1999. Incorporating contextual 
phonetics into automatic speech recognition. 
Proc. Int. Cong. Phon. Sci., San Francisco, pp. 
611-614. 
Steven Greenberg 1999. Speaking in shorthand - A 
syllablecentric perspective for understanding 
pronunciation variation. Speech Communication, 
29:159-176.  
Hindi Bangla English ? Tribhasa Abhidhaan. 2001 
Sandhya Publication  
John E. Hopcroft and Jeffery D. Ullman 1979. 
Introduction to Automata Theory, Languages 
and Computation, Addison-Wesley, USA  
Rene Kager 1999. Optimality Theory. Cambridge 
University Press 
S. Kaira 1976. Schwa-deletion in Hindi. Language 
forum (back volumes), Bhari publications, 2 (1)  
Peter F. MacNeilage and Barbara L. Davis 2000. 
On the Origin of Internal Structure of Word 
Forms. Science, 288:527-31 
B. G. Misra 1967. Historical Phonology of 
Standard Hindi: Proto Indo European to the 
present. Cornell University Ph. D. dissertation 
Manjari Ohala 1977. The Treatment of 
Phonological variation: An example from Hindi. 
Lingua, 42: 161-76 
Manjari Ohala. 1983. Aspects of Hindi Phonology, 
volume II. MLBD Series in Linguistics, Motilal 
Banarsidass, New Delhi.  
Bhuvana Narasimhan, Richard Sproat and G Kiraz. 
2001. Schwa-deletion in Hindi Text-to-Speech 
Synthesis. Workshop on Computational 
Linguistics in South Asian Languages, 21st 
SALA, Konstanz  
Martin A. Nowak, Natalia L. Komarova and Partha 
Niyogi 2002. Computational and Evolutionary 
Aspects of Language, Nature, 417:611-17 
B. R. Pray 1970. Topics in Hindi ? Urdu grammar. 
Research Monograph 1, Berkeley: Center for 
South and Southeast Asia Studies, University of 
California 
Bernard Tranel 1999. Optional Schwa Deletion: on 
syllable economy in French. Formal 
Perspectives on Romance Linguistics, Ed. By J. 
Mark Authier, Barbar S. Bullock, & Lisa A. 
Reed.  
T. Vennemann 1988. Preference Laws for Syllable 
Structures. Mouton de Gruyter, Berlin 
 
TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 81?88,
Rochester, April 2007 c?2007 Association for Computational Linguistics
How Difficult is it to Develop a Perfect Spell-checker?
A Cross-linguistic Analysis through Complex Network Approach
Monojit Choudhury1, Markose Thomas2, Animesh Mukherjee1,
Anupam Basu1, and Niloy Ganguly1
1Department of Computer Science and Engineering, IIT Kharagpur, India
{monojit,animeshm,anupam,niloy}@cse.iitkgp.ernet.in
2Google Inc. Bangalore, India
markysays@gmail.com
Abstract
The difficulties involved in spelling er-
ror detection and correction in a lan-
guage have been investigated in this work
through the conceptualization of SpellNet
? the weighted network of words, where
edges indicate orthographic proximity be-
tween two words. We construct SpellNets
for three languages - Bengali, English and
Hindi. Through appropriate mathemati-
cal analysis and/or intuitive justification,
we interpret the different topological met-
rics of SpellNet from the perspective of
the issues related to spell-checking. We
make many interesting observations, the
most significant among them being that
the probability of making a real word error
in a language is propotionate to the aver-
age weighted degree of SpellNet, which is
found to be highest for Hindi, followed by
Bengali and English.
1 Introduction
Spell-checking is a well researched area in NLP,
which deals with detection and automatic correc-
tion of spelling errors in an electronic text docu-
ment. Several approaches to spell-checking have
been described in the literature that use statistical,
rule-based, dictionary-based or hybrid techniques
(see (Kukich, 1992) for a dated but substantial sur-
vey). Spelling errors are broadly classified as non-
word errors (NWE) and real word errors (RWE). If
the misspelt string is a valid word in the language,
then it is called an RWE, else it is an NWE. For ex-
ample, in English, the word ?fun? might be misspelt
as ?gun? or ?vun?; while the former is an RWE, the
latter is a case of NWE. It is easy to detect an NWE,
but correction process is non-trivial. RWE, on the
other hand are extremely difficult to detect as it re-
quires syntactic and semantic analysis of the text,
though the difficulty of correction is comparable to
that of NWE (see (Hirst and Budanitsky, 2005) and
references therein).
Given a lexicon of a particular language, how
hard is it to develop a perfect spell-checker for that
language? Since context-insensitive spell-checkers
cannot detect RWE and neither they can effectively
correct NWE, the difficulty in building a perfect
spell-checker, therefore, is reflected by quantities
such as the probability of a misspelling being RWE,
probability of more than one word being orthograph-
ically closer to an NWE, and so on. In this work,
we make an attempt to understand and formalize
some of these issues related to the challenges of
spell-checking through a complex network approach
(see (Albert and Baraba?si, 2002; Newman, 2003)
for a review of the field). This in turn allows us to
provide language-specific quantitative bounds on the
performance level of spell-checkers.
In order to formally represent the orthographic
structure (spelling conventions) of a language, we
conceptualize the lexicon as a weighted network,
where the nodes represent the words and the weights
of the edges indicate the orthoraphic similarity be-
tween the pair of nodes (read words) they connect.
We shall call this network the Spelling Network or
SpellNet for short. We build the SpellNets for three
languages ? Bengali, English and Hindi, and carry
out standard topological analysis of the networks
following complex network theory. Through appro-
priate mathematical analysis and/or intuitive justi-
81
fication, we interpret the different topological met-
rics of SpellNet from the perspective of difficulties
related to spell-checking. Finally, we make sev-
eral cross-linguistic observations, both invariances
and variances, revealing quite a few interesting facts.
For example, we see that among the three languages
studied, the probability of RWE is highest in Hindi
followed by Bengali and English. A similar obser-
vation has been previously reported in (Bhatt et al,
2005) for RWEs in Bengali and English.
Apart from providing insight into spell-checking,
the complex structure of SpellNet alo reveals the
self-organization and evolutionary dynamics under-
lying the orthographic properties of natural lan-
guages. In recent times, complex networks have
been successfully employed to model and explain
the structure and organization of several natural
and social phenomena, such as the foodweb, pro-
tien interaction, formation of language invento-
ries (Choudhury et al, 2006), syntactic structure of
languages (i Cancho and Sole?, 2004), WWW, social
collaboration, scientific citations and many more
(see (Albert and Baraba?si, 2002; Newman, 2003)
and references therein). This work is inspired by
the aforementioned models, and more specifically
a couple of similar works on phonological neigh-
bors? network of words (Kapatsinski, 2006; Vite-
vitch, 2005), which try to explain the human per-
ceptual and cognitive processes in terms of the orga-
nization of the mental lexicon.
The rest of the paper is organized as follows. Sec-
tion 2 defines the structure and construction pro-
cedure of SpellNet. Section 3 and 4 describes the
degree and clustering related properties of Spell-
Net and their significance in the context of spell-
checking, respectively. Section 5 summarizes the
findings and discusses possible directions for future
work. The derivation of the probability of RWE in a
language is presented in Appendix A.
2 SpellNet: Definition and Construction
In order to study and formalize the orthographic
characteristics of a language, we model the lexicon
? of the language as an undirected and fully con-
nected weighted graph G(V,E). Each word w ? ?
is represented by a vertex vw ? V , and for every
pair of vertices vw and vw? in V , there is an edge
Figure 1: The structure of SpellNet: (a) the weighted
SpellNet for 6 English words, (b) Thresholded coun-
terpart of (a), for ? = 1
(vw, vw?) ? E. The weight of the edge (vw, vw?), is
equal to ed(w,w?) ? the orthographic edit distance
between w and w? (considering substitution, dele-
tion and insertion to have a cost of 1). Each node
vw ? V is also assigned a node weight WV (vw)
equal to the unigram occurrence frequency of the
word w. We shall refer to the graph G(V,E) as the
SpellNet. Figure 1(a) shows a hypothetical SpellNet
for 6 common English words.
We define unweighted versions of the graph
G(V,E) through the concept of thresholding as
described below. For a threshold ?, the graph
G?(V,E?) is an unweighted sub-graph of G(V,E),
where an edge (vw, vw?) ? E is assigned a weight 1
in E? if and only if the weight of the edge is less than
or equal to ?, else it is assigned a weight 0. In other
words, E? consists of only those edges in E whose
edge weight is less than or equal to ?. Note that all
the edges in E? are unweighted. Figure 1(b) shows
the thresholded SpellNet shown in 1(a) for ? = 1.
2.1 Construction of SpellNets
We construct the SpellNets for three languages ?
Bengali, English and Hindi. While the two Indian
languages ? Bengali and Hindi ? use Brahmi derived
scripts ? Bengali and Devanagari respectively, En-
glish uses the Roman script. Moreover, the orthog-
raphy of the two Indian languages are highly phone-
mic in nature, in contrast to the morpheme-based or-
thography of English. Another point of disparity lies
in the fact that while the English alphabet consists
of 26 characters, the alphabet size of both Hindi and
Bengali is around 50.
82
The lexica for the three languages have
been taken from public sources. For En-
glish it has been obtained from the website
www.audiencedialogue.org/susteng.html; for Hindi
and Bengali, the word lists as well as the unigram
frequencies have been estimated from the mono-
lingual corpora published by Central Institute of
Indian Languages. We chose to work with the most
frequent 10000 words, as the medium size of the
two Indian language corpora (around 3M words
each) does not provide sufficient data for estimation
of the unigram frequencies of a large number
of words (say 50000). Therefore, all the results
described in this work pertain to the SpellNets
corresponding to the most frequent 10000 words.
However, we believe that the trends observed do not
reverse as we increase the size of the networks.
In this paper, we focus on the networks at three
different thresholds, that is for ? = 1, 3, 5, and study
the properties of G? for the three languages. We
do not go for higher thresholds as the networks be-
come completely connected at ? = 5. Table 1 re-
ports the values of different topological metrics of
the SpellNets for the three languages at three thresh-
olds. In the following two sections, we describe in
detail some of the topological properties of Spell-
Net, their implications to spell-checking, and obser-
vations in the three languages.
3 Degree Distribution
The degree of a vertex in a network is the number of
edges incident on that vertex. Let Pk be the prob-
ability that a randomly chosen vertex has degree k
or more than k. A plot of Pk for any given network
can be formed by making a histogram of the degrees
of the vertices, and this plot is known as the cumu-
lative degree distribution of the network (Newman,
2003). The (cumulative) degree distribution of a net-
work provides important insights into the topologi-
cal properties of the network.
Figure 2 shows the plots for the cumulative de-
gree distribution for ? = 1, 3, 5, plotted on a log-
linear scale. The linear nature of the curves in the
semi-logarithmic scale indicates that the distribution
is exponential in nature. The exponential behaviour
is clearly visible for ? = 1, however at higher thresh-
olds, there are very few nodes in the network with
low degrees, and therefore only the tail of the curve
shows a pure exponential behavior. We also observe
that the steepness (i.e. slope) of the log(Pk) with re-
spect to k increases with ?. It is interesting to note
that although most of the naturally and socially oc-
curring networks exhibit a power-law degree distri-
bution (see (Albert and Baraba?si, 2002; Newman,
2003; i Cancho and Sole?, 2004; Choudhury et al,
2006) and references therein), SpellNets feature ex-
ponential degree distribution. Nevertheless, similar
results have also been reported for the phonological
neighbors? network (Kapatsinski, 2006).
3.1 Average Degree
Let the degree of the node v be denoted by k(v). We
define the quantities ? the average degree ?k? and the
weighted average degree ?kwt? for a given network
as follows (we drop the subscript w for clarity of
notation).
?k? = 1N
?
v?V
k(v) (1)
?kwt? =
?
v?V k(v)WV (v)?
v?V WV (v)
(2)
where N is the number of nodes in the network.
Implication: The average weighted degree of
SpellNet can be interpreted as the probability of
RWE in a language. This correlation can be derived
as follows. Given a lexicon ? of a language, it can
be shown that the probability of RWE in a language,
denoted by prwe(?) is given by the following equa-
tion (see Appendix A for the derivation)
prwe(?) =
?
w??
?
w???
w 6=w?
?ed(w,w?)p(w) (3)
Let neighbor(w, d) be the number of words in ?
whose edit distance from w is d. Eqn 3 can be rewrit-
ten in terms of neighbor(w, d) as follows.
prwe(?) =
?
w??
??
d=1
?d neighbor(w, d)p(w) (4)
Practically, we can always assume that d is bounded
by a small positive integer. In other words, the
number of errors simultaneously made on a word
is always small (usually assumed to be 1 or a
83
English Hindi Bengali
? = 1 ? = 3 ? = 5 ? = 1 ? = 3 ? = 5 ? = 1 ? = 3 ? = 5
M 8.97k 0.70M 8.46M 17.6k 1.73M 17.1M 11.9k 1.11M 13.2M
?k? 2.79 140.25 1692.65 4.52 347.93 3440.06 3.38 223.72 2640.11
?kwt? 6.81 408.03 1812.56 13.45 751.24 4629.36 7.73 447.16 3645.37
rdd 0.696 0.480 0.289 0.696 0.364 0.129 0.702 0.389 0.155?CC? 0.101 0.340 0.563 0.172 0.400 0.697 0.131 0.381 0.645
?CCwt? 0.221 0.412 0.680 0.341 0.436 0.760 0.229 0.418 0.681
?l? 7.07 3.50 N.E 7.47 2.74 N.E 8.19 2.95 N.E
D 24 14 N.E 26 12 N.E 29 12 N.E
Table 1: Various topological metrics and their associated values for the SpellNets of the three languages
at thresholds 1, 3 and 5. Metrics: M ? number of edges; ?k? ? average degree; ?kwt? ? average weighted
degree; ?CC? ? average clustering coefficient; ?CCwt? - average weighted clustering coefficient; rdd ?
Pearson correlation coefficient between degrees of neighbors; ?l? ? average shortest path; D ? diameter.
N.E ? Not Estimated. See the text for further details on definition, computation and significance of the
metrics.
 1e-04
 0.001
 0.01
 0.1
 1
 0  10  20  30  40  50  60
P k
Degree
Threshold 1
EnglishHindiBengali
 1e-04
 0.001
 0.01
 0.1
 1
 0  500  1000  1500  2000  2500
P k
Degree
Threshold 3
EnglishHindiBengali
 1e-04
 0.001
 0.01
 0.1
 1
 0  1000 2000 3000 4000 5000 6000 7000 8000
P k
Degree
Threshold 5
EnglishHindiBengali
Figure 2: Cumulative degree distribution of SpellNets at different thresholds presented in semi-logarithmic
scale.
slowly growing function of the word length (Kukich,
1992)). Let us denote this bound by ?. Therefore,
prwe(?) ?
?
w??
??
d=1
?d neighbor(w, d)p(w) (5)
Since ? < 1, we can substitute ?d by ? to get an
upper bound on prwe(?), which gives
prwe(?) < ?
?
w??
??
d=1
neighbor(w, d)p(w) (6)
The term ??d=1 neighbor(w, d) computes the
number of words in the lexicon, whose edit distance
from w is atmost ?. This is nothing but k(vw), i.e.
the degree of the node vw, in G?. Moreover, the term
p(w) is proportionate to the node weight WV (vw).
Thus, rewriting Eqn 6 in terms of the network pa-
rameters for G?, we get (subscript w is dropped for
clarity)
prwe(?) < ?
?
v?V k(v)WV (v)?
v?V WV (v)
(7)
Comparing Eqn 2 with the above equation, we can
directly obtain the relation
prwe(?) < C1?kwt? (8)
where C1 is some constant of proportionality. Note
that for ? = 1, prwe(?) ? ?kwt?. If we ignore
the distribution of the words, that is if we assume
p(w) = 1/N , then prwe(?) ? ?k?.
Thus, the quantity ?kwt? provides a good estimate
of the probability of RWE in a language.
Observations and Inference: At ? = 1, the av-
erage weighted degrees for Hindi, Bengali and En-
glish are 13.81, 7.73 and 6.61 respectively. Thus, the
probability of RWE in Hindi is significantly higher
84
 1
 10
 100
 10  100  1000  10000 100000 1e+06
Deg
ree
Frequency
Threshold 1
 1
 10
 100
 1000
 10000
 10  100  1000 10000 100000 1e+06
Deg
ree
Frequency
Threshold 3
 1
 10
 100
 1000
 10000
 10  100  1000 10000 100000 1e+06
Deg
ree
Frequency
Threshold 5
Figure 3: Scatter-plots for degree versus unigram
frequency at different ? for Hindi
than that of Bengali, which in turn is higher than
that of English (Bhatt et al, 2005). Similar trends
are observed at all the thresholds for both ?kwt? and
?k?. This is also evident from Figures 2, which show
the distribution of Hindi to lie above that of Bengali,
which lies above English (for all thresholds).
The average degree ?k? is substantially smaller
(0.5 to 0.33 times) than the average weighted de-
gree ?kwt? for all the 9 SpellNets. This suggests
that the higher degree nodes in SpellNet have higher
node weight (i.e. occurrence frequency). Indeed, as
shown in Figure 3 for Hindi, the high unigram fre-
quency of a node implies higher degree, though the
reverse is not true. The scatter-plots for the other
languages are similar in nature.
3.2 Correlation between Degrees of Neighbors
The relation between the degrees of adjacent words
is described by the degree assortativity coefficient.
One way to define the assortativity of a network is
through the Pearson correlation coefficient between
the degrees of the two vertices connected by an edge.
Each edge (u, v) in the network adds a data item
corresponding to the degrees of u and v to two data
sets x and y respectively. The Pearson correlation
coefficient for the data sets x and y of n items each
is then defined as
r = n
?xy ??x? y?[n?x2 ? (?x)2][n? y2 ? (? y)2]
Observation: r is positive for the networks in
which words tend to associate with other words of
similar degree (i.e. high degree with high degree
and vice versa), and it is negative for networks in
which words associate with words having degrees
in the opposite spectrum. Refering to table 1, we
see that the correlation coefficient rdd is roughly the
same and equal to around 0.7 for all languages at
? = 1. As ? increases, the correlation decreases as
expected, due to the addition of edges between dis-
similar words.
Implication: The high positive correlation coeffi-
cients suggest that SpellNets feature assortative mix-
ing of nodes in terms of degrees. If there is an RWE
corresponding to a high degree node vw, then due
to the assortative mixing of nodes, the misspelling
w? obtained from w, is also expected to have a high
degree. Since w? has a high degree, even after detec-
tion of the fact that w? is a misspelling, choosing the
right suggestion (i.e. w) is extremely difficult un-
less the linguistic context of the word is taken into
account. Thus, more often than not it is difficult to
correct an RWE, even after successful detection.
4 Clustering and Small World Properties
In the previous section, we looked at some of the de-
gree based features of SpellNets. These features pro-
vide us insights regarding the probability of RWE in
a language and the level of difficulty in correcting
the same. In this section, we discuss some of the
other characteristics of SpellNets that are useful in
predicting the difficulty of non-word error correc-
tion.
4.1 Clustering Coefficient
Recall that in the presence of a complete list of valid
words in a language, detection of NWE is a trivial
task. However, correction of NWE is far from triv-
ial. Spell-checkers usually generate a suggestion list
of possible candidate words that are within a small
edit distance of the misspelling. Thus, correction be-
comes hard as the number of words within a given
edit distance from the misspelling increases. Sup-
pose that a word w ? ? is transformed into w? due
to some typing error, such that w? /? ?. Also assume
that ed(w,w?) ? ?. We want to estimate the number
of words in ? that are within an edit distance ? of
w?. In other words we are interested in finding out
the degree of the node vw? in G?, but since there is
no such node in SpellNet, we cannot compute this
quantity directly. Nevertheless, we can provide an
85
approximate estimate of the same as follows.
Let us conceive of a hypothetical node vw? . By
definition of SpellNet, there should be an edge con-
necting vw? and vw in G?. A crude estimate of
k(vw?) can be ?kwt? of G?. Due to the assortative
nature of the network, we expect to see a high corre-
lation between the values of k(vw) and k(vw?), and
therefore, a slightly better estimate of k(vw?) could
be k(vw). However, as vw? is not a part of the net-
work, it?s behavior in SpellNet may not resemble
that of a real node, and such estimates can be grossly
erroneous.
One way to circumvent this problem is to look
at the local neighborhood of the node vw. Let us
ask the question ? what is the probability that two
randomly chosen neighbors of vw in G? are con-
nected to each other? If this probability is high, then
we can expect the local neighborhood of vw to be
dense in the sense that almost all the neighbors of
vw are connected to each other forming a clique-like
local structure. Since vw? is a neighbor of vw, it is
a part of this dense cluster, and therefore, its degree
k(vw?) is of the order of k(vw). On the other hand,
if this probability is low, then even if k(vw) is high,
the space around vw is sparse, and the local neigh-
borhood is star-like. In such a situation, we expect
k(vw?) to be low.
The topological property that measures the prob-
ability of the neighbors of a node being connected
is called the clustering coefficient (CC). One of the
ways to define the clustering coefficient C(v) for a
vertex v in a network is
C(v) = number of triangles connected to vertex vnumber of triplets centered on v
For vertices with degree 0 or 1, we put C(v) = 0.
Then the clustering coefficient for the whole net-
work ?CC? is the mean CC of the nodes in the net-
work. A corresponding weighted version of the CC
?CCwt? can be defined by taking the node weights
into account.
Implication: The higher the value of
k(vw)C(vw) for a node, the higher is the probability
that an NWE made while typing w is hard to correct
due to the presence of a large number of ortho-
graphic neighbors of the misspelling. Therefore,
in a way ?CCwt? reflects the level of difficulty in
correcting NWE for the language in general.
Observation and Inference: At threshold 1,
the values of ?CC? as well as ?CCwt? is higher
for Hindi (0.172 and 0.341 respectively) and Ben-
gali (0.131 and 0.229 respectively) than that of En-
glish (0.101 and 0.221 respectively), though for
higher thresholds, the difference between the CC
for the languages reduces. This observation further
strengthens our claim that the level of difficulty in
spelling error detection and correction are language
dependent, and for the three languages studied, it is
hardest for Hindi, followed by Bengali and English.
4.2 Small World Property
As an aside, it is interesting to see whether the Spell-
Nets exhibit the so called small world effect that is
prevalent in many social and natural systems (see
(Albert and Baraba?si, 2002; Newman, 2003) for def-
inition and examles). A network is said to be a small
world if it has a high clustering coefficient and if the
average shortest path between any two nodes of the
network is small.
Observation: We observe that SpellNets indeed
feature a high CC that grows with the threshold. The
average shortest path, denoted by ?l? in Table 1, for
? = 1 is around 7 for all the languages, and reduces
to around 3 for ? = 3; at ? = 5 the networks are
near-cliques. Thus, SpellNet is a small world net-
work.
Implication: By the application of triangle in-
equality of edit distance, it can be easily shown that
?l? ? ? provides an upper bound on the average edit
distance between all pairs of the words in the lexi-
con. Thus, a small world network, which implies a
small ?l?, in turn implies that as we increase the error
bound (i.e. ?), the number of edges increases sharply
in the network and soon the network becomes fully
connected. Therefore, it becomes increasingly more
difficult to correct or detect the errors, as any word
can be a possible suggestion for any misspelling. In
fact this is independently observed through the ex-
ponential rise in M ? the number of edges, and fall
in ?l? as we increase ?.
Inference: It is impossible to correct very noisy
texts, where the nature of the noise is random and
words are distorted by a large edit distance (say 3 or
more).
86
5 Conclusion
In this work, we have proposed the network of ortho-
graphic neighbors of words or the SpellNet and stud-
ied the structure of the same across three languages.
We have also made an attempt to relate some of the
topological properties of SpellNet to spelling error
distribution and hardness of spell-checking in a lan-
guage. The important observations of this study are
summarized below.
? The probability of RWE in a language can
be equated to the average weighted degree of
SpellNet. This probablity is highest in Hindi
followed by Bengali and English.
? In all the languages, the words that are more
prone to undergo an RWE are more likely to be
misspelt. Effectively, this makes RWE correc-
tion very hard.
? The hardness of NWE correction correlates
with the weighted clustering coefficient of the
network. This is highest for Hindi, followed by
Bengali and English.
? The basic topology of SpellNet seems to be an
invariant across languages. For example, all
the networks feature exponential degree distri-
bution, high clustering, assortative mixing with
respect to degree and node weight, small world
effect and positive correlation between degree
and node weight, and CC and degree. However,
the networks vary to a large extent in terms of
the actual values of some of these metrics.
Arguably, the language-invariant properties of
SpellNet can be attributed to the organization of
the human mental lexicon (see (Kapatsinski, 2006)
and references therein), self-organization of ortho-
graphic systems and certain properties of edit dis-
tance measure. The differences across the lan-
guages, perhaps, are an outcome of the specific or-
thographic features, such as the size of the alphabet.
Another interesting observation is that the phonemic
nature of the orthography strongly correlates with
the difficulty of spell-checking. Among the three
languages, Hindi has the most phonemic and En-
glish the least phonemic orthography. This corre-
lation calls for further investigation.
Throughout the present discussion, we have fo-
cussed on spell-checkers that ignore the context;
consequently, many of the aforementioned results,
especially those involving spelling correction, are
valid only for context-insensitive spell-checkers.
Nevertheless, many of the practically useful spell-
checkers incorporate context information and the
current analysis on SpellNet can be extended for
such spell-checkers by conceptualizing a network
of words that capture the word co-occurrence pat-
terns (Biemann, 2006). The word co-occurrence
network can be superimposed on SpellNet and the
properties of the resulting structure can be appro-
priately analyzed to obtain similar bounds on hard-
ness of context-sensitive spell-checkers. We deem
this to be a part of our future work. Another way
to improve the study could be to incorporate a more
realistic measure for the orthographic similarity be-
tween the words. Nevertheless, such a modification
will have no effect on the analysis technique, though
the results of the analysis may be different from the
ones reported here.
Appendix A: Derivation of the Probability
of RWE
We take a noisy channel approach, which is a com-
mon technique in NLP (for example (Brown et al,
1993)), including spellchecking (Kernighan et al,
1990). Depending on the situation. the channel may
model typing or OCR errors. Suppose that a word w,
while passing through the channel, gets transformed
to a word w?. Therefore, the aim of spelling cor-
rection is to find the w? ? ? (the lexicon), which
maximizes p(w?|w?), that is
argmax
w??
p(w|w?) = argmax
w??
p(w?|w)p(w)
(9)
The likelihood p(w?|w) models the noisy channel,
whereas the term p(w) is traditionally referred to
as the language model (see (Jurafsky and Martin,
2000) for an introduction). In this equation, as well
as throughout this discussion, we shall assume a uni-
gram language model, where p(w) is the normalized
frequency of occurrence of w in a standard corpus.
We define the probability of RWE for a word w,
87
prwe(w), as follows
prwe(w) =
?
w???
w 6=w?
p(w?|w) (10)
Stated differently, prwe(w) is a measure of the prob-
ability that while passing through the channel, w
gets transformed into a form w?, such that w? ? ?
and w? 6= w. The probability of RWE in the lan-
guage, denoted by prwe(?), can then be defined in
terms of the probability prwe(w) as follows.
prwe(?) =
?
w??
prwe(w)p(w) (11)
=
?
w??
?
w???
w 6=w?
p(w?|w)p(w)
In order to obtain an estimate of the likelihood
p(w?|w), we use the concept of edit distance (also
known as Levenstein distance (Levenstein, 1965)).
We shall denote the edit distance between two words
w and w? by ed(w,w?). If we assume that the proba-
bility of a single error (i.e. a character deletion, sub-
stitution or insertion) is ? and errors are independent
of each other, then we can approximate the likeli-
hood estimate as follows.
p(w?|w) = ?ed(w,w?) (12)
Exponentiation of edit distance is a common mea-
sure of word similarity or likelihood (see for exam-
ple (Bailey and Hahn, 2001)).
Substituting for p(w?|w) in Eqn 11, we get
prwe(?) =
?
w??
?
w???
w 6=w?
?ed(w,w?)p(w) (13)
References
R. Albert and A. L. Baraba?si. 2002. Statistical mechan-
ics of complex networks. Reviews of Modern Physics,
74:47?97.
Todd M. Bailey and Ulrike Hahn. 2001. Determinants of
wordlikeness: Phonotactics or lexical neighborhoods?
Journal of Memory and Language, 44:568 ? 591.
A. Bhatt, M. Choudhury, S. Sarkar, and A. Basu. 2005.
Exploring the limits of spellcheckers: A compara-
tive study in bengali and english. In Proceedings of
the Symposium on Indian Morphology, Phonology and
Language Engineering (SIMPLE?05), pages 60?65.
C. Biemann. 2006. Unsupervised part-of-speech tag-
ging employing efficient graph clustering. In Pro-
ceedings of the COLING/ACL 2006 Student Research
Workshop, pages 7?12.
P. F. Brown, S. A. D. Pietra, V. J. D. Pietra, and R. L.
Mercer. 1993. The mathematics of statistical machine
translation: Parameter estimation. Computational Lin-
guistics, 19(2):263?312.
M. Choudhury, A. Mukherjee, A. Basu, and N. Ganguly.
2006. Analysis and synthesis of the distribution of
consonants over languages: A complex network ap-
proach. In Proceedings of the COLING/ACL Main
Conference Poster Sessions, pages 128?135.
G. Hirst and A. Budanitsky. 2005. Correcting real-word
spelling errors by restoring lexical cohesion. Natural
Language Engineering, 11:87 ? 111.
R. Ferrer i Cancho and R. V. Sole?. 2004. Patterns in
syntactic dependency networks. Physical Review E,
69:051915.
D. Jurafsky and J. H. Martin. 2000. An Introduction
to Natural Language Processing, Computational Lin-
guistics, and Speech Recognition. Prentice Hall.
V. Kapatsinski. 2006. Sound similarity relations in
the mental lexicon: Modeling the lexicon as a com-
plex network. Speech research Lab Progress Report,
27:133 ? 152.
M. D. Kernighan, K. W. Church, and W. A. Gale. 1990.
A spelling correction program based on a noisy chan-
nel model. In Proceedings of COLING, pages 205?
210, NJ, USA. ACL.
K. Kukich. 1992. Technique for automatically correcting
words in text. ACM Computing Surveys, 24:377 ? 439.
V. I. Levenstein. 1965. Binary codes capable of cor-
recting deletions, insertions and reversals. Doklady
Akademii Nauk SSSR, 19:1 ? 36.
M. E. J. Newman. 2003. The structure and function of
complex networks. SIAM Review, 45:167?256.
M. S. Vitevitch. 2005. Phonological neighbors in a small
world: What can graph theory tell us about word learn-
ing? Spring 2005 Talk Series on Networks and Com-
plex Systems, Indiana University.
88
Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 65?74,
Prague, June 2007. c?2007 Association for Computational Linguistics
Evolution, Optimization, and Language Change:
The Case of Bengali Verb Inflections
Monojit Choudhury1, Vaibhav Jalan2, Sudeshna Sarkar1, Anupam Basu1
1 Department of Computer Science and Engineering
Indian Institute of Technology, Kharagpur, India
{monojit,sudeshna,anupam}@cse.iitkgp.ernet.in
2 Department of Computer Engineering
Malaviya National Institute of Technology, Jaipur, India
vaibhavjalan.mnit@gmail.com
Abstract
The verb inflections of Bengali underwent
a series of phonological change between
10th and 18th centuries, which gave rise
to several modern dialects of the language.
In this paper, we offer a functional ex-
planation for this change by quantifying
the functional pressures of ease of artic-
ulation, perceptual contrast and learnabil-
ity through objective functions or con-
straints, or both. The multi-objective and
multi-constraint optimization problem has
been solved through genetic algorithm,
whereby we have observed the emergence
of Pareto-optimal dialects in the system
that closely resemble some of the real
ones.
1 Introduction
Numerous theories have been proposed to explain
the phenomenon of linguistic change, which, of late,
are also being supported by allied mathematical or
computational models. See (Steels, 1997; Perfors,
2002) for surveys on computational models of lan-
guage evolution, and (Wang et al, 2005; Niyogi,
2006) for reviews of works on language change.
The aim of these models is to explain why and how
languages change under specific socio-cognitive as-
sumptions. Although computational modeling is a
useful tool in exploring linguistic change (Cangelosi
and Parisi, 2002), due to the inherent complexi-
ties of our linguistic and social structures, modeling
of real language change turns out to be extremely
hard. Consequently, with the exception of a few
(e.g., Hare and Elman (1995); Dras et al (2003);
Ke et al (2003); Choudhury et al (2006b)), all the
mathematical and computational models developed
for explaining language change are built for artifi-
cial toy languages. This has led several researchers
to cast a doubt on the validity of the current compu-
tational models as well as the general applicability
of computational techniques in diachronic explana-
tions (Hauser et al, 2002; Poibeau, 2006).
In this paper, we offer a functional explanation1
of a real world language change ? the morpho-
phonological change affecting the Bengali verb
inflections (BVI). We model the problem as a
multi-objective and multi-constraint optimization
and solve the same using Multi-Objective Genetic
Algorithm2 (MOGA). We show that the different
forms of the BVIs, as found in the several modern
dialects, automatically emerge in the MOGA frame-
work under suitable modeling of the objective and
constraint functions. The model also predicts several
1Functionalist accounts of language change invoke the basic
function of language, i.e. communication, as the driving force
behind linguistic change (Boersma, 1998). Stated differently,
languages change in a way to optimize their function, such that
speakers can communicate maximum information with min-
imum effort (ease of articulation) and ambiguity (perceptual
contrast). Often, ease of learnability is also considered a func-
tional benefit. For an overview of different explanations in di-
achronic linguistics see (Kroch, 2001) and Ch. 3 of (Blevins,
2004).
2Genetic algorithm was initially proposed by Hol-
land (1975) as a self-organizing adaptation process mimicking
the biological evolution. They are also used for optimization
and machine learning purposes, especially when the nature of
the solution space is unknown or there are more than one objec-
tive functions. See Goldberg (1989) for an accessible introduc-
tion to single and multi-objective Genetic algorithms. Note that
in case of a multi-objective optimization problem, MOGA gives
a set of Pareto-optimal solutions rather than a single optimum.
The concept of Pareto-optimality is defined later.
65
other possible dialectal forms of Bengali that seems
linguistically plausible and might exist or have ex-
isted in the past, present or future. Note that the
evolutionary algorithm (i.e., MOGA) has been used
here as a tool for optimization, and has no relevance
to the evolution of the dialects as such.
Previously, Redford et al (2001) has modeled the
emergence of syllable systems in a multi-constraint
and multi-objective framework using Genetic al-
gorithms. Since the model fuses the individual
objectives into a single objective function through
a weighted linear combination, it is not a multi-
objective optimization in its true sense and nei-
ther does it use MOGA for the optimization pro-
cess. Nevertheless, the present work draws heavily
from the quantitative formulation of the objectives
and constraints described in (Redford, 1999; Red-
ford and Diehl, 1999; Redford et al, 2001). Ke et
al. (2003) has demonstrated the applicability and ad-
vantages of MOGA in the context of the vowel and
tonal systems, but the model is not explicit about the
process of change that could give rise to the optimal
vowel systems. As we shall see that the conception
of the genotype, which is arguably the most impor-
tant part of any MOGA model, is a novel and signif-
icant contribution of this work. The present formu-
lation of the genotype not only captures a snapshot
of the linguistic system, but also explicitly models
the course of change that has given rise to the partic-
ular system. Thus, we believe that the current model
is more suitable in explaining a case of linguistic
change.
The paper is organized as follows: Sec. 2 intro-
duces the problem of historical change affecting the
BVIs and presents a mathematical formulation of the
same; Sec. 3 describes the MOGA model; Sec. 4
reports the experiments, observations and their in-
terpretations; Sec. 5 concludes the paper by sum-
marizing the contributions. In this paper, Bengali
graphemes are represented in Roman script follow-
ing the ITRANS notation (Chopde, 2001). Since
Bengali uses a phonemic orthography, the phonemes
are also transcribed using ITRANS within two /s.
2 The Problem
Bengali is an agglutinative language. There are
more than 150 different inflected forms of a single
Attributes Classical (?0) SCB ACB Sylheti
PrS1 kari kori kori kori
PrS2 kara karo kara kara
PrS3 kare kare kare kare
PrSF karen karen karen karoin
PrC1 kariteChi korChi kartAsi koirtAsi
PrC2 kariteCha korCho kartAsa koirtAsae
PrC3 kariteChe korChe kartAse koirtAse
PrCF kariteChen korChen kartAsen kortAsoin
PrP1 kariAChi koreChi korsi koirsi
PrP2 kariACha koreCho karsa koirsae
PrP3 kariAChe koreChe karse koirse
PrPF kariAChen koreChen karsen korsoin
Table 1: The different inflected verb forms of Clas-
sical Bengali and three other modern dialects. All
the forms are in the phonetic forms and for the verb
root kar. Legend: (tense) Pr ? present; (aspects) S
? simple, C ? continuous, P ? perfect, ; (person) 1
? first, 2 ? second normal, 3 ? third, F ? formal in
second and third persons. See (Bhattacharya et al,
2005) for list of all the forms.
verb root in Bengali, which are obtained through af-
fixation of one of the 52 inflectional suffixes, option-
ally followed by the emphasizers. The suffixes mark
for the tense, aspect, modality, person and polarity
information (Bhattacharya et al, 2005). The ori-
gin of modern Bengali can be traced back to Vedic
Sanskrit (circa 1500 BC 600 BC), which during
the middle Indo-Aryan period gave rise to the di-
alects like Ma?gadhi?, and Ardhama?gadhi? (circa
600 BC 200 AD), followed by the Ma?gadhi? ?
apabhramsha, and finally crystallizing to Bengali
(circa 10th century AD) (Chatterji, 1926). The ver-
bal inflections underwent a series of phonological
changes during the middle Bengali period (1200 -
1800 AD), which gave rise to the several dialectal
forms of Bengali, including the standard form ? the
Standard Colloquial Bengali (SCB).
The Bengali literature of the 19th century was
written in the Classical Bengali dialect or the
sa?dhubha?sha? that used the older verb forms and
drew heavily from the Sanskrit vocabulary, even
though the forms had disappeared from the spoken
dialects by 17th century. Here, we shall take the lib-
erty to use the terms ?classical forms? and ?Classi-
cal Bengali? to refer to the dialectal forms of middle
Bengali and not Classical Bengali of the 19th cen-
66
tury literature. Table 1 enlists some of the corre-
sponding verb forms of classical Bengali and SCB.
Table 3 shows the derivation of some of the current
verb inflections of SCB from its classical counter-
parts as reported in (Chatterji, 1926).
2.1 Dialect Data
Presently, there are several dialects of Bengali that
vary mainly in terms of the verb inflections and in-
tonation, but rarely over syntax or semantics. We do
not know of any previous study, during which the
different dialectal forms for BVI were collected and
systematically listed. Therefore, we have collected
dialectal data for the following three modern dialects
of Bengali by enquiring the na?ive informants.
? Standard Colloquial Bengali (SCB) spoken in a
region around Kolkata, the capital of West Ben-
gal,
? Agartala Colloquial Bengali (ACB) spoken in
and around Agartala, the capital of Tripura, and
? Sylheti, the dialect of the Sylhet region of
Bangladesh.
Some of the dialectal forms are listed in Table 1.
The scope of the current study is restricted to 28 in-
flected forms (12 present tense forms + 12 past tense
forms + 4 forms of habitual past) of a single verb
root, i.e., kar.
2.2 Problem Formulation
Choudhury et al (2006a) has shown that a sequence
of simple phonological changes, which we shall
call the Atomic Phonological Operators or APO for
short, when applied to the classical Bengali lexicon,
gives rise to the modern dialects. We conceive of
four basic types of APOs, namely Del or deletion,
Met or metathesis, Asm or assimilation, and Mut
or mutation. The complete specification of an APO
includes specification of its type, the phoneme(s)
that is(are) affected by the operation and the left and
right context of application of the operator specified
as regular expressions on phonemes. The seman-
tics of the basic APOs in terms of rewrite rules are
shown in Table 2.2. Since Bengali features assim-
ilation only with respect to vowel height, here we
shall interpret Asm(p, LC,RC) as the height as-
similation of the vowel p in the context of LC or
APO Semantics
Del(p, LC,RC) p? ?/LC?RC
Met(pipj , LC,RC) pipj ? pjpi/LC?RC
Asm(p, LC,RC) p? p?/LC?RC
Mut(p, p?, LC,RC) p? p?/LC?RC
Table 2: Semantics of the basic APOs in terms of
rewrite rules. LC and RC are regular expressions
specifying the left and right contexts respectively. p,
p?, pi and pj represent phonemes.
Rule APO Example Derivations
No. kar ? iteChe kar ? iten kar ? iAChi
1 Del(e, ?, Ch) kar ? itChe NA NA
2 Del(t, ?, Ch) kar ? iChe NA NA
3 Met(ri, ?, ?) kair ? Che kair ? ten kair ?AChi
5 Mut(A, e, ?, Ch) NA NA kair-eChi
6 Asm(a, i, ?, ?) koir ? Che koir ? ten koir ? eChi
7 Del(i, o, ?) kor ? Che kor ? ten kor ? eChi
Table 3: Derivations of the verb forms of SCB from
classical Bengali using APOs. ?NA? means the rule
is not applicable for the form. See (Choudhury et
al., 2006a) for the complete list of APOs involved in
the derivation of SCB and ACB forms
RC. Also, we do not consider epenthesis or inser-
tion as an APO, because epenthesis is not observed
for the case of the change affecting BVI.
The motivation behind defining APOs rather than
representing the change in terms of rewrite rules is
as follows. Rewrite rules are quite expressive and
therefore, it is possible to represent complex phono-
logical changes using a single rewrite rule. On the
other hand, APOs are simple phonological changes
that can be explained independently in terms of pho-
netic factors (Ohala, 1993). In fact, there are also
computational models satisfactorily accounting for
cases of vowel deletion (Choudhury et al, 2004;
Choudhury et al, 2006b) and assimilation (Dras et
al., 2003).
Table 3 shows the derivation of the SCB verb
forms from classical Bengali in terms of APOs. The
derivations are constructed based on the data pro-
vided in (Chatterji, 1926).
2.3 Functional Explanation for Change of BVI
Let ?0 be the lexicon of classical Bengali verb
forms. Let ? : ?1, ?2, ? ? ? ?r be a sequence of r
APOs. Application of an APO on a lexicon implies
the application of the operator on every word of the
67
lexicon. The sequence of operators ?, thus, repre-
sent a dialect obtained through the process of change
from ?0, which can be represented as follows.
?(?0) = ?r(? ? ? ?2(?1(?0)) ? ? ?) = ?d
The derivation of the dialect ?d from ?0 can be con-
structed by following the APOs in the sequence of
their application.
We propose the following functional explanation
for the change of BVI.
A sequence of APOs, ? is preferred if ?(?0) has
some functional benefit over ?0. Thus, the modern
Bengali dialects are those, which have some func-
tional advantage over the classical dialect.
We would like to emphasize the word ?some? in
the aforementioned statements, because the modern
dialects are not better than the classical one (i.e., the
ancestor language) in an absolute sense. Rather, the
classical dialect is suboptimal compared to the mod-
ern dialects only with respect to ?some? of the func-
tional forces and is better than the them with respect
to ?some other? forces. Stated differently, we expect
both the classical as well as the modern dialects of
Bengali to be Pareto-optimal3 with respect to the set
of functional forces.
In order to validate the aforementioned hypoth-
esis, we carry out a multi-objective and multi-
constraint optimization over the possible dialectal
forms of Bengali, thereby obtaining the Pareto-
optimal set, which has been achieved through
MOGA.
3 The MOGA Model
Specification of a problem within the MOGA frame-
work requires the definition of the genotype, phe-
notype and genotype-to-phenotype mapping plus the
objective functions and constraints. In this section,
we discuss the design choices explored for the prob-
lem of BVI.
3Consider an optimization problem with n objective func-
tions f1 to fn, where we want to minimize all the objectives.
Let S be the solution space, representing the set of all possible
solutions. A soulution sinS is said to be Pareto-optimal with re-
spect to the objective functions f1 to fn, if and only if there does
not exist any other solution s? ? S such that fi(s?) ? fi(s) for
all 1 ? i ? n and fi(s?) < fi(s) for at least one i.
3.1 Phenotype and Genotype
We define the phenotype of a dialect d to be the lex-
icon of the dialect, ?d, consisting of the 28 inflected
forms of the root verb kar. This choice of phenotype
is justified because, at the end of the optimization
process, we would like to obtain the Pareto-optimal
dialects of Bengali and compare them with their real
counterparts.
The genotype of a dialect d could also be defined
as ?d, where the word forms are the genes. How-
ever, for such a choice of genotype, crossover and
mutation lead to counter-intuitive results. For ex-
ample, mutation would affect only a single word in
the lexicon, which is against the regularity principle
of sound change (see Bhat (2001) for explanation).
Similarly, exchanging a set of words between a pair
of lexica, as crossover would lead to, seems insensi-
ble.
Therefore, considering the basic properties of
sound change as well as the genetic operators used
in MOGA, we define a chromosome (and thus the
genotype) as a sequence of APOs. The salient fea-
tures of the genotype are described below.
? Gene: A gene is defined as an APO. Since in
order to implement the MOGA, every gene must be
mapped to a number, we have chosen an 8-bit binary
representation for a gene. This allows us to spec-
ify 256 distinct genes or APOs. However, for rea-
sons described below, we use the first bit of a gene
to denote whether the gene (i.e., the APO) is active
(the bit is set to 1) or not. Thus, we are left with
128 distinct choices for APOs. Since the number of
words in the lexicon is only 28, the APOs for Del,
Asm andMet are limited, even after accounting for
the various contexts in which an APO is applicable.
Nevertheless, there are numerous choices for Mut.
To restrain the possible repertoire of APOs to 128,
we avoided any APO related to the mutation of con-
sonants. This allowed us to design a comprehensive
set of APOs that are applicable on the classical Ben-
gali lexicon and its derivatives.
? Chromosome: A chromosome is a sequence of
15 genes. The number 15 has been arrived through
experimentation, where we have observed that in-
creasing the length of a chromosome beyond 15
does not yield richer results for the current choice
of APOs and ?0. Since the probability of any gene
68
Figure 1: Schematic of genotype, phenotype and
genotype-to-phenotype mapping.
being switched off (i.e., the first bit being 0) is 0.5,
the expected number of active APOs on a chromo-
some with 15 genes is 7.5. It is interesting to note
that this value is almost equal to the number of APOs
required (7 to be precise) for derivation of the SCB
verb forms.
? Genotype to phenotype mapping: Let for a given
chromosome, the set of active APOs (whose first bit
is 1) in sequence be ?1, ?2, ? ? ? , ?r. Then the pheno-
type corresponding to this chromosome is the lex-
icon ?d = ?r(? ? ? ?2(?1(?0)) ? ? ?). In other words,
the phenotype is the lexicon obtained by successive
application of the active APOs on the chromosome
on the lexicon of classical Bengali.
The concepts of gene, chromosome and the map-
ping from genotype to the phenotype are illustrated
in Fig. 3.1. It is easy to see that the regularity hy-
pothesis regarding the sound change holds good for
the aforementioned choice of genotype. Further-
more, crossover in this context can be interpreted as
a shift in the course of language change. Similarly,
mutation of the first bit turns a gene on or off, and of
the other bits changes the APO. Note that according
to this formulation, a chromosome not only models
a dialect, but also the steps of its evolution from the
classical forms.
3.2 Objectives and Constraints
Formulation of the objective functions and con-
straints are crucial to the model, because the linguis-
tic plausibility, computational tractability and the re-
sults of the model are overtly dependent on them.
We shall define here three basic objectives of ease
of articulation, perceptual contrast and learnability,
which can be expressed as functions or constraints.
Several models have been proposed in the past for
estimating the articulatory effort (Boersma (1998),
Ch. 2, 5 and 7) and perceptual distance between
phonemes and/or syllables (Boersma (1998), Ch.
3, 4 and 8). Nevertheless, as we are interested in
modeling the effort and perceptual contrast of the
whole lexicon rather than a syllable, we have cho-
sen to work with simpler formulations of the objec-
tive functions. Due to paucity of space, we are not
able to provide adequate details and justification for
the choices made.
3.2.1 fe: Articulatory Effort
Articulatory effort of a lexicon ? is a positive real
number that gives an estimate of the effort required
to articulate the words in ? in some unit. If fe de-
notes the effort function, then
fe(?) =
1
|?|
?
w??
fe(w) (1)
The term fe(w) depends on three parameters: 1)
the length of w in terms of phonemes, 2) the struc-
ture of the syllables, and 3) the features of adjacent
phonemes, as they control the effort spent in co-
articulation. We define fe(w) to be a weighted sum
of these three.
fe(w) = ?1fe1(w) + ?2fe2(w) + ?3fe3(w) (2)
where, ?1 = 1, ?2 = 1 and ?3 = 0.1 are the relative
weights.
The value of fe1 is simply the length of the word,
that is
fe1(w) = |w| (3)
Suppose ? = ?1?2 ? ? ??k is the usual syllabifica-
tion of w, where the usual or optimal syllabification
for Bengali is defined similar to that of Hindi as de-
scribed in (Choudhury et al, 2004). Then, fe2 is
defined as follows.
fe2(w) =
k?
i=1
hr(?i) (4)
hr(?) measures the hardness of the syllable ? and is
a function of the syllable structure (i.e. the CV pat-
tern) of ?. The values of hr(?) for different syllable
structures are taken from (Choudhury et al, 2004).
69
Since vowel height assimilation is the primary
co-articulation phenomenon observed across the di-
alects of Bengali, we define fe3 so as to model
only the effort required due to the difference in the
heights of the adjacent vowels.
Let there be n vowels in w represented by Vi,
where 1 ? i ? n. Then fe3 is defined by the fol-
lowing equation.
fe3(w) =
n?1?
i=1
|ht(Vi)? ht(Vi+1)| (5)
The function ht(Vi) is the tongue height associ-
ated with the vowel Vi. The value of the function
ht(Vi) for the vowels /A/, /a/, /E/ /o/, /e/, /i/
and /u/ are 0, 1, 1, 2, 2, 3, and 3 respectively. Note
that the values are indicative of the ordering of the
vowels with respect to tongue height, and do not re-
flect the absolute height of the tongue in any sense.
3.2.2 fd and Cd: Acoustic Distinctiveness
We define the acoustic distinctiveness between
two words wi and wj as the edit distance between
them, which is denoted as ed(wi, wj). The cost of
insertion and deletion of any phoneme is assumed to
be 1; the cost of substitution of a vowel (consonant)
for a vowel (consonant) is also 1, whereas that of a
vowel (consonant) for a consonant (vowel) is 2, ir-
respective of the phonemes being compared. Since
languages are expected to increase the acoustic dis-
tinctiveness between the words, we define a mini-
mizing objective function fd over a lexicon ? as the
sum of the inverse of the edit distance between all
pair of words in ?.
fd(?) =
2
|?|(|?| ? 1)
?
ij,i6=j
ed(wi, wj)
?1 (6)
If for any pair of words wi and wj , ed(wi, wj) =
0, we redefine ed(wi, wj)?1 as 20 (a large penalty).
We say that a lexicon ? violates the acoustic dis-
tinctiveness constraintCd, if there are more than two
pairs of words in ?, which are identical.
3.2.3 Cp: Phonotactic constraints
A lexicon ? is said to violate the constraint Cp if
any of the words in ? violates the phonotactic con-
straints of Bengali. As described in (Choudhury et
al., 2004), the PCs are defined at the level of sylla-
ble onsets and codas and therefore, syllabification is
a preprocessing step before evaluation of Cp.
3.2.4 fr and Cr: Regularity
Although learnability is a complex notion, one
can safely equate the learnability of a system to the
regularity of the patterns within the system. In fact,
in the context of morphology, it has been observed
that the so called learning bottleneck has a regular-
izing effect on the morphological structures, thereby
leaving out only the most frequently used roots to
behave irregularly (Hare and Elman, 1995; Kirby,
2001).
In the present context, we define the regularity
of the verb forms in a lexicon as the predictability
of the inflectional suffix on the basis of the mor-
phological attributes. Brighton et al (2005) discuss
the use of Pearson correlation between phonologi-
cal edit distance and semantic/morphological ham-
ming distance measures as a metric for learnabil-
ity. On a similar note, we define the regularity func-
tion fr as follows. For two words wi, wj ? ?, the
(dis)similarity between them is given by ed(wi, wj).
Let ma(wi, wj) be the number of morphological at-
tributes shared by wi and wj . We define the reg-
ularity of ?, fr(?), as the Pearson correlation co-
efficient between ed(wi, wj) and ma(wi, wj) for
all pairs of words in ?. Note that for a regular
lexicon, ed(wi, wj) decreases with an increase in
ma(wi, wj). Therefore, fr(?) is negative for a reg-
ular lexicon and 0 or positive for an irregular one.
In other words, fr(?) is also a minimizing objective
function.
We also define a regularity constraint Cr, such
that a lexicon ? violates Cr if fr(?) > ?0.8.
4 Experiments and Observations
In order to implement the MOGA model, we have
used the Non-dominated Sorting GA-II or NSGA-
II (Deb et al, 2002), which is a multi-objective,
multi-constraint elitist GA. Different MOGA mod-
els have been incrementally constructed by intro-
ducing the different objectives and constraints. The
motivation behind the incorporation of a new ob-
jective or constraint comes from the observations
made on the emergent dialects of the previous mod-
els. For instance, with two objectives fe and fd,
70
and no constraints, we obtain dialects that violate
phonotactic constraints or/and are highly irregular.
One such example of an emergent dialect4 is ? =
{ kor, kara, kar, kore, korea, kore, karA, karAa,
karA, *korAlm, *korl, korla, *koreAlm, korel, ko-
rela, *karAlm, karAl, karAla }. The * marked forms
violate the phonotactic constraints. Also note that
the forms are quite indistinct or close to each other.
These observations led to the formulation of the con-
straints Cp and Cd.
Through a series of similar experiments, finally
we arrived at a model, where we could observe the
emergence of dialects, some of which closely resem-
ble the real dialects and others also seem linguisti-
cally plausible. In this final model, there are two
objectives, fe and fd, and 3 constraints, Cp, Cd and
Cr. Table 4 lists the corresponding forms of some
of the emergent dialects, whose real counterparts are
shown in Table 1.
Fig. 2 shows the Pareto-optimal front obtained
for the aforementioned model after 500 generations,
with a population size of 1000. Since the objectives
are minimizing in nature, the area on the plot below
and left of the Pareto-optimal front represents im-
possible languages, whereas the area to the right and
top of the curve pertains to unstable or suboptimal
languages. It is interesting to note that the four real
dialects lie very close to the Pareto-optimal front. In
fact, ACB and SCB lie on the front, whereas clas-
sical Bengali and Sylheti appears to be slightly sub-
optimal. Nevertheless, one should always be aware
that impossibility and suboptimality are to be inter-
preted in the context of the model and any general-
ization or extrapolation of these concepts for the real
languages is controversial and better avoided.
Several inferences can be drawn from the exper-
iments with the MOGA models. We have observed
that the Pareto-optimal fronts for all the MOGA
Models look like rectangular hyperbola with a hori-
zontal and vertical limb; the specific curve of Fig. 2
satisfies the equation:
fd(?)
0.3(fe(?)? 5.6) = 0.26 (7)
Several interesting facts, can be inferred from the
above equation. First, the minimum value of fe un-
der the constraints Cr and Cd, and for the given
4Due to space constraints, we intentionally omit the corre-
sponding classical forms.
Figure 2: The Pareto-optimal front. The gray trian-
gles (light blue in colored version available online)
show the position of the real dialects: 0 ? Classi-
cal Bengali, 1 ? SCB, 2 ? ACB, 3 ? Sylheti. The
top-most dot in the plot corresponds to the emergent
dialect D0 shown in Table 4.
repertoire of APOs is 5.6. Second, at fe(?) = 6,
the slope of the front, i.e. dfd/dfe, is approximately
?2, and the second derivative d2fd/df2e is around
20. This implies that there is sharp transition be-
tween the vertical and horizontal limbs at around
fe(?) = 6.
Interestingly, all the real dialects studied here lie
on the horizontal limb of the Pareto-optimal front
(i.e., fe(?) ? 6), classical Bengali being placed at
the extreme right. We also note the negative corre-
lation between the value of fe for the real dialects,
and the number of APOs invoked during derivation
of these dialects from classical Bengali. These facts
together imply that the natural direction of language
change in the case of BVIs has been along the hor-
izontal limb of the Pareto-optimal front, leading to
the formation of dialects with higher and higher ar-
ticulatory ease. Among the four dialects, SCB has
the minimum value for fe(?) and it is positioned on
the horizontal limb of the front just before the begin-
ning of the vertical limb.
Therefore, it is natural to ask whether there are
any real dialects of modern Bengali that lie on the
vertical limb of the Pareto-optimal front; and if not,
what may be the possible reasons behind their inex-
istence? In the absence of any comprehensive col-
lection of Bengali dialects, we do not have a clear
answer to the above questions. Nevertheless, it may
71
Attributes D0 D1 D2 D3
PrS1 kar kor kori kori
PrS2 kara kora kora kora
PrS3 kare kore kore korA
PrSF karen koren koren koren
PrC1 kartA karChi karteChi kairteChi
PrC2 kartAa karCha karteCha kairteCha
PrC3 kartAe karChe karteChe kairteChA
PrCF kartAen karChen karteChen kairteChen
PrP1 karA korChi koriChi koriChAi
PrP2 karAa korCha koriCha koriACha
PrP3 karAe korChe koriChe koriAChA
PrPF karAen korChen koriChen koriAChen
Table 4: Examples of emergent dialects in the
MOGA model. Note that the dialects D1, D2 and
D3 resemble SCB, ACB and Sylheti, whereas D0
seems to be linguistically implausible. For legends,
refer to Table 1
be worthwhile to analyze the emergent dialects of
the MOGA models that lie on the vertical limb. We
have observed that the vertical limb consists of di-
alects similar to D0 ? the one shown in the first
column of Table 4. Besides poor distinctiveness,
D0 also features a large number of diphthongs that
might result in poorer perception or higher effort of
articulation of the forms. Thus, in order to eliminate
the emergence of such seemingly implausible cases
in the model, the formulations of the objectives fe
and fd require further refinements.
Similarly, it can also be argued that the structure
of the whole lexicon, which has not been modeled
here, has also a strong effect on the BVIs. This is
because even though we have measured the acous-
tic distinctiveness fd with respect to the 28 inflected
forms of a single verb root kar, ideally fd should be
computed with respect to the entire lexicon. Thus,
change in other lexical items (borrowing or extinc-
tion of words or change in the phonological struc-
tures) can trigger or restrain an event of change in
the BVIs.
Furthermore, merging, extinction or appearence
of morphological attributes can also have significant
effects on the phonological change of inflections. It
is interesting to note that while Vedic Sanskrit had
different morphological markers for three numbers
(singular, dual and plural) and no gender markers
for the verbs, Hindi makes a distinction between the
genders (masculine and feminine) as well as num-
bers (but only singular and plural), and Bengali has
markers for neither gender nor number. Since both
Hindi and Bengali are offshoots of Vedic Sanskrit,
presumably the differences between the phonologi-
cal structure of the verb inflections of these two lan-
guages must have also been affected by the loss or
addition of morphological attributes. It would be in-
teresting to study the precise nature of the interac-
tion between the inflections and attributes within the
current computational framework, which we deem
to be a future extension of this work.
5 Conclusions
In this paper, we have described a MOGA based
model for the morpho-phonological change of BVIs.
The salient contributions of the work include: (1) the
conception of the genotype as a sequence of APOs,
whereby we have been able to capture not only the
emergent dialects, but also the path towards their
emergence, and (2) a plausible functional explana-
tion for the morpho-phonological changes affecting
the BVIs. Nevertheless, the results of the experi-
ments with the MOGA models must be interpreted
with caution. This is because, the results are very
much dependent on the formulation of the fitness
functions and the choice of the constraints. The set
of APOs in the repertoire also play a major role in
shaping the Pareto-optimal front of the model.
Before we conclude, we would like to re-
emphasize that the model proposed here is a func-
tional one, and it does not tell us how the dialects
of Bengali have self-organized themselves to strike
a balance between the functional pressures, if at all
this had been the case. The evolutionary algorithm
(i.e., MOGA) has been used here as a tool for op-
timization, and has no relevance to the evolution of
the dialects as such. Nevertheless, if it is possible
to provide linguistically grounded accounts of the
sources of variation and the process of selection,
then the MOGA model could qualify as an evolu-
tionary explanation of language change as well. Al-
though such models have been proposed in the liter-
ature (Croft, 2000; Baxter et al, 2006), the fact, that
global optimization can be an outcome of local inter-
actions between the speakers (e.g., Kirby (1999), de
72
Boer (2001), Choudhury et al (2006b)), alone pro-
vides sufficient ground to believe that there is also an
underlying self-organizational model for the present
functional explanation.
References
G. J. Baxter, R. A. Blythe, W. Croft, and A. J. McKane.
2006. Utterance selection model of language change.
Physical Review E, 73(046118).
D.N.S. Bhat. 2001. Sound Change. Motilal Banarsidass,
New Delhi.
S. Bhattacharya, M. Choudhury, S. Sarkar, and A. Basu.
2005. Inflectional morphology synthesis for bengali
noun, pronoun and verb systems. In Proc. of NCCPB,
pages 34?43, Dhaka.
Julia Blevins. 2004. Evolutionary Phonology. Cam-
bridge University Press, Cambridge, MA.
P. Boersma. 1998. Functional Phonology: Formaliz-
ing the interactions between articulatory and percep-
tual drives. Uitgave van Holland Academic Graphics,
Hague.
Henry Brighton, Kenny Smith, and Simon Kirby. 2005.
Language as an evolutionary system. Physics of Life
Reviews, 2(3):177?226, September.
A. Cangelosi and D. Parisi. 2002. Comuputer simula-
tion: A new scientific approach to the study of lan-
guage evolution. In Simulating the Evolution of Lan-
guage, pages 3?28. Springer Verlag, London.
S. K. Chatterji. 1926. The Origin and Development of
the Bengali Language. Rupa and Co., New Delhi.
A. Chopde. 2001. Itrans version 5.30: A package
for printing text in indian languages using english-
encoded input. http://www.aczoom.com/itrans/.
M. Choudhury, A. Basu, and S. Sarkar. 2004. A di-
achronic approach for schwa deletion in indo-aryan
languages. In Proc. of ACL SIGPHON-04, pages 20?
26, Barcelona.
M. Choudhury, M. Alam, S. Sarkar, and A. Basu.
2006a. A rewrite rule based model of bangla morpho-
phonological change. In Proc. of ICCPB, pages 64?
71, Dhaka.
M. Choudhury, A. Basu, and S. Sarkar. 2006b. Multi-
agent simulation of emergence of the schwa deletion
pattern in hindi. JASSS, 9(2).
W. Croft. 2000. Explaining Language Change: An Evo-
lutionary Approach. Longman Linguistic Library.
B. de Boer. 2001. The Origins of Vowel Systems. Oxford
University Press.
K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. 2002.
A fast and elitist multi-objective genetic algorithm:
NSGA-II. IEEE Transactions on Evolutionary Com-
putation, 6:182?197.
M. Dras, D. Harrison, and B. Kapicioglu. 2003. Emer-
gent behavior in phonological pattern change. In Arti-
ficial Life VIII. MIT Press.
David E. Goldberg. 1989. Genetic Algorithms in Search,
Optimization and Machine Learning. Addison-
Wesley.
M. Hare and J. L. Elman. 1995. Learning and morpho-
logical change. Cognition, 56(1):61?98, July.
M. D. Hauser, N. Chomsky, and W. T. Fitch. 2002. The
faculty of language: What is it, who has it, and how
did it evolve? Science, 298:1569?1579, 11.
John H. Holland. 1975. Adaptation in Natural and Arti-
ficial Systems. The University of Michigan Press, Ann
Arbor.
Jinyun Ke, Mieko Ogura, and William S-Y. Wang. 2003.
Modeling evolution of sound systems with genetic al-
gorithm. Computational Linguistics, 29(1):1?18.
S. Kirby. 1999. Function, Selection and Innateness: the
Emergence of Language Universals. Oxford Univer-
sity Press. The full-text is only a sample (chapter 1: A
Puzzle of Fit).
S. Kirby. 2001. Spontaneous evolution of linguistic
structure: an iterated learning model of the emergence
of regularity and irregularity. IEEE Transactions on
Evolutionary Computation, 5(2):102?110.
Anthony Kroch. 2001. Syntactic change. In Mark baltin
and Chris Collins, editors, Handbook of Syntax, pages
699?729. Blackwell.
P. Niyogi. 2006. The Computational Nature of Language
Learning and Evolution. MIT Press, Cambridge, MA.
J. Ohala. 1993. The phonetics of sound change. In
C. Jones, editor, Historical linguistics: Problems and
perspectives, page 237278. Longman, London.
A. Perfors. 2002. Simulated evolution of language: a
review of the field. Journal of Artificial Societies and
Social Simulation, 5(2).
T. Poibeau. 2006. Linguistically grounded models of
language change. In Proc. of CogSci 2006, pages 255?
276.
73
Melissa A. Redford and R. L. Diehl. 1999. The rela-
tive perceptibility of syllable-initial and syllable-final
consonants. Journal of Acoustic Society of America,
106:1555?1565.
Melissa A. Redford, Chun Chi Chen, and Risto Mi-
ikkulainen. 2001. Constrained emergence of univer-
sals and variation in syllable systems. Language and
Speech, 44:27?56.
Melissa A. Redford. 1999. An Articulatory Basis for
the Syllable. Ph.D. thesis, Psychology, University of
Texas, Austin.
L. Steels. 1997. The synthetic modeling of language
origins. Evolution of Communication, 1(1):1?34.
W. S-Y. Wang, J. Ke, and J. W. Minett. 2005. Computa-
tional studies of language evolution. In Computational
Linguistics and Beyond: Perspectives at the beginning
of the 21st Century, Frontiers in Linguistics 1. Lan-
guage and Linguistics.
74
Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 101?108,
Prague, June 2007. c?2007 Association for Computational Linguistics
Emergence of Community Structures in Vowel Inventories:
An Analysis based on Complex Networks
Animesh Mukherjee, Monojit Choudhury, Anupam Basu, Niloy Ganguly
Department of Computer Science and Engineering,
Indian Institute of Technology, Kharagpur
{animeshm,monojit,anupam,niloy}@cse.iitkgp.ernet.in
Abstract
In this work, we attempt to capture patterns
of co-occurrence across vowel systems and
at the same time figure out the nature of the
force leading to the emergence of such pat-
terns. For this purpose we define a weighted
network where the vowels are the nodes
and an edge between two nodes (read vow-
els) signify their co-occurrence likelihood
over the vowel inventories. Through this
network we identify communities of vow-
els, which essentially reflect their patterns
of co-occurrence across languages. We ob-
serve that in the assortative vowel communi-
ties the constituent nodes (read vowels) are
largely uncorrelated in terms of their fea-
tures indicating that they are formed based
on the principle of maximal perceptual con-
trast. However, in the rest of the communi-
ties, strong correlations are reflected among
the constituent vowels with respect to their
features indicating that it is the principle of
feature economy that binds them together.
1 Introduction
Linguistic research has documented a wide range of
regularities across the sound systems of the world?s
languages (Liljencrants and Lindblom, 1972; Lind-
blom, 1986; de Boer, 2000; Choudhury et al, 2006;
Mukherjee et al, 2006a; Mukherjee et al, 2006b).
Functional phonologists argue that such regulari-
ties are the consequences of certain general princi-
ples like maximal perceptual contrast (Liljencrants
and Lindblom, 1972), which is desirable between
the phonemes of a language for proper percep-
tion of each individual phoneme in a noisy envi-
ronment, ease of articulation (Lindblom and Mad-
dieson, 1988; de Boer, 2000), which requires that
the sound systems of all languages are formed of
certain universal (and highly frequent) sounds, and
ease of learnability (de Boer, 2000), which is re-
quired so that a speaker can learn the sounds of
a language with minimum effort. In the study of
vowel systems the optimizing principle, which has
a long tradition (Jakobson, 1941; Wang, 1968) in
linguistics, is maximal perceptual contrast. A num-
ber of numerical studies based on this principle have
been reported in literature (Liljencrants and Lind-
blom, 1972; Lindblom, 1986; Schwartz et al, 1997).
Of late, there have been some attempts to explain the
vowel systems through multi agent simulations (de
Boer, 2000) and genetic algorithms (Ke et al, 2003);
all of these experiments also use the principle of per-
ceptual contrast for optimization purposes.
An exception to the above trend is a school of
linguists (Boersma, 1998; Clements, 2004) who ar-
gue that perceptual contrast-based theories fail to ac-
count for certain fundamental aspects such as the
patterns of co-occurrence of vowels based on sim-
ilar acoustic/articulatory features1 observed across
1In linguistics, features are the elements, which distinguish
one phoneme from another. The features that describe the
vowles can be broadly categorized into three different classes
namely the height, the backness and the roundedness. Height
refers to the vertical position of the tongue relative to either the
roof of the mouth or the aperture of the jaw. Backness refers
to the horizontal tongue position during the articulation of a
vowel relative to the back of the mouth. Roundedness refers to
whether the lips are rounded or not during the articulation of a
101
the vowel inventories. Instead, they posit that the
observed patterns, especially found in larger size in-
ventories (Boersma, 1998), can be explained only
through the principle of feature economy (de Groot,
1931; Martinet, 1955). According to this principle,
languages tend to maximize the combinatorial pos-
sibilities of a few distinctive features to generate a
large number of sounds.
The aforementioned ideas can be possibly linked
together through the example illustrated by Figure 1.
As shown in the figure, the initial plane P constitutes
of a set of three very frequently occurring vowels /i/,
/a/ and /u/, which usually make up the smaller in-
ventories and do not have any single feature in com-
mon. Thus, smaller inventories are quite likely to
have vowels that exhibit a large extent of contrast
in their constituent features. However, in bigger in-
ventories, members from the higher planes (P? and
P
??) are also present and they in turn exhibit fea-
ture economy. For instance, in the plane P? com-
prising of the set of vowels /?i/, /a?/, /u?/, we find a
nasal modification applied equally on all the three
members of the set. This is actually indicative of an
economic behavior that the larger inventories show
while choosing a new feature in order to reduce the
learnability effort of the speakers. The third plane
P
?? reinforces this idea by showing that the larger
the size of the inventories the greater is the urge for
this economy in the choice of new features. An-
other interesting facet of the figure are the relations
that exist across the planes (indicated by the bro-
ken lines). All these relations are representative of a
common linguistic concept of robustness (Clements,
2004) in which one less frequently occurring vowel
(say /?i/) implies the presence of the other (and not
vice versa) frequently occurring vowel (say /i/) in a
language inventory. These cross-planar relations are
also indicative of feature economy since all the fea-
tures present in the frequent vowel (e.g., /i/) are also
shared by the less frequent one (e.g., /?i/). In sum-
mary, while the basis of organization of the vowel
inventories is perceptual contrast as indicated by
the plane P in Figure 1, economic modifications of
the perceptually distinct vowels takes place with the
vowel. There are however still more possible features of vowel
quality, such as the velum position (e.g., nasality), type of vocal
fold vibration (i.e., phonation), and tongue root position (i.e.,
secondary place of articulation).
increase in the inventory size (as indicated by the
planes P ? and P ?? in Figure 1).
In this work we attempt to corroborate the above
conjecture by automatically capturing the patterns of
co-occurrence that are prevalent in and across the
planes illustrated in Figure 1. In order to do so,
we define the ?Vowel-Vowel Network? or VoNet,
which is a weighted network where the vowels are
the nodes and an edge between two nodes (read vow-
els) signify their co-occurrence likelihood over the
vowel inventories. We conduct community struc-
ture analysis of different versions of VoNet in or-
der to capture the patterns of co-occurrence in and
across the planes P , P ? and P ?? shown in Figure 1.
The plane P consists of the communities, which
are formed of those vowels that have a very high
frequency of occurrence (usually assortative (New-
man, 2003) in nature). We observe that the con-
stituent nodes (read vowels) of these assortative
vowel communities are largely uncorrelated in terms
of their features. On the other hand, the commu-
nities obtained from VoNet, in which the links be-
tween the assortative nodes are absent, corresponds
to the co-occurrence patterns of the planes P? and
P
??
. In these communities, strong correlations are
reflected among the constituent vowels with respect
to their features. Moreover, the co-occurrences
across the planes can be captured by the community
analysis of VoNet where only the connections be-
tween the assortative and the non-assortative nodes,
with the non-assortative node co-occurring very fre-
quently with the assortative one, are retained while
the rest of the connections are filtered out. We find
that these communities again exhibit a high correla-
tion among the constituent vowels.
This article is organized as follows: Section 2 de-
scribes the experimental setup in order to explore
the co-occurrence principles of the vowel inven-
tories. In this section we formally define VoNet,
outline its construction procedure, and present a
community-finding algorithm in order to capture the
co-occurrence patterns across the vowel systems. In
section 3 we report the experiments performed to
obtain the community structures, which are repre-
sentative of the co-occurrence patterns in and across
the planes discussed above. Finally, we conclude in
section 4 by summarizing our contributions, point-
ing out some of the implications of the current work
102
Figure 1: The organizational principles of the vowels (in decreasing frequency of occurrence) indicated
through different hypothetical planes.
and indicating the possible future directions.
2 Experimental Setup
In this section we systematically develop the ex-
perimental setup in order to investigate the co-
occurrence principles of the vowel inventories. For
this purpose, we formally define VoNet, outline
its construction procedure, describe a community-
finding algorithm to decompose VoNet to obtain the
community structures that essentially reflects the co-
occurrence patterns of the vowel inventories.
2.1 Definition and Construction of VoNet
Definition of VoNet: We define VoNet as a network
of vowels, represented as G = ? V
V
, E ? where V
V
is the set of nodes labeled by the vowels and E is
the set of edges occurring in VoNet. There is an
edge e ? E between two nodes, if and only if there
exists one or more language(s) where the nodes
(read vowels) co-occur. The weight of the edge e
(also edge-weight) is the number of languages in
which the vowels connected by e co-occur. The
weight of a node u (also node-weight) is the number
of languages in which the vowel represented by u
occurs. In other words, if a vowel v
i
represented by
the node u occurs in the inventory of n languages
then the node-weight of u is assigned the value
n. Also if the vowel v
j
is represented by the node
v and there are w languages in which vowels v
i
and v
j
occur together then the weight of the edge
connecting u and v is assigned the value v. Figure 2
illustrates this structure by reproducing some of the
nodes and edges of VoNet.
Construction of VoNet: Many typological stud-
ies (Lindblom and Maddieson, 1988; Ladefoged
and Maddieson, 1996; Hinskens and Weijer, 2003;
Choudhury et al, 2006; Mukherjee et al, 2006a;
Mukherjee et al, 2006b) of segmental inventories
have been carried out in past on the UCLA Phono-
logical Segment Inventory Database (UPSID) (Mad-
dieson, 1984). Currently UPSID records the sound
inventories of 451 languages covering all the major
language families of the world. The selection of the
languages for the inclusion on UPSID is governed
by a quota principle seeking maximum genetic di-
versity among extant languages in order to reduce
bias towards any particular family. In this work we
have therefore used UPSID comprising of these 451
languages and 180 vowels found across them, for
103
Figure 3: A partial illustration of VoNet. All edges in this figure have an edge-weight greater than or equal to
15. The number on each node corresponds to a particular vowel. For instance, node number 72 corresponds
to /?i/.
constructing VoNet. Consequently, the set V
V
com-
prises 180 elements (nodes) and the set E comprises
3135 elements (edges). Figure 3 presents a partial
illustration of VoNet as constructed from UPSID.
2.2 Finding Community Structures
We attempt to identify the communities appearing
in VoNet by the extended Radicchi et al (Radic-
chi et al, 2003) algorithm for weighted networks
presented in (Mukherjee et al, 2006a). The ba-
sic idea is that if the weights on the edges form-
ing a triangle (loops of length three) are comparable
then the group of vowels represented by this trian-
gle highly occur together rendering a pattern of co-
occurrence while if these weights are not compara-
ble then there is no such pattern. In order to capture
this property we define a strength metric S (in the
lines of (Mukherjee et al, 2006a)) for each of the
edges of VoNet as follows. Let the weight of the
edge (u,v), where u, v ? V
V
, be denoted by w
uv
.
We define S as,
S =
w
uv
?
?
i?V
C
?{u,v}
(w
ui
? w
vi
)
2
(1)
if
?
?
i?V
C
?{u,v}
(w
ui
? w
vi
)
2
> 0 else S = ?.
The denominator in this expression essentially tries
to capture whether or not the weights on the edges
forming triangles are comparable (the higher the
value of S the more comparable the weights are).
The network can be then decomposed into clusters
104
Figure 2: A partial illustration of the nodes and
edges in VoNet. The labels of the nodes denote the
vowels represented in IPA (International Phonetic
Alphabet). The numerical values against the edges
and nodes represent their corresponding weights.
For example /i/ occurs in 393 languages; /e/ occurs
in 124 languages while they co-occur in 117 lan-
guages.
or communities by removing edges that have S less
than a specified threshold (say ?).
At this point it is worthwhile to clarify the sig-
nificance of a vowel community. A community of
vowels actually refers to a set of vowels which occur
together in the language inventories very frequently.
In other words, there is a higher than expected prob-
ability of finding a vowel v in an inventory which al-
ready hosts the other members of the community to
which v belongs. For instance, if /i/, /a/ and /u/ form
a vowel community and if /i/ and /a/ are present in
any inventory then there is a very high chance that
the third member /u/ is also present in the inventory.
3 Experiments and Results
In this section we describe the experiments per-
formed and the results obtained from the analysis of
VoNet. In order to find the co-occurrence patterns
in and across the planes of Figure 1 we define three
versions of VoNet namely VoNet
assort
, VoNet
rest
and VoNet
rest
? . The construction procedure for
each of these versions are presented below.
Construction of VoNet
assort
: VoNet
assort
com-
prises the assortative2 nodes having node-weights
2The term ?assortative node? here refers to the nodes having
a very high node-weight, i.e., consonants having a very high
above 120 (i.e, vowels occurring in more than 120
languages in UPSID), along with only the edges
inter-connecting these nodes. The rest of the nodes
(having node-weight less than 120) and edges are
removed from the network. We make a choice
of this node-weight for classifying the assortative
nodes from the non-assortative ones by observing
the distribution of the occurrence frequency of the
vowels illustrated in Figure 4. The curve shows
the frequency of a vowel (y-axis) versus the rank
of the vowel according to this frequency (x-axis)
in log-log scale. The high frequency zone (marked
by a circle in the figure) can be easily distinguished
from the low-frequency one since there is distinct
gap featuring between the two in the curve.
Figure 4: The frequency (y-axis) versus rank (x-
axis) curve in log-log scale illustrating the distrib-
ution of the occurrence of the vowels over the lan-
guage inventories of UPSID.
Figure 5 illustrates how VoNet
assort
is con-
structed from VoNet. Presently, the number of
nodes in VoNet
assort
is 9 and the number of edges
is 36.
Construction of VoNet
rest
: VoNet
rest
comprises
all the nodes as that of VoNet. It also has all
the edges of VoNet except for those edges that
inter-connect the assortative nodes. Figure 6 shows
how VoNet
rest
can be constructed from VoNet. The
number of nodes and edges in VoNet
rest
are 180
frequency of occurrence.
105
Figure 5: The construction procedure of VoNet
assort
from VoNet.
and 12933 respectively.
Construction of VoNet
rest
?: VoNet
rest
? again
comprises all the nodes as that of VoNet. It con-
sists of only the edges that connect an assorta-
tive node with a non-assortative one if the non-
assortative node co-occurs more than ninety five per-
cent of times with the assortative nodes. The basic
idea behind such a construction is to capture the co-
occurrence patterns based on robustness (Clements,
2004) (discussed earlier in the introductory section)
that actually defines the cross-planar relationships in
Figure 1. Figure 7 shows how VoNet
rest
? can be
constructed from VoNet. The number of nodes in
VoNet
rest
? is 180 while the number of edges is 1144.
We separately apply the community-finding al-
gorithm (discussed earlier) on each of VoNet
assort
,
VoNet
rest
and VoNet
rest
? in order to obtain the re-
spective vowel communities. We can obtain dif-
ferent sets of communities by varying the threshold
?. A few assortative vowel communities (obtained
from VoNet
assort
) are noted in Table 1. Some of the
3We have neglected nodes with node-weight less than 3
since these nodes correspond to vowels that occur in less than 3
languages in UPSID and the communities they form are there-
fore statistically insignificant.
4The network does not get disconnected due to this construc-
tion since, there is always a small fraction of edges that run be-
tween assortative and low node-weight non-assortative nodes of
otherwise disjoint groups.
communities obtained from VoNet
rest
are presented
in Table 2. We also note some of the communities
obtained from VoNet
rest
? in Table 3.
Tables 1 , 2 and 3 indicate that the communi-
ties in VoNet
assort
are formed based on the princi-
ple of perceptual contrast whereas the formation of
the communities in VoNet
rest
as well as VoNet
rest
?
is largely governed by feature economy. Hence,
the smaller vowel inventories which are composed
of mainly the members of VoNet
assort
are orga-
nized based on the principle of maximal percep-
tual contrast whereas the larger vowel inventories,
which also contain members from VoNet
rest
and
VoNet
rest
? apart from VoNet
assort
, show a consider-
able extent of feature economy. Note that the groups
presented in the tables are quite representative and
the technique described above indeed captures many
other such groups; however, due to paucity of space
we are unable to present all of them here.
4 Conclusion
In this paper we explored the co-occurrence prin-
ciples of the vowels, across the inventories of the
world?s languages. In order to do so we started with
a concise review of the available literature on vowel
inventories. We proposed an automatic procedure
to extract the co-occurrence patterns of the vowels
across languages.
Some of our important findings from this work
are,
? The smaller vowel inventories (corresponding
to the communities of
VoNet
assort
) tend to be organized based on the
principle of maximal perceptual contrast;
? On the other hand, the larger vowel invento-
ries (mainly comprising of the communities of
VoNet
rest
) reflect a considerable extent of fea-
ture economy;
? Co-occurrences based on robustness are preva-
lent across vowel inventories (captured through
the communities of VoNet
rest
?) and their emer-
gence is again a consequence of feature econ-
omy.
Until now, we have concentrated mainly on the
methodology that can be used to automatically cap-
106
Figure 6: The construction procedure of VoNet
rest
from VoNet.
Figure 7: The construction procedure of VoNet
rest
? from VoNet.
Community Features in Contrast
/i/, /a/, /u/ (low/high), (front/central/back), (unrounded/rounded)
/e/, /o/ (higher-mid/mid), (front/back), (unrounded/rounded)
Table 1: Assortative vowel communities. The contrastive features separated by slashes (/) are shown within
parentheses. Comma-separated entries represent the features that are in use from the three respective classes
namely the height, the backness, and the roundedness.
ture the co-occurrence patterns across the vowel sys-
tems. However, it would be also interesting to in-
vestigate the extent to which these patterns are gov-
erned by the forces of maximal perceptual contrast
and feature economy. Such an investigation calls
for quantitative definitions of the above forces and
107
Community Features in Common
/
?
i/, /a?/, /u?/ nasalized
/?i:/, /a?:/, /u?:/ long, nasalized
/i:/, /u:/, /a:/, /o:/, /e:/ long
Table 2: Some of the vowel communities obtained from VoNet
rest
.
Community Features in Common
/i/, /?i/ high, front, unrounded
/a/, /a?/ low, central, unrounded
/u/, /u?/ high, back, rounded
Table 3: Some of the vowel communities obtained from VoNet
rest
? . Comma-separated entries represent the
features that are in use from the three respective classes namely the height, the backness, and the rounded-
ness.
a thorough evaluation of the vowel communities in
terms of these definitions. We look forward to ac-
complish the same as a part of our future work.
References
B. de Boer. 2000. Self-organisation in vowel systems,
Journal of Phonetics, 28(4), 441?465.
P. Boersma. 1998. Functional phonology, Doctoral the-
sis, University of Amsterdam, The Hague: Holland
Academic Graphics.
M. Choudhury, A. Mukherjee, A. Basu and N. Ganguly.
2006. Analysis and synthesis of the distribution of
consonants over languages: A complex network ap-
proach, Proceedings of COLING?ACL, 128?135, Syd-
ney, Australia.
N. Clements. 2004. Features and sound inventories,
Symposium on Phonological Theory: Representations
and Architecture, CUNY.
A. W. de Groot. 1931. Phonologie und Phonetik als
funktionswissenschaften, Travaux du Cercle Linguis-
tique de, 4, 116?147.
F. Hinskens and J. Weijer. 2003. Patterns of segmen-
tal modification in consonant inventories: A cross-
linguistic study, Linguistics, 41, 6.
R. Jakobson. 2003. Kindersprache, aphasie und allge-
meine lautgesetze, Uppsala, reprinted in Selected Writ-
ings I. Mouton, (The Hague, 1962), 328-401.
J. Ke, M. Ogura and W.S.-Y. Wang. 2003. Optimization
models of sound systems using genetic algorithms,
Computational Linguistics, 29(1), 1?18.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
worlds languages, Oxford: Blackwell.
J. Liljencrants and B. Lindblom. 1972. Numerical simu-
lation of vowel quality systems: the role of perceptual
contrast, Language, 48, 839?862.
B. Lindblom. 1986. Phonetic universals in vowel sys-
tems, Experimental Phonology, 13?44.
B. Lindblom and I. Maddieson. 1988. Phonetic uni-
versals in consonant systems, Language, Speech, and
Mind, Routledge, London, 62?78.
I. Maddieson. Patterns of sounds, 1984. Cambridge
University Press, Cambridge.
A. Martinet. 1955. `Economie des changements
phone?tiques, Berne: A. Francke.
A. Mukherjee, M. Choudhury, A. Basu and N. Ganguly.
2006. Modeling the co-occurrence principles of the
consonant inventories: A complex network approach,
arXiv:physics/0606132 (preprint).
A. Mukherjee, M. Choudhury, A. Basu and N. Gan-
guly. 2006. Self-organization of the Sound In-
ventories: Analysis and Synthesis of the Occur-
rence and Co-occurrence Networks of Consonants.
arXiv:physics/0610120 (preprint).
M. E. J. Newman. 2003. The structure and function of
complex networks, SIAM Review, 45, 167?256.
F. Radicchi, C. Castellano, F. Cecconi, V. Loreto and D.
Parisi. 2003. Defining and identifying communities in
networks, PNAS, 101(9), 2658?2663.
J-L. Schwartz, L-J. Bo?e, N. Valle?e and C. Abry. 1997.
The dispersion-focalization theory of vowel systems,
Journal of Phonetics, 25, 255?286.
W. S.-Y. Wang. 1968. The basis of speech. Project
on linguistic analysis reports, University of California,
Berkeley, (reprinted in The Learning of Language in
1971).
108
Proceedings of the EACL 2009 Workshop on Cognitive Aspects of Computational Language Acquisition, pages 51?58,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
Language Diversity across the Consonant Inventories:
A Study in the Framework of Complex Networks
Monojit Choudhury
Microsoft Research India, Bangalore, India ? 560080
Email: monojitc@microsoft.com
Animesh Mukherjee, Anupam Basu and Niloy Ganguly
Indian Institute of Technology, Kharagpur, India ? 721302
Ashish Garg and Vaibhav Jalan
Malaviya National Institute of Technology, Jaipur, India ? 302017
Abstract
In this paper, we attempt to explain the
emergence of the linguistic diversity that
exists across the consonant inventories of
some of the major language families of the
world through a complex network based
growth model. There is only a single pa-
rameter for this model that is meant to
introduce a small amount of randomness
in the otherwise preferential attachment
based growth process. The experiments
with this model parameter indicates that
the choice of consonants among the lan-
guages within a family are far more pref-
erential than it is across the families. Fur-
thermore, our observations indicate that
this parameter might bear a correlation
with the period of existence of the lan-
guage families under investigation. These
findings lead us to argue that preferential
attachement seems to be an appropriate
high level abstraction for language acqui-
sition and change.
1 Introduction
In one of their seminal papers (Hauser et al,
2002), Noam Chomsky and his co-authors re-
marked that if a Martian ever graced our planet
then it would be awe-struck by the unique abil-
ity of the humans to communicate among them-
selves through the medium of language. How-
ever, if our Martian naturalist were meticulous
then it might also note the surprising co-existence
of 6700 such mutually unintelligible languages
across the world. Till date, the terrestrial scientists
have no definitive answer as to why this linguistic
diversity exists (Pinker, 1994). Previous work in
the area of language evolution has tried to explain
the emergence of this diversity through two differ-
ent background models. The first one assumes that
there is a set of predefined language configurations
and the movement of a particular language on this
landscape is no more than a random walk (Tom-
lin, 1986; Dryer, 1992). The second line of re-
search attempts to relate the ecological, cultural
and demographic parameters with the linguistic
parameters responsible for this diversity (Arita and
Taylor, 1996; Kirby, 1998; Livingstone and Fyfe,
1999; Nettle, 1999). From the above studies, it
turns out that linguistic diversity is an outcome of
the language dynamics in terms of its evolution,
acquisition and change.
In this work, we attempt to investigate the di-
versity that exists across the consonant inventories
of the world?s languages through an evolutionary
framework based on network growth. The use of
a network based model is motivated from the fact
that in the recent years, complex networks have
proved to be an extremely suitable framework for
modeling and studying the structure and dynam-
ics of linguistic systems (Cancho and Sole?, 2001;
Dorogovtsev and Mendes, 2001; Cancho and Sole?,
2004; Sole? et al, 2005).
Along the lines of the study presented
in (Choudhury et al, 2006), we model the struc-
ture of the inventories through a bipartite network,
which has two different sets of nodes, one la-
beled by the languages and the other by the con-
sonants. Edges run in between these two sets
depending on whether a particular consonant is
found in a particular language. This network
is termed the Phoneme?Language Network or
PlaNet in (Choudhury et al, 2006). We construct
five such networks that respectively represent the
consonant inventories belonging to the five ma-
51
jor language families namely, the Indo-European
(IE-PlaNet), the Afro-Asiatic (AA-PlaNet), the
Niger-Congo (NC-PlaNet), the Austronesian (AN-
PlaNet) and the Sino-Tibetan (ST-PlaNet).
The emergence of the distribution of occurrence
of the consonants across the languages of a fam-
ily can be explained through a growth model for
the PlaNet representing the family. We employ the
preferential attachment based growth model intro-
duced in (Choudhury et al, 2006) and later ana-
lytically solved in (Peruani et al, 2007) to explain
this emergence for each of the five families. The
model involves a single parameter that is essen-
tially meant to introduce randomness in the oth-
erwise predominantly preferential growth process.
We observe that if we combine the inventories for
all the families together and then attempt to fit this
new data with our model, the value of the param-
eter is significantly different from that of the in-
dividual families. This indicates that the dynam-
ics within the families is quite different from that
across them. There are possibly two factors that
regulate this dynamics: the innate preference of
the speakers towards acquiring certain linguistic
structures over others and shared ancestry of the
languages within a family.
The prime contribution of this paper lies in the
mathematical model that naturally captures and
quantifies the diversification process of the lan-
guage inventories. This diversification, which is
arguably an effect of language acquisition and
change, can be viewed as a manifestation of the
process of preferential attachment at a higher level
of abstraction.
The rest of the paper is laid out as follows. Sec-
tion 2 states the definition of PlaNet, briefly de-
scribes the data source and outlines the construc-
tion procedure for the five networks. In section 3
we review the growth model for the networks. The
experiments and the results are explained in the
next section. Section 5 concludes the paper by ex-
plaining how preferential attachment could possi-
bly model the phenomena of language acquisition,
change and evolution.
2 Definition and Construction of the
Networks
In this section, we revisit the definition of PlaNet,
discuss briefly about the data source, and explain
how we constructed the networks for each of the
families.
Figure 1: Illustration of the nodes and edges of
PlaNet.
2.1 Definition of PlaNet
PlaNet is a bipartite graph G = ? VL,VC ,Epl ? con-
sisting of two sets of nodes namely, VL (labeled
by the languages) and VC (labeled by the conso-
nants); Epl is the set of edges running between VL
and VC . There is an edge e ? Epl from a node
vl ? VL to a node vc ? VC iff the consonant c is
present in the inventory of the language l. Figure 1
illustrates the nodes and edges of PlaNet.
2.2 Data Source
We use the UCLA Phonological Segment Inven-
tory Database (UPSID) (Maddieson, 1984) as the
source of data for this work. The choice of this
database is motivated by a large number of typo-
logical studies (Lindblom and Maddieson, 1988;
Ladefoged and Maddieson, 1996; de Boer, 2000;
Hinskens and Weijer, 2003) that have been car-
ried out on it by earlier researchers. It is a well
known fact that UPSID suffers from several prob-
lems, especially those involving representational
issues (Vaux and Samuels, 2005). Therefore,
any analysis carried on UPSID and the inferences
drawn from them are subject to questions. How-
ever, the current analysis requires a large amount
of segment inventory data and to the best of our
knowledge UPSID is the biggest database of this
kind. Moreover, we would like to emphasize that
the prime contribution of this work lies in the
mathematical modeling of the data rather than the
results obtained, which, as we shall see shortly, are
not very surprising or novel. The current model
applied to a different database of segment inven-
52
tories may lead to different results, though we be-
lieve that the basic trends will remain similar. In
essence, the results described here should be taken
as indicative and not sacrosanct.
There are 317 languages in the database with
541 consonants found across them. From these
data we manually sort the languages into five
groups representing the five families. Note that we
included a language in any group if and only if we
could find a direct evidence of its presence in the
corresponding family. A brief description of each
of these groups and languages found within them
are listed below (Haspelmath et al, 2005; Gordon,
2005).
Indo-European: This family includes most of the
major languages of Europe and south, central and
south-west Asia. Currently, it has around 3 bil-
lion native speakers, which is largest among all
the recognized families of languages in the world.
The total number of languages appearing in this
family is 449. The earliest evidences of the Indo-
European languages have been found to date 4000
years back.
Languages ? Albanian, Lithuanian, Breton, Irish,
German, Norwegian, Greek, Bengali, Hindi-
Urdu, Kashmiri, Sinhalese, Farsi, Kurdish, Pashto,
French, Romanian, Spanish, Russian, Bulgarian.
Afro-Asiatic: Afro-Asiatic languages have about
200 million native speakers spread over north,
east, west, central and south-west Africa. This
family is divided into five subgroups with a total of
375 languages. The proto-language of this family
began to diverge into separate branches approxi-
mately 6000 years ago.
Languages ? Shilha, Margi, Angas, Dera, Hausa,
Kanakuru, Ngizim, Awiya, Somali, Iraqw, Dizi,
Kefa, Kullo, Hamer, Arabic, Amharic, Socotri.
Niger-Congo: The majority of the languages that
belong to this family are found in the sub-Saharan
parts of Africa. The number of native speakers
is around 300 million and the total number of
languages is 1514. This family descends from a
proto-language, which dates back 5000 years.
Languages ? Diola, Temne, Wolof, Akan, Amo,
Bariba, Beembe, Birom, Cham, Dagbani, Doayo,
Efik, Ga, Gbeya, Igbo, Ik, Koma, Lelemi, Senadi,
Tampulma, Tarok, Teke, Zande, Zulu, Kadugli,
Moro, Bisa, Dan, Bambara, Kpelle.
Austronesian: The languages of the Austronesian
family are widely dispersed throughout the islands
of south-east Asia and the Pacific. There are 1268
Networks |VL| |VC | |Epl|
IE-PlaNet 19 148 534
AA-PlaNet 17 123 453
NC-PlaNet 30 135 692
AN-PlaNet 12 82 221
ST-PlaNet 9 71 201
Table 1: Number of nodes and edges in the five
bipartite networks corresponding to the five fami-
lies.
languages in this family, which are spoken by a
population of 6 million native speakers. Around
4000 years back it separated out from its ancestral
branch.
Languages ? Rukai, Tsou, Hawaiian, Iai, Adz-
era, Kaliai, Roro, Malagasy, Chamorro, Tagalog,
Batak, Javanese.
Sino-Tibetan: Most of the languages in this fam-
ily are distributed over the entire east Asia. With
a population of around 2 billion native speakers it
ranks second after Indo-European. The total num-
ber of languages in this family is 403. Some of the
first evidences of this family can be traced 6000
years back.
Languages ? Hakka, Mandarin, Taishan, Jingpho,
Ao, Karen, Burmese, Lahu, Dafla.
2.3 Construction of the Networks
We use the consonant inventories of the languages
enlisted above to construct the five bipartite net-
works ? IE-PlaNet, AA-PlaNet, NC-PlaNet, AN-
PlaNet and ST-PlaNet. The number of nodes and
edges in each of these networks are noted in Ta-
ble 1.
3 The Growth Model for the Networks
As mentioned earlier, we employ the growth
model introduced in (Choudhury et al, 2006) and
later (approximately) solved in (Peruani et al,
2007) to explain the emergence of the degree dis-
tribution of the consonant nodes for the five bipar-
tite networks. For the purpose of readability, we
briefly summarize the idea below.
Degree Distribution: The degree of a node v, de-
noted by k, is the number of edges incident on
v. The degree distribution is the fraction of nodes
pk that have a degree equal to k (Newman, 2003).
The cumulative degree distribution Pk is the frac-
tion of nodes having degree greater than or equal
to k. Therefore, if there are N nodes in a network
53
then,
Pk =
N?
k=k?
pk? (1)
Model Description: The model assumes that the
size of the consonant inventories (i.e., the degree
of the language nodes in PlaNet) are known a pri-
ori.
Let the degree of a language node Li ? VL
be denoted by di (i.e., di refers to the inventory
size of the language Li in UPSID). The conso-
nant nodes in VC are assumed to be unlabeled, i.e,
they are not marked by the articulatory/acoustic
features (see (Trubetzkoy, 1931) for further refer-
ence) that characterize them. In other words, the
model does not take into account the phonetic sim-
ilarity among the segments. The nodes L1 through
L317 are sorted in the ascending order of their de-
grees. At each time step a node Lj , chosen in
order, preferentially gets connected to dj distinct
nodes (call each such node C) of the set VC . The
probability Pr(C) with which the node Lj gets
connected to the node C is given by,
Pr(C) = k + ??
?C? (k? + ?)
(2)
where k is the current degree of the node C, C ?
represents the nodes in VC that are not already
connected to Lj and ? is the model parameter that
is meant to introduce a small amount of random-
ness into the growth process. The above steps are
repeated until all the language nodes Lj ? VL get
connected to dj consonant nodes.
Intuitively, the model works as follows: If a
consonant is very frequently found in the invento-
ries of the languages, then there is a higher chance
of that consonant being included in the inventory
of a ?new language?. Here the term ?new lan-
guage? can be interpreted either as a new and hith-
erto unseen sample from the universal set of lan-
guages, or the formation of a new language due
to some form of language change. The param-
eter ? on the other hand ensures that the conso-
nants which are found in none of the languages
from the current sample also have a chance of be-
ing included in the new language. It is similar to
the add-? smoothing used to avoid zero probabil-
ities while estimating probability distributions. It
is easy to see that for very large values of ? the fre-
quency factor will play a very minor role and the
consonants will be chosen randomly by the new
language, irrespective of its present prevalence. It
is natural to ask why and how this particular pro-
cess would model the growth of the language in-
ventories. We defer this question until the last sec-
tion of the paper, and instead focus on some empir-
ical studies to see if the model can really explain
the observed data.
Peruani et al (2007) analytically derived an ap-
proximate expression for the degree distribution of
the consonant nodes for this model. Let the aver-
age consonant inventory size be denoted by ? and
the number of consonant nodes be N. The solu-
tion obtained in (Peruani et al, 2007) is based on
the assumption that at each time step t, a language
node gets attached to ? consonant nodes, follow-
ing the distribution Pr(C). Under the above as-
sumptions, the degree distribution pk,t for the con-
sonant nodes, obtained by solving the model, is a
?-distribution as follows
pk,t ' A
(k
t
)??1 (
1? kt
)N?
? ???1 (3)
where A is a constant term. Using equations 1
and 3 one can easily compute the value of Pk,t.
There is a subtle point that needs a mention
here. The concept of a time step is very crucial
for a growing network. It might refer to the addi-
tion of an edge or a node to the network. While
these two concepts coincide when every new node
has exactly one edge, there are obvious differences
when the new node has degree greater than one.
The analysis presented in Peruani et al (2007)
holds good for the case when only one edge is
added per time step. However, if the degree of the
new node being introduced to the system is much
less than N , then Eq. 3 is a good approximation of
the emergent degree distribution for the case when
a node with more than one edge is added per time
step. Therefore, the experiments presented in the
next section attempt to fit the degree distribution
of the real networks with Eq. 3 by tuning the pa-
rameter ?.
4 Experiments and Results
In this section, we attempt to fit the degree dis-
tribution of the five empirical networks with the
expression for Pk,t described in the previous sec-
tion. For all the experiments we set N = 541, t =
number of languages in the family under investi-
gation and ? = average degree of the language
nodes of the PlaNet representing the family under
investigation, that is, the average inventory size for
54
Network ? for least LSE Value of LSE
IE-PlaNet 0.055 0.16AA-PlaNet 0.040 0.24NC-PlaNet 0.035 0.19AN-PlaNet 0.030 0.17ST-PlaNet 0.035 0.03Combined-PlaNet 0.070 1.47
Table 2: The values of ? and the least LSE for the
different networks. Combined-PlaNet refers to the
network constructed after mixing all the languages
from all the families. For all the experiments
the family. Therefore, given the value of k we
can compute pk,t using Eq. 3 if ? is known, and
from pk,t we can further compute Pk,t. In order to
find the best fitting theoretical degree distribution,
we vary the value of ? in steps of 0.005 within the
range of 0 to 1 and choose that ? for which the log-
arithmic standard error1 (LSE) between the the-
oretical degree distribution and the epirically ob-
served degree distribution of the real network and
the equation is least. LSE is defined as the sum of
the square of the difference between the logarithm
of the ordinate pairs (say y and y?) for which the
abscissas are equal. The best fits obtained for each
of the five networks are shown in Figure 2. The
values of ? and the corresponding least LSE for
each of them are noted in Table 2. We make the
following significant and interesting observations.
Observation I: The very low value of the parame-
ter ? indicates that the choice of consonants within
the languages of a family is strongly preferential.
In this context, ? may be thought of as modeling
the (accidental) errors or drifts that can occur dur-
ing language transmission. The fact that the val-
ues of ? across the four major language families,
namely Afro-Asiatic,Niger-Congo, Sino-Tibetan
and Austronesian, are comparable indicates that
the rate of error propagation is a universal factor
that is largely constant across the families. The
value of ? for IE-PlaNet is slightly higher than
the other four families, which might be an effect
of higher diversification within the family due to
geographical or socio-political factors. Neverthe-
less, it is still smaller than the ? of the Combined-
1LSE = (log y ? log y?)2. We use LSE as the good-
ness of the fit because the degree distributions of PlaNets are
highly skewed. There are very few high degree nodes and a
large number of low degree nodes. The logarithmic error en-
sures that even very small errors made while fitting the high
degrees are penalized equally as compared to that of the low
degrees. Standard error would not capture this fact and de-
clare a fit as good if it is able to replicate the distribution for
low degrees, but fits the high degrees poorly .
PlaNet.
The optimal ? obtained for Combined-PlaNet is
higher than that of all the families (see Table 2),
though it is comparable to the Indo-European
PlaNet. This points to the fact that the choice
of consonants within the languages of a family is
far more preferential than it is across the families;
this fact is possibly an outcome of shared ances-
try. In other words, the inventories of genetically
related languages are similar (i.e., they share a lot
of consonants) because they have evolved from the
same parent language through a series of linguis-
tic changes, and the chances that they use a large
number of consonants used by the parent language
is naturally high.
Observation II: We observe a very interesting
relationship between the approximate age of the
language family and the values of ? obtained in
each case (see Table 3). The only anomaly is the
Indo-European branch, which possibly indicates
that this might be much older than it is believed
to be. In fact, a recent study (Balter, 2003) has
shown that the age of this family dates back to
8000 years. If this last argument is assumed to
be true then the values of ? have a one-to-one cor-
respondence with the approximate period of ex-
istence of the language families. As a matter of
fact, this correlation can be intuitively justified ?
the higher is the period of existence of a family, the
higher are the chances of transmission errors lead-
ing to its diversification into smaller subgroups,
and hence, the values of ? comes out to be more
for the older families. It should be noted that the
difference between the values of ? for the language
families are not significant2. Therefore, the afore-
mentioned observation should be interpreted only
as an interesting possibility; more experimentation
is required for making any stronger claim.
4.1 Control Experiment
How could one be sure that the aforementioned
observations are not an obvious outcome of the
construction of the PlaNet or some spurious cor-
relations? To this end, we conduct a control ex-
periment where a set of inventories is randomly
selected from UPSID to represent a family. The
2Note that in order to obtain the best fit for the cumulative
distribution, ? has been varied in steps of 0.005. Therefore,
the values of ? in Table 2 cannot be more accurate than ? ?
0.005. However, in many cases the difference between the
best-fit ? for two language families is exactly 0.005, which
indicates that the difference is not significant.
55
Figure 2: The degree distribution of the different real networks (black dots) along with the fits obtained
from the equation for the optimal values of ? (grey lines).
Families Age (in years) ?
Austronasean 4000 0.030
Niger-Congo 5000 0.035
Sino-Tibetan 6000 0.035
Afro-Asiatic 6000 0.040
Indo-European 4000 (or 8000) 0.055
Table 3: Table showing the relationship between
the age of a family and the value of ?.
number of languages chosen is the same as that of
the PlaNets of the various language families. We
observe that the average value of ? for these ran-
domly constructed PlaNets is 0.068, which, as one
would expect, is close to that of the Combined-
PlaNet. This reinforces the fact that the inherent
proximity among the languages of a real family is
not due to chance.
4.2 Correlation between Families
It can be shown theoretically that if we merge two
PlaNets (say PlaNet1 and PlaNet2) synthesized us-
ing the growth model described here using param-
eters ?1 and ?2, then the ? of the combined PlaNet
can be much greater than both ?1 and ?2 when
there is a low correlation between the degrees of
the consonant nodes between the two PlaNets.
This can be understood as follows. Suppose that
the consonant /k/ is very frequent (i.e., has a high
degree) in PlaNet1, but the consonant /m/ is not.
On the other hand suppose that /m/ is very fre-
quenct in PlaNeT2, but /k/ is not. In the combined
PlaNet the degrees of /m/ and /k/ will even out and
the degree distribution will therefore, be much less
skewed than the original degree distributions of
PlaNet1 and PlaNet2. This is equivalent to the fact
that while ?1 and ?2 were very small, the ? of the
combined PlaNet is quite high. By the same logic
it follows that if the degrees of the consonants are
highly correlated in PlaNet1 and PlaNet2, then the
combined PlaNet will have an ? that is compara-
ble in magnitude to ?1 and ?2. The fact that the
? for the Combined-PlaNet is higher than that of
family-specific PlaNets, therefore, implies that the
correlation between the frequencies of the conso-
nants across language families is not very high.
In order to verify the above observation we esti-
mate the correlation between the frequency of oc-
currence of the consonants for the different lan-
guage family pairs (i.e., how the frequencies of
the consonants /p/, /t/, /k/, /m/, /n/ . . . are corre-
lated across the different families). Table 4 notes
the value of this correlation among the five fami-
lies. The values in Table 4 indicate that, in general,
the families are somewhat weakly correlated with
each other, the average correlation being ? 0.47.
Note that, the correlation between the Afro-
Asiatic and the Niger-Congo families is high not
only because they share the same African origin,
but also due to higher chances of language con-
tacts among their groups of speakers. On the other
hand, the Indo-European and the Sino-Tibetan
families show least correlation because it is usu-
56
Families IE AA NC AN ST
IE ? 0.49 0.48 0.42 0.25
AA 0.49 ? 0.66 0.53 0.43
NC 0.48 0.66 ? 0.55 0.37
AN 0.42 0.53 0.55 ? 0.50
ST 0.25 0.43 0.37 0.50 ?
Table 4: The Pearson?s correlation between the
frequency distributions obtained for the family
pairs. IE: Indo-European, AA: Afro-Asiatic,
NC: Niger-Congo, AN: Austronesian, ST: Sino-
Tibetan.
ally believed that they share absolutely no genetic
connections. Interestingly, similar trends are ob-
served for the values of the parameter ?. If we
combine the languages of the Afro-Asiatic and the
Niger-Congo families and try to fit the new data
then ? turns out to be 0.035 while if we do the same
for the Indo-European and the Sino-Tibetan fam-
ilies then ? is 0.058. For many of the other com-
binations the value of ? and the correlation coeffi-
cient have a one-to-one correspondence. However,
there are clear exceptions also. For instance, if we
combine the Afro-Asiatic and the Indo-European
families then the value of ? is very low (close to
0.04) although the correlation between them is not
very high. The reasons for these exceptions should
be interesting and we plan to further explore this
issue in future.
5 Conclusion
In this paper, we presented a method of network
evolution to capture the emergence of linguistic
diversity that manifests in the five major language
families of the world. How does the growth model,
if at all, captures the process of language dynam-
ics? We argue that preferential attachment is a
high level abstraction of language acquisition as
well as language change. We sketch out two pos-
sible explanations for this fact, both of which are
merely speculations at this point and call for de-
tailed experimentation.
It is a well known fact that the process of lan-
guage acquisition by an individual largely gov-
erns the course of language change in a linguis-
tic community. In the initial years of language
development every child passes through a stage
called babbling during which he/she learns to pro-
duce non-meaningful sequences of consonants and
vowels, some of which are not even used in the
language to which they are exposed (Jakobson,
1968; Locke, 1983). Clear preferences can be
observed for learning certain sounds such as plo-
sives and nasals, whereas fricatives and liquids are
avoided. In fact, this hierarchy of preference dur-
ing the babbling stage follows the cross-linguistic
frequency distribution of the consonants. This in-
nate frequency dependent preference towards cer-
tain phonemes might be because of phonetic rea-
sons (i.e., for articulatory/perceptual benefits). It
can be argued that in the current model, this in-
nate preference gets captured through the process
of preferential attachment.
An alternative explanation could be conceived
of based on the phenomenon of language trans-
mission. Let there be a community of N speak-
ers communicating among themselves by means
of only two consonants say /k/ and /g/. Let the
number of /k/ speakers be m and that of /g/ speak-
ers be n. If we assume that each speaker has l de-
scendants and that language inventories are trans-
mitted with high fidelity then after i generations,
the number of /k/ speakers should be mli and that
of /g/ speakers should be nli. Now if m > n
and l > 1 then for sufficiently large values of i
we have mli ? nli. Stated differently, the /k/
speakers by far outnumbers the /g/ speakers after a
few generations even though the initial difference
between them is quite small. This phenomenon
is similar to that of preferential attachment where
language communities get attached to, i.e., select
consonants that are already highly preferred. In
this context ? can be thought to model the acciden-
tal errors during transmission. Since these errors
accumulate over time, this can intuitively explain
why older language families have a higher value
of ? than the younger ones.
In fact, preferential attachment (PA) is a uni-
versally observed evolutionary mechanism that
is known to shape several physical, biological
and socio-economic systems (Newman, 2003).
This phenomenon has also been called for to ex-
plain various linguistic phenomena (Choudhury
and Mukherjee, to appear). We believe that PA
also provides a suitable abstraction for the mech-
anism of language acquisition. Acquisition of vo-
cabulary and growth of the mental lexicon are few
examples of PA in language acquisition. This
work illustrates another variant of PA applied to
explain the structure of consonant inventories and
their diversification across the language families.
57
References
T. Arita and C. E. Taylor. 1996. A simple model
for the evolution of communication. In L. J. Fo-
gel, P. J. Angeline and T. Ba?ck, editors, The Fifth
Annual Conference On Evolutionary Programming,
405?410. MIT Press.
M. Balter. 2003. Early date for the birth of Indo-
European languages. Science 302(5650), 1490.
A.-L. Baraba?si and R. Albert. 1999. Emergence of
scaling in random networks. Science 286, 509-512.
D. Bickerton. 1990. Language and Species, The Uni-
versity of Chicago Press, Chicago.
B. de Boer. 2000. Self-organization in vowel systems.
Journal of Phonetics, 28(4), 441?465.
R. Ferrer i Cancho and R. V. Sole?. 2001. The small-
world of human language. Proceedings of the Royal
Society of London, Series B, Biological Sciences,
268(1482), 1228?1235.
R. Ferrer i Cancho and R. V. Sole?. 2004. Patterns
in syntactic dependency networks. Phys. Rev. E,
69(051915).
R. G. Gordon (ed.) 2005. Ethnologue: Languages of
the World, Fifteenth edition, SIL International.
M. Haspelmath, M. S. Dryer, D. Gil and B. Comrie
(ed.) 2005. World Atlas of Language Structures,
Oxford University Press.
M. Choudhury, A. Mukherjee, A. Basu and N. Gan-
guly. 2006. Analysis and synthesis of the distri-
bution of consonants over languages: A complex
network approach. Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Com-
putational Linguistics, Main Conference Poster Ses-
sions, 128?135.
M. Choudhury and A. Mukherjee. to appear. The
structure and dynamics of linguistic networks. In N.
Ganguly, A. Deutsch and A. Mukherjee, editors, Dy-
namics on and of Complex Networks: Applications
to Biology, Computer Science, Economics, and the
Social Sciences, Birkhauser, Springer, Boston.
S. N. Dorogovtsev and J. F. F. Mendes. 2001. Lan-
guage as an evolving word web. Proceedings of the
Royal Society of London, Series B, Biological Sci-
ences, 268(1485), 2603?2606.
M. S. Dryer. 1992. The Greenbergian word order cor-
relations. Language, 68, 81?138.
M. D. Hauser, N. Chomsky and W. T. Fitch. 2002. The
faculty of language: What is it, who has it, and how
did it evolve? Science, 298, 1569?1579.
F. Hinskens and J. Weijer. 2003. Patterns of segmen-
tal modification in consonant inventories: a cross-
linguistic study. Linguistics, 41(6), 1041?1084.
R. Jakobson. 1968. Child Language, Aphasia and
Phonological Universals. The Hague: Mouton.
H. Jeong, B. Tombor, R. Albert, Z. N. Oltvai and A.
L. Baraba?si. 2000. The large-scale organization of
metabolic networks. Nature, 406, 651-654.
S. Kirby. 1998. Fitness and the selective adaptation
of language. In J. R. Hurford, M. Studdert-Kennedy
and C. Knight, editors, Approaches to the Evolution
of Language: Social and Cognitive Bases, 359?383.
Cambridge: Cambridge University Press.
P. Ladefoged and I. Maddieson. 1996. Sounds of the
Worlds Languages, Oxford: Blackwell.
B. Lindblom and I. Maddieson. 1988. Phonetic univer-
sals in consonant systems. In L.M. Hyman and C.N.
Li, eds., Language, Speech, and Mind, Routledge,
London, 62?78.
D. Livingstone and C. Fyfe. 1999. Modelling the
evolution of linguistic diversity. In D. Floreano, J.
Nicoud and F. Mondada, editors, ECAL 99, 704?
708, Berlin: Springer-Verlag.
J. L. Locke. 1983. Phonological Acquisition and
Change. Academic Press New York.
I. Maddieson. 1984. Patterns of Sounds, Cambridge
University Press, Cambridge.
D. Nettle. 1999. Is the rate of linguistic change con-
stant? Lingua, 108(2):119?136.
M. E. J. Newman. 2001. Scientific collaboration net-
works. Physical Review E 64, 016131.
M. E. J. Newman. 2003. The structure and function of
complex networks. SIAM Review 45, 167?256.
F. Peruani, M. Choudhury, A. Mukherjee and N. Gan-
guly. 2007. Emergence of a non-scaling degree dis-
tribution in bipartite networks: a numerical and ana-
lytical study. Euro. Phys. Letters 76, 28001 (p1?p6).
S. Pinker. 1994. The Language Instinct, New York:
William Morrow.
E. Pulleyblank. 1993. The typology of Indo-European.
Journal of Indo-European Studies, p. 109.
Jose? J. Ramasco, S. N. Dorogovtsev, and Romualdo
Pastor-Satorras. 2004. Self-organization of collabo-
ration networks. Physical Review E, 70, 036106.
R. V. Sole? , B. C. Murtra, S. Valverde and L. Steels.
2005. Language networks: Their structure, function
and evolution. Santa Fe working paper, 05-12-042.
R. Tomlin. 1986. Basic Word Order: Functional Prin-
ciples, Croom Helm, London.
N. Trubetzkoy. 1931. Die phonologischen systeme.
TCLP 4, 96?116.
B. Vaux and B. Samuel. 2005. Laryngeal markedness
and aspiration Phonology 22(3), 96?116.
58
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 345?354, Dublin, Ireland, August 23-29 2014.
Influence of Target Reader Background and Text Features on Text 
Readability in Bangla: A Computational Approach 
 
 
Manjira Sinha 
Department of Computer 
Science and Engineering 
Indian Institute of Technology 
Kharagpur 
West Bengal, India 
manjira@cse.iitkgp.e
rnet.in 
Tirthankar Dasgupta 
Department of Computer 
Science and Engineering 
Indian Institute of 
Technology Kharagpur 
West Bengal, India 
tirtha@cse.iitkgp.e
rnet.in 
Anupam Basu 
Department of Computer 
Science and Engineering 
Indian Institute of 
Technology Kharagpur 
West Bengal, India 
anupam@cse.iitkgp.e
rnet.in 
 
  
Abstract 
In this paper, we have studied the effect of two important factors influencing text readability in 
Bangla: the target reader and text properties. Accordingly, at first we have built a novel Bangla 
readability dataset of 135 documents annotated by 50 readers from two different backgrounds. 
We have identified 20 different features that can affect the readability of Bangla texts; the 
features were divided in two groups, namely, ?classic? and ?non-classic?. Preliminary 
correlation analysis reveals that text features have varying influence on the text hardness stated 
by the two groups. We have employed support vector machine (SVM) and support vector 
regression (SVR) techniques to model the reading difficulties of Bangla texts. In addition to 
developing different models targeted towards different type of readers, separate combinations 
of features were tested to evaluate their comparative contributions. Our study establishes that 
the perception of text difficulty varies largely with the background of the reader. To the best of 
our knowledge, no such work on text readability has been recorded earlier in Bangla.  
1 Introduction 
Readability of a text generally refers to how well a reader is able to comprehend the content of a text, 
through reading (Dale and Chall, 1948). Readability is a complex cognitive phenomenon where, the 
cognitive load of a text for a reader depends on both the characteristics of a text like, lexical choice, 
syntactic complexity, semantic complexity, discourse level complexity and on the background of the 
user. Several experiments have already established that readability of texts are quite language 
dependent and existing readability measures in English cannot directly be used to compute readability 
of other languages like, Bangla and Hindi (Sinha et al., 2012). Yet, compared to the numerous 
readability measures in English and other European languages(Benjamin, 2012), few initiatives have 
been taken to compute text readability in a Eastern Indo-Aryan language like Bangla or any other 
Indian languages which are structurally very different from many of their Indo-European cousins such 
as English, which is of West-Germanic descent (Sinha et al., 2012). One important factor that affects 
the readability of a text is the background of the respective reader. According to Dale (Dale, 1949), 
?The interpretation of the expressed thought is related more to the reader?s informational background 
and motivations than to the internal evidences of the expressional facility of the author?. Reader?s 
background is a complex derivative of one?s educational and socio-economic state. As per one of the 
pioneering works in readability by Dale and Chall (1949), the outcome of reading depends on many 
characteristics of the prospective readers including ?reading abilities, interests, age, sex, intellectual 
This work is licensed under a Creative Commons Attribution 4.0 International License. 
345
maturity, background of information etc.?  However, we do not know of any such investigations for 
Bangla text readability that have investigate the way background of a reader affect the readability of 
text. Such language specific study is needed as Bangla as a language is very different from English 
and the inapplicability of English readability formulae for Bangla text has already been established. 
Considering the above issues as our motivation, in this paper we have developed models to predict 
reading difficulty of a Bangla document perceived according to different target reader groups. To 
categorize among different reader groups, we have considered age, education and socio-economic data 
as indicators of comprehension ability. In addition, we have also explored the impact of different types 
of text features on text comprehensibility in Bangla. However, development and evaluation of such 
model requires availability of well-annotated resources. To the best of our knowledge, no 
automatically accessible data annotated according to the reading difficulty level is available for 
Bangla. Therefore, we have developed a digital resource pool of Bangla text documents in Unicode 
encoding that can be used for various NLP tasks such as feature extraction, document analysis etc. 
Such a dataset is essential to analyze readability of text documents based on the target reader. Next, 
we have visualized the text readability problem from a machine learning perspective as a classification 
problem using support vector machines (SVM) and an estimation problem using support vector 
regression (SVR). Our study is based on a wide range of textual features, from the syntactic and 
lexical features of a text like, its average sentence length, average word length in terms of visual units, 
to discourse level features like, number of jukta-akshars (consonant conjuncts) , number of different 
parts of speeches, named entity and lexical relations (refer to section 3). Although regression analysis 
has been previously used to model the text readability in Bangla, reader group specific analysis and 
machine learning techniques like support vectors have not been used so far. We have considered two 
target reader groups namely Group-1(or Adult group) with average age of 23 Yrs and Group-2 (or 
minor?s group) with average age of 15 Yrs.   
The organization of the paper is as follows: section 2 presents a brief literature survey on existing 
readability metrics for English and Bangla; section 3 defines the features of a text considered in this 
study, and empirical data collection, section 4 discusses the experiment observations, the prediction 
techniques and presents the results and validations for the two techniques. Finally, section 5 offers 
conclusion and perspective. 
2 Related Works 
The quantitative analysis of text readability started with L.A. Sherman in 1880 (Sherman, 1893). Till 
date, English and other languages have got over 200 readability metrics (DuBay, 2004; Rabin et al., 
1988).The existing quantitative approaches towards predicting readability of a text can be broadly 
classified into three categories (Benjamin, 2012):  
Classical methods: they analyze the syntactic features of a text like sentence length, paragraph 
length etc. The examples are Flesch Reading Ease Score (Flesch, 1948), FOG index (Gunning, 1968), 
Fry graph (Fry, 1968), SMOG (McLaughlin, 1969) etc. The formulae do not take into account the 
background of the reader and the semantic features of the text such as whether the actual contents are 
making sense or not. Despite their shortcomings, these simple metrics are easy to calculate and 
provide a rough estimation of reading difficulty of a text provided. 
Cognitively motivated methods: texts are analyzed based on the cognitive features like, cohesion, 
organization and users? background. Proposition and inference model (Kintsch and Van Dijk, 1978), 
prototype theory (Rosch, 1978), latent semantic analysis (Landauer et al., 1998), Coh-metrix (Graesser 
et al., 2004) are some prominent members of this group. This group of models moves beyond the 
surface features of a text and try to measure objectively the different cognitive indicators associated 
with text and the reader. However, it has been observed that, many situations, some traditional 
indicators perform as well as the newer and more difficult versions (Crossley et al., 2007). 
Statistical language modeling: This class of approaches incorporates the power machine learning 
methods to the field of readability. They are particularly useful in determining readability of web texts 
(Collins-Thompson and Callan, 2005; Collins-Thompson and Callan, 2004; Si and Callan, 2003) (Liu 
et al., 2004). SVM has been used to identify grammatical patterns within a text and classification 
based on it (Schwarm and Ostendorf, 2005; Heilman et al., 2008; Petersen and Ostendorf, 2009). 
Although, these methods sound promising, the problem is that they cannot act as standalone measure: 
346
they need an amount of training data for classifiers appropriate to a particular user group and often 
these measures takes into account complex text features which for resource poor languages need 
manual effort to annotate. 
In Bangla, only a couple of works have been executed on text readability. Das and Roychoudhury 
(Das and Roychoudhury, 2006) studied a miniature model with respect to one parametric and two 
parametric fits. They have used seven paragraphs from seven literary texts. They considered two 
structural features of a text: average sentence length and number of syllables per 100 words. They 
found the two-parametric fit as better performer. Sinha et al. (Sinha et al., 2012) has developed two 
readability formulae for Bangla texts using regression analysis. For their study sixteen texts of length, 
about 100 words were used. They have considered six structural or syntactic features of a text for the 
work. They have demonstrated that the English readability formulae such as Flesch Reading Ease 
Index, SMOG Index do not perform appropriately while being applied to Bangla documents. They 
have found the textual features like average word length, number of polysyllabic words and number of 
jukta-akshars in a text to be the most influential ones. Both the works mentioned have taken into 
account a small subset of potentially important text features; none them have considered feature such 
as the extent of text cohesion. Moreover, their study did not explore the influence of readers? 
background on text readability. In our study, we have addressed the issue of readers? background as 
well as the effect of features at different textual level. 
3 Empirical Data Collection 
As mentioned, there is no annotated data present in Bangla, which can provide a direct classification 
of text difficulty for Bangla readers. Therefore, we have undertaken an effort to annotate the 
experiment texts with the target readers of Bangla.  
3.1 Participants 
Our objective in this study is to investigate how readability varies with the background of the reader. 
Therefore, two different target reader groups have been considered to study the relationship of effect 
of text parameters on comprehension and user background. SEC1 or socio-economic classification has 
been stated according to the standards of Market Research Society of India (MRSI). MRSI has defined 
12 socio-economic strata: A1 to E3, in the decreasing order. These strata have been designed based on 
the education level of the chief wage earner of the family and the number of ?consumer durables? (as 
per a predefined list including agricultural land) owned by the family. It has been seen that this way of 
grading reflect the social and economic position of a household in terms of fields such as education, 
awareness etc. As can be inferred from the chart, the participants range from classes C2 to E1 (C2, D1, 
D2, E1), which represents the medium to low social-economic classes.  
Type Background 
Mean age 
(Standard 
deviation) 
Group 1 (adult): 25 native speakers 
of Bangla 
Education: pursuing graduation 22.8 (1.74) 
SEC: C2-E1 
Group 2 (minors): 25 native 
speakers of Bangla 
Education: pursuing secondary or higher 
secondary 
15 (1.24) 
SEC: C2-E2 
Table1: User Statistics 
3.2 Readability corpus preparation 
We have stated in the introduction about the scarcity of annotated digital resource pool in Bangla 
useful for automatic processing. Although there are a few works on text readability in Bangla, the data 
is not available in accessible formats. To address the problem, we have developed a corpus of Bangla 
documents. The current size of the resource is about 250 documents of length about 2000 words 
spanning over broad categories such as News, literature, blogs, articles etc. A number of different text 
                                                 
1 http://imrbint.com/research/The-New-SEC-system-3rdMay2011.pdf 
347
features were computed against each document. The descriptions of the features and the justification 
for them have been stated below. 
3.3 Feature selection: 
Inferring from the cognitive load theory (Paas et al., 2003), we have assumed that the cognitive load 
exerted by a text on a reader depends on syntactic and lexical properties of a text like, average 
sentence length, average word length, number of polysyllabic words and as well as discourse features 
like the counts of the different parts of speeches and the number of co-references one has to resolve in 
order to comprehend the text. The logic behind such assumptions is as follows: while processing a text 
a user has to parse the sentences in it and extract semantically relevant meaning from those sentences 
and the words. In order to process a sentence, one has to take into account the length of the sentence 
and types of words contained in it; in addition, to infer the meaning of a sentence, it is important to 
establish the connections or the nature of dependencies among the different words in a sentence. The 
role of a word is determined by its parts of speech and its way of use in that context; apart from it, the 
words can have varied complexity based on factors like their length, count of syllables. Similarly, at 
the discourse level, a reader not only has to comprehend each sentence or paragraph, but also has to 
infer the necessary co-references among them to understand the message conveyed by the text. The 
complexity of this task depends on the number of entities (noun, proper nouns) in the text, how one 
entity is connected with other, relationships like synonymy, polysemy, and hyponymy. To capture the 
effects of all these parameters in our readability models, we have considered text features over a broad 
range. The details of the features are presented in Table 2. The word features like average word length, 
average syllable per word, sentence features like average sentence length and discourse features like 
number of polysyllabic words, number of jukta-akshars (consonant conjuncts) have been calculated as 
stated by Sinha et al. (Sinha et al., 2012), as the features need customizations for Bangla. The 
calculations based on lexical chains have been followed from Galley and McKeown (Galley and 
McKeown, 2003).  
 
Feature Description 
word features 
average word length Bangla orthographic word consists of a combination of four types of graphemes2, 
each of them is considered as a single visual unit. Average word length is total 
word length in terms of visual units divided by number of words. 
average syllable per word Total word length in terms of syllable divided by total number of words. 
sentence features 
average sentence length Total sentence length in terms of words divided by number of sentence. 
$(noun phrase) Average number of NP per sentence 
$(verb phrase) Average number of VP per sentence 
$(adjective) Average number of adjectives per sentence 
$(postposition) Average number of postpositions per sentence. Bangla grammar has postpositions, 
instead of prepositions present in English. Unlike English, postpositions in Bangla 
do not belong to separate part of speech. The postpositions require their object 
noun to take possessive, objective or locative case. Suffixes act as the case 
markers.  
$(entity) average number of named entity per sentence 
$(unique entity) Average number of unique entity per sentence 
$(clauses) Average number of clauses per sentence 
                                                 
2 http://en.wikipedia.org/wiki/Bengali_alphabet#Characteristics_of_the_orthographic_word 
348
discourse features 
Number of polysyllabic 
words and normalized 
measure for 30 sentences 
Polysyllabic words are the words whose count of syllable exceeds 2. 
number of jukta-akshars 
(consonant conjuncts) 
Total number of jukta-akshars in a text of 2000 words. It is an important feature 
for Bangla because each of the clusters has separate orthographic and 
phonemic (in some cases) representation than the constituents consonants.  
#(noun phrase) Total number of NP in the document 
#(verb phrase) Total number of VP in the document 
#(adjective) Total number of adjective in the document. 
#(postposition) Total number of postpositions in the document. 
#(entity) Total number of named entity in the document 
#(unique entity) Total number of unique entity in the document 
#(lexical chain)* Total number of lexical chain in the document 
average lexical chain 
length* 
Computed over the document 
Table2: Details of text features considered for the study 
The features marked with * in the above table have been manually annotated against each text. The other 
features, though they are computed automatically, a round of manual checking was incorporated for the sake of 
correctness. 
Expert annotations and user annotations: 
Since there is no formal ranking of Bangla texts according to their reading levels, therefore, the 
documents were then annotated by language experts to approximate the suitable reading level for each 
document. However, to develop any practical readability application, feedbacks from actual users are 
necessary. From the resource pool mentioned in Introduction, 135 texts were chosen for the present 
study: two sets of distinct 45 texts were for each group: for the adult group those were the texts 
annotated by experts to have relatively high reading level and for the minor?s group, the texts were 
annotated as having relatively low reading level; pairwise t-test were performed between the two type 
of text features to assure that their difference is significant (p<0.05).  
The rest 45 texts are common to both the groups to account for the difference in comprehension for 
the same document and the assumption that may in some cases group 2 participants have comparable 
reading skill as of group 1: consequently, the texts annotated by experts as demanding high reading 
level were selected for this purpose. These were required to ensure that the experimental data spans 
over a broad range and is unbiased. The text details are presented in table 2 below. 
 
Source of Texts  
Number of texts  
Gr.1 Gr.2 common 
Literary corpora_classical  5  5 5 
Literary corpora_contemporay 6  5 6 
News corpora_general news 6  6  5 
News corpora_interview 5 6 6 
Blog corpora_personal 6  5 5 
Blog corpora_official 5 5 5 
Article corpora_ scholar 6 7  7 
Article corpora_general 6  6 6 
Table3: Text details 
Each participant was asked 2 questions: ?How easy was it for you to understand/comprehend the 
text?? and ?How interesting was the reading to you??. Against each question, they were to answer on a 
5 point scale (1=easy, 5=very hard). Inter-rater reliability was measured through Krippendorff?s alpha3 
                                                 
3 http://en.wikipedia.org/wiki/Krippendorff's_alpha 
349
and ? = 0.81 was found. Therefore, we concluded that annotators agree more often than would have 
occurred by chance. We have measured the correlation between the outcomes of two questions 
corresponding to each of the fifty annotators; and found that in each case the correlation was greater 
than 0.8 (p < 0.05). Therefore, the questions can be considered as equivalent, and subsequently we 
have considered the rating for the first question as user input for our readability models. 
Corresponding to each text, the average of the user ratings was considered for further processing.  
4 Analysis and Model Development 
4.1 Correlation coefficients 
We have performed partial spearman correlation between each of the features and user rating. Table 4 
presents some of the examples from each type of features due to the space limitation; results 
corresponding to other features are also described subsequently. The following features have selected 
as they have been used in the existing literature for Bangla (Sinha et al., 2012). The correlations are 
presented separately for the distinct texts and the common texts delivered to the two groups of users. 
This will allow us to investigate is there any significance difference of reading feedbacks between the 
different target populations. 
 
Feature Correlation coefficient r (Significance 
(if p<0.05) p value) 
 Different texts Common texts 
 Gr. 1 Gr. 2 Gr.1 Gr. 2 
Word features 
average sentence length 0.8 (0.0017) 0.33(0.2011) 0.75 (0.0013) 0.54 (0.08) 
average word length 0.60 (0.0142) 0.73(0.0041) 0.66 (0.0026) 0.8 (0.0032) 
Sentence features 
average syllable per 
word 
0.66 (0.06) 0.64(0.0047) 0.60(0.07) 0.75(0.0043) 
Discourse features 
number of polysyllabic 
words 
0.73 (0.0013) 0.74 (0.0008) 0.67(0.0021) 0.65(0.0006) 
normalized measure for 
30 sentences 
0.76(0.0011) 0.66 (0.0041) 0.65 (0.0015) 0.66(0.0032) 
number of jukta-akshars  0.87 (0.0018) 0.39 (0.1228) 0.81 (0.0024) 0.85 (0.0043) 
Table 4: Correlation coefficients (user rating vs text features) 
Some interesting observations can be made from the above table: 
? Average sentence length or mean number of words per sentence have been long found to be a 
strong predictor of text difficulty [1]. In our case, while this holds true for the adult data, the 
correlation is less for the minors and it is not significant. 
? Average syllable per word does not hold significant correlation for the adult data in both cases 
but it does for the minor?s group  
? Jukta-akshars or consonant conjuncts have major impact on text readability in Bangla (Sinha 
et al., 2012). For adult data, it can be seen that this feature has a strong and significant 
correlation, which not true for the user data of group 2 for separate texts. On the other hand, for 
the common texts this feature was found to have high significant correlation with both the 
reader groups. This is may be due to the nature of the common texts.  
? Apart from the above two cases, the above table also presents evidence in support of the fact 
that the reader?s perception of text difficulty in relation to text features changes with the target 
reader background. 
The impact of the remaining features has been discussed here with respect to the two different types of 
text scenarios: 
350
Distinct texts for two groups: 
? In case of the readers from the first group, the user ratings have high correlation (? > 0.65) 
with $(clauses), #(verb phrases), #( unique entity), #(lexical chain) and  average lexical chain 
length. The correlations are also significant. However, the correlations with $(noun phrase), 
$(verb phrase) $(postpositions), #(postpositions), #(adjective) were found to be insignificant. 
The correlation of user annotation with features such as $(entity), $(unique entity) were found 
to be low (? < 0.45) but significant.  
? The group 2 readers were found to show high (? > 0.65) and significant correlation with $(verb 
phrases), $(unique entity), $(clauses), #(entity), #(lexical chain) and average lexical chain span. 
The correlations with $(postposition), #(postpositions) were not significant. Features like 
$(noun phrase), $(adjective) and #(adjective) were found to have low (? < 0.45) but significant 
correlations with user ratings. 
Common texts for both groups: 
? It has been observed that the group 2 user ratings have higher correlation with the sentence level 
features than the discourse level features. In particular, features such as number of $(noun 
phrase), $(adjective), $(unique entity) and $(clauses) have high correlation with the text 
difficulty ratings provided by the minor?s group. Among the discourse level features #(entity) 
and #(unique entity)have a high correlation, but #(verb phrase), #(adjective) were found to have 
not significant influence. 
? On the other hand, the adult data are more inclined towards discourse features such as #(noun 
phrase) and #(verb phrase),  #(unique entity) in a document. This may be due to the ability of 
the older people to comprehend the text as a whole rather than inferring meaning from 
individual units at a time. From sentence level feature $(clause) was found to be significant and 
important in terms of correlation, but $(noun phrase), $(adjective) do not bear significant 
correlation. 
? Properties like lexical chain, which require a reader to establish connections among different 
attributes of a concept have great significance for both group1 and group2 annotations.  
? For both the user groups the influence of average $(postposition and #(postposition) were found 
to be little and insignificant. 
From the above discussions, it is evident that the two different target reader groups show a large 
difference in their reading pattern and perception of text difficulty. The difference has been observed 
in both the cases: when they were presented with different type of texts and with same texts. 
Therefore, it has been established that the target reader background plays an important role in 
modelling text difficulty. Accordingly, in the following sections, we have developed different models 
of different reader groups, and in the process we have also shown that the models have different 
parameter values and configurations. 
4.2 Computational modelling 
Analyses of correlation coefficients give an estimation of trend in user ratings against text features. 
The next step is to develop suitable models for automatic readability prediction. To achieve the 
objective, we have used machine-learning methods such as support vector machine (SVM) and 
support vector regression (SVR) techniques. In addition, we have also presented a comparative study 
of performances of different text features in readability model building in this section. The features 
have been used in three combinations. First they were divided in  two categories i) comprising of only 
the six features mentioned in table 4 as they represent the ?classical? features used extensively to 
model text readability, and ii) second category consists of the rest 14 features and the group is termed 
?non-classical? , this yielded the first two combinations. The third combination consists of all the 
features. Therefore, we have evaluated six different types of SVM and SVR models for each group. 
We have employed a binary SVM classifier here. Given a training set instance-class pairs (?? ,??  ), i 
= 1?l, where ?? ?  ?
?   and ? ?   1,?1 l  , the general equation of a SVM is (Manning et al., 2008): 
351
12
?
?
 ? +  ? ??
l
?
 ?? ?????????,
? = ?????? ??????,? = ?????????????? ????         ? (equation: 1) 
 
?? ?
?
? ?? + ? ? 1?  ?? , ?? ????? ???????? ? 0               ?  (equation: 2) 
 
In this work, we have taken 90 texts against each group of users by combining the 45 reader group 
specific texts and 45 common texts (refer to section 3). Then for each category of reader, the texts 
were shuffled randomly. We have used 70 texts for training and 20 texts for evaluation of the model 
and performed 2-fold cross validation. The minimum, maximum and median of the rating distribution 
lie respectively at (2.33), (8.4) and (5.92) for adult (group1) and at (1.83), (8.2) and (5.5) for minor 
(group 2). To train and test the SVM models, we needed to spit the data in two classes ( easy and 
hard), this has been done by assigning the ratings less than the median in to class easy (label ?-1?) and 
the rest to the class hard (label ?1?), i.e., the user ratings were mapped to the label space ?. In case of 
SVR, the label space mapping was not required. The text features were mapped to the feature space ?? . 
Although we have tested four types of kernel functions: linear, polynomial, radial basis and sigmoid 
on the data using LIBSVM (Chang and Lin, 2011) software, here only the results corresponding to 
linear and polynomial kernels have been presented as the other two kernels performed poorly.  To 
evaluate the quality of the classifications for SVM, multiple correlation (R) and percentage of texts 
accurately classified (Acc) have been used. R denotes the extent to which the predictions are close to 
the actual classes and its square (R2) indicates the percentage of dependent variable variation that can 
be explained by the model. Therefore, while percentage accuracy is an indicator to how well the model 
has performed to classify, R indicates the extent of explanatory power it posses. A better fit will have 
large R-value as well as Acc. For SVR, root mean square error (RMSE) has been reported instead of 
Acc; a good fit will have less RMSE. Below tables present, the SVM and SVR results for adult and 
minor?s data for different kernels and different combination of features. The kernels were evaluated 
for a number of SVM parameter combinations and only the result corresponding to the most efficient 
one is presented.  
Features Classic features Non-classic features All features 
SVM parameters C = 10; d = 2; r = 0; ? = 1/6 = 0.1; ?? = 0.01 (total support vector = 28) 
Kernel R Acc. R Acc. R Acc.  
linear 0.75 76% 0.73 79% 0.80 87% 
Polynomial 0.73 75% 0.72 75% 0.75 79.5% 
Table 5: SVM for group1 readers 
Features Classic features Non-classic features All features 
SVM parameters C = 1; d = 2; r = 0; ? = 1/6 = 0.1; ?? = 0.001 (total support vector = 22 ) 
Kernel R Acc. R Acc R Acc.  
Linear 0.75 75% 0.72 77% 0.83 86% 
Polynomial 0.71 70% 0.73 72% 0.78 76% 
Table 6: SVM for group2 readers 
Features Classic Non-classic features All features 
Kernel R RMSE R RMSE R RMSE 
linear 0.56 1.6 0.53 1.7 0.68 1.1 
Polynomial 0.43 2.2 0.47 11.2 0.56 23.3 
Table 7: SVR for group1 readers 
Features Classic Non-classic features All 
Kernel R RMSE R RMSE R RMSE 
linear 0.50 1.5 0.54 1.4 0.65 1.2 
Polynomial 0.47 3.1 0.45 15.5 0.51 29.7 
352
Table 8: SVR for group2 readers 
From table 5 and table 6, it can be seen that the SVM for the two target reader groups differ 
significantly in term of parameter attributes and their accuracy. It is also evident that incorporating 
only non-classic features versus classic features improves the accuracy of SVM very slightly and both 
types of features have similar explanatory power; combining both the classic and non -classic feature 
improves the accuracy and multiple correlations significantly. The SVR from table 7 and table 8 show 
the similar trend in terms of feature performances: classic and non-classis features have comparable 
RMSE and R, but there is significant gain when the two types are taken together. The regression 
equations for group1 and group2 readers differ in the coefficients of the feature variables; these imply 
that the two groups require different readability models. Moreover, the linear kernel was found to 
perform better than the polynomial kernel in all the cases. 
5 Conclusion 
In this paper, we have studied the effect of two important factors affecting text readability in Bangla: 
the target reader and text properties. We have found that the perception of text difficulty varies largely 
with the background of the reader. Accordingly, we have developed computational models to compute 
readability of Bangla text documents based on the target reader group. In order to achieve our goal we 
have first developed a novel Bangla dataset annotated in terms of text readability by users with 
varying age group. A preliminary analysis of the reading pattern of each target group was performed 
by analysing the correlation of text features with user annotations. Next, we have applied the SVM 
classifier to classify text documents into two different classes namely, hard and easy; the SVM for the 
two reader groups have different properties, implying the difference between two corresponding 
models. We have also compared the performance of the classifier based on the feature set they use. 
We observed that in contrast to applying only the classical features or the non-classic features, 
performance of the classifier improves if both types of features are used. This is true for both the adult 
as well as the minor?s dataset. Overall, we have achieved an accuracy of around 86% for the minor?s 
dataset and 87% for the adult dataset respectively. In addition to classification, support vector 
regression has been used to model text difficulty from an estimation perspective. The result of the 
SVR also establishes our previous findings. To the best of our knowledge, no such work on text 
readability has been recorded earlier in Indian languages, especially in Bangla. The next step of this 
study is to analyse the performance of the readability formula from one group (say adult) when applied 
to the other group (say minors) and vice versa. We will also repeat our study with more spread apart 
user groups spread over less diverse economic strata. In future, we are planning to develop for multi-
class text readability models. The work will also be extended to model text comprehensibility for 
reading disabilities in Bangla.  
Reference 
Benjamin, R. (2012). Reconstructing readability: Recent developments and recommendations in the analysis of 
text difficulty. Educational Psychology Review, 24:1?26. 
Chang, C.-C. and Lin, C.-J. (2011). Libsvm: a library for support vector machines. ACM Transactions on 
Intelligent Systems and Technology (TIST), 2(3):27. 
Collins-Thompson, K. and Callan, J. (2004). A language modeling approach to predicting reading difficulty. In 
Proceedings of HLT/NAACL, volume 4. 
Collins-Thompson, K. and Callan, J. (2005). Predicting reading difficulty with statistical language models. 
Journal of the American Society for Information Science and Technology, 56(13):1448?1462. 
Dale, E. (1949). Readability. 
Dale, E. and Chall, J. (1948). A formula for predicting readability. Educational research bulletin, pages 11?28. 
Das, S. and Roychoudhury, R. (2006). Readability modelling and comparison of one and two parametric fit: A 
case study in bangla*. Journal of Quantitative Linguistics, 13(01):17?34. 
DuBay, W. (2004). The principles of readability. Impact Information, pages 1?76. 
Flesch, R. (1948). A new readability yardstick. Journal of applied psychology, 32(3):221. 
353
Fry, E. (1968). A readability formula that saves time. Journal of reading, 11(7):513?578. 
Galley, M. and McKeown, K. (2003). Improving word sense disambiguation in lexical chaining. In IJCAI, 
volume 3, pages 1486?1488. 
Graesser, A., McNamara, D., Louwerse, M., and Cai, Z. (2004). Coh-metrix: Analysis of text on cohesion and 
language. Behavior Research Methods, 36(2):193?202. 
Gunning, R. (1968). The technique of clear writing. McGraw-Hill NewYork, NY. 
Heilman, M., Collins-Thompson, K., and Eskenazi, M. (2008). An analysis of statistical models and features for 
reading difficulty prediction. In Proceedings of the Third Workshop on Innovative Use of NLP for Building 
Educational Applications, pages 71?79. Association for Computational Linguistics. 
Kintsch, W. and Van Dijk, T. (1978). Toward a model of text comprehension and production. Psychological 
review, 85(5):363. 
Landauer, T., Foltz, P., and Laham, D. (1998). An introduction to latent semantic analysis. Discourse processes, 
25(2-3):259?284. 
Liu, X., Croft, W., Oh, P., and Hart, D. (2004). Automatic recognition of reading levels from user queries. In 
Proceedings of the 27th annual international ACM SIGIR conference on Research and development in 
information retrieval, pages 548?549. ACM. 
Manning, C. D., Raghavan, P., and Sch?tze, H. (2008). Introduction to information retrieval, volume 1. 
Cambridge University Press Cambridge. 
McLaughlin, G. (1969). Smog grading: A new readability formula. Journal of reading, 12(8):639?646. 
Paas, F., Renkl, A., and Sweller, J. (2003). Cognitive load theory and instructional design: Recent developments. 
Educational psychologist, 38(1):1?4. 
Petersen, S. E. and Ostendorf, M. (2009). A machine learning approach to reading level assessment. Computer 
Speech & Language, 23(1):89?106. 
Rabin, A., Zakaluk, B., and Samuels, S. (1988). Determining difficulty levels of text written in languages other 
than english. Readability: Its past, present & future. Newark DE: International Reading Association, pages 
46?76. 
Rosch, E. (1978). Principles of categorization. Fuzzy grammar: a reader, pages 91?108. 
Schwarm, S. and Ostendorf, M. (2005). Reading level assessment using support vector machines and statistical 
language models. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, 
pages 523?530. Association for Computational Linguistics. 
Sherman, L. (1893). Analytics of literature: A manual for the objective study of english poetry and prose. 
Boston: Ginn. 
Si, L. and Callan, J. (2003). A semisupervised learning method to merge search engine results. ACM 
Transactions on Information Systems (TOIS), 21(4):457?491. 
Sinha, M., Sharma, S., Dasgupta, T., and Basu, A. (2012). New readability measures for Bangla and Hindi texts. 
In Proceedings of COLING 2012: Posters, pages 1141?1150, Mumbai, India. The COLING 2012 Organizing 
Committee. 
 
354
Coling 2008: Proceedings of the workshop on Human Judgements in Computational Linguistics, pages 58?65
Manchester, August 2008
An Agreement Measure for Determining Inter-Annotator Reliability of
Human Judgements on Affective Text
Plaban Kr. Bhowmick, Pabitra Mitra, Anupam Basu
Department of Computer Science and Engineering,
Indian Institute of Technology, Kharagpur, India ? 721302
{plaban,pabitra,anupam}@cse.iitkgp.ernet.in
Abstract
An affective text may be judged to be-
long to multiple affect categories as it may
evoke different affects with varying degree
of intensity. For affect classification of
text, it is often required to annotate text
corpus with affect categories. This task
is often performed by a number of hu-
man judges. This paper presents a new
agreement measure inspired by Kappa co-
efficient to compute inter-annotator relia-
bility when the annotators have freedom
to categorize a text into more than one
class. The extended reliability coefficient
has been applied to measure the quality of
an affective text corpus. An analysis of
the factors that influence corpus quality has
been provided.
1 Introduction
The accuracy of a supervised machine learning
task primarily depends on the annotation quality of
the data, that is used for training and cross valida-
tion. Reliability of annotation is a key requirement
for the usability of an annotated corpus. Inconsis-
tency or noisy annotation may lead to the degrada-
tion of performances of supervised learning algo-
rithms. The data annotated by a single annotator
may be prone to error and hence an unreliable one.
This also holds for annotating an affective corpus,
which is highly dependent on the mental state of
the subject. The recent trend in corpus develop-
ment in NLP is to annotate corpus by more than
one annotators independently. In corpus statistics,
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
the corpus reliability is measured by coefficient of
agreement. The coefficients of agreement are ap-
plied to corpus for various goals like measuring re-
liability, validity and stability of corpus (Artstein
and Poesio, 2008).
Jacob Cohen (Cohen, 1960) introduced Kappa
statistics as a coefficient of agreement for nom-
inal scales. The Kappa coefficient measures the
proportion of observed agreement over the agree-
ment by chance and the maximum agreement at-
tainable over chance agreement considering pair-
wise agreement. Later Fleiss (Fleiss, 1981) pro-
posed an extension to measure agreement in ordi-
nal scale data.
Cohen?s Kappa has been widely used in vari-
ous research areas. Because of its simplicity and
robustness, it has become a popular approach for
agreement measurement in the area of electron-
ics (Jung, 2003), geographical informatics (Hagen,
2003), medical (Hripcsak and Heitjan, 2002), and
many more domains.
There are other variants of Kappa like agree-
ment measures (Carletta, 1996). Scott?s pi (Scott,
1955) was introduced to measure agreement in sur-
vey research. Kappa and pi measures differ in the
way they determine the chance related agreements.
pi-like coefficients determine the chance agreement
among arbitrary coders, while ?-like coefficients
treats the chance of agreement among the coders
who produced the reliability data (Artstein and
Poesio, 2008).
One of the drawbacks of pi and Kappa like coef-
ficients except Fleiss? Kappa (Fleiss, 1981) is that
they treat all kinds of disagreements in the same
manner. Krippendorff?s ? (Krippendorff, 1980) is
a reliability measure which treats different kind of
disagreements separately by introducing a notion
of distance between two categories. It offers a way
58
to measure agreement in nominal, interval, ordinal
and ratio scale data.
Reliability assessment of corpus is an impor-
tant issue in corpus driven natural language pro-
cessing and the existing reliability measures have
been used in various corpus development tasks.
For example, Kappa coefficient has been used
in developing parts of speech corpus (Mieskes
and Strube, 2006), dialogue act tagging efforts
like MapTask (Carletta et al, 1997) and Switch-
board (Stolke et al, 1997), subjectivity tagging
task (Bruce and Wiebe, 1999) and many more.
The pi and ? coefficients measure the reliabil-
ity of the annotation task where a data item can
be annotated with one category. (Rosenberg and
Binkowski, 2004) puts an effort towards measur-
ing corpus reliability for multiply labeled data
points. In this measure, the annotators are allowed
to mark one data point with at most two classes,
one of which is primary and other is secondary.
This measure was used to determine the reliability
of a email corpus where emails are assigned with
primary and secondary labels from a set of email
types.
Affect recognition from text is a recent and
promising subarea of natural language process-
ing. The task is to classify text segments into ap-
propriate affect categories. The supervised ma-
chine learning techniques, which requires a reli-
able annotated corpus, may be applied for solv-
ing the problem. In general, a blend of emotions
is common in both verbal and non-verbal com-
munication. Unlike conventional annotation tasks
like POS corpus development, where one data item
may belong to only one category, in affective text
corpus, a data item may be fuzzy and may belong
to multiple affect categories. For example, the fol-
lowing sentence may belong to disgust and sad
category since it may evoke both the emotions to
different degrees of intensity.
A young married woman was burnt to
death allegedly by her in-laws for dowry.
This property makes the existing agreement mea-
sures inapplicable for determining agreement in
emotional corpus. Craggs and Wood (2004)
adopted a categorical scheme for annotating emo-
tion in affective text dialogue. They claimed to ad-
dress the problem of agreement measurement for
the data set where one data item may belong to
more than one category using an extension of Krip-
pendorff?s ?. But the details of the extension is yet
to be disseminated.
In this paper, we propose a new agreement mea-
sure for multiclass annotation which we denote by
A
m
. The new measure is then applied to an affec-
tive text corpus to
? Assess Reliability: To test whether the corpus
can be used for developing computational af-
fect recognizer.
? Determine Gold Standard: To define a gold
standard that will be used to test the accuracy
of the affect recognizer.
In section 2, we describe the affective text cor-
pus and the annotation scheme. In section 3, we
propose a new reliability measure (A
m
) for mul-
ticlass annotated data. In section 4, we provide
an algorithm to determine gold standard data from
the annotation and in section 5, we discuss about
applying A
m
measure to the corpus developed by
us and some observations related to the annotation.
2 Affective Text Corpus and Annotation
Scheme
The affective text corpus collected by us consists
of 1000 sentences extracted from Times of India
news archive1. The sentences were collected from
headlines as well as articles belonging to political,
social, sports and entertainment domain.
Selection of affect categories is a very crucial
and important decision problem due to the follow-
ing reasons.
? The affect categories should be applicable to
the considered genre.
? The affect categories should be identifiable
from language.
? The categories should be unambiguous.
We shall try to validate these points based on the
results obtained, after applying the our extended
measure on the text corpus with respect to a set of
selected basic emotional categories.
Basic emotions are those for which the respec-
tive expressions across culture, ethnicity, age, sex,
social structure are invariant (Ortony and Turner,
1990). But unfortunately, there is a long per-
sistent debate among the psychologists regarding
1http://timesofindia.indiatimes.com/archive.cms
59
the number of basic emotional categories (Ortony
and Turner, 1990). One of the theories behind
the basic emotions is that they are biologically
primitive because they possess evolutionary signif-
icance related to the basic needs for the survival of
the species (Plutchik, 1980). The universality of
recognition of emotions from distinctive facial ex-
pressions is an indirect technique to establish the
basic emotions (Darwin, 1965).
Six basic affect categories (Ekman, Friesen and
Ellsworth, 1982) have been considered in emotion
recognition from speech (Song et al, 2004), fa-
cial expression (Pantic and Rothkrantz, 2000). Our
annotation scheme considers six basic emotions,
namely, Anger, Disgust, Fear, Happiness, Sadness,
Surprise as specified by Ekman for affect recogni-
tion in text corpus.
The annotation scheme considers the following
points:
? Two types are sentences are collected for an-
notation.
? Direct Affective Sentence: Here, the
agent present in the sentence is experi-
encing a set of emotions, which are ex-
plicit in the sentence. For example, in
the following sentence Indian support-
ers are the agents experiencing a disgust
emotion.
Indian supporters are disgusted
about players? performances in
the World Cup.
? Indirect Affective Sentence: Here, the
reader of the sentence is experiencing a
set of emotions. In the following sen-
tence, the reader is experiencing a dis-
gust emotion because the event of ac-
cepting bribe, is an indecent act carried
out by responsible agents like Top offi-
cials.
Top officials are held for accept-
ing bribe from a poor villager.
? A sentence may trigger multiple emotions si-
multaneously. So, one annotator may classify
a sentence to more than one affective cate-
gories.
? For each emotion, the keywords that trigger
the particular emotion are marked.
? For each emotion, the events or objects that
trigger the concerned emotion are marked.
Here, we aim at measuring the agreement in an-
notation. The focus is to measure the agreement
in annotation pattern rather than the agreement in
individual emotional classes.
3 Proposed Agreement Measure
To overcome the shortcomings of existing relia-
bility measures mentioned earlier, we propose A
m
measure, which is an agreement measure for cor-
pus annotation task considering multiclass classifi-
cation. We present the notion of agreement below.
3.1 Notion of Paired Agreement
In order to allow for multiple labels, we calculate
agreement between all the pairs of possible labels.
Let C1 and C2 be two affect categories, e.g., anger
and disgust. Let <C1, C2> denote the category
pair. An annotator?s assignment of labels can be
represented as a pair of binary choices for each cat-
egory pair <C1, C2>, namely, < 0, 0 >, < 0, 1 >,
< 1, 0 >, and < 1, 1 >. It should be noted that the
proposed metric considers the non-inclusion in a
category by an annotator pair as an agreement.
For an item, two annotators U1 and U2 are said
to agree on <C1, C2> if the following conditions
hold.
U1.C1 = U2.C1
U1.C2 = U2.C2
where U
i
.C
j
signifies that the value for C
j
for an-
notator U
i
and the value may either be 1 or 0. For
example, if one coder marks an item with anger
and another with disgust, they would disagree on
the pairs that include these labels, but still agree
that the item does not express happiness and sad-
ness.
3.2 A
m
Agreement Measure
With the notion of paired agreement discussed ear-
lier, the observed agreement(P
o
) is the proportion
of items the annotators agreed on the category
pairs and the expected agreement(P
e
) is the pro-
portion of items for which agreement is expected
by chance when the items are randomly. Follow-
ing the line of Cohen?s Kappa (Cohen, 1960), A
m
is defined as the proportion of agreement after ex-
pected or chance agreement is removed from con-
sideration and is given by
A
m
=
P
o
? P
e
1? P
e
(1)
60
When P
o
equals P
e
, A
m
value is computed to
be 0, which signifies no non-random agreement
among the annotators. An A
m
value of 1, the
upper limit of A
m
, indicates a perfect agreement
among the annotators. We define P
o
and P
e
as
follows.
Observed Agreement (P
o
):
Let I be the number of items, C is the number of
categories and U is the number of annotators and
S be the set of all category pairs with cardinality
(
C
2
)
. The total agreement on a category pair p
for an item i is n
ip
, the number of annotator pairs
who agree on p for i.
The average agreement on a category pair p for
an item i is n
ip
divided by the total number of an-
notator pairs and is given by
P
ip
=
1
(
U
2
)
n
ip
(2)
The average agreement for the item i is the mean
of P
ip
over all category pairs and is given by
P
i
=
1
(
C
2
)(
U
2
)
?
p?S
n
ip
(3)
The observed agreement is the average agreement
over all the item and is given by
P
o
=
1
I
I
?
i=1
P
i
=
1
I
(
C
2
)(
U
2
)
I
?
i=1
?
p?S
n
ip
(4)
=
4
IC(C ? 1)U(U ? 1)
I
?
i=1
?
p?S
n
ip
Expected Agreement (P
e
):
The expected agreement is defined as the agree-
ment among the annotators when they assign the
items to a set of categories randomly. However,
since we are considering the agreement on cate-
gory pairs, we consider the expected agreement
to be the expectation that the annotators agree on
a category pair. For a category pair, four possible
assignment combinations constitute a set which is
given by
G = {[0 0], [0 1], [1 1]}.
It is to be noted that the combinations [0 1] and [1
0] are clubbed to one element as they are symmet-
ric to each other. Let ?P (p
g
|u) be the overall pro-
portion of items assigned with assignment combi-
nation g ? G to category pair p ? S by annotator
u and n
p
g
u
be the total number of assignments of
items by annotator u with assignment combination
g to category pair p. Then ?P (p
g
|u) is given by
?
P (p
g
|u) =
n
p
g
u
I
(5)
For an item, the probability that two arbitrary
coders agree with the same assignment combina-
tion in a category pair is the joint probability of
individual coders making this assignments inde-
pendently. For two annotators u
x
and u
y
the joint
probability is given by ?P (p
g
|u
x
)
?
P (pg|u
y
). The
probability that two arbitrary annotators agree on
a category pair p with assignment combination g
is the average over all annotator pairs belonging to
W , the set of annotator pairs and is given by
?
P (p
g
) =
1
(
U
2
)
?
(u
x
,u
y
)?W
?
P (p
g
|u
x
)
?
P (p
g
|u
y
)
(6)
The probability that two arbitrary annotators agree
on a category pair for all assignment combinations
is given by
?
P (p) =
?
pg?G
?
P (p
g
) (7)
The chance agreement is calculated by taking
average over all category pairs.
P
e
=
1
(
C
2
)
?
p?S
?
P (p) (8)
The A
m
measure may be calculated based on the
expressions of P
o
and P
e
as given in Equation 4
and Equation 8 to compute the reliability of anno-
tation with respect to multiclass annotation.
4 Gold Standard Determination
Gold standard data is used as a reference data set
for various goals like
? Building reliable classifier
61
? Determine the performance of a classifier
To attach a set of labels to a data item in the gold
standard data, we assign the majority decision
label to an item. Let n
O
be the number of annota-
tors, who have assigned an item i into category C
and n
?
annotators have decided not to assign the
same item into that category. Then i is assigned to
C if n
O
> n
?
; otherwise it is not assigned to that
category.
Algorithm 1: Algorithm for determining gold
standard data
Input: Set of I items annotated into C
categories by U annotators
Output: Gold standard data
foreach annotator u ? U do
?
u
? 0;
end
foreach item i ? I do
foreach category c ? C do
? = set of annotators who have
assigned i in category c;
? = set of annotators who have not
assigned i in category c;
if cardinality(?)>cardinality(?) then
assign label c to i;
?
j
? ?
j
+ 1 where j ? ?;
end
else if cardinality(?)<cardinality(?)
then
do not assign label c to i;
?
j
? ?
j
+ 1 where j ? ?;
end
else if
?
?
? >
?
?
? then
assign label c to i;
end
end
end
If n
O
= n
?
, then we resolve the tie based on the
performances of the annotators in previous assign-
ments. We assign an expert coder index(?) to each
annotator and it is updated based on the agreement
of their judgments over the corpus. There are two
cases when the ? values are incremented
? If the item is assigned to a category in the gold
standard data, the ? values are incremented
for those annotators who have assigned the
item into that category.
? If the item is not assigned to a category in
the gold standard data, the ? values are in-
cremented for those annotators who have not
assigned the item into that category.
If n
O
and n
?
are equal for an item, we make use
of the ? values for deciding upon the assignment of
the item to the category in concern. We assign the
item into that category if the combined ? values of
the annotators who have assigned the item into that
category is greater than the combined ? values of
the annotators who have not assigned the item into
that category, i.e.,
n
O
?
i=1
?
i
>
n
?
?
j=1
?
j
The algorithm for determining gold standard
data is given in Algorithm 1.
5 Experimental Results
We applied the proposed A
m
measure to estimate
the quality of the affective corpus described in sec-
tion 2. Below we present the annotation experi-
ment followed by some relevant analysis.
5.1 Annotation Experiment
Ten human judges with the same social back-
ground participated in the study, assigning affec-
tive categories to sentences independently of one
another. The annotators were provided with the
annotation instructions and they were trained with
some sentences not belonging to the corpus. The
annotation was performed with the help of a web
based annotation interface2. The corpus consists
of 1000 sentences. Three of judges were able to
complete the task within 20 days. In this paper,
we report the result of applying the measure with
data provided by three annotators without consid-
ering the incomplete annotations. Distribution of
the sentences across the affective categories for the
three judges is given in Figure 1.
5.2 Analysis of Corpus Quality
The corpus was evaluated in terms of the proposed
measure. Some of the relevant observations are
presented below.
? Agreement Value: Different agreement val-
ues related to A
m
measure are given in Ta-
ble 1. We present A
m
values for all the anno-
tator pairs in Table 2.
2http://www.mla.iitkgp.ernet.in/Annotation/index.php
62
Figure 1: Distribution of sentences for three
judges.
Agreement A
m
Value
Observed Agreement(P
o
) 0.878
Chance Agreement(P
e
) 0.534
A
m
0.738
Table 1: Agreement values for the affective text
corpus.
Annotator Pair P
o
P
e
A
m
Value
1-2 0.858 0.526 0.702
1-3 0.868 0.54 0.713
2-3 0.884 0.531 0.752
Table 2: Annotator pairwise A
m
values.
? Agreement Study: Table 3 provides the dis-
tribution of the sentences against individual
observed agreement values. It is observed
Observed Agreement No. of Sentences
0.0 < A
0
? 0.2 14
0.2 < A
0
? 0.4 73
0.4 < A
0
? 0.7 198
0.7 < A
0
? 1.0 715
Table 3: Distribution of the sentences over ob-
served agreement.
that 71.5% of the corpus belongs to [0.7 1.0]
range of observed agreement and among this
bulk portion of the corpus, the annotators as-
sign 78.6% of the sentences into a single cat-
egory. This is due to the existence of a domi-
nant emotion in a sentence and in most of the
cases, the sentence contains enough clues to
decode it. For the non-dominant emotions in
a sentence, ambiguity has been found while
decoding.
? Disagreement Study: In Table 4, we present
the category wise disagreement for all the an-
notator pairs. From the disagreement table it
is evident that the categories with maximum
number of disagreements are anger, disgust
and fear. The emotions which are close to
each other in the evaluation-activation space
are inherently ambiguous. For example,
anger and disgust are close to each other in
the evaluation-activation space. So, ambigu-
ity between these categories will be higher
compared to other pairs. If [a b] is the pair, we
count the number of cases where one annota-
tor categorized one item into [a -] pattern and
other annotator classified the same item into
[- b] pattern. In Table 5, we provide the con-
fusion between two affective categories for all
annotator pairs. This confusion matrix is a
symmetric one. So, we have provided only
the upper triangular matrix.
In Figure 2, we provide ambiguity counts of
the affective category pairs. It can be ob-
Figure 2: Category pair wise disagreement
(A=Anger, D=Disgust, F=Fear, H=Happiness,
S=Sadness and Su=Surprise).
served that anger, disgust and fear are asso-
ciated with three topmost ambiguous pairs.
5.3 Gold Standard for Affective Text Corpus
To determine the gold standard corpus, we have
applied majority decision label based approach
discussed in section 4 on the judgements provided
by only three annotators. However, as the num-
ber of annotators is much less in the current study,
the determined gold standard corpus may not have
63
Anger Disgust Fear Happiness Sadness Surprise
1-2 68 94 74 64 74 45
1-3 74 86 105 57 54 45
2-3 65 49 58 22 50 20
Total 207 229 273 143 178 110
Table 4: Categorywise disagreement for the annotator pairs.
Anger Disgust Fear Happiness Sadness Surprise
Anger - 39 28 11 22 7
Disgust - - 28 6 24 13
Fear - - - 2 24 12
Happiness - - - - 18 8
Sadness - - - - - 9
Surprise - - - - - -
Table 5: Confusion matrix for category pairs.
much significance. Here, we report the result
of applying the gold standard determination algo-
rithm on the data provided by three annotators.
The distribution of sentences over the affective cat-
egories is depicted in Figure 3.
Figure 3: Distribution of sentences in gold stan-
dard corpus.
6 Conclusion and Future Work
Measuring the reliability of the affective text cor-
pus where one single item may be classified into
more than one single category is a complex task.
In this paper, we have provided a new coefficient
to measure reliability in multiclass annotation task
by incorporating pairwise agreement in affective
class pairs. The measure yields an agreement value
0.72, when applied to an annotated corpus pro-
vided by three users. This considerable agreement
value indicates that the affect categories consid-
ered for annotation may be applicable to the news
genre.
We are in process of collecting annotated corpus
from more annotators which will ensure a statisti-
cally significant result. According to the disagree-
ment study presented in section 5.2, confusions
between specific emotions is most likely between
categories which are adjacent in the activation-
evaluation space. The models of annotator agree-
ment which use weights for different types of dis-
agreement will be interesting for future study. The
direct and indirect affective sentences have not
been treated separately in this study. The algo-
rithm for determination of gold standard requires
more details investigation as simple majority vot-
ing may not be sufficient for highly subjective data
like emotion.
Acknowledgement
Plaban Kr. Bhowmick is partially supported by
Microsoft Corporation, USA and Media Lab Asia,
India. The authors are thankful to the reviewers for
their detailed suggestions regarding the work.
References
Artstein, Ron and Massimo Poesio. 2008. Inter-coder
Agreement for Computational Linguistics. Compu-
tational Linguistics.
Bruce, Rebecca F. and Janyce M. Wiebe 1999. Rec-
64
ognizing Subjectivity: A Case Study of Manual Tag-
ging. Natural Language Engineering. 1(1):1-16.
Carletta, Jean. 1996. Assessing Agreement on Classi-
fication Tasks: The Kappa Statistic. Computational
Linguistics. 22(21):249-254.
Carletta, Jean, Isard .A, Isard S., Jacqueline C. Kowtko,
Gwyneth D. Sneddon, and Anne H. Anderson. 1997.
The Reliability of a Dialogue Structure Coding
Scheme. Computational Linguistics. 23(1):13-32.
Cohen, Jacob. 1960. A Coefficient of Agreement
for Nominal Scales. Educational and Psychological
Measurement. 20(1):37-46.
Craggs Richard and Mary M. Wood. 2004. A Categori-
cal Annotation Scheme for Emotion in the Linguistic
Content of Dialogue. Tutorial and Research Work-
shop, Affective Dialogue Systems. Kloster Irsee, 89-
100.
Darwin, Charles. 1965. The Expression of Emotions in
Man and Animals.. Chicago: University of Chicago
Press. (Original work published 1872)
Ekman, Paul., Friesen W. V., and Ellsworth P. 1982.
What Emotion Categories or Dimensions can Ob-
servers Judge from Facial Behavior? Emotion in
the human face, Cambridge University Press. pages
39-55, New York.
Fleiss, Joseph L. 1981. Statistical Methods for Rates
and Proportions. Wiley. second ed., New York.
Hagen-Zanker, Alex. 2003. Fuzzy Set Approach to
Assessing Similarity of Categorical Maps. Interna-
tional Journal for Geographical Information Science.
17(3):235-249.
Hripcsak, George and Daniel F. Heitjan. 2002. Mea-
suring Agreement in Medical Informatics Reliabil-
ity Studies. Journal of Biomedical Informatics.
35(2):99-110.
Jung, Ho-Won. 2003. Evaluating Interrater Agreement
in SPICE-based Assessments. Computer Standards
& Interfaces. 25(5):477-499.
Krippendorff, Klaus 1980. Content Analysis: An Intro-
duction to its Methodology. Sage Publications. Bev-
erley Hills, CA.
Mieskes, Margot and Michael Strube. 2006. Part-of-
Speech Tagging of Transcribed Speech. Proceedings
of International Conference on Language Resources
and Evaluation. GENOA
Ortony, Andrew and Terence J. Turner. 1990. What?s
Basic About Basic Emotions?. Psychological Re-
view. 97(3):315-331.
Pantic, Maja and Leon Rothkrantz. 2000. Automatic
Analysis of Facial Expressions: The State of the Art.
IEEE Transactions on Pattern Analysis and Machine
Intelligence. 22(12):1424-1445.
Plutchik, Robert 1980. A General Psychoevolutionary
Theory of Emotion. Emotion: Theory, research, and
experience: Vol. 1. Theories of emotion. Academic
Press, New York, 3-33.
Rosenberg, Andrew, and Ed Binkowski. 2004. Aug-
menting the Kappa Statistic to Determine Interanno-
tator Reliability for Multiply Labeled Data Points.
In Proceedings of North American Chapter of the
Association for Computational Linguistics. Boston,
77-80.
Scott, William A. 1955. Reliability of Content Anal-
ysis: The Case of Nominal Scale Coding. Public
Opinion Quarterly. 19(3):321-325.
Song, Mingli, Chun Chen, Jiajun Bu, and Mingyu You.
2004. Speech Emotion Recognition and Intensity Es-
timation. Internation Conference on Computational
Science and its Applications. Perugia, 406-413.
Stolcke A., Ries K., Coccaro N., Shriberg E., Bates R.,
Jurafsky .D, Taylor P., Martin C. Van-Ess-Dykema,
and Meteer .M. 1997. Dialogue Act Modeling
for Automatic Tagging and Recognition of Con-
versational Speech. Computational Linguistics.
26(3):339-371.
65
