Proceedings of the NAACL HLT Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics, pages 10?17,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Utilizing Contextually Relevant Terms in Bilingual Lexicon Extraction
Azniah Ismail
Department of Computer Science
University of York
York YO10 5DD UK
azniah@cs.york.ac.uk
Suresh Manandhar
Department of Computer Science
University of York
York YO10 5DD UK
suresh@cs.york.ac.uk
Abstract
This paper demonstrates one efficient tech-
nique in extracting bilingual word pairs from
non-parallel but comparable corpora. Instead
of using the common approach of taking high
frequency words to build up the initial bilin-
gual lexicon, we show contextually relevant
terms that co-occur with cognate pairs can be
efficiently utilized to build a bilingual dictio-
nary. The result shows that our models using
this technique have significant improvement
over baseline models especially when highest-
ranked translation candidate per word is con-
sidered.
1 Introduction
Bilingual lexicons or dictionaries are invaluable
knowledge resources for language processing tasks.
The compilation of such bilingual lexicons remains
as a substantial issue to linguistic fields. In gen-
eral practice, many linguists and translators spend
huge amounts of money and effort to compile this
type of knowledge resources either manually, semi-
automatically or automatically. Thus, obtaining the
data is expensive.
In this paper, we demonstrate a technique that uti-
lizes contextually relevant terms that co-occur with
cognate pairs to expand an initial bilingual lexi-
con. We use unannotated resources that are freely
available such as English-Spanish Europarl corpus
(Koehn, 2005) and another different set of cognate
pairs as seed words.
We show that this technique is able to achieve
high precision score for bilingual lexicon extracted
from non-parallel but comparable corpora. Our
model using this technique with spelling similarity
approach obtains 85.4 percent precision at 50.0 per-
cent recall. Precision of 79.0 percent at 50.0 percent
recall is recorded when using this technique with
context similarity approach. Furthermore, by using
a string edit-distance vs. precision curve, we also
reveal that the latter model is able to capture words
efficiently compared to a baseline model.
Section 2 is dedicated to mention some of the re-
lated works. In Section 3, the technique that we used
is explained. Section 4 describes our experimental
setup followed by the evaluation results in Section
5. Discussion and conclusion are in Section 6 and 7
respectively.
2 Related Work
Koehn and Knight (2002) describe few potential
clues that may help in extracting bilingual lexi-
con from two monolingual corpora such as identi-
cal words, similar spelling, and similar context fea-
tures. In reporting our work, we treat both identical
word pairs and similar spelling word pairs as cog-
nate pairs.
Koehn and Knight (2002) map 976 identical
word pairs that are found in their two monolin-
gual German-English corpora and report that 88.0
percent of them are correct. They propose to re-
strict the word length, at least of length 6, to in-
crease the accuracy of the collected word pairs.
Koehn and Knight (2002) mention few related works
that use different measurement to compute the sim-
ilarity, such as longest common subsequence ratio
(Melamed, 1995) and string edit distance (Mann
10
and Yarowski, 2001). However, Koehn and Knight
(2002) point out that majority of their word pairs
do not show much resemblance at all since they
use German-English language pair. Haghighi et al
(2008) mention one disadvantage of using edit dis-
tance, that is, precision quickly degrades with higher
recall. Instead, they propose assigning a feature to
each substring of length of three or less for each
word.
For approaches based on contextual features or
context similarity, we assume that for a word that
occurs in a certain context, its translation equivalent
also occurs in equivalent contexts. Contextual fea-
tures are the frequency counts of context words oc-
curring in the surrounding of target word W. A con-
text vector for each W is then constructed, with only
context words found in the seed lexicon. The context
vectors are then translated into the target language
before their similarity is measured.
Fung and Yee (1998) point out that not only the
number of common words in context gives some
similarity clue to a word and its translation, but the
actual ranking of the context word frequencies also
provides important clue to the similarity between a
bilingual word pair. This fact has motivated Fung
and Yee (1998) to use tfidf weighting to compute the
vectors. This idea is similar to Rapp (1999) who
proposed to transform all co-occurrence vectors us-
ing log likelihood ratio instead of just using the
frequency counts of the co-occurrences. These val-
ues are used to define whether the context words are
highly associated with the W or not.
Earlier work relies on a large bilingual dictionary
as their seed lexicon (Rapp, 1999; Fung and Yee,
1998; among others). Koehn and Knight (2002)
present one interesting idea of using extracted cog-
nate pairs from corpus as the seed words in order
to alleviate the need of huge, initial bilingual lex-
icon. Haghighi et al (2008), amongst a few oth-
ers, propose using canonical correlation analysis to
reduce the dimension. Haghighi et al(2008) only
use a small-sized bilingual lexicon containing 100
word pairs as seed lexicon. They obtain 89.0 percent
precision at 33.0 percent recall for their English-
Spanish induction with best feature set, using top-
ically similar but non-parallel corpora.
3 The Utilizing Technique
Most works in bilingual lexicon extraction use lists
of high frequency words that are obtained from
source and target language corpus to be their source
and target word lists respectively. In our work, we
aim to extract a high precision bilingual lexicon us-
ing different approach. Instead, we use list of con-
textually relevant terms that co-occur with cognate
pairs.
Figure 1: Cognate pair extraction
These cognate pairs can be derived automatically
by mapping or finding identical words occur in two
high frequency list of two monolingual corpora (see
Figure 1). They are used to acquire list of source
word Ws and target word Wt. Ws and Wt are contex-
tually relevant terms that highly co-occur with the
cognate pairs in the same context. Thus, log likeli-
hood measure can be used to identify them.
Next, bilingual word pairs are extracted among
words in these Ws and Wt list using either context
similarity or spelling similarity. Figure 2 shows
some examples of potential bilingual word pairs,
of Ws and Wt, co-occurring with identical cognate
pairs of word ?civil?.
As we are working on English-Spanish language
pair, we extract bilingual lexicon using string edit
distance to identify spelling similarity between Ws
11
and Wt. Figure 3 outlines the algorithm using
spelling similarity in more detail.
Using the same Ws and Wt lists, we extract bilin-
gual lexicon by computing the context similarity be-
tween each {Ws,Wt} pair. To identify the context
similarity, the relation between each {Ws, Wt} pair
can be detected automatically using a vector similar-
ity measure such as cosine measure as in (1). The A
and B are the elements in the context vectors, con-
taining either zero or non-zero seed word values for
Ws and Wt, respectively.
Cosine similarity = cos(?) = A?B||A|| ? ||B|| (1)
The cosine measure favors {Ws,Wt} pairs that
share the most number of non-zero seed word val-
ues. However, one disadvantage of this measure is
that the cosine value directly proportional to the ac-
tual Ws and Wt values. Even though Ws and Wt
might not closely correlated with the same set of
seed words, the matching score could be high if Ws
or Wt has high seed word values everywhere. Thus,
we transform the context vectors from real value
into binary vectors before the similarity is computed.
Figure 4 outlines the algorithm using context simi-
larity in more detail.
In the algorithm, after the Ws and Wt lists are ob-
tained, each Ws and Wt units is represented by their
context vector containing log likelihood (LL) values
of contextually relevant words, occurring in the seed
lexicon, that highly co-occur with the Ws and Wt re-
spectively. To get this context vector, for each Ws
and Wt, all sentences in the English or Spanish cor-
pora containing the respective word are extracted to
form a particular sub corpus, e.g. sub corpus soci-
ety is a collection of sentences containing the source
word society.
Using window size of a sentence, the LL value
of term occurring with the word Ws or Wt in their
respective sub corpora is computed. Term that is
highly associated with the Ws or Wt is called con-
textually relevant term. However, we consider each
term with LL value higher than certain threshold
(e.g. threshold ? 15.0) to be contextually relevant.
Contextually relevant terms occurring in the seed
lexicon are used to build the context vector for the
Figure 2: Bilingual word pairs are found within context
of cognate word civil
Figure 3: Utilizing technique with spelling similarity
12
Figure 4: Utilizing technique with context similarity
Ws or Wt respectively. For example, word participa-
tion and education occurring in the seed lexicon are
contextually relevant terms for source word society.
Thus, they become elements of the context vector.
Then, we transform the context vectors, from real
value into binary, before we compute the similarity
with cosine measure.
4 Experimental Setup
4.1 Data
For source and target monolingual corpus, we de-
rive English and Spanish sentences from parallel Eu-
roparl corpora (Koehn, 2005).
? We split each of them into three parts; year
1996 - 1999, year 2000 - 2003 and year 2004
- 2006.
? We only take the first part, about 400k sen-
tences of Europarl Spanish (year 1996 - 1999)
and 2nd part, also about 400k from Europarl
English (year 2000 - 2003). We refer the partic-
ular part taken from the source language corpus
as S and the other part of the target language
corpus as T.
This approach is quite common in order to ob-
tain non-parallel but comparable (or same domain)
corpus. Examples can be found in Fung and Che-
ung (2004), followed by Haghighi et al (2008).
For corpus pre-processing, we only use sentence
boundary detection and tokenization on raw text.
We decided that large quantities of raw text requir-
ing minimum processing could also be considered as
minimal since they are inexpensive and not limited.
These should contribute to low or medium density
languages for which annotated resources are limited.
We also clean all tags and filter out stop words from
the corpus.
4.2 Evaluation
We extracted our evaluation lexicon from Word Ref-
erence? free online dictionary . For this work, the
word types are not restricted but mostly are con-
tent words. We have two sets of evaluation. In one,
we take high ranked candidate pairs where Ws could
have multiple translations. In the other, we only con-
sider highest-ranked Wt for each Ws. For evalua-
tion purposes, we take only the top 2000 candidate
ranked-pairs from the output. From that list, only
candidate pairs with words found in the evaluation
lexicon are proposed. We use F1-measure to evalu-
ate proposed lexicon against the evaluation lexicon.
The recall is defined as the proportion of the high
ranked candidate pairs. The precision is given as the
number of correct candidate pairs divided by the to-
tal number of proposed candidate pairs.
4.3 Other Setups
The following were also setup and used:
? List of cognate pairs
We obtained 79 identical cognate pairs from the
?from website http://www.wordreference.com
13
top 2000 high frequency lists of our S and T but
we chose 55 of these that have at least 100 con-
textually relevant terms that are highly associ-
ated with each of them.
? Seed lexicon
We also take a set of cognate pairs to be our
seed lexicon. We defined the size of a small
seed lexicon ranges between 100 to 1k word
pairs. Hence, our seed lexicon containing 700
cognate pairs are still considered as a small-
sized seed lexicon. However, instead of acquir-
ing this set of cognate pairs automatically, we
compiled the cognate pairs from a few Learn-
ing Spanish Cognates websites ?. This ap-
proach is a simple alternative to replace the
10-20k general dictionaries (Rapp, 1999; Fung
and McKeown, 2004) or automatic seed words
(Koehn and Knight, 2002; Haghighi et al,
2008). However, this approach can only be
used if the source and target language are fairly
related and both share lexically similar words
that most likely have same meaning. Other-
wise, we have to rely on general bilingual dic-
tionaries.
? Stop list
Previously (Rapp, 1999; Koehn and Knight,
2002; among others) suggested filtering out
commonly occurring words that do not help
in processing natural language data. This idea
sometimes seem as a negative approach to the
natural articles of language, however various
studies have proven that it is sensible to do so.
? Baseline system
We build baseline systems using basic context
similarity and spelling similarity features.
5 Evaluation Results
For the first evaluation, candidate pairs are ranked
after being measured either with cosine for context
similarity or edit distance for spelling similarity. In
this evaluation, we take the first 2000 of {Ws, Wt}
candidate pairs from the proposed lexicon where Ws
may have multiple translations or multiple Wt. See
Table 1.
?such as http://www.colorincolorado.org and
http://www.language-learning-advisor.com
Setting P0.1 P0.25 P0.33 P0.5 Best-F1
ContextSim (CS) 42.9 69.6 60.7 58.7 49.6
SpellingSim (SS) 90.5 74.2 69.9 64.6 50.9
(a) from baseline models
Setting P0.1 P0.25 P0.33 P0.5 Best-F1
E-ContextSim (ECS) 78.3 73.5 71.8 64.0 51.2
E-SpellingSim (ESS) 95.8 75.6 71.8 63.4 51.5
(b) from our proposed models
Table 1: Performance of baseline and our model for top
2000 candidates below certain threshold and ranked
Setting P0.1 P0.25 P0.33 P0.5 Best-F1
ContextSim-Top1 (CST) 58.3 61.2 64.8 55.2 52.6
SpellingSim-Top1 (SST) 84.9 66.4 52.7 34.5 37.0
(a) from baseline models
Setting P0.1 P0.25 P0.33 P0.5 Best-F1
E-ContextSim-Top1 (ECST) 85.0 81.1 79.7 79.0 57.1
E-SpellingSim-Top1 (ESST) 100.0 93.6 91.6 85.4 59.0
(b) from our proposed models
Table 2: Performance of baseline and our model for top
2000 candidates of top 1
Using either context or spelling similarity ap-
proach on S and T (labeled ECS and ESS respec-
tively), our models achieved about 51.2 percent of
best F1 measure. Those are not a significant im-
provement with only 1.0 to 2.0 percent error reduc-
tion over the baseline models (labeled CS and SS).
For the second evaluation, we take the first 2000
of {Ws, Wt} pairs where Ws may only have the high-
est ranked Wt as translation candidates (See Table
2). This time, both of our models (with context
similarity and spelling similarity, labeled ECST and
ESST respectively) yielded almost 60.0 percent of
best F1 measure. It is noted that using ESST alone
recorded a significant improvement of 20.0 percent
in the F1 score compared to SST baseline model.
ESST obtained 85.4 percent precision at 50.0 per-
cent recall. Precision of 79.0 percent at 50.0 percent
recall is recorded when using ECST. However, the
ECST has not recorded a significant difference over
CST baseline model (57.1 and 52.6 percent respec-
tively) in the second evaluation. The overall perfor-
mances, represented by precision scores for different
14
Figure 5: String Edit Distance vs. Precision curve
range of recalls, for these four models are illustrated
in Appendix A.
It is important to see the inner performance of the
ECST model with further analysis. We present a
string edit distance value (EDv) vs. precision curve
for ECST and CST in Figure 5 to measure the per-
formance of the ECST model in capturing bilingual
pairs with less similar orthographic features, those
that may not be captured using spelling similarity.
The graph in Figure 5 shows that even though
CST has higher precision score than ECST at EDv
of 2, it is not significant (the difference is less than
5.0 percent) and the spelling is still similar. On the
other hand, precision for proposed lexicon with EDv
above 3 (where the Ws and the proposed translation
equivalent Wt spelling becoming more dissimilar)
using ECST is higher than CST. The most significant
difference of the precision is almost 35.0 percent,
where ECST achieved almost 75.0 percent precision
compared to CST with 40.0 percent precision at EDv
of 4. It is followed by ECST with almost 50.0 per-
cent precision compared to CST with precision less
than 35.0 percent, offering about 15.0 percent preci-
sion improvement at EDv of 5.
6 Discussion
As we are working on English-Spanish language
pair, we could have focused on spelling similar-
ity feature only. Performance of the model using
this feature usually record higher accuracy other-
wise they may not be commonly occurring in a cor-
pus. Our models with this particular feature have
recorded higher F1 scores especially when consid-
ering only the highest-ranked candidates.
We also experiment with context similarity ap-
proach. We would like to see how far this approach
helps to add to the candidate scores from our corpus
S and T. The other reason is sometimes a correct tar-
get is not always a cognate even though a cognate
for it is available. Our ECST model has not recorded
significant improvement over CST baseline model in
the F1-measure. However, we were able to show that
by utilizing contextually relevant terms, ECST gath-
ers more correct candidate pairs especially when it
comes to words with dissimilar spelling. This means
that ECST is able to add more to the candidate scores
compared to CST. Thus, more correct translation
pairs can be expected with a good combination of
ECST and ESST.
The following are the advantages of our utilizing
technique:
? Reduced errors, hence able to improve preci-
sion scores.
? Extraction is more efficient in the contextual
boundaries (see Appendix B for examples).
? Context similarity approach within our tech-
nique has a potential to add more to the can-
didate scores.
Yet, our attempt using cognate pairs as seed words is
more appropriate for language pairs that share large
number of cognates or similar spelling words with
same meaning. Otherwise, one may have to rely on
bilingual dictionaries.
There may be some possible supporting strate-
gies, which we could use to help improve further
the precision score within the utilizing technique.
For example, dimension reduction using canonical
correlation analysis (CCA), resemblance detection,
measure of dispersion, reference corpus and further
noise reduction. However, we do not include a re-
ranking method, as we are using collection of cog-
nate pairs instead of a general bilingual dictionary.
Since our corpus S and T is in similar domain, we
might still not have seen the potential of this tech-
nique in its entirety. One may want to test the tech-
nique with different type of corpora for future works.
15
Nevertheless, we are still concerned that many
spurious translation equivalents were proposed be-
cause the words actually have higher correlation
with the input source word compared to the real
target word. Otherwise, the translation equivalents
may not be in the boundaries or in the corpus from
which translation equivalents are to be extracted.
Haghighi et al(2008) have reported that the most
common errors detected in their analysis on top 100
errors were from semantically related words, which
had strong context feature correlations. Thus, the
issue remains. We leave all these for further discus-
sion in future works.
7 Conclusion
We present a bilingual lexicon extraction technique
that utilizes contextually relevant terms that co-
occur with cognate pairs to expand an initial bilin-
gual lexicon. We show that this utilizing technique
is able to achieve high precision score for bilingual
lexicon extracted from non-parallel but comparable
corpora. We demonstrate this technique using unan-
notated resources that are freely available.
Our model using this technique with spelling sim-
ilarity obtains 85.4 percent precision at 50.0 percent
recall. Precision of 79.0 percent at 50.0 percent re-
call is recorded when using this technique with con-
text similarity approach. We also reveal that the
latter model with context similarity is able to cap-
ture words efficiently compared to a baseline model.
Thus, we show contextually relevant terms that co-
occur with cognate pairs can be efficiently utilized
to build a bilingual dictionary.
References
Cranias, L., Papageorgiou, H, and Piperidis, S. 1994.
A matching technique in Example-Based Machine
Translation. In International Conference On Compu-
tational Linguistics Proceedings, 15th conference on
Computational linguistics, Kyoto, Japan.
Diab, M., and Finch, S. 2000. A statistical word-level
translation model for comparable corpora. In Proceed-
ings of the Conference on Content-based multimedia
information access (RIAO).
Fung, P., and Cheung, P. 2004. Mining very non-parallel
corpora: Parallel sentence and lexicon extraction via
bootstrapping and EM. In Proceedings of the 2004
Conference on Empirical Method in Natural Language
Processing (EMNLP), Barcelona, Spain.
Fung, P., and Yee, L.Y. 1998. An IR Approach for
Translating New Words from Nonparallel, Compara-
ble Texts. In Proceedings of COLING-ACL98, Mon-
treal, Canada, 1998.
Fung, P., and McKeown, K. 1997. Finding Terminology
Translations from Non-parallel Corpora. In The 5th
Annual Workshop on Very Large Corpora, Hong Kong,
Aug 1997.
Haghighi, A., Liang, P., Berg-Krikpatrick, T., and Klein,
D. 2008. Learning bilingual lexicons from monolin-
gual corpora. In Proceedings of The ACL 2008, June
15 -20 2008, Columbus, Ohio
Koehn, P. 2005. Europarl: a parallel corpus for statistical
machine translation. In MT Summit
Koehn, P., and Knight , K. 2001. Knowledge sources
for word-level translation models. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP).
Koehn, P., and Knight , K. 2002. Learning a translation
lexicon from monolingual corpora. In Proceedings of
ACL 2002, July 2002, Philadelphia, USA, pp. 9-16.
Rapp, R. 1995. Identifying word translations in non-
parallel texts. In Proceedings of ACL 33, pages 320-
322.
Rapp, R. 1999. Automatic identification of word transla-
tions from unrelated English and German corpora. In
Proceedings of ACL 37, pages 519-526.
16
Appendix A. Precision scores with different recalls
Appendix B. Some examples of effective extraction via utilizing technique
17
Coling 2010: Poster Volume, pages 481?489,
Beijing, August 2010
Bilingual lexicon extraction from comparable corpora using
in-domain terms
Azniah Ismail
Department of Computer Science
University of York
azniah@cs.york.ac.uk
Suresh Manandhar
Department of Computer Science
University of York
suresh@cs.york.ac.uk
Abstract
Many existing methods for bilingual
lexicon learning from comparable corpora
are based on similarity of context vectors.
These methods suffer from noisy vectors
that greatly affect their accuracy. We
introduce a method for filtering this noise
allowing highly accurate learning of
bilingual lexicons. Our method is based
on the notion of in-domain terms which
can be thought of as the most important
contextually relevant words. We provide
a method for identifying such terms.
Our evaluation shows that the proposed
method can learn highly accurate bilin-
gual lexicons without using orthographic
features or a large initial seed dictionary.
In addition, we also introduce a method
for measuring the similarity between
two words in different languages without
requiring any initial dictionary.
1 Introduction
In bilingual lexicon extraction, the context-based
approach introduced by Rapp (1995) is widely
used (Fung, 1995; Diab and Finch, 2000; among
others). The focus has been on learning from
comparable corpora since the late 1990s (Rapp,
1999; Koehn and Knight, 2002; among others).
However, so far, the accuracy of bilingual lexi-
con extraction using comparable corpora is quite
poor especially when orthographic features are
not used. Moreover, when orthographic features
are not used, a large initial seed dictionary is es-
sential in order to acquire higher accuracy lexicon
(Koehn and Knight, 2002). This means that cur-
rent methods are not suitable when the language
pairs are not closely related or when a large initial
seed dictionary is unavailable.
When learning from comparable corpora, a
large initial seed dictionary does not necessarily
guarantee higher accuracy since the source and
target texts are poorly correlated. Thus, inducing
highly accurate bilingual lexicon from compara-
ble corpora has so far been an open problem.
In this paper, we present a method that is able
to improve the accuracy significantly without re-
quiring a large initial bilingual dictionary. Our
approach is based on utilising highly associated
terms in the context vector of a source word.
For example, the source word powers is highly
associated with the context word delegation. We
note that, firstly, both share context terms such as
parliament and affairs. And, secondly, the trans-
lation equivalents of powers and delegation in the
target language are not only highly associated but
they also share context terms that are the trans-
lation equivalents of parliament and affairs (see
Figure 1).
2 Related work
Most of the early work in bilingual lexicon ex-
traction employ an initial seed dictionary. A large
bilingual lexicon with 10k to 20k entries is neces-
sary (Fung, 1995; Rapp, 1999).
Koehn and Knight (2002) introduce techniques
for constructing the initial seed dictionary auto-
matically. Their method is based on using identi-
cal spelling features. The accuracy of such initial
bilingual lexicon is almost 90.0 percent and can
be increased by restricting the word length (Koehn
and Knight, 2002). Koehn and Knight found ap-
proximately 1000 identical words in their German
481
Figure 1: An example of in-domain terms that co-occur in English and Spanish. The source word is
powers and the target word is poderes. The word delegation and delegacion are the highly associated
words with the source word and the target word respectively. Their in-domain terms, as shown in the
middle, can be used to map the source word in context of word delegation to its corresponding target
word in context of delegacion.
and English monolingual corpora. They expanded
the lexicon with the standard context-based ap-
proach and achieved about 25.0 percent accuracy
(Koehn and Knight, 2002).
Similar techniques were used in Haghighi et
al. (2008) who employ dimension reduction in
the extraction method. They recorded 58.0 per-
cent as their best F1 score for the context vec-
tor approach on non-parallel comparable corpora
containing Wikipedia articles. However, their
method scores less on comparable corpora con-
taining distinct sentences derived from the Eu-
roparl English-Spanish corpus.
3 Learning in-domain terms
In the standard context vector approach, we as-
sociate each source word and target word with
their context vectors. The source and target con-
text vectors are then compared using the initial
seed dictionary and a similarity measure. Learn-
ing from comparable corpora is particularly prob-
lematic due to data sparsity, as important context
terms may not occur in the training corpora while
some may occur but with low frequency and can
be missed. Some limitations may also be due to
the size of the initial seed dictionary being small.
The initial seed dictionary can also contribute
irrelevant or less relevant features that can mis-
lead the similarity measure especially when the
number of dimensions is large. The approach we
adopt attempts to overcome this problem.
In Figure 1, for the source word powers, dele-
gation is the highly associated word. Both powers
and delegation share common contextual terms
such as parliament and affairs. Now the transla-
tion equivalent of delegation is delegacion. For
the potential translation equivalent poderes, we
see that the common contextual terms shared by
powers and poderes are terms parlamento (par-
liament) and asuntos (affairs).
482
Figure 2: An example of English-Spanish lexicon learnt for the source word powers. On the top,
the system suggested competencias and rejected poderes when powers is associated with community,
democracy or independence. The word poderes is suggested when powers is associated with justice or
delegation.
We observe that these common contextual
terms are simultaneously the first-order and
second-order context terms of the target word.
They are the shared context terms of the target
word and its highly associated context term. We
define these terms as in-domain terms. These in-
domain terms can be used to map words to their
corresponding translations. The highly associated
context terms can be thought of as sense discrim-
inators that differentiate the different uses of the
target word. In Figure 2, we show how delegation
helps in selecting between the ?control or influ-
ence? sense of powers while rejecting the ?ability
or skill? sense.
In this paper, our focus is not on sense disam-
biguation and we follow current evaluation meth-
ods for bilingual lexicon extraction. However, it is
clear that our method can be adapted for building
sense disambiguated bilingual lexicons.
3.1 Identifying highly associated words
To identify the context terms CT (WS) of a source
word WS , as in (Rapp, 1999), we use log-
likelihood ratio (LL) Dunning (1993). We choose
all words with LL > t1 where t1 is a threshold.
The highly associated words then are the top k
highest ranked context terms. In our experiments,
we only choose the top 100 highest ranked context
terms as our highly associated terms.
In order to compute the log-likelihood ratio of
target word a to co-occur with context word b, we
create a contingency table. The contingency table
contains the observed values taken from a given
corpus. An example of the contingency table is
shown in Table 1.
C[i,j] community ? community
powers 124 1831 1955 C(powers)
? powers 11779 460218 471997 C(? powers)
11903 462049
C(community) C(? community)
Here C[i, j] denotes the count of the number of sentences in
which i co-occurs with j.
Total corpus size: N = 473952 in the above
Table 1: Contingency table for observed values of
target word powers and context word community.
The LL value of a target word a and context
word b is given by:
LL(a, b) =
?
i?{a,?a},j?{b,?b}
2C(i, j) log C(i, j)NC(i) C(j)
3.1.1 Identifying in-domain terms
In our work, to find the translation equivalent of a
source word WS , we do not use the context terms
CT (WS). Instead, we use the in-domain terms
IDT (WS ,WR). For each highly associated term
483
WR, we get different in-domain terms. Further-
more, IDT (WS ,WR) is a subset of CT (WS).
The in-domain terms of WS given the context
terms WR is given by:
ID(WS ,WR) = CT (WS) ? CT (WR)
Programme and public are some of the examples
of in-domain terms of powers given community as
the highly associated term.
3.1.2 Finding translations pairs
Note that ID(WS ,WR) is an in-domain term
vector in the source language. Let WT be a
potential translation equivalent for WS . Let,
tr(WR) be a translation equivalent for WR. Let
ID(WT , tr(WR)) be an in-domain term vector in
the target language.
We use tr(WS |WR) to denote the translation
proposed for WS given the highly associated term
WR. We compute tr(WS |WR) using:
tr(WS |WR) =
argmax
WT
sim(ID(WS ,WR), ID(WT , tr(WR)))
Our method learns translation pairs that are
conditioned on highly associated words (WR). Ta-
ble 2 provides a sample of English-Spanish lexi-
con learnt for the word power with different WR.
English Spanish
WS WR tr(WR) WT
Sim
powers
competencias 0.9876
poderes 0.9744community comunidad
independiente 0.9501
competencias 0.9948
poderes 0.9915democracy democracia
independiente 0.9483
competencias 0.9939
poderes 0.9745independence independencia
independiente 0.9633
poderes 0.9922
competencias 0.3450justice justicia
independiente 0.9296
poderes 0.9568
competencias 0.9266delegation delegacion
independiente 0.8408
Table 2: A sample of translation equivalents learnt
for powers.
In the next section, we introduce a similarity
measure that operates on the context vectors in the
source language and the target language without
requiring a seed dictionary.
4 Rank-binning similarity measure
Most existing methods for computing similarity
cannot be directly employed for measuring the
similarity between in-domain term context vec-
tors since each context vector is in a different lan-
guage. A bilingual dictionary can be assumed
but that greatly diminishes the practicality of the
method.
We address this by making an assumption. We
assume that the relative distributions of in-domain
context terms of translation equivalent pairs are
roughly comparable in the source language and
in the target language. For example, consider
the log-likelihood values of the in-domain terms
for the translation pair agreement-acuerdo (condi-
tioned on the highly associated term association-
associacion) given in Figure 3. We note that the
distribution of in-domain terms are comparable al-
though not identical. Thus, the distribution can be
used as a clue to derive translation pairs but we
need a method to compute similarity of the vector
of in-domain terms.
Rank-binning or rank histograms are usually
used as a diagnostic tool to evaluate the spread of
an ensemble rather than as a verification method.
Wong (2009) use the method of rank-binning to
roughly examine performance of a system on
learning lightweight ontologies. We apply the
rank-binning procedure for measuring the similar-
ity of word pairs.
Pre-processing step:
1. Let WS be a source language word and
x1, x2, ..., xn be the set of n context terms
ranked in descending log-likelihood values
of WS (see Table 3).
2. We transform the rank values of context
terms xk into the range [0,1] using:
zk =
rank(xk)? 1
n? 1
484
Figure 3: Similar distribution of in-domain terms
for agreement with association and acuerdo with
asociacion.
Binning procedure
We divide the interval [0, 1] into g bins1 of equal
length. Let b1, . . . , bg denote the g bins. Then
we map the in-domain terms vector ID(WS ,WR)
into the binned vector b1, . . . , bg. For each xk ?
ID(WS ,WR), this mapping is done by using the
corresponding zk from the pre-processing step.
For each bin, we count the number of different in-
domain terms that are mapped into this bin. Thus,
if the range of the first bin b1 is [0, 0.009] then eu-
ropean, legislative, parliament are mapped into b1
i.e. b1 = 3. The bins are normalised by dividing
with | ID(WS ,WR) |.
Rank binning similarity
We use Euclidean distance to compute similarity
between bins. Given, bins P = p1, . . . , pg and
Q = q1, . . . , qg, the Euclidean distance is given
by:
dist(P,Q) =
????
g?
i=1
(pi, qi)2
1We used the following formula to estimate the number
of bins:
g = 1 + 3.3 ? log (| ID(WS ,WR) |)
CT (powers)
Context term LL rank zk
european 491.33 1 0.00000
legislative 482.19 2 0.00406
parliament 408.26 3 0.00813
: : : :
: : : :
: : : :
public 16.96 245 0.99186
programme 15.40 246 0.99593
representatives 15.32 247 1.00000
n = 247
Table 3: Some examples of transformed values of
each term in CT (powers).
In the next section, we describe the setup in-
cluding the data, the lexicon and the evaluation
used in our experiments.
5 Experimental setup
5.1 Data
For comparable text, we derive English and Span-
ish distinct sentences from the Europarl parallel
corpora. We split the corpora into three parts ac-
cording to year. We used about 500k sentences
for each language in the experiments. This ap-
proach is further explained in Ismail and Man-
andhar (2009) and is similar to Koehn and Knight
(2001) and Haghighi et al (2008).
5.2 Pre-processing
For corpus pre-processing, we use sentence
boundary detection and tokenization on the raw
text before we clean the tags and filter stop words.
We sort and rank words in the text according to
their frequencies. For each of these words, we
compute their context term log-likelihood values.
5.3 Lexicon
In the experiment, a bilingual lexicon is required
for evaluation. We extract our evaluation lexicon
from the Word Reference2 free online dictio-
nary. This extracted bilingual lexicon has low cov-
erage.
2http://wordreference.com
485
5.4 Evaluation
In the experiments, we considered the task of
building a bilingual English-Spanish lexicon be-
tween the 2000 high frequency source and target
words, where we required each individual word
to have at least a hundred highly associated con-
text terms that are not part of the initial seed dic-
tionary. Different highly associated WR terms
for a given WT might derive similar (WS ,WT )
pairs. In this case, we only considered one of
the (WS ,WT ) pairs. In future work, we would
like to keep these for word sense discrimination
purposes. Note that we only considered proposed
translation pairs whose similarity values are above
a threshold t2.
We used the F1 measure to evaluate the pro-
posed lexicon against the evaluation lexicon. If
either WS or WT in the proposed translation pairs
is not in the evaluation lexicon, we considered the
translation pairs as unknown, although the pro-
posed translation pairs are correct. Recall is de-
fined as the proportion of the proposed lexicon di-
vided by the size of the lexicon and precision is
given by the number of correct translation pairs at
a certain recall value.
6 Experiments
In this section, we look into how the in-domain
context vectors affect system performance. We
also examine the potential of rank-binning simi-
larity measure.
6.1 From standard context vector to
in-domain context vector
Most research in bilingual lexicon extraction so
far has employed the standard context vector ap-
proach. In order to explore the potential of the
in-domain context vectors, we compare the sys-
tems that use in-domain approach against systems
that use the standard approach. We also employ
different sets of seed lexicon in each system to be
used in the similarity measure:
? Lex700: contains 700 cognate pairs from a
few Learning Spanish Cognate websites3.
3such as http://www.colorincolorado.org
and http://www.language-learning-advisor.com
? Lex100: contains 100 bilingual entries of the
most frequent words in the source corpus that
have translation equivalents in the extracted
evaluation lexicon. We select the top one
hundred words in the source corpus, so that
their translation equivalents is within the first
2000 high frequency words in the target cor-
pus.
? Lex160: contains words with similar spelling
that occur in both corpora. We used 160
word pairs with an edit distance value less
than 2, where each word is longer than 4
characters.
Models using the standard approach are de-
noted according to the size of the particular lex-
icon used in their context similarity measure,
i.e. CV-100 for using Lex100, CV-160 for using
Lex160 and CV-700 for using Lex700. We use IDT
to denote our model. We use lexicon sizes to dis-
tinguish the different variants, e.g. IDT-CV100 for
using Lex100, IDT-CV160 for using Lex160 and
IDT-CV700 for using Lex700.
With CV-700, the system achieved 52.6 per-
cent of the best F1 score. Using the same seed
dictionary, the best F1 score has increased about
20 percent points with IDT-CV700 recorded 73.1
percent. IDT-CV100 recorded about 15.0 percent
higher best F1 score than CV-100 with 80.9 and
66.4 percent respectively. Using an automatically
derived seed dictionary, IDT-CV160 yielded 70.0
percent of best F1 score while CV-160 achieved
62.4 percent. Results in Table 4 shows various
precisions px at recall values x.
Model P0.10 P0.25 P0.33 P0.50 BestF1score
CV-700 58.3 61.2 64.8 55.2 52.6
CV-100 52.0 53.0 47.2 44.8 66.4
CV-160 68.5 56.8 48.8 48.8 62.4
IDT-CV700 83.3 90.2 82.0 66.7 73.1
IDT-CV100 80.0 75.8 66.7 69.4 80.9
IDT-CV160 90.0 80.6 73.9 69.2 70.0
Table 4: Performance of different models.
486
6.2 Similarity measure using rank-binning
We use RB to denote our model based on the
rank-binning approach. Running RB means that
no seed dictionary is involved in the similarity
measure. We also ran the similarity measure in
the IDT (IDT-RB160) by employing the derived
Lex160 for the in-domain steps.
We ran several tests using IDT-RB160 with dif-
ferent numbers of bins. The results are illustrated
in Figure 4. The IDT-RB160 yielded 63.7 percent
of best F1 score with 4 bins. However, the F1
score starts to drop from 61.1 to 53.0 percent with
6 and 8 bins respectively. With 3 and 2 bins the
IDT-RB160 yielded 63.7 and 62.0 percent of best
F1 score respectively. Using 1 bin is not be pos-
sible as all values fall under one bin. Thus, the
rank-binning similarity measure for the rest of the
experiments where RB is mentioned, refers to a 4
bins setting.
Figure 4: Performance of IDT-RB160 with differ-
ent numbers of bins.
While systems using the standard context simi-
larity measure yielded scores higher than 50.0 per-
cent of best F1, the RB achieved only 39.2 per-
cent. However, RB does not employ an initial
dictionary and does not use orthographic features.
As mentioned above, the system scored higher
when the similarity measure was used in the IDT
(i.e. IDT-RB160). Note that Lex160 is derived au-
tomatically so the approach can also be consid-
ered as unsupervised. The system performance
is slightly lower compared to the conventional
CV-160. However, IDT-CV160 outperforms both
of the systems (see Figure 5).
Figure 5: Performance of different unsupervised
models.
Overall, systems that exploit in-domain terms
yielded higher F1 scores compared to the conven-
tional context vector approach.
6.3 Comparison with CCA
Previous work in extracting bilingual lexicons
from comparable corpora generally employ the
conventional context vector approach. Haghighi
et al (2008) focused on applying canonical cor-
relation analysis (CCA), a dimension reduction
technique, to improve the method. They were us-
ing smaller comparable corpora, taken from the
first 50k sentences of English Europarl and the
second 50k of Spanish Europarl, and different ini-
tial seed dictionary. Hence, we tested CCA in our
experimental setup. In CV-700 setting, using CCA
yields 57.5 percent of the best F1 score compared
to 73.1 percent of the best F1 score with IDT that
we reported in Section 6.2.
7 Discussion
7.1 Potential of in-domain terms
Our experiments clearly demonstrate that the use
of in-domain terms achieves higher F1 scores
compared to conventional methods. It also shows
that our method improves upon earlier reported
dimension reduction methods. From our obser-
vation, the number of incorrect translation pairs
487
were further reduced when the context terms were
filtered. Recall that the in-domain terms in the
target language were actually the shared context
terms of the target word and its highly associ-
ated context terms. Nevertheless, this approach
actually depends on the initial bilingual lexicon
in order to translate those highly associated con-
text terms into the source language. Table 5
shows some examples of most confidence trans-
lation pairs proposed by the IDT-CV100.
English Spanish Sim score Correct?
principle principio 0.9999 Yes
government estado 0.9999 No
government gobierno 0.9999 Yes
resources recursos 0.9999 Yes
difficult dificil 0.9999 Yes
sector competencia 0.9998 No
sector sector 0.9998 Yes
programme programa 0.9998 Yes
programme comunidad 0.9998 No
agreement acuerdo 0.9998 Yes
Table 5: Some examples of most confident trans-
lation pairs proposed by IDT-CV100 ranked by
similarity scores.
7.2 Seed dictionary variation
The initial seed dictionary plays a major role in
extracting bilingual lexicon from comparable cor-
pora. There are a few different ways for us to
derive a seed dictionary. Recall that Lex700 and
Lex100, that are used in the experiments, are de-
rived using different methods. The F1 scores of
the system using Lex100 were much higher com-
pared to the system using Lex700. Thus, extend-
ing Lex100 with additional high frequency words
may provide higher accuracy.
One important reason is that all bilingual en-
tries in Lex100 occur frequently in the corpora.
Although the size of Lex700 is larger, it is not sur-
prising that most of the words never occur in the
corpora, such as volleyball and romantic. How-
ever, using Lex160 is more interesting since it is
derived automatically from the corpora, though
one should realize that the relationship between
the language pair used in the respective mono-
lingual corpora, English and Spanish, may have
largely affect the results. Thus, for other sys-
tems involving unrelated language pairs, the rank-
binning similarity measure might be a good op-
tion.
7.3 Word sense discrimination ability
As mentioned in Section 5.4, each source word
may have more than one highly associated context
term, WR. Different WR may suggest different
target words for the same source word. For exam-
ple, given the source word powers and the highly
associated word community, competencias is pro-
posed as the best translation equivalent. On the
other hand, for same source word powers, when
the highly associated word is delegation, the tar-
get word poderes is suggested.
8 Conclusion
We have developed a method to improve the F1
score in extracting bilingual lexicon from compa-
rable corpora by exploiting in-domain terms. This
method also performs well without using an ini-
tial seed dictionary. More interestingly, our work
reveals the potential of building word sense dis-
ambiguated lexicons.
References
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In ACL 2008, Colum-
bus, Ohio.
Azniah Ismail and Suresh Manandhar. 2009. Utiliz-
ing contextually relevant terms in bilingual lexicon
extraction In Workshop on Unsupervised and Min-
imally Supervised Learning of Lexical Semantics,
Boulder, Colorado.
Mona Diab and Steve Finch. 2000. A statistical word-
level translation model for comparable corpora. In
Proceedings of the Conference on Content-based
multimedia information access (RIAO).
Pascale Fung. 1995. Compiling bilingual lexicon en-
tries from a non-parallel English-Chinese corpus. In
Proceedings of the 3rd Annual Workshop on Very
Large Corpora, Boston, Massachusetts, 173-183.
Philipp Koehn and Kevin Knight. 2001. Knowledge
sources for word-level translation models. In Pro-
ceedings of the Conference on empirical method in
natural language processing (EMNLP).
488
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In
Proceedings of the ACL 2002, Philadelphia, USA,
9-16.
Reinhard Rapp. 1995. Identifying word translations
in non-parallel texts. In Proceedings of the ACL 33,
320-322.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated English and Ger-
man corpora. In Proceedings of the ACL 37, 519-
526.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistic, volume 19(1), 61-74.
Wilson Yiksen Wong. 2009. Learning lightweight on-
tologies from text across different domains using the
web as background knowledge. Ph.D. Thesis. Uni-
versity of Western Australia
489
