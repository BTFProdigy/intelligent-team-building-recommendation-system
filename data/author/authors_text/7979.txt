Effect of Domain-Specific Corpus
in Compositional Translation Estimation for Technical Terms
Masatsugu Tonoike?, Mitsuhiro Kida?,
Takehito Utsuro?
?Graduate School of Informatics,
Kyoto University
Yoshida-Honmachi, Sakyo-ku,
Kyoto 606-8501 Japan
(tonoike,kida,takagi,sasaki,
utsuro)@pine.kuee.kyoto-u.ac.jp
Toshihiro Takagi?, Yasuhiro Sasaki?,
and Satoshi Sato?
?Graduate School of Engineering,
Nagoya University
Furo-cho, Chikusa-ku,
Nagoya 464-8603 JAPAN
ssato@nuee.nagoya-u.ac.jp
Abstract
This paper studies issues on compiling
a bilingual lexicon for technical terms.
In the task of estimating bilingual term
correspondences of technical terms, it
is usually quite difficult to find an exist-
ing corpus for the domain of such tech-
nical terms. In this paper, we take an
approach of collecting a corpus for the
domain of such technical terms from
the Web. As a method of translation
estimation for technical terms, we pro-
pose a compositional translation esti-
mation technique. Through experimen-
tal evaluation, we show that the do-
main/topic specific corpus contributes
to improving the performance of the
compositional translation estimation.
1 Introduction
This paper studies issues on compiling a bilingual
lexicon for technical terms. So far, several tech-
niques of estimating bilingual term correspon-
dences from a parallel/comparable corpus have
been studied (Matsumoto and Utsuro, 2000). For
example, in the case of estimation from compa-
rable corpora, (Fung and Yee, 1998; Rapp, 1999)
proposed standard techniques of estimating bilin-
gual term correspondences from comparable cor-
pora. In their techniques, contextual similarity
between a source language term and its transla-
tion candidate is measured across the languages,
and all the translation candidates are re-ranked ac-
cording to the contextual similarities. However,
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
Figure 1: Compilation of a Domain/Topic Spe-
cific Bilingual Lexicon
there are limited number of parallel/comparable
corpora that are available for the purpose of es-
timating bilingual term correspondences. There-
fore, even if one wants to apply those existing
techniques to the task of estimating bilingual term
correspondences of technical terms, it is usually
quite difficult to find an existing corpus for the
domain of such technical terms.
Considering such a situation, we take an ap-
proach of collecting a corpus for the domain of
such technical terms from the Web. In this ap-
proach, in order to compile a bilingual lexicon
for technical terms, the following two issues have
to be addressed: collecting technical terms to be
listed as the headwords of a bilingual lexicon, and
estimating translation of those technical terms.
Among those two issues, this paper focuses on the
second issue of translation estimation of technical
terms, and proposes a method for translation es-
timation for technical terms using a domain/topic
specific corpus collected from the Web.
More specifically, the overall framework of
114
compiling a bilingual lexicon from the Web can
be illustrated as in Figure 1. Suppose that we have
sample terms of a specific domain/topic, techni-
cal terms to be listed as the headwords of a bilin-
gual lexicon are collected from the Web by the re-
lated term collection method of (Sato and Sasaki,
2003). Those collected technical terms can be di-
vided into three subsets according to the number
of translation candidates they have in an existing
bilingual lexicon, i.e., the subset XUS of terms for
which the number of translations in the existing
bilingual lexicon is one, the subset XMS of terms
for which the number of translations is more than
one, and the subset YS of terms which are not
found in the existing bilingual lexicon. (Hence-
forth, the union XUS ? XMS is denoted as XS .)
The translation estimation task here is to estimate
translations for the terms of XMS and YS . For the
terms of XMS , it is required to select an appro-
priate translation from the translation candidates
found in the existing bilingual lexicon. For ex-
ample, as a translation of the Japanese technical
term ??????, which belongs to the logic cir-
cuit field, the term ?register? should be selected
but not the term ?regista? of the football field. On
the other hand, for the terms of YS , it is required
to generate and validate translation candidates. In
this paper, for the above two tasks, we use a do-
main/topic specific corpus. Each term of XUS has
the only one translation in the existing bilingual
lexicon. The set of the translations of terms of
XUS is denoted as XUT . Then, the domain/topic
specific corpus is collected from the Web using
the terms in the set XUT . A new bilingual lexicon
is compiled from the result of translation estima-
tion for the terms of XMS and YS , as well as the
translation pairs which consist of the terms of XUS
and their translations found in the existing bilin-
gual lexicon.
For each term of XMS , from the translation can-
didates found in the existing bilingual lexicon, we
select the one which appears most frequently in
the domain/topic specific corpus. The experimen-
tal result of this translation selection process is de-
scribed in Section 5.2.
As a method of translation genera-
tion/validation for technical terms, we propose a
compositional translation estimation technique.
Compositional translation estimation of a term
can be done through the process of composi-
tionally generating translation candidates of the
term by concatenating the translation of the
constituents of the term. Here, those translation
candidates are validated using the domain/topic
specific corpus.
In order to assess the applicability of the com-
positional translation estimation technique, we
randomly pick up 667 Japanese and English tech-
nical term translation pairs of 10 domains from
existing technical term bilingual lexicons. We
then manually examine their compositionality,
and find out that 88% of them are actually com-
positional, which is a very encouraging result.
Based on this assessment, this paper proposes a
method of compositional translation estimation
for technical terms, and through experimental
evaluation, shows that the domain/topic specific
corpus contributes to improving the performance
of compositional translation estimation.
2 Collecting a Domain/Topic Specific
Corpus
When collecting a domain/topic specific corpus of
the language T , for each technical term xUT in the
set XUT , we collect the top 100 pages with search
engine queries including xUT . Our search engine
queries are designed so that documents which de-
scribe the technical term xUT is to be ranked high.
For example, an online glossary is one of such
documents. Note that queries in English and those
in Japanese do not correspond. When collect-
ing a Japanese corpus, the search engine ?goo?1
is used. Specific queries used here are phrases
with topic-marking postpositional particles such
as ?xUT ???, ?xUT ????, ?xUT ??, and an ad-
nominal phrase ?xUT ??, and ?xUT ?. When col-
lecting a English corpus, the search engine ?Ya-
hoo!?2 is used. Specific queries used here are ?xUT
AND what?s?, ?xUT AND glossary?, and ?xUT ?.
3 Compositional Translation Estimation
for Technical Terms
3.1 Overview
An example of compositional translation estima-
tion for the Japanese technical term ??????
1http://www.goo.ne.jp/
2http://www.yahoo.com/
115
? application(1)
? practical(0.3)
? applied(1.6)
? action(1)
? activity(1)
? behavior(1)
? analysis(1)
? diagnosis(1)
? assay(0.3)
? behavior analysis(10)
??Compositional generation 
of translation candidate
? applied behavior analysis(17.6)
? application behavior analysis(11)
? applied behavior diagnosis(1)
??Decompose source term into constituents  
??Translate constituents into target language      process
?? ?? ??a
?? ????b
Generated translation candidates
?(1.6?1?1)+(1.6?10)
? application(1)
? practical(0.3)
? applied(1.6)
Figure 2: Compositional Translation Estimation
for the Japanese Technical Term ????????
?? is shown in Figure 2. First, the Japanese tech-
nical term ???????? is decomposed into
its constituents by consulting an existing bilin-
gual lexicon and retrieving Japanese headwords.3
In this case, the result of this decomposition can
be given as in the cases ?a? and ?b? (in Fig-
ure 2). Then, each constituent is translated into
the target language. A confidence score is as-
signed to the translation of each constituent. Fi-
nally, translation candidates are generated by con-
catenating the translation of those constituents
without changing word order. The confidence
score of translation candidates are defined as the
product of the confidence scores of each con-
stituent. Here, when validating those translation
candidates using the domain/topic specific cor-
pus, those which are not observed in the corpus
are not regarded as candidates.
3.2 Compiling Bilingual Constituents
Lexicons
This section describes how to compile bilingual
constituents lexicons from the translation pairs of
the existing bilingual lexicon Eijiro. The under-
lying idea of augmenting the existing bilingual
lexicon with bilingual constituents lexicons is il-
lustrated with the example of Figure 3. Suppose
that the existing bilingual lexicon does not in-
clude the translation pair ?applied :???, while
it includes many compound translation pairs with
the first English word as ?applied? and the first
3Here, as an existing bilingual lexicon, we use Ei-
jiro(http://www.alc.co.jp/) and bilingual constituents lexi-
cons compiled from the translation pairs of Eijiro (details
to be described in the next section).
 
applied mathematics : ?? ??
applied science : ?? ??
applied robot : ?? ????
.
.
. frequency
? ??
applied : ?? : 40
 
Figure 3: Example of Estimating Bilingual Con-
stituents Translation Pair (Prefix)
Table 1: Numbers of Entries and Translation Pairs
in the Lexicons
lexicon # of entries # of translationEnglish Japanese pairs
Eijiro 1,292,117 1,228,750 1,671,230
P
2
232,716 200,633 258,211
B
P
38,353 38,546 112,586
B
S
22,281 20,627 71,429
Eijiro : existing bilingual lexicon
P
2
: entries of Eijiro with two constituents
in both languages
B
P
: bilingual constituents lexicon (prefix)
B
S
: bilingual constituents lexicon (suffix)
Japanese word ????.4 In such a case, we align
those translation pairs and estimate a bilingual
constituent translation pair, which is to be col-
lected into a bilingual constituents lexicon.
More specifically, from the existing bilingual
lexicon, we first collect translation pairs whose
English terms and Japanese terms consist of two
constituents into another lexicon P
2
. We compile
?bilingual constituents lexicon (prefix)? from the
first constituents of the translation pairs in P
2
and
compile ?bilingual constituents lexicon (suffix)?
from their second constituents. The numbers of
entries in each language and those of translation
pairs in those lexicons are shown in Table 1.
In the result of our assessment, only 27% of the
667 translation pairs mentioned in Section 1 can
be compositionally generated using Eijiro, while
the rate increases up to 49% using both Eijiro and
?bilingual constituents lexicons?.5
4Japanese entries are supposed to be segmented into a
sequence of words by the morphological analyzer JUMAN
(http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html)
5In our rough estimation, the upper bound of this rate
is about 80%. Improvement from 49% to 80% could be
achieved by extending the bilingual constituents lexicons
and by introducing constituent reordering rules with preposi-
tions into the process of compositional translation candidate
generation.
116
3.3 Score of Translation Pairs in the
Lexicons
This section introduces a confidence score of
translation pairs in the various lexicons presented
in the previous section. Here, we suppose that
the translation pair ?s, t? of terms s and t is used
when estimating translation from the language of
the term s to that of the term t. First, in this pa-
per, we assume that translation pairs follow cer-
tain preference rules and can be ordered as below:
1. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of two or more constituents.
2. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are high.
3. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of exactly one constituent.
4. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are not
high.
As the definition of the confidence score
q(?s, t?) of a translation pair ?s, t?, in this paper,
we use the following:
q(?s, t?) =
?
?
?
?
?
10
(compo(s)?1) (?s, t? in Eijiro)
log
10
fp(?s, t?) (?s, t? in BP )
log
10
fs(?s, t?) (?s, t? in BS)
(1)
where compo(s) denotes the word (in English) or
morpheme (in Japanese) count of s, fp(?s, t?) the
frequency of ?s, t? as the first constituent in P
2
,
and fs(?s, t?) the frequency of ?s, t? as the second
constituent in P
2
.
6
3.4 Score of Translation Candidates
Suppose that a translation candidate yt is gener-
ated from translation pairs ?s
1
, t
1
?, ? ? ? , ?sn, tn?
by concatenating t
1
, ? ? ? , tn as yt = t1 ? ? ? tn.
Here, in this paper, we define the confidence score
of yt as the product of the confidence scores of the
6It is necessary to empirically examine whether this def-
inition of the confidence score is optimal or not. However,
according to our rough qualitative examination, the results
of the confidence scoring seem stable when without a do-
main/topic specific corpus, even with minor tuning by incor-
porating certain parameters into the score.
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
Figure 4: Experimental Evaluation of Translation
Estimation for Technical Terms with/without the
Domain/Topic Specific Corpus (taken from Fig-
ure 1)
constituent translation pairs ?s
1
, t
1
?, ? ? ? , ?sn, tn?.
Q(yt) =
n
?
i=1
q(?si, ti?) (2)
If a translation candidate is generated from
more than one sequence of translation pairs, the
score of the translation candidate is defined as the
sum of the score of each sequence.
4 Translation Candidate Validation
using a Domain/Topic Specific Corpus
It is not clear whether translation candidates
which are generated by the method described in
Section 3 are valid as English or Japanese terms,
and it is not also clear whether they belong to the
domain/topic. So using a domain/topic specific
corpus collected by the method described in Sec-
tion 2, we examine whether the translation candi-
dates are valid as English or Japanese terms and
whether they belong to the domain/topic. In our
validation method, given a ranked list of trans-
lation candidates, each translation candidate is
checked whether it is observed in the corpus, and
one which is not observed in the corpus is re-
moved from the list.
5 Experiments and Evaluation
5.1 Translation Pairs for Evaluation
In our experimental evaluation, within the frame-
work of compiling a bilingual lexicon for tech-
nical terms, we evaluate the translation estima-
tion part which is indicated with bold line in Fig-
117
Table 2: Number of Translation Pairs for Evaluation
dictionaries categories |X
S
| |Y
S
|
S = English S = Japanese
|X
U
S
| |X
M
S
| C(S) |X
U
S
| |X
M
S
| C(S)
Electromagnetics 58 33 36 22 82% 32 26 76%
McGraw-Hill Electrical engineering 52 45 34 18 67% 25 27 64%
Optics 54 31 42 12 65% 22 32 65%
Iwanami Programming language 55 29 37 18 86% 38 17 100%Programming 53 29 29 24 86% 29 24 79%
Dictionary of (Computer) 100 100 91 9 46% 69 31 56%Computer
Anatomical Terms 100 100 91 9 86% 33 67 39%
Dictionary of Disease 100 100 91 9 74% 53 47 51%
250,000 Chemicals and Drugs 100 100 94 6 58% 74 26 51%
medical terms Physical Science and Statistics 100 100 88 12 64% 58 42 55%
Total 772 667 633 139 68% 433 339 57%
McGraw-Hill : Dictionary of Scientific and Technical Terms
Iwanami : Encyclopedic Dictionary of Computer Science
C(S) : for Y
S
, the rate of including correct translations within the collected domain/topic specific corpus
ure 4. In the evaluation of this paper, we sim-
ply skip the evaluation of the process of collecting
technical terms to be listed as the headwords of a
bilingual lexicon. In order to evaluate the transla-
tion estimation part, from ten categories of exist-
ing Japanese-English technical term dictionaries
listed in Table 2, terms are randomly picked up
for each of the set XUS , XMS , and YS . (Here, as
the terms of YS , these which consist of the only
one word or morpheme are excluded.) As de-
scribed in Section 1, the terms of XUT (the set
of the translations for the terms of XUS ) is used
for collecting a domain/topic specific corpus from
the Web. Translation estimation evaluation is to
be done against the set XMS and YS . For each of
the ten categories, Table 2 shows the sizes of XUS ,
XMS and YS , and for YS , the rate of including cor-
rect translation within the collected domain/topic
specific corpus, respectively.
5.2 Translation Selection from Existing
Bilingual Lexicon
For the terms of XMS , the selected translations are
judged by a human. The correct rates are 69%
from English to Japanese on the average and 75%
from Japanese to English on the average.
5.3 Compositional Translation Estimation
for Technical Terms without the
Domain/Topic Specific Corpus
Without the domain specific corpus, the cor-
rect rate of the first ranked translation candidate
is 19% on the average (both from English to
Japanese and from Japanese to English). The
rate of including correct candidate within top 10
is 40% from English to Japanese and 43% from
Japanese to English on the average. The rate of
compositionally generating correct translation us-
ing both Eijiro and the bilingual constituents lex-
icons (n = ?) is about 50% on the average (both
from English to Japanese and from Japanese to
English).
5.4 Compositional Translation Estimation
for Technical Terms with the
Domain/Topic Specific Corpus
With domain specific corpus, on the average, the
correct rate of the first ranked translation candi-
date improved by 8% from English to Japanese
and by 2% from Japanese to English. However,
the rate of including correct candidate within top
10 decreased by 7% from English to Japanese,
and by 14% from Japanese to English. This is be-
cause correct translation does not exist in the cor-
pus for 32% (from English to Japanese) or 43%
(from Japanese to English) of the 667 translation
pairs for evaluation.
For about 35% (from English to Japanese) or
30% (from Japanese to English) of the 667 trans-
lation pairs for evaluation, correct translation does
exist in the corpus and can be generated through
the compositional translation estimation process.
For those 35% or 30% translation pairs, Fig-
ure 5 compares the correct rate of the first ranked
translation pairs between with/without the do-
main/topic specific corpus. The correct rates in-
crease by 34?37% with the domain/topic specific
corpus. This result supports the claim that the do-
118
??
???
???
???
???
???
???
???
???
???
????
???
???
??
??
??
???
?
???
???
???
???
??
???
???
??
??
???
?
??
??
???
??
??
???
??
??
??
??
??
???
??
??
??
??
???
?
??
???
??
??
???
???
?
???
??
??
??
??
???
???
??
???
???
?
??
??
???
???
???
??
?
??
???
??
??
??
??
??
??
??
??
???
???
??
??
??
??
??
??
??
??
???
?
??
??
??
??
??
??
?
??????????????
???????????
(a) English to Japanese
??
???
???
???
???
???
???
???
???
???
????
???
???
??
??
??
???
?
???
???
???
???
??
???
???
??
??
???
?
??
??
???
??
??
???
??
??
??
??
??
???
??
??
??
??
???
?
??
???
??
??
???
???
?
???
??
??
??
??
???
???
??
???
???
?
??
??
???
???
???
??
?
??
???
??
??
??
??
??
??
??
??
???
???
??
??
??
??
??
??
??
??
???
?
??
??
??
??
??
??
?
??????????????
???????????
(b) Japanese to English
Figure 5: Evaluation against the Translation Pairs
whose Correct Translation Exist in the Corpus
and can be Generated Compositionally
main/topic specific corpus is effective in transla-
tion estimation of technical terms.
6 Related Works
As a related work, (Fujii and Ishikawa, 2001)
proposed a technique of compositional estima-
tion of bilingual term correspondences for the
purpose of cross-language information retrieval.
In (Fujii and Ishikawa, 2001), a bilingual con-
stituents lexicon is compiled from the translation
pairs included in an existing bilingual lexicon in
the same way as our proposed method. One of the
major differences of the technique of (Fujii and
Ishikawa, 2001) and the one proposed in this pa-
per is that in (Fujii and Ishikawa, 2001), instead of
the domain/topic specific corpus, they use a cor-
pus of the collection of the technical papers, each
of which is published by one of the 65 Japanese
associations for various technical domains. An-
other important difference is that in (Fujii and
Ishikawa, 2001), they evaluate only the perfor-
mance of cross-language information retrieval but
not that of translation estimation.
(Cao and Li, 2002) proposed a method of com-
positional translation estimation for compounds.
In the proposed method of (Cao and Li, 2002),
translation candidates of a term are composition-
ally generated by concatenating the translation
of the constituents of the term and are re-ranked
by measuring contextual similarity against the
source language term. One of the major differ-
ences of the technique of (Cao and Li, 2002) and
the one proposed in this paper is that in (Cao and
Li, 2002), they do not use the domain/topic spe-
cific corpus.
7 Conclusion
This paper proposed a method of compositional
translation estimation for technical terms using
the domain/topic specific corpus, and through
the experimental evaluation, showed that the do-
main/topic specific corpus contributes to improv-
ing the performance of compositional translation
estimation.
Future works include the followings: first, in
order to improve the proposed method with re-
spect to its coverage, for example, it is desir-
able to extend the bilingual constituents lexicons
and to introduce constituent reordering rules with
prepositions into the process of compositional
translation candidate generation. Second, we are
planning to introduce a mechanism of re-ranking
translation candidates based on the frequencies of
technical terms in the domain/topic specific cor-
pus.
References
Y. Cao and H. Li. 2002. Base noun phrase translation using
Web data and the EM algorithm. In Proc. 19th COLING,
pages 127?133.
Atsushi Fujii and Tetsuya Ishikawa. 2001. Japanese/english
cross-language information retrieval: Exploration of
query translation and transliteration. Computers and the
Humanities, 35(4):389?420.
P. Fung and L. Y. Yee. 1998. An IR approach for translating
new words from nonparallel, comparable texts. In Proc.
17th COLING and 36th ACL, pages 414?420.
Y. Matsumoto and T. Utsuro. 2000. Lexical knowledge ac-
quisition. In R. Dale, H. Moisl, and H. Somers, editors,
Handbook of Natural Language Processing, chapter 24,
pages 563?610. Marcel Dekker Inc.
R. Rapp. 1999. Automatic identification of word transla-
tions from unrelated English and German corpora. In
Proc. 37th ACL, pages 519?526.
S. Sato and Y. Sasaki. 2003. Automatic collection of related
terms from the web. In Proc. 41st ACL, pages 121?124.
119
A Comparative Study on Compositional Translation Estimation
using a Domain/Topic-Specific Corpus collected from the Web
Masatsugu Tonoike?, Mitsuhiro Kida?, Toshihiro Takagi?, Yasuhiro Sasaki?,
Takehito Utsuro??, Satoshi Sato? ? ?
?Graduate School of Informatics, Kyoto University
Yoshida-Honmachi, Sakyo-ku, Kyoto 606-8501, Japan
??Graduate School of Systems and Information Engineering, University of Tsukuba
1-1-1, Tennodai, Tsukuba, 305-8573, Japan
? ? ?Graduate School of Engineering, Nagoya University
Furo-cho, Chikusa-ku, Nagoya 464-8603, Japan
Abstract
This paper studies issues related to the
compilation of a bilingual lexicon for tech-
nical terms. In the task of estimating bilin-
gual term correspondences of technical
terms, it is usually rather difficult to find
an existing corpus for the domain of such
technical terms. In this paper, we adopt
an approach of collecting a corpus for the
domain of such technical terms from the
Web. As a method of translation esti-
mation for technical terms, we employ a
compositional translation estimation tech-
nique. This paper focuses on quantita-
tively comparing variations of the compo-
nents in the scoring functions of composi-
tional translation estimation. Through ex-
perimental evaluation, we show that the
domain/topic-specific corpus contributes
toward improving the performance of the
compositional translation estimation.
1 Introduction
This paper studies issues related to the compilation
of a bilingual lexicon for technical terms. Thus
far, several techniques of estimating bilingual term
correspondences from a parallel/comparable cor-
pus have been studied (Matsumoto and Utsuro,
2000). For example, in the case of estimation from
comparable corpora, (Fung and Yee, 1998; Rapp,
1999) proposed standard techniques of estimating
bilingual term correspondences from comparable
corpora. In their techniques, contextual similarity
between a source language term and its translation
candidate is measured across the languages, and
all the translation candidates are re-ranked accord-
ing to their contextual similarities. However, there
are limited number of parallel/comparable corpora
that are available for the purpose of estimating
bilingual term correspondences. Therefore, even
if one wants to apply those existing techniques to
the task of estimating bilingual term correspon-
dences of technical terms, it is usually rather dif-
ficult to find an existing corpus for the domain of
such technical terms.
On the other hand, compositional translation es-
timation techniques that use a monolingual corpus
(Fujii and Ishikawa, 2001; Tanaka and Baldwin,
2003) are more practical. It is because collecting a
monolingual corpus is less expensive than collect-
ing a parallel/comparable corpus. Translation can-
didates of a term can be compositionally generated
by concatenating the translation of the constituents
of the term. Here, the generated translation candi-
dates are validated using the domain/topic-specific
corpus.
In order to assess the applicability of the com-
positional translation estimation technique, we
randomly pick up 667 Japanese and English tech-
nical term translation pairs of 10 domains from ex-
isting technical term bilingual lexicons. We then
manually examine their compositionality, and find
out that 88% of them are actually compositional,
which is a very encouraging result.
But still, it is expensive to collect a
domain/topic-specific corpus. Here, we adopt
an approach of using the Web, since documents
of various domains/topics are available on the
Web. When validating translation candidates
using the Web, roughly speaking, there exist the
following two approaches. In the first approach,
translation candidates are validated through
the search engine (Cao and Li, 2002). In the
second approach, a domain/topic-specific corpus
is collected from the Web in advance and fixed
11
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
domain/topic
specific
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
validating
translation
candidates
web
(language T )
web
(language T )
Figure 1: Compilation of a Domain/Topic-
Specific Bilingual Lexicon using the Web
before translation estimation, then generated
translation candidates are validated against the
domain/topic-specific corpus (Tonoike et al,
2005). The first approach is preferable in terms of
coverage, while the second is preferable in terms
of computational efficiency. This paper mainly
focuses on quantitatively comparing the two
approaches in terms of coverage and precision of
compositional translation estimation.
More specifically, in compositional translation
estimation, we decompose the scoring function
of a translation candidate into two components:
bilingual lexicon score and corpus score. In this
paper, we examine variants for those components
and define 9 types of scoring functions in total.
Regarding the above mentioned two approaches
to validating translation candidates using the Web,
the experimental result shows that the second
approach outperforms the first when the correct
translation does exist in the corpus. Furthermore,
we examine the methods that combine two scor-
ing functions based on their agreement. The ex-
perimental result shows that it is quite possible to
achieve precision much higher than those of single
scoring functions.
2 Overall framework
The overall framework of compiling a bilingual
lexicon from the Web is illustrated as in Figure 1.
Suppose that we have sample terms of a specific
domain/topic, then the technical terms that are to
be listed as the headwords of a bilingual lexicon
are collected from the Web by the related term col-
lection method of (Sato and Sasaki, 2003). These
collected technical terms can be divided into three
subsets depending on the number of translation
candidates present in an existing bilingual lexicon,
i.e., the subset XUS of terms for which the number
of translations in the existing bilingual lexicon is
one, the subset XMS of terms for which the number
of translations is more than one, and the subset YS
of terms that are not found in the existing bilingual
lexicon (henceforth, the union XUS ? XMS will be
denoted as XS). Here, the translation estimation
task here is to estimate translations for the terms
of the subsets XMS and YS . A new bilingual lex-
icon is compiled from the result of the translation
estimation for the terms of the subsets XMS and
YS as well as the translation pairs that consist of
the terms of the subset XUS and their translations
found in the existing bilingual lexicon.
For the terms of the subset XMS , it is required
that an appropriate translation is selected from
among the translation candidates found in the ex-
isting bilingual lexicon. For example, as a trans-
lation of the Japanese technical term ?????,?
which belongs to the logic circuit domain, the term
?register? should be selected but not the term ?reg-
ista? of the football domain. On the other hand, for
the terms of YS , it is required that the translation
candidates are generated and validated. In this pa-
per, out of the above two tasks, we focus on the
latter of translation candidate generation and val-
idation using the Web. As we introduced in the
previous section, here we experimentally compare
the two approaches to validating translation candi-
dates. The first approach directly uses the search
engine, while the second uses the domain/topic-
specific corpus, which is collected in advance from
the Web. Here, in the second approach, we use the
term of XUS , which has only one translation in the
existing bilingual lexicon. The set of translations
of the terms of the subset XUS is denoted as XUT .
Then, in the second approach, the domain/topic-
specific corpus is collected from the Web using the
terms of the set XUT .
3 Compositional Translation Estimation
for Technical Terms
3.1 Overview
An example of compositional translation estima-
tion for the Japanese technical term ??????
?? is illustrated in Figure 2. First, the Japanese
technical term ???????? is decomposed
into its constituents by consulting an existing
bilingual lexicon and retrieving Japanese head-
12
? application(1)
? practical(0.3)
? applied(1.6)
? action(1)
? activity(1)
? behavior(1)
? analysis(1)
? diagnosis(1)
? assay(0.3)
? behavior analysis(10)
??Compositional generation 
of translation candidate
? applied behavior analysis(17.6)
? application behavior analysis(11)
? applied behavior diagnosis(1)
??Decompose source term into constituents  
??Translate constituents into target language      process
?? ?? ??a
?? ????b
Generated translation candidates
?(1.6?1?1)+(1.6?10)
? application(1)
? practical(0.3)
? applied(1.6)
Figure 2: Compositional Translation Estimation
for the Japanese Technical Term ????????
words.1 In this case, the result of this decompo-
sition can be given as in the cases ?a? and ?b?
(in Figure 2). Then, each constituent is translated
into the target language. A confidence score is as-
signed to the translation of each constituent. Fi-
nally, translation candidates are generated by con-
catenating the translation of those constituents ac-
cording to word ordering rules considering prepo-
sitional phrase construction.
3.2 Collecting a Domain/Topic-Specific
Corpus
When collecting a domain/topic-specific corpus of
the language T , for each technical term xUT in the
set XUT , we collect the top 100 pages obtained
from search engine queries that include the term
xUT . Our search engine queries are designed such
that documents that describe the technical term xUT
are ranked high. For example, an online glossary
is one such document. When collecting a Japanese
corpus, the search engine ?goo?2 is used. The spe-
cific queries that are used in this search engine
are phrases with topic-marking postpositional par-
ticles such as ?xUT ??,? ?xUT ???,? ?xUT ?,?
and an adnominal phrase ?xUT ?,? and ?xUT .?
3.3 Translation Estimation
3.3.1 Compiling Bilingual Constituents
Lexicons
This section describes how to compile bilingual
constituents lexicons from the translation pairs of
1Here, as an existing bilingual lexicon, we use Ei-
jiro(http://www.alc.co.jp/) and bilingual constituents lexicons
compiled from the translation pairs of Eijiro (details to be de-
scribed in the next section).
2http://www.goo.ne.jp/
 
applied mathematics : ?? ??
applied science : ?? ??
applied robot : ?? ????
.
.
. frequency
? ??
applied : ?? : 40
 
Figure 3: Example of Estimating Bilingual Con-
stituents Translation Pair (Prefix)
the existing bilingual lexicon Eijiro. The under-
lying idea of augmenting the existing bilingual
lexicon with bilingual constituents lexicons is il-
lustrated in Figure 3. Suppose that the existing
bilingual lexicon does not include the translation
pair ?applied : ??,? while it includes many
compound translation pairs with the first English
word ?applied? and the first Japanese word ??
?.?3 In such a case, we align those translation
pairs and estimate a bilingual constituent transla-
tion pair which is to be collected into a bilingual
constituents lexicon.
More specifically, from the existing bilingual
lexicon, we first collect translation pairs whose
English terms and Japanese terms consist of two
constituents into another lexicon P
2
. We com-
pile the ?bilingual constituents lexicon (prefix)?
from the first constituents of the translation pairs
in P
2
and compile the ?bilingual constituents lex-
icon (suffix)? from their second constituents. The
number of entries in each language and those of
the translation pairs in these lexicons are shown in
Table 1.
The result of our assessment reveals that only
48% of the 667 translation pairs mentioned in Sec-
tion 1 can be compositionally generated by using
Eijiro, while the rate increases up to 69% using
both Eijiro and ?bilingual constituents lexicons.?4
3.3.2 Score of Translation Candidates
This section gives the definition of the scores
of a translation candidate in compositional trans-
lation estimation.
First, let ys be a technical term whose transla-
tion is to be estimated. We assume that ys is de-
3Japanese entries are supposed to be segmented into a
sequence of words by the morphological analyzer JUMAN
(http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html).
4In our rough estimation, the upper bound of this rate
is approximately 80%. An improvement from 69% to 80%
could be achieved by extending the bilingual constituents lex-
icons.
13
Table 1: Numbers of Entries and Translation Pairs
in the Lexicons
lexicon # of entries # of translationEnglish Japanese pairs
Eijiro 1,292,117 1,228,750 1,671,230
P
2
217,861 186,823 235,979
B
P
37,090 34,048 95,568
B
S
20,315 19,345 62,419
B 48,000 42,796 147,848
Eijiro : existing bilingual lexicon
P
2
: entries of Eijiro with two constituents
in both languages
B
P
: bilingual constituents lexicon (prefix)
B
S
: bilingual constituents lexicon (suffix)
B : bilingual constituents lexicon (merged)
composed into their constituents as below:
ys = s1, s2, ? ? ? , sn (1)
where each si is a single word or a sequence of
words.5 For ys, we denote a generated translation
candidate as yt.
yt = t1, t2, ? ? ? , tn (2)
where each ti is a translation of si. Then the trans-
lation pair ?ys, yt? is represented as follows.
?ys, yt? = ?s1, t1?, ?s2, t2?, ? ? ? , ?sn, tn? (3)
The score of a generated translation candidate is
defined as the product of a bilingual lexicon score
and a corpus score as follows.
Q(ys, yt) = Qdict(ys, yt) ? Qcoprus(yt) (4)
Bilingual lexicon score measures appropriateness
of correspondence of ys and yt. Corpus score
measures appropriateness of the translation candi-
date yt based on the target language corpus. If a
translation candidate is generated from more than
one sequence of translation pairs, the score of the
translation candidate is defined as the sum of the
score of each sequence.
Bilingual Lexicon Score
In this paper, we compare two types of bilin-
gual lexicon scores. Both scores are defined as the
product of scores of translation pairs included in
the lexicons presented in the previous section as
follows.
5Eijiro has both single word entries and compound word
entries.
? Frequency-Length
Qdict(ys, yt) =
n
?
i=1
q(?si, ti?) (5)
The first type of bilingual lexicon scores is re-
ferred to as ?Frequency-Length.? This score is
based on the length of translation pairs and the fre-
quencies of translation pairs in the bilingual con-
stituent lexicons (prefix,suffix) BP , BS in Table 1.
In this paper, we first assume that the translation
pairs follow certain preference rules and that they
can be ordered as below:
1. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of two or more constituents.
2. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are high.
3. Translation pairs ?s, t? in the existing bilin-
gual lexicon Eijiro, where the term s consists
of exactly one constituent.
4. Translation pairs in the bilingual constituents
lexicons whose frequencies in P
2
are not
high.
As the definition of the confidence score
q(?s, t?) of a translation pair ?s, t?, we use the fol-
lowing:
q(?s, t?) =
?
?
?
10
(compo(s)?1) (?s, t? in Eijiro)
log
10
fp(?s, t?) (?s, t? in BP )
log
10
fs(?s, t?) (?s, t? in BS)
(6)
, where compo(s) denotes the word count of s,
fp(?s, t?) represents the frequency of ?s, t? as the
first constituent in P
2
, and fs(?s, t?) represents the
frequency of ?s, t? as the second constituent in P
2
.
? Probability
Qdict(ys, yt) =
n
?
i=1
P (si|ti) (7)
The second type of bilingual lexicon scores is re-
ferred to as ?Probability.? This score is calcu-
lated as the product of the conditional probabili-
ties P (si|ti). P (s|t) is calculated using bilingual
lexicons in Table 1.
P (s|t) =
fprob(?s, t?)
?
s
j
fprob(?sj , t?)
(8)
14
Table 2: 9 Scoring Functions of Translation Candidates and their Components
bilingual lexicon score corpus score corpus
score ID freq-length probability probability frequency occurrence off-line on-line
(search engine)
A prune/final prune/final o
B prune/final prune/final o
C prune/final prune/final o
D prune/final prune o
E prune/final
F prune/final final prune o
G prune/final prune/final o
H prune/final final o
I prune/final final o
fprob(?s, t?) denotes the frequency of the transla-
tion pair ?s, t? in the bilingual lexicons as follows:
fprob(?s, t?) =
{
10 (?s, t? in Eijiro)
fB(?s, t?) (?s, t? in B)
(9)
Note that the frequency of a translation pair in Ei-
jiro is regarded as 106 and fB(?s, t?) denotes the
frequency of the translation pair ?s, t? in the bilin-
gual constituent lexicon B.
Corpus Score
We evaluate three types of corpus scores as fol-
lows.
? Probability: the occurrence probability of yt
estimated by the following bi-gram model
Qcorpus(yt) = P (t1) ?
n
?
i=1
P (ti+1|ti) (10)
? Frequency: the frequency of a translation
candidate in a target language corpus
Qcorpus(yt) = freq(yt) (11)
? Occurrence: whether a translation candidate
occurs in a target language corpus or not
Qcorpus(yt) =
?
?
?
?
?
1 yt occurs in a corpus
0 yt does not occur
in a corpus
(12)
6It is necessary to empirically examine whether or not the
definition of the frequency of a translation pair in Eijiro is
appropriate.
Variation of the total scoring functions
As shown in Table 2, in this paper, we examine
the 9 combinations of the bilingual lexicon scores
and the corpus scores. In the table, ?prune? indi-
cates that the score is used for ranking and pruning
sub-sequences of generated translation candidates
in the course of generating translation candidates
using a dynamic programming algorithm. ?Final?
indicates that the score is used for ranking the fi-
nal outputs of generating translation candidates.
In the column ?corpus?, ?off-line? indicates that
a domain/topic-specific corpus is collected from
the Web in advance and then generated transla-
tion candidates are validated against this corpus.
?On-line? indicates that translation candidates are
directly validated through the search engine.
Roughly speaking, the scoring function ?A? cor-
responds to a variant of the model proposed by
(Fujii and Ishikawa, 2001). The scoring func-
tion ?D? is a variant of the model proposed by
(Tonoike et al, 2005) and ?E? corresponds to the
bilingual lexicon score of the scoring function ?D?.
The scoring function ?I? is intended to evaluate the
approach proposed in (Cao and Li, 2002).
3.3.3 Combining Two Scoring Functions
based on their Agreement
In this section, we examine the method that
combines two scoring functions based on their
agreement. The two scoring functions are selected
out of the 9 functions introduced in the previous
section. In this method, first, confidence of trans-
lation candidates of a technical term are measured
by the two scoring functions. Then, if the first
ranked translation candidates of both scoring func-
tions agree, this method outputs the agreed trans-
lation candidate. The purpose of introducing this
method is to prefer precision to recall.
15
collecting terms
of specific
domain/topic
(language S )
XSU (# of translations
is one)
compiled bilingual lexicon
process data
collecting
corpus
(language T )
sample terms
of specific 
domain/topic
(language S )
XSTU , XSTM ,YST
estimating bilingual term
correspondences
language pair (S,T )
term set
(language S )
XTU
(lang. T )
translation set
(language T )
web
(language S )
web
(language S )
existing
bilingual lexicon
XSM (# of translations
is more than one)
YS (# of translations
is zero)
web
(language T )
web
(language T )
looking up
bilingual lexicon
domain/topic
specific
corpus
(language T )
validating
translation
candidates
web
(language T )
web
(language T )
Figure 4: Experimental Evaluation of Translation
Estimation for Technical Terms with/without the
Domain/Topic-Specific Corpus (taken from Fig-
ure 1)
4 Experiments and Evaluation
4.1 Translation Pairs for Evaluation
In our experimental evaluation, within the frame-
work of compiling a bilingual lexicon for techni-
cal terms, we evaluate the translation estimation
portion that is indicated by the bold line in Fig-
ure 4. In this paper, we simply omit the evalua-
tion of the process of collecting technical terms to
be listed as the headwords of a bilingual lexicon.
In order to evaluate the translation estimation por-
tion, terms are randomly selected from the 10 cate-
gories of existing Japanese-English technical term
dictionaries listed in Table 3, for each of the sub-
sets XUS and YS (here, the terms of YS that consist
of only one word or morpheme are excluded). As
described in Section 1, the terms of the set XUT (the
set of translations for the terms of the subset XUS )
is used for collecting a domain/topic-specific cor-
pus from the Web. As shown in Table 3, size of the
collected corpora is 48MB on the average. Trans-
lation estimation evaluation is to be conducted for
the subset YS . For each of the 10 categories, Ta-
ble 3 shows the sizes of the subsets XUS and YS ,
and the rate of including correct translation within
the collected domain/topic-specific corpus for YS .
In the following, we show the evaluation results
with the source language S as English and the tar-
get language T as Japanese.
4.2 Evaluation of single scoring functions
This section gives the results of evaluating single
scoring functions A ? I listed in Table 2.
Table 4 shows three types of experimental re-
sults. The column ?the whole set YS? shows the
results against the whole set YS . The column
?generatable? shows the results against the trans-
lation pairs in YS that can be generated through
the compositional translation estimation process.
69% of the terms in ?the whole set YS? belongs
to the set ?generatable?. The column ?gene.-exist?
shows the result against the source terms whose
correct translations do exist in the corpus and that
can be generated through the compositional trans-
lation estimation process. 50% of the terms in ?the
whole set YS? belongs to the set ?gene.-exist?. The
column ?top 1? shows the correct rate of the first
ranked translation candidate. The column ?top 10?
shows the rate of including the correct candidate
within top 10.
First, in order to evaluate the effectiveness of
the approach of validating translation candidates
by using a target language corpus, we compare the
scoring functions ?D? and ?E?. The difference be-
tween them is whether or not they use a corpus
score. The results for the whole set YS show that
using a corpus score, the precision improves from
33.9% to 43.0%. This result supports the effec-
tiveness of the approach of validating translation
candidates using a target language corpus.
As can be seen from these results for the whole
set YS , the correct rate of the scoring function ?I?
that directly uses the web search engine in the cal-
culation of its corpus score is higher than those
of other scoring functions that use the collected
domain/topic-specific corpus. This is because,
for the whole set YS , the rate of including cor-
rect translation within the collected domain/topic-
specific corpus is 72% on the average, which is
not very high. On the other hand, the results of the
column ?gene.-exist? show that if the correct trans-
lation does exist in the corpus, most of the scor-
ing functions other than ?I? can achieve precisions
higher than that of the scoring function ?I?. This
result supports the effectiveness of the approach
of collecting a domain/topic-specific corpus from
the Web in advance and then validating generated
translation candidates against this corpus.
4.3 Evaluation of combining two scoring
functions based on their agreement
The result of evaluating the method that combines
two scoring functions based on their agreement is
shown in Table 5. This result indicates that com-
binations of scoring functions with ?off-line?/?on-
16
Table 3: Number of Translation Pairs for Evaluation (S=English)
dictionaries categories |Y
S
| |X
U
S
| corpus size C(S)
Electromagnetics 33 36 28MB 85%
McGraw-Hill Electrical engineering 45 34 21MB 71%
Optics 31 42 37MB 65%
Iwanami Programming language 29 37 34MB 93%Programming 29 29 33MB 97%
Dictionary of (Computer) 100 91 67MB 51%Computer
Anatomical Terms 100 91 73MB 86%
Dictionary of Disease 100 91 83MB 77%
250,000 Chemicals and Drugs 100 94 54MB 60%
medical terms Physical Science and Statistics 100 88 56MB 68%
Total 667 633 482MB 72%
McGraw-Hill : Dictionary of Scientific and Technical Terms
Iwanami : Encyclopedic Dictionary of Computer Science
C(S) : for Y
S
, the rate of including correct translations within the collected domain/topic-specific corpus
Table 4: Result of Evaluating single Scoring Functions
the whole set Y
S
(667 terms?100%) generatable (458 terms?69%) gene.-exist (333 terms?50%)
ID top 1 top 10 top 1 top 10 top 1 top 10
A 43.8% 52.9% 63.8% 77.1% 82.0% 98.5%
B 42.9% 50.7% 62.4% 73.8% 83.8% 99.4%
C 43.0% 58.0% 62.7% 84.5% 75.1% 94.6%
D 43.0% 47.4% 62.7% 69.0% 85.9% 94.6%
E 33.9% 57.3% 49.3% 83.4% 51.1% 84.1%
F 40.2% 47.4% 58.5% 69.0% 80.2% 94.6%
G 39.1% 46.8% 57.0% 68.1% 78.1% 93.4%
H 43.8% 57.3% 63.8% 83.4% 73.6% 84.1%
I 49.8% 57.3% 72.5% 83.4% 74.8% 84.1%
Table 5: Result of combining two scoring func-
tions based on their agreement
corpus combination precision recall F
?=1
A & I 88.0% 27.6% 0.420
off-line/ D & I 86.0% 29.5% 0.440
on-line F & I 85.1% 29.1% 0.434
H & I 58.7% 37.5% 0.457
A & H 86.0% 30.4% 0.450
F & H 80.6% 33.7% 0.476
off-line/ D & H 80.4% 32.7% 0.465
off-line A & D 79.0% 32.1% 0.456
A & F 74.6% 33.0% 0.457
D & F 68.2% 35.7% 0.469
line? corpus tend to achieve higher precisions than
those with ?off-line?/?off-line? corpus. This result
also shows that it is quite possible to achieve high
precisions even by combining scoring functions
with ?off-line?/?off-line? corpus (the pair ?A? and
?H?). Here, the two scoring functions ?A? and ?H?
are the one with frequency-based scoring func-
tions and that with probability-based scoring func-
tions, and hence, have quite different nature in the
design of their scoring functions.
5 Related Works
As a related work, (Fujii and Ishikawa, 2001) pro-
posed a technique for compositional estimation of
bilingual term correspondences for the purpose of
cross-language information retrieval. One of the
major differences between the technique of (Fu-
jii and Ishikawa, 2001) and the one proposed in
this paper is that in (Fujii and Ishikawa, 2001), in-
stead of a domain/topic-specific corpus, they use a
corpus containing the collection of technical pa-
pers, each of which is published by one of the
65 Japanese associations for various technical do-
mains. Another significant difference is that in
(Fujii and Ishikawa, 2001), they evaluate only the
performance of the cross-language information re-
trieval and not that of translation estimation.
(Cao and Li, 2002) also proposed a method
of compositional translation estimation for com-
pounds. In the method of (Cao and Li, 2002), the
translation candidates of a term are composition-
ally generated by concatenating the translation of
the constituents of the term and are validated di-
rectly through the search engine. In this paper,
we evaluate the approach proposed in (Cao and
Li, 2002) by introducing a total scoring function
17
that is based on validating translation candidates
directly through the search engine.
6 Conclusion
This paper studied issues related to the compila-
tion a bilingual lexicon for technical terms. In
the task of estimating bilingual term correspon-
dences of technical terms, it is usually rather dif-
ficult to find an existing corpus for the domain
of such technical terms. In this paper, we adopt
an approach of collecting a corpus for the do-
main of such technical terms from the Web. As
a method of translation estimation for technical
terms, we employed a compositional translation
estimation technique. This paper focused on quan-
titatively comparing variations of the components
in the scoring functions of compositional transla-
tion estimation. Through experimental evaluation,
we showed that the domain/topic specific corpus
contributes to improving the performance of the
compositional translation estimation.
Future work includes complementally integrat-
ing the proposed framework of compositional
translation estimation using the Web with other
translation estimation techniques. One of them is
that based on collecting partially bilingual texts
through the search engine (Nagata and others,
2001; Huang et al, 2005). Another technique
which seems to be useful is that of transliteration
of names (Knight and Graehl, 1998; Oh and Choi,
2005).
References
Y. Cao and H. Li. 2002. Base noun phrase translation using
Web data and the EM algorithm. In Proc. 19th COLING,
pages 127?133.
A. Fujii and T. Ishikawa. 2001. Japanese/english cross-
language information retrieval: Exploration of query
translation and transliteration. Computers and the Hu-
manities, 35(4):389?420.
P. Fung and L. Y. Yee. 1998. An IR approach for translating
new words from nonparallel, comparable texts. In Proc.
17th COLING and 36th ACL, pages 414?420.
F. Huang, Y. Zhang, and S. Vogel. 2005. Mining key phrase
translations from web corpora. In Proc. HLT/EMNLP,
pages 483?490.
K. Knight and J. Graehl. 1998. Machine transliteration.
Computational Linguistics, 24(4):599?612.
Y. Matsumoto and T. Utsuro. 2000. Lexical knowledge ac-
quisition. In R. Dale, H. Moisl, and H. Somers, editors,
Handbook of Natural Language Processing, chapter 24,
pages 563?610. Marcel Dekker Inc.
M. Nagata et al 2001. Using the Web as a bilingual dictio-
nary. In Proc. ACL-2001 Workshop on Data-driven Meth-
ods in Machine Translation, pages 95?102.
J. Oh and K. Choi. 2005. Automatic extraction of english-
korean translations for constituents of technical terms. In
Proc. 2nd IJCNLP, pages 450?461.
R. Rapp. 1999. Automatic identification of word translations
from unrelated English and German corpora. In Proc.
37th ACL, pages 519?526.
S. Sato and Y. Sasaki. 2003. Automatic collection of related
terms from the web. In Proc. 41st ACL, pages 121?124.
T. Tanaka and T. Baldwin. 2003. Translation selection for
japanese-english noun-noun compounds. In Proc. Ma-
chine Translation Summit IX, pages 378?85.
M. Tonoike, M. Kida, T. Takagi, Y. Sasaki, T. Utsuro, and
S. Sato. 2005. Effect of domain-specific corpus in com-
positional translation estimation for technical terms. In
Proc. 2nd IJCNLP, Companion Volume, pages 116?121.
18
Chunking Japanese Compound Functional Expressions
by Machine Learning
Masatoshi Tsuchiya? and Takao Shime? and Toshihiro Takagi?
Takehito Utsuro?? and Kiyotaka Uchimoto?? and Suguru Matsuyoshi?
Satoshi Sato?? and Seiichi Nakagawa??
?Computer Center / ??Department of Information and Computer Sciences,
Toyohashi University of Technology, Tenpaku-cho, Toyohashi, 441?8580, JAPAN
?Graduate School of Informatics, Kyoto University, Sakyo-ku, Kyoto, 606?8501, JAPAN
??Graduate School of Systems and Information Engineering, University of Tsukuba,
1-1-1, Tennodai, Tsukuba, 305-8573, JAPAN
??National Institute of Information and Communications Technology,
3?5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619?0289 JAPAN
??Graduate School of Engineering, Nagoya University,
Furo-cho, Chikusa-ku, Nagoya, 464?8603, JAPAN
Abstract
The Japanese language has various types
of compound functional expressions,
which are very important for recogniz-
ing the syntactic structures of Japanese
sentences and for understanding their
semantic contents. In this paper, we
formalize the task of identifying Japanese
compound functional expressions in a
text as a chunking problem. We apply a
machine learning technique to this task,
where we employ that of Support Vector
Machines (SVMs). We show that the pro-
posed method significantly outperforms
existing Japanese text processing tools.
1 Introduction
As in the case of other languages, the Japanese
language has various types of functional words
such as post-positional particles and auxiliary
verbs. In addition to those functional words,
the Japanese language has much more compound
functional expressions which consist of more than
one words including both content words and func-
tional words. Those single functional words as
well as compound functional expressions are very
important for recognizing the syntactic structures
of Japanese sentences and for understanding their
semantic contents. Recognition and understanding
of them are also very important for various kinds
of NLP applications such as dialogue systems, ma-
chine translation, and question answering. How-
ever, recognition and semantic interpretation of
compound functional expressions are especially
difficult because it often happens that one com-
pound expression may have both a literal (in other
words, compositional) content word usage and
a non-literal (in other words, non-compositional)
functional usage.
For example, Table 1 shows two example sen-
tences of a compound expression ?? (ni)???
(tsuite)?, which consists of a post-positional par-
ticle ?? (ni)?, and a conjugated form ????
(tsuite)? of a verb ??? (tsuku)?. In the sentence
(A), the compound expression functions as a case-
marking particle and has a non-compositional
functional meaning ?about?. On the other hand,
in the sentence (B), the expression simply corre-
sponds to a literal concatenation of the usages of
the constituents: the post-positional particle ??
(ni)? and the verb ???? (tsuite)?, and has a
content word meaning ?follow?. Therefore, when
considering machine translation of those Japanese
sentences into English, it is necessary to precisely
judge the usage of the compound expression ??
(ni)??? (tsuite)?, as shown in the English trans-
lation of the two sentences in Table 1.
There exist widely-used Japanese text process-
ing tools, i.e., pairs of a morphological analysis
tool and a subsequent parsing tool, such as JU-
MAN1+ KNP2 and ChaSen3+ CaboCha4. How-
ever, they process those compound expressions
only partially, in that their morphological analy-
sis dictionaries list only limited number of com-
pound expressions. Furthermore, even if certain
expressions are listed in a morphological analysis
1http://www.kc.t.u-tokyo.ac.jp/
nl-resource/juman-e.html
2http://www.kc.t.u-tokyo.ac.jp/
nl-resource/knp-e.html
3http://chasen.naist.jp/hiki/ChaSen/
4http://chasen.org/?taku/software/
cabocha/
25
Table 1: Translation Selection of a Japanese Compound Expression ?? (ni)??? (tsuite)?
? (watashi) ? (ha) ? (kare) ? (ni)??? (tsuite) ??? (hanashita)
(A) (I) (TOP) (he) (about) (talked)
(I talked about him.)
? (watashi) ? (ha) ? (kare) ? (ni) ??? (tsuite) ??? (hashitta)
(B) (I) (TOP) (he) (ACC) (follow) (ran)
(I ran following him.)
Table 2: Classification of Functional Expressions based on Grammatical Function
# of major # of
Grammatical Function Type expressions variants Example
subsequent to predicate 36 67 ????
post-positional / modifying predicate (to-naru-to)
particle subsequent to nominal 45 121 ?????
type / modifying predicate (ni-kakete-ha)
subsequent to predicate, nominal 2 3 ???
/ modifying nominal (to-iu)
auxiliary verb type 42 146 ??? (te-ii)
total 125 337 ?
dictionary, those existing tools often fail in resolv-
ing the ambiguities of their usages, such as those
in Table 1. This is mainly because the frame-
work of those existing tools is not designed so as
to resolve such ambiguities of compound (possi-
bly functional) expressions by carefully consider-
ing the context of those expressions.
Considering such a situation, it is necessary
to develop a tool which properly recognizes and
semantically interprets Japanese compound func-
tional expressions. In this paper, we apply a ma-
chine learning technique to the task of identify-
ing Japanese compound functional expressions in
a text. We formalize this identification task as a
chunking problem. We employ the technique of
Support Vector Machines (SVMs) (Vapnik, 1998)
as the machine learning technique, which has been
successfully applied to various natural language
processing tasks including chunking tasks such
as phrase chunking (Kudo and Matsumoto, 2001)
and named entity chunking (Mayfield et al, 2003).
In the preliminary experimental evaluation, we fo-
cus on 52 expressions that have balanced distribu-
tion of their usages in the newspaper text corpus
and are among the most difficult ones in terms of
their identification in a text. We show that the pro-
posed method significantly outperforms existing
Japanese text processing tools as well as another
tool based on hand-crafted rules. We further show
that, in the proposed SVMs based framework, it is
sufficient to collect and manually annotate about
50 training examples per expression.
2 Japanese Compound Functional
Expressions and their Example
Database
2.1 Japanese Compound Functional
Expressions
There exist several collections which list Japanese
functional expressions and examine their usages.
For example, (Morita and Matsuki, 1989) examine
450 functional expressions and (Group Jamashii,
1998) also lists 965 expressions and their exam-
ple sentences. Compared with those two collec-
tions, Gendaigo Hukugouji Youreishu (National
Language Research Institute, 2001) (henceforth,
denoted as GHY) concentrates on 125 major func-
tional expressions which have non-compositional
usages, as well as their variants5 (337 expressions
in total), and collects example sentences of those
expressions. As a first step of developing a tool for
identifying Japanese compound functional expres-
sions, we start with those 125 major functional ex-
pressions and their variants. In this paper, we take
an approach of regarding each of those variants as
a fixed expression, rather than a semi-fixed expres-
sion or a syntactically-flexible expression (Sag et
al., 2002). Then, we focus on evaluating the ef-
fectiveness of straightforwardly applying a stan-
5For each of those 125 major expressions, the differences
between it and its variants are summarized as below: i) in-
sertion/deletion/alternation of certain particles, ii) alternation
of synonymous words, iii) normal/honorific/conversational
forms, iv) base/adnominal/negative forms.
26
Table 3: Examples of Classifying Functional/Content Usages
Expression Example sentence (English translation) Usage
(1) ???? ????????????? ????
??????
functional
(to-naru-to) (The situation is serious if it is not effec-
tive against this disease.)
(???? (to-naru-to) = if)
(2) ???? ???????????????
???? ????????
content
(to-naru-to) (They think that it will become a require-
ment for him to be the president.)
(????? (to-naru-to)
= that (something) becomes ?)
(3) ????? ???????? ????? ????
??????????
functional
(ni-kakete-ha) (He has a great talent for earning money.) (?????? (ni-kakete-ha)
= for ?)
(4) ????? ???? ????? ???? content
(ni-kakete-ha) (I do not worry about it.)
( (??)??????
((?)-wo-ki-ni-kakete-ha)
= worry about ?)
(5) ??? ??????? ??? ??????
??
functional
(to-iu) (I heard that he is alive.) (???? (to-iu) = that ?)
(6) ??? ????????????? ????? content
(to-iu) (Somebody says ?Please visit us.?.) (???? (to-iu)
= say (that) ?)
(7) ??? ???????????? ??? ? functional
(te-ii) (You may have a break after we finish this
discussion.)
(???? (te-ii) = may ?)
(8) ??? ????????? ??? ? content
(te-ii) (This bag is nice because it is big.) (???? (te-ii)
= nice because ?)
dard chunking technique to the task of identifying
Japanese compound functional expressions.
As in Table 2, according to their grammat-
ical functions, those 337 expressions in total
are roughly classified into post-positional particle
type, and auxiliary verb type. Functional expres-
sions of post-positional particle type are further
classified into three subtypes: i) those subsequent
to a predicate and modifying a predicate, which
mainly function as conjunctive particles and are
used for constructing subordinate clauses, ii) those
subsequent to a nominal, and modifying a predi-
cate, which mainly function as case-marking parti-
cles, iii) those subsequent to a nominal, and modi-
fying a nominal, which mainly function as adnom-
inal particles and are used for constructing adnom-
inal clauses. For each of those types, Table 2 also
shows the number of major expressions as well as
that of their variants listed in GHY, and an exam-
ple expression. Furthermore, Table 3 gives exam-
ple sentences of those example expressions as well
as the description of their usages.
2.2 Issues on Identifying Compound
Functional Expressions in a Text
The task of identifying Japanese compound func-
tional expressions roughly consists of detecting
candidates of compound functional expressions in
a text and of judging the usages of those can-
didate expressions. The class of Japanese com-
pound functional expressions can be regarded as
closed and their number is at most a few thousand.
27
Table 4: Examples of Detecting more than one Candidate Expression
Expression Example sentence (English translation) Usage
(9) ??? ????? ??? ???????? functional
(to-iu) (That?s why a match is not so easy.) (NP1??? (to-iu)NP2
= NP
2
called as NP
1
)
(10) ?????? ??? ?????? ???????? functional
(to-iu-mono-no) (Although he won, the score is bad.)
(???????
(to-iu-mono-no)
= although ?)
Therefore, it is easy to enumerate all the com-
pound functional expressions and their morpheme
sequences. Then, in the process of detecting can-
didates of compound functional expressions in a
text, the text are matched against the morpheme
sequences of the compound functional expressions
considered.
Here, most of the 125 major functional expres-
sions we consider in this paper are compound ex-
pressions which consist of one or more content
words as well as functional words. As we intro-
duced with the examples of Table 1, it is often
the case that they have both a compositional con-
tent word usage as well as a non-compositional
functional usage. For example, in Table 3, the
expression ????? (to-naru-to)? in the sen-
tence (2) has the meaning ? that (something) be-
comes ??, which corresponds to a literal concate-
nation of the usages of the constituents: the post-
positional particle ???, the verb ????, and the
post-positional particle ???, and can be regarded
as a content word usage. On the other hand, in
the case of the sentence (1), the expression ???
?? (to-naru-to)? has a non-compositional func-
tional meaning ?if?. Based on this discussion, we
classify the usages of those expressions into two
classes: functional and content. Here, functional
usages include both non-compositional and com-
positional functional usages, although most of the
functional usages of those 125 major expressions
can be regarded as non-compositional. On the
other hand, content usages include compositional
content word usages only.
More practically, in the process of detecting
candidates of compound functional expressions in
a text, it can happen that more than one can-
didate expression is detected. For example, in
Table 4, both of the candidate compound func-
tional expressions ???? (to-iu)? and ????
??? (to-iu-mono-no)? are detected in the sen-
tence (9). This is because the sequence of the two
morphemes ?? (to)? and ??? (iu)? constituting
the candidate expression ???? (to-iu)? is a sub-
sequence of the four morphemes constituting the
candidate expression ??????? (to-iu-mono-
no)? as below:
Morpheme sequence
? (to) ?? (iu) ?? (mono) ? (no)
Candidate expression??? (to-iu)
? (to) ?? (iu) ?? (mono) ? (no)
Candidate expression?????? (to-iu-mono-no)
? (to) ?? (iu) ?? (mono) ? (no)
This is also the case with the sentence (10).
Here, however, as indicated in Table 4, the sen-
tence (9) is an example of the functional usage of
the compound functional expression ???? (to-
iu)?, where the sequence of the two morphemes ?
? (to)? and ??? (iu)? should be identified and
chunked into a compound functional expression.
On the other hand, the sentence (10) is an ex-
ample of the functional usage of the compound
functional expression ??????? (to-iu-mono-
no)?, where the sequence of the four morphemes ?
? (to)?, ??? (iu)?, ??? (mono)?, and ?? (no)?
should be identified and chunked into a compound
functional expression. Actually, in the result of
our preliminary corpus study, at least in about 20%
of the occurrences of Japanese compound func-
tional expressions, more than one candidate ex-
pression can be detected. This result indicates that
it is necessary to consider more than one candidate
expression in the task of identifying a Japanese
compound functional expression, and also in the
task of classifying the functional/content usage of
a candidate expression. Thus, in this paper, based
on this observation, we formalize the task of iden-
tifying Japanese compound functional expressions
as a chunking problem, rather than a classification
problem.
28
Table 5: Number of Sentences collected from
1995 Mainichi Newspaper Texts (for 337 Expres-
sions)
# of expressions
50 ? # of sentences 187 (55%)
0 < # of sentences < 50 117 (35%)
# of sentences = 0 33 (10%)
2.3 Developing an Example Database
We developed an example database of Japanese
compound functional expressions, which is used
for training/testing a chunker of Japanese com-
pound functional expressions (Tsuchiya et al,
2005). The corpus from which we collect example
sentences is 1995 Mainichi newspaper text corpus
(1,294,794 sentences, 47,355,330 bytes). For each
of the 337 expressions, 50 sentences are collected
and chunk labels are annotated according to the
following procedure.
1. The expression is morphologically analyzed
by ChaSen, and its morpheme sequence6 is
obtained.
2. The corpus is morphologically analyzed by
ChaSen, and 50 sentences which include the
morpheme sequence of the expression are
collected.
3. For each sentence, every occurrence of the
337 expressions is annotated with one of the
usages functional/content by an annotator7.
Table 5 classifies the 337 expressions accord-
ing to the number of sentences collected from the
1995 Mainichi newspaper text corpus. For more
than half of the 337 expressions, more than 50 sen-
tences are collected, although about 10% of the
377 expressions do not appear in the whole cor-
pus. Out of those 187 expressions with more than
50 sentences, 52 are those with balanced distribu-
tion of the functional/content usages in the news-
paper text corpus. Those 52 expressions can be re-
garded as among the most difficult ones in the task
of identifying and classifying functional/content
6For those expressions whose constituent has conjugation
and the conjugated form also has the same usage as the ex-
pression with the original form, the morpheme sequence is
expanded so that the expanded morpheme sequences include
those with conjugated forms.
7For the most frequent 184 expressions, on the average,
the agreement rate between two human annotators is 0.93 and
the Kappa value is 0.73, which means allowing tentative con-
clusions to be drawn (Carletta, 1996; Ng et al, 1999). For
65% of the 184 expressions, the Kappa value is above 0.8,
which means good reliability.
usages. Thus, this paper focuses on those 52 ex-
pressions in the training/testing of chunking com-
pound functional expressions. We extract 2,600
sentences (= 52 expressions ? 50 sentences) from
the whole example database and use them for
training/testing the chunker. The number of the
morphemes for the 2,600 sentences is 92,899. We
ignore the chunk labels for the expressions other
than the 52 expressions, resulting in 2,482/701
chunk labels for the functional/content usages, re-
spectively.
3 Chunking Japanese Compound
Functional Expressions with SVMs
3.1 Support Vector Machines
The principle idea of SVMs is to find a separate
hyperplane that maximizes the margin between
two classes (Vapnik, 1998). If the classes are not
separated by a hyperplane in the original input
space, the samples are transformed in a higher di-
mensional features space.
Giving x is the context (a set of features) of
an input example; xi and yi(i = 1, ..., l, xi ?
Rn, yi?{1,?1}) indicate the context of the train-
ing data and its category, respectively; The deci-
sion function f in SVM framework is defined as:
f(x) = sgn
( l
?
i=1
?iyiK(xi,x) + b
)
(1)
where K is a kernel function, b ? R is a thresh-
old, and ?i are weights. Besides, the weights ?i
satisfy the following constraints:
0 ? ?i ? C (i = 1, ..., l) (2)
?l
i=1 ?iyi = 0 (3)
where C is a misclassification cost. The xi with
non-zero ?i are called support vectors. To train
an SVM is to find the ?i and the b by solving the
optimization problem; maximizing the following
under the constraints of (2) and (3):
L(?) =
l
?
i=1
?i?
1
2
l
?
i,j=1
?i?jyiyjK(x
i
,x
j
) (4)
The kernel function K is used to transform the
samples in a higher dimensional features space.
Among many kinds of kernel functions available,
we focus on the d-th polynomial kernel:
K(x,y) = (x ? y + 1)d (5)
29
Through experimental evaluation on chunking
Japanese compound functional expressions, we
compared polynomial kernels with d = 1, 2, and
3. Kernels with d = 2 and 3 perform best, while
the kernel with d = 3 requires much more compu-
tational cost than that with d = 2. Thus, through-
out the paper, we show results with the quadratic
kernel (d = 2).
3.2 Chunking with SVMs
This section describes details of formalizing the
chunking task using SVMs. In this paper, we use
an SVMs-based chunking tool YamCha8 (Kudo
and Matsumoto, 2001). In the SVMs-based
chunking framework, SVMs are used as classi-
fiers for assigning labels for representing chunks
to each token. In our task of chunking Japanese
compound functional expressions, each sentence
is represented as a sequence of morphemes, where
a morpheme is regarded as a token.
3.2.1 Chunk Representation
For representing proper chunks, we employ
IOB2 representation, one of those which have
been studied well in various chunking tasks of nat-
ural language processing (Tjong Kim Sang, 1999;
Kudo and Matsumoto, 2001). This method uses
the following set of three labels for representing
proper chunks.
I Current token is a middle or the end of a
chunk consisting of more than one token.
O Current token is outside of any chunk.
B Current token is the beginning of a chunk.
As we described in section 2.2, given a candi-
date expression, we classify the usages of the ex-
pression into two classes: functional and content.
Accordingly, we distinguish the chunks of the two
types: the functional type chunk and the content
type chunk. In total, we have the following five la-
bels for representing those chunks: B-functional,
I-functional, B-content, I-content, and O. Ta-
ble 6 gives examples of those chunk labels rep-
resenting chunks.
Finally, as for exending SVMs to multi-class
classifiers, we experimentally compare the pair-
wise method and the one vs. rest method, where
the pairwise method slightly outperformed the one
vs. rest method. Throughout the paper, we show
results with the pairwise method.
8http://chasen.org/?taku/software/
yamcha/
3.2.2 Features
For the feature sets for training/testing of
SVMs, we use the information available in the sur-
rounding context, such as the morphemes, their
parts-of-speech tags, as well as the chunk labels.
More precisely, suppose that we identify the chunk
label ci for the i-th morpheme:
?? Parsing Direction ??
Morpheme m
i?2
m
i?1
m
i
m
i+1
m
i+2
Feature set F
i?2
F
i?1
F
i
F
i+1
F
i+2
at a position
Chunk label c
i?2
c
i?1
c
i
Here, mi is the morpheme appearing at i-th po-
sition, Fi is the feature set at i-th position, and ci
is the chunk label for i-th morpheme. Roughly
speaking, when identifying the chunk label ci for
the i-th morpheme, we use the feature sets Fi?2,
Fi?1, Fi, Fi+1, Fi+2 at the positions i ? 2, i ? 1,
i, i + 1, i + 2, as well as the preceding two chunk
labels ci?2 and ci?1.
The detailed definition of the feature set Fi at i-
th position is given below. The feature set Fi is de-
fined as a tuple of the morpheme feature MF (mi)
of the i-th morpheme mi, the chunk candidate fea-
ture CF (i) at i-th position, and the chunk context
feature OF (i) at i-th position.
Fi = ? MF (mi), CF (i), OF (i) ?
The morpheme feature MF (mi) consists of the
lexical form, part-of-speech, conjugation type and
form, base form, and pronunciation of mi.
The chunk candidate feature CF (i) and the
chunk context feature OF (i) are defined consid-
ering the candidate compound functional expres-
sion, which is a sequence of morphemes includ-
ing the morpheme mi at the current position i. As
we described in section 2, the class of Japanese
compound functional expressions can be regarded
as closed and their number is at most a few thou-
sand. Therefore, it is easy to enumerate all the
compound functional expressions and their mor-
pheme sequences. Chunk labels other than O
should be assigned to a morpheme only when it
constitutes at least one of those enumerated com-
pound functional expressions. Suppose that a se-
quence of morphemes mj . . . mi . . . mk including
mi at the current position i constitutes a candidate
functional expression E as below:
m
j?2
m
j?1
m
j
. . . m
i
. . . m
k
m
k+1
m
k+2
candidate E of
a compound
functional expression
where the morphemes mj?2, mj?1, mk+1, and
mk+2 are at immediate left/right contexts of E.
Then, the chunk candidate feature CF (i) at i-th
position is defined as a tuple of the number of mor-
phemes constituting E and the position of mi in
E. The chunk context feature OF (i) at i-th posi-
tion is defined as a tuple of the morpheme features
30
Table 6: Examples of Chunk Representation and Chunk Candidate/Context Features
(a) Sentence (7) of Table 3
(English Chunk candidate Chunk context
Morpheme translation) Chunk label feature feature
?? (kono) (this) O ? ?
?? (giron) (discussion) O ? ?
? (ga) (NOM) O ? ?
???(owatt) (finish) O ? ?
?? (tara) (after) O ? ?
?? (kyuukei) (break) O ? ?
? (shi) (have) O ? ?
? (te) (may) B-functional ?2, 1? ? MF (?? (kyuukei)), ?, MF (? (shi)), ?,
?? (ii) I-functional ?2, 2? MF (?(period)), ?, ?, ? ?
?(period) (period) O ? ?
(b) Sentence (8) of Table 3
(English Chunk candidate Chunk context
Morpheme translation) Chunk label feature feature
?? (kono) (this) O ? ?
??? (bag) (discussion) O ? ?
? (ha) (TOP) O ? ?
??? (ookiku) (big) O ? ?
? (te) (because) B-content ?2, 1? ? MF (? (ha)), ?, MF (??? (ookiku)), ?,
?? (ii) (nice) I-content ?2, 2? MF (?(period)), ?, ?, ? ?
?(period) (period) O ? ?
as well as the chunk candidate features at immedi-
ate left/right contexts of E.
CF (i) = ? length of E, position of m
i
in E ?
OF (i) = ? MF (m
j?2
), CF (j ? 2),
MF (m
j?1
), CF (j ? 1),
MF (m
k+1
), CF (k + 1),
MF (m
k+2
), CF (k + 2) ?
Table 6 gives examples of chunk candidate fea-
tures and chunk context features
It can happen that the morpheme at the cur-
rent position i constitutes more than one candidate
compound functional expression. For example,
in the example below, the morpheme sequences
mi?1mimi+1, mi?1mi, and mimi+1mi+2 consti-
tute candidate expressions E
1
, E
2
, and E
3
, respec-
tively.
Morpheme sequence m
i?1
m
i
m
i+1
m
i+2
Candidate E
1
m
i?1
m
i
m
i+1
Candidate E
2
m
i?1
m
i
Candidate E
3
m
i
m
i+1
m
i+2
In such cases, we prefer the one starting with the
leftmost morpheme. If more than one candidate
expression starts with the leftmost morpheme, we
prefer the longest one. In the example above, we
prefer the candidate E
1
and construct the chunk
candidate features and chunk context features con-
sidering E
1
only.
4 Experimental Evaluation
The detail of the data set we use in the experimen-
tal evaluation was presented in section 2.3. As we
show in Table 7, performance of our SVMs-based
chunkers as well as several baselines including ex-
isting Japanese text processing tools is evaluated
in terms of precision/recall/F?=1 of identifying
functional chunks. Performance is evaluated also
in terms of accuracy of classifying detected can-
didate expressions into functional/content chunks.
Among those baselines, ?majority ( = functional)?
always assigns functional usage to the detected
candidate expressions. ?Hand-crafted rules? are
manually created 145 rules each of which has con-
ditions on morphemes constituting a compound
functional expression as well as those at immedi-
ate left/right contexts. Performance of our SVMs-
based chunkers is measured through 10-fold cross
validation.
As shown in Table 7, our SVMs-based chunkers
significantly outperform those baselines both in
F?=1 and classification accuracy9. We also evalu-
ate the effectiveness of each feature set, i.e., the
morpheme feature, the chunk candidate feature,
and the chunk context feature. The results in the
table show that the chunker with the chunk candi-
date feature performs almost best even without the
chunk context feature10.
9Recall of existing Japanese text processing tools is low,
because those tools can process only 50?60% of the whole
52 compound functional expressions, and for the remaining
40?50% expressions, they fail in identifying all of the occur-
rences of functional usages.
10It is also worthwhile to note that training the SVMs-
based chunker with the full set of features requires computa-
tional cost three times as much as training without the chunk
31
Table 7: Evaluation Results (%)
Identifying Acc. of classifying
functional chunks functional/content
Prec. Rec. F?=1 chunks
majority ( = functional) 78.0 100 87.6 78.0
Baselines Juman/KNP 89.2 49.3 63.5 55.8
ChaSen/CaboCha 89.0 45.6 60.3 53.2
hand-crafted rules 90.7 81.6 85.9 79.1
SVM morpheme 88.0 91.0 89.4 86.5
(feature morpheme + chunk-candidate 91.0 93.2 92.1 89.0
set) morpheme + chunk-candidate/context 91.1 93.6 92.3 89.2
Figure 1: Change of F?=1 with Different Number
of Training Instances
For the SVMs-based chunker with the chunk
candidate feature with/without the chunk context
feature, Figure 1 plots the change of F?=1 when
training with different number of labeled chunks
as training instances. With this result, the increase
in F?=1 seems to stop with the maximum num-
ber of training instances, which supports the claim
that it is sufficient to collect and manually annotate
about 50 training examples per expression.
5 Concluding Remarks
The Japanese language has various types of com-
pound functional expressions, which are very im-
portant for recognizing the syntactic structures of
Japanese sentences and for understanding their se-
mantic contents. In this paper, we formalized
the task of identifying Japanese compound func-
tional expressions in a text as a chunking prob-
lem. We applied a machine learning technique
to this task, where we employed that of Sup-
port Vector Machines (SVMs). We showed that
the proposed method significantly outperforms ex-
isting Japanese text processing tools. The pro-
context feature.
posed framework has advantages over an approach
based on manually created rules such as the one in
(Shudo et al, 2004), in that it requires human cost
to manually create and maintain those rules. On
the other hand, in our framework based on the ma-
chine learning technique, it is sufficient to collect
and manually annotate about 50 training examples
per expression.
References
J. Carletta. 1996. Assessing agreement on classification
tasks: the Kappa statistic. Computational Linguistics,
22(2):249?254.
Group Jamashii, editor. 1998. Nihongo Bunkei Jiten.
Kuroshio Publisher. (in Japanese).
T. Kudo and Y. Matsumoto. 2001. Chunking with support
vector machines. In Proc. 2nd NAACL, pages 192?199.
J. Mayfield, P. McNamee, and C. Piatko. 2003. Named entity
recognition using hundreds of thousands of features. In
Proc. 7th CoNLL, pages 184?187.
Y. Morita and M. Matsuki. 1989. Nihongo Hyougen Bunkei,
volume 5 of NAFL Sensho. ALC. (in Japanese).
National Language Research Institute. 2001. Gendaigo
Hukugouji Youreishu. (in Japanese).
H. T. Ng, C. Y. Lim, and S. K. Foo. 1999. A case study on
inter-annotator agreement for word sense disambiguation.
In Proc. ACL SIGLEXWorkshop on Standardizing Lexical
Resources, pages 9?13.
I. Sag, T. Baldwin, F. Bond, A. Copestake, and D. Flickinger.
2002. Multiword expressions: A pain in the neck for NLP.
In Proc. 3rd CICLING, pages 1?15.
K. Shudo, T. Tanabe, M. Takahashi, and K. Yoshimura. 2004.
MWEs as non-propositional content indicators. In Proc.
2nd ACL Workshop on Multiword Expressions: Integrat-
ing Processing, pages 32?39.
E. Tjong Kim Sang. 1999. Representing text chunks. In
Proc. 9th EACL, pages 173?179.
M. Tsuchiya, T. Utsuro, S. Matsuyoshi, S. Sato, and S. Nak-
agawa. 2005. A corpus for classifying usages of Japanese
compound functional expressions. In Proc. PACLING,
pages 345?350.
V. N. Vapnik. 1998. Statistical Learning Theory. Wiley-
Interscience.
32
