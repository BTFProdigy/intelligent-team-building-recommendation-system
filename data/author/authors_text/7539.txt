Extracting semantic lusters from the alignment of definitions 
Gerardo SIERRA 
Institute de Ingenierfa, UNAM 
Apdo. Postal 70-472 
Mdxico 04510, D.F. 
gsm @pumas.iingen.unanunx 
John McNAUGHT 
Department of Language Engineering, UMIST 
PO Box 88 
Manchester M60 IQD, UK 
John.McNaught @unlist.ac.uk 
Abstract 
Through tile alignment of definitions fronl 
two or more dilTerent sources, it is 
possible to retrieve pairs of words that can 
be used indistinguishably in the same 
sentence without changing tile meaning of 
the concept. As lexicographic work 
exploits common defining schemes, such 
as genus and dilTerentia, a concept is 
simihu'ly defined by different dictionaries. 
The dilTerence in words used between two 
lexicographic sources lets us extend lhe 
lexical knowledge base, so that clustering 
is available through merging two or more 
dictionaries into a single database and 
then using an approlwiate alignment 
techlaique. Since aligmnent starts from thc 
same entry of two dictionaries, clustering 
is l~lster than any other technique. 
Tile algorithm introduced here is analogy- 
based, and starts from calculating the 
Levenshtein distance, which is a variation 
o1' the edit distance, and allows us to align 
the definitions. As a measure of similarity, 
the concept el' longest collocation couple 
is introduced, which is the basis of 
clustering similar words. The process 
iterates, replacing similar pairs of words 
in tile definitions until no new clusters are 
found. 
Introduction 
Clustering methods to identify semantically 
similar words are usually divided in relation- 
based and distribution-based approaches 
\[Hirawaka, Xu and Haase 1996\]. Relation-based 
clustering methods rely on the relations in a 
semantic network or ontology to judge the 
similarity between two concepts, either by 
measuring the shortest length that connects two 
concepts in the hierarchical net \[Agirrc and 
Rigau 199611, oi" by comparing tile information 
content shared by the members unde," tile same 
cluster \[Morris and Hirst 1991, Resnik 1997\]. 
ltowever, even although these ontologies 
describe a huge number of members for a 
cluster, few words of a category may be 
interchangeable in the same context and then 
used as members of tile same cluster. This 
means that not all words in a category arc 
necessary. 
Conversely, distribution-based clustering 
methods depend on pure statistical analysis of 
the lexical occurrences ill running texts. A relier 
drawback is that distribution-based methods 
require us to process a large amount of data in 
order to get more reliable results. Moreover, tile 
use el hu'ge corpora is not always practical, due 
to economic, time or capabilities factors. Gao 
11199711 states that tile problem for statistical 
alignment algorilhms, such as those based on tile 
facts described by Gale and Church \[1991\], is
the low frequency of words that occur in parallel 
corpora. The consequences for lacking hu'ge 
corpora include results based on low-frequency 
words, which are quite unrepresentative for 
clustering. 
From a methodological point of view, there is, in 
addition to the above two approaches, a little 
known approach called the analogy-based 
approach. This employs an inferential process 
and is used ill computatkmal linguistics and 
artificial intelligence as an alternative to current 
rule-based linguistic models. 
1 Analogy-based clustering 
Jones \[11996\] suggests corpus alignment as a 
feasible analogy-based approach, ill order to 
align two sentences in tile same language, 
Waterman \[1996\] uses a technique for 
measuring tile similarity between lexical strings, 
named edit distance. This matches tile words of 
795 
two sentences in linear order and determines 
their correspondence. For example, given the 
followiug two definitions for alkalimeter: 
? An apparatus for determining the 
concentration o1' alkalis in solution \[CED\] 
? An instrument for ascertaining the amount 
of alkali in a solution \[OED2\] 
Alignment may identil'y which words in these 
definitions are equivalents of each other. A 
quick observation of the sentences lets us 
identify three pairs of words: (apparatus, 
instrument), (determining, ascertaining) and 
(concentration, amount). 
The appeal of using definitions as corpora for 
alignment is l'ounded on two reasons. Firstly, 
dictionaries contain all necessary information as 
a knowledge base for extracting keywords 
\[Boguraev and Pustejovsky 1996\]. Secondly, it 
is much easier to find the sentences for aligning, 
since definitions are distinguished by entry 
headword. 
Taking into account Waterman's tudies, we 
propose an analogy-based method to identify 
automatically semantic lusters. The difference 
in words used between two or more 
lexicographic definitions enables us to infer 
paradigms by merging the dictionary definitions 
into a single database and then using our own 
alignment technique. 
2 Clustering algorithm 
Tile overall structure of the clustering algorithn\] 
is shown in figure l, and its description is given 
below. 
2.1 Processing definitions 
Our algorithms are used in an overall system 
called "onomasiological search system" (OSS), 
whose aim is to allow the user to find terms by 
giving a description o1' a concept. Lexicographic 
and terminological definitions constitute the 
main lexical resources. Our algorithms cluster 
words that are used in the same context, thus 
operate on pairs of definitions for a same entry 
word, drawn fi'om two different dictionaries. If 
dictionary 1 does not have an entry word that 
exists in dictionary J, then this entry word is 
omitted from consideration. In order to balance 
the number of strings when an entry word in the 
dictionary 1 has two or more senses, the entry 
word in dictionary J is repeated as many times 
as necessary to equal the number of senses of 
dictionary I. We thus derive two files I and J 
containing an equal number of strings S~ and S 2, 
respectively. Each string consists of an entry 
term followed by its definition, the definition 
giving only one sense of the entry term. For each 
string S 1 there is a string S 2. 
Our experiments focus on 314 terms for 
measuring instruments extracted with their 
definitions from CED \[199411 and OED2 \[1994\], 
resulting in 387 strings from each dictionary. 
match S t and S 2 
/ S  1 and S 2 
/ definitions 
t 
processing 
H 
/ 
/ 
/ 
> 
ste ln l l ler  
calculate Levenshtein 
distance H align S~ and S 2 
I 
"'-I J replace strings ~ identify bindings 
<c lusters  ),~__~ cluster bindings 
Figure 1 Clustering algorithm 
stoplist \[ 
,L 
I find Ice @0 
796 
The strings consist ()1' the entry term and the 
definition, so that etymology, part of speech, 
inl'lected t'orms ol' the cntry term, examples and 
other inl'ormation were deleted. Subject-field 
labels, such as 'astronomy' and 'meteorology', 
were preserved, either in full or slightly 
abbreviated, as they are helpful to resolve which 
sense o1' a word to choose, and usually constitute 
a l'undamental property of the concept. 
It should be noted that none of the 387 strings 
suffered any additional transformation, apart 
l'rom a few cases in order to complete a 
del'inition when it had been broken in two pm'ts 
by the dictionary editor, such as when a core 
meaning appears just once at the beginning of 
several subsequent senses. Althongh some 
abbreviations ('U.S.A.'), initials of proper 
names ('C.T.R. Wilson') and possessives ( :un s 
rays') will come out as two or more words al'ter 
deleting punctuation marks and therefore can 
alter the efficiency el' the algorithm, they were 
preserved to observe their effect. 
2.2 Aligning definitions 
In order to compare two strings of woMs, we use 
the Levenshtein distance \[Levenshtein 196611, a
similar method to the edit distance. This method 
measures the edit transl'ormations that change 
one string into other. The Levenshtein distance 
arrangcs the strings in a matrix, with the words 
el' Sj heading the columns and those of S 2 
heading the rows. A null word is inserted at the 
beginning of each string S~ and S 2, in position 
i=0,.j=0. The matrix is filled with the costs of 
insertion, deletion and substitution using the 
l'ollowing formtfla ? 
D(ai,  b i_, ) + Di,,. ,, (bi) 
D(a i ,b j )=  rain D(ai_j,bi)+Di,,.,.(ai) 
D(aH,  b /< ) + D ,I, (ai, b j) 
Where the cost of insertion. D~,,.,(), is 1. and the 
cost of substitution. D,,i,(), is 0 or 1, according to 
whether a~ and bj differ or not. 
Our experimental results have shown that the 
application of the Levenshtein distance using 
stem forms gives better matches than nsing full 
forms. Therefore, we shall fill the matrix with 
the cost for the stem l'orms, although the strings 
preserve the fnll forms both l'or the following 
steps and in the output table. We used the 
stmnming algorithm or' Porter \[1980\], which 
removes endings l'ronl words. 
Building on the Levenshtein distance, Wagner 
and Fisher \[1974\] propose a dynamic 
t~rogramming method to align the elements of 
two strings. Their procedure to return the 
ordered pairs of the alignment starts with the last 
cell of the matrix with cost\[n\]\[m\] and works 
back until either i or j equals 0, according to 
which o1' its neighbours a cell was derived l'rom. 
I1' it is derived either from the previous 
horizontal or vertical cell (\[i-l\]\[j\] or \[i\]lj-l\] 
respectively) then the difference in cost is.just 1, 
otherwise it is derived l'rom the diagonal. 
2.3 Extracting triplets 
The alignment gives us a list of triplets formed 
by ~.ll, J,l~, cost\[i\]\[j\]), in decreasing order 
according to cost\[i\]\[jl, where./.)' I, and ./\]~ arc full 
forms from the strings S~ and S e, respectively. 
There are three possible pairings of words: 
"Equal couple" is defined as the pair (1-\[i, .ffj) of 
full forms such that the corresponding stem 
forms are equal (,s.'/' I = 4)" 
"Matched couple" is a pair (/.)~i, .Oj) such that .sf~ 
# .ff~. This couple represents a potential pair ot' 
similar words. 
"Null couple" is a pair (.g, .g) such that ,s:/I ()r 4 
is missing. 
With respect to the Levcnshtein distance, the 
equal couple means these words do not need any 
change to make both equal, while for the 
matched couple we shall replace one word with 
the other progressively, and for the null couple 
we must either insert one word into the given 
string or delete it from the given string. 
The purpose of clustering is to match different 
pairs of words (matched couples), thus neither 
pairs of equal words (equal couples) nor pairs 
with a null word (null couples) are relevant. 
2.4 Measuring similarity 
As a measure of the similarity between a 
matched couple, we quantify the surrounding 
equal couples above and below it. This concept 
is similar to the "longest common subsequence" 
of two strings suggested by Wagner and Fisher 
\[1974\], which is del'ined as the common 
subsequence of two strings having maximal 
length, although in our case both strings differ 
by the single matched couple. By analogy, we 
use longest collocation couple, henceforth 
797 
abbreviated lcc, since we refer to couples instead 
of a single string. Besides, the word 
"collocation" is more representative for a pair o1' 
words and their neighbourhood, being the core 
of two longest common subsequences. We 
define longest collocation couple as the maximal 
sequence of pairs of words formed by equal 
couples surrounding a matched couple. 
Given the alignment of the strings S~ and S 2 
consisting of a list of triplets formed by (ffi., ff ,  
cost\[ill/\]), in decreasing order according to 
cost\[i\]\[j\], where.ff I, and fl~ are, respectively, full 
fomas l'rom S~ and $2, the lcc is the longest 
consecutive sequence of triplets (~i., f~, 
cost\[i\]\[j\]) formed by one matched couple, such 
that it meets 3 conditions: 
? The cost dilTerence between the first triplet 
and the last triplet is 1. 
? There is no null couple. 
? The matched couple is neither the first nor 
the last triplet. 
By these conditions, only the matched couple 
becomes the core el' a Icc: we constrain a 
matched couple 1o be between two or more 
equal couples, and eliminate the possibility that 
the matched couple appears at the beginning or 
end o1' a phrase. 
As a result, we get a new triplet Off, .\[f~, Icco), 
where (If, J\[~) is the matched couple and lcc,a is 
the length of the longest collocation couple. As 
an example, for the definitions of "dynameter" 
in table 1, there is only one matched couple, 
"determining-measuring", whose lcc is 9 (the 
extent o1' the Icc is indicated by arrows). 
telescopes 
of 
power 
magnifying 
the 
determining 
for 
inslrulnent 
an 
dynameter 
,/,/; 
telescope 
a 
of 
power 
magnifying 
the 
measuring 
for 
instrument 
An 
dynameter 
cost\[il\[jl 
2 
2 
1 
1 
I 
1 
1 
0 
0 
0 
0 
Table 1 Triplets for "dynameter"  
<- 
?U> 
II 
?o 
?J 
<-- 
Ranking all triplets found by lcc in decreasing 
order, we observe that the greater the value o1' 
lcc, the greater the similarity between the words 
of the matched couple. 
2.5 Removing flmetion words 
So far, function words and other noise words 
will also be clustered by our algorithms, in 
general, such words interfere in the 
identification of clusters and can give more 
wrong than good results. We use a stoplist to 
automatically identify any pair of words where a 
non-relevant word appears and exclude it, on the 
grounds that they are not very useful words for 
clustering. Thus, when the program comes 
across a matched pair of different words in a 
context and il' that matched pair contains a word 
from the stoplist, then the pair is rejected. 
Essentially, this is the same thing as using a 
tagger and looking at the tags as well as the 
words, since one would not want to choose a 
noun pairing with a determiner or a relative. 
By inspection, we observe that, after stoplist 
discrimination, the best potential clusters are 
found at higher values ot' Icc. Our experimental 
results show us that a length of lcc equal to 5 is a 
reliable threshold. Although there are also good 
matches for values equal to 4 and 3, the majority 
of these are duplicates of higher values. 
2.6 Clustering 
We introduce the terln binding to represent a
candidate cluster, i.e. two words that may be 
used in the same context without changing the 
meaning o1' a definition. A binding is a matched 
couple (J.l~, .\[/'9 formed by the full forms .\[f~ and 
ft;, after stoplist discrimination, drawn t'rom the 
strings S, and S~, respectively, in such a way that 
the stem forms are equivalent, in a determined 
context, according to a determined threshold'. 
The threshold associated with a binding is the 
length of the lcc, and we consider only bindings 
of matched couples where lcc >_ 5. 
Each binding can be considered as an initial 
cluster. Clusters represent sets o1' words that are 
used with the same meaning in particular 
contexts. In a consecutive sequence of bindings, 
it may happen that a stem form occurs in two or 
more dilTerent bindings. In this case, one can 
cluster all bindings with a common stem form 
according to the transitive property. 
in order to cluster bindings, we use an algorithm 
consisting o1' three loops. First, it assigns a 
cluster number to each binding, so those 
bindings with a common word have the same 
cluster number. Secondly, it clusters bindings 
with the same cluster number, but removes 
798 
duplicate stem forms in tile same cluster. 
Thirdly, it checks if it is possible to inerge new 
clusters with those of previous cycles. This 
process will typically result in a set of 
overlapping clusters, reflecting the natm'al state 
where concepts may belong to more than one 
conceptual class. 
2.7 Cycling 
As bindings represent pairs of words such that 
the stem forms can be substituted in a particular 
context without changing the meaning, sJi = aJ~ 
we can replace any of the full formsf? with the 
full l'orms ffj according to each binding, so that 
the corresponding definition preserves the same 
meaning. After substituting bindings, we 
observe that several pairs of words will now 
typically present a high lcc score, even those 
pairs of words which initially did not yield 
matches with any word. It is then advantageous 
to replace thus the bindings in the definitions 
alld to repeat the entire process until no new 
clusters are found. The first cycle runs from the 
reading o1' definitkms up to merging of clusters. 
All subsequent cycles will start by replacing 
retained bindings in the definitions, thus each 
subsequent cycle works with new data. 
3 Experimental results 
The current clustering algorithm was developed 
by analysing definitions on the following basis: 
? Language dictionaries. The use of language 
dictionaries has been preferred because there 
are enough to extract data from. As they are 
in machine-readable form, it is possible to 
copy definitions, avoiding likely mistakes 
while typewriting. 
? Corpus on 314 "measuring instruments". 
This domain has the advantage that it is easy 
to search for the terms that correspond to it, 
as they usually end in "-meter", "-scope" or 
"-graph". As a conscqueuce o1' applying the 
clustering program to the 387 strings, it is 
evident that the maiority of clusters were 
related to "measure" and "instrument". 
? Alignment of two strings. We have shown 
that two sources of data (pairs of del'inition) 
are sufficient for clustering to yield good 
results. 
? No manipulation el'data. After ktentification 
of the term and the definitions, these were 
truncated to 200 characters and punctuation 
marks were removed. No words in 
definitions were replaced or moved, to "tidy 
up" the data, before being submitted to the 
main process. 
? Stemming algorithm. The stemmer 
algorithm presents both overstemming and 
understemming, but nevertheless the 
clustering program yiekts good results. 
? Stoplist discrimination. The stoplist has 
been used as a tagger, i.e. as a filter to avoid 
matching words with dil'ferent parts ot' 
speech. 
? Bindings for Ice _> 5. The best clusters have 
been observed for bindings with lcc> 5, and 
the results presented m'e good. 
Table 2 presents ome cluster results after two 
cycles of the clustering procedure starting from 
the Levcnshtein distance. In addition to these 
clusters, 14 other clusters of two or three 
elements were obtained. 
I. apparalus inslrumcnt telescope 
2. analyse ascerlaining determining estimating 
location measuring recording lakins testing 
3. amotmt concenlration intensity percentage 
proportion rate salinity strength 
Table 2 Cluster results for "measuring 
illstFunlents" 
The procedure then stops, as no more matched 
words with lcc _> 5 have been found for our data. 
The following sections analyse variations of 
these considerations. 
3.1 Using multiple resources 
General language dictionaries present the 
advantage of using well-established 
lexicographic riteria to normalise definitions. 
These criteria, as for example the use of 
analytical definitious by genus and differentia, 
have been nowadays implemented by 
terminological or specialiscd ictionaries, with 
the addition of a richer vocabulary and the 
identification of properties that are not always 
considered relevant in other resources. 
Unfortunately, these are more oriented to a 
specific domain, so that it is sometimes 
necessary to search in two or more resources to 
compile the data. 
We used many online lexical resources, some of 
them available on the lnternct. This allowed us 
to easily use different databases to extract 
799 
Coling 2008: Proceedings of the workshop on Cognitive Aspects of the Lexicon (COGALEX 2008), pages 32?38
Manchester, August 2008
Natural Language Searching  
in Onomasiological Dictionaries 
Gerardo Sierra 
Instituto de Ingenier?a 
Universidad Nacional Aut?noma de M?xico 
gsierram@ii.unam.mx 
 
Abstract 
When consulting a dictionary, people can 
find the meaning of a word via the defini-
tion, which usually contains the relevant 
information to fulfil their requirement. 
Lexicographers produce dictionaries and 
their work consists in presenting informa-
tion essential for grasping the meaning of 
words. However, when people need to 
find a word it is likely that they do not 
obtain the information they are looking 
for. There is a gap between dictionary 
definitions and the information being 
available in peoples? mind. This paper at-
tempts to present the conceptualisation 
people engage in, in order to arrive at a 
word from its meaning. The insights of 
an experiment conducted show us the dif-
ferences between the knowledge availa-
ble in peoples? minds and in dictionary 
definitions. 
1 Introduction 
Many lexicographers recognise users need dic-
tionaries to look for a word that has escaped their 
memory although they remember the concept. 
From a semantic point of view, Baldinger (1980) 
takes user needs into account and thus distin-
guishes dictionaries that serve as aids in encod-
ing from those that help with decoding. The best 
known dictionaries of this type allow users to 
find the meaning of a word they already know. 
Such dictionaries are semasiological: they asso-
ciate meanings with expressions/words, i.e. 
within entries we move from word to meaning. 
                                                 
? 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
The second kind of dictionary helps those users 
who have an idea to convey and want to find a 
word to designate it. Such dictionaries are ono-
masiological: they connect names to concepts, i.e. 
within entries we move from meaning or concept 
to name or word.  
Sierra (2000) confirmed the well known ob-
servation that the organisation of the world varies 
from author to author, by contrasting some rec-
ognized onomasiological dictionaries, such as 
Roget's Thesaurus of English Words and Phrases 
(1852), Bernstein's Reverse Dictionary (1975), 
and WordNet (Miller et al, 2008).  
In order to build a system that maps natural 
language descriptions of concepts to the terms 
corresponding to those concepts, Sierra and 
McNaught (2000) outlined the design of an 
Onomasiological Search System. They described 
the principles of the system, whereas the archi-
tecture and its components are presented as part 
of the design. This also includes an idealised user 
interface, with a discussion of the organisation of 
the probable terms and additional information 
that can help the user to identify precisely the 
term he is looking for.  
As cognitive issues for the design of such sys-
tem, this paper attempts to present the conceptu-
alisation people engage in, in order to arrive at a 
word from its meaning. In this sense, it breaks 
the traditional lexicographic assumption that one 
should utilise a semasiological approach to pro-
vide formal representations to describe the mean-
ing of a word. In contrast, in the onomasiological 
approach, the user can formulate a concept in 
several ways and use a variety of words in order 
to find a particular word.  
Our starting point is to understand what con-
ceptualisation is (section 2), and the process of 
designation (section 3). To validate our approach 
in practice, section 4 presents the results of an 
experiment, which is compared with other stud-
32
ies on conceptual analysis. Finally, the conclu-
sions are stated. 
2 Conceptualisation 
The concept is a mental representation of an 
object which is formed in the mind of individuals 
through a process of abstraction. We call this 
process of constructing an internal representation 
of external things a conceptualisation. 
Conceptualisation is a mental activity of 
grouping the data of common properties 
according to external factors, and then concepts 
are internalised and form part of each 
individual?s knowledge. 
2.1 Properties 
The terms property, characteristic or feature 
have been used for the knowledge necessary to 
describe and classify a concept. The 
identification of properties is crucial to concept 
analysis since it helps to define concepts and 
identify their interrelationships. 
According to Sager (1990) some properties are 
necessary and sufficient to distinguish a concept 
from any other, and these properties reflect the 
essential characteristics of a concept. Conversely, 
other properties are inessential, merely observ-
able in an individual thing, so that they are acci-
dental, may change with time and may not even 
be necessarily true in a scientific sense (Pet?fi, 
1982).  
The dichotomy of these two opposing types of 
properties has been discussed from a psycholin-
guistic point of view. Aitchison (1994) does not 
consider that it is obvious that experts and ordi-
nary people distinguish between essential and 
inessential characteristics. Despite the fact that 
experts might be able to specify the true nature of 
things, they sometimes provide information 
which is irrelevant to the mental lexicon. Con-
versely, ordinary people disagree and change 
their minds. 
As the comparative analysis in section 4 
shows, the essential characteristics are not neces-
sarily present in the mental lexicon of a person; 
each one describes different properties. Never-
theless, even a description of the inessential 
characteristics, given together, provides enough 
information to identify the term (Wierzbicka, 
1985). 
2.2 Social conceptualisation 
People acquire knowledge about things on the 
basis of cultural, geographical and social factors. 
The environment conditions the conceptualisa-
tion of reality and the use of language. In order to 
communicate effectively, people will try to use 
language in a similar way to that of the collective 
view of the community, in agreement with the 
social norm. In fact, because of the social norm, 
there is an idealised knowledge structure which 
makes it possible to use the same names for the 
same things. In the contrary case, when the des-
ignation of a concept is outside that norm, people 
assume that the individual's knowledge is wrong. 
However, as we will see in the final analysis, we 
must accept that an individual's knowledge can-
not cover the whole knowledge of the commu-
nity norm.  
2.3 Individual conceptualisation  
Reality goes beyond the perception of 
individuals. Our knowledge about reality has 
increased throughout human history. No one ?
human, computer or even the biggest library? 
possesses the whole knowledge about reality. 
The knowledge structure of things varies from 
one person to the other, so that their description 
of concepts will be different. As Fugman (1993) 
states, since the number of properties is virtually 
unlimited, people concentrate on those character-
istics which appear essential, according to their 
personal or professional view. As an example, he 
points out the different essential properties for 
the concept ?benzene? given by a physicist, a 
biologist, an engineer, a fire-fighter and a chem-
ist. 
Even the same person can demonstrate differ-
ent conceptualisations of simple things, such as 
"dog" or "apple", depending on the contextual 
situation. For example, a dog seen in different 
domains, such as a conference, a zoology lecture, 
a road or a house, may be described as canine, 
mammal, animal or pet.  
3 Designation 
The process of designation is the opposite of sig-
nification. Signification is the identification of 
the meaning of a word, and the result of finding a 
meaning is a definition. Designation is the identi-
fication of a term for a concept and the result is a 
word. 
To retrieve a term, one can use a terminologi-
cal definition, which provides the information 
necessary to identify and differentiate a concept 
within a system of concepts, so that it sometimes 
comprises encyclopaedic information, not usu-
ally necessary in a lexicographic definition. 
33
3.1 Properties 
Just as a word may have many meanings 
(semasiological approach), a concept, which is 
described by a set of properties, may be 
designated by more than one word 
(onomasiological approach). Within the 
onomasiological approach, all the properties 
together provide the necessary and sufficient 
information to identify the concept. However, 
since the description of concepts in natural 
language does not incorporate all knowledge or 
ideas associated with each concept, it can happen 
that the projection of a concept, i.e., the query 
formulation of the user, will retrieve a set of 
terms. For example, the concept ?strong winds?, 
consisting of two properties, can retrieve, in the 
domain of weather terminology, a variety of 
terms, such as: ?gale?, ?tornado?, ?hurricane?, 
?typhoon?, etc. 
The concept a user has in mind when looking 
for a target word is expressed by a sentence. 
When a person hears this sentence, he translates 
each word into his own language and easily iden-
tifies the context. A person may understand the 
expression ?that which determines air pressure? 
and get a mental representation of ?that? for 
?thing? and then for ?instrument?; or that the 
speaker might have said ?measures? instead of 
?determines?. From the context, at the same time, 
he may differentiate whether the word ?air? re-
fers to the atmosphere or the air of a tyre. 
Equally, either the lack or change of any one 
property may result in the identification of a dif-
ferent concept. For example, take the following 
definition for ?barometer?: 
? A device to measure air pressure. 
Each of the four keywords yields a property. 
Then, we can change one property at a time and 
get a different concept. If we change 
 
? ?Device? to ?unit?, the result is the con-
cepts ?inch? or ?millibar?. 
? ?Measure? to ?provide?, the result is ?air 
scoop?. 
? ?Air? to ?blood?, the result is ?sphyg-
momanometer?. 
? ?Pressure? to ?humidity?, the result is 
the concept ?hygrometer?. 
4 Comparative analysis on conceptuali-
zation 
In order to verify some of the ideas presented 
above, an experiment was carried out with a 
small group of twenty undergraduate students. 
Although a small group is unrepresentative for 
any generalisation to be made from a statistical 
point of view, it has been sufficient for our pur-
pose to demonstrate that the conceptualisation 
used by a random set of students is far from the 
definitions found in a dictionary.  
From two sets of five words, each student was 
asked to take a set and write on a blank sheet of 
paper, similar to an onomasiological search, a 
concept, a definition or the ideas suggested to 
them by each word. After interchanging the 
sheets, the other students participating in the ex-
periment wrote the word or words designating 
the concepts identified or written on the blank 
sheets by the previous student.  
The sets of word given contained three general 
language words and two terms. 
? Set A: water, squirrel, bench, euthanasia, 
hurricane. 
? Set B: lemon, bucket, clothing, monop-
oly, barometer. 
The general words were chosen because they 
permit us, as can be observed from the following 
sections, to compare the results with the words 
analysed by other researchers as well. 
We will next introduce our definitions by 
comparing with four studies on conceptualisa-
tion. 
4.1 Putnam 
Putnam (1975) proposes the representation of the 
meaning of a word as a finite sequence of at least 
four properties: 
The syntactic markers, which are the category-
indicators used in a host of contexts to classify 
words. 
The semantic markers, which are the most 
central properties, form part of a widely used 
classification system and very may be affected 
by any change in the knowledge about the thing. 
A description of the features of the stereotype, 
which is a conventional idea of what the object 
looks like or acts like or is, regardless whether it 
is true or not for all the objects. For example, 
?yellow? is a stereotype of ?gold?, even when 
gold is white by nature. 
A description of the extension, i.e., the set of 
things of which a term is true. The extension is 
determined socially depending upon the nature of 
the particular things, rather than on the concept 
of the individual speaker. 
The first three properties belong to the indi-
vidual competence of speakers. The extension 
34
does not necessarily have to be known to every 
member of a linguistic community.  
According to Pet?fi (1982), the semantic 
markers and the stereotype may be compared 
with Ullman?s concept of meaning. From the 
perspective of the lexicographic definition, they 
resemble genus and differentia, respectively. 
The description of the meaning of ?water?, as 
a particular natural kind, following these compo-
nents, is given in table 1. 
Syntactic 
markers 
Semantic 
markers 
Stereotype Extension 
mass noun natural kind colourless H2O 
concrete liquid transparent (give or take 
impurities)   tasteless 
  thirst-
quenching 
Table 1. Properties for the natural kind ?wa-
ter? 
In order to permit comparison of the defini-
tions given in our experiment with his meaning 
of ?water?, the same four kinds of properties are 
used. Our definitions, as shown in Table 2, in-
clude the property ?fluid?, which easily can be 
classified as a semantic marker.  
n. Concept 
1 It?s a clear liquid that you get from a tap 
2 The colourless transparent liquid occurring on 
rivers 
3 A clear, neutral liquid that surrounds us 
everywhere 
4 Liquid, clear, drinkable ? constituents are 
hydrogen and oxygen 
5 Liquid, clear, H2O 
6 Liquid form, scientific term H2O 
7 Liquid, freezes at 0?C 
8 Liquid, clear, boils at 100?C, freezes at 0?C 
9 Fluid, clear, tasteless, colourless 
10 Wash with it; drink it; used for dilution; H2O; 
found in springs, rivers, lakes, seas, oceans  
Table 2. Conceptualisation of water 
The properties referring to the boiling and 
freezing points of water, given in definitions 7 
and 8 in our experiment, may be considered as 
part of the concept?s extension, since these prop-
erties depend upon the nature of the water.  
Therefore, definitions one to nine include the 
semantic marker ?liquid?, beside the particular 
features of water, the stereotypes, and/or the de-
scription by extension. The definition ten, which 
does not include the semantic marker, describes 
water by extension. 
4.2 Wiegand 
Wiegand (1984) tries to identify the properties of 
a definition by means of a scale of usability ob-
tained statistically from a questionnaire to 100 
students. He suggests 21 properties and asks the 
students to judge which of them describe a 
lemon. Each property is evaluated in three cate-
gories according to the sum of ticks it received as 
good, not so good and not good (Table 3). 
GOOD NOT SO 
GOOD 
NOT GOOD 
oval yellow tapers at both ends 
juicy pulp thick rind oblong 
sour pulp citrus fruit thin rind 
yellow rind green rind used to make pectin 
fruit of the 
lemon tree 
 pulp containing 
approx. 3.5-8% citric 
acid 
  pulp rich in vitamin C 
  variable protuberant tip 
  pulp rich in vitamins 
  many uses in cooking 
  used to make drinks 
  used to make citric acid 
Table 3. Properties of lemon using a scale of 
usability 
Even although a test with ten students is not a 
representative sample from which one can gener-
alise the scale of usability of the properties of a 
concept, our experiment, as shows in table 4, 
allows us to challenge the values identified by 
Wiegand. 
n. Concept 
1 It?s a yellow fruit, like limes. Citrus. Used in 
cooking for sharpness  
2 A yellow citrus fruit. Sour tasting. Often used 
as an accompaniment to drinks  
3 a yellow citrus fruit with a bitter taste often 
sliced and put in drinks 
4 It?s a citrus fruit, yellow, used with sugar on 
pancakes  
5 It?s a yellow citrus fruit. Tastes bitter. Oval 
shaped  
6 A yellow sour fruit  
35
n. Concept 
7 A yellow citrus fruit 
8 Yellow, citrus, fruit 
9 Citrus fruit which is yellow 
10 Yellow citrus fruit 
Table 4. Conceptualisation of lemon 
As observed in table 5, there is no match be-
tween the values for the seven properties ex-
tracted by Wiegand and our own experiment 
from the definitions. 
Property Our ex-
periment 
Wiegand 
yellow good not so good 
citrus good not so good 
oval not good good 
sour pulp not good good 
many uses in cook-
ing and drinks 
not good not good 
variable protuber-
ant tip 
not good not good 
similar to limes not good --- 
Table 5. Comparative analysis of the proper-
ties of lemon 
The reasons why these values differ are not 
obvious. Probably this comparison means statis-
tical methods from a group of students are not 
reliable to assess the properties of concepts.  
4.3 Ayto 
In order to define the meaning of words, Ayto 
(1983) adapts the componential analysis intro-
duced by Pottier to semantic fields. He also iden-
tifies the semantic features that characterise vari-
ous sorts of seats, but analyses these characteris-
tics to compose an analytical definition. The 
definition of a word is determined by the seman-
tic features that differentiate it from other words 
rather than by the sum of the individual charac-
teristics. The genus for each word in the semantic 
field is ?seat?, as it presents the only common 
characteristic for the rest of the set. 
The differentia is determined by comparing 
the other characteristics and checking those 
which are different. The characteristics are: For 
several people, not upholstered, for outdoors, 
functional. 
Then the definition for ?bench? is, for exam-
ple, ?a seat for two or more people that has a 
back, is typically used outdoors, and may be 
fixed in position?. 
For a comparative analysis, it is possible to 
find the semantic features of the definitions in 
our experiment (Table 6) and try to match them 
with those given by Ayto. 
 
n. Concept 
1 You can sit on it in the street or a park and 
they are made of wood  
2 A long hard seat for several persons on which 
the players on a sport team sit  
3 An object for sitting on, usually long which 
can seat many people  
4 Sit on it (a few people can) in parks, made of 
wood or iron  
5 Object used for sitting on. Often found in 
public places such as parks and gardens. Used 
to seat 1 or more people at a time 
6 Something you seat on, is longer than a chair, 
usually made of wood 
7 Long platform for sitting on (fit many people 
on one) 
8 Apparatus for sitting on, designed for more 
than one person, often found in parks 
9 A kind of seat found in parks, made of wood 
10 A type of chair 
Table 6. Conceptualisation of bench 
For this purpose, we should assume that: 
 
1. For several people = longer than a chair. 
2. Not upholstered = made of wood or iron, 
hard seat, platform. 
3. Outdoors = street, park. 
4. Functional = for a sports team. 
 
Table 7 presents the four semantic features 
used in our experiment to define ?bench?. 
 
 Char. 
1 
Char. 
2 
Char. 
3 
Char. 
4 
Bench 1  + +  
Bench 2 + +  + 
Bench 3 +    
Bench 4 + + +  
Bench 5 +  +  
Bench 6 + +   
36
Bench 7 + +   
Bench 8 +  +  
Bench 9  + +  
Bench 10     
Table 7. Semantic features of bench  
In the light of this contrastive analysis, it is 
clear that each semantic feature (for example 
?outdoor?) can be expressed by a set of equiva-
lent alternatives (for example, ?public places?, 
?parks?). 
4.4 Wierzbicka 
Wierzbicka (1985) considers that a good lexico-
graphic definition must be exhaustive, i.e., pro-
viding all the properties of the concept. Her view 
of a definition differs from an encyclopaedic 
definition because the latter conveys knowledge 
about the object, while the lexicographic defini-
tion does not include specialised knowledge, 
unless it is part of the concept. Her demand for 
exhaustiveness is contrary to traditional semasi-
ological lexicography, where, through a genus 
and the differentia, the definition provides the 
essential properties to identify a concept and dis-
tinguish it from others. However, when there is a 
full description, we may be sure that a user will 
retrieve the word in an onomasiological search. 
Wierzbicka uses five general properties to 
reach a definition of animals, e.g. squirrels, 
namely: habitat, size, appearance, behaviour and 
relation to people. Table 8 presents an example 
of a description for each general property. 
General 
property 
Description 
Habitat They live in places where there are 
many trees. 
Size They are not too big for a person to 
be able to hold one easily in both 
hands. 
Appear-
ance 
They have a big bushy tail. 
Their fur is reddish or greyish. 
Behaviour They collect and eat small hard 
things which grow on trees of cer-
tain kinds. 
Relation to 
people 
People think of them as nice and 
amusing little creatures. 
Table 8. Examples of full description of 
"squirrel" 
As observed in the definitions of our experi-
ment (Table 9), the sum of properties in our defi-
nitions agrees with the description of the five 
kinds of properties of Wierzbicka, although she 
does not consider that squirrels build nests, as 
one of our definitions does. 
n. Concept 
1 It?s a little rodent and can be red or grey, it 
has a big bushy tail  
2 A small rodent living in trees with a long 
bushy tail  
3 A small rodent which lives in trees, collects 
nuts and has a bushy tail  
4 Animal, grey/red, bushy tail, lives in trees, 
buries nuts  
5 Small animal, lives in trees, eats acorns, has a 
bushy tail 
6 Animal, bushy tail, eats nuts, builds nests in 
trees called dreys 
7 Small funny animal with big, bushy tail, likes 
nuts, likes trees 
8 Animal that lives in trees and collects acorns, 
has a long tail 
9 A small-sized animal, habitat in trees 
10 Small grey mammal, relative to the rodent, 
found in both countryside and town 
Table 9 Conceptualisation of lemon 
5 Conclusions 
The distinction between semasiology and ono-
masiology permits us to consider a new perspec-
tive in lexicography. In the semasiological ap-
proach, the perspective is from the dictionary to 
the user. Dictionaries are a lexicographer?s prod-
uct and definitions provide the necessary and 
sufficient elements in order to know the meaning 
of a word. 
Conversely, the onomasiological approach is 
from the user to the dictionary. The user should 
provide the concept, while the dictionary inter-
prets that concept in order to find the most ap-
propriate word. The user can formulate the con-
cept by several methods and may use a variety of 
words that in a certain context are similar. Ac-
cording to the user?s social, cultural and geo-
graphical background, the description of the con-
cept may differ in multiple properties.  
With regard to the preceding analysis, it is 
worthwhile to note that even the most complete 
description of a concept can lack "essential" 
properties from the point of view of a user. None 
37
of the methods of componential analysis, even 
the most open ones, has been sufficient to foresee 
the properties used by a small set of students. 
That gap should be filled with the aid of a good 
onomasiological retrieval system.  
This does not mean that it is unlikely that we 
shall be able to design a complete and efficient 
onomasiological dictionary. In our context, effi-
ciency means that a dictionary has to satisfy the 
requirements of a particular kind of user, in a 
certain domain of a terminology with a specific 
background. Therefore, the design of an onoma-
siological dictionary must first foresee a multi-
plicity of properties for each concept and sec-
ondly the diversity of words that can be used to 
name them. Then, the task consists in the accu-
rate interpretation of the description of the con-
cept and providing the word or probable words 
the user is looking for. 
The core of such onomasiological dictionary, 
as reported by Sierra and McNaught (2000), is 
the lexical knowledge base (LKB), which should 
provide all the necessary knowledge to be ma-
nipulated in order to enable onomasiological 
search. In principle, it must represent what a per-
son knows about both concepts and their corre-
sponding terms. Such LKB consists then of a set 
of terms, a set of definitions for each term, a set 
of keywords associated with the definitions and a 
set of lexical paradigms that group keywords 
with the same meaning. It not only includes the 
databases that constitute these sets of data, but 
the interrelationships among all the sets. 
References 
Aitchison, Jean. 1994. Words in the mind: an intro-
duction to the mental lexicon. Blackwell Publish-
ers, Oxford.  
Ayto, John R. 1983. ?On specifying meaning: seman-
tic analysis and dictionary definitions?. Lexicogra-
phy: principles and practice. R.R.K. Hartmann 
(ed). Academic Press, London: 89-98. 
Baldinger, Kurt. 1980. Semantic theory: towards a 
modern semantics. Basil Blackwell, Oxford. 
Bernstein, Theodore M. 1975. Bernstein?s reverse 
dictionary. Routledge & Kegan Paul, London. 
Fugman, Robert. 1993. Subject analysis and indexing: 
theoretical foundation and practical advice. IN-
DEKS Verlag, Frankfurt. 
Miller, George A., Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine Miller. 1990. 
?Introduction to WordNet: An on-line lexical data-
base?. International Journal of Lexicography, 3(4): 
235-244. 
 Pet?fi, J?nos S. 1982. ?Exploration in semantics: 
analysis and representation of concept systems?. 
The Cocta Conference. F.W. Riggs (ed). 
Putnam, Hilary. 1975. Mind, language and reality: 
philosophical papers, Volume 2. Cambridge Uni-
versity Press, New York. 
Roget, Peter. 1852. Thesaurus of English Words and 
Phrases. Longman, London.  
Sager, Juan C 1990. A practical course in terminology 
processing. John Benjamins, Amsterdam. 
Sierra, Gerardo. 2000. ?The onomasiological dictio-
nary: a gap in lexicography?. Proceedings of the 
Ninth EuralexInternational Congress. Stuttgart.  
Sierra, Gerardo and John McNaught. 2000. ?Design 
of an Onomasiological Search System: a Concept-
Oriented Tool for Terminology?. Terminology 
6(1). 
Wiegand, Herbert E. 1984. ?On the structure and con-
tents of a general theory of lexicography?. Pro-
ceedings of the International Conference on Lex-
icography. M. Niemeyer, T?bingen, 13-30. 
Wierzbicka, Anna 1985. Lexicography and concep-
tual analysis. Karoma Publishers. 
 
38
Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,
pages 109?116, Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Recognition and extraction of definitional contexts in Spanish for sketch-
ing a lexical network
C?sar Aguilar Olga Acosta Gerardo Sierra
Department of Linguistics Postgraduate School of Computer 
Science
Language Engineering Group
Autonomous University of 
Queretaro
UNAM Engineering Institute, UNAM
Cerro de las Campanas, s/n, 
Queretaro, Mexico
Ciudad Universitaria, Mexico City Ciudad Universitaria, Mexico City
CAguilar@iingen.unam.mx OAcostaL@iingen.unam.mx GSierraM@iingen.unam.mx
Abstract
In this paper we propose a method to exploit ana-
lytical definitions extracted from Spanish corpora, 
in order to build a lexical network based on the hy-
ponymy/hyperonymy,  part/whole  and  attribution 
relations.  Our  method  considers  the  following 
steps: (a) the recognition and extraction of defini-
tional contexts from specialized documents, (b) the 
identification of analytical definitions on these def-
initional contexts, using verbal predications, (c) the 
syntactic and probabilistic analysis of the associa-
tion observed between verbal predication and ana-
lytical definitions, (d) the identification of the hy-
ponymy/hyperonymy,  part/whole  and  attribution 
relations  based on the lexical information that lies 
between  predications  and  definitions  and  other 
types of phrases, in particular prepositional phrases 
mapped by the preposition de (Eng. of/from).
1 Introduction
Nowadays, the possibility of searching and recog-
nizing lexical relations in definitions occurring in 
specialized  text  corpora  is  an  important  task  in 
computational lexicography and terminology. 
In  this  sense,  authors  such  as  Vossen  and 
Copestake (1993), as well as  Wilks, Slator & Gu-
thrie (1995) are pioneers in offering a relevant set 
of experiments and techniques about how to identi-
fy hyponymy/hypernymy relations from analytical 
definitions, taking into account  the underlying as-
sociation  that  exists  between  terms  and  genus 
terms.
Complementary to these first attempts for iden-
tifying  such  lexical  relations,  Riloff  & Shepherd 
(2004) argue that while these efforts have been ori-
ented  to  extract  lexical  relations  from corpus  of 
general  language, it  is  necessary to focus on do-
main-specific corpora, in order to obtain a special-
ized knowledge that is required for in-depth under-
standing of the subject matter. 
In line with the argument formuled by Riloff & 
Shepherd,  Buiteelar,  Cimiano & Magnini  (2005) 
have  proposed  several  methods  for  building  on-
tologies from text corpora, priorizing the automatic 
recognition  of  syntactic  patterns  that  codify 
hyponymy/hyperonymy relations.
Following all  these authors,  we sketch here a 
research  project  to  design  a  lexical  network,  fo-
cused on classifying scientific and technical con-
cepts extracted from Spanish text corpora. In par-
ticular, we obtain these concepts by extracting def-
initional contexts (DCs) with terms and definitions 
clearly  formulated,  according  to  the  theoretical 
framework  developed  by  Sierra,  Alarcon  & 
Aguilar (2006). 
After  extracted  these  DCs,  we  propose  a 
method to identify lexical relations between terms 
inserted into the DCs.  The method considers,  on 
the one hand, a grammatical analysis for detecting 
syntactic  patterns  that  represent  term  and  genus 
term, bearing in mind their association through lex-
ical relations such as hyponymy/hyperonymy, part/
whole or attribution relations. On the other hand, 
we proposed a semi-automatic evaluation to deter-
mine the degree of accuracy respect to the results 
obtained by our method.   
The issues that we will deal in this paper are or-
ganized as follows: (a) as a starting point, we ex-
pose briefly  the  theoretical  framework to  extract 
DCs from Spanish corpora. (b) According to this 
framework, we describe how analytical definitions 
109
linked to terms can be identified, considering the 
identification of verbal  predications  that  function 
as connectors between such definitions and terms. 
(c) Thus, we offer a probabilistic evaluation for de-
termining the degree of association between pre-
dications and analytical definitions. (d) After this 
evaluation, we sketch a method for exploiting this 
association  between  predications  and  definitions, 
in  order  to  identify  lexical  relations,  specifically 
hyponymy/hyperonymy, part/whole and attribution 
relations.
2 Theoretical framework: DC extraction 
We situate our analysis  within the framework of 
definitional contexts (or DCs) extraction. Accord-
ing to  Sierra  et  al.  (2008),  a  DC is  a  discursive 
structure that contains relevant information to de-
fine a term. DCs have at least two constituents: a 
term and a definition, and usually linguistic or met-
alinguistic  forms,  such  as  verbal  phrases,  typo-
graphical  markers  and/or  pragmatic  patterns.  An 
example is:
(1) La cuchilla fusible [Term] se define como [Verbal 
Phrase] un elemento de conexi?n y desconexi?n 
de circuitos el?ctricos [Definition]. (Engl. The 
fuse-switch disconnector is defined as an ele-
ment of connection and disconnection of 
electric circuits).
In (1), the term cuchilla flexible is  emphasized by 
the use of bold font, and it appears linked with the 
verbal predication  se define como, and the defini-
tion un elemento de conexi?n y desconexi?n de cir-
cuitos el?ctricos. Following to Sierra et al (2008), 
we  consider  the  term,  the  verbal  phrase  and  the 
definition as the three main units constituting the 
syntactic structure of a DC.
This  kind of  syntactic  structure  introduces  an 
analytical  definition  (in  the  Aristotle's  sense), 
where  the  genus  term  is  represented  by  a  noun 
phrase (NP) un elemento and the differentia is rep-
resented by a prepositional phrase (PP)  de conex-
i?n y desconexi?n de circuitos el?ctricos.
In a detailed analysis on these syntactic struc-
tures, Aguilar (2009) explains that these structures 
are  predicate  phrases  (PrP),  according to  the  de-
scription proposed by Bowers (1993, 2001). A PrP 
is a phrase mapped by a functional head, and its 
grammatical behavior is similar to other functional 
phrases such as Inflexional Phrase (IP) or Comple-
ment Phrase (CP). A graphical tree representation 
of a PrP is:
Figure 1: Tree representation for PrP, according to 
Bowers (1993: 596)
The Figure 1 describes the syntactic configuration 
of a PrP. We recognise a functional head with the 
feature +/- predicative (Pr). This head maps two sub-
jects: a primary subject in the Specifier position of 
PrP (represented for a NP); and a secondary sub-
ject,  in the Specifier position of verbal phrase or 
VP (often a NP). Finally, both subjects, the VP and 
the PrP are linked to one or several complements, 
which assume phrasal representations (e.g.: NP, IP, 
CP, and other types of phrases).
Based on this description about PrP, Sierra  et  
al. (2008) and Aguilar (2009) observed that both 
primary and secondary predications  have a close 
relation  with  analytical  definitions  expressed  in 
specialized  texts.  Examples  of  this  relation  be-
tween PrP and analytical definitions are:
(2) [Una computadora [es [un tipo de m?quina 
electr?nica que sirve para hacer operaciones 
PrP] VP] IP] (Eng. [A computer [is [a kind of 
electronic machine used to make operations 
PrP] VP] IP]).
(3) [Turing [define una computadora [como un 
mecanismo electr?nico que procesa conjuntos 
de datos PrP] VP] IP] (Eng. [Turing [defines a 
computer [as a kind of electronic device that 
processes a set of data PrP] VP] IP]).
We observe in (2) a canonical primary predication 
where  the  subject  una computadora  represents  a 
term directly associated to predicate es un tipo de  
m?quina que... This predicate introduces an analyt-
ical  definition,  conformed  by  a  genus  term 
110
eletronic  machine,  and  the  differentia  que  sirve  
para hacer operaciones. In (3), the predicate como 
un  mecanismo  electr?nico...  (Engl.  as  a  kind  of  
electronic  device...)  affects  the secondary subject 
una computadora (Engl.  a computer), in concord-
ance with the explanation of Bowers (1993). Our 
analysis  considers  both  types  of  predications  as 
regular patterns that codify syntactically sequences 
of terms, verbal predications and definitions.
3 Searching  analytical  definitions  in  text 
corpora
We have adapted the predicative patterns deduced 
from our syntactic analysis, in order to search and 
find  (semi-)automatically  analytical  definitions 
linked to these patterns. So, we conducted an ex-
periment  of  identification  of  these  definitions  in 
two text corpora:
? Linguistic  Corpus  on  Engineering  (or 
CLI).  The  CLI,  prepared by Medina and 
others (2004), is a collection of technical 
documents in  different  thematic areas  of 
engineering, with an extension of 500,000 
words, approximately.
? Corpus  on  Informatics  for  Spanish  (or 
CIE). This corpus was built under the su-
pervision of L'Homme and Drouin (2006). 
The  CIE  compiles several documents re-
lated to computer science and   informat-
ics. For our experiment we took a portion 
of  CIE,  which contains articles extracted 
from Wikipedia. This portion has an ex-
tension of   500,000 words.
Following to Aguilar et al (2004) and Sierra et al 
(2008), we selected a set of verbs that function as 
heads  of  predicative  patterns  in  Spanish,  taking 
into account the distinction between primary and 
secondary predications. 
In the case of primary predication, the analytic-
al  definition is  integrated in  a  sequence  Term + 
Verbal  Predication  +  Definition.  This  definition 
does not refer to possible author(s) of a definition. 
An example is:
(4) [El apartarrayos Term] [es Verbal Predication] [un dis-
positivo Genus Term] [que protege las instalacio-
nes contra sobretensiones de origen atmosf?-
rico Differentia] (Engl. [The lightning conductor 
Term] [is Verbal Predication] [a device Genus Term] [that 
protects electrical systems against surges of 
atmospheric origin Differentia]).
Having in mind this sequence, we propose a gram-
matical description model for this relation:
Table 1: Construction patterns derived from the relation 
between primary predication and analytical definition
Definition Genus Term Differentia
Analytical 
(Primary 
Predication)
NP =  Noun + 
{AdjP/PP}*
CP = Relative Pronoun  + 
IP 
PP = Preposition  + NP
AdjP = Adjective + NP
The verbs that  operate  as  head of  these  predica-
tions are:  referir (to refer to),  representar (to rep-
resent),  ser  (to  be)  and  significar (to  signify/to 
mean). In contrast,  when a secondary predication 
introduces an analytical definition, this predication 
follows   the  sequence  Author  +  Term + Verbal 
Predication + Definition, where the Author is equi-
valent  to  the  primary subject,  the  Term assumes 
the position of secondary subject,  and the defini-
tion is introduced after the Verbal Predication. In 
this  case,  the  adverbial  particle  como (Eng. 
as/like), or the preposition por (Eng. for/by) indic-
ates the place of the definition. An example is:
(5) [Carlos Godino Author] [define Verbal Predication] [la 
arquitectura naval Term]  [como la ciencia que 
se enfoca en la construcci?n de los buques De-
finition] (Eng. [Carlos Godino Author] [defines 
Verbal Predication] [the naval architecture Term] [as 
the science that focuses on the construction of 
ships Definition])
Thus, the formal description of this sequence is:
Table 2: Construction patterns derived from the relation 
between secondary predication and analytical definition
 Definition Adverb/
Preposition
Genus Term Differentia
Analytical
(Secondary 
Predica-
tion)
Como
Por
NP =  Noun + 
{AdjP /PP}*
CP = Relative Pro-
noun  +  IP
PP = Preposition  + 
NP
AdjP = Adjective + 
NP
The verbs linked to secondary predications are: ca-
racterizar + como/por (Engl. to characterize + 
as/for), comprender + como (Engl. to comprehend 
111
+ as), concebir + como (Engl. to conceive + as), 
conocer + como (Engl. to know + as), considerar  
+ como (Engl. to consider + as), definir + como 
(Engl. to define + as), describir + como (Engl. to 
define + as), entender + como (Engl. to understand 
+ as) , identificar + como (Engl. to identify + as) 
and visualizar + como (Engl. to visualize + as).
In order to recognize these sequences of predic-
ations and analytical definitions, we employed a 
system developed in Python by Rodr?guez (2004). 
Broadly speaking, the input for this system is a set 
of previously delimited text fragments. The output 
is a XML table with a list of patterns, the verb used 
for searching these patterns, and the frequency of 
use in both corpora.
4 Results
Once  we  accomplished  the  process  of  searching 
and  extracting  of  fragments  with  sequences  of 
predication  patterns  of  analytical  definitions,  we 
determined values of precision and recall  for the 
CLI and CIE corpora based on the real number of 
analytical DCs in the corpus. This data was deter-
mined by a human expert through an exploration in 
the  corpora  mentioned  above.  In  table  3  we 
showed DC candidates, as well as the real number 
of true DCs extracted from these candidates.     
Thus, from CLI corpora we obtained a total of 
1686 candidates. From these candidates, the human 
expert recognized a set of 111 true DCs to analyti-
cal  definition  linked  to  primary  predication  pat-
terns. Our recall  was 100% because we obtained 
all of the DCs with analytical definitions, but the 
precision achieved was very low (6.6%). 
The main cause about this low precision is due 
to the verb ser (Eng. to be). The verb ser is highly 
productive in Spanish, however, much of the frag-
ments found are not analytical definitions. In con-
trast, from secondary predication patterns, our re-
call was 100% and precision 9.4%. Thus, the CIE 
corpora showed measures of  precision and recall 
higher than those of CLI corpora because most of 
documents  were  extracted  from  resources  as 
Wikipedia. We suppose this factor is related with a 
definition scheme more canonical in scientific and 
technical documents. 
Table 3: Sequence frequencies of predication patterns 
and analytical definitions
Analytical Definitions  CLI CIE
 
Primary Predication
Candidates 1686 494
DCs 111 127
Recall
Precision
100%
6.6%
100%
25.7%
 
 
Secondary Predication
Candidates 701 61
DCs 66 11
Recall
Precision
100%
9.4%
100%
18.0%
We derived a frequency distribution of the verbs 
with type of predication for CLI and CIE corpora. 
The table 4 shows the relative frequency of use of 
each  verb  explored.  Most  of  these  verbs  do  not 
have been considered in automatic extraction tasks 
of hyponymy-hyperonymy relations, e.  g.:  Hearst 
(1992) or Wilks, Slator & Guthrie (1995).
Table 4: Frequency distribution of verbal predicate, and 
its use in analytical definitions
Predication Corpora
CLI CIE
Primary
Referir(a)/To refer 0 0.02
Representar/To represent 0 0.04
Significar/To signify 0 0.03
Ser/To be 1 0.91
Secondary
Caracterizar/To characterize 0.12 0.18
Concebir/To concibe 0.09 0
Conocer/To know 0.17 0
Considerar/To consider 0.21 0.27
Definir/To define 0.27 0.27
Describir/To describe 0.03 0.09
Entender/To understand 0.06 0.18
Identificar/To identify 0.03 0
Visualizar/To visualize 0.02 0
Once  established  this  distribution,  we  have  ana-
lyzed the degree of assurance to find a good candi-
date for analytical definitions. We have applied a 
method of conditional probabilities for primary and 
secondary predications. Our conditional probabili-
ties are formulated by the hypothesis that the prob-
ability (P) of co-occurrence of predications (Pred) 
linked to analytical definition (AD) is high. Thus, 
we  apply  the  following  formula  of  conditional 
probability:
P(AD ? Pred)  
P(AD|Pred) =  P(Pred)  
112
Taking into account the formula mentioned above, 
we obtained the following results:
Table 5: Conditional probabilities of co-occurrence 
between predications and analytical definitions
Predication CLI CIE
Primary 
Analytical definitions 93% 100%
Not-analytical definitions 7% 0%
Secondary 
Analytical definitions 95% 100%
Not-analytical definitions 5% 0%
Therefore, we considered that the possibility to 
identify a good candidate of analytical definition is 
high, insofar as we took into account their relation-
ship with primary and secondary predications.
In  addition,  Alarc?n,  Bach  &  Sierra  (2007), 
propose a methodology for filtering true DCs from 
a set of candidates to DCs. An important advance 
provided for this work is the application of a filter 
phase that discards those syntactic patterns without 
true analytical definitions. For example, if we find 
a particle as no (Eng. not) or tampoco (Eng. either) 
in the first position before or after of a predication, 
there is a high probability these pattern do not in-
troduce a good analytical definition. In Table 5 we 
showed some results in terms of precision and re-
call reported by authors only for analytical defini-
tion patterns.
Table 6: Precision & recall values 
Verbal pattern Precision Recall
Concebir(como)/To conceive(as) 0.67 0.98
Definir(como)/To define(as) 0.84 0.99
Entender(como)/To understand(as) 0.34 0.94
Identificar(como)/To identify(as) 0.31 0.90
Significar/To signify 0.29 0.98
5 Sketching a method 
In this section, we propose a method for recogniz-
ing lexical relations from the previous extraction of 
DCs. In particular, we assume that a good way to 
reach these relations is to improve the syntactic as-
sociation observed between predications and ana-
lytical definitions inserted into these DCs.
This assumption is in line with the methodology 
proposed by Buitelaar, Cimiano & Magnini (2005) 
for building ontologies based on textual informa-
tion  obtained  from  corpora.  These  three  authors 
conceive a chain of  processes and sub-processes, 
represented with a layer cake scheme: 
Figure 2: Ontology learning layer cake (according to 
Buitelaar, Cimiano & Magnani 2005)
Briefly,  in  this  scheme  Buitelaar,  Cimiano  & 
Magnini establish a sequence of 6 basic tasks for 
developing a possible ontology. Thus, the first task 
is the identification of a set of specific terms to a 
certain knowledge domain (in this case, a medical 
domain). After that, it is necessary to identify syn-
onyms related to these terms (e.g., disease/illness). 
Given both sets of  terms and synonyms, the fol-
lowing task is to determine concepts in a formal 
way.  For  delineating  these  concepts,  in  the  next 
task are deduced lexical relations following lexical 
networks  formulated  by  WordNet  (Fellbaum 
1998). 
Once these lexical relations are established, the 
semantic  relations  are  proposed,  keeping  this  in 
mind,  for  example,  first-order  logic  to  represent 
predicate-arguments  structures.  The  final  process 
of this chain is to derive universal rules for build-
ing concepts, joining lexical and semantic relations 
deduced previously.
Thus, the recognition and extraction of concepts 
is  a  step  towards  the  general  goal  proposed  by 
Buitelaar, Cimiano & Magnini for building ontolo-
gies.  For this particular  phase,  our proposal  con-
sists  on identifying and extracting conceptual  in-
formation through lexical-syntactic patterns as we 
mentioned above.
6 Towards the (semi-)automatic identifica-
tion of lexical relations 
In agreement with the methodology of  Buitelaar, 
Cimiano & Magnini mentioned above, we propose 
to extract lexical relations from analytical defini-
tions for covering the next step about hierarchical 
relations.  Hiponymy/hypernymy  and 
meronym/holonymy relations are considered as re-
113
lations organizing a conceptual space in a hierarch-
ical way (Winston, Chaffin & Herrmann 1987). 
Additionally, our method provides a way to get 
more relations from a domain corpus through the 
application of a bootstrapping technique with the 
genus terms/wholes set as seed set.  
? Hyponymy/hyperonymy relations: We 
consider works such as Hearst (1992), as 
well as Wilks, Slator & Guthrie (1995), 
because  their  methods  allow combining 
linguistic and probabilistic criteria. 
? Part/whole  relations:  In  this  case,  we 
consider  works  such  as  Charniak  & 
Berland (1999),  as well  as those results 
reported  by  Girju,  Badulescu  &  Mod-
olvan (2006). We propose a method ex-
ploiting the pattern with preposition  de, 
due to its use frequency to link parts and 
wholes in Spanish. Table 6 shows exam-
ples about meronymy/holonymy relations 
using  this  pattern  compared  with  other 
patterns worked in the literature.
Table 7: Number of hits returned by the search en-
gine Google
Part Whole X is part 
of Y
Y has 
X
X of the 
Y
Mouse Computer 27360 514 280400
Keyboard Computer 60800 64730 1798000
Screen Computer 58800 64100 556000
? Attribution  relations: Attribution  rela-
tions play an important role in disciplines 
involved  with  conceptual  representation 
as artificial intelligence/knowledge repre-
sentation,  linguistics  and  psychology 
(Poesio  &  Almuhareb,  2005).   So,  we 
consider  the  work  about  the  automatic 
extraction  of  attribution  relations  pro-
posed  by  Poesio  &  Almuhareb (2004). 
They used an approach as that proposed 
by Charniak & Berland (1999) but to ex-
tract  attribution  relations  using  the  pat-
tern:
?the * of the C [is|was]?
Here, * represents a potential attribute for 
the concept C. In Spanish a common pat-
tern to express attribution relations is the 
use of the preposition  de, e.g.:  edad del  
paciente (Eng.  age  of  patient/patient's 
age),  altura del paciente  (Eng. height of 
the patient/ patient's height), and so on.
Summarizing, our methodology to extract lexical 
relations starts with the extraction of hyponymy-
hypernymy relations from analytical DCs. For this 
phase  we  consider  a  lexical-syntactic  approach 
due to the regularity of the definition schemes us-
ing  predication  patterns  as  those  mentioned 
above. 
Additionally,  we  propose  a  bootstrapping 
technique starting with the set of genus terms as a 
seedset  to  extract  more  lexical  relations  from a 
domain corpus. We use the preposition de to link 
genus term and other potential terms due to its im-
portance to produce lexical relations of our inter-
est. 
For example, in a first phase exploring a do-
main corpus, a genus term as dilataci?n (Eng. di-
lation)  links  with  a  set  of  two elements  {vena,  
pupila} (Eng. {vein, pupil}). In a next phase, the 
element pupila is linked to ojo (Eng. eye), and so 
on. Thus, on the one hand we have two relations 
IS-KIND-OF:  dilataci?n de la pupila and  dilat-
aci?n de la vena. On the other hand, we have a 
meronymy-holonymy relation: pupila-ojo.
Integrating the three relations described above, 
we will  implement  a  lexical  network that  allows 
organizing concepts related to terms. An example 
of this possible network is:
Figure 3: Example of a possible lexical network
In the figure, we can distinguish a set of sub?terms 
linked  to  the  main  term  Ojo (Engl.  Eye).  These 
114
sub?terms operate as nodes, and the possible lexic-
al relations are branches connected with the main 
term. Thus, based on a lexical Parth/whole relation, 
we can infer that  c?rnea  (Eng. cornea), is a con-
stituent  of  eye.  In  contrast,  the  term  enfermedad 
(Engl.  disease) is an attribute of eye. Finally, the 
glaucoma is a type of disease that affects the eyes.
7 Work in progress and possible topics of 
collaborations 
In this paper we proposed a method for recogniz-
ing lexical relations, taking into account the identi-
fication  and  extraction  of  analytical  definitions 
situated into DCs in Spanish. This extraction con-
siders verbal predications associated to these defin-
itions. So, in order to explain this extraction, we 
have showed a formal syntactic analysis, based on 
the idea that  these predications:  (a)  could be de-
scribed in terms of predicative phrases, and (b), the 
association  of  predications  and  analytical  defini-
tions  has  a  high  frequency of  use  in  specialized 
documents. For evaluating this frequency, we have 
exposed the results obtained for an experiment of 
extraction in two technical corpora.
Currently, we are situated in the phase to imple-
ment  and evaluate  a new experiment  oriented to 
the detection of lexical relations between the term 
and the genus term formulated for analytical defin-
itions. In particular, we are interested in discover-
ing three types of relations: hyponym/hyperonymy, 
part-whole and attribution-entity.
We conclude suggesting some topics of collab-
orations for our potential colleges:
I. The construction of specialized texts 
corpora with good candidates of DCs, 
having in mind the basic features for 
identifying a DC.
II. The implementation of new linguistic 
and statistical methods for detecting 
and extracting lexical relations from 
text corpora.
III. The improvement of search systems, 
using these underlying lexical relations 
in electronic documents.
IV. Following to Wilks, Slator & Guthrie 
(1995), the design of lexical-semantic 
tags for recognizing and classifying 
concepts in taxonomies.
Similarly,  according  to  Buitelaar,  Cimiano  & 
Magnini, we can use external lexical resources as 
Spanish WordNet and Spanish FrameNet (Subirats 
2009) for  determining and evaluating our lexical 
networks,  in  order  to  enrich  the  results  that  we 
could generate.
Acknowledgments
This paper was made possible by the financial sup-
port  of  the  Consejo  Nacional  de  Ciencia  y  Tec-
nolog?a, CONACYT, and DGAPA?UNAM. Also, 
we  wish  to  thank  the  anonymous  reviewers  for 
theirs comments and suggestions.
References 
C?sar Aguilar, Rodrigo Alarc?n, Carlos Rodr?guez and 
Gerardo Sierra. 2004. Reconocimiento y clasificaci?n 
de patrones verbales definitorios en corpus especiali-
zados?. En Cabre T., Estop? R. & Teb? C. (Eds.). La 
terminolog?a en el siglo XXI, IULA-UPF, Barcelona, 
Spain: 259-269.
C?sar Aguilar. 2009. An?lisis ling??stico de definiciones  
en contextos definitorios.  Ph. D. Thesis, Department 
of Linguistics, UNAM, Mexico.
Rodrigo  Alarc?n,  Gerardo  Sierra  and  Carme  Bach. 
2007. Developing a Definitional Knowledge Extrac-
tion System.  Conference Proceedings of Third Lan-
guage  &  Technology  Conference  LTC'07,  Pozna?, 
Poland.
John  Bowers.  1993.  The  Syntax  of  Predication,  Lin-
guistic Inquiry, 24(4): 591-636.
John  Bowers.  2001.  Predication.  In  Baltin,  M.  & 
Collins,  C. (eds.),  The Handbook of  Contemporary  
Syntactic Theory, Blackwell, Oxford, UK: 299-333.
Paul  Buitelaar,  Philipp  Cimiano  and  Bruno  Magnini. 
2005. Ontology learning from text. IOS Press, Ams-
terdam, The Netherlands.
Eugene Charniak and Matthew Berland. 1999. Finding 
parts in very large corpora.  Proceedings of the 37th 
Annual  Meeting  of  the  Association  for  Computa-
tional Linguistics: 57-64.
Christiane  Fellbaum.  1998.  WordNet:  An  Electronic 
Lexical Database, MIT Press, Cambridge, Mass.
Roxana Girju, Adriana Badulescu and Dan I. Moldovan. 
2006. Automatic Discovery of Part?Whole Relations. 
Computational Linguistics, 32(1): 83-135.
Marti  Hearst.  1992.  Automatic  Acquisition  of 
Hyponyms from Large Text Corpora. Proceedings of  
the Fourteenth International Conference on Compu-
tational Linguistics, Nantes, France.
Marie-Claude  L?Homme  and  Patrick  Drouin.  2006. 
Corpus de Inform?tica para el espa?ol, Groupe ?k-
115
lectick, OLST-Universit? de Montr?al, Montr?al, Ca-
nada: http://www.olst.umontreal.ca/. 
Alfonso Medina, Gerardo Sierra, Gabriel Gardu?o, Car-
los  M?ndez  and  Roberto  Salda?a.  2004.  CLI:  An 
Open Linguistic Corpus for Engineering. In De Ita, 
G. Fuentes, O. & Galindo, M. (Eds.) Proceedings of  
IX  Ibero-American  Workshop  on  Artificial  Intelli-
gence, Puebla, BUAP: 203-208.
Massimo Poesio  and  Abdulrahman  Almuhareb.  2004. 
Feature-Based vs. property-based KR: An empirical 
perspective. In  Proceedings of International Confer-
ence  on  Formal  Ontology  in  Information  Systems  
FOIS 2004, Torino, Italy.
Ellen  Riloff  and  Jessica  Shepherd.  1999.  A  corpus-
based  bootstrapping  algorithm for  Semi-Automated 
semantic  lexicon  construction. Journal  of  Natural  
Language Engineering . 5(2): 147-156. 
Carlos Rodr?guez. 2004. Metalinguistic Information Ex-
traction  from  specialized  texts  to  enrich  computa-
tional lexicons.  Ph. D. Thesis, Universidad Pompeu 
Fabra, Barcelona, Spain.
Gerardo  Sierra,  Rodrigo  Alarc?n  and  C?sar  Aguilar. 
2006.  Extracci?n  autom?tica  de  contextos  definito-
rios en textos especializados.  In Inchaurralde,  C. & 
Ibarretxe, I. (Eds.). Memorias del XXII Congreso de  
la  Sociedad  Espa?ola  para  el  Procesamiento  del  
Lenguaje Natural, University of Zaragoza, Zaragoza, 
Spain: 351-352.
Gerardo  Sierra,  Rodrigo  Alarc?n,  C?sar  Aguilar  and 
Carme Bach. 2008.  Definitional Verbal  Patterns for 
Semantic  Relation Extraction.  In  Auger  A.  & Bar-
ri?re C. (Eds.), Pattern-based Approaches to Semant-
ic Relation Extraction. Special issue of Terminology, 
14(1): 74?98.
Carlos Subirats (2009). Spanish Framenet: A frame se-
mantic analysis of the Spanish lexicon. In Boas H. 
(Ed.),  Multilingual  FrameNets  in  Computational  
Lexicography. Methods and Applications, Mouton de 
Gruyter, Berlin/New York:  135-162.
Yorick Wilks, Brian Slator and Louise Guthrie.  1996. 
Electric Words. MIT Press, Cambridge, Mass.
Morton  E.  Winston, Roger  Chaffin  and  Douglas  Her-
rmann.  1987.  A  taxonomy of  part-whole  relations. 
Cognitive Science, 11(4): 417 ? 444.
116
Proceedings of the Fifth Law Workshop (LAW V), pages 1?10,
Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational Linguistics
On the Development of the RST Spanish Treebank 
Iria da Cunha Juan-Manuel Torres-Moreno Gerardo Sierra 
Institute for Applied 
Linguistics (UPF), Spain 
Laboratoire Informatique 
d?Avignon (UAPV), France 
Instituto de Ingenier?a (UNAM), 
Mexico 
Instituto de Ingenier?a 
(UNAM), Mexico 
Instituto de Ingenier?a (UNAM), 
Mexico 
gsierram@iingen.unam.
mx 
Laboratoire Informatique 
d?Avignon (UAPV), France 
?cole Polytechnique de Montr?al, 
Canada 
 
iria.dacunha@upf.edu juan-manuel.torres@univ-
avignon.fr 
 
 
 
Abstract 
In this article we present the RST Spanish 
Treebank, the first corpus annotated with 
rhetorical relations for this language. We 
describe the characteristics of the corpus, 
the annotation criteria, the annotation 
procedure, the inter-annotator agreement, 
and other related aspects. Moreover, we 
show the interface that we have developed 
to carry out searches over the corpus? 
annotated texts. 
1 Introduction 
The Rhetorical Structure Theory (RST) (Mann and 
Thompson, 1988) is a language independent theory 
based on the idea that a text can be segmented into 
Elementary Discourse Units (EDUs) linked by 
means of nucleus-satellite or multinuclear 
rhetorical relations. In the first case, the satellite 
gives additional information about the other one, 
the nucleus, on which it depends (ex. Result, 
Condition, Elaboration or Concession). In the 
second case, several elements, all nuclei, are 
connected at the same level, that is, there are no 
elements dependent on others and they all have the 
same importance with regard to the intentions of 
the author of the text (ex. Contrast, List, Joint or 
Sequence). The rhetorical analysis of a text by 
means of RST includes 3 phases: segmentation, 
detection of relations and building of hierarchical 
rhetorical trees. For more information about RST 
we recommend the original article of Mann and 
Thompson (1988), the web site of RST1 and the 
RST review by Taboada and Mann (2006a). 
RST has been used to develop several 
applications, like automatic summarization, 
information extraction (IE), text generation, 
question-answering, automatic translation, etc. 
(Taboada and Mann, 2006b). Nevertheless, most of 
these works have been developed for English, 
German or Portuguese. This is due to the fact that 
at present corpora annotated with RST relations are 
available only for these languages (for English: 
Carlson et al, 2002, Taboada and Renkema, 2008; 
for German: Stede, 2004; for Portuguese: Pardo et 
al., 2008) and there are automatic RST parsers for 
two of them (for English: Marcu, 2000; for 
Portuguese: Pardo et al, 2008) or automatic RST 
segmenters (for English: Tofiloski et al, 2009). 
Scientific community working on RST applied to 
Spanish is very small. For example, Bouayad-Agha 
et al (2006) apply RST to text generation in 
several languages, Spanish among them. Da Cunha 
et al (2007) develop a summarization system for 
medical texts in Spanish based on RST. Da Cunha 
and Iruskieta (2010) perform a contrastive analysis 
of Spanish and Basque texts. Romera (2004) 
analyzes coherence relations by means of RST in 
spoken Spanish. Taboada (2004) applies RST to 
analyze the resources used by speakers to elaborate 
conversations in English and Spanish.  
We consider that it is necessary to build a 
Spanish corpus annotated by means of RST. This 
corpus should be useful for the development of a 
rhetorical parser for this language and several other 
applications related to computational linguistics, 
like those developed for other languages 
                                                           
1 http://www.sfu.ca/rst/index.html 
1
(automatic translation, automatic summarization, 
IE, etc.). And that is what we pretend to achieve 
with our work. We present the development of the 
RST Spanish Treebank, the first Spanish corpus 
annotated by means of RST. 
In Section 2, we present the state of the art 
about RST annotated corpora. In Section 3, we 
explain the characteristics of the RST Spanish 
Treebank. In Section 4, we show the search 
interface we have developed. In Section 5, we 
establish some conclusions and future work. 
2 State of the Art 
The most known RST corpus is the RST Discourse 
Treebank, for English (Carlson et al, 2002a, 
2002b). It includes 385 texts of the journalistic 
domain, extracted from the Penn Treebank 
(Marcus et al, 1993), such as cultural reviews, 
editorials, economy articles, etc. 347 texts are used 
as a learning corpus and 38 texts are used as a test 
corpus. It contains 176,389 words and 21,789 
EDUs. 13.8% of the texts (that is, 53) were 
annotated by two people with a list of 78 relations. 
For annotation, the annotation tool RSTtool 2 
(O'Donnell, 2000) was used, with some 
adaptations. The principal advantages of this 
corpus stand on the high number of annotated texts 
(for the moment it is the biggest RST corpus) and 
the clarity of the annotation method (specified in 
the annotation manual by Carlson and Marcu, 
2001). However, some drawbacks remain. The 
corpus is not free, it is not on-line and it only 
includes texts of one domain (journalistic).  
For English there is also the Discourse 
Relations Reference Corpus (Taboada and 
Renkema, 2008). This corpus includes 65 texts 
(each one tagged by one annotator) of several types 
and from several sources: 21 articles from the Wall 
Street Journal extracted from the RST Discourse 
Treebank, 30 movies and books? reviews extracted 
from the epinions.com website, and 14 diverse 
texts, including letters, webs, magazine articles, 
newspaper editorials, etc. The tool used for 
annotation was also the RSTtool. The advantages 
of this corpus are that it is free and on-line, and it 
includes texts of several types and domains. The 
disadvantages are that the amount of texts is not 
very high, the annotation methodology is not 
                                                           
2 http://www.wagsoft.com/RSTTool/ 
specified and it does not include texts annotated by 
several people. 
Another well-known corpus is the Potsdam 
Commentary Corpus, for German (Stede, 2004; 
Reitter and Stede, 2003). This corpus includes 173 
texts on politics from the on-line newspaper 
M?rkische Allgemeine Zeitung. It contains 32,962 
words and 2,195 sentences. It is annotated with 
several data: morphology, syntax, rhetorical 
structure, connectors, correference and informative 
structure. Nevertheless, only a part of this corpus 
(10 texts), which the authors name "core corpus", 
is annotated with all this information. The texts 
were annotated with the RSTtool. This corpus has 
several advantages: it is annotated at different 
levels (the annotation of connectors is especially 
interesting); all the texts were annotated by two 
people (with a previous RST training phase); it is 
free for research purposes, and there is a tool for 
searching over the corpus (although it is not 
available on-line). The disadvantages are: the 
genre and domain of all the texts are the same, the 
methodology of annotation was quite intuitive 
(without a manual or specific criteria) and the 
inter-annotator agreement is not given. 
For Portuguese, there are 2 corpora, built in 
order to develop a rhetorical parser (Pardo et al, 
2008). The first one, the CorpusTCC (Pardo et al, 
2008), was used as learning corpus for detection of 
linguistic patterns indicating rhetorical relations. It 
contains 100 introduction sections of computer 
science theses (53,000 words and 1,350 sentences). 
To annotate the corpus a list of 32 rhetorical 
relations was used. The annotation manual by 
Carlson and Marcu (2001) was adapted to 
Portuguese. The annotation tool was the ISI RST 
Annotation Tool3 , an extension of the RSTtool. 
The advantages of this corpus are: it is free, it 
contains an acceptable number of texts and words 
and it follows a specific annotation methodology. 
The disadvantage is: it only includes texts of one 
genre and domain, only annotated by one person. 
The second one, Rhetalho (Pardo and Seno, 
2005), was used as reference corpus for the parser 
evaluation. It contains 50 texts: 20 introduction 
sections and 10 conclusion sections from computer 
science scientific articles, and 20 texts from the on-
line newspaper Folha de S?o Paulo (7 from the 
Daily section, 7 from the World section and 6 from 
                                                           
3 http://www.isi.edu/~marcu/discourse/ 
2
the Science section). It includes approximately 
5,000 words. The relations and the annotation tool 
are the same as those used in the CorpusTCC. The 
advantages of this corpus are that it is free, it was 
annotated by 2 people (they both were RST experts 
and followed an annotation manual) and it contains 
texts of several genres and domains. The main 
disadvantage is the scarce amount of texts. 
The Penn Discourse Treebank (Rashmi et al, 
2008)f for English includes texts annotated with 
information related to discourse structure and 
semantics (without a specific theoretical approach). 
Its advantages are: its big size (it contains 40,600 
annotated discourse relations) allows to apply 
machine learning, and the discourse annotations 
are aligned with the syntactic constituency 
annotations of the Penn Treebank. Its limitations 
are: dependencies across relations are not marked, 
it only includes texts of the journalistic domain, 
and it is not free. Although there are several 
corpora annotated with discourse relations, there is 
not a corpus of this type for Spanish. 
3 The RST Spanish Treebank  
As Sierra (2008) states, a corpus consists of a 
compilation of a set of written and/or spoken texts 
sharing some characteristics, created for certain 
investigation purposes. According to Hovy (2010), 
we use 7 core questions in corpus design, detailed 
in the next subsections. 
3.1 Selecting a Corpus 
For the RST Spanish Treebank, we wanted to 
include short texts (finally, the average is 197 
words by text; the longest containing 1,051 words 
and the shortest, 25) in order to get a best on-line 
visualization of the RST trees. Moreover, in the 
first stage of the project, we preferred to select 
specialized texts of very different areas, although 
in the future we plan to include also non-
specialized texts (ex. blogs, news, websites) in 
order to guarantee the representativity of the 
corpus. We did not find a pre-existing Spanish 
corpus with these characteristics, so we decided to 
build our own corpus. Following Cabr? (1999), we 
consider that a text is specialized if it is written by 
a professional in a given domain. According to this 
work, specialized texts can be divided in three 
levels: high (both the author and the potential 
reader of the text are specialists), average (the 
author of the text is a specialist, and the potential 
reader of that text is a student or someone 
interested in or possessing some prior knowledge 
about the subject) and low (the author of the text is 
a specialist, and the potential reader is the general 
public). The RST Spanish Treebank includes 
specialized texts of the three mentioned levels: 
high (scientific articles, conference proceedings, 
doctoral theses, etc.), average (textbooks) and low 
(articles and reports from popular magazines, 
associations? websites, etc.). The texts have been 
divided in 9 domains (some of them including 
subdivisions): Astrophysics, Earthquake 
Engineering, Economy, Law, Linguistics (Applied 
Linguistics, Language Acquisition, PLN, 
Terminology), Mathematics (Primary Education, 
Secondary Education, Scientific Articles), 
Medicine (Administration of Health Services, 
Oncology, Orthopedy), Psychology and Sexuality 
(Clinical Perspective, Psychological Perspective). 
The size of a corpus is also a polemic question. 
If the corpus is developed for machine learning, its 
size will be enough when the application we want 
to develop obtains acceptable percentages of 
precision and recall (in the context of that 
application). Nevertheless, if the corpus is built 
with descriptive purposes, it is difficult to 
determine the corpus size. In the case of a corpus 
annotated with rhetorical relations, it is even more 
difficult, because there are various factors 
involved: EDUs, SPANs (that is, a group of related 
EDUs), nuclearity and relations. In addition, 
relations are multiple (we use 28). As Hovy (2010: 
13) mentions, one of the most difficult phenomena 
to annotate is the discourse structure. Our corpus 
contains 52,746 words and 267 texts. Table 1 
includes RST Spanish Treebank statistics in terms 
of texts, words, sentences and EDUs. 
 
 Texts Words Sentences EDUs 
Learning corpus 183 41,555 1,759 2,655 
Test corpus  84 11,191 497 694 
Total corpus  267 52,746 2,256 3,349 
 
Table 1: RST Spanish Treebank statistics 
 
To increase the linear performance of a 
statistical method, it is necessary that the training 
corpus size grows exponentially (Zhao et al, 
2010). However, the RST Spanish Treebank is not 
designed only to use statistical methods; we think 
it will be useful to employ symbolic or hybrid 
3
algorithms (combining symbolic and statistical 
methods). Moreover, this corpus will be dynamic, 
so we expect to have a bigger corpus in the future, 
useful to apply machine learning methods. 
If we measure the corpus size in terms of words 
or texts, we can take as a reference the other RST 
corpora. Nevertheless, as Sierra states (2008), it is 
?absurd? to try to build an exhaustive corpus 
covering all the aspects of a language. On the 
contrary, the linguist looks for the 
representativeness of the texts, that is, tries to 
create a sample of the studied language, selecting 
examples which represent the linguistic reality, in 
order to analyze them in a pertinent way. In this 
sense and in the frame of this work, we consider 
that the size will be adequate if the rhetorical trees 
of the corpus include a representative number of 
examples of rhetorical relations, at least 20 
examples of each one (taking into account that the 
corpus contains 3115 relations, we consider that 
this quantity is acceptable; however, we expect to 
have even more examples when the corpus grows).  
Table 2 shows the number of examples of each 
relation currently included into the RST Spanish 
Treebank (N-S: nucleus-satellite relation; N-N: 
multinuclear relation). As it can be observed, it 
contains more than 20 examples of most  of the  
relations. The exceptions are the nucleus-satellite 
relations of Enablement, Evaluation, Summary,  
Otherwise and  Unless, and the multinuclear 
relations of Conjunction and Disjunction, because 
it is not so usual to find these rhetorical relations in 
the language, in comparison with others. Hovy 
(2010: 128) states that, given the lack of examples 
in the corpus, there are 2 possible strategies: a) to 
leave the corpus as it is, with few or no examples 
of some cases (but the problem will be the lack of 
training examples for machine learning systems), 
or b) to add low-frequency examples artificially to 
?enrich? the corpus (but the problem will be the 
distortion of the native frequency distribution and 
perhaps the confusion of machine learning 
systems). In the current state of our project, we 
have chosen the first option. We think that, 
including specialized texts in a second stage, we 
will get more examples of these less common 
relations. If we carry out a more granulated 
segmentation maybe we could obtain more 
examples; however, we wanted to employ the 
segmentation criteria used to develop the Spanish 
RST discourse segmenter (da Cunha et al, 2011). 
 
Quantity Relation Type 
N? % 
Elaboration N-S 765 24.56 
Preparation N-S 475 15.25 
Background N-S 204 6.55 
Result N-S 193 6.20 
Means N-S 175 5.62 
List N-N 172 5.52 
Joint N-N 160 5.14 
Circumstance N-S 140 4.49 
Purpose N-S 122 3.92 
Interpretation N-S 88 2.83 
Antithesis N-S 80 2.57 
Cause N-S 77 2.47 
Sequency N-N 74  2.38 
Evidence N-S 59 1.89 
Contrast N-N 58 1.86 
Condition N-S 53 1.70 
Concession N-S 50 1.61 
Justification N-S 39 1.25 
Solution N-S 32 1.03 
Motivation N-S 28 0.90 
Reformulation N-S 22 0.71 
Otherwise N-S 3 0.10 
Conjunction N-N 11 0.35 
Evaluation N-S 11 0.35 
Disjunction N-N 9 0.29 
Summary N-S 8 0.26 
Enablement  N-S 5 0.16 
Unless N-S 2 0.06 
 
Table 2: Rhetorical relations in RST Spanish Treebank 
 
3.2 Instantiating the Theory 
Our segmentation and annotation criteria are very 
similar to the original ones used by Mann and 
Thompson (1988) for English, and by da Cunha 
and Iruskieta (2010) for Spanish. We also explore 
the annotation manual for English by Carlon and 
Marcu (2001). Though we use some of their 
postulates, we think that their analysis is too 
meticulous in some aspects. Because of this, we 
consider that it is not adjusted to our interest, 
which is the finding of the simplest and most 
objective annotation method, orientated to the 
4
future development of a rhetorical parser for 
Spanish. To sum up, our segmentation criteria are:  
 
a) All the sentences of the text are segmented as 
EDUs (we consider that a sentence is a textual 
passage between a period and another period, a 
semicolon, a question mark or an exclamation 
point; texts? titles are also segmented). Exs.4 
 
[?stas son las razones fundamentales que motivaron 
este trabajo.] 
      [These are the fundamental reasons which motivated this 
work.] 
[Estudio de caso ?nico sobre violencia conyugal] 
      [Study of a case on conjugal violence] 
 
b) Intra-sentence EDUs are segmented, using the 
following criteria: 
 
b1) An intra-sentence EDU has to include a finite 
verb, an infinitive or a gerund. Ex.  
 
[Siendo una variante de la eliminaci?n Gaussiana,] 
[posee caracter?sticas did?cticas ventajosas.] 
      [Being a variant of Gaussian elimination,] [it possesses 
didactic profitable characteristics.] 
 
b2) Subject/object subordinate clauses or 
substantive sentences are not segmented. Ex.  
 
[Se muestra que el modelo discreto en diferencias finitas 
es convergente y que su realizaci?n se reduce a resolver 
una sucesi?n de sistemas lineales tridiagonales.] 
      [It appears that the discreet model in finite differences is 
convergent and that its accomplishment is to solve a 
succession of tridiagonal linear systems.] 
 
b3) Subordinate relative clauses are not segmented. 
Ex. 
 
[Durante el proceso, que utiliza solo aritm?tica entera, 
se obtiene el determinante de la matriz de coeficientes 
del sistema, sin necesidad de c?lculos adicionales.] 
       [During the process, which only uses entire arithmetic, the 
determinant of the system coefficient matrix is obtained, 
without  additional calculations.] 
 
b4) Elements in parentheses are only segmented if 
they follow the criterion b1. Ex.  
[Este a?o se cumple el bicentenario del nacimiento de 
Niels (Nicol?s, en nuestro idioma) Henrik Abel.] 
       [This year is the bicentenary of Niels's birth (Nicol?s, in 
our language) Henrik Abel.]     
b5) Embedded units are segmented by means of 
the non-relation Same-Unit proposed by Carlon 
and Marcu (2001). Figure 1 shows this structure. 
 
[En d?cadas precedentes se ha puesto de manifiesto,] [y 
as? lo han atestiguado muchos investigadores de la 
                                                           
4 Spanish examples were extracted from the corpus. English 
translations are ours. 
terminolog?a cient?fica serbia,] [una tendencia a 
importar pr?stamos del ingl?s.]  
        [In previous decades it has been shown,] [and it has been 
testified by many researchers of the scientific Serbian 
terminology,] [a trend to import loanwords from English.]  
 
 
Figure 1: Example of the non-relation Same-Unit 
3.3 Designing the Interface 
The annotation tool used in this work is the 
RSTtool, since it is free and easy to use. Therefore, 
we preferred to use it instead of designing a new 
one. Nevertheless, we have designed an on-line 
interface to include the corpus and to carry out 
searches over it (see Section 4). 
3.4 Selecting and Training the Annotators 
With regard to the corpus annotators, we have a 
team of 10 people (last year Bachelor?s degree 
students, Master?s degree students and PhDs) 5 . 
Before the annotation, they took a RST course of 6 
months (100 hours), where the segmentation and 
annotation methodology used for the development 
of the RST Spanish Treebank was explained.6 We 
called this period "training phase". The course had 
a theoretical and a practical part. In the theoretical 
part, some criteria with regard to the 3 phases of 
rhetorical analysis (segmentation, detection of 
relations, and rhetorical trees building) were given 
to annotators. In the practical part, firstly, it was 
explained how to use the RSTtool. Secondly, 
annotators extracted several texts from the web, 
following their personal interests, as for example, 
music, video games, cookery or art webs. They 
segmented those texts, using the established 
segmentation criteria. Once segmented, all the 
doubts and problematic examples were discussed, 
and they tried to get an agreement on the most 
complicated cases. Thirdly, the relations were 
                                                           
5  We thank annotators (Adriana Valerio, Brenda Castro, 
Daniel Rodr?guez, Ita Cruz, Jessica M?ndez, Josu? Careaga, 
Luis Cabrera, Marina Fomicheva and Paulina De La Vega) 
and interface developers (Luis Cabrera and Juan Rolland). 
6 This course was given in the framework of a last-year subject 
in the Spanish Linguistics Degree at UNAM (Mexico City).  
5
analyzed (using a given relations list) and, once 
again, annotators discussed the difficult cases. 
After the discussion, texts were re-annotated to 
verify if the difficulties were solved. This process 
was doubly interesting, since it helped to create 
common criteria for the annotation of the final 
corpus and to define the annotation criteria more 
clearly and consensually, in order to include them 
in the RST Spanish Treebank annotation manual. 
Once annotators agreed on the most difficult cases, 
we consider that the training phase finished. 
3.5 Designing and Managing the Annotation 
Procedure 
We start from the following annotation definition:  
 
Annotation (?tagging?) is the process of adding new 
information into source material by humans 
(annotators) or suitably trained machines. [...]. The 
addition process usually requires some sort of 
mental decision that depends both on the source 
material and on some theory or knowledge that the 
annotator has internalized earlier. (Hovy, 2010: 6) 
 
Exactly, after our annotators internalized the 
theory and annotation criteria during the training 
phase, the "annotation phase" of the final texts 
included in the RST Spanish Treebank started. In 
this phase, the annotation tasks were assigned to 
annotators (the number of texts assigned to each 
annotator was different, depending on their 
availability). They were asked to carry out the 
annotation individually and without questions 
among them. We calculated that the average time 
to carry out the annotation of one text was between 
15 minutes and 1 hour. This time difference is due 
to the fact that the corpus includes both short and 
long texts. The annotation process is the following: 
once a text is segmented, rhetorical relations 
between EDUs are annotated. First, EDUs inside 
the same sentence are annotated in a binary way. 
Second, sentences inside the same paragraph are 
linked. Finally, paragraphs are linked.  
Hovy (2010) states that it is difficult to 
determine if, for the same money (we add ?for the 
same time?), it is better to double-annotate less, or 
to single-annotate more. As he explains, Dligach et 
al. (2010) made an experiment with OntoNotes 
(Pradhan et al, 2007) verb sense annotation. The 
result was that, assuming the annotation is stable 
(that is, inter-annotator agreement is high), it is 
better to annotate more, even with only one 
annotator. The problem with RST annotation is 
that there are so many categories to annotate, that 
is very difficult to obtain a stable annotation. 
Therefore, we consider it is necessary to have at 
least some texts double-annotated (or even triple-
annotated), in order to have an adequate discourse 
corpus. This is the reason why, following the RST 
Discourse Treebank methodology, we use some 
texts as learning corpus and some others (from the 
Mathematics, Psychology and Sexuality domains) 
as test corpus: 69% (183 texts) and 31% (84 texts), 
respectively. The texts of the learning corpus were 
annotated by 1 person, whereas the texts of the test 
corpus were annotated by 2 people. 
3.6 Validating Results 
Da Cunha and Iruskieta (2010) measure inter-
annotator agreement by using the RST trees 
comparison methodology by Marcu (2000). This 
methodology evaluates the agreement on 4 
elements (EDUs, SPANs, Nuclearity and 
Relations), by means of precision and recall 
measures (an annotation with regard to the other 
one). Following this methodology, we have 
measured inter-annotator agreement over the test 
corpus. We employ an on-line automatic tool for 
RST trees comparison, RSTeval (Mazeiro and 
Pardo, 2009), where Marcu?s methodology has 
been implemented (for 4 languages: English, 
Portuguese, Spanish and Basque). We know that 
there are some other ways to measure agreement, 
such as Cohen's kappa (Cohen, 1960) or Fleiss's 
kappa (Fleiss, 1971), for example. Nevertheless, 
we consider that Marcu's methodology (2000) is 
suitable to compare adequately 2 annotations of the 
same original text, because it has been designed 
specifically for this task.  
For each trees pair from the test corpus, 
precision and recall were measured separately. 
Afterwards, all those individual results were put 
together to obtain general results. Table 3 shows 
global results for the 4 categories. The category 
with more agreement was EDUs (recall: 91.04% / 
precision: 87.20%), that is, segmentation. This 
result was expected, since the segmentation criteria 
given to the annotators were quite precise and the 
possibility of mistake was low. The lowest 
agreement was obtained for the category Relations 
(recall: 78.48% / precision: 76.81%). This result is 
lower than the other, but we think it is acceptable. 
In the RST Discourse Treebank the trend was 
similar to the one detected in our corpus: the 
6
highest agreement is obtained at the segmentation 
level and the lowest at the relations level. 
 
 
Category Precision Recall 
EDUs 87.20% 91.04% 
SPANs 86% 87.31% 
Nuclearity 82.46% 84.66% 
Relations 76.81% 78.48% 
 
Table 3: Inter-annotator agreement 
 
 
Precision and recall have not been calculated 
with respect to a gold standard because it does not 
exist for Spanish. Our future aim is to reach a 
consensus on the annotation of the test corpus 
(using an external "judge"), in order to establish a 
set of texts considered as a preliminary gold 
standard for this language. We consider that the 
annotations have quality at present, because inter-
annotator agreement is quite high; however, this 
consensus could solve the typical annotation 
mistakes we have detected or some ambiguities. 
We have analyzed the main discrepancy reasons 
between annotators. With regard to the 
segmentation, the main one was human mistake; 
ex. segmenting EDUs without a verb (one 
annotator segmented the following passage into 2 
EDUs because she detected a Means relation, but 
the second EDU does not include any verb): 
 
[Adem?s estudiamos el desarrollo de criterios para 
determinar si un semigrupo dado tiene dicha propiedad ] 
[mediante el estudio de desigualdades de curvatura-
dimensi?n. ]  
      [We also study the development of tests in order to 
determine if a given semi group has this property] [by means 
of curvature-dimension inequalities.]  
 
The second reason was that in the manual some 
aspects were not explained in detail. For example, 
if a substantive sentence or a direct/object clause 
(which must not be segmented, according to the 
point b2) includes two coordinated clauses, these 
must not be segmented either. Thus, we found 
some erroneous segmentations. For example: 
 
[Los hombres adultos tienen miedo de fracasar] [y no 
cumplir con el rol masculino de ser proveedores del 
hogar y de proteger a su familia.]  
      [Adult men are scared to fail] [and not to fulfill the 
masculine role of being the suppliers of the home and to 
protect their family.]  
 
This kind of mistakes allowed us to refine our 
segmentation manual a posteriori. In the future, we 
will ask the test corpus annotators to make a new 
annotation of the texts, using the refined manual, in 
order to check if the agreement increases, in the 
same way as the RST Discourse Treebank. 
With regard to rhetorical annotations, we 
detected 2 main reasons of inter-annotator 
disagreement. The first one was the ambiguity of 
some relations and their corresponding connectors; 
for example, Justification-Reason, Antithesis-
Concession or Circumstance-Means relations, like 
in the following passage (in Spanish, ?al? may 
indicate time or manner): 
 
[Los ni?os aprenden matem?ticas] [al resolver 
problemas.] 
      [Children learn mathematics] [when solving problems.] 
 
The second one is due to differences between 
annotators when determining nuclearity. For 
example, in the following passage, one annotator 
marked Background and the other one Elaboration: 
 
[Qued? un hueco en la pared de 60 x 
1.20cm.]S_Background [Norma y Andr?s quieren 
colocar en el hueco una pecera. ]N_Background 
 
[Qued? un hueco en la pared de 60 x 
1.20cm.]N_Elaboration [Norma y Andr?s quieren 
colocar en el hueco una pecera. ]S_Elaboration 
      [A hole of 60 x 1.20 cm remained in the wall.] [Norma and 
Andr?s want to place a fish tank in the hole.]  
 
It is easier to solve segmentation disagreement 
than relations disagreement, since in this case 
annotator subjectivity is more evident; we must 
consider how to refine our manual in this sense. 
3.7 Delivering and Maintaining the Product 
Hovy (2010) mentions some technical issues 
regarding these points: licensing, distribution, 
maintenance and updates. With regard to licensing 
and distribution, the RST Spanish Treebank will be 
free for research purposes. We have a data 
manager responsible for maintenance and updates.  
The description of the annotated corpus is also 
a very important issue (Ide and Pustejovsky, 2010). 
It is important to provide a high level description 
of the corpus, including the theoretical framework, 
the methodology (annotators, annotation manual 
and tool, agreement, etc.), the means for resource 
maintenance, the technical aspects, the project 
leader, the contact, the team, etc. The RST Spanish 
Treebank includes all this detailed information. 
XML (with a DTD) has been used, in order the 
corpus can be reused for several aplications. In the 
future, we plan to use the standard XCES. 
7
To know more about resources development, 
linguistic annotation or inter-annotator agreement, 
we recommend: Palmer et al (on-line), Palmer and 
Xue (2010), and Artstein and Poesio (2008). 
4 The Search Interface of the RST 
Spanish Treebank 
The RST Spanish Treebank interface is freely 
available on-line7. It allows the visualization and 
downloading of all the texts in txt format, with 
their corresponding annotated trees in RSTtool 
format (rs3), as well as in image format (jpg). Each 
text includes its title, its reference, its web link (if 
it is an on-line text) and its number of words. The 
interface shows texts by areas and allows the user 
to select a subcorpus (including individual files or 
folders containing several files). The selected 
subcorpus can be saved on local disk (generating a 
xml file) for future analyses.  
The interface includes a statistical tool which 
allows obtaining statistics of rhetorical relations in 
a subcorpus selected by the user. The RSTtool also 
offers this option but it can be only used for one 
text. We consider that it is more useful for the user 
to obtain statistics from various texts, in order to 
get significant statistical results. As the RSTtool, 
our tool allows to count the multinuclear relations 
in two ways: a) one unit for each detected 
multinuclear relation, and b) one unit for each 
detected nucleus. If we use b), the statistics of the 
multinuclear relations of Table 2 are higher: List 
(864), Joint (537), Sequence (289), Contrast (153), 
Conjunction (28) and Disjunction (24).  
We are developing another tool, aimed to 
extract information from the annotated texts, which 
we will soon include into the interface. This tool 
will allow to the user to select a subcorpus and to 
extract from it the EDUs corresponding to the 
rhetorical relations selected, like a multidocument 
specialized summarizer guided by user's interests.  
The RST Spanish Treebank interface also 
includes a screen which permits the users to send 
their own annotated texts. Our aim is for the RST 
Spanish Treebank to become a dynamic corpus, in 
constant evolution, being increased with texts 
annotated by users. This has a double advantage 
since, on the one hand, the corpus will grow and, 
on the other hand, users will profit from the 
                                                           
7 http://www.corpus.unam.mx/rst/ 
interface's applications, using their own 
subcorpora. The only requirement is to use the 
relations and the segmentation and annotation 
criteria of our project. Once the texts are sent, the 
RST Spanish Treebank data manager will verify if 
the annotation corresponds to these criteria. 
5 Conclusions and Future Work 
We think that this work means an important step 
for the RST research in Spanish, and that the RST 
Spanish Treebank will be useful to carry out 
diverse researches about RST in this language, 
from a descriptive point of view (ex. analysis of 
texts from different domains or genres) and an 
applied point of view (development of discourse 
parsers and NLP applications, like automatic 
summarization, automatic translation, IE, etc.).  
For the moment the corpus' size is acceptable 
and, though the percentage of double-annotated 
texts is not very high, we think that having 10 
annotators (using the same annotation manual) 
avoids the bias of only one annotator. In addition, 
the corpus includes texts of diverse domains and 
genres, which provides us with a heterogeneous 
Spanish corpus. Moreover, the corpus interface 
that we have designed allows the user to select a 
subcorpus and to analyze it statistically. In 
addition, we think that it is essential to release a 
free corpus, on-line and dynamic, that is, in 
continuous growth. Nevertheless, we are conscious 
that our work still has certain limitations, which we 
will try to solve in the future. In the short term, we 
have 5 aims:  
 
a) To add one more annotator for the test corpus 
and to measure inter-annotator agreement. 
b) To use more agreement measures, like kappa. 
c) To reach a consensus on the annotation of the 
test corpus, in order to establish a set of texts 
considered as a preliminary gold standard. 
d) To finish and to evaluate the IE tool. 
e) To analyze the corpus to extract linguistic 
patterns for the automatic relations detection. 
 
In the long term, we consider other aims: 
 
f) To increase the corpus, by adding non-
specialized texts, and new domains and genres. 
g) To annotate all the texts by 3 people, to get a 
representative gold-standard for Spanish (this aim 
will depend on the funding of the project). 
 
8
References  
Ron Artstein, and Massimo Poesio. 2008. Survey 
Article: Inter-Coder Agreement for Computational 
Linguistics. Computational Linguistics, 34(4):555-
596. 
Nadjet Bouayad-Agha, Leo Wanner, and Daniel 
Nicklass. 2006. Discourse structuring of dynamic 
content. Procesamiento del lenguaje natural, 37:207-
213. 
M. Teresa Cabr? (1999). La terminolog?a: 
representaci?n y comunicaci?n. Barcelona: IULA-
UPF. 
Lynn Carlson and Daniel Marcu. 2001. Discourse 
Tagging Reference Manual. ISI Technical Report 
ISITR-545. Los ?ngeles: University of Southern 
California. 
Lynn Carlson, Daniel Marcu, and Mary Ellen 
Okurowski. 2002a. RST Discourse Treebank. 
Pennsylvania: Linguistic Data Consortium. 
Lynn Carlson, Daniel Marcu, and Mary Ellen 
Okurowski. 2002b. Building a Discourse-Tagged 
Corpus in the Framework of Rhetorical Structure 
Theory. In Proceedings of the 2nd SIGDIAL 
Workshop on Discourse and Dialogue, Eurospeech 
2001. 
Jacob Cohen. 1960. A coefficient of agreement for 
nominal scales. Educational and Psychological 
Measurement, 20(1):37-46 
Iria da Cunha, Eric SanJuan, Juan-Manuel Torres-
Moreno, Marina Lloberes, and Irene Castell?n. 2010. 
Discourse Segmentation for Spanish based on 
Shallow Parsing. Lecture Notes in Computer 
Science, 6437:13-23.  
Iria da Cunha, and Mikel Iruskieta. 2010. Comparing 
rhetorical structures of different languages: The 
influence of translation strategies. Discourse Studies, 
12(5):563-598.  
Iria da Cunha, Leo Wanner, and M. Teresa Cabr?. 2007. 
Summarization of specialized discourse: The case of 
medical articles in Spanish. Terminology, 13(2):249-
286.  
Dmitriy Dligach, Rodney D. Nielsen, and Martha 
Palmer. 2010. To Annotate More Accurately or to 
Annotate More. In Proceedings of the 4th Linguistic 
Annotation Workshop (LAW-IV). 48th Annual 
Meeting of the Association for Computational 
Linguistics. 
Joseph L. Fleis. 1971. Measuring nominal scale 
agreement among many raters. Psychological 
Bulletin, 76(5):378-382. 
Eduard Hovy. 2010. Annotation. A Tutorial. Presented 
at the 48th Annual Meeting of the Association for 
Computational Linguistics. 
Nancy Ide and Pustejovsky, J. (2010). What Does 
Interoperability Mean, anyway? Toward an 
Operational Definition of Interoperability. In 
Proceedings of the Second International Conference 
on Global Interoperability for Language Resources 
(ICGL 2010).  
William C. Mann, and Sandra A. Thompson. 1988. 
Rhetorical structure theory: Toward a functional 
theory of text organization. Text, 8(3):243-281. 
Daniel Marcu. 2000. The Theory and Practice of 
Discourse Parsing Summarization. Massachusetts: 
Institute of Technology. 
Mitchell P. Marcus, Beatrice Santorini, Mary A. 
Marcinkiewicz. 1993. Building a large annotated 
corpus of English: the Penn Treenbank. 
Computational Linguistics, 19(2):313-330. 
Michael O?Donnell. 2000. RSTTOOL 2.4 ? A markup 
tool for rhetorical structure theory. In Proceedings of 
the International Natural Language Generation 
Conference. 253-256. 
Martha Palmer, and Nianwen Xue. 2010. Linguistic 
Annotation. Handbook of Computational Linguistics 
and Natural Language Processing.  
Martha Palmer, Randee Tangi, Stephanie Strassel, 
Christiane Fellbaum, and Eduard Hovy (on-line). 
Historical Development and Future Directions in 
Data Resource Development. MINDS report. 
http://www-nlpir.nist.gov/MINDS/FINAL/data.web.pdf 
Sameer Pradhan, Eduard Hovy, Mitch Marcus, Martha 
Palmer, Lance Ramshaw, Ralph Weischedel. 2007. 
OntoNotes: A Unified Relational Semantic 
Representation. In Proceedings of the First IEEE 
International Conference on Semantic Computing 
(ICSC-07). 
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni 
Miltsakaki, Livio Robaldo, Aravind Joshi, and 
Bonnie Webber. 2008. The Penn Discourse Treebank 
2.0. In Proceedings of the 6th International 
Conference on Language Resources and Evaluation 
(LREC 2008). 
David Reitter, and Mandred Stede. 2003. Step by step: 
underspecified markup in incremental rhetorical 
analysis. In Proceedings of the 4th International 
9
Workshop on Linguistically Interpreted Corpora 
(LINC-03). 
Magdalena Romera. 2004. Discourse Functional Units: 
The Expression of Coherence Relations in Spoken 
Spanish. Munich: LINCOM. 
Thiago Alexandre Salgueiro Pardo, and Lucia Helena 
Machado Rino. 2001. A summary planner based on a 
three-level discourse model. In Proceedings of 
Natural Language Processing Pacific Rim 
Symposium. 533-538. 
Thiago Alexandre Salgueiro Pardo, Maria das Gra?as 
Volpe Nunes, and Lucia Helena Machado Rino. 
2008. DiZer: An Automatic Discourse Analyzer for 
Brazilian Portuguese. Lecture Notes in Artificial 
Intelligence, 3171:224-234.  
Thiago Alexandre Salgueiro Pardo, and Eloize Rossi 
Marques Seno. 2005. Rhetalho: um corpus de 
refer?ncia anotado retoricamente. In Anais do V 
Encontro de Corpora. S?o Carlos-SP, Brasil. 
Gerardo Sierra. 2008. Dise?o de corpus textuales para 
fines ling??sticos. In Proceedings of the IX Encuentro 
Internacional de Ling??stica en el Noroeste 2. 445-
462. 
Manfred Stede. 2004. The Potsdam commentary corpus. 
In Proceedings of the Workshop on Discourse 
Annotation, 42nd Meeting of the Association for 
Computational Linguistics. 
Maite Taboada. 2004. Building Coherence and 
Cohesion: Task-Oriented Dialogue in English and 
Spanish. Amsterdam/Philadelphia: John Benjamins. 
Maite Taboada, and Jan Renkema. 2008. Discourse 
Relations Reference Corpus [Corpus]. Simon Fraser 
University and Tilburg University. 
http://www.sfu.ca/rst/06tools/discourse_relations_cor
pus.html. 
Maite Taboada, and William C. Mann. 2006a. 
Rhetorical Structure Theory: Looking Back and 
Moving Ahead. Discourse Studies, 8(3):423-459.  
Maite Taboada, and William C. Mann. 2006b. 
Applications of Rhetorical Structure Theory. 
Discourse Studies, 8(4):567-588.  
Milan Tofiloski, Julian Brooke, and Maite Taboada. 
2009. A Syntactic and Lexical-Based Discourse 
Segmenter. In Proceedings of the 47th Annual 
Meeting of the Association for Computational 
Linguistics.  
Hai Zhao, Yan Song, and Chunyu Kit. 2010. How Large 
a Corpus Do We Need: Statistical Method Versus 
Rule-based Method. In Proceedings of the Seventh 
conference on International Language Resources and 
Evaluation (LREC'10). 
 
10
