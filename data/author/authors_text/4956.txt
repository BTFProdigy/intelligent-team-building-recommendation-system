An Extended Architecture for Robust  Generation* 
T i lman Becker ,  Anne  K i lger ,  Pat r i ce  Lopez ,  Peter  Po l le r  
DFK I  GmbH 
Stuh lsatzenhausweg 3 
D-66123 Saarbr i i cken ,  Germany 
{becker, kilger, lopez, poller}@dfki, de 
Abst rac t  
Based on our experiences in VERBMOBIL, a large 
scale speech-to-speech translation system, we iden- 
tify two types of problems that a generation com- 
ponent must address in a realistic implementation 
and present relevant examples. As an extension to 
the architecture ofa translation system, we present a
module for robustness preprocessing on the interface 
between translation and generation. 
1 In t roduct ion  
Based on our experiences with VERBMOBIL, a large 
scale speech-to-speech translation system, we iden- 
tify two types of problems that a generation com- 
ponent must address in a comprehensive implemen- 
tation. Besides general task-inherent problems like, 
e.g., the processing of spontaneous speech input, the 
translation step itself, and real-time processing, we 
found that an implementation of such a large scale 
system additionally exhibits technical problems that 
are caused by various faults in the steps prior to 
generation. 
The task of VERBMOBIL is the multi-lingual (Ger- 
man, English, Japanese) speaker-independent trans- 
lation of spontaneous peech input that enables 
users to converse about the scheduling of a busi- 
ness appointment including travel, accommodation, 
and leisure time planning in a multi-lingual dia- 
logue. The system covers 10,000 words in each 
language with the corresponding knowledge bases 
(grammars, translation rules, etc.). In contrast to 
a text translation system, the processing of spon- 
taneous speech requires extended functionalities in 
almost ever:,- module because the system has to be 
able do deal with, e.g., ill-formed and disfluent (hes- 
Due to the high complexity of this task, the sys- 
tem is subdivided into 24 separate subtasks (imple- 
mented modules). 
For the translation step the system contains 
four different parallel translation "tracks" consist- 
ing Of three "shallow" (case based, statistical, and 
dialogue-act based (Reithinger, 1999)) and one 
"deep" translation track (see figure 1) for each lan- 
guage. The individual translation results are partly 
associated with confidence values reflecting their 
quality and then sent to a special selection compo- 
nent to choose the most appropriate one. Our prac- 
tical experience shows that there are cases in which 
the input to the generation component is impossible 
to process. Here the shallow translation paths serve 
as a fall-back in order to fulfill the strong necessity 
of a translation result as far as possible. 
Although some parts of the analysis task (e.g., re- 
solving scopal ambiguities) can actually be left un- 
solved when they are not necessary for the transla- 
tion task, in general, problems in some module result 
in an accumulated inadequacy of the final transla- 
tion. 
Since the translation task is distributed to a set 
of cooperating modules, there is a choice of solving 
the task inherent and technical problems either lo- 
cally inside the individual modules or handing them 
to problem specific correction modules. We found 
that robustness must be included in every module. 
For the architecture of the generation module, we 
have devised a submodule for robustness that pre- 
processes the input data. This proved an elegant 
and promising extension to achieve the required local 
module robustness without touching tile core gener- 
ation module directly. A similar module also ex- 
ists for analysis (see 'Robust Semantics' in figure 1), 
itations, repetitions, repairs) speech input. In a dia- (Worm, 1998). 
logue system, there is also.anapparently simp! ebut :. ? In.this paper~ we,foeus..on the generation eompo- 
very strong constraint on the system to achieve its 
task: For each user input the system has to produce 
a translation result. 
" The research within VERBMOBIL presented here is funded 
by the German Ministry of Research and q~mhnology under 
grant 011\.'101K/1. 
nent of our system. Besides the general robustness 
requirements, the mentioned inadequacy accunmla- 
tion reaches its maxinmm since generation is posi- 
tioned at the end of the translation process. In the 
following sections, we show how the strong robust- 
ness requirement influenced the architecture of our 
63 
User 1 
Language A 
User 2 
Language B 
Speech 
777 W ..... 
Figure 1: Simplified system architecture of the speech-to-speech translation system VERBMOBIL. 
generation module. We classify the above mentioned 
problems from the point of view of generation and 
present our solutions to these problems, mainly un- 
der the aspect of robust generation with problematic 
input. 
2 Task - inherent  and  Techn ica l  
Prob lems 
The problems for generation that arise in a speech- 
to-speech translation system fall into two main 
classes: as in any large-scale system, there will 
be software-engineering problems which we will call 
technical problems and there are task-inherent prob- 
lems that are particular to the translation task and 
the highly variable input in spontaneous peech. 
Since it is impossible to draw a clear line be- 
tween technical and task-inherent problems, we will 
present a short classification and then go into more 
detail without much discussion whether a certain 
problem should be viewed as technical or task- 
inherent. 
One would hope to be able to eliminate technical 
problems completely. However, in a large system, 
where development is distributed over many mod- 
ules (implemented at different sites), some robust- 
ness against certain technical problems can become 
a necessity, as our experiences have shown. This is 
even more important during the development phase- 
which a research system never leaves. Most technical 
problems have to do with violations of the interface 
definitions. Thisranges. from simple ~things uch as 
using unknown predicates in the semantic represen- 
tation to complex constructions that cannot be gen- 
erated (the generation gap). We actually regard the 
latter as a task-inherent problem. 
Secondly, tile task-inherent problems can be di- 
vided into problems that are caused by (i) spon- 
taneous speech input and (ii) insufficiencies in the 
analysis and translation steps. 
2.1 Robustness  in Ana lys i s  
The problems in (i) are quite varied and many cases 
are dealt with in analysis (and translation), some 
cases are dealt with in our robustness preprocess- 
ing submodule, a few in the classical submodules of 
generation. For example, there is a separate mod- 
ule on the level of speech recognition which deals 
with hesitations and self-corrections. Phenomena 
like ellipsis, phrasal and other incomplete utterances 
are handled by analysis, so generation must be able 
to deal with the corresponding semantic representa- 
tions too. Agreement errors are handled (i.e., cor- 
rected) in analysis. But some serious syntactic errors 
cannot be corrected. However, at least the maxi- 
mal analyzable segments are determined so that un- 
grammatical utterances are translated as sequences 
of several meaningful segments. 
2.2 Robustness  in Generat ion  
The problems in (ii) are caused by an accunmla- 
tion of problems which result in (semantic) input to 
the generator that cannot be processed. Robustness 
in our system concentrates on this type of problenl 
which is and should be handled as a separate step 
between analysis/transfer and generation. (See the 
discussion of the architecture in section 3.) 
The list below contains some examples that are 
picked up again in section 4. 
* Problems with the structure of the semantic rep- 
resentation: 
- unconnected subgraphs 
- multiple predicates referring to the same 
object 
64 
- omission of obligatory arguments 
? Problems with the content of the semantic rep- 
resentation: 
- contradicting information 
- missing information (e.g. agreement infor- 
mation) 
3 Arch i tecture  
As described in section t, the  deep processing in 
VERBMOBIL is based on a pipeline of modules which 
use a unique interface language (VIT 1) that incorpo- 
rates a semantic representation. Since this seman- 
tic representation is obviously grammar-independent 
and could reflect the effects of spoken, spontaneous 
language, we have no guarantee that the gram- 
mar covers the semantic representation given by the 
transfer module. Consequently we have chosen to 
extend the classical generation architecture with a 
new module dedicated to robust preprocessing. We 
first present our classical generator architecture (see 
also (Becker et al, 1998; Becker et al, 2000)) in 
terms of the RAGS architecture and then discuss its 
extension to the task-inherent problems. 
The RAGS architecture (Cahill et al, 1999) is a 
reference architecture for natural language genera- 
tion systems. Reflecting the common parts of natu- 
ral language generation systems, this proposal aims 
to provide a standard architecture allowing the iden- 
tification of some important generation subtasks and 
resources. By presenting our system in the light of 
the RAGS specifications, our goal is to propose gen- 
eral solutions that could be used by other researchers 
who need to extend their own generation architec- 
ture to similar tasks. 
While the macro-planning task is important and 
mandatory in text generation, it is limited in dia- 
logue translation. Most of the related problems, for 
instance the sentence segmentation a d the pronoun 
choices, have been solved by the user in the source 
language. Considering the RAGS architecture, con- 
ceptual and rhetorical evels of representation are 
also outside the scope of our system. Our architec- 
ture consists of four main modules (see figure 2). 
For an easy adaptation to other domains and lan- 
guages, we have emphasized an organization based 
on a general kernel system and the declarativity of 
knowledge sources (Becker et al, 1998). All but the 
first modules are captured by the RAGS architec- 
ture. However, the first module is dedicated solely 
to robustness in the specific speech-to-speech trans- 
lation task and will be presented and discussed last 
in this section. It can easily be added to a RAGS- 
like system whose whiteboard is perfectly suited for 
lVerbmobil Interface Term, (Bos et al, 1996; Dorna, 
1996) 
the transformations that the robustness preprocess- 
ing module performs. 
Robustness 
Preprocessing 
Module 
Standard 
Generation 
Module 
Repairing Strutural 
kx~.~ss ing  GHae~risfics for Generation J 
(%e:::::: 
Selecting Planning Ru les~ 
Checking Lexical Choice J 
C0nstraints . - ~ . .  
e Selecting LTAG Trees 
e Tree Combination 
? Inflection 
e Synthesis Annotation 
Figure 2: An extended generation system architec- 
ture 
M ic rop lann ing  Modu le  At the level of sentence 
generation, the quality of the planning process de- 
pends on the interdependencies between conceptual 
semantics, predicative semantics and syntax. A par- 
ticular lexical choice can imply constraints on other 
lexical items. The role of the microplanner is to re- 
alize lexical choices in a way that a syntactic realiza- 
tion is possible and costly backtracking is prevented. 
The microplanning task can be viewed as a con- 
straint solving problem and implemented using an 
adapted constraint solving mechanism in order to 
achieve efficiency, flexibility, and declarativity of 
knowledge. The microplanner produces a depen- 
dency tree representation i dicating for each node 
a set of syntactical constraints to be fulfilled by 
the corresponding lexical syntactic units (predicate, 
tense, aspect, mood, etc.). 
Syntact ic  Rea l izat ion Modu le  This module is 
in charge of the concrete syntax generation. The 
processing is .based ,on a fully lexicatized Tree- 
Adjoining Grammar derived from the HPSG gram- 
mar used in the deep-processing parser module 
(Kasper~et aL, 1995; Becker, 1998). 
S u r f a c e  Real izat ion  Modu le  The syntactic re- 
alization module produces a derived tree from which 
tile output string is extracted. The morphological 
features in preterminal nodes are used for inflection. 
The surface string is also annotated by syntactic in- 
formation (phrase boundary, aspect, sentence mood) 
65 
that are exploited by the speech synthesis module. 
Robustness Preprocess ing  Modu le  We have 
described three modules corresponding to classical 
tasks of generation systems and pointed out at the 
beginning of this section the necessity for robustness. 
Where can we integrate the required robustness in 
such a generation architecture? One approach could 
be the relaxation of constraints during the syntac- 
tic realization (relaxing word order or/and depen- 
dency relations). One can argue against this ap- 
proach that: 
clearly separated from the microplanning rules, jus- 
tifying our presentation of robustness as a separate 
module. 
4.2 Conforming  to the Interface Language 
Definition 
The definition of the interface language 2 comprises 
only its syntax and some semantic constraints. 
There is an implementation of expressions in the in- 
terface language as an abstract data type which can 
at least check syntactic conformity (Dorna, 1996). 
But we also have to deal with semantic faults. 
-*. There is no .straightf~r~ard~Way~t~Aimi.t~he.J~e~.:.~.~`-~,;~T~f~rs~e~amp~e~i~''minating>r`0bust~pre~r~ess- 
laxation of syntactic onstraints only to the ro- 
bustness problematic structures. 
? We must be sure that the microplanning module 
can deal with problematic semantic input. 
These points suggest to check and repair the 
inconsistencies of the semantic representation as 
early as possible, i.e., before sentence microplanning. 
Moreover we show in the next section that most of 
the problems presented in section 2 can be identified 
based on the microplanner input. 
We now present more concretely the robust pre- 
processing module. 
4 Robustness  
In this section we describe the types of problems 
defined in section 2 using examples from our system 
and discuss how our module is made robust enough 
to handle a lot of these problems. 
Before the semantic representation is handed to 
microplanning, the robustness preproeessing module 
of the generator checks the input, inspecting its parts 
for known problems. For each problem found, the 
preprocessor lowers a confidence value for the gen- 
eration output which measures the reliability of our 
result. In a number of cases, we use heuristics to fix 
problems, aiming at improved output. 
As discussed in section 2, problems in the input 
to the generator can be technical or task-inherent. 
Technical problems manifest themselves as faults 
wrt. the interface language definition, whereas the 
task-inherent problems concern mismatches between 
a specific semantic expression and the coverage of 
the natural language grammar used in the genera- 
tor. These mismatches are known as the generation 
gap (Meteer, 1990). 
4.1 Dec la ra t iv i ty  
In..our implementation; the  :robustness module is 
partly integrated into the constraint solving ap- 
proach of the microplanning module. Using the con- 
straint solving approach allows for a strict separa- 
tion of algorithms (i.e., some constraint solving al- 
gorithln) and declarative knowledge sources. On this 
level, the rules (constraints) for robustness can be 
ing is on the connectedness of the semantic input 
graph. Our interface language describes an interface 
term to contain a connected semantic graph plus an 
index pointing to the root of the graph. Two types 
of problems can occur according to this definition: 
Disconnectedness of the Graph: The robust- 
ness preprocessor checks whether the input 
graph is in fact connected. If there are several 
disconnected parts, a distinct generation call 
is made for each subgraph. In the end, all 
sub-results are connected to produce a global 
result. We are currently working on a better 
heuristic to order the sub-results, taking into 
account information about the word order in 
the source language. 
Wrong Index:  The robustness preprocessor tests 
whether the index points to the root of the 
graph or one of the subgraphs. For each sub- 
graph without an adequate index, we compute 
a local root pointer which is used for further 
processing. This turned out to be an easy and 
reliable heuristic, leading to good results. 
There are several types of technical problems 
which cannot be repaired well. Minimally, these 
cases are detected, warning messages are produced, 
and the confidence value is lowered. We apply 
heuristics where possible. Examples are unique- 
ness of labels (every semantic predicate must have 
a unique identifier), the use of undefined predicate 
names, and contradicting information (e.g., the use 
of  a DEFINITE and an INDEFINITE quantifier for the 
same object). In the case of incorrect predicate 
classes, i.e., where a predicate is used with an unde- 
fined-argument frame, only those parts of the input 
are handled which are analyzed as correct. 
4.3 Fal l ing into the Generat ion  Gap 
The robustness preprocessor even does more than 
checking for structural contradictions between in- 
put and interface language. Based on analyses of 
2A further complication in a research system like ours 
s tems from the fact that the interface language itself is de- 
veloped, i.e., changed over time. 
66 
a large amount of test-suites it is fed with some 
heuristics which help to bridge the generation gap 
that reflects the unpredictability, whether_a specific 
semantic structure can be mapped to an acceptable 
utterance in the target language. Some examples of 
heuristics used in our system are as follows: 
Conf l ic t ing In fo rmat ion :  Often it is inconsistent 
to allow several predicates to include the same 
depending structure in their argument frames, 
e.g., two predicates describing different prepo- 
sitions should not point to the same entity. We 
have to pick one-,possibitity~heuristically: ........ 
Gaps  in Generat ion  Knowledge:  There are in- 
put configurations that have no reflection 
within the generator's knowledge bases, e.g., 
the DISCOURSE predicate defining a sequence 
of otherwise unrelated parts of the input. The 
robustness preprocessor removes this predicate, 
thereby subdividing the connected graph into 
several unconnected ones and continuing as for 
disconnected graphs described above. 
Other examples for generation constraints that 
can conflict with the input are the occurrence 
of some specific cyclic subparts of graphs, self- 
referring predicates, and chains of predicates 
which are not realizable in generation. 
Robustness  inside the  Microp lanner  and the  
Syntact i c  Generator  additionally helps to get rid 
of some generation gap problems: 
Cont rad ic t ions  to Generat ion  Constra ints :  
The knowledge bases of the generator (mi- 
eroplanning rules, grammar and lexicon) 
describe constraints on the structure of the 
output utterance that might conflict with the 
input. A common problem occuring in our 
system is the occurrence of subordinating 
predicates with empty obligatory arguments. 
Here the microplanner relaxes the constraint 
for argument completeness and hands over a 
structure to the syntactic generator that does 
not fulfill all syntactic constraints or contains 
elliptical arguments. In these cases, the gram- 
mar constraints for obligatory arguments are 
relaxed in the syntactic generator and elliptical 
arguments are allowed.beyond the constraints 
of the grammar. The result is often output that 
reflects the spontaneous speech input which we 
accept for the sake of robustness. 
M iss ing  a t t r ibutes :  Often there are obligatory at- 
tributes for the semantic predicates missing in 
the input, e.g., statements about the direction- 
ality of prepositions, agreement information, 
etc. The generator uses heuristics to choose a 
value for its own. 
Cont rad ic t ions  on  the  Semant ic  Level: Some 
attributes may lead to conflicts during genera- 
tion,.e.g:, i f~ pronoun is given:as SORT~HUMAN 
and TYPE-~SPEAKER. The generator uses a 
heuristics to set the value of SORT in this case. 
So lv ing Part  o f  the  Ana lys i s  Task: Sometimes 
the input to the generator is underspecified in
a way that it can be improved easily by using 
simple heuristics to "continue analysis." A 
common example in. our system is an input 
expression like "on the third" which often is 
.... .. ~analyzed..as.. (ABSTR.,-NOM .A  OPal)(.3.).), e~-e,,..an 
elliptical noun with ordinal number 3. We 
add the sort TIME_DOFM 3 to the attributes of 
ABSTR_NOM SO that, e.g., a semantic relation 
TEMPORAL_OR_LOCAL is correctly mapped to 
the German preposition "an." 
4.4 How much robustness?  
There is a limit to the power of heuristics that we 
have determined using a large corpus of test data. 
Some examples for possible pitfalls: 
? When realizing "empty nominals" ABSTR_NOM 
as elliptical nouns, guessing the gender can 
cause problems: "Thursday is my free day ti " 
as FREE A DAY A ABSTR_NOM (with a reading 
as in "day job") might result in "*Donnerstag 
ist mein freies Tag ti." 
o Conflicts between sort and gender of a pronoun 
might be resolved incorrectly: "Es (English: 
'it') trifft sich ganz hervorragend" with PRON 
(GENDER:NTR, SORT~HUMAN) should not be 
translated as "#He is really great." 
Although the boundary beyond which deep trans- 
lation cannot be achieved even with heuristics is 
somewhat arbitrary, the big advantage of deep pro- 
cessing lies in the fact that the system 'knows' its 
boundaries and actually fails when a certain level of 
quality cannot be guaranteed. As discussed in sec- 
tion 1, in a dialogue system, a bad translation fight 
still be better than none at all, so one of the shallow 
modules can be selected when deep processing fails. 
5 Re la ted  Work  and  Conc lus ions  
VERB~;IOBIL also contains a component hat au- 
tomatically generates dialogue scripts and result 
summaries of the dialogues in all target languages 
(Alexandersson and Poller, 1998; Alexandersson and 
::Poller~ 2000 )~:: ~This component , uses the'generation 
modules of VERB1V\[OBIL for sentence generation as 
well as the translation system itself to achieve multi- 
linguality. To some extend, this task also benefits 
3DOFM: day of the month. Note that in this paper, the 
presentation of the semantic representation language is highly 
abstracted from tile actual interface language. 
67 
from the task inherent robustness features of the 
overall system and its modules which we described 
in this paper. 
Our problem classification also shows up in other 
generation systems. There is a multi-lingual gen- 
eration project (Uchida et al, 1999) that utilizes 
an interlingua-based semantic representation to gen- 
erate web-documents in different output languages 
from one common representation. Although techni- 
cal problems are less prominent, the task-inherent 
problems are almost he same. Again, the genera- 
R. Kasper, B. Kiefer, K. Netter, and K. Vijay- 
Shanker. 1995. Compilation of hpsg to tag. In 
. . . . .  Proceedings o f  .the:..33rd ~Aunual: Meeting :of the 
Association for Computational Linguistics, pages 
92-99, Cambridge, Mass. 
M.W. Meteer. t990. The "Generation Gap" - The 
Problem of Expressibility in Text Planning. Ph.D. 
thesis, Amherst, MA. BBN Report No. 7347. 
Norbert Reithinger. 1999. Robust information ex- 
traction in a speech translation system. In Pro- 
ceedings of EuroSpeech-99, pages 2427-2430. 
tot has to able to deal with, e.g., disconnected or Hiroshi Uchida, Meiying Zhu, and Tarcisio Della 
? contradicting inpu't graphs: . . . . . . . . . . . . . . . . . . . .  ~" ~ Sieiiit~2 "1999.-UNL::~I~S;" U/iitei:l ~Na~i6hg"Ufii-~~ ::: - 
sity, Tokyo, Japan, November. 
Re ferences  
Jan Alexandersson and Peter Poller. 1998. Toward 
multilingual protocol generation for spontaneous 
speech dialogues. In Proceedings of the Ninth In- 
ternational Workshop on Natural Language Gen- 
eration, Niagara-on-the-Lake, Ontario, Canada, 
August. 
Jan Alexandersson and Peter Poller. 2000. Multi- 
lingual summary generation i a speech-to-speech 
translation system for multilingual negotiation di- 
alogues. In Proceedings of INLG 2000, Mitzpe Ra- 
mon, Israel, June. 
T. Becker, W. Finkler, A. Kilger, and P. Poller. 
1998. An efficient kernel for multilingual genera- 
tion in speech-to-speech dialogue translation. In 
Proceedings of COLING/A CL-98, Montreal, Que- 
bec, Canada. 
Tilman Becker, Anne Kilger, Patrice Lopez, and 
Peter Poller. 2000. Multilingual generation for 
translation in speech-to-speech dialogues and its 
realization in verbmobil. In Proceedings of ECAI 
2000, Berlin, Germany, August. 
Tihnan Becker. 1998. Fully lexicalized head- 
driven syntactic generation. In Proceedings of the 
Ninth International Workshop on Natural Lan- 
guage Generation, Niagara-on-the-Lake, Ontario, 
Canada, August. 
Johan Bos, Bj6rn Gambfi.ck, Christian Lieske, 
Yoshiki Mori, Manfred Pinkal, and Karsten 
Worm. 1996. Compositional semantics in verb- 
mobil. In Proceedings of Coling '96, Copenhagen, 
Denmark. 
Lynne Cahill, Christy Doran, Roger Evans, Chris 
Mellish, Daniel Paiva, Mike Reape, Donia Scott, 
and Neil Tipper. 1999. Towards a Reference Ar- 
chitecture for Natural Language: Generation Sys- 
tems. Technical Report ITRI-99-14, Information 
Technology Research Institute (ITRI), University 
of Brighton. 
Michael Dorna. 1996. The adt package for the verb- 
mobil interface term. Verbmobil-lrleport 104, Uni- 
versity Stuttgart, April. 
Karsten Worm. 1998. A model for robust processing 
of spontaneous speech by integrating viable frag- 
ments. In Proceedings of COLING-ACL '98, Mon- 
treal, Canada. 
68 
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 11?15,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Collaborative Machine Translation Service for Scientific texts
Patrik Lambert
University of Le Mans
patrik.lambert@lium.univ-lemans.fr
Jean Senellart
Systran SA
senellart@systran.fr
Laurent Romary
Humboldt Universita?t Berlin /
INRIA Saclay - Ile de France
laurent.romary@inria.fr
Holger Schwenk
University of Le Mans
holger.schwenk@lium.univ-lemans.fr
Florian Zipser
Humboldt Universita?t Berlin
f.zipser@gmx.de
Patrice Lopez
Humboldt Universita?t Berlin /
INRIA Saclay - Ile de France
patrice.lopez@inria.fr
Fre?de?ric Blain
Systran SA /
University of Le Mans
frederic.blain@
lium.univ-lemans.fr
Abstract
French researchers are required to fre-
quently translate into French the descrip-
tion of their work published in English. At
the same time, the need for French people
to access articles in English, or to interna-
tional researchers to access theses or pa-
pers in French, is incorrectly resolved via
the use of generic translation tools. We
propose the demonstration of an end-to-end
tool integrated in the HAL open archive for
enabling efficient translation for scientific
texts. This tool can give translation sugges-
tions adapted to the scientific domain, im-
proving by more than 10 points the BLEU
score of a generic system. It also provides
a post-edition service which captures user
post-editing data that can be used to incre-
mentally improve the translations engines.
Thus it is helpful for users which need to
translate or to access scientific texts.
1 Introduction
Due to the globalisation of research, the English
language is today the universal language of sci-
entific communication. In France, regulations re-
quire the use of the French language in progress
reports, academic dissertations, manuscripts, and
French is the official educational language of the
country. This situation forces researchers to fre-
quently translate their own articles, lectures, pre-
sentations, reports, and abstracts between English
and French. In addition, students and the general
public are also challenged by language, when it
comes to find published articles in English or to
understand these articles. Finally, international
scientists not even consider to look for French
publications (for instance PhD theses) because
they are not available in their native languages.
This problem, incorrectly resolved through the
use of generic translation tools, actually reveals
an interesting generic problem where a commu-
nity of specialists are regularly performing trans-
lations tasks on a very limited domain. At the
same time, other communities of users seek trans-
lations for the same type of documents. Without
appropriate tools, the expertise and time spent for
translation activity by the first community is lost
and do not benefit to translation requests of the
other communities.
We propose the demonstration of an end-to-end
tool for enabling efficient translation for scientific
texts. This system, developed for the COSMAT
ANR project,1 is closely integrated into the HAL
open archive,2 a multidisciplinary open-access
archive which was created in 2006 to archive pub-
lications from all the French scientific commu-
nity. The tool deals with handling of source doc-
ument format, generally a pdf file, specialised
translation of the content, and user-friendly user-
interface allowing to post-edit the output. Behind
1http://www.cosmat.fr/
2http://hal.archives-ouvertes.fr/?langue=en
11
the scene, the post-editing tool captures user post-
editing data which are used to incrementally im-
prove the translations engines. The only equip-
ment required by this demonstration is a computer
with an Internet browser installed and an Internet
connection.
In this paper, we first describe the complete
work-flow from data acquisition to final post-
editing. Then we focus on the text extraction pro-
cedure. In Section 4, we give details about the
translation system. Then in section 5, we present
the translation and post-editing interface. We fi-
nally give some concluding remarks.
The system will be demonstrated at EACL in
his tight integration with the HAL paper deposit
system. If the organizers agree, we would like to
offer the use of our system during the EACL con-
ference. It would automatically translate all the
abstracts of the accepted papers and also offers
the possibility to correct the outputs. This result-
ing data would be made freely available.
2 Complete Processing Work-flow
The entry point for the system are ?ready to pub-
lish? scientific papers. The goal of our system
was to extract content keeping as many meta-
information as possible from the document, to
translate the content, to allow the user to perform
post-editing, and to render the result in a format as
close as possible to the source format. To train our
system, we collected from the HAL archive more
than 40 000 documents in physics and computer
science, including articles, PhD theses or research
reports (see Section 4). This material was used to
train the translation engines and to extract domain
bilingual terminology.
The user scenario is the following:
? A user uploads an article in PDF format3 on
the system.
? The document is processed by the open-
source Grobid tool (see section 3) to extract
3The commonly used publishing format is PDF files
while authoring format is principally a mix of Microsoft
Word file and LaTeX documents using a variety of styles.
The originality of our approach is to work on the PDF file
and not on these source formats. The rationale being that 1/
the source format is almost never available, 2/ even if we had
access to the source format, we would need to implement a
filter specific to each individual template required by such or
such conference for a good quality content extraction
the content. The extracted paper is structured
in the TEI format where title, authors, refer-
ences, footnotes, figure captions are identi-
fied with a very high accuracy.
? An entity recognition process is performed
for markup of domain entities such as:
chemical compounds for chemical papers,
mathematical formulas, pseudo-code and ob-
ject references in computer science papers,
but also miscellaneous acronyms commonly
used in scientific communication.
? Specialised terminology is then recognised
using the Termsciences4 reference termi-
nology database, completed with terminol-
ogy automatically extracted from the train-
ing corpus. The actual translation of the pa-
per is performed using adapted translation as
described in Section 4.
? The translation process generates a bilingual
TEI format preserving the source structure
and integrating the entity annotation, multi-
ple terminology choices when available, and
the token alignment between source and tar-
get sentences.
? The translation is proposed to the user for
post-editing through a rich interactive inter-
face described in Section 5.
? The final version of the document is then
archived in TEI format and available for dis-
play in HTML using dedicated XSLT style
sheets.
3 The Grobid System
Based on state-of-the-art machine learning tech-
niques, Grobid (Lopez, 2009) performs reliable
bibliographic data extraction from scholar articles
combined with multi-level term extraction. These
two types of extraction present synergies and cor-
respond to complementary descriptions of an arti-
cle.
This tool parses and converts scientific arti-
cles in PDF format into a structured TEI docu-
ment5 compliant with the good practices devel-
oped within the European PEER project (Bretel et
al., 2010). Grobid is trained on a set of annotated
4http://www.termsciences.fr
5http://www.tei-c.org
12
scientific article and can be re-trained to fit tem-
plates used for a specific conference or to extract
additional fields.
4 Translation of Scientific Texts
The translation system used is a Hybrid Machine
Translation (HMT) system from French to En-
glish and from English to French, adapted to
translate scientific texts in several domains (so
far physics and computer science). This sys-
tem is composed of a statistical engine, cou-
pled with rule-based modules to translate spe-
cial parts of the text such as mathematical for-
mulas, chemical compounds, pseudo-code, and
enriched with domain bilingual terminology (see
Section 2). Large amounts of monolingual and
parallel data are available to train a SMT system
between French and English, but not in the scien-
tific domain. In order to improve the performance
of our translation system in this task, we extracted
in-domain monolingual and parallel data from the
HAL archive. All the PDF files deposited in HAL
in computer science and physics were made avail-
able to us. These files were then converted to
plain text using the Grobid tool, as described in
the previous section. We extracted text from all
the documents from HAL that were made avail-
able to us to train our language model. We built
a small parallel corpus from the abstracts of the
PhD theses from French universities, which must
include both an abstract in French and in English.
Table 1 presents statistics of these in-domain data.
The data extracted from HAL were used to
adapt a generic system to the scientific litera-
ture domain. The generic system was mostly
trained on data provided for the shared task of
Sixth Workshop on Statistical Machine Transla-
tion6 (WMT 2011), described in Table 2.
Table 3 presents results showing, in the
English?French direction, the impact on the sta-
tistical engine of introducing the resources ex-
tracted from HAL, as well as the impact of do-
main adaptation techniques. The baseline statis-
tical engine is a standard PBSMT system based
on Moses (Koehn et al 2007) and the SRILM
tookit (Stolcke, 2002). Is was trained and tuned
only on WMT11 data (out-of-domain). Incorpo-
rating the HAL data into the language model and
tuning the system on the HAL development set,
6http://www.statmt.org/wmt11/translation-task.html
Set Domain Lg Sent. Words Vocab.
Parallel data
Train cs+phys En 55.9 k 1.41 M 43.3 k
Fr 55.9 k 1.63 M 47.9 k
Dev cs En 1100 25.8 k 4.6 k
Fr 1100 28.7 k 5.1 k
phys En 1000 26.1 k 5.1 k
Fr 1000 29.1 k 5.6 k
Test cs En 1100 26.1 k 4.6 k
Fr 1100 29.2 k 5.2 k
phys En 1000 25.9 k 5.1 k
Fr 1000 28.8 k 5.5 k
Monolingual data
Train cs En 2.5 M 54 M 457 k
Fr 761 k 19 M 274 k
phys En 2.1 M 50 M 646 k
Fr 662 k 17 M 292 k
Table 1: Statistics for the parallel training, develop-
ment, and test data sets extracted from thesis abstracts
contained in HAL, as well as monolingual data ex-
tracted from all documents in HAL, in computer sci-
ence (cs) and physics (phys). The following statistics
are given for the English (En) and French (Fr) sides
(Lg) of the corpus: the number of sentences, the num-
ber of running words (after tokenisation) and the num-
ber of words in the vocabulary (M and k stand for mil-
lions and thousands, respectively).
yielded a gain of more than 7 BLEU points, in
both domains (computer science and physics). In-
cluding the theses abstracts in the parallel training
corpus, a further gain of 2.3 BLEU points is ob-
served for computer science, and 3.1 points for
physics. The last experiment performed aims at
increasing the amount of in-domain parallel texts
by translating automatically in-domain monolin-
gual data, as suggested by Schwenk (2008). The
synthesised bitext does not bring new words into
the system, but increases the probability of in-
domain bilingual phrases. By adding a synthetic
bitext of 12 million words to the parallel training
data, we observed a gain of 0.5 BLEU point for
computer science, and 0.7 points for physics.
Although not shown here, similar results were
obtained in the French?English direction. The
French?English system is actually slightly bet-
ter than the English?French one as it is an easier
translation direction.
13
Translation Model Language Model Tuning Domain CS PHYS
words (M) Bleu words (M) Bleu
wmt11 wmt11 wmt11 371 27.3 371 27.1
wmt11 wmt11+hal hal 371 36.0 371 36.2
wmt11+hal wmt11+hal hal 287 38.3 287 39.3
wmt11+hal+adapted wmt11+hal hal 299 38.8 307 40.0
Table 3: Results (BLEU score) for the English?French systems. The type of parallel data used to train the
translation model or language model are indicated, as well as the set (in-domain or out-of-domain) used to tune
the models. Finally, the number of words in the parallel corpus and the BLEU score on the in-domain test set are
indicated for each domain: computer science and physics.
Figure 1: Translation and post-editing interface.
Corpus English French
Bitexts:
Europarl 50.5M 54.4M
News Commentary 2.9M 3.3M
Crawled (109 bitexts) 667M 794M
Development data:
newstest2009 65k 73k
newstest2010 62k 71k
Monolingual data:
LDC Gigaword 4.1G 920M
Crawled news 2.6G 612M
Table 2: Out-of-domain development and training data
used (number of words after tokenisation).
5 Post-editing Interface
The collaborative aspect of the demonstrated ma-
chine translation service is based on a post-editing
tool, whose interface is shown in Figure 1. This
tool provides the following features:
? WYSIWYG display of the source and target
texts (Zones 1+2)
? Alignment at the sentence level (Zone 3)
? Zone to review the translation with align-
ment of source and target terms (Zone 4) and
terminology reference (Zone 5)
? Alternative translations (Zone 6)
The tool allows the user to perform sentence
level post-editing and records details of post-
editing activity, such as keystrokes, terminology
selection, actual edits and time log for the com-
plete action.
6 Conclusions and Perspectives
We proposed the demonstration of an end-to-end
tool integrated into the HAL archive and enabling
14
efficient translation for scientific texts. This tool
consists of a high-accuracy PDF extractor, a hy-
brid machine translation engine adapted to the sci-
entific domain and a post-edition tool. Thanks to
in-domain data collected from HAL, the statisti-
cal engine was improved by more than 10 BLEU
points with respect to a generic system trained on
WMT11 data.
Our system was deployed for a physic confer-
ence organised in Paris in Sept 2011. All accepted
abstracts were translated into author?s native lan-
guages (around 70% of them) and proposed for
post-editing. The experience was promoted by
the organisation committee and 50 scientists vol-
unteered (34 finally performed their post-editing).
The same experience will be proposed for authors
of the LREC conference. We would like to offer
a complete demonstration of the system at EACL.
The goal of these experiences is to collect and dis-
tribute detailed ?post-editing? data for enabling
research on this activity.
Acknowledgements
This work has been partially funded by the French
Government under the project COSMAT (ANR
ANR-09-CORD-004).
References
Foudil Bretel, Patrice Lopez, Maud Medves, Alain
Monteil, and Laurent Romary. 2010. Back to
meaning ? information structuring in the PEER
project. In TEI Conference, Zadar, Croatie.
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical ma-
chine translation. In Proc. of the 45th Annual
Meeting of the Association for Computational Lin-
guistics (Demo and Poster Sessions), pages 177?
180, Prague, Czech Republic, June. Association for
Computational Linguistics.
Patrice Lopez. 2009. GROBID: Combining auto-
matic bibliographic data recognition and term ex-
traction for scholarship publications. In Proceed-
ings of ECDL 2009, 13th European Conference on
Digital Library, Corfu, Greece.
Holger Schwenk. 2008. Investigations on large-scale
lightly-supervised training for statistical machine
translation. In IWSLT, pages 182?189.
A. Stolcke. 2002. SRILM: an extensible language
modeling toolkit. In Proc. of the Int. Conf. on Spo-
ken Language Processing, pages 901?904, Denver,
CO.
15
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 248?251,
Uppsala, Sweden, 15-16 July 2010.
c?2010 Association for Computational Linguistics
HUMB: Automatic Key Term Extraction from Scientific Articles
in GROBID
Patrice Lopez
INRIA
Berlin, Germany
patrice lopez@hotmail.com
Laurent Romary
INRIA & HUB-IDSL
Berlin, Germany
laurent.romary@inria.fr
Abstract
The Semeval task 5 was an opportunity
for experimenting with the key term ex-
traction module of GROBID, a system for
extracting and generating bibliographical
information from technical and scientific
documents. The tool first uses GROBID?s
facilities for analyzing the structure of sci-
entific articles, resulting in a first set of
structural features. A second set of fea-
tures captures content properties based on
phraseness, informativeness and keyword-
ness measures. Two knowledge bases,
GRISP and Wikipedia, are then exploited
for producing a last set of lexical/semantic
features. Bagged decision trees appeared
to be the most efficient machine learning
algorithm for generating a list of ranked
key term candidates. Finally a post rank-
ing was realized based on statistics of co-
usage of keywords in HAL, a large Open
Access publication repository.
1 Introduction
Key terms (or keyphrases or keywords) are meta-
data providing general information about the con-
tent of a document. Their selection by authors
or readers is, to a large extent, subjective which
makes automatic extraction difficult. This is, how-
ever, a valuable exercise, because such key terms
constitute good topic descriptions of documents
which can be used in particular for information
retrieval, automatic document clustering and clas-
sification. Used as subject headings, better key-
words can lead to higher retrieval rates of an arti-
cle in a digital library.
We view automatic key term extraction as a sub-
task of the general problem of extraction of tech-
nical terms which is crucial in technical and scien-
tific documents (Ahmad and Collingham, 1996).
Among the extracted terms for a given scientific
document in a given collection, which key terms
best characterize this document?
This article describes the system realized for
the Semeval 2010 task 5, based on GROBID?s
(GeneRation Of BIbilographic Data) module ded-
icated to key term extraction. GROBID is a tool
for analyzing technical and scientific documents,
focusing on automatic bibliographical data extrac-
tion (header, citations, etc.) (Lopez, 2009) and
structure recognition (section titles, figures, etc).
As the space for the system description is very
limited, this presentation focuses on key aspects.
We present first an overview of our approach, then
our selection of features (section 3), the different
tested machine learning models (section 4) and the
final post-ranking (section 5). We briefly describe
our unsuccessful experiments (section 6) and we
conclude by discussing future works.
2 Bases
Principle As most of the successful works for
keyphrase extraction, our approach relies on Ma-
chine Learning (ML). The following steps are ap-
plied to each document to be processed:
1. Analysis of the structure of the article.
2. Selection of candidate terms.
3. Calculation of features.
4. Application of a ML model for evaluating
each candidate term independently.
5. Final re-ranking for capturing relationships
between the term candidates.
For creating the ML model, steps 1-3 are applied
to the articles of the training set. We view steps 1
and 5 as our main novel contributions. The struc-
ture analysis permits the usage of reliable features
in relation to the logical composition of the arti-
cle to be processed. The final re-ranking exploits
248
general relationships between the set of candidates
which cannot be captured by the ML models.
Candidate term selection In the following,
word should be understood as similar to token in
the sense of MAF
1
. Step 2 has been implemented
in a standard manner, as follows:
1. Extract all n-grams up to 5 words,
2. Remove all candidate n-grams starting or
ending with a stop word,
3. Filter from these candidates terms having
mathematical symbols,
4. Normalize each candidate by lowercasing
and by stemming using the Porter stemmer.
Training data The task?s collection consists of
articles from the ACM (Association for Computa-
tional Machinery) in four narrow domains (C.2.4
Distributed Systems, H.3.3 Information Search
and Retrieval, I.2.6 Learning and J.4 Social and
Behavioral Sciences). As training data, we used
this task?s training resources (144 articles from
ACM) and the National University of Singapore
(NUS) corpus
2
(156 ACM articles from all com-
puting domains). Adding the additional NUS
training data improved our final results (+7.4%
for the F-score at top 15, i.e. from 25.6 to 27.5).
3 Features
3.1 Structural features
One of the goals of GROBID is to realize reli-
able conversions of technical and scientific docu-
ments in PDF to fully compliant TEI
3
documents.
This conversion implies first the recognition of
the different sections of the document, then the
extraction of all header metadata and references.
The analysis is realized in GROBID with Condi-
tional Random Fields (CRF) (Peng and McCal-
lum, 2004) exploiting a large amount of training
data. We added to this training set a few ACM doc-
uments manually annotated and obtained a very
high performance for field recognitions, between
97% (section titles, reference titles) and 99% (ti-
tle, abstract) accuracy for the task?s collection.
Authors commonly introduce the main concepts
of a written communication in the header (title,
abstract, table of contents), the introduction, the
1
Morpho-syntactic Annotation Framework, see
http://pauillac.inria.fr/ clerger/MAF/
2
http://wing.comp.nus.edu.sg/downloads/keyphraseCorpus
3
Text Encoding Initiative (TEI), http://www.tei-c.org.
section titles, the conclusion and the reference list.
Similarly human readers/annotators typically fo-
cus their attention on the same document parts.
We introduced thus the following 6 binary fea-
tures characterizing the position of a term with re-
spect to the document structure for each candidate:
present in the title, in the abstract, in the introduc-
tion, in at least one section titles, in the conclusion,
in at least one reference or book title.
In addition, we used the following standard fea-
ture: the position of the first occurrence, calcu-
lated as the number of words which precede the
first occurrence of the term divided by the num-
ber of words in the document, similarly as, for in-
stance, (Witten et al, 1999).
3.2 Content features
The second set of features used in this work tries
to captures distributional properties of a term rel-
atively to the overall textual content of the docu-
ment where the term appears or the collection.
Phraseness The phraseness measures the lexical
cohesion of a sequence of words in a given docu-
ment, i.e. the degree to which it can be consid-
ered as a phrase. This measure is classically used
for term extraction and can rely on different tech-
niques, usually evaluating the ability of a sequence
of words to appear as a stable phrase more often
than just by chance. We applied here the Gen-
eralized Dice Coeficient (GDC) as introduced by
(Park et al, 2002), applicable to any arbitrary n-
gram of words (n ? 2). For a given term T , | T |
being the number of words in T , freq(T ) the fre-
quency of occurrence of T and freq(w
i
) the fre-
quency of occurrence of the word w
i
, we have:
GDC(T ) =
| T | log
10
(freq(T ))freq(T )
?
w
i
?T
freq(w
i
)
We used a default value for a single word, because,
in this case, the association measure is not mean-
ingful as it depends only on the frequency.
Informativeness The informativeness of a term
is the degree to which the term is representative of
a document given a collection of documents. Once
again many measures can be relevant, and we opt
for the standard TF-IDF value which is used in
most of the keyphrase extraction systems, see for
instance (Witten et al, 1999) or (Medelyan and
249
Witten, 2008). The TF-IDF score for a Term T in
document D is given by:
TF-IDF(T,D) =
freq(T,D)
| D |
??log
2
count(T )
N
where | D | is the number of words in D,
count(T ) is the number of occurrence of the term
T in the global corpus, and N is the number of doc-
uments in the corpus.
Keywordness Introduced by (Witten et al,
1999), the keywordness reflects the degree to
which a term is selected as a keyword. In prac-
tice, it is simply the frequency of the keyword in
the global corpus. The efficiency of this feature
depends, however, on the amount of training data
available and the variety of technical domains con-
sidered. As the training set of documents for this
task is relatively large and narrow in term of tech-
nical domains, this feature was relevant.
3.3 Lexical/Semantic features
GRISP is a large scale terminological database
for technical and scientific domains resulting from
the fusion of terminological resources (MeSH, the
Gene Ontology, etc.), linguistic resources (part of
WordNet) and part of Wikipedia. It has been cre-
ated for improving patent retrieval and classifica-
tion (Lopez and Romary, 2010). The assumption
is that a phrase which has been identified as con-
trolled term in these resources tend to be a more
important keyphrase. A binary feature is used to
indicate if the term is part of GRISP or not.
We use Wikipedia similarly as the Wikipedia
keyphraseness in Maui (Medelyan, 2009). The
Wikipedia keyphraseness of a term T is the prob-
ability of an appearance of T in a document being
an anchor (Medelyan, 2009). We use Wikipedia
Miner
4
for obtaining this value.
Finally we introduced an additional feature
commonly used in keyword extraction, the length
of the term candidate, i.e. its number of words.
4 Machine learning model
We experimented different ML models: Decision
tree (C4.5), Multi-Layer perceptron (MLP) and
Support Vector Machine (SVM). In addition, we
combined these models with boosting and bagging
techniques. We used WEKA (Witten and Frank,
2005) for all our experiments, except for SVM
4
http://wikipedia-miner.sourceforge.net
where LIBSVM (Chang and Lin, 2001) was used.
We failed to obtain reasonable results with SVM.
Our hypothesis is that SVM is sensitive to the very
large number of negative examples compared to
the positive ones and additional techniques should
be used for balancing the training data. Results
for decision tree and MLP were similar but the lat-
ter is approx. 57 times more time-consuming for
training. Bagged decision tree appeared to per-
form constantly better than boosting (+8,4% for
F-score). The selected model for the final run was,
therefore, bagged decision tree, similarly as, for
instance, in (Medelyan, 2009).
5 Post-ranking
Post-ranking uses the selected candidates as a
whole for improving the results, while in the pre-
vious step, each candidate was selected indepen-
dently from the other. If we have a ranked list of
term T
1?N
, each having a score s(T
i
), the new
score s
?
for the term T
i
is obtained as follow:
s
?
(T
i
) = s(T
i
) + ?
?1
?
j 6=i
P (T
j
|T
i
)s(T
j
)
where ? is a constant in [0 ? 1] for control-
ling the re-ranking factor. ? has been set ex-
perimentally to 0.8. P (T
j
|T
i
) is the probability
that the keyword T
j
is chosen by the author when
the keyword T
i
has been selected. For obtain-
ing these probabilities, we use statistics for the
HAL
5
research archive. HAL contains approx.
139,000 full texts articles described by a rich set of
metadata, often including author?s keywords. We
use the keywords appearing in English and in the
Computer Science domain (a subset of 29,000 ar-
ticles), corresponding to a total of 16,412 different
keywords. No smoothing was used. The usage of
open publication repository as a research resource
is in its infancy and very promising.
6 Results
Our system was ranked first of the competition
among 19 participants. Table 1 presents our offi-
cial results (Precision, Recall, F-score) for com-
bined keywords and reader keywords, together
with the scores of the systems ranked second
(WINGNUS and KX FBK).
5
HAL (Hyper Article en Ligne) is the French Institutional
repository for research publications: http://hal.archives-
ouvertes.fr/index.php?langue=en
250
Set System top 5 top 10 top 15
Comb. HUMB P:39.0 R:13.3 F:19.8 F:32.0 R:21.8 F:25.9 P:27.2 R:27.8 F:27.5
WINGNUS P:40.2 R:13.7 F:20.5 P:30.5 R:20.8 F:24.7 P:24.9 R:25.5 F:25.2
Reader HUMB P:30.4 R:12.6 F:17.8 P:24.8 R:20.6 F:22.5 P:21.2 R:26.4 F:23.5
KX FBK P:29.2 R:12.1 F:17.1 P:23.2 R:19.3 F:21.1 P:20.3 R:25.3 F:22.6
Table 1: Performance of our system (HUMB) and of the systems ranked second.
7 What did not work
The previously described features were selected
because they all had a positive impact on the ex-
traction accuracy based on our experiments on the
task?s collection. The following intuitively perti-
nent ideas appeared, however, to deteriorate or to
be neutral for the results.
Noun phrase filtering We applied a filtering of
noun phrases based on a POS tagging and extrac-
tion of all possible NP based on typical patterns.
This filtering lowered both the recall and the pre-
cision (?7.6% for F-score at top 15).
Term variants We tried to apply a post-ranking
by conflating term variants using FASTR
6
, result-
ing in a disappointing ?11.5% for the F-score.
Global keywordness We evaluated the key-
wordness using also the overall HAL keyword fre-
quencies rather than only the training corpus. It
had no impact on the results.
Language Model deviation We experimented
the usage of HMM deviation using LingPipe
7
as
alternative informativeness measure, resulting in
?3.7% for the F-score at top 15.
Wikipedia term Relatedness Using Wikipedia
Miner, we tried to apply as post-ranking a boosting
of related terms, but saw no impact on the results.
8 Future work
We think that automatic key term extraction can
be highly valuable for assisting self-archiving of
research papers by authors in scholarly reposito-
ries such as arXiv or HAL. We plan to experiment
keyword suggestions in HAL based on the present
system. Many archived research papers are cur-
rently not associated with any keyword.
We also plan to adapt our module to a large col-
lection of approx. 2.6 million patent documents in
6
http://perso.limsi.fr/jacquemi/FASTR
7
http://alias-i.com/lingpipe
the context of CLEF IP 2010. This will be the op-
portunity to evaluate the relevance of the extracted
key terms for large scale topic-based IR.
References
K. Ahmad and S. Collingham. 1996. Pointer project
final report. Technical report, University of Surrey.
http://www.computing.surrey.ac.uk/ai/pointer/report.
C.-C. Chang and C.-J. Lin. 2001. Libsvm: a library
for support vector machines. Technical report.
P. Lopez and L. Romary. 2010. GRISP: A Massive
Multilingual Terminological Database for Scientific
and Technical Domains. In Seventh international
conference on Language Resources and Evaluation
(LREC), Valletta, Malta.
P. Lopez. 2009. GROBID: Combining Automatic
Bibliographic Data Recognition and Term Extrac-
tion for Scholarship Publications. In Proceedings of
ECDL 2009, 13th European Conference on Digital
Library, Corfu, Greece.
O. Medelyan and I.H. Witten. 2008. Domain-
independent automatic keyphrase indexing with
small training sets. Journal of the American
Society for Information Science and Technology,
59(7):1026?1040.
O. Medelyan. 2009. Human-competitive automatic
topic indexing. Ph.D. thesis.
Y. Park, R.J. Byrd, and B.K. Boguraev. 2002. Auto-
matic glossary extraction: beyond terminology iden-
tification. In Proceedings of the 19th international
conference on Computational linguistics-Volume 1,
pages 1?7. Association for Computational Linguis-
tics.
F. Peng and A. McCallum. 2004. Accurate infor-
mation extraction from research papers using con-
ditional random fields. In Proceedings of HLT-
NAACL, Boston, USA.
I.H. Witten and E. Frank. 2005. Data Mining: Practi-
cal machine learning tools and techniques. Morgan
Kaufmann, San Francisco, 2nd edition edition.
I.H. Witten, G.W. Paynter, E. Frank, C. Gutwin, and
C.G. Nevill-Manning. 1999. KEA: Practical auto-
matic keyphrase extraction. In Proceedings of the
fourth ACM conference on Digital libraries, page
255. ACM.
251
