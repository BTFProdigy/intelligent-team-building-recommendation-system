BUPT Systems in the SIGHAN Bakeoff 2007 
Ying Qin   Caixia Yuan   Jiashen Sun   Xiaojie Wang 
Center of Intelligent Science and Technology Research 
Beijing University of Posts and Telecommunications 
Beijing, 100876, China 
qinyingmail@163.com, yuancx@gmail.com, 
b.bigart911@gmail.com, xjwang@bupt.edu.cn 
 
 
Abstract 
Chinese Word Segmentation(WS), Name 
Entity Recognition(NER) and Part-Of-
Speech(POS) are three important Chinese 
Corpus annotation tasks. With the great 
improvement in these annotations on some 
corpus, now, the robustness, a capability of 
keeping good performances for a system by 
automatically fitting the different corpus 
and standards, become a focal problem. 
This paper introduces the work on 
robustness of WS and POS annotation 
systems from Beijing University of Posts 
and Telecommunications(BUPT), and two 
NER systems. The WS system combines a 
basic WS tagger with an adaptor used to fit 
a specific standard given. POS taggers are 
built for different standards under a two 
step frame, both steps use ME but with 
incremental features. A multiple 
knowledge source system and a less 
knowledge Conditional Random Field 
(CRF) based systems are used for NER. 
Experiments show that our WS and POS 
systems are robust. 
1 Introduction 
In the last SIGHAN bakeoff, there is no single 
system consistently outperforms the others on 
different test standards of Chinese WS and NER 
standards(Sproat and Emerson, 2003). 
Performances of some systems varied significantly 
on different corpus and different standards, this 
kind of systems can not satisfy demands in 
practical applications. The robustness, a capability 
of keeping good performances for a system by 
automatically fitting the different corpus and 
standard, thus become a focal problem in WS and 
NER, it is the same for Chinese Part-of-
Speech(POS) task which is new in the SIGHAN 
bakeoff 2007.  
It is worthy to distinguish two kinds of different 
robustness, one is for different corpus (from 
different sources or different domain and so on) 
under a same standard, we call it corpus robustness, 
and another is for different standards (for different 
application goals or demands and so on) for a same 
corpus. We call it standard robustness. The 
SIGHAN bakeoff series seems to focus more on 
later. We think corpus robustness should be 
received more attentions in the near future. 
We participant all simplified Chinese track on 
WS, NER and POS task in the SIGHAN bakeoff 
2007. There are more than two tracks for WS and 
POS. This gives us a chance to test the robustness 
of our systems. This paper reports our WS, NER 
and POS systems in the SIGHAN Bakeoff 2007, 
especially on the work of achieving robustness of 
WS and POS systems.  
This paper is arranged as follows, we introduce 
our WS, NER and POS system separately in 
section 2, section 3 and section 4, experiments and 
results are listed in section 5, finally we draw some 
conclusions. 
2 Word Segmentation 
WS system includes three sequent steps, which are 
basic segmentation, disambiguation and out-of 
vocabulary (OOV) recognition. In each step, we 
construct a basic work unit first, and then have an 
adaptor to tune the basic unit to fit different 
standards. 
94
Sixth SIGHAN Workshop on Chinese Language Processing
2.1 Basic Segmentation 
For constructing a basic work unit for WS, a 
common wordlist containing words ratified by four 
different segmentation standards (from SXU, NCC, 
PKU and CTB separately) are built. We finally get 
64,000 words including about 1500 known entity 
words as the common wordlist. A forward-
backward maximum matching algorithm with the 
common wordlist is employed as the common unit 
of our basic segmentor.  
To cater for different characteristics in different 
segmentation standards, we construct another 
wordlist containing words for each specification.  
A wordlist based adaptor is built to implement the 
tuning task after basic segmentation.  
2.2 Disambiguation 
Disambiguation of overlapping Ambiguity (OA) is 
a major task in this step.  
Strings with OA are also detected during basic 
forward-backward maximum matching in basic 
WS step. These strings are common OA strings for 
different standards. Class-based bigram model is 
applied to resolve the ambiguities. In class-based 
bigram, all named entities, all punctuation and 
factoids is one class respectively and each word is 
one class. We train the bigram transition 
probability based on the corpus of Chinese 
People?s Daily 2000 newswire.  
For corpus from different standards, overlapping 
ambiguity strings with less than 3 overlapping 
chain are extracted from each train corpus. We do 
not work on all of them but on some strings with a 
frequency that is bigger than a given value. A 
disambiguation adaptor using the highest 
probability segmentations is built for OA strings 
from each different standard.  
2.3 OOV Recognition 
In OOV recognition, we have a similar model 
which consists of a common part based on 
common characteristics and an individual part 
automatically constructed for each standard. 
We divide OOV into factoid which contains 
non-Chinese characters like date, time, ordinal 
number, cardinal number, phone number, email 
address and non-factoid.  
Factoid is recognized by an automaton. To 
compatible to different standards, we also built 
core automata and several adaptors. 
Non-factoid is tackled by a unified character-
based segmentation model based on CRF. We first 
transform the WS training dataset into character-
based two columns format as the training dataset in 
NER task. The right column is a boundary tag of 
each character. The boundary tags are B I and S, 
which B is the tag of the first character of a word 
which contains more than two characters, I is the 
other non-initial characters in a word, S is for the 
single character word. Then the transformed 
training data is used to train the CRF model. 
Features in the model are current character and 
other three characters within the context and 
bigrams.  
The trigger of non-factoid recognition is 
continual single character string excluding all the 
punctuations in a line after basic word matching, 
disambiguation and factoid incorporation. The 
model will tell whether these consecutive 
characters can form multi-character words in a 
given context. 
At last, several rules are used to recognize some 
proper names separated by coordinate characters 
like ???, ???, ??? and symbol ??? in foreign 
person names.  
3 Named Entity Recognition 
We built two NER systems separately. One is a 
unified named entity model based on CRF. It used 
only a little knowledge include a small scale of 
entity dictionary, a few linguistic rules to process 
some special cases such as coordinate relation in 
corpus and some special symbols like dot among a 
transliteration foreign person name.  
Another one is an individual model for each 
kind of entity based on Maximum Entropy where 
more rules found from corpus are used on entity 
boundary detection. Some details on this model 
can be found in Suxiang Zhang et al2006. 
4 POS Tagging 
In POS, we construct POS taggers for different 
standards under a two steps frame, both steps use 
ME but with incremental features. First, we use 
normal features based Maximum Entropy (ME) to 
train a basic model, and then join some 
probabilistic features acquired from error analysis 
to training a finer model.  
95
Sixth SIGHAN Workshop on Chinese Language Processing
4.1 Normal Features for ME 
In the first step of feature selection for ME 
tagger, we select contextual syntactic features for 
all words basing on a series of incremental 
experiments. 
For shrinking the search space, the model only 
assigns each word a label occurred in the training 
data. That is, the model builds a subset of all POS 
tags for each token and restricts all possible labels 
of a word within a small candidate set, which 
greatly saves computing cost. 
We enlarged PKU training corpus by using one 
month of Peking University's China Daily corpus 
(June in 2003) and CTB training corpus by using 
CTB 2.0 data which includes 325 passages. 
To adapt with the given training corpus, the 
samples whose labels are not included in the 
standard training data were omitted firstly. After 
preprocessing, we get two sets of training samples 
for PKU and CTB with 1178 thousands tokens and 
206 thousands tokens respectively. But the NCC 
test remains its original data due to we have no 
corpus with this standard. 
4.2 Probabilistic feature for ME 
By detecting the label errors when training and 
testing using syntactic features such as words 
around the current tokens and tags of previous 
tokens, words with multiple possible tags are 
obviously error-prone. We thus define some 
probabilistic features especially for multi-tag 
words.  
We find labels of these tokens are most closely 
related to POS tag of word immediately previous 
to them. For instance, in corpus of Peking 
University, word ?Report? has three different tags 
of ?n(noun), v(verb), vn(noun verb)?. But when we 
taken into account its immediately previous words, 
we can find that when previous word's label is 
?q(quantifier)?, ?Report? is labeled as ?n? with a 
frequency of 91.67%, ?v? with a frequency of 
8.33% and ?vn? with a frequency of 0.0%. We can 
assume that ?Report? is labeled as ?n? with the 
91.67% probability when previous word's label is 
?q?, and so on. 
 Such probability is calculated from the whole 
training data and is viewed as discriminating 
probabilistic feature when choosing among the 
multiple tags for each word.  But for words with 
only one possible tag, no matter what the label of 
previous word is, the label for them is always the 
tag occurred in the training data.  
5 Experiments 
We participant all simplified Chinese tracks on WS, 
NER and POS task in the SIGHAN bakeoff 2007. 
Our systems only deal with Chinese in GBK code. 
There are some mistakes in some results submitted 
to bakeoff organizer due to coding transform from 
GBK to UTF-16. We then use WS evaluation 
program in the SIGHAN bakeoff 2006 to re-
evaluate WS system using same corpus, as for POS, 
since there is no POS evaluation in the SIGHAN 
bakeoff 2006, we implement a evaluation using 
ourselves? program using same corpus.  
Table 1 shows evaluation results of WS using 
evaluation programs from both the SIGHAN 
bakeoff 2007 and the SIGHAN bakeoff 2006. 
Table 2 lists evaluation results of NER using 
evaluation program from the SIGHAN bakeoff 
2007. Table 3 gives evaluation results of POS 
using evaluation programs from both the SIGHAN 
bakeoff 2007 and ourselves(BUPT).  
 
 
Track UTF-16 
(SIGHAN4) 
GBK 
(SIGHAN 3) 
CTB 0.9256 0.950 
SXU 0.8741 0.969 
NCC 0.9592 0.972 
Table 1. WS results (F-measure) 
 
 
SIGHAN 4 R P F 
System-1 0.8452 0.872 0.8584 
System-2 0.8675 0.9163 0.8912 
Table 2. NER results (F-measure) 
 
 
Track UTF-16 
(SIGHAN 4) 
GBK 
(BUPT) 
CTB 0.9689 0.9689 
NCC 0.9096 0.9096 
PKU 0.6649 0.9462 
Table 3. POS Results (F-measure) 
 
From the table 1 and Table 3, we can find our 
system is robust enough. WS system keeps at a 
relatively steady performance. Difference in POS 
96
Sixth SIGHAN Workshop on Chinese Language Processing
between NCC and other two tracks is mainly due 
to the difference of the training corpus.  
6 Conclusion 
Recently, the robustness, a capability of keeping 
good performances for a system by automatically 
fitting the different corpus and standards, become a 
focal problem. This paper introduces our WS, NER 
and POS systems, especially on how they can get a 
robust performance. 
The SIGHAN bakeoff series seems to focus 
more on standard robustness. We think corpus 
robustness should be received more attentions in 
the near future. 
 
Acknowledgement 
Thanks to Zhang Yan, Zhang Bichuan, Zhang 
Taozheng, Liu Haipeng and Jiang Huixing for all 
the work they done to make the WS, NER and 
POS systems go on wheels in a very short time.  
References 
Berger, A., Della Pietra, S. and Della Pietra, V.: A 
Maximum Entropy Approach to Natural 
Language Processing. Computational 
Linguistics. 22(1): pp 39-71, 1996. 
Thomas Emerson. 2005. The Second International 
Chinese Word Segmentation Bakeoff. In 
Proceedings of the Fourth SIGHAN Workshop 
on Chinese Language Processing, Jeju Island, 
Republic of Korea. 
NanYuan Liang. 1987 A Written Chinese 
Segmentation system? CDWS.  Journal of 
Chinese Information Processing, Vol.2: 44-52 
YaJuan Lv, Tie-jun Zhao, et al 2001. Leveled 
unknown Chinese Words resolution by dynamic 
programming. Journal Information Processing, 
15(1): 28-33.  
Yintang Yan, XiaoQiang Zhou. 2000. Study of 
Segmentation Strategy on Ambiguous Phrases 
of Overlapping Type  Journal of The China 
Society For Scientific and Technical Information  
Vol. 19 , ?6  
Richard Sproat and Thomas Emerson. 2003. The 
First International Chinese Word Segmentation 
Bakeoff. In Proceedings of the Second SIGHAN 
Workshop on Chinese Language Processing, 
Sapporo, Japan. 
Caixia Yuan, Xiaojie Wang, Yixin Zhong. Some 
Improvements on Maximum Entropy Based 
Chinese POS Tagging. The Journal of China 
Universities of Posts and Telecommunications, 
Vol. 13, pp 99-103, 2006. 
Suxiang Zhang, Xiaojie Wang, Juan Wen, Ying 
Qin, Yixin Zhong. A Probabilistic Feature 
Based Maximum Entropy Model for Chinese 
Named Entity Recognition, in proceedings of 
21st International Conference on the Computer 
Processing of Oriental Languages,December 
17-19, 2006, Singapore.  
 
 
97
Sixth SIGHAN Workshop on Chinese Language Processing
Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 54?62,
Suntec, Singapore, 4 August 2009.
c
?2009 ACL and AFNLP
Accurate Learning for Chinese Function Tags from Minimal Features
Caixia Yuan
1,2
, Fuji Ren
1,2
and Xiaojie Wang
2
1
The University of Tokushima, Tokushima, Japan
2
Beijing University of Posts and Telecommunications, Beijing, China
{yuancai,ren}@is.tokushima-u.ac.jp
xjwang@bupt.edu.cn
Abstract
Data-driven function tag assignment has
been studied for English using Penn Tree-
bank data. In this paper, we address
the question of whether such method can
be applied to other languages and Tree-
bank resources. In addition to simply
extend previous method from English to
Chinese, we also proposed an effective
way to recognize function tags directly
from lexical information, which is eas-
ily scalable for languages that lack suf-
ficient parsing resources or have inher-
ent linguistic challenges for parsing. We
investigated a supervised sequence learn-
ing method to automatically recognize
function tags, which achieves an F-score
of 0.938 on gold-standard POS (Part-of-
Speech) tagged Chinese text ? a statisti-
cally significant improvement over exist-
ing Chinese function label assignment sys-
tems. Results show that a small number
of linguistically motivated lexical features
are sufficient to achieve comparable per-
formance to systems using sophisticated
parse trees.
1 Introduction
Function tags, such as subject, object, time, loca-
tion, etc. are conceptually appealing by encoding
an event in the format of ?who did what to whom,
where, when?, which provides useful semantic in-
formation of the sentences. Lexical semantic re-
sources such as Penn Treebank (Marcus et al,
1994) have been annotated with phrase tree struc-
tures and function tags. Figure 1 shows the parse
tree with function tags for a sample sentence form
the Penn Chinese Treebank 5.0
1
(Xue et al, 2000)
(file 0043.fid).
1
released by Linguistic Data Consortium (LDC) catalog
NO. LDC2005T01
Figure 1: Simplified parse tree with function tags
(in black bold) for example sentence.
When dealing with the task of function tag
assignment (or function labeling thereafter), one
basic question that must be addressed is what
features can be extracted in practice for distin-
guishing different function tag types. In answer-
ing this question, several pieces of work (Blaheta
and Charniak, 2000; Blaheta, 2004; Merlo and
Musillo, 2005; Gildea and Palmer, 2002) have
already been proposed. (Blaheta and Charniak,
2000; Blaheta, 2004) described a statistical sys-
tem trained on the data of Penn Treebank to au-
tomatically assign function tags for English text.
The system first passed sentences through an au-
tomatic parser, then extracted features from the
parse trees and predicted the most plausible func-
tion label of constituent from these features. Not-
ing that parsing errors are difficult or even impos-
sible to recover at function tag recognition stage,
the alternative approaches are obtained by assign-
ing function tags at the same time as producing
parse trees (Merlo and Musillo, 2005), through
learning deeper syntactic properties such as finer-
grained labels, features from the nodes to the left
of the current node.
Through all that research, however, success-
fully addressing function labeling requires accu-
rate parsing model and training data, and the re-
54
sults of them show that the performance ceil-
ing of function labeling is limited by the parsers
they used. Given the imperfection of existing
automatic parsers, which are far from producing
gold-standard results, function tags output by such
models cannot be satisfactory for practical use.
The limitation is even more pertinent for the lan-
guages that do not have sophisticated parsing re-
sources, or languages that have inherent linguistic
challenges for parsing (like Chinese). It is there-
fore worthwhile to investigate alternatives to func-
tion labeling for languages under the parsing bot-
tleneck, both in terms of features used and effec-
tive learning algorithms.
In current study, we focused on the use of
parser-independent features for function labeling.
Specifically, our proposal is to classify function
types directly from lexical features like words and
their POS tags and the surface sentence informa-
tion like the word position. The hypothesis that
underlies our proposal is that lexical features are
informative for different function types, and cap-
ture fundamental properties of the semantics that
sometimes can not be concluded from the glance
of parse structure. Such cases come when distin-
guishing phrases of the same structure that differ
by just one word ? for instance, telling ?3??
(in Shanghai)?, which is locative, from ?3?
(in May)?, which is temporal.
At a high level, we can say that class-based dif-
ferences in function labels are reflected in statistics
over the lexical features in large-scale annotated
corpus, and that such knowledge can be encoded
by learning algorithms. By exploiting lexical in-
formation collected from Penn Chinese Treebank
(CTB) (Xue et al, 2000), we investigate a super-
vised sequence learning model to test our core hy-
pothesis ? that function tags could be guessed pre-
cisely through informative lexical features and ef-
fective learning methods. At the end of this pa-
per, we extend previous function labeling meth-
ods from English to Chinese. The result proves, at
least for Chinese language, our proposed method
outperforms previous ones that utilize sophisti-
cated parse trees.
In section 2 we will introduce the CTB re-
sources and function tags used in our study. In
section 3, we will describe the sequence learn-
ing algorithm in the framework of maximum mar-
gin learning, showing how to approximate func-
tion tagging by simple lexical statistics. Section 4
Table 1: Complete set of function labels in Chi-
nese Treebank and function labels used in our sys-
tem (selected labels).
type labels in CTB selected labels
clause types IMP imperative
Q question
(function/form)
ADV adverbial
?
discrepancies
grammatical roles EXT extent
?
FOC focus
?
IO indirect object
?
OBJ direct object
?
PRD predicate
?
SBJ subject
?
TPC topic
?
adverbials BNF beneficiary
?
CND condition
?
DIR direction
?
IJ interjective
?
LGS logic subject
?
LOC locative
?
MNR manner
?
PRP purpose/reason
?
TMP temporal
?
VOC vocative
?
miscellaneous APP appositive
HLN headline
PN proper names
SHORT short form
TTL title
WH wh-phrase
gives a detailed discussion of our experiment and
comparison with pieces of related work. Some fi-
nal remarks will be given in Section 5.
2 Chinese Function Tags
The label such as subject, object, time, location,
etc. are named as function tags
2
in Penn Chi-
nese Treebank (Xue et al, 2000), a complete list
of which is shown in Table 1. Among the 5 cat-
egories, grammatical roles such as SBJ, OBJ are
useful in recovering predicate-argument structure,
while adverbials are actually semantically oriented
labels (though not true for all cases, see (Merlo
and Palmer, 2006)) that carry semantic role infor-
mation.
As for the task of function parsing, it is reason-
able to ignore the IMP and Q in Table 1 since they
do not form natural syntactic or semantic classes.
In addition, we regard the miscellaneous labels as
an ?O? label (out of any function chunks) like la-
beling constituents that do not bear any function
2
The annotation guidelines of Penn Chinese Treebank talk
of function tags. We will use the term function labels and
function tags identically, and hence make no distinction be-
tween function labeling and function tagging throughout this
paper. Also, the term function chunk signifies a sequence of
words that are decorated with the same function label.
55
tags. Punctuation marks like comma, semi-colon
and period that separate sentences are also denoted
as ?O?. But the punctuation that appear within one
sentence like double quotes are denoted with the
same function labels with the content they quote.
In the annotation guidelines of CTB (Xue et al,
2000), the function tag ?PRD? is assigned to non-
verbal predicate. Since VP (verb phrase) is always
predicate, ?PRD? is assumed and no function tag
is attached to it. We make a slight modification to
such standard by calling this kind of VP ?verbal
predicates?, and assigning them with function la-
bel ?TAR (target verb)?, which is grouped into the
same grammar roles type with ?PRD?.
To a large extent, PP (preposition phrase) al-
ways plays a functional role in sentence, like ?PP-
MNR? in Figure 1. But there are many such PPs
bare of any function type in CTB resources. Like
in the sentence ?'c??O 25% (increase
by 25% over the same period of last year)?, ?'
c?? (over the same period of last year)? is la-
beled as ?PP? in CTB without any function labels
attached, thus losing to describe the relationship
with the predicate ?O (increases)?. In order to
capture various relationships related to the predi-
cate, we assign function label ?ADT (adjunct)? for
this scenario, and merge it with other adverbials
to form adverbials category. There are 1,415 such
cases in CTB resources, which account for a large
proportion of adverbials types.
After the modifications discussed above, in our
final system we use 20 function labels
3
(18 origi-
nal CTB labels shown in Table 2 and two newly
added labels) that are grouped into two types:
grammatical roles and adverbials.
We calculate the frequency (the number of times
each tag occurs) and average length (the average
number of words each tag covers) of each func-
tion category in our selected sentences, which are
listed in Table 2. As can be seen, the frequency of
adverbials is much smaller than that of grammati-
cal roles. Furthermore, the average length of most
adverbials are somewhat larger than 4. Such data
distribution is likely to be one cause of the lower
identification accuracy of adverbials as we will see
in the experiments.
From the layer of function labeling, sentences
3
ADV includes ADV and ADVP in CTB recourses,
grouped into adverbials. In function labeling level, EXT that
signifies degree, amount of the predicates should be grouped
into adverbials like in the work of (Blaheta and Charniak,
2000) and (Merlo and Musillo, 2005).
Table 2: Categories of function tags with their rel-
ative frequencies and average length.
Function Labels Frequency Average Length
grammatical roles 99507 2.62
FOC 133 1.89
IO 126 1.26
OBJ 25834 4.15
PRD 4428 5.20
SBJ 23809 3.02
TPC 676 3.51
TAR 44501 1.25
adverbials 33287 2.11
ADT 1415 4.51
ADV 21891 1.32
BNF 465 4.66
CND 68 3.15
DIR 1558 4.68
EXT 1048 1.99
IJ 1 1.00
LGS 204 5.42
LOC 2051 4.27
MNR 1053 4.48
PRP 224 4.91
TMP 3309 2.25
in CTB are described with the structure of ?SV?
which indicates a sentence is basically composed
of ?subject + verb?. But in order to identify objects
and complements of predicates, we express sen-
tence by ?SVO? framework in our system, which
regards sentence as a structure of ?subject + verb +
object?. The structure transformation is obtained
through a preprocessing procedure, by upgrading
OBJs and complements (EXT, DIR, etc.) which
are under VP in layered brackets.
3 Learning Function Labels
Function labeling deals with the problem of pre-
dicting a sequence of function tags y = y
1
, ..., y
T
,
from a given sequence of input words x =
x
1
, ..., x
T
, where y
i
? ?. Therefore the function
labeling task can be formulated as a stream of se-
quence learning problem. The general approach
is to learn a w-parameterized mapping function
F : X?Y ? < based on training sample of input-
output pairs and to maximize F (x, y;w) over the
response variable to make a prediction.
There has been several algorithms for label-
ing sequence data including hidden Markov model
(Rabiner, 1989), maximum entropy Markov model
(Mccallum et al, 2000), conditional random fields
(Lafferty et al, 2001) and hidden Markov support
vector machine (HM-SVM) (Altun et al, 2003;
Tsochantaridis et al, 2004), among which HM-
SVM shows notable advantages by its learning
56
non-linear discriminant functions via kernel func-
tion, the properties inherited from support vec-
tor machines (SVMs). Furthermore, HM-SVM
retains some of the key advantages of Markov
model, namely the Markov chain dependency
structure between labels and an efficient dynamic
programming formulation.
In this paper we investigate the application of
the HM-SVM model to Chinese function labeling
task. In order to keep the completeness of paper,
we here address briefly the HM-SVM algorithm,
more details of which could be founded in (Altun
et al, 2003; Tsochantaridis et al, 2004), then we
will concentrate on the techniques of applying it to
our specific task.
3.1 Learning Model
The framework from which HM-SVM are derived
is a maximum margin formulation for joint fea-
ture functions in kernel learning setting. Given n
labeled examples (x
1
, y
1
), ..., (x
n
, y
n
), the notion
of a separation margin proposed in standard SVMs
is generalized by defining the margin of a train-
ing example with respect to a discriminant func-
tion F (x, y;w), as:
?
i
= F (x
i
, y
i
;w)?max
y/?y
i
F (x
i
, y;w). (1)
Then the maximum margin problem can be de-
fined as finding a weight vector w that maxi-
mizes min
i
?
i
. By fixing the functional margin
(max
i
?
i
? 1) like in the standard setting of SVMs
with binary labels, we get the following hard-
margin optimization problem with a quadratic ob-
jective:
min
w
1
2
||w||
2
, (2)
with constraints,
F (x
i
, y
i
;w)? F (x
i
, y;w) ? 1,?
n
i=1
,?
y 6=y
i
.
In the particular setting of SVM, F is as-
sumed to be linear in some combined feature
representation of inputs and outputs ?(x, y), i.e.
F (x, y;w) = ?w,?(x, y)?. ?(x, y) can be
specified by extracting features from an obser-
vation/label sequence pair (x, y). Inspired by
HMMs, we propose to define two types of fea-
tures, interactions between neighboring labels
along the chain as well as interactions between at-
tributes of the observation vectors and a specific
label. For instance, in our function labeling task,
we might think of a label-label feature of the form
?(y
t?1
, y
t
) = [[y
t?1
= SBJ ? y
t
= TAR]], (3)
that equals 1 if a SBJ is followed by a TAR. Anal-
ogously, a label-observation feature may be
?(x
t
, y
t
) = [[y
t
= SBJ ? x
t
is a noun]], (4)
which equals 1 if x at position t is a noun and la-
beled as SBJ. The described feature map exhibits
a first-order Markov property and as a result, de-
coding can be performed by a Viterbi algorithm in
O(T |?|
2
).
All the features extracted at location t are sim-
ply stacked together to form ?(x, y; t). Finally,
this feature map is extended to sequences (x, y) of
length T in an additive manner as
?(x, y) =
T
?
t=1
?(x, y; t). (5)
3.2 Features
It deserves to note that features in HM-SVM
model can be easily changeable regardless of de-
pendency among them. In this prospect, features
are very far from independent can be cooperated
in the model.
By observing the particular property of function
structure in Chinese sentences, we design several
sets of label-observation features which are inde-
pendent of parse trees, namely:
Words and POS tags: The lexical context is ex-
tremely important in function labeling, as indi-
cated by their importance in related task of phrase
chunking. Due to long-distance dependency of
function structure, intuitively, more wider con-
text window will bring more accurate prediction.
However, the wider context window is more likely
to bring sparseness problem of features and in-
crease computation cost. So there should be a
proper compromise among them. In our experi-
ment, we start from a context of [-2, +2] and then
expand it to [-4, 4], that is, four words (and POS
tags) around the word in question, which is closest
to the average length of most function types shown
in Table 2.
Bi-gram of POS tags: Apart from POS tags them-
selves, we also try on the bi-gram of POS tags. We
regard POS tag sequence as an analog to function
57
chains, which reveals somewhat the dependent re-
lations among words.
Verbs: Function labels like subject and object
specify the relations between verb and its argu-
ments. As observed in English verbs (Levin,
1993), each class of verb is associated with a set
of syntactic frames. Similar criteria can also be
found in Chinese. In this sense, we can rely on
the surface verb for distinguishing argument roles
syntactically. Besides the verbs themselves, we
also take into account the special words sharing
common property with verbs in Chinese language,
which are active voice ?r(BA)? and passive voice
?A Chinese LPCFG Parser with Hybrid Character Information
Wenzhi Xu, Chaobo Sun and Caixia Yuan
School of Computer,
Beijing University of Posts and Telecommunications,
Beijing, 100876 China
{ earl808, sunchaobo}@gmail.com
yuancx@bupt.edu.cn
Abstract
We present a new probabilistic model
based on the lexical PCFG model, which
can easily utilize the Chinese character in-
formation to solve the lexical information
sparseness in lexical PCFG model. We
discuss in particular some important fea-
tures that can improve the parsing perfor-
mance, and describe the strategy of mod-
ifying original label structure to reduce
the label ambiguities. Final experiment
demonstrates that the character informa-
tion and label modification improve the
parsing performance.
1 Introduction
Parsing is an important and fundamental task in
natural language processing. The challenge of
Chinese parser has been the focus of attention in
recent years, and many different kinds of Chi-
nese parsing models are investigated. (Bikel,
2000) adopts Head-Driven model to parse Chi-
nese. (Levy, 2003) analyzes the difficulties of
Chinese parsing through comparing the differ-
ences between Chinese and English. (Wang,
2006) utilizes shift-reduce approach, dramatically
improved the decoding speed of parsing. All these
research adopted the same models which are also
used in English parser ? the models based on the
words.
However, there is a big difference between En-
glish and Chinese: the expressing unit in English
is word, while character is the smallest unit in
Chinese. Due to difficulties of word segmenta-
tion, especially for different segmenting criteria,
many researchers explored parsing Chinese based
on characters. The parser of (Luo, 2003) received
sentence as input and conducted word segmenta-
tion and syntactic parsing at the same time, but
they did not utilize the character information in
generating subtree; (Zhao, 2009)?s dependency
parsing tree totally abandoned the word concept,
so the dependency relations are the relations be-
tween characters.
We combine both word and character informa-
tion to gain better performance of parsing. Al-
though the criteria of segmentation are difficult to
be unified, different criteria conflict only within
the phrases which have little influence on the
structure between phrases. So we still use word
as our basic unit of parsing. Although word
has been proved to be effective in head-driven
parser (Collins,1999), the data of word depen-
dence is very sparse. While it is worthy to note
that words with similar concept always share the
same characters in Chinese. For instance, ???
[(scientist)?, ?{??[(historian)?, etc., share
the same character ?[(expert)?, since they belong
to the same concept ?expert in a certain field?. So
the problem of word sparseness can be solved by
combining the character information to some ex-
tent.
Throughout this paper, we use TCT Treebank
(Zhou, 2004) as experimental data. TCT mainly
consists of binary trees, with a few of multi-
branch and single-branch trees. Thus, we first
transfer all trees to binary trees. Then we use
Lexical-PCFG model to exploit the word and
character information, and Maximum Entropy
Model to calculate the probability of induced trees
as (Charinak, 2000). Finally we use CKY-based
decoder.
In the following section, we will introduce how
to utilize character information in our parsing
model and the other features in detail. Section 3
gives experiment results and analysis, which show
improvement of our parsing approach. Section 4
presents the conclusion and future work.
2 Lexical PCFG model
2.1 Model Introduction
Starting from the Lexical-PCFG model (Model 2
in Collins, 1999), we propose a new generative
process which can conveniently exploit the char-
acter information and other features.
Assume P is the label of parent, H is the head
child of the rule, and L1, ..., Ln and R1, ..., Rn is
the left and right modifiers of H . Then the rule of
Lexical-PCFG (LPCFG) can be written as:
P (hw, ht) ? (1)
Ln(lwn, ltn)...L1(lw1, lt1)H(hw, ht)
R1(rw1, rt1)...Rn(rwn, rtn),
where (hw, ht) represents the head word and
head tag of head child, (lw1, lt1), ..., (lwn, ltn)
and (rw1, rt1), ..., (rwn, rtn) are the head words
and head tags of left and right modifiers, and par-
ent node P ?s head word and tag are the same as
that of H .
As mentioned above, our trees are all binary
trees. In this case, the LPCFG can be written as:
P (hw, ht)? H(hw, ht)R(rw, rt), (2)
P (hw, ht)? L(lw, lt)H(hw, ht). (3)
Formula 2 and 3 represent that the head child is
the left or right child respectively. The probability
of the rule is conditioned on the head words and
tags of head and its modified children, which is
specified as:
Pr(P,L,H|hw, ht, lw, lt), (4)
and
Pr(P,R,H|hw, ht, rw, rt). (5)
To calculate these probabilities, we rewrite
Equation 4 and 5 by three factors in 6 and 7 us-
ing the chain rule.
Pr(P,R,H|hw, ht, lw, lt) = (6)
Prd(P ?DIR|hw, ht, lw, lt) ? Prh(H|P, hw, ht)
?Prm(L?DIR|P,H, hw, ht),
P r(P,R,H|hw, ht, rw, rt) = (7)
Prd(P ?DIR|hw, ht, rw, rt) ? Prh(H|P, hw, ht)
?Prm(R?DIR|P,H, hw, ht).
in which, DIR=LEFT/RIGHT. DIR in P-DIR
is used to discriminate different positions of head
child, DIR in L-DIR and R-DIR are used to repre-
sent different positions of modifiers.
The calculation processes of Equation 6 and 7
can be interpreted by following generative pro-
cess. Firstly, the head words and tags of chil-
dren generate the parent and the head position (the
first probability in Equation 6 and 7). We define
this probability as the word dependency probabil-
ity Prd: if two words (or characters in words)
always appear together in the training data, this
probability will be large (< 1); if two words (or
characters in words) do not have any dependence
in the training data, this probability will be ap-
proximately equal to 1/|Y |, where |Y | is the pre-
dicted number of the Prd. The second probability
generates the head child label (defined as the head
child probability Prh), we hold that the head word
and tag of modifier do not provide information to
determine the head child label, so we omit them.
The third one produces the modifier label, which
is defined as the modifier probability Prm, and
evaluates the dependency relation between modi-
fier and the head child. We also omit the influence
of the head word and tag of modifier.
For example, assume there is a tree as shown
in Figure 1. For the rule ?vp ? v np?, head
child of parent vp and np are the left child v and
right child n respectively, so ?|?(organize)? and
?;[(expert)? are the head word of vp and np.
Thus the LPCFG rule is ?vp(|?,v)? v(|?,v)
Figure 1: Tree representation of LPCFG rule.
np(;[,n)?. The probability can be written as:
Prd(vp-LEFT | |?,v,;[,n) ? Prh(v|vp,|
?,v) ? Prm(np-RIGHT | vp, v,|?,v).
2.2 Probability Model and Feature Set
We use Maximum Entropy (ME) Model to com-
pute probabilities of candidate trees. ME model
estimate parameters that would maximize the en-
tropy over distributions, meanwhile satisfy certain
constraints. These constraints will force the model
to reflect characteristic of training data. With the
feature function, Maximum Entropy can exploit
kinds of features flexibly, some of which are very
important to improve the performance of tasks at
hand. ME model has been applied successfully
in many tasks, such as parser (Charniak, 2000;
Luo, 2003), POS tagging (Ratnaparkhi,1996), etc.
In our experiment, we use Maxent toolkit de-
velopped by Zhang (Zhang, 2004), which uses
the LBFGS algorithm for parameter estimation.
Details of the model and toolkit can be seen in
(Berger, 1996; Zhang, 2004).
Our features consist of four parts: basic fea-
tures, character features, context features and
overlapping features of character and context. Ba-
sic features are traditional LPCFG features, in-
cluding head word, head tag and the label. We
extract the first and last characters of a word as the
Character features, of course for a single character
word the first and last character are the same. Con-
text features are defined as the previous and fol-
lowing POS tags of the current subtree, and these
features utilize the information outside of the sub-
tree very well without increasing the complex-
ity of parsing decoder. Overlapping features are
the combinations of character features and context
features.
Take Chinese sentence ??
?/n d/p ??
?/n|?/vk'/b;[/n|?/v?/v (Com-
mittee is composed of experts organized by the
Ministry of Agriculture)? for example, the corre-
sponding rule is ?vp(|?,v) ? v(|?,v) np(;
[,n)?, the feature template of the example sen-
tence is shown in Table 1.
When applying the character information, it is
worthwhile to note that character is always com-
bined with the POS tag of the word since the
sense of single character varies as word?s POS tag
changes. For example, the sense of ?O(love)?
in verb ?Oo(care and protect)? and noun ?O
?(love)? is different. Of course the sense dis-
cussed here is reflected in the dependency of
words: ?Oo(care and protect)? can be followed
by some nouns which are objects, while ?O
?(love)? can not.
For the multi-branch tree, (Collins,1999) calcu-
lates the probability of the left or right modifier
with a feature which represent whether there are
modifiers between current modifier and the head
child (distance feature). But in the situation of
binary tree, it is obvious that current modifier is
unlikely to follow other modifiers. Since the rep-
resentation of binary tree conforms to the X-bar
theory of Chomsky, we can modify the head child
label to get this non-local information in binary
tree. For instance, a multi-branche tree rule ?vp1
? pp d vp2? corresponding to these two binary
tree rules: ?vp3 ? pp vp4? and ?vp4 ? d vp5?
(the index numbers of the vb here stand for dif-
ferent vp). So when we calculate the probability
of pp with the multi-branch situations, d lies be-
tween pp and vp2. While in binary tree situation,
we cannot catch this information between pp and
vp4. However, we can modify vp4 to vp-LEFT,
which means there is a modifier at the left child
of vp4, then we get the similar effect in (Collins,
1999). We call this as the head position labeling.
2.3 Label splitting and Head Position
Modifying
(Klein, 2003) improves the performance of parser
via splitting the POS tag in corpus. We split the
non-terminal label using the same approaches (as-
suming the POS tag is terminal label). The need
of label splitting is that the corpus does not suffi-
ciently consider different situations and treat them
Table 1: Feature templates and symbol explanation.
Prd (vp-LEFT) Prh (v) Prm (np-RIGHT)
basic lw rw |?;[ p vp p h vp v
feature lw lt rw rt |?v;[n p hw vp|? p h hw vp v|?
p hw ht vp|?v p h hw ht vp v|?v
p ht vp v p h ht vp v v
char. lw frc rt |?;n p fhc ht vp|v p h fhc ht vp v|v
feature other combinations , p lhc ht vp?v p h lhc ht vp v?v
flc lt frc rt |v;n
other combinations ,
context lw rw pt1 at1 |?;[n v p pt1 vp n p h pt1 vp v n
feature lw lt rw rt pt1 at1 |?v;[n n v p pt1 pt2 vp n p p h pt1 pt2 vp v n p
p at1 vp v p h at1 vp v v
p at1 at2 vp v v p h at1 at2 vp v v v
p pt1 at1 vp n v p h pt1 at1 vp v n v
p hw pt1 at1 vp|?v n p h hw pt1 at1 vp v|?v n
overlap lw frc rt pt1 at1 |?;n n v p fhc ht pt1 at1 vp|v n v p h fhc ht pt1 at1 vp v|v n v
feature other combinations ... p lhc ht pt1 at1 vp?v n v p h lhc ht pt1 at1 vp v?v n v
flc lt frc rt pt1 at1 |v;n n v
other combinations ...
Symbol Explanation
frc lrc the first and last characters of the head word of the right child
pt at previous and following POS tag of current subtree, number indicates the position
flc llc the first and last characters of the head word of the left child
fhc lhc the first and last characters of the head word
as the same label which results in ambiguity. Fur-
thermore, in our experiment, the corpus that we
adopt is binary tree. Though the rule set in binary
tree is closed, it brings stronger independent as-
sumption (Jonson,1998). Thus splitting the label
can make the node label represent more informa-
tion from descendants. Just like the intuition of
head position labeling, this is also one method to
utilize the non-local information. We mainly con-
sider these modifying as follows.
First of all, we split the label vp. There are
three kinds of verb phrases: the first one is that
there is modifier ahead (such as advp); the second
phrase consists of an object; while the third one
has the form of two verbs or verb plus an auxil-
iary word. The formal two situations can not fol-
low any object any more (some double-object verb
phrase may be continued to contain object, but
their POS label is different with common verb),
the vp in last situation can be followed by object
(there maybe actually no object). If we do not dis-
criminate these situations, it will be easy to result
in dividing the object into two objects during pars-
ing test, just as shown in Figure 2. However, if
we modify vp in the third situation into vb, then
this difference can be discriminated well. We take
a simple statistics as an example to illustrate the
sense. Assume our object is np, rule ?vp ? vp
np? appears for 5,284 times in corpus before mod-
ifying, while it present only 166 times after mod-
ifying.
Figure 2: Parsing Result Example: (a) is a correct
tree, (b) is a wrong one, while the probability may
be not small enough, (c) is also wrong, but the
probability is very small due to the symbol vb.
Secondly, we also split the np tag. We notice
that a noun phrase, which consists of non-noun
(phrase) modifier (such as ADJP, PP) and a noun
(phrase), is always the final noun phrase but rarely
part of another noun phrase. So we transform the
np, which has the non-noun (phrase) modifier, to
nm. From the statistics of corpus, we find rule ?np
? np n? occurs for 4,502 times, while ?np? nm
n? only appears 826 times.
Finally, we change the head position of prepo-
sition phrase. The head position of preposition
phrases in corpus mostly is the phrase behind the
preposition, but we found the grammar of prepo-
sition phrase is much related to the preposition.
Take the preposition ??(by)? and ??(to)? as ex-
ample, these two prepositions occur for 755 and
1,300 times respectively. In our corpus, 98.7% of
preposition phrases with?(by)? are the modifiers
of verb phrases, while only 57.2% of phrases with
??(to)? appear as the modifiers of verb phrases,
and the remaining 42.8% are the modifiers of noun
phrases.
3 Experiment Result and Analysis
Our experiments are conducted on the TCT cor-
pus, which is used as the standard data of the
CIPS-SIGHAN Parser 2010 bakeoff. We omit the
sentences with length 1 during training and test-
ing. Performance on the test corpus is evaluated
with the standard measures from (SIGHAN RE-
PORT, 2010).
We submit two results for the parsing bakeoff:
one is single model we described in Section 2, an-
other is reranking model, which is an attempt to
apply a perceptron algorithm to rerank the 50-best
result produced by the ME model.1 Table 2 shows
the result of our parser compared with the top one
in this bakeoff. Since the parser we built is strictly
dependent on the POS tags, the precision of POS
tagging has a harsh effect on the overall parsing
performance.
The performance of the rerank model is lightly
lower than that of the single model. The most
likely reason is that the features we count on
are far from enough, and the informative features
proved to be useful in (Charniak and Johnson,
2003) are not yet included in our discriminative
ranker. Besides, the rank model we used is a
simple perceptron learner, more delicated model,
such as ME model used in (Charniak and Johnson,
1More details can be found in (Charniak and Johnson,
2003; Huang, 2008). The features we used include Paren-
tRule, RightBranch, Rule, Heads, WProj described in (Char-
niak and Johnson, 2003).
Table 3: Results of different features with no limit
sentence length.
feature set LR LP F CB 0CB 2CB
basic 80.19 79.61 79.90 1.20 56.10 83.49
+ch 81.91 81.38. 81.65 1.10 58.34 84.95
+cont 85.53 85.34 85.44 0.83 65.62 88.86
+ch + cont 86.17 85.94 86.06 0.80 66.61 89.62
+ch + cont + ol 86.34 86.13 86.24 0.79 66.65 89.81
+ch + cont + ol + cwd 86.47 86.26 86.37 0.78 66.73 89.87
+ch + cont + ol + cwd + cm 87.03 86.77 86.90 0.75 67.06 90.36
+ch + cont + ol + cwd + cm + hpl 87.20 86.94 87.07 0.74 67.43 90.40
ch=character feature, cont=context feature
ol=overlap feature, cwd=coordinate word dependence
cm=corpus modifying, hpl= head position label
2003), might improve the result.
In order to make clear how different features
effect the parser performance, we conducted ex-
periments on the TCT data provided by CIPS-
ParEval-2009 for Chinese parser bakeoff 2, since
the sentences in CIPSParEval-2009 are given with
head words and gold-standard POS tags. The re-
sults of our parser are given in Table 3. From Ta-
ble 3 we can see that character features bring the
improvement of F score for 1.75 compared with
the basic features (line 2 vs line 3), and for 0.8
after adding the context features (line 4 vs line
6). These results show that character features can
improve the model with basic features very well.
After applying the context features, character fea-
tures can still bring improvement, which states
that character features can solve the ambiguities
that can not be solved by the context features.
One likely reason why character information is
helpful is that the character can partly represent
the meaning of word and can partly resolve the
sparseness problem of word dependence as been
observed in the work of (Kang, 2005). Kang cal-
culated the statistics for 50,000 double characters
words and divided the methods of constructing
word into 8 types according to the relations of
meaning between word and characters:
(1) A+B=A=B (2) A+B=A
(3) A+B=B (4) A+B=C
(5) A+B=A+B (6) A+B=A+B+D
(7) A+B=A+D (8) A+B=D+B
A and B stand for the meaning of the two char-
acters which are used to construct the word. C
is a totally new meaning and D represents an ad-
2http://www.ncmmsc.org/CIPS-ParsEval-
2009/index.asp, the first workshop on Chinese Syntactic
Parsing Evaluation, November, 2009.
Table 2: Results of different features with no limit sentence length.
?B+C?-P ?B+C?-R ?B+C?-F1 ?B+C+H?-P ?B+C+H?-R ?B+C+H?-F1 POS-P
Top one 85.42 85.35 85.39 83.69 83.63 83.66 93.96
Single 74.86 76.05 75.45 71.06 72.20 71.63 87.00
Rerank 74.48 75.64 75.05 70.72 71.81 71.26 87.00
Table 4: The relation between the meaning of
words and characters.
type 1 2 3 4 5 6 7 8
word number 4035 1031 297 4201 14455 23562 2780 1886
rate(%) 7.71 1.97 0.57 8.02 27.60 44.99 5.31 3.60
ditional meaning. The expression after the first
?=? is the meaning of the word, and the symbol
?+? indicates the melding of meaning. For exam-
ple, A+B=A+D indicates that the word retains the
meaning of character A, and adds new meaning
D. The distribution of each type in the dataset is
shown in Table 4. From Table 4 we can see that
type 4, i.e., there are no relation between charac-
ters and word, occupies only 8.02%. This data
proves that the word inherits the meaning from the
characters which are used to construct the word.
However, the relations are really complicated. For
example, some words only inherit the meaning of
formal characters and others of the last characters.
This might be the reason why character informa-
tion does not have very obvious effect as expected.
In our parsing model, context features are re-
ally helpful to the parsing accuracy. Different with
the decision method in (Rantnaparkhi, 1999) and
(Wang, 2006), and reranking in (Collins, 2000)
which all can utilize the context of current sub-
tree very well (not only the POS tag), the CYK
decoding algorithm restricts our context features.
However, we can conveniently exploit the POS
tags around the current subtree without increas-
ing the complexity of decoding and thus improve
the performance.
Commonly, each subtree has only one head
word. However, we notice that the two head
words of two coordinate children are equivalent,
as illustrated in Figure 3. We assume that the par-
ent node of these two children is A and the two
head word are all the head words of A. When
A is the child of the parent node B, all the head
words in A can be dependent with the other head
Figure 3: Example of dependence between coor-
dinate words.
words of another child C. When A is still the
head child of B, the head words of B are also the
same as A. Then we can extract more word depen-
dence data. For example, A have two head words
???(construct)? and ??(complete)?, and ??
?(rule)? is the head word of C, then we consider
that ???(construct)? and ??(complete)? are
all dependent with ???(rule)?. Meanwhile, A is
also the head child of B, and the head words of B
are also ???(construct)? and ??(complete)?.
During the decoding, we choose the most proba-
ble dependence as the dependence probability of
B. From the result, we can see that this strategy
yields 0.17 improvements in the F score.
Label splitting can also improve the perfor-
mance. However, modifying the labels need
much linguistic knowledge and manual work.
(Petrov, 2006) proposed an automated splitting
and merging method. As an attempt, we tested
the effectiveness of it in our parser empirically.
When tested on the TCT data provided by CIPS-
ParsEval-2009 for Chinese parser, bakeoff the la-
bel spitting improve the F1 measure from 0.864 to
0.869.
4 Conclusion and Future Work
This paper presents a new lexical PCFG model,
which can synthetically exploit the word and char-
acter information. The results of experiment
prove the effectiveness of character information.
Also our model can utilize the context features
and some non-local features which can dramati-
cally improve the performance.
In future work, we need improve the decod-
ing algorithm to exploit more complex features.
As the parser we build is greatly dependent on
the preprocessing result of word segmentation,
POS tagging and head labeling, a critical direc-
tion of future work is to do word-segmentation,
POS tagging, head detection and parsing in a uni-
fied framework. Besides, as for the K-best rerank-
ing, we should take into account more informative
features and more powerful reranking model.
Acknowledgment
This research has been partially supported by
the National Science Foundation of China (NO.
NSFC90920006). We also thank Xiaojie Wang,
Huixing Jiang, Jiashen Sun and Bichuan Zhang
for useful discussion of this work.
References
A.L. Beger, S. A. D Pietra, and V.J.D Pietra. 1996.
A maximum entropy approach to natural language
processing. Computational Linguistics, 39?71.
D.M. Bikel and D. Chiang. 2000. Two statistical pars-
ing models applied to the Chinese Treebank. In Pro-
ceedings of the Second Chinese Language Process-
ing Workshop, 1?6.
E. Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the 1st NAACL, Seattle,
WA, 132?139.
E. Charniak. 1997. Statistical parsing with a context-
free grammar and word statistics. In Proceddings
of the Fourteenth National Conference on Artificial
Intelligence, Menlo Park, CA. 598?603.
X. Chen, C.N. Huang, M. Li, and C.Y. Kit. 2009. Bet-
ter Parser Combination. In CIPS ParsEval, Beijing,
China. 81?90.
M. Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. Dissertation,
University of Pennsylvania.
M. Collins. 2000. Discriminative reranking for natural
language parsing. In Proceedings of ICML 2000,
175?182.
S.Y. Kang, X.X. Xu, and M.S. Sun. 2005. The
Research on the Modern Chinese Semantic Word-
Formation. Journal of Chinese Language and Com-
puting, 103?112.
D. Klein and C. Manning. 2003. Accurate unlexical-
ized parsing. In Proceedings of ACL 2003, 423?
430.
L. Huang. 2008. Forest Reranking: Discriminative
Parsing with Non-Local Features. In Proceedings
of ACL 2008, 586?594.
D. Klein and C.D. Manning. 2003. Accurate unlexi-
calized parsing. In Proceedings of ACL 2003, 423?
430.
E. Charniak and M. Johnson. 2005. Coarse-to-fine n-
best parsing and MaxEnt discriminative reranking.
In Proceedings of ACL 2005, 173?180.
R. Levy and C.D. Manning. 2003. Is it harder to parse
Chinese, or the Chinese Treebank? In Proceedings
of ACL 2003, 439?446.
X.Q. Luo. 2003. A maximum entropy Chinese
character-based parser. In Proceedings of EMNLP
2003, 192?199.
M. Johnson. 1998. PCFG models of linguistic tree
representations. Computational Linguistics, 613?
632.
S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006.
Learning accurate, compact, and interpretable tree
annotation. In Proceedings of ACL 2006, 433?440.
A. Ratnaparkhi. 1996. A maximum entropy part-of-
speech tagger. In Proceedings of EMNLP 1996,
133?142.
A. Ratnaparkhi. 1999. Learning to parse natural lan-
guage with maximum entropy models. Machine
Learning, 503?512.
M.W. Wang, K. Sagae, and T. Mitamura. 2006. A
Fast, Accurate Deterministic Parser for Chinese. In
Proceedings of ACL 2006, 425?432.
L. Zhang. 2004. Reference Manual. Maximum En-
tropy Modeling Toolkit for Python and C++.
H. Zhao. 2009. Character-Level Dependencies in Chi-
nese: Usefulness and Learning. In Proceedings of
12th ECACL 2009, 879?887.
SIGHAN REPORT. 2010. SIGHAN REPORT ON
TASK2. In Proceedings of CIPS-SIGHAN 2010,
Beijing, China.
Q. Zhou. 2004. Annotation Scheme for Chinese Tree-
bank. Journal of Chinese Information Processing,
1?8.
