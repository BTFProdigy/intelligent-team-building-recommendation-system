Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages ? AfLaT 2009, pages 38?45,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
Part-of-Speech tagging of Northern Sotho:
Disambiguating polysemous function words
Gertrud Faa??? Ulrich Heid? Elsabe? Taljard? Danie Prinsloo?
? Institut fu?r Maschinelle Sprachverarbeitung ? University of Pretoria
Universita?t Stuttgart South Africa
Germany
faaszgd@ims.uni-stuttgart.de elsabe.taljard@up.ac.za
heid@ims.uni-stuttgart.de danie.prinsloo@up.ac.za
Abstract
A major obstacle to part-of-speech
(=POS) tagging of Northern Sotho
(Bantu, S 32) are ambiguous function
words. Many are highly polysemous and
very frequent in texts, and their local
context is not always distinctive.
With certain taggers, this issue leads to
comparatively poor results (between 88
and 92 % accuracy), especially when
sizeable tagsets (over 100 tags) are used.
We use the RF-tagger (Schmid and Laws,
2008), which is particularly designed for
the annotation of fine-grained tagsets (e.g.
including agreement information), and
we restructure the 141 tags of the tagset
proposed by Taljard et al (2008) in a way
to fit the RF tagger. This leads to over
94 % accuracy. Error analysis in addition
shows which types of phenomena cause
trouble in the POS-tagging of Northern
Sotho.
1 Introduction
In this paper, we discuss issues of the part-of-
speech (POS) tagging of Northern Sotho, one of
the eleven official languages of South Africa, spo-
ken in the North-east of the country. Northern
Sotho is a Bantu language belonging to the Sotho
family (Guthrie, 1967: S32). It is written disjunc-
tively (contrary to e.g. Zulu), i.e. certain mor-
phemes appear as character strings separated by
blank spaces. It makes use of 18 noun classes (1,
1a, 2, 2b, 3 to 10, 14, 15, and the locative classes
16, 17, 18, N-, which may be summarized as LOC
for their identical syntactic features). A concor-
dial system helps to verify agreement or resolve
ambiguities.
We address questions of the ambiguity of func-
tion words, in the framework of an attempt to use
?standard? European-style statistical POS taggers
on Northern Sotho texts.
In the remainder of this section, we briefly dis-
cuss our objectives (section 1.1) and situate our
work within the state of the art (section 1.2). Sec-
tion 2 deals with the main issues at stake, the han-
dling of unknown open class words, and the pol-
ysemy of Northern Sotho function words. In sec-
tion 3, we discuss our methodology, summarizing
the tagset and the tagging technique used, and re-
porting results from other taggers. Section 4 is
devoted to details of our own results, the effects
of the size of training material (4.2), the effects
of polysemy and reading frequency (4.3), and it
includes a discussion of proposals for quality im-
provement (Spoustova? et al, 2007). We conclude
in section 5.
1.1 Objectives
The long term perspective of our work is to sup-
port information extraction, lexicography, as well
as grammar development of Northern Sotho with
POS-tagged and possibly parsed corpus data. We
currently use the 5.5 million word University of
Pretoria Sepedi Corpus (PSC, cf. de Schryver
and Prinsloo (2000)), as well as a 45,000 words
training corpus. We aim at high accuracy in the
POS-tagging, and at minimizing the amount of un-
known word forms in arbitrary unseen corpora, by
using guessers for the open word classes.
1.2 Recent work
A few publications, so far, deal with POS-tagging
of Northern Sotho; most prominently, de Schryver
and de Pauw (2007) have presented the MaxTag
method, a tagger based on Maximum Entropy
38
Learning (Berger et al, 1996) as implemented in
the machine learning package Maxent (Le, 2004).
When trained on manually annotated text, it ex-
tracts features such as the first and last letter of
each word, or the first two and last two letters or
the first three and last three letters of each word;
it takes the word and the tag preceding and fol-
lowing the item to be tagged, etc., to decide about
word/tag probabilities. De Schryver and de Pauw
report an accuracy of 93.5 % on unseen data, using
a small training corpus of only ca. 10,000 word
forms.
Other work is only partly engaged in POS-
tagging, e.g. Kotze??s (2008) finite state analysis of
the verb complex of Northern Sotho. This study
does not cover all parts of speech and can thus not
be directly compared with our work. Taljard et al
(2008) and Van Rooy and Pretorius (2003) present
tagsets for Northern Sotho and the closely related
language Setswana, but they focus on the defini-
tion of the tagsets without discussing their auto-
matic application in detail. In (Prinsloo and Heid,
2005), POS-tagging is mentioned as a step in a
corpus processing pipeline for Northern Sotho, but
no experimental results are reported.
2 Challenges in tagging Northern Sotho
POS-tagging of Northern Sotho and of any dis-
junctively written Bantu language has to deal es-
pecially with two major issues which are con-
sequences of their morphology and their syntax.
One is the presence, in any unseen text, of a num-
ber of lexical items which are not covered by the
lexicon of the tagger (?unknown words?), and the
other is an extraordinarily high number of ambigu-
ous function words.
2.1 Unknown words
In Northern Sotho, nouns, verbs and adverbs are
open class items; all other categories are closed
word classes: their items can be listed. The open
classes are characterized in particular by a rich
morphology: nouns can form derivations to ex-
press diminutives and augmentatives, as well as
locative forms, to name just a few. Adding the
suffix -ng to toropo ?town?, for example, forms
toropong, ?in/at/to town?. For verbs, tense, voice,
mood and many other dimensions, as well as nom-
inalization, lead to an even larger number of de-
rived items. Prinsloo (1994) distinguishes 18 clus-
ters of verbal suffixes which give rise to over 260
individual derivation types per verb. Only a few
of these derivations are highly frequent in corpus
text; however, due to productivity, a large number
of verbal derivation types can potentially appear in
any unseen text.
For tagging, noun and verb derivations show up
as unknown items, and an attempt to cover them
within a large lexicon will partly fail due to pro-
ductivity and recursive applicability of certain af-
fixes. The impact of the unknown material on
tagging quality is evident: de Schryver and de
Pauw (2007) report 95.1 % accuracy on known
items, but only 78.9 % on unknowns; this leads
to a total accuracy of 93.5 % on their test corpus.
We have carried out experiments with a version
of the memory-based tagger, MBT (Daelemans et
al., 2007), which arrives at 90.67 % for the known
items of our own test corpus (see section 3.2), as
opposed to only 59.68 % for unknowns.
To counterbalance the effect of unknown items,
we use rule-based and partly heuristic guessers for
noun and verb forms (cf. Prinsloo et al (2008) and
(Heid et al, 2008)) and add their results to the tag-
ger lexicon before applying the statistical tagger:
the possible annotations for all words contained in
the text are thus part of the knowledge available to
the tagger.
Adverbs are also an open word class in North-
ern Sotho; so far, we have no tools for identifying
them. In high quality tagging, the suggestions of
our guessers are examined manually, before they
are added to the tagger lexicon.
2.2 Polysemous function words and
ambiguity
Function words of Northern Sotho are highly am-
biguous, and because of the disjunctive writing
system of the language, a number of bound mor-
phemes are written separately from other words.
A single form can have several functions. For
example, the token -a- is nine-ways ambiguous:
it can be a subject concord of noun class 1 or 6,
an object concord of class 6, a possessive concord
of class 6, a demonstrative of class 6, a hortative
or a question particle or a verbal morpheme in-
dicating present tense or past tense (Appendix A
illustrates the ambiguity of -a- with example sen-
tences). Furthermore, the most polysemous func-
tion words are also the most frequent word types in
corpora. The highly ambiguous item go1 alone ac-
111 different functions of go may be distinguished: object
39
counts for over 5 % of all occurrences in our train-
ing corpus, where 88 types of function words, with
an average frequency of well over 200, make up
for about 40 % of all occurrences.
The different readings of the function words are
not evenly distributed: some are highly frequent,
others are rare. Furthermore, many ambiguous
function words appear in the context of other func-
tion words; thus the local context does not nec-
essarily disambiguate individual function words.
This issue is particularly significant with ambigu-
ities between concords which can have the same
function (e.g. object) in different noun classes. As
mentioned, -a- can be a subject concord of either
noun class 1 or 6: though there are some clearcut
cases, like the appearance of a noun of class 6 (in-
dicating class 6), or an auxiliary or the conjunction
ge in the left context (both rather indicating class
1) there still remain a number of occurrences of -a-
in the corpora only where a broader context, some-
times even information from preceding sentences,
may help to disambiguate this item.
Consequently, comparing tagging performance
across different tagsets does not give very clear re-
sults: if a tagset, like the one used by de Schryver
and de Pauw (2007), does not distinguish noun
classes, obviously a large number of difficult dis-
ambiguation cases does not appear at all (their
tagset distinguishes, for example, subject and ob-
ject concord, but gives no information on noun
class numbers). For the lexicographic applica-
tion we are interested in, and more generally as a
preparatory step to chunking or parsing of North-
ern Sotho texts, an annotation providing informa-
tion on noun classes is however highly desirable.
3 Methodology
3.1 Tagset
There are several proposals for tagsets to be used
for Northern Sotho and related languages. Van
Rooy and Pretorius (2003) propose a detailed
tagset for Setswana, which is fully in line with
the guidelines stated by the EAGLES project, cf.
Leech and Wilson (1999). This tagset encodes a
considerable number of semantic distinctions in
its nominal and verbal tags. In Kotze??s work on
concord of class 15, object concord of the locative classes,
object concord of the 2nd person singular, subject concord
of class 15, indefinite subject concord, subject concord of
the locative classes, class prefix of class 15, locative particle,
copulative indicating either an indefinite subject, or a subject
of class 15 or a locative subject.
the Northern Sotho verb complex, (Kotze?, 2008),
a number of POS tags are utilized to distinguish
the elements of the verb, however, due to Kotze??s
objectives, her classification does not cover other
items. De Schryver and de Pauw (2007) use a
tagset of only 56 different tags, whereas the pro-
posal by Van Rooy and Pretorius leads to over 100
tags. Finally, Taljard et al (2008) propose a rather
detailed tagset: contrary to the other authors men-
tioned, they do encode noun classes in all relevant
tags, which leads to a total of 141 tags. Further-
more, they encode a number of additional mor-
phosyntactic distinctions on a second level of their
tagset, which leads to a total of 262 different clas-
sifications of Northern Sotho morphemes.
Our current tagset is inspired by Taljard et al
(2008). However, we disregard some of their sec-
ond level information for the moment (which in
many cases encodes lexical properties of the items,
e.g. the subdivision of particles: hortative, ques-
tion, instrumental, locative, connective, etc.). We
use the RF-tagger (Schmid and Laws, 2008) (cf.
section 3.3), which is geared towards the annota-
tion of structured tagsets, by separating informa-
tion which partitions the inventory of forms (e.g.
broad word classes) from feature-like information
possibly shared by several classes, such as the
Sotho noun classes. With this method, we are able
to account for Taljard et al?s (2008) 141 tags by
means of only 25 toplevel tags, plus a number of
feature-like labels of lower levels. We summarize
the properties of the tagsets considered in table 1.
3.2 Training corpus
Our training corpus consists of ca. 45.000 manu-
ally annotated word forms, from two text types.
Over 20.000 word forms come from a novel of
the South African author Oliver K. Matsepe (Mat-
sepe, 1974); over 10.000 forms come from a Ph.D.
dissertation by Raphehli M. Thobakgale (Thobak-
gale, 2005), and another 10.000 from a second
Ph.D. dissertation, by Ramalau R. Maila (Maila,
2006). Obviously, this is not a balanced corpus; it
was indeed chosen because of its easy accessibil-
ity. We use this corpus to train our taggers and to
test them; in a ten-fold cross validation, we split
the text into ten slices of roughly equal size, train
on 9 of them and test on the tenth. In this article,
we give figures for the median of these results.
40
Authors No. of tags ? noun class tool?
(van Rooy and Pretorius, 2003) 106 - noun class no
(De Schryver and De Pauw, 2007) 56 - noun class yes
(Kotze?, 2008) partial N.R. yes
(Taljard et al, 2008) 141/262 + noun class no
This paper 25/141 + noun class yes
Table 1: Tagsets for N. Sotho: authors, # of tags, consideration of the noun class system, use in tools
3.3 Tagging techniques: the RF-tagger
We opt for the RF-tagger (Schmid and Laws,
2008), because it is a Hidden-Markov-Model
(HMM) tagger which was developed especially
for POS tagsets with a large number of (fine-
grained) tags. Tests with our training corpus have
shown that this tagger outperforms the Tree-tagger
((Schmid, 1994) and (Schmid, 1995)), as shown in
figure 1. An additional external lexicon may serve
as input, too. The development of the RF-tagger
was based on the widely shared opinion that for
languages like German or Czech, agreement in-
formation (e.g. case, number or person) should
preferably appear as part of all appropriate part
of speech tags. However, as tagsets increase im-
mensely in size when such information is part of
the tags, the data are decomposed, i.e. split into
several levels of processing. The probability of
each level is then calculated separately (the joint
probability of all levels is afterwards calculated as
their product). With such methodology, a tag of
the German determiner das may contain five levels
of information, e.g. ART.Def.Nom.Sg.Neut to de-
fine a definite, nominative singular, neutral deter-
miner (article) that appears in the nominative case.
This approach makes sense for the Bantu-
languages as well, since information on noun class
numbers should be part of the noun tags, too, as in
Taljard et als (2008) tagset. A noun here is not
only tagged ?N?, but Nclass, e.g. mohumagadi
?(married) woman? as N01. All concords, pro-
nouns or other types that concordially agree with
nouns are also labelled with a class number, e.g.
o, the subject concord of class 1, is labelled CS01.
This approach makes sense, especially in the view
of chunking/parsing and reference resolution, be-
cause any of those elements can acquire a pronom-
inal function when the noun that they refer to is
deleted (Louwrens, 1991).
To utilize the RF-tagger, we split all tags con-
taining noun class numbers into several levels (e.g.
the tag N01 becomes N.01). Emphatic and posses-
sive pronouns are represented on three levels (e.g.
PROPOSSPERS becomes PRO.POSS.PERS)2.
4 Results
In a preliminary experiment, we compared several
taggers3 on our manually annotated data. Apart
from the RF-tagger (Schmid and Laws, 2008),
we also used the Tree-Tagger (Schmid, 1994), the
TnT tagger (Brants, 2000) and MBT (Daelemans
et al, 2007).
4.1 Comparing taggers
The results give a relatively homogenous picture,
with the RF-tagger achieving a median of 94.16 %
when utilising a lexicon containing several thou-
sand nouns and verbs. It leads to 91 % accuracy
without this lexicon (to simulate similar condi-
tions as for TnT or MBT where no external lex-
icon was offered). TnT achieves 91.01 %, and
MBT 87.68 %. Data from the Tree-Tagger were
not comparable for they had been obtained at an
earlier stage using the lexicon (92.46 %).
4.2 Effects of the size of the training corpus
on the tagging results
All probabilistic taggers are in need of training
data the size of which depends on the size of the
tagset and on the frequencies of occurrence of
each context. De Schryver and de Pauw (2007)
demonstrated that when utilizing a tagset that con-
tains only about a third of the tags (56) contained
in Taljard et al?s (2008) tagset (141), their Max-
Tag POS-tagger reaches a 93.5 % accuracy with a
training corpus of only about 10,000 tokens.
Figure 1 depicts the effects of the size of the
training corpus on the accuracy figures of the Tree-
tagger and the RF-tagger. Tests with training cor-
pora of the sizes 15,000, 30,000 and 45,000 tokens
2Tests have shown that the quantitative pronouns should
be treated separately, their tags are thus only split into two
levels.
3Check the References section for the availability of these
taggers.
41
Figure 1: Effects of the size of the training corpus
on tagger results.
showed that the results might not improve much if
more data is added. The RF-tagger already reaches
more than 94 % correctness when utilizing the cur-
rent 45,000 token training corpus.
4.3 Effects of the highly polysemous function
words of Northern Sotho
The less frequently a token-label pair appears in
the corpus, the lower is its probability (leading to
the sparse data problem, when probability guesses
become unreliable because of low numbers of oc-
currences). This issue poses a problem for North-
ern Sotho function words: if they occur very fre-
quently with a certain label, the chances of them
being detected with another label are fairly low.
This effect is demonstrated in table 2, which de-
scribes the detection of the parts of speech of the
highly ambiguous function word -a-. The word -
a- as PART(icle) occurs only 45 times while -a-
as CS.01 occurs 1,182 times. More than 50 % of
the particle occurrences (23) are wrongly labelled
CS.01 by the tagger. In table 2, we list the cor-
rect tags of all occurrences of -a-, as well as the
assigned tags to each of them by our tagger. Each
block of table 2 is ordered by decreasing numbers
of occurrence of each tag in the output of the RF-
tagger. For easier reference, the correct tags as-
signed by the RF-tagger are printed in bold. Table
2 also clearly shows the effect of ambiguous local
context on the tagging result: the accuracy of the
CS.06-annotation (subject concord of class 6) is
considerably lower than that of the more frequent
CS.01 (96.45 % vs. 63.08 %), and CS.01 is the
most frequent error in the CS.06 assignment pro-
a as freq RF-tagger sums %
CS.01 1182 CS.01 1140 96.4
CS.06 19 1.6
MORPH 14 1.2
CDEM.06 3 0.3
PART 2 0.2
CPOSS.06 2 0.2
CO.06 2 0.2
CS.06 176 CS.06 111 63.1
CS.01 43 24.4
CPOSS.06 10 5.7
CDEM.06 5 2.8
MORPH 3 1.7
PART 3 1.7
CO.06 1 0.6
CO.06 18 MORPH 7 38.9
CS.01 6 33.3
CO.06 3 16.7
CS.06 2 11.11
PART 45 CS.01 23 51.1
MORPH 11 24.4
CDEM.06 5 11.1
PART 5 11.1
CPOSS.06 1 2.2
CDEM.06 97 CDEM.06 89 91.8
CPOSS.06 4 4.1
CS.06 2 2.1
CS.01 1 1.0
PART 1 1.0
CPOSS.06 209 CPOSS.06 186 89.0
CDEM.06 12 5.7
CS.06 6 2.9
PART 4 1.9
CS.01 1 0.5
MORPH 89 MORPH 44 49.4
CO.06 26 29.2
CS.01 15 16.9
CPOSS.06 4 4.5
sums 1816 1816
Table 2: RF-tagger results for -a-
cess.
4.4 Suggestions for increasing correctness
percentages
Spoustova? et al (2007) describe a significant in-
crease of accuracy in statistical tagging when uti-
lizing rule-based macros as a preprocessing, for
Czech. We have contemplated, in an earlier stage
of our work (Prinsloo and Heid, 2005) to adopt a
42
similar strategy, i.e. to design rule-based macros
for the (partial) disambiguation of high-frequency
function words. However, the fact that the local
context of many function words is similar (i.e. the
ambiguity of this local context (see above)), is a
major obstacle to a disambiguation of single func-
tion words by means of rules. Rules would interact
in many ways, be dependent on the application or-
der, or disambiguate only partially (i.e. leave sev-
eral tag options). An alternative would be to de-
sign rules for the disambiguation of word or mor-
pheme sequences. This would however amount to
partial parsing. The status of such rules within a
tagging architecture would then be unclear.
4.5 Effects of tagset size and structure
While a preprocessing with rule-based disam-
biguation does not seem to be promising, there
are other methods of improving accuracy, such as,
e.g., the adaptation of the tagset. Obviously, types
appearing in different contexts should have differ-
ent labels. For example, in the tagset of Taljard et
al. (2008), auxiliary verbs are a sub-class of verbs
(V aux). In typical Northern Sotho contexts, how-
ever, auxiliaries are surrounded by subject con-
cords, while verbs are only preceded by them.
When ?promoting? the auxiliaries to the first level
by labelling them VAUX, the RF-tagger result in-
creases by 0.13 % to 94.16 % accuracy. We still
see room for further improvement here. For exam-
ple, ga as PART (either locative particle PART loc
or hortative particle PART hort) is identified cor-
rectly in only 29.2 % of all cases at the moment.
The hortative particle usually appears at the be-
ginning of a verbal segment, while the locative in
most cases follows the segment. Results may in-
crease to an even higher accuracy when ?promot-
ing? these second level annotations, hort(ative) and
loc(ative) to the first annotation level.
5 Conclusions and future work
This article gives an overview of work on POS-
tagging for Northern Sotho. Depending on the
place of tagging in an overall NLP chain for this
language, different choices with respect to the
tagset and to the tagging technology may prove
adequate.
In our work, which is part of a detailed lin-
guistic annotation of Northern Sotho corpora for
linguistic exploration with a view to lexicons and
grammars, it is vital to provide a solid basis for
chunking and/or parsing, by including informa-
tion on noun class numbers in the annotation.
We found that the RF-tagger (Schmid and Laws,
2008) performs well on this task, partly because
it allows us to structure the tagset into layers, and
to deal with noun class information in the same
way as with agreement features for European lan-
guages. We reach over 94 % correctness, which
indicates that at least a first attempt at covering the
PSC corpus may now be in order.
Our error analysis, however, also highlights a
few more general aspects of the POS annotation
of Northern Sotho and related languages: obvi-
ously, frequent items and items in distinctive lo-
cal contexts are tagged quite well. When noun
class information is part of the distinctions under-
lying the tagset, function words usable for more
than one noun class tend however, to appear in
non-distinctive local contexts and thus to lead to
a considerable error rate. Furthermore, we found a
few cases of uses of, e.g., subject concords that are
anaphoric, with antecedents far away and thus not
accessible to tagging procedures based on the lo-
cal context. These facts raise the question whether,
to achieve the highest quality of lexical classifica-
tion of the words and morphemes of a text, chunk-
ing/parsing might be required altogether, rather
than tagging.
Our experiments also showed that several pa-
rameters are involved in fine-tuning a Sotho tag-
ger. The size and structure of the tagset is one
such a prominent parameter. Tendencies towards
simpler and smaller tagsets obviously conflict with
the needs of advanced processing of the texts and
of linguistically demanding applications. It seems
that tagset design and tool development go hand in
hand.
We intend to apply the current version of the
RF-tagger to the PSC corpus and to evaluate the
results carefully. We expect a substantial gain
from the use of the guessers for nouns and verbs,
cf. (Prinsloo et. al, 2008) and (Heid et al, 2008).
Detailed error analysis should allow us to also
design specific rules to correct the output of the
tagger. Instead of preprocessing (as proposed by
Spoustova? et al (2007)), a partial postprocess-
ing may contribute to further improving the overall
quality. Rules would then probably have to be ap-
plied to particular sequences of words and/or mor-
phemes which cause difficulties in the statistical
process.
43
References
Adam L. Berger, Stephen Della Peitra, and Vincent
J. Della Pietra. 1996. A Maximum Entropy Ap-
proach to Natural Language Processing. Computa-
tional Linguistics 22(1): pp. 39 ? 71.
Thorsten Brants. 2000. TnT - A Statistical Part-of-
Speech Tagger. In Proceedings of the Sixth Applied
Natural Language Processing Conference ANLP-
2000, Seattle, WA.
Walter Daelemans, Jakub Zavrel, Antal van den Bosch.
2007. MBT: Memory-Base Tagger, version 3.1. Ref-
erence Guide. ILK Technical Report Series 07?08
[online]. Available : http://ilk.uvt.nl/
mbt (10th Jan, 2009).
Gilles-Maurice de Schryver and Guy de Pauw. 2007.
Dictionary Writing System (DWS) + Corpus Query
Package (CQP): The Case of TshwaneLex. Lexikos
17 AFRILEX-reeks/series 17:2007: pp. 226 ?
246. [Online tagger:] http://aflat.org/?q=
node/177. (10th Feb, 2009)
Gilles-Maurice de Schryver and Daan J. Prinsloo.
2000. The compilation of electronic corpora with
special reference to the African languages. South-
ern African Linguistics and Applied Language Stud-
ies 18(1-4): pp. 89 ? 106.
Malcolm Guthrie. 1971. Comparative Bantu: an in-
troduction to the comparative linguistics and prehis-
tory of the Bantu languages, vol 2, Farnborough:
Gregg International.
Ulrich Heid, Daan J. Prinsloo, Gertrud Faa?, and
Elsabe? Taljard. 2008 Designing a noun guesser for
part of speech tagging in Northern Sotho (33 pp).
ms: University of Pretoria.
Petronella M. Kotze?. 2008. Northern Sotho grammat-
ical descriptions: the design of a tokeniser for the
verbal segment. Southern African Linguistics and
Applied Language Studies 26(2): pp. 197 ? 208.
Zhang Le. 2004. Maximum Entropy Modeling Toolkit
for Python and C++ (Technical Report) [online].
Available: http://homepages.inf.ed.
ac.uk/s0450736/maxent_toolkit.html
(10th Jan, 2009).
Geoffrey Leech, Andrew Wilson. 1999. Standards for
Tagsets. in van Halteren (Ed.) Syntactic world-class
tagging: pp. 55 ? 80 Dordrecht/Boston/London:
Kluwer Academic Publishers.
Louis J. Louwrens. 1991. Aspects of the Northern
Sotho Grammar p. 154. Pretoria:Via Afrika.
Ramalau A. Maila. 2006. Kgolo ya tiragatso ya Se-
pedi. [=?Development of the Sepedi Drama?]. Doc-
toral thesis. University of Pretoria, South Africa.
Oliver K. Matsepe. 1974. Ts?a Ka Mafuri. [=?From the
homestead?]. Pretoria: Van Schaik.
Daan J. Prinsloo. 1994. Lemmatization of verbs in
Northern Sotho. SA Journal of African Languages
14(2): pp. 93 ? 102.
Daan J. Prinsloo and Ulrich Heid. 2005. Creating
word class tagged corpora for Northern Sotho by lin-
guistically informed bootstrapping. in: Isabella Ties
(Ed.): LULCL, Lesser used languages and compu-
tational linguistics, 27/28-10-2005, Bozen/Bolzano,
(Bozen: Eurac) 2006: pp. 97 ? 113.
Daan J. Prinsloo, Gertrud Faa?, Elsabe? Taljard, and
Ulrich Heid. 2008. Designing a verb guesser for
part of speech tagging in Northern Sotho. Southern
African Linguistics and Applied Languages Studies
(SALALS) 26(2).
Helmut Schmid and Florian Laws. 2008. Es-
timation of Conditional Probabilities with
Decision Trees and an Application to Fine-
Grained POS Tagging [online]. COLING
2008. Manchester, Great Britain. Available:
http://www.ims.uni-stuttgart.de/
projekte/corplex/RFTagger/ (10th Jan,
2009).
Helmut Schmid. September 1994. Probabilistic
Part-of-Speech Tagging Using Decision Trees. Pro-
ceedings of the International Conference on New
Methods in Language Processing[online]. Avail-
able: http://www.ims.uni-stuttgart.
de/projekte/corplex/TreeTagger/
(10th Jan, 2009).
Helmut Schmid. March 1995. Improvements in Part-
of-Speech Tagging with an Application to German.
Proceedings of the ACL SIGDAT-Workshop.
Drahom??ra ?johanka? Spoustova?, Jan Hajic?, Jan
Votrubec, Pavel Krbec, and Pavel Kve?ton?. Jun
29, 2007. The best of two worlds: Coop-
eration of Statistical and Rule-based Taggers
for Czech. Balto-Slavonic Natural Language
Processing: pp. 67 ? 74 [online]. Available:
http://langtech.jrc.it/BSNLP2007/
m/BSNLP-2007-proceedings.pdf (10th
Jan, 2009).
Elsabe? Taljard, Gertrud Faa?, Ulrich Heid and Daan J.
Prinsloo. 2008. On the development of a tagset for
Northern Sotho with special reference to standardi-
sation. Literator 29(1) 2008. Potchefstroom, South
Africa.
Raphehli M. Thobakgale. Khuets?o ya OK Matsepe go
bangwadi ba Sepedi [=?Influence of OK Matsepe
on the writers of Sepedi?]. Doctoral thesis. Univer-
sity of Pretoria, South Africa.
Bertus van Rooy and Rigardt Pretorius. 2003. A word-
class tagset for Setswana. Southern African Linguis-
tics and Applied Language Studies 21(4): pp. 203 ?
222.
44
Appendix A. The polysemy of -a-
Description Example
1 Subject ge monna a fihla
concord of conjunctive + noun cl. 1 + subject concord cl. 1 + verb stem
if/when + man + subj-cl1 + arrive
?when the man arrives?
2 Subject masogana a thus?a basadi
concord of noun cl. 6 + subject concord cl. 6 + verb stem + noun cl.2
nominal cl. 6 young men + subj-cl6 + help women
?the young men help the women?
3 Possessive maoto a gagwe
concord of noun cl. 6 + possessive concord cl. 6 + possessive pronoun cl. 1
nominal cl. 6 feet + of + his
?his feet?
4 Present tense morutis?i o a bits?a
morpheme noun cl. 1 + subject concord cl.1 + present tense marker + verb stem
teacher + subj-cl1 + pres + call
?the teacher is calling?
5 Past tense morutis?i ga o a bits?a masogana
morpheme noun cl. 1 + negation morpheme + subject concord cl.1 +
past tense marker + verb stem + noun cl. 6
teacher + neg + subj-cl1 + past + call + young men
?the teacher did not call the young men?
6 Demonstrative ba nyaka masogana a
concord of subject concord cl. 2 + verb stem + noun cl. 6 + demonstrative concord
nominal cl. 6 they + look for + young men + these
?they are looking for these young men?
7 Hortative a ba tsene
particle hortative particle + subject concord cl. 2 + verb stem
let + subj-cl2 + come in
?let them come in?
8 Interrogative a o tseba Sepedi
particle interrogative particle + subject concord 2nd pers sg. + verb stem + noun cl. 7
ques + subj-2nd-pers-sg + know + Sepedi
?do you know Sepedi?
9 Object moruti o a bidits?e
concord of noun cl. 1 + subject concord cl. 1 + object concord cl. 6 + verb stem
teacher + subj-cl1 + obj-cl6 + called
?the teacher called them?
45
Proceedings of the 8th Workshop on Asian Language Resources, pages 103?110,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
Building NLP resources for Dzongkha: 
A Tagset and A Tagged Corpus
Chungku Chungku, Jurmey Rabgay
Research Division
Department of Information Technology 
& Telecom
{chungku,jrabgay}@dit.gov.bt
Gertrud Faa?
Institute f?r Maschinelle 
Sprachverarbeitung(NLP processing), 
University of Stuttgart
faasz@ims.uni-stuttgart.de
Abstract
This paper describes the application of 
probabilistic  part  of  speech taggers  to 
the  Dzongkha  language.  A  tag  set 
containing 66 tags is designed, which is 
based  on  the  Penn  Treebank1.  A 
training  corpus  of  40,247  tokens  is 
utilized  to  train  the  model.  Using  the 
lexicon  extracted  from  the  training 
corpus and lexicon from the available 
word  list,  we  used  two  statistical 
taggers  for  comparison  reasons.  The 
best  result  achieved  was  93.1% 
accuracy in  a  10-fold cross  validation 
on the training set. The winning tagger 
was  thereafter  applied  to annotate  a 
570,247 token corpus.
1 Introduction
Dzongkha is  the national  language of Bhutan. 
Bhutan  has  only  begun  recently  applying 
Natural Language Processing (henceforth NLP) 
methodologies  and  tools.  However,  Dzongkha 
computing is currently progressing rapidly.
Part of speech (henceforth POS) tagging means 
annotating each word with their respective POS 
label  according  to  its  definition  and  context. 
Such annotation generates a description of the 
text  on  a  meta-level,  i.e.  a  representation  of 
linguistic units on the basis of their properties. 
This POS-level provides significant information 
usable by further linguistic research, may it be 
of  the  morphological,  syntactic  or  semantic 
1 [http://www.cis.upenn.edu/~treebank/]
kind. Producing such enriched data is proven to 
be  useful  especially  when  designing  NLP 
representations  of  higher  levels  of 
representation, e.g. syntactic parses. 
Our project  is  designed to annotate Dzongkha 
cyclopedia  text  with  parts  of  speech  using  a 
probabilistic  tagger.  This  means  that  a  set  of 
tags is to be developed and applied manually to 
parts  of  these  texts  creating  training  data. 
Probabilistic  taggers  can  then  be  applied  to 
annotate other texts with their  parts  of speech 
automatically. In this paper, we make use of two 
such taggers and report on their results.
At present,  our POS tagged data is already in 
use  in  projects  concerning  Dzongkha  Text  to 
Speech (TTS) processing, further tests on word 
segmentation  (see  current  state  below)  and  in 
corpus-linguistic  research.  Future  work  entails 
its utilization for higher-level NLP tasks such as 
parsing,  building parallel  corpora,  research on 
semantics, machine translation, and many more. 
Sections  2  and  3  of  this  paper  describe  the 
Dzongkha  script  and  the  challenges  in 
Dzongkha,  section  4  presents  our  resources, 
tagset and corpus. Section 5 describes tagging 
and  validation  processes  and  reports  on  their 
results. Section 6 concludes and discusses future 
work.
2  The Dzongkha Language 
Dzongkha  is  recognized  as  the  national  and 
official language of Bhutan. It is categorized as 
a  Sino-Tibetan  Language  and  said  to  have 
derived  from  the  classical  Tibetan  or  choka: 
Dzongkha  consonants,  vowels,  phonemes, 
phonetics and writing system are all identical. 
103
From a linguistic perspective, Dzongkha script 
is syllabic, a syllable can contain one character 
or as many as six characters. A syllable marker 
known  as  ?tsheg?,  which  is  simply  a 
superscripted  dot,  separates  the  syllables  of  a 
word.  Linguistic  words  may  contain  one  or 
more  syllables  and  are  also  separated  by  the 
same  symbol,  ?tsheg?,  thus  the  language  is 
lacking word boundaries.
Sentences  of  Dzongkha  contain  one  or  more 
phrases which themselves contain one or more 
words.  A character  known as  ?shed? marks  a 
sentence border, it looks like a vertical pipe.
Phonetic information is available, too: In most 
sentences, a pause of silence is taken after each 
phrase while speaking the Dzongkha language. 
The written form of Dzongkha represents this 
pause with a space after each phrase in the case 
that it occurs not at the end of the sentence. The 
Dzongkha  writing  system  leads  to  a  serious 
problem: the detection of word borders, because 
only  phrases  are  separated  by  a  space. POS 
tagging  usually  requires  a  one-token-per  line 
format,  which is produced by a process called 
word  segmentation.  The  tagger  then  adds  the 
POS category to each token. 
The  training  data  of  (40247  tokens)  was 
segmented manually to achieve higher accuracy 
of word boundary and also due to lack of word 
segmentation  during  that  time.  After  a 
Dzongkha  word  segmentation2 tool  was 
developed,  the  remaining  text  was  segmented 
with  this  tool,  which  works  basically  with  a 
lexicon and the longest string matching method.
3 Challenges  and  suggestions  for 
tagging Dzongkha texts
3.1 Words unknown to the language model
A  statistical  tagger  learns  from  POS  dis-
tributions in manually tagged data while being 
trained  and,  when  being  applied  to  unknown 
text,  ?guesses?  the  POS  of  each  word.  The 
TreeTagger (Schmid, 1994) additionally makes 
use  of  a  lexicon  externally  provided  when 
producing its  language model  (the  ?parameter 
file?). We had opted for using the TreeTagger 
2This tool was developed at NETEC(National Electronics 
and Computer Technology Center), Thailand.
and  hence  we  have  listed  about  28,300 
Dzongkha  words  with  their  POS in  a  lexicon 
selected from the 570,247 token corpus to  be 
tagged. We fed these data to  the tagger during 
its  training phase.  Note,  however,  that  such a 
lexicon  may  never  be  complete,  as  there  are 
morphologically  productive  processes  creating 
new forms (these belong to POS classes that are 
often named ?open?).  Such forms may be taken 
into  account  when  developing  a  tagset, 
however, in this work, we opted for postponing 
the issue until a morphological analyser can be 
developed.
3.2  Ambiguous function words
A  number  of  Dzongkha  function  words  are 
ambiguous; for each occurrence of such a word, 
the  tagger  has  to  decide  on  the  basis  of  the 
word?s contexts, which of the possible tags is to 
be assigned. Here, the tagset itself comes into 
view:  whenever  it  is  planned  to  utilize 
probabilistic POS taggers, the tagset should be 
designed  on  the  basis  of  the  words? 
distributions,  otherwise  the  potential  accuracy 
of the taggers may never be achieved.
In Dzongkha it is mainly the function words that 
are ambiguous in terms of their POS. A typical 
example  is  ???/le/(from)  belonging  to  the 
category  PP  (post  position)  and  ???/le/(so) 
which is of the category CC (conjunction). 
3.3 Fused forms
Some morpho-phonemic processes in Dzongkha 
lead to the fusing of words, presenting another 
challenge for tagging. Such words3 are not very 
frequent,  thus  proposing  a  challenge  to 
statistical  taggers.  The  word ????????/gelpoi/
(king[+genitive]),  for  example,  is  fused  from  the 
phrase  ?????????/gelpo  gi/  (king  is);  another 
example is the fused form ??????/sen/ ([to] kill), 
made from ????????????/se wa cin/ (if [to] kill).
When a tagset does not cater for fused forms of 
words,  one  could  split  these  forms  while 
tokenizing  adding  an  intermediate  level  of 
representation  between  original  text  level  and 
3 In our training set, there were 1.73% of all words 
detected as fused forms.
104
the  POS  level:  a  level  of  text  material  to  be 
utilized for tagging or other further processing, 
as  e.g.  done  by  (Taljard  et  al.,  2008)  for  the 
Bantu Language Northern Sotho. However, the 
forms  could not easily be split, as the resulting 
first  parts  of the words would not contain the 
separator  ?tsheg?.  Splitting  the  word ???
?????/gelpoi/  (king[+genitive]),  for  example,  would 
result  in  ?????/gelpo/(king)  and ???/yi/[+genitive]. 
The language model  does  not  cater  for  words 
ending in  characters  other than "tsheg" (word 
border) or being directly followed by "shed" (a 
word like ?????/gelpo/(king) may only appear if 
preceding a sentence border). Tagging accuracy 
for such theoretical forms are not expected to be 
acceptable. Fusing  processes  are  productive, 
therefore,  further  research  in  the  frame  of  a 
project  developing  a  Dzongkha  tokenizer  is 
deemed necessary.
We examined all fused words contained in our 
textual data to find an workable solution at the 
current  stage  of  the  project.  As  long  as  the 
problem  of  tokenizing  automatically  is  not 
solved, we opted for keeping the fused forms as 
they  are.  To  enhance  our  tagger  results,   we 
suggest to add  a number of tags to our tagset 
that consist of the two POS tags involved.  ???
?????/gelpoi/  (king[+genitive]),  for  example,  is 
tagged as ?NN+CG? and   ??????/sen/ ([to] kill) 
as  ?VB+SC?.  The  ?+?  indicates  combined 
individual tags. All known forms are added to a 
new version of the lexicon. Note, however, that 
all tagging results reported upon in this paper, 
are still based on the tag set described below.
4  Resources used
4.1  Tagset
During  the  first  phase  of  PAN  Localization 
project,  the  first  Dzongkha  POS  tagset4 was 
created.  It  consisted  of  47  tags,  its  design  is 
based on the Penn Guidelines5 and its categories 
of  POS  correspond  to  the  respective  English 
Penn categories.  PAN generally makes  use of 
4 The original Dzongkha tag set is described at 
http://www.panl10n.net
5 The Penn Guidelines can be downloaded from: 
http://www.cis.upenn.edu/~treebank/
the Penn Treebank tags as a basis for tagging. 
Examining  the  similar  features  exhibited  by 
both  the  languages  (Dzongkha  and  English), 
tags  that  were  applicable  to  Dzongkha  were 
taken directly from the Penn Treebank. In cases 
where these languages showed dissimilarities in 
their  nature,  new  tags  for  Dzongkha  were 
assigned  (based  e.g.  on  the  work  on  Urdu of 
Sajjad and Schmid,  2009). As an example  for 
such dissimilarity,  Dzongkha postpositions are 
mentioned here, cf. (1); the respective tag (PP) 
only exist for Dzongkha whereas in English the 
whole set  of  ad position tags (preposition and 
postpositions) exist. 
        (1)   ?????? ??????????????? 
j'ili shing-gi w?lu -d?
Cat tree[posp] under[PP] be
''A cat is under the tree''
Whenever  a  tagset  designed  on  theoretical 
implications is applied to text, it will be found 
in the course of creating the training data that 
not  all  morpho-syntactic  phenomena  of  the 
language  had been considered.  This  happened 
for Dzongkha, too: words appeared in the texts 
that didn't fit in any of the pre-defined classes. 
Dzongkha uses honorific forms:  ??????/nam za/
(cloths)  is  the  honorific  form  of  the  noun  ???
??/gola/(cloths),  ?????/sung/(tell)  the  honorific 
form of the verb ???/lab/(tell). We opted to mark 
them  by  adding  the  tag  NNH  (honorific 
common  noun)  and  VBH  (honorific  verb)  to 
enable future research on this specific usage of 
Dzongkha  language.  A  number  of  tags  were 
added to the set, of which we describe four in 
more detail: two of the additional tags are sub-
classes  of  verbs:  VBH (honorific  verb  form), 
and VBN which describes past participle forms, 
like,  e.g.  ????/jun/(created),  the  past  particle 
form of ???/jung/(create).
Concerning case,  we  added two subclasses  of 
case: CDt and CA. These differentiate between 
dative  (CDt)  and  ablative  (CA):  The  CDt 
(Dative  case)  labels  e.g.???????/doen  le/(for  it) 
and  ??????/doen lu/(for  this).  The Ablative  case 
105
(CA)  is  used  when  the  argument  of  the 
preposition describes a source. For example, in 
the phrase   ?????????????/shing le kang thri/(from 
wood chair),  ???/le/from/   will  be labeled CA 
since  the  chair  described  is  made  from  (the 
source)  wood  (Muaz,  et  al.  2009).  The  tagset 
utilized in our experiment consists of a total of 
66 parts of speech as shown in Appendix (A).
4.2 Collecting a Corpus and generating a 
training data set
The Corpus collection process. The process of 
collecting  a  corpus  should  be  based  on  its 
purpose.  As  our  goal  was  the  design  a 
Dzongkha text corpus as balanced as possible in 
terms of its linguistic diversity, the text data was 
gathered from different sources like newspaper 
articles,  samples  from  traditional  books,  and 
dictionaries,  some  text  was  added  manually 
(poetry and songs). The text selection was also 
processed with a view on the widest range of 
genres possible: texts from social science, arts 
and culture, and texts describing world affairs, 
travel adventure, fiction and history books were 
added as our goal is to make it representative of 
every  linguistic  phenomena  of  language 
(Sarkar, et al 2007). The corpus is however not 
balanced  for  a  lack  of  available  electronic 
resources of informative text (so far only 14% 
belong  to  this  category).  Future  work  will 
therefore  entail  collecting  more  data  from 
respective websites and newspapers. 
The  entire  corpus  contains  570,247  tokens;  it 
made from the domains described in table (1).
Domain Share % Text type
1) World Affairs 12% Informative  
2) Social Science 2% Informative
3) Arts 9% Descriptive
4) Literature 72% Expository
5) Adventure 1% Narrative 
6) Culture 2% Narrative 
7) History 2% Descriptive
Table (1): Textual domains contained 
in the corpus
The Training data set
Cleaning  of  texts.  Raw text  is  usually  to  be 
modified before it can be offered to a tagger. It 
is  to  be  cleaned  manually,  e.g.  by  removing 
extra  blank  spaces,  inserting  missing  blanks, 
correcting spelling mistakes,  and by removing 
duplicate  occurrences  of  sequences.  Secondly, 
the  process  of  tokenization  (?Word 
Segmentation?) is to be applied.
Design and generation of training data.  The 
training data set was produced in several steps: 
Firstly,  20,000  tokens  were  manually  labeled 
with  their  respective  parts  of  speech (for  a 
comparison of tagging techniques, cf. Hasan et 
al.,   2007). Thereafter,  the  problems  that  had 
occurred  during  the  manual  process  were 
summarized and the tagset revised as described 
in  section  4.1.  Thereafter,  we  added  another 
20,247 tokens. The final training data set hence 
consists  of  40,247  tokens  (2,742  sentences, 
36,362 words, 3,265 punctuation, 650 numbers).
4.3 Tagging  technique:  TreeTagger  and 
TnT
TreeTagger  (Schmid,  1994): TreeTagger 
(Schmid, 1994) is a probabilistic part of speech 
tagger operating on the basis of decision trees. 
Helmut Schmid developed it in the frame of the 
?TC?6 project at the Institute for Computational 
Linguistics  at  the  University  of  Stuttgart, 
Germany.
The software consists of two modules 
a)  train-tree-tagger:  utilized  to  generate  a 
parameter  file  from  a  lexicon  and  a  hand-
tagged corpus.
b) tree-tagger: makes use of the parameter file 
generated with a); annotates text (which is to 
be  tokenized  first)  with  part-of-speech 
automatically.
a) Generating a language model: Training
When generating a language model stored in a 
so-called  ?parameter  file?,  three  files  are 
required: a lexicon describing tokens and their 
respective tags, a list of open tags, and training 
6 The tagger is freely available at http://www.ims.uni-
stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTag
ger.html 
106
data. The ?train-tree-tagger? module generates 
a binary parameter file.
The lexicon is a file that contains tokens (word 
forms and punctuation),  in the format  of one 
per  line.  The  TreeTagger  was  developed  for 
languages with inflection, i.e. languages where 
one  word  may  occur  in  a  number  of 
allomorphs. To ease the task of tagging such 
languages, the tool can operate on the level of 
a base form, the ?lemma? which may be added 
to every word form. In the case of Dzongkha, 
lemmatization  has  not  been  developed  yet, 
therefore, we either make use of the word form 
itself, or a hyphen in the case that no lemma is 
available.  As  table  (2)  demonstrates,  the 
lexicon  contains  the  word  forms  in  the  first 
column, the second column contains the POS 
and  the  third  a  hyphen.  In  the  case  of 
ambiguous  entries,  one  line  may  contain  a 
sequence of tag-?lemma? pairs that follow the 
word  form  of  the  first  column.  The  lexicon 
may not contain any spaces; all columns must 
be  separated  by  exactly  one  tab(ulator). 
Because the lexicon is only made use of during 
the  training  phase  of  the  tagger,  any  update 
must result in reproducing the parameter file. 
Word Pos tag lemma Pos tag lemma
?? NN ??
???? NN ???
?????? NNP --
??? PP ??? CC ???
Table (2) Example entries of the lexicon 
Open class  tags:  a  file  containing  the  list  of 
open class tags, i.e. the productive classes (one 
entry per line), cf. Appendix A. In the upcoming 
version of the tagset, tags of the following fused 
forms  will  be  added,  like,  e.g.  NN+CG 
(combination of all  forms nouns with genitive 
case  CG),  VB+CG (combination  of  all  forms 
verb  with  genitive  case  CG),  JJ+CG 
(combination  of  all  forms  of  adjective  with 
genitive case CG), RB+CG (combination of all 
adverb with genitive case CG), and same with 
the  combination  of  Subordinate  conjunction 
NN+SC, VB+SC, JJ+SC, RB+SC, just to name 
a few. 
Tagged  training  data: a  file  that  contains 
tagged training data. The data must be stored in 
one-token-per-line format. This means that each 
line contains one token and its  respective tag, 
these  are  separated  by one tabulator.  The file 
should be cleaned from empty lines, no meta-
information,  like,  e.g.  SGML  markup  is 
allowed.
b) Tagging
Two files serve as input: the binary parameter 
file and a text file that is to be tagged.
Parameter file: the file that was generated by 
step a) above.
Text  file:  a  file  that  is  to  be  tagged;  it  is 
mandatory that the data in this file appears in a 
one-token-per line format.
TnT  (Brants,  2000):The  Trigram?s?n?Tags 
(TnT) tagger was developed by Thorsten Brants 
(Brants, 2000). It  is language independent and 
has  been  used  widely  for  a  number  of 
languages, often yielding an accuracy of +96% 
without utilizing an external lexicon or an open 
word  class  file.  TnT  is  based  on  Markov 
models, and takes not only distributional data of 
tokens,  but  also  the  final  sequences  of 
characters  of  a  token  into  account  when 
guessing the POS of a word. It can use the same 
format  for  training  data  as  the  TreeTagger, 
therefore,  in order to use TnT for comparison 
reasons, no additional preparations for tagging 
Dzongkha are necessary.
5 Validation and Results
5.1 k-fold  cross  validation  and 
bootstrapping
When applying a tagset to training data for the 
first time, it is advisable to progress in steps and 
to  validate  each  step  separately:  One  begins 
with  annotating  a  rather  small  portion  of  text 
that  is  then  divided  into  k  number  of  slices. 
Slices k-1 are then utilized to create a parameter 
file, the slice k is stripped of its annotations and 
annotated  by  the  tagger  using  that  parameter 
file.  The  same  procedure  is  followed  for  all 
other  slices  (?k-fold  cross  validation?). 
107
Afterwards, a comparison between the original 
tags with the tags assigned by the tagger will 
then help to judge upon a number of issues, like, 
e.g.,  whether  the  size  of  the  training  data  is 
sufficient  (quantitative review). Examining the 
most frequent (typical) assignment errors of the 
tagger will also support the enhancement of the 
tagset:  if  e.g.  the  distribution of  two different 
tags  is  more  or  less  identical,  a  probabilistic 
tagger  will  not  succeed  in  making  the  right 
choices, here, one is to consider if using one tag 
would be acceptable from a linguistic point of 
view (qualitative review).
The  knowledge  gained  here  usually  leads  to 
updates in the tagset and/or to the necessity to 
add  more  amounts  of  texts  containing 
constellations  that  were  found  as  being 
problematic  for  probabilistic  tagging  for  they 
occur too rarely in the texts. After such updates 
are done on the existing training texts and tagset 
respectively,  the  k-fold  validation  may  be 
repeated and reviewed again. 
Updating  training  data  and  tagset  will  be 
repeated until the tagging results are satisfying 
(such  a  progressing  method  is  usually  called 
?bootstrap-ping?). 
5.2 TreeTagger results
The work on automatic part of speech tagging 
for Dzongkha began with the manual annotation 
of  20,000  tokens.  Because  a  non-linguistic 
person  performed  the  process  manually,  the 
language coordinator did thorough correction.
The 20,000 token training set, made use of 43 
different  single  tags  (of  47  provided  by  the 
tagset). The token-tag combinations from there 
were  combined  with  an  external  lexicon 
produced  from  a  dictionary;  the  resulting 
lexicon file thus contained all types.
The  10-fold  cross  validation  resulted  in  an 
accuracy of  around 78%.  Result  introspection 
lead to the knowledge that more data had to be 
added and that fused words will have to receive 
separate  tags.  It  also  showed  that  manual 
tokenization  is  an  error-prone  procedure,  as  a 
significant  number  of  word  and  sentence 
borders had to be corrected in the data.
After updating tagset and training data, another 
20,247 tokens were added to the training set and 
the lexicon was updated accordingly, except for 
the fused forms, where a final solution on how 
to  tag  them is  not  found yet.  The  tagset  was 
extended to 66 tags (cf.  Appendix A).  With a 
full  knowledge  of  the  possible  tag-token 
combinations,  the  Tree-Tagger  achieved  a 
median accuracy of 93.1%. 
5.3 TnT  results  and  comparison  with 
the TreeTagger
Using the 40,247 tokens text segment, a 10-fold 
cross  validation  was  also  performed  with  the 
TnT  tagger.  It  achieves  a  91.5  %  median 
accuracy when the tagset containing 47 tags is 
applied. Results for each slice and mean/median 
can  be  found in  table  (3)  of  both  taggers  for 
comparison reasons. TnT reports on the number 
of unknown tokens detected in each slice;  the 
mean of 16.49 % (median 14.18%) of unknown 
tokens offers an explanation why TnT does not 
perform as good as the TreeTagger which was 
supplied with a complete lexicon thus not being 
faced with unknown tokens at all. 
Tagger:
Tree-Tagger
accuracy %
TNT
accuracy %
slice 1 92.13 92.33
slice 2 84.61 89.73
slice 3 89.08 89.88
slice 4 90.17 90.43
slice 5 92.95 91.01
slice 6 93.32 91.35
slice 7 94.24 91.69
slice 8 93.32 92.03
slice 9 95.21 92.55
slice 10 94.56 92.60
Mean 91.96 91.36
Median 93.14 91.20
Table (3) 10-fold cross validation results for 
TreeTagger and TnT
A qualitative review of the results showed that 
usually it  is  the tag CC that  is  confused with 
others (NN, DT, NN, DT, PRL, etc.) by TnT, 
while  the  TreeTagger  is  rather  confusing  NN 
(with VB, NNP, PRL, CC).
However,  a  more  thorough  qualitative 
examination of these results is still to be done 
and may lead to further updates on the tagset. 
108
6 Discussion,  Conclusions  and  Future 
work
This  paper  describes  the  building  of  NLP 
resources for the national language of Bhutan, 
namely Dzongkha. We have designed and built 
an electronic corpus containing 570,247 tokens 
belonging to different text types and domains. 
Automated  word  segmentation  with  a  high 
precision/recall  still  remains  a  challenge.  We 
have  begun  to  examine  statistical  methods  to 
find solutions for this and we plan to report on 
our progress in the near future.
We have developed a first version of a tag set 
on the basis of the Penn Tree tagset for English 
(cf.  section 4.1)  A training data set  of  40,247 
tokens  has  been  tagged  manually  and 
thoroughly checked. Lastly, we have tagged the 
corpus  with  the  TreeTagger  (Schmid,  1994) 
using a full form lexicon achieving 93.1% and, 
for  comparison  reasons,  with  TnT  (Brants, 
2000), without a lexicon, achieving 91.5 %.  
We  have  used  the  present  output  in  the 
construction  of  an  advance   Dzongkha  TTS 
(text  to speech) using an HMM-based method 
which  is  developed  by  the  Bhutan  team  in 
collaboration  with  HLT  team  at  NECTEC, 
Thailand7 
Loads  of  work  still  remains,  we  are  still  to 
examine  the  tagger  results  from  a  qualitative 
aspect  in  order  to  answer  inter  Alia  the 
following  questions:  Are  there  any  further 
updates  on  the  tag  set  necessary,  what  is  the 
best  way to process fused forms.  Quantitative 
aspects might also still play a role:  It still might 
be  necessary  to  add  further  training  data 
containing  part  of  speech  constellations  that 
rarely  occur,  so  tagger  results  for  those  will 
enhance.
We also  plan to increase our corpus collection 
from  various  ranges of  domains.  At  present 
there are more media, e.g. newspapers available 
in  the  world  wide  web,  we  will  be  able  to 
collect such texts easily.  In Bhutan, there is  an 
ongoing  project  on  OCR  (optical  character 
recognition) of  Dzongkha  under  the  PAN 
project (www.PANL10n.net). Given the success 
of this project, we will be able to scan text from 
textbooks. 
7 http://www.nectec.or.th/en/
Acknowledgments
This research work carried out as part of PAN 
Localization  Project  (www.PAN10n.net)  with 
the  aid  of  grant  from  the  International 
Development Research Center (IDRC), Ottawa, 
Canada,  administered  through  the  Center  of 
Research  in  Urdu  language  Processing 
(CRULP), National University of Computer and 
Emerging  Sciences  (NUCES),  Pakistan.  The 
research team would also like to thank PD Dr. 
Helmut Schmid and Prof. Dr. Heid, Insitut f?r 
Maschinelle  Sprachverarbeitung  (NLP 
institute),  Universit?t  Stuttgart,  Germany  for 
their  valuable  support  and  contributions  that 
made this research successful. 
References
Brants, Thorsten. 2000. TnT - as statistical part-of-
speech tagger. In Proceedings of the Sixth Applied 
Natural Language Processing Conference  
(ANLP-2000), Seattle, WA, USA, pages 224 ? 231.
Hasan, Fahim Muhammad, Naushad UzZaman, and 
Mumit Khan. 2007. Comparison of different POS 
Tagging Techniques (N-Gram, HMM and
Brill?s tagger) for Bangla. PAN Localization 
Working Papers, 2004-2007, pages 31-37.
Hassan, Sajjad and Helmut Schmid . 2009. Tagging 
Urdu Text with Parts of Speech: A Tagger 
Comparison, Proceedings of the 12th Conference of  
the European Chapter of the Association for 
Computational Linguistics (EACL) . Athens, Greece, 
2009. 
Muaz, Ahmed,  Aasim Ali,  and Sarmad Hussain. 
2009. Analysis and Development of Urdu POS 
Tagged Corpus. Association for Computational 
Linguistics. Morristown, NJ, USA.
Retrieved  December 1, 2009, from 
http://  www.lancs.ac.uk  
Schmid, Helmut. 1994. Probabilistic Part-of-Speech 
Tagging Using Decision Trees. In Proceedings of  
the International Conference on New Methods in  
Language Processing.  Manchester, UK, pages 44 ? 
49.
Sarkar, Asif Iqbal, Dewan Shahriar Hossain Pavel 
and Mumit Khan. 2007.  Automatic Bangla Corpus 
Creation. BRAC University, Dhaka, Bangladesh. 
109
PAN Localization Working Papers, 2004-2007. 
pages 22-26.
Taljard Elsab?, Faa? Gertrud, Heid Ulrich, and Daan 
J. Prinsloo. 2000. On the development of a tagset for 
Northern Sotho with special reference to 
standardization. Literator 29(1), April 2008 (special 
edition on Human Language Technologies), South 
Africa, pages 111 ? 137
APPENDIX A 
The Dzongkha Tagset 
as used for the validation tests
Type SubClass Label
Open classes:
Noun Common Noun NN
Honorific form NNH
Particular/Person NNP
Quantifier NNQ
Plural NNS
Verb Aspirational VBAs
Honorific VBH
Agentive VBAt
Non-Agentive VBNa
Auxiliary VBAUX
Imperative VBI
Modal VBMD
Past participle VBN
Verb VB
Adjective Characteristic JJCt
Periodic JJP
Comparative JJR
Superlative JJS
Adjective JJ
Adverb Behavioral RBB
Comparative RBR
Superlative RBS
Adverb RB
Interjection UH
Closed classes:
Marker Affirmative AM
Interrogative IrM
Tense TM
Case marker Ablative Case CA
Dative Case CDt
Genitive Case CG
Type SubClass Label
Vocative Case CV
Pronouns Locative PRL
Differential PRD
Personal PRP
Reflexive PRRF
Conjunction Coordinate CC
Subordinate SC
Number Cardinal Number CD
Ordinal Number OD
Nominal Number ND
Ad position Post position PP
Determiner Definite DT
Possessive DT$
Indefinite DTI
Negator NEG
Punctuation PUN
Combined 
tags:
Noun+Genitiv
e case(CG)
Common+CG NNCG
Particular+CG NNPCG
Quantifier+CG NNQCG
Plural+CG NNSCG
Adjective+CG Adjective+CG JJCG
Characteristic +CG JJCtCG
Periodic+CG JJPCG
Verb+CG Honorific+CG VBHCG
Agentive+CG VBAtCG
Verb+CG VBCG
Modal+CG VBMDCG
DefiniteDeter
miner+CG
Determiner+CG DTCG
Locative 
Pronoun +CG
Locative+CG PRLCG
Negator+CG Negator+CG NEGCG
Noun+
Subordinate 
Conjunction(S
C)
Common Noun 
+SC 
NNSC
Verb+SC Verb+SC VBSC
Agentive+SC VBAtSC
Modal verb+SC VBMDC
Affirmative 
+SC
Affirmative +SC AMSC
Negator+SC Negator+SC NEGSC
110
