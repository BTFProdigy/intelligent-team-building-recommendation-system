Proceedings of the 43rd Annual Meeting of the ACL, pages 223?230,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Exploring and Exploiting the Limited Utility of Captions in Recognizing
Intention in Information Graphics?
Stephanie Elzer1 and Sandra Carberry2 and Daniel Chester2 and Seniz Demir2 and
Nancy Green3 and Ingrid Zukerman4 and Keith Trnka2
1Dept. of Computer Science, Millersville University, Millersville, PA 17551
2Dept. of Computer Science, University of Delaware, Newark, DE 19716
3Dept. of Mathematical Sciences, Univ. of NC at Greensboro, Greensboro, NC 27402
4School of CS & Software Engrg, Monash Univ., Clayton, Victoria 3800 Australia
Abstract
This paper presents a corpus study that ex-
plores the extent to which captions con-
tribute to recognizing the intended mes-
sage of an information graphic. It then
presents an implemented graphic interpre-
tation system that takes into account a va-
riety of communicative signals, and an
evaluation study showing that evidence
obtained from shallow processing of the
graphic?s caption has a significant impact
on the system?s success. This work is part
of a larger project whose goal is to provide
sight-impaired users with effective access
to information graphics.
1 Introduction
Language research has posited that a speaker or
writer executes a speech act whose intended mean-
ing he expects the listener to be able to deduce, and
that the listener identifies the intended meaning by
reasoning about the observed signals and the mutual
beliefs of author and interpreter (Grice, 1969; Clark,
1996). But as noted by Clark (Clark, 1996), lan-
guage is more than just words. It is any ?signal? (or
lack of signal when one is expected), where a sig-
nal is a deliberate action that is intended to convey a
message.
Although some information graphics are only in-
tended to display data values, the overwhelming ma-
jority of the graphics that we have examined (taken
?Authors can be reached via email as fol-
lows: elzer@cs.millersville.edu, nlgreen@uncg.edu,
{carberry, chester, demir, trnka}@cis.udel.edu, In-
grid.Zukerman@infotech.monash.edu.au.
1998 1999 2000 20011000
1500
2000
2500
3000
personal filingsLocal bankruptcy
Figure 1: Graphic from a 2001 Local Newspaper
from newspaper, magazine, and web articles) ap-
pear to have some underlying goal or intended mes-
sage, such as the graphic in Figure 1 whose com-
municative goal is ostensibly to convey the sharp in-
crease in local bankruptcies in the current year com-
pared with the previous decreasing trend. Applying
Clark?s view of language, it is reasonable to presume
that the author of an information graphic expects the
viewer to deduce from the graphic the message that
the graphic was intended to convey, by reasoning
about the graphic itself, the salience of entities in
the graphic, and the graphic?s caption.
This paper adopts Clark?s view of language as any
deliberate signal that is intended to convey a mes-
sage. Section 3 investigates the kinds of signals used
in information graphics. Section 4 presents a cor-
pus study that investigates the extent to which cap-
tions capture the message of the graphic, illustrates
the issues that would arise in trying to fully under-
stand such captions, and proposes shallow process-
ing of the caption to extract evidence from it. Sec-
tion 5 then describes how evidence obtained from
a variety of communicative signals, including shal-
low processing of the graphic?s caption, is used in a
probabilistic system for hypothesizing the intended
message of the graphic. Section 6 presents an eval-
223
10
 5
15
0?680+ 65?79 7?19 35?4980+65?7950?6435?49
10
 5
15
20?347?190?6 20?3450?64
(a) (b)
Figure 2: Two Alternative Graphs from the Same Data
uation showing the system?s success, with particu-
lar attention given to the impact of evidence from
shallow processing of the caption, and Section 7 dis-
cusses future work.
Although we believe that our findings are ex-
tendible to other kinds of information graphics, our
current work focuses on bar charts. This research is
part of a larger project whose goal is a natural lan-
guage system that will provide effective access to
information graphics for individuals with sight im-
pairments, by inferring the intended message under-
lying the graphic, providing an initial summary of
the graphic that includes the intended message along
with notable features of the graphic, and then re-
sponding to follow-up questions from the user.
2 Related Work
Our work is related to efforts on graph summariza-
tion. (Yu et al, 2002) used pattern recognition tech-
niques to summarize interesting features of automat-
ically generated graphs of time-series data from a
gas turbine engine. (Futrelle and Nikolakis, 1995)
developed a constraint grammar for parsing vector-
based visual displays and producing representations
of the elements comprising the display. The goal
of Futrelle?s project is to produce a graphic that
summarizes one or more graphics from a document
(Futrelle, 1999). The summary graphic might be a
simplification of a graphic or a merger of several
graphics from the document, along with an appropri-
ate summary caption. Thus the end result of summa-
rization will itself be a graphic. The long range goal
of our project, on the other hand, is to provide alter-
native access to information graphics via an initial
textual summary followed by an interactive follow-
up component for additional information. The in-
tended message of the graphic will be an important
component of the initial summary, and hypothesiz-
ing it is the goal of our current work.
3 Evidence about the Intended Message
The graphic designer has many alternative ways of
designing a graphic; different designs contain differ-
ent communicative signals and thus convey differ-
ent communicative intents. For example, consider
the two graphics in Figure 2. The graphic in Fig-
ure 2a conveys that average doctor visits per year
is U-shaped by age; it starts out high when one is
very young, decreases into middle age, and then
rises again as one ages. The graphic in Figure 2b
presents the same data; but instead of conveying a
trend, this graphic seems to convey that the elderly
and the young have the highest number of doctor vis-
its per year. These graphics illustrate how choice of
design affects the message that the graphic conveys.
Following the AutoBrief work (Kerpedjiev and
Roth, 2000) (Green et al, 2004) on generating
graphics that fulfill communicative goals, we hy-
pothesize that the designer chooses a design that best
facilitates the perceptual and cognitive tasks that
are most important to conveying his intended mes-
sage, subject to the constraints imposed by compet-
ing tasks. By perceptual tasks we mean tasks that
can be performed by simply viewing the graphic,
such as finding the top of a bar in a bar chart; by
cognitive tasks we mean tasks that are done via men-
tal computations, such as computing the difference
between two numbers.
Thus one source of evidence about the intended
message is the relative difficulty of the perceptual
tasks that the viewer would need to perform in order
to recognize the message. For example, determining
224
the entity with maximum value in a bar chart will be
easiest if the bars are arranged in ascending or de-
scending order of height. We have constructed a set
of rules, based on research by cognitive psycholo-
gists, that estimate the relative difficulty of perform-
ing different perceptual tasks; these rules have been
validated by eye-tracking experiments and are pre-
sented in (Elzer et al, 2004).
Another source of evidence is entities that have
been made salient in the graphic by some kind of fo-
cusing device, such as coloring some elements of the
graphic, annotations such as an asterisk, or an arrow
pointing to a particular location in a graphic. Enti-
ties that have been made salient suggest particular
instantiations of perceptual tasks that the viewer is
expected to perform, such as comparing the heights
of two highlighted bars in a bar chart.
And lastly, one would expect captions to help con-
vey the intended message of an information graphic.
The next section describes a corpus study that we
performed in order to explore the usefulness of cap-
tions and how we might exploit evidence from them.
4 A Corpus Study of Captions
Although one might suggest relying almost ex-
clusively on captions to interpret an information
graphic, (Corio and Lapalme, 1999) found in a cor-
pus study that captions are often very general. The
objective of their corpus study was to categorize the
kinds of information in captions so that their find-
ings could be used in forming rules for generating
graphics with captions.
Our project is instead concerned with recogniz-
ing the intended message of an information graphic.
To investigate how captions might be used in a sys-
tem for understanding information graphics, we per-
formed a corpus study in which we analyzed the
first 100 bar charts from our corpus of information
graphics; this corpus contains a variety of bar charts
from different publication venues. The following
subsections present the results of this corpus study.
4.1 Do Captions Convey the Intended
Message?
Our first investigation explored the extent to which
captions capture the intended message of an infor-
mation graphic. We extracted the first 100 graphics
Category #
Category-1: Captures intention (mostly) 34
Category-2: Captures intention (somewhat) 15
Category-3: Hints at intention 7
Category-4: No contribution to intention 44
Figure 3: Analysis of 100 Captions on Bar Charts
from our corpus of bar charts. The intended mes-
sage of each bar chart had been previously annotated
by two coders. The coders were asked to identify
1) the intended message of the graphic using a list
of 12 high-level intentions (see Section 5 for exam-
ples) and 2) the instantiation of the parameters. For
example, if the coder classified the intended mes-
sage of a graphic as Change-trend, the coder was
also asked to identify where the first trend began,
its general slope (increasing, decreasing, or stable),
where the change in trend occurred, the end of the
second trend, and the slope of the second trend. If
there was disagreement between the coders on either
the intention or the instantiation of the parameters,
we utilized consensus-based annotation (Ang et al,
2002), in which the coders discussed the graphic to
try to come to an agreement. As observed by (Ang
et al, 2002), this allowed us to include the ?harder?
or less obvious graphics in our study, thus lowering
our expected system performance. We then exam-
ined the caption of each graphic, and determined to
what extent the caption captured the graphic?s in-
tended message. Figure 3 shows the results. 44%
of the captions in our corpus did not convey to any
extent the message of the information graphic. The
following categorizes the purposes that these cap-
tions served, along with an example of each:
? general heading (8 captions): ?UGI Monthly
Gas Rates? on a graphic conveying a recent
spike in home heating bills.
? reference to dependent axis (15 captions):
?Lancaster rainfall totals for July? on a
graphic conveying that July-02 was the driest
of the previous decade.
? commentary relevant to graphic (4 captions):
?Basic performers: One look at the best per-
forming stocks in the Standard&Poor?s 500 in-
dex this year shows that companies with ba-
sic businesses are rewarding investors? on a
225
graphic conveying the relative rank of different
stocks, some of which were basic businesses
and some of which were not. This type of in-
formation was classified as deductive by (Corio
and Lapalme, 1999) since it draws a conclusion
from the data depicted in the graphic.
? commentary extending message of graphic (8
captions): ?Profits are getting squeezed? on
a graphic conveying that Southwest Airlines
net income is estimated to increase in 2003 af-
ter falling the preceding three years. Here the
commentary does not draw a conclusion from
the data in the graphic but instead supplements
the graphic?s message. However this type of
caption would probably fall into the deductive
class in (Corio and Lapalme, 1999).
? humor (7 captions): ?The Sound of Sales? on
a graphic conveying the changing trend (down-
ward after years of increase) in record album
sales. This caption has nothing to do with the
change-trend message of the graphic, but ap-
pears to be an attempt at humor.
? conclusion unwarranted by graphic (2 cap-
tions): ?Defense spending declines? on a
graphic that in fact conveys that recent defense
spending is increasing.
Slightly over half the captions (56%) contributed
to understanding the graphic?s intended message.
34% were judged to convey most of the intended
message. For example, the caption ?Tennis play-
ers top nominees? appeared on a graphic whose in-
tended message is to convey that more tennis players
were nominated for the 2003 Laureus World Sports
Award than athletes from any other sport. Since we
argue that captions alone are insufficient for inter-
preting information graphics, in the few cases where
it was unclear whether a caption should be placed
in Category-1 or Category-2, we erred on the side
of over-rating the contribution of a caption to the
graphic?s intended message. For example, consider
the caption ?Chirac is riding high in the polls?
which appeared on a graphic conveying that there
has been a steady increase in Chirac?s approval rat-
ings from 55% to about 75%. Although this caption
does not fully capture the communicative intention
of the graphic (since it does not capture the steady
increase conveyed by the graphic), we placed it in
the first category since one might argue that riding
high in the polls would suggest both high and im-
proving ratings.
15% of the captions were judged to convey only
part of the graphic?s intended message; an example
is ?Drug spending for young outpace seniors? that
appears on a graphic whose intended message ap-
pears to be that there is a downward trend by age for
increased drug spending; we classified the caption
in Category-2 since the caption fails to capture that
the graphic is talking about percent increases in drug
spending, not absolute drug spending, and that the
graphic conveys the downward trend for increases in
drug spending by age group, not just that increases
for the young were greater than for the elderly.
7% of the captions were judged to only hint at the
graphic?s message. An example is ?GM?s Money
Machine? which appeared on a graphic whose in-
tended message was a contrast of recent perfor-
mance against the previous trend ? ie., that al-
though there had been a steady decrease in the per-
centage of GM?s overall income produced by its fi-
nance unit, there was now a substantial increase in
the percentage provided by the finance unit. Since
the term money machine is a colloquialism that sug-
gests making a lot of money, the caption was judged
to hint at the graphic?s intended message.
4.2 Understanding Captions
For the 49 captions in Category 1 or 2 (where the
caption conveyed at least some of the message of
the graphic), we examined how well the caption
could be parsed and understood by a natural lan-
guage system. We found that 47% were fragments
(for example, ?A Growing Biotech Market?), or in-
volved some other kind of ill-formedness (for ex-
ample, ?Running tops in sneaker wear in 2002? or
?More seek financial aid?1). 16% would require ex-
tensive domain knowledge or analogical reasoning
to understand. One example is ?Chirac is riding
high in the polls? which would require understand-
ing the meaning of riding high in the polls. Another
example is ?Bad Moon Rising?; here the verb ris-
ing suggests that something is increasing, but the
1Here we judge the caption to be ill-formed due to the ellip-
sis since More should be More students.
226
system would need to understand that a bad moon
refers to something undesirable (in this case, delin-
quent loans).
4.3 Simple Evidence from Captions
Although our corpus analysis showed that captions
can be helpful in understanding the message con-
veyed by an information graphic, it also showed that
full understanding of a caption would be problem-
atic; moreover, once the caption was understood, we
would still need to relate it to the information ex-
tracted from the graphic itself, which appears to be
a difficult problem.
Thus we began investigating whether shallow pro-
cessing of the caption might provide evidence that
could be effectively combined with other evidence
obtained from the graphic itself. Our analysis pro-
vided the following observations:
? Verbs in a caption often suggest the kind of
message being conveyed by the graphic. An
example from our corpus is ?Boating deaths
decline?; the verb decline suggests that the
graphic conveys a decreasing trend. Another
example from our corpus is ?American Express
total billings still lag?; the verb lag suggests
that the graphic conveys that some entity (in
this case American Express) is ranked behind
some others.
? Adjectives in a caption also often suggest the
kind of message being conveyed by the graphic.
An example from our corpus is ?Air Force has
largest percentage of women?; the adjective
largest suggests that the graphic is conveying
an entity whose value is largest. Adjectives de-
rived from verbs function similarly to verbs.
An example from our corpus is ?Soaring De-
mand for Servers? which is the caption on a
graphic that conveys the rapid increase in de-
mand for servers. Here the adjective soaring is
derived from the verb soar, and suggests that
the graphic is conveying a strong increase.
? Nouns in a caption often refer to an entity that
is a label on the independent axis. When this
occurs, the caption brings the entity into focus
and suggests that it is part of the intended mes-
sage of the graphic. An example from our cor-
pus is ?Germans miss their marks? where the
graphic displays a bar chart that is intended to
convey that Germans are the least happy with
the Euro. Words that usually appear as verbs,
but are used in the caption as a noun, may func-
tion similarly to verbs. An example is ?Cable
On The Rise?; in this caption, rise is used as a
noun, but suggests that the graphic is conveying
an increase.
5 Utilizing Evidence
We developed and implemented a probabilistic
framework for utilizing evidence from a graphic and
its caption to hypothesize the graphic?s intended
message. To identify the intended message of a
new information graphic, the graphic is first given
to a Visual Extraction Module (Chester and Elzer,
2005) that is responsible for recognizing the indi-
vidual components of a graphic, identifying the re-
lationship of the components to one another and to
the graphic as a whole, and classifying the graphic
as to type (bar chart, line graph, etc.); the result is
an XML file that describes the graphic and all of its
components.
Next a Caption Processing Module analyzes the
caption. To utilize verb-related evidence from cap-
tions, we identified a set of verbs that would indicate
each category of high-level goal2, such as recover
for Change-trend and beats for Relative-difference;
we then extended the set of verbs by examining
WordNet for verbs that were closely related in mean-
ing, and constructed a verb class for each set of
closely related verbs. Adjectives such as more and
most were handled in a similar manner. The Caption
Processing Module applies a part-of-speech tagger
and a stemmer to the caption in order to identify
nouns, adjectives, and the root form of verbs and
adjectives derived from verbs. The XML represen-
tation of the graphic is augmented to indicate any
independent axis labels that match nouns in the cap-
tion, and the presence of a verb or adjective class in
the caption.
The Intention Recognition Module then analyzes
the XML file to build the appropriate Bayesian net-
work; the current system is limited to bar charts, but
2As described in the next paragraph, there are 12 categories
of high-level goals.
227
the principles underlying the system should be ex-
tendible to other kinds of information graphics. The
network is described in (Elzer et al, 2005). Very
briefly, our analysis of simple bar charts has shown
that the intended message can be classified into one
of 12 high-level goals; examples of such goals in-
clude:
? Change-trend: Viewer to believe that there
is a <slope-1> trend from <param1>
to <param2> and a significantly differ-
ent <slope-2> trend from <param3> to
<param4>
? Relative-difference: Viewer to believe that the
value of element <param1> is <comparison>
the value of element <param2> where
<comparison> is greater-than, less-than, or
equal-to.
Each category of high-level goal is represented by a
node in the network (whose parent is the top-level
goal node), and instances of these goals (ie., goals
with their parameters instantiated) appear as chil-
dren with inhibitory links (Huber et al, 1994) cap-
turing their mutual exclusivity. Each goal is broken
down further into subtasks (perceptual or cognitive)
that the viewer would need to perform in order to
accomplish the goal of the parent node. The net-
work is built dynamically when the system is pre-
sented with a new information graphic, so that nodes
are added to the network only as suggested by the
graphic. For example, low-level nodes are added for
the easiest primitive perceptual tasks and for per-
ceptual tasks in which a parameter is instantiated
with a salient entity (such as an entity colored dif-
ferently from others in the graphic or an entity that
appears as a noun in the caption), since the graphic
designer might have intended the viewer to perform
these tasks; then higher-level goals that involve these
tasks are added, until eventually a link is established
to the top-level goal node.
Next evidence nodes are added to the network to
capture the kinds of evidence noted in Sections 3
and 4.3. For example, evidence nodes are added to
the network as children of each low-level perceptual
task; these evidence nodes capture the relative dif-
ficulty (categorized as easy, medium, hard, or im-
possible) of performing the perceptual task as esti-
mated by our effort estimation rules mentioned in
Section 3, whether a parameter in the task refers to
an entity that is salient in the graphic, and whether
a parameter in the task refers to an entity that is a
noun in the caption. An evidence node, indicating
for each verb class whether that verb class appears
in the caption (either as a verb, or as an adjective de-
rived from a verb, or as a noun that can also serve as
a verb) is added as a child of the top level goal node.
Adjectives such as more and most that provide evi-
dence are handled in a similar manner.
In a Bayesian network, conditional probability ta-
bles capture the conditional probability of a child
node given the value of its parent(s). For example,
the network requires the conditional probability of
an entity appearing as a noun in the caption given
that recognizing the intended message entails per-
forming a particular perceptual task involving that
entity. Similarly, the network requires the condi-
tional probability, for each class of verb, that the
verb class appears in the caption given that the in-
tended message falls into a particular intention cat-
egory. These probabilities are learned from our cor-
pus of graphics, as described in (Elzer et al, 2005).
6 Evaluation
In this paper, we are particularly interested in
whether shallow processing of captions can con-
tribute to recognizing the intended message of an
information graphic. As mentioned earlier, the in-
tended message of each information graphic in our
corpus of bar charts had been previously annotated
by two coders. To evaluate our approach, we used
leave-one-out cross validation. We performed a se-
ries of experiments in which each graphic in the cor-
pus is selected once as the test graphic, the probabil-
ity tables in the Bayesian network are learned from
the remaining graphics, and the test graphic is pre-
sented to the system as a test case. The system was
judged to fail if either its top-rated hypothesis did
not match the intended message that was assigned
to the graphic by the coders or the probability rat-
ing of the system?s top-rated hypothesis did not ex-
ceed 50%. Overall success was then computed by
averaging together the results of the whole series of
experiments.
Each experiment consisted of two parts, one in
228
Diner?s Club
Discover
American Express
Mastercard
Visa
400 600200
Total credit card purchases per year in billions
Figure 4: A Graphic from Business Week3
which captions were not taken into account in the
Bayesian network and one in which the Bayesian
network included evidence from captions. Our
overall accuracy without the caption evidence was
64.5%, while the inclusion of caption evidence in-
creased accuracy to 79.1% for an absolute increase
in accuracy of 14.6% and a relative improvement of
22.6% over the system?s accuracy without caption
evidence. Thus we conclude that shallow process-
ing of a caption provides evidence that can be effec-
tively utilized in a Bayesian network to recognize
the intended message of an information graphic.
Our analysis of the results provides some interest-
ing insights on the role of elements of the caption.
There appear to be two primary functions of verbs.
The first is to reflect what is in the data, thereby
strengthening the message that would be recognized
without the caption. One example from our corpus
is a graphic with the caption ?Legal immigration to
the U.S. has been rising for decades?. Although
the early part of the graphic displays a change from
decreasing immigration to a steadily increasing im-
migration trend, most of the graphic focuses on the
decades of increasing immigration and the caption
strengthens increasing trend in immigration as the
intended message of the graphic. If we do not in-
clude the caption, our system hypothesizes an in-
creasing trend message with a probability of 66.4%;
other hypotheses include an intended message that
emphasizes the change in trend with a probability
of 15.3%. However, when the verb increasing from
the caption is taken into account, the probability of
increasing trend in immigration being the intended
message rises to 97.9%.
3This is a slight variation of the graphic from Business
Week. In the Business Week graphic, the labels sometimes ap-
The second function of a verb is to focus atten-
tion on some aspect of the data. For example, con-
sider the graphic in Figure 4. Without a caption, our
system hypothesizes that the graphic is intended to
convey the relative rank in billings of different credit
card issuers and assigns it a probability of 72.7%.
Other possibilities have some probability assigned
to them. For example, the intention of conveying
that Visa has the highest billings is assigned a prob-
ability of 26%. Suppose that the graphic had a cap-
tion of ?Billings still lag?; if the verb lag is taken
into account, our system hypothesizes an intended
message of conveying the credit card issuer whose
billings are lowest, namely Diner?s Club; the prob-
ability assigned to this intention is now 88.4%, and
the probability assigned to the intention of convey-
ing the relative rank of different credit card issuers
drops to 7.8%. This is because the verb class con-
taining lag appeared in our corpus as part of the cap-
tion for graphics whose message conveyed an en-
tity with a minimum value, and not with graphics
whose message conveyed the relative rank of all the
depicted entities. On the other hand, if the caption
is ?American Express total billings still lag? (which
is the caption associated with the graphic in our cor-
pus), then we have two pieces of evidence from the
caption ? the verb lag, and the noun American Ex-
press which matches a label. In this case, the proba-
bilities change dramatically; the hypothesis that the
graphic is intended to convey the rank of American
Express (namely third behind Visa and Mastercard)
is assigned a probability of 76% and the probability
drops to 24% that the graphic is intended to con-
vey that Diner?s Club has the lowest billings. This is
not surprising. The presence of the noun American
Express in the caption makes that entity salient and
is very strong evidence that the intended message
places an emphasis on American Express, thus sig-
nificantly affecting the probabilities of the different
hypotheses. On the other hand, the verb class con-
taining lag occurred both in the caption of graphics
whose message was judged to convey the entity with
the minimum value and in the caption of graphics
pear on the bars and sometimes next to them, and the heading
for the dependent axis appears in the empty white space of the
graphic instead of below the values on the horizontal axis as we
show it. Our vision system does not yet have heuristics for rec-
ognizing non-standard placement of labels and axis headings.
229
that conveyed an entity ranked behind some others.
Therefore, conveying the entity with minimum value
is still assigned a non-negligible probability.
7 Future Work
It is rare that a caption contains more than one verb
class; when it does happen, our current system by
default uses the first one that appears. We need to
examine how to handle the occurrence of multiple
verb classes in a caption. Occasionally, labels in the
graphic appear differently in the caption. An exam-
ple is DJIA (for Dow Jones Industrial Average) that
occurs in one graphic as a label but appears as Dow
in the caption. We need to investigate resolving such
coreferences.
We currently limit ourselves to recognizing what
appears to be the primary communicative intention
of an information graphic; in the future we will also
consider secondary intentions. We will also extend
our work to other kinds of information graphics such
as line graphs and pie charts, and to complex graph-
ics, such as grouped and composite bar charts.
8 Summary
To our knowledge, our project is the first to inves-
tigate the problem of understanding the intended
message of an information graphic. This paper
has focused on the communicative evidence present
in an information graphic and how it can be used
in a probabilistic framework to reason about the
graphic?s intended message. The paper has given
particular attention to evidence provided by the
graphic?s caption. Our corpus study showed that
about half of all captions contain some evidence that
contributes to understanding the graphic?s message,
but that fully understanding captions is a difficult
problem. We presented a strategy for extracting ev-
idence from a shallow analysis of the caption and
utilizing it, along with communicative signals from
the graphic itself, in a Bayesian network that hy-
pothesizes the intended message of an information
graphic, and our results demonstrate the effective-
ness of our methodology. Our research is part of a
larger project aimed at providing alternative access
to information graphics for individuals with sight
impairments.
References
J. Ang, R. Dhillon, A. Krupski, E. Shriberg, and A. Stol-
cke. 2002. Prosody-based automatic detection of an-
noyance and frustration in human-computer dialog. In
Proc. of the Int?l Conf. on Spoken Language Process-
ing (ICSLP).
D. Chester and S. Elzer. 2005. Getting computers to see
information graphics so users do not have to. To ap-
pear in Proc. of the 15th Int?l Symposium on Method-
ologies for Intelligent Systems.
H. Clark. 1996. Using Language. Cambridge University
Press.
M. Corio and G. Lapalme. 1999. Generation of texts
for information graphics. In Proc. of the 7th European
Workshop on Natural Language Generation, 49?58.
S. Elzer, S. Carberry, N. Green, and J. Hoffman. 2004.
Incorporating perceptual task effort into the recogni-
tion of intention in information graphics. In Proceed-
ings of the 3rd Int?l Conference on Diagrams, LNAI
2980, 255?270.
S. Elzer, S. Carberry, I. Zukerman, D. Chester, N. Green,
S. Demir. 2005. A probabilistic framework for recog-
nizing intention in information graphics. To appear in
Proceedings of the Int?l Joint Conf. on AI (IJCAI).
R. Futrelle and N. Nikolakis. 1995. Efficient analysis of
complex diagrams using constraint-based parsing. In
Proc. of the Third International Conference on Docu-
ment Analysis and Recognition.
R. Futrelle. 1999. Summarization of diagrams in docu-
ments. In I. Mani and M. Maybury, editors, Advances
in Automated Text Summarization. MIT Press.
Nancy Green, Giuseppe Carenini, Stephan Kerpedjiev,
Joe Mattis, Johanna Moore, and Steven Roth. Auto-
brief: an experimental system for the automatic gen-
eration of briefings in integrated text and information
graphics. International Journal of Human-Computer
Studies, 61(1):32?70, 2004.
H. P. Grice. 1969. Utterer?s Meaning and Intentions.
Philosophical Review, 68:147?177.
M. Huber, E. Durfee, and M. Wellman. 1994. The auto-
mated mapping of plans for plan recognition. In Proc.
of Uncertainty in AI, 344?351.
S. Kerpedjiev and S. Roth. 2000. Mapping communica-
tive goals into conceptual tasks to generate graphics in
discourse. In Proc. of Int. Conf. on Intelligent User
Interfaces, 60?67.
J. Yu, J. Hunter, E. Reiter, and S. Sripada. 2002.
Recognising visual patterns to communicate gas tur-
bine time-series data. In ES2002, 105?118.
230
An Experiment to Evaluate the Effectiveness of Cross-Media Cues in
Computer Media
Nancy Green
Department of Mathematical Sciences
383 Bryan Building
University of North Carolina Greensboro
Greensboro, NC 27402
nlgreen@uncg.edu
Abstract
We present the motivation for and
design of an experiment to evaluate
the usefulness of cross-media cues,
phrases such as 'See Figure 1'.
1 Introduction
Authors of English-language print documents
containing both text and graphics traditionally
have used phrases such as 'See Figure 1'.
Intuitively, these cross-media cues (CMCs)
help the print reader to integrate information
presented in different media, i.e., printed text
and printed graphics.  We are investigating
how, if at all, these cues should be used in
presentations delivered in computer media
such as web pages. Our long-term goal is to
develop a non-application-specific
computational model for the decision of when
to direct the reader's attention to related
graphics, what kinds of things to say about
them, and where to place the cross-media cues
in the text.
For exploratory purposes, we previously
performed an informal corpus study of the use
of cross-media cues in arguments (Green
2001).  However, we contend that print-media-
based corpus studies may not provide sound
information on which to base a model for on-
screen presentations. Human-computer
interaction (HCI) studies have shown that there
are significant differences between reading
from print and computer media, e.g., that
reading from screen is slower and
comprehension is worse (Dillon, 1992; Muter,
1996).  Thus, as an alternative to corpus
analysis we have begun controlled user studies
employing "throwaway" prototypes. In this
paper, we present the design and preliminary
results of an experiment on effective cross-
media cue usage in computer media.
2     Related Work
2.1     Computational linguistics
Cross-media cues are similar in some respects
to discourse cue phrases. First, some functions
of cross-media cues can be classified using
discourse coherence relations such as
Preparation, Restatement, Summary,
Evaluation, and Elaboration (Green, 2001).
Second, there is not a one-to-one
correspondence between form and function.
For example, the same CMC can be used to
indicate different coherence relations between
a span of text and the named figure, e.g.,
Restatement and Evaluation. On the other
hand, a relation of Summary can be indicated,
for example,  by 'From Fig. 9.5, you can see
that' or '(see Figure 4)'. Another similarity is
that CMCs are not always provided to mark
explicitly the relationship obtaining between
text and graphic. Research on discourse cue
placement has framed our thinking on asking
when and where to generate CMCs
(DiEugenio, Moore and Paolucci, 1997).
     A multimedia presentation may include
multimodal referring expressions, references to
things in the world made through a
combination of text and graphics (McKeown et
al., 1992; Andr? and Rist, 1994). Such cross-
references are similar to cross-media cues in
that they direct the user's attention to a related
graphic. However, their function is different,
namely, to enable the user to perform reference
resolution. Another form of cross-reference,
discourse deixis is the use of an expression that
refers to part of the document containing it,
e.g., 'the next chapter' (Paraboni and van
       Philadelphia, July 2002, pp. 42-45.  Association for Computational Linguistics.
                  Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
Deemter, 1999). Although a user's
interpretation of a cross-media cue may
depend on discourse deixis to determine the
graphic in question, the problem of selecting
an appropriate description to refer to a graphic
(e.g. 'Figure 4' versus 'the Figure below') is
not a concern of our work at present.
      In our previous corpus study of multimedia
arguments, we classified text in a document as
either argument-bearing or commentary-
bearing, where the latter is text about a graphic
included in the document (Green 2001). The
topics of commentary-bearing text include the
graphic's role in the argument (e.g. 'From Fig.
9.5, you can see that'), the interpretation of
graphical elements in terms of the underlying
domain and data, and salient visual features of
the graphic.  Furthermore, we noted that
commentary-bearing and argument-bearing
text may be interleaved, and that the ratio of
the number of sentences of commentary to
their related CMC may be many to one.
     Previous work in caption generation is
relevant to the question of what kinds of things
to say about accompanying graphics (Mittal et
al., 1998; Fasciano and Lapalme, 1999).
However, neither of those systems face the
problem of integrating commentary-bearing
text with text generated to achieve other
presentation goals.
2.2    Human-Computer Interaction
HCI research has focused on interaction
techniques and features of layout that influence
effectiveness. Use of contact points, control
buttons in text on a web page that enable
readers to control related animations (Faraday
and Sutcliffe, 1999), is an interaction
technique that, like CMCs, explicitly marks the
relationship between information presented in
two media. That paper provides experimental
evidence that contact points improve
comprehension of integrated text and
animation.
     According to Moreno and Mayer's Spatial
Contiguity Principle (2000), learning in
multimedia presentations is improved when
related text and graphics are spatially
contiguous rather than separated. However,
this does not imply that instead of providing
CMCs a generator can rely on layout alone, for
the following reasons.  First, a generator may
have responsibility for producing text but not
have control over layout, e.g. when a
document is displayed by a web browser.
Second, a graphic may be relevant to multiple
non-contiguous spans of text in a document.
3 Experiment
3.1    Overview
As a first step, we must address a basic
question: is it ever worthwhile to generate
cross-media cues in computer presentations?
Thus we designed a between-groups
experiment (Lewis & Rieman, 1994) to test
whether performance on tasks requiring a
subject to skim for information presented in
text and graphics via a web browser would
benefit from the inclusion of cross-media cues
in the text.   Skimming, defined as "moving
rapidly through text to locate specific
information or gain the gist", is a type of
reading strategy often used by readers of web
pages (Dyson and Haselgrove 2001).
     Each of the three groups of subjects
receives a different version of a presentation
consisting of four articles.  Each article fills a
19 inch computer screen and consists of a short
text followed by several figures with
information graphics such as line graphs and
bar charts.  The graphics are arranged in a row
near the bottom of the screen so that the cost to
the user of looking up and down between text
and graphics is the same for each figure.
Multiple figures are provided so that the reader
is required to determine which figure is
relevant to the task.
     In version 1, the layout of each article
consists of text containing no cross-media cues
followed by the figures.  A short caption is
given under each graphic. In version 2, the
caption text has been removed from the figures
and integrated into the paragraph of text above
the figures, i.e., it now functions as
commentary text. Version 3 is identical to
version 2 except that for each figure a cross-
media cue of the form 'See Figure n.' has been
inserted in the text; the CMC is inserted
following the commentary created from the
corresponding caption in Version 1.
     Version 1 represents the case where it is
feasible to design the layout so that text
commenting upon a figure can be placed in
proximity to the figure (i.e. maximizing
adherence to the Spatial Contiguity Principle).
We assume that task performance will be best
for version 1 and include it in the experiment
to provide a baseline.  The main point of the
experiment, however, is to compare
performance on version 2 with performance on
version 3.  Then, if performance on version 3
is better, we have shown that CMCs can be
useful to readers performing a similar task.
3.2    Experimental Design
The independent variable is the version of the
article that is presented.  The three versions are
constructed by varying layout and presence of
cross media cue phrases as described above.
The dependent variables are the time to
complete the tests (Time) and score on the tests
(Score). Time and Score are compared
between groups.
3.3    Participants
The participants (subjects) are undergraduate
college students. The participants are randomly
assigned to one of three groups.  Each group is
tested on a different version of the same
articles.  Information about college major and
experience using computers is collected via a
short questionnaire before the experiment.
3.4    Materials
Each article was constructed by the
experimenter by selecting an excerpt from a
published source; the sources of the four
articles represent different genre, topics,
layouts, and audiences. (We chose to use
excerpts rather than authoring our own articles
to avoid experimenter bias.) The excerpts are
approximately the same word-length and,
except for the first article, which is used for
practice and only includes two figures, each
excerpt includes three figures.  The layout was
modified by the experimenter to create
versions 1 through 3.  Other differences in
presentation (e.g., line length, color scheme,
font style, and font size) between different
versions of the same article and between
articles were minimized as much as possible.
     The multiple choice test for each article
consists of one question asking the subject to
identify one of the main points of the
presentation, and three questions asking the
subject to identify where in the presentation
certain facts were given.  For the identification
questions the subject is asked to select one or
more of the following choices: in the text, in
the graph in Figure 1, in the graph in Figure 2,
in the graph in Figure 3, or none of the above.
3.5    Procedure
Each participant is given a series of four tests
displayed on a desktop PC with a 19 inch color
monitor. The first test is used as a practice test
and data collected from it will not be used. The
test series is implemented by a computer
program written in HTML and Javascript that
is run by a web browser. Scrolling is disabled
throughout the test series. The first screen of
each test presents an article; the next screen
contains the four test questions described
above. The participant is free to move back
and forth between the article and the test
question screen for it by using
Forward/Backward buttons, but cannot see the
article and test question screens at the same
time. The participant cannot go back to
previous tests, and is not allowed to go on to
the next test until he or she has answered all
questions on the current test and has confirmed
that he or she is ready to go on to the next test.
The participant answers the test questions
using the computer mouse. The program
records the participant's answers and times
automatically.  Subjects are not told that their
task time is being measured.
3.6  Status of Work
We have finished running the pilot version of
the experiment and are currently running the
main experiment.  It is interesting that in the
post-experiment questionnaire, some subjects
who have received version 2 have commented
that references to the figures (i.e. CMCs)
would have been helpful.
4 Discussion
We have presented the motivation for and
design of an experiment to evaluate the
usefulness of cross-media cues in multimedia
presentations shown on computer screens. In
future work, we plan to investigate questions
of cross-media cue placement, e.g., whether to
insert a CMC before or after commentary
about the named figure. An interesting
question is whether CMC placement should be
influenced by discourse structure.
Acknowledgments
We thank Jennifer Brooks of the University of
North Carolina at Greensboro for her
implementation of much of the Javascript
programs used in the experiment and for
running an initial group of subjects through it.
References
E. Andr? and T. Rist.  1994..  Referring to
World Objects with Text and Pictures.
COLING-94, 530-534.
A. Dillon. 1992.  Reading from paper versus
screens: a critical review of the empirical
literature.  Ergonomics, 35, 1297-1326.
M.C. Dyson and M. Haselgrove. 2001. The
influence of reading speed and line length on
the effectiveness of reading from screen.
International Journal of Human-Computer
Studies, 54, 585-612.
Barbara Di Eugenio, Johanna D. Moore,
Massimo Paolucci. 1997. Learning Features
that Predict Cue Usage, Proceedings 35th
Annual Meeting of the Association for
Computational Linguistics.
P. Faraday and A. Sutcliffe. 1999. Authoring
Animated Web Pages Using 'Contact Points',
in Proceedings of CHI '99, 458-465.
M. Fasciano and G. Lapalme. 1999.
Intentions in the coordinated generation of
graphics and text from tabular  data.
Knowledge and Information Systems, Oct
1999.
N. Green. 2001.  An Empirical Study of
Multimedia Argumentation.   Proceedings of
the International Conference on
Computational Systems, Workshop on
Computational Models of Natural Language
Arguments, May 2001.  Springer Lecture Notes
in Computer Science 2073, pp. 1009-18.
Lewis & Rieman. 1994. Lewis, C. and
Rieman, R. Task-Centered User Interface
Design: A Practical Introduction.
[ftp://ftp.cs.colorado.edu]
K. R. McKeown, S. K. Feiner, J. Robin, D.D.
Seligmann, and M. Tanenblatt. 1992.
Generating Cross-References for Multimedia
Explanation.  Proceedings of AAAI, 9-16.
V. Mittal, J. Moore, G. Carenini, and S.
Roth. 1998. Describing Complex Charts in
Natural Language: A Caption Generation
System.  Computational. Linguistics, Vol.
24,  issue 3, (1998), 431-467.
R. Moreno and R. Mayer. 2000. A Learner-
Centered Approach to Multimedia
Explanations: Deriving Instructional Design
Principles from Cognitive Theory, Interactive
Multimedia Electronic Journal of Computer-
Enhanced Learning.
P. Muter. 1996. Interface design and
optimization of reading of continuous text. In
H. Van Oostendorp and S. DeMul (eds.)
Cognitive Aspects of Electronic Text
Processing, pp. 161-180.
I. Paraboni and K. van Deemter.  1999. Issues
for the Generation of Document Deixis.  In
Andr? et al (Eds.),  Deixis, Demonstration
and Deictic Belief in Multimedia Contexts,
Proceedings of the Workshop associated with
the 11th European Summer School in Logic,
Language and Information (ESSLLI),
Utrecht, The Netherlands, 1999, pp. 43-48.
Understanding Information Graphics: A Discourse-Level Problem ?
?Sandra Carberry, ?Stephanie Elzer, ??Nancy Green, ?Kathleen McCoy, and ?Daniel Chester
?Dept. of Computer Science, University of Delaware, Newark, DE 19716
(carberry, elzer, mccoy, chester@cis.udel.edu)
??Dept. of Math. Sciences, Univ. of North Carolina at Greensboro, Greensboro, NC 27402
(nlgreen@uncg.edu)
Abstract
Keywords: graphics, understanding, dis-
course, plan-based models
Information graphics that appear in newspa-
pers and magazines generally have a message that
the viewer is intended to recognize. This paper ar-
gues that understanding such information graph-
ics is a discourse-level problem. In particular,
it requires assimilating information from multi-
ple knowledge sources to recognize the intended
message of the graphic, just as recognizing in-
tention in text does. Moreover, when an article
is composed of text and graphics, the intended
message of the information graphic (its discourse
intention) must be integrated into the discourse
structure of the surrounding text and contributes
to the overall discourse intention of the article.
This paper describes how we extend plan-based
techniques that have been used for understanding
traditional discourse to the understanding of in-
formation graphics. This work is part of a project
to develop an interactive natural language system
that provides sight-impaired users with access to
information graphics.
1 Introduction
Information graphics (non-pictorial graphics
such as bar charts and line graphs) are a variant of
language with many similarities to other forms of
communication. Information graphics are preva-
lent in information resources since they enable
complex information to be assimilated perceptu-
ally with ease. Unfortunately, knowledge sources
such as information graphics are not accessible to
some users. For example, individuals with im-
0The work of the third author was supported by the Na-
tional Science Foundation under Grant No. 0132821.
paired eyesight have limited access to information
graphics, thus preventing them from fully utiliz-
ing information resources.
Some information graphics are only intended
to display data values; (Yu et al, 2002) devel-
oped a pattern recognition algorithm for summa-
rizing interesting features of automatically gener-
ated graphics of time-series data from a gas tur-
bine engine. However, the overwhelming major-
ity of the graphics that we have examined (taken
from newspaper, magazine, and web articles) ap-
pear to have some underlying goal, such as get-
ting the viewer to believe that interest rates have
fallen substantially and that this would therefore
be a good time to refinance a mortgage. We
have found that understanding information graph-
ics is a discourse-level problem. In particular,
it requires assimilating information from multi-
ple knowledge sources to recognize the intended
message of the graphic, just as recognizing inten-
tion in text does. Moreover, the communicative
intention of the information graphic must be in-
tegrated into the discourse intentions of the sur-
rounding text.
We are developing an interactive natural lan-
guage system that infers the intended message
underlying an information graphic, augments it
with related interesting features of the graphic,
provides an initial summary of the graphic, and
then responds to followup questions from the
user. This paper presents the system architecture,
shows why interpreting information graphics is
a discourse-level problem, and outlines how we
extend techniques that have been used for under-
standing traditional discourse to the understand-
ing of information graphics.
2 A Natural Language Modality
Information is the key to knowledge and ef-
fective decision-making. But information is use-
ful only if it is accessible in a form that can be
easily assimilated. For sighted users, information
graphics capture complex information and enable
it to be assimilated perceptually with ease. For
individuals who have serious sight-impairments,
documents that contain information graphics pose
challenging problems. Although devices have
been developed for conveying information graph-
ics in alternative mediums such as musical tones
or tactile images, these approaches have serious
limitations. For example, systems that attempt to
convey graphics via a soundscape(Meijer, 1992)
do not facilitate easy comparison of two line
graphs linked in a single graphical display. More-
over, these approaches require the user to con-
struct a ?mental map? of the graphic, which is
difficult for congenitally blind users who do not
have the personal knowledge to assist them in the
interpretation of the image(Kennel, 1996). The
underlying hypothesis of our work is that alterna-
tive access to what the graphic looks like is not
enough ? the user should be provided with the
message and knowledge that one would gain from
viewing the graphic in order to enable effective
and efficient use of this information resource. To
accomplish this objective, we are developing an
interactive natural language system for communi-
cating the content of an information graphic. Our
methodology offers promise as a means of provid-
ing access to information graphics without expen-
sive equipment, with few limitations on the com-
plexity of the graphic that can be handled, and
with relatively little cognitive load on the user.
3 Architecture and Overview
Our current work is concerned with bar charts,
line graphs, and pie charts, although eventually
we will handle other kinds of graphics. Figure 1
shows the architecture of our system for convey-
ing information graphics. The visual extraction
component (VEC) analyzes the graphic and pro-
vides an XML representation of the graphic to
the intention recognition component (IRC). The
IRC is responsible for recognizing the intended
message of the information graphic and sending it
to the content planning component (CPC), which
will augment the intended message of the graphic
with related interesting features. The message or-
ganization component (MOC) then organizes the
most salient propositions into a coherent sum-
mary, which will be rendered in natural language
and conveyed to the user via speech synthesis.
The followup question component (FQC) will al-
low the user to interactively seek additional infor-
mation about the graphic.
Our work thus far (Section 4) has focused on
understanding an information graphic so that its
intended message can be conveyed to the user.
Section 4.1 discusses the extension of speech act
theory to the generation and understanding of in-
formation graphics. Section 4.2 argues that un-
derstanding information graphics is a discourse-
level problem in which the system must recog-
nize the intended message of the graphic and in-
tegrate it into the intentions of any surrounding
text; it further argues that understanding informa-
tion graphics requires similar kinds of knowledge
and processing as does the understanding of tra-
ditional textual discourse. Section 4.3 provides
a brief overview of the visual extraction compo-
nent that analyzes the graphical image and con-
structs an XML representation of the graphic for
use by the graphic understanding system. Sec-
tion 4.4 then describes how we have extended
techniques used for understanding traditional dis-
course and dialogue to the understanding of infor-
mation graphics. Section 5 gives a brief overview
of future work on the rest of the system. The Ap-
pendix contains information graphics that are part
of the corpus on which our work is based.
4 Understanding Information Graphics
4.1 Intention in Information Graphics
Information graphics are a variant of language.
As noted by Clark(Clark, 1996), language is more
than just words. It is any ?signal? (or lack of sig-
nal when one is expected), where a signal is a de-
liberate action that is intended to convey a mes-
sage. According to speech act theory, a speaker
or writer executes a speech act whose intended
meaning he expects the listener or reader to be
able to deduce(Searle, 1970; Grice, 1969; Clark,
1996). In their work on multimedia generation,
Figure 1: System Architecture
the AutoBrief group proposed that speech act the-
ory could be extended to cover the generation
of graphical representations(Kerpedjiev and Roth,
2000). They developed a multimedia presenta-
tion system that generated text and information
graphics. It included 1) an algorithm that could
map communicative goals to a set of perceptual
and cognitive tasks that must be enabled for a
viewer to recognize the goals and 2) an automatic
graph designer that used constraint satisfaction to
construct an information graphic that best facili-
tated those tasks, subject to competing constraints
among the tasks.
The overwhelming majority of information
graphics accompanying newspaper and magazine
articles appear to carry a message that the de-
signer intends to convey to the viewer by virtue
of the graphic?s design and the data presented in
the graphic. Consider the graphic in Figure 9. It
conveys the message that the salary of women
in science, mathematics, and engineering fields
is consistently less than that of men in the same
fields. Other messages could have been con-
veyed by a different graphic design. For ex-
ample, by grouping the bars for men together,
grouping the bars for women together, and or-
dering the bars for each group by height, the
graphic would have conveyed the message that
both men and women earn the least in the so-
cial sciences and the most in engineering. Or
if the bars for Computer/Mathematical Sciences
were highlighted in Figure 9 by coloring them
significantly differently from the other bars in the
graphic, the graphic would have invoked a com-
parison of the discrepancies between male and
female salaries in Computer/Mathematical Sci-
ences and the salary discrepancies between men
and women in other fields. Although a graphic?s
caption can be helpful in identifying its intended
message (as in Figure 8), Corio performed a large
corpus study(Corio and Lapalme, 1999) in which
he found that captions are often missing or fail
to provide any indication of what the information
graphic conveys (as in Figures 6 and 10). Thus
we cannot rely entirely on the presence of useful
captions to identify the intended message of an
information graphic.
Language research has posited that the listener
or reader who is interpreting a speech act identi-
fies its intended meaning by reasoning about the
observed signals and the mutual beliefs of author
and interpreter(Grice, 1969; Clark, 1996). Ap-
plying this to graphical displays, it is reasonable
to presume that the author of a graphic similarly
expects the viewer to use perceptual skills along
with other knowledge sources to deduce from the
graphic the message that he intended to convey.
Thus we are applying speech act theory in the re-
verse direction of the AutoBrief project, namely
to the recognition of the intended message under-
lying an information graphic.
4.2 A Discourse Level Problem
This section argues that interpreting informa-
tion graphics is a discourse-level problem ? not
only is it necessary to recognize the intention of
the graphic as noted in Section 4.1, but under-
standing an information graphic requires similar
kinds of knowledge and processing as does un-
derstanding traditional discourse.
Grosz and Sidner contended that discourse
has a structure comprised of discourse segments.
Each discourse segment has a discourse seg-
ment purpose that contributes to the discourse
purpose or intention underlying the overall dis-
course(Grosz and Sidner, 1986). When an arti-
cle is comprised of text and graphics, the graphic
generally expands on the text and contributes to
the discourse purpose of the article. Consider the
graphic and partial surrounding text reproduced
in Figure 6. Nowhere in the text is it stated that
the income of black women has risen dramati-
cally over the last decade and has reached the
level of white women. Yet this message is clearly
conveyed by the graphic and contributes to the
overall communicative intention of this portion
of the article ? namely, that there has been a
?monumental shifting of the sands? with regard
to the achievements of black women. Not only
does the intended message of the graphic (its dis-
course segment purpose) contribute to this overall
intention, but in fact the discourse intention of the
graphic helps to recognize the overall intention.
Even when the graphic stands in isolation as
in Figures 7 and 8, understanding the graphic
is a discourse-level problem. Grosz and Sid-
ner(Grosz and Sidner, 1986) claim that a robust
model of discourse understanding must use mul-
tiple knowledge sources in order to recognize the
complex relationships that utterances have to one
another. Information graphics have similar com-
plex relationships among their component ele-
ments. Not only might the graphic include mul-
tiple elements that must be related to one another
(such as multiple lines in a line graph, or individ-
ual bars in a bar chart), but information graphics
often include highlighting of certain elements to
make them particularly salient (as in Figure 10)
or include captions that might contribute to rec-
ognizing the graphic?s intention. The graphic in
Figure 8 includes such a helpful caption, although
many graphics, such as the ones in Figures 7
and 9, do not.
Furthermore, identifying the intended message
of a composite graphic (one comprised of multi-
ple individual graphics) requires relating the in-
dividual graphics to one another to identify the
intended message of the composite. Figure 11 il-
lustrates a composite information graphic. The
discourse purpose of the composite graphic is that
audits of affluent taxpayers are declining with re-
spect to audits of all taxpayers. This message can
only be deduced by relating the two individual
graphics and their underlying messages.
Moreover, understanding information graphics
requires the use of multiple knowledge sources.
In earlier work on recognizing expressions of
doubt, we developed an algorithm that combined
linguistic, contextual, and world knowledge and
applied it to the recognition of complex discourse
acts(Carberry and Lambert, 1999). In the case
of information graphics, the corollary to linguis-
tic knowledge is perceptual knowledge, by which
one recognizes the individual elements of the
graphic (for example, the bars in a bar chart), the
relation of the individual elements in the graphic
to one another, the type of graphic (line graph,
bar chart, pie chart, etc.), and what the different
graphic types can be used to convey. For exam-
ple, both a scatter plot and a pie chart can be
used to portray how an entity (such as govern-
ment income) is divided up among several cate-
gories (such as social welfare, military spending,
etc.); however, a graphic designer will choose a
pie chart if the intent is to convey the relative dis-
tributions as opposed to their absolute amounts.
Furthermore, a particular type of graphic (such as
a line graph) might be appropriate for conveying
several different intentions (maximum data point,
data trend, data variation, etc.).
Contextual and world knowledge are also es-
sential for understanding information graphics.
Contextual knowledge includes the caption as-
sociated with the graphic, any highlighting of
graphic elements that affects the focus of atten-
tion in the graphic, and the discourse structure and
focus of attention in any surrounding text. World
knowledge consists of mutual beliefs between de-
signer and viewer about entities of interest to the
intended viewing audience. For example, if an in-
formation graphic appears in a document targeted
at residents of New York City, then both the de-
signer and the viewer will mutually believe that
entities such as New York City, its football and
baseball teams, etc. will be particularly salient
to the viewer. Our methodology for understand-
ing information graphics takes these knowledge
sources into account.
4.3 The Visual Extraction Component
The visual extraction component (VEC) cap-
tures much of the perceptual knowledge discussed
in Section 4.2. It is responsible for recogniz-
ing the individual components comprising the
graphic, identifying the relationship of the differ-
ent components to one another and to the graphic
as a whole, and classifying the graphic as to type.
Extracted components include not only the bars,
lines, or wedges of a graphic but also the titles of
the axes, the legend, and the graphic?s title or cap-
tion. The present implementation deals only with
gray scale images (in pgm format) of bar charts,
pie charts, and line graphs, though eventually it
will be extended to handle color and other kinds
of information graphics. Words and numbers that
appear in the chart are associated with particular
bars, wedges and lines by their proximity to the
chart component in question. The output of the
visual extraction component is an XML file that
describes the chart and all of its components.
4.4 Applying Discourse Understanding
Strategies
Many researchers have cast the understanding
of discourse and dialogue as a plan recognition
problem ? that is, the writer or speaker (or char-
acters in the case of a story) has an underlying
goal and a plan for accomplishing that goal, and
understanding requires that the reader or listener
infer the plan and in turn the goal that the plan is
intended to achieve. (Perrault and Allen, 1980;
Wilensky, 1983; Litman and Allen, 1987; Car-
berry, 1990; Charniak and Goldman, 1993; Ardis-
onno and Sestero, 1996) are just a few examples
of such systems.
Since understanding information graphics is a
discourse-level problem, we are extending plan
inference techniques to recognizing the intended
message of an information graphic(Elzer et al,
2003) and to identifying its contribution to an
extended discourse that includes both text and
graphics. Planning and plan inference systems re-
quire knowledge about goals and how they can
be achieved. Typically, this is provided by a li-
brary of operators. Each operator encodes a goal
in its header; the body of the operator encodes
the subgoals that must be accomplished in order
to achieve the operator?s goal. A planning sys-
tem starts with a high-level goal, and uses oper-
ators to decompose the goal into a set of simpler
subgoals, which eventually decompose into prim-
itive subgoals that can be accomplished by prim-
itive actions in the domain. On the other hand,
a plan inference system starts with the primitive
goals associated with observed actions, and uses
the operators to chain backwards to higher-level
goals which the lower-level subgoals contribute to
achieving. In the case of traditional discourse and
dialogue, the subgoals in the plan operators are ei-
ther communicative or domain goals, and the ob-
served actions that start the plan inference process
are the speech acts represented by the utterances
in a story or a dialogue.
To extend plan inference to information graph-
ics, the plan operators must include goals that
can be accomplished by viewing an information
graphic, as opposed to being the recipient of an
utterance. As discussed in Section 4.1, the Auto-
Brief project(Kerpedjiev and Roth, 2000) devel-
oped an algorithm to map communicative goals to
a sequence of perceptual and cognitive tasks that
the graphic should support. Perceptual tasks are
tasks that can be performed by simply viewing the
graphic, such as finding the top of a bar in a bar
chart; cognitive tasks are tasks that are performed
via mental computations, such as computing the
difference between two numbers. We draw on
the AutoBrief notion of perceptual and cognitive
tasks enabled by an information graphic. Our plan
operators not only encode knowledge about how
to achieve domain and communicative goals (the
latter of which may require that the viewer per-
form perceptual and cognitive tasks) but they also
encode knowledge about how information-access
tasks, such as finding the value of an entity in
a graphic, can be decomposed into simpler sub-
goals. Figures 2 and 3 present two plan operators
for achieving the goal of finding the value <v> of
an attribute <att> for a graphical element <e>
(for example, the value associated with the top of
a bar in a bar chart). The body of the operator in
Goal: Find-value(<viewer>, <g>, <e>, <ds>, <att>, <v>)
Gloss: Given graphical element <e> in graphic <g>, <viewer> can find the value <v>
in dataset <ds> of attribute <att> for <e>
Data-req: Dependent-variable(<att>, <ds>)
Body: 1. Perceive-dependent-value(<viewer>, <g>, <att>, <e>, <v>)
Figure 2: Operator for achieving a goal perceptually
Goal: Find-value(<viewer>, <g>, <e>, <ds>, <att>, <v>)
Gloss: Given graphical element <e> in graphic <g>, <viewer> can find the value <v>
in dataset <ds> of attribute <att> for <e>
Data-req: Natural-quantitative-ordering(<att>)
Display-const: Ordered-values-on-axis(<g>, <axis>, <att>)
Body: 1. Perceive-info-to-interpolate(<viewer>,<g>,<axis>,<e>,<l1>,<l2>,<f>)
2. Interpolate(<viewer>, <l1>, <l2>, <f>, <v>)
Figure 3: Operator that employs both perceptual and cognitive subgoals
Figure 2 specifies that the goal can be achieved
by a primitive perceptual task in which the viewer
just perceives the value; this could be done, for
example, if the element in the graphic is annotated
with its value, as are the bars in the bar chart in
Figure 8 of the Appendix. On the other hand, the
body of the operator in Figure 3 captures a differ-
ent way of finding the value, one that presumably
requires more effort. It specifies the perceptual
task of finding the values <l1> and <l2> sur-
rounding the desired value on the axis along with
the fraction <f> of the distance that the desired
value lies between <l1> and <l2>, followed by
the cognitive task of interpolating between the re-
trieved values <l1> and <l2>.
Our operators contain data requirements (la-
belled Data-req) which the data must satisfy in
order for the operator to be applicable in a graphic
planning paradigm; they may also contain display
constraints (labelled Display-const) which con-
strain how the information graphic is constructed
if this operator is part of a final plan. In the case
of plan recognition, these constraints are used
in reverse. The display constraints are used to
eliminate operators from consideration, since if
a graphic does not satisfy the operator?s display
constraints, then the operator could not be part of
a plan that led to the graphic. If a graphic meets
the display constraints of an operator, then the
data requirements are used to limit how the op-
erator?s parameters might be instantiated.
4.4.1 Beginning the Plan Inference Process
Traditional plan inference systems used for
language understanding start with the primitive
goal achieved by the speech act in the dialogue
or discourse. In the case of information graphics,
the role of the speech act is played by the primi-
tive perceptual tasks that the viewer performs on
the graphic. To limit the set of perceptual tasks
that are considered, we make two observations:
? The graphic designer has many alternative
ways of designing a graphic, and the de-
sign choices facilitate some perceptual tasks
more than others. Following the Auto-
Brief work(Kerpedjiev and Roth, 2000) on
generating graphics that fulfill communica-
tive goals, we hypothesize that the designer
chooses a design that best facilitates the
tasks that are most important to conveying
his intended message, subject to the con-
straints imposed by competing tasks.
? Entities may become particularly salient by
virtue of highlighting in the graphic (for ex-
ample, coloring certain elements different
from the others, annotating an element with
an asterisk, or exploding one piece of a pie
chart1), by their mention in the caption or
surrounding text, or via world knowledge
1(Mittal, 1997) discusses a variety of such design tech-
niques in the context of distorting the message inferred from
a graphic.
capturing mutual beliefs about entities of in-
terest to the intended audience. We hypoth-
esize that the designer relies on the viewer
recognizing particularly salient entities, in
order to make certain perceptual tasks more
salient to the viewer.
As noted in Section 4.1, one cannot rely on a
graphic?s caption to provide the intended mes-
sage of the graphic. Consequently, the plan in-
ference process starts with both the set of tasks
that are best enabled by the information graphic
and the set of tasks (if any) that are particularly
salient. These will be referred to as candidate
tasks. The next two subsections describe how
candidate tasks are identified.
Identifying the Best Enabled Tasks The
APTE (Analysis of Perceptual Task Effort) sub-
module, shown in Figure 1 as part of the Inten-
tion Recognition Component, captures perceptual
knowledge about performing primitive perceptual
tasks2, and it encapsulates the results of cognitive
psychology research to estimate the relative effort
required for different tasks. The output of APTE
is the set of perceptual tasks that are best enabled
by the graphic. These become candidate tasks.
Each APTE rule captures a primitive percep-
tual task that can be performed on a particu-
lar type of information graphic, the conditions
(graphic design choices) that affect the difficulty
of performing that task, and the estimated effort
expended by a viewer if those conditions are sat-
isfied in the graphic. The condition-computation
pairs are ordered so that the ones producing the
lowest effort estimates appear first in a rule.
To derive the effort estimates in the rules, we
have followed the GOMS approach(Card et al,
1983) by breaking down the tasks that are re-
garded as primitive in our plan operators into
even more basic component tasks, and then sum-
ming the effort estimates for these very basic
tasks. Lohse?s work(Lohse, 1993) is an exam-
ple of the GOMS architecture applied to predict-
ing performance on graph comprehension tasks,
and many of our effort estimates are based on
Lohse?s research. For example, Figure 4 dis-
2Primitive perceptual tasks are those that we do not de-
compose into a set of simpler subtasks; this is not to be con-
fused with the notion of a psychological primitive.
plays the APTE rule for the task of finding the
value associated with the top of a bar in a bar
chart. If the bar is annotated with its value,
then condition-computation pair B1-1 estimates
its effort as 150 units for discriminating the label
(based on work by Lohse(Lohse, 1993)) and 300
units for recognizing a 6-letter word (John and
Newell, 1990). If the bar is not annotated with its
value but is aligned with a tick mark on the axis,
then condition-computation pair B1-2 estimates
the perceptual effort in terms of the distance to the
dependent axis (in order to capture the degrees of
visual arc scanned(Kosslyn, 1989)) plus the effort
of discriminating and recognizing the label. Fig-
ure 5 displays the APTE rule associated with the
first subgoal in Figure 3. It estimates the effort for
the primitive task Perceive-info-to-interpolate as
the effort of the scan to the dependent axis (based
on (Kosslyn, 1989)), the effort of discriminating
the intersection location on the axis (150 units
based on (Lohse, 1993)), plus the effort of the sac-
cade to each label (230 units each (Russo, 1978))
along with the effort involved in discriminating
and recognizing the labels. Similarly, there is a
cognitive rule (not discussed here) for estimating
the effort associated with the cognitive task Inter-
polate (the second subgoal in the operator in Fig-
ure 3). (Elzer et al, 2003a) presents a more ex-
tensive discussion of the cognitive principles un-
derlying the APTE rules.
Given the XML representation of an informa-
tion graphic, each APTE rule that is applicable
to the graphic produces an effort estimate for the
task captured by the rule. When a task might be
instantiated in multiple ways and still satisfy the
conditions of a condition-computation pair (for
example, the task of finding the value of the top
of a bar could be instantiated for each bar in a
bar chart), only the instantiation that produces the
lowest effort estimate becomes a candidate task.
(If the bars are not annotated with values, then the
instantiation that will produce the lowest effort es-
timate for the task of finding the value of the top
of a bar in a bar chart would be the bar with the
shortest scan to the dependent axis.) This is con-
sistent with the idea that the graphic designer will
make the important tasks easy to perform. The
set of perceptual tasks that require the least effort
become candidate tasks.
Rule-1:Estimate effort for task Perceive-dependent-value(<viewer>, <g>, <att>, <e>, <v>)
Graphic-type: bar-chart
Gloss: Compute effort for finding the exact value <v> for attribute <att> represented by top <e>
of a bar <b> in graph <g>
B1-1: IF the top of bar <b> is annotated with a value,
THEN effort=150 + 300
B1-2: IF the top <e> of bar <b> aligns with a labelled tick mark on the dependent axis,
THEN effort=scan + 150 + 300
Figure 4: A rule for estimating effort for the primitive perceptual task Perceive-value
Rule-2:Estimate effort for task
Perceive-info-to-interpolate(<viewer>,<g>,<axis>,<e>,<l1>,<l2>,<f>)
Graphic-type: bar-chart
Gloss: Compute effort for finding the information needed for interpolation, including the labels
<l1> and <l2> on either side of entity <e> on axis <axis> in graph <g>,
and the fraction <f> that is the distance between <l1> and entity <e> on <axis>
relative to the distance between <l1> and <l2>
B2-1: IF <axis> is labelled with values THEN effort=scan + 150 + ((230 + 150 + 300) x 2)
Figure 5: A rule for estimating effort for the primitive perceptual task Perceive-info-to-interpolate
Identifying Particularly Salient Tasks
Salient tasks are those that the viewer might
perform because they relate to entities that are
in the viewer?s current focus of attention, as
determined by contextual knowledge provided
by the caption, highlighting, and the surrounding
text and by world knowledge in the form of
mutual beliefs about items of particular interest
to the viewing audience.
Ideally, a caption will provide clues about the
message that an information graphic is intended
to convey, and thus noun phrases in captions rep-
resent salient entities.3 The graphic designer can
also call into focus certain aspects of the graphic
by using attention-getting devices such as col-
oring it differently from the rest of the graphic,
annotating it with an arrow, etc. Our working
hypothesis is that if the graphic designer goes
to the effort of employing such attention-getting
devices, then the highlighted items almost cer-
tainly contribute to the intended message. Thus
the attributes of these highlighted items (for ex-
ample, the attributes of a highlighted bar in a bar
chart), which are captured in the XML represen-
3Verb phrases in captions also provide evidence, but they
suggest particular operators of interest rather than instanti-
ated perceptual tasks, and thus we associate verbs with oper-
ators in the plan library.
tation of the graphic, are also regarded as salient
entities. Salient entities also include those that
world knowledge suggests are mutually believed
to be of interest to the viewing audience. We en-
vision in the future using the notion of lexical
chains(Silber and McCoy, 2000) to identify enti-
ties that the accompanying text makes particularly
salient. Perceptual tasks that are instantiated with
a salient entity and that can be performed on the
graphic are designated salient tasks.
4.4.2 The Search Process
Candidate tasks consist of the set of percep-
tual tasks that require the least effort and the set of
salient tasks. Once the set of candidate tasks has
been identified, plan inference begins. Initial can-
didate plans are constructed from each operator
in which a candidate task appears as a subgoal;
the root of the candidate plan is the goal of the
operator, and its children are the subgoals in the
body of the operator. Chaining from the root goal
to other operators whose body contains the root
goal as a subgoal produces larger candidate plans
with higher-level goals as the new root goal.
Plan inference systems have used a variety of
heuristics to evaluate candidate plans and to se-
lect the candidate plan to expand further. These
heuristics help to guide the search through the
space of candidate plans in order to hypothe-
size the plan that best represents the user?s in-
tentions. These heuristics have included increas-
ing the rating of partial plans as their arguments
become instantiated(Perrault and Allen, 1980),
preferring coherent discourse moves(Litman and
Allen, 1987; Carberry, 1990), and biasing the
plan inference process based on knowledge about
the user group(Gertner and Webber, 1996). We
have identified several kinds of evidence for guid-
ing plan inference from information graphics, in-
cluding the estimated effort required by a candi-
date plan, the basis for instantiating parameters in
the plan, adherence to the proximity compatibil-
ity principle from cognitive science research, and
the relation between a candidate plan and the es-
tablished discourse context.
Since our working hypothesis is that the
graphic designer tried to enable those tasks neces-
sary to recognize his intended message, candidate
plans that require substantially more effort than
other candidate plans are less likely to represent
the intentions of the designer. The effort associ-
ated with a candidate plan is measured as the sum
of the effort of the tasks comprising it.
There are many ways that a parameter in a task
or subgoal might become instantiated, and the ba-
sis for the instantiation provides evidence about
the likelihood that a hypothesized candidate plan
represents the graphic designer?s intentions. If
an instantiation is suggested by highlighting or
a caption or entities that are particularly salient
to the targeted audience, that partial plan should
be evaluated more favorably since the designer of
the graphic has provided reasons for the viewer to
use these instantiations in recognizing his inten-
tions. Similarly, if the instantiation is one of sev-
eral possible alternatives with no reason for pre-
ferring one over the other, then the partial plan
should be evaluated less favorably since the de-
signer did not give the viewer any reason to prefer
one over the other. This relates to Allen?s forking
heuristic(Perrault and Allen, 1980). The proxim-
ity compatibility principle(Wickens and Carswell,
1995) also suggests that candidate plans which
use similarly encoded elements (for example, all
red bars) in an integrated fashion should be eval-
uated more favorably than those that do not.
If there is a context established by the text pre-
ceding or surrounding the graphic, then candidate
plans whose root goal contributes to the exist-
ing discourse context should be preferred. If the
surrounding text has a reference to the graphic,
then focusing heuristics(Carberry, 1990) will pre-
fer candidate plans that relate most closely to the
current focus of attention at that point in the sur-
rounding text. However, the surrounding text of-
ten does not refer to accompanying graphics, as is
the case in the Newsweek article whose excerpt is
shown in Figure 6. Future work will investigate
how we should handle instances such as this.
5 Response Generation and Followup
The intended message of the graphic must be
augmented with additional propositions that con-
vey interesting features that a viewer would glean
from the graphic. For example, the intended mes-
sage of the graphic in Figure 6 appears to be that
the income of black women has risen dramati-
cally over the last decade and reached the level
of white women. But other interesting features of
the graphic might include the trends over the past
several decades, periods where they were closest,
etc. In future work, we anticipate developing a
methodology for identifying propositions that ex-
pand on the message of the graphic designer and
for including the most salient of these in the sum-
marization of the graphic. We also envision re-
sponding to followup requests for further infor-
mation about the graphic by selecting the highest
ranking propositions that were not included in the
initial message, organizing them into a coherent
response, and conveying it to the user.
6 Summary
This paper has argued that understanding
information graphics is a discourse-level prob-
lem. Not only must the system recognize the in-
tended message of the information graphic, but
the recognition process requires similar kinds of
knowledge sources and similar kinds of process-
ing as does the understanding of traditional dis-
course and dialogue. Moreover, when an article
is composed of text and graphics, the intended
message of the information graphic must be in-
tegrated into the discourse structure of the sur-
rounding text, and it contributes to the overall dis-
course intention of the article.
References
L. Ardisonno and D. Sestero. 1996. Using dynamic
user models in the recognition of the plans of the
user. User Modeling and User-Adapted Interac-
tion, 5(2):157?190.
S. Carberry and L. Lambert. 1999. A process model
for recognizing communicative acts and modeling
negotiation subdialogues. Computational Linguis-
tics, 25(1):1?53.
S. Carberry. 1990. Plan Recognition in Natural Lan-
guage Dialogue. ACL-MIT Press Series on Natural
Language Processing. MIT Press, Cambridge, MA.
S. Card, T. Moran, and A. Newell. 1983. The Psychol-
ogy of Human-Computer Interaction. Lawrence
Erlbaum Associates, Inc., Hillsdale, NJ.
E. Charniak and R. Goldman. 1993. A bayesian
model of plan recognition. Artificial Intelligence,
64:53?79.
H. Clark. 1996. Using Language. Cambridge Univer-
sity Press.
M. Corio and G. Lapalme. 1999. Generation of texts
for information graphics. In Proceedings of the 7th
European Workshop on Natural Language Genera-
tion EWNLG?99, pages 49?58.
S. Elzer, N. Green, and S. Carberry. 2003a. Exploit-
ing cognitive psychology research for recognizing
intention in information graphics. In Proceedings
of the 25th Annual Meeting of the Cognitive Science
Society. To appear.
S. Elzer, N. Green, S. Carberry, and K. McCoy. 2003.
Extending plan inference techniques to recognize
intentions in information graphics. In Proceedings
of the Ninth International Conference on User Mod-
eling. To appear.
A. Gertner and B. Webber. 1996. A Bias Towards
Relevance: Recognizing Plans Where Goal Mini-
mization Fails. In Proc. of the Thirteenth National
Conference on Artificial Intelligence, pages 1133?
1138.
H. P. Grice. 1969. Utterer?s Meaning and Intentions.
Philosophical Review, 68:147?177.
B. Grosz and C. Sidner. 1986. Attention, Intentions,
and the Structure of Discourse. Computational Lin-
guistics, 12(3):175?204.
B. John and A. Newell. 1990. Toward an engi-
neering model of stimulus response compatibility.
In R. Gilmore and T. Reeve, editors, Stimulus-
response compatibility: An integrated approach,
pages 107?115. North-Holland, New York.
A. Kennel. 1996. Audiograf: A diagram-reader for
the blind. In Second Annual ACM Conference on
Assistive Technologies, pages 51?56.
S. Kerpedjiev and S. Roth. 2000. Mapping com-
municative goals into conceptual tasks to generate
graphics in discourse. In Proc. of the International
Conference on Intelligent User Interfaces, pages
60?67.
S. Kosslyn. 1989. Understanding charts and graphs.
Applied Cognitive Psychology, 3:185?226.
D. Litman and J. Allen. 1987. A Plan Recognition
Model for Subdialogues in Conversation. Cognitive
Science, 11:163?200.
G. Lohse. 1993. A cognitive model for understand-
ing graphical perception. Human-Computer Inter-
action, 8:353?388.
Peter B. Meijer. 1992. An experimental system for
auditory image representations. IEEE Transactions
on Biomedical Engineering, 39(2):291?300, Febru-
ary.
V. Mittal. 1997. Visual prompts and graphical design:
A framework for exploring the design space of 2-D
charts and graphs. In Proc. of the Fourteenth Na-
tional Conference on Artificial Intelligence, pages
57?63.
R. Perrault and J. Allen. 1980. A Plan-Based Anal-
ysis of Indirect Speech Acts. American Journal of
Computational Linguistics, 6(3-4):167?182.
J. Russo. 1978. Adaptation of cognitive processes to
eye movement systems. In J. Senders, D. Fisher,
and R. Monty, editors, Eye movements and higher
psychological functions. Lawrence Erlbaum, Hills-
dale, NJ.
J. Searle. 1970. Speech Acts: An Essay in the Phi-
losophy of Language. Cambridge University Press,
London.
G. Silber and K. McCoy. 2000. Efficient text summa-
rization using lexical chains. In Proc. of the Inter-
national Conference on Intelligent User Interfaces,
pages 252?255.
C. Wickens and M. Carswell. 1995. The proximity
compatibility principle: Its psychological founda-
tion and relevance to display design. Human Fac-
tors, 37(3):473?494.
R. Wilensky. 1983. Planning and Understanding.
Addison-Wesley.
J. Yu, J. Hunter, E. Reiter, and S. Sripada. 2002.
Recognising visual patterns to communicate gas
turbine time-series data. In ES2002, pages 105?
118.
Appendix of Graphics from our Corpus
Graphic from Newsweek Article
60 70 80 90 01
$15
10
5
Black women
White women
Median Income
In thousands of 2001 dollars
1948
Relevant Text from Newsweek Article
This is not to say that black women have
climbed the storied crystal stair. They remain
?in the proving stage?, observes Alabama ex-
ecutive Alice Gordon. Nearly 14 percent of
working black women remain below the poverty
level. And women don?t yet out-earn black men.
But the growing educational-achievement gap
portends a monumental shifting of the sands.
College-educated black women already earn
more than the median for all black working men
? or, for that matter, for all women. And as
women in general move up the corporate pyra-
mid, black women, increasingly, are part of the
parade. In 1995 women held less than 9 per-
cent of corporate-officer positions in Fortune
500 companies, according to Catalyst, a New
York-based organization that promotes the inter-
ests of women in business. Last year they held
close to 16 percent, a significant step up. Of
those 2,140 women, 163 were black ? a minus-
cule proportion, but one that is certain to grow.
Figure 6: Excerpt from Newsweek Magazine
How reliable adults think DNA tests are for identifying an individual:
Trusting DNA
Don?t know
Very unreliable
unreliable
Somewhat 
reliable
Somewhat
Very reliable
2%
3%
4%
68%
23%
Figure 7: Standalone Graphic from USA Today
Europe
Canada
African
Other
countries
South
United
States
Africa
21
metric tons
Leading producers in
in gold production
South Africa tops
428
355
187 155
Gold Production
M
et
ric
 T
on
s
Figure 8: Standalone Graphic from USA Today
010,000
Median Salaries (in dollars), Full?Time Employed SMET Doctorates, by Field and Gender, 1997
Computer/All SMET Physical Sciences
Sal
ari
es 
(in 
dol
lars
)
SciencesMathematical
Engineering Life Sciences Social Sciences
80,000
70,000
60,000
50,000
40,000
30,000
20,000
Male
Female
Figure 9: Graphic from Report of the NSF Committee on Equal Opportunities in Science & Engineering
personal filings
Delaware bankruptcy
3000
2500
1000
1500
2000
1998 1999 2000 2001
Figure 10: Graphic from Wilmington News
Journal
0.6%
?96 ?97 ?98 ?99 ?00 ?01
1.0%
2.0%
3.0%
0.8%
0
?96 ?97 ?98 ?99 ?00 ?01
All taxpayers
Affluent taxpayers
1.2%
continue to slide
Audits of affluent
were audited by the IRS:
Percentage of taxpayers who
0
0.6%
1.8%
Figure 11: Graphic from USA Today
Extending Document Summarization to Information Graphics
?Sandra Carberry, ??Stephanie Elzer, ? ? ?Nancy Green, ?Kathleen McCoy and ?Daniel Chester
?Dept. of Computer Science, University of Delaware, Newark, DE 19716
(carberry, mccoy, chester@cis.udel.edu)
??Dept. of Computer Science, Millersville Univ., Millersville, PA 17551
(elzer@cs.millersville.edu)
? ? ?Dept. of Math. Sciences, Univ. of North Carolina at Greensboro, Greensboro, NC 27402
(nlgreen@uncg.edu)
Abstract
Information graphics (non-pictorial graphics such
as bar charts or line graphs) are an important
component of multimedia documents. Often such
graphics convey information that is not contained
elsewhere in the document. Thus document summa-
rization must be extended to include summarization
of information graphics. This paper addresses our
work on graphic summarization. It argues that the
message that the graphic designer intended to con-
vey must play a major role in determining the con-
tent of the summary, and it outlines our approach
to identifying this intended message and using it to
construct the summary.
1 Introduction
Summarization work has focused primarily on the
written words in a document. However, graphics
are an important part of many documents, and they
often convey information that is not included else-
where in the document. Thus as text summarization
branches out, it is essential that it consider the sum-
marization of graphical information in documents.
Graph summarization has received some atten-
tion. (Yu et al, 2002) has used pattern recogni-
tion techniques to summarize interesting features of
automatically generated graphs of time-series data
from a gas turbine engine. (Futrelle and Nikolakis,
1995) developed a constraint grammar formalism
for parsing vector-based visual displays and produc-
ing structured representations of the elements com-
prising the display. The goal of Futrelle?s project
is to produce a graphic that summarizes one or
more graphics from a document (Futrelle, 1999).
The summary graphic might be a simplification of
a graphic or a merger of several graphics from the
document, along with an appropriate summary cap-
tion. Thus the end result of summarization will it-
self be a graphic.
Our project is concerned with information graph-
ics (non-pictorial graphics such as bar charts or line
graphs). Our current focus is on providing an ini-
tial summary of an information graphic, within a
larger interactive natural language system that can
respond to followup questions about the graphic.
There are several useful applications for a system
that can summarize information graphics. For dig-
ital libraries, the initial summary of the graphic
will be used in conjunction with the document
text/summary to provide a more complete represen-
tation of the content of the document to be used
for searching and indexing. In the case of environ-
ments with low-bandwidth transmission and minia-
ture viewing facilities, such as cellular telephones
for accessing the web, the initial summary and fol-
lowup capability will provide an alternative modal-
ity for access to the document.
However, the most compelling application of the
overall system is to provide effective access to in-
formation graphics for individuals with sight im-
pairments. The rapidly growing Information Infras-
tructure has had a major impact on society and the
development of technology. However, the growing
reliance on visual information display paradigms
obliges society to ensure that individuals with visual
impairments can access and assimilate information
resources as effectively as their sighted counter-
parts. The underlying hypothesis of our work is that
alternative access to what the graphic looks like is
not enough ? the user should be provided with the
message and knowledge that one would gain from
viewing the graphic in order to enable effective and
efficient use of this information resource. Thus our
system will present the user with an initial summary
that includes the primary message that the graphic
designer intended to convey, augmented with rel-
evant interesting features of the graphic, and then
interactively allow the user to access more detailed
summaries of information contained in the graphic.
As an example of the kinds of summaries that we
envision, consider the information graphic in Fig-
ure 1. The graphic designer?s communicative goal is
ostensibly to convey the sharp increase in bankrupt-
cies in 2001 compared with the previous decreasing
trend. More detailed features that might be of inter-
est include 1) that bankruptcies had been decreasing
at a steady rate since 1998, 2) that bankruptcies had
been decreasing slowly since 1998, 3) the percent-
age decrease each year, 4) the percentage increase
in bankruptcies in 2001, 5) the absolute increase in
bankruptcies in 2001, and 6) the total number of
bankruptcies in 2001. Thus the initial summary of
this graphic might be
This graphic shows that although
Delaware bankruptcy personal filings
decreased slowly and steadily from 1998
to 2000, they rose sharply in 2001.
Note that the proposed summary includes the hy-
pothesized intended message of the graphic, along
with the first two of the additional interesting fea-
tures of the graphic. The selection of additional fea-
tures to augment the summary is discussed further
in Section 3.3. The system would then respond to
user requests for additional information by present-
ing some or all of the other interesting features that
had been identified, as discussed in Section 3.4.
This paper provides an overview of our project.
Section 2 discusses the essential role of intention
recognition in graphics summarization. It argues
not only that the intended message of the graphic
designer must be inferred and included in a sum-
mary of a graphic, but also that the intended mes-
sage significantly influences the additional propo-
sitions that should be included in the summary.
Section 3 presents our approach to graph summa-
rization. It discusses how we use a computer vi-
sion module to construct an XML representation
that captures the components of the graphic and
their relationship to one another, and how we use
a Bayesian belief network to hypothesize the inten-
tions of the graph designer. The paper then dis-
cusses our plans for constructing a summary that
includes the graphic designer?s intended message
along with highly ranked additional propositions,
and how the lesser ranked propositions will be used
in an interactive natural language system that re-
sponds to the user?s requests for further summaries
of additional features of the graphic.
2 The Role of Intention in Graphics
Summarization
Text summarization has generally relied on statis-
tical techniques and identification and extraction
of key sentences from documents. However, it is
widely acknowledged that to truly understand a text
and produce the best summary, one must under-
stand the document and recognize the intentions of
the author. Recent work in text summarization has
personal filings
Delaware bankruptcy
3000
2500
1000
1500
2000
1998 1999 2000 2001
Figure 1: Graphic from a City Newspaper
60 70 80 90 01
$15
10
5
Black women
White women
Median Income
In thousands of 2001 dollars
1948
Figure 2: Graphic from Newsweek Magazine
begun to address this issue. For example, (Marcu,
2000) presents algorithms for automatically identi-
fying the rhetorical structure of a text and argues
that the hypothesized rhetorical structure can be
successfully used in text summarization.
Information graphics are an important component
of many documents. In some cases, information
graphics are stand-alone and constitute the entire
document. This is the case for many graphics ap-
pearing in newspapers, such as the graphic shown
in Figure 1. On the other hand, when an article is
comprised of text and graphics, the graphic gener-
ally expands on the text and contributes to the dis-
course purpose (Grosz and Sidner, 1986) of the arti-
cle. For example, Figure 2 illustrates a graphic from
Newsweek showing that the income of black women
has risen dramatically over the last decade and has
reached the level of white women. Although this in-
formation is not conveyed elsewhere in the article, it
contributes to the overall communicative intention
of this portion of the article ? namely, that there
has been a ?monumental shifting of the sands? with
regard to the achievements of black women.
Our project is concerned with the understand-
ing and summarization of information graphics: bar
charts, line graphs, pie charts, etc. We contend that
analyzing the data points underlying an informa-
tion graphic is insufficient. One must instead iden-
tify the message that the graphic designer intended
to convey via the design choices that were made
in constructing the graphic. (Although one might
suggest relying on captions to provide the intended
message of a graphic, Corio and Lapalme found
in a large corpus study (Corio and Lapalme, 1999)
that captions are often missing or are very general
and uninformative; our collected corpus of informa-
tion graphics supports their observations.) Design
choices include selection of chart type (bar chart,
pie chart, line graph, etc.), organization of informa-
tion in the chart (for example, aggregation of bars in
a bar chart), and attention-getting devices that high-
light certain aspects of a chart (such as coloring one
bar of a bar chart different from the others). Not
only should the graphic designer?s intended mes-
sage comprise the primary component of any sum-
mary, but this intended message has a strong influ-
ence on the salience of additional propositions that
might be included in the summary.
To see the importance of recognizing the graphic
designer?s intended message, consider the two
graphics in Figure 3. The one on the left, Fig-
ure 3a, appeared in an NSF publication. Both graph-
ics were constructed from the same data set. The
intended message of the graphic in Figure 3a is that
the salary of females is consistently less than that of
males for each of the science and engineering dis-
ciplines.1 Notice that the graphic designer selected
an organization for the graphic in Figure 3a that fa-
cilitated the comparison between male and female
salaries in each field. A different display of the
same data would facilitate different analyses. For
example, the graph in Figure 3b depicts the same
data as the graph in Figure 3a, yet the organiza-
tion tends to draw attention to comparisons within
male and female groups rather than between them,
1This graphic was constructed by a colleague who served
on the NSF panel that prepared the report. Thus we know the
intentions underlying the graphic.
and perhaps an integration/comparison of the mes-
sages conveyed by the two subgraphs. Thus the in-
tended message of the graphic in Figure 3b appears
to be that the ranking of the disciplines by salary are
about the same for both men and women. The dis-
tinctions between presentation formats illustrate the
extent to which the format can itself convey infor-
mation relevant to the graphic designer?s intended
message.
Now let us consider how the intended message
influences additional information that might be in-
cluded in a summary. Suppose that 1) the salary
differential between females and males was signif-
icantly larger in the life sciences than in other dis-
ciplines and 2) the average salary for both females
and males was much larger in engineering than in
any of the other disciplines. Feature 1) would be
particularly interesting and relevant to the intended
message of Figure 3a, and thus should be included
as part of the graphic?s summary. On the other hand,
this aspect would be less relevant to the intended
message of Figure 3b and thus not as important to
include. Similarly, Feature 2) would be particularly
relevant to the intended message of Figure 3b and
thus should be given high priority for inclusion in
its summary. Although an interactive system that
could analyze a graphic to any desired level of de-
tail might extract from the graphic the information
in both 1) and 2) above, we contend that a summary
of the graphic should prioritize content according to
its relevance to the designer?s intended message.
3 Graphic Summarization
Our architecture for graphic summarization consists
of modules for identifying the components of the
graphic, hypothesizing the graphic designer?s in-
tended message, planning the content of the sum-
mary, organizing a coherent summary, and interac-
tive followup. The following sections discuss four
of these modules.
3.1 Analyzing and Classifying a Graphic
The visual extraction module takes a screen image
of an information graphic. It is responsible for rec-
ognizing the individual components comprising the
graphic, identifying the relationship of the different
components to one another and to the graphic as a
whole, and classifying the graphic as to type. This
includes using heuristics (such as relative position
of a string of characters) to identify the axis labels
? for example, that the y-axis label is Delaware
2The source of the leftmost graph is the National Science
Foundation, Survey of Doctorate Recipients, 1997.
  
 
 
 
 
 
 

















 
 
 
 
 
 
 
 
 




































		
		
		
		
		
		
		
		
		





































80,000
70,000
60,000
50,000 50,000
60,000
70,000
80,000
40,000
30,000
20,000 20,000
30,000
40,000
FEMALE SALARIES MALE SALARIES
Computer/All
Math Sci
Engin. Phys.
Sci. Sci.
Social
Sci.
Life Sci.
Social Sci.
A
ll
Com
puter/M
ath Sci.
Phys Sci.
Engineering
Social Sci.
Life Sci.
Com
puter/M
ath Sci.
A
ll
Phys Sci.
Engineering
Life
Female
Male
(a) (b)
Figure 3: Two alternative graphs from the same data2
bankruptcy personal filings in Figure 1. Our cur-
rent implementation deals only with gray scale im-
ages (in pgm format) of bar charts, pie charts, and
line graphs, though eventually it will be extended to
handle color and other kinds of information graph-
ics. The output of the visual extraction component
is an XML file that describes the chart and all of its
components.
3.2 Identifying the Intended Message
The second module of our architecture is respon-
sible for inferring the graphic designer?s intended
message. In their work on multimedia generation,
the AutoBrief group proposed that speech act the-
ory can be extended to the generation of graphical
presentations (Kerpedjiev and Roth, 2000; Green et
al., 2004). They contended that the graphic design
was intended to convey its message by facilitating
requisite perceptual and cognitive tasks. By percep-
tual tasks we mean tasks that can be performed by
simply viewing the graphic, such as finding the top
of a bar in a bar chart; by cognitive tasks we mean
tasks that are done via mental computations, such as
computing the difference between two numbers.
The goal of our intention recognizer is the inverse
of the design process: namely, to use the displayed
graphic as evidence to hypothesize the communica-
tive intentions of its author. This is done by an-
alyzing the graphic to identify evidence about the
designer?s intended message and then using plan
recognition (Carberry, 1990) to hypothesize the au-
thor?s communicative intent.
3.2.1 Evidence about Intention
Following AutoBrief (Kerpedjiev and Roth, 2000),
we hypothesize that the graphic designer chooses
a design that makes important tasks (the ones that
the viewer is intended to perform in recognizing the
graphic?s message) as salient or as easy as possi-
ble. Thus salience and ease of performance should
be taken into account in reasoning about the graphic
designer?s intentions.
There are several ways that a task can be made
salient. The graphic designer can draw attention
to a component of a graphic (make it salient) by
an attention-getting or highlighting device, such as
by coloring a bar in a bar chart differently from
the other bars as in Figure 1 or by exploding a
wedge in a pie chart (Mittal, 1997). Attributes of
the highlighted graphic component are treated as
focused entities. Nouns in captions also serve to
establish focused entities. For example, a caption
such as ?Studying not top priority? would estab-
lish the noun studying as a focused entity. Focused
entities that appear as instantiations of parameters
in perceptual or cognitive tasks serve as evidence
that those tasks might be particularly salient. Sim-
ilarly, verbs that appear in captions serve as evi-
dence for the salience of particular tasks. For ex-
ample, the verb beats in a caption such as ?Canada
Beats Europe? serves as evidence for the salience
of a Recognize relative difference task. In the fu-
ture, we plan to capture the influence of surrounding
text by identifying the important concepts from the
text using lexical chains. Lexical chains have been
used in text summarization (Barzilay et al, 1999),
and our linear time algorithm (Silber and McCoy,
2002) makes their computation feasible even for
large texts. Whether a task is salient and the method
by which it was made salient are used as evidence
in our plan inference system.
The graphic design makes some tasks easier than
others. We use a set of rules, based on research by
cognitive psychologists, to estimate the relative ef-
fort of performing different perceptual and cogni-
tive tasks. These rules, described in (Elzer et al,
2004), have been validated by eye-tracking experi-
ments. Since the viewer is intended to recognize the
message that the graphic designer wants to convey,
we contend that the designer will choose a graphic
design that makes the requisite tasks easy to per-
form. This was illustrated in the two graphics in
Figure 3. The relative effort of performing a task is
thus used as another source of evidence in our plan
inference framework.
3.2.2 The Plan Inference Process
Our plan inference framework takes the form of
a Bayesian belief network. Bayesian belief net-
works have been applied to a variety of problems,
including reasoning about utterances (Charniak and
Goldman, 1993) and observed actions (Albrecht et
al., 1997). The belief network uses plan operators,
along with evidence that is gleaned from the infor-
mation graphic itself (as discussed in the preceding
section), to reason about the likelihood that vari-
ous hypothesized candidate plans represent the in-
tentions of the graphic designer.
Plan Operators for Information Graphics Our
system uses plan operators that capture knowledge
about how the graphic designer?s goal of conveying
a message can be achieved via the viewer perform-
ing certain perceptual and cognitive tasks, as well
as knowledge about how information-access tasks,
such as finding the value of an entity in a graphic,
can be decomposed into simpler subgoals. Our plan
operators consist of:
? Goal: the goal that the operator achieves
? Data-requirements: requirements that the data
must satisfy in order for the operator to be ap-
plicable in a graphic planning paradigm
? Display-constraints: features that constrain
how the graphic is eventually constructed if
this operator is part of the final plan
? Body: lower-level subgoals that must be ac-
complished in order to achieve the overall goal
of the operator.
Figures 4 and 5 present two plan operators for the
goal of finding the value <v> of an attribute <att>
for a graphical element <e> (for example, the value
associated with the top of a bar in a bar chart). The
body of the operator in Figure 4 specifies that the
goal can be achieved by a primitive perceptual task
in which the viewer just perceives the value; this
could be done, for example, if the element in the
graphic is annotated with its value. On the other
hand, the body of the operator in Figure 5 captures a
different way of finding the value, one that presum-
ably requires more effort. It specifies the perceptual
task of finding the values <l1> and <l2> surround-
ing the desired value on the axis along with the frac-
tion <f> of the distance that the desired value lies
between <l1> and <l2>, followed by the cogni-
tive task of interpolating between the retrieved val-
ues <l1> and <l2>.
Plan inference uses the plan operators to reasons
backwards from the XML representation of the ob-
served graphic (constructed by the visual extraction
module briefly described in Section 3.1). The dis-
play constraints are used to eliminate operators from
consideration ? if the graphic does not capture the
operator?s constraints on the display, then the opera-
tor could not have been part of a plan that produced
the graphic. The data requirements are used to in-
stantiate parameters in the operator ? the data must
have had certain characteristics for the operator to
have been included in the graphic designer?s plan,
and these often limit how the operator?s arguments
can be instantiated.
The Bayesian Belief Network The plan operators
are used to dynamically construct a Bayesian net-
work for each new information graphic. The net-
work includes the possible top level communicative
intentions (with uninstantiated parameters), such as
the intention to convey a trend, and the alternative
ways of achieving them via different plan opera-
tors. The perceptual tasks of lowest effort and the
tasks that are hypothesized as potentially salient are
added to the network. Other tasks are entered into
the network as they are inferred during chaining on
the plan operators; unification serves to instantiate
parameters in higher-level nodes. Evidence nodes
are added for each of the tasks entered into the net-
work, and they provide evidence (such as the degree
of perceptual effort required for a task or whether
a parameter of the task is a focused entity in the
graphic as discussed in Section 3.2.1) for or against
the instantiated tasks to which they are linked. Af-
ter propagation of evidence, the top-level intention
with the highest probability is hypothesized as the
graphic designer?s primary intention for the graphic.
Of course, a Bayesian network requires a set of
conditional probabilities, such as 1) the probability
that perceptual Task-A will be of low, medium, or
high effort given that the graphic designer?s plan in-
cludes the viewer performing Task-A, 2) the prob-
ability that parameter <x> of Task-A will be a fo-
Goal: Find-value(<viewer>, <g>, <e>, <ds>, <att>, <v>)
Gloss: Given graphical element <e> in graphic <g>, <viewer> can find the value <v>
in dataset <ds> of attribute <att> for <e>
Data-req: Dependent-variable(<att>, <ds>)
Body: 1. Perceive-dependent-value(<viewer>, <g>, <att>, <e>, <v>)
Figure 4: Operator for achieving a goal perceptually
Goal: Find-value(<viewer>, <g>, <e>, <ds>, <att>, <v>)
Gloss: Given graphical element <e> in graphic <g>, <viewer> can find the value <v>
in dataset <ds> of attribute <att> for <e>
Data-req: Natural-quantitative-ordering(<att>)
Display-const: Ordered-values-on-axis(<g>, <axis>, <att>)
Body: 1. Perceive-info-to-interpolate(<viewer>,<g>,<axis>,<e>,<l1>,<l2>,<f>)
2. Interpolate(<viewer>, <l1>, <l2>, <f>, <v>)
Figure 5: Operator that employs both perceptual and cognitive subgoals
cused entity in the caption given that the graphic de-
signer?s plan includes the viewer performing Task-
A, or 3) the probability that the viewer perform-
ing Task-B will be part of the designer?s intended
plan given that Task-A is part of his plan. (Note that
there may be several alternative ways of perform-
ing a particular task, as illustrated by the two plan
operators displayed in Figures 4 and 5.) We have
collected a rapidly expanding corpus of information
graphics, and have analyzed a small part of this cor-
pus to construct an initial set of probabilities. The
results suggest that our approach is very promising.
We will increase the number of analyzed graphics
to improve the probability estimates.
3.3 Planning the Content of the Summary
The recognized intention of the graphic designer,
such as to convey an overall increasing trend or to
compare salaries of females and males in different
disciplines as in Figure 3a, will provide one set of
highly salient propositions that should be included
in the graphic?s summary. Once the intentions have
been recognized, other visual features of the graphic
will influence the identification of additional salient
propositions.
We conducted a set of experiments in which sub-
jects were asked to write a brief summary of a set of
line graphs, each of which arguably could be said
to have the same high-level intention. Although
each summary included the high-level intention, the
summaries often differed significantly for different
graphs. By comparing these with summaries of the
same graph by different subjects, we have hypoth-
esized that certain features, such as the variance of
the data, can influence the generated summary, and
that the importance of including a specific feature in
a summary is related to the high-level intention of
the graphic. For example, variation in the data will
be relevant for an intention of conveying a trend,
but it will be less important than the overall slope
of the data points. This impact of the intended mes-
sage on the priority of including a specific feature
in a graphic was illustrated in Section 2, where we
showed how a significantly larger differential be-
tween female and male salaries for one particular
discipline would be more relevant to the summary of
the graphic in Figure 3a than for the graphic in Fig-
ure 3b. In addition, our experiments indicate that the
strength of a feature in the graphic also influences
its inclusion in a summary. For example, the more
ragged a sequence of line segments, the more salient
variance becomes for inclusion in a summary.
Once the content planning module has identified
and ranked interesting features that might augment
the intended message of the graphic, the most im-
portant propositions will be organized into a coher-
ent summary that can be stored for access in a digital
library or presented to a user. In the future, we will
also investigate integrating the summary of an infor-
mation graphic with the summary of its surrounding
text.
3.4 Interactive Followup
One of the primary goals of our work is an inter-
active natural language system that can convey the
content of an information graphic to a user with
sight impairments. For this application, the sum-
mary will be rendered in natural language and con-
veyed as an initial summary to the user via speech
synthesis. The system will then provide the user
with the opportunity to seek additional information.
We will utilize the propositions that were not in-
cluded in the initial message as indicative of ad-
ditional information about the graphic that might
be useful. Several kinds of followup will be pro-
vided. For example, if the user requests focused
followup, the system will categorize the remaining
propositions (for example, extreme values, trend de-
tail, etc.) and ask the user to select one of the cate-
gories of further information. The system will then
construct a followup message summarizing the most
important (often all) of the remaining propositions
in the selected category. This interactive followup
will continue until either all the propositions have
been conveyed or the user terminates the followup
cycle.
4 Summary
This paper extends document summarization to the
summarization of information graphics. It argues
that an effective summary must be based on the
message that the graphic designer intended to con-
vey in constructing the graphic, and that this in-
tended message strongly influences the relevance
of other propositions that might be included in the
summary. The paper describes our approach to
graphic summarization, including our plan infer-
ence system for inferring the intended message un-
derlying a graphic. This work has many applica-
tions. These include enabling information graphics
to be accessed via content in a digital library, allow-
ing access to information graphics via devices with
small bandwidth (such as cellular phones), and most
importantly making information graphics accessible
to individuals with sight impairments via an interac-
tive natural language system that can provide sum-
maries at various levels of detail.
References
David Albrecht, Ingrid Zukerman, Ann Nicholson,
and A. Bud. 1997. Towards a bayesian model
for keyhole plan recognition in large domains.
In Proceedings of the Sixth International Confer-
ence on User Modeling, pages 365?376.
R. Barzilay, K. McKeown, and M. Elhadad. 1999.
Information fusion in the context of multi-
document summarization. In Proc. of the 37th
Annual Meeting of the ACL, pages 550?557.
Sandra Carberry. 1990. Plan Recognition in Natu-
ral Language Dialogue. ACL-MIT Press Series
on Natural Language Processing. MIT Press.
Eugene Charniak and Robert Goldman. 1993. A
bayesian model of plan recognition. Artificial In-
telligence Journal, 64:53?79.
Marc Corio and Guy Lapalme. 1999. Generation of
texts for information graphics. In Proceedings of
the 7th European Workshop on Natural Language
Generation EWNLG?99, pages 49?58.
Stephanie Elzer, Nancy Green, Sandra Carberry,
and James Hoffman. 2004. Incorporating per-
ceptual task effort into the recognition of inten-
tion in information graphics. In Diagrammatic
Representation and Inference: Proceedings of
the Third International Conference on the Theory
and Application of Diagrams, LNAI 2980, pages
255?270.
Robert Futrelle and Nikos Nikolakis. 1995. Ef-
ficient analysis of complex diagrams using
constraint-based parsing. In Proceedings of the
Third International Conference on Document
Analysis and Recognition.
Robert Futrelle. 1999. Summarization of diagrams
in documents. In I. Mani and M. Maybury, edi-
tors, Advances in Automated Text Summarization.
MIT Press.
Nancy Green, Giuseppe Carenini, Stephan Kerped-
jiev, Joe Mattis, Johanna Moore, and Steven
Roth. 2004. Autobrief: An experimental system
for the automatic generation of briefings in inte-
grated text and graphics. International Journal of
Human-Computer Studies. to appear.
Barbara Grosz and Candace Sidner. 1986. Atten-
tion, Intentions, and the Structure of Discourse.
Computational Linguistics, 12(3):175?204.
Stephan Kerpedjiev and Steven Roth. 2000. Map-
ping communicative goals into conceptual tasks
to generate graphics in discourse. In Proceed-
ings of the International Conference on Intelli-
gent User Interfaces, pages 60?67.
Daniel Marcu. 2000. The rhetorical parsing of un-
restricted texts: A surface-based approach. Com-
putational Linguistics, 26(3):395?448.
Vibhu Mittal. 1997. Visual prompts and graphical
design: A framework for exploring the design
space of 2-d charts and graphs. In Proceedings
of the Fourteenth National Conference on Artifi-
cial Intelligence, pages 57?63.
Gregory Silber and Kathleen McCoy. 2002. Effi-
ciently computed lexical chains as an intermedi-
ate representation for automatic text summariza-
tion. Computational Linguistics, 28(4):487?496.
Jin Yu, Jim Hunter, Ehud Reiter, and Somaya-
julu Sripada. 2002. Recognising visual patterns
to communicate gas turbine time-series data. In
ES2002, pages 105?118.
Proceedings of the Fourth International Natural Language Generation Conference, pages 114?121,
Sydney, July 2006. c?2006 Association for Computational Linguistics
 
Generation of Biomedical Arguments for Lay Readers  
 Nancy Green 
Department of Computer Science 
University of North Carolina Greensboro 
Greensboro, North Carolina 27402-6170 USA 
nlgreen at uncg.edu 
 
 
 
Abstract 
This paper presents the design of a discourse 
generator that plans the content and organi-
zation of lay-oriented genetic counseling 
documents containing arguments, and an 
experiment to evaluate the arguments. Due 
to the separation of domain, argument, and 
genre-specific concerns and the methodol-
ogy used for acquiring a domain model, this 
approach should be applicable to argument 
generation in other domains. 
1 Introduction 
The goal of our research is to develop methods by 
which intelligent systems can help lay audiences to 
understand biomedical and other kinds of scientific 
arguments. We have been studying how one type 
of lay-communication and biomedical-domain ex-
pert, the genetic counselor, presents written argu-
ments in patient letters, standard documents 
summarizing information and services provided to 
the client (Baker et al, 2002). Clinical genetics 
involves causal probabilistic reasoning, e.g., diag-
nosis of a genetic basis for a health problem or 
prediction of inheritance risks. The patient letter is 
designed to document the experts? reasoning for 
medical and legal purposes, as well as to provide 
an explanation that a lay client can understand.  
    This paper presents, for the first time, the design 
of a discourse generator that plans the content and 
organization of genetic counseling patient letters 
containing arguments; and an experiment that we 
performed to evaluate the arguments.  The dis-
course generation process involves three modules: 
a qualitative causal probabilistic domain model, a 
normative argument generator, and a genre-
specific discourse grammar. In (Green, 2005), we 
reported a corpus study that produced a reliable 
biomedical coding scheme. In subsequent work-
shop papers (Green et al, 2004; 2005), we intro-
duced our use of qualitative probabilistic 
constraints and provided a brief description of the 
biomedical domain model. We have also provided 
informal descriptions of argument patterns in the 
corpus (Green, to appear; 2006). However, we 
have not previously published the design of the 
discourse generator, including the discourse 
grammar and argument generator, and their rela-
tionship to the domain model. 
    The theoretical significance of this work is 
three-fold. First, it is empirically based, i.e., based 
on analysis of arguments in a corpus of genetic 
counseling patient letters, since the goal is to pro-
duce the same kinds of normative arguments as are 
used in expert-lay communication. Second, the 
normative argument generator creates an inten-
tional-level representation of the arguments in the 
text, which provides a foundation for an intelligent 
system?s ability to engage in follow-up discussion 
about the arguments that have been presented. Fi-
nally, due to the separation of domain, argument, 
and genre-specific concerns in the design, and due 
to the methodology used to acquire a domain 
model, it should be possible to apply this approach 
to lay-oriented argument generation in other do-
mains. The practical significance of this work is 
that it is major step in the design of a deployable 
system to generate the first draft of genetic coun-
seling patient letters. As genetics plays an increas-
ingly important role in medicine, there is a need for 
tools to aid in dissemination of patient-tailored in-
formation. 
114
     In the next section, we give an overview of a 
prototype generation system, whose main compo-
nents are described in more detail in sections 3-5; 
an example of the generation process is given in 
section 6; an experiment to evaluate the generated 
arguments is presented in section 7; and related 
work is summarized in section 8. 
2 System Overview  
We are developing a prototype system for genetic 
counselors that will synthesize the first draft of a 
patient letter. The deployed system will consist of 
a graphical user interface for the genetic counselor, 
a domain model/reasoner, an argument generator, a 
discourse grammar, and a linguistic realizer. Proto-
types of all components except the linguistic real-
izer have been implemented. Although this paper 
focuses on discourse generation and its relationship 
to the domain model, as background we now de-
scribe the flow of information through the system. 
The domain model (section 3) is initialized with 
generic information on clinical genetics. Through a 
user interface providing menus and other non-free-
text input devices, the counselor will provide stan-
dard clinical information such as a patient?s symp-
toms and information about his family tree; test 
results; preliminary diagnosis (before testing); and 
final diagnosis (after test results are known). The 
system uses this information to transform its ge-
neric domain model into a specialized domain 
model of the patient and his family. 
In this genre, a patient letter must provide not 
only the above information, but arguments for the 
diagnosis and other inferences made by the medi-
cal experts. The discourse generation process 
works as follows. A discourse grammar (section 4) 
encodes the high-level topic structure of letters in 
this genre. The discourse grammar rules generate a 
derivation instantiated from the domain model with 
information specific to a patient?s case. For each of 
the writer?s claims about the case for which a nor-
mative  argument must be provided according to 
standard practice, the discourse grammar invokes 
the argument generator.  
The argument generator (section 5) uses non-
domain-specific argument strategies that are in-
stantiated with information from the domain 
model. The argument generator returns a structured 
representation of an argument in which the com-
municative function of information, e.g., as data or 
warrant, is identified. As illustrated in section 6, in 
future interactive systems  knowledge of commu-
nicative function could be used to support follow-
up discussion. In the current prototype, this knowl-
edge is used to determine presentation order, e.g., 
that data supporting a claim is to be presented be-
fore that claim. One of the goals of the experiment 
described in section 7 was to evaluate this order-
ing. In the final system, the output of discourse 
generation will be transformed by a linguistic real-
izer into the first draft of a letter. 
3     Domain Model 
In a previous study of the corpus (Green, 2005), 
we identified a small set of categories (e.g. geno-
type, test result, symptom) with good inter-rater 
reliability that can be used to describe the biomedi-
cal content of a genetic counseling letter as a 
causal probabilistic network (Korb and Nicholson, 
2004). A prototype domain model has been manu-
ally constructed covering representative genetic 
disorders using only these categories of variables. 
By restricting a domain model to these categories, 
the result should reflect the simplified conceptual 
model of genetics used by genetic counselors in 
communication with their lay clients; this facili-
tates generation since the generator will not have to 
distinguish what information in the domain model 
is appropriate to communicate to a lay audience. 
Another benefit of restricting a domain model in 
this way is that it reduces the knowledge acquisi-
tion effort of choosing variables and determining 
network topology; any genetic disorder in the 
scope of the coding scheme (over 4500 single-gene 
autosomal disorders) would be modeled in terms of 
a small number of variable types and a standard 
topology. Thus, it should be straightforward to 
semi-automatically construct a domain model cov-
ering many different genetic disorders. 
Figure 1 shows part of a domain model after it 
has been updated with information about a particu-
lar patient?s case. The nodes labeled GJB2 
(mother), GJB2 (father), GJB2 (child) are geno-
type variables, representing the mother?s, father?s, 
and child?s GBJ2 genotype, respectively. (A geno-
type is a pair of alleles of a gene; one allele is in-
herited from each parent. An individual who has 
two mutated alleles of the GJB2 gene usually ex-
periences hearing loss.) The nodes labeled hearing 
loss (child) and non-syndromic (child) are vari-
115
 ables representing the child?s symptoms. The node 
labeled test result (child) is a variable representing 
the results of testing the child?s GJB2 genotype.  
The most likely states of the variables are 
shown beside the nodes in Figure 1; T1 and T2 rep-
resent the time at which the (experts?) belief is 
held, before or after the child?s genetic test results 
are known, respectively. The information recorded 
in the network about this particular case is that the 
child was observed to have hearing loss and no 
features of a genetic syndrome; the preliminary 
diagnosis, i.e. before testing, was that the cause of 
hearing loss is having two mutated alleles of GJB2; 
the test results were negative, however; thus, the 
current diagnosis is some other (unspecified) auto-
somal recessively inherited genetic condition, rep-
resented by the genotype variable labeled other 
genotype (child). In addition, the parents are hy-
pothesized to be carriers (i.e. to each have one mu-
tated allele) of that genotype, represented by the 
variables labeled other genotype (mother), other 
genotype (father).  
     Although a causal probabilistic network used to 
perform diagnosis or risk calculation would require 
specification of numeric probabilities, the role of 
the network in our system is to qualitatively model 
the reasoning that the medical experts have per-
formed outside of the system. Also, we found that 
in the corpus numeric probabilities were provided 
only when citing epidemiological statistics or risks 
calculated according to Mendelian inheritance the-
ory (which does not require Bayesian probability 
computation). Thus, instead of using numeric 
probabilities for domain reasoning, the domain 
model uses qualitative constraints based upon for-
mal relations of qualitative influence, product syn-
ergy, and additive synergy (Druzdzel and Henrion, 
1993).  
     In addition to being adequate for natural lan-
guage generation, this approach greatly reduces  
knowledge acquisition effort; it should be straight-
forward to semi-automatically acquire the qualita-
tive constraints of a full-scale domain model due to 
regularities in this domain and the use of a re-
stricted set of variable types as described above. 
For example, qualitative constraints between geno-
types of parents and child would be determined by 
whether a genotype follows an autosomal domi-
nant or recessive inheritance pattern. 
     We now describe some of the qualitative do-
main constraints. An influence relation holds be-
tween a node in a causal graph and its direct 
descendant. A has a positive qualitative influence 
on B, written S+(state(A,VA), state(B,VB)), if the 
state of A reaching a threshold value VA makes it 
more likely that the state of B reaches value VB. 
For example, if having two mutated alleles of a 
genotype A normally results in the appearance of a 
symptom B, this could be described as 
S+(state(A,2), state(B,yes)). Each arc in Figure 1 
implicitly represents an S+ relation. 
Product and additive synergy describe converg-
ing connections, i.e., the relation between a set of 
variables {A, B} and their direct descendant C in a 
graph. A and B have negative product synergy 
with respect to state VC of C, written                    
X-({state(A,VA), state(B,VB)}, state(C,VC)), if 
either the state of A reaching a threshold VA or the 
state of B reaching a threshold VB makes it more 
likely that the state of C reaches VC. This type of 
relationship characterizes mutually exclusive alter-
native diagnoses that could account for the same 
symptom; it also characterizes autosomal dominant 
inheritance, an inheritance pattern where inheriting 
one mutated allele of a genotype (from either par-
ent) is usually sufficient to cause health problems. 
In Figure 1, the possible alternative causes of the 
symptoms are indicated by the X- annotations. 
On the other hand, autosomal recessive inheri-
tance, an inheritance pattern where inheriting two 
mutated alleles (one from each parent) is usually 
necessary to cause health problems, is character-
ized by zero product synergy (X0); A and B have 
zero product synergy with respect to state VC of C,  
X0({state(A,VA), state(B,VB)}, state(C,VC)), if the 
state of A reaching a threshold VA and the state of 
B reaching a threshold VB makes it more likely that 
the state of C reaches VC. For example, if the 
mother?s, father?s, and child?s genotype are repre-
sented by variables A, B, and C, respectively, then 
X0({state(A,1), state(B,1)}, state(C,2)) can repre-
sent the constraint that if the child?s genotype C 
has two mutated alleles, then one mutated allele 
must have come from each parent. In Figure 1, the 
autosomal recessive inheritance pattern of GJB2 
and the other hypothesized genetic disorder are 
indicated by the X0 annotations. 
Other qualitative constraints used in the domain 
model are based on negative qualitative influence 
(S-), positive product synergy (X+), and negative 
additive synergy (Y-). In addition, the domain 
model stores epidemiological statistics as probabil-
116
 ity statements composed of variables used in the 
network, e.g., the frequency of hearing loss due to 
GJB2. This type of information can be used as 
backing in an argument (see section 5) but does not 
play a role in domain reasoning. 
4 Discourse Grammar 
A discourse grammar was written based upon our  
analysis of the corpus and a description of standard 
practice in genetic counseling (Baker et al, 2002). 
The current grammar is intended to cover letters on 
single-factor autosomal genetic disorders. Thanks 
to the regularities in this domain and in this genre, 
the grammar consists of a small number of rules. 
The starting rule of the grammar represents the 
main sections of a letter in their standard order: 
opening, referral, preliminary diagnosis, testing, 
final diagnosis, origin of genetic condition, inheri-
tance implications, prognosis/treatment, and clos-
ing. One or more grammar rules describe each of 
these sections.  
     Grammar rules may request the domain rea-
soner for case-specific information to be included 
in the letter. In addition, when the grammar pro-
vides a choice of rules, rule selection is based upon 
case-specific information provided by the domain 
reasoner. For example, one rule for reporting the 
final diagnosis handles cases in which the patient?s 
test results confirm the preliminary diagnosis, and 
another rule those cases where the preliminary di-
agnosis has been disconfirmed by test results; the 
domain reasoner returns the information needed to 
choose between those two rules. 
     The process described so far creates an initial 
outline of the information to be presented (in non-
linguistic form), including various claims requiring 
an argument. Each of those claims is passed to the 
argument generator described in the next section. 
For example, the letter shown in Figure 2 contains 
seven claims labeled C1 to C7; argument generation 
adds information labeled D1 to D7, W1 to W7, and 
B1 to B4. The information returned by the argument 
generator is added to the outline, completing the 
structure that will be transformed by the linguistic 
realizer into text.      
5 Argument Generation 
Given a claim, the argument generator uses argu-
ment strategies to construct a normative argument 
for the claim from information provided by the 
domain reasoner. The strategies are non-domain-
specific in the sense that they refer to formal prop-
erties of the qualitative causal probabilistic domain 
model rather than to genetics.  
    According to Toulmin?s model of normative 
argument structure (1998), an argument for a claim 
can be analyzed in terms of various functional 
components: the data, warrant, and backing. The 
data are the facts used to defend a claim. The war-
rant is a principle that licenses the claim given the 
data. An optional backing may be used to justify 
the warrant, e.g., by giving the facts upon which 
the warrant is based. To derive the argument 
strategies used in the system, we analyzed the ar-
guments in the corpus in terms of Toulmin?s 
model; the resulting strategies describe mappings 
from formal properties of the domain model to the 
data and warrant supporting a claim and to the 
backing of a warrant. Several strategies are para-
phrased below for illustration.  
    Strategy 1. Argument for belief in causal claim, 
based on effects: An argument for the claim that it 
is believed to some extent at time Ti that 
state(A,VA) holds and that state(A,VA) is responsi-
ble for the states of variables B1..Bi, i.e., 
state(B1,VB1) .. state(Bi,VBi), consists of the (pre-
supposed) data that state(B1,VB1) .. state(Bi,VBi) 
hold, and optionally other data that state(Bj,VBj) .. 
state(Bk,VBk) hold, where the warrant is a positive 
influence relation S+(state(A,VA), state(Bp,VBp)) 
for each Bp in   { B1 .. Bi , Bj .. Bk}. 
     Strategy 2. Argument for decrease in belief to 
unlikely that state of causal variable is at or over 
threshold value, based on absence of predicted 
effect: An argument for the claim that there has 
been a decrease in belief, from time T1 to T2, to the 
belief at T2 that it is unlikely that state(A,VA) 
holds, consists of the (newly acquired) data that it 
is unlikely that state(C,VCi) holds for all VCi$VC, 
where the warrant is a positive influence relation 
S+(state(A,VA), state(C,VC)). 
    Strategy 3. Argument for increase in belief in 
causal claim, based on decrease in belief in alter-
native cause: An argument for the claim that there 
has been a increase in belief, from time T1 to T2, to 
the belief at T2 that it is believed to some extent 
that state(A,VA) holds and that state(A,VA) is re-
sponsible for the states of variables state(B1,VB1) .. 
state(Bi,VBi), consists of the (presupposed) data 
that state(B1,VB1) .. state(Bi,VBi) hold, and the 
117
 (newly acquired) data that it is unlikely that 
state(Alt,VAlt) holds for all VAlt$Vthreshold, where the 
warrant is a negative product synergy relation     
X-({state(A,VA),state(Alt,Vthreshold)},state(B,VB)) 
for each B in {B1 .. Bi}. 
    Strategy 4. Argument for belief in joint respon-
sibility, based on effect. An argument for the claim 
that it is believed to some extent at time Ti that 
state(A,VA) and state(B,VB) hold and that 
state(A,VA) and state(B,VB) are jointly responsible 
for state(C,VC), consists of the (presupposed) data 
that state(C,VC) holds, where the warrant is a zero 
product synergy relation X0({state(A,VA), 
state(B,VB)}, state(C,VC)). 
6 Example 
This section gives an example of discourse genera-
tion for the case in section 3. An outline created by 
application of the discourse grammar to the do-
main model in Figure 1 would contain, in addition 
to basic information about the case not requiring an 
argument, several claims requiring further support 
to be provided by the argument generator.  
    First, the claim that it was believed, before test-
ing, that the child?s hearing loss could be due to 
having two mutated alleles of GJB2 would be sup-
ported by an argument constructed using Strategy 
1. The data of the argument is the presupposition 
that the child has hearing loss and the additional 
finding that she has no syndromic features. The 
warrant is the positive influence relations (S+) link-
ing the variable representing the child?s GJB2 
genotype to each of the two variables representing 
the child?s symptoms. Note that if a reader ques-
tioned this argument, an interactive system could 
provide information on the source of the data or 
epidemiological statistics backing the warrant. 
      Second, the claim that it is currently believed, 
after testing, that it is unlikely that the child?s 
GJB2 genotype has two mutated alleles would be 
supported by an argument constructed using Strat-
egy 2. The data of the argument is that the child?s 
GJB2 test results were negative. The warrant is the 
positive influence relation (S+) from the child?s 
GJB2 genotype to the child?s GJB2 test results, 
which predicts that if the child had this mutation, 
then the test results would have been positive. If a 
reader questioned this argument, an interactive sys-
tem could provide information on the source of the 
data or back the warrant by providing information 
about the rate of false negatives.  
     Third, the claim that it is currently believed, 
after testing, that it is possible that the child has 
some other genetic condition that is responsible for 
her hearing loss would be supported by an argu-
ment constructed using Strategy 3. The data of the 
argument is that she has hearing loss and the cur-
rent belief that GJB2 is not likely responsible. The 
warrant is the negative product synergy relation 
(X-) between the child?s GJB2 genotype and an-
other genotype to hearing loss. If a reader ques-
tioned this argument, an interactive system could 
provide information on the proportion of cases of 
hearing loss that are due to other genetic conditions 
as backing for the warrant. 
    Fourth, the claim that it is currently believed, 
after testing, that it is possible that the parents are 
carriers (i.e., each has one mutated allele) of the 
unspecified genotype claimed to be responsible for 
the child?s hearing loss would be supported by an 
argument constructed using Strategy 4. The data of 
the argument is the presupposition that the child 
has two mutated alleles of the other genotype. The 
warrant is the zero product synergy relation (X0) 
between the two parents? genotype for this alterna-
tive to GJB2 and the child?s genotype for this same 
alternative. If a reader questioned this argument, an 
interactive system could provide an explanation of 
the warrant, which is based on the theory of Men-
delian inheritance; or it could provide the argument 
for the data, i.e., the belief that the child has two 
mutated alleles of the other genotype. 
    Finally, the claim that it is currently believed, 
after testing, that assuming they are both carriers 
there is a 25% probability that each future child 
that the two parents have together will inherit two 
mutated alleles of the other genotype would be 
supported by an argument constructed by a strat-
egy not shown in section 5. The data is the as-
sumption that the parents are both carriers, and the 
warrant is the same zero product synergy relation 
(X0) used in the argument for the fourth claim. If a 
reader questioned this argument, an interactive sys-
tem could provide an explanation of how the prob-
abilities are determined by zero product synergy.  
7 Experiment 
Argument generation was evaluated in the follow-
ing experiment. Five biology graduate students, 
118
 screened beforehand for writing ability in biology, 
were shown two patient letters. The letters were 
created by the experimenter by paraphrasing the 
output of discourse generation that would be input 
to the realizer. The paraphrases are similar in syn-
tax and lexical style to letters in  the corpus, but the 
genetic disorders covered in the experiment?s let-
ters differ from those covered in the corpus. One 
letter concerns a child confirmed to have cystic 
fibrosis (CF); the other a child whose test results 
for Waardenburg syndrome (WS) were negative. 
The text of letter CF is given in Figure 2. The first 
column contains annotations describing the com-
municative function of the information: C for 
claim, D for data, W for warrant, and B for back-
ing. Each label is subscripted with an integer refer-
ring to the argument. (The row labeled C2/D3 
functions as both the claim of argument 2 and the 
data of argument 3.) Annotations were not shown 
to the experiment?s participants. Communicative 
function was used to determine presentation order 
within each argument. Letters CF and WS had 23 
and 25 segments, respectively, where a segment is 
defined as a unit fulfilling one of the above func-
tions, or a non-argument-related function. 
    The goal of the experiment was to conduct a 
preliminary evaluation of the acceptability of the 
arguments in terms of content, explicitness, and 
presentation order within arguments. The partici-
pants were asked to revise each letter as needed to 
make it more appropriate for its intended recipi-
ents, the biological parents of a patient. Partici-
pants were told they could reword, reorder, and 
make deletions and additions to a letter. The results 
are summarized in Table 1, which includes the av-
erage number of segments to/from which informa-
tion was added (New) or deleted (Delete), and 
reordered (Reorder). (Rewordings are not tabulated 
since it was not our goal to evaluate wording.) 
New and Delete are measures of acceptability of 
argument content and explicitness. Reorder is a 
measure of acceptability of ordering. On average, 
the number of New, Delete, and Reorder revisions 
were low: less than two per letter, with most revi-
sions in the category of Reorder. This is encourag-
ing since the system to be built for genetic 
counselors should provide acceptable arguments 
requiring a minimum of revision. 
     To provide more details about the results, first, 
the only segments to which participants added in-
formation are warrants. The deletions of data con-
sist of information presumably already known to 
the recipients, e.g. D6 in letter CF; other deletions 
are of part or all of a warrant or all of a backing. 
The only deletions of claims consist of information 
duplicated in another part of the letter; there were  
no cases where a claim was deleted even though it  
could be inferred from data and warrant. The reor-
derings were across-argument, which violates con-
ventional topic structure in the genre, or within-
argument. In the latter, half repositioned a claim 
from final position in an argument to a position 
before the warrant or backing; the other half repo-
sitioned the warrant or backing before the data.  
8 Related Work 
Due to space limitations, this section focuses on 
research on generation of normative arguments (as 
opposed to behavior-change and evaluative argu-
ments), and arguments designed for text rather than 
dialogue. Zukerman et al have presented several 
papers on argument generation from Bayesian 
network domain models (e.g., 2000). The type of 
domain model used in our work differs in two re-
spects. First, it is based on empirical research since 
it is intended to represent the simplified conceptual 
model presented to a lay audience in this genre. 
Second, it uses qualitative probabilistic constraints. 
One difference in argument generation is that our 
system?s argument strategies are based on analysis 
of the corpus. Also, our system creates an inten-
tional-level representation of an argument.     
     Teufel and Moens (2002) present a coding 
scheme for scientific argumentation in research 
articles that is designed for automatic summariza-
tion of human-authored text. Thus, it would not be 
sufficient for generation from a non-linguistic 
knowledge base. Also, it does not make the finer-
grained distinctions of the Toulmin model. 
     Branting et al (1999) present the architecture of 
a legal document drafting system. In it, a discourse 
grammar applies genre-specific knowledge, while 
a legal reasoning module creates the illocutionary 
structure of legal arguments. Branting et al argue 
for maintaining a distinct intentional-level repre-
sentation of arguments to support interactive fol-
low-up discussion. We agree, but our design 
further distinguishes domain reasoning from argu-
ment generation.  
    As for work on ordering and explicitness, Reed 
and Long (1997) propose ordering heuristics for 
119
 arguments of classical deductive logic. Fiedler and 
Horacek (2001) present a model for deciding what 
can be omitted from explanations of mathematical 
proofs. Carenini and Moore (2000) present an ex-
periment to determine how much evidence is opti-
mal in an evaluative argument.  
9 Conclusions 
This paper presents the design of a discourse gen-
erator that plans the content and organization of 
genetic counseling letters containing arguments. A 
preliminary evaluation of the arguments was prom-
ising. The most important contribution of this work 
is the design of a non-domain-specific normative 
argument generator that creates an intentional-level 
representation of an argument. From the corpus, 
we formulated argument strategies that map formal 
properties of qualitative causal probabilistic mod-
els to components of Toulmin?s model. Due to the 
separation of domain, argument and genre-specific 
concerns and the methodology used for acquiring 
the domain model, this approach should be appli-
cable to lay-oriented normative argument genera-
tion in other domains.  
Acknowledgments  
 
This material is based upon work supported by the 
National Science Foundation under CAREER 
Award No. 0132821. 
References 
Baker DL, Eash T, Schuette JL, Uhlmann WR. 2002. 
Guidelines for writing letters to patients. J Genetic 
Counseling, 11(5):399-418. 
Branting LK, Callaway CB, Mott BW, Lester JC. 1999. 
Integrating Discourse and Domain Knowledge for 
Document Drafting. Proc ICAIL-99, 214-220. 
Carenini G, Moore J.  2000. An empirical study of the 
influence of argument conciseness on argument ef-
fectiveness. Proc Ann Meeting of ACL, 150-7. 
Druzdzel MJ, Henrion M. 1993. Efficient reasoning in 
qualitative probabilistic networks. Proc 11th Nat Conf 
on AI, 548-553. 
Fiedler A, Horacek H. 2001. Argumentation in Explana-
tions to Logical Problems.  Computational Models of 
Natural Language Arguments. Proc ICCS 2001. 
Springer LNCS 2073, 969-978. 
Green N. 2005. A Bayesian Network Coding Scheme 
for Annotating Biomedical Information Presented to 
Genetic Counseling Clients. J Biomed Inf, 38: 130-
144. 
Green N. 2006. Representing Normative Arguments in 
Genetic Counseling. AAAI SSS: Argumentation for 
Consumers of Healthcare. 
Green N. To appear. Argumentation in a Causal Prob-
abilistic Humanistic Domain. Int J Intell Sys. 
Green N, Britt T, Jirak K. 2004. Communication of Un-
certainty in Genetic Counseling Patient Education 
Systems. AAAI FSS: Dialog Sys for Health Commun. 
Green N, Britt T, Jirak K, Waizenegger D, Xin X. 2005. 
User Modeling for Tailored Genomic E-health In-
formation. User Modeling 2005 Workshop: Person-
alisation for eHealth, 
Korb K, Nicholson AE. 2004. Bayesian artificial intel-
ligence.  Chapman Hall/CRC, Boca Raton, Florida.  
Reed C, Long D. 1997. Content ordering in the genera-
tion of persuasive discourse.  IJCAI-97, 1022-27. 
Teufel S, Moens M. 2002. Summarizing Scientific Arti-
cles: Experiments with Relevance and Rhetorical 
Status. CL, 28(4):409-445. 
Toulmin SE. 1998. The uses of argument. 9th ed. Cam-
bridge Univ. Press, Cambridge, England. 
Zukerman I, McConacy R,  Korb K. 2000. Using argu-
mentation strategies in automated argument genera-
tion. Proc INLG-2000.
 
letter CF New Delete Reorder letter WS New Delete Reorder 
 0 2 1  0 2 4 
 0 2 0  0 0 1 
 0 0 1  0 1 1 
 0 0 6  2 1 1 
 0 2 1  1 0 0 
AVG 0 1.2 1.8 AVG 0.6 0.8 1.4 
STDEV 0 1.1 2.4 STDEV 0.9 0.8 1.5 
 
Table 1. Number of revisions in letters CF and WS. (N=5) 
120
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Qualitative causal probabilistic network for hearing loss case. 
 
 [Patient] was referred by [doctor] to [clinic] on [date] for evaluation. 
D1 She has had frequent respiratory infections. 
W1 A genetic condition known as cystic fibrosis (CF) can cause respiratory problems. 
B1 Eighty percent of CF patients have chronic respiratory complaints. 
C1 [Doctor] suspected that CF could be the cause of her respiratory problems. 
 Patient was given a sweat chloride test for CF.  
D2 The test showed an abnormal sweat chloride level (75 mmol/L). 
W2 A result over 60 mmol/L is considered positive for CF. 
C2 / 
D3 
It is very likely that [patient] has CF. This means that cells in [patient?s] body contain two altered copies 
of a gene called CFTR. 
W3 This alteration affects organs that secrete mucous, such as the lungs. The alteration causes excessive se-
cretions, resulting in frequent lung infections. 
C3 This alteration of the CFTR gene is most likely the cause of [patient?s] respiratory problems. 
D4 Both of you, [patient?s] parents, are of Northern European ancestry. 
B4 One in twenty-five people of N. European ancestry carry one altered copy of the CFTR gene. 
C4 Each of you could carry this alteration. 
W5 Our cells contain two copies of each gene. One copy is inherited from each parent. A child who inherited 
two altered copies of a gene must have gotten one ...  from the mother and one ?  from the father. 
D5 Since [patient?s] cells contain two altered copies of CFTR, 
C5 it is likely that she got one altered copy of CFTR from each of you. 
C6 This is likely 
D6 even though neither of you have cystic fibrosis. 
W6 When a parent has one altered copy and one normal copy of a gene such as CFTR, he or she is not usually 
affected. Someone who has only one altered copy is called a ?carrier?. A child who inherits two altered 
copies will be affected since she has no normal copy. 
W7 A couple in which both are carriers will have a one in four (25%) chance that each child that they con-
ceive will inherit two altered copies and be affected. This also means that they have a three in four (75%) 
chance that the child will inherit at least one unaltered copy from one parent and not be affected. 
D7 Assuming that you are both carriers, 
C7 the chances for each child that you conceive together is 25% that the child will have CF, and 75% that the 
child will not have CF. 
 
Figure 2. Letter  used in experiment (column 2) with argument annotations (column 1).  
T1: unknown 
T2: negative 
T1: yes 
T2: yes 
X- 
X0 
GJB2 
(father) 
GJB2 (child) 
Hearing 
loss (child) 
Test result 
(child) 
T1: 2 mutated alleles 
T2: 0 mutated alleles 
T1: yes 
T2: yes 
T1: 1 mutated alleles 
T2: 0 mutated alleles 
T1: 1 mutated alleles
T2: 0 mutated alleles
X- 
T1: 0 mutated alleles 
T2: 2 mutated alleles 
Other genotype  
(father) 
Other genotype  
(mother)
X0
T1: 0 mutated alleles
T2: 1 mutated alleles
T1: 0 mutated alleles
T2: 1 mutated alleles
Non-syndromic 
(child) 
GJB2 
(mother) 
Other genotype 
(child) 
121
NAACL-HLT 2012 Workshop on Speech and Language Processing for Assistive Technologies (SLPAT), pages 37?46,
Montre?al, Canada, June 7?8, 2012. c?2012 Association for Computational Linguistics
Assisting Social Conversation between Persons with Alzheimer?s Disease 
and their Conversational Partners 
 
 
 
Nancy L. Green Curry Guinn Ronnie W. Smith  
UNC Greensboro 
Dept. of Computer Science 
UNC Wilmington 
Dept. of Computer Science 
East Carolina University 
Dept. of Computer Science 
 
Greensboro, NC, USA Wilmington, NC, USA Greenville, NC, USA  
nlgreen@uncg.edu guinnc@uncw.edu rws@cs.ecu.edu  
 
 
 
 
Abstract 
The number of people with dementia of the Alzheimer's 
type (DAT) continues to grow. One of the significant 
impacts of this disease is a decline in the ability to 
communicate using natural language. This decline in 
language facility often results in decreased social inter-
action and life satisfaction for persons with DAT and 
their caregivers. One possible strategy to lessen the ef-
fects of this loss of language facility is for the unaffect-
ed conversational partner (Facilitator) to "co-construct" 
short autobiographical stories from the life of the DAT-
affected conversational partner (Storyteller).  It has been 
observed that a skilled conversational partner can facili-
tate co-constructed narrative with individuals who have 
mild to moderate DAT.  Developing a computational 
model of this type of co-constructed narrative would 
enable assistive technology to be developed that can 
monitor a conversation between a Storyteller and Facili-
tator. This technology could provide context-sensitive 
suggestions to an unskilled Facilitator to help maintain 
the flow of conversation. This paper describes a frame-
work in which the necessary computational model of 
co-constructed narrative can be developed. An analysis 
of the fundamental elements of such a model will be 
presented.   
1 Introduction 
 
According to the Alzheimer?s Association 
[2009], 13% of Americans over the age of 65 pre-
sent with AD [Alzheimer?s Disease]. The decline 
in language associated with AD can result in de-
creased social interaction and life satisfaction for 
persons with AD and their caregivers.  In particu-
lar, persons with AD begin to feel a loss of their 
personal identity.  ?Reminiscent therapy is an ex-
ample of an intervention activity that can reveal 
and support a person?s identity. Even the family 
can participate and play a major role to support 
their relative? (Cohene et al 2005).  
 
It has been suggested that if caregivers can learn 
communication techniques to enhance social con-
versation with individuals affected by dementia of 
the Alzheimer?s type (DAT), it may make a signif-
icant difference in the quality of life of the persons 
with DAT, as well as reduce stress on their care-
givers (Dijkstra et al 2004). One recommended 
technique (Moore and Davis 2002; Waller 2006) is 
for the unaffected conversational partner (called 
the Facilitator in this paper) to ?co-construct? short 
autobiographical vignettes with the DAT-affected 
conversational partner (called the Storyteller in this 
paper). Typically, such ?small stories? (Bamberg 
and Georgakopoulou 2008) present the teller?s 
self-identity (e.g., hard-working, frugal, etc.). Ac-
cording to Cheepen (1988), co-constructed narra-
tive is common in social conversation. 
Furthermore, skilled conversational partners can 
facilitate co-constructed narrative with individuals 
who have mild to moderate DAT (Davis 2005; Da-
vis & Maclagan 2009; Davis 2010). A co-
constructed narrative produced by a person with 
DAT in conversation with skilled Facilitators is 
illustrated in Figure 1.  Increased social interaction 
can improve quality of life by enabling persons 
with DAT to remain socially engaged, which in 
turn may reduce their health problems as well as 
delay memory loss (Davis and Pope 2009; Len-
chuk and Swain 2010). 
37
  
Figure 1. An excerpt from Shenk et al (2002, p. 409) of 
a conversation between GM, a person with early moder-
ate DAT, and her skilled conversational partners BD 
and LM. We added annotations highlighting narrative 
elements (Labov 1972). 
 
 
While there have been several notable efforts in 
the area of communication training for caregivers 
of persons with DAT (see section 2.1), none have 
focused on assistive technology for improving 
communication in real-time as the conversation is 
occurring.  This paper presents a framework for 
developing a natural language processing system, 
ASSIST (Assistive Story Intervention Technolo-
gy), which can listen to the conversation between a 
person with DAT and his conversational partner 
and provide context-sensitive suggestions to the 
unaffected participant to help maintain the flow of 
conversation. In particular, ASSIST will help the 
unaffected partner to co-construct the autobio-
graphical stories of the participant with DAT.  To 
build a system such as ASSIST will require devel-
opment of a novel computational model of narra-
tive co-construction and other communication-
enhancing techniques for conversation with per-
sons with DAT.  After reviewing related research 
efforts, we present an analysis of the unique ele-
ments of the required computational model includ-
ing an NLU component designed to interpret the 
sometimes disfluent utterances of a Storyteller with 
DAT, a Dialogue/Story Manager which recognizes 
the discourse goals of the Storyteller and plans dia-
logue acts that the Facilitator could use to co-
construct the narrative, and an NLG/Coach that 
provides the Facilitator with suggestions on what 
to say next to co-construct the narrative and sustain 
the conversation.    
2 Related Research 
2.1 DAT Caregiver Communication 
For the most part, communication training for 
caregivers of persons with DAT has used non-
technological modes of active instruction such as 
role playing with human trainers (Ripich et al 
1998, Burgio et al 2001) and individualized one-
on-one coaching (McCallion et al 1999, Bourgeois 
et al 2004). Irvine et al (2003) describe a comput-
er program that enables a user to observe videos of 
conversations in which nurse aids demonstrate use 
of recommended communication techniques in 
conversation with patients. Davis and colleagues 
have developed a range of computer-based training 
materials (Davis and Smith 2009; Smith, Davis et 
al. 2010) providing information on stereotypes of 
aging and dementia, communication changes in 
dementia, and communication techniques such as 
?quilting? (Moore and Davis 2003), in which the 
caregiver repeats or paraphrases statements given 
by the person with DAT that seem to be elabora-
tions or evaluations of elements of a narrative. 
Green and colleagues developed and evaluated a 
menu-based interactive system for training care-
givers to engage more effectively in social conver-
sation with persons with DAT (Green 2002; Green 
and Davis 2003; Green, Lawton and Davis 2004; 
Green 2005a; Green and Bevan 2009). 
 /* orientation: */ 
1. GM:  I just lived in a regular farm home. 
Farmed cotton, corn, eh-everything 
you?grow on a farm. 
2. BD:   That?s right. 
/* complicating action: */ 
3. GM:  I had a big ol? cotton bag tied 
around me, pickin? a hundred pounds of 
cotton ? UhhmmHmm. 
4. BD:  A hundred pounds? An? you so ti-
ny! 
5. GM:  Huh? 
6. LM: You?re a tiny person to be carrying 
that much cotton. 
7. GM: I decided one day I?d pick a hun-
dred pounds. Guess how much! 
8. LM: How much? 
/* resolution: */ 
9. GM:  A hundred and three. 
10. LM:  Oooohh.  
11. BD: Wow. 
12. GM:  I went over. 
13. BD: That?s fantastic. 
/* evaluation: */ 
14. GM: A hundred and three?you?ve got 
to grab it to?get a hundred and three 
pounds of cotton in one day.  
38
2.2 Augmentative and Alternative Communi-
cation Technology  
There has been recent interest in developing remi-
niscence technology for the general population, 
e.g., (Cosley et al 2009; Petrelli et al 2009). Wal-
ler (2006) cites the need to develop augmentative 
and alternative communication systems for people 
with complex communication needs (CCN) to en-
gage in conversational narrative. One assistive 
software package, Talk:About, enables someone 
with CCN to edit pre-stored text during a conversa-
tion, enabling the user to retell autobiographical 
stories. Phototalk (Allen et al 2008) allows people 
with aphasia to manage personal photographs to 
support face-to-face communication. Non-
technology-based reminiscence therapy has been 
used in dementia care (Hsieh 2003; Woods et al 
2005) and gerontological nursing (Burnside 1996).  
 
CIRCA is a computer system that people with de-
mentia and caregivers can use together to prompt 
reminiscing by providing multimedia stimuli (Alm 
et al 2007). CIRCA provides touch-screen access 
to hypermedia presenting non-personalized remi-
niscence materials (e.g., photographs and music of 
a certain era). In a controlled study, CIRCA was 
compared to traditional reminiscence (TRAD) ses-
sions with materials provided by caregivers (Astell 
et al 2010). In TRAD sessions, ?the caregivers 
worked very hard to keep the interaction going, 
particularly by asking lots of questions. These were 
typically closed questions ? that did not encour-
age either initiation or choosing [topics] by people 
with dementia ? caregivers offer more choice dur-
ing CIRCA sessions and are much more likely to 
encourage the people with dementia to decide what 
they want to look at and talk about? (p. 7).  
 
Baecker and colleagues (Cohene et al 2005; Mas-
simi et al 2008; Smith et al 2009; Damianakis et 
al. 2010) have been investigating creation and use 
of personalized DVD-based multimedia biog-
raphies by persons with AD and mild cognitive 
impairments. These researchers note that organiza-
tions such as the National Institutes of Health rec-
ommend creation of personal reminiscence aids 
such as photographs to help maintain the affected 
individual?s sense of identity (Smith et al 2009). 
?The loss of identity is among the most devastating 
effects of Alzheimer?s disease ? it is possible that 
sensitively designed technologies may help com-
pensate for identity loss by acting as external 
memory or conversational aids? (Massimi et al 
2008).  Roark et al (2011) report on an initial 
study of technology-assisted co-construction.  
However, their emphasis is very different from 
ours and is focused on assisting with word and 
phrase completion of general conversation involv-
ing typewritten communication. 
2.3 Narrative Technology 
Cassell?s research group has focused on systems 
that interact with human storytellers. In Grand-
Chair, an embodied conversational agent (ECA) 
portrays a grandchild who elicits autobiographical 
stories from elderly users by providing feedback 
(through speech recognition technology) while the 
stories are recorded (Smith 2000). Story Listening 
Systems (SLS) use technology to encourage young 
children to create personally relevant stories in or-
der to improve their oral linguistic skills (Cassell 
2004). Sam the CastleMate (Ryokai, Vaucelle, & 
Cassell 2003) is an SLS in which SAM, an ECA, 
listens to the child?s stories (also using speech 
recognition technology) and tells stories to the 
child. Natural language processing and statistical 
machine learning tools have been applied to the 
problem of automatic plot analysis of children?s 
stories (Halpin et al 2004; Passonneau et al 2007) 
and to creation of story understanding tools (Elson 
and McKeown 2009).  
 
Other researchers have focused on story genera-
tion. Narrative scholars distinguish the fabula ? 
events in a fictional world ? and sujhet ? the au-
thor?s choices in presentation of selected elements 
of the fabula. (Note that in our future ASSIST sys-
tem, the fabula is already established when the us-
er?s stories are collected; the role of ASSIST is to 
facilitate the retelling, i.e., the sujhet.) Most past 
natural language generation research in narrative 
has focused on prose rather than dialogue (Calla-
way 2000; Theune et al 2007; Herv?s et al 2006). 
Piwek and Stoyanchev (2010) have investigated 
automatically transforming human-authored narra-
tive prose into dialogue performed by virtual char-
acters as a way of presenting educational 
information.  
39
3 Corpus Analysis  
Most previous computationally-oriented re-
search on human-human dialogue has focused on 
task-driven dialogue, i.e., dialogue intended to 
achieve an agent?s (or agents? collaborative) task 
goals such as making a travel reservation. In con-
trast, ASSIST is modeling social conversation con-
taining co-constructed narrative. That is, through 
certain conversational moves one participant (the 
Facilitator) can enable the other participant (the 
Storyteller) to retell short autobiographical stories, 
despite the Storyteller?s language and memory 
problems associated with DAT. The model will be 
informed by interdisciplinary research on retained 
language competencies of speakers with DAT 
(Davis 2005; Guendouzi and Muller 2006), as well 
as by our own statistical and qualitative analyses of 
the Carolina Conversations Collection (CCC) Cor-
pus (Davis and Pope 2009; Pope and Davis 2011). 
The CCC corpus includes 400 recorded and tran-
scribed conversations between researchers and stu-
dents and 125 persons with DAT. Our model will 
be constructed by annotating and analyzing a set of 
the DAT conversations as described in more detail 
in Section 4. The overall goal is to analyze the ef-
ficacy of narrative co-construction and other com-
munication-enhancing techniques proposed in 
previous studies of language of persons with DAT 
(e.g., Ripich and Wykle, 1996; Ramanathan 1997; 
Moore and Davis 2002; Santo Pietro and Ostuni, 
2003) and to possibly identify other effective tech-
niques.  As context for discussion of the necessary 
analysis of the CCC, we will first present a high-
level description of the necessary system architec-
ture. 
4 System Architecture 
The ASSIST architecture is shown in Figure 2. 
While a Storyteller and Facilitator converse, 
ASSIST listens with the goals of detecting poten-
tial problems in the flow of conversation and of 
providing suggestions to the Facilitator on what to 
say next to co-construct the narrative and sustain 
conversation. The tasks of the NLU component 
include syntactic and semantic interpretation and 
reference resolution; note that these tasks may re-
quire use of biographical information about the 
Storyteller to help interpret disfluencies character-
istic of AD language. Another key task of NLU is 
to recognize the Facilitator?s use of grounding acts,  
which play a key role in narrative co-construction 
and in sustaining conversation in general. One of 
the Dialogue/Story Manager?s tasks is to recog-
nize the conversational goals of the Storyteller?s 
contributions, including narrative goals. Having 
recognized the Storyteller?s current goal, the other 
task of the Dialogue Manager is to plan the next 
dialogue act that the Facilitator could use to con-
tinue to co-construct the Storyteller?s narrative. 
The Dialogue Manager may use biographical in-
formation about the Storyteller in both tasks, i.e., 
to help recognize narrative goals and to select con-
tent when planning the next suggested narrative 
act. The NLG/Coach component is responsible 
for providing the Facilitator with one or more sug-
gested utterances that the Facilitator could say 
next. Based upon the current discourse state, the 
suggested dialogue acts provided by the Dia-
logue/Story Manager, and a coaching model, the 
NLG/Coach component chooses one or more Fa-
cilitator acts and realizes them.  In the remainder of 
this section we will describe the required analyses 
of the corpus needed to inform the development of 
the computational model for each of these main 
architectural components. 
 
 
 
Figure 2. ASSIST system architecture. 
4.1 Dialogue/Story Manager  
Part of the CCC corpus study will analyze narra-
tive features of the dialogue and related pragmatic 
and affective features. Coelho (1998) surveys vari- 
Storyteller 
ASR 
Discourse 
State 
Biographical Info: 
People, relation-
ships, major events 
NLU 
Dialogue/ 
Story 
Manager 
NLG/
Coach 
Facilitator 
40
ous approaches to narrative analysis in discourse of 
communicatively impaired adults. Our analysis 
will reflect the following characteristics of conver-
sational narrative identified in narrative studies 
(Georgakopoulou and Goutsos 1997; Polkinghorne 
1996):  
? Conversational narratives have a characteristic 
structure, consisting of an abstract, orientation, 
one or more complicating actions, resolution, 
evaluation, and coda (Labov 1972). Note that 
only the complicating action and resolution are 
required. We will annotate this structure, as 
shown in Figure 1. 
? They often convey the teller?s attitudes and 
feelings about narrated events, i.e., although 
not required the evaluation is often present. 
Furthermore, the objective truth of the events 
is not important. We will also annotate polarity 
and intensity of the evaluation (Wiebe et al 
2005). 
? Conversational narrative is context-dependent, 
i.e., dependent upon the audience and the sit-
uation in which it is told. We will also annotate 
features of the social context such as the age, 
gender, and relationship of the conversational 
participants. 
? There are culture-specific properties that make 
a story tellable. We will annotate the recurrent 
cultural themes in the corpus informed by pre-
vious studies of narrative themes as in, e.g., 
(Polanyi 1985; Shenk et al 2002).   
 
Although the above characteristics were derived 
from studies of narrative in other populations than 
in speakers with DAT, there is preliminary evi-
dence of their applicability to ASSIST. For exam-
ple, by examining retellings of the same stories 
over time, Davis and Maclagan (2009) found that 
?With AD story-tellers, components vanish from 
surface retellings, particularly the ab-
stract/orientation. Instead, the listener is presented 
with parts of the story?s complicating action or an 
evaluative comment that includes a fragment of the 
complication and its result?; yet, ?even when full 
stories are not retrieved ? the emotion is still con-
veyed to the listener? (p. 152). Comparing life-
history narratives of two rural American older 
women, one with dementia and one without, Shenk 
et al (2002, p. 410) found similar ?major themes 
that are consistent with rural American cultural 
values?, e.g., strong family ties, hard work, and 
religious faith.  
 
Based on analysis of the stories in the CCC, we 
plan to define a set of abstract narrative schemas. 
A schema will include constraints on tellability 
with respect to audience characteristics (e.g., age, 
gender, social relationship) and current topic, and a 
specification of narrative goals (e.g. present the 
Storyteller as having been hard-working and 
thrifty). Each schema will be structured according 
to Labov?s elements of a well-formed narrative. 
The schemas will be derived by analysis of the 
CCC corpus and informed by previous studies of 
narrative themes. 
 
In addition to analysis of features suggested by 
previous narrative studies, we will analyze occur-
rences of pragmatic features that may be used by a 
speaker with DAT to compensate for difficulties 
when telling a story. For example, Davis and 
Maclagan (2009) studied both  how use of unfilled 
pauses and pauses with fillers (e.g., ?oh?, ?um?, or 
a formulaic phrase) changed over time in DAT 
discourse, and also the placement of filled and un-
filled pauses with respect to narrative components. 
Pauses in earlier stages of DAT correlated with 
word-finding problems, while pauses in later stag-
es marked narrative components. Thus, Davis and 
Maclagan hypothesize that pauses in the later stag-
es correlate with search for the next component of 
the story. Also, the Facilitator?s contribution to the 
co-constructed narrative will be analyzed, e.g., 
when the Facilitator invites the Storyteller to begin 
a particular story and responds appropriately to an 
element supplied by the Storyteller. Development 
of the computational model for the Dia-
logue/StoryManager requires consideration of both 
the narrative structure and these related pragmatic 
and affective features. 
4.2 Natural Language Understanding (NLU)  
A skilled Facilitator tries to anticipate the kinds of 
problems that a Storyteller with DAT might have 
in a conversation and provide appropriate support 
so that the frequency and severity of DAT-related 
disfluencies will be reduced. In the event that a 
disfluency does occur, the Facilitator tries to pro-
vide support either by trying to resolve the particu-
lar kind of disfluency via a direct or indirect repair 
41
or by trying to advance the story without necessari-
ly resolving the disfluency. Therefore, in order for 
ASSIST to facilitate conversation between a Story-
teller and his or her conversational partner, the 
NLU module must be able to listen to a conversa-
tion and be able to determine the following: (1) 
How fluent was the Storyteller in the prior utter-
ances? (2) If the Storyteller exhibited any issues 
with fluency, what was the nature of the problems? 
(3) What conversational strategies did the Facilita-
tor use to help alleviate issues related to fluency, if 
any, before, during or after the Storyteller?s utter-
ances? Addressing these questions requires an 
analysis of the Carolina Conversations Collection 
(CCC) as discussed below. 
Fluency 
Considerable research has investigated the lan-
guage of individuals with DAT (Bucks et al 2000; 
Martin and Fedio 1983; Phillips et al 1996; Sabat 
1994). Linguistic features such as long pauses, re-
starts, repetitions, unfinished sentences, pronomi-
nal reference mistakes, and filler phrases are 
prevalent in the spontaneous speech of persons 
with DAT. Further, research has shown deviations 
from the norm in syntactic measurements such as 
part-of-speech rates (nouns, verbs, adjectives, pro-
nouns), richness of vocabulary (Type Token Ratio, 
Brunet?s Index, Honore?s Statistic), and semantic 
cohesion in text (Singh and Bookless 1997).   It is 
necessary to analyze the CCC corpus to determine 
the statistical prevalence of these phenomena with-
in the corpus with a goal of making predictions 
about the relative fluency of an utterance based on 
the presence or dearth of these measurements.    
Conversational Repair Strategies 
Once we have a calculation for the level of fluency 
of each turn that a person with DAT (the Storytell-
er) takes in the dialog, we can then look at the sur-
rounding behavior of the Facilitator.    One of our 
hypotheses is that there are certain strategies that 
will be beneficial in increasing the fluency of DAT 
utterances. For example, narrative co-construction 
techniques recommended for caregivers of persons 
with DAT (Moore and Davis 2002) will be anno-
tated in the corpus, including two-syllable go-
ahead phrases (e.g., ?uh huh?, ?really?, ?ok?), par-
aphrases and repetitions, and indirect questions. 
Most of these strategies can be described as  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3. An excerpt from Davis (2005, p. 141) of a 
conversation between GM, a person with early moderate 
DAT, and her skilled conversational partner BD. 
 
grounding acts (Clark and Schaefer 1989). The 
following seven types of grounding acts occur in 
co-constructed narratives:  
 
? Continued attention.  These utterances, such 
as ?That?s right? (line 2 in Figure 1), indicate 
that the listener is paying attention to the 
speaker. 
? Relevant next contribution.  By these utter-
ances, which we call forward grounding 
moves, the conversational participant contin-
ues the conversation with a question or com-
ment that requires that he or she understood 
the previous speaker?s utterance (e.g. lines 2, 
4, and 8 in Figure 3). 
? Acknowledgement.  In addition to showing 
continued attention, these utterances provide 
an assessment, e.g. ?wow? (line 11 in Figure 
1).  
? Demonstration.  The conversational partici-
pant paraphrases a previous utterance of his 
own or of the other participants (e.g. line 4 of 
Fig. 3). 
? Display.  The listener repeats all or part of the 
previous utterance verbatim (e.g. line 6 in Fig-
ure 3). 
1. BD:  You were telling me about your hus-
band. 
2. Did he preach sermons? 
3. GM:  My husband? 
4. BD: Would he be a preacher? 
5. GM: Yes. He was a preacher that preached 
?hell hot and heaven beautiful!?  
(They both laugh.) 
6. BD: Heaven beautiful ? 
7. GM:  Yes. ?Hell hot and heaven beautiful!? 
That was one of his messages. I don?t  
know? he preached all right. He was 
an Evangelistic-type preacher. 
8. BD: I bet you went many places! 
9. GM: Well, I had my family while I was 
young and couldn?t go. I mean ? you can?t 
go with a bunch of little kids. 
10. BD: No you can?t. 
42
? Completion. The conversational participant 
completes the utterance of the previous speak-
er. 
? Request for repair. The listener indicates that 
he or she did not understand all or part of the 
previous utterance (e.g. line 3 in Figure 3). 
 
The first five types are described in Clark and 
Schaefer (1989) while Completion and Request for 
Repair have been described in Traum (1994) and 
elsewhere. Of particular importance is the use of 
the Relevant next contribution or forward ground-
ing move. Persons with DAT have difficulty with 
lexical retrieval and other memory tasks associated 
with generating language (Martin and Fedio 1983). 
An effective Facilitator will provide lexical prim-
ing and syntactic structures to help these memory 
tasks (Ramanathan 1997; Orange 2001).   
 
Unlike previous research on techniques for auto-
matic grading of children?s written stories (e.g. 
Halpin et al 2004), the contributions of the partner 
with DAT will not necessarily be counted as dis-
fluent when details are missing, incorrect, or pre-
sented out of temporal sequence. As discussed pre- 
viously, in conversation with people with DAT 
narrative elements are often missing and a narra-
tive may consist of as little as a fragment of the 
complicating action and the evaluation. The Facili-
tator?s role is not to correct inaccuracies, to de-
mand clarification, or to tell the story for the 
Storyteller. For example, suppose the Storyteller 
said, "I uh used to have a farm there." Suppose that 
the word "there" is not something that the Facilita-
tor can resolve based on the context of the conver-
sation. So, from the Facilitator's point of view, to 
understand the story better, it might make sense to 
resolve the word "there" by asking, "Where was 
your farm?" However, a more appropriate response 
would be a grounding move that prompts the con-
tinuation of the story without asking a wh-
question: "Really? You were a farmer?" 
 
By analyzing the CCC corpus, we can determine 
the prevalence of the above grounding actions by 
the Facilitator. Based on the fluency of the Story-
teller?s subsequent utterances, we can determine 
the relative effectiveness of these strategies on in-
creasing or decreasing Storyteller fluency. This 
analysis can be further refined by examining the 
types of disfluency exhibited by the Storyteller 
before and after these grounding actions. In turn, 
this data can be used to make predictions about 
what repair strategies a conversational participant 
might use in response to a particular type of disflu-
ent utterance. Based on the analysis techniques 
presented in Cherney et. al. (1998), we will be able 
to examine the extent to which greater fluency in 
the Storyteller utterances leads to more complete 
and coherent narrative.  This anaylsis is also used 
in the development of the NLG/Coach module as 
described below. 
 
4.3 NLG/Coach 
Based upon the current discourse state and the 
suggested dialogue acts provided by the Dia-
logue/Story Manager, the NLG/Coach component 
must choose one or more Facilitator acts and real-
ize them.  The coaching model will be based upon 
empirical studies of the CCC of effective repair 
strategies for conversing with persons with AD, as 
well as a study of particular syntactic forms used 
with specific strategies.  This analysis makes great 
use of the necessary analysis about fluency and 
especially conversational repair strategies de-
scribed in the previous section about NLU. 
5 Summary 
Co-constructed narrative between a person with 
DAT, and a skilled conversational partner offers a 
means by which persons with DAT and their care-
givers may improve their social interaction and life 
satisfaction.  Assistive technology can play a role 
in enabling even an unskilled conversational part-
ner in maintaining the flow of the conversation.  
This paper presents an architecture for such a sys-
tem, ASSIST, and describes how analysis of an 
existing corpus, the Carolinas Conversation Col-
lection (CCC), can inform the development of the 
computational model for co-constructed narrative 
in ASSIST.  We have begun preliminary analysis 
of excerpts from the CCC. 
Acknowledgments 
We gratefully acknowledge many years of encour-
agement and guidance from Dr. Boyd Davis, UNC 
Charlotte.    
43
References  
Allen, M., McGrenere, J., and Purves, B. (2008). The 
Field Evaluation of a Mobile Digital Image Communi-
cation Application Designed for People with Aphasia. 
ACM Transactions on Accessible Computing, Vol. 1, 
No. 1, Article 5. 
 
Alm N., Dye, R., Gowans, G., Campbell, J., Astell, A. 
and Ellis, M. (2007). A communication support system 
for older people with dementia. IEEE Computer, May 
2007: 35-41. 
 
Alzheimer?s Association. (2009). 2009 Alzheimer?s 
Disease Facts and Figures. Downloaded on 4/30/09 
from www.alz.org. 
 
Astell, A.J. et al (2010). Using a touch screen computer 
to support relationships between people with dementia 
and caregivers. Interacting with Computers. 
 
Bamberg, M. and Georgakopoulou, A. (2008). Small 
stories as a new perspective in narrative and identity 
analysis. Text and Talk 28(3): 377-396. 
 
Bourgeois, M.S., Dijkstra, K., Burgio, L.D., and Allen, 
R.S. (2004). Communication Skills Training for Nurs-
ing Aides of Residents with Dementia: The Impact of 
Measuring Performance. Clinical Gerontologist, Vol. 
27(1/2) 2004, 119-138. 
 
Bucks, R., Singh, S., Cuerden, J.M., and G. Wilcock. 
(2000). Analysis of spontaneous, conversational speech 
in dementia of Alzheimer type: Evaluation of an objec-
tive technique for analyzing lexical performance, Apha-
siology, vol. 14, no. 1, pp. 71-91. 
 
Burgio, L.D., Allen-Burge, R., Roth, D.L., Bourgeois, 
M.S., Dijkstra, K., Gerstle, J., Jackson, E. and Bankes-
ter, L. (2001). Come talk with me: Improving commu-
nication between nursing assistants and nursing home 
residents during care routines. The Gerontologist 41: 
449-460. 
 
Burnside, I. (1996). Life Review and Reminiscence in 
Nursing Practice. In Aging and Biography: Explorations 
in Adult Development, Birren et al (Eds.), Springer. 
 
Callaway, C. (2000). Narrative Prose Generation. Ph.D. 
thesis, North Carolina State University, Raleigh, NC.  
 
Cassell, J. (2004). Towards a model of technology and 
literacy development: Story listening systems. Applied 
Developmental Psychology 25: 75-105. 
 
Cheepen, C. (1988). The predictability of informal con-
versation. Oxford: Printer Publishers Ltd.  
 
Cherney, L.R., Shadden, B.B., and Coelho, C.A. (1998). 
Analyzing Discourse in Communicatively Impaired 
Adults. Aspen Publishers, Inc., Gaithersburg, Maryland. 
 
Clark, H. H. and Schaefer, E.F.. Contributing to dis-
course. (1989). Cognitive Science, 13:259?294. 
 
Coelho, C.A. (1998). Analysis of Story Grammar. In 
Cherney, L.R., Shadden, B.B., and Coelho, C.A. Ana-
lyzing Discourse in Communicatively Impaired Adults. 
Aspen Publishers, Inc., Gaithersburg, Maryland. 
 
Cohene, T., Baecker, R., and Marziali, E.  Designing 
Interactive Life Story Multimedia for a Family Affected 
by Alzheimer?s Disease: A Case Study. CHI 2005, April 
2?7, 2005, Portland, Oregon, USA., p.1300-1303. 
 
Cosley, D., Akey, K., Alson, B., Baxter, J., Broomfield, 
M., Lee, S., and Sarabu, C. (2009). Using Technologies 
to Support Reminiscence. HCI 2009 ? People and Com-
puters XXIII ? Celebrating people and technology, 480-
484 
 
Damianakis, T., Crete-Nishihata, Smith, K., Baecker, 
R.M., and Marziali, E. (2010). The psychosocial im-
pacts of multimedia biographies on persons with cogni-
tive impairments. The Gerontologist 50(1): 23-35. 
 
Davis, B.H. (Ed.) (2005). Alzheimer talk, text and con-
text: Enhancing communication. New York: Palgrave 
Macmillan. 
 
Davis, B.H. (2010). Intentional stance and Lucinda 
Greystone. In V. Ramanathan and P. McPherron, eds. 
Language, Bodies and Health. NY: Continuum. 
 
Davis, B.H. and Maclagan, M. (2009). Examining paus-
es in Alzheimer?s discourse. American Journal of Alz-
heimer?s Disease and Other Dementias 24, 141-154. 
 
Davis, B.H. and Pope, C. (2009). Institutionalized 
ghosting: policy contexts and language use in erasing 
the person with Alzheimer?s. Language Policy. Online 
First DOI 10.1007/s10993-009-9153-8.  
 
Davis, B.H. and Smith, M. (2009). Infusing cultural 
competence training into the curriculum: Describing the 
development of culturally sensitive dementia care com-
munication. Kaohsiung Journal of Medical Sciences 25, 
503-510. 
 
Dijkstra, K., Bourgeois, M., Allen, R.,  and Burgio, L. 
(2004). Conversational coherence: discourse analysis of 
44
older adults with and without dementia. Journal of Neu-
rolinguistics 17: 263-283. 
 
Elson, D.K. and McKeown, K.R. (2009). Extending and 
Evaluating a Platform for Story Understanding. AAAI 
2009 Spring Symposium on Intelligent Narrative Tech-
nologies II. 
 
Georgakopoulou, A. and Goutsos, D. (1997). Discourse 
Analysis: An Introduction. Edinburgh: Edinburgh Uni-
versity Press. 
 
Green, N. (2002). A Virtual World for Coaching Care-
givers of Persons with Alzheimer's Disease.  Papers 
from the AAAI Workshop on Automation as Caregiver: 
The Role of Intelligent Technology in Elder Care.  
AAAI Press, Menlo Park, CA, pp. 18-23. 
 
Green, N. (2005). Simulating Alzheimer's discourse for 
caregiver training in artificial intelligence-based dia-
logue systems. In Davis, Boyd H. (ed.). Alzheimer talk, 
text and context: enhancing communication. New York, 
NY: Palgrave Macmillan, 2005, 199-207. 
 
Green, N and Bevan, C. (2009). Efficacy of Active Par-
ticipation in  Conversation with a Virtual Patient with 
Alzheimer's Disease. Papers from 2009 AAAI Fall  
Symposium: Virtual Healthcare Interaction, Arlington, 
Virginia from November 5- 7,2009. 
 
Green, N. and B. Davis.  (2003). Dialogue Generation in 
an Assistive Conversation Skills Training System  for 
Caregivers of Persons with Alzheimer's Disease. In Pa-
pers from the 2003 AAAI  Spring Symposium on Natu-
ral Language Generation in Spoken and Written 
Dialogue, pp. 36-43. 
 
Green, N, Lawton, W., and Davis, B. (2004). An Assis-
tive Conversation Skills Training System for Caregivers 
of Persons with Alzheimer's Disease. In Proceedings of 
the AAAI 2004 Fall Symposium on Dialogue Systems for 
Health Communication. 
 
Guendouzi, J. and Muller, N. (2006). Approaches to 
discourse in dementia. Mahwah, NJ: Lawrence Erl-
baum. 
 
Halpin, H., Moore, J.D., and Robertson,J. (2004). Au-
tomatic Analysis of Plot for Story Rewriting. Proceed-
ings of Empirical Methods in Natural Language 
Processing. 
 
Herv?s, R., Pereira, F., Gerv?s, P., andCardoso, A. 
(2006) Cross-domain analogy in automated text genera-
tion, Proc. of the Third joint workshop on Computation-
al Creativity, ECAI?06, Trento, Italy.  
 
Hsieh, H.F. Effect of reminiscence therapy on depres-
sion in older adults: a systematic review. (2003). Inter-
national Journal of Nursing Studies, 40(4):335?345. 
 
Irvine, A.B., Ary, D.V., and Bourgeois, M.S. (2003). An 
Interactive Multimedia Program to Train Professional 
Caregivers. Journal of Applied Gerontology 22(2), June 
2003, 269-288. 
 
Labov, W. (1972). Language in the inner city. Philadel-
phia: University of Pennsylvania Press. 
 
Lenchuk, I. and M. Swain. (2010). Alise?s small stories: 
indices of identity construction and of resistance to the 
discourse of cognitive impairment. Language Policy : 9-
28. 
 
Martin, A. and P. Fedio, (1983). Word production and 
comprehension in Alzheimer's disease: The breakdown 
of semantic knowledge, Brain and Language, Volume 
19, Issue 1, May 1983, Pages 124-141. 
 
Massimi, M., Berry, E., Browne, G., Smyth, G., Wat-
son, P., and Baecker, R. M. (2008). Neuropsychological 
Rehabilitation 18(5-6): 742-765. 
 
McCallion, P., Toseland, R.W., Lacey, D., and  Banks, 
S. (1999). Educating nursing assistants to communicate 
more effectively with nursing home residents with de-
mentia. The Gerontologist 39(5): 546-558. 
 
Moore, L. & B. Davis. (2002) Quilting narrative: using 
repetition techniques to help elderly communicators. 
Geriatric Nursing, 23(5):262-6. 
 
Orange, J. B. (2001). Family caregivers, communica-
tion, and Alzheimer's disease. In M. L. Hummert & J. F. 
Nussbaum (Eds.), Aging communication, and health: 
Linking research and practice for successful aging (pp. 
225-248). Mahwah, NJ: Lawrence Eribaum Associates, 
Inc. 
 
Passonneau,R., Goodkind, A., and Levy, E. (2007). An-
notation of children?s oral narrations: Modeling emer-
gent narrative skills for computational applications. 
Proceedings of the 20th Annual Meeting of the Florida 
Artificial Intelligence Research Society (FLAIRS-20). 
 
Petrelli, D., van den Hoven, E., and Whittaker, S. 
(2009). Making history: Intentional capture of future 
memories. CHI 2009, April 4-9, 2009, Boston, MA. pp. 
1723-1732. 
 
Phillips, L., Sala, S.D. and C. Trivelli. (1996). Fluency 
deficits in patients with Alzheimer's disease and frontal 
45
lobe lesions, European Journal of Neurology, vol. 3, pp. 
102.108. 
 
Piwek, P. and S. Stoyanchev (2010). Generating Ex-
pository Dialogue from Monologue: Motivation, Corpus 
and Preliminary Rules. NAACL HLT 2010. 
 
Polanyi , L. (1985). Telling the American Story: A 
Structural and Cultural Analysis of Conversational Sto-
rytelling. Norwood, NJ: Ablex. 
 
Polkinghorne, D.E. (1996). Narrative Knowing and the 
Study of Lives. In Aging and biography: explorations in 
adult development, Birren, J.E., Kenyon, G.M., Ruth, J., 
Schroots, J.J.F., and Svensson, T. (Eds.), Springer. 
 
Pope, C. and Davis, B.H. (2011). Finding a balance: 
The Carolinas Conversation Collection. Corpus Linguis-
tics and Linguistic Theory 7-1, 143-161. 
 
Ramanathan V. (1997).  Alzheimer Discourse: Some 
Sociolinguistic Dimensions. Mahwah, NJ: Lawrence 
Erlbaum. 
 
Ripich, D.N., Ziol, E., and Lee, M.M. (1998). Longitu-
dinal Effects of Communication Training on Caregivers 
of Persons with Alzheimer's Disease. Clinical Geron-
tologist 19(2): 37-55. 
  
Roark, B., Fowler, A., Sproat, R., Gibbons, C., and 
Fried-Oken, M. 2011. Towards technology-assisted co-
construction with communication partners. Proceedings 
of the 2nd Workshop on Speech and Language Pro-
cessing for Assistive Technologies. pp. 22-31. 
 
Ryokai, K., Vaucelle, C. and Cassell, J. 2003. Virtual 
peers as partners in storytelling and literacy learning. 
Journal of Computer Assisted Learning, 19(2), 195-208. 
 
Sabat, S. (1994). Language function in Alzheimer's dis-
ease: a critical review of selected literature, Language 
and Communication, vol. 14, pp. 331-351. 
 
Santo Pietro, Mary Jo and Ostuni, Elizabeth. (2003). 
Successful Communication with Persons with Alz-
heimer?s Disease, An In-Service Manual, 2nd ed., But-
terworth Heinemann, St. Louis, Missouri. 
 
Shenk, D., Davis, B., Peacock, J. and  L.  Moore. 
(2002). Narratives and self-identity in later life: Two 
rural American older women, Journal of Aging Studies, 
Volume 16, Issue 4, November 2002, Pages 401-413. 
 
Singh, S. and T. Bookless. (1997).Analyzing Spontane-
ous Speech in Dysphasic Adults, International Journal 
of Applied Linguistics, vol. 7.2, no. 2, pp. 165-182. 
 
Smith, J. (2000). GrandChair: Conversational collec-
tion of family stories. Media Arts and Sciences. Un-
published master?s thesis, MIT, Cambridge, MA. 
 
Smith, K.L., Crete-Nishihata, M., Damianakis, T., 
Baecker,R.M., and Marziali, E. (2009). Multimedia 
biographies: a reminiscence and social stimulus tool for 
persons with cognitive impairment. Journal of 
Technology in Human Services, 27(4): 287-306. 
 
Smith, M., Davis B., et al (2010). Twelve important 
minutes: Introducing enhanced online materials about 
elder abuse to Nursing Assistants. Journal of 
Continuing Education for Nursing. 
 
Theune, M., Slabbers, N., and Hielkema, F. (2007). The 
Narrator: NLG for digital storytelling. Proc ENLG 07, 
109-112. 
 
Traum, D. R.  (1994). A Computational Theory of 
Grounding in Natural Language Conversation. PhD 
thesis, Department of Computer Science, University of 
Rochester, Also available as TR 545, Department of 
Computer Science, University of Rochester. 
 
Waller, A. (2006). Communication Access to Conversa-
tional Narrative. Topics in Language Disorders 26(3): 
221-239. 
 
Wiebe, J., Wilson, T., and Cardie, C. (2005). Annotat-
ing expressions of opinions and emotions in language, 
Language Resources and Evaluation, 1(2): 165-210. 
 
 
Woods, B., Spector, A., Jones, C.,  Orrell,M., and Da-
vies, S. (2005). Reminiscence therapy for demen-
tia.Cochrane Database of Systematic Reviews.  
 
46
Proceedings of the First Workshop on Argumentation Mining, pages 11?18,
Baltimore, Maryland USA, June 26, 2014. c?2014 Association for Computational Linguistics
Towards Creation of a Corpus for Argumentation Mining                                  
the Biomedical Genetics Research Literature 
 
 
 Nancy L. Green 
Dept. of Computer Science 
U. of N. Carolina Greensboro 
Greensboro, NC 27402, USA 
nlgreen@uncg.edu 
 
 
  
 
Abstract  
Argumentation mining involves automat-
ically identifying the premises, conclu-
sion, and type of each argument as well 
as relationships between pairs of argu-
ments in a document. We describe our 
plan to create a corpus from the biomedi-
cal genetics research literature, annotated 
to support argumentation mining re-
search. We discuss the argumentation el-
ements to be annotated, theoretical chal-
lenges, and practical issues in creating 
such a corpus. 
1 Introduction 
Argumentation mining is a relatively new chal-
lenge in corpus-based discourse analysis that in-
volves automatically identifying argumentation 
within a document, i.e., the premises, conclusion, 
and type of each argument, as well as relation-
ships between pairs of arguments in the docu-
ment. To date, researchers have investigated 
methods for argumentation mining of non-
scientific text and dialogue. However, the lack of 
appropriately annotated corpora has hindered 
research on argumentation mining of scientific 
research articles. Using the term ?argument? in a 
related but different sense than here, researchers 
have investigated annotation of scientific ab-
stracts and full-text articles (e.g. Teufel, 2002; 
Mizuta et al., 2005; Liakata et al., 2012). How-
ever, the annotated corpora they have created are 
not designed for argumentation mining in the 
above sense.   
   Our goal is to create a freely available corpus 
of open-access, full-text scientific articles from 
the biomedical genetics research literature, anno-
tated to support argumentation mining research. 
The corpus also would provide a rich new re-
source for researchers in related areas including 
information retrieval, information extraction, 
summarization, and question-answering. There is 
a critical need for automated analysis of the rap-
idly growing genetics research literature. Availa-
bility of the corpus should promote the develop-
ment of computational tools for use by biomedi-
cal and genetics researchers. In the future, e.g., a 
tool enabled by argumentation mining could be 
used to automatically summarize arguments in 
the research literature that a certain genetic muta-
tion is a cause of breast cancer.  Methods devel-
oped from experimentation with this corpus 
should be adaptable to other scientific domains 
as well. 
Section 2 of this paper discusses some terms 
from argumentation theory that are relevant to 
our goals and surveys related work. Section 3 
discusses examples of argumentation in the tar-
get literature. The next three sections discuss 
challenges, practical issues, and future plans for 
creating the corpus. 
2 Background 
2.1 Argumentation Theory  
Traditionally, an argument is said to consist of a 
set of premises and a conclusion, and a formal 
model such as deductive logic is used to deter-
mine whether the argument is valid. An argu-
ment can be attacked by refuting a premise or by 
presenting an argument for a conclusion in con-
tradiction to the original conclusion. However 
Toulmin (1998), who was concerned with mod-
eling arguments in fields such as law and sci-
ence, argued that logical validity is too restrictive 
a criterion for determining argument acceptabil-
ity. Toulmin distinguished two types of premis-
11
es: data, i.e., observations or conclusions of oth-
er arguments, and warrant, i.e., a field-
dependent accepted principle (such as a legal 
rule or a ?law? of science).  
    Argumentation schemes are abstract descrip-
tions of forms of argument that are used to con-
struct acceptable arguments in everyday conver-
sation, law, and science (Walton et al., 2008). 
Argumentation schemes may describe non-
deductively valid arguments, and their conclu-
sions may be retracted when more information is 
obtained. For example, an abductive argumenta-
tion scheme, often used in genetic counseling 
(Green et al., 2011), is reasoning from observa-
tions to a hypothesized cause. Critical questions 
associated with argumentation schemes play an 
important role in evaluating argument acceptabil-
ity (Walton et al., 2008). For example, one of the 
critical questions of the abductive argumentation 
scheme is whether there is an alternative, more 
plausible explanation for the observation used as 
a premise.  An enthymeme is an argument with 
implicit premises or conclusion. Argumentation 
schemes are sometimes useful in reconstruction 
of missing components of enthymemes. 
2.2 Argumentation Corpora  
A corpus of genetic counseling patient letters 
was analyzed in several ways to design a compu-
tational model for generation of arguments from 
healthcare experts to patients (Green et al., 
2011). An annotation scheme was developed to 
describe the conceptual model of genetic disease 
and inheritance communicated to patients 
(Green, 2005a). Formal argumentation schemes 
describing arguments found in the corpus were 
defined (Green et al., 2011). Analyses of prag-
matic features included rhetorical relations 
(Green, 2010a), ordering constraints and dis-
course markers (Green et al., 2011), point of 
view (Green 2005b), and use of probability ex-
pressions (Green 2010b). However, it was not a 
goal of that project to provide a publicly availa-
ble corpus.       
   The Araucaria argumentation diagramming 
tool was developed to aid human analysts and 
students to visualize and annotate naturally oc-
curring arguments (Reed and Rowe, 2004). Dia-
grams can be stored as text files with stand-off 
annotation of premises and conclusions, argu-
mentation schemes, and relationships between 
arguments. The Araucaria project has created a 
publicly available corpus of annotated argumen-
tation from newspaper articles, parliamentary 
records, magazines, and on-line discussion 
boards (Reed et al., 2010). The corpus has been 
used in some argumentation mining research 
(Mochales and Moens, 2011; Feng and Hirst, 
2011; Cabrio and Villata, 2012).  
2.3 Argumentation Mining  
To date, researchers have investigated methods 
for argumentation mining of non-science con-
tent: legal documents (Mochales and Moens, 
2011; Bach et al., 2013; Ashley and Walker, 
2013; Wyner et al., 2010), on-line debates (Cab-
rio and Villata, 2012), product reviews (Villalba 
and Saint-Dizier, 2012; Wyner et al., 2012), and 
newspaper articles and court cases (Feng and 
Hirst, 2011). Here we summarize the work that is 
most relevant to our project. 
   Mochales and Moens (2011) experimented 
with the Araucaria corpus and a legal corpus.  
They developed a multi-stage approach to argu-
mentation mining. The first stage, argumentative 
information detection, addresses the problem of 
classifying a sentence (or sentential subunit) as 
being part of an argument or not. Next, argument 
boundary detection, or segmentation, is the prob-
lem of determining the boundaries of each argu-
ment. Third, argumentative proposition classifi-
cation labels the sentences in an argument ac-
cording to their role as a premise or the conclu-
sion. Lastly, argumentation structure detection is 
the problem of detecting the relationships be-
tween arguments, i.e., whether two atomic argu-
ments are ?chained? (the conclusion of one is a 
premise of another), whether multiple arguments 
are provided in support of the same conclusion, 
and whether one argument attacks another argu-
ment in some way. Statistical techniques were 
used for the first three stages, while manually 
constructed context-free grammar rules were 
used for argumentation structure detection. 
    Cabrio and Villata (2012) used an approach to 
argumentation structure detection based on cal-
culating textual entailment (Dagan 2006) to de-
tect support and attack relations between argu-
ments in a corpus of on-line dialogues stating 
user opinions.  
   Feng and Hirst (2011) focused on the problem 
of argumentation scheme recognition in the Ar-
aucaria corpus. Assuming that the conclusion 
and premises of an argument have been identi-
fied already, classification techniques achieved 
high accuracy for two argumentation schemes 
described in (Walton et al., 2008), argument 
from example and practical reasoning. Those 
schemes are less likely to be useful in analysis of 
scientific texts however. 
12
   In fact, since scientific research articles sub-
stantially differ from the genres that have been 
explored for argumentation mining so far, it is an 
open question what techniques will be successful 
in the scientific literature.   
 
2.4 Argumentative Zoning and Related 
Annotation Schemes   
Some NLP researchers have studied ways to au-
tomatically identify discourse structure in scien-
tific text. The motivation is to provide contextual 
information that will improve automatic infor-
mation access without the need to represent or 
reason about domain knowledge (Teufel, 2010). 
These researchers have developed several anno-
tation schemes.  
    The argumentative zoning (AZ) annotation 
scheme was developed for automatically classi-
fying the sentences of a scientific article in terms 
of their contribution of new knowledge to a field 
(Teufel and Moens, 2002; Teufel, 2010).  Ap-
plied to articles in computational linguistics, AZ 
labels ?zones? or variable-length sequences of 
sentences with one of seven categories:  AIM 
(the research goal of the article), BASIS (the 
contribution of existing knowledge to a 
knowledge claim of the article), CONTRAST 
(criticizing or negatively contrasting competi-
tors? knowledge claims to a knowledge claim of 
the article), TEXTUAL (indicating the structure 
of the article), BACKGROUND (generally ac-
cepted background knowledge), OTHER (exist-
ing knowledge claims), and OWN (describing 
any aspect of a new knowledge claim made by 
the authors).  
   An extension of AZ (AZ-II) developed for ap-
plication to chemistry articles, refined AZ?s dis-
tinctions into fifteen categories (Teufel, 2010). In 
another extension of AZ developed for genetics 
articles (Mizuta et al., 2005), the AZ OWN cate-
gory was replaced by categories distinguishing 
descriptions of methodology (MTH), experi-
mental results (RSL), insights from experimental 
results or previous work (INS), and implications 
(such as conjectures and applications) of experi-
mental results or previous work (IMP).   
    The CoreSC (Core Scientific Concepts) anno-
tation scheme was developed for automatic clas-
sification of sentences in terms of the compo-
nents of a scientific investigation: Hypothesis, 
Motivation, Goal, Object, Background, Method, 
Experiment, Model, Observation, Result and 
Conclusion (Liakata et al., 2012a). An automatic 
classifier for CoreSC was developed and evalu-
ated on a corpus of 265 full-text articles in bio-
chemistry and chemistry. A comparison study 
(Liakata et al., 2012b) in which articles were an-
notated with both AZ-II and CoreSC ?found that 
CoreSC provides finer granularity ? while the 
strength of AZ-II lies in detecting the attribution 
of knowledge claims and identifying the different 
functions of background information? (Liakata et 
al. 2012b, p. 45). Liakata et al. (2012b) com-
pared CoreSC to two other scientific discourse 
annotation schemes (Thompson et al., 2011; De 
Waard and Pander Maat, 2009). The three 
schemes were found to be complementary, oper-
ating at different levels of granularity.     
    However, none of the above annotation 
schemes address argumentation as described in 
section 2.3. They are not designed to identify the 
premises and conclusion of each argument (in-
cluding missing components of enthymemes) 
and the argumentation scheme, nor relationships 
between pairs of arguments. Nevertheless, we 
plan to coordinate our efforts with that research 
community to benefit from their expertise and to 
ensure that our corpus will ultimately provide a 
valuable resource for their research.    
3 Examples 
In this section we discuss examples of some of 
the arguments in an article (Schrauwen et al., 
2012) that is representative of the articles to be 
included in the corpus. The main claim of this 
article is that a c.637+1G>T mutation of the 
CABP2 gene in the region 11q12.3-11q13.3 
(DFNB93) is a cause of autosomal recessive 
non-syndromic hearing loss (arNSHL) in hu-
mans. The article?s body is divided into four sec-
tions: Introduction, Material and Methods, Re-
sults, and Discussion. The following examples in 
Table 1 are from the first subsection of the Re-
sults section (under the subheading ?Next-
Generation Sequencing of the DFNB93 Region 
Identifies a Splice-Site Mutation in CABP2?). 
The excerpt has been manually segmented into 
regions of text conveying arguments. Adjacent 
segments not conveying arguments have been 
omitted to save space; the approximate number 
of omitted lines is given in square brackets. Also, 
for readability, alternative identifiers of genetic 
variants have been replaced by ellipses. 
 
 
 
 
 
13
1 ?The DFNB93 region contains more than 
300 annotated and hypothetical genes, 
and several genes are expressed in the 
mouse and human inner ear. Because 
there are many strong candidate genes in 
the region, we sequenced all genes and 
noncoding genes in this region by using 
a custom DNA capture array to identify 
the disease-causing mutation in one af-
fected individual from the family. 
 [skip next 5 lines] 
2 ?After the identified homozygous vari-
ants were filtered through the 1000 Ge-
nomes Project November 2010 release 
and dbSNP131, 47 previously unreported 
variants remained and included two exo-
nic mutations, one splicing mutation, six 
nontranslated mutations, 16 intergenic 
(downstream or upstream) mutations, 
and 22 intronic mutations. 
3 The two exonic variants included one 
nonsynonymous variant, c.1379A>G ? 
in PPFIA1 ? and synonymous variant 
c.174G>A ? in GAL3ST3 ... The 
splice-site variant, c.637+1G>T ? was 
located at the 5? donor site of intron 6 of 
CABP2 (Figure 1 and Figure S1, availa-
ble online). 
?The variants in PPFIA1 and CABP2 
were subsequently validated by Sanger 
DNA sequencing, which only confirmed 
the splicing variant in CABP2. 
 [skip next 4 lines] 
4 Next, we checked the inheritance of the 
CABP2 variant in the entire Sh10 family 
(Figure 1) and screened an additional 
100 random Iranian controls to ensure 
that the variant is not a frequent poly-
morphism. The mutation was not detect-
ed in any of the controls, and inheritance 
was consistent with hearing loss in the 
family. 
 
Table 1. Excerpt from (Schrauwen et al., 2012) 
 
In an annotation scheme such as AZ, the first 
sentence of segment 1 might be classified as 
BKG (background) and the second as MTH 
(methodology).  In CoreSC, the second sentence 
might be classified as Hypothesis and Method. 
However, the following argument is also com-
municated in (1) to the intended audience of sci-
entists. (A genetics researcher has confirmed our 
interpretation of the arguments in this paper.) 
Note that in the following analyses in our paper, 
square brackets indicate implicit information de-
rivable from the discourse context or domain 
knowledge. In the following argument, two of 
the premises are implicit, i.e., this is an example 
of an enthymeme. Also, premises are distin-
guished as Data or Warrant, where the former 
type of premise corresponds to old or new evi-
dence or a conclusion of another argument in the 
article, and the latter to generally accepted prin-
ciples or assumptions in genetics. It is under-
stood by the intended audience that warrants may 
have exceptions and that the conclusions of the 
following arguments are tentative.  
    Note that the conclusion of Argument 1 has 
been recovered from the phrase there are many 
strong candidate genes in the region. The argu-
ment can be analyzed in terms of a type of ab-
ductive argumentation scheme, i.e., reasoning 
from effect (arNSHL) to plausible cause (a muta-
tion in the DFNB932 region).  For a specification 
of the argumentation schemes identified in the 
genetics paper, see (Green and Schug, in prepa-
ration). 
 
Argument 1:  
Data: Several genes in the DFNB93 region are 
expressed in the human inner ear. 
Data: [arNSHL involves the inner ear] 
Warrant: [If a gene is expressed in a tissue relat-
ed to a genetic condition then a mutation of that 
gene may be a cause of that condition] 
Warrant: [Autosomal recessive genetic condi-
tions are caused by homozygous mutations.]  
Conclusion: A [homozygous] mutation of a gene 
in the DFNB93 region may be a cause of 
arNSHL in humans. 
 
    In an annotation scheme such as AZ, the sub-
ordinate clause at the beginning of segment 2 
might be classified as MTH, and the main clause 
as RSL (results). However it has been analyzed 
in Argument 2 as an instance of an argumenta-
tion scheme involving the elimination of candi-
dates. Note that the identity of the arNSHL-
affected individual whose DNA was tested 
(V:14) and the family to which she belonged (Sh 
10) was not specified in this section, but was 
given in the Material and Methods section. Also 
note that the first premise in Argument 2 is the 
conclusion of the preceding Argument 1. In our 
paper, this is indicated by providing the previous 
argument?s identifier in parentheses. 
   
 
 
14
Argument 2:  
Data: (Argument 1) [A homozygous mutation of 
a gene in the DFNB93 region may be a cause of 
arNSHL in humans] 
Data: [In a DNA sample from one arNSHL-
affected individual, identified as V:14 of family 
Sh10] 47 previously unreported [i.e. not frequent 
polymorphisms] homozygous variant alleles in 
the DFNB93 region were identified.   
Warrant: [If a variant is a frequent polymorphism 
then it is not a cause of a genetic condition] 
Conclusion: [One of the 47 variants may be the 
cause of arNSHL in individual V:14] 
 
   Various clauses in segment 3 might be classi-
fied as MTH or RSL in a scheme such as AZ. In 
an argumentation analysis, however, it conveys 
an argument that the CABP2 mutation may be 
the cause of arNSHL in one individual (:V14), 
after the elimination of the other candidates.  
  
Argument 3  
Data: (Argument 2) [One of the 47 variants may 
be the cause of arNSHL in individual V:14] 
Data: Only splice-site variant c.637+1G>T of 
CABP2 was confirmed. 
Warrant: [Only confirmed exonic or splice-site 
variants may be the cause of arNSHL.] 
Conclusion: [The c.637+1G>T variant of CABP2 
may be the cause of arNSHL in individual V:14] 
 
    Segment 4 uses two different sets of data to 
argue that the c.637+1G>T variant of CABP2 
may be the cause of arNSHL in the family of 
V:14,  Sh10. In a scheme such as AZ, the first 
sentence would probably be described as MTH 
and the second as RSL. However, an argumenta-
tion analysis provides two arguments, 4a and 4b. 
They each support the same conclusion, which is 
not explicitly stated in the text.    
 
Argument 4a 
Data: (Argument 3) [The c.637+1G>T variant of 
CABP2 may be the cause of arNSHL in individ-
ual V:14] 
Data: Inheritance of the variant segregates with 
arNSHL in family Sh10. 
Warrant: [A mutation that is present in one af-
fected family member may be the cause of an 
autosomal recessive genetic condition in the rest 
of the family if the mutation segregates with the 
genetic condition in the family (i.e., the mutation 
is present in all and only the family members 
who have the genetic condition, and the oc-
curence of the condition is consistent with auto-
somal recessive inheritance)] 
Conclusion: [The c.637+1G>T variant of CABP2 
may be the cause of arNSHL in family Sh10] 
 
Argument 4b 
Data: Inheritance of the variant c.637+1G>T of 
CABP2 segregates with arNSHL in family Sh10. 
Data: The variant c.637+1G>T of CABP2 is not 
found in the DNA of a control group of 100 indi-
viduals [who are not in family Sh10 and who are 
not affected with arNSHL] 
Warrant: [If a variant segregates with an autoso-
mal recessive condition in a family but is not 
found in the DNA of a control group of individu-
als who are not affected with the condition, then 
it may be the cause of the condition in that    
family] 
Conclusion: [The c.637+1G>T variant of CABP2 
may be the cause of arNSHL in family Sh10] 
     
    In addition to identifying individual argu-
ments, argumentation mining addresses relation-
ships between pairs of arguments. Arguments 1-
4a illustrate a chain of arguments, i.e., where the 
conclusion of Argument i is a premise of Argu-
ment i+1. Also, arguments 4a and 4b illustrate 
two arguments in support of the same conclu-
sion. Note that, individually, Arguments 1-3 are 
relatively weak. However, Argument 1 might be 
useful in answer to a query such as What regions 
may carry a mutation leading to arNSHL? Ar-
guments 2-3 might be useful in answer to a query 
such as Have any individual cases of arNSHL 
been attributed to a mutation of CABP2? Argu-
ments 1-4a and Argument 4b could be given as 
the answer to the query What mutation may be 
the cause of arNSHL in an affected family? (Note 
that in an interactive query facility, instead of 
presenting the user with a chain of arguments, 
the system could leave it up to the user to ?drill 
down? to see the subarguments in a chain.) 
    The above arguments are provided here for 
purposes of illustration. In the remainder of the 
genetics article the main claim (that the CABP2 
mutation is a cause of arNSHL in humans) is 
supported by arguments that the mutation is the 
cause of arNSHL in two other families. Also, 
using a different type of argumentation, it pro-
vides a biochemical explanation for how the mu-
tation may cause an abnormality in the inner ear 
that could cause hearing loss. In addition to the 
main claim, the article contains several other 
supported claims, e.g., that the c.637+1G>T var-
iant of CABP2 may be a founder mutation. 
15
4 Challenges 
Argumentation mining of this type of discourse 
will be challenging. A challenge that is shared 
with BioNLP text mining in general is dealing 
with the extensive use of biological, chemical, 
and clinical terminology in the BioNLP domain. 
A number of challenges specific to argumenta-
tion mining are discussed next. 
   To specify an argument it is necessary to iden-
tify the premises (or data and warrant), conclu-
sion, and argumentation scheme. However, as 
illustrated in the previous examples, arguments 
with implicit components (enthymemes) are 
common, e.g., where a conclusion is implicit or 
used as an implicit premise of another argument. 
A related challenge is to supply domain 
knowledge for reconstructing implicit warrants 
in this genre. Another related challenge is the 
need to make use of discourse context to supply 
missing information, e.g., where context is re-
quired to supply the identity of individual V:14 
in Argument 2. Note that in that case, it was nec-
essary to read the previous Materials and Meth-
ods section to supply that information. 
    Another problem illustrated in the example is 
that argument boundaries do not coincide with 
sentential subunit boundaries. For example, seg-
ment 4 contains parts of Argument 4a and 4b in 
the first sentence and parts of those two argu-
ments in the second sentence. Furthermore, iden-
tification of argument components does not ap-
pear to be systematically associated with dis-
course markers such as ?therefore?. However, the 
arguments contain lexical items relating to scien-
tific discovery (e.g., ?confirmed?, ?detected?, 
?consistent with?, ?indicate?, ?is likely that?, ?ex-
pected to?, ?showed?, ?suggests?) that may aid in 
automatic identification of the components. 
   Our analysis of argumentation in genetic coun-
seling (Green et al., 2011) and in the genetics 
research literature (Green and Schug, in prepara-
tion) has identified other (and more specific) ar-
gumentation schemes and critical questions than 
those listed in (Walton et al., 2008). Since some 
of the argumentation schemes we have identified 
are causal, lexical patterns of causality may be 
useful features for use in argumentation mining. 
5 Practical Considerations for Creating 
the Corpus 
In order to ensure that the future corpus can be 
freely disseminated, we will select articles from 
journals that are fully open-access, i.e., that are 
published under the Creative Commons attribu-
tion license ?which allows articles to be re-used 
and re-distributed without restriction, as long as 
the original work is correctly cited? 
(http://www.biomedcentral. com.about). To date, 
we have identified the following fully open-
access journals that contain biomedical genetics 
research articles: 
? BMC http://www.biomedcentral.com jour-
nals: BMC Genetics, BMC Genomics, BMC 
Medical Genetics, BMC Medical Genomics 
and BMC Molecular Biology,  
? PLoS http://www.plos.org/ journals: Genet-
ics, Biology, Medicine 
A number of other journals (e.g. American Jour-
nal of Human Genetics), indexed by PubMed 
http://www.pubmedcentral.nih.gov, make a sub-
set of their articles available as open-access. 
   After selecting articles for the corpus, we will 
define and evaluate the intercoder reliability (Ar-
stein and Poesio, 2008) of the following types of 
annotations: 
? Data, warrant, and conclusion and argumen-
tation scheme of each argument,  
? Multiple arguments for the same conclusion, 
and 
? Chained relationships between arguments, 
i.e., where the conclusion of an argument is 
the premise of a subsequent argument. 
Note that we plan to employ graduate students 
with a background in genetics and biochemistry 
as coders.   
   Identifying implicit components of arguments 
will be challenging for coders. However, there 
are a number of constraints that will be given in 
the instructions to help the coders.  First, they 
will be given a list of commonly accepted princi-
ples of genetics as possible warrants, such as 
Mendel?s laws, the concept of segregation in a 
pedigree, etc. Second, coders will be instructed 
to look for chained arguments, i.e., where the 
premises/conclusions of chained arguments can 
be reconstructed from the relationship between 
two arguments. Third, coders will be given a de-
scription of argumentation schemes, which also 
constrain the interpretation of argument compo-
nents.  
   A pilot annotated corpus and associated docu-
mentation of the argumentation coding scheme 
will be made available to other researchers on a 
temporary basis for the purpose of publicizing 
the planned corpus and getting feedback from 
potential stakeholders.   
   An important consideration is the selection of 
corpus annotation tools to facilitate argumenta-
tion mining research. On the one hand, the text 
16
mining community uses linguistic annotation 
tools such as GATE (http://gate.ac.uk/), UIMA 
(http://www.ibm.com/research/uima), and Open-
NLP tools http://opennlp.sourceforge.net). It 
would be advisable to use tools that would allow 
that community to benefit from the argumenta-
tion corpus, as well as to allow argumentation 
mining researchers to use previously developed 
tools. For example, argumentation mining re-
searchers may find it useful to automatically pre-
process the corpus with linguistic annotations as 
well as the annotation schemes described in sec-
tion 2.4. BioNLP researchers may find it useful 
to consider argumentation annotations as well. 
Just as modality and negation currently are used 
for BioNLP tasks, a text segment?s participation 
in argumentation as outlined in this paper may 
provide useful context at a deeper level of analy-
sis.   
   On the other hand, the argumentation and edu-
cational community uses tools for diagramming 
argumentation, e.g.  
Araucaria http://arg.computing.dundee.ac.uk and 
LASAD http://cscwlab.in.tu-clausthal.de/ lasad). 
It is important to maintain compatibility between 
argumentation mining corpora developed with 
linguistic annotation tools and corpora developed 
with diagramming tools. 
6 Conclusion 
This paper described our plan to create a freely 
available corpus of open-access, full-text scien-
tific articles from the biomedical genetics re-
search literature, annotated to support argumen-
tation mining research. It discussed the argumen-
tation elements to be annotated, theoretical chal-
lenges, and practical issues in creating such a 
corpus. We hope this workshop will provide an 
opportunity for us to get feedback from potential 
users (or contributors) to this effort, and possibly 
even identify synergistic research opportunities. 
 
Acknowledgments  
 
We thank Dr. Malcolm Schug of the Biology 
Department of the University of North Carolina 
Greensboro for verifying our interpretation of the 
arguments in the genetics article.  
References  
Artstein, R. and Poesio, M. 2008. Inter-Coder Agree-      
    ment for Computational Linguistics. Computational    
    Linguistics 34(4): 555-596. 
 
Ashley, K.D. and Walker, V.R. 2013. Towards Con 
    structing Evidenced-Based Legal Arguments Using   
    Legal Decision Documents and Machine Learning.    
    In Proc. ICAIL 2013, June 10-14, Rome. 
 
Bach, N.X., Minh, N.L., Oanh, T.T., and Shimazu, A.  
   2013. A Two-Phase Framework for Learning Logi 
   cal Structures of Paragraphs in Legal Articles. ACM   
   Trans. Asian Lang. Inform. Process. 12, 1, Article 3  
   (March 2013). 
 
Cabrio, E. and Villata, S. 2012. Generating Abstract  
   Arguments: A Natural Language Approach. In Ver 
   heij, B., Szeider, S., and Woltran, S. (eds.) Compu- 
   tational Models of Argument: Proceedings of  
   COMMA 2012. Amsterdam, IOS Press, 454-461.   
 
Dagan, I., Dolan, B., Magnini, B., and Roth, D. 2009.  
   Recognizing textual entailment: Rationale, evalua 
   tion, and approaches. Natural Language Engineer 
   ing 15(4): i-xvii. 
 
De Waard, A. and Pander Maat, H. 2012. Knowledge  
   Attribution in Scientific Discourse: A Taxonomy of  
   Types and Overview of Features. In Proc. of the  
   ACL 2012 Workshop on Detecting Structure in Sci 
   entific Discourse. 
 
Feng, V.W. and Hirst, G. 2011. Classifying Argu 
   ments by Scheme. In Proceedings of the 49th Annual  
   Meeting of the Association for Computational Lin 
   guistics, Portland, OR, 987-996. 
 
Green, N. 2005a. A Bayesian Network Coding  
   Scheme for Annotating Biomedical Information  
   Presented to Genetic Counseling Clients. Journal of  
   Biomedical Informatics 38: 130-144. 
 
Green, N. 2005b. Analysis of Linguistic Features As 
   sociated with Point of View for Generating Stylisti 
   cally Appropriate Text. In J. G. Shanahan, James  
   G., Qu, Y., and Wiebe, J. (Eds). Computing Attitude  
   and Affect in Text: Theory and Applications, 33-40.  
   Secaucus, NJ: Springer-Verlag. 
 
Green, N. 2010a. Representation of Argumentation in  
   Text with Rhetorical Structure Theory. Argumenta 
   tion 24(2): 181-196. 
 
Green, N. 2010b. Analysis of communication of un 
   certainty in genetic counseling patient letters for  
   design of a natural language generation system. So 
   cial Semiotics. 20(1):77-86.  
 
Green, N., Dwight, R.,  Navoraphan, K., and Stadler,  
   B. 2011. Natural Language Generation of Transpar 
   ent Arguments for Lay Audiences. Argument and  
   Computation 2(1): 23-50. 
 
 
17
Green, N. and Schug, M. In preparation. Modeling  
   Argumentation in Scientific Discourse. 
 
Liakata, M, et al. 2012a. Automatic recognition of  
   conceptualization zones in scientific articles and  
   two life science applications. Bioinformatics 28(7).  
 
Liakata, M., et al. 2012b. A Three-Way Perspective  
   on Scientific Discourse Annotation for Knowledge  
   Extraction. In Proc. of the ACL 2012 Workshop on     
   Detecting Structure in Scientific Discourse, 37-46. 
 
Mizuta, Y., Korhonen, A., Mullen, T. and Collier, N.  
   2005. Zone Analysis in Biology Articles as a Basis  
   for Information Extraction. International Journal of  
   Medical Informatics 75(6): 468-487. 
 
Mochales, R. and Moens, M. 2011. Argumentation  
   mining. Artificial Intelligence and Law 19, 1-22.  
 
Monteserin, A. and Amandi, A. 2010. Building user  
   argumentative models. Applied Intelligence 32, 131- 
   145. 
 
Reed, C. and Rowe, G. 2004. Araucaria: Software for  
   argument analysis, diagramming and representation.  
   International Journal of Artificial Intelligence Tools  
  14, 961-980. 
 
Reed, C., Mochales-Palau, R., Moens, M., and Mil- 
   ward, D. 2010. Language resources for studying  
   argument. In Proceedings of the 6th Conference on    
   Language Resources and Evaluation, LREC2008,  
   ELRA, 91-100. 
 
Schrauwen et al. 2012. A Mutation in CABP2, Ex- 
   pressed in Cochlear Hair Cells, Causes Autosomal- 
   Recessive Hearing Impairment. The American  
   Journal of Human Genetics 91, 636-645, October 5,  
   2012.  
 
Teufel, S. and Moens, M. 2002. Summarizing Scien 
   tific Articles: Experiments with Relevance and  
   Rhetorical Status. Computational Linguistics 28(4),    
   409-445. 
 
Teufel, S. 2010. The Structure of Scientific Articles:  
   Applications to Citation Indexing and Summariza-      
   tion. Stanford, CA, CSLI Publications. 
 
Thompson, P., Nawaz, R., McNaught, J. and Anani- 
   adou, S. 2011. Enriching a biomedical event corpus  
   with meta-knowledge annotation. BMC Bioinfor 
   matics, 12: 393. 
 
Toulmin, S. E. 1998. The Uses of Argument, Cam- 
   bridge, UK: Cambridge University Press. 
 
 
 
Villalba, M.P.G. and Saint-Dizier, P. 2012. Some      
   Facets of Argument Mining for Opinion Analysis.    
   In Proc. COMMA 2012, 23-34. 
 
Walton, D., Reed, C., and Macagno, F. 2008. Argu- 
   mentation Schemes. Cambridge University Press. 
 
Wyner, A., Mochales-Palau, R., Moens, M-F, and  
   Milward, D. 2010. Approaches to Text Mining  
   Arguments from Legal Cases. In Semantic Pro 
   cessing of Legal Texts, 60-79. 
 
Wyner, A., Schneider, J., Atkinson, K., and Bench- 
   Capon, T. 2012. Semi-Automated Argumentative  
   Analysis of Online Product Reviews. In Proc.  
   COMMA 2012, 43-50. 
 
18
Proceedings of the 8th International Natural Language Generation Conference, pages 143?146,
Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational Linguistics
TBI-Doc: Generating Patient & Clinician Reports from Brain Imaging
Data
Pamela Jordan1, Nancy L. Green2, Christopher Thomas3, Susan Holm1
Learning Research & Development Center, University of Pittsburgh, Pittsburgh, PA1
Department of Computer Science, University of North Carolina Greensboro, Greensboro, NC2
Department of Computer Science, University of Pittsburgh, Pittsburgh, PA3
pjordan@pitt.edu, nlgreen@uncg.edu, clt29@pitt.edu,
susan.holm@gmail.com
Abstract
The TBI-Doc prototype demonstrates the
feasibility of automatically producing
draft case reports for a new brain imaging
technology, High Definition Fiber Track-
ing (HDFT). Here we describe the ontol-
ogy for the HDFT domain, the system ar-
chitecture and our goals for future research
and development.
1 Introduction
The goal of TBI-Doc is to automatically produce
a draft of a traumatic brain injury (TBI) case re-
port similar to existing expert-authored reports
that interpret the results of a High Definition Fiber
tracking (HDFT) procedure (Shin et al., 2012).
HDFT is a new, revolutionary technology for ren-
dering detailed images of the brain and is expected
to have significant implications for TBI patients?
prognosis and treatment. The typical patient for
whom HDFT is indicated has suffered multiple
impacts to the head over an extended period of
time. Although these patients suffer significant
symptoms, in most cases current imaging tools
(e.g. MRI and CT) are unable to pinpoint the lo-
cations of the injuries, much less any evidence of
TBI. Fortunately, HDFT is providing a wealth of
details for the patient and clinician about the TBI.
Unfortunately, the 25 page, expert-generated re-
port takes up to 10 hours of effort to produce once
the HDFT procedure is completed: part of the time
is analysis and part is report writing.
Accordingly, TBI-Doc?s success will be mea-
sured in terms of reducing the amount of human
time involved in creating the final report presented
to the patient and clinicians. In this paper we de-
scribe the TBI-Doc prototype which demonstrates
the feasibility of the system. The main contribu-
tion at this stage of development and the focus of
this paper is the ontology necessary for generating
the reports and the system architecture. We con-
clude with our goals for future research and devel-
opment.
2 The HDFT Results and
Expert-Authored Case Reports
Currently HDFT produces data on 13 brain tracts.
One such tract, which we focused on for the
TBI-Doc prototype, is the superior longitudinal
fasciculus (SLF) which connects regions of the
frontal lobe with the parietal and temporal lobes
(Fernandez-Miranda et al., 2012). The brain re-
gions that a tract connects and the areas of the tract
that appear abnormal suggest the brain functions
that may be impacted (Shin et al., 2012).
To identify abnormalities, the imaging process
mathematically compares the volume of the pa-
tient?s right and left hemisphere for a particu-
lar tract (Shin et al., 2012) and looks for unex-
pected asymmetries.1 The volume is also com-
pared against the HDFT data of a population of
individuals who have not suffered any TBI. Fi-
nally, the analyst also uses his/her knowledge of
the anatomy of a healthy brain to identify abnor-
malities and can further characterize the density,
distribution and connectivity of the fibers of the
tract by visually examining a representation of it,
as shown within Figure 1 for the fronto-occiptal
fasciculus tract. As part of the reporting, the an-
alyst describes the above comparisons, marks up
the visual representations of the tract that illustrate
his/her observations and includes graphs that rep-
resent the volume comparisons.
Because HDFT is new, currently, there are rel-
atively few ideal expert-generated case reports
upon which to model TBI-Doc?s reports. When
we began the development of TBI-Doc, an ana-
lyst had written 29 case reports but only 2-3 of
these reports were considered model final reports.
1Some tracts normally are expected to have some asym-
metries between hemispheres.
143
Figure 1: Tract Report Excerpt: shows HDFT im-
ages of fibers representing the FOF Tract
The content and format of the final case report is
continuing to evolve as the primary physician and
nurse on the HDFT team provide feedback on the
type of report they believe will be most benefi-
cial. As of yet, there has been no feedback from
patients or other types of treating clinicians (e.g.
speech therapists, physical therapists, etc.) on the
content and format that they find most helpful.
For the prototype we focused on modeling the
tract section of one of the case reports but used
the remaining reports for determining the ontol-
ogy. An excerpt of the SLF tract section of that
model case report is shown in Figure 2.
3 The TBI-Doc System Design
Given the existing analyst workflow, we designed
the TBI-Doc system process (see Figure 3) as fol-
lows; after interpreting and manually annotating
HDFT images of tracts, and creating and annotat-
Figure 2: Expert Observation being Modeled
ing data graphics that show quantitative HDFT re-
sults, the analyst uses TBI-Doc?s graphical user in-
terface (GUI) to provide his qualitative evaluation
of the HDFT results and preferences for tailoring
the report. Using the analyst?s specifications pro-
vided through the TBI-Doc GUI and the annotated
tract images and data graphics, TBI-Doc automat-
ically produces a first draft of the case report. The
draft is then manually reviewed and edited by the
analyst before delivery. The case report is deliv-
ered to the clients as a file that can be printed on
paper and viewed on a tablet.
The architecture of TBI-Doc (shown by the re-
mainder of Figure 3) follows the standard NLG
pipeline (Reiter et al., 2000) and is similar to the
architecture of the healthcare-related systems de-
scribed in (Green et al., 2011; Hunter et al., 2012;
Scott et al., 2013). The TBI-Doc GUI represents
the TBI-Doc ontology and its columns (an excerpt
is shown in Table 1) cue the analyst to enter his/her
qualitative judgments about the data for a tract
at the region level, which is the lowest judgment
level as it describes the endpoints of subsections of
a tract, bundles between regions, hemisphere level
and overall. The ontology was derived by analyz-
ing existing reports to understand what is being de-
scribed across all of the reports and by interview-
ing HDFT team members. The ontology identi-
fies states (e.g. measures), relations (e.g. similar
Figure 3: The TBI-Doc Process
144
Table 1: Example Input for SLF Tract Assessment
Tract SPARSE
Assessment
Tract hemi- Area Area Second Measure Evaluation Kind of
sphere Type Name End Point Comparison
SLF left OverallTract tract density very sparse healthy
SLF left BundleBtwnRegions DLPFC pTemporal density sparse right
SLF left BundleBtwnRegions DLPFC pTemporal connectivity reduced right
SLF left SpecificRegion DLPFC connectivity little right
SLF left SpecificRegion pTemporal connectivity little right
SLF left SpecificRegion DLPFC density sparse right
SLF left SpecificRegion pTemporal density sparse right
SLF left BundleBtwnRegions DLPFC pParietal connectivity little right
SLF left BundleBtwnRegions DLPFC pParietal density sparse right
SLF right OverallTract tract density normal healthy
SLF right OverallTract tract density some sparse healthy
to), and entities (e.g. tract(s), regions(s), connec-
tion(s), measurements such as density) relevant to
the HDFT reporting domain.
When the qualitative judgment entries or up-
dates are complete, the analyst requests that a re-
port be generated. The TBI-Doc Document Plan-
ner (logic implemented in Java) selects appro-
priate content from the database using the TBI-
Doc Data Interface and adds messages constructed
from that content as leaves of the Document Plan.
For the parts of the report that are not dependent
on values in the database, the Document Planner
also adds English (canned) text as leaves of the
Document Plan. The Document Planner is a set of
rules for what content to select and how to order
that content. For example, an abbreviated excerpt
of the content selection rules follow.
GENERATETRACTSECTION(tract, patientId)
GETTRACTSTATUS(tract,patientId)
If status=reduced then
GETTRACTFUNCTION(tract)
GENTRACTOBSERVATION(tract,patientId)
GENTRACTOBSERVATION(tract, patientId)
If Evaluation=reduced & TractOverall then
GENTRACTSUMMARYSENTENCE
ElsIf hemi not both & AreaType=OverallTract then
GENHEMISPHERESUMMARYSENTENCE
regions=
GATHERREGIONS(SpecificRegion,BundleBtwnRegions)
orderedRegions=ORDERREGIONS(regions)
For region in orderedRegions do
GENSENTENCE(region)
While there is often just a single sentence for a
tract or hemisphere summary, region descriptions
are generally multi-sentential. Currently the or-
derRegions function is designed as a default set
of guidelines for ordering the region descriptions.
The output of the Document Plan is then a series
of predicates that represent the content to be real-
ized. Some content, such as getTractFunction, is
static and does not pass through the pipeline to the
Microplanner.
The TBI-Doc Microplanner transforms the
predicates output from the Document Plan into
SimpleNLG sentence specifications (in Java) via
a set of mapping rules. The Microplanner selects
mapping rules based on the predicates to be real-
ized and any context variables that are available.
The mapping rules indicate what syntactic struc-
tures to create for a predicate and where to attach
them in the sentence being built. Currently, for
this demonstration prototype we have not yet ad-
dressed lexical realization and sentence aggrega-
tion. In the final step of the pipeline, SimpleNLG
(Gatt and Reiter, 2009) renders the sentence spec-
ifications as English sentences. Once the pipeline
is complete, the TBI-Doc Formatter combines all
the sentences from SimpleNLG and the canned
text into an HTML document which can then be
displayed by a browser and edited via an XML ed-
itor.
Rather than implementing each of the above
steps one-by-one to cover all possible cases, each
step was implemented to focus on replicating the
observation section of one case report. This al-
lowed us to perform an end-to-end demonstration
of the feasibility of this design. Thus many of
the rules described above are incomplete for al-
ternative pathways. TBI-Doc can currently gen-
erate from input data an observation section such
as the one shown below. The judgments entered
on behalf of the analyst for this demonstration
are shown in Table 1 and represent what was ex-
pressed in the expert-written observations section
in Figure 2:
145
Observations Left SLF is particularly sparse
throughout the tract. The left tract from the
DLPFC to the pTemporal region when com-
pared to the right has a sparse density and a re-
duced connectivity. In particular little connectiv-
ity and sparse density are observed in the DLPFC
and pTemporal regions as well as between the
DLPFC and pParietal regions on the left. Overall
the right tract appears similar to a healthy tract
but still appears somewhat sparse.
4 Future Work
The current TBI-Doc is a demonstration of the fea-
sibility of generating case reports and the main
contribution of the work thus far has been to de-
fine an ontology for the HDFT domain. However,
because HDFT is a new technology that is continu-
ing to be improved rapidly and the reporting goals
are still evolving, the ontology is not yet complete.
Because the ontology drives the rest of the system,
it follows that the rest of the system components
still need more development.
For the demonstration we focused on reporting
on one of the 13 existing types of brain tracts.
While we anticipate that the ontology will gener-
alize well to the other tract types, each tract type
may introduce some extensions to the ontology. In
addition the HDFT developers anticipate provid-
ing data on additional tract types over time.
Since knowledge acquisition is still ongoing,
the Document Planner logic is still very shallow.
As a result, the demonstration version of TBI-
Doc is currently limited to reacting to descriptor
changes and does not yet alter the document struc-
ture or intelligently alter content selection. The
Microplanner currently does some context check-
ing to select the appropriate set of transforma-
tion rules to apply but this will need expansion
as the Document Planner becomes more complete.
More specifically, the sentence structure needs to
vary depending on the choices made by the Doc-
ument Planner. In addition, lexical selection in
which internal abbreviations are mapped to user
preferred forms needs more work (e.g. depending
on user preferences, DLPFC could map to dorso-
lateral prefrontal cortex and pParietal to posterior
Parietal).
Our longer term interest is to explore ways
to appropriately adapt the reports for different
clients. A patient for whom the HDFT results indi-
cate cognitive processing issues may find a differ-
ent style of report and reading level more suitable
than a supporting family member or a treating clin-
ician. Different treating clinicians may prefer re-
ports with different content selected. For example,
a speech therapist may prefer a report that focuses
on the injuries that relate to a patient?s speech and
language goals, while a sleep specialist may prefer
a different focus.
Acknowledgments
This work was supported by US Army Com-
bat Casualty Care Research Program contracts
CDMRP PT110773 (W81XH-12-2-0140) & US
Army 12342013 (W81XWH-12-2-0319). We
thank Walter Schneider, Kevin Jarbo, Lauren Wa-
gener, Will Bird & the HDFT team for their exper-
tise and for involving us in their research.
References
Juan C Fernandez-Miranda, Sudhir Pathak, Johnathan
Engh, Kevin Jarbo, Timothy Verstynen, Fang-Cheng
Yeh, Yibao Wang, Arlan Mintz, Fernando Boada,
Walter Schneider, et al. 2012. High-definition fiber
tractography of the human brain: neuroanatomical
validation and neurosurgical applications. Neuro-
surgery, 71(2):430?453.
Albert Gatt and Ehud Reiter. 2009. Simplenlg: A re-
alisation engine for practical applications. In Pro-
ceedings of the 12th European Workshop on Natural
Language Generation, pages 90?93. Association for
Computational Linguistics.
Nancy Green, Rachael Dwight, Kanyama Navoraphan,
and Brian Stadler. 2011. Natural language genera-
tion of biomedical argumentation for lay audiences.
Argument & Computation, 2(1):23?50.
James Hunter, Yvonne Freer, Albert Gatt, Ehud Reiter,
Somayajulu Sripada, and Cindy Sykes. 2012. Au-
tomatic generation of natural language nursing shift
summaries in neonatal intensive care: Bt-nurse. Ar-
tificial intelligence in medicine, 56(3):157?172.
Ehud Reiter, Robert Dale, and Zhiwei Feng. 2000.
Building natural language generation systems, vol-
ume 33. MIT Press.
Donia Scott, Catalina Hallett, and Rachel Fetti-
place. 2013. Data-to-text summarisation of pa-
tient records: Using computer-generated summaries
to access patient histories. Patient education and
counseling, 92(2):153?159.
Samuel S Shin, Timothy Verstynen, Sudhir Pathak,
Kevin Jarbo, Allison J Hricik, Megan Maserati,
Sue R Beers, Ava M Puccio, Fernando E Boada,
David O Okonkwo, and Walter Schneider. 2012.
High-definition fiber tracking for assessment of neu-
rological deficit in a case of traumatic brain injury:
finding, visualizing, and interpreting small sites of
damage: Case report. Journal of neurosurgery,
116(5):1062?1069.
146
