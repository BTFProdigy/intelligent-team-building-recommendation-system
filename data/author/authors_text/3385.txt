Proceedings of the Workshop on Linguistic Distances, pages 91?99,
Sydney, July 2006. c?2006 Association for Computational Linguistics
A Structural Similarity Measure
Petr Homola and Vladislav Kubon?
Institute of Formal and Applied Linguistics
Malostranske? na?me?st?? 25
110 00 Praha 1, Czech republic
{homola,vk}@ufal.mff.cuni.cz
Abstract
This paper outlines a measure of lan-
guage similarity based on structural
similarity of surface syntactic depen-
dency trees. Unlike the more tradi-
tional string-based measures, this mea-
sure tries to reflect ?deeper? correspon-
dences among languages. The develop-
ment of this measure has been inspired
by the experience from MT of syntac-
tically similar languages. This experi-
ence shows that the lexical similarity is
less important than syntactic similar-
ity. This claim is supported by a num-
ber of examples illustrating the prob-
lems which may arise when a measure
of language similarity relies too much
on a simple similarity of texts in differ-
ent languages.
1 Introduction
Although the similarity of natural languages is
in principal a very vague notion, the linguistic
literature seems to be full of claims classifying
two natural languages as being more or less
similar. These claims are in some cases a result
of a detailed comparative examination of lex-
ical and/or syntactic properties of languages
under question, in some cases they are based
on a very subjective opinion of the author, in
many other cases they reflect the application
of some mathematical formula on textual data
(a very nice example of such mathematical ap-
proach can be found at (Scannell, 2004)).
Especially in the last case the notion of lan-
guage similarity is very often confused with the
notion of text similarity. Even the well known
paper (Lebart and Rajman, 2000) deals more
with the text similarity than language similar-
ity. This general trend is quite understand-
able, the mathematical methods for measur-
ing text similarity are of a prominent impor-
tance especially for information retrieval and
similar fields. On the other hand, they con-
centrate too much on the surface similarity
of word forms and thus may not reflect the
similarity of languages properly. This paper
tries to advocate different approach, based on
the experience gained in MT experiments with
closely related (and similar) languages, where
it is possible to ?measure? the similarity indi-
rectly by a complexity of modules we have to
use in order to achieve a reasonable transla-
tion quality. This experience led us to formu-
lating an evaluation measure trying to capture
not only textual, but also syntactic similarities
between natural languages.
2 Imperfections of measures based
on string similarity
There are many application areas in the NLP
in which it is useful to apply the measures ex-
ploiting the similarity of word forms (strings).
They serve very well for example for tasks
like spellchecking (where the choice of the best
candidates for correction of a spelling error is
typically based upon the Levenshtein metrics)
or estimating the similarity of a new source
sentence to those stored in the translation
memory of a Machine Aided Translation sys-
tem. They are a bit controversial in a ?proper?
machine translation, where the popular BLEU
score (Papineni et al, 2002), although widely
accepted as a measure of translation accuracy,
seems to favor stochastic approaches based on
91
an n-gram model over other MT methods (see
the results in (Nist, 2001)).
The controversies the BLEU score seems to
provoke arise due to the fact that the evalua-
tion of MT systems can be, in general, per-
formed from two different viewpoints. The
first one is that of a developer of such a sys-
tem, who needs to get a reliable feedback in
the process of development and debugging of
the system. The primary interest of such a
person is the grammar or dictionary coverage
and system performance and he needs a cheap,
fast and simple evaluation method in order to
allow frequent routine tests indicating the im-
provements of the system during the develop-
ment of the system.
The second viewpoint is that of a user, who
is primarily concerned with the capability of
the system to provide fast and reliable trans-
lation requiring as few post-editing efforts as
possible. The simplicity, speed and low costs
are not of such importance here. If the eval-
uation is performed only once, in the mo-
ment when the system is considered to be
ready, the evaluation method may even be rel-
atively complicated, expensive and slow. A
good example of such a complex measure is the
FEMTI framework (Framework for the Evalu-
ation of Machine Translation). The most com-
plete description of the FEMTI framework can
be found in (Hovy et al, 2002). Such mea-
sures are much more popular among transla-
tors than among language engineers and MT
systems developers.
If we aim at measuring the similarity of lan-
guages or language distances, our point of view
should be much more similar to that of a hu-
man translator than of a system developer, if
we?ll stick to our MT analogy. When looking
for clues concerning the desirable properties
of a language similarity (or distance) measure,
we can first try to formulate the reasons why
we consider the simple string-based (or word-
form-based) measures inadequate.
If we take into account a number of lan-
guages existing in the world, the number of
word forms existing in each of those languages
and a simple fact that a huge percentage of
those word forms is not longer than five or
six characters, it is quite clear that there is a
huge number of overlapping word forms which
have completely different meaning in all lan-
guages containing that particular word form.
Let us take for illustration some language pairs
of non-related languages.
For example for Czech and English (the lan-
guages very different with regard both to the
lexicon and syntax) we can find several exam-
ples of overlapping word forms. The English
word house means a duckling in Czech, the En-
glish indefinite article a is in Czech also very
frequent, because it represents a coordinating
conjunction and, while an is an archaic form
of a pronoun in Czech. On the other hand, if
we look at the identical (or nearly identical)
word forms in similar languages, we can find
many examples of totally different meaning.
For example, the word form z?ivot means life
in Czech and belly in Russian; godina means
year in Serbo-Croatian while hodina is an hour
in Czech (by the way, an hour in Russian is c?as
? and the same word means time in Czech).
The overlapping word forms between rela-
tively distant languages are so frequent that it
is even possible to create (more or less) syntac-
tically correct sentences in one language con-
taining only word forms from the other lan-
guage. Again, let us look at the Czech-English
language pair. The English sentences Let my
pal to pile a lumpy paste on a metal pan. or
I had to let a house to a nosy patron. consist
entirely of word forms existing also in Czech,
while the Czech sentence Adept demise metal
hole pod led. ? [A resignation candidate was
throwing sticks under the ice.] consists of En-
glish word forms.
Creating such a Czech sentence is more com-
plicated ? as a highly inflected language it
uses a wide variety of endings, which make it
more difficult to create a syntactically correct
sentence from word forms of a language which
has incomparably smaller repertoire of end-
ings. This fact directly leads to another argu-
ment against the string similarity based mea-
sures ? even though two languages may have
very similar syntactic properties and their ba-
sic word forms may also be very similar, then if
the languages are highly inflective and the only
difference between those languages are differ-
ent endings used for expressing identical mor-
phosyntactic properties, the string similarity
based methods will probably show a substan-
92
tial difference between these languages.
This is highly probable especially for shorter
words ? the words with a basic form
only four or five characters long may have
endings longer or equal to the length of
the basic form, for example: nova?/novata
?new? (Cze/Mac), vide?ny?/vidimyj ?seen?
(Cze/Rus), fotografuj??c??/fotografuojantysis
?photographing? (Cze/Lit).
The last but not least indirect argument
against the use of string-based metrics can be
found in (Kubon? and Be?mova?, 1990). The pa-
per describes so called transducing dictionary,
a set of rules designed for a direct transcrip-
tion of a certain category of source language
words into a target language. The system has
been tested on two language pairs (English-
to-Czech and Czech-to-Russian) and although
there was a natural original assumption that
such a system will cover substantially more ex-
pressions when applied to a pair of related lan-
guages (which are not only related, but also
quite similar), this assumption turned to be
wrong. The system covered almost identical
set of words for both language pairs ? namely
the words with Greek or Latin origin. The
similarity of coverage even allowed to build an
English-to-Russian transducing dictionary us-
ing Czech as a pivot language with a negligible
loss of the coverage.
3 Experience from MT of similar
languages
The Machine Translation field is a good testing
ground for any theory concerning the similar-
ity of natural languages. The systems dealing
with related languages usually achieve higher
translation quality than the systems aiming at
the translation of more distant language pairs
? the average MT quality for a given system
and a given language pair might therefore also
serve as some kind of a very rough metrics of
similarity of languages concerned.
Let us demonstrate this idea using an ex-
ample of a multilingual MT system described
in several recently published papers (see e.g.
(Hajic? et al, 2003) or (Homola and Kubon?,
2004)). The system aims at the translation
from a single source language (Czech) into
multiple more or less similar target languages,
namely into Slovak, Polish, Lithuanian, Lower
Sorbian and Macedonian.
The system is very simple ? it doesn?t con-
tain any full-fledged parser, neither rule based,
nor stochastic one. It relies on the syntactic
similarity of the source and target languages.
It is transfer-based with the transfer being per-
formed as soon as possible, depending on the
similarity of both languages. In its simplest
form (Czech to Slovak translation) the system
consists of the following modules:
1. Morphological analysis of the source lan-
guage (Czech)
2. Morphological disambiguation of the
source language text by means of a
stochastic tagger
3. Transfer exploiting the domain-related
bilingual glossaries and a general (domain
independent) bilingual dictionary
4. Morphological synthesis of the target lan-
guage
The lower degree of similarity between Czech
and the remaining target languages led to
an inclusion of a shallow parsing module for
Czech for some of the language pairs. This
module directly follows the morphological dis-
ambiguation of Czech.
The evaluation results presented in (Homola
and Kubon?, 2004) indicate that even though
Czech and Lithuanian are much less similar
at the lexical and morphological level (e.g. at
both levels actually dealing with strings), the
translation quality is very similar due to the
syntactic similarity between all languages con-
cerned.
4 Typology of language similarity
The experience from the field of MT of closely
related languages presented in the previus sec-
tions shows that it is very useful to classify the
language similarity into several categories:
? typological
? morphological
? syntactic
? lexical
Let us now look at these categories from the
point of view of machine translation,
93
4.1 Typological similarity
The first type of similarity is probably the
most important one. If both the target and
the source language are of a different language
type, it is more difficult to obtain good MT
quality. The notions like word order, the ex-
istence or non-existence of articles, different
temporal system and several other properties
have direct consequences for the translation
quality. Let us take Czech and Lithuanian as
an example of the language pair, which doesn?t
belong to the same group of languages (Czech
is a Slavic and Lithuanian Baltic language).
Both languages have rich inflection and very
high degree of word order freedom, thus it is
not necessary to change the word order at the
constituent level. On the other hand, both
languages differ a lot in the lexics and mor-
phology.
For example, both (1) and (3) mean approx-
imately ?The father read a/the book?. What
these sentences differ in is the information
structure. (1) should be translated as ?The
father read a book?, whereas (3) means in
fact ?The book has been read by the father?.1
The category of voice differs in both sentences
because of strict word order in English, al-
though in both Czech equivalents, active voice
is used.2 We see that in the Lithuanian trans-
lation, the word order is exactly the same.
(1) Otec
father-nom
c?etl
read-3sg,past
knihu
book-acc
?The father read a book.? (Cze)
(2) Te?vas
father-nom
skaite?
read-3sg,past
knyg ?a
book-acc
?The father read a book.? (Lit)
(3) Knihu
book-acc
c?etl
read-3sg,past
otec
father-nom
?The father read a book.? (Cze)
1Note that in the first sentence, an indefinite article
is used, whereas in the latter one, a definite article
stands in front of ?book?. The reason is that in the first
sentence, the noun?book? is not contextually bound (it
belongs to the focus), in the latter one it belongs to the
topic.
2Passive voice (except of the reflexive one) occurs
rarely in Czech (and most other Slavonic languages).
It can be used if one would like to underline the di-
rect object or if there is no subject at all (for example,
Kniha byla c?tena ?The book has been read?).
(4) Knyg ?a
book-acc
skaite?
read-3sg,past
te?vas
father-nom
?The father read a book.? (Lit)
4.2 Lexical similarity
The lexical similarity does not mean that the
vocabulary has to have the same origin, i.e.,
that words have to be created from the same
(proto-)stem. What is important for shallow
MT (and for MT in general), is the seman-
tic correspondence (preferably one-to-one re-
lation).
Lexical similarity is the least important one
from the point of view of MT, because the lex-
ical differences are solved in the glossaries and
general dictionaries.
4.3 Syntactic similarity
Syntactic similarity is also very important es-
pecially on higher levels, in particular on the
verbal level. The differences in verbal va-
lences have negative influence on the quality
of translation due to the fact that the trans-
fer thus requires a large scale valence lexicon
for both languages, which is extremely difficult
to build. Syntactic structure of smaller con-
stituents, such as nominal and prepositional
phrases, is not that important, because it is
possible to analyze those constituents syntac-
tically using a shallow syntactic analysis and
thus it is possible to adapt locally the syntactic
structure of a target sentence.
4.4 Morphological similarity
Morphological similarity means similar struc-
ture of morphological hierarchy and paradigms
such as case system, verbal system etc. In
our understanding Baltic and Slavic languages
(except for Bulgarian and Macedonian) have
a similar case system and their verbal system
is quite similar as well. Some problems are
caused by synthetic forms, which have to be
expressed by analytical constructions in other
languages (e.g., future tense or conjunctive in
Czech and Lithuanian). The differences in
morphology can be relatively easily overcomed
by the exploitation of full-fledged morphology
of both languages (source and target).
Similar morphological systems simplify the
transfer. For example, Slavonic languages (ex-
cept of Bulgarian and Macedonian) have 6-7
94
cases. The case system of East Baltic lan-
guages is very similar, although it has been re-
duced formally in Latvian (instrumental forms
are equal as dative and accusative and the
function of instrumentral is expressed by the
preposition ar ?with?, similarly as in Upper
Sorbian). (Ambrazas, 1996) gives seven cases
for Lithuanian, but there are in fact at least
eight cases in Lithuanian (or ten cases but only
eight of them are productive3). Nevertheless
the case systems of Slavonic and East Baltic
languages are very similar which makes the
languages quite similar even across the border
of different language groups.
Significant differences occur only in the ver-
bal system, East Baltic languages have a huge
amount of participles and half-participles that
have no direct counterpart in Czech. The
Lithuanian translation of an example from
(Gamut, 1991) is given in (5):
(5) Gime?
was-born-3sg
vaikas,
child-nom
valdysiantis
ruling-fut,masc,sg,nom
pasauli?
world-acc
?A child was born which will rule the
world.? (Lit)
The participle valdysiantis is used instead
of an embedded sentence, because Lithuanian
has future participles. These participles have
to be expresses by an embedded sentence in
Slavonic languages.
5 An outline of a structural
similarity measure
In this section, we propose a comparatively
simple measure of syntactic (structural) sim-
ilarity. There are generally two levels which
may serve as a basis for such a structural mea-
sure, the surface or deep syntactic level. Let us
first explain the reasons supporting our choice
of surface syntactic level.
Compared to deep syntactic representation,
the surface syntactic trees are much more
3Although some Balticists argue that illative forms
are adverbs, it is a fact that this case is productive and
used quite often (Erika Rimkute?, personal communica-
tion), though it has been widely replaced by preposi-
tional phrases. Allative and adessive are used only in
some Lithuanian dialects, except of a few fixed allative
forms (e.g., vakarop(i) ?in the evening?, velniop(i) ?to
the hell?.)
closely related to the actual surface form of a
sentence. It is quite common that every word
form or punctuation sign is directly related to
a single node of a surface syntactic tree. The
deep syntactic trees, on the other hand, usu-
ally represent autosemantic words only, they
may even actually contain more nodes than
there are words in the input sentence (for ex-
ample, when the input sentence contains ellip-
sis). It is also quite clear that the deep syntac-
tic trees are much more closely related to the
meaning of the sentence than its original sur-
face form, therefore they may hide certain dif-
ferences between the languages concerned, it is
a generally accepted hypothesis that transfer
performed on the deep syntactic level is eas-
ier than the transfer at the surface syntactic
level, especially for syntactically and typolog-
ically less similar languages.
The second important decision we had to
make was to select the best type of surface
syntactic trees between the dependency and
phrase structure trees. For practical reasons
we have decided to use dependency trees. The
main motivation for this decision is the enor-
mous structural ambiguity of phrase structure
trees that represent sentences with identical
surface form. Let us have a look at the follow-
ing Polish sentence:
(6) Pawe l
Pawe l-nom
czyta
read-3sg
ksi ?az?k ?e
book-fem,sg,acc
?Pawe l is reading a/the book.?
The syntactic structure of this sentence can
be expressed by two phrase structure trees rep-
resenting different order of attaching nominal
phrases to a verb.4
4The full line denotes the head of the phrase, the
dotted line a dependent.
95
??
?



?



?



Pawe l czyta ksi ?az?k ?e
?
?
?



?



?



Pawe l czyta ksi ?az?k ?e
There is no linguistically relevant difference
between these two trees. Although generally
useful, the information hidden in both trees
is purely superfluous for our goal of designing
a simple structural metrics. The dependency
tree obtained from the phrase structure ones
by contraction of all head edges seem to be
much more appropriate for our purpose. In our
example, we therefore get the following form
of the dependency tree:
czyta
zzuu
u
u
u
u
u
u
u
$$J
J
J
J
J
J
J
J
J
Pawe l ksi ?az?k ?e
The nodes of the dependency trees repre-
senting surface syntactic level directly corre-
spond to word forms present in the sentence.
For the sake of simplicity, the punctuation
marks are not represented in our trees. They
would probably cause a lot of technical prob-
lems and might distort the whole similarity
measure. The node of a tree are ordered and
reflect the surface word-order of the sentence.
Different labels of nodes in both languages (see
the example below) don?t influence the value
of the measure, however they are important
for the identification of corresponding nodes
(a bilingual dictionary is used here).
The structural measure we are suggesting is
based on the analogy to the Levenshtein mea-
sure. It is therefore pretty simple ? the dis-
tance of two trees is the minimal amount of
elementary operations that transform one tree
to the other. We consider the following ele-
mentary operations:
1. adding a node,
2. removing a node,
3. changing the order of a node,
4. changing the father of a node.
The similarity of languages can be obtained
as an average distance of individual sentences
in a parallel corpus.
The following examples show the use of the
measure on individual trees. The correspon-
dence between individual nodes of both trees
can be handled by exploiting the bilingual dic-
tionary wherever necessary:
(7) Vesna
Vesna-nom
je
is-3sg
pri?sla
come-respart,fem,sg
?Vesna has come.? (Slo)
(8) Vesna
Vesna-nom
przysz la
come-respart,fem,sg
?Vesna has come.? (Pol)
The distance between (7) and (8) is equal 1,
since one node has been removed (the dotted
line gives the removed node).
pri?sla/przysz la
ttjj
jj
jj
jj
jj
jj
jj
jj
xx
Vesna je
(9) Grem
go-1sg
z
with
avtom
car-masc,sg,ins
?I am going by car.? (Slo)
(10) Jad ?e
go-1sg
samochodem
car-masc,sg,ins
?I am going by car.? (Pol)
96
The distance between (9) and (10) is equal
1, since one node has been removed (the dotted
line gives the removed node).
grem/jad ?e
**UU
UU
UU
UU
UU
UU
UU
UU
U
avtom/samochodem
wwz
5.1 Formalization
(11) On
he-nom
ra?d
with-pleasure
plave
swims-3sg
?He likes swimming.? (Cze)
plave
uujj
jj
jj
jj
jj
jj
jj
jj
jj
j
yy










on ra?d
likes
|| %%
he 11 swimming
The Czech-English example (11) shows two
sentences which have a mutual distance equal
to 3 ? if we start changing the Czech tree
into an English one, then the first elemen-
tary operation is the deletion of the node ra?d,
the second operation adds the new node cor-
responding to the English word likes and the
third and last operation is the change of the
father of the node corresponding to the per-
sonal pronoun on [he] from swimming to likes.
As mentioned above, the node labels are not
taken into account, the fact that the Czech fi-
nite verbal form plave changes into an English
gerund has no effect on the distance.
A similar case are sentences with a dative
agent, for example:
(12) Je
is
mi
me-dat
zima
cold-f,sg,nom
?I am cold? (Cze)
In this sentence, the Czech mi does not
match to I since it is no subject. Similarly,
the substantive zima does not match to cold,
since it is a different part of speech. Hence
two nodes are removed and two new nodes
are added, which gives us a distance of 4.
This example demonstrates that the measure
tends to behave naturally - even short sen-
tences containing syntactically different con-
structions get a relatively high score.
To formalize the process described above, let
us introduce a notion of lexical and analytical
equality of nodes in analytical trees:
? Two nodes equal lexically if and only if
they share the same meaning in the given
context. Nevertheless to simplify auto-
matic processing, we treat two nodes as
lexically equal if they share a particular
meaning (defined e.g. as a non-empty in-
tersection of Wordnet classes).
? Two nodes equal analytically if and only
if they have the same analytical label (e.g.
subject, spacial adverbial etc.).
As for the measure, two nodes match to each
other if they 1) occur at the same position in
the subtree of their parent and 2) equal lexi-
cally and analytically.
If a subtree (greater than 1) is added or re-
moved, the operation contributes to the mea-
sure with the size of the subtree (the amount
of its nodes), for example in the following id-
iomatic phrase:
(13) pus?cic?
leave-inf
z
with
dymem
smoke-masc,sg,ins
?burn down? (Pol)
(14) zapa?lit
burn-down-inf
?burn down? (Cze)
In the above example, the distance is
equal 2.
The automatic procedure can be described
as follows (given two trees):
1. Align all sons of the root node.
2. Count discrepancies.
3. For all matched nodes, go to step 1 to
process subtrees and sum up distances.
97
5.2 Discussion
It is obvious that our measure expresses the ty-
pological similarity of languages. We get com-
paratively high values even for genetically re-
lated languages if their typology is different.
Let us demonstrate this fact on Czech and
Macedonian examples.
(15) Ivan
Ivan-nom
dal
gave-respart,masc,sg
knihu
book-fem.sg,acc
Stojanovi
Stojan-dat
?Ivan gave the book to Stojan.? (Cze)
dal
||y
y
y
y
y
y
y
y
##F
F
F
F
F
F
F
F
F
**T
TT
TT
TT
TT
TT
TT
TT
TT
T
Ivan knihu Stojanovi
(16) Ivan
Ivan-nom
mu
him
ja
her-fem,sg,acc
ima
has-3sg
dadeno
given-ppart,neut,sg
knigata
book-fem.sg,def
na
on
Stojan
Stojan
?Ivan gave the book to Stojan.? (Mac)
The distance equals 5. The score is rela-
tively high, taken into account that both lan-
guages are related. It indicates again that for
a given purpose the measure seems to provide
consistent results.
The proposed measure takes into account
only the structure of the trees, completely ig-
noring node and edge labels. Let us analyze
the following example:
(17) Ta
this-fem,sg,nom
ksi ?az?ka
book-fem.sg,nom
si ?e
REFL
cz ?esto
well
czyta
read-3sg
?This book is read often.?
(18) T?e
this-fem,sg,acc
ksi ?az?k ?e
book-fem.sg,acc
si ?e
REFL
cz ?esto
well
czyta
read-3sg
?This book is read often.?
The syntactic trees of both sentences have
the same structure, but (17) is passive and
(18) active (with a general subject). This is
of course a significant difference and as such
it should be captured in the measure, never-
theless our simple measure doesn?t reflect it.
There are several reasons why a current ver-
sion of the measure doesn?t include morpho-
logical and morphosyntactic labels. One of the
reasons is a different nature of the problem ?
to design a reliable measure combining struc-
tural information with the information con-
tained in node labels is very difficult. From the
technical point of view, a great obstacle is also
the variety of systems of tags used for this pur-
pose for individual languages, which may not
be compatible. For example, Macedonian has
almost no cases at nouns, therefore it would
make no sense to use cases in the noun anno-
tation, while for other Slavic languages (and
not only for Slavic ones) is this information
very important. To find a good integration of
morphosyntactic features into the structural
measure is definitely a very interesting topic
for future research.
6 Conclusions
This paper contains an outline of a simple lan-
guage similarity measure based upon the sur-
face syntactic dependency trees. According to
our opinion, such a measure expresses more
adequately the similarity of languages than
simple string-based measures used for the text
similarity. The measure is defined on pairs of
trees from a parallel corpus. In its current
form it doesn?t account for differences in mor-
phosyntactic labels of corresponding nodes or
edges, although it is an important parameter
of language similarity. The proper combina-
tion of our basic structural similarity measure
with some measure reflecting the differences of
labels opens a wide range of options for a fu-
ture research. Equally important seems to be
a task of gathering properly syntactically an-
notated parallel corpora of a reasonable size.
The only corpus of such kind which we have
at our disposal, the Prague Czech-English De-
pendency Treebank (Cur???n et al, 2004) re-
lies on imperfect automatic annotation which
might distort the results. The human annota-
tion of the PCEDT is just starting, so there?s a
98
dadeno
rrffff
fff
fff
fff
fff
fff
fff
fff
fff
fff
f
ss uu
zz %%
L
L
L
L
L
L
L
L
L
L
++XX
XX
XX
XX
XX
XX
XX
XX
XX
XX
XX
XX
XX
X
Ivan mu ja ima knigata Stojan
{{
na
Figure 1: The dependency tree of (16)
good chance that the measure will bring some
reliable results at least for those two lenguages
soon.
7 Acknowledgements
This research was supported by the Min-
istry of Education of the Czech Repub-
lic, project MSM0021620838, by the grant
No. GAUK 351/2005 and by the grant
No. 1ET100300517. We would like to thank
the anonymous reviewers for their valuable
comments and recommendations.
References
Vytautas Ambrazas. 1996. Dabartine?s lietuviu? kal-
bos gramatika. Mokslo ir enciklopediju? leidykla,
Vilnius.
Jan Cur???n, Martin C?mejrek, Ji?r?? Havelka, Jan Ha-
jic?, Vladislav Kubon?, and Zdene?k Z?abokrtsky?.
2004. Prague Czech-English Dependency Tree-
bank Version 1.0. Linguistic Data Consortium.
LTF Gamut. 1991. Login, loanguage and meaning
2: Intensional logic and logical grammar. Uni-
versity of Chicago Press, Chicago.
Jan Hajic?, Petr Homola, and Vladislav Kubon?.
2003. A simple multilinguale machine transla-
tion system. In Proceedings of the MT Summit
IX, New Orleans.
Petr Homola and Vladislav Kubon?. 2004. A trans-
lation model for languages of accessing coun-
tries. In Proceedings of the 9th EAMT Work-
shop, La Valetta, Malta.
Eduard Hovy, Margaret King, and Andrei
Popescu-Beli. 2002. Principles of Context-
Based Machine Translation Evaluation. Ma-
chine Translation, 1(17).
Vladislav Kubon? and Alevtina Be?mova?. 1990.
Czech-to-Russian Transducing Dictionary. In
Proceedings of the XIIIth conference COLING
?90, volume 3.
Ludovic Lebart and Martin Rajman, 2000. Hand-
book of Natural Language Processing, chapter
Computing similarity. Dekker, New York.
Nist. 2001. Automatic evaluation of machine
translation quality using n-gram co-occurrence
statistics. Technical report, NIST.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a Method for
Automatic Evaluation of Machine Translation.
In Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics,
Philadelphia.
Kevin P. Scannell. 2004. Cor-
pus building for minority languages.
http://borel.slu.edu/crubadan/index.html.
99
Proceedings of the ACL-08: HLT Workshop on Mobile Language Processing, pages 27?28,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
A Distributed Database for Mobile NLP Applications?
Petr Homola
Institute of Formal and Applied Linguistics
Charles University
Malostranske? na?me?st?? 25
CZ-118 00, Prague, Czech Republic
homola@ufal.mff.cuni.cz
Abstract
The paper presents an experimental machine
translation system for mobile devices and its
main component ? a distributed database
which is used in the module of lexical trans-
fer. The database contains data shared among
multiple devices and provides their automatic
synchronization.
1 Introduction
In Europe, machine translation (MT) is very impor-
tant due to the amount of languages spoken there.
In the European Union, for example, there are more
then 20 official languages. Some of them have very
few native speakers and it is quite problematic for
institutions and companies to find enough transla-
tors for comparatively rare language pairs, such as
Danish-Maltese. We have developed an experimen-
tal MT system for Central and East European lan-
guages which is in detail presented in (Homola and
Kubon?, 2004); at the moment, we have resources for
German, Polish, Czech, Slovak and Russian. As the
languages are syntactically and, except of German,
lexically related, the system is rule-based. All com-
ponents of the system are implemented in Objective-
C (ObjC) and have been ported to the iPhone.
2 Architecture of the MT System
The basic version of the system consists of the fol-
lowing modules:
?The research presented in this paper has been supported by
the grant No. 1ET100300517 of the GAAV C?R.
Morphological analyzer. Since the languages have
rich inflection, a word has usually many different
endings that express case, number, person etc. It is
necessary to assign a lemma and a set of morpholog-
ical tags to each word form.
Shallow parser. The parser analyzes constituents of
the source sentence, but not necessarily whole sen-
tences.
Lexical and structural transfer. The lexical trans-
fer provides a lemma-to-lemma or a term-to-term
translation. The structural transfer adapts the syn-
tax of the phrases so that they are grammatical in
the target language.
Morphological synthesis of the target language.
This final phase generates proper word forms in the
target language.
The shallow parser uses the dynamic algorithm
described in (Colmerauer, 1969) with feature struc-
tures being the main data structure. The hand-
written rules are fully declarative and defined in the
LFG format (Bresnan, 2001), i.e., they consist of
a context-free rule and a set of unificational con-
ditions. The transfer (lexical and structural) is fol-
lowed by the syntactic and morphological synthe-
sis, i.e., the syntactic structures which represent the
source sentences are linearized and proper morpho-
logical forms of all words are generated, according
to the tag associated with them.
3 Lexical Transfer
The dictionaries are sub-components of the transfer
module. Their task is to provide lexical translation
of constituents analyzed by the shallow parser. The
dictionary contains translation pairs for words and
27
phrases. Most items contain an additional morpho-
logical or syntactic information such as gender, va-
lence frames etc.
The creation of the dictionaries is a very time-
consuming task and they can never cover the com-
plete lexicon of a language. In a production environ-
ment, it is inevitable to add new items to the database
as new texts are processed. The typical workflow is
as follows:
1. During the translation of a document (possibly
on a mobile device), unknown words or phrases are
found. In the translation, they appear in the source
form since the system does not know how to process
them. After the processing of the whole document,
all found unknown words are added to the database
with a remark that the words are new to the system.
2. The new items are transmitted to the computer of
a translator whose task is to translate them. More-
over, most items will be assigned a morphological or
syntactico-semantical annotation for the structural
transfer.
3. The manually updated items are distributed to all
instances of application, i.e., to all devices the MT
system is installed on, so that they are available for
future use by all users of the system.
The capacity of the used mobile device is suffi-
cient to store the lexicon persistently but one could
run into problems trying to keep the whole lexicon
in memory. For this reason, we use a ternary tree as
an index which is kept in memory while full items of
the lexicon are loaded from a persistent repository at
the moment they are needed.
4 Distributed Database
The database can be used on multiple devices and
it is synchronized automatically, i.e., an update of
an object is transmitted to all other instances of the
database. The synchronization can be deferred if the
modifier or the receiver of the update are offline. In
such a case, the database is synchronized as soon as
the device with the database has access to the inter-
net. Due to the offline synchronization, synchroniza-
tion conflicts can arise if two or more users update an
object simultaneously. If the users have changed dif-
ferent properties of the same object, the changes are
merged automatically. Otherwise, the administrator
of the database has to resolve the conflict manually.
The distributed database consists of the following
components:
Object repository. A local repository of ObjC ob-
jects so that the database is accessible even if there
is no internet connection.
Transceiver. A communication module that
sends/receives updates to/from the relay server. It
includes a local persistent cache for updates which
is used if there is no internet connection.
Relay server. A server that accepts updates and dis-
tributes them to other instances of the database. This
component ensures that the database is synchronized
even if two or more users are never online at the
same time.
It is noteworthy that there is no replica of the
database on the server, it only serves as a tempo-
rary repository for updated records that cannot be
synchronized immediately because a receiving de-
vice may be offline at the moment another device has
committed an update (this is the expected situation
for mobile devices such as PDAs and smartphones).
Currently, the distributed database is being used
as a collaboration platform in the Czech Broadcast-
ing Company (C?esky? rozhlas).
5 Conclusions
We have presented an experimental MT system that
works on the iPhone and described how it uses a
distributed object database with automatic synchro-
nization to keep the lexicon of the system up-to-date
on all devices it is installed on. We believe that the
presented database is an effective way to keep fre-
quently updated data up-to-date on multiple comput-
ers and/or mobile devices. The system is developed
in Objective-C thus the code base can be used on the
iPhone and on Macs, and it can be easily ported to
systems for which the GNU C Compiler is available.
References
Joan Bresnan. 2001. Lexical-Functional Syntax. Black-
well Publishers, Oxford.
Alain Colmerauer. 1969. Les syste`mes Q ou un formal-
isme pour analyser et synthe?tiser des phrases sur ordi-
nateur. Technical report, Mimeo, Montre?al.
Petr Homola and Vladislav Kubon?. 2004. A translation
model for languages of acceding countries. In Pro-
ceedings of the EAMT Workshop, Malta.
28
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 33?36,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
A Simple Automatic MT Evaluation Metric
Petr Homola
Charles University
Prague, Czech Republic
Vladislav Kubon?
Charles University
Prague, Czech Republic
{homola|vk|pecina}@ufal.mff.cuni.cz
Pavel Pecina
Charles University
Prague, Czech Republic
Abstract
This paper describes a simple evaluation
metric for MT which attempts to overcome
the well-known deficits of the standard
BLEU metric from a slightly different an-
gle. It employes Levenshtein?s edit dis-
tance for establishing alignment between
the MT output and the reference transla-
tion in order to reflect the morphological
properties of highly inflected languages. It
also incorporates a very simple measure
expressing the differences in the word or-
der. The paper also includes evaluation on
the data from the previous SMT workshop
for several language pairs.
1 Introduction
The problem of finding a reliable machine trans-
lation metrics corresponding with a human judg-
ment has recently returned to the centre of atten-
tion. After a brief period following the introduc-
tion of generally accepted and widely used met-
rics, BLEU (Papineni et al, 2002) and NIST (Dod-
dington, 2002), when it seemed that this persistent
problem has finally been solved, the researchers
active in the field of machine translation (MT)
started to express their worries that although these
metrics are simple, fast and able to provide con-
sistent results for a particular system during its de-
velopment, they are not sufficiently reliable for the
comparison of different systems or different lan-
guage pairs.
The results of the NIST evaluation in 2005
(Le and Przybocki, 2005) have also strengthened
the suspicion that the correlation between human
judgment and the BLEU and NIST measures is not
as strong as it was widely believed. Both mea-
sures seem to favor the MT output created by sys-
tems based on n-gram architecture, they are un-
able to take into account certain factors which are
very important for the human judges of translation
quality.
The article (Callison-Burch et al, 2006) thor-
oughly discusses the deficits of the BLEU and
similar metrics. The authors claim that the existing
automatic metrics, including some of the new and
seemingly more reliable ones as e.g. Meteor (cf.
(Banerjee and Lavie, 2005)) ?. . . they are all quite
rough measures of translation similarity, and have
inexact models of allowable variation in transla-
tion.? This claim is supported by a construction of
translation variations which have identical BLEU
score, but which are very different for a human
judge. The authors identify three prominent fac-
tors which contribute to the inadequacy of BLEU ?
the failure to deal with synonyms and paraphrases,
no penalties for missing content, and the crudeness
of the brevity penalty.
Let us add some more factors based on our ex-
periments with languages typologically different
than English, Arabic or Chinese, which are prob-
ably the languages most frequently used in recent
shared-task MT evaluations. The highly inflected
languages and languages with a higher degree of
word-order freedom may provide additional ex-
amples of sentences in which relatively small al-
terations of correct word forms may have a dire
effect on the BLEU score while the sentence still
remains understandable and acceptable for human
evaluators.
The effect of rich inflection has been observed
for example in (Ty?novsky?, 2007), where the au-
thor mentions the fact that the BLEU score used
for measuring the improvements in his experimen-
tal Czech-German EBMT system penalized heav-
ily all subtle errors in Czech morphology arising
from an out-of-context combined partial transla-
tions taken from different examples.
The problem of the insensitivity of BLEU to the
variations of the order of n-grams identified in ref-
erence translations has already been mentioned in
33
the paper (Callison-Burch et al, 2006). The au-
thors showed examples where changing a good
word order into an unacceptable one did not af-
fect the BLEU score. We may add a different ex-
ample documenting the phenomenon that a pair
of syntactically correct Czech sentences with the
same word forms, differing only in the word order
whose n-gram score for n = 2, 3, and 4 differs
greatly. Let us take one of the sentences from the
2008 SMT workshop and its reference translation:
When Caligula appointed his horse to the Sen-
ate, the horse at least did not have blood on its
hoofs. ? Kdyz? Caligula zvolil do sena?tu sve?ho
kone?, neme?l jeho ku?n? aspon? na kopytech krev.
If we modify the Czech reference sentence into
Kdyz? sve?ho kone? do sena?tu zvolil Caligula, jeho
ku?n? aspon? neme?l na kopytech krev., we destroy 8
out of 15 bigrams, 11 out of 14 trigrams and 12
out of 13 quadrigrams while we still have sentence
with almost identical meaning and probably very
similar human evaluation. The BLEU score of the
modified sentence is, however, lower than it would
be for the identical copy of the reference transla-
tion.
2 The description of the proposed metric
There is one aspect of the problem of a MT
quality metric which tends to be overlooked but
which is very important from the practical point
of view. This aspect concerns the expected diffi-
culties when post-editing the MT output. It is very
important for everybody who really wants to use
the MT output and who faces the decision whether
it is better to post-edit the MT output or whether a
new translation made by human translators would
be faster and more efficient way towards the de-
sired quality. It is no wonder that such a met-
ric is mentioned only in connection with systems
which really aim at practical exploitation, not with
a majority of experimental MT system which will
hardly ever reach the stage of industrial exploita-
tion.
We have described one example of such practi-
cally oriented metric in (Hajic? et al, 2003). The
metric exploits the matching algorithm of Trados
Translator?s Workbench for obtaining the percent-
age of differences between the MT output and the
reference translation (created by post-editing the
MT output). The advantage of this measure is its
close connection to the real world of human trans-
lating by means of translation memory, the disad-
vantage concerns the use of a proprietary match-
ing algorithm which has not been made public and
which requires the actual use of the Trados soft-
ware.
Nevertheless, the matching algorithm of Trados
gives results which to a great extent correspond
to a much simpler traditional metric, to the Lev-
enshtein?s edit distance. The use of this metric
may help to refine a very strict treatment of word-
form differences by BLEU. A similar approach at
the level of unigram matching has been used by
the well-known METEOR metric (Agarwal and
Lavie, 2008), which proved its qualities during the
previous MT evaluation task in 2008 (Callison-
Burch et al, 2008). Meteor uses Porter stemmer
as one step in the word alignment algorithm. It
also relies on synonymy relations in WordNet.
When designing our metric, we have decided to
follow two general strategies ? to use as simple
means as possible and to avoid using any language
dependent tools or resources. Levenshtein metric
(or its modification for word-level edit distance)
therefore seemed to be the best candidate for sev-
eral aspects of the proposed measure.
The first aspect we have decided to include was
the inflection. The edit distance has one advan-
tage over the language independent stemmer ? it
can uniformly handle the differences regardless of
their position in the string. The stemmer will prob-
ably face certain problems with changes inside the
stem as e.g. in the Czech equivalent of the word
house in different cases du?m (nom.sg) ? domu
(gen., dat. or loc. sg.) or German Mann in differ-
ent numbers der Mann (sg.) ? die Ma?nner (pl.),
while the edit distance will treat them uniformly
with the variation of prefixes, suffixes and infixes.
As mentioned above, we have also intended to
aim at the treatment of the free word order in our
metric. However this seems to be one of the ma-
jor flaws of the BLEU score, it turned out that the
word order is extremely difficult if we stick to the
use of simple and language independent means. If
we take Czech as an example of a language with
relatively high degree of word-order freedom, we
can still find certain restrictions (e.g. the sentence-
second position of clitics, their mutual order, the
adjectives typically, but not always preceding the
nouns they depend upon etc.) which will defi-
nitely influence the human judgment of the accept-
ability of a particular sentence. These restrictions
are language dependent (for example Polish, the
34
language very closely related to Czech, has dif-
ferent rules for congruent attributes, the adjectives
stand much more often to the right of the govern-
ing noun) and they are also very difficult to capture
algorithmically. If the MT output is compared to
a single reference translation only, there is, in fact,
no way how the metric could account for the pos-
sible correct variations of the word order without
exploiting very deep language dependent informa-
tion. If there are more reference translations, it is
possible that they will provide the natural varia-
tions of the word order, but it, in fact, means that
if we want to stick to the above mentioned require-
ments, we have to give up the hope that our metric
will capture this important phenomenon.
2.1 Word alignment algorithm
In order to capture the word form variations
caused by the inflection, we have decided to em-
ploy the following alignment algorithm at the level
of individual word forms. Let us use the follow-
ing notation: Let the reference translation R be a
sequence of words ri, where i ?< 1, . . . , n >.
Let the MT output T be a sequence of words tj,
where j ?< 1, . . . ,m >. Let us also set a thresh-
old of similarity s ?< 0, 1 >. (s roughly ex-
presses how different the forms of a lemma may
be. The idea behind this criterion is that a mistake
in one morphological category (reflected mostly
by a different ending of the corresponding word
form) is not as serious as a completely different
lexeme. This holds especially for morphologically
rich languages that can have tens or even hun-
dreds of distinct word forms for a single lemma.)
Starting from t1, let us find for each tj the best
ri for i ?< 1, . . . , n > such that the edit dis-
tance dj from tj to ri normalized by the length
of tj is minimal and at the same time dj < s.
If the ri is already aligned to some tk, k < j
and the edit distance dk > dj , then align tj to
ri and re-calculate the alignment for tk to its sec-
ond best candidate, otherwise take the second best
candidate rl conforming with the above mentioned
conditions and align it to tj . As a result of this
process, we get the alignment score ATR from T
to R. ATR =
?
(1?di)
m (for i ?< 1, . . . , n >)
where di = 1 for those word forms ti which are
not aligned to any of the word forms rj from R.
Then we calculate the alignment score ART using
the same algorithm and aligning the words from R
to T. The similarity score S equals the minimum
from ATR and ART . The way how the similar-
ity score S is constructed ensures that the score
takes into account a difference in length between
T and R, therefore it is not necessary to include
any brevity penalty into the metric.
2.2 A structural metric
In order to express word-order difference between
the MT output and the reference translation we
have designed a structural part of the metric. It
is based on an algorithm similar to one of the stan-
dard sorting methods, an insert sort. The refer-
ence translation R represents the desired word or-
der and the algorithm counts the number of op-
erations necessary for obtaining the correct word
order from the word order of the MT output T by
inserting the words ti to their desired positions rj
(ti is aligned to rj). If a particular word ti is not
aligned to any rj , a penalty of 1 is added to the
number of operations.
2.3 A combination of both metrics
The overall score is computed as a weighted aver-
age of both metrics mentioned above. Let L be the
lexical similarity score and M the structural score
based on a word mapping. Then then overall score
S can be obtained as follows:
S = aL+ bM
The coefficients a and b must sum up to one.
They allow to capture the difference in the degree
of word-order freedom among target languages.
The coefficient b should be set lower for the tar-
get languages with more free word-order. Because
both then partial measures L andM have values in
the interval < 0, 1 >, the value of S will also fall
into this interval.
3 The experiment
We have performed a test of the proposed met-
ric using the data from the last year?s SMT work-
shop.1 The parameters a, b, and s have been set to
the same value for all evaluated language pairs, no
language dependent alterations were tested in this
experiment:
Parameter Value
s 0.15
a 0.9
b 0.1
1The data are available at http://www.statmt.org/wmt08.
35
The values for the parameters have been set up
empirically with special attention being paid to
Czech, the only language with really rich inflec-
tion among the languages being tested.
We have performed sentence-level and system-
level evaluation using the Spearman?s rank corre-
lation coefficient which is defined as follows:
? = 1?
6
?
d2i
n(n2 ? 1)
where di = xi?yi is the difference between the
ranks of corresponding values Xi and Yi and n is
the number of values in each data set.
The following scores express the correlation of
our automatic metric and the human judgements
for the language pairs English-Czech and English-
German. The sentence-level correlation ?sent is
the average of Spearman?s ? across all sentences.
Language pair Metric ?sent ?sys
English-Czech proposed 0.20 0.50
English-Czech BLEU 0.21 0.50
English-German proposed 0.91 0.37
English-German BLEU 0.90 0.20
3.1 Conclusions
The metric presented in this paper attempts to
combine some of the important factors which
seem to be neglected by some generally accepted
MT evaluation metrics. Inspired by the fact that
human judges tend to accept incorrect word-forms
of corectly translated lemmas, it employs a simi-
larity measure relaxing the requirements on iden-
tity (or similarity) of matching word forms in the
MT output and the reference translation. At the
same time, it also incorporates a penalty for dif-
ferent length of the MT output and the reference
translation. The second component of the metric
tackles the problem of incorrect word-order. The
constants used in the metric allow to set the weight
of its two components with regard to the target lan-
guage properties.
The experiments performed on the data from
the previous shared evaluation task are promising.
They indicate that the first component of the met-
ric succesfully replaces the strict unigram mea-
sure used in BLEU while the second component
may require certain alteration in order to achieve a
higher correlation with human judgement.
Acknowledgments
The presented research has been supported by the
grant No. 1ET100300517 of the GAAV C?R and
by Ministry of Education of the Czech Republic,
project MSM 0021620838.
References
Abhaya Agarwal and Alon Lavie. 2008. Meteor,
M-BLEU and M-TER: Evaluation metrics for high
correlation with human rankings of machine trans-
lation output. In Proceedings of the Third Work-
shop on Statistical Machine Translation, pages 115-
118. Columbus, Ohio, Association for Computa-
tional Linguistics.
Satanjeev Banerjee and Alon Lavie. 2005. Meteor: An
automatic metric for MT evaluation with improved
correlation with human judgments.. In Workshop
on Intrinsic and Extrinsic Evaluation Measures for
MT and/or Summarization, Ann Arbor, Michigan.
Chris Callison-Burch, Miles Osborne, Philipp Koehn.
2006. Re-evaluating the Role of BLEU in Ma-
chine Translation Research.. In Proceedings of the
EACL?06, Trento, Italy.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, Josh Schroeder. 2008.
Further Meta-Evaluation of Machine Translation..
In Proceedings of the Third Workshop on Statisti-
cal Machine Translation, pages 70-106, Columbus,
Ohio. Association for Computational Linguistics.
George Doddington. 2002. Automatic evaluation
of machine translation quality using n-gram co-
occurrence statistics. In Proceedings of the second
international conference on Human Language Tech-
nology Research, San Diego, California,USA
Jan Hajic?, Petr Homola, Vladislav Kubon?. 2003. A
Simple Multilingual Machine Translation System..
In Proceedings of the MT Summit IX, New Orleans,
USA.
Kishore Papineni, Salim Roukos, ToddWard, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic eval-
uation of machine translation.. In Proceedings of
ACL 2002.
Audrey Le and Mark Przybocki. 2005. NIST 2005
machine translation evaluation official results.. Of-
ficial release of automatic evaluation scores for all
submissions.
Miroslav Ty?novsky?. 2007. Exploitation of Linguis-
tic Information in EBMT.. Master thesis at Charles
University in Prague, Faculty of Mathematics and
Physics.
36
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 74?81,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Annotation of Sentence Structure;
Capturing the Relationship among Clauses in Czech Sentences
Marke?ta Lopatkova? and Natalia Klyueva and Petr Homola
Charles University in Prague, Institute of Formal and Applied Linguistics
Malostranske? na?m. 25, 118 00 Prague 1, Czech Republic
{lopatkova,kljueva,homola}@ufal.mff.cuni.cz
Abstract
The goal of the presented project is to as-
sign a structure of clauses to Czech sen-
tences from the Prague Dependency Tree-
bank (PDT) as a new layer of syntactic an-
notation, a layer of clause structure. The
annotation is based on the concept of seg-
ments, linguistically motivated and easily
automatically detectable units. The task
of the annotators is to identify relations
among segments, especially relations of
super/subordination, coordination, apposi-
tion and parenthesis. Then they identify
individual clauses forming complex sen-
tences.
In the pilot phase of the annotation, 2,699
sentences from PDT were annotated with
respect to their sentence structure.
1 Motivation
Syntactic analysis of natural languages is the
fundamental requirement of many applied tasks.
Parsers providing automatic syntactic analysis are
quite reliable for relatively short and simple sen-
tences. However, their reliability is significantly
lower for long and complex sentences, especially
for languages with free word order; see, e.g., Ze-
man (2004) for results for Czech.
The identification of the overall structure of
a sentence prior to its full syntactic analysis is
a natural step capable to reduce the complex-
ity of full analysis. Such methods brought good
results for typologically different languages, see
e.g. Jones (1994) for English or Ohno et al (2006)
for Japanese.
The goal of the presented project is to annotate
a structure of clauses to Czech sentences from the
Prague Dependency Treebank. The main idea is to
reuse the already existing language resource and to
enrich it with a new layer of annotation, a layer of
clause structure.
We exploit a concept of segments, easily auto-
matically detectable and linguistically motivated
units, as they were defined by Lopatkova? and
Holan (2009).1 The annotation captures relation-
ship among segments, especially subordination,
coordination, apposition and parenthesis. Based
on segment annotation, the annotators identify
clauses forming (complex) sentences: they group
the segments constituting individual clauses of
complex sentences.
Contrary to such well known approaches as e.g.
chunking, see Abney (1991) or cascaded parsing,
see Abney (1995) or Ciravegna and Lavelli (1999),
which group individual tokens into more complex
structures as nominal or prepositional phrases, i.e.,
in a bottom-up direction, the proposed approach
aims at determining a hierarchy of sentence parts
in a ?top-down? way. Such an approach is quite
novel not only for Czech, it has not been reported
for other Slavic languages.
Prague Dependency Treebank2 (PDT), see Hajic?
et al (2006) is a large and elaborated corpus
with rich syntactic annotation of Czech newspaper
texts. As the dependency-based framework has
been adopted for PDT, the treebank contains ex-
plicit information on mutual relations among in-
dividual tokens (words and punctuation marks).
However, relations among more complex units,
esp. clauses, are not explicitly indicated, see Fig-
ure 1.
Syntactic information stored in PDT can be
used (at least to some extent) for the identification
of individual clauses as well. Let us refer to the
experiments described in the papers by Lopatkova?
and Holan (2009) and Kru?za and Kubon? (2009). In
both papers, the authors designed well-developed
procedures for identifying segments and their mu-
1We adopt the basic idea of segments introduced and used
by Kubon? (2001) and Kubon? et al (2007). We slightly modify
it for the purposes of the annotation task.
2http://ufal.mff.cuni.cz/pdt2.0/
74
Figure 1: Analytic tree of the sentence Poc?a?tec?n??
nejistota, jak obstoj??, zmizela. ?Initial uncertainty,
how it-will-do, vanished.?
tual relationship from the analytical layer of PDT
(i.e., layer of surface syntax). However, they ei-
ther do not identify individual clauses in the com-
plex sentence at all, or their procedural definition
of clause does not exactly model what a human
would consider as a clause.
The previous experiments brought clear speci-
fication of segmentation charts describing the re-
lation among individual segments. The results
showed that for further research it is necessary to
work with a large set of precisely annotated data.
It has turned out that such data cannot be obtained
without extensive (semi)manual annotation of a
large set of sentences, see Lopatkova? and Holan
(2009) and Kru?za and Kubon? (2009).
In this article, we present a project of man-
ual annotation of sentence structure for complex
Czech sentences. In Section 2, we introduce the
basic concepts, esp. boundaries, segments and
segmentation charts. Then we focus on the anno-
tation of basic linguistic phenomena (Section 3).
Section 4 brings specification of a data format and
an editor used for the annotation. Lastly, basic
statistics of the annotated data are presented (Sec-
tion 5).
2 Boundaries, Segments and
Segmentation Charts
The aim of the annotation is to explicitly describe
relations among clauses of (complex) Czech sen-
tences. We focus on the annotation of (part of)
Czech sentences from PDT. We take advantage
of morphological analysis (m-layer) and partially
also surface syntactic analysis (a-layer) stored in
PDT.
All tokens from PDT are disjunctively divided
into two groups ? ordinary words and segment
boundaries. Segment boundaries are tokens and
their sequences that divide a sentence into indi-
vidual units referred to as segments. As segment
boundaries, the following tokens are considered:
? punctuation marks: comma, colon, semi-
colon, question mark, exclamation mark,
dash (all types), opening and closing bracket
(all kinds), and quotation mark (all types);
? coordinating conjunctions: tokens morpho-
logical tag of which starts with the pair J?
(e.g., a ?and?, ale ?but?, nebo ?or?, nebot? ?for?,
ani ?nor?), see Hajic? (2004).
After the identification of boundaries, the in-
put sentence is partitioned into individual seg-
ments ? a segment is understood as a maximal
non-empty sequence of tokens that does not con-
tain any boundary.
This concept of the linear segment serves as a
good basis for the identification of clauses, basic
linguistically motivated syntactic units. We will
see that a single clause consists of one or more
segments; one or more clauses then create(s) a
complex sentence (see Section 3).
The definition of segments adopted in this
project is based on very strict rules for punctuation
in Czech. Generally, beginning and end of each
clause must be indicated by a boundary, i.e., sen-
tence boundary (usually fullstop, question mark or
exclamation mark), punctuation (mostly comma)
or conjunction. This holds for embedded clauses
as well. In particular, there are only very few ex-
ceptions to a general rule saying that there must be
some kind of a boundary between two finite verb
forms of meaningful verbs.
Segmentation Charts and Clauses
Relations between clauses, esp. super- or sub-
ordination, coordination, apposition or parenthe-
sis, are described by so called segmentation charts
(one or more, if we allow for ambiguous annota-
tion) ? segmentation chart captures the levels of
embedding for individual segments, as described
below.
75
The principal idea of the segmentation chart is
quite clear ? it can be described by the follow-
ing basic instructions. (In examples, segments are
marked by square brackets [ and ]k, where k is a
level of embedding. In addition, individual clauses
are marked by brackets { and }j , where j is an in-
dex of a particular clause.)
Main clauses. Segments forming all main
clauses3 of a complex sentence belong to the basic
level (level of embedding 0), as in the following
sentence.
{[O studium byl velky? za?jem]0}1, {[v pr?ij??mac??ch
pohovorech bylo vybra?no 50 uchazec?u?]0}2. ?There
was a lot of interest in studying, 50 applicants
were selected in admission interviews.?
Dependent clauses. Segments forming clauses
that depend on clauses at the k-th level obtain level
of embedding k + 1 (i.e., the level of embedding
for subordinated segments is higher than the level
of segments forming their governing clause).
{[Potom zjist??te]0}1, {[ z?e va?m nikdo neda? vstup-
n?? v??zum]1}2. ?Then you realize that nobody gives
you entrance visa.?
Coordination and apposition. Segments forming
coordinated sentence members and coordinated
clauses occupy the same level. The same holds
for apposition.
{[Hra na?m jde]0}1 a {[forma stoupa?]0}1. ?We?re
getting on well in game and our form improves.?
Parenthesis. Segments forming parenthesis
(e.g., sequence of wordforms within brackets) ob-
tain the level of embedding k + 1 if the level of
their neighboring segments is k .
{[Na?vrh mluv?? o dvou letech u muz?u?]0 ( {[zvys?uje
ve?k z 60 na 62]1}1 ) a [o c?tyr?ech letech u z?en]0}2.
?The proposal mentions two years for men (it
raises the age from 60 to 62) and four years for
women.?
Although this basic idea of segmentation charts
seems simple, it appears that ? working with ?real
data? from newspaper corpus ? detailed annota-
tion guidelines are necessary for good and con-
sistent annotation of specific linguistic phenomena
and especially for their combination. We focus on
some of them in the following section.
3As a main clauses, such clauses are considered that are
syntactically / formally independent, see also Section 3.
3 Annotation of Complex Sentences
Segments can be divided into two main groups,
mutually independent and mutually related seg-
ments.
Mutually independent segments. Mutually
independent segments are, e.g., segments forming
two dependent clauses, each of them modifying
(different) part of the main clause, as segments
do ktere? se zamiloval ?with whom he felt in love?
and ktery? zazvonil ?that rang? in the following
sentence.
{[Marie]0, {[do ktere? se zamiloval]1}1, {[kdyz?
ji potkal]2}2, [zvedla telefon]0}3, {[ktery?
zazvonil]1}4. ?Mary, with whom he felt in
love when he met her, answered the phone that
rang.?
Such segments can have the same level of em-
bedding (as the above mentioned segments) or
they can belong to clauses with different levels of
embedding (as segments kdyz? ji potkal ?when he
met her? and ktery? zazvonil ?that rang?).
Mutually related segments. Mutually related
segments either belong to different levels of em-
bedding ? they are super- or subordinated, we fo-
cus on this group in the following Section 3.1, or
they have the same level of embedding ? this type
is described in Section 3.2.
Let us stress here that the segment annotation
is based on formally expressed structures rather
than on their semantic interpretation. For exam-
ple, we do not interpret text enclosed in brackets
? whether it is semantically apposition, sentence
member or independent sentence part, see also the
discussion in Kubon? et al (2007). We annotate
such text as parenthetical segment(s) on a lower
level compared to the neighboring segments.
The annotators have been instructed to disam-
biguate annotated sentences ? if more readings of
a particular sentence are possible, they should re-
spect the reading rendered in PDT.
3.1 Subordination and Superordination
The super- or subordinated mutually related seg-
ments capture primarily relations between gov-
erning and dependent clauses.
Identification of subordinated status of a par-
ticular segment is based on morphological prop-
erties of tokens forming this segment, i.e., on the
presence of a token with ?subordinating function?.
76
?Subordinating tokens? are especially of the fol-
lowing types:
? subordinating conjunctions (e.g., aby ?in or-
der that?, dokud ?till?, kdyby ?if?, protoz?e ?be-
cause?, pr?estoz?e ?although?, z?e ?that?);
? relative/interrogative pronouns and some
types of numerals (e.g., kdo ?who?, co ?what?,
jaky? ?which?, kolik ?how many?);
? pronominal adverbs (e.g., kde ?where?, kdy
?when?, jak ?how?, proc? ?why?).
In Czech, a subordinating token is usually at the
beginning of the segment, as in the following sen-
tence (marked pronoun ktery? ?who? serves as sub-
ordinating token here).
{[Klejch]0 , {[ktery? dal deve?t ze dvana?cti ligovy?ch
go?lu? Zl??na]1}1 , [ma? vydatne? pomocn??ky]0}2. ?Kle-
jch who scored nine goals out of twelve for Zl??n
has good helpers.?
A particular subordinated segment can precede
or follow its superordinated segment or it can be
placed between two superordinated segments (in
case of a governing clause with embedded depen-
dent clause, as in the previous example).
In addition to governing and dependent clauses,
there are also other constructions that should evi-
dently be captured as subordinated segments, es-
pecially:
? Segments representing direct speech:
,,{[ Kupr???kladu za?vod Ejpovice projevil za?jem
dokonce o 150 pracovn??ku?]1}1,?{[ uvedl
Ladislav Vltavsky?]0}2. ? ?For example
Ejpovice company showed interest in 150
workers,? said Ladislav Vltavsky?.?
? Some types of parenthesis, esp. those
marked by brackets:
{[Guido Reni]0 ( {[1575 az? 1642]1}1 [byl
vynikaj??c?? figuralista]0}2. ?Guido Reni (1575
to 1642) was an outstanding figural painter.?
In such cases, parenthetical expressions are
captured as separate clauses even if they con-
sist of fragmental expression.
3.2 Segments on the Same Level and
Identification of Clauses
We can identify three main groups of structures
where segments are mutually related and they
share the same level of embedding:
? segments forming a clause with embedded
dependent clause, as the attributive depen-
dent clause in the following example.
{[V pr???pade?]0, {[z?e se nedovola?te]1}1,
[vytoc?te c???slo ve vec?ern??ch hodina?ch
znovu]0}2. ?In case that you will not succeed,
redial the number again in the evening.?
? coordinated segments (see the corresponding
section below);
? others, esp. segments in apposition and some
types of parenthesis (see the corresponding
section below).
In particular, segments on the same level ? un-
like the super/subordinated ones ? can form a sin-
gle clause. For the annotators, the important task
is to identify individual clauses. They group those
segments that constitute individual clauses of a
complex sentence and thus mark them as a sin-
gle syntactic unit of a higher level, level of clause
structures. (Let us recall that clauses are marked
here by brackets { and }j where j is an index of a
particular clause).
Coordination of sentence members and
coordination of clauses
The relation of coordination may occur between
two (or more) sentence members or between two
(or more) clauses, be they main clauses or depen-
dent ones. The syntactic position of coordinated
units is ?multiplied?, that is, they share the same
syntactic relations to other sentence members. The
annotators have to identify segments containing
coordinated sentence members and put them to-
gether into a single clause; coordinated clauses are
marked as separate clauses sharing the same level
of embedding,4 as in the following sentence.
{[C?esky? prezident apeloval na C?echy]0 a [na
Ne?mce]0}1, {[aby odpove?dne? zacha?zeli s min-
ulost??]1}2 a {[aby posouvali vpr?ed dialog]1 a
[spolupra?ci.]1}3 ?Czech president appealed to
Czechs and Germans that they should treat their
history responsibly and improve their mutual di-
alogue and cooperation.? This complex sentence
consists of five segments (marked by [ and ]),
which form three clauses (marked by { and }),
namely one main clause (on the zero level) and
two coordinated dependent clauses (first embed-
ded level), see also Figure 3.
4In PDT, coordination of sentence members and coordina-
tion of clauses are not distinguished (at the analytical layer).
77
Segmentation is purely linear (on segment fol-
lows another); after the identification of segments,
they are grouped into the clauses. As we have
seen, a single clause consists (prototypically) of
one or more segments. This is fully true for se-
mantically and syntactically complete sentences,
i.e. sentences without ellipses of different kinds.
Let us mention one construction where clauses
identified by the annotators (i.e., clauses based on
segments) do not conform with the linguistic intu-
ition, namely the case of coordinated clauses shar-
ing one (or more) sentence member(s) or a syntac-
tic particle. We interpret such cases as cases of el-
lipses, i.e., a shared sentence member or particle is
supposed to belong only to one of the clauses and
to be elided in the second clause. Thus a shared
sentence member or particle is annotated only as a
part of one clause.
{[Neopravuje se]0}1 a {[neinvestuje]0}2, {[pen??ze
stac??? jen na be?z?ny? provoz]0}1. ?They do not ren-
ovate nor invest, there is enough money only for
routine operation.? (The underlined reflexive par-
ticle belongs to both verbs opravovat ?to reno-
vate? and investovat ?to invest? (reflexive passive
forms of the verbs); in the segmentation chart, it is
marked as a part of the first clause Neopravuje se
and elided in the second clause neinvestuje.)
On the other hand, a basic rule was adopted say-
ing that a single finite verb form indicates a single
clause, i.e., verb constitutes (a core of) a sentence5
(providing that other formal labels as, e.g., brack-
ets do not indicate more levels). This rule implies
that if the shared sentence member is a predicate,
then the particular segments are joined together
into a single clause, as in the following example.
{[Petr pr?is?el vc?era]0 a [babic?ka dneska]0}1. ?Petr
came yesterday and my grandma today.?
Other constructions
Apposition is a construction where the same
?idea? is rendered in different ways (the latter be-
ing an explanatory equivalent of the former), both
having the same syntactic relation to other sen-
tence members (e.g., a name and a function of par-
ticular person, as in the following sentence).
{[Ozna?mil to Va?clav Havel]0, [president C?eske?
republiky]0}1. ?It was announced by Va?clav
Havel, president of the Czech Republic.?
Following PDT, apposition is treated in the
same way as coordination as the members of an
5The account for this decision lies in the verb-centric
character of dependency syntax traditionally used for Czech.
apposition are considered to share (multiple) syn-
tactic position in a sentence (like in the case of
coordination).
Contrary to PDT, parenthesis without ex-
plicit/unambiguous formal mark, as e.g. brackets,
is annotated as segment(s) on the same level as
its/their neighboring segments.
{[Pr?ed smrt??]0, {[nezna?mo proc?]0}1, [si koupil
tramvajenku]0}2. ?Before dying, nobody knows
why, he bought a tram pass.?
Again, parenthetical expressions are captured as
separate clauses even if they consist of fragmental
expression.
Semi-direct speech, i.e., direct speech without
quotation marks (or other formal label(s)) is anno-
tated as segment(s) on the same level as the seg-
ment containing a governing verb. The reason is
quite evident ? there is no formally expressed indi-
cation of subordination in the segment(s) creating
a semi-direct speech.
{[Pr?ijde pozde?ji]0}1, {[ohla?sil doma Pavel]0}2. ?I
will be late, said Pavel.?
4 Data Format and Editor for Segment
Annotation
4.1 PML Data Format
The Prague Markup Language6 (PML), see Pa-
jas and S?te?pa?nek (2006) is an XML-based domain
language which has been developed and is used as
primary data format for PDT (version 2.0).
The PDT 2.0 data consist of one non-annotated
word layer (w-layer) and three layers of annota-
tion: morphological (m-layer), analytical (a-layer)
and tectogrammatical (t-layer). In PML, individ-
ual layers of annotation can be stacked one over
another in a stand-off fashion and linked together
as well as with other data resources in a consistent
way.
We use two layers in our annotation editor,
namely the m-layer and the a-layer. The m-layer
provides the word form, lemma and tag for every
token. The a-layer represents syntactic relations
between tokens, resulting in an analytical tree. For
the segment annotation, only information on ana-
lytical functions of tokens is used ? it helps the an-
notators in their decisions on the appropriate level
of embedding and in disambiguation if more read-
ings of a particular sentence are possible.
6http://ufal.mff.cuni.cz/pdt2.0/doc/pdt
-guide/en/html/ch03.html#a-data-formats
78
Figure 2: Class hierarchy of SegView annotation
editor.
The output of the segment annotation is stored
as a new layer of annotation, the seg-layer.
4.2 SegView Annotation Editor
The SegView annotation editor is implemented
completely in Java because of its cross-platformity
and availability of rich libraries. The presenta-
tion layer is implemented in the class MainWin-
dow using the standard Swing library. As for the
data layer, the editor works with files in the PML
format (see Section 4.1). The model represent-
ing the core of the implementation comprises three
classes: Sentence, Word and Segment, Figure 2.
After launching the editor, the user has the pos-
sibility to select multiple files to annotate. After
the selection, the program directly reads the files
and creates an internal representation with the in-
stances of the three aforementioned classes. The
manual annotation is saved in files with the exten-
sion .seg.
The screenshot of SegView editor is shown in
Figure 3.
5 Basic Statistics and Conclusion
We have described the pilot phase of the segment
annotation, during which 2,699 sentences from
PDT were annotated with respect to their sentence
structure.7 Table 1 summarizes the amount of an-
notated data and gives statistics on number of pro-
cessed segments and clauses.
The most frequent annotation patterns are pre-
sented in Table 2 showing the most common types
of sentences and relation among their clauses
(only patterns with more than 100 sentence in-
stances are listed).
7We have focused on the sentences from
data/full/amw/train2 portion of the PDT data.
# sentences 2,699
# segments 7,975
# clauses 5,003
max segments in clause 27
max clauses in sentence 11
max levels of embedding 4
Table 1: Basic statistics of the annotated texts.
sentences segments clauses max level
783 1 1 0
298 2 1 0
195 2 2 1
148 3 2 1
123 3 1 0
111 2 2 0
Table 2: Distribution of segments and clauses.
The most frequent type of annotated sentence
consists of one segment only (and thus one
clause), then comes the case where two segments
form a single clause. The third position is for sen-
tences with two segments, each forming an in-
dividual clause, where one of them depends on
the other). The fourth case represents sentences
formed by two clauses, one either depending on
the other or forming a parenthesis. The fifth and
sixth line represent sentences with segments on the
same level, e.i., with sentence members in coordi-
nation or apposition and with coordinated clauses,
respectively. (The most common cases listed in
the table represent 61.5% of the annotated sen-
tences; the rest has more complicated structures.)
Future work
We focus on the inter-annotator agreement on a
reasonable large set of data now to check the con-
sistency between the human annotators. Then the
annotation will continue ? the goal is to cover
10% of sentences from PDT with assigned sen-
tence structure.
We expect the use of the manually annotated
data for testing tools and hypotheses on possible
sentence structures. The proposed amount of data
is comparable with the standard PDT testing data.
We do not foreseen the use of this set of segmen-
tation charts for training statistically-based tool(s)
for an automatic identification of sentence struc-
tures.
The set of precisely annotated data allows us
to solidly compare and evaluate the already ex-
isting automatic segmentation tools processing ei-
ther the raw texts or syntactically annotated trees,
see Kru?za and Kubon? (2009) and Lopatkova? and
79
Figure 3: SegView editor: The segmentation chart for sentence ?According to the General-Anzeiger,
Czech president appealed to Czechs and Germans that they should treat their history responsibly and
improve their mutual dialogue and cooperation.? (clauses marked by ellipses).
Holan (2009). These data also allow us to search
for systemic differences between the manual and
automatic sentence structure annotation. Then the
possibility of further improving the tools will be
opened.
The use of data with automatically annotated
sentence structure in machine translation sys-
tem among related languages, as in Homola and
Kubon? (2008), is also foreseen.
Acknowledgements
This paper presents the results of the grant
of the Grant Agency of Czech Republic
No. 405/08/0681. The research is carried
out within the project of the Ministry of Ed-
ucation, Youth and Sports of Czech Republic
No. MSM0021620838.
References
Steven P. Abney. 1991. Parsing By Chunks. In
R. Berwick, S. Abney, and C. Tenny, editors,
Principle-Based Parsing, pages 257?278. Kluwer
Academic Publishers.
Steven P. Abney. 1995. Partial Parsing via Finite-State
Cascades. Journal of Natural Language Engineer-
ing, 2(4):337?344.
Fabio Ciravegna and Alberto Lavelli. 1999. Full Text
Parsing using Cascades of Rules: An Information
Extraction Procedure. In Proceedings of EACL?99,
pages 102?109. University of Bergen.
Jan Hajic?, Eva Hajic?ova?, Jarmila Panevova?, Petr Sgall,
Petr Pajas, Jan S?te?pa?nek, Jir??? Havelka, and Marie
Mikulova?. 2006. Prague Dependency Treebank 2.0.
LDC.
Jan Hajic?. 2004. Disambiguation of Rich Inflection
(Computational Morphology of Czech). Karolinum
Press.
Petr Homola and Vladislav Kubon?. 2008. A hybrid
machine translation system for typologically related
languages. In David Wilson and Chad Lane, editors,
Proceedings of FLAIRS 2008), pages 227?228, Co-
conut Grove, Florida, USA. AAAI Press.
Bernard E. M. Jones. 1994. Exploiting the Role of
Punctuation in Parsing Natural Text. In Proceedings
of the COLING?94, pages 421?425.
Oldr?ich Kru?za and Vladislav Kubon?. 2009. Automatic
Extraction of Clause Relationships from a Treebank.
In Computational Linguistics and Intelligent Text
Processing - Proceedings of CICLing 2009, volume
5449 of LNCS, pages 195?206. Springer-Verlag.
Vladislav Kubon?, Marke?ta Lopatkova?, Martin Pla?tek,
and Patrice Pognan. 2007. A Linguistically-Based
Segmentation of Complex Sentences. In D.C. Wil-
son and G.C.J. Sutcliffe, editors, Proceedings of
FLAIRS Conference, pages 368?374. AAAI Press.
Vladislav Kubon?. 2001. Problems of Robust Parsing
of Czech. Ph.D. thesis, Faculty of Mathematics and
Physics, Charles University in Prague.
Marke?ta Lopatkova? and Toma?s? Holan. 2009. Seg-
mentation Charts for Czech ? Relations among Seg-
ments in Complex Sentences. In A. H. Dediu, A. M.
Ionescu, and C. Mart??n-Vide, editors, Proceedings of
LATA 2009, volume 5457 of LNCS, pages 542?553.
Springer-Verlag.
Tomohiro Ohno, Shigeki Matsubara, Hideki Kashioka,
Takehiko Maruyama, and Yasuyoshi Inagaki. 2006.
Dependency Parsing of Japanese Spoken Mono-
logue Based on Clause Boundaries. In Proceedings
of COLING and ACL, pages 169?176. ACL.
80
Petr Pajas and Jan S?te?pa?nek. 2006. XML-Based Rep-
resentation of Multi-Layered Annotation in the PDT
2.0. In Proceedings of LREC 2006 Workshop on
Merging and Layering Linguistic Information, pages
40?47. ELRA.
Daniel Zeman. 2004. Parsing with a Statistical De-
pendency Model. Ph.D. thesis, Charles University
in Prague, Prague.
81
Problems Of Reusing An Existing MT System?
Ondr?ej Bojar, Petr Homola, Vladislav Kubon?
Institute of Formal and Applied Linguistics
?UFAL MFF UK, Malostranske? na?me?st?? 25, Praha 1, CZ-11800
Czech Republic
{bojar,homola,vk}@ufal.mff.cuni.cz
Abstract
This paper describes an attempt to recy-
cle parts of the Czech-to-Russian ma-
chine translation system (MT) in the
new Czech-to-English MT system. The
paper describes the overall architecture
of the new system and the details of
the modules which have been added.
A special attention is paid to the prob-
lem of named entity recognition and
to the method of automatic acquisition
of lexico-syntactic information for the
bilingual dictionary of the system. The
paper concentrates on the problems en-
countered in the process of reusing ex-
isting modules and their solution.
1 Introduction
The last decade has witnessed several attempts to
increase the quality of MT systems by introduc-
ing new methods. The strong stress on stochastic
methods in the NLP in general and in the MT in
particular, the attempts to develop hybrid systems,
a wide acceptance of translation-memory based
systems among the translation professionals, the
aim at limited domain speech-to-speech transla-
tion systems, all these (and many other) trends
have demonstrated encouraging results in recent
years.
Developing and using new methods definitely
moves the whole MT field forward, but one
?The work described in this paper has been supported by
the grant of the Grant Agency of the Czech Republic GACR
No.405/03/0914 and partially also by the grant of the Grant
Agency of the Charles University GAUK No. 351/2005
should not forget about all the effort invested into
the old systems. Reusing at least some parts of
those systems may help to decrease the costs of
new systems, especially when one of the lan-
guages is not a ?big? language and therefore there
is not such a wide range of tools, grammars, dic-
tionaries available as for example for English,
German, Japanese or Spanish. In this paper we
would like to describe one such attempt to reuse
the existing system for a new language pair.
2 The original system
One of the systems which was silently abandoned
in early nineties was the system for the translation
from Czech to Russian called RUSLAN (Oliva,
1989). It was being developed in the second half
of eighties with the aim to translate texts from a
relatively closed thematic domain, the domain of
operating systems of mainframes.
The system used transfer-based architecture.
The implementation of the system was almost
completely done in Q-systems, a formalism cre-
ated by Alain Colmerauer (Colmerauer, 1969)
for the TAUM-METEO project. The Czech-to
Russian system also relied upon a set of dictio-
naries containing all data exploited by individ-
ual modules of the system. Each lexical item
in the main (bilingual) dictionary contained not
only lexico-syntactic data (valency frames etc.),
but also a set of semantic features.
The work on the system RUSLAN has been ter-
minated in 1990, in the final phase of system test-
ing and debugging. The reason was quite sim-
ple - after the political changes in 1989 there was
no more any commercial demand for Czech to
179
Russian MT system.
The demand for Czech-English translation has
grown dramatically during the years following the
abandonment of the system RUSLAN. On the
other hand, also the range of methods, tools and
resources for MT has grown substantially. Sev-
eral corpora were created for Czech, the most
prominent ones being the morphologically anno-
tated Czech National Corpus and syntactically an-
notated Prague Dependency Treebank. In 2002
we have started the work on the parallel bilin-
gual Prague Czech English Dependency Treebank
(PCEDT) (Cur???n et al, 2004), which contains
about a half of the texts from PennTreebank 3
translated into Czech by native speakers. A large
morphological dictionary of Czech has been de-
veloped (Hajic?, 2001), allowing for a good quality
morphological analysis of Czech, which has been
tested in numerous commercial applications and
scientific projects since then.
3 The background of the project
The main motivation for our Czech-English MT
experiment was to test several hypotheses. The
most prominent of these hypotheses concerns the
level, at which it is reasonable to perform the
transfer. Due to the differences between both lan-
guages it is not sufficient to perform the transfer
immediately after the morphological analysis or
shallow parsing, as it has been done in the MT
system eslko aiming at the translation between
closely related (and similar) languages [cf (Hajic?
et al, 2003)]. On the other hand, it is a ques-
tion whether the typological differences between
Czech and English justify the transfer being per-
formed at the tectogrammatical (deep syntactic)
level.
Last but not least, one of our aims was to de-
velop a rule-based MT system with minimal pos-
sible costs, either reusing the existing modules or
trying to use (semi)automatic methods whenever
possible, concentrating on areas where using the
human labor would be extremely expensive (for
example building a large coverage bilingual dic-
tionary, cf. the following paragraphs.)
4 Czech-English MT system
The main goal of our project is to develop an ex-
perimental MT system for the translation of texts
from the PCEDT from Czech to English. The sys-
tem investigates the possibility of reusing the ex-
isting resources (grammar, dictionary) in order to
decrease the development time. It also exploits
the parallel bilingual corpus of syntactically anno-
tated texts, although not as a direct learning ma-
terial, more like an additional source of linguis-
tic data especially for the dictionary development
and for the testing of the system.
The task is complicated by the fact that this
translation direction is according to our opinion
more complicated than the reverse one. There are
several reasons for this claim; the most prominent
one is the free word-order nature of the source
language. It generally means that it is very of-
ten necessary to make substantial changes of the
word order if we want to get a grammatical Eng-
lish sentence, while when translating from Eng-
lish to Czech the results are more or less gram-
matically correct and comprehensible even if we
don?t change the word order at all.
Another problem of the Czech-English transla-
tion is the insertion of articles. Czech doesn?t use
any articles and it is of course much easier to re-
move them from the text (when translating from
English) than to insert a proper article on a proper
place (when translating from Czech).
Let us now look at the individual modules of
the new system.
4.1 Morphological analysis
Due to the limited size of the original morpho-
syntactic dictionary of the system it was neces-
sary to replace the original module by a new one.
The new module of morphological analysis of
Czech (Hajic?, 2001) has been already exploited in
numerous applications. It covers almost the entire
Czech language, with very few exceptions (it is
estimated that it contains about 800 000 lemmas).
It is very reliable, due to a really large coverage
there are almost no unknown words in the whole
PCEDT. The only problem was the incorporation
of the new module into the system - the original
module of syntactic analysis of Czech from the
system RUSLAN was very closely bound to a dic-
tionary lookup and to the morphological module.
The new module also uses a different tagset.
180
4.2 Bilingual dictionary
The bilingual dictionary of the system RUSLAN
contained approximately 8000 lexical items with
a rich lexico-syntactic information. We have orig-
inally assumed that the information contained in
the dictionary might be transformed and reused in
the new system, but this assumption turned to be
false. Although the information contained in the
original bilingual dictionary is extremely valuable
for the module of syntactic analysis of Czech, we
have decided to sacrifice it. The mere 8000 lex-
ical items constitute too small part of the new
bilingual dictionary and we have decided to prefer
handling the dictionary in a uniform way.
At the moment there are no Czech-English dic-
tionaries exploitable in an MT system. The avail-
able machine-readable dictionaries built mainly
for a human user (such as WinGED1 or
Svoboda (2001)) suffer from important limita-
tions:
? Sometimes, several variants of translation
are combined in one entry2.
? No clear annotation of meta-language is
present, although the entries contain valu-
able morphological or syntactic information
to some extent. (E.g. valency frames are
encoded by means of rather inconsistent ab-
breviations in plain text: accession to = vs-
toupen?? do or adjudge sb. to be guilty = uz-
nat vinny?m koho.)
? Usually, no morphological information is
given along the entries, although the mor-
phological information can be vital for cor-
rectly recognizing an occurrence of the entry
in a text. For example, an expression kniha
u?c?etn?? can be translated as either an account-
ing book or a book of an accountant depend-
ing whether the Czech word u?c?etn?? is an ad-
jective or a noun.
? No syntactic information is available and no
consistent rules have been adopted by the
1http://www.rewin.cz/
2Throughout the text, we use the term ENTRY as a syn-
onym to translation pair, i.e. a pair of Czech and English
expressions.
lexicographers to annotate syntactic proper-
ties in plain text (such as putting the head of
the clause as the first word).
From the point of view of structural machine
translation, the lack of syntactic information in
the translation dictionary is crucial. In the course
of translation, the input sentence is syntactically
analyzed before searching for foreign language
equivalents. In order to check for presence of
multi-word expressions in the input, the dictio-
nary must encode the structural shape of such en-
tries, otherwise the system does not know how to
traverse the relevant part of the tree. Similarly,
some expressions require some constraints to be
met (such as an agreement in case or number) in
the input text. If these constraints are not fulfilled,
the proposed foreign language equivalent is not
applicable.
The importance of valency (subcategorization)
frames and their equivalents should be stressed,
too. In the described system, already the syntac-
tic analyzer requires verb and adjective valency
frames in order to allow for specific syntactic con-
structions. In general, knowledge of translation
equivalents of valencies is important to preserve
the meaning (pr?ij??t na ne?jaky? na?pad = come at an
idea, literal translation: come on an idea; chodit
na housle = attend violin lessons, lit. walk on vi-
olin) or to handle auxiliary words properly (c?ekat
na ne?hoko = wait for somebody, lit. wait on sb.;
r???ci ne?co = tell something but pr?ejet ne?co = run
over something).
4.2.1 Dictionary cleanup
In order to handle the problems mentioned
above, we performed an extensive cleanup of the
data from available machine-readable dictionar-
ies. The core steps of the cleanup are as follows:
Identifying meta-information.
We manually processed all the entries and
searched for frequent words that typically encode
some meta-information, such as sth., st., oneself.
We also checked all entries ending with a word
that is potentially a preposition. Based on the ex-
pression in the other language, we were able to
recognize the meaning and identify, whether the
suspicious word expresses a ?slot? in the expres-
sion or whether it is a fixed part of the expression.
(E.g. m??t o sobe? vysoke? m??ne?n?? = think something
181
of oneself, only the word oneself encodes a slot,
the word something is a fixed part of the expres-
sion.)
During this phase, entries encoding several
translation variants at once were disassembled
into separate translation pairs, too.
Part-of-speech disambiguation.
We processed the Czech part of each entry with
a morphological analyzer (Hajic?, 2001) and we
performed manual part-of-speech disambiguation
of expressions with ambiguity. It should be noted
that automatic tagging would not provide us with
satisfactory results due to the lack of sentential
context around the expressions.
Adding morphological constraints.
Morphological constraints on word entries de-
scribe which values of morphological features are
valid for each word of the entry or have to be
shared among some words of the entry. Once
identified, morphological constraints can be used
to check whether a word group in the input text
represents an entry or not. With respect to our fi-
nal task (translation from Czech to English), we
aim at Czech constraints only.
We decided to induce morphological con-
straints automatically, based on corpus examples
of the entries. For each entry, we look up sen-
tences that contain all the lemmas of the entry
in a close neighborhood (but irrespective to the
word order and possible presence of inserted extra
words). We weight the instances to promote those
with no intervening words and those with con-
nected dependency graph. The list of weighted
instances is scanned for both unary (such as ?case
is accusative?, ?number is singular?) and binary
(?the case of the first and second words match?)
pre-defined constraints selecting those that are
satisfied by at least 75% of total weight.
Most of the expressions with at least 10 corpus
instances obtain a valid set of constraints. Only
expressions containing very common words (so
that the words do appear quite often close together
without actually forming the expression) obtain
too weak constraints. For instance, no case and
gender agreement constraints are selected for the
expression bohaty? c?love?k (wealthy man).
Adding syntactic information.
Syntactic information (dependency relations
among words in the expression) is needed mainly
during the analysis of input sentences, therefore
we focused on adding the information to the
Czech part of entries first. For most of the en-
tries, it was possible to add the dependency struc-
ture manually, based on the part-of-speech pattern
of the entry. For instance all the entries contain-
ing an adjective followed by a noun get the same
structure: the noun governs the preceeding adjec-
tive. For the remaining entries (with very varied
POS patterns), we employ a corpus-based search
similar to the automatic procedure of identifying
morphological constraints.
4.3 Named entity recognition module
Named entities (NE) are atomic units such as
proper names, temporal expressions (e.g., dates)
and quantities (e.g., monetary expressions). They
occur quite often in various texts and carry impor-
tant information. Hence, proper analysis of NEs
and their translation has an enormous impact on
MT quality (Babych and Hartley, 2004). In our
system they are extremely important due to the
nature of input texts. The Wall Street Journal sec-
tion of PennTreebank shows much higher density
of named entities than ordinary texts. Their cor-
rect recognition therefore has a tremendous im-
pact on the performance of the whole system, es-
pecially if the evaluation of the translation quality
is based on golden standard translations.
NE translation involves both semantic transla-
tion and phonetic transliteration. Each type of NE
is handled in a different way. For instance, person
names do not undergo semantic translation (only
transliteration is required), while certain titles and
part of names do (e.g., prvn?? da?ma Laura Bushova?
? first lady Laura Bush). In case of organiza-
tions, application of regular transfer rules for NPs
seems to be sufficient (e.g., ?Ustav forma?ln?? a ap-
likovane? lingvistiky ? Institute of formal and ap-
plied linguistics), although an idiomatic transla-
tion may be probably preferable sometimes. With
respect to geographical places we apply bilingual
glossaries and a set of regular transfer rules as
well.
For NE-recognition, we have developed a
grammar based on regular expressions that
processes typed feature structures. The gram-
mar framework, similarly as the formally a bit
weaker platform SProUT (Bering et al, 2003),
182
uses finite-state techniques and unification, i.e., a
grammar consists of pattern/action rules, where
the left-hand side is a regular expression over
typed feature structures (TFS) with variables, rep-
resenting the recognition pattern, and the right-
hand side is a TFS specification of the output
structure.
The NE grammar is based on the experiment
described in (Piskorski et al, 2004). An example
of a simple rule is:
#subst[LEMMA: ministerstvo]$s1
+ #top[CASE: gen, PHRASE: $phr]$s2
== $s1#ministry[ATTR: $s2,
PHRASE: &(?ministerstvo ? + phr)]
(1)
The first TFS matches any morphological vari-
ant of the word ministerstvo (ministry), followed
by a genitive NP. The variables $s1, $s2 and $phr
create dynamic value assignments and allow to
transport these values to the slots in the output
structure of type ministry. The output structure
contains a new attribute called PHRASE with the
lemmatized value of the whole phrase.
If the input phrase is
informace ministerstva zahranic???
o cestova?n?? do ohroz?eny?ch oblast?? (2)
then the phrase ?ministerstva zahranic???? will be
recognized as a NE and handled as an atomic unit
in the whole MT process:
?
?
?
?
?
?
?
?
?
?
?
?
?
?
ministry
LEMMA ministerstvo
FORM ministerstva
PHRASE ministerstvo zahranic???
ATTR
?
?
?
?
?
subst
LEMMA zahranic???
PHRASE zahranic???
FORM zahranic???
CASE gen
NUMBER sg
GENDER n
?
?
?
?
?
CASE gen
NUMBER sg
GENDER n
?
?
?
?
?
?
?
?
?
?
?
?
?
?
(3)
Lemmatization of NEs is crucial in the context
of MT. However, it might pose a serious problem
in case of languages with rich inflection due to
structural ambiguities, e.g., internal bracketing of
complex noun phrases might be difficult to ana-
lyze. The core of the framework is based on gram-
mars that have been developed for the MT system
?Ces??lko (Hajic? et al, 2003).
4.4 Syntactic analysis of Czech
Although we have originally assumed that the
module of syntactic analysis of Czech will re-
quire only small modifications and its reuse in the
new system was one of the goals of our system,
it turned out that this module is one of the main
sources of problems.
In the course of testing and debugging of the
system we had to create a number of new gram-
mar rules covering the phenomena which were
not properly accounted for in the original system
due to the different nature of the original domain.
The texts from PCEDT show for example much
higher number of numerals and numeric expres-
sions, some of which require either special gram-
matical or transfer rules than operating systems
manuals from the system RUSLAN. The com-
plexity of input sentences with regard to the num-
ber of clauses and their mutual relationship is also
much higher. This, of course, decreases the num-
ber of sentences which are completely syntacti-
cally analyzed and thus degrades the translation
quality.
One of the biggest problems of the grammar
are the properties of Q-systems. It was quite
clear since the start of the project that it is im-
possible to extract only the knowledge encoded
into the grammar, the grammar rules written in
Q-systems are so complicated that rewriting them
into a different (even chart-parser based) formal-
ism would actually mean to write a completely
new grammar. Although we have at our disposal
a new, modernized and reimplemented version of
a Q-systems compiler and interpreter which over-
comes the technical problems of the original ver-
sion, the nature of the formalism is of course pre-
served.
4.5 Transfer
The main task of this module is to transform the
syntactic structure (syntactic tree) of the input
Czech sentence into the syntactic structure (tree)
of the corresponding English sentence. The trans-
fer module does not handle the translation of reg-
ularly translated lexical units, it is handled by the
bilingual dictionary in the earlier phases of the
system. The transfer concentrates on three main
tasks:
183
? The transformation of the Czech syntactic
tree into the English one reflecting the dif-
ferences in the word order between both lan-
guages.
? The identification and translation of those
constructions in Czech, which require spe-
cific (irregular) translation into English.
? The insertion of articles (which do not exist
in Czech) into the target language sentences.
The development of this module still continues,
the initial tests confirmed that a substantial im-
provement can be achieved in the future.
4.6 Syntactic synthesis of English
The syntactic synthesis of Russian in RUSLAN is
very closely bound to transfer, therefore we have
tried to use as big portion of the grammar as possi-
ble, but of course, substantial modifications of the
grammar were necessary. As well as the work on
the transfer module, also the work on this module
still continues.
4.7 Morphological synthesis of English
Due to the simplicity of English morphology this
module has a very limited role in our system. It
handles plurals, 3rd persons and irregular words.
5 Conclusion
The problems mentioned in this paper do not al-
low to formulate an answer to the crucial ques-
tion - does it really pay off to recycle the old sys-
tem or not? The integration of existing parts into
a new system is so complicated that we are still
not able to perform evaluation of results on texts
of a reasonable size. One way out of this situa-
tion would be the combination of the new mod-
ules mentioned in this paper with one of the ex-
isting stochastic parsers of Czech instead of the
rule-based grammar.
Another possible direction for the future re-
search might be the exploitation of two new mod-
ules. The first one will contain partial, but error-
free disambiguation of the results of morpholog-
ical analysis of Czech, which will substantially
decrease the morphological ambiguity of individ-
ual Czech word forms. This ambiguity (the aver-
age number of morphological tags per word form
exceeds four in Czech) also negatively influences
the performance of the syntactic analysis.
The second way how to decrease the ambigu-
ity is the exploitation of a special module resolv-
ing the lexical ambiguity in those cases when the
bilingual dictionary provides more than one lexi-
cal equivalent. This stochastic module would ex-
ploit the context and would suggest the best trans-
lation.
References
B. Babych and A. Hartley. 2004. Selecting transla-
tion strategies in MT using automatic named en-
tity recognition. In Proceedings of the Ninth EAMT
Workshop, Valetta, Malta.
C. Bering, W. Droz?dz?yn?ski, G. Erbach, C. Guasch,
P. Homola, S. Lehmann, H. Li, H.-U. Krieger,
J. Piskorski, U. Schaefer, A. Shimada, M. Siegel,
F. Xu, and D. Ziegler-Eisele. 2003. Corpora
and evaluation tools for multilingual named entity
grammar development.
Alain Colmerauer. 1969. Les Systemes Q ou un for-
malisme pour analyser et synthetiser des phrases sur
ordinateur.
Jan Cur???n, Martin ?Cmejrek, Jir??? Havelka, and
Vladislav Kubon?. 2004. Building a Parallel Bilin-
gual Syntactically Annotated Corpus. In Proceed-
ings of the 1st International Joint Conference on
NLP.
Jan Hajic?. 2001. Disambiguation of Rich Inflection
- Computational Morphology of Czech, volume I.
Prague Karolinum, Charles University Press. 334
pp.
J. Hajic?, P. Homola, and V. Kubon?. 2003. A sim-
ple multilingual machine translation system. In In:
Proceedings of the MT Summit IX, New Orleans.
Karel Oliva. 1989. A Parser for Czech Implemented
in Systems Q. Explizite Beschreibung der Sprache
und automatische Textbearbeitung.
J. Piskorski, P. Homola, M. Marciniak,
A. Mykowiecka, A. Przepio?rkowski, and
M. Wolin?ski. 2004. Information extraction
for Polish using the SProUT platform. In Pro-
ceedings of the International IIS:IIP WM?04
Conference, Zakopane, Poland.
Milan Svoboda. 2001. GNU/FDL English-Czech
Dictionary. http://slovnik.zcu.cz/.
184
