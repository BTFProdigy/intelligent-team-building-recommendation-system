Language choice models for microplanning and readability
Sandra Williams
Department of Computing Science
University of Aberdeen
Aberdeen AB24 3UE, UK
swilliam@csd.abdn.ac.uk
Abstract
This paper describes the construction of lan-
guage choice models for the microplanning of
discourse relations in a Natural Language
Generation system that attempts to generate
appropriate texts for users with varying levels
of literacy. The models consist of constraint
satisfaction problem graphs that have been de-
rived from the results of a corpus analysis.
The corpus that the models are based on was
written for good readers. We adapted the
models for poor readers by allowing certain
constraints to be tightened, based on psycho-
linguistic evidence.  We describe how the de-
sign of microplanner is evolving. We discuss
the compromises involved in generating more
readable textual output and implications of
our design for NLG architectures. Finally we
describe plans for future work.
1  Introduction
Generator for Individual Reading Levels (GIRL) is a
Natural Language Generation (NLG) system that gener-
ates feedback reports for adults during a web-based lit-
eracy assessment. The inputs to GIRL are answers to
questions in a literacy assessment. GIRL currently gen-
erates a feedback report after each of eight skill-based
tests in the assessment. An example output report, gen-
erated after the spelling test, is shown in Figure 1.
GIRL is being developed with the aim of tailoring
its output texts to the individual reading skills of read-
ers. Our particular focus is on adults who have poor
reading skills due to a number of reasons including
missed school, dyslexia, poor eyesight, memory prob-
lems, etc. Poor literacy is a major problem in the UK
where up to one fifth of the adult population is function-
ally illiterate (Moser 1999).
Using Kintsch and Vipond?s (1979) definition, we
relate readability to performance on the reading task
(i.e. reading speed, ability to answer comprehension
questions and ability to recall content). We measured
the first two of these in preliminary experiments that
tested outputs from GIRL on both good and bad readers
(Williams et al 2003).
Sally Test,
SPELLING
You finished the SPELLING test, well done.
You got eleven out of fifteen, so you need to practise.
Sometimes you could not spell longer words. For
example, you did not click on: necessary.
Many people find learning to spell hard, but you can do it.
If you practise reading, then your skills will improve.
Figure 1. A feedback report generated by GIRL
Our research is focused on decisions GIRL makes at
the discourse level. A previous project, PSET  (Devlin
and Tait 1998, Devlin et al 2000), has already made
some progress towards lexical-level and syntax-level
simplifications for poor readers. In GIRL, it is at the
discourse level that choices are made that affect sen-
tence length and selection of discourse cue phrases
(phrases that render discourse relations explicit to the
reader, e.g. ?for example?, ?so? and ?if?, in Figure 1).
These choices are made in a module called the micro-
planner (see Reiter and Dale 2000).
The inputs to the microplanner are a model of a
user?s reading ability and a tree-structured document
plan (Reiter and Dale 2000) that includes discourse re-
lations. In GIRL, discourse relations are schemas ar-
ranged in a discourse tree structure. Each schema has
slots for semantic roles filled by daughter text spans, or
daughter relations. For instance, the condition  relation
has two semantic roles: a condition and a consequent.
Figure 2 shows a discourse relation tree structure with
its corresponding schema. The root relation, R1, is a
concession  (type: concession), with one daughter rela-
                                                               Edmonton, Ma -June 2003
                                                 Student Research Workshop , pp. 13-18
                                                         Proceedings of HLT-NAACL 2003
tion, R2, filling the ?concession? slot and a text span
daughter, S1, filling the ?statement? slot. R2 is a condi-
tion relation with two text span daughters: S3 filling the
?condition? slot and S2 the ?consequent? slot.
Figure 2. Discourse relation tree structure and schema.
The task of GIRL?s microplanner is to decide on the
ordering of the daughters, how they should be packed
into sentences (aggregation), whether there should be
punctuation between the daughters, whether discourse
cue phrases should be present and, if so, which ones and
where they should be placed. The microplanner will
ultimately adapt the choices it makes to the reading
level of individual users (readers) from user models
built from users? answers to up to ninety questions from
a literacy test. Our current implementation only consid-
ers two generic types of user - ?good readers? and ?bad
readers?.
Suppose the input to the microplanner is a discourse
plan containing the discourse relation tree in Figure 2. It
should be able to calculate that this could be generated
in a number of different ways. Just a few of them are:
  You made four mistakes. But you can learn to fill in forms if
you practise.
  Although you made four mistakes, you can learn to fill in
forms ... just as soon as you practise.
  You made four mistakes. But if you practise, you can learn
to fill in forms.
  If you practise, you can learn to fill in forms. You made four
mistakes, though.
and it should be able to choose which of these is the
most appropriate for poor readers.
The remainder of this paper describes what we be-
lieve is a novel approach to building language choice
models for microplanning. We explain how these mod-
els evolved (section 2) and the implications of this de-
sign (section 3).  Section 4 draws conclusions from the
current work and outlines our plans for future work.
2  Constructing the microplanner
This section describes the stages in the construction of
the microplanner. Each stage is based on empirical evi-
dence. Firstly, we acquired knowledge about how hu-
man writers linguistically realise specific discourse
relations by carrying out a corpus analysis (see Williams
and Reiter 2003). Secondly, we selected the best method
for representing this knowledge and built choice models
from the corpus analysis data.  Then, because the corpus
was written for good readers, we had to adapt the mod-
els for poor readers.  For this, we used results from psy-
cholinguistic studies, including results from our own
preliminary experiments (see Williams et al 2003).
Finally, these individual parts were combined to pro-
duce the finished microplanner.
2.1 Reconfiguring our corpus analysis results
We analysed seven discourse relations  (Williams and
Reiter 2003), including concession, condition, elabora-
tion-additional, evaluation, example, reason  and re-
statement, using the RST Discourse Treebank corpus
(Carlson et al 2002). We analysed one hundred in-
stances of each relation noting the following six fea-
tures:
  L1: length of the first text span (in words).
  L2: length of the second text span (in words).
  O: ordering of the text spans.
  Ps: position(s) of discourse cue phrase(s).
  P: between-text-span punctuation.
  C: discourse cue phrase(s).
An example to demonstrate these features is the conces-
sion relation in the last example given above: ?If you
practise, you can learn to fill in forms. You made four
mistakes, though.? Here, L1  is ten words (this includes
the whole of the condition daughter), L2  is five words,
O  is concession-statement, Ps is after the statement, P  is
a full stop and C  is ?though?.
These features were chosen on the basis of previous
work (Moser and Moore 1996) and because they influ-
ence sentence length and lexical choice which are
known to be important factors in readability. The analy-
sis revealed some of the ways in which human authors
select these features when writing for good readers.
These provided a partial specification for modelling
discourse-level choices that should be available in an
   RELATION
id: R1
type: concession
concession:
statement:
    RELATION
id: R2
type: condition
condition:
consequent:
TEXT SPAN
id:    S1
text: ?you made four mistakes?
TEXT SPAN
id:     S3
text: ?you practise ?
TEXT SPAN
id:    S2
text: ?you can learn
       to fill in forms?
S3 S2
S1R2
R1
NLG system. Furthermore the analysis demonstrated
that the features are interdependent.
The results from our corpus analysis (Williams and
Reiter 2003) were simplified. The numbers of values for
some features were cut down by re-classifying them as
members of a smaller number of categories. Length
became either ?long? or ?short?. The data for each rela-
tion was split into two, so that roughly half the L1 in-
stances fell into the ?short? category (e.g. for
concession, short = 1-15 words, long = >15 words).
Between-text-span punctuation was divided into just
three categories: none, non-sentence-breaking, and sen-
tence-breaking. The restatement relation was an excep-
tion because it had such a large proportion of open-
parentheses (62%) that an extra category was created. In
restatement, it seems that punctuation is often used in-
stead of a cue phrase to signal the relation. The cue
phrase feature was left with larger numbers of values to
provide GIRL with the maximum number of choices for
lexical selection.
The data was reconfigured as sets of 6-tuples. Each
represents a set of values for one instance of a relation:
i.e. <L1,L2,O,Ps,P,C>. For instance, the concession
relation described above would be represented as
<short, short, concession-statement, after_statement, full
stop, ?though?>. We thus created seven hundred 6-
tuples in total, one hundred per relation. For each rela-
tion, these were sorted, duplicates were counted and
superfluous duplicates removed. Of the resulting unique
6-tuples, some were rejected and are not used in the
current language choice models. For example, in the
concession choice  model forty-six unique 6-tuples cover
100% of the corpus data and sixteen were rejected, re-
sulting in a coverage of 75%. For condition, forty-seven
unique 6-tuples cover 100% but only twenty-six were
included and these cover 72%.
Figure 3. Some cue phrases, with those not in the
current language models marked with asterisks
The reason why some tuples were rejected is be-
cause GIRL?s present shallow approaches to syntactic
and semantic processing cannot generate them. It cannot
currently generate embedded discourse text spans, nor
can it generate discourse cue phrases in mid-text-span
positions. Both of these would require the implementa-
tion of deeper syntactic processing. Certain 6-tuples
contain discourse cue phrases that would not make
sense when generated unless we implement deeper se-
mantic processing. Figure 3 shows some examples of
these. Cue phrases marked with asterisks have been
rejected from the current language models because they
require deeper processing.
Our current method for reconfiguring the data is
manual, using existing spreadsheet, database and statis-
tics packages. We are investigating how it could be
automated, given that some decisions, such as which 6-
tuples to reject, require human judgement.
2.2 Building CSP graphs for good readers
Having reconfigured the results of our corpus analy-
sis, we searched for the best way to model the choices
they represent. We tried exploring both discriminant
analysis statistics and machine learning of decision trees
in attempts to identify which feature(s) would most
clearly divide the data into groups.  For most discourse
relations, the positions of discourse cue phrases were
the most discriminating features.
The most crucial characteristic of the choice models
we were attempting to build was that they should reflect
the interdependencies of the features found in the corpus
analysis.  For instance, in most relations the selection of
between-span punctuation is dependent on the length of
the first text span.  For some relations (not all), this
means that as the first text span gets longer, the be-
tween-span punctuation tends to change from no punc-
tuation, to comma, to full stop. Similarly, the selection
of punctuation depends on the order of text spans, par-
ticularly with the condition  relation.  If the order is con-
dition-consequent, there tends to be a comma between
text spans, if the order is consequent-condition, there is
often no punctuation.  And so on with interdependencies
between all the other features.
The best representation we have found to date that
fits this requirement is constraint satisfaction problem
(CSP) graphs. Power (2000) demonstrated that CSPs
could be used to map rhetorical structures (i.e. discourse
relation trees) to text structures (paragraphs, sentences,
etc.). Our task is similar to Power?s, but we emphasise
different processes, such as cue phrase choice, our
choice models are based on empirical evidence, and we
have the additional criteria that the representations
should be adaptable for different reading abilities. It
turned out that CSP graphs were ideal for this purpose,
since we exploit CSP?s notion of ?tightening? the con-
straints in our solution for adapting the models for poor
readers (see section 2.3).
       If
As soon as
Once              you practise, you will improve.
* Until
* Should
* Without
* Unless
* Given
                                      if
You will improve    as long as      you practise.
                              as soon as
                                  only if
                               * should
                               * unless
                                  *until
We used the Java Constraint Library (JCL 2.1) from
the Artificial Intelligence Laboratory at the Swiss Fed-
eral Institute of Technology in Lausanne (Torrens 2002)
which we found to be portable, relatively bug-free and
easy to plug straight into our system which is written
entirely in Java.
We built computer models representing the six key fea-
tures of discourse relations and their interdependent
values. One CSP graph was built for each of the seven
discourse relations. The structure of the graphs is ex-
actly the same for each relation with six nodes and fif-
teen connections linking every node to all the others.
This structure is illustrated in figure 4.
Figure 4. CSP graph representing a discourse relation.
The nodes in the graph in figure 4 are CSP domain vari-
ables. Each represents one of the six features. The num-
bers of values for each node varies for each relation.
Constraints between the variables were represented as
?good lists?. Both values and constraints were coded
directly from the 6-tuple data. Good lists contain pairs
of values that are ?legal? for two variables.  For in-
stance, a connection between L1 and P might contain
the pair <short, non-sentence-breaking> in its good list,
meaning: if the length of the first text span in the rela-
tion is short, put non-sentence-breaking punctuation,
such as a comma, between the text spans. The numbers
of pairs in the ?good lists? attached to each of the fifteen
connections varies for each relation.
We used pairs of ?legal? values in the CSP good
lists because the corpus analysis is too small to predict
the probabilities of triples. We are currently working on
expanding the size of our corpus analysis. We wanted
the CSP graphs to generate solutions that gave as good a
coverage of the 6-tuples included in the models as pos-
sible, but we did not want to overgenerate instances that
did not occur in the analysis. This required delicate bal-
ancing of the two factors.
2.3  Adapting the models for poor readers
based on psycholinguistic evidence
The language choice models were adapted for poor
readers by tightening the constraints. We studied the
psycholinguistic and educational literature to determine
how they should be tightened. We also carried out pre-
liminary experiments of our own (Williams et al 2003)
which indicated that certain discourse-level features
affect readability for poor readers more than good read-
ers. Selecting more common discourse cue phrases and
the placing punctuation between discourse segments
were both particularly helpful for poor readers.
Existing psycholinguistic research on reading has
little to say about adults with poor literacy. It has tended
to focus on proficient adult readers (University stu-
dents), rather than on the problems of adult learner
readers. Where it has investigated the development of
reading skills, it has tended to focus on children, rather
than adults. Educationalists maintain that the reading
skill profiles of adults with poor literacy are different
from those of children. ?Normal? children tend to de-
velop reading skills evenly, whereas adults who are
functionally illiterate tend to have developed unevenly
(Strucker 1997). Yet another problem is that it tends to
focus on single words, single sentences, or pairs of sen-
tences, that are presented to a reader out-of-context,
rather than in multiple-sentence documents.
There are some exceptions, however. Devlin and
Tait (1998) found that the readability of newspaper texts
was increased for seven out of ten aphasic readers when
they replaced infrequent words with more frequent
synonyms. Leijten and Van Waes (2001) reported that
elderly readers? comprehension and recall improved
when they were presented with causal discourse struc-
tures containing explicit discourse cue phrases and ex-
plicit headings.  Degand et al (1999) observed that
removal of even a few cue phrases affects comprehen-
sion and recall of the entire content. The last two studies
were with adult readers from the general public with
(presumably) varying levels of reading ability.
To sum up, use of cue phrases, selection of common
cue phrases and use of between-span punctuation all
seem to help bad readers. We therefore chose to tighten
the constraints to favour solutions with these features.
Frequencies for cue phrases were obained from a
part-of-speech (POS) search  (Aston and Burnard 1998)
in the 100 million word British National Corpus.
Phrases like ?for example? are annotated with a single
part-of-speech in the BNC. Some results are shown in
Table 1. Cue phrases do not all have the same POS, and
they are not, of course, exact synonyms, so it is not al-
ways possible to substitute one for another even if both
are from the same relation. ?Such as? can not always be
substituted for ?for instance?, but ?for example? is a
close synonym and it is possible to do a substitution.
We tightened constraints, where possible, to favour
words that occur in the Dolch lists used by adult literacy
tutors. These list the most commonly occurring function
words that beginner readers are taught to sight read.
Another danger with substituting common phrases
for less common ones is that the most common phrases
L2
O Ps
L1
P  C
are also the most ambiguous. The cue phrases ?but? and
?and? both occurred in four relations (concession, elabo-
ration-additional, evaluation and reason) out of seven
in the corpus analysis and these are relations with very
different meanings. These problems require further in-
vestigation.
Cue phrase BNC freq. Dolch list
although 42,758 -
and  2,615,144 yes
because 83,181 yes
but 443,164 yes
for example 23,643 yes
for instance 7,344 -
if 230,892 yes
still 67,106 -
though 33,337 -
Table 1. Cue, BNC frequency & Dolch list presence.
2.4  Putting it all together ? the microplanner
Figure 4 shows the main components of the microplan-
ner. The inputs are a model of the user?s reading ability
(marked ?user model?) and a document plan containing
discourse relation trees, marked ?DocPlan?. Both are
built by system modules occurring earlier than the mi-
croplanner in the processing sequence. The document
plan in figure 4 is the same as shown above in figure 2.
Working bottom-up, a CSP graph for the current rela-
tion is retrieved from the CSP graph knowledge base
and the constraints are tightened or relaxed according to
the user model. The CSP Solver (Torrens 2002) then
uses simple backtracking search to find all solutions for
the relation. The solutions found by the CSP Solver are
passed through a filter which currently picks the most
frequently occurring one for good readers and the one
with overall shortest sentences for poor readers.  The
output is a schema that the next module of GIRL uses to
construct messages.
It does not always output the most coherent solution.
For instance, the output shown in figure 5 would result
in a final output of ?You made four mistakes. But if you
practise, you can learn to fill in forms?. Adjacent dis-
course cue phrases do not improve coherency. The mi-
croplanner is still under development, however, future
improvements, possibly including backtracking, will
improve readability, possibly including coherence con-
siderations, such as focus and reference.
3  Discussion
Additional functionality would need to be added to the
?filter? module to choose solutions that optimise dis-
course coherence. Additional nodes might be required in
the constraint graphs. The simple string content of dis-
course relations would have to be replaced by semantic
representations. If it were, the simple pipeline architec-
ture would no longer be appropriate, since it currently
depends on knowing the final length of the strings.
On the other hand, when generating text for bad
readers, we might have to sacrifice some of these, since
they might impact on readability. Ellipsis, for instance,
may not be good for bad readers. Ellipsis is one way
that conciseness can be achieved during aggregation.
Current opinion in the NLG community is that aggrega-
tion for conciseness is ?a good thing?. Reape and Mel-
lish (1999) even suggest that an NLG system should
?aggregate whenever possible?. But conciseness may be
less comprehensible for poor readers. The sentences in
A, below, could be aggregated as in B.
A.  Spelling is hard. But spelling is important.
B.  Spelling is hard but important.
However, in B a single sentence is longer and the
cognitive load for poor readers in working out the el-
lipse could be higher. A little repetition and redundancy
might actually turn out to be beneficial!
Figure 5. The microplanner
DocPlan
USER MODEL CSP Graph
Knowledge
Base
Tighten/Relax
Constraints
MICROPLANNER
FILTER
Output
R2: <short, short,
       S3-S2, beforeS3,
       comma, ?if?>
R1: <short, long,
       S1-R2, beforeR2,
       full stop, ?but?>
CSP Solver
S3 S2
S1R2
R1
L1 L2
O
P
Ps
C
4  Conclusions and future work
This paper described how we used the results of a cor-
pus analysis to build language choice models for a mi-
croplanner. We discussed the creation of constraint
satisfaction problem graphs for our default ?good
reader? models and how we adapted the models for poor
readers. Our ?poor reader? models are based on psy-
cholinguistic evidence, including evidence from our
own preliminary experiments.  We discussed some of
the compromises involved in generating more readable
textual output and the impacts that further development
could have on GIRL?s architecture.
Plans for future work include expanding the size of
our corpus analysis and automating at least some of the
analysis and data reconfiguration. We plan further de-
velopment of the microplanner to prevent incoherent
solutions being generated. Further on, we plan to take
discourse coherence considerations into account.
We have plans to carry out additional reading ex-
periments with good and bad readers to investigate
whether the constraints we tighten to adjust the lan-
guage models for poor readers actually produce more
readable results. We will generate texts under the de-
fault ?good reader? models and under the constrained,
poor reader, models. We will measure reading speeds
and comprehension as in our preliminary experiment.
(Williams et al 2003). We predict that, as we found
then, good readers will perform equally well on both
models and poor readers will perform better on the con-
strained models. We will also carry out user satisfaction
evaluations and carry out evaluation surveys with pro-
fessional basic skills (adult literacy) tutors.
References
Guy Aston and Lou Burnard. 1998. The BNC Hand-
book: Exploring the British National Corpus with
SARA.  Edinburgh University Press.
Lynn Carlson, D. Marcu, and M Okurowski. 2002.
Building a Discourse-Tagged Corpus in the Frame-
work of Rhetorical Structure Theory. Kuppevelt and
Smith (eds.) Current Directions in Discourse and
Dialogue, Kluwer.
Liesbeth Degand, N. Lef?vre and Y. Bestgen. 1999. The
impact of connectives and anaphoric expressions on
expository discourse comprehension. Document De-
sign: Journal of Research and Problem Solving in
Organizational Communication, 1 pp. 39-51.
Siobhan Devlin and John Tait. 1998. The Use of a Psy-
cholinguistic Database in the Simplification of Text
for Aphasic Readers. Linguistic Databases. J. Ner-
bonne (ed.) CSLI Publications.
Siobhan Devlin, Y. Canning, J. Tait, J. Carroll, G. Min-
nen and D. Pearce. 2000. An AAC aid for aphasic
people with reading difficulties. Proceeding of the 9th
Biennial Conference of the International Society for
Augmentative and Alternative Communication.
Walter Kintsch and Douglas Vipond. 1979. Reading
Comprehension and Readability in Educational Prac-
tice and Psychological Theory. L.Nilsson (ed.) Per-
spectives on Memory Research. Lawrence Erlbaum.
Mari?lle Leijten and Luuk Van Waes. 2001.The impact
of text structure and linguistic markers on the text
comprehension of elderly people. W. Spooren and L.
van Waes (eds.) Proceedings of Multidisciplinary
Approaches to Discourse.
Claus Moser. 1999. Improving literacy and numeracy: a
fresh start. Report of the working group chaired by
Sir Claus Moser.
Megan Moser and Johanna Moore. 1996. On the corre-
lation of cues with discourse structure: results from a
corpus study.  Unpublished manuscript.
Richard Power. 2000. Mapping Rhetorical Structures to
Text Structures by Constraint Satisfaction. Informa-
tion Technology Research Institute, Technical Report
ITRI-00-01, University of Brighton.
Mike Reape and Chris Mellish. 1999. Just what is ag-
gregation anyway? Proceedings of the Seventh Euro-
pean Workshop on Natural Language Generation.
Ehud Reiter and Robert Dale. 2000. Building Natural-
Language Generation Systems. Cambridge Univer-
sity Press.
John Strucker. 1997. What silent reading tests alone
can?t tell you: two case studies in adult reading dif-
ferences. Focus on Basics, Vol. 1B, National Center
for the Study of Adult Learning and Literacy
(NCSALL), Harvard University.
Marc Torrens. 2002. Java Constraint Library 2.1. Artifi-
cial Intelligence Laboratory, Swiss Federal Institute
of Technology. GNU Lesser Public Licence.
Sandra Williams and Ehud Reiter. 2003. A corpus
analysis of discourse relations for Natural Language
Generation. To appear in proceedings of Corpus Lin-
guistics 2003.
Sandra Williams, Ehud Reiter and Liesl Osman. 2003.
Experiments with discourse-level choices and read-
ability. To appear in proceedings of the 9th European
Workshop on Natural Language Generation.
Abstract 
Most NLG systems generate texts for readers with 
good reading ability, but SkillSum adapts its output 
for readers with poor literacy. Evaluation with low-
skilled readers confirms that SkillSum?s knowl-
edge-based microplanning choices enhance read-
ability. We also discuss future readability im-
provements. 
1 Introduction 
Most existing NLG systems assume that generated texts are 
read by proficient readers with good literacy levels. How-
ever, many people in the UK and elsewhere are not profi-
cient readers; indeed, according to a UK Government survey 
[Moser, 1999], twenty percent of the UK adult population 
have problems with reading (and an even greater number 
have problems with simple maths). Some of these individu-
als have physical or cognitive disabilities (such as dyslexia), 
but many have no such problems; their poor basic skills are 
because of factors such as social deprivation and attending 
low-quality schools. NLG systems that generate personal-
ised health information, for example Cawsey et al [2000] 
and Reiter et al [2003a], would probably be more effective 
if they could generate appropriate texts for poor readers as 
well as good readers. Certainly real world NLG applications 
should at least consider such readers; otherwise there is a 
danger that many readers will not understand the texts we 
generate. 
Generating appropriate texts for poor readers is a multifac-
eted problem. At a content level, texts should be short, ex-
plicit, and clearly useful to the reader  [Sripada et al, 2003], 
so that he or she is willing to make the effort required to 
read it. At a linguistic level, texts should use simple and 
easy-to-understand words and short sentences with simple 
syntactic structures [Harley, 2001]. At a presentation level, 
texts should have an easy-to-understand layout [Bouayad-
Agha et al, 2001] and be communicated in clear fonts par-
ticularly for dyslexic readers (e.g. K-type fonts, www.k-
type.com) and for readers with visual impairment (e.g. 
tiresias font, www.tiresias.org). 
The focus of our research is on the linguistic level, and to 
date we have looked at choices related to the expression of 
discourse structure, such as the order in which phrases re-
lated by a discourse relation are expressed. Our hope was 
that rules for linguistic choices at least would be generic and 
easy to ?plug in? to NLG systems intended for poor readers. 
Future work in the project will look at lexical choice and 
also at improved content selection and personalisation.  
1.1 The SkillSum project 
SkillSum is an on-going collaborative project between 
Cambridge Training and Development Ltd. (CTAD), who 
build educational resources, and NLG researchers at Aber-
deen University. The project is developing a web-based 
application that assesses adult basic skills in literacy (read-
ing and writing skills) or numeracy (maths skills) and gen-
erates feedback reports. Users of SkillSum take a test devel-
oped by CTAD that assesses their literacy or numeracy, and 
then SkillSum generates reports that summarise their 
performance. SkillSum is being developed in a user-centred 
manner involving rapid prototyping and frequent evalua-
tions with users. 
The ultimate goal of the SkillSum project is to build a sys-
tem that allows people who are concerned about their liter-
acy or numeracy to assess their skills with minimal support 
from others, and that encourages people with poor skills to 
take steps to improve them. Currently most people with 
poor skills do not in fact enrol in courses to improve their 
skills, and our hope is that making the assessment process as 
easy (and private) as possible will encourage more people 
who need help to seek it out.  
The SkillSum project originally used detailed diagnostic 
literacy and numeracy assessments developed by CTAD. 
However, in pilots with users, we found that these took too 
long to complete and it seemed unlikely that people would 
be able to use them in an unsupported environment. Our 
current solution uses modified versions of CTAD?s shorter 
literacy and numeracy screeners, i.e. tests that identify in a 
broader sense whether a user has problems with literacy or 
numeracy, but without a detailed analysis. These administer 
twenty-seven questions graded according to the Adult Basic 
Skills Core Curriculum for England and Wales [Steeds, 
2001] and covering a broad range of skills from simpler 
levels to higher levels in this curriculum. The tests adminis-
ter the easiest questions first. Ideally, the difficulty of the 
questions that are administered should change according to 
Generating readable texts for readers with low basic skills 
Sandra Williams and Ehud Reiter 
Department of Computing Science 
University of Aberdeen 
Aberdeen AB24 3UE, U.K. 
{ swilliam,ereiter }@csd.abdn.ac.uk 
a user?s ability to answer correctly, but at present if a user 
has difficulties with the questions, the test simply ends. 
The reports generated by SkillSum are, of course, tailored to 
individuals, but this tailoring is in terms of content, rather 
than language. The focus of research to date has been on 
how to generate appropriate texts for readers with below 
average literacy and numeracy; i.e. language tailoring for 
the group as a whole, not for individuals.  
1.2 Related work 
Using NLG in educational applications is not new, but the 
type of text generated is different from SkillSum?s reports. 
For example, generating turns in intelligent tutoring system 
(ITS) dialogues (e.g. [Di Eugenio et al, 2001; [Moore et al, 
2004]). Although turns can give feedback, the kind of feed-
back differs in that it attempts to teach a student about an 
immediate domain-specific learning problem, rather than to 
summarise his/her overall skills.  
With regard to tailoring texts for different readers, a number 
of previous researchers have looked at tailoring generated 
texts according to whether the reader is a domain expert or a 
novice (for example [Paris, 1988; McKeown et al, 1993; 
Milosavljevic and Oberlander, 1998]). Less work has been 
done on tailoring texts according to the reader?s literacy. 
Perhaps the best-known previous work in this area is PSET 
[Devlin et al, 1999], which focused on syntactic and lexical 
choices in texts intended for aphasic readers. Unfortunately 
most of PSET?s adaptation rules were not experimentally 
validated. Siddharthan [2003] similarly proposed and im-
plemented a system for simplifying texts, but did not evalu-
ate how readable his generated texts were for poor readers. 
Scott and de Souza [1990] suggested some psycholinguisti-
cally-motivated rules for expressing discourse relations, but 
did not evaluate them at all. 
2 Linguistic choices investigated 
Figure 1 ? Extract from typical content plan 
The document (content) planners of our system produce as 
output a tree, where core messages are related by discourse 
relations such as explanation or concession; this basically 
follows the architecture described by Reiter and Dale 
[2000]. Discourse relations are essentially rhetorical struc-
ture theory (RST) relations [Mann and Thompson, 1987], 
and messages are represented using a deep-syntactic repre-
sentation, which is loosely based on RealPro [Lavoie and 
Rambow, 1997]. An example of an extract from a typical 
content plan, with messages shown as text glosses instead of 
deep syntactic structures, is shown in Figure 1.  
Our focus to date has been on how discourse relations such 
as Concession and Condition in Figure 1 are expressed, in 
particular: 
? cue phrases: should a cue phrase (or multiple cue 
phrases) be used to express a discourse relation? If so, 
which one(s)? For example, should we generate: 
? If you practise reading, your skills will improve 
(one cue, If) 
? If you practise reading, then your skills will im-
prove (two cues, If and then) 
? ordering: which order should the constituents related 
by a discourse relation be expressed in? Should the 
nucleus (core) be first or second? For example, should 
we generate: 
? Your skills will improve if you practise reading 
(nucleus first) 
? If you practise reading, your skills will improve 
(nucleus second) 
? punctuation (sentence structure): should constituents 
be expressed in separate paragraphs, separate sen-
tences, in a single sentence with punctuation separat-
ing them, or in a single sentence without punctuation? 
For example, should we generate (just showing two of 
these options):  
? Many people find reading hard, but your skills 
will improve if you practise reading (single sen-
tence, comma separation)  
? Many people find reading hard. But your skills 
will improve if you practise reading (two sen-
tences)  
These choices are inter-dependent. For example, we cannot 
say, ?Then your skills will improve, if you practise reading? 
(both if and then cue phrases, nucleus first). 
This problem is related to the document structuring task of 
Power et al [2002]. Power et al?s approach is essentially 
algorithmic; whereas our approach is centred on the knowl-
edge required to make the choices, and the algorithm used is 
less important. Their task is how to map an input RST tree 
to a set of output trees representing possible alternative 
document structures and then choose the best; whereas 
SkillSum?s microplanning task is to map an input RST tree 
to flat, ordered lists of syntactic structures representing pos-
sible lists of alternative sentences and then pick the best. 
Power et al include document layout in their task, whereas 
SkillSum makes layout decisions later, during the final re-
alisation stage.  
3 Choice rules and the microplanner  
We created a microplanner (developed from the one de-
scribed in [Williams, 2004]) that made the above choices 
based on hard constraints and optimisation rules; the hard 
Concession 
Condition [Many people find 
reading hard] 
[Your skills will improve] [You practise reading] 
constraints forbade illegal combinations, and the optimisa-
tion rules expressed readability preferences. 
3.1 Hard constraints 
The hard constraints were intended to forbid combinations 
of choices that led to ungrammatical texts, such as ?Then 
your skills will improve, if you practise reading?. We cre-
ated these by analyzing the RST Discourse Treebank Cor-
pus (RST-DTC) [Carlson et al 2002]; this is a corpus of 
Wall Street Journal texts that have been annotated with dis-
course relations. For each discourse relation of the type that 
occurs in SkillSum texts, we extracted 200 instances of the 
relation from the RST-DTC (or as many as possible if the 
corpus contained fewer than 200 instances), and analysed 
what combination of the above choices were instantiated in 
each of these instances. We then created hard constraints 
that forbade any pair of choices which was not present in 
any of the RST-DTC instances that we analysed. These con-
straints were specified on pairs of choices (for example, 
ordering and punctuation), not a complete choice set (order-
ing, punctuation, cue phrases), because we did not have 
enough instances to make rules for complete choice sets.  
The RST-DTC corpus was not ideal for this exercise, as it is 
based on texts (Wall Street Journal articles) that are in-
tended for good readers and written in U.S. English. It 
would have been preferable to use a corpus of U.K. English 
texts intended for low-skilled readers. Unfortunately there is 
no such corpus that includes discourse relation annotations. 
3.2 Optimisation rules 
The optimisation rules expressed preferences between legal 
sets of choices. We created two sets of rules: control and 
enhanced-readability (ER). The control rules were based on 
the most common choices observed in the RST-DTC; they 
also penalised cue phrases which were highly ambiguous 
(could be used for many discourse relations). The ER rules 
expressed a set of preferences for the above choices which 
we hypothesized would result in more readable texts for 
low-skilled readers. 
The ER model was based on a literature review of relevant 
psycholinguistic findings (such as [Millis and Just, 1994; 
Degand et al, 1999; Harley, 2001]) and also on a series of 
pilot experiments that we performed with low-skilled read-
ers [Williams et al, 2003]. Essentially, it prefers that 
? each discourse relation should be expressed by a cue 
phrase. Only a single cue phrase should be used (for 
example, not both if and then for condition); 
? lexically common cue phrases are preferred, even if 
they are ambiguous; for example but instead of how-
ever for concession;  
? a cue phrase should be placed between the constituents 
if possible, and the nucleus (core) should come first if 
possible. For example, ?Your skills will improve if you 
practise reading? is preferred over ?If you practise 
reading, your skills will improve?; 
? constituents should preferably be in separate sentences; 
if they are in the same sentence, they should be sepa-
rated by a comma. 
With regard to the choice of cue phrases, obviously cue 
phrases do not have identical meanings; even if in a broad 
sense they express the same discourse relation, they have 
different connotations and applicability constraints [Knott, 
1996]. Hence the choice of cue phrases should be influenced   
 
Figure 2 ? Example text produced by SkillSum and generated with enhanced readability (ER) model. 
 
		

	



	


Proceedings of the 12th European Workshop on Natural Language Generation, pages 118?121,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
Precision and mathematical form in first and subsequent mentions of
numerical facts and their relation to document structure
Sandra Williams and Richard Power
The Open University
Walton Hall, Milton Keynes MK7 6AA, U.K.
s.h.williams@open.ac.uk; r.power@open.ac.uk
Abstract
In a corpus study we found that authors
vary both mathematical form and preci-
sion1 when expressing numerical quanti-
ties. Indeed, within the same document,
a quantity is often described vaguely in
some places and more accurately in others.
Vague descriptions tend to occur early in a
document and to be expressed in simpler
mathematical forms (e.g., fractions or ra-
tios), whereas more accurate descriptions
of the same proportions tend to occur later,
often expressed in more complex forms
(e.g., decimal percentages). Our results
can be used in Natural Language Gener-
ation (1) to generate repeat descriptions
within the same document, and (2) to gen-
erate descriptions of numerical quantities
for different audiences according to math-
ematical ability.
1 Introduction
This study is part of the NUMGEN project2, which
aims (a) to investigate how numerical quantity de-
scriptions vary in English, (b) to specify a gram-
mar that covers these variations, and (c) to develop
an algorithm that selects appropriate descriptions
for people with different levels of mathematical
ability. We collected, from newspapers, popular
science magazines and scientific journals, exam-
ples of numerical facts that were mentioned more
than once, so that first mentions could be com-
pared with subsequent mentions. For example in
the following text, two mentions of the same nu-
merical fact ? the proportion of A grades in UK
A-level examinations in 2008 ? are underlined:
1Our use of the term precision has nothing to do with pre-
cision in information retrieval (i.e., the percentage of docu-
ments retrieved that are relevant).
2http://mcs.open.ac.uk/sw6629/numgen
A-level results show record number of
A grades
Record numbers of teenagers have re-
ceived top A-level grades
By Graeme Paton, Education Editor
More than a quarter of papers were
marked A as results in the so-called gold
standard examination reach a new high.
. . .
According to figures released today by
the Joint Council for Qualifications,
25.9 per cent of A-level papers were
awarded an A grade this summer . . .
(Daily Telegraph, 14 August 2008)
Comparing the two, (a) the first (More than a
quarter) is less precise than the second (25.9 per
cent), (b) its mathematical form, a common frac-
tion, is less complex than the decimal percentage
form of the second, and (c) its string has more
characters (i.e., it is not shorter in length as might
be expected if it were a summary). Also, the two
mentions occur in different parts of the document
? the first paragraph, and the fifth paragraph.
1.1 What do we mean by precision?
To compare the precision of numerical expres-
sions we needed a more exact definition of the
concept. We derived the following rules to deter-
mine precision:
? Precision increases with the number of sig-
nificant figures
? Round numbers imply vagueness (implicit
approximation)
? Modifiers increase the precision of round
numbers when they indicate the direction of
approximation (> or <)
? Common proportional quantities imply
vagueness (implicit approximation similar to
round numbers)
118
Our first rule concerns arithmetical precision ?
i.e., the number of significant figures. Thus 344
with three significant figures is more precise than
340 with only two and 56% with two significant
figures is more precise than 50% with one.
Second, we adhere to Krifka?s RNRI (round
number round interpretation) theory that when
speakers or writers mention a round figure such as
sixty, they mean that the actual figure is slightly
less than or more than the round number un-
less they explicitly modify it with (say) exactly,
and similarly, hearers or readers interpret it as
rounded (Krifka, 2007). As a consequence, sixty
and around sixty have the same level of precision,
while exactly sixty is more precise than sixty.
Third, we take into account modifiers (or nu-
merical hedges) such as under, over, more than,
and verbs such as topped. So we say that over
sixty and topped sixty are more precise than sixty
since they give more information.
Finally, we extend Krifka?s ideas (2007) to
cover common proportional quantities. Krifka
confined his ideas to scalar and numerical quan-
tities, but we propose that they can also be applied
to common proportions such as half, two thirds
and three quarters and their ratio, decimal, per-
centage and multiple equivalents. We hypothesise
that when speakers or writers use a common pro-
portion, they implicitly round up or down just the
same as with round whole numbers, so we would
argue that around a half is the same level of preci-
sion as a half, whereas more than half is more pre-
cise than half. When comparing different types,
we take the implied vagueness of common propor-
tions into account, so that we consider 25% to be
more precise than one quarter.
1.2 Maths form and conceptual complexity
Numerical proportions may be expressed by dif-
ferent mathematical forms, e.g., fractions, ratios,
percentages. Complexity of mathematical form
denotes the amount of effort and numerical skill
required by readers to interpret a numerical quan-
tity; as complexity of mathematical concepts in-
creases, the amount of effort required for compre-
hension also increases.
As a convenient measure of the complexity of
mathematical forms, we employ a scale corre-
sponding to the levels at which they are intro-
duced in the Mathematics Curriculum for Schools
(1999); that is, we assume that simple concepts are
Maths Form Level or
Complexity
Whole numbers 1?10 Level 1
Whole numbers 1?100 Level 2
Whole numbers 1?1000 Level 3
1-place decimals Level 3
Common fractions Level 3
Money and temperature Level 3
Whole numbers > 1000 Level 4
3-place decimals Level 4
Multiples Level 4
Percentages Level 4
Fractions Level 5
Ratios Level 5
Decimal Percentages Level 6
Standard index form Level 8
Table 1: Scale of Level/Complexity extracted
from the Maths Curriculum for Schools (1999)
taught before difficult ones, so that a child learns
whole numbers up to ten at Level 1, then much
later learns standard index form (e.g., 4.12x106)
at Level 8 (table 1).
2 Hypotheses
Our hypotheses about repeated mentions of nu-
merical facts are as follows:
? Precision will increase from first to subse-
quent mentions.
? Level of complexity of mathematical forms
will increase from first to subsequent men-
tions.
? Changes in precision and mathematical form
are related to document structure.
3 Empirical Study
3.1 The NUMGEN Corpus
The corpus has 97 articles on ten topics, where
each topic describes the same underlying numer-
ical quantities, e.g., 19 articles on the discovery of
a new planet al published in the first week of May
2007 (from Astronomy and Astrophysics, Nature,
Scientific American, New Scientist, Science, 11
newspapers and three Internet news sites). In total,
the corpus has 2,648 sentences and 54,684 words.
119
3.2 Corpus analysis and annotation
The articles were split into sentences automati-
cally, then checked and corrected manually. We
annotated 1,887 numerical quantity expressions
(788 integers, 319 dates, 140 decimals, 87 frac-
tions, 107 multiples, 66 ordinals, 336 percentages
and 44 ratios).
In this study, we looked for coreferring phrases
containing numerical quantities, such as the sen-
tences . . . of papers were marked A and . . . of A-
level papers were awarded an A grade in the above
text, and compared the numerical expressions as-
sociated with them.3 Then, for each fact, we noted
the linguistic form of first and subsequent men-
tions in each text and their document positions.
3.3 Judgements on precision and
mathematical level
Two readers (the authors) judged whether preci-
sion had changed from first to subsequent men-
tions of a numerical fact in a text, and if so,
whether it had increased or decreased, according
to the rules set out in the list in section 1.1. We
also judged the conceptual complexity of mathe-
matical forms, ranging from 1 to 8 (as defined in
table 1). For precision, the judges agreed on 94%
of cases (Cohen?s kappa is 0.88). Differences were
resolved by discussion.
3.4 Results
Table 2 shows results for binomial tests on 88
cases of repeated numerical facts. They show
a clear trend towards unequal precision between
first and subsequent mentions and, in the 62 cases
where it is unequal, an overwhelming trend for
precision to increase. Regarding mathematical
level (i.e., the complexity scale for mathematical
form), the trend is for subsequent mentions to have
a level equal to that of first mentions, but in the 31
cases where it is unequal, they show a significant
trend towards an increase in level ? i.e., subse-
quent mentions are conceptually more difficult.
Our first hypothesis (precision increases from
first to subsequent mentions) is thus clearly sup-
ported. Our second hypothesis (level of concep-
tual complexity increases from first to subsequent
mentions) is supported by significant increases in
level only where the level changed. Note that by
3Note that the numerical facts themselves do not corefer,
since they are merely properties of coreferring sets or scales
(Deemter and Kibble, 2000).
Observation n Prop. Sig.
Precision: Equal 26 .30 .0002
Unequal 62 .70
Precision: Increase 56 .90
Decrease 6 .10 .00001
Maths Level: Equal 57 .65
Unequal 31 .35 .007
Maths Level: Increase 25 .81
Decrease 6 .19 .0009
Table 2: Binomial tests on repeated mentions,
based on .5 probability, 2-tailed, Z approximation.
our definition, complexity of mathematical con-
cepts is distinct from precision: for example, 59
is more precise than 60 but equally complex (both
are taught at Level 2 ? whole numbers up to 100).
Further investigation revealed that mathematical
level tended to remain the same where both men-
tions were at the beginning of a document (n=14,
p < 0.005, in a 2-tailed binomial test, as above).
Hypothesis three (changes in precision and
mathematical form are related to document struc-
ture) is partially validated in that precision and
mathematical level both increase from early to
later positions in the document structure.
4 Discussion
Are these results surprising? We believe they show
that appropriate presentation of numerical infor-
mation requires surprising sophistication. It is
usual to summarise information early in an arti-
cle, but with numerical facts, summarisation can-
not be equated with lower precision or with sim-
pler mathematical form. If summarisation means
identifying important facts and presenting them
in a condensed form, then why are early men-
tions of numerical facts not condensed? A sur-
prisingly large proportion of first mentions (45%)
had longer (or equally long) strings than subse-
quent mentions (see the text in the introduction,
where More than a quarter is longer than 25.9 per
cent). Also, why change the mathematical form?
It is not obvious that 25.9% should be converted
to a common fraction. Intuitively we might reason
that 25.9% is close to 25% which can be expressed
by the simpler mathematical form a quarter, but it
is far from obvious how this reasoning should be
generalised so that it applies to all cases.
A side-effect of our analysis is that it pro-
vides some empirical evidence in support of
120
Krifka?s RNRI theory (2007); however, the data
is sparse. Ten repeated mentions of numerical
facts had round, whole number first mentions
and subsequent mentions that were more precise,
e.g., 200,000. . . 207,000. Thus demonstrating that
authors do indeed write round numbers which
they intend readers to interpret as being approxi-
mate. There is similar evidence from 22 examples
demonstrating that RNRI can be extended to com-
mon proportions.
5 Related work
Communicating numerical information is impor-
tant in Natural Language Generation (NLG) be-
cause input data is wholly or partially numerical
in nearly every NLG system, but the problem has
received little attention. For example, SUMTIME
summarises weather prediction data for oil rig per-
sonnel e.g., 1.0-1.5 mainly SW swell falling 1.0
or less mainly SSW swell by afternoon (Reiter et
al., 2005) but would require much greater flexi-
bility to present the same numerical facts to non-
professionals.
The difficulty of communicating numerical in-
formation has been highlighted in educational and
psychological research. Hansen et al?s book
(2005) provides ample evidence of confusions that
many children have about e.g., decimal places; in-
deed, they demonstrate that many believe 68.95%
is larger than 70.1% -- misconceptions that often
persist into adulthood. Even professionals misun-
derstand the mathematics of risk. Gingerenzer and
Edwards (2003) found doctors calculate more re-
liably with reference sets than with proportions.
We are not aware of any research on linguistic
variation in proportions; in fact, a recent special is-
sue on numerical expressions contained no papers
on proportions (Corver et al, 2007).
6 Conclusions and Future Work
In this paper we presented:
? A set of rules for determining precision in nu-
merical quantities that is sufficient to cover
the examples in our corpus
? A scale for conceptual complexity in numer-
ical expressions derived from the Mathemat-
ics Curriculum for Schools.
? A corpus of sets of articles whose main mes-
sage is to present numerical facts
? Empirical results demonstrating trends to-
wards increasing precision and complexity in
repeat mentions of numerical facts with posi-
tion in document structure.
Our results identify an interesting and well-
defined problem that will be addressed in the fi-
nal stage of NUMGEN: how to derive appropriate
simplified expressions (less precise, simpler math-
ematical form) for use in contexts like the open-
ings of articles, or communications intended for
readers with lower levels of mathematical ability.
Acknowledgements
Our thanks to members of The Open University
NLG Group. NUMGEN is supported by ESRC4
Small Grant RES-000-22-2760.
References
N. Corver, J. Doetjes, and J. Zwarts. 2007. Linguis-
tic perspectives on numerical expressions: Introduc-
tion. Lingua, Special issue on Linguistic perspec-
tives on numerical expressions, 117(5):751?775.
K. Van Deemter and R. Kibble. 2000. On Corefer-
ring: coreference in MUC and related annotation
schemes. Computational Linguistics, 26:629?637.
G. Gigerenza and A. Edwards. 2003. Simple tools
for understanding risks: from innumeracy to insight.
British Medical Journal, 327:714?744.
A. Hansen, D. Drews, J. Dudgeon, F. Lawton, and
L. Surtees. 2005. Children?s Errors in Maths:
Understanding Common Misconceptions in Primary
Schools. Learning Matters Ltd, Exeter, UK.
M. Krifka. 2007. Approximate interpretation of num-
ber words: A case for strategic communication. In
G. Bouma, I. Kraer, and J. Zwarts, editors, Cognitive
foundations of interpretation, pages 111?126, Am-
sterdam. Koninklijke Nederlandse Akademie van
Wetenschapen.
Qualification and Curriculum Authority. 1999. Math-
ematics: the National Curriculum for England. De-
partment for Education and Employment, London.
E. Reiter, S. Sripada, J. Hunter, J. Yu, and I. Davy.
2005. Choosing words in computer-generated
weather forecasts. Artificial Intelligence, 167(1-
2):137?169.
4Economic and Social Research Council
121
Generating Numerical Approximations
Richard Power?
Open University
Sandra Williams??
Open University
We describe a computational model for planning phrases like ?more than a quarter? and ?25.9
per cent? which describe proportions at different levels of precision. The model lays out the key
choices in planning a numerical description, using formal definitions of mathematical form
(e.g., the distinction between fractions and percentages) and roundness adapted from earlier
studies. The task is modeled as a constraint satisfaction problem, with solutions subsequently
ranked by preferences (e.g., for roundness). Detailed constraints are based on a corpus of numer-
ical expressions collected in the NUMGEN project,1 and evaluated through empirical studies in
which subjects were asked to produce (or complete) numerical expressions in specified contexts.
1. Introduction
We describe in this article a computational model for planning phrases that express
proportions (e.g., ?more than a quarter? and ?25.9 percent,? among others, as alternative
descriptions of the proportion 0.259). This task is of interest for several reasons. First,
such expressions are very common in factual discourse?they will be found on almost
any page in a newspaper or scientific journal. Second, any numerical value can be
expressed in a variety of ways, differing along such dimensions as precision, formality,
and mathematical sophistication; generating the range of suitable phrases is therefore
non-trivial. Third, the matter has been largely ignored in the literature on Natural
Language Generation (NLG), even though many NLG systems are designed to produce
text from numerical data in domains like weather forecasting (Reiter et al 2005), stock
market trends,2 and medical records (Hallett, Scott, and Power 2007). Finally, and more
subtly, the task provides a convenient microcosm of the general pragmatic problem
of determining optimal information content?for instance, of balancing preferences for
precision and brevity (Krifka 2002).
The work reported here was carried out in the NUMGEN project, and exploits the
NUMGEN corpus of numerical expressions drawn from families of texts describing the
? Department of Computing, Open University, Milton Keynes MK7 6AA, UK.
E-mail: r.power@open.ac.uk.
?? Department of Computing, Open University, Milton Keynes MK7 6AA, UK.
E-mail: s.h.williams@open.ac.uk.
Submission received: 1 August 2009; revised submission received: 31 March 2011; accepted for publication:
25 May 2011.
1 NUMGEN: Generating intelligent descriptions of numerical quantities for people with different levels of
numeracy (http://mcs.open.ac.uk/sw6629/numgen). NUMGEN was funded by the Economic and Social
Research Council under Grant Ref. RES-000-22-2760.
2 http://www.ics.mq.edu.au/lt-gdemo/StockReporter/.
? 2012 Association for Computational Linguistics
Computational Linguistics Volume 38, Number 1
same facts. Because the same quantitative fact is mentioned within and across multiple
texts, the corpus provides many examples of linguistic expressions that describe exactly
the same quantity. For instance, the following excerpt from an article in the UK news-
paper The Daily Telegraph contains several expressions representing proportions, includ-
ing the two phrases given as examples in the opening sentence of this article (and shown
here in italics), both of which describe the proportion of A-level papers3 that received
the top grade (A) in 2008:
A-level results show record number of A grades
Record numbers of teenagers have received top A-levels grades. More than a quarter of
papers were marked A as results in the so-called gold standard examination reach a
new high.
The overall pass rate also rose beyond 97 per cent for the first time ? the 28th straight
increase ? fuelling claims that A-levels are now almost impossible to fail. [. . . ] Today?s
results for 300,000 students in England, Wales and Northern Ireland were expected to
trigger a scramble to get into university, with experts predicting a record rise in the
number of applicants going through the clearing system. Applications to university
have already increased by nine per cent this year.
According to figures released today by the Joint Council for Qualifications, 25.9 per cent
of A-level papers were awarded an A grade this summer, compared to 25.3 per cent
12 months earlier ? and just 12 per cent in 1990.
(Daily Telegraph, 14th August 2008)
The NUMGEN corpus contains 14 articles reporting this story, mostly from UK news-
papers; in total, it has nearly 100 articles covering ten stories. The numerical facts found
in the corpus include cardinalities (e.g., ?300,000 students?) and measures (?28 years?)
as well as proportions, but the project focused on proportions as a convenient subset.
Elsewhere we have shown that proportions tend to be expressed differently at dif-
ferent locations within a document (Williams and Power 2009). The phrases ?more than
a quarter? and ?25.9 percent? in the example extract provide a convenient illustration
of the nature of these differences. First, there is an obvious disparity in precision. Next,
the phrases differ in mathematical form (fraction vs. percentage); we have argued that this
distinction is conceptual as well as notational, because fractions are accessible to a wider
readership than percentages?as testified by the levels at which they are introduced
in the UK mathematics curriculum (Qualification and Curriculum Authority 1999).
Finally, one of the phrases contains not only a quantity (?a quarter?) but a modifier
(?more than?); such modifiers have been called hedges (Lakoff 1973; Crystal 1988), and
they serve (among other things) to indicate the arithmetical relationship between the
quantity that follows and the actual value (0.259 > 1/4). Our corpus study showed that
fractions and round numbers tend to occur in the opening of a document, whereas
subsequent references to the same fact are more likely to use precise percentages.
These differences in precision and formality raise two questions, one concerning
motivation (why do speakers/writers approximate?), the other concerning technique
(how do they approximate?). On the first point, various motives have been proposed.
Speakers might aim at conceptual simplicity (Krifka 2007)?for example, because round
numbers are easier to remember and calculate with; or they might wish for various rea-
sons to avoid commitment (van Deemter 2009). Also, as implied by Grice?s (1975) qual-
ity and quantity maxims, the benefits of precision need to be balanced against the costs;
this trade-off has been discussed within the framework of optimality theory (Dekker
3 The A-level examination is taken by British 18-year-olds in their final year of school; university places are
usually conditional on the grades obtained in this examination.
114
Power and Williams Generating Numerical Approximations
and van Rooy 2000; Krifka 2002; Blutner and Zeevat 2011). Little attention has been paid,
however, to the second question?regarding the technique of approximation?despite its
intrinsic interest and its practical importance in applications of NLG.
Our aim in this article is to explain formally how speakers/writers are able to
produce numerical expressions with varying degrees of precision and formality. We
propose a two-stage generation process, the first stage producing a language-neutral
semantic form such as > 1/4, the second stage realizing this semantic form in English
or some other natural language (e.g., ?over a quarter?, ?more than 1/4?). Our model
considers the first stage only, and aims to generate the set of alternative semantic
forms underlying acceptable numerical expressions. Choosing the most appropriate
alternative from this set would depend on the pragmatic context; here, for generality,
the model identifies a number of criteria (roundness, accuracy, etc.) but leaves open
how they should be weighted (or otherwise combined).4
The structure of the article is as follows. In the next section we review previ-
ous linguistic and philosophical work on numerical expressions and approximation.
Section 3 adapts some important insights from this literature to propose a new formal
model for planning the semantic forms of proportion expressions; we then describe
an implementation of this model in Section 4, followed by an empirical evaluation in
Section 5. Section 6 discusses the outcome of the evaluation, and concludes.
2. Previous Work
2.1 Linguistic Background
Mathematically, a proportion is the cardinality of a set divided by the cardinality of
a superset. If S is a set, its cardinality CS is defined as the number of elements that S
contains; thus if SS is a superset of S (meaning that every element in S is also in SS), then
CS/CSS is a proportion. From this it follows that a proportion must lie between 0.0 and
1.0, because it will have its minimum value when S is empty, and its maximum value
when S is identical to SS. Typically, S and SS can be identified by descriptions, with S
distinguished by an extra attribute. Thus in our A-level example, SS is the set of A-level
papers marked in 2008, and S is the subset of these papers that received an A grade. To
calculate the proportion 25.9%, somebody or something (probably a computer program)
must have counted the total number of papers, then counted those distinguished by an
A-grade, then divided the latter number by the former.
Syntactically, proportion expressions usually occur as pre-modifiers in noun
phrases, in constructions of the form P of Ns where N is a noun. Both mentions of the
A-grade proportion in our sample text fit this pattern:
More than a quarter of papers were marked A
25.9 per cent of A-level papers were awarded an A grade this summer
In general, such expressions comprise a numerical value, optionally preceded by a
hedge. It is important to note that the numerical value in the expression may differ from
the actual value of the proportion, just as a place can be described with reference to
a convenient (but different) landmark (e.g., ?beyond the church?). For this reason we
4 The program actually prints out solutions in order of accuracy, so that precise descriptions occur towards
the beginning and round ones towards the end.
115
Computational Linguistics Volume 38, Number 1
will introduce the term given value for the numerical value found in the quantifying
expression. To understand the expression, a reader must infer the relationship between
the given value (call it VG) and the actual value (VA). One important clue is provided by
the hedge; thus in ?more than a quarter? the hedge ?more than? indicates that VA > VG
where VG = 1/4. Another clue, it has been argued, is provided by the given value itself,
because round numbers are likely to be interpreted as approximations (Krifka 2002).
Thus in ?a quarter of papers were marked A? the given value is a simple fraction,
suggesting that VG has been selected by the writer as a round number conveniently
near VA, and that the relationship is accordingly VA ? VG.
The term hedge was introduced by Lakoff (1973) and subsequently applied to nu-
merical descriptions by Dubois (1987), who studied imprecision in oral scientific presen-
tations and listed some common numerical hedges (e.g., ?about?, ?almost?, ?nearly?,
?of the order of?, ?a little over?); Crystal (1988) added a few more. Because Crystal
applied the term to any expression indicating imprecision or uncertainty, he included
some terms like ?maybe?, ?usually?, ?probably?, which are not relevant here. However,
restricting the field to numerical hedges, all Dubois?s examples concern the relationship
between given value and actual value, and in particular VA ? VG. In the NUMGEN
corpus, the most common hedge was ?more than? (expressing VA > VG), followed by
?about? (VA ? VG), ?under? (VA < VG), ?almost?, and ?nearly?.5 In marking up the
corpus, the modifier ?exactly? was also counted as a hedge, even though its purpose
is to confirm rather than to disclaim a precise commitment, since in common with the
other hedges it indicates a relationship between a given and an actual value (VA = VG).
We have discussed informally the possible forms and meanings of hedges; what
of the given value itself? From preliminary analysis of the NUMGEN corpus, three
basic forms for proportion values were identified, and used subsequently for mark-up:
fractions, percentages, and ratios. Fractions almost invariably had simple denominators
(2, 3 or 4) and were expressed in words rather than digits (e.g., ?two-thirds? rather than
?2/3?). Percentages were by contrast expressed almost always in digits??25 percent?
(or ?25%?) rather than ?twenty-five percent?; the numerical part was often a decimal,
usually with just one digit after the point. Ratios were sometimes used as an alternative
to fractions (e.g., ?one in four students obtained an A grade?), but with more freedom in
choosing denominators, which were sometimes large or non-round numbers (?roughly
one in 17 Britons?); because they were relatively rare, they are not included in the model
presented here.6
Stepping back, one could ask whether these are merely distinctions in surface
form, because the underlying quantities are always expressible as rational numbers
(i.e., Num/Den where numerator Num and denominator Den are both integers). We
have several reasons for treating mathematical form as a deeper conceptual distinc-
tion, however.7 Firstly, as we will show later, fractions and percentages typically have
denominators from different sets?low integers for fractions, powers of ten and related
5 Note that the hedges ?almost? and ?nearly? do not mean the same as ?less than?, because they can
also be used when VA > VG (e.g., ?the temperature fell to nearly zero?). However, it has been pointed
out to us that they do not mean the same as ?about? (i.e., VA ? VG) either; rather, they imply that VA
approaches VG from a direction indicated by the context, which might be either from above or below
(e.g., ?fell?, ?rose?)?a more subtle relation that we have not attempted to cover in the present article.
6 Note that by ratio here we refer not to the abstract mathematical operator, but to linguistic realizations
like ?N in M?, ?N out of M?, ?N of any M?, where N and M are integers.
7 In terms of the standard NLG pipeline architecture (Reiter 1994), this would mean that mathematical
form is already decided in the phase of content determination, so that the distinction between fractions,
ratios, and percentages is an input to the subsequent phases (sentence planning, surface realization, etc.).
116
Power and Williams Generating Numerical Approximations
integers for percentages. They also represent distinguishable levels of numerical compe-
tence, as evidenced by the UK mathematics curriculum (Qualification and Curriculum
Authority 1999) in which percentages are introduced later than fractions and depend
conceptually upon them. Finally, judgments of roundness can only be made relative
to a given mathematical form: thus in fractions 1/3 is rounder than 3/10, whereas in
percentages 33.33% is less round than 30%. This means that any program planning to
describe a proportion VA by relating it to a round number VG will have to take account
of mathematical form in selecting VG.
2.2 Roundness
It is a matter of common observation that some numbers are perceived as rounder
than others, and hence more likely to be employed in approximations. You might
approximate 0.259 by saying ?about a quarter?, but you would never approximate 0.25
by saying ?about 25.9 percent.? But what exactly is meant by roundness? Linguists and
psychologists have approached this question in various ways.
In Hurford?s book The Linguistic Theory of Numerals (Hurford 1975), numbers are
distinguished according to the roles they can play in verbal numerals. A few privileged
numbers can serve as multiplicands: In English and most European numeral systems
these would include 100, 1000, 1000000, and also perhaps 10 if we take account of word
morphology (i.e., if we think of ?forty? as meaning 4 ? 10). An important (although less
exalted) set can be named by forming a product with one of the multiplicands (e.g.,
?twenty?, ?two hundred?). Finally, at the bottom of the heap, we find the numbers
typically named as the sum of a product and another (smaller) number: thus ?sixty
five? is the sum of 60 and 5, or ?three hundred sixty five? is 300 + 65.
An alternative three-tier classification has been proposed by Pollmann and Jansen
(1996), on the basis of empirical evidence including number frequencies, currency sys-
tems, and approximations of the form ?30 or 35 people.? At the top level of roundness
are ?favorite numbers,? defined thus:
In any numeration system in base N, there is a set of favourite numbers comprising
(a) any integer power of the base, and (b) half, double, and half of half of any integer
power of the base.
(Pollmann and Jansen 1996, page 225)
With a numerical system based on 10, this definition yields the set F(10) defined as
follows:
F(10) = { f |f = 10n ? K} where K is 1, 2, 1/2 or 1/4, and n is any integer.
Note that this definition allows n to take negative values, or zero; hence 0.05 is also
classified as a favorite number because it can be formed by f = 10?1 ? 1/2.
The special status of F(10) numbers is attested by currency systems: For instance,
in pounds sterling there are coins for ?0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0, and 2.0, as well
as notes for ?5, 10, 20, 50, 100, and so forth. In a survey of currencies from 84 countries
(Pollmann and Jansen 1996), only 13 out of about 1,000 coins/notes lay outside F(10)
(e.g., a three-dollar banknote in the Cook Islands). Frequency data also support the
principle: Using a corpus of Dutch newspaper articles, Jansen and Pollmann (2001)
found spikes (local maxima) in the frequency plot for numbers belonging to F(10) (thus
10 was more common than 9 or 11). From experiments on phrases like ?30 or 35 people,?
117
Computational Linguistics Volume 38, Number 1
they also arrived at a wider group of round numbers (termed ?sequences?), formed
by multiplying any favorite number F by a low integer M with values in the range
M = 1 . . . 20: This set would include for example 5, 10, 15, . . . 95, 100, which are multiples
M*F of the favorite number 5.
Another approach to roundness is to think of measurements as taken from scales
of different granularity, as suggested for example by Krifka (2007). A scale is defined
as a set of evenly spaced points, so that consecutive points are always separated by a
unit distance d?it is equivalent, in other words, to Pollmann and Jansen?s concept of
?sequence.? However, scales can be organized into systems of varying granularity, so
that for example in the metric system for measuring length we have meters, decimeters,
centimeters, millimeters, and so forth, with granularity increasing tenfold from each
scale to the next. Less obviously, we can think of the minutes in an hour as belonging
to the following four scales, in which the units are respectively one hour, half an hour, a
quarter of an hour, and five minutes (example from Krifka 2007):
0---------------------------------60----------------------...--120
0---------------30----------------60----------------90----...--120
0------15-------30-------45-------60-------75-------90----...--120
0-5-10-15-20-25-30-35-40-45-50-55-60-65-70-75-80-85-90-95-...--120
The roundness of a number, relative to a scale system, can then be equated with the
coarsest-grained scale to which it belongs (i.e., the earliest scale, if they are arranged
in order of increasing granularity). Thus in this scale system 45 is rounder than 40,
although in most systems (e.g., metric distance) 40 would be rounder than 45.
3. Formal Model for Proportions
We have reviewed some insights from the literature on hedging, mathematical form,
and roundness; we now aim to draw these together into a formal model that can be
implemented and evaluated.
The first crucial insight from linguistic work on hedging is that proportions (and
indeed other quantities) are expressed by relating them to another, typically different
quantity that we have called the given value VG, with the hedge (if present) indicating
the nature of this relationship. Thus in expressing the proportion 0.259 by ?over a
quarter,? we have an actual value VA (0.259), a given value VG (1/4), and a relationship
VA > VG. This leads to the idea that underlying any numerical expression there will
be some kind of arithmetical relationship between VA and VG. The task of producing
the expression can therefore be divided into two stages: (a) choosing an appropriate
semantic relationship such as VA > 1/4 or VA ? 26/100; (b) choosing an appropriate
linguistic realization of this relationship, such as ?over a quarter? or ?about 26 percent.?
The second crucial insight, from the work on favorite numbers and roundness, is
that given numbers can be conceptualized as points along scales, of varying granularity,
organized into systems. This is obvious in Krifka?s (2007) example of time measures,
and also for distance measures where we are familiar with different systems such as
imperial units (inches, feet, yards, etc.) and metric units (centimeters, meters), but it
can be applied also to representing proportions. Adopting the simplest and most direct
approach, we can measure proportions on scales that divide the interval from 0.0 to 1.0
into N equal segments, where N is an integer greater than 1. A scale system can then
be defined as a set of scales ordered by increasing granularity (and hence increasing
N). Thus if we denote a scale with N segments by SN, an example of a scale system
would be the set [S10,S100,S1000], for which the units correspond to 10%, 1%, and 0.1%.
118
Power and Williams Generating Numerical Approximations
To specify a given value VG we must choose (a) a system, (b) a scale from the system,
and (c) a point from the scale?the points on a scale SN being represented by integers
from 0 to N.
This formalization of the given value has the advantage of distinguishing not only
degrees of roundness, but also different mathematical forms, which can be equated with
scale systems. Thus the system including [S10,S100,S1000] corresponds to the mathemati-
cal form percentages, whereas simple fractions use instead a system with very low values
of N, including [S2,S3,S4]. Equating roundness with the N value of the scale, it follows
that simple fractions are rounder than percentages, and that within any scale system,
earlier scales are rounder than later ones. For instance, within the percentage system,
40% would be considered rounder than 45%, because it first appears on the S10 scale
whereas 45% first appears on S100.
Conceptualized in this way, the semantic form of a proportion expression is the
result of four choices, each from a finite domain of options.8
 Choose an arithmetical relation between VA and VG (e.g., from the
set {=,?,>,<}).
 Choose a scale system for expressing VG (e.g., either fractions or
percentages).
 Choose a scale from this system.
 Choose a point from this scale.
Thus to obtain the semantic form for ?over a quarter,? starting from VA = 0.259, we
would choose (1) the relation >, (2) the scale system [S2,S3,S4, . . .] (fractions), (3) the
scale S4, and (4) the point 1. Alternatively, to obtain the semantic form for ?about 26 per-
cent,? the choices would be (1) the relation ?, (2) the scale system [S10,S100,S1000, . . .]
(percentages), (3) the scale S100, and (4) the point 26.
3.1 Scale Systems
We have described the outline of a model for planning proportion expressions; to im-
plement this model in an actual generator, we need to make specific assumptions about
the scale systems to be employed. We have suggested earlier that there are two major
scale systems for proportions, corresponding to fractions and percentages, the former
based on very low values of N (e.g., [S2,S3,S4]), the latter based on powers of ten. As a
preliminary test of this idea, we have taken all VG values for fractions and percentages in
the NUMGEN corpus, and re-expressed them as rational numbers of the form Num/Den,
reduced to their minimal terms so that numerator Num and denominator Den have no
common factor, and counted the frequencies of all denominators.9 The results (Table 1)
show a clear difference in the two distributions, with fractions having denominators in
the range 2?4 (apart from a couple of outliers), and percentages spread more widely,
with peaks in powers of 10 or their multiples.
8 Note that in a constraint-based model these choices are not sequentially ordered, so we are not, for
instance, implying that the arithmetical relation should be chosen first.
9 Thus, for example, 50% would be expressed as 1/2, which is 50/100 reduced to minimal terms; similarly,
7.5% would be expressed as 3/40 after reducing 75/1000.
119
Computational Linguistics Volume 38, Number 1
Table 1
Denominators for fractions and percentages in NUMGEN corpus.
Frequencies
Denominator Fractions Percentages
1 0 13
2 33 16
3 29 0
4 18 11
5 0 12
10 0 24
14 2 0
20 0 13
25 0 35
40 0 4
50 0 21
100 0 54
Other 0 139
Total 82 324
These data support an initial calibration of the model with separate scale systems
for fractions and percentages, the system for fractions being simply [S2,S3,S4]. For
percentages, we need to decide (a) how far to extend the granularity (e.g., whether to
include S10000, S100000, etc.), and (b) which intermediate scales to include (e.g., whether
to include S20, which would cover percentages divisible by 5, such as 5% and 15%).
For practical convenience in presenting and testing the model, we have decided to limit
granularity to S1000, so that we cover, for instance, 25.9% but not 25.95%. Regarding
intermediate scales, Table 1 provides support for S20 but even stronger support for S25,
which would yield percentages like 16% divisible by 4 rather than 5. This result could
also be due to bias in our (fairly small) corpus, however; searching for phrases of the
form ?X percent? in the Google Labs Ngram Viewer10 showed a clear preponderance
of percentages divisible by 5 compared with neighbors divisible by 4 (Table 2). We
therefore begin by limiting the scale system for percentages to [S10,S20,S100,S1000]11?
that is, powers of ten up to 1,000 with a single intermediate scale for percentages
divisible by 5.
3.2 Imposing Constraints
Having specified two scale systems and a set of arithmetical relations (=,?,>,<), we
can generate a large (but finite) set of semantic forms, most of which will of course be
unsuitable for describing any particular input proportion such as 0.259. To narrow these
down, we need to impose constraints which can be separated into three categories: (1) Is
the description true? (2) Is the description competent? (3) Is the description appropriate,
given the context and the speaker?s goals?
10 The search was performed in July 2011 at http://ngrams.googlelabs.com/.
11 These initial settings of the scale systems are motivated by a trade-off between keeping the model simple
while covering the most likely solutions; they could and should be modified if, for example, a domain
has special requirements or conventions (such as the use of eighths in U.S. stock prices).
120
Power and Williams Generating Numerical Approximations
Table 2
Hits on Google Labs Ngram Viewer (millions) for percentages divisible by 5, and close neighbors
divisible by 4. The data were obtained by searching for bigrams such as ?15 percent? in the
Google English Books corpus for the years 1800?2000.
Divisible by 5 Divisible by 4
Percentages Frequencies Percentages Frequencies
15 2.1 16 0.7
25 2.4 24 0.5
35 1.3 36 0.4
45 0.9 44 0.4
55 0.6 56 0.3
65 0.7 64 0.2
75 1.5 76 0.2
85 1.0 84 0.2
95 1.2 96 0.2
Total 11.7 Total 3.1
To obtain a true description, the generator must obviously ensure that the relation-
ship asserted between VA and VG actually holds. Thus for VA = 0.259, the solution
VA > 26/100 (choosing the 26th point along the S100 scale from the percentage scale
system, with the relation >) should be rejected as untrue, because the actual value 0.259
is less than the given value 26/100, not greater.
Having overcome the hurdle of truth, a candidate solution can be checked for what
we have called ?competence.? By this we mean that a solution should be excluded if
another solution is superior in all contexts. Consider, for example, the solution VA < 4/10
(again for the input VA = 0.259), in which VG is represented by the fourth point along
the S10 percentage scale. As a method for approximating 0.259 we would argue that this
is incompetent, because using the same arithmetical relation < and the same scale S10,
a closer approximation could have been obtained by choosing the third point instead
of the fourth. Of course the generator could get even closer by choosing, for instance,
VA < 26/100, but VA < 3/10 has the potential benefit of using a rounder scale, so both
are competent.
Finally, from the set of true and competent solutions, the generator needs to select
the semantic form that is most appropriate pragmatically. Here many factors come into
play, some of which have been mentioned previously (e.g., technical sophistication of
the reader/hearer, ease of comprehension, utilities of different levels of precision, eval-
uation of the proportion as higher or lower than expected). We have not included such
factors in the model described and evaluated in this article, but it is worth commenting
briefly on how this could be done, through optimization methods typical of constraint-
based applications.
In broad terms, what is required is a function that associates a contextually based
cost with each solution, so that the set of true and competent solutions can be ranked
from most to least appropriate. Plausibly, this function would measure various features
of the solution, including mathematical difficulty, emphasis, roundness, and accuracy,
and combine them through a weighted sum, with weights reflecting the contextual
revelance of the features. Thus, for contexts in which readers lack mathematical so-
phistication, solutions using the percentage scale system should incur extra cost; if the
writer?s aim is to emphasize that the actual value is higher than expected, solutions
121
Computational Linguistics Volume 38, Number 1
using the arithmetical relation < should be penalized; where small differences in the
actual value have important practical consequences, accuracy should receive a higher
weighting than roundness; and so forth.
4. Implementation of the Generator
The input to the generator is a proportion, specified as a real number between 0.0
and 1.0 correct to three places of decimals; the output is a set of alternative semantic
forms describing the proportion, where each semantic form is constructed by making
four choices from finite domains: (1) a scale system, (2) a scale from this system, (3) a
point from this scale, and (4) an arithmetical relation. To implement a generator of this
kind, it is convenient to formulate the task as a constraint satisfaction problem, which is
characterized by the following components (van Hentenryck 1989):
 A set of variables V1. . .Vn
 For each variable Vi a finite domain Di of possible values
 A set of constraints on the values of the variables
A solution assigns to each variable Vi a specific value from its domain Di, while
respecting all constraints. In implementations using Constraint Logic Programming
(CLP), programs typically have a three-part structure: first, the domains of the variables
are initialized; secondly, constraints over the variables are imposed; finally, values for
the variables are chosen?a process sometimes called ?labeling.? The labeling stage
introduces backtracking points whenever a variable can take one of several values,
so that multiple solutions can be generated if desired (and if they exist). However,
by using the constraints before labeling in order to reduce the domains of the vari-
ables, CLP can achieve substantial efficiency gains over algorithms that rely on
generate-and-test, and has been used successfully for a variety of NLP tasks (Koller
and Niehren 2000).
4.1 Assigning Domains to Solution Variables
Any solution is defined by four variables which we will call System, Scale, Point, and Re-
lation. For two of these variables, domains can be assigned during initialization: System
must belong to {Fraction, Percentage} and Relation to {=,?,>,<}. For the other vari-
ables, the domain can be assigned only during the search phase, because it depends on
the values of other variables. For instance, the domain of Scale can be set to {S2,S3,S4}
as soon as System receives the value Fraction, or alternatively to {S10,S20,S100,S1000} if
System receives instead the value Percentage. Similarly, the domain of Point can be set
only when a value of Scale has been chosen?in general, if Scale has the value SN, Point
should have the domain 0. . .N.
4.2 Constraints
Having initialized the domains of the variables (where possible), the program next
applies five constraints which rule out solutions that are ill-formed (i.e., outside our
scale systems), untrue, or incompetent; for convenience these will be given names (see
122
Power and Williams Generating Numerical Approximations
subsequent list). The first two (Scale Domain, Point Domain) perform the conditional
domain assignments just described, thus ensuring that solutions lie on the scales that
we have prescribed. The third (Correct Description) is concerned with correctness, and
the final two (Minimal Distance, Extreme Point) with competence.
1. Scale Domain: The scale must belong to the selected scale system. For
instance, if System = Fraction, the domain of Scale is {S2,S3,S4}.
2. Point Domain: The point chosen as given value must belong to the
selected scale. For instance, if Scale is S4, the domain of Point is 0..4.
3. Correct Description: The relation must be adapted to the given value so
that the proportion is described correctly. For instance, if VA is 0.259 and
VG (i.e., Point/Scale) is 1/4, then Relation must be one of {?,>}.
4. Minimal Distance: For a given relation and scale, the point selected as
given value should be as close as possible to the actual value of the
proportion. For instance, if VA is 0.259, Relation is >, and Scale is S4, Point
must be 1, not 0.
5. Extreme Point: If extreme points (equivalent to 0.0 and 1.0) are used
as given values, the relation should not be either > or < (i.e., when
approximating one should avoid expressions like ?more than 0%?
and ?less than 100%?).
Whereas the first three constraints are straightforward and obviously necessary, Mini-
mal Distance and Extreme Point make more interesting claims that require discussion
and empirical testing.
4.2.1 Minimal Distance. The assumption here is that when making an approximation, the
generator should make the best possible use of the chosen scale, by considering only
points that are adjacent to the actual value.12 This means, for instance, that if VA = 0.259
and Scale = S10, the only points that should be considered are 2 and 3. Which of these is
chosen will depend on the relation: for ? it will be 3 (which is closer); for < and > the
choice will depend on correct description. Note that we have not excluded > 2 on the
grounds that < 3 is closer, because there might be pragmatic reasons for preferring one
relation to the other.13
4.2.2 Extreme Point. This constraint prohibits the use of the relations > and < in associa-
tion with given values at the extreme points of the scale (e.g., 0/10 and 10/10 if Scale =
10); such combinations are not found in the NUMGEN corpus and it is hard to imagine
contexts when they would be appropriate as approximations.14
12 Note that we are assuming that the purpose of the given value is to approximate the actual value. The
minimal distance constraint would not apply when the given value had a special practical significance:
For instance, in a country where a referendum was valid only with turnout exceeding 55%, a journalist
might report ?Turnout was more than 55%? when the actual value was 93%.
13 Intuitively, ?more than 20%? seems to emphasize how high the proportion is compared with what was
desired or expected, and ?less than 30%? how low.
14 One sometimes hears pronouncements like ?I will not accept less than 100% effort? (e.g., in a team talk),
but this seems more a rhetorical flourish than an attempt to approximate an actual value.
123
Computational Linguistics Volume 38, Number 1
4.3 Preferences
The constraints just described yield multiple solutions for any given input value; to
complete the model, we need to consider contextual reasons why speakers/writers
might prefer some solutions to others. Regarding for example the System variable,
we have already pointed out some reasons why writers might prefer fractions to per-
centages (or vice versa), including location within the document, and the educational
level of the reader. Similarly, with regard to Relation, considerations of emphasis might
favor > over < (or vice versa), as in the sentence ?More than a quarter of papers
were marked A. . . ? in our initial example, which focuses attention on how easy the
A-level examinations have become. For present purposes, nothing can be said about
these choices except that they depend on contextual features outside the scope of our
current model. However, regarding the choice of Scale, we can filter out some solutions
on the assumption that speakers/writers apply a trade-off between roundness and
accuracy. That is, we can show that however these two factors are weighted (provided
that they are not judged irrelevant or even undesirable), some solutions will be inferior
to others and can therefore be discarded. This is done by the following rule:
Roundness Preference
If two solutions have the same values for System and Relation, and different values for
Scale, then the solution with the larger Scale value should be discarded unless it has
higher accuracy.
A similar rule could be formulated for solutions along the same scale with different
accuracies, but in our implementation this case is already covered by the Minimal
Distance constraint.
One advantage of the Roundness Preference rule is that it avoids duplicate solutions
in which the values for Point/Scale are arithmetically equivalent, such as 5/10 and 10/20
(values for System and Relation being the same). According to Krifka?s Round Number
Round Interpretation principle, readers of a phrase like ?about 50%? will apply an
interpretation bias favoring coarse-grained representations (i.e., scales with a relatively
low N-value), and writers will take this bias into account. We can therefore prefer 5/10
to 10/20, 50/100, and any other equivalent given value with Scale exceeding 10, and
filter out these dispreferred duplicates.15
In our implementation, filtering through the Roundness Preference is applied after
labeling, because it relies on comparing each candidate solution with the other can-
didates. In general this kind of procedure can lead to computational inefficiency; in
planning descriptions of proportions, however, the number of candidates should not be
large enough for this to be a problem, given that most combinations will already have
been eliminated by the constraints applied before labeling.16
15 Note incidentally that this principle has empirical consequences, because different Scale values imply
different degrees of approximation. Thus if ?more than 50 percent? means ?> 5/10,? the implied range
of the proportion (applying the Minimal Distance Constraint) is from 50.1% to 59.9%, whereas if it
means ?> 10/20? the implied range is from 50.1% to 54.9%.
16 If efficiency became an issue, owing for instance to very complex scale systems, it could be increased by
using branch-and-bound search, which discards any solution (even if incomplete) as soon as its cost
exceeds the best alternative found so far, thus avoiding the need to generate all solutions before filtering.
Some simple efficiency tests using the Sicstus Prolog statistics operator showed that with our current scale
systems (two systems each with four scales), runtimes averaged over 100 trials were 3.5 milliseconds;
extending each system first to 8 then to 12 scales increased average runtimes to 6.0 and 11.9 milliseconds;
extending the number of systems first to three then four increased them to 5.5 and 11.4 milliseconds.
124
Power and Williams Generating Numerical Approximations
Table 3
Solutions generated for VA = 0.259.
System Point/Scale Relation Realization
Perc 259/1000 = exactly 25.9 percent
Perc 26/100 ? about 26 percent
Perc 26/100 < less than 26 percent
Frac 1/4 ? about a quarter
Frac 1/4 > more than a quarter
Perc 5/20 ? about 25 percent
Perc 5/20 > more than 25 percent
Perc 3/10 ? about 30 percent
Perc 3/10 < less than 30 percent
Frac 1/3 ? about a third
Frac 1/3 < less than a third
Frac 1/2 ? about a half
Frac 1/2 < less than a half
4.4 Example of Output
Table 3 gives a full listing of output for our original A-level example (VA = 0.259),
with solutions ordered by accuracy.17 For convenience, the table includes a possible
verbalization of each semantic form.
5. Evaluation
Overall, we would like the generator to satisfy two requirements: First, it should allow
all the good solutions; second, it should exclude the bad ones. This assumes (a) that
we can measure ?goodness,? and (b) that we can draw a line separating wheat from
chaff. Theoretically these are difficult tasks to achieve, because we are dealing with
dimensions of judgment that are continuous and partly subjective, but this should
not stop us from looking for practical evaluation criteria which can support rough
assessments and comparisons of different algorithms.
To evaluate a proposed linguistic solution, the two criteria in common use are the
judgments of native speakers, and frequency in a corpus. Using the former method, we
could ask people to judge whether the 13 plans proposed previously for describing 0.259
are all appropriate (to some context), and whether there are other acceptable solutions
that have been omitted. Using the latter method, we could collect from a corpus all
phrases describing a given proportion (say 0.259), identify the plans behind them, and
find out whether (i) the solutions actually found in the corpus are all generated by our
model, and (ii) solutions absent from the corpus are not generated.
We would argue, however, that the overall performance of the program is actually
not the most instructive aspect to evaluate. Any reasonably complex system is based
on a number of methods and assumptions, some of which might be correct and some
17 We have preferred to include some very inaccurate solutions such as ?about a half?, in order to cater
for all positions along the roundness/accuracy trade-off. For instance, ?half of the birds flew away?
seems acceptable in a context in which the exact proportion is unimportant, whereas the more accurate
?a quarter? or ?a third? might sound fussy.
125
Computational Linguistics Volume 38, Number 1
incorrect; separate evaluations of these components should provide more useful evi-
dence on how the model can be improved. We have therefore designed the empirical
study so that as well as assessing overall coverage and quality, it allows us to evaluate
the Minimal Distance and Extreme Point Constraints, the Roundness Preference, and
the suggested scale systems for fractions and percentages.
5.1 Method
The model was evaluated through two surveys in which participants were asked to
fill in gaps in sentences describing proportions, with reference to data from which the
actual value VA could be easily computed. The surveys were presented on-line using
SurveyMonkey18 through a link sent to two computational linguistics mailing lists
(SIGGEN and SIGDIAL). Survey 1, completed by 50 participants, tested the predictions
of the model concerning given (VG) values for percentages. Survey 2, completed by
62 participants,19 investigated given (VG) values for fractions, and their relationship to
the decision whether to use a fraction or a percentage; it also included four questions
testing the Extreme Point constraint. The content of all questions was adapted from
newspaper articles in the NUMGEN corpus. In detail, the composition of the surveys
was as follows:
A. Eight questions where subjects were asked to provide the given number
(VG) in a sentence that already contained a hedge, with reference to data
determining an actual value (VA). The context of the VG response was
varied systematically to cover the three approximation relations (?,<,>)
with actual values at different distances from a convenient round number.
[Survey 1]
B. Ten questions where subjects were asked to complete a sentence by
providing a fraction/percentage (possibly including a hedge). The data
were varied so that the actual value was sometimes close to a convenient
VG value from the fraction scale system [S2,S3,S4] (i.e., halves, thirds,
quarters), and sometimes close to VG values on other scales (e.g., fifths,
sixths, tenths). [Survey 2]
C. Four questions where subjects were asked to choose a hedge for a sentence
that already contained a given (VG) number, in each case either 0% or
100%. Their purpose was to test the Extreme Point constraint on the choice
of relation. [Survey 2]
Examples of each kind of question are shown in Figure 1. The instructions in both
surveys were as follows, with the italicized paragraph occurring only in Survey 2.
This survey will take about 5 minutes to complete. Its purpose is to investigate how
people choose numerical descriptions. It is not a test where answers are either right
or wrong.
18 http://www.surveymonkey.com/.
19 In fact, 65 people completed Survey 2, but three were eliminated, one for responding at random, and two
for giving responses that were not proportions. Our policy was to eliminate participants only when all
their responses were nonsensical, therefore as can be seen, a few obviously mistaken responses remain.
126
Power and Williams Generating Numerical Approximations
Figure 1
Snapshots of questions from the surveys, illustrating the three question types.
Imagine that you are the subeditor of a newspaper. You have been asked to
complete an article which has some gaps where data were not yet available to the
original author.
You are given the incomplete sentence, and the data which it should describe. Your
task is to choose a suitable expression to complete the sentence, leaving the rest of the
wording unchanged (even if you disagree with it).
Each expression should use either a fraction or a percentage, and may also include
modifying words like ?over?, ?about? (e.g., ?55 percent?, ?over a half?).
The data are fictional, but assume they are correct. We are interested in your choice
of numerical expression, not in the validity of the data.
Schematically, each question presented the raw data of a proportion in the form CS/CSS
(cardinality of set divided by cardinality of superset)?for instance, 712 out of 1,000 UK
teenagers?so that the actual value VA could be calculated. The values of CSS were chosen
so that this calculation would be relatively simple (1,000).20
The whole design is shown in Table 4, where the questions are numbered in order
of presentation, and the gaps to be filled by the subjects are shown by question marks.
In Survey 1, all participants viewed questions A1?A8 in the same order on separate
20 There is a possible bias here in that the denominator used in presenting the data (1,000) might lead
participants to favor scales that easily divide this number (e.g., 10 in preference to 3). Without a control
we cannot rule out this possibility, but the results for fractions, where 3 was actually the most common
denominator (46.8% of responses), show no evidence that non-decimal scales were handicapped.
127
Computational Linguistics Volume 38, Number 1
Table 4
Design of the surveys. Questions A1?A8 were presented in Survey 1, and questions B1?B10 and
C1?C4 in Survey 2. VA is the actual value, derived from data supplied in the question; VG is the
given value; the Relation holds between VA and VG. Responses required from subjects are
shown by ???.
Q VA Relation VG
A1 0.712 ? ?%
A2 0.437 > ?%
A3 0.625 ? ?%
A4 0.336 < ?%
A5 0.475 ? ?%
A6 0.561 < ?%
A7 0.286 ? ?%
A8 0.619 > ?%
B1 0.372 ? ?
B2 0.493 ? ?
B3 0.894 ? ?
B4 0.744 ? ?
B5 0.661 ? ?
B6 0.056 ? ?
B7 0.257 ? ?
B8 0.170 ? ?
B9 0.605 ? ?
B10 0.339 ? ?
C1 0.983 ? 100%
C2 0.028 ? 0%
C3 0.962 ? 100%
C4 0.021 ? 0%
pages.21 In Survey 2, similarly, questions B1?B10 were presented on separate pages,
followed by questions C1?C4 presented on a single page (see Figure 1).22
5.2 Results
Before presenting the results schematically, we will look in detail at the responses
actually typed for the question A1 (top of Figure 1). Subjects were asked to complete
the sentence About [. . . ] percent of UK teenagers under 16 have used sunbeds during the
last year given the data 712/1,000, equivalent to VA = 0.712. Reproduced as strings, the
following responses were received (some more than once):
70, 71, 71.2, 70%, seventy, 75, 20, 15, 2
As can be seen, the same answer was sometimes given in different forms (70, sev-
enty, 70%); in collating the results, these were all normalized to 70. Occasional bizarre
21 Questions A1?A8 were ordered so that Relation values varied from one question to the next and were
evenly distributed.
22 To check that there were no effects of question order, questions B1?B10 were presented to half the
subjects in one order, and to the other half in the reverse order. Because no differences were
apparent?the preferred response was the same for every question?the data were then amalgamated.
For questions C1?C4, the order was randomized.
128
Power and Williams Generating Numerical Approximations
Table 5
Results for questions A1?A8 (50 participants). VA is the actual value indicated by the question
data; R is the arithmetical relation implied by the hedge in the question text. Response
frequencies for VG (given value) are shown in parentheses, or unspecified if the response
occurred only once.
Q R VA Responses (frequencies)
A1 ? 0.712 70 (33), 71 (8), 71.2 (5), 75, 20, 15, 2
A2 > 0.437 40 (26), 43 (21), 30 (2), 45
A3 ? 0.625 60 (19), 62 (17), 63 (10), 62.5 (2), 30, 20
A4 < 0.336 35 (30), 34 (17), 50, 40, 1
A5 ? 0.475 50 (17), 48 (12), 47 (12), 45 (5), 47.5 (2), 46, 25
A6 < 0.561 60 (27), 57 (17), 56 (3), 55 (2), 30
A7 ? 0.286 30 (28), 29 (15), 28 (4), 25, 28.6, 1
A8 > 0.619 60 (38), 61 (9), 62 (2), 50
Table 6
Results for questions B1?B10 (62 participants). Questions marked with an asterisk were
predicted to favor fractions because their actual values are close to fractions from scales 2?4;
nearest fractions are shown in column F. Response frequencies are shown in parentheses, or
unspecified if the response occurred only once.
Q VA F Fraction responses Percentage responses
B1 0.372 3/8 1/3 (28) 37 (13), 40 (9), 37.2 (6), 33, 30, 38
B2* 0.493 1/2 1/2 (45) 50 (9), 49.3 (5), 49 (3)
B3 0.894 9/10 90 (46), 89.4 (5), 89 (4)
B4* 0.744 3/4 3/4 (28), 2/3 75 (17), 74.4 (5), 74 (4), 70 (2), 80
B5* 0.661 2/3 2/3 (34), 1/2 (4) 66 (13), 66.1 (5), 60 (2), 70
B6 0.056 1/20 1/2 5 (25), 5.6 (10), 6 (10), 56 (2), 10, 60, 1.2, 1
B7* 0.257 1/4 1/4 (34) 25 (15), 25.7 (6), 26 (5)
B8 0.170 1/6 1/6 (3), 1/5, 1/4 17 (48), 20 (6), 1.7 (2)
B9 0.605 3/5 1/2 (8), 2/3 (8) 60 (37), 60.5 (6), 61
B10* 0.339 1/3 1/3 (39) 34 (10), 33.9 (6), 30 (2), 35 (2), 40
responses (20, 15, 2) were not excluded. Collating in this way, and ordering by frequency,
the results for the first eight questions were as shown in Table 5.
For questions B1?B10, we were interested in whether subjects would choose a
fraction or a percentage, and whether fractions would conform to the proposed scale
system (favoring denominators in the range 2?4). Responses such as ?a quarter?, ?two
thirds?, ?1/4?, ?2/3?, were classified as fractions; responses like ?one out of four?, ?2
of every 3? were instead classified as ratios. For each actual value, a convenient fraction
was located within a distance of 0.01 on the proportion scale: for instance, 0.257 is just
0.007 above 1/4, and 0.372 just 0.003 below 3/8. Five of these fractions lay within the
proposed scale system (denominators 2?4) and five lay outside (denominators 5, 6, 8,
10, 20); questions in the former category are marked by an asterisk in Table 6.
For questions C1?C4, subjects had to choose from the four hedging options about,
less than, more than, and approximately.23 The purpose of these questions was to test the
23 The plausible option ?almost? was omitted because, as pointed out earlier, this denotes a subtler relation
of approaching the given value either from above or below. We hope in future work to extend the model
so that it includes this relation as well as the four treated here.
129
Computational Linguistics Volume 38, Number 1
Table 7
Results for questions C1?C4 (62 participants). Response frequencies are shown in parentheses.
For these questions, actual and given values (VA, VG) were specified in the question, and
participants were asked to choose the hedge?and thus, implicitly, the arithmetical relation.
Q VA VG Responses (frequencies)
C1 0.983 100% about (25), approximately (31), less than (6)
C2 0.028 0% about (30), approximately (19), more than (13)
C3 0.962 100% about (29) approximately (23), less than (10)
C4 0.021 0% about (28), approximately (27), more than (8)
Table 8
Predictions for questions A1?A8. Coverage reports the number of responses conforming to the
predictions. Quality reports the number of predicted solutions that were produced by at least
one subject.
Q R Actual Predictions Coverage Quality
A1 ? 0.712 70, 71 41 (82%) 2/2
A2 > 0.437 40, 43 47 (94%) 2/2
A3 ? 0.625 60, 62, 63 46 (92%) 3/3
A4 < 0.336 35, 34, 40 48 (96%) 3/3
A5 ? 0.475 50, 48, 47 41 (82%) 3/3
A6 < 0.561 60, 57 44 (88%) 2/2
A7 ? 0.286 30, 29 43 (86%) 2/2
A8 > 0.619 60, 61 47 (94%) 2/2
Extreme Point constraint?our hypothesis was that when constrained to use the extreme
points 0% or 100% as given values, people would avoid the relations< and>. Two other
hedges were employed so that on a random response the frequencies would be equally
divided, with half favoring either < or >. Results for these questions are presented in
Table 7, which shows that the hedges ?less than? and ?more than? (corresponding to <
and >) were strongly dispreferred for extreme given values.24
5.3 Analysis of Issues
5.3.1 Overall Performance. Comparing the solutions generated by the program with those
produced by human authors (including participants in our survey), we can ask (a) how
many solutions produced by humans were generated by the program, and (b) how
many solutions generated by the program were produced by humans?thus addressing
the competing criteria of coverage and quality. A model that generates many solutions
will increase coverage at the expense of quality, because it accepts some solutions that
competent authors would never produce.
Considering coverage first, the results predicted for questions A1?A8 are shown in
Table 8; comparing these with the actual results in Table 5, we observe that participants
chose one of the predicted given values in 357 out of 400 responses, giving an overall
24 Collating the results for VG = 100% we obtain the frequency distribution 54-54-16 for the three choices
?about,? ?approximately,? ?less than? (?2 = 23.3, df = 2, p < 0.00001). For VG = 0% the corresponding
distribution is 58-45-21 for the three choices ?about,? ?approximately,? ?more than? (?2 = 17.1, df = 2,
p < 0.0002).
130
Power and Williams Generating Numerical Approximations
coverage rate of about 90%. Turning to quality, the final column of Table 8 shows that
all of the predicted solutions occurred at least once in a sample of 50 responses, giving
a quality rate of 100%. This confirms that the fairly high coverage rate was not achieved
by the artifice of generating an overlarge set of predicted solutions.
For questions B1?B10 (Survey 2), considering only responses that were fractions or
percentages, we obtained 576/588 responses conforming to the predicted given values
(98% coverage), and 49 out of 76 predicted given values used at least once (64% quality).
Here the quality rate is lower because our model generates some very rough approxima-
tions using fractions (e.g., < 1/2 for actual values like 0.257 and 0.170)?responses that
would only occur in contexts where roundness overwhelmingly dominates precision.
5.3.2 Fraction and Percentage Scales. Responses to questions B1?B10 supported our as-
sumption that fractions are normally drawn from a scale system with denominators in
the range 2?4. This is shown (a) by the preponderance of fractions using these scales,
and (b) by the tendency of subjects to prefer percentages when the closest fraction used
another scale (e.g., fifths or tenths).
Out of 235 fraction responses overall, only 5 denominators were used, covering the
range 2?6, with frequencies as follows: halves 58 (24.7%), thirds 110 (46.8%), quarters
63 (26.8%), fifths 1 (0.4%), and sixths 3 (1.3%). Thus overall, 98.3% of fraction responses
used the proposed scales. Strikingly, none of the subjects chose three-fifths as a given
number for 0.605 (question B9), where the 16 fraction responses divided equally be-
tween half and two-thirds. Similarly, no subjects chose nine-tenths for VA = 0.894 (ques-
tion B3), for which the overwhelming preference was 90%, and there were no fraction
responses at all. The data thus supported a clear division into fraction and percentage
scale systems, with most subjects staying within a fraction system with scales limited to
the range 2?4.
Regarding the decision whether to use a fraction or a percentage, the actual values
were chosen so that five were close to convenient fractions in the range 2?4, and five
were not (see Table 6). For the former group, fractions outnumbered percentages by
185 to 114; for the latter group, percentages outnumbered fractions by 237 to 50?a
clear crossover (on a 2 ? 2 association test, ?2 = 120.5, df = 2, p < 0.00001). Another
way of showing this result is to correlate fraction frequencies with the distance between
the actual value and the nearest fraction with a denominator in the range 2?4: As this
difference increases, fraction frequencies decline, so that we obtain a strong negative
correlation (product-moment correlation r = ?0.9, df = 8, p < 0.01).
5.3.3 Minimal Distance. The Minimal Distance constraint relates the choice of the given
value VG to the choices made for the relation and the scale. It states that VG should
be chosen from the scale so as to minimize the distance from the actual value VA,
while obtaining a true description. Applied for example to question A1, for which the
relation is ? and VA = 0.712, the only point along the S10 scale satisfying the constraint
will be VG = 7/10, yielding a distance from VA of 0.012 (compared with a distance
of 0.088 when VG = 8/10, the nearest rival). For the other scales, the nearest points
are respectively, 14/20, 71/100, and 712/1,000, with the result that there are only two
predicted VG values, 7/10 and 71/100 (realized as 70% and 71%): 14/20 is a duplicate
of 7/10 removed by the Roundness Preference, and 712/1,000 is inconsistent with the
relation ? because it is exactly equal to VA.
Excluding non-serious responses such as ?about 15 percent? as an approximation
of 0.712, we can find in Table 5 (questions A1?A8) only seven violations of minimal
distance (2%), compared with 357 responses respecting the constraint (98%). The only
131
Computational Linguistics Volume 38, Number 1
violation that occurred more than once was ?about 28 percent? as an approximation
of 0.286. For questions B1?B10 we counted only five violations (1%) compared with
583 respecting the constraint (99%). Four of these violations were obvious arithmetical
mistakes (e.g., 56% as a realization of 0.056); the other was the response 33% as an
approximation for 0.372, suggesting an attempt to realize the underlying form 1/3 as
a percentage.25
5.3.4 Extreme Point. The Extreme Point constraint states that the relations < and > will
be avoided with given values at the extremes of the scale (VG = 0%, 100%). To test this
claim, the survey contained four questions (C1?C4) in which subjects had to choose a
hedge to accompany an extreme value of VG. For instance in question C1, with VA =
0.983, the sentence presented was A survey has found that [. . . ] 100 percent of people believe
they are smarter than average, and subjects had to choose from the hedges about, less than,
more than, approximately in order to fill the gap. The arithmetically correct answers to
this question are < 100 (represented by ?less than?) and ? 100 (represented by ?about?
and ?approximately?); most subjects, however, respected the Extreme Point constraint
by opting for the latter, with only 6/62 choosing ?less than.? Overall, 211/248 responses
to questions C1?C4 respected the constraint (85%), with 37 violations (15%).
5.3.5 Roundness Preference. Two questions in Survey 1 were included specifically to test
the Roundness Preference; both employed the relation ? in combination with an actual
value exactly midway between two round numbers, one on the scale S10 and the other
on the scale S20. The prediction was that subjects would favor the VG value taken from
the coarser-grained scale (S10). Results were as follows:
 For question A3 (?, VA = 0.625), 19 subjects chose ?about 60 percent? and
no subjects chose ?about 65 percent.?
 For question A5 (?, VA = 0.475), 17 subjects chose ?about 50 percent? and
5 chose ?about 45 percent.?
The overall count was therefore 36 to 5 in favor of the Roundness Preference (p <
0.00001, binomial test), but there was at least a hint of some other factor intruding, with
over 10% of responses going the other way.
6. Conclusion
We have proposed and tested a theoretical model for planning expressions that describe
proportions, with varying degrees of formality and precision. Our central idea is that
such expressions describe an arithmetical relationship between an actual value VA and
a given value VG, where the relation belongs to the set {=,?,>,<} and the given
value is a point from a scale belonging to a scale system. We use the concept of scale
system in order to distinguish the two commonest mathematical forms for representing
proportions?fractions and percentages. In everyday usage, fractions are conceptually
25 The use of 33% as an approximation suggests an alternative way of setting up the model using a single
scale system [S2,S3,S4,S10,S20,S100,S1000], and treating the choice between fraction and percentage
as a subsequent step influenced but not determined by the scale value. This approach receives some
support from the peaks in Table 2 for 25% and 75%, which would correspond to points along the S4 scale.
However, overall we obtained 67 responses of 1/3 as a fraction compared with only one as a percentage,
confirming a strong association of the scales [S2,S3,S4] with a particular mathematical form.
132
Power and Williams Generating Numerical Approximations
simpler because they have low-valued scales (usually in the region 2?4), whereas per-
centages use higher-valued scales based on powers of ten; both scales, however, could
be extended to finer granularities, for instance, to meet the requirements of specialized
domains. Scales for proportions are characterized by their SN numbers: lower SN values
represent coarser granularities and are associated intuitively with rounder given values.
The model provides a convenient formalization of the notions of mathematical form and
roundness, and a framework for investigating the detailed structure of scale systems
and the constraints and preferences that inform the planning process.
In evaluating the model, we found that most given values produced by partici-
pants in our survey were predicted by the model, with an overall coverage over 90%;
quality was also high (i.e., most generated solutions were employed at least once by
participants). These results support our assumptions about the composition of the scale
systems for fractions ([S2, S3, S4]) and percentages ([S10, S20, S100, S1000, . . . ]), which
determine the range of generated given values. Regarding the other assumptions of
the model, we found overwhelming evidence for a Minimal Distance constraint, which
requires speakers/writers to choose (for a specified scale and relation) the nearest point
to the actual value that yields a true description, and strong evidence for an Extreme
Point constraint, which disallows approximations in which the relations> or< are used
in combination with extreme points of a scale (e.g., with the percentages 0% or 100%).
We also found clear evidence for a Roundness Preference which, all other things being
equal, favors solutions using coarser-grained scales within the selected system.
We hope that with some calibration of the details, our model can provide a reliable
set of plans for describing any proportion, although when incorporated into an NLG
application it would obviously have to be complemented by a module for selecting
the best solution for a given pragmatic context. Despite not covering this problem
in the model, we have given examples of how pragmatic considerations might affect
each component of a solution (scale system, given value, arithmetical relation), thus
providing a framework for investigating such questions systematically.
Acknowledgments
NUMGEN was funded by the Economic
and Social Research Council under Grant
Ref. RES-000-22-2760. We are grateful to
our colleagues and reviewers for helpful
comments and suggestions.
References
Blutner, Reinhard and Henk Zeevat. 2004.
Optimality Theory and Pragmatics. Palgrave
MacMillan, Houndmills, Basingstoke,
Hampshire. Mouton de Gruyter, Berlin.
Crystal, David. 1988. On keeping one?s
hedges in order. English Today, 15:46?47.
Dekker, P. and R. van Rooy. 2000.
Bi-directional optimality theory: An
application of game theory. Journal of
Semantics, 17:217?242.
Dubois, B. L. 1987. Something of the order
of around forty to forty-four. Language
in Society, 16(4):527?541.
Grice, H. P. 1975. Logic and conversation.
In P. Cole and J. L. Morgan, editors, Syntax
and Semantics: Vol. 3: Speech Acts. Academic
Press, San Diego, CA, pages 41?58.
Hallett, Catalina, Donia Scott, and Richard
Power. 2007. Composing queries through
conceptual authoring. Computational
Linguistics, 33(1):105?133.
Hurford, J. R. 1975. The Linguistic Theory of
Numerals. Cambridge University Press,
Cambridge.
Jansen, C. J. M. and M. M. W. Pollmann.
2001. On round numbers: Pragmatic
aspects of numerical expressions. Journal
of Quantitative Linguistics, 8(3):187?201.
Koller, Alexander and Joachim Niehren.
2000. Constraint programming in
computational linguistics. In Proceedings
of 8th CSLI Workshop on Logic, Language
and Communication, pages 95?122, Stanford
University.
Krifka, Manfred. 2002. Be brief and vague!
and how bidirectional optimality theory
allows for verbosity and precision. In
133
Computational Linguistics Volume 38, Number 1
D. Restle and D. Zaefferer, editors,
Sounds and Systems: Studies in Structure
and Change: A Festschrift for Theo
Vennemann (Trends in Linguistics 141).
Mouton de Gruyter, Berlin, pages 439?458.
Krifka, Manfred. 2007. Approximate
interpretation of number words:
A case for strategic communication.
In G. Bouma, I. Kra?mer, and J. Zwarts,
editors, Cognitive Foundations of
Interpretation. Koninklijke Nederlandse
Akademie van Wetenschapen,
Amsterdam, pages 111?126.
Lakoff, George. 1973. Hedges: A study in
meaning criteria and the logic of fuzzy
concepts. Journal of Philosophical Logic,
2(4):458?508.
Pollmann, M. M. W. and C. J. M. Jansen.
1996. The language user as an
arithmetician. Cognition, 59:219?237.
Qualification and Curriculum Authority.
1999. Mathematics: the National
Curriculum for England. Department for
Education and Employment, London.
Reiter, Ehud. 1994. Has a consensus NL
architecture appeared, and is it
psychologically plausible? In Proceedings
of the 7th International Workshop on Natural
Language Generation, pages 163?170,
Kennebunkport, ME.
Reiter, Ehud, Somayajulu Sripada, Jim
Hunter, Jin Yu, and Ian Davy. 2005.
Choosing words in computer-generated
weather forecasts. Artificial Intelligence,
167(1-2):137?169.
van Deemter, Kees. 2009. What game
theory can do for NLG: the case of
vague language. In Proceedings of the
12th European Workshop on Natural
Language Generation, pages 154?161,
Athens.
van Hentenryck, P. 1989. Constraint
Satisfaction in Logic Programming.
MIT Press, Cambridge, MA.
Williams, Sandra and Richard Power.
2009. Precision and mathematical form
in first and subsequent mentions of
numerical facts and their relation to
document structure. In Proceedings of
the 12th European Workshop on Natural
Language Generation, pages 118?121,
Athens.
134
Grouping axioms for more coherent ontology descriptions
Sandra Williams
The Open University
Milton Keynes, United Kingdom
s.h.williams@open.ac.uk
Richard Power
The Open University
Milton Keynes, United Kingdom
r.power@open.ac.uk
Abstract
Ontologies and datasets for the Semantic
Web are encoded in OWL formalisms that
are not easily comprehended by people.
To make ontologies accessible to human
domain experts, several research groups
have developed ontology verbalisers using
Natural Language Generation. In practice
ontologies are usually composed of simple
axioms, so that realising them separately
is relatively easy; there remains however
the problem of producing texts that are co-
herent and efficient. We describe in this
paper some methods for producing sen-
tences that aggregate over sets of axioms
that share the same logical structure. Be-
cause these methods are based on logical
structure rather than domain-specific con-
cepts or language-specific syntax, they are
generic both as regards domain and lan-
guage.
1 Introduction
When the Semantic Web becomes established,
people will want to build their own knowledge
bases (i.e., ontologies, or TBox axioms, and data,
or ABox axioms1). Building these requires a high
level of expertise and is time-consuming, even
with the help of graphical interface tools such as
Prote?ge? (Knublauch et al, 2004). Fortunately, nat-
ural language engineers have provided a solution
to at least part of the problem: verbalisers, e.g.,
the OWL ACE verbaliser (Kaljurand and Fuchs,
2007).
Ontology verbalisers are NLG systems that gen-
erate controlled natural language from Semantic
1Description Logic (DL) underlies the Web Ontology
Language OWL. DL distinguishes statements about classes
(TBox) from those about individuals (ABox). OWL cov-
ers both kinds of statements, which in OWL terminology are
called ?axioms?.
Web languages, see Smart (2008). Typically they
generate one sentence per axiom: for example,
from the axiom2 Cat v Animal the OWL ACE
verbaliser (Kaljurand and Fuchs, 2007) generates
?Every cat is an animal?. The result is not a co-
herent text, however, but a disorganised list, often
including inefficient repetitions such as:
Every cat is an animal.
Every dog is an animal.
Every horse is an animal.
Every rabbit is an animal.
An obvious first step towards improved efficiency
and coherence would be to replace such lists with
a single aggregated sentence:
The following are kinds of animals: cats, dogs,
horses and rabbits.
In this paper, we show how all axiom patterns
in EL++, a DL commonly used in the Semantic
Web, can be aggregated without further domain
knowledge, and describe a prototype system that
performs such aggregations. Our method aggre-
gates axioms while they are still in logical form,
i.e., as part of sentence planning but before con-
verting to a linguistic representation and realising
as English sentences. This approach is somewhat
different from that proposed by other researchers
who convert ontology axioms to linguistic struc-
tures before aggregating (Hielkema, 2009; Galanis
et al, 2009; Dongilli, 2008). We present results
from testing our algorithm on over fifty ontologies
from the Tones repository3.
2 Analysis of axiom groupings
In this section we analyse which kinds of axioms
might be grouped together. Power (2010) anal-
2For brevity we use logic notation rather than e.g., OWL
Functional Syntax: subClassOf(class(ns:cat)
class(ns:animal)) where ns is any valid namespace.
The operatorv denotes the subclass relation, u denotes class
intersection, and ?P.C the class of individuals bearing the
relation P to one or more members of class C.
3http://owl.cs.manchester.ac.uk/
No. Logic OWL %
1 A v B subClassOf(A B) 51
2 A v ?P.B subClassOf(A
someValuesFrom(P B)) 33
3 [a, b] ? P propertyAssertion(P a b) 8
4 a ? A classAssertion(A a) 4
Table 1: The four most common axiom patterns.
ysed axiom patterns present in the same fifty on-
tologies. In spite of the richness of OWL, the sur-
prising result was that only four relatively simple
patterns dominated, accounting for 96% of all pat-
terns found in more than 35,000 axioms. Overall
there were few unique patterns, typically only 10
to 20, and up to 34 in an unusually complex ontol-
ogy. Table 1 lists the common patterns in logic no-
tation and OWL Functional Syntax, and also gives
the frequencies across the fifty knowledge bases.
Examples of English paraphrases for them are:
1. Every Siamese is a cat.
2. Every cat has as body part a tail.
3. Mary owns Kitty.
4. Kitty is a Siamese.
When two or more axioms conform to a pattern:
A v B
A v C
B v C
C v D
there are two techniques with which to aggregate
them: merging and chaining. If the right-hand
sides are identical we can merge the left-hand
sides, and vice versa:4
[A,B] v C
A v [B,C]
Alternatively, where the right-hand side of an ax-
iom is identical to the left-hand side of another ax-
iom, we can ?chain? them:
A v B v C v D
Merging compresses the information into a more
efficient text, as shown in the introduction, while
chaining orders the information to facilitate infer-
ence ? for example, ?Every A is a B and every
B is a C? makes it easier for readers to draw the
inference that every A is a C.
4We regard expressions like A v [B,C] and A v B v C
as shorthand forms allowing us to compress several axioms
into one formula. For merges one could also refactor the set
of axioms into a new axiom: thus for example A v [B,C]
could be expressed as A v (B u C), or [A,B] v C as
(A unionsq B) v C. This formulation would have the advantage
of staying within the normal notation and semantics of DL;
however, it is applicable only to merges, not to chains.
1. 2. 3. 4.
1. L,R,C ?,R?,? ?,?,? L?,?,C
2. L,R,? ?,?,? ?,?,C
3. L,R,? ?,R?,?
4. L,R,?
Table 2: Aggregating common axioms: 1. A v B,
2. A v ?P.B, 3. [a, b] ? P , 4. a ? A
Table 2 summarises our conclusions on whether
each pair of the four common patterns can be
merged or chained. Each cell contains three en-
tries, indicating the possibility of left-hand-side
merge (L), right-hand-side merge (R), and chain-
ing (C). As can be seen, some merges or chains
are possible across different patterns, but the safest
aggregations are those grouping axioms with the
same pattern (down the diagonal), and it is these
on which we focus here.
3 Merging similar patterns
Function Merge Patterns
f1(A) f1([A1, A2, A3, . . . ])
f2(A,B) f2([A1, A2, A3, . . . ], B)
f2(A, [B1, B2, B3, . . . ])
f3(A,B,C) f3([A1, A2, A3, . . . ], B,C)
f3(A, [B1, B2, B3, . . . ], C)
f3(A,B, [C1, C2, C3, . . . ])
Table 3: Generic merging rules.
If we represent ABox and TBox axioms as
Prolog terms (or equivalently in OWL Func-
tional Syntax), they take the form of functions
with a number of arguments ? for example
subClassOf(A,B), where subClassOf is the func-
tor, A is the first argument and B is the second argu-
ment. We can then formulate generic aggregation
rules for merging one-, two- and three-argument
axioms, as shown in table 3.
In general, we combine axioms for which the
functor is the same and only one argument differs.
We do not aggregate axiom functions with more
than three arguments. The merged constituents
must be different expressions with the same log-
ical form.
4 Implemention
This section describes a Prolog application which
performs a simple verbalisation including aggre-
gation. It combines a generic grammar for real-
ising logical forms with a domain-specific lexicon
derived from identifiers and labels within the input
ontology.
Input to the application is an OWL/XML file.5
Axioms that conform to EL++ DL are selected
and converted into Prolog format. A draft lex-
icon is then built automatically from the iden-
tifier names and labels, on the assumption that
classes are lexicalised by noun groups, properties
by verb groups with valency two, and individuals
by proper nouns.
Our aggregation rules are applied to axioms
with the same logical form. The first step picks
out all the logical patterns present in the input
ontology by abstracting from atomic terms. The
next step searches for all axioms matching each
of the patterns present. Then within each pattern-
set, the algorithm searches for axioms that differ
by only one argument, grouping axioms together
in the ways suggested in table 3. It exhaustively
lists every possible grouping and builds a new, ag-
gregated axiom placing the values for the merged
argument in a list, e.g., consider the axioms:
subClassOf(class(cat), class(feline)).
subClassOf(class(cat), class(mammal)).
subClassOf(class(dog), class(mammal)).
subClassOf(class(mouse), class(mammal)).
Identical first arguments =?
subClassOf(class(cat),
[class(feline),
class(mammal)]).
?Every cat is a feline and a mammal.?
Identical second arguments =?
subClassOf([class(cat), class(dog),
class(mouse)], class(mammal)).
?The following are kinds of mammal:
cats, dogs and mice.?
For all axioms with an identical first argu-
ment, class(cat), the algorithm places the
second arguments in a list, [class(feline),
class(mammal)], and builds a new axiom with the
first argument and the merged second argument.
From this, our realiser generates the sentence ?Ev-
ery cat is a feline and a mammal.? A similar pro-
cess is performed on first arguments when the sec-
ond arguments are identical.
To construct the grammar, we first formulated
rules for realising single axioms, and then added
rules for the aggregated patterns, incorporating
aggregation cues such as ?both? and ?the follow-
ing:? (Dalianis and Hovy, 1996). For the word-
ing of single axioms we relied mainly on proposals
5We convert OWL to OWL/XML with
the Manchester OWL Syntax Converter
http://owl.cs.manchester.ac.uk/converter/
from the OWL Controlled Natural Language task
force (Schwitter et al, 2008), so obtaining rea-
sonably natural sentences for common axiom pat-
terns, even though some less common axioms such
as those describing attributes of properties (e.g.,
domain, range, functionality, reflexivity, transitiv-
ity) are hard to express without falling back on
technical concepts from the logic of relations; for
these we have (for now) allowed short technical
formulations (e.g., ?The property ?has as part?
is transitive?). With these limitations, the gram-
mar currently realises any single axiom conform-
ing to EL++, or any aggregation of EL++ axioms
through the merge rules described above. Table 4
lists example aggregated axiom patterns and En-
glish realisations generated with our grammar.
5 Testing the ?merging? algorithm
Unit Original Aggregated Reduction
Sentences 35,542 11,948 66%
Words 320,603 264,461 18%
Table 5: Reduction achieved by aggregating
We have tested our generic merging rules on ax-
ioms conforming to EL++ in a sample of around
50 ontologies. Table 5 shows the reduction in the
number of generated sentence after aggregation.
Remember that previously, the system generated
one sentence for every axiom (35,542 sentences),
but with aggregation this is reduced to 11,948 sen-
tences, an overall reduction of 66%. However, ag-
gregation increases sentence length so the saving
in words is only 18%.
The effect of merging is to replace a large num-
ber of short sentences with a smaller number of
longer ones. Sometimes the aggregated sentences
were very long indeed, e.g., when a travel ontol-
ogy cited 800 instances of the class island ?
perhaps such cases would be expressed better by
a table than by prose6.
The algorithm computes all possible merges, so
we get, for instance, Fred described as a person
in both ?The following are people: Fred, . . . ? and
?Fred is all of the following: a person, . . . ?. This
means that the greater efficiency achieved through
aggregation may be counterbalanced by the extra
text required when the same axiom participates in
several merges ? for a few of our ontologies, in
6In a summary one might instead simply give a count and
an example: ?There are 800 islands, e.g., The Isle of Skye?.
Aggregated Axiom Pattern Example of Generated Text
subClassOf([C1,C2,. . . ], C3). The following are kinds of vehicles: a bicycle, a car, a truck and a van.
subClassOf(C1, [C2,C3,. . . ]). Every old lady is all of the following: a cat owner, an elderly and a woman.
subClassOf([C1,C2,. . . ], The following are kinds of something that has as topping a tomato: a fungi,
objectSomeValuesFrom(P1, C3)). a fiorella and a margherita.
subClassOf(C1, [ objectSomeValuesFrom(P1, C2) Every fiorella is something that has as topping a mozzarella and is
objectSomeValuesFrom(P2, C3)]). something that has as topping an olive.
classAssertion(C1, [I1, I2, . . . ]). The following are people: Fred, Joe, Kevin and Walt.
classAssertion([C1,C2,. . . ], I). Fred is all of the following: an animal, a cat owner and a person.
objectPropertyAssertion(P1, [I1, I2, I3], I4). The following are pet of Walt: Dewey, Huey and Louie.
objectPropertyAssertion(P1, I4, [I1, I2, I3]). Walt has as pet Dewey, Huey and Louie.
disjointClasses([C1,C2,. . . ], C3). None of the following are mad cows: an adult, . . . a lorry or a lorry driver.
disjointClasses(C1, [C2,C3,. . . ]). No grownup is any of the following: a kid, a mad cow, a plant, or a tree.
dataPropertyDomain([P1, P2, . . . ], C1). If any of the following relationships hold between X and Y then X
must be a contact: ?has as city?, ?has as street? and ?has as zip code?.
dataPropertyRange([P1, P2, . . . ], C1). If any of the following relationships hold between X and Y then Y
must be a string: ?has as city?, ?has as e mail? and ?has as street?.
differentIndividuals(I1, [I2, I3, . . . ]). The One Star Rating is a different individual from any of the following:
differentIndividuals([I1, I2, . . . ], I3). the Three Star Rating or the Two Star Rating.
equivalentDataProperties(P1, [P2,P3,. . . ]). The following properties are equivalent to the property ?has as zip code?:
equivalentDataProperties([P1,P2,. . . ], P3). ?has as post code?, ?has as zip? and ?has as postcode?.
equivalentObjectProperties([P1,P2,. . . ], P3). The following properties are equivalent to the property ?has as father?: . . . .
negativeobjectPropertyAssertion(P1, [I1, I2, . . . ], I3). None of the following are pet of Walt: Fluffy, Mog or Rex.
negativeobjectPropertyAssertion(P1, I1, [I2, I3, . . . ]). It is not true that Walt has as pet Fluffy or Rex.
Table 4: Example realisations of common aggregated EL++ axiom patterns.
fact, the word count for the aggregated version was
greater. This is an interesting problem that we
have not seen treated elsewhere. Merely pursu-
ing brevity, one might argue that an axiom already
included in a merge should be removed from any
other merges in which it participates; on the other
hand, the arbitrary exclusion of an axiom from a
list might be regarded as misleading. For now we
have allowed repetition, leaving the problem to fu-
ture work.
6 Related work
Reape and Mellish?s (1999) survey of aggrega-
tion in NLG proposed a continuum of definitions
ranging from narrow to wide. Our technique fits
into the narrow definition, i.e., it is language-
independent, operating on non-linguistic concep-
tual representations with the aim of minimising re-
dundancy and repetition. It implements the subject
and predicate grouping rules and aggregation cues
suggested by Dalianis and Hovy (1996).
Recent NLG systems that aggregate data from
ontologies (Hielkema, 2009; Galanis and An-
droutsopoulos, 2007; Dongilli, 2008) do not per-
form aggregation directly on axioms, but only af-
ter converting them to linguistic representations.
Moreover, their systems generate only from ABox
axioms in restricted domains while ours generates
English for both ABox and TBox in any domain.
The approach most similar to ours is that
of Bontcheva and Wilks (2004), who aggre-
gate a subset of RDF triples after domain-
dependent discourse structuring ? a task equiv-
alent to merging axioms that conform to the
objectPropertyAssertion pattern in table 4.
7 Conclusion
We have demonstrated that for the EL++ DL that
underlies many Semantic Web ontologies we can
define generic aggregation rules based on logical
structure, each linked to a syntactic rule for ex-
pressing the aggregated axioms in English. The
work described here is a first step in tackling a
potentially complex area, and relies at present on
several intuitive assumptions that need to be con-
firmed empirically. First, from an examination
of all combinations of the four commonest axiom
patterns, we concluded that axioms sharing the
same pattern could be combined more effectively
than axioms with different patterns, and there-
fore focussed first on same-pattern merges with
variations in only one constituent. Secondly, af-
ter systematically enumerating all such merges for
EL++, we have implemented a grammar that ex-
presses each aggregated pattern in English, relying
on an intuitive choice of the best form of words: at
a later stage we need to confirm that the resulting
sentences are clearly understood, and to consider
whether different formulations might be better.
Acknowledgments
This work is supported by the UK Engineering
and Physical Sciences Research Council (EPSRC)
grant EP/G033579/1 (SWAT: Semantic Web Au-
thoring Tool). We thank our colleagues and the
anonymous reviewers.
References
K. Bontcheva and Y. Wilks. 2004. Automatic re-
port generation from ontologies: the MIAKT ap-
proach. In Nineth International Conference on Ap-
plications of Natural Language to Information Sys-
tems (NLDB?2004), pages 214?225, Manchester,
UK.
Hercules Dalianis and Eduard H. Hovy. 1996. Aggre-
gation in natural language generation. In EWNLG
?93: Selected papers from the Fourth European
Workshop on Trends in Natural Language Gener-
ation, An Artificial Intelligence Perspective, pages
88?105, London, UK. Springer-Verlag.
Paolo Dongilli. 2008. Natural language rendering of
a conjunctive query. Technical Report Knowledge
Representation Meets Databases (KRDB) Research
Centre Technical Report: KRDB08-3, Free Univer-
sity of Bozen-Bolzano.
Dimitrios Galanis and Ion Androutsopoulos. 2007.
Generating multilingual descriptions from linguisti-
cally annotated OWL ontologies: the NaturalOWL
system. In Proceedings of the 11th European Work-
shop on Natural Language Generation, pages 143?
146, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Dimitrios Galanis, George Karakatsiotis, Gerasimos
Lampouras, and Ion Androutsopoulos. 2009. An
open-source natural language generator for OWL
ontologies and its use in prote?ge?, and second life.
In Proceedings of the 12th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics: Demonstrations Session, pages 17?20,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Feikje Hielkema. 2009. Using Natural Language Gen-
eration to Provide Access to Semantic Metadata.
Ph.D. thesis, University of Aberdeen.
Kaarel Kaljurand and Norbert Fuchs. 2007. Ver-
balizing OWL in Attempto Controlled English. In
Proceedings of the Third International Workshop on
OWL: Experiences and Directions OWLED 2007.
Holger Knublauch, Ray W. Fergerson, Natalya Frid-
man Noy, and Mark A. Musen. 2004. The Prote?ge?
OWL Plugin: An Open Development Environment
for Semantic Web Applications. In International Se-
mantic Web Conference, pages 229?243.
Richard Power. 2010. Complexity assumptions in on-
tology verbalisation. In 48th Annual Meeting of the
Association for Computational Linguistics.
Michael Reape and Chris Mellish. 1999. Just what is
aggregation anyway? In Proceedings of the 7th Eu-
ropean Workshop on Natural Language Generation,
pages 20?29, Toulouse, France.
Rolf Schwitter, Kaarel Kaljur, Anne Cregan, Cather-
ine Dolbear, and Glen Hart. 2008. A comparison
of three controlled natural languages for owl 1.1.
In 4th OWL Experiences and Directions Workshop
(OWLED 2008).
Paul Smart. 2008. Controlled Natural Languages
and the Semantic Web. Technical Report Technical
Report ITA/P12/SemWebCNL, School of Electron-
ics and Computer Science, University of Southamp-
ton),.
Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 128?136,
Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational Linguistics
Experimental Identification of the Use of Hedges in the Simplification of
Numerical Expressions
Susana Bautista and Raquel Herva?s and Pablo Gerva?s
Universidad Complutense de Madrid, Spain
{raquelhb,subautis}@fdi.ucm.es, pgervas@sip.ucm.es
Richard Power and Sandra Williams
Department of Computing, The Open University, Milton Keynes MK76AA, UK
{r.power,s.h.williams}@open.ac.uk
Abstract
Numerical information is very common in
all kinds of documents from newspapers and
magazines to household bills and wage slips.
However, many people find it difficult to un-
derstand, particularly people with poor educa-
tion and disabilities. Sometimes numerical in-
formation is presented with hedges that mod-
ify the meaning. A numerical hedge is a word
or phrase employed to indicate explicitly that
some loss of precision has taken place (e.g.,
?around?) and it may also indicate the di-
rection of approximation (e.g., ?more than?).
This paper presents a study of the use of nu-
merical hedges that is part of research inves-
tigating the process of rewriting difficult nu-
merical expressions in simpler ways. We car-
ried out a survey in which experts in numer-
acy were asked to simplify a range of pro-
portion expressions and analysed the results to
obtain guidelines for automating the simplifi-
cation task.
1 Introduction
All public information services and documents
should be accessible in such a way that makes them
easily understood by everybody, according to the
United Nations (1994). Nowadays, a large percent-
age of information expressed in daily news comes
in the form of numerical expressions (statistics of
economy, demography data, etc). But many people
have problems with understanding such expressions
-e.g., people with limited education or some kind of
mental disability.
Lack of ability to understand numerical informa-
tion is an even greater problem than poor literacy.
A U.K. Government Survey in 2003 estimated that
6.8 million adults had insufficient numeracy skills
to perform simple everyday tasks such as paying
house-hold bills and understanding wage slips, and
23.8 million adults would be unable to achieve grade
C in the GCSE maths examination for 16 year-old
school children (Williams et al, 2003).
A first possible approach to solve this impor-
tant social problem is making numerical informa-
tion accessible by rewriting difficult numerical ex-
pressions using alternative wordings that are easier
to understand. Some loss of precision could have
positive advantages for numerate people as well as
less numerate. Such an approach would require a
set of rewriting strategies yielding expressions that
are linguistically correct, easier to understand than
the original, and as close as possible to the original
meaning.
In rewriting, hedges play an important role. For
example,?50.9%? could be rewritten as ?just over
half? using the hedge ?just over?. In this kind of
simplification, hedges indicate that the original num-
ber has been approximated and, in some cases, also
the direction of approximation.
This paper presents a preliminary study of the use
of hedges when numerical expressions are simplified
to make them more accessible. We have carried out
a survey in which experts in numeracy were asked to
simplify a range of proportion expressions to obtain
guidelines for developing the numerical expressions
simplification task automatically. As a first step to-
wards more complex simplification strategies, we
128
are trying to simplify numerical expressions without
losing substantial information. Our study does not
have a particular kind of disability in mind. Rather,
we aim to simplify according to levels of difficulty
defined in the Mathematics Curriculum of the Quali-
fications and Curriculum Authority (1999). Adapta-
tion to particular types of users is beyond the scope
of this paper.
2 Background
Text simplification, a relative new task in Natu-
ral Language Processing, has been directed mainly
at syntactic constructions and lexical choices that
some readers find difficult, such as long sentences,
passives, coordinate and subordinate clauses, ab-
stract words, low frequency words, and abbrevia-
tions. Chandrasekar et al (1996) introduced a two-
stage process, first transforming from sentence to
syntactic tree, then from syntactic tree to new sen-
tence; Siddharthan (2002) instead proposed a three-
stage process comprising analysis, transformation
and generation. In 1998, the project PSET (Car-
roll et al, 1998) employed lexical as well as syn-
tactic simplifications. Other researchers have fo-
cused on the generation of readable texts for readers
with low basic skills (Williams and Reiter, 2005),
and for teaching foreign languages (Petersen and
Ostendorf, 2007). There has been some previous
work on numerical expressions but more for experts
than for people who have difficulties with numer-
acy (Ellen Peters and Dieckmann, 2007), (Nathan
F. Dieckmann and Peters, 2009), (Ann M. Bisantz
and Munch, 2005), (Mishra H, 2011). However,
to our knowledge, there have been no previous at-
tempts to automatically simplify numerical informa-
tion in texts.
A corpus of numerical expressions was collected
for the NUMGEN project (Williams and Power,
2009). The corpus contains 10 sets of newspaper ar-
ticles and scientific papers (110 texts in total). Each
set is a collection of articles on the same topic ?
e.g., the increased risk of breast cancer in red meat
eaters, and the decline in the puffin population on
the Isle of May. Within each set, identical numeri-
cal facts are presented in a variety of linguistic and
mathematical forms.
3 Experiment
Our survey took the form of a questionnaire in
which participants were shown a sentence contain-
ing one or more numerical expressions which they
were asked to simplify using hedges if necessary.
3.1 Materials
Our simplification strategies are focused at two lev-
els: decimal percentages and whole-number per-
centages. For the survey we chose three sets of can-
didate sentences from the NUMGEN corpus: eight
sentences containing only decimal percentages and
two sets of eight sentences containing mixed whole-
number and decimal percentages. The number of
numerical expressions are more than eight because
some sentences contained more than one proportion
expression.
A wide spread of proportion values was present in
each set, including the two end points at nearly 0.0
and almost 1.0. We also included some numerical
expressions with hedges and sentences from differ-
ent topics in the corpus. In short, we included as
many variations in context, precision and different
wordings as possible.
3.2 Participants
We carried out the survey with primary or secondary
school mathematics teachers or adult basic numer-
acy tutors, all native English speakers. We found
them through personal contacts and posts to Inter-
net forums. The task of simplifying numerical ex-
pressions is difficult, but it is a task that this group
seemed well qualified to tackle since they are highly
numerate and accustomed to talking to people who
do not understand mathematical concepts very well.
Our experimental evaluation involved 34 partici-
pants who answered at least one question in our sur-
vey (some participants did not complete it).
3.3 Survey Design and Implementation
The survey was divided into three parts as follows:
1. Simplification of numerical expressions for a
person who can not understand percentages
2. Simplification of numerical expressions for a
person who can not understand decimals
129
3. Free simplification of numerical expressions
for a person with poor numeracy
Each part of the survey is considered as a differ-
ent kind of simplification: (1) simplification with no
percentages, (2) simplification with no decimals and
(3) free simplification.
For part (2), the set of sentences containing only
decimal percentages was used. One of the two
mixed sets of sentences with whole-number and
decimal percentages was used for part (1) and the
other for part (3). The experiment was presented on
SurveyMonkey1, a commonly-used provider of web
surveys. The survey was configured so that partic-
ipants could leave the questionnaire and later con-
tinue with it.
We asked participants to provide simplifications
for numerical expressions that were marked by
square brackets in each sentence. Below the sen-
tence, each bracketed number was shown beside a
text box in which the participant was asked to type
the simplified version. Our instructions said that nu-
merical expressions could be simplified using any
format: number words, digits, fractions, ratios, etc.
and that hedges such as ?more than?, ?almost? and
so on could be introduced if necessary. Participants
were also told that the meaning of the simplified ex-
pression should be as close to the original expres-
sion as possible and that, if necessary, they could
rewrite part of the original sentence. Figure 1 shows
a screenshot of part of the questionnaire.
3.4 Underlying assumptions
A numerical expression (NE) is considered to be a
phrase that represents a quantity, sometimes modi-
fied by a numerical hedge as in ?less than a quarter?
or ?about 20%?. We have restricted coverage to pro-
portions -i.e., fractions, ratios and percentages. We
had five hypotheses:
? H1: The use of hedges to accompany the sim-
plified numerical expression is influenced by
the simplification strategy selected. We con-
sider the use of fractions, ratios and percent-
ages like simplification strategies.
? H2: The use of hedges to simplify the numeri-
cal expression is influenced by the value of the
1www.surveymonkey.com
proportion, with values in the central range (say
0.2 to 0.8) and values at the extreme ranges (say
0.0-0.2 and 0.8-1.0) having a different use of
hedges.
? H3: The loss of precision allowed for the sim-
plified numerical expression is influenced by
the simplification strategy selected.
? H4: There is some kind of correlation between
the loss of precision and the use of hedges, in
such a way that the increase or decrease in the
former influences changes in the latter.
? H5: As an specific case of H4, when writers
choose numerical expressions for readers with
low numeracy, they do not tend to use hedges if
they are not losing precision.
4 Results
The results of the survey were carefully analyzed as
follows. First, within each block of questions, a set
of simplification strategies was identified for each
specific numerical expression. These strategies were
then grouped together according to the mathematical
forms and/or linguistic expressions employed (frac-
tions, ratios, percentages).
With a view to using these data to design an au-
tomated simplification system, these data have to be
analyzed in terms of pairs of a given input numeri-
cal expression and the simplified expression result-
ing from applying a specific simplification strategy.
For such pairings, three important features must be
considered as relevant to choosing a realization:
? Whether any numbers in the expression are re-
alized as one of the different types of available
expressions (fractions, ratios, percentages).
? The loss of precision involved in the simplifi-
cation.
? The possible use of a hedge to cover this loss
of precision explicitly in the simplified expres-
sion.
To calculate the loss of precision, we defined
Equation 1.
error =
(simplifiedNE ? originalNE)
originalNE
(1)
130
Figure 1: Screenshot of part of the questionnaire.
The set of pairings of input expression and ob-
served simplification strategies, loss of precision and
use of hedges as found in the results of the survey is
given in Tables 1, 2 and 3. For each input numer-
ical expression, the set of available simplification
strategies is represented as three lines in the table.
For each pairing, three columns are shown in the
table. Empty cells represent that the strategy was
not used. The first column presents the relative fre-
quency of usage with respect to the total set of possi-
ble simplification strategies used for that expression.
The second column captures the loss of precision in-
volved, represented in terms of the ratio between the
value of the difference between the original numer-
ical value in the input expression and the numerical
value that is conveyed by the corresponding simpli-
fied expression (using Equation 1). This ratio is also
expressed as a percentage. The third column indi-
cates the percentage of simplified numerical expres-
sions that contained a hedge. All of them are mean
values.
Each line represents one kind of simplification
strategy used to simplify the original numerical ex-
pression. Another point to explain is that frequen-
cies that belong to the same expression do not al-
ways add up to 100%. This is because a small num-
ber of others kinds of simplification strategies, like
deletions or rewriting of the whole sentence, are not
shown in the table. Moreover, we must keep in mind
that not all participants answered each question of
the survey.
Table 1 presents the relationships identified be-
tween the original numerical expressions and the
simplification strategies (presented as lines) for the
results of the first part of the survey (simplification
of numerical expressions for a person who can not
understand percentages). All the values are repre-
sented in percentages. Table 2 represents the same
data for the second part of the survey (simplification
of numerical expressions for a person who can not
understand decimals) and Table 3 for the third part
(free simplification of numerical expressions for a
person with poor numeracy).
In the three parts of the survey, the percentage of
simplifications that use hedges is slightly higher than
that of those not using hedges especially in the sec-
ond and third part of the survey. Adapting original
numerical expressions by inserting hedges accounts
for more than the 50% of cases. This reinforces
our assumption that simplifications involving loss of
precision may be better understood if an appropriate
hedge is used.
4.1 Analysis of the Use of Hedges in the
Simplified Numerical Expressions
In order to test hypothesis H1 (the use of hedges
in the simplified numerical expression is influenced
by the simplification strategy selected), we carried
out a series of two sample t-tests where statistical
significance was adjusted for multiple comparisons
by using the Bonferroni correction. Results are pre-
sented in Table 4. When considering the entire sur-
vey (Whole column), there is no significant differ-
ence in the use of hedges in fractions and percent-
ages. When analyzing the survey by parts we find
similar results. There is no significant difference in
the use of hedges in any strategy in the second (no
decimals) and the third (free simplification) parts of
131
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions 18 0 67
more than 1% Ratios 6 0 100
Percentages 18 17 50
Fractions 6 0 50
2% Ratios 18 -1 17
Percentages 12 0 0
Fractions 26 1 67
16.8% Ratios 65 5 45
Percentages 9 -3 0
Fractions 82 -4 86
27% Ratios 12 8 75
Percentages 6 6 50
Fractions 41 0 93
at least 30% Ratios 35 13 67
Percentages 3 0 100
Fractions 53 12 50
40% Ratios 29 0 10
Percentages 6 0 0
Fractions 82 -13 82
56% Ratios
Percentages 6 -5 50
Fractions 74 -3 84
63% Ratios 24 0 75
Percentages 3 0 0
Fractions 32 0 0
75% Ratios 29 0 0
Percentages
Fractions 3 0 0
97.2% Ratios 38 -8 23
Percentages 18 1 50
Fractions 6 0 0
98% Ratios 12 0 0
Percentages 3 0 0
Fractions 39 -1 53
Average Ratios 24 2 41
Percentages 7 1 30
Table 1: Analysis of the data for 34 participants from the
first part of the survey (simplifications intended for peo-
ple who do not understand percentages). All values are
percentages. The first column represents the frequencies
of use for each simplification strategy. The second col-
umn shows the error as the loss of precision involved in
the simplification. And the last column displays the use
of hedges in the simplifications.
the survey, but in the first part (no percentages) we
find significant difference between fractions and ra-
tios (p<0.0006). These results do not support the
hypothesis, as there is not a direct relation between
the use of hedges and the selected strategy.
We performed another t-test adjusted by using the
Bonferroni correction on the simplification strate-
gies and central and peripheral values to test hypoth-
esis H2 (the use of hedges to simplify the numerical
expression is influenced by the value of the propor-
tion, with values in the central range (say 0.2 to 0.8)
and values at the extreme ranges (say 0.0-0.2 and
0.8-1.0) having a different use of hedges). In this
case there is also no significant difference. The re-
sults show that the use of hedges is not influenced by
central and peripheral values, rejecting our hypoth-
esis H2 with a p-value p=0.77 in the worst case for
the percentages strategy.
A new t-test adjusted by using the Bonferroni cor-
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions 6 25 50
0.6% Ratios 9 22 33
Percentages 47 21 100
Fractions 3 -29 0
2.8% Ratios 24 6 63
Percentages 47 7 63
Fractions
6.1% Ratios 18 -4 50
Percentages 50 -3 82
Fractions 12 9 75
7.5% Ratios 12 -10 0
Percentages 50 7 41
Fractions 15 -1 80
15.5% Ratios 12 6 50
Percentages 44 2 33
Fractions 15 -3 100
25.9% Ratios 12 -3 75
Percentages 38 5 62
Fractions 3 0 0
29.1% Ratios 15 3 60
Percentages 50 2 71
Fractions 12 -5 100
35.4% Ratios 15 -4 60
Percentages 41 -1 71
Fractions 44 -2 93
50.8% Ratios 3 0 0
Percentages 21 0 43
Fractions 44 1 93
73.9% Ratios 6 1 50
Percentages 18 0 50
Fractions 3 0 0
87.8% Ratios 15 -1 60
Percentages 47 1 88
Fractions 3 0 0
96.9% Ratios 12 -2 75
Percentages 29 0 80
Fractions 6 0 50
96.9% Ratios 18 -1 67
Percentages 21 0 86
Fractions 3 0 0
97.2% Ratios 18 -1 67
Percentages 41 0 93
Fractions 3 0 0
97.2% Ratios 18 -1 83
Percentages 32 0 91
Fractions 3 0 0
98.2% Ratios 15 -2 40
Percentages 44 0 67
Fractions 11 0 43
Average Ratios 14 1 52
Percentages 39 2 70
Table 2: Analysis of the data for 34 participants from
the second part of the survey (simplifications intended for
people who do not understand decimals). All values are
percentages. The first column represents the frequencies
of use for each simplification strategy. The second col-
umn shows the error as the loss of precision involved in
the simplification. And the last column displays the use
of hedges in the simplifications.
rection was done to test hypothesis H3 (the loss of
precision allowed for the simplified numerical ex-
pression is influenced by the simplification strategy
selected). Table 5 shows significant differences be-
tween each simplification strategy and each kind of
simplification. In the Whole column we can observe
that the loss of precision in fractions is significantly
different to the one in ratios and percentages. In the
first part (no percentages) there is a significant dif-
ference between ratios and the rest of simplification
strategies. In the second part (no decimals) there is
132
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions
0.7% Ratios 6 43 100
Percentages 9 43 100
Fractions 6 -17 100
12% Ratios 21 -8 71
Percentages 21 -17 100
Fractions 41 -4 57
26% Ratios 12 -4 50
Percentages
Fractions 41 -8 86
36% Ratios 9 -2 67
Percentages
Fractions 41 -6 50
53% Ratios
Percentages 6 -6 50
Fractions 21 -5 100
65% Ratios 18 -1 33
Percentages 3 0 0
Fractions 15 0 20
75% Ratios 9 0 33
Percentages 3 0 0
Fractions
91% Ratios 29 -1 50
Percentages 6 -1 50
Fractions
above 97% Ratios 32 0 64
Percentages 6 2 100
Fractions 18 -7 69
Average Ratios 15 3 59
Percentages 6 3 57
Table 3: Analysis of the data for 34 participants from the
third part of the survey (free simplification intended for
people with poor literacy). All values are percentages.
The first column represents the frequencies of use for
each simplification strategy. The second column shows
the error as the loss of precision involved in the simplifi-
cation. And the last column displays the use of hedges in
the simplifications.
no significant difference between any strategy. And
in the last part (free simplification) there is only a
significant difference between fractions and ratios.
These results seem not to support the hypothesis,
as there is not a direct relation between the use of
hedges and the loss of precision in the simplified nu-
merical expression.
For hypothesis H4 (there is some kind of corre-
lation between the loss of precision and the use of
hedges), we looked for correlations between each
part of the survey and each kind of simplification
strategy. We carried out a non-parametric measure
of statistical dependence between the two variables
(loss of precision and use of hedges) calculated by
the Spearman?s rank correlation coefficient.
In general, the results show no correlation, so
there is no linear dependence between the loss of
precision in the strategy and use of hedges, rejecting
our hypothesis. For example, there are cases with
a weak correlation (e.g. in the second part of the
survey for fractions with r=0.49, N=17 and p=0.03),
and cases where there is a strong correlation (e.g.
in the third part of the survey, with r=1, N=18 and
p<.0001).
Finally, when we analyzed hypothesis H5 (when
writers choose numerical expressions for readers
with low numeracy, they do not tend to use hedges if
they are not losing precision), we worked with each
part of the survey to study the cases where the loss
of precision is zero and what is the tendency of use
of hedges.
? In the first part of the survey (simplification
of numerical expressions for a person who can
not understand percentages), considering our
34 participants, in a 46% of responses the loss
of precision is zero, and for these cases only
11% used hedges.
? For the second part (simplification of numeri-
cal expressions for a person who can not un-
derstand decimals), considering our 34 partici-
pants, in a 16% of responses the loss of preci-
sion is zero and for these cases only 7% used
hedges.
? And finally, in the last part (simplification of
numerical expressions for a person with poor
numeracy), considering the same participants,
in a 23% of cases the loss of precision is zero
in the simplification and for these cases only
6% used hedges.
With this data, it seems that we can accept hypoth-
esis H5, that is, we found evidence for our assump-
tion that when writers choose numerical expressions
for readers with poor numeracy, they tend to use
hedges when they round the original numerical ex-
pression, i.e when the loss of precision is not zero.
4.2 Original Numerical Expressions with
Hedges
In our survey there were a few cases where the orig-
inal numerical expression had a hedge. We have
observed that if the original numerical expression
has hedge almost always the simplified numerical
expression contained a hedge. There is a special
case, ?above 97%? where we do not count the use
of hedges because in this case the participants chose
non-numeric options mostly and they rewrote the
numerical expression with phrases like ?around all?.
133
Strategy No Pct. No Dec. Free Simp. Whole
Fractions A A A A
Percentages A B A A A
Ratios B A A B
Table 4: Results of t-test adjusted by Bonferroni correction for H1 (the use of hedges in simplified numerical ex-
pressions is influenced by the simplification strategy selected). Strategies which do not share a letter are significantly
different.
Strategy No Pct. No Dec. Free Simp. Whole
Fractions A A A A
Percentages A A A B B
Ratios B A B B
Table 5: Results of t-test adjusted by Bonferroni correction for H3 (the loss of precision allowed for the simplified
numerical expression is influenced by the simplification strategy selected). Strategies which do not share a letter are
significantly different.
In the remaining cases, the same hedge is nearly al-
way chosen to simplify the numerical expression.
4.3 Kinds of Hedges
With respect to the actual hedges used, we have
identified two different possible roles of hedge in-
gredients in a numerical expression. In some cases,
hedges are used to indicate that the actual numeri-
cal value given is an approximation to the intended
value. Uses of about or around are instances of this.
This kind of hedge is employed to indicate explic-
itly that some loss of precision has taken place dur-
ing simplification. In other cases, hedges are used to
indicate the direction in which the simplified value
diverges from the original value. Uses of under or
over are instances of this. In some cases more than
one hedge may be added to an expression to indi-
cate both approximation and direction, or to some-
how specify the precision involved in the simplifica-
tion, as in just under or a little less than.
In our analysis we studied which hedges were
the most frequent in each part of the survey. Only
hedges with more than ten appearances in total (in-
cluding simplification strategies not present in the
table) have been considered in Table 6. We observed
that the three parts of the survey have three hedges
in common: about, just over and over. They are
used in different strategies for each kind of simpli-
fication. In the second part of the survey, where
simplifications of numerical expressions for a per-
son who can not understand decimals are done, is
where more hedges are used, in special for percent-
ages strategy. In the last part of the survey, where
there is more freedom to decide how simplify the
original numerical expression, participants used less
hedges compare to the others parts.
No Percentages
Hedge Fractions Ratios Percent.
about 15 9 0
at least 8 5 1
just over 21 1 0
more than 9 3 0
over 6 3 2
Total 59 21 3
No Decimals
Hedges Fractions Ratios Percent.
about 8 12 6
almost 4 1 8
just over 13 3 39
just under 3 2 27
nearly 7 5 24
over 7 5 9
Total 42 28 113
Free Simplification
Hedges Fractions Ratios Percent.
about 6 5 1
just over 6 0 5
more than 4 5 0
nearly 4 0 2
over 11 2 3
Total 31 12 11
Table 6: Use of the most frequent hedges in each part of
the survey
134
5 Discussion
As can be seen in the results, the use of hedges to
simplify numerical expressions can be influenced by
three parameters. The first is the kind of simplifica-
tion. Our survey was divided in three parts depend-
ing on the mathematical knowledge of the final user.
The second is the simplification strategy for choos-
ing mathematical form (fractions, ratios, or percent-
ages). In our data we observed some differences in
the usage of hedges with ratios and their usage with
fractions and percentages (see Table 4). The last pa-
rameter is the loss of precision that occurs when the
numerical expression is rounded. We investigated
the use of hedges vs. loss of precision with different
tests hoping to define some dependencies, but there
was no clear correlation between them, and it was
only when we tried a deeper analysis of strategies
and kind of simplifications that we found some cor-
relations such as those we presented in Section 4.1.
When asked to simplify for people who do not
understand percentages, or for people with poor nu-
meracy, the participants use different simplification
strategies and sometimes they use hedges to simplify
the original numerical expression. As some partic-
ipants commented, not only are percentages mathe-
matically sophisticated forms, but they may be used
in sophisticated ways in the text, often for example
describing rising and falling values, for which in-
creases or decreases can themselves be described in
percentages terms. Such complex relationships are
likely to pose problems for people with poor numer-
acy even if a suitable strategy can be found for sim-
plifying the individual percentages. In some of the
examples with more than one numerical expression
being compared, some of the evaluators reported a
tendency to phrase them both according to a com-
parable base. Thus we should consider the role of
context (the set of numerical expressions in a given
sentence as a whole, and the meaning of the text) in
establishing what simplifications must be used.
6 Conclusions and Future Work
Through a survey administered to experts on nu-
meracy, we have collected a wide range of exam-
ples of appropriate simplifications of percentage ex-
pressions. These examples of simplified expressions
give us information about the use of hedges that our
participants carry out to adapt the original numer-
ical expression to be understood by the final user.
We investigated the loss of precision that occurs with
each hedge and the relation between the simplifica-
tion strategy and the use of hedges.
Our aim is to use this data to guide the develop-
ment of a system for automatically simplifying per-
centages in texts. With the knowledge acquired from
our study we will improve our algorithm to simplify
numerical expressions. We could determinate from
the simplification strategy, kind of simplification and
the loss of precision allowed, which will be the best
option to adapt the original numerical expression to
the final user and if that option uses hedges to under-
stand better the original numerical expression. As a
part of our algorithm, we will have to look at inter-
rater agreements for identifying appropriate hedges.
As future work, we plan to carry out another study
to determine a ranking of simplification strategies
from collecting a repertoire of rewriting strategies
used to simplify. This data should allow us to deter-
mine whether common values are considered sim-
pler and whether the value of the original expression
influences the chosen simplification strategy. So,
given a numerical expression, we could choose what
simplification strategy to apply and whether to insert
a hedge. We could investigate whether the value of
the original proportion also influences choices, de-
pending on its correspondence with central or pe-
ripheral values.
We have also collected a parallel corpus of numer-
ical expressions (original vs. simplified version).
This corpus will be shared with other researches so
it can be used in different applications to improve
the readability of text. This could be a very use-
ful resource because simplification of percentages
remains an interesting and non-trivial problem.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2009-14659-C03-01
Project), Universidad Complutense de Madrid and
Banco Santander Central Hispano (GR58/08 Re-
search Group Grant), and the FPI grant program.
135
References
Stephanie Schinzing Marsiglio Ann M. Bisantz and Jes-
sica Munch. 2005. Displaying uncertainty: Inves-
tigating the effects of display format and specificity.
Human Factors: The Journal of the Human Factors
and Ergonomics Society, 47(4):777.
J. Carroll, G. Minnen, Y. Canning, S. Devlin, and J. Tait.
1998. Practical simplification of English newspaper
text to assist aphasic readers. In AAAI-98 Workshop on
Integrating Artificial Intelligence and Assistive Tech-
nology, Madison, Wisconsin.
Raman Chandrasekar, Christine Doran, and Bangalore
Srinivas. 1996. Motivations and Methods for Text
Simplification. In COLING, pages 1041?1044.
Paul Slovic Ellen Peters, Judith Hibbard and Nathan
Dieckmann. 2007. Numeracy skill and the commu-
nication, comprehension, and use of risk-benefit infor-
mation. Health Affairs, 26(3):741?748.
Shiv B. Mishra H, Mishra A. 2011. In praise of vague-
ness: malleability of vague information as a perfor-
mance booster. Psychological Science, 22(6):733?8,
April.
Paul Slovic Nathan F. Dieckmann and Ellen M. Peters.
2009. The use of narrative evidence and explicit like-
lihood by decisionmakers varying in numeracy. Risk
Analysis, 29(10).
The United Nations. 1994. Normas uniformes sobre la
igualdad de oportunidades para las personas con dis-
capacidad. Technical report.
Sarah E. Petersen and Mari Ostendorf. 2007. Text Sim-
plification for Language Learners: A Corpus Analy-
sis. Speech and Language Technology for Education
(SLaTE).
Qualification and Curriculum Authority. 1999. Mathe-
matics: the national curriculum for england. Depart-
ment for Education and Employment, London.
Advaith Siddharthan. 2002. Resolving Attachment and
Clause Boundary Amgiguities for Simplifying Rela-
tive Clause Constructs. In Proceedings of the Student
Research Workshop, 40th Meeting of the Association
for Computacional Linguistics.
Sandra Williams and Richard Power. 2009. Precision
and mathematical form in first and subsequent men-
tions of numerical facts and their relation to document
structure. In Proceedings of the 12th European Work-
shop on Natural Language Generation, Athens.
Sandra Williams and Ehud Reiter. 2005. Generating
readable texts for readers with low basic skills. In
Proceeding of the 10th European Workshop on Natu-
ral Language Generation, pages 140?147, Aberdeen,
Scotland.
Joel Williams, Sam Clemens, Karin Oleinikova, and
Karen Tarvin. 2003. The Skills for Life survey: A
national needs and impact survey of literacy, numer-
acy and ICT skills. Technical Report Research Report
490, Department for Education and Skills.
136
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 110?114,
Utica, May 2012. c?2012 Association for Computational Linguistics
Planning Accessible Explanations for Entailments in OWL Ontologies
Tu Anh T. Nguyen, Richard Power, Paul Piwek, Sandra Williams
The Open University
Milton Keynes, United Kingdom
{t.nguyen,r.power,p.piwek,s.h.williams}@open.ac.uk
Abstract
A useful enhancement of an NLG system for
verbalising ontologies would be a module ca-
pable of explaining undesired entailments of
the axioms encoded by the developer. This
task raises interesting issues of content plan-
ning. One approach, useful as a baseline, is
simply to list the subset of axioms relevant
to inferring the entailment; however, in many
cases it will still not be obvious, even to OWL
experts, why the entailment follows. We sug-
gest an approach in which further statements
are added in order to construct a proof tree,
with every step based on a relatively simple
deduction rule of known difficulty; we also de-
scribe an empirical study through which the
difficulty of these simple deduction patterns
has been measured.
1 Introduction
A practical problem in developing ontologies for
the semantic web is that mistakes are hard to spot.
One reason for this lies in the opacity of the stan-
dard OWL formalisms, such as OWL/RDF, which
are designed for efficient processing by computer
programs and not for fast comprehension by peo-
ple. Various tools have been proposed to address
this problem, including not only graphical interfaces
such as Prote?ge?, but NLG (Natural Language Gener-
ation) programs that verbalise the axioms of an on-
tology as text (Kaljurand and Fuchs, 2007; Schwit-
ter and Meyer, 2007; Hart et al, 2008). Using such a
tool, a mistaken axiom presented through a sentence
like ?Every person is a movie? immediately leaps to
the eye.
Although there is evidence that verbalisation
helps developers to check individual axioms
(Stevens et al, 2011), there remains a more subtle
problem of undesired entailments, often based on in-
teractions among axioms. The difference between
axioms and entailments is that whereas axioms are
statements encoded by the developer, entailments
are statements inferred from axioms by automated
reasoners such as FaCT++ (Tsarkov and Horrocks,
2006). Because reasoning systems interpret state-
ments absolutely literally, it is quite common for ap-
parently innocuous axioms to lead to absurd conclu-
sions such as ?Everything is a person?, ?Nothing is
a person?, or indeed ?Every person is a movie?. The
standard reasoning algorithms, based on tableau al-
gorithms, will compute these entailments efficiently,
but they provide no information that helps explain
why an undesired conclusion was drawn, and hence
which axiom or axioms need to be corrected.
To provide an explanation of an entailment, the
first step is obviously to determine which axioms are
relevant to the inference. A set of relevant axioms
is known technically as a justification of the entail-
ment, defined as any minimal subset of the ontology
from which the entailment can be drawn (Kalyan-
pur, 2006). The minimality requirement here means
that if any axiom is removed from a justification, the
entailment will no longer be inferable.
Drawing on Kalyanpur?s work, the most direct
strategy for planning an explanation is simply to
verbalise the axioms in the justification, followed
by the entailment, with no additional content. This
strategy serves as a useful baseline for comparison,
and might even be effective for some simple justi-
110
Entailment Person v Movie Every person is a movie.
1. GoodMovie ? ?hasRating.FourStars 1. A good movie is anything that only has ratings of four stars.
Justification 2. Domain(hasRating) = Movie 2. Anything that has a rating is a movie.
3. GoodMovie v StarRatedMovie 3. Every good movie is a star-rated movie.
4. StarRatedMovie v Movie 4. Every star-rated movie is a movie.
Table 1: An example justification that requires further explanation
fications; however, user studies have shown that in
many cases even OWL experts are unable to work
out how the conclusion follows from the premises
without further explanation (Horridge et al, 2009).
This raises two problems of content planning that
we now address: (a) how we can ascertain that fur-
ther explanation is needed, and (b) what form such
explanation should take.
2 Explaining complex justifications
An example of a justification requiring further ex-
planation is shown in Table 1. Statements are pre-
sented in mathematical notation in the middle col-
umn (rather than in OWL, which would take up a
lot more space), with a natural language gloss in the
right column. Since these sentences are handcrafted
they should be more fluent than the output of a ver-
baliser, but even with this benefit, it is extremely
hard to see why the entailment follows.
The key to understanding this inference lies in the
first axiom, which asserts an equivalence between
two classes: good movies, and things that only have
ratings of four stars. The precise condition for an in-
dividual to belong to the second class is that all of its
ratings should be four star, and this condition would
be trivially satisfied if the individual had no ratings
at all. From this it follows that people, parrots,
parsnips, or in general things that cannot have a rat-
ing, all belong to the second class, which is asserted
to be equivalent to the class of good movies. If in-
dividuals with no rating are good movies, then by
axioms 3 and 4 they are also movies, so we are left
with two paradoxical statements: individuals with a
rating are movies (axiom 2), and individuals without
a rating are movies (the intermediate conclusion just
derived). Since everything that exists must either
have some rating or no rating, we are driven to the
conclusion that everything is a movie, from which it
follows that any person (or parrot, etc.) must also be
a movie: hence the entailment. Our target explana-
tion for this case is as follows:
Every person is a movie because the ontology
implies that everything is a movie.
Everything is a movie because (a) anything that
has a rating is a movie, and (b) anything that has
no rating at all is a movie.
Statement (a) is stated in axiom 2 in the justifica-
tion. Statement (b) is inferred because the ontology
implies that (c) anything that has no rating at all
is a good movie, and (d) every good movie is a
movie.
Statement (d) is inferred from axioms 3 and 4 in
the justification. Statement (c) is inferred from
axiom 1, which asserts an equivalence between
two classes: ?good movie? and ?anything that has
as rating only four stars?. Since the second class
trivially accepts anything that has no rating at all,
we conclude that anything that has no rating at all
is a good movie.
Note that in this or any other intelligible explana-
tion, a path is traced from premises to conclusion by
introducing a number of intermediate statements, or
lemmas. Sometimes a lemma merely unpacks part
of the meaning of an axiom ? the part that actually
contributes to the entailment. This is clearly what
we are doing when we draw from axiom 1 the im-
plication that all individuals with no ratings are good
movies. Alternatively a lemma could be obtained by
combining two axioms, or perhaps even more. By
introducing appropriate lemmas of either type, we
can construct a proof tree in which the root node is
the entailment, the terminal nodes are the axioms in
the justification, and the other nodes are lemmas. An
explanation based on a proof tree should be easier to
understand because it replaces a single complex in-
ference step with a number of simpler ones.
Assuming that some kind of proof tree is needed,
the next question is how to construct proof trees that
provide effective explanations. Here two conditions
need to be met: (1) the proof tree should be correct,
in the sense that all steps are valid; (2) it should be
111
accessible, in the sense that all steps are understand-
able. As can be seen, one of these conditions is logi-
cal, the other psychological. Several research groups
have proposed methods for producing logically cor-
rect proof trees for description logic (McGuinness,
1996; Borgida et al, 1999; Horridge et al, 2010),
but explanations planned in this way will not nec-
essarily meet our second requirement. In fact they
could fail in two ways: either they might employ a
single reasoning step that most people cannot fol-
low, or they might unduly complicate the text by
including multiple steps where a single step would
have been understood equally well. We believe this
problem can be addressed by constructing the proof
tree from deduction rules for which the intuitive dif-
ficulty has been measured in an empirical study.1
3 Collecting Deduction Rules
For our purposes, a deduction rule consists of a
conclusion (i.e., an entailment) and up to three
premises from which the conclusion logically fol-
lows. Both conclusion and premises are generalised
by using variables that abstract over class and prop-
erty names, as shown in Table 2, where for example
the second rule corresponds to the well-known syl-
logism that from ?Every A is a B? and ?Every B is a
C?, we may infer ?Every A is a C?.
Our deduction rules were derived through a cor-
pus study of around 500 OWL ontologies. First
we computed entailment-justification pairs using the
method described in Nguyen et al (2010), and
collated them to obtain a list of deduction patterns
ranked by frequency. From this list, we selected pat-
terns that were simple (in a sense that will be ex-
plained shortly) and frequent, subsequently adding
some further rules that occurred often as parts of
more complex deduction patterns, but were not com-
puted as separate patterns because of certain limi-
tations of the reasoning algorithm.2 The deduction
rules required for the previous example are shown
1Deduction rules were previously used by Huang for re-
constructing machine-generated mathematical proofs; however,
these rules were not for description logic based proofs and
assumed to be intuitive to people (Huang, 1994). The out-
put proofs were then enhanced (Horacek, 1999) and verbalised
(Huang, 1994).
2Reasoning services for OWL typically compute only some
kinds of entailment, such as subclass and class membership
statements, and ignore others.
in Table 2. So far, 41 deduction rules have been ob-
tained in this way; these are sufficient to generate
proof trees for 48% of the justifications of subsump-
tion entailments in the corpus (i.e., over 30,000 jus-
tifications).
As a criterion of simplicity we considered the
number of premises (we stipulated not more than
three) and also what is called the ?laconic? property
(Horridge et al, 2008) ? that an axiom should not
contain information that is not required for the en-
tailment to hold. We have assumed that deduction
rules that are simple in this sense are more likely to
be understandable by people; we return to this issue
in section 5, which describes an empirical test of the
understandability of the rules.
4 Constructing Proof Trees
A proof tree can be defined as any tree linking the
axioms of a justification (terminal nodes) to an en-
tailment (root node), in such a way that every local
tree (i.e., every node and its children) corresponds
to a deduction rule. This means that if the entail-
ment and justification already correspond to a de-
duction rule, no further nodes (i.e., lemmas) need
to be added. Otherwise, a proof can be sought by
applying the deduction rules, where possible, to the
terminal nodes, so introducing lemmas and grow-
ing the tree bottom-up towards the root. Exhaus-
tive search using this method may yield zero, one or
multiple solutions ? e.g., for our example two proof
trees were generated, as depicted in Figure 1.3
5 Measuring understandability
To investigate the difficulty of deduction rules em-
pirically, we have conducted a survey in which 43
participants (mostly university staff and students un-
familiar with OWL) were shown the premises of the
rule, expressed as English sentences concerning fic-
titious entities, and asked to choose the correct con-
clusion from four alternatives. They were also asked
to rate the difficulty of this choice on a five-point
scale. For instance, in one problem the premises
3In the current implementation, the proof tree can also be de-
veloped by adding lemmas that unpack part of the meaning of
an axiom, using the method proposed by Horridge et al(2008).
These steps in the proof are not always obvious, so their under-
standability should also be measured.
112
ID Deduction Rule Example Success Rate
1 ?r.? v C Anything that has no ratings at all is a movie. 65%
?r.> v C Anything that has a rating is a movie.
? > v C ? Everything is a movie.
2 C v D Anything that has no ratings at all is a good movie. 88%
D v E Every good movie is a movie.
? C v E ? Anything that has no ratings at all is a movie.
3 C ? ?r.D A good movie is anything that only has ratings of four stars. ?
? ?r.? v C ? Anything that has no ratings at all is a good movie.
Table 2: Deduction rules for the example in Table 1
Figure 1: Proof trees generated by our current system
Figure 2: Results of the empirical study. In our difficulty
scale, 1 means ?very easy? and 5 means ?very difficult?
were ?Every verbeeg is a giantkin; no giantkin is
a verbeeg.?; to answer correctly, participants had to
tick ?Nothing is a verbeeg? and not ?Nothing is a gi-
antkin?.
So far 9/41 deduction rules have been measured
in this way. Figure 2 shows the success rates and the
means of difficulty of those rules. For most prob-
lems the success rates were around 80%, confirm-
ing that the rules were understandable, although in
a few cases performance fell to around 50%, sug-
gesting that further explanation would be needed.
The study also indicates a statistically significant re-
lationship between the accuracy of the participants?
performance and their perceptions of difficulty (r =
0.82, p < 0.01). Two of the three rules in Table 2
were measured in this way. The third rule has not
been tested yet; however, its success rate is expected
to be very low as it was proved to be a very difficult
inference (Horridge et al, 2009).
6 Conclusion
This paper has reported our work in progress on con-
tent planning for explanations of entailments. The
main steps involved in the planning process are sum-
113
Figure 3: Our approach for the content planning. E, J, Pn
are entailments, justifications and proofs respectively; d1
and d2 are difficulty scores and d2 ? d1
marised in Figure 3. We have focused on one as-
pect: the introduction of lemmas that mediate be-
tween premises and conclusion, so organising the
proof into manageable steps. Lemmas are derived
by applying deduction rules collected through a cor-
pus study on entailments and their justifications.
Through a survey we have measured the difficulty of
some of these rules, as evidenced by performance on
the task of choosing the correct conclusion for given
premises. These measures should indicate which
steps in a proof are relatively hard, and thus perhaps
in need of further elucidation, through special strate-
gies that can be devised for each problematic rule.
Our hypothesis is that these measures will also allow
an accurate assessment of the difficulty of a candi-
date proof tree, so providing a criterion for choos-
ing among alternatives ? e.g., by using the success
rates as an index of difficulty, we can sum the in-
dex over a proof tree to obtain a simple measure
of its difficulty. Our verbaliser currently translates
OWL statements literally, and needs to be improved
to make sure any verbalisations do not give rise to
unwanted presuppositions and Gricean implicatures.
Acknowledgments
This research was undertaken as part of the ongo-
ing SWAT project (Semantic Web Authoring Tool),
which is supported by the UK Engineering and
Physical Sciences Research Council (EPSRC). We
thank our colleagues and the anonymous viewers.
References
Alexander Borgida, Enrico Franconi, Ian Horrocks, Deb-
orah L. McGuinness, and Peter F. Patel-Schneider.
1999. Explaining ALC Subsumption. In DL 1999,
International Workshop on Description Logics.
Glen Hart, Martina Johnson, and Catherine Dolbear.
2008. Rabbit: developing a control natural language
for authoring ontologies. In ESWC 2008, European
Semantic Web Conference, pages 348?360.
Helmut Horacek. 1999. Presenting Proofs in a Human-
Oriented Way. In CADE 1999, International Confer-
ence on Automated Deduction, pages 142?156.
Matthew Horridge, Bijan Parsia, and Ulrike Sattler.
2008. Laconic and Precise Justifications in OWL. In
ISWC 2008, International Semantic Web Conference,
pages 323?338.
Matthew Horridge, Bijan Parsia, and Ulrike Sattler.
2009. Lemmas for Justifications in OWL. In DL 2009,
International Workshop on Description Logics.
Matthew Horridge, Bijan Parsia, and Ulrike Sattler.
2010. Justification Oriented Proofs in OWL. In ISWC
2010, International Semantic Web Conference, pages
354?369.
Xiaorong Huang. 1994. Human Oriented Proof Presen-
tation: A Reconstructive Approach. Ph.D. thesis, The
University of Saarbru?cken, Germany.
Kaarel Kaljurand and Norbert Fuchs. 2007. Verbaliz-
ing OWL in Attempto Controlled English. In OWLED
2007, International Workshop on OWL: Experiences
and Directions.
Aditya Kalyanpur. 2006. Debugging and repair of OWL
ontologies. Ph.D. thesis, The University of Maryland,
US.
Deborah Louise McGuinness. 1996. Explaining reason-
ing in description logics. Ph.D. thesis, The State Uni-
versity of New Jersey, US.
Tu Anh T. Nguyen, Paul Piwek, Richard Power, and San-
dra Williams. 2010. Justification Patterns for OWL
DL Ontologies. Technical Report TR2011/05, The
Open University, UK.
Rolf Schwitter and Thomas Meyer. 2007. Sydney OWL
Syntax - towards a Controlled Natural Language Syn-
tax for OWL 1.1. In OWLED 2007, International
Workshop on OWL: Experiences and Directions.
Robert Stevens, James Malone, Sandra Williams,
Richard Power, and Allan Third. 2011. Automating
generation of textual class definitions from OWL to
English. Journal of Biomedical Semantics, 2(S 2:S5).
Dmitry Tsarkov and Ian Horrocks. 2006. FaCT++ De-
scription Logic Reasoner: System Description. In IJ-
CAR 2006, International Joint Conference on Auto-
mated Reasoning, pages 292?297.
114
Proceedings of the 2th Workshop of Natural Language Processing for Improving Textual Accessibility (NLP4ITA), pages 39?48,
Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational Linguistics
A System for the Simplification of Numerical Expressions at Different Levels
of Understandability
Susana Bautista, Raquel Herva?s,
Pablo Gerva?s
Universidad Complutense de Madrid
Prof. Jose? Garc??a Santesmases
Madrid, Spain
{subautis,raquelhb}@fdi.ucm.es
pgervas@sip.ucm.es
Richard Power, Sandra Williams
Department of Computing,
The Open University
Milton Keynes,
MK76AA, UK
r.power@open.ac.uk
s.h.williams@open.ac.uk
Abstract
The purpose of this paper is to motivate and
describe a system that simplifies numerical
expression in texts, along with an evaluation
study in which experts in numeracy and liter-
acy assessed the outputs of this system. We
have worked with a collection of newspaper
articles with a significant number of numerical
expressions. The results are discussed in com-
parison to conclusions obtained from a prior
empirical survey.
1 Introduction
A surprisingly large number of people have limited
access to information because of poor literacy. The
most recent surveys of literacy in the United King-
dom reveal that 7 million adults in England can-
not locate the reference page for plumbers if given
the Yellow Pages alphabetical index. This means
that one in five adults has less literacy than the ex-
pected literacy in an 11-year-old child (Jama and
Dugdale, 2010; Williams et al, 2003a; Christina and
Jonathan, 2010). Additionally, almost 24 million
adults in the U.K. have insufficient numeracy skills
to perform simple everyday tasks such as paying
household bills and understanding wage slips. They
would be unable to achieve grade C in the GCSE
maths examination for 16-year-old school children
(Williams et al, 2003a).
?The Standard Rules on the Equalization of Op-
portunities for Persons with Disabilities? by United
Nations (1994) state that all public information ser-
vices and documents should be accessible in such
a way that they could be easily understood. If we
focus on numerical information, nowadays, a large
percentage of information expressed in daily news
or reports comes in the form of numerical expres-
sions (economic statistics, demography data, etc)
but many people have problems understanding the
more complex expressions. In the text simplification
process, different tasks are carried out: replacing
difficult words, splitting sentences, etc., and the sim-
plification of numerical expressions is one of them.
A possible approach to solve this important social
problem of making numerical information accessi-
ble is to rewrite difficult numerical expressions using
alternative wordings that are easier to understand.
For example, the original sentence, ?25.9% scored A
grades? could be rewritten by ?Around 26% scored
A grades?. In our study we define a ?numerical ex-
pression? as a phrase that presents a quantity, some-
times modified by a numerical hedge as in these ex-
amples: ?less than a quarter? or ?about 98%?. Such
an approach would require a set of rewriting strate-
gies yielding expressions that are linguistically cor-
rect, easier to understand than the original, and as
close as possible to the original meaning. Some loss
of precision could have positive advantages for nu-
merate people as well as less numerate. In rewrit-
ing, hedges play also an important role. For exam-
ple, ?50.9%? could be rewritten as ?about a half? us-
ing the hedge ?about?. In this kind of simplification,
hedges indicate that the original number has been
approximated and, in some cases, also the direction
of the approximation.
This paper presents a system developed for auto-
mated simplification of numerical expressions. Ex-
perts in simplification tasks are asked to validate the
39
simplifications done automatically. The system is
evaluated and the results are discussed against con-
clusions obtained from previous empirical survey.
2 Previous work
Text simplification, a relative new task in Natural
Language Processing, has been directed mainly at
syntactic constructions and lexical choices that some
readers find difficult, such as long sentences, pas-
sives, coordinate and subordinate clauses, abstract
words, low frequency words, and abbreviations.
The rule-based paradigm has been used in the
implementation of some systems for text simpli-
fication, each one focusing on a variety of read-
ers (with poor literacy, aphasia, etc) (Chandrasekar
et al, 1996; Siddharthan, 2003; Jr. et al, 2009;
Bautista et al, 2009).
The transformation of texts into easy-to-read ver-
sions can also be phrased as a translation problem
between two different subsets of language: the orig-
inal and the easy-to-read version. Corpus-based sys-
tems can learn from corpora the simplification oper-
ations and also the required degree of simplification
for a given task (Daelemans et al, 2004; Petersen
and Ostendorf, 2007; Gasperin et al, 2009).
A variety of simplification techniques have been
used, substituting common words for uncommon
words (Devlin and Tait, 1998), activating passive
sentences and resolving references (Canning, 2000),
reducing multiple-clause sentences to single-clause
sentences (Chandrasekar and Srinivas, 1997; Can-
ning, 2000; Siddharthan, 2002) and making appro-
priate choices at the discourse level (Williams et al,
2003b). Khan et at. (2008) studied the tradeoff be-
tween brevity and clarity in the context of generat-
ing referring expressions. Other researchers have fo-
cused on the generation of readable texts for readers
with low basic skills (Williams and Reiter, 2005),
and for teaching foreign languages (Petersen and
Ostendorf, 2007).
Previous work on numerical expressions has stud-
ied the treatment of numerical information in differ-
ent areas like health (Peters et al, 2007), forecast
(Dieckmann et al, 2009), representation of proba-
bilistic information (Bisantz et al, 2005) or vague
information (Mishra et al, 2011). In the NUM-
GEN project (Williams and Power, 2009), a corpus
of numerical expressions was collected and a for-
mal model for planning specifications for propor-
tions (numbers between 0 and 1) was developed.
The underlying theory and the design of the work-
ing program are described in (Power and Williams,
2012).
3 Experimental identification of
simplification strategies for numerical
information
In order to analyze different simplification strategies
for numerical expressions, first we have to study the
mathematical complexity of the expressions. Ex-
pressions can be classified and a level of difficulty
can be assigned. A study about the simplification
strategies selected by experts to simplify numerical
expressions expressed as decimal percentages in a
corpus was carried out in Bautista et al (2011b).
Other important aspect of the simplification task is
the use of hedges to simplify numerical expressions
in the text. A study was performed in Bautista et
al. (2011a) to analyze the use of hedges in the sim-
plification process. This study was done with ex-
perts in simplification tasks. A set of sentences with
numerical expressions were presented and they had
to rewrite the numerical expressions following some
rules. Several hypotheses were expressed and an-
alyzed to understand experts? preferences on sim-
plification strategies and use of hedges to simplify
numerical expressions in the text. The main conclu-
sions from the study were:
Conclusion 1: When experts choose expressions
for readers with low numeracy, they tend to prefer
round or common values to precise values. For ex-
ample, halves, thirds and quarters are usually pre-
ferred to eighths or similar, and expressions like N
in 10 or N in 100 are chosen instead of N in 36.
Conclusion 2: The value of the original propor-
tion influences the choice of simplification strategies
(fractions, ratios, percentages). With values in the
central range (say 0.2 to 0.8 in a 0.0 to 1.0 scale)
and values at the extreme ranges (say 0.0-0.2 and
0.8-1.0) favoring different strategies.
Conclusion 3: When writers choose numerical
expressions for readers with low numeracy, they
only use hedges if they are losing precision.
40
4 A system for adapting numerical
expressions
In this first prototype, only numerical expressions
defined as percentages are adapted. From an in-
put text, the percentage numerical expressions are
detected, a target level of difficulty is chosen and
the simplified version of the text is generated by re-
placing the original numerical expression with the
adapted expression.
4.1 Numerical expression
A numerical expression consists of: (1) a numerical
value, a quantity which may be expressed with dig-
its or with words; (2) an optional unit accompanying
the quantity (euro, miles, . . . ); and (3) an optional
numerical hedge modifier (around, less than, . . . ).
Some examples of numerical expressions used in
our experiments are: ?more than a quarter?, ?around
98.2%?, ?just over 25 per cent? or ?less than 100 kilo-
metres?.
4.2 Levels of difficulty
The Mathematics Curriculum of the Qualifications
and Curriculum Authority (1999) describes a num-
ber of teaching levels and we assume that concepts
to be taught at lower levels will be simpler than ones
taught at higher levels. Following this idea a Scale of
Mathematic Concepts is defined to identify the dif-
ferent levels of difficulty to understand mathematic
concepts. The scale defined from less to greater dif-
ficulty is: numerical expression in numbers (600),
words (six), fractions (1/4), ratios (1 in 4), percent-
ages (25%) and decimal percentages (33.8%).
From the Scale of Mathematic Concepts defined,
different levels of difficulty are considered in our
system. There are three different levels (from eas-
iest to hardest):
1. Fractions Level: each percentage in the text is
adapted using fractions as mathematical form
for the quantity, and sometimes a hedge is used.
2. Percentages without decimals Level (PWD):
the system rounds the original percentage with
decimals and uses hedges if they are needed.
3. Percentages with decimals Level: This is the
most difficult level where no adaptation is per-
formed.
The system operates only on numerical expres-
sions at the highest levels of the scale (the most dif-
ficult levels), that is, numerical expression given in
percentages or decimal percentages, adapting them
to other levels of less difficulty. So, the user can
select the level to which adapt the original numeri-
cal expression from the text. Using the interface of
the system, the level of difficulty is chosen by the fi-
nal user and the numerical expressions from the text
with higher level of difficulty than the level chosen
are adapted following the rules defined.
4.3 Set of strategies
A set of strategies is defined so they can be applied to
adapt the original numerical expression. The quan-
tity of the expression is replaced with another ex-
pression and sometimes numerical hedges are added
to create the simplified numerical expression.
The use of hedges to simplify numerical expres-
sion can be influenced by three parameters. The first
is the type of simplification depending on the math-
ematical knowledge of the final user. The second is
the simplification strategy for the choice of the final
mathematical form. And the last is the loss of preci-
sion that occurs when the expression is simplified.
Out of the European Guidelines for the Produc-
tion of Easy-to-Read Information for People with
Learning Disability (Freyhoff et al, 1998), only one
involves the treatment of numbers: ?Be careful with
numbers. If you use small numbers, always use the
number and not the word?. For example, if the texts
says ?four?, the system adapts it by ?4? following this
European Guideline. This strategy is applied by the
system at all levels.
There are other strategies to adapt numerical ex-
pressions in the form of percentage to other levels of
difficulty: (1) replace decimal percentages with per-
centages without decimals; (2) replace decimal per-
centages with ratios; (3) replace percentages with ra-
tios; (4) replace decimal percentages with fractions;
(5) replace percentages with fractions; (6) replace
ratios with fractions; (7) replace numerical expres-
sions in words with numerical expressions in digits.
At each level of difficulty, a subset of the strate-
gies is applied to simplify the numerical expression.
For the Fractions Level the strategies 4, 5 and 7
are used. For the Percentages with decimals Level
the strategies 1 and 7 are applied. And for the last
41
level, Percentages without decimals Level only the
last strategy, number 7, is used.
4.4 System operation
The system takes as input the original text. The user
of the system has to choose the level of difficulty. A
set of numerical expressions are selected and a set
of transformations is applied to adapt them, generat-
ing as output of the system a text with the numerical
expressions simplified at the chosen level.
The system works through several phases to adapt
the numerical expressions in the input text. Some of
them are internal working phases (2, 4 and 5). The
rest of them (1, 3 and 6) are phases where the user
of the system plays a role. The phases considered in
the system are:
1. Input text: an original text is selected to adapt
its numerical expressions.
2. Mark Numerical Expressions: the numerical
expressions that can be adapted are marked.
3. Choose the level of difficulty: the user chooses
the desired level of difficulty for the numerical
expressions in the text.
4. Adapt the numerical expression from the
text: each numerical expression is adapted if
the level of the numerical expression is higher
than the level of difficulty chosen.
5. Replace numerical expression in the text:
adapted numerical expressions replace the orig-
inals in the text.
6. Output text: the final adapted version of the
text is presented to the user.
The next subsections presents how the system acts
in each phase and what kind of tools are used to
achieve the final text.
4.4.1 Phase 1: Input text
In this first phase, a plain text is chosen as input to
the system to adapt its numerical expressions. Using
a Graphical User Interface (GUI) in Java, the user
can upload an original text.
4.4.2 Phase 2: Mark numerical expressions
For the text chosen, the system executes the Nu-
merical Expression Parser1. Using this parser the
numerical quantities are annotated with their type
(cardinal, fraction, percentage, decimal percentage,
etc.), their format (words, digits), their value (Vg),
their units, and hedging phrases, such as ?more
than?. The input to the program is the plain text file
and the output is the text with sentences and numer-
ical expressions annotated in XML format. In the
following code we can see how a numerical quantity
is annotated in the parser.
Overall figures showed the national pass
rate soared
<numex hedge=?above? hedge-
sem=?greaterthan? type=?percentage?
format=?digits? Vg=?0.97?>
above 97% </numex>
The XML file is treated by the system and numer-
ical expressions are marked in the original text. So,
the user can see which numerical expressions are go-
ing to be adapted by the system (in the next phase)
depending on the level of difficulty chosen.
4.4.3 Phase 3: Choose the level of difficulty
The user of the system chooses the level of dif-
ficulty to adapt the original numerical expressions.
There are three levels: fractions, percentages with-
out decimals and percentages with decimals.
4.4.4 Phase 4: Adapt the Numerical
Expressions
After deciding the level of difficulty, the system
has to adapt each numerical expression to generate
the final version. The process of simplification has
two stages: obtaining the candidate and applying the
adaptation and hedge choice rules.
From the XML file produced by the parser the fol-
lowing information for a numerical expression is ob-
tained: (1) if there is or not hedge and the kind of
hedge; (2) the type (cardinal, fraction, percentage,
decimal percentage) and format (digits or words)
of the original numerical expression; (3) the given
value (Vg) translated from the original numerical ex-
pression value of the text; and (4) the units from the
1For more details see (Williams, 2010)
42
O
rig
in
al
 
Ex
pr
es
sio
n
Pa
rs
er
Vm
g
Pr
op
or
tio
n
Ap
pr
ox
.
Pr
og
ra
m
Vr
M
or
e 
th
an
 2
8%
0.
28
0.
28
1/
3
0.
33
Vg
Vc
[0
...
1]
[0
...
1]
1/
3
30
%
28
%
Figure 1: Obtaining the candidate for simplification. The original expression is annotated by the parser (Vg), and this
value is normalized (Vmg). A candidate substitute value (Vc) is chosen from the proportion approximation program
and normalized (Vr).
original expression (M, ins, grams). For example,
if in the text the original numerical expression is a
percentage like ?25.9%?, there is no hedge, the type
is ?decimal percentage?, the format is ?digits?, Vg is
0.259 and there are no units. In the expression, ?20
grams?, there is no hedge, the type is ?cardinal?, the
format is ?digits?, Vg is 20 and the parser annotates
the units with ?g?.
The given value Vg annotated by the parser is
transformed into a value between 0 to 1, referred
to as mapping given value (Vmg), which represents
the proportion under consideration. This value is
given as input to the proportion approximation pro-
gram (Power and Williams, 2012), which returns a
list of candidates for substitution. From this list,
the first option is taken as candidate substitute value
(Vc), because the program returns them in decreas-
ing order of precision. This means that the most
precise candidate at the required level of difficulty
is chosen. The program also might return the val-
ues ?none? and ?all? if the input value is close to
0 or 1, respectively. From the Vc we calculate the
rounded value (Vr) corresponding to the normaliza-
tion of the candidate value between 0 to 1. For ex-
ample, if Fraction level is chosen, for the original
expression ?more than 28%? with Vmg=0.28, the
system chooses Vc=1/3 with Vr=0.33. The whole
process can be seen in Figure 1.
An additional level of adaptation is required be-
yond simple replacement with the candidate substi-
tute value. If the original numerical expressions in
the text are difficult to understand, the system must
adapt them to the desired level of difficulty. For each
numerical expression, the system only applies the
adaptation rules if the difficulty level of the numer-
ical expression is higher than the level of difficulty
chosen by the user. This is captured by a set of three
adaptation rules:
? If the type of the numerical expression is ?car-
dinal? and the format is ?words? then the candi-
date to be used in the simplification is Vg. For
example, if the original numerical expression is
?six?, it will be replaced by ?6?.
? In a similar way, if the type is ?fraction? (the
lowest possible level of difficulty) and the for-
mat is also ?words? then the candidate is ob-
tained by applying the proportion approxima-
tion program. For example, if the original nu-
merical expression is ?a quarter?, it would be
replaced by ?1/4?.
? If the type is ?percentages? or ?decimal percent-
ages? and the format is ?digits? then the can-
didate is calculated by the proportion approxi-
mation program provided that the level of dif-
ficulty chosen in the GUI was lower than the
level of the calculated numerical expression.
In order to complete the simplification, the system
has to decide if a hedge should be used to achieve
the final version of the adapted numerical expres-
sion. This decision is taken based on the difference
in value between the value of the original expression
in the text (Vg) and the value of the candidate substi-
tute (Vc) (as given by the relative difference between
the normalized values Vr and Vmg calculated in the
first stage). The actual hedge used in the original
expression (if any) is also considered. The various
possible combinations of these values, and the corre-
sponding choice of final hedge, are described in Ta-
ble 1, which presents all possible options to decide
in each case, the hedge and the value corresponding
to the final numerical expression. For example, if
the original expression is ?more than 28%?, we have
Vc=1/3, Vmg=0.28 and Vr=0.33. Then Vr>Vmg so
the corresponding choice of the final hedge is in the
43
OriginalNumExp if Vr>Vmg if Vr=Vmg if Vr<Vmg
more than OrigValue around Vc more than Vc more than Vc
exactly OrigValue less than Vc exactly Vc more than Vc
less than OrigValue less than Vc less than Vc around Vc
OrigValue around Vc Vc around Vc
Table 1: Hedge Choice Rules. For each original expression (OrigValue), the normalized values (Vmg, Vr) are used to
determinate the hedge chosen for the simplified expression. The final version is composed by the hedge chosen and
the candidate value (Vc)
first column of Table 1 (?around?) and the simplified
expression is ?around 1/3?.
When the user chooses the Fraction Level in the
system, every numerical expression with difficulty
level greater than fraction level will be replaced by
a numerical expression expressed in fraction form.
Depending on the values Vr and Vmg, the appropri-
ate hedge will be chosen.
4.4.5 Phase 5: Replace numerical expressions
Once the system has applied its rules, an adapted
version is available for each original numerical ex-
pression which was more difficult than the target dif-
ficulty level. The output text is obtained by replac-
ing these difficult expressions with the correspond-
ing simplified version.
5 Evaluation of the system
This section presents the evaluation of the system,
describing the materials, experiment, participants
and results of the evaluation.
5.1 Materials
We selected for the experiment a set of eight can-
didate sentences from the NUMGEN corpus, but the
number of numerical expressions was larger as some
sentences contained more than one proportion ex-
pression. In total we had 13 numerical expressions.
We selected sentences with as many variations in
context, precision and different wordings as possi-
ble. The range of proportions values was from points
nearly 0.0 to almost 1.0, to give coverage to a wide
spread of proportion values. We considered values
in the central range (say 0.2 to 0.8) and values at the
extreme ranges (say 0.0-0.2 and 0.8-1.0). We also
classified as common values the well-known per-
centages and fractions like 25%, 50%, 1/4 and 1/2,
and as uncommon values the rest like 15% or 6/7.
5.2 Experiment
To evaluate the system a questionnaire was pre-
sented to a set of human evaluators. The experi-
ment was created and presented on SurveyMonkey2,
a commonly-used provider of web surveys. For each
original sentence, we presented two possible simpli-
fications generated by the system. Participants were
asked to use their judgement to decide whether they
agreed that the simplified sentences were acceptable
for the original sentence. A Likert scale of four val-
ues (Strongly Disagree, Disagree, Agree, Strongly
Agree) was used to collect the answers.
In the survey only two levels of adaptation from
the original sentence were presented. The first op-
tion generated by the system was for the Fractions
level. The second option generated by the system
was for the Percentages without decimals (PWD).
5.3 Participants
The task of simplifying numerical expressions is dif-
ficult, so we selected a group of 34 experts made up
of primary or secondary school mathematics teach-
ers or adult basic numeracy tutors, all native English
speakers. This group is well qualified to tackle the
task since they are highly numerate and accustomed
to talking to people who do not understand mathe-
matical concepts very well. We found participants
through personal contacts and posts to Internet fo-
rums for mathematics teachers and numeracy tutors.
5.4 Results
The answers from the participants were evaluated.
In total we collected 377 responses, 191 responses
for the Fraction level and 186 responses for the Per-
centage without decimals (PWD). Table 2 shows the
average from the collected responses, considering 1
2http://www.surveymonkey.com/s/WJ69L86
44
Level Total average Values Average Values Average
Fraction 2,44
Central 2,87 Common 2,59
Extreme 2,14 Uncommon 1,21
PWD 2,96
Central 3,00 Common 2,80
Extreme 2,96 Uncommon 3,22
Table 2: System Evaluation: Fraction Level and Percentages Without Decimals (PWD)
Opinion Fraction PWD
Level Level
Strongly Disagree 19% 6%
Disagree 27% 15%
Agree 43% 56%
Strongly Agree 11% 23%
Table 3: Opinion of the experts in percentages
to 4 for strongly disagree to strongly agree. In ad-
dition, Table 3 shows the distribution in percentages
of the opinion of the experts. At the Fraction level,
there is not too much difference between the average
of the answers of the experts that agree with the sys-
tem and those that disagree. Most experts are neu-
tral. But for the PWD level the average shows that
most experts agree with the simplification done.
We have also analyzed the answers considering
two different criteria from the original numerical ex-
pressions: when they are central (20% to 80%) or
extreme values (0% to 20% and 80% to 100%), and
when the original numerical expressions are com-
mon or uncommon values. In general terms, the ex-
perts think that the simplification done by the sys-
tem in the PWD level is better than the simplification
done in the Fraction level. They disagree specially
with the simplification using fractions in two cases.
One is the treatment of the extreme values where the
system obtains as possible candidates ?none? and
?all?3. Another case is when uncommon fractions
are used to simplify the numerical expression, like
for example 9/10. In these two cases the average is
lower than the rest of the average achieved.
5.5 Discussion
The system combines syntactic transformations (via
the introduction of hedges) and lexical substitu-
3See (Power and Williams, 2012) for a discussion of appro-
priate hedges for values near the extreme points of 0 and 1.
tions (by replacing actual values with substitution
candidates and transforming quantities expressed as
words into digits) to simplify the original numerical
expression. These kinds of transformations are dif-
ferent from those used by other systems, which rely
only on syntactic transformations or only on lexi-
cal substitutions. Rules are purpose-specific and fo-
cused on numerical expressions. With this kind of
transformations the readability of the text improves
in spite of the fact that the resulting syntactic struc-
ture of the numerical expression is more compli-
cated, due to the possible presence of hedges. For
example, for a original numerical expression like
?25.9%? the system generates the simplified ?more
than a quarter? which is easier to understand even
though longer and syntactically more complex.
With respect to coverage of different types of nu-
merical expressions, this system does not consider
ratios as a possible simplification strategy because
the proportion approximation program does not use
them as candidates to simplify a proportion. This
possibility should be explored in the future.
Another observation is that the system does not
consider the context of the sentence in which the
numerical expression occurs. For example, if the
sentence makes a comparison between two numer-
ical expressions that the system rounded to the same
value, the original meaning is lost. One example
of this case is the following sentence from the cor-
pus: ?One in four children were awarded A grades
(25.9%, up from 25.3% last year)?. Both percent-
ages ?25.9%? and ?25.3%? are simplified by the sys-
tem using ?around 1/4? and the meaning of the sen-
tence is lost. Thus we should consider the role of
context (the set of numerical expressions in a given
sentence as a whole and the meaning of the text) in
establishing what simplifications must be used.
45
6 Conforming with conclusions of prior
surveys
The results presented for the system are evaluated
in this section for conformance with the conclusions
resulting from the empirical studies described in
(Bautista et al, 2011b) and (Bautista et al, 2011a).
With respect to the preference for round or com-
mon values in simplification (Conclusion 1), the sys-
tem presented conforms to this preference by virtue
of the way in which the list of candidate substitu-
tions is produced by the program. The candidates re-
turned by the program are already restricted to com-
mon values of percentages (rounded up) and frac-
tions, so the decision to consider as preferred candi-
date the one listed first implicitly applies the criteria
that leads to this behavior.
With respect to the need to treat differently values
in the extreme or central ranges of proportion (Con-
clusion 2), the system addresses this need by virtue
of the actual set of candidates produced by the pro-
gram in each case. For example, if the original ex-
pression is a extreme value like ?0.972?, the program
produces a different candidate substitution (?almost
all?) that in the central ranges is not considered.
With respect to restricting the use of hedges to
situations where loss of precision is incurred (Con-
clusion 3), the hedge choice rules applied by the
system (see Table 1) satisfy this restriction. When
Vr=Vmg hedges are included in the simplified ex-
pression only if they were already present in the
original expression.
In addition, the system rounds up any quantities
with decimal positions to the nearest whole num-
ber whenever the decimal positions are lost during
simplification. This functionality is provided im-
plicitly by the program, which presents the rounded
up version as the next option immediately follow-
ing the alternative which includes the decimal posi-
tions. For example, if the input proportion is ?0.198?,
some rounded candidate substitutions are calculated
as ?almost 20%? or ?less than 20%?.
Finally, the system follows the European guide-
lines for the production of easy to read information
in that it automatically replaces numerical quantities
expressed in words with the corresponding quantity
expressed in digits.
7 Conclusions and future work
The system described in this paper constitutes a first
approximation to the task of simplifying numerical
expressions in a text to varying degrees of difficulty.
The definition of an scale of difficulty of numeri-
cal expressions, the identification of rules governing
the selection of candidate substitution and the appli-
cation of hedges constitute important contributions.
The empirical evaluation of the system with human
experts results in acceptable rates of agreement. The
behavior of the system conforms to the conclusions
on simplification strategies as applied by humans re-
sulting from previous empirical surveys.
There are different aspects to improve the actual
system from the data collected, with a special atten-
tion to cases in which the experts disagree. As future
work, the syntactic context should be considered to
simplify numerical expression, extending the kind
of proportion to simplify and treating special cases
analyzed in this first version. At the syntactic level,
some transformation rules can be implemented from
a syntactic analysis. It is important that the meaning
of the sentences be preserved regardless of whether
part of the sentence is deleted or rewritten by the
adaptation rules. In addition, the numerical expres-
sion parser and the proportion approximation pro-
gram could also be studied in order to evaluate the
impact of their errors in the final performance.
Our final aim is to develop an automatic simplifi-
cation system in a broader sense, possibly including
more complex operations like syntactic transforma-
tions of the structure of the input text, or lexical sub-
stitution to reduce the complexity of the vocabulary
employed in the text. Additionally we hope to de-
velop versions of the simplification system for other
languages, starting with Spanish. Probably the sim-
plification strategies for numbers would be the same
but the use of hedge modifiers may be different.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2009-14659-C03-01
Project), Universidad Complutense de Madrid and
Banco Santander Central Hispano (GR58/08 Re-
search Group Grant), and the FPI grant program.
46
References
Susana Bautista, Pablo Gerva?s, and Ignacio Madrid.
2009. Feasibility Analysis for SemiAutomatic Con-
version of Text to Improve Readability. In Proceed-
ings of The Second International Conference on Infor-
mation and Communication Technologies and Acces-
sibility, Hammamet, Tunusia, May.
Susana Bautista, Raquel Herva?s, Pablo Gerva?s, Richard
Power, and Sandra Williams. 2011a. Experimental
identification of the use of hedges in the simplifica-
tion of numerical expressions. In Proceedings of the
Second Workshop on Speech and Language Process-
ing for Assistive Technologies, pages 128?136, Edin-
burgh, Scotland, UK, July. Association for Computa-
tional Linguistics.
Susana Bautista, Raquel Herva?s, Pablo Gerva?s, Richard
Power, and Sandra Williams. 2011b. How to
Make Numerical Information Accessible: Experimen-
tal Identification of Simplification Strategies. In Cam-
pos, Pedro and Graham, Nicholas and Jorge, Joaquim
and Nunes, Nuno and Palanque, Philippe and Winck-
ler, Marco, editor, Human-Computer Interaction IN-
TERACT 2011, volume 6946 of Lecture Notes in Com-
puter Science, pages 57?64. Springer Berlin / Heidel-
berg.
Ann M. Bisantz, Stephanie Schinzing, and Jessica
Munch. 2005. Displaying uncertainty: Investigating
the effects of display format and specificity. Human
Factors: The Journal of the Human Factors and Er-
gonomics Society, 47(4):777.
Yvonne Canning. 2000. Cohesive simplification of
newspaper text for aphasic readers. In 3rd annual
CLUK Doctoral Research Colloquium.
Raman Chandrasekar and Bangalore Srinivas. 1997.
Automatic induction of rules for text simplification.
Knowledge-Based Systems, 10.
Raman Chandrasekar, Christine Doran, and Bangalore
Srinivas. 1996. Motivations and methods for text
simplification. In In Proceedings of the Sixteenth In-
ternational Conference on Computational Linguistics
(COLING ?96), pages 1041?1044.
Clark Christina and Douglas Jonathan. 2010. Young
people reading and writing today: Whether, what and
why. Technical report, London: National Literacy
Trust.
Walter Daelemans, Anja Hothker, and Erik Tjong Kim
Sang. 2004. Automatic Sentence Simplification for
Subtitling in Dutch and English. In Proceedings of the
4th Conference on Language Resources and Evalua-
tion, pages 1045?1048, Lisbon, Portugal.
Siobhan Devlin and John Tait. 1998. The use of a
Psycholinguistic database in the Simplification of Text
for Aphasic Readers. Lecture Notes. Stanford, USA:
CSLI.
Nathan Dieckmann, Paul Slovic, and Ellen Peters. 2009.
The use of narrative evidence and explicit likelihood
by decision makers varying in numeracy. Risk Analy-
sis, 29(10).
Geert Freyhoff, Gerhard Hess, Linda Kerr, Elizabeth
Menzel, Bror Tronbacke, and Kathy Van Der Veken.
1998. European guidelines for the production of easy-
to-read information.
Caroline Gasperin, Lucia Specia, Tiago F. Pereira, and
Sandra M. Aluisio. 2009. Learning when to simplify
sentences for natural text simplification. In Proceed-
ings of the Encontro Nacional de Inteligencia Artificial
(ENIA), pages 809?818, Bento Gonalves, Brazil.
Deeqa Jama and George Dugdale. 2010. Literacy: State
of the nation. Technical report, National Literacy
Trust.
Arnaldo Candido Jr., Erick Maziero, Caroline Gasperin,
Thiago A. S. Pardo, Lucia Specia, and Sandra M.
Aluisio. 2009. Supporting the Adaptation of Texts
for Poor Literacy Readers: a Text Simplification Ed-
itor for Brazilian Portuguese. In Proceedings of the
NAACL/HLT Workshop on Innovative Use of NLP
for Building Educational Applications, pages 34?42,
Boulder, Colorado.
Imtiaz Hussain Khan, Kees Deemter, and Graeme
Ritchie. 2008. Generation of refering expressions:
managing structural ambiguities. In Proceedings of
the 22nd International Conference on Computational
Linguistics(COLING), pages 433?440, Manchester.
Himanshu Mishra, Arul Mishra, and Baba Shiv. 2011.
In praise of vagueness: malleability of vague informa-
tion as a performance booster. Psychological Science,
22(6):733?8, April.
Ellen Peters, Judith Hibbard, Paul Slovic, and Nathan
Dieckmann. 2007. Numeracy skill and the commu-
nication, comprehension, and use of risk-benefit infor-
mation. Health Affairs, 26(3):741?748.
Sarah E. Petersen and Mari Ostendorf. 2007. Text Sim-
plification for Language Learners: A Corpus Analysis.
In Proceedings of Workshop on Speech and Language
Technology for Education (SLaTE).
Richard Power and Sandra Williams. 2012. Generating
numerical approximations. Computational Linguis-
tics, 38(1).
Qualification and Curriculum Authority. 1999. Mathe-
matics: the National Curriculum for England. Depart-
ment for Education and Employment, London.
Advaith Siddharthan. 2002. Resolving attachment and
clause boundary amgiguities for simplifying relative
clause constructs. In Proceedings of the Student Re-
search Workshop, 40th Meeting of the Association for
Computacional Linguistics.
47
Advaith Siddharthan. 2003. Syntactic Simplification and
Text Cohesion. Ph.D. thesis, University of Cambridge.
United Nations. 1994. Standard Rules on the Equal-
ization of Opportunities for Persons with Disabilities.
Technical report.
Sandra Williams and Richard Power. 2009. Precision
and mathematical form in first and subsequent men-
tions of numerical facts and their relation to document
structure. In Proc. of the 12th European Workshop on
Natural Language Generation, Athens.
Sandra Williams and Ehud Reiter. 2005. Generating
readable texts for readers with low basic skills. In
Proceeding of the 10th European Workshop on Natu-
ral Language Generation, pages 140?147, Aberdeen,
Scotland.
Joel Williams, Sam Clemens, Karin Oleinikova, and
Karen Tarvin. 2003a. The Skills for Life survey: A
national needs and impact survey of literacy, numer-
acy and ICT skills. Technical Report Research Report
490, Department for Education and Skills.
Sandra Williams, Ehud Reiter, and Liesl Osman. 2003b.
Experiments with discourse-level choices and read-
ability. In In Proceedings of the European Natu-
ral Language Generation Workshop (ENLG) and 11th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (EACL03), pages
127?134.
Sandra Williams. 2010. A Parser and Information
Extraction System for English Numerical Expres-
sions. Technical report, The Open University, Milton
Keynes, MK7 6AA, U.K.
48
