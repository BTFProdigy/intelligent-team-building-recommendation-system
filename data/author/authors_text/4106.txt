Deep Processing of Honorification Phenomena in a Typed Feature
Structure Grammar
Jong-Bok Kim
School of English
Kyung Hee U.
Seoul, 130-701
jongbok@khu.ac.kr
Peter Sells
Dept. of Linguistics
Stanford U.
Stanford, CA 94305
sells@stanford.edu
Jaehyung Yang
School of Computer Eng.
Kangnam U.
Kyunggi, 449-702, Korea
jhyang@kangnam.ac.kr
Abstract
Honorific agreement is one of the main
properties of languages like Korean or
Japanese, playing an important role
in appropriate communication. This
makes the deep processing of honorific
information crucial in various computa-
tional applications such as spoken lan-
guage translation and generation. We
argue that, contrary to the previous lit-
erature, an adequate analysis of Ko-
rean honorification involves a system
that has access not only to morpho-
syntax but to semantics and pragmatics
as well. Along these lines, we have de-
veloped a typed feature structure gram-
mar of Korean (based on the frame-
work of HPSG), and implemented it
in the Linguistic Knowledge Builder
System (LKB). The results of parsing
our experimental test suites show that
our grammar provides us with enriched
grammatical information that can lead
to the development of a robust dialogue
system for the language.
1 Basic Properties of Honorific
Agreement
Honorification, one of the main features of spoken
language in Korean, plays a key role in proper and
successful verbal communication (Chang 1996,
Lee 1998, Sohn 1999). The Korean honorific sys-
tem basically requires that when the subject is in
the honorific form (usually with the marker -nim),
the predicate also be inflected with the honorific
form -(u)si as in (1):1
(1) a. sensayng-nim-i wus-usi-ess-e.
teacher-HON-NOM laugh-HON-PST-DECL
?The teacher laughed.?
b.#sensayng-nim-i wus-ess-e.
This type of agreement is often assumed to be
purely pragmatic, mainly because certain contexts
allow disagreeing cases between the subject and
the verb: the utterance of (1)b can be felicitous
when the speaker does not honor the referent of
the subject (marked by #). The possibility of hav-
ing such disagreement has often to an assumption
in the literature that using the -nim and -si form
of verbs is a matter of gradience and appropriate-
ness rather than grammaticality (cf. Chang 1996,
Pollard and Sag 1994, Lee 1998).
However, one often neglected fact is that this
agreement constraint must be observed when the
subject is non-human as in (2) (cf. Sohn 1999):
(2) a. cha-ka o-(*si)-ess-e.
cha-NOM come-HON-PST-DECL
?The car came.?
b. kwukhoy-ka pepan-ul simuy-ha-(*si)-ess-e.
congress bill review-HON-PST-DECL
?The congress reviewed the bill.?
If we rely only on pragmatic information, we
would have difficulty understanding why, in con-
trast to the disagreement in (1)b, disagreement
like that in (2) are rarely found in real language
usages.
1Abbreviations we use in the paper include ARG
(ARGUMENT), ACC (Accusative), BAKGR (BACK-
GROUND), COMP (Complementizer), CTXT (CON-
TEXT), DECL (Declarative), HON (Honorific), IMPER
(Imperative), NOM (Nominative), ORTH (ORTHOGRA-
PHY), PST (Past), SYN (SYNTAX), SEM (SEMANTICS),
RELS (RELATIONS), and POS (part of speech).
97
In addition, there exist agreement-sensitive
syntactic phenomena such as auxiliary verb con-
structions:
(3) a. sensayng-nim-i nolay-lul
teacher-HON-NOM song-ACC
pwulu-si-ci anh-(usi)-ess-e.
sing-HON-COMP not-HON-PST-DECL
?The teacher did not sing a song.?
b. sensayng-nim-i ton-ul mo-(*si)-e
teacher-NOM money-ACC save-HON-COMP
twu-si-ess-e.
hold-HON-PST-DECL
?The teacher saved money (for rainy days).?
c. sensayng-nim-i nolay-lul
teacher-HON-NOM song-ACC
pwulu-si-na po-(*si)-e.
sing-HON-COMP seem-HON-DECL
?The teacher seems to sing a song.?
As noted here, even though the subject is hon-
ored in each case, the honorific marker on the
main predicate in (3)a is optional with the aux-
iliary anh- ?not?; in (3)b the marker must appear
only on the auxiliary verb twu- ?hold?; meanwhile
in (3)c the marker cannot appear on the auxiliary
po ?seem?. Such clear contrasts, we can hardly
attribute to pragmatic factors.2
2 Honorification in a Typed Feature
Structure Grammar
A closer look at the honorific phenomena of the
language in the previous section suggests that an
adequate theory of honorification aiming for inte-
gration into a proper communication system re-
quires not just complex pragmatic information
but also morpho-syntactic information. The ba-
sic framework of the grammar we adopt for mod-
elling the language is the type-feature structure
grammar of HPSG. HPSG seeks to model human
languages as systems of constraints on typed fea-
ture structures. In particular, the grammar adopts
the mechanism of a type hierarchy in which ev-
ery linguistic sign is typed with appropriate con-
straints and hierarchically organized. This system
then allows us to express cross-classifying gen-
eralizations about linguistic entities such as lex-
emes, stems, words, and phrases in the language
(cf. Kim and Yang 2004, Kim 2004).
2In addition to this subject-verb agreement, the language
employs addressee agreement marked on a verbal suffix de-
pending on the honoring relationship between speaker and
addressee. Such agreement, though implemented in our
grammar, is not presented here because of space limit here.
2.1 Lexicon and Subject Agreement
Our grammar, named KPSG (Korean Phrase
Structure Grammar), first assumes that a nominal
with -nim and a verbal with -si bear the head fea-
ture specification [HON +]. This is supported by
the contrast in the following:
(4) a. [[haksayng-i manna-n] sensayng-nim-i]
student-NOM meet-MOD teacher-HON-NOM
o-si-ess-e.
come-HON-PST-DECL
?The teacher that the student met came.?
b. [[sensayng-nim-i manna-si-n]
teacher-NOM-NOM meet-HON-MOD
haksayng-i] o-(*si)-ess-e.
student-NOM come-HON-PST-DECL
?The student that the teacher met came.?
As seen here, it is the honorific information on the
head noun sensayng-nim in (4)a that agrees with
that of the verb.
With this head feature information, the gram-
mar builds the honorific nominal type (n-hon)
from the basic lexeme (n-lxm) as represented in
the following feature structures:3
(5) a.?
?????????????
n-lxm
ORTH ?sensayng ? ?teacher?
SYN |HEAD
[
POS noun
HON boolean
]
SEM 2
?
???
INDEX i
RELS
?[
PRED teacher-rel
INSTANCE i
]?
?
???
?
?????????????
b.
?
??????
n-hon
ORTH ?sensayng-nim ? ?teacher-HON?
SYN |HEAD
[
POS noun
HON +
]
SEM 2
?
??????
As seen in (5)a, a nominal lexeme with no hon-
orific marker -nim is underspecified for the HON
feature.4
Meanwhile, the subject of an honorific verbal
element carries the feature [HON +] in addition
to the relevant pragmatic information:
3The information our grammar encodes for such lexeme
entries is only the shaded part: all the other information is
inherited from its supertypes defined in the grammar. For
a more comprehensive system of morphology built within
such a system, see Kim (2004) and Kim and Yang (2004).
4The boxed number here is used as a way of showing that
semantic value of the lexeme, n-lxm is identical with that of
the honorific noun n-hon.
98
(6)
a.
?
?????????
v-lxm
ORTH 1
SYN |HEAD
[
POS verb
HON boolean
]
ARG-ST
?
NP
[
INDEX i
]
, . . .
?
SEM 2
?
?????????
b.
?
????????????????????
v-hon
ORTH 1 + si
SYN |HEAD
[
POS verb
HON +
]
ARG-ST
?
NP
[
HON +
INDEX i
]
, . . .
?
CTXT
?
????
C-INDICES | SPEAKER p
BAKGR
??
?
PRED honoring
ARG1 p
ARG2 i
?
?
?
?
????
?
????????????????????
The basic verbal lexeme type v-lxm in (6)a does
not carry any restriction on its subject. However,
as given in (6)b, the v-hon type with the -(u)si suf-
fix adds the information that its subject (the first
element in the ARG-ST (argument structure)) is
[HON +], in addition to the information that the
speaker is honoring the subject referent as given
in the CTXT value.
One of the key points in this system is that even
though the [HON +] verb selects a [HON +] sub-
ject, the subject of a nonhonorific verb can be ei-
ther in the honorific or nonhonorific form since its
value is underspecified with respect to the verb.
This then correctly allows disagreeing examples
like (1)b where the subject is [HON +] and the
verb?s HON value is ?boolean?:
(7) sensayng-nim-i wuc-ess-e. ?The teacher laughed.?
The nonhonorific verb combines with the hon-
orific subject with no honoring intention from the
speaker since the nonhonorific verb does not bear
the pragmatic constraint that the speaker honors
the referent of the subject.
Yet the grammar blocks disagreeing cases like
(2) where an honorific verb combines a non-
honorific subject:
(2) a. *cha-ka o-si-ess-ta. ?The car came.?
b. *kwukhoy-ka ku pepan-ul simuy-ha-si-ess-e.
?The congress reviewed the bill.?
These are simply not parsed since the honorific
verb here would combine with the [HON ?] sub-
ject, violating the constraint in (6)b. A noun
like sensayng ?teacher? is [HON boolean], while
sensayng-nim is [HON +], and most nouns are
[HON ?].
2.2 Object and Oblique Agreement
While subject honorification has a productive suf-
fixal expression, there are some lexically sup-
pletive forms like poyp-e ?see.HON-DECL? and
mosi-e ?take.HON-DECL?, which require their
object to be in the honorific form:
(8) a. *John-i Mary-lul poyp-ess-e.
John-NOM Mary-ACC see.HON-PST-DECL
?John honorably saw Mary.?
b. John-i sensayng-nim-ul poyp-ess-e.
John-NOM teacher-HON-ACC
?John honorably saw the teacher.?
Our grammar lexically specifies that these supple-
tive verbs require the object to be [HON +] to-
gether with the pragmatic honoring relation. The
following is the lexical information that a supple-
tive verb like this accumulates from the inheri-
tance hierarchy:
(9) ?
????????????????
v-lxm
ORTH ?poyp-? ?HON.see?
SYN |HEAD 1 [HON +]
ARG-ST
?
NP[INDEX i], NP
[
HON +
INDEX j
]?
SEM see-rel
CTXT
?
??BAKGR
??
?
PRED honoring
ARG1 i
ARG2 j
?
?
??
??
?
????????????????
Such lexical information can easily block exam-
ples like (8)a where the object is [HON ?].
Lexically suppletive forms like tuli-e
?give.HON-DECL? and yeccup-e ?ask.HON-
DECL? require their oblique argument to be in
the HON form (nonhonorific forms are cwu-e
and mwut-e, respectively):
(10) a. John-i sensayng-nim-eykey senmwul-ul
John-NOM teacher-HON-DAT present-ACC
tuli-ess-e.
give.HON-PST-DECL
?John gave the present to the teacher.?
b. *John-i haksayng-eykey senmwul-ul tuli-ess-e.
Just like object agreement, our grammar assigns
the HON restriction on its dative argument to-
gether with the pragmatic honoring constraint:
99
(11) ?
????????????
v-lxm
SYN |HEAD |HON +
ARG-ST
?
[INDEX i], [ ],
[
HON +
INDEX k
]?
CTXT |BAKGR
??
?
PRED honoring
ARG1 i
ARG2 k
?
?
?
?
????????????
Once again the grammar rules out examples like
(10)b in which the dative argument haksayng-
eykey ?student-DAT? is nonhonorific. How-
ever, nothing blocks the grammar from gener-
ating examples like (12) where the dative argu-
ment sensayng-nim-eykey ?teacher-HON-DAT? is
[HON +] even if the verb cwu- ?give? is in the
nonhonorific (unspecified) form:
(12) John-i sensayng-nim-eykey senmwul-ul cwu-ess-e.
2.3 Multiple Honorification
Given this system, we can easily predict that it
is possible to have multiple honorific examples
in which subject agreement cooccurs with object
agreement:
(13) ape-nim-i sensayng-nim-ul
father-HON-NOM teacher-HON-ACC
poyp-(usi)-ess-e.
HON.see-HON-PST-DECL
?The father saw the teacher.?
The honorific suffix -si on the verb here requires
the subject to be [HON +] whereas the supple-
tive verb stem asks its object to be [HON +]. In
such examples, the honorific marker in the verb
can be optional or the verb can even be replaced
by the nonsuppletive form po- ?seem?. However,
the grammar does not generate cases like the fol-
lowing:
(14) a. *John-i sensayng-nim-ul
John-NOM teacher-HON-ACC
poyp-usi-ess-e.
HON.see-HON-PST-DECL
?John saw the teacher.?
b. *ape-nim-i John-ul
HON.see-HON-PST-DECL
poyp-ess-e.
HON.see-HON-PST-DECL
?The father saw John.?
(14)a is ruled out since the HON form -(u)si re-
quires the subject to be [HON +] whereas (14)b is
ruled out since the suppletive form poyp- selects
a [HON +] object.
We also can see that oblique agreement can oc-
cur together with subject agreement:
(15) a. eme-nim-i sensayng-nim-eykey
mother-HON-NOM teacher-HON-DAT
senmwul-ul tuli-si-ess-e.
present-ACC give.HON-PST-DECL
?Mother gave the teacher a present.
b.#eme-nim-i sensayng-nim-eykey senmwul-ul
tuli-ess-e.
c.#eme-nim-i sensayng-nim-eykey senmwul-ul
cwu-(si)-ess-e.
d. *John-i sensayng-nim-eykey senmwul-ul tuli-si-
ess-e.
e. *eme-nim-i John-eykey senmwul-ul tuli-si-ess-e.
Since the nonhonorific verb places no restriction
on the subject, the grammar allows the disagree-
ment in (15)b and c. However, (15)d and (15)e
cannot be generated: the former violates subject
agreement and the latter violates object agree-
ment.
2.4 Agreement in Auxiliary Constructions
The present honorification system in the KPSG
can offer us a streamlined way of explaining
the agreement in auxiliary verb constructions we
noted in section 1.1. Basically there are three
types of auxiliaries with respect to agreement (see
Sells 1998):
Type I: In the construction with auxiliary verbs
like anh- ?not?, when the subject is in the hon-
orific form, the honorific suffix -si can optionally
appear either on the preceding main verb or on the
auxiliary verb or on both:
(16) a. sensayng-nim-i o-si-ci
teacher-NOM come-HON-COMP
anh-usi-ess-e.
not.HON-PST-DECL
?The teacher did not come.?
b. sensayng-nim-i o-si-ci anh-ess-e.
c. sensayng-nim-i o-ci anh-usi-ess-e.
d.#sensayng-nim-i o-ci anh-ess-e .
Type II: When the head auxiliary verb is one
like po- ?try?, twu- ?hold?, and ci- ?become?, sub-
ject honorification occurs only on the auxiliary
verb. That is, the preceding main verb with the
specific COMP suffix form -a/e cannot have the
honorific suffix -si:
(17) a. *sensayng-nim-i John-ul cap-usi-e
teacher-NOM John-ACC catch-HON-COMP
twu-si-ess-e.
do.for.the.future
?The teacher hold John for future.?
b. sensayng-nim-i John-ul cap-a twu-si-ess-e.
c. *sensayng-nim-i John-ul cap-usi-e twu-ass-e.
d. sensayng-nim-i John-ul cap-a twu-ass-e.
100
Type III: Unlike Type II, auxiliary verbs like
po- ?see? and kath- ?seem? cannot have the hon-
orific suffix -si even if the subject is in the hon-
orific form:
(18) a. *sensayng-nim-i chayk-ul ilk-usi-na
teacher-NOM book-ACC read-HON-COMP
po-si-ta.
seem-DECL
?The teacher seems to read a book.?
b. sensayng-nim-i chayk-ul ilk-usi-na po-ta.
c.#sensayng-nim-i chayk-ul ilk-na po-ta.
d. *sensayng-nim-i chayk-ul ilk-usi-na po-si-ta.
First, the agreement in Type I simply follows
from the general assumption that this kind of aux-
iliary verbs acts like a raising verb whose subject
is identical with that of the main verb:
(19) a. ?
?????????
aux-v
ORTH ?anh-a? ?not-DECL?
SYN |HEAD |AUX +
ARG-ST
?
1 , 2
[
LEX +
ARG-ST
?
1 , . . .
?
]?
SEM not-rel
?
?????????
b.
?
?????????
aux-hon-v
ORTH ?anh-usi-e? ?not-HON-DECL?
SYN |HEAD
[
AUX +
HON +
]
ARG-ST
?
1 [HON +] , 2
?
SEM not-rel
?
?????????
The negative auxiliary verb with or without the
-(u)si suffix selects as its arguments a subject and
a lexical complement whose subject is identical
with the auxiliary?s subject. This means when ei-
ther one of the verbs requires an HON subject,
then the combination of the main verb as a com-
plex predicate will also require an HON subject.5
The absence of the HON on the main verb for
the Type II AUX is due to the language?s mor-
phological constraints. Such an auxiliary verb
forms a verbal complex together with a main
verb that bears the COMP suffix -a/e: this suf-
fix morphologically requires its verb stem to have
no honorific -(u)si (cf. Kim and Yang 2004).
This morphological constraint can be attested by
the fact that suppletive honorific form with no
5This treatment assumes that the auxiliary verb combines
with the preceding (main or auxiliary) verb and forms a com-
plex predicate. See Kim and Yang (2004) for this line of
treatment.
productively-formed -si marking can occur in the
Type II construction:6
(20) a. sensayng-nim-i sakwa-lul tusi-e
teacher-NOM apple-ACC HON.eat-COMP
po-si-ess-e.
try-HON-PST-DECL
?The teacher tried to eat the apple.?
b. sensayng-nim-i chayk-ul ilk-(*usi)-e
teacher-NOM book-ACC read-HON-COMP
po-si-ess-e.
try-HON-PST-DECL
?The teacher tried to read the book.?
Within the grammar we developed where each
specific verb stem has its own type constraint, the
stem value of the COMP suffix -a/e must be a verb
lexeme with no suffix -si.
As for the Type III AUX, the grammar needs
to rely on semantics: AUX verbs like po- ?seem?
and kath- ?seem? select propositions as their se-
mantic argument:
(21) ?
?????????????
?po-? ?see?
SYN |HEAD
[
AUX +
HON ?
]
ARG-ST ?S[INDEX s2]?
SEM
?
????
INDEX s1
RELS
??
?
PRED seem-rel
ARG0 s1
ARG1 s2
?
?
?
?
????
?
?????????????
The honoring relation applies not to a proposition
but to a human individual: it is such a seman-
tic property that places a restriction on the HON
value of the auxiliary verb.
3 Testing the Feasibility of the Analysis
In testing the performance and feasibility of the
grammar, we implemented our grammar in the
LKB (Linguistic Knowledge Building) system
(cf. Copestake 2002). The test suites we used con-
sist of the SERI Test Suites ?97 (Sung and Jang
1997), the Sejong Corpus, and sentences from
the literature on honorification. The SERI Test
Suites (Sung and Jang 1997), designed to evalu-
ate the performance of Korean syntactic parsers,
6The verb in Korean cannot be an independent word
without inflectional suffixes. The suffixes cannot be attached
arbitrarily to a stem or word, but need to observe a regular
fixed order. Reflecting this, the verbal morphology has tra-
ditionally been assumed to be templatic:
(i) V-base + (Passive/Causative) + (HON) + (TENSE)
+ MOOD
101
consists of total 472 sentences (292 test sentences
representing the core phenomena of the language
and 180 sentences representing different types of
predicate). Meanwhile, the Sejong Corpus has
179,082 sentences with about 2 million words.
We randomly selected 200 simple sentences (the
average number of words in each sentence is
about 5) from the corpus. These sentences are
classified according to their honorification types
(agreement target ? predicate) and the ratio of
parsed sentences:7
(22) (target) # of # Parsed
(predicate) Sentences Sentences
nonHON (tgt)
? 514 (76.4%) 455 (88.5%)
nonHON (pred)
HON (tgt)
? 64 (9.5%) 58 (90%)
HON (pred)
HON (tgt)
? 90 (13.3%) 82 (91%)
nonHON (pred)
nonHON (tgt)
? 4 (0.05%) 0 (0%)
HON (pred)
Total 672 595 (88.5%)
In addition to these sentences, we selected 100
sentences (including the ones given in the paper)
from the literature on Korean honorification: 51
sentences with -si marked verbs, 31 with auxiliary
verb constructions, and 18 with suppletive verb
forms. We obtained similar results: the grammar
parsed a total of 96 sentences.
Among the total of 691 parsed sentences, we
checked the meaning representations (minimal re-
cursion semantics: MRS) and the pragmatic rep-
resentations of 100 randomly selected sentences,
and could see that the representations contain the
correct information that the grammar is designed
for. We believe that the enriched deep process-
ing of grammatical honorific information that the
grammar successfully composed in the parsing
process can well function for the proper under-
standing of natural data.
4 Conclusion
Honorification, one of the most salient features of
the language, involves various grammatical levels
7The four nonHON ? HON sentences are cases where
the nominals are not in the honorific form. One way to ac-
cept such examples is to remove the [HON +] restriction on
the object of such verbs while keeping the pragmatic honor-
ing relationship between the subject and object.
of information: morphology, syntax, semantics,
and pragmatics. It is thus necessary for a parser
to have not only shallow but also deep process-
ing of the honorific information, so that we can
check that a given sentence is felicitous. Such
deep processing is a prerequisite to the success of
dialogue processing, zero pronominal/anaphoric
resolution, and so forth.
The grammatical architecture we adopt is a
typed feature structure grammar, couched upon
HPSG, that allows us to handle morpho-syntactic,
semantic, and also pragmatic information. The
implementation of this grammar in the LKB sys-
tem proves that a type-feature structure grammar
can provide us with a proper deep processing
mechanism for Korean honorification that opens
doors for promising applications in such areas as
machine translation and dialogue systems.
References
Chang, Suk-Jin. 1996. Korean. Amsterdam:
John Benjamins.
Copestake, Ann. 2002. Implementing Typed Fea-
ture Structure Grammars. Stanford: CSLI
Publications.
Kim, Jong-Bok and Jaehyung Yang. 2004. Pro-
jections from Morphology to Syntax in the
Korean Resource Grammar: Implementing
Typed Feature Structures. In Lecture Notes
in Computer Science Vol. 2945: 13?24.
Springer-Verlag.
Kim, Jong-Bok. 2004. Korean Phrase Struc-
ture Grammar (In Korean). Seoul: Hankwuk
Publishing.
Lee, Dong-Young. 1998. Information-based pro-
cessing of Korean dialogue with reference to
English. Seoul: Thaehak Publishing.
Pollard, Carl and Sag, Ivan A. 1994. Head-
Driven Phrase Structure Grammar.
Chicago: University of Chicago Press.
Sells, Peter. 1998. Structural Relationships
within complex predicates. In B.-S. Park and
J. Yoon (eds.), The 11th International Con-
ference on Korean Linguistics. Seoul: Han-
kwuk Publishing, 115?147.
Sohn, Ho-Min. 1999. The Korean Language.
Cambridge: Cambridge University Press.
Sung, Won-Kyung and Myung-Gil Jang. 1997.
SERI Test Suites ?95. In Proceedings of
the Conference on Hanguel and Korean Lan-
guage Information Processing.
102
Proceedings of the 8th Workshop on Asian Language Resources, pages 144?152,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
Development of the Korean Resource Grammar:
Towards Grammar Customization
Sanghoun Song
Dept. of Linguistics
Univ. of Washington
sanghoun@uw.edu
Jong-Bok Kim
School of English
Kyung Hee Univ.
jongbok@khu.ac.kr
Francis Bond
Linguistics and Multilingual Studies
Nanyang Technological Univ.
bond@ieee.org
Jaehyung Yang
Computer Engineering
Kangnam Univ.
jhyang@kangnam.ac.kr
Abstract
The Korean Resource Grammar (KRG)
is a computational open-source grammar
of Korean (Kim and Yang, 2003) that has
been constructed within the DELPH-IN
consortium since 2003. This paper re-
ports the second phase of the KRG devel-
opment that moves from a phenomena-
based approach to grammar customiza-
tion using the LinGO Grammar Matrix.
This new phase of development not only
improves the parsing efficiency but also
adds generation capacity, which is nec-
essary for many NLP applications.
1 Introduction
The Korean Resource Grammar (KRG) has been
under development since 2003 (Kim and Yang,
2003) with the aim of building an open source
grammar of Korean. The grammatical frame-
work for the KRG is Head-driven Phrase Struc-
ture Grammar (HPSG: (Pollard and Sag, 1994;
Sag et al, 2003)), a non-derivational, constraint-
based, and surface-oriented grammatical archi-
tecture. The grammar models human languages
as systems of constraints on typed feature struc-
tures. This enables the extension of grammar
in a systematic and efficient way, resulting in
linguistically precise and theoretically motivated
descriptions of languages.
The initial stage of the KRG (hereafter,
KRG1) has covered a large part of the Korean
grammar with fine-grained analyses of HPSG.
However, this version, focusing on linguistic
data with theory-oriented approaches, is unable
to yield efficient parsing or generation. The addi-
tional limit of the KRG1 is its unattested parsing
efficiency with a large scale of naturally occur-
ring data, which is a prerequisite to the practical
uses of the developed grammar in the area of MT.
Such weak points have motivated us to move
the development of KRG to a data-driven ap-
proach from a theory-based one upon which the
KRG1 is couched. In particular, this second
phase of the KRG (henceforth, KRG2) also starts
with two methods: shared grammar libraries (the
Grammar Matrix (Bender et al, 2002; Bender et
al., 2010)) and data-driven expansion (using the
Korean portions of multilingual texts).
Next, we introduce the resources we used
(? 2). this is followed by more detailed motiva-
tion for our extensions (? 3). We then detail how
we use the grammar libraries from the Grammar
Matrix to enable generation (? 2) and then ex-
pand the coverage based on a corpus study (? 5).
2 Background
2.1 Open Source NLP with HPSG
The Deep Linguistic Processing with HPSG
Initiative (DELPH-IN: www.delph-in.net)
provides an open-source collection of tools and
grammars for deep linguistic processing of hu-
man language within the HPSG and MRS (Min-
imal Recursion Semantics (Copestake et al,
2005)) framework. The resources include soft-
ware packages, such as the LKB for parsing and
generation, PET (Callmeier, 2000) for parsing,
and a profiling tool [incr tsdb()] (Oepen, 2001).
There are also several grammars: e.g. ERG; the
144
English Resource Grammar (Flickinger, 2000),
Jacy; a Japanese Grammar (Siegel and Bender,
2002), the Spanish grammar, and so forth. These
along with some pre-compiled versions of pre-
processing or experimental tools are packaged in
the LOGON distribution.1 Most resources are un-
der the MIT license, with some parts under other
open licenses such as the LGPL.2 The KRG has
been constructed within this open-source infras-
tructure, and is released under the MIT license3.
2.2 The Grammar Matrix
The Grammar Matrix (Bender et al, 2002; Ben-
der et al, 2010) offers a well-structured envi-
ronment for the development of precision-based
grammars. This framework plays a role in build-
ing a HPSG/MRS-based grammar in a short
time, and improving it continuously. The Gram-
mar Matrix covers quite a few linguistic phe-
nomena constructed from a typological view.
There is also a starter-kit, the Grammar Matrix
customization system which can build the back-
bone of a computational grammar from a linguis-
tic description.
2.3 A Data-driven Approach
Normally speaking, building up a computational
grammar is painstaking work, because it costs
too much time and effort to develop a grammar
by hand only. An alternative way is a data-driven
approach which ensures ?cheap, fast, and easy?
development. However, this does not mean that
one is better than the other. Each of these two
approaches has its own merits. To achieve the
best or highest performance of parsing and gen-
eration, each needs to complement the other.
3 Directions for Improvement
3.1 Generation for MT
HPSG/MRS-based MT architecture consists of
parsing, transfer, and generation, as assumed in
Figure 1 (Bond et al, 2005). As noted earlier,
1wiki.delph-in.net/moin/LogonTop
2www.opensource.org/licenses/
3It allows people ?. . . without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies? so long as ?The above copyright notice
and this permission notice shall be included . . . ?
Figure 1: HPSG/MRS-based MT Architecture
the KRG1 with no generation function is limited
only to the Source Analysis in Figure 1. In addi-
tion, since its first aim was to develop a Korean
grammar that reflects its individual properties in
detail, the KRG1 lacks compatible semantic rep-
resentations with other grammars such as ERG
and Jacy. The mismatches between the compo-
nents of the KRG1 and those of other grammars
make it difficult to adopt the Korean grammar for
an MT system. To take a representative example,
the KRG1 treats tense information as a feature
type of HEAD, while other grammars incorpo-
rate it into the semantics; thus, during the trans-
fer process in Figure 1, some information will be
missing. In addition, KRG1 used default inheri-
tance, which makes the grammar more compact,
but means it could not used with the faster PET
parser. We will discuss this issue in more detail
in Section 4.1.
Another main issue in the KRG1 is that some
of the defined types and rules in the grammar are
inefficient in generation. Because the declared
types and rules are defined with theoretical mo-
tivations, the run-time for generating any parsing
units within the system takes more than expected
and further causes memory overflow errors to
crop up almost invariably, even though the in-
put is quite simple. This problem is partially due
to the complex morphological inflection system
in the KRG1. Section 4.2 discusses how KRG2,
solves this problem.
Third it is better ?to be robust for parsing and
strict for generation? (Bond et al, 2008). That
means robust rules will apply in parsing, though
the input sentence does not sound perfect, but not
in generation. For example, the sentence (1b),
the colloquial form of the formal, standard sen-
tence (1a), is used more frequently in colloquial
context:
(1) a. ney-ka
you-NOM
cham
really
yeppu-ney.
pretty-DECL
?You are really pretty.?
b. ni-ka cham ippu-ney
The grammar needs to parse both (1a) and
145
(1b) and needs to yield the same MRS be-
cause both sentences convey the same truth-
conditional meaning. However, the KRG1 han-
dles only the legitimate sentence (1a), exclud-
ing (1b). The KRG1 is thus not sophisticated
enough to distinguish these two stylistic differ-
ent sentences. Therefore we need to develop the
generation procedures that can choose a proper
sentence style. Section 4.3 proposes the ?STYLE?
feature structure as the choice device.
3.2 Exploiting Corpora
One of the main motivations for our grammar
improvement is to achieve more balance between
linguistic motivation and practical purpose. We
have first evaluated the coverage and perfor-
mance of the KRG1 using a large size of data
to track down the KRG1?s problems that may
cause parsing inefficiencies and generating clog.
In other words, referring to the experimental re-
sults, we patterned the problematic parts in the
current version. According to the error pattern,
on the one hand, we expanded lexicon from oc-
curring texts in our generalization. On the other
hand, we fixed the previous rules and sometimes
introduced new rules with reference to the occur-
rence in texts.
3.3 How to Improve
In developing the KRG, we have employed two
strategies for improvement; (i) shared grammar
libraries and (ii) exploiting large text corpora.
We share grammar libraries with the Gram-
mar Matrix in the grammar (Bender et al, 2002)
as the foundation of KRG2. The Grammar Ma-
trix provides types and constraints that assist the
grammar in producing well-formed MRS repre-
sentations. The Grammar Matrix customization
system provides with a linguistically-motivated
broad coverage grammar for Korean as well as
the basis for multilingual grammar engineering.
In addition, we exploit naturally occurring texts
as the generalization corpus. We chose as our
corpora Korean texts that have translations avail-
able in English or Japanese, because they can be
the baseline of multilingual MT. Since the data-
driven approach is influenced by data type, mul-
tilingual texts help us make the grammar more
suitable for MT in the long term. In developing
the grammar in the next phrase, we assumed the
following principles:
(2) a. The Grammar Matrix will apply when a judg-
ment about structure (e.g. semantic represen-
tation) is needed.
b. The KRG will apply when a judgment about
Korean is needed.
c. The resulting grammar has to run on both
PET and LKB without any problems.
d. Parsing needs to be accomplished as robustly
as possible, and generation needs to be done
as strictly as possible.
4 Generation
It is hard to alter the structure of the KRG1
from top to bottom in a relatively short time,
mainly because the difficulties arise from con-
verting each grammar module (optimized only
for parsing) into something applicable to gener-
ation, and further from making the grammar run
separately for parsing and generation.
Therefore, we first rebuilt the basic schema of
the KRG1 on the Grammar Matrix customiza-
tion system, and then imported each grammar
module from KRG1 to the matrix-based frame
(?4.1). In addition, we reformed the inflectional
hierarchy assumed in the KRG1, so that the
grammar does not impede generation any longer
(? 4.2). Finally, we introduced the STYLE feature
structure for sentence choice in accordance with
our principles (2c-d) (?4.3).
4.1 Modifying the Modular Structure
The root folder krg contains the basic type
definition language files (*.tdl. In the
KRG2, we subdivided the types.tdl into:
matrix.tdl file which corresponds to gen-
eral principles; korean.tdl with language
particular rules; types-lex.tdl for lex-
ical types and types-ph.tdl for phrasal
types. In addition, we reorganized the KRG1?s
lexicons.tdl file into the lex folder con-
sisting of several sub-files in accordance with the
POS values (e.g.; lex-v.tdl for verbs).
The next step is to revise grammar modules
in order to use the Grammar Matrix to a full ex-
tent. In this process, when inconsistencies arise
between KRG1 and KRG2, we followed (2a-b).
146
We further transplanted each previous module
into the KRG2, while checking the attested test
items used in the KRG1. The test items, con-
sisting of 6,180 grammatical sentences, 118 un-
grammatical sentences, were divided into sub-
groups according to the related phenomena (e.g.
light verb constructions).
4.2 Simplifying the Inflectional Hierarchy
Korean has rigid ordering restrictions in the mor-
phological paradigm for verbs, as shown in (3).
(3) a. V-base + HON + TNS + MOOD + COMP
b. ka-si-ess-ta-ko ?go-HON-PST-DC-COMP?
KRG1 dealt with this ordering of suffixes by us-
ing a type hierarchy that represents a chain of in-
flectional slots (Figure 2: Kim and Yang (2004)).
Figure 2: Korean Verbal Hierarchy
This hierarchy has its own merits, but it is not
so effective for generating sentences. This is be-
cause the hierarchy requires a large number of
calculations in the generation process. Figure 3
and Table 1 explains the difference in computa-
tional complexity according to each structure.In
Figure 3: Calculating Complexity
Figure 3, (a) is similar to Figure 2, while (b) is on
the traditional template approach. Let us com-
pare each complexity to get the target node D.
For convenience? sake, let us assume that each
node has ten constraints to be satisfied. In (a),
since there are three parents nodes (i.e. A, B, and
C) on top of D, D cannot be generated until A,
B, and C are checked previously. Hence, it costs
at least 10,000 (10[A] ?10[B] ?10[C] ?10[D])
calculations. In contrast, in (b), only 100 (10[A]
?10[D]) calculations is enough to generate node
D. That means, the deeper the hierarchy is, the
more the complexity increases. Table 1 shows
(a) requires more than 52 times as much com-
plexity as (b), though they have the same number
of nodes.
Table 1: Complexity of (a) and (b)
(a) (b)
B? 10[A]?10[B?] 100 10[A]?10[B?]
C? 10[A]?10[B]?10[C?] 1,000 10[A]?10[C?]
D? 10[A]?10[B]?10[C]?10[D?] 10,000 10[A]?10[D?]
D 10[A]?10[B]?10[C]?10[D] 10,000 10[A]?10[D]
? 21,100 400
When generation is processed by LKB, all po-
tential inflectional nodes are made before syntac-
tic configurations according to the given MRS.
Thus, if the hierarchy becomes deeper and con-
tains more nodes, complexity of (a)-styled hi-
erarchy grows almost by geometric progres-
sion. This makes generation virtually impossi-
ble, causing memory overflow errors to the gen-
eration within the KRG1.
A fully flat structure (b) is not always supe-
rior to (a). First of all, the flat approach ig-
nores the fact that Korean is an agglutinative
language. Korean morphological paradigm can
yield a wide variety of forms; therefore, to enu-
merate all potential forms is not only undesirable
but also even impossible.
The KRG2 thus follows a hybrid approach (c)
that takes each advantage of (a) and (b). (c) is
more flattened than (a), which lessens computa-
tional complexity. On the other hand, in (c), the
depth of the inflectional hierarchy is fixed as two,
and the skeleton looks like a unary form, though
each major node (marked as a bigger circle) has
its own subtypes (marked as dotted lines). Even
though the depth has been diminished, the hier-
archy is not a perfectly flat structure; therefore, it
can partially represent the austere suffix ordering
in Korean. The hierarchy (c), hereby, curtails the
cost of generation.
In this context, we sought to use the minimum
number of possible inflectional slots for Korean.
We need at least three: root + semantic slot(s)
+ syntactic slot(s). That is, a series of suffixes
147
Table 2: Complexity of (a-c)
Depth Complexity
(a) n ? 3 ? 10,000
(b) n = 1 100
(c) n = 2 10,000
that denote semantic information attaches to the
second slot, and a series of suffixes, likewise,
attaches to the third slot. Since semantic suf-
fixes are, almost invariably, followed by syntac-
tic ones in Korean, this ordering is convincing,
granting that it does not fully represent that there
is also an ordering among semantic forms or syn-
tactic ones. (4) is an example from hierarchy (c).
There are three slots; root ka ?go?, semantic suf-
fixes si-ess, and syntactic ones ta-ko.
(4) a. V-base + (HON+TNS) + (MOOD+COMP)
b. ka-si+ess-ta+ko ?go-HON+PST-DC+COMP?
Assuming there are ten constraints on each node,
the complexity to generate D in (c) is just 10,000.
The measure, of course, is bigger than that of (b),
but the number never increases any more. That
means, all forms at the same depth have equal
complexity, and it is fully predictable. Table 2
compares the complexity from (a) to (c). By con-
verting (a) to (c), we made it possible to generate
with KRG2.
4.3 Choosing a Sentence Style
The choice between formal or informal (collo-
quial) sentence styles depends on context. A ro-
bust parser should cover both styles, but we gen-
erally want a consistent style when generating.
Figure 4: Type Hierarchy of STYLE
In such a case, the grammar resorts to STYLE
to filter out the infelicitous results. The type hi-
erarchy is sketched out in Figure 4. strict is near
to school grammar (e.g. written is a style of
newspapers). On the other hand, some variant
forms that stem from the corresponding canoni-
cal forms falls under robust in Figure 4. For in-
stance, if the text domain for generation is news-
paper, we can select only written as our sentence
choice, which excludes other styled sentences
from our result.
Let us see (1a-b) again. ni ?you? in (1b) is a di-
alect form of ney, but it has been used more pro-
ductively than its canonical form in daily speech.
In that case, we can specify STYLE of ni as di-
alect as given below. In contrast, the neutral
form ney has an unspecified STYLE feature:
ni := n-pn-2nd-non-pl &
[ STEM < ??ni?? >, STYLE dialect ].
ney := n-pn-2nd-non-pl &
[ STEM < ??ney?? > ].
Likewise, since the predicate in (1b) ippu
?pretty? stems from yeppu in (1a), they share
the predicate name ? yeppu a 1 rel? (i.e. the
RMRS standard for predicate names such as
? lemma pos sense rel?), but differ in each
STYLE feature. That means (1a-b) share the
same MRS structure (given below). KRG hereby
can parse (1b) into the same MRS as (1a) and
generate (1a) from it.
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
mrs
LTOP h1 h
INDEX e2 e
RELS
?
?
?
?
?
?
?
?
?
person rel
LBL h3 h
ARG0 x4
?
?
?
x
PNG.PER 2nd
PNG.NUM non-pl
?
?
?
?
?
?
?
?
?
?
?
,
?
?
?
?
?
?
?
exist q rel
LBL h5 h
ARG0 x4
RSTR h6 h
BODY h7 h
?
?
?
?
?
?
?
,
?
?
?
?
?
cham d 1 rel
LBL h1
ARG0 e9 e
ARG1 h8 h
?
?
?
?
?
,
?
?
?
?
?
yeppu a 1 rel
LBL h10 h
ARG0 e2
ARG1 x4
?
?
?
?
?
?
HCONS
?
?
?
?
qeq
HARG h6
LARG h3
?
?
?
,
?
?
?
qeq
HARG h8
LARG h10
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 5: MRS of (1a-b)
These kinds of stylistic differences can take
place at the level of (i) lexicon, (ii) morpholog-
ical combination, and (iii) syntactic configura-
tion. The KRG2 revised each rule with reference
to its style type; therefore, we obtained totally
96 robust rules. As a welcoming result, we could
manipulate our generation, which was successful
respect to (2c-d). Let us call the version recon-
structed so far ?base?.
148
5 Exploiting Corpora
5.1 Resources
This study uses two multilingual corpora; one is
the Sejong Bilingual Corpora: SBC (Kim and
Cho, 2001), and the other is the Basic Travel Ex-
pression Corpus: BTEC (Kikui et al, 2003). We
exploited the Korean parts in each corpus, taking
them as our generalization corpus. Table 3 repre-
sents the configuration of two resources (KoEn:
Korean-English, KoJa: Korean-Japanese):
Table 3: Generalization Corpora
SBC BTEC
Type Bilingual Multilingual
Domain Balanced Corpus Tourism
Words KoEn : 243,788 914,199KoJa : 276.152
T/T ratio KoEn : 27.63 92.7KoJa : 20.28
Avr length KoEn : 16.30 8.46KoJa : 23.30
We also make use of nine test suites sorted
by three types (Each test suite includes 500 sen-
tences). As the first type, we used three test
sets covering overall sentence structures in Ko-
rean; Korean Phrase Structure Grammar (kpsg;
Kim (2004)), Information-based Korean Gram-
mar (ibkg; Chang (1995)), and the SERI test set
(seri; Sung and Jang (1997)).
Second, we randomly extracted sentences
from each corpus, separately from our gener-
alization corpus; two suites were taken from
the Korean-English and Korean-Japanese pair in
SBC (sj-ke and sj-kj, respectively). The other
two suites are from the BTEC-KTEXT (b-k),
and the BTEC-CSTAR (b-c); the former consists
of relatively plain sentences, while the latter is
composed of spoken ones.
Third, we obtained two test suites from sample
sentences in two dictionaries; Korean-English
(dic-ke), and Korean-Japanese (dic-kj). These
suites assume to have at least two advantages
with respect to our evaluation; (i) the sentence
length is longer than that of BTEC as well as
shorter than that of SBC, (ii) the sample sen-
tences on dictionaries are normally made up of
useful expressions for translation.
5.2 Methods
We tried to do experiments and improve the
KRG, following the three steps repeatedly: (i)
evaluating, (ii) identifying, and (iii) exploiting.
In each of the first step, we tried to parse the nine
test suites and generate sentences with the MRS
structures obtained from the parsing results, and
measured their coverage and performance. Here,
?coverage? means how many sentences can be
parsed or generated, and ?performance? repre-
sents how many seconds it takes on average. In
the second step, we identified the most serious
problems. In the third step, we sought to exploit
our generalization corpora in order to remedy the
drawbacks. After that, we repeated the proce-
dures until we obtain the desired results.
5.3 Experiments
So far, we have got two versions; KRG1 and
base. Our further experiments consist of four
phases; lex, MRS, irules, and KRG2.
Expanding the lexicon: To begin with, in or-
der to broaden our coverage, we expanded our
lexical entries with reference to our generaliza-
tion corpus and previous literature. Verbal items
are taken from Song (2007) and Song and Choe
(2008), which classify argument structures of
Korean verbal lexicon into subtypes within the
HPSG framework in a semi-automatic way. The
reason why we do not use our corpus here is
that verbal lexicon commonly requires subcat-
egorization frames, but we cannot induce them
so easily only using corpora. For other word
classes, we extracted lexical items from the POS
tagged SBC and BTEC corpora. Table 4 explains
how many items we extracted from our general-
ization corpus. Let us call this version ?lex?.
Table 4: Expansion of Lexical Items
verbal nouns 4,474
verbs and adjectives 1,216
common nouns 11,752
proper nouns 7,799
adverbs 1,757
numeral words 1,172
MRS: Generation in LKB, as shown in Fig-
ure 1, deploys MRS as the input, which means
our generation performance hinges on the well-
149
formedness of MRS. In other words, if our MRS
is broken somewhere or constructed inefficiently,
generation results is directly affected. For in-
stance, if the semantic representation does not
scope, we will not generate correctly. We were
able to identify such sentences by parsing the
corpora, storing the semantic representations and
then using the semantic well formedness check-
ers in the LKB. We identified all rules and lexi-
cal items that produced ill-formed MRSs using
a small script and fixed them by hand. This had
an immediate and positive effect on coverage as
well as performance in generation. We refer to
these changes as ?MRS?.
Different inflectional forms for sentence
styles: Texts in our daily life are actually com-
posed of various styles. For example, spoken
forms are normally more or less different from
written ones. The difference between them in
Korean is so big that the current version of KRG
can hardly parse spoken forms. Besides, Ko-
rean has lots of compound nouns and derived
words. Therefore, we included these forms into
our inflectional rules and expanded lexical en-
tries again (3,860 compound nouns, 2,791 de-
rived words). This greatly increased parsing cov-
erage. We call this version ?irules?.
Grammaticalized and Lexicalized Forms:
There are still remaining problems, because our
test suites contain some considerable forms.
First, Korean has quite a few grammaticalized
forms; for instance, kupwun is composed of a
definite determiner ku and a classifier for human
pwun ?the person?, but it functions like a sin-
gle word (i.e. a third singular personal pronoun).
In a similar vein, there are not a few lexical-
ized forms as well; for example, a verbal lexeme
kkamek- is composed of kka- ?peel? and mek-
?eat?, but it conveys a sense of ?forget?, rather
than ?peel and eat?. In addition, we also need to
cover idiomatic expressions (e.g. ?thanks?) for
robust parsing. Exploiting our corpus, we added
1,720 grammaticalized or lexicalized forms and
352 idioms. Now, we call this ?KRG2?.
Table 5 compares KRG2 with KRG1, and Fig-
ure 6 shows how many lexical items we have
covered so far.
Table 5: Comparison between KRG1 and KRG2
KRG1 KRG2
# of default types 121 159
# of lexical types 289 593
# of phrasal types 58 106
# of inflectional rules 86 244
# of syntactic rules 36 96
# of lexicon 2,297 39,190
Figure 6: Size of Lexicon
5.4 Evaluation
Table 6 shows the evaluation measure of this
study. ?p? and ?g? stand for ?parsing? and ?gener-
ation?, respectively. ?+? represents the difference
compared to KRG1. Since KRG1 does not gen-
erate, there is no ?g+?.
Table 6: Evaluation
coverage (%) ambiguity
p p+ g s p g
kpsg 77.0 -5.5 55.2 42.5 174.9 144.4
ibkg 61.2 41.8 68.3 41.8 990.5 303.5
seri 71.3 -0.8 65.7 46.8 289.1 128.4
b-k 43.0 32.6 62.8 27.0 1769.4 90.0
b-c 52.2 45.8 59.4 31.0 1175.8 160.6
sj-ke 35.4 31.2 58.2 20.6 358.3 170.3
sj-kj 23.0 19.6 52.2 12.0 585.9 294.9
dic-ke 40.4 31.0 42.6 17.2 1392.7 215.9
dic-kj 34.8 25.2 67.8 23.6 789.3 277.9
avr 48.7 24.5 59.1 28.8 836.2 198.4
On average, the parsing coverage increases
24.5%. The reason why there are negative val-
ues in ?p+? of kpsg and seri is that we discarded
some modules that run counter efficient process-
ing (e.g., the grammar module for handling float-
ing quantifiers sometimes produces too many
ambiguities.). Since KRG1 has been constructed
largely around the test sets, we expected it to
perform well here. If we measure the parsing
coverage again, after excluding the results of
kpsg and seri, it accounts for 32.5%.4 The gen-
eration coverage of KRG2 accounts for almost
60% per parsed sentence on average. Note that
KRG1 could not parse at all. ?s? (short for ?suc-
cess?) means the portion of both parsed and gen-
erated sentences (i.e. ?p???g?), which accounts
4The running times, meanwhile, becomes slower as we
would expect for a grammar with greater coverage. How-
ever, we can make up for it using the PET parser, as shown
in Figure 9.
150
 
0 
10 
20 
30 
40 
50 
60 
70 
80 
90 
KRG1 base lex MRS irules KRG2
%
kpsg
ibkg
seri
b-k
b-c
sj-ke
sj-kj
dic-ke
dic-kj
Figure 7: Parsing Coverage (%)
 
0 
10 
20 
30 
40 
50 
60 
70 
80 
90 
base lex MRS irules KRG2
%
kpsg
ibkg
seri
b-k
b-c
sj-ke
sj-kj
dic-ke
dic-kj
Figure 8: Generation Coverage (%)
for about 29%. Ambiguity means ?# of parses/#
of sentences? for parsing and ?# of realizations/#
of MRSes? for generation. The numbers look
rather big, which should be narrowed down in
our future study.
In addition, we can find out in Table 6 that
there is a coverage ordering with respect to the
type of test suites; ?test sets > BTEC > dic >
SBC?. It is influenced by three factors; (i) lexi-
cal variety, (ii) sentence length, and (iii) text do-
main. This difference implies that it is highly
necessary to use variegated texts in order to im-
prove grammar in a comprehensive way.
Figure 7 to 10 represent how much each exper-
iment in ?5.3 contributes to improvement. First,
let us see Figure 7 and 8. As we anticipated,
lex and irules contribute greatly to the growth of
parsing coverage. In particular, the line of b-c in
Figure 8, which mostly consists of spoken forms,
rises rapidly in irules and KRG2. That implies
Korean parsing largely depends on richness of
lexical rules. On the other hand, as we also ex-
pected, MRS makes a great contribution to gen-
eration coverage (Figure 8). In MRS, the growth
accounts for 22% on average. That implies test-
ing with large corpora must take precedence in
order for coverage to grow.
Figure 9 and 10 shows performance in pars-
ing and generation, respectively. Comparing to
KRG1, our Matrix-based grammars (from base
 
0.0 
5.0 
10.0 
15.0 
20.0 
25.0 
KRG1 base lex MRS irules KRG2
sec.
kpsg
ibkg
seri
b-k
b-c
sj-ke
sj-kj
dic-ke
dic-kj
Figure 9: Parsing Performance (s)
 
0.0 
5.0 
10.0 
15.0 
20.0 
25.0 
base lex MRS irules KRG2
sec.
kpsg
ibkg
seri
b-k
b-c
sj-ke
sj-kj
dic-ke
dic-kj
Figure 10: Generation Performance (s)
to KRG2) yields fairly good performance. It is
mainly because we deployed the PET parser that
runs fast, whereas KRG1 runs only on LKB. Fig-
ure 10, on the other hand, shows that the revi-
sion of MRS also does much to enhance gen-
eration performance, in common with coverage
mentioned before. It decreases the running times
by about 3.1 seconds on average.
6 Conclusion
The newly developed KRG2 has been success-
fully included in the LOGON repository since
July, 2009; thus, it is readily available. In fu-
ture research, we plan to apply the grammar in
an MT system (for which we already have a
prototype). In order to achieve this goal, we
need to construct multilingual treebanks; Korean
(KRG), English (ERG), and Japanese (Jacy).
Acknowledgments
We thank Emily M. Bender, Dan Flickinger,
Jae-Woong Choe, Kiyotaka Uchimoto, Eric
Nichols, Darren Scott Appling, and Stephan
Oepen for comments and suggestions at vari-
ous stages. Parts of this research was conducted
while the first and third authors were at the Na-
tional Institute for Information and Communi-
cations Technologies (NICT), Japan; we thank
NICT for their support. Our thanks also go to
three anonymous reviewers for helpful feedback.
151
References
Bender, Emily M., Dan Flickinger, and Stephan
Oepen. 2002. The Grammar Matrix: An Open-
Source Starter-Kit for the Rapid Development of
Cross-Linguistically Consistent Broad-Coverage
Precision Grammars. In Procedings of the Work-
shop on Grammar Engineering and Evaluation at
the 19th International Conference on Computa-
tional Linguistics.
Bender, Emily M., Scott Drellishak, Antske Fokkens,
Michael Wayne Goodman, Daniel P. Mills, Laurie
Poulson, and Safiyyah Saleem. 2010. Grammar
Prototyping and Testing with the LinGO Grammar
Matrix Customization System. In Proceedings of
ACL 2010 Software Demonstrations.
Bond, Francis, Stephan Oepen, Melanie Siegel, Ann
Copestake, and Dan Flickinger. 2005. Open
Source Machine Translation with DELPH-IN. In
Proceedings of Open-Source Machine Transla-
tion: Workshop at MT Summit X.
Bond, Francis, Eric Nichols, Darren Scott Appling,
and Michael Paul. 2008. Improving Statistical
Machine Translation by Paraphrasing the Train-
ing Data. In Proceedings of the 5th International
Workshop on Spoken Languaeg Translation.
Callmeier, Ulrich. 2000. PET?a Platform for Exper-
imentation with Efficient HPSG Processing Tech-
niques. Natural Language Engineering, 6(1):99?
107.
Chang, Suk-Jin. 1995. Information-based Korean
Grammar. Hanshin Publishing, Seoul.
Copestake, Ann, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal Recursion Seman-
tics: An Introduction. Research on Language and
Computation, 3(4):281?332.
Flickinger, Dan. 2000. On Building a More Efficient
Grammar by Exploiting Types. Natural Language
Engineering, 6 (1) (Special Issue on Efficient Pro-
cessing with HPSG):15 ? 28.
Kikui, Genichiro, Eiichiro Sumita, Toshiyuki
Takezawa, and Seiichi Yamamoto. 2003. Creating
corpora for speech-to-speech translation. In Proc.
of the EUROSPEECH03, pages 381?384, Geneve,
Switzerland.
Kim, Se-jung and Nam-ho Cho. 2001. The progress
and prospect of the 21st century Sejong project. In
ICCPOL-2001, pages 9?12, Seoul.
Kim, Jong-Bok and Jaehyung Yang. 2003. Ko-
rean Phrase Structure Grammar and Its Implemen-
tations into the LKB System. In Proceedings of
the 17th Pacific Asia Conference on Language, In-
formation and Computation.
Kim, Jong-Bok and Jaehyung Yang. 2004. Projec-
tions from Morphology to Syntax in the Korean
Resource Grammar: Implementing Typed Feature
Structures. In Lecture Notes in Computer Science,
volume 2945, pages 13?24. Springer-Verlag.
Kim, Jong-Bok. 2004. Korean Phrase Structure
Grammar. Hankwuk Publishing, Seoul.
Oepen, Stephan. 2001. [incr tsdb()] ? competence
and performance laboratory. User manual. Tech-
nical report, Computational Linguistics, Saarland
University.
Pollard, Carl and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. The University of
Chicago Press, Chicago, IL.
Sag, Ivan A., Thomas Wasow, , and Emily M. Bender.
2003. Syntactic Theory: A Formal Introduction.
CSLI Publications, Stanford, CA.
Siegel, Melanie and Emily M. Bender. 2002. Effi-
cient Deep Processing of Japanese. In Proceed-
ings of the 3rd Workshop on Asian Language Re-
sources and International Standardization.
Song, Sanghoun and Jae-Woong Choe. 2008.
Automatic Construction of Korean Verbal Type
Hierarchy using Treebank. In Proceedings of
HPSG2008.
Song, Sanghoun. 2007. A Constraint-based Analysis
of Passive Constructions in Korean. Master?s the-
sis, Korea University, Department of Linguistics.
Sung, Won-Kyung and Myung-Gil Jang. 1997. SERI
Test Suites ?95. In Proceedings of the Confer-
ence on Hanguel and Korean Language Informa-
tion Processing.
152
