R. Dale et al (Eds.): IJCNLP 2005, LNAI 3651, pp. 177 ? 187, 2005. 
? Springer-Verlag Berlin Heidelberg 2005 
Linguistically-Motivated Grammar Extraction, 
Generalization and Adaptation 
Yu-Ming Hsieh, Duen-Chi Yang, and Keh-Jiann Chen 
Institute of Information Science, Academia Sinica, Taipei 
{morris, ydc, kchen}@iis.sinica.edu.tw 
Abstract. In order to obtain a high precision and high coverage grammar, we 
proposed a model to measure grammar coverage and designed a PCFG parser to 
measure efficiency of the grammar. To generalize grammars, a grammar binari-
zation method was proposed to increase the coverage of a probabilistic context-
free grammar. In the mean time linguistically-motivated feature constraints 
were added into grammar rules to maintain precision of the grammar. The gen-
eralized grammar increases grammar coverage from 93% to 99% and bracket-
ing F-score from 87% to 91% in parsing Chinese sentences. To cope with error 
propagations due to word segmentation and part-of-speech tagging errors, we 
also proposed a grammar blending method to adapt to such errors. The blended 
grammar can reduce about 20~30% of parsing errors due to error assignment of 
pos made by a word segmentation system.  
Keywords: Grammar Coverage, Ambiguity, Sentence Parsing, Grammar  
Extraction. 
1   Introduction 
Treebanks provide instances of phrasal structures and their statistical distributions. 
However none of treebanks provide sufficient amount of samples which cover all types 
of phrasal structures, in particular, for the languages without inflectional markers, such 
as Chinese. It results that grammars directly extracted from treebanks suffer low cover-
age rate and low precision [7]. However arbitrarily generalizing applicable rule patterns 
may cause over-generation and increase ambiguities. It may not improve parsing per-
formance [7]. Therefore a new approach of grammar binarization was proposed in this 
paper. The binarized grammars were derived from probabilistic context-free grammars 
(PCFG) by rule binarization. The approach was motivated by the linguistic fact that 
adjuncts could be arbitrarily occurred or not occurred in a phrase. The binarized gram-
mars have better coverage than the original grammars directly extracted from treebank. 
However they also suffer problems of over-generation and structure-ambiguity. Con-
temporary grammar formalisms, such as GPSG, LFG, HPSG, take phrase structure rules 
as backbone for phrase structure representation and adding feature constraints to elimi-
nate illegal or non-logical structures. In order to achieve higher coverage, the backbone 
grammar rules (syntactic grammar) are allowed to be over-generation and the feature 
constraints (semantic grammar for world knowledge) eliminate superfluous structures 
178 Y.-M. Hsieh, D.-C. Yang, and K.-J. Chen 
and increase the precision of grammar representation. Recently, probabilistic prefer-
ences for grammar rules were incorporated to resolve structure-ambiguities and had 
great improvements on parsing performances [2, 6, 10]. Regarding feature constrains, it 
was shown that contexture information of categories of neighboring nodes, mother 
nodes, or head words are useful for improving grammar precision and parsing perform-
ances [1, 2, 7, 10, 12]. However tradeoffs between grammar coverage and grammar 
precision are always inevitable. Excessive grammatical constraints will reduce grammar 
coverage and hence reduce parsing performances. On the other hand, loosely con-
strained grammars cause structure-ambiguities and also reduce parsing performances. In 
this paper, we consider grammar optimization in particular for Chinese language. Lin-
guistically-motivated feature constraints were added to the grammar rules and evaluated 
to maintain both grammar coverage and precision. In section 2, the experimental envi-
ronments were introduced. Grammar generalization and specialization methods were 
discussed in section 3. Grammars adapting to pos-tagging errors were discussed in sec-
tion 4. Conclusions and future researches were stated in the last section. 
2   Research Environments 
The complete research environment, as shown in the figure 1, comprises of the fol-
lowing five modules and functions. 
a) Word segmentation module: identify words including out-of-vocabulary word 
and provide their syntactic categories. 
b) Grammar construction module: extract and derive (perform rule generalization, 
specialization and adaptation processes) probabilistic grammars from tree-
banks. 
c) PCFG parser: parse input sentences. 
d) Evaluation module: evaluate performances of parsers and grammars. 
e) Semantic role assignment module: resolve semantic relations for constituents. 
 
Fig. 1. The system diagram of CKIP parsing environment 
 Linguistically-Motivated Grammar Extraction, Generalization and Adaptation 179 
2.1   Grammar Extraction Module  
Grammars are extracted from Sinica Treebank [4, 5]. Sinica Treebank version 2.0 
contains 38,944 tree-structures and 230,979 words. It provides instances of phrasal 
structures and their statistical distributions. In Sinica Treebank, each sentence is anno-
tated with its syntactic structure and semantic roles for constituents in a dependency 
framework. Figure 2 is an example. 
e.g. ? ? ?? ? ?. 
 Ta  jiao  Li-si  jian  qiu. 
 ?He asked Lisi to pick up the ball.? 
Tree-structure:  
S(agent:NP(Head:Nh:?)|Head:VF:?|goal:NP(Head:Nb:??)|theme:VP(Head:VC:?| 
goal:NP(Head:Na:?))) 
Fig. 2. A sample tree-structure 
Since the Treebank cannot provide sufficient amount of samples which cover all 
types of phrasal structures, it results that grammars directly extracted from treebanks 
suffer low coverage rate [5]. Therefore grammar generalization and specialization 
processes are carried out to obtain grammars with better coverage and precision. The 
detail processes will be discussed in section 3. 
2.2   PCFG Parser and Grammar Performance Evaluation 
The probabilistic context-free parsing strategies were used as our parsing model [2, 6, 
8]. Calculating probabilities of rules from a treebank is straightforward and we use 
maximum likelihood estimation to estimate the rule probabilities, as in [2]. The parser 
adopts an Earley?s Algorithm [8]. It is a top-down left-to-right algorithm. The results 
of binary structures will be normalized into a regular phrase structures by removing 
intermediate nodes, if used grammars are binarized grammars. Grammar efficiency 
will be evaluated according to its parsing performance. 
2.3   Experiments and Performance Evaluation 
Three sets of testing data were used in our performance evaluation. Their basic statis-
tics are shown in Table 1. Each set of testing data represents easy, hard and moderate 
respectively.  
Table 1. Three sets of testing data were used in our experiments 
Testing data Sources hardness
# of short 
sentence 
(1-5 words) 
# of normal 
sentences 
(6-10 words)
# of long 
sentences 
(>11 words) 
Total 
sentences 
Sinica Balanced corpus moderate 612 385 124 1,121 
Sinorama Magazine harder 428 424 104 956 
Textbook Elementary school easy 1,159 566 25 1,750 
180 Y.-M. Hsieh, D.-C. Yang, and K.-J. Chen 
The following parser and grammar performance evaluation indicators were used in 
our experiments: 
z LP(Labeled Precision) 
parser by the labeled phrases of #
parser by the labeled phrasescorrect  of #LP =  
z LR(Labeled Recall) 
data  testing thein phrases of #
parser by the labeled phrasescorrect  of #LR =  
z LF(Labeled F-measure) 
LR  LP
2* LR * LPLF
+
=
 
z BP(Bracketed Precision) 
parser by the made brackets of pairs of #
parser by the madecorrectly  brackets of pairs of #BP =  
z BR(Bracketed Recall) 
data  testing theof standard gold  thein brackets of pairs of #
parser by the madecorrectly  brackets of pairs of #BR =  
z BF(Bracketed F-measure) 
BR  BP
2* BR * BPBF
+
=
 
Additional indicators regarding coverage of grammars?  
z RC-Type?type coverage of rules 
data  testingin  typesrule of #
rulesgrammar  anddata   testingboth in  typesrules of #Type-RC =
 
z RC-Token?token coverage of rules 
data  testingin  tokensrule of #
rulesgrammar  anddata   testingboth in  tokensrules of #Token-RC =
 
The token coverage of a set of rules is the ceiling of parsing algorithm to achieve. 
Tradeoff effects between grammar coverage and parsing F-score can be examined for 
each set of rules. 
3   Grammar Generalization and Specialization 
By using above mentioned research environment, we intend to find out most effec-
tive grammar generalization method and specialization features for Chinese lan-
guage. To extend an existing or extracted grammar, there are several different ap-
proaches. A na?ve approach is to generalize a fine-grained rule to a coarse-grained 
rule. The approach does not generate new patterns. Only the applicable patterns for 
each word were increased. However it was shown that arbitrarily increasing the 
applicable rule patterns does increase the coverage rates of grammars, but degrade 
parsing performance [5]. A better approach is to generalizing and specializing rules 
under linguistically-motivated way. 
 Linguistically-Motivated Grammar Extraction, Generalization and Adaptation 181 
3.1   Binary Grammar Generation, Generalization, and Specialization 
The length of a phrase in Treebank is variable and usually long phrases suffer from 
low probability. Therefore most PCFG approaches adopt the binary equivalence 
grammar, such as Chomsky normal form (CNF). For instance, a grammar rule of S? 
NP Pp Adv V can be replaced by the set of equivalent rules of {S?Np R0, R0?Pp 
R1, R1?Adv V}. The binarization method proposed in our system is different from 
CNF. It generalizes the original grammar to broader coverage. For instance, the above 
rule after performing right-association binarization 1  will produce following three 
binary rules {S?Np S?, S??Pp S?, S??Adv V}. It results that constituents (adjuncts 
and arguments) can be occurred or not occurred at almost any place in the phrase. It 
partially fulfilled the linguistic fact that adjuncts in a phrase are arbitrarily occurred. 
However it also violated the fact that arguments do not arbitrarily occur. Experimental 
results of the Sinica testing data showed that the grammar token coverage increased 
from 92.8% to 99.4%, but the labeling F-score dropped from 82.43% to 82.11% [7]. 
Therefore feature constraints were added into binary rules to limit over-generation 
caused by recursively adding constituents into intermediate-phrase types, such as S? at 
above example. 
Feature attached rules will look like following: 
S?
-left:Adv-head:V? Adv V; 
S?
-left:Pp-head:V?Pp S?-left:Adv-head:V; 
The intermediated node S?
-left:Pp-head:V says that it is a partial S structure with left-
most constituent Pp and a phrasal head V. Here the leftmost feature constraints linear 
order of constituents and the head feature implies that the structure patterns are head 
word dependent. Both constraints are linguistically plausible. Another advantage of 
the feature-constraint binary grammar is that in addition to rule probability it is easy 
to implement association strength of modifier word and head word to evaluate plausi-
bility of derived structures. 
3.2   Feature Constraints for Reducing Ambiguities of Generalized Grammars 
Adding feature constraints into grammar rules attempts to increase precision of gram-
mar representation. However the side-effect is that it also reduces grammar coverage. 
Therefore grammar design is balanced between its precision and coverage. We are 
looking for a grammar with highest coverage and precision. The tradeoff depends on 
the ambiguity resolution power of adopted parser. If the ambiguity resolution power 
of adopted parser is strong and robust, the grammar coverage might be more impor-
tant than grammar precision. On the other hand a weak parser had better to use 
grammars with more feature constraints. In our experiments, we consider grammars 
suited for PCFG parsing. The follows are some of the most important linguistically-
motivated features which have been tested. 
                                                          
1
 The reason for using right-association binarization instead of left-association or head-first 
association binarization is that our parsing process is from left to right. It turns out that pars-
ing speed of right associated grammars is much faster than left-associated grammars for left-
to-right parsing. 
182 Y.-M. Hsieh, D.-C. Yang, and K.-J. Chen 
Head (Head feature): Pos of phrasal head will propagate to all intermediate nodes 
within the constituent. 
Example:S(NP(Head:Nh:?)|S?
-VF(Head:VF:?|S?-VF(NP(Head:Nb:??)| 
VP(Head:VC:?| NP(Head:Na:?))))) 
Linguistic motivations: Constrain sub-categorization frame. 
Left (Leftmost feature): The pos of the leftmost constitute will propagate one?level to 
its intermediate mother-node only. 
Example:S(NP(Head:Nh:?)|S?
-Head:VF(Head:VF:?|S?-NP(NP(Head:Nb:??)| 
VP(Head:VC:?| NP(Head:Na:?))))) 
Linguistic motivation: Constraint linear order of constituents. 
Mother (Mother-node): The pos of mother-node assigns to all daughter nodes. 
Example:S(NP
-S(Head:Nh:?)|S?(Head:VF:?|S?(NP-S(Head:Nb:??)|VP-S(Head:VC:
?| NP
-VP(Head:Na: ? ))))) 
Linguistic motivation: Constraint syntactic structures for daughter nodes. 
Head0/1 (Existence of phrasal head): If phrasal head exists in intermediate node, the 
nodes will be marked with feature 1; otherwise 0. 
Example:S(NP(Head:Nh:? )|S?
-1(Head:VF:? |S?-0(NP(Head:Nb:?? )|VP(Head:VC:
?| NP(Head:Na: ? ))))) 
Linguistic motivation: Enforce unique phrasal head in each phrase. 
Table 2. Performance evaluations for different features 
(a)Binary rules without features (b)Binary+Left 
 Sinica Snorama Textbook Sinica Sinorama Textbook 
RC-Type 95.632 94.026 94.479 95.074 93.823 94.464 
RC-Token 99.422 99.139 99.417 99.012 98.756 99.179 
LP 81.51 77.45 84.42 86.27 80.28 86.67 
LR 82.73 77.03 85.09 86.18 80.00 87.23 
LF 82.11 77.24 84.75 86.22 80.14 86.94 
BP 87.73 85.31 89.66 90.43 86.71 90.84 
BR 89.16 84.91 90.52 90.46 86.41 91.57 
BF 88.44 85.11 90.09 90.45 86.56 91.20 
(c)Binary+Head (d)Binary+Mother 
 Sinica Snorama Textbook Sinica Sinorama Textbook 
RC-Type 94.595 93.474 94.480 94.737 94.082 92.985 
RC-Token 98.919 98.740 99.215 98.919 98.628 98.857 
LP 83.68 77.96 85.52 81.87 78.00 83.77 
LR 83.75 77.83 86.10 82.83 76.95 84.58 
LF 83.71 77.90 85.81 82.35 77.47 84.17 
BP 89.49 85.29 90.17 87.85 85.44 88.47 
BR 89.59 85.15 90.91 88.84 84.66 89.57 
BF 89.54 85.22 90.54 88.34 85.05 89.01 
 Linguistically-Motivated Grammar Extraction, Generalization and Adaptation 183 
Each set of feature constraint added grammar is tested and evaluated. Table 2 
shows the experimental results. Since all features have their own linguistic motiva-
tions, the result feature constrained grammars maintain high coverage and have im-
proving grammar precision. Therefore each feature more or less improves the parsing 
performance and the feature of leftmost daughter node, which constrains the linear 
order of constituents, is the most effective feature. The Left-constraint-added gram-
mar reduces grammar token-coverage very little and significantly increases label and 
bracket f-scores. 
It is shown that all linguistically-motivated features are more or less effective. The 
leftmost constitute feature, which constraints linear order of constituents, is the most 
effective feature. The mother-node feature is the least effective feature, since syntactic 
structures do not vary too much for each phrase type while playing different gram-
matical functions in Chinese. 
Table 3. Performances of grammars with different feature combinations 
(a) Binary+Left+Head1/0 (b) Binary+Left+Head 
 Sinica Sinorama Textbook Sinica Sinorama Textbook 
RC-Type 94.887 93.745 94.381 92.879 91.853 92.324 
RC-Token 98.975 98.740 99.167 98.173 98.022 98.608 
LF 86.54 79.81 87.68 86.00 79.53 86.86 
BF 90.69 86.16 91.39 90.10 86.06 90.91 
LF-1 86.71 79.98 87.73 86.76 79.86 87.16 
BF-1 90.86 86.34 91.45 90.89 86.42 91.22 
Table 4. Performances of the grammar with most feature constraints 
Binary+Left+Head+Mother+Head1/0  
Sinica Sinorama Textbook 
RC-Type 90.709 90.460 90.538 
RC-Token 96.906 96.698 97.643 
LF 86.75 78.38 86.19 
BF 90.54 85.20 90.07 
LF-1 88.56 79.55 87.84 
BF-1 92.44 86.46 91.80 
Since all the above features are effective, we like to see the results of multi-feature 
combinations. Many different feature combinations were tested. The experimental 
results show that none of the feature combinations outperform the binary grammars 
with Left and Head1/0 features, even the grammar combining all features, as shown in 
the Table 3 and 4. Here LF-1 and BF-1 measure the label and bracket f-scores only on 
the sentences with parsing results (i.e. sentences failed of producing parsing results 
are ignored). The results show that grammar with all feature constraints has better LF-
1 and BF-1 scores, since the grammar has higher precision. However the total per-
formances, i.e. Lf and BF scores, are not better than the simpler grammar with feature 
184 Y.-M. Hsieh, D.-C. Yang, and K.-J. Chen 
constraints of Left and Head1/0, since the higher precision grammar losses slight edge 
on the grammar coverage. The result clearly shows that tradeoffs do exist between 
grammar precision and coverage. It also suggests that if a feature constraint can im-
prove grammar precision a lot but also reduce grammar coverage a lot, it is better to 
treat such feature constraints as a soft constraint instead of hard constraint. Probabilis-
tic preference for such feature parameters will be a possible implementation of soft 
constraint.  
3.3   Discussions 
Feature constraints impose additional constraints between constituents for phrase 
structures. However different feature constraints serve for different functions and 
have different feature assignment principles. Some features serve for local constraints, 
such as Left, Head, and Head0/1. Those features are only assigned at local intermedi-
ate nodes. Some features are designed for external effect such as Mother Feature, 
which is assigned to phrase nodes and their daughter intermediate nodes. For in-
stances, NP structures for subject usually are different from NP structures for object 
in English sentences [10]. NP attached with Mother-feature can make the difference. 
NPS rules and NPVP rules will be derived each respectively from subject NP and ob-
ject NP structures. However such difference seems not very significant in Chinese. 
Therefore feature selection and assignment should be linguistically-motivated as 
shown in our experiments. 
In conclusion, linguistically-motivated features have better effects on parsing per-
formances than arbitrarily selected features, since they increase grammar precision, 
but only reduce grammar coverage slightly. The feature of leftmost daughter, which 
constraints linear order of constituents, is the most effective feature for parsing. Other 
sub-categorization related features, such as mother node and head features, do not 
contribute parsing F-scores very much. Such features might be useful for purpose of 
sentence generation instead of parsing. 
4   Adapt to Pos Errors Due to Automatic Pos Tagging 
Perfect testing data was used for the above experiments without considering word 
segmentation and pos tagging errors. However in real life word segmentation and pos 
tagging errors will degenerate parsing performances. The real parsing performances 
of accepting input from automatic word segmentation and pos tagging system are 
shown in the Table 5. 
Table 5. Parsing performances of inputs produced by the automatic word segmentation and  
pos tagging 
Binary+Left+Head1/0  
Sinica Sinorama Textbook 
LF 76.18 64.53 73.61 
BF 84.01 75.95 84.28 
 Linguistically-Motivated Grammar Extraction, Generalization and Adaptation 185 
The na?ve approach to overcome the pos tagging errors was to delay some of the 
ambiguous pos resolution for words with lower confidence tagging scores and leave 
parser to resolve the ambiguous pos until parsing stage. The tagging confidence of 
each word is measured by the following value. 
Confidence value= 
)c(P)c(P
)c(P
w,2w,1
w,1
+
, where P(c1,w) and P(c2,w) are probabilities  
assigned by the tagging model for the best candidate c1,w and the second best candi-
date c2,w. 
The experimental results, Table 6, show that delaying ambiguous pos resolution 
does not improve parsing performances, since pos ambiguities increase structure am-
biguities and the parser is not robust enough to select the best tagging sequence.  The 
higher confidence values mean that more words with lower confidence tagging will 
leave ambiguous pos tags and the results show the worse performances. Charniak et al
[3] experimented with using multiple tags per word as input to a treebank parser, and 
came to a similar conclusion. 
Table 6. Parsing performances for different confidence level of pos ambiguities 
Confidence value=0.5  
Sinica Sinorama Textbook 
LF 75.92 64.14 74.66 
BF 83.48 75.22 83.65 
Confidence value=0.8  
Sinica Sinorama Textbook 
LF 75.37 63.17 73.76 
BF 83.32 74.50 83.33 
Confidence value=1.0  
Sinica Sinorama Textbook 
LF 74.12 61.25 69.44 
BF 82.57 73.17 81.17 
4.1   Blending Grammars 
A new approach of grammar blending method was proposed to cope with pos tagging 
errors. The idea is to blend the original grammar with a newly extracted grammar 
derived from the Treebank in which pos categories are tagged by the automatic pos 
tagger. The blended grammars contain the original rules and the extended rules due to 
pos tagging errors. A 5-fold cross-validation was applied on the testing data to tune 
the blending weight between the original grammar and the error-adapted grammar. 
The experimental results show that the blended grammar of weights 8:2 between the 
original grammar and error-adapted grammar achieves the best results. It reduces 
about 20%~30% parsing errors due to pos tagging errors, shown in the Table 7. The 
pure error-adapted grammar, i.e. 0:10 blending weight, does not improve the parsing 
performance very much 
186 Y.-M. Hsieh, D.-C. Yang, and K.-J. Chen 
Table 7. Performances of the blended grammars 
Error-adapted grammar i.e. 
blending weight (0:10) 
Blending weight 8:2  
Sinica Sinirama Textbook Sinica Sinirama Textbook 
LF 75.99 66.16 71.92 78.04 66.49 74.69 
BF 85.65 77.89 85.04 86.06 77.82 85.91 
5   Conclusion and Future Researches 
In order to obtain a high precision and high coverage grammar, we proposed a model 
to measure grammar coverage and designed a PCFG parser to measure efficiency of 
the grammar. Grammar binarization method was proposed to generalize rules and to 
increase the coverage of context-free grammars. Linguistically-motivated feature 
constraints were added into grammar rules to maintain grammar rule precision. It is 
shown that the feature of leftmost daughter, which constraints linear order of constitu-
ents, is the most effective feature. Other sub-categorization related features, such as 
mother node and head features, do not contribute parsing F-scores very much. Such 
features might be very useful for purpose of sentence generation instead of parsing. 
The best performed feature constraint binarized grammar increases the grammar cov-
erage of the original grammar from 93% to 99% and bracketing F-score from 87% to 
91% in parsing moderate hard testing data. To cope with error propagations due to 
word segmentation and part-of-speech tagging errors, a grammar blending method 
was proposed to adapt to such errors. The blended grammar can reduce about 20~30% 
of parsing errors due to error assignment of a pos tagging system.  
In the future, we will study more effective way to resolve structure ambiguities. In 
particular, consider the tradeoff effect between grammar coverage and precision. The 
balance between soft constraints and hard constraints will be focus of our future re-
searches. In addition to rule probability, word association probability will be another 
preference measure to resolve structure ambiguity, in particular for conjunctive  
structures.  
Acknowledgement 
This research was supported in part by National Science Council under a Center Ex-
cellence Grant NSC 93-2752-E-001-001-PAE and National Digital Archives Program 
Grant NSC93-2422-H-001-0004.  
References 
1. E. Charniak, and G. Carroll, ?Context-sensitive statistics for improved grammatical lan-
guage models.? In Proceedings of the 12th National Conference on Artificial Intelligence, 
AAAI Press, pp. 742-747, Seattle, WA, 1994, 
2. E. Charniak, ?Treebank grammars.? In Proceedings of the Thirteenth National Conference 
on Artificial Intelligence, pp. 1031-1036. AAAI Press/MIT Press, 1996. 
 Linguistically-Motivated Grammar Extraction, Generalization and Adaptation 187 
3. E. Charniak, and G. Carroll, J. Adcock, A. Cassanda, Y. Gotoh, J. Katz, M. Littman, J. 
Mccann, "Taggers for Parsers", Artificial Intelligence, vol. 85, num. 1-2, 1996. 
4. Feng-Yi Chen, Pi-Fang Tsai, Keh-Jiann Chen, and Huang, Chu-Ren, ?Sinica Treebank.? 
Computational Linguistics and Chinese Language Processing, 4(2):87-103, 2000. 
5. Keh-Jiann Chen and, Yu-Ming Hsieh, ?Chinese Treebanks and Grammar Extraction.? the 
First International Joint Conference on Natural Language Processing (IJCNLP-04), March 
2004. 
6. Michael Collins, ?Head-Driven Statistical Models for Natural Language parsing.? Ph.D. 
thesis, Univ. of Pennsylvania, 1999. 
7. Yu-Ming Hsieh, Duen-Chi Yang and Keh-Jiann Chen, ?Grammar extraction, generaliza-
tion and specialization. ( in Chinese)?Proceedings of ROCLING 2004. 
8. Christopher D. Manning and Hinrich Schutze, ?Foundations of Statistical Natural Lan-
guage Processing.? the MIT Press, Cambridge, Massachusetts, 1999. 
9. Mark Johnson, ?PCFG models of linguistic tree representations.? Computational Linguis-
tics, Vol.24, pp.613-632, 1998. 
10. Dan Klein and Christopher D. Manning, ?Accurate Unlexicalized Parsing.? Proceeding of 
the 4lst Annual Meeting of the Association for Computational Linguistics, pp. 423-430, 
July 2003. 
11. Honglin Sun and Daniel Jurafsky, ?Shallow Semantic Parsing of Chinese.? Proceedings of 
NAACL 2004. 
12. 12.Hao Zhang, Qun Liu, Kevin Zhang, Gang Zou and Shuo Bai, ?Statistical Chinese 
Parser ICTPROP.? Technology Report, Institute of Computing Technology, 2003. 
 
Resolving Ambiguities of Chinese Conjunctive Structures by Divide-
and-conquer Approaches 
Duen-Chi Yang, Yu-Ming Hsieh, Keh-Jiann Chen  
Institute of Information Science, Academia Sinica, Taipei 
{ydc, morris, kchen}@iis.sinica.edu.tw 
 
 
Abstract 
This paper presents a method to enhance a 
Chinese parser in parsing conjunctive 
structures. Long conjunctive structures 
cause long-distance dependencies and tre-
mendous syntactic ambiguities. Pure syn-
tactic approaches hardly can determine 
boundaries of conjunctive phrases properly. 
In this paper, we propose a divide-and-
conquer approach which overcomes the dif-
ficulty of data-sparseness of the training 
data and uses both syntactic symmetry and 
semantic reasonableness to evaluate am-
biguous conjunctive structures. In compar-
ing with the performances of the PCFG 
parser without using the divide-and-
conquer approach, the precision of the con-
junctive boundary detection is improved 
from 53.47% to 83.17%, and the bracketing 
f-score of sentences with conjunctive struc-
tures is raised up about 11 %. 
1 Introduction 
Parsing a sentence with long conjunctive structure 
is difficult, since it is inadequate for a context-free 
grammar to represent context-sensitive-like coordi-
nation structures, such as ?a b c? and a? b? c?? ?.  
It causes long-distance dependencies and tremen-
dous syntactic ambiguities (a large number of al-
ternatives). Pure syntactic approaches cannot de-
termine boundaries of conjunctive phrases properly. 
It is obvious that both syntactic and semantic in-
formation are necessary for resolving ambiguous 
boundaries of conjunctive structures. 
Some analysis methods of the detection of con-
junctive structures have been studied for a while. 
Despite of using different resources and tools, these 
methods mainly make use of the similarity of 
words or word categories on both sides of conjunc-
tive structure (Agarwal et al, 1992; Kurohashi et 
al., 1994; Delden, 2002; Steiner 2003). They as-
sumed that two sides of conjuncts should have 
similar syntactic and semantic structures. Some 
papers also suggest that certain key word patterns 
can be used to decide the boundaries (Wu 2003). 
Agarwal et al (1992) used a semantic tagger and a 
syntactic chunker to label syntactic and semantic 
chunks. And then they defined multi-level (cate-
gory to category or semantic type to semantic type) 
similarity matching to find the structure boundaries. 
Delden (2002) included semantic analysis by 
applying WordNet (Miller 1993) information. 
These presented methods used similarity measures 
heuristically according to the property of the lan-
guages. However detecting conjunctive boundaries 
with a similar method in Chinese may meet some 
problems, since a Chinese word may play different 
syntactic functions without inflection. It results that 
syntactic symmetry is not enough to resolve ambi-
guities of conjunctive structures and semantic rea-
sonableness is hard to be evaluated. Therefore we 
propose a divide-and-conquer approach which 
takes the advantage of using structure information 
of partial sentences located at both sides of con-
junction. Furthermore we believe that simple cases 
can be solved by simple methods which are effi-
cient and only complex cases require deep syntac-
tic and semantic analysis. Therefore we develop an 
algorithm to discriminate simple cases and com-
plex cases first. We then use a sophisticated algo-
rithm to handle complex cases only.  
For simple cases, we use conventional pattern 
matching approach to speedup process. For com-
plex conjunctive structures, we propose a divide-
and-conquer approach to resolve the problem. An 
input sentence with complex conjunctive structure 
715
is first divided into two parts, one to the left of the 
conjunctive and one to the right, and then parsed 
independently to detect possible candidates of two 
conjuncts. The particular property of complex con-
junctive structures of Chinese language allows us 
to parse and to produce syntactic structures of two 
partial sentences, since according to our observa-
tions and experiments the syntactic structures of 
partial sentences at either side of a complex con-
junctive construction are grammatical most of the 
times. Figure 1 shows an instance. The parsing re-
sults not only reduce the possible ambiguous 
boundaries but also provide global structural in-
formation for checking the properness of both sides 
of conjunctive structure. Another important point 
worth mentioning is that since the size of available 
Treebank is small, a two-stage approach is pro-
posed to resolve the data sparseness problems in 
evaluating syntactic symmetry and semantic rea-
sonableness. At the first stage, a Conditional Ran-
dom Fields model is trained and used to generate a 
set of candidate boundaries. At the second stage, a 
word-association model is trained from a giga-
word corpus to evaluate the semantic properness of 
candidates. The proposed divide-and-conquer algo-
rithm avoids parsing full complex conjunctive 
structures and handles conjunctive structures with 
deep structural and semantic analysis. 
The extraction method for context-dependent 
rules is described in Section 2 and detail of the di-
vide-and-conquer approach is stated in Section 3. 
In Section 4, we introduce our experimental envi-
ronment and show the results of our experiment. 
We also make some discussions about our observa-
tions in Section 4. Finally, we offer our conclusion 
and future work in Section 5. 
2 Boundary Detection for Simple Con-
junctive Phrases 
The aim of this phase of approach is to determine if 
simple conjunctive phrases exist in input sentences 
and then identify their boundaries by matching 
context-dependent rules. To derive a set of context-
dependent rules for conjunctive phrases, a na?ve 
approach is to extract all conjunctive patterns with 
their contextual constraints from Treebank. How-
ever such a set of extracted rules suffers a low cov-
erage rate, since limited size of training data causes 
zero frequency of long n-gram PoS patterns. 
2.1 Rule extraction and generalization 
Agarwal et al, (1992), Kurohashi et al, (1994), 
and Delden (2002) had shown that the properties of 
likeness and symmetry in both syntactic types and 
lengths for example, exist in most conjunctive 
cases. Hence we use both properties as the condi-
tions in deciding boundaries of conjunctive phrases. 
When we observe Sinica Treebank (Chen et al, 
2003), we also find that this property is more obvi-
ous in simple conjunctive cases than in complex 
cases. 
First, we use a simple algorithm to detect the 
boundaries of completely symmetric conjunctive 
phrases. If PoS patterns of ?A B C and A B C? or 
?A B and A B? occurred in the input sentence, we 
consider patterns of such structures are legitimate 
conjunctive structures regardless whether the PoS 
sequences ?A B C and A B C? or ?A B and A B? 
ever occurred in the Treebank. For other cases we 
use context-dependent rule patterns to determine 
boundaries of conjunctive structures. 
Statistical context-dependent PoS-based rule pat-
terns are extracted automatically from Sinica Tree-
bank. Each rule contains the PoS pattern of a con-
junctive phrase and its left/right contextual con-
straints. The occurrence frequency of the rule and 
its correct identification rate are also associated. e.g. 
[VC] (Na Caa Nc) [DE]1 ;  12; 11 
This rule says that PoS sequence Na Caa Nc 
forms a conjunctive phrase when its left context is 
a VC and its right context is a DE. Such pattern 
occurred 12 times in the training corpus and 11 out 
of 12 times (Na Caa Nc) are correct conjunctive 
phrases. 
Context-dependent rule patterns are generated 
and generalized by the following procedure. 
Rule Generation and Generalization 
For each conjunctive structure in the Treebank, we 
consider a window pattern of at most 9 words. This 
pattern contains conjunction in the center and at 
most 4 words at each side of the conjunction. The 
PoS sequence of these 9 words forms a context-
dependent rule. For instance, the conjunctive struc-
ture shown in Figure 1 will generate the pattern (1). 
(1) [Vc DM] (VH  Na  Caa Neu Na) [DE Na] 
The long pattern has low applicability and hardly 
                                                 
1 Caa is a PoS for coordinate conjunction. Na is a common 
noun; Nc denotes place noun, and Vc is a transitive verb. DE 
denotes the relativizer ???. 
716
can evaluate its precision. Therefore a rule gener-
alization process is applied. Two kinds of generali-
zations are available. One is reducing the length of 
contextual constrains and the other is to reduce a 
fine-grained PoS constraint to a coarse-grained PoS. 
Some instances, shown in (2), are the generalized 
patterns of (1). 
(2)  [DM] (VH  Na  Caa Neu Na) [DE];1;1 
(VH  Na  Caa Neu Na); 10; 5 
[DM] (V  N  Caa N N) [DE]; 3; 2 
Then the applicability and precision of rules higher 
than threshold values will be selected. The threshold 
values for the rule selection are determined by test-
ing results on the development data. 
3 Resolution of Complex Conjunctive 
Structures 
Complex structures are cases whose boundaries can 
not be identified by the pattern matching at phase-1. 
We propose a divide-and-conquer approach to re-
solve the problem. An input sentence with complex 
conjunctive structure was first divided into two 
parts with each part containing one of the conjuncts 
and then parsed independently to produce their 
syntactic structures for detecting possible bounda-
ries of two conjuncts. Then ambiguous candidate 
structures are generated and the best conjunctive 
structure is selected by evaluating syntactic sym-
metry and semantic reasonableness of the candi-
dates. Since the two parts of the partial sentences 
are simple without conjunctive structure and nor-
mally grammatical 2 , hence they can be easily 
parsed by a PCFG parser. 
Here we illustrate the divide-and-conquer algo-
rithm by the following example. For instance, the 
example shown in Figure 1 has complex conjunc-
tive structure and it was first split into two parts (1a) 
and (1b) at conjunction marker ? ??. 
(1a) ?? if (Cbb) ? I (Nh) ?? invent (VC) ?? a 
kind (DM) ? low (VH) ?? pollution (Na) 
(1b) ? null (Neu) ?? accident (Na) ?(DE) ??
car (Na)  
The two parts of partial sentences are then 
parsed to produce their syntactic structures as 
shown in Figure 1. Then a CRF model trained from 
Sinica Treebank for checking syntactic symmetry 
                                                 
2 According to our experiments only 0.8% of the complex 
testing data and development data are failed to parse their 
partial structures at both sides of conjunction. 
was derived to pick the top-N candidates according 
to the syntactic information of both sides of partial 
sentences. Then at the second stage, a semantic 
evaluation model is proposed to select the best 
candidate. The detail of the semantic evaluation 
model is described in the section 3.2. The reason 
for using a two-stage approach is that the size of 
the Treebank is limited, but the semantic evaluation 
model requires the values of association strengths 
between words. The current Treebank cannot pro-
vide enough coverage and reliable values of word-
association strengths.  
3.1  Derive and evaluate possible candidates 
CRF is a well-known probabilistic framework for 
segmenting and labeling sequence data (Lafferty, et 
al. 2001). In our experiments, we regard the prob-
lem of boundary detection as a chunking-like prob-
lem (Lee et al, 2005). Due to this reason, we use 
CRF model to generate candidates and their ranks. 
The features used in CRF model included some 
global syntactic information, such as syntactic 
category of a partial structure and its phrasal head. 
Such global syntactic information is crucial for the 
success of boundary detection and is not available 
if without the step of parsing process. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. The syntactic structures of 5(a) and 5(b) 
produced by a PCFG parser. 
The features used are: 
WL,i ; CL,i; WR,j ; CR,j : The left(i)/right(j) most word 
and its pos category of the left/right conjunct. 
PL, ; PR,: The phrasal category of the left/right con-
junct. 
HwL ; HcL ; HwR ; HcR: The phrasal head and its pos 
category of the left/right conjunct. 
DL ; DR: The length of the left/right conjunct.  
Three types of feature patterns are used for CRF. 
The first type is feature patterns regarding individ-
WL,i+1 (WLi WL,i-1 ?.       WL1    W0   WR1 ?WR,j )WR,j+1, 
 
Some example feature values of the above hypothesis boundaries.  
WLi  = ?; CLi  =Nh; WR,j  =??; CR,j  =Na; 
PL, =S; PR, =NP; 
HwL=??; HcL= VC; HwR =??; HcR=Na; 
DL = 5; DR = 2;
717
ual conjuncts. The second type is feature patterns 
regarding symmetry between two conjuncts. The 
third type is feature patterns regarding contextual 
properness of a conjunctive structure. 
Type1: WLi, WLi-1, WLi+1, CLi, CLi-1, CLi-2, CLi-1CLi-2, CLi+1, CLi+2, 
CLi+1CLi+2, CLiCLi-1CLi-2, CLi-1CLiCLi+1, CLiCLi+1CLi+2, 
WLiHwL, CLiHcL, and WRj, WRj-1, WRj+1, CRj, CRj-1, CRj-2, CRj-
1CRj-2, CRj+1, CRj+2, CRj+1CRj+2, CRjCRj-1CRj-2, CRj-1CRjCRj+1, 
CRjCRj+1CRj+2, WRjHwR, CRjHcR.. 
Type 2: PL PR, HwLHwR, HcLHcR, DLDR. 
Type 3: WL,i+1HwRj, WR,j+1HwLi, WL,1WR,j, WR,1WL,j, 
WL,1WR,j+1, WR,1WL,j+1, WL,1WR,jWR,j+1, 
WR,1WL,iWL,i+1, WL,1WR,j-1WR,j, WR,1WL,i-1WL,i,  
CL,i-1HcRj, CR,j-1HcLi, CL,i+1HcRj, CR,j+1HcLi, 
CL,iCL,i+1HcRj, CR,jCR,j+1HcLi, CL,1CR,j, CR,1CL,j, 
CL,1CR,j+1, CR,1CL,j+1, CL,1CR,jCR,j+1, CR,1CL,iCL,i+1, 
CL,1CR,j-1CR,j, CR,1CL,i-1CL,i. 
A CRF model is trained from the Sinica Tree-
bank and estimated the probabilities of hypothesis 
conjunctive boundary pairs by the feature patterns 
listed above. The top ranked candidates are se-
lected according to the CRF model. In general, for 
further improvement, a final step of semantic 
evaluation will be performed to select the best can-
didate from top-N boundary structures ranked by 
the CRF model, which is described in the next sec-
tion.  
3.2 The word-association evaluation model 
For the purpose of selecting the best candidates of 
complex conjunctive structures, a word association 
evaluation model is adopted (Hsieh et al 2007). 
The word-to-word association data is learned 
automatically by parsing texts from the Taiwan 
Central News Agency corpus (traditional charac-
ters), which contains 735 million characters. The 
syntactically dependent words-pairs are extracted 
from the parsed trees. The word-pairs are phrasal 
heads and their arguments or modifiers. Though the 
data is imperfect (due to some errors produced by 
auto-tagging system and parser), the amount of 
data is large enough to compensate parsing errors 
and reliably exhibit strength between two 
words/concepts. 
37,489,408 sentences in CNA (Central News 
Agency) corpus are successfully parsed and the 
number of extracted word associations is 
221,482,591. The word association probabilities is 
estimated by eq.(1). 
)(
),(
)|(
Headfreq
ModifyHeadfreq
HeadModifyP =        (1) 
?freq(Head)? means Head word frequency in the 
corpus and ?freq(Head,Modify)? is the cooccur-
rence frequency of Head and Modify/Argument.  
The final evaluation is done by combining three 
scores, i.e. (1) the probability produced by PCFG 
parser, (2) the scores of CRF classifier and (3) the 
scores of semantic evaluation. The detail is de-
scribed in Section 4.2. 
4 Experiments 
3,484 sentences of the Sinica Treebank are used as 
training data. The development data and testing 
data are extracted from three different set of cor-
pora the Sinica corpus, Sinorama magazines and 
textbooks of elementary school (Hsieh et al 2005). 
They are totally 202 sentences (244 conjunctions) 
with 6-10 words and 107 sentences (159 conjunc-
tions) with more than 11 words. We only test the 
sentences which contain the coordinate conjunction 
category or categories.  
We adopt the standard PARSEVAL metrics 
(Manning et al, 1999) including bracket f-score to 
evaluate the performance of the tree structures of 
sentences and accuracies of boundary detection of 
conjunction structures. 
4.1 Phase-1 experimental results 
For the phase-1 experiments, the context-
dependent rules are extracted and generalized from 
Sinica treebank. We then use the development data 
to evaluate the performances for different sets of 
rules selected by different threshold values. The 
results show that the threshold values of occurrence 
once and precision 70% performed best. This 
means any context-dependent rule with precision 
greater than or equal to 70% is used for the future 
processes. 39941 rules are in the set. In Table 1, we 
compare the phase-1 result with the baseline model 
on test data. It is shown that the boundary detection 
precision is very high, but the recall rate is com-
paratively low, since the phase-1 process cannot 
handle the complex cases. We also compare the 
processing time between the baseline model and 
the phase-1 parsing processes in Table 2. Marking 
conjunctive boundaries before parsing can limit the 
search range for parser and save processing time. 
The effect is more obvious when parsing long sen-
tences. Because long sentences generate more am-
718
biguous paths than shorter sentences, these surely 
spend much more time. 
6-10 words more than 11 words Test data  
Baseline phase1 Baseline phase1
C-boundary  
f-score 
55.74 84.43 50.0 63.75 
S-bracket        
f-score 
72.67 84.44 71.20 79.40 
Table 1. The comparison between the baseline 
PCFG model and the phase1 parsing process . 
6-10 words more than 11 words unit: second 
Baseline  phase1  Baseline  phase1
development data 14 12 34 23 
test data 14 11 34 24 
Table 2. The comparison of processing time be-
tween the baseline model and the phase1 parsing 
process. 
4.2 Phase-2 experimental results 
Complex cases cannot be matched by context-
dependent rules at the phrase-1 which will be han-
dled by the phase-2 algorithms mentioned in Sec-
tion 3. We use the CRF++ tool (Kudo, 2006) to 
train our CRF model. The CRF model can produce 
the N-best candidates for an input conjunctive sen-
tence. We experiment on the models of Top1-CRF 
and TopN-CRF where the Top1-CRF algorithm 
means that the final output is the best candidate 
produced by CRF model and the TopN-CRF means 
that the final output is the best candidate produced 
by the structure evaluation process described below. 
For each N-best candidate structure, three 
evaluation scores is derived: (a) the probability 
score generated from the PCFG parser, i.e. 
RuleScore, (b) the probability score generated from 
the CRF classifier, i.e. CRF-Score, and (c) the 
word association score, i.e. WA-Score. We normal-
ize each of the three scores by eq.(2): 
minmax
min)(
ScoreScore
ScoreScore
Scorenormal ii ?
?=                 (2) 
Scorei means the score of the i-th candidate, and 
Scoremin and Scoremax mean the worst and the best 
score in the candidate set for a target conjunctive 
sentence. The normalized scores are between 0 and 
1. After normalization, we combine the three 
scores with different weights: 
Total Score = w1*RuleScore + w2*CRF-Score + 
w3*WA-Score                                   (3) 
The w1, w2 and w3 are regarded as the degree of 
importance of the three types of information. We 
use development data to determine the best combi-
nation of w1, w2, w3. Due to limit amount of de-
velopment data, many local maximum and global 
maximum are achieved by different values of w1, 
w2, w3. Therefore we use a clustering algorithm to 
cluster the grid points of (w1, w2, w3) which pro-
duce the best performance. We then pick the larg-
est cluster and calculate its centroid as our final 
weights which are shown at Table 3.  
 Top N w1 w2 w3 
6-10words N = 3 0.11 0.64 0.25 
11- words N = 3 0.18 0.76 0.06 
Table 3. The best weights determined by the devel-
opment data for the sentences with different 
lengths using the best-3 candidates.  
The performance results of the testing data are 
shown in Table 4. In comparing with the results of 
the baseline model shown in Table 1, the conjunc-
tion boundary f-score increased from about 53% to 
83% for the testing data. The processes also im-
prove the overall parsing f-scores from 72% to 
83%. The results of Table 4 also show that the 
evaluation function indeed improves the perform-
ances but marginally. However the experiments are 
done under the condition that the input sentences 
are perfectly word segmented and pos tagged. In 
real practices, parser may accept sentences with 
ambiguous word segmentation and pos tagging to 
avoid the error accumulation due to early commit-
ment on word segmentation and pos tagging. 
Therefore parsers require much more information 
to resolve much more ambiguous conditions. A 
robust evaluation function may play a very impor-
tant role. We will do more researches in the future. 
 Top1CRF TopNCRF 
C-boundary f-score 85.57 89.55 Develop-
ment data S-bracket f-score 80.10 82.34 
C-boundary f-score 82.18 83.17 Test data 
S-bracket f-score 83.15 83.45 
Table 4. The final results of our overall processes.  
Another point worth mentioning, the perform-
ances of ?CRF? (using CRF model without phase-1) 
and ?phase1+CRF? (using CRF model after phase-
1) algorithms are comparable. However ?phase1+ 
CRF? algorithm is much more efficient, since 
?phase1+CRF? algorithm can determine the simple 
conjunctive structures by pattern matching and 
most of conjunctive structures are simple. On the 
other hand, the ?CRF? model requires twice partial 
sentence parsing, generates candidates with CRF 
719
classifier and evaluates structure with three syntac-
tic and semantic scores. 
5 Conclusion 
Conjunctive boundary detection is not a simple 
task. It is not only time consuming but also knowl-
edge intensive. Therefore we propose a context-
dependent rules matching approach to handle sim-
ple cases to get fast returns.  For complex cases, we 
use a knowledge intensive divide-and-conquer ap-
proach. To resolve the problems of inadequate 
knowledge and data sparseness due to limit amount 
of structure annotated training data, we extract 
word/concept associations from CNA corpus.  
In our experiments, the proposed model works 
well. Most conjunctive phrases are simple cases 
and can be matched by context-dependent rules and 
indeed avoid unnecessary calculation. Compared 
with the baseline method of straight forward PCFG 
parsing, the f-score of conjunctive boundary detec-
tion can be raised about 22%. For the complex 
cases, the boundaries f-score is further raised about 
7% after phase-2 processes. The experimental re-
sults show that the method not only works well on 
boundary resolution for conjunctive phrases but 
also improves the total performances of syntactic 
parsing. 
Our solutions include the rule-based method and 
cooperate with semantic and syntactic analyses. 
Therefore in the future we will try to enhance the 
syntactic and semantic analyses. For syntactic 
analysis, we still need to find more effective meth-
ods to improve the performance of our parser. For 
the semantic analysis, we will try to refine the word 
association data and discover a better semantic 
evaluation model. 
Acknowledgements 
This research was supported in part by National 
Digital Archives Program (NDAP, Taiwan) spon-
sored by the National Science Council of Taiwan 
under NSC Grants: NSC95-2422-H-001-031-. 
References 
Agarwal, Rajeev and Boggess, Lois. 1992. A Simple but 
Useful Approach to Conjunct Identification. In Pro-
ceedings of 30th Annual Meeting of Association for 
Computational Linguistics, pages 15-21. 
Chen, Keh-Jiann, Huang, Chu-Ren, Chen, Feng-Yi, Luo, 
Chi-Ching, Chang, Ming-Chung, Chen, Chao-Jan and 
Gao, Zhao-Ming. 2003. Sinica Treebank: design cri-
teria, representational issues and implementation. In 
Anne Abeille, (ed.): Building and Using Parsed Cor-
pora. Text, Speech and Language Technology. 
20:231-248, pages 231-248. 
Hsieh,Yu-Min, Yang, Duen-Chi and Chen, Keh-Jiann. 
2005. Linguistically-motivated grammar extraction, 
generalization and adaptation. In Proceedings of the 
Second International Join Conference on Natural 
Language Processing (IJCNLP2005), pages 177-187, 
Jeju Island, Republic of Korea. 
Hsieh, Yu-Ming, Duen-Chi Yang and Keh-Jiann Chen. 
2007. Improve Parsing Performance by Self-Learning. 
International Journal of Computational Linguistics 
and Chinese Language Processing, Vol. 12, #2, 
pages 195-216. 
Kurohashi, Sadao, and Nagao, Makoto. 1994. A Syntac-
tic Analysis Method of Long Japanese Sentences 
Based on the Detection of Conjunctive Structure. 
Computational Linguistics 20(4), pages 507-534. 
Kudo, Taku. 2006. (software)CRF++: Yet Another CRF 
toolkit http://chasen.org/~taku/software/CRF++/. 
Lafferty, John, McCallum, Andrew, Pereira, Fernando. 
2001. Conditional Random Fields: Probabilistic 
Models for Segmenting and Labeling Sequence Data. 
In Proceedings of the 18th International Conference 
on Machine Learning (ICML-01), pages 282-289. 
Lee, Yong-Hun, Kim, Mi-Young and Lee, Jong-Hyeok. 
2005. Chunking Using Conditional Random Fields in 
Korea Texts. In Proceedings of the Second Interna-
tional Join Conference on Natural Language Proc-
essing (IJCNLP2005), pages 155-164, Jeju Island, 
Republic of Korea. 
Manning, Christopher D., and Schutze, Hinrich. 1999. 
Foundations of Statistical Natural Language process-
ing. The MIT Press, Cambridge, Massachusetts.  
Miller, Geroge, 1993. Introduction to WordNet: An 
Online Lexical Database. Princeton, CSL Report 43. 
Steiner, Ilona. 2003. Parsing Syntactic Redundancies in 
Coordinate Structures. Poster presentation at the 
European Cognitive Science Conference (Euro-
CogSci03). 
Van Delden, Sebastian. 2002. A Hybrid Approach to 
Pre-Conjunct Identification. In Proceedings of the 
2002 Language Engineering Conference (LEC 2002), 
pages 72-77, University of Hyderabad, India. 
Wu, Yunfang. 2003. Contextual Information of Coordi-
nate Structure. Advances on the Research of Machine 
Translation, pages 103-109, Publishing house of 
Electronics Industry. 
720
