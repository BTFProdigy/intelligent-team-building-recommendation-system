Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 37?46,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Probabilistic Ontology Trees for Belief Tracking in Dialog Systems
Neville Mehta
Oregon State University
mehtane@eecs.oregonstate.edu
Rakesh Gupta
Honda Research Institute
rgupta@hra.com
Antoine Raux
Honda Research Institute
araux@hra.com
Deepak Ramachandran
Honda Research Institute
dramachandran@hra.com
Stefan Krawczyk
Stanford University
stefank@cs.stanford.edu
Abstract
We introduce a novel approach for robust
belief tracking of user intention within
a spoken dialog system. The space of
user intentions is modeled by a proba-
bilistic extension of the underlying do-
main ontology called a probabilistic on-
tology tree (POT). POTs embody a prin-
cipled approach to leverage the dependen-
cies among domain concepts and incorpo-
rate corroborating or conflicting dialog ob-
servations in the form of interpreted user
utterances across dialog turns. We tailor
standard inference algorithms to the POT
framework to efficiently compute the user
intentions in terms of m-best most proba-
ble explanations. We empirically validate
the efficacy of our POT and compare it to
a hierarchical frame-based approach in ex-
periments with users of a tourism informa-
tion system.
1 Introduction
A central function of a spoken dialog system
(SDS) is to estimate the user?s intention based on
the utterances. The information gathered across
multiple turns needs to be combined and under-
stood in context after automatic speech recogni-
tion (ASR). Traditionally, this has been addressed
by dialog models and data structures such as forms
(Goddeau et al, 1996) and hierarchical task de-
composition (Rich and Sidner, 1998). To formal-
ize knowledge representation within the SDS and
enable the development of reusable software and
resources, researchers have investigated the or-
ganization of domain concepts using IS-A/HAS-A
ontologies (van Zanten, 1998; Noh et al, 2003).
Because the SDS only has access to noisy ob-
servations of what the user really uttered due to
speech recognition and understanding errors, be-
lief tracking in speech understanding has received
particular attention from proponents of probabilis-
tic approaches to dialog management (Bohus and
Rudnicky, 2006; Williams, 2006). The mecha-
nism for belief tracking often employs a Bayesian
network (BN) that represents the joint probabil-
ity space of concepts while leveraging conditional
independences among them (Paek and Horvitz,
2000). Designing a domain-specific BN requires
significant effort and expert knowledge that is not
always readily available. Additionally, real-world
systems typically yield large networks on which
inference is intractable without major assumptions
and approximations. A common workaround to
mitigate the intensive computation of the joint dis-
tribution over user intentions is to assume full con-
ditional independence between concepts which vi-
olates the ground truth in most domains (Bohus
and Rudnicky, 2006; Williams, 2006).
We propose a novel approach to belief track-
ing for an SDS that solves both the design and
tractability issues while making more realistic
conditional independence assumptions. We repre-
sent the space of user intentions via a probabilistic
ontology tree (POT) which is a tree-structured BN
whose structure is directly derived from the hier-
archical concept structure of the domain specified
via an IS-A/HAS-A ontology. The specialization
(IS-A) and composition (HAS-A) relationships be-
tween the domain concepts are intuitive and pro-
vide a systematic way of representing ontological
knowledge for a wide range of domains.
The remainder of the paper is structured as fol-
lows. We begin by describing the construction of
the POT given a domain ontology. We show how
a POT employs null semantics to represent con-
sistent user intentions based on the specialization
and composition constraints of the domain. We
then show how standard inference algorithms can
be tailored to exploit the characteristics of the POT
to efficiently infer the m-best list of probable ex-
planations of user intentions given the observa-
37
tions. The POT and the associated inference al-
gorithm empower a dialog manager (DM) to ac-
count for uncertainty while avoiding the design
complexity, intractability issues, and other restric-
tive assumptions that characterize state-of-the-art
systems. The section on empirical evaluation de-
scribes experiments in a tourist information do-
main that compare the performance of the POT
system to a frame-based baseline system. The pa-
per concludes with a discussion of related work.
2 Problem Formulation
Let {X1, X2, . . . , XN} be a set of N concepts.
Every conceptXi takes its value from its finite dis-
crete domain D(Xi) which includes a special null
element for the cases where Xi is irrelevant. The
user intention space is defined as U = D(X1) ?
D(X2) ? ? ? ? ? D(XN ). At each dialog turn t,
the system makes a noisy observation ot about
the true user intention u ? U . ot consists of
a set of slots. A slot is a tuple ?v, d, c? where
v ? {X1, . . . , XN}, d ? D(v) is a value of v,
and c ? R is the confidence score assigned to that
concept-value combination by the speech under-
standing (SU) system.
The goal of belief tracking is to maintain
Pr(X1, . . . , XN |o1, . . . , ot), a distribution over
the N -dimensional space U conditioned on all the
observations made up to turn t. At each turn, the
belief is updated based on the new observations to
estimate the true, unobserved, user intention.
3 Probabilistic Ontology Trees
We model the space of the user intentions via a
POT. A POT is a tree-structured BN that extends
a domain ontology by specifying probability dis-
tributions over its possible instantiations based on
specializations and compositions.
3.1 Domain Ontology
To ensure that the corresponding POTs are tree-
structured, we consider a restricted class of do-
main ontologies over concepts.
Definition 1. A domain ontology is a labeled di-
rected acyclic graph. The set of vertices (corre-
sponding to the domain concepts) is partitioned
into {V0}, VS , and VC , where V0 is the only root
node, VS is the set of specialization nodes (re-
lated via IS-A to their parents), and VC is the set
of composition nodes (related via HAS-A to their
parents). The set of edges satisfy the constraints
A
B
D
C
E
H
F
I
G
J
K
I
J
K
Figure 1: The ontology for a sample domain where
B IS-A A, C IS-A A, D IS-A A, E IS-A B, F IS-A B,
C HAS-A G (essential), D HAS-A G (nonessential),
H IS-A D, E HAS-A I (essential), J IS-A G, and
K IS-A G. Specialization nodes are drawn single-
lined, composition nodes are drawn double-lined,
and the root node is drawn triple-lined. Special-
ization subtrees are marked by dashed ovals.
that a specialization node has exactly one parent
and a composition node may only have more than
one parent if they are all specialization nodes with
a common parent.
Specialization nodes represent refinements of
their parent concepts. Specializations of a con-
cept are disjoint, that is, for any particular instance
of the parent exactly one specialization is applica-
ble and the rest are inapplicable. For example, if
Dog IS-A Animal and Cat IS-A Animal, then Cat
is inapplicable when Dog is applicable, and vice
versa. Composition nodes represent attributes of
their parents and may be essential or nonessential,
e.g., Dog HAS-A Color (essential), Dog HAS-A
Tail (nonessential). These definitions correspond
with the standard semantics in the knowledge rep-
resentation community (Noh et al, 2003). An ex-
ample ontology is shown in Figure 1.
Definition 2. A specialization subtree (spec-tree)
in the ontology is a subtree consisting of a node
with its specialization children (if any).
3.2 POT Construction
We now describe how a POT may be constructed
from a domain ontology. The purpose of the POT
is to maintain a distribution of possible instanti-
ations of the ontology such that the ontological
structure is respected.
38
Given an ontology G, the corresponding POT is
a tree-structured BN defined as follows:
Variables. Let T be a spec-tree in G with root
R. Unless R is a (non-root) specialization node
with no specialization children, T is represented
in the POT by a variable X with the domain
D(X) =
?
??
??
{exists, null}, if ChildrenT (R) = ?
ChildrenT (R), if R = V0
ChildrenT (R) ? {null}, otherwise.
Edges. Let POT variables X and Y correspond
to distinct spec-trees TX and TY in G. There is a
directed edge from X to Y if and only if either
? A leaf of TX is the root of TY .
? There is an edge from a leaf in TX to the non-
specialization root of TY .
? There is an edge from the non-specialization
root of TX to that of TY .
Conditional Probability Tables (CPTs). If X
(corresponding to spec-tree TX ) is the parent of Y
(corresponding to spec-tree TY ) in the POT, then
Y ?s CPT is conditioned as follows:
? If TY is rooted at one of the leaves of TX ,
then
Pr(Y = null|X = Y) = 0
Pr(Y = null|X 6= Y) = 1
where Y is the domain value of X corre-
sponding to child Y .
? If R is the root of TX , and TY has a compo-
sition root node that is attached only to nodes
in S ? ChildrenTX (R), then
Pr(Y = null|X = V) = 1
for any domain value V of X corresponding
to a node V ? ChildrenTX (R)? S.
? If the root of TY is an essential composition
node attached to a leaf V of TX , then
Pr(Y = null|X = V) = 0
where V is the domain value of X corre-
sponding to the leaf V .
We label a POT variable with that of the root of
the corresponding spec-tree for convenience. The
domain of a POT variable representing a spec-tree
comprises the specialization children (node names
in sanserif font) and the special value null; the null
A
B
C
D
0.4
0.3
50
.25
B
D
E
F
nu
ll
B
0.6
0.4
0
C
0
0
1
D
0
0
1
H
nu
ll
B
0
1
C
0
1
D
1
0
ex
ist
sn
ull
E
1
0
F
0
1
nu
ll
0
1
J
K
nu
ll
B
0
0
1
C
0.8
0.2
0
D
0.7
0.1
0.2
I
G
Figure 2: The POT for the example domain. If a
node represents a spec-tree in the ontology, then it
is labeled by the root of the spec-tree; otherwise,
it is labeled with the name of the corresponding
ontology node. D(A) = {B, C, D}, D(B) = {E, F,
null}, D(D) = {H, null}, and Pr(A), Pr(B|A) and
Pr(D|A) represent some distributions over the re-
spective specializations. D(I) = {exists, null} and
D(G) = {J, K, null}. Note that a composition node
(G) can be shared between multiple specializa-
tions (C and D) in the ontology while the resulting
POT remains tree-structured.
value allows us to render any node (except the
root) inapplicable. Spec-trees comprising single
nodes have the domain value exists to switch be-
tween being applicable and inapplicable. The CPT
entries determine the joint probabilities over pos-
sible valid instantiations of the ontology and could
be based on expert knowledge or learned from
data. The conditions we impose on them (null se-
mantics) ensure that inconsistent instantiations of
the ontology have probability 0 in the POT. While
the ontology might have undirected cycles involv-
ing the children of spec-trees, the corresponding
POT is a tree because spec-trees in the ontology
collapse into single POT nodes. The POT for the
example domain is shown in Figure 2.
3.3 Tourist Information POT
For the empirical analysis, we designed a POT for
a tourist information system that informs the user
about places to shop, eat, get service, and displays
relevant information such as the distance to an in-
tended location. The user can also provide con-
versational commands such as stop, reset, undo,
etc. The full ontology for the tourist information
domain is shown in Figure 3 and the POT is in
Figure 4. In the POT, Action is the root node, with
D(Action) = {Venue, Command}, and D(Venue)
39
Ac
tio
n
Ve
nue
Co
mm
and
Sta
rt
Ca
nce
l
Re
sta
ura
nt
Sto
re
Ser
vic
e
Ar
ea
Dis
pla
y
Mi
les
Am
bie
nce
Cu
isin
e
Ho
urs
Ser
vic
eT
ype
Str
eet
Ra
tin
g
Sto
reT
ype
Pri
ceR
ang
e
Figure 3: The ontology for the tourist information domain. All the composition nodes have specializa-
tions of their own (such as Japanese and Greek for Cuisine), but have not been shown for the sake of
compactness.
= {Restaurant, Store, Service, null}. All the com-
position (or attribute) nodes such as Hours and
Rating are made children of Venue by construc-
tion. Since a Command is inapplicable when the
Action is a Venue, we have Pr(Command = null
| Action = Venue) = 1. The composition nodes
(Cuisine, Street, etc.) have specializations of their
own ({Japanese, Greek, . . . }, {Castro, Elm, . . . },
etc.), but are not shown for the sake of clarity.
Since Cuisine is an essential attribute of Restau-
rant, Pr(Cuisine = null | Venue = Restaurant) = 0;
moreover, Pr(Cuisine = null | Venue = Service) =
1 because Cuisine is not relevant for Service.
4 Inferring User Intention
We have seen how the POT provides the proba-
bilistic machinery to represent domain knowledge.
We now discuss how the POT structure can be
leveraged to infer user intention based on the slots
provided by the SU.
4.1 Soft Evidence
Every slot retrieved from the SU needs to be incor-
porated as observed evidence in the POT. We can
set the associated node within the POT directly to
its domain value as hard evidence when we know
these values with certainty. Instead, we employ
probabilistic observations to soften the evidence
entered into the POT. We assume that the confi-
dence score c ? [0, 100] of a slot corresponds to
the degree of certainty in the observation. For an
observed slot variableX , we create an observation
node X? on the fly with the same domain as X and
make it a child of X . If x is the observed value for
slot X , then the CPT of X? is constructed from the
slot?s confidence score as follows:
Pr(X?|X = x) =
{
c(|D(X)|?1)/100+1
|D(X)| , X? = x
1?c/100
|D(X)| , X? 6= x
The probability values are generated by lin-
early interpolating between the uniform probabil-
ity value and 1 based on the confidence score. For
the remaining values,
Pr(X?|X 6= x) =
{
1? ?(|D(X)| ? 1), X? = X
?, X? 6= X
where ? > 0.1 Since the confidence score gives an
indication of the probability for the observed value
of a slot but says nothing about the remaining val-
ues, the diagonal elements for the remaining val-
ues are near 1. We cannot make them exactly 1
because the observation node needs to coexist with
possibly conflicting observations in the POT.
If the user confirms the current POT hypothesis,
then observations corresponding to the current hy-
pothesis (with CPTs proportional to the score of
the confirmation) are added to the POT to enforce
the belief. If the user denies the current hypothe-
sis, then all observations corresponding to the cur-
rent hypothesis are removed from the POT.
1In our experiments, we use ? = 10?10.
40
Ac
tio
n
Ve
nue
Co
mm
and
Am
bie
nce
Cu
isin
e
Dis
pla
y
Ho
urs
Ser
vic
eT
ype
Mi
les
Ra
tin
g
Sto
reT
ype
Ar
ea
Str
eet
Pri
ceR
ang
e
Cu
isin
e
Str
eet
Cas
tro
Elm
nul
l
Cas
tro
0.8
0.1
0.1
Jap
ane
se
Gre
ek
nul
l
Jap
ane
se
0.6
0.2
0.2
Cu
isin
e
Str
eet
Elm
?
1?2
?
?
nul
l
?
?
1?2
?
p Gre
ek
?
1?2
?
?
nul
l
?
?
1?2
?
Figure 4: The POT for the tourist information domain. Assuming that D(Cuisine) = {Japanese, Greek,
null} and D(Street) = {Castro, Elm, null}, the shaded observation nodes represent the soft evidence for
input slots ?Cuisine, Japanese, 40? and ?Street, Castro, 70?.
The POT for the tourist information domain af-
ter getting two slots as input is shown in Figure 4.
The attached nodes are set to the observed slot val-
ues and the evidence propagates through the POT
as explained in the next section.
4.2 POT Inference
A probable explanation (PE) or hypothesis is an
assignment of values to the variables in the POT,
and the most probable explanation (MPE) within
the POT is the explanation that maximizes the
joint probability conditioned on the observed vari-
ables. The top m estimates of the user?s intentions
correspond to them-best MPEs. The design of the
POT ensures that the m-best MPEs are all con-
sistent across specializations, that is, exactly one
specialization is applicable per node in any PE; all
inconsistent explanations have a probability of 0.
The m-best MPEs could be found naively us-
ing the Join-Tree algorithm to compute the joint
distribution over all variables and then use that to
find the top m explanations. The space required to
store the joint distribution alone is O(nN ), where
N is the number of nodes and n the number of
values per node. Because the run time complex-
ity is at least as much as this, it is impractical for
any reasonably sized tree. However, we can get
a significant speedup for a fixed m by using the
properties of the POT.
Algorithm 1 uses a message-passing protocol,
similar to many in the graphical models litera-
ture (Koller and Friedman, 2009), to simulate a
Algorithm 1 COMPUTE-PE
Input: POT T with rootX0, number of MPEsm, evidence E
Output: m MPEs for T
1: for X ? T in reverse topological order do
2: Collect messages ?Yi from all children Yi of X
3: ?X = COMPUTE-MPE-MESSAGE(X,m, {?Yi})
4: end for
5: return top m elements of Pr(X0|E)?X0(?) without E
Algorithm 2 COMPUTE-MPE-MESSAGE
Input: POT node X , number of MPEs m, messages from
children ?Yi
Output: Message ?X(?)
1: if X is a leaf node then
2: ?X(x)? 1,?x ? D(X)
3: return ?X
4: end if
5: for x ? D(X) do
6: for ~z = ((y1, ~z1), . . . , (yk, ~zk)) ? {D(?Y1)? . . .?
D(?Yk ) : Pr (Yi = null|X = x,E) < 1} do
7: ??X(x, ~z)?
?
i
[
Pr(Yi = yi|X = x,E)?Yi (yi, ~zi)
]
8: end for
9: ?X(x)? top m elements of ??X(x).
10: end for
11: return ?X
dynamic programming procedure across the lev-
els of the tree (see Figure 5). In Algorithm 2, an
MPE message is computed at each node X using
messages from the children, and sent to the par-
ent. The message from X is the function (or ta-
ble) ?X(x,~z) that represents the probabilities of
the top m explanations, ~z, of the subtree rooted at
X for a particular value of X = x. At the root
node X0 we try all values of x0 to find the top m
MPEs for the entire tree. Note that in step 7, we
41
A
? D
? B B
D
? D
? B
?
? G
I
G
? I
(a)
A =
 B
? D
? B B
D
? D
? B
?
? G
I
G
? I
(b)
A =
 C
? D
? B B
D
? D
? B
?
? G
I
G
? I
(c)
A =
 D
? D
? B B
D
?
? G
? D
? B I
G
? I
(d)
Figure 5: COMPUTE-MPE applied to the exam-
ple POT. (a) Inference starts with the messages be-
ing passed up from the leaves to the root A. Every
message ?X is an m ? n table that contains the
probabilities for the m-best MPEs of the subtree
rooted at X for all the n domain values of X . (b)
At the root, A is set to its first element B, and its
marginal Pr(A = B) is combined with the mes-
sage ?B . The semantics of the POT ensures that
the other messages can be safely ignored because
those subtrees are known to be null with probabil-
ity 1. (c) A is set to C and only the essential at-
tribute G is non-null. (d) A is set to its final el-
ement D, and consequently both the node D and
the nonessential attribute G are non-null and their
messages are mutually independent.
need the marginal P (Y |X,E) which can be ef-
ficiently computed by a parallel message-passing
method. Evidence nodes can only appear as leaves
because of our soft evidence representation, and
are encompassed by the base case. The algorithm
leverages the fact that the joint of any entire sub-
tree rooted at a node that is null with probability 1
can be safely assumed to be null with probability
1. The validity of Algorithm 1 is proven in Ap-
pendix A.
4.3 Complexity Analysis
At a POT node with at most n values and branch-
ing factor k, we do nmaximizations over the prod-
uct space of k nm-sized lists. Thus, the time
complexity of Algorithm 1 on a POT with N
nodes is O(N(nm)k) and the space complexity is
O(Nnmk). (Insertion sort maintains a sorted list
truncated at m elements to keep track of the top
m elements at any time.) However, the algorithm
is significantly faster on specialization nodes be-
cause only one child is applicable and needs to be
considered in the maximization (step 7). In the ex-
treme case of a specialization-only POT, the time
and space complexities both drop to O(Nmn).
A similar algorithm for incrementally finding
m-best MPEs in a general BN is given in Srinivas
and Nayak (1996). However, our approach has the
ability to leverage the null semantics in POTs re-
sulting in significant speedup as described above.
This is crucial because the run-time complexity of
enumerating MPEs is known to be PPP -Complete
for a general BN (Kwisthout, 2008).
5 Empirical Evaluation
To test the effectiveness of our POT approach, we
compare it to a frame-based baseline system for
inferring user intentions.
The baseline system uses a hierarchical frame-
based approach. Each frame maps to a par-
ticular user intention, and the frames are filled
concurrently from the dialog observations. The
slots from a turn overwrite matching slots re-
ceived in previous turns. The baseline system uses
the same ontology as the POT to insure that it
only produces consistent hypotheses, e.g., it never
produces ?Venue=Service, Cuisine=Japanese? be-
cause Service does not have a Cuisine attribute.
When several hypotheses compete, the system se-
lects the one with the maximum allocated slots.
We implemented the POT engine based on the
Probabilistic Network Library (Intel, 2005). It
takes a POT specification as input, receives the
ASR slots, and returns its m-best MPEs.
Using a tourism information spoken dialog sys-
tem, we collected a corpus of 375 dialogs from
15 users with a total of 720 turns (details in
Appendix B). Evaluation is performed by run-
ning these collected dialogs in batch and pro-
viding the ASR slots of each turn to both the
baseline and POT belief-tracking systems.2 Af-
ter each turn, both systems return their best hy-
pothesis of the overall user intention in the form
of a set of concept-value pairs. These hypothe-
2Speech recognition and understanding was performed
using the Nuance Speech Recognition System v8.5 running
manual and statistical grammars with robust interpretation.
42
System Precision Recall F1
Top hypothesis 0.84 0.81 0.83
Top 2 hypotheses 0.87 0.84 0.85
POT Top 3 hypotheses 0.89 0.85 0.87
Top 4 hypotheses 0.91 0.86 0.89
Top 5 hypotheses 0.92 0.86 0.89
Baseline 0.84 0.79 0.81
Table 1: Precision/recall results comparing the
baseline system against the POT-based system on
the 25-scenario experiment. Results are averaged
over all 15 users.
?1 ?0.8 ?0.6 ?0.4 ?0.2 00.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Log?likelihood of top POT hypothesis 
F1
Figure 6: F1 score as a function of the log-
likelihood of the top hypothesis for the user?s goal.
ses are compared to the true user intention ex-
pressed so far in the dialog (e.g., if the user wants
a cheap restaurant but has not mentioned it yet,
PriceRange=Cheap is not considered part of the
ground truth). This offline approach allows us to
compare both versions on the same input.
Table 1 shows the precision/recall results for the
experiment based on comparing the set of true user
intention concepts to the inferred hypotheses of
the POT and baseline systems. The average word
error rate for all users is 29.6%. The POT sys-
tem shows a 2% improvement in recall and F1
over the baseline. Additionally, leveraging the m-
best hypotheses beyond just the top one could help
enhance performance or guide useful clarification
questions as shown by the improved performance
when using the top 2?5 hypotheses; we assume
an oracle for selecting the hypothesis with highest
F1 among the top m hypotheses. All of the CPTs
in the POT (besides the structural constraints) are
uniformly distributed. Thus, the performance of
the POT could be further improved by training the
CPTs on real data.
To assess the quality of likelihood returned by
the POT as a belief confidence measure, we binned
dialog turns according to the log-likelihood of the
top hypothesis and then computed the F1 score of
each bin. Figure 6 shows that belief log-likelihood
is indeed a good predictor of the F1 score. This
information could be very useful to a dialog man-
ager to trigger confirmation or clarification ques-
tions for example.
6 Discussion
The definition and construction of POTs provide a
principled and systematic way to construct proba-
bilistic models for an SDS. While any BN can be
used to model the space of user intentions, design-
ing an effective network is not an easy task for sys-
tem designers not well versed in graphical mod-
els. In previous belief tracking work, researchers
describe their networks with little indication on
how they arrived at the specific structure (Paek and
Horvitz, 2000; Thomson and Young, 2009). Prior
work on ontologies for SDSs (van Zanten, 1998;
Noh et al, 2003) as well as the prominence of
concept hierarchies in other areas such as object-
oriented programming and knowledge engineer-
ing make them a natural and intuitive way of repre-
senting SDS domains. The development of POTs
builds on past research on constructing BNs based
on ontological knowledge (Helsper and van der
Gaag, 2002; Pfeffer et al, 1999).
While most approaches to belief tracking in the
dialog systems community make a strict indepen-
dence assumption between concepts (Bohus and
Rudnicky, 2006; Williams, 2006), POTs model
the dependencies between concepts connected by
specialization and composition relationships while
remaining significantly more tractable than gen-
eral BNs and being very straightforward to de-
sign. The null semantics allow a POT to capture
disjoint values and the applicability of attributes
which are common aspects of concept ontologies.
Obviously, a POT cannot capture all types of con-
cept relationships since each concept can have
only one parent. However, this restriction allows
us to perform efficient exact computation of the
m-best MPEs which is a significant advantage.
Statistical Relational Learning approaches such as
Markov Logic Networks (Richardson and Domin-
gos, 2006) have been developed for more general
relational models than strict ontologies, but they
lack the parsimony and efficiency of POTs.
43
Thomson and Young (2009) describe an ap-
proach to dialog management based on a partially
observable Markov decision process (POMDP)
whose policy depends only on individual con-
cepts? marginal distributions rather than on the
overall user intention. Because their system per-
forms belief tracking with a dynamic Bayesian
network (DBN) rather than a static BN, the ex-
act marginal computation is intractable and the au-
thors use loopy belief propagation to compute the
marginals. Even then, they indicate that the depen-
dencies of the subgoals must be limited to enable
tractability. In practice, all concepts are made in-
dependent except for the binary validity nodes that
deterministically govern the dependence between
nodes (similar to the null semantics of a POT).
Williams (2007) also represents the user goal as
a DBN for a POMDP-based DM. They perform
belief updating using particle filtering and approx-
imate the joint probability over the user intention
with the product of the concept marginals. This
could lead to inaccurate estimation for condition-
ally dependent concepts.
Among authors who have used m-best lists of
dialog states for dialog management, Higashinaka
et al (2003) have shown empirically that main-
taining multiple state hypotheses facilitates shorter
dialogs. Their system scores each dialog state
using a linear combination of linguistic and dis-
course features, and this score is used by a hand-
crafted dialog policy. While illustrating the advan-
tages of m-best lists, this scoring approach lacks
theoretical justification and ability to include prior
knowledge that POTs inherit from BNs.
7 Conclusion
We have presented the POT framework for belief
tracking in an SDS. We have shown how a POT
can be constructed from the domain ontology and
provided an exact algorithm to infer the user?s in-
tention in real-time. POTs strike a balance be-
tween representing rich concept dependencies and
facilitating efficient tracking of them-best user in-
tentions based on exact joint probabilities rather
than approximations such as concept marginals.
References
D. Bohus and A. Rudnicky. 2006. A K Hypotheses
+ Other Belief Updating Model. In AAAI Workshop
on Statistical and Empirical Approaches to Spoken
Dialogue Systems.
D. Goddeau, H. Meng, J. Polifroni, S. Seneff, and
S. Busayapongchai. 1996. A Form-Based Dialogue
Manager for Spoken Language Applications. In IC-
SLP.
E. Helsper and L. van der Gaag. 2002. Building
Bayesian Networks through Ontologies. In Euro-
pean Conference on Artificial Intelligence.
R. Higashinaka, M. Nakano, and K. Aikawa. 2003.
Corpus based Discourse Understanding on Spoken
Dialog Systems. In Annual Meeting on Association
for Computational Linguistics.
Intel. 2005. Probabilistic Network Library. http://
sourceforge.net/projects/openpnl/.
D. Koller and N. Friedman. 2009. Probabilistic
Graphical Models: Principles and Techniques. MIT
Press.
J. Kwisthout. 2008. Complexity Results for Enumerat-
ing MPE and Partial MAP. In European Workshop
on Probabilistic Graphical Models.
H. Noh, C. Lee, and G. Lee. 2003. Ontology-based
Inference for Information-seeking in Natural Lan-
guage Dialog Systems. In IEEE International Con-
ference on Industrial Informatics.
T. Paek and E. Horvitz. 2000. Conversation as Ac-
tion under Uncertainty. In Uncertainty in Artificial
Intelligence.
A. Pfeffer, D. Koller, B. Milch, and K. T. Takusagawa.
1999. Spook: A system for probabilistic object-
oriented knowledge representation. In Uncertainty
in Artifical Intelligence.
C. Rich and C. Sidner. 1998. COLLAGEN: a Col-
laboration Manager for Software Interface Agents.
An International Journal: User Modeling and User
Adapted Interaction, 8.
M. Richardson and P. Domingos. 2006. Markov Logic
Networks. Machine Learning, 62:107?136.
S. Srinivas and P. Nayak. 1996. Efficient Enumeration
of Instantiations in Bayesian Networks. In UAI.
B. Thomson and S. Young. 2009. Bayesian Update
of Dialogue State: A POMDP Framework for Spo-
ken Dialogue Systems. Computer Speech and Lan-
guage.
G. van Zanten. 1998. Adaptive Mixed-Initiative Dia-
logue Management. In IEEE Workshop on Interac-
tive Voice Technology for Telecommunications Ap-
plications.
J. Williams. 2006. Partially Observable Markov Deci-
sion Processes for Dialog Management.
J. Williams. 2007. Using Particle Filters to Track
Dialogue State. In IEEE Workshop on Automatic
Speech Recognition & Understanding.
44
A Analysis of the Inference Algorithm
Theorem 1. Algorithm 1 returns the top m MPEs
of the POT along with their joint probabilities.
Proof. We first prove this for the special case of
m = 1 to simplify notation. For the base case
of a node with no children, Algorithm 2 sim-
ply returns a message with all probabilities at
1 for all values of that node. Now, consider a
node X with children Y1, . . . , Yk. Let Desc(Y )
be the descendants of node Y . Since Algo-
rithm 2 given node X returns exactly one expla-
nation, z for each x ? D(X), we will define
?X(x) = ?X(x, z). Now, to show that ?X(x) =
maxDesc(X) Pr(Desc(X)|X = x,E), that is, Al-
gorithm 2 returns the top explanation of the entire
subtree rooted at X for every value in D(X), we
use structural induction on the tree.
max
Desc(X)
Pr(Desc(X)|X = x,E)
= max
Y1:k,Desc(Y1:k)
Pr(Y1:k,Desc(Y1:k)|X = x,E)
= max
Y1:k,Desc(Y1:k)
?
i
Pr(Yi|X = x,E) Pr(Desc(Yi)|Yi, E)
=
?
i
max
Yi,Desc(Yi)
[
Pr(Yi|X = x,E) Pr(Desc(Yi)|Yi, E)
]
=
?
i
max
Yi
[
Pr(Yi|X = x,E) max
Desc(Yi)
Pr(Desc(Yi)|Yi, E)
]
=
?
i
max
Yi
[
Pr(Yi|X = x,E)?Yi(yi)
]
{Inductive step}
= ?X(x).
The proof for m > 1, where every maximization
returns a list of the top m elements, is similar.
B Dialogs in the Tourist Information
Domain
Each user conducted 25 dialogs according to pre-
scribed scenarios for the tourist information do-
main. The order of scenarios was randomized for
each user. Sample scenarios:
1. Find a good and cheap Mexican restaurant in
Mountain View.
2. There is a medical emergency and you need
to get to the hospital. Find a route.
3. You need to find your favorite coffee fran-
chise. You have 10 minutes to get coffee.
4. Find a place to buy some fruits and vegeta-
bles.
5. Find a Chinese restaurant in Santa Clara with
good ambiance, and display travel distance.
6. Find an ATM on Castro Street in Mountain
View.
Figure 7 shows a typical interaction with the
system for the first scenario along with a possi-
ble hypothesis inferred by the system at every turn
of the dialog. Figure 8 shows an example where
the POT system is able to discard an incorrect ob-
servation about a restaurant based on the accumu-
lated belief about bookstores over multiple turns.
Figure 9 shows how the POT is able to leverage the
ontological structure to pick out higher-level con-
cepts with lower confidence scores over spurious
low-level concepts with higher confidence scores.
45
User Find a Mexican restaurant in Mountain View.
Hypothesis [venue restaurant] [area mountain view] [cuisine italian]
{Note: Mexican is misrecognized as Italian.}
User No, Mexican.
Hypothesis [venue restaurant] [area mountain view] [cuisine mexican]
User Show me ones with at least four star rating.
Hypothesis [venue restaurant] [area mountain view] [cuisine mexican] [rating four star]
User I want a cheap place.
Hypothesis [venue restaurant] [area mountain view] [cuisine mexican] [rating four star] [price cheap]
User Is there anything on Castro?
Hypothesis [venue restaurant] [area mountain view] [street castro] [cuisine mexican] [rating four star] [price cheap]
Figure 7: A sample dialog in the tourism information domain showing the inferred hypothesis of the
user?s intention at every turn. The information response from the system?s back-end is based on its
current hypothesis.
User utterance Where is the bookstore?
ASR where is the bookstore
True hypothesis [action venue] [venue store] [sell book]
Baseline hypothesis [action venue] [venue store] [sell book]
POT hypothesis [action venue] [venue store] [sell book]
User utterance Store on Market Street.
ASR store on market street
True hypothesis [action venue] [venue store] [sell book] [street market]
Baseline hypothesis [action venue] [venue store] [sell book] [street market]
POT hypothesis [action venue] [venue store] [sell book] [street market]
User utterance In downtown.
ASR dennys
True hypothesis [action venue] [venue store] [sell book] [street market] [area downtown]
Baseline hypothesis [action venue] [venue restaurant] [brand dennys]
POT hypothesis [action venue] [venue store] [sell book] [street market]
Figure 8: A dialog showing the ASR input for the user?s utterance, and the corresponding true, baseline,
and POT hypotheses. The POT is able to correctly discard the inconsistent observation in the third turn
with the observations in previous turns.
User utterance Where should I go to buy Lego for my kid?
SU slots ?Venue Store 38? ?ServiceType GolfCourse 60?
True hypothesis [action venue] [venue store] [storetype toy]
Baseline hypothesis [action venue] [venue service] [servicetype golf course]
POT hypothesis [action venue] [venue store]
Figure 9: A single dialog turn showing the SU slots for the user?s utterance, and the corresponding
baseline, POT, and true hypotheses. Any system that looks at the individual confidence scores will base
its hypothesis on the ?ServiceType GolfCourse 60? slot. Instead, the POT hypothesis is influenced by
?Venue Store 38? because its score in combination with the concept?s location in the POT makes it more
likely than the other slot.
46
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 169?178,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Landmark-based Location Belief Tracking in a Spoken Dialog System
Yi Ma
The Ohio State University
Columbus, OH 43210
may@cse.ohio-state.edu
Antoine Raux, Deepak Ramachandran, Rakesh Gupta
Honda Research Institute, USA
425 National Ave, Mountain View, CA 94043
{araux,dramachandran,
rgupta}@hra.com
Abstract
Many modern spoken dialog systems use
probabilistic graphical models to update their
belief over the concepts under discussion, in-
creasing robustness in the face of noisy input.
However, such models are ill-suited to prob-
abilistic reasoning about spatial relationships
between entities. In particular, a car naviga-
tion system that infers users? intended desti-
nation using nearby landmarks as descriptions
must be able to use distance measures as a fac-
tor in inference. In this paper, we describe
a belief tracking system for a location iden-
tification task that combines a semantic belief
tracker for categorical concepts based on the
DPOT framework (Raux and Ma, 2011) with
a kernel density estimator that incorporates
landmark evidence from multiple turns and
landmark hypotheses, into a posterior proba-
bility over candidate locations. We evaluate
our approach on a corpus of destination set-
ting dialogs and show that it significantly out-
performs a deterministic baseline.
1 Introduction
Mobile devices such as smart phones and in-car in-
fotainment systems have generated demand for a
new generation of location-based services such as
local business search, turn-by-turn navigation, and
social event recommendation. Accessing such ser-
vices in a timely manner through speech is a crucial
requirement, particularly on the go when the user is
unable to resort to other modalities e.g. where safety
regulations prohibit drivers from using buttons or a
touchscreeen while driving.
In such systems, a Point of Interest (POI)
or a destination such as a restaurant, store or a
public place is often specified. For example, a
car navigation system needs the user to input the
destination before giving directions. Similarly, a
photo tagging application must allow its users to
designate the location where a picture was taken.
While postal addresses can be used to unambigously
identify locations, they are often either unknown
or hard for users to remember. A more natural
(though potentially ambiguous) means of speci-
fying locations is to use landmarks such as ?the
Italian restaurant near Red Rock
cafe on Castro Street? or ?the bakery
near that mall with a Subway and
a 7 Eleven?. A location-based dialog system
that understands referring expressions using land-
marks could lead to more succinct dialogs, higher
recognition accuracy and a greater appearance of
intelligence to the user.
We present a system that performs belief track-
ing over multiple turns of user speech input to infer
the most probable target location. The user inter-
acts with the system through speech in order to spec-
ify a target location, and may include references to
one or more landmarks. Such a system must han-
dle two sources of uncertainty. First, ASR is notori-
ously error-prone and modern ASR engines provide
ranked lists of possible interpretations of speech in-
put rather than single hypotheses. Second, the suit-
ability of a particular landmark or its likelihood of
usage by the speaker depends on a number of factors
such as distance, size and prominence of the land-
mark, familiarity of the user and his expectation of
169
common ground for understanding. These factors,
or at least the resulting variability, must be taken into
account when making inferences about target loca-
tions from landmark-based expressions.
The first source of ambiguity (speech understand-
ing) has been the target of research on belief tracking
(Mehta et al, 2010; Raux and Ma, 2011; Thomson
and Young, 2010). In previous work, the concepts
of interest are entities that are ontologically related
(i.e. with is-a or has-a relations), thus discrete prob-
abilistic graphical models such as DBNs have gen-
erally sufficed as representations. But these mod-
els are ill-suited for dense continuous spatial rela-
tions like the distance between any two locations on
a map. In this paper, we introduce a kernel-based
belief tracker as a probabilistic model for inferring
target locations from (uncertain) landmarks. The
kernel-based representation allows a natural way to
weigh the suitability of a landmark and the speech
understanding confidence. The output of this tracker
is combined with that of a Dynamic Probabilistic
Ontology Tree (DPOT) (Raux and Ma, 2011), which
performs ontological reasoning over other features
of the target location, to give a posterior distribu-
tion over the intended location. We evaluate our ap-
proach on a new corpus of location setting dialogs
specially collected for this work and find it to signif-
icantly outperform a deterministic baseline.
2 Related Work
In the context of a location-based dialog system,
Seltzer et al (2007) describes a speech understand-
ing system designed to recognize street intersec-
tions and map them to a database of valid intersec-
tions using information retrieval techniques. Ro-
bustness is achieved by exploiting both words and
phonetic information at retrieval time, allowing a
soft-matching of the ASR result to the canonical in-
tersection name. Their approach is specifically tar-
geted at intersections, to the exclusion of other types
of landmarks. While intersections are frequently
used as landmarks in North America (where their
study was conducted), this is not always the case
in other cultures, such as Japan (Suzuki and Wak-
abayashi, 2005), where points of interests such as
train stations are more commonly used. Also, their
approach, which is framed as speech understanding,
does not exploit information from previous dialog
turns to infer user intention.
Landmarks have been integrated in route direc-
tions (Pierre-emmanuel Michon, 2001; Tversky and
Lee, 1999) with significant use at origin, destination
and decision points. Further, landmarks have been
found to work better than street signs in wayfind-
ing (Tom and Denis, 2003). The multimodal system
described in (Gruenstein and Seneff, 2007) supports
the use of landmarks from a limited set that the user
specifies by pointing at the map and typing landmark
names. While this allows the landmarks (and their
designations) to be of any kind, the burden of defin-
ing them is on the user.
Spatial language, including landmarks, has also
been the focus of research within the context of
human-robot interaction. (Huang et al, 2010;
MacMahon et al, 2006) describe systems that trans-
late natural language directions into motion paths or
physical actions. These works focus on understand-
ing the structure of (potentially complex) spatial lan-
guage and mapping it into a representation of the
environment. Issues such as imperfect spoken lan-
guage understanding have not been investigated in
this context. Similarly, this vein of spatial language
research has traditionally been conducted on small
artificial worlds with a few dozen objects and places
at most, whereas real-world location-based services
deal with thousands or millions of entities.
3 Hybrid Semantic / Location Belief
Tracking
Our belief tracking system consists of two trackers
running in parallel: a DPOT belief tracker (Raux and
Ma, 2011) and a novel kernel-based location tracker.
The final inference of user intentions is produced by
combining information from the two trackers. The
general idea is to rerank the user goals given spatial
information provided by the location tracker.
3.1 Semantic Belief Tracker
We perform belief tracking over non-landmark con-
cepts such as business name and street using a Dy-
namic Probabilistic Ontology Tree (DPOT) (Raux
and Ma, 2011). A DPOT is a Bayesian Network
composed of a tree-shaped subnetwork representing
the (static) user goal (Goal Network), connected to
170
Figure 1: Top view heat map of spatial distribution with landmarks Subway and 7 Eleven over potential target
places in Mountain View, CA
a series of subnetworks representing the evidence
gathered from each successive dialog turn (Evidence
Networks). Details of the model and an efficient in-
ference method for posterior probability computa-
tions can be found in (Raux and Ma, 2011).
In the context of this paper, the purpose of the
semantic tracker is to update a list of the most
likely target locations using attributes of that
location provided by the user (see Figure 2). In
a local business database, such attributes include
Business Name, Street, Category (e.g.
Japanese restaurant or convenience store), etc.
The structure and parameters of the Goal Network
encode probabilistic ontological relations between
the attributes (e.g. a Mcdonalds would be described
as a fast-food restaurant with high probability)
that can be exploited during inference. These can
be derived from expert knowledge, learned from
data, or as is the case in our experimental system,
populated from a database of local businesses (see
section 4). After each user utterance, the DPOT
outputs a ranked list of user goal hypotheses (an ex-
ample goal hypothesis is [Category=italian
restaurant,Street=castro street]).
Each hypothesis is converted into a query to the
backend database, and the posterior probability of
the hypothesis is split equally among all matching
entries. This results in a ranked list of database
entries corresponding to the system?s belief over
potential target locations, with potentially many
entries having the same probability.
3.2 Kernel-based Location Tracker
Landmark concepts extracted by the Natural Lan-
guage Understanding module (NLU) are passed to
the location tracker, which maintains a distribution
over coordinates of potential target locations. Each
such landmark concept is treated as evidence of spa-
tial proximity of the target to the landmark and the
distribution is accordingly updated. Any location in
the database can serve as a landmark observation,
including major POIs such as train stations or pub-
lic facilities. If the name of a generic chain store
with multiple locations such as Subway is used for
the landmark, then an observation corresponding to
each individual location is added to the tracker.
For each observed landmark `, the location
tracker constructs a 2-dimensional Gaussian kernel
with mean equal to the longitude and latitude of the
landmark (?` = (long`, lat`)) and a fixed covari-
171
Figure 2: Overview of the hybrid semantic / location belief tracking approach; the database entry in shade is the
underlying true target place to which the provided landmark is close
ance matrix ?` for each landmark:
 `(t) =
1
2?|?|1/2 exp( 
1
2(t  ?`)
T? 1` (t  ?`))
This kernel density determines the conditional prob-
ability that the target is at coordinates t =
(longt, latt) given the fixed landmark `. The covari-
ance matrix ?` and hence the shape of the kernel
can be adjusted for different landmarks depending
on considerations such as the familiarity, size and
prominence of the landmark (a large historic monu-
ment is likely to be used as a landmark for locations
much further away than a small corner grocery store)
etc.
The probability density of the location t being the
target is then given by a weighted mixture model:
Pr(t|L) =
X
`2L
w` `(t) (1)
where L is the set of candidate landmarks returned
by the NLU (see Section 4.1) up to the current turn
and w` is set to the confidence score of ` from the
NLU. Thus candidate landmarks that have higher
confidence in the NLU will contribute more strongly
to the total likelihood. Since Pr(t|L) is a den-
sity function, it is unnormalized. In Figure 1, we
show the kernel tracker distribution for a dialog state
where Subway and 7 Eleven are provided as
landmarks.
The kernel density estimator is a simple approach
to probabilistic spatial reasoning. It is easy to imple-
ment and requires only a moderate amount of tuning.
It naturally models evidence from multiple speech
hypotheses and multiple provided landmarks, and
it benefits from accumulated evidence across dia-
log turns. It can also potentially be used to model
more general kinds of spatial expressions by using
appropriate kernel functions. For example, ?Along
Castro street? can be modeled by a Gaussian
with an asymmetric covariance matrix such that the
shape of the resulting distribution is elongated and
concentrated on the street. While ?Two blocks
away from ...? could be modeled by adding
an extra ?negative? density kernel that extends from
172
Figure 3: Overview of the Destination Setting System
the center of the landmark to a distance two blocks
away.
3.3 Combining the Two Trackers
At each turn, the updated results from the Seman-
tic and Location tracker are combined to give a
single ranked list of likely target locations. In
Figure 2, this process is illustrated for a dia-
log turn where two possible concepts are identi-
fied   a category attribute [Category:italian
restaurant] and a landmark [Landmark:red
rock coffee company]. These are passed to
the DPOT tracker and the location tracker respec-
tively. The output of the DPOT is used to retrieve
and score matching database entries. The score for
each entry is reweighted by the kernel density esti-
mator measured at the coordinates of the location 1:
Pr(eij) = (
pi
Ni
)? ? Pr(eij |L) (2)
where Ni is the number of matching database en-
tries retrieved from ith goal hypothesis (having joint
probability pi) and eij is the jth such entry (j 2
[1..Ni]). The exponent ? for the posterior term is
introduced to account for scale difference between
the semantic score and the kernel density.
The set of candidate entries can then be reranked
according to Eq 2 and returned as the output of the
combined belief tracker.
Figure 4: Structure of the Goal Network for the experi-
mental system.
4 Evaluation
4.1 Experimental System
The architecture of our experimental system is
shown in Figure 3. The web client, shown in Figure
5, runs in the participant?s web browser and displays
the target location of the current scenario using the
Google Map API. The user?s goal is to convey this
target location to the system through speech only.
The system backend consists of a database of
2902 businesses located in Mountain View, Cali-
fornia with their name, street, street number, busi-
ness category, latitude and longitude provided. The
grammar rules for the NLU and the probability ta-
bles in the DPOT are populated from this database.
The web client captures the user speech and sends
it to our server with a push-to-talk interface based
on the WAMI toolkit (Gruenstein et al, 2008). The
server uses a commercial cloud-based ASR service
with generic acoustic and language models, which
were not adapted to our task. The n-best list of hy-
potheses from the ASR is sent to our robust natural
1The scores are renormalized to between 0 and1.
173
language understanding module for parsing.
Our NLU uses a hybrid approach combining
a weighted finite-state transducer (WFST) with
string matching based rescoring of the output. The
WFST incorporates out-of-grammar word loops
that allow skipping input words at certain points
in the parse2. This parser robustly maps free form
utterances (e.g. ?Okay let?s go to that
Italian place near, uh..., Red
Rock Cafe, on Castro?) to semantic frames
(e.g. [Category=italian restaurant,
Street=castro street, Landmark=red
rock coffee company]).
The NLU confidence score is computed based on
the number of words skipped while parsing, and
how close the important concept words match the
canonical phrases found in the database. For in-
stance, ?Red Rock Cafe? matches the canoni-
cal name ?Red Rock Coffee Company? with
high confidence because rare words (Red, Rock)
are identical, and differing but common words
(Cafe, Coffee, Company) have a low weight
in the score. The string matching score is based
on the term-frequency/inverse document frequency
(TF-IDF) metric commonly used in information re-
trieval. In our case, the weight of different terms
(IDF) is estimated based on their frequency of occur-
rence in different database entries (i.e. how uniquely
they describe a matching entry). We use the sec-
ondstring open-source library (Cohen et al, 2003)
for string matching. For any ASR hypothesis, the
NLU is likely to generate several parses which are
all merged in a global list of candidate parses.
For each candidate parse, the system generates
a set of dialog acts (one per concept in the parse)
which are input to the belief tracker with their confi-
dence score. Following the approach described in
section 3, dialog acts corresponding to the Land-
mark concept are sent to the kernel-based location
belief tracker, while all other concepts are sent to a
Dynamic Probabilistic Ontology Trees (DPOT) se-
mantic belief tracker, whose structure is shown in
Figure 4. We use a two-level tree. The value of
the root node (Id) is never directly observed and
represents the database entry targeted by the user.
2This module is implemented using the OpenFST library
(Allauzen et al, 2007)
The leaf nodes correspond to the relevant attributes
Name, Category, and Street. For any database
entry e, attribute a and value of that attribute va, the
conditional probability P (a = va|Id = e) is set to 1
if the value of a is va for entry e in the database, and
to 0 otherwise. For attributes such as Category,
which allow several possible values for each entry,
the probability is split equally among valid values.
After each user utterance, the network is augmented
with a new Evidence Network capturing the possi-
ble interpretations and their likelihood, as computed
by the NLU. The posterior probability distribution
over user goals is computed and rescored using the
kernel-based location tracker.
Finally, the Response Generator takes the highest
scoring target location from the belief tracker and
sends it back to the web client which displays it on
the map and also indicates what are the values of
the Name, Category, and Street concepts for
the top belief (see Figure 5). If the top belief lo-
cation does not match the goal of the scenario, the
user can speak again to refine or correct the system
belief. After the user has spoken 5 utterances, they
also get the choice of moving on to the next scenario
(in which case the dialog is considered a failure).
4.2 Data collection
To evaluate our approach, we ran a data collection
experiment using the Amazon Mechanical Turk on-
line marketplace. We defined 20 scenarios grouped
into 4 Human Intelligence Tasks (HITs). Figure 5
shows a screen shot of the web interface to the sys-
tem. In each scenario, the worker is given a target
location to describe by referring to nearby landmark
information. The target locations were chosen so as
to cover a variety of business categories and nearby
landmarks. The compensation for completing each
set of 5 scenarios is 1 US dollar. Before their first
scenario, workers are shown a video explaining the
goal of the task and how to use the interface, in
which they are specifically encouraged to use land-
marks in their descriptions.
At the beginning of each scenario, the target
location is displayed on the map with a call-
out containing a short description using either a
generic category (e.g. Italian restaurant,
Convenience store) or the name of a chain
store (e.g. Subway, Mcdonalds). The worker
174
Figure 5: Screen capture of the data collection web interface where the target location is an Italian restaurant (in
green, underlying target place is [Ristorante Don Giovanni]) and after the first turn user input ?Italian
restaurant? with a system belief [Frankie, Johnnie & Luigi, Too] in blue returned without any land-
mark information provided so far
then interacts with the system described in section
4.1 until either the system?s top belief matches the
target location, or they decide to skip the scenario.
4.3 Data Statistics
Overall, 99 workers participated in the data col-
lection, providing 948 dialogs (2,869 utterances, 3
turns per scenario on average), which two of the
authors manually transcribed and annotated for di-
alog acts. 76% of the dialogs (46% of utterances)
contained a reference to a landmark. Other strate-
gies commonly used by workers to uniquely identify
a location include using a category or chain name
and a street, as well as explicitly mentioning the tar-
get business name (although workers were explicitly
discouraged form doing so). Figure 7 in appendix
provides one example dialog from the corpus.
Overall, the workers provided 203 unique land-
marks, of which 143 (70%) are in the database.
Workers were able to set the target destination
within 5 turns in 60.1% of the dialogs, which we
hereafter refer to as task successes. However, based
on the manual transcripts, 19.0% of the dialogs
could not have succeeded with the current system
because the workers used landmark or attributes that
do not appear in the database. Since the focus of this
study is robustness rather than coverage, we base our
evaluation on the remaining 768 dialogs, which we
split between a development set of 74 dialogs and
a test set of 694 dialogs. On this test set, the live
system has a task success rate of 70.6%. By inspect-
ing the log files, we noticed that runtime issues such
as timeouts prevented the system from getting any
belief from the belief tracker in 6.3% of the dialogs.
The mean Word Error Rate (WER) per worker on
the test set is 27.5%. There was significant variabil-
ity across workers, with a standard deviation 20.7%.
Besides the usual factors such as acoustic noise and
non-native accents, many of the errors came from
the misrecognition of business names, due to the fact
that ASR uses an open-ended language model that is
tuned neither to Mountain View, nor to businesses,
nor to the kind of utterances that our set up tends
to yield, which is a realistic situation for large scale
practical applications.
Concept precision of the top scoring NLU hypoth-
esis is 73.0% and recall is 57.7%. However, when
considering the full list of NLU hypotheses and us-
ing an oracle to select the best one for each turn,
precision increases to 89.3% and recall to 66.2%,
underscoring the potential of using multiple input
hypotheses in the belief tracker.
175
42% 
50% 
69% 
83% 
0% 
10% 
20% 
30% 
40% 
50% 
60% 
70% 
80% 
90% 
W/o landmarks 
baseline 
W/o landmarks BT W/ landmarks 
baseline 
W/ landmarks BT 
Tas
k S
ucc
ess
 Ra
te 
Figure 6: Batch evaluation of the proposed (BT) and baseline approaches with and without landmark information.
4.4 Batch Results
To further analyze the performance of our approach,
we conducted a series of batch experiments on the
data collected with the runtime system. We first
tuned the parameters of the belief tracker ? and ?l
(see section 3) on the development set (? = 3 and
?l corresponds to a circular Gaussian with standard
deviation 500 meters).
We compare the tuned proposed belief tracking
system (labeled BT) with three other versions. First,
we define a deterministic baseline system which, at
each turn, updates its belief by overwriting each con-
cept?s value with the value found in the top NLU
hypothesis. Based on this (single) user goal hy-
pothesis, we query the database to retrieve match-
ing entries. If the current goal hypothesis con-
tains a Landmark concept, the baseline system se-
lects the matching entry that is closest to any loca-
tion matching the landmark name, by computing the
pairwise distance between candidate target locations
and landmarks.
We also compute the performance of both the
baseline and our proposed approach without us-
ing landmark information at all. In these versions,
the belief over the attributes (Name, Street, and
Category) is updated according to either the top
NLU hypothesis (baseline) or the DPOT model (BT)
and the first matching database entry is returned, ig-
noring any landmark information.
Figure 6 shows the task success of each of the four
versions on the test set. First, it is clear that land-
mark information is critical to complete the tasks in
this corpus since both systems ignoring landmarks
perform significantly worse than their counterparts.
Second, the belief tracking approach significantly
outperforms the deterministic baseline (83.0% vs
69.3%, p < 0.001 using sign test for matched pairs).
To further analyze the performance of the sys-
tem in different input conditions, we split the di-
alogs based on their measured concept accuracy (ex-
pressed in terms of concept F-measure). All dialogs
with an F-measure higher than the median (70.0%)
are labeled as high-accuracy, while the other half of
the data is labeled as low-accuracy. While both the
proposed approach and the baseline perform simi-
larly well for high-accuracy dialogs (task success of
resp. 96.0% and 92.8%, difference is not statisti-
cally significant), the difference is much larger for
low-accuracy dialogs (70.0% vs 45.8%, p < 0.001)
confirming the robustness of the landmark-based be-
lief tracking approach when confronted with poor
input conditions.
5 Conclusion
In this paper, we have explored the possibilities of
incorporating spatial information into belief tracking
in spoken dialog systems. We proposed a landmark-
based location tracker which can be combined with
a semantic belief tracker to output inferred joint user
goal. Based on the results obtained from our batch
experiments, we conclude that integrating spatial in-
formation into a location-based dialog system could
improve the overall accuracy of belief tracking sig-
nificantly.
176
References
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Woj-
ciech Skut, and Mehryar Mohri. 2007. Openfst: A
general and efficient weighted finite-state transducer
library. In Proceedings of the Ninth International
Conference on Implementation and Application of Au-
tomata (CIAA) Lecture Notes in Computer Science,
volume 4783, pages 11?23. Springer.
W.W. Cohen, P. Ravikumar, and S.E. Fienberg. 2003.
A comparison of string distance metrics for name-
matching tasks. In Proceedings of the IJCAI-2003
Workshop on Information Integration on the Web
(IIWeb-03), pages 73?78.
Alexander Gruenstein and Stephanie Seneff. 2007. Re-
leasing a multimodal dialogue system into the wild:
User support mechanisms. In In Proceedings of the
8th SIGdial Workshop on Discourse and Dialogue,
pages 111?119, September.
A. Gruenstein, I. McGraw, and I. Badr. 2008. The wami
toolkit for developing, deploying, and evaluating web-
accessible multimodal interfaces. In Proceedings of
the 10th international conference on Multimodal in-
terfaces, pages 141?148. ACM.
Albert Huang, Stefanie Tellex, Abe Bachrach, Thomas
Kollar, Deb Roy, and Nick Roy. 2010. Natural lan-
guage command of an autonomous micro-air vehicle.
In International Conference on Intelligent Robots and
Systems (IROS).
M. MacMahon, B. Stankiewicz, and B. Kuipers. 2006.
Walk the talk: Connecting language, knowledge, and
action in route instructions. In Proceedings of the
National Conference on Artificial Intelligence, vol-
ume 21, page 1475. Menlo Park, CA; Cambridge, MA;
London; AAAI Press; MIT Press; 1999.
N. Mehta, R. Gupta, A. Raux, D. Ramachandran, and
S. Krawczyk. 2010. Probabilistic ontology trees for
belief tracking in dialog systems. In Proceedings of
the 11th Annual Meeting of the Special Interest Group
on Discourse and Dialogue, pages 37?46. Association
for Computational Linguistics.
Michel Denis Pierre-emmanuel Michon. 2001. When
and why are visual landmarks used in giving direc-
tions? In D. R. Montello, editor, Spatial Information
Theory, Volume 2205 of Lecture Notes in Computer
Science, pages 292?305. Springer, Berlin.
A. Raux and Y. Ma. 2011. Efficient probabilistic track-
ing of user goal and dialog history for spoken dialog
systems. In Proceedings of Interspeech 2011.
Michael L. Seltzer, Yun-Cheng Ju, Ivan Tashev, and Alex
Acero. 2007. Robust location understanding in spo-
ken dialog systems using intersections. In Proceed-
ings of Interspeech 2007, pages 2813?2816.
K. Suzuki and Y. Wakabayashi. 2005. Cultural dif-
ferences of spatial descriptions in tourist guidebooks.
Spatial Cognition IV. Reasoning, Action, and Interac-
tion, 3343:147?164.
B. Thomson and S. Young. 2010. Bayesian update of di-
alogue state: A pomdp framework for spoken dialogue
systems. Computer Speech & Language, 24(4):562?
588.
Ariane Tom and Michel Denis. 2003. Referring to land-
mark or street information in route directions: What
difference does it make? Spatial Information The-
ory. Foundations of Geoghraphic Information Science,
Lecture Notes in Computer Science, 2825/2003:362?
374.
Barbara Tversky and Paul U. Lee. 1999. Pictorial and
verbal tools for conveying routes. In Proceedings of
the International Conference on Spatial Information
Theory: Cognitive and Computational Foundations
of Geographic Information Science(COSIT). Springer-
Verlag London.
177
User: &Italian&restaurant&near&
ASR: %italian%restaurant%near%
NLU: %Category=Italian%Restaurant%
Category %Italian'Restaurant'
Target !Dominos!Pizza!
Category %Italian'Restaurant'
Target !Dominos!Pizza!
User: &Italian&restaurant&near&Kappo&Nami&Nami&
ASR: %italian%restaurant%near%camp%to%numa%numa%
NLU: %Category=Italian%Restaurant,%Street=Camp%Avenue%
%Category=Italian%Restaurant,%Landmark=Jefunira%Camp%
Category %Italian'Restaurant%%
Street %Camp'Avenue'
Target &No!match!
Category %Italian'Restaurant'
Landmark %Jefunira'Camp'
Target ! !Maldonado?s%
User: &Italian&restaurant&near&Tempta5ons&
ASR: %italian%restaurant%near%temptaAons%
NLU: %Category=Italian%Restaurant,%Landmark=TemptaAons%
Category %Italian'Restaurant'
Street %Camp'Avenue'
Landmark %Tempta5ons'
Target &No!match!
Category %Italian'Restaurant'
Landmark %Jefunira'Camp,'Tempta5ons'
Target &Don!Giovanni!
Baseline' DPOT+Kernels'
Example&Dialog
Figure 7: Comparison between baseline and proposed method on an example dialog whose underlying true target is
an Italian restaurant called Don Giovanni.
178
Proceedings of the SIGDIAL 2014 Conference, pages 22?31,
Philadelphia, U.S.A., 18-20 June 2014.
c?2014 Association for Computational Linguistics
Situated Language Understanding at 25 Miles per Hour
Teruhisa Misu, Antoine Raux
?
, Rakesh Gupta
Honda Research Institute USA
425 National Avenue
Mountain View, CA 94040
tmisu@hra.com
Ian Lane
Carnegie Mellon University
NASA Ames Research Park
Moffett Field, CA 93085
Abstract
In this paper, we address issues in situ-
ated language understanding in a rapidly
changing environment ? a moving car.
Specifically, we propose methods for un-
derstanding user queries about specific tar-
get buildings in their surroundings. Unlike
previous studies on physically situated in-
teractions such as interaction with mobile
robots, the task is very sensitive to tim-
ing because the spatial relation between
the car and the target is changing while
the user is speaking. We collected situated
utterances from drivers using our research
system, Townsurfer, which is embedded
in a real vehicle. Based on this data, we
analyze the timing of user queries, spa-
tial relationships between the car and tar-
gets, head pose of the user, and linguis-
tic cues. Optimized on the data, our al-
gorithms improved the target identification
rate by 24.1% absolute.
1 Introduction
Recent advances in sensing technologies have en-
abled researchers to explore applications that re-
quire a clear awareness of the systems? dynamic
context and physical surroundings. Such appli-
cations include multi-participant conversation sys-
tems (Bohus and Horvitz, 2009) and human-robot
interaction (Tellex et al., 2011; Sugiura et al.,
2011). The general problem of understanding and
interacting with human users in such environments
is referred to as situated interaction.
We address yet another environment, where sit-
uated interactions takes place ? a moving car. In
the previous work, we collected over 60 hours of
in-car human-human interactions, where drivers
interact with an expert co-pilot sitting next to them
in the vehicle (Cohen et al., 2014). One of the
?
Currently with Lenovo.
insights from the analysis on this corpus is that
drivers frequently use referring expressions about
their surroundings. (e.g. What is that big building
on the right?) Based on this insight, we have de-
veloped Townsurfer (Lane et al., 2012; Misu et
al., 2013), a situated in-car intelligent assistant.
Using geo-location information, the system can
answer user queries/questions that contain object
references about points-of-interest (POIs) in their
surroundings. We use driver (user) face orienta-
tion to understand their queries and provide the re-
quested information about the POI they are look-
ing at. We have previously demonstrated and eval-
uated the system in a simulated environment (Lane
et al., 2012). In this paper, we evaluate its utility
in real driving situations.
Compared to conventional situated dialog tasks,
query understanding in our task is expected to be
more time sensitive, due to the rapidly changing
environment while driving. Typically, a car will
move 10 meters in one second while driving at 25
mi/h. So timing can be a crucial factor. In addi-
tion, it is not well understood what kind of linguis-
tic cues are naturally provided by drivers, and their
contributions to situated language understanding
in such an environment. To the best of our knowl-
edge, this is the first study that tackles the issue of
situated language understanding in rapidly moving
vehicles.
In this paper, we first present an overview of the
Townsurfer in-car spoken dialog system (Section
2). Based on our data collection using the sys-
tem, we analyze user behavior while using the sys-
tem focusing on language understanding (Section
3). Specifically, we answer the following research
questions about the task and the system through
data collection and analysis:
1. Is timing an important factor of situated lan-
guage understanding?
2. Does head pose play an important role in lan-
guage understanding? Or is spatial distance
information enough?
22
Speech recognition
Natural language understanding
Gaze (Head-pose) estimation
3) POI Posterior calculation            by Belief tracking
1) (Candidate)     POI look-up
Microphone
Depth sensor
Sensors Sensor signal understanding POI identification (situated understanding)
Speech
Gaze
2) POI score (prior) calculation
Understanding result (POI with maximum posterior)
Geo-location estimation Semantic         geo-spatial database
GPS
IMU
Geo-location
Figure 1: System overview of Townsurfer
Table 1: Example dialog with Townsurfer
U1: What is that place. (POI in gaze)
S1: This is Specialty Cafe, a mid-scale coffee
shop that serves sandwiches.
U2: What is its (POI in dialog history) rating.
S2: The rating of Specialty Cafe is above av-
erage.
U3: How about that one on the left.
(POI located on the left)
S3: This is Roger?s Deli, a low-priced restau-
rant that serves American food.
3. What is the role of linguistic cues in this task?
What kinds of linguistic cues do drivers nat-
urally provide?
Based on the hypothesis obtained from the analy-
sis for these questions, we propose methods to im-
prove situated language understanding (Section 4),
and analyze their contributions based on the col-
lected data (Sections 5 and 6). We then clarify our
research contributions through discussion (Section
7) and comparison with related studies (Section 8).
2 Architecture and Hardware of
Townsurfer
The system uses three main input modalities,
speech, geo-location, and head pose. Speech is
the main input modality of the system. It is used to
trigger interactions with the system. User speech
is recognized, then requested concepts/values are
extracted. Geo-location and head pose informa-
tion are used to understand the target POI of the
user query. An overview of the system with a pro-
cess flow is illustrated in Figure 1 and an exam-
ple dialog with the system is shown in Table 1. A
video of an example dialog is also attached.
In this paper, we address issues in identify-
ing user intended POI, which is a form of ref-
erence resolution using multi-modal information
sources
1
. The POI identification process consists
of the following three steps (cf. Figure 1). This
is similar to but different from our previous work
on landmark-based destination setting (Ma et al.,
2012).
1) The system lists candidate POIs based on geo-
location at the timing of a driver query. Rela-
tive positions of POIs to the car are also cal-
culated based on geo-location and the head-
ing of the car.
2). Based on spatial linguistic cues in the user
utterance (e.g. to my right, on the left), a
2D scoring function is selected to identify ar-
eas where the target POI is likely to be. This
function takes into account the position of the
POI relative to the car, as well as driver head
pose. Scores for all candidate POIs are cal-
culated.
3) Posterior probabilities of each POI are cal-
culated using the score of step 2 as prior,
and non-spatial linguistic information (e.g.
POI categories, building properties) as obser-
vations. This posterior calculation is com-
puted using our Bayesian belief tracker called
DPOT (Raux and Ma, 2011).
The details are explained in Section 4.
System hardware consists of a 3D depth sen-
sor (Primesense Carmine 1.09), a USB GPS (BU-
353S4), an IMU sensor (3DM-GX3-25) and a
close talk microphone (plantronics Voyage Leg-
1
We do not deal with issues in language understanding
related to dialog history and query type. (e.g. General infor-
mation request such as U1 vs request about specific property
of POI such as U2 in Table 1)
23
end UC). These consumer grade sensors are in-
stalled in our Honda Pilot experiment car. We
use Point Cloud Library (PCL) for the face direc-
tion estimation. Geo-location is estimated based
on Extended Kalman filter-based algorithm using
GPS and gyro information as input at 1.5 Hz. The
system is implemented based on the Robot Oper-
ating System ROS (Quigley et al., 2009). Each
component is implemented as a node of ROS, and
communications between the nodes are performed
using the standard message passing mechanisms
in ROS.
3 Data Collection and Analysis
3.1 Collection Setting
We collected data using a test route. The route
passes through downtown Mountain View
2
and
residential area around Honda Research Institute.
We manually constructed our database containing
250 POIs (businesses such as restaurants, compa-
nies) in this area. Each database entry (POI) has
name, geo-location, category and property infor-
mation explained in Section 3.4. POI geo-location
is represented as a latitude-longitude pair (e.g.
37.4010,-122.0539). Size and shape of buildings
are not taken into account. It takes about 30 min-
utes to drive the route. The major difference be-
tween residential area and downtown is the POI
density. While each POI in downtown has on aver-
age 7.2 other POIs within 50 meters, in residential
area POIs have only 1.9 neighbors. Speed limits
also differ between the two (35 mi/h vs 25 mi/h).
We collected data from 14 subjects. They were
asked to drive the test route and make queries
about surrounding businesses. We showed a demo
video
3
of the system to the users before starting the
data collection. We also told them that the objec-
tive is a data collection for a situated spoken dia-
log system, rather than the evaluation of the whole
system. We asked subjects to include the full de-
scription of the target POI within a single utterance
to avoid queries whose understanding requires di-
alog history information
4
. Although the system
answered based on the baseline strategy explained
in Section 4.1, we asked subjects to ignore the sys-
tem responses.
As a result, we collected 399 queries with a
valid target POI. Queries about businesses that do
2
We assumed that a POI is in downtown when it is located
within the rectangle by geo-location coordinates (37.3902, -
122.0827) and (37.3954, -122.0760).
3
not the attached one.
4
Understanding including dialog history information is
our future work.
POI
x
y ?
face direction
target 
direction
Heading 
direction
Figure 2: Parameters used to calculate POI score
(prior)
?  :   rightX:   left+:   no cue
Distance (m)y
RightLeft Distance (m)
x
Figure 3: Target POI positions
not exist on our database (typically a vacant store)
were excluded. The data contains 171 queries in
downtown and 228 in residential area. The queries
were transcribed and the user-intended POIs were
manually annotated by confirming the intended
target POI with the subjects after the data collec-
tion based on a video taken during the drive.
3.2 Analysis of Spatial Relation of POI and
Head Pose
We first analyze the spatial relation between posi-
tion cues (right/left) and the position of the user-
intended target POIs Out of the collected 399
queries, 237 (59.4%) of them contain either right
or left position cue (e.g. What is that on the left?).
The relation between the position cues (cf. Figure
2) and POI positions at start-of-speech timing
5
is
plotted in Figure 3. The X-axis is a lateral distance
(a distance in the direction orthogonal to the head-
ing; a positive value means the right direction) and
the Y-axis is an axial distance (a distance in the
heading direction; a negative value means the POI
is in back of the car. ). The most obvious finding
from the scatter plot is that right and left are pow-
5
Specifically, the latest GPS and face direction informa-
tion at that timing is used.
24
Table 2: Comparison of average and standard deviation of distance (in meter) of POI form the car
ASR result timing Start-of-speech timing
Position cue Site Ave dist. Std dist. Ave dist. Std dist.
Right/left Downtown 17.5 31.0 31.9 28.3
Residential 22.0 36.3 45.2 36.5
No right/left Downtown 17.4 27.8 31.1 26.5
cue Residential 38.3 45.9 52.3 43.4
Distance (m)y
?angular difference (degree)
Figure 4: Relation between POI positions and
head pose
erful cues for the system to identify target POIs.
We can also see that the POI position distribution
has a large standard deviation. This is partly be-
cause the route has multiple sites from downtown
and residential area. Interestingly, while the aver-
age distance to the target POI in downtown is 37.0
meters, that of residential area is 57.4 meters.
We also analyze the relation between face di-
rection and POI positions. Figure 4 plots the re-
lation between the axial distance and the angular
difference ? (between the user face direction and
the target POI direction) (cf. Figure 2). The scat-
ter plot suggests that the angular differences for
distant target POIs is often small. For close target
POIs the angular differences are larger and have a
large variance
6
.
3.3 Analysis of Timing
Referring expressions such as ?the building on the
right? must be resolved with respect to the context
in which the user intended. However, in a moving
car, such a context (i.e. the position of the car and
the situation in the surroundings) can be very dif-
ferent between the time when the user starts speak-
ing the sentence and the time they finish speaking
it. Therefore, situated understanding must be very
time sensitive.
To confirm and investigate this issue, we ana-
lyze the difference in the POI positions between
the time the ASR result is output vs the time the
user actually started speaking. The hypothesis is
6
We will discuss the reason for this in Section 6.2.
Table 3: User-provided linguistic cues
Category of linguistic cue Percentage
used (%)
Relative position to the car (right/left) 59.4
Business category (e.g. restaurant, cafe) 31.8
Color of the POI (e.g. green, yellow) 12.8
Cuisine (e.g. Chinese, Japanese, Mexican) 8.3
Equipments (e.g. awning, outside seating) 7.2
Relative position to the road (e.g. corner) 6.5
that the latter yields a more accurate context in
which to interpret the user sentence. In contrast,
our baseline system uses the more straightforward
approach of resolving expressions using the con-
text at the time of resolution, i.e. whenever the
ASR/NLU has finished processing an utterance
(hereafter ?ASR results timing?).
Specifically, we compare the average axial dis-
tance to the target POIs and its standard deviation
between these two timings. Table 2 lists these fig-
ures broken down by position cue types and sites.
The average axial distance from the car to the tar-
get POIs is often small at the ASR result timing,
but the standard deviation is generally small at the
start-of-speech timing. This indicates that the tar-
get POI positions at the start-of-speech timing is
more consistent across users and sentence lengths
than that at the ASR result timing. This result indi-
cates the presence of a better POI likelihood func-
tion using the context (i.e. car position and orien-
tation) at the start-of-speech timing than using the
ASR result timing.
3.4 Analysis of Linguistic Cues
We then analyze the linguistic cues provided by
the users. Here, we focus on objective and sta-
ble cues. We exclude subjective cues (e.g. big,
beautiful, colorful) and cues that might change in
a short period of time (e.g. with a woman dressed
in green in front). We have categorized the linguis-
tic cues used to describe the target POIs. Table 3
lists the cue types and the percentage of user utter-
ances containing each cue type.
The cues that the users most often provided con-
cern POI position related to the car (right and left).
Nearly 60% of queries included this type of cue
and every subject provided it at least once. The
second most frequent cue is category of business,
especially in downtown. Users also provided col-
25
ors of POIs. Other cues include cuisine, equip-
ments, relative position to the road (e.g. on the
corner).
Another interesting finding from the analysis is
that the users provided more linguistic cues with
increasing candidate POIs in their field of view.
Actually, the users provided 1.51 categories in av-
erage per query in downtown, while they provided
1.03 categories in residential area. (cf. POI den-
sity in Section 3.2: 7.2 vs 1.9) This indicates that
users provide cues considering environment com-
plexity.
4 Methods for Situated Language
Understanding
4.1 Baseline Strategy
We use our previous version (Misu et al., 2013)
as the baseline system for situated language un-
derstanding. The baseline strategy consists of the
following three paragraphs, which correspond to
the process 1)-3) in Section 2 and Figure 1.
The system makes a POI look-up based on the
geo-location information at the time ASR result
is obtained. The search range of candidate POIs
is within the range (relative geo-location of POIs
against the car location) of -50 to 200 meters in
the travelling direction and 100 meters to the left
and 100 meters to the right in the lateral direction.
The ASR result timing is also used to measure the
distances to the candidate POIs.
POI priors are calculated based on the distance
from the car (= axial distance) based on ?the closer
to the car the likely? principle. We use a likelihood
function inversely proportional to the distance. We
use position cues simply to remove POIs from a
list of candidates. For example ?right? position
cue is used to remove candidate POIs that are lo-
cated on< 0 position in the lateral distance. When
no right/left cue is provided, POIs outside of 45
degrees from the face direction are removed from
the list of candidates.
No linguistic cues except right/left are used to
calculate POI posterior probabilities. So, the sys-
tem selects the POI with the highest prior (POI
score) as the language understanding result.
4.2 Strategies Toward Better Situated
Language Understanding
To achieve better situated language understanding
(POI identification) based on the findings of the
analysis in Section 3, we modify steps 1)-3) as fol-
lows:
1. Using start-of-speech timing for the POI
prior calculation
Distance (m)y
?  :   rightX:   left
RightLeft Distance (m)x
Figure 5: Example GMM fitting
2. Gaussian mixture model (GMM)-based POI
probability (prior) calculation
3. Linguistic cues for the posterior calculation.
We use the start-of-speech timing instead of the
time ASR result is output. Because the standard
deviations of the POI distances are small (cf. Sec-
tion 3.2), we expect that a better POI probability
score estimation with the POI positions at this tim-
ing in the subsequent processes than the positions
at the ASR result timing. The POI look-up range
is the same as the baseline.
We apply Gaussian mixture model (GMM) with
diagonal covariance matrices over the input pa-
rameter space. The POI probability (prior) is cal-
culated based on these Gaussians. We use two in-
put parameters of the lateral and axial distances for
queries with right/left cue, and three parameters of
the lateral and axial distances and the difference
in degree between the target and head pose direc-
tions for queries without right/left cue. (The effect
of the parameters is discussed later in Section 6.2.)
We empirically set the number of Gaussian com-
ponents to 2. An example GMM fitting to the POI
positions for queries with right and left cues is il-
lustrated in Figures 5. The center of ellipse is the
mean of the Gaussian.
We use the five linguistic cue categories of Sec-
tion 3.4 for the posterior calculation by the belief
tracker. In the following experiments, we use ei-
ther 1 or 0 as a likelihood of natural language un-
derstanding (NLU) observation. The likelihood
for the category value is 1 if a user query (NLU
result) contains the target value, otherwise 0. This
corresponds to a strategy of simply removing can-
didate POIs that do not have the category values
specified by the user. Here, we assume a clean POI
database with all their properties annotated manu-
ally.
26
Table 4: Comparison of POI identification rate
Method Success
rate (%)
right/left linguistic cues,
the-closer-the-likely likelihood, 43.1
ASR result timing) (Baseline)
1) Start-of-speech timing 42.9
2) GMM-based likelihood 47.9
3) Linguistic cues 54.6
1) + 2) 50.6
1) + 3) 54.4
2) + 3) 62.2
1) + 2) + 3) 67.2
5 Experiments
We use manual transcriptions and natural language
understanding results of the user queries to focus
our evaluations on the issues listed in Section 1.
We evaluate the situated language understanding
(POI identification) performance based on cross
validation. We use the data from 13 users to train
GMM parameters and to define a set of possible
linguistic values, and the data from the remaining
user for evaluation. We train the model parameters
of the GMM using the EM algorithm. Knowledge
about the sites (downtown or residential area) is
not used in the training
7
.
We do not set a threshold for the presentation.
We judge the system successfully understands a
user query when the posterior of the target (user-
intended) POI is the highest. The chance rate,
given by the average of the inverse number of can-
didate POIs in the POI look-up is 10.0%.
6 Analysis of the Results
We first analyze the effect of our three methods
described in Section 4.2. The results are listed in
Table 4.
Simply using the POI positions at the start-of-
speech timing instead of those of the ASR result
timing did not lead to an improvement. This re-
sult is reasonable because the distances to target
POIs are often smaller at the ASR result timing
as we showed in Table 2. However, we achieved
a better improvement (7.5% over the baseline) by
combining it with the GMM-based likelihood cal-
culation. The results supports our Section 3.3 hy-
pothesis that the POI position is less dependent
on users/scenes at the start-of-speech timing. The
linguistic cues were the most powerful informa-
7
The performance was better when the knowledge was not
used.
Confusion
Linguistic cue
Localization error
User error
Figure 6: Breakdown of error causes
tion for this task. The improvement over the base-
line was 11.5%. By using these three methods to-
gether, we obtained more than additive improve-
ment of 24.1% in the POI identification rate over
the baseline
8
. The success rates per site were
60.8% in downtown and 71.9% in residential area.
6.1 Error Analysis
To analyze the causes of the remaining errors, we
have categorized the errors into the following four
categories:
1. Ambiguous references: There were multi-
ple POIs that matched the user query. (e.g.
another yellow building sat next to the target)
2. Linguistic cue: The driver used undefined
linguistic cues such subjective expressions or
dynamic references objects (e.g. optometrist,
across the street, colorful)
3. Localization error: Errors in estimating
geo-location or heading of the car.
4. User error: There were errors in the user
descriptions (e.g. user misunderstood the
neighbor POI?s outside seating as the tar-
get?s)
The distribution of error causes is illustrated in
Figure 6. More than half of the errors are due
to reference ambiguity. These errors are expected
to be resolved through clarification dialogs. (e.g.
asking user ?Did you mean the one in front or
back??) Linguistic errors might be partly resolved
by using a better database with detailed category
information. For dynamic references and subjec-
tive cues, use of image processing techniques will
help. Localization errors can be solved by using
high-quality GPS and IMU sensors. User errors
were rare and only made in downtown.
6.2 Breakdown of Effect of the Spatial
Distance and Head Pose
We then evaluate the features used for the POI
prior calculation to investigate the effect of the in-
put parameters of the lateral and axial distances
8
For reference, the performances of ?1) + 2) + 3)? were
62.9%, 67.2%, 66.1%, 67.2%, and 66.2% when the number
of Gaussian components were 1, 2, 3, 4, and 5.
27
Table 5: Relation between the parameters used for
the POI identification and success rates (%)
query type
parameters used right/left no cue
lateral (x) distance 58.6 51.2
axial (y) distance 59.5 53.7
face direction 43.3 44.4
lateral + axial (x+ y) 73.8 54.3
lateral (x) + face direction 57.8 48.1
axial (y) + face direction 59.1 54.9
lateral + axial + face 68.4 57.4
and the difference in degree between the target
and user face direction angles. Table 5 lists the
relationship between the parameters used for the
GMM-based likelihood calculation and the POI
identification performances
9
.
The results indicate that the axial distance is
the most important parameter. We got a slight
improvement by using the face direction informa-
tion for the queries without right/left cue, but the
improvement was not significant. On the other
hand, use of face direction information for the
right/left queries clearly degraded the POI iden-
tification performance. We think this is because
the users finished looking at the POI and returned
the face to the front when they started speaking,
thus they explicitly provided right/left information
to the system. However, we believe that using a
long-term trajectory of the user face direction will
contribute to an improve in the POI identification
performance.
6.3 Breakdown of the Effect of Linguistic
Cues
We then evaluate the effect of the linguistic cues
per category. Table 6 lists the relationship between
the categories used for the posterior calculation
and the success rates. There is a strong correlation
between the frequency of the cues used (cf. Table
3) and their contributions to the improvement in
success rate. For example, business category in-
formation contributed the most, boosting the per-
formance by 8.5%.
Another point we note is that the contribution of
business category and cuisine categories is large.
Because other categories (e.g. color) are not read-
ily available in a public POI database (e.g. Google
Places API, Yelp API), we can obtain reasonable
performance without using a special database or
9
Note that, we first determine the function to calculate
POI scores (priors) based on the position cues, then calculate
scores with the selected function.
Table 6: Effect of linguistic cues
linguistic cue Success
category used rate (%)
No linguistic cues (*) 50.6
(*) + Business category (e.g. cafe) 59.1
(*) + Color of the POI (e.g. green) 57.6
(*) + Cuisine (e.g. Chinese) 54.1
(*) + Equipments (e.g. awning) 53.9
(*) + Relative position (e.g. corner) 51.4
image processing.
We also found that linguistic cues were espe-
cially effective in downtown. Actually, while the
improvement
10
was 20.0% in downtown that for
residential area was 14.4%. This mainly would be
because the users provided more linguistic cues in
downtown considering the difficulty of the task.
6.4 Using Speech Recognition Results
We evaluate the degradation by using automatic
speech recognition (ASR) results. We use Google
ASR
11
and Julius (Kawahara et al., 2004) speech
recognition system with a language model trained
from 38K example sentences generated from a
grammar. An acoustic model trained from the
WSJ speech corpus is used. Note that they are
not necessarily the best system for this domain.
Google ASR uses a general language model for
dictation and Julius uses a mismatched acoustic
model in terms of the noise condition.
The query success rate was 56.3% for Julius and
60.3% for Google ASR. We got ASR accuracies
of 77.9% and 80.4% respectively. We believe the
performance will improve when N-best hypothe-
ses with confidence scores are used in the posterior
calculating using the belief tracker.
7 Discussion
The main limitation of this work comes from the
small amount of data that we were able to collect.
It is not clear how the results obtained here would
generalize to other sites, POI density, velocities
and sensor performances. Also, results might de-
pend on experimental conditions, such as weather,
hour, season. Hyper-parameters such as the opti-
mal number of Gaussian components might have
to be adapted to different situations. We there-
fore acknowledge that the scenes we experimented
are only a limited cases of daily driving activities.
10
1) + 2) vs 1) + 2) + 3).
11
Although it is not realistic to use cloud-based speech
recognition system considering the current latency, we use
this as a reference system.
28
However, the methods we propose are general and
our findings should be verifiable without loss of
generality by collecting more data and using more
input parameters (e.g. velocity) for the POI prior
calculation.
In addition, much future work remains to realize
a natural interaction with the system, such as tak-
ing into account dialog history and selecting opti-
mal system responses. On the other hand, we be-
lieve this is one of the best platform to investigate
situated interactions. The major topics that we are
going to tackle are:
1. Dialog strategy: Dialog strategy and system
prompt generation for situated environments
are important research topics, especially to
clarify the target when there is ambiguity as
mentioned in Section 6.1. The topic will in-
clude an adaptation of system utterances (en-
trainment) to the user (Hu et al., 2014).
2. Eye tracker: Although we believe head pose
is good enough to estimate user intentions be-
cause we are trained to move the head in driv-
ing schools to look around to confirm safety,
we would like to confirm the difference in
this task between face direction and eye-gaze.
3. POI identification using face direction trajec-
tory: Our analysis showed that the use of face
direction sometimes degrades the POI identi-
fication performance. However, we believe
that using a trajectory of face direction will
change the result.
4. Database: We assumed a clean and perfect
database but we are going to evaluate the per-
formance when noisy database is used. (e.g.
A database based on image recognition re-
sults or user dialog log.)
5. Feedback: Koller et al. (2012) demonstrated
referential resolution is enhanced by giving
gaze information feedback to the user. We
would like to analyze the effect of feedback
with an automotive augmented reality envi-
ronment using our 3D head-up display (Ng-
Thow-Hing et al., 2013).
8 Related Work
The related studies include a landmark-based nav-
igation that handles landmarks as information for
a dialog. Similar system concepts have been
provided for pedestrian navigation situations (Ja-
narthanam et al., 2013; Hu et al., 2014), they do
not handle a rapidly changing environment.
Several works have used timing to enhance
natural interaction with systems. Rose and
Horvitz (2003) and Raux and Eskenazi (2009)
used timing information to detect user barge-ins.
Studies on incremental speech understanding and
generation (Skantze and Hjalmarsson, 2010; Deth-
lefs et al., 2012) have proved that real-time feed-
back actions have potential benefits for users.
Komatani et al. (2012) used user speech timing
against user?s previous and system?s utterances
to understand the intentions of user utterances.
While the above studies have handled timing fo-
cusing on (para-)linguistic aspect, our work han-
dles timing issues in relation to the user?s physical
surroundings.
Recent advancements in gaze and face direction
estimation have led to better user behavior under-
standing. There are a number of studies that have
analyzed relationship between gaze and user in-
tention, such as user focus (Yonetani et al., 2010),
preference (Kayama et al., 2010), and reference
expression understanding (Koller et al., 2012), be-
tween gaze and turn-taking (Jokinen et al., 2010;
Kawahara, 2012). Nakano et al. (2013) used face
direction for addressee identification. The previ-
ous studies most related to ours are reference res-
olution methods by Chai and Prasov (2010), Iida
et al. (2011) and Kennington et al. (2013). They
confirmed that the system?s reference resolution
performance is enhanced by taking the user?s eye
fixation into account. However, their results are
not directly applied to an interaction in a rapidly
changing environment while driving, where eye
fixations are unusual activities.
Marge and Rudnicky (2010) analyzed the effect
of space and distance for spatial language under-
standing for a human-robot communication. Our
task differs with this because we handle a rapidly
changing environment. We believe we can im-
prove our understanding performance based on
their findings.
9 Conclusion
We addressed situated language understanding in
a moving car. We focused on issues in understand-
ing user language of timing, spatial distance, and
linguistic cues. Based on the analysis of the col-
lected user utterances, we proposed methods of us-
ing start-of-speech timing for the POI prior calcu-
lation, GMM-based POI probability (prior) calcu-
lation, and linguistic cues for the posterior calcula-
tion to improve the accuracy of situated language
understanding. The effectiveness of the proposed
methods was confirmed by achieving a significant
improvement in a POI identification task.
29
10 Acknowledgments
The authors would like to thank Yi Ma at Ohio
State University for his contributions to the devel-
opment of HRItk.
References
D. Bohus and E. Horvitz. 2009. Models for Multi-
party Engagement in Open-World Dialog. In Proc.
SIGDIAL, pages 225?234.
J. Chai and Z. Prasov. 2010. Fusing eye gaze with
speech recognition hypotheses to resolve exophoric
reference in situated dialogue. In Proc. EMNLP.
D. Cohen, A. Chandrashekaran, I. Lane, and A. Raux.
2014. The hri-cmu corpus of situated in-car interac-
tions. In Proc. IWSDS, pages 201?212.
N. Dethlefs, H. Hastie, V. Rieser, and O. Lemon. 2012.
Optimising incremental dialogue decisions using in-
formation density for interactive systems. In Proc.
EMNLP, pages 82?93.
Z. Hu, G. Halberg, C. Jimenez, and M. Walker. 2014.
Entrainment in pedestrian direction giving: How
many kinds of entrainment? In Proc. IWSDS, pages
90?101.
R. Iida, M. Yasuhara, and T. Tokunaga. 2011. Multi-
modal reference resolution in situated dialogue by
integrating linguistic and extra-linguistic clues. In
Proc. IJCNLP, pages 84?92.
S. Janarthanam, O. Lemon, X. Liu, P. Bartie, W. Mack-
aness, and T. Dalmas. 2013. A multithreaded con-
versational interface for pedestrian navigation and
question answering. In Proc. SIGDIAL, pages 151?
153.
K. Jokinen, M. Nishida, and S. Yamamoto. 2010. On
eye-gaze and turn-taking. In Proc. EGIHMI.
T. Kawahara, A. Lee, K. Takeda, K. Itou, and
K. Shikano. 2004. Recent Progress of Open-Source
LVCSR Engine Julius and Japanese Model Reposi-
tory. In Proc. ICSLP, volume IV.
T. Kawahara. 2012. Multi-modal sensing and analysis
of poster conversations toward smart posterboard. In
Proc. SIGDIAL.
K. Kayama, A. Kobayashi, E. Mizukami, T. Misu,
H. Kashioka, H. Kawai, and S. Nakamura. 2010.
Spoken Dialog System on Plasma Display Panel Es-
timating User?s Interest by Image Processing. In
Proc. 1st International Workshop on Human-Centric
Interfaces for Ambient Intelligence (HCIAmi).
C. Kennington, S. Kousidis, and D. Schlangen. 2013.
Interpreting situated dialogue utterances: an update
model that uses speech, gaze, and gesture informa-
tion. In Proc. SIGDIAL.
A. Koller, K. Garoufi, M. Staudte, and M. Crocker.
2012. Enhancing referential success by tracking
hearer gaze. In Proc. SIGDIAL, pages 30?39.
K. Komatani, A. Hirano, and M. Nakano. 2012. De-
tecting system-directed utterances using dialogue-
level features. In Proc. Interspeech.
I. Lane, Y. Ma, and A. Raux. 2012. AIDAS - Immer-
sive Interaction within Vehicles. In Proc. SLT.
Y. Ma, A. Raux, D. Ramachandran, and R. Gupta.
2012. Landmark-based location belief tracking in
a spoken dialog system. In Proc. SIGDIAL, pages
169?178.
M. Marge and A. Rudnicky. 2010. Comparing Spo-
ken Language Route Instructions for Robots across
Environment Representations. In Proc. SIGDIAL,
pages 157?164.
T. Misu, A. Raux, I. Lane, J. Devassy, and R. Gupta.
2013. Situated multi-modal dialog system in vehi-
cles. In Proc. Gaze in Multimodal Interaction, pages
25?28.
Y. Nakano, N. Baba, H. Huang, and Y. Hayashi.
2013. Implementation and evaluation of a multi-
modal addressee identification mechanism for mul-
tiparty conversation systems. In Proc. ICMI, pages
35?42.
V. Ng-Thow-Hing, K. Bark, L. Beckwith, C. Tran,
R. Bhandari, and S. Sridhar. 2013. User-centered
perspectives for automotive augmented reality. In
Proc. ISMAR.
M. Quigley, K. Conley, B. Gerkey, J. Faust, T. Foote,
J. Leibs, R. Wheeler, and A. Ng. 2009. ROS:
an open-source Robot Operating System. In Proc.
ICRA Workshop on Open Source Software.
A. Raux and M. Eskenazi. 2009. A Finite-state Turn-
taking Model for Spoken Dialog Systems. In Proc.
HLT/NAACL, pages 629?637.
A. Raux and Y. Ma. 2011. Efficient probabilistic track-
ing of user goal and dialog history for spoken dialog
systems. In Proc. Interspeech, pages 801?804.
R. Rose and H. Kim. 2003. A hybrid barge-in proce-
dure for more reliable turn-taking in human-machine
dialog systems. In Proc. Automatic Speech Recog-
nition and Understanding Workshop (ASRU), pages
198?203.
G. Skantze and A. Hjalmarsson. 2010. Towards incre-
mental speech generation in dialogue systems. In
Proc. SIGDIAL, pages 1?8.
K. Sugiura, N. Iwahashi, H. Kawai, and S. Nakamura.
2011. Situated spoken dialogue with robots using
active learning. Advance Robotics, 25(17):2207?
2232.
30
Table 7: Example user utterances
- What is that blue restaurant on the right?
- How about this building to my right with outside seating?
- What is that Chinese restaurant on the left?
- Orange building to my right.
- What kind of the restaurant is that on the corner?
- The building on my right at the corner of the street.
- What about the building on my right with woman with a jacket in front
- Do you know how good is this restaurant to the left?
- Townsurfer, there is an interesting bakery what is that?
- Is this restaurant on the right any good?
S. Tellex, T. Kollar, S. Dickerson, M. Walter, A. Baner-
jee, S. Teller, and N. Roy. 2011. Understanding nat-
ural language commands for robotic navigation and
mobile manipulation. In Proc. AAAI.
R. Yonetani, H. Kawashima, T. Hirayama, and T. Mat-
suyama. 2010. Gaze probing: Event-based estima-
tion of objects being focused on. In Proc. ICPR,
pages 101?104.
11 Appendix
Test route:
https://www.google.com/maps/
preview/dir/Honda+Research+
Institute,+425+National+Ave+
%23100,+Mountain+View,+CA+
94043/37.4009909,-122.0518957/
37.4052337,-122.0565795/37.
3973374,-122.0595982/37.4004787,
-122.0730021/Wells+Fargo/37.
4001639,-122.0729708/37.3959193,
-122.0539449/37.4009821,-122.
0540093/@37.3999836,-122.
0792529,14z/data=!4m21!4m20!
1m5!1m1!1s0x808fb713c225003d:
0xcf989a0bb230e5c0!2m2!
1d-122.054006!2d37.401016!
1m0!1m0!1m0!1m0!1m5!1m1!1s0x0:
0x86ca9ba8a2f15150!2m2!1d-122.
082546!2d37.388722!1m0!1m0!1m0!
3e0
31
