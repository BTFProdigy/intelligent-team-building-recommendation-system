227
228
229
230
231
232
233
234
GoDiS  - An  Accommodat ing  Dia logue System 
Sta f fan  Larsson ,  Peter  L jung l6 f ,  Rob in  Cooper ,  E l i sabet  Engdah l ,  S t ina  Er i csson  
Depar tment  of linguistics, GSteborg University 
Box 200-295, Humanisten,  SE-405 30 G5teborg,  Sweden 
{s l ,  peb,  cooper ,  engdah l ,  s t inae}01 ing ,  gu. se 
Abst rac t  
This paper accompanies a demo of the GoDiS sys- 
tem. Work on~hi~ system was reported at IJCAI- 
99 (Bohlin et-al.~ 1999). GoDiS is a prototype 
dialogue system for information-seeking dialogue, 
capable of accommodating questions and tasks to 
enable the user to present information in any de- 
sired order, without explicitly naming the dialogue 
task. GoDiS is implemented using the TRINDIKIT 
software package, which enables implementation f 
these behaviours in a compact and natural way. 
1 In t roduct ion  
This paper accompanies a demo of the GoDiS 1 
system reported at IJCAI-99 (Bohlin et al, 
1999). GoDiS is a prototype dialogue system for 
information-seeking dialogue, capable of accommo- 
dating questions and tasks to enable the user to 
present information in any desired order, without 
explicitly naming the dialogue task. GoDiS is im- 
plemented using the TRINDIKIT 2 software package 
developed in the TRINDI project. The TRINDIKIT 
is a toolkit for building and experimenting with dia- 
logue move engines and information states (IS), We 
use the term information state to mean, roughly, 
the information stored internally by an agent, in 
this case a dialogue system. A dialogue move engine 
(DME) updates the information state on the basis 
of observed ialogue moves and selects appropriate 
moves to be performed. 
2 System Descr ip t ion  
The overall structure of the GoDiS system is 
illustrated below: 
1Work on GoDiS has been supported by the TRINDI 
(Task Oriented Instructional Dialogue), EC Project LE4- 
8314, SDS (Swedish Dialogue Systems), NUTEK/HSFR Lan- 
guage Technology Project F1472/1997, and INDI (Infor- 
mation Exchange in Dialogue), Riksbankens Jubileumsfond 
1997-0134, projects. 
2 .x~.n~. ling, gU. se/research/proJ ects/trlndi/ 
Like any dialogue system built using the 
TRINDIKIT, GoDiS consists of a number of mod- 
ules, an information state, and a number of resources 
hooked up to the information state. 
In addition to the control module, which wires 
together the other modules, there are six modules in 
? GoDiS: input, which receives input3from the user; 
interpret, which interprets utterances as dialogue 
moves with some content; generate, which gener- 
ates natural language from dialogue moves; out- 
put, which produces output to the user; update, 
which updates the information state based on in- 
terpreted moves; and select, which selects the next 
move(s) to perform 4. The last two are DME rood- 
ules, which means that they together make up the 
3GoDiS originally accepted written input only, but it is 
currently being hooked up to a speech recogniser toaccept 
spoken input. 
4This is done by updating the part of the information state 
containing the moves to be performed. 
7 
DME in GoDiS. DME modules consist of a set of up- 
date rules and (optionally) an update algorithm gov- 
erning the order in which rules are applied. Update 
rules are rules for updating the information state. 
They consist of a rule name, a precondition list, and 
an effect list. The preconditions are conditions on 
the information state, and the effects are operations 
on the information state. If the preconditions of a 
rule are true for the information state, then the ef- 
fects of that rule can be applied to the information 
state. 
There are three resources in GoDiS: a lexicon, a 
database and a domain resource containing (among 
other things) domain-specific dialogue plans. Cur- 
rently, there are GoDiS resources for a travel agency 
domain andS-the autoroute domain. Also, for each 
of these domains there are lexicons in both English 
and Swedish. 
The question about what should be included in 
the information state is central to any theory of dia- 
logue management. The notion of information state 
we are putting forward here is basically a simplified 
version of the dialogue game board which has been 
proposed by Ginzburg. We are attempting to use as 
simple a version as possible in order to have a more 
or less practical system to experiment with. 
The main division in the information state is be- 
tween information which is private to the agent and 
that which is (assumed to be) shared between the 
dialogue participants. What we mean by shared in- 
formation here is that which has been established 
(i.e. grounded) during the conversation, akin to 
what Lewis in (Lewis, 1979) called the "conversa- 
tional scoreboard". We represent information states 
of a dialogue participant as a record of the type 
shown in figure 1. 
The private part of the information state includes 
a set of beliefs and a dialogue plan, i.e. is a list 
of dialogue actions that the agent wishes to carry 
out. The plan can be changed during the course 
of the conversation. For example, if a travel agent 
discovers that his customer wishes to get information 
about a flight he will adopt a plan to ask her where 
she wants to go, when she wants to go, what price 
class she wants and so on. The agenda, on the other 
hand, contains the short term goals or obligations 
that the agent has, i.e. what the agent is going to do 
next. For example, if the other dialogue participant 
raises a question, then the agent will normally put 
an action on the agenda to respond to the question. 
This action may or may not be in the agent's plan. 
The private part of the IS also includes "tem- 
porary" shared information that saves the previ- 
ously shared information until the latest utterance is
grounded, i.e. confirmed as having been understood 
8 
by the other dialogue participant 5. In this way it 
is easy to retract the "optimistic" assumption that 
the information was understood if it should turn out 
that the other dialogue participant does not under- 
stand or accept it. If the agent pursues a cautious 
rather than an optimistic strategy then information 
will at first only be placed in the "temporary" slot 
until it has been acknowledged by the other dialogue 
participant whereupon it can be moved to the appro- 
priate shared field. 
The (supposedly) shared part of the IS consists 
of three subparts. One is a set of propositions 
which the agent assumes for the sake of the conversa- 
tion and which are established uring the dialogue. 
The second is a stack of questions under discussion 
(QUD). These are questions that have been raised 
and are currently under discussion in the dialogue. 
The third contains information about the latest ut- 
terance (speaker, moves and integration status). 
3 Accommodat ion in GoDiS 
Dialogue participants can address questions that 
have not been explicitly raised in the dialogue. How- 
ever, it is important hat a question be available to 
the agent who is to interpret it because the utter- 
ance may be elliptical. Here is an example from a 
travel agency dialogue6: 
$J: what month do you want to go 
SP: well around 3rd 4th april / some time 
there 
SP: as cheap as possible 
The strategy we adopt for interpreting elliptical 
utterances i to think of them as short answers (in 
the sense of Ginzburg (Ginzburg, 1998)) to questions 
on QUD. A suitable question here is What kind of 
price does P want for the ticket?. This question 
is not under discussion at the point when P says 
"as cheap as possible". But it can be figured out 
since J knows that this is a relevant question. In 
fact it will be a question which J has as an action 
in his plan to raise. On our analysis it is this fact 
which enables A to interpret he ellipsis. He finds 
the matching question on his plan, accommodates 
by placing it on QUD and then continues with the 
integration of the information expressed by as cheap 
as possible as normal. Note that if such a question is 
? not available then the ellipsis cannot be interpreted 
as in the dialogue below. 
A. What  time are you coming to pick up Maria? 
B. Around 6 p.m. As cheap as possible. 
5In discussing rounding we will assume that  there is just 
one other dialogue participant. 
6This dialogue has been collected by the University of 
Lund as part of the SDS project. We quote a translation 
of the transcription done in GSteborg as part of the same 
project. 
IS : 
PRIVATE : 
SHARED : 
PLAN : STACKSET(AcT1ON)  
AGENDA : STACK(ACTION) 
PaL : SET(PRoP) 
I BEL : SET(PRoP) 
QUD : STACK(QUESTION) 
TMP : \[ SPEAKER : 
LU : \[ MOVES : 
BEL : SET(PRoP)  
QUD : STACKSET(QUESTION) 
SPEAKER : PARTICIPANT 
LU : MOVES : 
PARTICIPANT 
ASsoCSET(MOvE,BOoL) 
ASsOCSET(MOvE,BooL) \] \] 
Figure 1: The type of information state we are assuming 
This dialogue is incoherent if what is being dis- 
cussed is when the child Maria is going to be picked 
up from her friend's house (at least under standard 
dialogue plans-that we might have for such a con- 
versation). 
Question accommodation has been implemented 
in GoDiS using a single information state update 
rule accommodateQuest ion,  seen below. When 
interpreting the latest utterance by the other par- 
ticipant, the system makes the assumption that it 
was a reply move with content A. This assump- 
tion requires accommodating some question Q such 
that A is a relevant answer to Q. The check operator 
"answer-to(A, Q)" is true if A is a relevant answer to 
Q given the current information state, according to 
a (domain-dependent) definition of question-answer 
relevance. 
RULE: accommodateQuest ion  
CLASS: accommodate  
val( SHARED.LU.SPEAKER, us r  ) 
in( SHARED.LU.MOVES, answer(A) ) 
not ( lexicon :: yn_answer(A) ) 
PRE: aSSOC( SHARED.LU.MOVES, answer(A), false ) 
in( PRIVATE.PLAN, raise(Q) ) 
domain :: relevant_answer(Q, A)
del( PRIVATE.PLAN, raise(Q) ) 
EFF: push( SHARED.QUD, Q ) 
After an initial exchange for establishing contact 
the first thing that P says to the travel agent in our 
dialogue is "flights to paris". This is again an el- 
lipsis which on our analysis has to be interpreted as 
the answer to a question (two questions, actually) 
in order to be understandable and relevant. As no 
questions have been raised yet in the dialogue (apart 
from whether the participants have each other's at- 
tention) the travel agent cannot find the appropriate 
question on his plan. Furthermore, as this is the first 
indication of what the customer wants, the travel 
agent cannot have a plan with detailed questions. 
We assume that the travel agent has various plan 
types in his domain knowledge determining what 
kind of conversations heis able to have. Each plan 
is associated with a task. E.g. he is able to book 
trips by various modes of travel, he is able to han- 
dle complaints, book hotels, rental cars etc. What 
he needs to do is take the customer's utterance and 
try to match it against questions in his plan types 
in his domain knowledge. When he finds a suitable 
match he will accommodate the corresponding task, 
thereby providing a plan to ask relevant question 
for flights, e.g. when to travel?, what date? etc. 
Once he has accommodated this task and retrieved 
the plan he can proceed as in the previous example. 
That is, he can accommodate the; QUD with the rel- 
evant question and proceed with the interpretation 
of ellipsis in the normal fashion. 
This example is interesting for a couple of reasons. 
It provides us with an example of "recursive" accom- 
modation. The QUD needs to be accommodated, 
but in order to do this the dialogue task needs to be 
accommodated and the plan retrieved. The other 
interesting aspect of this is that accommodating the 
dialogue task in this way actually serves to drive the 
dialogue forward. That is, the mechanism by which 
the agent interprets this ellipsis, gives him a plan for 
a substantial part of the rest of the dialogue. This is 
a way of capturing the intuition that saying flights to 
Paris to a travel agent immediately makes a number 
of questions become relevant. 
Task accommodation a d retrieval of the relevant 
plan has been implemented in GoDiS by two infor- 
mation state update rules. 
4 Sample dialogues 
We will give some examples of CoDiS dialogues in 
the English travel agency domain. One of the fea- 
tures of the TRINDIKIT is that it provides methods 
for inspecting the information state at any stage of 
a dialogue, and also to see which rules are applied. 
Unfortunately, because of space limitations, we are 
not able to include examples of this in this paper; 
however, it is an integral part of our demo. 
The first dialogue shows the typical behaviour of 
dialogue systems for information-seeking: each ques- 
tion is answered in turn, and the user always gives 
exactly the information requested. 
$S> Welcome to the travel agency! 
$U> hello 
9 
$S> What can I do for you? 
$U> I want price information on a trip 
please 
$S> How do you want to travel? 
$U> by plane 
$S> What city do you want to go to? 
SU> gothenburg 
$S> What city do you want to go from? 
SU> london 
$S> Do you want a return ticket? 
$U> yes 
$S> What month do you want to  leave?  
$U> april 
$S> What class did you have in mind? 
$U> as cheap as possible 
$S> It~wil-i cost 50 crowns 
SU> thanks-, bye! 
$S> Thank you for your visit! 
In contrast, the second dialogue (below) shows 
how GoDiS is able to accommodate the task and in- 
tegrate information i  the order that the user gives 
it. 
$S> Welcome to the travel agency! 
$U> flights to paris 
$S> What city do you want to go from? 
$U> gothenburg, in april, as cheap as 
possible 
$S> Do you want a return ticket7 
$U> no 
$S> It will cost 50 crowns 
SU> thanks~ bye! 
$S> Thank you for your visit! 
5 Limitat ions 
GoDiS is a small-scale prototype and as such it suf- 
fers from the familiar drawbacks of many experi- 
mental systems: its lexicons and databases are very 
small, and the domain knowledge is limited. The di- 
alogue plans cover only a small (but important) part 
of the kind of dialogues that can take place in the 
travel agency and autoroute domains. We hope to 
be able to extend both the number of domains and 
the scale of each domain in the future. 
Also, the focus in the development of GoDiS has 
been on the dialogue management, i.e. the dialogue 
move engine and the information state. Less effort 
has been put into the interpretation a d generation 
modules, which currently use (a slightly extended 
version of) keyword spotting and partially canned 
text, respectively. We hope to replace these by plug- 
ging in existing interpretation a d generation tech- 
nology to GoDiS. 
For the tasks that GoDiS currently is able to han- 
dle, full-blown semantics i not needed. We use a 
very limited semantics where propositions are essen- 
tially feature-value pairs. As a consequence, GoDiS 
10 
is e.g. not able to handle dialogue with more than 
one referent; for this, the information state would 
have to be amended with a set of referents, and 
propositions would have to include referent informa- 
tion. This is an area where we hope to improve 
GoDiS in the near future. 
Speech recognition and synthesis i currently be- 
ing added to GoDiS, but at the time of writing only 
written input and output is available. 
6 Contr ibut ions 
Currently, the main contribution of GoDiS is per- 
haps to show how an extended notion of accommo- 
dation can serve to make dialogue systems easier to 
interact with, by letting the user decide how and 
in what order to present information to the system. 
Also, the fact that accommodation can be imple- 
mented simply by adding three update rules indi- 
cates that information state update rules provide a 
natural and compact way of implementing dialogue 
strategies. An important issue for future research 
is the relation of question and task accommodation 
to plan recognition approaches to dialogue (Sidner, 
1985). 
GoDiS also features a simple grounding strategy 
which is nevertheless ufficient in many cases. The 
grounding mechanism is implemented by three up- 
date rules. It is possible to switch resources in mid- 
dialogue, e.g. to change language. Also, GoDiS 
is easily reconfigurable to new information-seeking 
domains. To adapt GoDiS to a new domain, one 
needs to supply a database, a lexicon and domain 
knowledge, including a set of dialogue plans. The 
GoDiS modules or information state don't need to 
be changed in any way. 
In general, as an example of a dialogue system ira- 
plemented using the TRINDIKIT package, GoDiS 
shows how the information state approach is use- 
ful for clarifying and comparing theories of dialogue, 
and for exploring new solutions. 
References 
P. Bohlin, R. Cooper, E. Engdahl, and S. Lars- 
son. 1999. Information states and dialogue move 
engines. In J. Alexandersson, editor, IJCAI-99 
Workshop on Knowledge and Reasoning in Prac- 
tical Dialogue Systems. 
? J. Ginzburg. 1998. Clarifying utterances. In J. Hul- 
stijn and A. Niholt, editors, Proc. of the Twente 
Workshop on the Formal Semantics and Pragmat- 
ics of Dialogues, pages 11-30, Enschede. Univer- 
siteit Twente, Faculteit Informatica. 
D. K. Lewis. 1979. Scorekeeping in a language 
game. Journal of Philosophical Logic, 8:339-359. 
C. L. Sidner. 1985. Plan parsing for intended re- 
sponse recognition in discourse. Computational 
Intelligence, 1 (1) :1-10, February. 
Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 110?119,
Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational Linguistics
Lekbot: A talking and playing robot for children with disabilities
Peter Ljungl?f
Computer Science and Engineering
University of Gothenburg, Sweden
peter.ljunglof@gu.se
Britt Claesson
Ingrid Mattsson M?ller
DART: Centre for AAC and AT
Queen Silvia Children?s Hospital
Gothenburg, Sweden
{britt.claesson,ingrid.mattsson-muller}@vgregion.se
Stina Ericsson
Cajsa Ottesj?
Philosophy, Linguistics and
Theory of Science
University of Gothenburg, Sweden
{stina.ericsson,cajsa.ottesjo}@gu.se
Alexander Berman
Fredrik Kronlid
Talkamatic AB
Gothenburg, Sweden
{alex,fredrik}@talkamatic.se
Abstract
This paper describes an ongoing project
where we develop and evaluate a setup in-
volving a communication board and a toy
robot, which can communicate with each
other via synthesised speech. The purpose
is to provide children with communicative
disabilities with a toy that is fun and easy
to use together with peers, with and with-
out disabilities. When the child selects
a symbol on the communication board,
the board speaks and the robot responds.
This encourages the child to use language
and learn to cooperate to reach a common
goal. Throughout the project, three chil-
dren with cerebral palsy and their peers
use the robot and provide feedback for fur-
ther development. The multimodal inter-
action with the robot is video recorded and
analysed together with observational data
in activity diaries.
1 Background
The vision of our project is to utilise current
technology in human computer interaction and
dialogue systems to provide young people with
communication disabilities with a fun and ex-
citing toy. Currently there are not many op-
portunities for children with severe disabilities
to play independently and to interact on equal
terms with typically developing children. Our
hope is that the toy will give children, with and
without disabilities, the opportunity to interact
Figure 1: The robot and the communication board
and play with each other. As a side effect this
can also help them develop their communicative
skills.
We are developing a remote-controlled robot
that can be used by children with severe phys-
ical and/or communicative disabilities, such as
cerebral palsy or autism. The child communi-
cates by selecting a symbol on a communication
board, which is translated into an utterance us-
ing a speech synthesiser. The robot responds us-
ing synthesised utterances and physical actions,
that the child in turn can respond to. The com-
munication board acts as an extension of the
child, by giving the child speech as a means of
communication. The robot and its communica-
tion board is shown in Figure 1.
Technically the robot is controlled wirelessly,
110
with no speech recognition. The spoken dialogue
is there for the benefit of the child, and enables
the child to engage in a spoken dialogue, without
having the physical and/or cognitive ability to
do so. Our hope is that this will facilitate the
child?s own language development while having
fun with the radio-controlled robot.
1.1 The Lekbot project
The Lekbot project is a collaboration between
DART,1 Talkamatic AB and the University of
Gothenburg. It is funded by VINNOVA2 and
runs from March 2010 to August 2011.
The project is similar to the TRIK project
(Ljungl?f et al, 2009), which developed a draw-
ing robot that was controlled in the same man-
ner as above. The very limited user study that
was conducted suggested that the product had
great potential. The current project can be seen
as a continuation of TRIK, where we perform a
more full-scale user study, with video recording,
transcription, interaction analyses, etc.
1.2 Dialogue systems and robots
Most existing dialogue systems are meant to be
used by competent language users without phys-
ical, cognitive or communicative disabilities; ei-
ther they are supposed to be spoken to (e.g.,
phone based systems), or one has to be able to
type the utterances (e.g., the interactive agents
that can be found on the web). Dialogue sys-
tems for users with disabilities have so far been
targeted at people with physical disabilities, who
need help in performing daily activities.
Dialogue systems have also been used for sec-
ond language learning; i.e., learning a new lan-
guage for already language competent people.
Two examples are the artificial agent ?Ville: The
Virtual Language Tutor? (Beskow et al, 2004),
and ?SCILL: Spoken Conversational Interface
for Language Learning?, a system for practicing
Mandarin Chinese (Seneff et al, 2004).
However, we are not aware of any examples
where a dialogue system is used for communicat-
1Centre for AAC and AT at the Queen Silvia Chil-
dren?s Hospital
2The Swedish Governmental Agency for Innovation
Systems
ing with people with communication disorders.
With the advent of tablet computers, there
now exist several spoken-language and touch-
screen apps for children?s games and interactive
and linguistic training. In these apps, the in-
teraction is between the child and the tablet,
whereas in Lekbot the child and the tablet act
together as one dialogue participant, interact-
ing with the robot. The Lekbot robot is also a
physical agent, acting in the world, thus adding
another dimension to the interaction.
When it comes to robots, there are a number
of past and present research projects on robots
and children. An early inspiration is the LOGO
robot developed at Massachusetts Institute of
Technology for teaching children to use com-
puters and program simple applications (Papert,
1993). There are several robots focusing on chil-
dren with disabilities (Robins et al, 2008; Sal-
dien et al, 2006; Kozima et al, 2007; Lee et al,
2008; Arent and Wnuk, 2007), and most com-
monly autism. Some of these communicate with
children in different ways. For instance, KAS-
PAR is a child-sized humanoid robot for chil-
dren with autism, and it trains interactional ca-
pabilities through gesture imitation.3 Probo, de-
veloped for hospitalised children, produces non-
sense speech intended to convey different feel-
ings.4 KOALA is a small round ball that in-
teracts with children with autism using lights
and sounds (Arent and Wnuk, 2007). However,
none of these robots and research projects in-
volves natural language communication in any
form between the child and the robot.
2 Project description
Our basic idea is to use a dialogue system
to stimulate play and interaction for children
with severe communicative disabilities. There
are already communication boards connected to
speech synthesis in the form of communication
software on computers. The main values that
this project adds to existing systems are that:
? the child is offered an exciting, creative and
fun activity
3http://kaspar.feis.herts.ac.uk/
4http://probo.vub.ac.be/
111
? the child can play and interact with other
peers on equal terms
? the child can explore language in stimulat-
ing cooperation with the robot and with
other children
By being able to use a symbol-based communi-
cation board the children are given an opportu-
nity to play, interact, explore language, and at
the same time learn to use tools for alternative
and augmentative communication.
2.1 Description of the system
The child has a communication board that can
talk; when the child points at one of the symbols
it is translated to an utterance which the board
expresses via speech synthesis in Swedish. This
is recognised by a robot that moves around in the
room, and performs the commands that the child
expresses through the board. The robot has an
incarnation as a toy animal, currently a bumble-
bee. It has a very basic personality which means
that it can take the initiative, without the child
telling it, refuse actions, or even negotiate with
the child.
The inspiration for the robot comes from robot
toys such as babies, dogs and dinosaurs, but
also from electronic pets such as Tamagotchi and
Talking Tom. The main difference is that our
robot is able to have a dialogue with the child,
to find out what to do, or just to be teasingly
playful.
The Lekbot robot can move forward and back-
ward, and turn right and left. Furthermore it
can perform actions such as laughing, dancing,
yawning, farting and eating. The functionality
is constantly improving during the evaluation, to
keep the children interested in playing with the
robot.
2.2 Needs and potential
The target audience is children with severe
physical, cognitive or communicative disabilities.
These children depend on assistive devices and
persons to be able to interact with other people
and artifacts. The idea is that the robot will be
a fun toy that gives the child an opportunity to
control the artifacts itself, without the help of
other people. Hopefully this will increase the
child?s confidence, and also promote language
development.
2.2.1 The importance of play
Play may be defined by the following terms
(Knutsdotter Olofsson, 1992):
? spontaneous; the child takes the initiative,
not the adults
? not goal-oriented; the game does not have
an explicit purpose
? fun and pleasurable
? repeating; that it can be played many times
as one wants
? voluntary
For children with severe disabilities, playing re-
quires adult help, and it is difficult for the adult
not to control the game, especially if the child
has problems communicating what it wants. Of-
ten play is used as a tool for development train-
ing, and many times play is so scheduled that
it is no longer spontaneous (Brodin and Lind-
strand, 2007). A toy that is always available for
the child to play with whenever it wants, and
on its own terms can help the child to play ?for
real?.
Children learn from each other, and a toy that
is used on equal terms by children, with and
without disabilities, encourages interaction that
otherwise would not have been possible between
children with such diverse backgrounds.
2.2.2 Educational advantages
As discussed in section 3.3 later, the setup
works without the robot and the communication
board actually listening to each others? speech ?
instead, they communicate wirelessly. However,
there is an important educational point in hav-
ing them (apparently) communicate using spo-
ken language. It provides the child with an ex-
perience of participating in a spoken dialogue,
even though the child is not physically able to
speak. For children who are more advanced in
their language development, the robot can offer
112
the opportunity to understand the basic proper-
ties of the dialogue, such as taking turns, asking
and answering questions, the importance of pro-
viding sufficient information, and cooperating to
achieve a shared goal. Another educational ad-
vantage is that the child learns to use tools for
alternative and augmentative communication.
3 Implementation
This section describes some technical aspects of
the implementation of the Lekbot system.
3.1 Components
The final Lekbot setup consists of the following
components:
? a simple LEGO Mindstorms robot which
can turn and move in all directions, can
perform different specialised actions, and
has a ?costume? which makes it look like
a bumble-bee
? a touch-screen computer which functions as
a communication board, and a custom sup-
port frame for the computer
? the dialogue system GoDiS (Larsson, 2002),
using Acapela Multimedia text-to-speech
with Swedish voices
? Bluetooth communication and wireless au-
dio transmission, from the touch-screen
computer to the robot, and two sets of loud-
speakers, for the computer and the robot
If the target user already has his or her ownWin-
dows based communication device, with adapted
accessibility for him or her, this special software
for the robot play can be installed on this device.
Note that it is the communication board com-
puter that controls the robot via the dialogue
system, but the intention is that it should seem
like the robot is autonomous. Every utterance
by the robot is executed by the speech synthe-
siser, and then sent to the robot via radio.
3.2 LEGO Mindstorms
The robot is built using LEGO Mindstorms
NXT,5 a kind of technical lego which can be con-
5http://mindstorms.lego.com/
trolled and programmed via a computer. Apart
from being cheap, this technology makes it easy
to build a prototype and to modify it during the
course of the project.
3.3 Perfect speech recognition
Typically, the most error-prone component of a
spoken dialogue system is speech recognition;
the component responsible for correctly inter-
preting speech. This of course becomes even
more problematic when working with language
learning or communication disorders, since in
these situations it is both more difficult and more
important that the computer correctly hears and
understands the user?s utterances. An advan-
tage of the Lekbot setup is that we will, in a
sense, have ?perfect speech recognition?, since
we are cheating a bit. The robot does not ac-
tually have to listen for the speech generated by
the communication board; since the information
is already electronically encoded, it can instead
be transferred wirelessly. This means that the
robot will never hear ?go forward and then stop?
when the communication board actually says ?go
forward seven steps?.
3.4 The GoDiS dialogue manager
A dialogue system typically consists of several
components: speech recogniser, natural lan-
guage interpreter, dialogue manager, language
generator, speech synthesiser and a short-term
memory for keeping track of the dialogue state.
One can make a distinction between dialogue
systems, which (ideally) are general and reusable
over several domains, and dialogue system appli-
cations, which are specific to a certain domain.
The dialogue manager is the ?intelligence? of the
system, keeping track of what has been said so
far and deciding what should be said next.
The GoDiS dialogue manager (Larsson, 2002)
has been developed at the Department of Philos-
ophy, Linguistics and Theory of Science at the
University of Gothenburg over several years. It
is designed to be easily adaptable to new do-
mains, but nevertheless be able to handle a va-
riety of simpler or more complex dialogues. For
example, GoDiS can either take initiative and
prompt a user for information, or take a back
113
seat and let the experienced user provide infor-
mation in any desired order, without having to
wait for the right question from the system.
From the viewpoint of dialogue systems re-
search, there are some interesting aspects in the
Lekbot setting:
? Constantly changing environment : the sur-
roundings of the robot can change all the
time, and the dialogue system needs to
adapt
? Alternative input modalities: instead of
speech input, we are using a touch screen in-
terface, on which the symbols on the screen
also changes depending on the current dia-
logue state
? Utterance generation: it is important for ev-
eryone, but in particular children with com-
municative disabilities, that information is
presented in a correct way ? with correct
and consequent grammar, lexicon and pro-
nunciation
3.5 Utterance generation
Clear pronunciation is important, and perhaps
even more important when we are dealing with
communicative disabilities. We are experiment-
ing with using different utterance generation
strategies and stressing important words to make
the children understand the robot better. Inter-
estingly, user feedback from children and pre-
schools during the project has also indicated
when default intonation does not work and needs
to be modified.
The Lekbot system uses two different voices,
one for the touch screen, acting as the child?s
voice, and one for the robot. Whereas the touch-
screen voice is a vocalisation of something the
child has already seen on the screen, the utter-
ances of the robot have no visualisations. Hence,
it is particularly important that the robot?s ut-
terances are as clear as possible, and the TTS
voice chosen for the robot is therefore the voice
that was determined to have the best and most
flexible intonation in informal perception tests
at the start of the project.
3.5.1 Contextual intonation
We have incorporated models of information
structure in GoDiS to enable the appropriate
assignment of phonological emphasis (Ericsson,
2005).
Lekbot uses a fairly basic dialogue-move-to-
string mapping for the creation of output utter-
ances, which are then fed to the speech synthe-
siser. Determining the information structure of
an utterance to be generated, involves the deter-
mination of what is informative in the utterance
? the focus ? and what is a reflection of some-
thing already in the context ? the ground (Vall-
duv?, 1992). The system assigns emphasis to all
alternatives, that is, all contrasting elements, in
alternative questions, that are produced by the
robot. Consider the following example:
User : Go forward.
Robot : Do you want me to go forward
a lot or go forward a little?
For the generation of the robot utterance, the
system determines ?go forward a lot? and ?go
forward a little? as alternatives, and assigns em-
phasis to these. Future development of the sys-
tem may involve the inclusion of information
structure also for utterances other than non-
alternative questions, to determine appropriate
intonation assignment more generally.
Unfortunately, we have not yet been able to
use this feature in the actual demonstration sys-
tem, since the Swedish TTS voices do not em-
phasise properly with regard to the markup. In-
stead we have tuned the utterances lexically and
syntactically to make the best possible use of the
default TTS intonation.
4 Evaluation
We are evaluating the Lekbot system during
spring and summer 2011, in parallel with con-
tinued development, in the spirit of eXtreme
Programming (XP). Some major themes in XP
that were deemed particularly interesting in this
project are i) the need to involve the users in
the development process, ii) to work in short it-
erations with frequent releases to get a nearly
constant feedback from users, and iii) to always
114
prioritise the tasks that provide the greatest ben-
efit to users.
4.1 Users
A test group was recruited consisting of three
target children with peers and staff, at three
different pre-schools, was recruited. The target
children, two boys and one girl are in the ages 4?
6 years, two boys and one girl. They have cere-
bral palsy with complex communication needs.
They also have a poor gross motor control, but
are able to use their hands for activating a touch
screen on a computer. They serve as the test
group and as a basis for the specifications of the
further development of the system. During the
course of development the children in the test
group use the system to verify that it works as
intended and help to identify the most important
qualities to develop. The project group works
with one month iterations with a new public re-
lease every second month. Therefore, the users
have in the end used about six releases of the
robot.
Along with the target children, three typically
developed peers, of the same age, or slightly
younger, were recruited at each pre-school. The
three peers were all girls. Hence, there are three
groups of children playing with the robot. At
various occasions other children in the pre-school
group are involved in the robot play.
The children were assessed regarding their re-
ceptive language levels by using Test for Re-
ception of Grammar (TROG) (Bishop et al,
1998). Their communication levels were es-
timated by the project group in cooperation
with the pre-school staff using Communication
Function Classification System (CFCS) for In-
dividuals with Cerebral Palsy (Hidecker et al,
2009). The pre-school staff also completed
Swedish Early Communicative Development In-
ventories (SECDI) forms for each child (Eriks-
son and Berglund, 1999; Berglund and Eriksson,
2000). A pre-school form (F?rskoleformul?r) was
also completed (Granlund and Olsson, 1998). It
consists of questions concerning the child?s en-
gagement in various situations, the pre-school
teacher?s perception of the interaction between
her and the child as well as the interaction be-
tween the child and other children.
With the two youngest target children TROG
testing was not feasible, while the oldest one ap-
peared to have some difficulties in understand-
ing verbs, prepositions and sentences containing
these components, thus a bit lower than his age.
The three peers showed results matching their
age. From here on the target children will be
named Per, Hans and Greta.
The purpose of CFCS is to classify the every
day communication performance of an individ-
ual with cerebral palsy. The levels are ranged
between 1 and 5, where 1 is the highest and 5
the lowest.
? The 6 year old Per shows a level of 3: Ef-
fective sender and effective receiver with fa-
miliar partners.
? The 5 year old Hans is estimated to level
5: Seldom effective sender and effective re-
ceiver with familiar partners, and
? The 4 year old Greta is at level 4: Incon-
sistent sender and/or receiver with familiar
partners.
? All the peers, of course, reach the level of 1.
The CFCS levels will be estimated over again
when the Lekbot testing is finished.
The results of SECDI and the pre-school form
will be presented at a later stage of the Lekbot
project, as they will be redistributed.
4.2 Evaluation tools and methods
The tools used to evaluate the robot play are
three:
? Talking Mats,6 which is an established com-
munication tool that uses a mat with at-
tached symbols as the basis for communi-
cation. It is designed to help people with
communicative and cognitive difficulties to
think about issues discussed with them, and
provide them with a way to effectively ex-
press their opinions. Both the target chil-
dren and their peers were interviewed about
the robot and the interaction, in order to get
6http://www.talkingmats.com
115
feedback for evaluation and for developing
the system.
They were asked questions about the be-
haviour of the robot and answered by
putting symbol cards either at the ?fun? side
of the mat or at the ?boring/not nice? side.
It is also possible to put symbols between
?fun? and ?boring/not nice?. The answers
were then checked and evaluated together
with the children. An example is shown in
Figure 2.
? Video recordings during the robot play were
made by the project group from January
to May 2011, six recordings from each peer
group, in all 18 recordings. The duration
is between 20 and 30 minutes each and
shot with one camera by one of the project
members. Short sequences from the videos
have been transcribed and analysed with
focus on cooperation between the children
and joyfulness. Transcriptions were made
in CLAN7 with detailed descriptions of the
non-verbal actions, signs and gaze. We got
permissions to do the recordings from the
parents of the children.
? Weekly Activity diaries were kept by the
pre-school staff, where they could provide
their reflections about the play sessions.
The diaries included headings regarding
numbers of play occasions, duration of the
play, persons participating, what happened
in the play, functionality of the robot, sug-
gestions for improvement and the children?s
satisfaction with the play perceived by the
staff.
Furthermore, the interaction between the com-
munication board and the robot is logged by the
system, providing valuable information.
Beside these evaluation tools there have also
been discussions with the designated staff at the
current pre-schools.
7http://childes.psy.cmu.edu/clan/
Figure 2: Talking Mats
4.3 Preliminary evaluation results from
the activity diaries
According to the activity diaries, Lekbot was
used 56 times during releases 2?5; just below 10
times each for the early releases, and 20 times
each for releases 4 and 5. There is a great varia-
tion in numbers of performed play sessions and
in completed activity diaries, mainly due to ill-
ness in children or staff, orthopedic surgery in
one child and holidays. In the beginning there
was always the same peer, and only that one,
attending the play sessions. Further on in the
project the staff chose to engage more peers
from the pre-school. That means that sometimes
there was a different peer than originally and
sometimes there was a group of peers interact-
ing in the play. The support person attending
the play sessions was always the same. She also
was the one completing the activity diaries.
4.3.1 Functionality
15 comments were given about the system
working well, where release 5 got the best scores.
Problems with the system were reported 16
times. Comments were given about rebooting
the system, loosing the commands, or problems
with activating them. Dissatisfaction with the
actions of the Lekbot was reported 5 times,
mainly about the delay between activating a
command and the activation of the robot. There
were also reports of improved accessibility of the
system, by finding a mobile piece of furniture
116
for the stand and by changing the angle of the
display.
4.3.2 Interaction
The project group chose not to give strict in-
structions on what to do in the play, just to let
everyone use the Lekbot at suitable level. Thus,
there was a variation in complexity of the com-
ments, as the headings in the activity diaries
gave a structure of open questions. The col-
lected, written comments were categorised in five
groups; Preparations for the Lekbot play, Ex-
plicit support from adult, Target child?s activity
and perception of the play, Peer?s activity and
perception of the play and Shared activity and
perception of the play between target child and
peer(s). The three latter are reported together
release by release.
Preparation for the Lekbot play occurred
mainly for Per?s group, where he and his peers
built different tracks for the robot to follow. Ex-
plicit support by adult is mentioned only for
Per?s group, where the adult chose target point
for the robot and she used the play for educa-
tional matters regarding letter teaching. She
also mediated between the children which im-
proved their cooperation. In the final sessions
Per initiated turn taking after being urged by
the adult.
4.3.3 Activity and perception
Target child?s activity and perception of the
play is mentioned a lot, especially for Per and
Greta. Most frequent among the comments are
those concerning Shared activity and perception
of the play between target child and peer(s).
Release 2: Per initiates turn taking, reacts
to the event followed by the activation of the
command on the display, protests when his peer
choses ?the wrong command?. Together they re-
peatedly perform turn taking and use Per?s dig-
ital communication device in the Lekbot activ-
ity. Hans and his peers make a tunnel and the
children give commands that make the robot go
through it. Greta has high expectations on the
play before the session. Repeatedly she is unwill-
ing to stop the play and she gives oral comments
to the activities of the robot.
Release 3: Per explores the commands and
what happens when using them to answer the
newly implemented supplementary questions.
Around Hans there is turn taking. Several chil-
dren are playing together and the children most
frequently choose the dance command. Greta
is excited and unwilling to stop the play. She
protests when the adult makes the choice for the
robot.
Release 4: Per shows the new commands for
his peer, and the children imitate the robot.
Per and his original peer chose one new peer
each. Interaction between the children takes
place through dancing and hand clapping. Hans
plays with the robot together with adults from
outside the preschool. Greta likes going back-
wards, turning and hitting things with the robot.
She starts telling her peer how to act by us-
ing the commands on the display and her paper
communication chart. Her peer enjoys follow-
ing Greta?s ?instructions? and she likes dancing.
There are repeated turn taking between them
and they enjoy to cooperate getting the robot to
move from one spot to another.
Release 5: Per plays with the new commands,
by himself. He finds strategies for the robot in
finding food. When there are more than two
children in the play, Per chooses to be the one
controlling the display. He cooperates more ?
waits for his turn and shows better understand-
ing for the other?s turn. All children repeatedly
use communication charts and Blissymbolics to
express themselves. They imitate the robot and
they act instead of it when it is out of order.
In Hans?s group there is dancing and looking
for food play. Turn taking takes place and all
children want to participate in the Lekbot play.
Greta decides whose turn it is to control the
robot. Her peer likes the play of finding food.
4.3.4 Satisfaction
Starting in release 3, the level of satisfaction
with the play session was noted in the activity
diary. The staff was asked to estimate how sat-
isfied the target child and the peer were on a
scale from 1 to 5, where 1 is the lowest and 5
the highest. This was done every time at some
117
pre-schools and some times at others. The ten-
dency is that the target children seem to be more
satisfied with the play than their peers from the
start of the play session. This is most protrud-
ing regarding the oldest pair. At release 4 where
Per and his peer interact as a group for the first
time, the scores suddenly are reversed so the Per
is perceived to 3 on the satisfactory scale and the
peer(s) at 5. In release 5 the scores get a more
even variation.
4.4 Video recordings
Most of the interviews with Talking Mats were
video recorded. The full analysis will be done
later in the project. The analysis of the video
recordings of the robot interaction is an ongoing
work were three of the project members partic-
ipate. This part of the work is time consuming
and only minor sequences are transcribed and
analysed so far. Through micro analysis the fine
grained interactional movements and the coop-
eration between the children and the teacher ap-
pears, as well as the joy of playing.
Figure 3 contains a segment from the tran-
scription. The participants are Per, his peer
Selma and his teacher Isa; and the Computer
and the Robot. In the excerpt we can see how
Per asks for Selma?s attention and with the help
of Isa and the communication map tells Selma
to take her turn, which is to make a new com-
mand for the robot to perform. Finally they
both dance to the music.
4.5 Conclusion
All target children have enjoyed the Lekbot play
from the beginning. The more commands and
abilities the robot has received the more appre-
ciated has the play become also by the peers.
Improved play and interaction skills can be ob-
served in varying degrees depending on the level
of each child. The Lekbot has been a nice and
fun artefact for the children to gather round and
it has given both the target children and their
peers experiences of playing with each other.
From Talking Mats interviews performed with
Per and Greta it was revealed that they had no
problems handling the computer display or see-
ing and hearing the display and the robot. Mak-
126 %gaze: Per looks at Selma
127 %move: Selma is standing on her knees, sits down
on her heels, keeps booths hands on her skirt
128 %gaze: Selma looks toward the mirror on the wall
129 %move: Per touches the left hand of Selma, keeps
his arm stretched when Selma moves a bit
131 %gaze: Isa looks at Per?s hand
132 *Selma: ????????
133 %comment : Selma is singing while Per stretches to-
ward her left hand
134 %gesture: Isa draws the pointing map closer
135 %gaze: Per looks down at the map
136 %gaze: Selma looks down at the map
137 *Per : ????????
138 %move: Selma stands up on her knee, departs on a
movement forward
139 *Isa: eh::: (0.3) your turn (0.3) Selma?s turn
140 %gesture: Isa moves her finger back and forth over
the 6th picture on the map
141 %gesture: Isa rests her finger at the picture, then
withdraws it
142 %gesture: Per points at the map
143 %move: Selma moves toward the screen
144 (2.1)
145 %action: Selma makes a fast press at the screen
146 %gaze: Per looks at the screen
147 *Selma: dance: my king ????????
148 %move: Selma moves left with arms swinging, bends
forward, landing on hands and knees
149 %action: Per looks at Selma, smiles
150 *Computer : dance
151 *Selma: mi:ine ?: ?: ?(1.8)?
152 *Robot : okay I gladly dance
153 (1.0)
154 *Robot : plays music 11 sec
155 %comment : both children are dancing, Selma on her
knees and Per sitting down
Figure 3: An example transcription segment, trans-
lated to English
ing the same interview with Hans was not feasi-
ble, though the project group experienced that
he seemed to deal pretty well with the system,
although he needed a little more support than
the two other children, who were able to control
the toy autonomously. More results will be pre-
sented when the video sequences are analysed,
later on in the project.
5 Acknowledgements
We are grateful to 5 anonymous referees for
their valuable comments. The Lekbot project
is financed by Vinnova, and Acapela has kindly
provided us with speech synthesis.
118
References
K. Arent and M. Wnuk. 2007. Remarks on be-
haviours programming of the interactive therapeu-
tic robot Koala based on fuzzy logic techniques.
In First KES International Symposium on Agent
and Multi-Agent Systems: Technologies and Ap-
plications, Wroclaw, Poland.
E. Berglund and M. Eriksson. 2000. Communicative
development in Swedish children 16?28 months
old: The Swedish early communicative develop-
ment inventory ? words and sentences. Scandina-
vian Journal of Psychology, 41(2):133?144.
Jonas Beskow, Olov Engwall, Bj?rn Granstr?m, and
Preben Wik. 2004. Design strategies for a virtual
language tutor. In INTERSPEECH 2004.
Dorothy Bishop, Eva Holmberg, and Eva Lund?lv.
1998. TROG: Test for Reception of Grammar
(Swedish version). SIH L?romedel.
J. Brodin and P. Lindstrand. 2007. Perspektiv p?
IKT och l?rande f?r barn, ungdomar och vuxna
med funktionshinder. Studentlitteratur.
Stina Ericsson. 2005. Information Enriched Con-
stituents in Dialogue. Ph.D. thesis, University of
Gothenburg, Gothenburg, Sweden.
M. Eriksson and E. Berglund. 1999. Swedish early
communicative development inventory ? words
and gestures. First Language, 19(55):55?90.
M. Granlund and C. Olsson. 1998. Familjen och
habiliteringen. Stiftelsen ALA.
M. J. C. Hidecker, N. Paneth, P. Rosenbaum, R. D.
Kent, J. Lillie, and B. Johnson. 2009. Develop-
ment of the Communication Function Classifica-
tion System (CFCS) for individuals with cerebral
palsy. Developmental Medicine and Child Neurol-
ogy, 51(Supplement s2):48.
B. Knutsdotter Olofsson. 1992. I lekens v?rld.
Almqvist och Wiksell.
H. Kozima, C. Nakagawa, and Y. Yasuda. 2007.
Children-robot interaction: a pilot study in autism
therapy. Progress in Brain Research, 164:385?400.
Staffan Larsson. 2002. Issue-based Dialogue Man-
agement. Ph.D. thesis, Department of Linguistics,
University of Gothenburg, Sweden.
C.H. Lee, K. Kim, C. Breazeal, and R.W. Picard.
2008. Shybot: Friend-stranger interaction for chil-
dren living with autism. In CHI2008, Florence,
Italy.
Peter Ljungl?f, Staffan Larsson, Katarina M?hlen-
bock, and Gunilla Thunberg. 2009. TRIK: A talk-
ing and drawing robot for children with commu-
nication disabilities. In Nodalida?09: 17th Nordic
Conference of Computational Linguistics. Short
paper and demonstration.
Seymour Papert. 1993. Mindstorms: Children,
Computers, and Powerful Ideas. Basic Books.
B. Robins, K. Dautenhahn, R. te Boekhorst, and
C.L. Nehaniv. 2008. Behaviour delay and ex-
pressiveness in child-robot interactions: a user
study on interaction kinesics. In HRI?08, 3rd
ACM/IEEE International Conference on Human
Robot Interaction, Amsterdam, Netherlands.
J. Saldien, K. Goris, B. Verrelst, R. Van Ham, and
D. Lefeber. 2006. ANTY: The development of
an intelligent huggable robot for hospitalized chil-
dren. In CLAWAR, 9th International Conference
on Climbing and Walking Robots, Brussels, Bel-
gium.
Stephanie Seneff, Chao Wang, and Julia Zhang.
2004. Spoken conversational interaction for lan-
guage learning. In InSTIL/ICALL 2004 Sympo-
sium on Computer Assisted Learning: NLP and
Speech Technologies in Advanced Language Learn-
ing Systems.
E. Vallduv?. 1992. The Informational Component.
Garland.
119
