Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 369?377,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
Dependency Grammar Induction via Bitext Projection Constraints
Kuzman Ganchev and Jennifer Gillenwater and Ben Taskar
Department of Computer and Information Science
University of Pennsylvania, Philadelphia PA, USA
{kuzman,jengi,taskar}@seas.upenn.edu
Abstract
Broad-coverage annotated treebanks nec-
essary to train parsers do not exist for
many resource-poor languages. The wide
availability of parallel text and accurate
parsers in English has opened up the pos-
sibility of grammar induction through par-
tial transfer across bitext. We consider
generative and discriminative models for
dependency grammar induction that use
word-level alignments and a source lan-
guage parser (English) to constrain the
space of possible target trees. Unlike
previous approaches, our framework does
not require full projected parses, allowing
partial, approximate transfer through lin-
ear expectation constraints on the space
of distributions over trees. We consider
several types of constraints that range
from generic dependency conservation to
language-specific annotation rules for aux-
iliary verb analysis. We evaluate our ap-
proach on Bulgarian and Spanish CoNLL
shared task data and show that we con-
sistently outperform unsupervised meth-
ods and can outperform supervised learn-
ing for limited training data.
1 Introduction
For English and a handful of other languages,
there are large, well-annotated corpora with a vari-
ety of linguistic information ranging from named
entity to discourse structure. Unfortunately, for
the vast majority of languages very few linguis-
tic resources are available. This situation is
likely to persist because of the expense of creat-
ing annotated corpora that require linguistic exper-
tise (Abeill?, 2003). On the other hand, parallel
corpora between many resource-poor languages
and resource-rich languages are ample, motivat-
ing recent interest in transferring linguistic re-
sources from one language to another via parallel
text. For example, several early works (Yarowsky
and Ngai, 2001; Yarowsky et al, 2001; Merlo
et al, 2002) demonstrate transfer of shallow pro-
cessing tools such as part-of-speech taggers and
noun-phrase chunkers by using word-level align-
ment models (Brown et al, 1994; Och and Ney,
2000).
Alshawi et al (2000) and Hwa et al (2005)
explore transfer of deeper syntactic structure:
dependency grammars. Dependency and con-
stituency grammar formalisms have long coex-
isted and competed in linguistics, especially be-
yond English (Mel?c?uk, 1988). Recently, depen-
dency parsing has gained popularity as a simpler,
computationally more efficient alternative to con-
stituency parsing and has spurred several super-
vised learning approaches (Eisner, 1996; Yamada
and Matsumoto, 2003a; Nivre and Nilsson, 2005;
McDonald et al, 2005) as well as unsupervised in-
duction (Klein and Manning, 2004; Smith and Eis-
ner, 2006). Dependency representation has been
used for language modeling, textual entailment
and machine translation (Haghighi et al, 2005;
Chelba et al, 1997; Quirk et al, 2005; Shen et al,
2008), to name a few tasks.
Dependency grammars are arguably more ro-
bust to transfer since syntactic relations between
aligned words of parallel sentences are better con-
served in translation than phrase structure (Fox,
2002; Hwa et al, 2005). Nevertheless, sev-
eral challenges to accurate training and evalua-
tion from aligned bitext remain: (1) partial word
alignment due to non-literal or distant transla-
tion; (2) errors in word alignments and source lan-
guage parses, (3) grammatical annotation choices
that differ across languages and linguistic theo-
ries (e.g., how to analyze auxiliary verbs, conjunc-
tions).
In this paper, we present a flexible learning
369
framework for transferring dependency grammars
via bitext using the posterior regularization frame-
work (Gra?a et al, 2008). In particular, we ad-
dress challenges (1) and (2) by avoiding com-
mitment to an entire projected parse tree in the
target language during training. Instead, we ex-
plore formulations of both generative and discrim-
inative probabilistic models where projected syn-
tactic relations are constrained to hold approxi-
mately and only in expectation. Finally, we ad-
dress challenge (3) by introducing a very small
number of language-specific constraints that dis-
ambiguate arbitrary annotation choices.
We evaluate our approach by transferring from
an English parser trained on the Penn treebank to
Bulgarian and Spanish. We evaluate our results
on the Bulgarian and Spanish corpora from the
CoNLL X shared task. We see that our transfer
approach consistently outperforms unsupervised
methods and, given just a few (2 to 7) language-
specific constraints, performs comparably to a su-
pervised parser trained on a very limited corpus
(30 - 140 training sentences).
2 Approach
At a high level our approach is illustrated in Fig-
ure 1(a). A parallel corpus is word-level aligned
using an alignment toolkit (Gra?a et al, 2009) and
the source (English) is parsed using a dependency
parser (McDonald et al, 2005). Figure 1(b) shows
an aligned sentence pair example where depen-
dencies are perfectly conserved across the align-
ment. An edge from English parent p to child c is
called conserved if word p aligns to word p? in the
second language, c aligns to c? in the second lan-
guage, and p? is the parent of c?. Note that we are
not restricting ourselves to one-to-one alignments
here; p, c, p?, and c? can all also align to other
words. After filtering to identify well-behaved
sentences and high confidence projected depen-
dencies, we learn a probabilistic parsing model us-
ing the posterior regularization framework (Gra?a
et al, 2008). We estimate both generative and dis-
criminative models by constraining the posterior
distribution over possible target parses to approxi-
mately respect projected dependencies and other
rules which we describe below. In our experi-
ments we evaluate the learned models on depen-
dency treebanks (Nivre et al, 2007).
Unfortunately the sentence in Figure 1(b) is
highly unusual in its amount of dependency con-
servation. To get a feel for the typical case, we
used off-the-shelf parsers (McDonald et al, 2005)
for English, Spanish and Bulgarian on two bi-
texts (Koehn, 2005; Tiedemann, 2007) and com-
pared several measures of dependency conserva-
tion. For the English-Bulgarian corpus, we ob-
served that 71.9% of the edges we projected were
edges in the corpus, and we projected on average
2.7 edges per sentence (out of 5.3 tokens on aver-
age). For Spanish, we saw conservation of 64.4%
and an average of 5.9 projected edges per sentence
(out of 11.5 tokens on average).
As these numbers illustrate, directly transfer-
ring information one dependency edge at a time
is unfortunately error prone for two reasons. First,
parser and word alignment errors cause much of
the transferred information to be wrong. We deal
with this problem by constraining groups of edges
rather than a single edge. For example, in some
sentence pair we might find 10 edges that have
both end points aligned and can be transferred.
Rather than requiring our target language parse to
contain each of the 10 edges, we require that the
expected number of edges from this set is at least
10?, where ? is a strength parameter. This gives
the parser freedom to have some uncertainty about
which edges to include, or alternatively to choose
to exclude some of the transferred edges.
A more serious problem for transferring parse
information across languages are structural differ-
ences and grammar annotation choices between
the two languages. For example dealing with aux-
iliary verbs and reflexive constructions. Hwa et al
(2005) also note these problems and solve them by
introducing dozens of rules to transform the trans-
ferred parse trees. We discuss these differences
in detail in the experimental section and use our
framework introduce a very small number of rules
to cover the most common structural differences.
3 Parsing Models
We explored two parsing models: a generative
model used by several authors for unsupervised in-
duction and a discriminative model used for fully
supervised training.
The discriminative parser is based on the
edge-factored model and features of the MST-
Parser (McDonald et al, 2005). The parsing
model defines a conditional distribution p?(z | x)
over each projective parse tree z for a particular
sentence x, parameterized by a vector ?. The prob-
370
(a)
(b)
Figure 1: (a) Overview of our grammar induction approach via bitext: the source (English) is parsed and word-aligned with
target; after filtering, projected dependencies define constraints over target parse tree space, providing weak supervision for
learning a target grammar. (b) An example word-aligned sentence pair with perfectly projected dependencies.
ability of any particular parse is
p?(z | x) ?
?
z?z
e???(z,x), (1)
where z is a directed edge contained in the parse
tree z and ? is a feature function. In the fully su-
pervised experiments we run for comparison, pa-
rameter estimation is performed by stochastic gra-
dient ascent on the conditional likelihood func-
tion, similar to maximum entropy models or con-
ditional random fields. One needs to be able to
compute expectations of the features ?(z,x) under
the distribution p?(z | x). A version of the inside-
outside algorithm (Lee and Choi, 1997) performs
this computation. Viterbi decoding is done using
Eisner?s algorithm (Eisner, 1996).
We also used a generative model based on de-
pendency model with valence (Klein and Man-
ning, 2004). Under this model, the probability of
a particular parse z and a sentence with part of
speech tags x is given by
p?(z,x) = proot(r(x)) ? (2)
(?
z?z
p?stop(zp, zd, vz) pchild(zp, zd, zc)
)
?
(?
x?x
pstop(x, left, vl) pstop(x, right, vr)
)
where r(x) is the part of speech tag of the root
of the parse tree z, z is an edge from parent zp
to child zc in direction zd, either left or right, and
vz indicates valency?false if zp has no other chil-
dren further from it in direction zd than zc, true
otherwise. The valencies vr/vl are marked as true
if x has any children on the left/right in z, false
otherwise.
4 Posterior Regularization
Gra?a et al (2008) introduce an estimation frame-
work that incorporates side-information into un-
supervised problems in the form of linear con-
straints on posterior expectations. In grammar
transfer, our basic constraint is of the form: the
expected proportion of conserved edges in a sen-
tence pair is at least ? (the exact proportion we
used was 0.9, which was determined using un-
labeled data as described in Section 5). Specifi-
cally, let Cx be the set of directed edges projected
from English for a given sentence x, then given
a parse z, the proportion of conserved edges is
f(x, z) = 1|Cx|
?
z?z 1(z ? Cx) and the expected
proportion of conserved edges under distribution
p(z | x) is
Ep[f(x, z)] =
1
|Cx|
?
z?Cx
p(z | x).
The posterior regularization framework (Gra?a
et al, 2008) was originally defined for gener-
ative unsupervised learning. The standard ob-
jective is to minimize the negative marginal
log-likelihood of the data : E?[? log p?(x)] =
E?[? log
?
z p?(z,x)] over the parameters ? (we
use E? to denote expectation over the sample sen-
tences x). We typically also add standard regular-
ization term on ?, resulting from a parameter prior
? log p(?) = R(?), where p(?) is Gaussian for the
MST-Parser models and Dirichlet for the valence
model.
To introduce supervision into the model, we de-
fine a set Qx of distributions over the hidden vari-
ables z satisfying the desired posterior constraints
in terms of linear equalities or inequalities on fea-
ture expectations (we use inequalities in this pa-
per):
Qx = {q(z) : E[f(x, z)] ? b}.
371
Basic Uni-gram Features
xi-word, xi-pos
xi-word
xi-pos
xj-word, xj-pos
xj-word
xj-pos
Basic Bi-gram Features
xi-word, xi-pos, xj-word, xj-pos
xi-pos, xj-word, xj-pos
xi-word, xj-word, xj-pos
xi-word, xi-pos, xj-pos
xi-word, xi-pos, xj-word
xi-word, xj-word
xi-pos, xj-pos
In Between POS Features
xi-pos, b-pos, xj-pos
Surrounding Word POS Features
xi-pos, xi-pos+1, xj-pos-1, xj-pos
xi-pos-1, xi-pos, xj-pos-1, xj-pos
xi-pos, xi-pos+1, xj-pos, xj-pos+1
xi-pos-1, xi-pos, xj-pos, xj-pos+1
Table 1: Features used by the MSTParser. For each edge (i, j), xi-word is the parent word and xj-word is the child word,
analogously for POS tags. The +1 and -1 denote preceeding and following tokens in the sentence, while b denotes tokens
between xi and xj .
In this paper, for example, we use the conserved-
edge-proportion constraint as defined above. The
marginal log-likelihood objective is then modi-
fied with a penalty for deviation from the de-
sired set of distributions, measured by KL-
divergence from the set Qx, KL(Qx||p?(z|x)) =
minq?Qx KL(q(z)||p?(z|x)). The generative
learning objective is to minimize:
E?[? log p?(x)] +R(?) + E?[KL(Qx||p?(z | x))].
For discriminative estimation (Ganchev et al,
2008), we do not attempt to model the marginal
distribution of x, so we simply have the two regu-
larization terms:
R(?) + E?[KL(Qx||p?(z | x))].
Note that the idea of regularizing moments is re-
lated to generalized expectation criteria algorithm
of Mann and McCallum (2007), as we discuss in
the related work section below. In general, the
objectives above are not convex in ?. To opti-
mize these objectives, we follow an Expectation
Maximization-like scheme. Recall that standard
EM iterates two steps. An E-step computes a prob-
ability distribution over the model?s hidden vari-
ables (posterior probabilities) and an M-step that
updates the model?s parameters based on that dis-
tribution. The posterior-regularized EM algorithm
leaves the M-step unchanged, but involves project-
ing the posteriors onto a constraint set after they
are computed for each sentence x:
argmin
q
KL(q(z) ? p?(z|x))
s.t. Eq[f(x, z)] ? b,
(3)
where p?(z|x) are the posteriors. The new poste-
riors q(z) are used to compute sufficient statistics
for this instance and hence to update the model?s
parameters in the M-step for either the generative
or discriminative setting.
The optimization problem in Equation 3 can be
efficiently solved in its dual formulation:
argmin
??0
b>?+log
?
z
p?(z | x) exp {??
>f(x, z)}.
(4)
Given ?, the primal solution is given by: q(z) =
p?(z | x) exp{??>f(x, z)}/Z, where Z is a nor-
malization constant. There is one dual variable per
expectation constraint, and we can optimize them
by projected gradient descent, similar to log-linear
model estimation. The gradient with respect to ?
is given by: b ? Eq[f(x, z)], so it involves com-
puting expectations under the distribution q(z).
This remains tractable as long as features factor by
edge, f(x, z) =
?
z?z f(x, z), because that en-
sures that q(z) will have the same form as p?(z |
x). Furthermore, since the constraints are per in-
stance, we can use incremental or online version
of EM (Neal and Hinton, 1998), where we update
parameters ? after posterior-constrained E-step on
each instance x.
5 Experiments
We conducted experiments on two languages:
Bulgarian and Spanish, using each of the pars-
ing models. The Bulgarian experiments transfer a
parser from English to Bulgarian, using the Open-
Subtitles corpus (Tiedemann, 2007). The Span-
ish experiments transfer from English to Spanish
using the Spanish portion of the Europarl corpus
(Koehn, 2005). For both corpora, we performed
word alignments with the open source PostCAT
(Gra?a et al, 2009) toolkit. We used the Tokyo
tagger (Tsuruoka and Tsujii, 2005) to POS tag
the English tokens, and generated parses using
the first-order model of McDonald et al (2005)
with projective decoding, trained on sections 2-21
of the Penn treebank with dependencies extracted
using the head rules of Yamada and Matsumoto
(2003b). For Bulgarian we trained the Stanford
POS tagger (Toutanova et al, 2003) on the Bul-
372
Discriminative model Generative model
Bulgarian Spanish Bulgarian Spanish
no rules 2 rules 7 rules no rules 3 rules no rules 2 rules 7 rules no rules 3 rules
Baseline 63.8 72.1 72.6 67.6 69.0 66.5 69.1 71.0 68.2 71.3
Post.Reg. 66.9 77.5 78.3 70.6 72.3 67.8 70.7 70.8 69.5 72.8
Table 2: Comparison between transferring a single tree of edges and transferring all possible projected edges. The transfer
models were trained on 10k sentences of length up to 20, all models tested on CoNLL train sentences of up to 10 words.
Punctuation was stripped at train time.
gtreebank corpus from CoNLL X. The Spanish
Europarl data was POS tagged with the FreeLing
language analyzer (Atserias et al, 2006). The dis-
criminative model used the same features as MST-
Parser, summarized in Table 1.
In order to evaluate our method, we a baseline
inspired by Hwa et al (2005). The baseline con-
structs a full parse tree from the incomplete and
possibly conflicting transferred edges using a sim-
ple random process. We start with no edges and
try to add edges one at a time verifying at each
step that it is possible to complete the tree. We
first try to add the transferred edges in random or-
der, then for each orphan node we try all possible
parents (both in random order). We then use this
full labeling as supervision for a parser. Note that
this baseline is very similar to the first iteration of
our model, since for a large corpus the different
random choices made in different sentences tend
to smooth each other out. We also tried to cre-
ate rules for the adoption of orphans, but the sim-
ple rules we tried added bias and performed worse
than the baseline we report. Table 2 shows at-
tachment accuracy of our method and the baseline
for both language pairs under several conditions.
By attachment accuracy we mean the fraction of
words assigned the correct parent. The experimen-
tal details are described in this section. Link-left
baselines for these corpora are much lower: 33.8%
and 27.9% for Bulgarian and Spanish respectively.
5.1 Preprocessing
Preliminary experiments showed that our word
alignments were not always appropriate for syn-
tactic transfer, even when they were correct for
translation. For example, the English ?bike/V?
could be translated in French as ?aller/V en
v?lo/N?, where the word ?bike? would be aligned
with ?v?lo?. While this captures some of the se-
mantic shared information in the two languages,
we have no expectation that the noun ?v?lo?
will have a similar syntactic behavior to the verb
?bike?. To prevent such false transfer, we filter
out alignments between incompatible POS tags. In
both language pairs, filtering out noun-verb align-
ments gave the biggest improvement.
Both corpora also contain sentence fragments,
either because of question responses or frag-
mented speech in movie subtitles or because of
voting announcements and similar formulaic sen-
tences in the parliamentary proceedings. We over-
come this problem by filtering out sentences that
do not have a verb as the English root or for which
the English root is not aligned to a verb in the
target language. For the subtitles corpus we also
remove sentences that end in an ellipsis or con-
tain more than one comma. Finally, following
(Klein and Manning, 2004) we strip out punctu-
ation from the sentences. For the discriminative
model this did not affect results significantly but
improved them slightly in most cases. We found
that the generative model gets confused by punctu-
ation and tends to predict that periods at the end of
sentences are the parents of words in the sentence.
Our basic model uses constraints of the form:
the expected proportion of conserved edges in a
sentence pair is at least ? = 90%.1
5.2 No Language-Specific Rules
We call the generic model described above ?no-
rules? to distinguish it from the language-specific
constraints we introduce in the sequel. The no
rules columns of Table 2 summarize the perfor-
mance in this basic setting. Discriminative models
outperform the generative models in the majority
of cases. The left panel of Table 3 shows the most
common errors by child POS tag, as well as by
true parent and guessed parent POS tag.
Figure 2 shows that the discriminative model
continues to improve with more transfer-type data
1We chose ? in the following way: we split the unlabeled
parallel text into two portions. We trained a models with dif-
ferent ? on one portion and ran it on the other portion. We
chose the model with the highest fraction of conserved con-
straints on the second portion.
373
 0.52 0.54 0.56 0.58 0.6 0.62 0.64 0.66 0.68
 0.1
 1
 10
accuracy (%)
trainin
g data 
size (th
ousand
s of se
ntence
s)
our me
thod baselin
e
Figure 2: Learning curve of the discriminative no-rules
transfer model on Bulgarian bitext, testing on CoNLL train
sentences of up to 10 words.
Figure 3: A Spanish example where an auxiliary verb dom-
inates the main verb.
up to at least 40 thousand sentences.
5.3 Annotation guidelines and constraints
Using the straightforward approach outlined
above is a dramatic improvement over the standard
link-left baseline (and the unsupervised generative
model as we discuss below), however it doesn?t
have any information about the annotation guide-
lines used for the testing corpus. For example, the
Bulgarian corpus has an unusual treatment of non-
finite clauses. Figure 4 shows an example. We see
that the ?da? is the parent of both the verb and its
object, which is different than the treatment in the
English corpus.
We propose to deal with these annotation dis-
similarities by creating very simple rules. For
Spanish, we have three rules. The first rule sets
main verbs to dominate auxiliary verbs. Specifi-
cally, whenever an auxiliary precedes a main verb
the main verb becomes its parent and adopts its
children; if there is only one main verb it becomes
the root of the sentence; main verbs also become
Figure 4: An example where transfer fails because of
different handling of reflexives and nonfinite clauses. The
alignment links provide correct glosses for Bulgarian words.
?Bh? is a past tense marker while ?se? is a reflexive marker.
parents of pronouns, adverbs, and common nouns
that directly preceed auxiliary verbs. By adopt-
ing children we mean that we change the parent
of transferred edges to be the adopting node. The
second Spanish rule states that the first element
of an adjective-noun or noun-adjective pair domi-
nates the second; the first element also adopts the
children of the second element. The third and fi-
nal Spanish rule sets all prepositions to be chil-
dren of the first main verb in the sentence, unless
the preposition is a ?de? located between two noun
phrases. In this later case, we set the closest noun
in the first of the two noun phrases as the preposi-
tion?s parent.
For Bulgarian the first rule is that ?da? should
dominate all words until the next verb and adopt
their noun, preposition, particle and adverb chil-
dren. The second rule is that auxiliary verbs
should dominate main verbs and adopt their chil-
dren. We have a list of 12 Bulgarian auxiliary
verbs. The ?seven rules? experiments add rules for
5 more words similar to the rule for ?da?, specif-
ically ?qe?, ?li?, ?kakvo?, ?ne?, ?za?. Table 3
compares the errors for different linguistic rules.
When we train using the ?da? rule and the rules for
auxiliary verbs, the model learns that main verbs
attach to auxiliary verbs and that ?da? dominates
its nonfinite clause. This causes an improvement
in the attachment of verbs, and also drastically re-
duces words being attached to verbs instead of par-
ticles. The latter is expected because ?da? is an-
alyzed as a particle in the Bulgarian POS tagset.
We see an improvement in root/verb confusions
since ?da? is sometimes errenously attached to a
the following verb rather than being the root of the
sentence.
The rightmost panel of Table 3 shows similar
analysis when we also use the rules for the five
other closed-class words. We see an improvement
in attachments in all categories, but no qualitative
change is visible. The reason for this is probably
that these words are relatively rare, but by encour-
aging the model to add an edge, it also rules out in-
correct edges that would cross it. Consequently we
are seeing improvements not only directly from
the constraints we enforce but also indirectly as
types of edges that tend to get ruled out.
5.4 Generative parser
The generative model we use is a state of the art
model for unsupervised parsing and is our only
374
No Rules Two Rules Seven Rules
child POS parent POS
acc(%) errors errors
V 65.2 2237 T/V 2175
N 73.8 1938 V/V 1305
P 58.5 1705 N/V 1112
R 70.3 961 root/V 555
child POS parent POS
acc(%) errors errors
N 78.7 1572 N/V 938
P 70.2 1224 V/V 734
V 84.4 1002 V/N 529
R 79.3 670 N/N 376
child POS parent POS
acc(%) errors errors
N 79.3 1532 N/V 1116
P 75.7 998 V/V 560
R 69.3 993 V/N 507
V 86.2 889 N/N 450
Table 3: Top 4 discriminative parser errors by child POS tag and true/guess parent POS tag in the Bulgarian CoNLL train data
of length up to 10. Training with no language-specific rules (left); two rules (center); and seven rules (right). POS meanings:
V verb, N noun, P pronoun, R preposition, T particle. Accuracies are by child or parent truth/guess POS tag.
 0.6 0.65 0.7 0.75
 20 4
0 60
 80 1
00 12
0 140
accuracy (%)
supervis
ed traini
ng data s
ize
supervis
ed no rules two rule
s
seven ru
les
 0.65 0.7 0.75 0.8
 20 4
0 60
 80 1
00 12
0 140
accuracy (%)
supervis
ed traini
ng data s
ize
supervis
ed no rules three rul
es
 0.65 0.7 0.75 0.8
 20 4
0 60
 80 1
00 12
0 140
accuracy (%)
supervis
ed train
ing data
 size
supervis
ed no rules two rule
s
seven ru
les
 0.65 0.7 0.75 0.8
 20 4
0 60
 80 1
00 12
0 140
accuracy (%)
supervis
ed train
ing data
 sizesupervis
ed no rules three ru
les
Figure 5: Comparison to parsers with supervised estimation and transfer. Top: Generative. Bottom: Discriminative. Left:
Bulgarian. Right: Spanish. The transfer models were trained on 10k sentences all of length at most 20, all models tested
on CoNLL train sentences of up to 10 words. The x-axis shows the number of examples used to train the supervised model.
Boxes show first and third quartile, whiskers extend to max and min, with the line passing through the median. Supervised
experiments used 30 random samples from CoNLL train.
fully unsupervised baseline. As smoothing we add
a very small backoff probability of 4.5 ? 10?5 to
each learned paramter. Unfortunately, we found
generative model performance was disappointing
overall. The maximum unsupervised accuracy it
achieved on the Bulgarian data is 47.6% with ini-
tialization from Klein and Manning (2004) and
this result is not stable. Changing the initialization
parameters, training sample, or maximum sen-
tence length used for training drastically affected
the results, even for samples with several thousand
sentences. When we use the transferred informa-
tion to constrain the learning, EM stabilizes and
achieves much better performance. Even setting
all parameters equal at the outset does not prevent
the model from learning the dependency structure
of the aligned language. The top panels in Figure 5
show the results in this setting. We see that perfor-
mance is still always below the accuracy achieved
by supervised training on 20 annotated sentences.
However, the improvement in stability makes the
algorithm much more usable. As we shall see be-
low, the discriminative parser performs even better
than the generative model.
5.5 Discriminative parser
We trained our discriminative parser for 100 iter-
ations of online EM with a Gaussian prior vari-
ance of 100. Results for the discriminative parser
are shown in the bottom panels of Figure 5. The
supervised experiments are given to provide con-
text for the accuracies. For Bulgarian, we see that
without any hints about the annotation guidelines,
the transfer system performs better than an unsu-
375
pervised parser, comparable to a supervised parser
trained on 10 sentences. However, if we spec-
ify just the two rules for ?da? and verb conjuga-
tions performance jumps to that of training on 60-
70 fully labeled sentences. If we have just a lit-
tle more prior knowledge about how closed-class
words are handled, performance jumps above 140
fully labeled sentence equivalent.
We observed another desirable property of the
discriminative model. While the generative model
can get confused and perform poorly when the
training data contains very long sentences, the dis-
criminative parser does not appear to have this
drawback. In fact we observed that as the maxi-
mum training sentence length increased, the pars-
ing performance also improved.
6 Related Work
Our work most closely relates to Hwa et al (2005),
who proposed to learn generative dependency
grammars using Collins? parser (Collins, 1999) by
constructing full target parses via projected de-
pendencies and completion/transformation rules.
Hwa et al (2005) found that transferring depen-
dencies directly was not sufficient to get a parser
with reasonable performance, even when both
the source language parses and the word align-
ments are performed by hand. They adjusted for
this by introducing on the order of one or two
dozen language-specific transformation rules to
complete target parses for unaligned words and
to account for diverging annotation rules. Trans-
ferring from English to Spanish in this way, they
achieve 72.1% and transferring to Chinese they
achieve 53.9%.
Our learning method is very closely related to
the work of (Mann and McCallum, 2007; Mann
and McCallum, 2008) who concurrently devel-
oped the idea of using penalties based on pos-
terior expectations of features not necessarily in
the model in order to guide learning. They call
their method generalized expectation constraints
or alternatively expectation regularization. In this
volume (Druck et al, 2009) use this framework
to train a dependency parser based on constraints
stated as corpus-wide expected values of linguis-
tic rules. The rules select a class of edges (e.g.
auxiliary verb to main verb) and require that the
expectation of these be close to some value. The
main difference between this work and theirs is
the source of the information (a linguistic infor-
mant vs. cross-lingual projection). Also, we de-
fine our regularization with respect to inequality
constraints (the model is not penalized for exceed-
ing the required model expectations), while they
require moments to be close to an estimated value.
We suspect that the two learning methods could
perform comparably when they exploit similar in-
formation.
7 Conclusion
In this paper, we proposed a novel and effec-
tive learning scheme for transferring dependency
parses across bitext. By enforcing projected de-
pendency constraints approximately and in expec-
tation, our framework allows robust learning from
noisy partially supervised target sentences, instead
of committing to entire parses. We show that dis-
criminative training generally outperforms gener-
ative approaches even in this very weakly super-
vised setting. By adding easily specified language-
specific constraints, our models begin to rival
strong supervised baselines for small amounts of
data. Our framework can handle a wide range of
constraints and we are currently exploring richer
syntactic constraints that involve conservation of
multiple edge constructions as well as constraints
on conservation of surface length of dependen-
cies.
Acknowledgments
This work was partially supported by an Integra-
tive Graduate Education and Research Trainee-
ship grant from National Science Foundation
(NSFIGERT 0504487), by ARO MURI SUB-
TLE W911NF-07-1-0216 and by the European
Projects AsIsKnown (FP6-028044) and LTfLL
(FP7-212578).
References
A. Abeille?. 2003. Treebanks: Building and Using
Parsed Corpora. Springer.
H. Alshawi, S. Bangalore, and S. Douglas. 2000.
Learning dependency translation models as collec-
tions of finite state head transducers. Computational
Linguistics, 26(1).
J. Atserias, B. Casas, E. Comelles, M. Gonza?lez,
L. Padro?, and M. Padro?. 2006. Freeling 1.3: Syn-
tactic and semantic services in an open-source nlp
library. In Proc. LREC, Genoa, Italy.
376
P. F. Brown, S. Della Pietra, V. J. Della Pietra, and R. L.
Mercer. 1994. The mathematics of statistical ma-
chine translation: Parameter estimation. Computa-
tional Linguistics, 19(2):263?311.
C. Chelba, D. Engle, F. Jelinek, V. Jimenez, S. Khudan-
pur, L. Mangu, H. Printz, E. Ristad, R. Rosenfeld,
A. Stolcke, and D. Wu. 1997. Structure and perfor-
mance of a dependency language model. In Proc.
Eurospeech.
M. Collins. 1999. Head-Driven Statistical Models for
Natural Language Parsing. Ph.D. thesis, University
of Pennsylvania.
G. Druck, G. Mann, and A. McCallum. 2009. Semi-
supervised learning of dependency parsers using
generalized expectation criteria. In Proc. ACL.
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: an exploration. In Proc. CoLing.
H. Fox. 2002. Phrasal cohesion and statistical machine
translation. In Proc. EMNLP, pages 304?311.
K. Ganchev, J. Graca, J. Blitzer, and B. Taskar.
2008. Multi-view learning over structured and non-
identical outputs. In Proc. UAI.
J. Grac?a, K. Ganchev, and B. Taskar. 2008. Expec-
tation maximization and posterior constraints. In
Proc. NIPS.
J. Grac?a, K. Ganchev, and B. Taskar. 2009. Post-
cat - posterior constrained alignment toolkit. In The
Third Machine Translation Marathon.
A. Haghighi, A. Ng, and C. Manning. 2005. Ro-
bust textual inference via graph matching. In Proc.
EMNLP.
R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and
O. Kolak. 2005. Bootstrapping parsers via syntactic
projection across parallel texts. Natural Language
Engineering, 11:11?311.
D. Klein and C. Manning. 2004. Corpus-based induc-
tion of syntactic structure: Models of dependency
and constituency. In Proc. of ACL.
P. Koehn. 2005. Europarl: A parallel corpus for statis-
tical machine translation. In MT Summit.
S. Lee and K. Choi. 1997. Reestimation and best-
first parsing algorithm for probabilistic dependency
grammar. In In WVLC-5, pages 41?55.
G. Mann and A. McCallum. 2007. Simple, robust,
scalable semi-supervised learning via expectation
regularization. In Proc. ICML.
G. Mann and A. McCallum. 2008. Generalized expec-
tation criteria for semi-supervised learning of con-
ditional random fields. In Proc. ACL, pages 870 ?
878.
R. McDonald, K. Crammer, and F. Pereira. 2005. On-
line large-margin training of dependency parsers. In
Proc. ACL, pages 91?98.
I. Mel?c?uk. 1988. Dependency syntax: theory and
practice. SUNY. inci.
P. Merlo, S. Stevenson, V. Tsang, and G. Allaria. 2002.
A multilingual paradigm for automatic verb classifi-
cation. In Proc. ACL.
R. M. Neal and G. E. Hinton. 1998. A new view of the
EM algorithm that justifies incremental, sparse and
other variants. In M. I. Jordan, editor, Learning in
Graphical Models, pages 355?368. Kluwer.
J. Nivre and J. Nilsson. 2005. Pseudo-projective de-
pendency parsing. In Proc. ACL.
J. Nivre, J. Hall, S. Ku?bler, R. McDonald, J. Nils-
son, S. Riedel, and D. Yuret. 2007. The CoNLL
2007 shared task on dependency parsing. In Proc.
EMNLP-CoNLL.
F. J. Och and H. Ney. 2000. Improved statistical align-
ment models. In Proc. ACL.
C. Quirk, A. Menezes, and C. Cherry. 2005. De-
pendency treelet translation: syntactically informed
phrasal smt. In Proc. ACL.
L. Shen, J. Xu, and R. Weischedel. 2008. A new
string-to-dependency machine translation algorithm
with a target dependency language model. In Proc.
of ACL.
N. Smith and J. Eisner. 2006. Annealing structural
bias in multilingual weighted grammar induction. In
Proc. ACL.
J. Tiedemann. 2007. Building a multilingual parallel
subtitle corpus. In Proc. CLIN.
K. Toutanova, D. Klein, C. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In Proc. HLT-NAACL.
Y. Tsuruoka and J. Tsujii. 2005. Bidirectional infer-
ence with the easiest-first strategy for tagging se-
quence data. In Proc. HLT/EMNLP.
H. Yamada and Y. Matsumoto. 2003a. Statistical de-
pendency analysis with support vector machines. In
Proc. IWPT, pages 195?206.
H. Yamada and Y. Matsumoto. 2003b. Statistical de-
pendency analysis with support vector machines. In
Proc. IWPT.
D. Yarowsky and G. Ngai. 2001. Inducing multilin-
gual pos taggers and np bracketers via robust pro-
jection across aligned corpora. In Proc. NAACL.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001.
Inducing multilingual text analysis tools via robust
projection across aligned corpora. In Proc. HLT.
377
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 710?720, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
Discovering Diverse and Salient Threads in Document Collections
Jennifer Gillenwater Alex Kulesza
Department of Computer and Information Science
University of Pennsylvania
Philadelphia, PA 19104
{jengi,kulesza,taskar}@cis.upenn.edu
Ben Taskar
Abstract
We propose a novel probabilistic technique
for modeling and extracting salient struc-
ture from large document collections. As
in clustering and topic modeling, our goal
is to provide an organizing perspective into
otherwise overwhelming amounts of infor-
mation. We are particularly interested in
revealing and exploiting relationships be-
tween documents. To this end, we focus on
extracting diverse sets of threads?singly-
linked, coherent chains of important doc-
uments. To illustrate, we extract research
threads from citation graphs and construct
timelines from news articles. Our method
is highly scalable, running on a corpus of
over 30 million words in about four minutes,
more than 75 times faster than a dynamic
topic model. Finally, the results from our
model more closely resemble human news
summaries according to several metrics and
are also preferred by human judges.
1 Introduction
The increasing availability of large document
collections has the potential to revolutionize
our ability to understand the world. However,
the scale and complexity of such collections fre-
quently make it difficult to quickly grasp the
important details and the relationships between
them. As a result, automatic interfaces for data
navigation, exploration, aggregation, and analy-
sis are becoming increasingly valuable.
In this work we propose a novel approach:
threading structured document collections. Con-
sider a large graph, with documents as nodes
and edges indicating relationships, as in Figure 1.
Our goal is to find a diverse set of paths (or
threads) through the collection that are indi-
vidually coherent and together cover the most
salient parts. For example, given a collection
of academic papers, we might want to identify
the most significant lines of research, threading
the citation graph to produce chains of impor-
tant papers. Or, given news articles connected
chronologically, we might want to extract threads
of articles to form timelines describing the ma-
jor events from the most significant news stories.
Top-tier news organizations like The New York
Times and The Guardian regularly publish such
timelines, but have so far been limited to creat-
ing them by hand. Other possibile applications
might include discovering trends on social media
sites, or perhaps mining blog entries for impor-
tant conversations through trackback links. We
show how these kinds of threading tasks can be
done efficiently, providing a simple, practical tool
for representing graph-based data that offers new
possibilities compared with existing models.
The Topic Detection and Tracking (TDT) pro-
gram (Wayne, 2000) has recently led to some
research in this direction. Several of TDT?s core
tasks, like link detection, topic detection, and
topic tracking, can be seen as subroutines for
the threading problem. Our work, however, ad-
dresses these tasks jointly, using a global prob-
abilistic model with a tractable inference algo-
rithm. To achieve this, we employ structured
determinantal point processes (SDPPs) (Kulesza
710
Figure 1: An illustration of document collection threading. We first build a graph from the collection, using
measures of importance and relatedness to weight nodes (documents) and build edges (relationships). Then,
from this graph, we extract a diverse, salient set of threads to represent the collection. The supplement
contains a version of this figure for our real-world news dataset.
and Taskar, 2010), which offer a natural prob-
abilistic model over sets of structures (such as
threads) where diversity is desired, and we incor-
porate k-DPP extensions to control the number
of threads (Kulesza and Taskar, 2011).
We apply our model to two real-world datasets,
extracting threads of research papers and time-
lines of news articles. An example of news
threads extracted using our model is shown in
Figure 2. Quantitative evaluation shows that our
model significantly outperforms multiple base-
lines, including dynamic topic models, in com-
parisons with human-produced news summaries.
It also outperforms baseline methods in a user
evaluation of thread coherence, and runs 75 times
faster than a dynamic topic model.
The primary contributions of this paper
are: (1) proposing a novel framework for finding
diverse and salient sets of document threads; (2)
combining SDPPs and k-DPPs to implement the
proposed model; (3) introducing random projec-
tions to improve efficiency with only bounded
deviation; and (4) demonstrating the model on
large-scale, real-world datasets.
2 Related Work
A variety of papers from the topic tracking liter-
ature are broadly related to our work (Mei and
Zhai, 2005; Blei and Lafferty, 2006; Leskovec et
al., 2009; Ahmed and Xing, 2010). Blei and Laf-
ferty (2006) recently introduced dynamic topic
models (DTMs). Assuming a division of doc-
uments into time slices, a DTM draws in each
slice a set of topics from a Gaussian distribution
whose mean is determined by the topics from
the previous slice. In this way, a DTM generates
topic threads. In this work we are interested in
the related but not identical task of generating
document threads. We engineer a baseline for
constructing document threads from DTM topic
threads (see Section 6.2.2), but the topic-centric
nature of DTMs means they are not ideal for
this task. Figure 2 illustrates some of the issues.
The work of Ahmed and Xing (2010) general-
izes DTMs to iDTMs (infinite DTMs) by allowing
topics to span only a subset of time slices, and
allowing an arbitrary number of topics. However,
iDTMs still require placing documents into dis-
crete epochs, and the issue of generating topic
rather than document threads remains. In Sec-
tion 6 we compare to DTMs but not iDTMs
because an implementation of iDTMs was not
readily available.
In the information retrieval community there
has also been work on extracting temporal in-
formation from document collections. Swan and
Jensen (2000) proposed a system for finding tem-
porally clustered named entities in news text and
presenting them on a timeline. Allan, Gupta,
and Khandelwal (2001) introduced the task of
temporal summarization, which takes a stream
of news articles on a particular topic and tries to
extract sentences describing important events as
they occur. Yan et al011) evaluated methods
for choosing sentences from temporally clustered
documents that are relevant to a query. Here, we
are interested not in extracting topically grouped
entities or sentences, but instead in organizing a
subset of the articles themselves into timelines,
with topic identification as a side effect.
There has also been some prior work focus-
ing more directly on threading. Shahaf and
711
Jan 08 Jan 28 Feb 17 Mar 09 Mar 29 Apr 18 May 08 May 28 Jun 17
pope vatican church parkinson 
israel palestinian iraqi israeli gaza abbas baghdad 
owen nominees senate democrats judicial filibusters 
social tax security democrats rove accounts 
iraq iraqi killed baghdad arab marines deaths forces 
Jan 08 Jan 28 Feb 17 Mar 09 Mar 29 Apr 18 May 08 May 28 Jun 17
cancer heart breast women disease aspirin risk study 
palestinian israel baghdad palestinians sunni korea gaza israeli 
social security accounts retirement benefits tax workers 401 payroll 
mets rangers dodgers delgado martinez astacio angels mientkiewicz 
hotel kitchen casa inches post shade monica closet 
Feb 24: Parkinson?s Disease Increases Risks to Pope
Feb 26: Pope?s Health Raises Questions About His Ability to Lead
Mar 13: Pope Returns Home After 18 Days at Hospital
Apr 01: Pope?s Condition Worsens as World Prepares for End of Pa-
pacy
Apr 02: Pope, Though Gravely Ill, Utters Thanks for Prayers
Apr 18: Europeans Fast Falling Away from Church
Apr 20: In Developing World, Choice [of Pope] Met with Skepticism
May 18: Pope Sends Message with Choice of Name
Jan 11: Study Backs Meat, Colon Tumor Link
Feb 07: Patients?and Many Doctors?Still Don?t Know How Often
Women Get Heart Disease
Mar 07: Aspirin Therapy Benefits Women, but Not in the Way It
Aids Men
Mar 16: Study Shows Radiation Therapy Doesn?t Increase Heart Dis-
ease Risk for Breast Cancer Patients
Apr 11: Personal Health: Women Struggle for Parity of the Heart
May 16: Black Women More Likely to Die from Breast Cancer
May 24: Studies Bolster Diet, Exercise for Breast Cancer Patients
Jun 21: Another Reason Fish is Good for You
Figure 2: A set of five news threads generated by our method (left) and a dynamic topic model (right) for
the first half of 2005. Above, the threads are shown on a timeline with the most salient words superimposed;
below, the dates and headlines from the threads appearing at the bottom are listed. Topic models are not
designed for threading and often link together topically similar documents that do not constitute a coherent
news story, as on the right.
Guestrin (2010) and Chieu and Lee (2004) pro-
posed selecting a single thread, whereas we seek
a set of threads, which is a more general task.
Shahaf, Guestrin, and Horvitz (2012) recently
proposed metro maps as alternative structured
representations of related news stories. Metro
maps are effectively sets of non-chronological
threads that are encouraged to intersect and thus
create a ?map? of events and topics. However,
these approaches assume some prior knowledge
about content. Shahaf and Guestrin (2010), for
example, assume the thread endpoints are spec-
ified, and Chieu and Lee (2004) require a set
of query words. These inputs make it possible
to quickly pare down the document graph. In
constrast, we work with very large graphs and
consider all possible threads. Furthermore, while
some prior work has relied on heuristics and ap-
proximate optimization, we can efficiently sample
a joint probabilistic model with approximation
guarantees.
In previous work on SDPPs (structured DPPs),
which we use here to model threads, Kulesza and
Taskar (2010) derived exact polynomial-time al-
gorithms for sampling and other inference. How-
ever, their experiments involved feature vectors
of only 32 dimensions. For text, natural features
like word occurrences typically yield dimension-
ality in the tens of thousands, making SDPP
inference prohibitively expensive. We solve this
problem by reducing the feature space using ran-
dom projections (see Section 5). We prove that
even a logarithmic number of projections is suffi-
cient to yield a close approximation to the origi-
nal SDPP distribution.
3 Framework
Before presenting our probabilistic model, we
describe a natural framework for representing
document collections. We assume that the collec-
tion has been transformed into a directed graph
G = (V,E) on n vertices, where each node cor-
responds to a document and each edge repre-
sents a relationship between documents whose
semantics depend on the task. We also as-
sume the existence of a weight function w on
nodes and edges, which measures the impor-
tance or salience of documents and the relative
strength of the relationships between them. For-
mally, we define the weight of a path (or thread)
y = (y(1), y(2), . . . , y(T )), (y(t), y(t+1)) ? E by:
w(y) =
T?
t=1
w
(
y(t)
)
+
T?1?
t=1
w
(
y(t), y(t+1)
)
. (1)
712
Lastly, we also assume the existence of node
features. Specifically, let ? represent a feature
mapping from nodes to RD (for example, tf-idf
word vectors). The feature map on a thread is
then just a sum over the nodes in the thread:
?(y) =
T?
t=1
?
(
y(t)
)
. (2)
(If it is convenient to have features on edges as
well as on nodes, it is possible to accommodate
them without affecting asymptotic performance.)
Given this framework, our goal is to develop
a probabilistic model over sets of k threads of
length T , favoring sets whose threads have large
weight but are also distinct from one another with
respect to ?. In other words, a high-probability
set under the model should include threads that
are both salient and diverse.
This is a daunting problem, given that the
number of possible sets of threads is O(nkT ).
For the datasets we use later, the actual number
is around 21000. However, we will show how to
construct the desired model in a way that allows
efficient inference, even for large datasets, using
determinantal point processes (DPPs). We begin
with some background.
4 Determinantal point processes
A DPP is a type of distribution over subsets.
Formally, a DPP P on a set of items Y =
{y1, . . . , yN} is a probability measure on 2Y , the
set of all subsets of Y . (In our setting, Y will be
the set of all possible threads.) For every Y ? Y
we have:
P(Y ) =
det(LY )
?
Y?Y
det(LY )
=
det(LY )
det(L+ I)
, (3)
where L is a positive semidefinite matrix and I
is the N ?N identity matrix. LY ? [Lij ]yiyj?Y
denotes the restriction of L to the entries indexed
by elements of Y , and det(L?) = 1. We can
define the entries of L as follows:
Lij = q(yi)?(yi)
>?(yj)q(yj) , (4)
where we can think of q(yi) ? R+ as the ?qual-
ity? of an item yi, and ?(yi) ? RD, ??(yi)?2 = 1
Figure 3: (a) The DPP probability of a set Y depends
on the volume spanned by vectors q(yi)?(yi) for i ? Y .
(b) As quality (length) increases, so does volume. (c)
As similarity increases, volume decreases.
as a normalized D-dimensional feature vector
such that ?(yi)>?(yj) ? [?1, 1] is a measure of
similarity between items yi and yj . This simple
definition gives rise to a distribution that places
most of its weight on sets that are both high qual-
ity and diverse. To understand why this is the
case, note that determinants are closely related
to volumes; in particular, det(LY ) is proportional
to the volume spanned by the vectors q(yi)?(yi)
for yi ? Y . Thus, sets with high-quality, diverse
items have the highest probability; see Figure 3
for an illustration.
4.1 Structured DPPs
Kulesza and Taskar (2010) introduced structured
DPPs (SDPPs) to efficiently handle Y containing
exponentially many structures. In our setting, Y
contains all threads of length T , so each yi ? Y is
a sequence (y(1)i , . . . , y
(T )
i ), where y
(t)
i is the docu-
ment included in the thread at position t. When
G is a complete graph, there are nT possible
sequences, so |Y| = N = nT .
In order to allow for efficient normalization
and sampling, SDPPs assume a factorization
of the quality score q(yi) and similarity score
?(yi)>?(yj) into parts, decomposing quality mul-
tiplicatively and similarity additively:
q(yi) =
T?
t=1
q
(
y(t)i
)
?(yi) =
T?
t=1
?
(
y(t)i
)
(5)
For threading, the definition of ? is just as given
in Equation (2). However, in order to convert the
weight function defined in Equation (1) to the
713
appropriate multiplicative form, we use a sim-
ple log-linear model, setting q(yi) = exp(?w(yi)),
where ? is a hyperparameter that effectively gov-
erns the balance between quality and diversity
by adjusting the dynamic range of the quality
function.
An efficient algorithm for sampling structures
(in this case, sets of threads) from an SDPP is
derived in Kulesza and Taskar (2010). While
the details are beyond the scope of this paper,
we note that the sampling algorithm requires
O(Tn2D2) time. If the node degrees are bounded
by r then the time is reduced to O(TrnD2). This
is not quite efficient enough when the number
of features, D, is large, as it often is for textual
tasks, but we will show in Section 5 how to
overcome this last hurdle.
Note that, in our later experiments, we fix T
to moderate values (T = 5, 8) for ease of analysis
and display. However, it is possible (and effi-
cient, due to the linear scaling) to allow longer
threads, as well as threads of variable length.
The latter effect can be achieved by adding a sin-
gle ?dummy? node to the document graph, with
incoming edges from all other documents and a
single outgoing self-loop edge. Shorter threads
will simply transition to this dummy node when
they are complete.
4.2 k-DPPs
SDPPs allow us to efficiently model all sets of
threads; however, for practical reasons we would
prefer to focus only on sets of exactly k threads.
To do so we exploit recently developed methods
for working with DPPs of fixed size (Kulesza
and Taskar, 2011). A k-DPP Pk is a DPP con-
ditioned on the event that the subset Y ? Y has
cardinality k; formally, whenever |Y | = k:
Pk(Y ) =
det(LY )
?
|Y ?|=k det(LY ?)
. (6)
In this work we combine k-DPPs with SDPPs,
referring to the result as a k-SDPP. We note that
using k-SDPPs instead of SDPPs does not affect
efficiency of sampling; it merely affords a mecha-
nism for controlling the number of threads.
5 Random projections
As described above, the time complexity for sam-
pling sets from SDPPs is O(TrnD2). Although
this is polynomial, for practical problems nD2
is prohibitively large. While previous work has
dealt only with small datasets, in our experi-
ments we typically have n,D > 30,000; storing
a single message for the message-passing routine
involved in SDPP sampling would require over
200 terabytes of memory. To make the model
practical, therefore, we turn to techniques for
dimensionality reduction.
Standard PCA requires O(D3) time and would
be much too slow. But a classic result of John-
son and Lindenstrauss (1984) shows that high-
dimensional points can be randomly projected
onto a logarithmic number of dimensions while
approximately preserving the distances between
them. More recently, Magen and Zouzias (2008)
extended this idea to the preservation of volumes
spanned by sets of points. Here, we use a rela-
tionship between determinants and volumes to
adapt the latter result. We will prove the follow-
ing bound on the variational distance between
the original k-SDPP and a randomly projected
version.
Theorem 1. Fix , ? < 1/2, and set d =
max
{
2k

,
24
2
(
log(3/?)
logN
+ 1
)
log 2N + k ? 1
}
.
(7)
Let Pk be the k-SDPP distribution in Equa-
tion (6), let G be a d ? D random matrix
whose entries are independently sampled from
N (0, 1/d), and let P?k(Y ) be the k-SDPP distri-
bution after projecting ? by G?that is, replacing
? with G?. Then with probability at least 1? ?,
?Pk?P?k?1 =
?
|Y |=k
|Pk(Y )?P?k(Y )| ? e6k?1 .
(8)
Note that e6k ? 1 ? 6k when k is small, and
d = O(max{k/, (log(1/?) + T log n)/2}).
Practically, Theorem 1 says that if we project
? down to dimension d logarithmic in the number
of documents and linear in thread length, the L1
variational distance between the true model and
the projected model is bounded.
714
To prove Theorem 1, we will first state a vari-
ant of Magen and Zouzias? result, which bounds
the ratio of volumes before and after projection
from D down to d dimensions.
Lemma 1. Let X be a D?N matrix. Fix k < N
and , ? < 1/2, and set d and G as in Theorem 1.
Then with probability at least 1? ? we have, for
all D ? k matrices Y formed by a subset of k
columns from X:
(1? )k ?
Vol(GY )
Vol(Y )
? (1 + )k ,
where Vol(Y ) is the k-dimensional volume
spanned by the columns of Y and the origin.
We can make use of the following fact to con-
vert this bound on volumes to a bound on deter-
minants:
Vol(Y ) =
1
k!
?
det(Y >Y ) . (9)
In order to handle the k-SDPP normalization
constant
?
|Y |=k
?
?
?
yi?Y
q2(yi)
?
?det(?(Y )>?(Y )) , (10)
we also must adapt Lemma 1 to sums of deter-
minants. The following lemma gives the details.
Lemma 2. Under the same conditions as
Lemma 1, with probability at least 1? ?,
(1+2)?2k ?
?
|Y |=k det((GY )
>(GY ))
?
|Y |=k det(Y
>Y )
? (1+)2k .
Proof.
?
|Y |=k
det((GY )>(GY ))
=
?
|Y |=k
(k!Vol(GY ))2
?
?
|Y |=k
(
k!Vol(Y )(1? )k
)2
? (1 + 2)?2k
?
|Y |=k
det(Y >Y ) ,
0 50 100 1500
0.2
0.4
0.6
0.8
1
1.2
L1 
var
iati
ona
l di
sta
nce
Projection dimension
0
1
2
3
4x 10
8
Me
mo
ry u
se 
(byt
es)
Figure 4: The effect of random projections. In black,
on the left, we estimate the L1 variational distance
between the true and projected models. In blue, on
the right, we plot the memory required for sampling.
Running time is proportional to memory use.
where the first inequality holds with probability
at least 1?? by Lemma 1, and the second follows
from the fact that (1? )(1 + 2) ? 1 (since  <
1/2), thus (1? )2k ? (1 + 2)?2k. A symmetric
argument gives the upper bound.
Proof (of Theorem 1). Let B be the matrix
whose columns are given by Bi = q(yi)?(yi).
We have
?Pk ? P?k?1 =
?
|Y |=k
|Pk(Y )? P?k(Y )|
=
?
|Y |=k
Pk(Y )
?
?
?
?
?
1?
P?k(Y )
Pk(Y )
?
?
?
?
?
=
?
|Y |=k
Pk(Y )
?
?
?
?1?
det([GB>Y ][GBY ])
det(B>Y BY )
?
?
|Y ?|=k det(B
>
Y ?BY ?)
?
|Y ?|=k det([GB
>
Y ? ][GBY ? ])
?
?
?
?
?
?
?
?
?1? (1 + )2k(1 + 2)2k
?
?
?
?
|Y |=k
Pk(Y )
? e6k ? 1 ,
where the first inequality follows from Lemma 1
and Lemma 2, which hold simultaneously with
probability at least 1? ?, and the second follows
from (1 + a)b ? eab for a, b ? 0.
715
delay interconnectwiresizing elmore-basedrouting tree
mobile clients hoard server client database
policy decisionmarkov pomdpspartially uncertainty
learning lifelong training tasks invariances control learning lifelong training tasks invariances control
? Locally Weighted Learning for Control
? Discovering Structure in Multiple Learning Tasks: The TC Al-
gorithm
? Learning One More Thing
? Explanation Based Learning for Mobile Robot Perception
? Learning Analytically and Inductively
mobile clients hoard server client database
? A Database Architecture for Handling Mobile Clients
? An Architecture for Mobile Databases
? Database Server Organization for Handling Mobile Clients
? Mobile Wireless Computing: Solutions and Challenges in Data
Management
? Energy Efficient Query Optimization
Figure 5: Example threads sampled from a 4-SDPP with thread length T = 5 on the Cora dataset. We
project from word-space to two dimensions by running PCA on the centroids of the threads. The nodes not
on the thread paths form a representative subset of the other documents from Cora. Displayed beside each
thread are a few of its maximum-tfidf words. Paper titles from two of the threads are shown to the right.
6 Experiments
We begin by showing the performance of random
projections on a small, synthetic threading task
where the exact model is tractable, with n = 600
and D = 150. Figure 4 shows the L1 variational
distance (estimated by sampling) as well as the
actual memory required for a variety of projec-
tion dimensions d. Note that, as predicted by
Theorem 1, fidelity to the true model increases
rapidly with d.
6.1 Cora citation graph
To qualitatively illustrate our model, we apply
it to Cora (McCallum et al2000). Cora is a
large collection of academic papers on computer
science topics, plus citations between them. We
construct a directed graph with papers as nodes
and citations as edges; after removing papers
with missing metadata or zero outgoing citations,
our graph contains n = 28,155 papers.
To obtain useful threads, we set edge weights
to reflect the degree of textual similarity between
the citing and cited papers, and set node weights
to reflect paper ?importance?. Edge weights
are given by normalized cosine similarity (NCS),
which for two documents i and j is the dot prod-
uct of their normalized tfidf vectors:
?
w?W tfidfi(w)tfidfj(w)??
w?W tfidfi(w)
2
??
w?W tfidfj(w)
2
,
where W is a subset of the words found in the
documents. We select W by filtering according
to document frequency; that is, we remove words
that are too common or too rare. After filtering,
there are 50,912 unique words. The node weights
are given by LexRank scores (Erkan and Radev,
2004), which are similar to node degrees.
Finally, we build a similarity feature map ? to
encourage diversity. We represent each document
by the 1000 documents to which it is most similar
according to NCS; this results in binary ? of
dimension m = n with exactly 1000 non-zeros.
The dot product between the similarity features
of two documents is thus proportional to the
fraction of top-1000 similar documents they have
in common. As described in Section 5, we then
randomly project this large feature set from D ?
28,000 to d = 50 dimensions.
We illustrate the behavior of the resulting
model in Figure 5. The discovered threads oc-
cupy distinct regions of word-space, standing
apart visually, and contain diverse salient terms.
6.2 News articles
For quantitative evaluation, we use newswire
data. Our dataset comprises over 200,000 arti-
cles from the New York Times, collected from
2005-2007 as part of the English Gigaword cor-
pus (Graff and Cieri, 2009). We split the articles
into six-month time periods, with an average of
716
n = 34,504 articles per period. After filtering,
there are a total of 36,356 unique words.
For each time period, we generate a graph with
articles as nodes. We use NCS for edge weights,
and throw away edges with weight < 0.1. We
also require that edges go forward in time; this
enforces the chronological ordering of our threads.
The supplement contains illustrations of one of
the resulting graphs. We use LexRank for node
weights and the top-1000 similar documents as
similarity features ?, projecting to d = 50, as
before (Section 6.1). We also add a constant fea-
ture ? to ?, which controls the overall degree of
repulsion; large values of ? make all documents
more similar. This makes the k-SDPP distri-
bution more peaked around diverse sets. For
all of the following results, we use T = 8 and
k = 10 so that the resulting timelines are of a
manageable size for analysis. However, we tried
several values of k and T in our experiments, and
did not see significant differences in relative per-
formance. We report all metrics averaged over
100 random samples from the model for each
six-month period.
6.2.1 Graph visualizations
The (very large) news graph for the first
half of 2005 can be viewed interactively at
http://zoom.it/jOKV. In this graph each node
(dark circle) represents a news article, and is an-
notated with its headline. Node size corresponds
to weight (LexRank score). Nodes are laid out
chronologically, left-to-right, from January to
June of 2005. The five colored paths indicate a
set of threads sampled from the k-SDPP. Head-
lines of the articles in each thread are colored
to match the thread. Edges are included as de-
scribed in the paper, but due to the scale of this
dataset, only 1% of the edges are shown. Edge
thickness corresponds to weight (NCS).
We provide a view of a small subgraph for
illustration purposes in Figure 6, which shows
the incoming and outgoing edges for a single
node. A zoomable version of this subgraph is
available at http://zoom.it/GUCR.
STUDY ANALYZES DATA ON ILLEGAL IMMIGRANTS
WELCOME TO 'TEH-JAS,' LAND OF THE ALAMO AND COWBOYFOR IMMIGRANTS, SUCCESS OFTEN STARTS WITH BIZARRE STREET SIGNSDOMINICANS TAKE THEIR PLACE AS AN AMERICAN SUCCESS STORY
MEXICAN MANUAL ON ILLEGAL IMMIGRATION DRAWS FIRECALIFORNIA REPUBLICAN COUNTERS BUSH IMMIGRATION PLANHOUSE BILL TARGETS FAKE SOCIAL SECURITY CARDS; PROPOSAL CALLS FOR DIGITAL PHOTO, ELECTRONIC STRIPGARCIA SEEKS MAJOR FOR HIS RESUMEVIDEOCONFERENCES LINK IMMIGRANTS AND LOVED ONESBORDER CROSSING: A GUIDE FOR THE ILLEGAL MIGRANTPOLITICIANS' DREAM WOULD BECOME A NIGHTMARE FOR COPSNEW SOCIAL SECURITY CARD COULD THWART ILLEGAL IMMIGRANTSAS HISPANICS EMBRACE LIFE IN U.S., SOME PREFER TO LIMIT FAMILY SIZETEXAS CONGRESSMAN CORNYN TO LEAD IMMIGRATION PANEL; SENATOR'S BILL, REFLECTIVE OF WHITE HOUSE REFORM GOALS, MEETS OPPOSITIONFIGHTING FOR U.S., AND FOR GREEN CARDSBUSH VOWS TO PUSH IMMIGRATION PLAN THROUGH THIS TIMEON SCREEN, TACKLING EUROPE'S NEW REALITYBUSH AGENDA FACES SOME GOP RESISTANCE
EDITORIAL: THE PRESIDENT'S SHOELACESPROBLEMS WITH SPEAKING ENGLISH MULTIPLY IN A DECADEGUEST WORKER PLAN DIVIDES LAWMAKERS PRESIDENT SUPPORTS IDEA TO HELP ILLEGAL ALIENS TOILING IN U.S.ALLEGED LEADER IN HUMAN-SMUGGLING DEATHS WANTS TO WITHDRAW GUILTY PLEAJURY SELECTION TO BEGIN TUESDAY IN HUMAN-SMUGGLING TRIAL OF ACCUSED TRUCKER IN DEATHS OF 19 ILLEGAL IMMIGRANTSNEW MIGRANT LAW IRKS MEXICOHELPING EDUCATORS THROW OUT OLD RULES AND TAKE A FEW RISKSRECORD IMMIGRATION CHANGING NEW YORK'S NEIGHBORHOODSATTORNEYS SAY TESTIMONY WILL SHOW OFFICIALS LET TRUCK PASS WITH ILLEGAL IMMIGRANTSFEINSTEIN BILL WOULD PROTECT FOREIGN KIDS IN U.S. CUSTODY SENATE BILL WOULD PROTECT FOREIGN CHILDREN IN U.S. CUSTODYIMMIGRATION BOOM COOLINGREPUBLICANS SQUARING OFF OVER BUSH PLAN ON IMMIGRATIONSMUGGLING-DEFENDANT-HNSBUSH VOWS COOPERATION ON IMMIGRATION REFORM; DIFFERENCES OVER SCOPE, AGENDA MAY STALL PLAN
JUDGE SAYS GUILTY PLEA IN DEADLY TEXAS SMUGGLING MUST STANDHOUSING, IMMIGRATION CALLED KEYS TO THE FUTUREPRESIDENT REIGNITES EMOTIONAL DEBATE OVER IMMIGRATION POLICYGUEST WORKER PLAN WILL BE TOUGH SELL FOR BUSHMEXICAN POLITICIANS FIND BENEFITS IN U.S. CAMPAIGNSSEN. CORNYN FOCUESES IN IMMIGRATIONTANCREDO WEIGHS PRESIDENTIAL RUN WITH PILGRIMAGE TO N.H.BRITAIN, SPAIN, BOTH IN EU, ANNOUNCE DIVERGENT IMMIGRATION POLICIESSPAIN LETS ILLEGAL IMMIGRANTS SEEK RESIDENCYIMMIGRANT-LICENSES-HNSBUSH BACKS DRIVER'S LICENSE BANDEPORTED FROM MEXICO, 3 MORE IN ALLEGED SMUGGLING RING MAY FACE CAPITAL PUNISHMENT IN DEATHS OF 19 IMMIGRANTSHOUSE APPROVES TOUGHER IMMIGRATION BILLTAKING HARD LINE ON ILLEGAL IMMIGRANTS: HOUSE PASSES BILL TO MAKE IT TOUGHER TO GET ASYLUM OR DRIVER'S LICENSES
HOUSE PASSES TIGHTENING OF LAWS ON IMMIGRATIONHOUSE OKS BAN ON LICENSES FOR ILLEGAL IMMIGRANTSMEXICANS HELP TRANSFORM HOMES THEY LEFTANDY GARCIA NEARS END OF HIS QUEST: A FILM ON CUBAMEXICO HAS JOBS PLAN FOR CITIZENS DEPORTED FROM U.S.REPORT LINKS SOCIAL SECURITY FINANCES IN PART TO LEVELS OF IMMIGRATIONIN DEPORTATIONS OF PARENTS, FATE OF CHILDREN IS OFTEN AN AFTERTHOUGHTJUDGE BLOCKS NEW YORK DENIAL OF IMMIGRANT DRIVER LICENSESIMMIGRANT VOTERS DEFY POLITICAL PATTERNSKC-AFGHAN-NEWSPOLICY SHIFT IN GERMANY TRIMS JEWISH MIGRATIONIN JOB MARKET, SOME WIN, SOME LOSEHUNDREDS GET AID AT VALLEY SHELTERSPOLITICAL PRESSURE MOUNTING TO BOOST BORDER PATROL AGENTS ALONG BORDER
P1 A23 MEXICO-HNSMEXICO-VOTE-HNSBILL TO LET MEXICAN MIGRANTS VOTE HITS ROADBLOCKSMORE DUTCH PLAN TO EMIGRATE AS MUSLIM INFLUX TIPS SCALESGONZALES LAYS OUT HIS PRIORITIES AT JUSTICE DEPT.MOST UNDOCUMENTED IMMIGRANTS RECEPTIVE TO GUEST WORKER PROGRAMSURVEY: MOST MEXICAN IMMIGRANTS WOULD USE GUEST WORKER PROGRAMSURVEY: MOST UNDOCUMENTED ALIENS SUPPORT GUEST WORKER PLANNEW STUDY PAINTS CLEARER PICTURE OF MEXICANS IN NEW YORK CITYIMMIGRATION CHANGES COULD CUT BACK ASYLUM SEEKERSTEXAS TO HOST U.S.-MEXICO-CANDADA SUMMITYOUNG BULLDOGS LEARN HARD WAYTRIAL STARTS IN NATION'S DEADLIEST HUMAN SMUGGLING CASERICE SAYS AL-QAIDA FOCUSED ON BREACHING U.S. BORDERS, ANNOUNCES WATER AGREEMENT WITH MEXICOBORDER-PATROL-HNS
RICE SEEKS THAW IN MEXICO-U.S. RELATIONSCASE FOCUSES ON DEFINITION OF TORTURE FOR DEPORTEESFIRST THEY WERE SOLDIERS -- NOW THEY'RE CITIZENS; IMMIGRANTS WHO FOUGHT FOR U.S. ARE NATURALIZED, GREETED BY BUSH SR.ADVANCE FOR SUNDAY, MARCH 13 IMMIGRANTS MAY GET TO VOTE HERE IN MEXICO'S 2006 ELECTIONDESPITE NEW EFFORTS ALONG ARIZONA BORDER, 'SERIOUS PROBLEMS' REMAINMYTH CITED REPEATEDLY IN IMMIGRATION DEBATESWEEP NETS 103 SUSPECTS OF MS-13 GANG IN SEVEN CITIESFEDS SAY SWEEP NETS 100 MEMBERS OF IMMIGRANT GANGU.S.-MEXICO BORDER STILL TOO POROUS, OFFICIALS SAYALLEGED OBSCENE GESTURE DELAYS IMMIGRANT SMUGGLING TRIAL; DEATH PENALTY PROTESTERS CLAIM JUROR HAS ALREADY MADE UP HIS MINDFOX REFUTES U.S. CLAIMS ON AL-QAIDA, VOWS LEGAL ACTION TO HALT VIGILANTESFOX TO PUSH IMMIGRATION, SECURITY, TRADE ISSUES DURING MEETING WITH BUSH, CANADA'S PRIME MINISTERTESTIMONY IN TRUCK DRIVER'S IMMIGRANT SMUGGLING CASE HALTED AFTER PROSECUTION RESTS; JUDGE QUESTIONS HARBORING CHARGES57 BRAZILIANS HELD AFTER BRIBE IS ALLEGED
WAL-MART TO PAY $11 MILLION IN ILLEGAL IMMIGRANT CASEWAL-MART SETTLES ILLEGAL IMMIGRANT CASE FOR $11 MILLIONGARCIA WANTS TO BE PART OF THE CONVERSATIONEDITORIAL OBSERVER: ENLIGHTENED IMMIGRATIONEDITORIAL: OUR TERRORIST-FRIENDLY BORDERS
10.3 MILLION FROM MEXICO IN U.S. ILLEGALLY, RESEARCHER ON LATINOS SAYSBUSH FOCUSES ON BORDER ISSUES WITH MEXICO, CANADALANGUAGE PLAYS A LOUD VOICE IN DEBATE ABOUT IMMIGRATION REFORMU.S. BEGINS TO SEE NATIONAL SECURITY GAP IN MEXICAN SMUGGLINGMEXICANS VOTING IN U.S. COULD ALTER POLITICSTEXAS ADVOCATES FOR IMMIGRATION REFORMS JOIN OTHERS AROUND NATION IN RALLIES URGING BUSH, FOX TO ACT QUICKLYSECURITY, TRADE TO BE PRIMARY FOCUS OF BUSH-FOX-MARTIN SUMMITNORTH AMERICAN LEADERS MAKE BORDERS AND TRADE A PRIORITYBUSH TELLS MEXICAN LEADER HE'LL CONTINUE TO SEEK IMMIGRATION LAW CHANGESBUSH TELLS MEXICAN LEADER HE'LL SEEK IMMIGRATION LAW CHANGESLEAVING A YEAR EARLY, BUT A YEAR TOO LATEBUSH SUMMIT VOWS CLOSER TIES, BETTER TIMES AHEADU.S. SIGNS TRADE, SECURITY DEAL WITH MEXICO, CANADA; BUSH PUSHES FOR IMPROVED TIES WITH SOUTH AMERICAKEEPING IMMIGRATION LEGAL
DUKE BLOCKS GEORGIA'S ROAD TO INDYTHAT BURGER-FLIPPER IS NO KID ANYMOREMOTHERS IMMIGRATING TO BECOME BREADWINNERSLAST OF THREE PARTS; WITH PHOTOS, GRAPHIC CANADA'S OPEN BORDER BOON TO HUMAN TRAFFICKERSBEST, BRIGHTEST MUST CHOOSE BETWEEN MENIAL JOBS IN U.S., ROCKY FUTURE AT HOMEU.S. TO REINFORCE POROUS ARIZONA BORDERREPORT URGES CUTS IN CARE FOR ILLEGAL IMMIGRANTSDNA HELPS IDENTIFIES MEXICAN MIGRANTS IN PAUPERS' GRAVESCIVILIAN PATROL TO RAISE BORDER CONCERNSFALLEN BROTHER INSPIRATION FOR GARCIAARMED VOLUNTEERS WAIT ALONG ARIZONA BORDER TO STOP ILLEGAL IMMIGRANTSKC-5LOUVILLE1,WANTED: BORDER HOPPERS. AND SOME EXCITEMENT, TOO.VOLUNTEERS SET TO PATROL ARIZ. BORDER
IMMIGRATION FOES BEGIN ARIZONA BORDER WATCHHOW SOCIAL SECURITY BALANCES BOOKS ON BACKS OF IMMIGRANTSCITIZEN PATROL SPREADS FEAR, RESOLVE AT US-MEXICO BORDERCITIZEN PATROL SPREADS FEAR, RESOLVE AT BORDERFEW VOLUNTEERS FOR BORDER PROJECTWHITE POWER GROUPS TRY NEW TACTICS AND TOOLSPOLICE SAY IMMIGRANT POLICY IS A HINDRANCEBATTLE OVER LICENSES FOR IMMIGRANTS BACK IN COURTTHE INVISIBLE DELIVERYMANGIRL CALLED WOULD-BE BOMBER WAS DRAWN TO ISLAMRAID NETS 53 ILLEGAL IMMIGRANTS IN SOUTHWEST HOUSTON HOMEBUSINESSES MAKING A PUSH FOR GUEST WORKER PLAN MOVING IN WASHINGTON AND FINANCIAL CATEGORIES FOR RELEASE SUNDAY, APRIL 10.OUTRAGE AT ARREST OF GIRL, 16, AS TERRORIST THREATADVANCE FOR USE SUNDAY, APRIL 10, AND THEREAFTER. "MINUTEMEN" SEE LITTLE ACTION ALONG BORDER
COMMENTARY: AILING HEALTH CARELOCAL BRAZILIANS SAY THEY'RE TARGETED UNFAIRLYEDITORIAL: A WEST TOO WILDSIERRA CLUB ASKS MEMBER VOTE ON IMMIGRATION LIMITSSIERRA CLUB SPLIT AGAIN ON IMMIGRATION STANCEFRIST OPPOSES AMENDMENTS ON IMMIGRANTSBORDER RESIDENTS SAY 'MINUTEMAN' PATROLS HIGHLIGHT A CRISISIMMIGRATION MEASURE HITS SENATE ROADBLOCKHOTEL FIRE SHEDS LIGHT ON FRANCE'S ILLEGAL IMMIGRANTSDEEPLY SPLIT SENATE REJECTS GUEST FARMWORKER BILLSENATE CLEARS WAY FOR VOTE ON SPENDING FOR MILITARYSENATE APPROVES $81.26 BILLION IN A MILITARY EMERGENCY BILLIMMIGRATION CONTROL ADVOCATES DESCEND ON CAPITOL HILLPOLICE REPORT NONCITIZENS TO U.S., OFFICIAL SAYSBRITISH ELECTION DEBATE SPOTLIGHTS CONCERN ABOUT IMMIGRATIONTOP DOGS! GYM DOGS TAKE TITLE
ILLEGAL IMMIGRATION FOES DEMANDING ACTIONSIERRA CLUB STANDS PAT ON IMMIGRATION POLICYKOSOVAR FEARS ID PROPOSAL WILL JEOPARDIZE SAFE LIFE IN U.S.A MISTAKEN ID LAW (FOR USETRAFFICKING LEADS LATINO SUMMIT AGENDAIMMIGRATION-SCAM-HNSLATINO KIDS LAG IN HEALTH COVERAGELAWMAKERS TO DECIDE FATE OF DRIVER'S LICENSE IMMIGRATION BILLWHITE HOUSE BACKS LEGISLATION THAT WOULD TOUGHEN IMMIGRATION RULESIN RARE ACCORD, SPURNED ASYLUM SEEKER TO GET $87,500COMMENTARY: A PRIVATE OBSESSIONEX-VALLEY MAN IN VANGUARD OF MINUTEMAN PROJECTSCHWARZENEGGER ENDORSES ARMED VOLUNTEERS ON BORDERGOVERNOR SIGNALS HE'D WELCOME MINUTEMEN ON CALIFORNIA BORDER
VALLEY HOSPITAL BOOM UNDER WAYACTIVISTS, OPPONENTS CLASH AT IMMIGRATION RALLYMEXICAN SENATOR WANTS TO BLOCK WOULD-BE ILLEGAL IMMIGRANTS FROM ENTERING U.S.MAYANS HERE TRY TO SAVE OLD WAYSSTATE OFFICIALS WARY OF NEW DRIVER'S LICENSE REQUIREMENTSEDITORIAL: AN UNREALISTIC 'REAL ID'ROUTINE LICENSE CHECK CAN MEAN JAIL AND DEPORTATIONHOUSE PASSES EMERGENCY SPENDING BILLBILL WOULD PROTECT ILLEGAL IMMIGRANT DRIVERS' CARS FROM IMPOUNDHOUSE OKS $82 BILLION MORE FOR WARS
IMMIGRANTS IN TENNESSEE ISSUED CERTIFICATES TO DRIVE ARIEL HART CONTRIBUTED REPORTING FOR THIS ARTICLE FROM ATLANTA.
PAYMENTS TO HELP HOSPITALS CARE FOR ILLEGAL IMMIGRANTSIMMIGRANTS' PLIGHT BECOMES A RALLYING CRY AMONG LATINO, U.S. MUSICIANSCATHOLIC GROUPS LAUNCH IMMIGRATION REFORM CAMPAIGNBORDER STATES COMPLAIN THAT U.S. ISN'T FOOTING THE BILL FOR JAILING ILLEGAL IMMIGRANTSNATIONAL CHILDREN'S STUDY STARVING FOR FUNDS, BACKERS SAYSENATE APPROVES MONEY FOR IRAQ WAR; RESTRICTS DRIVER'S LICENSES FOR ILLEGAL IMMIGRANTSIMMIGRANTS ENCOURAGED TO RIDE BUSIMMIGRATION-CRACKDOWN-HNSSENATE UNANIMOUSLY OKS WAR FUNDING AND DRIVERS LICENSE RESTRICTIONS FOR IMMIGRANTSDENIAL OF DRIVER'S LICENSES TO MANY IMMIGRANTS VOIDED IN NEW YORKMINUTEMEN-IMMIGRANTS-HNSMAJOR IMMIGRATION REFORM MEASURE TO BE INTRODUCEDGARCIA MAY HAVE CRASHED, BUT HE'S NOT BURNED UPBILL WOULD ALLOW ILLEGAL IMMIGRANTS TO BECOME LEGAL TEMPORARY WORKERS
MCCAIN, KENNEDY BILL WOULD PUT MILLIONS OF ILLEGALS ON PATH TO GREEN CARDKENNEDY, MCCAIN BILL ADDRESSES IMMIGRANTSIMMIGRATION-REFORM-HNSIMMIGRANT LABOR BILL CREATES 3-YEAR VISAS FOR GUEST WORKERSU.S. OFFICIALS, AFRICAN AMERICAN LEADERS SEEK APOLOGY OVER MEXICAN PRESIDENT'S REMARKSSMUGGLING OF IMMIGRANTS IS DETAILED AS TRIAL STARTSFOX MEETS JACKSON SEEKING TO EASE UPROAR OVER REMARKSEDITORIAL: MAJOR IMMIGRATION SURGERYN.H. POLICE CHIEF'S TACTICS STIR A STORM ON IMMIGRATIONNH-IMMIGRATION-ART-BOSPOST-9/11 PROGRAM MAY END FAMILY'S AMERICAN DREAMSTRESSFUL LIVES BURDEN REFUGEESECUADORANS LEAD DANBURY IMMIGRATION PROTEST RALLYEARLY HEAT WAVE KILLS 12 ILLEGAL IMMIGRANTS IN THE ARIZONA DESERT
FEDERAL RESERVE PROGRAM GIVES BANKS A SHOT AT TRANSFERS TO MEXICOBILL WOULD FORCE SAVINGS ON MEDICAID SPENDINGBILL BY GOP SENATORS INCREASES BORDER GUARDS; NEW SECURITY IS PART OF AN OVERALL IMMIGRATION PLANA BATTLE AGAINST ILLEGAL WORKERS, WITH AN UNLIKELY DRIVING FORCEPOLICE ACROSS U.S. DON'T CHECK IMMIGRANT STATUS DURING STOPSBOOK REVIEW: EXPLORING IMMIGRANT SMUGGLING TRAGEDYIMMIGRATION MAY BE MAJOR ISSUE IN 2008 ELECTION EUNICE MOSCOSOBULLDOGS SET PACE IN NCAASTEXAN PLANS TO BRING MINUTEMEN PATROLS TO MEXICAN BORDERGEORGIA TO BATTLE JACKETS FOR TITLESOME SKILLED FOREIGNERS FIND JOBS SCARCE IN CANADAAT VATICAN'S DOORSTEP, A CONTEST FOR IMMIGRANT SOULSBABY SURVIVES AGAINST ALL ODDSIDENTITY CRISIS: SOCIAL SECURITY NUMBERS FOR RENT
NATION PONDERS IMMIGRANT WORKER PARADOXWEB CLASSES FROM MEXICO HELP MIGRANTSNUMBER OF NON-MEXICAN ALIENS CROSSING SOUTHERN BORDER SKYROCKETINGIMMIGRATION OFFICIALS SEEK EXPANSION OF PROGRAM THAT ALLOWS BORDER AGENTS TO QUICKLY DEPORT ILLEGAL IMMIGRANTSLAZARUS AT LARGE COLUMN HEALTH CARE A DRAG ON U.S. BUSINESSMOST ILLEGAL ALIENS FREED ON BAIL, OWN RECOGNIZANCEDELAY SAYS BUSH PROMISES BETTER EFFORT ON IMMIGRATION LAWBUSH-IMMIGRATION-HNSGROWTH RATE OF HISPANIC POPULATION IS RISING, CENSUS BUREAU SAYSREPORT DESCRIBES IMMIGRANTS AS YOUNGER, MORE DIVERSESHARED LANGUAGE (FOR USEDIPLOMAT: MIGRANT BILL NEEDEDIMMIGRATION REFORM AT TOP OF MANY AGENDAS; SIMILAR PROPOSALS BY BUSH, SEN. CORNYN TO TACKLE GUEST WORKERS, BORDER SECURITYSOUTH TEXAS COUNTY OVERWHELMED BY ILLEGAL IMMIGRANTS
STUDY TRACKS SURGE IN ILLEGAL IMMIGRATION FROM MEXICONO WORRIES AT PINEHURST FOR 'EL NINO'ONE IN 11 MEXICAN NATIVES IN U.S., HALF ILLEGALLOW-PROFILE KENTUCKY TOBACCO MAN BUYS UP TEXAS RANCH LANDBOOK REVIEW: CREATING A NEW AMERICANISMOCORNYN-IMMIGRATION-HNSLAWMAKER SAYS ILLEGAL IMMIGRANTS SHOULDN'T COUNT IN THE CENSUSGEORGIA STATE LOOKS AT FOOTBALLGARCIA HAS ALL THE SHOTS BUT NOT A MAJOR TITLEGUARDSMAN KILLED IN AFGHANISTAN BURIEDTWO IMMIGRATION PLANS TAKE SHAPE IN SENATEUP TO 64 LABORERS LIVED IN A SMALL HOUSE, AUTHORITIES SAY
THE VALUE OF IMMIGRANTSFEDS FAIL TO GO AFTER COMPANIES HIRING ILLEGAL IMMIGRANTSMINUTEMAN GROUP MAKES PLANS FOR TEXAS PATROL GEORGIA LAGS BEHIND IN LOCAL EMERGENCY PLANNING GROUPSEDITORIAL: SHAM SANCTIONSON LONG ISLAND, A RAID STIRS DISPUTE OVER INFLUX OF IMMIGRANTSHISPANIC POLITICAL POWER LAGS BEHIND RECORD GROWTH , STUDY SAYSLEGISLATION TO LICENSE UNDOCUMENTED IMMIGRANTS MOVES FORWARDBUSH ADMINISTRATION BORDER SURVEY NOT RELEASEDMEXICO TO LET MIGRANTS VOTE BY MAILLAWMAKERS IN MEXICO APPROVE ABSENTEE VOTING FOR MIGRANTSGARCIA: TOO GOOD TO BE TRUE?BUSH'S STAND ON IMMIGRATION RILES SOME OF THE PARTY'S BASE
BRAZILIANS STREAMING INTO U.S. THROUGH MEXICAN BORDERBUSH ADMINISTRATION SAYS MEXICAN STAMPS ARE INAPPROPRIATETECH ASSISTANT TAPPED FOR GEORGIA STATE ADLONG ISLAND OFFICIALS TRY A DIFFERENT APPROACH TO IMMIGRANT CRACKDOWN
Figure 6: Snapshot of a single article node
and all of its neghboring article nodes. See
http://zoom.it/GUCR for the zoomable image.
6.2.2 Baselines
k-means baseline: A simple baseline is to
split each six-month period of articles into T
equal time slices, then apply k-means clustering
to each slice, using NCS to measure distance.
We then select the most central article from each
cluster, and finally match the k articles from
time slice i one-to-one with those from slice i+ 1
by computing the pairing that maximizes the
average NCS of the pairs, i.e., the coherence of
the threads. The result is a set of k threads
of length T , where no two threads contain the
same article. In its use of clustering, this base-
line is somewhat similar to the ?event threading?
baseline of Shahaf and Guestrin (2010).
DTM baseline: A more sophisticated base-
line is the dynamic topic model (Blei and Lafferty,
2006), which explicitly attempts to find topics
that are smooth through time. We use code
provided by the authors to fit DTMs with the
number of topics set to k and with the data split
into T equal slices, as before. We then choose,
for each topic at each time step, the document
with the highest per-word probability of being
generated by that topic. Documents from the
same topic form a single thread.
717
CosSim
ROUGE-1 ROUGE-2 ROUGE-SU4
F Prec/ Rec F Prec / Rec F Prec/ Rec
k-means 29.9 16.5 17.3/15.8 0.695 0.725 / 0.669 3.76 3.94/3.60
DTM 27.0 14.7 15.5/14.0 0.750 0.813 / 0.698 3.44 3.63/3.28
k-SDPP 33.2 17.2 17.7/16.7 0.892 0.917/0.870 3.98 4.11/3.87
Table 1: Similarity of automatically generated timelines to human summaries. Bold entries are significantly
higher than others in the column at 99% confidence, computed using bootstrapping (Hesterberg et al2003).
6.2.3 Comparison to human summaries
We compare the threads generated by our
baselines and sampled from the k-SDPP to a
set of human-generated news summaries. The
human summaries are not threaded; they are
flat, roughly daily news summaries published by
Agence France-Presse and found in the Gigaword
corpus, distinguished by their ?multi? type tag.
A sample summary is included in the supplement.
These summaries tend to focus on world news,
which is only a subset of the contents of our
dataset. However, they allow us to provide an
extrinsic evaluation of our method without gold
standard timelines. We compute four statistics:
? Cosine similarity: NCS (in percent) be-
tween the concatenated threads and con-
catenated human summaries. The hyper-
parameters for all methods?such as the
constant feature magnitude ? for k-SDPPs
and the parameter governing topic propor-
tions for DTMs?were tuned to optimize
cosine similarity on a development set from
January-June 2005.
? ROUGE-1, 2, and SU4: Standard
ROUGE scores for summarization evalua-
tion (Lin, 2004).
Table 1 shows the results of these comparisons,
averaged across all six half-year intervals. Under
each measure, the k-SDPP threads more closely
resemble human summaries.
6.2.4 Mechanical Turk evaluation
An important distinction between the base-
lines and the k-SDPP is that the former are
topic-oriented, choosing articles that relate to
broad subject areas, while our approach is story-
oriented, chaining together articles with direct
Rating Interlopers
k-means 2.73 0.71
DTM 3.19 1.10
k-SDPP 3.31 1.15
Table 2: Rating: average coherence score from 1
(worst) to 5 (best). Interlopers: average number of
interloper articles identified (out of 2). Bold entries
are significantly higher with 95% confidence.
individual relationships. An example of this dis-
tinction can be seen in Figure 2.
To obtain a large-scale evaluation of thread co-
herence, we turn to Mechanical Turk. We asked
Turkers to read the headlines and first few sen-
tences of each article in a timeline and then rate
the overall narrative coherence of the timeline on
a scale of 1 (?the articles are totally unrelated?)
to 5 (?the articles tell a single clear story?). Five
separate Turkers rated each timeline; the average
ratings are shown in Table 2. Note that k-means
does particularly poorly in terms of coherence
since it has no way to ensure that clusters are
similar between time slices.
We also had Turkers evaluate threads implic-
itly by performing a simple task. We showed
them timelines into which two additional ?in-
terloper? articles selected at random had been
inserted, and asked them to remove the two ar-
ticles that they thought should be removed to
?improve the flow of the timeline?. A screenshot
of the task is provided in the supplement. Intu-
itively, the interlopers should be selected more
often when the original timeline is coherent. The
average number of interloper articles correctly
identified is shown in Table 2.
718
Runtime
k-means 625.63
DTM 19,433.80
k-SDPP 252.38
Table 3: Time (in seconds) required to produce a
complete set of threads. The test machine has eight
Intel Xeon E5450 cores and 32GB of memory.
6.2.5 Runtimes
Finally, we report in Table 3 the time required
to produce a complete set of threads for each
method. This time includes clustering for k-
means, model fitting for DTM and random pro-
jections, computation of the covariance matrix,
and sampling for k-SDPP. We view the graph
as an input (much like tfidf vectors for the base-
lines), and so do not include its computation in
the runtime for the k-SDPP. Constructing the
graph only requires an additional 160 seconds
though.
6.3 Analysis
Below we briefly summarize the main differences
between the k-SDPP and the baselines, and dis-
cuss their significance.
? Neither baseline directly models the docu-
ment threads themselves. In contrast, the
k-SDPP defines a probability distribution
over all possible sets of document threads.
This makes the k-SDPP a better choice for
applications where, for instance, the coher-
ence of individual threads is important.
? While the baselines seek threads that cover
or explain as much of the dataset as possible,
k-SDPPs are better suited for tasks where
a balance between quality and diversity is
key, since its hyperparameters correspond
to weights on these quantities. With news
timelines, for example, we want not just
topical diversity but also a focus on the
most important stories.
? Both baselines require input to be split into
time slices, whereas the k-SDPP does not;
this flexibility allows the k-SDPP to put
multiple articles from a single time slice in
a thread, or to build threads that span only
part of the input period.
? While clustering and topic models rely on
EM to approximately optimize their objec-
tives, the k-SDPP comes with an exact,
polynomial-time sampling algorithm.
Revisiting Figure 2, we can see all of these
advantages in action. The k-SDPP produces
more consistent threads due to its use of graph
information, while the DTM threads, though
topic-focused, are less coherent as a story. Fur-
thermore, DTM threads span the entire time
period, while our method selects threads cover-
ing only relevant spans. The quantitative results
in this section underscore the empirical value of
these characteristics.
7 Conclusion
We introduced the novel problem of finding di-
verse and salient threads in graphs of large doc-
ument collections. We developed a probabilistic
approach, combining SDPPs and k-SDPPs, and
showed how random projections make inference
efficient and yield an approximate model with
bounded variational distance to the original. We
then demonstrated that the method produces
qualitatively reasonable results, and, relative to
several baslines, reproduces human news sum-
maries more faithfully, builds more coherent story
threads, and is significantly faster. It would be
interesting to extend our model to structures be-
yond linear chains to trees and other structures.
8 Acknowledgements
This material is based upon work supported un-
der a National Science Foundation Graduate Re-
search Fellowship and NSF award 0803256.
References
[Ahmed and Xing2010] A. Ahmed and E. Xing. 2010.
Timeline: A Dynamic Hierarchical Dirichlet Pro-
cess Model for Recovering Birth/Death and Evolu-
tion of Topics in Text Stream. In Proc. UAI.
[Allan et al01] J. Allan, R. Gupta, and V. Khan-
delwal. 2001. Temporal Summaries of New Topics.
In Proc. SIGIR.
719
[Blei and Lafferty2006] D. Blei and J. Lafferty. 2006.
Dynamic Topic Models. In Proc. ICML.
[Chieu and Lee2004] H. Chieu and Y. Lee. 2004.
Query Based Event Extraction along a Timeline.
In Proc. SIGIR.
[Erkan and Radev2004] G. Erkan and D.R. Radev.
2004. LexRank: Graph-Based Lexical Central-
ity as Salience in Text Summarization. Journal of
Artificial Intelligence Research, 22(1):457?479.
[Graff and Cieri2009] D. Graff and C. Cieri. 2009. En-
glish Gigaword.
[Hesterberg et al03] T. Hesterberg, S. Monaghan,
D. Moore, A. Clipson, and R. Epstein. 2003. Boot-
strap Methods and Permutation Tests.
[Johnson and Lindenstrauss1984] W. B. Johnson and
J. Lindenstrauss. 1984. Extensions of Lipschitz
Mappings into a Hilbert Space. Contemporary
Mathematics, 26:189?206.
[Kulesza and Taskar2010] A. Kulesza and B. Taskar.
2010. Structured Determinantal Point Processes.
In Proc. NIPS.
[Kulesza and Taskar2011] A. Kulesza and B. Taskar.
2011. k-DPPs: Fixed-Size Determinantal Point
Processes. In Proc. ICML.
[Leskovec et al09] J. Leskovec, L. Backstrom, and
J. Kleinberg. 2009. Meme-tracking and the Dy-
namics of the News Cycle. In Proc. KDD.
[Lin2004] C.Y. Lin. 2004. Rouge: A package for
automatic evaluation of summaries. In Proc. WAS.
[Magen and Zouzias2008] A. Magen and A. Zouzias.
2008. Near Optimal Dimensionality Reductions
that Preserve Volumes. Approximation, Random-
ization and Combinatorial Optimization. Algo-
rithms and Techniques, pages 523?534.
[McCallum et al00] A. McCallum, K. Nigam,
J. Rennie, and K. Seymore. 2000. Automating
the Construction of Internet Portals with Machine
Learning. Information Retrieval Journal, 3:127?
163.
[Mei and Zhai2005] W. Mei and C. Zhai. 2005. Dis-
covering Evolutionary Theme Patterns From Text:
An Exploration of Temporal Text Mining. In Proc.
KDD.
[Shahaf and Guestrin2010] D. Shahaf and
C. Guestrin. 2010. Connecting the Dots
Between News Articles. In Proc. KDD.
[Shahaf et al12] D. Shahaf, C. Guestrin, and
E. Horvitz. 2012. Trains of Thought: Generating
Information Maps. In Proc. WWW.
[Swan and Jensen2000] R. Swan and D. Jensen. 2000.
TimeMines: Constructing Timelines with Statisti-
cal Models of Word Usage. In Proc. KDD.
[Wayne2000] C. Wayne. 2000. Multilingual Topic De-
tection and Tracking: Successful Research Enabled
by Corpora and Evaluation. In Proc. LREC.
[Yan et al11] R. Yan, X. Wan, J. Otterbacher,
L. Kong, X. Li, and Y. Zhang. 2011. Evolutionary
Timeline Summarization: A Balanced Optimiza-
tion Framework via Iterative Substitution. In Proc.
SIGIR.
720
Proceedings of the ACL 2010 Conference Short Papers, pages 194?199,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Sparsity in Dependency Grammar Induction
Jennifer Gillenwater and Kuzman Ganchev
University of Pennsylvania
Philadelphia, PA, USA
{jengi,kuzman}@cis.upenn.edu
Jo?o Gra?a
L2F INESC-ID
Lisboa, Portugal
joao.graca@l2f.inesc-id.pt
Fernando Pereira
Google Inc.
Mountain View, CA, USA
pereira@google.com
Ben Taskar
University of Pennsylvania
Philadelphia, PA, USA
taskar@cis.upenn.edu
Abstract
A strong inductive bias is essential in un-
supervised grammar induction. We ex-
plore a particular sparsity bias in de-
pendency grammars that encourages a
small number of unique dependency
types. Specifically, we investigate
sparsity-inducing penalties on the poste-
rior distributions of parent-child POS tag
pairs in the posterior regularization (PR)
framework of Gra?a et al (2007). In ex-
periments with 12 languages, we achieve
substantial gains over the standard expec-
tation maximization (EM) baseline, with
average improvement in attachment ac-
curacy of 6.3%. Further, our method
outperforms models based on a standard
Bayesian sparsity-inducing prior by an av-
erage of 4.9%. On English in particular,
we show that our approach improves on
several other state-of-the-art techniques.
1 Introduction
We investigate an unsupervised learning method
for dependency parsing models that imposes spar-
sity biases on the dependency types. We assume
a corpus annotated with POS tags, where the task
is to induce a dependency model from the tags for
corpus sentences. In this setting, the type of a de-
pendency is defined as a pair: tag of the dependent
(also known as the child), and tag of the head (also
known as the parent). Given that POS tags are de-
signed to convey information about grammatical
relations, it is reasonable to assume that only some
of the possible dependency types will be realized
for a given language. For instance, in English it
is ungrammatical for nouns to dominate verbs, ad-
jectives to dominate adverbs, and determiners to
dominate almost any part of speech. Thus, the re-
alized dependency types should be a sparse subset
of all possible types.
Previous work in unsupervised grammar induc-
tion has tried to achieve sparsity through priors.
Liang et al (2007), Finkel et al (2007) and John-
son et al (2007) proposed hierarchical Dirichlet
process priors. Cohen et al (2008) experimented
with a discounting Dirichlet prior, which encour-
ages a standard dependency parsing model (see
Section 2) to limit the number of dependent types
for each head type.
Our experiments show a more effective sparsity
pattern is one that limits the total number of unique
head-dependent tag pairs. This kind of sparsity
bias avoids inducing competition between depen-
dent types for each head type. We can achieve the
desired bias with a constraint on model posteri-
ors during learning, using the posterior regulariza-
tion (PR) framework (Gra?a et al, 2007). Specifi-
cally, to implement PR we augment the maximum
marginal likelihood objective of the dependency
model with a term that penalizes head-dependent
tag distributions that are too permissive.
Although not focused on sparsity, several other
studies use soft parameter sharing to couple dif-
ferent types of dependencies. To this end, Cohen
et al (2008) and Cohen and Smith (2009) inves-
tigated logistic normal priors, and Headden III et
al. (2009) used a backoff scheme. We compare to
their results in Section 5.
The remainder of this paper is organized as fol-
194
lows. Section 2 and 3 review the models and sev-
eral previous approaches for learning them. Sec-
tion 4 describes learning with PR. Section 5 de-
scribes experiments across 12 languages and Sec-
tion 6 analyzes the results. For additional details
on this work see Gillenwater et al (2010).
2 Parsing Model
The models we use are based on the generative de-
pendency model with valence (DMV) (Klein and
Manning, 2004). For a sentence with tags x, the
root POS r(x) is generated first. Then the model
decides whether to generate a right dependent con-
ditioned on the POS of the root and whether other
right dependents have already been generated for
this head. Upon deciding to generate a right de-
pendent, the POS of the dependent is selected by
conditioning on the head POS and the direction-
ality. After stopping on the right, the root gener-
ates left dependents using the mirror reversal of
this process. Once the root has generated all its
dependents, the dependents generate their own de-
pendents in the same manner.
2.1 Model Extensions
For better comparison with previous work we
implemented three model extensions, borrowed
from Headden III et al (2009). The first exten-
sion alters the stopping probability by condition-
ing it not only on whether there are any depen-
dents in a particular direction already, but also on
how many such dependents there are. When we
talk about models with maximum stop valency Vs
= S, this means it distinguishes S different cases:
0, 1, . . . , S?2, and? S?1 dependents in a given
direction. The basic DMV has Vs = 2.
The second model extension we implement is
analogous to the first, but applies to dependent tag
probabilities instead of stop probabilities. Again,
we expand the conditioning such that the model
considers how many other dependents were al-
ready generated in the same direction. When we
talk about a model with maximum child valency
Vc = C, this means we distinguish C different
cases. The basic DMV has Vc = 1. Since this
extension to the dependent probabilities dramati-
cally increases model complexity, the third model
extension we implement is to add a backoff for the
dependent probabilities that does not condition on
the identity of the parent POS (see Equation 2).
More formally, under the extended DMV the
probability of a sentence with POS tags x and de-
pendency tree y is given by:
p?(x,y) = proot(r(x))?
Y
y?y
pstop(false | yp, yd, yvs)pchild(yc | yp, yd, yvc)?
Y
x?x
pstop(true | x, left, xvl) pstop(true | x, right, xvr )
(1)
where y is the dependency of yc on head yp in di-
rection yd, and yvc , yvs , xvr , and xvl indicate va-
lence. For the third model extension, the backoff
to a probability not dependent on parent POS can
be formally expressed as:
?pchild(yc | yp, yd, yvc) + (1? ?)pchild(yc | yd, yvc) (2)
for ? ? [0, 1]. We fix ? = 1/3, which is a crude
approximation to the value learned by Headden III
et al (2009).
3 Previous Learning Approaches
In our experiments, we compare PR learning
to standard expectation maximization (EM) and
to Bayesian learning with a sparsity-inducing
prior. The EM algorithm optimizes marginal like-
lihood L(?) = log
?
Y p?(X,Y), where X =
{x1, . . . ,xn} denotes the entire unlabeled corpus
and Y = {y1, . . . ,yn} denotes a set of corre-
sponding parses for each sentence. Neal and Hin-
ton (1998) view EM as block coordinate ascent on
a function that lower-bounds L(?). Starting from
an initial parameter estimate ?0, the algorithm it-
erates two steps:
E : qt+1 = argmin
q
KL(q(Y) ? p?t(Y | X)) (3)
M : ?t+1 = argmax
?
Eqt+1 [log p?(X,Y)] (4)
Note that the E-step just sets qt+1(Y) =
p?t(Y|X), since it is an unconstrained minimiza-
tion of a KL-divergence. The PR method we
present modifies the E-step by adding constraints.
Besides EM, we also compare to learning with
several Bayesian priors that have been applied to
the DMV. One such prior is the Dirichlet, whose
hyperparameter we will denote by ?. For ? < 0.5,
this prior encourages parameter sparsity. Cohen
et al (2008) use this method with ? = 0.25 for
training the DMV and achieve improvements over
basic EM. In this paper we will refer to our own
implementation of the Dirichlet prior as the ?dis-
counting Dirichlet? (DD) method. In addition to
195
the Dirichlet, other types of priors have been ap-
plied, in particular logistic normal priors (LN) and
shared logistic normal priors (SLN) (Cohen et al,
2008; Cohen and Smith, 2009). LN and SLN aim
to tie parameters together. Essentially, this has a
similar goal to sparsity-inducing methods in that it
posits a more concise explanation for the grammar
of a language. Headden III et al (2009) also im-
plement a sort of parameter tying for the E-DMV
through a learning a backoff distribution on child
probabilities. We compare against results from all
these methods.
4 Learning with Sparse Posteriors
We would like to penalize models that predict a
large number of distinct dependency types. To en-
force this penalty, we use the posterior regular-
ization (PR) framework (Gra?a et al, 2007). PR
is closely related to generalized expectation con-
straints (Mann and McCallum, 2007; Mann and
McCallum, 2008; Bellare et al, 2009), and is also
indirectly related to a Bayesian view of learning
with constraints on posteriors (Liang et al, 2009).
The PR framework uses constraints on posterior
expectations to guide parameter estimation. Here,
PR allows a natural and tractable representation of
sparsity constraints based on edge type counts that
cannot easily be encoded in model parameters. We
use a version of PR where the desired bias is a
penalty on the log likelihood (see Ganchev et al
(2010) for more details). For a distribution p?, we
define a penalty as the (generic) ?-norm of expec-
tations of some features ?:
||Ep? [?(X,Y)]||? (5)
For computational tractability, rather than penaliz-
ing the model?s posteriors directly, we use an aux-
iliary distribution q, and penalize the marginal log-
likelihood of a model by the KL-divergence of p?
from q, plus the penalty term with respect to q.
For a fixed set of model parameters ? the full PR
penalty term is:
min
q
KL(q(Y) ? p?(Y|X)) + ? ||Eq[?(X,Y)]||? (6)
where ? is the strength of the regularization. PR
seeks to maximize L(?) minus this penalty term.
The resulting objective can be optimized by a vari-
ant of the EM (Dempster et al, 1977) algorithm
used to optimize L(?).
4.1 `1/`? Regularization
We now define precisely how to count dependency
types. For each child tag c, let i range over an enu-
meration of all occurrences of c in the corpus, and
let p be another tag. Let the indicator ?cpi(X,Y)
have value 1 if p is the parent tag of the ith occur-
rence of c, and value 0 otherwise. The number of
unique dependency types is then:
X
cp
max
i
?cpi(X,Y) (7)
Note there is an asymmetry in this count: occur-
rences of child type c are enumerated with i, but
all occurrences of parent type p are or-ed in ?cpi.
That is, ?cpi = 1 if any occurrence of p is the par-
ent of the ith occurrence of c. We will refer to PR
training with this constraint as PR-AS. Instead of
counting pairs of a child token and a parent type,
we can alternatively count pairs of a child token
and a parent token by letting p range over all to-
kens rather than types. Then each potential depen-
dency corresponds to a different indicator ?cpij ,
and the penalty is symmetric with respect to par-
ents and children. We will refer to PR training
with this constraint as PR-S. Both approaches per-
form very well, so we report results for both.
Equation 7 can be viewed as a mixed-norm
penalty on the features ?cpi or ?cpij : the sum cor-
responds to an `1 norm and the max to an `?
norm. Thus, the quantity we want to minimize
fits precisely into the PR penalty framework. For-
mally, to optimize the PR objective, we complete
the following E-step:
argmin
q
KL(q(Y)||p?(Y|X)) + ?
X
cp
max
i
Eq[?(X,Y)],
(8)
which can equivalently be written as:
min
q(Y),?cp
KL(q(Y) ? p?(Y|X)) + ?
X
cp
?cp
s. t. ?cp ? Eq[?(X,Y)]
(9)
where ?cp corresponds to the maximum expecta-
tion of ? over all instances of c and p. Note that
the projection problem can be solved efficiently in
the dual (Ganchev et al, 2010).
5 Experiments
We evaluate on 12 languages. Following the ex-
ample of Smith and Eisner (2006), we strip punc-
tuation from the sentences and keep only sen-
tences of length ? 10. For simplicity, for all mod-
els we use the ?harmonic? initializer from Klein
196
Model EM PR Type ?
DMV 45.8 62.1 PR-S 140
2-1 45.1 62.7 PR-S 100
2-2 54.4 62.9 PR-S 80
3-3 55.3 64.3 PR-S 140
4-4 55.1 64.4 PR-AS 140
Table 1: Attachment accuracy results. Column 1: Vc-
Vs used for the E-DMV models. Column 3: Best PR re-
sult for each model, which is chosen by applying each of
the two types of constraints (PR-S and PR-AS) and trying
? ? {80, 100, 120, 140, 160, 180}. Columns 4 & 5: Con-
straint type and ? that produced the values in column 3.
and Manning (2004), which we refer to as K&M.
We always train for 100 iterations and evaluate
on the test set using Viterbi parses. Before eval-
uating, we smooth the resulting models by adding
e?10 to each learned parameter, merely to remove
the chance of zero probabilities for unseen events.
(We did not tune this as it should make very little
difference for final parses.) We score models by
their attachment accuracy ? the fraction of words
assigned the correct parent.
5.1 Results on English
We start by comparing English performance for
EM, PR, and DD. To find ? for DD we searched
over five values: {0.01, 0.1, 0.25, 1}. We found
0.25 to be the best setting for the DMV, the same
as found by Cohen et al (2008). DD achieves ac-
curacy 46.4% with this ?. For the E-DMV we
tested four model complexities with valencies Vc-
Vs of 2-1, 2-2, 3-3, and 4-4. DD?s best accuracy
was 53.6% with the 4-4 model at ? = 0.1. A
comparison between EM and PR is shown in Ta-
ble 1. PR-S generally performs better than the PR-
AS for English. Comparing PR-S to EM, we also
found PR-S is always better, independent of the
particular ?, with improvements ranging from 2%
to 17%. Note that in this work we do not perform
the PR projection at test time; we found it detri-
mental, probably due to a need to set the (corpus-
size-dependent) ? differently for the test set. We
also note that development likelihood and the best
setting for ? are not well-correlated, which un-
fortunately makes it hard to pick these parameters
without some supervision.
5.2 Comparison with Previous Work
In this section we compare to previously published
unsupervised dependency parsing results for En-
glish. It might be argued that the comparison is
unfair since we do supervised selection of model
Learning Method Accuracy
? 10 ? 20 all
PR-S (? = 140) 62.1 53.8 49.1
LN families 59.3 45.1 39.0
SLN TieV & N 61.3 47.4 41.4
PR-AS (? = 140) 64.4 55.2 50.5
DD (? = 1, ? learned) 65.0 (?5.7)
Table 2: Comparison with previous published results. Rows
2 and 3 are taken from Cohen et al (2008) and Cohen and
Smith (2009), and row 5 from Headden III et al (2009).
complexity and regularization strength. However,
we feel the comparison is not so unfair as we per-
form only a very limited search of the model-?
space. Specifically, the only values of ? we search
over are {80, 100, 120, 140, 160, 180}.
First, we consider the top three entries in Ta-
ble 2, which are for the basic DMV. The first en-
try was generated using our implementation of
PR-S. The second two entries are logistic nor-
mal and shared logistic normal parameter tying re-
sults (Cohen et al, 2008; Cohen and Smith, 2009).
The PR-S result is the clear winner, especially as
length of test sentences increases. For the bot-
tom two entries in the table, which are for the E-
DMV, the last entry is best, corresponding to us-
ing a DD prior with ? = 1 (non-sparsifying), but
with a special ?random pools? initialization and a
learned weight ? for the child backoff probabil-
ity. The result for PR-AS is well within the vari-
ance range of this last entry, and thus we conjec-
ture that combining PR-AS with random pools ini-
tialization and learned ? would likely produce the
best-performing model of all.
5.3 Results on Other Languages
Here we describe experiments on 11 additional
languages. For each we set ? and model complex-
ity (DMV versus one of the four E-DMV exper-
imented with previously) based on the best con-
figuration found for English. This likely will not
result in the ideal parameters for all languages, but
provides a realistic test setting: a user has avail-
able a labeled corpus in one language, and would
like to induce grammars for many other languages.
Table 3 shows the performance for all models and
training procedures. We see that the sparsifying
methods tend to improve over EM most of the
time. For the basic DMV, average improvements
are 1.6% for DD, 6.0% for PR-S, and 7.5% for
PR-AS. PR-AS beats PR-S in 8 out of 12 cases,
197
Bg Cz De Dk En Es Jp Nl Pt Se Si Tr
DMV Model
EM 37.8 29.6 35.7 47.2 45.8 40.3 52.8 37.1 35.7 39.4 42.3 46.8
DD 0.25 39.3 30.0 38.6 43.1 46.4 47.5 57.8 35.1 38.7 40.2 48.8 43.8
PR-S 140 53.7 31.5 39.6 44.0 62.1 61.1 58.8 31.0 47.0 42.2 39.9 51.4
PR-AS 140 54.0 32.0 39.6 42.4 61.9 62.4 60.2 37.9 47.8 38.7 50.3 53.4
Extended Model
EM (3,3) 41.7 48.9 40.1 46.4 55.3 44.3 48.5 47.5 35.9 48.6 47.5 46.2
DD 0.1 (4,4) 47.6 48.5 42.0 44.4 53.6 48.9 57.6 45.2 48.3 47.6 35.6 48.9
PR-S 140 (3,3) 59.0 54.7 47.4 45.8 64.3 57.9 60.8 33.9 54.3 45.6 49.1 56.3
PR-AS 140 (4,4) 59.8 54.6 45.7 46.6 64.4 57.9 59.4 38.8 49.5 41.4 51.2 56.9
Table 3: Attachment accuracy results. The parameters used are the best settings found for English. Values for hyperparameters
(? or ?) are given after the method name. For the extended model (Vc, Vs) are indicated in parentheses. En is the English Penn
Treebank (Marcus et al, 1993) and the other 11 languages are from the CoNLL X shared task: Bulgarian [Bg] (Simov et al,
2002), Czech [Cz] (Bohomov? et al, 2001), German [De] (Brants et al, 2002), Danish [Dk] (Kromann et al, 2003), Spanish
[Es] (Civit and Mart?, 2004), Japanese [Jp] (Kawata and Bartels, 2000), Dutch [Nl] (Van der Beek et al, 2002), Portuguese
[Pt] (Afonso et al, 2002), Swedish [Se] (Nilsson et al, 2005), Slovene [Sl] (D?eroski et al, 2006), and Turkish [Tr] (Oflazer et
al., 2003).
Unad
papeleranc esvs und
objetonc civilizadoaq
Unad
papeleranc esvs und
objetonc civilizadoaq
1.00
1.00 1.000.49
0.51
1.00
0.57
0.43
Unad
papeleranc esvs und
objetonc civilizadoaq
1.00 0.83 0.75 0.990.92
0.35
0.48
Figure 1: Posterior edge probabilities for an example sen-
tence from the Spanish test corpus. At the top are the gold
dependencies, the middle are EM posteriors, and bottom are
PR posteriors. Green indicates correct dependencies and red
indicates incorrect dependencies. The numbers on the edges
are the values of the posterior probabilities.
though the average increase is only 1.5%. PR-S
is also better than DD for 10 out of 12 languages.
If we instead consider these methods for the E-
DMV, DD performs worse, just 1.4% better than
the E-DMV EM, while both PR-S and PR-AS con-
tinue to show substantial average improvements
over EM, 6.5% and 6.3%, respectively.
6 Analysis
One common EM error that PR fixes in many lan-
guages is the directionality of the noun-determiner
relation. Figure 1 shows an example of a Span-
ish sentence where PR significantly outperforms
EM because of this. Sentences such as ?Lleva
tiempo entenderlos? which has tags ?main-verb
common-noun main-verb? (no determiner tag)
provide an explanation for PR?s improvement?
when PR sees that sometimes nouns can appear
without determiners but that the opposite situation
does not occur, it shifts the model parameters to
make nouns the parent of determiners instead of
the reverse. Then it does not have to pay the cost
of assigning a parent with a new tag to cover each
noun that doesn?t come with a determiner.
7 Conclusion
In this paper we presented a new method for unsu-
pervised learning of dependency parsers. In con-
trast to previous approaches that constrain model
parameters, we constrain model posteriors. Our
approach consistently outperforms the standard
EM algorithm and a discounting Dirichlet prior.
We have several ideas for further improving our
constraints, such as: taking into account the direc-
tionality of the edges, using different regulariza-
tion strengths for the root probabilities than for the
child probabilities, and working directly on word
types rather than on POS tags. In the future, we
would also like to try applying similar constraints
to the more complex task of joint induction of POS
tags and dependency parses.
Acknowledgments
J. Gillenwater was supported by NSF-IGERT
0504487. K. Ganchev was supported by
ARO MURI SUBTLE W911NF-07-1-0216.
J. Gra?a was supported by FCT fellowship
SFRH/BD/27528/2006 and by FCT project CMU-
PT/HuMach/0039/2008. B. Taskar was partly
supported by DARPA CSSG and ONR Young
Investigator Award N000141010746.
198
References
S. Afonso, E. Bick, R. Haber, and D. Santos. 2002.
Floresta Sinta(c)tica: a treebank for Portuguese. In
Proc. LREC.
K. Bellare, G. Druck, and A. McCallum. 2009. Al-
ternating projections for learning with expectation
constraints. In Proc. UAI.
A. Bohomov?, J. Hajic, E. Hajicova, and B. Hladka.
2001. The prague dependency treebank: Three-level
annotation scenario. In Anne Abeill?, editor, Tree-
banks: Building and Using Syntactically Annotated
Corpora.
S. Brants, S. Dipper, S. Hansen, W. Lezius, and
G. Smith. 2002. The TIGER treebank. In Proc.
Workshop on Treebanks and Linguistic Theories.
M. Civit and M.A. Mart?. 2004. Building cast3lb: A
Spanish Treebank. Research on Language & Com-
putation.
S.B. Cohen and N.A. Smith. 2009. The shared logistic
normal distribution for grammar induction. In Proc.
NAACL.
S.B. Cohen, K. Gimpel, and N.A. Smith. 2008. Lo-
gistic normal priors for unsupervised probabilistic
grammar induction. In Proc. NIPS.
A.P. Dempster, N.M. Laird, and D.B. Rubin. 1977.
Maximum likelihood from incomplete data via the
EM algorithm. Journal of the Royal Statistical So-
ciety, 39(1):1?38.
S. D?eroski, T. Erjavec, N. Ledinek, P. Pajas,
Z. ?abokrtsky, and A. ?ele. 2006. Towards a
Slovene dependency treebank. In Proc. LREC.
J. Finkel, T. Grenager, and C. Manning. 2007. The
infinite tree. In Proc. ACL.
K. Ganchev, J. Gra?a, J. Gillenwater, and B. Taskar.
2010. Posterior regularization for structured latent
variable models. Journal of Machine Learning Re-
search.
J. Gillenwater, K. Ganchev, J. Gra?a, F. Pereira, and
B. Taskar. 2010. Posterior sparsity in unsupervised
dependency parsing. Technical report, MS-CIS-10-
19, University of Pennsylvania.
J. Gra?a, K. Ganchev, and B. Taskar. 2007. Expec-
tation maximization and posterior constraints. In
Proc. NIPS.
W.P. Headden III, M. Johnson, and D. McClosky.
2009. Improving unsupervised dependency pars-
ing with richer contexts and smoothing. In Proc.
NAACL.
M. Johnson, T.L. Griffiths, and S. Goldwater. 2007.
Adaptor grammars: A framework for specifying
compositional nonparametric Bayesian models. In
Proc. NIPS.
Y. Kawata and J. Bartels. 2000. Stylebook for the
Japanese Treebank in VERBMOBIL. Technical re-
port, Eberhard-Karls-Universitat Tubingen.
D. Klein and C. Manning. 2004. Corpus-based induc-
tion of syntactic structure: Models of dependency
and constituency. In Proc. ACL.
M.T. Kromann, L. Mikkelsen, and S.K. Lynge. 2003.
Danish Dependency Treebank. In Proc. TLT.
P. Liang, S. Petrov, M.I. Jordan, and D. Klein. 2007.
The infinite PCFG using hierarchical Dirichlet pro-
cesses. In Proc. EMNLP.
P. Liang, M.I. Jordan, and D. Klein. 2009. Learn-
ing from measurements in exponential families. In
Proc. ICML.
G. Mann and A. McCallum. 2007. Simple, robust,
scalable semi-supervised learning via expectation
regularization. In Proc. ICML.
G. Mann and A. McCallum. 2008. Generalized expec-
tation criteria for semi-supervised learning of condi-
tional random fields. In Proc. ACL.
M. Marcus, M. Marcinkiewicz, and B. Santorini.
1993. Building a large annotated corpus of En-
glish: The Penn Treebank. Computational Linguis-
tics, 19(2):313?330.
R. Neal and G. Hinton. 1998. A new view of the EM
algorithm that justifies incremental, sparse and other
variants. In M. I. Jordan, editor, Learning in Graph-
ical Models, pages 355?368. MIT Press.
J. Nilsson, J. Hall, and J. Nivre. 2005. MAMBA meets
TIGER: Reconstructing a Swedish treebank from
antiquity. NODALIDA Special Session on Tree-
banks.
K. Oflazer, B. Say, D.Z. Hakkani-T?r, and G. T?r.
2003. Building a Turkish treebank. Treebanks:
Building and Using Parsed Corpora.
K. Simov, P. Osenova, M. Slavcheva, S. Kolkovska,
E. Balabanova, D. Doikoff, K. Ivanova, A. Simov,
E. Simov, and M. Kouylekov. 2002. Building a lin-
guistically interpreted corpus of bulgarian: the bul-
treebank. In Proc. LREC.
N. Smith and J. Eisner. 2006. Annealing structural
bias in multilingual weighted grammar induction. In
Proc. ACL.
L. Van der Beek, G. Bouma, R. Malouf, and G. Van No-
ord. 2002. The Alpino dependency treebank. Lan-
guage and Computers.
199
Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 38?46,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Graph-Based Posterior Regularization
for Semi-Supervised Structured Prediction
Luheng He Jennifer Gillenwater
Computer and Information Science
University of Pennsylvania
{luhe,jengi}@cis.upenn.edu
Ben Taskar
Computer Science and Engineering
University of Washington
taskar@cs.washington.edu
Abstract
We present a flexible formulation of semi-
supervised learning for structured mod-
els, which seamlessly incorporates graph-
based and more general supervision by ex-
tending the posterior regularization (PR)
framework. Our extension allows for any
regularizer that is a convex, differentiable
function of the appropriate marginals. We
show that surprisingly, non-linearity of
such regularization does not increase the
complexity of learning, provided we use
multiplicative updates of the structured ex-
ponentiated gradient algorithm. We il-
lustrate the extended framework by learn-
ing conditional random fields (CRFs) with
quadratic penalties arising from a graph
Laplacian. On sequential prediction tasks
of handwriting recognition and part-of-
speech (POS) tagging, our method makes
significant gains over strong baselines.
1 Introduction
Recent success of graph-based semi-supervised
learning builds on access to plentiful unsupervised
data and accurate similarity measures between
data examples (Zhu et al, 2003; Joachims, 2003;
Belkin et al, 2005; Zhu and Lafferty, 2005; Al-
tun et al, 2005; Zhu, 2005; Chapelle et al, 2006;
Subramanya and Bilmes, 2009; Subramanya et
al., 2010; Das and Petrov, 2011). Many ap-
proaches, such as Joachims (2003) and Subra-
manya and Bilmes (2009) use graph-based learn-
ing in the transductive setting, where unlabeled ex-
amples are classified without learning a parametric
predictive model. While predicted labels can then
be leveraged to learn such a model (e.g. a CRF),
this pipelined approach misses out on the benefits
of modeling sequential correlations during graph
propagation. In this work we seek to better inte-
grate graph propagation with estimation of a struc-
tured, parametric predictive model.
To do so, we build on the posterior regulariza-
tion (PR) framework of Ganchev et al (2010). PR
is a principled means of providing weak super-
vision during structured model estimation. More
concretely, PR introduces a penalty whenever the
model?s posteriors over latent variables contra-
dict the specified weak supervision. Ganchev
et al (2010) show how to efficiently optimize a
likelihood-plus-posterior-penalty type objective in
the case where the penalty is linear in the model?s
marginals. Yet, there are many forms of supervi-
sion that cannot be expressed as a linear function
of marginals. For example, graph Laplacian regu-
larization. In this work, we extend PR to allow for
penalties expressed as any convex, differentiable
function of the marginals and derive an efficient
optimization method for such penalties.
In our experiments, we explore graph Lapla-
cian posterior regularizers for two applications:
handwriting recognition and POS tagging. The
methods of Altun et al (2005), Subramanya et al
(2010), and Das and Petrov (2011) are the most
closely related to this work. Altun et al (2005)
describes coupling a graph regularizer with a max-
margin objective for pitch accent prediction and
handwriting recognition tasks. Their method suf-
fers from scalability issues though; it relies on op-
timization in the dual, which requires inversion of
a matrix whose dimension grows with graph size.
The more recent work of Subramanya et al
(2010) tackles the POS tagging task and pro-
vides a more scalable method. Their method
is a multi-step procedure that iterates two main
steps, graph propagation and likelihood optimiza-
tion, until convergence. Actually computing the
optimum for the graph propagation step would re-
quire a matrix inversion similar to that used by Al-
tun et al (2005), but they skirt this issue by using
an heuristic update rule. Unfortunately though, no
38
guarantees for the quality of this update are es-
tablished. Das and Petrov (2011) proceed very
similarly, adapting the iterative procedure to in-
clude supervision from bi-text data, but applying
the same heuristic update rule.
The work we present here similarly avoids the
complexity of a large matrix inversion and iter-
ates steps related to graph propagation and likeli-
hood optimization. But in contrast to Subramanya
et al (2010) and Das and Petrov (2011) it comes
with guarantees for the optimality of each step and
convergence of the overall procedure. Further, our
approach is based on optimizing a joint objective,
which affords easier analysis and extensions us-
ing other constraints or optimization methods. The
key enabling insight is a surprising factorization of
the non-linear regularizer, which can be exploited
using multiplicative updates.
2 Posterior regularization
We focus on the semi-supervised setting, showing
how to extend the discriminative, penalty-based
version of PR for a linear chain CRF. Our results
apply more generally though to the unsupervised
setting, the constraint-based versions of PR, and
other graphical models.
In the standard semi-supervised setting we are
given n data instances, {x1, . . . ,xn}, and labels
{y1, . . . ,yl} for the first l  n instances. For
simplicity of notation, we?ll assume each xi has
T components. Modeling this data with a linear
chain CRF, the standard conditional log-likelihood
objective with a Gaussian prior (variance? ?2) is:
L(?) =
l?
i=1
log p?(yi | xi)?
||?||22
2?2 . (1)
Note that this discriminative objective does not at-
tempt to leverage the unlabeled data. Since p? de-
composes according to the independence assump-
tions of a linear chain CRF, it can be expressed as:
p?(y | x) =
exp
[?T
t=1 ?>f(yt, yt?1,x)
]
Zp(x)
(2)
where the Zp(x) is a normalizer:
Zp(x) =
?
y?
exp
[ T?
t=1
?>f(y?t, y?t?1,x)
]
(3)
and the f are arbitrary feature functions. We as-
sume f(y1, y0,x) receives a special ?start? marker
for y0. In what follows, we refer to functions
over the (yt, yt?1,x) as local factors, or p-factors;
p?(y | x) decomposes as a product of p-factors.
Given this decomposition, L and its gradient
with respect to ? can be efficiently computed using
the forward-backward algorithm for linear chains.
This amounts to computing posterior marginals
for each p-factor (yt, yt?1,x). Following the gra-
dient suffices to find the global optimum of L,
since likelihood is concave, and the Gaussian prior
makes it strictly concave.
Penalty-based posterior regularization (PR)
modifies the likelihood objective by adding a
?penalty? term expressing prior knowledge about
the posteriors (Ganchev et al, 2010). To allow for
more efficient optimization, penalty terms are im-
posed on an auxiliary joint distribution q over the
labels instead of directly on p?. Agreement be-
tween q and p? is encouraged by a KL term:
KL(q ? p?) =
n?
i=1
KL(q(Y | xi) ? p?(Y | xi))
where Y is a random variable that can take on any
possible labeling y, and q(Y |xi) is a an arbitrary
distribution over Y for each i1. The penalty term
itself is restricted to be an essentially linear func-
tion of the p-factor marginals of q(Y | xi). To
compactly express this, we first define some no-
tation. Let mi denote the p-factor marginals of
q(Y | xi). For first-order linear chain models,
if K is the total number of labels a y variable
can take on, then mi contains the marginals for
t ? {1, . . . , T} and all K2 possible (yt, yt?1) la-
bel pairs. That is, mi is a length O(TK2) vector
with entries:
mit,k,j =
?
y
1(yt = k, yt?1 = j)q(y | xi) .
(4)
Stacking all these mi, we let m represent the
O(nTK2) vector [m1, . . . ,mn]. We further de-
fine a matrix A of constraint features. The product
Am is then the expectation of these features under
q. Finally we have, with a vector b of limits, the
following expression for the penalty term:
hlin(m) = ||max (Am? b,0)||? (5)
where ||?||? denotes an arbitrary norm. This ex-
pression will be non-zero if the expected value of
1We use a notation that is slightly different than, but
equivalent to, that of prior work, in order to facilitate our ex-
tensions later.
39
Am is larger than the limit b. The full posterior
regularizer is then:
R(?, q) = KL(q ? p?) + ?hlin(m) , (6)
where ? is a hyperparameter that controls the
strength of the second term.
Running example: Consider the task of part-
of-speech (POS) tagging, where the y are tags
and the x are words. To encourage every sen-
tence to contain at least one verb, we can pe-
nalize if the expected number of verbs under
the q distribution is less than 1. Specifically,
if ?verb? is represented by tag number v, for
sentence i we penalize unless:
1 ?
T?
t=1
K?
yt?1=1
mit,v,yt?1 . (7)
In the notation of Equation (5), these penal-
ties correspond to: an n-row A matrix, where
row i has?1?s to select exactly the portion of
m from Equation (7), and a limit b = ?1.
We briefly note here that generalized expec-
tation (Mann and McCallum, 2007; Mann and
McCallum, 2008) can be used to impose similar
penalties, but without the auxiliary q distribution.
Unfortunately though, this means the expectation
of the A features is with respect to p?, so comput-
ing the gradient requires the covariance between
the constraint features in A and the model features
f , under ?. For a linear chain CRF, this means the
run time of forward-backward is squared, although
some optimizations are possible. PR?s use of the
auxiliary q allows us to optimize more efficiently
by splitting the problem into easier blocks.
The new objective that combines likelihood
with the PR penalty is: J (?, q) = L(?) ?
R(?, q). While optimizing L(?) is easy, finding
max?,q J (?, q) is NP-hard even for the simplest
models. To optimize J , Ganchev et al (2010)
employ an expectation maximization (EM) based
method. At iteration t + 1, the algorithm updates
q and ? as follows:
E : qt+1 = argmin
q
R(?t, q) (8)
M : ?t+1 = argmax
?
L(?) + (9)
?
n?
i=l+1
?
y
qt+1(y | xi) log p?(y | xi)
where ? here is a hyperparameter that trades off
between the labeled and unlabeled data. Though
not stated above, note that in the E-step minimiza-
tion over q(Y | xi) is constrained to the probabil-
ity simplex. Ganchev et al (2010) show that this
E-step can be efficiently implemented, via pro-
jected gradient descent on the dual. The M-step
is similar to optimizing the original L, but with a
contribution from the unlabeled data that further
encourages q and p? to agree. Thus, the M-step
can be implemented via the same gradient ascent
methods as used for L. As with standard EM,
this method monotonically increases J and thus
is guaranteed to converge to a local optimum.
In this work, we contemplate what other types
of posterior penalty terms besides hlin(m) are
possible. In the subsequent section, we show that
it is possible to extend the class of efficiently-
optimizable PR penalties to encompass all convex,
differentiable functions of the marginals.
3 Non-linear PR
Let h(m) denote an arbitrary convex, differen-
tiable function of the marginals of q. Replacing
R?s penalty term with h, we have:
R?(?, q) = KL(q ? p?) + ?h(m) (10)
Let J? represent the full objective with R?. We
show that J? can be efficiently optimized.
Running example: Returning to our POS
tagging example, let?s consider one type of
non-linear convex penalty that might be use-
ful. Suppose our corpus has N unique
trigrams, and we construct a graph G =
(V,E,W ) where each vertex in V is a trigram
and each edge (a, b) ? E has a weight wab
that indicates the similarity of trigrams a and
b. To use the information from this graph to
inform our CRF, we can use the graph Lapla-
cian: L = D?W , where D is a diagonal de-
gree matrix with daa =?Nj=1waj . The form
of L is such that for every vector v ? RN :
v>Lv = 12
N?
a=1
N?
b=1
wab(va ? vb)2 . (11)
The larger the disparity in v values of similar
vertices, the larger the value of v>Lv. The
matrix L is positive semi-definite, so v>Lv is
40
convex in v. If each entry va is a linear func-
tion of the vector of marginals m described
above, then v(m)>Lv(m) is convex in m.
Thus, for any linear v(m), we can use this
Laplacian expression as a PR penalty.
For example, we can define v(m) such that
h(m) applies a penalty if trigrams that are
similar according to the graph have different
expected taggings under the CRF model. To
state this more formally, let?s define a map-
pingB : ({1, . . . , n}, {1, . . . , T}) 7? V from
words in the corpus to vertices in the graph:
B(i, t) = a implies word xit maps to vertex a.
Then, for a given tag k, we have the following
formula for the value of vertex a:
va,k = m?a,k =
n?
i=1
T?
t=1
B(i,t)=a
K?
yt?1=1
mit,k,yt?1
?n
i=1
?T
t=1 1(B(i, t) = a)
There are several issues to overcome in showing
that EM with these more general h(m) can still
be run efficiently and will still reach a local opti-
mum. First, we have to show that the optimal q
for the E-step minimization can still be compactly
representable as a product of p-factors.
3.1 Decomposition
Theorem 1. If h(m) is a convex, differen-
tiable function of q?s p-factor marginals, q? =
argminq R?(?, q) decomposes as a product of p-
factors.
Proof. Consider the E-step gradient of R?(?, q)
with respect to q. Using the shorthand qiy for
q(y | xi), the gradient is:
?R?
?qiy
= log qiy + 1? log p?(y | xi) + (12)
??h(m)?m
>?m
?qiy
.
Here, ?m?qiy is just a 0-1 vector indicating which of
the marginals from m apply to qiy. For example,
for yt = k and yt?1 = j, the marginal mit,k,j is
relevant. We can more simply write:
?h(m)
?m
>?m
?qiy
=
T?
t=1
?h(m)
?mit,yt,yt?1
. (13)
Setting the gradient equal to zero and solving for
qiy, we see that it must take the following form:
qiy =
p?(y | xi) exp
[
??
T?
t=1
?h(m)
?mit,yt,yt?1
]
Zq(xi)
.
(14)
From this expression, it is clear that qiy is propor-
tional to a product of p-factors.
Running example: Recall the graph Lapla-
cian penalty, discussed above for a particular
tag k. Summing over all tags, the penalty is:
h(m) = 12
K?
k=1
N?
a=1
N?
b=1
wab(m?a,k ? m?b,k)2 .
The derivative ?h(m)?mit,yt,yt?1 is then:
2
K?
k=1
N?
a=1
wa,B(i,t)(m?B(i,t),k ? m?a,k) . (15)
In words: for a given k, this gradient is pos-
itive if node B(i, t) has larger probability of
taking tag k than its close neighbors. Moving
in the direction opposite the gradient encour-
ages similar taggings for similar trigrams.
Theorem 1 confirms that the optimal q will de-
compose as desired, but does not address whether
we can efficiently find this q. Previous PR work
optimized the E-step in the dual. But while the
dual is easy to compute in closed form for norms
or linear functions, for arbitrary convex functions
the dual is often non-trivial.
Running example: For the case of a
graph Laplacian regularizer, in the primal the
penalty takes the form of a quadratic pro-
gram: v>Lv. Unfortunately, the dual of a
quadratic program contains a matrix inverse,
L?1 (van de Panne and Whinston, 1964).
Taking a matrix inverse is expensive, which
makes optimization in the dual unattractive.
Since moving to the dual would be inefficient,
optimizing R? will require some form of gradient
descent on the qiy. However, the standard gradient
descent update:
qiy ? qiy ? ?
?R?
?qiy
(16)
41
where ? is the step size, does not result in a fea-
sible optimization scheme, for several reasons.
First, it is possible for the updated q to be outside
the probability simplex. To be sure it remains in
the simplex would require a projection step on the
full, exponential-size set of all qiy, for each exam-
ple xi. Second, the updated q may not be propor-
tional to a product of p-factors. To be concrete,
suppose the starting point is qiy = p?(y | xi),
which does decompose as a product of p-factors.
Then after the first gradient update, we have:
qiy = p?(y | xi)? ?
(
1 + ?
T?
t=1
?h(m)
?mit,yt,yt?1
)
.
Unfortunately, while p?(y | xi) decomposes as a
product of p-factors, the other term decomposes
as a sum. Naturally, as we discuss in the following
section, multiplicative updates are more suitable.
3.2 Exponentiated Gradient
The exponentiated gradient descent (EGD) algo-
rithm was proposed by Kivinen and Warmuth
(1995), who illustrate its application to linear pre-
diction. More recently, Collins et al (2005) and
Collins et al (2008) extended EGD to exploit fac-
torization in structured models. The most impor-
tant aspect of EGD for us is that a variable?s up-
date formula takes a multiplicative rather than an
additive form. Specifically, the update for qiy is:
qiy ? qiy exp
[
?? ?R??qiy
]
. (17)
Lemma 2. EGD update Equation (17) preserves
decomposition of q into p-factors.
Proof. Applying the multiplicative EGD update
formula to qiy, we see that its new value equals the
following product:
(qiy)1??p?(y | xi)? exp
[
???
T?
t=1
?h(m)
?mit,yt,yt?1
]
,
up to a normalization constant. Since qiy and
p?(y | xi) both decompose as a product of p-
factors and since the update term is another prod-
uct of p-factors, the updated expression is itself a
product of p-factors (up to normalization).
Note that normalization is not an issue with
the EGD updates. Since q retains its decompo-
sition, the normalization can be efficiently com-
puted using forward-backward. Thus, Lemma 2
moves us much closer to the goal of running EM
efficiently, though there remain several stumbling
blocks. First and foremost, we cannot afford to ac-
tually apply EGD to each qiy, as there are an expo-
nential number of them. Thankfully, we can show
these EGD updates are equivalent to following the
gradient on a much smaller set of values. In par-
ticular, letting F represent the dimension of m,
which for example is O(nTK2) for linear chains,
we have the following result.
Lemma 3. Given the gradient vector ?h(m)?m , one
step of EGD on R?(?, q) can be completed in time
O(F ), where F is the dimension ofm.
Proof. First, we re-express qiy in log-linear form.
Applying Lemma 2, we know that qiy is propor-
tional to a product of p-factors This means that
there must exist some factors r such that qiy can
be written:
qiy =
1
Zq(xi)
exp
[ T?
t=1
ri,t(yt, yt?1)
]
. (18)
Re-expressing ?R??qiy given these r, we have:
?R?
?qiy
= C +
T?
t=1
[
ri,t(yt, yt?1)? (19)
?>f(yt, yt?1,xi) + ?
?h(m)
?mit,yt,yt?1
]
,
whereC = 1?logZq(xi)+logZp(xi) is constant
with respect to y. This means that we can just
update the individual r factors as follows:
ri,t(yt, yt?1)? (1? ?)ri,t(yt, yt?1) +
??>f(yt, yt?1,xi)? ??
?h(m)
?mit,yt,yt?1
. (20)
Note that if we start from qiy = p?(y | xi), then
the initial ri,t(yt, yt?1) are just ?>f(yt, yt?1,xi).
To conclude, since the number of r functions is
equal to the dimension ofm, the overall update is
linear in the number of marginals.
At this point, just one small issue remains: how
expensive is computing ?h(m)?m ? Work analyzingthe reverse mode of automatic differentiation in-
dicates that if computing a function h requires c
operations, then computing its gradient vector re-
quires no more than O(c) operations (Griewank,
1988). Thus, as long as our penalty function is
42
itself efficiently computable, the gradient vector
will be too. We conclude by observing that our
efficient algorithm converges to a local optimum.
Theorem 4. The above EGD-based EM algorithm
for optimizing J? (?, q) converges to a local opti-
mum of this objective.
Proof. The M-step remains unchanged from stan-
dard PR EM, and as such is strictly convex in
?. The E-step is strictly convex in q, since KL-
divergence is strictly convex and h(m) is convex.
Applying EGD, we know that we can efficiently
find the E-step optimum. Therefore, the EGD-
based EM algorithm efficiently implements coor-
dinate ascent on J? (?, q), with each step monoton-
ically increasing J? :
J? (?t, qt) ? J? (?t, qt+1) ? J? (?t+1, qt+1) .
Hence, we have shown that it is possible to
efficiently use an arbitrary convex, differentiable
function of the marginals, h(m), as a PR penalty
function. In the following section, we apply one
such function ? the graph Laplacian quadratic
from the running example ? to several tasks.
4 Experiments
We evaluate the effect of a graph Laplacian PR
penalty on two different sequence prediction tasks:
part-of-speech (POS) tagging and handwriting
recognition. Our experiments are conducted in a
semi-supervised setting, where only a small num-
ber, l, of labeled sequences are available during
training. Both the l labeled sequences and the re-
mainder of the dataset (instances l + 1 through n)
are used to construct a graph Laplacian2. We train
a second-order CRF using the methods described
in Section 3 and report results for a test set con-
sisting of instances l + 1 through n.
4.1 Graph construction
For each task we define a symmetric similarity
function on the task?s vertices V , sim : V ? V 7?
R, and build the graph based on its values. Specif-
ically, denoting the k nearest neighbors (NN) of
node u by Nk(u), we use the following mutual k-
NN criterion to decide which edges to include:
(u, v) ? E ?? u ? Nk(v) ? v ? Nk(u) .
2While these particular experiments are transductive, our
method can easily be applied inductively as well.
Entries in the final edge weight matrix are: wuv =
1[(u, v) ? E]sim(u, v).
4.2 Part-of-speech tagging
We experiment on ten languages. Our English
(EN) data is from the Penn Treebank (Marcus et
al., 1993), Italian (IT) and Greek (EL) are from
CoNLL-2007 (Nivre et al, 2007), and the remain-
ing languages in Figure 1 (a): German (DE), Span-
ish (ES), Portuguese (PT), Danish (DA), Slovene
(SL), Swedish (SV), and Dutch (NL) are from
CoNLL-X (Buchholz and Marsi, 2006). We use
a universal tag set (Das et al, 2012) throughout.
For each language, we first construct a mu-
tual 60-NN graph3 on trigram types, excluding
trigrams whose center word is punctuation. Our
smallest graph (Slovene) contains 25,198 nodes
while the largest (English) has 611,730.
For the similarity function sim(u, v), we follow
the method used in (Subramanya et al, 2010) and
(Das and Petrov, 2011), but with a somewhat mod-
ified feature set. For instance, while (Subramanya
et al, 2010) uses suffixes of the trigram?s center
word, we find this type of feature is too easy for
unrelated trigrams to match, leading to a noisy
graph. Let a trigram and its left/right context be
denoted by the 5-gram (w0, w1, w2, w3, w4). Then
the features we use to build the graph are:
? Trigram features: w12, w13, w23, w2,
suffix(w3)w2, suffix(w1)w2
? Context features: w0134, w012, w023, w024,
w124, w234, w01, w02, w24, w34
where suffix indicates common suffixes collected
from Wiktionary data. For a given feature f and
trigram type t, the value of the feature is deter-
mined by pointwise mutual information (PMI):
log #(f?t)#(f)#(t) . Then, for each pair of trigram types,
sim(u, v) is given by the cosine similarity of the
trigrams? feature vectors.
For the second-order CRF, we use a fairly stan-
dard set of features:
? Emission features: 1(yt = k ? f(xt?)),
where k can be any POS tag and t? ? {t, t ?
1, t + 1}. The f(xt?) takes the form of a
function from the following set: one indica-
tor for each word, lowercased word, and suf-
3In preliminary experiments we tested graphs with 20, 40,
60, 80, and 100 NNs and found that beyond 60 NNs addi-
tional performance gains are small.
43
fix, and also is-capitalized, is-punctuation, is-
digit, contains-hyphen, and contains-period.
? Transition features: For any POS tags
k1, k2, k3, we have a feature 1(yt =
k1, yt?1 = k2, yt+1 = k3) and its backoffs
(indicators for one or two matching tags).
4.3 Handwriting recognition
The handwriting dataset we use was collected by
Kassel (1995) and filtered to 6,877 words (Taskar
et al, 2003). For each word, the first letter is re-
moved so that every remaining letter is one of the
English language?s 26 lowercase letters.
Again, we first build a mutual NN graph. In this
case, we use 20-NN, since our graph has fewer
nodes and a larger set of possible node identi-
ties (26 letters instead of 12 tags). Each node
in this graph is one letter from the dataset, for a
total of 52,152 nodes. As a first step, we com-
pute cosine similarity on the pixels of each pair of
nodes, and then consider only pairs with a similar-
ity greater than 0.3. Next, we apply the Fast Earth
Mover?s distance E?MD(u, v) (Pele and Werman,
2009) with default parameters to compute the dis-
similarity of each pair of images. We convert these
into similarities via:
s(u, v) = exp
{
?E?MD(u, v)
?2EMD
}
(21)
where we set the variance ?EMD = 10. The fi-
nal similarity function sim(u, v) is the weighted
combination of the similarity of the nodes (u, v)
and their left neighbors (ul, vl) and right neigh-
bors (ur, vr) from their respective words:
sim(u, v) = ?s(u, v)+(1??)(s(ul, vl)+s(ur, vr))
where we fix ? = 0.8.
For the second-order CRF, the transition fea-
tures are same as for POS tagging, but with tags re-
placed by the English alphabet. The emission fea-
tures take a similar form, but with different mean-
ings for the f(xt?) indicator functions. Specifi-
cally, there is one indicator for each pixel loca-
tion, with value 1 if the pixel is turned on. As
there are many more emission than transition fea-
tures, we count the number of fired emission and
transition features, say fe and ft, then discount all
emission features, multiplying them by ftfe to bal-ance the amount of supervision.
4.4 Baselines
We compare our posterior regularization (PR) re-
sults with three baselines. We also include results
for the first EM iteration of our PR method (PR1),
to show there is still significant optimization oc-
curring after the first iteration.
The first baseline is graph propagation (GP).
Specifically, we start from uniform posteriors for
all the unlabeled nodes in the graph, then for each
tag/letter k and each node v we apply the gradient
update:
qk,v ? qk,v ? ?
?
u?Nk(v)
wkuv(qk,v ? qk,u) (22)
until convergence. We then select the tag/letter
with the largest probability as the prediction for
a node. If multiple tokens are mapped to a node,
then all receive the same prediction.
The second baseline incorporates both graph
propagation and sequence information. As a first
step, we run the GP baseline, then use the decod-
ing as additional labeled data to train a second-
order CRF (see GP?CRF results). The third base-
line is simply a second-order CRF, trained on the l
labeled examples.
4.5 Training details
For optimizing the CRF, we use L-BFGS (Bert-
sekas, 2004) and a Gaussian prior with ? = 100
(chosen by cross-validation on the labeled train-
ing examples). The final predictions are obtained
via posterior decoding. For PR, we run EM for
at most 20 iterations, which is enough for con-
vergence of the combined objective J? (?, q). We
cross-validate the constraint strength parameter ?
over the following values: {0.1, 0.5, 1.0, 2.0}, ul-
timately selecting ? = 1 for the POS tagging task
and ? = 0.1 for the handwriting recognition task.
4.6 Results and analysis
POS tagging. For each language, we randomly
sample 1000 labeled examples and split them into
10 non-overlapping training sets of size l = 100.
Figure 1 (a) shows the average error and its stan-
dard deviation for these training sets. If for each
language we take the difference between the aver-
age error of PR and that of the best of the three
baselines, the min, average, and max improve-
ments are: 2.69%, 4.06%, and 5.35%. When
analyzing the results, we observed that one re-
gion where PR makes substantial gains over the
44
EN DE ES PT DA SL SV EL IT NL Avg0
5
10
15
20
25
Language
POS T
agging
 Error
 
 GP GP? CRF CRF PR1 PR
(a)
0 100 200 300 400 5000
5
10
15
20
# of Labeled Examples
Portugue
se Taggi
ng Error
 
 
GP GP? CRF CRF PR1 PR
(b)
Figure 1: (a): POS results for 10 languages. Each bar in each group corresponds to the average POS
tagging error of one method; the left-to-right order of the methods is the same as in the legend. Whiskers
indicate standard deviations. The final set of bars is an average across all languages. See supplement for
a table with the exact numbers. (b): POS results on one language for a range of l.
CRF baseline is on unseen words (words that do
not occur in the set of l labeled examples). If
we measure performance only on such words, the
gain of PR over CRF is 6.7%. We also test with
l = {50, 100, 150, 200, 300, 400, 500} on one lan-
guage to illustrate how PR performs with different
amounts of supervision. Figure 1 (b) shows that
even when l = 500 our PR method is still able to
provide improvement over the best baseline.
Handwriting recognition. For this task, the
overall dataset contains 55 distinct word types.
Thus, we set l = 110 and sample 10 training
sets such that each contains 2 examples of each
of word. Note that due to the well-balanced train-
ing sets, baselines are fairly high here compared
to other similar work with this dataset. Table 1
shows there is an average improvement of 4.93%
over the best of the three baselines.
GP GP?CRF CRF PR1 PR
Mean 17.57 15.07 9.82 6.03 4.89
StdDev 0.30 0.35 0.48 0.20 0.42
Table 1: Handwriting recognition errors.
Even in a simpler setting closer to that of POS
tagging, where we just draw l = 100 samples ran-
domly, there are many cases where PR beats the
baselines. Figure 2 shows predictions from such
a setting and provides general intuition as to why
PR does well on handwriting recognition. For the
word ?Wobble? (with the first letter removed), the
CRF predicts ?obble? as ?ovely?, because of it re-
lies heavily on sequential information; in our small
training set, bigrams ?ov? (2 times) and ?ly? (12
times) are more frequent than ?ob? (1 time) and
?le? (7 times). GP correctly predicts these letters
because the graph connects them to good neigh-
bors. However, GP mislabels ?l? as ?i?, since most
of this letter?s neighbors are i?s. The coupling of
GP and CRF via PR links the neighbor informa-
tion with bigram information ? ?bl? (5 times) is
more frequent than ?bi? in the training set ? to
yield the correct labeling.
      l    t    l    l    l
      i    i    i    l    i
      l    l    l    l    l 
  CRF   b    b    b    b    m
  GP    b    b    b    b    b
  PR    b    b    b    b    b
CRF  o  v  e  l  y
GP   o  b  b  i  e
PR   o  b  b  l  e  
Figure 2: Predictions on the word ?Wobble? and
the 5-NNs of its first ?b? and ?l?.
5 Conclusion
We have presented an efficient extension of the
posterior regularization (PR) framework to a more
general class of penalty functions. Encouraging
results using a graph Laplacian penalty suggest
potential applications to a much larger class of
weakly supervised problems.
Acknowledgements
J. Gillenwater was supported by a National Sci-
ence Foundation Graduate Research Fellowship.
L. He and B. Taskar were partially supported by
ONR Young Investigator Award N000141010746.
45
References
[Altun et al2005] Y. Altun, D. McAllester, and
M. Belkin. 2005. Maximum Margin Semi-
Supervised Learning for Structured Variables. In
Proc. NIPS.
[Belkin et al2005] M. Belkin, P. Niyogi, and V. Sind-
hwani. 2005. On Manifold Regularization. In Proc.
AISTATS.
[Bertsekas2004] D. Bertsekas. 2004. Nonlinear Pro-
gramming.
[Buchholz and Marsi2006] S. Buchholz and E. Marsi.
2006. CoNLL-X Shared Task on Multilingual De-
pendency Parsing. In Proc. CoNLL.
[Chapelle et al2006] O. Chapelle, B. Scho?lkopf, and
A. Zien, editors. 2006. Semi-Supervised Learning.
[Collins et al2005] M. Collins, P. Bartlett,
D. McAllester, and B. Taskar. 2005. Expo-
nentiated Gradient Algorithms for Large-Margin
Structured Classification. In Proc. NIPS.
[Collins et al2008] M. Collins, A. Globerson, T. Koo,
and X. Carreras. 2008. Exponentiated Gradient Al-
gorithms for Conditional Random Fields and Max-
Margin Markov Networks. JMLR.
[Das and Petrov2011] D. Das and S. Petrov. 2011. Un-
supervised Part-of-Speech Tagging with Bilingual
Graph-Based Projections. In Proc. ACL.
[Das et al2012] D. Das, S. Petrov, and R. McDonald.
2012. A Universal Part-of-Speech Tagset. In Proc.
LREC.
[Ganchev et al2010] K. Ganchev, J. Grac?a, J. Gillen-
water, and B. Taskar. 2010. Posterior Regulariza-
tion for Structured Latent Variable Models. JMLR.
[Griewank1988] A. Griewank. 1988. On Automatic
Differentiation. Technical report, Argonne National
Laboratory.
[Joachims2003] T. Joachims. 2003. Transductive
Learning via Spectral Graph Partitioning. In Proc.
ICML.
[Kassel1995] R. Kassel. 1995. A Comparison of Ap-
proaches to On-line Handwritten Character Recog-
nition. Ph.D. thesis, Massachusetts Institute of
Technology.
[Kivinen and Warmuth1995] J. Kivinen and M. War-
muth. 1995. Additive Versus Exponentiated Gra-
dient Updates for Linear Prediction. In Proc. STOC.
[Mann and McCallum2007] G. Mann and A. McCal-
lum. 2007. Simple, Robust, Scalable Semi-
Supervised Learning via Expectation Regulariza-
tion. In Proc. ICML.
[Mann and McCallum2008] G. Mann and A. McCal-
lum. 2008. Generalized Expectation Criteria for
Semi-Supervised Learning of Conditional Random
Fields. In Proc. ACL.
[Marcus et al1993] M. Marcus, M. Marcinkiewicz, and
B. Santorini. 1993. Building a Large Annotated
Corpus of English: Then Penn Treebank. Compu-
tational Linguistics.
[Nivre et al2007] J. Nivre, J. Hall, S. Ku?bler, R. Mc-
Donald, J. Nilsson, S. Riedel, and D. Yuret. 2007.
The CoNLL 2007 Shared Task on Dependency Pars-
ing. In Proc. CoNLL.
[Pele and Werman2009] O. Pele and M. Werman.
2009. Fast and Robust Earth Mover?s Distances. In
Proc. ICCV.
[Subramanya and Bilmes2009] A. Subramanya and
J. Bilmes. 2009. Entropic Graph Regularization in
Non-Parametric Semi-Supervised Classification. In
Proc. NIPS.
[Subramanya et al2010] A. Subramanya, S. Petrov, and
F. Pereira. 2010. Efficient Graph-Based Semi-
Supervised Learning of Structured Tagging Models.
In Proc. EMNLP.
[Taskar et al2003] B. Taskar, C. Guestrin, and
D. Koller. 2003. Max Margin Markov Networks.
In Proc. NIPS.
[van de Panne and Whinston1964] C. van de Panne and
A. Whinston. 1964. The Simplex and the Dual
Method for Quadratic Programming. Operational
Research Quarterly.
[Zhu and Lafferty2005] X. Zhu and J. Lafferty. 2005.
Harmonic Mixtures: Combining Mixture Models
and Graph-Based Methods for Inductive and Scal-
able Semi-Supervised Learning. In Proc. ICML.
[Zhu et al2003] X. Zhu, Z. Ghahramani, and J. Laf-
ferty. 2003. Semi-Supervised Learning Using
Gaussian Fields and Harmonic Functions. In Proc.
ICML.
[Zhu2005] X. Zhu. 2005. Semi-Supervised Learning
Literature Survey. Technical report, University of
Wisconsin-Madison.
46
