Thai Spelling Recognition Using a Continuous Speech Corpus 
Chutima Pisarn 
Sirindhorn International Institute of Technology  
131 Moo 5 Tiwanont Rd., Bangkadi, 
Muang, Phathumthani, Thailand, 12000 
chutimap@siit.tu.ac.th 
Thanaruk Theeramunkong 
Sirindhorn International Institute of Technology  
131 Moo 5 Tiwanont Rd., Bangkadi, 
Muang, Phathumthani, Thailand, 12000 
thanaruk@siit.tu.ac.th 
 
Abstract 
Spelling recognition is an approach to enhance a 
speech recognizer?s ability to cope with incorrectly 
recognized words and out-of-vocabulary words. 
This paper presents a general framework for Thai 
speech recognition enhanced with spelling 
recognition. In order to implement Thai spelling 
recognition, Thai alphabets and their spelling 
methods are analyzed. Based on hidden Markov 
models, we propose a method to construct a Thai 
spelling recognition system by using an existing 
continuous speech corpus. To compensate the 
difference between spelling utterances and 
continuous speech utterances, the adjustment of 
utterance speed is taken into account. Assigning 
different numbers of states for syllables with 
different durations is helpful to improve the 
recognition accuracy. Our system achieves up to 
79.38% accuracy. 
1 Introduction 
Nowadays, several works on automatic speech 
recognition (ASR) for continuous speech are being 
developed, not only system that rely on dictionary, 
but also the recognition on out of vocabulary 
circumstances. In a situation of misrecognition and 
out-of-vocabulary words, a practical and efficient 
solution that would assist the ASR is to equip the 
system with a spelling recognition subsystem, 
where users can spell out a word letter by letter. 
Spelling recognition is a challenging task with a 
high interest for directory assistance sevices, or 
other applications where a large number of proper 
names or addresses are handled. Many works that 
focus on spelling recognition were widely 
developed in several languages, for instance, 
English, Spanish, Portuguese and German. In (San-
Segundo et al, 2001) the hypothesis-verification 
Spanish continuous spelled proper name 
recognition over the telephone was proposed. In 
this work, several feature sets were investigated by 
using models of neural networks. In their 
succeeding work (San-Segundo et al, 2002), three 
different recognition architectures, including the 
two-level architecture, the integrated architecture 
and the hypothesis-verification architecture, are 
analyzed and compared. In (Rodrigues et al, 
1997), a Portuguese speaker -independent system 
for recognizing an isolated letter was introduced. 
The system dealt with speech utterances over a 
telephone line using Hidden Markov Model 
(HMM). A number of experiments were made over 
four different perplexity language models. Mitchell 
and Setlur (1999) proposed a fast list matcher to 
select a name from a name list that was created 
from an n-best letter recognizer on spelling over a 
telephone line recognition task. In (Bauer and 
Junkawitsch, 1999), an approach is proposed to 
combine word recognition with spelling 
recognition in a user-friendly manner as a fall back 
strategy. As a German city name recognizer, the 
system was applied to directory assistance 
services. 
Unlike other languages, spelling in Thai has 
several styles. One of them is similar to spelling in 
English, i.e., /d-ii//z-oo//g-ii/ for ?dog?. There are 
three more methods in Thai spelling, where some 
syllables are inserted to make it clearer for the 
hearer. One is to spell out a letter followed by its 
representative word?s utterance. Another way is to 
mix the former two types. The third method is to 
spell out a set of letters that form a syllable, 
followed by its corresponding utterance. So far 
spelling recognition for Thai language has not been 
explored yet. One of the main reasons is that there 
is no standard corpus for this purpose. Creating a 
corpus of spelled utterances is a time comsuming 
task. In this work we use the NECTEC-ATR Thai 
Speech Corpus, a standard continuous Thai speech 
corpus, for our spelling recognition system. 
Another objective of this work is to examine how a 
spelling system can be implemented using a 
normal Thai continuous speech corpus. That is, as 
the preliminary stage, we investigate the effects of 
spelling using such existing corpus. 
This paper is organized as follows. In section 2, 
language characteristics in Thai are introduced. 
Section 3 presents our recognition framework. The 
spelling styles for Thai words are discussed in 
section 4. The experimental results and analysis are 
shown in section 5. Finally, the conclusion and 
future works are given in section 6. 
2 Thai Language Characteristics 
In this section, Thai alphabets, phonetic symbols 
and the phone components of Thai syllable are 
described. 
2.1 Thai Alphabets  
Theoritically, Thai language has totally 69 
alphabets which can be basically grouped into 
three classes of phone expression; consonant, 
vowel and tone. There are 44, 21, and 4 alphabets 
for consonants, vowels, and tones, repectively. 
Some Thai consonant alphabets share the same 
phonetic sounds. There are only 21 phones for 
Thai consonants. Since some vowels can be 
combined with others, there are possible 32 
phones. However, in practical spelling manner, 
only 18 alphabets in the vowel class are mostly 
used. There are 5 tones in Thai, including one 
without an alphabet. In conclusion, there are totally 
66 alphabets actually used. They are shown in 
Table 1. 
Basic Classes  Alphabets in each class 
Consonant ?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?
,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,
?,?,?,?,?,? 
Vowel ??, ?, ??, ?, ??, ??, ??, ??, ??, ??, ?, ?, ?, ???, ? 
,?, ?, ?? 
Tone ??, ??, ??, ??   
Table 1. Thai Alphabets: Consonants, Vowels 
and Tones. 
2.2 Thai Syllable Characteristics and 
Phonetic Representation 
Initial 
Consonant 
Vowel 
 
Final 
Consonant 
Tone 
 
(Ci) (V) (Cf) (T) 
p,pr,phr,pl,p
hl,t,tr,thr,c,k
r,khr,k,z,ph,t
h,ch,k,kl,khl,
kw,khw,h,b,b
r,bl,d,dr,m,n
,ng,r,f,fr,fl,s,
h,w,j 
a,aa,i,ii,v,v
v,u,uu,e,ee,
x,xx,o,oo,
@,@@,q, 
qq,ia,iia,va
,vva,ua,uua 
p^,t^,k^,n^,
m^,ng^,j^,w
^,f^,l^,s^,ch
^,jf^,ts^ 
0,1,2
,3,4 
Table 2. Phonetic Symbols Grouped as Initial 
Consonants, Vowels, Final Consonants and Tones. 
In Thai language, a syllable can be separated into 
three parts; (1) initial consonant, (2) vowel and (3) 
final consonant. The phonetic representation of one 
syllable can be expressed in the form of /Ci-VT-Cf/, 
where Ci is an initial consonant, V is a vowel, Cf  is 
a final consonant and T is a tone which is 
phonetically attached to the vowel part. Following 
the concept in (Pisarn and Theeramunkong, 2003) 
there are 76 phonetic symbols and 5 tone symbols 
applied in this work as shown in Table 2. 
3 Our Framework 
The recognition framework illustrated in Figure 1 
presents our overall framework designed for Thai 
continuous speech recognition system that  
incorporates a conventional recognizer with a 
spelling recognition subsystem. The whole process 
can be divided into two modules; (1) training 
module and (2) recognition module.  
 
Speech
Corpus
Signal
Processing
Text Corpus
General
Pronunc. Dict.
Acoustic Model
fs
Conventional
Speech
Recognizer
 
New
Utterances
Spelling
Recognizer
 
Spelled
utterance
The hypotheses
Acceptable?
Signal
Processing
Speaker spell
the word
Recognition
 Result
   Yes
Language Model
w1 w2 w3
w4
w6 w7
Proper  Name
Corpus
Language Model
L1 L2 L3
L4
L6 L7
Alphabet
Pronunc. Dict.
Spelling
 Result
No
TRAINING MODULE
RECOGNITION
MODULE  
Figure 1. The Recognition Framework 
In the training module, waveforms of continuous 
speech utterances in a corpus are transformed to 
feature vectors by using a signal quantization 
technique. The derived feature vectors are used for 
training a set of acoustic models. In the system,  
two language models are equiped; one stands for 
traditional word recognition, whereas the other one 
is used for spelling recognition. The traditional 
language model is trained by transcriptions in the 
text corpus, while the spelling language model is 
trained by sequences of letters in a proper name 
corpus. 
In the recognition module, the two well-trained 
models; the acoustic model and the traditional 
language model, together with a pronunciation 
dictionary are applied to recognize a new 
utterance, yeilding a set of hypothesis results. The 
hypotheses are then verified whether it is valid or 
not. If it is not, the system will turn to the spelling 
recognition subsystem.  
At this stage, the user is asked to spell the word 
letter-by-letter. The utterance of spelling is then 
fed to the signal-processing module for converting 
the waveform to feature vectors. In this work, as 
our preliminary stage, we used the acoustic models 
trained by normal continuous speech utterances 
because of a lacking spelling corpus. Working with 
well-trained spelling language model and 
alphabetic pronunciation dictionary, the spelling 
results could be obtained. 
4 Spelling Style for Thai Word 
4.1 Basic Pronunciation of Thai Alphabets 
As refered in section 2.1, there are three basic 
classes of Thai alphabets. Pronouncing Thai 
alphabets in different classes has different styles. 
The consonant class alphabets can be uttered in 
either of the following two styles. The first style is 
simply pronouncing the core sound of a consonant. 
For example, the alphabet ???, its core sound can be 
represented as the syllable phonetic /k-@@0/. 
Normally, some consonants share a same core 
sound, for instance ???, ???, ??? have the same 
phonetic /kh-@@0/. In such case, the hearer may 
encounter an alphabet ambiguity. To solve this 
issue, the second style is generally applied by 
uttering a core sound of the consonant followed by 
the representative word of that consonant. Every 
consonant has its representative word. For 
example, the representative word of ???  is ????? 
(chicken), with the phonetic sound /k-a1-j^/, and 
that of  ??? is ????? (egg, /kh-a1-j^/). To express the 
alphabet ??? using this style, the sound /k-
@@0/+/k-a1-j^/ is uttered.  
Expressing alphabets in the vowel class is quite 
different to that of the consonant class. There are 
two types of vowels. The first-type of vowels can 
be pronounced in two ways. One is to pronounce 
the word ????? (meaning: ?vowel?, sound: /s-a1//r-
a1/), followed by the core sound of the vowel. The 
other is to pronounce by simply pronouncing the 
core sound of the vowel. The second-type of 
vowels are uttered by calling their names. The 
vowel alphabets of each type are listed in Table 3. 
As the last class, tone symbols can be pronounced 
by calling their names. 
Type Vowels 
The first-type   ?,  ?, ??, ??, ??, ??, ??, ??, ?, ?, ?, ???, ?.? 
The second-type ??, ??, ??, ? 
 Table 3.  Two Types of Vowels  
4.2 Thai Word Spelling Methods 
Spelling out a word is the way to utter each 
alphabet in the word in order. It refers to 
combinations of the pronunciation style of each 
alphabet in the word. Only the four Thai most 
commonly used spelling methods have been 
addressed. For all methods, the second-type vowels 
and tones are pronounced by calling their names. 
The differences are taken place in spelling 
consonants and the first-type vowels. For the first 
spelling method, the consonants are spelled out by 
using only their core sounds, and the first-type 
vowels are pronounced by their core sound without 
the word ????? (/s-a1//r-a1/). This spelling method 
is similar to the spelling approach in English 
language. 
In the second method, the representative word of 
each consonant is pronounced followed by its core 
sound while pronounce a first-type vowel is to 
utter the word ????? and then its core sound. In the 
third method, the way to pronounce a consonant 
and vowel are varied. For instance, the word can 
be spelled a consonant by using only core sound 
together with a vowel beginning with the word 
?????. The last method is to spell out a set of letters 
that form a syllable and then followed by its 
corresponding utterances. The spelling sequence of 
alphabets in each syllable starts with initial 
consonant, vowel, and followed by final consonant 
(if any) and tone (if any), and then, the sound of 
that syllable is inserted at the end of the sequence. 
The examples of these methods in spelling the 
word ??????? are depicted in Figure 2. 
?  ? ? ?  ?
/s-@@4/ /ng-@@0/ /h-@@4/Core-Sound: /z-ii1/
Calling by name /k-aa0//r-a0-n^/
Basic Class: Consonant Consonant ConsonantVowel Vowel
Representative word /s-vva4/ /ng-uu0/ /h-ii1-p^/
?Vowel? /s-a1//r-a1/
Sequence of word
???????
/s-@@4/ /ng-@@0/ /h-@@4//z-ii1/ /k-aa0//r-a0-n^/1 st Method:
2 nd  Method:
3 rd Method: /s-@@4/ /ng-@@0/ /h-@@4/ /k-aa0//r-a0-n^/
/z-ii1/
/s-a1//r-a1/
/k-aa0//r-a0-n^//s-@@4/
/s-vva4/
/ng-@@0/
/ng-uu0/
/h-@@4/
/h-ii1-p^//z-ii1/
/s-a1//r-a1/
/s-@@4/ /ng-@@0/ /h-@@4//z-ii1/ /k-aa0//r-a0-n^/4 th Method: /s-ii4-ng^/  
Figure 2.  Four spelling methods for the word 
??????? 
In this paper, we concentrate on the second 
method as the first step, since this is the most 
popular spelling method in Thai language. 
5 Experimental Results and Analysis 
5.1 Experimental Environment 
As mentioned above, the corpus for a spelling 
recognition task is unfortunately not available at 
this time. Therefore, this work applies the 
NECTEC-ATR Thai Speech Corpus, constructed 
by NECTEC (National Electronics and Computer 
Technology Center) incorporated with ATR 
Spoken Language Translation Laboratories. In 
Thai language speech recognition, this corpus is 
normally used for a continuous speech recognition 
task. This speech corpus is used as the training set 
for our spelling recognition system. The corpus 
contains 390 sentences gathered by assigning 42 
speakers (21 males and 21 females) to read all 
sentences for a trail. So, there are totally 16,380 
read utterances. 
In the first place, by the reason of computation 
time, only utterances of 5 males and 5 females, are 
used, i.e., totally 3,900 trained utterances. In 
addition, as our preliminary work, the effects of 
spelling result with a normal continuous training 
corpus are investigated. Even though, the training 
corpus has quite different characteristics compared 
to the test utterances, we can expect a reasonable 
result. The test utterance is constructed by 
recording the spelling of 136 proper names by a 
female participant. 
The speech signals were digitized by 16-bit A/D 
converter of 16 kHz. A feature vector used in our 
experiment is a 39-feature vector, consists of 12 
PLP coefficients and the 0th coefficient, as well as 
their first and second order derivatives. Therefore, 
there are totally 39 elements. 
The language model used in this task is a bigram 
language model, trained from totally 6,107 proper 
names, i.e., 5,971 Thai province, district and 
subdistrict names, as well as 136 proper names 
from the test transcription. 
A phone-based HMM is applied as the 
recognition system. The acoustic units used in this 
experiment are defined in the same manner as in 
(Pisarn and Theeramunkong, 2003). All 
experiments, including automatic transcription 
labelling, are performed using HTK toolkit (Young 
et al, 2002). The word correctness is given by the 
percentage of numbers of correct words divided by 
total number of words and the accuracy is 
computed by the percentage of subtracted the 
numbers of correct words by the number of 
insertion errors, which are then divided by total 
number of words. 
5.2 Setting a Baseline 
In the first experiment, we investigate the spelling 
results using the original training and testing data 
as they are. This will be a baseline for all of our 
experiment. In this initial stage, the context-
independent method (CI), achieves 79.94 and 
57.99 for correctness and accuracy, respectively. 
The system with context-dependent method (CD) 
gains 70.80 and 46.09 for correctness and accuracy 
respectively. In principle, low accuracy is triggered 
by a large number of insertion errors. Because of 
this figure, two possible assumptions can be made 
(1) there is in compatible duration between the 
training and the test set, and (2) Our HMM models 
are inappropriate. 
5.3 Adjusting the Duration 
To investigate the results of the first assumption, 
the utterance speed of the utterances from the 
training and testing are measured in the form of the 
number of phone per second. The speed can be 
computed by dividing the number of total phones 
in each utterance transcription by its utterances 
duration in seconds. As a result, the average 
utterance speed of the training set is 11.7 
phones/sec while the average utterance speed of 
the test set is only 4.6 phones/sec. This indicates 
that the speed of test utterances are approximately 
2.5 times slower than that of train utteraces. This 
difference may cause low accuracy.  
To compensate for this duration difference 
among the training utterance and the testing 
utterance, a method to shrink and stretch a speech 
signal, by preserving pitch and auditory features of 
the original signal, is applied in our signal 
preprocessing. The experiments are done in two 
environments; stretching the training utterances 
and shrinking the test utterences. By adjusting the 
duration of the training and testing utterances, 
insertion errors could be reduced. Stretching the 
training utterances and shrinking the test utterances 
are performed using various scale factors in order 
to investigate the effectiveness. Table 4 shows the 
recognition results of stretched training utterances 
with various scale factors. Here, the original test 
utterances are used. 
Duration Model %Correct Accuracy 
CI 81.91 62.49 1.25Train CD 82.05 66.36 
CI 85.43 68.54 1.43Train CD 85.86 70.09 
CI 86.42 63.34 1.67Train CD 84.59 63.97 
Table 4. Recognition Results of Stretched 
Training Utterances with Various Scale Factors.  
In principle, stretching training utterances causes 
the original utterances to be distorted. The more 
scale the utterances are stretched, the more distored 
the utterances we obtain. As stated in the previous 
section, utterances training are approximately 2.5 
times faster than the test utterances. However, they 
are expected to achieve a very low accuracy. The 
experimental results show that by adjusting 
training utterances 1.43 times slower than the 
original one (1.43Train) can improve the 
correctness to 85.86 % and the accuracy to 70.09% 
in a context-dependent method. But with more 
stretching, the accuracy drops to 63.97%. 
Reversely we also examine the system accuracy 
when the test utterances are shrinked on various 
scale factors. The original training utterances are 
used for training our system. The recognition 
results are shown in Table 5. 
Duration Model %Correct Accuracy 
CI 86.28 74.88 0.71Test CD 82.41 73.12 
CI 82.97 77.34 0.43Test CD 80.93 75.93 
Table 5. Recognition Results of Shrinked Test 
Utterances with Various Scale Factors. 
Shrinking test utterances can improve accuracy. 
Especially, the test utterances with 0.43 scaling 
factor can reduce the accuracy error to 19.35%, 
from 57.99% to 77.34%. 
No.of 
states  
Model %Correct Accuracy 
CI 82.97 77.34 3 CD 80.93 75.93 
CI 80.01 76.78 4 CD 79.73 76.85 
CI 80.79 79.38 5 CD 79.31 78.25 
CI 78.04 76.99 6 CD 76.92 76.21 
Table 6. Recognition Accuracy with Various 
Numbers of States for a Long Vowel Phoneme. 
5.4 Acoustic Models with Different 
Numbers of States 
In fact, phone durations of each phoneme in Thai 
language do not have the same duration. Especially 
in the vowel class, there are vowels pairs, where 
one has a longer phone while the other has a 
shorter phone. For example, the vowel pair, a and 
aa, have a similar phone but different durations. 
The phoneme a has a shorter duration than the 
phoneme aa. The other vowel pairs are i-ii, v-vv, u-
uu, e-ee, x-xx, o-oo, @-@@, q-qq, ia-iia, va-vva, 
and ua-uua. The shorter phone should not have the 
same number of state as the longer one. Therefore, 
we examined the recognition rate on different 
numbers of HMM states. The experiment is 
examined using the 0.43Test set since it is the best 
one in the previous experiment. The results are 
shown in Table 6. In this experiment, the number 
of states for a long vowel phoneme is varied from 
3 to 6 states. However, the numbers of states for 
the other phonemes are set to 3 states. 
Table 6 shows that a 5-state HMM for a long 
vewel phoneme and a 3-state HMM for the other 
phonemes achieve the highest recognition 
accuracy, i.e., 79.38. This is, 2.04% error rate 
reduction compared with the 3-state HMM. 
6 Conclusion 
In this paper, we present a general framework for 
Thai speech recognition enhanced with spelling 
recognition. Four styles for spelling Thai words 
were discussed. To recognize spelling utterances, 
HMMs were constructed using a continuous 
speech corpus. To achieve higher correctness and 
accuracy, we compensated the utterance speed 
among the training and test utterances by 
stretching the training utterances or shrinking the 
test utterances. The experimental results indicated 
promising performance of 79.38% recognition 
accuracy after this adjustment. With a good scaling 
factor, the system achieved 19.35% improvement 
compared with the baseline where the training and 
test utterances were used as they are. Assigning a 
larger number of states to a longer syllable (i.e., 
long vowel) could improve recognition accuracy 
by 2.04 %. Our further works include (1) to 
construct a system that deals with several kinds of 
spelling methods, and (2) to explore the 
incorporation of spelling recognition into the 
conventional speech recognition system. 
Acknowledgements 
The authors would like to thank National 
Electronics and Computer Technology Center 
(NECTEC) for allowing us to use the NECTEC-
ATR Thai Speech Corpus. We also would like to 
thank Dr. Virach Sornlertlamvanich for his useful 
suggestions through this work. This work has 
partly been supported by NECTEC under project 
number NT-B-22-I5-38-47-04. 
References  
A. Anastasakos, R. Schwartz and H. Shu. 1995. 
?Duration Modeling in Large Vocabulary 
Speech Recognition?. In, ?Proceedings of IEEE 
International Conference on Acoustics, Speech, 
and Signal Processing?, pages 628-631. 
Carl D. Mitchell and Anand R. Setlur. 1999. 
Improved Spelling Recognition using a Tree-
based Fast Lexical Match. In ?Proceedings of 
IEEE International Conference on Acoustics, 
Speech, and Signal Processing?, volume2,  pages 
597-600. 
Chutima Pisarn and Thanaruk Theeramunkong. 
2003. Incorporating Tone Information to 
Improve Thai Continuous Speech Recognition. In 
?Proceedings of International Conference on 
Intelligent Technologies 2003?. 
Daniel Jurafsky and James H. Martin. 2000. 
Speech and Language Processing: An 
Introduction to Natural Language Processing, 
Computational Linguistics, and Speech 
Recognition. Prentice Hall. 
Frederico Rodrigues, Richardo Rodrigues and Ciro 
Martins. 1997. An Isolated Letter Recognizer for 
Proper Name Identification Over the Telephone. 
In ?Proceedings of 9th Portuguese Conference 
on Pattern Recognition (RECPAD?97)?, 
Coimbra. 
Josef G. Bauer and Jochen Junkawitsch. 1999. 
Accurate recognition of city names with spelling 
as a fall back strategy. In ?Proceedings of 
EUROSPEECH 1999?, pages 263-266. 
Martin Betz and Hermann Hild. 1995. Language 
Models for a Spelled Letter Recognizer. In 
?Proceedings of IEEE International Conference 
on Acoustics, Speech and Signal Processing?. 
Pages 856-859. 
Nattakorn Thubthong and Boonserm Kijsirikul. 
2001. Tone Recognition of Continuous Thai 
Speech under Tonal Assimilation and 
Declination Effects using Half-Tone Model. 
Journal of International of Uncertainty, 
Fuzziness and Knowledge-Based System, 
9(6):815-825. 
Ruben San-Segundo, J. Macias-Guarasa, J. 
Ferreiros, P. Martin and J.M. Pardo. 2001. 
Detection of Recognition Errors and Out of the 
Spelling Dictionary Names in a Spelled Name 
Recognizer for Spanish. In ?Proceedings of 
EUROSPEECH 2001?, Aalborg (Dinamarca). 
Ruben San-Segundo, Jose Colas, Ricardo de 
Cordoba and Jose M. Pardo 2002. Spanish 
Recognizer of Continuously Spelled Names 
Over the Telephone. Journal of Speech 
Communication, volume 38,  pp.287-303. 
Steve Young, Gunnar Evermann, Thomas Hain, 
Dan Kershaw, Gareth Moore, Julian Odell, Dave 
Ollason, Dan Povey, Valtcho Valtchev, and Phil 
Woodland. 2002. The HTK Book (for HTK 
Version 3.2.1). Cambride University Engineering 
Department. 
W.Verhelst and M.Roelands. 1993. An overlap-
add technique based on waveform similarit 
(wsola) for high quality time-scale modification 
of speech. In ?Proceedings of IEEE International 
Conference on Acoustics, Speech, and Signal 
Processing?, volume 2, pages 554-557, 
Minneapolis, Minnesota. 
 
Proceedings of the 2009 Workshop on Knowledge and Reasoning for Answering Questions, ACL-IJCNLP 2009, pages 11?14,
Suntec, Singapore, 6 August 2009.
c
?2009 ACL and AFNLP
QAST: Question Answering System for Thai Wikipedia
Wittawat Jitkrittum? Choochart Haruechaiyasak? Thanaruk Theeramunkong?
?School of Information, Computer and Communication Technology (ICT)
Sirindhorn International Institute of Technology (SIIT)
131 Moo 5 Tiwanont Rd., Bangkadi, Muang, Phathumthani, Thailand, 12000
wittawatj@gmail.com, thanaruk@siit.tu.ac.th
?Human Language Technology Laboratory (HLT)
National Electronics and Computer Technology Center (NECTEC)
Thailand Science Park, Klong Luang, Pathumthani 12120, Thailand
choochart.haruechaiyasak@nectec.or.th
Abstract
We propose an open-domain question an-
swering system using Thai Wikipedia as
the knowledge base. Two types of in-
formation are used for answering a ques-
tion: (1) structured information extracted
and stored in the form of Resource De-
scription Framework (RDF), and (2) un-
structured texts stored as a search index.
For the structured information, SPARQL
transformed query is applied to retrieve a
short answer from the RDF base. For the
unstructured information, keyword-based
query is used to retrieve the shortest text
span containing the questions?s key terms.
From the experimental results, the system
which integrates both approaches could
achieve an average MRR of 0.47 based on
215 test questions.
1 Introduction
Most keyword-based search engines available on-
line do not support the retrieval of precise infor-
mation. They only return a list of URLs, each re-
ferring to a web page, sorted by relevancy to the
user?s query. Users then have to manually scan
those documents for needed information. Due to
this limitation, many techniques for implement-
ing QA systems have been proposed in the past
decades.
From the literature reviews, previous and exist-
ing QA systems can be broadly categorized into
two types:
1. Knowledge Intensive: Knowledge intensive
systems focus on analyzing and understand-
ing the input questions. The system knows
exactly what to be answered, and also what
type the answer should be. The analysis
phase usually depends on an ontology or a
semantic lexicon like WordNet. The an-
swer is retrieved from a predefined organized
knowledge base. Natural Language Process-
ing (NLP) techniques are heavily used in a
knowledge intensive system.
2. Data Intensive: Data intensive systems,
which do not fully analyze the input ques-
tions, rely on the redundancy of huge amount
of data (Dumais et al, 2002). The idea is that
if we have a huge amount of data, a piece of
information is likely to be stated more than
once in different forms. As a result, the data-
intensive QA systems are not required to per-
form many complex NLP techniques.
In this paper, we propose an open-domain QA
system for Thai Wikipedia called QAST. The sys-
tem supports five types of close-ended questions:
person, organization, place, quantity, and date/-
time. Our system can be classified as a data in-
tensive type with an additional support of struc-
tured information. Structured information in Thai
Wikipedia is extracted and represented in the form
of RDF. We use SPARQL to retrieve specific in-
formation from the RDF base. If using SPARQL
cannot answer a given question, the system will re-
trieve answer candidates from the pre-constructed
search index using a technique based on Minimal
Span Weighting (Monz, 2003).
2 System Architecture
Figure 1 shows the system architecture of QAST
which consists of three main sub-systems: Data
Representation , Question Processor , and Answer
11
Figure 1: The system architecture of QAST
Processor .
2.1 Data Representation
The Data Representation part is a storage for all
information contained in Thai Wikipedia. Two
modules constitute this sub-system.
RDF Base: In QAST, RDF triples are generated
from Wikipedia?s infoboxes following similar ap-
proaches described in the works of Isbell and But-
ler (2007) and Auer and Lehmann (2007). To gen-
erate RDF triples from an infobox, we would have
the article title as the subject. The predicates are
the keys in the first column. The objects are the
values in the second column. Altogether, the num-
ber of generated triples corresponds to the number
of rows in the infobox.
In addition to the infoboxes, we also store syn-
onyms in the form of RDF triples. The synonyms
are extracted from redirect pages in Wikipedia.
For example, a request for the Wikipedia article
titled ?Car? will result in another article titled ?Au-
tomobile? to be shown up. The former page usu-
ally has no content and only acts as a pointer to
another page which contains the full content. The
relationship of these two pages implies that ?Car?
and ?Automobile? are synonymous. Synonyms
are useful in retrieving the same piece of informa-
tion with different texual expressions.
Search Index: QAST stores the textual content
as a search index. We used the well-known IR li-
brary, Lucene
1
, for our search backend. We in-
dexed 41,512 articles (as of February 5, 2009)
from a Thai Wikipedia dump with full term posi-
tions. Firstly, all template constructs and the Wiki-
Text markups are removed, leaving with only the
plain texts. A dictionary-based longest-matching
word segmentation is then performed to tokenize
the plain texts into series of terms. Finally, the
resulted list of non-stopwords are passed to the
Lucene indexing engine. The dictionary used for
word segmentation is a combination of word list
from the LEXiTRON
2
and all article titles from
Thai Wikipedia. In total, there are 81,345 words
in the dictionary.
2.2 Question Processor
Question processor sub-system consists of four
modules as follows.
1. Question Normalizer ? This first module is
to change the way the question is formed into
a normal form to ease the processing at lat-
ter stages. This includes correcting mistyped
words or unusual spelling such as f33t for
feet.
2. Word Segmenter ? This module performs
tokenizing on the normalized question to ob-
tain a list of non-stopwords.
3. Question Analyzer ? The question ana-
lyzer determines the expected type of answer
(i.e., quantity, person, organization, location,
date/time and unknown) and constructs an
appropriate query. Normally, a SPARQL
query is generated and used to retrieve a can-
didate answer from the RDF base. When the
SPARQL fails to find an answer, the system
will switch to the index search. In that case,
the module also defines a set of hint terms to
help in locating candidate answers.
4. Searcher ? This module executes the query
and retrieves candidate answers from the data
representation part.
To generate a SPARQL query, the input ques-
tion is compared against a set of predefined regu-
lar expression patterns. Currently, the system has
two types of patterns: pattern for definitional ques-
tions, and pattern for questions asking for a prop-
1
Apache Lucene, http://lucene.apache.org
2
LEXiTRON, http://lexitron.nectec.or.th
12
erty of an entity. The pattern for definitional ques-
tion is of the form a-rai-kue-X ?What is X ?? or
X-kue-a-rai ?X is what ??. After X is determined
from a user?s question, the first paragraph of the
article titled X is retrieved and directly returned to
the user. Since the first paragraph in any article is
usually the summary, it is appropriate to use the
first paragraph to answer a definitional question.
Questions asking for a property of an entity are
of the form a-rai-kue-P-kong-X ?What is P of X ??
e.g., ?When was SIIT established ?? which can be
answered by looking for the right information in
the RDF base. A simplified SPARQL query used
to retrieve an answer for this type of question is as
follows.

SELECT ? o
WHERE {
? tempPage h a s I n f o b o x ? tempBox .
? tempPage r d f s : l a b e l ?X? .
? tempBox ?P ? o .
}


 
The query matches an object of a RDF triple with
the predicate P (e.g., ?date of establishment?), pro-
vided that the triple is generated from an infobox
titled X (e.g.,?SIIT?) . The object of the year 1992
is then correctly returned as the answer.
When SPARQL fails, i.e., the question does
not match any known pattern or the answer does
not exist in the RDF base, the system switches to
the index search which performs the following the
steps.
1. Word Segmenter tokenizes the question into
a list of keywords q.
2. Question analyzer analyzes q, generates a ba-
sic Lucene? TermQuery, and defines a set of
hint terms H .
3. Retrieve the most relevant c documents using
Lucene?s default search scoring function
3
.
Denote D as the set of retrieved documents.
4. For each document d in D where d =
{t
1
, t
2
, . . . , t
|d|
} (t is a term),
(a) Find in d the start term index
mmsStart and end term index
mmsEnd of the shortest term span
containing all terms in q (Monz, 2003).
(b) spanLength ? 1 + mmsEnd ?
mmsStart
(c) If spanLength > 30, skip current d.
Go to the next document.
3
http://lucene.apache.org/java/2_3_0/
scoring.html
(d) Find minimal span weighting
score msw (Monz, 2003). If
|q ? d| = 1 then, msw =
RSV
n
(q, d). Otherwise, msw =
0.4 ?RSV
n
(q, d)+0.6 ?(
|q?d|
spanLength
)
1/8
?
(
|q?d|
|q|
) where RSV
n
(q, d) =
lucene(q, d)/max
d
lucene(q, d)
(e) mmsStart? max(mmsStart?s, 1)
(f) mmsEnd? min(mmsEnd + s, |d|)
(g) Find the weighting for hint terms hw
(0 ? hw ? 1).
(h) Calculate the span score
sp = msw ? (1 + hw)
(i) Add the text span to the span set P (Sort
P by sp in descending order).
5. Return the top k spans in P as answers.
In the actual implementation, we set c equal to
500 so that only the top 500 documents are con-
sidered. Although retrieving more texts from the
corpus would likely increase the chance of find-
ing the answer (Moldovan et al, 2002), our trial-
and-error showed that 500 documents seem to be
a good trade-off between speed and content cov-
erage. To look for an occurrence of hint terms,
each span is stretched backward and forward for
10 terms (i.e., s = 10). Finally, we set k equal to
5 to return only the top five spans as the answers.
2.3 Answer Processor
This sub-system contains two modules: Answer
Ranker and Answer Generator.
Answer Ranker concerns with how to rank the
retrieved answer candidates. In the case where
SPARQL query is used, this module is not re-
quired since most of the time there will be only
one result returned.
In the case when the search index is used, all
candidate answers are sorted by the heuristic span
score (i.e., sp = msw ? (1 + hw)). The func-
tion mostly relies on regular expressions defining
expected answer patterns. If a span has an occur-
rence of one of the defined patterns (i.e., hw > 0),
it is directly proportional to the suitability of the
occurrence with respect to the question, length and
rareness of the pattern occurrence. For example,
the hint terms of questions asking for a person
would be personal titles such as Ms. and Dr.
As for the final step, the Answer Generator
module formats the top five candidate answers into
an HTML table and returns the results to the user.
13
Question Type Index & RDF Index
Person 0.47 0.37
Organization 0.56 0.46
Place/Location 0.43 0.36
Quantity 0.51 0.44
Date/Time 0.39 0.34
Average MRR 0.47 0.39
Table 1: QAST?s performance comparison be-
tween (1) using both index and RDF and (2) using
only the index.
3 Evaluation Metric
To evaluate the system, 215 test questions (43
questions for each question type) and their cor-
rect answers were constructed based on the con-
tents of random articles in Thai Wikipedia. Mean
Reciprocal Rank (MRR), the official measurement
used for QA systems in TREC (Voorhees and Tice,
2000), is used as the performance measurement.
To evaluate the system, a question is said to be
correctly answered only when at least one of the
produced five ranked candidates contained the true
answer with the right context. Out-of-context can-
didate phrases which happen to contain the true
answers are not counted. If there is no correct an-
swer in any candidate, the score for that question
is equal to zero.
4 Experimental Results and Discussion
Table 1 shows a comparison of the MRR values
when using both index and RDF, and using only
the index. The approach of using only the index,
the overall MRR is equal to 0.39 which is fairly
high with respect to the answer retrieval method-
ology. The index search approach simply relies on
the fact that if the question keywords in a ranked
candidate document occur close together and at
least one occurrence of expected answer pattern
exists, then there is a high chance that the term
span contains an answer.
The MRR significantly increases to 0.47 (20.5%
improvement) when RDF (structured information)
is used together with the index. A thorough analy-
sis showed that out of 215 questions, 21 questions
triggered the RDF base. Among these, 18 ques-
tions were correctly answered. Therefore, using
the additional structured information helps answer
the definitional and factoid questions. We expect a
higher improvement when more structured infor-
mation is incorporated into the system.
5 Conclusions and Future Works
We proposed an open-domain QA system called
QAST. The system uses Thai Wikipedia as the cor-
pus and does not rely on any complex NLP tech-
nique in retrieving an answer.
As for future works, some possiblities for im-
proving the current QAST are as follows.
? An information extraction module may be
added to extract and generate RDF triples
from unstructured text.
? Infoboxes, wikipedia categories and internal
article links may be further explored to con-
struct an ontology which will allow an auto-
matic type inference of entities.
? More question patterns and the correspond-
ing SPARQL queries can be added so that
SPARQL is used more often.
Acknowledgement
The financial support from Young Scientist and
Technologist Programme, NSTDA (YSTP : SP-
51-NT-15) is gratefully acknowledged.
References
Soren Auer and Jens Lehmann. 2007. What Have
Innsbruck and Leipzig in Common? Extracting Se-
mantics from Wiki Content. In Proc. of the 4
th
Eu-
ropean conference on The Semantic Web: Research
and Applications, pp. 503-517.
Susan Dumais, Michele Banko, Eric Brill, Jimmy Lin,
and Andrew Ng. 2002. Web Question Answering:
Is More Always Better?. In Proc. of the 25th ACM
SIGIR, pp. 291-298.
Jonathan Isbell and Mark H. Butler. 2007. Extracting
and Re-using Structured Data from Wikis. Technical
Report HPL-2007-182, Hewlett-Packard.
Dan Moldovan, Marius Pasca, Sanda Harabagiu, and
Mihai Surdeanu . 2002. Performance Issues and Er-
ror Analysis in an Open-Domain Question Answer-
ing System. Proc. of the 40
th
ACL, pp. 33-40.
Christof Monz. 2003. From Document Retrieval to
Question Answering. Ph.D. Thesis. University of
Amsterdam.
Ellen M. Voorhees and Dawn Tice. 2000. Building a
Question Answering Test Collection. In 23
rd
ACM
SIGIR, pp. 200-207.
14
Multi-Dimensional Text Classification
Thanaruk THEERAMUNKONG
IT Program, SIIT, Thammasat University
P.O. Box 22 Thammasat Rangsit Post Office,
Pathumthani, Thailand, 12121
ping@siit.tu.ac.th
Verayuth LERTNATTEE
IT Program, SIIT, Thammasat University
P.O. Box 22 Thammasat Rangsit Post Office,
Pathumthani, Thailand, 12121
verayuth@siit.tu.ac.th
Abstract
This paper proposes a multi-dimensional
framework for classifying text documents.
In this framework, the concept of multi-
dimensional category model is introduced
for representing classes. In contrast with
traditional flat and hierarchical category
models, the multi-dimensional category
model classifies each text document in a
collection using multiple predefined sets of
categories, where each set corresponds to a
dimension. Since a multi-dimensional model
can be converted to flat and hierarchical
models, three classification strategies are
possible, i.e., classifying directly based on
the multi-dimensional model and classifying
with the equivalent flat or hierarchical
models. The efficiency of these three
classifications is investigated on two data
sets. Using k-NN, na?ve Bayes and centroid-
based classifiers, the experimental results
show that the multi-dimensional-based and
hierarchical-based classification performs
better than the flat-based classifications.
1 Introduction
In the past, most of previous works on text
classification focus on classifying text
documents into a set of flat categories. The task
is to classify documents into a predefined set of
categories (or classes) (Lewis and Ringuetee,
1994; Eui-Hong and Karypis, 2000) where there
are no structural relationships among these
categories. Many existing databases are
organized in this type of flat structure, such as
Reuters newswire, OHSUMED and TREC. To
improve classification accuracy, a variety of
learning techniques are developed, including
regression models (Yang and Chute, 1992),
nearest neighbour classification (Yang and Liu,
1999), Bayesian approaches (Lewis and
Ringuetee, 1994; McCallum et al, 1998),
decision trees (Lewis and Ringuetee 1994),
neural networks (Wiener et al,1995) and
support vector machines (Dumais and Chen,
2000). However, it is very difficult to browse or
search documents in flat categories when there
are a large number of categories. As a more
efficient method, one possible natural extension
to flat categories is to arrange documents in
topic hierarchy instead of a simple flat structure.
When people organize extensive data sets into
fine-grained classes, topic hierarchy is often
employed to make the large collection of classes
(categories) more manageable. This structure is
known as category hierarchy. Many popular search
engines and text databases apply this structure, such
as Yahoo, Google Directory, Netscape search and
MEDLINE. There are many recent works
attempting to automate text classification based on
this category hierarchy (McCallum et al, 1998;
Chuang W. T. et al, 2000). However, with a large
number of classes or a large hierarchy, the problem
of sparse training data per class at the lower levels in
the hierarchy raises and results in decreasing
classification accuracy of lower classes. As another
problem, the traditional category hierarchy may be
too rigid for us to construct since there exist several
possible category hierarchies for a data set.
To cope with these problems, this paper
proposes a new framework, called multi-
dimensional framework, for text classification.
The framework allows multiple pre-defined sets
of categories (viewed as multiple dimensions)
instead of a single set of categories like flat
categories. While each set of classes with some
training examples (documents) attached to each
class, represents a criterion to classify a new text
document based on such examples, multiple sets
of classes enable several criteria. Documents are
classified based on these multiple criteria
(dimensions) and assigned a class per criterion
(dimension). Two merits in the multi-
dimensional approach are (1) the support of
multiple viewpoints of classification, (2) a
solution to data sparseness problem. The
efficiency of multi-dimensional classification is
investigated using three classifiers: k-NN, na?ve
Bayes and centroid-based methods.
2 Multi-Dimensional Category Model
for Text Classification
Category is a powerful tool to manage a large
number of text documents. By grouping text
documents into a set of categories, it is possible
for us to efficiently keep or search for
information we need. At this point, the structure
of categories, called category model, becomes
one of the most important factors that determine
the efficiency of organizing text documents. In
the past, two traditional category models, called
flat and hierarchical category models, were
applied in organizing text documents. However,
these models have a number of disadvantages as
follows. For the flat category model, when the
number of categories becomes larger, it faces
with difficulty of browsing or searching the
categories. For the hierarchical category model,
constructing a good hierarchy is a complicated
task. In many cases, it is not intuitive to
determine the upward/downward relations
among categories. There are several possible
hierarchies for the same document set. Since
hierarchies in the hierarchical category model
are static, browsing and searching documents
along the hierarchy are always done in a fix
order, from the root to a leaf node. Therefore,
the searching flexibility is lost.
As an alternative to flat and hierarchical
category models, the multi-dimensional category
is introduced. So far the concept of multi-
dimensional data model has been very well
known in the field of database technology. The
model was shown to be powerful in modeling a
data warehouse or OLAP to allow users to store,
view and utilize relational data efficiently
(Jiawei and Micheline, 2001). This section
describes a way to apply multi-dimensional data
model to text classification, so called multi-
dimensional category. The proposed model is an
extension of flat category model, where
documents are not classified into a single set of
categories, instead they are classified into
multiple sets. Each set of categories can be
viewed as a dimension in the sense that
documents may be classified into different kinds
of categories. For example in Figure 1, a set of
news issues (documents) can be classified into
three dimensions, say TOPIC, ZONE and
TOPIC, each including {sports, economics,
politics, social, entertainment, science and
technology}, {domestic, intra-continental, inter-
continental} and {good news, bad news, neutral
news}, respectively. A news issue in a Thailand
newspaper titled ?Airplanes attacked World
Trader Center? can be classified into ?social
news?, ?inter-continental?, ?bad news? in the
first, second and third dimensions, respectively.
sports economics
politics social
entertainment S & T
TOPIC dimension
intra-continental
ZONE dimension
inter-continental
domestic
bad news
MOOD dimension
neutral news
good news
Figure 1. Three-dimension category model for
classifying news documents
sports
domestic
bad news
sports
domestic
good news
sports
domestic
neural news
S&T
inter-con
bad news
S&T
inter-con
good news
S&T
inter-con
neural news
Figure 2. Flat category model for the model in Figure 1
Comparing with flat and/or hierarchical
category models, the multi-dimensional model
has the following merits. First, it is more natural
than flat model in the sense that a document
could be classified basing on not a single
criterion (one dimension) but multiple criteria
(multiple dimensions). Secondly, in contrast
with hierarchical model, it is possible for us to
browse or search documents flexibly without the
order constraint defined in the structure. Lastly,
the multi-dimensional category model can be
basically transformed to and represented by flat
category or hierarchical category models, even
the converses are not always intuitive.
In the previous example, the corresponding
flat and hierarchical models for the multi-
dimensional model in Figure 1 are illustrated
Figure 2 and 3, respectively. The total number of
derived flat categories equals to the product of
the number of categories in each dimension, i.e.,
54(=6x3x3). In the derived hierarchical model,
the number of leaf categories is also equivalent
to 54 but there exist 24 (=6+6x3) internal
categories. Note that the figure shows only one
possible hierarchy where the dimensions ordered
by TOPIC, ZONE and MOOD. However, there
are totally 6 (=3!) possible hierarchies for the
model in Figure 1.
From a viewpoint of category representation,
the fact that the derived flat model enumerates
all combinations among categories, makes the
representation of a class be more precise than
the class in multi-dimensional model. However,
from the viewpoint of relationship constraints in
these models, the derived flat category model
ignores the relationship among categories while
the derived hierarchical model explicitly
declares such relationship in a rigid manner, and
the multi-dimensional model is a compromise
between these two previous models. These
different aspects affect classification efficiency
as shown in the next section.
3 Multi-Dimensional Classification
Described in the previous section, a multi-
dimensional category model can be transformed
into flat and hierarchical category models. As a
result, there are three different classification
strategies: flat-based, hierarchical-based and
multi-dimensional-based methods.
3.1 Flat-based classification
The na?ve method to classify documents according
to a multi-dimensional model is flat-based
classification. After transforming a multi-
dimensional category model to flat category model,
traditional flat classification is applied directly to the
derived flat categories. The granularity of the
derived flat categories is finer than the original
multi-dimensional categories since all combinations
of classes in the dimensions are enumerated. This
fact implies that a flat category represents the class
more precisely than a multi-dimensional category
and then one can expect high classification
accuracy. However, on the other hand, the number
of training data (documents) per class is reduced. As
a consequence, flat classification may face with the
sparseness problem of training data. This may cause
a classifier harder to classify and then reduce
classification accuracy. In the view of
computational cost, a test document has to be
compare to all enumerated classes, resulting in high
computation.
3.2 Hierarchical-based classification
The second method is to transform a multi-
dimensional category model to a hierarchical
category model and then apply the standard
hierarchical classification on the derived
hierarchical model. There are several possible
models generated from a multi-dimensional
model due to the order of dimensions as
described in section 2. The classification is held
along the hierarchy from the root to a leaf. The
decision of the class, which a document belongs
Sports
S&T
good
bad
neutral
domes.
intra.
inter.
good
bad
neutral
domes.
intra.
inter.
Figure 3. Hierarchical category model for the
model in Figure 1
to, is made in step by step. The classifications of
different levels occupy different granularities of
training data. Nodes at the level closed to the
root will have coarser granularity. This makes
such nodes represent classes less imprecisely but
there are more training data (documents) for
these nodes. On the other hand, nodes near
leaves will have finer granularity and then have
more precise representation but have less
training data. The classification accuracy varied
with the order of dimensions in the hierarchy.
3.3 Multi-dimensional-based  classification
It is possible to directly classify a document
using the multi-dimensional category model.
The class of the document for each dimension is
determined independently. We called this multi-
dimensional-based classification. Compared
with flat-based classification, the granularity of
multi-dimensional classification is coarser. For
each dimension, it classifies a document based
on categories in that dimension instead of
classifying it into the set of finer categories as
done in flat classification. Although the multi-
dimensional category is not precisely represent
any finer categories, the number of training data
(documents) per class is relatively high. As a
consequence, multi-dimensional classification
gains high accuracy for each dimension and
results in high accuracy for the overall
classification accuracy when there are a small
number of training data. It also performs faster
than flat-based classification since there are
fewer classes needed to be compared.
4 Implementation
To investigate efficiency of text classification on
the multidimensional category model, three
well-known classification algorithms called k-
nearest neighbors (k-NN), na?ve Bayesian (NB)
and centroid-based (CB) approaches are applied.
4.1 k-NN Classifier
As a similarity-based method, the k-nearest
neighbor classifier (k-NN) is applied to our text
classification. First, the classifier calculates k
most similar documents (i.e., k nearest
neighbors) of the test document being classified.
The similarity of this document to a class is
computed by summing up the similarities of
documents among the k documents, whose
classes are equivalent to such class. The test
document is assigned the class that has the
highest similarity to the document. Two
parameters involved are the definition of
similarity and the number k. While the standard
similarity is defined as tf?idf, a variant
(0.5+0.5tf/tfmax)?idf that performed better in our
preliminary experiments, is applied in this work.
The parameter k is determined by experiments as
shown in the next section.
4.2 Na?ve Bayes Classifier
The standard na?ve Bayesian (NB) is applied as
a statistical approach to our text classification in
this work. For each document, the classifier first
calculates the posterior probability P(ci|d) of
class ci that the document belongs to different
classes and assigns it to the class with the
highest posterior probability. Basically, a
document d can be represented by a bag of
words {w1, w2, ?, wn} in that document (i.e., a
vector of occurrence frequencies of words in the
document). NB assumes that the effect of a
word?s occurrence on a given class is
independent of other words? occurrence. With
this assumption, a NB classifier finds the most
probable class ci ? C, called a maximum a
posteriori (MAP) cMAP for the document, where
C={c1, c2, ?, ck}  is a set of predefined classes.
(1)
4.3 Centroid-based Classifier
Applied in our implementation is a variant of
centroid-based classification (CB) with different
weight methods from the standard weighting tf-
idf. A centroid-based classifier (CB) is a
modified version of k-NN classifier. Instead of
comparing the test document with all training
documents, CB calculates a centroid (a vector)
for all training documents in each class and
compares the test document with these centroids
to find the most probable (similar) class. A
simple centroid-based classifier represents a
document with a vector each dimension of
which expresses a term in the document with a
weight of tf?idf. The resultant vector is
??
?
=
n
j iijc
n
iin
c
MAP
cPcwP
wwwP
cPcwwwPc
i
i
1
21
21
)()|(maxarg
}),...,,({
)()|},...,,({maxarg
normalized with the document length to a unit-
length vector.  A different version of a centroid
vector is so-called a prototype vector (Chuang,
W. T. et al, 2000). Instead of normalizing each
vector in the class before calculating a centroid,
the prototype vector is calculated by normalizing
the summation of all vectors of documents in the
class. Both methods utilizing centroid-based and
prototype vectors obtained high classification
accuracy with small time complexity. In our
implementation, we use a variant of the
prototype vector that does not apply the standard
tf-idf but use either of the following weighting
formulas. These weighting formulas, we called
CB1 and CB2, were empirically proved to work
well in (Theeramunkong and Lertnattee, 2001).
(2)
icsd stands for inter-class standard deviation,
tfrms is the root mean square of document term
frequency in a class, and sd means standard
deviation. After this weighting, a prototype
vector is constructed for each class. Due to the
length limitation of the paper, we ignore the
detail of this formula but the full description can
be found in (Theeramunkong and Lertnattee, 2001).
5 Experimental Results
Two data sets, WebKB and Drug information
collection (DI) are used for evaluating our multi-
dimensional model. These two data sets can be
viewed as a two-dimensional category model as
follows. Composed of 8,145 web pages, the
WebKB data set is a collection of web pages of
computer science departments in four
universities with some additional pages from
other universities. The original collection is
divided into seven classes (1st dimension): student,
faculty, staff, course, project, department and
others. Focusing on each class, five subclasses
(2nd dimension) are defined according to the
university a web page belongs to: Cornell,
Texas, Washington, Wisconsin and
miscellaneous. In our experiment, we use the
four most popular classes: student, faculty,
course and project. This includes 4,199 web
pages. Drug information, the second data set, is
a collection of web documents that have been
collected from www.rxlist.com. This collection
is composed of 4,480 web pages providing
information about widely used drugs in seven
topics (1st dimension): adverse drug reaction,
clinical pharmacology, description, indications,
overdose, patient information, and warning.
There exists exactly one page for each drug in
each class, i.e., the number of recorded drugs is
640 (=4480/7). Moreover We manually grouped
the drugs according to major pharmacological
actions, resulting in five classes (2nd dimension):
chemotherapy (Chem), neuro-muscular system
(NMS), cardiovascular & hematopoeitic (CVS),
hormone (Horm) and respiratory system (Resp).
The multi-dimensional classification is tested
using four algorithms: k-NN, NB and two
centroid-based classifiers (CB1 and CB2). In the
k-NN, the parameter k is set to 20 for WebKB,
and set to 35 for DI. For the centroid-based
method, the applied weighting systems are those
shown in Section 4.3. All experiments were
performed with 10-fold cross validation. That is,
90% of documents are kept as a training set
while the rest 10% are used for testing. The
performance was measured by classification
accuracy defined as the ratio between the
number of documents assigned with correct
classes and the total number of test documents.
As a preprocess, some stop words (e.g., a, an,
the) and all tags (e.g., <B>, </HTML>) were
omitted from documents to eliminate the affect
of these common words and typographic words.
In the rest, first the results on flat and
hierarchical classification on the data sets are
shown, followed by that of multi-dimensional
classification. Finally overall discussion is given.
5.1 Flat-based Classification
In this experiment, test documents are classified
into the most specified classes say D12, which
are the combinations of two dimensions, D1 and
D2. Therefore, the number of classes equals to
the product of the number of classes in each
dimension. That is 20 (=5?4) classes for
WebKB and 35 (=7?5) classes for DI. A test
document was assigned the class that gained the
highest score from the classifier applied. Table 1
displays the classification accuracy of flat
classification on WebKB and DI data sets. Here,
two measures, two-dimension and single-
dimension accuracy, are taken into account.    
or(CB1) (CB2)
sdtf
icsdidftf
rms ?
??
sdtf
idftf
rms?
?
WebKB DI
D12D1 D12D2 D12 D12D1 D12D2 D12
k-NN 68.02 84.69 57.32 79.46 66.14 60.04
NB 80.23 78.76 62.66 93.75 73.97 69.61
CB1 77.54 91.52 71.59 96.14 72.08 69.42
CB2 71.52 89.12 63.42 89.49 80.58 73.28
Table 1.  Flat classification accuracy (%)
In the table, D12 shows the two-dimension
accuracy where the test document is completely
assigned to the correct class. D12D1 and D12
D2, the single-dimension accuracy, mean the
accuracy of the first and second dimensions
where the classes in D1 and D2 dimensions are
generated from the result class D12, respectively.
The result shows that the centroid-based
classifiers perform better than k-NN and NB.
CB1 and CB2 works well on WebKB and DI,
respectively. Even low two-dimension accuracy,
high single-dimension accuracy is obtained.
5.2 Hierarchical-based Classification
Since there are two dimensions in the data
set, hierarchical-based classification can be held
in two different ways according to the
classifying order. In the first version, documents
are classified based on the first dimension to
determine the class to which those documents
belong. They are further classified again
according to the second dimension using the
model of that class. The other version classifies
documents based on the second dimension first
and then the first dimension. The results are
shown in Table 2. In the tables, D1, D2 and D*12
mean the accuracy of the first dimension, the
second dimension and the two-dimension
accuracy, respectively. D1+D*12=>D2 expresses
the accuracy of the second dimension that used
the result from the first dimension during
classifying the second dimension. D2+D*12=>D1
represents the accuracy of the second dimension
that used the result from the first dimension
during classifying the first dimension.
From the results, we found that the centroid-
based classifiers also perform better than k-NN
and NB, and CB1 works well on WebKB while
CB2 gains the highest accuracy on DI. In almost
cases, the hierarchical-based classification
performs better than the flat-based classification.
Moreover, an interesting observation is that
classifying on the worse dimension before the
better one yields a better result.
WebKB DI
D1 D1+D*12=>D2 D*12 D1 D1+D*12=>D2 D*12
k-NN 69.85 84.31 58.61 80.20 73.17 60.20
NB 80.54 78.85 62.42 95.00 73.35 70.38
CB1 80.42 91.28 73.90 96.23 73.44 69.26
CB2 76.04 88.59 66.87 91.43 80.09 74.24
WebKB DI
D2+D*12=>D1 D2 D*12 D2+D*12=>D1 D2 D*12
k-NN 67.42 83.34 56.04 79.29 76.36 61.25
NB 79.92 87.45 69.35 93.08 83.75 78.33
CB1 77.99 90.02 70.18 95.60 73.44 70.36
CB2 71.44 92.36 65.78 88.33 84.87 76.05
Table 2. Hierarchical classification accuracy(%)
(upper: D1 before D2 , lower: D2 before D1)
5.3 Multi-dimensional Classification
In the last experiment, multi-dimensional
classification is investigated. Documents are
classified twice based on two dimensions
independently. The results of the first and
second dimensions are combined to be the
suggested class for a test document. The
classification accuracy of multi-dimensional
classification is shown in Table 3.
WebKB DI
D1 D2 D1+D2D1+2 D1 D2 D1+D2D1+2
k-NN 69.85 83.34 57.37 80.20 76.36 61.85
NB 80.54 87.45 69.66 95.00 83.75 79.51
CBC1 80.42 90.02 72.52 96.23 73.44 70.05
CBC2 76.04 92.36 69.90 91.43 84.87 77.99
Table 3. Multi-dimensional.classification accuracy (%)
In the tables, D1 and D2 mean the accuracy of
the first and second dimensions, respectively.
D1+D2D1+2  is the two-dimension accuracy of
the class which is the combination of classes
suggested in the first dimension and the second
dimension. From the results, we found that CB1
performs well on WebKB but NB gains the
highest accuracy on DI. The multi-dimensional
classification outperforms flat classification in
most cases but sometime the hierarchical-based
classification performs well.
5.4 Overall Evaluation and Discussion
Two accuracy criteria are (1) all dimensions are
correct or (2) some dimensions are correct. The
classification accuracy based on the first
criterion is shown in all previous tables as the
two-dimension accuracy. As the second
criterion, the classification accuracy can be
evaluated when some dimensions are correct.
The result is summarized in Table 4. The multi-
dimensional classification outperforms other two
methods for WebKB but the hierarchical-based
classification sometimes works better for DI.
WebKB DI
F H1 H2 M F H1 H2 M
k-NN 72.80 77.08 75.38 78.28 76.36 76.69 77.83 76.59
NB 83.86 79.70 83.69 89.38 79.50 84.18 88.42 84.00
CB1 84.11 85.85 84.01 84.84 84.53 84.84 84.52 85.22
CB2 85.04 82.32 81.90 88.15 80.32 85.76 86.60 84.20
Table 4. Classification accuracy (%) when some
dimensions are correct.
From this result, some observations can be
given as follows. There are two tradeoff factors
that affect classification accuracy of multi-
dimensional category model: training set size
and the granularity of classes. The flat-based
classification in the multi-dimensional model
deals with the finest granularity of classes
because all combinations of classes from
predefined dimensions are combined to form a
large set of classes. Although this precise
representation of classes may increase the
accuracy, the flat-based classification suffers
with sparseness problem where the number of
training data per class is reduced.  The accuracy is
low when the training set is small. The multi-
dimensional-based classification copes with the
coarsest granularity of the classes. Therefore the
number of training document per class is larger than
flat-based classification approach but the
representation of classes is not exact. However, It
works well when we have a relatively small training
set. The hierarchical-based classification occupies a
medium granularity of classes. However, the size of
training set is smaller than multi-dimensional
approach at the low level of the hierarchy. It works
well when the training set is medium.
6 Conclusion
In this paper, a multi-dimensional framework on
text classification was proposed. The framework
applies a multi-dimensional category for
representing classes, in contrast with traditional
flat and hierarchical category models.
Classifying text documents based on a multi-
dimensional category model can be performed
using the multi-dimensional-based classification
or the flat and hierarchical classifications. By
experiments on two data sets and three
algorithms, k-NN, na?ve Bayes and centroid-
based methods, the results show that the multi-
dimensional-based and hierarchical-based
classifications outperform flat-based one.
References
Chuang W. T. et al  (2000), A Fast Algorithm for
Hierarchical Text Classification. Data
Warehousing and Knowledge Discovery,  409-418.
Dumais S. T. and Chen H. (2000) Hierarchical
Classification of Web Content, In Proc. of the 23rd
International ACM SIGIR, pp. 256-263.
Eui-Hong H. and Karypis G. (2000) Centroid-Based
Document Classification: Analysis & Experimental
Results.  In Proc. of European Conference on
PKDD, pp. 424-431.
Jiawei H. and Micheline K. (2001) Data Mining: Concepts
and Techniques. Morgan Kaufmann publishers.
Lewis D. D. and Ringuette M. (1994) A Comparison
of Two Learning Algorithms for Text
Categorization. In Proc. of Third Annual
Symposium on Document Analysis and
Information Retrieval, pages 81-93.
McCallum A. et al (1998) Improving Text
Classification by Shrinkage in a Hierarchy of
Classes, In Proc. of the 15th International
Conference on Machine Learning, pp. 359-367.
Theeramunkong T. and Lertnattee V. (2001)  Improving
Centroid-Based Text Classification Using Term-
Distribution-Based Weighting System and
Clustering.  In Proc. of International Symposium
on Communications and Information Technology
(ISCIT 2001), pp. 33-36.
Wiener E. D. et al (1995) A Neural Network Approach to
Topic Spotting. In Proc. of SDAIR-95, the 4th Annual
Symposium on Document Analysis and Information
Retrieval. pp. 317-332.
Yang Y. and Chute C. G. (1992) A Linear Least
Square Fit Mapping Method for Information
Retrieval from Natural Language Texts.  In Proc.
of the 14th International Conference on
Computational Linguistics, pp. 358-362.
Yang, Y. and Liu X. (1999) A Re-examination of Text
Categorization Methods. In Proc. of the 22nd ACM
SIGIR Conference, 42-49.
Non-Dictionary-Based Thai Word Segmentation Using
Decision Trees
Thanaruk Theeramunkong1
Information Technology Program
Sirindhorn International Institute of Technology
Thammasat University, Pathumthani 12121, Thailand
+66-2-986-9103(-8) Ext. 2004
ping@siit.tu.ac.th
Sasiporn Usanavasin
Information Technology Program
Sinrindhorn International Institute of Technology
Thammasat University, Pathumthani 12121, Thailand
+66-2986-9103(-8) Ext. 2002
sasiporn@kind.siit.tu.ac.th
ABSTRACT
For languages without word boundary delimiters, dictionaries are
needed for segmenting running texts. This figure makes
segmentation accuracy depend significantly on the quality of the
dictionary used for analysis. If the dictionary is not sufficiently
good, it will lead to a great number of unknown or unrecognized
words. These unrecognized words certainly reduce segmentation
accuracy. To solve such problem, we propose a method based on
decision tree models. Without use of a dictionary, specific
information, called syntactic attribute, is applied to identify the
structure of Thai words. C4.5 is used as a tool for this purpose.
Using a Thai corpus, experiment results show that our method
outperforms some well-known dictionary-dependent techniques,
maximum and longest matching methods, in case of no dictionary.
Keywords
Decision trees, Word segmentation without a dictionary
1. INTRODUCTION
Word segmentation is a crucial topic in analysis of languages
without word boundary markers. Many researchers have been
trying to develop and implement in order to gain higher accuracy.
Unlike in English, word segmentation in Thai, as well as in many
other Asian languages, is more complex because the language
does not have any explicit word boundary delimiters, such as a
space, to separate between each word. It is even more complicated
to precisely segment and identify the word boundary in Thai
language because there are several levels and several roles in Thai
characters that may lead to ambiguity in segmenting the words. In
the past, most researchers had implemented Thai word
segmentation systems based on using a dictionary ([2], [3], [4],
[6], [7]). When using a dictionary, word segmentation has to cope
with an unknown word problem. Up to present, it is clear that
most researches on Thai word segmentation with a dictionary
suffer from this problem and then introduce some particular
process to handle such problem. In our preliminary experiment,
we extracted words from a pre-segmented corpus to form a
dictionary, randomly deleted some words from the dictionary and
used the modified dictionary in segmentation process based two
well-known techniques; Maximum and Longest Matching
methods. The result is shown in Figure 1. The percentages of
accuracy with different percentages of unknown words are
explored. We found out that in case of no unknown words, the
accuracy is around 97% in both maximum matching and longest
matching but the accuracy drops to 54% and 48% respectively, in
case that 50% of words are unknown words. As the percentage of
unknown words rises, the percentage of accuracy drops
continuously. This result reflects seriousness of unknown word
problem in word segmentation. 1
Accuracy (%)Unknown
word (%) Maximum Matching Longest Matching
0 97.24 97.03
5 95.92 95.63
10 93.12 92.23
15 89.99 87.97
20 86.21 82.60
25 78.40 74.41
30 68.07 64.52
35 69.23 62.21
40 61.53 57.21
45 57.33 54.84
50 54.01 48.67
Figure 1. The accuracy of two dictionary-based systems vs.
percentage of unknown words
In this paper, to take care of both known and unknown words, we
propose the implementation of a non-dictionary-based system
with the knowledge based on the decision tree model ([5]). This
model attempts to identify word boundaries of a Thai text. To do
                                                                
1 National Electronics and Computer Technology Center
(NECTEC), 539/2 Sriyudhya Rd., Rajthevi Bangkok 10400,
Thailand
this, the specific information about the structure of Thai words is
needed. We called such information in our method as syntactic
attributes of Thai words. As the learning stage, a training corpus is
utilized to construct a decision tree based on C4.5 algorithm. In
the segmentation process, a Thai text is segmented according to
the rules produced by the obtained decision tree. The rest shows
the proposed method, experimental results, discussion and
conclusion.
2. PREVIOUS APPROACHES
2.1 Longest Matching
Most of Thai early works in Thai word segmentation are based on
longest matching method ([4]). The method scans an input
sentence from left to right, and select the longest match with a
dictionary entry at each point. In case that the selected match
cannot lead the algorithm to find the rest of the words in the
sentence, the algorithm will backtrack to find the next longest one
and continue finding the rest and so on. It is obvious that this
algorithm will fail to find the correct the segmentation in many
cases because of its greedy characteristic. For example:?????????
(go to see the queen) will be incorrectly segmented as: ??(go)   ???
(carry)  ??(deviate)   ? ?(color), while the correct one that cannot be
found by the algorithm is: ??(go)  ??(see)  ???? ?(Queen).
2.2 Maximum Matching
The maximum matching algorithm was proposed to solve the
problem of the longest matching algorithm describes above ([7]).
This algorithm first generates all possible segmentations for a
sentence and then select the one that contain the fewest words,
which can be done efficiently by using dynamic programming
technique. Because the algorithm actually finds real maximum
matching instead of using local greedy heuristics to guess, it
always outperforms the longest matching method. Nevertheless,
when the alternatives have the same number of words, the
algorithm cannot determine the best candidate and some other
heuristics have to be applied. The heuristic often used is again the
greedy one: to prefer the longest matching at each point. For the
example, ???(expose) ??(wind) is preferred to ??(eye) ???(round).
2.3 Feature-based Approach
A number of feature-based methods have been developed in
([3]) for solving ambiguity in word segmentation. In this
approach, the system generates multiple possible segmentation for
a string, which has segmentation ambiguity. The problem is that
how to select the best segmentation from the set of candidates. At
this point, this research applies and compares two learning
techniques, called RIPPER and Winnow. RIPPER algorithm is a
propositional learning algorithm that constructs a set of rules
while Winnow algorithm is a weighted-majority learning
algorithm that learns a network, where each node in the network is
called a specialist. Each specialist looks at a particular value of an
attribute of the target concept, and will vote for a value of the
target concept based on its specialty; i.e., based on a value of the
attribute it examines. The global algorithm combines the votes
from all specialists and makes decision. This approach is a
dictionary-based approach. It can acquire up to 91-99% of the
number of correct segmented sentences to the total number of
sentences.
2.4 Thai Character Chuster
In Thai language, some contiguous characters tend to be an
inseparable unit, called Thai character cluster (TCC). Unlike word
segmentation that is a very difficult task, segmenting a text into
TCCs is easily realized by applying a set of rules. The method to
segment a text into TCCs was proposed in ([8]). This method
needs no dictionary and can always correctly segment a text at
every word boundaries.
3. WORD SEGMENTATION WITH
DECISION TREE MODELS
In this paper, we propose a word segmentation method that (1)
uses a set of rules to combine contiguous characters to an
inseparable unit (syllable-like unit) and (2) then applies a learned
decision tree to combine these contiguous units to words. This
section briefly shows the concept of TCC and the proposed
method based on decision trees.
3.1 Segmenting a Text into TCCs
In Thai language, some contiguous characters tend to be an
inseparable unit, called Thai character cluster (TCC). Unlike word
segmentation that is a very difficult task, segmenting a text into
TCCs is easily recognized by applying a set of rules (in our
system, 42 BNF rules). The method to segment a text into TCCs
was proposed in [8]. This method needs no dictionary and can
always correctly segment a text at every word boundaries. As the
first step of our word segmentation approach, a set of rules is
applied to group contiguous characters in a text together to form
TCCs. The accuracy of this process is 100% in the sense that there
is no possibility that these units are divided to two or more units,
which are substrings in two or more different words. This process
can be implemented without a dictionary, but uses a set of simple
linguistic rules based on the types of characters. Figure 2 displays
the types of Thai characters. As an example rule, a front vowel
and its next consonant must exist in the same unit. Figure 3 shows
a fragment of a text segmented into TCCs by the proposed method
and its correct word segmentation.  Here, a character ?|? indicates
a segmentation point. The corpus where characters are grouped
into TCCs is called a TCC corpus.
Types of Thai
Characters Members
Consonant ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
Upper vowel     ?    ?    ?       ?     ?      ?      ?
Lower vowel  ?    ?
Front vowel ? ? ? ? ?
Rear vowel ? ? ? ? ? ? ???
Figure 2. Types of Thai characters
TCCs ??|?| ????|??|?|??|??|??|?|??|?|
CORRECT ???| ????|???|???????|???|???|
Figure 3. An example of TCCs vs. correct 
3.2 Learning a Decision Tree for W
Segmentation
To learn a decision tree for this task, some attri
for classifying whether two contiguous TCCs are
unit or not. In this paper, eight types of attribute
proposed to identify possible word boundaries
answers (or classes) in the decision tree for thi
types: combine and not combine. Moreover, to
two contiguous TCCs should be combined or 
front of the current two TCCs and the TCC behi
into account. That is, there are four sets of attr
two for current two TCCs and two for TCCs
behind the current TCCs. Therefore, the total nu
is 32 (that is, 8x4) and there is one dependent v
whether the current two contiguous TCCs shoul
not.
Attribute Name Attribute D
Front_vowel 0(don?t have), 1(don?t h2(may be followed by re
Front_consonant 0(don?t have), 1(don?t lor oang), 2(lead with ho
Middle_vowel 0(don?t have), 1(upper v2(lower vowel)
Middle_consonant 0(don?t have), 1 (have)
Rear_vowel 0(don?t have), 1 (sara_a2 (sara_aa, sara_am)
Rear_consonant
0-9 are (don?t have), (ko
(kod_tone), (kong_tone
(kob_tone), (kon_tone),
(wowaen_tone), (yoyak
Length Length of the block(the number of characte
Space & Enter 0 (don?t have), 1 (have)
Figure 4. Types of TCC Attribu
   ??|?|????|??|    ?|??|??
  ??   |?|????|??|?|?     ?|
  ??|?   |????|??|?|??|     
TCC
From above we get th
1! 0,1,0,0,2,0,2,0,0,
2! 0,1,0,0,0,0,1,0,1,
3! 1,1,1,0,0,5,4,0,0,???|?|??|??|?|
??????|
segmentation
ord
butes are defined
 combined to one
s (in Figure 4 are
 in the text. The
s task are of two
 decide whether
not, the TCC in
nd them are taken
ibutes concerned:
 in front of and
mber of attributes
ariable indicating
d be combined or
etail
ave rear vowel),
ar vowel)
ead with hohip
hip or oang)
owel),
),
k_tone),
), (kom_tone),
_tone), (others)
rs)
tes
Figure 5 illustrates an example of the process to extract attributes
from the TCC corpus and use them as a training corpus. The
process is done by investigating the current TCCs in the buffer
and recording their attribute values. The dependent variable is set
by comparing the combination of the second and the third blocks
of characters in the buffer to the same string in the correct word-
segmented corpus, the corpus that is segmented by human. The
result of this comparison will output whether the second and the
third blocks in the buffer should be merged to each other or not.
This output is then kept as a training set with the dependent
variable, ?Combine (1)? or ?NotCombine (0)?. Repetitively,  the
start of the buffer is shifted by one block. This process executes
until the buffer reaches the end of the corpus. The obtained
training set then is used as the input to the C4.5 application ([5])
for learning a decision tree.
The C4.5 program will examine and construct the decision tree
using the statistical values calculated from the events occurred.
After the decision tree is created, the certainty factor is calculated
and assigned to each leaf as a final decision-making factor. This
certainty factor is the number that identifies how certain the
answer at each terminal node is. It is calculated according to the
number of terminal class answers at each leaf of the tree. For
example, at leaf node i, if there are ten terminal class answers; six
of them are ?Combine? and the rest are ?Not Combine?. The
answer at this node would be ?Combine? with the certainty factor
equals to 0.6 (6/10).  On the other hand, leaf node j has 5
elements; two are ?Combine? and three are ?Not Combine?, then
the answer at this node would be ?Not Combine? with the
certainty factor equals to 0.6 (3/5). The general formula for the
certainty factor (CF) is shown as follow:
CFi = Total number of the answer elements at leaf node i
Total number of all elements at leaf node i
We also calculate the recall, precision, and accuracy as defined
below:
Precision   =   number of  correct ?|?s  in the system answer
                  number of ?|?s in the system answer
Recall        =   number of  correct ?|?s in the system answer
     number of ?|?s in the correct answer
 Accuracy  =  number of correct segmented units in system answer
         total number of segmented units in correct answer
|??|?|??|?|???|?|??|??|?|     !1      
??|??|?|??|?|???|?|??|??|?|  !2
??|??|?|??|?|???|?|??|??|?|  !3
Buffer = 4 blocks
e following sets of attributes for the three points.
1,0,0,0,0,1,0,1,1,1,0,0,5,4,0,0,1,0,0,2,0,2,0,0
1,1,0,0,5,4,0,0,1,0,0,2,0,2,0,0,1,1,0,0,0,2,0,0
1,0,0,2,0,2,0,0,1,1,0,0,0,2,0,0,1,0,0,0,0,1,0,1
Not Combine
Combine
Figure 5. Attributes taken from the corpus
4. EXPERIMENT RESULTS
In our experiments, the TCC corpus is divided into five sets, four
for training and one for testing. Based on this, five times cross
validation are performed. To test the accuracy, we trained the
decision trees and tested them several times for six different levels
of merging permission according to certainty factor(CF). Each
level is the starting level of merging permission of the strings in
the second and the third blocks in the buffer. Recall, precision,
and accuracy where the certainty factor ranges between 50% and
100% are shown in Figure 6.
From the result, we observed that our m
satisfactory in the percentage of accuracy an
and recall compared to those numbers of
performance. The TCC corpus has 100% re
precision, and 44.93% accuracy. Using the d
from a Thai corpus, the precision improves 
and the accuracy increases up to 85.51-87
recall drops to 63.72-94.52%. For a high CF
drops a little because there are few cases to m
precision and accuracy improve dominantly to
respectively. For a lower CF, say 50%, reca
but precision and accuracy dramatically imp
85.51% respectively.
However, from 50 to 100% CF, at approxim
accuracy had declined. The reason to this decl
very high level of merging permission, there a
removing ?|? because of the %CF at those le
this permission level. Therefore, there are mo
word segmentation, which lead to dec
conclusion, the appropriate level of merging 
used in order to achieve high accuracy. From
best permission level is approximately equal 
the recall equals to 96.13%, precision equals to 91.92% and the
accuracy equals to 87.41%.
5. DISCUSSION AND CONCLUSION
Due to the problem of the unknown words that most of the
existing Thai word segmentation systems have to cope with, this
paper has introduced an alternative method for avoiding such
problem. Our approach is based on using the decision tree as the
decision support model with no need of dictionary at all. The
experimental results clearly show that our method gives some
hieving high accuracy when suitable and
ng permission factor is used. In our experiments,
60.000
65.000
70.000
75.000
80.000
85.000
90.000
95.000
100.000
50% 60% 70% 80% 90% 100%
Decision tree certainty factor
Pe
rc
en
tag
e
Recall (%) Precision (%) Accuracy (%)
Figure 4. Recall, precision, and accuracyethod presented the
promises on ac
appropriate mergid both in precision
 the original TCC
call but has 52.12%
ecision tree learned
up to 94.11-99.85%
.41%. However, the
, say 100 %, recall
erge two TCCs but
 63.72% and 62.97,
ll drops dominantly
rove to 94.52% and
ately 80% CF, the
ination is that with a
re a few chances for
aves are lower than
re chances for wrong
rease accuracy. In
permission has to be
 our experiment, the
to 70%, which gives
the best level of permission that leads to the highest accuracy is
approximately equals to 70%, which gives the accuracy equal to
87.41%, as shown in Figure 6.
The dictionary-based method so-called the feature-based system
with context independence gives the highest accuracy equals to
99.74% and with context dependence, which has the highest
accuracy equals to 95.33% ([3]). In [1], the Japanese word
segmentation is explored based on decision tree. However, it
focuses on the part-of-speech for word segmentation. Another two
well known dictionary-based methods, Maximum and Longest
Matching methods, have the accuracy equal to 86.21% and
82.60% respectively when there are 20% of unknown words,
which are lower than our system accuracy, and their accuracy
drops as percentage of unknown words increases.  By comparing
these percentages of accuracy, we can conclude that our method
can achieve satisfied accuracy even without dictionary. Therefore,
our method is useful for solving an unknown word problem and it
will be even more useful to apply our method to the dictionary-
based system in order to improve the system accuracy. In
addition, our results seem to suggest that our method is efficient
not only for Thai texts but also for any language when suitable
and appropriate syntactic attributes are used.
Our plan for further research is to apply our method to the
dictionary based system in order to take care of the unknown
word parts. This would improve the accuracy of the system
regardless of the level of the unknown words found in the context.
6. ACKNOWLEDGEMENT
This work has been supported by National Electronics and
Computer Technology Center (NECTEC) under the project
number NT-B-06-4F-13-311.
7. REFERENCES
[1] Kasioka, H., Eubank, S. G., and Black, E. W., Decision-Tree
Morphological Analysis without a Dictionary for Japanese,
Proceedings of the Natural Language Processing Pacific Rim
Symposium, pp. 541-544, Phuket, Thailand, 1997.
[2] Kawtrakul, A., Thumkanon, C., Poovorawan, Y., Varasrai, P.
and Suktarachan, M., Automatic Thai Unknown Word
Recognition, Proceedings of the Natural Language
Processing Pacific Rim Symposium, pp. 341-348, Phuket,
Thailand, 1997.
[3] Mekanavin, S., Charenpornsawat, P., and Kijsirikul, B.,
Feature-based Thai Words Segmentation, Proceedings of the
Natural Language Processing Pacific Rim Symposium, pp.
41-48, Phuket, Thailand, 1997.
[4] Poowarawan, Y., Dictionary-based Thai Syllable Separation,
Proceedings of the Ninth Electronics Engineering
Conference, 1986.
[5] Quinlan, J.R., Induction of Decision Trees, Machine
Learning, 1, pp. 81-106, 1986.
[6] Rarunrom, S. Dictionary-based Thai Word Separation,
Thesis, Thailand.
[7] Sornlertlamvanich, V., Word Segmentation for Thai in a
Machine Translation system (in Thai), Papers on Natural
Language processing, NECTEC, Thailand, 1995.
[8] Theeramunkong, T., Sornlertlamvanich, V., Tanhermhong,
T., Chinnan, W., Character-Cluster Based Thai Information
Retrieval, Proceedings of the Fifth International Workshop
on Information Retrieval with Asian Languages, September
30 - October 20, 2000, Hong Kong, pp.75-80.
