Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 89?92, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Transonics: A Practical Speech-to-Speech Translator for English-Farsi
Medical Dialogues
Emil Ettelaie, Sudeep Gandhe, Panayiotis Georgiou,
Kevin Knight, Daniel Marcu, Shrikanth Narayanan ,
David Traum
University of Southern California
Los Angeles, CA 90089
ettelaie@isi.edu, gandhe@ict.usc.edu,
georgiou@sipi.usc.edu, knight@isi.edu,
marcu@isi.edu, shri@sipi.usc.edu,
traum@ict.use.edu
Robert Belvin
HRL Laboratories, LLC
3011 Malibu Canyon Rd.
Malibu, CA 90265
rsbelvin@hrl.com
Abstract
We briefly describe a two-way speech-to-
speech English-Farsi translation system
prototype developed for use in doctor-
patient interactions.  The overarching
philosophy of the developers has been to
create a system that enables effective
communication, rather than focusing on
maximizing component-level perform-
ance.  The discussion focuses on the gen-
eral approach and evaluation of the
system by an independent government
evaluation team.
1 Introduction
In this paper we give a brief description of a
two-way speech-to-speech translation system,
which was created under a collaborative effort
between three organizations within USC (the
Speech Analysis and Interpretation Lab of the
Electrical Engineering department, the Information
Sciences Institute, and the Institute for Creative
Technologies) and the Information Sciences Lab of
HRL Laboratories.  The system is intended to pro-
vide a means of enabling communication between
monolingual English speakers and monolingual
Farsi (Persian) speakers.  The system is targeted at
a domain which may be roughly characterized as
"urgent care" medical interactions, where the Eng-
lish speaker is a medical professional and the Farsi
speaker is the patient.  In addition to providing a
brief description of the system (and pointers to pa-
pers which contain more detailed information), we
give an overview of the major system evaluation
activities.
2 General Design of the system
Our system is comprised of seven speech and
language processing components, as shown in Fig.
1. Modules communicate using a centralized mes-
sage-passing system. The individual subsystems
are the Automatic Speech Recognition (ASR) sub-
system, which uses n-gram Language Models
(LM) and produces n-best lists/lattices along with
the decoding confidence scores. The output of the
ASR is sent to the Dialog Manager (DM), which
displays the n-best and passes one hypothesis on to
the translation modules, according to a user-
configurable state. The DM sends translation re-
quests to the Machine Translation (MT) unit. The
MT unit works in two modes: Classifier based MT
and a fully Stochastic MT. Depending on the dia-
logue manager mode, translations can be sent to
the unit selection based Text-To-Speech synthe-
sizer (TTS), to provide the spoken output. The
same basic pipeline works in both directions: Eng-
lish ASR, English-Persian MT, Persian TTS, or
Persian ASR, Persian-English MT, English TTS.
There is, however, an asymmetry in the dia-
logue management and control, given the desire for
the English-speaking doctor to be in control of the
device and the primary "director" of the dialog.
The English ASR used the University of Colo-
rado Sonic recognizer, augmented primarily with
LM data collected from multiple sources, including
89
our own large-scale simulated doctor-patient dia-
logue corpus based on recordings of medical stu-
dents examining standardized patients (details in
Belvin et al 2004).
1
 The Farsi acoustic models r e-
quired an eclectic approach due to the lack of ex-
isting labeled speech corpora.  The approach
included borrowing acoustic data from English by
means of developing a sub-phonetic mapping be-
tween the two languages, as detailed in (Srini-
vasamurthy & Narayanan 2003), as well as use of
a small existing Farsi speech corpus (FARSDAT),
and our own team-internally generated acoustic
data.  Language modeling data was also obtained
from multiple sources.  The Defense Language
Institute translated approximately 600,000 words
of English medical dialogue data (including our
standardized patient data mentioned above), and in
addition, we were able to obtain usable Farsi text
from mining the web for electronic news sources.
Other  smaller  amounts of  training  data  were ob
tained from various sources, as detailed in  (Nara-
yanan et al 2003, 2004).  Additional detail on de-
velopment methods for all of these components,
system integration and evaluation can also be
found in the papers just cited.
The MT components, as noted, consist of both a
Classifier and a stochastic translation engine,  both
                                                           
1
 Standardized Patients are typically actors who have been
trained by doctors or nurses to portray symptoms of particular
illnesses or injuries.  They are used extensively in medical
education so that doctors in training don't have to "practice"
on real patients.
developed by USC-ISI team members.  The Eng-
lish Classifier uses approximately 1400 classes
consisting mostly of standard questions used by
medical care providers in medical interviews.
Each class has a large number of paraphrases asso-
ciated with it, such that if the care provider speaks
one of those phrases, the system will identify it
with the class and translate it to Farsi via table-
lookup.  If the Classifier cannot succeed in finding
a match exceeding a confidence threshold, the sto-
chastic MT engine will be employed.  The sto-
chastic MT engine relies on n-gram
correspondences between the source and target
languages.  As with ASR, the performance of the
component is highly dependent on very large
amounts of training data.  Again, there were multi-
ple sources of training data used, the most signifi-
cant being the data generated by our own team's
English collection effort, supported by translation
into Farsi by DLI. Further details of the MT com-
ponents can be found in Narayanan et al, op.cit.
3 Enabling Effective Communication
The approach taken in the development of Tran-
sonics was what can be referred to as the total
communication pathway.  We are not so concerned
with trying to maximize the performance of a
given component of the system, but rather with the
effectiveness of the system as a whole in facilitat-
ing actual communication.  To this end, our design
and development included the following:
MT
English to Farsi
Farsi to English
ASR
English
Prompts or TTS
Farsi
Prompts or TTS
English
ASR
Farsi
GUI:
prompts,
 confirmations,
 ASR switch
Dialog
Manager
SMT
English to Farsi
Farsi to English
Figure 1: Architecture of the Transonics system.  The Dialogue Manager acts as the hub through which the
individual components interact.
90
i. an "educated guess" capability (system
guessing at the meaning of an utterance) from the
Classifier translation mechanism?this proved very
useful for noisy ASR output, especially for the re-
stricted domain of medical interviews.
ii. a flexible and robust SMT good for filling in
where the more accurate Classifier misses.
iii. exploitation of a partial n-best list as part of
the GUI used by the doctor/medic for the English
ASR component and the Farsi-to-English transla-
tion component.
iv. a dialog manager which in essence occa-
sionally makes  "suggestions" (for next questions
for the doctor to ask) based on query sets which are
topically related to the query the system believes it
recognized the doctor to have spoken.
Overall, the system achieves a respectable level of
performance in terms of allowing users to follow a
conversational thread in a fairly coherent way, de-
spite the presence of frequent ungrammatical or
awkward translations (i.e. despite what we might
call non-catastrophic errors).
4 Testing and Evaluation
In addition to our own laboratory tests, the sys-
tem was evaluated by MITRE as part of the
DARPA program.  There were two parts to the
MITRE evaluations, a "live" part, designed pri-
marily to evaluate the overall task-oriented effec-
tiveness of the systems, and a "canned" part,
designed primarily to evaluate individual compo-
nents of the systems.
The live evaluation consisted of six medical
professionals (doctors, corpsmen and physician?s
assistants from the Naval Medical Center at Quan-
tico, and a nurse from a civilian institution) con-
ducting unrehearsed "focused history and physical
exam" style interactions with Farsi speakers play-
ing the role of patients, where the English-speaking
doctor and the Farsi-speaking patient communi-
cated by means of the Transonics system.  Since
the cases were common enough to be within the
realm of general internal medicine, there was no
attempt to align ailments with medical specializa-
tions among the medical professionals.
MITRE endeavored to find primarily monolin-
gual Farsi speakers to play the role of patient, so as
to provide a true test of the system to enable com-
munication between people who would otherwise
have no way to communicate.  This goal was only
partially realized, since one of the two Farsi patient
role-players was partially competent in English.
2
The Farsi-speaking role-players were trained by a
medical education specialist in how to simulate
symptoms of someone with particular injuries or
illnesses.  Each Farsi-speaking patient role-player
received approximately 30 minutes of training for
any given illness or injury.  The approach was
similar to that used in training standardized pa-
tients, mentioned above (footnote 1) in connection
with generation of the dialogue corpus.
MITRE established a number of their own met-
rics for measuring the success of the systems, as
well as using previously established metrics.  A
full discussion of these metrics and the results ob-
tained for the Transonics system is beyond the
scope of this paper, though we will note that one of
the most important of these was task-completion.
There were 5 significant facts (5 distinct facts for
each of 12 different scenarios) that the medical
professional should have discovered in the process
of interviewing/examining each Farsi patient.  The
USC/HRL system averaged 3 out of the 5 facts,
which was a slightly above-average score among
the 4 systems evaluated.  A "significant fact" con-
sisted of determining a fact which was critical for
diagnosis, such as the fact that the patient had been
injured in a fall down a stairway, the fact that the
patient was experiencing blurred vision, and so on.
Significant facts did not include items such as a
patient's age or marital status.
3
  We report on this
measure in that it is perhaps the single most im-
portant component in the assessment, in our opin-
ion, in that it is an indication of many aspects of
the system, including both directions of the trans-
lation system.  That is, the doctor will very likely
conclude correct findings only if his/her question is
translated correctly to the patient, and also if the
patient's answer is translated correctly for the doc-
tor.  In a true medical exam, the doctor may have
                                                           
2
 There were additional difficulties encountered as well, hav-
ing to do with one of the role-players not adequately grasping
the goal of role-playing.  This experience highlighted the
many challenges inherent in simulating domain-specific
spontaneous dialogue.
3
 Unfortunately, there was no baseline evaluation this could be
compared to,  such as assessing whether any of the critical
facts could be determined without the use of the system at all.
91
other means of determining some critical facts
even in the absence of verbal communication, but
in the role-playing scenario described, this is very
unlikely.  Although this measure is admittedly
coarse-grained, it simultaneously shows, in a crude
sense, that the USC/HRL system compared fa-
vorably against the other 3 systems in the evalua-
tion, and also that there is still significant room for
improvement in the state of the art.
As noted, MITRE devised a component evalua-
tion process also consisting of running 5 scripted
dialogs through the systems and then measuring
ASR and MT performance.  The two primary
component measures were a version of BLEU for
the MT component (modified slightly to handle the
much shorter sentences typical of this kind of dia-
log) and a standard Word-Error Rate for the ASR
output.  These scores are shown below.
Table 1:  Farsi BLEU Scores
IBM BLEU
ASR
IBM BLEU
TEXT
English to Farsi
0.2664 0.3059
Farsi  to English 0.2402 0.2935
The reason for the two different BLEU scores is
that one was calculated based on the ASR compo-
nent output being translated to the other language,
while the other was calculated from human tran-
scribed text being translated to the other language.
Table 2:  HRL/USC WER for Farsi and English
English Farsi
WER 11.5% 13.4%
5 Conclusion
In this paper we have given an overview of the
design, implementation and evaluation of the Tran-
sonics speech-to-speech translation system for nar-
row domain two-way translation.  Although there
are still many significant hurdles to be overcome
before this kind of technology can be called truly
robust, with appropriate training and two coopera-
tive interlocutors, we can now see some degree of
genuine communication being enabled.  And this is
very encouraging indeed.
6 Acknowledgements
This work was supported primarily by the DARPA
CAST/Babylon program, contract N66001-02-C-
6023.
References
R. Belvin, W. May, S. Narayanan, P. Georgiou, S. Gan-
javi.  2004. Creation of a Doctor-Patient Dialogue
Corpus Using Standardized Patients. In Proceedings of
the Language Resources and Evaluation Conference
(LREC), Lisbon, Portugal.
S. Ganjavi, P. G. Georgiou, and S. Narayanan. 2003.
Ascii based transcription schemes for languages with
the Arabic script: The case of Persian. In Proc. IEEE
ASRU,  St. Thomas, U.S. Virgin Islands.
S. Narayanan, S. Ananthakrishnan, R. Belvin, E. Ette-
laie, S. Ganjavi, P. Georgiou, C. Hein, S. Kadambe,
K. Knight, D. Marcu, H. Neely, N. Srinivasamurthy,
D. Traum and D. Wang.  2003. Transonics: A speech
to speech system for English-Persian Interactions,
Proc. IEEE ASRU,  St. Thomas, U.S. Virgin Islands.
S. Narayanan, S. Ananthakrishnan, R. Belvin, E. Ette-
laie, S. Gandhe, S. Ganjavi, P. G. Georgiou, C. M.
Hein, S. Kadambe, K. Knight, D. Marcu, H. E.
Neely, N. Srinivasamurthy, D. Traum, and D. Wang.
2004. The Transonics Spoken Dialogue Translator:
An aid for English-Persian Doctor-Patient interviews,
in Working Notes of the AAAI Fall symposium on
Dialogue Systems for Health Communication, pp 97-
-103.
N. Srinivasamurthy, and S. Narayanan. 2003. Language
adaptive Persian speech recognition. In proceedings
of Eurospeech 2003.
92
Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 1?4
Manchester, August 2008
Mitigation of data sparsity in classifier-based translation
Emil Ettelaie, Panayiotis G. Georgiou, Shrikanth S. Narayanan
Signal Analysis and Interpretation Laboratory
Ming Hsieh Department of Electrical Engineering
Viterbi School of Engineering
University of Southern California
ettelaie@usc.edu
Abstract
The concept classifier has been used as a
translation unit in speech-to-speech trans-
lation systems. However, the sparsity of
the training data is the bottle neck of its
effectiveness. Here, a new method based
on using a statistical machine translation
system has been introduced to mitigate the
effects of data sparsity for training classi-
fiers. Also, the effects of the background
model which is necessary to compensate
the above problem, is investigated. Exper-
imental evaluation in the context of cross-
lingual doctor-patient interaction applica-
tion show the superiority of the proposed
method.
1 Introduction
Statistical machine translation (SMT) methods
are well established in speech-to-speech transla-
tion systems as the main translation technique
(Narayanan et al, 2003; Hsiao et al, 2006). Due
to their flexibility these methods provide a good
coverage of the dialog domain. The fluency of
the translation, however, is not guaranteed. Dis-
fluencies of spoken utterances plus the speech rec-
ognizer errors degrade the translation quality even
more. All these ultimately affect the quality of the
synthesized speech output in the target language,
and the effectiveness of the concept transfer.
It is quite common, though, to use other means of
translation in parallel to the SMT methods (Gao et
al., 2006; Stallard et al, 2006). Concept classifica-
tion, as an alternative translation method, has been
successfully integrated in speech-to-speech transla-
tors (Narayanan et al, 2003; Ehsani et al, 2006).
A well defined dialog domain, e.g. doctor-patient
dialog, can be partly covered by a number of con-
cept classes. Upon a successful classification of
the input utterance, the translation task reduces to
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
synthesizing a previously created translation of the
concept, as a mere look up. Since the main goal in
such applications is an accurate exchange of con-
cepts, this method would serve the purpose as long
as the input utterance falls within the coverage of
the classifier. This process can be viewed as a quan-
tization of a continuous ?semantic? sub-space. The
classifier is adequate when the quantization error is
small (i.e. the derived concept and input utterance
are good matches), and when the utterance falls in
the same sub-space (domain) as the quantizer at-
tempts to cover. Since it is not feasible to accu-
rately cover the whole dialog domain (since a large
number of quantization levels needed) the classi-
fier should be accompanied by a translation system
with a much wider range such as an SMT engine.
A rejection mechanism can help identify the cases
that the input utterance falls outside the classifier
coverage (Ettelaie et al, 2006).
In spite of this short coming, the classifier-
based translator is an attractive option for speech-
to-speech applications because of its tolerance to
?noisy? input and the fluency of its output, when it
operates close to its design parameters. In practice
this is attainable for structured dialog interactions
with high levels of predictability. In addition, it can
provide the users with both an accurate feedback
and different translation options to choose from.
The latter feature, specially, is useful for applica-
tions like doctor-patient dialog.
Building a concept classifier starts with identify-
ing the desired concepts and representing them with
canonical utterances that express these concepts. A
good set of concepts should consist of the ones that
are more frequent in a typical interaction in the do-
main. For instance in a doctor-patient dialog, the
utterance ?Where does it hurt?? is quite common
and therefore its concept is a good choice. Phrase
books, websites, and experts? judgment are some of
the resources that can be used for concept selection.
Other frequently used concepts include those that
correspond to basic communicative and social as-
pects of the interaction such as greeting, acknowl-
edgment and confirmation.
After forming the concept space, for each class,
1
utterances that convey its concept must be gath-
ered. Hence, this training corpus would consist of
a group of paraphrases for each class. This form of
data are often very difficult to collect as the number
of classes grow. Therefore, the available training
data are usually sparse and cannot produce a classi-
fication accuracy to the degree possible. Since the
classifier range is limited, high accuracy within that
range is quite crucial for its effectiveness. One of
the main issues is dealing with data sparsity. Other
techniques have also been proposed to improve the
classification rates. For example in (Ettelaie et al,
2006) the accuracy has been improved by introduc-
ing a dialog model. Also, a background model has
been used to improve the discrimination ability of a
given concept class model.
In this work a novel method for handling the
sparsity is introduced. This method utilizes an SMT
engine to map a single utterance to a group of them.
Furthermore, the effect of the background model on
classification accuracy is investigated.
Section 2 reviews the concept classification pro-
cess and the background model. In Section 3 the
sparsity handling method using an SMT is intro-
duced. Data and experiments are described in Sec-
tion 4. The results are discussed in Section 5.
2 Concept classifier and background
model
The concept classifier based on the maximum like-
lihood criterion can be implemented as a language
model (LM) scoring process. For each class a lan-
guage model is built using data expressing the class
concept. The classifier scores the input utterance
using the class LM?s and selects the class with high-
est score. In another word if C is the set of concept
classes and e is the input utterance, the classifica-
tion process is,
c? = argmax
c?C
{P
c
(e | c)} (1)
where P
c
(e | c) is the score of e from the LM of
class c. The translation job is concluded by playing
out a previously constructed prompt that expresses
the concept c? in the target language.
It is clear that a class with limited training data
items will have an undertrained associated LM with
poor coverage. In practice such a model fails to pro-
duce a usable LM score and leads to a poor classifi-
cation accuracy. Interpolating the LM with a back-
ground language model results in a smoother model
(Stolcke, 2002) and increases the overall accuracy
of the classifier.
The background model should be built from a
larger corpus that fairly covers the domain vocab-
ulary. The interpolation level can be optimized for
the best performance based on heldout set.
3 Handling sparsity by statistical
machine translation
The goal is to employ techniques that limit the ef-
fects of data sparsity. What is proposed here is to
generate multiple utterances ? possibly with lower
quality ? from a single original one. One approach
is to use an SMT to generate n-best lists of trans-
lation candidates for the original utterances. Such
lists are ranked based on a combination of scores
from different models (Ney et al, 2000). The hy-
pothesis here is that for an SMT trained on a large
corpus, the quality of the candidates would not de-
grade rapidly as one moves down the n-best list.
Therefore a list with an appropriate length would
consist of translations with acceptable quality with-
out containing a lot of poor candidates. This pro-
cess would result in more data, available for train-
ing, at the cost of using noisier data.
Although the source language of the SMT must
be the same as the classifier?s, its target language
can be selected deliberately. It is clear that a lan-
guage with large available resources (in the form of
parallel corpora with the source language) must be
selected. For simplicity this language is called the
?intermediate language? here.
A classifier in the intermediate language can be
built by first generating an n-best list for every
source utterance in the classifier?s training corpus.
Then the n-best lists associated with each class are
combined to form a new training set. The class
LM?s are now built from these training sets rather
than the original sets of the source utterances.
To classify a source utterance e, first the SMT
is deployed to generate an n-best list (in the inter-
mediate language) from it. The list will consist of
candidates f
1
, f
2
,..., f
n
. The classification process
can be reformulated as,
c? = argmax
c?C
{
n
?
i=1
?
P
c
(f
i
| c)
}
(2)
Here,
?
P
c
(f
i
| c) is the score of the i
th
candidate f
i
from the LM of class c. The scores are considered
in the probability domain.
The new class LM?s can also be smoothed by in-
terpolation with a background model in the inter-
mediate language.
4 Data and Experiments
4.1 Data
The data used in this work were originally collected
for, and used in, the Transonics project (Narayanan
et al, 2003) to develop an English/Farsi speech-to-
speech translator in the doctor-patient interaction
domain. For the doctor side, 1,269 concept classes
were carefully chosen using experts? judgment and
medical phrase books. Then, for each concept, En-
glish data were collected from a website, a web-
based game, and multiple paraphrasing sessions at
the Information Sciences Institute of the University
2
Conventional n-best length
(baseline) 100 500 1,000 2,000
Accuracy [%]
74.9 77.4 77.5 76.8 76.4
Relative error
reduction [%]
0.0 10.0 10.4 7.6 6.0
Accuracy in
4-best [%]
88.6 90.7 91.0 91.3 90.5
Relative error
reduction [%]
0.0 18.4 21.1 23.7 16.7
Table 1: Classification accuracy for the conventional method
and the proposed method with different lengths of n-best list
of Southern California. The total size of the data
set consists of 9,893 English phrases.
As the test corpus for this work, 1,000 phrases
were randomly drawn from the above set and the
rest were used for training. To make sure that the
training set covered every class, one phrase per
class was excluded from the test set selection pro-
cess.
To generate the n-best lists, a phrase based SMT
(Koehn et al, 2003) was used. The intermedi-
ate language was Farsi and the SMT was trained
on a parallel English/Farsi corpus with 148K lines
(1.2M words) on the English side. This corpus
was also used to build the classification background
models in both languages. The SMT was opti-
mized using a parallel development set with 915
lines (7.3K words) on the English side.
4.2 Classification Accuracy Measures
Classifier accuracy is often used as the the qual-
ity indicator of the classification task. However, it
is common in the speech-to-speech translation sys-
tems to provide the user with a short list of potential
translations to choose from. For example the user
of system in (Narayanan et al, 2003) is provided
with the top four classifier outputs. In such cases, it
is practically useful to measure the accuracy of the
classifier within its n-best outputs (e.g., n = 4 for
the above system). In this work the classification
accuracy was measured on both the single output
and the 4-best outputs.
4.3 Experiments
To compare the proposed method with the con-
ventional classification, a classifier based on each
method was put to test. In the proposed method,
it is expected that the accuracy is affected by the
length of the n-best lists. To observe that, n-best
lists of lengths 100, 500, 1000, and 2000 were used
in the experiments. The results are shown in Table
1. In all of the above experiments the background
interpolation factor was set to 0.9 which is close
to the optimum value obtained in (Ettelaie et al,
2006).
To examine the effect of the background model,
the conventional and proposed methods were tried
with different values of the interpolation factor ?
(the background model is weighted by 1 ? ?). For
the conventional method the length of the n-best
list was set to 500. Figure 1 shows the accuracy
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.045%
50%55%
60%65%
70%75%
80%85%
90%95%
Conv. 4-bestConv.New 4-bestNew
Background Interpolation Factor
Accu
racy
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.00%
5%
Background Interpolation Factor (?)
Accu
racy
Figure 1: The effect of background model on classification
accuracy
changes with respect to the interpolation factor for
these two methods.
5 Discussion
Table 1 shows the advantage of the proposed
method over the conventional classification with a
relative error rate reduction up to 10.4% (achieved
when the length of the SMT n-best list was 500).
However, as expected, this number decreases with
longer SMT n-best lists due to the increased noise
present in lower ranked outputs of the SMT.
Table 1 also shows the accuracy within 4-best
classifier outputs for each method. In that case
the proposed method showed an error rate which
was relatively 23.7% lower than the error rate of
the conventional method. That was achieved at the
peak of the accuracy within 4-best, when the length
of the SMT n-best list was 1,000. In this case too,
further increase in the length of the n-best list led
to an accuracy degradation as the classifier models
became noisier.
The effect of the background model on classifier
accuracy is shown in Figure 1. The figure shows
the one-best accuracy and the accuracy within 4-
best outputs, versus the background interpolation
factor (?) for both conventional and proposed meth-
ods. As the curves indicate, with ? equal to zero the
classifier has no discriminating feature since all the
class scores are driven solely from the background
model. However, a slight increase in ?, leads to
a large jump in the accuracy. The reason is that
the background model was built from a large gen-
eral domain corpus and hence, had no bias toward
any of the classes. With a small ?, the score from
the background model dominates the overall class
scores. In spite of that, the score differences caused
by the class LM?s are notable in improving the clas-
sifier performance.
As ? increases the role of the class LM?s be-
comes more prominent. This makes the classifier
models more discriminative and increases its accu-
racy as shown in Figure 1. When the factor is in
the close vicinity of one, the smoothing effect of
the background model diminishes and leaves the
3
classes with spiky models with very low vocabu-
lary coverage (lots of zeros). This leads to a rapid
drop in accuracy as ? reaches one.
Both the conventional and proposed methods
follow the above trend as Figure 1 shows, al-
though, the proposed method maintains its supe-
riority throughout the range of ? that was exam-
ined. The maximum measured accuracies for con-
ventional and proposed methods were 75.2% and
78.7% respectively and was measured at ? = 0.999
for both methods. Therefore, the error rate of the
proposed method was relatively 14.1% lower than
its counterpart from the conventional method.
Figure 1 also indicates that when the accuracy is
measured within the 4-best outputs, again the pro-
posed method outperforms the conventional one.
The maximum 4-best accuracy for the conventional
method was measured at the sample point ? = 0.9
and was equal to 88.6%. For the proposed method,
that number was measured as 91.5% achieved at the
sample point ? = 0.999. In another words, consid-
ering the 4-best classifier outputs, the error rate of
the proposed method was relatively 25.4% lower.
6 Conclusion
The proposed language model based method can be
used to improve the accuracy of the concept classi-
fiers specially in the case of sparse training data.
It outperformed the conventional classifier, trained
on the original source language paraphrases, in the
experiments. With this method, when the input ut-
terance is within the classification domain, the clas-
sifier can be viewed as a filter that produces fluent
translations (removes the ?noise?) from the SMT
output.
The experiments also emphasized the impor-
tance of the background model, although indicated
that the classification accuracy was not very sen-
sitive to the value of the background interpolation
factor. This relieves the developers from the fine
tuning of that factor and eliminates the need for a
development data set when a suboptimal solution is
acceptable.
We believe that significant improvements to the
technique can be made through the use of weighted
n-best lists based on the SMT scores. In addition
we believe that using a much richer SMT engine
could provide significant gains through increased
diversity in the output vocabulary. We intend to ex-
tend on this work through the use of enriched, mul-
tilingual SMT engines, and the creation of multiple
classifiers (in several intermediate languages).
7 Acknowledgment
This work was supported in part by funds from
DARPA.
References
Ehsani, F., J. Kinzey, D. Master, K. Sudre, D. Domingo,
and H. Park. 2006. S-MINDS 2-way speech-to-
speech translation system. In Proc. of the Medi-
cal Speech Translation Workshop, Conference of the
North American Chapter of the Association for Com-
putational Linguistics on Human Language Technol-
ogy (NAACL-HLT), pages 44?45, New York, NY,
USA, June.
Ettelaie, E., P. G. Georgiou, and S. Narayanan. 2006.
Cross-lingual dialog model for speech to speech
translation. In Proc. of the Ninth International Con-
ference on Spoken Language Processing (ICLSP),
pages 1173?1176, Pittsburgh, PA, USA, September.
Gao, Y., L. Gu, B. Zhou, R. Sarikaya, M. Afify, H. Kuo,
W. Zhu, Y. Deng, C. Prosser, W. Zhang, and L. Be-
sacier. 2006. IBM MASTOR SYSTEM: Multilin-
gual automatic speech-to-speech translator. In Proc.
of the Medical Speech Translation Workshop, Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics on Human
Language Technology (NAACL-HLT), pages 53?56,
New York, NY, USA, June.
Hsiao, R., A. Venugopal, T. Kohler, Y. Zhang,
P. Charoenpornsawat, A. Zollmann, S. Vogel, A. W.
Black, T. Schultz, and A. Waibel. 2006. Optimiz-
ing components for handheld two-way speech trans-
lation for an English-Iraqi Arabic system. In Proc. of
the Ninth International Conference on Spoken Lan-
guage Processing (ICLSP), pages 765?768, Pitts-
burgh, PA, USA, September.
Koehn, P., F. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. of the Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology (NAACL-HLT), volume 1, pages 48?54,
Edmonton, AB, Canada, May-June.
Narayanan, S., S. Ananthakrishnan, R. Belvin, E. Ette-
laie, S. Ganjavi, P. Georgiou, C. Hein, S. Kadambe,
K. Knight, D. Marcu, H. Neely, N. Srinivasamurthy,
D. Traum, and D. Wang. 2003. Transonics: A
speech to speech system for English-Persian inter-
actions. In Proc. of IEEE Workshop on Automatic
Speech Recognition and Understanding (ASRU),
pages 670?675, St.Thomas, U.S. Virgin Islands,
November-Decmeber.
Ney, H., S. Nie?en, F. J. Och, C. Tillmann, H. Sawaf,
and S. Vogel. 2000. Algorithms for statistical trans-
lation of spoken language. IEEE Trans. on Speech
and Audio Processing, Special Issue on Language
Modeling and Dialogue Systems, 8(1):24?36, Jan-
uary.
Stallard, D., F. Choi, K. Krstovski, P. Natarajan,
R. Prasad, and S. Saleem. 2006. A hybrid
phrase-based/statistical speech translation system.
In Proc. of the Ninth International Conference on
Spoken Language Processing (ICLSP), pages 757?
760, Pittsburgh, PA, USA, September.
Stolcke, A. 2002. SRILM - an extensible language
modeling toolkit. In Proc. of the International Con-
ference on Spoken Language Processing (ICSLP),
pages 901?904, Denver, CO, USA, September.
4
