Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 153?160
Manchester, August 2008
Hybrid processing for grammar and style checking
Berthold Crysmann?, Nuria Bertomeu?, Peter Adolphs?, Dan Flickinger?, Tina Klu?wer??
? Universita?t Bonn, Poppeldorfer Allee 47, D-53115 Bonn, {bcr,tkl}@ifk.uni-bonn.de
? Zentrum fu?r Allgemeine Sprachwissenschaft, Berlin, nuria.bertomeu@dfki.de
? DFKI GmbH, Berlin, {peter.adolphs,kluewer}@dfki.de
? CSLI, Stanford University, danf@csli.stanford.edu
Abstract
This paper presents an implemented hy-
brid approach to grammar and style
checking, combining an industrial pattern-
based grammar and style checker with bi-
directional, large-scale HPSG grammars
for German and English. Under this ap-
proach, deep processing is applied selec-
tively based on the error hypotheses of a
shallow system. We have conducted a com-
parative evaluation of the two components,
supporting an integration scenario where
the shallow system is best used for error de-
tection, whereas the HPSG grammars add
error correction for both grammar and con-
trolled language style errors.
1 Introduction
With the enormous amount of multilingual techni-
cal documentation produced by companies nowa-
days grammar and controlled language checking
(henceforth: style checking) is becoming an appli-
cation highly in demand. It is not only a helpful
tool for authors, but also facilitates the translation
of documents into foreign languages. Through the
use of controlled language by the authors, docu-
ments can be automatically translated more suc-
cessfully than with the use of free language. Style
checking should make authors aware of the con-
structions which should not be used, as well as
aiding in reformulating them. This can save a lot
of translation costs for companies producing large
amounts of mulitilingual documentation. Another
application of grammar and style checking is the
development of tutorial systems for learning a for-
eign language, as well as any kind of authoring sys-
tem for non-native speakers.
Previous approaches to grammar and style
checking can be divided into those based on fi-
nite state methods and those based on linguisti-
cally motivated grammars. To the former group be-
long e.g. the systems FLAG (Bredenkamp et al,
2000a; Bredenkamp et al, 2000b) and MultiLint
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
(Haller, 1996; Schmidt-Wigger, 1998). The basic
approach taken by such systems is the description
of error patterns through finite state automata. The
automata access the textual input enriched with
annotations from shallow linguistic analysis com-
ponents, such as part-of-speech tagging, morphol-
ogy and chunking. In FLAG, for instance, the an-
notation delivered by the shallow components is
integrated into a complex feature structure. Rules
are defined as finite state automata over feature
structures. The great advantages of such systems
are their robustness and efficient processing, which
make them highly suitable for real-life grammar
and style checking applications. However, since
shallow modules usually cannot provide a full syn-
tactic analysis, the coverage of these systems is
limited to error types not requiring a broader (non-
local) syntactic context for their detection. There-
fore their precision in the recognition of non-local
errors is not satisfactory.
Another short-coming of most shallow ap-
proaches to grammar checking is that they typi-
cally do not provide error correction: owing to the
absence of an integrated target grammar, genera-
tion of repairs cannot take the syntactic context
into account: as a result, some of the repairs sug-
gested by shallow systems are not globally well-
formed.
Grammar-based error checking constitutes the
other main strand in language checking technol-
ogy. These systems are typically equipped with a
model of target well-formedness. The main prob-
lem, when applied to the task of error checking
is that the sentences that are the focus of a gram-
mar checker are ideally outside the scope of the
grammar. To address this problem, grammar-based
checkers typically employ robustness techniques
(Ravin, 1988; Jensen et al, 1993; Douglas, 1995;
Menzel, 1998; Heinecke et al, 1998). The addi-
tion of robustness features, while inevitable for a
grammar-based approach, has the disadvantage of
considerably slowing down runtime performance.
Another issue with purely grammar-based check-
ing is related to the scarce distribution of actual
errors: thus, most effort is spent on the processing
of perfectly impeccable utterances. Finally, since
coverage of real-world grammars is never perfect,
these system also have difficulty to distinguish be-
153
tween extragrammatical and truly ungrammatical
sentences. Conversely, since grammars often over-
generate, a successful parse does not guarantee
wellformedness either.
One of the two major robustness techniques
used in the context of grammar-based language
checking are constraint relaxation (see e.g. (Dou-
glas, 1995; Menzel, 1998; Heinecke et al, 1998)),
which is typically realised by means of modifica-
tions to the parser (e.g. relaxation levels, robust uni-
fication). An alternative approach is error anticipa-
tion where errors are explicitly modelled by means
of grammar rules, so-called MAL-rules (McCoy et
al., 1996). This approach has already been inves-
tigated with an HPSG grammar, the ERG (Copes-
take and Flickinger, 2000), in the scenario of a tu-
torial system for language learning by (Bender et
al., 2004). We will follow this approach in the part
of our hybrid system based on deep processing.
Finite state methods and linguistically motivated
grammars are not only compatible, but also com-
plementary. Shallow methods are robust and effi-
cient, while deep processing based on grammars
provides high precision and detail. With the fo-
cussed application of deep analysis in finite state
based grammar and style checking systems, both
coverage and precision can be improved, while
the performance remains acceptable for real-world
applications. The combination of shallow and
deep components, hybrid processing, has already
been investigated in several modular architectures,
such as GATE (Gaizauskas et al, 1996), White-
board (Crysmann et al, 2002) and Heart-of-Gold
(Callmeier et al, 2004). Moreover, the improve-
ment in efficiency and robustness in deep process-
ing together with methods for its efficient applica-
tion makes the employment of deep processing in
real-world applications quite feasible. Hybrid pro-
cessing has been used for applications such as in-
formation extraction and question answering. But
to the best of our knowledge, the application of hy-
brid processing to grammar and style checking has
not been previously investigated.
In this paper, we present an implemented proto-
type of a hybrid grammar and style checking sys-
tem for German and English, called Checkpoint.
As the baseline shallow system we have taken
an industrial strength grammar and controlled lan-
guage style checker, which is based on the FLAG
technology. The deep processing platform used in
the project is the PET parser (Callmeier, 2000)
operating on wide-coverage English and German
HPSG grammars, the English Resource Grammar
(ERG) (Copestake and Flickinger, 2000) and the
German Grammar (GG) (Mu?ller and Kasper, 2000;
Crysmann, 2005; Crysmann, 2007), respectively.
The ERG and the GG have been developed for over
15 years and have already been used as deep pro-
cessing engines in the Heart-of-Gold hybrid pro-
cessing platform. We have developed an approach
for the selective application of deep processing
based on the error hypotheses of the shallow sys-
tem. Error detection in the deep system follows a
MAL-rule approach. In order to compare the ben-
efits of the selective application of deep process-
ing with its nonselective application, we have de-
veloped two scenarios: one parallel and one inte-
grated. While the parallel (nonselective) scenario
enables improvement in both recall and precision,
the integrated (selective) scenario only enables im-
provement in precision. However, the performance
of the integrated approach is much better. We have
also investigated several possibilities of integrating
deep processing in the selective scenario. Since the
HPSG grammars are suitable both for parsing and
generation, the system can successfully provide
both error corrections and paraphrases of stylistic
errors. For the purpose of investigation, evaluation
and statistical parse ranking, we have collected and
annotated several corpora of texts from technical
manuals. Finally, the approach has been evaluated
regarding error detection and performance.
2 The approach
Checkpoint has two main goals: (a) improving the
precision and recall of existing pattern-based gram-
mar and style checking systems for error types
whose detection requires considering more than
the strictly local syntactic context; and (b) gener-
ating error corrections for both grammar and style
errors. Accordingly, we have chosen to focus on
certain error types based on the difficulties of the
pattern-based system.
2.1 Anticipation of grammar errors
Grammar errors are detected by means of error
anticipation rules, or MAL-rules. MAL-rules ex-
actly model errors, so that erroneous sentences can
be parsed by the grammar. For this purpose we
enlarged two HPSG grammars for German, the
GG, and English, the ERG, with MAL-rules for
error types that were problematic for the pattern-
based shallow system. For German the following
phenomena have been handled: subject verb agree-
ment (subject verb agreement), NP internal agree-
ment (NP internal agreement), confusion of the
complementiser ?dass? with the homophonous pro-
noun or determiner ?das? (dass das), as well as
editing errors, such as local and non local repeti-
tion of words (repetitions). Here follow some ex-
amples (taken from the FLAG error corpus (Becker
et al, 2000), and die tageszeitung ?taz?, a German
newspaper):
(1) Auch in AOL gibt es Newsgroups, die
dieses Thema diskutiert [=diskutieren]. (FLAG)
Also in AOL are there newgroups, which (Pl)
this topic discuss (Sg).
?There are also newsgroups in AOL which dis-
cuss this topic.?
154
(2) Ich habe dem ganze [=ganzen] Geschehen
von meinem Sofa aus zugesehen. (FLAG)
I have the whole (wrong adj. form) events
from my couch out watched.
?I have watched the whole events from my
couch.?
(3) Vor allem im Su?den . . . fu?hrten [=haben] die
Liberalen der MR einen heftigen Wahlkampf
gegen die PS gefu?hrt. (taz, June 2007)
Above all in the south . . . led (past tense) the
liberals of the MR a hard election campaign
against the PS led (past participle).
?Particularly in the south, the liberals of the
MR led a hard election campaign against the
PS.?
For English, MAL-rules for errors concerning
subject verb agreement and missing determiners
were implemented.
2.2 Detection of stylistic errors
Stylistic errors are grammatical constructions that
are dispreferred in a particular register or type
of document. Sometimes certain constructions are
not desirable because machine translation systems
have problems dealing with them or because they
prevent easy understanding. In such cases a con-
trolled language approach is taken, where the prob-
lematic constructions are paraphrased into equiv-
alent less problematic constructions. Since these
constructions are grammatical they can be parsed
and, thus, detected. A generation of a paraphrase
is possible based on the semantic representation
obtained through parsing. For German the follow-
ing phenomena were handled: passive, future and
implicit conditional sentences, as in the following
example:
(4) Wartet man zulange, kriegt man keine Karten.
Waits one too long, gets one no tickets.
?If one waits too long one gets no tickets.?
Correct: Wenn man zulange wartet, kriegt
man keine Karten.
For English we focussed on the following phenom-
ena: passive (avoid passive), future (avoid future),
modal verbs (avoid modal verbs), subjunctive
(avoid subjunctive), stand-alone deictic pro-
nouns (use this that these those with noun) and
clause order in conditional sentences (condi-
tion must precede action).
2.3 Integrated vs. parallel scenarios
We have developed two integration scenarios: an
integrated one and a parallel one. In the parallel
scenario the pattern-based shallow system and the
deep processing parser run independently of each
other, that is, all sentences are parsed independent
of whether the shallow system has found an error
in them. In the integrated scenario the deep parser
is only called for those sentences where the shal-
low system has detected some error of the type
of those which Checkpoint is able to process (enu-
merated in subsection 2.1). The parallel scenario
allows improvement in the recall of the shallow
system, since Checkpoint can find errors that the
shallow system has not found. In the integrated
scenario, on the contrary, only the precision of the
shallow system can be improved, since Checkpoint
departs from the hypotheses of the shallow system.
The integrated scenario, however, promises to per-
form better in time than the parallel scenario, since
only a fraction of the whole text has to be scanned
for errors. Moreover, the performance of the inte-
grated system can also be improved with the se-
lective activation of the MAL-rules that model the
specific errors found by the shallow system. This
greatly reduces the enormous search space of the
parsing algorithms and the processing time result-
ing from the simultaneous processing of several
MAL-rules.
The integration of the shallow system and the
deep parser has been achieved through an exten-
sion of the PET parser that allows it to receive any
kind of input information and integrate this into
the chart. This preprocessing information can be,
for example, part-of-speech tagging, morphology
and lemmatisation, and already guides the parsing
process. It allows, for instance, recognition of un-
known words or identification of the correct lexi-
cal entry in cases where there is ambiguity. An in-
put format in terms of feature structures, the ?Fea-
ture Structure Chart? (FSC) format, has been devel-
oped for this purpose (Adolphs et al, 2008). The
shallow system, thus, produces a feature structure
chart, based on the information delivered by the
various shallow modules, and this information is
given as input to the PET deep parser, which reads
it and integrates it into the chart.
Error hypotheses from the shallow system are
passed to the deep parser by means of specific fea-
tures in the input feature structure (MAL-features)
of every input token in the FSC, permitting selec-
tive activation of MAL-rules. To this end, the origi-
nal FSC generated by the shallow system, which
contains information on the part-of-speech, the
lemma and morphological features such as num-
ber, gender and case, will be extended with MAL-
features. These MAL-features correspond to the
class of some MAL-rule in the grammar and have
boolean values. Signs in the grammar are speci-
fied for these MAL-features. MAL-rules are de-
fined such that they can only take as their daughters
edges with a positive value for the corresponding
MAL-feature. All information in the FSC input to-
kens is passed to the tokens in the chart through
a feature called TOKEN in lexical items. Thus, er-
ror hypotheses are passed from the input tokens to
the lexical items in the chart by stating that the val-
ues of the MAL-features in the lexical items are
155
equal to the values of the MAL-features in the cor-
responding input tokens in the FSC.
The values of the MAL-features are obtained
by checking the error report delivered by the shal-
low system. For certain errors detected by the shal-
low system there is a mapping to MAL-features.
The value of a MAL-feature will be set to ?+? if
the shallow system has found the corresponding
error. The rest of the MAL-features can be set to
?bool? if we want to allow other MAL-rules to
fire (which can improve recall, but increases am-
biguity and, consequently, has a negative effect on
performance). The values of the rest of the MAL-
features can also be set to ?-?, if we want to prevent
other MAL-rules from firing (which allows im-
provement only in precision, but limits ambiguity
and, consequently, results in better performance).
There is also the possibility of activating the rel-
evant MAL-features only for those tokens which
are, according to the shallow system, within the er-
ror span, instead of activating the MAL-features
for all tokens in the erroneous sentence.
2.4 Generation of corrections and
paraphrases
One of the advantages of using deep processing
in grammar and style checking is the possibility
of generating corrections and paraphrases which
obey the constraints imposed by the syntactic con-
text. Since the HPSG grammars that we are using
are suitable both for parsing and generation, this
is straightforward. Robust parsing delivers as out-
put a semantic representation in the Minimal Re-
cursion Semantics formalism (MRS) (Copestake
et al, 2006) of the sentence which can be used for
generation with the LKB (Carroll et al, 1999).
The MAL-rules directly assign well-formed se-
mantic representations from which a correct sur-
face string can be generated. In the case of stylis-
tic errors, transfer rules are used to generate the
desired paraphrase, using MRS-to-MRS mapping
rules modelled on the semantic transfer-based ma-
chine translation approach of (L?nning et al,
2004).
We identified two areas where generation of re-
pairs will actually provide a considerable added
value to a grammar checking system: first, for non-
native speakers, simple highlighting of the error
location is often insufficient, since the user may
not be familiar with the rules of the language. Sec-
ond, some areas, in particular stylistic ones may
involve considerable rearrangement of the entire
sentence. In these cases, generation of repairs and
paraphrases can reduce editing cost and also min-
imise the issue of editing errors associated with
non-local phenomena.
The generator and HPSG grammars we use are
able to provide a range of realisations for a given
semantic input. As a result, realisation ranking is
of utmost importance. In order to select repairs
which are both smooth and maximally faithful to
the input, modulo the error site, of course, we com-
bined two methods: a discriminative PCFG-model
trained on a generation treebank, enhanced by an
n-gram language model, cf. (Velldal and Oepen,
2005), and an alignment approach that chooses the
most conservative edit from a set of input realisa-
tions. As our similarity measure, we employed a
variant of BLEU score (NEVA), suggested in (Fors-
bom, 2003). The probabilistic ranking models we
trained achieve an exact match accuracy of 73%
for both English (Velldal and Oepen, 2005) and
German (as evaluated on the subset of TiGer the
error corpus was based on).
3 Error corpora
In order to learn more about the frequencies of the
different error types, to induce statistical models
that allow us to obtain the best parse in the do-
main of technical manuals and to evaluate our im-
plemented approach to grammar and style check-
ing, we collected and manually annotated corpora
from the domain of technical documentation.
Since errors in pre-edited text tend to be very
scarcely distributed, manual annotation is quite
costly. As a result, instance of certain well-known
error types cannot be tested in a greater variety of
linguistic environments. To overcome this problem,
we semi-automatically derived an additional error
corpus from a treebank of German.
English For purposes of evaluation in a real
world scenario, we constructed a corpus for En-
glish, consisting of 12241 sentences (169459
words) from technical manuals. The corpus was
semi-automatically annotated with several types of
grammar and style errors. For this purpose annota-
tion guidelines were developed, which contained
the description of the errors together with exam-
ples of each and their possible corrections. The an-
notation took place in two phases. First, we wanted
to find out about the precision of the shallow sys-
tem, so we ran the shallow system over the data.
This resulted in an annotation for each error found
consisting of the erroneous sentence, the error span
and the type of error. The annotators, who were na-
tive speakers, then decided whether the errors had
been correctly detected. In the second phase, we
aimed to create a gold standard, so as to be able to
evaluate both the shallow system and Checkpoint
regarding recall and precision. For this purpose, we
extracted the errors that had been annotated as cor-
rectly detected in the previous phase and the an-
notators only had to find the non-detected errors
in the rest of the corpus. For the latter, they also
marked the span and identified the error type.
Subsets of these two datasets were treebanked
with the corresponding HPSG grammars. We em-
ployed the treebanking methodology developed for
Redwoods (Oepen et al, 2002), which involved
156
first parsing a corpus and recording for each item
the alternative analyses (the parse forest) assigned
by the grammar, then manually identifying the cor-
rect analysis (if available) within that parse forest.
This approach provides both a gold standard syn-
tactic/semantic analysis for each parsed item, and
positive and negative training data for building an
accurate statistical model for automatic parse selec-
tion.
German For German, we pursued a complemen-
tary approach towards corpus construction. Here
the focus lay on creating a test and evaluation cor-
pus that provided instances of common error types
in a variety of linguistic contexts. Since manual
error annotation is highly costly, owing to scarce
error distributions in pre-edited text, we chose to
automatically derive an error corpus from an ex-
isting treebank resource. As for the error types, we
focussed on those errors which are arguably perfor-
mance errors, as e.g. missing final consonants in in-
flectional endings, the confusion of homophonous
complementiser and relative pronoun, or else, edit-
ing errors, such as local and non-local duplicates.
We introduced instances of errors in a sub-
corpus of the German TiGer treebank (Brants
et al, 2002), nicknamed TiG-ERR, consisting of
77275 words (5652 sentences) from newspaper
texts. All the sentences in this subcorpus were
parsable, so that an evaluation of Checkpoint in
the ideal situation of 100% coverage could be car-
ried out. The artificially introduced errors were
of the following types: subject verb agreement,
NP internal agreement, dass/das, and repetitions,
all of them already illustrated with examples in sec-
tion 2.1.
Additionally, we annotated a corpus of technical
documents for these error types to estimate the dis-
tribution of these error types in pre-edited text.
4 Error models
In order to construct a statistical parse-ranking
model which could determine the intended use of
a MAL-rule in the analysis of a sentence where the
grammar produced analyses both with and without
MAL-rules, the English treebank was constructed
using the version of the ERG which included the
MAL-rules. 4000 sentences from the English cor-
pus were presented to the parser, of which 86.8%
could be parsed with the ERG, and of these, the an-
notators found an intended analysis for 2500 sen-
tences, including some which correctly used MAL-
rules. From these annotations, a customised parse
selection model was computed and then used in
parsing all of the corpus, this time recording only
the one analysis determined to be most likely ac-
cording to this model. We also compared accu-
racy of error detection based on this new model
with the accuracy of a pre-existing parse-selection
model trained on tourism data for LOGON, and
confirmed that the new model indeed improved
over the old one.
For German, we have not created a specific sta-
tistical model yet, but, instead, we have used an ex-
isting parse selection model (Crysmann, 2008) and
combined it with some heuristics which enable us
to select the best error hypothesis. The heuristics
check for each parsed sentence whether there is an
analysis containing no MAL-rule. If there is one
and this is not ranked as the best parse, it is moved
to the first position in the parse list. As a result, we
can eliminate a high percentage of false alarms.
5 Evaluation results
We have evaluated the English and the German ver-
sions of Checkpoint against the corpora described
in section 3.
German For German we have taken as a test
corpus standard the TiG-ERR subcorpus contain-
ing the automatically introduced errors, and have
parsed all its sentences. The following table shows
the frequencies of the different types of handled er-
rors in the corpus of technical manuals, the FLAG
error corpus (Becker et al, 2000), and in the TiG-
ERR corpus. The electronic version of the FLAG
corpus consists of 14,492 sentences, containing
1,547 grammar or style errors.
ERROR TYPE MANUALS FLAG TiG-ERR
NP internal agr 119 180 2258
subject verb agr 17 63 748
dass/das 1 152 75
repetitions 19 n/a 2571
Table 1: Frequencies of the error types for German
The following charts show the values for recall
and precision for the shallow system and Check-
point. As you can see, Checkpoint improves the
recall for the error types subject verb agreement
and NP internal agreement, whereas the precision
remains more or less the same. For the error type
dass/das Checkpoint improves both recall and pre-
cision. For the error type repetitions, which is only
partially handled by the spell checker in the shal-
low system, Checkpoint reaches considerable re-
call and precision values.
Deep processing on average improves the recall
of the shallow system by 21% and the precision
remains equal at 0.83. According to the error fre-
quencies in the corpus of technical manuals, deep
processing would improve the recall of the shallow
system by only 1.7%, since the error types sub-
ject verb agreement, NP internal agreement and
dass/das only make up 6.57% of the total amount
of annotated errors. However, as we found out later,
the corpora of technical manuals consist of texts
that have already undergone correction, so the er-
rors are very sparse.
157
Figure 1: Checkpoint values for recall and preci-
sion for German
Figure 2: Values for recall and precision for the
shallow system for German
Through the MAL-rules the coverage of the GG
on the TiG-ERR corpus increased to 85% - 95%,
whereas without the MAL-rules the coverage was
10%. This 10% coverage included overgeneration
by the grammar, as well as sentences that, after the
automatic insertion of errors, still remained gram-
matical, although they didn?t express the intended
meaning any more.
The performance of the parallel and integrated
scenarios was compared. The ambiguity of the
MAL-rules, that is, the possibility of applying sev-
eral MAL-rules to a unique error, considerably de-
teriorates the performance when processing sen-
tences containing several errors. In a subcorpus
containing NP internal agreement errors, the aver-
age processing time per sentence increases from
8.3 seconds with the selective activation of MAL-
rules to 31.4 seconds with the activation of all
MAL-rules. Particularly the MAL-rules modeling
the error subject verb agreement are a source of
ambiguity. If these MAL-rules are only selectively
activated the average processing time per sentence
decreases to 14.9 seconds.
Finally, we have evaluated the performance of
the German grammar in the task of error correction,
using non-local duplicates and adjectival agree-
ment errors as a test bed. For these error types,
the German HPSG grammar generated repairs for
85.4% of the detected non-local duplicates and
90% of the detected agreement errors.
English For English we have only implemented
and evaluated the parallel scenario. The focus for
English evaluation was the recognition of those
stylistic errors whose correction requires a re-
structuring of the sentence, and the generation of
the corresponding paraphrases. The recognition of
such error types is not based on MAL-rules, but
on certain already existing rules in the grammar.
The approach was evaluated taking the manually
annotated English corpus of technical manuals as
a gold standard. The following table shows the fre-
quencies of the error types handled by Checkpoint.
ERROR TYPE OCCURRENCES
avoid future 404
avoid modal verbs 657
avoid passive 213
Table 2: Frequencies of the error types for English
The PET parser with the ERG reached 86.1%
coverage on the full corpus. The following charts
show the values for recall and precision for Check-
point and the shallow system.
Figure 3: Checkpoint values for recall and preci-
sion for English
Figure 4: Values for recall and precision for the
shallow system for English
As one can see, for the stylistic errors
avoid future and avoid modal verbs, Checkpoint
reaches values which, although relatively high, are
lower than the shallow system. In most cases a
paraphrase for these errors can be constructed,
so the improvement Checkpoint provides here is
the generation of corrections. For the error type
avoid passive the precision is not so high, which
is due in part to mistakes in the manual annotation.
The passive sentences found by Checkpoint are
actually passive sentences. However, these were
158
not annotated as passives, because the annotators
were told to annotate only those stylistic errors
for which a paraphrase was possible. The same
happens for stylistic errors like avoid subjunctive,
use this that these those with noun and condi-
tion must precede action. In principle, Check-
point is very good at finding these types of errors,
but we cannot yet present a reliable evaluation here,
since only those errors were annotated for which
a paraphrase was possible. This approach is rea-
sonable, since no error alarm should be produced
when there is no other possibility of expressing the
same. However, since we have not yet developed
a method which allows us to automatically distin-
guish those cases for which a paraphrase is possi-
ble from those for which none is, we would need
to annotate all occurrences of a phenomenon in the
corpus, and introduce a further annotation tag for
the paraphrase potential of the sentence.
Nevertheless, even if the grammar-based re-
search prototype cannot beat the industrial pattern-
based system in terms of f-measures, we still be-
lieve that the results are highly valuable in the con-
text of our integrated hybrid scenario: Since the
full reversibility of the ERG has already been estab-
lished independently by (Velldal and Oepen, 2005),
the combined system is able to generate error cor-
rection for a great proportion of the errors detected
by the shallow component. This includes 80% and
above for avoid future and avoid modal verbs.
6 Summary and conclusions
In this paper we have presented an implemented
approach to grammar and style checking based on
hybrid processing. The hybrid system has two com-
ponents: a shallow grammar and style checking
system based on the FLAG technology, and the
PET deep parser operating on linguistically moti-
vated grammars for German and English. The Ger-
man version of the hybrid system improves the re-
call and in certain cases the precision of the shal-
low system and generates error corrections. For
English, the hybrid system in most cases success-
fully generates paraphrases of sentences contain-
ing stylistic errors. Although we only have ex-
plored some of the possibilities of integrating deep
and shallow processing for the grammar and style
checking application, these results speak for the
feasibility of using hybrid processing in this task.
We have developed an integrated strategy which
forwards the output of the shallow system, includ-
ing both the output from several pre-processing
linguistic modules and the error hypotheses, as in-
put to the deep parser. This procedure not only im-
proves the robustness of the deep parser with the
recognition of unknown words and reduces ambi-
guity by instantiating only those lexical items con-
sistent with the hypotheses of the POS tagger or
the morphology; but it also allows the selective
application of grammar rules, which considerably
reduces the search space for parsing and, conse-
quently, improves performance. Based on the error
hypotheses of the shallow system, the selective ap-
plication of grammar rules is achieved by positing
features in the Feature Structure Chart whose par-
ticular values are a pre-condition for MAL-rules
to apply. The improvement in performance sug-
gests that this strategy can be extensible to parsing
in general based on pre-processing components.
Given the output of a chunker, for example, certain
syntactic configurations can already be excluded.
Having features whose values allow one to switch
off certain rules not compatible with these con-
figurations would considerably reduce the search
space.
On the other hand, we have run the two mod-
ules independently from each other to find out
how the recall of the shallow system can be im-
proved by deep processing. The fact that for sev-
eral error types, such as subject verb agreement
and NP internal agreement, recall can be consider-
ably improved suggests that, in order not to parse
all sentences, the shallow system should send an
error hypothesis to the deep system when finding
particular syntactic configurations which may indi-
cate the occurrence of such errors. In this way, such
error hypotheses, although not reliably detectable
by the shallow system alone, could be confirmed
or discarded with a focussed application of deep
processing, which would not be as resource con-
suming as parsing every sentence.
One of the results of the experiment has been
an on-line demonstration system. The running sys-
tem shows that the different modules can be eas-
ily combined with each other. Our hybrid approach,
however, is generic and portable. Although imple-
mented for our specific baseline system, it can in
principle be used with other shallow systems.
Acknowledgements
The research reported in this paper has been car-
ried out as part of the DFKI project Checkpoint,
running from February until November 2007. The
project was funded by the ProFIT program of the
Federal State of Berlin and the EFRE program of
the European Union.
References
Adolphs P., S. Oepen, U. Callmeier, B. Crysmann, and
B. Kiefer. 2008. Some Fine Points of Hybrid Natural
Language Parsing. Proceedings LREC-2008, Mar-
rakech, Morocco.
Becker M., A. Bredenkamp, B. Crysmann, and J. Klein.
2003. Annotation of error types for a German news-
group corpus. In A. Abeille?, editor, Treebanks.
Building and Using Parsed Corpora, number 20 in
Text, Speech And Language Technology. Kluwer,
Dordrecht.
159
Bender, E. M., D. Flickinger, S. Oepen, A. Walsh,
and T. Baldwin. 2004. Arboretum: Using a preci-
sion grammar for grammar checking in call. In In-
STIL/ICALL symposium 2004. NLP and speech tech-
nologies in advanced language learning systems.
Venice, Italy.
Brants, T., S. Dipper, S. Hansen, W. Lezius, and G.
Smith. 2002. The TIGER Treebank. In Proceedings
of the Workshop on Treebanks and Linguistic Theo-
ries. Sozopol.
Bredenkamp, A., B. Crysmann and M. Petrea. 2000.
Looking for errors: A declarative formalism for
resource-adaptive language checking. In Proceed-
ings LREC-2000. Athens, Greece.
Bredenkamp, A., B. Crysmann and M. Petrea. 2000.
Building multilingual controlled language perfor-
mance checkers. In Proceedings of the CLAW 2000.
Seattle, WA.
Callmeier, U., A. Eisele, U. Scha?fer, and M. Siegel.
2004. The Deepthought core architecture frame-
work. In Proceedings of LREC-2004, 1205?1208,
Lisbon, Portugal.
Callmeier, Ulrich. 2000. PET ? a platform for ex-
perimentation with efficient HPSG processing tech-
niques. Natural Language Engineering 6(1):99?
108.
Carroll, John and Ann Copestake and Dan Flickinger
and Victor Poznanski. 1999. An efficient chart gen-
erator for semi-lexicalist grammars. Proceedings of
ENLG, pp. 86?95.
Copestake, A., and D. Flickinger. 2000. An open-
source grammar development environment and
broad-coverage english grammar using HPSG. In
Proceedings LREC-2000. Athens, Greece.
Copestake, A., D. Flickinger, C. Pollard, and I. Sag.
2006. Minimal recursion semantics: an introduction.
Research on Language and Computation 3(4):281?
332.
Crysmann, B., A. Frank, B. Kiefer, S. Mu?ller, G. Neu-
mann, J. Piskorski, U. Scha?fer, M. Siegel, H. Uszko-
reit, F. Xu, M. Becker, and H.-U. Krieger. An inte-
grated architecture for shallow and deep processing.
In Proceedings of ACL 2002, University of Pennsyl-
vania, Philadelphia, 2002.
Crysmann B. 2005. Relative clause extraposition in
German: An efficient and portable implementation.
Research on Language and Computation, 3(1):61?
82.
Crysmann B. 2007 Local ambiguity packing and dis-
continuity in German. In T. Baldwin, M. Dras,
J. Hockenmaier, T. H. King, and G. van Noord, ed-
itors, Proceedings of the ACL 2007 Workshop on
Deep Linguistic Processing, pages 144?151, Prague,
Czech Republic.
Crysmann B. 2008. Parse Selection with a German
HPSG Grammar. In S. Ku?bler and G. Penn, editors,
Proceedings of the ACL 2008 Workshop on Parsing
German (PaGe), pages 9?15, Columbus, Ohio, USA.
Douglas, S. 1995. Robust PATR for error detec-
tion and correction. In A. Schoeter and C. Vogel
(Eds.)Nonclassical feature systems, Vol. 10, pp. 139-
156. Centre for Cognitive Science, University of Ed-
inburgh.
Forsbom, E. 2003. Training a Super Model Look-
Alike. Proceedings of the MT Summit IX Workshop
?Towards Systemizing MT Evaluation?, pp. 29-36.
Gaizauskas, R., H. Cunningham, Y. Wilks, P. Rodgers
and K. Humphreys. 1996. GATE: An environment
to support research and development in natural lan-
guage engineering. In Proceedings of the 8th IEEE
international conference on tools with artificial in-
telligence. Toulouse, France.
Jensen, K., G. E., Heidorn and S. D. Richardson (Eds.).
1993. Natural language processing: The PLNLP ap-
proach. Boston - Dordrecht - London.
Haller, J. 1996. MULTILINT: A technical documenta-
tion system with multilingual intelligence. In Trans-
lating and the computer 18. London.
Heinecke, J., J. Kunze, W. Menzel, and I. Schroeder.
1998. Eliminative parsing with graded constraints.
In Proceedings ACL/Coling 1998, Vol. I, pp. 526-
530. Universite de Montreal, Montreal, Quebec,
Canada.
L?nning J. T. , S. Oepen, D. Beermann, L. Hellan, J.
Carroll, H. Dyvik, D. Flickinger, J. B. Johannessen,
P. Meurer, T. Nordga?rd, V. Rose?n and E. Velldal.
2004. LOGON. A Norwegian MT effort. In Pro-
ceedings of the Workshop in Recent Advances in
Scandinavian Machine Translation. Uppsala, Swe-
den.
McCoy, K. F., C. A. Pennington, and L. Z. Suri. 1996.
English error correction: A syntactic user model
based on principled ?mal-rule? scoring. In Proceed-
ings of UM-96, the Fifth International Conference on
User Modeling, pp. 59-66. Kona, Hawaii.
Menzel, W. 1998. Constraint satisfaction for robust
parsing of natural language. In Theoretical and Ex-
perimental Artificial Intelligence, 10 (1), 77-89.
Mu?ller, S., and W. Kasper. 2000. HPSG analysis of
German. In W. Walster (Ed.), Verbmobil: Foun-
dations of Speech-to-Speech Translation, 238?253
Springer, Berlin.
Oepen, S., K. Toutanova, S. Shieber, C. Manning, D.
Flickinger and T Brants. 2002. The LinGO Red-
woods Treebank. Motivation and Preliminary Appli-
cations. In Proceedings of COLING 2002. Taipei,
Taiwan.
Ravin, Y. 1998. Grammar errors and style weaknesses
in a text-critiquing system. In IEEE Transactions on
Communication, 31 (3)
Schmidt-Wigger, A. 1998. Grammar and style check-
ing for German. In Proceedings of CLAW 98. Pitts-
burgh, PA.
Velldal, E. and S. Oepen. 2005. Maximum entropy
models for realization ranking. In Proceedings of
the 10th MT-Summit (X), Phuket, Thailand.
160
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,
pages 100?104, Dublin, Ireland, August 23-29 2014.
A Marketplace for Web Scale Analytics and Text Annotation Services
Johannes Kirschnick
1
, Torsten Kilias
1
, Holmer Hemsen
1
Alexander L
?
oser
2
, Peter Adolphs
3
, Heiko Ehrig
3
, Holger D?uwiger
3
(1) Technische Universit?at Berlin, Einsteinufer 17, 10587 Berlin, Germany
{firstname.lastname}@tu-berlin.de
(2) Beuth Hochschule f?ur Technik Berlin, Luxemburger Stra?e 10, 13353 Berlin, Germany
aloeser@beuth-hochschule.de
(3) Neofonie GmbH, Robert-Koch-Platz 4, 10115 Berlin, Germany
{firstname.lastname}@neofonie.de
Abstract
We present MIA, a data marketplace which enables massive parallel processing of data from
the Web. End users can combine both text mining and database operators in a structured query
language called MIAQL. MIA offers many cost savings through sharing text data, annotations,
built-in analytical functions and third party text mining applications. Our demonstration show-
cases MIAQL and its execution on the platform for the example of analyzing political campaigns.
1 Introduction
Data-driven services and data marketplaces are young phenomena (Schomm et al., 2013). Commonly
known commercial examples are Factual.com for location-related data, Amazon as a marketplace for
infrastructure and data, and Microsoft?s datamarket.azure.com. These marketplaces offer common data
flow and service characteristics (Muschalle et al., 2012). MIA is such a marketplace, it offers data driven
services in the area of natural language processing in combination with business intelligence services for
analyzing more than 600 million pages of the German language Web (from 2013-2014). The user can
combine linguistic components with standard SQL operators in data execution pipes to create new data
sets. The marketplace permits the user to keep the insightful data exclusive or to grant access permissions
to other users for data, annotation services or pipelines. MIA enables to turn the Web, a particular rich
source of information using extraction, processing and enrichment tasks (e.g., parsing or semantically
annotating) into a valuable knowledge resources to support various business intelligence (BI) tasks. Such
tasks are exemplified by the following questions from the area of political campaign analysis:
? What is the polarity (sentiment) associated with events found in online news media?
? Which newspapers are biased in the last years towards certain political parties?
The MIA project started in 2011, since then we observed many similar queries and demands from sales
departments (monitor and identify leads that soon will buy a car), human resources (identify professionals
with capabilities in text mining), market research (monitor the effectiveness of a campaign) as well as
product development (incorporate feedback from customers into the development process).
1.1 Background
Transforming huge volumes of text into structured information that is suitable and useful for empowering
applications in heterogeneous and previously unknown application areas is a challenge. MIA addresses
this using own and third party research in the areas of text mining and distributed databases.
Single system for analytical and NLP tasks. The parse tree database (PTDB) by Tari (2012) stores
dependency tagged sentences and retrieves subtrees with a key value index based on Lucene. MIA goes
drastically beyond this functionality. It enables GATE (gate.ac.uk) and UIMA (uima.apache.
org) developers to integrate their components. This greatly expands the available processing modules
This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are
added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
100
on the platform as existing pipelines can be easily incorporated into the marketplace. Furthermore,
it gives users the ability to store and retrieve lexical, syntactic and semantic annotations. The MIA
platform executes these components as user-defined functions in a massively parallel database, enables
the aggregation of resulting annotations with other data sources, such as in-house relational databases,
and conducts these operations, all in a single system. AnnoMarket (Tablan et al., 2013) is a marketplace
for executing GATE pipelines and permits to upload third party extractors, but lacks the functionality to
aggregate and join results. Rather, it requires the user to ship preliminary results to a database where the
user conducts advanced analytical tasks. However, companies may eschew the high investment risk and
the technical difficulties to ship and analyze hundreds of millions of documents.
Declarative languages for text mining. System-T (Chiticariu et al., 2010) includes AQL, a declarative
language for defining extractors through rules. MIAQL extends this idea with SQL predicates for sub-
queries, views, joins and for data crawling that operate on datasets represented as collections of nested
tuples. MIA?s data model incorporates a span-algebra and operators for processing sequences or trees
(Kilias et al., 2013). MIA also leverages our research for extracting relations (Akbik et al., 2012) and for
restricting attribute types (Kirschnick et al., 2013) which builds on the provided abstractions.
1.2 Our Contribution
MIAQL: Text mining and analytical tasks with a single structured query language. We demon-
strate how our declarative language MIAQL empowers end users to describe text mining tasks. MIAQL
also supports common SQL-92 operations, such as joins, views, sub-queries, aggregations and group by.
We showcase how our parallel execution framework compiles a MIAQL query into a dataflow represen-
tation and finally into a set of map/reduce tasks (Dean and Ghemawat, 2008).
Data marketplace for annotation services. We showcase how data providers can integrate data sets,
developers can share modules for text mining or data analytics, application vendors can offer specialized
applications and analysts can use the raw or annotated data for ad-hoc queries.
Optimizations for Web-scale corpora. We showcase on 600 million pages from the German language
Web how our parallel execution framework optimizes queries for distributed multi-core environments and
for file-, key-value- and column-based datastores, such as HBase
1
or the Parquet.io
2
file format.
2 Demonstration
Scenario: How biased are newspapers? Consider an analyst with the hypothesis that certain newspa-
pers bias their reports towards certain political parties. Listing 1 shows a set of queries for determining
such a bias. For solving this task the analyst must first obtain a news corpus, either by crawling or by
buying and downloading the documents. Next, the analyst formulates a query for spotting sentences
that mention a politician and computes the subjectivity. Finally, the analyst counts these tuples over all
documents, groups them by the newspaper/party, aggregates the subjectivity and sorts the results.
2.1 Execution Environment for the Obtain-Annotate-Join-Aggregate-Process
This and many other monitoring processes follow the same schema: Obtaining already exclusive data,
such as fresh data, and make data even more exclusive by complementing (joining), aggregating and
sorting it. Nearly every company uses similar processes in the data warehouse on relational data but not
on text data from the Web. MIA supports this process now also on hundreds of millions of Web pages
with the following technologies:
Simple SQL interface for analysts. MIAQL provides standard SQL-92 statements for data aggrega-
tion, such as COUNTS, MIN, MAX, AVG, GROUP BY, including sub-queries and views. As a result,
MIAQL presents a familiar environment for data analysts and reduces the necessity to learn a new query
language. For example, listing 1 shows aggregations for counting and averaging the subjectivity for each
1
https://hbase.apache.org (Last visited: 16/5/2014)
2
http://parquet.io (Last visited: 16/5/2014)
101
1 CREATE VIEW sentences AS
2 SELECT srcName,text,unnest(splitSentences(text)) AS sentence
3 FROM news2013;
4
5 CREATE VIEW sentencesWithPOSTags AS
6 SELECT
*
,annotatePOSTags(sentence) AS posTags
7 FROM sentences;
8
9 CREATE VIEW sentencesWithSubjectivity AS
10 SELECT
*
,isSentenceSubjective(text,sentence,posTags) AS
sentenceSubjective
11 FROM sentencesWithPOSTags;
12
13 CREATE VIEW sentencesWithEntities AS
14 SELECT
*
,unnest(annotateEntites(sentence, posTags)) AS entity
15 FROM sentencesWithSubjectivity;
16
17 CREATE VIEW filterSentencesWithPoliticians AS
18 SELECT
srcName,party,politician,booleanToInt(sentenceSubjective)
AS subjectivity
19 FROM sentencesWithEntities AS s
JOIN politicians AS p ON s.uri=p.uri;
20
21 SELECT srcName,party,politician,COUNT(
*
), AVG(subjectivity)
22 FROM filterSentencesWithPoliticians
23 GROUP BY srcName, party, politician;
Listing 1: The listing shows a set of views in MIAQL
for correlating mentions of politicians in newspapers and
detecting whether the reporting is subjective. The MIAQL
optimizer compiles this into an execution plan, see Figure 1
for an example.
List of 
Politicians
News
2013
Sentence
Splitting
POS
Annotation
Detect
Subjectivity
Annotate
Entities
AGGREGATE
JOIN
Obtain
Data
Annotate 
Data
External 
Data
Figure 1: MIA supports user defined
functions, optimizes equi, theta and
cross joins into local, broadcast and
repartitioning joins and supports com-
mon aggregate functions of SQL-92.
newspaper and politician/party pair. The query is transparently compiled into the data flow description
language Pig Latin (Olston et al., 2008). This allows programs defined in MIAQL to be processed in a
massively parallel way on a Hadoop system (Dean and Ghemawat, 2008). Figure 1 highlights the execu-
tion plan for the sample MIAQL query, which uses different data sources, processes them by executing
a chain of annotators, joins the results and aggregates them to produce the final answer.
Reuse base annotators and user defined annotators. We observed from our users the need to enrich
raw data with linguistic annotations at various levels. Users of the platform might be interested in named
entities and their referents, topic labels or sentiment judgements for which they need to run specialized
annotators. These annotators in turn might also depend on other levels of linguistic analysis. To prevent
multiple processing of the same data with the same tools, the MIA platform crawls raw data and anno-
tates it on ingestion at the most common linguistic levels. Multiple users can access these annotations
across their projects and can thus save costs. For example, MIA performs sentence splitting, tokeniza-
tion, lemmatization, part-of-speech tagging, named-entity recognition and a document-specific topic
detection for each document. Other processing steps such as dependency parsing or entity linking (Kem-
merer et al., 2014) can be applied on the fly at query time. Analysts may reuse this data in domain specific
annotation functions. In the above listing the subjectivity analysis function reuses for example sentence
boundaries and part-of-speech tags. The system executes such transformations as user-defined functions.
Multiple functions are grouped into logical modules and registered on the platform for reuse, each with
an associated description and a schema mapping from input to output tuples.
Complement Web data with in-house data. MIA permits users to upload in-house data to the dis-
tributed file system with restricted visibility. Our users join this data with the goal of complementing
with existing data. For example, in the listing above a list of German politicians is joined with the list of
extracted sentences to filter out all sentences that are not mentioning one of the defined politicians.
3 Lessons Learned
Data freshness, completeness and veracity. MIA?s strongest asset is the ability to complement exist-
ing (possibly exclusive) in-house data with ?signals? from the Web, avoiding huge data set shipments.
102
MIAQL Application
Marketplace
Data & Modules
          Hadoop
Execution Environment
Select 
from
Repository
HDFS
Custom
Module
Custom
Data
Modules Data abstractions
HBASE ...
Issue
Query
Analyst Developer
write
Re- usable
Analytics
Results
Pig Latin 
Script
Compile Results
Execute
DB
DB
Monitor
Provides
 Backends
Figure 2: This figure shows the architecture of the marketplace. It contains the repository for data sets
and text mining code modules. Developers can upload text mining modules, content providers can upload
data sets and grant selected analysts reuse permissions. The application provides analysts with a Web
interface for browsing the repository, authoring new MIAQL queries and downloading analytic results.
Queries are transparently compiled into Pig Latin and executed on the distributed platform.
The Pig-Latin-based query processing engine provides users with answers within minutes. Currently, our
users tolerate these answering times, for example for monitoring applications. However, users also often
request fresh (minutes- hours) data, for tighter feedback loop integrations. Realizing short updates and
low latency response times are research topics of the project, as well as delivering higher level insights
beyond tabular reports, such as automated visualization and result clustering.
Cloud-based one-stop-shop marketplace vs. on-premise solution. Users can protect their data, func-
tionality and processing results. However, some require running the MIA platform ?behind their fire-
walls?. Currently, they need to ?download? the processed results and execute the join in-house with their
?secret? data. For these users, we investigate operations for selecting the likely minimal and fresh but
still highly complete data sets, such as L?oser et al. (2013).
4 Current Status
The marketplace is currently available in private beta mode and accessible via a Web UI, which is dis-
played in Figure 3. Users can author, execute and monitor new jobs as well as inspect and download the
results, while developers can create and upload new processing modules. New modules can be created
by adhering to a simple tuple based processing interface defined by the platform, which greatly reduces
the friction of writing new modules and leveraging existing text pipelines. The available public datasets
are constantly expanded by continuously crawling the German Web, uploading new news articles and
incorporating new social media posts.
While the project is targeted at providing large scale processing for German language texts, the core
software platform is not tied to a particular language. All language specific contributions are packaged
into separate data and processing modules. Supporting a new language sums up to creating and uploading
new data and algorithm packages. More information as well as a demonstration video for MIA can
be found at the project website www.neofonie.de/forschung/mia. We furthermore encourage
requesting a demo login to the system.
Acknowledgments
We would like to thank the anonymous reviewers for their helpful comments. The work to build the
demonstrator and the underlying technologies received funding from the German Federal Ministry of
103
Figure 3: This figure shows the sophisticated execution environment presented by the MIA platform.
The Web-driven UI supports the analysts with query authoring, data and function modules browsing as
well as job monitoring and results download.
Economics and Energy (BMWi) under grant agreement 01MD11014A, ?A cloud-based Marketplace for
Information and Analytics on the German Web? (MIA).
References
Alan Akbik, Larysa Visengeriyeva, Priska Herger, Holmer Hemsen, and Alexander L?oser. 2012. Unsupervised
Discovery of Relations and Discriminative Extraction Patterns. In COLING, pages 17?32.
Laura Chiticariu, Rajasekar Krishnamurthy, Yunyao Li, Sriram Raghavan, Frederick Reiss, and Shivakumar
Vaithyanathan. 2010. SystemT: An Algebraic Approach to Declarative Information Extraction. In ACL, pages
128?137.
Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce: Simplified Data Processing on Large Clusters. Commun.
ACM, 51(1):107?113, January.
Steffen Kemmerer, Benjamin Gro?mann, Christina M?uller, Peter Adolphs, and Heiko Ehrig. 2014. The neofonie
nerd system at the erd challenge 2014. SIGIR Forum. To appear.
Torsten Kilias, Alexander L?oser, and Periklis Andritsos. 2013. INDREX: in-database distributional relation ex-
traction. In DOLAP, pages 93?100.
Johannes Kirschnick, Alan Akbik, Larysa Visengeriyeva, and Alexander L?oser. 2013. Effective Selectional Re-
strictions for Unsupervised Relation Extraction. In IJCNLP. The Association for Computer Linguistics.
Alexander L?oser, Christoph Nagel, Stephan Pieper, and Christoph Boden. 2013. Beyond search: Retrieving
complete tuples from a text-database. Information Systems Frontiers, 15(3):311?329.
Alexander Muschalle, Florian Stahl, Alexander L?oser, and Gottfried Vossen. 2012. Pricing Approaches for Data
Markets. In BIRTE, pages 129?144.
Christopher Olston, Benjamin Reed, Utkarsh Srivastava, Ravi Kumar, and Andrew Tomkins. 2008. Pig latin:
a not-so-foreign language for data processing. In Jason Tsong-Li Wang, editor, SIGMOD Conference, pages
1099?1110. ACM.
Fabian Schomm, Florian Stahl, and Gottfried Vossen. 2013. Marketplaces for data: an initial survey. SIGMOD
Record, 42(1):15?26.
Valentin Tablan, Kalina Bontcheva, Ian Roberts, Hamish Cunningham, and Marin Dimitrov. 2013. AnnoMarket:
An Open Cloud Platform for NLP. In ACL (Conference System Demonstrations), pages 19?24.
Luis Tari, Phan Huy Tu, J?org Hakenberg, Yi Chen, Tran Cao Son, Graciela Gonzalez, and Chitta Baral. 2012.
Incremental information extraction using relational databases. IEEE Trans. Knowl. Data Eng., 24(1):86?99.
104
Proceedings of the EACL 2009 Demonstrations Session, pages 13?16,
Athens, Greece, 3 April 2009. c?2009 Association for Computational Linguistics
GOSSIP GALORE
A Self-Learning Agent for Exchanging Pop Trivia
Xiwen Cheng, Peter Adolphs, Feiyu Xu, Hans Uszkoreit, Hong Li
DFKI GmbH, Language Technology Lab
Stuhlsatzenhausweg 3, D-66123 Saarbru?cken, Germany
{xiwen.cheng,peter.adolphs,feiyu,uszkoreit,lihong}@domain.com
Abstract
This paper describes a self-learning soft-
ware agent who collects and learns knowl-
edge from the web and also exchanges her
knowledge via dialogues with the users.
The agent is built on top of information
extraction, web mining, question answer-
ing and dialogue system technologies, and
users can freely formulate their questions
within the gossip domain and obtain the
answers in multiple ways: textual re-
sponse, graph-based visualization of the
related concepts and speech output.
1 Introduction
The system presented here is developed within the
project Responsive Artificial Situated Cognitive
Agents Living and Learning on the Internet (RAS-
CALLI) supported by the European Commission
Cognitive Systems Programme (IST-27596-2004).
The goal of the project is to develop and imple-
ment cognitively enhanced artificial agents, using
technologies in natural language processing, ques-
tion answering, web-based information extraction,
semantic web and interaction driven profiling with
cognitive modelling (Krenn, 2008).
This paper describes a conversational agent
?Gossip Galore?, an active self-learning system
that can learn, update and interpret information
from the web, and can make conversations with
users and provide answers to their questions in the
domain of celebrity gossip. In more detail, by
applying a minimally supervised relation extrac-
tion system (Xu et al, 2007; Xu et al, 2008), the
agent automatically collects the knowledge from
relevant websites, and also communicates with the
users using a question-answering engine via a 3D
graphic interface.
This paper is organized as follows. Section 2
gives an overview of the system architecture and
Figure 1: Gossip Galore responding to ?Tell me
something about Carla Bruni!?
presents the design and functionalities of the com-
ponents. Section 3 explains the system setup and
discusses implementation details, and finally Sec-
tion 4 draws conclusions.
2 System Overview
Figure 1 shows a use case of the system. Given a
query ?Tell me something about Carla Bruni?, the
application would trigger a series of background
actions and respond with: ?Here, have a look at
the personal profile of Carla Bruni?. Meanwhile,
the personal profile of Carla Bruni, would be dis-
played on the screen. The design of the interface
reflects the domain of celebrity gossip: the agent
is depicted as a young lady in 3D graphics, who
communicates with users. As an additional fea-
ture, users can access the dialogue memory of the
system, which simulates the human memory in di-
alogues. An example of the dialogue memory is
sketched in Figure 2.
As shown in Figure 3, the system consists of a
number of components. In principle, first, a user?s
query is linguistically analyzed, and then inter-
13
Dialogue
State
Dialogue
Memory
MM GeneratorResponseHandler
NE RecognizerSpellChecker Parser
Anaphora
Resolver
Knowledge
Base
Web
Miner
Input
Interpreter
Input
Analyzer
Relation
Extractor
Information
Wrapper
NL Generator
Conversational
Agent
Figure 3: Agent architecture and interaction of components
Figure 2: Representation of Social Network in Di-
alogue Memory
preted with respect to the context of the dialogue.
A Response Handler will then consult the knowl-
edge base pre-constructed by extracting relevant
information from the Web, and pass the answer, in
an abstract representation, to a Multimodal Gener-
ator, which realizes and presents the answer to the
user in multiple ways. The main components are
described in the following sections.
2.1 Knowledge Base
The knowledge base is automatically built by the
Web Miner. It contains knowledge regarding prop-
erties of persons or groups and their social rela-
tionships. The persons and groups that we concern
are celebrities in the entertainment industry (e.g.,
singers, bands, or movie stars) and their relatives
(e.g., partners) and friends. Typical properties of a
person include name, gender, birthday, etc., and
profiles of celebrities contain additional proper-
ties such as sexual orientation, home pages, stage
names, genres of their work, albums, and prizes.
Social relationships between the persons/groups
such as parent-child, partner, sibling, influenc-
ing/influenced and group-member, are also stored.
2.2 Web Miner
The Web Miner fetches relevant concepts and their
relations by means of two technologies: a) infor-
mation wrapping for exaction of personal profiles
from structured and semi-structured web content,
and b) a minimally supervised machine learning
method provided by DARE (Xu et al, 2007; Xu
et al, 2008) to acquire relations from free texts.
DARE learns linguistic patterns indicating the tar-
get semantic relations by taking some relation in-
stances as initial seed. For example, assume that
the following seed for a parent-child relationship
is given to the DARE system:
(1) Seed: ?Angelina Jolie, Shiloh Nouvel Jolie-Pitt,
daughter?
One sentence that matches the entities men-
tioned in the seed above could be (2), and from
which the DARE system can derive a linguistic
pattern as shown in 3.
(2) Matched sentence: Angelina Jolie and Brad Pitt
welcome their new daughter Shiloh Nouvel Jolie-Pitt.
(3) Extracted pattern: ?subject: celebrity? welcome
?mod: ?new daughter?? ?object: person?
Given the learned pattern, new instances of the
?parent-child? relationship can be automatically
discovered, e.g.:
(4) New acquired instances: ?Adam Sandler, Sunny
Madeline? ?Cynthia Rodriguez, Ella Alexander?
Given the discovered relations among the
celebrities and other people, the system constructs
a social network, which is the basis for providing
answers to users? questions regarding celebrities?
relationships. The network also serves as a re-
source for the active dialogue memory of the agent
as shown in Figure 2.
14
2.3 Input Analyzer and Input Interpreter
The Input Analyzer is designed as both domain
and dialogue context independent. It relies on sev-
eral linguistic analysis tools: 1) a spell checker, 2)
a named entity recognizer SProUT (Drozdzynski
et al, 2004), and 3) a syntactic parsing component
for which we currently employ a fuzzy paraphrase
matcher to approximate the output of a deep syn-
tactic/semantic parser.
In contrast to the Input Analyzer, the Input In-
terpreter analyzes the input with respect to the
context of the dialogue. It contains two major
components: 1) anaphoric resolution, which refers
pronouns to previously mentioned entities with the
help of the dialogue memory, and 2) domain clas-
sification, which determines whether the entities
contained in a user query can be found in the gos-
sip knowledge base (cf. ?Carla Bruni? vs. ?Nico-
las Sarkozy?) and whether the answer focus be-
longs to the domain (cf. ?stage name? vs ?body
guard?). For example, a simple factoid query such
as ?Who is Madonna?, an embedded questions
like ?I wonder who Madonna is?, and expressions
of requests and wishes such as ?I?m interested in
Madonna?, would share the same answer focus,
i.e., the ?personal profile? of ?Madonna?. In ad-
dition to the simple answer types such as ?person
name?, ?location? and ?date/time?, our system can
also deal with complex answer focus types such as
?personal profile?, ?social network? and ?relation
path?, as well as domain-relevant concepts such as
?party affiliation? or ?sexual orientation?.
Finally, the analysis of each query is associated
with a meaning representation, an answer focus
and an expected answer type.
2.4 Response Handler
This component executes the planned action based
on the properties of the answer focus and the en-
tities in a query. In cases where the answer focus
or the entities cannot be found in the knowledge
base, the system would still attempt to provide a
constructive answer. For instance, if a question
contains a domain-specific answer focus but en-
tities unknown to the knowledge base, the agent
will automatically look for alternative knowledge
resources, e.g., Wikipedia. For example, given
the question ?Tell me something about Nicolas
Sarkozy!?, the agent would attempt a Web search
and return the corresponding page on Wikipedia
about ?Nicolas Sarkozy?, even if the knowledge
base does not contain his information since he is a
politician rather than an entertainer.
In addition, specific strategies have been devel-
oped to deal with negative answers. For instance,
the agent would answer the question: When did
Madonna die?, with ?As far as I know, Madonna
is still alive.?, as it cannot find any information re-
garding Madonna?s death.
2.5 Multimodal Generator
The agent (i.e., the young lady in Figure 1) is
equipped with multimodal capabilities to inter-
act with users. It can show the results in tex-
tual and speech forms, using body gestures, fa-
cial expressions, and finally via multimedia out-
put to an embedded screen. We currently employ
template-based generators for producing both the
natural language utterances and the instructions to
the agent that controls the multimodal communi-
cation with the user.
2.6 Dialogue State
The responsibility of this component is to keep
track of the current state of the dialogue between a
user and the agent. It models the system?s expec-
tation of the user?s next action and the system?s re-
actions. For example, if a user misspelled a name
as in the question ?Who is Roby Williams??, the
system would answer with a clarification question:
?Did you mean Robbie Williams?? The user is
then expected to react to the question with either
?yes? or ?no?, which would not be interpretable in
other dialogue contexts where the user is expected
to ask a question. The fact that the system asks a
clarification question and expects a yes/no answer
as well as the repaired question are stored in the
Dialogue State component.
2.7 Dialogue Memory
This component aims to simulate the cognitive ca-
pacity of the memory of a human being: con-
struction of a short-time memory and activation
of long-time memory (our Knowledge Base). It
records the sequence of all entities mentioned dur-
ing the conversation and their respective target
foci. Simultaneously, it retrieves all the related in-
formation from the Knowledge Base. In figure 2,
the dialogue memory for the three questions ?Tell
me something about Carla Bruni.?, ?Can you tell
me some news about her??, ?How many kids does
Brad Pitt have?? is shown. Green and yellow bub-
bles are entities mentioned in the dialogue context,
15
where the yellow one is the last mentioned entity.
White bubbles indicate the newest records which
are acquired in the last process of online QA.
3 Implementation
The system uses a client-server architecture. The
server is responsible for accepting new connec-
tions, managing accounts, processing conversa-
tions and passing responses to the clients. All
the server-side functions are implemented in Java
1.6. We use Jetty as a web server to deliver mul-
timedia representations of an answer and to pro-
vide selected functionalities of the system as web
services to our partners. The knowledge base is
stored in a MySQL database whose size is 11MB,
and contains information of 38,758 persons in-
cluding 16,532 artists and 1,407 music groups. As
for the social connection data, there are 14,909
parent-child, 16,886 partner, 4,214 sibling, 308
influence/influenced and 9,657 group-member re-
lational pairs. The social network is visualized
in JGraph, and speech output is generated by the
open-source speech synthesis system OpenMary
(Schro?der and Hunecke, 2007).
There are two interfaces realizing the client-
side of the system: a 3D software application and
a web interface. The software application uses
a 3D computer game engine, and communicates
with the server by messages in an XML format
based on BML and SSML. In addition, we provide
a web interface1, implemented using HTML and
Javascript on the browser side, and Java Servlets
on the server side, offering the same core func-
tionality as the 3D client.
Both the server and the web client are platform
independent. The 3D client runs on Windows with
a dedicated 3D graphics card. The recommended
memory for the server is 1GB.
4 Conclusions
This paper describes a fully implemented software
application, which discovers and learns informa-
tion and knowledge from the Web, and communi-
cates with users and exchanges gossip trivia with
them. The system uses many novel technologies
in order to achieve the goal of vividly chatting and
interacting with the users in a fun way. The tech-
nologies include information extraction, question
answering, dialogue modeling, response planning
and multimodal presentation generation. Please
1http://rascalli.dfki.de/live/dialogue.page
refer to (Xu et al, 2009) for additional details
about the ?Gossip Galore? system.
The planned future extensions include the in-
tegration of deeper language processing methods
to discover more precise linguistic patterns. A
prime candidate for this extension is our own deep
syntactic/semantic parser. Another plan concerns
the required temporal aspects of relations together
with credibility checking. Finally, we plan to ex-
ploit the dialogue memory for moving more of the
dialogue initiative to the agent. In cases of miss-
ing or negative answers or in cases of pauses on
the user side, the agent can use the active parts
of the dialogue memory to propose additional rel-
evant information or to guide the user to fruitful
requests within the range of user?s interests.
References
Witold Drozdzynski, Hans-Ulrich Krieger, Jakub Piskorski,
Ulrich Scha?fer, and Feiyu Xu. 2004. Shallow processing
with unification and typed feature structures ? foundations
and applications. Ku?nstliche Intelligenz, 1:17?23.
Brigitte Krenn. 2008. Responsive artificial situated cognitive
agents living and learning on the internet, April. Poster
presented at CogSys 2008.
Marc Schro?der and Anna Hunecke. 2007. Mary tts partici-
pation in the Blizzard Challenge 2007. In Proceedings of
the Blizzard Challenge 2007, Bonn, Germany.
Feiyu Xu, Hans Uszkoreit, and Hong Li. 2007. A seed-
driven bottom-up machine learning framework for extract-
ing relations of various complexity. Proceedings of ACL-
2007, pages 584?591.
Feiyu Xu, Hans Uszkoreit, and Hong Li. 2008. Task driven
coreference resolution for relation extraction. In Proceed-
ings of ECAI 2008, Patras, Greece.
Feiyu Xu, Peter Adolphs, Hans Uszkoreit, Xiwen Cheng, and
Hong Li. 2009. Gossip galore: A conversational web
agent for collecting and sharing pop trivia. In Joaquim
Filipe, Ana Fred, and Bernadette Sharp (eds). Proceed-
ings of ICAART 2009, Porto, Portugal.
16
Proceedings of the ACL 2010 System Demonstrations, pages 36?41,
Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics
Talking NPCs in a Virtual Game World
Tina Klu?wer, Peter Adolphs, Feiyu Xu, Hans Uszkoreit, Xiwen Cheng
Deutsches Forschungszentrum fu?r Ku?nstliche Intelligenz (DFKI)
Projektbu?ro Berlin
Alt-Moabit 91c
10559 Berlin
Germany
{tina.kluewer,peter.adolphs,feiyu,uszkoreit,xiwen.cheng}@dfki.de
Abstract
This paper describes the KomParse sys-
tem, a natural-language dialog system
in the three-dimensional virtual world
Twinity. In order to fulfill the various
communication demands between non-
player characters (NPCs) and users in
such an online virtual world, the system
realizes a flexible and hybrid approach
combining knowledge-intensive domain-
specific question answering, task-specific
and domain-specific dialog with robust
chatbot-like chitchat.
1 Introduction
In recent years multi-user online games in virtual
worlds such as Second Life or World of Warcraft
have attracted large user communities. Such vir-
tual online game worlds provide new social and
economic platforms for people to work and inter-
act in. Furthermore, virtual worlds open new per-
spectives for research in the social, behavioral, and
economic sciences, as well as in human-centered
computer science (Bainbridge, 2007). Depending
on the game type, non-player characters (NPCs)
are often essential for supporting the game plot,
for making the artificial world more vivid and ulti-
mately for making it more immersive. In addition,
NPCs are useful to populate new worlds by carry-
ing out jobs the user-led characters come in touch
with. The range of functions to be filled by NPCs
is currently still strongly restricted by their limited
capabilities in autonomous acting and communi-
cation. This shortcoming creates a strong need for
progress in areas such as AI and NLP, especially
their planning and dialog systems.
The KomParse system, described in this paper,
provides NPCs for a virtual online world named
Twinity, a product of the Berlin startup company
Metaversum1. The KomParse NPCs offer vari-
ous services through conversation with game users
using question-answering and dialog functional-
ity. The utilization of Semantic Web technology
with RDF-encoded generic and domain-specific
ontologies furthermore enables semantic search
and inference.
This paper is organized as follows: Section 2
presents the NPC modelling and explains the ap-
plication scenarios. Section 3 details the knowl-
edge representation and semantic inference in our
system. Section 4 explains the system architecture
and its key components. Section 5 describes the
KomParse dialog system. Section 7 gives a con-
clusion and closes off with our future work.
2 Application Scenario and NPC
Modelling
The online game Twinity extends the Second Life
idea by mirroring an urban part of the real world.
At the time of this writing, the simulated section of
reality already contains 3D models of the cities of
Berlin, Singapore and London and it keeps grow-
ing. Users can log into the virtual world, where
they can meet other users and communicate with
them using the integrated chat function or talk
to each other via Voice-over-IP. They can style
their virtual appearance, can rent or buy their own
flats and decorate them as to their preferences and
tastes.
Out of many types of NPCs useful for this appli-
cation such as pedestrians, city guides and person-
nel in stores, restaurants and bars, we start with
two specific characters: a female furniture sales
agent and a male bartender. The furniture seller
is designed for helping users furnish their virtual
apartments. Users can buy pieces of furniture and
room decoration from the NPC by describing their
demands and wishes in a text chat. During the di-
1http://www.metaversum.com/
36
Figure 1: The furniture sales NPC selling a sofa
alog with the NPC, the preferred objects are then
selected and directly put into a location in the
apartment, which can be further refined with the
user interfaces that Twinity provides.
In the second scenario, the bartender sells vir-
tual drinks. He can talk about cocktails with users,
but moreover, he can also entertain his guests by
providing trivia-type information about popular
celebrities and various relations among them.
We chose these two characters not only because
of their value for the Twinity application but also
for our research goals. They differ in many in-
teresting aspects. First of all, the furniture sales
agent is controlled by a complex task model in-
cluding ontology-driven and data-driven compo-
nents to guide the conversation. This agent also
possesses a much more fine-grained action model,
which allows several different actions to cover
the potential conversation situations for the sell-
ing task. The bartender agent on the other hand is
designed not to fulfill one strict task because his
clients do not follow a specific goal except order-
ing drinks. Our bartender has the role of a conver-
sation companion and is able to entertain clients
with his broad knowledge. Thus, he is allowed to
access to several knowledge bases and is able to
handle questions (and later conversations) about
a much larger domain called the ?gossip domain?
which enables conversation about pop stars, movie
actors and other celebrities as well as the relations
between these people. In order to achieve a high
robustness, we integrate a chatbot into the bar-
tender agent to catch chitchat utterances we cannot
handle.
Figure 2: Our bartender NPC in his bar in Twinity
3 Knowledge Representation and
Semantic Inference
Semantic Web technology is employed for mod-
elling the knowledge of the NPCs. The Resource
Description Format (RDF) serves as the base for
the actual encoding. An RDF statement is a binary
relation instance between two individuals, that is a
triple of a predicate and two arguments, called the
subject and the object, and written as subj pred obj
(e.g. f:Sofa Alatea f:hasMainColour
f:Burgundy).
All objects and properties the NPC can talk
about are modelled in this way. Therefore the
knowledge base has to reflect the physical prop-
erties of the virtual objects in Twinity as faithfully
as possible. For instance, specific pieces of furni-
ture are described by their main color, material or
style, whereas cocktails are characterized by their
ingredients, color, consistence and taste. Further-
more, references to the 3D models of the objects
are stored in order to create, find and remove such
objects in the virtual world.
The concepts and individuals of the particular
domain are structured and organized in domain-
specific ontologies. These ontologies are mod-
elled in the Web Ontology Language (OWL).
OWL allows us to define concept hierarchies, re-
lations between concepts, domains and ranges of
these relations, as well as specific relation in-
stances between instances of a concept. Our on-
tologies are defined by the freely available ontol-
ogy editor Prote?ge? 4.02. The advantage of using an
ontology for structuring the domain knowledge is
2http://protege.stanford.edu/, as accessed
27 Oct 2009
37
Twinity
Server
KomParse
Server
Twinity
Client
Conversational
AgentConversational
AgentConversational
Agent
Twinity
ClientTwinity
Client
Figure 3: Overall System Architecture ? Server/Client Architecture for NPC Control
the modular non-redundant encoding. When com-
bined with a reasoner, only a few statements about
an individual have to be asserted explicitely, while
the rest can be inferred from the ontology. We em-
ploy several ontologies, among which the follow-
ing are relevant for modelling the specific domains
of our NPCs:
? An extensive furniture ontology, created by
our project partner ZAS Berlin, defining
kinds of furniture, room parts, colors and
styles as well as the specific instances of fur-
niture in Twinity. This knowledge base con-
tains 95,258 triples, 123 furniture classes, 20
color classes, 243 color instances and various
classes defining styles and similar concepts.
? A cocktail ontology, defining 13 cocktail
classes with ingredients and tastes in 21,880
triples.
? A biographical ontology, the ?gossip on-
tology?, defining biographical and career-
specific concepts for people. This ontology is
accompanied by a huge database of celebri-
ties, which has been automatically acquired
from the Web and covers nearly 600,000 per-
sons and relations between these people like
family relationships, marriages and profes-
sional relations. (Adolphs et al, 2010)
The furniture ontology is the only knowledge
base for the furniture sales agent, whereas the bar-
tender NPC has access to both the cocktail as well
as the gossip knowledge base.
We use SwiftOwlim3 for storing and querying
the data. SwiftOwlim is a ?triple store?, a kind
of database which is specifically built for storing
and querying RDF data. It provides a forward-
chaining inference engine which evaluates the
domain definitions when loading the knowledge
repository, and makes implicit knowledge explicit
by asserting triples that must also hold true accord-
ing to the ontology. Once the reasoner is finished,
the triple store can be queried directly using the
RDF query language SPARQL.
3http://www.ontotext.com/owlim/
4 Overall System Architecture
Figure 3 shows the overall system architecture.
Twinity is a server/client application, in which the
server hosts the virtual world and coordinates the
user interactions. In order to use Twinity, users
have to download the Twinity client. The client
allows the user to control the physical represen-
tation of the user?s character in the virtual world,
also called the ?avatar?. Thus the client is respon-
sible for displaying the graphics, calculating the
effects of physical interactions, handling the user?s
input and synchronizing the 3D data and user ac-
tions with the Twinity server.
Each NPC comprises two major parts: whereas
its avatar is the physical appearance of the NPC in
the virtual world, the ?conversational agent? pro-
vides the actual control logic which controls the
avatar autonomously. It is in particular able to hold
a conversation with Twinity users in that it reacts
to a user?s presence, interprets user?s utterances in
dialog context and generates adequate responses.
The KomParse server is a multi-client, multi-
threaded server written in Java that hosts the con-
versational agents for the NPCs (section 5). The
NPC?s avatar, on the other hand, is realized by a
modified Twinity client. We utilize the Python in-
terface provided by the Twinity client to call our
own plugin which opens a bidirectional socket
connection to the KomParse server. The plugin is
started together with the Twinity client and serves
as a mediator between the Twinity server and the
KomParse server from then on (fig. 3). It sends all
in-game events relevant to our system to the server
and translates the commands sent by the server
into Twinity-specific actions.
The integration architecture allows us to be
maximally independent of the specific game plat-
form. Rather than using the particular program-
ming language and development environment of
the platform for realizing the conversational agent
or reimplementing a whole client/server proto-
col for connecting the avatar to the corresponding
agent, we use an interface tailored to the specific
needs of our system. Thus the KomParse system
38
can be naturally extended to other platforms since
only the avatar interfaces have to be adapted.
The integration architecture also has the advan-
tage that the necessary services can be easily dis-
tributed in a networked multi-platform environ-
ment. The Twinity clients require aMicrosoftWin-
dows machine with a 3D graphics card supporting
DirectX 9.0c or higher, 1 GB RAM and a CPU
core per instance. The KomParse server requires
roughly 1 GB RAM. The triple store is run as
a separate server process and is accessed by an
XML-RPC interface. Roughly 1.2 GB RAM are
required for loading our current knowledge base.
5 Conversational Agent: KomParse
Dialog System
Figure 4: Dialog System: Conversational Agent
The KomParse dialog system, the main func-
tionality of the conversational agent, consists of
the following three major components: input ana-
lyzer, dialog manager and output generator (fig.4).
The input analyzer is responsible for the lin-
guistic analysis of the user?s textual input includ-
ing preprocessing such as string cleaning, part-of-
speech tagging, named entity recognition, parsing
and semantic interpretation. It yields a semantic
representation which is the input for the dialog
manager.
The dialog manager takes the result of the input
analyzer and delivers an interpretation based on
the dialog context and the available knowledge. It
also controls the task conversation chain and han-
dles user requests. The dialog manager determines
the next system action based on the interpreted pa-
rameters.
The output generator realizes the action defined
by the dialog manager with its multimodal gener-
ation competence. The generated results can be
verbal, gestural or a combination of both.
As mentioned above, our dialog system has to
deal with two different scenarios. While the fo-
cal point of the bartender agent lies in the question
answering functionality, the furniture sales agent
is driven by a complex dialog task model based on
a dialog graph. Thus, the bartender agent relies
mainly on question answering technology, in that
it needs to understand questions and extract the
right answer from our knowledge bases, whereas
the sales agent has to accommodate various dialog
situations with respect to a sales scenario. It there-
fore has to understand the dialog acts intended
by the user and trigger the corresponding reac-
tions, such as presenting an object, memorizing
user preferences, negotiating further sales goals,
etc.
The task model for sales conversations is in-
spired by a corpus resulting from the annotation of
a Wizard-of-Oz experiment in the furniture sales
agent scenario carried out by our project partner at
ZAS (Bertomeu and Benz, 2009). In these exper-
iments, 18 users spent one hour each on furnish-
ing a virtual living room in a Twinity apartment by
talking to a human wizard controlling the virtual
sales agent. The final corpus consists of 18 di-
alogs containing 3,171 turns with 4,313 utterances
and 23,015 alpha-numerical strings (words). The
following example shows a typical part of such a
conversation:
USR.1: And do we have a little side table for the TV?
NPC.1: I could offer you another small table or a sideboard.
USR.2: Then I?ll take a sideboard thats similar to my shelf.
NPC.2: Let me check if we have something like that.
Table 1: Example Conversation from the Wizard-
of-Oz Experiment
The flow of the task-based conversation is con-
trolled by a data-driven finite-state model, which
is the backbone of the dialog manager. During
a sales conversation, objects and features of ob-
jects mentioned by the NPC and the user are ex-
tracted from the knowledge bases and added into
the underspecified graph nodes and egdes at run-
time. This strategy keeps the finite-state graph as
small as possible. Discussed objects and their fea-
tures are stored in a frame-based sub-component
named ?form?. The form contains entries which
correspond to ontological concepts in the furni-
39
ture ontology. During conversation, these entries
will be specified with the values of the properties
of the discussed objects. This frame-based ap-
proach increases the flexibility of the dialog man-
ager (McTear, 2002) and is particularly useful for
a task-driven dialog system. As long as the negoti-
ated object is not yet fully specified, the form rep-
resents the underspecified object description ac-
cording to the ontology concept. Every time the
user states a new preference or request, the form
is enriched with additional features until the set of
objects is small enough to be presented to the user
for final selection. Thus the actual flow of dia-
log according to the task model does not have to
be expressed by the graph but can be derived on
demand from the knowledge and handled by the
form which in turn activates the appropriate dia-
log subgraphs. This combination of graph-based
dialog models and form-based task modelling ef-
fectively accounts for the interaction of sequential
dialog strategies and the non-sequential nature of
complex dialog goals.
Given a resolved semantic representation, the
dialog manager triggers either a semantic search
in the knowledge bases to deliver factual answers
as needed in a gossip conversation or a further di-
alog response for example providing choices for
the user in a sales domain. The semantic search is
needed in both domains. In case that the semantic
representation can neither be resolved in the task
domain nor in the gossip domain, it gets passed to
the embedded A.L.I.C.E. chatbot that uses its own
understanding and generation components (Wal-
lace and Bush, 2001).
5.1 Semantic Representation
The input understanding of the system is imple-
mented as one single understanding pipeline.The
understanding pipeline delivers a semantic repre-
sentation which is the basis for the decision of the
dialog manager which action to perform next.
This semantic representation can be extracted
from the user input by our understanding com-
ponent via a robust hybrid approach: either via a
number of surface patterns containing regular ex-
pressions or via patterns reflecting the syntactic
analysis of a dependency parser (de Marneffe and
Manning, 2008).
The representation?s structure is inspired by our
knowledge representation design described in sec-
tion 3 as well as by predicate logic. The core of the
representation is a predicate-argument structure
limited to two arguments including message type
and the whole syntactic information found by the
analysis pipeline. The field ?Message Type? can
have one of the following values: wh-question,
yes/no-question, declarative. Predicates can often
be instantiated with the lemmatized matrix verb of
the successfully analysed piece of the input. If the
input contains a wh-question, the questioned fact
is marked as an unfilled argument slot. The gen-
eral structure can be simplified described as:
<PREDICATE, ARG1, ARG2, [message-type]>
The following examples show the structure used
for different input:
? ?Who is the boyfriend of Madonna??
<hasBoyfriend, Madonna, ?, [wh]>
? ?I want to buy a sofa.?
<buy, I, "a sofa", [declarative]>
5.2 Information Extraction
Both scenarios make use of state-of-the-art infor-
mation extraction approaches to extract the impor-
tant pieces from the user input. While the bar-
tender depends on relation extraction to detect the
fact or relation questioned by the user (Xu et al,
2007), the sales agent uses information extraction
methods to recognize user wishes and demands.
As a result, the questioned fact or the demanded
object feature equals the ontology structure con-
taining the knowledge needed to handle the user
input. The input ?Do you have any red couches??
for example needs to get processed by the system
in such a way that the information regarding the
sofa with red color is extracted.
This is done by the system in a data-driven way.
The input analysis first tries to find a demanded
object in the input via asking the ontology: Every
object which can be discussed in the scenario is
encoded in the sales agents knowledge base. This
can be seen as a Named Entity Recognition step.
In case of success, the system tries to detect one
of the possible relations of the object found in the
input. This is achieved by querying the ontology
about what kind of relations the identified object
can satisfy. Possible relations are encoded in the
class description of the given object. As a result
the system can detect a relation ?hasColour? for
the found object ?sofa? and the color value ?red?.
The found information gets inserted into the form
which gets more and more similar or if possible
equal to a search query via RDF.
40
Figure 5: Comparison of Input, Extracted Information and Knowledge Base
6 Conclusion and Future Work
The KomParse system demonstrates an attractive
application area for dialog systems that bears great
future potential. Natural language dialog with
NPCs is an important factor in making virtual
worlds more interesting, interactive and immer-
sive. Virtual worlds with conversing characters
will also find many additional applications in edu-
cation, marketing, and entertainment.
KomParse is an ambitious and nevertheless
pragmatic attempt to bring NLP into the world of
virtual games. We develop a new strategy to inte-
grate task models and domain ontologies into dia-
log models. This strategy is useful for task-driven
NPCs such as furniture sellers. With the chatty
bartender, a combination of task-specific dialog
and domain-specific question answering enables a
smart wide-domain off-task conversation. Since
the online game employs bubble-chat as a mode
of communication in addition to Voice-over-IP, we
are able to test our dialog system in a real-time
application without being hindered by imperfect
speech recognition.
The system presented here is still work in
progress. The next goals will include various eval-
uation steps. On the one hand we will focus on
single components like hybrid parsing of input ut-
terances and dialog interpretation in terms of pre-
cision and recall. On the other hand an evaluation
of the two different scenarios regarding the us-
ability are planned in experiments with end users.
Moreover we will integrate some opinion mining
and sentiment analysis functionality which can be
helpful to better detect and understand the user?s
preferences in the furniture sales agents scenario.
Acknowledgements
The project KomParse is funded by the ProFIT
programme of the Federal State of Berlin, co-
funded by the EFRE programme of the Euro-
pean Union. The research presented here is ad-
ditionally supported through a grant to the project
TAKE, funded by the German Ministry for Edu-
cation and Research (BMBF, FKZ: 01IW08003).
Many thanks go to our project partners at the Cen-
tre for General Linguistics (ZAS) in Berlin as well
as to the supporting company Metaversum.
References
Peter Adolphs, Xiwen Cheng, Tina Klu?wer, Hans
Uszkoreit, and Feiyu Xu. 2010. Question answering
biographic information and social network powered
by the semantic web. In Proceedings of LREC 2010,
Valletta, Malta.
William Sims Bainbridge. 2007. The scientific re-
search potential of virtual worlds. Science, 317.
Nuria Bertomeu and Anton Benz. 2009. Annotation of
joint projects and information states in human-npc
dialogues. In Proceedings of the First International
Conference on Corpus Linguistics (CILC-09), Mur-
cia, Spain.
Marie C. de Marneffe and Christopher D. Manning.
2008. The Stanford typed dependencies repre-
sentation. In Coling 2008: Proceedings of the
workshop on Cross-Framework and Cross-Domain
Parser Evaluation, Manchester, UK.
Michael F. McTear. 2002. Spoken dialogue tech-
nology: enabling the conversational user interface.
ACM Comput. Surv., 34(1).
Richard Wallace and Noel Bush. 2001. Artificial
intelligence markup language (aiml) version 1.0.1
(2001). Unpublished A.L.I.C.E. AI Foundation
Working Draft (rev 006).
Feiyu Xu, Hans Uszkoreit, and Hong Li. 2007. A
seed-driven bottom-up machine learning framework
for extracting relations of various complexity. In
Proceedings of the 45th Annual Meeting of the As-
sociation of Computational Linguistics, pages 584?
591, Prague, Czech Republic, June. Association for
Computational Linguistics.
41
