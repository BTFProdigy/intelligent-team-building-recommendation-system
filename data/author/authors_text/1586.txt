An Integrated Architecture for Shallow and Deep Processing
Berthold Crysmann, Anette Frank, Bernd Kiefer, Stefan Mu?ller,
Gu?nter Neumann, Jakub Piskorski, Ulrich Scha?fer, Melanie Siegel, Hans Uszkoreit,
Feiyu Xu, Markus Becker and Hans-Ulrich Krieger
DFKI GmbH
Stuhlsatzenhausweg 3
Saarbru?cken, Germany
whiteboard@dfki.de
Abstract
We present an architecture for the integra-
tion of shallow and deep NLP components
which is aimed at flexible combination
of different language technologies for a
range of practical current and future appli-
cations. In particular, we describe the inte-
gration of a high-level HPSG parsing sys-
tem with different high-performance shal-
low components, ranging from named en-
tity recognition to chunk parsing and shal-
low clause recognition. The NLP com-
ponents enrich a representation of natu-
ral language text with layers of new XML
meta-information using a single shared
data structure, called the text chart. We de-
scribe details of the integration methods,
and show how information extraction and
language checking applications for real-
world German text benefit from a deep
grammatical analysis.
1 Introduction
Over the last ten years or so, the trend in application-
oriented natural language processing (e.g., in the
area of term, information, and answer extraction)
has been to argue that for many purposes, shallow
natural language processing (SNLP) of texts can
provide sufficient information for highly accurate
and useful tasks to be carried out. Since the emer-
gence of shallow techniques and the proof of their
utility, the focus has been to exploit these technolo-
gies to the maximum, often ignoring certain com-
plex issues, e.g. those which are typically well han-
dled by deep NLP systems. Up to now, deep natural
language processing (DNLP) has not played a sig-
nificant role in the area of industrial NLP applica-
tions, since this technology often suffers from insuf-
ficient robustness and throughput, when confronted
with large quantities of unrestricted text.
Current information extractions (IE) systems
therefore do not attempt an exhaustive DNLP analy-
sis of all aspects of a text, but rather try to analyse or
?understand? only those text passages that contain
relevant information, thereby warranting speed and
robustness wrt. unrestricted NL text. What exactly
counts as relevant is explicitly defined by means
of highly detailed domain-specific lexical entries
and/or rules, which perform the required mappings
from NL utterances to corresponding domain knowl-
edge. However, this ?fine-tuning? wrt. a particular
application appears to be the major obstacle when
adapting a given shallow IE system to another do-
main or when dealing with the extraction of com-
plex ?scenario-based? relational structures. In fact,
(Appelt and Israel, 1997) have shown that the cur-
rent IE technology seems to have an upper perfor-
mance level of less than 60% in such cases. It seems
reasonable to assume that if a more accurate analy-
sis of structural linguistic relationships could be pro-
vided (e.g., grammatical functions, referential rela-
tionships), this barrier might be overcome. Actually,
the growing market needs in the wide area of intel-
ligent information management systems seem to re-
quest such a break-through.
In this paper we will argue that the quality of cur-
                Computational Linguistics (ACL), Philadelphia, July 2002, pp. 441-448.
                         Proceedings of the 40th Annual Meeting of the Association for
rent SNLP-based applications can be improved by
integrating DNLP on demand in a focussed manner,
and we will present a system that combines the fine-
grained anaysis provided by HPSG parsing with a
high-performance SNLP system into a generic and
flexible NLP architecture.
1.1 Integration Scenarios
Owing to the fact that deep and shallow technologies
are complementary in nature, integration is a non-
trivial task: while SNLP shows its strength in the
areas of efficiency and robustness, these aspects are
problematic for DNLP systems. On the other hand,
DNLP can deliver highly precise and fine-grained
linguistic analyses. The challenge for integration is
to combine these two paradigms according to their
virtues.
Probably the most straightforward way to inte-
grate the two is an architecture in which shallow and
deep components run in parallel, using the results of
DNLP, whenever available. While this kind of ap-
proach is certainly feasible for a real-time applica-
tion such as Verbmobil, it is not ideal for processing
large quantities of text: due to the difference in pro-
cessing speed, shallow and deep NLP soon run out
of sync. To compensate, one can imagine two possi-
ble remedies: either to optimize for precision, or for
speed. The drawback of the former strategy is that
the overall speed will equal the speed of the slow-
est component, whereas in case of the latter, DNLP
will almost always time out, such that overall preci-
sion will hardly be distinguishable from a shallow-
only system. What is thus called for is an integrated,
flexible architecture where components can play at
their strengths. Partial analyses from SNLP can be
used to identify relevant candidates for the focussed
use of DNLP, based on task or domain-specific crite-
ria. Furthermore, such an integrated approach opens
up the possibility to address the issue of robustness
by using shallow analyses (e.g., term recognition)
to increase the coverage of the deep parser, thereby
avoiding a duplication of efforts. Likewise, integra-
tion at the phrasal level can be used to guide the
deep parser towards the most likely syntactic anal-
ysis, leading, as it is hoped, to a considerable speed-
up.
shallow
NLP
components
NLP
deep
components internal repr.
layer
multi
chart
annot.
XML
external repr.
generic OOP
component
interface
WHAM
application
specification
input and
result
Figure 1: The WHITEBOARD architecture.
2 Architecture
The WHITEBOARD architecture defines a platform
that integrates the different NLP components by en-
riching an input document through XML annota-
tions. XML is used as a uniform way of represent-
ing and keeping all results of the various processing
components and to support a transparent software
infrastructure for LT-based applications. It is known
that interesting linguistic information ?especially
when considering DNLP? cannot efficiently be
represented within the basic XML markup frame-
work (?typed parentheses structure?), e.g., linguistic
phenomena like coreferences, ambiguous readings,
and discontinuous constituents. The WHITEBOARD
architecture employs a distributed multi-level repre-
sentation of different annotations. Instead of trans-
lating all complex structures into one XML docu-
ment, they are stored in different annotation layers
(possibly non-XML, e.g. feature structures). Hyper-
links and ?span? information together support effi-
cient access between layers. Linguistic information
of common interest (e.g. constituent structure ex-
tracted from HPSG feature structures) is available in
XML format with hyperlinks to full feature struc-
ture representations externally stored in correspond-
ing data files.
Fig. 1 gives an overview of the architecture of
the WHITEBOARD Annotation Machine (WHAM).
Applications feed the WHAM with input texts and
a specification describing the components and con-
figuration options requested. The core WHAM en-
gine has an XML markup storage (external ?offline?
representation), and an internal ?online? multi-level
annotation chart (index-sequential access). Follow-
ing the trichotomy of NLP data representation mod-
els in (Cunningham et al, 1997), the XML markup
contains additive information, while the multi-level
chart contains positional and abstraction-based in-
formation, e.g., feature structures representing NLP
entities in a uniform, linguistically motivated form.
Applications and the integrated components ac-
cess the WHAM results through an object-oriented
programming (OOP) interface which is designed
as general as possible in order to abstract from
component-specific details (but preserving shallow
and deep paradigms). The interfaces of the actu-
ally integrated components form subclasses of the
generic interface. New components can be inte-
grated by implementing this interface and specifying
DTDs and/or transformation rules for the chart.
The OOP interface consists of iterators that walk
through the different annotation levels (e.g., token
spans, sentences), reference and seek operators that
allow to switch to corresponding annotations on a
different level (e.g., give all tokens of the current
sentence, or move to next named entity starting
from a given token position), and accessor meth-
ods that return the linguistic information contained
in the chart. Similarily, general methods support
navigating the type system and feature structures of
the DNLP components. The resulting output of the
WHAM can be accessed via the OOP interface or as
XML markup.
The WHAM interface operations are not only
used to implement NLP component-based applica-
tions, but also for the integration of deep and shallow
processing components itself.
2.1 Components
2.1.1 Shallow NL component
Shallow analysis is performed by SPPC, a rule-
based system which consists of a cascade of
weighted finite?state components responsible for
performing subsequent steps of the linguistic anal-
ysis, including: fine-grained tokenization, lexico-
morphological analysis, part-of-speech filtering,
named entity (NE) recognition, sentence bound-
ary detection, chunk and subclause recognition,
see (Piskorski and Neumann, 2000; Neumann and
Piskorski, 2002) for details. SPPC is capable of pro-
cessing vast amounts of textual data robustly and ef-
ficiently (ca. 30,000 words per second in standard
PC environment). We will briefly describe the SPPC
components which are currently integrated with the
deep components.
Each token identified by a tokenizer as a poten-
tial word form is morphologically analyzed. For
each token, its lexical information (list of valid read-
ings including stem, part-of-speech and inflection
information) is computed using a fullform lexicon
of about 700,000 entries that has been compiled out
from a stem lexicon of about 120,000 lemmas. Af-
ter morphological processing, POS disambiguation
rules are applied which compute a preferred read-
ing for each token, while the deep components can
back off to all readings. NE recognition is based on
simple pattern matching techniques. Proper names
(organizations, persons, locations), temporal expres-
sions and quantities can be recognized with an av-
erage precision of almost 96% and recall of 85%.
Furthermore, a NE?specific reference resolution is
performed through the use of a dynamic lexicon
which stores abbreviated variants of previously rec-
ognized named entities. Finally, the system splits
the text into sentences by applying only few, but
highly accurate contextual rules for filtering implau-
sible punctuation signs. These rules benefit directly
from NE recognition which already performs re-
stricted punctuation disambiguation.
2.1.2 Deep NL component
The HPSG Grammar is based on a large?scale
grammar for German (Mu?ller, 1999), which was
further developed in the VERBMOBIL project for
translation of spoken language (Mu?ller and Kasper,
2000). After VERBMOBIL the grammar was adapted
to the requirements of the LKB/PET system (Copes-
take, 1999), and to written text, i.e., extended with
constructions like free relative clauses that were ir-
relevant in the VERBMOBIL scenario.
The grammar consists of a rich hierarchy of
5,069 lexical and phrasal types. The core grammar
contains 23 rule schemata, 7 special verb move-
ment rules, and 17 domain specific rules. All rule
schemata are unary or binary branching. The lexicon
contains 38,549 stem entries, from which more than
70% were semi-automatically acquired from the an-
notated NEGRA corpus (Brants et al, 1999).
The grammar parses full sentences, but also other
kinds of maximal projections. In cases where no full
analysis of the input can be provided, analyses of
fragments are handed over to subsequent modules.
Such fragments consist of maximal projections or
single words.
The HPSG analysis system currently integrated
in the WHITEBOARD system is PET (Callmeier,
2000). Initially, PET was built to experiment
with different techniques and strategies to process
unification-based grammars. The resulting sys-
tem provides efficient implementations of the best
known techniques for unification and parsing.
As an experimental system, the original design
lacked open interfaces for flexible integration with
external components. For instance, in the beginning
of the WHITEBOARD project the system only ac-
cepted fullform lexica and string input. In collabora-
tion with Ulrich Callmeier the system was extended.
Instead of single word input, input items can now
be complex, overlapping and ambiguous, i.e. essen-
tially word graphs. We added dynamic creation of
atomic type symbols, e.g., to be able to add arbitrary
symbols to feature structures. With these enhance-
ments, it is possible to build flexible interfaces to
external components like morphology, tokenization,
named entity recognition, etc.
3 Integration
Morphology and POS The coupling between the
morphology delivered by SPPC and the input needed
for the German HPSG was easily established. The
morphological classes of German are mapped onto
HPSG types which expand to small feature struc-
tures representing the morphological information in
a compact way. A mapping to the output of SPPC
was automatically created by identifying the corre-
sponding output classes.
Currently, POS tagging is used in two ways. First,
lexicon entries that are marked as preferred by the
shallow component are assigned higher priority than
the rest. Thus, the probability of finding the cor-
rect reading early should increase without excluding
any reading. Second, if for an input item no entry is
found in the HPSG lexicon, we automatically create
a default entry, based on the part?of?speech of the
preferred reading. This increases robustness, while
avoiding increase in ambiguity.
Named Entity Recognition Writing HPSG gram-
mars for the whole range of NE expressions etc. is
a tedious and not very promising task. They typi-
cally vary across text sorts and domains, and would
require modularized subgrammars that can be easily
exchanged without interfering with the general core.
This can only be realized by using a type interface
where a class of named entities is encoded by a gen-
eral HPSG type which expands to a feature structure
used in parsing. We exploit such a type interface for
coupling shallow and deep processing. The classes
of named entities delivered by shallow processing
are mapped to HPSG types. However, some fine-
tuning is required whenever deep and shallow pro-
cessing differ in the amount of input material they
assign to a named entity.
An alternative strategy is used for complex syn-
tactic phrases containing NEs, e.g., PPs describ-
ing time spans etc. It is based on ideas from
Explanation?based Learning (EBL, see (Tadepalli
and Natarajan, 1996)) for natural language analy-
sis, where analysis trees are retrieved on the basis
of the surface string. In our case, the part-of-speech
sequence of NEs recognised by shallow analysis is
used to retrieve pre-built feature structures. These
structures are produced by extracting NEs from a
corpus and processing them directly by the deep
component. If a correct analysis is delivered, the
lexical parts of the analysis, which are specific for
the input item, are deleted. We obtain a sceletal
analysis which is underspecified with respect to the
concrete input items. The part-of-speech sequence
of the original input forms the access key for this
structure. In the application phase, the underspeci-
fied feature structure is retrieved and the empty slots
for the input items are filled on the basis of the con-
crete input.
The advantage of this approach lies in the more
elaborate semantics of the resulting feature struc-
tures for DNLP, while avoiding the necessity of
adding each and every single name to the HPSG lex-
icon. Instead, good coverage and high precision can
be achieved using prototypical entries.
Lexical Semantics When first applying the origi-
nal VERBMOBIL HPSG grammar to business news
articles, the result was that 78.49% of the miss-
ing lexical items were nouns (ignoring NEs). In
the integrated system, unknown nouns and NEs can
be recognized by SPPC, which determines morpho-
syntactic information. It is essential for the deep sys-
tem to associate nouns with their semantic sorts both
for semantics construction, and for providing se-
mantically based selectional restrictions to help con-
straining the search space during deep parsing. Ger-
maNet (Hamp and Feldweg, 1997) is a large lexical
database, where words are associated with POS in-
formation and semantic sorts, which are organized in
a fine-grained hierarchy. The HPSG lexicon, on the
other hand, is comparatively small and has a more
coarse-grained semantic classification.
To provide the missing sort information when re-
covering unknown noun entries via SPPC, a map-
ping from the GermaNet semantic classification to
the HPSG semantic classification (Siegel et al,
2001) is applied which has been automatically ac-
quired. The training material for this learning pro-
cess are those words that are both annotated with se-
mantic sorts in the HPSG lexicon and with synsets
of GermaNet. The learning algorithm computes a
mapping relevance measure for associating seman-
tic concepts in GermaNet with semantic sorts in the
HPSG lexicon. For evaluation, we examined a cor-
pus of 4664 nouns extracted from business news
that were not contained in the HPSG lexicon. 2312
of these were known in GermaNet, where they are
assigned 2811 senses. With the learned mapping,
the GermaNet senses were automatically mapped to
HPSG semantic sorts. The evaluation of the map-
ping accuracy yields promising results: In 76.52%
of the cases the computed sort with the highest rel-
evance probability was correct. In the remaining
20.70% of the cases, the correct sort was among the
first three sorts.
3.1 Integration on Phrasal Level
In the previous paragraphs we described strategies
for integration of shallow and deep processing where
the focus is on improving DNLP in the domain of
lexical and sub-phrasal coverage.
We can conceive of more advanced strategies for
the integration of shallow and deep analysis at the
length cover- complete LP LR 0CB   2CB
age match
  40 100 80.4 93.4 92.9 92.1 98.9
 40 99.8 78.6 92.4 92.2 90.7 98.5
Training: 16,000 NEGRA sentences
Testing: 1,058 NEGRA sentences
Figure 2: Stochastic topological parsing: results
level of phrasal syntax by guiding the deep syntac-
tic parser towards a partial pre-partitioning of com-
plex sentences provided by shallow analysis sys-
tems. This strategy can reduce the search space, and
enhance parsing efficiency of DNLP.
Stochastic Topological Parsing The traditional
syntactic model of topological fields divides basic
clauses into distinct fields: so-called pre-, middle-
and post-fields, delimited by verbal or senten-
tial markers. This topological model of German
clause structure is underspecified or partial as to
non-sentential constituent boundaries, but provides
a linguistically well-motivated, and theory-neutral
macrostructure for complex sentences. Due to its
linguistic underpinning the topological model pro-
vides a pre-partitioning of complex sentences that is
(i) highly compatible with deep syntactic structures
and (ii) maximally effective to increase parsing ef-
ficiency. At the same time (iii) partiality regarding
the constituency of non-sentential material ensures
the important aspects of robustness, coverage, and
processing efficiency.
In (Becker and Frank, 2002) we present a corpus-
driven stochastic topological parser for German,
based on a topological restructuring of the NEGRA
corpus (Brants et al, 1999). For topological tree-
bank conversion we build on methods and results
in (Frank, 2001). The stochastic topological parser
follows the probabilistic model of non-lexicalised
PCFGs (Charniak, 1996). Due to abstraction from
constituency decisions at the sub-sentential level,
and the essentially POS-driven nature of topologi-
cal structure, this rather simple probabilistic model
yields surprisingly high figures of accuracy and cov-
erage (see Fig.2 and (Becker and Frank, 2002) for
more detail), while context-free parsing guarantees
efficient processing.
The next step is to elaborate a (partial) map-
ping of shallow topological and deep syntactic struc-
tures that is maximally effective for preference-gui-
Topological Structure:
CL-V2
VF-TOPIC LK-FIN MF RK-t
NN VVFIN ADV NN PREP NN VVFIN
[ 	 [ 
	 Peter] [ 
 i?t] [ 
 gerne Wu?rstchen mit Kartoffelsalat] [ Integrated Shallow and Deep Parsing: TopP meets HPSG
Anette Frank, Markus Beckerz, Berthold Crysmann, Bernd Kiefer and Ulrich Scha?fer
DFKI GmbH School of Informaticsz
66123 Saarbru?cken, Germany University of Edinburgh, UK
firstname.lastname@dfki.de M.Becker@ed.ac.uk
Abstract
We present a novel, data-driven method
for integrated shallow and deep parsing.
Mediated by an XML-based multi-layer
annotation architecture, we interleave a
robust, but accurate stochastic topological
field parser of German with a constraint-
based HPSG parser. Our annotation-based
method for dovetailing shallow and deep
phrasal constraints is highly flexible, al-
lowing targeted and fine-grained guidance
of constraint-based parsing. We conduct
systematic experiments that demonstrate
substantial performance gains.1
1 Introduction
One of the strong points of deep processing (DNLP)
technology such as HPSG or LFG parsers certainly
lies with the high degree of precision as well as
detailed linguistic analysis these systems are able
to deliver. Although considerable progress has been
made in the area of processing speed, DNLP systems
still cannot rival shallow and medium depth tech-
nologies in terms of throughput and robustness. As
a net effect, the impact of deep parsing technology
on application-oriented NLP is still fairly limited.
With the advent of XML-based hybrid shallow-
deep architectures as presented in (Grover and Las-
carides, 2001; Crysmann et al, 2002; Uszkoreit,
2002) it has become possible to integrate the added
value of deep processing with the performance and
robustness of shallow processing. So far, integration
has largely focused on the lexical level, to improve
upon the most urgent needs in increasing the robust-
ness and coverage of deep parsing systems, namely
1This work was in part supported by a BMBF grant to the
DFKI project WHITEBOARD (FKZ 01 IW 002).
lexical coverage. While integration in (Grover and
Lascarides, 2001) was still restricted to morphologi-
cal and PoS information, (Crysmann et al, 2002) ex-
tended shallow-deep integration at the lexical level
to lexico-semantic information, and named entity
expressions, including multiword expressions.
(Crysmann et al, 2002) assume a vertical,
?pipeline? scenario where shallow NLP tools provide
XML annotations that are used by the DNLP system
as a preprocessing and lexical interface. The per-
spective opened up by a multi-layered, data-centric
architecture is, however, much broader, in that it en-
courages horizontal cross-fertilisation effects among
complementary and/or competing components.
One of the culprits for the relative inefficiency of
DNLP parsers is the high degree of ambiguity found
in large-scale grammars, which can often only be re-
solved within a larger syntactic domain. Within a hy-
brid shallow-deep platform one can take advantage
of partial knowledge provided by shallow parsers to
pre-structure the search space of the deep parser. In
this paper, we will thus complement the efforts made
on the lexical side by integration at the phrasal level.
We will show that this may lead to considerable per-
formance increase for the DNLP component. More
specifically, we combine a probabilistic topological
field parser for German (Becker and Frank, 2002)
with the HPSG parser of (Callmeier, 2000). The
HPSG grammar used is the one originally developed
by (Mu?ller and Kasper, 2000), with significant per-
formance enhancements by B. Crysmann.
In Section 2 we discuss the mapping problem
involved with syntactic integration of shallow and
deep analyses and motivate our choice to combine
the HPSG system with a topological parser. Sec-
tion 3 outlines our basic approach towards syntactic
shallow-deep integration. Section 4 introduces vari-
ous confidence measures, to be used for fine-tuning
of phrasal integration. Sections 5 and 6 report on
experiments and results of integrated shallow-deep
parsing, measuring the effect of various integra-
tion parameters on performance gains for the DNLP
component. Section 7 concludes and discusses pos-
sible extensions, to address robustness issues.
2 Integrated Shallow and Deep Processing
The prime motivation for integrated shallow-deep
processing is to combine the robustness and effi-
ciency of shallow processing with the accuracy and
fine-grainedness of deep processing. Shallow analy-
ses could be used to pre-structure the search space of
a deep parser, enhancing its efficiency. Even if deep
analysis fails, shallow analysis could act as a guide
to select partial analyses from the deep parser?s chart
? enhancing the robustness of deep analysis, and the
informativeness of the combined system.
In this paper, we concentrate on the usage of shal-
low information to increase the efficiency, and po-
tentially the quality, of HPSG parsing. In particu-
lar, we want to use analyses delivered by an effi-
cient shallow parser to pre-structure the search space
of HPSG parsing, thereby enhancing its efficiency,
and guiding deep parsing towards a best-first analy-
sis suggested by shallow analysis constraints.
The search space of an HPSG chart parser can
be effectively constrained by external knowledge
sources if these deliver compatible partial subtrees,
which would then only need to be checked for com-
patibility with constituents derived in deep pars-
ing. Raw constituent span information can be used
to guide the parsing process by penalizing con-
stituents which are incompatible with the precom-
puted ?shape?. Additional information about pro-
posed constituents, such as categorial or featural
constraints, provide further criteria for prioritis-
ing compatible, and penalising incompatible con-
stituents in the deep parser?s chart.
An obvious challenge for our approach is thus to
identify suitable shallow knowledge sources that can
deliver compatible constraints for HPSG parsing.
2.1 The Shallow-Deep Mapping Problem
However, chunks delivered by state-of-the-art shal-
low parsers are not isomorphic to deep syntactic
analyses that explicitly encode phrasal embedding
structures. As a consequence, the boundaries of
deep grammar constituents in (1.a) cannot be pre-
determined on the basis of a shallow chunk analy-
sis (1.b). Moreover, the prevailing greedy bottom-up
processing strategies applied in chunk parsing do not
take into account the macro-structure of sentences.
They are thus easily trapped in cases such as (2).
(1) a. [
CL
There was [
NP
a rumor [
CL
it was going
to be bought by [
NP
a French company [
CL
that
competes in supercomputers]]]]].
b. [
CL
There was [
NP
a rumor]] [
CL
it was going
to be bought by [
NP
a French company]] [
CL
that competes in supercomputers].
(2) Fred eats [
NP
pizza and Mary] drinks wine.
In sum, state-of-the-art chunk parsing does nei-
ther provide sufficient detail, nor the required accu-
racy to act as a ?guide? for deep syntactic analysis.
2.2 Stochastic Topological Parsing
Recently, there is revived interest in shallow anal-
yses that determine the clausal macro-structure of
sentences. The topological field model of (German)
syntax (Ho?hle, 1983) divides basic clauses into dis-
tinct fields ? pre-, middle-, and post-fields ? delim-
ited by verbal or sentential markers, which consti-
tute the left/right sentence brackets. This model of
clause structure is underspecified, or partial as to
non-sentential constituent structure, but provides a
theory-neutral model of sentence macro-structure.
Due to its linguistic underpinning, the topologi-
cal field model provides a pre-partitioning of com-
plex sentences that is (i) highly compatible with
deep syntactic analysis, and thus (ii) maximally ef-
fective to increase parsing efficiency if interleaved
with deep syntactic analysis; (iii) partiality regarding
the constituency of non-sentential material ensures
robustness, coverage, and processing efficiency.
(Becker and Frank, 2002) explored a corpus-
based stochastic approach to topological field pars-
ing, by training a non-lexicalised PCFG on a topo-
logical corpus derived from the NEGRA treebank of
German. Measured on the basis of hand-corrected
PoS-tagged input as provided by the NEGRA tree-
bank, the parser achieves 100% coverage for length
 40 (99.8% for all). Labelled precision and recall
are around 93%. Perfect match (full tree identity) is
about 80% (cf. Table 1, disamb +).
In this paper, the topological parser was provided
a tagger front-end for free text processing, using the
TnT tagger (Brants, 2000). The grammar was ported
to the efficient LoPar parser of (Schmid, 2000). Tag-
ging inaccuracies lead to a drop of 5.1/4.7 percent-
CL-V2
VF-TOPIC LK-VFIN MF RK-VPART NF
ART NN VAFIN ART ADJA NN VAPP CL-SUBCL
Der,1 Zehnkampf,2 ha?tte,3 eine,4 andere,5 Dimension,6 gehabt,7 ,
The decathlon would have a other dimension had LK-COMPL MF RK-VFIN
KOUS PPER PROAV VAPP VAFIN
wenn,9 er,10 dabei,11 gewesen,12 wa?re,13 .
if he there been had .
<TOPO2HPSG type=?root? id=?5608?>
<MAP CONSTR id=?T1? constr=?v2 cp? conf
ent
=?0.87? left=?W1? right=?W13?/>
<MAP CONSTR id=?T2? constr=?v2 vf? conf
ent
=?0.87? left=?W1? right=?W2?/>
<MAP CONSTR id=?T3? constr=?vfronted vfin+rk? conf
ent
=?0.87? left=?W3? right=?W3?/>
<MAP CONSTR id=?T6? constr=?vfronted rk-complex? conf
ent
=?0.87? left=?W7? right=?W7?/>
<MAP CONSTR id=?T4? constr=?vfronted vfin+vp+rk? conf
ent
=?0.87? left=?W3? right=?W13?/>
<MAP CONSTR id=?T5? constr=?vfronted vp+rk? conf
ent
=?0.87? left=?W4? right=?W13?/>
<MAP CONSTR id=?T10? constr=?extrapos rk+nf? conf
ent
=?0.87? left=?W7? right=?W13?/>
<MAP CONSTR id=?T7? constr=?vl cpfin compl? conf
ent
=?0.87? left=?W9? right=?W13?/>
<MAP CONSTR id=?T8? constr=?vl compl vp? conf
ent
=?0.87? left=?W10? right=?W13?/>
<MAP CONSTR id=?T9? constr=?vl rk fin+complex+finlast? conf
ent
=?0.87? left=?W12? right=?W13?/>
</TOPO2HPSG>
Der
D
Zehnkampf
N?
NP-NOM-SG
haette
V
eine
D
andere
AP-ATT
Dimension
N?
N?
NP-ACC-SG
gehabt
V
EPS
wenn
C
er
NP-NOM-SG
dabei
PP
gewesen
V
waere
V-LE
V
V
S
CP-MOD
EPS
EPS
EPS/NP-NOM-SG
S/NP-NOM-SG
S
Figure 1: Topological tree w/param. cat., TOPO2HPSG map-constraints, tree skeleton of HPSG analysis
dis- cove- perfect LP LR 0CB 2CB
amb rage match in % in % in % in %
+ 100.0 80.4 93.4 92.9 92.1 98.9
  99.8 72.1 88.3 88.2 87.8 97.9
Table 1: Disamb: correct (+) / tagger ( ) PoS input.
Eval. on atomic (vs. parameterised) category labels.
age points in LP/LR, and 8.3 percentage points in
perfect match rate (Table 1, disamb  ).
As seen in Figure 1, the topological trees abstract
away from non-sentential constituency ? phrasal
fields MF (middle-field) and VF (pre-field) directly
expand to PoS tags. By contrast, they perfectly ren-
der the clausal skeleton and embedding structure of
complex sentences. In addition, parameterised cate-
gory labels encode larger syntactic contexts, or ?con-
structions?, such as clause type (CL-V2, -SUBCL,
-REL), or inflectional patterns of verbal clusters (RK-
VFIN,-VPART). These properties, along with their
high accuracy rate, make them perfect candidates for
tight integration with deep syntactic analysis.
Moreover, due to the combination of scrambling
and discontinuous verb clusters in German syntax, a
deep parser is confronted with a high degree of local
ambiguity that can only be resolved at the clausal
level. Highly lexicalised frameworks such as HPSG,
however, do not lend themselves naturally to a top-
down parsing strategy. Using topological analyses to
guide the HPSG will thus provide external top-down
information for bottom-up parsing.
3 TopP meets HPSG
Our work aims at integration of topological and
HPSG parsing in a data-centric architecture, where
each component acts independently2 ? in contrast
to the combination of different syntactic formalisms
within a unified parsing process.3 Data-based inte-
gration not only favours modularity, but facilitates
flexible and targeted dovetailing of structures.
3.1 Mapping Topological to HPSG Structures
While structurally similar, topological trees are not
fully isomorphic to HPSG structures. In Figure 1,
e.g., the span from the verb ?ha?tte? to the end of the
sentence forms a constituent in the HPSG analysis,
while in the topological tree the same span is domi-
nated by a sequence of categories: LK, MF, RK, NF.
Yet, due to its linguistic underpinning, the topo-
logical tree can be used to systematically predict
key constituents in the corresponding ?target? HPSG
2See Section 6 for comparison to recent work on integrated
chunk-based and dependency parsing in (Daum et al, 2003).
3As, for example, in (Duchier and Debusmann, 2001).
analysis. We know, for example, that the span from
the fronted verb (LK-VFIN) till the end of its clause
CL-V2 corresponds to an HPSG phrase. Also, the
first position that follows this verb, here the leftmost
daughter of MF, demarcates the left edge of the tra-
ditional VP. Spans of the vorfeld VF and clause cat-
egories CL exactly match HPSG constituents. Cate-
gory CL-V2 tells us that we need to reckon with a
fronted verb in position of its LK daughter, here 3,
while in CL-SUBCL we expect a complementiser in
the position of LK, and a finite verb within the right
verbal complex RK, which spans positions 12 to 13.
In order to communicate such structural con-
straints to the deep parser, we scan the topological
tree for relevant configurations, and extract the span
information for the target HPSG constituents. The
resulting ?map constraints? (Fig. 1) encode a bracket
type name4 that identifies the target constituent and
its left and right boundary, i.e. the concrete span in
the sentence under consideration. The span is en-
coded by the word position index in the input, which
is identical for the two parsing processes.5
In addition to pure constituency constraints, a
skilled grammar writer will be able to associate spe-
cific HPSG grammar constraints ? positive or neg-
ative ? with these bracket types. These additional
constraints will be globally defined, to permit fine-
grained guidance of the parsing process. This and
further information (cf. Section 4) is communicated
to the deep parser by way of an XML interface.
3.2 Annotation-based Integration
In the annotation-based architecture of (Crysmann
et al, 2002), XML-encoded analysis results of all
components are stored in a multi-layer XML chart.
The architecture employed in this paper improves
on (Crysmann et al, 2002) by providing a central
Whiteboard Annotation Transformer (WHAT) that
supports flexible and powerful access to and trans-
formation of XML annotation based on standard
XSLT engines6 (see (Scha?fer, 2003) for more de-
tails on WHAT). Shallow-deep integration is thus
fully annotation driven. Complex XSLT transforma-
tions are applied to the various analyses, in order to
4We currently extract 34 different bracket types.
5We currently assume identical tokenisation, but could ac-
commodate for distinct tokenisation regimes, using map tables.
6Advantages we see in the XSLT approach are (i) minimised
programming effort in the target implementation language for
XML access, (ii) reuse of transformation rules in multiple mod-
ules, (iii) fast integration of new XML-producing components.
extract or combine independent knowledge sources,
including XPath access to information stored in
shallow annotation, complex XSLT transformations
to the output of the topological parser, and extraction
of bracket constraints.
3.3 Shaping the Deep Parser?s Search Space
The HPSG parser is an active bidirectional chart
parser which allows flexible parsing strategies by us-
ing an agenda for the parsing tasks.7 To compute pri-
orities for the tasks, several information sources can
be consulted, e.g. the estimated quality of the parti-
cipating edges or external resources like PoS tagger
results. Object-oriented implementation of the prior-
ity computation facilitates exchange and, moreover,
combination of different ranking strategies. Extend-
ing our current regime that uses PoS tagging for pri-
oritisation,8 we are now utilising phrasal constraints
(brackets) from topological analysis to enhance the
hand-crafted parsing heuristic employed so far.
Conditions for changing default priorities Ev-
ery bracket pair br
x
computed from the topological
analysis comes with a bracket type x that defines its
behaviour in the priority computation. Each bracket
type can be associated with a set of positive and neg-
ative constraints that state a set of permissible or for-
bidden rules and/or feature structure configurations
for the HPSG analysis.
The bracket types fall into three main categories:
left-, right-, and fully matching brackets. A right-
matching bracket may affect the priority of tasks
whose resulting edge will end at the right bracket
of a pair, like, for example, a task that would
combine edges C and F or C and D in Fig. 2.
Left-matching brackets work analogously. For fully
matching brackets, only tasks that produce an edge
that matches the span of the bracket pair can be af-
fected, like, e.g., a task that combines edges B and C
in Fig. 2. If, in addition, specified rule as well as fea-
ture structure constraints hold, the task is rewarded
if they are positive constraints, and penalised if they
are negative ones. All tasks that produce crossing
edges, i.e. where one endpoint lies strictly inside the
bracket pair and the other lies strictly outside, are
penalised, e.g., a task that combines edges A and B.
This behaviour can be implemented efficiently
when we assume that the computation of a task pri-
7A parsing task encodes the possible combination of a pas-
sive and an active chart edge.
8See e.g. (Prins and van Noord, 2001) for related work.
brxbrx
A
B C
D E
F
Figure 2: An example chart with a bracket pair of
type x. The dashed edges are active.
ority takes into account the priorities of the tasks it
builds upon. This guarantees that the effect of chang-
ing one task in the parsing process will propagate
to all depending tasks without having to check the
bracket conditions repeatedly.
For each task, it is sufficient to examine the start-
and endpoints of the building edges to determine if
its priority is affected by some bracket. Only four
cases can occur:
1. The new edge spans a pair of brackets: a match
2. The new edge starts or ends at one of the brack-
ets, but does not match: left or right hit
3. One bracket of a pair is at the joint of the build-
ing edges and a start- or endpoint lies strictly
inside the brackets: a crossing (edges A and B
in Fig. 2)
4. No bracket at the endpoints of both edges: use
the default priority
For left-/right-matching brackets, a match behaves
exactly like the corresponding left or right hit.
Computing the new priority If the priority of a
task is changed, the change is computed relative to
the default priority. We use two alternative confi-
dence values, and a hand-coded parameter (x), to
adjust the impact on the default priority heuristics.
conf
ent
(br
x
) specifies the confidence for a concrete
bracket pair br
x
of type x in a given sentence, based
on the tree entropy of the topological parse. conf
pr
specifies a measure of ?expected accuracy? for each
bracket type. Sec. 4 will introduce these measures.
The priority p(t) of a task t involving a bracket
br
x
is computed from the default priority ~p(t) by:
p(t) = ~p(t)  (1 conf
ent
(br
x
)  conf
pr
(x) (x))
4 Confidence Measures
This way of calculating priorities allows flexible pa-
rameterisation for the integration of bracket con-
straints. While the topological parser?s accuracy is
high, we need to reckon with (partially) wrong anal-
yses that could counter the expected performance
gains. An important factor is therefore the confi-
dence we can have, for any new sentence, into the
best parse delivered by the topological parser: If
confidence is high, we want it to be fully considered
for prioritisation ? if it is low, we want to lower its
impact, or completely ignore the proposed brackets.
We will experiment with two alternative confi-
dence measures: (i) expected accuracy of particular
bracket types extracted from the best parse deliv-
ered, and (ii) tree entropy based on the probability
distribution encountered in a topological parse, as
a measure of the overall accuracy of the best parse
proposed ? and thus the extracted brackets.9
4.1 Conf
pr
: Accuracy of map-constraints
To determine a measure of ?expected accuracy? for
the map constraints, we computed precision and re-
call for the 34 bracket types by comparing the ex-
tracted brackets from the suite of best delivered
topological parses against the brackets we extracted
from the trees in the manually annotated evalua-
tion corpus in (Becker and Frank, 2002). We obtain
88.3% precision, 87.8% recall for brackets extracted
from the best topological parse, run with TnT front
end. We chose precision of extracted bracket types
as a static confidence weight for prioritisation.
Precision figures are distributed as follows: 26.5%
of the bracket types have precision  90% (93.1%
in avg, 53.5% of bracket mass), 50% have pre-
cision  80% (88.9% avg, 77.7% bracket mass).
20.6% have precision  50% (41.26% in avg, 2.7%
bracket mass). For experiments using a threshold
on conf
pr
(x) for bracket type x, we set a threshold
value of 0.7, which excludes 32.35% of the low-
confidence bracket types (and 22.1% bracket mass),
and includes chunk-based brackets (see Section 5).
4.2 Conf
ent
: Entropy of Parse Distribution
While precision over bracket types is a static mea-
sure that is independent from the structural complex-
ity of a particular sentence, tree entropy is defined as
the entropy over the probability distribution of the
set of parsed trees for a given sentence. It is a use-
ful measure to assess how certain the parser is about
the best analysis, e.g. to measure the training utility
value of a data point in the context of sample selec-
tion (Hwa, 2000). We thus employ tree entropy as a
9Further measures are conceivable: We could extract brack-
ets from some n-best topological parses, associating them with
weights, using methods similar to (Carroll and Briscoe, 2002).
10
20
30
40
50
60
70
80
90
00.20.40.60.81
in
 %
Normalized entropy
precision
recall
coverage
Figure 3: Effect of different thresholds of normal-
ized entropy on precision, recall, and coverage
confidence measure for the quality of the best topo-
logical parse, and the extracted bracket constraints.
We carry out an experiment to assess the effect
of varying entropy thresholds  on precision and re-
call of topological parsing, in terms of perfect match
rate, and show a way to determine an optimal value
for . We compute tree entropy over the full prob-
ability distribution, and normalise the values to be
distributed in a range between 0 and 1. The normali-
sation factor is empirically determined as the highest
entropy over all sentences of the training set.10
Experimental setup We randomly split the man-
ually corrected evaluation corpus of (Becker and
Frank, 2002) (for sentence length  40) into a train-
ing set of 600 sentences and a test set of 408 sen-
tences. This yields the following values for the train-
ing set (test set in brackets): initial perfect match
rate is 73.5% (70.0%), LP 88.8% (87.6%), and LR
88.5% (87.8%).11 Coverage is 99.8% for both.
Evaluation measures For the task of identifying
the perfect matches from a set of parses we give the
following standard definitions: precision is the pro-
portion of selected parses that have a perfect match
? thus being the perfect match rate, and recall is the
proportion of perfect matches that the system se-
lected. Coverage is usually defined as the proportion
of attempted analyses with at least one parse. We ex-
tend this definition to treat successful analyses with
a high tree entropy as being out of coverage. Fig. 3
shows the effect of decreasing entropy thresholds
 on precision, recall and coverage. The unfiltered
set of all sentences is found at =1. Lowering  in-
10Possibly higher values in the test set will be clipped to 1.
11Evaluation figures for this experiment are given disregard-
ing parameterisation (and punctuation), corresponding to the
first row of figures in table 1.
82
84
86
88
90
92
94
96
0.160.180.20.220.240.260.280.3
in
 %
Normalized entropy
precision
recall
f-measure
Figure 4: Maximise f-measure on the training set to
determine best entropy threshold
creases precision, and decreases recall and coverage.
We determine f-measure as composite measure of
precision and recall with equal weighting (=0.5).
Results We use f-measure as a target function on
the training set to determine a plausible . F-measure
is maximal at =0.236 with 88.9%, see Figure 4.
Precision and recall are 83.7% and 94.8% resp.
while coverage goes down to 83.0%. Applying the
same  on the test set, we get the following results:
80.5% precision, 93.0% recall. Coverage goes down
to 80.6%. LP is 93.3%, LR is 91.2%.
Confidence Measure We distribute the comple-
ment of the associated tree entropy of a parse tree tr
as a global confidence measure over all brackets br
extracted from that parse: conf
ent
(br) = 1 ent(tr).
For the thresholded version of conf
ent
(br), we set
the threshold to 1   = 1  0:236 = 0:764.
5 Experiments
Experimental Setup In the experiments we use
the subset of the NEGRA corpus (5060 sents,
24.57%) that is currently parsed by the HPSG gram-
mar.12 Average sentence length is 8.94, ignoring
punctuation; average lexical ambiguity is 3.05 en-
tries/word. As baseline, we performed a run with-
out topological information, yet including PoS pri-
oritisation from tagging.13 A series of tests explores
the effects of alternative parameter settings. We fur-
ther test the impact of chunk information. To this
12This test set is different from the corpus used in Section 4.
13In a comparative run without PoS-priorisation, we estab-
lished a speed-up factor of 1.13 towards the baseline used in
our experiment, with a slight increase in coverage (1%). This
compares to a speed-up factor of 2.26 reported in (Daum et al,
2003), by integration of PoS guidance into a dependency parser.
end, phrasal fields determined by topological pars-
ing were fed to the chunk parser of (Skut and Brants,
1998). Extracted NP and PP bracket constraints are
defined as left-matching bracket types, to compen-
sate for the non-embedding structure of chunks.
Chunk brackets are tested in conjunction with topo-
logical brackets, and in isolation, using the labelled
precision value of 71.1% in (Skut and Brants, 1998)
as a uniform confidence weight.14
Measures For all runs we measure the absolute
time and the number of parsing tasks needed to com-
pute the first reading. The times in the individual
runs were normalised according to the number of
executed tasks per second. We noticed that the cov-
erage of some integrated runs decreased by up to
1% of the 5060 test items, with a typical loss of
around 0.5%. To warrant that we are not just trading
coverage for speed, we derived two measures from
the primary data: an upper bound, where we asso-
ciated every unsuccessful parse with the time and
number of tasks used when the limit of 70000 pas-
sive edges was hit, and a lower bound, where we
removed the most expensive parses from each run,
until we reached the same coverage. Whereas the
upper bound is certainly more realistic in an applica-
tion context, the lower bound gives us a worst case
estimate of expectable speed-up.
Integration Parameters We explored the follow-
ing range of weighting parameters for prioritisation
(see Section 3.3 and Table 2).
We use two global settings for the heuristic pa-
rameter . Setting  to 1
2
without using any confi-
dence measure causes the priority of every affected
parsing task to be in- or decreased by half its value.
Setting  to 1 drastically increases the influence of
topological information, the priority for rewarded
tasks is doubled and set to zero for penalized ones.
The first two runs (rows with  P  E) ignore
both confidence parameters (conf
pr=ent
=1), measur-
ing only the effect of higher or lower influence of
topological information. In the remaining six runs,
the impact of the confidence measures conf
pr=ent
is
tested individually, namely +P  E and  P +E, by
setting the resp. alternative value to 1. For two runs,
we set the resp. confidence values that drop below
a certain threshold to zero (PT, ET) to exclude un-
14The experiments were run on a 700 MHz Pentium III ma-
chine. For all runs, the maximum number of passive edges was
set to the comparatively high value of 70000.
factor msec (1st) tasks
low-b up-b low-b up-b low-b up-b
Baseline     524 675 3813 4749
Integration of topological brackets w/ parameters
 P  E  1
2
2.21 2.17 237 310 1851 2353
 P  E 1 2.04 2.10 257 320 2037 2377
+P  E  1
2
2.15 2.21 243 306 1877 2288
PT  E  1
2
2.20 2.30 238 294 1890 2268
 P +E  1
2
2.27 2.23 230 302 1811 2330
 P ET  1
2
2.10 2.00 250 337 1896 2503
+P  E 1 2.06 2.12 255 318 2021 2360
PT  E 1 2.08 2.10 252 321 1941 2346
PT with chunk and topological brackets
PT  E  1
2
2.13 2.16 246 312 1929 2379
PT with chunk brackets only
PT  E  1
2
0.89 1.10 589 611 4102 4234
Table 2: Priority weight parameters and results
certain candidate brackets or bracket types. For runs
including chunk bracketing constraints, we chose
thresholded precision (PT) as confidence weights
for topological and/or chunk brackets.
6 Discussion of Results
Table 2 summarises the results. A high impact on
bracket constraints (1) results in lower perfor-
mance gains than using a moderate impact ( 1
2
)
(rows 2,4,5 vs. 3,8,9). A possible interpretation is
that for high , wrong topological constraints and
strong negative priorities can mislead the parser.
Use of confidence weights yields the best per-
formance gains (with  1
2
), in particular, thresholded
precision of bracket types PT, and tree entropy
+E, with comparable speed-up of factor 2.2/2.3 and
2.27/2.23 (2.25 if averaged). Thresholded entropy
ET yields slightly lower gains. This could be due to
a non-optimal threshold, or the fact that ? while pre-
cision differentiates bracket types in terms of their
confidence, such that only a small number of brack-
ets are weakened ? tree entropy as a global measure
penalizes all brackets for a sentence on an equal ba-
sis, neutralizing positive effects which ? as seen in
+/ P ? may still contribute useful information.
Additional use of chunk brackets (row 10) leads
to a slight decrease, probably due to lower preci-
sion of chunk brackets. Even more, isolated use of
chunk information (row 11) does not yield signifi-
01000
2000
3000
4000
5000
6000
7000
0 5 10 15 20 25 30 35
baseline
+PT ?(0.5)
12867 12520 11620 9290
0
100
200
300
400
500
600
#sentences
msec
Figure 5: Performance gain/loss per sentence length
cant gains over the baseline (0.89/1.1). Similar re-
sults were reported in (Daum et al, 2003) for inte-
gration of chunk- and dependency parsing.15
For PT -E  1
2
, Figure 5 shows substantial per-
formance gains, with some outliers in the range of
length 25?36. 962 sentences (length >3, avg. 11.09)
took longer parse time as compared to the baseline
(with 5% variance margin). For coverage losses, we
isolated two factors: while erroneous topological in-
formation could lead the parser astray, we also found
cases where topological information prevented spu-
rious HPSG parses to surface. This suggests that
the integrated system bears the potential of cross-
validation of different components.
7 Conclusion
We demonstrated that integration of shallow topo-
logical and deep HPSG processing results in signif-
icant performance gains, of factor 2.25?at a high
level of deep parser efficiency. We show that macro-
structural constraints derived from topological pars-
ing improve significantly over chunk-based con-
straints. Fine-grained prioritisation in terms of con-
fidence weights could further improve the results.
Our annotation-based architecture is now easily
extended to address robustness issues beyond lexical
matters. By extracting spans for clausal fragments
from topological parses, in case of deep parsing fail-
15(Daum et al, 2003) report a gain of factor 2.76 relative to a
non-PoS-guided baseline, which reduces to factor 1.21 relative
to a PoS-prioritised baseline, as in our scenario.
ure the chart can be inspected for spanning anal-
yses for sub-sentential fragments. Further, we can
simplify the input sentence, by pruning adjunct sub-
clauses, and trigger reparsing on the pruned input.
References
M. Becker and A. Frank. 2002. A Stochastic Topological
Parser of German. In Proceedings of COLING 2002,
pages 71?77, Taipei, Taiwan.
T. Brants. 2000. Tnt - A Statistical Part-of-Speech Tag-
ger. In Proceedings of Eurospeech, Rhodes, Greece.
U. Callmeier. 2000. PET ? A platform for experimenta-
tion with efficient HPSG processing techniques. Nat-
ural Language Engineering, 6 (1):99 ? 108.
C. Carroll and E. Briscoe. 2002. High precision extrac-
tion of grammatical relations. In Proceedings of COL-
ING 2002, pages 134?140.
B. Crysmann, A. Frank, B. Kiefer, St. Mu?ller, J. Pisko-
rski, U. Scha?fer, M. Siegel, H. Uszkoreit, F. Xu,
M. Becker, and H.-U. Krieger. 2002. An Integrated
Architecture for Deep and Shallow Processing. In
Proceedings of ACL 2002, Pittsburgh.
M. Daum, K.A. Foth, and W. Menzel. 2003. Constraint
Based Integration of Deep and Shallow Parsing Tech-
niques. In Proceedings of EACL 2003, Budapest.
D. Duchier and R. Debusmann. 2001. Topological De-
pendency Trees: A Constraint-based Account of Lin-
ear Precedence. In Proceedings of ACL 2001.
C. Grover and A. Lascarides. 2001. XML-based data
preparation for robust deep parsing. In Proceedings of
ACL/EACL 2001, pages 252?259, Toulouse, France.
T. Ho?hle. 1983. Topologische Felder. Unpublished
manuscript, University of Cologne.
R. Hwa. 2000. Sample selection for statistical gram-
mar induction. In Proceedings of EMNLP/VLC-2000,
pages 45?52, Hong Kong.
S. Mu?ller and W. Kasper. 2000. HPSG analysis of
German. In W. Wahlster, editor, Verbmobil: Founda-
tions of Speech-to-Speech Translation, Artificial Intel-
ligence, pages 238?253. Springer, Berlin.
R. Prins and G. van Noord. 2001. Unsupervised pos-
tagging improves parsing accuracy and parsing effi-
ciency. In Proceedings of IWPT, Beijing.
U. Scha?fer. 2003. WHAT: An XSLT-based Infrastruc-
ture for the Integration of Natural Language Process-
ing Components. In Proceedings of the SEALTS Work-
shop, HLT-NAACL03, Edmonton, Canada.
H. Schmid, 2000. LoPar: Design and Implementation.
IMS, Stuttgart. Arbeitspapiere des SFB 340, Nr. 149.
W. Skut and T. Brants. 1998. Chunk tagger: statistical
recognition of noun phrases. In ESSLLI-1998 Work-
shop on Automated Acquisition of Syntax and Parsing.
H. Uszkoreit. 2002. New Chances for Deep Linguistic
Processing. In Proceedings of COLING 2002, pages
xiv?xxvii, Taipei, Taiwan.
 
			Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 9?15,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Parse selection with a German HPSG grammar
Berthold Crysmann?
Institut fu?r Kommunikationswissenschaften, Universita?t Bonn &
Computerlinguistik, Universita?t des Saarlandes
Poppelsdorfer Allee 47
D-55113 Bonn
crysmann@ifk.uni-bonn.de
Abstract
We report on some recent parse selection ex-
periments carried out with GG, a large-scale
HPSG grammar for German. Using a manu-
ally disambiguated treebank derived from the
Verbmobil corpus, we achieve over 81% exact
match accuracy compared to a 21.4% random
baseline, corresponding to an error reduction
rate of 3.8.
1 Introduction
The literature on HPSG parsing of German has al-
most exclusively been concerned with issues of the-
oretical adequacy and parsing efficiency. In contrast
to LFG parsing of German, or even to HPSG work
on English or Japanese, very little effort has been
spent on the question of how the intended, or, for
that matter a likely parse, can be extracted from the
HPSG parse forest of some German sentence. This
issue becomes all the more pressing, as the gram-
mars gain in coverage, inevitably increasing their
ambiguity. In this paper, I shall present preliminary
results on probabilistic parse selection for a large-
scale HPSG of German, building on technology de-
veloped in the Lingo Redwoods project (Oepen et
al., 2002).
?The research reported here has been carried out at the Ger-
man Research Center for Artificial Intelligence (DFKI GmbH)
as part of the projects COLLATE, QALL-ME, and Checkpoint,
funded by the German Federal Ministery for education and Sci-
ence (BMBF), the European Union, and the State of Berlin, re-
spectively. I am also greatly indepted to my colleagues Bernd
Kiefer and Gu?nter Neumann, as well as to Stephan Oepen and
Dan Flickinger for support and comments relating to the work
presented here.
The paper is organised as follows: in section 2, I
shall give a brief overview of the grammar. Section 3
discusses the treebanking effort we have undertaken
(3.1), followed by a presentation of the parse selec-
tion results we achieve using probabilistic models
trained on different feature sets (3.2).
2 The grammar
The grammar used in the experiments reported here
has originally been developed, at DFKI, in the con-
text of the Verbmobil project (Mu?ller and Kasper,
2000). Developed initially for the PAGE devel-
opment and processing platform (Uszkoreit et al,
1994), the grammar has subsequently been ported to
LKB (Copestake, 2001) and Pet (Callmeier, 2000)
by Stefan Mu?ller. Since 2002, the grammar has
been extended and modified by Berthold Crysmann
(Crysmann, 2003; Crysmann, 2005; Crysmann,
2007).
The grammar, codename GG, is a large scale
HPSG grammar for German, freely available un-
der an open-source license: it consists of roughly
4000 types, out of which 290 are parametrised lexi-
cal types, used in the definition of about 35,000 lex-
ical entries. The lexicon is further extended by 44
lexical rules and about 300 inflectional rules. On
the syntactic side, the grammar has about 80 phrase
structure rules.
The grammar covers all major aspects of German
clausal and phrasal syntax, including free word or-
der in the clausal domain, long-distance dependen-
cies, complex predicates, passives, and extraposition
(Crysmann, 2005). Furthermore, the grammar cov-
ers different coordination constructions, including
9
the so-called SGF coordination. Furthermore, the
grammar is fully reversible, i.e. it can be used for
parsing, as well as generation.
The phrase structure rules of the grammar are
either unary or binary branching phrase structure
schemata, permitting free interspersal of modifiers
between complements in the clausal domain. The
relatively free order of complements is captured by
means of lexical rules which permute the elements
on the COMPS valence list. As a result, the verb?s
complements can be saturated in any order.
The treatment of verb placement is somewhat spe-
cial: in sentences without a right sentence bracket, a
left branching structure is assumed, permitting effi-
cient processing. Whenever the right bracket is oc-
cupied by a non-finite verb cluster, the finite verb in
the left bracket is related to the clause finla cluster
by means of simulated head movement, following
the proposal by (Kiss and Wesche, 1991), inter alia.
As a consequence, the grammar provides both head-
initial and head-final versions of the Head-Adjunct,
Head-Complement and Head-Subject schemata.
As output, the grammar delivers detailed seman-
tic representations in the form of Minimal Recursion
Semantics (Copestake et al, 2005). These represen-
tations have been successfully used in the context
of automated email response or question answering
(Frank et al, 2006). Most recently, the grammar has
been used for automatic correction of grammar and
style errors, combining robust parsing with genera-
tion.
3 Parse Selection
3.1 Treebank construction
The treebank used in the experiments reported here
has been derived from the German subset of the
Verbmobil (Wahlster, 2000) corpus. In essence, we
removed any duplicates on the string level from the
corpus, in order to reduce the amount of subsequent
manual annotation. Many of the duplicates thus re-
moved were short interjection, such as ja ?yes?, nein
?no?, or hm ?euhm?, which do not give rise to any
interesting structural ambiguities. As a side effect,
removal of these duplicates also enhanced the qual-
ity of the resulting treebank.
The construction of the disambiguated treebank
for German followed the procedure suggested for
English by (Oepen et al, 2002): the corpus was first
analysed with the German HPSG GG, storing the
derivation trees of all successful parses. In a sub-
sequent annotation step, we manually selected the
best parse, if any, from the parse forest, using the
Redwoods annotation tool cited above.
After removal of duplicates, syntactic coverage
of the corpus figured at 69.3 percent, giving a to-
tal of 11894 out of 16905 sentences. The vast ma-
jority of sentences in the corpus are between 1 and
15 words in length (14757): as a result, average
sentence length of parsed utterances figures at 7.64,
compared to 8.72 for the entire corpus. Although av-
erage sentence length is comparatively low, the tree-
bank still contains items up to sentence length 47.
The 11894 successfully parsed sentences have
subsequently been disambiguated with the Red-
woods treebanking tool, which is built on top of
LKB (Copestake, 2001) and [incr tsdb()] (Oepen,
2002). Figure 2 shows the annotation of an exam-
ple sentence from the treebank.
During annotation, 10356 sentences were suc-
cessfully disambiguated to a single reading (87.1%).
Another 276 sentences were also disambiguated, yet
contain some unresolved ambiguity (2.3%), while
95 sentences were left unannotated (0.8%). The re-
maining 1167 items (=9.8%) were rejected, since
the parse forest did not contain the desired reading.
Since not all test items in the tree bank were am-
biguous, we were left, after manual disambiguation,
with 8230 suitable test items, i.e. test items where
the number of readings assigned by the parser ex-
ceeds the number of readings judged as acceptable.
Average ambiguity of fully disambiguated sen-
tences in the tree bank is around 12.7 trees per sen-
tence. This corresponds to a baseline of 21.4% for
random parse selection, owing to the unequal distri-
bution of low and high ambiguity sentences.
3.2 Parse selection
3.2.1 Feature selection
The parse selection experiments reported on here
have been performed using the LOGON branch of
the LKB and [incr tsdb()] systems. In particular, we
used Rob Malouf?s tadm maximum entropy toolkit
for training and evaluation of our log-linear parse
selection models.
10
212.5i?length in [30 .. 35| 020 0.0031.63 0.0211.1
i?length in [10 .. 15|
111
i?length in [0 .. 5|
2100
30.0032.00
12.7
2661
11.63
33.0226.3
283
3.16
24.8
8
5.04
2.8
333
30.50
12.9
83
11.83
95
3.63
40.2
9.80
3.8
1706
65.4
49.0
2418
11.43
11
3.21
17.27 63.5
800.0
7
0
16.71
0.00
76.6
i?length in [25 .. 30|
0.0
56
0
26.70
0.00
5.9
377.5
0.0
89
26
Total
7.00
26.58
11894
10.1
508.3
9.07
42
27
17.2
7.05
282.726.41
1167
9.3
3
11.43
25.67
55.5
98.0
10349
0
7.32
0.00
i?length in [45 .. 50|
0.0
2 47.00 800.0
i?length in [20 .. 25|
0
172
0.00
21.3
21.54
0.0
24
173.0
2
11.33
69
46.00
28.5
21.72
1636.0
37
203.4
0
11.51
99
0.00
44.2
21.52
0.0 0 0.00
2.6
0.0
154 1.44
i?length in [35 .. 40|
5.8
6
6
36.78
3.67
136.2
545.2
1.7
i?length in [15 .. 20|
2
5
i?length in [5 .. 10|
650
20.50
37.60
6227
16.58
92.0
327.0
6.84
70.1
2
1
6.3
185
20.00
36.00
455
16.59
1023.5
7.24
81.3
10.2
447
5641
16.35
6.74
trees
?
trees
?
trees
?
t?active = 0 unannotated
items
#
words
?
t?active > 1
words
?
words
?
trees
?
t?active = 1
items
#
Aggregate items
#
words
?
items
#
all results
items
#
trees
?
words
?
(generated by [incr tsdb()] at 24?mar?08 (22:28))
Figure 1: The GG Verbmobil treebank
Figure 2: An example from the German treebank, featuring the Redwoods annotation tool
11
All experiments were carried out as a ten-fold
cross-evaluation with 10 iterations, using 10 differ-
ent sets of 7407 annotated sentences for training and
10 disjoint sets of 823 test items for testing.
The discriminative models we evaluate here were
trained on different subsets of features, all of which
were extracted from the rule backbone of the deriva-
tions stored in the treebank. As node labels, we used
the names of the HPSG rules licensing a phrasal
node, as well as the types of lexical entries (preter-
minals). On the basis of these derivation trees,
we selected several features for training our disam-
biguation models: local trees of depth 1, several lev-
els of grandparenting, i.e. inclusion of grandpar-
ent node (GP 2), great-grandparent node (GP 3) and
great-great-grandparent node (GP 4), partial trees of
depth 1 (+AE). Grandparenting features involve lo-
cal trees of depth 1 plus a sequence of grandparent
nodes, i.e. the local tree is contextualised in relation
to the dominating tree. Information about a grand-
parent?s other daughters, however, is not taken into
consideration. Partial trees, by contrast, are included
as a kind of back-off model.
In addition to tree-configurational features, we ex-
perimented with n-gram models, using n-gram sizes
between 2 and 4. These models were further varied,
according to whether or not a back-off model was
included.
Apart from these linguistic features, we also var-
ied two parameters of the maximum entropy learner,
viz. variance and relative tolerance. The relative tol-
erance parameter restricts convergence of the model,
whereas variance defines a prior in order to reduce
over-fitting. In the results reported here, we used
optimal setting for each individual set of linguistic
parameters, although, in most cases, these optimal
values figured at 10?4 for variance and 10?6 for rel-
ative tolerance.
3.2.2 Results
The results of our parse selection experiments for
German are summarised in tables 1 and 2, as well as
figures 3 and 4.
As our major result, we can report an exact match
accuracy for parse selection of 81.72%, using great-
grandparenting (GP 3) and 4-grams. This result cor-
responds to an error reduction by a factor of 3.8, as
compared to the 21.4% random baseline.
?AE +AE
GP 0 77.96 78.14
GP 2 81.27 80.87
GP 3 81.34 80.4
GP 4 81.49 80.78
Table 1: PCFG model with Grandparenting
Figure 3: PCFG model with Grandparenting
Apart from the overall result in terms of achiev-
able parse selection accuracy, a comparison of the
individual results is also highly informative.
As illustrated by figure 3, models including any
level of grandparenting clearly outperform the basic
model without grandparenting (GP0). Furthermore,
relative gains with increasing levels of grandparent-
ing are quite low, compared to the more than 3% in-
crease in accuracy between the GP0 and GP2 mod-
els.
Another interesting observation regarding the data
in table 1 and figure 3 is that the inclusion of par-
tial constituents into the model (+AE) only benefits
the most basic model. Once the more sophisticated
grandparenting models are used, partial constituent
worsen rather than improve the overall performance.
Another observation we made regarding the rela-
tive usefulness of the features we have employed re-
lates to n-gram models: again, we find that n-gram
models clearly improve on the basic model without
grandparenting (by about 1 percentage point), al-
beit to a lesser degree than grandparenting itself (see
12
N0 N2 N3 N4
GP 0 77.96 78.79 78.92 78.74
GP 2 81.27 81.5 81.65 81.55
GP 3 81.34 81.44 81.51 81.72
GP 4 81.49 81.62 81.69 81.67
Table 2: PCFG model with Grandparenting & N-grams
Figure 4: PCFG model with Grandparenting & N-Grams
(-AE)
above). With grandparenting added, however, the
relative gains of the n-gram models greatly dimin-
ishes. A possible explanation for this finding is that
reference to grandparenting indirectly makes avail-
able information about the preceding and linear con-
text, obviating the need for direct encoding in terms
of n-grams. Again, the best combined model (hier-
archy + n-grams) outperforms the best purely hierar-
chical model by a mere 0.23 percentage points. The
results obtained here for German thus replicate the
results established earlier for English, namely that
the inclusion of n-gram information only improves
overall parse selection to a less significant extent.
A probably slightly unsurprising result relates
to the use of back-off models: we found that n-
gram models with backing-off yielded better results
throughout our test field than the correspoding n-
gram models that did not use this feature. Differ-
ences, however, were not dramatic, ranging roughly
between 0.07 and 0.3 percentage points.
The results obtained here for German compare
quite well to the results previously achieved for the
ERG, a broad coverage HPSG for English: using
a similar treebank1 (Toutanova et al, 2002) report
81.80 exact match accuracy for a log-linear model
with local trees plus ancestor information, the model
which is closest to the models we have evaluated
here. The baseline in their experiments is 25.81. The
best model they obtain includes semantic dependen-
cies, as well, yielding 82.65 exact match accuracy.
Probably the most advanced approach to parse se-
lection for German is (Forst, 2007): using a broad
coverage LFG grammar, he reports an f-score of
83% of correctly assigned dependency triples for a
reference corpus of manually annotated newspaper
text. However, it is unclear how these figures relate
to the exact match accuracy used here.
Relevant, in principle, to our discussion here, are
also the results obtained with treebank grammars for
German: (Dubey and Keller, 2003) have trained a
PCFG on the Negra corpus (Skut et al, 1998), re-
porting labelled precision and recall between 70 and
75%. (Ku?bler et al, 2006) essentially confirm these
results for the Negra treebank, but argue instead that
probabilistic parsing for German can reach far bet-
ter results (around 89%), once a different treebank
is chosen, e.g. Tu?ba-D/Z. However, it is quite dif-
ficult to interpret the significance of these two tree-
bank parsers for our purposes here: not only is the
evaluation metric an entirely different one, but so are
the parsing task and the corpus.
In an less recent paper, however, (Ruland, 2000)
reports on probabilistic parsing of Verbmobil data
using a probabilistic LR-parser. The parser has been
trained on a set of 19,750 manually annotated sen-
tences. Evaluation of the parser was then performed
on a hold-out set of 1000 sentences. In addition to
labelled precision and recall, (Ruland, 2000) also
report exact match, which figures at 46.3%. Us-
ing symbolic postprocessing, exact match improves
to as much as 53.8%. Table 3.2.2 summarizes Ru-
land?s results, permitting a comparison between ex-
act match and PARSEVAL measures. Although the
test sets are certainly not fully comparable,2 these
1In fact, the Redwoods treebank used by (Toutanova et al,
2002) was also derived from Verbmobil data. The size of the
treebank, however, is somewhat smaller, containing a total of
5312 sentences.
2The overall size of the treebank suggests that we are ac-
13
German
Not parsed 4.3%
Exact match 53.8%
LP 90.8%
LR (all) 84.9%
LR (in coverage) 91.6%
Table 3: Performance of Ruland?s probabilistic parser
(with postprocessing) on Verbmobil data
figures at least gives us an indication about how to
judge the the performance of the HPSG parse selec-
tion models presented here: multiplying our 69.3%
coverage with 81.72% exact match accuracy still
gives us an overall exact match accuracy of 56.6%
for the entire corpus.
However, comparing our German treebank to
a structurally similar English treebank, we have
shown that highly comparable parse selection fig-
ures can be obtained for the two languages with es-
sentially the same type of probabilistic model.
4 Conclusion
We have presented a treebanking effort for a large-
scale German HPSG grammar, built with the Red-
woods treebank technology (Oepen et al, 2002), and
discussed some preliminary parse selection results
that are comparable in performance to the results
previously achieved for the English Resource Gram-
mar (lingoredwoods:2002tlt). Using a treebank of
8230 disambiguated sentences, we trained discrim-
inative log-linear models that achieved a maximal
exact match accuracy of 81.69%, against a random
baseline of 21.4%. We further investigated the im-
pact of different levels of grandparenting and n-
grams, and found that inclusion of the grandpar-
ent node into the model improved the quality sig-
nificantly, reference, however, to any higher nodes
only lead to very mild improvements. For n-grams
we could only observe significant gains for models
without any grandparenting. We therefore hope to
test these findings against treebanks with a higher
syntactic complexity, in the near future, in order to
tually dealing with the same set of primary data. However, in
our HPSG treebank string-identical test items had been removed
prior to annotation and training. As a result, our treebank con-
tains less redundancy than the original Verbmobil test suites.
establish whether these observations are indeed ro-
bust.
References
Ulrich Callmeier. 2000. PET ? a platform for experi-
mentation with efficient HPSG processing techniques.
Journal of Natural Language Engineering, 6(1):99?
108.
Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan
Sag. 2005. Minimal recursion semantics: an intro-
duction. Research on Language and Computation,
3(4):281?332.
Ann Copestake. 2001. Implementing Typed Feature
Structure Grammars. CSLI Publications, Stanford.
Berthold Crysmann. 2003. On the efficient implemen-
tation of German verb placement in HPSG. In Pro-
ceedings of RANLP 2003, pages 112?116, Borovets,
Bulgaria.
Berthold Crysmann. 2005. Relative clause extraposition
in German: An efficient and portable implementation.
Research on Language and Computation, 3(1):61?82.
Berthold Crysmann. 2007. Local ambiguity packing
and discontinuity in german. In T. Baldwin, M. Dras,
J. Hockenmaier, T. H. King, and G. van Noord, editors,
Proceedings of the ACL 2007 Workshop on Deep Lin-
guistic Processing, pages 144?151, Prague, Czech Re-
public, June. Association for Computational Linguis-
tics.
Amit Dubey and Frank Keller. 2003. Probabilistic pars-
ing for german using sister-head dependencies. In
ACL, pages 96?103.
Martin Forst. 2007. Filling statistics with linguistics
? property design for the disambiguation of german
lfg parses. In ACL 2007 Workshop on Deep Linguis-
tic Processing, pages 17?24, Prague, Czech Republic,
June. Association for Computational Linguistics.
Anette Frank, Hans-Ulrich Krieger, Feiyu Xu, Hans
Uszkoreit, Berthold Crysmann, Brigitte Jo?rg, and Ul-
rich Scha?fer. 2006. Querying structured knowledge
sources. Journal of Applied Logic.
Tibor Kiss and Birgit Wesche. 1991. Verb order
and head movement. In Otthein Herzog and Claus-
Rolf Rollinger, editors, Text Understanding in LILOG,
number 546 in Lecture Notes in Artificial Intelligence,
pages 216?240. Springer-Verlag, Berlin.
Sandra Ku?bler, Erhard W. Hinrichs, and Wolfgang Maier.
2006. Is it really that difficult to parse german? In
Proceedings of EMNLP 2006, Sydney, Australia.
Stefan Mu?ller and Walter Kasper. 2000. HPSG analy-
sis of German. In Wolfgang Wahlster, editor, Verb-
mobil: Foundations of Speech-to-Speech Translation,
pages 238?253. Springer, Berlin.
14
Stephan Oepen, E. Callahan, Daniel Flickinger, Christo-
pher Manning, and Kristina Toutanova. 2002. LinGO
Redwoods: A rich and dynamic treebank for HPSG.
In Beyond PARSEVAL. Workshop at the Third Interna-
tional Conference on Language Resources and Evalu-
ation, LREC 2002, Las Palmas, Spain.
Stephan Oepen. 2002. Competence and Performance
Profiling for Constraint-based Grammars: A New
Methodology, Toolkit, and Applications. Ph.D. thesis,
Saarland University.
Tobias Ruland. 2000. Probabilistic LR-parsing with
symbolic postprocessing. In Wolfgang Wahlster, ed-
itor, Verbmobil: Foundations of Speech-to-Speech
Translation, pages 147?162. Springer, Berlin.
Wojciech Skut, Thorsten Brants, and Hans Uszkoreit.
1998. A linguistically interpreted corpus of Ger-
man newspaper text. In Proceedings of the ESSLLI
Workshop on Recent Advances in Corpus Annotation,
Saarbru?cken, Germany.
Kristina Toutanova, Christopher D. Manning, Stuart M.
Shieber, Dan Flickinger, and Stephan Oepen. 2002.
Parse disambiguation for a rich HPSG grammar. In
Proceedings of the First Workshop on Treebanks and
Linguistic Theories (TLT2002), pages 253?263, So-
zopol, Bulgaria.
Hans Uszkoreit, Rolf Backofen, Stephan Busemann,
Abdel Kader Diagne, Elizabeth Hinkelman, Wal-
ter Kasper, Bernd Kiefer, Hans-Ulrich Krieger,
Klaus Netter, Gu?nter Neumann, Stephan Oepen, and
Stephen P. Spackman. 1994. Disco - an hpsg-
based nlp system and its application for appoint-
ment scheduling. In Proceedings of the 15th In-
ternational Conference on Computational Linguistics
(COLING?94), August 5-9, volume 1, pages 436?440,
Kyoto, Japan.
Wolfgang Wahlster, editor. 2000. Verbmobil: Foun-
dations of Speech-to-Speech Translation. Springer,
Berlin.
15
Proceedings of the 5th Workshop on Important Unresolved Matters, pages 144?151,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Local ambiguity packing and discontinuity in German
Berthold Crysmann
DFKI GmbH & Saarland University
Stuhlsatzenhausweg 3
D-66123 Saarbru?cken
crysmann@dfki.de
Abstract
We report on recent advances in HPSG pars-
ing of German with local ambiguity pack-
ing (Oepen and Carroll, 2000), achieving a
speed-up factor of 2 on a balanced test-suite.
In contrast to earlier studies carried out for
English using the same packing algorithm,
we show that restricting semantic features
only is insufficient for achieving acceptable
runtime performance with a German HPSG
grammar. In a series of experiments relating
to the three different types of discontinuities
in German (head movement, extraction, ex-
traposition), we examine the effects of re-
strictor choice, ultimately showing that ex-
traction and head movement require partial
restriction of the respective features encod-
ing the dependency, whereas full restriction
gives best results for extraposition.
1 Introduction
It is a well-known fact that chart parsing with-
out techniques for local ambiguity packing (Earley,
1970) faces a combinatorial explosion of the search
space, owing to the (structural) ambiguity immi-
nent to natural language. Thus, identical edges with
different internal derivation history can be packed
into a single representative for further processing,
thereby effectively solving the complexity issue. In
context-free grammars augmented with a unifica-
tion formalism, packing based on the CF symbol
equality has been complemented by subsumption- or
disjunction-based packing of the associated feature
structures (Moore and Alshawi, 1992; Maxwell and
Kaplan, 1995). For parsing with constraint-based
grammars, such as HPSG, which do not possess an
explicit context-free backbone, (Oepen and Carroll,
2000) have proposed an efficient packing algorithm
based on feature structure subsumption only.
In contrast to the symbols in context-free gram-
mars, feature structures in unification-based gram-
mars often include information encoding (part of)
the derivation history, most notably semantics. In or-
der to achieve successful packing rates, feature re-
striction (Shieber, 1985) is used to remove this in-
formation during creation of the packed parse forest.
During the unpacking phase, which operates only
on successful parse trees, these features are unified
back in again.
For their experiments with efficient subsumption-
based packing, (Oepen and Carroll, 2000) experi-
mented with different settings of the packing restric-
tor for the English Resource Grammar ERG (Copes-
take and Flickinger, 2000): they found that good
packing rates, and overall good performance dur-
ing forest creation and unpacking were achieved, for
the ERG, with partial restriction of the semantics,
e.g. keeping index features unrestricted, since they
have an impact on external combinatorial potential,
but restricting most of the internal MRS represen-
tation, including the list of elementary predications
and scope constraints. Restriction of syntactically
potent features, has thus been found both unneces-
sary and less efficient.
First experiments in ambiguity packing with a
German HPSG grammar (GG; http://gg.dfki.de) re-
vealed that restriction of semantics only does not
give rise to any acceptible results in terms of runtime
performance. It became clear quite quickly that the
144
bulk of failing subsumptions impeding creation of a
sufficiently compact forest were related to two syn-
tactic features, SLASH and DSL. In German, these
features contain references to non-empty valence
lists, which eventually wind up encoding derivation
history. Using a more aggressive restrictor to elim-
inate these features during forest creation did not
show the desired performance either: owing to mas-
sive overgeneration, the resulting forest was either
not compact enough, or most of the efficiency gains
were wasted on unpacking failures in the second
phase.
In this paper we report on recent advances with
local ambiguity packing for German, showing how
partial restriction can achieve good packing rates at
negligible unpacking cost, yielding an overall speed-
up by a factor of 2, as compared to parsing without
ambiguity packing. Running a series of experiments
with different restrictor setting for three different
features involved with non-local dependencies we
examine in detail how the choice of restrictor affects
the observable performance. The paper is organised
as follows: section 2 will give an overview of the rel-
evant syntactic constructions of German, and their
implementation in GG. Section 3 gives a description
of the experimental setup (3.1), followed by a dis-
cussion of the main results (3.2), detailing how dif-
ferent settings for feature restriction affect parsing
performance.
2 Discontinuity in German
Head movement German, in contrast to English is
a verb-final language with a verb-second effect, that
is, non-finite verbs are standardly placed sentence-
finally. In clauses other than complementizer-
introduced subclauses and relative clauses, the finite
verb surfaces in a clause-initial position (either first
or second). Any major constituent may occupy the
topic position preceding the finite verb, including
subject, complements or modifiers.
Owing to the V2 effect, the parts of a verb cluster
are discontinuous. Since both the finite verb and the
non-finite verb cluster impose constraints on con-
stituents in the Mittelfeld, standard approaches to
German syntax in HPSG assume, since (Kiss and
Wesche, 1991), that the initial verb is related to
the final verb cluster by means of head movement:
clause-finally, a trace is inserted that combines the
Montag
N
NP-A-V-MOD
lasse
V
ich
NP-NOM-SG
ihn
NP-ACC-SG
dem
D
Mann
N
NP-DAT
helfen
V
EPS
EPS/NP-A-V-MOD
EPS/NP-A-V-MOD
EPS/NP-A-V-MOD
EPS/NP-A-V-MOD
S/NP-A-V-MOD
S
Figure 1: DSL: Monday let he him the man help
argument structure of the final cluster with the sub-
categorisation requirements percolated down from
the finite verb using a special feature DSL (=?dou-
ble SLASH?). Arguments in the Mittelfeld are satu-
rated as complements of the clause-final trace. The
grammar used here assumes head movement for dis-
continuous predicates (Crysmann, 2003), following
in this respect the earlier implementation by (Mu?ller
and Kasper, 2000). In order to relate the initial verb
to the verb cluster and its arguments in the Mit-
telfeld, like the subject and direct object in figure 2,
the DSL (or V1) feature must percolate subcategori-
sation requirements for subject and object, as well as
for the verb cluster. At the gap site, the valence in-
formation percolated via DSL is inserted into the ac-
tual valence lists of the verb trace. Since the require-
ments are matched against actual arguments found
in the Mittelfeld, the valence lists contained in DSL
get instantiated to whatever argument it satisfies,
thereby creating a partial representation of deriva-
tion history. While theoretically, this is just the right
behaviour, it has clear repercussions for parsing with
ambiguity packing.
Partial VP fronting Another aspect, in which the
syntax of German differs from that of English is
in the area of extraction: while in English only
constituents with a saturated COMPS list can un-
dergo wh-movement, this is not the case in Ger-
man: as shown in figure 2, the verb schenken
?give/donate? has been fronted, leaving its two com-
plements behind.
In HPSG, partial VP fronting is analysed by
a combination of two mechanisms (Mu?ller, 1999;
Nerbonne, 1994): first, standard argument com-
position in the verb cluster, following (Hinrichs
and Nakazawa, 1990), combined with a standard
SLASH-based treatment of long-distance extraction.
Again, since argument composition is performed
145
schenken
V
V
hat
V
er
NP-NOM-SG
ihm
NP-DAT
das
D
Buch
N
NP-ACC-SG
wollen
V
V/V
V/V
EPS/V
EPS/V
EPS/V
EPS/V
S/V
S
Figure 2: SLASH: give has he him the book wanted
by strcuture-sharing, i.e. reentrancy between the va-
lence list of the governing predicate and the unsatu-
rated valence list of the governed predicate, extrac-
tion of the governed predicate by means of SLASH
percolation carries this reentrancy over into SLASH.
From a general linguistic point of view, this is highly
desirable, because valence requirements of the ex-
tracted verb must be matched against the arguments
that satisfy them in the Mittelfeld. The only draw-
back is, that we are confronted, again, with a syntac-
tic feature containing, among other things, records
of derivation history.
3 Evaluation
3.1 Test setup
In order to systematically investigate the effect of re-
striction of syntactically potent features on the pars-
ing efficiency with local ambiguity packing, we cre-
ated a test field consisting of 8 different parameter
settings (out of 27 logically possible settings): 1 run
without packing, 1 run with optimal settings for the
three features under consideration, and 2 runs with
suboptimal settings for each of the three features.
All test runs were performed on a balanced test
suite extracted from the Verbmobil corpus, using
100 items per input length, from sentence length 1
to 22, thus totalling 2200 test items. Although the
Verbmobil corpus does contain test sentences of up
to 70 words long, their number drops quite quickly
from sentence length 23 on.
The parser used in the experiments is the cur-
rent SVN version of Pet (Callmeier, 2000), run-
ning the March 24 version of GG (http://gg.dfki.de;
(Mu?ller and Kasper, 2000; Crysmann, 2003; Crys-
mann, 2005)). Tests were run on an Intel Core Duo
machine using a single T2600 CPU at 2.16GHz with
2 GB main memory.
To ensure that we can study parser performance
on input of increasing length, we used a rather gener-
ous upper limit of 150,000 passive edges. Taking as
a guideline the average space consumption per edge
of the non-packing parser, we calculated that pars-
ing could still be done comfortably in main memory,
i.e., without using swap space.
All measurements were performed using the [incr
tsdb()] profiling platform (Oepen and Flickinger,
1998). Parsing times reported are total CPU times
(in seconds), including exhaustive unpacking of the
parse forest, whenever applicable.
3.2 Results
The main result of our study is that local ambiguity
packing in constraint-based parsing of German can
lead to performance improvements, once feature re-
striction is extended from purely semantic features
to syntactically potent features used to model dis-
continuity, such as SLASH, DSL, and ANC (see be-
low). We also found that positive performance ef-
fects could only be achieved, if SLASH and DSL
features were partially restricted in such a way as to
only eliminate all records of derivation history (in
terms of instatiated subcategorisation lists), while
retaining most of the other constraints represented
in these features.
Compared to a non-packing baseline parser with
feature structure unfilling, we observed an overall
speed-up by a factor of 2 with local ambiguity pack-
ing on a balanced test suite. As shown by figure
3.2, local ambiguity packing with optimal restrictor
settings is effective in taming the combinatorial ex-
plosition of the search observed by the non-packing
parser.
Analogous to the reduction in search space, per-
formance savings grow continuously with increas-
ing input length: from sentence length 14 onwards
(factor 0.84) relative processing time decreases con-
tinually up to a factor of 0.27 at sentence length
22. With an average CPU time of 0.69s at sentence
length 22, performance is by far better than real-
time behaviour. Note further, that the non-packing
parser benefits here from a ceiling effect: with 25 out
of 2200 test items (1%), the available resources of
150,000 passive chart edges were exhausted before
the search space was fully explored. With ambiguity
packing under an appropriate restrictor, by contrast,
the search space was fully explored.
146
1 3 5 7 9 11 13 15 17 19 21
String Length
0
20000
40000
60000
80000
100000
120000
140000
No packing
???? ??? ????? ??? ?? ?????????? ?
???
?
? ???
?
?
?
? ????
?
??
???
????
??
?
????
???
?
????
?
?
?
?
?
?
?
?
?
??
?
?
??
?
??
?
?
?
?
?? ??
?
????
?
?
?
???
?
??
?
?
?
??
?
?
?
?
??
?
?
?
??
?
?
??
?
????
?
?
?
??
?
?
?
?
??
?
?
?
?
?
?
???
?
?
??
?
?
?
?
???
?
??
?
??
?
?
?
?
?
??
??
?
?
?
?
?
?
??
?
?
?
?
?
?
?
?
??
?
?
?
?
?
?
?
?
??
?
?
?
?
??
?
?
? ? passive edges
1 3 5 7 9 11 13 15 17 19 21
String Length
0
20000
40000
60000
80000
100000
120000
140000
Packing w/ partial SLASH/DSL; no ANC
?? ?? ?? ?? ?? ?? ?? ???? ?? ??? ???????? ???? ???????? ????? ??
? ????
?? ?????
??
?
????
?? ????
?
????????
?
?
??
? ? passive edges
Figure 3: Comparison of chart size relative to input length
1 3 5 7 9 11 13 15 17 19 21
String Length
0
2
4
6
8
10
12
14
16
18
20
22
No packing (unfilling)
(generated by [incr tsdb()] at 25-mar-2007 (17:44 h))      









 




 






























































































 ? Total CPU time (s)
1 3 5 7 9 11 13 15 17 19 21
String Length
0
2
4
6
8
10
12
14
16
18
20
22
Packing w/ partial SLASH/DSL; no ANC
      

 









 
 




 


































 ? Total CPU time (s)
Figure 4: Comparison of processing time relative to input length
Restricting DSL The first syntactically potent
feature investigated in these experiments is the fea-
ture DSL (or V1), which serves to relate, by means
of simulated head movement, the finite verb in
clause-second position to the clause-final verb clus-
ter. Essentially, this feature is used to pass down
the valence information from the initial verb to the
clause-final verb trace, where this valence informa-
tion is combined with that of the cluster. In the
grammar under consideration, verb movement is re-
stricted to discontinuous verb clusters (Crysmann,
2003), i.e., to situations where there is either an overt
verb cluster, or a stranded verb particle in the right
sentence bracket.
Since actual or putative arguments of the verb
trace must be checked against the actual valence in-
formation of the V2 verb, derivation history must be
carried along as part of the DSL feature.
Obviously, any feature that (partially) encodes
derivation history is a potential threat to efficient
ambiguity packing. We therefore experimented with
three different settings regarding restriction of this
feature: full restriction, no restriction, and a par-
tial restriction, where only constraints pertaining to
HEAD information of the final cluster were retained,
such as category, or form (most crucial for stranded
particles).
Results are summarised in table 1. Besides the
feature studied here, the restrictor includes the se-
1Here, and in the following two tables ? stands for packing
under equivalence, = for proactive packing, < for retroactive
packing, and ? for freezing.
147
Edges Time (s) Unpack (s) Subsumption ? = < ? Factor (time) Subs. cost Pack rate
Unfill 6424 0.56 0 0 0 0 0 0 1 N/A 0
Partial DSL 1494 0.28 0.01 36404.15 307.28 193.33 36.67 335.84 0.5 67.76 0.36
Full DSL 1832 1.96 0.01 363840.47 186.19 111.31 42.96 251.32 3.5 1068.68 0.19
No DSL 1917 0.61 0.01 106392.57 568.34 484.68 80.8 926.79 1.09 93.83 0.59
Table 1: Performance of packed parsing with different restriction of DSL1
mantic features like RELS and HCONS, as in
(Oepen and Carroll, 2000), as well as optimal set-
tings for SLASH and ANC.
Leaving DSL unrestricted features the lowest
number of packings, amongst the three settings,
both in absolute terms, and in relative packings per
edge (0.19). As a consequence, average chart size is
bigger than with either partially or fully restricted
DSL. Another negative behaviour of packed pars-
ing with an unrestricted DSL is the incommensu-
rate number of subsumption tests carried out: at a
ratio of 1068.68 subsumption tests per packing, this
accounts chiefly for the inefficiency, in particular,
when compared to the much more moderate rates
of 67.76 and 93.83 achieved with partially restricted
and fully restricted DSL. Thus, even though over-
all chart size is reduced when compared to parsing
without ambiguity packing, these savings in space
are not sufficient enough to pay off the overhead in-
curred by testing for subsumption. As a net effect,
overall parsing time is 3.5 times longer compared to
the non-packing baseline.2
Fully restricting DSL by contrast yields a very
good packing rate (0.59) at moderate costs in terms
of subsumption test per packing (93.83). However,
with the grammar not being restrictive enough dur-
ing forest creation, overall chart size is bigger (1832
passive edges) than with partially restricted DSL
(1494). Best results are obtained with partially re-
stricted DSL, where derivation history in terms of
actual or putative arguments of the verb trace is re-
moved, but reference to HEAD information of the
final cluster is maintained, thereby ensuring that the
initial verb only combines with appropriate verb
clusters. This not only leads to the most compact
chart, but also features the lowest number of sub-
sumption tests, both absolute and relative. In sum,
2Edges in packed parsing are actually more costly than in
parsing without ambiguity packing. Since efficient subsumption
checking and feature structure unfilling are mutually exclusive,
edges in general consume much more space when parsing with
ambiguity packing, increasing the cost of copying in unification.
partial restriction of DSL was the only setting that
actually beat the baseline defined by parsing with-
out ambiguity packing.
Restricting SLASH The second experiment we
carried out relates to the feature SLASH, used for
long-distance dependencies. Owing to the V2 ef-
fect in German, constituents in the clause-initial pre-
verbal position are typically placed there by means
of extraction, including unmarked subjects. This dif-
fers quite clearly from English, where standard SVO
order does not involve any movement at all. Another
striking difference between the two languages is that
German, but not English permits fronting of par-
tial VPs: in complex predicates, as witnessed with
modals and control verbs, as well as in auxiliary-
participle combinations, the downstairs predicate
can be fronted, leaving part (or even all) of its com-
plements to be realised in the Mittelfeld. Since Ger-
man is a non-configurational language, pretty much
any combination of fronted vs. stranded comple-
ments can be found, in any order. In GG, partial
VP fronting is effected by special extraction rules,
which removes the valency of pertaing to the fronted
verb from the subcategorisation list of the embed-
ding predicate, and inserts it into SLASH. Simulta-
neously, the remaining complements of the embed-
ding verb are composed with the locally underspec-
ified subcategorisation list of the extracted verbal
complement. In order to match the subcategorisation
requirement of the extracted verb with those of its
complements that are realised in the Mittelfeld, the
subcategorisation list must be percolated via SLASH
as well. Since elements on the subcategorisation list
in SLASH are reentrant with elements on the com-
posed subcategorisation list of the embedding pred-
icate, the former gets specified to the complements
that saturate the requirements in the Mittelfeld. As a
result, we observe a massive encoding of derivation
history in SLASH.
Besides the rules for partial VP fronting, the
grammar recognises 3 more extraction rules, one for
148
subject, one for non-subject complements, and one
for adjuncts. Out of these three, only adjunct ex-
traction rules encode reference to their extraction
context in SLASH: since modifiers select the heads
they adjoin to via a feature MOD, which is reentrant
with the SYNSEM of that head, they inevitably carry
along a good deal of that head?s derivation history.
We tested three different configurations of the re-
strictor: one with unrestricted SLASH, one where
the entire SLASH feature was removed during for-
est creation, and a partially restricted variant. This
partially restricted variant preserves the full SLASH
representation for ordinary subject and complement
extraction, but uses an impoverished representation
for adjunct extraction and partial VP fronting. Tech-
nically, this was achieved by using two SLASH fea-
tures in parallel: an auxiliary, impoverished SLASH
to be used during forest creation, and the full
SLASH feature during unpacking. For adjunct ex-
traction and partial VP fronting, SLASH contains
type restrictions on the head value of the fronted el-
ement, together with restrictions on the saturation of
valence lists, if applicable.3 For subject and comple-
ment extraction SLASH contains the same infor-
mation as SLASH. In sum, partial restriction tries
to maximise restrictiveness in those case, where no
reference to the extraction context is encoded in
SLASH, while at the same time it minimises encod-
ing of derivation history in the other cases, by re-
placing token identity with somewhat weaker type
constraints.
The results of this second experiment are sum-
marised in table 2. Again, we have used optimal set-
tings for DSL and ANC, as established by indepen-
dent experiments.
Parallel to our observations regarding the restric-
tion of DSL, we observe that performance is worst
for packed pasring with a completely unrestricted
SLASH feature: not only is the packing rate quite
low (0.25 packings per edge), but also the costs
for packing in terms of the number of subsumption
checks carried out is highest amongst all the experi-
ments reported on in this paper, peaking at 1355.85
subsumption tests per successful packing. The im-
pact on chart size is slightly worse than what we ob-
served with an unrestricted DSL feature. In sum, the
3E.g., modifiers must have saturated valence lists, whereas
fronted partial VP constituents may have open valencies relating
to complements in the Mittelfeld.
suboptimal packing together with the excessive sub-
sumption costs account for the fact that this setting
performs more than 8 times as badly as the baseline.
Although packed parsing with fully restricted
SLASH performs much better than having SLASH
entirely unrestricted, it still falls short of the base-
line by a factor of 1.36. This is due to several rea-
sons: first, although the packing rate is good (0.59),
the chart is the biggest observed with packed pars-
ing in all the experiments carried out, being more
than 2 times as big as the parse chart with optimal
restrictor settings. This is mainly due to the fact that
the grammar is far to unconstrained during forest
creation, allowing too many inconsistent analyses to
enter the chart. This is also corroborated by the fact
that this is the only test run where we experienced a
noticeable increase in unpacking time. Another ob-
servation, for which we cannot offer any explanation
at present, pertains to the increased cost associated
with retroactive packing: the amount of frezing that
has to be done for edges masked by retroactive pack-
ing is far higher than any other value found in these
experiments.
In a separate test run, we used simultaneous full
restriction for DSL and SLASH, in order to verify
whether our assumtion that the choice of one re-
strictor is independent from the others. By and large,
our hypothesis was confirmed: having both DSL and
SLASH fully restricted performed more than 2.5
times worse than full restrcition of SLASH whith
partial restriction of DSL.
Still in parallel to our findings regarding DSL,
partial restriction of SLASH performs best, con-
firming that the compromise between restrictiveness
and eleimination of derivation history is effective
to achieve a runtime behaviour that clearly outper-
forms the baseline. The packing rate achieved with
partial restriction of semantics, DSL and SLASH
(0.36) is actually very close to the packing rates re-
ported in (Oepen and Carroll, 2000) for the ERG,
which figures around 0.33 for input longer than 10
words. Also, the compactness of the chart with in-
put of increasing length (cf. figure 3.2), and the low
number (2) of performance outliers (cf. figure 3.2)
suggest that we are indeed close to optimal feature
restriction.
Decisions on which features to preserve within
SLASH under partial restriction were mainly de-
149
Edges Time (s) Unpack (s) Subsumption ? = < ? Factor (time) Subs. cost Pack rate
Unfill 6424 0.56 0 0 0 0 0 0 1 N/A 0
Partial SLASH 1494 0.28 0.01 36404.15 307.28 193.33 36.67 335.84 0.5 67.76 0.36
Full SLASH 2187 4.72 0.01 728385.4 314.66 149.21 73.35 826.1 8.43 1355.85 0.25
No SLASH 3435 0.76 0.16 97965.05 883.79 994.87 145.44 2583.51 1.36 48.4 0.59
Table 2: Performance of packed parsing with different restriction of SLASH
rived in a test-debug cycle. We therefore plan to
investigate different configurations of partially re-
stricted SLASH in future work.
Restricting ANC The last experiment we carried
out relates to the ANC (=ANCHOR) feature used
to percolate semantic attachment anchors for rela-
tive clause extraposition in the style of (Kiss, 2005;
Crysmann, 2005). Using ANC, index and handle of
each and every NP are collected and passed up the
tree, to be bound by an extraposed relative clause
attached to the same subclause.
Again, we tested three different settings: full re-
striction of all 3 anchor feature (SELF, ACTIVE, IN-
ERT), no restriction, and partial retsriction, where
the elements on the lists were restricted to *top*,
thereby recording only the number of percolated an-
chors, but not their nature in terms of index fea-
tures. ANC features encode derivation history in two
ways: first, structurally higher anchors (NPs) are
represented at the front of the list, whereas more
deeply embedded anchors are found further down
the list. Second, to control for spurious attachments,
only anchors inherited from a left daughter are ac-
cessible for binding (ACTIVE), the others remain on
the INERT list. Both the order of indices on the lists,
list length and the distribution of anchors over AC-
TIVE and INERT lists partially encode constituent-
internal structure.
Results of this experiment are summarised in ta-
ble 3.
Similar to our two previous experiments, en-
tirely unrestricted ANC behaves worst, but nowhere
nearly as bad as having SLASH or DSL unrestricted.
In fact, relative packing rates achieved by all three
restrictor settings are by and large the same in
this experiment. The main difference between un-
restricted ANC concerns the overall compactness of
the forest and the number of subsumption test per-
formed.
Partial restriction already performs better than un-
restricted ANC: since partially restricted ANC does
not record the nature of the anchors, at least one way
in which derivation history is recorded is effectively
masked.
Contrary to our previous experiments, however,
partial restriction does not outperform full restric-
tion. Although this finding comes somewhat at a
surprise, there is nevertheless a straightforward ex-
planation for the difference in behaviour: while full
restriction necessarily improves chart compactness,
the adverse effects of full restriction do not come
to bear as often as in the case of fully restricted
SLASH or DSL, since attachment of extraposed rel-
ative clauses presupposes the existence of an al-
ready constructed chart edge for the relative clause.
In contrast to extraction and head movement, which
can be found in practically every sentence-size test
item, distribution of relative clauses is comparatively
low. Furthermore, constituents serving as fillers for
SLASH or DSL dependencies can actually be quite
small in size and different in shape, which increases
the potential for overgeneration with fully restricted
movement features. Relative clauses, on the other
hand, are always clause-sized, and their properties
depend on the information percolated in ANC only
to a very little degree (namely number and gender
agreement of the relative pronoun).
4 Conclusion
In this paper, we have explored the effects in the
choice of restrictor for HPSG parsing of German
with local ambiguity packing. Based on initial ob-
servation that a semantics-only restrictor gives sub-
optimal runtime performance in packed parsing, we
found that three features representing discontinuities
were mainly responsible for inefficiency with lo-
cal ambiguity packing, namely SLASH for extrac-
tion, DSL for head movement, and ANC for relative
clause extraposition, all of which may encode part
of the derivation history.
We have shown that partial restriction of SLASH
and DSL features, together with full restriction
of ANC yields satisfactory parsing performance
150
Edges Time (s) Unpack (s) Subsumption ? = < ? Factor (time) Subs. cost Pack rate
Unfill 6424 0.56 0 0 0 0 0 0 1 N/A 0
Partial ANC 1586 0.37 0.01 55392.34 319.35 232.28 51.34 608.51 0.66 91.87 0.38
Full ANC 1704 0.58 0.01 104699.81 346.35 257.92 64.66 758.27 1.04 156.52 0.39
No ANC 1494 0.28 0.01 36404.15 307.28 193.33 36.67 335.84 0.5 67.76 0.36
Table 3: Performance of packed parsing with different restriction of ANC
with ambiguity packing, outperforming the a non-
packing baseline parser with feature structure unfill-
ing by a factor of 2. Even more importantly, combi-
natorial explosion at increasing input length is effec-
tively tamed, such that performance gains improve
with longer input sentences.
Acknowledgement
The research reported on in this paper has been car-
ried out as part of the DFKI project Checkpoint,
funded by the Federal State of Berlin and the EFRE
programme of the European Union. I am also grate-
fully indepted to Bernd Kiefer for his support of the
runtime parser and his expert advice. Many thanks
also to Ulrich Callmeier, Dan Flickinger, Stefan
Mu?ller, Geert-Jan van Noord, and Stephan Oepen,
for their comments and suggestions.
References
Ulrich Callmeier. 2000. PET ? a platform for experi-
mentation with efficient HPSG processing techniques.
Journal of Natural Language Engineering, 6(1):99?
108.
Ann Copestake and Dan Flickinger. 2000. An open-
source grammar development environment and broad-
coverage English grammar using HPSG. In Proceed-
ings of the Second conference on Language Resources
and Evaluation (LREC-2000), Athens.
Berthold Crysmann. 2003. On the efficient implemen-
tation of German verb placement in HPSG. In Pro-
ceedings of RANLP 2003, pages 112?116, Borovets,
Bulgaria.
Berthold Crysmann. 2005. Relative clause extraposition
in German: An efficient and portable implementation.
Research on Language and Computation, 3(1):61?82.
J. Earley. 1970. An efficient context-free parsing algo-
rithm. Communications of the ACM, 13(2):94?102.
E. Hinrichs and T. Nakazawa. 1990. Subcategorization
and VP structure in German. In Hughes, Shaun, and
Salmons, editors, Proceedings of the Third Symposium
on Germanic Linguistics, Amsterdam. Benjamins.
Tibor Kiss and Birgit Wesche. 1991. Verb order
and head movement. In Otthein Herzog and Claus-
Rolf Rollinger, editors, Text Understanding in LILOG,
number 546 in Lecture Notes in Artificial Intelligence,
pages 216?240. Springer-Verlag, Berlin.
Tibor Kiss. 2005. Semantic constraints on relative clause
extraposition. Natural Language and Linguistic The-
ory, 23:281?334.
John T. Maxwell and Ronald M. Kaplan. 1995. A
method for disjunctive constraint satisfaction. In Mary
Dalrymple, Ronald M. Kaplan, John T. Maxwell, III,
and Annie Zaenen, editors, Formal Issues in Lexical-
Functional Grammar, pages 381?401, Stanford Uni-
versity. CSLI.
R. C Moore and H. Alshawi. 1992. Syntactic and seman-
tic processing. In H. Alshawi, editor, The Core Lan-
guage Engine, pages 129?148. The MIT Press, Cam-
bridge, MA.
Stefan Mu?ller and Walter Kasper. 2000. HPSG analy-
sis of German. In Wolfgang Wahlster, editor, Verb-
mobil: Foundations of Speech-to-Speech Translation,
pages 238?253. Springer, Berlin.
Stefan Mu?ller. 1999. Deutsche Syntax ? deklarativ.
Linguistische Arbeiten. Niemeyer, Tu?bingen.
John Nerbonne. 1994. Partial verb phrases and spu-
rious ambiguities. In John Nerbonne, Klaus Netter,
and Carl Pollard, editors, German in Head-Driven
Phrase Structure Grammar, number 46 in Lecture
Notes, pages 109?150. CSLI Publications, Stanford
University.
Stephan Oepen and John Carroll. 2000. Ambiguity pack-
ing in constraint-based parsing - practical results. In
Proceedings of the 1st Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics, pages 162?169, Seattle, WA.
Stephan Oepen and Dan Flickinger. 1998. Towards sys-
tematic grammar profiling. test suite technology ten
years after. Journal of Computer Speech and Lan-
guage, 12:411?436.
Stuart Shieber. 1985. Using restriction to extend pars-
ing algorithms for complex feature-based formalisms.
In Proceedings of 23rd meeting of the Association of
Computational Linguistics, pages 145?152, Chicago,
IL.
151
Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 153?160
Manchester, August 2008
Hybrid processing for grammar and style checking
Berthold Crysmann?, Nuria Bertomeu?, Peter Adolphs?, Dan Flickinger?, Tina Klu?wer??
? Universita?t Bonn, Poppeldorfer Allee 47, D-53115 Bonn, {bcr,tkl}@ifk.uni-bonn.de
? Zentrum fu?r Allgemeine Sprachwissenschaft, Berlin, nuria.bertomeu@dfki.de
? DFKI GmbH, Berlin, {peter.adolphs,kluewer}@dfki.de
? CSLI, Stanford University, danf@csli.stanford.edu
Abstract
This paper presents an implemented hy-
brid approach to grammar and style
checking, combining an industrial pattern-
based grammar and style checker with bi-
directional, large-scale HPSG grammars
for German and English. Under this ap-
proach, deep processing is applied selec-
tively based on the error hypotheses of a
shallow system. We have conducted a com-
parative evaluation of the two components,
supporting an integration scenario where
the shallow system is best used for error de-
tection, whereas the HPSG grammars add
error correction for both grammar and con-
trolled language style errors.
1 Introduction
With the enormous amount of multilingual techni-
cal documentation produced by companies nowa-
days grammar and controlled language checking
(henceforth: style checking) is becoming an appli-
cation highly in demand. It is not only a helpful
tool for authors, but also facilitates the translation
of documents into foreign languages. Through the
use of controlled language by the authors, docu-
ments can be automatically translated more suc-
cessfully than with the use of free language. Style
checking should make authors aware of the con-
structions which should not be used, as well as
aiding in reformulating them. This can save a lot
of translation costs for companies producing large
amounts of mulitilingual documentation. Another
application of grammar and style checking is the
development of tutorial systems for learning a for-
eign language, as well as any kind of authoring sys-
tem for non-native speakers.
Previous approaches to grammar and style
checking can be divided into those based on fi-
nite state methods and those based on linguisti-
cally motivated grammars. To the former group be-
long e.g. the systems FLAG (Bredenkamp et al,
2000a; Bredenkamp et al, 2000b) and MultiLint
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
(Haller, 1996; Schmidt-Wigger, 1998). The basic
approach taken by such systems is the description
of error patterns through finite state automata. The
automata access the textual input enriched with
annotations from shallow linguistic analysis com-
ponents, such as part-of-speech tagging, morphol-
ogy and chunking. In FLAG, for instance, the an-
notation delivered by the shallow components is
integrated into a complex feature structure. Rules
are defined as finite state automata over feature
structures. The great advantages of such systems
are their robustness and efficient processing, which
make them highly suitable for real-life grammar
and style checking applications. However, since
shallow modules usually cannot provide a full syn-
tactic analysis, the coverage of these systems is
limited to error types not requiring a broader (non-
local) syntactic context for their detection. There-
fore their precision in the recognition of non-local
errors is not satisfactory.
Another short-coming of most shallow ap-
proaches to grammar checking is that they typi-
cally do not provide error correction: owing to the
absence of an integrated target grammar, genera-
tion of repairs cannot take the syntactic context
into account: as a result, some of the repairs sug-
gested by shallow systems are not globally well-
formed.
Grammar-based error checking constitutes the
other main strand in language checking technol-
ogy. These systems are typically equipped with a
model of target well-formedness. The main prob-
lem, when applied to the task of error checking
is that the sentences that are the focus of a gram-
mar checker are ideally outside the scope of the
grammar. To address this problem, grammar-based
checkers typically employ robustness techniques
(Ravin, 1988; Jensen et al, 1993; Douglas, 1995;
Menzel, 1998; Heinecke et al, 1998). The addi-
tion of robustness features, while inevitable for a
grammar-based approach, has the disadvantage of
considerably slowing down runtime performance.
Another issue with purely grammar-based check-
ing is related to the scarce distribution of actual
errors: thus, most effort is spent on the processing
of perfectly impeccable utterances. Finally, since
coverage of real-world grammars is never perfect,
these system also have difficulty to distinguish be-
153
tween extragrammatical and truly ungrammatical
sentences. Conversely, since grammars often over-
generate, a successful parse does not guarantee
wellformedness either.
One of the two major robustness techniques
used in the context of grammar-based language
checking are constraint relaxation (see e.g. (Dou-
glas, 1995; Menzel, 1998; Heinecke et al, 1998)),
which is typically realised by means of modifica-
tions to the parser (e.g. relaxation levels, robust uni-
fication). An alternative approach is error anticipa-
tion where errors are explicitly modelled by means
of grammar rules, so-called MAL-rules (McCoy et
al., 1996). This approach has already been inves-
tigated with an HPSG grammar, the ERG (Copes-
take and Flickinger, 2000), in the scenario of a tu-
torial system for language learning by (Bender et
al., 2004). We will follow this approach in the part
of our hybrid system based on deep processing.
Finite state methods and linguistically motivated
grammars are not only compatible, but also com-
plementary. Shallow methods are robust and effi-
cient, while deep processing based on grammars
provides high precision and detail. With the fo-
cussed application of deep analysis in finite state
based grammar and style checking systems, both
coverage and precision can be improved, while
the performance remains acceptable for real-world
applications. The combination of shallow and
deep components, hybrid processing, has already
been investigated in several modular architectures,
such as GATE (Gaizauskas et al, 1996), White-
board (Crysmann et al, 2002) and Heart-of-Gold
(Callmeier et al, 2004). Moreover, the improve-
ment in efficiency and robustness in deep process-
ing together with methods for its efficient applica-
tion makes the employment of deep processing in
real-world applications quite feasible. Hybrid pro-
cessing has been used for applications such as in-
formation extraction and question answering. But
to the best of our knowledge, the application of hy-
brid processing to grammar and style checking has
not been previously investigated.
In this paper, we present an implemented proto-
type of a hybrid grammar and style checking sys-
tem for German and English, called Checkpoint.
As the baseline shallow system we have taken
an industrial strength grammar and controlled lan-
guage style checker, which is based on the FLAG
technology. The deep processing platform used in
the project is the PET parser (Callmeier, 2000)
operating on wide-coverage English and German
HPSG grammars, the English Resource Grammar
(ERG) (Copestake and Flickinger, 2000) and the
German Grammar (GG) (Mu?ller and Kasper, 2000;
Crysmann, 2005; Crysmann, 2007), respectively.
The ERG and the GG have been developed for over
15 years and have already been used as deep pro-
cessing engines in the Heart-of-Gold hybrid pro-
cessing platform. We have developed an approach
for the selective application of deep processing
based on the error hypotheses of the shallow sys-
tem. Error detection in the deep system follows a
MAL-rule approach. In order to compare the ben-
efits of the selective application of deep process-
ing with its nonselective application, we have de-
veloped two scenarios: one parallel and one inte-
grated. While the parallel (nonselective) scenario
enables improvement in both recall and precision,
the integrated (selective) scenario only enables im-
provement in precision. However, the performance
of the integrated approach is much better. We have
also investigated several possibilities of integrating
deep processing in the selective scenario. Since the
HPSG grammars are suitable both for parsing and
generation, the system can successfully provide
both error corrections and paraphrases of stylistic
errors. For the purpose of investigation, evaluation
and statistical parse ranking, we have collected and
annotated several corpora of texts from technical
manuals. Finally, the approach has been evaluated
regarding error detection and performance.
2 The approach
Checkpoint has two main goals: (a) improving the
precision and recall of existing pattern-based gram-
mar and style checking systems for error types
whose detection requires considering more than
the strictly local syntactic context; and (b) gener-
ating error corrections for both grammar and style
errors. Accordingly, we have chosen to focus on
certain error types based on the difficulties of the
pattern-based system.
2.1 Anticipation of grammar errors
Grammar errors are detected by means of error
anticipation rules, or MAL-rules. MAL-rules ex-
actly model errors, so that erroneous sentences can
be parsed by the grammar. For this purpose we
enlarged two HPSG grammars for German, the
GG, and English, the ERG, with MAL-rules for
error types that were problematic for the pattern-
based shallow system. For German the following
phenomena have been handled: subject verb agree-
ment (subject verb agreement), NP internal agree-
ment (NP internal agreement), confusion of the
complementiser ?dass? with the homophonous pro-
noun or determiner ?das? (dass das), as well as
editing errors, such as local and non local repeti-
tion of words (repetitions). Here follow some ex-
amples (taken from the FLAG error corpus (Becker
et al, 2000), and die tageszeitung ?taz?, a German
newspaper):
(1) Auch in AOL gibt es Newsgroups, die
dieses Thema diskutiert [=diskutieren]. (FLAG)
Also in AOL are there newgroups, which (Pl)
this topic discuss (Sg).
?There are also newsgroups in AOL which dis-
cuss this topic.?
154
(2) Ich habe dem ganze [=ganzen] Geschehen
von meinem Sofa aus zugesehen. (FLAG)
I have the whole (wrong adj. form) events
from my couch out watched.
?I have watched the whole events from my
couch.?
(3) Vor allem im Su?den . . . fu?hrten [=haben] die
Liberalen der MR einen heftigen Wahlkampf
gegen die PS gefu?hrt. (taz, June 2007)
Above all in the south . . . led (past tense) the
liberals of the MR a hard election campaign
against the PS led (past participle).
?Particularly in the south, the liberals of the
MR led a hard election campaign against the
PS.?
For English, MAL-rules for errors concerning
subject verb agreement and missing determiners
were implemented.
2.2 Detection of stylistic errors
Stylistic errors are grammatical constructions that
are dispreferred in a particular register or type
of document. Sometimes certain constructions are
not desirable because machine translation systems
have problems dealing with them or because they
prevent easy understanding. In such cases a con-
trolled language approach is taken, where the prob-
lematic constructions are paraphrased into equiv-
alent less problematic constructions. Since these
constructions are grammatical they can be parsed
and, thus, detected. A generation of a paraphrase
is possible based on the semantic representation
obtained through parsing. For German the follow-
ing phenomena were handled: passive, future and
implicit conditional sentences, as in the following
example:
(4) Wartet man zulange, kriegt man keine Karten.
Waits one too long, gets one no tickets.
?If one waits too long one gets no tickets.?
Correct: Wenn man zulange wartet, kriegt
man keine Karten.
For English we focussed on the following phenom-
ena: passive (avoid passive), future (avoid future),
modal verbs (avoid modal verbs), subjunctive
(avoid subjunctive), stand-alone deictic pro-
nouns (use this that these those with noun) and
clause order in conditional sentences (condi-
tion must precede action).
2.3 Integrated vs. parallel scenarios
We have developed two integration scenarios: an
integrated one and a parallel one. In the parallel
scenario the pattern-based shallow system and the
deep processing parser run independently of each
other, that is, all sentences are parsed independent
of whether the shallow system has found an error
in them. In the integrated scenario the deep parser
is only called for those sentences where the shal-
low system has detected some error of the type
of those which Checkpoint is able to process (enu-
merated in subsection 2.1). The parallel scenario
allows improvement in the recall of the shallow
system, since Checkpoint can find errors that the
shallow system has not found. In the integrated
scenario, on the contrary, only the precision of the
shallow system can be improved, since Checkpoint
departs from the hypotheses of the shallow system.
The integrated scenario, however, promises to per-
form better in time than the parallel scenario, since
only a fraction of the whole text has to be scanned
for errors. Moreover, the performance of the inte-
grated system can also be improved with the se-
lective activation of the MAL-rules that model the
specific errors found by the shallow system. This
greatly reduces the enormous search space of the
parsing algorithms and the processing time result-
ing from the simultaneous processing of several
MAL-rules.
The integration of the shallow system and the
deep parser has been achieved through an exten-
sion of the PET parser that allows it to receive any
kind of input information and integrate this into
the chart. This preprocessing information can be,
for example, part-of-speech tagging, morphology
and lemmatisation, and already guides the parsing
process. It allows, for instance, recognition of un-
known words or identification of the correct lexi-
cal entry in cases where there is ambiguity. An in-
put format in terms of feature structures, the ?Fea-
ture Structure Chart? (FSC) format, has been devel-
oped for this purpose (Adolphs et al, 2008). The
shallow system, thus, produces a feature structure
chart, based on the information delivered by the
various shallow modules, and this information is
given as input to the PET deep parser, which reads
it and integrates it into the chart.
Error hypotheses from the shallow system are
passed to the deep parser by means of specific fea-
tures in the input feature structure (MAL-features)
of every input token in the FSC, permitting selec-
tive activation of MAL-rules. To this end, the origi-
nal FSC generated by the shallow system, which
contains information on the part-of-speech, the
lemma and morphological features such as num-
ber, gender and case, will be extended with MAL-
features. These MAL-features correspond to the
class of some MAL-rule in the grammar and have
boolean values. Signs in the grammar are speci-
fied for these MAL-features. MAL-rules are de-
fined such that they can only take as their daughters
edges with a positive value for the corresponding
MAL-feature. All information in the FSC input to-
kens is passed to the tokens in the chart through
a feature called TOKEN in lexical items. Thus, er-
ror hypotheses are passed from the input tokens to
the lexical items in the chart by stating that the val-
ues of the MAL-features in the lexical items are
155
equal to the values of the MAL-features in the cor-
responding input tokens in the FSC.
The values of the MAL-features are obtained
by checking the error report delivered by the shal-
low system. For certain errors detected by the shal-
low system there is a mapping to MAL-features.
The value of a MAL-feature will be set to ?+? if
the shallow system has found the corresponding
error. The rest of the MAL-features can be set to
?bool? if we want to allow other MAL-rules to
fire (which can improve recall, but increases am-
biguity and, consequently, has a negative effect on
performance). The values of the rest of the MAL-
features can also be set to ?-?, if we want to prevent
other MAL-rules from firing (which allows im-
provement only in precision, but limits ambiguity
and, consequently, results in better performance).
There is also the possibility of activating the rel-
evant MAL-features only for those tokens which
are, according to the shallow system, within the er-
ror span, instead of activating the MAL-features
for all tokens in the erroneous sentence.
2.4 Generation of corrections and
paraphrases
One of the advantages of using deep processing
in grammar and style checking is the possibility
of generating corrections and paraphrases which
obey the constraints imposed by the syntactic con-
text. Since the HPSG grammars that we are using
are suitable both for parsing and generation, this
is straightforward. Robust parsing delivers as out-
put a semantic representation in the Minimal Re-
cursion Semantics formalism (MRS) (Copestake
et al, 2006) of the sentence which can be used for
generation with the LKB (Carroll et al, 1999).
The MAL-rules directly assign well-formed se-
mantic representations from which a correct sur-
face string can be generated. In the case of stylis-
tic errors, transfer rules are used to generate the
desired paraphrase, using MRS-to-MRS mapping
rules modelled on the semantic transfer-based ma-
chine translation approach of (L?nning et al,
2004).
We identified two areas where generation of re-
pairs will actually provide a considerable added
value to a grammar checking system: first, for non-
native speakers, simple highlighting of the error
location is often insufficient, since the user may
not be familiar with the rules of the language. Sec-
ond, some areas, in particular stylistic ones may
involve considerable rearrangement of the entire
sentence. In these cases, generation of repairs and
paraphrases can reduce editing cost and also min-
imise the issue of editing errors associated with
non-local phenomena.
The generator and HPSG grammars we use are
able to provide a range of realisations for a given
semantic input. As a result, realisation ranking is
of utmost importance. In order to select repairs
which are both smooth and maximally faithful to
the input, modulo the error site, of course, we com-
bined two methods: a discriminative PCFG-model
trained on a generation treebank, enhanced by an
n-gram language model, cf. (Velldal and Oepen,
2005), and an alignment approach that chooses the
most conservative edit from a set of input realisa-
tions. As our similarity measure, we employed a
variant of BLEU score (NEVA), suggested in (Fors-
bom, 2003). The probabilistic ranking models we
trained achieve an exact match accuracy of 73%
for both English (Velldal and Oepen, 2005) and
German (as evaluated on the subset of TiGer the
error corpus was based on).
3 Error corpora
In order to learn more about the frequencies of the
different error types, to induce statistical models
that allow us to obtain the best parse in the do-
main of technical manuals and to evaluate our im-
plemented approach to grammar and style check-
ing, we collected and manually annotated corpora
from the domain of technical documentation.
Since errors in pre-edited text tend to be very
scarcely distributed, manual annotation is quite
costly. As a result, instance of certain well-known
error types cannot be tested in a greater variety of
linguistic environments. To overcome this problem,
we semi-automatically derived an additional error
corpus from a treebank of German.
English For purposes of evaluation in a real
world scenario, we constructed a corpus for En-
glish, consisting of 12241 sentences (169459
words) from technical manuals. The corpus was
semi-automatically annotated with several types of
grammar and style errors. For this purpose annota-
tion guidelines were developed, which contained
the description of the errors together with exam-
ples of each and their possible corrections. The an-
notation took place in two phases. First, we wanted
to find out about the precision of the shallow sys-
tem, so we ran the shallow system over the data.
This resulted in an annotation for each error found
consisting of the erroneous sentence, the error span
and the type of error. The annotators, who were na-
tive speakers, then decided whether the errors had
been correctly detected. In the second phase, we
aimed to create a gold standard, so as to be able to
evaluate both the shallow system and Checkpoint
regarding recall and precision. For this purpose, we
extracted the errors that had been annotated as cor-
rectly detected in the previous phase and the an-
notators only had to find the non-detected errors
in the rest of the corpus. For the latter, they also
marked the span and identified the error type.
Subsets of these two datasets were treebanked
with the corresponding HPSG grammars. We em-
ployed the treebanking methodology developed for
Redwoods (Oepen et al, 2002), which involved
156
first parsing a corpus and recording for each item
the alternative analyses (the parse forest) assigned
by the grammar, then manually identifying the cor-
rect analysis (if available) within that parse forest.
This approach provides both a gold standard syn-
tactic/semantic analysis for each parsed item, and
positive and negative training data for building an
accurate statistical model for automatic parse selec-
tion.
German For German, we pursued a complemen-
tary approach towards corpus construction. Here
the focus lay on creating a test and evaluation cor-
pus that provided instances of common error types
in a variety of linguistic contexts. Since manual
error annotation is highly costly, owing to scarce
error distributions in pre-edited text, we chose to
automatically derive an error corpus from an ex-
isting treebank resource. As for the error types, we
focussed on those errors which are arguably perfor-
mance errors, as e.g. missing final consonants in in-
flectional endings, the confusion of homophonous
complementiser and relative pronoun, or else, edit-
ing errors, such as local and non-local duplicates.
We introduced instances of errors in a sub-
corpus of the German TiGer treebank (Brants
et al, 2002), nicknamed TiG-ERR, consisting of
77275 words (5652 sentences) from newspaper
texts. All the sentences in this subcorpus were
parsable, so that an evaluation of Checkpoint in
the ideal situation of 100% coverage could be car-
ried out. The artificially introduced errors were
of the following types: subject verb agreement,
NP internal agreement, dass/das, and repetitions,
all of them already illustrated with examples in sec-
tion 2.1.
Additionally, we annotated a corpus of technical
documents for these error types to estimate the dis-
tribution of these error types in pre-edited text.
4 Error models
In order to construct a statistical parse-ranking
model which could determine the intended use of
a MAL-rule in the analysis of a sentence where the
grammar produced analyses both with and without
MAL-rules, the English treebank was constructed
using the version of the ERG which included the
MAL-rules. 4000 sentences from the English cor-
pus were presented to the parser, of which 86.8%
could be parsed with the ERG, and of these, the an-
notators found an intended analysis for 2500 sen-
tences, including some which correctly used MAL-
rules. From these annotations, a customised parse
selection model was computed and then used in
parsing all of the corpus, this time recording only
the one analysis determined to be most likely ac-
cording to this model. We also compared accu-
racy of error detection based on this new model
with the accuracy of a pre-existing parse-selection
model trained on tourism data for LOGON, and
confirmed that the new model indeed improved
over the old one.
For German, we have not created a specific sta-
tistical model yet, but, instead, we have used an ex-
isting parse selection model (Crysmann, 2008) and
combined it with some heuristics which enable us
to select the best error hypothesis. The heuristics
check for each parsed sentence whether there is an
analysis containing no MAL-rule. If there is one
and this is not ranked as the best parse, it is moved
to the first position in the parse list. As a result, we
can eliminate a high percentage of false alarms.
5 Evaluation results
We have evaluated the English and the German ver-
sions of Checkpoint against the corpora described
in section 3.
German For German we have taken as a test
corpus standard the TiG-ERR subcorpus contain-
ing the automatically introduced errors, and have
parsed all its sentences. The following table shows
the frequencies of the different types of handled er-
rors in the corpus of technical manuals, the FLAG
error corpus (Becker et al, 2000), and in the TiG-
ERR corpus. The electronic version of the FLAG
corpus consists of 14,492 sentences, containing
1,547 grammar or style errors.
ERROR TYPE MANUALS FLAG TiG-ERR
NP internal agr 119 180 2258
subject verb agr 17 63 748
dass/das 1 152 75
repetitions 19 n/a 2571
Table 1: Frequencies of the error types for German
The following charts show the values for recall
and precision for the shallow system and Check-
point. As you can see, Checkpoint improves the
recall for the error types subject verb agreement
and NP internal agreement, whereas the precision
remains more or less the same. For the error type
dass/das Checkpoint improves both recall and pre-
cision. For the error type repetitions, which is only
partially handled by the spell checker in the shal-
low system, Checkpoint reaches considerable re-
call and precision values.
Deep processing on average improves the recall
of the shallow system by 21% and the precision
remains equal at 0.83. According to the error fre-
quencies in the corpus of technical manuals, deep
processing would improve the recall of the shallow
system by only 1.7%, since the error types sub-
ject verb agreement, NP internal agreement and
dass/das only make up 6.57% of the total amount
of annotated errors. However, as we found out later,
the corpora of technical manuals consist of texts
that have already undergone correction, so the er-
rors are very sparse.
157
Figure 1: Checkpoint values for recall and preci-
sion for German
Figure 2: Values for recall and precision for the
shallow system for German
Through the MAL-rules the coverage of the GG
on the TiG-ERR corpus increased to 85% - 95%,
whereas without the MAL-rules the coverage was
10%. This 10% coverage included overgeneration
by the grammar, as well as sentences that, after the
automatic insertion of errors, still remained gram-
matical, although they didn?t express the intended
meaning any more.
The performance of the parallel and integrated
scenarios was compared. The ambiguity of the
MAL-rules, that is, the possibility of applying sev-
eral MAL-rules to a unique error, considerably de-
teriorates the performance when processing sen-
tences containing several errors. In a subcorpus
containing NP internal agreement errors, the aver-
age processing time per sentence increases from
8.3 seconds with the selective activation of MAL-
rules to 31.4 seconds with the activation of all
MAL-rules. Particularly the MAL-rules modeling
the error subject verb agreement are a source of
ambiguity. If these MAL-rules are only selectively
activated the average processing time per sentence
decreases to 14.9 seconds.
Finally, we have evaluated the performance of
the German grammar in the task of error correction,
using non-local duplicates and adjectival agree-
ment errors as a test bed. For these error types,
the German HPSG grammar generated repairs for
85.4% of the detected non-local duplicates and
90% of the detected agreement errors.
English For English we have only implemented
and evaluated the parallel scenario. The focus for
English evaluation was the recognition of those
stylistic errors whose correction requires a re-
structuring of the sentence, and the generation of
the corresponding paraphrases. The recognition of
such error types is not based on MAL-rules, but
on certain already existing rules in the grammar.
The approach was evaluated taking the manually
annotated English corpus of technical manuals as
a gold standard. The following table shows the fre-
quencies of the error types handled by Checkpoint.
ERROR TYPE OCCURRENCES
avoid future 404
avoid modal verbs 657
avoid passive 213
Table 2: Frequencies of the error types for English
The PET parser with the ERG reached 86.1%
coverage on the full corpus. The following charts
show the values for recall and precision for Check-
point and the shallow system.
Figure 3: Checkpoint values for recall and preci-
sion for English
Figure 4: Values for recall and precision for the
shallow system for English
As one can see, for the stylistic errors
avoid future and avoid modal verbs, Checkpoint
reaches values which, although relatively high, are
lower than the shallow system. In most cases a
paraphrase for these errors can be constructed,
so the improvement Checkpoint provides here is
the generation of corrections. For the error type
avoid passive the precision is not so high, which
is due in part to mistakes in the manual annotation.
The passive sentences found by Checkpoint are
actually passive sentences. However, these were
158
not annotated as passives, because the annotators
were told to annotate only those stylistic errors
for which a paraphrase was possible. The same
happens for stylistic errors like avoid subjunctive,
use this that these those with noun and condi-
tion must precede action. In principle, Check-
point is very good at finding these types of errors,
but we cannot yet present a reliable evaluation here,
since only those errors were annotated for which
a paraphrase was possible. This approach is rea-
sonable, since no error alarm should be produced
when there is no other possibility of expressing the
same. However, since we have not yet developed
a method which allows us to automatically distin-
guish those cases for which a paraphrase is possi-
ble from those for which none is, we would need
to annotate all occurrences of a phenomenon in the
corpus, and introduce a further annotation tag for
the paraphrase potential of the sentence.
Nevertheless, even if the grammar-based re-
search prototype cannot beat the industrial pattern-
based system in terms of f-measures, we still be-
lieve that the results are highly valuable in the con-
text of our integrated hybrid scenario: Since the
full reversibility of the ERG has already been estab-
lished independently by (Velldal and Oepen, 2005),
the combined system is able to generate error cor-
rection for a great proportion of the errors detected
by the shallow component. This includes 80% and
above for avoid future and avoid modal verbs.
6 Summary and conclusions
In this paper we have presented an implemented
approach to grammar and style checking based on
hybrid processing. The hybrid system has two com-
ponents: a shallow grammar and style checking
system based on the FLAG technology, and the
PET deep parser operating on linguistically moti-
vated grammars for German and English. The Ger-
man version of the hybrid system improves the re-
call and in certain cases the precision of the shal-
low system and generates error corrections. For
English, the hybrid system in most cases success-
fully generates paraphrases of sentences contain-
ing stylistic errors. Although we only have ex-
plored some of the possibilities of integrating deep
and shallow processing for the grammar and style
checking application, these results speak for the
feasibility of using hybrid processing in this task.
We have developed an integrated strategy which
forwards the output of the shallow system, includ-
ing both the output from several pre-processing
linguistic modules and the error hypotheses, as in-
put to the deep parser. This procedure not only im-
proves the robustness of the deep parser with the
recognition of unknown words and reduces ambi-
guity by instantiating only those lexical items con-
sistent with the hypotheses of the POS tagger or
the morphology; but it also allows the selective
application of grammar rules, which considerably
reduces the search space for parsing and, conse-
quently, improves performance. Based on the error
hypotheses of the shallow system, the selective ap-
plication of grammar rules is achieved by positing
features in the Feature Structure Chart whose par-
ticular values are a pre-condition for MAL-rules
to apply. The improvement in performance sug-
gests that this strategy can be extensible to parsing
in general based on pre-processing components.
Given the output of a chunker, for example, certain
syntactic configurations can already be excluded.
Having features whose values allow one to switch
off certain rules not compatible with these con-
figurations would considerably reduce the search
space.
On the other hand, we have run the two mod-
ules independently from each other to find out
how the recall of the shallow system can be im-
proved by deep processing. The fact that for sev-
eral error types, such as subject verb agreement
and NP internal agreement, recall can be consider-
ably improved suggests that, in order not to parse
all sentences, the shallow system should send an
error hypothesis to the deep system when finding
particular syntactic configurations which may indi-
cate the occurrence of such errors. In this way, such
error hypotheses, although not reliably detectable
by the shallow system alone, could be confirmed
or discarded with a focussed application of deep
processing, which would not be as resource con-
suming as parsing every sentence.
One of the results of the experiment has been
an on-line demonstration system. The running sys-
tem shows that the different modules can be eas-
ily combined with each other. Our hybrid approach,
however, is generic and portable. Although imple-
mented for our specific baseline system, it can in
principle be used with other shallow systems.
Acknowledgements
The research reported in this paper has been car-
ried out as part of the DFKI project Checkpoint,
running from February until November 2007. The
project was funded by the ProFIT program of the
Federal State of Berlin and the EFRE program of
the European Union.
References
Adolphs P., S. Oepen, U. Callmeier, B. Crysmann, and
B. Kiefer. 2008. Some Fine Points of Hybrid Natural
Language Parsing. Proceedings LREC-2008, Mar-
rakech, Morocco.
Becker M., A. Bredenkamp, B. Crysmann, and J. Klein.
2003. Annotation of error types for a German news-
group corpus. In A. Abeille?, editor, Treebanks.
Building and Using Parsed Corpora, number 20 in
Text, Speech And Language Technology. Kluwer,
Dordrecht.
159
Bender, E. M., D. Flickinger, S. Oepen, A. Walsh,
and T. Baldwin. 2004. Arboretum: Using a preci-
sion grammar for grammar checking in call. In In-
STIL/ICALL symposium 2004. NLP and speech tech-
nologies in advanced language learning systems.
Venice, Italy.
Brants, T., S. Dipper, S. Hansen, W. Lezius, and G.
Smith. 2002. The TIGER Treebank. In Proceedings
of the Workshop on Treebanks and Linguistic Theo-
ries. Sozopol.
Bredenkamp, A., B. Crysmann and M. Petrea. 2000.
Looking for errors: A declarative formalism for
resource-adaptive language checking. In Proceed-
ings LREC-2000. Athens, Greece.
Bredenkamp, A., B. Crysmann and M. Petrea. 2000.
Building multilingual controlled language perfor-
mance checkers. In Proceedings of the CLAW 2000.
Seattle, WA.
Callmeier, U., A. Eisele, U. Scha?fer, and M. Siegel.
2004. The Deepthought core architecture frame-
work. In Proceedings of LREC-2004, 1205?1208,
Lisbon, Portugal.
Callmeier, Ulrich. 2000. PET ? a platform for ex-
perimentation with efficient HPSG processing tech-
niques. Natural Language Engineering 6(1):99?
108.
Carroll, John and Ann Copestake and Dan Flickinger
and Victor Poznanski. 1999. An efficient chart gen-
erator for semi-lexicalist grammars. Proceedings of
ENLG, pp. 86?95.
Copestake, A., and D. Flickinger. 2000. An open-
source grammar development environment and
broad-coverage english grammar using HPSG. In
Proceedings LREC-2000. Athens, Greece.
Copestake, A., D. Flickinger, C. Pollard, and I. Sag.
2006. Minimal recursion semantics: an introduction.
Research on Language and Computation 3(4):281?
332.
Crysmann, B., A. Frank, B. Kiefer, S. Mu?ller, G. Neu-
mann, J. Piskorski, U. Scha?fer, M. Siegel, H. Uszko-
reit, F. Xu, M. Becker, and H.-U. Krieger. An inte-
grated architecture for shallow and deep processing.
In Proceedings of ACL 2002, University of Pennsyl-
vania, Philadelphia, 2002.
Crysmann B. 2005. Relative clause extraposition in
German: An efficient and portable implementation.
Research on Language and Computation, 3(1):61?
82.
Crysmann B. 2007 Local ambiguity packing and dis-
continuity in German. In T. Baldwin, M. Dras,
J. Hockenmaier, T. H. King, and G. van Noord, ed-
itors, Proceedings of the ACL 2007 Workshop on
Deep Linguistic Processing, pages 144?151, Prague,
Czech Republic.
Crysmann B. 2008. Parse Selection with a German
HPSG Grammar. In S. Ku?bler and G. Penn, editors,
Proceedings of the ACL 2008 Workshop on Parsing
German (PaGe), pages 9?15, Columbus, Ohio, USA.
Douglas, S. 1995. Robust PATR for error detec-
tion and correction. In A. Schoeter and C. Vogel
(Eds.)Nonclassical feature systems, Vol. 10, pp. 139-
156. Centre for Cognitive Science, University of Ed-
inburgh.
Forsbom, E. 2003. Training a Super Model Look-
Alike. Proceedings of the MT Summit IX Workshop
?Towards Systemizing MT Evaluation?, pp. 29-36.
Gaizauskas, R., H. Cunningham, Y. Wilks, P. Rodgers
and K. Humphreys. 1996. GATE: An environment
to support research and development in natural lan-
guage engineering. In Proceedings of the 8th IEEE
international conference on tools with artificial in-
telligence. Toulouse, France.
Jensen, K., G. E., Heidorn and S. D. Richardson (Eds.).
1993. Natural language processing: The PLNLP ap-
proach. Boston - Dordrecht - London.
Haller, J. 1996. MULTILINT: A technical documenta-
tion system with multilingual intelligence. In Trans-
lating and the computer 18. London.
Heinecke, J., J. Kunze, W. Menzel, and I. Schroeder.
1998. Eliminative parsing with graded constraints.
In Proceedings ACL/Coling 1998, Vol. I, pp. 526-
530. Universite de Montreal, Montreal, Quebec,
Canada.
L?nning J. T. , S. Oepen, D. Beermann, L. Hellan, J.
Carroll, H. Dyvik, D. Flickinger, J. B. Johannessen,
P. Meurer, T. Nordga?rd, V. Rose?n and E. Velldal.
2004. LOGON. A Norwegian MT effort. In Pro-
ceedings of the Workshop in Recent Advances in
Scandinavian Machine Translation. Uppsala, Swe-
den.
McCoy, K. F., C. A. Pennington, and L. Z. Suri. 1996.
English error correction: A syntactic user model
based on principled ?mal-rule? scoring. In Proceed-
ings of UM-96, the Fifth International Conference on
User Modeling, pp. 59-66. Kona, Hawaii.
Menzel, W. 1998. Constraint satisfaction for robust
parsing of natural language. In Theoretical and Ex-
perimental Artificial Intelligence, 10 (1), 77-89.
Mu?ller, S., and W. Kasper. 2000. HPSG analysis of
German. In W. Walster (Ed.), Verbmobil: Foun-
dations of Speech-to-Speech Translation, 238?253
Springer, Berlin.
Oepen, S., K. Toutanova, S. Shieber, C. Manning, D.
Flickinger and T Brants. 2002. The LinGO Red-
woods Treebank. Motivation and Preliminary Appli-
cations. In Proceedings of COLING 2002. Taipei,
Taiwan.
Ravin, Y. 1998. Grammar errors and style weaknesses
in a text-critiquing system. In IEEE Transactions on
Communication, 31 (3)
Schmidt-Wigger, A. 1998. Grammar and style check-
ing for German. In Proceedings of CLAW 98. Pitts-
burgh, PA.
Velldal, E. and S. Oepen. 2005. Maximum entropy
models for realization ranking. In Proceedings of
the 10th MT-Summit (X), Phuket, Thailand.
160
Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks, ACL-IJCNLP 2009, pages 28?36,
Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLP
Autosegmental representations in an HPSG of Hausa
Berthold Crysmann
Universit?t Bonn
Poppelsdorfer Allee 47, D?53115 Bonn
crysmann@ifk.uni-bonn.de
Abstract
In this paper I shall present a treatment of
lexical and grammatical tone and vowel
length in Hausa, as implemented in an
emerging bidirectional HPSG of the lan-
guage based on the Lingo Grammar Ma-
trix (Bender et al, 2002). I shall argue
in particular that a systematic treatment
of suprasegmental phonology is indispen-
sible in an implemented grammar of the
language, both for theoretical and practical
reasons. I shall propose an LKB represen-
tation that is strongly inspired by linguistic
and computational work on Autosegmental
Phonology. Finally, I shall show that the
specific implementation presented here is
flexible enough to accommodate different
levels of suprasegmental information in the
input.
1 Introduction
Hausa is a tone language spoken by over 30 million
speakers in Northern Nigeria and bordering areas
of Niger. Genetically, the language belongs to the
Chadic sub-branch of the Afroasiatic family.
In this language, both tone and length are lexi-
cally and grammatically distinctive: Hausa distin-
guishes two vowel lengths, as well as two underly-
ing tones, H(igh) and L(ow). At the surface level,
we can observe two level tones, as well as one con-
tour tone (fall). Wolff (1993) cites the following
minimal pairs for tone:
(1) a. f?r?? ? ?look (n)?
b. far`?? ? ?dry season?
c. far?? ? ?white/whiteness?
Rising tone only results from the interaction of
grammatical and intonational tone (Sharon Inkelas
and Cobler, 1987; Inkelas and Leben, 1990).
In addition to its function of differentiating lex-
ical items, tone is also grammatically distinctive:
the paradigms of subjunctive and preterite (=rel-
ative completive) TAM markers partially over-
lap in terms of their segments (k? ?2sg.subj, y?
?3sg.m.subj?, t? ?3sg.f.subj? vs. ka ?2sg.rel.compl,
ya ?3sg.m.rel.compl?, ta ?3sg.f.rel.compl?). Fur-
ther, the bound possessive linker and the previous
reference (=specificity) marker are systematically
distinguished by tonal means alone.
(2) a. r`??ga-r
gown.f-of.f
Aud?
Aud?.m
?Audu?s gown?
b. r`??g?-r
gown.f-spec.f
?the (aforementioned) gown
(3) a. birni-n
town.m-of.m
Kan`?o
Kano
?Kano town?
b. birn?-n
town.m-spec.m
?the (aforementioned) town?
Similarly, vowel length is also distinctive on both
lexical and grammatical levels: Newman (2000)
cites the following pair (inter alia): fa?s `?a ?postpone?
vs. fas `?a ?smash?. Examples of grammatical length
distinctions can again be found in the areas of TAM
marking: in relative clauses and focus construc-
tions, completive aspect is expressed by means of
the relative completive set (or preterite), using short
vowel na ?1.sg.rel.compl, ka ?2.sg.rel.compl?, ya
?3.sg.m.rel.compl? and ta ?3.sg.f.rel.compl?, inter
alia, which contrasts with the long vowel abso-
lute completive na?, ka?, ya?, and ta? used elsewhere
(see Jaggar (2006) for discussion of the use of the
preterite in narratives). Furthermore, Hausa uses
verb-final vowel length to signal presence of a fol-
lowing in-situ direct object (Hayes, 1990; Crys-
mann, 2005).
Despite the fact that the sophisticated models of
suprasegmental phonology developed more than
a quarter of a century ago within Autosegmental
28
Theory (Goldsmith, 1976; Leben, 1973) have al-
ready been rigorously formalised in the nineties
in the context of feature-structure-based computa-
tional phonology (Bird, 1995; Scobbie, 1991; Bird
and Klein, 1994; Walther, 1999), the representa-
tion of tone and length has received little or no
attention in the area of grammar engineering. This
may be partly due to the fact that the languages for
which substantial grammars have been developed
are not tone languages. Existing grammar imple-
mentations of tone languages like Chinese (Fang
and King, 2007) do not appear to make use of au-
tosegmental models either, possibly because the
assignment of tone in an isolating language is not
as intimately connected to inflectional and deriva-
tional processes, as it is in a morphologically rich
language like Hausa.
In this paper, I shall argue that the issue of
suprasegmental phonology is an integral part of any
implemented grammar of Hausa, not only from the
point of view of linguistic adequacy, but also un-
der grammar-engineering and application-oriented
perspectives. I shall propose a treatment of tone
and length in an LKB-grammar of Hausa that sys-
tematically builds on separate representations of
segments, tone and length and discuss how various
salient aspects of Hausa syntax and morphology
can be addressed using a representation inspired
by Autosegmental Theory. Furthermore, I shall ad-
dress how different levels of suprasegmental infor-
mation encoded in the different writing systems em-
ployed in the language can be robustly integrated
into a single grammar, and explore its application
potential.
2 Suprasegmental information in Hausa
writing systems
2.1 Latin script
2.1.1 Standard orthography (Boko)
Modern Hausa is standardly written using (a mod-
ified version of) the Latin script, called bo?k?o. In
addition to the standard 26 letters of the Latin alpha-
bet, Boko uses hooked letters, the apostrophe, as
well as digraphs to represent glottalised consonants
(?, ?, ?, ts [s?], ?y [Pj], ? [P]). Yet, neither tone nor
length are represented in the standard orthography.
2.1.2 Tone & length in scientific and
educational literature
In contrast to the standard orthography, tone and
length are typically fully represented in the aca-
demic literature on Hausa. Besides reference gram-
mars and other scientific publications on the lan-
guage, this includes lexica, some of which exist in
machine-readable form (e.g., the on-line version
of Bargery (1934) at http://bargeryhausa.
gotdns.com/).
Length in scientific publications is typically
marked using one of the following strategies: di-
acritical marking of long (macron or post-fixed
colon; Newman (2000; Jaggar (2001)) or short vow-
els (ogonek; Newman and Ma Newman (1977)),
and segmental gemination of vowels (long) (Wolff,
1993). Regardless of whether the strategy is di-
acritic or segmental, there is a strong tendency
to have short vowels unmarked, representing the
length information on long vowels only.
Tone, by contrast, is exclusively marked by
means of diacritics: again, two systems are typ-
ically used, one marking low tone with a grave
accent leaving high tone unmarked, the other mark-
ing high tone with an acute accent, leaving low
tone unmarked. Besides that, fully toned represen-
tations can also occasionally be found (using acute
and grave accents). Falling tone, which phonologi-
cally corresponds to a H-L contour associated with
a single heavy syllable, is standardly marked with a
circumflex accent. Rising tone, by contrast, which
only ever plays a role in intonational phonology,
as mentioned in section 1, is typically not repre-
sented.1
Apart from the scientific literature, full represen-
tation of suprasegmental information is also pro-
vided in most of the Hausa language teaching liter-
ature, e.g. Cowan and Schuh (1976; Jungraithmayr
et al (2004). Conventions tend to follow those
found in the scientific literature, given that Hausa
language teaching often forms an integral part of
African linguistics curricula.
The marking strategy assumed in this paper fol-
lows the one found in Newman (2000) and Jaggar
(2001), using diacritics for low and falling tones,
taking high tone as the default. Long vowels are
marked by a macron.
2.2 Arabic script (Ajami)
Besides the now standard Latin orthography, Hausa
has been written traditionally using a slightly mod-
ified version of the Arabic script called ?j?mi. To-
day, Ajami is still used occasionally, mainly in the
context of religious texts.
Just like Boko, Ajami does not represent tone.
Owing to the Semitic origin of the script, however,
length distinctions are indeed captured: while short
vowels are solely marked by diacritics, if at all,
long vowels are represented using a combination
of letters and diacritics: long front vowels (/i:/ and
/e:/) using the letter ya (?


), otherwise used for the
palatal glide /j/, long back vowels using the letter
wau (?), also used for the labio-velar glide /w/, and
1Lexical L-H sequences associated with a single syllable
undergo tonological simplification rules (Leben, 1971; New-
man, 1995).
29
long /a:/ being represented by alif ( @ ).2 Vowel
quality (/i:/ vs. /e:/ and /o:/ vs. /u:/) is differentiated
by means of diacritics.
Thus, depending on the writing system, differ-
ent levels of suprasegmental information need to
be processed, ranging from full representation in
scientific and educational texts, over partial rep-
resentation (Ajami), to complete absence of any
tone or length marking (Boko). This means that
the grammar should be able to extract what infor-
mation is available, and robustly deal with both
specified and underspecified input. This is even
more important, if we want to include applications,
where input in parsing is an underspecified rep-
resentation, but output in generation requires full
specification of suprasegmentals, e.g., in TTS or
CALL scenarios.
3 Morphology and suprasegmental
phonology
Hausa morphological processes, like derivation and
inflection, display close interaction between seg-
mental and suprasegmental marking. Affixation in
Hausa is predominantly suffixal, although prefixes
and circumfixes are also attested. On the segmental
level, affixes can be divided into fully specified suf-
fixes, and reduplicative suffixes. Although partial
and full reduplication of entire CV-sequences can
also be observed, probably the most common redu-
plicative pattern involves reduplication and gem-
ination of root consonants, with vowel melodies
prespecified.
Tonally, affixes fall into one of three categories:
affixes lexically unspecified for tone (only prefixes),
tone-integrating affixes (suffixes only) and non-
integrating affixes3. While non-integrating affixes
only specify their own lexical tone, possibly affect-
ing the segmental and suprasegmental realisation
of a preceding syllable, tone-integrating suffixes
holistically assign a tonal melody to the entire word
they attach to.
In contrast to tone, which is often assigned to the
entire morphological word, alternations in length
do not tend to affect the entire base, but rather only
syllables at morpheme boundaries.
3.1 Tone-integrating suffixes
Hausa plurals represent the prototypical case of
tone-integrating affixation. The language has an
2Ajami letter names are the Hausa equivalent of original
Arabic names. For a more complete description of Ajami, see
Newman (2000, pp. 729?740).
3Among the non-integrating affixes, there is a subclass
bearing polar tone, i.e., the surface tone is opposite to that of
the neighbouring syllable.
extremely rich set of morphological patterns for
plural formation: Newman (2000) identifies 15
classes, many of which have between 2 and 6 sub-
classes. Quite a few Hausa nouns form the plural
according to more than one pattern. Among these
15 plural classes, three are particularly productive,
most notably classes 1-3. All these three classes are
tone integrating, as are almost all plural formation
patterns. Thus, regardless of the tonal specification
in the singular, plural formation assigns a regular
tone melody to the entire word:
(4) -o?X?? (H) (Class I)
a. gul`?a (HL) ? gulo?l?? ?drum stick?
b. ta?g`?a (HL) ? ta?go?g?? ?window?
c. gy?l? (LL) ? gyalo?l?? ?shawl?
d. t?mbay`?a (LHL) ? tambayo?y?? ?ques-
tion?
e. kamf?n?? (HLH) ? kamfano?n?? ?com-
pany?
f. kw?m?t?? (LLHL) ? kwamito?c?? ?com-
mittee?
(5) -ai (LH) (Class II)
a. ?lhaj`?? (LHL) ? ?lh`?azai ?Hadji?
b. ?a?l?b?? (HLH) ? ? `?al?bai ?pupil?
c. sankac`?e (HHL) ? s?nk?tai ?reaped
corn laid down in a row?
d. ?lm?bazz?r?? (LLHLH) ?
?lm?b?zz?rai ?spendthrift?
Class I plural formation involves affixation of
a partially reduplicative suffix -o?X?? replacing the
base-final vowel, if there is one. Tone in class I
plurals is all H, regardless of whether the base is
HL, LH, LL, HLH, or LHL. Length specifications,
by contrast are carried over from the base, except
of course for the base-final vowel. The quality
of the affix-internal consonant is determined by
reduplication of the base-final consonant, possibly
undergoing regular palatalisation.
Class II plurals are formed by means of the fully
specified suffix -ai, with an associated integrating
LH. Tone assignment in Hausa is right to left: thus,
L automatically spreads to the left. Again, the tonal
shape of the base gets entirely overridden by the
LH plural pattern. Non-final length specifications,
however, are identical between the singular and the
plural.
3.2 Toneless prefixes
As we have seen above, tonal association in Hausa
proceeds from right to left. As a result, suffixes
carry a lexical specification for tone. Amongst
30
Hausa prefixes, however, one must distinguish be-
tween those prefixes carrying a (non-integrating)
lexical tone specification themselves, and those pre-
fixes which are inherently unspecified for tone but
have their surface tone determined by means of
automatic spreading. An example of a prefix of the
latter type is provided by the reduplicative prefixes
C1VC1- and C1VC2 found with pluractional verbs.
These prefixes consists of an initial consonant that
copies the first consonant of the base, followed by
a short vowel copying the first vowel of the base
(possibly undergoing centralisation). The prefix-
final consonant either forms a geminate with the
following base-initial consonant, or else copies the
second consonant of the base.
(6) C1VC1-
a. darn?ce? (HLH) ? daddarn?ce? (HHLH)
?press down/oppress (gr 1)?
b. kar?nta? (HLH) ? kakkar?nta? (HHLH)
?read (gr 1)?
c. d`?agur`?a (LHL) ? d?dd`?agur`?a (LLHL)
?gnaw at (gr 2)?
d. gy`?aru (LH) ? gy?ggy`?aru (LLH) ?be
well repaired (gr 7)?
With trisyllabic bases, it is evident that the tone
assumed by the prefix is just a copy of the initial
tone of the base.
The tonal pattern assigned to Hausa verbs are
determined by paradigm membership, the so-called
grade (Parsons, 1960), together with the number
of syllables. Tone melodies range from monotonal,
over bitonal, to maximally tritonal patterns. Thus,
tone-assignment to quadrisyllabic verbs, as derived
by pluractional prefixes, is an effect of automatic
spreading.
Pluractional affixation to bisyllabic verbs con-
stitutes a slightly more complicated case: Since
some paradigms assign different tone melodies to
bisyllabic and trisyllabic verbs, prefixation to bi-
syllabic bases triggers a change in tonal pattern.
Note, however, that the tonal pattern assigned to
the derived trisyllabic pluractional verb is just the
one expected for trisyllabic underived verbs of the
same paradigm (cf. underived grade 1 kar?nta? and
grade 2 d `?agur `?a above to the pluractional grade 1
and grade 2 verbs below).
(7) a. ta?k`?a (HL) ? tatt`?aka? (HLH) ?step on
(gr 1)?
b. j`?efa? (LH) ? j?jje?f`?a (LHL) ?throw at
(gr 2)?4
4Owing to the inherent shortness of the reduplicated vowel,
long /e:/ and /o:/ undergo regular reduction to [a] in the
reduplicant.
Thus, instead of the affix carrying lexical tone,
tone is rather assigned holistically to the entire
derived word (Newman, 2000).
3.3 Non-integrating affixes
The third class of affixes we shall discuss are lex-
ically specified for tone again (if vocalic). Yet, in
contrast to tone-integrating suffixes, they do not
override the entire tonal specification of the base.
Examples of tonally non-integrating suffixes are
manifold. They include nominal and verbal suf-
fixes like the bound accusative (polar) and genitive
pronouns, the genitive linker (-n/-r), the inherently
low-tone specificity marker (-n`/-r`), and the regular
gerundive suffix -`wa?, among many others. What is
common to all these suffixes is that they only affect
the segmental and suprasegmental specification of
the immediately preceding base-final syllable.
Regular gerunds of verbs in grades 1, 4, 5, 6 and
7 are formed by affixation of a floating tone-initial
suffix -`wa?. When attached to a verb ending in a
long high syllable, the base final high tone and the
floating low tone combine into a falling contour
tone. If the base ends in a high short syllable, as in
grade 7, or if the base-final vowel is already low,
no tonal change to the base can be observed.
(8) a. kar?nta? ? kar?nt??awa? ?read (gr1)?
b. sayar ? say?rwa? ?sell (gr5)?
c. ka?wo? ? ka?w??owa? ?come (gr6)?
d. ka?m`?a ? ka?m`?awa? ?catch (gr1)?
e. gy`?aru ? gy`?aruwa? ?be repaired (gr7)?
Note that apart from tonal change of high long to
falling, the base undergoes no segmental or length
change.
Consonantal suffixes, like the genitive linker and
the specificity marker, by contrast, necessarily inte-
grate into the coda of the preceding syllable. Since
Hausa does not allow long vowels in closed syl-
lables, base-final long vowels and diphthongs are
shortened. The specificity marker is identical to the
genitive linker, as far as truncation of long vowels
and diphthongs is concerned. It differs from the
genitive linker, in that it is inherently specified as
low, giving rise to a falling tone with high-final
bases. With low-final bases, no tonal change can
be observed.
(9) a. ?wai ? ?wa-n-t? ?(her) egg?
b. r`??ga? ? r`??ga-r-t? ?(her) gown?
c. mo?t`?a ? mo?t?-r-t? ?(her) car?
(10) a. ?wai ? ?w?-n ?the (aforementioned)
egg?
31
b. r`??ga? ? r`??g?-r ?the (aforementioned)
gown?
c. mo?t`?a ? mo?t?-r ?(her) car?
Note that in contrast to tone-integrating suffixes,
segmental and suprasegmental changes are strictly
local, affecting material in adjacent syllables only.
Besides non-integrating suffixes there are some
very rare prefixes that can be regarded as inherently
specified for tone. One such prefix is low tone
b?- that features in singular ethnonyms, like, e.g.
b?haush `?e ?Hausa person?. Typically, the prefix b?-
is accompanied by a final tone-integrating HL suf-
fix - `?e (masc) or HLH -a?/-?ya? (fem), but not always.
With regular ethnonyms, the initial tone of the suf-
fix (H) spreads to the left, up to but excluding the
low tone prefix. The plural of such ethnonyms is
formed without a prefix. Instead, a tone-integrating
H or LH suffix -a?wa? is used. Vowel length of the
base is retained throughout:
(11) F?rans? ?France? ? B?faransh`?e (m), B?-
faransh?ya? (f) , Faransa?wa? (pl) ?French?
(12) Ja?m?s ?Germany? ? B?ja?mush`?e (m),
B?ja?mush?ya? (f) , Ja?musa?wa? (pl) ?French?
Besides the regular pattern, there are a few eth-
nonyms that use a non-integrating -?? e.g. B?g `?obir??
from G `?obir, thus preserving the tonal pattern of the
place name base. According to Newman (2000),
however, many Hausa speakers prefer to use the
regular tone-integrating suffix - `?e instead. Thus, en-
tirely non-integrating formation of ethnonyms has
ceased to be a part of productive Hausa morphol-
ogy.
Moreover, even the productivity of tonally spec-
ified b?- seems to be diminished: while the plu-
ral is still productive, new ethnonyms tend to be
formed using alternate periphrastic constructions
?an/m?tum?n ?son/man of? (Newman, 2000).
(13) a. P?l?s???n? ?Palestine? ? ?an/m?tum?n
P?l?s???n? (m) ? Palas???na?wa? (pl)
?Palestinian?
b. Bosniy? ?Bosnia? ? ?an/m?tum?n
Bosniy? (m) ? Bosniya?wa? (pl)
?Bosnian?
To summarise, I shall take integrating and non-
integrating suffixation as the standard case in
Hausa, together with toneless prefixation. As we
shall see in the description of our implementation
in the following section, the treatment of isolated
cases of tonally specified prefixes will be treated as
a non-productive sub-regularity.
4 Representing autosegmental phonology
in the LKB
4.1 Orthographemics in the LKB
The LKB (Copestake, 2002) has built-in support
for orthographemic alternations, providing support
for inflectional and derivational morphology. Tech-
nically, the orthographemic component of the LKB
adopts a string-unification approach. Below is an
example of the spelling part of regular -o?X?? plural
formation, together with the definitions of letter
sets and wild-cards used. Patterns on the right pre-
empt patterns further to the left.
(14) %(wild-card (?v aeiou))
%(letter-set (!c bcdfghjklmnpqrstvwxyz???)?)
noun_pl1_vow_ir :=
%suffix (!c?v !co!ci) (t?v toci)
(s?v soshi) (w?v woyi) (ts?v tsotsi)
noun-plural-infl-rule &
...
In the above rule, the letter set !c is string uni-
fied with the corresponding consonantal letter in the
input. Note that in contrast to wild cards (e.g. ?v),
multiple occurrences of letter set identifiers within
the same pattern are bound to the same consonant,
providing a convenient solution to gemination and
partial reduplication.
Orthographemic rules are unary (lexical) rules
consisting of a feature structure description and an
associated spelling change. The orthographemic
part is applied to surface tokens in order to derive
potential stem forms. The parser?s chart is then
initialised with lexical entries that have a corre-
sponding stem form. The orthographemic rules
that have been applied in order to derive the stem
are recorded on an agenda such that the feature
structure part can be applied to the lexical entries
thus retrieved.
Recall from section 2 that Hausa standard or-
thography does not represent tone or length. Thus,
suprasegmentally unmarked strings define the com-
mon denominator for retrieving entries from the
lexicon. But even if the input is marked diacrit-
ically for suprasegmentals, tone-integrating mor-
phology can lead to drastic tonal changes, which
are superficially encoded as segmental alternations
(since ? 6= ?). Moreover, we hope to have shown
above that tone and segmental phonology should
best be treated separately. Consequently, ortho-
graphic representations unmarked for tone consti-
tute the common denominator for all orthographic
input representations.
In a first preprocessing step, tone and length
specifications on input tokens are extracted by
means of a regular expression preprocessing en-
gine built into the LKB (Waldron et al, 2006).
32
Instead of simply removing this potentially valu-
able information, the preprocessor rules convert
the (diacritical) marking of tone and length into an
inverse suffixal representation, separated from the
segmental string by _. Overtly marked high will be
represented as _H, overtly marked low as _L, and
lack of tonal marking is recorded as _*. Similarly,
length information, if present, will be recorded by
means of a colon next to the corresponding tone.
E.g., input ? `?al `??bai ?pupils? will be converted
into ?alibai_*_L_L:, whereas tonally unspec-
ified ?alibai will become ?alibai_*_*_*.
Input partially specified for length (?aalibai),
as, e.g., in Ajami, will receive a representation as
?alibai_*_*_*:.
Once we have separated suprasegmental infor-
mation from the orthography proper and stored
it in the form of suffixal annotations, we can use
LKB?s standard orthographemic machinery to con-
vert the suffixal annotation into feature structure
constraints.5
4.2 Phonological representation
As we have seen above, there are several strategies
of tone and length marking in Hausa. While overtly
marked tone and length is both unambiguous in it-
self and directly enables us to infer what marking
strategy is used, the interpretation of vowels un-
marked for tone or length depends entirely on the
context: if a low-marking strategy is employed, un-
marked segments (=_*) can be interpreted as high.
However, if no marking of tone occurs at all in
the input, unmarked segments should be compati-
ble with any tone. The very same goes for length.
In order to enable the grammar to flexibly infer
the meaning of these underspecified annotations,
we introduce the following type hierarchy of tonal
marking. The only assumption made here is that
the marking strategy being adopted is used consis-
tently across the entire input sentence.6
Lexical and grammatical tones will be one of
high, low, or fall.7 In addition to these three lin-
guistic tones, the type hierarchy features tonal types
that correspond to tonal annotations found in the
input: utone is the type associated with tonally un-
marked syllables, tone_ is the type associated with
5In the near future, we plan to supplant this two-step solu-
tion with a direct conversion of using diacritical information
into feature structure annotations, using the advanced token-
mapping developed by Adolphs et al (2008). At present,
however, this token-mapping has only been integrated into the
Pet run-time system (Callmeier, 2000), but not yet into the
LKB.
6In principle, even this assumption can be relaxed, at the
peril of having reduced cross-sentence disambiguation.
7I do not decompose falling tone into HL sequences,
thereby simplifying the alignment between tone specifications,
length specifications and segments.
a high-marking strategy, _tone corresponds to low-
marking, and _tone_ to full tonal marking (overt
high and low).
(15)
tone
_tone _utone
_uhigh
_tone_
_low_
_high_
_fall_
_low
_high
_fall
utone
utone_
ulow_
ufall
tone_
low_
high_
fall_
low
high
fall
Depending on which annotations are present in
the input, the meaning of underspecified annota-
tions can be determined on the basis of type infer-
ence. The orthographemic rules that consume tonal
annotations do exactly two things: first, they record
the tone specification just found as the first mem-
ber of the TONE list of the daughter, successfully
building up a list of surface tones from right to left.
(16) _HH_ir :=
%suffix (* _H:)
diacritic-irule &
[SUPRA [TONE [LIST #tones,
LAST #tl],
LEN [LIST #lens,
LAST #ll]],
DTR [SUPRA [TONE [LIST
high-marked-list &
<high . #tones>,
LAST #last],
LEN [LIST
long-marked-list &
<long . #lens>,
LAST #ll]]]].
_*_ir :=
%suffix (* \*)
diacritic-irule &
[SUPRA [TONE [LIST #tones,
LAST #tl],
LEN [LIST #lens,
LAST #ll]],
DTR [SUPRA [TONE [LIST
<utone . #tones>,
LAST #last],
LEN [LIST
<ulength . #lens>,
LAST #ll]]]].
If the annotation is that of an overtly unmarked
tone, the underspecified type utone is inserted, oth-
erwise high or low, as appropriate. H or L tone
rules simultaneously constrain the entire tone list
according to the marking strategy, using list con-
straints.
(17) high-marked-list :=
tone-marked-list.
high-marked-null :=
high-marked-list &
tone-marked-null.
33
high-marked-cons :=
high-marked-list &
tone-marked-cons &
[FIRST tone_,
REST high-marked-list].
Presence of a single overtly marked high tone
will constrain every element of the tone list to be
a subtype of high_. According to the hierarchy of
tonal types given above, the greatest lower bound
of utone and high_ however, is low_, denoting (un-
marked) low tone under a high-marking strategy.
Thus, whatever tonal marking is found, unmarked
tones are coerced to represent the opposite tones.
The way the type hierarchy is set up, 4 different
marking strategies are possible: completely unspec-
ified tone, high-tone marking, low-tone marking
and fully explicit high- and low-tone marking.
With the constraints we have just seen, we only
get disambiguation of unmarked tone (and length)
within the same word. In order to disambiguate
across the entire sentence, we use difference lists
of these tone and length lists to propagate the mark-
ing regime to preceding and following words. In
essence, we use two difference lists _LTONE and
_RTONE to propagate from left to right and vice
versa.8 Lexically, every word inserts its own tone
list as the singleton member of each difference list.
The general phrasal types from which all gram-
mar rules inherit now concatenate the _LTONE and
_RTONE values of their daughters left to right and
right to left, respectively.
The tone marking rules given above are then fur-
ther constrained according to the types of _LTONE
and _RTONE. Using list-of-list type constraints as
given below, every word marked for tone will con-
strain the marking regime found to its left and to
its right.
(18) hm-llist := tm-llist.
hm-clist := tm-clist &
hm-llist &
[FIRST high-marked-list,
REST hm-llist].
hm-nlist := hm-llist & tm-nlist.
The treatment of length marking, as we have
hinted at already, is entirely analogous to that of
tone, imposing the corresponding constraints on a
list of vowel length specifications.
With these constraints in place, we get the fol-
lowing disambiguation results (note that the verb
zo? is lexically specified as long):
(19) a. Fully unspecified: Ya zo (3 readings:
ya? zo?, ya zo?, y? zo?)
8Since only overtly marked items can disambiguate tonally
unmarked ones, and the position of these disambiguating items
in the string is not known a priori, we need two lists of lists,
one for disambiguation of preceding material (_LTONE), the
other for following material _RTONE.
b. Length specified: Ya zoo (2 read-
ings: ya zo?, y? zo?)
c. Length specified: Yaa zoo (1 read-
ing: ya? zo?)
d. Tone/length specified: Ya kaawoo
sh? (1 reading: ya ka?wo? sh?)
e. Fully specified: Y? z?? (1 reading:
ya zo?)
f. Inconsistent: Yaa zo (0 readings)
As witnessed above, presence of length mark-
ing coerces vowels not marked as long into the
short vowel reading. Similarly, presence of a single
low tone marking enforces a high tone reading of
overtly unmarked tones.
In generation, the grammar only uses fully spec-
ified tone marking, i.e., application of rules such
as _*_ir is blocked. As a result, we always get a
surface representation with full tone and length in-
formation. Post-generation Lisp functions are used
to convert the suffixal notation into the appropriate
diacritic format.
4.3 Morphology
The main motivation for having tone and length
represented on separate lists is two-fold: first, as
witnessed by Ajami, writing systems may overtly
mark one distinction but not the other. Second, and
more importantly, we have seen in section 3, that
morphological processes tend to leave length in-
tact, even if the entire word is holistically marked
with a completely new tonal melody, unrelated to
that of the base. Having two separate lists, we can
replace the tonal structure in the course of mor-
phological derivation but still have the rhythmic
structure shared between base and derived form by
means of reentrancies.
Here we investigate in more detail the role these
representations play in morphological derivation.
In the previous section, we provided a general
representation of segmental and suprasegmental
information, the latter being encoded by means of
two lists and showed how preprocessor rules and
orthographemic rules are used to extract this infor-
mation from the input and associate it with parts of
the feature structure, such that it can be matched
against morphological and lexical constraints on
length and tone.
Since both tone and length are lexically distinc-
tive, every lexical item specifies the contents of its
SUPRA|TONE and SUPRA|LEN lists. The order of
the elements on these two lists is right to left, facil-
itating a treatment of tone spreading by means of
list types. At the same time, this encoding provides
convenient access to the right-most length and tone
34
specification. Since Hausa is predominantly suf-
fixal, non-holistic morphophonological changes to
tone and length specifications exclusively target the
right-most syllable of the base.
As we have observed above, tonal changes can
be far more global than segmental and length alter-
nations. Thus, we will use the LEN list to synchro-
nise the segmental and suprasegmental represen-
tations. Consequently, length specifications will
always be a closed list. Tone, by contrast, may
involve spreading, i.e. the exact number of indi-
vidual H of an all H tone melody is determined by
the number of available tone bearing units, which
corresponds to vowel length specifications in our
grammar. Since the number of tone bearing units is
already fixed by the length of LEN, and because the
tone marking rules operate synchronously on TONE
and LEN, we are free to underspecify the tonal rep-
resentation as to the exact length of the melody.
Therefore, we can provide a straightforward ac-
count of right-to-left association and left-ward tone
spreading in terms of open tone list types.
(20) h*-list := list.
h*-cons := h*-list &
cons & [FIRST high,
REST h*-list].
h*-null := h*-list & null.
h*-l-list := list.
h*-l-cons := h*-l-list &
cons & [FIRST low,
REST h*-list].
As we shall see shortly, these list types provide
a highly general way to constrain holistic tonal
assignment, independently of the segmental make-
up of the base.
In order to illustrate the interplay between seg-
mental and suprasegmental constraints in morpho-
logical derivation, I provide a treatment of the
two major types of morphological rules: tone-
integrating and non-integrating.9
(21) noun_pl1_vow_ir :=
%suffix (!c?v !co!ci) ...
noun-plural-infl-rule \&
[SUPRA
[TONE [LIST h*-list],
LEN [LIST < long, long . #ll>,
LAST #llast] ],
DTR [SYNSEM.LKEYS.--MCLASS n-pl-1,
SUPRA.LEN [LIST < [] . #ll>,
LAST #llast]]].
Tone integrating affixes In our discussion of the
Class I plural inflection rule above, we have only
specified the segmental changes. As detailed in
the version below, holistic assignment of tone is
achieved by means of a list type constraint on the
9Toneless prefixation with automatic spreading constitutes
just a special sub-case of tone-integrating rules.
TONE of the mother, paired with the absence of
any tonal restrictions regarding the morphological
daughter (the base). The length marking of the two
inherently long suffix vowels is captured by means
of the addition of two long specification at the front
of LEN. Affixation of -o?X?? replaces the base final
vowel. Accordingly, the associated initial length
specification of the daughter is skipped and the re-
maining list is passed on to the length specification
of the mother.
Non-integrating affixes In feminine singular
specificity marking, both non-integrating tone and
length changes can be observed. As depicted be-
low, high-final bases undergo a tone change to fall.
The remainder of the TONE list is structure-shared
between mother and daughter, carrying over any
list constraints that might be imposed there.
(22) f-sg-noun_def_high_ir :=
%suffix (!v !vr) (!vi !vr) ...
noun-def-f-sg-irule &
[SUPRA [TONE [LIST <fall . #tl >,
LAST #tlast],
LEN [LIST <short . #ll>,
LAST #llast]],
DTR [SUPRA
[TONE [LIST <high . #tl>,
LAST #tlast],
LEN [LIST <[] . #ll>,
LAST #llast] ]]].
Likewise, final shortening, which is triggered
by the affixation of a syllable-final consonant, is
captured by an analogous constraint on LEN.
5 Conclusion
In this paper, we have proposed a treatment of tone
and length in Hausa in terms of distinct representa-
tions of segments, tone and length. We have shown
that this separation is not only needed to accommo-
date different orthographic representations in the
input, but that it also paves the way for a more gen-
eral account of Hausa morphology, most notably
holistic assignment of tonal melodies combined
with tone spreading. At present, the grammar is
not only capable of extracting different levels of
suprasegmental annotations contained in the input,
but can also resolving tone and length ambigui-
ties on the basis of grammatical constraints: e.g.,
the ambiguity between genitive linker and previ-
ous reference marker, or the ambiguity between
subjunctive, preterite, and absolute completive in
relative and focus constructions. In the future, we
intend to equip the grammar with parse selection
models, to further enhance disambiguation. Given
the bidirectionality of the grammar and its flexible
support for tone and length, we plan to use it in the
context of TTS and CALL applications in the near
future.
35
References
Peter Adolphs, Stephan Oepen, Ulrich Callmeier,
Berthold Crysmann, Dan Flickinger, and Bernd
Kiefer. 2008. Some fine points of hybrid natural
language parsing. In Proceedings of the 6th Confer-
ence on Language Resources and Evaluation (LREC
2008), May, Marrakesh.
G. P. Bargery. 1934. A Hausa?English Dictionary
and English?Hausa Vocabulary. Oxford University
Press, London.
Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2002. The grammar matrix: An open-source starter-
kit for the rapid development of cross-linguistically
consistent broad-coverage precision grammar. In
John Carroll, Nelleke Oostdijk, and Richard Sut-
cliffe, editors, Proceedings of the Workshop on
Grammar Engineering and Evaluation at the 19th
International Conference on Computational Linguis-
tics, pages 8?14.
Steven Bird and Ewan Klein. 1994. Phonological anal-
ysis in typed feature systems. Computational Lin-
guistics, 20(3):455?491.
Steven Bird. 1995. Computational Phonology. A
Constraint-based Approach. Studies in Natural
Language Processing. Cambridge University Press,
Cambridge.
Ulrich Callmeier. 2000. PET ? a platform for ex-
perimentation with efficient HPSG processing tech-
niques. Journal of Natural Language Engineering,
6(1):99?108.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI Publications, Stanford.
J. Ronayne Cowan and Russell Schuh. 1976. Spoken
Hausa. Spoken Language Services, Ithaca.
Berthold Crysmann. 2005. An inflectional approach to
Hausa final vowel shortening. In Geert Booij and
Jaap van Marle, editors, Yearbook of Morphology
2004, pages 73?112. Kluwer.
Ji Fang and Tracy Holloway King. 2007. An LFG Chi-
nese grammar for machine use. In Tracy Holloway
King and Emily Bender, editors, Proceedings of the
GEAF 2007 Workshop, CSLI Studies in Computa-
tional Linguistics ONLIN. CSLI Publications.
John A. Goldsmith. 1976. Autosegmental Phonology.
Ph.D. thesis, MIT.
Bruce Hayes. 1990. Precompiled phrasal phonol-
ogy. In Sharon Inkelas and Draga Zec, editors, The
Phonology-Syntax Connection, pages 85?108. Uni-
versity of Chicago Press.
Sharon Inkelas and William R. Leben. 1990. Where
phonology and phonetics intersect: The case of
Hausa intonation. In Mary E. Beckman and John
Kingston, editors, Between the Grammar and the
Physics of Speech, Papers in Laboratory Phonol-
ogy, pages 17?34. Cambridge University Press, New
York.
Philip Jaggar. 2001. Hausa. John Benjamins, Amster-
dam.
Philip Jaggar. 2006. The Hausa perfective tense-aspect
used in wh-/focus constructions and historical narra-
tives: A unified account. In Larry Hyman and Paul
Newman, editors, West African Linguistics: Descrip-
tive, Comparative, and Historical Studies in Honor
of Russell G. Schuh, Studies in African Linguistics,
pages 100?133.
Herrmann Jungraithmayr, Wilhelm J. G. M?hlig, and
Anne Storch. 2004. Lehrbuch der Hausa-Sprache.
R?diger K?ppe Verlag, K?ln.
William R. Leben. 1971. The morphophonemics of
tone in Hausa. In C.-W. Kim and Herbert Stahlke,
editors, Papers in African Linguistics, pages 201?
218. Linguistic Research, Edmonton.
William Leben. 1973. Suprasegmental Phonology.
Ph.D. thesis, MIT.
Paul Newman and Roxana Ma Newman. 1977. Mod-
ern Hausa?English Dictionary. University Press,
Ibadan and Zaria, Nigeria.
Paul Newman. 1995. Hausa tonology: Complexities in
an ?easy? tone language. In John Goldsmith, editor,
The Handbook of Phonological Theory, pages 762?
781. Blackwell, Oxford.
Paul Newman. 2000. The Hausa Language. An En-
cyclopedic Reference Grammar. Yale University
Press, New Haven, CT.
F. W. Parsons. 1960. The verbal system in Hausa.
Afrika und ?bersee, 44:1?36.
Jim Scobbie. 1991. Attribute-Value Phonology. Ph.D.
thesis, University of Edinburgh.
William R. Leben Sharon Inkelas and Mark Cobler.
1987. The phonology of intonation in Hausa. In
Proceedings of the North-Eastern Linguistic Society
17, pages 327?341.
Ben Waldron, Ann Copestake, Ulrich Sch?fer, and
Bernd Kiefer. 2006. Preprocessing and tokenisa-
tion standards in DELPH-IN tools. In Proceedings
of the 5th International Conference on Language Re-
sources and Evaluation (LREC-2006), pages 2263?
2268, Genova, May.
Markus Walther. 1999. Deklarative Prosodische
Morphologie, volume 399 of Linguistische Arbeiten.
Niemeyer, T?bingen.
Ekkehard Wolff. 1993. Referenzgrammatik des Hausa.
LIT, M?nster.
36
Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE 2011), pages 65?73,
Portland, Oregon, USA, 23 June 2011. c?2011 Association for Computational Linguistics
A machine learning approach to relational noun mining in German
Berthold Crysmann
Arbeitsbereich Sprache und Kommunikation
Universita?t Bonn
crysmann@uni-bonn.de
Abstract
In this paper I argue in favour of a col-
location extraction approach to the acquisi-
tion of relational nouns in German. We an-
notated frequency-based best lists of noun-
preposition bigrams and subsequently trained
different classifiers using (combinations of)
association metrics, achieving a maximum F-
measure of 69.7 on a support vector machine
(Platt, 1998). Trading precision for recall, we
could achieve over 90% recall for relational
noun extraction, while still halving the anno-
tation effort.
1 Mining relational nouns: almost a MWE
extraction problem
A substantial minority of German nouns are char-
acterised by having an internal argument structure
that can be expressed as syntactic complements. A
non-negligeable number of relational nouns are de-
verbal, inheriting the semantic argument structure of
the verbs they derive from. In contrast to verbs, how-
ever, complements of nouns are almost exclusively
optional.
The identification of relational nouns is of great
importance for a variety of content-oriented applica-
tions: first, precise HPSG parsing for German can-
not really be achieved, if a high number of noun
complements is systematically analysed as modi-
fiers. Second, recent extension of Semantic Role La-
beling to the argument structure of nouns (Meyers
et al, 2004) increases the interest in lexicographic
methods for the extraction of noun subcategorisa-
tion information. Third, relational nouns are also
a valuable resource for machine translation, sepa-
rating the more semantic task of translating modi-
fying prepositions from the more syntactic task of
translating subcategorised for prepositions. Despite
its relevance for accurate deep parsing, the German
HPSG grammar developed at DFKI (Mu?ller and
Kasper, 2000; Crysmann, 2003; Crysmann, 2005)
currently only includes 107 entries for proposition
taking nouns, and lacks entries for PP-taking nouns
entirely.
In terms of subcategorisation properties, rela-
tional nouns in German can be divided up into 3
classes:
? nouns taking genitival complements (e.g., Be-
ginn der Vorlesung ?beginning of the lecture?,
Zersto?rung der Stadt ?destruction of the city? )
? nouns taking propositional complements, ei-
ther a complementiser-introduced finite clause
(der Glaube, da? die Erde flach ist ?the belief
that earth is flat?), or an infinitival clause (die
Hoffnung, im Lotto zu gewinnen ?the hope to
win the lottery?), or both
? nouns taking PP complements
In this paper, I will be concerned with nouns tak-
ing prepositional complements, although the method
described here can also be easily applied to the case
of complementiser-introduced propositional com-
plements.1
1In fact, I expect the task of mining relational nouns tak-
ing finite propositional complements to be far easier, owing to
a reduced ambiguity of the still relatively local complementiser
65
The prepositions used with relational nouns all
come from a small set of basic prepositions, mostly
locative or directional.
A characteristic of these prepositions when used
as a noun?s complement, is that their choice becomes
relatively fixed, a property shared with MWEs in
general. Furthermore, choice of preposition is of-
ten arbitrary, sometimes differing between relational
nouns and the verbs they derive from, e.g., Interesse
an ?lit: interest at? vs. interessieren fu?r ?lit: to inter-
est for?. Owing to the lack of alternation, the prepo-
sition by itself does not compositionally contribute
to sentence meaning, its only function being the en-
coding of a thematic property of the noun. Thus, in
syntacto-semantic terms, we are again dealing with
prototypical MWEs.
The fact that PP complements of nouns, like mod-
ifiers, are syntactically optional, together with the
fact that their surface form is indistinguishable from
adjunct PPs, makes the extraction task far from triv-
ial. It is clear that grammar-based error mining tech-
niques (van Noord, 2004; Cholakov et al, 2008)
that have been highly successful in other areas of
deep lexical acquisition (e.g., verb subcategorisa-
tion) cannot be applied here: first, given that an al-
ternative analysis as a modifier is readily available
in the grammar, missing entries for relational nouns
will never incur any coverage problems. Further-
more, since PP modifiers are highly common we
cannot expect a decrease in tree probability either.
Instead, I shall exploit the MWE-like properties of
relational nouns, building on the expectation that the
presence of a subcategorisation requirement towards
a fixed, albeit optional, prepositional head should
leave a trace in frequency distributions. Thus, build-
ing on previous work in MWE extraction, I shall
pursue a data-driven approach that builds on a va-
riety of association metrics combined in a proba-
bilistic classifier. Despite the difference of the task,
da?. Although complement that-clauses in German can indeed
can be extraposed, corpus studies on relative clause extraposi-
tion (Uszkoreit et al, 1998) have shown that the great majority
of extrapositions operates at extremely short surface distance,
typically crossing the verb or verb particle in the right sentence
bracket. Since locality conditions on complement clause extra-
position are more strict than those for relative clause extrapo-
sition (Kiss, 2005; Crysmann, to appear), I conjecture that the
actual amount of non-locality found in corpora will be equally
limited.
the approach suggested here shares some significant
similarity to previous classifier-based approaches to
MWE (Pecina, 2008).
2 Data
2.1 Data preparation
As primary data for relational noun extraction, I
used the deWaC corpus (Baroni and Kilgariff, 2006),
a 1.6 billion token corpus of German crawled from
the web. The corpus is automatically tagged and
lemmatised by TreeTagger (Schmid, 1995). From
this corpus, I extracted all noun (NN) and prepo-
sition (APPR) unigrams and noun?preposition bi-
grams. Noun unigrams occuring less than ten times
in the entire corpus were subsequently removed. In
addition to the removal of hapaxes, I also filtered out
any abbreviations.
Frequency counts were lemma-based, a deci-
sion that was motivated by the intended applica-
tion, namely mining of relational noun entries for
a lemma-based HPSG lexicon.
From the corpus, I extracted a best-list, based
on bigram frequency, a well-established heuristical
measure for collocational status (Krenn, 2000). Us-
ing a frequency based best list not only minimises
initial annotation effort, but also ensures the quick-
est improvement of the target resource, the gram-
mar?s lexicon. Finally, the use of ranked best lists
will also ensure that we will always have enough
positive items in our training data.
2.2 Annotation
The ranked best list was subsequently annotated by
two human annotators (A1,A2) with relatively little
prior training in linguistics. In order to control for
annotation errors, the same list was annotated a sec-
ond time by a third year student of linguistics (A3).
In order to operationalise the argument/modifier
annotators were asked to take related verbs into
consideration, as well as to test (local and tempo-
ral) prepositions for paradigmatic interchangeabil-
ity. Furthermore, since we are concerned with logi-
cal complements of nouns but not possessors, which
can be added quite freely, annotators were advised to
further distinguish whether a von-PP was only pos-
sible as a possessor or also as a noun complement.
An initial comparison of annotation decisions
66
showed an agreement of .82 between A1 and A3,
and an agreement of .84 between A2 and A3. In
a second round discrepancies between annotators
were resolved, yielding a gold standard annotation
of 4333 items, out of which 1179 (=27.2%) were
classified as relational nouns.
3 Experiments
All experiments reported here were carried out us-
ing WEKA, a Java platform for data exploration
and experimentation developed at the University of
Waikato (Hall et al, 2009).
Since our task is to extract relational nouns and
since we are dealing with a binary decision, per-
formance measures given here report on relational
nouns only. Thus, we do not provide figures for the
classification of non-relational nouns or any uninfor-
mative (weighted) averages of the two.2
3.1 Learners
In a pre-study, we conducted experiments with a sin-
gle feature set, but different classifiers in order to de-
termine which ones performed best on our data set.
Amongst the classifiers we tested were 2 Bayesian
classifiers (Naive Bayes and Bayesian Nets), a Sup-
port Vector Machine, a Multilayer Perceptron clas-
sifier, as well as the entire set of decision tree clas-
sifiers offered by WEKA 3.6.4 (cf. the WEKA doc-
umentation for an exhaustive list of references). All
test runs were performed with default settings. Un-
less otherwise indicated, all tests were carried out
using 10-fold cross-validation.
Among these, decision tree classifiers perform
quite well in general, with NBTree, a hybrid de-
cision tree classifier using Naive Bayes classifiers
at leave nodes producing optimal results. Perfor-
mance of the Naive Bayes classifier was subopti-
mal, with respect to both precision and recall. Over-
all performance of the Bayesian Net classifier (with
a K2 learner) was competitive to average decision
tree classifiers, delivering particularly good recall,
but fell short of the best classifiers in terms of preci-
sion and F-measure.
2A base-line classifier that consistently choses the majority
class (non-relational) and therefore does not detect a single re-
lational noun, already achieves an F-measure for non-relational
nouns of 84.3, and a weighted F-measure of 61.3%.
Thus, for further experimentation, we concen-
trated on the two best-performing classifiers, i.e.,
NBTree (Kohavi, 1996), which achieved the high-
est F-score and the second best precision, and SMO
(Platt, 1998), a support vector machine, which pro-
duced the best precision value.
After experimentation regarding optimal feature
selection (see next section), we re-ran our experi-
ments with the modified feature set, in order to con-
firm that the classifiers we chose were still optimal.
The results of these runs are presented in table 1.
Prec. Rec. F-meas.
ADTree 68.3 61.1 64.5
BFTree 75.0 51.7 61.2
DecisionStump 52.5 80.2 63.5
FT 73.8 59.1 65.7
J48 72.9 58.4 64.8
J48graft 72.6 58.4 64.7
LADTree 70.5 57.5 63.3
LMT 74.9 59.8 66.5
NBTree 74.9 62.8 68.7
RandomForest 67.4 63.4 65.3
RandomTree 61.8 61.1 61.4
REPTree 74.5 61.2 67.2
Naive Bayes 70.5 53.9 61.1
Bayes Net 60.6 71.4 65.6
SMO 76.5 57.7 65.8
MultilayerPerceptron 67.5 64.5 65.9
Bagging (RepTree) 75.9 62.4 68.5
Voting (maj) 72.7 66.3 69.4
Voting (av) 71.3 68.4 69.8
Table 1: Performance of different classifiers
Finally, we did some sporadic test using a vot-
ing scheme incorporating 3 classifiers with high pre-
cision values (SMO, NBTree, Bagging(REPTree)
(Breiman, 1996)), as well as two classifiers with
high recall (BayesNet, recall-oriented SMO, see be-
low). Using averaging, we managed to bring the F-
measure up to 69.8, the highest value we measured
in all our experiments.
3.2 Features
For NBTree, our best-performing classifier, we sub-
sequently carried out a number of experiments to as-
sess the influence and predictive power of individual
association measures and to study their interactions.
67
Essentially, we make use of two basic types of
features: string features, like the form of the preposi-
tion or the prefixes and suffixes of the noun, and as-
sociation measures. As for the latter, we drew on the
set of measures successfully used in previous studies
on collocation extraction:
Mutual information (MI) An information theo-
retic measure proposed by (Church and Hanks,
1990) which measures the joint probability of
the bigram in relation to the product of the
marginal probabilities, i.e., the expected proba-
bility.
MI =
p(noun, prep)
p(noun) ? p(prep)
MI2 A squared variant of mutal information, previ-
ously suggested by (Daille, 1994). Essentially,
the idea behind squaring the joint probability is
to counter the negative effect of extremely low
marginal probabilities yielding high MI scores.
MI2 =
(p(noun, prep))2
p(noun) ? p(prep)
Likelihood ratios A measure suggested by (Dun-
ning, 1993) that indicates how much more
likely the cooccurence is than mere coinci-
dence.
LR = logL(pi, k1, n1) + logL(p2, k2, n2)
? logL(p, k1, n1) ? logL(p, k2, n2)
where
logL(p, n, k) = k log p+ (n? k) log(1 ? p)
and
p1 =
k1
n1
, p2 =
k2
n2
, p =
k1 + k2
n1 + n2
t-score The score of Fisher?s t-test. Although the
underlying assumption regarding normal distri-
bution is incorrect (Church and Mercer, 1993),
the score has nevertheless been used with re-
peated success in collocation extraction tasks
(Krenn, 2000; Krenn and Evert, 2001; Evert
and Krenn, 2001).
tscore =
p(noun, prep) ? (p(noun) ? p(prep))
?
?2
N
As suggested by (Manning and Schu?tze, 1999)
we use p as an approximation of ?2.
Association Strength (Smadja, 1993)
A factor indicating how many times the stan-
dard deviation a bigram frequency differs from
the average.
Strength =
freqi ? f?
?
Best Indicates whether a bigram is the most fre-
quent one for the given noun or not.
Best-Ratio A relative version of the previous fea-
ture indicating the frequency ratio between the
current noun?preposition bigram and the best
bigram for the given noun.
In addition to the for,m of the preposition, we in-
cluded information about the noun?s suffixes or pre-
fixes:
Noun suffix We included common string suffixes
that may be clues as to the relational nature of
the noun, as, e.g., the common derviational suf-
fixes -ion, -schaft, -heit, -keit as well as the end-
ings -en, which are found inter alia with nom-
inalised infinitives, and -er, which are found,
inter alia with agentive nominals. All other suf-
fixes were mapped to the NONE class.
Noun prefix Included were prefixes that commonly
appear as verb prefixes. Again, this was used
as a shortcut for true lexical relatedness.
As illustrated by the diagrams in Figure 1, the
aforementioned association measures align differ-
ently with the class of relational nouns (in black):
The visually discernible difference in alignment
between association metrics and relational nouns
was also confirmed by testing single-feature classi-
fiers: as detailed in Table 2, MI, MI2, and t-score
all capable to successfully identify relational nouns
by themselves, whereas best, best-ratio and strength
68
Figure 1: Distribution of relational and non-relational nouns across features (created with WEKA 3.6.4)
are entirely unable to partition the data appropri-
ately. LR assumes an intermediate position, suffer-
ing mainly from recall problems.
Prec. Rec. F-meas.
MI 65.2 45.2 53.4
MI2 62.2 50.7 55.9
LR 60 23.5 33.8
T-score 66.4 42 51.5
Strength 0 0 0
Best 0 0 0
Best-Ratio 0 0 0
Table 2: Classification by a single association metric
The second experiment regarding features differs
from the first by the addition of form features:
Two things are worth noting here: first, the values
achieved by MI and T-score now come very close to
the values obtained with much more elaborate fea-
ture sets, confirming previous results on the useful-
ness of these metrics. Second, all association mea-
sures now display reasonable performance. Both
Prec. Rec. F-meas.
MI 74.2 61.2 67.1
MI2 72.5 56.4 63.5
LR 73.1 54.4 62.4
T-score 74.9 60.6 67
Strength 72.5 52.4 60.9
Best 69.7 48.7 57.3
Best-Ratio 72.1 53.4 61.3
Table 3: Classification by a single association metric +
form features (preposition, noun prefix, noun suffix)
these effects can be traced to a by-category sampling
introduced by the form features. The most clear-cut
case is probably the best feature: as shown in Fig-
ure 1, there is a clear increase in relational nouns in
the TRUE category of the Boolean best feature, yet,
they still do not represent a majority. Thus, a clas-
sifier with a balanced cost function will always pre-
fer the majority vote. However, for particular noun
classes (and prepositions for that matter) majorities
can be tipped.
69
Figure 2: MI-values of relational nouns relative to preposition
As depicted by the preposition-specific plot of MI
values in Figure 2, some prepositions have a clear
bias for their use with relational nouns (e.g., von
?of?) or against it (e.g., ab ?from?), while others ap-
pear non-commital (e.g., fu?r ?for?). Similar observa-
tions can be made for noun suffixes and prefixes.
The next set of experiments were targetted at op-
timisation. Assuming that the candidate sets se-
lected by different metrics will not stand in a sub-
set relation I explored which combination of met-
rics yielded the best results. To do this, I started
out with a full set of features and compared this to
the results obtained with one feature left out. In a
second and third step of iteration, I tested whether
simultaneously leaving out some features for which
we observed some gain would produce an even more
optimised classifier.
Table 4 presents the result of the first step. Here,
two outcomes are of particular interest: deleting
information about the noun suffix is detrimental,
Prec. Rec. F-meas.
All 74.4 61.2 67.2
?T-score 75.3 62.4 68.3
?MI 72.8 62.3 67.1
?MI2 75.1 61.6 67.7
?LR 74.1 60.1 66.3
?Strength 73.4 62 67.2
?Best 73.7 60.7 66.6
?Best-Ratio 74.2 61.8 67.4
?Prep 74.7 61.1 67.2
?Noun-Prefix 74.7 61.1 67.2
?Noun-Suffix 71.3 55.3 62.3
Table 4: Effects of leaving one feature out
whereas ignoring the t-score value appears to be
beneficial to overall performance.
In a second (and third) iteration, I tested whether
any additional feature deletion apart from t-score
would give rise to any further improvements.
70
?t-score Prec. Rec. F-meas.
75.3 62.4 68.3
?MI 74.4 57.6 64.9
?LR 74.8 61.3 67.4
?MI2 74.1 61.7 67.4
?Strength 75.1 62.8 68.4
?Best 74.1 61.5 67.2
?Best-Ratio 75.4 62.6 68.4
?Best-Ratio ?Strength 74.9 63.4 68.7
Table 5: Effects of leaving two or more features out
In fact, removal of the Strength feature provided
good results, whether taken out individually or in
combination, which may be due to this feature?s in-
herently poor statistical properties (cf. Figure 1). Ig-
noring best-ratio was also beneficial, probably due
to the fact that most of its benefical properties are al-
ready covered by the best feature and that non-best
noun-preposition combinations hardly ever give rise
to positive hits.
As a matter of fact, simultaneous removal of best-
ratio and strength, in addition to the removal of t-
score of course, yielded best overall results. As a
consequence, all remaining test runs were based on
this feature set. In separate test runs with the SMO
classifier, I finally confirmed that the optimality of
this feature set was not just an artifact of the classi-
fier, but that it generalises to SVMs as well.
3.3 Trade-offs
Since our main aim in relational noun mining is
the improvement of the accuracy of our grammar?s
lexicon, and since the quickest improvement are
expected for highly frequent noun-preposition bi-
grams, I tested whether I could bring the recall of our
classifiers up, at the expense of moderate losses in
precision. For this evaluation, I used again our best-
performing classifier (NBTree), as well as SMO,
which had the highest head-room in terms of preci-
sion, while already providing satisfactory recall. To
this end, I manipulated the classifier?s cost matrix
during training and testing, gradually increasing the
costs for false negatives compared to false positives.
The results of this evaluation are given in Figure
3. First, we obtained a new optimal f-measure for
the SMO classifier: at a cost factor of 2.1 for false
negatives, the f-measure peaks at 69.7, with a recall
of 75.1% and precision still acceptable (65.1%). At
this level, we still save more than two thirds of the
annotation effort.
By way of penalising false negatives 6 times more
than false positives, the suppport vector machine
was able to detect over 90% of all relational nouns,
at a precision of 50%. At these levels, we can still
save more than half of the entire annotation effort.
Going further down the Zipf distribution, we ex-
pect the savings in terms of annotation effort to go
further up, since our bigram frequency ranking en-
sures that relational nouns are overrepresented at the
top of the list, a rate that will gradually go down.
Finally, including false positives in the data to
be annotated will also ensure that we always have
enough positive and negative training data for learn-
ing a classifier on an extended data set.
3.4 Outlook
Although results are already useful at this point, I
hope to further improve precision and recall rates
by means of additional features. Evaluating the
NBTree classifier on the training data, we observe
an F-measure of only 74.7%, which suggests that
the current set of features models the training data
still quite imperfectly. Thus, one needs to incorpo-
rate further independent evidence in order to predict
relation nouns more reliably. Owing to the seman-
tic nature of the relational vs. non-relational dis-
tinction one type of additional evidence could come
from multilingual resources: as a first step, I en-
visage incorporating the classification of nouns in
the English Resource Grammar (ERG; (Copestake
and Flickinger, 2000)) as prior information regard-
ing relational status. In a second step I shall explore
whether one can exploit information from parallel
corpora, using in particular item-specific divergence
of preposition choice to detect whether we are deal-
ing with a contentful or rather a functional prepo-
sition.3 The intuition behind using cross-linguistic
evidence to try and boost the performance of the
learner is based on the observation that predicate ar-
gument structure in closely related languages such
as English and German tends to be highly similar,
with differences mostly located in syntactic proper-
3I expect that arbitrary divergence in the choice of preposi-
tion provides an indicator of grammaticalisation.
71
0 2 4 6 8 10 12 14 16
40
50
60
70
80
90
100
PrecisionRecallF-measurePrecisionRecallF-measure
Figure 3: Effect of trading precision for recall (NBTree: white; SMO: black)
ties such as selection for case or choice of preposi-
tion. As a consequence, I do not expect to be able to
predict the actual form of the German preposition,
but rather gain additional evidence as to whether a
given noun has some relational use at all or not.
The second type of information that I plan to use
more systematically in the future is morphological
and lexical relatedness which is only approximated
at present by the noun sufix and noun prefix fea-
tures which hint at the derived (deverbal) nature
of the noun under discussion. In addition to these
brute-force features, I plan to incorporate the HPSG
grammar?s verb subcategorisation lexicon, pairing
nouns and verbs by means of minimum edit dis-
tance.4 In essence, we hope to provide a more
general approach to lexical relatedness between re-
lational nouns and the non-unary verbal predicates
they derive from: in the current feature set, this was
only suboptimally approximated by the use of noun
suffix and prefix features, resulting in most nouns
being mapped to the unpredictive class NONE.5
Finally, I plan to apply the current approach to
the extraction of nouns taking propositional comple-
ments. Given the comparative ease of that task com-
pared to the extraction of PP-taking nouns, I shall in-
vestigate whether we can exploit the fact that many
4Being aware of the fact that lexical derivation may give rise
to arbitrary changes in syntactic subcategorisation, I minimally
expect to gather evidence regarding the arity of the derived noun
predicate. To what extent actual selectional properties as to the
shape of the functional preposition are maintained by deriva-
tional processes remains a matter of empirical research.
5The inclusion of noun prefixes, which are actually verb pre-
fixes, is inherently limited to mimick lexical relatedness to pre-
fix verbs.
relational nouns taking propositional complements
(e.g., der Glaube, da? ... ?the belief that?) also take
PP-complements (der Glaube an ?the belief in?) in
order to further improve our present classifier. In a
similar vein, I shall experiment whether it is possible
to extrapolate from relational nouns taking von-PPs
to genitive complements.
4 Conclusion
In this paper I have suggested to treat the task of
mining relational nouns in German as a MWE ex-
traction problem. Based on the first 4333 hand-
annotated items of a best-list ranked by bigram fre-
quencies, several classifiers have been trained in or-
der to determine which learner and which (combina-
tion of) association measures performed best for the
task.
Testing different classifiers and different metrics,
we found that optimal results were obtained us-
ing a support vector machine (Platt, 1998), includ-
ing Mutual Information (MI), its squared variant
(MI2), and Likelihood Ratios (LR) as association
measures, together with information about the iden-
tity of the preposition and the noun?s prefix and suf-
fix. The second best classifier, a hybrid decision tree
with Naive Bayes classifiers at the leaves produced
highly competitive results. T-scores, while being a
good predictor on its own, however, led to a slight
decrease in performance, when a full feature set was
used. Likewise, performance suffered when Associ-
ation Strength (Smadja, 1993) was included. Overall
performance of the best individual classifier figured
at an F-score of 69.7.
72
References
Marco Baroni and Adam Kilgariff. 2006. Large
linguistically-processed web corpora for multiple lan-
guages. In Proceedings of EACL 2006.
Leo Breiman. 1996. Bagging predictors. Machine
Learning, 24(2):123?140.
Kostadin Cholakov, Valia Kordoni, and Yi Zhang. 2008.
Towards domain-independent deep linguistic process-
ing: Ensuring portability and re-usability of lexicalised
grammars. In Coling 2008: Proceedings of the work-
shop on Grammar Engineering Across Frameworks,
pages 57?64, Manchester, England, August. Coling
2008 Organizing Committee.
Kenneth Church and Patrick Hanks. 1990. Word asso-
ciation norms, mutual information, and lexicography.
Computational Linguistics, 16(1):22?29.
Kenneth Church and Robert Mercer. 1993. Introduction
to the special issue on computational linguistics using
large corpora. Computational Linguistics, 19:1?24.
Ann Copestake and Dan Flickinger. 2000. An open-
source grammar development environment and broad-
coverage English grammar using HPSG. In Proceed-
ings of the Second conference on Language Resources
and Evaluation (LREC-2000), Athens.
Berthold Crysmann. 2003. On the efficient implemen-
tation of German verb placement in HPSG. In Pro-
ceedings of RANLP 2003, pages 112?116, Borovets,
Bulgaria.
Berthold Crysmann. 2005. Relative clause extraposition
in German: An efficient and portable implementation.
Research on Language and Computation, 3(1):61?82.
Berthold Crysmann. to appear. On the locality of com-
plement clause and relative clause extraposition. In
Gert Webelhuth, Manfred Sailer, and Heike Walker,
editors, Rightward Movement in a Comparative Per-
spective. John Benjamins, Amsterdam.
Be?atrice Daille. 1994. Approche mixte pour l?extraction
automatique de terminologie : statistique lexicale et
filtres linguistiques. Ph.D. thesis, Universite? Paris 7.
Ted Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Linguis-
tics, 19:61?74.
Stefan Evert and Brigitte Krenn. 2001. Methods for the
qualitative evaluation of lexical association measures.
In Proceedings of the 39th Annual Meeting of the
Association for Computational Linguistics, Toulouse,
France, pages 188?195.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: an update.
SIGKDD Explorations, 11(1):10?18.
Tibor Kiss. 2005. Semantic constraints on relative clause
extraposition. Natural Language and Linguistic The-
ory, 23:281?334.
Ron Kohavi. 1996. Scaling up the accuracy of naive-
bayes classifiers: A decision-tree hybrid. In Sec-
ond International Conference on Knowledge Discov-
ery and Data Mining, pages 202?207.
Brigitte Krenn and Stefan Evert. 2001. Can we do better
than frequency? a case study on extracting PP-verb
collocations. In Proceedings of the ACL Workshop on
Collocations, Toulouse, France, pages 39?46.
Brigitte Krenn. 2000. The Usual Suspects: Data-
oriented Models for the Identification and Representa-
tion of Lexical Collocations. Ph.D. thesis, Universita?t
des Saarlandes.
Christopher Manning and Hinrich Schu?tze. 1999. Foun-
dations of Statistical Natural Language Processing.
MIT Press.
A. Meyers, R. Reeves, C. Macleod, R. Szekely, V. Zielin-
ska, B. Young, and R. Grishman. 2004. The nombank
project: An interim report. In A. Meyers, editor, HLT-
NAACL 2004 Workshop: Frontiers in Corpus Annota-
tion, pages 24?31, Boston, Massachusetts, USA, May
2 - May 7. Association for Computational Linguistics.
Stefan Mu?ller and Walter Kasper. 2000. HPSG analy-
sis of German. In Wolfgang Wahlster, editor, Verb-
mobil: Foundations of Speech-to-Speech Translation,
pages 238?253. Springer, Berlin.
Pavel Pecina. 2008. A machine learning approach to
multiword expression extraction. In Proceedings of
the LREC Workshop Towards a Shared Task for Multi-
word Expressions (MWE 2008), pages 54?61.
J. Platt. 1998. Fast training of support vector ma-
chines using sequential minimal optimization. In
B. Schoelkopf, C. Burges, and A. Smola, editors, Ad-
vances in Kernel Methods - Support Vector Learning.
MIT Press.
Helmut Schmid. 1995. Improvements in part-of-speech
tagging with an application to German. In Proceed-
ings of the ACL SIGDAT-Workshop, March.
Frank Smadja. 1993. Retrieving collocations from text:
Xtract. Computational Linguistics, 19(1):143?177.
Hans Uszkoreit, Thorsten Brants, Denys Duchier,
Brigitte Krenn, Lars Konieczny, Stephan Oepen, and
Wojciech Skut. 1998. Studien zur performanzori-
entierten Linguistik. Aspekte der Relativsatzextrapo-
sition im Deutschen. Kognitionswissenschaft, 7:129?
133.
Gertjan van Noord. 2004. Error mining for wide cover-
age grammar engineering. In Proceedings of the 42nd
Meeting of the Association for Computational Linguis-
tics (ACL?04), Barcelona, Spain, pages 446?453.
73
