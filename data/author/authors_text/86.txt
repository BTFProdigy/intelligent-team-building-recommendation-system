Corpus-based Discourse Understanding in Spoken Dialogue Systems
Ryuichiro Higashinaka and Mikio Nakano and Kiyoaki Aikawa?
NTT Communication Science Laboratories
Nippon Telegraph and Telephone Corporation
3-1 Morinosato Wakamiya
Atsugi, Kanagawa 243-0198, Japan
{rh,nakano}@atom.brl.ntt.co.jp, aik@idea.brl.ntt.co.jp
Abstract
This paper concerns the discourse under-
standing process in spoken dialogue sys-
tems. This process enables the system to
understand user utterances based on the
context of a dialogue. Since multiple can-
didates for the understanding result can
be obtained for a user utterance due to
the ambiguity of speech understanding, it
is not appropriate to decide on a single
understanding result after each user ut-
terance. By holding multiple candidates
for understanding results and resolving the
ambiguity as the dialogue progresses, the
discourse understanding accuracy can be
improved. This paper proposes a method
for resolving this ambiguity based on sta-
tistical information obtained from dia-
logue corpora. Unlike conventional meth-
ods that use hand-crafted rules, the pro-
posed method enables easy design of the
discourse understanding process. Experi-
ment results have shown that a system that
exploits the proposed method performs
sufficiently and that holding multiple can-
didates for understanding results is effec-
tive.
?Currently with the School of Media Science, Tokyo Uni-
versity of Technology, 1404-1 Katakuracho, Hachioji, Tokyo
192-0982, Japan.
1 Introduction
For spoken dialogue systems to correctly understand
user intentions to achieve certain tasks while con-
versing with users, the dialogue state has to be ap-
propriately updated (Zue and Glass, 2000) after each
user utterance. Here, a dialogue state means all
the information that the system possesses concern-
ing the dialogue. For example, a dialogue state in-
cludes intention recognition results after each user
utterance, the user utterance history, the system ut-
terance history, and so forth. Obtaining the user in-
tention and the content of an utterance using only the
single utterance is called speech understanding, and
updating the dialogue state based on both the previ-
ous utterance and the current dialogue state is called
discourse understanding. In general, the result of
speech understanding can be ambiguous, because it
is currently difficult to uniquely decide on a single
speech recognition result out of the many recogni-
tion candidates available, and because the syntac-
tic and semantic analysis process normally produce
multiple hypotheses. The system, however, has to be
able to uniquely determine the understanding result
after each user utterance in order to respond to the
user. The system therefore must be able to choose
the appropriate speech understanding result by re-
ferring to the dialogue state.
Most conventional systems uniquely determine
the result of the discourse understanding, i.e., the
dialogue state, after each user utterance. However,
multiple dialogue states are created from the current
dialogue state and the speech understanding results
corresponding to the user utterance, which leads to
ambiguity. When this ambiguity is ignored, the dis-
course understanding accuracy is likely to decrease.
Our idea for improving the discourse understanding
accuracy is to make the system hold multiple dia-
logue states after a user utterance and use succeed-
ing utterances to resolve the ambiguity among di-
alogue states. Although the concept of combining
multiple dialogue states and speech understanding
results has already been reported (Miyazaki et al,
2002), they use intuition-based hand-crafted rules
for the disambiguation of dialogue states, which are
costly and sometimes lead to inaccuracy. To resolve
the ambiguity of dialogue states and reduce the cost
of rule making, we propose using statistical infor-
mation obtained from dialogue corpora, which com-
prise dialogues conducted between the system and
users.
The next section briefly illustrates the basic ar-
chitecture of a spoken dialogue system. Section 3
describes the problem to be solved in detail. Then
after introducing related work, our approach is de-
scribed with an example dialogue. After that, we
describe the experiments we performed to verify our
approach, and discuss the results. The last section
summarizes the main points and mentions future
work.
2 Discourse Understanding
Here, we describe the basic architecture of a spoken
dialogue system (Figure 1). When receiving a user
utterance, the system behaves as follows.
1. The speech recognizer receives a user utterance
and outputs a speech recognition hypothesis.
2. The language understanding component re-
ceives the speech recognition hypothesis. The
syntactic and semantic analysis is performed
to convert it into a form called a dialogue
act. Table 1 shows an example of a dialogue
act. In the example, ?refer-start-and-end-time?
is called the dialogue act type, which briefly
describes the meaning of a dialogue act, and
?start=14:00? and ?end=15:00? are add-on in-
formation.1
1In general, a dialogue act corresponds to one sentence.
However, in dialogues where user utterances are unrestricted,
smaller units, such as phrases, can be regarded as dialogue acts.
Speech
Recognizer
Language
Understanding
Component
Discourse
Understanding
Component
Dialogue
State
Dialogue
Manager
Speech
Synthesizer
Update
Update
Refer
Refer
Speech Recognition
Hypothesis Dialogue Act
Figure 1: Architecture of a spoken dialogue system.
3. The discourse understanding component re-
ceives the dialogue act, refers to the current di-
alogue state, and updates the dialogue state.
4. The dialogue manager receives the current dia-
logue state, decides the next utterance, and out-
puts the next words to speak. The dialogue state
is updated at the same time so that it contains
the content of system utterances.
5. The speech synthesizer receives the output of
the dialogue manager and responds to the user
by speech.
This paper deals with the discourse understand-
ing component. Since we are resolving the ambi-
guity of speech understanding from the discourse
point of view and not within the speech understand-
ing candidates, we assume that a dialogue state is
uniquely determined given a dialogue state and the
next dialogue act, which means that a dialogue act
is a command to change a dialogue state. We also
assume that the relationship between the dialogue
act and the way to update the dialogue state can be
easily described without expertise in dialogue sys-
tem research. We found that these assumptions are
reasonable from our experience in system develop-
ment. Note also that this paper does not separately
deal with reference resolution; we assume that it is
performed by a command. A speech understanding
result is considered to be equal to a dialogue act in
this article.
In this paper, we consider frames as representa-
tions of dialogue states. To represent dialogue states,
plans have often been used (Allen and Perrault,
1980; Carberry, 1990). Traditionally, plan-based
discourse understanding methods have been imple-
mented mostly in keyboard-based dialogue systems,
User Utterance ?from two p.m. to three p.m.?
Dialogue Act [act-type=refer-start-and-end-
time, start=14:00, end=15:00]
Table 1: A user utterance and the corresponding di-
alogue act.
although there are some recent attempts to apply
them to spoken dialogue systems as well (Allen et
al., 2001; Rich et al, 2001); however, considering
the current performance of speech recognizers and
the limitations in task domains, we believe frame-
based discourse understanding and dialogue man-
agement are sufficient (Chu-Carroll, 2000; Seneff,
2002; Bobrow et al, 1977).
3 Problem
Most conventional spoken dialogue systems
uniquely determine the dialogue state after a user
utterance. Normally, however, there are multiple
candidates for the result of speech understanding,
which leads to the creation of multiple dialogue
state candidates. We believe that there are cases
where it is better to hold more than one dialogue
state and resolve the ambiguity as the dialogue
progresses rather than to decide on a single dialogue
state after each user utterance.
As an example, consider a piece of dialogue in
which the user utterance ?from two p.m.? has been
misrecognized as ?uh two p.m.? (Figure 2). Fig-
ure 3 shows the description of the example dia-
logue in detail including the system?s inner states,
such as dialogue acts corresponding to the speech
recognition hypotheses2 and the intention recogni-
tion results.3 After receiving the speech recogni-
tion hypothesis ?uh two p.m.,? the system cannot
tell whether the user utterance corresponds to a dia-
logue act specifying the start time or the end time
(da1,da2). Therefore, the system tries to obtain
further information about the time. In this case,
the system utters a backchannel to prompt the next
user utterance to resolve the ambiguity from the dis-
course.4 At this stage, the system holds two dialogue
2In this example, for convenience of explanation, the n-best
speech recognition input is not considered.
3An intention recognition result is one of the elements of a
dialogue state.
4A yes/no question may be an appropriate choice as well.
 
S1 : what time would you like to reserve a
meeting room?
U1 : from two p.m. [uh two p.m.]
S2 : uh-huh
U2 : to three p.m. [to three p.m.]
S3 : from two p.m. to three p.m.?
U3 : yes [yes]
 
Figure 2: Example dialogue.
(S means a system utterance and U a user utterance.
Recognition results are enclosed in square brackets.)
states having different intention recognition results
(ds1,ds2). The next utterance, ?to three p.m.,? is
one that uniquely corresponds to a dialogue act spec-
ifying the end time (da3), and thus updates the two
current dialogue states. As a result, two dialogue
states still remain (ds3,ds4). If the system can tell
that the previous dialogue act was about the start
time at this moment, it can understand the user in-
tention correctly. The correct understanding result,
ds3, is derived from the combination of ds1 and
da3, where ds1 is induced by ds0 and da1. As
shown here, holding multiple understanding results
can be better than just deciding on the best speech
understanding hypothesis and discarding other pos-
sibilities.
In this paper, we consider a discourse understand-
ing component that deals with multiple dialogue
states. Such a component must choose the best com-
bination of a dialogue state and a dialogue act out of
all possibilities. An appropriate scoring method for
the dialogue states is therefore required.
4 Related Work
Nakano et al (1999) proposed a method that holds
multiple dialogue states ordered by priority to deal
with the problem that some utterances convey mean-
ing over several speech intervals and that the under-
standing result cannot be determined at each inter-
val end. Miyazaki et al (2002) proposed a method
combining Nakano et al?s (1999) method and n-best
recognition hypotheses, and reported improvement
in discourse understanding accuracy. They used a
metric similar to the concept error rate for the evalu-
[System utterance (S1)]
?What time would you like to reserve a meeting
room??
[Dialogue act] [act-type=ask-time]
[Intention recognition result candidates]
1. [room=nil, start=nil, end=nil] (ds0)
?
[User utterance (U1)]
?From two p.m.?
[Speech recognition hypotheses]
1. ?uh two p.m.?
[Dialogue act candidates]
1. [act-type=refer-start-time,time=14:00] (da1)
2. [act-type=refer-end-time,time=15:00] (da2)
[Intention recognition result candidates]
1. [room=nil, start=14:00, end=nil]
(ds1, induced from ds0 and da1)
2. [room=nil, start=nil, end=14:00]
(ds2, induced from ds0 and da2)
?
[System utterance (S2)] ?uh-huh?
[Dialogue act] [act-type=backchannel]
?
[User utterance (U2)]
?To three p.m.?
[Speech recognition hypotheses]
1. ?to three p.m.?
[Dialogue act candidates]
1. [act-type=refer-end-time, time=15:00] (da3)
[Intention recognition result candidates]
1. [room=nil, start=14:00, end=15:00]
(ds3, induced from ds1 and da3)
2. [room=nil, start=nil, end=15:00]
(ds4, induced from ds2 and da3)
?
[System utterance (S3)]
?from two p.m. to three p.m.??
[Dialogue act]
[act-type=confirm-time,start=14:00, end=15:00]
?
[User utterance (U3)] ?yes?
[Speech recognition hypotheses]
1. ?yes?
[Dialogue act candidates]
1. [act-type=acknowledge]
[Intention recognition result candidates]
1. [room=nil, start=14:00, end=15:00]
2. [room=nil, start=nil, end=15:00]
Figure 3: Detailed description of the understanding
of the example dialogue.
ation of discourse accuracy, comparing reference di-
alogue states with hypothesis dialogue states. Both
these methods employ hand-crafted rules to score
the dialogue states to decide the best dialogue state.
Creating such rules requires expert knowledge, and
is also time consuming.
There are approaches that propose statistically es-
timating the dialogue act type from several previous
dialogue act types using N-gram probability (Nagata
and Morimoto, 1994; Reithinger and Maier, 1995).
Although their approaches can be used for disam-
biguating user utterance using discourse informa-
tion, they do not consider holding multiple dialogue
states.
In the context of plan-based utterance understand-
ing (Allen and Perrault, 1980; Carberry, 1990),
when there is ambiguity in the understanding re-
sult of a user utterance, an interpretation best suited
to the estimated plan should be selected. In ad-
dition, the system must choose the most plausible
plans from multiple possible candidates. Although
we do not adopt plan-based representation of dia-
logue states as noted before, this problem is close to
what we are dealing with. Unfortunately, however,
it seems that no systematic ways to score the candi-
dates for disambiguation have been proposed.
5 Approach
The discourse understanding method that we pro-
pose takes the same approach as Miyazaki et al
(2002). However, our method is different in that,
when ordering the multiple dialogue states, the sta-
tistical information derived from the dialogue cor-
pora is used. We propose using two kinds of statisti-
cal information:
1. the probability of a dialogue act type sequence,
and
2. the collocation probability of a dialogue state
and the next dialogue act.
5.1 Statistical Information
Probability of a dialogue act type sequence
Based on the same idea as Nagata and Morimoto
(1994) and Reithinger and Maier (1995), we use the
probability of a dialogue act type sequence, namely,
the N-gram probability of dialogue act types. Sys-
tem utterances and the transcription of user utter-
ances are both converted to dialogue acts using a di-
alogue act conversion parser, then the N-gram prob-
ability of the dialogue act types is calculated.
# explanation
1. whether slots asked previously by the system
are changed
2. whether slots being confirmed are changed
3. whether slots already confirmed are changed
4. whether the dialogue act fills slots that do not
have values
5. whether the dialogue act tries changing slots
that have values
6. when 5 is true, whether slot values are not
changed as a result
7. whether the dialogue act updates the initial
dialogue state 5
Table 2: Seven binary attributes to classify collo-
cation patterns of a dialogue state and the next dia-
logue act.
Collocation probability of a dialogue state and
the next dialogue act From the dialogue corpora,
dialogue states and the succeeding user utterances
are extracted. Then, pairs comprising a dialogue
state and a dialogue act are created after convert-
ing user utterances into dialogue acts. Contrary to
the probability of sequential patterns of dialogue act
types that represents a brief flow of a dialogue, this
collocation information expresses a local detailed
flow of a dialogue, such as dialogue state changes
caused by the dialogue act. The simple bigram of
dialogue states and dialogue acts is not sufficient
due to the complexity of the data that a dialogue
state possesses, which can cause data sparseness
problems. Therefore, we classify the ways that di-
alogue states are changed by dialogue acts into 64
classes characterized by seven binary attributes (Ta-
ble 2) and compute the occurrence probability of
each class in the corpora. We assume that the un-
derstanding result of the user intention contained in
a dialogue state is expressed as a frame, which is
common in many systems (Bobrow et al, 1977). A
frame is a bundle of slots that consist of attribute-
value pairs concerning a certain domain.
5The first user utterance should be treated separately, be-
cause the system?s initial utterance is an open question leading
to an unrestricted utterance of a user.
5.2 Scoring of Dialogue Acts
Each speech recognition hypothesis is converted to
a dialogue act or acts. When there are several di-
alogue acts corresponding to a speech recognition
hypothesis, all possible dialogue acts are created as
in Figure 3, where the utterance ?uh two p.m.? pro-
duces two dialogue act candidates. Each dialogue
act is given a score using its linguistic and acous-
tic scores. The linguistic score represents the gram-
matical adequacy of a speech recognition hypothe-
sis from which the dialogue act originates, and the
acoustic score the acoustic reliability of a dialogue
act. Sometimes, there is a case that a dialogue act
has such a low acoustic or linguistic score and that
it is better to ignore the act. We therefore create a
dialogue act called null act, and add this null act to
our list of dialogue acts. A null act is a dialogue act
that does not change the dialogue state at all.
5.3 Scoring of Dialogue States
Since the dialogue state is uniquely updated by a di-
alogue act, if there are l dialogue acts derived from
speech understanding and m dialogue states, m ? l
new dialogue states are created. In this case, we de-
fine the score of a dialogue state S
t+1
as
S
t+1
= S
t
+ ? ? s
act
+ ? ? s
ngram
+ ? ? s
col
where S
t
is the score of a dialogue state just before
the update, s
act
the score of a dialogue act, s
ngram
the score concerning the probability of a dialogue
act type sequence, s
col
the score concerning the col-
location probability of dialogue states and dialogue
acts, and ?, ?, and ? are the weighting factors.
5.4 Ordering of Dialogue States
The newly created dialogue states are ordered based
on the score. The dialogue state that has the best
score is regarded as the most probable one, and the
system responds to the user by referring to it. The
maximum number of dialogue states is needed in
order to drop low-score dialogue states and thereby
perform the operation in real time. This dropping
process can be considered as a beam search in view
of the entire discourse process, thus we name the
maximum number of dialogue states the dialogue
state beam width.
6 Experiment
6.1 Extracting Statistical Information from Di-
alogue Corpus
Dialogue Corpus We analyzed a corpus of dia-
logues between naive users and a Japanese spoken
dialogue system, which were collected in acousti-
cally insulated booths. The task domain was meet-
ing room reservation. Subjects were instructed to
reserve a meeting room on a certain date from a cer-
tain time to a certain time. As a speech recognition
engine, Julius3.1p1 (Lee et al, 2001) was used with
its attached acoustic model. For the language model,
we used a trigram trained from randomly generated
texts of acceptable phrases. For system response,
NTT?s speech synthesis engine FinalFluet (Takano
et al, 2001) was used. The system had a vocabulary
of 168 words, each registered with a category and
a semantic feature in its lexicon. The system used
hand-crafted rules for discourse understanding. The
corpus consists of 240 dialogues from 15 subjects
(10 males and 5 females), each one performing 16
dialogues. Dialogues that took more than three min-
utes were regarded as failures. The task completion
rate was 78.3% (188/240).
Extraction of Statistical Information From the
transcription, we created a trigram of dialogue act
types using the CMU-Cambridge Toolkit (Clarkson
and Rosenfeld, 1997). Figure 3 shows an example
of the trigram information starting from {refer-start-
time backchannel}. The bigram information used
for smoothing is also shown. The collocation proba-
bility was obtained from the recorded dialogue states
and the transcription following them. Out of 64 pos-
sible patterns, we found 17 in the corpus as shown in
Figure 4. Taking the case of the example dialogue in
Figure 3, it happened that the sequence {refer-start-
time backchannel refer-end-time} does not appear in
the corpus; thus, the probability is calculated based
on the bigram probability using the backoff weight,
which is 0.006. The trigram probability for {refer-
end-time backchannel refer-end-time} is 0.031.
The collocation probability of the sequence ds1
+ da3 ? ds3 fits collocation pattern 12, where a
slot having no value was changed. The sequence
ds2 + da3 ? ds4 fits collocation pattern 17, where
a slot having a value was changed to have a differ-
ent value. The probabilities were 0.155 and 0.009,
dialogue act type sequence (trigram) probability
score
refer-start-time backchannel backchannel -1.0852
refer-start-time backchannel ask-date -2.0445
refer-start-time backchannel ask-start-time -0.8633
refer-start-time backchannel request -2.0445
refer-start-time backchannel refer-day -1.7790
refer-start-time backchannel refer-month -0.4009
refer-start-time backchannel refer-room -0.8633
refer-start-time backchannel refer-start-time -0.7172
dialogue act type sequence
(bigram)
backoff
weight
probability
score
refer-start-time backchannel -1.1337 -0.7928
refer-end-time backchannel 0.4570 -0.6450
backchannel refer-end-time -0.5567 -1.0716
Table 3: An example of bigram and trigram of dia-
logue act types with their probability score in com-
mon logarithm.
collocation occurrence
# pattern probability
1. 0 1 1 1 0 0 1 0.001
2. 0 1 1 0 0 1 0 0.053
3. 0 0 0 0 0 0 0 0.273
4. 1 0 0 0 1 0 0 0.001
5. 1 0 1 1 0 0 0 0.005
6. 0 0 1 1 0 0 0 0.036
7. 0 0 0 0 1 0 0 0.047
8. 0 1 1 0 1 0 0 0.041
9. 0 0 1 1 0 0 1 0.010
10. 0 0 1 0 0 1 0 0.016
11. 0 0 0 0 0 0 1 0.064
12. 0 0 0 1 0 0 0 0.155
13. 1 0 0 1 0 0 0 0.043
14. 0 0 1 0 1 0 0 0.061
15. 1 0 0 1 0 0 1 0.001
16. 0 0 0 1 0 0 1 0.186
17. 0 0 0 0 0 1 0 0.009
Table 4: The 17 collocation patterns and their oc-
currence probabilities. See Figure 2 for the detail
of binary attributes. Attributes 1-7 are ordered from
left to right.
respectively. By the simple adding of the two proba-
bilities in common logarithms in each case, ds3 has
the probability score -3.015 and ds4 -3.549, sug-
gesting that the sequence ds3 is the most probable
discourse understanding result after U2.
6.2 Verification of our approach
To verify the effectiveness of the proposed ap-
proach, we built a Japanese spoken dialogue system
in the meeting reservation domain that employs the
proposed discourse understanding method and per-
formed dialogue experiments.
The speech recognition engine was Julius3.3p1
(Lee et al, 2001) with its attached acoustic models.
For the language model, we made a trigram from
the transcription obtained from the corpora. The
system had a vocabulary of 243. The recognition
engine outputs 5-best recognition hypotheses. This
time, values for s
act
, s
ngram
, s
col
are the logarithm
of the inverse number of n-best ranks,6 the log like-
lihood of dialogue act type trigram probability, and
the common logarithm of the collocation probabil-
ity, respectively. For the experiment, weighting fac-
tors are all set to one (? = ? = ? = 1). The di-
alogue state beam width was 15. We collected 256
dialogues from 16 subjects (7 males and 9 females).
The speech recognition accuracy (word error rate)
was 65.18%. Dialogues that took more than five
minutes were regarded as failures. The task com-
pletion rate was 88.3% (226/256).7
From all user speech intervals, the number of
times that dialogue states below second place be-
came first place was 120 (7.68%), showing a relative
frequency of shuffling within the dialogue states.
6.3 Effectiveness of Holding Multiple Dialogue
States
The main reason that we developed the proposed
corpus-based discourse understanding method was
that it is difficult to manually create rules to deal
with multiple dialogue states. It is yet to be exam-
ined, however, whether holding multiple dialogue
states is really effective for accurate discourse un-
derstanding.
To verify that holding multiple dialogue states is
effective, we fixed the speech recognizer?s output to
1-best, and studied the system performance changes
when the dialogue state beam width was changed
from 1 to 30. When the dialogue state beam width is
too large, the computational cost becomes high and
the system cannot respond in real time. We therefore
selected 30 for empirical reasons.
The task domain and other settings were the same
6In this experiment, only the acoustic score of a dialogue act
was considered.
7It should be noted that due to the creation of an enormous
number of dialogue states in discourse understanding, the pro-
posed system takes a few seconds to respond after the user in-
put.
as in the previous experiment except for the dialogue
state beam width changes. We collected 448 dia-
logues from 28 subjects (4 males and 24 females),
each one performing 16 dialogues. Each subject was
instructed to reserve the same meeting room twice,
once with the 1-beam-width system and again with
30-beam-width system. The order of what room to
reserve and what system to use was randomized.
The speech recognition accuracy was 69.17%. Di-
alogues that took more than five minutes were re-
garded as failures. The task completion rates for the
1-beam-width system and the 30-beam-width sys-
tem were 88.3% and 91.0%, and the average task
completion times were 107.66 seconds and 95.86
seconds, respectively. A statistical hypothesis test
showed that times taken to carry out a task with the
30-beam-width system are significantly shorter than
those with the 1-beam-width system (Z = ?2.01,
p < .05). In this test, we used a kind of censored
mean computed by taking the mean of the times
only for subjects that completed the tasks with both
systems. The population distribution was estimated
by the bootstrap method (Cohen, 1995). It may be
possible to evaluate the discourse understanding by
comparing the best dialogue state with the reference
dialogue state, and calculate a metric such as the
CER (concept error rate) as Miyazaki et al (2002)
do; however it is not clear whether the discourse
understanding can be evaluated this way, since it is
not certain whether the CER correlates closely with
the system?s performance (Higashinaka et al, 2002).
Therefore, this time, we used the task completion
time and the task completion rate for comparison.
7 Discussion
Cost of creating the discourse understanding
component The best task completion rate in the ex-
periments was 91.0% (the case of 1-best recognition
input and a 30 dialogue state beam width). This high
rate suggests that the proposed approach is effective
in reducing the cost of creating the discourse un-
derstanding component in that no hand-crafted rules
are necessary. For statistical discourse understand-
ing, an initial system, e.g., a system that employs
the proposed approach with only s
act
for scoring the
dialogue states, is needed in order to create the di-
alogue corpus; however, once it has been made, the
creation of the discourse understanding component
requires no expert knowledge.
Effectiveness of holding multiple dialogue states
The result of the examination of dialogue state beam
width changes suggests that holding multiple dia-
logue states shortens the task completion time. As
far as task-oriented spoken dialogue systems are
concerned, holding multiple dialogue states con-
tributes to the accuracy of discourse understanding.
8 Summary and Future Work
We proposed a new discourse understanding method
that orders multiple dialogue states created from
multiple dialogue states and the succeeding speech
understanding results based on statistical informa-
tion obtained from dialogue corpora. The results of
the experiments show that our approach is effective
in reducing the cost of creating the discourse under-
standing component, and the advantage of keeping
multiple dialogue states was also shown.
There still remain several issues that we need to
explore. These include the use of statistical informa-
tion other than the probability of a dialogue act type
sequence and the collocation probability of dialogue
states and dialogue acts, the optimization of weight-
ing factors ?, ?, ?, other default parameters that we
used in the experiments, and more experiments in
larger domains. Despite these issues, the present re-
sults have shown that our approach is promising.
Acknowledgements
We thank Dr. Hiroshi Murase and all members of the
Dialogue Understanding Research Group for useful
discussions. Thanks also go to the anonymous re-
viewers for their helpful comments.
References
James F. Allen and C. Raymond Perrault. 1980. Analyz-
ing intention in utterances. Artif. Intel., 15:143?178.
James Allen, George Ferguson, and Amanda Stent. 2001.
An architecture for more realistic conversational sys-
tems. In Proc. IUI, pages 1?8.
Daniel G. Bobrow, Ronald M. Kaplan, Martin Kay, Don-
ald A. Norman, Henry Thompson, and Terry Wino-
grad. 1977. GUS, a frame driven dialog system. Artif.
Intel., 8:155?173.
Sandra Carberry. 1990. Plan Recognition in Natural
Language Dialogue. MIT Press, Cambridge, Mass.
Junnifer Chu-Carroll. 2000. MIMIC: An adaptive
mixed initiative spoken dialogue system for informa-
tion queries. In Proc. 6th Applied NLP, pages 97?104.
P.R. Clarkson and R. Rosenfeld. 1997. Statistical lan-
guagemodeling using the CMU-Cambridge toolkit. In
Proc. Eurospeech, pages 2707?2710.
Paul R. Cohen. 1995. Empirical Methods for Artificial
Intelligence. MIT Press.
Ryuichiro Higashinaka, Noboru Miyazaki, Mikio
Nakano, and Kiyoaki Aikawa. 2002. A method
for evaluating incremental utterance understanding
in spoken dialogue systems. In Proc. ICSLP, pages
829?832.
Akinobu Lee, Tatsuya Kawahara, and Kiyohiro Shikano.
2001. Julius ? an open source real-time large vocab-
ulary recognition engine. In Proc. Eurospeech, pages
1691?1694.
Noboru Miyazaki, Mikio Nakano, and Kiyoaki Aikawa.
2002. Robust speech understanding using incremen-
tal understanding with n-best recognition hypothe-
ses. In SIG-SLP-40, Information Processing Society
of Japan., pages 121?126. (in Japanese).
Masaaki Nagata and Tsuyoshi Morimoto. 1994. First
steps toward statistical modeling of dialogue to predict
the speech act type of the next utterance. Speech Com-
munication, 15:193?203.
Mikio Nakano, Noboru Miyazaki, Jun-ichi Hirasawa,
Kohji Dohsaka, and Takeshi Kawabata. 1999. Un-
derstanding unsegmented user utterances in real-time
spoken dialogue systems. In Proc. 37th ACL, pages
200?207.
Norbert Reithinger and Elisabeth Maier. 1995. Utiliz-
ing statistical dialogue act processing in Verbmobil. In
Proc. 33th ACL, pages 116?121.
Charles Rich, Candace Sidner, and Neal Lesh. 2001.
COLLAGEN: Applying collaborative discourse the-
ory. AI Magazine, 22(4):15?25.
Stephanie Seneff. 2002. Response planning and genera-
tion in the MERCURY flight reservation system. Com-
puter Speech and Language, 16(3?4):283?312.
Satoshi Takano, Kimihito Tanaka, Hideyuki Mizuno,
Masanobu Abe, and ShiN?ya Nakajima. 2001. A
Japanese TTS system based on multi-form units and a
speech modification algorithm with harmonics recon-
struction. IEEE Transactions on Speech and Process-
ing, 9(1):3?10.
Victor W. Zue and James R. Glass. 2000. Conversational
interfaces: Advances and challenges. Proceedings of
IEEE, 88(8):1166?1180.
Spoken Dialogue Control Based on a Turn-minimization
Criterion Depending on the Speech Recognition Accuracy
YASUDA Norihito and DOHSAKA Kohji and AIKAWA Kiyoaki
NTT Communication Science Laboratories
3-1 Morinosato-Wakamiya, Atsugi, Kanagawa, 243-0198 Japan
{yasuda, dohsaka}@atom.brl.ntt.co.jp, aik@idea.brl.ntt.co.jp
Abstract
This paper proposes a new dialogue
control method for spoken dialogue
systems. The method configures a
dialogue plan so as to minimize the
estimated number of turns to com-
plete the dialogue. The number of
turns is estimated depending on the
current speech recognition accuracy
and probability distribution of the
true user?s request. The proposed
method reduces the number of turns
to complete the task at almost any
recognition accuracy.
1 Introduction
A spoken dialogue system determines user
requests from user utterances. Spoken di-
alogue systems, however, can?t determine a
user?s request only from an initial utterance,
because there is a limitation to automatic
speech recognition and recognition errors are
unavoidable. Thus, most spoken dialogue sys-
tems confirm a user?s utterance or demand the
information that is lacking in order to deter-
mine user?s request. Such dialogues for con-
firmation or demand between the system and
the user are called ?confirmation dialogues?.
Long confirmation dialogues are annoying, so
more efficient confirmation is desirable. To
measure the efficiency of the dialogue, we use
the number of turns (exchanges), where of
course, the fewer number of turns is better.
In practical applications, the system can
accepts multiple types of user requests like
?making a new appointment?, ?changing a
schedule?, and ?inquiring about a schedule?.
If the user request type is different, the re-
quired information for determining the user
request is also different. Sometimes the user
request type is ambiguous due to recognition
errors, and various types of user requests are
possible. In such a case, it is important for
the system to choose the type of user request
it will confirm at first, since it will be useless
to confirm items that are required for unlikely
type of request.
The recognition accuracy affects the effi-
ciency in other cases. For example, if there
are multiple items to be confirmed, intu-
itively, it seems efficient to confirm all of them
at once. However, the system must include
candidates for all attributes in recognition vo-
cabulary, which cause more recognition er-
rors. Moreover, even though there is only one
misrecognized item in confirmed items, the
user might just say coldly ?No?, and the sys-
tem cannot know that what are correct items.
Several efficient dialogue control methods
have been proposed (Niimi and Kobayashi,
1996; Litman et al, 2000). But there is no
previous works that take into account mul-
tiple types of user requests and recognition
accuracy during confirmation, which changes
what to be confirmed without domain-specific
rules or training.
To prevent needlessly long confirmation di-
alogues even if the system can accepts mul-
tiple types of user request, our method esti-
mates the expected number of turns to a cer-
tain use request type and the approximated
probability distribution of user request types.
The expected number of turns can be derived
from the required vocabulary for confirmation
and base recognition accuracy under certain
vocabulary size.
2 Method
Overview First, we describe about a sys-
tem to which we assume this method will be
applied. The system has belief state which
is represented by the set of attributes, their
values, and the certainty of the values. The
certainty is in [0 .. 1], and the certainty for
the determined value is 1. That is, if the
user replies ?Yes? to the confirmation, the
system changes the certainty for that value to
1. In practice, we can use the score from the
recognition engine as this certainty. The sys-
tem changes the recognition vocabulary ac-
cording to the attributes to be confirmed at
each confirmation. At any given time, the
system either confirms or demands some at-
tribute(s); it doesn?t confirm and demand at
the same time. Any values required in order
to determine the user request are explicitly-
confirmed without exception. Words that are
irrelevant to the present confirmation are ex-
cluded from the recognition vocabulary. The
system knows the base recognition accuracy
under a certain vocabulary size, which is used
to estimate the recognition accuracy.
Our method can be divided roughly into
five parts; the first three parts are used to
obtain the expected number of turns, granting
that the user request type are already known,
the fourth part is used to approximate the
probability distribution of the user request,
and the last part is used to decide the next
action to be taken by the system.
The system needs to know only three sorts
of information: 1) the vocabulary for each
attribute; 2) the meaning constraints among
words like ?If the family name of the person
is Yasuda, then his department must be ac-
counting?; and 3) the required information
for each type of user request like ?To can-
cel an appointment; the day and the time are
required?. No other domain-specific rules or
training are necessary.
Guessing the Recognition Accuracy
Here we consider how to estimate the recogni-
tion accuracy during confirmation from con-
firmation target. Once attributes for confir-
mation are decided, the recognition vocabu-
lary will consist of the words accepted by the
attributes and general words for moving the
dialogue along that are at least necessary to
progress the dialogue such as ?Yes?, ?No?,
etc. We call the recognition accuracy at this
time the ?attribute recognition accuracy?.
We adopt the rule of thumb that the recog-
nition error rate is in proportion to the square
root of vocabulary size (Rosenfeld, 1996; Nak-
agawa and Ida, 1998). Thus, the approxi-
mated attribute recognition accuracy can be
derived from the number of words accepted
by the attributes.
Note that the attribute recognition accu-
racy can?t be estimated beforehand, because
the candidates for some attributes are dynam-
ically change, as a result of the meaning con-
straints among words; if the value of one at-
tribute is fixed, then candidates for other at-
tributes will be limited to values that satisfy
the constraints. Besides, the degree of lim-
itation varies with the values. The relation
between the user?s family name and depart-
ment is such an example.
Turn Estimation to Determine Some
Attributes Next we consider how to esti-
mate the expected number of turns for de-
termining some attributes using the approxi-
mated attribute recognition accuracy.
We assume that the user?s reply to the con-
firmation must contain the intention that cor-
responds to ?Yes? or ?No?, and the inten-
tion must be transmitted to the system with-
out fail. Then, the expected number of turns
to complete confirming for some attributes is
equal to the expected number of turns in the
case that the confirmation is incorrect (i.e.
misrecognized). Therefore, we can derive the
number of expected turns to complete con-
firming Tc and demanding Td for some at-
tributes by the following expression:
Tc =
?
?
t=1
tr(1? r)t?1 = 1
r
Td = Tc + 1 = 1 +
1
r
where r denotes the attribute recognition ac-
curacy for attributes that are to be confirmed.
Turn Estimation to a Certain User Re-
quest Type Here we estimate the expected
number of turns, granting that the type of
user request is already known.
If the user request type is fixed, the re-
quired attributes for that type are also fixed.
By comparing the belief state with these at-
tributes, we can represent the required actions
to determine the user request by a set of pairs
made up of attributes and actions for the at-
tribute (confirmation or demand). Once this
set of pairs is given, we can choose the optimal
plan, because we can estimate the expected
turns of any permutations of any partitions
of this set. The expected number of turns
for this optiomal plan is used as the expected
number of turns for a given user request type.
Probability Distribution of User Re-
quest Types Here, we consider how to es-
timate the relevance between the belief state
and each user request types.
As it is hard to obtain the actual probabil-
ity distribution, we define the degree of rele-
vance between the belief state and each user
request type as an approximation.
Let ai, vi, ci be the i-th attribute, the value
of ai, and the certainty of vi respectively. We
define the relevance Rel(S, Rj) between the
belief state S and the user request type Rj as
for any vi which can be accepted
by Rj:
Rel(S, Rj) =
1
NG
j
? ci
Mv
i
where NR
j
denotes the number of required at-
tributes in user request type Rj, and Mv
i
de-
notes the number of user requests that accept
the value vi.
Choosing the Next Action Even if there
is a highly possible user request type, choos-
ing confirmation plan for it is not always best,
if the expected number of turns for that re-
quest is very large. In such case, confirm-
ing another type of request that is easily con-
firmed and medium possibility may better.
We assume that when the user request type
guessed by the system is not the real user re-
quest type, the number of turns required to
know that the guess is incorrect is equal to
the number of turns when the guess is correct
and finish confirming the contents.
Let pR
i
be the probability of user request
type Ri, and tR
i
be the expected number of
turns to user request type Ri.
From permutations of request types,
our method chooses the optimal order
a(1), a(2), . . . , a(n) such that the expression
pR
a(1)
tR
a(1)
+ pR
a(2)
(tR
a(1)
+ tR
a(2)
) + . . . +
pR
a(n)
(tR
a(1)
+ . . .+ tR
a(n)
) is minimal. Then
our method chooses the action that appears
first in the optimal plan for request type Ra(1)
as the next action.
3 Experiments
We evaluated the proposed method by simula-
tion. In the simulation, the system conversed
with a simulated user program. Simulation
with a simulated user enables rapid prototyp-
ing and evaluation (Eckert et al, 1998). The
conversation was not done by exchanging spo-
ken language, but by exchanging attribute-
value pairs.
Simulated User Program The simulated
user program works in the following steps:
1. Select a request. The request never
changes throughout the dialogue
2. Tell the system the request or a subset of
the request
3. Respond Yes or No if the system confirms
4. Give corrections at random if confirma-
tion contains errors
5. Respond to the demand from the system
6. Tell the system that there is no infor-
mation if the system refers to attributes
with which the user is not concerned
Specification of Test Task We prepared
a fictitious task for simulation. This task ac-
cepts six types of user demand. There are
six attributes, and two of them have meaning
dependence like the family name and depart-
ment. The numbers of persons, family names,
and departments are 3000, 1000, 300 respec-
tively.
24
6
8
10
12
14
16
0.65 0.7 0.75 0.8 0.85 0.9 0.95 1
m
e
a
n
 n
u
m
be
r o
f t
ur
ns
recognition rate under 500 words vocaburaly
Our method
Naive method
Figure 1: Average number of turns to com-
plete a dialogue
0
20
40
60
80
100
0.65 0.7 0.75 0.8 0.85 0.9 0.95 1
va
ria
nc
e 
of
 th
e 
nu
m
be
r o
f t
ur
ns
recognition rate under 500 words vocaburaly
Our method
Naive method
Figure 2: Variance of the number of turns to
complete a dialogue
Comparison with a Naive Method For
comparison, we prepared a naive confirmation
dialogue control method, with the following
specifications:
1. If the user request can be fixed uniquely
and there are unbound attributes re-
quired for that request, demand those at-
tributes one by one.
2. If there are values that are not confirmed,
confirm them one by one.
3. If the user request type can?t be fixed yet,
demand a value for an attribute in the
order of the number of user request types
that require that attribute.
Experimental Results Figures 1 and 2
show the average number of turns and its vari-
ance out of 1000 diaglogue. We can see from
these figures that our method can complete
dialogues in shorter turns than other methods
under various levels of recognition accuracy.
In addition, the variance is small in almost
every range, which illustrates the stability of
our method.
4 Conclusion
A new dialogue control method is proposed.
The method takes into consideration the ex-
pected number of turns based on the guessed
recognition accuracy and the approximated
probability distribution of user requests.
We don?t have to write domain-specific
rules manually by using this method. We can
thus easily transfer domain of the system.
We evaluated our method by simulation.
The result shows that it can complete di-
alogues in shorter turns than conventional
methods under various recognition accuracy.
Acknowledgements
We thank Ken?ichiro Ishii, Norihiro Hagita,
and all our colleagues in the Dialogue Un-
derstanding Research Group for useful discus-
sions.
References
Wieland Eckert, Esther Levin, and Roberto Pier-
accini. 1998. Automatic evaluation of spoken
dialogue systems. In TWLT13: Formal seman-
tics and pragmatics of dialogue.
Diane J. Litman, Michael S. Kearns, and Mari-
lyn A. Walker. 2000. Automatic optimization
of dialogue management. In COLING.
Seiichi Nakagawa and Masaki Ida. 1998. A
new measure of task complexity for continuous
speech recognition. IEICE, J81-D-II(7):1491?
1500(in Japanese).
Yasuhisa Niimi and Yutaka Kobayashi. 1996. Di-
alog control stragey based on the reliability of
speech recognition. In International Confer-
ence on Spoken Language Processing, pages 25?
30.
R. Rosenfeld. 1996. A maximum entropy ap-
proach to adaptive statistical language model-
ing. Computer, Speech and Language, 10:187?
228.
WIT: A Toolkit for Building Robust and Real-Time Spoken Dialogue 
Systems 
Mikio Nakano* Noboru Miyazaki, Norihito Yasuda, Akira Sugiyama, 
Jun-ichi Hirasawa, Kohji Dohsaka, Kiyoaki Aikawa 
NTT Corporation 
3-1 Morinosato-Wakamiya 
Atsugi, Kanagawa 243-0198, Japan 
E-mail: nakano@atom.brl.ntt.co.jp 
Abstract 
This paper describes WI'I; a toolkit 
for building spoken dialogue systems. 
WIT features an incremental under- 
standing mechanism that enables ro- 
bust utterance understanding and real- 
time responses. WIT's ability to com- 
pile domain-dependent system specifi- 
cations into internal knowledge sources 
makes building spoken dialogue sys- 
tems much easier than :it is from 
scratch. 
1 Introduction 
The recent great advances in speech and language 
technologies have made it possible to build fully 
implemented spoken dialogue systems (Aust et 
al., 1995; Allen et al, 1996; Zue et al, 2000; 
Walker et al, 2000). One of the next research 
goals is to make these systems task-portable, that 
is, to simplify the process of porting to another 
task domain. 
To this end, several toolkits for building spo- 
ken dialogue systems have been developed (Bar- 
nett and Singh, 1997; Sasajima et al, 1999). 
One is the CSLU Toolkit (Sutton et al, 1998), 
which enables rapid prototyping of a spoken di- 
alogue system that incorporates a finite-state dia- 
logue model. It decreases the amount of the ef- 
fort required in building a spoken dialogue sys- 
tem in a user-defined task domain. However, it 
limits system functions; it is not easy to employ 
the advanced language processing techniques de- 
veloped in the realm of computational linguis- 
tics. Another is GALAXY-II (Seneffet al, 1998), 
*Mikio Nakano is currently a visiting scientist at MIT 
Laboratory for Computer Science. 
which enables modules in a dialogue system to 
communicate with each other. It consists of the 
hub and several servers, such as the speech recog- 
nition server and the natural language server, and 
the hub communicates with these servers. Al- 
though it requires more specifications than finite- 
state-model-based toolkits, it places less limita- 
tions on system functions. 
Our objective is to build robust and real-time 
spoken dialogue systems in different ask do- 
mains. By robust we mean utterance understand- 
ing is robust enough to capture not only utter- 
ances including rammatical errors or self-repairs 
but also utterances that are not clearly segmented 
into sentences by pauses. Real time means the 
system can respond to the user in real time. The 
reason we focus on these features i  that they are 
crucial to the usability of spoken dialogue sys- 
tems as well as to the accuracy of understand- 
ing and appropriateness of the content of the sys- 
tem utterance. Robust understanding allows the 
user to speak to the system in an unrestricted 
way. Responding in real time is important be- 
cause if a system response is delayed, the user 
might think that his/her utterance was not recog- 
nized by the system and make another utterance, 
making the dialogue disorderly. Systems having 
these features hould have several modules that 
work in parallel, and each module needs some 
domain-dependent k owledge sources. Creat- 
ing and maintaining these knowledge sources re- 
quire much effort, thus a toolkit would be help- 
ful. Previous toolkits, however, do not allow us to 
achieve these features, or do not provide mecha- 
nisms that achieve these features without requir- 
ing excessive fforts by the developers. 
This paper presents WIT 1, which is a toolkit 
IWIT is an acronym of Workable spoken dialogue lnter- 
150 
for building spoken dialogue systems that inte- 
grate speech recognition, language understanding 
and generation, and speech output. WIT features 
an incremental understanding method (Nakano et 
al., 1999b) that makes it possible to build a robust 
and real-time system. In addition, WIT compiles 
domain-dependent system specifications into in- 
ternal knowledge sources o that building systems 
is easier. Although WIT requires more domain- 
dependent specifications than finite-state-model- 
based toolkits, WIT-based systems are capable 
of taking full advantage of language processing 
technology. WIT has been implemented and used 
to build several spoken dialogue systems. 
In what follows, we overview WIT, explain its 
architecture, domain-dependent system specifica- 
tions, and implementation, and then discuss its 
advantages and problems. 
2 Overview 
A WIT-based spoken dialogue system has four 
main modules: the speech recognition module, 
the language understanding module, the lan- 
guage generation module, and the speech out- 
put module. These modules exploit domain- 
dependent knowledge sources, which are auto- 
matically generated from the domain-dependent 
system specifications. The relationship among 
the modules, knowledge sources, and specifica- 
tions are depicted in Figure 1. 
WIT can also display and move a human-face- 
like animated agent, which is controlled by the 
speech output module, although this paper does 
not go into details because it focuses only on spo- 
ken dialogue. We also omit the GUI facilities pro- 
vided by WIT. 
3 Architecture of  WIT-Based Spoken 
Dialogue Systems 
Here we explain how the modules in WIT work 
by exploiting domain-dependent k owledge and 
how they interact with each other. 
3.1 Speech Recognition 
The speech recognition module is a phoneme- 
HMM-based speaker-independent continuous 
speech recognizer that incrementally outputs 
face Toolldt. 
word hypotheses. As the recogn/fion engine, 
either VoiceRex, developed by NTI" (Noda et 
al., 1998), or HTK from Entropic Research can 
be used. Acoustic models for HTK is trained 
with the continuous peech database of the 
Acoustical Society of Japan (Kobayashi et al, 
1992). This recognizer incrementally outputs 
word hypotheses a soon as they are found in the 
best-scored path in the forward search (Hirasawa 
et al, 1998) using the ISTAR (Incremental 
Structure Transmitter And Receiver) protocol, 
which conveys word graph information as well as 
word hypotheses. This incremental output allows 
the language understanding module to process 
recognition results before the speech interval 
ends, and thus real-time responses are possible. 
This module continuously runs and outputs 
recognition results when it detects a speech 
interval. This enables the language generation 
module to react immediately touser interruptions 
while the system is speaking. 
The language model for speech recognition 
is a network (regular) grammar, and it allows 
each speech interval to be an arbitrary number 
of phrases. A phrase is a sequence of words, 
which is to be defined in a domain-dependent 
way. Sentences can be decomposed into a cou- 
ple of phrases. The reason we use a repeti- 
tion of phrases instead of a sentence grammar 
for the language model is that the speech recog- 
nition module of a robust spoken dialogue sys- 
tem sometimes has to recognize spontaneously 
spoken utterances, which include self-repairs and 
repetition. In Japanese, bunsetsu is appropriate 
for defining phrases. A bunsetsu consists of one 
content word and a number (possibly zero) of 
function words. In the meeting room reservation 
system we have developed, examples of defined 
phrases are bunsetsu to specify the room to be re- 
served and the time of the reservation and bun- 
setsu to express affirmation and negation. 
When the speech recognition module finds a 
phrase boundary, it sends the category of the 
phrase to the language understanding module, 
and this information is used in the parsing pro- 
cess. 
It is possible to hold multiple language mod- 
els and use any one of them when recogniz- 
ing a speech interval. The language models are 
151 
Semantic \[ 
I ~e  I 
/ specifications \[ r 1 
I R~ae I /L..___..--  - ' - ' -~ ' -  / Ph~e l 
/de~;,i~ions I /" "-. I de~i*~._l 
I Feature I L._.___..~.. -~-'-'-'~ , ( "~ "'. 
L____i----',.,'-... ~ ~ "-.. 
? Surface- I de .~ons  \[:- ,, l ;~ : : - - ?Y \ l  Language II Language I ~Genera f io~n_ /  . I , ~ ,  "., "~"----~__Z_--.--" M . -. i i . ) i . . . . . . .  l,,_J generaraon I ~ \  ,, ~ ~ unaerstanding I I generation IO  t procedures I TM / . . . .  ~ . . . .  I 
\ I I I . . . .  J 
I definitions I '\ \ I word I strings I hypothesea + 
I . - -  I _ __~ '~seto f - " -L__~I  Speech i I~ ,~ L iT -s t  o f - - / L / i . , i s to f  
I ~"  t I ~angu.~ge I- -I ~t io .  I I ou~u, r ' - - ' \ ]  pre-r~o.dedr'--\] pre-r~o~ed I 
I d~f~i~23~_l t.models .....~1 I module I I ~oam~ I~Peech m~._J , I L_  j 
user utterance system utterance 
domain-dependent: 
specification knowledge source module 
Figure 1: Architecture of WIT 
switched according to the requests from the lan- 
guage understanding module. In this way, the 
speech recognition success rate is increased by 
using the context of the dialogue. 
Although the current version of WIT does not 
exploit probabilistic language models, such mod- 
els can be incorporated without changing the ba- 
sic WIT architecture. 
3.2 Language Understanding 
The language understanding :module receives 
word hypotheses from the speech recognition 
module and incrementally understands the se- 
quence of the word hypotheses to update the di- 
alogue state, in which the resnlt of understand- 
ing and discourse information are represented 
by a frame (i.e., attribute-value pairs). The un- 
derstanding module utilizes ISSS (Incremental 
Significant-utterance Sequence Search) (Nakano 
et al, 1999b), which is an integrated parsing and 
discourse processing method. ISSS enables the 
incremental understanding of user utterances that 
are not segmented into sentences prior to pars- 
ing by incrementally finding the most plausible 
sequence of sentences (or significant utterances 
in the ISSS terms) out of the possible sentence 
sequences for the input word sequence. ISSS 
also makes it possible for the language generation 
module to respond in real time because it can out- 
put a partial result of understanding at any point 
in time. 
The domain-dependent knowledge used in this 
module consists of a unification-based lexicon 
and phrase structure rules. Disjunctive feature 
descriptions are also possible; WIT incorporates 
an efficient method for handling disjunctions 
(Nakano, 1991). When a phrase boundary is de- 
tected, the feature structure for a phrase is com- 
puted using some built-in rules from the feature 
structure rules for the words in the phrase. The 
phrase structure rules specify what kind of phrase 
sequences can be considered as sentences, and 
they also enable computing the semantic repre- 
sentation for found sentences. Two kinds of sen- 
tenees can be considered; domain-related ones 
that express the user's intention about he reser- 
152 
vafion and dialogue-related ones that express the 
user's attitude with respect to the progress of the 
dialogue, such as confirmation and denial. Con- 
sidering the meeting room reservation system, ex- 
amples of domain-related sentences are "I need to 
book Room 2 on Wednesday", I need to book 
Room 2", and "Room 2" and dialogue-related 
ones are "yes", "no", and "Okay". 
The semantic representation for a sentence is
a command for updatingthe dialogue state. The 
dialogue state is represented bya list of attribute- 
value pairs. For example, attributes used in the 
meeting room reservation system include task- 
related attributes, such as the date and time of 
the reservation, as well as attributes that represent 
discourse-related information, such as confirma- 
tion and grounding. 
3.3 Language Generation 
How the language generation module works 
varies depending on whether the user or system 
has the initiative of turn taking in the dialogue 2.
Precisely speaking, the participant having the ini- 
tiative is the one the system assumes has it in the 
dialogue. 
The domain-dependent k owledge used by the 
language generation module is generation proce- 
dures, which consist of a set of dialogue-phase 
definitions. For each dialogue phase, an initial 
function, an action function, a time-out function, 
and a language model are assigned. In addition, 
phase definitions designate whether the user or 
the system has the initiative. In the phases in 
which the system has the initiative, only the ini- 
tial function and the language model are assigned. 
The meeting room reservation system, for exam- 
ple, has three phases: the phase in which the 
user tells the system his/her equest, he phase in 
which the system confirms it, and the phase in 
which the system tells the user the result of the 
database access. In the first two phases, the user 
holds the initiative, and in the last phase, the sys- 
tern holds the initiative. 
Functions defined here decide what string 
should be spoken and send that string to the 
speech output module based on the current di- 
alogue state. They can also shift the dialogue 
2The notion of the initiative inthis paper isdifferent from 
that of the dialogue initiative of Chu-Carroll (2000). 
phase and change the holder of the initiative as 
well as change the dialogue state. When the dia- 
logue phase shifts, the language model foi" speech 
recognition is changed to get better speech recog- 
nition performance. Typically, the language gen- 
eration module is responsible for database access. 
The language generation module works as fol- 
lows. It first checks which dialogue participant 
has the initiative. If the initiative is held by the 
user, it waits until the user's speech interval ends 
or a duration of silence after the end of a system 
utterance is detected. The action function in the 
dialogue phase at that point in time is executed in
the former case; the time-out function is executed 
in the latter case. Then it goes back to the initial 
stage. If the system holds the initiative, the mod- 
ule executes the initial function of the phase. In 
typical question-answer systems, the user has the 
initiative when asking questions and the system 
has it when answering. 
Since the language generation module works in 
parallel with the language understanding module, 
utterance generation is possible even while the 
system is listening to user utterances and that ut- 
terance understanding is possible even while it is 
speaking (Nakano et al, 1999a). Thus the system 
can respond immediately after user pauses when 
the user has the initiative. When the system holds 
the initiative, it can immediately react to an in- 
terruption by the user because user utterances are 
understood in an incremental way (Dohsaka nd 
Shimazu, 1997). 
The time-out function is effective in moving 
the dialogue forward when the dialogue gets 
stuck for some reason. For example, the system 
may be able to repeat the same question with an- 
other expression and may also be able to ask the 
user a more specific question. 
3.4 Speech Output 
The speech output module produces peech ac- 
cording to the requests from the language gener- 
ation module by using the correspondence table 
between strings and pre-recorded speech data. It 
also notifies the language generation module that 
speech output has finished so that the language 
generation module can take into account the tim- 
ing of the end of system utterance. The meeting 
room reservation system uses speech files of short 
153 
phrases. 
4 Building Spoken Dialo~te Systems 
with WIT  
4.1 Domain-Dependent System 
Specifications 
Spoken dialogue systems can be built with WIT 
by preparing several domain-dependent specifica- 
tions. Below we explain the specifications. 
Feature Definitions: Feature definitions pec- 
ify the set of features used in the grammar for lan- 
guage understanding. They also specify whether 
each feature is a head feature or a foot feature 
(Pollard and Sag, 1994). This information isused 
when constructing feature structures for phrases 
in a built-in process. 
The following is an example of a feature defini- 
tion. Here we use examples from the specification 
of the meeting room reservation system. 
(case head) 
It means that the case feature is used and it is a 
head feature 3.
Lexieal Descriptions: Lexical descriptions 
specify both pronunciations and grammatical 
features for words. Below is an example lexical 
item for the word 1-gatsu (January). 
(l-gatsu ichigatsu month nil i) 
The first three elements are the identifier, the pro- 
nunciation, and the grammatical category of the 
word. The remaining two elements are the case 
and semantic feature values. 
Phrase Definitions: Phrase definitions pecify 
what kind of word sequence can be recognized 
as a phrase. Each definition is a pair compris- 
ing a phrase category name and a network of 
word categories. In the example below, month-  
phrase is the phrase category name and the re- 
maining part is the network of word categories. 
opt  means an option and or  means a disjunc- 
tion. For instance, a word sequence that con- 
sists of a word in the month  category, such as 1- 
gatsu (January), and a word in the adraon ina l -  
par t i c le  category, such as no (of), forms a 
phrase in the month-phrase  category. 
3In this section, we use examples of different description 
from the actual ones for simplicity. Actual specifications are 
written in part in Japanese. 
(month-phrase 
(month 
(opt 
(or 
expression-following-subject 
(admoninal-particle 
(opt 
sentence-final-particle)))))) 
Network Definitions: Network definitions 
specify what kind of phrases can be included in 
each language model. Each definition is a pair 
comprising a network name and a set of phrase 
category names. 
Semantic-Frame Specifications: The result of 
understanding and dialogue history can be stored 
in the dialogue state, which is represented by a 
flat frame structure, i.e., a set of attribute-value 
pairs. Semantic-frame specifications define the 
attributes used in the frame. The meeting room 
reservation system uses task-related attributes. 
Two are s tar t  and end, which represent the 
user's intention about the start and end times of 
the reservation for some meeting room. It also 
has attributes that represent discourse informa- 
tion. One is conf i rmed,  whose value indicates 
whether if the system has already made an utter- 
ance to confirm the content of the task-related at- 
tributes. 
Rule Definitions: Each rule has one of the fol- 
lowing two forms. 
((rule name) 
(child feature structure) 
? . .  (child feature structure) 
=> (mother feature structu_e) 
(priority increase) ) 
((role name) 
(child feature structure) 
? . .  (child feature structure) 
=> (flame operation command) 
(priority increase) ) 
These roles are similar to DCG (Pereira nd War- 
ren, 1980) rules; they can include logical vari- 
ables and these variables can be bound when 
these rules are applied. It is possible to add to the 
rules constraints that stipulate relationships that 
must hold among variables (Nakano, 199 I), but 
we do not explain these constraints indetail in this 
154 
paper. The priorities are used for disambiguat- 
ing interpretation i  the incremental understand- 
ing method (Nakano et al, 1999b). 
When the command on the right-hand side of 
the arrow is a frame operation command, phrases 
to which this rule can be applied can be consid- 
ered a sentence, and the sentence's semantic rep- 
resentation is the command for updating the dia- 
logue state. The command is one of the follow- 
ing: 
? A command to set the value of an attribute 
of the frame, 
? A command to increase the priority, 
Conditional commands (If-then-else type 
command, the condition being whether the 
value of an attribute of the flame is or is not 
equal to a specified value, or a conjunction 
or disjunction of the above condition), or 
? A list of commands to be sequentially exe- 
cuted. 
Thanks to conditional commands, it is possible 
to represent the semantics of sentences context- 
dependently. 
The following rule is an example. 
( s ta r t -end- t imes-command 
( t ime-phrase  : f rom *start) 
( t ime-phrase  (:or :to nil) *end) 
=> (command (set :start *start) 
(set :end *end))) 
The name of this rule is s ta r t -end- t imes-  
command. The second and third elements 
are child feature structures. In these elements, 
t ime-phrase  is a phrase category, : f rom and 
( : or : to n i l  ) are case feature values, and 
*s tar t  and *end are semantic feature val- 
ues. Here :or means a disjunction, and sym- 
bols starting with an asterisk are variables. The 
right-hand side of the arrow is a command to up- 
date the frame. The second element of the com- 
mand, (set :start  *start), changes the 
: s ta r t  atttribute value of the frame to the in- 
stance of *s tar t ,  which should be bound when 
applying this rule to the child feature structures. 
Phase Definitions: Each phase definition con- 
sists of a phase name, a network name, an ini- 
tiative holder specification, an initial function, an 
action function, a maximum silence duration, and 
a time-out function. The network name is the 
identifier of the language model for the speech 
recognition. The maximum silence duration spec- 
ifies how long the generation module should wait 
until the time-out function is invoked. 
Below is an example of a phase definition. 
The first element request  is the name of this 
phase, " f ra r_ request"  is the name of the 
network, and move- to - reques  t -phase  and 
request -phase-act ion  are the names of 
the initial and action functions. In this phase, 
the maximum silence duration is ten seconds and 
the name of the time-out function is request -  
phas e- t imeou t. 
(request " fmr_request"  
move-  to - reques  t -phase  
request -phase-act ion  
10.0 
request -phase-  t imeout  ) 
For the definitions of these functions, WIT pro- 
vides functions for accessing the dialogue state, 
sending a request o speak to the speech out- 
put module, generating strings to be spoken us- 
ing surface generation templates, hifting the di- 
alogue phase, taking and releasing the initiative, 
and so on. Functions are defined in terms of the 
Common Lisp program. 
Surface-generation Templates: Surface- 
generation templates are used by the surface 
generation library function, which converts 
a list-structured semantic representation to a 
sequence of strings. Each string can be spoken, 
i.e., it is in the list of pre-recorded speech files. 
For example, let us consider the conversion 
of the semantic representation (date  (date -  
express ion  3 15) ) to strings using the fol- 
lowing template. 
( (date 
(date -express ion  *month  *day)) 
( (*month gatsu) (*day nichi)  ) ) 
The surface generation library function matches 
the input semantic representation with the first el- 
ement of the template and checks if a sequences 
155 
of strings appear in the speech file list. It re- 
turns ( '  '3gagsu l5n ich i ' ' )  (March 15th) 
if the string "3gatsul5nichi" s in the list of 
pre-recorded speech files, and otherwise, returns 
( ' ' 3gatsu  . . . .  15n ich i '  ' ) when these 
strings are in the list. 
List of Pre-recorded Speech Files: The list of 
pre-recorded speech files should show the corre- 
spondence between strings and speech files to be 
played by the speech output module. 
4.2 Compiling System Specifications 
From the specifications explained above, domain- 
dependent knowledge sources are created as indi- 
cated by the dashed arrows in Figure 1. When cre- 
ating the knowledge sources, WIT checks for sev- 
eral kinds of consistency. For example, the set of 
word categories appearing in the lexicon and the 
set of word categories appearing in phrase deft- 
nifions are compared. This makes it easy to find 
errors in the domain specifications. 
5 Implementation 
WIT has been implemented in Common Lisp and 
C on UNIX, and we have built several experi- 
mental and demonstration dialogue systems using 
it, including a meeting room reservation system 
(Nakano et al, 1999b), a video-recording pro- 
gramming system, a schedule management sys- 
tem (Nakano et al, 1999a), and a weather in- 
formation system (Dohsaka et al, 2000). The 
meeting room reservation system has vocabulary 
of about 140 words, around 40 phrase structure 
rules, nine attributes in the semantic frame, and 
around 100 speech files. A sample dialogue be- 
tween this system and a naive user is shown 
in Figure 2. This system employs HTK as the 
speech recognition engine. The weather informa- 
tion system can answer the user's questions about 
weather forecasts in Japan. The vocabulary size 
is around 500, and the number of phrase structure 
rules is 31. The number of attributes in the se- 
mantic flame is 11, and the number of the files of 
the pre-recorded speech is about 13,000. 
6 Discussion 
As explained above, the architecture of WIT al- 
lows us to develop a system that can use utter- 
ances that are not clearly segmented into sen- 
tences by pauses and respond in real time. Below 
we discuss other advantages and remaining prob- 
lems. 
6.1 Descriptive Power 
Whereas previous finite-state-model-based tool- 
kits place many severe restrictions on domain de- 
scriptions, WIT has enough descriptive power to 
build a variety of dialogue systems. Although the 
dialogue state is represented bya simple attribute- 
value matrix, since there is no limitation on the 
number of attributes, it can hold more compli- 
cated information. For example, it is possible to 
represent a discourse stack whose depth is lim- 
ited. Recording some dialogue history is also 
possible. Since the language understanding mod- 
ule utilizes unification, a wide variety of lin- 
guistic phenomena can be covered. For exam- 
ple, speech repairs, particle omission, and fillers 
can be dealt with in the framework of unifica- 
tion grammar (Nakano et al, 1994; Nakano and 
Shimazu, 1999). The language generation mod- 
ule features Common Lisp functions, so there is 
no limitation on the description. Some of the 
systems we have developed feature a generation 
method based on hierarchical planning (Dohsaka 
and Shirnazu, 1997). It is also possible to build a 
simple finite-state-model-based dialogue system 
using WIT. States can be represented bydialogue 
phases in WIT. 
6.2 Consistency 
In an agglutinative language such as Japanese, 
there is no established definition of words, so dia- 
logue system developers must define words. This 
sometimes causes a problem in that the defini- 
tion of word, that is, the word boundaries, in the 
speech recognition module are different from that 
in the language understanding module. In WIT, 
however, since the common lexicon is used in 
both the speech recognition module and language 
understanding module, the consistency between 
them is maintained. 
6-3 Avoiding Information Loss 
In ordinary spoken language systems, the speech 
recognition module sends just a word hypoth- 
esis to the language processing module, which 
156 
speaker start end utterance 
time (s) time (s) 
system: 614.53 615.93 
user: 616.38 618.29 
system: 619.97 620.13 
user: 622.65 624.08 
system: 625.68 625.91 
user: 626.65 627.78 
system: 629.25 629.55 
user: 629.91 631.67 
system: 633.29 633.57 
user: 634.95 636.00 
system: 637.50 645.43 
user: 645.74 646.04 
system: 647.05 648.20 
Figure 2: 
donoy6na goy6ken desh6 ka (how may I help you?) 
kaigishitsu oyoyaku shitai ndesu ga (I'd like to make a reserva- 
tion for a meeting room) 
hai (uh-huh) 
san-gatsujfini-nichi (on March 12th) 
hal (uh-huh) 
jayo-ji kara (from 14:00) 
hai (uh-huh) 
jashichi-ji sanjup-pun made (to 17:30) 
hai (uh-huh) 
dai-kaigishitsu (the large meeting room) 
san-gatsu jani-nichi, j~yo-ji kara, jashichi-ji sanjup-pun made, 
dai-kaigishitsu toyfi koto de yoroshf deshrka (on March 12th, 
from 14:00 to 17:30, the large meeting room, is that right?) " 
hai (yes) 
kashikomarimashitd (allright) 
An example dialogue of an example system 
must disambiguate word meaning and find phrase 
boundaries by parsing. In contrast, the speech 
recognition module in WIT sends not only words 
but also word categories, phrase boundaries, and 
phrase categories. This leads to less expensive 
and better language understanding. 
6.4 Problems and Limitations 
Several problems remain with WIT. One of the 
most significant is that he system developer must 
write language generation functions. If the gen- 
eration functions employ sophisticated dialogue 
strategies, the system can perform complicated 
dialogues that are not just question answering. 
WIT, however, does not provide task-independent 
facilities that make it easier to employ such dia- 
logue strategies. 
There have been several efforts aimed at de- 
veloping a domain-independent me hod for gen- 
erating responses from a frame representation f 
user requests (Bobrow et al, 1977; Chu-CarroU, 
1999). Incorporating such techniques would deo 
crease the system developer workload. However, 
there has been no work on domain-independent 
response generation for robust spoken dialogue 
systems that can deal with utterances that might 
include pauses in the middle of a sentence, which 
WIT handles well. Therefore incorporating those 
techniques remains as a future work. 
Another limitation is that WIT cannot deal with 
multiple speech recognition candidates such as 
those in an N-best list. Extending WIT to deal 
with multiple recognition results would improve 
the performance of the whole system. The ISSS 
preference mechanism is expected to play a role 
in choosing the best recognition result. 
7 Conclusion 
This paper described WIT, a toolkit for build- 
ing spoken dialogue systems. Although it re- 
quires more system specifications than previous 
finite-state-model-based toolkits, it enables one 
to easily construct real-time, robust spoken dia- 
logue systems that incorporates advanced compu- 
tational linguistics technologies. 
Acknowledgements 
The authors thank Drs. Ken'ichiro Ishii, Nori- 
hiro Hagita, and Takeshi Kawabata for their sup- 
port of this research. Thanks also go to Tetsuya 
Kubota, Ryoko Kima, and the members of the 
Dialogue Understanding Research Group. We 
used the speech recognition engine VoiceRex de- 
veloped by NTT Cyber Space Laboratories and 
thank those who helped us use it. Comments by 
157 
the anonymous reviewers were of' great help. 
References 
James F. Allen, Bradford W. Miller, Eric K. Ringger, 
and Teresa Sikorski. 1996. A robust system for nat- 
ural spoken dialogue. In Proceedings of the 34th 
Annual Meeting of the Association for Computa- 
tional Linguistics (A CL-96), pages 62-70. 
Harald Aust, Martin Oerder, Frank Seide, and Volker 
Steinbiss. 1995. The Philips automatic train 
timetable information system. Speech Communi- 
cation, 17:249--262. 
James Barnett and Mona Singh. 1997. Designing 
a portable spoken language system. In Elisabeth 
Maier, Marion Mast, and Susann LuperFoy, editors, 
Dialogue Processing inSpoken Language Systems, 
pages 156--170. Springer-Vedag. 
Daniel G. Bobrow, Ronald M. Kaplan, Martin Kay, 
Dona!d A. Norman, Henry Thompson, and Terry 
Winograd. 1977. GUS, a frame driven dialog sys- 
tem. Arnficial Intelligence, 8:155-173. 
Jennifer Chu-Carroll. 1999. Fo:rrn-based reason- 
ing for mixed-initiative dialogue management in 
information-query systems. In Proceedings of the 
Sixth European Conference on Speech Communica- 
tion and Technology (Eurospeech-99) , pages 1519- 
1522. 
Junnifer Chu-Carroll. 2000. MIMIC: An adaptive 
mixed initiative spoken dialogue system for infor- 
mation queries. In Proceedings of the 6th Con- 
f~rence on Applied Natural Language Processing 
(ANLP-O0), pages 97-104. 
Kohji Dohsaka nd Akira Shimazu. 1997. System ar- 
chitecture for spoken utterance production in col- 
laborative dialogue. In Working Notes of IJCAI 
1997 Workshop on Collaboration, Cooperation and 
Conflict in Dialogue Systems. 
Kohji Dohsaka, Norihito Yasuda, Noboru Miyazaki, 
Mikio Nakano, and Kiyoaki AJkawa. 2000. An ef- 
ficient dialogue control method under system's lim- 
ited knowledge. In Proceedings of the Sixth Inter- 
national Conference on Spoken Language Process- 
ing (ICSLP-O0). 
Jun-ichi Hirasawa, Noboru Miyazaki, Mikio Nakano, 
and Takeshi Kawabata. 1998. Implementation 
of coordinative nodding behavior on spoken dia- 
logue systems. In Proceedings of the Fgth Interna- 
tional Conference on Spoken Language Processing 
(1CSLP-98), pages 2347-2350. 
Tetsunod Kobayashi, Shuichi Itahashi, Satoru 
Hayamizu, and Toshiyuki Takezawa. 1992. Asj 
continuous speech corpus for research. The journal 
of th e Acoustical Society of Japan, 48(12): 888-893. 
Mikio Nakano and Akira Shimazu. 1999. Pars- 
ing utterances including self-repairs. In Yorick 
Wilks, editor, Machine Conversations, pages 99- 
112. Kluwer Academic Publishers. 
Mikio Nakano, Aldra Shimazu, and Kiyoshi Kogure. 
1994. A grammar and a parser for spontaneous 
speech. In Proceedings of the 15th Interna- 
tional Conference on Computational Linguistics 
(COLING-94), pages 1014-1020. 
Mildo Nakano, Kohji Dohsaka, Noboru Miyazald, 
Inn ichi Hirasawa, Masafiami Tamoto, Masahito 
Kawarnon, Akira Sugiyama, and Takeshi Kawa- 
bata. 1999a. Handling rich turn-taking in spoken 
dialogue systems. In Proceedings of the Sixth Eu- 
ropean Conference on Speech Communication a d 
Technology (Eurospeech-99), pages 1167-1170. 
Mikio Nakano, Noboru Miyazaki, Jun-ichi Hirasawa, 
Kohji Dohsaka, and Takeshi Kawabata. 1999b. 
Understanding unsegmented user utterances in real- 
time spoken dialogue systems. In Proceedings of 
the 37th Annual Meeting of the Association for 
Computational Linguistics (ACL-99), pages 200-- 
207. 
Mikio Nakano. 1991. Constraint projection: An ef- 
ficient treatment of disjunctive f ature descriptions. 
In Proceedings of the 29th Annual Meeting of the 
Association for Computational Linguistics (ACL- 
90, pages 307-314. 
Yoshiaki Noda, Yoshikazu Yamaguchi, Tomokazu 
Yamada, Akihiro Imamura, Satoshi Takahashi, 
Tomoko Matsui, and Kiyoaki Aikawa. 1998. The 
development of speech recognition engine REX. In 
Proceedings of the 1998 1EICE General Confer- 
ence D-14-9, page 220. (in Japanese). 
Fernando C. N. Pereira and David H. D. Warren. 
1980. Definite clause grammars for language 
analysis--a survey of the formalism and a compar- 
ison with augmented transition etworks. Artificial 
Intelligence, 13:231-278. 
Carl J. Pollard and Ivan A. Sag. 1994. Head-Driven 
Phrase Structure Grammar. CSLI, Stanford. 
Munehiko Sasajima, Yakehide Yano, and Yasuyuki 
Kono. 1999. EUROPA: A genetic framework for 
developing spoken dialogue systems. In Proceed- 
ings of the Sixth European Conference on Speech 
Communication a d Technology (Eurospeech-99), 
pages 1163--1166. 
Stephanie Seneff, Ed Hurley, Raymond Lau, Chris- 
fine Pao, Philipp Sehmid, and Victor Zue. 1998. 
GALAXY-H: A reference architecture for conver- 
sational system development. In Proceedings of 
158 
the Fifth International Con l~rence on Spoken Lan- 
guage Processing (ICSLP-98). 
Stephen Sutton, Ronaid A. Cole, Jacques de Villiers, 
Johan SchMkwyk, Pieter Vermeulen, Michael W. 
Macon, Yonghong Yah, Edward Kaiser, Brian Run- 
die, K.haldoun Shobaki, Paul Hosom, Alex Kain, 
Johan Wouters, Dominic W. Massaro, and Michael 
Cohen. 1998. Universal speech tools: The 
CSLU toolkit. In Proceedings of the Fifth Interna- 
tional Conference on Spoken Language Processing 
(1CSLP-98), pages 3221-3224. 
Marilyn Walker, Irene Langkilde, Jerry Wright, Allen 
Gorin, and Diane Litman. 2000. Learning to pre- 
dict problematic situations in a spoken dialogue 
system: Experiments with how may I help you? In 
Proceedings of the First Meeting of the North Amer- 
ican Chapter of the Association for Computational 
Linguistics (NAA CL-O0), pages 210--217. 
Victor Zue, Stephanie Seneff, James Glass, Joseph Po- 
lifroni, Christine Pao, Timothy J. Hazen, and Lee 
He~erington. 2000. Jupiter: A telephone-based 
conversational interface for weather information. 
1EEE Transactions on Speech and Audio Process- 
ing, 8(1):85-96. 
159 
