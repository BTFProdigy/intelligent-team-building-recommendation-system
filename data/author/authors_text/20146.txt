Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 97?103,
Dublin, Ireland, August 23-24, 2014.
Alpage: Transition-based Semantic Graph Parsing with Syntactic
Features
Corentin Ribeyre
? ?
Eric Villemonte de la Clergerie
?
Djam? Seddah
? 
?
Alpage, INRIA
?
Univ Paris Diderot, Sorbonne Paris Cit?

Universit? Paris Sorbonne
firstname.lastname@inria.fr
Abstract
This paper describes the systems deployed
by the ALPAGE team to participate to the
SemEval-2014 Task on Broad-Coverage
Semantic Dependency Parsing. We de-
veloped two transition-based dependency
parsers with extended sets of actions to
handle non-planar acyclic graphs. For the
open track, we worked over two orthog-
onal axes ? lexical and syntactic ? in or-
der to provide our models with lexical and
syntactic features such as word clusters,
lemmas and tree fragments of different
types.
1 Introduction
In recent years, we have seen the emergence
of semantic parsing, relying on various tech-
niques ranging from graph grammars (Chiang et
al., 2013) to transitions-based dependency parsers
(Sagae and Tsujii, 2008). Assuming that obtain-
ing predicate argument structures is a necessary
goal to move from syntax to accurate surface se-
mantics, the question of the representation of such
structures arises. Regardless of the annotation
scheme that should be used, one of the main is-
sues of semantic representation is the construction
of graph structures, that are inherently harder to
generate than the classical tree structures.
In that aspect, the shared task?s proposal (Oepen
et al., 2014), to evaluate different syntactic-
semantic schemes (Ivanova et al., 2012; Hajic et
al., 2006; Miyao and Tsujii, 2004) could not ar-
rive at a more timely moment when state-of-the-art
surface syntactic parsers regularly reach, or cross,
a 90% labeled dependency recovery plateau for a
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/.
wide range of languages (Nivre et al., 2007a; Sed-
dah et al., 2013).
The two systems we present both extend
transition-based parsers in order to be able to gen-
erate acyclic dependency graphs. The first one
follows the standard greedy search mechanism of
(Nivre et al., 2007b), while the second one fol-
lows a slightly more global search strategy (Huang
and Sagae, 2010; Goldberg et al., 2013) by rely-
ing on dynamic programming techniques. In addi-
tion to building graphs directly, the main original-
ity of our work lies in the use of different kinds of
syntactic features, showing that using syntax for
pure deep semantic parsing improves global per-
formance by more than two points.
Although not state-of-the-art, our systems per-
form very honorably compared with other single
systems in this shared task and pave quite an in-
teresting way for further work. In the remainder
of this paper, we present the parsers and their ex-
tensions for building graphs; we then present our
syntactic features and discuss our results.
2 Systems Description
Shift-reduce transition-based parsers essentially
rely on configurations formed of a stack and a
buffer, with stack transitions used to go from a
configuration to the next one, until reaching a fi-
nal configuration. Following K?bler et al. (2009),
we define a configuration by c = (?, ?,A) where
? denotes a stack of words w
i
, ? a buffer of
words, and A a set of dependency arcs of the form
(w
i
, r, w
j
), with w
i
the head, w
j
the dependent,
and r a label in some set R.
However, despite their overall similarities,
transition-based systems may differ on many as-
pects, such as the exact definition of the configura-
tions, the set of transitions extracted from the con-
figurations, the way the search space is explored
(at parsing and training time), the set of features,
the way the transition weights are learned and ap-
97
(?,w
i
|?,A) ` (?|w
i
, ?, A) (shift) BOTH
(?|w
j
|w
i
, ?, A) ` (?|w
i
, ?, A ? (w
i
, r, w
j
)) (left-reduce) S&T PARSER
(?|w
j
|w
i
, ?, A) ` (?|w
j
, ?, A ? (w
j
, r, w
i
)) (right-reduce) S&T PARSER
(?|w
j
|w
i
, ?, A) ` (?|w
j
|w
i
, ?, A ? (w
i
, r, w
j
)) (left-attach) BOTH
(?|w
j
|w
i
, ?, A) ` (?|w
j
, w
i
|?,A ? (w
j
, r, w
i
) (right-attach) BOTH
(?|w
i
, ?, A) ` (?, ?,A) (pop0) BOTH
(?|w
j
|w
i
, ?, A) ` (?|w
i
, ?, A) (pop1) DYALOG-SR
(?|w
j
|w
i
, ?, A) ` (?|w
i
|w
j
, ?, A) (swap) DYALOG-SR
Figure 1: An extended set of transitions for building dependency graphs.
plied, etc.
For various reasons, we started our experiments
with two rather different transition-based parsers,
which have finally converged on several aspects.
In particular, the main convergence concerns the
set of transitions needed to parse the three pro-
posed annotation schemes. To be able to attach
zero, one, or more heads to a word, it is necessary
to clearly dissociate the addition of a dependency
from the reduction of a word (i.e. its removal from
the stack). Following Sagae and Tsujii (2008), as
shown in Figure 1, beside the usual shift and re-
duce transitions of the arc-standard strategy, we
introduced the new left and right attach actions for
adding new dependencies (while keeping the de-
pendent on the stack) and two reduce pop0 and
pop1 actions to remove a word from the stack af-
ter attachement of its dependents. All transitions
adding an edge should also satisfy the condition
that the new edge does not create a cycle or mul-
tiple edges between the same pair of nodes. It is
worth noting that the pop actions may also be used
to remove words with no heads.
2.1 Sagae & Tsujii?s DAG Parser
Our first parsing system is a partial rewrite, with
several extensions, of the Sagae and Tsujii (2008)
DAG parser (henceforth S&T PARSER). We mod-
ified it to handle dependency graphs, in particu-
lar non-governed words using pop0 transitions.
This new transition removes the topmost stack el-
ement when all its dependents have been attached
(through attach or reduce transitions). Thus, we
can handle partially connected graphs, since a
word can be discarded when it has no incoming
arc.
We used two different learning algorithms:
(i) the averaged perceptron because of its good
balance between training time and performance
(Daume, 2006), (ii) the logistic regression model
(maximum entropy (Ratnaparkhi, 1997)). For the
latter, we used the truncated gradient optimiza-
tion (Langford et al., 2009), implemented in Clas-
sias (Okazaki, 2009), in order to estimate the pa-
rameters. These algorithms have been used inter-
changeably to test their performance in terms of F-
score. But the difference was negligeable in gen-
eral.
2.2 DYALOG-SR
Our second parsing system is DYALOG-SR
(Villemonte De La Clergerie, 2013), which has
been developed to participate to the SPMRL?13
shared task. Coded on top of tabular logic
programming system DYALOG, it implements
a transition-based parser relying on dynamic
programming techniques, beams, and an aver-
aged structured perceptron, following ideas from
(Huang and Sagae, 2010; Goldberg et al., 2013).
It was initially designed to follow an arc-
standard parsing strategy, relying on shift and
left/right reduce transitions. To deal with depen-
dency graphs and non governed words, we first
added the two attach transitions and the pop0
transition. But because there exist some overlap
between the reduce and attach transitions leading
to some spurious ambiguities, we finally decided
to remove the left/right reduce transitions and to
complete with the pop1 transition. In order to
handle some cases of non-projectivty with mini-
mal modifications of the system, we also added
a swap transition. The parsing strategy is now
closer to the arc-eager one, with an oracle sug-
gesting to attach as soon as possible.
2.3 Tree Approximations
In order to stack several dependency parsers, we
needed to transform our graphs into trees. We re-
port here the algorithms we used.
The first one uses a simple strategy. For nodes
with multiple incoming edges, we keep the longest
incoming edge. Singleton nodes (with no head)
are attached with a _void_-labeled edge (by
decreasing priority) to the immediately adjacent
98
Word
?
1
Lemma
?
1
POS
?
1
leftPOS
?
1
rightPOS
?
1
leftLabel
?
1
rightLabel
?
1
Word
?
2
Lemma
?
2
POS
?
2
leftPOS
?
2
rightPOS
?
2
leftLabel
?
2
rightLabel
?
2
Word
?
3
POS
?
3
Word
?
1
Lemma
?
1
POS
?
1
Word
?
2
Lemma
?
2
POS
?
2
POS
?
3
a d
12
d
?
11
Table 1: Baseline features for S&T PARSER.
node N , or the virtual root node (token 0). This
strategy already improves over the baseline, pro-
vided by the task organisers, on the PCEDT by 5
points.
The second algorithm tries to preserve more
edges: when it is possible, the deletion of a re-
entrant edge is replaced by reversing its direction
and changing its label l into <l. We do this for
nodes with no incoming edges by reversing the
longest edge only if this action does not create cy-
cles. The number of labels increases, but many
more edges are kept, leading to better results on
DM and PAS corpora.
3 Feature Engineering
3.1 Closed Track
For S&T PARSER we define Word
?
i
(resp.
Lemma
?
i
and POS
?
i
) as the word (resp. lemma
and part-of-speech) at position i in the queue. The
same goes for ?
i
, which is the position i in the
stack. Let d
i,j
be the distance between Word
?
i
and Word
?
j
. We also define d
?
i,j
, the distance be-
tween Word
?
i
and Word
?
j
. In addition, we define
leftPOS
?
i
(resp. leftLabel
?
i
) the part-of-speech
(resp. the label if any) of the word immediately
at the left handside of ?
i
, and the same goes for
rightPOS
?
i
(resp. rightLabel
?
i
). Finally, a is the
previous predicted action by the parser. Table 1
reports our baseline features.
For DYALOG-SR we have the following lexi-
cal features lex, lemma, cat, and morphosyn-
tactic mstag. They apply to next unread word
(
*
I, say lemmaI), the three next lookahead
words (
*
I2 to
*
I4), and (when present) to the
3 stack elements (
*
0 to
*
2), their two leftmost
and rightmost children (before b[01]
*
[012]
and after a[01]
*
[012]). We have dependency
features such as the labels of the two leftmost
and rightmost edges ([ab][01]label[012]),
the left and right valency (number of depen-
dency, [ab]v[012]) and domains (set of de-
pendency labels, [ab]d[012]). Finally, we
have 3 (discretized) distance features between the
next word and the stack elements (delta[01])
and between the two topmost stack elements
(delta01). Most feature values are atomic (ei-
ther numerical or symbolic), but they can also be
(recursively) a list of values, for instance for the
mstag and domain features. For dealing with
graphs, features were added about the incoming
edges to the 3 topmost stack elements, similar to
valency (ngov[012]) and domain (gov[012]).
For the PCEDT scheme, because of the high num-
ber of dependency labels, the 30 most unfrequent
ones were replaced by a generic label when used
as feature value.
Besides, for the PCEDT and DM corpora, static
and dynamic guiding features have been tried
for DYALOG-SR, provided by MATE (Bohnet,
2010) (trained on versions of these corpora pro-
jected to trees, using a 10-fold cross valida-
tion). The two static features mate_label and
mate_distance are attached to each token h,
indicating the label and the relative distance to its
governor d (if any). At runtime, dynamic features
are also added relative to the current configuration:
if a semantic dependency (h, l, d) has been pre-
dicted by MATE, and the topmost 2 stack elements
are either (h, d) or (d, h), a feature suggesting a
left or right attachment for l is added.
We did the same for S&T PARSER, except that
we used a simple but efficient hack: instead of
keeping the labels predicted by our parser, we re-
placed them by MATE predictions whenever it was
possible.
3.2 Open Track
For this track, we combined the previously de-
scribed features (but the MATE-related ones) with
various lexical and syntactic features, our intu-
ition being that syntax and semantic are inter-
dependent, and that syntactic features should
therefore help semantic parsing. In particular, we
have considered the following bits of information.
Unsupervized Brown clusters To reduce lexi-
cal sparsity, we extracted 1,000 clusters from the
BNC (Leech, 1992) preprocessed following Wag-
ner et al. (2007). We extended them with capi-
talization, digit features and 3 letters suffix signa-
tures, leading to a vocabulary size reduced by half.
Constituent tree fragments They were part of
the companion data provided by the organizers.
99
They consist of fragments of the syntactic trees
and can be used either as enhanced parts of speech
or as features.
Spinal elementary trees A full set of parses was
reconstructed from the tree fragments. Then we
extracted a spine grammar (Seddah, 2010), us-
ing the head percolation table of the Bikel (2002)
parser, slightly modified to avoid determiners to be
marked as head in some configurations.
Predicted MATE dependencies Also provided
in the companion data, they consist in the parses
built by the MATE parsers, trained on the Stanford
dependency version of the PTB. We combined the
labels with a distance ? = t ? h where t is the
token number and h the head number.
Constituent head paths Inspired by Bj?rkelund
et al. (2013), we used the MATE dependencies to
extract the shortest path between a token and its
lexical head and included the path length (in terms
of traversed nodes) as feature.
Tree frag. MATE labels+? Spines trees Head Paths
Train 648 1305 637 27,670
Dev 272 742 265 3,320
Test 273 731 268 2,389
Table 2: Syntactic features statistics.
4 Results and Discussion
We present here the results on section 21 (test set)
1
for both systems. We report in Table 3, the differ-
ent runs we submitted for the final evaluation of
the shared task. We also report improvements be-
tween the two tracks.
Both systems show relatively close F-measures,
with correct results on every corpus. If we com-
pare the results more precisely, we observe that in
general, DYALOG-SR tends to behave better for
the unlabeled metrics. Its main weakness is on
MRS scheme, for both tracks.
2
1
Dev set results are available online at
http://goo.gl/w3XcpW.
2
The main and still unexplained problem of DYALOG-
SR was that using larger beams has no impact, and often a
negative one, when using the attach and pop transitions. Ex-
cept for PAS and PCEDT where a beam of size 4 worked
best for the open track, all other results were obtained for
beams of size 1. This situation is in total contradiction with
the large impact of beam previously observed for the arc stan-
dard strategy during the SPMRL?13 shared task and during
experiments led on the French TreeBank (Abeill? et al., 2003)
(FTB). Late experiments on the FTB using the attach and
pop actions (but delaying attachments as long as possible) has
On the other hand, it is worth noting that syn-
tactic features greatly improve semantic parsing.
In fact, we report in Figure 2(a) the improvement
of the five most frequent labels and, in Figure 2(b),
the five best improved labels with a frequency over
0.5% in the training set, which represent 95% of
the edges in the DM Corpus. As we can see, syn-
tactic information allow the systems to perform
better on coordination structures and to reduce am-
biguity between modifiers and verbal arguments
(such as the ARG3 label).
We observed the same behaviour on the PAS
corpus, which contains also predicate-argument
structures. For PCEDT, the results show that syn-
tactic features give only small improvements, but
the corpus is harder because of a large set of labels
and is closer to syntactic structures than the two
others.
Of course, we only scratched the surface with
our experiments and we plan to further investigate
the impact of syntactic information during seman-
tic parsing. We especially plan to explore the deep
parsing of French, thanks to the recent release of
the Deep Sequoia Treebank (Candito et al., 2014).
5 Conclusion
In this paper, we presented our results on the task
8 of the SemEval-2014 Task on Broad-Coverage
Semantic Dependency Parsing. Even though the
results do not reach state-of-the-art, they compare
favorably with other single systems and show that
syntactic features can be efficiently used for se-
mantic parsing.
In future work, we will continue to investigate
this idea, by combining with more complex sys-
tems and more efficient machine learning tech-
niques, we are convinced that we can come closer
to state of the art results. and that syntax is the key
for better semantic parsing.
Acknowledgments
We warmly thank Kenji Sagae for making his
parser?s code available and kindly answering our
questions.
References
Anne Abeill?, Lionel Cl?ment, and Fran?ois Toussenel.
2003. Building a Treebank for French. In Treebanks
confirmed a problem with beams, even if less visible. We are
still investigating why the use of the attach transitions and/or
of the pop transitions seems to be incompatible with beams.
100
Closed track
PCEDT LF UF
PEKING - BEST 76.28 89.19
S&T PARSER b5 67.83 80.86
DYALOG-SR b1 67.81 81.23
DM (MRS)
PEKING - BEST 89.40 90.82
S&T PARSER b5 78.44 80.88
DYALOG-SR b1 78.32 81.85
PAS (ENJU)
PEKING - BEST 92.04 93.13
S&T PARSER b5 82.44 84.41
DYALOG-SR b1 84.16 86.09
Open track
PCEDT LF UF
PRIBERAM - BEST 77.90 89.03
S&T PARSER b5 69.20 +1.37 82.68 +1.86
DYALOG-SR b4 69.58 +1.77 84.80 +3.77
DM (MRS)
PRIBERAM - BEST 89.16 90.32
S&T PARSER b5 81.46 +3.02 83.68 +2.80
DYALOG-SR b1 79.71 +1.39 81.97 +0.12
PAS (ENJU)
PRIBERAM - BEST 91.76 92.81
S&T PARSER b5 84.97 +2.53 86.64 +2.23
DYALOG-SR b4 85.58 +1.42 86.98 +0.87
Table 3: Results on section 21 (test) of the PTB for closed and open track.
60 70 80 90 100
ARG1
ARG2
compound
BV
poss
F-score S&T PARSER (%)
With Syntax
No Syntax
60 70 80 90 100
ARG1
ARG2
compound
BV
poss
40.2%
24.5%
11.7%
11.0%
2.4%
F-score DYALOG-SR (%)
(a) the 5 most frequent labels
20 40 60 80 100
conj
-and-c
appos
loc
ARG3
F-score S&T PARSER (%)
With Syntax
No Syntax
20 40 60 80 100
conj
-and-c
appos
loc
ARG3
0.6%
2.1%
0.8%
1.5%
1.3%
F-score DYALOG-SR (%)
(b) the 5 best improved labels (edges frequency above 0.5 % in the training set)
Figure 2: Improvement with syntactic features for DM (test) corpus.
(numbers indicate edge frequency in training set)
101
: Building and Using Parsed Corpora, pages 165?
188. Springer.
Daniel M. Bikel. 2002. Design of a multi-lingual,
parallel-processing statistical parsing engine. In
Proceedings of the second international conference
on Human Language Technology Research, pages
178?182. Morgan Kaufmann Publishers Inc. San
Francisco, CA, USA.
Anders Bj?rkelund, Ozlem Cetinoglu, Rich?rd Farkas,
Thomas Mueller, and Wolfgang Seeker. 2013.
(re)ranking meets morphosyntax: State-of-the-art
results from the SPMRL 2013 shared task. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 135?
145, Seattle, Washington, USA, October.
Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, COLING ?10, pages 89?97,
Stroudsburg, PA, USA.
Marie Candito, Guy Perrier, Bruno Guillaume,
Corentin Ribeyre, Kar?n Fort, Djam? Seddah, and
?ric De La Clergerie. 2014. Deep Syntax Anno-
tation of the Sequoia French Treebank. In Interna-
tional Conference on Language Resources and Eval-
uation (LREC), Reykjavik, Islande, May.
David Chiang, Jacob Andreas, Daniel Bauer,
Karl Moritz Hermann, Bevan Jones, and Kevin
Knight. 2013. Parsing graphs with hyperedge
replacement grammars. In Proceedings of the 51st
Meeting of the ACL.
Harold Charles Daume. 2006. Practical structured
learning techniques for natural language process-
ing. Ph.D. thesis, University of Southern California.
Yoav Goldberg, Kai Zhao, and Liang Huang. 2013.
Efficient implementation of beam-search incremen-
tal parsers. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics
(ACL), Sophia, Bulgaria, August.
Jan Hajic, Jarmila Panevov?, Eva Hajicov?, Petr
Sgall, Petr Pajas, Jan ?tep?nek, Ji?r? Havelka,
Marie Mikulov?, Zdenek Zabokrtsk`y, and
Magda ?evc?kov? Raz?mov?. 2006. Prague
dependency treebank 2.0. CD-ROM, Linguistic
Data Consortium, LDC Catalog No.: LDC2006T01,
Philadelphia, 98.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In
Proceedings of the 48th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 1077?
1086. Association for Computational Linguistics.
Angelina Ivanova, Stephan Oepen, Lilja ?vrelid, and
Dan Flickinger. 2012. Who did what to whom?:
A contrastive study of syntacto-semantic dependen-
cies. In Proceedings of the sixth linguistic annota-
tion workshop, pages 2?11.
Sandra K?bler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. Morgan and Claypool
Publishers.
John Langford, Lihong Li, and Tong Zhang. 2009.
Sparse online learning via truncated gradient. Jour-
nal of Machine Learning Research, 10(777-801):65.
Geoffrey Leech. 1992. 100 million words of English:
the British National Corpus. Language Research,
28(1):1?13.
Yusuke Miyao and Jun?ichi Tsujii. 2004. Deep
Linguistic Analysis for the Accurate Identification
of Predicate-Argument Relations. In Proceedings
of the 18th International Conference on Compu-
tational Linguistics (COLING 2004), pages 1392?
1397, Geneva, Switzerland.
Joakim Nivre, Johan Hall, Sandra K?bler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007a. The CoNLL 2007 shared task on
dependency parsing. In Proceedings of the CoNLL
Shared Task Session of EMNLP-CoNLL 2007, pages
915?932, Prague, Czech Republic, June.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, G?ls?en Eryi?git, Sandra K?bler, Svetoslav
Marinov, and Erwin Marsi. 2007b. MaltParser:
A language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13(2):95?135.
Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Dan Flickinger, Jan Haji
?
c, Angelina
Ivanova, and Yi Zhang. 2014. SemEval 2014 Task
8: Broad-coverage semantic dependency parsing. In
Proceedings of the 8th International Workshop on
Semantic Evaluation, Dublin, Ireland.
Naoaki Okazaki. 2009. Classias: A collection of ma-
chine learning algorithms for classification.
Adwait Ratnaparkhi. 1997. A simple introduction to
maximum entropy models for natural language pro-
cessing. IRCS Technical Reports Series, page 81.
Kenji Sagae and Jun?ichi Tsujii. 2008. Shift-reduce
dependency DAG parsing. In Proceedings of the
22nd International Conference on Computational
Linguistics (Coling 2008), pages 753?760, Manch-
ester, UK, August. Coling 2008 Organizing Com-
mittee.
Djam? Seddah, Reut Tsarfaty, Sandra K?bler, Marie
Candito, Jinho D. Choi, Rich?rd Farkas, Jen-
nifer Foster, Iakes Goenaga, Koldo Gojenola Gal-
letebeitia, Yoav Goldberg, Spence Green, Nizar
Habash, Marco Kuhlmann, Wolfgang Maier, Joakim
Nivre, Adam Przepi?rkowski, Ryan Roth, Wolfgang
Seeker, Yannick Versley, Veronika Vincze, Marcin
Woli
?
nski, Alina Wr?blewska, and ?ric Villemonte
De La Clergerie. 2013. Overview of the SPMRL
2013 shared task: A cross-framework evaluation of
102
parsing morphologically rich languages. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 146?
182, Seattle, Washington, USA, October.
Djam? Seddah. 2010. Exploring the spinal-stig
model for parsing french. In Proceedings of the
Seventh conference on International Language Re-
sources and Evaluation (LREC?10), Valletta, Malta,
may. European Language Resources Association
(ELRA).
?ric Villemonte De La Clergerie. 2013. Exploring
beam-based shift-reduce dependency parsing with
DyALog: Results from the SPMRL 2013 shared
task. In 4th Workshop on Statistical Parsing of Mor-
phologically Rich Languages (SPMRL?2013), Seat-
tle, ?tats-Unis.
Joachim Wagner, Djam? Seddah, Jennifer Foster, and
Josef Van Genabith. 2007. C-structures and F-
structures for the British National Corpus. In Pro-
ceedings of the Twelfth International Lexical Func-
tional Grammar Conference. Citeseer.
103
First Joint Workshop on Statistical Parsing of Morphologically Rich Languages
and Syntactic Analysis of Non-Canonical Languages, pages 103?109 Dublin, Ireland, August 23-29 2014.
Introducing the SPMRL 2014 Shared Task on Parsing
Morphologically-Rich Languages
Djame? Seddah
INRIA & Univ. Paris Sorbonne
Paris, France
djame.seddah@paris-sorbonne.fr
Sandra Ku?bler
Indiana University
Bloomington, IN, USA
skuebler@indiana.edu
Reut Tsarfaty
Weizman Institute
Rehovot, Israel
reut.tsarfaty@weizmann.ac.il
1 Introduction
This first joint meeting on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis
of Non-Canonical English (SPMRL-SANCL) featured a shared task on statistical parsing of morpholog-
ically rich languages (SPMRL). The goal of the shared task is to allow to train and test different partic-
ipating systems on comparable data sets, thus providing an objective measure of comparison between
state-of-the-art parsing systems on data data sets from a range of different languages. This 2014 SPMRL
shared task is a continuation and extension of the SPMRL shared task, which was co-located with the
SPMRL meeting at EMNLP 2013 (Seddah et al., 2013).
This paper provides a short overview of the 2014 SPMRL shared task goals, data sets, and evaluation
setup. Since the SPMRL 2014 largely builds on the infrastructure established for the SPMRL 2013
shared task, we start by reviewing the previous shared task (?2) and then proceed to the 2014 SPMRL
evaluation settings (?3), data sets (?4), and a task summary (?5). Due to organizational constraints,
this overview is published prior to the submission of all system test runs, and a more detailed overview
including the description of participating systems and the analysis of their results will follow as part of
(Seddah et al., 2014), once the shared task is completed.
2 The SPMRL Shared Task 2013
The SPMRL Shared Task 2013 (Seddah et al., 2013) was organized with the goal of providing standard
data sets, streamlined evaluation metrics, and a set of strong baselines for parsing morphologically rich
languages (MRLs). The goals were both to provide a focal point for researchers interested in parsing
MRLs and consequently to advance the state of the art in this area of research.
The shared task focused on parsing nine morphologically rich languages, from different typological
language families, in both a constituent-based and a dependency-based format. The set of nine typolog-
ically diverse languages comprised data sets for Arabic, Basque, French, German, Hebrew, Hungarian,
Korean, Polish, and Swedish. Compared to previous multilingual shared tasks (Buchholz and Marsi,
2006; Nivre et al., 2007), the SPMRL shared task targeted parsing in realistic evaluation scenarios, in
which the analysis of morphologically ambiguous input tokens is not known in advance. An additional
novelty of the SPMRL shared task is that it allowed for both a dependency-based and a constituent-
based parse representation. This setting relied on an intricate and careful data preparation process which
ensured consistency between the constituent and the dependency version by aligning the two representa-
tion types at the token level and at the level of part-of-speech tags. For all languages, we provided two
versions of the data sets: an all data set, identical in size to the one made available by the individual
treebank providers, and a small data set, with a training set of 5,000 sentences, and a test set of about 500
sentences. Controlling the set sizes across languages allows us to level the playing field across languages
and treebanks.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
103
The shared task also advanced the state of the art by introducing different levels of complexity in
parsing. In general, parsing is reduced to the parsing proper step, assuming gold segmentation of the
text into sentences and words as well as gold POS tags and morphological analyses. This is a serious
simplification of the task since especially in Semitic languages, the segmentation into input tokens is a
task that is best performed in combination with parsing because of the ambiguities involved.
The shared task deviated from this standard configuration by adding conditions in which more realistic
settings were given: In the gold setting, unambiguous gold morphological segmentation, POS tags, and
morphological features for each input token were given. In the predicted setting, disambiguated morpho-
logical segmentation was provided, but the POS tags and morphological features for each input segment
were not. In the raw setting, there was no gold information, i.e., morphological segmentation, POS tags
and morphological features for each input token had to be predicted as part of the parsing task. To lower
the entry cost, participants were provided with reasonable baseline (if not state-of-the-art) morphological
predictions (either disambiguated ? in most cases? or ambiguous prediction in lattice forms).
As a consequence of the raw scenario, it was not possible to (only) rely on the accepted parsing met-
rics, labeled bracket evaluation via EVALB1 (Black et al., 1991), Leaf-Ancestor (Sampson and Babarczy,
2003) for constituents and CONLL X?s Labeled/Unlabeled Attachment Score for dependencies (Buch-
holz and Marsi, 2006). When the segmentation of words into input tokens is not given, there may be
discrepancies on the lexical levels, which neither EVALB and LEAF-ANCESTOR nor LAS/UAS are pre-
pared to handle. Thus, we also used TedEval, a distance-based metric that evaluates a morphosyntactic
structure as a complete whole (Tsarfaty et al., 2012b). Note that given the workload brought to the par-
ticipants, we did not try to enforce function label evaluation for constituent parsing. We hope that further
shared tasks will try to generalize such an evaluation. Indeed, having predicted function labels would
ease labeled TEDEVAL evaluation and favor a full parsing chain evaluation. Nevertheless, the choice of
TEDEVAL allowed us to go beyond the standard cross-parser evaluation within one setting and approach
cross-framework (constituent vs. dependency (Tsarfaty et al., 2012a)) and cross-language evaluation,
thus pushing the envelope on parsing evaluation. Additionally, we performed a specialized evaluation of
multi-word expressions in the French treebank.
The SPMRL Shared Task 2013 featured seven teams who approached the dependency parsing task
and one team that approached constituent parsing. The best performing system (Bjo?rkelund et al., 2013)
in either framework consisted of an ensemble system, combining several dependency parsers or sev-
eral instantiations of a PCFG-LA parser by a (re-)ranker, both on top of state-of-the-art morphological
analyses. The results show that parser combination helps to reach a robust performance across lan-
guages. However, the integration of morphological analysis into the parsing needs to be investigated
thoroughly, and new, morphologically aware approaches are needed. The cross-parser, cross-scenario,
and cross-framework evaluation protocols show that performance on gold morphological input is signif-
icantly higher than that in more realistic scenarios, and more training data is beneficial. Additionally,
differences between dependency and constituents are smaller than previously assumed, and languages
which are typologically farthest from English, such as Semitic and Asian languages, are still amongst
the hardest to parse, regardless of the parsing method used.
3 SPMRL 2014 Parsing Scenarios
As in the previous edition, this year, we consider three parsing scenarios, depending on how much of the
morphological information is provided. The scenarios are listed below, in increasing order of difficulty.
? Gold: In this scenario, the parser is provided with unambiguous gold morphological segmentation,
POS tags, and morphological features for each input token.
? Predicted: In this scenario, the parser is provided with disambiguated morphological segmentation.
However, the POS tags and morphological features for each input segment are unknown.
? Raw: In this scenario, the parser is provided with morphologically ambiguous input. The morpho-
logical segmentation, POS tags, and morphological features for each input token are unknown.
1We extended the usualEVALB to penalize unparsed sentences.
104
Scenario Segmentation PoS+Feat. Tree
Gold X X ?
Predicted X 1-best ?
Raw (1-best) 1-best 1-best ?
Raw (all) ? ? ?
Table 1: A summary of the parsing and evaluation scenarios. X depicts gold information, ? depicts
unknown information, to be predicted by the system.
The Predicted and Raw scenarios require predicting morphological analyses. This may be done using
a language-specific morphological analyzer, or it may be done jointly with parsing. We provide inputs
that support these different scenarios:
? Predicted: Gold treebank segmentation is given to the parser. The POS tags assignment and mor-
phological features are automatically predicted by the parser or by an external resource.
? Raw (1-best): The 1-best segmentation and POS tags assignment is predicted by an external re-
source and given to the parser.
? Raw (all): All possible segmentations and POS tags are specified by an external resource. The
parser selects jointly a segmentation and a tree.
An overview of all scenarios is shown in table 1. For languages in which terminals equal tokens, only
Gold and Predicted scenarios are considered. For the Semitic languages, we further provide input for
both Raw (1-best) and Raw (all) scenarios.2
4 SPMRL 2014 Data Sets
The main innovation of the SPMRL 2014 shared task with respect to the previous edition is the availabil-
ity of additional, unannotated data, for the purpose of semi-supervised training. This section provides
a description of the unlabeled-data preparation that is required in the context of parsing MRLs, and the
core labeled data that is used in conjunction with it.
4.1 SPMRL Unlabeled Data Set
One of the common problems when dealing with morphologically rich languages (MRLs) is lexical data
sparseness due to the high level of variation in word forms (Tsarfaty et al., 2010; Tsarfaty et al., 2012c).
The use of large, unlabeled corpora in a semi-supervised setting, in addition to the relatively small MRL
data sets, can become a valid option to overcome such issues. For instance, using Brown clusters (Brown
et al., 1992) has been shown to boost the performance of a PCFG-LA based parser for French (Candito
and Crabbe?, 2009; Candito and Seddah, 2010). External lexical acquisition was successfully used for
Arabic (Habash, 2008) and Hebrew (Goldberg et al., 2009), self-training increased accuracy for parsing
German (Rehbein, 2011), and more recently, the use of word embeddings led to some promising results
for some MRLs (Cirik and S?ensoy, 2013).
By releasing large, unlabeled data sets and by providing accurate pre-annotation in a format directly
compatible with models trained on the SPMRL Shared Task treebanks, we hope to foster the development
of interesting and feature-rich parsing models that build on larger, morphologically rich, lexicons. Table
2 presents basic facts about the data sets. Details on the unlabeled data and their pre-annotations will
be provided in (Seddah et al., 2014). Note that we could not ensure the same volume of data for all
languages, nor we could run the same parser, or morphology prediction, on all data. Potential future work
could focus on ensuring a stricter level of comparability of these data or on investigating the feasibility
of such a normalization of procedures.
2The raw Arabic lattices were made available later than the other data. They are now included in the shared task release.
105
Language Source (main) type size (tree tokens) morph parsed
Arabic news domain news 120M X* X*
Basque web balanced 150M X X
French news domain newswire 120M X+mwe X*
German Wikipedia wiki (edited) 205M X X
Hebrew Wikipedia wiki (edited) 160M X X
Hungarian news domain newswire 100M X X
Korean news domain newswire 40M X X*
Polish Wikipedia wiki (edited) 100M X X
Swedish PAROLE balanced 24M X X
Table 2: Unlabeled data set properties.*: made available mid-july
4.2 SPMRL Core Labeled Data Set
In order to provide a faithful evaluation of the impact of these additional sets of unlabeled data, we used
the exact same data sets for training and testing as in the previous edition. Specifically, we used an Arabic
data set, originally provided by the LDC (Maamouri et al., 2004), in a dependency form, derived from the
Columbia Catib Treebank (Habash and Roth, 2009; Habash et al., 2009) and in a constituency instance,
following the Stanford pre-processing scheme (Green and Manning, 2010) and extended according to the
SPMRL 2013 extension scheme (Seddah et al., 2013). For Basque, the data was provided by Aduriz et
al. (2003) in both dependency and constituency, we removed sentences with non-projective trees so both
instances could be aligned at the token level. Regarding French, we used a new instance of the French
Treebank (Abeille? et al., 2003) that includes multi-word expression (MWE) annotations, annotated at the
morpho-syntactic level in both instances. Predicted MWEs were added this year, using the same tools as
Constant et al. (2013). The German data are based on the Tiger corpus (Brants et al., 2002), and converted
to constituent and dependency following (Seeker and Kuhn, 2012). The Hebrew data set is based on the
Modern Hebrew Treebank (Sima?an et al., 2001), with the Goldberg (2011) dependency version, in turn
aligned with the phrase structure instance described in (Tsarfaty, 2010; Tsarfaty, 2013). Note that in
order to match the Hebrew unlabeled data encoding, the Hebrew treebank was converted back to UTF-8.
The Hungarian data are derived from the Szeged treebank (Csendes et al., 2005; Vincze et al., 2010),
while the Korean data originate from the Kaist Treebank (Choi et al., 1994) which was converted to
dependency for the SPMRL shared task by Choi (2013). The Polish treebank we used is described in
(Wolin?ski et al., 2011; S?widzin?ski and Wolin?ski, 2010; Wro?blewska, 2012). Compared to the last year?s
edition, we added explicit feature names in the relevant data fields. The Swedish data originate from
(Nivre et al., 2006), we added function labels extracted from the original Swedish XML data. Note
that in addition to constituency and dependency versions, the Polish, German and Swedish data sets are
also available in the Tiger XML format (Mengel and Lezius, 2000), allowing a direct representation of
discontinuous structures in their phrase-based structures.
5 Conclusion
At the time of writing this short introduction, the shared task is ongoing, and neither results nor the final
submitting teams are known. At this point, we can say that 15 teams registered for the 2014 shared
task edition, indicating an increased awareness of and continued interest in the topic of the shared task.
Results, cross-parser and cross-data analysis, and shared task description papers will be made available
at http://www.spmrl.org/spmrl2014-sharedtask.html.
Acknowledgments
We would like to express our gratitude to the original treebank labeled and unlabeled data contribu-
tors for the considerable time they devoted to our shared task. Namely, Arabic: Nizar Habash, Ryan
Roth (Columbia University); Spence Green (Stanford University) , Ann Bies, Seth Kulick, Mohamed
Maamouri (the Linguistic Data Consortium) ; Basque: Koldo Gojenola, Iakes Goenaga (University of
the Basque Country) ; French: Marie Candito (Univ. Paris 7 & Inria), Djame? Seddah (Univ. Paris
Sorbonne & Inria) , Matthieu Constant (Univ. Marne la Valle?e) ; German: Wolfgang Seeker (IMS
106
Stuttgart), Wolfgang Maier (Univ. of Dusseldorf), Yannick Versley (Univ. of Tuebingen) ; Hebrew:
Yoav Goldberg (Bar Ilan Univ.), Reut Tsarfaty (Weizmann Institute of Science) ; Hungarian: Richa`rd
Farkas, Veronika Vincze (Univ. of Szeged) ; Korean: Jinho D. Choi (Univ. of Massachusetts Amherst),
Jungyeul Park (Kaist); Polish: Adam Przepio?rkowski, Marcin Wolin?ski, Alina Wro?blewska (Institute
of Computer Science, Polish Academy of Sciences) ; Swedish: Joakim Nivre (Uppsala Univ.), Marco
Kuhlmann (Linko?ping University).
We gratefully acknowledge the contribution of Spra?kbanken and the University of Gothenburg for
providing the PAROLE corpus. We are also very grateful to the Philosophical Faculty of the Heinrich-
Heine Universita?t Du?sseldorf for hosting the shared task data via their dokuwiki.
References
Anne Abeille?, Lionel Cle?ment, and Franc?ois Toussenel. 2003. Building a treebank for French. In Anne Abeille?,
editor, Treebanks. Kluwer, Dordrecht.
I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A. D??az de Ilarraza, A. Garmendia, and M. Oronoz. 2003.
Construction of a Basque dependency treebank. In Proceedings of the Second Workshop on Treebanks and
Linguistic Theories, pages 201?204, Va?xjo?, Sweden.
Anders Bjo?rkelund, Ozlem Cetinoglu, Richa?rd Farkas, Thomas Mueller, and Wolfgang Seeker. 2013. (Re)ranking
meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task. In Proceedings of the Fourth
Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 134?144, Seattle, WA.
Ezra Black, Steven Abney, Dan Flickinger, Claudia Gdaniec, Ralph Grishman, Philip Harrison, Donald Hindle,
Robert Ingria, Frederick Jelinek, Judith Klavans, Mark Liberman, Mitchell Marcus, Salim Roukos, Beatrice
Santorini, and Tomek Strzalkowski. 1991. A procedure for quantitatively comparing the syntactic coverage
of English grammars. In Proceedings of the DARPA Speech and Natural Language Workshop 1991, pages
306?311, Pacific Grove, CA.
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER treebank.
In Proceedings of the First Workshop on Treebanks and Linguistic Theories (TLT), pages 24?41, Sozopol,
Bulgaria.
Peter F. Brown, Vincent J. Della, Peter V. Desouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Class-based
n-gram models of natural language. Computational Linguistics, 18(4):467?479.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceed-
ings of CoNLL, pages 149?164, New York, NY.
Marie Candito and Beno??t Crabbe?. 2009. Improving generative statistical parsing with semi-supervised word
clustering. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT?09), pages
138?141, Paris, France.
Marie Candito and Djame? Seddah. 2010. Parsing word clusters. In Proceedings of the NAACL/HLT Workshop on
Statistical Parsing of Morphologically Rich Languages (SPMRL 2010), Los Angeles, CA.
Key-sun Choi, Young S. Han, Young G. Han, and Oh W. Kwon. 1994. KAIST Tree Bank Project for Korean:
Present and Future Development. In In Proceedings of the International Workshop on Sharable Natural Lan-
guage Resources, pages 7?14, Nara, Japan.
Jinho D. Choi. 2013. Preparing Korean data for the shared task on parsing morphologically rich languages.
arXiv:1309.1649.
Volkan Cirik and Hu?snu? S?ensoy. 2013. The AI-KU system at the SPMRL 2013 shared task: Unsupervised features
for dependency parsing. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich
Languages, pages 68?75, Seattle, WA.
Matthieu Constant, Marie Candito, and Djame? Seddah. 2013. The LIGM-Alpage architecture for the SPMRL
2013 shared task: Multiword expression analysis and dependency parsing. In Proceedings of the Fourth Work-
shop on Statistical Parsing of Morphologically-Rich Languages, pages 46?52, Seattle, WA.
Do?ra Csendes, Ja?nos Csirik, Tibor Gyimo?thy, and Andra?s Kocsor. 2005. The Szeged treebank. In Proceedings
of the 8th International Conference on Text, Speech and Dialogue (TSD), Lecture Notes in Computer Science,
pages 123?132, Berlin / Heidelberg. Springer.
107
Yoav Goldberg, Reut Tsarfaty, Meni Adler, and Michael Elhadad. 2009. Enhancing unlexicalized parsing per-
formance using a wide coverage lexicon, fuzzy tag-set mapping, and EM-HMM-based lexical probabilities.
In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL), pages 327?335, Athens,
Greece.
Yoav Goldberg. 2011. Automatic syntactic processing of Modern Hebrew. Ph.D. thesis, Ben Gurion University of
the Negev.
Spence Green and Christopher D. Manning. 2010. Better Arabic parsing: Baselines, evaluations, and analysis. In
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 394?402,
Beijing, China.
Nizar Habash and Ryan Roth. 2009. CATiB: The Columbia Arabic Treebank. In Proceedings of ACL-IJCNLP,
pages 221?224, Suntec, Singapore.
Nizar Habash, Reem Faraj, and Ryan Roth. 2009. Syntactic Annotation in the Columbia Arabic Treebank. In
Proceedings of MEDAR International Conference on Arabic Language Resources and Tools, Cairo, Egypt.
Nizar Habash. 2008. Four techniques for online handling of out-of-vocabulary words in Arabic-English statistical
machine translation. In Proceedings of ACL-08: HLT, Short Papers, pages 57?60, Columbus, OH.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic treebank: Build-
ing a large-scale annotated Arabic corpus. In Proceedings of NEMLAR International Conference on Arabic
Language Resources and Tools, pages 102?109, Cairo, Egypt.
Andreas Mengel and Wolfgang Lezius. 2000. An XML-based encoding format for syntactically annotated cor-
pora. In Proceedings of the Second International Conference on Language Resources and Engineering (LREC
2000), pages 121?126, Athens, Greece.
Joakim Nivre, Jens Nilsson, and Johan Hall. 2006. Talbanken05: A Swedish treebank with phrase structure and
dependency annotation. In Proceedings of LREC, pages 1392?1395, Genoa, Italy.
Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session
of EMNLP-CoNLL 2007, pages 915?932, Prague, Czech Republic.
Ines Rehbein. 2011. Data point selection for self-training. In Proceedings of the Second Workshop on Statistical
Parsing of Morphologically Rich Languages, pages 62?67, Dublin, Ireland.
Geoffrey Sampson and Anna Babarczy. 2003. A test of the leaf-ancestor metric for parse accuracy. Natural
Language Engineering, 9(04):365?380.
Djame? Seddah, Reut Tsarfaty, Sandra Ku?bler, Marie Candito, Jinho D. Choi, Richa?rd Farkas, Jennifer Foster, Iakes
Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolf-
gang Maier, Joakim Nivre, Adam Przepio?rkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika
Vincze, Marcin Wolin?ski, Alina Wro?blewska, and Eric Villemonte de la Clergerie. 2013. Overview of the
SPMRL 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages. In Pro-
ceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 146?182,
Seattle, WA.
Djame? Seddah, Reut Tsarfaty, Sandra Ku?bler, Marie Candito, Jinho Choi, Matthieu Constant, Richa?rd Farkas,
Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang
Maier, Joakim Nivre, Adam Przepiorkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze,
Marcin Wolin?ski, Alina Wro?blewska, and Eric Villemonte de la Cle?rgerie. 2014. Overview of the spmrl 2014
shared task on parsing morphologically rich languages. In Notes of the SPMRL 2014 Shared Task on Parsing
Morphologically-Rich Languages, Dublin, Ireland.
Wolfgang Seeker and Jonas Kuhn. 2012. Making Ellipses Explicit in Dependency Conversion for a German
Treebank. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pages
3132?3139, Istanbul, Turkey.
Khalil Sima?an, Alon Itai, Yoad Winter, Alon Altmann, and Noa Nativ. 2001. Building a tree-bank of Modern
Hebrew text. Traitement Automatique des Langues, 42:347?380.
Marek S?widzin?ski and Marcin Wolin?ski. 2010. Towards a bank of constituent parse trees for Polish. In Proceed-
ings of Text, Speech and Dialogue, pages 197?204, Brno, Czech Republic.
108
Reut Tsarfaty, Djame Seddah, Yoav Goldberg, Sandra Ku?bler, Marie Candito, Jennifer Foster, Yannick Versley,
Ines Rehbein, and Lamia Tounsi. 2010. Statistical parsing for morphologically rich language (SPMRL): What,
how and whither. In Proceedings of the First workshop on Statistical Parsing of Morphologically Rich Lan-
guages (SPMRL), Los Angeles, CA.
Reut Tsarfaty, Joakim Nivre, and Evelina Andersson. 2012a. Cross-framework evaluation for statistical parsing.
In Proceeding of EACL, Avignon, France.
Reut Tsarfaty, Joakim Nivre, and Evelina Andersson. 2012b. Joint evaluation for segmentation and parsing. In
Proceedings of ACL, Jeju, Korea.
Reut Tsarfaty, Djame? Seddah, Sandra Ku?bler, and Joakim Nivre. 2012c. Parsing morphologically rich languages:
Introduction to the special issue. Computational Linguistics, 39(1):15?22.
Reut Tsarfaty. 2010. Relational-Realizational Parsing. Ph.D. thesis, University of Amsterdam.
Reut Tsarfaty. 2013. A unified morpho-syntactic scheme of Stanford dependencies. In Proceedings of ACL, Sofia,
Bulgaria.
Veronika Vincze, Do?ra Szauter, Attila Alma?si, Gyo?rgy Mo?ra, Zolta?n Alexin, and Ja?nos Csirik. 2010. Hungarian
Dependency Treebank. In Proceedings of LREC, Valletta, Malta.
Marcin Wolin?ski, Katarzyna G?owin?ska, and Marek S?widzin?ski. 2011. A preliminary version of Sk?adnica?a
treebank of Polish. In Proceedings of the 5th Language & Technology Conference, pages 299?303, Poznan?,
Poland.
Alina Wro?blewska. 2012. Polish Dependency Bank. Linguistic Issues in Language Technology, 7(1):1?15.
109
