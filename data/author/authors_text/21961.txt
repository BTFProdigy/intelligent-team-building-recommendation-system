Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 36?46,
October 29, 2014, Doha, Qatar.
c?2014 Association for Computational Linguistics
Exploiting Language Variants Via Grammar Parsing Having
Morphologically Rich Information
Qaiser Abbas
Fachbereich Sprachwissenschaft
Universit?at Konstanz
78457 Konstanz, Germany
qaiser.abbas@uni-konstanz.de
Abstract
In this paper, the development and evalua-
tion of the Urdu parser is presented along
with the comparison of existing resources
for the language variants Urdu/Hindi. This
parser was given a linguistically rich
grammar extracted from a treebank. This
context free grammar with sufficient en-
coded information is comparable with the
state of the art parsing requirements for
morphologically rich and closely related
language variants Urdu/Hindi. The ex-
tended parsing model and the linguisti-
cally rich grammar together provide us
promising parsing results for both the lan-
guage variants. The parser gives 87% of
f-score, which outperforms the multi-path
shift-reduce parser for Urdu and a simple
Hindi dependency parser with 4.8% and
22% increase in recall, respectively.
1 Introduction
An Urdu invariant of Hindavi came into existence
during the muslim rule from 1206 AD to 1858
AD (Khan, 2006). They used Persian/Urdu script
for Urdu in contrast to the Devanagari script for
Hindavi. The informal versions of the two lan-
guage variants are quite similar, in fact so sim-
ilar that they can really be called dialects of a
same language. Loose examples would be how a
Spanish speaker could comprehend Portuguese or
Swedish speaker could comprehend Norwegian.
However the formal version of the two languages
will be much more different as Urdu vocabulary is
influenced heavily from Persian, Arabic and Turk-
ish whilst the emphasis in Hindi is on Sanskrit.
Urdu became a literary language after existence of
an increasing number of literature during the 18th
and the 19th century (McLane, 1970). Urdu/Hindi
is the national language of Pakistan and an official
language in India. According to a report by the
SIL Ethnologue (Lewis, 2013), Urdu/Hindi has
456.2 million speakers in the whole world.
Getting state of the art parsing results for mor-
phologically rich languages (MRLs) is a challenge
to date. According to Tsarfaty et al. (2010; 2013),
without proper handling of morphological entities
in the sentences, promising results for MRLs can
not be achieved. Complex morphosyntactic in-
teractions may impose constraints, which lead to
explicit encoding of such information. The best
broad coverage and robust parsers to date have
grammars extracted from treebanks and the depth
of information encoded in an annotation corre-
lates with the parsing performance (Tsarfaty et al.,
2013).
To fulfill the encoding of information in an
annotation, a treebank for Urdu known as the
URDU.KON-TB treebank with sufficient encoded
information at morphological, POS, syntactic and
functional level was constructed (Abbas, 2012).
Its annotation was found reliable according to the
Krippendorffs ? values achieved in (Abbas, 2014)
but its reliability or the suitability for machine
learning (ML) can be evaluated with the develop-
ment of an Urdu parser presented in Section 3. A
context free grammar (CFG) is extracted from the
URDU.KON-TB treebank computationally. The
development procedure and the depth of encoded
information in the grammar is presented in Section
2. The grammar is then given to an extended dy-
namic programming parsing model known as the
Earley parsing algorithm (Earley, 1970). The ex-
tended parsing model for Urdu is then called as
the Urdu parser and given in Section 3. This al-
gorithm is language independent and is capable
to parse the MRLs like the CKY (Cocke-Kasami-
Younger) parsing algorithm as advocated in (Tsar-
faty et al., 2013) and (Abbas et al., 2009). Issues
faced during the parsing are discussed in Section
4. By applying a rich grammar along with the ex-
36
tended parsing model, promising results obtained
are discussed in Section 5. Conclusions along with
the future directions are presented in Section 6.
Similarly, the related work of language variants is
described in Section 1.1, which set a path towards
the construction of the Urdu parser.
1.1 Related Work
In the Urdu ParGram project (Butt and King,
2007), the XLE
1
parser is in use. The encoding
of LFG grammar in XLE interface is not a sim-
ple task. Such a grammar can be encoded only
by those persons who have expertise in theoreti-
cal linguistics as well. The team of the ParGram
project has made a tremendous effort in this re-
gard. This project of Urdu LFG grammar develop-
ment is still in progress and the parser evaluation
results are not available yet. Similarly, the parser
for evaluation of the NU-FAST treebank (Abbas
et al., 2009) used a built in utility available in the
inference engine of the Prolog to parse the Urdu
sentences. This utility can only be used if you
have a definite clause grammar (DCG) or proba-
bilistic definite clause grammar (PDCG). In this
work, a parser was not designed but a built-in pro-
log parser was used, due to which it was not con-
sidered to be the candidate for comparison.
A simple dependency parser for Hindi was de-
veloped by Bharati et al. (2009). The parser used
a grammar oriented approach, which was designed
on the basis of Paninian grammatical model (Be-
gum et al., 2008; Bharati et al., 1995). The annota-
tion scheme was designed on the basis of chunks,
intra-chunks and karakas
2
. This scheme (Be-
gum et al., 2008) of dependency structure (DS)
is different from the annotation scheme (Abbas,
2012; Abbas, 2014) of phrase structure (PS) and
the hyper dependency structure (HDS) of the
URDU.KON-TB treebank along with the different
data sets used. As compared to phrase/constituent
structure, the dependency structure lacks in infor-
mation at non-terminal nodes (Bharati et al., 2008)
and often the information at POS level. This infor-
mation can also be provided at dependency anno-
tation but people are stick to the standard norms.
The Hindi treebank is rich in functional informa-
tion as compared to morphological, POS and syn-
tactical information. Due to differences in the de-
1
http://www2.parc.com/isl/groups/nltt/xle/
2
Karakas are the syntactico-semantic relations between
the verbs and other related constituents in a sentence (Bharati
et al., 1996)
signs of the simple dependency parser for Hindi
and the Urdu parser, only performance results are
compared and presented in Section 5.
Ali and Hussain used the MaltParser with its de-
fault settings in Urdu dependency parser (Ali and
Hussain, 2010). When somebody performs ex-
periments with MaltParser with its default settings
then such evaluation results are advised not to be
compared according to MaltParser license.
3
The
same exercise for parsing Hindi was performed
in (Agrawal et al., 2013), but it was clearly men-
tioned in the work that MaltParser was used for
error detection in the annotation of Hindi/Urdu
treebank (HUTB).
4
Similarly, the Urdu sentences
were parsed in (Bhat et al., 2012b) using the same
MaltParser. The experiments were performed to
identify the parsing issues of Urdu and a devel-
opment of parser was not claimed. Moreover,
these data-driven systems are highly criticized on
a given set of annotated corpus because they are
not able to observe all morphological variants of a
word form from it (Tsarfaty et al., 2013).
A multi-path shift-reduce parsing algorithm was
proposed in (Jiang et al., 2009) for Chinese. Later
on, this algorithm was used for Urdu parsing by
Mukhtar et al. (2012b). A probabilistic context
free grammar (PCFG) developed in (Mukhtar et
al., 2011) was given to the multi-path shift-reduce
Urdu parsing model. A multi-path shift-reduce
parser for Urdu has some limitations. It takes a
POS tagged sentence as input and is not able to
parse sentences without the POS tagging. The
stack used has a fixed memory size, which is not
reliable and it can overflow during the parsing
of long sentences. A PCFG used in this parsing
model is ambiguous (Mukhtar et al., 2012a). Both
the fixed memory size and the ambiguous gram-
mar can resist the parsing of long sentences,thats
why the parser could not parse the sentences
with length more than 10 words (Mukhtar et al.,
2012b). In this work, the results were not evalu-
ated properly by using some measure e.g. PAR-
SEVAL. A number of 74 sentences having length
not more than 10 words were parsed successfully
from 100 sentences, which were then quoted as a
74% of accuracy. The raw corpus used in the de-
velopment of this parser is partially the same as
compared to the Urdu parser (Section 3). A com-
parative study made is detailed in Section 5.
3
http://www.maltparser.org/
4
http://faculty.washington.edu/fxia/treebank/
37
Figure 1: A verb V example from the URDU.KON-TB treebank
2 Setup
The URDU.KON-TB treebank having phrase
structure (PS) and the hyper dependency struc-
ture (HDS) annotation with rich encoded informa-
tion (Abbas, 2012; Abbas, 2014) is used for the
training of the Urdu parser discussed in Section 3.
The treebank has a semi-semantic POS (SSP) tag
set, a semi-semantic syntactic (SSS) tag set and a
functional (F) tag set. The morphological infor-
mation in the labeling of the parsers lexicon can
be explained by discussing the POS tag set of the
URDU.KON-TB treebank.
The SSP tag set hierarchy has 22 main tag cate-
gories which are divided into sub-categories based
on morphology and semantics. In Figure 1, an ex-
ample of only a verb V is given. A dot ?.? symbol
is used for the representation of morphology and
semantics at POS level. In Figure 1, the hierarchy
of tag labels for verb V is divided into three lev-
els of depth. The first level contains only one la-
bel to distinguish a verb V from other POS labels.
The second level contains 11 subcategories of V
to represent different morphological or functional
forms e.g. V.COP (V as a copula verb (Abbas and
Raza, 2014)), V.IMPERF (V has an imperfective
form (Butt and Rizvi, 2010; Butt and Ramchand,
2001)), V.INF (V has an infinitive form (Butt,
1993; Abbas and Nabi Khan, 2009)), etc. The
third level contains further 25 subcategories to rep-
resent the morphological information in depth e.g.
V.COP.IMPERF (copula verb has an imperfective
form), V.COP.PERF (copula verb has a perfective
form), V.COP.ROOT (copula verb has a ROOT
form), V.COP.PAST (copula verb has a past tense),
V.LIGHT.PAST (light verb has a past tense (Butt
and Rizvi, 2010; Butt, 2003)), etc. These types of
combinations are also possible in case of an auxil-
iary verb as described in (Abbas, 2014). This short
discussion is about the idea of morphological and
functional information encoded at POS level. This
lexical information can be passed up to the syn-
tactical level because the lexical items have some
relationship with other lexical items in a sentence.
The detail of syntactic (SSS) and functional (F) tag
sets can be seen in (Abbas, 2012).
A stack based extraction Algorithm 1 was de-
signed to extract a context free grammar (CFG)
from the URDU.KON-TB treebank. The CFG ob-
tained is then given to the Urdu parser (Section 3)
for sentence parsing.
3 Urdu Parser
The URDU.KON-TB treebank is a manually an-
notated set of 1400 parsed sentences, which were
then recorded in a text file on a computer in the
form of 1400 bracketed sentences. Initial twenty
bracketed-sentences from each hundred were sep-
arated in another text file, whose total 280 sen-
tences were then used for the development of a
test suite. The test suite was further divided into
two halves representing test data and held out data
resulting in 140 sentences in each half.
The held out data was used in the development
of the Urdu parser, while the test data was used for
the evaluation of results after the completion of the
Urdu parser. From the first residual text file with
1120 bracketed sentences, a context free grammar
(CFG) was extracted using a stack based extrac-
tion module given in Algorithm 1. The CFG was
then processed by the Urdu parser to produce a
grammar database with unique productions. Dur-
ing this process, production type (TYPE) labeling
38
as lexical (L) and non-lexical (NL) at the end of
each production was done. The productions hav-
ing only the lexical items at their right hand side
(RHS) were labelled as L and the productions con-
taining non-lexical items on their RHS only were
labelled as NL. The purpose of this labeling is to
provide an already processed mechanism, through
which the Urdu parser can identify a production
type L or NL speedily without checking it thor-
oughly.
Algorithm 1 A CFG extraction algorithm
Input: A input and an empty output file
1: (Sentence, Top, Counter)? 0
2: Read: InputString
3: while InputString 6= Input.EOF () do . Loop until end of file
4: if InputString = $ then
5: Print: + + Sentence
6: Read: InputString . Read a string from an input file
7: Write: \n \n . Writing two newlines in output file
8: (Stack[0], StrArray[0])? ? . Initializing stack and array
9: (Top, Counter)? 0 . Initializing stack and array variables
10: end if
11: if InputString 6= ?)? then
12: Stack[Top]? InputString;Top++
13: else . When ?)? comes
14: Top??
15: while Stack[Top] 6= ?(? do
16: StrArray[Counter] = Stack[Top]
17: Stack[Top] = ?; Counter ++; Top??
18: end while
19: Counter ??
20: Stack[Top] = StrArray[Counter]
21: Top++ and Check = Counter
22: while Counter ? 0 do
23: if Counter = Check then
24: Write: StrArray[Counter] ?;
StrArray[Counter] = ?
25: else
26: Write: StrArray[Counter] + ??;
StrArray[Counter] = ?
27: end if
28: Counter ??
29: end while
30: Write: \n; Counter = 0 . In output file
31: end if
32: Read: InputString . Read a string from an input file
33: end while
Output: An output file having complete CFG productions for each sentence
Without handling the issues discussed in Sec-
tion 4, the Earley?s algorithm simply was not
able to provide the state of the art evaluation re-
sults for Urdu. These issues caused the pars-
ing discontinuities, due to which extensions are
made on the basic algorithm. The extended ver-
sion of the Urdu parser is depicted in Algorithm
2. The grammar database of the Urdu parser
has three fields in the form of a left hand side
(LHS), a RHS and a TYPE. After taking a sen-
tence as input, variables are initialized along with
a starting value of the chart as ROOT @ S. In
place of a dot symbol ??? used in the Earley al-
gorithm, here an ?@? symbol is used because
the dot symbol is extensively used in the hier-
archal annotation of the URDU.KON-TB tree-
bank, from which the grammar productions are
extracted. The working of the algorithm is simi-
lar to the Earley?s algorithm except the modifica-
tions in the PREDICTOR(), SCANNER() and
a COMPLETER() presented in Sections 4.1, 4.2
and 4.7, respectively. Besides these some addi-
tional functions are introduced like an EDITOR()
for an automatic editing of discontinuous parses,
a BUILDER() for building the parse trees and
a BACKPOINTER() for calculating the back-
pointers.
Algorithm 2 Urdu Parser
1: function URDU-PARSER(grammar)
2: Input: Sentence . reading a sentence
3: (id, fi, fj, fid)? 0
4: chart[0].add(?id?, ?ROOT @ S?, ?0,0?, ? ?, ?Seed?)
5: for i? 0 to LENGTH(sentence[]) do
6: scannerF lag ? false, id? 1
7: Print: chart[i] ? (StateId, Rule, @Position, BackPointer, Op-
eration)
8: for j ? 0 to ChartSize[i] do . Loop for chart entries
9: currentRule? chart[i].getRule(j).split(? ?)
10: (tempString, index) ?(string-after-@, @Position) in
currentRule
11: if tempString = ? ? then
12: call COMPLETER() . calling completer procedure
13: else
14: rs? All grammar rules with LHS = tempString
15: if rs.next() 6= false then . checking rs is not empty
16: call PREDICTOR() . calling predictor procedure
17: else
18: call SCANNER()
19: end if
20: end if
21: if scannerF lag=false & j+1=chartSize[i] &
i 6=LENGTH(sentence[]) then
22: call EDITOR()
23: end if
24: end for
25: end for
26: call BUILDER()
27: end function
During processing of
COMPLETER(), PREDICTOR() and
SCANNER(), some sort of parsing disconti-
nuities can happen. To check these types of
phenomena, an EDITOR() will come into an ac-
tion and it will remove all the faulty states and the
charts causing discontinuity up to a right choice of
parsing as discussed in Section 4.6. At the end of
external loop, the generated parsed-solutions have
been stored in the form of the charts with entries,
but not in the form of parsed trees. To represent
parsed solutions in the form of bracketed parsed
trees, a BUILDER() function will be executed,
which will construct the parsed trees of solutions
by manipulating the back-pointers calculated in
the COMPLETER() function. The BUILDER()
is able to display all parsed solutions of a given
sentence as discussed in Section 4.4 and then the
Algorithm 2 for the Urdu parser is exited with
the complete generation of charts and bracketed
parsed trees. The algorithms called by the Urdu
39
parser are discussed briefly in Section 4 along
with their issues.
4 Issues Analysis and Their Evaluation
Through Extensions
4.1 Eliminating L Type Useless Predictions
Earley?s Predictor() adds useless productions in
charts which causes the Urdu parser to end up with
a discontinuous parse for a given sentence. Sup-
pose, the current token to be parsed in an input
sentence is a proper noun
	
?A
	
g ?Khan? and there is
a NL type production NP?@ N.PROP N.PROP
residing in the current chart of the parser, where
N.PROP is the tag for proper noun. The ?@?
symbol before a non-terminal on the RHS of the
production is the case of predictor and the non-
extended PREDICTOR() adds all the available L
type productions of N.PROP into the chart from
the grammar, even they are not required. Only
the relevant production N.PROP ? @
	
?A
	
g has
to be added in the chart. This addition of irrele-
vant/useless productions is also true for other lex-
ical items e.g. adjectives, personal pronouns, case
markers, etc. These useless additions cause the
wastage of time and increase the chance of mis-
leading direction towards a discontinuous parse.
To resolve this issue, the PREDICTOR() of the
existing Earley?s Algorithm is modified in the
Urdu parser as follows.
When the main parsing Algorithm 2 calls the
extended PREDICTOR() then it checks the type
of production either as NL or L in contrast of the
Earley algorithm. The handling of NL type pro-
ductions is same but in dealing of L type of pro-
ductions, the PREDICTOR() is introduced with
another condition, which enforces the predictor to
add only the relevant productions into the respec-
tive charts. It matches the token at the RHS of
the predicted-production with the current token in
an input sentence. This condition eliminates the
limited possibility of misleading direction towards
the discontinuous state. The wastage-time factor
is reduced to O(n) after the removal of irrelevant
matching, where n is the number of tokens in an
input sentence.
4.2 Irrelevant POS Selection
In the Earley?s parsing algorithm, the
Scanner() only matches the RHS of the
L type production with the current token in a
given sentence and causes a selection of L type
production with the wrong POS. For example, the
verb ??
f
?is? has different tags in the grammar. It
can act as an auxiliary in a sentence with present
tense e.g. VAUX.PRES ? ??
f
. It can behave as
a copula verb e.g. V.COP.PRES ? ??
f
and it can
also act as a main verb e.g. V.PRES ? ??
f
. This
concept of having more than one tag is true for
other lexical items. So, if this L type production
VAUX.PRES? @ ??
f
is existed in a current chart
as right candidate then the Scanner() of the
Earley algorithm can select other available pro-
ductions from the grammar due to a check on the
RHS only. This can cause the wrong solution or a
discontinuous state during the parsing. To remove
this issue, the Scanner() is extended in the
same way as was done with the PREDICTOR()
in Section 4.1. At this level, this solution solves
the issue described below, but it is completed in
Section 4.6.
When the SCANNER() is called, it extracts a
relevant L type production from the grammar af-
ter matching the LHS and the RHS completely. It
adds only the true L type production in a new chart
after checking three additional conditions. At first,
it checks that the chart number is not exceeding the
length of a sentence. At second, it checks that the
token in the current processing L type production
is equal to the current token in a given sentence.
After that if the scannerFlag is false, then the
new entry of the matched L type production is
added into the new chart. During this process, the
scannerFlag is set to a true value along with
a record of some variables fi, fj, and fid,
which will be used in the EDITOR() discussed
in Section 4.6. By introducing this modification,
the possibility of wrong selection of the produc-
tion from the grammar is abandoned. An issue
related to this problem is still remained, which is
addressed and resolved in Section 4.6.
4.3 Back-Pointers Calculation
Earley parsing algorithm is a generator or a rec-
ognizer and hence can not produce the parse trees
or the bracketed trees. To produce the parse trees
or the bracketed trees, an unimplemented idea of
back-pointers by Earley (1968) is implemented
and presented in Algorithm 3. To understand the
calculation of the back pointers, a sentence given
in example 1 is parsed from the Urdu parser. The
charts generated through the Urdu parser are de-
picted in Figure 2. Only the relevant states are dis-
40
played as can be inferred from the non-sequential
values of the STATEID column. The column
DOT-POSITION is basically the position of ?@?
in productions.
Algorithm 3 Back Pointer
1: function BACKPOINTER(previousRule, dummy@Position, i, chartSize, chart)
2: backPointer ? ??
3: tempIndex? previousRule.indexOf(?@?)
4: tempIndex? tempIndex-1 . subtracting index
5: NT ? previousRule.get(tempIndex)
6: k ? dummy@Position[0]
7: for l? i to k step -1 do . loop for backward backpointers
8: if tempIndex > 0 then
9: for m? 0 to chartSize[l]-1 do
10: pString ? chart[l].getRule(m).split(? ?)
11: cRule.add(pString[]) . store pString in cRule
12: tIndex? cRule.indexOf(?@?)
13: if (NT = cRule[0]) & (tIndex+1 = SIZE(cRule)) then
14: backPointer ? (l + ?-? +
chart[l].getStateId(m) +? ?+backPointer)
15: dummy@P = chart[l].get@Position(m).split(?,?)
. getting ?@? position
16: l? dummy@P [0] . updating loop counter l
17: l? l + 1
18: tempIndex? tempIndex-1
19: NT ? previousRule[tempIndex]
20: break
21: else
22: cRule.clear()
23: end if
24: end for
25: else
26: break
27: end if
28: end for
29: end function
(1) ??
f
?P?Q?
	
? ?A?
f
E


???K
.
Q?
	
X A?
	
?@
un
their/P.PERS
kA
of/CM
zikr
reference/N
bHI
also/PT.INTF
yahAN
here/ADV.SPT
zarUrI
essential/ADJ.MNR
hE
is/V.COP.PRES
?Their reference is also essential here?
The COMPLETER() calls the Algorithm 3 of
BACKPOINTER() to calculate the values of the
back-pointers. For example, during the process-
ing of a production KP.POSS P.PERS @ CM
at STATEID 3 in chart 1 of Figure 2, a pro-
cessed non-terminal P.PERS before the ?@? in
the RHS of the production is located in the
chart 1 at 0
th
position. The located ?1-0? value
of the backPointer is then displayed by the
COMPLETER() in the same state of the chart.
The rest of the back pointers are calculated in the
same way. These back-pointers are further used
in building the bracketed parse trees discussed in
Sections 4.4 and 4.7.
4.4 Building Bracketed Parse Trees
The possible bracketed parse trees are evaluated
and displayed by the BUILDER() function dis-
played in Algorithm 4. Both the BUILDER() and
Algorithm 4 Builder
1: function BUILDER(Sentence[], chartSize[], chart[])
2: num=0, chartN = LENGTH(Sentence[])
3: for count ? chartSize[LENGTH(Sentence[]]-1 to 0 step -1
do
4: dummystr ??S? and rule ?
chart[chartN ].getRule(count).split(? ?)
5: if rule[0] = dummystr then
6: num = num+ 1
7: bp.add(chartN+?-?+chart[chartN ].getStateId(count))
8: end if
9: end for
10: tree[]? new BTree[num]
11: for i? 0 to SIZE(bp)-1 do
12: tree[i].build(bp.get(i), chart) . building tree with pointers
13: end for
14: for i?0 to SIZE(bp)-1 do
15: tree[i].prepare(chart)
16: end for
17: for i?0 to SIZE(bp)-1 do . loop for displaying all parsed trees
18: bracketedSentenceLength ? tree[i].getSize() and
left? 0
19: if bracketedSentenceLength > 0 then
20: Print : Bracketed Parse Tree ?+(i+1)+? of ?+SIZE(bp)+?
21: for j ?0 to bracketedSentenceLength-1 do
22: if tree[i].getString(j) = ?(? then
23: left = left+ 1 and Print : newline
24: for tab?0 to left-1 do
25: Print : eight spaces
26: end for
27: Print : tree[i].getString(j)
28: else if tree[i].getString(j) = ?)? then
29: left = left? 1 and Print : tree[i].getString(j)
30: else
31: Print : space+tree[i].getString(j)+space
32: end if
33: end for
34: end if
35: end for
36: end function
the BACKPOINTER() contribute to shift our Al-
gorithm 2 from a generator to a parser in contrast
of the Earley?s algorithm. After displaying chart
entries in Figure 2 for a sentence given in exam-
ple 1, the Urdu parser calls the BUILDER(). At
first, it locates all the solution productions from
the last chart and stores their back-pointers in a
list e.g. ?8-1? value for the solution production
ROOT S @ in the last chart of Figure 2. A user
defined method build() is called then. This
method builds an unformatted intermediate brack-
eted parse tree with the interlinked back-pointers
from the chart states and reveals the leaf nodes
only as ( 8-1 ( 4-1 ( 2-2 ( 1-0
	
?@ ) ( 2-0 A? ) ) ( 3-0 Q?
	
X )
( 4-0 ???K
.
) ) ( 5-1 ( 5-0 ?A?
f
E


) ) ( 6-1 ( 6-0 ?P?Q?
	
? ) ) ( 7-1
( 7-0 ??
f
) ) ( 8-0 . ) ). This intermediate parse tree can
be understood well by looking at the given back-
pointers in the respective chart states.
Another user defined method prepare() pre-
pares the intermediate parse tree into a com-
plete unformatted parse tree as ( S ( NP.NOM-SUB
( KP.POSS ( P.PERS
	
?@ ) ( CM A? ) ) ( N Q?
	
X ) ( PT.INTF ???K
.
) ) ( ADVP-SPT-MODF ( ADV.SPT ?A?
f
E


) ) ( ADJP-MNR-
41
Figure 2: A back-pointer calculation example of the Urdu parser
PLINK ( ADJ.MNR ?P?Q?
	
? ) ) ( VCMAIN ( V.COP.PRES
??
f
) ) ( M.S . ) ) . This prepare() method only re-
places the back-pointers with the LHS of the rele-
vant productions. Finally, the bracketed parse tree
is displayed in a formatted way as depicted in Fig-
ure 3.
Figure 3: An output of the BUILDER() method
4.5 Empty Productions
Empty productions are divided into two cate-
gories. The first one is related to diacritic produc-
tions and the second one is related to non-diacritic
productions. It can cause the discontinuity during
the parsing because the lexical item may or may
not present for both the categories in a given sen-
tence. Only the first category of diacritic produc-
tions is discussed here to provide an idea about the
issues related to empty productions.
In modern Urdu, the diacritics may or may not
appear in the text e.g.

HA

J



k H
.


@ AbE h2ayAt ?The
water of life? and

AJ
.
K


Q


?

K taqrIban ?almost?. The
first example is related to compound words and
the second one is an independent word. The zErE-
Iz3Afat (a diacritic for addition) under the last let-
ter H
.

b of the first word in the first example is
still in use in the modern Urdu writing. Similar
is the case of tanwin (a diacritic for final post-
nasalization) on the last letter

@ a in the second
example. There are also other diacritics in use as
well e.g. zEr, zabar, pEsh, taSdId, etc.
In the grammar of the Urdu parser, a DIA
tag is used to represent the diacritics e.g. DIA
? *, where ?*? represents the absence of a di-
acritic or an empty production. During parsing,
a compound word may or may not appear with
a diacritic e.g.???Q?
f
D

? Sehr makkah ?The city of
42
Makkah?. This example has two words Q?
f
D

? Sehr
?city? and the ??? makkah ?Makkah?, but the dia-
critic is absent between the two words. In such
cases, its presence is by default understood by the
native speakers. The production extracted from
the grammar to handle this compound word is
the NP-SPT ? @ N.SPT DIA N.PROP.SPT. Af-
ter processing of the first word Sehr/N.SPT by
the SCANNER(), the production becomes NP-
SPT ? N.SPT @ DIA N.PROP.SPT. Now, the
PREDICTOR() deals this DIA empty produc-
tion implicitly by moving the ?@? ahead and
adds the updated production NP-SPT ? N.SPT
DIA @ N.PROP.SPT in the same chart. Sim-
ilarly, the second word makkah/N.PROP.SPT is
processed by the SCANNER() and the production
final state becomes like this NP-SPT ? N.SPT
DIA N.PROP.SPT @. The problem with this so-
lution adopted from (Aycock and Horspool, 2002)
is that it performs the transaction silently with the
compound words and also with the non-compound
words at such positions where it is not needed. For
example, If this is the case as discussed then the
solution is perfect, but in the case of the non com-
pound words, if two independent words Q?? gHar
?The house? and ??? makkah ?Makkah? appear in
the same position like compound words e.g. ??
f
?



?
??? Q?? gHar makkah mEN hE ?The house is in
Makkah?, then this solution can not identify the
context and it applies the transaction in the same
way due to the same POS tagging of gHar and the
Sehr. This solution causes frequent discontinuity
during the parsing and its property of self deci-
sion at the irrelevant places makes the things more
worse.
Due to high frequency of the DIA produc-
tions in the grammar, the proposed solution (Ay-
cock and Horspool, 2002) was implemented in
the PREDICTOR() but the results found were not
promising. So, an explicit method to represent the
absent value has been chosen, through which an
asterisk ?*? is usually typed in a given sentence to
represent the absence of the diacritics, arguments,
lexical items, etc. At present, due to this explicit
approach, the Urdu parser is jelling with the gram-
mar without any issue related to empty produc-
tions.
4.6 Lexical Dynamic Behavior
The issue is related to a class of words which
has the following attributes like the homonym,
homograph, homophone, heteronym and the pol-
ysemes. A strict definition is considered to these
attributes, that means at least the words have the
same spelling. The case of homonym words in a
strict sense is discussed here and the same concept
is applicable on other attributes as well.
For example, the word ?? kI is a homonym in
Urdu. It can behave in two ways e.g. a pos-
sessive case marker and a verb. Being a posses-
sive case marker, it contains a possessive meaning
?of? in 2. On the other hand, it contains a mean-
ing of ?did? in 3. In the grammar, this word has
different POS tags as a case marker (CM), a per-
fective verb (V.PERF) and a perfective light verb
(V.LIGHT.PERF). Suppose the word ?kI? actually
comes as a V.PERF at the end of a given sen-
tence. For its processing, the Scanner() can
pick up the wrong choice with the CM and the
V.LIGHT.PERF, if these choices are available in
the current chart at earlier positions as compared
to the right choice. Due to this wrong selection,
the relevant productions of a verb will not be com-
pleted in the next chart and the parser will go into
the discontinuous state. To address this issue, the
Scanner() of the Earley algorithm is modified,
which records the failed state in variables fi, fj
and fid. These failed states are then utilized by
the EDITOR() in Algorithm 5, which is called
by the Urdu parser to heal this discontinuous state.
The failed chart and the states are deleted first. Af-
ter skipping the wrong choice e.g. the CM? ?? in
a chart, the next choice from available homonyms
is selected and tried to parse. In this way, the next
choice V.PERF ? ?? is located and the i
th
and
j
th
loop variables of the Urdu parser are set to that
choice for further processing. Continuing in this
way, the parser finally gets a direction towards the
optimal solution.
Algorithm 5 Editor
1: function EDITOR(i, id, fi, fj, fid, chart, chartSize)
2: Drop and re-initialize chart[i+ 1]
3: for z ? i to fi+1 step -1 do
4: Drop and re-initialize chart[z]
5: end for
6: rule? chart[fi].getRule(fj).split(? ?) . splitting rule with space
7: for z ? 0 to chartSize[fi]-1 do
8: temprule? chart[fi].getRule(z).split(? ?)
9: if temprule[2] = rule[2] then
10: if !(temprule[0] = rule[0]) then
11: j ? z ? 1, i? fi, id? z
12: break
13: end if
14: end if
15: end for
16: end function
(2) H
.
A

J? ?? AJ


??k
.
43
jUlIA=kI
Julia.Fem.Sg=Poss
kitAb
book.Fem.Sg
?The book of Julia?
(3) ??
f
??

HAK
.
?K


@ ?
	
LAW VIII - The 8th Linguistic Annotation Workshop, pages 75?81,
Dublin, Ireland, August 23-24 2014.
Semi-Semantic Part of Speech Annotation and Evaluation
Qaiser Abbas
Fachbereich Sprachwissenschaft
Universit?at Konstanz
78457 Konstanz, Germany
qaiser.abbas@uni-konstanz.de
Abstract
This paper presents the semi-semantic part of speech annotation and its evaluation via Krip-
pendorff?s ? for the URDU.KON-TB treebank developed for the South Asian language Urdu.
The part of speech annotation with the additional subcategories of morphology and semantics
provides a treebank with sufficient encoded information. The corpus used is collected from the
Urdu Wikipedia and news papers. The sentences were annotated manually to ensure a high an-
notational quality. The inter-annotator agreement obtained after evaluation is 0.964, which lies
in the range of perfect agreement on a scale. Urdu is comparatively an under-resourced language
and the development of the treebank with rich part of speech annotation will have significant
impact on the state-of-the-art for Urdu language processing.
1 Introduction
Urdu, an invariant of Hindavi came into existence during the muslim rule from 1206 AD to 1858
AD (Khan, 2006). They used Persian/Urdu script for Urdu in contrast of the Devanagari script for Hin-
davi. Urdu became a literary language after existence of an increasing number of literature during 18th
and 19th century (McLane, 1970). Hindi/Hindavi is a close language to Urdu except the script writing
style and the differences in the formal and informal versions. Urdu is the national language of Pakistan
and an official language in India. According to a report by SIL Ethnologue (Lewis, 2013), Urdu/Hindi
has 456.2 million speakers in the whole world. Urdu is a morphologically rich language (MRL) and in
need of a number of resources to compete in the race of computational resources.
The design of the part of speech (POS) annotation scheme depends upon the need. If the people
want to do text processing, text mining, etc., then they might be interested in a limited POS annotation
scheme. However, the people who are interested in language parsing, then a POS annotation scheme
with rich information is needed. Getting state-of-the-art parsing results for a MRL is a challenge till to
date. According to Tsarfaty et. al. (2013; 2010), without proper handling of morphological entities in
the sentences, promising results for MRLs can not be achieved and the depth of information encoded
in an annotation correlates with the parsing performance. The best broad coverage and robust parsers
to date have grammars extracted from the treebanks, which are a collection of syntactically annotated
sentences by humans. The problem statement described requires an explicit encoding of morphological
information at the POS level and the treebanks with sufficient encoding of morphology, POS, syntactic
and functional information are the best candidates to provide the state-of-the-art parsing results in case of
MRLs. The work presented here is the part of a large effort made for the construction of the URDU.KON-
TB treebank, which was built by considering the parsing needs of Urdu. The annotation scheme of the
treebank contains semi-semantic POS (SSP), semi-semantic syntactic (SSS) and functional (F) tag sets,
from which only the SSP tag set is presented here along with its annotation evaluation.
The relevant resources of Urdu are now growing but most of the resources lack in morphological and
functional information. The initial corpus developed in the EMILLE project (McEnery et al., 2000) com-
prised multi-lingual corpora for the South Asian languages. Its Urdu part was annotated according to a
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are
added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
75
POS annotation scheme devised by Hardie (2003), which contained 350 morpho-syntactic tags based
on the gender, number agreement. It was so detailed that the Urdu computational linguists avoided it
to practice in statistical parsing, even it was a good effort. However, now the computational linguists
are realizing and attempting morphological information in their annotation (Manning, 2011). In (2007),
Urdu ParGram project introduced a resource that lied in the domain of tree-banking. In this project, Urdu
lexical functional grammar (LFG) was encoded, which is still in progress. The LFG grammar encoded
has rich morphological information, but unfortunately, the annotation scheme is not published yet due
to their different motives towards the parallel treebank development. Similarly, in (2009), Sajjad and
Schmid presented a new POS annotation scheme, which lacks in morphological, syntactical and func-
tional information. Due to which, it can only be used for the training of POS taggers and is not suitable
for the parsing purpose. Moreover, the explicit annotation evaluation was not performed. Another POS
tag set was devised by Muaz et. al. in (2009), which contained 32 general POS tags. The devised
scheme has the same issues as mentioned in the work of Sajjad and Schmid (2009). In (2009), Abbas et.
al. built the first NU-FAST treebank for Urdu with the POS and syntactic labels only. The design of that
treebank neither contained detailed morphological and functional information nor any information about
the displaced constituents, empty arguments, etc. Another Hindi-Urdu tree-banking (HUTB) (Bhatt et
al., 2009; Palmer et al., 2009) effort was done in a collaborative project
1
. However, the Urdu treebank
being developed was comparatively small and was being done as a part of a larger effort at establish-
ing a treebank for Hindi. Moreover, many of the issues with respect to Urdu were not quite addressed
and the project is still in progress. To continue this effort, another treebank for Urdu was designed by
Abbas in (2012), which comprised of 600 annotated sentences and it was done without the annotation
evaluation.
The current work presented in this paper, not only enhances the size of the proposed treebank by
Abbas (2012), but also resolves the annotation issues along with the complete annotation guidelines and
its evaluation. The development of the URDU.KON-TB treebank starts with the collection of a corpus
discussed briefly in Section 2. The semi-semantic (partly or partially semantic) POS (SSP) annotation
scheme is described in Section 3. Similarly, the evaluation of the SSP annotation is presented in Section 4
along with a brief presentation of annotation issues. Finally, the conclusion is given in Section 5 and the
detailed version of the SSP tag set is given in Appendix.
2 Corpus Collection
One thousand (1000) sentences taken from the corpus (Ijaz and Hussain, 2007) are extensively modified
to get rid of licensing constraints, because we want to share our corpus freely under a Creative-Commons-
Attribution/Share-Alike License 3.0 or higher. The next four hundred (400) sentences are collected from
the Urdu Wikipedia
2
, which is already under the same license. Thus the size of the corpus is limited to
fourteen hundred (1400) sentences. The corpus contains text of local & international news, social stories,
sports, culture, finance, history, religion, traveling, etc.
3 Semi-Semantic POS (SSP) Annotation
After the annotation evaluation presented in Section 4, the revised annotation scheme of the
URDU.KON-TB treebank has a semi-semantic POS (SSP), semi-semantic syntactic (SSS) and a func-
tional (F) tag set. The term semi-semantic (partly or partially semantic) is used with the POS because
the tags are compounded with the semantic tags partially e.g. a noun house with spatial semantics tagged
as N.SPT, an adjective previous in the previous year with temporal semantics tagged as ADJ.TMP, etc.
The same concept is applied on the SSS annotation. The details of SSS and F labeling is beyond the
scope of this paper. At POS level, a dot ?.? is used to add morphological and semantical subcategories
into the main POS categories displayed in Table 1 of Appendix. The POS, morphological and semantical
information all together, make a rich SSP annotation scheme for the URDU.KON-TB treebank. The
need for such type of schemes is highly advocated in (Clark et al., 2010; Skut et al., 1997), etc.
1
http://verbs.colorado.edu/hindiurdu/
2
http://ur.wikipedia.org/wiki/??@ ?
f
j
	
??
76
A simple POS tag set was devised first, which had twenty two (22) main POS-tag categories described
in Table 1 of Appendix, which includes some non-familiar tags like HADEES and M to represent the
Arabic statements of prophets in Urdu text and a phrase or a sentence marker, respectively. The labels
for morphological and semantic subcategories are presented in Tables 2 and 3 of Appendix, respectively,
which can be added to the 22 main POS tag categories by using a dot ?.? symbol in the form of compound
tags like N.SPT and ADJ.TMP mentioned earlier. In case of morphology, if a verb V has a perfective
morphology, then the compound tag becomes V.PERF. The SSP tag set was refined during the manual
annotation process of the sentences and further refined after the annotation evaluation process discussed
in Section 4. The final refined form of the SSP tag set depicted in Table 4 of Appendix is the revised form
of the POS tag set presented in the initial version of the URDU.KON-TB treebank by Abbas in (2012).
As an example, consider the ADJ (adjective) from the final refined form of the SSP tag set given in
Appendix, which is divided into five subcategories of tags DEG (Degree), ECO (Echo), MNR (Manner),
SPT (Spatial) and TMP (Temporal). Relevant examples are provided in 1 of Appendix. The example 1(a)
of Appendix is a simple case of ADJ, while 1(b) of Appendix is the case of a degree adjective
3
annotated
with ADJ.DEG. The example 1(c) of Appendix is the case of reduplication
4
(Abbi, 1992; B?ogel et al.,
2007). Reduplication has two versions. First Echo Reduplication is discussed in the footnote, while the
other Full Word Reduplication is the repetition of the original word e.g. sAtH sAtH ?with/alongwith?.
These are adopted in our annotation as ECO (echo) and the REP (repetition), respectively. The example
1(d) of Appendix is the case of adjective having a sense of manner annotated as ADJ.MNR. If an adjective
qualifies an action noun, then a sense of action or something is produced, whose behavior or the way
to do that action is exploited through ADJ.MNR e.g. z4AlemAnah t2abdIlIyAN ?brutal changes?. An
exercise of manner adjectives and manner adverbs for English can be seen at Cambridge University
5
. The
example 1(e) of Appendix is the case of an adjective having a temporal sense discussed earlier. Finally,
the example 1(f) of Appendix is the case of an adjective having a spatial sense. The adjective used here
is the derivational form of a city name ?Multan?, but it appears here as an adjective and annotated as
ADJ.SPT
6
like in this sentence e.g. voh Ek pAkistAnI laRkA hE ?He is a pakistani boy?.
Example 1 of Appendix exploited the POS tags for adjectives along with the semantic tagging like
TMP, SPT, MNR, etc. However, to give an introduction about morphology and verb functions, another
POS category of verb V given in Appendix is presented. It is divided into 11 subcategories, which include
COP (copula verb), IMPERF (imperfective morphological form of verb), INF (infinitive form of verb),
LIGHT (1st light verb with nouns and adjectives), LIGHTV (2nd light verb with verbs), MOD (modal
verb), PERF (perfective morphology), ROOT (root form), SUBTV (subjunctive form), PAST (past tense
of a verb) and PRES (present tense of a verb). These tags have further subcategories. All tags represents
different morphological forms and the function of a verb that it governs. A few high quality studies were
adopted to identify different forms and functions of Urdu verbs (Butt, 2003; Butt, 1995; Butt and Rizvi,
2010; Butt and Ramchand, 2001; Butt, 2010; Abbas and Raza, 2014; Abbas and Nabi Khan, 2009) and
some annotated sentences from the URDU.KON-TB treebank are given in example 2 of Appendix.
The sentence in example 2(a) of Appendix is the case of adjective-verb complex verb predicate. These
adjective/noun-verb complex predicates were first proposed by Ahmed and Butt (2011). The adjective
dubHar ?hard? and the verb kiyA ?did? with a perfective morphology yA at the end are annotated as a ADJ
and a V.LIGHT.PERF, respectively. Similarly, a perfective verb liyA ?took? after a root form of verb kar
?do? is an example of the verb-verb complex predicate depicted in 2(d) of Appendix. This construction
is adopted from the studies given in (Butt, 2010). The next sentence in 2(b) of Appendix has a passive
construction, which can be inferred from the inflected form of a verb or a verb auxiliary jAnA ?to go?
preceded by another verb with perfective morphology. To explore some unusual tags, a long sentence
3
This division is used to represent absolute, comparative and superlative degree in adjectives and adverbs.
4
In Urdu like other South Asian languages, the reduplication of a content word is frequent. Its effect is only to strengthen
the proceeding word or to expand the specific idea of a proceeding word into a general form e.g. kAm THIk-THAk karnA ?Do
the work right? or kOI kapRE-vapRE dE dO ?Give me the clothes or something like those?.
5
http://www.cambridge.org/grammarandbeyond/wp-content/uploads/2012/09/
Communicative_Activity_Hi-BegIntermediate-Adjectives_and_Adverbs.pdf
6
Spatial adjectives are used to describe a place/location, direction or distance e.g. multAnI ?Multani?, aglI ?next?, and dUr
?far? respectively.
77
is presented in 2(c) of Appendix. After the name of prophets or righteous religious-personalities, some
specific and limited prayers called s3alAvAt ?prayers? like sal-lal-la-ho-a2lEhE-va-AlEhI-salam ?May
Allah grant peace and honor on him and his family?, a2lEh salAm ?peace be upon him?, etc., in Arabic is
the most likely in Urdu text and annotated as the PRAY. Similarly, the statements of prophet Muhammad
(PBUH) known as h2adIs2 ?narration? like In-namal-aa2mAlo-bin-niyAt ?The deeds are considered by
the intensions? in Arabic script is also a tradition in Urdu text and annotated as the HADEES. The phrase
markers like comma, double quotes, single quotes, etc. are annotated with the M.P and sentence marker
like full-stop, question mark, etc., are annotated with the M.S as presented in the same example.
4 SSP Annotation Evaluation
The SSP annotation evaluation was performed via Krippendorff?s ? coefficient (Krippendorff, 2004),
which is a statistical measure to evaluate the reliability annotation or the inter-annotator agreement (IAA).
Krippendorff?s ? (Krippendorff, 1970; Krippendorff, 2004) satisfies all our needs including random
nominal data and five number of annotators in contrast to multi-pi (Fleiss, 1971) and multi-? (Cohen
and others, 1960), which can handle only fixed nominal data and they are basically not designed for
more than two annotators (Artstein and Poesio, 2008; Carletta et al., 1997). The nominal data given to
annotators for the SSP annotation was not fixed. In this situation, the general form of the Krippendorff?s
? coefficient was selected to meet this requirement.
For the reliability evaluation of the SSP annotation guidelines, it was essential that the annotators
should be the native speakers of Urdu along with the linguistics skills. To fulfill this purpose, an un-
dergraduate class of 25 linguistic students was trained at the Department of English, University of Sar-
godha
7
, Pakistan. During this training, thirty two lectures on annotation guidelines with practical ses-
sions were delivered. The duration of each lecture was of 3 hours. The class was further divided into
five groups and during their initial practical sessions, one student with a high caliber of understanding
from each group was selected (but not informed) secretly for the final annotation. The annotation task
of 100 random sentences was divided into 10 home assignments, which were then given to all students
(including 5 secret students) periodically with an instruction not to discuss it with each other. The anno-
tation performed by the selected 5 students was then recorded and evaluated. The value of ? coefficient
obtained after evaluation is 0.964 for the SSP annotation, which is narrated as a good reliability in (Krip-
pendorff, 2004) and lies in the category of perfect agreement according to a scale in (Landis and Koch,
1977). It also means that the IAA is 0.964 and the SSP annotation guidelines are reliable.
The issues found before and after the annotation evaluation concludes the addition, deletion or revision
of several tags. For example, the continuous auxiliary rahA/VAUX.PROG.PERF and its inflected forms
can behave as a copula verb as V.COP.PERF, which was not considered in the initial work. The annotators
did not respond well during the annotation of complex predicates, so their identification rules are revised
which includes tense, passive, modal, etc., auxiliaries or verbs can not behave as complex predicate e.g.
VAUX.LIGHT.MOD is not possible in the updated version. Similarly, the KER tag for identification of
a special clause ending with kar/V.KER kE/KER ?after doing?, was found to be ambiguous and deleted.
It was updated with their genuine tags as kar/V.ROOT kE/CM.
5 Conclusion
Sufficient rich information in the SSP annotation was encoded to meet the parsing needs of MRL Urdu.
The ? coefficient value obtained advocates the quality of the SSP annotation along with the complete
annotation guidelines for the URDU.KON-TB treebank. Such kind of annotated corpus with rich mor-
phology and semantics is not only useful for the parsing purpose but can be used for the training of POS
taggers, text mining, language identification (Abbas et al., 2010) and in many other applications as well.
Acknowledgements
Special thanks to Professor Miriam Butt, due to which linguistically rich the URDU.KON-TB treebank
is existing and she participated overwhelmingly in the annotation process of this treebank.
7
http://uos.edu.pk/
78
References
Qaiser Abbas and A Nabi Khan. 2009. Lexical Functional Grammar For Urdu Modal Verbs. In Emerging
Technologies, 2009. ICET 2009. International Conference on, pages 7?12. IEEE.
Qaiser Abbas and Ghulam Raza. 2014. A Computational Classification Of Urdu Dynamic Copula Verb. Interna-
tional Journal of Computer Applications, 85(10):1?12, January.
Qaiser Abbas, Nayyara Karamat, and Sadia Niazi. 2009. Development Of Tree-Bank Based Probabilistic Gram-
mar For Urdu Language. International Journal of Electrical & Computer Science, 9(09):231?235.
Qaiser Abbas, MS Ahmed, and Sadia Niazi. 2010. Language Identifier For Languages Of Pakistan Including
Arabic And Persian. International Journal of Computational Linguistics (IJCL), 1(03):27?35.
Qaiser Abbas. 2012. Building A Hierarchical Annotated Corpus Of Urdu: The URDU.KON-TB Treebank.
Lecture Notes in Computer Science, 7181(1):66?79.
Anvita Abbi. 1992. Reduplication In South Asian Languages: An Areal, Typological, And Historical Study. Allied
Publishers New Delhi.
Tafseer Ahmed and Miriam Butt. 2011. Discovering Semantic Classes For Urdu NV Complex Predicates. In
Proceedings of the Ninth International Conference on Computational Semantics, pages 305?309. Association
for Computational Linguistics.
Ron Artstein and Massimo Poesio. 2008. Inter-Coder Agreement For Computational Linguistics. Computational
Linguistics, 34(4):555?596.
Rajesh Bhatt, Bhuvana Narasimhan, Martha Palmer, Owen Rambow, Dipti Misra Sharma, and Fei Xia. 2009. A
Multi-Representational And Multi-Layered Treebank For Hindi/urdu. In Proceedings of the Third Linguistic
Annotation Workshop, pages 186?189. Association for Computational Linguistics.
Tina B?ogel, Miriam Butt, Annette Hautli, and Sebastian Sulger. 2007. Developing A Finite-State Morphological
Analyzer For Urdu And Hindi. Finite State Methods and Natural Language Processing, page 86.
Miriam Butt and Tracy Holloway King. 2007. Urdu In A Parallel Grammar Development Environment. Language
Resources and Evaluation, 41(2):191?207.
Miriam Butt and Gillian Ramchand. 2001. Complex Aspectual Structure In Hindi/Urdu. M. Liakata, B. Jensen,
& D. Maillat, Eds, pages 1?30.
Miriam Butt and Jafar Rizvi. 2010. Tense And Aspect In Urdu. Layers of Aspect. Stanford: CSLI Publications.
Miriam Butt. 1995. The Structure Of Complex Predicates In Urdu. Center for the Study of Language (CSLI).
Miriam Butt. 2003. The Light Verb Jungle. In Workshop on Multi-Verb Constructions.
Miriam Butt. 2010. The Light Verb Jungle: Still Hacking Away. Complex predicates: cross-linguistic perspec-
tives on event structure, page 48.
Jean Carletta, Stephen Isard, Gwyneth Doherty-Sneddon, Amy Isard, Jacqueline C Kowtko, and Anne H Anderson.
1997. The Reliability Of A Dialogue Structure Coding Scheme. Computational linguistics, 23(1):13?31.
Alexander Clark, Chris Fox, and Shalom Lappin. 2010. The Handbook Of Computational Linguistics And Natural
Language Processing, volume 57. Wiley. com.
Jacob Cohen et al. 1960. A Coefficient Of Agreement For Nominal Scales. Educational and psychological
measurement, 20(1):37?46.
Joseph L Fleiss. 1971. Measuring Nominal Scale Agreement Among Many Raters. Psychological bulletin,
76(5):378.
Andrew Hardie. 2003. Developing A Tagset For Automated Part-Of-Speech Tagging In Urdu. In Corpus Linguis-
tics 2003.
Madiha Ijaz and Sarmad Hussain. 2007. Corpus Based Urdu Lexicon Development. In the Proceedings of
Conference on Language Technology (CLT07), University of Peshawar, Pakistan.
Abdul Jamil Khan. 2006. Urdu/Hindi: An Artificial Divide: African Heritage, Mesopotamian Roots, Indian
Culture & Britiah Colonialism. Algora Pub.
79
Klaus Krippendorff. 1970. Estimating The Reliability, Systematic Error And Random Error Of Interval Data.
Educational and Psychological Measurement, 30(1):61?70.
Klaus Krippendorff. 2004. Reliability In Content Analysis. Human Communication Research, 30(3):411?433.
J Richard Landis and Gary G Koch. 1977. The Measurement Of Observer Agreement For Categorical Data.
biometrics, pages 159?174.
Gary F. Simons & Charles D. Fennig Lewis, M. Paul. 2013. Ethnologue: Languages Of The World, 17th Edition.
Dallas: SIL International.
Christopher D Manning. 2011. Part-Of-Speech Tagging From 97% To 100%: Is It Time For Some Linguistics?
In Computational Linguistics and Intelligent Text Processing, pages 171?189. Springer.
Anthony McEnery, Paul Baker, Rob Gaizauskas, and Hamish Cunningham. 2000. EMILLE: Building A Corpus
Of South Asian Languages. VIVEK-BOMBAY-, 13(3):22?28.
John R McLane. 1970. The Political Awakening In India. Prentice Hall.
Ahmed Muaz, Aasim Ali, and Sarmad Hussain. 2009. Analysis And Development Of Urdu POS Tagged Corpus.
In Proceedings of the 7th Workshop on Asian Language Resources, pages 24?29. Association for Computational
Linguistics.
Martha Palmer, Rajesh Bhatt, Bhuvana Narasimhan, Owen Rambow, Dipti Misra Sharma, and Fei Xia. 2009.
Hindi Syntax: Annotating Dependency, Lexical Predicate-Argument Structure, And Phrase Structure. In The
7th International Conference on Natural Language Processing, pages 14?17.
Hassan Sajjad and Helmut Schmid. 2009. Tagging Urdu Text With Parts Of Speech: A Tagger Comparison. In
Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,
pages 692?700. Association for Computational Linguistics.
Wojciech Skut, Brigitte Krenn, Thorsten Brants, and Hans Uszkoreit. 1997. An Annotation Scheme For Free
Word Order Languages. In Proceedings of the fifth conference on Applied natural language processing, pages
88?95. Association for Computational Linguistics.
Reut Tsarfaty, Djam?e Seddah, Yoav Goldberg, Sandra Kuebler, Marie Candito, Jennifer Foster, Yannick Versley,
Ines Rehbein, and Lamia Tounsi. 2010. Statistical Parsing Of Morphologically Rich Languages (SPMRL):
What, How And Whither. In Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of
Morphologically-Rich Languages, pages 1?12. Association for Computational Linguistics.
Reut Tsarfaty, Djam?e Seddah, Sandra K?ubler, and Joakim Nivre. 2013. Parsing Morphologically Rich Languages:
Introduction To The Special Issue. Computational Linguistics, 39(1):15?22.
Appendix
(1) (a) acHA
ADJ
laRkA
N
?good boy?
(b) aham
ADJ
tarIn
ADJ.DEG
Saxs2iat
N
?most important
personality?
(c) burA
ADJ
vurA
ADJ.ECO
kAm
N
?ugly work?
(d) jaberaanah
ADJ.MNR
hakUmat
N
?forceful government?
(e) guzaStah
ADJ.TMP
sAl
N
?previous year?
(f) mUltAnI
ADJ.SPT
kHUsah
N
?multani shoe?
(2) (a) mehangAI
N
nE
CM
lOgON
N
kA
CM
jInA
N
dUbHar
ADJ
kiyA
V.LIGHT.PERF
tHA
VAUX.PAST
?The inflation had made the life of people hard?
(b) giraN-faroSoN
N
kE
CM
xilAf
POSTP.MNR
qAnUn
N
harkat
N
mEN
CM
lAyA
V.PERF
jAyE
VAUX.PASS.SUBTV
?The law would be practiced against inflators?
80
(c) mUhammad
N.PROP
sal-lal-la-ho-a2lEhE-va-AlEhI-salam
PRAY
nE
CM
farmAyA
V.PERF
keh
C.SBORD
?
M.P
al-hUsynON-mInnI-vA-anA-mInal-hUsyn
HADEES
?
M.P
ya2nI
ADV
?
M.P
hUsyn
N.PROP
mUjH
P.PERS
sE
CM
hE
V.COP.PRES
aOr
C.CORD
mEN
P.PERS
hUsyn
N.PROP
sE
CM
hUN
V.SUBTV
?
M.P
.
M.S
?Muhammad (May Allah grant peace and honor on him and his family) said that
?al-hUsynON-mInnI-vA-anA-mInal-hUsyn? means ?Hussain is from me and I am from Hussain? . ?
(d) tUm
P.PERS
nE
CM
haj
N
tO
PT.EMP
kar
V.ROOT
liyA
V.LIGHTV.PERF
hO
VAUX.SUBTV
gA
VAUX.FUTR
?
M.S
?You will have made the pilgrimage??
Table 1: The main POS-Tag categories
Table 2: Morphological tag set subcategories
Table 3: Semantical tagset.
Table 4: A detailed version of the SSP tagset for the URDU.KON-TB treebank
81
