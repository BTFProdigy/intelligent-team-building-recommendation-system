  
A Lemmatization Method for Modern Mongolian and           
its Application to Information Retrieval 
Badam-Osor Khaltar           Atsushi Fujii 
Graduate School of Library, Information and Media Studies 
University of Tsukuba 
1-2 Kasuga Tsukuba, 305-8550, Japan 
{khab23, fujii}@slis.tsukuba.ac.jp 
 
 
 
Abstract 
In Modern Mongolian, a content word can 
be inflected when concatenated with suf-
fixes. Identifying the original forms of 
content words is crucial for natural lan-
guage processing and information retrieval. 
We propose a lemmatization method for 
Modern Mongolian and apply our method 
to indexing for information retrieval. We 
use technical abstracts to show the effec-
tiveness of our method experimentally. 
1 Introduction 
The Mongolian language is divided into Tradition-
al Mongolian, which uses the Mongolian alphabet, 
and Modern Mongolian, which uses the Cyrillic 
alphabet. In this paper, we focus solely on the lat-
ter and use the word ?Mongolian? to refer to Mod-
ern Mongolian. 
In Mongolian, which is an agglutinative lan-
guage, each sentence is segmented on a phrase-by-
phrase basis. A phrase consists of a content word, 
such as a noun or a verb, and one or more suffixes, 
such as postpositional participles. A content word 
can potentially be inflected when concatenated 
with suffixes. 
Identifying the original forms of content words 
in Mongolian text is crucial for natural language 
processing and information retrieval. In informa-
tion retrieval, the process of normalizing index 
terms is important, and can be divided into lemma-
tization and stemming. Lemmatization identifies 
the original form of an inflected word, whereas 
stemming identifies a stem, which is not necessari-
ly a word.  
Existing search engines, such as Google and 
Yahoo!, do not perform lemmatization or stem-
ming for indexing Web pages in Mongolian. 
Therefore, Web pages that include only inflected 
forms of a query cannot be retrieved. 
In this paper, we propose a lemmatization me-
thod for Mongolian and apply our method to in-
dexing for information retrieval. 
2 Inflection types in Mongolian phrases 
Nouns, adjectives, numerals, and verbs can be 
concatenated with suffixes. Nouns and adjectives 
are usually concatenated with a sequence of a 
plural suffix, case suffix, and reflexive possessive 
suffix. Numerals are concatenated with either a 
case suffix or a reflexive possessive suffix. Verbs 
are concatenated with various suffixes, such as an 
aspect suffix, a participle suffix, and a mood suffix. 
Figure 1 shows the inflection types of content 
words in Mongolian phrases. In (a), there is no in-
flection in the content word ???? (book)?, conca-
tenated with the suffix ??? (the genitive case)?. 
The content words are inflected in (b)-(e). 
 
Type Example 
(a) No inflection ??? + ?? ? ????? 
book + genitive case 
(b) Vowel insertion ?? + ? ? ???? 
brother + dative case 
(c) Consonant insertion ?????? + ???? ?????????? 
building + genitive case 
(d) The letters ??? or ??? 
are eliminated, and the 
vowel converts to ???  
???? + ??? ? ?????? 
return + ablative case 
(e) Vowel elimination ???? + ??? ? ?????? 
work + ablative case  
Figure 1: Inflection types of content words in 
Mongolian phrases. 
1
  
Loanwords, which can be nouns, adjectives, or 
verbs in Mongolian, can also be concatenated with 
suffixes. In this paper, we define a loanword as a 
word imported from a Western language. 
Because loanwords are linguistically different 
from conventional Mongolian words, the suffix 
concatenation is also different from that for con-
ventional Mongolian words. Thus, exception rules 
are required for loanwords. 
For example, if the loanword ?????? (station)? 
is to be concatenated with a genitive case suffix, 
???? should be selected from the five genitive 
case suffixes (i.e., ??, ???, ?, ??, and ?) based 
on the Mongolian grammar. However, because 
?????? (station)? is a loanword, the genitive case 
????? is selected instead of ????, resulting in the 
noun phrase ????????? (station?s)?. 
Additionally, the inflection (e) in Figure 1 never 
occurs for noun and adjective loanwords.  
3 Related work 
Sanduijav et al (2005) proposed a lemmatization 
method for noun and verb phrases in Mongolian. 
They manually produced inflection rules and con-
catenation rules for nouns and verbs. Then, they 
automatically produced a dictionary by aligning 
nouns or verbs with suffixes. Lemmatization for 
phrases is performed by consulting this dictionary. 
Ehara et al (2004) proposed a morphological 
analysis method for Mongolian, for which they 
manually produced rules for inflections and conca-
tenations. However, because the lemmatization 
methods proposed by Sanduijav et al (2005) and 
Ehara et al (2004) rely on dictionaries, these me-
thods cannot lemmatize new words that are not in 
dictionaries, such as loanwords and technical terms. 
Khaltar et al (2006) proposed a lemmatization 
method for Mongolian noun phrases that does not 
use a noun dictionary. Their method can be used 
for nouns, adjectives, and numerals, because the 
suffixes that are concatenated with these are almost 
the same and the inflection types are also the same. 
However, they were not aware of the applicability 
of their method to adjectives and numerals. 
The method proposed by Khaltar et al (2006) 
mistakenly extracts loanwords with endings that 
are different from conventional Mongolian words. 
For example, if the phrase ?????????? 
(ecology?s)? is lemmatized, the resulting content 
word will be ????????, which is incorrect. The 
correct word is ???????? (ecology)?. This error 
occurs because the ending ?-????? (-ology)? does 
not appear in conventional Mongolian words.  
In addition, Khaltar et al (2006)?s method 
applies (e) in Figure 1 to loanwords, whereas in-
flection (e) never occurs in noun and adjective 
loanwords. 
Lemmatization and stemming are arguably ef-
fective for indexing in information retrieval (Hull, 
1996; Porter, 1980). Stemmers have been devel-
oped for a number of agglutinative languages, in-
cluding Malay (Tai et al, 2000), Indonesian (Ber-
lian Vega and Bressan, 2001), Finnish (Korenius et 
al., 2004), Arabic (Larkey et al, 2002), Swedish 
(Carlberger et al, 2001), Slovene (Popovi? and 
Willett, 1992) and Turkish (Ekmek?ioglu et al, 
1996). 
Xu and Croft (1998) and Melucci and Orio 
(2003) independently proposed a language-
independent method for stemming, which analyzes 
a corpus in a target language and identifies an 
equivalent class consisting of an original form, 
inflected forms, and derivations. However, their 
method, which cannot identify the original form in 
each class, cannot be used for natural language 
applications where word occurrences must be stan-
dardized by their original forms.  
Finite State Transducers (FSTs) have been ap-
plied to lemmatization. Although Karttunen and 
Beesley (2003) suggested the applicability of FSTs 
to various languages, no rule has actually been 
proposed for Mongolian. The rules proposed in this 
paper can potentially be used for FSTs. 
To the best of our knowledge, no attempt has 
been made to apply lemmatization or stemming to 
information retrieval for Mongolian. Our research 
is the first serious effort to address this problem. 
4 Methodology 
4.1 Overview 
In view of the discussion in Section 3, we en-
hanced the lemmatization method proposed by 
Khaltar et al (2006). The strength of this method is 
that noun dictionaries are not required. 
Figure 2 shows the overview of our lemmatiza-
tion method for Mongolian. Our method consists 
of two segments, which are identified with dashed 
lines in Figure 2: ?lemmatization for verb phrases? 
and ?lemmatization for noun phrases?. 
2
  
 
 
In Figure 2, we enhanced the method proposed 
by Khaltar et al (2006) from three perspectives. 
First, we introduced ?lemmatization for verb 
phrases?. There is a problem to be solved when we 
target both noun and verb phrases. There are a 
number of suffixes that can concatenate with both 
verbs and nouns, but the inflection type can be dif-
ferent depending on the part of speech. As a result, 
verb phrases can incorrectly be lemmatized as 
noun phrases and vice versa. 
Because new verbs are not created as frequently 
as nouns, we predefine a verb dictionary, but do 
not use a noun dictionary. We first lemmatize an 
entered phrase as a verb phrase and then check 
whether the extracted content word is defined in 
our verb dictionary. If the content word is not de-
fined in our verb dictionary, we lemmatize the in-
put phrase as a noun phrase.  
Second, we introduced a ?loanword identifica-
tion rule? in ?lemmatization for noun phrases?. We 
identify a loanword phrase before applying a 
?noun suffix segmentation rule? and ?vowel inser-
tion rule?. Because segmentation rules are different 
for conventional Mongolian words and loanwords, 
we enhance the noun suffix segmentation rule that 
was originally proposed by Khaltar et al (2006). 
Additionally, we do not use the vowel insertion 
rule, if the entered phrase is detected as a loanword 
phrase. The reason is that vowel elimination never 
occurs in noun loanwords.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Third, unlike Khaltar et al (2006), we targeted 
adjective and numeral phrases. Because the suffix-
es concatenated with nouns, adjectives, and num-
erals are almost the same, the lemmatization me-
thod for noun phrases can also be used for adjec-
tive and numeral phrases without any modifica-
tions. We use ?lemmatization for noun phrases? to 
refer to the lemmatization for noun, adjective, and 
numeral phrases. 
We briefly explain our lemmatization process 
using Figure 2. 
We consult a ?verb suffix dictionary? and per-
form backward partial matching to determine 
whether a suffix is concatenated at the end of a 
phrase. If a suffix is detected, we use a ?verb suffix 
segmentation rule? to remove the suffix and extract 
the content word. This process will be repeated 
until the residue of the phrase does not match any 
of the entries in the verb suffix dictionary. 
We use a ?vowel insertion rule? to check wheth-
er vowel elimination occurred in the content word 
and insert the eliminated vowel.  
If the content word is defined in a ?verb dictio-
nary?, we output the content word as a verb and 
terminate the lemmatization process. If not, we use 
the entered phrase and perform lemmatization for 
noun phrases. We consult a ?noun suffix dictio-
nary? to determine whether one or more suffixes 
are concatenated at the end of the target phrase. 
Yes 
No 
Detect a suffix in the phrase 
Remove suffixes and extract a content word 
Check if the content word is a verb 
Detect a suffix in the phrase 
Remove suffixes and extract a content word
Input a 
phrase 
Output the 
content word 
Process the inputted phrase as a noun phrase
Loanword identification rule 
Verb dictionary 
Verb suffix segmentation rule  
Noun suffix dictionary 
Noun suffix segmentation rule 
Verb suffix dictionary  
Figure 2: Overview of our lemmatization method for Mongolian.   
Lemmatization for noun phrases 
Vowel insertion rule Insert an eliminated vowel  
Insert an eliminated vowel  
Identify loanword 
Vowel insertion rule 
Lemmatization for verb phrases 
3
  
We use a ?loanword identification rule? to iden-
tify whether the phrase is a loanword phrase. We 
use a ?noun suffix segmentation rule? to remove 
the suffixes and extract the content word. If the 
phrase is identified as a loanword phrase we use 
different segmentation rules. 
We use the ?vowel insertion rule? which is also 
used for verb phrases to check whether vowel eli-
mination occurred in the content word and insert 
the eliminated vowel. However, if the phrase is 
identified as a loanword phrase, we do not use the 
vowel insertion rule. 
If the target phrase does not match any of the 
entries in the noun suffix dictionary, we determine 
that a suffix is not concatenated and we output the 
phrase as it is. 
The inflection types (b)?(d) in Figure 1 are 
processed by the verb suffix segmentation rule and 
noun suffix segmentation rule. The inflection (e) in 
Figure 1 is processed by the vowel insertion rule. 
We elaborate on the dictionaries and rules in 
Sections 4.2?4.8. 
4.2 Verb suffix dictionary 
We produced a verb suffix dictionary, which con-
sists of 126 suffixes that can concatenate with 
verbs. These suffixes include aspect suffixes, parti-
ciple suffixes, and mood suffixes. 
Figure 3 shows a fragment of our verb suffix 
dictionary, in which inflected forms of suffixes are 
shown in parentheses. All suffixes corresponding 
to the same suffix type represent the same meaning. 
4.3 Verb suffix segmentation rule 
For the verb suffix segmentation rule, we produced 
179 rules. There are one or more segmentation 
rules for each of the 126 verb suffixes mentioned 
in Section 4.2. 
Figure 4 shows a fragment of the verb suffix 
segmentation rule for suffix ?? (past)?. In the 
column ?Segmentation rule?, the condition of each 
?if? sentence is a phrase ending. ?V? refers to a 
vowel and ?*? refers to any strings. ?C9? refers to 
any of the nine consonants ???, ???, ???, ???, ???, 
???, ???, ???, or ???, and ?C7? refers to any of the 
seven consonants ???, ???, ???, ???, ???, ???, or 
???. If a condition is satisfied, we remove one or 
more corresponding characters. 
For example, because the verb phrase 
????????? (renew + past)? satisfies condition (ii),  
Suffix type Suffix 
Appeal 
Complete 
Perfect 
Progressive-perfect 
????, ???? 
??? 
??? (???), ??? (???), ???, ??? 
????, ????, ????, ???? 
Figure 3: Fragment of verb suffix dictionary. 
 
Suffix Segmentation rule   
 
? 
Past 
(i)  If ( *+ V + V +  ? )   
Remove ? 
(ii) If ( * + C9 + C7 + V + ? )  
Remove V + ? 
Figure 4: Fragment of verb suffix segmentation 
rule. 
 
we remove the suffix ??? and the preceding vowel 
??? to extract ????????. 
4.4 Verb dictionary 
We use the verb dictionary produced by Sanduijav 
et al (2005), which includes 1254 verbs. 
4.5 Noun suffix dictionary 
We use the noun suffix dictionary produced by 
Khaltar et al (2006), which contains 35 suffixes 
that can be concatenated with nouns. These suffix-
es are postpositional particles. Figure 5 shows a 
fragment of the dictionary, in which inflected 
forms of suffixes are shown in parentheses. 
4.6 Noun suffix segmentation rule 
There are 196 noun suffix segmentation rules, of 
which 173 were proposed by Khaltar et al (2006). 
As we explained in Section 3, these 173 rules often 
incorrectly lemmatize loanwords with different 
endings from conventional Mongolian words. 
We analyzed the list of English suffixes and 
found that English suffixes ?-ation? and ?-ology? 
are incorrectly lemmatized by Khaltar et al (2006). 
In Mongolian, ?-ation? is transliterated into ????? 
or ????? and ?-ology? is transliterated into 
???????. Thus, we produced 23 rules for 
loanwords that end with ?????, ?????, or ???????.  
Figure 6 shows a fragment of our suffix segmen-
tation rule for loanwords. For example, for the 
loanword phrase ?????????? (ecology + geni-
tive)?, we use the segmentation rule for suffix 
???? (genitive)? in Figure 6. We remove the suffix 
???? (genitive)? and add ??? to the end of the 
content word. As a result, the noun ???????? 
(ecology)? is correctly extracted. 
 
4
  
 Case Suffix 
Genitive 
Accusative 
Dative 
Ablative 
?, ?, ??, ??, ??? 
??, ???, ? 
?, ? 
??? (???), ??? (???), ???, ??? 
Figure 5: Fragment of noun suffix dictionary. 
 
Suffix Segmentation rule for loanwords  
??? 
Genitive 
If (* + ??????) 
     Remove (???) , Add (?) 
??? 
Accusative 
If (* + ??????) 
     Remove (???), Add (?) 
Figure 6: Fragment of suffix segmentation rules 
for loanwords. 
4.7 Vowel insertion rule 
To insert an eliminated vowel and extract the orig-
inal form of a content word, we check the last two 
characters of the content word. If they are both 
consonants, we determine that a vowel was elimi-
nated. However, a number of Mongolian words 
end with two consonants inherently and, therefore, 
Khaltar et al (2006) referred to a textbook on the 
Mongolian grammar (Ts, 2002) to produce 12 rules 
to determine when to insert a vowel between two 
consecutive consonants. We also use these rules as 
our vowel insertion rule. 
4.8 Loanword identification rule 
Khaltar et al (2006) proposed rules for extracting 
loanwords from Mongolian corpora. Words that 
satisfy one of seven conditions are extracted as 
loanwords. Of the seven conditions, we do not use 
the condition that extracts a word ending with 
?consonants + ?? as a loanword because it was not 
effective for lemmatization purposes in prelimi-
nary study. 
5 Experiments 
5.1 Evaluation method 
We collected 1102 technical abstracts from the 
?Mongolian IT Park? 1 and used them for experi-
ments. There were 178,448 phrase tokens and 
17,709 phrase types in the 1102 technical abstracts. 
We evaluated the accuracy of our lemmatization 
method (Section 5.2) and the effectiveness of our 
method in information retrieval (Section 5.3) expe-
rimentally. 
                                                 
1 http://www.itpark.mn/ (October, 2007)  
5.2 Evaluating lemmatization 
Two Mongolian graduate students served as asses-
sors. Neither of the assessors was an author of this 
paper. The assessors provided the correct answers 
for lemmatization. The assessors also tagged each 
word with its part of speech. 
The two assessors performed the same task in-
dependently. Differences can occur between two 
assessors on this task. We measured the agreement 
of the two assessors by the Kappa coefficient, 
which ranges from 0 to 1. The Kappa coefficients 
for performing lemmatization and tagging of parts 
of speech were 0.96 and 0.94, respectively, which 
represents almost perfect agreement (Landis and 
Koch, 1977). However, to enhance the objectivity 
of the evaluation, we used only the phrases for 
which the two assessors agreed with respect to the 
part of speech and lemmatization. 
We were able to use the noun and verb dictiona-
ries of Sanduijav et al (2005). Therefore, we com-
pared our lemmatization method with Sanduijav et 
al. (2005) and Khaltar et al (2006) in terms of ac-
curacy.  
Accuracy is the ratio of the number of phrases 
correctly lemmatized by the method under evalua-
tion to the total number of target phrases. Here, the 
target phrases are noun, verb, adjective, and num-
eral phrases. 
Table 1 shows the results of lemmatization. We 
targeted 15,478 phrase types in the technical ab-
stracts. Our experiment is the largest evaluation for 
Mongolian lemmatization in the literature. In con-
trast, Sanduijav et al (2005) and Khaltar et al 
(2006) used only 680 and 1167 phrase types, re-
spectively, for evaluation purposes. 
In Table 1, the accuracy of our method for 
nouns, which were targeted in all three methods, 
was higher than those of Sanduijav et al (2005) 
and Khaltar et al (2006). Because our method and 
that of Sanduijav et al (2005) used the same verb 
dictionary, the accuracy for verbs is principally the 
same for both methods. The accuracy for verbs 
was low, because a number of verbs were not in-
cluded in the verb dictionary and were mistakenly 
lemmatized as noun phrases. However, this prob-
lem will be solved by enhancing the verb dictio-
nary in the future. In total, the accuracy of our me-
thod was higher than those of Sanduijav et al 
(2005) and Khaltar et al (2006). 
 
5
  
Table 1: Accuracy of lemmatization (%). 
 #Phrase 
types 
Sanduijav 
et al 
(2005) 
Khaltar 
et al 
(2006) 
Our 
method 
Noun 13,016 57.6 87.7 92.5 
Verb 1,797 24.5 23.8 24.5 
Adjective 609 82.6 83.5 83.9 
Numeral 56 41.1 80.4 81.2 
Total 15,478 63.2 72.3 78.2 
 
We analyzed the errors caused by our method in 
Figure 7. In the column ?Example?, the left side 
and the right side of an arrow denote an error and 
the correct answer, respectively.  
The error (a) occurred to nouns, adjectives, and 
numerals, in which the ending of a content word 
was mistakenly recognized as a suffix and was re-
moved. The error (b) occurred because we did not 
consider irregular nouns. The error (c) occurred to 
loanword nouns because the loanword identifica-
tion rule was not sufficient. The error (d) occurred 
because we relied on a verb dictionary. The error 
(e) occurred because a number of nouns were in-
correctly lemmatized as verbs.  
For the errors (a)-(c), we have not found solu-
tions. The error (d) can be solved by enhancing the 
verb dictionary in the future. If we are able to use 
part of speech information, we can solve the error 
(e). There are a number of automatic methods for 
tagging parts of speech (Brill, 1997), which have 
promise for alleviating the error (e). 
5.3 Evaluating the effectiveness of lemmatiza-
tion in information retrieval 
We evaluated the effectiveness of lemmatization 
methods in indexing for information retrieval. No 
test collection for Mongolian information retrieval 
is available to the public. We used the 1102 tech-
nical abstracts to produce our test collection. 
Figure 8 shows an example technical abstract, in 
which the title is ?Advanced Albumin Fusion 
Technology? in English. Each technical abstract 
contains one or more keywords. In Figure 8, key-
words, such as ?????? ?????? (blood serum)? 
and ????? (placenta)? are annotated. 
We used two different types of queries for our 
evaluation. First, we used each keyword as a query, 
which we call ?keyword query (KQ)?. Second, we 
used each keyword list as a query, which we call 
?list query (LQ)?. The average number for key-
words in the keywords list was 6.1. For each query,  
 
Reasons of errors #Errors Example 
(a) Word ending is 
the same as a suffix. 274 
???? ? ??? 
sort 
(b) Noun plural 
tense is irregular. 244 
?????? ? ???? 
animal 
(c) Noun loanword 
ends with two con-
sonants. 
94 
???????? ? ????????? 
dinosaur 
(d) Verb does not 
exist in our verb 
dictionary.  
689 
????? ? ??????
to code  
(e) Word corres-
ponds to multiple 
part of speech. 
853 
???? ? ?? 
country   inter 
 
Figure 7: Errors of our lemmatization method. 
 
we used as the relevant documents the abstracts 
that were annotated with the query keyword in the 
keywords field. Thus, we were able to avoid the 
cost of relevance judgments. 
The target documents are the 1102 technical ab-
stracts, from which we extracted content words in 
the title, abstract, and result fields as index terms. 
However, we did not use the keywords field for 
indexing purposes. We used Okapi BM25 (Robert-
son et al, 1995) as the retrieval model. 
We used the lemmatization methods in Table 2 
to extract content words and compared the Mean 
Average Precision (MAP) of each method using 
KQ and LQ. MAP has commonly been used to 
evaluate the effectiveness of information retrieval. 
Because there were many queries for which the 
average precision was zero in all methods, we dis-
carded those queries. There were 686 remaining 
KQs and 273 remaining LQs. 
The average number of relevant documents for 
each query was 2.1. Although this number is small, 
the number of queries is large. Therefore, our eval-
uation result can be stable, as in evaluations for 
question answering (Voorhees and Tice, 2000).  
We can derive the following points from Table 2. 
First, to clarify the effectiveness of the lemmatiza-
tion in information retrieval, we compare ?no 
lemmatization? with the other methods. Any lem-
matization method improved the MAP for both KQ 
and LQ. Thus, lemmatization was effective for 
information retrieval in Mongolian. Second, we 
compare the MAP of our method with those of 
Sanduijav et al (2005) and Khaltar et al (2006). 
Our method was more effective than the method of 
Sanduijav et al (2005) for both KQ and LQ. How-
ever, the difference between Khaltar et al (2006) 
and our method was small for KQ and our method  
6
  
Figure 8: Example of technical abstract. 
 
Table 2: MAP of lemmatization methods.  
 Keyword query List query 
No lemmatization 0.2312 0.2766 
Sanduijav et al (2005) 0.2882 0.2834 
Khaltar et al (2006) 0.3134 0.3127 
Our method 0.3149 0.3114 
Correct lemmatization 0.3268 0.3187 
 
was less effective than Khaltar et al(2006) for LQ. 
This is because although we enhanced the lemma-
tization for verbs, adjectives, numerals, and loan-
words, the effects were overshadowed by a large 
number of queries comprising conventional Mon-
golian nouns. Finally, our method did not outper-
form the method using the correct lemmatization.  
We used the paired t-test for statistical testing, 
which investigates whether the difference in per-
formance is meaningful or simply because of 
chance (Keen, 1992). Table 3 shows the results, in 
which ?<? and ?<<? indicate that the difference of 
two results was significant at the 5% and 1% levels, 
respectively, and ??? indicates that the difference 
of two results was not significant.  
Looking at Table 3, the differences between no 
lemmatization and any lemmatization method, 
such as Sanduijav et al (2005), Khaltar et al 
(2006), our method, and correct lemmatization, 
were statistically significant in MAP for KQ. 
However, because the MAP value of no lemmati-
zation was improved for LQ, the differences be-
tween no lemmatization and the lemmatization me-
thods were less significant than those for KQ. The 
difference between Sanduijav et al (2005) and our 
method was statistically significant in MAP for 
both KQ and LQ. However, the difference between 
Khaltar et al (2006) and our method was not sig-
nificant in MAP for both KQ and LQ. Although, 
the difference between our method and correct 
lemmatization was statistically significant in MAP 
for KQ, the difference was not significant in MAP 
for LQ.  
 
 
 
Table 3: t-test result of the differences between 
lemmatization methods. 
 Keyword query List query 
No lemmatization vs. 
Correct lemmatization << < 
No lemmatization vs. 
Sanduijav et al (2005) << ? 
No lemmatization vs. 
Khaltar et al (2006) << < 
No lemmatization vs. 
Our method << < 
Sanduijav et al (2005) 
vs. Our method << < 
Khaltar et al (2006) vs. 
Our method ? ? 
Our method vs. Correct 
lemmatization < ? 
6 Conclusion 
In Modern Mongolian, a content word can poten-
tially be inflected when concatenated with suffixes. 
Identifying the original forms of content words is 
crucial for natural language processing and infor-
mation retrieval.  
In this paper, we proposed a lemmatization me-
thod for Modern Mongolian. We enhanced the 
lemmatization method proposed by Khaltar et al 
(2006). We targeted nouns, verbs, adjectives, and 
numerals. We also improved the lemmatization for 
loanwords.  
We evaluated our lemmatization method expe-
rimentally. The accuracy of our method was higher 
than those of existing methods. We also applied 
our lemmatization method to information retrieval 
and improved the retrieval accuracy. 
Future work includes using a part of speech tag-
ger because the part of speech information is effec-
tive for lemmatization.  
References 
Vinsensius Berlian Vega S N and St?phane Bressan. 
2001. Indexing the Indonesian Web: Language iden-
tification and miscellaneous issues. Tenth Interna-
tional World Wide Web Conference, Hong Kong.  
Eric Brill. 1997. Natural Language Processing Using 
Very Large Corpora. Kluwer Academic Press. 
Johan Carlberger, Hercules Dalianis, Martin Hassel, and 
Ola Knutsson. 2001. Improving Precision in Informa-
tion Retrieval for Swedish using Stemming. Proceed-
ings of NODALIDA ?01 - 13th Nordic Conference on 
Computational Linguistics. 
Title: ???????? ????????? ????????? ????????? 
Author?s name: ???? ?????? 
Keywords: ????? ??????, ???? ? 
Abstract: ?????????? ????? ?????? 5, 10% ???? 
Result: ????????? ?????? ??????????, ?????? ? 
7
  
Terumasa Ehara, Suzushi Hayata, and Nobuyuki Kimu-
ra. 2004. Mongolian morphological analysis using 
ChaSen. Proceedings of the 10th Annual Meeting of 
the Association for Natural Language Processing, 
pp. 709-712. (In Japanese). 
?una F. Ekmek?ioglu, Michael F. Lynch, and Peter 
Willett. 1996. Stemming and n-gram matching for 
term conflation in Turkish texts. Information Re-
search News, Vol. 7, No. 1, pp. 2-6. 
David A. Hull. 1996. Stemming algorithms ? a case 
study for detailed evaluation. Journal of the Ameri-
can Society for Information Science and Technology, 
Vol. 47, No. 1, pp. 70-84. 
Lauri Karttunen and Kenneth R. Beesley. 2003. Finite 
State Morphology. CSLI Publications. Stanford. 
Micheal E. Keen. 1992. Presenting results of experi-
mental retrieval comparisons. Information 
Processing and Management, Vol. 28, No. 4, pp. 
491-502. 
Badam-Osor Khaltar, Atsushi Fujii, and Tetsuya Ishi-
kawa. 2006. Extracting loanwords from Mongolian 
corpora and producing a Japanese-Mongolian bilin-
gual dictionary. Proceedings of the 21st International 
Conference on Computational Linguistics and 44th 
Annual Meeting of the Association for Computational 
Linguistics, pp. 657-664. 
Tuomo Korenius, Jorma Laurikkala, Kalervo J?rvelin, 
and Martti Juhola. 2004. Stemming and 
Lemmatization in the Clustering of Finnish Text 
Documents. Proceedings of the thirteenth Associa-
tion for Computing Machinery international confe-
rence on Information and knowledge management. 
pp. 625-633. 
Richard J. Landis and Gary G. Koch. 1977. The mea-
surement of observer agreement for categorical data. 
Biometrics, Vol. 33, No. 1, pp. 159-174. 
Leah S. Larkey, Lisa Ballesteros, and Margaret E. Con-
nel. 2002. Improving Stemming for Arabic Informa-
tion Retrieval: Light Stemming and Co-occurrence 
Analysis. Proceedings of the 25th annual interna-
tional ACM SIGIR conference on Research and de-
velopment in information retrieval, pp. 275-282. 
Massimo Melucci and Nicola Orio. 2003. A Novel Me-
thod for Stemmer Generation Based on Hidden Mar-
kov Models. Proceedings of the twelfth international 
conference on Information and knowledge manage-
ment, pp. 131-138. 
 
 
Mirko Popovi? and Peter Willett. 1992. The effective-
ness of stemming for natural-language access to Slo-
vene textual data. Journal of the American Society 
for Information Science and Technology, Vol. 43, No. 
5, pp. 384-390. 
Martin F. Porter. 1980. An algorithm for suffix strip-
ping. Program, Vol. 14, No. 3, pp. 130-137.  
Stephen E. Robertson, Steve Walker, Susan Jones, 
Micheline Hancock-Beaulieu, and Mike Gatford. 
1995. Okapi at TREC-3. Proceedings of the Third 
Text REtrieval Conference, NIST Special Publication 
500-226. pp. 109-126.   
Enkhbayar Sanduijav, Takehito Utsuro, and Satoshi 
Sato. 2005. Mongolian phrase generation and mor-
phological analysis based on phonological and mor-
phological constraints. Journal of Natural Language 
Processing, Vol. 12, No. 5, pp. 185-205. (In Japa-
nese) . 
Sock Y. Tai, Cheng O. Ong, and Noor A. Abdullah. 
2000. On designing an automated Malaysian stem-
mer for the Malay language. Proceedings of the fifth 
international workshop on information retrieval with 
Asian languages, Hong Kong, pp. 207-208. 
Bayarmaa Ts. 2002. Mongolian grammar for grades I-
IV. (In Mongolian). 
Ellen M. Voorhees and Dawn M. Tice. 2000. Building a 
Question Answering Test Collection. Proceedings of 
the 23rd Annual International ACM SIGIR Confe-
rence on Research and Development in Information 
Retrieval, pp. 200-207. 
Jinxi Xu and Bruce W. Croft. 1998. Corpus-based 
stemming using co-occurrence of word variants. 
ACM Transactions on Information Systems, Vol. 16, 
No. 1, pp. 61-81. 
8
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 657?664,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Extracting loanwords from Mongolian corpora and producing a 
Japanese-Mongolian bilingual dictionary
 
Badam-Osor Khaltar 
Graduate School of Library, 
Information and Media Studies 
University of Tsukuba 
1-2 Kasuga Tsukuba, 305-8550 
Japan 
khab23@slis.tsukuba.ac.jp 
 
 
 
Atsushi Fujii 
Graduate School of Library, 
Information and Media Studies 
University of Tsukuba 
1-2 Kasuga Tsukuba, 305-8550 
Japan 
fujii@slis.tsukuba.ac.jp 
 
 
 
Tetsuya Ishikawa 
The Historiographical Institute 
The University of Tokyo 
3-1 Hongo 7-chome, Bunkyo-ku 
Tokyo, 133-0033 
Japan 
ishikawa@hi.u-tokyo.ac.jp 
 
 
 
Abstract 
This paper proposes methods for extracting 
loanwords from Cyrillic Mongolian corpora 
and producing a Japanese?Mongolian 
bilingual dictionary. We extract loanwords 
from Mongolian corpora using our own 
handcrafted rules. To complement the 
rule-based extraction, we also extract words 
in Mongolian corpora that are phonetically 
similar to Japanese Katakana words as 
loanwords. In addition, we correspond the 
extracted loanwords to Japanese words and 
produce a bilingual dictionary. We propose a 
stemming method for Mongolian to extract 
loanwords correctly. We verify the 
effectiveness of our methods experimentally. 
 
1 Introduction  
Reflecting the rapid growth in science and 
technology, new words and technical terms are being 
progressively created, and these words and terms are 
often transliterated when imported as loanwords in 
another language. 
Loanwords are often not included in dictionaries, 
and decrease the quality of natural language 
processing, information retrieval, machine 
translation, and speech recognition. At the same time, 
compiling dictionaries is expensive, because it relies 
on human introspection and supervision. Thus, a 
number of automatic methods have been proposed to 
extract loanwords and their translations from corpora, 
targeting various languages. 
In this paper, we focus on extracting loanwords in 
Mongolian. The Mongolian language is divided into 
Traditional Mongolian, written using the Mongolian 
alphabet, and Modern Mongolian, written using the 
Cyrillic alphabet. We focused solely on Modern 
Mongolian, and use the word ?Mongolian? to refer 
to Modern Mongolian in this paper. 
There are two major problems in extracting 
loanwords from Mongolian corpora. 
The first problem is that Mongolian uses the 
Cyrillic alphabet to represent both conventional 
words and loanwords, and so the automatic 
extraction of loanwords is difficult. This feature 
provides a salient contrast to Japanese, where the 
Katakana alphabet is mainly used for loanwords and 
proper nouns, but not used for conventional words. 
The second problem is that content words, such as 
nouns and verbs, are inflected in sentences in 
Mongolian. Each sentence in Mongolian is 
segmented on a phrase-by-phase basis. A phrase 
consists of a content word and one or more suffixes, 
such as postpositional particles. Because loanwords 
are content words, then to extract loanwords 
correctly, we have to identify the original form using 
stemming. 
In this paper, we propose methods for extracting 
loanwords from Cyrillic Mongolian and producing a 
Japanese?Mongolian bilingual dictionary. We also 
propose a stemming method to identify the original 
forms of content words in Mongolian phrases. 
657
2 Related work 
To the best of our knowledge, no attempt has been 
made to extract loanwords and their translations 
targeting Mongolian. Thus, we will discuss existing 
methods targeting other languages.  
In Korean, both loanwords and conventional 
words are spelled out using the Korean alphabet, 
called Hangul. Thus, the automatic extraction of 
loanwords in Korean is difficult, as it is in 
Mongolian. Existing methods that are used to extract 
loanwords from Korean corpora (Myaeng and Jeong, 
1999; Oh and Choi, 2001) use the phonetic 
differences between conventional Korean words and 
loanwords. However, these methods require 
manually tagged training corpora, and are expensive. 
A number of corpus-based methods are used to 
extract bilingual lexicons (Fung and McKeown, 
1996; Smadja, 1996). These methods use statistics 
obtained from a parallel or comparable bilingual 
corpus, and extract word or phrase pairs that are 
strongly associated with each other. However, these 
methods cannot be applied to a language pair where 
a large parallel or comparable corpus is not available, 
such as Mongolian and Japanese. 
Fujii et al (2004) proposed a method that does not 
require tagged corpora or parallel corpora to extract 
loanwords and their translations. They used a 
monolingual corpus in Korean and a dictionary 
consisting of Japanese Katakana words. They 
assumed that loanwords in multiple countries 
corresponding to the same source word are 
phonetically similar. For example, the English word 
?system? has been imported into Korean, Mongolian, 
and Japanese. In these languages, the romanized 
words are ?siseutem?, ?sistem?, and ?shisutemu?, 
respectively. 
It is often the case that new terms have been 
imported into multiple languages simultaneously, 
because the source words are usually influential 
across cultures. It is feasible that a large number of 
loanwords in Korean can also be loanwords in 
Japanese. Additionally, Katakana words can be 
extracted from Japanese corpora with a high 
accuracy. Thus, Fujii et al (2004) extracted the 
loanwords in Korean corpora that were phonetically 
similar to Japanese Katakana words. Because each 
of the extracted loanwords also corresponded to a 
Japanese word during the extraction process, a 
Japanese?Korean bilingual dictionary was produced 
in a single framework. 
However, a number of open questions remain 
from Fujii et al?s research. First, their stemming 
method can only be used for Korean. Second, their 
accuracy in extracting loanwords was low, and thus, 
an additional extraction method was required. Third, 
they did not report on the accuracy of extracting 
translations, and finally, because they used Dynamic 
Programming (DP) matching for computing the 
phonetic similarities between Korean and Japanese 
words, the computational cost was prohibitive. 
In an attempt to extract Chinese?English 
translations from corpora, Lam et al (2004) 
proposed a similar method to Fujii et al (2004). 
However, they searched the Web for 
Chinese?English bilingual comparable corpora, and 
matched named entities in each language corpus if 
they were similar to each other. Thus, Lam et al?s 
method cannot be used for a language pair where 
comparable corpora do not exist. In contrast, using 
Fujii et al?s (2004) method, the Katakana dictionary 
and a Korean corpus can be independent. 
In addition, Lam et al?s method requires 
Chinese?English named entity pairs to train the 
similarity computation. Because the accuracy of 
extracting named entities was not reported, it is not 
clear to what extent this method is effective in 
extracting loanwords from corpora. 
 
3 Methodology 
3.1 Overview 
In view of the discussion outlined in Section 2, we 
enhanced the method proposed by Fujii et al (2004) 
for our purpose. Figure 1 shows the method that we 
used to extract loanwords from a Mongolian corpus 
and to produce a Japanese?Mongolian bilingual 
dictionary. Although the basis of our method is 
similar to that used by Fujii et al (2004), 
?Stemming?, ?Extracting loanwords based on rules?, 
and ?N-gram retrieval? are introduced in this paper. 
First, we perform stemming on a Mongolian 
corpus to segment phrases into a content word and  
one or more suffixes. 
658
 
Second, we discard segmented content words if 
they are in an existing dictionary, and extract the 
remaining words as candidate loanwords. 
Third, we use our own handcrafted rules to extract 
loanwords from the candidate loanwords. While the 
rule-based method can extract loanwords with a high 
accuracy, a number of loanwords cannot be extracted 
using predefined rules. 
Fourth, as performed by Fujii et al (2004), we use 
a Japanese Katakana dictionary and extract a 
candidate loanword that is phonetically similar to a 
Katakana word as a loanword. We romanize the 
candidate loanwords that were not extracted using 
the rules. We also romanize all words in the 
Katakana dictionary.  
However, unlike Fujii et al (2004), we use 
N-gram retrieval to limit the number of Katakana 
words that are similar to the candidate loanwords. 
Then, we compute the phonetic similarities between 
each candidate loanword and each retrieved 
Katakana word using DP matching, and select a pair 
whose score is above a predefined threshold. As a 
result, we can extract loanwords in Mongolian and 
their translations in Japanese simultaneously. 
Finally, to identify Japanese translations for the 
loanwords extracted using the rules defined in the 
third step above, we perform N-gram retrieval and 
DP matching.  
We will elaborate further on each step in Sections 
3.2?3.7. 
3.2 Stemming 
A phrase in Mongolian consists of a content word 
and one or more suffixes. A content word can 
potentially be inflected in a phrase. Figure 2 shows 
 
 
Mongolian corpus Katakana dictionary
 Stemming 
 
 Extracting candidate loanwords Romanization 
 
Japanese-Mongolian bilingual dictionaryExtracting loanwords based on rules 
 
 
 
Romanization N-gram retrieval 
 
 
Mongolian loanword dictionary 
High Similarity
Computing phonetic similarity 
Fig  ure 1: Overview of our extraction method.
Type Example 
(a) No inflection. ??? + ?? ? ????? 
Book + Genitive Case 
(b) Vowel elimination. ???? +???+ ??? ???????? 
Work + Ablative Case +Reflexive
(c) Vowel insertion. ?? + ? ? ???? 
Brother + Dative Case 
(d) Consonant insertion. ?????? + ???? ??????????
Building + Genitive Case 
(e) The letter ??? is 
converted to ???, and 
the vowel is eliminated. 
????????+ ???? ?????????? 
School + Ablative Case 
Figure 2: Inflection types of nouns in Mongolian. 
the inflection types of content words in phrases. In 
phrase (a), there is no inflection in the content word 
???? (book)? concatenated with the suffix ??? 
(genitive case)?. 
However, in phrases (b)?(e) in Figure 2, the 
content words are inflected. Loanwords are also 
inflected in all of these types, except for phrase (b). 
Thus, we have to identify the original form of a 
content word using stemming. While most 
loanwords are nouns, a number of loanwords can 
also be verbs. In this paper, we propose a stemming 
method for nouns. Figure 3 shows our stemming 
method. We will explain our stemming method 
further, based on Figure 3. 
First, we consult a ?Suffix dictionary? and 
perform backward partial matching to determine 
whether or not one or more suffixes are concatenated 
at the end of a target phrase. 
Second, if a suffix is detected, we use a ?Suffix 
segmentation rule? to segment the suffix and extract 
659
 
Figure 3: Overview of our noun stemming method. 
 
the noun. The inflection type in phrases (c)?(e) in 
Figure 2 is also determined. 
Third, we investigate whether or not the vowel 
elimination in phrase (b) in Figure 2 occurred in the 
extracted noun. Because the vowel elimination 
occurs only in the last vowel of a noun, we check the 
last two characters of the extracted noun. If both of 
the characters are consonants, the eliminated vowel 
is inserted using a ?Vowel insertion rule? and the 
noun is converted into its original form. 
Existing Mongolian stemming methods (Ehara et 
al., 2004; Sanduijav et al, 2005) use noun 
dictionaries. Because we intend to extract loanwords 
that are not in existing dictionaries, the above 
methods cannot be used. Noun dictionaries have to 
be updated as new words are created. 
Our stemming method does not require a noun 
dictionary. Instead, we manually produced a suffix 
dictionary, suffix segmentation rule, and vowel 
insertion rule. However, once these resources are 
produced, almost no further compilation is required. 
The suffix dictionary consists of 37 suffixes that 
can concatenate with nouns. These suffixes are 
postpositional particles. Table 1 shows the dictionary 
entries, in which the inflection forms of the 
postpositional particles are shown in parentheses. 
The suffix segmentation rule consists of 173 rules. 
We show examples of these rules in Figure 4. Even 
if suffixes are identical in their phrases, the 
segmentation rules can be different, depending on  
the counterpart noun. 
In Figure 4, the suffix ????? matches both the 
noun phrases (a) and (b) by backward partial 
matching. However, each phrase is segmented by a        
Table 1: Entries of the suffix dictionary. 
detect a suffix in
the phrase 
Suffix dictionary Suffix segmentation rule
phrase 
noun 
segment a suffix 
and extract a noun
Yes 
 
insert a vowel 
check if the last two characters of the 
noun are both consonants 
Vowel insertion rule
No 
Case Suffix 
Genitive 
Accusative 
Dative 
Ablative 
Instrumental 
Cooperative 
Reflexive 
Plural 
?, ?, ??, ??, ??, ???, ??? 
??, ???, ? 
?, ? 
??? (???), ??? (???), ???, ??? 
??? (???), ??? (???), ???, ??? 
???, ???, ??? 
?? (??), ?? (??), ??, ?? 
??? (???), ??? (???) 
 
Suffix Noun phrase Noun 
(a) ?????? 
mother?s 
??? 
mother 
 
??? 
Genitive 
 
(b) ????????? 
Haraa?(river name)s 
????? 
Haraa 
Figure 4: Examples of the suffix segmentation rule. 
 
deferent rule independently. The underlined suffixes 
are segmented in each phrase, respectively. In phrase 
(a), there is no inflection, and the suffix is easily 
segmented. However, in phrase (b), a consonant 
insertion has occurred. Thus, both the inserted 
consonant, ???, and the suffix have to be removed. 
 The vowel insertion rule consists of 12 rules. To 
insert an eliminated vowel and extract the original 
form of the noun, we check the last two characters of 
a target noun. If both of these are consonants, we 
determine that a vowel was eliminated. 
However, a number of nouns end with two 
consonants inherently, and therefore, we referred to a 
textbook on Mongolian grammar (Bayarmaa, 2002) 
to produce 12 rules to determine when to insert a 
vowel between two consecutive consonants. 
For example, if any of ???, ???, ???, ???, ???, or 
??? are at the end of a noun, a vowel is inserted. 
However, if any of ???, ???, ???, ???, ???, ???, ???, 
???, or ??? are the second to last consonant in a noun, 
a vowel is not inserted. 
The Mongolian vowel harmony rule is a 
phonological rule in which female vowels and male 
vowels are prohibited from occurring in a single 
word together (with the exception of proper nouns). 
We used this rule to determine which vowel should 
be inserted. The appropriate vowel is determined by 
the first vowel of the first syllable in the target noun. 
660
For example, if there are ??? and ??? in the first 
syllable, the vowel ??? is inserted between the last 
two consonants. 
3.3 Extracting candidate loanwords 
After collecting nouns using our stemming method, 
we discard the conventional Mongolian nouns. We 
discard nouns defined in a noun dictionary 
(Sanduijav et al, 2005), which includes 1,926 nouns. 
We also discard proper nouns and abbreviations. The 
first characters of proper nouns, such as ?????????? 
(Erdenebat)?, and all the characters of abbreviations, 
such as ????? (Nuclear research centre)?, are 
written using capital letters in Mongolian. Thus, we 
discard words that are written using capital 
characters, except those occurring at the beginning of 
sentences. In addition, because ??? and ??? are not 
used to spell out Western languages, words including 
those characters are also discarded. 
3.4 Extracting loanwords based on rules 
We manually produced seven rules to identify 
loanwords in Mongolian. Words that match with one 
of the following rules are extracted as loanwords. 
(a) A word including the consonants ???, ???, ???, 
or ???. 
These consonants are usually used to spell out 
foreign words. 
(b) A word that violated the Mongolian vowel 
harmony rule. 
Because of the vowel harmony rule, a word 
that includes female and male vowels, which is 
not based on the Mongolian phonetic system, is 
probably a loanword. 
(c) A word beginning with two consonants. 
A conventional Mongolian word does not 
begin with two consonants. 
(d) A word ending with two particular consonants. 
A word whose penultimate character is any 
of: ???, ???, ???, ???, ???, ???, or ??? and 
whose last character is a consonant violates 
Mongolian grammar, and is probably a 
loanword. 
(e) A word beginning with the consonant ???. 
In a modern Mongolian dictionary (Ozawa, 
2000), there are 54 words beginning with ???, 
of which 31 are loanwords. Therefore, a word 
beginning with ??? is probably a loanword. 
(f) A word beginning with the consonant ???. 
In a modern Mongolian dictionary (Ozawa, 
2000), there are 49 words beginning with ???, 
of which only four words are conventional 
Mongolian words. Therefore, a word beginning 
with ??? is probably a loanword. 
(g) A word ending with ?<consonant> + ??. 
We discovered this rule empirically. 
3.5 Romanization  
We manually aligned each Mongolian Cyrillic 
alphabet to its Roman representation1. 
In Japanese, the Hepburn and Kunrei systems are 
commonly used for romanization proposes. We used 
the Hepburn system, because its representation is 
similar to that used in Mongolian, compared to the 
Kunrei system. 
However, we adapted 11 Mongolian romanization 
expressions to the Japanese Hepburn romanization. 
For example, the sound of the letter ?L? does not 
exist in Japanese, and thus, we converted ?L? to ?R? 
in Mongolian. 
3.6 N-gram retrieval 
By using a document retrieval method, we efficiently 
identify Katakana words that are phonetically similar 
to a candidate loanword. In other words, we use a 
candidate loanword, and each Katakana word as a 
query and a document, respectively. We call this 
method ?N-gram retrieval?. 
Because the N-gram retrieval method does not 
consider the order of the characters in a target word, 
the accuracy of matching two words is low, but the 
computation time is fast. On the other hand, because 
DP matching considers the order of the characters in 
a target word, the accuracy of matching two words is 
high, but the computation time is slow. We combined 
these two methods to achieve a high matching 
accuracy with a reasonable computation time. 
First, we extract Katakana words that are 
phonetically similar to a candidate loanword using 
N-gram retrieval. Second, we compute the similarity 
between the candidate loanword and each of the 
retrieved Katakana words using DP matching to 
improve the accuracy. 
We romanize all the Katakana words in the 
dictionary and index them using consecutive N 
                                                         
1 http://badaa.mngl.net/docs.php?p=trans_table (May, 2006) 
661
characters. We also romanize each candidate 
loanword when use as a query. We experimentally 
set N = 2, and use the Okapi BM25 (Robertson et al, 
1995) for the retrieval model. 
3.7 Computing phonetic similarity 
Given the romanized Katakana words and the 
romanized candidate loanwords, we compute the 
similarity between the two strings, and select the 
pairs associated with a score above a predefined 
threshold as translations. We use DP matching to 
identify the number of differences (i.e., insertion, 
deletion, and substitution) between two strings on an 
alphabet-by-alphabet basis. 
While consonants in transliteration are usually the 
same across languages, vowels can vary depending 
on the language. The difference in consonants 
between two strings should be penalized more than 
the difference in vowels. We compute the similarity 
between two romanized words using Equation (1). 
         
vc
dvdc
+?
+??? ?
? )(2
1           (1) 
Here, dc and dv denote the number of differences in 
consonants and vowels, respectively, and ? is a 
parametric consonant used to control the importance 
of the consonants. We experimentally set ? = 2. 
Additionally, c and v denote the number of all the 
consonants and vowels in the two strings, 
respectively. The similarity ranges from 0 to 1. 
 
4 Experiments  
4.1 Method 
We collected 1,118 technical reports published in 
Mongolian from the ?Mongolian IT Park?2 and used 
them as a Mongolian corpus. The number of phrase 
types and phrase tokens in our corpus were 110,458 
and 263,512, respectively. 
We collected 111,116 Katakana words from 
multiple Japanese dictionaries, most of which were 
technical term dictionaries. 
We evaluated our method from four perspectives: 
?stemming?, ?loanword extraction?, ?translation 
extraction?, and ?computational cost.? We will 
discuss these further in Sections 4.2-4.5, respectively. 
4.2 Evaluating stemming  
We randomly selected 50 Mongolian technical 
                                                         
2 http://www.itpark.mn/ (May, 2006) 
reports from our corpus, and used them to evaluate 
the accuracy of our stemming method. These 
technical reports were related to: medical 
science (17), geology (10), light industry (14), 
agriculture (6), and sociology (3). In these 50 reports, 
the number of phrase types including conventional 
Mongolian nouns and loanword nouns was 961 and 
206, respectively. We also found six phrases 
including loanword verbs, which were not used in 
the evaluation.  
Table 2 shows the results of our stemming 
experiment, in which the accuracy for conventional 
Mongolian nouns was 98.7% and the accuracy for 
loanwords was 94.6%. Our stemming method is 
practical, and can also be used for morphological 
analysis of Mongolian corpora. 
We analyzed the reasons for any failures, and 
found that for 12 conventional nouns and 11 
loanwords, the suffixes were incorrectly segmented. 
4.3 Evaluating loanword extraction 
We used our stemming method on our corpus and 
selected the most frequently used 1,300 words. We 
used these words to evaluate the accuracy of our 
loanword extraction method. Of these 1,300 words, 
165 were loanwords. We varied the threshold for the 
similarity, and investigated the relationship between 
precision and recall. Recall is the ratio of the number 
of correct loanwords extracted by our method to the 
total number of correct loanwords. Precision is the 
ratio of the number of correct loanwords extracted 
by our method to the total number of words 
extracted by our method. We extracted loanwords 
using rules (a)?(g) defined in Section 3.4. As a result, 
139 words were extracted. 
Table 3 shows the precision and recall of each rule. 
The precision and recall showed high values using 
?All rules?, which combined the words extracted by 
rules (a)?(g) independently. 
We also extracted loanwords using the phonetic 
similarity, as discussed in Sections 3.6 and 3.7. 
 
Table 2: Results of our noun stemming method. 
 No. of each phrase type Accuracy (%) 
Conventional 
nouns 
961 98.7
Loanwords 206 94.6
662
 
 
 
 
 
 
 
We used the N-gram retrieval method to obtain up to 
the top 500 Katakana words that were similar to each 
candidate loanword. Then, we selected up to the top 
five pairs of a loanword and a Katakana word whose 
similarity computed using Equation (1) was greater 
than 0.6. Table 4 shows the results of our 
similarity-based extraction. 
Both the precision and the recall for the 
similarity-based loanword extraction were lower 
than those for the ?All rules? data listed in Table 3. 
 
Table 4: Precision and recall for our similarity-based 
loanword extraction. 
Words extracted 
automatically 
Extracted correct 
loanwords 
Precision 
(%) 
Recall
(%) 
3,479 109 3.1 66.1
 
We also evaluated the effectiveness of a 
combination of the N-gram and DP matching 
methods. We performed similarity-based extraction 
after rule-based extraction. Table 5 shows the results, 
in which the data of the ?Rule? are identical to those 
of the ?All rules? data listed in Table 3. However, the 
?Similarity? data are not identical to those listed in 
Table 4, because we performed similarity-based 
extraction using only the words that were not 
extracted by rule-based extraction.  
When we combined the rule-based and 
similarity-based methods, the recall improved from 
84.2% to 91.5%. The recall value should be high 
when a human expert modifies or verifies the 
resultant dictionary. 
Figure 5 shows example of extracted loanwords in 
Mongolian and their English glosses. 
4.4 Evaluating Translation extraction  
In the row ?Both? shown in Table 5, 151 loanwords 
were extracted, for each of which we selected up to 
the top five Katakana words whose similarity 
computed using Equation (1) was greater than 0.6 as 
 
 
Table 3: Precision and recall for rule-based loanword extraction. 
Rules (a) (b) 
 
(c) (d) (e) (f) (g) All rules 
Words extracted automatically 102 63
 
21 6 4 5 24 150
Extracted correct loanwords 101 60
 
20 5 4
 
5 19 139
Precision (%) 99.0 95.2 95.2 83.3
 
Table 5: Precision and recall of different loanword 
extraction methods. 
 No. of 
words
No. that 
were correct 
Precision 
(%)  
Recall 
(%) 
Rule 150 139 92.7 84.2
Similarity 60 12 20.0 46.2
Both 210 151 71.2 91.5
 
Mongolian English gloss 
???????? 
????????? 
???????? 
????????? 
albumin 
laboratory 
mechanism 
mitochondria 
Figure 5: Example of extracted loanwords. 
 
translations. As a result, Japanese translations were 
extracted for 109 loanwords. Table 6 shows the 
results, in which the precision and recall of 
extracting Japanese?Mongolian translations were 
56.2% and 72.2%, respectively. 
We analyzed the data and identified the reasons 
for any failures. For five loanwords, the N-gram 
retrieval failed to search for the similar Katakana 
words. For three loanwords, the phonetic similarity 
computed using Equation (1) was not high enough 
for a correct translation. For 27 loanwords, the 
Japanese translations did not exist inherently. For 
seven loanwords, the Japanese translations existed, 
but were not included in our Katakana dictionary.  
Figure 6 shows the Japanese translations extracted 
for the loanwords shown in Figure 5. 
 
Table 6: Precision and recall for translation 
extraction.  
No. of translations 
extracted 
automatically 
No. of extracted 
correct 
translations 
Precision 
(%) 
 
Recall 
(%) 
194 109 56.2 72.2
 
100 100 79.2 92.7
Recall (%) 61.2 36.4 12.1 3.0 2.4 3.03 11.5 84.2
663
Japanese Mongolian English gloss 
????? 
?????  ?
????? 
??????? 
???????? 
????????? 
???????? 
????????? 
albumin 
laboratory 
mechanism 
mitochondria 
Figure 6: Japanese translations extracted for the 
loanwords shown in Figure 5. 
 
4.5 Evaluating computational cost 
We randomly selected 100 loanwords from our 
corpus, and used them to evaluate the computational 
cost of the different extraction methods. We 
compared the computation time and the accuracy of 
?N-gram?, ?DP matching?, and ?N-gram + DP 
matching? methods. The experiments were 
performed using the same PC (CPU = Pentium III 1 
GHz dual, Memory = 2 GB). 
Table 7 shows the improvement in computation 
time by ?N-gram + DP matching? on ?DP matching?, 
and the average rank of the correct translations for 
?N-gram?. We improved the efficiency, while 
maintaining the sorting accuracy of the translations. 
 
Table 7: Evaluation of the computational cost. 
Method N-gram DP N-gram + DP
Loanwords 100 
Computation time (sec.) 95 136,815 293
Extracted correct 
translations 
66 66 66
Average rank of correct 
translations 
44.8 2.7 2.7
 
5 Conclusion 
We proposed methods for extracting loanwords from 
Cyrillic Mongolian corpora and producing a 
Japanese?Mongolian bilingual dictionary. Our 
research is the first serious effort in producing 
dictionaries of loanwords and their translations 
targeting Mongolian. We devised our own rules to 
extract loanwords from Mongolian corpora. We also 
extracted words in Mongolian corpora that are 
phonetically similar to Japanese Katakana words as 
loanwords. We also corresponded the extracted 
loanwords to Japanese words, and produced a 
Japanese?Mongolian bilingual dictionary. A noun 
stemming method that does not require noun 
dictionaries was also proposed. Finally, we evaluated 
the effectiveness of the components experimentally. 
 
References  
Terumasa Ehara, Suzushi Hayata, and Nobuyuki Kimura. 2004. 
Mongolian morphological analysis using ChaSen. Proceedings 
of the 10th Annual Meeting of the Association for Natural 
Language Processing, pp. 709-712. (In Japanese). 
Atsushi Fujii, Tetsuya Ishikawa, and Jong-Hyeok Lee. 2004. 
Term extraction from Korean corpora via Japanese. 
Proceedings of the 3rd International Workshop on 
Computational Terminology, pp. 71-74. 
Pascal Fung and Kathleen McKeown. 1996. Finding terminology 
translations from non-parallel corpora. Proceedings of the 5th 
Annual Workshop on Very Large Corpora, pp. 53-87. 
Wai Lam, Ruizhang Huang, and Pik-Shan Cheung. 2004. 
Learning phonetic similarity for matching named entity 
translations and mining new translations. Proceedings of the 
27th Annual International ACM SIGIR Conference on 
Research and Development in Information Retrieval, pp. 
289-296. 
Sung Hyun Myaeng and Kil-Soon Jeong. 1999. 
Back-Transliteration of foreign words for information retrieval. 
Information Processing and Management, Vol. 35, No. 4, pp. 
523 -540. 
Jong-Hooh Oh and Key-Sun Choi. 2001. Automatic extraction of 
transliterated foreign words using hidden markov model. 
Proceedings of the International Conference on Computer 
Processing of Oriental Languages, 2001, pp. 433-438. 
Shigeo Ozawa. Modern Mongolian Dictionary. Daigakushorin. 
2000. 
Stephen E. Robertson, Steve Walker, Susan Jones, Micheline 
Hancock-Beaulieu, and Mike Gatford. 1995. Okapi at TREC-3,  
Proceedings of the Third Text REtrieval Conference (TREC-3), 
NIST Special Publication 500-226. pp. 109-126. 
Enkhbayar Sanduijav, Takehito Utsuro, and Satoshi Sato. 2005. 
Mongolian phrase generation and morphological analysis 
based on phonological and morphological constraints. Journal 
of Natural Language Processing, Vol. 12, No. 5, pp. 185-205. 
(In Japanese) . 
Frank Smadja, Vasileios Hatzivassiloglou, Kathleen R. McKeown. 
1996. Translating collocations for bilingual lexicons: A 
statistical approach. Computational Linguistics, Vol. 22, No. 1, 
pp. 1-38.  
Bayarmaa Ts. 2002. Mongolian grammar in I-IV grades. (In 
Mongolian). 
664
