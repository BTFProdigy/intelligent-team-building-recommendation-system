Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 485?494,
Honolulu, October 2008. c?2008 Association for Computational Linguistics
Improving Interactive Machine Translation via Mouse Actions
Germa?n Sanchis-Trilles and Daniel Ortiz-Mart??nez and Jorge Civera
Instituto Tecnolo?gico de Informa?tica
Universidad Polite?cnica de Valencia
{gsanchis,dortiz,jorcisai}@iti.upv.es
Francisco Casacuberta and Enrique Vidal
Departamento de Sistemas Informa?ticos y Computacio?n
Universidad Polite?cnica de Valencia
{fcn,evidal}@dsic.upv.es
Hieu Hoang
University of Edinburgh
hhoang@sms.ed.ac.uk
Abstract
Although Machine Translation (MT) is a very
active research field which is receiving an in-
creasing amount of attention from the research
community, the results that current MT sys-
tems are capable of producing are still quite
far away from perfection. Because of this,
and in order to build systems that yield correct
translations, human knowledge must be inte-
grated into the translation process, which will
be carried out in our case in an Interactive-
Predictive (IP) framework. In this paper, we
show that considering Mouse Actions as a sig-
nificant information source for the underly-
ing system improves the productivity of the
human translator involved. In addition, we
also show that the initial translations that the
MT system provides can be quickly improved
by an expert by only performing additional
Mouse Actions. In this work, we will be using
word graphs as an efficient interface between
a phrase-based MT system and the IP engine.
1 Introduction
Information technology advances in modern society
have led to the need of more efficient methods of
translation. It is important to remark that current
MT systems are not able to produce ready-to-use
texts (Kay, 1997; Hutchins, 1999; Arnold, 2003).
Indeed, MT systems are usually limited to specific
semantic domains and the translations provided re-
quire human post-editing in order to achieve a cor-
rect high-quality translation.
A way of taking advantage of MT systems is to
combine them with the knowledge of a human trans-
lator, constituting the so-called Computer-Assisted
Translation (CAT) paradigm. CAT offers different
approaches in order to benefit from the synergy be-
tween humans and MT systems.
An important contribution to interactive CAT
technology was carried out around the TransType
(TT) project (Langlais et al, 2002; Foster et al,
2002; Foster, 2002; Och et al, 2003). This project
entailed an interesting focus shift in which interac-
tion directly aimed at the production of the target
text, rather than at the disambiguation of the source
text, as in former interactive systems. The idea
proposed was to embed data driven MT techniques
within the interactive translation environment.
Following these TT ideas, (Barrachina and oth-
ers, 2008) propose the usage of fully-fledged statis-
tical MT (SMT) systems to produce full target sen-
tence hypotheses, or portions thereof, which can be
partially or completely accepted and amended by a
human translator. Each partial correct text segment
is then used by the SMT system as additional infor-
mation to achieve further, hopefully improved sug-
gestions. In this paper, we also focus on the inter-
active and predictive, statistical MT (IMT) approach
to CAT. The IMT paradigm fits well within the In-
teractive Pattern Recognition framework introduced
in (Vidal and others, 2007).
485
SOURCE (x): Para encender la impresora:
REFERENCE (y): To power on the printer:
ITER-0 (p) ( )(s?h) To switch on:
ITER-1
(p) To
(sl) switch on:
(k) power
(s?h) on the printer:
ITER-2
(p) To power on the printer:
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) To power on the printer:
Figure 1: IMT session to translate a Spanish sentence into English. Non-validated hypotheses are displayed in italics,
whereas accepted prefixes are printed in normal font.
Figure 1 illustrates a typical IMT session. Ini-
tially, the user is given an input sentence x to be
translated. The reference y provided is the trans-
lation that the user would like to achieve at the end
of the IMT session. At iteration 0, the user does not
supply any correct text prefix to the system, for this
reason p is shown as empty. Therefore, the IMT sys-
tem has to provide an initial complete translation sh,
as it were a conventional SMT system. At the next
iteration, the user validates a prefix p as correct by
positioning the cursor in a certain position of sh. In
this case, after the words ?To print a?. Implicitly, he
is also marking the rest of the sentence, the suffix sl,
as potentially incorrect. Next, he introduces a new
word k, which is assumed to be different from the
first word sl1 in the suffix sl which was not validated,
k 6= sl1 . This being done, the system suggests a new
suffix hypothesis s?h, subject to s?h1 = k. Again, the
user validates a new prefix, introduces a new word
and so forth. The process continues until the whole
sentence is correct that is validated introducing the
special word ?#?.
As the reader could devise from the IMT session
described above, IMT aims at reducing the effort
and increasing the productivity of translators, while
preserving high-quality translation. For instance, in
Figure 1, only three interactions were necessary in
order to achieve the reference translation.
In this paper, we will show how Mouse Actions
performed by the human expert can be taken advan-
tage of in order to further reduce this effort.
2 Statistical interactive-predictive MT
In this section we will briefly describe the statistical
framework of IMT. IMT can be seen as an evolution
of the SMT framework, which has proved to be an
efficient framework for building state-of-the-art MT
systems with little human effort, whenever adequate
corpora are available (Hutchings and Somers, 1992).
The fundamental equation of the statistical approach
to MT is
y? = argmax
y
Pr(y |x) (1)
= argmax
y
Pr(x |y)Pr(y) (2)
where Pr(x |y) is the translation model modelling
the correlation between source and target sentence
and Pr(y) is the language model representing the
well-formedness of the candidate translation y.
In practise, the direct modelling of the posterior
probability Pr(y|x) has been widely adopted. To
this purpose, different authors (Papineni et al, 1998;
Och and Ney, 2002) propose the use of the so-called
log-linear models, where the decision rule is given
by the expression
y? = argmax
y
M
?
m=1
?mhm(x,y) (3)
where hm(x,y) is a score function representing an
important feature for the translation of x into y, M
is the number of models (or features) and ?m are the
weights of the log-linear combination.
486
One of the most popular instantiations of log-
linear models is that including phrase-based (PB)
models (Zens et al, 2002; Koehn et al, 2003).
Phrase-based models allow to capture contextual in-
formation to learn translations for whole phrases in-
stead of single words. The basic idea of phrase-
based translation is to segment the source sentence
into phrases, then to translate each source phrase
into a target phrase, and finally to reorder the trans-
lated target phrases in order to compose the tar-
get sentence. Phrase-based models were employed
throughout this work.
In log-linear models, the maximisation problem
stated in Eq. 3 is solved by means of the beam search
algorithm1 which was initially introduced in (Low-
erre, 1976) for its application in the field of speech
recognition. The beam search algorithm attempts to
generate partial solutions, called hypotheses, until
a complete sentence is found; these hypotheses are
stored in a stack and ordered by their score. Such a
score is given by the log-linear combination of fea-
ture functions.
However, Eq. 1 needs to be modified according to
the IMT scenario in order to take into account part
of the target sentence that is already translated, that
is p and k
s?h = argmax
sh
Pr(sh|x,p, k) (4)
where the maximisation problem is defined over the
suffix sh. This allows us to rewrite Eq. 4, by decom-
posing the right side appropriately and eliminating
constant terms, achieving the equivalent criterion
s?h = argmax
sh
Pr(p, k, sh|x). (5)
An example of the intuition behind these variables
can be seen in Figure 1.
Note that, since (p k sh) = y, Eq. 5 is very simi-
lar to Eq. 1. The main difference is that the argmax
search is now performed over the set of suffixes sh
that complete (p k) instead of complete sentences
(y in Eq. 1). This implies that we can use the same
models if the search procedures are adequately mod-
ified (Barrachina and others, 2008).
1Also known as stack decoding algorithm.
3 Phrase-based IMT
The phrase-based approach presented above can be
easily adapted for its use in an IMT scenario. The
most important modification is to rely on a word
graph that represents possible translations of the
given source sentence. The use of word graphs
in IMT has been studied in (Barrachina and oth-
ers, 2008) in combination with two different trans-
lation techniques, namely, the Alignment Templates
technique (Och et al, 1999; Och and Ney, 2004),
and the Stochastic Finite State Transducers tech-
nique (Casacuberta and Vidal, 2007).
3.1 Generation of word graphs
A word graph is a weighted directed acyclic graph,
in which each node represents a partial translation
hypothesis and each edge is labelled with a word of
the target sentence and is weighted according to the
scores given by an SMT model (see (Ueffing et al,
2002) for more details). In (Och et al, 2003), the
use of a word graph is proposed as interface between
an alignment-template SMT model and the IMT en-
gine. Analogously, in this work we will be using
a word graph built during the search procedure per-
formed on a PB SMT model.
During the search process performed by the above
mentioned beam search algorithm, it is possible to
create a segment graph. In such a graph, each node
represents a state of the SMT model, and each edge
a weighted transition between states labelled with a
sequence of target words. Whenever a hypothesis is
extended, we add a new edge connecting the state
of that hypothesis with the state of the extended hy-
pothesis. The new edge is labelled with the sequence
of target words that has been incorporated to the ex-
tended hypothesis and is weighted appropriately by
means of the score given by the SMT model.
Once the segment graph is generated, it can be
easily converted into a word graph by the introduc-
tion of artificial states for the words that compose
the target phrases associated to the edges.
3.2 IMT using word graphs
During the process of IMT for a given source sen-
tence, the system makes use of the word graph gen-
erated for that sentence in order to complete the pre-
fixes accepted by the human translator. Specifically,
487
SOURCE (x): Para encender la impresora:
REFERENCE (y): To power on the printer:
ITER-0 (p) ( )(s?h) To switch on:
ITER-1
(p) To
(sl) |switch on:
(s?h) power on the printer:
ITER-2
(p) To power on the printer:
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) To power on the printer:
Figure 2: Example of non-explicit positioning MA which solves an error of a missing word. In this case, the system
produces the correct suffix sh immediately after the user validates a prefix p, implicitly indicating that we wants the
suffix to be changed, without need of any further action. In ITER-1, character | indicates the position where a MA
was performed, sl is the suffix which was rejected by that MA, and s?h is the new suffix that the system suggests after
observing that sl is to be considered incorrect. Character # is a special character introduced by the user to indicate that
the hypothesis is to be accepted.
the system finds the best path in the word graph as-
sociated with a given prefix so that it is able to com-
plete the target sentence, being capable of providing
several completion suggestions for each prefix.
A common problem in IMT arises when the user
sets a prefix which cannot be found in the word
graph, since in such a situation the system is un-
able to find a path through the word graph and pro-
vide an appropriate suffix. The common procedure
to face this problem is to perform a tolerant search
in the word graph. This tolerant search uses the well
known concept of Levenshtein distance in order to
obtain the most similar string for the given prefix
(see (Och et al, 2003) for more details).
4 Enriching user?machine interaction
Although the IMT paradigm has proved to offer in-
teresting benefits to potential users, one aspect that
has not been reconsidered as of yet is the user?
machine interface. Hence, in traditional IMT the
system only received feedback whenever the user
typed in a new word. In this work, we show how
to enrich user?machine interaction by introducing
Mouse Actions (MA) as an additional information
source for the system. By doing so, we will consider
two types of MAs, i.e. non-explicit (or positioning)
MAs and interaction-explicit MAs.
4.1 Non-explicit positioning MAs
Before typing in a new word in order to correct a hy-
pothesis, the user needs to position the cursor in the
place where he wants to type such a word. In this
work, we will assume that this is done by perform-
ing a MA, although the same idea presented can also
be applied when this is done by some other means.
It is important to point out that, by doing so, the user
is already providing some very useful information to
the system: he is validating a prefix up to the posi-
tion where he positioned the cursor, and, in addition,
he is signalling that whatever word is located after
the cursor is to be considered incorrect. Hence, the
system can already capture this fact and provide a
new translation hypothesis, in which the prefix re-
mains unchanged and the suffix is replaced by a new
one in which the first word is different to the first
word of the previous suffix. We are aware that this
does not mean that the new suffix will be correct, but
given that we know that the first word in the previ-
ous suffix was incorrect, the worst thing which can
happen is that the the first word of the new suffix is
incorrect as well. However, if the new suffix hap-
pens to be correct, the user will happily find that he
does not need to correct that word any more.
An example of such behaviour can be seen in
Figure 2. In this example, the SMT system first
provides a translation which the user does not
488
like. Hence, he positions the cursor before word
?postscript?, with the purpose of typing in ?lists?.
By doing so, he is validating the prefix ?To print
a?, and signalling that he wants ?postscript? to be
replaced. Before typing in anything, the system re-
alises that he is going to change the word located
after the cursor, and replaces the suffix by another
one, which is the one the user had in mind in the
first place. Finally, the user only has to accept the
final translation.
We are naming this kind of MA non-explicit be-
cause it does not require any additional action from
the user: he has already performed a MA in order to
position the cursor at the place he wants, and we are
taking advantage of this fact to suggest a new suffix
hypothesis.
Since the user needs to position the cursor before
typing in a new word, it is important to point out
that any improvement achieved by introducing non-
explicit MAs does not require any further effort from
the user, and hence is considered to have no cost.
Hence, we are now considering two different situ-
ations: the first one, the traditional IMT framework,
in which the system needs to find a suffix according
to Eq. 5, and a new one, in which the system needs
to find a suffix in which the first word does not need
to be a given k, but needs to be different to a given
sl1. This constraint can be expressed by the follow-
ing equation:
s?h = argmax
sh:sh1 6=sl1
Pr(p, sh|x, sl) (6)
where sl is the suffix generated in the previous iter-
ation, already discarded by the user, and sl1 is the
first word in sl. k is omitted in this formula because
the user did not type any word at all.
4.2 Interaction-explicit MAs
If the system is efficient and provides suggestions
which are good enough, one could easily picture a
situation in which the expert would ask the system
to replace a given suffix, without typing in any word.
We will be modelling this as another kind of MA,
interaction-explicit MA, since the user needs to in-
dicate explicitly that he wants a given suffix to be
replaced, in contrast to the non-explicit positioning
MA. However, if the underlying MT engine provid-
ing the suffixes is powerful enough, the user would
quickly realise that performing a MA is less costly
that introducing a whole new word, and would take
advantage of this fact by systematically clicking be-
fore introducing any new word. In this case, as
well, we assume that the user clicks before an in-
correct word, hence demanding a new suffix whose
first word is different, but by doing so he is adopting
a more participative and interactive attitude, which
was not demanded in the case of non-explicit posi-
tioning MAs. An example of such an explicit MA
correcting an error can be seen in Figure 3
In this case, however, there is a cost associated to
this kind of MAs, since the user does need to per-
form additional actions, which may or may not be
beneficial. It is very possible that, even after asking
for several new hypothesis, the user will even though
need to introduce the word he had in mind, hence
wasting the additional MAs he had performed.
If we allow the user to perform n MAs before in-
troducing a word, this problem can be formalised in
an analogous way as in the case of non-explicit MAs
as follows:
s?h= argmax
sh:sh1 6=sil1?i?{1..n}
Pr(p, sh|x, s1l , s2l , . . . , snl ) (7)
where sil1 is the first word of the i-th suffix dis-
carded and s1l , s2l , . . . , snl is the set of all n suffixes
discarded.
Note that this kind of MA could also be imple-
mented with some other kind of interface, e.g. by
typing some special key such as F1 or Tab. How-
ever, the experimental results would not differ, and
in our user interface we found it more intuitive to
implement it as a MA.
5 Experimental setup
5.1 System evaluation
Automatic evaluation of results is a difficult problem
in MT. In fact, it has evolved to a research field with
own identity. This is due to the fact that, given an
input sentence, a large amount of correct and differ-
ent output sentences may exist. Hence, there is no
sentence which can be considered ground truth, as is
the case in speech or text recognition. By extension,
this problem is also applicable to IMT.
In this paper, we will be reporting our results as
measured by Word Stroke Ratio (WSR) (Barrachina
489
SOURCE (x): Seleccione el tipo de instalacio?n.
REFERENCE (y): Select the type of installation.
ITER-0 (p) ( )(s?h) Select the installation wizard.
ITER-1
(p) Select the
(sl) |installation wizard.
(s?h) install script.
ITER-2
(p) Select the
(k) type
(s?h) installation wizard.
ITER-3
(p) Select the type
(sl) |installation wizard.
(s?h) of installation.
ITER-4
(p) Select the type of installation.
(sl) ( )
(k) (#)
(s?h) ( )
FINAL (p ? y) Select the type of installation.
Figure 3: Example of explicit interactive MA which corrects an erroneous suffix. In this case, a non-explicit MA is
performed in ITER-1 with no success. Hence, the user introduces word ?type? in ITER-2, which leaves the cursor
position located immediately after word ?type?. In this situation the user would not need to perform a MA to re-
position the cursor and continue typing in order to further correct the remaining errors. However, since he has learnt
the potential benefit of MAs, he performs an interaction-explicit MA in order to ask for a new suffix hypothesis, which
happens to correct the error.
and others, 2008), which is computed as the quotient
between the number of word-strokes a user would
need to perform in order to achieve the translation
he has in mind and the total number of words in
the sentence. In this context, a word-stroke is in-
terpreted as a single action, in which the user types
a complete word, and is assumed to have constant
cost. Moreover, each word-stroke also takes into ac-
count the cost incurred by the user when reading the
new suffix provided by the system.
In the present work, we decided to use WSR in-
stead of Key Stroke Ratio (KSR), which is used in
other works on IMT such as (Och et al, 2003). The
reason for this is that KSR is clearly an optimistic
measure, since in such a scenario the user is often
overwhelmed by receiving a great amount of trans-
lation options, as much as one per key stroke, and
it is not taken into account the time the user would
need to read all those hypotheses.
In addition, and because we are also introducing
MAs as a new action, we will also present results in
terms of Mouse Action Ratio (MAR), which is the
quotient between the amount of explicit MAs per-
formed and the number of words of the final trans-
lation. Hence, the purpose is to elicit the number of
times the user needed to request a new translation
(i.e. performed a MA), on a per word basis.
Lastly, we will also present results in terms of
uMAR (useful MAR), which indicates the amount
of MAs which were useful, i.e. the MAs that actu-
ally produced a change in the first word of the suffix
and such word was accepted. Formally, uMAR is
defined as follows:
uMAR = MAC ? n ?WSCMAC (8)
where MAC stands for ?Mouse Action Count?,
WSC for ?Word Stroke Count? and n is the max-
imum amount of MAs allowed before the user types
in a word. Note that MAC?n ?WSC is the amount
of MAs that were useful since WSC is the amount
of word-strokes the user performed even though he
had already performed n MAs.
Since we will only use single-reference WSR and
MAR, the results presented here are clearly pes-
simistic. In fact, it is relatively common to have the
underlying SMT system provide a perfectly correct
490
Table 1: Characteristics of Europarl for each of the sub-
corpora. OoV stands for ?Out of Vocabulary? words,
Dev. for Development, K for thousands of elements and
M for millions of elements.
De En Es En Fr En
Tr
ai
n
in
g Sentences 751K 731K 688K
Run. words 15.3M16.1M 15.7M15.2M 15.6M13.8M
Avg. len. 20.3 21.4 21.5 20.8 22.7 20.1
Voc. 195K 66K 103K 64K 80K 62K
D
ev
.
Sentences 2000 2000 2000
Run. words 55K 59K 61K 59K 67K 59K
Avg. len. 27.6 29.3 30.3 29.3 33.6 29.3
OoV 432 125 208 127 144 138
Te
st
Sentences 2000 2000 2000
Run. words 54K 58K 60K 58K 66K 58K
Avg. len. 27.1 29.0 30.2 29.0 33.1 29.3
OoV 377 127 207 125 139 133
translation, which is ?corrected? by the IMT proce-
dure into another equivalent translation, increasing
WSR and MAR significantly by doing so.
5.2 Corpora
Our experiments were carried out on the Eu-
roparl (Koehn, 2005) corpus, which is a corpus
widely used in SMT and that has been used in sev-
eral MT evaluation campaigns. Moreover, we per-
formed our experiments on the partition established
for the Workshop on Statistical Machine Translation
of the NAACL 2006 (Koehn and Monz, 2006). The
Europarl corpus (Koehn, 2005) is built from the pro-
ceedings of the European Parliament. Here, we will
focus on the German?English, Spanish?English and
French?English tasks, since these were the language
pairs selected for the cited workshop. The corpus is
divided into three separate sets: one for training, one
for development, and one for test. The characteris-
tics of the corpus can be seen in Table 1.
5.3 Experimental results
As a first step, we built a SMT system for each of
the language pairs cited in the previous subsection.
This was done by means of the Moses toolkit (Koehn
and others, 2007), which is a complete system for
building Phrase-Based SMT models. This toolkit in-
volves the estimation from the training set of four
different translation models, which are in turn com-
Table 2: WSR improvement when considering non-
explicit MAs. ?rel.? indicates the relative improvement.
All results are given in %.
pair baseline non-explicit rel.
Es?En 63.0?0.9 59.2?0.9 6.0?1.4
En?Es 63.8?0.9 60.5?1.0 5.2?1.6
De?En 71.6?0.8 69.0?0.9 3.6?1.3
En?De 75.9?0.8 73.5?0.9 3.2?1.2
Fr?En 62.9?0.9 59.2?1.0 5.9?1.6
En?Fr 63.4?0.9 60.0?0.9 5.4?1.4
bined in a log-linear fashion by adjusting a weight
for each of them by means of the MERT (Och, 2003)
procedure, optimising the BLEU (Papineni et al,
2002) score obtained on the development partition.
This being done, word graphs were generated
for the IMT system. For this purpose, we used a
multi-stack phrase-based decoder which will be dis-
tributed in the near future together with the Thot
toolkit (Ortiz-Mart??nez et al, 2005). We discarded
the use of the Moses decoder because preliminary
experiments performed with it revealed that the de-
coder by (Ortiz-Mart??nez et al, 2005) performs
clearly better when used to generate word graphs
for use in IMT. In addition, we performed an ex-
perimental comparison in regular SMT with the Eu-
roparl corpus, and found that the performance dif-
ference was negligible. The decoder was set to
only consider monotonic translation, since in real
IMT scenarios considering non-monotonic transla-
tion leads to excessive waiting time for the user.
Finally, the word graphs obtained were used
within the IMT procedure to produce the reference
translation contained in the test set, measuring WSR
and MAR. The results of such a setup can be seen in
Table 2. As a baseline system, we report the tradi-
tional IMT framework, in which no MA is taken into
account. Then, we introduced non-explicit MAs, ob-
taining an average improvement in WSR of about
3.2% (4.9% relative). The table also shows the
confidence intervals at a confidence level of 95%.
These intervals were computed following the boot-
strap technique described in (Koehn, 2004). Since
the confidence intervals do not overlap, it can be
stated that the improvements obtained are statisti-
cally significant.
491
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
Spanish -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
Spanish -> English
WSR
uMAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
German -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
German -> English
WSR
uMAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 50
 100
 150
 200
 250
 300
W
SR
M
AR
max. MAs per incorrect word
French -> English
WSR
MAR
 40
 45
 50
 55
 60
 65
 70
 0  1  2  3  4  5
 4
 6
 8
 10
 12
W
SR
u
M
AR
max. MAs per incorrect word
French -> English
WSR
uMAR
Figure 4: WSR improvement when considering one to five maximum MAs. All figures are given in %. The left
column lists WSR improvement versus MAR degradation, and the right column lists WSR improvement versus uMAR.
Confidence intervals at 95% confidence level following (Koehn, 2004).
Once the non-explicit MAs were considered and
introduced into the system, we analysed the effect
of performing up to a maximum of 5 explicit MAs.
Here, we modelled the user in such a way that, in
case a given word is considered incorrect, he will
always ask for another translation hypothesis until
he has asked for as many different suffixes as MAs
considered. The results of this setup can be seen in
Figure 4. This yielded a further average improve-
ment in WSR of about 16% (25% relative improve-
ment) when considering a maximum of 5 explicit
MAs. However, relative improvement in WSR and
492
uMAR increase drop significantly when increasing
the maximum allowed amount of explicit MAs from
1 to 5. For this reason, it is difficult to imagine that
a user would perform more than two or three MAs
before actually typing in a new word. Nevertheless,
just by asking twice for a new suffix before typing
in the word he has in mind, the user might be saving
about 15% of word-strokes.
Although the results in Figure 4 are only
for the translation direction ?foreign??English,
the experiments in the opposite direction (i.e.
English??foreign?) were also performed. How-
ever, the results were very similar to the ones dis-
played here. Because of this, and for clarity pur-
poses, we decided to omit them and only display the
direction ?foreign??English.
6 Conclusions and future work
In this paper, we have considered new input sources
for IMT. By considering Mouse Actions, we have
shown that a significant benefit can be obtained, in
terms of word-stroke reduction, both when consid-
ering only non-explicit MAs and when considering
MAs as a way of offering the user several suffix hy-
potheses. In addition, we have applied these ideas
on a state-of-the-art SMT baseline, such as phrase-
based models. To achieve this, we have first ob-
tained a word graph for each sentence which is to be
translated. Experiments were carried out on a refer-
ence corpus in SMT.
Note that there are other systems (Esteban and
others, 2004) that, for a given prefix, provide n-
best lists of suffixes. However, the functionality of
our system is slightly (but fundamentally) different,
since the suggestions are demanded to be different
in their first word, which implies that the n-best list
is scanned deeper, going directly to those hypothe-
ses that may be of interest to the user. In addition,
this can be done ?on demand?, which implies that
the system?s response is faster and that the user is
not confronted with a large list of hypotheses, which
often results overwhelming.
As future work, we are planning on performing a
human evaluation that assesses the appropriateness
of the improvements described.
Acknowledgements
This work has been partially supported by the Span-
ish MEC under scholarship AP2005-4023 and un-
der grants CONSOLIDER Ingenio-2010 CSD2007-
00018, and by the EC (FEDER) and the Spanish
MEC under grant TIN2006-15694-CO2-01.
References
D. J. Arnold, 2003. Computers and Translation: A trans-
lator?s guide, chapter 8, pages 119?142.
S. Barrachina et al 2008. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, page In press.
F. Casacuberta and E. Vidal. 2007. Learning finite-state
models for machine translation. Machine Learning,
66(1):69?91.
J. Esteban et al 2004. Transtype2 - an innovative
computer-assisted translation system. In The Compan-
ion Volume to the Proc. ACL?04, pages 94?97.
G. Foster, P. Langlais, and G. Lapalme. 2002. User-
friendly text prediction for translators. In Proc. of
EMNLP?02, pages 148?155.
G. Foster. 2002. Text Prediction for Translators. Ph.D.
thesis, Universite? de Montre?al.
J. Hutchings and H. Somers. 1992. An introduction to
machine translation. In Ed. Academic Press.
J. Hutchins. 1999. Retrospect and prospect in computer-
based translation. In Proc. of MT Summit VII, pages
30?44.
M. Kay. 1997. It?s still the proper place. Machine Trans-
lation, 12(1-2):35?38.
P. Koehn and C. Monz, editors. 2006. Proc. of the Work-
shop on SMT.
P. Koehn et al 2007. Moses: Open source toolkit for
statistical machine translation. In Proc. of the ACL?07.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. HLT/NAACL?03,
pages 48?54.
P. Koehn. 2004. Statistical significance tests for machine
translation evaluation. In Proc. of EMNLP?04, pages
388?395, Barcelona, Spain.
P. Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. In Proc. of the MT Summit X,
pages 79?86.
P. Langlais, G. Lapalme, and M. Loranger. 2002.
Transtype: Development-evaluation cycles to boost
translator?s productivity. Machine Translation,
15(4):77?98.
Bruce T. Lowerre. 1976. The harpy speech recogni-
tion system. Ph.D. thesis, Carnegie Mellon University,
Pittsburgh, PA, USA.
493
F. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical machine
translation. In Proc. of the ACL?02, pages 295?302.
F.J. Och and H. Ney. 2004. The alignment template ap-
proach to statistical machine translation. Comput. Lin-
guist., 30(4):417?449.
F. Och, C. Tillmann, and H. Ney. 1999. Improved align-
ment models for statistical machine translation. In
Proc. of EMNLP/WVLC?99, pages 20?28.
F.J. Och, R. Zens, and H. Ney. 2003. Efficient search for
interactive statistical machine translation. In Proc. of
EACL?03, pages 387?393.
F.J. Och. 2003. Minimum error rate training for statis-
tical machine translation. In Proc. of ACL?03, pages
160?167.
D. Ortiz-Mart??nez, I. Garc??a-Varea, and F. Casacuberta.
2005. Thot: a toolkit to train phrase-based statisti-
cal translation models. In Proc. of the MT Summit X,
pages 141?148.
K. Papineni, S. Roukos, and T. Ward. 1998. Maximum
likelihood and discriminative training of direct transla-
tion models. In Proc. of ICASSP?98, pages 189?192.
K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2002.
Bleu: A method for automatic evaluation of machine
translation. In Proc. of ACL?02.
N. Ueffing, F. Och, and H. Ney. 2002. Generation of
word graphs in statistical machine translation. In Proc.
of EMNLP?02, pages 156?163.
E. Vidal et al 2007. Interactive pattern recognition. In
Proc. of MLMI?07, pages 60?71.
R. Zens, F.J. Och, and H. Ney. 2002. Phrase-based sta-
tistical machine translation. In Proc. of KI?02, pages
18?32.
494
Proceedings of the Workshop on Statistical Machine Translation, pages 64?71,
New York City, June 2006. c?2006 Association for Computational Linguistics
Generalized Stack Decoding Algorithms for Statistical Machine Translation?
Daniel Ortiz Mart??nez
Inst. Tecnolo?gico de Informa?tica
Univ. Polite?cnica de Valencia
46071 Valencia, Spain
dortiz@iti.upv.es
Ismael Garc??a Varea
Dpto. de Informatica
Univ. de Castilla-La Mancha
02071 Albacete, Spain
ivarea@info-ab.uclm.es
Francisco Casacuberta Nolla
Dpto. de Sist Inf. y Comp.
Univ. Polite?c. de Valencia
46071 Valencia, Spain
fcn@dsic.upv.es
Abstract
In this paper we propose a generalization
of the Stack-based decoding paradigm for
Statistical Machine Translation. The well
known single and multi-stack decoding
algorithms defined in the literature have
been integrated within a new formalism
which also defines a new family of stack-
based decoders. These decoders allows
a tradeoff to be made between the ad-
vantages of using only one or multiple
stacks. The key point of the new formal-
ism consists in parameterizeing the num-
ber of stacks to be used during the de-
coding process, and providing an efficient
method to decide in which stack each par-
tial hypothesis generated is to be inserted-
during the search process. Experimental
results are also reported for a search algo-
rithm for phrase-based statistical transla-
tion models.
1 Introduction
The translation process can be formulated from a
statistical point of view as follows: A source lan-
guage string fJ1 = f1 . . . fJ is to be translated into
a target language string eI1 = e1 . . . eI . Every tar-
get string is regarded as a possible translation for the
source language string with maximum a-posteriori
probability Pr(eI1|fJ1 ). According to Bayes? theo-
rem, the target string e?I1 that maximizes1 the product
?This work has been partially supported by the Spanish
project TIC2003-08681-C02-02, the Agencia Valenciana de
Ciencia y Tecnolog??a under contract GRUPOS03/031, the Gen-
eralitat Valenciana, and the project HERMES (Vicerrectorado
de Investigacio?n - UCLM-05/06)
1Note that the expression should also be maximized by I ;
however, for the sake of simplicity we suppose that it is known.
of both the target language model Pr(eI1) and the
string translation model Pr(fJ1 |eI1) must be chosen.
The equation that models this process is:
e?I1 = arg max
eI1
{Pr(eI1) ? Pr(fJ1 |eI1)} (1)
The search/decoding problem in SMT consists in
solving the maximization problem stated in Eq. (1).
In the literature, we can find different techniques to
deal with this problem, ranging from heuristic and
fast (as greedy decoders) to optimal and very slow
decoding algorithms (Germann et al, 2001). Also,
under certain circumstances, stack-based decoders
can obtain optimal solutions.
Many works (Berger et al, 1996; Wang and
Waibel, 1998; Germann et al, 2001; Och et al,
2001; Ort??z et al, 2003) have adopted different types
of stack-based algorithms to solve the global search
optimization problem for statistical machine trans-
lation. All these works follow two main different
approaches according to the number of stacks used
in the design and implementation of the search algo-
rithm (the stacks are used to store partial hypotheses,
sorted according to their partial score/probability,
during the search process) :
? On the one hand, in (Wang and Waibel, 1998;
Och et al, 2001) a single stack is used. In
that case, in order to make the search feasible,
the pruning of the number of partial hypothe-
ses stored in the stack is needed. This causes
many search errors due to the fact that hy-
potheses covering a different number of source
(translated) words compete in the same condi-
tions. Therefore, the greater number of covered
words the higher possibility to be pruned.
? On the other hand (Berger et al, 1996; Ger-
mann et al, 2001) make use of multiple stacks
64
(one for each set of source covered/translated
words in the partial hypothesis) in order to
solve the disadvantages of the single-stack ap-
proach. By contrast, the problem of finding
the best hypothesis to be expanded introduces
an exponential term in the computational com-
plexity of the algorithm.
In (Ort??z et al, 2003) the authors present an em-
pirical comparison (about efficiency and translation
quality) of the two approaches paying special atten-
tion to the advantages and disadvantages of the two
approaches.
In this paper we present a new formalism consist-
ing of a generalization of the classical stack-based
decoding paradigm for SMT. This new formalism
defines a new family of stack-based decoders, which
also integrates the well known stack-based decoding
algorithms proposed so far within the framework of
SMT, that is single and multi-stack decoders.
The rest of the paper is organized as follows: in
section 2 the phrase-based approach to SMT is de-
picted; in section 3 the main features of classical
stack-based decoders are presented; in section 4 the
new formalism is presented and in section 5 exper-
imental results are shown; finally some conclusions
are drawn in section 6.
2 Phrase Based Statistical Machine
Translation
Different translation models (TMs) have been pro-
posed depending on how the relation between the
source and the target languages is structured; that is,
the way a target sentence is generated from a source
sentence. This relation is summarized using the con-
cept of alignment; that is, how the constituents (typ-
ically words or group-of-words) of a pair of sen-
tences are aligned to each other. The most widely
used single-word-based statistical alignment mod-
els (SAMs) have been proposed in (Brown et al,
1993; Ney et al, 2000). On the other hand, models
that deal with structures or phrases instead of single
words have also been proposed: the syntax trans-
lation models are described in (Yamada and Knight,
2001) , alignment templates are used in (Och, 2002),
and the alignment template approach is re-framed
into the so-called phrase based translation (PBT)
in (Marcu and Wong, 2002; Zens et al, 2002; Koehn
et al, 2003; Toma?s and Casacuberta, 2003).
For the translation model (Pr(fJ1 |eI1)) in Eq. (1),
PBT can be explained from a generative point of
view as follows (Zens et al, 2002):
1. The target sentence eI1 is segmented into K
phrases (e?K1 ).
2. Each target phrase e?k is translated into a source
phrase f? .
3. Finally, the source phrases are reordered in or-
der to compose the source sentence f?K1 = fJ1 .
In PBT, it is assumed that the relations between
the words of the source and target sentences can
be explained by means of the hidden variable a?K1 ,
which contains all the decisions made during the
generative story.
Pr(fJ1 |eI1) =
?
K,a?K1
Pr(, f?K1 , a?K1 |e?K1 )
=
?
K,a?K1
Pr(a?K1 |e?K1 )Pr(f?K1 |a?K1 , e?K1 )
(2)
Different assumptions can be made from the pre-
vious equation. For example, in (Zens et al, 2002)
the following model is proposed:
p?(fJ1 |eI1) = ?(eI1)
?
K,a?K1
K
?
k=1
p(f?k|e?a?k ) (3)
where a?k notes the index of the source phrase e?
which is aligned with the k-th target phrase f?k and
that all possible segmentations have the same proba-
bility. In (Toma?s and Casacuberta, 2001; Zens et al,
2002), it also is assumed that the alignments must be
monotonic. This led us to the following equation:
p?(fJ1 |eI1) = ?(eI1)
?
K,a?K1
K
?
k=1
p(f?k|e?k) (4)
In both cases the model parameters that have to be
estimated are the translation probabilities between
phrase pairs (? = {p(f? |e?)}), which typically are es-
timated as follows:
p(f? |e?) = N(f? , e?)N(e?) (5)
65
where N(f? |e?) is the number of times that f? have
been seen as a translation of e? within the training
corpus.
3 Stack-Decoding Algorithms
The stack decoding algorithm, also called A? algo-
rithm, was first introduced by F. Jelinek in (Jelinek,
1969). The stack decoding algorithm attempts to
generate partial solutions, called hypotheses, until a
complete translation is found2; these hypotheses are
stored in a stack and ordered by their score. Typi-
cally, this measure or score is the probability of the
product of the translation and the language models
introduced above. The A? decoder follows a se-
quence of steps for achieving a complete (and possi-
bly optimal) hypothesis:
1. Initialize the stack with an empty hypothesis.
2. Iterate
(a) Pop h (the best hypothesis) off the stack.
(b) If h is a complete sentence, output h and
terminate.
(c) Expand h.
(d) Go to step 2a.
The search is started from a null string and obtains
new hypotheses after an expansion process (step 2c)
which is executed at each iteration. The expansion
process consists of the application of a set of op-
erators over the best hypothesis in the stack, as it
is depicted in Figure 1. Thus, the design of stack
decoding algorithms involves defining a set of oper-
ators to be applied over every hypothesis as well as
the way in which they are combined in the expansion
process. Both the operators and the expansion algo-
rithm depend on the translation model that we use.
For the case of the phrase-based translation models
described in the previous section, the operator add is
defined, which adds a sequence of words to the tar-
get sentence, and aligns it with a sequence of words
of the source sentence.
The number of hypotheses to be stored during the
search can be huge. In order then to avoid mem-
2Each hypothesis has associated a coverage vector of length
J , which indicates the set of source words already cov-
ered/translated so far. In the following we will refer to this
simply as coverage.
Figure 1: Flow chart associated to the expansion of
a hypothesis when using an A? algorithm.
ory overflow problems, the maximum number of hy-
potheses that a stack may store has to be limited. It
is important to note that for a hypothesis, the higher
the aligned source words, the worse the score. These
hypotheses will be discarded sooner when an A?
search algorithm is used due to the stack length lim-
itation. Because of this, the multi-stack algorithms
were introduced.
Multi-stack algorithms store those hypotheses
with different subsets of source aligned words in dif-
ferent stacks. That is to say, given an input sentence
fJ1 composed of J words, multi-stack algorithms
employes 2J stacks to translate it. Such an organi-
zation improves the pruning of the hypotheses when
the stack length limitation is exceeded, since only
hypotheses with the same number of covered posi-
tions can compete with each other.
All the search steps given for A? algorithm can
also be applied here, except step 2a. This is due
to the fact that multiple stacks are used instead of
only one. Figure 2 depicts the expansion process
that the multi-stack algorithms execute, which is
slightly different than the one presented in Figure 1.
Multi-stack algorithms have the negative property of
spending significant amounts of time in selecting the
hypotheses to be expanded, since at each iteration,
the best hypothesis in a set of 2J stacks must be
searched for (Ort??z et al, 2003). By contrast, for the
A? algorithm, it is not possible to reduce the length
of the stack in the same way as in the multi-stack
case without loss of translation quality.
Additionally, certain translation systems, e.g. the
Pharaoh decoder (Koehn, 2003) use an alternative
66
Figure 2: Flow chart associated to the expansion of
a hypothesis when using a multi-stack algorithm.
approach which consists in assigning to the same
stack, those hypotheses with the same number of
source words covered.
4 Generalized Stack-Decoding Algorithms
As was mentioned in the previous section, given a
sentence fJ1 to be translated, a single stack decod-
ing algorithm employs only one stack to perform the
translation process, while a multi-stack algorithm
employs 2J stacks. We propose a possible way to
make a tradeoff between the advantages of both al-
gorithms that introduces a new parameter which will
be referred to as the granularity of the algorithm.
The granularity parameter determines the number of
stacks used during the decoding process.
4.1 Selecting the granularity of the algorithm
The granularity (G) of a generalized stack algorithm
is an integer which takes values between 1 and J ,
where J is the number of words which compose the
sentence to translate.
Given a sentence fJ1 to be translated, a general-
ized stack algorithm with a granularity parameter
equal to g, will have the following features:
? The algorithm will use at most 2g stacks to per-
form the translation
? Each stack will contain hypotheses which have
2J?g different coverages of fJ1
? If the algorithm can store at most S = s hy-
potheses, then, the maximum size of each stack
will be equal to s2g
4.2 Mapping hypotheses to stacks
Generalized stack-decoding algorithms require a
mechanism to decide in which stack each hypothesis
is to be inserted. As stated in section 4.1, given an
input sentence fJ1 and a generalized stack-decoding
algorithm with G = g, the decoder will work with
2g stacks, and each one will contain 2J?g different
coverages. Therefore, the above mentioned mecha-
nism can be expressed as a function which will be
referred to as the ? function. Given a hypothesis
coverage composed of J bits, the ? function return
a stack identifier composed of only g bits:
? : ({0, 1})J ?? ({0, 1})g (6)
Generalized stack algorithms are strongly in-
spired by multi-stack algorithms; however, both
types of algorithms differ in the way the hypothesis
expansion is performed. Figure 3 shows the expan-
sion algorithm of a generalized stack decoder with
a granularity parameter equal to g and a function ?
which maps hypotheses coverages to stacks.
Figure 3: Flow chart associated to the expansion of
a hypothesis when using a generalized-stack algo-
rithm.
The function ? can be defined in many ways,
but there are two essential principles which must be
taken into account:
? The ? function must be efficiently calculated
? Hypotheses whose coverage have a similar
number of bits set to one must be assigned to
the same stack. This requirement allows the
pruning of the stacks to be improved, since the
67
hypotheses with a similar number of covered
words can compete fairly
A possible way to implement the ? function,
namely ?1, consists in simply shifting the coverage
vector J ? g positions to the right, and then keeping
only the first g bits. Such a proposal is very easy
to calculate, however, it has a poor performance ac-
cording to the second principle explained above.
A better alternative to implement the ? function,
namely ?2, can be formulated as a composition of
two functions. A constructive definition of such a
implementation is detailed next:
1. Let us suppose that the source sentence is com-
posed by J words, we order the set of J bit
numbers as follows: first the numbers which do
not have any bit equal to one, next, the numbers
which have only one bit equal to one, and so on
2. Given the list of numbers described above, we
define a function which associates to each num-
ber of the list, the order of the number within
this list
3. Given the coverage of a partial hypothesis, x,
the stack on which this partial hypothesis is to
be inserted is obtained by a two step process:
First, we obtain the image of x returned by the
function described above. Next, the result is
shifted J ? g positions to the right, keeping the
first g bits
Let ? be the function that shifts a bit vector J ? g
positions to the right, keeping the first g bits; and let
? be the function that for each coverage returns its
order:
? : ({0, 1})J ?? ({0, 1})J (7)
Then, ?2 is expressed as follows:
?2(x) = ? ? ?(x) (8)
Table 1 shows an example of the values which re-
turns the ?1 and the ?2 functions when the input sen-
tence has 4 words and the granularity of the decoder
is equal to 2. As it can be observed, ?2 function
performs better than ?1 function according to the
second principle described at the beginning of this
section.
x ?1(x) ?(x) ?2(x)
0000 00 0000 00
0001 00 0001 00
0010 00 0010 00
0100 01 0011 00
1000 10 0100 01
0011 00 0101 01
0101 01 0110 01
0110 01 0111 01
1001 10 1000 10
1010 10 1001 10
1100 11 1010 10
0111 01 1011 10
1011 10 1100 11
1101 11 1101 11
1110 11 1110 11
1111 11 1111 11
Table 1: Values returned by the ?1 and ?2 function
defined as a composition of the ? and ? functions
4.3 Single and Multi Stack Algorithms
The classical single and multi-stack decoding al-
gorithms can be expressed/instantiated as particular
cases of the general formalism that have been pro-
posed.
Given the input sentence fJ1 , a generalized stack
decoding algorithm with G = 0 will have the fol-
lowing features:
? The algorithm works with 20 = 1 stacks.
? Such a stack may store hypotheses with 2J dif-
ferent coverages. That is to say, all possible
coverages.
? The mapping function returns the same stack
identifier for each coverage
The previously defined algorithm has the same
features as a single stack algorithm.
Let us now consider the features of a generalized
stack algorithm with a granularity value of J :
? The algorithm works with 2J stacks
? Each stack may store hypotheses with only
20 = 1 coverage.
? The mapping function returns a different stack
identifier for each coverage
The above mentioned features characterizes the
multi-stack algorithms described in the literature.
68
EUTRANS-I XEROX
Spanish English Spanish English
Training
Sentences 10,000 55,761
Words 97,131 99,292 753,607 665,400
Vocabulary size 686 513 11,051 7,957
Average sentence leng. 9.7 9.9 13.5 11.9
Test
Sentence 2,996 1,125
Words 35,023 35,590 10,106 8,370
Perplexity (Trigrams) ? 3.62 ? 48.3
Table 2: EUTRANS-I and XEROX corpus statistics
5 Experiments and Results
In this section, experimental results are presented for
two well-known tasks: the EUTRANS-I (Amengual
et al, 1996), a small size and easy translation task,
and the XEROX (Cubel et al, 2004), a medium size
and difficult translation task. The main statistics of
these corpora are shown in Table 2. The translation
results were obtained using a non-monotone gener-
alized stack algorithm. For both tasks, the training
of the different phrase models was carried out us-
ing the publicly available Thot toolkit (Ortiz et al,
2005).
Different translation experiments have been car-
ried out, varying the value of G (ranging from 0 to
8) and the maximum number of hypothesis that the
algorithm is allow to store for all used stacks (S)
(ranging from 28 to 212). In these experiments the
following statistics are computed: the average score
(or logProb) that the phrase-based translation model
assigns to each hypothesis, the translation quality
(by means of WER and Bleu measures), and the av-
erage time (in secs.) per sentence3.
In Figures 4 and 5 two plots are shown: the av-
erage time per sentence (left) and the average score
(right), for EUTRANS and XEROX corpora respec-
tively. As can be seen in both figures, the bigger the
value of G the lower the average time per sentence.
This is true up to the value of G = 6. For higher
values of G (keeping fixed the value of S) the aver-
age time per sentence increase slightly. This is due
to the fact that at this point the algorithm start to
spend more time to decide which hypothesis is to be
expanded. With respect to the average score similar
values are obtained up to the value of G = 4. Higher
3All the experiments have been executed on a PC with a
2.60 Ghz Intel Pentium 4 processor with 2GB of memory. All
the times are given in seconds.
values of G slightly decreases the average score. In
this case, as G increases, the number of hypothe-
ses per stack decreases, taking into account that the
value of S is fixed, then the ?optimal? hypothesis
can easily be pruned.
In tables 3 and 4 detailed experiments are shown
for a value of S = 212 and different values of G, for
EUTRANS and XEROX corpora respectively.
G WER Bleu secsXsent logprob
0 6.6 0.898 2.4 -18.88
1 6.6 0.898 1.9 -18.80
2 6.6 0.897 1.7 -18.81
4 6.6 0.898 1.3 -18.77
6 6.7 0.896 1.1 -18.83
8 6.7 0.896 1.5 -18.87
Table 3: Translation experiments for EUTRANS cor-
pus using a generalized stack algorithm with differ-
ent values of G and a fixed value of S = 212
G WER Bleu secsXsent logProb
0 32.6 0.658 35.1 -33.92
1 32.8 0.657 20.4 -33.86
2 33.1 0.656 12.8 -33.79
4 32.9 0.657 7.0 -33.70
6 33.7 0.652 6.3 -33.69
8 36.3 0.634 13.7 -34.10
Table 4: Translation experiments for XEROX cor-
pus using a generalized stack algorithm with differ-
ent values of G and a fixed value of S = 212
According to the experiments presented here we
can conclude that:
? The results correlates for the two considered
tasks: one small and easy, and other larger and
difficult.
? The proposed generalized stack decoding
paradigm can be used to make a tradeoff be-
69
 0
 0.5
 1
 1.5
 2
 2.5
 0  1  2  3  4  5  6  7  8
tim
e
G
S=512
S=1024
S=2048
S=4096
-20
-19.5
-19
-18.5
-18
 0  1  2  3  4  5  6  7  8
A
vg
. S
co
re
G
S=512
S=1024
S=2048
S=4096
Figure 4: Average time per sentence (in secs.) and average score per sentence. The results are shown for
different values of G and S for the EUTRANS corpus.
 0
 5
 10
 15
 20
 25
 30
 35
 40
 0  1  2  3  4  5  6  7  8
tim
e
G
S=512
S=1024
S=2048
S=4096
-37
-36
-35
-34
-33
-32
-31
 0  1  2  3  4  5  6  7  8
A
vg
. S
co
re
G
S=512
S=1024
S=2048
S=4096
Figure 5: Average time per sentence (in secs.) and average score per sentence. The results are shown for
different values of G and S for the XEROX corpus.
tween the advantages of classical single and
multi-stack decoding algorithms.
? As we expected, better results (regarding effi-
ciency and accuracy) are obtained when using
a value of G between 0 and J .
6 Concluding Remarks
In this paper, a generalization of the stack-decoding
paradigm has been proposed. This new formalism
includes the well known single and multi-stack de-
coding algorithms and a new family of stack-based
algorithms which have not been described yet in the
literature.
Essentially, generalized stack algorithms use a pa-
rameterized number of stacks during the decoding
process, and try to assign hypotheses to stacks such
that there is ?fair competition? within each stack,
i.e., brother hypotheses should cover roughly the
same number of input words (and the same words)
if possible.
The new family of stack-based algorithms allows
a tradeoff to be made between the classical single
and multi-stack decoding algorithms. For this pur-
pose, they employ a certain number of stacks be-
tween 1 (the number of stacks used by a single stack
algorithm) and 2J (the number of stacks used by a
multiple stack algorithm to translate a sentence with
J words.)
According to the experimental results, it has been
proved that an appropriate value of G yields in a
stack decoding algorithm that outperforms (in effi-
70
ciency and acuraccy) the single and multi-stack al-
gorithms proposed so far.
As future work, we plan to extend the experimen-
tation framework presented here to larger and more
complex tasks as HANSARDS and EUROPARL cor-
pora.
References
J.C. Amengual, J.M. Bened??, M.A. Castao, A. Marzal,
F. Prat, E. Vidal, J.M. Vilar, C. Delogu, A. di Carlo,
H. Ney, and S. Vogel. 1996. Definition of a ma-
chine translation task and generation of corpora. Tech-
nical report d4, Instituto Tecnolo?gico de Informa?tica,
September. ESPRIT, EuTrans IT-LTR-OS-20268.
Adam L. Berger, Peter F. Brown, Stephen A. Della Pietra,
Vincent J. Della Pietra, John R. Gillett, A. S. Kehler,
and R. L. Mercer. 1996. Language translation ap-
paratus and method of using context-based translation
models. United States Patent, No. 5510981, April.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and R. L. Mercer. 1993. The mathematics of
statistical machine translation: Parameter estimation.
Computational Linguistics, 19(2):263?311.
E. Cubel, J. Civera, J. M. Vilar, A. L. Lagarda,
E. Vidal, F. Casacuberta, D. Pico?, J. Gonza?lez, and
L. Rodr??guez. 2004. Finite-state models for computer
assisted translation. In Proceedings of the 16th Euro-
pean Conference on Artificial Intelligence (ECAI04),
pages 586?590, Valencia, Spain, August. IOS Press.
Ulrich Germann, Michael Jahr, Kevin Knight, Daniel
Marcu, and Kenji Yamada. 2001. Fast decoding and
optimal decoding for machine translation. In Proc.
of the 39th Annual Meeting of ACL, pages 228?235,
Toulouse, France, July.
F. Jelinek. 1969. A fast sequential decoding algorithm
using a stack. IBM Journal of Research and Develop-
ment, 13:675?685.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statisti-
cal phrase-based translation. In Proceedings of the
HLT/NAACL, Edmonton, Canada, May.
Phillip Koehn. 2003. Pharaoh: a beam search decoder
for phrase-based statistical machine translation mod-
els. User manual and description. Technical report,
USC Information Science Institute, December.
Daniel Marcu and William Wong. 2002. A phrase-based,
joint probability model for statistical machine transla-
tion. In Proceedings of the EMNLP Conference, pages
1408?1414, Philadelphia, USA, July.
Hermann Ney, Sonja Nie?en, Franz J. Och, Hassan
Sawaf, Christoph Tillmann, and Stephan Vogel. 2000.
Algorithms for statistical translation of spoken lan-
guage. IEEE Trans. on Speech and Audio Processing,
8(1):24?36, January.
Franz J. Och, Nicola Ueffing, and Hermann Ney. 2001.
An efficient A* search algorithm for statistical ma-
chine translation. In Data-Driven Machine Transla-
tion Workshop, pages 55?62, Toulouse, France, July.
Franz Joseph Och. 2002. Statistical Machine Trans-
lation: From Single-Word Models to Alignment Tem-
plates. Ph.D. thesis, Computer Science Department,
RWTH Aachen, Germany, October.
D. Ort??z, Ismael Garc??a-Varea, and Francisco Casacu-
berta. 2003. An empirical comparison of stack-based
decoding algorithms for statistical machine transla-
tion. In New Advance in Computer Vision, Lec-
ture Notes in Computer Science. Springer-Verlag. 1st
Iberian Conference on Pattern Recongnition and Im-
age Analysis -IbPRIA2003- Mallorca. Spain. June.
D. Ortiz, I. Garca-Varea, and F. Casacuberta. 2005. Thot:
a toolkit to train phrase-based statistical translation
models. In Tenth Machine Translation Summit, pages
141?148, Phuket, Thailand, September.
J. Toma?s and F. Casacuberta. 2001. Monotone statistical
translation using word groups. In Procs. of the Ma-
chine Translation Summit VIII, pages 357?361, Santi-
ago de Compostela, Spain.
J. Toma?s and F. Casacuberta. 2003. Combining phrase-
based and template-based models in statistical ma-
chine translation. In Pattern Recognition and Image
Analisys, volume 2652 of LNCS, pages 1021?1031.
Springer-Verlag. 1st bPRIA.
Ye-Yi Wang and Alex Waibel. 1998. Fast decoding
for statistical machine translation. In Proc. of the
Int. Conf. on Speech and Language Processing, pages
1357?1363, Sydney, Australia, November.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proc. of the 39th
Annual Meeting of ACL, pages 523?530, Toulouse,
France, July.
R. Zens, F.J. Och, and H. Ney. 2002. Phrase-based sta-
tistical machine translation. In Advances in artificial
intelligence. 25. Annual German Conference on AI,
volume 2479 of Lecture Notes in Computer Science,
pages 18?32. Springer Verlag, September.
71
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 244?254,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Interactive Machine Translation using Hierarchical Translation Models
Jesu?s Gonza?lez-Rubio, Daniel Ortiz-Mart??nez, Jose?-Miguel Bened??, Francisco Casacuberta
D. de Sistemas Informa?ticos y Computacio?n
Universitat Polite`cnica de Vale`ncia
Camino de Vera s/n, 46021 Valencia (Spain)
{jegonzalez,dortiz,jbenedi,fcn}@dsic.upv.es
Abstract
Current automatic machine translation sys-
tems are not able to generate error-free trans-
lations and human intervention is often re-
quired to correct their output. Alternatively,
an interactive framework that integrates the
human knowledge into the translation pro-
cess has been presented in previous works.
Here, we describe a new interactive ma-
chine translation approach that is able to work
with phrase-based and hierarchical translation
models, and integrates error-correction all in
a unified statistical framework. In our experi-
ments, our approach outperforms previous in-
teractive translation systems, and achieves es-
timated effort reductions of as much as 48%
relative over a traditional post-edition system.
1 Introduction
Research in the field of machine translation (MT)
aims to develop computer systems which are able
to translate between languages automatically, with-
out human intervention. However, the quality of
the translations produced by any automatic MT sys-
tem still remain below than that of human transla-
tion. Typical solutions to reach human-level quality
require a subsequent manual post-editing process.
Such decoupled post-edition solution is rather inef-
ficient and tedious for the human translator. More-
over, it prevents the MT system from taking advan-
tage of the knowledge of the human translator and,
reciprocal, the human translator cannot take advan-
tage of the adapting ability of MT technology.
An alternative way to take advantage of the exist-
ing MT technology is to use them in collaboration
with human translators within a computer-assisted
translation (CAT) or interactive framework (Isabelle
and Church, 1998). The TransType and TransType2
projects (Foster et al, 1998; Langlais and Lapalme,
2002; Barrachina et al, 2009) entailed an interesting
focus shift in CAT technology by aiming interaction
directly at the production of the target text. These
research projects proposed to embed an MT system
within an interactive translation environment. This
way, the human translator can ensure a high-quality
output while the MT system ensures a significant
gain of productivity. Particularly interesting is the
interactive machine translation (IMT) approach pro-
posed in (Barrachina et al, 2009). In this scenario,
a statistical MT (SMT) system uses the source sen-
tence and a previously validated part (prefix1) of its
translation to propose a suitable continuation. Then
the user finds and corrects the next system error,
thereby providing a longer prefix which the system
uses to suggests a new, hopefully better continua-
tion. The reported results showed that IMT can save
a significant amount of human effort.
Barrachina et al. (2009) provide a thorough de-
scription of the IMT approach and describe algo-
rithms for its practical implementation. Neverthe-
less, we identify two basic problems for which we
think there is room for improvement. The first prob-
lem arises when the system cannot generate the pre-
fix validated by the user. To solve this problem,
the authors simply provide an ad-hoc heuristic error-
correction technique. The second problem is how
the system deals with word reordering. Particularly,
the models used by the system were either mono-
1We use the terms prefix and suffix to denote any sub-string
at the beginning and end respectively of a string of characters
(including spaces and punctuation). These terms do not imply
any morphological significance as they usually do in linguistics.
244
tonic by nature or non-monotonic but heuristically
defined (not estimated from training data).
We work on the foundations of Barrachina et
al., (2009) and provide formal solutions to these
two challenges. On the one hand, we adopt the
statistical formalization of the IMT framework de-
scribed in (Ortiz-Mart??nez, 2011), which includes
a stochastic error-correction model in its formaliza-
tion to address prefix coverage problems. Moreover,
we refine this formalization proposing an alternative
error-correction formalization for the IMT frame-
work (Section 2). Additionally, we also propose a
specific error-correction model based on a statisti-
cal interpretation of the Levenshtein distance (Lev-
enshtein, 1966). These formalizations provide a
unified statistical framework for the IMT model in
comparison to the ad-hoc heuristic error-correction
methods previously used.
In order to address the problem of properly deal
with reordering in IMT, we introduce the use of hi-
erarchical MT models (Chiang, 2005; Zollmann and
Venugopal, 2006). These methods provide a natural
approach to handle long range dependencies and al-
low the incorporation of reordering information into
a consistent statistical framework. Here, we also de-
scribe how state-of-the-art hierarchical MT models
can be extended to handle IMT (Sections 3 and 4).
We evaluate the proposed IMT approach on two
different translation task. The comparative results
against the IMT approach described by Barrachina
et al, (2009) and a conventional post-edition ap-
proach show that our IMT formalization for hier-
archical SMT models indeed outperform other ap-
proaches (Sections 5 and 6). Moreover, it leads to
large reductions in the human effort required to gen-
erate error-free translations.
2 Statistical Framework
2.1 Statistical Machine Translation
Assuming that we are given a sentence s in a source
language, the translation problem can be stated as
finding its translation t in a target language of max-
imum probability (Brown et al, 1993):
t? = argmax
t
Pr(t | s) (1)
= argmax
t
Pr(t) ? Pr(s | t) (2)
source (s): Para ver la lista de recursos
desired translation (t?): To view a listing of resources
IT-0
p
ts To view the resources list
IT-1
p To view
k a
ts list of resources
IT-2
p To view a list
k list i
ts list i ng resources
IT-3
p To view a listing
k o
ts o f resources
END p To view a listing of resources
Figure 1: IMT session to translate a Spanish sentence into
English. The desired translation is the translation the hu-
man user wants to obtain. At IT-0, the system suggests
a translation (ts). At IT-1, the user moves the mouse to
accept the first eight characters ?To view ? and presses the
a key (k), then the system suggests completing the sen-
tence with ?list of resources? (a new ts). Iterations 2 and
3 are similar. In the final iteration, the user accepts the
current translation.
The terms in the latter equation are the lan-
guage model probability Pr(t) that represents the
well-formedness of t (n-gram models are usu-
ally adopted), and the (inverted) translation model
Pr(s | t) that represents the relationship between the
source sentence and its translation.
In practice all of these models (and possibly oth-
ers) are often combined into a log-linear model for
Pr(t | s) (Och and Ney, 2002):
t? = argmax
t
{
N?
n=1
?n ? log(fn(t, s))
}
(3)
where fn(t, s) can be any model that represents an
important feature for the translation, N is the num-
ber of models (or features), and ?n are the weights
of the log-linear combination.
2.2 Statistical Interactive Machine Translation
Unfortunately, current MT technology is still far
from perfect. This implies that, in order to achieve
good translations, manual post-editing is needed.
An alternative to this decoupled approach (first
MT, then manual correction) is given by the IMT
245
paradigm (Barrachina et al, 2009). Under this
paradigm, translation is considered as an iterative
left-to-right process where the human and the com-
puter collaborate to generate the final translation.
Figure 1 shows an example of the IMT approach.
There, a source Spanish sentence s =?Para ver la
lista de recursos? is to be translated into a target En-
glish sentence t?. Initially, with no user feedback, the
system suggests a complete translation ts =?To view
the resources list?. From this translation, the user
marks a prefix p =?To view? as correct and begins
to type the rest of the target sentence. Depending on
the system or the user?s preferences, the user might
type the full next word, or only some letters of it (in
our example, the user types the single next charac-
ter ?a?). Then, the MT system suggests a new suffix
ts =?list of resources? that completes the validated
prefix and the input the user has just typed (p =?To
view a?). The interaction continues with a new pre-
fix validation followed, if necessary, by new input
from the user, and so on, until the user considers the
translation to be complete and satisfactory.
The crucial step of the process is the production
of the suffix. Again decision theory tells us to max-
imize the probability of the suffix given the avail-
able information. Formally, the best suffix of a given
length will be:
t?s = argmax
ts
Pr(ts | s,p) (4)
which can be straightforwardly rewritten as:
t?s = argmax
ts
Pr(p, ts | s) (5)
= argmax
ts
Pr(p, ts) ? Pr(s | p, ts) (6)
Note that, since p ts = t, this equation is very
similar to Equation (2). The main difference is that
now the search process is restricted to those target
sentences t that contains p as prefix. This implies
that we can use the same MT models (including
the log-linear approach) if the search procedures are
adequately modified (Och et al, 2003). Finally, it
should be noted that the statistical models are usu-
ally defined at word level, while the IMT process
described in this section works at character level. To
deal with this problem, during the search process it
is necessary to verify the compatibility between t
and p at character level.
2.3 IMT with Stochastic Error-Correction
A common problem in IMT arises when the user sets
a prefix which cannot be explained by the statistical
models. To solve this problem, IMT systems typi-
cally include ad-hoc error-correction techniques to
guarantee that the suffixes can be generated (Bar-
rachina et al, 2009). As an alternative to this heuris-
tic approach, Ortiz-Mart??nez (2011) proposed a for-
malization of the IMT framework that does include
stochastic error-correction models in its statistical
formalization. The starting point of this alternative
IMT formalization accounts for the problem of find-
ing the translation t that, at the same time, better
explains the source sentence s and the prefix given
by the user p:
t? = argmax
t
Pr(t | s,p) (7)
= argmax
t
Pr(t) ? Pr(s,p | t) (8)
The following na??ve Bayes? assumption is now
made: the source sentence s and the user prefix p are
statistically independent variables given the transla-
tion t, obtaining:
t? = argmax
t
Pr(t) ? Pr(s | t) ? Pr(p | t) (9)
where Pr(t) can be approximated with a language
model, Pr(s | t) can be approximated with a trans-
lation model, and Pr(p | t) can be approximated
by an error correction model that measures the com-
patibility between the user-defined prefix p and the
hypothesized translation t.
Note that the translation result, t?, given by Equa-
tion (9) may not contain p as prefix because every
translation is compatible with p with a certain prob-
ability. Thus, despite being close, Equation (9) is not
equivalent to the IMT formalization in Equation (6).
To solve this problem, we define an alignment,
a, between the user-defined prefix p and the hy-
pothesized translation t, so that the unaligned words
of t, in an appropriate order, constitute the suffix
searched in IMT. This allows us to rewrite the error
correction probability as follows:
Pr(p | t) =
?
a
Pr(p,a | t) (10)
To simplify things, we assume that p is mono-
tonically aligned to t, leaving the potential word-
reordering to the language and translation models.
246
Under this assumption, a determines an alignment
for t, such that t = tpts, where tp is fully-aligned to
p and ts remains unaligned. Taking all these things
into consideration, and following a maximum ap-
proximation, we finally arrive to the expression:
(t?, a?) = argmax
t,a
Pr(t)?Pr(s | t)?Pr(p,a | t) (11)
where the suffix required in IMT is obtained as the
portion of t? that is not aligned with the user prefix.
In practice, we combine the models in Equa-
tion (11) in a log-linear fashion as it is typically done
in SMT (see Equation (3)).
2.4 Alternative Formalization for IMT with
Stochastic Error-Correction
Alternatively to Equation (11), we can operate from
Equation (9) and reach a different formalization for
IMT with error-correction. We can re-write the first
and last terms of Equation (9) as:
Pr(t) ? Pr(p | t) = Pr(p) ? Pr(t | p) (12)
As in the previous section, we introduce an align-
ment variable, a, between t and p, giving:
Pr(t | p) =
?
a
Pr(t,a | p) (13)
=
?
a
Pr(a | p) ? Pr(t | p,a) (14)
If we consider monotonic alignments, a defines
again an alignment between a prefix of the system
translation (tp) and the user prefix, producing the
suffix required in IMT (ts) as the unaligned part.
Thus, we can re-write Pr(t | p,a) as:
Pr(t | p,a) = Pr(tp, ts | p,a) (15)
? Pr(tp | p,a) ? Pr(ts | p,a) (16)
where Equation (16) has been obtained following a
na??ve Bayes? decomposition.
Combining equations (12), (14), and (16) into
Equation (9), and following a maximum approxima-
tion for the summation of the alignment variable a,
we arrive to the following expression:
(t?, a?) = argmax
t,a
Pr(s |t)?Pr(tp |p,a)?Pr(ts |p,a) (17)
where Pr(p) and Pr(a|p) have been dropped down
because the former does not participate in the maxi-
mization and the latter is assumed uniform.
The terms in this equation can be interpreted sim-
ilarly as those in Equation (9): Pr(s | t) is the trans-
lation model, Pr(tp | p,a) is the error-correction
probability that measures the compatibility between
the prefix tp of the hypothesized translation and the
user-defined prefix p, and Pr(ts | p,a) is the lan-
guage model for the corresponding suffix ts condi-
tioned by the user-defined prefix. Again, in the ex-
periments we combine the different models in a log-
linear fashion.
The main difference between the two alternative
IMT formalization (Equations (11) and (17)) is that
in the latter the suffix to be returned is conditioned
by the user-validated prefix p. Thus, in the fol-
lowing we will refer to Equation (11) as indepen-
dent suffix formalization while we will denote Equa-
tion (17) by conditioned suffix formalization.
3 Statistical Models
We now present the statistical models used to esti-
mate the probability distributions described in the
previous section. Section 3.1 describes the error-
correction model, while Section 3.2 describes the
models for the conditional translation probability.
3.1 Statistical Error-Correction Model
Following the vast majority of IMT systems de-
scribed in the literature, we implement an error-
correction model based on the concept of edit dis-
tance (Levenshtein, 1966). Typically, IMT systems
use non-probabilistic error correction models. The
first stochastic error correction model for IMT was
proposed in (Ortiz-Mart??nez, 2011) and it is based
on probabilistic finite state machines. Here, we pro-
pose a simpler approach which can be seen as a
particular case of the previous one. Specifically,
the proposed approach models the edit distance as a
Bernoulli process where each character of the candi-
date string has a probability pe of being erroneous.
Under this interpretation, the number of characters
that need to be edited E in a sentence of length n
is a random variable that follows a binomial distri-
bution, E ? B(n, pe), with parameters n and pe.
The probability of performing exactly k edits in a
247
sentence of n characters is given by the following
probability mass function:
f(k;n, pe) =
n!
k!(n? k)!
pke(1? pe)
n?k (18)
Note that this error-correction model penalizes
equally all edit operations. Alternatively, we can
model the distance with a multinomial distribution
and assign different probabilities to different types
of edit operations. Nevertheless, we adhere to the
binomial approximation due to its simplicity.
Finally, we compute the error-correction proba-
bility between two strings from the total number of
edits required to transform the candidate translation
into the reference translation. Specifically, we define
the error-correction distribution in Equation (11) as:
Pr(p,a | t) ?
|p|!
k!(|p| ? k)!
pke(1? pe)
|p|?k (19)
where k = Lev(p, ta) is the character-level Lev-
enshtein distance between the user defined prefix p
and the prefix ta of the hypothesized translation t
defined by alignment a. The error-correction prob-
ability Pr(tp | p,a) in Equation (17) is computed
analogously.
The probability of edition pe is the single free pa-
rameter of this formulation. We will use a separate
development corpus to find an adequate value for it.
3.2 Statistical Machine Translation Models
Next sections briefly describe the statistical transla-
tion models used to estimate the conditional proba-
bility distribution Pr(s | t). A detailed description
of each model can be found in the provided citations.
3.2.1 Phrase-Based Translation Models
Phrase-based translation models (Koehn et al,
2003) are an instance of the noisy-channel approach
in Equation (2). The translation of a source sentence
s is obtained through a generative process composed
of three steps: first, the s is divided into K segments
(phrases), next, each source phrase, s?, is translated
into a target phrase t?, and finally the target phrases
are reordered to compose the final translation.
The usual phrase-based implementation of the
translation probability takes a log-linear form:
Pr(s | t) ? ?1 ? |t|+ ?2 ?K+
K?
k=1
[
?3 ? log(P (s?k | t?k)) + ?4 ? d(j)
]
(20)
where P (s? | t?) is the translation probability between
source phrase s? and target phrase t?, and d(j) is a
function (distortion model) that returns the score of
translating the k-th source phrase given that it is sep-
arated j words from the (k?1)-th phrase. Weights ?1
and ?2 play a special role since they are used to con-
trol the number of words and the number of phrases
of the target sentence to be generated, respectively.
3.2.2 Hierarchical Translation Models
Phrase-based models have shown a very strong
performance when translating between languages
that have similar word orders. However, they are not
able to adequately capture the complex relationships
that exist between the word orders of languages of
different families such as English and Chinese. Hi-
erarchical translation models provide a solution to
this challenge by allowing gaps in the phrases (Chi-
ang, 2005):
yu X1 you X2? have X2 with X1
where subscripts denote placeholders for sub-
phrases. Since these rules generalize over possi-
ble phrases, they act as discontinuous phrase pairs
and may also act as phrase-reordering rules. Hence,
they are not only considerably more powerful than
conventional phrase pairs, but they also integrate re-
ordering information into a consistent framework.
These hierarchical phrase pairs are formalized as
rewrite rules of a synchronous context-free grammar
(CFG) (Aho and Ullman, 1969):
X ?< ?,?,?> (21)
where X is a non-terminal, ? and ? are both strings
of terminals (words) and non-terminals , and ? is
a one-to-one correspondence between non-terminal
occurrences in ? and ?. Given the example above,
? ??yu X1 you X2?, ? ??have X2 with X1?, and?
is indicated by the subscript numbers.
Additionally, two glue rules are also defined:
S ?<S1X2 , S1X2> S ?<X1 , X1>
248
These give the model the option to build only par-
tial translations using hierarchical phrases, and then
combine them serially as in a phrase-based model.
The typical implementation of the hierarchical
translation model also takes the form of a log-linear
model. Let s? and t? be the source and target strings
generated by a derivation ? of the grammar. Then,
the conditional translation probability is given by:
Pr(s? | t?) ? ?1 ? |t?|+ ?2 ? |?|+ ?3 ?#g(?)+
?
r??
[?4 ? w(r)] (22)
where |?| denotes the total number of rules used
in ?, #g(?) returns the number of applications of
the glue rules, r ? ? are the rules in ?, and w(r)
is the weight of rule r. Weights ?1 and ?2 have
a similar interpretation as for phrase-based models,
they respectively give some control over the total
number of words and rules that conform the trans-
lation. Additionally, ?3 controls the model?s prefer-
ence for hierarchical phrases over serial combination
of phrases. Note that no distortion model is included
in the previous equation. Here, reordering is defined
at rule level by the one-to-one non-terminal corre-
spondence. In other words, reordering is a property
inherent to each rule and it is the individual score of
each rule what defines, at each step of the derivation,
the importance of reordering.
It should be noted that the IMT formalizations
presented in Section 2 can be applied to other hier-
archical or syntax-based SMT models such as those
described in (Zollmann and Venugopal, 2006; Shen
et al, 2010).
4 Search
In offline MT, the generation of the best trans-
lation for a given source sentence is carried out
by incrementally generating the target sentence2.
This process fits nicely into a dynamic program-
ming (DP) (Bellman, 1957) framework, as hypothe-
ses which are indistinguishable by the models can
be recombined. Since the DP search space grows
exponentially with the size of the input, standard DP
search is prohibitive, and search algorithms usually
resort to a beam-search heuristic (Jelinek, 1997).
2Phrase-based systems follow a left-to-right generation or-
der while hierarchical systems rely on a CYK-like order.
6
1
5
I saw a man with a telescope
2 3
4
I saw a man with a telescope
I saw with a telescope a man
Figure 2: Example of a hypergraph encoding two differ-
ent translations (one solid and one dotted) for the Spanish
sentence ?Vi a un hombre con un telescopio?.
Due to the demanding temporal constraints inher-
ent to any interactive environment, performing a full
search each time the user validates a new prefix is
unfeasible. The usual approach is to rely on a certain
representation of the search space that includes the
most probable translations of the source sentence.
The computational cost of this approach is much
lower, as the whole search for the translation must
be carried out only once, and the generated represen-
tation can be reused for further completion requests.
Next, we introduce hypergraphs, the formalism
chosen to represent the search space of both phrase-
based and hierarchical systems (Section 4.1). Then,
we describe the algorithms implemented to search
for suffix completions in them (Section 4.2).
4.1 Hypergraphs
A hypergraph is a generalization of the concept
of graph where the edges (now called hyperedges)
may connect several nodes (hypernodes) at the same
time. Formally, a hypergraph is a weighted acyclic
graph represented by a pair < V, E >, where V is a
set of hypernodes and E is a set of hyperedges. Each
hyperedge e ? E connects a head hypernode and a
set of tail hypernodes. The number of tail nodes is
called the arity of the hyperedge and the arity of a
hypergraph is the maximum arity of its hyperedges.
We can use hypergraphs to represent the deriva-
tions for a given CFG. Each hypernode represents
a partial translation generated during the decoding
process. Each ingoing hyperedge represents the rule
with which the corresponding non-terminal was sub-
stituted. Moreover, hypergraphs can represent a
whole set of possible translations. An example is
249
shown in Figure 2. Two alternative translations are
constructed from the leave nodes (1, 2 and 3) up to
the root node (6) of the hypergraph. Additionally,
hypernodes and hyperedges may be shared among
different derivations if they represent the same in-
formation. Thus, we can achieve a compact repre-
sentation of the translation space that allows us to
derive efficient search algorithms.
Note that word-graphs (Ueffing et al, 2002),
which are used to represent the search space for
phrase-based models, are a special case of hyper-
graphs in which the maximum arity is one. Thus,
hypergraphs allow us to represent both phrase-based
and hierarchical systems in a unified framework.
4.2 Suffix Search on Hypergraphs
Now, we describe a unified search process to obtain
the suffix ts that completes a prefix p given by the
user according to the two IMT formulations (Equa-
tion (11) and Equation (17)) described in Section 2.
Given an hypergraph, certain hypernodes define a
possible solution to the maximization defined in the
two IMT formulations. Specifically, only those hy-
pernodes that generate a prefix of a potential trans-
lation are to be taken into account3. The prob-
ability of the solution defined by each hypernode
has two components, namely the probability of the
SMT model (given by the language and translation
models) and the probability of the error-correction
model. On the one hand, the SMT model probabil-
ity is given by the translation of maximum probabil-
ity through the hypernode. On the other hand, the
error-correction probability is computed between p
and the partial translation of maximum probability
actually covered by the hypernode. Among all the
solutions defined by the hypernodes, we finally se-
lect that of maximum probability.
Once the best-scoring hypernode is identified, the
rest of the translation not covered by it is returned as
the suffix completion required in IMT.
5 Experimental Framework
The models and search procedure introduced in the
previous sections were assessed through a series of
3For example, in Figure 2 the hypernodes that generate pre-
fixes are those labeled with numbers 1 (?I saw?), 4 (?I saw with
a telescope) and 6 (?I saw a man with a telescope? and ?I saw
with a telescope a man?).
EU (Es/En)
Train Development Test
Sentences 214K 400 800
Token 5.9M / 5.2M 12K / 10K 23K / 20K
Vocabulary 97K / 84K 3K / 3K 5K / 4K
TED (Zh/En)
Train Development Test
Sentences 107K 934 1664
Token 2M / 2M 22K / 20K 33K / 32K
Vocabulary 42K / 52K 4K / 3K 4K / 4K
Table 1: Main figures of the processed EU and TED cor-
pora. K and M stand for thousands and millions of ele-
ments respectively.
IMT experiments with different corpora. These cor-
pora, the experimental methodology, and the evalu-
ation measures are presented in this section.
5.1 EU and TED corpora
We tested the proposed methods in two different
translation tasks each one involving a different lan-
guage pair: Spanish-to-English (Es?En) for the EU
(Bulletin of the European Union) task, and Chinese-
to-English (Zh?En) for the TED (TED4 talks) task.
The EU corpora were extracted from the Bul-
letin of the European Union, which exists in all of-
ficial languages of the European Union and is pub-
licly available on the Internet. Particularly, the cho-
sen Es?En corpus was part of the evaluation of the
TransType2 project (Barrachina et al, 2009). The
TED talks is a collection of recordings of public
speeches covering a variety of topics, and for which
high quality transcriptions and translations into sev-
eral languages are available. The Zh?En corpus
used in the experiments was part of the MT track
in the 2011 evaluation campaign of the workshop on
spoken language translation (Federico et al, 2011).
Specifically, we used the dev2010 partition for de-
velopment and the test2010 partition for test.
We process the Spanish and English parts of the
EU corpus to separate words and punctuation marks
keeping sentences truecase. Regarding the TED cor-
pus, we tokenized and lowercased the English part
(Chinese has no case information), and split Chi-
nese sentences into words with the Stanford word
4www.ted.com
250
segmenter (Tseng et al, 2005). Table 1 shows the
main figures of the processed EU and TED corpora.
5.2 Model Estimation and User Simulation
We used the standard configuration of the Moses
toolkit (Koehn et al, 2007) to estimate one phrase-
based and one hierarchical model for each cor-
pus; log-linear weights were optimized by minimum
error-rate training (Och, 2003) with the development
partitions. Then, the optimized models were used to
generate the word-graphs and hypergraphs with the
translations of the development and test partitions.
A direct evaluation of the proposed IMT proce-
dures involving human users would have been slow
and expensive. Thus, following previous works in
the literature (Barrachina et al, 2009; Gonza?lez-
Rubio et al, 2010), we used the references in the
corpora to simulate the translations that a human
user would want to obtain. Each time the system
suggested a new translation, it was compared to
the reference and the longest common prefix (LCP)
was obtained. Then, the first non-matching charac-
ter was replaced by the corresponding character in
the reference and a new system suggestion was pro-
duced. This process is iterated until a full match with
the reference was obtained.
Finally, we used this user simulation to optimize
the value for the probability of edition pe in the
error-correction model (Section 3.1), and for the log-
linear weights in the proposed IMT formulations. In
this case, these values were chosen so that they min-
imize the estimated user effort required to interac-
tively translate the development partitions.
5.3 Evaluation Measures
Different measures have been adopted to evaluate
the proposed IMT approach. On the one hand, dif-
ferent IMT systems can be compared according to
the effort needed by a human user to generate the de-
sired translations. This effort is usually estimated as
the number of actions performed by the user while
interacting with the system. In the user simulation
described above these actions are: looking for the
next error and moving the mouse pointer to that po-
sition (LCP computation), and correcting errors with
some key strokes. Hence, we implement the follow-
ing IMT effort measure (Barrachina et al, 2009):
Key-stroke and mouse-action ratio (KSMR):
number of key strokes plus mouse movements per-
formed by the user, divided by the total number of
characters in the reference.
On the other hand, we also want to compare the
proposed IMT approach against a conventional CAT
approach without interactivity, such as a decoupled
post-edition system. For such systems, character-
level user effort is usually measured by the Charac-
ter Error Rate (CER). However, it is clear that CER
is at a disadvantage due to the auto-completion ap-
proach of IMT. To perform a fairer comparison be-
tween post-edition and IMT, we implement a post-
editing system with autocompletion. Here, when
the user enters a character to correct some incor-
rect word, the system automatically completes the
word with the most probable word in the task vo-
cabulary. To evaluate the effort of a user using such
a system, we implement the following measure pro-
posed in (Romero et al, 2010):
Post-editing key stroke ratio (PKSR): using
a post-edition system with word-autocompleting,
number of user key strokes divided by the total num-
ber of reference characters.
The counterpart of PKSR in an IMT scenario
is (Barrachina et al, 2009):
Key-stroke ratio (KSR): number of key strokes,
divided by the number of reference characters.
PKSR and KSR are fairly comparable and the rel-
ative difference between them gives us a good es-
timate of the reduction in human effort that can be
achieved by using IMT instead of a conventional
post-edition system.
We also evaluate the quality of the automatic
translations generated by the MT models with the
widespread BLEU score (Papineni et al, 2002).
Finally, we provide both confidence intervals for
the results and statistical significance of the ob-
served differences in performance. Confidence in-
tervals were computed by pair-wise re-sampling as
in (Zhang and Vogel, 2004) while statistical signifi-
cance was computed using the Tukey?s HSD (honest
significance difference) test (Hsu, 1996).
251
EU TED
WG HG WG HG
1-best BLEU [%] 45.0 45.1 11.0 11.2
1000-best Avg. BLEU [%] 43.6 44.2 10.2 11.0
Table 2: BLEU score of the word-graphs (WG) and hy-
pergraphs (HG) used to implement the IMT procedures.
IMT EU TED
Setup PB HT PB HT
ISF 27.4?.5? 26.5?.5? 53.0?.4? 52.3?.4?
CSF 26.6?.5? 25.1?.5F 52.2?.4? 50.8?.4F
Table 3: IMT results (KSMR [%]) for the EU and
TED tasks using the independent suffix formalization
(ISF) and the conditioned suffix formalization (CSF). PB
stands for phrase-based model and HT stands for hierar-
chical translation model. For each task, the best result
is displayed boldface, an asterisk ? denotes a statistically
significant better result (99% confidence) with respect to
ISF with PB, and a star F denotes a statistically signifi-
cant difference with respect to all the other systems.
6 Results
We start by reporting conventional MT quality re-
sults to test if the generated word-graphs and hyper-
graphs encode translations of similar quality. Ta-
ble 2 displays the quality (BLEU (Papineni et al,
2002)) of the automatic translations generated for
the test partitions. The lower 1-best BLEU results
obtained for TED show that this is a much more dif-
ficult task than EU. Additionally, the similar aver-
age BLEU results obtained for the 1000-best transla-
tions indicate that word-graphs and hypergraphs en-
code translations of similar quality. Thus, the IMT
systems that use these word-graphs and hypergraphs
can be compared in a fair way.
Then, we evaluated different setups of the pro-
posed IMT approach. Table 3 displays the IMT re-
sults obtained for the EU and TED tasks. We report
KSMR (as a percentage) for the independent suffix
formalization (ISF) and the conditioned suffix for-
malization (CSF) using both phase-based (PB) and
hierarchical (HT) translation models. The KSMR
result of ISF using a phrase-based model can be con-
sidered our baseline since this setup is comparable
to that used in (Barrachina et al, 2009). Results for
HT consistently outperformed the corresponding re-
sults for PB. Similarly, results for CSF were con-
EU TED
PE IMT PE IMT
PKSR [%] KSR [%] PKSR [%] KSR [%]
27.1 14.1 (48%) 40.8 29.7 (27.2%)
Table 4: Estimation of the effort required to translate
the test partition of the EU and TED tasks using post-
editing with word-completion (PE) and IMT under the
independent suffix formalization (IMT). We used hierar-
chical MT in both approaches. In parenthesis we display
the estimated effort reduction of IMT with respect to PE.
sistently better than those for ISF. More specifically,
no statistically significant difference were found be-
tween ISF with HT and CSF with PB but both sta-
tistically outperformed the baseline (ISF with PB).
Finally, CSF with HT statistically outperformed the
other three configurations reducing KSMR by ?2.2
points with respect to the baseline. We hypothe-
size that the better results of HT can be explained
by its more efficient representation of word reorder-
ing. Regarding the CSF, its better results are due to
the better suffixes that can be obtained by taking into
account the actual prefix validated by the user.
Finally, we compared the estimated human effort
required to translate the test partitions of the EU and
TED corpora with the best IMT configuration (inde-
pendent suffix formalization with hierarchical trans-
lation model) and a conventional post-editing (PE)
CAT system with word-completion. That is, when
the user corrects a character, the PE system auto-
matically proposes a different word that begins with
the given word prefix but, obviously, the rest of the
sentence is not changed. According to the results,
the estimated human effort to generate the error-free
translations was significantly reduced with respect
to using the conventional PE approach. IMT can
save about 48% of the overall eastimated effort for
the EU task and about 27% for the TED task.
7 Summary and Future Work
We have proposed a new IMT approach that uses hi-
erarchical SMT models as its underlying translation
technology. This approach is based on a statistical
formalization previously described in the literature
that includes stochastic error correction. Addition-
ally, we have proposed a refined formalization that
improves the quality of the IMT suffixes by taking
252
into account the prefix validated by the user. More-
over, since word-graphs constitute a particular case
of hypergraphs, we are able to manage both phrase-
based and hierarchical translation models in a uni-
fied IMT framework.
Simulated results on two different translation
tasks showed that hierarchical translation models
outperform phrase-based models in our IMT frame-
work. Additionally, the proposed alternative IMT
formalization also allows to improve the results of
the IMT formalization previously described in the
literature. Finally, the proposed IMT system with
hierarchical SMT models largely reduces the esti-
mated user effort required to generate correct trans-
lations in comparison to that of a conventional post-
edition system. We look forward to corroborating
these result in test with human translators.
There are many ways to build on the work de-
scribed here. In the near future, we plan to explore
the following research directions:
? Alternative IMT scenarios where the user is not
bounded to correct translation errors in a left-
to-right fashion. In such scenarios, the user will
be allowed to correct errors at any position in
the translation while the IMT system will be
required to derive translations compatible with
these isolated corrections.
? Adaptive translation engines that take advan-
tage of the user?s corrections to improve its sta-
tistical models. As the translator works and
corrects the proposed translations, the transla-
tion engine will be able to make better predic-
tions. One of the first works on this topic was
proposed in (Nepveu et al, 2004). More re-
cently, Ortiz-Mart??nez et al (2010) described a
set of techniques to obtain an incrementally up-
dateable IMT system, solving technical prob-
lems encountered in previous works.
? More sophisticated measures to estimate the
human effort. Specifically, measures that esti-
mate the cognitive load involve in reading, un-
derstanding and detecting an error in a trans-
lation (Foster et al, 2002), in contrast KSMR
simply considers a constant cost. This will lead
to a more accurate estimation of the improve-
ments that may be expected by a human user.
Acknowledgments
Work supported by the European Union 7th Frame-
work Program (FP7/2007-2013) under the Cas-
MaCat project (grans agreement no 287576), by
Spanish MICINN under grant TIN2012-31723, and
by the Generalitat Valenciana under grant ALMPR
(Prometeo/2009/014).
References
Alfred V. Aho and Jeffrey D. Ullman. 1969. Syn-
tax directed translations and the pushdown assembler.
Journal of Computer and Systems Science, 3(1):37?
56, February.
Sergio Barrachina, Oliver Bender, Francisco Casacu-
berta, Jorge Civera, Elsa Cubel, Shahram Khadivi, An-
tonio Lagarda, Hermann Ney, Jesu?s Toma?s, Enrique
Vidal, and Juan-Miguel Vilar. 2009. Statistical ap-
proaches to computer-assisted translation. Computa-
tional Linguistics, 35:3?28, March.
Richard Bellman. 1957. Dynamic Programming.
Princeton University Press, Princeton, NJ, USA, 1 edi-
tion.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Computational Linguistics, 19:263?311.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting on Association for Computa-
tional Linguistics, pages 263?270.
M. Federico, L. Bentivogli, M. Paul, and S. Stu?ker. 2011.
Overview of the iwslt 2011 evaluation campaign. In
Proceedings of the International Workshop on Spoken
Language Translation, pages 11?20.
George Foster, Pierre Isabelle, and Pierre Plamondon.
1998. Target-text mediated interactive machine trans-
lation. Machine Translation, 12(1/2):175?194, Jan-
uary.
George Foster, Philippe Langlais, and Guy Lapalme.
2002. User-friendly text prediction for translators.
In Proceedings of the 2002 conference on Empirical
methods in natural language processing - Volume 10,
pages 148?155.
Jesu?s Gonza?lez-Rubio, Daniel Ortiz-Mart??nez, and Fran-
cisco Casacuberta. 2010. Balancing user effort and
translation error in interactive machine translation via
confidence measures. In Proceedings of the ACL 2010
Conference Short Papers, pages 173?177.
Jason Hsu. 1996. Multiple Comparisons: Theory and
Methods. Chapman and Hall/CRC.
253
Pierre Isabelle and Ken Church. 1998. Special issue on:
New tools for human translators, volume 12. Kluwer
Academic Publishers, January.
Frederick Jelinek. 1997. Statistical methods for speech
recognition. MIT Press.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics on Human Language Technology - Volume 1,
pages 48?54.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Pro-
ceedings of the Association for Computational Lin-
guistics, demonstration session, June.
Philippe Langlais and Guy Lapalme. 2002. TransType:
development-evaluation cycles to boost translator?s
productivity. Machine Translation, 17(2):77?98,
September.
Vladimir Levenshtein. 1966. Binary codes capable of
correcting deletions, insertions and reversals. Soviet
Physics Doklady, 10(8):707?710, February.
Laurent Nepveu, Guy Lapalme, Philippe Langlais, and
George Foster. 2004. Adaptive language and trans-
lation models for interactive machine translation. In
Proceedings of the conference on Empirical Methods
on Natural Language Processing, pages 190?197.
Franz Josef Och and Hermann Ney. 2002. Discrimi-
native training and maximum entropy models for sta-
tistical machine translation. In Proceedings of the
40th Annual Meeting on Association for Computa-
tional Linguistics, pages 295?302.
Franz Josef Och, Richard Zens, and Hermann Ney.
2003. Efficient search for interactive statistical ma-
chine translation. In Proceedings of the European
chapter of the Association for Computational Linguis-
tics, pages 387?393.
Franz Och. 2003. Minimum error rate training in statisti-
cal machine translation. In Proceedings of the 41st An-
nual Meeting on Association for Computational Lin-
guistics - Volume 1, pages 160?167. Association for
Computational Linguistics.
Daniel Ortiz-Mart??nez, Ismael Garc??a-Varea, and Fran-
cisco Casacuberta. 2010. Online learning for inter-
active statistical machine translation. In Proceedings
of the 2010 Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 546?554.
Daniel Ortiz-Mart??nez. 2011. Advances in Fully-
Automatic and Interactive Phrase-Based Statistical
Machine Translation. Ph.D. thesis, Universitat
Polite`cnica de Vale`ncia. Advisors: Ismael Garc??a
Varea and Francisco Casacuberta.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th Annual Meeting on Association for Computa-
tional Linguistics, ACL ?02, pages 311?318. Associa-
tion for Computational Linguistics.
Veronica Romero, Alejandro H. Toselli, and Enrique Vi-
dal. 2010. Character-level interaction in computer-
assisted transcription of text images. In Proceedings
of the 12th International Conference on Frontiers in
Handwriting Recognition, pages 539?544.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2010.
String-to-dependency statistical machine translation.
Computational Linguistics, 36(4):649?671, Decem-
ber.
Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel
Jurafsky, and Christopher Manning. 2005. A condi-
tional random field word segmenter. In Proceedings of
the Fourth SIGHAN Workshop on Chinese Language
Processing.
Nicola Ueffing, Franz J. Och, and Hermann Ney. 2002.
Generation of word graphs in statistical machine trans-
lation. In Proceedings of the conference on Empirical
Methods in Natural Language Processing, pages 156?
163.
Ying Zhang and Stephan Vogel. 2004. Measuring confi-
dence intervals for the machine translation evaluation
metrics. In Proceedings of The international Confer-
ence on Theoretical and Methodological Issues in Ma-
chine Translation.
Andreas Zollmann and Ashish Venugopal. 2006. Syntax
augmented machine translation via chart parsing. In
Proceedings of the Workshop on Statistical Machine
Translation, pages 138?141.
254
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 245?254,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Active learning for interactive machine translation
Jesu?s Gonza?lez-Rubio and Daniel Ortiz-Mart??nez and Francisco Casacuberta
D. de Sistemas Informa?ticos y Computacio?n
U. Polite`cnica de Vale`ncia
C. de Vera s/n, 46022 Valencia, Spain
{jegonzalez,dortiz,fcn}@dsic.upv.es
Abstract
Translation needs have greatly increased
during the last years. In many situa-
tions, text to be translated constitutes an
unbounded stream of data that grows con-
tinually with time. An effective approach
to translate text documents is to follow
an interactive-predictive paradigm in which
both the system is guided by the user
and the user is assisted by the system to
generate error-free translations. Unfortu-
nately, when processing such unbounded
data streams even this approach requires an
overwhelming amount of manpower. Is in
this scenario where the use of active learn-
ing techniques is compelling. In this work,
we propose different active learning tech-
niques for interactive machine translation.
Results show that for a given translation
quality the use of active learning allows us
to greatly reduce the human effort required
to translate the sentences in the stream.
1 Introduction
Translation needs have greatly increased during
the last years due to phenomena such as global-
ization and technologic development. For exam-
ple, the European Parliament1 translates its pro-
ceedings to 22 languages in a regular basis or
Project Syndicate2 that translates editorials into
different languages. In these and many other ex-
amples, data can be viewed as an incoming un-
bounded stream since it grows continually with
time (Levenberg et al 2010). Manual translation
of such streams of data is extremely expensive
given the huge volume of translation required,
1http://www.europarl.europa.eu
2http://project-syndicate.org
therefore various automatic machine translation
methods have been proposed.
However, automatic statistical machine trans-
lation (SMT) systems are far from generating
error-free translations and their outputs usually
require human post-editing in order to achieve
high-quality translations. One way of taking ad-
vantage of SMT systems is to combine them
with the knowledge of a human translator in the
interactive-predictive machine translation (IMT)
framework (Foster et al 1998; Langlais and La-
palme, 2002; Barrachina et al 2009), which is
a particular case of the computer-assisted trans-
lation paradigm (Isabelle and Church, 1997). In
the IMT framework, a state-of-the-art SMT model
and a human translator collaborate to obtain high-
quality translations while minimizing required
human effort.
Unfortunately, the application of either post-
editing or IMT to data streams with massive data
volumes is still too expensive, simply because
manual supervision of all instances requires huge
amounts of manpower. For such massive data
streams the need of employing active learning
(AL) is compelling. AL techniques for IMT se-
lectively ask an oracle (e.g. a human transla-
tor) to supervise a small portion of the incoming
sentences. Sentences are selected so that SMT
models estimated from them translate new sen-
tences as accurately as possible. There are three
challenges when applying AL to unbounded data
streams (Zhu et al 2010). These challenges can
be instantiated to IMT as follows:
1. The pool of candidate sentences is dynam-
ically changing, whereas existing AL algo-
rithms are dealing with static datasets only.
245
2. Concepts such as optimum translation and
translation probability distribution are con-
tinually evolving whereas existing AL algo-
rithms only deal with constant concepts.
3. Data volume is unbounded which makes
impractical to batch-learn one single sys-
tem from all previously translated sentences.
Therefore, model training must be done in an
incremental fashion.
In this work, we present a proposal of AL for
IMT specifically designed to work with stream
data. In short, our proposal divides the data
stream into blocks where AL techniques for static
datasets are applied. Additionally, we implement
an incremental learning technique to efficiently
train the base SMT models as new data is avail-
able.
2 Related work
A body of work has recently been proposed to ap-
ply AL techniques to SMT (Haffari et al 2009;
Ambati et al 2010; Bloodgood and Callison-
Burch, 2010). The aim of these works is to
build one single optimal SMT model from manu-
ally translated data extracted from static datasets.
None of them fit in the setting of data streams.
Some of the above described challenges of AL
from unbounded streams have been previously ad-
dressed in the MT literature. In order to deal with
the evolutionary nature of the problem, Nepveu et
al. (2004) propose an IMT system with dynamic
adaptation via cache-based model extensions for
language and translation models. Pursuing the
same goal for SMT, Levenberg et al (2010)
study how to bound the space when processing
(potentially) unbounded streams of parallel data
and propose a method to incrementally retrain
SMT models. Another method to efficiently re-
train a SMT model with new data was presented
in (Ortiz-Mart??nez et al 2010). In this work,
the authors describe an application of the online
learning paradigm to the IMT framework.
To the best of our knowledge, the only previ-
ous work on AL for IMT is (Gonza?lez-Rubio et
al., 2011). There, the authors present a na??ve ap-
plication of the AL paradigm for IMT that do not
take into account the dynamic change in proba-
bility distribution of the stream. Nevertheless, re-
sults show that even that simple AL framework
halves the required human effort to obtain a cer-
tain translation quality.
In this work, the AL framework presented
in (Gonza?lez-Rubio et al 2011) is extended in
an effort to address all the above described chal-
lenges. In short, we propose an AL framework for
IMT that splits the data stream into blocks. This
approach allows us to have more context to model
the changing probability distribution of the stream
(challenge 2) and results in a more accurate sam-
pling of the changing pool of sentences (chal-
lenge 1). In contrast to the proposal described
in (Gonza?lez-Rubio et al 2011), we define sen-
tence sampling strategies whose underlying mod-
els can be updated with the newly available data.
This way, the sentences to be supervised by the
user are chosen taking into account previously su-
pervised sentences. To efficiently retrain the un-
derlying SMT models of the IMT system (chal-
lenge 3), we follow the online learning technique
described in (Ortiz-Mart??nez et al 2010). Finally,
we integrate all these elements to define an AL
framework for IMT with an objective of obtaining
an optimum balance between translation quality
and human user effort.
3 Interactive machine translation
IMT can be seen as an evolution of the SMT
framework. Given a sentence f from a source
language to be translated into a sentence e of
a target language, the fundamental equation of
SMT (Brown et al 1993) is defined as follows:
e? = argmax
e
Pr(e | f) (1)
where Pr(e | f) is usually approximated by a log
linear translation model (Koehn et al 2003). In
this case, the decision rule is given by the expres-
sion:
e? = argmax
e
{
M?
m=1
?mhm(e, f)
}
(2)
where each hm(e, f) is a feature function repre-
senting a statistical model and ?m its weight.
In the IMT framework, a human translator is in-
troduced in the translation process to collaborate
with an SMT model. For a given source sentence,
the SMT model fully automatically generates an
initial translation. The human user checks this
translation, from left to right, correcting the first
246
source (f ): Para ver la lista de recursos
desired translation (e?): To view a listing of resources
inter.-0
ep
es To view the resources list
inter.-1
ep To view
k a
es list of resources
inter.-2
ep To view a list
k list i
es list i ng resources
inter.-3
ep To view a listing
k o
es o f resources
accept ep To view a listing of resources
Figure 1: IMT session to translate a Spanish sentence
into English. The desired translation is the translation
the human user have in mind. At interaction-0, the sys-
tem suggests a translation (es). At interaction-1, the
user moves the mouse to accept the first eight charac-
ters ?To view ? and presses the a key (k), then the
system suggests completing the sentence with ?list of
resources? (a new es). Interactions 2 and 3 are simi-
lar. In the final interaction, the user accepts the current
translation.
error. Then, the SMT model proposes a new ex-
tension taking the correct prefix, ep, into account.
These steps are repeated until the user accepts the
translation. Figure 1 illustrates a typical IMT ses-
sion. In the resulting decision rule, we have to
find an extension es for a given prefix ep. To do
this we reformulate equation (1) as follows, where
the term Pr(ep | f) has been dropped since it does
not depend on es:
e?s = argmax
es
Pr(ep, es | f) (3)
? argmax
es
p(es | f , ep) (4)
The search is restricted to those sentences e
which contain ep as prefix. Since e ? ep es, we
can use the same log-linear SMT model, equa-
tion (2), whenever the search procedures are ad-
equately modified (Barrachina et al 2009).
4 Active learning for IMT
The aim of the IMT framework is to obtain high-
quality translations while minimizing the required
human effort. Despite the fact that IMT may
reduce the required effort with respect to post-
editing, it still requires the user to supervise all
the translations. To address this problem, we pro-
pose to use AL techniques to select only a small
number of sentences whose translations are worth
to be supervised by the human expert.
This approach implies a modification of the
user-machine interaction protocol. For a given
source sentence, the SMT model generates an ini-
tial translation. Then, if this initial translation is
classified as incorrect or ?worth of supervision?,
we perform a conventional IMT procedure as in
Figure 1. If not, we directly return the initial au-
tomatic translation and no effort is required from
the user. At the end of the process, we use the new
sentence pair (f , e) available to refine the SMT
models used by the IMT system.
In this scenario, the user only checks a small
number of sentences, thus, final translations are
not error-free as in conventional IMT. However,
results in previous works (Gonza?lez-Rubio et al
2011) show that this approach yields important
reduction in human effort. Moreover, depending
on the definition of the sampling strategy, we can
modify the ratio of sentences that are interactively
translated to adapt our system to the requirements
of a specific translation task. For example, if the
main priority is to minimize human effort, our
system can be configured to translate all the sen-
tences without user intervention.
Algorithm 1 describes the basic algorithm to
implement AL for IMT. The algorithm receives as
input an initial SMT model, M , a sampling strat-
egy, S, a stream of source sentences, F, and the
block size, B. First, a block of B sentences, X ,
is extracted from the data stream (line 3). From
this block, we sample those sentences, Y , that
are worth to be supervised by the human expert
(line 4). For each of the sentences in X , the cur-
rent SMT model generates an initial translation,
e?, (line 6). If the sentence has been sampled as
worthy of supervision, f ? Y , the user is required
to interactively translate it (lines 8?13) as exem-
plified in Figure 1. The source sentence f and its
human-supervised translation, e, are then used to
retrain the SMT model (line 14). Otherwise, we
directly output the automatic translation e? as our
final translation (line 17).
Most of the functions in the algorithm denote
different steps in the interaction between the hu-
man user and the machine:
? translate(M, f): returns the most proba-
ble automatic translation of f given by M .
? validPrefix(e): returns the prefix of e
247
input : M (initial SMT model)
S (sampling strategy)
F (stream of source sentences)
B (block size)
auxiliar : X (block of sentences)
Y (sentences worth of supervision)
begin1
repeat2
X = getSentsFromStream (B,F);3
Y = S(X,M);4
foreach f ? X do5
e? = translate(M, f);6
if f ? Y then7
e = e?;8
repeat9
ep = validPrefix(e);10
e?s = genSuffix(M, f , ep);11
e = ep e?s;12
until validTranslation(e) ;13
M = retrain(M, (f , e));14
output(e);15
else16
output(e?);17
until True ;18
end19
Algorithm 1: Pseudo-code of the proposed
algorithm to implement AL for IMT from
unbounded data streams.
validated by the user as correct. This prefix
includes the correction k.
? genSuffix(M, f , ep): returns the suffix of
maximum probability that extends prefix ep.
? validTranslation(e): returns True if
the user considers the current translation to
be correct and False otherwise.
Apart from these, the two elements that define
the performance of our algorithm are the sampling
strategy S(X,M) and the retrain(M, (f , e))
function. On the one hand, the sampling strat-
egy decides which sentences should be supervised
by the user, which defines the human effort re-
quired by the algorithm. Section 5 describes our
implementation of the sentence sampling to deal
with the dynamic nature of data streams. On the
other hand, the retrain(?) function incremen-
tally trains the SMT model with each new training
pair (f , e). Section 6 describes the implementa-
tion of this function.
5 Sentence sampling strategies
A good sentence sampling strategy must be able
to select those sentences that along with their cor-
rect translations improve most the performance of
the SMT model. To do that, the sampling strat-
egy have to correctly discriminate ?informative?
sentences from those that are not. We can make
different approximations to measure the informa-
tiveness of a given sentence. In the following
sections, we describe the three different sampling
strategies tested in our experimentation.
5.1 Random sampling
Arguably, the simplest sampling approach is ran-
dom sampling, where the sentences are randomly
selected to be interactively translated. Although
simple, it turns out that random sampling per-
form surprisingly well in practice. The success
of random sampling stem from the fact that in
data stream environments the translation proba-
bility distributions may vary significantly through
time. While general AL algorithms ask the user to
translate informative sentences, they may signifi-
cantly change probability distributions by favor-
ing certain translations, consequently, the previ-
ously human-translated sentences may no longer
reveal the genuine translation distribution in the
current point of the data stream (Zhu et al 2007).
This problem is less severe for static data where
the candidate pool is fixed and AL algorithms are
able to survey all instances. Random sampling
avoids this problem by randomly selecting sen-
tences for human supervision. As a result, it al-
ways selects those sentences with the most similar
distribution to the current sentence distribution in
the data stream.
5.2 n-gram coverage sampling
One technique to measure the informativeness
of a sentence is to directly measure the amount
of new information that it will add to the SMT
model. This sampling strategy considers that
sentences with rare n-grams are more informa-
tive. The intuition for this approach is that rare
n-grams need to be seen several times in order to
accurately estimate their probability.
To do that, we store the counts for each n-gram
present in the sentences used to train the SMT
model. We assume that an n-gram is accurately
represented when it appears A or more times in
248
the training samples. Therefore, the score for a
given sentence f is computed as:
C(f) =
?N
n=1 |N
<A
n (f)|
?N
n=1 |Nn(f)|
(5)
where Nn(f) is the set of n-grams of size n
in f , N<An (f) is the set of n-grams of size n in
f that are inaccurately represented in the training
data and N is the maximum n-gram order. In
the experimentation, we assume N = 4 as the
maximum n-gram order and a value of 10 for the
threshold A. This sampling strategy works by se-
lecting a given percentage of the highest scoring
sentences.
We update the counts of the n-grams seen by
the SMT model with each new sentence pair.
Hence, the sampling strategy is always up-to-date
with the last training data.
5.3 Dynamic confidence sampling
Another technique is to consider that the most in-
formative sentence is the one the current SMT
model translates worst. The intuition behind this
approach is that an SMT model can not generate
good translations unless it has enough informa-
tion to translate the sentence.
The usual approach to compute the quality of a
translation hypothesis is to compare it to a refer-
ence translation, but, in this case, it is not a valid
option since reference translations are not avail-
able. Hence, we use confidence estimation (Gan-
drabur and Foster, 2003; Blatz et al 2004; Ueff-
ing and Ney, 2007) to estimate the probability of
correctness of the translations. Specifically, we
estimate the quality of a translation from the con-
fidence scores of their individual words.
The confidence score of a word ei of the trans-
lation e = e1 . . . ei . . . eI generated from the
source sentence f = f1 . . . fj . . . fJ is computed
as described in (Ueffing and Ney, 2005):
Cw(ei, f) = max
0?j?| f |
p(ei|fj) (6)
where p(ei|fj) is an IBM model 1 (Brown et al
1993) bilingual lexicon probability and f0 is the
empty source word. The confidence score for the
full translation e is computed as the ratio of its
words classified as correct by the word confidence
measure. Therefore, we define the confidence-
based informativeness score as:
C(e, f) = 1?
|{ei | Cw(ei, f) > ?w}|
| e |
(7)
Finally, this sampling strategy works by select-
ing a given percentage of the highest scoring sen-
tences.
We dynamically update the confidence sampler
each time a new sentence pair is added to the SMT
model. The incremental version of the EM algo-
rithm (Neal and Hinton, 1999) is used to incre-
mentally train the IBM model 1.
6 Retraining of the SMT model
To retrain the SMT model, we implement the
online learning techniques proposed in (Ortiz-
Mart??nez et al 2010). In that work, a state-
of-the-art log-linear model (Och and Ney, 2002)
and a set of techniques to incrementally train this
model were defined. The log-linear model is com-
posed of a set of feature functions governing dif-
ferent aspects of the translation process, includ-
ing a language model, a source sentence?length
model, inverse and direct translation models, a
target phrase?length model, a source phrase?
length model and a distortion model.
The incremental learning algorithm allows us
to process each new training sample in constant
time (i.e. the computational complexity of train-
ing a new sample does not depend on the num-
ber of previously seen training samples). To do
that, a set of sufficient statistics is maintained for
each feature function. If the estimation of the
feature function does not require the use of the
well-known expectation?maximization (EM) al-
gorithm (Dempster et al 1977) (e.g. n-gram lan-
guage models), then it is generally easy to incre-
mentally extend the model given a new training
sample. By contrast, if the EM algorithm is re-
quired (e.g. word alignment models), the estima-
tion procedure has to be modified, since the con-
ventional EM algorithm is designed for its use in
batch learning scenarios. For such models, the in-
cremental version of the EM algorithm (Neal and
Hinton, 1999) is applied. A detailed description
of the update algorithm for each of the models in
the log-linear combination is presented in (Ortiz-
Mart??nez et al 2010).
7 Experiments
We carried out experiments to assess the perfor-
mance of the proposed AL implementation for
IMT. In each experiments, we started with an
initial SMT model that is incrementally updated
249
corpus use sentences
words
(Spa/Eng)
Europarl
train 731K 15M/15M
devel. 2K 60K/58K
News
test 51K 1.5M/1.2M
Commentary
Table 1: Size of the Spanish?English corpora used in
the experiments. K and M stand for thousands and
millions of elements respectively.
with the sentences selected by the current sam-
pling strategy. Due to the unavailability of public
benchmark data streams, we selected a relatively
large corpus and treated it as a data stream for AL.
To simulate the interaction with the user, we used
the reference translations in the data stream cor-
pus as the translation the human user would like
to obtain. Since each experiment is carried out
under the same conditions, if one sampling strat-
egy outperforms its peers, then we can safely con-
clude that this is because the sentences selected to
be translated are more informative.
7.1 Training corpus and data stream
The training data comes from the Europarl corpus
as distributed for the shared task in the NAACL
2006 workshop on statistical machine transla-
tion (Koehn and Monz, 2006). We used this data
to estimate the initial log-linear model used by our
IMT system (see Section 6). The weights of the
different feature functions were tuned by means
of minimum error?rate training (Och, 2003) exe-
cuted on the Europarl development corpus. Once
the SMT model was trained, we use the News
Commentary corpus (Callison-Burch et al 2007)
to simulate the data stream. The size of these cor-
pora is shown in Table 1. The reasons to choose
the News Commentary corpus to carry out our
experiments are threefold: first, its size is large
enough to simulate a data stream and test our
AL techniques in the long term; second, it is
out-of-domain data which allows us to simulate
a real-world situation that may occur in a trans-
lation company, and, finally, it consists in edito-
rials from eclectic domain: general politics, eco-
nomics and science, which effectively represents
the variations in the sentence distributions of the
simulated data stream.
7.2 Assessment criteria
We want to measure both the quality of the gener-
ated translations and the human effort required to
obtain them.
We measure translation quality with the well-
known BLEU (Papineni et al 2002) score.
To estimate human user effort, we simulate the
actions taken by a human user in its interaction
with the IMT system. The first translation hypoth-
esis for each given source sentence is compared
with a single reference translation and the longest
common character prefix (LCP) is obtained. The
first non-matching character is replaced by the
corresponding reference character and then a new
translation hypothesis is produced (see Figure 1).
This process is iterated until a full match with the
reference is obtained. Each computation of the
LCP would correspond to the user looking for the
next error and moving the pointer to the corre-
sponding position of the translation hypothesis.
Each character replacement, on the other hand,
would correspond to a keystroke of the user.
Bearing this in mind, we measure the user ef-
fort by means of the keystroke and mouse-action
ratio (KSMR) (Barrachina et al 2009). This mea-
sure has been extensively used to report results in
the IMT literature. KSMR is calculated as the
number of keystrokes plus the number of mouse
movements divided by the total number of refer-
ence characters. From a user point of view the
two types of actions are different and require dif-
ferent types of effort (Macklovitch, 2006). In any
case, as an approximation, KSMR assumes that
both actions require a similar effort.
7.3 Experimental results
In this section, we report results for three different
experiments. First, we studied the performance
of the sampling strategies when dealing with the
sampling bias problem. In the second experiment,
we carried out a typical AL experiment measur-
ing the performance of the sampling strategies as
a function of the percentage of the corpus used
to retrain the SMT model. Finally, we tested our
AL implementation for IMT in order to study the
tradeoff between required human effort and final
translation quality.
7.3.1 Dealing with the sampling bias
In this experiment, we want to study the perfor-
mance of the different sampling strategies when
250
 16
 17
 18
 19
 20
 21
 22
 0  10  20  30  40  50
BL
EU
Block number
DCS NS RS
Figure 2: Performance of the AL methods across dif-
ferent data blocks. Block size 500. Human supervision
10% of the corpus.
dealing with the sampling bias problem. Fig-
ure 2 shows the evolution of the translation qual-
ity, in terms of BLEU, across different data blocks
for the three sampling strategies described in sec-
tion 5, namely, dynamic confidence sampling
(DCS), n-gram coverage sampling (NS) and ran-
dom sampling (RS). On the one hand, the x-axis
represents the data blocks number in their tempo-
ral order. On the other hand, the y-axis represents
the BLEU score when automatically translating a
block. Such translation is obtained by the SMT
model trained with translations supervised by the
user up to that point of the data stream. To fairly
compare the different methods, we fixed the per-
centage of words supervised by the human user
(10%). In addition to this, we used a block size of
500 sentences. Similar results were obtained for
other block sizes.
Results in Figure 2 indicate that the perfor-
mances for the data blocks fluctuate and fluctu-
ations are quite significant. This phenomenon is
due to the eclectic domain of the sentences in the
data stream. Additionally, the steady increase in
performance is caused by the increasing amount
of data used to retrain the SMT model.
Regarding the results for the different sam-
pling strategies, DCS consistently outperformed
RS and NS. This observation asserts that for con-
cept drifting data streams with constant changing
translation distributions, DCS can adaptively ask
the user to translate sentences to build a superior
SMT model. On the other hand, NS obtains worse
results that RS. This result can be explained by the
 15
 16
 17
 18
 19
 20
 21
 22
 23
 0  5  10  15  20
BL
EU
Percentage (%) of the corpus in words
DCS NS SCS RS
 17
 18
 19
 20
 2  4  6  8
Figure 3: BLEU of the initial automatic translations
as a function of the percentage of the corpus used to
retrain the model.
fact that NS is independent of the target language
and just looks into the source language, while
DCS takes into account both the source sentence
and its automatic translation. Similar phenomena
has been reported in a previous work on AL for
SMT (Haffari et al 2009).
7.3.2 AL performance
We carried out experiments to study the perfor-
mance of the different sampling strategies. To this
end, we compare the quality of the initial auto-
matic translations generated in our AL implemen-
tation for IMT (line 6 in Algorithm 1). Figure 3
shows the BLEU score of these initial translations
represented as a function of the percentage of the
corpus used to retrain the SMT model. The per-
centage of the corpus is measured in number of
running words.
In Figure 3, we present results for the three
sampling strategies described in section 5. Ad-
ditionally, we also compare our techniques with
the AL technique for IMT proposed in (Gonza?lez-
Rubio et al 2011). Such technique is similar to
DCS but it does not update the IBM model 1 used
by the confidence sampler with the newly avail-
able human-translated sentences. This technique
is referred to as static confidence sampler (SCS).
Results in Figure 3 indicate that the perfor-
mance of the retrained SMT models increased as
more data was incorporated. Regarding the sam-
pling strategies, DCS improved the results ob-
tained by the other sampling strategies. NS ob-
tained by far the worst results, which confirms the
results shown in the previous experiment. Finally,
251
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 0  10  20  30  40  50  60  70
BL
EU
KSMR
DCSNS SCSRS w/o AL
 50 55
 60 65
 70 75
 16  18  20  22  24
Figure 4: Quality of the data stream translation
(BLEU) as a function of the required human effort
(KSMR). w/o AL denotes a system with no retraining.
as it can be seen, SCS obtained slightly worst re-
sults than DCS showing the importance of dy-
namically adapting the underlying model used by
the sampling strategy.
7.3.3 Balancing human effort and
translation quality
Finally, we studied the balance between re-
quired human effort and final translation error.
This can be useful in a real-world scenario where
a translation company is hired to translate a
stream of sentences. Under these circumstances,
it would be important to be able to predict the ef-
fort required from the human translators to obtain
a certain translation quality.
The experiment simulate this situation using
our proposed IMT system with AL to translate
the stream of sentences. To have a broad view
of the behavior of our system, we repeated this
translation process multiple times requiring an in-
creasing human effort each time. Experiments
range from a fully-automatic translation system
with no need of human intervention to a system
where the human is required to supervise all the
sentences. Figure 4 presents results for SCS (see
section 7.3.2) and the sentence selection strate-
gies presented in section 5. In addition, we also
present results for a static system without AL (w/o
AL). This system is equal to SCS but it do not per-
form any SMT retraining.
Results in Figure 4 show a consistent reduction
in required user effort when using AL. For a given
human effort the use of AL methods allowed to
obtain twice the translation quality. Regarding the
different AL sampling strategies, DCS obtains the
better results but differences with other methods
are slight.
Varying the sentence classifier, we can achieve
a balance between final translation quality and re-
quired human effort. This feature allows us to
adapt the system to suit the requirements of the
particular translation task or to the available eco-
nomic or human resources. For example, if a
translation quality of 60 BLEU points is satisfac-
tory, then the human translators would need to
modify only a 20% of the characters of the au-
tomatically generated translations.
Finally, it should be noted that our IMT sys-
tems with AL are able to generate new suffixes
and retrain with new sentence pairs in tenths of a
second. Thus, it can be applied in real time sce-
narios.
8 Conclusions and future work
In this work, we have presented an AL frame-
work for IMT specially designed to process data
streams with massive volumes of data. Our pro-
posal splits the data stream in blocks of sentences
of a certain size and applies AL techniques indi-
vidually for each block. For this purpose, we im-
plemented different sampling strategies that mea-
sure the informativeness of a sentence according
to different criteria.
To evaluate the performance of our proposed
sampling strategies, we carried out experiments
comparing them with random sampling and the
only previously proposed AL technique for IMT
described in (Gonza?lez-Rubio et al 2011). Ac-
cording to the results, one of the proposed sam-
pling strategies, specifically the dynamic con-
fidence sampling strategy, consistently outper-
formed all the other strategies.
The results in the experimentation show that the
use of AL techniques allows us to make a tradeoff
between required human effort and final transla-
tion quality. In other words, we can adapt our sys-
tem to meet the translation quality requirements
of the translation task or the available human re-
sources.
As future work, we plan to investigate on
more sophisticated sampling strategies such as
those based in information density or query-by-
committee. Additionally, we will conduct exper-
iments with real users to confirm the results ob-
tained by our user simulation.
252
Acknowledgements
The research leading to these results has re-
ceived funding from the European Union Seventh
Framework Programme (FP7/2007-2013) under
grant agreement no 287576. Work also supported
by the EC (FEDER/FSE) and the Spanish MEC
under the MIPRCV Consolider Ingenio 2010 pro-
gram (CSD2007-00018) and iTrans2 (TIN2009-
14511) project and by the Generalitat Valenciana
under grant ALMPR (Prometeo/2009/01).
References
Vamshi Ambati, Stephan Vogel, and Jaime Carbonell.
2010. Active learning and crowd-sourcing for ma-
chine translation. In Proc. of the conference on
International Language Resources and Evaluation,
pages 2169?2174.
Sergio Barrachina, Oliver Bender, Francisco Casacu-
berta, Jorge Civera, Elsa Cubel, Shahram Khadivi,
Antonio Lagarda, Hermann Ney, Jesu?s Toma?s, En-
rique Vidal, and Juan-Miguel Vilar. 2009. Sta-
tistical approaches to computer-assisted translation.
Computational Linguistics, 35:3?28.
John Blatz, Erin Fitzgerald, George Foster, Simona
Gandrabur, Cyril Goutte, Alex Kulesza, Alberto
Sanchis, and Nicola Ueffing. 2004. Confidence es-
timation for machine translation. In Proc. of the in-
ternational conference on Computational Linguis-
tics, pages 315?321.
Michael Bloodgood and Chris Callison-Burch. 2010.
Bucking the trend: large-scale cost-focused active
learning for statistical machine translation. In Proc.
of the Association for Computational Linguistics,
pages 854?864.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
parameter estimation. Computational Linguistics,
19:263?311.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2007.
(Meta-) evaluation of machine translation. In Proc.
of the Workshop on Statistical Machine Translation,
pages 136?158.
Arthur Dempster, Nan Laird, and Donald Rubin.
1977. Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statis-
tical Society., 39(1):1?38.
George Foster, Pierre Isabelle, and Pierre Plamon-
don. 1998. Target-text mediated interactive ma-
chine translation. Machine Translation, 12:175?
194.
Simona Gandrabur and George Foster. 2003. Confi-
dence estimation for text prediction. In Proc. of the
Conference on Computational Natural Language
Learning, pages 315?321.
Jesu?s Gonza?lez-Rubio, Daniel Ortiz-Mart??nez, and
Francisco casacuberta. 2011. An active learn-
ing scenario for interactive machine translation. In
Proc. of the 13thInternational Conference on Mul-
timodal Interaction. ACM.
Gholamreza Haffari, Maxim Roy, and Anoop Sarkar.
2009. Active learning for statistical phrase-based
machine translation. In Proc. of the North Ameri-
can Chapter of the Association for Computational
Linguistics, pages 415?423.
Pierre Isabelle and Kenneth Ward Church. 1997. Spe-
cial issue on new tools for human translators. Ma-
chine Translation, 12(1-2):1?2.
Philipp Koehn and Christof Monz. 2006. Man-
ual and automatic evaluation of machine transla-
tion between european languages. In Proc. of the
Workshop on Statistical Machine Translation, pages
102?121.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology - Vol-
ume 1, pages 48?54.
Philippe Langlais and Guy Lapalme. 2002. Trans
Type: development-evaluation cycles to boost trans-
lator?s productivity. Machine Translation, 17:77?
98.
Abby Levenberg, Chris Callison-Burch, and Miles Os-
borne. 2010. Stream-based translation models for
statistical machine translation. In Proc. of the North
American Chapter of the Association for Compu-
tational Linguistics, pages 394?402, Los Angeles,
California, June.
Elliott Macklovitch. 2006. TransType2: the last word.
In Proc. of the conference on International Lan-
guage Resources and Evaluation, pages 167?17.
Radford Neal and Geoffrey Hinton. 1999. A view of
the EM algorithm that justifies incremental, sparse,
and other variants. Learning in graphical models,
pages 355?368.
Laurent Nepveu, Guy Lapalme, Philippe Langlais, and
George Foster. 2004. Adaptive language and trans-
lation models for interactive machine translation. In
Proc, of EMNLP, pages 190?197, Barcelona, Spain,
July.
Franz Och and Hermann Ney. 2002. Discriminative
training and maximum entropy models for statisti-
cal machine translation. In Proc. of the Association
for Computational Linguistics, pages 295?302.
Franz Och. 2003. Minimum error rate training in sta-
tistical machine translation. In Proc. of the Associa-
tion for Computational Linguistics, pages 160?167.
253
Daniel Ortiz-Mart??nez, Ismael Garc??a-Varea, and
Francisco Casacuberta. 2010. Online learning for
interactive statistical machine translation. In Proc.
of the North American Chapter of the Association
for Computational Linguistics, pages 546?554.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Proc.
of the Association for Computational Linguistics,
pages 311?318.
Nicola Ueffing and Hermann Ney. 2005. Applica-
tion of word-level confidence measures in interac-
tive statistical machine translation. In Proc. of the
European Association for Machine Translation con-
ference, pages 262?270.
Nicola Ueffing and Hermann Ney. 2007. Word-
level confidence estimation for machine translation.
Computational Linguistics, 33:9?40.
Xingquan Zhu, Peng Zhang, Xiaodong Lin, and Yong
Shi. 2007. Active learning from data streams. In
Proc. of the 7th IEEE International Conference on
Data Mining, pages 757?762. IEEE Computer So-
ciety.
Xingquan Zhu, Peng Zhang, Xiaodong Lin, and Yong
Shi. 2010. Active learning from stream data using
optimal weight classifier ensemble. Transactions
on Systems, Man and Cybernetics Part B, 40:1607?
1621, December.
254
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 546?554,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Online Learning for Interactive Statistical Machine Translation
Daniel Ortiz-Mart??nez
Dpto. de Sist. Inf. y Comp.
Univ. Polite?c. de Valencia
46071 Valencia, Spain
dortiz@dsic.upv.es
Ismael Garc??a-Varea
Dpto. de Informa?tica
Univ. de Castilla-La Mancha
02071 Albacete, Spain
ivarea@info-ab.uclm.es
Francisco Casacuberta
Dpto. de Sist. Inf. y Comp.
Univ. Polite?c. de Valencia
46071 Valencia, Spain
fcn@dsic.upv.es
Abstract
State-of-the-art Machine Translation (MT)
systems are still far from being perfect. An al-
ternative is the so-called Interactive Machine
Translation (IMT) framework. In this frame-
work, the knowledge of a human translator is
combined with a MT system. The vast ma-
jority of the existing work on IMT makes use
of the well-known batch learning paradigm.
In the batch learning paradigm, the training of
the IMT system and the interactive translation
process are carried out in separate stages. This
paradigm is not able to take advantage of the
new knowledge produced by the user of the
IMT system. In this paper, we present an ap-
plication of the online learning paradigm to
the IMT framework. In the online learning
paradigm, the training and prediction stages
are no longer separated. This feature is par-
ticularly useful in IMT since it allows the user
feedback to be taken into account. The online
learning techniques proposed here incremen-
tally update the statistical models involved in
the translation process. Empirical results show
the great potential of online learning in the
IMT framework.
1 Introduction
Information technology advances have led to the
need for more efficient translation methods. Current
MT systems are not able to produce ready-to-use
texts. Indeed, MT systems usually require human
post-editing to achieve high-quality translations.
One way of taking advantage of MT systems is to
combine them with the knowledge of a human trans-
lator in the IMT paradigm, which is a special type of
the computer-assisted translation paradigm (Isabelle
and Church, 1997). An important contribution to
IMT technology was pioneered by the TransType
project (Foster et al, 1997; Langlais et al, 2002)
where data driven MT techniques were adapted for
their use in an interactive translation environment.
Following the TransType ideas, Barrachina et
al. (2009) proposed a new approach to IMT, in which
fully-fledged statistical MT (SMT) systems are used
to produce full target sentence hypotheses, or por-
tions thereof, which can be partially or completely
accepted and amended by a human translator. Each
partial, correct text segment is then used by the
SMT system as additional information to achieve
improved suggestions. Figure 1 illustrates a typical
IMT session.
source(f ): Para ver la lista de recursos
reference(e?): To view a listing of resources
inter.-0
ep
es To view the resources list
inter.-1
ep To view
k a
es list of resources
inter.-2
ep To view a list
k list i
es list i ng resources
inter.-3
ep To view a listing
k o
es o f resources
accept ep To view a listing of resources
Figure 1: IMT session to translate a Spanish sen-
tence into English. In interaction-0, the system sug-
gests a translation (es). In interaction-1, the user
moves the mouse to accept the first eight characters
?To view ? and presses the a key (k), then the sys-
tem suggests completing the sentence with ?list of
resources? (a new es). Interactions 2 and 3 are sim-
ilar. In the final interaction, the user accepts the cur-
rent suggestion.
In this paper, we also focus on the IMT frame-
work. Specifically, we present an IMT system that is
able to learn from user feedback. For this purpose,
we apply the online learning paradigm to the IMT
framework. The online learning techniques that we
propose here allow the statistical models involved in
the translation process to be incrementally updated.
546
Figure 2 (inspired from (Vidal et al, 2007)) shows
a schematic view of these ideas. Here, f is the in-
put sentence and e is the output derived by the IMT
system from f . By observing f and e, the user inter-
acts with the IMT system until the desired output e? is
produced. The input sentence f and its desired trans-
lation e? can be used to refine the models used by the
system. In general, the model is initially obtained
through a classical batch training process from a pre-
viously given training sequence of pairs (fi,ei) from
the task being considered. Now, the models can be
extended with the use of valuable user feedback.
e
f
e
k
f
       Interactive 
     SMT System
 Batch
Learning
 Online
Learning
 . . .
 f  , e
 2    2
 f  , e
 1    1
feedback/interactions
e
f ^
^
Incremental
Models
Figure 2: An Online Interactive SMT system
2 Interactive machine translation
IMT can be seen as an evolution of the SMT frame-
work. Given a sentence f from a source lan-
guage F to be translated into a target sentence e
of a target language E , the fundamental equation of
SMT (Brown et al, 1993) is the following:
e? = argmax
e
{Pr(e | f)} (1)
= argmax
e
{Pr(f | e)Pr(e)} (2)
where Pr(f | e) is approximated by a translation
model that represents the correlation between the
source and the target sentence and where Pr(e) is
approximated by a language model representing the
well-formedness of the candidate translation e.
State-of-the-art statistical machine translation
systems follow a loglinear approach (Och and Ney,
2002), where direct modelling of the posterior prob-
ability Pr(e | f) of Equation (1) is used. In this case,
the decision rule is given by the expression:
e? = argmax
e
{
M
?
m=1
?mhm(e, f)
}
(3)
where each hm(e, f) is a feature function represent-
ing a statistical model and ?m its weight.
Current MT systems are based on the use of
phrase-based models (Koehn et al, 2003) as transla-
tion models. The basic idea of Phrase-based Trans-
lation (PBT) is to segment the source sentence into
phrases, then to translate each source phrase into a
target phrase, and finally to reorder the translated
target phrases in order to compose the target sen-
tence. If we summarize all the decisions made dur-
ing the phrase-based translation process by means of
the hidden variable a?K1 , we obtain the expression:
Pr(f |e) =
?
K,a?K1
Pr(f?K1 , a?K1 | e?K1 ) (4)
where each a?k ? {1 . . .K} denotes the index of the
target phrase e? that is aligned with the k-th source
phrase f?k, assuming a segmentation of length K.
According to Equation (4), and following a max-
imum approximation, the problem stated in Equa-
tion (2) can be reframed as:
e? ? arg max
e,a
{
p(e) ? p(f ,a | e)
}
(5)
In the IMT scenario, we have to find an extension
es for a given prefix ep. To do this we reformulate
Equation (5) as follows:
e?s ? arg max
es,a
{
p(es | ep) ? p(f ,a | ep, es)
}
(6)
where the term p(ep) has been dropped since it does
depend neither on es nor on a.
Thus, the search is restricted to those sentences e
which contain ep as prefix. It is also worth mention-
ing that the similarities between Equation (6) and
Equation (5) (note that epes ? e) allow us to use
the same models whenever the search procedures are
adequately modified (Barrachina et al, 2009).
Following the loglinear approach stated in Equa-
tion (3), Equation (6) can be rewriten as:
e?s = argmax
es,a
{
M
?
m=1
?mhm(e,a, f)
}
(7)
547
which is the approach that we follow in this work.
A common problem in IMT arises when the user
sets a prefix (ep) which cannot be found in the
phrase-based statistical translation model. Differ-
ent solutions have been proposed to deal with this
problem. The use of word translation graphs, as a
compact representation of all possible translations
of a source sentence, is proposed in (Barrachina
et al, 2009). In (Ortiz-Mart??nez et al, 2009), a
technique based on the generation of partial phrase-
based alignments is described. This last proposal has
also been adopted in this work.
3 Related work
In this paper we present an application of the online
learning paradigm to the IMT framework. In the on-
line learning setting, models are trained sample by
sample. Our work is also related to model adapta-
tion, although model adaptation and online learning
are not exactly the same thing.
The online learning paradigm has been previ-
ously applied to train discriminative models in
SMT (Liang et al, 2006; Arun and Koehn, 2007;
Watanabe et al, 2007; Chiang et al, 2008). These
works differ from the one presented here in that we
apply online learning techniques to train generative
models instead of discriminative models.
In (Nepveu et al, 2004), dynamic adaptation of
an IMT system via cache-based model extensions to
language and translation models is proposed. The
work by Nepveu et al (2004) constitutes a domain
adaptation technique and not an online learning
technique, since the proposed cache components re-
quire pre-existent models estimated in batch mode.
In addition to this, their IMT system does not use
state-of-the-art models.
To our knowledge, the only previous work on on-
line learning for IMT is (Cesa-Bianchi et al, 2008),
where a very constrained version of online learn-
ing is presented. This constrained version of online
learning is not able to extend the translation models
due to technical problems with the efficiency of the
learning process. In this paper, we present a purely
statistical IMT systemwhich is able to incrementally
update the parameters of all of the different models
that are used in the system, including the transla-
tion model, breaking with the above mentioned con-
straints. What is more, our system is able to learn
from scratch, that is, without any preexisting model
stored in the system. This is demonstrated empiri-
cally in section 5.
4 Online IMT
In this section we propose an online IMT system.
First, we describe the basic IMT system involved
in the interactive translation process. Then we in-
troduce the required techniques to incrementally up-
date the statistical models used by the system.
4.1 Basic IMT system
The basic IMT system that we propose uses a log-
linear model to generate its translations. According
to Equation (7), we introduce a set of seven feature
functions (from h1 to h7):
? n-gram language model (h1)
h1(e) = log(
?|e|+1
i=1 p(ei|ei?1i?n+1)), 1 where
p(ei|ei?1i?n+1) is defined as follows:
p(ei|ei?1i?n+1) =
max{cX(eii?n+1)?Dn, 0}
cX(ei?1i?n+1)
+
Dn
cX(ei?1i?n+1)
N1+(ei?1i?n+1?) ? p(ei|ei?1i?n+2) (8)
where Dn = cn,1cn,1+2cn,2 is a fixed discount (cn,1
and cn,2 are the number of n-grams with one
and two counts respectively),N1+(ei?1i?n+1?) is the
number of unique words that follows the history
ei?1i?n+1 and cX(eii?n+1) is the count of the n-gram
eii?n+1, where cX(?) can represent true counts
cT (?) or modified counts cM (?). True counts are
used for the higher order n-grams and modified
counts for the lower order n-grams. Given a cer-
tain n-gram, its modified count consists in the
number of different words that precede this n-
gram in the training corpus.
Equation (8) corresponds to the probability given
by an n-gram language model with an interpolated
version of the Kneser-Ney smoothing (Chen and
Goodman, 1996).
1|e| is the length of e, e0 denotes the begin-of-sentence sym-
bol, e|e|+1 denotes the end-of-sentence symbol, e
j
i ? ei...ej
548
? target sentence-length model (h2)
h2(e, f) = log(p(|f | | |e|)) = log(?|e|(|f |+0.5)?
?|e|(|f | ? 0.5)), where ?|e|(?) denotes the cumula-
tive distribution function (cdf) for the normal dis-
tribution (the cdf is used here to integrate the nor-
mal density function over an interval of length 1).
We use a specific normal distribution with mean
?|e| and standard deviation ?|e| for each possible
target sentence length |e|.
? inverse and direct phrase-based models (h3, h4)
h3(e,a, f) = log(
?K
k=1 p(f?k|e?a?k)), where
p(f?k|e?a?k) is defined as follows:
p(f?k|e?a?k) = ? ? pphr(f?k|e?a?k) +
(1? ?).phmm(f?k|e?a?k) (9)
In Equation (9), pphr(f?k|e?a?k) denotes the proba-
bility given by a statistical phrase-based dictionary
used in regular phrase-based models (see (Koehn
et al, 2003) for more details). phmm(f?k|e?a?k) is
the probability given by an HMM-based (intra-
phrase) alignment model (see (Vogel et al, 1996)):
phmm(f? |e?) = ?
?
a|f? |1
|f? |
?
j=1
p(f?j |e?aj ) ? p(aj |aj?1, |e?|)
(10)
The HMM-based alignment model probability is
used here for smoothing purposes as described
in (Ortiz-Mart??nez et al, 2009).
Analogously h4 is defined as:
h4(e,a, f) = log(
?K
k=1 p(e?a?k |f?k))
? target phrase-length model (h5)
h5(e,a, f) = log(
?K
k=1 p(|e?k|)), where p(|e?k|) =
?(1? ?)|e?k|. h5 implements a target phrase-length
model by means of a geometric distribution with
probability of success on each trial ?. The use of a
geometric distribution penalizes the length of tar-
get phrases.
? source phrase-length model (h6)
h6(e,a, f) = log(
?K
k=1 p(|f?k| | |e?a?k |)),
where p(|f?k| | |e?a?k |) = ?(1? ?)abs(|f?k|?|e?a?k |) and
abs(?) is the absolute value function. A geometric
distribution is used to model this feature (it penal-
izes the difference between the source and target
phrase lengths).
? distortion model (h7)
h7(a) = log(
?K
k=1 p(a?k|a?k?1)), where
p(a?k|a?k?1) = ?(1 ? ?)abs(ba?k?la?k?1 ), ba?k
denotes the beginning position of the source
phrase covered by a?k and la?k?1 denotes the last
position of the source phrase covered by a?k?1.
A geometric distribution is used to model this
feature (it penalizes the reorderings).
The log-linear model, which includes the above
described feature functions, is used to generate the
suffix es given the user-validated prefix ep. Specif-
ically, the IMT system generates a partial phrase-
based alignment between the user prefix ep and a
portion of the source sentence f , and returns the suf-
fix es as the translation of the remaining portion of
f (see (Ortiz-Mart??nez et al, 2009)).
4.2 Extending the IMT system from user
feedback
After translating a source sentence f , a new sen-
tence pair (f , e) is available to feed the IMT system
(see Figure 1). In this section we describe how the
log-linear model described in section 4.1 is updated
given the new sentence pair. To do this, a set of suf-
ficient statistics that can be incrementally updated is
maintained for each feature function hi(?). A suffi-
cient statistic for a statistical model is a statistic that
captures all the information that is relevant to esti-
mate this model.
Regarding feature function h1 and according to
equation (8), we need to maintain the following data:
ck,1 and ck,2 given any order k, N1+(?), and cX(?)
(see section 4.1 for the meaning of each symbol).
Given a new sentence e, and for each k-gram eii?k+1
of e where 1 ? k ? n and 1 ? i ? |e|+1, we mod-
ify the set of sufficient statistics as it is shown in Al-
gorithm 1. The algorithm checks the changes in the
counts of the k-grams to update the set of sufficient
statistics. Sufficient statistics forDk are updated fol-
lowing the auxiliar procedure shown in Algorithm 2.
Feature function h2 requires the incremental cal-
culation of the mean ?|e| and the standard deviation
?|e| of the normal distribution associated to a target
sentence length |e|. For this purpose the procedure
described in (Knuth, 1981) can be used. In this pro-
cedure, two quantities are maintained for each nor-
mal distribution: ?|e| and S|e|. Given a new sentence
549
input : n (higher order), eii?k+1 (k-gram),
S = {?j(cj,1, cj,2), N1+(?), cX(?)}
(current set of sufficient statistics)
output : S (updated set of sufficient statistics)
begin
if cT (eii?k+1) = 0 then
if k ? 1 ? 1 then
updD(S,k-1,cM (ei?1i?k+2),cM (ei?1i?k+2)+1)
if cM (ei?1i?k+2) = 0 then
N1+(ei?1i?k+2) = N1+(ei?1i?k+2) + 1
cM (ei?1i?k+2) = cM (ei?1i?k+2) + 1
cM (eii?k+2) = cM (eii?k+2) + 1
if k = n then
N1+(ei?1i?k+1) = N1+(ei?1i?k+1) + 1
if k = n then
updD(S,k,cT (eii?k+1),cT (eii?k+1) + 1)
cT (ei?1i?k+1)=cT (ei?1i?k+1) + 1
cT (eii?k+1)=cT (eii?k+1) + 1
end
Algorithm 1: Pseudocode for updating the suf-
ficient statistics of a given k-gram
input : S (current set of sufficient statistics),k
(order), c (current count), c? (new count)
output : (ck,1, ck,2) (updated sufficient statistics)
begin
if c = 0 then
if c? = 1 then ck,1 = ck,1 + 1
if c? = 2 then ck,2 = ck,2 + 1
if c = 1 then
ck,1 = ck,1 ? 1
if c? = 2 then ck,2 = ck,2 + 1
if c = 2 then ck,2 = ck,2 ? 1
end
Algorithm 2: Pseudocode for the updD proce-
dure
pair (f , e), the two quantities are updated using a re-
currence relation:
?|e| = ?
?
|e| + (|f | ? ?
?
|e|)/c(|e|) (11)
S|e| = S
?
|e| + (|f | ? ?
?
|e|)(|f | ? ?|e|) (12)
where c(|e|) is the count of the number of sentences
of length |e| that have been seen so far, and ??|e| and
S?|e| are the quantities previously stored (?|e| is ini-
tialized to the source sentence length of the first sam-
ple and S|e| is initialized to zero). Finally, the stan-
dard deviation can be obtained from S as follows:
?|e| =
?
S|e|/(c(|e|)? 1).
Feature functions h3 and h4 implement inverse
and direct smoothed phrase-based models respec-
tively. Since phrase-based models are symmetric
models, only an inverse phrase-based model is main-
tained (direct probabilities can be efficiently ob-
tained using appropriate data structures, see (Ortiz-
Mart??nez et al, 2008)). The inverse phrase model
probabilities are estimated from the phrase counts:
p(f? |e?) = c(f? , e?)
?
f? ? c(f? ?, e?)
(13)
According to Equation (13), the set of suffi-
cient statistics to be stored for the inverse phrase
model consists of a set of phrase counts (c(f? , e?) and
?
f? ? c(f? ?, e?) must be stored separately). Given a
new sentence pair (f , e), the standard phrase-based
model estimation method uses a word alignment ma-
trix between f and e to extract the set of phrase pairs
that are consistent with the word alignment ma-
trix (see (Koehn et al, 2003) for more details). Once
the consistent phrase pairs have been extracted, the
phrase counts are updated. The word alignment ma-
trices required for the extraction of phrase pairs are
generated by means of the HMM-based models used
in the feature functions h3 and h4.
Inverse and direct HMM-based models are used
here for two purposes: to smooth the phrase-based
models via linear interpolation and to generate word
alignment matrices. The weights of the interpola-
tion can be estimated from a development corpus.
Equation (10) shows the expression of the probabil-
ity given by an inverse HMM-based model. The
probability includes lexical probabilities p(fj |ei)
and alignment probabilities p(aj |aj?1, l). Since the
alignment in the HMM-based model is determined
by a hidden variable, the EM algorithm is required
to estimate the parameters of the model (see (Och
and Ney, 2003)). However, the standard EM algo-
rithm is not appropriate to incrementally extend our
HMM-based models because it is designed to work
in batch training scenarios. To solve this problem,
we apply the incremental view of the EM algorithm
described in (Neal and Hinton, 1998). According
to (Och and Ney, 2003), the lexical probability for a
550
pair of words is given by the expression:
p(f |e) = c(f |e)?
f ? c(f ?|e)
(14)
where c(f |e) is the expected number of times that
the word e is aligned to the word f . The alignment
probability is defined in a similar way:
p(aj |aj?1, l) =
c(aj |aj?1, l)
?
a?j
c(a?j |aj?1, l)
(15)
where c(aj |aj?1, l) denotes the expected number of
times that the alignment aj has been seen after the
previous alignment aj?1 given a source sentence
composed of l words.
Given the equations (14) and (15), the set of suf-
ficient statistics for the inverse HMM-based model
consists of a set of expected counts (numerator and
denominator values are stored separately). Given a
new sentence pair (f , e), we execute a new iteration
of the incremental EM algorithm on the new sample
and collect the contributions to the expected counts.
The parameters of the direct HMM-based model
are estimated analogously to those of the inverse
HMM-based model. Once the direct and the inverse
HMM-based model parameters have been modified
due to the presentation of a new sentence pair to the
IMT system, both models are used to obtain word
alignments for the new sentence pair. The resulting
direct and inverse word alignment matrices are com-
bined by means of the symmetrization alignment op-
eration (Och and Ney, 2003) before extracting the
set of consistent phrase pairs.
HMM-based alignment models are used here
because, according to (Och and Ney, 2003)
and (Toutanova et al, 2002), they outperform IBM 1
to IBM 4 alignment models while still allowing the
exact calculation of the likelihood for a given sen-
tence pair.
The ? parameters of the geometric distributions
associated to the feature functions h5, h6 and h7 are
left fixed. Because of this, there are no sufficient
statistics to store for these feature functions.
Finally, the weights of the log-linear combination
are not modified due to the presentation of a new
sentence pair to the system. These weights can be
adjusted off-line by means of a development corpus
and well-known optimization techniques.
5 Experiments
This section describes the experiments that we car-
ried out to test our online IMT system.
5.1 Experimental setup
The experiments were performed using the XE-
ROX XRCE corpus (SchlumbergerSema S.A. et
al., 2001), which consists of translations of Xe-
rox printer manuals involving three different pairs
of languages: French-English, Spanish-English, and
German-English. The main features of these cor-
pora are shown in Table 1. Partitions into training,
development and test were performed. This corpus
is used here because it has been extensively used in
the literature on IMT to report results.
IMT experiments were carried out from English
to the other three languages.
5.2 Assessment criteria
The evaluation of the techniques presented in this
paper were carried out using the Key-stroke and
mouse-action ratio (KSMR) measure (Barrachina
et al, 2009). This is calculated as the number of
keystrokes plus the number of mouse movements
plus one more count per sentence (aimed at simulat-
ing the user action needed to accept the final transla-
tion), the sum of which is divided by the total num-
ber of reference characters. In addition to this, we
also used the well-known BLEU score (Papineni et
al., 2001) to measure the translation quality of the
first translation hypothesis produced by the IMT sys-
tem for each source sentence (which is automatically
generated without user intervention).
5.3 Online IMT results
To test the techniques proposed in this work, we
carried out experiments in two different scenarios.
In the first one, the first 10 000 sentences extracted
from the training corpora were interactively trans-
lated by means of an IMT system without any pre-
existent model stored in memory. Each time a new
sentence pair was validated, it was used to incremen-
tally train the system. Figures 3a, 3b and 3c show the
evolution of the KSMR with respect to the number
of sentence pairs processed by the IMT system; the
results correspond to the translation from English to
Spanish, French and German, respectively. In addi-
551
En Sp En Fr En Ge
Train
Sent. pairs 55761 52844 49376
Running words 571960 657172 542762 573170 506877 440682
Vocabulary 25627 29565 24958 27399 24899 37338
Dev.
Sent. pairs 1012 994 964
Running words 12111 13808 9480 9801 9162 8283
Perplexity (3-grams) 46.2 34.0 96.2 74.1 68.4 124.3
Sent. pairs 1125 984 996
Test
Running words 7634 9358 9572 9805 10792 9823
Perplexity (3-grams) 107.0 59.6 192.6 135.4 92.8 169.2
Table 1: XEROX corpus statistics for three different language pairs (from English (En) to Spanish (Sp),
French (Fr) and German (Ge))
tion, for each language pair we interactively trans-
lated the original portion of the training corpus and
the same portion of the original corpus after being
randomly shuffled.
As these figures show, the results clearly demon-
strate that the IMT system is able to learn from
scratch. The results were similar for the three lan-
guages. It is also worthy of note that the obtained
results were better in all cases for the original cor-
pora than for the shuffled ones. This is because,
in the original corpora, similar sentences appear
more or less contiguosly (due to the organization of
the contents of the printer manuals). This circum-
stance increases the accuracy of the online learning,
since with the original corpora the number of lat-
eral effects ocurred between the translation of sim-
ilar sentences is decreased. The online learning of
a new sentence pair produces a lateral effect when
the changes in the probability given by the models
not only affect the newly trained sentence pair but
also other sentence pairs. A lateral effect can cause
that the system generates a wrong translation for a
given source sentence due to undesired changes in
the statistical models.
The accuracy were worse for shuffled corpora,
since shuffling increases the number of lateral ef-
fects that may occur between the translation of sim-
ilar sentences (because they no longer appear con-
tiguously). A good way to compare the quality of
different online IMT systems is to determine their
robustness in relation to sentence ordering. How-
ever, it can generally be expected that the sentences
to be translated in an interactive translation session
will be in a non-random order.
Alternatively, we carried out experiments in a dif-
ferent learning scenario. Specifically, the XEROX
 30
 40
 50
 60
 70
 80
 90
 100
 0  1000  2000  3000  4000  5000  6000  7000  8000  9000 10000
K
SM
R
#Sentences
original
shuffled
(a) English-Spanish
 40
 50
 60
 70
 80
 90
 100
 0  1000  2000  3000  4000  5000  6000  7000  8000  9000 10000
K
SM
R
#Sentences
original
shuffled
(b) English-French
 40
 50
 60
 70
 80
 90
 100
 0  1000  2000  3000  4000  5000  6000  7000  8000  9000 10000
K
SM
R
#Sentences
original
shuffled
(c) English-German
Figure 3: KSMR evolution translating a portion of
the training corpora
test corpora were interactively translated from the
English language to the other three languages, com-
paring the performance of a batch IMT system with
552
that of an online IMT system. The batch IMT sys-
tem is a conventional IMT system which is not able
to take advantage of user feedback after each transla-
tion while the online IMT system uses the new sen-
tence pairs provided by the user to revise the sta-
tistical models. Both systems were initialized with
a log-linear model trained in batch mode by means
of the XEROX training corpora. The weights of the
log-linear combination were adjusted for the devel-
opment corpora by means of the downhill-simplex
algorithm. Table 2 shows the obtained results. The
table shows the BLEU score and the KSMR for the
batch and the online IMT systems (95% confidence
intervals are shown). The BLEU score was calcu-
lated from the first translation hypothesis produced
by the IMT system for each source sentence. The ta-
ble also shows the average online learning time (LT)
for each new sample presented to the system2. All
the improvements obtained with the online IMT sys-
tem were statistically significant. Also, the average
learning times clearly allow the system to be used in
a real-time scenario.
IMT system BLEU KSMR LT (s)
En-Sp
batch 55.1? 2.3 18.2? 1.1 -
online 60.6? 2.3 15.8? 1.0 0.04
En-Fr
batch 33.7? 2.0 33.9? 1.3 -
online 42.2? 2.2 27.9? 1.3 0.09
En-Ge
batch 20.4? 1.8 40.3? 1.2 -
online 28.0? 2.0 35.0? 1.3 0.07
Table 2: BLEU and KSMR results for the XEROX
test corpora using the batch and the online IMT sys-
tems. The average online learning time (LT) in sec-
onds is shown for the online system
Finally, in Table 3 a comparison of the KSMR re-
sults obtained by the online IMT system with state-
of-the-art IMT systems is reported (95% confidence
intervals are shown). We compared our system with
those presented in (Barrachina et al, 2009): the
alignment templates (AT), the stochastic finite-state
transducer (SFST), and the phrase-based (PB) ap-
proaches to IMT. The results were obtained using
the same Xerox training and test sets (see Table 1)
for the four different IMT systems. Our system out-
performed the results obtained by these systems.
2All the experiments were executed on a PC with a 2.40 Ghz
Intel Xeon processor with 1GB of memory.
AT PB SFST Online
En-Sp 23.2?1.3 16.7?1.2 21.8?1.4 15.8? 1.0
En-Fr 40.4?1.4 35.8?1.3 43.8?1.6 27.9? 1.3
En-Ge 44.7?1.2 40.1?1.2 45.7?1.4 35.0? 1.3
Table 3: KSMR results comparison of our system
and three different state-of-the-art batch systems
6 Conclusions
We have presented an online IMT system. The pro-
posed system is able to incrementally extend the sta-
tistical models involved in the translation process,
breaking technical limitations encountered in other
works. Empirical results show that our techniques
allow the IMT system to learn from scratch or from
previously estimated models.
One key aspect of the proposed system is the use
of HMM-based alignment models trained by means
of the incremental EM algorithm.
The incremental adjustment of the weights of the
log-linear models and other parameters have not
been tackled here. For the future we plan to incor-
porate this functionality into our IMT system.
The incremental techniques proposed here can
also be exploited to extend SMT systems (in fact,
our proposed IMT system is based on an incremen-
tally updateable SMT system). For the near future
we plan to study possible aplications of our tech-
niques in a fully automatic translation scenario.
Finally, it is worthy of note that the main ideas
presented here can be used in other interactive ap-
plications such as Computer Assisted Speech Tran-
scription, Interactive Image Retrieval, etc (see (Vi-
dal et al, 2007) for more information). In conclu-
sion, we think that the online learning techniques
proposed here can be the starting point for a new
generation of interactive pattern recognition systems
that are able to take advantage of user feedback.
Acknowledgments
Work supported by the EC (FEDER/FSE), the
Spanish Government (MEC, MICINN, MITyC,
MAEC, ?Plan E?, under grants MIPRCV ?Con-
solider Ingenio 2010? CSD2007-00018, iTrans2
TIN2009-14511, erudito.com TSI-020110-2009-
439), the Generalitat Valenciana (grant Prome-
teo/2009/014), the Univ. Polite?cnica de Valencia
(grant 20091027) and the Spanish JCCM (grant
PBI08-0210-7127).
553
References
A. Arun and P. Koehn. 2007. Online learning methods
for discriminative training of phrase based statistical
machine translation. In Proc. of the MT Summit XI,
pages 15?20, Copenhagen, Denmark, September.
S. Barrachina, O. Bender, F. Casacuberta, J. Civera,
E. Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Toma?s,
and E. Vidal. 2009. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, 35(1):3?28.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and R. L. Mercer. 1993. The mathematics of
statistical machine translation: Parameter estimation.
Computational Linguistics, 19(2):263?311.
N. Cesa-Bianchi, G. Reverberi, and S. Szedmak. 2008.
Online learning algorithms for computer-assisted
translation. Deliverable D4.2, SMART: Stat. Multi-
lingual Analysis for Retrieval and Translation, Mar.
S.F. Chen and J. Goodman. 1996. An empirical study of
smoothing techniques for language modeling. In Proc.
of the ACL, pages 310?318, San Francisco.
D. Chiang, Y. Marton, and P. Resnik. 2008. Online large-
margin training of syntactic and structural translation
features. In Proc. of EMNLP.
George Foster, Pierre Isabelle, and Pierre Plamondon.
1997. Target-text mediated interactive machine trans-
lation. Machine Translation, 12(1):175?194.
P. Isabelle and K. Church. 1997. Special issue on
new tools for human translators. Machine Translation,
12(1?2).
D.E. Knuth. 1981. Seminumerical Algorithms, volume 2
of The Art of Computer Programming. Addison-
Wesley, Massachusetts, 2nd edition.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. of the HLT/NAACL,
pages 48?54, Edmonton, Canada, May.
P. Langlais, G. Lapalme, and M. Loranger. 2002.
Transtype: Development-evaluation cycles to boost
translator?s productivity. Machine Translation,
15(4):77?98.
P. Liang, A. Bouchard-Co?te?, D. Klein, and B. Taskar.
2006. An end-to-end discriminative approach to ma-
chine translation. In Proc. of the 44th ACL, pages 761?
768, Morristown, NJ, USA.
R.M. Neal and G.E. Hinton. 1998. A view of the EM
algorithm that justifies incremental, sparse, and other
variants. In Proceedings of the NATO-ASI on Learning
in graphical models, pages 355?368, Norwell, MA,
USA.
L. Nepveu, G. Lapalme, P. Langlais, and G. Foster. 2004.
Adaptive language and translation models for interac-
tive machine translation. In Proc. of EMNLP, pages
190?197, Barcelona, Spain, July.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive Training and Maximum Entropy Models for Sta-
tistical Machine Translation. In Proc. of the 40th ACL,
pages 295?302, Philadelphia, PA, July.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51, March.
D. Ortiz-Mart??nez, I. Garc??a-Varea, and Casacuberta F.
2008. The scaling problem in the pattern recognition
approach to machine translation. Pattern Recognition
Letters, 29:1145?1153.
Daniel Ortiz-Mart??nez, Ismael Garc??a-Varea, and Fran-
cisco Casacuberta. 2009. Interactive machine trans-
lation based on partial statistical phrase-based align-
ments. In Proc. of RANLP, Borovets, Bulgaria, sep.
Kishore A. Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2001. Bleu: a method for auto-
matic evaluation of machine translation. Technical
Report RC22176 (W0109-022), IBM Research Divi-
sion, Thomas J. Watson Research Center, Yorktown
Heights, NY, September.
SchlumbergerSema S.A., ITI Valencia, RWTH Aachen,
RALI Montreal, Celer Soluciones, Socie?te? Gamma,
and XRCE. 2001. TT2. TransType2 - computer as-
sisted translation. Project Tech. Rep.
Kristina Toutanova, H. Tolga Ilhan, and Christopher
Manning. 2002. Extensions to hmm-based statistical
word alignment models. In Proc. of EMNLP.
E. Vidal, L. Rodr??guez, F. Casacuberta, and I. Garc??a-
Varea. 2007. Interactive pattern recognition. In Proc.
of the 4th MLMI, pages 60?71. Brno, Czech Republic,
28-30 June.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proc. of COLING, pages 836?841, Copen-
hagen, Denmark, August.
T. Watanabe, J. Suzuki, H. Tsukada, and H. Isozaki.
2007. Online large-margin training for statistical ma-
chine translation. In Proc. of EMNLP and CoNLL,
pages 764?733, Prage, Czeck Republic.
554
Proceedings of the ACL 2010 Conference Short Papers, pages 173?177,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Balancing User Effort and Translation Error in Interactive Machine
Translation Via Confidence Measures
Jesu?s Gonza?lez-Rubio
Inst. Tec. de Informa?tica
Univ. Polite?c. de Valencia
46021 Valencia, Spain
jegonzalez@iti.upv.es
Daniel Ortiz-Mart??nez
Dpto. de Sist Inf. y Comp.
Univ. Polite?c. de Valencia
46021 Valencia, Spain
dortiz@dsic.upv.es
Francisco Casacuberta
Dpto. de Sist Inf. y Comp.
Univ. Polite?c. de Valencia
46021 Valencia, Spain
fcn@dsic.upv.es
Abstract
This work deals with the application of
confidence measures within an interactive-
predictive machine translation system in
order to reduce human effort. If a small
loss in translation quality can be tolerated
for the sake of efficiency, user effort can
be saved by interactively translating only
those initial translations which the confi-
dence measure classifies as incorrect. We
apply confidence estimation as a way to
achieve a balance between user effort sav-
ings and final translation error. Empiri-
cal results show that our proposal allows
to obtain almost perfect translations while
significantly reducing user effort.
1 Introduction
In Statistical Machine Translation (SMT), the
translation is modelled as a decission process. For
a given source string fJ1 = f1 . . . fj . . . fJ , we
seek for the target string eI1 = e1 . . . ei . . . eI
which maximises posterior probability:
e?I?1 = argmax
I,eI1
Pr(eI1|fJ1 ) . (1)
Within the Interactive-predictive Machine
Translation (IMT) framework, a state-of-the-art
SMT system is employed in the following way:
For a given source sentence, the SMT system
fully automatically generates an initial translation.
A human translator checks this translation from
left to right, correcting the first error. The SMT
system then proposes a new extension, taking the
correct prefix ei1 = e1 . . . ei into account. These
steps are repeated until the whole input sentence
has been correctly translated. In the resulting
decision rule, we maximise over all possible
extensions eIi+1 of ei1:
e?I?i+1 = argmax
I,eIi+1
Pr(eIi+1|ei1, fJ1 ) . (2)
An implementation of the IMT famework was
performed in the TransType project (Foster et al,
1997; Langlais et al, 2002) and further improved
within the TransType2 project (Esteban et al,
2004; Barrachina et al, 2009).
IMT aims at reducing the effort and increas-
ing the productivity of translators, while preserv-
ing high-quality translation. In this work, we inte-
grate Confidence Measures (CMs) within the IMT
framework to further reduce the user effort. As
will be shown, our proposal allows to balance the
ratio between user effort and final translation error.
1.1 Confidence Measures
Confidence estimation have been extensively stud-
ied for speech recognition. Only recently have re-
searchers started to investigate CMs for MT (Gan-
drabur and Foster, 2003; Blatz et al, 2004; Ueffing
and Ney, 2007).
Different TransType-style MT systems use con-
fidence information to improve translation predic-
tion accuracy (Gandrabur and Foster, 2003; Ueff-
ing and Ney, 2005). In this work, we propose a fo-
cus shift in which CMs are used to modify the in-
teraction between the user and the system instead
of modify the IMT translation predictions.
To compute CMs we have to select suitable con-
fidence features and define a binary classifier. Typ-
ically, the classification is carried out depending
on whether the confidence value exceeds a given
threshold or not.
2 IMT with Sentence CMs
In the conventional IMT scenario a human trans-
lator and a SMT system collaborate in order to
obtain the translation the user has in mind. Once
the user has interactively translated the source sen-
tences, the output translations are error-free. We
propose an alternative scenario where not all the
source sentences are interactively translated by the
user. Specifically, only those source sentences
173
whose initial fully automatic translation are incor-
rect, according to some quality criterion, are in-
teractively translated. We propose to use CMs as
the quality criterion to classify those initial trans-
lations.
Our approach implies a modification of the
user-machine interaction protocol. For a given
source sentence, the SMT system generates an ini-
tial translation. Then, if the CM classifies this
translation as correct, we output it as our final
translation. On the contrary, if the initial trans-
lation is classified as incorrect, we perform a con-
ventional IMT procedure, validating correct pre-
fixes and generating new suffixes, until the sen-
tence that the user has in mind is reached.
In our scenario, we allow the final translations
to be different from the ones the user has in mind.
This implies that the output may contain errors.
If a small loss in translation can be tolerated for
the sake of efficiency, user effort can be saved by
interactively translating only those sentences that
the CMs classify as incorrect.
It is worth of notice that our proposal can be
seen as a generalisation of the conventional IMT
approach. Varying the value of the CM classifi-
cation threshold, we can range from a fully auto-
matic SMT system where all sentences are clas-
sified as correct to a conventional IMT system
where all sentences are classified as incorrect.
2.1 Selecting a CM for IMT
We compute sentence CMs by combining the
scores given by a word CM based on the IBM
model 1 (Brown et al, 1993), similar to the one
described in (Blatz et al, 2004). We modified this
word CM by replacing the average by the max-
imal lexicon probability, because the average is
dominated by this maximum (Ueffing and Ney,
2005). We choose this word CM because it can be
calculated very fast during search, which is cru-
cial given the time constraints of the IMT sys-
tems. Moreover, its performance is similar to that
of other word CMs as results presented in (Blatz
et al, 2003; Blatz et al, 2004) show. The word
confidence value of word ei, cw(ei), is given by
cw(ei) = max
0?j?J
p(ei|fj) , (3)
where p(ei|fj) is the IBM model 1 lexicon proba-
bility, and f0 is the empty source word.
From this word CM, we compute two sentence
CMs which differ in the way the word confidence
Spanish English
Tr
a
in Sentences 214.5K
Running words 5.8M 5.2M
Vocabulary 97.4K 83.7K
D
ev
. Sentences 400
Running words 11.5K 10.1K
Perplexity (trigrams) 46.1 59.4
Te
st
Sentences 800
Running words 22.6K 19.9K
Perplexity (trigrams) 45.2 60.8
Table 1: Statistics of the Spanish?English EU cor-
pora. K and M denote thousands and millions of
elements respectively.
scores cw(ei) are combined:
MEAN CM (cM (eI1)) is computed as the geo-
metric mean of the confidence scores of the
words in the sentence:
cM (eI1) =
I
?
?
?
?
I
?
i=1
cw(ei) . (4)
RATIO CM (cR(eI1)) is computed as the percent-
age of words classified as correct in the sen-
tence. A word is classified as correct if
its confidence exceeds a word classification
threshold ?w.
cR(eI1) =
|{ei / cw(ei) > ?w}|
I
(5)
After computing the confidence value, each sen-
tence is classified as either correct or incorrect, de-
pending on whether its confidence value exceeds
or not a sentence clasiffication threshold ?s. If
?s = 0.0 then all the sentences will be classified
as correct whereas if ?s = 1.0 all the sentences
will be classified as incorrect.
3 Experimentation
The aim of the experimentation was to study the
possibly trade-off between saved user effort and
translation error obtained when using sentence
CMs within the IMT framework.
3.1 System evaluation
In this paper, we report our results as measured
by Word Stroke Ratio (WSR) (Barrachina et al,
2009). WSR is used in the context of IMT to mea-
sure the effort required by the user to generate her
174
 0
 20
 40
 60
 80
 100
 0  0.2  0.4  0.6  0.8  1
 0
 20
 40
 60
 80
 100
W
SR
BL
EU
Threshold (?s)
WSR IMT-CM
BLEU IMT-CM
WSR IMT
BLEU SMT
Figure 1: BLEU translation scores versus WSR
for different values of the sentence classification
threshold using the MEAN CM.
translations. WSR is computed as the ratio be-
tween the number of word-strokes a user would
need to achieve the translation she has in mind and
the total number of words in the sentence. In this
context, a word-stroke is interpreted as a single ac-
tion, in which the user types a complete word, and
is assumed to have constant cost.
Additionally, and because our proposal allows
differences between its output and the reference
translation, we will also present translation qual-
ity results in terms of BiLingual Evaluation Un-
derstudy (BLEU) (Papineni et al, 2002). BLEU
computes a geometric mean of the precision of n-
grams multiplied by a factor to penalise short sen-
tences.
3.2 Experimental Setup
Our experiments were carried out on the EU cor-
pora (Barrachina et al, 2009). The EU corpora
were extracted from the Bulletin of the European
Union. The EU corpora is composed of sentences
given in three different language pairs. Here, we
will focus on the Spanish?English part of the EU
corpora. The corpus is divided into training, de-
velopment and test sets. The main figures of the
corpus can be seen in Table 1.
As a first step, be built a SMT system to trans-
late from Spanish into English. This was done
by means of the Thot toolkit (Ortiz et al, 2005),
which is a complete system for building phrase-
based SMT models. This toolkit involves the esti-
mation, from the training set, of different statisti-
cal models, which are in turn combined in a log-
linear fashion by adjusting a weight for each of
them by means of the MERT (Och, 2003) proce-
 0
 20
 40
 60
 80
 100
 0  0.2  0.4  0.6  0.8  1
 0
 20
 40
 60
 80
 100
W
SR
BL
EU
Threshold (?s)
WSR IMT-CM (?w=0.4)
BLEU IMT-CM (?w=0.4)
WSR IMT
BLEU SMT
Figure 2: BLEU translation scores versus WSR
for different values of the sentence classification
threshold using the RATIO CM with ?w = 0.4.
dure, optimising the BLEU score on the develop-
ment set.
The IMT system which we have implemented
relies on the use of word graphs (Ueffing et al,
2002) to efficiently compute the suffix for a given
prefix. A word graph has to be generated for each
sentence to be interactively translated. For this
purpose, we used a multi-stack phrase-based de-
coder which will be distributed in the near future
together with the Thot toolkit. We discarded to
use the state-of-the-art Moses toolkit (Koehn et
al., 2007) because preliminary experiments per-
formed with it revealed that the decoder by Ortiz-
Mart??nez et al (2005) performs better in terms of
WSR when used to generate word graphs for their
use in IMT (Sanchis-Trilles et al, 2008). More-
over, the performance difference in regular SMT is
negligible. The decoder was set to only consider
monotonic translation, since in real IMT scenar-
ios considering non-monotonic translation leads to
excessive response time for the user.
Finally, the obtained word graphs were used
within the IMT procedure to produce the refer-
ence translations in the test set, measuring WSR
and BLEU.
3.3 Results
We carried out a series of experiments ranging the
value of the sentence classification threshold ?s,
between 0.0 (equivalent to a fully automatic SMT
system) and 1.0 (equivalent to a conventional IMT
system), for both the MEAN and RATIO CMs.
For each threshold value, we calculated the effort
of the user in terms of WSR, and the translation
quality of the final output as measured by BLEU.
175
src-1 DECLARACI ?ON (No 17) relativa al derecho de acceso a la informacio?n
ref-1 DECLARATION (No 17) on the right of access to information
tra-1 DECLARATION (No 17) on the right of access to information
src-2 Conclusiones del Consejo sobre el comercio electro?nico y los impuestos indirectos.
ref-2 Council conclusions on electronic commerce and indirect taxation.
tra-2 Council conclusions on e-commerce and indirect taxation.
src-3 participacio?n de los pa??ses candidatos en los programas comunitarios.
ref-3 participation of the applicant countries in Community programmes.
tra-3 countries? involvement in Community programmes.
Example 1: Examples of initial fully automatically generated sentences classified as correct by the CMs.
Figure 1 shows WSR (WSR IMT-CM) and
BLEU (BLEU IMT-CM) scores obtained varying
?s for the MEAN CM. Additionally, we also show
the BLEU score (BLEU SMT) obtained by a fully
automatic SMT system as translation quality base-
line, and the WSR score (WSR IMT) obtained by
a conventional IMT system as user effort baseline.
This figure shows a continuous transition between
the fully automatic SMT system and the conven-
tional IMT system. This transition occurs when
ranging ?s between 0.0 and 0.6. This is an unde-
sired effect, since for almost a half of the possible
values for ?s there is no change in the behaviour
of our proposed IMT system.
The RATIO CM confidence values depend on
a word classification threshold ?w. We have car-
ried out experimentation ranging ?w between 0.0
and 1.0 and found that this value can be used to
solve the above mentioned undesired effect for
the MEAN CM. Specifically, varying the value of
?w we can stretch the interval in which the tran-
sition between the fully automatic SMT system
and the conventional IMT system is produced, al-
lowing us to obtain smother transitions. Figure 2
shows WSR and BLEU scores for different val-
ues of the sentence classification threshold ?s us-
ing ?w = 0.4. We show results only for this value
of ?w due to paper space limitations and because
?w = 0.4 produced the smoothest transition. Ac-
cording to Figure 2, using a sentence classification
threshold value of 0.6 we obtain a WSR reduction
of 20% relative and an almost perfect translation
quality of 87 BLEU points.
It is worth of notice that the final translations
are compared with only one reference, therefore,
the reported translation quality scores are clearly
pessimistic. Better results are expected using a
multi-reference corpus. Example 1 shows the
source sentence (src), the reference translation
(ref) and the final translation (tra) for three of the
initial fully automatically generated translations
that were classified as correct by our CMs, and
thus, were not interactively translated by the user.
The first translation (tra-1) is identical to the corre-
sponding reference translation (ref-1). The second
translation (tra-2) corresponds to a correct trans-
lation of the source sentence (src-2) that is differ-
ent from the corresponding reference (ref-2). Fi-
nally, the third translation (tra-3) is an example of
a slightly incorrect translation.
4 Concluding Remarks
In this paper, we have presented a novel proposal
that introduces sentence CMs into an IMT system
to reduce user effort. Our proposal entails a mod-
ification of the user-machine interaction protocol
that allows to achieve a balance between the user
effort and the final translation error.
We have carried out experimentation using two
different sentence CMs. Varying the value of
the sentence classification threshold, we can range
from a fully automatic SMT system to a conven-
tional IMT system. Empirical results show that
our proposal allows to obtain almost perfect trans-
lations while significantly reducing user effort.
Future research aims at the investigation of im-
proved CMs to be integrated in our IMT system.
Acknowledgments
Work supported by the EC (FEDER/FSE) and
the Spanish MEC/MICINN under the MIPRCV
?Consolider Ingenio 2010? program (CSD2007-
00018), the iTransDoc (TIN2006-15694-CO2-01)
and iTrans2 (TIN2009-14511) projects and the
FPU scholarship AP2006-00691. Also supported
by the Spanish MITyC under the erudito.com
(TSI-020110-2009-439) project and by the Gener-
alitat Valenciana under grant Prometeo/2009/014.
176
References
S. Barrachina, O. Bender, F. Casacuberta, J. Civera,
E. Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Toma?s,
and E. Vidal. 2009. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, 35(1):3?28.
J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur,
C. Goutte, A. Kulesza, A. Sanchis, and N. Ueffing.
2003. Confidence estimation for machine transla-
tion.
J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur,
C. Goutte, A. Kuesza, A. Sanchis, and N. Ueffing.
2004. Confidence estimation for machine transla-
tion. In Proc. COLING, page 315.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and
R. L. Mercer. 1993. The Mathematics of Statistical
Machine Translation: Parameter Estimation. Com-
putational Linguistics, 19(2):263?311.
J. Esteban, J. Lorenzo, A. Valderra?banos, and G. La-
palme. 2004. Transtype2: an innovative computer-
assisted translation system. In Proc. ACL, page 1.
G. Foster, P. Isabelle, and P. Plamondon. 1997. Target-
text mediated interactive machine translation. Ma-
chine Translation, 12:12?175.
S. Gandrabur and G. Foster. 2003. Confidence esti-
mation for text prediction. In Proc. CoNLL, pages
315?321.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Proc. ACL,
pages 177?180.
P. Langlais, G. Lapalme, and M. Loranger. 2002.
Transtype: Development-evaluation cycles to boost
translator?s productivity. Machine Translation,
15(4):77?98.
F. J. Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proc. ACL, pages 160?
167.
D. Ortiz, I. Garc??a-Varea, and F. Casacuberta. 2005.
Thot: a toolkit to train phrase-based statistical trans-
lation models. In Proc. MT Summit, pages 141?148.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a method for automatic evaluation of MT.
In Proc. ACL, pages 311?318.
G. Sanchis-Trilles, D. Ortiz-Mart??nez, J. Civera,
F. Casacuberta, E. Vidal, and H. Hoang. 2008. Im-
proving interactive machine translation via mouse
actions. In Proc. EMNLP, pages 25?27.
N. Ueffing and H. Ney. 2005. Application of word-
level confidence measures in interactive statistical
machine translation. In Proc. EAMT, pages 262?
270.
N. Ueffing and H. Ney. 2007. Word-level confidence
estimation for machine translation. Comput. Lin-
guist., 33(1):9?40.
N. Ueffing, F.J. Och, and H. Ney. 2002. Generation
of word graphs in statistical machine translation. In
Proc. EMNLP, pages 156?163.
177
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 68?73,
Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational Linguistics
An Interactive Machine Translation System with Online Learning
Daniel Ortiz-Mart??nez, Luis A. Leiva, Vicent Alabau,
Ismael Garc??a-Varea?, Francisco Casacuberta
ITI - Institut Tecnolo`gic d?Informa`tica, Universitat Polite`cnica de Vale`ncia
? Departamento de Sistemas Informa?ticos, Universidad de Castilla-La Mancha
{dortiz,luileito,valabau,fcn}@iti.upv.es, ?ismael.garcia@uclm.es
Abstract
State-of-the-art Machine Translation (MT)
systems are still far from being perfect. An
alternative is the so-called Interactive Ma-
chine Translation (IMT) framework, where
the knowledge of a human translator is com-
bined with the MT system. We present a sta-
tistical IMT system able to learn from user
feedback by means of the application of on-
line learning techniques. These techniques al-
low the MT system to update the parameters of
the underlying models in real time. According
to empirical results, our system outperforms
the results of conventional IMT systems. To
the best of our knowledge, this online learning
capability has never been provided by previ-
ous IMT systems. Our IMT system is imple-
mented in C++, JavaScript, and ActionScript;
and is publicly available on the Web.
1 Introduction
The research in the field of machine translation
(MT) aims to develop computer systems which are
able to translate text or speech without human in-
tervention. However, current translation technology
has not been able to deliver full automated high-
quality translations. Typical solutions to improve the
quality of the translations supplied by an MT system
require manual post-editing. This serial process pre-
vents the MT system from integrating the knowledge
of the human translator.
An alternative way to take advantage of the exist-
ing MT technologies is to use them in collaboration
with human translators within a computer-assisted
translation (CAT) or interactive framework (Isabelle
and Church, 1997). Interactivity in CAT has been
explored for a long time. Systems have been de-
signed to interact with linguists to solve ambiguities
or update user dictionaries.
An important contribution to CAT technology was
pioneered by the TransType project (Foster et al,
1997; Langlais et al, 2002). The idea proposed in
that work was to embed data driven MT techniques
within the interactive translation environment. Fol-
lowing the TransType ideas, Barrachina et al (2009)
proposed the so-called IMT framework, in which
fully-fledged statistical MT (SMT) systems are used
to produce full target sentences hypotheses, or por-
tions thereof, which can be accepted or amended
by a human translator. Each corrected text segment
is then used by the MT system as additional infor-
mation to achieve improved suggestions. Figure 1
shows an example of a typical IMT session.
The vast majority of the existing work on
IMT makes use of the well-known batch learning
paradigm. In the batch learning paradigm, the train-
ing of the IMT system and the interactive transla-
tion process are carried out in separate stages. This
paradigm is not able to take advantage of the new
knowledge produced by the user of the IMT system.
In this paper, we present an application of the online
learning paradigm to the IMT framework. In the on-
line learning paradigm, the training and prediction
stages are no longer separated. This feature is par-
ticularly useful in IMT since it allows to take into ac-
count the user feedback. Specifically, our proposed
IMT system can be extended with the new training
samples that are generated each time the user vali-
dates the translation of a given source sentence. The
online learning techniques implemented in our IMT
system incrementally update the statistical models
involved in the translation process.
2 Related work
There are some works on IMT in the literature that
try to take advantage of user feedback. One exam-
ple is the work by Nepveu et al (2004), where dy-
namic adaptation of an IMT system via cache-based
model extensions to language and translation models
is proposed. One major drawback of such proposal
is its inability to learn new words.
68
source(f ): Para ver la lista de recursos
reference(e?): To view a listing of resources
interaction-0
ep
es To view the resources list
interaction-1
ep To view
k a
es list of resources
interaction-2
ep To view a list
k list i
es list i ng resources
interaction-3
ep To view a listing
k o
es o f resources
accept ep To view a listing of resources
Figure 1: IMT session to translate a Spanish sentence into English. In interaction-0, the system suggests a translation
(es). In interaction-1, the user moves the mouse to accept the first eight characters ?To view ? and presses the a key
(k), then the system suggests completing the sentence with ?list of resources? (a new es). Interactions 2 and 3 are
similar. In the final interaction, the user accepts the current suggestion.
Recent research on IMT has proposed the use of
online learning as one possible way to successfully
incorporate user feedback in IMT systems (Ortiz-
Mart??nez et al, 2010). In the online learning setting,
models are trained sample by sample. For this rea-
son, such learning paradigm is appropriate for its use
in the IMT framework. The work by Ortiz-Mart??nez
et al (2010) implements online learning as incre-
mental learning. Specifically, an IMT system able
to incrementally update the parameters of all of the
different models involved in the interactive transla-
tion process is proposed. One previous attempt to
implement online learning in IMT is the work by
Cesa-Bianchi et al (2008). In that work, the authors
present a very constrained version of online learn-
ing, which is not able to extend the translation mod-
els due to the high time cost of the learning process.
We have adopted the online learning techniques
proposed in (Ortiz-Mart??nez et al, 2010) to imple-
ment our IMT system. We are not aware of other
IMT tools that include such functionality. For in-
stance, a prototype system for text prediction to help
translators is shown in (Foster et al, 2002). Addi-
tionally, Koehn (2009) presents the Caitra transla-
tion tool. Caitra aids linguists suggesting sentence
completions, alternative words or allowing users to
post-edit machine translation output. However, nei-
ther of these systems are able to take advantage of
the user validated translations.
3 Interactive Machine Translation
IMT can be seen as an evolution of the statistical ma-
chine translation (SMT) framework. In SMT, given
source string f , we seek for the target string e which
maximizes the posterior probability:
e? = argmax
e
Pr(e|f) (1)
Within the IMT framework, a state-of-the-art
SMT system is employed in the following way. For
a given source sentence, the SMT system automati-
cally generates an initial translation. A human trans-
lator checks this translation from left to right, cor-
recting the first error. The SMT system then pro-
poses a new extension, taking the correct prefix ep
into account. These steps are repeated until the
whole input sentence has been correctly translated.
In the resulting decision rule, we maximize over all
possible extensions es of ep:
e?s = argmax
es
Pr(es|ep, f) (2)
It is worth to note that the user interactions are at
character level, that is, for each submitted keystroke
the system provides a new extension (or suffix) to
the current hypothesis. A typical IMT session for a
given source sentence is depicted in Figure 1.
State-of-the-art SMT systems follow a log-linear
approach (Och and Ney, 2002), where the posterior
69
probability Pr(e | f) of Eq. (1) is used. Such log-
linear approach can be easily adapted for its use in
the IMT framework as follows:
e?s = argmax
es
{
M?
m=1
?mhm(ep, es, f)
}
(3)
where each hm(ep, es, f) is a feature function rep-
resenting a statistical model and ?m its correspond-
ing weight. Typically, a set of statistical generative
models are used as feature functions. Among this
feature functions, the most relevant are the language
and translation models. The language model is im-
plemented using statistical n-gram language mod-
els and the translation model is implemented using
phrase-based models.
The IMT system proposed here is based on a log-
linear SMT system which includes a total of seven
feature functions: an n-gram language model, a tar-
get sentence length model, inverse and direct phrase-
based models, source and target phrase length mod-
els and a reordering model.
4 Online Learning
In the online learning paradigm, learning proceeds
as a sequence of trials. In each trial, a sample is
presented to the learning algorithm to be classified.
Once the sample is classified, its correct label is told
to the learning algorithm.
The online learning paradigm fits nicely in the
IMT framework, since the interactive translation of
the source sentences generates new user-validated
training samples that can be used to extend the sta-
tistical models involved in the translation process.
One key aspect in online learning is the time re-
quired by the learning algorithm to process the new
training samples. One way to satisfy this constraint
is to obtain incrementally updateable versions of the
algorithms that are executed to train the statistical
models involved in the translation process. We have
adopted this approach to implement our IMT sys-
tem. Specifically, our proposed IMT system imple-
ments the set of training algorithms that are required
to incrementally update each component of the log-
linear model. Such log-linear model is composed of
seven components (see section 3). One key aspect of
the required training algorithms is the necessity to
replace the conventional expectation-maximization
(EM) algorithm by its incremental version (Neal and
Hinton, 1998). The complete details can be found in
(Ortiz-Mart??nez et al, 2010).
5 System Overview
In this section the main features of our prototype are
shown, including prototype design, interaction pro-
tocol, prototype functionalities and demo usage.
5.1 Prototype Design
Prototype architecture has been built on two main
aspects, namely, accessibility and flexibility. The
former is necessary to reach a larger number of po-
tential users. The latter allows researchers to test
different techniques and interaction protocols.
For that reason, we developed an CAT Appli-
cation Programming Interface (API) between the
client and the actual translation engine, by using
a network communication protocol and exposing a
well-defined set of functions.
Figure 2: IMT system architecture.
A diagram of the architecture is shown in Fig-
ure 2. On the one hand, the IMT client provides a
User Interface (UI) which uses the API to commu-
nicate with the IMT server through the Web. The
hardware requirements in the client are very low,
as the translation process is carried out remotely on
the server, so virtually any computer (including net-
books, tablets or 3G mobile phones) should be fairly
enough. On the other hand, the server, which is
unaware of the implementation details of the IMT
client, uses and adapts the statistical models that are
used to perform the translation.
5.2 User Interaction Protocol
The protocol that rules the IMT process has the fol-
lowing steps:
1. The system proposes a full translation of the
selected text segment.
70
Figure 3: Demo interface. The source text segments are automatically extracted from source document. Such segments
are marked as pending (light blue), validated (dark green), partially translated (light green), and locked (light red). The
translation engine can work either at full-word or character level.
2. The user validates the longest prefix of the
translation which is error-free and/or corrects
the first error in the suffix. Corrections are
entered by amendment keystrokes or mouse
clicks/wheel operations.
3. In this way, a new extended consolidated pre-
fix is produced based on the previous validated
prefix and the interaction amendments. Using
this new prefix, the system suggests a suitable
continuation of it.
4. Steps 2 and 3 are iterated until the user-desired
translation is produced.
5. The system adapts the models to the new vali-
dated pair of sentences.
5.3 Prototype Functionality
The following is a list of the main features that the
prototype supports:
? When the user corrects the solution proposed
by the system, a new improved suffix is pre-
sented to the user.
? The system is able to learn from user-validated
translations.
? The user is able to perform actions by means
of keyboard shortcuts or mouse gestures. The
supported actions on the proposed suffix are:
Substitution Substitute the first word or char-
acter of the suffix.
Deletion Delete the first word of the suffix.
Insertion Insert a word before the suffix.
Rejection The rejected word will not appear in
the following proposals.
Acceptance Assume that the current transla-
tion is correct and adapt the models.
? At any time, the user is able to visualize the
original document (Figure 4(a)), as well as a
properly formated draft of the current transla-
tion (Figure 4(b)).
? Users can select the document to be translated
from a list or upload their own documents.
5.4 Demo Description and Usage
This demo exploits the WWW to enable the connec-
tion of simultaneous accesses across the globe, coor-
dinating client-side scripting with server-side tech-
nologies. The interface uses web technologies such
as XHTML, JavaScript, and ActionScript; while the
IMT engine is written in C++.
The prototype is publicly available on the Web
(http://cat.iti.upv.es/imt/). To begin
with, the UI loads an index of all available transla-
tion corpora. Currently, the prototype can be tested
with the well-known Europarl corpora (Koehn,
2005). The user chooses a corpus and navigates to
the main interface page (Figure 3), where she in-
teractively translates the text segments one by one.
User?s feedback is then processed by the IMT server.
71
(a) Source document example, created from EuroParl corpus.
(b) Translated example document, preserving original format and highlighting non-translated sentences.
Figure 4: Translating documents with the proposed system.
All corrections are stored in plain text logs on the
server, so the user can retake them in any mo-
ment, also allowing collaborative translations be-
tween users. On the other hand, this prototype al-
lows uploading custom documents in text format.
Since the users operate within a web browser,
the system also provides crossplatform compatibil-
ity and requires neither computational power nor
disk space on the client?s machine. The communi-
cation between application and web server is based
on asynchronous HTTP connections, providing thus
a richer interactive experience (no page refreshes are
required.) Moreover, the Web server communicates
with the IMT engine through binary TCP sockets,
ensuring really fast response times.
6 Experimental Results
Experimental results were carried out using the Xe-
rox corpus (Barrachina et al, 2009), which con-
sists of translation of Xerox printer manual involv-
ing three different language pairs: French-English,
Spanish-English, and German-English. This corpus
has been extensively used in the literature to report
IMT results. The corpus consists of approximately
50,000 sentences pairs for training, 1,000 for devel-
opment, and 1,000 for test.
The evaluation criteria used in the experiments are
the key-stroke and mouse-action ratio (KSMR) met-
ric (Barrachina et al, 2009), which measures the
user effort required to generate error-free transla-
tions, and the well-known BLEU score, which con-
stitutes a measure of the translation quality.
The test corpora were interactively translated
from English to the other three languages, compar-
ing the performance of a batch IMT (baseline) and
the online IMT systems. The batch IMT system
is a conventional IMT system which is not able to
take advantage of user feedback after each trans-
lation is performed. The online IMT system uses
the translations validated by the user to adapt the
translation models at runtime. Both systems were
initialized with a log-linear model trained in batch
mode using the training corpus. Table 1 shows the
BLEU score and the KSMR for the batch and the
online IMT systems (95% confidence intervals are
shown). The BLEU score was calculated from the
first translation hypothesis produced by the IMT sys-
tem for each source sentence. All the obtained im-
provements with the online IMT system were statis-
tically significant. The average online training time
for each new sample presented to the system, and
the average response time for each user interaction
72
(that is, time that the system uses to propose new
extensions for corrected prefixes) are also shown in
Table 1, which are less than a tenth of a second and
around two tenths of a second respectively1. Ac-
cording to the reported response and online training
times, we can argue that the system proposed here is
able to be used on real time scenarios.
System BLEU KSMR LT/RT (s)
En-Sp
batch 55.1? 2.3 18.2? 1.1 ? /0.09
online 60.6? 2.3 15.8? 1.0 0.04 /0.09
En-Fr
batch 33.7? 2.0 33.9? 1.3 ? /0.14
online 42.2? 2.2 27.9? 1.3 0.09 /0.14
En-Ge
batch 20.4? 1.8 40.3? 1.2 ? /0.15
online 28.0? 2.0 35.0? 1.3 0.07 /0.15
Table 1: BLEU and KSMR results for the XEROX test
corpora using the batch and the online IMT systems, re-
porting the average online learning (LT) and the interac-
tion response times (RP) in seconds.
It is worth mentioning that the results presented
here significantly improve those presented in (Bar-
rachina et al, 2009) for other state-of-the-art IMT
systems using the same corpora.
7 Conclusions
We have described an IMT system with online learn-
ing which is able to learn from user feedback in real
time. As far as we know, to our knowledge, this
feature have never been provided by previously pre-
sented IMT prototypes.
The proposed IMT tool is publicly available
through the Web (http://cat.iti.upv.es/
imt/). Currently, the system can be used to inter-
actively translate the well-known Europarl corpus.
We have also carried out experiments with simulated
users. According to such experiments, our IMT
system is able to outperform the results obtained
by conventional IMT systems implementing batch
learning. Future work includes researching further
on the benefits provided by our online learning tech-
niques with experiments involving real users.
Acknowledgments
Work supported by the EC (FEDER/FSE), the Span-
ish Government (MEC, MICINN, MITyC, MAEC,
1All the experiments were executed in a PC with 2.40 GHz
Intel Xeon processor and 1GB of memory.
?Plan E?, under grants MIPRCV ?Consolider In-
genio 2010? CSD2007-00018, iTrans2 TIN2009-
14511, erudito.com TSI-020110-2009-439), the
Generalitat Valenciana (grant Prometeo/2009/014,
grant GV/2010/067), the Universitat Polite`cnica de
Vale`ncia (grant 20091027), and the Spanish JCCM
(grant PBI08-0210-7127).
References
S. Barrachina, O. Bender, F. Casacuberta, J. Civera,
E. Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Toma?s,
and E. Vidal. 2009. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, 35(1):3?28.
N. Cesa-Bianchi, G. Reverberi, and S. Szedmak. 2008.
Online learning algorithms for computer-assisted
translation. Deliverable D4.2, SMART: Stat. Multi-
lingual Analysis for Retrieval and Translation.
G. Foster, P. Isabelle, and P. Plamondon. 1997. Target-
text mediated interactive machine translation. Ma-
chine Translation, 12(1):175?194.
G. Foster, P. Langlais, and G. Lapalme. 2002. Transtype:
text prediction for translators. In Proc. HLT, pages
372?374.
P. Isabelle and K. Church. 1997. Special issue on
new tools for human translators. Machine Translation,
12(1?2).
P. Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. In Proc. of the MT Summit X,
pages 79?86, September.
P. Koehn. 2009. A web-based interactive computer aided
translation tool. In Proc. ACL-IJCNLP, ACLDemos,
pages 17?20.
P. Langlais, G. Lapalme, and M. Loranger. 2002.
Transtype: Development-evaluation cycles to boost
translator?s productivity. Machine Translation,
15(4):77?98.
R.M. Neal and G.E. Hinton. 1998. A view of the
EM algorithm that justifies incremental, sparse, and
other variants. In Proc. of the NATO-ASI on Learning
in graphical models, pages 355?368, Norwell, MA,
USA.
L. Nepveu, G. Lapalme, P. Langlais, and G. Foster. 2004.
Adaptive language and translation models for interac-
tive machine translation. In Proc. EMNLP, pages 190?
197.
F. J. Och and H. Ney. 2002. Discriminative Training
and Maximum Entropy Models for Statistical Machine
Translation. In Proc. ACL, pages 295?302.
D. Ortiz-Mart??nez, I. Garc??a-Varea, and F. Casacuberta.
2010. Online learning for interactive statistical ma-
chine translation. In Proc. NAACL/HLT, pages 546?
554.
73
