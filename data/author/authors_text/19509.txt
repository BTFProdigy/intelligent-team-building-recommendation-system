Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 99?108, Dublin, Ireland, August 23-29 2014.
Multi-Objective Search Results Clustering
Sudipta Acharya Sriparna Saha
Indian Institute of Technology Patna
Kurji, Patna, Bihar, India
{sudipta.pcs13,sriparna}@iitp.ac.in
Jose G. Moreno Ga
?
el Dias
Normandie University - CNRS GREYC
Caen, France
first.last@unicaen.fr
Abstract
Most web search results clustering (SRC) strategies have predominantly studied the definition of
adapted representation spaces to the detriment of new clustering techniques to improve perfor-
mance. In this paper, we define SRC as a multi-objective optimization (MOO) problem to take
advantage of most recent works in clustering. In particular, we define two objective functions
(compactness and separability), which are simultaneously optimized using a MOO-based simu-
lated annealing technique called AMOSA. The proposed algorithm is able to automatically detect
the number of clusters for any query and outperforms all state-of-the-art text-based solutions in
terms of F
?
-measure and F
b
3-measure over two gold standard data sets.
1 Introduction
Web search results clustering (SRC), also known as post-retrieval clustering or ephemeral clustering has
received much attention for the past twenty years for easing up user?s effort in web browsing. The key
idea behind SRC systems is to return some meaningful labeled clusters from a set of web documents (or
web snippets) retrieved from a search engine for a given query.
Recently, SRC strategies have been focusing on the introduction of external (exogenous) knowledge to
better capture semantics between documents (Scaiella et al., 2012; Marco and Navigli, 2013). Although
this research direction has evidenced competitive results, the proposed clustering techniques are based
on a single cluster quality measure, which must reflect alone the goodness of a given partitioning. These
techniques are usually referred to as single objective optimizations (SOO).
In this paper, we hypothesize that improved clustering can be achieved by defining different objective
functions over well-known data representations. As such, our study aims to focus on new clustering
issues for SRC instead of defining new representation spaces.
Recent studies (Maulik et al., 2011) have shown that clustering can be defined as a multi-objective
optimization (MOO) problem. Within the context of SRC, we propose to define two objective functions
(compactness and separability), which are simultaneously optimized using a MOO-based simulated an-
nealing technique called AMOSA (Bandyopadhyay et al., 2008).
In order to draw conclusive remarks, we present an exhaustive evaluation where our MOO algorithm
(MOO-clus) is compared to the most competitive text-based (endogenous) SRC algorithms: STC (Zamir
and Etzioni, 1998), LINGO (Osinski and Weiss, 2005), OPTIMSRC (Carpineto and Romano, 2010) and
GK-means (Moreno et al., 2013). Experiments are run over two different gold standard data sets (ODP-
239 and MORESQUE) for two clustering evaluation metrics (F
?
-measure and F
b
3
-measure). Results
show that MOO-clus outperforms all text-based solutions and approaches performances of knowledge
driven strategies (Scaiella et al., 2012). In this paper, our main contributions are:
? The first
1
attempt to solve SRC by defining multiple objective functions,
? A new MOO clustering algorithm for SRC, which automatically determines the number of clusters,
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/.
1
As far as we know.
99
? An exhaustive evaluation of SRC algorithms with recent data sets and evaluation metrics over the
most competitive state-of-the-art text-based SRC algorithms.
2 Related Work
2.1 SRC Algorithms
One of the most cited SRC solutions is the Suffix Tree Clustering (STC) algorithm proposed by (Zamir
and Etzioni, 1998). They propose a monothetic clustering technique, which merges base clusters with
high string overlap based on web snippets represented as compact tries. Their evaluation shows improve-
ments over agglomerative hierarchical clustering, K-Means, Buckshot, Fractionation and Single-Pass
algorithms, and is still a hard baseline to beat (Moreno and Dias, 2014).
Later, (Osinski and Weiss, 2005) proposed a polythetic solution called LINGO based on the same
string representation as of (Zamir and Etzioni, 1998). They first extract frequent phrases based on suffix-
arrays and match group descriptions with topics obtained with latent semantic analysis. Documents are
then assigned straightforwardly to their corresponding groups. Their evaluation does not allow conclu-
sive remarks but they propose an open source implementation, which is an important contribution.
More recently, (Carpineto and Romano, 2010) showed that the characteristics of the outputs returned
by SRC algorithms suggest the adoption of a meta clustering approach. The underlying idea is that dif-
ferent SOO solutions lead to complementary results that must be combined. So, they introduce a novel
criterion to measure the concordance of two partitions of objects into different clusters based on the infor-
mation content associated to the series of decisions made by the partitions on single pairs of objects. The
results of OPTIMSRC demonstrate that meta clustering is superior over individual clustering techniques.
The latest work, exclusively based on endogenous information (i.e. web snippets returned by the
search engine), is proposed by (Moreno et al., 2013). They adapt the K-means algorithm to a third-order
similarity measure and propose a stopping criterion to automatically determine the ?optimal? number of
clusters. Experiments are run over two gold standard data sets, ODP-239 (Carpineto and Romano, 2010)
and MORESQUE (Navigli and Crisafulli, 2010), and show improved results over all state-of-the-art
text-based SRC techniques so far.
A great deal of works have also proposed to include exogenous information to solve the SRC problem.
One important work is proposed by (Scaiella et al., 2012) who use Wikipedia articles to build a bipartite
graph and apply spectral clustering over it to discover relevant clusters. More recently, (Marco and
Navigli, 2013) proposed to include word sense induction based on the Web1T corpus (Brants and Franz,
2006) to improve SRC. In this paper, we exclusively focus on endogenous solutions.
2.2 MOO-based Clustering
Many works have been proposed where the problem of clustering is posed as one of multi-objective op-
timization (Deb, 2009; Maulik et al., 2011). One important work is proposed by (Handl and Knowles,
2007) who define a multi-objective clustering technique with automatic K-determination called MOCK.
Their algorithm outperforms several standard single-objective clustering algorithms (K-means, agglom-
erative hierarchical clustering and ensemble clustering) on artificial data sets.
In parallel, a multi-objective evolutionary algorithm for fuzzy clustering is proposed by (Bandyopad-
hyay et al., 2007) for clustering gene expressions. Here, two objectives are simultaneously optimized.
The first one is the objective function optimized in the fuzzy C-means algorithm (Bezdek, 1981) and the
other one is the Xie-Beni index (Xie and Beni, 1991).
Later, (Mukhopadhyay and Maulik, 2009) proposed a novel approach that combines the multi-
objective fuzzy clustering method of (Bandyopadhyay et al., 2007) with a Support Vector Machines
(SVM) classifier. Performance results are provided for remote sensing data.
As far as we know, within text applications, (Morik et al., 2012) is the first work, which formulates
text clustering a multi-objective optimization problem. In particular, they express desired properties
of frequent termset clustering in terms of multiple conflicting objective functions. The optimization is
solved by a genetic algorithm and the result is a set of Pareto-optimal solutions. Note that this effort is
100
defined for large text colllections with high dimensional data, which is contradictory to the specific task
of SRC (Carpineto et al., 2009)
2
.
2.3 Our Motivation
Recent works have focused on the introduction of external (exogenous) knowledge to solve the SRC
task. However, this research direction higly depends on existing resources, which are not available for a
great deal of languages. Moreover, (Carpineto and Romano, 2010) has suggested an interesting research
direction, which has still remained unexplored. Indeed, (Carpineto and Romano, 2010) showed that meta
clustering leads to improved results in the context of text-based (endogenous) SRC. This suggests that
better clustering can be obtained by combining different SOO solutions. However, their algorithm is
casted to a SOO problem of the concordance between the clustering combination and a meta partition.
As a consequence, we hypothesize that improved performances can be obtained by defining the SRC
task as a MOO clustering problem. For that purpose, we (1) take advantage of the recent advances in the
field of multi-objective clustering (Saha and Bandyopadhyay, 2010), (2) define new objective functions
in a non euclidean space and (3) adapt a MOO-based simulated annealing technique called AMOSA
(Bandyopadhyay et al., 2008) to take into account third-order similarity metrics (Moreno et al., 2013).
3 Clustering as a MOO Problem
3.1 Formal Definition of MOO Clustering
Multi-objective optimization can be formally stated as finding the vector x
?
= [x
?
1
, x
?
2
, . . . , x
?
n
]
T
of
decision variables that simultaneously optimize M objective function values {f
1
(x), f
2
(x), . . . , f
M
(x)}
while satisfying user-defined constraints, if any.
An important concept in MOO is that of domination. Within the context of a maximization prob-
lem, a solution x
i
is said to dominate x
j
if ?k ? 1, 2, . . . ,M, f
k
(x
i
) ? f
k
(x
j
) and ?k ?
1, 2, . . . ,M, such that f
k
(x
i
) > f
k
(x
j
).
Among a set of solutions R, the non-dominated set of solutions R
?
are those that are not dominated by
any member of the set R and is called the globally Pareto-optimal set or Pareto front. In general, a MOO
algorithm outputs a set of solutions not dominated by any solution encountered by it. These notions can
be illustrated by considering an optimization problem with two objective functions (f
1
and f
2
) with six
different solutions, as shown in Figure 1. Here target is to maximize both objective functions f
1
and f
2
.
1
3
4
5
Pareto Front
2
6
f1(maximize)
f2(maximize)
Figure 1: Example of dominance and Pareto optimal front.
In this example, solutions 3, 4 and 5 dominate all the other three solutions 1, 2 and 6. Solutions 3, 4
and 5 are nondominating to each other. Because 3 is better than 4 w.r.t. function f
1
, but 4 is better than
3 w.r.t. f
2
. Similarly 4 is better than 5 w.r.t. f
1
but 5 is better than 4 w.r.t. f
2
. The same happens for
solutions 3 and 5. So, the Pareto front is made of solutions 3, 4 and 5.
Within the specific context of clustering, two objective functions are usually defined, which must be
optimized simultaneously. These functions are based on two intrinsic properties of the data space and
are defined as follows.
2
SRC is usually referred to as text clustering in the ?small?: i.e. small list of short text documents.
101
Compactness: This objective function measures the proximity among the various elements of a given
cluster and must be maximized.
Separability: This objective function measures the similarity between two cluster centroids and must
be minimized.
3.2 AMOSA Optimization Strategy
Clustering is viewed as a search problem, where optimal partitions satisfying the given set of objective
functions must be discovered. As such, an optimization strategy must be defined. Here, we propose to
use archived multi-objective simulated annealing (AMOSA) proposed by (Bandyopadhyay et al., 2008).
AMOSA incorporates the concept of an archive where the non-dominated solutions seen so far are stored.
Two limits are kept on the size of the archive: a hard limit denoted by HL and a soft limit denoted by
SL. Given ? > 1, the algorithm begins with the initialization of a number (? ? SL) of solutions each of
which representing a state in the search space. Thereafter, the non-dominated solutions are determined
and stored in the archive.
Then, one point is randomly selected from the archive. This is taken as the current point, or the initial
solution, at temperature T = T
max
. The current point is perturbed/mutated to generate a new solution
named new-pt and its objective functions are computed. The domination status of the new-pt is checked
w.r.t. the current point and the solutions in the archive. Based on domination status, different cases may
arise: (i) accept the new-pt, (ii) accept the current-pt or (iii) accept a solution from the archive. In case
of overflow of the archive, its size is reduced to HL.
The process is repeated iter times for each temperature that is annealed with a cooling rate of ? (<1)
till the minimum temperature T
min
is attained. The process thereafter stops and the archive contains the
final non-dominated solutions i.e. the Pareto front.
4 SRC as MOO Problem: MOO-clus
4.1 Archive Initialization
As we follow an endogenous approach, only the information returned by a search engine is used. In
particular, we only deal with web snippets and each one is represented as a word feature vector. So, our
solution called MOO-clus starts its execution after initializing the archive with some random solutions
as archive members. Here, a particular solution refers to a complete assignment of web snippets (or data
points) in several clusters. So, the first step is to represent a solution compatible with AMOSA, which
represents each individual solution as a string. In order to encode the clustering problem in the form of
a string, a center-based representation is used. Note that the use of a string representation facilitates the
definition of individuals and mutation functions (Bandyopadhyay et al., 2008).
Let us assume that the archive member i represents the centroids of K
i
clusters and the number of
tokens in a centroid is p
3
, then the archive member (or string) has length l
i
where l
i
= p?K
i
. To initialize
the number of centroids K
i
encoded in the string i, a random value between 2 and K
max
is chosen and
each K
i
cluster centroid is initialized by randomly generated tokens from the global vocabulary.
4.2 Assignment of Web Snippets
As for any classical clustering algorithms, web snippets (or data points) must be assigned to their respec-
tive clusters. In MOO-clus, this assignment is computed as in (Moreno et al., 2013), to take advantage
of recent advances in similarity measures. For two word feature vectors d
i
and d
j
, their similarity is
evaluated by the similarity of their constituents as defined in Equation 1.
S(d
i
, d
j
) =
1
?d
i
??d
j
?
?d
i
?
?
r=1
?d
j
?
?
b=1
SCP (w
r
i
, w
b
j
), with SCP (w
1
, w
2
) =
P (w
1
, w
2
)
2
P (w
1
) ? P (w
2
)
(1)
3
A centroid is represented by a p word feature vector (w
1
k
, w
2
k
, w
3
k
, . . . , w
p
k
).
102
Here, w
r
i
(resp. w
b
j
) corresponds to the token at the r
th
(resp. b
th
) position of the word feature vector d
i
(resp. d
j
). ?d
i
? and ?d
j
? respectively denote the total number of tokens in word feature vectors d
i
and
d
j
. SCP (w
r
i
, w
b
j
) is the Symmetric Conditional Probability (da Silva et al., 1999) where P (., .) is the
joint probability of two tokens (w
1
and w
2
) appearing in the same word feature vector and P (.) is the
marginal probability of any token appearing in a word feature vector.
Note that each cluster centroid is a word feature vector of varying number of tokens. Thus, Equation 2
is used to assign any data point (web snippet) d
j
to a cluster twhose centroid has the maximum similarity
value to d
j
.
t = argmax
k=1,...K
S(d
j
,m
pi
k
) (2)
K denotes the total number of clusters, d
j
is the j
th
web snippet, m
pi
k
is the centroid of the k
th
cluster pi
k
and S(d
j
,m
pi
k
) denotes similarity measurement between the point d
j
and cluster centroid
m
pi
k
defined in Equation 1.
4.3 Definition of Objective Functions
A string i represents a set of centroids to which web snippets can be assigned as seen in Section 4.2. As a
consequence, each string i corresponds to a candidate partition of the data space. Now, in order to verify
the domination of different solutions over other ones, objective functions must be defined. Compactness
and separability are usually used in MOO clustering solutions. Here, compactness can be defined as the
informational density of each cluster. This can be straightforwardly formulated as in Equation 3.
Compactness =
K
?
k=1
?
d
i
?pi
k
S(d
i
,m
pi
k
) (3)
Note that if tokens in a particular cluster are very similar to the cluster centroid then the corresponding
Compactness value would be maximized. Here our target is to form good clusters whose compactness
in terms of similarity should be maximum.
The second objective function is cluster separability, which measures the dissimilarity between two
cluster centroids. Indeed, the purpose of any clustering algorithm is to obtain compact similar typed
clusters, which are dissimilar to each other. Here, we define separability as the minimization of the
summation of similarities between each pair of cluster centroids. This is defined in Equation 4, where
m
pi
k
and m
pi
o
are the centroids of clusters pi
k
and pi
o
, respectively.
Separability =
K
?
k=1
K
?
o=k+1
S(m
pi
k
,m
pi
o
) (4)
Finally, for a particular string, the following objectives {Compactness,
1
Separability
} are maximized
using the search capability of AMOSA.
4.4 Search Operators
In MOO-clus, AMOSA is used as the optimization strategy. For that purpose, three different types of
mutation operations have been defined to suit the framework.
Mutation 1: This mutation operation is used to update the cluster center representation. Each token of
cluster centroid is replaced by one token from the global vocabulary according to highest SCP similarity.
This is applied individually to all tokens of a particular centroid if it is selected for mutation.
Mutation 2: This mutation operation is used to reduce the size of the string by 1. We randomly select a
cluster centroid and thereafter all the tokens of this centroid are deleted from the string.
Mutation 3: This mutation is for increasing the size of string by 1 i.e. one new centroid is inserted in
the string. For that purpose, we randomly choose p number of tokens from the global vocabulary and
add it to the string.
103
Let be a string < w
1
w
2
w
3
w
4
w
5
w
6
> representing three cluster centroids (w
1
, w
2
), (w
3
, w
4
) and
(w
5
, w
6
)
4
. For mutation 1, let position 2 be selected randomly. Each token of the word vector (w
3
, w
4
)
will be changed by some token from the global vocabulary using SCP. Then, after change, the string
will look like < w
1
w
2
w
new
3
w
new
4
w
5
w
6
>. If mutation 2 is selected, a centroid will be removed from
the string. Let centroid 3 be selected for deletion. The new string will look like < w
1
w
2
w
3
w
4
>.
In case of mutation 3, a new centroid will be added to the string. A new cluster centroid is generated
choosing p=2 number of tokens from the global vocabulary. Let the randomly generated new clus-
ter centroid to be added to the string be (w
7
, w
8
). After inclusion of this centroid, the string will be
< w
1
w
2
w
3
w
4
w
5
w
6
w
7
w
8
>. In our experiments, we have associated equal probability to each of
these mutation operations. Thus, each mutation is applied in 33% cases of the cases.
5 Experimental Setup
5.1 Datasets
The main gold standards used for the evaluation of SRC algorithms are ODP-239 and MORESQUE
5
.
In ODP-239 (Carpineto and Romano, 2010), each document is represented by a title and a web snip-
pet and the subtopics are chosen from the top levels of DMOZ
6
. On the other hand, the subtopics in
MORESQUE (Navigli and Crisafulli, 2010) follow a more natural distribution as they are defined based
on the disambiguation pages of Wikipedia. As such, the subtopics cover most of the query-related senses.
However, not all queries are Wikipedia related or ambiguous (e.g. ?Olympic Games?, which Wikipedia
entry is not ambiguous, although there are many events related to this topic). As a consequence, it is
clear that different results can be obtained from one data set to another. A quick summary of both data
sets is presented in Table 1.
# of # of Subtopics # of
Dataset queries Avg / Min / Max Snippets
ODP-239 239 10 / 10 / 10 25580
MORESQUE 114 6.7 / 2 / 38 11402
Table 1: SRC gold standard data sets.
5.2 Evaluation Metrics
A successful SRC systemmust evidence high quality level clustering. Each query subtopic should ideally
be represented by a unique cluster containing all the relevant web pages inside. However, determining a
unique and complete metric to evaluate the performance of a clustering algorithm is still an open problem
(Amig?o et al., 2013).
In this paper, we propose to use the F
b
3
-measure (Amig?o et al., 2009) to explore the Pareto front.
In particular, F
b
3
has been defined to evaluate cluster homogeneity, completeness, rag-bag and size-vs-
quantity constraints. F
b
3
is a function of Precision
b
3
(P
b
3
) and Recall
b
3
(R
b
3
). All metrics are defined
in Equation 5
F
b
3
=
2 ? P
b
3
?R
b
3
P
b
3
+ R
b
3
, P
b
3
=
1
N
K
?
i=1
?
d
j
?pi
i
1
|pi
i
|
?
d
l
?pi
i
g
?
(d
j
, d
l
), R
b
3
=
1
N
K
?
i=1
?
d
j
?pi
?
i
1
|pi
?
i
|
?
d
l
?pi
?
i
g(d
j
, d
l
) (5)
where pi
i
is i
th
cluster, pi
?
i
is the gold standard of the category i, and g
?
(., .) and g(., .) are defined as
follows:
g
?
(d
i
, d
j
) =
{
1 ? ?l : d
i
? pi
?
l
? d
j
? pi
?
l
0 otherwise
and g(d
i
, d
j
) =
{
1 ? ?l : d
i
? pi
l
? d
j
? pi
l
0 otherwise
.
4
with p=2.
5
AMBIENT has received less attention since the creation of ODP-239.
6
http://www.dmoz.org [Last access: 14/03/2014].
104
Most SRC studies have also used the F
?
-measure (F
?
), which is defined in Equation 6.
F
?
=
(?
2
+ 1) ? P ?R
?
2
? P + R
, P =
TP
TP + FP
, R =
TP
TP + FN
(6)
where
TP =
K
?
i=1
?
d
j
?pi
?
i
?
d
l
? pi
?
i
l 6= j
g(d
i
, d
j
), FP =
K
?
i=1
?
d
j
?pi
i
?
d
l
? pi
i
l 6= j
(1? g
?
(d
i
, d
j
)), FN =
K
?
i=1
?
d
j
?pi
?
i
?
d
l
? pi
?
i
l 6= j
(1? g(d
i
, d
j
)).
6 Results and Discussion
In this evaluation, we used the open source framework GATE (Cunningham et al., 2013) without stop-
word removal for web snippet tokenization
7
. We executed MOO-clus over ODP-239 and MORESQUE.
The parameters of MOO-clus are: T
min
= 0.01, T
max
= 100, ? = 0.85, HL = 10, SL = 20 and
iter = 15. Note that, they have been determined after conducting a thorough sensitivity study. A first
set of experiments have been conducted for different p values of tokens present in the centroid, namely
in the range 2 to 5 in order to understand the behavior of MOO-clus w.r.t. centroid size
8
. Note that the
partition with maximum F
b
3 is choosen for each size of p
9
. Overall results are shown in Table 2.
MORESQUE ODP-239
MOO-clus MOO-clus
2 3 4 5 2 3 4 5
F
b
3
0.477 0.491 0.497 0.502 0.478 0.481 0.484 0.481
F
1
0.661 0.666 0.675 0.658 0.379 0.379 0.384 0.381
F
2
0.750 0.768 0.764 0.742 0.534 0.536 0.537 0.535
F
5
0.831 0.862 0.846 0.820 0.717 0.720 0.716 0.715
Table 2: Evaluation results of MOO-clus over MORESQUE and ODP239 data sets.
Results show that for MORESQUE, MOO-clus obtains the highest F
b
3 value for p=5. In particular,
performance increases for higher values of p. For ODP-239, best results are reported for p=4, but evi-
dence less sensitivity to the number of words in the centroids. Indeed, a marginal difference is obtained
between all runs. In terms of F
?
, the same behaviour is obtained for ODP-239. But, for MORESQUE,
best results are provided for smaller values of p, namely p=3.
Two important comments must be pointed at. In the first place, F
b
3
shows a steady behaviour compared
to F
?
when the data set changes. The conclusions drawn in (Amig?o et al., 2009) reporting the superiority
of F
b
3
over F
?
seem to be verified for the specific case of SRC. In the second place, MOO-clus evidences
a marginal sensitivity to different p values. Indeed, for ODP-239, changing p between 2 and 5 words has
a negligible impact on F
b
3 . The figures show a different behaviour for MORESQUE but this can easily
be explained. In MORESQUE, less queries are provided for test and the number of reference clusters
varies between 2 and 38, with a majority of queries containing very few clusters (the average cluster size
is 6.7). As such, small clustering errors may result in high deviations in the evaluation metrics. So, p
can be seen as a non influent parameter for clustering purposes. In fact, increasing the value of p may
exclusively allow a more descriptive power for cluster labeling.
We also compared MOO-clus to the current state-of-the-art text-based (endogenous) SRC algorithms:
STC (Zamir and Etzioni, 1998), LINGO (Osinski and Weiss, 2005), OPTIMSRC (Carpineto and Ro-
mano, 2010), Bisecting Incremental K-means (BIK), GK-means (Moreno et al., 2013) and the combi-
nation STC-LINGO (Moreno and Dias, 2014). The results are illustrated in Table 3 where we provide
values for all the metrics for open source implementations and reported values in the literature for the
7
Note that keeping stop words is a challenging task as most methodologies withdraw these elements as they are hard to
handle. This decision is supported by the fact that we aim to produce as much as possible language-independent solutions.
8
Note that to ease the user effort in searching for information, the cluster label must be small and expressive. Typical
configurations range between 3 to 5 to include multiword expressions.
9
F
?
metrics are calculated over the partition with highest F
b
3
value.
105
other experiments i.e. OPTIMSRC, GK-means and STC-LINGO. In particular, the Min (resp. Max)
column refers to the worst (resp. best) performance when varying p, the size of the centroid.
The results of Table 3 clearly show the performance improvements of our proposed methodology over
existing text-based techniques for both data sets and most evaluation metrics. For ODP-239, MOO-clus
attains the highest values with respect to F
1
, F
2
, F
5
and F
b
3
metrics against all existing endogenous algo-
rithms. For MORESQUE, our algorithm reaches highest performance over all state-of-the-art algorithms
for F
1
and F
b
3 metrics but marginally fails for F
2
and F
5
against GK-means.
MOO-clus SOO SRC Combination of SOO SRC
Min Max GK-means STC LINGO BIK OPTIMSRC STC-LINGO
MORESQUE F
1
0.658 0.675 0.665 0.455 0.326 0.317 N/A 0.561
F
2
0.742 0.768 0.770 0.392 0.260 0.269 N/A N/A
F
5
0.820 0.862 0.872 0.370 0.237 0.255 N/A N/A
F
b
3
0.477 0.502 0.482 0.460 0.399 0.315 N/A 0.498
ODP-239 F
1
0.379 0.384 0.366 0.324 0.273 0.200 0.313 0.362
F
2
0.534 0.537 0.416 0.319 0.167 0.173 0.341 N/A
F
5
0.715 0.720 0.462 0.322 0.153 0.165 0.380 N/A
F
b
3
0.478 0.484 0.452 0.403 0.346 0.307 N/A 0.425
Table 3: Comparative results with respect to F
?
and F
b
3 metrics over the ODP-239 and MORESQUE
datasets obtained by different SRC techniques.
It is important to notice that OPTIMSRC and STC-LINGO can be viewed as a combination of different
SRC SOO solutions but still casted to a SOO solution. These previous results report interesting issues
for SRC and confort the idea that the combination of different objective functions may lead to enhanced
SRC algorithms. But, MOO-clus is capable to find better partitions than OPTIMSRC and STC-LINGO
for all data sets and all evaluation metrics as reported in Table 3.
It is important to notice that the MOO-clus provides a set of partitions with automatic definition of
the number of clusters. So, defining one unique solution is an important issue for SRC. So far, we have
provided results for the best partition evaluated by F
b
3
. However, deeper analysis of all the partitions
on the Pareto front must be endeavoured. Results are reported for F
b
3
only as all other metrics behave
correspondingly and are reported in Table 4.
MORESQUE ODP-239
2 3 4 5 2 3 4 5
Min 0.428 0.464 0.464 0.462 0.396 0.401 0.403 0.408
Max 0.477 0.491 0.497 0.502 0.478 0.481 0.484 0.481
Avg. 0.454 0.479 0.482 0.486 0.443 0.447 0.448 0.449
Table 4: F
b
3 evaluation results of the Pareto front.
Figures show the validity of each individual solution of the Pareto front. In the worst case, MOO-clus
produces similar results compared to the hard baseline STC. On average, it reaches the results of GK-
means and the highest performance values can be found on the Pareto front. The correct identification
of the best partition is still an open issue and can be compared to the automatic selection of K clusters,
which is a hard task as shown in recent studies (Scaiella et al., 2012; Marco and Navigli, 2013).
7 Conclusions
In this paper, we proposed the first attempt
10
to define the SRC task as a multi-objective problem. For that
purpose, we defined two objective functions, which are simultaneously optimized through the archived
multi-objective simulated annealing framework called AMOSA. A correct definition of the task allowed
to take advantage of the most recent advances in terms of endogenous SRC algorithms as well as the most
powerful techniques for multi-objective clustering. The performance of MOO-clus has been evaluated
over two gold standard data sets, ODP-239 andMORESQUE for different evaluation metrics, F
1
and F
b
3 .
10
As far as we know.
106
Results showed that our proposal steadily outperforms all existing state-of-the-art text-based endogenous
SRC algorithms and approaches recent knowledge-driven exogenous strategies (Scaiella et al., 2012),
which reach F
1
=0.413 for ODP-239
11
.
As future works, we propose to use MOO clustering in a strict meta learning way, where any labeled-
based SOO solution is defined by specific Compactness and Separability functions. Another research
direction is the definition of the Dual representation proposed by (Moreno et al., 2014) as a MOO prob-
lem. Finally, new objective functions can be defined to measure the quality of the labels, which may
integrate meaningful multiword expressions or named entities.
Acknowledgement
We would like to thank the CNRS to provide Sriparna Saha with a 6 months internship at the GREYC
Laboratory of the Normandie University.
References
Enrique Amig?o, Julio Gonzalo, Javier Artiles, and Felisa Verdejo. 2009. A comparison of extrinsic clustering
evaluation metrics based on formal constraints. Information Retrieval, 12(4):461?486.
Enrique Amig?o, Julio Gonzalo, and Felisa Verdejo. 2013. A general evaluation measure for document organization
tasks. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in
Information Retrieval (SIGIR), pages 643?652.
Sanghamitra Bandyopadhyay, Anirban Mukhopadhyay, and Ujjwal Maulik. 2007. An improved algorithm for
clustering gene expression data. Bioinformatics, 23(21):2859?2865.
Sanghamitra Bandyopadhyay, Sriparna Saha, Ujjwal Maulik, and Kalyanmoy Deb. 2008. A simulated annealing-
based multiobjective optimization algorithm: Amosa. In IEEE transactions on evolutionary computation, pages
269?283.
James C. Bezdek. 1981. Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum, New York.
Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram.
Claudio Carpineto and Giovanni Romano. 2010. Optimal meta search results clustering. In 33rd International
ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 170?177.
Claudio Carpineto, Stanislaw Osinski, Giovanni Romano, and Dawid Weiss. 2009. A survey of web clustering
engines. ACM Computing Surveys, 41(3):1?38.
Hamish Cunningham, Valentin Tablan, Angus Roberts, and Kalina Bontcheva. 2013. Getting more out of
biomedical documents with gate?s full lifecycle open source text analytics. PLoS Computational Biology,
9(2):e1002854.
Joaquim Ferreira da Silva, Ga?el Dias, Sylvie Guillor?e, and Jos?e Gabriel Pereira Lopes. 1999. Using localmaxs
algorithm for the extraction of contiguous and non-contiguous multiword lexical units. In Proceedings of 9th
Portuguese Conference in Artificial Intelligence (EPIA), pages 113?132.
Kalyanmoy Deb. 2009. Multi-Objective Optimization Using Evolutionary Algorithms. Wiley.
Julia Handl and Joshua Knowles. 2007. An evolutionary approach to multiobjective clustering. IEEE Transactions
on Evolutionary Computation, 11:56?76.
Antonio D. Marco and Roberto Navigli. 2013. Clustering and diversifying web search results with graph-based
word sense induction. Computational Linguistics, 39(4):1?43.
Ujjwal Maulik, Sanghamitra Bandyopadhyay, and Anirban Mukhopadhyay. 2011. Multiobjective Genetic Algo-
rithms for Clustering - Applications in Data Mining and Bioinformatics. Springer.
Jos?e G. Moreno and Ga?el Dias. 2014. Easy web search results clustering: When baselines can reach state-of-
the-art algorithms. In Proceedings of the 14th Conference of the European Chapter of the Association for
Computational Linguistics (EACL), pages 1?5.
11
Note that results of (Marco and Navigli, 2013) are not reported in this paper as the authors do not use the standard versions
of MORESQUE and do not provide experiments for ODP-239.
107
Jos?e G. Moreno, Ga?el Dias, and Guillaume Cleuziou. 2013. Post-retrieval clustering using third-order similarity
measures. In 51st Annual Meeting of the Association for Computational Linguistics (ACL), pages 153?158.
Jos?e G. Moreno, Ga?el Dias, and Guillaume Cleuziou. 2014. Query log driven web search results clustering. In
Proceedings of the 37th Annual ACM SIGIR Conference (SIGIR).
Katharina Morik, Andreas Kaspari, Michael Wurst, and Marcin Skirzynsk. 2012. Multi-objective frequent termset
clustering. Knowledge Information Systems, 30(3):715?738.
Anirban Mukhopadhyay and Ujjwal Maulik. 2009. Unsupervised pixel classification in satellite imagery using
multiobjective fuzzy clustering combined with SVM classifier. IEEE Transactions on Geoscience and Remote
Sensing, pages 1132?1138.
Roberto Navigli and Giuseppe Crisafulli. 2010. Inducing word senses to improve web search result clustering. In
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages
116?126.
Stanislaw Osinski and Dawid Weiss. 2005. A concept-driven algorithm for clustering search results. IEEE
Intelligent Systems, 20(3):48?54.
Sriparna Saha and Sanghamitra Bandyopadhyay. 2010. A symmetry based multiobjective clustering technique for
automatic evolution of clusters. Pattern Recognition, 43(3):738?751.
Ugo Scaiella, Paolo Ferragina, Andrea Marino, and Massimiliano Ciaramita. 2012. Topical clustering of search
results. In 5th ACM International Conference on Web Search and Data Mining (WSDM), pages 223?232.
Xuanli L. Xie and Gerardo Beni. 1991. A validity measure for fuzzy clustering. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 13:841?847.
Oren Zamir and Oren Etzioni. 1998. Web document clustering: A feasibility demonstration. In 21st Annual
International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages
46?54.
108
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 1?5,
Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational Linguistics
Easy Web Search Results Clustering:
When Baselines Can Reach State-of-the-Art Algorithms
Jose G. Moreno
Normandie University
UNICAEN, GREYC CNRS
F-14032 Caen, France
jose.moreno@unicaen.fr
Gae?l Dias
Normandie University
UNICAEN, GREYC CNRS
F-14032 Caen, France
gael.dias@unicaen.fr
Abstract
This work discusses the evaluation of
baseline algorithms for Web search re-
sults clustering. An analysis is performed
over frequently used baseline algorithms
and standard datasets. Our work shows
that competitive results can be obtained by
either fine tuning or performing cascade
clustering over well-known algorithms. In
particular, the latter strategy can lead to
a scalable and real-world solution, which
evidences comparative results to recent
text-based state-of-the-art algorithms.
1 Introduction
Visualizing Web search results remains an open
problem in Information Retrieval (IR). For exam-
ple, in order to deal with ambiguous or multi-
faceted queries, many works present Web page re-
sults using groups of correlated contents instead
of long flat lists of relevant documents. Among
existing techniques, Web Search Results Cluster-
ing (SRC) is a commonly studied area, which
consists in clustering ?on-the-fly? Web page re-
sults based on their Web snippets. Therefore,
many works have been recently presented includ-
ing task adapted clustering (Moreno et al., 2013),
meta clustering (Carpineto and Romano, 2010)
and knowledge-based clustering (Scaiella et al.,
2012).
Evaluation is also a hot topic both in Natural
Language Processing (NLP) and IR. Within the
specific case of SRC, different metrics have been
used such as F
1
-measure (F
1
), kSSL1 and F
b
3-
measure (F
b
3) over different standard datasets:
ODP-239 (Carpineto and Romano, 2010) and
Moresque (Navigli and Crisafulli, 2010). Unfor-
tunately, comparative results are usually biased as
1This metric is based on subjective label evaluation and as
such is out of the scope of this paper.
baseline algorithms are run with default parame-
ters whereas proposed methodologies are usually
tuned to increase performance over the studied
datasets. Moreover, evaluation metrics tend to cor-
relate with the number of produced clusters.
In this paper, we focus on deep understand-
ing of the evaluation task within the context of
SRC. First, we provide the results of baseline algo-
rithms with their best parameter settings. Second,
we show that a simple cascade strategy of base-
line algorithms can lead to a scalable and real-
world solution, which evidences comparative re-
sults to recent text-based algorithms. Finally, we
draw some conclusions about evaluation metrics
and their bias to the number of output clusters.
2 Related Work
Search results clustering is an active research area.
Two main streams have been proposed so far:
text-based strategies such as (Hearst and Peder-
sen, 1996; Zamir and Etzioni, 1998; Zeng et al.,
2004; Osinski et al., 2004; Carpineto and Romano,
2010; Carpineto et al., 2011; Moreno et al., 2013)
and knowledge-based ones (Ferragina and Gulli,
2008; Scaiella et al., 2012; Di Marco and Nav-
igli, 2013). Successful results have been obtained
by recent works compared to STC (Zamir and Et-
zioni, 1998) and LINGO (Osinski et al., 2004)
which provide publicly available implementations,
and as a consequence, are often used as state-
of-the-art baselines. On the one hand, STC pro-
poses a monothetic methodology which merges
base clusters with high string overlap relying on
suffix trees. On the other hand, LINGO is a poly-
thetic solution which reduces a term-document
matrix using single value decomposition and as-
signs documents to each discovered latent topic.
All solutions have been evaluated on differ-
ent datasets and evaluation measures. The well-
known F
1
has been used as the standard evaluation
metric. More recently, (Carpineto and Romano,
1
Moresque ODP-239
F
1
F
b
3
F
1
F
b
3
Algo. Stand. k Tuned k Stand. k Tuned k Stand. k Tuned k Stand. k Tuned k
STC 0.4550 12.7 0.6000 2.9 0.4602 12.7 0.4987 2.9 0.3238 12.4 0.3350 3.0 0.4027 12.4 0.4046 14.5
LINGO 0.3258 26.7 0.6034 3.0 0.3989 26.7 0.5004 5.8 0.2029 27.7 0.3320 3.0 0.3461 27.7 0.4459 8.7
BiKm 0.3165 9.7 0.5891 2.1 0.3145 9.7 0.4240 2.1 0.1995 12.1 0.3381 2.2 0.3074 12.1 0.3751 2.2
Random - - 0.5043 2 - - 0.3548 2 - - 0.2980 2 - - 0.3212 2
Table 1: Standard, Tuned and Random Results for Moresque and ODP-239 datasets.
2010) evidenced more complete results with the
general definition of the F
?
-measure for ? =
{1, 2, 5}, (Navigli and Crisafulli, 2010) introduced
the Rand Index metric and (Moreno et al., 2013)
used F
b
3 introduced by (Amigo? et al., 2009) as a
more adequate metric for clustering.
Different standard datasets have been built such
as AMBIENT2 (Carpineto and Romano, 2009),
ODP-2393 (Carpineto and Romano, 2010) and
Moresque4 (Navigli and Crisafulli, 2010). ODP-
239, an improved version of AMBIENT, is based
on DMOZ5 where each query, over 239 ones, is a
selected category in DMOZ and its associated sub-
categories are considered as the respective clus-
ter results. The small text description included in
DMOZ is considered as a Web snippet. Moresque
is composed by 114 queries selected from a list
of ambiguous Wikipedia entries. For each query, a
set of Web results have been collected from a com-
mercial search engine and manually classified into
the disambiguation Wikipedia pages which form
the reference clusters.
In Table 2, we report the results obtained so
far in the literature by text-based and knowledge-
based strategies for the standard F
1
over ODP-239
and Moresque datasets.
F
1
ODP239 Moresque
Text
STC 0.324 0.455
LINGO 0.273 0.326
(Carpineto and Romano, 2010) 0.313 -
(Moreno et al., 2013) 0.390 0.665
Know. (Scaiella et al., 2012) 0.413 -(Di Marco and Navigli, 2013) - 0.7204*
Table 2: State-of-the-art Results for SRC. (*) The
result of (Di Marco and Navigli, 2013) is based
on a reduced version of AMBIENT + Moresque.
3 Baseline SRC Algorithms
Newly proposed algorithms are usually tuned to-
wards their maximal performance. However, the
results of baseline algorithms are usually run with
2http://credo.fub.it/ambient/ [Last acc.: Jan., 2014]
3http://credo.fub.it/odp239/ [Last acc.: Jan., 2014]
4http://lcl.uniroma1.it/moresque/ [Last acc.: Jan., 2014]
5http://www.dmoz.org [Last acc.: Jan., 2014]
default parameters based on available implemen-
tations. As such, no conclusive remarks can be
drawn knowing that tuned versions might provide
improved results.
In particular, available implementations6 of
STC, LINGO and the Bisection K-means (BiKm)
include a fixed stopping criterion. However, it
is well-known that tuning the number of output
clusters may greatly impact the clustering perfor-
mance. In order to provide fair results for base-
line algorithms, we evaluated a k-dependent7 ver-
sion for all baselines. We ran all algorithms for
k = 2..20 and chose the best result as the ?op-
timal? performance. Table 1 sums up results for
all the baselines in their different configurations
and shows that tuned versions outperform standard
(available) ones both for F
1
and F
b
3 over ODP-
239 and Moresque.
4 Cascade SRC Algorithms
In the previous section, our aim was to claim that
tunable versions of existing baseline algorithms
might evidence improved results when faced to
the ones reported in the literature. And these
values should be taken as the ?real? baseline re-
sults within the context of controllable environ-
ments. However, exploring all the parameter space
is not an applicable solution in a real-world situa-
tion where the reference is unknown. As such, a
stopping criterion must be defined to adapt to any
dataset distribution. This is the particular case for
the standard implementations of STC and LINGO.
Previous results (Carpineto and Romano, 2010)
showed that different SRC algorithms provide dif-
ferent results and hopefully complementary ones.
For instance, STC demonstrates high recall and
low precision, while LINGO inversely evidences
high precision for low recall. Iteratively apply-
ing baseline SRC algorithms may thus lead to
improved results by exploiting each algorithm?s
strengths.
6http://carrot2.org [Last acc.: Jan., 2014]
7Carrot2 parameters maxClusters, desiredClusterCount-
Base and clusterCount were used to set k value.
2
In a cascade strategy, we first cluster the ini-
tial set of Web page snippets with any SRC al-
gorithm. Then, the input of the second SRC al-
gorithm is the set of meta-documents built from
the documents belonging to the same cluster8. Fi-
nally, each clustered meta-document is mapped to
the original documents generating the final clus-
ters. This process can iteratively be applied, al-
though we only consider two-level cascade strate-
gies in this paper.
This strategy can be viewed as an easy, re-
producible and parameter free baseline SRC im-
plementation that should be compared to existing
state-of-the-art algorithms. Table 3 shows the re-
sults obtained with different combinations of SRC
baseline algorithms for the cascade strategy both
for F
1
and F
b
3 over ODP-239 and Moresque. The
?Stand.? column corresponds to the performance
of the cascade strategy and k to the automatically
obtained number of clusters. Results show that
the combination STC-STC achieves the best per-
formance overall for the F
1
and STC-LINGO is
the best combination for the F
b
3 in both datasets.
In order to provide a more complete evaluation,
we included in column ?Equiv.? the performance
that could be obtained by the tunable version of
each single baseline algorithm based on the same
k. Interestingly, the cascade strategy outperforms
the tunable version for any k for F
1
but fails to
compete (not by far) with F
b
3 . This issue will be
discussed in the next section.
5 Discussion
In Table 1, one can see that when using the tuned
version and evaluating with F
1
, the best perfor-
mance for each baseline algorithm is obtained for
the same number of output clusters independently
of the dataset (i.e. around 3 for STC and LINGO
and 2 for BiKm). As such, a fast conclusion would
be that the tuned versions of STC, LINGO and
BiKm are strong baselines as they show similar
behaviour over datasets. Then, in a realistic situa-
tion, k might be directly tuned to these values.
However, when comparing the output number
of clusters based on the best F
1
value to the refer-
ence number of clusters, a huge difference is ev-
idenced. Indeed, in Moresque, the ground-truth
average number of clusters is 6.6 and exactly 10
in ODP-239. Interestingly, F
b
3 shows more accu-
rate values for the number of output clusters for
8Fused using concatenation of strings.
the best tuned baseline performances. In particu-
lar, the best F
b
3 results are obtained for LINGO
with 5.8 clusters for Moresque and 8.7 clusters
for ODP-239 which most approximate the ground-
truths.
In order to better understand the behaviour of
each evaluation metric (i.e. F
?
and F
b
3) over dif-
ferent k values, we experienced a uniform random
clustering over Moresque and ODP-239. In Fig-
ure 1(c), we illustrate these results. The important
issue is that F
?
is more sensitive to the number
of output clusters than F
b
3 . On the one hand, all
F
?
measures provide best results for k = 2 and
a random algorithm could reach F
1
=0.5043 for
Moresque and F
1
=0.2980 for ODP-239 (see Ta-
ble 1), thus outperforming almost all standard im-
plementations of STC, LINGO and BiKm for both
datasets. On the other hand, F
b
3 shows that most
standard baseline implementations outperform the
random algorithm.
Moreover, in Figures 1(a) and 1(b), we illus-
trate the different behaviours between F
1
and F
b
3
for k = 2..20 for both standard and tuned ver-
sions of STC, LINGO and BiKm. One may clearly
see that F
b
3 is capable to discard the algorithm
(BiKm) which performs worst in the standard ver-
sion while this is not the case for F
1
. And, for
LINGO, the optimal performances over Moresque
and ODP-239 are near the ground-truth number of
clusters while this is not the case for F
1
which ev-
idences a decreasing tendency when k increases.
In section 4, we showed that competitive results
could be achieved with a cascade strategy based on
baseline algorithms. Although results outperform
standard and tunable baseline implementations for
F
1
, it is wise to use F
b
3 to better evaluate the SRC
task, based on our previous discussion. In this
case, the best values are obtained by STC-LINGO
with F
b
3=0.4980 for Moresque and F
b
3=0.4249
for ODP-239, which highly approximate the val-
ues reported in (Moreno et al., 2013): F
b
3=0.490
(Moresque) and F
b
3=0.452 (ODP-239). Addition-
ally, when STC is performed first and LINGO later
the cascade algorithm scale better due to LINGO
and STC scaling properties9.
6 Conclusion
This work presents a discussion about the use of
baseline algorithms in SRC and evaluation met-
9http://carrotsearch.com/lingo3g-comparison [Last acc.:
Jan., 2014]
3
Moresque ODP-239
F
1
F
b
3
F
1
F
b
3
Level 1 Level 2 Stand. Equiv. k Stand. Equiv. k Stand. Equiv. k Stand. Equiv. k
STC
STC 0.6145 0.5594 3.1 0.4550 0.4913 3.1 0.3629 0.3304 3.2 0.3982 0.4023 3.2
LINGO 0.5611 0.4932 7.3 0.4980 0.4716 7.3 0.3624 0.3258 6.9 0.4249 0.4010 6.9
BiKm 0.5413 0.5160 4.5 0.4395 0.4776 4.5 0.3319 0.3276 4.3 0.3845 0.4020 4.3
LINGO
STC 0.5696 0.5176 6.7 0.4602 0.4854 6.7 0.3457 0.3029 7.2 0.4229 0.4429 7.2
LINGO 0.4629 0.4371 13.7 0.4447 0.4566 13.7 0.2789 0.2690 13.6 0.3931 0.4237 13.6
BiKm 0.4038 0.4966 8.6 0.3801 0.4750 8.6 0.2608 0.2953 8.5 0.3510 0.4423 8.5
BiKm
STC 0.5873 0.5891 2.7 0.4144 0.4069 2.7 0.3425 0.3381 2.7 0.3787 0.3677 2.7
LINGO 0.4773 0.5186 5.4 0.3832 0.3869 5.4 0.2819 0.3191 6.3 0.3546 0.3644 6.3
BiKm 0.4684 0.5764 3.5 0.3615 0.4114 3.5 0.2767 0.3322 4.3 0.3328 0.3693 4.3
Table 3: Cascade Results for Moresque and ODP-239 datasets.
(a) F
1
for Moresque (Left) and ODP-239 (Right).
0.3
0.35
0.4
0.45
0.5
0.55
0.6
0.65
2 4 6 8 10 12 14 16 18 20
F1
k
BiKm(Tuned)
STC(Tuned)
LINGO(Tuned)
BiKm(Stand.)
STC(Stand.)
LINGO(Stand.)
0.18
0.2
0.22
0.24
0.26
0.28
0.3
0.32
0.34
0.36
2 4 6 8 10 12 14 16 18 20
F1
k
BiKm(Tuned)
STC(Tuned)
LINGO(Tuned)
BiKm(Stand.)
STC(Stand.)
LINGO(Stand.)
(b) F
b
3
for Moresque (Left) and ODP-239 (Right).
0.3
0.32
0.34
0.36
0.38
0.4
0.42
0.44
0.46
0.48
0.5
0.52
2 4 6 8 10 12 14 16 18 20
Fb
cu
be
d
k
BiKm(Tuned)
STC(Tuned)
LINGO(Tuned)
BiKm(Stand.)
STC(Stand.)
LINGO(Stand.)
0.3
0.32
0.34
0.36
0.38
0.4
0.42
0.44
0.46
2 4 6 8 10 12 14 16 18 20
Fb
cu
be
d
k
BiKm(Tuned)
STC(Tuned)
LINGO(Tuned)
BiKm(Stand.)
STC(Stand.)
LINGO(Stand.)
(c) Evaluation Metrics for Random Clustering for Moresque (Left) and ODP-239 (Right).
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
2 4 6 8 10 12 14 16 18 20
Pe
rf
or
m
an
ce
k
F1
F2
F5
Fbcubed
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
2 4 6 8 10 12 14 16 18 20
Pe
rf
or
m
an
ce
k
F1
F2
F5
Fbcubed
Figure 1: F
1
and F
b
3 for Moresque and ODP-239 for Standard, Tuned and Random Clustering.
rics. Our experiments show that F
b
3 seems more
adapted to evaluate SRC systems than the com-
monly used F
1
over the standard datasets avail-
able so far. New baseline values which approxi-
mate state-of-the-art algorithms in terms of clus-
tering performance can also be obtained by an
easy, reproducible and parameter free implemen-
tation (the cascade strategy) and could be consid-
ered as the ?new? baseline results for future works.
4
References
E. Amigo?, J. Gonzalo, J. Artiles, and F. Verdejo. 2009.
A comparison of extrinsic clustering evaluation met-
rics based on formal constraints. Information Re-
trieval, 12(4):461?486.
C. Carpineto and G. Romano. 2009. Mobile infor-
mation retrieval with search results clustering : Pro-
totypes and evaluations. Journal of the American
Society for Information Science, 60:877?895.
C. Carpineto and G. Romano. 2010. Optimal meta
search results clustering. In 33rd International ACM
SIGIR Conference on Research and Development in
Information Retrieval (SIGIR), pages 170?177.
C. Carpineto, M. D?Amico, and A. Bernardini. 2011.
Full discrimination of subtopics in search results
with keyphrase-based clustering. Web Intelligence
and Agent Systems, 9(4):337?349.
A. Di Marco and R. Navigli. 2013. Clustering and
diversifying web search results with graph-based
word sense induction. Computational Linguistics,
39(3):709?754.
P. Ferragina and A. Gulli. 2008. A personalized search
engine based on web-snippet hierarchical clustering.
Software: Practice and Experience, 38(2):189?225.
M.A. Hearst and J.O. Pedersen. 1996. Re-examining
the cluster hypothesis: Scatter/gather on retrieval re-
sults. In 19th Annual International Conference on
Research and Development in Information Retrieval
(SIGIR), pages 76?84.
J.G. Moreno, G. Dias, and G. Cleuziou. 2013. Post-
retrieval clustering using third-order similarity mea-
sures. In 51st Annual Meeting of the Association for
Computational Linguistics (ACL), pages 153?158.
R. Navigli and G. Crisafulli. 2010. Inducing word
senses to improve web search result clustering.
In Proceedings of the 2010 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), pages 116?126.
S. Osinski, J. Stefanowski, and D. Weiss. 2004. Lingo:
Search results clustering algorithm based on singu-
lar value decomposition. In Intelligent Information
Systems Conference (IIPWM), pages 369?378.
U. Scaiella, P. Ferragina, A. Marino, and M. Ciaramita.
2012. Topical clustering of search results. In 5th
ACM International Conference on Web Search and
Data Mining (WSDM), pages 223?232.
O. Zamir and O. Etzioni. 1998. Web document clus-
tering: A feasibility demonstration. In 21st Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval (SIGIR),
pages 46?54.
H.J. Zeng, Q.C. He, Z. Chen, W.Y. Ma, and J. Ma.
2004. Learning to cluster web search results. In
27th Annual International Conference on Research
and Development in Information Retrieval (SIGIR),
pages 210?217.
5
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 6?11,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Propagation Strategies for Building Temporal Ontologies
Md. Hasanuzzaman
Normandie University
GREYC UMR 6072
Caen, France
Ga
?
el Dias
Normandie University
GREYC UMR 6072
Caen, France
St
?
ephane Ferrari
Normandie University
GREYC UMR 6072
Caen, France
Yann Mathet
Normandie University
GREYC UMR 6072
Caen, France
Abstract
In this paper, we propose to build temporal
ontologies from WordNet. The underlying
idea is that each synset is augmented with
its temporal connotation. For that purpose,
temporal classifiers are iteratively learned
from an initial set of time-sensitive synsets
and different propagation strategies to give
rise to different TempoWordNets.
1 Introduction
Temporality has recently received increased at-
tention in Natural Language Processing (NLP)
and Information Retrieval (IR). Initial works have
been proposed in NLP and are exhaustively sum-
marized in (Mani et al., 2005). More recently,
the introduction of the TempEval task (Verhagen
et al., 2009) in the Semantic Evaluation workshop
series has clearly established the importance of
time to deal with different NLP tasks. The ulti-
mate aim of research in this area is the automatic
identification of temporal expressions (timexes),
events and temporal relations within a text in the
TimeML format (Pustejovsky et al., 2005).
In IR, the time dimension has also received par-
ticular attention for the past few years. Accord-
ing to (Metzger, 2007), time is one of the key five
aspects that determine a document credibility be-
sides relevance, accuracy, objectivity and cover-
age. So, the value of information or its quality is
intrinsically time-dependent. As a consequence, a
new reasearch field called Temporal Information
Retrieval (T-IR) has emerged (Alonso et al., 2011)
and deals with all classical IR tasks such as crawl-
ing (Kulkarni et al., 2011), indexing (Anand et al.,
2012) or ranking (Kanhabua et al., 2011) from the
time viewpoint.
However, both NLP and IR evidence the lack
of temporal lexical resources. For example, auto-
matic temporal ordering of events in text is usu-
ally performed via various linguistic mechanisms
including the use of time expressions such as ?be-
fore?,?after? or ?during? that explicitly assert a
temporal relation. In particular, (Derczynski and
Gaizauskas, 2012) investigate the role of tempo-
ral signals in temporal relation extraction over the
TimeBank annotated corpus. However, the list of
such expressions is limited. From the IR view-
point, most methodologies rely on the presence of
explicit timexes and hardly bridge the gap when
no explicit mention of time is available. One re-
cent exception is proposed in (Jatowt et al., 2013)
where text time-tagging is seen as a classification
task, but no use of specific temporal clues is intro-
duced or proposed.
Inspired by SentiWordNet (Esuli and Sebas-
tiani, 2006), we propose to introduce the tempo-
ral connotation of each synset in WordNet (Miller,
1995) by iteratively learning temporal classifiers
from an initial set of time-sensitive synsets and a
given propagation strategy. As such, each synset
is automatically time-tagged with four dimensions
i.e. atemporal, past, present and future, thus giv-
ing rise to different TempoWordNets depending
on the propagation strategy.
TempoWordNets are evaluated both manually
and automatically. First, results show that man-
ual annotation of time-tagged synsets is a hard
task for humans. Second, automatic evaluation
based on sentence temporal classification shows
that the introduction of time-augmented lexical
knowledge bases (TempoWordNets) allows 3.9%
improvements of F
1
-measure against the vector
space model representation and 4.2% against the
semantic vector space model obtained with the ex-
isting WordNet time subtree.
2 Related Work
A great deal of works have been proposed in tem-
poral NLP. Most recent studies have been devel-
oped in the context of the TempEval evaluation
contests, which were initiated by (Verhagen et al.,
6
2007). TempEval was initially divided into three
challenges: (A) identifying temporal relations be-
tween events and time expressions, (B) identifying
temporal relations between events and the docu-
ment creation time and (C) identifying the tem-
poral relations between contiguous pairs of matrix
verbs. In TempEval-2 (Pustejovsky and Verhagen,
2009), the best performing systems were based
on conditional random fields mixed with parsing
methodologies (UzZaman and Allen, 2010). More
recently, in TempEval-3 (UzZaman et al., 2013),
new systems have been performing at high level
of performance for all three tasks such as the
rule-based multilingual temporal tagger Heidel-
time (Str?otgen and Gertz, 2013). In IR, the work
of (Baeza-Yates, 2005) defines the foundations of
T-IR. Since, research have been tackling several
topics such as query understanding (Metzler et al.,
2009), temporal snippets generation (Alonso et al.,
2007), temporal ranking (Kanhabua et al., 2011),
temporal clustering (Alonso et al., 2009), future
retrieval (Radinsky and Horvitz, 2013) or tempo-
ral image retrieval (Dias et al., 2012).
As expressed in (Str?otgen and Gertz, 2013),
time taggers usually contain pattern files with
words and phrases, which are typically used to
express temporal expressions in a given language
(e.g. names of months). In fact, most temporal
NLP tasks rely on a time-sensitive vocabulary. On
the contrary, T-IR systems usually do not use in-
formation about time in language although they
could benefit from it when facing the recurrent
problem of missing explicit timexes.
WordNet is a good place to start to find time-
sensitive concepts. Indeed, one can list a set
of 21 temporal synsets by iteratively following
the hyponym relation from the concept of time
(synset # 00028270) represented by the follow-
ing gloss: the continuum of experience in which
events pass from the future through the present to
the past. However, likewise the tennis problem ev-
idenced in (Fellbaum, 1998), most temporal words
are not under the concept of time. For example,
concepts such as ?prediction?, ?remember?, ?an-
cient? or ?fresh? clearly have a time dimension al-
though they are not listed under the time subtree
of WordNet. Based on the intial ideas of (Moens
and Steedman, 1987) on temporal ontologies and
inspired by SentiWordNet (Esuli and Sebastiani,
2006), we propose to enrich all WordNet synsets
with their temporal connotation.
3 TempoWordNet as SentiWordNet
In (Dias et al., 2014), we first proposed to build
TempoWordNet based on the idea of (Esuli and
Sebastiani, 2006) for SentiWordNet. Each synset
is automatically time-tagged with four dimensions
i.e. atemporal, past, present and future by per-
forming a two-step process.
A first temporal classifier is built based on a set
of manually selected seed synsets and their corre-
sponding glosses tagged as past, present and fu-
ture. This process is then iterated based on the
repetitive lexico-semantic expansion
1
of the initial
seeds lists until cross-validation accuracy drops.
This first step results in a three-class temporal
classifier and an expanded list of temporal synset
candidates.
A second temporal classifier is then learned to
time-tag synsets as atemporal or temporal. This
process is obtained by taking the final list of ex-
panded seed synsets from the previous learning
problem and randomly choosing a balanced num-
ber atemporal synsets. A 10-fold cross-validation
is then used to learn the model.
TempoWordNet is finally obtained by (1) classi-
fying all WordNet synsets as atemporal or tempo-
ral with the second classifier and (2) the resulting
temporal synsets are tagged as past, present and
future by the first classifier. This step is detailed in
(Dias et al., 2014) and all materials can be found
at http://tempowordnet.greyc.fr.
4 Diversified Expansion Strategies
The initial strategy proposed in the previous sec-
tion evidences a clear lack. As the expansion pro-
cess is semantically driven, the temporal conno-
tation is highly depend on the initial seeds lists
and as a consequence may not spread over a wide
range of concepts in WordNet. As such, we pro-
pose two different strategies of expansion: (1) the
probabilistic expansion and (2) the hybrid (proba-
bilistic combined with semantic) expansion.
Probabilistic Expansion: We first learn a tem-
poral vs. atemporal classifier based on the ini-
tial hand-crafted set of seeds proposed in (Dias
et al., 2014). In particular, the seeds defined as
past, present and future are markers of temporal-
ity, while the list of atemporal synsets is the ob-
vious counterpart. Based on this list of tempo-
1
Only exisiting lexico-semantic links inWordNet are used
to propagate the temporal connotation.
7
ral and atemporal synsets, a 10-fold cross vali-
dation process is performed to learn the temporal
vs. atemporal model, which is used to time-tag
the whole WordNet. The synsets (or glosses) with
highest temporal and atemporal values in Word-
Net are then used for the expansion process of the
seeds lists. The process is iteratively performed
and stops when accuracy drops.
After building the temporal vs. atemporal clas-
sifier, WordNet is divided into two subsets: tem-
poral synsets and atemporal ones. In order to
fine tune the temporal part of WordNet, we learn
a three-class classifier (i.e. past, present and fu-
ture) based on the initial past, present and future
seeds lists and the probabilistic expansion exclu-
sively
2
within the temporal part of WordNet. So, a
10-fold cross validation process is iteratively per-
formed until accuracy drops.
The results of the probabilistic expansion are
presented in Table 1 and Table 2, when the expan-
sion is based on the maximum probability value
3
.
Steps 1 2 3
Precision 87.3 100 100
Recall 86.7 100 100
F
1
-measure 86.9 100 100
Table 1: Cross validation for temporal vs. atem-
poral at each iteration. Probabilistic Expansion.
Steps 1 2 3
Precision 80.0 99.7 99.6
Recall 80.1 99.7 99.6
F
1
-measure 80.0 99.7 99.6
Table 2: Cross validation for past, present and fu-
ture at each iteration. Probabilistic Expansion.
Note that in our experiment, Support Vector
Machines (SVM) with a linear kernel
4
over the
vector space model representation of the synsets
(i.e. each synset is represented by its gloss en-
coded as a vector of unigrams weighted by their
frequency) have been used to classify all the
synsets of WordNet. The results show that in both
cases the expansion process stops at iteration 2.
2
Only temporal synsets are classified as past, present or
future and used for the expansion process. Note that unbal-
anced sets can be formed.
3
That means that all the synsets getting the highest value
produced by the classifier are used to expand the initial seeds
lists.
4
We used theWeka implementation SMOwith default pa-
rameters.
Hybrid Expansion: Choosing synsets from
WordNet with highest probability assigned by a
classifier learned on the glosses of initial seeds
lists can lead to the well-known semantic shift
problem. So, the idea of the hybrid expansion
is to control the expansion process so that the
most probable time-sensitive synsets are also cho-
sen based on their semantic distance with the ex-
panded seed synsets at the previous iteration. The
process is straightforward when compared to the
probabilistic expansion.
First, a two-class (temporal vs. atemporal) text
classifier is trained based on the glosses of each
synsets contained in the initial seed lists to clas-
sify all the synsets of WordNet. Thereafter, Word-
Net synsets with highest probability are selected as
candidates for expansion. From these candidates,
only the ones that present the maximum seman-
tic similarity to the previous seeds lists are cho-
sen for expansion. Note that the semantic simi-
larity is calculated between the candidate synset
and all synsets in the previous expanded seeds
lists. Once candidates for expansion have been
chosen, a 10-fold cross validation process is itera-
tively performed until accuracy becomes steady.
Second, a three-class (past, present and fu-
ture) classifier is learned over the temporal part of
WordNet with the hybrid expansion process in the
same exact manner as explained for the previous
probabilistic expansion. Results for the expansion
process are presented in the Table 3 and Table 4
for the same experimental setups as for the prob-
abilistic expansion and using the (Leacock et al.,
1998) semantic similarity measure
5
.
Steps 1 2 ... 25 26 27
Precision 87.3 94.1 ... 96.0 97.2 96.6
Recall 86.7 93.2 ... 95.5 97.0 96.3
F
1
-measure 86.9 93.6 ... 95.7 97.1 96.4
Table 3: Cross validation for temporal vs. atem-
poral at each iteration. Hybrid Expansion.
Steps 1 2 ... 15 16 17
Precision 80.0 75.7 ... 95.7 96.4 95.6
Recall 80.1 74.3 ... 95.1 96.0 95.0
F
1
-measure 80.0 74.9 ... 95.4 96.2 95.3
Table 4: Cross validation for past, present and fu-
ture at each iteration. Hybrid Expansion.
5
Different configurations as well as different similarity
metrics have been tested but these experiments are out-of-
the-scope of this paper.
8
Representation Uni.+SW Uni.+SW+Wn Uni.+SW+TWnL Uni.+SW+TWnP Uni.+SW+TWnH
Precision 85.8 85.6 87.8 89.8 89.5
Recall 85.7 85.3 87.8 89.5 89.4
F
1
-measure 85.8 85.4 87.8 89.6 89.4
Table 5: Evaluation results for sentence classification with different TempoWordNets. Balanced corpus:
346 sentences for past, 346 sentences for present and 346 sentences for future.
Evaluation: In order to intrinsically evaluate
the time-tagged WordNets (TempoWordNets), we
first performed an inter-annotation process over
samples of 50 automatically time-tagged Word-
Net synsets. In particular, three different anno-
tators were presented with temporal synsets and
their respective glosses, and had to decide upon
their correct classification (temporal vs. atempo-
ral). The results of the multirater agreement eval-
uation are presented in Table 6. In particular, we
processed the free-marginal multirater kappa val-
ues (Randolph, 2005) and the fixed-marginal mul-
tirater kappa (Siegel and Castellan, 1988) as no
bias is present in the data. Overall figures assess
moderate agreement for the three TempoWord-
Nets: TWnL for the lexico-semantic expansion,
TWnP for the probabilistic expansion and TWnH
for the hybrid expansion.
Metric TWnL TWnP TWnH
Fixed-marginal ? 0.5073 0.5199 0.4197
Free-marginal ? 0.5199 0.5199 0.4399
Table 6: Inter-annotator agreement.
These results evidence the difficulty of the task
for humans as they do not agree on a great deal of
decisions. This is particularly due to the fact that
the temporal dimension of synsets is judged upon
their glosses and not directly on their inherent con-
cept. For example, ?dinosaur? can be classified as
temporal or atemporal as its gloss any of numer-
ous extinct terrestrial reptiles of the Mesozoic era
allows both interpretations.
So, we performed a new experiment based on
those examples where human annotator agreement
was 100%. From this dataset, we performed an
inter-annotator agreement process with four an-
notators (three human annotators plus the classi-
fier). The underlying idea is to understand to what
extent the built TempoWordNets comply with the
?easy? cases. Results are illustrated in Table 7 and
clearly show the enhanced intrinsic quality of the
hybrid expansion strategy with an almost adequate
agreement for the free-marginal ?.
Metric TWnL TWnP TWnH
Fixed-marginal ? 0.4133 0.4767 0.5655
Free-marginal ? 0.4242 0.5161 0.6896
Table 7: Inter-annotation for ?easy? cases.
5 Sentence Temporal Classification
In order to evaluate TempoWordNets, we pro-
posed to test their capability to enhance the exter-
nal task of sentence temporal classification. For
that purpose, we used the corpus developed by
(Dias et al., 2014), which contains 1455 sen-
tences distributed as follows: 724 for past, 385
for present and 346 for future. Different sentence
representations have been used. First, we pro-
posed to represent each sentence with the classi-
cal vector space model using the tf.idf weighting
scheme for unigrams without stop-words removal
(Uni.+SW). Then, we proposed a semantic vector
space representation where each sentence is aug-
mented with the synonyms of any temporal word
contained in it. In particular, we proposed that
the words were matched directly from the Word-
Net time subtree (Uni.+SW+Wn) or from Tem-
poWordNet (Uni.+SW+TWnL, Uni.+SW+TWnP
and Uni.+SW+TWnH) and weighted with tf.idf.
The results of our experiments are reported in Ta-
ble 5. The results evidence that the WordNet time
subtree does not embody enough time-related in-
formation and the process of automatically time-
tagging WordNet can improve the task of sentence
temporal classification, especially with the proba-
bilistic or the hybrid expansion.
6 Conclusion
In this paper, we proposed the first steps towards
the automatic construction of temporal ontologies.
In particular, we presented and evaluated different
propagation strategies to time tag WordNet giving
rise to different TempoWordNets. First results are
promising and we deeply believe that such a re-
source can be important for time related applica-
tions both in NLP and IR. All resources can be
found at http://tempowordnet.greyc.fr.
9
References
O. Alonso, R. Baeza-Yates, and M. Gertz. 2007. Ex-
ploratory search using timelines. In Proceedings of
the ACM SIGCHI Workshop on Exploratory Search
and HCI.
O. Alonso, M. Gertz, and R. Baeza-Yates. 2009. Clus-
tering and exploring search results using timeline
constructions. In Proceedings of the 18th ACM
Conference on Information and Knowledge Man-
agement (CIKM), pages 97?106. ACM.
O. Alonso, J. Str?otgen, R. Baeza-Yates, and M. Gertz.
2011. Temporal information retrieval: Challenges
and opportunities. In Proceedings of the 1st Interna-
tional Temporal Web Analytics Workshop (TWAW),
pages 1?8.
A. Anand, S. Bedathur, K. Berberich, and R. Schenkel.
2012. Index maintenance for time-travel text search.
In Proceedings of the 35th International ACM Con-
ference on Research and Development in Informa-
tion Retrieval (SIGIR), pages 235?244.
Ricardo Baeza-Yates. 2005. Searching the future. In
Proceedings of the ACM SIGIR Workshop on Math-
ematical/Formal Methods in Information Retrieval,
pages 1?6.
L. Derczynski and R. Gaizauskas. 2012. A corpus-
based study of temporal signals. arXiv:1203.5066.
G. Dias, J.G. Moreno, A. Jatowt, and R. Campos.
2012. Temporal web image retrieval. In Proceed-
ings of the 19th Edition of the International Sympo-
sium on String Processing and Information Retrieval
(SPIRE), pages 199?204. Springer.
G. Dias, Md. Hasanuzzaman, S. Ferrari, and Y. Mathet.
2014. Tempowordnet for sentence time tagging. In
Proceedings of the 4th ACM Temporal Web Analyt-
ics Workshop (TEMPWEB).
A. Esuli and F. Sebastiani. 2006. Sentiwordnet:
A publicly available lexical resource for opinion
mining. In Proceedings of the 5th Conference on
Language Resources and Evaluation (LREC), pages
417?422.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. Bradford Books.
A. Jatowt, C.-M. Au Yeung, and K. Tanaka. 2013. Es-
timating document focus time. In Proceedings of the
22nd ACM International Conference on Information
and Knowledge Management (CIKM), pages 2273?
2278.
N. Kanhabua, R. Blanco, and M. Matthews. 2011.
Ranking related news predictions. In Proceedings of
the 34th International ACMConference on Research
and Development in Information Retrieval (SIGIR),
pages 755?764.
A. Kulkarni, J. Teevan, K.M. Svore, and S. Dumais.
2011. Understanding temporal query dynamics. In
Proceedings of the 4th ACM International Confer-
ence on Web Search and Data Mining (WSDM),
pages 167?176.
C. Leacock, G.A. Miller, and M. Chodorow. 1998.
Using corpus statistics and wordnet relations for
sense identification. Computational Linguisics,
24(1):147?165.
I. Mani, J. Pustejovsky, and R. Gaizauskas. 2005. The
language of time: a reader, volume 126. Oxford
University Press.
M.J. Metzger. 2007. Making sense of credibility on
the web: Models for evaluating online information
and recommendations for future research. Journal
of the American Society for Information Science and
Technology, 58(13):2078?2091.
D. Metzler, R. Jones, F. Peng, and R. Zhang. 2009.
Improving search relevance for implicitly temporal
queries. In Proceedings of the 32nd International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval (SIGIR), pages 700?
701.
G.A. Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39?
41.
M. Moens and M. Steedman. 1987. Temporal ontol-
ogy in natural language. In Proceedings of the 25th
Annual Meeting on Association for Computational
Linguistics (ACL), pages 1?7.
J. Pustejovsky and M. Verhagen. 2009. Semeval-
2010 task 13: evaluating events, time expressions,
and temporal relations (tempeval-2). In Proceedings
of the Workshop on Semantic Evaluations: Recent
Achievements and Future Directions, pages 112?
116.
J. Pustejovsky, B. Ingria, R. Sauri, J. Castano,
J. Littman, R. Gaizauskas, A. Setzer, G. Katz, and
I. Mani. 2005. The specification language timeml.
The language of time: A reader, pages 545?557.
K. Radinsky and E. Horvitz. 2013. Mining the web
to predict future events. In Proceedings of the 6th
ACM International Conference on Web Search and
Data Mining (WSDM), pages 255?264.
J.J. Randolph. 2005. Free-marginal multirater kappa
(multirater ?free): an alternative to fleiss? fixed-
marginal multirater kappa. Joensuu Learning and
Instruction Symposium.
N. Siegel and J.N. Castellan. 1988. Nonparametric
Statistics for the Social Sciences. Mcgraw-hill edi-
tion.
J. Str?otgen and M. Gertz. 2013. Multilingual and
cross-domain temporal tagging. Language Re-
sources and Evaluation (LRE), 47(2):269?298.
10
N. UzZaman and J.F. Allen. 2010. Trips and trios
system for tempeval-2: Extracting temporal infor-
mation from text. In Proceedings of the 5th Inter-
national Workshop on Semantic Evaluation, pages
276?283.
N. UzZaman, H. Llorens, L. Derczynski, M. Verhagen,
J. Allen, and J. Pustejovsky. 2013. Semeval-2013
task 1: Tempeval-3: Evaluating time expressions,
events, and temporal relations. In Proceedings of the
7th International Workshop on Semantic Evaluation
(SemEval).
M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple,
G. Katz, and J. Pustejovsky. 2007. Semeval-2007
task 15: Tempeval temporal relation identification.
In Proceedings of the 4th International Workshop on
Semantic Evaluations, pages 75?80.
M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple,
J. Moszkowicz, and J. Pustejovsky. 2009. The tem-
peval challenge: Identifying temporal relations in
text. Language Resources and Evaluation (LRE),
43(2):161?179.
11
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 305?308,
Dublin, Ireland, August 23-24, 2014.
HulTech: A General Purpose System for Cross-Level Semantic Similarity
based on Anchor Web Counts
Jose G. Moreno Rumen Moraliyski Asma Berrezoug Ga
?
el Dias
Normandie University
UNICAEN, GREYC CNRS
F-14032 Caen, France
firstname.lastname@unicaen.fr
Abstract
This paper describes the HULTECH team par-
ticipation in Task 3 of SemEval-2014. Four
different subtasks are provided to the partici-
pants, who are asked to determine the semantic
similarity of cross-level test pairs: paragraph-
to-sentence, sentence-to-phrase, phrase-to-
word and word-to-sense. Our system adopts
a unified strategy (general purpose system) to
calculate similarity across all subtasks based
on word Web frequencies. For that purpose,
we define ClueWeb InfoSimba, a cross-level
similarity corpus-based metric. Results show
that our strategy overcomes the proposed base-
lines and achieves adequate to moderate re-
sults when compared to other systems.
1 Introduction
Similarity between text documents is considered a
challenging task. Recently, many works concentrate on
the study of semantic similarity for multi-level text doc-
uments (Pilehvar et al., 2013), but skipping the cross-
level similarity task. In the later, the underlying idea is
that text similarity can be considered between pairs of
text documents at different granularities levels: para-
graph, sentence, phrase or word. One obvious partic-
ularity of this task is that text pairs may not share the
same characteristics of size, context or structure, i.e.,
the granularity level.
In task 3 of SemEval-2014, two different strategies
have been proposed to solve this issue. On the one
hand, participants may propose a combination of indi-
vidual systems, each one solving a particular subtask.
On the other hand, a general purpose system may be
proposed, which deals with all the subtasks following
the exact same strategy.
In this paper, we describe a language-independent
corpus-based general purpose system, which relies on
a huge freely available Web collection called Anchor-
ClueWeb12 (Hiemstra and Hauff, 2010). In particular,
we calculate ClueWeb InfoSimba
1
a cross-level seman-
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
1
It is a Web version of InfoSimba (Dias et al., 2007).
tic similarity based on word-word frequencies. Indeed,
these frequencies are captured by the use of a colloca-
tion metric called SCP
2
(Silva et al., 1999), which has
similar properties as the well studied PMI-IR (Turney,
2001) but does not over-evaluate rare events.
Our system outputs a normalized (between 0 and 1)
similarity value between two pieces of texts. However,
the subtasks proposed in task 3 of SemEval-2014 in-
clude a different scoring scale between 0 and 4. To
solve this issue, we applied linear, polynomial and ex-
ponential regressions as three different runs. Results
show that our strategy overcomes the proposed base-
lines and achieves adequate to moderate results when
compared to other systems.
2 System Description
Our system is based on a reduced version of the
ClueWeb12 dataset called Anchor ClueWeb12 and an
informative attributional similarity measure called In-
foSimba (Dias et al., 2007) adapted to this dataset.
2.1 Anchor ClueWeb12 Dataset
The Anchor ClueWeb12 dataset contains 0.5 billion
Web pages, which cover about 64% of the total num-
ber of Web pages in ClueWeb12. The particularity of
Anchor ClueWeb12 is that each Web page is repre-
sented by the anchor texts of the links pointing to it
in ClueWeb12. Web pages are indexed not on their
content but on their references. As such, the size of
the index is drastically reduced and the overall results
are consistent with full text indexing as discussed in
(Hiemstra and Hauff, 2010).
For development purposes, this dataset was indexed
in Solr 4.4 on a desktop computer using a batch in-
dexing script. Particularly, each compressed part file
of the Anchor ClueWeb12 was uncompressed, prepro-
cessed and indexed in a sequential way using the fea-
tures of incremental indexing offered by Solr (Smiley
and Pugh, 2009).
2.2 InfoSimba
In (Dias et al., 2007), the authors proposed the hypothe-
sis that two texts are similar if they share related (even-
tually different) constituents. So, their concept of simi-
2
Symmetric Conditional Probability.
305
larity is not any more based on the exact match of con-
stituents but relies on related constituents (e.g. words).
For example, it is clear that the following text pieces
extracted from the sentence-to-phrase subtask are re-
lated
3
although they do not share any word.
1. he is a nose-picker
2. an uncouth young man
The InfoSimba similarity measure models this phe-
nomenon evaluating individual similarities between all
possible words pairs. Indeed, each piece of text is rep-
resented by the vector of its words. So, given two
pieces of texts X
i
and X
j
, their similarity is defined
in Equation 1 where SCP (., .) is the Symmetric Con-
ditional Probability association measure proposed in
(Silva et al., 1999) and defined in Equation 2.
IS(X
i
, X
j
) =
1
pq
p
?
k=1
q
?
l=1
SCP (w
ik
, w
jl
). (1)
SCP (w
ik
, w
jl
) =
P (w
ik
, w
jl
)
2
P (w
ik
)? P (w
jl
)
. (2)
Following the previous example, the In-
foSimba value between the two vectors
X
1
= {?he?, ?is?, ?a?, ?nose-picker?} and
X
2
= {?an?, ?uncouth?, ?young?, ?man?} is
an average weight formed by all possible words pairs
associations as illustrated in Figure 1. Note that each
vertex is a word of a X
l
vector and each edge is
weighted by the SCP (., .) value of the connected
words. In particular, each w
ij
corresponds to the
word at the j
th
position in vector X
i
, P (., .) is the
joint probability of two words appearing in the same
document, P (.) is the marginal probability of any
word appearing in a document and p (resp. q) is the
size of the vector X
i
(resp. X
j
).
Figure 1: Pairs of words evaluated when InfoSimba is
calculated.
In the case of task 3 of SemEval-2014, each text
pair is represented by two word vectors for which a
modified version of InfoSimba, ClueWeb InfoSimba,
is computed.
3
The score of this pair (#85) in the training set is the max-
imum value 4.
2.3 ClueWeb InfoSimba
The final similarity metric, called ClueWeb InfoSimba
(CWIS), between two pieces of texts is defined in
Equation 3, where hits(w) returns the number of doc-
uments retrieved by Solr over Anchor ClueWeb12 for
the query w and hits(w
a
? w
b
) is the number of doc-
uments retrieved when both words are present simul-
taneously. In this case, SCP is modified into SCP-IR
similarly as PMI is to PMI-IR, i.e., using hits counts
instead of probability values (see Equation 4).
CWIS(X
i
, X
j
) =
1
pq
p
?
k=1
q
?
l=1
SCP ? IR(w
ik
, w
jl
).
(3)
SCP ? IR(w
ik
, w
jl
) =
hits(w
ik
? w
jl
)
2
hits(w
ik
).hits(w
jl
)
. (4)
2.4 System Input
The task 3 of SemEval-2014 consists of (1) paragraph-
to-sentence, (2) sentence-to-phrase, (3) phrase-to-word
and (4) word-to-sense subtasks. Before submitting the
pieces of texts to our system, we first performed simple
stop-words removal with the NLTK toolkit (Bird et al.,
2009). Note that in the case of the word-to-sense sub-
task, the similarity is performed over the word itself
and the gloss of the corresponding sense
4
.
2.5 Output Values Transformations
The CWIS(., .) similarity metric returns a value be-
tween 0 and 1. However, the subtasks suppose that
each pair must be attributed a score between 0 and 4.
As such, an adequate scale transformation must be per-
formed. For that purpose, we proposed linear, polyno-
mial and exponential regressions and submitted three
different runs, one for each regression
5
. Note that the
regressions have been tuned on the training dataset us-
ing the respective R regression functions with default
parameters:
? lm(y ? x),
? lm(y ? x + I(x
2
) + I(x
3
)),
? lm(log(y + ) ? x),
where 
6
is a small value included to avoid undefined
log values. The regression results on the test datasets
are presented in Figure 2.
4
Glosses are obtained from WordNet using the sense id
provided for the task by the organizers.
5
In the case of linear and exponential, these are mono-
thetic functions therefore ranking-based evaluation metrics
give the same score before and after this step.
6
In our experiments, this value was set to 0.001.
306
Figure 2: Linear, polynomial and exponential predic-
tions for the test dataset of the paragraph-to-sentence
subtask (colored dots). Black dots correspond to the
obtained ClueWeb InfoSimba value versus the manu-
ally assigned score in the training dataset.
3 Evaluation and Results
For evaluation purposes, two metrics have been se-
lected by the organizers: Pearson correlation (Pearson,
1895) and Spearman?s rank correlation (Hollander and
Wolfe, 1973). Detailed information about the evalu-
ation setup can be found in the task discussion paper
(Jurgens et al., 2014).
All results are given in Tables 1 and 2 for each
run. Note that the baseline metric is calculated for the
longest common string (LCS) and that each regression
has been tuned on the training dataset for each one of
the four tasks.
First, in almost all cases, the results outperform the
baseline. Second, performances show that with a cer-
tain amount of information (longer pieces of texts), in-
teresting results can be obtained. However, when the
size decreases, the performance diminishes and extra
information is certainly needed to better capture the se-
mantics between two pieces of text. Third, the poly-
nomial regression provides better results for the Pear-
son correlation evaluation, while for the Rho test, linear
and polynomial regressions get the lead. Note that this
situation depends on the data distribution and cannot
be seen as a conclusive remark. However, it is cer-
tainly an important subject of study for our unsuper-
vised methodology.
Another key point is that training examples were
used only for evaluation purposes
7
. In the case of
Spearman?s rank correlation, the linear and exponen-
7
For Pearson correlation, valid interval was fixed to [0,4].
tial transformations obviously show exact same values
(See Table 2).
4 Conclusions
In this paper, we proposed a general purpose system
to deal with cross-level text similarity. The aim of
our research was to push as far as possible the lim-
its of language-independent corpus-based solutions in
a general context of text similarity. We were also con-
cerned with reproducibility and as such we exclusively
used publicly available datasets and tools
8
. The results
clearly show the limits of a simple solution based on
word statistics. Nevertheless, the framework can easily
be empowered with the straightforward introduction of
more competitive resources.
Acknowledgement
The authors would like to thank the University of
Mostaganem (Algeria) for providing an internship to
Asma Berrezoug at the Normandie University.
References
Steven Bird, Ewan Klein, and Edward Loper.
2009. Natural Language Processing with Python.
O?Reilly Media, Inc., 1st edition.
Ga?el Dias, Elsa Alves, and Jos?e Gabriel Pereira Lopes.
2007. Topic segmentation algorithms for text sum-
marization and passage retrieval: An exhaustive
evaluation. In Proceedings of AAAI, pages 1334?
1339.
Djoerd Hiemstra and Claudia Hauff. 2010. Mirex:
Mapreduce information retrieval experiments. In
CTIT Technical Report TR-CTIT-10-15, Centre for
Telematics and Information Technology, University
of Twente, pages 1?8.
Myles Hollander and Douglas A. Wolfe. 1973. Non-
parametric Statistical Methods. John Wiley and
Sons, New York.
David Jurgens, Mohammad Taher Pilehvar, and
Roberto Navigli. 2014. Task 3: Cross-level seman-
tic similarity. In Proceedings of SemEval-2014.
Karl Pearson. 1895. Note on regression and inheri-
tance in the case of two parents. Proceedings of the
Royal Society of London, 58(347-352):240?242.
Mohammad Taher Pilehvar, David Jurgens, and
Roberto Navigli. 2013. Align, disambiguate and
walk: A unified approach for measuring semantic
similarity. In Proceedings of ACL, pages 1341?
1351.
Joaquim Ferreira da Silva, Ga?el Dias, Sylvie Guillor?e,
and Jos?e Gabriel Pereira Lopes. 1999. Using local-
maxs algorithm for the extraction of contiguous and
8
Scripts to Index the Anchor ClueWeb12 Dataset are
available under request.
307
Method Paragraph2Sentence Sentence2Phrase Phrase2Word Word2Sense
Linear (run 3) 0.669 0.671 0.232 0.137
Polynomial (run 1) 0.693 0.665 0.254 0.150
Exponential (run 2) 0.667 0.633 0.180 0.169
Baseline (LCS) 0.527 0.562 0.165 0.109
Table 1: Overall results for the Pearson correlation.
Method Paragraph2Sentence Sentence2Phrase Phrase2Word Word2Sense
Linear (run 3) 0.688 0.633 0.260 0.124
Polynomial (run 1) 0.666 0.633 0.260 0.126
Exponential (run 2) 0.688 0.633 0.260 0.124
Baseline (LCS) 0.613 0.626 0.162 0.130
Table 2: Overall results for the Spearman?s rank correlation.
non-contiguous multiword lexical units. In Proceed-
ings of EPIA, pages 113?132.
David Smiley and Eric Pugh. 2009. Solr 1.4 Enter-
prise Search Server. Packt Publishing.
Peter Turney. 2001. Mining the web for synonyms:
Pmi-ir versus lsa on toefl. In Proceedings of ECML,
pages 491?502.
308
Proceedings of the 25th International Conference on Computational Linguistics, pages 95?102,
Dublin, Ireland, August 23-29 2014.
A Hybrid Segmentation of Web Pages for Vibro-Tactile Access on 
Touch-Screen Devices 
  Waseem Safi1    Fabrice Maurel1   Jean-Marc Routoure1, 2    Pierre Beust1     Ga?l Dias1 
1 University of Caen Basse-Normandie - UNICAEN 
2 National Superior Engineering School of Caen - ENSICAEN   
    14032 Caen - France   
firstName.lastName@unicaen.fr 
 
Abstract 
           Navigating the Web is one of important missions in the field of computer accessibility. 
Many specialized techniques for Visually Impaired People (VIP) succeed to extract the visual 
and textual information displayed on digital screens and transform it in a linear way: either 
through a written format on special Braille devices or a vocal output using text-to-speech syn-
thesizers. However, many researches confirm that perception of the layout of web pages en-
hances web navigation and memorization. But, most existing screen readers still fail to trans-
form the 2-dimension structures of web pages into higher orders. In this paper, we propose a 
new framework to enhance VIP web accessibility by affording a ?first glance? web page 
overview, and by suggesting a hybrid segmentation algorithm to afford nested and easy navi-
gation of web pages. In particular, the web page layout is transformed into a coarse grain 
structure, which is then converted into vibrating pages using a graphical vibro-tactile lan-
guage. First experiments with blind users show interesting issues on touch-screen devices. 
 
1 Introduction 
In October 2013, the world health organization estimated that the number of Visually Impaired 
People (VIP) in the world is 285 million: 39 million of them are blind and 246 million have low vi-
sion. In particular, the organization defined four levels of visual functions depending on the interna-
tional classification of diseases: normal vision, moderate visual impairment, severe visual impairment 
and blindness.  
VIP depend on screen readers in order to deal with computer operating systems and computational 
programs. One of most important and desired targets by VIP is navigating the Web, considering the 
increased importance and expansion of web-based computational programs. Screen readers present 
some solutions to navigate the textual and graphical contents of web pages, either by transforming a 
web page into a written Braille, or into a vocal output. In addition to these solutions, some screen 
readers installed on touch devices transform a web page into a vocal-tactile output.  
But, there are some drawbacks for these proposed solutions. On the one hand, Braille techniques are 
costly and only few number of VIP have learned Braille (in France in 2011, there were about 77,000 
visually impaired people and only 15,000 of them had learned Braille). On the other hand, transform-
ing the information of a web page into a vocal format might not be suitable in public and noisy envi-
ronments. Finally most of Braille solutions are not suitable for mobile devices [Maurel et al, 2012].  
In addition to these drawbacks, the most important one is the failure to transform the 2-dimension web 
page structure. Indeed, as reported by many authors, perceiving the 2D structure of web documents 
greatly improves navigation efficiency and memorization as it allows high level text reading strategies 
such as: rapid or cursory reading, finding or locating information, to name but a few [Maurel et al, 
2003].  
Our work focuses on developing and evaluating a sensory substitution system based on a vibro-tactile 
solution, which may solve the mentioned drawbacks. In particular, we study how to increase the VIP 
perception of a 2D web page structure and how to enhance their techniques to navigate the contents of 
This work is licensed under a Creative Commons Attribution 4.0 International Licence. License details: 
http://creativecommons.org/licenses/by/4.0/ 95
web pages on touch-screen devices. The suggested solution is very cheap compared to Braille devices 
and may be efficient in noisy and public environments compared to vocal-tactile solutions.  
Our contribution is three-fold: (1) designing a Tactile Vision Sensory System (TVSS) represented by 
an electronic circuit and an Android program in order to transform light contrasts of touch-screen de-
vices into low-frequencies tactile vibrations; (2) designing an algorithm for segmenting web pages in 
order to support the visually impaired persons by a way which may enhance their ability to navigate 
the textual and graphical contents of web pages and (3) analyzing the effects of the suggested segmen-
tation method on navigation models and tactics of blind persons, and its effect on enhancing their 
strategies for text reading and looking for textual information.    
The paper is organized as follows. First, in section 2, we review most advanced VIP targeted tech-
nologies. Then, in section 3, we describe the new proposed framework. In section 4, we view the state 
of the art for web pages segmentation methods. In the fifth section, our hybrid segmentation method is 
presented and how this method could be integrated in our framework. In section 6, we enumerate the 
desired effects of the proposed segmentation method on navigation models and tactics of blind per-
sons, and how it may enhance their strategies for text reading and searching of textual information. 
Finally, in the seventh section, perspectives and conclusions are presented. 
2 VIP targeted technologies 
Current products for VIP such as screen readers mainly depend on speech synthesis or Braille solu-
tions, e.g. ChromeVox [3], Windows-Eyes [4], or JAWS (Job Access With Speech) [5]. Braille displays 
are complex and expensive electromechanical devices that connect to a computer and display Braille 
characters. Speech synthesis engines convert texts into artificial speech, where the text is analyzed and 
transformed into phonemes. These phonemes are then processed using signal processing techniques. 
Some screen readers can also support tactile feedback when working on touch-screen devices, such 
as Mobile Accessibility [6] and Talkback [7] for Android, or VoiceOver [8] for IPad. Many of these 
products propose shortcuts for blind users to display a menu of HTML elements existing in the web 
page, for example headers, links and images. But, the main drawback of all these products is the fact 
that they transfer the information of web pages into a linear way i.e. without any indication of the 2-
dimension global structure.  
Many researches tried to enhance the way by which VIP interact with web pages, such as [Alaeldin et 
al, 2011], who proposed a tactile web navigator to enable blind people access the Web. This navigator 
extracts texts from web pages and sends them to a microcontroller responsible of displaying the text in 
Braille language using an array of solenoids. A tactile web browser for hypertext documents has been 
proposed by [Rotard et al, 2005]. This browser renders texts and graphics for VIP on a tactile graphics 
display and supports also a voice output to read textual paragraphs and to provide a vocal feedback. 
The authors implemented two exploration modes, one for bitmap graphics and another one for scalable 
vector graphics. A pin matrix device is then used to produce the output signal for blind users. The 
main drawback of these two proposed systems is that they need specific devices (solenoids and pin 
matrix), which are expensive and cannot be integrated to handled devices such as PDAs or Tablet PCs. 
Another interesting model called MAP-RDF (Model of Architecture of Web Pages) has been proposed 
by [BouIssa et al, 2011]. This model allows representing the structure of a web page and provides 
blind users with an overview of the web page layout and the document structure semantics. Tactos is a 
perceptual interaction system, which has been suggested by [Lenay et al, 2003] and consists of three 
elements: (1) tactile simulators (two Braille cells with 8 pins) represent a tactile feedback system, (2) a 
graphics tablet with a stylus represents an input device and (3) the computer. More than 30 prototypes 
of Tactos have been released to serve a lot of users in many domains. Tactos has been successfully 
used to recognize simple and complex shapes. The device has been also used in geometry teaching 
domain in an institution for visually impaired and blind children. Tactos also allowed psychology re-
searchers to propose and develop new paradigms for studying perceptions and mediated communica-
tion of blind persons [Tixier et al, 2013]. However, it shows the same drawback as the previous sys-
tems, which are expensive and need specific devices. Moreover, the blind user can only explore the 
web page with a stylus and both hands are occupied by the system. Moreover, it is unemployable for a 
large set of environments, for example in public. 
96
3 Proposed Framework 
The ?first glance? can be defined as the ability to understand the document layout and its structural 
semantics in a blink of an eye [Maurel et al, 2012]. In this work, we aim to increase the ability of visu-
ally impaired persons to understand the 2-dimension web page layout in order to enhance their tactics 
to navigate the Web with a vibro-tactile feedback. 
The first phase in our model is to extract visual structures in the navigated web page and convert these 
?visual? blocks into zones (or segments) to facilitate the navigation in later phases. We achieve this 
phase depending on a hybrid segmentation method. Then the system represents the extracted visual 
elements as symbols using a graphical language. The third phase is to browse these graphical symbols 
depending on the size of the used touched-screen device; and in the fourth phase, our system provides 
a vibro-tactile feedback when the blind user touches the tablet by giving the user a vibro-tactile feed-
back by transforming light contrasts of touch-screen devices into low-frequencies tactile vibrations. A 
tablet (Asus Model TF101 with Android operating system) has being used for our tests. 
  
To achieve the desired system, we have designed an electronic circuit, which controls two micro-
vibrators placed on two fingers. A Bluetooth connection with an android tablet allows controlling the 
vibration intensity (i.e. amplitude) of vibrators. An Android dedicated program on the tablet views an 
image on the screen and detects where the user touches the tablet screen (the viewed image represents 
the result of web page segmentation). The intensity of the light emitted by the tablet at touched points 
is then transmitted to the embedded device in order to control the vibration intensity. In this paper, we 
focus only on the first phase (extracting visual structures in the navigated web page, and convert them 
into zones), with considering that detailed description of hardware components of the system, and re-
sults of pre-tests are described in [Maurel et al, 2012] and [Maurel et al, 2013]. 
4 Related Works 
Segmenting a web page is a fundamental phase for understanding its global structure. Extracting the 
global structure of web pages is useful in many domains such as information retrieval, data extraction, 
and similarity of web pages.  
Many approaches have been suggested for segmenting web pages, such as: 
-1) DOM-based segmentation: it depends on analyzing the DOM tree (Document Object Model), and 
extracting the main structure of web pages depending on HTML tags. An example of this approach is 
the work of [Sanoja et al, 2013], which determines firstly the layout template of a web page, and then 
it divides the page into minimum blocks, and finally collects these minimum blocks into content 
blocks.  
-2) Vision-based segmentation: this method divides the web page depending on the visual view of web 
page contents on a web browser. The most famous tool depends on this approach is VIPS (VIsion 
based Page Segmentation) [Deng et al, 2003].  
-3) Image processing based segmentation: this approach captures an image for the visual view of a 
web page, and then depends on image processing techniques to divide the captured image into sub 
blocks [Cai et al, 2004] [Cao et al, 2010].  
-4) Text-based Segmentation: this approach focuses on extracting only information about texts existed 
in a web page. After dividing the web page into blocks of texts, it could be possible to find the seman-
tic relations between these textual blocks. This method is useful in many information retrieval do-
mains such as question answering applications [Foucault e al, 2013].  
-5) Fixed-length segmentation: this approach divides the web pages into fixed length blocks (pas-
sages), after removing all HTML tags, where each passage contains a fixed number of words [Callan, 
1994].  
-6) Densitometric analysis based segmentation: this approach depends on methods applied in quantita-
tive linguistics, where text-density refers to a measure for identifying important textual segments of a 
web page [Kohlsch?tter et al, 2008].  
-7) Graph-based segmentation: This approach depends on transforming the visual segments of a web 
page into graph nodes, then applying many common graph methods on these nodes for combining 
97
them into blocks, or for making a clustering for these nodes. Some common works which depend on 
this approach are [Chakrabarti et al, 2008] [Liu et al, 2011].  
-8) and Hybrid-based segmentation: This approach combines many approaches indicated previously. 
5 Suggested Hybrid Segmentation Algorithm  
Most of segmentation algorithms render firstly the web page using a web browser, and then segments 
the HTML elements into many blocks depending on the visual layout. The constructed hybrid segmen-
tation algorithm has been tested on 154 pages collected manually from many newspaper and e-
commerce sites (www.leparisien.fr, www.lefigaro.fr, www.liberation.fr, www.amazon.fr, 
www.materiel.net), and the results have been integrated with our under-development Android pro-
gram. The obtained results are promised because the segmentation algorithm can extract well the web 
page blocks depending on the visual structure, and the algorithm can also convert correctly these 
blocks into zones (clustering the blocks). Our algorithm blends three segmentation approaches, DOM-
based segmentation, vision-based segmentation, and graph-based segmentation. 
Proposed Corpora 
To achieve the previous mentioned model, we construct two corpora, one for training, and another for 
testing. We selected many criteria for crawling web pages, such as, the type of crawled pages (infor-
mation web sites, and e-commerce web sites), the size (about 10,000 pages), the language (French), 
the version of web site (Classic, Mobile), and the technology used to build the crawled web site 
(framework JavaScript: JQuery, mootools, ... / CMS: Prestashop, Drupal, Joomla...). 
5.1 Vision-Based Approach 
In this phase, we render the web page using Mozilla FireFox browser, and getting its visual structure 
by injection Java-script code inside the HTML source code of the rendered web page. The obtained 
visual structure indicates a global hierarchy of the rendered web page, and assigns a bounding box for 
each HTML element. Figure 1.a represents a part of a web page, and the result of its vision-based 
segmentation is presented in figure 1.b. 
 
              (a) A part of a web page                             (b) Vision-based segmentation  
       Figure 1. A part of a web page (leparisien.fr) and its vision-based segmentation  
 
The input of this phase is a web page HTML source code, and its output is injected information about 
bounding boxes for each HTML element. In next sections, we refer to bounding boxes by blocks (i.e. 
each bounding box represents an HTML element, and may contain other bounding boxes.).   
5.2 DOM-Based Approach 
After segmenting a web page depending on its visual structure, we analyze its DOM structure by ap-
plying filters and re-organization rules for enhancing results of next phases. Dead-Nodes filter is an 
example of these filters: it deletes all HTML nodes that do not affect on the appearance, for example 
nodes with height or width equals to ?0px? (zero pixel); or nodes with style properties ("display : 
98
none" or "visibility:hidden"). An example of re-organization rules is Paragraph-Reorganization rule, 
where this rule re-constructs all paragraph child-nodes in one node contains the extracted text; we 
made this rule after analyzing many DOM structures, and observing that some paragraph nodes con-
tain child-nodes which affect negatively on extracting the text, such as <i>, <span>, etc.., and these 
child-nodes contain important texts. We made many filters and re-organization rules, and integrated 
them with our framework, and then we tested applying these rules and filters on the vision-based seg-
mented web pages (154 pages mentioned previously). As a result of applying the two approaches (vi-
sion-based and DOM-based), we succeeded to get the first glance visual structure for many pages.  
The result of this phase is a filtered DOM-tree, each of its nodes is visible and contains a bounding 
box information. Figure 1.b represents a hierarchy of some HTML nodes, the first level contains 3 
main blocks (B1, B2, and B3), and each one contains many sub blocks, for example B3 contains B3-1 
and B3-2.  
To illustrate results of applying previous two mentioned approaches, we represented an obtained fil-
tered DOM-tree on the used tablet. Figure 2 views a graphical representation for a page web, since 
each rectangle represents a block in the analyzed web page. Red rectangles represent images (<img> 
tags), green rectangles represent links (<a> tags), blue rectangles represent list of items (<ul> or <ol> 
tags), and finally, black rectangles represent paragraphs (<p> tags).     
 
 
 
 
 
 
                           Figure 2. A graphical representation for a page web (leparisien.fr)            
 
5.3 Graph-Based Approach 
After segmenting the web page depending on its visual structures and analyzing its DOM-structure, 
we apply a new graph-based segmentation algorithm which called ?Blocks2Zones Clustering? in order 
to group many similar blocks together in one zone. Clustering many blocks together is necessary in 
order to decrease the number of viewed blocks in some interfaces (instead of viewing many blocks, we 
view one zone represents these blocks and then the user can navigate intra-elements inside the zone by 
double clicking on the graphical element of the chosen zone.), and to group closed blocks in one zone 
(here, closeness depends on distances between blocks, this will be described next sections in details). 
The pseudo-code of the proposed algorithm is: 
 
 
 
 
 
 
 
 
 
 
 
 
Blocks2Zones Clustering Algorithm 
Input (Blocks, ? of desired Zones) 
Output: Graph of  nodes ( Zones)    
1- Transform the blocks into a graph (on-Directed graph)  
     1.1. Blocks  odes, 
1.2. Make relations between the nodes, and assign weights for these relations. 
2- If number of zones >= number of blocks 
            end the algorithm, 
    Else  
    3- Find the node with the smallest size (node A) (Figure 3.a (6 zones), Figure 3.b (5 zones)) 
    4- For node A, find the relation which has the largest weight (node B). (Figure 3.a (6 zones),  
           Figure 3.b (5 zones))  
    5- Group the nodes A, and B (A+B). (Figure 3.a (5 zones), Figure 3.b (4 zones))  
    6- Repeat steps 3-4-5 till  number of blocks ==  number of zones  
 
 
99
Figure 3 represents some examples of applying this algorithm, where each rectangle represents a zone 
(a block or a collection of blocks), and the center of each ellipse represents the zone center.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
       (a) Converting 6 zones to 5 zones                                   (b) Converting 5 zones to 4 zones 
                                  Figure 3. Examples of applying Blocks2Zones clustering Algorithm 
 
To calculate weights between nodes, we tested 2 relations of distances: the first one is Minkowski 
Manhattan distance (dp, q = dq, p = |p ? q| = ? |p ? q| ), and the second is Minkowski 
Euclidian distance (dp, q = dq, p = p ? q + p ? q +?.. +p ? q). To ensure 
which distance should be used, we applied an internal quality criterion for the two used distances; the 
applied criterion is Sum of Squared Error (SSE) (SSE =  ||x