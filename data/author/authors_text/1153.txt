Jurilinguistic Engineering in Cantonese Chinese: 
An N-gram-based Speech to Text Transcription System 
B K T'sou, K K Sin, S W K Chan, T B Y Lai, C Lun, K T Ko, G K K Chan, L Y L Cheung 
Language hfformation Sciences Research Centre 
City University of Itong Kong 
Tat Chee Avenue, Kowloon 
Hong Kong SAR, China 
Email: rlbtsou @nxmail.cityu.edu.hk 
Abstract  
A Cantonese Chinese transcription system to 
automatically convert stenograph code to 
Chinese characters ix reported. The major 
challenge in developing such a system is the 
critical homocode problem because of 
homonymy. The statistical N-gram model is 
used to compute the best combination of 
characters. Supplemented with a 0.85 million 
character corpus of donmin-specific training 
data and enhancement measures, the bigram 
and trigrmn implementations achieve 95% 
and 96% accuracy respectively, as compared 
with 78% accuracy in the baseline model. The 
system perforlnance is comparable with other 
adwmced Chinese Speech-to-Text input 
applications under development. The system 
meets an urgent need o1' the .ludiciary ot: post- 
1997 Hong Kong. 
Keyword: Speech to Text, Statistical 
Modelling, Cantonese, Chinese, Language 
Engineering 
1. Introduct ion 
British rule in Hong Kong lnade English the only 
official language in the legal domain for over a 
Century. After the reversion of Hong Kong 
sovereignty to China in 1997, legal bilingualism 
has brought on an urgent need to create a 
Computer-Aided Transcription (CAT) system for 
Cantonese Chinese to produce and maintain the 
massive legally tenable records of court 
proceedings conducted in the local majority 
language (T'sou, 1993, Sin and T'sou, 1994, Lun 
et al, 1995). With the support fl'om the Hong 
Kong Judiciary, we have developed a 
transcription system for converting stenograph 
code to Chinese characters. 
CAT has been widely used for English for 
many years and awlilable R~r Mandarin Chinese, 
but none has existed for Cantonese. Althongh 
Cantonese is a Chinese dialect, Cantonese and 
Mandarin differ considerably in terms of 
phonological struclure, phouotactics, word 
morphology, vocabulary and orthogral)hy. Mutual 
intelligibility between the two dialects is generally 
very low. For example, while Cantonese has lnole 
than 700 distinct syllables, Mandarin has only 
about 400. Cantonese has 6 tone contours and 
Mandarin only 4. As for vocabulary, 16.5% of the 
words in a 1 million character corpus of court 
proceedings in Canlonese cannot be found in a 
corlms consisting of 30 million character 
newspaper texts in Modern Written Chinese 
(T'sou el al, 1997). For orthography, Mainhmd 
China uses the Simplified Chinese character set, 
and Hong Kong uses the Traditional set l~lus 
4,702 special local Cantonese Chinese characters 
(Hong Kong Government, 1999). Such 
differences between Cantonese and Mandarin 
necessitate the Jtnilinguistic Engineering 
undertaking to develop an independent Cantonese 
CAT system for the local language nvironment. 
The major challenge in developing a 
Cantonese CAT system lies in the conversion of 
phonologically-based stenograph code into 
Chinese text. Chinese is a logographic language. 
Each character or logograph represents a syllable. 
While the total inventory of Cantonese syllable 
types is about 720, them am at least 14,000 
Chinese character types. The limited syllabary 
creates many homophones in the language (T'sou, 
1976). In a one million character corlms of court 
proceedings, 565 distinct syllable types were 
found, representing 2,922 distinct character types. 
Of the 565 syllable types, 470 have 2 or morn 
homophonous characters. In the extreme case, zi 
represents 35 homophonous character types. 
1121 
Coverage ofl lomophonous and Non-homophous Characters 
100.00% ?'o o~ 4:~ ~ ~os 4:e 
80.00% 
6 
60.00% 
# 40.00% 
c~ 20.00% 
0.00% 
? No. of High Freq. Characters %~ t~ p 
\[EJ HoInophonous Charactcrs \[\] Non-honaophonous chaliactcrs\] 
Figure I. Covcragc of Homonymous Characters 
These 470 syllables represent 2,810 homophonous 
character types which account for 94.7% of the 
text, as shown in Figure \]. The homocode 
problem nmst be properly resolved to ensure 
successful conversion. 
2. Computer-Aided Transcription (CAT) 
~dJ l  
t 
? I 
co 2F2L . 
Stcnoma~h code I i 
Slzg?2 E 
I Transcription \[ | 
/ ! EIt?illC ; | 
h Trigranl ,, Big,an, i ~ '9 
=, E ) 
! 
Proofreading 
\[ i 
' I 
' Bigram / Trip, ram 
i Statistical Dala 
Chinese Text i l l :~!  
Figure 2. Automatic Transcription Process 
Figure 2 outlines the transcription process in the 
Cantonese CAT system. Following typical 
courtroom CAT systems, our process is divided 
into three major stages. In Stage 1, simultaneous 
to a litigant speaking, a stenographer inputs 
speech, i.e. a sequence of transcribed syllables or 
stenograph codes, via a stenograph code generator. 
Each stenograph code basically stands for a 
syllable. In Stage 2, the transcription software 
converts the sequence of stenograph codes \[Sl . . . . .  
s,,} into the original character text {q . . . . .  c,,}. 
This procedure requires the conversion 
component to be tightly bound to the phonology 
and orthography of a specific language. To 
specifically address homonymy in Cantonese, the 
conversion procedure in our system is supported 
by bigram and trigram statistical data derived 
from domain-specific training. In Stage 3, manual 
editing of the transcribed texts corrects errors 
from typing mistakes or his-transcription. 
3. System Architecture 
3.1 Statistical Formulation 
To resolve massive ambiguity in speech to text 
conversion, the N-gram model is used to 
determine the most probable character sequence 
{q . . . . .  ck} given the input stenograph code 
sequence {s~ . . . . .  Sk}. The conditional probability 
(1) is to be maximized. 
(1) P(q . . . . .  c~l sl . . . . .  sk) 
where {q . . . . .  c~} stands for a sequence of N 
characters, and {sl . . . . .  sk} for a sequence of k 
input stenograph codes. 
The co-occurrence frequencies necessary for 
computation are acquired through training. 
However, a huge amount of data is needed to 
generate reliable statistical estimates for (1) if 
N > 3. Consequently, N-gram probability is 
approximated by bigram or trigram estimates. 
First, rewrite (1) as (2) using Bayes' rule. 
P(c, ..... c )xP(s, ..... s lc, ..... c , )  
(2) 
P(s, ..... s k ) 
As the value of P(s I . . . . .  st) remains unchanged 
for any choice of {q . . . . .  ct}, one needs only to 
maximize the numerator in (2), i.e. (3). 
(3) P(cl ..... Ck) X P(sl ..... s,\[cl ..... ck) 
(3) can then be approximated by (4) or (5) using 
bigram and trigram models respectively. 
(4) FL=,...., (P(c,lq_,) x P(s,.Iq)) 
(5) ?P(silci)) 
The transcription program is to compute the best 
sequence of {q . . . . .  c,} so as to maximize (4) or 
(5). The advantage of the approximations in (4) 
and (5) is that P(s,lc,), P(c,lc,.,) and P(c,lc,_2c,_,) 
can be readily estimated using a training corpus of 
manageable size. 
3.2 Viterbi Algorithm 
The Viterbi algorithm (Viterbi, 1967) is 
implemented toefficiently compute the maxinmm 
value of (4) and (5) for different choices of 
1122 
character sequences. Instead o1' exhaustively 
computing tile values for all possible character 
sequences, the algorithm only keeps track of the 
probability of the best character sequence 
terminating in each possible character candidate 
for a stenograph code. 
In the trigram implelnentatiou, size limitation 
in the training cortms makes it impossible to 
estimate all possible P(c i lc i_2ci . i )  because some 
{ci_2, ci_l, q} may never occur there. Following 
Jelinek (1990), P(cil ci.2ci_ i ) is approximated by 
the summation of weighted lrigram, bigram and 
unigram estimates in (6). 
(6) p(c i I ci_ 2 ci_ 1) 
f(ci_ 2 ci- I ci ) f(ci_ 1 c i ) f(c i ) 
= w 3 X + w 2 X + w 1 X -  
f(ci_ 2 ci_ 1 ) f(ci_ I ) Z f(cj ) 
where (i) w,, w2, w-s _> 0 are weights, (ii) 
wl-l-w2-{-H; 3 = 1, and (iii) Z f(q) is the stun of 
frequencies of all characters. Typically lhe best 
results can be obtained if w:~, the weight for 
trigram, is significantly greater than the olher two 
weights so that the trigram probability has 
dominant effect in the probability expression. In 
our tests, we sot wl=0.01, w2=0.09, aud u;3=0.9. 
The Viterbi algorithm substantially reduces the 
computational complexity flom O(m") to O(m.-~n) 
and O(nr~n) using bigram and trigram estimation 
rc:spectively where n is the number of stenograph 
code tokens in a sentence, and m is tile upper 
bound of the number of homophonous characters 
for a stenograph code. 
To maximize the transcription accuracy, we 
also refine the training corpus to ensure that the 
bigram and trigram statistical models reflect the 
comtroom lauguage closely. This is done by 
enlarging tile size of tile training corpus and by 
compiling domain-specific text corpora. 
3.,3 Special Encoding 
After some initial trial tests, error analysis was 
conducted to investigate the causes of the mis- 
transcribed characters. It showed that a noticeable 
amount of errors were due to high failure rate in 
the mtriewtl of seine characters in the 
transcription. The main reason is that high 
fiequency characters are more likely to interfere 
with the correct retrieval of other relatively lower 
frequency homophouous characters. For example, 
Cantonese, hal ('to be') and hal ('at') are 
homophouous in terms of seglnental makeup. 
Their absolute fiequcucies in our training corpus 
are 8,695 and 1,614 respectively. Because of the 
large fi'equency discrepancy, the latter was mis- 
transcribed as tile former 44% of the times in a 
trial test. 32 such high fi'equency characters were 
found to contribute to about 25% of all 
transcription errors. To minimize the interference, 
special encoding, which resulted flom shallow 
linguistic processing, is applied to the 32 
characters o that each of them is assigned a 
unique stenograph code. This was readily 
accepted by the court stenographers. 
4. hnplementation and Results 
4.1 Compilation of Corpora 
In our expreriments, authentic Chinese court 
proceedings from the Hong Kong Judiciary were 
used fox tile compilation of the training and 
testing corpora for the CAT prototypes. To ensure 
that tile training data is comparable with tile data 
to be transcribed, the training corpus should be 
large enough to obtain reliable estimates for 
P(silc,.), P(cilci j) and P(cilci_2ci_l).  in our trials, 
we quickly approached the point of diminishing 
return when the size of the training corpus reaches 
about 0.85 million characters. (See Section 4.2.2.) 
To further enhance training, the system also 
exploited stylistic and lexical variations across 
different legal domains, e.g. tra\[.'fic, assauh,  and 
f raud  offences. Since different case types show 
distinct domain-specific legal vocabulary or usage, 
simply integrating all texts in a single training 
corpus may obscure the characteristics o1' specific 
language domains, thus degrading the modelling. 
Hence domain-specific training corpora were also 
compiled to enhance performance. 
Two sets of data were created for testing and 
comparison: Gener ic  Coqms (GC) and Domain -  
,specific Cmpus  (DC). Whereas GC consists of 
texts representing various legal case types, DC is 
restricted to traffic offence cases. Each set 
consists of a training corpus of 0.85 million 
characters and a testing corpus of 0.2 million 
characters. The training corpus consists of 
Chinese characters along with the corresponding 
stenograph codes, and tile testing corpus consists 
solely of stenograph codes of the Chinese texts. 
4.2 Experimental Results 
For ewfluation, several prototypes were set up to 
1123 
test how different factors affected transcription 
accuracy. They included (i) use of bigram vs. 
trigram models, (ii) the size of the training 
corpora, (iii) domain-specific training, and (iv) 
special encoding. To measure conversion 
accuracy, the output text was compared with the 
original Chinese text in each test on a character by 
character basis, and the percentage of correctly 
transcribed characters was computed. Five sets of 
experiments are reported below. 
4.2.1 Bigram vs. Trigram 
Three prototypes were developed: the Bigram 
Prototype, CA Tva2, the Trigram Prototype, CA Tva.~, 
and the Baseline Prototype, CATo. CATva2 and 
CATvA.~ implelnent he conversion engines using 
the bigram and trigram Viterbi algorithm 
respectively. CA7o, was set up to serve as an 
experimental control. Instead of implementing the 
N-gram model, conversion is accomplished by 
selecting the highest fiequency item out of the 
homophonous character set for each stenograph 
code. GC was used throughout the three 
experiments. The training and testing data sets are 
0.85 and 0.20 million characters respectively. The 
results are summarized in Table 1. 
Corpus GC GC GC 
Accuracy 78.0% 92.4% 93.6% 
Table 1. Different N-gram Models 
The application of the bigram and trigram models 
offers about 14% and 15% improvement in 
accuracy over Control Prototype, CATo. 
4.2.2 Size of Training Corpora 
In this set of tests, the size of the training corpora 
was varied to determine the impact of the training 
corpus size on accuracy. The sizes tested are 0.20, 
0.35, 0.50, 0.63, 0.73 and 0.85 million characters. 
Each corpus is a proper subset of the immediately 
larger corpus so as to ensure the comparability of 
he trainin texts. CATvA 2 was used in the tests. 
Training Corpus GC GC GC 
Accurac~ 89.5% 91.2% 91.8% 
Training Corpus GC GC GC 
Accuracy 92.1% 92.3 % 92.4 % 
Table 2. Variable Training Data Size 
The results in Table 2 show that increasing the 
size of the training corpus enhances the accuracy 
incrementally. However, the point of diminishing 
return is reached when the size reaches 0.85 
million characters. We also tried doubling the 
corpus size to 1.50 million characters. It only 
yields 0.8% gain over the 0.85 million character 
corpus. 
4.2.3 Use of Domain-specific Training 
This set of tests evaluates the effectiveness of 
domain-specific training. Data fi'oln the two 
corpora, GC and DC, are utilized in the training of 
the bigram and trigram prototypes. The size of 
each training set is 0.85 million characters. The 
same set of 0.2 million character testing data from 
DC is used in all four conversion tests. Without 
increasing the size of the training data, setups with 
domain-specific training consistently ield about 
2% improvement. A more comprehensive set of 
corpora including Tra.lfic, Assault, and Robbeo~ is
bein )iled and will be re )ortcd in future. 
Prototypes 
Training Data 
CATvA; CATvA3 CATvaz CATvA3 
GC GC DC DC 
Testing Data DC DC DC DC 
Accuracy 92.6% 92.8% 94.7% 94.8% 
Table 3. Application of Domain-Specificity 
4.2.4 Special Encoding 
Following shallow linguistic processing, special 
encoding assigns unique codes to 32 characters to 
reduce confusion with other characters. Another 
round of tests was repeated, identical to the 
CATvA2 and CATvA 3 tests in Section 4.2.1, except 
for the use of special encoding. The use of 
training and testing corpora have 0.85 and 0.20 
million characters respective 
S ~ i ~  I;:~ :::NOfA~I~Ii~: 
Prototypes CATw~ CATvA~ CATw2 CATvA3 
Corpus GC GC GC GC 
Accuracy 92.4% 93.6% 94.7% 95.6% 
Table 4. Application of Special Encoding 
Table 4 shows that the addition of special 
encoding consistently offers about 2% increase in 
accuracy. Special encoding and hence shallow 
linguistic processing provide the most significant 
improvement in accuracy. 
4.2.5 Incorporation of Domain-Specificity and 
Special Eneoding 
As discussed above, both domain-specific training 
and special encoding raise the accuracy of 
transcription. The last set of tests deals with the 
integration of the two features. Special encoding 
1124 
is utilized in the training and testing data of DC 
which have 0.85 and 0.20 million characters 
respectively. 
~raining/Testing, Data DC DC 
I S. Encoding Applied Applied / zcuracy 95.4 % 96.2 % 
Table 5. Integration of D. Specificity and S. Encoding 
Recall that Domain-Specificity and Special 
Encoding each offers 2% improvelnent. Table 5 
shows that combining BOTH features offer about 
3% improvement over tests without them. (See 
non-domain-specific tests in Section 4.2.3) 
The 96.2% accuracy achieved by CATvA 3 
represents the best performance of our system. 
The result is conaparable with other relevant 
advanced systems for speech to text conversion. 
For example, Lee (1999) reported 94% accuracy 
in a Chinese speech to text transcription system 
under developlnent with very large training 
corpus. 
5. Conclusion 
We have created a Cantonese Chinese CAT 
system which uses the phonologically-based 
stenograph machine. The system delivers 
encouragingly accurate transcription in a language 
which has many hon\]ol~honous characters. To 
resolve problematic ambiguity in the conversion 
fi'on-i a I)honologically-based code to the 
logograt)hic Chinese characters, we made use of 
lhe N-gram statistical model. The Viterbi 
algorithm has enabled us to identify the most 
probable sequence of characters from the sels of 
possible homophonous characters. With the 
additional use of special encoding and domain- 
specific training, the Cantonese CAT system has 
attained 96% transcription accuracy. The success 
of the Jurilinguistic Engineering project can 
further enhance the efforts by the Hong Kong 
Judiciary to conduct trials in the language of the 
majority population. Further improvement to the 
system will include (i) more domain-specific 
training and testing across different case types, (2) 
firm-tuning for the optimal weights in the trigram 
formula, and (3) optilnizing the balance between 
training corpus size and shallow linguistic 
processing. 
Acknowledgement  
Support for the research reported here is provided 
mainly through the Research Grants Council of 
Hong Kong under Competitive Earmarked 
Research Grant (CERG) No. 9040326. 
References 
Hong Kong Govennnent. 1999. Hong Kong 
Szq~plemenmry Character Set. hfformation 
Technology Services Department & Official 
Languages Agency. 
Jelinek, F. 1990. "Self-organized Language Modeling 
lbr Speech Recognition." In A. Waibel and K.F. 
Lee, (eds.). Readings in Speech Recognition. San 
Mateo: CA: Morgan Kaufmann Publishers. 
Lee, K. F. 1999. "Towards a Multimedia, Multimodal, 
Multilingual Computer." Paper presented on behall' 
of Microsoft Research Institute, China in the 5th 
Natural Language Processing Pacil'ic Rim 
Symposium held in Belling, China, November 5-7, 
1999. 
Lun, S., K. K. Sin, B. K. T'sou and T. A. Cheng. 1997. 
"l)iannao Fuzhu Yueyu Suii Fangan." (The 
Cantonese Shorthand System for Computer-Aided 
Transcription) (in Chinese) Proceedings o.f the 5th 
lntermttional Confere,ce on Cantonese and Other 
Yue Dialects. B. H. Zhan (ed). Guangzhou: Jinan 
University Press. pp. 217--227. 
Sin, K. K. and B. K. T'sou. 1994. "Hong Kong 
Courtroon\] Language: Some Issues on Linguistics 
and Language Technology." Paper presented at lhe 
Third International Conference on Chinese 
Linguistics. Hong Kong. 
T'sou, B. K. 1976. "Homophony and Internal Change 
in Chinese." Computational Analyses of Asian and 
African Lauguages 3, 67--86. 
T'sou, t3. K. 1993. "Some Issues on Law and Language 
in the ltong Kong Special Administrative Region 
(HKSAR) of China." Language, Law attd Equality: 
Proceedings of the 3rd International Conference of 
the International Acaden G of Language Law (IALL). 
K. Prinsloo et al Pretoria (cds.): University of South 
Africa. pp. 314-331. 
T'sou, B. K., H. L. Lin, G. Liu, T. Chan, J. Hu, C. H. 
Chew, and J. K. P. Tse. 1997. "A Synchronous 
Chinese Language Corpus fi'om Different Speech 
Communities: Construction and Applications." 
Computational Linguistics and Chinese Language 
Ptwcessing 2:91-- 104. 
Viterbi, A. J. 1967. "Error Bounds for Convolution 
Codes and an Asymptotically Optimal l)ecoding 
Algorithm." IEEE 7'ransactions on htformation 
TheoG 13: 260--269. 
1125 
Mining Discourse Markers for Chinese Textual Summarization 
Samuel W. K. Chan I, Tom B. Y. Lai 2, W. J. Gao 3, Benjamin K. T'sou 4 
J 24Languag e Information Sciences Research Centre 
City Un!versity of Hong Kong 
Tat CheeAvenue, Kowloon Tong, 
Hong Kong SAR, China 
3 North Eastern University, China 
Iswkchan@cs.cityu.edu.hk, {2cttomlai, 4rlbtsou} @cpccux0.cityu.edu.hk, 3wjgao@ramm.neu.edu.cn 
Abstract 
Discourse markers foreshadow the message 
thrust of texts and saliently guide their 
rhetorical structure which are important for 
content filtering and text abstraction. This 
paper reports on efforts to automatically 
identify and classify discourse markers in 
Chinese texts using heuristic-based and 
corpus-based ata-mining methods, as an 
integral part of automatic text 
summarization via rhetorical structure and 
Discourse Markers. Encouraging results are 
reported. 
1 Introduction 
Discourse is understood to refer to any form of 
language-based communication involving multiple 
sentences or utterances. The most important forms 
of discourse of interest o computerized natural 
.language processing are text and dialogue. While 
discourse such as written text normally appears to 
? be a linear sequence of clauses and sentences, it 
has "long been recognized by linguists that these 
clauses and sentences tend to cluster together into 
units, called discourse segments, that are related 
pragmatically toform a hierarchical structure. 
Discourse analysis goes beyond the levels of 
syntactic and semantic analysis, which typically 
treats each sentence as an isolated, independent 
unit. The function of discourse analysis is to 
divide a text into discourse segments, and to 
recognize and re-construct the discourse structure 
of the text as intended by its author. Results of 
discourse analysis can be used to solve many 
important NLP problems such as anaphoric 
reference (Hirst 1981), tense and aspect analysis 
(Hwang and Schubert 1992), intention recognition 
(Grosz and Sidner 1986; Litman and Allen 1990), 
or'can be directly applied to computational NLP 
applications uch as text abstraction (Ono et al 
1994; T'sou et al 1996) and text generation 
(McKeown 1985; Lin et al 1991). 
Automatic text abstraction has received 
considerable attention (see Paice (1990) for a 
comprehensive r view). While some statistical 
approaches have had some success in extracting 
one or more sentences which can serve as a 
summary (Brandow et al 1995; Kupiec et al 1995; 
Salton et al 1997), summarization i  general has 
remained an elusive task. McKeown and Radev 
(1995) develop a system SUMMONS to 
summarize full text input using templates 
produced by the message understanding systems, 
developed under ARPA human language 
technology. Unlike previous approaches, their 
system summarizes a series of news articles on the 
same event, producing a paragraph consisting of 
one or more sentences. Endres-Niggemeyer et al 
(1995) uses a blackboard system architecture with 
co-operating object-oriented agents and a dynamic 
text representation which borrows its conceptual 
relations from Rhetorical Structure Theory (RST) 
(Mann and Thompson 1986). Furthermore, 
connectionist models of discourse summarization 
have also attracted a lot of attention (Aretoulaki et 
al. 1998). The main underlying principles are the 
distributed encoding of concepts and the 
simulation of human association with a large 
amount of processing nodes. What is crucial in 
this approach is to provide a subconceptual l yer 
in the linguistic reasoning. 
As in Paice (1990), summarization 
techniques in text analysis are severely impaired 
by the absence of a generally accepted iscourse 
11 
model and the use of superstructural schemes is 
promising for abstracting text. Johnson et al (1993) 
describes a text processing system that can 
identify anaphors o that they may be utilized to 
enhance sentence selection. It is based on the 
assumption that sentences which contain non- 
anaphoric noun phrases and introduce key 
concepts into the text are worthy of inclusion in an 
abstract. Ono et al (1994), T'sou et al (1992) and 
Marcu (1997) focus on discourse structure in 
summarization using the Rhetorical Structure 
Theory (RST). The theory has been exploited in a. 
number of computational systems (e.g. Hovy 
1993). The main idea is to build a discourse tree 
where each node of the tree represents a RST 
relation. Summarization is achieved by trimming 
unimportant sentences on the basis of the relative 
saliency or rhetorical relations. On the other hand, 
cohesion can also provide context o aid in the 
resolution of ambiguity as well as in text 
summarization (Halliday and Hasan 1976; Morris 
and Hirst 1991; Hearst 1997). Mani et al (1998) 
describes a method based on text coherence which 
models text in terms of macro-level relations 
between clauses or sentences tohelp determine the 
overall argumentative structure of the text. They 
examine the extent to which cohesion and 
coherence can each be used to establish saliency of 
textual units. 
The SIFAS (S,yntactic Marker based Eull- 
Text Abstration System) system has been designed 
and implemented to use discourse markers in the 
automatic summarization of Chinese. Section 2 
provides an introduction to discourse markers in 
Chinese. An overview of SIFAS is presented in 
Section 3. In Section 4, we describe a coding 
scheme for tagging every discourse marker 
appearing in the SIFAS corpus. In Section 5, we 
introduce a heuristic-based algorithm for 
automatic tagging of discourse markers. In Section 
6, we describe the application of the C4.5 
algorithm to the same task. In Section 7, we 
present he evaluation results of applying the two 
algorithms to corpus tagging, followed by a 
conclusion. 
2 Chinese Discourse Markers 
Among all kinds of information that may be found 
in a piece of discourse, discourse markers (also 
known as discourse connectives, clue words 
(Reichman 1978; Siegel et al 1994) or cue phrases 
(Grosz et al 1986; Litman 1996) are regarded as 
the major linguistic deviceavailable for a writer to 
structure a discourse. Discourse markers are 
expressions which signal a sequential relationship 
between the current basic message and the 
previous discourse. Schiffrin (1987) is concerned 
with elements which mark sequentially dependent 
units of discourse. She examines discourse 
markers in interview data, looking specifically at 
their distribution and their particular 
interpretation(s). She proposes that these markers 
typically serve three functions: (i) they index 
adjacent utterances to the speaker, the hearer, or 
both; (ii) they index adjacent utterances to prior 
and/or subsequent discourse; (iii) they work as 
contextual coordinates for utterances by locating 
them on one or more planes of her discourse 
model. 
Discourse markers also figure prominently in
Chinese which has a tendency to delay topic 
introduction (Kaplan 1996; Kirkpatrick 1993). 
Hinds (1982) and Kong (1998) also maintain that 
the Chinese tendency of delayed topic introduction 
is heavily influenced by the qi cheng zhuan he 
canonical structure (a Chinese rhetorical pattern). 
In a study examining rhetorical structure in 
Chinese, Kirkpatrick (1993) found that several 
major patterns, favored and considered to be good 
style by native Chinese writers, are hinted at by 
Chinese discourse markers. Although the effect of 
discourse markers in other languages might not be 
too prominent, here is a great necessity to study 
discourse markers in Chinese in order to capture 
the major associated rhetorical patterns in Chinese 
texts. While the full semantic understanding in
Chinese texts is obviously much more difficult to 
accomplish, the approach using text mining 
techniques in identifying discourse markers and 
associated rhetorical structures in a sizeable 
Chinese corpus will be certainly beneficial to any 
language processing, such as summarization and 
knowledge xtraction i  Chinese. 
In Chinese, two distinct classes of discourse 
markers are useful for identification and 
interpretation of the discourse structure of a 
Chinese text: pr imary discourse markers and 
secondary discourse markers (T'sou et al 1999). 
Discourse markers can be either words or phrases. 
Table 1 provides a sample listing of various 
12 
I 
I 
I 
I 
i 
I 
I 
rhetorical relations and examples considered in 
this research. 
\[Discourse Type 
Sufficiency 
Necessity 
Causality 
Deduction 
?\[dversativity 
Concession 
Conjunction 
Disjunction 
Progression 
Table 
Discourse 
Primary Marker 
ruguo 'if', name 'then' 
zhiyou 'only if', cai 'only \[hen' 
?inwei 'because', suoyi 'therefore' 
iiran 'given that', name 'then' 
suiran 'although', danshi 'but' 
"ishi 'even if', rengran 'still' 
chule 'except', j ianzhi 'also' 
huozhe 'or', huozhe 'or' 
~udan 'not only', erqie 'but also' 
/ 
Examples of Discourse Markers 
Markers 
Discourse Type 
Summary 
Contrast 
fflustration 
Specification 
Generalization 
Digression 
rtemization 
Paraphrasing 
Equivalence 
Enquiry 
ludgment 
Secondary Marker  
zong er yan zhi 'in one word' 
~hishi shang 'in fact' 
liru 'for example' 
tebie shi 'in particular' 
dati er yan 'in general' 
wulun ruhe 'anyway'  
shouxian 'first', qici "next" 
huan ju hua shuo 'in other words' 
zhengru 'just as' 
nandao ('does it mean... ')  
kexi 'unfortunately' 
and Associated Rhetorical Relations in Chinese 
It may be noted that our analysis of Chinese 
has yielded about 150 discourse markers, and that 
on the average, argumentative t xt (e.g. editorials) 
in Chinese shows more than one third of the 
discourse segments to contain discourse markers. 
While primary discourse markers can be paired 
discontinuous constituents, with each marker 
attached to one of the two utterances or 
propositions, the socondary discourse markers 
tend to be unitary constituents only. In the case of 
primary discourse markers, it is quite common that 
one member of the pair is deleted, unless for 
emphasis. The deletion of both discourse markers 
ts also possible. The recovery process therefore 
faces considerable challenge ven when concerned 
? with the deletion of only one member of the paired 
discourse markers. Since these discourse markers 
'have no unique lexical realization, there is also the 
need for disambiguation i  a homocode problem. 
Moreover, primary discourse markers can 
also be classified as simple adverbials, as is the 
case in English: 
(I) Even though a child, John is so tall that 
he has problem getting half-fare. 
(2) Even though a child, (because) John is 
tall, so he has problem getting half-fare. 
In (1), so is usually classified as an adverb 
within a sentence, but in (2) so is recognized as 
marking a change in message thrust at the 
discourse level. 
In the deeper linguistic analysis the two so's 
may be related, for they refer to a situation 
involving excessive height with implied 
consequence which may or may not be stated. In 
terms of the surface syntactic structure, so in (1) 
can occur in a simple (exclamatory) sentence (e.g. 
"John is so tall!"), but so in (2) must occur in the 
context of complex sentences. Our concern in this 
project is to identify so in the discourse sense as in 
(2) in contrast to so used as an adverb in the 
sentential sense as in (1). Similar difficulties are 
found in Chinese, as discussed in Section 7. 
3 SIFAS System Architecture 
From the perspective of discourse analysis, the 
study of discourse markers basically involves four 
distinct but fundamental issues: 1) the occurrence 
and the frequency of occurrence of discourse 
markers (Moser and Moore 1995), 2) determining 
whether a candidate linguistic item is a discourse 
marker (identification / disambiguation) 
(Hirschberg and Litman 1993; Siegel and 
McKeown 1994), 3) determination or selection of 
the discourse function of an identified discourse 
marker (Moser and Moore 1995), and 4) the 
coverage capabilities (in terms of levels of 
embedding) among rhetorical relations, as well as 
among individual discourse markers. Discussion 
of these problems for Chinese compound 
sentences can be found in Wang et al (1994). 
Previous attempts to address the above 
problems in Chinese text have usually been based 
on the investigators' intuition and knowledge, or 
on a small number of constructed examples. In our 
current research, we adopt heuristics-based 
13 
corpus-based 
learning to discover the correlation between 
various linguistic features and different aspects of 
approaches, and use machine discourse marker usage. Our research framework 
i 
Statistical Analysis i 
Discourse Analysis 
Text Abstraction i 
i Natural Language 1 
\[ Understanding 
\[ 
! 
I 
Analysis 
& 
Application 
is shown in Figure I. 
Raw Corpus . 
...... (Editorials) 
...... ~ ' " !  ....... ~,~uto Tagging & 
Proofreading 
Segmented 
Corpus " 
~'~-~ ~ J  Word 
~.-~.._~.: . . . .  Segmentation 
Discourse 
Marker & 
Rhetorical 
Relation Tagged 
Corpus 
Feature 
.. ~ ~. .  Extractiov 
Feature 
Database 
; i i 1 
f f  ~ i 
j 
i Dicti?naries \] ,~ ,, 
Heuristics I / .......... ;-
i Induced Rules ! \ ........... ~ i 
? "- '~- ~ ML & 
Evaluation 
xq 
=_. 
OQ 
K 
?-) 
- i  
?tl 
t-' ?D 
,< 
Figure 1 Framework for Corpus-based Study of Discourse Marker Usage in Chinese Text 
Data in the segmented corpus are divided 
into two sets of texts, namely, the training set and 
:the test set, each of which includes 40 editorials in 
:our present research. Texts in the training set are 
. manually and semi-automatically tagged to reflect where, 
the  properties of every Candidate Discourse DMi: 
Marker (CDM). Texts in the test set are 
automatically tagged and proofread. Different 
algorithms, depending on the features being RRi: 
investigated, are derived to automatically extract 
the interesting features to form a feature database. RPi: 
Machine learning algorithms are then applied to 
the feature database to generate linguistic rules 
(decision trees) reflecting the characteristics of 
various discourse markers and the relevant CT~: 
rhetorical relations. For every induced rule (or a 
combination of them), its performance is evaluated 
by tagging the discourse markers appearing in th- 
test set of the corpus. 
4 A Framework for Tagging MN~: 
Discourse Markers 
The following coding scheme is designed to 
encode all and only Real Discourse Markers RN~: 
(RDM) appearing in the SIFAS corpus. We 
describe the i th discourse marker with a 7-tuple 
RDMi, 
RDMi=< DMI, RR/,  RPI, CTi, MNi ,  RNI ,  
> 
the lexical item of the Discourse Marker, 
or the value 'NULL'.  
the Rhetorical Relation in which DMi is 
one of the constituting markers. 
the Relative Position of DM;. The value 
of RPi can be either 'Front' or 'Back' 
denoting the relative posit ion of the 
marker in the rhetorical relation RRi. 
the Connection Type of RRi. The value 
of CT~ can be either 'Inter" or ' Intra', 
which indicates that the DM~ functions as 
a discourse marker in an inter-sentence 
relation or an Intra-sentence relation. 
the Discourse Marker Sequence Number. 
The value of MNi is assigned 
sequentially from the beginning of the 
processed text to the end. 
the Rhetorical Relation Sequence 
Number. The value of RNi is assigned 
14 
I 
I 
I 
I 
I 
l 
sequentially to the corresponding 
rhetorical relation RR; in the text. 
OTi: the Order Type of RR;. The value of OTi 
can be 1, -1 or 0, denoting respectively 
the normal order, reverse order or 
irrelevance of the premise-consequence 
ordering of RRI. 
For Apparent Discourse Markers (ADM) that do 
not function as real discourse markers in a text, a 
different 3-tuple coding scheme is used to encode 
them: 
ADM~ = < LIi, *, SNi > where, 
LIi: the Lexical Item of the ADM. 
SNi: the Sequence Number of the ADM. 
To illustrate the above coding scheme 
consider the following examples of encoded 
sentences where every CDM has been tagged to be 
either a 7-tuple or a 3-tuple. 
Example 1 
<vouvu ('because').Causalitv. Front. lntra. 2. 2. 
/> Zhu Pei ('Jospin') zhengfu ('government') 
taidu ('attitude') qiangying ('adamant'), chaoye 
('government-public') duikang ('confrontation') 
yue-yan-yue ('more-develop-more') -lie 
('strong'), <NULL. Causality. Back. Intra, O. 2. 
/> gongchao ('labour unrest') <vi ('with'). * 
:1> liaoyuan ('bum-plain') zhi ('gen') shi 
'tendency' xunshu 'quick' poji 'spread to' ge 
('every') hang ('profession') ge ('every') ye 
, ('trade'). 
'As a result of the adamant attitude of the 
Jospin administration, confrontation between 
the government and the public is becoming 
w.orse and worse. Labour unrest has spread 
quickly to all industrial sectors.' 
From the above tagging, we can immediately 
obtain the discourse structure that the two clauses 
encapsulated by the two discourse markers youyu 
(with sequence number 2) and NULL (with 
sequence number 0). They have formed a causality 
relation (with sequence number 2). We denote this 
as a binary relation 
Causality(FrontClause(2), BaekClause(2)) 
where FrontClause(n) denotes the discourse 
segment that is encapsulated by the Front 
discourse marker of the corresponding rhetorical 
relation whose sequence number is n. 
15 
BackClause(n) can be defined similarly. Note that 
although yi is a CDM, it does not function as a 
discourse indicator in this sentence. Therefore, it is " 
encoded as an apparent discourse marker. 
Example 2 
<dan ('however'). Adversativitv. Back. Inter. 
17. 14. 1> <ruguo 'if'. Su_~ciencv. Front. Inter, 
18. 15. 1> Zhu Pei ('Jospin') zhengfu 
('government') cici ('this time') zai ('at') 
gongchao ('labour unrest') mianqian ('in the 
face of') tuique ('back down'), <NULL. 
Su.~ciencv. Back. Inter. O. 15. 1> houguo 
('result') <geng.('more'). *. 3> shi bukan ('is 
unbearable') shexian ('imagine'). 
'However, if the Jospin administration backs 
down in the face of the labour unrest, the result 
will be terrible.' 
From the above tagging, we can obtain the 
following discourse structure with embedding 
relations: 
A dversativity ( &F (14 ), 
Sufficiency(F rontClause(15), 
BackClause(15))) 
where &F(n) denotes the Front discourse segment 
of an inter-sentence rhetorical relation whose 
sequence number is n. We can define &B(n) 
similarly. 
5 Heuristic-based Tagging of 
Discourse Markers 
In the previous section, we have introduced a
coding, scheme for CDMs, and have explained 
how to automatically derive the discourse 
structure from sentences with tagged discourse 
markers. Now, the problem we have to resolve is: 
Is there an algorithm that will tag the markers 
according to the above encoding scheme? 
To derive such an algorithm,-even an 
imperfect one, it is necessary that we have 
knowledge of the usage patterns and statistics of 
discourse markers in unrestricted texts. This is 
exactly what project SIFAS intends to achieve as 
explained in Section 3. Instead of completely 
relying on a human encoder to encode all the 
training texts in the SIFAS corpus, we have 
experimented with a simple algorithm using a 
small number of heuristic rules to automatically 
encode the CDMs. The algorithm is a 
straightforward matching algorithm for rhetorical 
relations based recognition of their constituent 
discourse markers as specified in the Rhetorical 
Relation Dictionary (T'sou et al 1999). The 
following principles are adopted by the heuristic- 
based algorithm to resolve ambiguous ituations 
encountered in the process of matching discourse 
markers: 
(1) Principle of Greediness: When matching a
pair of CDMs for a rhetorical relation, 
priority is given to the first matched relation 
from the left. 
(2) Principle of Locality: When matching a pair 
of CDMs for a rhetorical relation, priority is 
given to the relation where the distance 
between its constituent CDMs is shortest. 
(3) Principle of Explicitness: When matching a
pair of CDMs for a rhetorical relation, 
priority is given to the relation that has both 
CDMs explicitly present. 
(4) Principle of Superiority: When matching a
pair of CDMs for a rhetorical relation, 
priority is given to the inter-sentence relation 
whose back discourse marker matches the 
first CDM of a sentence. 
(5) Principle of Back-Marker Preference: this 
principle is applicable only to rhetorical 
relations where either the front or the back 
marker is absent. In such cases, priority is 
given to the relation with the back marker 
present. 
' Application of the above principles to 
process a text is in the order shown, with the 
? exception that the principle of greediness is 
applied whenever none of the other principles can 
be, used to resolve an ambiguous ituation. The 
following pseudo code realizes principles 1, 2 and 
3: 
I := l ;  
whi le I < NumberOfCDMsInTheSentence  do 
beg in  
for J := l  to NumberOfCDMsInTheSentencen  - 
I do 
i f  ((not CDMs\ [ J \ ] .Tagged)  and (not 
CDMs\ [ J+ I \ ] .Tagged)}  then 
Match ing(CDMs\ [ J \ ] ,  CDMs\ [ J+ I \ ] )  ; 
I := I + 1 ; 
end ; 
The following code realizes principles 1,4 and 5: 
16 
for I :=l  to NumberOfCDMs lnTheSentence  do 
begin 
if (not CDMs\ [ I \ ] .Tagged)  then  
Match ing(NULL ,  CDMs\[ I \ ] )  ; 
i f  (not CDMs\ [ I \ ] .Tagged)  then  
Match ing(CDMs\ [ I \ ] ,  NULL) ; 
end ; 
In the above pseudo codes, CDMs\[\] denotes 
the array holding the candidate discourse markers, 
and the Boolean variable Tagged is used to 
indicate whether a CDM has been tagged. 
Furthermore, the procedure Matching0 is to 
examine whether the first word or phrase 
appearing in a sentence is an inter-sentence 
CDMs\[I\]. 
6 Mining Discourse Marker Using 
Machine Learning 
Data mining techniques constitute a field 
dedicated to the development of computational 
methods underlying learning processes and they 
have been applied in various disciplines in text 
processing, such as finding associations in a 
collection of texts (Feldman and Hirsh 1997) and 
mining online text (Knight 1999). In this section, 
we focus on the problem of discourse marker 
disambiguation using decision trees obtained by 
machine learning techniques. Our novel approach 
in mining Chinese discourse markers attempts to 
apply the C4.5 learning algorithm, as introduced 
by Quinlan (1993), in the context of non-tabular, 
unstructured ata. A decision tree consists of 
nodes and branches connecting the nodes. The 
nodes located at the bottom of the tree are called 
leaves, and indicate classes. The top node in the 
tree is called the root, and contains all the training 
examples that are to be divided into classes. In 
order to minimize the branches in the tree, the best 
attribute is selected and used in the test at the root 
node of the tree. A descendant of the root node is 
then created for each possible value of this 
attribute, and the training examples are sorted to 
the appropriate descendant node. The entire 
process is then repeated using the training 
examples associated with each descendant ode to 
select he best attribute for testing at that point in 
the tree. A statistical property, called information 
gain, is used to measure how well a given attribute 
differentiates the training examples according to 
their target classificatory scheme and to select he 
I 
I 
I 
I 
| 
I 
I 
I 
! 
I 
I 
I 
I 
I 
II. 
I 
I- 
II 
I 
most suitable candidate attribute at each step while 
expanding the tree. 
The attributes we use in this research include 
the candidate discourse marker itself, two words 
immediately to the left of the CDM, and two 
words immediately to the right of the CDM. The 
attribute names are F2, F1, CDM, B1,  B2, 
respectively. All these five attributes are discrete. 
The following are two examples: 
? ",", dan 'but', youyu 'since', Xianggang 
'Hong Kong', de 'of', T. 
? zhe 'this', yi 'also', zhishi 'is only', 
Xianggang 'Hong Kong', de 'of', F. 
where "T" denotes the CDM youyu as a discourse 
marker in the given context, and "F" denotes that 
zhishi is not a discourse marker. 
In building up a decision-tree in our 
application of C4.5 to the mining of discourse 
markers, entropy, first of all, is used to measure 
the homogeneity of the examples. For any possible 
candidate A chosen as an attribute in classifying 
the training data S, Gain(S, A) information gain, 
relative to a data set S is defined. This information 
gain measures the expected reduction in entropy 
and defines one branch for the possible subset Si 
of the training examples. For each subset Si, a new 
test is then chosen for any further split. If Si 
satisfies a stopping criterion, such as all the 
element in S~ belong to one class, the decision tree 
is formed with all the leaf nodes associated with 
the most frequent class in S. C4.5 uses arg 
max(Gain(S, A)) or arg max(Gain Ratio(S, A)) as 
defined in the following to construct the minimal 
decision tree. 
c 
Entropy(S) = -~_ -  p, log 2 p~ (Eqn. I) 
i=1 
Gain(S,A) = Entropy(S)- ~ -~'Entropy(S~) isl 
(Eqn. 2) 
Gain Ratio - Gain(S,A) (Eqn. 3) 
Splitlnformation( S, A) 
? ? j is, t.  s,i where Splitlnformation=-2./--,Jog 2 ~, Si is 
!S! iS! 
subset of S for which A has value vt 
In our text mining, according to the number 
of times a CDM occurs in the 80 tagged editorials, 
we select 75 CDMs with more than 10 occurrences. 
To avoid decision trees being over-fitted or trivial, 
for F2, F1, B1 and B2, only values of attributes 
with frequency more than 15 in the corpus are 
used in building the decision trees. We denote all 
values of attributes with frequency less than 15 as 
'Other'.  If a CDM is the first, the second or the 
last word of a sentence, values of F2, F1, or B2 
will be null, we denote a null-value as "*". The 
following are two other examples: 
? "*", "*", zheyang 'thus', ",", Other, T. 
? "*", "*", zheyang 'thus', Other, de 'of', F. 
7 Evaluation 
7.1 Evaluation of Heuristic-based 
Algorithm 
In order to evaluate the effectiveness of the 
heuristic-based algorithm, we randomly selected 
40 editorials from Ming Pao, a Chinese newspaper 
of Hong Kong, to form our test data. Only 
editorials are chosen because they are mainly 
argumentative texts and their lengths are relatively 
uniform. 
The steps of evaluation consist of: 1) tagging 
all of the test data using the heuristic-based 
algorithm, and 2) proofreading, correcting and 
recording all the tagging errors by a human 
encoder. The resulting statistics include, for each 
editorial in the test data, the number of lexical 
items (#Lltms), the number of sentences (#Sens), 
the number of discourse markers (#Mrkrs), and the 
number of sentences containing at least one 
discourse marker (#CSens). Table 2 shows the 
minimum, maximum and average values of these 
characteristics. The ratio of the average number of 
discourse markers to the average number of lexical 
items is 4.37%, and the ratio of the average 
number of sentences 
discourse marker to 
sentences i  62.66%. 
#Lltms 
MIN 466 
MAX 1082 
AVERAGE 676.25 
containing at least one 
the average number of 
#Mrkrs #Sens #CSens 
14 11 6 
52 45 26 
29.58 22.15 13.88 
Table 2 Characteristics of the Test Data 
Our evaluation is based on counting the 
number of discourse markers that are correctly 
17 
tagged. For incorrectly tagged iscourse markers, 
we classify them according to the types of errors 
that we have introduced in T'sou et al (1999). We 
define two evaluation metrics as follows: Gross 
Accuracy (GA) is defined to be the percentage of
correctly tagged discourse markers to the total 
number of discourse markers while Relation- 
Matching Accuracy (RMA) is defined to be the 
percentage of correctly tagged discourse markers 
to the total number of discourse markers minus 
those errors caused by non-markers and 
unrecorded markers. The results for our testing. 
data have GA = 68.89% and RMA = 95.07%. 
Since the heuristic-based algorithm does 
not assume any knowledge of the statistics and 
behavioral patterns of discourse markers, our GA 
demonstrates the usefulness of the algorithm in 
alleviating the burden of human encoders in 
developing a sufficiently large-corpus for the 
purpose of studying the usage of discourse 
markers. 
In our experiment, most errors come from 
tagging non-discourse markers as discourse 
markers (T'sou et al 1999). This is due to the fact 
that, similar to the question of cue phrase 
polysemy (Hirschberg and Litman 1993), many 
Chinese discourse markers have both discourse 
senses and alternate sentential senses in different 
;utterances. For example: 
? ... Zhe ('this') buguo shi ('only is') yi ('one') 
ge ('classifier') wanxiao ('joke') 
...('This is only a joke'.) (sentential sense) 
? ...Buguo ('however'), wo (T)  bu ('neg') 
zheyang ('thus') renwei ('consider') 
? . . ( 'But  I don't think so.') (discourse sense) 
7.2 Evaluation of Decision Tree 
Algorithm (with C4.5) 
In Section 6, we discuss how machine learning 
techniques have been applied to the problem of 
discourse marker disambiguation in Chinese. 
In our experiment, there are a total of 2627 
cases. In our decision tree construction, we use 75 
percent of the total cases as a training set, and the 
remaining 25 percent of cases as a test set. Many 
decision trees can be generated by adjusting the 
parameters in the learning algorithm. Many 
decision trees generated in our experiment have an 
accuracy around 80% for both the training set and 
the test set. Figure 2 shows one of the possible 
decision trees in our experiment. The last branch 
of the decision tree 
F1 = danshi 'but' 
I CDM in {ru 'if', reng 'still', geng 'even more', que 
'however' }:F (6/0) 
I CDM in {chule 'except', youyu 'since', ruo 'if"} : T 
(4/0) 
can be explained as: 
if (F1 = danshi 'but') then 
if (CDM in {ru 'if', reng 'still', geng "even more', que 
'however' }) then dassify as F 
else 
if (CDM in {chule 'except',youyu 'since', ru0 'if '  }) 
then classify as T 
Decision Tree: (Size = 38, Items = 1971, Errors = 282) 
F1 in {di, ye, yi} : F (25/5) 
F i  in (,shi, ;} : T (712/131) 
F1 = Other: 
F I  = danshi :
I CDM in {ru, reng, geng, que} : F (7/10) 
I CDM in {chule, youyu, ruo} : T (4/0) 
Evaluation on trainine data from Data. Data (1971 cases~: 
Classified results: 
T F I <" Classified 
937 125 \] C lass :T  
157 752 C.lass : F Errors : 282 (14.3%) 
Evaluation on testin~ data from Data. Test (656 cases): 
T F ~ f i e d  
293 62 \[Class : T 
68 233 IClass : F Errors : 130 (19.8%) 
1 
Figure 2 An Example of Decision Trees 
The two numbers in the brackets denote the 
number of cases covered by the branch and the 
number of cases being misclassified respectively: 
The results of our experiment will be elaborated 
on in future, when we shall also explore the 
application of machine learning techniques to 
recognizing rhetorical relations on the basis of 
discourse markers, and extracting important 
sentences from Chinese text. 
8. Conclusion 
We discuss in this paper the use of discourse 
markers in Chinese text summarization. Discourse 
structure trees with nodes representing RST 
(Rhetorical Structure Theory) relations are built 
and summarization is achieved by trimming 
18 
unimportant sentences on the basis of the relative 
saliency or rhetorical relations. In order to study 
discourse markers for use in the automatic 
summarization f Chinese, we have designed and 
implemented the SIFAS system. We investigate 
the relationships between various linguistic 
features and different aspects of discourse marker 
usage on naturally occurring text. An encoding 
scheme that captures the essential features of 
discourse marker usage is introduced. A heuristic- 
based algorithm for automatic tagging of discourse 
markers is designed to alleviate the burden of a 
human encoder in developing a large corpus of 
encoded texts and to discover potential problems 
in automatic discourse marker tagging. A study on 
applying machine learning techniques todiscourse 
marker disambiguation is also conducted. C4.5 is 
used to generate decision tree classifiers. Our 
results indicate that machine learning is a 
promising approach to improving the accuracy of 
discourse marker tagging. 
9 Acknowledgement  , 
Support for the research reported here is 
provided through the Research Grants Council 
of Hong Kong under Competitive Earmarked 
Research Grants (CERG) No. 9040067, 
9040233 and 9040326. 
10 References 
~Aretoulaki M., Scheler G. and Brauer W. (1998) 
"Connectionist Modeling of Human Event 
Memorization Processes with Application to 
Automatic Text Summarization." In 
Proceedings of AAAI Spring Symposium on 
Intelligent Text Summarization, Stanford, pp. 
148-150. 
Brandow R., Mitze K. and Rau L. F. (1995) 
"Automatic Condensation of Electronic 
Publications by Sentence Selection." 
Information Processing and Management, 
31(5): 675-685. 
Endres-Niggemeyer B., Maier E. and Sigel A. 
(1995) "How to Implement a Naturalistic 
Model of Abstracting: Four Core Working 
Steps of an Expert Abstractor." Information 
Processing and Management, 31(5): 631-674. 
19 
Feldman R. and Hirsh H. (1997). "Finding 
associations in collections of text." In R.S. 
Michalski I. Bratko and Kubat M. (Eds.)," 
Machine Learning and Data Mining: Methods 
and Applications, pp. 224-240. Wiley. 
Grosz B.J. and Sidner C. (1986) "Attention, 
Intention, and the Structure of Discourse," 
Computational Linguistics 12(3): 175-204. 
Halliday M. A. K. and Hasan R. (1976) Cohesion 
in English, Longman. 
Hearst M. A. (1997) "Texttiling: Segmenting Text 
into Multi-paragraph Subtopic Passages." 
Computational Linguistics, 23(1):33-64. 
Hinds J. (1982) "Inductive, deductive, quasi- 
.inductive: Expository writing in Japanese, 
Korean, Chinese, and Thai." In U. Connor and 
A.M. Johns (Eds.). Coherence in Writing, pp. 
89-109. TESOL publisher. 
Hirschberg J. and Litman D. (1993) "Empirical 
Studies on the Disambiguation f Cue Phrases." 
Computational Linguistics 19(3): 501-530. 
Hirst G. (1981) "Discourse Oriented Anaphoral 
Resolution in Natural Language Understanding: 
A Review." Computational Linguistics 7(2): 
85-98. 
Hovy E. (1993) "Automated Discourse Generation 
using Discourse Structure Relations." Artificial 
Intelligence 63: 341-385. 
Hwang C. H. and Schubert L. K. (1992) "Tense 
Trees as the 'Fine Structure' of Discourse." In 
Proc. 30 th Annual Meeting, Assoc. for 
Computational Linguistics, pp. 232-240. 
Johnson F. C., Paice C. D., Black W. J. and Neal 
A. P. (1993) "'The Application of Linguistic 
Processing to Automatic Abstract Generation." 
Journal of Document and Text Management I:
215-241. 
Kaplan R. B. (1996) "Cultural though patterns in 
intercultural education." Language Learning, 
l&2: 1-20. 
Kirkpatrick A. (1993) "Information sequencing in
modem standard Chinese in a genre of extended 
spoken discourse." Text 13(3): 423-453. 
Kong K.C.C. (1998) "Are simple business request 
letters really simple? A comparison of Chinese 
and English business request letters." Text 18(1 ) :  
103-141. 
Knight K. (1999) "Mining online text." 
Communications of the A CM 42(11): 58-61. 
Kupiec J., Pedersen J., and Chen F. (1995) "A 
Trainable Document Summarizer." In 
Proceedings of the lff h Annual International 
ACM SIGIR Conference on Research and 
Development in Information Retrieval, Seattle, 
pp. 68-73. 
Lin H. L., T'sou B. K., H. C. Ho, Lai T., Lun C., 
C. K. Choi and C.Y. Kit. (1991) "Automatic 
Chinese Text Generation Based on Inference 
Trees.'" In Proc. of ROCL1NG Computational 
Linguistic Conference IV, Taipei, pp. 215-236. 
Litman D. J. and Allen J. (1990) "Discourse 
Processing and Commonsense Plans." In Cohen 
et al(ed.) Intentions in Communications, pp. 
365-388. 
Litman D. J. (1996) "Cue Phrase Classification 
Using Machine Learning." Journal of Artificial 
Intelligence Research 5: 53-94. 
Mani I., Bloedorn E. and B. Gates (1998) "Using 
Cohesion and Coherence Models for Text 
Summarization." In Proceedings of AAAI 
Spring Symposium on Intelligent Text 
Summarization, Stanford, pp. 69-76. 
Mann W. C. and Thompson S. A (1988) 
"Rhetorical Structure Theory: Towards a 
Functional Theory of Text Organization." Text 
8(3): 243-281. 
Marcu D. (1997) "From Discourse Structures to 
Text Summaries." In Proceedings of the 
A CL/EA CL '97 Workshop on Intelligent 
: Scalable Text Summarization, Spain, pp. 82-88. 
McKeown K. and Radev D. (1995) "Summaries of 
Multiple News Articles." In Proceedings of the 
18 'h Annual International A CM S1GIR 
Conference on Research and Development in
Information Retrieval, Seattle, pp. 74-82. 
McKeown K. R. (1985) "Discourse Strategies for 
Generating Natural-Language T xt." Artificial 
Intelligence 27(1): 1-41. 
Morris J. and Hirst G. (1991) "Lexical Cohesion 
Computed by Thesaural Relations as an 
Indicator of the Structure of Text." 
Computational Linguistics 17(1): 21-48. 
Moser M. and Moore J. D. (1995) "Investigating 
Cue Selection and Placement in Tutorial 
Discourse.'" In Proceedings of ACL'95, pp. 
130-135. 
Ono K., Sumita K. and S. Miike. (1994) "Abstract 
Generation based on Rhetorical Structure 
Extraction." In Proceedings of International 
Conference on Computational Linguistics, 
Japan, pp. 344-348. 
Paice C. D. (1990) "Constructing Literature 
Abstracts by Computer: Techniques and 
Prospects." Information Processing and" 
Management 26(1): 171-186. 
Quinlan J. Ross (1993)"C4.5 Programs for 
Machine Learning." San Mateo, CA: Morgan 
Kaufmann. 
Reichman R. (1978) "Conversational Coherence." 
Cognitive Science 2(4): 283-328. 
Salton G., Singhal A., Mitra M. and Buckley C. 
(1997) "Automatic Text Structuring and 
Summarization." Information Processing and 
Management 33(2): 193-207. 
Schiffrin D. (1987) Discourse Markers. 
' Cambridge: Cambridge University Press. 
Siegel E. V. and McKeown K. R. (1994) 
"Emergent Linguistic Rules from Inducing 
Decision Trees: Disambiguating Discourse Clue 
Words." In Proceedings of AAAI, pp. 820-826. 
T'sou B. K., Ho H. C., Lai B. Y., Lun C. and Lin 
H. L. (1992) "A Knowledge-based Machine- 
aided System for Chinese Text Abstraction." In 
Proceedings of International Conference on 
Computational Linguistics, France, pp, 1039- 
1042. 
T'sou B. K., Gao W. J., Lin H. L., Lai T. B. Y. 
and Ho H. C. (1999) "Tagging Discourse 
Markers: Towards a Corpus based Study of 
Discourse Marker Usage in Chinese Text" In 
Proceedings of the 18th International 
Conference on Computer Processing of 
Oriental Languages, March 1999, Japan, pp. 
391-396. 
T'sou B. K., Lin H. L., Ho H. C., Lai T. and Chan 
T. (1996) "Automated Chinese Full-text 
Abstraction Based on Rhetorical Structure 
Analysis." Computer Processing of Oriental 
Languages 10(2): 225-238. 
Wang W. X., Zhang X. C., Lu M. Y. and Cheng H. 
Y. (1994) "Xian Dai Han Yu Fu Ju Xian Jie (A 
New Analysis of Complex Sentences in Modern 
Standard Chinese)", Hua Dong S.hi Fan Da Xue 
Chu Ban She, 1994. 
20 
! 
I 
i 
i 
! 
I 
I 
I 
I 
I 
i 
I 
I 
i 
i 
I 
I 
I 
I 
Enhancement of a Chinese Discourse Marker Tagger with C4.5 
Benjamin K. T'sou l, Torn B. Y. Lai 2, Samuel W. K. Chan 3, Weijun Gao 4, Xuegang Zhan 5
23Languag e Information Sciences Research Centre 
City University of Hong Kong 
Tat Chee Avenue, Kowloon 
Hong Kong SAR, China 
Northeastern U iversity, China 
{ ~rlbtsou, 2ettomlai} @uxmail.cityu.edu.hk, 3swkchan@cs.cityu.edu.hk, 
4wj gao@mail.neu.edu.cn, Szxg@ics.cs.neu.edu.cn 
Abstract 
Discourse markers are complex 
discontinuous linguistic expressions which 
are used to explicitly signal the discourse 
structure of a text. This paper describes 
efforts to improve an automatic tagging 
system which identifies and classifies 
discourse markers in Chinese texts by 
applying machine learning (ML) to the 
disambiguation f discourse markers, as an 
integral part of automatic text summarization 
via rhetorical structure. Encouraging results 
are reported. 
Keywords: discourse marker, Chinese 
corpus, rhetorical relation, automatic tagging, 
machine learning 
1 Introduction 
Discourse refers to any form of 
language-based communication involving 
multiple sentences or utterances. The most 
important forms of discourse of interest o 
Natural Language Processing (NLP) are text 
and dialogue. The function of discourse 
analysis is to divide a text into discourse 
segments, and to recognize and re-construct 
the discourse structure of the text as intended 
by its author. 
Automatic text abstraction has received 
considerable attention (Paice 1990). Various 
systems have been developed (Chan et al 
2000). Ono et al (1994), T'sou et al (1992) 
and Marcu (1997) focus on discourse 
structure in summarization using the 
Rhetorical Structure Theory (RST, Mann and 
Thompson 1986). The theory has been 
exploited in a number of computational 
systems (e.g. Hovy 1993). The main idea is 
to build a discourse tree where each node of 
the tree represents an RST relation. 
Summarization is achieved by trimming 
lmimportant sentences on the basis of the 
relative saliency or rhetorical relations. 
The SIFAS (Syntactic Marker based 
Full-Text Abstraction System) system has 
been implemented to use discourse markers 
in the automatic summarization of Chinese 
(T'sou et al 1999). In this paper, we report 
our efforts to improve the SIFAS tagging 
system by applying machine learning 
techniques to disambiguation of discourse 
markers. C4.5 (Quirdan, 1993) is used in our 
system. 
2 Manual Tagging Process 
To tag the discourse markers, the 
following coding scheme is designed to 
encode Real Discourse Markers (RDM) 
appearing in the SIFAS corpus (T'sou et al 
1998). We describe the z ~h discourse marker 
with a 7-tuple RDM; 
RDMi=< DM i, RRi, RPi, CTi, MNi, 
RNi, OT i >, where 
38 
DMi 
RP i : 
: 
MN~ : 
RNi : 
OT~ : 
the lexical item of the 
Discourse Marker, or the 
value'NULL'. 
the Rhetorical Relation in 
which DIVI~ is a constituent 
marker. 
the Relative Position of DMi. 
the Connection Type of RRi. 
the Discourse Marker 
Sequence Number. 
the Rhetorical Relation 
Sequence Number. 
the Order Type of RR~. The 
value of OTi can be 1, -1 or 0, 
denoting respectively the 
normal order, reverse order or 
irrelevance of the premise- 
consequence ordering of RR i . 
For apparent discourse markers that do 
not function as a real discourse marker in a 
text, a different coding scheme is used to 
encode them. We describe the i th apparent 
discourse marker using a 3-Tuple ADM~: 
ADMi =< LIi, *, SNi >, where 
LIi : the Lexical Item of the 
apparent discourse marker. 
SNi : the Sequence Number of the 
apparent discourse marker. 
In Chinese, discourse markers can be 
either words or phrases. To tag the SIFAS 
corpus, all discourse markers are organized 
into a discourse marker pair-rhetorical 
relation correspondence table. Part of the 
table is shown Table 1. 
To construct an automatic tagging 
system, let us first examine the sequential 
steps in the tagging process of a human 
tagger. 
S1. Written Chinese consists of rurming texts 
without word delimiters; the first step is 
is to segment the text into Chinese word 
sequences. 
$2. On the basis of a discourse marker list, 
we identify those words in the text 
which appear on the list as Candidate 
Discourse Markers (CDMs). 
$3. To winnow Real Discourse Markers 
(RDMs) and Apparent Discourse 
Markers (ADMs) from the CDMs, and 
encode the ADMs with a 3-tuple. 
$4. To encode the RDM with a 7-tuple 
according to a Discourse Marker Pair- 
Rhetorical Relation correspondence 
table. 
Relat- 
ion 
Adver- 
sativity 
Adver- 
sativity 
Causa- 
nty 
Causa- 
lity 
Front Back Con- 
nection 
Type 
Inter 
Intra 
Intra 1 
Intra -1 
Table 1 Discourse Marker Pair- 
Rhetorical Relation Table 
Order 
Type 
3 Automat ic  Tagg ing  Process  
The identification of candidate discourse 
markers is based on a discourse marker list, 
which now contains 306 discourse markers 
plus a NULL marker. The markers are 
extracted from newspaper editorials of Hong 
Kong, Mainland China, Taiwan and 
Singapore. These markers constitute 480 
distinct discontinuous pairs that correspond 
to 25 rhetorical relations. In actual usage, 
some discourse marker pairs designate 
multiple rhetorical relations according to 
context. Some pairs can represent both 
INTER-sentence and INTRA-sentence 
relations. Thus the correspondence b tween 
the discourse marker pairs and the rhetorical 
relations is not single-valued. Some 
discourse marker pairs correspond to more 
than one rhetorical relation or connection 
type. We have 504 correspondences between 
the discourse marker pairs and the rhetorical 
relations. 
39 
In practice, one discontinuous 
constituent member of a marker pair is often 
omitted. We use the NULL marker to 
indicate the omission. In the 504 
correspondences, 244 of them are double 
constituent marker pairs, 260 are single 
constituent markers (i.e. One of the markers 
is NULL). And in the 244 double constituent 
markers, only 3 are not single-valued 
correspondences (one of" which is an 
INTER/INTRA relation, and can easily be 
distinguished.). Thus the tagging of the 244 
double constituent markers is basically a 
table searching process. But for the 260 
single constituent markers, the identity of the 
NULL marker is often difficult o determine. 
The SIFAS tagging system works in two 
modes: automatic and interactive (semi- 
automatic). The automatic tagging procedure 
is as follows: 
1. Data preparation: Input data files are 
modified according to the required 
format. 
2. Word segmentation: Because there are 
no delimiters between Chinese words in 
a text, words have to be extracted 
through asegmentation process. 
3. CDM identification 
4. Full-Marker RDM recognition 
5. ADM identification (first pass, 
deterministic) 
6. CDM feature xtraction 
7. ADM identification (2nd pass, via ML) 
8. Tagging NuLL-marker CDM pairs (via 
ML) 
9.ADM and RDM sequencing, proof- 
reading, training data generation, and 
statistics 
The following principles are adopted by 
the tagging algorithm to resolve ambiguity in 
the process of matching discontinuous 
discourse markers: 
1. the principle of greediness: When 
matching a pair of discourse markers for 
a rhetorical relation, priority is given to 
the first matched relation from the left. 
2.the principle of locality: When 
matching apair of discourse markers for 
a rhetorical relation, priority is given to 
the relation where the distance between 
its constituent markers is shortest. 
3.the principle of explicitness: When 
matching a pair of discourse markers for 
a rhetorical relation, priority is given to 
the relation where both markers are 
explicitly presented. 
4. the principle of superiority: When 
matching a pair of discourse markers for 
a rhetorical relation, priority is given to 
the inter-sentence r lation whose back 
discourse marker matched with the first 
word of a sentence. 
5. the principle of Back-marker 
preference: This is applicable only to 
rhetorical relations where either the 
front or the back marker is absent, or to 
a NULL marker. In such cases, priority 
is given to the relation with the back 
marker present. 
Steps 1 to 6 and the five principles 
underlie the original naive tagger of the 
SIFAS system (T'sou et al 1998), which also 
contains the system framework. 
4 Improvement 
4.1 Problems 
Many Chinese discourse markers have 
both discourse senses and alternate sentential 
senses in different context. For a human 
tagger, steps $3 and $4 in section 2 are not 
difficult because he/she can identify an 
ADM/RDM based on his/her text 
comprehension. However, for an automatic 
process, it is quite difficult o distinguish an 
ADM from an RDM if no syntactic/semantic 
information is available. 
Another problem is the location of 
NULL-Marker described above. Our earlier 
statistics howed some characteristics in the 
distance measured by punctuation marks. 
Statistics from 80 tagged editorials how that 
most of the relations are INTRA-Sentence 
relations (about 93%), about 70% of the 
INTRA RDM pairs have NULL markers. 
Most of these RDM pairs are separated by 
ONE comma (62%). These statistics how 
40 
the importance of the problems of 
positioning the NULL markers. 
The naive tagger partially solved the 
CDM discrimination and NULL marker 
location problems. Our experiment shows 
that about 45% of the ADMs can be 
correctly identified, and about 60% of the 
NULL markers can be correctly located one 
comma/period away from the current RDM. 
This leaves much room for improvement. 
One solution is to add a few rules 
according to previous tatistics. The original 
naive tagger did not assume any knowledge 
of the statistics and behavioral patterns of 
discourse markers. From the error analysis, 
we extracted some additional rules to guide 
the classification and matching of the 
discourse markers. For example, one of the 
rules we extracted is: 
"A matching pair must be separated by 
at least two words or by punctuation 
marks". Using this rule, the following 
full marker matching error is avoided. 
< ~ ~ >< ~ ~ >< ~ x ~ >< 
./~ ,conjunction,Front, Intra,5,5,1>< ~ >< ~,  
conjunction, Back, Intra, 6,5,1><~>, <~t~><7~ 
?~x~><~><t$ i~>,  <~,* ,7xf f~>< 
X><~x<~><~x~><~x~_~ 
><~>0 
Another solution is to use 
? syntactic/semantic information through 
machine learning. 
4.2 C4.5 
Most empirical learning systems are 
given a set of pre-classified cases, each 
described by a vector of attribute values, and 
construct from them a mapping from 
attribute values to classes. C4.5 is one such 
system that learns decision-tree classifiers. It
uses a divide-and-conquer approach to 
growing decision trees. The current version 
of C4.5 is C5.0 for Unix and See5 for 
Windows. 
Let attributes be denoted A={a~, a2, ..., 
a,,J, cases be denoted D={d 1, d2, ..., d J ,  and 
classes be denoted C={c, c 2, ..., cJ. For a 
set of cases D, a test 1q is a split of D based 
on attribute at. It splits D into mutually 
exclusive subsets D~, D 2, ..., D r These 
subsets of cases are single-class collections 
of cases. 
If a test T is chosen, the decision tree 
for D consists of a node identifying the test 
T ,  and one branch for each possible subset 
D~. For each subset D~, a new test is then 
chosen for further split. If D~ satisfies a 
stopping criterion, the tree for Dr is a leaf 
associated with the most frequent class in D~. 
One reason for stopping is that cases in D~ 
belong to one class. 
C4.5 uses arg max(gain(D,1)) or arg 
max(gain ratio(D,T)) to choose tests for 
split: 
k 
Info(D) = -~p(c , ,D)  * log2(p(c,,D)) 
i=I 
Split(D,T) = _L ID ,  I .  log2(~-~) 
i=l IDI 
Gain(D,T) = Info(D)- "J"'~.~'. Di I.  Info(Di) 
i=l I DI 
Gain ratio(D, T) = gain(D, T) / Split(D, T) 
where, p(c~,D) denotes the proportion of 
cases in D that belong to the i th class. 
4.3 Application of C4.5 
Since using semantic information 
requires a comprehensive thesaurus, which is 
unavailable at present, we only use syntactic 
information through machine learning. 
The attributes used in the original 
SIFAS system include the candidate 
discourse marker itself, two words 
immediately to the left of the CDM, and two 
words immediately to the right of the CDM. 
The attribute names are F2, F1, CDM, B1, 
B2, respectively (T'sou et al 1999). SIFAS 
only uses the Part Of Speech attribute of the 
neighboring words. This reflects to some 
degree the syntactic characteristics of the 
CDM. 
To reflect the distance characteristics, 
we add two other attributes: the number of 
discourse delimiters (commas, semicolons 
for INTRA-sentence relation, periods and 
41 
exclamation marks for INTER-sentence 
relation) before and after the current CDM, 
denoted Fcom and Boom, respectively. For 
the location of the NULL marker, we still 
add an actual number of delirniters Acorn. 
The order of these attributes is: CDM, 
F1, F2, B1, B2, Fcom, Boom Acorn for Null 
marker location, and CDM, F1, F2, B1, B2, 
Fcom, Bcom, IsRDM for CDM classification, 
where IsRDM is a Boolean value. 
The following are two examples of 
cases: 
9~: _N. ,?,q,a,a,7,1,1 for NULL marker 
location 
N~,d,?,u,?,l ,0,F for CDM classificati 
on 
where "?" denotes that no corresponding 
word is at the position (beginning or end of 
sentence); a, d, q, and u are part-of-speech 
symbols in our segmentation dictionary, 
representing adjective, adverb, classifier, and 
auxiliary, respectively. 
The following are two examples of the 
rules generated by the C4.5. The first is a 
CDM classification rule, and the other is a 
NULL marker location rule. 
Rule 5: (11/1, lift 2.2) 
CDM = 
B1 =v 
Fcom > 0 
class T \[0.846\] 
which can be explained as: if the word after 
the CDM "~:" is a verb, and there is one 
comma in the sentence, before "~J:~:", then 
"~:" is an RDM. 
Rule 22: (1, lift 3.4) 
B2 = p 
Fcom > 1 
class 2 \[0.667\] 
which can be explained as: if the second 
word after the RDM is a preposition, and 
there is more then one commas before the 
current RDM, then the location of the NULL 
marker is two commas away from the RDM. 
4.4 Objects in the SIFAS system 
The objects in the new SIFAS tagging 
system are listed below. 
1. Dictionary Editor: for the update of 
word segmentation dictionary and the 
rhetorical relation table. 
2. Data Manager: for the modification of 
the input data (editorial texts) to 
conform with the required format. 
3. Word Segmenter: for the segmentation 
of the original texts, and the recognition 
of CDMs. 
4. RDM Tagger: The initial identification 
of RDMs is a table searching process. 
All those full-marker pairs are identified 
as rhetorical relations according to the 
principles described above. For those 
Null-marker pairs, the location of the 
Null maker is left to the rule interpreter. 
5. ADM Tagger: The identification of 
ADMs is also a table searching process, 
because, without other 
syntactic/semantic information, the only 
way to identify ADMs from the CDMs 
is to find out that the CDM cannot form 
a valid pair with any other CDMs 
(including the NULL marker) to 
correspond to a rhetorical relation. 
6. CDM Feature Extractor: For those 
untagged CDMs, the classification is 
carried out through C4.5. The Feature 
Extractor extracts yntactic information 
about he current CDM and send it to the 
Rule Interpreter (see below). 
7. Rule Interpreter: C4.5 takes feature data 
file as the input to construct a classifier, 
and the rules formed are stored in an 
output file. The rule interpreter eads 
this output file and applies the rules to 
classify the CDMs. In our system, The 
Rule Interpreter functions as a NULL 
Marker Locator and a CDM classifier. 
8. Sequencer: for the rearrangement of
RDM and ADM order number. In the 
rearranging process, the Sequencer also 
extracts statistical information for 
analysis. 
9. Interaction Recorder: for the recording 
of user interaction information for 
42 
statistics use. 
10. Data Retriever: for data retrieval and 
browsing. 
5 Evaluation 
In order to evaluate the effectiveness of 
the tagging system in terms of the percentage 
of discourse markers that can be tagged 
correctly, we have chosen 80 tagged 
editorials from Ming Pao, a Chinese 
newspaper of Hong Kong, in the duration 
from December 1995 to January 1996 to 
form a training data set. Then we randomly 
selected 20 editorials from Mainland China 
and Hong Kong newspapers for the system 
to tag automatically, and then manually 
checked the results. 
The total CDMs in the training data set 
is 4764, in which 2116 are RDMs and 2648 
are ADMs. The distribution of INTER- 
sentence r lations, INTRA-sentence r lations, 
and NULL marker pairs is shown below. 
Total 
Relations 
Inter- 
Sentence 
Relations 
Intra- 
Sentence 
Relations 
Relations 
with 
NULL 
marker 
pair 
1589 98 1491 1062 
100% 6.17% 93.83% 66.83% 
Table 2 Distribution of INTER-/INTRA- 
sentence relations, 
and NULL marker pairs 
Our evaluation is based on counting the 
number of discourse markers that are 
correctly and incorrectly tagged. 
The total CDMs in the test data set is 
1134, in which 563 are RDMs and 571 are 
ADMs. The distribution of INTER-sentence 
relations, INTRA-sentence relations, and 
NULL marker pairs in the test data set is 
shown in Table 3. 
Total 
Relations 
Inter- 
Sentence 
Relations 
Intra- 
Sentence 
Relations 
Relations 
with 
NULL 
marker 
pair 
424 23 401 285 
100% 5.42% 94.58% 67.22% 
Table 3 Distribution of INTER-/INTRA- 
sentence relations, and NULL marker 
pairs in testing data set 
451 399 11 1 65 3 
Table 4 Test Results 
From the test results shown in Table 4, 
we can see that most of the errors are caused 
by the misclassification f the CDMs. An 
example of Other errors is shown below. 
The following sentence is from an editorial 
of People's Daily. 
< ~ ~17 >< ~ ~.~ >< ~ ~ > , 
<NULL,sufficienc y, Front, Intra, O,81,1x -- ~ ~ff \[\] 
><~ ><~. ~lJ><~.~.>< \[\] ~>,  <~><~iA><-- 
+~ \[ \ ]><~><)~lJ>, <~><~iA><~>< 
~,*,80><~ \[\]><1~><--~52">, <~~>< 
~,sufticiency, Back,Intra,81,81,1 < ~ ~ x :~ x 
~.><~><~>,  <~ ~><~ :~ ><~,*,SZ><~ l~J, 
><~>? 
In the above sentence, the first "R"  is 
matched with the NULL marker, but the 
second "R" is left as an ADM. This causes 
an "Other error" and an "ADM/RDM 
classification error". 
The Gross Accuracy (GA) as defined in 
T'sou et al (1999) is: 
GA = correctly tagged discourse 
markers / total number of discourse markers 
= 95.38% 
This greatly improves the performance 
compared with the original GA = 68.89%. 
The overgeneration problem (tagged 415, 
actual 424) is caused by the mismatch of 
CDMs as RDM pairs, or by the 
43 
misclassification of CDMs as RDMs. 
Following are two examples. 
< ~\[I ~ ,sufficieney, Front, Intra,54,54,1x ~ ~1"\] >_< 
~\[1- ~><~,* ,56x~xf f  ~ >, <~A.x~x~ :t: 
>< ~ > , < ~1~. ,sufficieney, Back,Intra,57,54,1>_< 
,*,58><~ x~ ~><~><:~ ~x~ ~x 
><~I l~ . l><~x(~ ~ x~,* ,59><~ A.x~ ~ 
><:t:~><--~>? 
In this example, "~tl ~"  could have 
matched <:~,*.55>, < ~,*,56>, or<~,*,58>. 
Only the <:~,*,55> and the <~,*,58> can be 
eliminated from the candidates according to 
the "simple rules" mentioned in section 4.1. 
The system has to choose from <~,*,56> and 
<}J~,*,57> to match with "~zn~'. Luckily, 
the system has given a right choice here. 
< --  ~" ~ \[\] >< ~ ,conjunction,Front, Intra,46, 
46,1><~~><~><~r~> , <NULL, 
conjunction,Front, Intra,0,49,1 ><-- f" ~ \[\] ><)~ 
>< ~,~ ,conjunction,Back, Intra,47,46,1>< 
~i~,*,48>< ~ ~><1~ \]\]~><~E ~><~><~ >< 
~ \[\] A .><~><~ ~ ><th~> , < 
,eonjunction,Baek,Intra,49,49,1>< ~ ~tJ ~ 
><?x~ ~><\[ \ ]  ~><~n><~,*,50><l~# 
\[\]><~ I x~x\ [ \ ]  g,~><~ ~>< ~ ><Lib>. 
The two "~" are misclassified as RDMs, 
and causes a mismatch of RDM pair. Such 
errors are difficult to avoid for an automatic 
system. Without further syntactic/semantic 
analysis, we can only hope for the ML 
algorithm to give us a solution from more 
training data. 
6 Conc lus ion  
In order to study discourse markers for 
use in the automatic summarization of 
Chinese text, we have designed and 
implemented the SIFAS system. In this 
paper, we have focused on the problems of 
NULL marker location and the classification 
of RDMs and ADMs. A study on applying 
machine learning techniques to discourse 
marker disambiguation is conducted. C4.5 is 
used to generate decision tree classifiers. Our 
results indicate that machine learning is an 
effective approach to improving the accuracy 
of discourse marker tagging. For interactive 
use of the system, if we set a threshold for 
the rule precision and only display those low 
precision rules for interactive selection, we 
can greatly speed up the semi-automatic 
tagging process. 
7 References  
Chart S., Lai T., Gao W. J. and T'sou B. K. 
(2000) "Mining Discourse Markers for 
Chinese Textual Summarization." In 
Proceedings of the Sixth Applied Natural 
Language Processing Conference and the 
North American Chapter of the 
Association for Computational Linguistics. 
Workshop on Automatic Summarization, 
Seattle, Washington, 29 April to 3 May, 
2000. 
Grosz B.J. and Sidner C. (1986) "Attention, 
Intention, and the Structure of Discourse," 
Computational Linguistics 12(3): 175-204. 
Hirst G. (1981) "Discourse Oriented 
Anaphoral Resolution in Natural Language 
Understanding: A Review." Computational 
Linguistics 7(2): 85-98. 
Hovy E. (1993) "Automated Discourse 
Generation using Discourse Structure 
Relations." Artificial Intelligence 63: 341- 
385. 
Hwang C. H. and Schubert L. K. (1992) 
"Tense Trees as the 'Fine Structure' of 
Discourse." In Proc. 30th Annual Meeting, 
Assoc. for Computational Linguistics, pp. 
232-240. 
Lin H. L., T'sou B. K., H. C. Ho, Lai T., Lun 
C., C. K. Choi and C.Y. Kit. (1991) 
"Automatic Chinese Text Generation 
Based on Inference Trees." In Proe. of 
ROCLING Computational Linguistic 
Conference IV, Taipei, pp. 215-236. 
Litman D. J. and Allen J. (1990) "Discourse 
Processing and Commonsense Plans." In 
Cohen et al(ed.) Intentions in 
Communications, pp. 365-388. 
Mann W. C. and Thompson S. A (1988) 
"Rhetorical Structure Theory: Towards a 
Functional Theory of Text Organization." 
44 
? Text 8(3): 243-281. 
Marcu D. (1997) "From Discourse Structures 
to Text Summaries." In Proceedings of the 
ACL/EACL'97 Workshop on Intelligent 
Scalable Text Summarization, Spain, pp. 
82-88. 
McKeown K. and Radev D. (1995) 
"Summaries of Multiple News Articles." 
In Proceedings of the 18th Annual 
International ACM SIGIR Conference on 
Research and Development in Information 
Retrieval, Seattle, pp. 74-82. 
Ono K., Surnita K. and S. Miike. (1994) 
"Abstract Generation based on Rhetorical 
Structure Extraction." In Proceedings of 
International Conference on 
Computational Linguistics, Japan, pp. 344- 
348. 
Paice C. D. (1990) "Constructing Literature 
Abstracts by Computer: Techniques and 
Prospects." Information Processing and 
Management 26(1): 171-186. 
Qulnlan J. Ross (1993) "C4.5 Programs for 
Machine Learning." San Mateo, CA: 
Morgan Kaufmann. 
T'sou B. K., Ho H. C., Lai B. ?., Lun C. and 
Lin H. L. (1992) "A Knowledge-based 
Machine-aided System for Chinese Text 
Abstraction." In Proceedings of 
International Conference on 
Computational Linguistics, France, pp. 
1039-1042. 
T'sou B. K., Gao W. J., Lin H. L., Lai T. B. 
Y. and Ho H. C. (1999) "Tagging 
Discourse Markers: Towards a Corpus 
based Study of Discourse Marker Usage in 
Chinese Text" In Proceedings of the 18th 
International Conference on Computer 
Processing of Oriental Languages, March 
1999, Japan, pp. 391-396. 
T'sou B. K., Lin H. L., Ho H. C., Lai T. and 
Chan T. (1996) "Automated Chinese Full- 
text Abstraction Based on Rhetorical 
Structure Analysis." Computer Processing 
of Oriental Languages 10(2): 225-238. 
Tsou, B.K., et al, 1998: ~1~,  ~ ,  
i ~ ~ 1 - ~ 3 - ~ ~  ~ ~ " ,  
ICCIP'98, Beijing, Nov. 18-20, 1998. 
45 
An Agent-Based Approach to Chinese Word Segmentation 
Samuel W.K. Chan 
Dept. of Decision Sciences 
The Chinese University of Hong Kong 
Hong Kong, China 
swkchan@cuhk.edu.hk 
Mickey W.C. Chong 
Dept. of Decision Sciences 
The Chinese University of Hong Kong
Hong Kong, China 
mickey@baf.msmail.cuhk.edu.hk
 
 
Abstract 
This paper presents the results of our sys-
tem that has participated in the word seg-
mentation task in the Fourth SIGHAN 
Bakeoff. Our system consists of several ba-
sic components which include the pre-
processing, token identification and the 
post-processing. An agent-based approach 
is introduced to identify the weak segmen-
tation points. Our system has participated 
in two open and five closed tracks in five 
major corpora. Our results have attained 
top five in most of the tracks in the bakeoff. 
In particular, it is ranked first in the open 
track of the corpus from Academia Sinica, 
second in the closed track of the corpus 
from City University of Hong Kong, third 
in two closed tracks of the corpora from 
State Language Commission of P.R.C. and 
Academia Sinica. 
1 Introduction 
Our word segmentation system consists of three 
major components, namely, the pre-processing, 
token identification and the post-processing. In this 
paper, an overview of our system is briefly intro-
duced and the structure of the paper is as follows. 
Section 2 presents the system description. An agent 
based approach is introduced in the system. Asso-
ciated to each agent in the system, a vote is cast to 
indicate the certainty by each agent in the system. 
In Section 3, we describe the experimental results 
of our system, followed by the conclusion.  
 
2 System Description 
2.1 Preprocessing  
In the preprocessing, the traditional Chinese char-
acters, punctuation marks and other symbols are 
first identified. Instead of training all these sym-
bols with the traditional Chinese characters in an 
agent-based system, an initial, but rough, segmen-
tation points (SPr) are first inserted to distinguish 
the symbols and Chinese characters. For example, 
for the input sentence shown in Figure 1, segmen-
tation points are first assumed in the sentence as 
shown in the Figure 2, where ?/? indicates the pres-
ence of a segmentation point. This roughly seg-
mented sentence is then subject to an agent-based 
learning algorithm to have the token identification.   
 
?? 6 ? 05 ??????????????
????????????? 
Figure 1: Original sentence for the process 
 
??/ 6/ ?/ 05/ ????????????
????????/ ?/ ????/ ?/ ? 
Figure 2: Rough segmented sentence from pre-
processing 
 
2.2 Token Identification 
In this stage, a learning algorithm is first devised 
and implemented. The algorithm is based on an 
agent based model which is a computational model 
for simulating the actions and interactions of an 
orchestra of autonomous agents in the determina-
tion of the possible segmentation points (SPl) 
(Weiss, 1999; Wooldridge, 2002). Each agent will 
112
Sixth SIGHAN Workshop on Chinese Language Processing
make its own decision, i.e., either true or false, for 
the insertion of ?/? between the two characters. 
Moreover, associated with each decision, there is a 
vote that reflects the certainty of the decision. For 
each training corpus, we have trained more than 
200 intelligent agents, each of which exhibits cer-
tain aspects of segmentation experience and lan-
guage behaviors. In making the final verdict, the 
system will consult all the related agents by sum-
ming up their votes. For example, as shown in Ta-
ble 1, the vote that supports there is a segmentation 
point between the characters ? and ?  is zero 
while 57.33 votes recommend that there should 
have no break point. All these votes are logged for 
the further post-processing. 
 
C1 C2 Vote(T) Vote(F) ND Outcome
? ? 0 57.33 1.000 false 
? ? 44.52 6.54 0.744 true 
? ? 0 57.74 1.000 false 
? ? 64.61 0 1.000 true 
? ? 0 60.23 1.000 false 
? ? 56.29 0.99 0.965 true 
? ? 0.58 58.22 0.980 false 
? ? 58.21 0 1.000 true 
? ? 57.80 0 1.000 true 
? ? 0 51.34 1.000 false 
? ? 48.70 0 1.000 true 
? ? 60.04 0 1.000 true 
? ? 0 53.97 1.000 false 
? ? 46.19 2.00 0.917 true 
? ? 0 58.32 1.000 false 
? ? 62.44 0 1.000 true 
? ? 59.16 0 1.000 true 
? ? 4.89 40.81 0.786 false 
? ? 45.83 3.41 0.862 true 
? ? 0 60.91 1.000 false 
? ? 0 59.39 1.000 false 
? ? 54.44 0.48 0.983 true 
? ? 11.98 27.94 0.400 false 
Table 1: Votes from agents and the ND of the cor-
responding segment point. 
 
??/ 6 / ?/ 05 / ?/ ??/ ??/ ??/ ?
/ ??/ ?/ ??/ ??/ ?/ ??/ ??/ ?/ 
??/ ??/ ?/ ? 
Figure 3: Segmented sentence based on the votes 
from all agents. 
 
2.3 Post-processing 
In our experience, our system is most likely to 
generate over-segmented sentences. Several tech-
niques have implemented in our post-processing to 
merge several tokens into ones. As shown in the 
previous steps, we have introduced two main types 
of segmentation points, SPr and SPl. In the type SPr, 
segmentation points are pre-inserted between sym-
bol and Chinese characters. For example, the token 
6 ? will become 6/ ? in the early beginning. 
Obviously, this kind of errors should be identified 
and the segmentation points should be removed. 
Similarly, in SPl, segmentation points are decided 
by the votes. Our post-processing is to identify the 
weak segmentation points which are having tie-
break votes. A normalized difference (ND) is de-
fined for the certainty of the segmentation.  
falsetrue
falsetrue
VoteVote
VoteVote
ND +
?=  Eqn.(1)
 
The smaller the value of the ND, the lesser the cer-
tainty of the segmentation point. We define the 
segmentation point as weak if the value of ND is 
smaller than a threshold. For a weak segmentation 
point, the system will consult a dictionary and 
search for the presence of the token in the diction-
ary. The segmentation point will be removed if 
found. Otherwise, the system will leave as it is. As 
shown in the Table 1, almost all segmentation 
points with the ND value equal to 1. This shows 
that all the votes from the agents support the same 
decision. However, it seems that not all agents 
have the same decision to the last characters pair 
????, with ND equal to 0.4. If the threshold is 
set to be 0.4, the segmentation point will be re-
examined in our post-processing. 
Our dictionary is constructed by tokens from the 
training corpus and the local context of the text 
that is being segmented. That is to say, besides the 
corpus, the tokens from the previous segmented 
text will also contribute to the construction of the 
dictionary. On the other hand, Chinese idiom 
should be in one token as found in most dictionar-
ies. However, idiom sometimes would be identi-
fied as a short phrase and segmented into several 
pieces. In this case, we tend to merge these small 
fragments into one long token. On the other hand, 
different training sources may produce different 
segmentation rules and, thus, produce different 
113
Sixth SIGHAN Workshop on Chinese Language Processing
segmentation results. In the open tracks, some 
handlers are tailor-made for different testing data. 
These include handlers for English characters, date, 
time, organization. 
 
??/ 6 ?/ 05 ?/ ??/ ??/ ??/ ?/ ?
?/ ?/ ??/ ??/ ?/ ??/ ??/ ?/ ?
?/ ??/ ?/ ? 
Figure 4: Final result of the segmentation 
 
3 Experiments and Results 
We have participated in five closed tracks and two 
open tracks in the bakeoff. While we have built a 
dictionary from each training data set for the 
closed tracks, a dictionary of more than 150,000 
entries is maintained for the open tracks. Table 2 
shows the size of the training data sets. 
 
Source of training data Size 
Academia Sinica (CKIP) 721,551
City University of Hong Kong (CityU) 1,092,687
University of Colorado (CTB) 642,246
State Language Commission of P.R.C. 
(NCC) 
917,255
Shanxi University (SXU) 528,238
Table 2: Size of the training data in the bakeoff. 
 
Tables 3 and 4 show the recall (R), precision (P), 
F-score (F) and our ranking in the bakeoff. All the 
rankings are produced based on the best run of the 
participating teams in the tracks. 
 
 R P F Rank
CityU 0.9513 0.9430 0.9471 2nd 
CKIP 0.9455 0.9371 0.9413 3rd 
NCC 0.9365 0.9365 0.9365 3rd 
SXU 0.9558 0.9552 0.9555 5th 
Table 3: Performance of our system in the closed 
tracks of word segmentation task in the bakeoff. 
 
 R P F Rank
CKIP 0.9586 0.9541 0.9563 1st 
NCC 0.9440 0.9517 0.9478 4th 
Table 4: Performance of our system in the open 
tracks of word segmentation task in the bakeoff.  
 
From the above tables, we have the following ob-
servations: 
y First, our system is performing well if it is a 
sufficient large set of training data. This is 
evidenced by the results found in the training 
data from CKIP, CityU and NCC.   
y Second, the dictionaries play an important 
role in our open tracks. While we have main-
tained a dictionary with 150,000 traditional 
Chinese words, no such a device is for our 
simplified characters corpora. Certainly, there 
is a room for our further improvement. 
4 Conclusion 
In this paper, we have presented the general over-
view of our segmentation system. Even though, it 
is our first time to participate the bakeoff, the ap-
proach is promising. Further exploration is needed 
to enhance the system.   
Acknowledgement 
The work described in this paper was partially 
supported by the grants from the Research Grants 
Council of the Hong Kong Special Administrative 
Region, China (Project Nos. CUHK4438/04H and 
CUHK4706/05H). 
 
References 
Weiss, G. (1999) Multiagent Systems, A Modern 
Approach to Distributed Artificial Intelligence, MIT 
Press. 
Wooldridge, M. (2002). An Introduction to MultiAgent 
Systems, John Wiley. 
 
114
Sixth SIGHAN Workshop on Chinese Language Processing
Coling 2010: Poster Volume, pages 117?125,
Beijing, August 2010
Tree Topological Features for Unlexicalized Parsing
Samuel W. K. Chan? Lawrence Y. L. Cheung# Mickey W. C. Chong?
?Dept. of Decision Sciences 
Chinese University of Hong Kong 
#Dept. of Linguistics & Modern Languages 
Chinese University of Hong Kong 
{swkchan, yllcheung, mickey_chong}@cuhk.edu.hk 
Abstract 
As unlexicalized parsing lacks word to-
ken information, it is important to inves-
tigate novel parsing features to improve 
the accuracy. This paper studies a set of 
tree topological (TT) features. They 
quantitatively describe the tree shape 
dominated by each non-terminal node. 
The features are useful in capturing lin-
guistic notions such as grammatical 
weight and syntactic branching, which 
are factors important to syntactic proc-
essing but overlooked in the parsing lit-
erature. By using an ensemble classifier-
based model, TT features can signifi-
cantly improve the parsing accuracy of 
our unlexicalized parser. Further, the 
ease of estimating TT feature values 
makes them easy to be incorporated into 
virtually any mainstream parsers.  
1 Introduction 
Many state-of-the-art parsers work with lexical-
ized parsing models that utilize the information 
and statistics of word tokens (Magerman, 1995; 
Collins, 1999, 2003; Charniak, 2000). The per-
formance of lexicalized models is susceptible to 
vocabulary variation as lexical statistics is often 
corpus-specific (Ratnaparkhi, 1999; Gildea, 
2001). As parsers are typically evaluated using 
the Penn Treebank (Marcus et al, 1993), which 
is based on financial news, the problems of 
lexicalized parsing could easily be overlooked. 
Unlexicalized models, on the other hand, are 
less sensitive to lexical variation and are more 
portable across domains. Though the perform-
ance of unlexicalized models was believed not 
to exceed that of lexicalized models (Klein & 
Manning, 2003), Petrov & Klein (2007) show 
that unlexicalized parsers can match lexicalized 
parsers in performance using the grammar rule 
splitting technique. Given the practical advan-
tages and the latest development, unlexicalized 
parsing deserves further scrutiny.  
A profitable direction of research on unlexi-
calized parsing is to investigate novel parsing 
features. This paper examines a set of what we 
call tree topological (TT) features, including 
phrase span, phrase height, tree skewness, etc. 
This study is motivated by the fact that conven-
tional parsers rarely consider the shape of 
subtrees dominated by these nodes and rely 
primarily on matching tags. As a result, an NP 
with a complicated structure is treated the same 
as an NP that dominates only one word. How-
ever, our study shows that TT features are use-
ful predictors of phrase boundaries, a critical 
ambiguity resolution issue. TT features have 
two more advantages. First, TT features capture 
linguistic properties, such as branching and 
grammatical ?heaviness?, across different syn-
tactic structures. Second, they are easily com-
putable without the need for extra language re-
sources.  
The organization of the paper is as follows. 
Section 2 reviews the features commonly used 
in parsing. Section 3 provides the details of TT 
features in the unlexicalized parser. The parser 
is evaluated in Section 4. In Section 5, we 
discuss the effectiveness and advantages of TT 
features in parsing and possible enhancement. 
This is followed by a conclusion in Section 6. 
2 Related Work 
2.1 Parsing Features 
This section reviews major types of information 
in parsing.  
117
Tags: The dominant types of information that 
drive parsing and chunking algorithms are 
POS/syntactic tags, context-free grammar (CFG) 
rules, and their statistical properties. Matching 
tags against CFG rules to form phrases is central 
to all basic parsing algorithms such as Cocke-
Kasami-Younger (CKY) algorithm, and the Ear-
ley algorithm, and the chart parsing.  
Word Token-based: Machine learning and sta-
tistical modelling emerged in the 90s as an ideal 
computational approach to feature-rich parsing. 
Classifiers can typically capitalize on a large set 
of features in decision making. Magerman 
(1995), Ratnaparkh (1999) and Charniak (2000) 
used classifiers to model dependencies between 
word pairs. They popularized the use word to-
kens as attributes in lexicalized parsing. Collins 
(1999, 2003) also integrated information like 
head word and distance from head into the sta-
tistical model to enhance probabilistic chart 
parsing. Since then, word tokens, head words 
and their statistical derivatives have become 
standard features in many parsers. Word token 
information is also fundamental to dependency 
parsing (K?bler et al, 2009) because depend-
ency grammar is rooted in the idea that the head 
and the dependent word are related by different 
dependency relations.  
Semantic-based: Some efforts have also been 
made to consider semantic features, such as 
sense tags, in parsing. Words are first tagged 
with semantic classes, often using WordNet-
based resources. The lexical semantic class can 
be instructive to the selection of the correct 
parse from a set of candidate structures. It has 
been reported that the lexical semantics of 
words is effective in resolving structural ambi-
guity, especially PP-attachment (Black et al, 
1992; Stetina & Nagao, 1997; Agirre et al, 
2008). Nevertheless, the use of semantic fea-
tures has still been relatively rare. They incur 
overheads in acquiring semantic language re-
sources, such as sense-tagged corpora and 
WordNet databases. Semantic-based parsing 
also requires accurate sense-tagging.  
Since substantial gain from tag features is 
unlikely in the near future and deriving seman-
tic features is often a tremendous task, there is a 
pressing need to seek for new features, particu-
larly in unlexicalized parsing. 
2.2 Linguistic-motivated Features 
In this section, a review of the linguistic motiva-
tion behind the TT features is provided. 
Grammatical Weight: Apart from syntactic 
categories, linguists have long observed that the 
number of words (often referred to as ?weight? 
or ?heaviness?) in a phrase can affect syntactic 
processing of sentences (Quirk et al, 1985; Wa-
sow, 1997; Rosenbach, 2005). It corresponds 
roughly to the span feature described in Section 
3.2. The effect of grammatical weight often 
manifests in word order variation. Heavy NP 
shift, dative alternation, particle movement and 
extraposition in English are canonical examples 
where ?heavy? chunks get dislocated to the end 
of a sentence. In his corpus analysis, Wasow 
(1997) found that weight is a very crucial factor 
in determining dative alternation. Hawkins 
(1994) also argued that due to processing con-
straints, the human syntactic processor tends to 
group an incoming stream of words as rapidly 
as possible, preferring smaller chunks on the left.
Tree Topology: CFG-based parsing approach 
hides the structural properties of the dominated 
subtree from the associated syntactic tag. Struc-
tural topology, or tree shape, however, can be 
useful in guiding the parser to group tags into 
phrases. Structures significantly deviating from 
left/right branching, e.g. center embedding, are 
much more difficult to process and rare in pro-
duction (Gibson, 1998). Another example is the 
resolution of scope ambiguity in coordinate 
structures (CSs). CSs are common but notori-
ously difficult to parse due to scope ambiguity 
when the conjuncts are complex (Collins, 1999; 
K?bler et al, 2009). One good cue to the prob-
lem is that humans prefer CSs with parallel in-
ternal syntactic structures (Frazier et al, 2000). 
In a corpus-based study, Dubey et al (2008) 
show that structural repetition across conjuncts 
is significantly more frequent. The implication 
to parsing is that preference should be given to 
bracketing in which conjuncts are structurally 
similar. TT information can inform the parser of 
the structural properties of phrases.  
3 An Ensemble-based Parser 
To accommodate a large set of features, we opt 
for classifier-based parsing because classifiers 
118
can easily handle many features, as pointed out 
in Ratnaparkhi (1999). This is different from 
chart parsing models popular in many parsers 
(e.g. Collins, 2003) which require special statis-
tical modelling. Our parser starts from a string 
of POS tags without any hints from words. As 
in other similar approaches (Abney 1991; Ram-
shaw & Marcus, 1995; Sang, 2001; Sagae & 
Lavie, 2005), the first and the foremost problem 
that has to be resolved is to identify the bound-
ary points of phrases, without any explicit 
grammar rules. Here we adopt the ensemble 
learning technique to unveil boundary points, or 
chunking points hereafter. Two heterogeneous 
and mutually independent attribute feature sets 
are introduced in Section 3.2 and 3.3.   
3.1 Basic Architecture of the Parser 
Our parser has two modules, namely, a chunker 
and a phrase recognizer. The chunker locates 
the boundaries of chunks while the phrase rec-
ognizer predicts the non-terminal syntactic tag 
of the identified chunks, e.g. NP, VP, etc. In the 
chunker, we explore a new approach that aims 
at identifying chunk boundaries. Assume that 
the input of the chunker is a tag sequence <x0 ? 
xn ? xm> where 0 ? n ? m. Let yn be the point of 
focus between two consecutive tags xn and xn+1. 
The chunker classifies all focus points as either 
a chunking point or a merging point at the rele-
vant level. A focus point yn is a merging point if 
xn and xn+1 are siblings of the same parent node 
in the target parse tree. Otherwise, yn is a chunk-
ing point. Consider the tag sequence and the 
expected classification of points in the example 
below. Chunking points are marked with ?%? 
and merging points with ?+?. 
PRP % VBZ % DT % RB   +  JJ  % NN 
He    is    a    very    nice  guy  
The point between RB and JJ is a merging 
point because they are siblings of the parent 
node ADJP in the target parse tree. The point 
between DT and RB is a chunking point since 
DT and RB are not siblings and do not share the 
same parent node. Chunks are defined as the 
consecutive tag sequences not split up by %. 
When a focus point yn is classified as a chunk-
ing point, it effectively means that no fragment 
preceding yn can combine with any fragment 
following yn to form a phrase, i.e. a distituent.  
Both the chunker and the recognizer are 
trained using the Penn Treebank (Marcus et al, 
1993). In addition, we adopt the ensemble tech-
nique to combine two sets of heterogeneous fea-
tures. The method yields a much more accurate 
predictive power (Dietterich, 2000). One neces-
sary and sufficient condition for an ensemble of 
classifiers to be more accurate than any of its 
individual members is that the classifiers must 
be diverse. Table 1 summaries the basic ration-
ale of the parser. The two feature sets will be 
further explained in Section 3.2 and 3.3.  
 Prepare training data from the Treebank based 
on topological & information-theoretic features 
 Train the chunker and phrase recognizer using 
the ensemble technique 
 For any input tag sequence l,  
WHILE l contains more than one element DO 
IDENTIFY the status, + or %, of each focus 
point in l
RECOGNIZE the syntactic tag (ST) of each 
identified chunk 
UPDATE l with the new ST sequence
ENDWHILE 
 Display the parse tree 
Table 1. Basic rationale of the parser 
The learning module acquires the knowledge 
encoded in the Penn Treebank to support vari-
ous classification tasks. The input tag sequence 
is first fed into the chunker. The phrase recog-
nizer then analyzes the chunker?s output and 
assigns non-terminal syntactic tags (e.g. NP, VP, 
etc.) to identified chunks. The updated tag se-
quence is fed back to the chunker for processing 
at the next level. The iteration continues until a 
complete parse is formed. 
3.2 Tree Topological Feature Set 
Tree topological (TT) features describe the 
shape of subtrees quantitatively. Our approach 
to addressing this problem involves examining a 
set of topological features, without any assump-
tion of the word tokens. They all have been im-
plemented for chunking.  
Node Coordinates (NCs): NCs include the level 
of focus (LF) and the relative position (RP) of 
the target subtree. The level of focus is defined 
as the total number of levels under the target 
node, with the terminal level inclusive while the 
RP indicates the linear position of the target 
node in that level. As in Figure 1, the LF for 
119
subtree A and B are the same; however, the RP
for subtree A is smaller than that for subtree B.  
Span Ratio (SR): The SR is defined as the total 
number of terminal nodes spanned under the 
target node and is divided by the length of the 
sentence. In Figure 1, the span ratio for the tar-
get node VP at subtree B is 5/12. This ratio il-
lustrates not only how many terminal nodes are 
covered by the target node, but also how far the 
target node is from the root S.  
Aspect Ratio (AR): The AR of a target node in a 
subtree is defined as the ratio of the total num-
ber of non-terminal nodes involved to the total 
number of terminal nodes spanned. The AR is 
also indicative of the average branching factor 
of the subtree.  
Skewness Measure (SM): The SM estimates the 
degree to which the subtree leans towards either 
left or right. In this research, the SM of a subtree 
is evaluated by the distribution of the length of 
the paths connecting the target node and each 
terminal node it dominates. The length of a path 
from a target node V to a terminal node T is the 
number of edges between V and T. For a tree 
with n terminal nodes, there are n paths. A pivot 
is defined as the [n/2]th terminal node when n is 
odd and between [n/2]th and [(n+1)/2]th termi-
nal nodes if n is even, where [ ] is a ceiling 
function. The SM is defined as  
( )
??
??
?
?
??
??
?
?
?
=
?
?
=
>
3
1
3
0
1
?
?
?
?
n
i
ii
i
xx
SM
i
          Eqn (1) 
where xi is the length of the i-th path pointing to 
the i-th terminal node, x and ? are the average 
and standard deviation of the length of all paths 
at that level of focus (LF). ?i is the distance 
measured from the i-th terminal node to the 
pivot. The distance is positive if the terminal 
node is to the left of the pivot, zero if it is right 
at the pivot, and negative if the terminal node is 
to the right of the pivot. Obviously, if the 
lengths of all paths are the same in the tree, the 
numerator of Eqn (1) will be crossed out and the 
SM returns to zero. The pivot also provides an 
axis of vertical flipping where the SM still holds. 
The farther the terminal node from the pivot, the 
longer the distance. The distances ? provide the 
moment factors to quantify the skewness of 
trees. For illustration, let us consider subtree B
with the target node VP at level of focus (LF) = 
4 in Figure 1. Since there are five terminal 
nodes, the pivot is at the third node VB. The 
lengths of the paths xi from left to right in the 
subtree are 1, 2, 3, 4, 4 and the moment factors 
?i for the paths are 2, 1, 0, -1, -2. Assuming that 
x and ? for all the trees in the Treebank at 
level 4 are, say, 2.9 and 1.2 respectively, then 
SM = -3.55. It implies that subtree B under the 
target node VP has a strong right branching ten-
dency, even though it has a very uniform 
branching factor which is usually defined as the 
number of children at each node. 









	
	

 

       
 

