Proceedings of the 7th Workshop on Statistical Machine Translation, pages 267?274,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
Formemes in English-Czech Deep Syntactic MT ?
Ondr?ej Du?ek, Zdene?k ?abokrtsk?, Martin Popel,
Martin Majli?, Michal Nov?k, and David Marec?ek
Charles University in Prague, Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
Malostransk? n?me?st? 25, Prague
{odusek,zabokrtsky,popel,majlis,mnovak,marecek}@ufal.mff.cuni.cz
Abstract
One of the most notable recent improve-
ments of the TectoMT English-to-Czech trans-
lation is a systematic and theoretically sup-
ported revision of formemes?the annotation
of morpho-syntactic features of content words
in deep dependency syntactic structures based
on the Prague tectogrammatics theory. Our
modifications aim at reducing data sparsity,
increasing consistency across languages and
widening the usage area of this markup.
Formemes can be used not only in MT, but in
various other NLP tasks.
1 Introduction
The cornerstone of the TectoMT tree-to-tree ma-
chine translation system is the deep-syntactic lan-
guage representation following the Prague tec-
togrammatics theory (Sgall et al, 1986), and its ap-
plication in the Prague Dependency Treebank (PDT)
2.01 (Hajic? et al, 2006), where each sentence is
analyzed to a dependency tree whose nodes corre-
spond to content words. Each node has a number
of attributes, but the most important (and difficult)
for the transfer phase are lemma?lexical informa-
tion, and formeme?surface morpho-syntactic infor-
? This research has been supported by the grants
FP7-ICT-2009-4-247762 (FAUST), FP7-ICT-2009-4-249119
(Metanet), LH12093 (Kontakt II), DF12P01OVV022 (NAKI),
201/09/H057 (Czech Science Foundation), GAUK 116310, and
SVV 265 314. This work has been using language resources de-
veloped and/or stored and/or distributed by the LINDAT-Clarin
project of the Ministry of Education of the Czech Republic
(project LM2010013).
1http://ufal.mff.cuni.cz/pdt2.0
mation, including selected auxiliary words (Pt?c?ek
and ?abokrtsk?, 2006; ?abokrtsk? et al, 2008).
This paper focuses on formemes?their definition
and recent improvements of the annotation, which
has been thoroughly revised in the course of prepa-
ration of the CzEng 1.0 parallel corpus (Bojar et al,
2012b), whose utilization in TectoMT along with the
new formemes version has brought the greatest ben-
efit to our English-Czech MT system in the recent
year. However, the area of possible application of
formemes is not limited to MT only or to the lan-
guage pair used in our system; the underlying ideas
are language-independent.
We summarize the development of morpho-
syntactic annotations related to formemes (Sec-
tion 2), provide an overview of the whole TectoMT
system (Section 3), then describe the formeme an-
notation (Section 4) and our recent improvements
(Section 5), as well as experimental applications, in-
cluding English-Czech MT (Section 6). The main
asset of the formeme revision is a first systematic re-
organization of the existing practical aid, providing
it with a solid theoretical base, but still bearing its
intended applications in mind.
2 Related Work
Numerous theoretical approaches had been made
to morpho-syntactic description, mainly within va-
lency lexicons, starting probably with the work by
Helbig and Schenkel (1969). Perhaps the best one
for Czech is PDT-VALLEX (Hajic? et al, 2003), list-
ing all possible subtrees corresponding to valency
arguments (Ure?ov?, 2009). ?abokrtsk? (2005)
gives an overview of works in this field.
267
This kind of information has been most exploited
in structural MT systems, employing semantic re-
lations (Menezes and Richardson, 2001) or surface
tree substructures (Quirk et al, 2005; Marcu et al,
2006). Formemes, originally developed for Natural
Language Generation (NLG) (Pt?c?ek and ?abokrt-
sk?, 2006), have been successfully applied to MT
within the TectoMT system. Our revision of for-
meme annotation aims to improve the MT perfor-
mance, keeping other possible applications in mind.
3 The TectoMT English-Czech Machine
Translation System
The TectoMT system is a structural machine trans-
lation system with deep transfer, first introduced
by ?abokrtsk? et al (2008). It currently supports
English-to-Czech translation. Its analysis stage
follows the Prague tectogrammatics theory (Sgall,
1967; Sgall et al, 1986), proceeding over two layers
of structural description, from shallow (analytical)
to deep (tectogrammatical) (see Section 3.1).
The transfer phase of the system is based on Max-
imum Entropy context-sensitive translation models
(Marec?ek et al, 2010) and Hidden Tree Markov
Models (?abokrtsk? and Popel, 2009). It is factor-
ized into three subtasks: lemma, formeme and gram-
matemes translation (see Sections 3.2 and 3.3).
The subsequent generation phase consists of rule-
based components that gradually change the deep
target language representation into a shallow one,
which is then converted to text (cf. Section 6.1).
The version of TectoMT submitted to WMT122
builds upon the WMT11 version. Several rule-based
components were slightly refined. However, most of
the effort was devoted to creating a better and bigger
parallel treebank?CzEng 1.03 (Bojar et al, 2012b),
and re-training the statistical components on this re-
source. Apart from bigger size and improved filter-
ing, one of the main differences between CzEng 0.9
(Bojar and ?abokrtsk?, 2009) (used in WMT11) and
CzEng 1.0 (used in WMT12) is the revised annota-
tion of formemes.
2http://www.statmt.org/wmt12
3http://ufal.mff.cuni.cz/czeng
3.1 Layers of structural analysis
There are two distinct structural layers used in the
TectoMT system:
? Analytical layer. A surface syntax layer, which
includes all tokens of the sentence, organized
into a labeled dependency tree. The labels cor-
respond to surface syntax functions.
? Tectogrammatical layer. A deep syntax/se-
mantic layer describing the linguistic meaning
of the sentence. Its dependency trees include
only content words as nodes, assigning to each
of them a deep lemma (t-lemma), a semantic
role label (functor), and other deep linguistic
features (grammatemes), such as semantic part-
of-speech, person, tense or modality.
The analytical layer can be obtained using differ-
ent dependency parsers (Popel et al, 2011); the tec-
togrammatical representation is then created by rule-
based modules from the analytical trees.
In contrast to the original PDT annotation,
the TectoMT tectogrammatical layer also includes
formemes describing the surface morpho-syntactic
realization of the nodes (cf. also Section 3.3).
3.2 Transfer: Translation Factorization and
Symmetry
Using the tectogrammatical representation in struc-
tural MT allows separating the problem of translat-
ing a sentence into relatively independent simpler
subtasks: lemma, functors, and grammatemes trans-
lation (Bojar et al, 2009; ?abokrtsk?, 2010). Since
topology changes to deep syntax trees are rare in MT
transfer, each of these three subtasks allows a vir-
tually symmetric source-target one-to-one mapping,
thus simplifying the initial n-to-m mapping of word
phrases or surface subtrees.
?abokrtsk? et al (2008) obviated the need for
transfer via functors (i.e. semantic role detection)
by applying a formeme transfer instead. While
formeme values are much simpler to obtain by au-
tomatic processing, this approach preserved the ad-
vantage of symmetric one-to-one value translation.
Moreover, translations of a given source morpho-
syntactic construction usually follow a limited num-
ber of patterns in the target language regardless of
268
their semantic functions, e.g. a finite clause will
most often be translated as a finite clause.
3.3 Motivation for the Introduction of
Formemes
Surface-oriented formemes have been introduced
into the semantics-oriented tectogrammatical layer,
as it proves beneficial to combine the deep syntax
trees, smaller in size and more consistent across lan-
guages, with the surface morphology and syntax to
provide for a straightforward transition to the surface
level (?abokrtsk?, 2010).
The three-fold factorization of the transfer phase
(see Section 3.2) helps address the data sparsity is-
sue faced by today?s MT systems. As the translation
of lemmas and their morpho-syntactic forms is sepa-
rated, combinations unseen in the training data may
appear on the output.
To further reduce data sparsity, only minimal in-
formation needed to reconstruct the surface form is
stored in formemes; morphological categories deriv-
able from elsewhere, i.e. morphological agreement
or grammatemes, are discarded.
4 Czech and English Formemes in
TectoMT
A formeme is a concise description of relevant
morpho-syntactic features of a node in a tectogram-
matical tree (deep syntactic tree whose nodes usu-
ally correspond to content words). The general
shape of revised Czech and English formemes, as
implemented within the Treex4 NLP framework
(Popel and ?abokrtsk?, 2010) for the TectoMT sys-
tem, consists of three main parts:
1. Syntactic part-of-speech.5 The number of syn-
tactic parts-of-speech is very low, as only con-
tent words are used on the deep layer and the
categories of pronouns and numerals have been
divided under nouns and adjectives accord-
ing to syntactic behavior (?evc??kov?-Raz?mov?
and ?abokrtsk?, 2006). The possible values are
v for verbs, n for nouns, adj for adjectives,
and adv for adverbs.
4http://ufal.mff.cuni.cz/treex/,
https://metacpan.org/module/Treex
5Cf. Section 5.2 for details.
2. Subordinate conjunction/preposition. Applies
only to formemes of prepositional phrases and
subordinate clauses introduced by a conjunc-
tion and contains the respective conjunction or
preposition; e.g. if, on or in_case_of.
3. Form. This part represents the morpho-
syntactic form of the node in question and de-
pends on the part-of-speech (see Table 1).
The two or three parts are concatenated into
a human-readable string to facilitate usage in
hand-written rules as well as statistical systems
(?abokrtsk?, 2010), producing values such as
v:inf, v:if+fin or n:into+X. Formeme val-
ues of nodes corresponding to uninflected words are
atomic.
Formemes are detected by rule-based modules op-
erating on deep and surface trees. Example deep
syntax trees annotated with formemes are shown in
Fig. 1. A listing of all possible formeme values is
given in Table 1.
Verbal formemes remain quite consistent in both
languages, except for the greater range of forms in
English (Czech uses adjectives or nouns instead of
gerunds and verbal attributes). Nominal formemes
differ more significantly: Czech is a free-word order
language with rich morphology, where declension
is important to syntactic relations?case is therefore
included in formemes. As English makes its syntac-
tic relations visible rather with word-order than with
morphology, English formemes indicate the syntac-
tic position instead. The same holds for adjecti-
val complements to verbs. Posession is expressed
mostly using nouns in English and adjectives in
Czech, which is also reflected in formemes.
5 Recent Markup Improvements
Our following markup innovations address several
issues found in the previous version and aim to adapt
the range of values more accurately to the intended
applications.
5.1 General Form Changes
The relevant preposition and subordinate conjunc-
tion nodes had been selected based on their depen-
dency labels; we use a simple part-of-speech tag fil-
ter instead in order to minimize the influence of pars-
ing errors and capture more complex prepositions,
269
Figure 1: An example English and Czech deep sentence structure annotated with formemes (in typewriter font).
Formeme Language Definition
v:(P+)fin both Verbs as heads of finite clauses
v:rc both Verbs as heads of relative clauses
v:(P+)inf both Infinitive clauses; typically with the particle to in English?
v:(P+)ger EN Gerunds, e.g. I like reading (v:ger), but I am tired of arguing (v:of+ger).
v:attr EN Present or past participles (i.e. -ing or -ed forms) in the attributive syntactic
position, e.g. Striking (v:attr) teachers hate bored (v:attr) students.
n:[1..7] CS Bare nouns; the numbers indicate morphological case?
n:X CS Bare nouns that cannot be inflected
n:subj EN Nouns in the subject position (i.e. in front of the main verb of the clause)
n:obj EN Nouns in the object position (i.e. following the verb with no preposition)
n:obj1, n:obj2 EN Nouns in the object position; distinguishing the two objects of ditransitive
verbs (e.g. give, consider)
n:adv EN Nouns in an adverbial position, e.g. The sales went up by 1 % last month
n:P+X EN Prepositional phrases
n:P+[1..7] CS Prepositional phrases; the preposition surface form is combined with the re-
quired case?
n:attr both Nominal attributes, e.g. insurance company or president Smith in English
and prezident Smith in Czech
n:poss EN English possessive pronouns and nouns with the ?s suffix
adj:attr both Adjectival attributes (Czech inflection forms need not be stored thanks to
congruency with the parent noun)
adj:compl EN Direct adjectival complements to verbs
adj:[1..7] CS Direct adjectival complements to verbs (morphological case must be stored
in Czech, as it is determined by valency)
adj:poss CS Czech possesive adjectives and pronouns; a counterpart to English n:poss
adv both Adverbs (not inflected, can take no prepositions etc.)
x both Coordinating conjunctions, other uninflected words
drop both Deep tree nodes which do not appear on the surface (e.g. pro-drop pronouns)
?I.e. infinitives as head of clauses, not infinitives as parts of compound verb forms with finite auxiliary verbs.
?Numbers are traditionally used to mark morphological case in Czech; 1 stands for nominative, 2 for genitive etc.
?Since many prepositions may govern multiple cases in Czech, the case number is necessary.
Table 1: A listing of all possible formeme values, indicating their usage in Czech, English or both languages. ?P+?
denotes the (lowercased) surface form of a preposition or a subordinate conjunction. Round brackets denote optional
parts, square brackets denote a set of alternatives.
270
e.g. in case of. Our revision also allows combining
prepositions with all English gerunds and infinitives,
preventing a loss of important data.
We also use the lowercased surface form in the
middle formeme part instead of lemmas to allow for
a more straightforward surface form generation.
5.2 Introducing Syntactic Part-of-Speech
Formemes originally contained the semantic part-of-
speech (sempos) (Raz?mov? and ?abokrtsk?, 2006)
as their first part. We replaced it with a syntac-
tic part-of-speech (syntpos), since it proved compli-
cated to assign sempos reliably by a rule-based mod-
ule and morpho-syntactic behavior is more relevant
to formemes than semantics.
The syntpos is assigned in two steps:
1. A preliminary syntpos is selected, using our
categorization based on the part-of-speech tag
and lemma.
2. The final syntpos is selected according to the
syntactic position of the node, addressing nom-
inal usage of adjectives and cardinal numerals
(see Sections 5.4 and 5.5).
5.3 Capturing Czech Nominal Attributes
Detecting the attributive usage of nouns is straight-
forward for English, where any noun depending di-
rectly on another noun is considered an attribute.
In Czech, one needs to distinguish case-congruent
attributes from others that have a fixed case. We
aimed at assigning the n:attr formeme only in the
former case and thus replaced the original method
based on word order with a less error-prone one
based on congruency and named entity recognition.
5.4 Numerals: Distinguishing Usage and
Correcting Czech Case
The new formemes now distinguish adjectival and
nominal usage of cardinal numerals (cf. also Sec-
tion 5.2), e.g. the number in 5 potatoes is now as-
signed the adj:attr formeme, whereas Apollo 11
is given n:attr. The new situation is analogous
in Czech, with nominal usages of numerals having
their morphological case marked in formemes.
To reduce data sparsity in the new formemes ver-
sion, we counter the inconsistent syntactic behavior
of Czech cardinal numerals, where 1-4 behave like
The word ban?n is in genitive (n:2), but would have an ac-
cusative (n:4) form if the numeral behaved like an adjective.
Figure 2: Case correction with numerals in Czech.
adjectives but other numerals behave like nouns and
shift their semantically governing noun to the po-
sition of a genitive attribute. An example of this
change is given in Fig. 2.
5.5 Adjectives: Nominal Usage and Case
The new formemes address the usage of adjectives
in the syntactic position of nouns (cf. Section 5.2),
which occurs only rarely, thus preventing sparse val-
ues, namely in these syntactic positions:
? The subject. We replaced the originally as-
signed adj:compl value, which was impos-
sible to tell from adjectival objects, with the
formeme a noun would have in the same po-
sition, e.g. in the sentence Many of them were
late, the subject many is assigned n:subj.
? Prepositional phrases. Syntactic behavior of
adjectives is identical to nouns here; we thus
assign them the formeme values a noun would
receive in the same position, e.g. n:of+X in-
stead of adj:of+X in He is one of the best at
school.
In Czech, we detect nominal usage of adjectives
in verbal direct objects as well, employing large-
coverage valency lexicons (Lopatkov? et al, 2008;
Hajic? et al, 2003).
Instead of assigning the compl value in Czech,
our formemes revision includes the case of adjecti-
val complements, which depends on the valency of
the respective verb.
5.6 Mutual Information Across Languages
The changes described above have been motivated
not only by theoretical linguistic description of the
languages in question, but also by the intended us-
age within the TectoMT translation system. Instead
271
of retraining the translation model after each change,
we devised a simpler and faster estimate to measure
the asset of our innovations: using Mutual Informa-
tion (MI) (Manning and Sch?tze, 1999, p. 66) of
formemes in Czech and English trees.
We expect that an inter-language MI increase will
lead to lower noise in formeme-to-formeme transla-
tion dictionary (Bojar et al, 2009, cf. Section 3.2),
thus achieving higher MT output quality.
Using the analysis pipeline from CzEng1.0, we
measured the inter-language MI on sentences from
the Prague Czech-English Dependency Treebank
(PCEDT) 2.0 (Bojar et al, 2012a). The overall re-
sults show an MI increase from 1.598 to 1.687 (Bo-
jar et al, 2012b). Several proposed markup changes
have been discarded as they led to an inter-language
MI drop; e.g. removing the v:rc relative clause
formeme or merging the v:attr and adj:attr
values in English.
6 Experimental Usage
We list here our experiments with the newly de-
veloped annotation: an NLG experiment aimed at
assessing the impact of formemes on the synthesis
phase of the TectoMT system, and the usage in the
English-Czech MT as a whole.
6.1 Czech Synthesis
The synthesis phase of the TectoMT system relies
heavily on the information included in formemes, as
its rule-based blocks use solely formemes and gram-
mar rules to gradually change a deep tree node into
a surface subtree.
To directly measure the suitability of our changes
for the synthesis stage of the TectoMT system, we
used a Czech-to-Czech round trip?deep analysis of
Czech PDT 2.0 development set sentences using the
CzEng 1.0 pipeline (Bojar et al, 2012b), followed
directly by the synthesis part of the TectoMT sys-
tem. The results were evaluated using the BLEU
metric (Papineni et al, 2002) with the original sen-
tences as reference; they indicate a higher suitability
of the new formemes for deep Czech synthesis (see
Table 2).
6.2 English-Czech Machine Translation
To measure the influence of the presented formeme
revision on the translation quality, we compared
Version BLEU
Original formemes 0.6818
Revised formemes 0.7092
Table 2: A comparison of formeme versions in Czech-to-
Czech round trip.
Version BLEU
Original formemes 0.1190
Revised formemes 0.1199
Table 3: A comparison of formeme versions in English-
to-Czech TectoMT translation on the WMT12 test set.
two translation scenarios?one using the origi-
nal formemes and the second using the revised
formemes in the formeme-to-formeme translation
model. Due to time reasons, we were able to
train both translation models only on 1/2 of the
CzEng 1.0 training data.
The results in Table 3 demonstrate a slight6 BLEU
gain when using the revised formemes version. The
gain is expected to be greater if several rule-based
modules of the transfer phase are adapted to the re-
visions.
7 Conclusion and Further Work
We have presented a systematic and theoretically
supported revision of a surface morpho-syntactic
markup within a deep dependency annotation sce-
nario, designed to facilitate the TectoMT transfer
phase. Our first practical experiments proved the
merits of our innovations in the tasks of Czech syn-
thesis and deep structural MT as a whole. We have
also experimented with formemes in the functor as-
signment (semantic role labelling) task and gained
moderate improvements (ca. 1-1.5% accuracy).
In future, we intend to tune the rule-based parts
of our MT transfer for the new version of formemes
and examine further possibilities of data sparsity re-
duction (e.g. by merging synonymous formemes).
We are also planning to create formeme annotation
modules for further languages to widen the range of
language pairs used in the TectoMT system.
6Significant at 90% level using pairwise bootstrap resam-
pling test (Koehn, 2004).
272
References
O. Bojar and Z. ?abokrtsk?. 2009. CzEng 0.9: Large
Parallel Treebank with Rich Annotation. Prague Bul-
letin of Mathematical Linguistics, 92.
O. Bojar, D. Marec?ek, V. Nov?k, M. Popel, J. Pt?c?ek,
J. Rou?, and Z. ?abokrtsk?. 2009. English-Czech MT
in 2008. In Proceedings of the Fourth Workshop on
Statistical Machine Translation, pages 125?129. As-
sociation for Computational Linguistics.
O. Bojar, J. Hajic?, E. Hajic?ov?, J. Panevov?, P. Sgall,
S. Cinkov?, E. Fuc??kov?, M. Mikulov?, P. Pajas,
J. Popelka, J. Semeck?, J. ?indlerov?, J. ?te?p?nek,
J. Toman, Z. Ure?ov?, and Z. ?abokrtsk?. 2012a.
Announcing Prague Czech-English Dependency Tree-
bank 2.0. In Proceedings of LREC 2012, Istanbul,
Turkey, May. ELRA, European Language Resources
Association. In print.
O. Bojar, Z. ?abokrtsk?, O. Du?ek, P. Galu?c??kov?,
M. Majli?, D. Marec?ek, J. Mar??k, M. Nov?k,
M. Popel, and A. Tamchyna. 2012b. The Joy of Par-
allelism with CzEng 1.0. In Proceedings of LREC
2012, Istanbul, Turkey, May. ELRA, European Lan-
guage Resources Association. In print.
J. Hajic?, J. Panevov?, Z. Ure?ov?, A. B?mov?,
V. Kol?rov?, and P. Pajas. 2003. PDT-VALLEX: Cre-
ating a large-coverage valency lexicon for treebank an-
notation. In Proceedings of The Second Workshop on
Treebanks and Linguistic Theories, volume 9, pages
57?68.
J. Hajic?, J. Panevov?, E. Hajic?ov?, P. Sgall, P. Pajas,
J. ?te?p?nek, J. Havelka, M. Mikulov?, Z. ?abokrtsk?,
and M. ?evc??kov?-Raz?mov?. 2006. Prague Depen-
dency Treebank 2.0. CD-ROM LDC2006T01, LDC,
Philadelphia.
G. Helbig and W. Schenkel. 1969. W?rterbuch zur
Valenz und Distribution deutscher Verben. VEB Bib-
liographisches Institut, Leipzig.
P. Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proceedings of
EMNLP 2004, Barcelona, Spain.
M. Lopatkov?, Z. ?abokrtsk?, V. Kettnerov?, and
K. Skwarska. 2008. Valenc?n? slovn?k c?esk?ch sloves.
Karolinum, Prague.
C.D. Manning and H. Sch?tze. 1999. Foundations of
statistical natural language processing. MIT Press.
D. Marcu, W. Wang, A. Echihabi, and K. Knight. 2006.
SPMT: Statistical machine translation with syntacti-
fied target language phrases. In Proceedings of the
2006 Conference on Empirical Methods in Natural
Language Processing, pages 44?52. Association for
Computational Linguistics.
D. Marec?ek, M. Popel, and Z. ?abokrtsk?. 2010. Maxi-
mum entropy translation model in dependency-based
MT framework. In Proceedings of the Joint Fifth
Workshop on Statistical Machine Translation and Met-
rics (MATR), pages 201?206. Association for Compu-
tational Linguistics.
A. Menezes and S. D. Richardson. 2001. A best-first
alignment algorithm for automatic extraction of trans-
fer mappings from bilingual corpora. In Proceed-
ings of the workshop on Data-driven methods in ma-
chine translation - Volume 14, DMMT ?01, pages 1?8,
Stroudsburg, PA. Association for Computational Lin-
guistics.
K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2002.
BLEU: a method for automatic evaluation of machine
translation. In Proceedings of the 40th annual meet-
ing on association for computational linguistics, pages
311?318. Association for Computational Linguistics.
M. Popel and Z. ?abokrtsk?. 2010. TectoMT: modular
NLP framework. Advances in Natural Language Pro-
cessing, pages 293?304.
M. Popel, D. Marec?ek, N. Green, and Z. ?abokrtsk?.
2011. Influence of parser choice on dependency-based
MT. In Chris Callison-Burch, Philipp Koehn, Christof
Monz, and Omar Zaidan, editors, Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 433?439, Edinburgh, UK. Association for Com-
putational Linguistics.
J. Pt?c?ek and Z. ?abokrtsk?. 2006. Synthesis of
Czech sentences from tectogrammatical trees. In Text,
Speech and Dialogue, pages 221?228. Springer.
C. Quirk, A. Menezes, and C. Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal SMT. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguis-
tics, pages 271?279. Association for Computational
Linguistics.
M. Raz?mov? and Z. ?abokrtsk?. 2006. Annotation
of grammatemes in the Prague Dependency Treebank
2.0. In Proceedings of the LREC 2006 Workshop on
Annotation Science, pages 12?19.
M. ?evc??kov?-Raz?mov? and Z. ?abokrtsk?. 2006. Sys-
tematic parameterized description of pro-forms in the
Prague Dependency Treebank 2.0. In J. Hajic? and
J. Nivre, editors, Proceedings of the Fifth Workshop on
Treebanks and Linguistic Theories (TLT), pages 175?
186, Prague.
P. Sgall, E. Hajic?ov?, J. Panevov?, and J. Mey. 1986. The
meaning of the sentence in its semantic and pragmatic
aspects. Springer.
P. Sgall. 1967. Generativn? popis jazyka a c?esk? dekli-
nace. Academia, Prague.
Z. Ure?ov?. 2009. Building the PDT-VALLEX valency
lexicon. In On-line proceedings of the fifth Corpus
Linguistics Conference. University of Liverpool.
273
Z. ?abokrtsk?, J. Pt?c?ek, and P. Pajas. 2008. Tec-
toMT: highly modular MT system with tectogrammat-
ics used as transfer layer. In Proceedings of the Third
Workshop on Statistical Machine Translation, StatMT
?08, pages 167?170, Stroudsburg, PA. Association for
Computational Linguistics.
Z. ?abokrtsk?. 2005. Valency Lexicon of Czech Verbs.
Ph.D. thesis, Charles University in Prague.
Z. ?abokrtsk?. 2010. From Treebanking to Machine
Translation. Habilitation thesis, Charles University in
Prague.
Z. ?abokrtsk? and M. Popel. 2009. Hidden Markov
Tree Model in Dependency-based Machine Transla-
tion. In Proceedings of the ACL-IJCNLP 2009 Con-
ference Short Papers, pages 145?148, Suntec, Singa-
pore.
274
Proceedings of the 7th Workshop on Statistical Machine Translation, pages 362?368,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
DEPFIX: A System for Automatic Correction of Czech MT Outputs?
Rudolf Rosa, David Marec?ek and Ondr?ej Dus?ek
Charles University in Prague, Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
Malostranske? na?me?st?? 25, Prague
{rosa,marecek,odusek}@ufal.mff.cuni.cz
Abstract
We present an improved version of DEPFIX
(Marec?ek et al, 2011), a system for auto-
matic rule-based post-processing of English-
to-Czech MT outputs designed to increase
their fluency. We enhanced the rule set used
by the original DEPFIX system and measured
the performance of the individual rules.
We also modified the dependency parser of
McDonald et al (2005) in two ways to adjust
it for the parsing of MT outputs. We show that
our system is able to improve the quality of the
state-of-the-art MT systems.
1 Introduction
The today?s outputs of Machine Translation (MT)
often contain serious grammatical errors. This
is particularly apparent in statistical MT systems
(SMT), which do not employ structural linguistic
rules. These systems have been dominating the area
in the recent years (Callison-Burch et al, 2011).
Such errors make the translated text less fluent and
may even lead to unintelligibility or misleading
statements. The problem is more evident in lan-
guages with rich morphology, such as Czech, where
morphological agreement is of a relatively high im-
portance for the interpretation of syntactic relations.
The DEPFIX system (Marec?ek et al, 2011) at-
tempts to correct some of the frequent SMT sys-
?This research has been supported by the European Union
Seventh Framework Programme (FP7) under grant agree-
ment n? 247762 (Faust), and by the grants GAUK116310,
GA201/09/H057 (Res-Informatica), and LH12093.
tems? errors in English-to-Czech translations.1 It an-
alyzes the target sentence (the SMT output in Czech
language) using a morphological tagger and a de-
pendency parser and attempts to correct it by apply-
ing several rules which enforce consistency with the
Czech grammar. Most of the rules use the source
sentence (the SMT input in English language) as a
source of information about the sentence structure.
The source sentence is also tagged and parsed, and
word-to-word alignment with the target sentence is
determined.
In this paper, we present DEPFIX 2012, an im-
proved version of the original DEPFIX 2011 system.
It makes use of a new parser, described briefly in
Section 3, which is adapted to handle the generally
ungrammatical target sentences better. We have also
enhanced the set of grammar correction rules, for
which we give a detailed description in Section 4.
Section 5 gives an account of the experiments per-
formed to evaluate the DEPFIX 2012 system and
compare it to DEPFIX 2011. Section 6 then con-
cludes the paper.
2 Related Work
Our approach can be regarded as converse to the
more common way of using an SMT system to auto-
matically post-edit the output of a rule-based transla-
tion system, as described e.g. in (Simard et al, 2007)
or (Lagarda et al, 2009).
The DEPFIX system is implemented in the
1Although we apply the DEPFIX system just to SMT systems
in this paper as it mainly targets the errors induced by this type
of MT systems, it can be applied to virtually any MT system
(Marec?ek et al, 2011).
362
TectoMT/Treex NLP framework (Popel and
Z?abokrtsky?, 2010),2 using the Morc?e tagger (Spous-
tova? et al, 2007) and the MST parser (McDonald
et al, 2005) trained on the CoNLL 2007 Shared
Task English data (Nivre et al, 2007) to analyze the
source sentences. The source and target sentences
are aligned using GIZA++ (Och and Ney, 2003).
3 Parsing
The DEPFIX 2011 system used the MST parser (Mc-
Donald et al, 2005) with an improved feature set
for Czech (Nova?k and Z?abokrtsky?, 2007) trained on
the Prague Dependency Treebank (PDT) 2.0 (Hajic?
and others, 2006) to analyze the target sentences.
DEPFIX 2012 uses a reimplementation of the MST
parser capable of utilizing parallel features from the
source side in the parsing of the target sentence.
The source text is usually grammatical and there-
fore is likely to be analyzed more reliably. The
source structure obtained in this way can then pro-
vide hints for the target parser. We use local features
projected through the GIZA++ word alignment ? i.e.
for each target word, we add features computed over
its aligned source word, if there is one.
To address the differences between the gold stan-
dard training data and SMT outputs, we ?worsen?
the treebank used to train the parser, i.e. introduce
errors similar to those found in target sentences:
The trees retain their correct structure, only the word
forms are modified to resemble SMT output.
We have computed a ?part-of-speech tag er-
ror model? on parallel sentences from the Prague
Czech-English Dependency Treebank (PCEDT) 2.0
(Bojar et al, 2012), comparing the gold standard
Czech translations to the output of an SMT system
(Koehn et al, 2007) and estimating the Maximum
Likelihood probabilities of errors for each part-of-
speech tag. We then applied this error model to the
Czech PCEDT 2.0 sentences and used the resulting
?worsened? treebank to train the parser.
4 Rules
DEPFIX 2012 uses 20 hand-written rules, address-
ing various frequent errors in MT output. Each
rule takes an analyzed target sentence as its in-
put, often together with its analyzed source sen-
2http://ufal.mff.cuni.cz/treex
tence, and attempts to correct any errors found ?
usually by changing morphosyntactic categories of
a word (such as number, gender, case, person and
dependency label) and regenerating the correspond-
ing word form if necessary, more rarely by deleting
superfluous particles or auxiliary words or changing
the target dependency tree structure. However, nei-
ther word order problems nor bad lexical choices are
corrected.
Many rules were already present in DEPFIX 2011.
However, most were modified in DEPFIX 2012 to
achieve better performance (denoted as modified),
and new rules were added (new). Rules not modified
since DEPFIX 2011 are denoted as reused.
The order of rule application is important as there
are dependencies among the rules, e.g. FixPrepo-
sitionNounAgreement (enforcing noun-preposition
congruency) depends on FixPrepositionalCase (fix-
ing incorrectly tagged prepositional case). The rules
are applied in the order listed in Table 2.
4.1 Analysis Fixing Rules
Analysis fixing rules try to detect and rectify tagger
and parser errors. They do not change word forms
and are therefore invisible on the output as such;
however, rules of other types benefit from their cor-
rections.
FixPrepositionalCase (new)
This rule corrects part-of-speech-tag errors in
prepositional phrases. It looks for all words that de-
pend on a preposition and do not match its part-of-
speech tag case. It tries to find and assign a com-
mon morphological case fitting for both the word
form and the preposition. Infrequent preposition-
case combinations are not considered.
FixReflexiveTantum (new)
If the word form ?se? or ?si? is classified as reflex-
ive tantum particle by the parser, but does not be-
long to an actual reflexive tantum verb (or a dever-
bative noun or an adjective), its dependency label is
changed to a different value, based on the context.
FixNounNumber (reused)
If a noun is tagged as singular in target but as plu-
ral in source, the tag is likely to be incorrect. This
rule tries to find a tag that would match both the
363
source number and the target word form, changing
the target case if necessary.
FixPrepositionWithoutChildren (reused)
A target preposition with no child nodes is clearly
an analysis error. This rule tries to find children for
childless prepositions by projecting the children of
the aligned source preposition to the target side.
FixAuxVChildren (new)
Since auxiliary verbs must not have child nodes,
we rehang all their children to the governing full
verb.
4.2 Agreement Fixing Rules
These rules relate to morphological agreement re-
quired by Czech grammar, which they try to enforce
in case it is violated. Czech grammar requires agree-
ment in morphological gender, number, case and
person where applicable.
These rules typically use the source sentence only
for confirmation.
FixRelativePronoun (new)
The Czech word relative pronoun ?ktery?? is as-
signed gender and number identical to the closest
preceding noun or pronoun, if the source analysis
confirms that it depends on this noun/pronoun.
FixSubject (modified)
The subject (if the subject dependency label is
confirmed by the source analysis) will have its case
set to nominative; the number is changed if this leads
to the word form staying unchanged.
FixVerbAuxBeAgreement (modified)
If an auxiliary verb is a child of an infinitive, the
auxiliary verb receives the gender and number of the
subject, which is a child of the infinitive (see also
FixAuxVChildren).
FixSubjectPredicateAgreement (modified)
An active verb form receives the number and per-
son from its subject (whose relation to the verb must
be confirmed by the source).
FixSubjectPastParticipleAgreement (modified)
A past participle verb form receives the number
and gender from its subject (confirmed by the source
analysis).
FixPassiveAuxBeAgreement (modified)
An auxiliary verb ?by?t? (?to be?) depending on a
passive verb form receives its gender and number.
FixPrepositionNounAgreement (modified)
A noun or adjective depending on a preposition
receives its case. The dependency must be con-
firmed in the source.
FixNounAdjectiveAgreement (modified)
An adjective (or an adjective-like pronoun or nu-
meral) preceding its governing noun receives its
gender, number and case.
4.3 Translation Fixing Rules
The following rules detect and correct structures of-
ten mistranslated by SMT systems. They usually de-
pend heavily on the source sentence.
FixBy (new)
English preposition ?by? is translated to Czech us-
ing the instrumental case (if modifying a verb, e.g.
?built by David?: ?postaveno Davidem?) or using the
genitive case (if modifying a noun, e.g. ?songs by
David?: ?p??sne? Davida?).
FixPresentContinuous (modified)
If the source sentence is in a continuous tense (e.g.
?Ondr?ej isn?t experimenting.?), the auxiliary verb ?to
be? must not appear on the output, which is often
the case (e.g. *?Ondr?ej nen?? experimentovat.?). This
rule deletes the auxiliary verb in target and transfers
its morphological categories to the main verb (e.g.
?Ondr?ej neexperimentuje.?).
FixVerbByEnSubject (new)
If the subject of the source sentence is a personal
pronoun, its following morphological categeries are
propagated to the target predicate:
? person
? number (except for ?you?, which does not ex-
hibit number)
? gender (only in case of ?he? or ?she?, which ex-
hibit the natural gender)
FixOf (new)
English preposition ?of? modifying a noun is
translated to Czech using the genitive case (e.g. ?pic-
tures of Rudolf?: ?obra?zky Rudolfa?).
364
FixAuxT (reused)
Reflexive tantum particles ?se? or ?si? not belong-
ing to any verb or adjective are deleted. This situa-
tion usually occurs when the meaning of the source
verb/adjective is lost in translation and only the par-
ticle is produced.
4.4 Other Rules
VocalizePrepos (reused)
Prepositions ?k?, ?s?, ?v?, ?z? are vocalized (i.e.
changed to ?ke?, ?se?, ?ve?, ?ze?) where neces-
sary. The vocalization rules in Czech are similar to
?a?/?an? distinction in English.
FixFirstWordCapitalization (new)
If the first word of source is capitalized and the
first word of target is not, this rule capitalizes it.
5 Experiments and Results
For parameter tuning, we used datasets from the
WMT10 translation task and translations by ON-
LINEB and CU-BOJAR systems.
5.1 Manual Evaluation
Manual evaluation of both DEPFIX 2011 and DEP-
FIX 2012 was performed on the WMT113 test set
translated by ONLINEB. 500 sentences were ran-
domly selected and blind-evaluated by two indepen-
dent annotators, who were presented with outputs of
ONLINEB, DEPFIX 2011 and DEPFIX 2012. (For
246 sentences, at least one of the DEPFIX setups
modified the ONLINEB translation.) They provided
us with a pairwise comparison of the three setups,
with the possibility to mark the sentence as ?indef-
inite? if translations were of equal quality. The re-
sults are given in Table 1.
In Table 2, we use the manual evaluation to mea-
sure the performance of the individual rules in DEP-
FIX 2012. For each rule, we ran DEPFIX 2012 with
this rule disabled and compared the output to the
output of the full DEPFIX 2012. The number of
affected sentences on the whole WMT11 test set,
given as ?changed?, represents the impact of the
rule. The number of affected sentences selected for
manual evaluation is listed as ?evaluated?. Finally,
the annotators? ratings of the ?evaluated? sentences
3http://www.statmt.org/wmt11
A / B
Setup 1 Setup 2
Indefinite
better better
Setup 1 better 55% 1% 11%
Setup 2 better 1% 8% 4%
Indefinite 3% 2% 15%
Table 3: Inter-annotator agreement matrix for ONLINEB
+ DEPFIX 2012 as Setup 1 and ONLINEB as Setup 2.
(suggesting whether the rule improved or worsened
the translation, or whether the result was indefinite)
were counted and divided by the number of anno-
tators to get the average performance of each rule.
Please note that the lower the ?evaluated? number,
the lower the confidence of the results.
The inter-annotator agreement matrix for com-
parison of ONLINEB + DEPFIX 2012 (denoted as
Setup 1) with ONLINEB (Setup 2) is given in Ta-
ble 3. The results for the other two setup pairs were
similar, with the average inter-annotator agreement
being 77%.
5.2 Automatic Evaluation
We also performed several experiments with auto-
matic evaluation using the standard BLEU metric
(Papineni et al, 2002). As the effect of DEPFIX in
terms of BLEU is rather small, the results are not as
confident as the results of manual evaluation.4
In Table 4, we compare the DEPFIX 2011 and
DEPFIX 2012 systems and measure the contribution
of parser adaptation (Section 3) and rule improve-
ments (Section 4). It can be seen that the com-
bined effect of applying both system modifications
is greater than when they are applied alone. The im-
provement of DEPFIX 2012 over ONLINEB without
DEPFIX is statistically significant at 95% confidence
level.
The effect of DEPFIX 2012 on the outputs of some
of the best-scoring SMT systems in the WMT12
Translation Task5 is shown in Table 5. Although
DEPFIX 2012 was tuned only on ONLINEB and CU-
BOJAR system outputs, it improves the BLEU score
of all the best-scoring systems, which suggests that
4As already noted by Marec?ek et al (2011), BLEU seems
not to be very suitable for evaluation of DEPFIX. See (Kos and
Bojar, 2009) for a detailed study of BLEU performance when
applied to evaluation of MT systems with Czech as the target
language.
5http://www.statmt.org/wmt12
365
Setup 1 Setup 2
Differing
Annotator
Setup 1 Setup 2
Indefinite
sentences better better
ONLINEB
ONLINEB 169
A 58% 13% 29%
+ DEPFIX 2011 B 47% 11% 42%
ONLINEB
ONLINEB 234
A 65% 14% 21%
+ DEPFIX 2012 B 59% 11% 30%
ONLINEB ONLINEB
148
A 54% 24% 22%
+ DEPFIX 2012 + DEPFIX 2011 B 56% 22% 22%
Table 1: Manual pairwise comparison on 500 sentences from WMT11 test set processed by ONLINEB, ONLINEB +
DEPFIX 2011 and ONLINEB + DEPFIX 2012. Evaluated by two independent annotators.
Sentences
Rule changed evaluated impr. % wors. % indef. %
FixPrepositionalCase 34 5 3 60 2 40 0 0
FixReflexiveTantum 1 0 ? ? ? ? ? ?
FixNounNumber 80 11 5 45 5 45 1 9
FixPrepositionWithoutChildren 16 6 3 50 3 50 0 0
FixBy 75 13 10.5 81 1 8 1.5 12
FixAuxVChildren 26 6 4.5 75 0 0 1.5 25
FixRelativePronoun 56 8 6 75 2 25 0 0
FixSubject 142 18 13.5 75 3 17 1.5 8
FixVerbAuxBeAgreement 8 2 1 50 1 50 0 0
FixPresentContinuous 30 7 5.5 79 1 14 0.5 7
FixSubjectPredicateAgreement 87 10 5.5 55 1 10 3.5 35
FixSubjectPastParticipleAgreement 396 63 46.5 74 9.5 15 7 11
FixVerbByEnSubject 25 6 5 83 0 0 1 17
FixPassiveAuxBeAgreement 43 8 6 75 0.5 6 1.5 19
FixPrepositionNounAgreement 388 62 40 65 13 21 9 15
FixOf 84 13 11.5 88 0 0 1.5 12
FixNounAdjectiveAgreement 575 108 69.5 64 20 19 18.5 17
FixAuxT 38 7 4 57 1 14 2 29
VocalizePrepos 53 12 6 50 2.5 21 3.5 29
FixFirstWordCapitalization 0 0 ? ? ? ? ? ?
Table 2: Impact and accuracy of individual DEPFIX 2012 rules using manual evaluation on 500 sentences from
WMT11 test set translated by ONLINEB. The number of changed sentences is counted on the whole WMT11 test
set, i.e. 3003 sentences. The numbers of improved, worsened and indefinite translations are averaged over the annota-
tors.
366
DEPFIX setup BLEU
without DEPFIX 19.37
DEPFIX 2011 19.41
DEPFIX 2011 + new parser 19.42
DEPFIX 2011 + new rules 19.48
DEPFIX 2012 19.56
Table 4: Performance of ONLINEB and various DEPFIX
setups on the WMT11 test set.
System BLEU
ONLINEB 16.25
ONLINEB + DEPFIX 2012 16.31
UEDIN 15.54
UEDIN + DEPFIX 2012 15.75
CU-BOJAR 15.41
CU-BOJAR + DEPFIX 2012 15.45
CU-TAMCH-BOJ 15.35
CU-TAMCH-BOJ + DEPFIX 2012 15.39
Table 5: Comparison of BLEU of baseline system output
and corrected system output on WMT12 test set.
it is able to improve the quality of various SMT
systems when applied to their outputs. (The im-
provement on UEDIN is statistically significant at
95% confidence level.) We submitted the ONLINEB
+ DEPFIX 2012 system to the WMT12 Translation
Task as CU-DEPFIX.
6 Conclusion
We have presented two improvements to DEPFIX,
a system of rule-based post-editing of English-to-
Czech Machine Translation outputs proven by man-
ual and automatic evaluation to improve the qual-
ity of the translations produced by state-of-the-art
SMT systems. First, improvements in the existing
rules and implementation of new ones, which can be
regarded as an additive, evolutionary change. Sec-
ond, a modified dependency parser, adjusted to pars-
ing of SMT outputs by training it on a parallel tree-
bank with worsened word forms on the Czech side.
We showed that both changes led to a better perfor-
mance of the new DEPFIX 2012, both individually
and combined.
In future, we are planning to incorporate deeper
analysis, devising rules that would operate on the
deep-syntactic, or tectogrammatical, layer. The
Czech and English tectogrammatical trees are more
similar to each other, which should enable us to ex-
ploit more information from the source sentences.
We also hope to be able to perform more complex
corrections, such as changing the part of speech of a
word when necessary.
Following the success of our modified parser, we
would also like to modify the tagger in a similar way,
since incorrect analyses produced by the tagger of-
ten hinder the correct function of our rules, some-
times leading to a rule worsening the translation in-
stead of improving it.
As observed e.g. by Groves and Schmidtke (2009)
for English-to-German and English-to-French trans-
lations, SMT systems for other language pairs also
tend to produce reoccurring grammatical errors. We
believe that these could be easily detected and cor-
rected in a rule-based way, using an approach similar
to ours.
References
Ondr?ej Bojar, Jan Hajic?, Eva Hajic?ova?, Jarmila Panevova?,
Petr Sgall, Silvie Cinkova?, Eva Fuc???kova?, Marie
Mikulova?, Petr Pajas, Jan Popelka, Jir??? Semecky?,
Jana S?indlerova?, Jan S?te?pa?nek, Josef Toman, Zden?ka
Ures?ova?, and Zdene?k Z?abokrtsky?. 2012. Announc-
ing Prague Czech-English Dependency Treebank 2.0.
In Proceedings of LREC 2012, Istanbul, Turkey, May.
ELRA, European Language Resources Association.
In print.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Omar Zaidan. 2011. Findings of the 2011 work-
shop on statistical machine translation. In Proceedings
of the Sixth Workshop on Statistical Machine Transla-
tion, pages 22?64, Edinburgh, Scotland, July. Associ-
ation for Computational Linguistics.
Declan Groves and Dag Schmidtke. 2009. Identification
and analysis of post-editing patterns for MT. Proceed-
ings of MT Summit XII, pages 429?436.
Jan Hajic? et al 2006. Prague Dependency Treebank 2.0.
CD-ROM, Linguistic Data Consortium, LDC Catalog
No.: LDC2006T0 1, Philadelphia.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In ACL
2007, Proceedings of the 45th Annual Meeting of the
367
Association for Computational Linguistics Companion
Volume Proceedings of the Demo and Poster Sessions,
pages 177?180, Prague, Czech Republic, June. Asso-
ciation for Computational Linguistics.
Kamil Kos and Ondr?ej Bojar. 2009. Evaluation of ma-
chine translation metrics for czech as the target lan-
guage. The Prague Bulletin of Mathematical Linguis-
tics, 92(-1):135?148.
Antonio L. Lagarda, Vicent Alabau, Francisco Casacu-
berta, Roberto Silva, and Enrique Diaz-de Liano.
2009. Statistical post-editing of a rule-based ma-
chine translation system. In Proceedings of Human
Language Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, Companion Vol-
ume: Short Papers, pages 217?220. Association for
Computational Linguistics.
David Marec?ek, Rudolf Rosa, Petra Galus?c?a?kova?, and
Ondr?ej Bojar. 2011. Two-step translation with gram-
matical post-processing. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
426?432. Association for Computational Linguistics.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic?. 2005. Non-projective dependency parsing
using spanning tree algorithms. In HLT ?05: Proceed-
ings of the conference on Human Language Technol-
ogy and Empirical Methods in Natural Language Pro-
cessing, pages 523?530, Vancouver, British Columbia,
Canada.
Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In Proceedings of the CoNLL 2007
Shared Task. Joint Conf. on Empirical Methods in Nat-
ural Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), June.
Va?clav Nova?k and Zdene?k Z?abokrtsky?. 2007. Feature
engineering in maximum spanning tree dependency
parser. In Va?clav Matous?ek and Pavel Mautner, edi-
tors, Lecture Notes in Artificial Intelligence, Proceed-
ings of the 10th I nternational Conference on Text,
Speech and Dialogue, Lecture Notes in Computer Sci-
ence, pages 92?98, Pilsen, Czech Republic. Springer
Science+Business Media Deutschland GmbH.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic Eval-
uation of Machine Translation. In ACL 2002, Proceed-
ings of the 40th Annual Meeting of the Association for
Computational Linguistics, pages 311?318, Philadel-
phia, Pennsylvania.
Martin Popel and Zdene?k Z?abokrtsky?. 2010. TectoMT:
modular NLP framework. In Proceedings of the 7th
international conference on Advances in natural lan-
guage processing, IceTAL?10, pages 293?304, Berlin,
Heidelberg. Springer-Verlag.
Michel Simard, Cyril Goutte, and Pierre Isabelle. 2007.
Statistical phrase-based post-editing. In Human Lan-
guage Technologies 2007: The Conference of the
North American Chapter of the Association for Com-
putational Linguistics; Proceedings of the Main Con-
ference, pages 508?515, Rochester, New York, April.
Association for Computational Linguistics.
Drahom??ra Spoustova?, Jan Hajic?, Jan Votrubec, Pavel Kr-
bec, and Pavel Kve?ton?. 2007. The best of two worlds:
Cooperation of statistical and rule-based taggers for
czech. In Proceedings of the Workshop on Balto-
Slavonic Natural Language Processing, ACL 2007,
pages 67?74, Praha.
368
Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 39?48,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
Using Parallel Features in Parsing of Machine-Translated Sentences for
Correction of Grammatical Errors ?
Rudolf Rosa, Ondr?ej Dus?ek, David Marec?ek, and Martin Popel
Charles University in Prague, Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
{rosa,odusek,marecek,popel}@ufal.mff.cuni.cz
Abstract
In this paper, we present two dependency
parser training methods appropriate for pars-
ing outputs of statistical machine transla-
tion (SMT), which pose problems to standard
parsers due to their frequent ungrammatical-
ity. We adapt the MST parser by exploiting
additional features from the source language,
and by introducing artificial grammatical er-
rors in the parser training data, so that the
training sentences resemble SMT output.
We evaluate the modified parser on DEP-
FIX, a system that improves English-Czech
SMT outputs using automatic rule-based cor-
rections of grammatical mistakes which re-
quires parsed SMT output sentences as its in-
put. Both parser modifications led to im-
provements in BLEU score; their combina-
tion was evaluated manually, showing a sta-
tistically significant improvement of the trans-
lation quality.
1 Introduction
The machine translation (MT) quality is on a steady
rise, with mostly statistical systems (SMT) dominat-
ing the area (Callison-Burch et al, 2010; Callison-
Burch et al, 2011). Most MT systems do not employ
structural linguistic knowledge and even the state-
of-the-art MT solutions are unable to avoid making
serious grammatical errors in the output, which of-
ten leads to unintelligibility or to a risk of misinter-
pretations of the text by a reader.
?This research has been supported by the EU Seventh
Framework Programme under grant agreement n? 247762
(Faust), and by the grants GAUK116310 and GA201/09/H057.
This problem is particularly apparent in target lan-
guages with rich morphological inflection, such as
Czech. As Czech often conveys the relations be-
tween individual words using morphological agree-
ment instead of word order, together with the word
order itself being relatively free, choosing the cor-
rect inflection becomes crucial.
Since the output of phrase-based SMT shows fre-
quent inflection errors (even in adjacent words) due
to each word belonging to a different phrase, a
possible way to address the grammaticality prob-
lem is a combination of statistical and structural ap-
proach, such as SMT output post-editing (Stymne
and Ahrenberg, 2010; Marec?ek et al, 2011).
In this paper, we focus on improving SMT output
parsing quality, as rule-based post-editing systems
rely heavily on the quality of SMT output analy-
sis. Parsers trained on gold standard parse trees of-
ten fail to produce the expected result when applied
to SMT output with grammatical errors. This is
partly caused by the fact that when parsing highly in-
flected free word-order languages the parsers have to
rely on morphological agreement, which, as stated
above, is often erroneous in SMT output.
Training a parser specifically by creating a man-
ually annotated treebank of MT systems? outputs
would be very expensive, and the application of such
treebank to other MT systems than the ones used
for its generation would be problematic. We address
this issue by two methods of increasing the quality
of SMT output parsing:
? a different application of previous works on
bitext parsing ? exploiting additional features
from the source language (Section 3), and
39
? introducing artificial grammatical errors in the
target language parser training data, so that the
sentences resemble the SMT output in some
ways (Section 4). This technique is, to our
knowledge, novel with regards to its applica-
tion to SMT and the statistical error model.
We test these two techniques on English-Czech
MT outputs using our own reimplementation of the
MST parser (McDonald et al, 2005) named RUR1
parser. and evaluate their contribution to the SMT
post-editing quality of the DEPFIX system (Marec?ek
et al, 2011), which we outline in Section 5. We
describe the experiments carried out and present the
most important results in Section 6. Section 7 then
concludes the paper and indicates more possibilities
of further improvements.
2 Related Work
Our approach to parsing with parallel features is
similar to various works which seek to improve the
parsing accuracy on parallel texts (?bitexts?) by us-
ing information from both languages. Huang et
al. (2009) employ ?bilingual constraints? in shift-
reduce parsing to disambiguate difficult syntac-
tic constructions and resolve shift-reduce conflicts.
Chen et al (2010) use similar subtree constraints to
improve parser accuracy in a dependency scenario.
Chen et al (2011) then improve the method by ob-
taining a training parallel treebank via SMT. In re-
cent work, Haulrich (2012) experiments with a setup
very similar to ours: adding alignment-projected
features to an originally monolingual parser.
However, the main aim of all these works is to im-
prove the parsing accuracy on correct parallel texts,
i.e. human-translated. This paper applies similar
methods, but with a different objective in mind ? in-
creasing the ability of the parser to process ungram-
matical SMT output sentences and, ultimately, im-
prove rule-based SMT post-editing.
Xiong et al (2010) use SMT parsing in translation
quality assessment, providing syntactic features to a
classifier detecting erroneous words in SMT output,
yet they do not concentrate on improving parsing ac-
curacy ? they employ a link grammar parser, which
1The abbreviation ?RUR? parser stands for ?Rudolph?s Uni-
versal Robust? parser.
is robust, but not tuned specifically to process un-
grammatical input.
There is also another related direction of research
in parsing of parallel texts, which is targeted on pars-
ing under-resourced languages, e.g. the works by
Hwa et al (2005), Zeman and Resnik (2008), and
McDonald et al (2011). They address the fact that
parsers for the language of interest are of low qual-
ity or even non-existent, whereas there are high-
quality parsers for the other language. They ex-
ploit common properties of both languages and de-
lexicalization. Zhao et al (2009) uses information
from word-by-word translated treebank to obtain ad-
ditional training data and boost parser accuracy.
This is different from our situation, as there ex-
ist high performance parsers for Czech (Buchholz
and Marsi, 2006; Nivre et al, 2007; Hajic? et al,
2009). Boosting accuracy on correct sentences is
not our primary goal and we do not intend to re-
place the Czech parser by an English parser; instead,
we aim to increase the robustness of an already ex-
isting Czech parser by adding knowledge from the
corresponding English source, parsed by an English
parser.
Other works in bilingual parsing aim to parse the
parallel sentences directly using a grammar formal-
ism fit for this purpose, such as Inversion Trans-
duction Grammars (ITG) (Wu, 1997). Burkett et
al. (2010) further include ITG parsing with word-
alignment in a joint scenario. We concentrate here
on using dependency parsers because of tools and
training data availability for the examined language
pair.
Regarding treebank adaptation for parser robust-
ness, Foster et al (2008) introduce various kinds of
artificial errors into the training data to make the fi-
nal parser less sensitive to grammar errors. How-
ever, their approach concentrates on mistakes made
by humans (such as misspellings, word repetition or
omission etc.) and the error models used are hand-
crafted. Our work focuses on morphology errors of-
ten encountered in SMT output and introduces sta-
tistical error modelling.
3 Parsing with Parallel Features
This section describes our SMT output parsing setup
with features from analyzed source sentences. We
40
explain our motivation for the inclusion of parallel
features in Section 3.1, then provide an account of
the parsers used (including our RUR parser) in Sec-
tion 3.2, and finally list all the monolingual and par-
allel features included in the parser training (in Sec-
tions 3.3 and 3.4, respectively).
3.1 Motivation
An advantage of SMT output parsing over general
dependency parsing is that one can also make use of
source ? English sentences in our case. Moreover,
although SMT output is often in many ways ungram-
matical, source is usually grammatical and therefore
easier to process (in our case especially to tag and
parse). This was already noticed in Marec?ek et al
(2011), who use the analysis of source sentence to
provide additional information for the DEPFIX rules,
claiming it to be more reliable than the analysis of
SMT output sentence.
We have carried this idea further by having de-
vised a simple way of making use of this information
in parsing of the SMT output sentences: We parse
the source sentence first and include features com-
puted over the parsed source sentence in the set of
features used for parsing SMT output. We first align
the source and SMT output sentences on the word
level and then use alignment-wise local features ?
i.e. for each SMT output word, we add features com-
puted over its aligned source word, if applicable (cf.
Section 3.4 for a listing).
3.2 Parsers Used
We have reimplemented the MST parser (McDonald
et al, 2005) in order to provide for a simple insertion
of the parallel features into the models.
We also used the original implementation of the
MST parser by McDonald et al (2006) for com-
parison in our experiments. To distinguish the two
variants used, we denote the original MST parser
as MCD parser,2 and the new reimplementation as
RUR parser.
We trained RUR parser in a first-order non-
projective setting with single-best MIRA. Depen-
dency labels are assigned in a second stage by a
2MCD uses k-best MIRA, does first- and second-order
parsing, both projectively and non-projectively, and can be
obtained from http://sourceforge.net/projects/
mstparser.
MIRA-based labeler, which has been implemented
according to McDonald (2006) and Gimpel and Co-
hen (2007).
We used the Prague Czech-English Dependency
Treebank3 (PCEDT) 2.0 (Bojar et al, 2012) as the
training data for RUR parser ? a parallel treebank
created from the Penn Treebank (Marcus et al,
1993) and its translation into Czech by human trans-
lators. The dependency trees on the English side
were converted from the manually annotated phrase-
structure trees in Penn Treebank, the Czech trees
were created automatically using MCD. Words of
the Czech and English sentences were aligned by
GIZA++ (Och and Ney, 2003).
We apply RUR parser only for SMT output pars-
ing; for source parsing, we use MCD parser trained
on the English CoNLL 2007 data (Nivre et al,
2007), as the performance of this parser is sufficient
for this task.
3.3 Monolingual Features
The set of monolingual features used in RUR parser
follows those described by McDonald et al (2005).
For parsing, we use the features described below.
The individual features are computed for both the
parent node and the child node of an edge and con-
joined in various ways. The coarse morphological
tag and lemma are provided by the Morc?e tagger
(Spoustova? et al, 2007).
? coarse morphological tag ? Czech two-letter
coarse morphological tag, as described in
(Collins et al, 1999),4
? lemma ? morphological lemma,
? context features: preceding coarse morpholog-
ical tag, following coarse morphological tag
? coarse morphological tag of a neighboring
node,
? coarse morphological tags in between ? bag of
coarse morphological tags of nodes positioned
between the parent node and the child node,
3http://ufal.mff.cuni.cz/pcedt
4The first letter is the main POS (12 possible values), the
second letter is either the morphological case field if the main
POS displays case (i.e. for nouns, adjectives, pronouns, numer-
als and prepositions; 7 possible values), or the detailed POS if
it does not (22 possible values).
41
? distance ? signed bucketed distance of the par-
ent and the child node in the sentence (in # of
words), using buckets 1, 2, 3, 4, 5 and 11.
To assign dependency labels, we use the same
set as described above, plus the following features
(called ?non-local? by McDonald (2006)), which
make use of the knowledge of the tree structure.
? is first child, is last child ? a boolean indicating
whether the node appears in the sentence as the
first/last one among all the child nodes of its
parent node,
? child number ? the number of syntactic chil-
dren of the current node.
3.4 Parallel Features
Figure 1: Example sentence for parallel features illustra-
tion (see Table 1).
In RUR parser we use three types of parallel fea-
tures, computed for the parent and child node of an
edge, which make use of the source English nodes
aligned to the parent and child node.
? aligned tag: morphological tag following the
Penn Treebank Tagset (Marcus et al, 1993) of
the English node aligned to the Czech node
Feature Feature value on
parent node child node
word form jel Martin
aligned tag VBD NNP
aligned dep. label Pred Sb
aligned edge existence true
word form jel autem
aligned tag VBD NN
aligned dep. label Pred Adv
aligned edge existence false
word form do zahranic???
aligned tag ? RB
aligned dep. label ? Adv
aligned edge existence ?
word form #root# .
aligned tag #root# .
aligned dep. label AuxS AuxK
aligned edge existence true
Table 1: Parallel features for several edges in Figure 1.
? aligned dependency label: dependency label of
the English node aligned to the Czech node in
question, according to the PCEDT 2.0 label set
(Bojar et al, 2012)
? aligned edge existence: a boolean indicating
whether the English node aligned to the Czech
parent node is also the parent of the English
node aligned to the Czech child node
The parallel features are conjoined with the
monolingual coarse morphological tag and lemma
features in various ways.
If there is no source node aligned to the parent
or child node, the respective feature cannot be com-
puted and is skipped.
An example of a pair of parallel sentences is given
in Figure 1 with the corresponding values of parallel
features for several edges in Table 1.
4 Worsening Treebanks to Simulate Some
of the SMT Frequent Errors
Addressing the issue of great differences between
the gold standard parser training data and the actual
analysis input (SMT output), we introduced artificial
inconsistencies into the training treebanks, in order
to make the parsers more robust in the face of gram-
mar errors made by SMT systems. We have concen-
42
trated solely on modeling incorrect word flection,
i.e. the dependency trees retained their original cor-
rect structures and word lemmas remained fixed, but
the individual inflected word forms have been modi-
fied according to an error model trained on real SMT
output. We simulate thus, with respect to morphol-
ogy, a treebank of parsed MT output sentences.
In Section 4.1 we describe the steps we take to
prepare the worsened parser training data. Sec-
tion 4.2 contains a description of our monolingual
greedy alignment tool which is needed during the
process to map SMT output to reference transla-
tions.
4.1 Creating the Worsened Parser Training
Data
The whole process of treebank worsening consists
of five steps:
1. We translated the English side of PCEDT5 to
Czech using SMT (we chose the Moses sys-
tem (Koehn et al, 2007) for our experiments)
and tagged the resulting translations using the
Morc?e tagger (Spoustova? et al, 2007).
2. We aligned the Czech side of PCEDT, now
serving as a reference translation, to the SMT
output using our Monolingual Greedy Aligner
(see Section 4.2).
3. Collecting the counts of individual errors, we
estimated the Maximum Likelihood probabili-
ties of changing a correct fine-grained morpho-
logical tag (of a word from the reference) into
a possibly incorrect fine-grained morphological
tag of the aligned word (from the SMT output).
4. The tags on the Czech side of PCEDT were
randomly sampled according to the estimated
?fine-grained morphological tag error model?.
In those positions where fine-grained morpho-
logical tags were changed, new word forms
were generated using the Czech morphological
generator by Hajic? (2004).6
5This approach is not conditioned by availability of parallel
treebanks. Alternatively, we might translate any text for which
reference translations are at hand. The model learned in the
third step would then be applied (in the fourth step) to a different
text for which parse trees are available.
6According to the ?fine-grained morphological tag error
We use the resulting ?worsened? treebank to train
our parser described in Section 3.2.
4.2 The Monolingual Greedy Aligner
Our monolingual alignment tool, used in treebank
worsening to tie reference translations to MT out-
put (see Section 4.1), scores all possible alignment
links and then greedily chooses the currently highest
scoring one, creating the respective alignment link
from word A (in the reference) to word B (in the
SMT output) and deleting all scores of links from A
or to B, so that one-to-one alignments are enforced.
The process is terminated when no links with a score
higher than a given threshold are available; some
words may thus remain unaligned.
The score is computed as a linear combination of
the following four features:
? word form (or lemma if available) similar-
ity based on Jaro-Winkler distance (Winkler,
1990),
? fine-grained morphological tag similarity,
? similarity of the relative position in the sen-
tence,
? and an indication whether the word following
(or preceding) A was already aligned to the
word following (or preceding) B.
Unlike bilingual word aligners, this tool needs no
training except for setting weights of the four fea-
tures and the threshold.7
5 The DEPFIX System
The DEPFIX system (Marec?ek et al, 2011) applies
various rule-based corrections to Czech-English
SMT output sentences, especially of morphological
agreement. It also employs the parsed source sen-
tences, which must be provided on the input together
with the SMT output sentences.
The corrections follow the rules of Czech gram-
mar, e.g. requiring that the clause subject be in the
model?, about 20% of fine-grained morphological tags were
changed. In 4% of cases, no word form existed for the new
fine-grained morphological tag and thus it was not changed.
7The threshold and weights were set manually using just ten
sentence pairs. The resulting alignment quality was found suf-
ficient, so no additional weights tuning was performed.
43
nominative case or enforcing subject-predicate and
noun-attribute agreements in morphological gender,
number and case, where applicable. Morphological
properties found violating the rules are corrected and
the corresponding word forms regenerated.
The source sentence parse, word-aligned to the
SMT output using GIZA++ (Och and Ney, 2003),
is used as a source of morpho-syntactic information
for the correction rules. An example of a correction
rule application is given in Figure 2.
Some
people
came
later
Atr
Sb
Pred
Advplpl
.AuxK
p?i?liPredpl
N?kte??
lid?
p?i?el
pozd?ji
Atr
Sb
Pred
Advsg, mpl
.AuxK
Figure 2: Example of fixing subject-predicate agreement.
The Czech word pr?is?el [he came] has a wrong morpho-
logical number and gender. Adapted from Marec?ek et al
(2011).
The system is implemented within the
TectoMT/Treex NLP framework (Popel and
Z?abokrtsky?, 2010). Marec?ek et al (2011) feed the
DEPFIX system with analyses by the MCD parser
trained on gold-standard treebanks for parsing of
English source sentences as well as Czech SMT
output.
6 Experiments and Results
We evaluate RUR parser indirectly by using it in the
DEPFIX system and measuring the performance of
the whole system. This approach has been chosen
instead of direct evaluation of the SMT output parse
trees, as the task of finding a correct parse tree of
a possibly grammatically incorrect sentence is not
well defined and considerably difficult to do.
We used WMT10, WMT11 and WMT12 En-
glish to Czech translation test sets, newssyscomb-
test2010, newssyscombtest2011 and news-
test2012,8 (denoted as WMT10, WMT11 and
8http://www.statmt.org/wmt10,
WMT12) for the automatic evaluation. The data sets
include the source (English) text, its reference trans-
lation and translations produced by several MT sys-
tems. We used the outputs of three SMT systems:
GOOGLE,9 UEDIN (Koehn et al, 2007) and BOJAR
(Bojar and Kos, 2010).
For the manual evaluation, two sets of 1000 ran-
domly selected sentences from WMT11 and from
WMT12 translated by GOOGLE were used.
6.1 Automatic Evaluation
Table 2 shows BLEU scores (Papineni et al, 2002)
for the following setups of DEPFIX:
? SMT output: output of an SMT system without
applying DEPFIX
? MCD: parsing with MCD
? RUR: parsing with RUR (Section 3.2)
? RUR+PARA: parsing with RUR using parallel
features (Section 3.4)
? RUR+WORS: parsing with RUR trained on
worsened treebank (Section 4)
? RUR+WORS+PARA: parsing with RUR
trained on worsened treebank and using
parallel features
It can be seen that both of the proposed ways of
adapting the parser to parsing of SMT output of-
ten lead to higher BLEU scores of translations post-
processed by DEPFIX, which suggests that they both
improve the parsing accuracy.
We have computed 95% confidence intervals
on 1000 bootstrap samples, which showed that
the BLEU score of RUR+WORS+PARA was sig-
nificantly higher than that of MCD and RUR
parser in 4 and 3 cases, respectively (results
where RUR+WORS+PARA achieved a significantly
higher score are marked with ?*?). On the other
hand, the score of neither RUR+WORS+PARA nor
RUR+WORS and RUR+PARA was ever signifi-
cantly lower than the score of MCD or RUR parser.
This leads us to believe that the two proposed meth-
ods are able to produce slightly better SMT output
parsing results.
http://www.statmt.org/wmt11,
http://www.statmt.org/wmt12
9http://translate.google.com
44
Test set WMT10 WMT11 WMT12
SMT system BOJAR GOOGLE UEDIN BOJAR GOOGLE UEDIN BOJAR GOOGLE UEDIN
SMT output *15.85 *16.57 *15.91 *16.88 *20.26 *17.80 14.36 16.25 *15.54
MCD 16.09 16.95 *16.35 *17.02 20.45 *18.12 14.35 16.32 *15.65
RUR 16.08 *16.85 *16.29 17.03 20.42 *18.09 14.37 16.31 15.66
RUR+PARA 16.13 *16.90 *16.35 17.05 20.47 18.19 14.35 16.31 15.72
RUR+WORS 16.12 16.96 *16.45 17.06 20.53 18.21 14.40 16.31 15.71
RUR+WORS+PARA 16.13 17.03 16.54 17.12 20.53 18.25 14.39 16.30 15.74
Table 2: Automatic evaluation using BLEU scores for the unmodified SMT output (output of BOJAR, GOOGLE and
UEDIN systems on WMT10, WMT11 and WMT12 test sets), and for SMT output parsed by various parser setups and
processed by DEPFIX. The score of RUR+WORS+PARA is significantly higher at 95% confidence level than the scores
marked with ?*? on the same data.
6.2 Manual Evaluation
Performance of RUR+WORS+PARA setup was man-
ually evaluated by doing a pairwise comparison with
other setups ? SMT output, MCD and RUR parser.
The evaluation was performed on both the WMT11
(Table 4) and WMT12 (Table 5) test set. 1000 sen-
tences from the output of the GOOGLE system were
randomly selected and processed by DEPFIX, using
the aforementioned SMT output parsers. The anno-
tators then compared the translation quality of the
individual variants in differing sentences, selecting
the better variant from a pair or declaring two vari-
ants ?same quality? (indefinite). They were also pro-
vided with the source sentence and a reference trans-
lation. The evaluation was done as a blind test, with
the sentences randomly shuffled.
The WMT11 test set was evaluated by two inde-
pendent annotators. (The WMT12 test set was eval-
uated by one annotator only.) The inter-annotator
agreement and Cohen?s kappa coefficient (Cohen
and others, 1960), shown in Table 3, were computed
both including all annotations (?with indefs?), and
disregarding sentences where at least one of the an-
notators marked the difference as indefinite (?with-
out indefs?) ? we believe a disagreement in choos-
ing the better translation to be more severe than a
disagreement in deciding whether the difference in
quality of the translations allows to mark one as be-
ing better.
For both of the test sets, RUR+WORS+PARA sig-
nificantly outperforms both MCD and RUR base-
line, confirming that a combination of the proposed
modifications of the parser lead to its better perfor-
mance. Statistical significance of the results was
RUR+WORS+PARA with indefs without indefs
compared to IAA Kappa IAA Kappa
SMT output 77% 0.54 92% 0.74
MCD 79% 0.66 95% 0.90
RUR 75% 0.60 94% 0.85
Table 3: Inter-annotator agreement on WMT11 data set
translated by GOOGLE
confirmed by a one-sided pairwise t-test, with the
following differences ranking: RUR+WORS+PARA
better = 1, baseline better = -1, indefinite = 0.
6.3 Inspection of Parser Modification Benefits
For a better understanding of the benefits of using
our modified parser, we inspected a small number of
parse trees, produced by RUR+WORS+PARA, and
compared them to those produced by RUR.
In many cases, the changes introduced by
RUR+WORS+PARA were clearly positive. We
provide two representative examples below.
Subject Identification
Czech grammar requires the subject to be in nom-
inative case, but this constraint is often violated in
SMT output and a parser typically fails to identify
the subject correctly in such situations. By wors-
ening the training data, we make the parser more ro-
bust in this respect, as the worsening often switches
the case of the subject; by including parallel fea-
tures, especially the aligned dependency label fea-
ture, RUR+WORS+PARA parser can often identify
the subject as the node aligned to the source subject.
45
Out of the differing sentences
Annotator Baseline Differing sentences RUR+WORS+PARA better baseline better indefinite
count percent count percent count percent
SMT output 422 301 71% 79 19% 42 10%
A MCD 211 120 57% 65 31% 26 12%
RUR 217 123 57% 64 29% 30 14%
SMT output 422 284 67% 69 16% 69 16%
B MCD 211 107 51% 56 26% 48 23%
RUR 217 118 54% 53 24% 46 21%
Table 4: Manual comparison of RUR+WORS+PARA with various baselines, on 1000 sentences from WMT11 data set
translated by GOOGLE, evaluated by two independent annotators.
Out of the differing sentences
Annotator Baseline Differing sentences RUR+WORS+PARA better baseline better indefinite
count percent count percent count percent
SMT output 420 270 64% 88 21% 62 15%
A MCD 188 86 45% 64 34% 38 20%
RUR 187 96 51% 57 30% 34 18%
Table 5: Manual comparison of RUR+WORS+PARA with various baselines, on 1000 sentences from WMT12 data set
translated by GOOGLE.
Governing Noun Identification
A parser for Czech typically relies on morpho-
logical agreement between an adjective and its gov-
erning noun (in morphological number, gender and
case), which is often violated in SMT output. Again,
RUR+WORS+PARA is more robust in this respect,
aligned edge existence now being the crucial feature
for the correct identification of this relation.
7 Conclusions and Future Work
We have studied two methods of improving the pars-
ing quality of Machine Translation outputs by pro-
viding additional information to the parser.
In Section 3, we propose a method of integrat-
ing additional information known at runtime, i.e.
the knowledge of the source sentence (source), from
which the sentence being parsed (SMT output) has
been translated. This knowledge is provided by
extending the parser feature set with new features
from the source sentence, projected through word-
alignment.
In Section 4, we introduce a method of utilizing
additional information known in the training phase,
namely the knowledge of the ways in which SMT
output differs from correct sentences. We provide
this knowledge to the parser by adjusting its training
data to model some of the errors frequently encoun-
tered in SMT output, i.e. incorrect inflection forms.
We have evaluated the usefulness of these two
methods by integrating them into the DEPFIX rule-
based MT output post-processing system (Marec?ek
et al, 2011), as MT output parsing is crucial for the
operation of this system. When used with our im-
proved parsing, the DEPFIX system showed better
performance both in automatic and manual evalua-
tion on outputs of several, including state-of-the-art,
MT systems.
We believe that the proposed methods of improv-
ing MT output parsing can be extended beyond their
current state. The parallel features used in our setup
are very few and very simple; it thus remains to
be examined whether more elaborate features could
help utilize the additional information contained in
the source sentence to a greater extent. Modeling
other types of SMT output inconsistencies in parser
training data is another possible step.
We also believe that the methods could be adapted
for use in other applications, e.g. automatic classifi-
cation of translation errors, confidence estimation or
multilingual question answering.
46
References
Ondr?ej Bojar and Kamil Kos. 2010. 2010 Failures in
English-Czech Phrase-Based MT. In Proceedings of
the Joint Fifth Workshop on Statistical Machine Trans-
lation and MetricsMATR, pages 60?66, Uppsala, Swe-
den, July. Association for Computational Linguistics.
Ondr?ej Bojar, Jan Hajic?, Eva Hajic?ova?, Jarmila Panevova?,
Petr Sgall, Silvie Cinkova?, Eva Fuc???kova?, Marie
Mikulova?, Petr Pajas, Jan Popelka, Jir??? Semecky?,
Jana S?indlerova?, Jan S?te?pa?nek, Josef Toman, Zden?ka
Ures?ova?, and Zdene?k Z?abokrtsky?. 2012. Announc-
ing Prague Czech-English Dependency Treebank 2.0.
In Proceedings of LREC 2012, Istanbul, Turkey, May.
ELRA, European Language Resources Association.
In print.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of the Tenth Conference on Computa-
tional Natural Language Learning, pages 149?164.
Association for Computational Linguistics.
David Burkett, John Blitzer, and Dan Klein. 2010.
Joint parsing and alignment with weakly synchronized
grammars. In Human Language Technologies: The
2010 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 127?135. Association for Computational Lin-
guistics.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Kay Peterson, Mark Przybocki, and Omar Zaidan.
2010. Findings of the 2010 joint workshop on sta-
tistical machine translation and metrics for machine
translation. In Proceedings of the Joint Fifth Workshop
on Statistical Machine Translation and MetricsMATR,
pages 17?53, Uppsala, Sweden, July. Association for
Computational Linguistics.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Omar Zaidan. 2011. Findings of the 2011 work-
shop on statistical machine translation. In Proceedings
of the Sixth Workshop on Statistical Machine Transla-
tion, pages 22?64, Edinburgh, Scotland, July. Associ-
ation for Computational Linguistics.
Wenliang Chen, Jun?ichi Kazama, and Kentaro Torisawa.
2010. Bitext dependency parsing with bilingual sub-
tree constraints. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, pages 21?29. Association for Computational Lin-
guistics.
Wenliang Chen, Jun?ichi Kazama, Min Zhang, Yoshi-
masa Tsuruoka, Yujie Zhang, Yiou Wang, Kentaro
Torisawa, and Haizhou Li. 2011. SMT helps bitext
dependency parsing. In EMNLP, pages 73?83. ACL.
Jacob Cohen et al 1960. A coefficient of agreement for
nominal scales. Educational and psychological mea-
surement, 20(1):37?46.
Michael Collins, Lance Ramshaw, Jan Hajic?, and
Christoph Tillmann. 1999. A statistical parser for
Czech. In Proceedings of the 37th annual meeting
of the Association for Computational Linguistics on
Computational Linguistics, ACL ?99, pages 505?512,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Jennifer Foster, Joachim Wagner, and Josef Van Gen-
abith. 2008. Adapting a WSJ-trained parser to gram-
matically noisy text. In Proceedings of the 46th An-
nual Meeting of the Association for Computational
Linguistics on Human Language Technologies: Short
Papers, pages 221?224. Association for Computa-
tional Linguistics.
Kevin Gimpel and Shay Cohen. 2007. Discriminative
online algorithms for sequence labeling- a comparative
study.
Jan Hajic?, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Anto`nia Mart??, Llu??s
Ma`rquez, Adam Meyers, Joakim Nivre, Sebastian
Pado?, Jan S?te?pa?nek, et al 2009. The CoNLL-
2009 shared task: Syntactic and semantic dependen-
cies in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task, pages 1?18. Associa-
tion for Computational Linguistics.
Jan Hajic?. 2004. Disambiguation of rich inflection: com-
putational morphology of Czech. Karolinum.
Martin Haulrich. 2012. Data-Driven Bitext Dependency
Parsing and Alignment. Ph.D. thesis.
Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
Bilingually-constrained (monolingual) shift-reduce
parsing. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing:
Volume 3-Volume 3, pages 1222?1231. Association for
Computational Linguistics.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Nat. Lang. Eng., 11:311?325, September.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In ACL
2007, Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics Companion
Volume Proceedings of the Demo and Poster Sessions,
pages 177?180, Prague, Czech Republic, June. Asso-
ciation for Computational Linguistics.
47
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-
rice Santorini. 1993. Building a large annotated cor-
pus of English: The Penn Treebank. Comput. Lin-
guist., 19:313?330, June.
David Marec?ek, Rudolf Rosa, Petra Galus?c?a?kova?, and
Ondr?ej Bojar. 2011. Two-step translation with gram-
matical post-processing. In Chris Callison-Burch,
Philipp Koehn, Christof Monz, and Omar Zaidan, edi-
tors, Proceedings of the Sixth Workshop on Statistical
Machine Translation, pages 426?432, Edinburgh, UK.
Association for Computational Linguistics.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic?. 2005. Non-projective dependency parsing
using spanning tree algorithms. In HLT ?05: Proceed-
ings of the conference on Human Language Technol-
ogy and Empirical Methods in Natural Language Pro-
cessing, pages 523?530, Vancouver, British Columbia,
Canada.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a two-
stage discriminative parser. In Proceedings of the
Tenth Conference on Computational Natural Lan-
guage Learning, CoNLL-X ?06, pages 216?220,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the Conference on Empir-
ical Methods in Natural Language Processing, pages
62?72. Association for Computational Linguistics.
Ryan McDonald. 2006. Discriminative learning and
spanning tree algorithms for dependency parsing.
Ph.D. thesis, Philadelphia, PA, USA. AAI3225503.
Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In Proceedings of the CoNLL 2007
Shared Task. Joint Conf. on Empirical Methods in Nat-
ural Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), June.
Franz Josef Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19?51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic Eval-
uation of Machine Translation. In ACL 2002, Proceed-
ings of the 40th Annual Meeting of the Association for
Computational Linguistics, pages 311?318, Philadel-
phia, Pennsylvania.
Martin Popel and Zdene?k Z?abokrtsky?. 2010. TectoMT:
modular NLP framework. In Proceedings of the 7th
international conference on Advances in natural lan-
guage processing, IceTAL?10, pages 293?304, Berlin,
Heidelberg. Springer-Verlag.
Drahom??ra Spoustova?, Jan Hajic?, Jan Votrubec, Pavel Kr-
bec, and Pavel Kve?ton?. 2007. The best of two worlds:
Cooperation of statistical and rule-based taggers for
Czech. In Proceedings of the Workshop on Balto-
Slavonic Natural Language Processing, ACL 2007,
pages 67?74, Praha.
Sara Stymne and Lars Ahrenberg. 2010. Using a gram-
mar checker for evaluation and postprocessing of sta-
tistical machine translation. In Proceedings of LREC,
pages 2175?2181.
William E. Winkler. 1990. String comparator met-
rics and enhanced decision rules in the Fellegi-Sunter
model of record linkage. In Proceedings of the Section
on Survey Research Methods (American Statistical As-
sociation), pages 354?359.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?403.
Deyi Xiong, Min Zhang, and Haizhou Li. 2010. Er-
ror detection for statistical machine translation using
linguistic features. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, pages 604?611. Association for Computational
Linguistics.
Daniel Zeman and Philip Resnik. 2008. Cross-language
parser adaptation between related languages. NLP for
Less Privileged Languages, page 35.
Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.
2009. Cross language dependency parsing using a
bilingual lexicon. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP: Volume 1-Volume 1, pages
55?63. Association for Computational Linguistics.
48
