Proceedings of the Workshop on Language in Social Media (LASM 2013), pages 41?48,
Atlanta, Georgia, June 13 2013. c?2013 Association for Computational Linguistics
Topical Positioning: A New Method for Predicting Opinion Changes in Conversation  Ching-Sheng Lin1, Samira Shaikh1, Jennifer Stromer-Galley1,2,  Jennifer Crowley1, Tomek Strzalkowski1,3, Veena Ravishankar1   1State University of New York - University at Albany, NY 12222 USA 2Syracuse University 3Polish Academy of Sciences clin3@albany.edu, sshaikh@albany.edu, tomek@albany.edu    Abstract 
In this paper, we describe a novel approach to automatically detecting and tracking discus-sion dynamics in Internet social media by fo-cusing on attitude modeling of topics. We characterize each participant?s attitude to-wards topics as Topical Positioning, employ Topical Positioning Map to represent the posi-tions of participants with respect to each other and track attitude shifts over time. We also discuss how we used participants? attitudes towards system-detected meso-topics to re-flect their attitudes towards the overall topic of conversation. Our approach can work across different types of social media, such as Twitter discussion and online chat room. In this article, we show results on Twitter data. 
1 Introduction The popularity of social networks and the new kinds of communication they support provides never before available opportunities to examine people behaviors, ideas, and sentiments in various forms of interaction. One of the active research subjects is to automatically identify sentiment, which has been adopted in many different applica-tions such as text summarization and product re-view. In general, people express their stances and rationalize their thoughts on the topics in social media discussion platform. Moreover, some of them explicitly or implicitly establish strategies to persuade others to embrace his/her belief. For ex-ample, in the discussion of the topic ?Should the legal drinking age be lowered to 18?, the partici-pants who are against it may state their views ex-plicitly and list negative consequences of lowering 
drinking age to 18 in an attempt to change opinions of those who appear to support the change. This phenomenon actually involves two research prob-lems which have been of great interest in Natural Language Processing: opinion identification and sociolinguistic modeling of discourse. The first problem can be addressed by traditional opinion analysis that recognizes which position or stance a person is taking for the given topics (So-masundaran and Wiebe, 2009). The second part requires modeling the sociolinguistic aspects of interactions between participants to detect more subtle opinion shifts that may be revealed by changes in interpersonal conversational dynamics. In this paper, we bring these two research avenues together and describe a prototype automated sys-tem that: (1) discovers each participant?s position polarities with respect to various topics in conver-sation, (2) models how participants? positions change over the course of conversation, and (3) measures the distances between participants? rela-tive positions on all topics. We analyzed discus-sions on Twitter to construct a set of meso-topics based on the persistence of certain noun phrases and co-referential expressions used by the partici-pants. A meso-topic is any local topic in conversa-tion referred to by a noun phrase and subsequently mentioned again at least 5 times via repetition, pronoun or synonym. Meso-topics do not neces-sarily represent actual topics of conversations, but certainly are important interactive handles used by the speakers. It is our hypothesis that meso-topics can be effectively used to track and predict polarity changes in speakers? positions towards the overall topic of conversation. Once the meso-topics and their polarities for each participant are determined, we can generate a topical positioning map (or net-work) (TPN) showing relative distances between 
41
participants based on all meso-topics in discourse. Comparing different snapshots of the TPN over time, we can observe how the group?s dynamic changes, i.e., how some participants move closer to one another while others drift apart in the discus-sion. In particular, we suggest that TPN changes can track and predict participants? changes of opin-ion about the overall topic of conversation. The remainder of this paper is organized as follows. In Section 2, we review related work. In Section 3, we describe the components of the pro-posed technique and the way they are used to im-plement the system. In Section 4, we discuss initial empirical studies, including data collection and evaluation. In final section, we present conclusions and some future work. 2 Related Work While systematic research on opinion tracking and influence in dialogues is a relatively new area of computational linguistics, related research includes automatic opinion mining and sentiments extrac-tion from text (Wiebe et al, 2005; Strapparava and Mihalcea, 2008), speech (Vogt et al, 2008) and social networking sites (Martineau and Finin, 2009). Much of the recent work was focused on automatic analysis of product reviews (books, movies, etc.) and extracting customers? opinions from them (Hu and Liu, 2004; David and Pinch, 2006; Zhuang et al, 2006). A typical approach is to count the number of ?opinion? words within a text window around the product names, possibly augmented with syntactic parsing to get dependen-cies right. An opinion mining application can ex-tract either full opinion sentences (Philip et al, 2003) or may generate a more structured represen-tation (Hu and Liu, 2004). Another recent applica-tion of sentiment analysis is ECO system (Effective Communication Online) (Small et al, 2010) that constructs a model of a community-wide sentiment towards certain common issues discussed in social media, particularly forums and open blogs. This model is then used to assess whether a new post would fit into the targeted community by comparing the sentiment polarities about the concepts in the message and in the model. Potential posters are then guided in ways to shape their communication so that it minimizes the num-ber of conflicting concept sentiments, while still preserving the intended message.  
Another related research domain is about modeling the social phenomena in discourse. (Strzalkowski et al, 2010, Broadwell et al, 2012) proposed a two-tier approach that relies on extract-ing observable linguistic features of conversational text to detect mid-level social behaviors such as Topic Control, Disagreement and Involvement. These social behaviors are then used to infer high-er-level social roles such as Leader and Influencer, which may have impact on how other participants? opinions form and change. 3 System Modules  In this section, we describe a series of modules in our system, which include meso-topic extraction, topical positioning and topical positioning map, and explain how we capture opinion shifts. 3.1 Meso-Topic Extraction Participants mention many ideas and subjects in dialogue. We call these Local Topics, which are any noun phrases introduced that are subsequently mentioned via repetition, synonym, or pronoun (Strzalkowski et al, 2010) by the same participant or different participants. Some local topics persist for only a couple of turns, others for much longer; some are closely relevant to the overall discussion, while others may appear to be digressions. We identify local topics, their first mentions and sub-sequent mentions, and track participants who make these mentions. Once local topics have been intro-duced into the dialogue we track their persistence as topic chains, through repetitions of the noun phrase as well as references via pronouns and the use of synonyms. Topic chains do not have to be continuous, they may contain gaps. The lengths of these gaps are also important to measures for some behaviors. Meso-topics are the most persistent lo-cal topics, topics that are widely cited through long stretches of discourse. A selection of meso-topics is closely associated with the task in which the dis-course participants are engaged. Short ?gaps? in the chain are permitted (up to 10 turns, to accom-modate digressions, obscure references, noise, etc.). Meso-topics can be distinguished from the local topics because the participants often make polar-ized statements about them. We use the Stanford part-of-speech tagger (Klein and Manning, 2003) to automatically detect nouns and noun phrases in dialogue and select those with subsequent men-
42
tions as local topics using a fairly simple pronoun resolution method based primarily on presence of specific lexical features as well as temporal dis-tance between utterances. Princeton Wordnet (Fellbaum et al, 2006) is consulted to identify synonyms and other related words commonly used in co-references. The local topics that form suffi-ciently long co-reference chains are designated as meso-topics. 3.2 Topical Positioning Topical Positioning is defined as the attitude a speaker has towards the meso-topics of discussion. Speakers in a dialogue, when discussing issues, especially ones with some controversy, will estab-lish their attitude on each topic, classified as for, against, or neutral/undecided. In so doing, they establish their positions on the issue or topic, which shapes the agenda of the discussion and also shapes the outcomes or conclusions of the discus-sion. Characterizing topical positioning allows us to see the speakers who are for, who are against, and who are neutral/undecided on a given topic or issue. To establish topical positioning, we first identify meso-topics that are present in a discourse. For each utterance made by a speaker on a meso-topic we then establish its polarity, i.e., if this ut-terance is ?for? (positive) or ?against? (negative), or neutral on the topic. We distinguish three forms of meso-topic valuation that may be present: (a) ex-press advocacy/disadvocacy, when the valuation is applied directly to the topic (e.g., ?I?m for Carla?); (b) supporting/dissenting information, when the valuation is made indirectly by offering additional information about the topic (e.g., ?He's got experi-ence with youngsters.?); and (c) express agree-ment/disagreement with a polarized statement made by another speaker. The following measures of Topical Position-ing are defined: Topic Polarity Index, which estab-lishes the polarity of a speaker?s attitude towards the topic, and Polarity Strength Index, which measures the magnitude of this attitude.   [Topic Polarity Index (TPX)] In order to detect the polarity of Topical Positioning on meso-topic T, we count for each speaker: - All utterances on T using statements with po-larity P applied directly to T using appropriate 
adverb or adjective phrases, or when T is a di-rect object of a verb. Polarities of adjectives and adverbs are taken from the expanded ANEW lexicon (Bradley and Lang, 1999). - All utterances that offer information with po-larity P about topic T. - All responses to other speakers? statements with polarity P applied to T. In the Twitter environment (and the like), for now we in-clude a re-tweet in this category. Given these counts we can calculate TPX for each speaker as a proportion of positive, negative and neutral polarity utterances made by this speaker about topic T. A speaker whose utterances are overwhelmingly positive (80% or more) has a pro-topic position (TPX = +1); a speaker whose utter-ances are overwhelmingly negative takes an against-topic position (TPX = ?1); a speaker whose utterances are largely neutral or whose utterances vary in polarity, has a neutral/undecided position on the topic (TPX = 0).  [Polarity Strength Index (PSX)] In addition to the valence of the Topical Positioning, we also wish to calculate its strength. To do so, we calculate the proportion of utterances on the topic made by each speaker to all utterances made about this topic by all speakers in the discourse. Speakers, who make most utterances on the topic relative to other speakers, take a stronger position on this topic. PSX is measured on a 5-point scale corresponding to the quintiles in normal distribution.   Topical Positioning Measure (TPM)  In order to establish the value of Topical Position-ing for a given topic we combine the values of TPX*PSX. Topical Positioning takes values be-tween +5 (strongest pro) to 0 (neutral/undecided) to ?5 (strongest against). For example, a speaker who makes 25% of all utterances on the topic ?Carla? (group mean is 12%) and whose most statements are positive, has the strongest pro Topi-cal Positioning on Carla: +5 (for fifth quintile on the positive side). 3.3 Topical Positioning Map (TPN) Given the combined values of TPM for each par-ticipant in a group, we can calculate distances be-tween the speakers on each meso-topic as well as on all meso-topics in a conversation. For meso-
43
topics (t1, ? tN), the distance is calculated using a cosine between speakers? ?vectors? (TPMt1(A) ? TPMtN(A)) and (TPMt1(B) ? TPMtN(B)). Specifi-cally, we use (1-Cosine(V1, V2)) to represent dis-tance between node V1 and V2 in the network, where the range becomes 0 to 2.  With the aid of TPN, we can detect the opin-ion shifts and model the impact of speakers with specific social roles in the group, which in our case is the influencer. An influencer is a group partici-pant who has credibility in the group and introduc-es ideas that others pick up on or support. An influencer model is generated from mid-level soci-olinguistic behaviors, including Topic Control, Disagreement and Involvement (Shaikh et al, 2012). In order to calculate effect of the influencer on a group, we track changes in the TPN distances between speakers, and particularly between the influencer and other speakers. We want to know if the other speakers in the group moved closer to or further away from the influencer, who may be promoting a particular position on the overall sub-ject of discussion. Our hypothesis is that other par-ticipants will move closer (as a group, though not necessarily individually) to an influential speaker. We may also note that some speakers move closer while others move away, indicating a polarizing effect of an influential speaker. If there is more than one influencer in the group these effects may be still more complex. 4 Data Collection and Experiment  Our initial focus has been on Twitter discussions which enable users to create messages, i.e., ?tweets?. There are plenty of tweet messages gen-erated all the time and it is reported that Twitter has surpassed 400 million tweets per day. With the Twitter API, it is easy to collect those tweets for research, as the communications are considered public. However, most of data obtained publicly is of limited value due to its complexity, lack of fo-cus, and inability to control for many independent variables. In order to derive reliable models of conversational behavior that fulfill our interests in opinion change, we needed a controlled environ-ment with participants whose initial opinions were known and with conversation reasonably focused on a topic of interest. To do so, we recruited partic-ipants for a two-week Twitter debates on a variety of issues, one of the topics was ?Should the mini-
mum legal drinking age be lowered to 18?? We captured participants? initial positions through sur-veys before each debate, and their exit positions through surveys after the debate was completed two weeks later. The surveys were designed to col-lect both the participants? opinions about the over-all topic of conversation as well as about the roles they played in it. These data were then compared to the automatically computed TPN changes. 4.1 Data Collection To obtain a suitable dataset, we conducted two groups of controlled and secured experiments with Twitter users. The experiment was specially de-signed to ensure that participants stay on topic of discussion and that there was a minority opinion represented in the group. We assigned the same overall topic for both groups: ?lowering the drink-ing age from 21 to 18?. Before the discussion, the participants completed an 11-question survey to determine their pre-discussion attitudes toward overall topic. One participant with the minority opinion was then asked to act as an influencer in the discussion, i.e., to try to convince as many people as possible to adopt his or her position. Af-ter the discussion, the participants were asked the same 11 questions to determine if their positions have changed. All 11 questions probed various aspects of the overall topic, thus providing a relia-ble measure of participant?s opinion. All responses were on a 7-point scale from ?strongly agree? to ?strongly disagree?. The orientation of individual questions vs. the overall topic was varied to make sure that the participants did not mechanically fill their responses. Some of the questions were:  (1) Lowering the drinking age to 18 would make alcohol less of a taboo, making alcohol consump-tion a more normalized activity to be done in mod-eration.   +3 strongly agree ----- -3 strongly disagree (2) 18 year olds are more susceptible to binge drinking and other risky/irresponsible behaviors than people who are 21 and older. -3 strongly agree ----- +3 strongly disagree  (note reversed polarity) The basic statistical information about the two ex-perimental groups is given in Table 1 and the tweet distribution of each participant in Group-1 is shown in Figure 1. Participants are denoted by a 
44
two-letter abbreviation (WS, EP and so on). The current data set is only a fraction of a larger cor-pus, which is currently under development. Addi-tional datasets cover a variety of discussion topics and involve different groups of participants.  Group # participants # tweets Influencer 1 20 225 WS 2 14 222 EP Table 1: Selected details of two experimental groups.   
 Figure 1: Tweet distribution for each participant in Group-1 where participants with asterisk are against ?lowering drinking age?.  As we would like to know the participants? pre- and post-discussion attitudes about the overall top-ic, we used the responses on 11 survey questions to calculate how strongly participants feel on the overall topic of discussion. Each question is given on a seven-point scale ranging from ?+3? to ?-3?, where ?+3? implies strongly agree to keep drinking age at 21 and ?-3? means strongly disagree. Posi-tions of participants are determined by adding the scores of the 11 questions according to their re-sponses on pre- or post- discussion questionnaires. Figure 2 is an example of pre-discussion responses for two participants in Group-1. WS largely agrees that drinking age should be kept at 21 whereas EK has an opposing opinion. The pre- and post-discussion attitudes of participants in Group-1 to-wards the overall topic are shown in Figure 3.  
 Figure 2: Pre-discussion survey scores of WS and EK. 
Subsequently, we computed relative pre-discussion attitude distance between each participant and the influencer based on the pre-discussion surveys and their post-discussion attitude distance based on the post-discussion surveys. We normalized these dis-tances to a [0, 2] interval to be consistent with co-sine distance computation scale used in the TPN module. The changes from pre-discussion attitude distance to post-discussion attitude distance based on the surveys are considered the gold standard against which the system-computed TPN values are measured. As shown in Figure 4(a), the pre-discussion distance between WS and EK is 1.43 (first bar) and the post-discussion distance is 0.07 (second bar), which implies their positions on the overall topic moved significantly closer. We also note that WS?s position did not change much throughout the discussion (Figure 3). This was just as we expected since WS was our designated influ-encer, and this fact was additionally confirmed in the post survey: in response to the question ?Who was the influencer in the discussion?? the majority of participants selected WS. The post survey re-sponses from the other group also confirmed our selected influencer. In addition, we used the auto-mated DSARMD system (Strzalkowski et al, 2013) to compute the most influential participants in each group, and again the same people were identified.  
 Figure 3: Pre- and post-discussion attitudes of partici-pants in Group-1 where the left bar of the participant is their pre-discussion attitude and right bar of the partici-pant is their post-discussion attitude. 
45
  Figure 4: (a) Relative position change between speakers WS (the influencer) and EK based on surveys and au-tomatically computed TPN distance. The first bar in each par corresponds to their pre-discussion distance and second bar is post-discussion distance. We note that TPN predicts correctly that WS and EK move closer together. (b) Relative position change between partici-pants WS and BC.   
4.2 Experiment After detailed analysis of participants? opinion be-fore and after the discussion, two twitter discus-sions are run through our system to extract the required information in order to compute topical positioning as explained in section 3. In Group-1, ten meso-topics were generated by our system (in-cluding, e.g., ?drinking age?, ?teens? and ?alco-hol?). Each participant?s polarity associated with these meso-topics was computed by our system to form ten-dimensional topical positioning vectors for Group-1. In our experiment, we used the first quarter of discussion to compute initial topical po-sitioning of the group and last-three quarters to compute the final topical positioning. Once the pre- and post-topical positioning were determined, the topical positioning map between participants was calculated accordingly, i.e., pre- and post-TPN. We used the first quarter of discussion for the initial TPN because we required a sufficient amount of data to compute a stable measure; how-ever, we expected it would not fully represent par-ticipants? initial positions. Nonetheless, we should still see the change when compared with post-TPN, which was computed on the last three-quarters of the discussion. In order to detect the opinion shifts and also to measure the effect of the influencer on a group, we tracked the changes in the TPN with respect to the influencer. As shown in Figure 4(a), the pre-TPN between WS and EK is 1.33 (third bar) and post-TPN is 0.72 (fourth bar). Hence, the system determines that their opinions are moving closer which conforms to the survey results. Figure 4(b) is another example of WS and BC that system result shows the same tendency as the survey result. The pre-discussion distance between WS and BC is 1.87 (first bar) and the post-discussion distance is 1.42 (second bar), which implies their positions on the overall topic moved closer after discussion. In system detection, the pre-TPN between is 1.56 (third bar) and post-TPN is 1.02 (fourth bar), which also concludes their attitudes are closer. An-other examples showing that speaker moved away from influencer are in Figure 5(a) and 5(b). Ac-cording to the survey, the pre-discussion attitude distance between WS and CC is 0.62 (first bar) and post-discussion attitude distance is 1.35 (second bar), which implies their positions diverged after the discussion. Our system determined pre-TPN between WS and CC is 1.0 (third bar) and post-
46
TPN is 1.29 (fourth bar), which shows their diver-gence.  
Figure 5: (a) Relative position change between WS and CC based on surveys and TPN. (b) Relative position change between participants WS and RF. We note that RF moves away from WS, which is correctly predicted by TPN.   In a separate exercise we also explored differ-ent parts of the Twitter session to compute pre-TPN and post-TPN, in addition to the ? vs. ? split discussed above. In particular, we computed TPN distances between speakers at first ? vs. second ?, 
first ? vs. last ?, first ? vs. last ?, etc. Experiment results show that using the first quarter of discus-sion as initial topical positioning and last quarter as final topical positioning (? vs. ?) produces the most accurate prediction of opinion changes for all group participants: 87.5% in Group-1 and 76% in Group-2.  We should also note here that there is no specific correlation between the meso-topics and the overall topic other than the meso-topics arise spontaneously in the conversation. The set of me-so-topics in the second discussion on the same top-ic was different than the in the first discussion. In particular, meso-topics are not necessarily correlat-ed with the aspects of the overall topic that are ad-dressed in the surveys. Nonetheless, the TPN changes appear to predict the changes in surveys in both discussions. At this time the results is indica-tive only. Further experiments need to be run on additional data (currently being collected) to con-firm this finding. 5 Conclusion In this paper, we described an automated approach to detect participant?s Topical Positioning and cap-ture the opinion shifts by Topical Position Maps. This work is still in progress and we intend to pro-cess more genres of data, including Twitter and on-line chat, to confirm effects seen in the data we currently have. The future work should be able to account for the relationship between meso-topic and overall topic (i.e., supporting meso-topic means for or against overall topic). A potential so-lution could be determined by aligning with TPN of influencers who are known strongly pro- or against- overall topic. Another avenue of future work is to apply proposed model on virtual chat-room agent to guide the discussion and change par-ticipants? attitudes.  References  Bradley, M. M., & Lang, P. J. 1999. Affective norms for English words (ANEW): Instruction manual and af-fective ratings(Tech. Rep. No. C-1). Gainesville, FL: University of Florida, The Center for Research in Psychophysiology. Broadwell, George, Jennifer Stromer-Galley, Tomek Strzalkowski, Samira Shaikh, Sarah Taylor, Umit Boz, Alana Elia, Laura Jiao, Ting Liu, and Nick Webb. "Modeling Socio-Cultural Phenomena in Dis-
47
course." Journal of Natural Language Engineering (2012): 1-45. David, S., and Pinch, T. J. 2006. Six degrees of reputa-tion: The use and abuse of online review and recom-mendation systems. First Monday. Special Issue on Commercial Applications of the Internet.  Fellbaum, C., B. Haskell, H. Langone, G. Miller, R. Poddar, R. Tengi and P. Wakefield. 2006. WordNet 2.1. Hu, M., and Liu, B. 2004. Mining opinion features in customer reviews. In Proceedings of AAAI, 755?760. Klein, D., & Manning, C. D. 2003. Accurate unlexical-ized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguis-tics-Volume 1 , 423-430. Association for Computa-tional Linguistics. Martineau, J., & Finin, T. 2009. Delta tfidf: An im-proved feature space for sentiment analysis. In Pro-ceedings of the 3rd AAAI International Conference on Weblogs and Social Media, 258-261. Philip Beineke, Trevor Hastie, Christopher Manning and Shivakumar Vaithyanathan 2003. An exploration of sentiment summarization. In Proceedings of AAAI, 12-15. Shaikh, Samira, et al2012. Modeling Influence in Online Multi-party Discourse. Cloud and Green Computing (CGC), 2012 Second International Con-ference on. IEEE. Small, S., Strzalkowski, T. and Webb, N. 2010. ECO: Effective Communication Online. Technical Report ILS-015, University at Albany, SUNY Somasundaran, S., & Wiebe, J. 2009. Recognizing stances in online debates. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natu-ral Language Processing of the AFNLP. Strapparava, C., and Mihalcea, R. 2008. Learning to Identify Emotions in Text. In Proceedings of the ACM Conference on Applied Computing ACM-SAC. Strzalkowski, T.; Broadwell, G. A.; Stromer-Galley, J.; Shaikh, S.; Taylor, S.; and Webb, N. 2010. Modeling socio-cultural phenomena in discourse. In Proceed-ings of the 23rd International Conference on Compu-tational Linguistics, 1038-1046. Strzalkowski, T., Samira Shaikh, Ting Liu, George Aa-ron Broadwell, Jennifer Stromer-Galley, Sarah M. Taylor, Veena Ravishankar, Umit Boz, Xiaoai Ren: Influence and Power in Group Interactions. SBP 2013: 19-27 Vogt, T., Andre?, E., & Bee, N. 2008. EmoVoice?A framework for online recognition of emotions from voice. Perception in Multimodal Dialogue Systems, 188-199. Wiebe, J., Wilson, T., and Cardie, C. 2005. Annotating expressions of opinions and emotions in language. 
Journal of Language Resources and Evaluation 39(2-3):165?210 Zhuang, L., Jing, F., Zhu, X. Y., & Zhang, L. 2006. Movie review mining and summarization. In Confer-ence on Information and Knowledge Management: Proceedings of the 15 th ACM international confer-ence on Information and knowledge management, 43-50. 
48
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 210?220,
Dublin, Ireland, August 23, 2014.
Discovering Conceptual Metaphors Using Source Domain Spaces 
  Samira Shaikh1, Tomek Strzalkowski1, Kit Cho1, Ting Liu1, George Aaron Broadwell1, Laurie Feldman1, Sarah Taylor2, Boris Yamrom1, Ching-Sheng Lin1, Ning Sa1, Ignacio Cases1, Yuli-ya Peshkova1 and Kyle Elliot3  1State University of New York  ? University at Albany 2Sarah M. Taylor Consulting LLC samirashaikh@gmail.com     
3Plessas Experts Network 
 Abstract This article makes two contributions towards the use of lexical resources and corpora; specifically making use of them for gaining access to and using word associations. The direct application of our approach is for detecting linguistic and conceptual metaphors automatically in text. We describe our method of building conceptual spaces, that is, defining the vocabulary that characterizes a Source Domain (e.g., Disease) of a conceptual metaphor (e.g., Poverty is a Disease). We also describe how these conceptual spaces are used to group linguistic metaphors into conceptual metaphors. Our method works in multiple languages, including English, Spanish, Russian and Farsi. We provide details of how our method can be evaluated and evaluation results that show satisfactory performance across all languages. 1 Introduction Metaphors are communicative devices that are pervasive in discourse. When understood in a cultural context, they provide insights into how a culture views certain salient concepts, typically broad, abstract concepts such as poverty or democracy. In our research, we are focusing on metaphors on targets of governance, economic inequality and democracy, although our approach works for metaphors on any target. Suppose it is found in a culture that its people use metaphors when speaking of poverty; for example, they may talk about ?symptom of poverty? or that ?poverty infects areas of the city?. These expressions are linguistic metaphors that are instances of a broader conceptual metaphor: Poverty is a Disease. Similarly, if it is found that common linguistic metaphors about poverty for peoples of a culture include ?deep hole of poverty? and ?fall into poverty?, it would lead to the conceptual metaphor: Poverty is an Abyss. A communicator wishing to speak of ways to deal with poverty would use metaphors such as ?treat poverty? and ?cure poverty? to make their framing consistent with the conceptual metaphor of Disease, whereas she would use metaphors such as ?lift out of poverty? when speaking to people who are attuned to the Abyss conceptual metaphor. Here Disease and Abyss are source domains, and poverty is the target domain. Relations, like ?symptom of?, ?infect? and ?fall into? from the respective source domains are mapped onto the target domain of poverty. In order to discover conceptual metaphors and group linguistic metaphors together, we make use of corpora to define the conceptual space that characterizes a source domain. We wish to discover the set of relations that are used literally for a given source domain, and would create metaphors if applied to some other target domain. That is, we wish to automatically discover that relations such as ?symptom?, ?infect?, ?treat? and ?cure? characterize the source domain of Disease, for example. To create the conceptual spaces, we employ a fully automated method in which we search a balanced corpus using specific search patterns. Search patterns are so created as to look for co-occurence of                                                 This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/  
210
relations with members of a given source domain. Relations could be nouns, verbs, verb phrases and adjectives that are frequently used literally within a source domain. In addition, we calculate the frequency with which relations occur in a given source domain, or Relation Frequency. We then calculate the Inverse Domain Frequency (IDF), a variant of the inverse document frequency measure quite commonly used in field of information retrieval; the IDF captures the degree of distribution of relations across all source domains under consideration. Using these two measures, the relation frequency and inverse domain frequency, we are able to rank relations within a source domain. This ranked list of relations are then used to group linguistic metaphors belonging to the same source domain together. A group of linguistic metaphors so formed is a conceptual metaphor.  2 Related Research Most current research on metaphor falls into three groups: (1) theoretical linguistic approaches (as de-fined by Lakoff & Johnson, 1980; and their followers) that generally look at metaphors as abstract language constructs with complex semantic properties; (2) quantitative linguistic approaches (e.g., Charteris-Black, 2002; O?Halloran, 2007) that attempt to correlate metaphor semantics with their us-age in naturally occurring text but generally lack robust tools to do so; and (3) social science ap-proaches, particularly in psychology and anthropology that seek to explain how people deploy and understand metaphors in interaction, but which lack the necessary computational tools to work with anything other than relatively isolated examples.     Metaphor study in yet other disciplines has included cognitive psychologists (e.g., Allbritton, McKoon & Gerrig, 1995) who have focused on the way metaphors may signify structures in human memory and human language processing. Cultural anthropologists, such as Malkki in her work on ref-ugees (1992), see metaphor as a tool to help outsiders interpret the feelings and mindsets of the groups they study, an approach also reflective of available metaphor case studies, often with a Political Sci-ence underpinning (Musolff, 2008; Lakoff, 2001).      In computational investigations of metaphor, knowledge-based approaches include MetaBank (Mar-tin, 1994), a large knowledge base of metaphors empirically collected. Krishnakumaran and Zhu (2007) use WordNet (Felbaum, 1998) knowledge to differentiate between metaphors and literal usage. Such approaches entail the existence of lexical resources that may not always be present or satisfacto-rily robust in different languages. Gedigan et al (2006) identify a system that can recognize metaphor. However their approach is only shown to work in a narrow domain (Wall Street Journal, for example).     Computational approaches to metaphor (largely AI research) to date have yielded only limited scale, often hand designed systems (Wilks, 1975; Fass, 1991; Martin, 1994; Carbonell, 1980; Feldman & Narayan, 2004; Shutova & Teufel, 2010; inter alia, also Shutova, 2010b for an overview). Baumer et al (2010) used semantic role labels and typed dependency parsing in an attempt towards computational metaphor identification. However, they self-report their work to be an initial exploration and hence, inconclusive. Shutova et al (2010a) employ an unsupervised method of metaphor identification using nouns and verb clustering to automatically impute metaphoricity in a large corpus using an annotated training corpus of metaphors as seeds. Their method relies on annotated training data, which is diffi-cult to produce in large quantities and may not be easily generated in different languages.  More recently, several important approaches to metaphor extraction have emerged from the IARPA Metaphor program, including Broadwell et al (2013), Strzalkowski et al. (2014), Wilks et al (2013), Hovy et al (2013) inter alia. These papers concentrate on the algorithms for detection and classification of individual linguistic metaphors in text rather than formation of conceptual metaphors in a broader cultural context. Taylor et al (2014) outlines the rationale why conceptual level metaphors may provide important insights into cross-cultural contrasts. Our work described here is a first attempt at automatic discovery of conceptual metaphors operating within a culture directly from the linguistic evidence in language. 3 Our Approach The process of discovering conceptual metaphors is necessarily divided into two phases: (1) collecting evidence about potential source domains that may be invoked when metaphorical expressions are used; and (2) building a conceptual space for each sufficiently evidenced source domain so that linguistic metaphors can be accurately classified as instances of appropriate conceptual metaphors. In 
211
this paper, we concentrate on the second phase only. Strzalkowski et al (2013) in their work have described a data-driven linguistic metaphor extraction method and our approach builds upon their work. During the source domain evidencing phase, we established a set of 50 source domains that operate frequently with the target concepts we are focusing on (government, bureaucracy, poverty, wealth, taxation, democracy and elections). These domains were a joint effort of several teams participating in the Metaphor program and we are taking this set as a starting point. These are shown in Table 1.   A_GOD	 ? CONFINEMENT	 ? GAME	 ? MONSTER	 ? PLANT	 ?A_RIGHT	 ? CRIME	 ? GAP	 ? MORAL_DUTY	 ? PORTAL	 ?ABYSS	 ? CROP	 ? GEOGRAPHIC_FEATURE	 ? MOVEMENT	 ? POSITION	 ?AND	 ?CHANGE	 ?OF	 ?	 ?POSITION	 ?ON	 ?A	 ?SCALE	 ?ADDICTION	 ? DARKNESS	 ? GREED	 ? NATURAL_PHYSICAL_FORCE	 ? RACE	 ?ANIMAL	 ? DESTROYER	 ?	 ? HUMAN_BODY	 ? OBESITY	 ? RESOURCE	 ?BATTLE	 ? DISEASE	 ? IMPURITY	 ? PARASITE	 ? STAGE	 ?BLOOD_STREAM	 ? ENERGY	 ? LIGHT	 ? PATHWAY	 ? STRUGGLE	 ?BODY_OF_WATER	 ? ENSLAVEMENT	 ? MACHINE	 ? PHYSICAL_BURDEN	 ? THEFT	 ?BUILDING	 ? FOOD	 ? MAZE	 ? PHYSICAL_HARM	 ? VISION	 ?COMPETITION	 ? FORCEFUL_EXTRACTION	 ? MEDICINE	 ? PHYSICAL_LOCATION	 ? WAR	 ?Table 1. Set of 50 source domains that operate frequently with target concepts being investigated. Only English names are shown for ease of presentation, equivalent sets in Spanish, Russian and Farsi have been created. Some of the domains are self explanatory, while others require a further specification since the labels are sometimes ambiguous. For example, PLANT represents things that grow in the soil, not factories; similarly, BUILDING represents artifacts such as houses or edifices, but not the act of constructing something; RACE refers to a running competition, not skin color, etc.  Consequently, each of these domains need to be seeded with the prototypical representative elements to make the meaning completely clear. This seeding occurs during the first phase of the process when a linguistic expression, such as ?cure poverty? is classified as a linguistic metaphor. This process of classifying ?cure poverty? as metaphorical is described in detail in Strzalkowski et al. (2013). Part of the seeding process is to establish that a source domain different than the target domain (here: poverty) is invoked by the relation (here: cure). To find the source domain where ?cure? is typically used literally, we form a linguistic pattern [cure [OBJ: X/nn]] (derived automatically from the parsed metaphoric expression) which is subsequently run through a balanced language corpus. Arguments matching the variable X are then clustered into semantic categories, using lexical resources such as Wordnet (Felbaum, 1998) and the most frequent and concrete category is selected as a possible source domain (proto-source domain). From the balanced language corpus, it is possible to compute the frequency with which the arguments resulting from search appear with relation (?cure?). We determine concreteness by looking up concreteness score in MRC psycholinguistic database (Coltheart 1981, Wilson 1988). As may be expected, the initial elements of the proto-source obtained from the above patterns will include: disease, cancer, plague, etc. These become the seeds of the source domain DISEASE in our list. The same process was performed for each of the 50 domains listed here, for each of the 4 languages under consideration. Additional Source Domains are continously generated bottom-up fashion by this phase 1 process elaborated above. In Table 2, we show seeds so obtained for a few source domains.    DISEASE	 ? disease,	 ?cancer,	 ?plague	 ?ABYSS	 ? abyss,	 ?chasm,	 ?crevasse	 ?BODY_OF_WATER	 ? ocean,	 ?lake	 ?river,	 ?pond,	 ?sea	 ?PLANT	 ? plant,	 ?tree,	 ?flower,	 ?weed,	 ?shrub,	 ?vegetable	 ?GEOGRAPHIC_FEATURE	 ? land,	 ?land	 ?form,	 ?earth,	 ?mountain,	 ?plateau,	 ?island,	 ?valley	 ?Table 2. Example of seeds corresponding to a few source domains 
212
Once such seeds are obtained, we perform another search through a balanced corpus in the corresponding language to discover relations that characterize the source domains. The purpose of source domain spaces in our research is two-fold: a) to provide a sufficiently complete characterization of a source domain via a list of relations ; and b) such a list of relations should sufficiently distinguish between different source domains. Creating these spaces is phase 2 of the conceptual metaphor discovery process. We search for nouns, verbs and verb phrases, and adjectives that co-occur with seeds of given source domain with sufficiently high frequency and sufficiently high mutual information. Our goal with this process is to approximate normal usage patterns of relations within source domains. The results of balanced corpora search form our conceptual spaces. The balanced corpora we use are English: Corpus of Contemporary American English (Davies, 2008), Spanish:  Corpus del Espa?ol Actual (Davies, 2002), Russian: Russian National Corpus2 and Farsi: Bijankhan Corpus (Oroumchian et al., 2006). In addition to retrieving the relations, we retrieve the frequency with which these relations can be found to co-occur with seeds of a source domain, Relation Frequency (RF). We calculate Inverse Domain Frequency (IDF) of all relations across all 50 source domains using a variant of the inverse document frequency measure. The formula for IDF is as given below:  IDF = log (total number of source domains / total number of source domains a relation appears in)  For example, if a relation such as ?dive into? is found to appear in two source domains, BODY_OF_WATER and GEOGRAPHIC_FEATURE, then the IDF for ?dive into? would be log (50/2). The rank of a relation is computed as the product of RF and IDF. However, computing rank using RF without normalization results in inflated ranks for relations that are quite common across domains even when they do not sufficiently disambiguate between the domains. We assume a normal distribution of frequencies of relations within a source domain and normalize RF by taking its logarithm. We also normalize with respect to seeds within a source domain. If a relation frequency is disproportionately high with a specific seed, we disregard that frequency. For example, one of the seeds for the source domain of BUILDING is ?house?. A search through balanced corpus for nouns adjacent to ?house? revealed a disproportionately large number for ?white?, which is meant to be the White House, and would be disregarded.  In Table 3, we show a few top ranked relations for the source domains DISEASE and BODY_OF_WATER. In columns 1 and 2, we show the source domain and the relation. Column 3 shows the relation frequency and column 4 shows the part of speech of relation (V=verb or verb phrase, N=noun, ADJ=adjective). An RF score of 800 for row 1 indicates that the relation ?diagnose with? appears 800 times with one or more of the seeds we search for source domain DISEASE (?diagnose with cancer?, ?diagnose with disease? and so on. In column 5, we show the position where the relation is commonly found to co-occur with the source domain. For example, ?afflict? in row 2 has a position ?after? which means it appears after DISEASE: ?DISEASE afflict(s)?; whereas row 3 would be read as ?affict with DISEASE? since it appears ?before?. In column 6, we show the normalized RF*IDF score. The highest RF*IDF score for a relation across our spaces is 2.165. From Table 3, we can see that even if  frequency for some relations may be relatively low, their rank would be high if they are strongly associated with a single source domain.    	 ? 1.	 ?Source	 ?Domain	 ? 2.	 ?Relation	 ? 3.	 ?RF	 ? 4.	 ?Type	 ? 5.	 ?Position	 ? 6.	 ?Norm	 ?RF*IDF	 ?1	 ? DISEASE	 ? diagnose	 ?with	 ? 800	 ? V	 ? before	 ? 1.94	 ?2	 ? DISEASE	 ? afflict	 ? 85	 ? V	 ? after	 ? 1.67	 ?3	 ? DISEASE	 ? afflict	 ?with	 ? 33	 ? V	 ? before	 ? 1.52	 ?4	 ? DISEASE	 ? cure	 ?of	 ? 29	 ? N	 ? before	 ? 1.46	 ?5	 ? BODY_OF_WATER	 ? dive	 ?into	 ? 49	 ? V	 ? before	 ? 2.01	 ?6	 ? BODY_OF_WATER	 ? wade	 ?through	 ? 44	 ? V	 ? before	 ? 1.88	 ?7	 ?	 ? BODY_OF_WATER	 ? wade	 ?into	 ? 42	 ? V	 ? before	 ? 1.84	 ?8	 ? BODY_OF_WATER	 ? rinse	 ?in	 ? 41	 ? V	 ? before	 ? 1.80	 ?Table 3. A few top ranking relations for the source domains DISEASE and BODY_OF_WATER. Relations are ranked by their normalized RF*IDF score.                                                 2 http://ruscorpora.ru/en/ 
213
With the conceptual spaces defined in this manner, we can now use them to group linguistic metaphors together. Shaikh et al (2014) have created a repository of thousands of automatically extracted lingusitic metaphors in all four languages, which we are using to create conceptual metaphors. To discover which conceptual metaphors exist within such large sets of linguistic metaphors would be quite challenging, if not impossible, for a human expert. We automatically assign each linguistic metaphor to ranked list of source domains.  Consider the linguistic metaphor ?plunge into poverty?, where the relation is ?plunge into?. We search through our conceptual spaces and retrieve a list of source domains where the relation ?plunge into? may appear. From this list, only the domains that have this relation RF*IDF score higher than a threshold are considered. This threshold is currently assigned to be 0.40, although it is subject to further experimentation. The source domain where the RF*IDF score of ?plunge into? is the highest is chosen as the source domain, along with the next source domains only if the difference in scores is 5% or lower. Tables 4 and 5 depicts this part of algorithm for two relations, ?plunge into? and ?explorar? (from Spanish ? ?explore?). The relation ?plunge into? is thus assigned to BODY_OF_WATER source domain. ?explorar? is assigned to GEOGRAPHIC_FEATURE and BODY_OF_WATER since difference in RF*IDF scores is less than 5%.  Relation	 ? Source	 ?Domains	 ? RF*IDF	 ?	 ? 	 ? Relation	 ? Source	 ?Domains	 ? RF*IDF	 ?
plunge	 ?into	 ?	 ?
BODY_OF_WATER	 ? 1.82	 ? 	 ?
explorar	 ?
GEOGRAPHIC_FEATURE	 ? 0.77	 ?DARKNESS	 ? 1.28	 ? 	 ? BODY_OF_WATER	 ? 0.76	 ?ABYSS	 ? 0.68	 ? 	 ? PHYSICAL_LOCATION	 ? 0.56	 ?WAR	 ? 0.57	 ? 	 ? PATHWAY	 ? 0.56	 ?GEOGRAPHIC_FEATURE	 ? 0.48	 ? 	 ? BUILDING	 ? 0.41	 ?Table 4 and Table 5. Assigning relations of linguistic metaphor to source domains. ?plunge into? is assigned to BODY_OF_WATER; ?explorar? is assigned to GEOGRAPHIC_FEATURE and BODY_OF_WATER Once this process of assigning linguistic metaphors to source domains is accomplished for all linguistic metaphors in our repository, we validate the resulting conceptual metaphors. A small percentage of metaphors cannot be assigned to any of the 50 Source Domains. We explain the validation process in Section 4. In Tables 6 and 7, we show sample conceptual metaphors in English and Spanish. Our validation process revealed an interesting insight regarding forming conceptual metaphor, wherein they should contain relations that are anchors for that given source domain that we shall describe next.  
 Table 6. A conceptual metaphor in English: POVERTY is a BODY_OF_WATER 
214
 Table 7. A conceptual metaphor in Spanish: POVERTY is a DISEASE 3.1 Anchor relations in Conceptual Metaphors When human assessors are presented with a set of linguistic metaphors and the task to assign them into a source domain, some relations will have stronger impact on their decision that others. For example, ?cure? would almost invariably be assigned to DISEASE domain, while ?dive in? would invoke BODY_OF_WATER domain. Other relations, such as ?spread? or ?fall into? are less specific, however, when paired with highly evocative relations above are likely to be classified the same way. Thus, there are two types of metaphorical relations in linguistic metaphors: (1) the highly evocative relations that unambigously point to a specific source domain ? we shall call them anchors; and (2) the relations that are compatible with the anchor but are not anchors themselves. We can add another class: (3) the relations that are not compatible with a given anchor. Thus, a set of linguistic metaphors that provides evidence for a conceptual metaphor should contain at least some anchor relations and the balance of the set may be composed of anchor-compatible relations. Our current hypothesis is that there should be at least one anchor for each 7 anchor compatible relations for a group of linguistic metaphors to provide a sufficient evidence for a conceptual metaphor.  As part of our validation process, we conducted a series of experiments with human assessors. One of the tasks was to assign a single linguistic metaphor to one of 50 source domains. As an illustrative example, we show in Table 8, one linguistic metaphor. When presented with this example, a majority of assessors chose ENEMY source domain, while DISEASE was selected second. Additionally, there was greater variance among their selections, only 31% chose the top source domain of ENEMY.  Subsequently, human assessors were presented a set of linguistic metaphors where at least one anchor relation was present. In this case, the majority of assessors chose the DISEASE source domain. Even though the ?fight against poverty? example was included in the set, the presence of anchors such as ?cure poverty? and ?treat poverty? lead assessors to choose DISEASE source domain. The variance in selection was also less, a 70% majority choosing DISEASE. We show the conceptual metaphor in Table 9.  The	 ?summit	 ?has	 ?proven	 ?that	 ?there	 ?is	 ?a	 ?renewed	 ?appetite	 ?for	 ?the	 ?fight	 ?against	 ?poverty.	 ?	 ?ENEMY:	 ?31%;	 ?DISEASE:	 ?17%;	 ?ANIMAL,	 ?MONSTER,?.<10%	 ?Table 8. A single linguistic metaphor was assigned a varied number of source domains by human assessors.   Of	 ?course,	 ?many	 ?government	 ?programs	 ?aim	 ?to	 ?alleviate	 ?poverty.	 ?We	 ?seek	 ?to	 ?stimulate	 ?true	 ?prosperity	 ?rather	 ?than	 ?simply	 ?treat	 ?poverty.	 ?Unless	 ?the	 ?fight	 ?against	 ?poverty	 ?is	 ?honestly	 ?addressed	 ?by	 ?the	 ?West,	 ?there	 ?will	 ?be	 ?many	 ?more	 ?Afghanistans.	 ?Above	 ?all,	 ?he	 ?knows	 ?that	 ?the	 ?only	 ?way	 ?to	 ?cure	 ?poverty	 ?is	 ?to	 ?grow	 ?the	 ?economy.	 ?	 ?DISEASE:	 ?70%;	 ?ENEMY:	 ?30%	 ?Table 9. A conceptual metaphor containing anchors. When sample metaphor from Table 8 is included in this set, human assessors still choose the source domain to be DISEASE. 
215
4 Evaluation and Results A group of human experts who are native speakers and have been substantively trained to achieve high levels of agreement (0.78 Krippendorf?s alpha (1970) or higher) form our validation team. In addition, we aim to run crowd-sourced experiments on Amazon Mechanical Turk. In Figure 1, we show a web interface we built to present our human assessors. The task shown here is the assignment of a single linguistic metaphor to one of 50 source domains. Then, we present our validation team with conceptual metaphors we created. Each conceptual metaphor is validated by at least two language experts. This interface is shown in Figure 2. These interfaces are carefully created by our team of social scientists and psychologists, designed to elicit proper responses from native speakers of the language.  
 Figure 1. Interface of task where human assessors select source domain for a single linguistic metaphor.  
216
 Figure 2. Interface of task where human assessors select source domains for a conceptual metaphor. Assessors provide their top two choices along with a description detailing how they made their decision.  In Table 10, we show the number of conceptual metaphors currently in the repository and the accuracy of our method across four languages, as computed by using validation data. We show the number of conceptual metaphors present in the Governance target domain (metaphors about government and bureaucracy), Economic Inequality (dealing with metaphors of poverty, wealth and taxation) and Democracy (democracy and elections metaphors). These conceptual metaphors on the three target domains of Governace, Economic Inequality and Democracy, when compared across cultures could provide deep insight about peoples? perceptions regarding salient concepts. We note that Russian and Farsi performance is lower than that in English and Spanish. The size of balanced corpus and accuracy of lexical tools such as stemmers and morphological analyzers affect performance of our algorithm.  The Farsi balanced corpus is relatively small when compared to English balanced corpus. The smaller size affects computation of statistics such as Relation Frequency and subsequently the thresholds of RF*IDF scores. One improvement we are currently investigating is that the thresholds may be set specifically for a language.   	 ? ENGLISH	 ? SPANISH	 ? RUSSIAN	 ? FARSI	 ?#	 ?of	 ?Governance	 ?Conceptual	 ?Metaphors	 ? 27	 ? 7	 ? 8	 ? 7	 ?#	 ?of	 ?Economic	 ?Inequality	 ?Conceptual	 ?Metaphors	 ? 32	 ? 26	 ? 57	 ? 7	 ?#	 ?of	 ?Democracy	 ?	 ?Conceptual	 ?Metaphors	 ? 51	 ? 16	 ? 18	 ? 8	 ?Total	 ?#	 ?of	 ?	 ?Conceptual	 ?Metaphors	 ? 110	 ? 49	 ? 83	 ? 22	 ?Accuracy	 ?(%)	 ?	 ? 85%	 ? 76%	 ? 67%	 ? 62%	 ?Table 10. Number of conceptual metaphors discovered thus far and performance of our approach across four languages. 
217
5 Conclusion and Future Work In this article, we presented our approach towards automatic discovery of conceptual metaphors directly from linguistic evidence in a given language. We make use of corpora in two unique ways: the first is to discover prototypical seeds that form the basis of source domains and second is to create conceptual spaces that allow us to characterize the relations that operate within source domains automatically. In addition, our approach also allows us to distinguish between source domains as necessary. The validation results show that this is indeed a promising first attempt of tackling a challenging research problem.  We note that the assignment of source domains is limited to the set of 50 in our current prototype. This assumes a closed set of 50 source domains, whereas in reality, there might be many others that operate in the realm of metaphors we are investigating. Although additional source domains are continually being discovered in a bottom-up fashion by the linguistic metaphor extraction process, we cannot account for every source domain that may be relevant. One way of overcoming this limitation would be to define a source domain ?OTHER? that would be the all-encompassing domain accounting for any yet undiscovered domains. The details of how it would be represented are still under investigation.  Another potential improvement to our method is to experimentally refine the threshold score of RF*IDF. Through large scale validation experiments, we could learn the optimal thresholds automatically by using machine learning. 6 Acknowledgements This paper is based on work supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense US Army Research Laboratory contract number W911NF-12-C-0024. The U.S. Government is authorized to reproduce and distribute reprints for Governmental pur-poses notwithstanding any copyright annotation thereon.  Disclaimer: The views and conclusions con-tained herein are those of the authors and should not be interpreted as necessarily representing the of-ficial policies or endorsements, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Gov-ernment. References David W. Allbritton, Gail McKoon, and Richard J. Gerrig. 1995. Metaphor-based schemas and text Representa-tions: making connections through conceptual metaphors, Journal of Experimental Psychology: Learning, Memory, and Cognition, 21(3):612-625. Jonathan, Charteris-Black. 2002. Second language figurative proficiency: A comparative study of Malay and English. Applied Linguistics 23(1):104?133. George Aaron Broadwell, Umit Boz, Ignacio Cases, Tomek Strzalkowski, Laurie Feldman, Sarah Taylor, Samira Shaikh, Ting Liu and Kit Cho. 2013. Using Imageability and Topic Chaining to Locate Metaphors in Linguis-tic Corpora. In Proceedings of The 2013 International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction (SBP 2013), Washington D.C., USA. Jaime Carbonell. 1980. Metaphor: A key to extensible semantic analysis. In Proceedings of the 18th Annual Meeting on Association for Computational Linguistics. M. Coltheart. 1981. The MRC Psycholinguistic Database. Quarterly Journal of Experimental Psychology, 33A: 497-505. Davies, Mark. 2008-. The Corpus of Contemporary American English: 450 million words, 1990-present. Availa-ble online at http://corpus.byu.edu/coca/. Davies, Mark. 2002-. Corpus del Espa?ol: 100 million words, 1200s-1900s. Available online at http://www.corpusdelespanol.org. Dan, Fass. 1991. met*: A Method for Discriminating Metonymy and Metaphor by Computer. Computational Linguistics, 17:49-90 Jerome Feldman, and Srinivas Narayanan. 2004. Embodied meaning in a neural theory of language. Brain and Language, 89(2):385?392. 
218
Christiane D. Fellbaum. 1998. WordNet: An electronic lexical database (1st ed.). MIT Press. Matt Gedigian, John Bryant, Srini Narayanan and Branimir Ciric. 2006. Catching Metaphors. In Proceedings of the Third Workshop on Scalable Natural Language Understanding ScaNaLU 2006, pages 41?48. New York City: NY. Dirk Hovy, Shashank Shrivastava, Sujay Kumar Jauhar, Mrinmaya Sachan, Kartik Goyal, Huying Li, Whitney Sanders and Eduard Hovy. 2013. Identifying Metaphorical Word Use with Tree Kernels. In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL). Atlanta. Krippendorff, Klaus. 1970. Estimating the reliability, systematic error, and random error of interval da-ta. Educational and Psychological Measurement, 30 (1),61-70. Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. Hunting elusive metaphors using lexical resources. In Pro-ceedings of the Workshop on Computational Approaches to Figurative Language, pages 13?20. Rochester, NY. George Lakoff, and Mark Johnson. 1980. Metaphors we live by. University Of Chicago Press, Chicago, Illinois. George, Lakoff. 2001. Moral politics: what conservatives know that liberals don?t. University of Chicago Press, Chicago, Illinois. Liisa, Malkki.  1992. National geographic: The rooting of people and the territorialization of national identity among scholars and refugees. Society for Cultural Anthropology, 7(1):24?44. James Martin. 1988. A computational theory of metaphor. Ph.D. Dissertation. Musolff, Andreas. 2008. What can critical metaphor analysis add to the understanding of racist ideology? Recent studies of Hitler?s anti-semitic metaphors, critical approaches to discourse analysis across disciplines. Critical Approaches to Discourse Analysis Across Disciplines, 2(2):1?10. Kieran, O?Halloran. 2007. Critical discourse analysis and the corpus-informed interpretation of metaphor at the register level. Oxford University Press Farhad Oroumchian, Samira Tasharofi, Hadi Amiri, Hossein Hojjat, Fahime Raja. 2006. Creating a Feasible Corpus for Persian POS Tagging.Technical Report, no. TR3/06, University of Wollongong in Dubai. Samira Shaikh, Tomek Strzalkowski, Ting Liu, George Aaron Broadwell, Boris Yamrom, Sarah Taylor, Laurie Feldman, Kit Cho, Umit Boz, Ignacio Cases, Yuliya Peshkova and Ching-Sheng Lin. 2014. A Multi-Cultural Repository of Automatically Discovered Linguistic and Conceptual Metaphors. In Proceedings of the The 9th edition of the Language Resources and Evaluation Conference , Reykjavik, Iceland.  Ekaterina Shutova and Simone Teufel. 2010a. Metaphor corpus annotated for source - target domain mappings. In Proceedings of Language Resources and Evaluation Conference 2010. Malta. Ekaterina Shutova. 2010b. Models of metaphor in nlp. In Proceedings of the 48th Annual Meeting of the Associ-ation for Computational Linguistics, ACL ?10, pages 688?697. Ekaterina Shutova, Tim Van de Cruys, and Anna Korhonen. 2012. Unsupervised metaphor paraphrasing using a vector space model In Proceedings of COLING 2012, Mumbai, India Tomek Strzalkowski, George Aaron Broadwell, Sarah Taylor, Laurie Feldman, Boris Yamrom, Samira Shaikh, Ting Liu, Kit Cho, Umit Boz, Ignacio Cases and Kyle Elliott. 2013. Robust extraction of metaphor from novel data. In Proceedings of Workshop on Metaphor in NLP, NAACL. Atlanta. Tomek Strzalkowski, Samira Shaikh, Kit Cho, George Aaron Broadwell, Laurie Feldman, Sarah Taylor, Boris Yamrom, Ting Liu, Ignacio Cases, Yuliya Peshkova and Kyle Elliot. 2014. Computing Affect in Metaphors. In Proceedings of the Second Workshop on Metaphor in NLP, Baltimore Maryland.  Sarah Taylor, Laurie Beth Feldman, Kit Cho, Samira Shaikh, Ignacio Cases,Yuliya  Peshkiva, George Aaron Broadwell Ting Liu, Umit Boz, Kyle Elliott. Boris Yamrom, and Tomek Strzalkowski. 2014. Extracting Un-derstanding from automated metaphor identification: Contrasting Concepts of Poverty across Cultures and Languages. AHFE Conference, Cracow, Poland. Yorick, Wilks. 1975. Preference semantics. Formal Semantics of Natural Language, E. L. Keenan, Ed. Cam-bridge University Press, Cambridge, U.K., 329?348. Yorick Wilks, Lucian Galescu, James Allen, Adam Dalton. 2013. Automatic Metaphor Detection using Large-Scale Lexical Resources and Conventional Metaphor Extraction. In the Proceedings of the First Workshop on Metaphor in NLP, (NAACL). Atlanta.  
219
Wilson, M. D. 1988. The MRC Psycholinguistic Database: Machine Readable Dictionary, Version 2. Behav-ioural Research Methods, Instruments and Computers, 20(1): 6-11. 
220
