Proceedings of the TextInfer 2011 Workshop on Textual Entailment, EMNLP 2011, pages 40?49,
Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational Linguistics
Representing and resolving ambiguities
in ontology-based question answering
Christina Unger
Cognitive Interaction Technology ? Center of Excellence (CITEC),
Universit?t Bielefeld, Germany
{cunger|cimiano}@cit-ec.uni-bielefeld.de
Philipp Cimiano
Abstract
Ambiguities are ubiquitous in natural lan-
guage and pose a major challenge for the au-
tomatic interpretation of natural language ex-
pressions. In this paper we focus on differ-
ent types of lexical ambiguities that play a role
in the context of ontology-based question an-
swering, and explore strategies for capturing
and resolving them. We show that by employ-
ing underspecification techniques and by us-
ing ontological reasoning in order to filter out
inconsistent interpretations as early as possi-
ble, the overall number of interpretations can
be effectively reduced by 44 %.
1 Introduction
Ambiguities are ubiquitous in natural language.
They pose a key challenge for the automatic inter-
pretation of natural language expressions and have
been recognized as a central issue in question an-
swering (e.g. in (Burger et al, 2001)). In gen-
eral, ambiguities comprise all cases in which nat-
ural language expressions (simple or complex) can
have more than one meaning. These cases roughly
fall into two classes: They either concern structural
properties of an expression, e.g. different parses due
to alternative preposition or modifier attachments
and different quantifier scopings, or they concern al-
ternative meanings of lexical items. It is these lat-
ter ambiguities, ambiguities with respect to lexical
meaning, that we are interested in. More specifi-
cally, we will look at ambiguities in the context of
ontology-based interpretation of natural language.
The meaning of a natural language expression in
the context of ontology-based interpretation is the
ontology concept that this expression verbalizes. For
example, the expression city can refer to a class
geo:city (where geo is the namespace of the corre-
sponding ontology), and the expression inhabitants
can refer to a property geo:population. The cor-
respondence between natural language expressions
and ontology concepts need not be one-to-one. On
the one hand side, different natural language expres-
sions can refer to a single ontology concept, e.g.
flows through, crosses through and traverses could
be three ways of expressing an ontological property
geo:flowsThrough. On the other hand, one natu-
ral language expression can refer to different ontol-
ogy concepts. For example, the verb has is vague
with respect to the relation it expresses ? it could
map to geo:flowsThrough (in the case of rivers)
as well as geo:inState (in the case of cities). Such
mismatches between the linguistic meaning of an
expression, i.e. the user?s conceptual model, and the
conceptual model in the ontology give rise to a num-
ber of ambiguities. We will give a detailed overview
of those ambiguities in Section 3, after introducing
preliminaries in Section 2.
For a question answering system, there are mainly
two ways to resolve ambiguities: by interactive clar-
ification and by means of background knowledge
and the context with respect to which a question is
asked and answered. The former is, for example,
pursued by the question answering system FREyA
(Damljanovic et al, 2010). The latter is incorporated
in some recent work in machine learning. For exam-
ple, (Kate & Mooney, 2007) investigate the task of
40
learning a semantic parser from a corpus whith sen-
tences annotated with multiple, alternative interpre-
tations, and (Zettlemoyer & Collins, 2009) explore
an unsupervised algorithm for learning mappings
from natural language sentences to logical forms,
with context accounted for by hidden variables in a
perceptron.
In ontology-based question answering, context as
well as domain knowledge is provided by the ontol-
ogy. In this paper we explore how a given ontology
can be exploited for ambiguity resolution. We will
consider two strategies in Section 4. The first one
consists in simply enumerating all possible interpre-
tations. Since this is not efficient (and maybe not
even feasible), we will use underspecification tech-
niques for representing ambiguities in a much more
compact way and then present a strategy for resolv-
ing ambiguities by means of ontological reasoning,
so that the number of interpretations that have to be
considered in the end is relatively small and does not
comprise inconsistent and therefore undesired inter-
pretations. We will summarize with quantitative re-
sults in Section 5.
2 Preliminaries
All examples throughout the paper will be based on
Raymond Mooney?s GeoBase1 dataset and the DB-
pedia question set published in the context of the
1st Workshop on Question Answering Over Linked
Data (QALD-1)2. The former is a relatively small
and well-organized domain, while the latter is con-
siderably larger and much more heterogenous. It is
interesting to note that ontological ambiguituies turn
out to be very wide-spread even in a small and ho-
mogenuous domain like GeoBase (see Section 3 for
specific results).
For specifying entries of a grammar that a ques-
tion answering system might work with, we will use
the general and principled linguistic representations
that our question answering system Pythia3 (Unger
et al, 2010) relies on, as they are suitable for dealing
with a wide range of natural language phenomena.
Syntactic representations will be trees from Lexi-
calized Tree Adjoining Grammar (LTAG (Schabes,
1cs.utexas.edu/users/ml/nldata/geoquery.html
2http://www.sc.cit-ec.uni-bielefeld.de/qald-1
3http://www.sc.cit-ec.uni-bielefeld.de/pythia
1990)). The syntactic representation of a lexical
item is a tree constituting an extended projection of
that item, spanning all of its syntactic and semantic
arguments. Argument slots are nodes marked with a
down arrow (?), for which trees with the same root
category can be substituted. For example, the tree
for a transitive verb like borders looks as follows:
1. S
DP1 ? VP
V
borders
DP2 ?
The domain of the verb thus spans a whole sentence,
containing its two nominal arguments ? one in sub-
ject position and one in object position. The corre-
sponding nodes, DP1 and DP2, are slots for which
any DP-tree can be substituted. For example, substi-
tuting the two trees in 2 for subject and object DP,
respectively, yields the tree in 3.
2. (a) DP
DET
no
NP
state
(b) DP
Hawaii
3. S
DP
DET
no
NP
state
VP
V
borders
DP
Hawaii
As semantic representations we take DUDEs
(Cimiano, 2009), representations similar to struc-
tures from Underspecified Discourse Representation
Theory (UDRT (Reyle, 1993)), extended with some
additional information that allows for flexible mean-
ing composition in parallel to the construction of
LTAG trees. The DUDE for the verb to border, for
example, would be the following (in a slightly sim-
plified version):
geo:borders (x, y)
(DP1, x), (DP2, y)
41
It provides the predicate geo:borders correspond-
ing to the intended concept in the ontology. This
correspondence is ensured by using the vocabulary
of the ontology, i.e. by using the URI4 of the con-
cept instead of a more generic predicate. The pre-
fix geo specifies the namespace, in this case the one
of the GeoBase ontology. Furthermore, the seman-
tic representation contains information about which
substitution nodes in the syntactic structure provide
the semantic arguments x and y. That is, the seman-
tic referent provided by the meaning of the tree sub-
stituted for DP1 corresponds to the first argument x
of the semantic predicate, while the semantic refer-
ent provided by the meaning of the tree substituted
for DP2 corresponds to the second argument y. The
uppermost row of the box contains the referent that
is introduced by the expression. For example, the
DUDE for Hawaii (paired with the tree in 2b) would
be the following:
h
geo:name (h,?hawaii?)
It introduces a referent h which is related to the lit-
eral ?hawaii? by means of the relation geo:name.
As it does not have any arguments, the third row
is empty. The bottom-most row, empty in both
DUDEs, is for selectional restrictions of predicates;
we will see those in Section 4.
Parallel to substituting the DP-tree in 2b for the
DP1-slot in 1, the DUDE for Hawaii is combined
with the DUDE for borders, amounting to the satu-
ration of the argument (DP2, y) by unifying the vari-
ables h and y, yielding the following DUDE:
h
geo:borders (x, h)
geo:name (h,?hawaii?)
(DP1, x)
Substituting the subject argument no state involves
quantifier representations which we will gloss over
as they do not play a role in this paper. At this point
4URI stands for Uniform Resource Identifier. URIs uniquely
identify resources on the Web. For an overview, see, e.g.,
http://www.w3.org/Addressing/.
it suffices to say that we implement the treatment of
quantifier scope in UDRT without modifications.
Once a meaning representation for a question is
built, it is translated into a SPARQL query, which
can then be evaluated with respect to a given dataset.
Not a lot hinges on the exact choice of the for-
malisms; we could as well have chosen any other
syntactic and semantic formalism that allows the in-
corporation of underspecification mechanisms. The
same holds for the use of SPARQL as formal query
language. The reason for choosing SPARQL is that
it is the standard query language for the Seman-
tic Web5; we therefore feel safe in relying on the
reader?s familiarity with SPARQL and use SPARQL
queries without further explanation.
3 Types of ambiguities
As described in the introduction above, a central task
in ontology-based interpretation is the mapping of
a natural language expression to an ontology con-
cept. And this mapping gives rise to several different
cases of ambiguities.
First, ambiguities can arise due to homonymy of a
natural language expression, i.e. an expression that
has several lexical meanings, where each of these
meanings can be mapped to one ontology concept
unambiguously. The ambiguity is inherent to the ex-
pression and is independent of any domain or ontol-
ogy. This is what in linguistic contexts is called a
lexical ambiguity. A classical example is the noun
bank, which can mean a financial institution, a kind
of seating, the edge of a river, and a range of other
disjoint, non-overlapping alternatives. An example
in the geographical domain is New York. It can mean
either New York city, in this case it would be mapped
to the ontological entity geo:new york city, or
New York state, in this case it would be mapped to
the entity geo:new york. Ambiguous names are ac-
tually the only case of such ambiguities that occur in
the GeoBase dataset.
Another kind of ambiguities is due to mismatches
between a user?s concept of the meaning of an
expression and the modelling of this meaning
in the ontology. For example, if the ontology
modelling is more fine-grained than the meaning
5For the W3C reference, see
http://www.w3.org/TR/rdf-sparql-query/.
42
of a natural language expression, then an expres-
sion with one meaning can be mapped to several
ontology concepts. These concepts could differ
extensionally as well as intensionally. An example
is the above mentioned expression starring, that
an ontology engineer could want to comprise only
leading roles or also include supporting roles. If
he decides to model this distinction and introduces
two properties, then the ontological model is
more fine-grained than the meaning of the natural
language expression, which could be seen as corre-
sponding to the union of both ontology properties.
Another example is the expression inhabitants
in question 4, which can be mapped either to
<http://dbpedia.org/property/population>
or to <http://dbpedia.org/ontology/popula-
tionUrban>. For most cities, both alternatives give
a result, but they differ slightly, as one captures only
the core urban area while the other also includes
the outskirts. For some city, even only one of them
might be specified in the dataset.
4. Which cities have more than two million inhab-
itants?
Such ambiguities occur in larger datasets like DB-
pedia with a wide range of common nouns and tran-
sitive verbs. In the QALD-1 training questions for
DBpedia, for example, at least 16 % of the questions
contain expressions that do not have a unique onto-
logical correspondent.
Another source for ambiguities is the large num-
ber of vague and context-dependent expressions in
natural language. While it is not possible to pin-
point such expressions to a fully specified lexical
meaning, a question answering system needs to map
them to one (or more) specific concept(s) in the on-
tology. Often there are several mapping possibili-
ties, sometimes depending on the linguistic context
of the expression.
An example for context-dependent expressions
in the geographical domain is the adjective big: it
refers to size (of a city or a state) either with respect
to population or with respect to area. For the ques-
tion 5a, for example, two queries could be intended
? one refering to population and one refering to area.
They are given in 5b and 5c.
5. (a) What is the biggest city?
(b) SELECT ?s WHERE {
?s a geo:city .
?s geo:population ?p . }
ORDER BY DESC ?p LIMIT 1
(c) SELECT ?s WHERE {
?s a geo:city .
?s geo:area ?a . }
ORDER BY DESC ?a LIMIT 1
Without further clarification ? either by means of
a clarification dialog with the user (e.g. employed
by FREyA (Damljanovic et al, 2010)) or an ex-
plicit disambiguation as in What is the biggest city
by area? ? both interpretations are possible and ade-
quate. That is, the adjective big introduces two map-
ping alternatives that both lead to a consistent inter-
pretation.
A slightly different example are vague expres-
sions. Consider the questions 6a and 7a. The
verb has refers either to the object property
flowsThrough, when relating states and rivers, or
to the object property inState, when relating states
and cities. The corresponding queries are given in
6b and 7b.
6. (a) Which state has the most rivers?
(b) SELECT COUNT(?s) AS ?n WHERE {
?s a geo:state .
?r a geo:river .
?r geo:flowsThrough ?s. }
ORDER BY DESC ?n LIMIT 1
7. (a) Which state has the most cities?
(b) SELECT COUNT(?s) AS ?n WHERE {
?s a geo:state .
?c a geo:city .
?c geo:inState ?s. }
ORDER BY DESC ?n LIMIT 1
In contrast to the example of big above, these two
interpretations, flowsThrough and inState, are
exclusive alternatives: only one of them is admis-
sible, depending on the linguistic context. This
is due to the sortal restrictions of those proper-
ties: flowsThrough only allows rivers as domain,
whereas inState only allows cities as domain.
This kind of ambiguities are very frequent, as a
lot of user questions contain semantically light ex-
pressions, e.g. the copula verb be, the verb have,
43
and prepositions like of, in and with (cf. (Cimiano
& Minock, 2009)) ? expressions which are vague
and do not specify the exact relation they are de-
noting. In the 880 user questions that Mooney pro-
vides, there are 1278 occurences of the light expres-
sions is/are, has/have, with, in, and of, in addition
to 151 ocurrences of the context-dependent expres-
sions big, small, and major.
4 Capturing and resolving ambiguities
When constructing a semantic representation and
a formal query, all possible alternative meanings
have to be considered. We will look at two strate-
gies to do so: simply enumerating all interpretations
(constructing a different semantic representation and
query for every possible interpretation), and under-
specification (constructing only one underspecified
representation that subsumes all different interpreta-
tions).
4.1 Enumeration
Consider the example of a lexically ambiguous
question in 8a. It contains two ambiguous expres-
sions: New York can refer either to the city or the
state, and big can refer to size either with respect
to area or with respect to population. This leads to
four possible interpretations of the questions, given
in 8b?8e.
8. (a) How big is New York?
(b) SELECT ?a WHERE {
geo:new york city geo:area ?a . }
(c) SELECT ?p WHERE {
geo:new york city geo:population ?p.}
(d) SELECT ?a WHERE {
geo:new york geo:area ?a . }
(e) SELECT ?p WHERE {
geo:new york geo:population ?p . }
Since the question in 8a can indeed have all four in-
terpretations, all of them should be captured. The
enumeration strategy amounts to constructing all
four queries. In order to do so, we specify two
lexical entries for New York and two lexical en-
tries for the adjective big ? one for each reading.
For big, these two entries are given in 9 and 10.
The syntactic tree is the same for both, while the
semantic representations differ: one refers to the
property geo:area and one refers to the property
geo:population.
9. N
ADJ
big
N?
a
geo:area (x, a)
(N, x)
10. N
ADJ
big
N?
p
geo:population (x, p)
(N, x)
When parsing the question How big is New York,
both entries for big are found during lexical lookup,
and analogously two entries for New York are found.
The interpretation process will use all of them and
therefore construct four queries, 8b?8e.
Vague and context-dependent expressions can be
treated similarly. The verb to have, for example,
can map either to the property flowsThrough, in
the case of rivers, or to the property inState, in
the case of cities. Now we could simply spec-
ify two lexical entries to have ? one using the
meaning flowsThrough and one using the mean-
ing inState. However, contrary to lexical ambigu-
ities, these are not real alternatives in the sense that
both lead to consistent readings. The former is only
possible if the relevant argument is a river, the lat-
ter is only relevant if the relevant argument is a city.
So in order not to derive inconsistent interpretations,
we need to capture the sortal restrictions attached to
such exclusive alternatives. This will be discussed
in the next section.
4.2 Adding sortal restrictions
A straightforward way to capture ambiguities con-
sists in enumerating all possible interpretations
and thus in constructing all corresponding formal
queries. We did this by specifying a separate lex-
ical entry for every interpretation. The only diffi-
culty that arises is that we have to capture the sor-
tal restrictions that come with some natural language
expressions. In order to do so, we add sortal restric-
tions to our semantic representation format.
Sortal restrictions will be of the general form
variable?class. For example, the sortal restriction
that instances of the variable x must belong to the
class river in our domain would be represented as
x?geo:river. Such sortal restrictions are added as
44
a list to our DUDEs. For example, for the verb has
we specify two lexical entries. One maps has to
the property flowThrough, specifying the sortal re-
striction that the first argument of this property must
belong to the class river. This entry looks as fol-
lows:
S
DP1 ? VP
V
has
DP2 ?
geo:flowsThrough (y, x)
(DP1, x), (DP2, y)
x?geo:river
The other lexical entry for has consists of the
same syntactic tree and a semantic representation
that maps has to the property inState and contains
the restriction that the first argument of this property
must belong to the class city. It looks as follows:
S
DP1 ? VP
V
has
DP2 ?
geo:inState (y, x)
(DP1, x), (DP2, y)
x?geo:city
When a question containg the verb has, like 11a,
is parsed, both interpretations for has are found dur-
ing lexical lookup and two semantic representations
are constructed, both containing a sortal restriction.
When translating the semantic representations into a
formal query, the sortal restriction is simply added as
a condition. For 11a, the two corresponding queries
are given in 11b (mapping has to flowsThrough)
and 11c (mapping has inState). The contribution
of the sortal restriction is boxed.
11. (a) Which state has the most rivers?
(b) SELECT COUNT(?r) as ?c WHERE {
?s a geo:state .
?r a geo:river .
?r geo:flowsThrough ?s .
?r a geo:river . }
ORDER BY ?c DESC LIMIT 1
(c) SELECT COUNT(?r) as ?c WHERE {
?s a geo:state .
?r a geo:river .
?r geo:inState ?s .
?r a geo:city . }
ORDER BY ?c DESC LIMIT 1
In the first case, 11b, the sortal restriction adds a
redundant condition and will have no effect. We can
say that the sortal restriction is satisfied. In the sec-
ond case, in 11c, however, the sortal restriction adds
a condition that is inconsistent with the other condi-
tions, assuming that the classes river and city are
properly specified as disjoint. The query will there-
fore not yield any results, as no instantiiation of r
can be found that belongs to both classes. That is,
in the context of rivers only the interpretation using
flowsThrough leads to results.
Actually, the sortal restriction in 11c is al-
ready implicitly specified in the ontological relation
inState: there is no river that is related to a state
with this property. However, this is not necessar-
ily the case and there are indeed queries where the
sortal restriction has to be included explicitly. One
example is the interpretation of the adjective major
in noun phrases like major city and major state. Al-
though with respect to the geographical domain ma-
jor always expresses the property of having a pop-
ulation greater than a certain threshold, this thresh-
old differs for cities and states: major with respect
to cities is interpreted as having a population greater
than, say, 150 000, while major with respect to states
is interpreted as having a population greater than,
say, 10 000 000. Treating major as ambiguous be-
tween those two readings without specifying a sortal
restriction would lead to two readings for the noun
phrase major city, sketched in 12. Both would yield
non-empty results and there is no way to tell which
one is the correct one.
12. (a) SELECT ?c WHERE {
?c a geo:city .
?c geo:population ?p .
FILTER ( ?p > 150000 ) }
(b) SELECT ?c WHERE {
?c a geo:city .
?c geo:population ?p .
FILTER ( ?p > 10000000 ) }
Specifying sortal restrictions, on the other hand,
would add the boxed material in 13, thereby caus-
ing the wrong reading in 13b to return no results.
13. (a) SELECT ?c WHERE {
?c a geo:city .
?c geo:population ?p .
45
FILTER ( ?p > 150000 ) .
?c a geo:city . }
(b) SELECT ?c WHERE {
?c a geo:city .
?c geo:population ?p .
FILTER ( ?p > 10000000 ) .
?c a geo:state . }
The enumeration strategy thus relies on a conflict
that results in queries which return no result. Un-
wanted interpretations are thereby filtered out auto-
matically. But two problems arise here. The first
one is that we have no way to distinguish between
queries that return no result due to an inconsistency
introduced by a sortal restriction, and queries that
return no result, because there is none, as in the case
of Which states border Hawaii?. The second prob-
lem concerns the number of readings that are con-
structed. In view of the large number of ambiguities,
even in the restricted geographical domain we used,
user questions easily lead to 20 or 30 different pos-
sible interpretations. In cases in which several natu-
ral language terms can be mapped to many different
ontological concepts, this number rises. Enumerat-
ing all alternative interpretations is therefore not ef-
ficient. A more practical alternative is to construct
one underspecified representation instead and then
infer a specific interpretation in a given context. We
will explore this strategy in the next section.
4.3 Underspecification
In the following, we will explore a strategy for rep-
resenting and resolving ambiguities that uses under-
specification and ontological reasoning in order to
keep the number of constructed interpretations to a
minimum. For a general overview of underspecifica-
tion formalisms and their applicability to linguistic
phenomena see (Bunt, 2007).
In order not to construct a different query for
every interpretation, we do not any longer specify
separate lexical entries for each mapping but rather
combine them by using an underspecified semantic
representation. In the case of has, for example, we
do not specify two lexical entries ? one with a se-
mantic representation using flowsThrough and one
entry with a representation using inState ? but in-
stead specify only one lexical entry with a represen-
tation using a metavariable, and additionally specify
which properties this metavariable stands for under
which conditions.
So first we extend DUDEs such that they now can
contain metavariables, and instead of a list of sor-
tal restrictions contain a list of metavariable speci-
fications, i.e. possible instantiations of a metavari-
able given that certain sortal restrictions are satis-
fied, where sortal restrictions can concern any of the
property?s arguments. Metavariable specifications
take the following general form:
P ? p1 (x = class1, . . . , y = class2)
| p2 (x = class3, . . . , y = class4)
| . . .
| pn (x = classi, . . . , y = classj)
This expresses that some metavariable P stands for
a property p1 if the types of the arguments x, . . . , y
are equal to or a subset of class1,. . . ,class2, and
stands for some other property if the types of the
arguments correspond to some other classes. For
example, as interpretation of has, we would chose
a metavariable P with a specification stating that P
stands for the property flowsThrough if the first ar-
gument belongs to class river, and stands for the
property inState if the first argument belongs to
the class city. Thus, the lexical entry for has would
contain the following underspecified semantic repre-
sentation.
14. Lexical meaning of ?has?:
P (y, x)
(DP1, x), (DP2, y)
P ? geo:flowsThrough (y = geo:river)
| geo:inState (y = geo:city)
Now this underspecified semantic representation has
to be specified in order to lead to a SPARQL query
that can be evaluated w.r.t. the knowledge base.
That means, in the course of interpretation we need
to determine which class an instantiation of y be-
longs to and accordingly substitute P by the prop-
erty flowsThrough or inState. In the following
section, we sketch a way of exploiting the ontology
to this end.
46
4.4 Reducing alternatives with ontological
reasoning
In order to filter out interpretations that are inconsis-
tent as early as possible and thereby reduce the num-
ber of interpretations during the course of a deriva-
tion, we check whether the type information of a
variable that is unified is consistent with the sor-
tal restrictions connected to the metavariables. This
check is performed at every relevant step in a deriva-
tion, so that inconsistent readings are not allowed to
percolate and multiply. Let us demonstrate this strat-
egy by means of the example Which state has the
biggest city?.
In order to build the noun phrase the biggest
city, the meaning representation of the superlative
biggest, given in 15, is combined with that of the
noun city, which simply contributes the predication
geo:city (y), by means of unification.
15.
z
Q (y, z)
(N, y)
Q ? geo:area(y = geo:city unionsq geo:state)
| geo:population(y = geo:city unionsq geo:state)
The exact details of combining meaning represen-
tations do not matter here. What we want to fo-
cus on is the metavariable Q that biggest introduces.
When combining 15 with the meaning of city, we
can check whether the type information connected
to the unified referent y is compatible with the do-
main restrictions of Q?s interpretations. One way
to do this is by integrating an OWL reasoner and
checking the satisfiability of
geo:city u (geo:city unionsq geo:state)
(for both interpretations of Q, as the restrictions on
y are the same). Since this is indeed satisfiable,
both interpretations are possible, thus cannot be dis-
carded, and the resulting meaning representation of
the biggest city is the following:
y z
geo:city(y)
Q (y, z)
max(z)
Q ? geo:area(y = geo:city unionsq geo:state)
| geo:population(y = geo:city unionsq geo:state)
This is desired, as the ambiguity of biggest is a lexi-
cal ambiguity that could only be resolved by the user
specifying which reading s/he intended.
In a next step, the above representation is com-
bined with the semantic representation of the verb
has, given in 14. Now the type information of the
unified variable y has to be checked for compati-
bility with instantiations of an additional metavari-
able, P . The OWL reasoner would therefore have to
check the satisfiability of the following two expres-
sions:
16. (a) geo:city u geo:river
(b) geo:city u geo:city
While 16b succeeds trivially, 16a fails, assuming
that the two classes geo:river and geo:city are
specified as disjoint in the ontology. Therefore
the instantiation of P as geo:flowsThrough is
not consistent and can be discarded, leading to the
following combined meaning representation, where
P is replaced by its only remaining instantiation
geo:inState:
y z
geo:city(y)
geo:inState (y, x)
Q (y, z)
(DP1, x)
Q ? geo:area(y = geo:city unionsq geo:state)
| geo:population(y = geo:city unionsq geo:state)
Finally, this meaning representation is com-
bined with the meaning representation of which
state, which simply contributes the predication
geo:state (x). As the unified variable x does not
occur in any metavariable specification, nothing fur-
ther needs to be checked. The final meaning repre-
sentation thus leaves one metavariable with two pos-
sible instantiations and will lead to the following two
corresponding SPARQL queries:
47
17. (a) SELECT ?x WHERE {
?x a geo:city .
?y a geo:state.
?x geo:population ?z .
?x geo:inState ?y . }
ORDER BY DESC(?z) LIMIT 1
(b) SELECT ?x WHERE {
?x a geo:city .
?y a geo:state.
?x geo:area ?z .
?x geo:inState ?y . }
ORDER BY DESC(?z) LIMIT 1
Note that if the ambiguity of the metavariable
P were not resolved, we would have ended up
with four SPARQL queries, where two of them use
the relation geo:flowsThrough and therefore yield
empty results. So in this case, we reduced the num-
ber of constructed queries by half by discarding in-
consistent readings. We therefore solved the prob-
lems mentioned at the end of 4.2: The number of
constructed queries is reduced, and since we discard
inconsistent readings, null answers can only be due
to the lack of data in the knowledge base but not can-
not anymore be due to inconsistencies in the gener-
ated queries.
5 Implementation and results
In order to see that the possibility of reducing the
number of interpretations during a derivation does
not only exist in a small number of cases, we ap-
plied Pythia to Mooney?s 880 user questions, imple-
menting the underspecification strategy in 4.3 and
the reduction strategy in 4.4. Since Pythia does not
yet integrate a reasoner, it approximates satisfiabil-
ity checks by means of SPARQL queries. When-
ever meaning representations are combined, it ag-
gregates type information for the unified variable,
together with selectional information connected to
the occuring metavariables, and uses both to con-
struct a SPARQL query. This query is then evalu-
ated against the underlying knowledge base. If the
query returns results, the interpetations are taken to
be compatible, if it does not return results, the in-
terpretations are taken to be incompatible and the
according instantiation possibility of the metavari-
able is discarded. Note that those SPARQL queries
are only an approximation for the OWL expressions
used in 4.4. Furthermore, the results they return are
only an approximation of satisfiability, as the reason
for not returning results does not necessarily need to
be unsatisfiability of the construction but could also
be due the absence of data in the knowledge base.
In order to overcome these shortcomings, we plan to
integrate a full-fledged OWL reasoner in the future.
Out of the 880 user questions, 624 can be parsed
by Pythia (for an evaluation on this dataset and rea-
sons for failing with the remaining 256 questions,
see (Unger & Cimiano, 2011)). Implementing the
enumeration strategy, i.e. not using disambiguation
mechanisms, there was a total of 3180 constructed
queries. With a mechanism for removing scope am-
biguities by means of simulating a linear scope pref-
erence, a total of 2936 queries was built. Addi-
tionally using the underspecification and resolution
strategies described in the previous section, by ex-
ploiting the ontology with respect to which natural
language expressions are interpreted in order to dis-
card inconsistent interpretations as early as possible
in the course of a derivation, the number of total
queries was further reduced to 2100. This amounts
to a reduction of the overall number of queries by
44 %. The average and maximum number of queries
per question are summarized in the following table.
Avg. # queries Max. # queries
Enumeration 5.1 96
Linear scope 4.7 (-8%) 46 (-52%)
Reasoning 3.4 (-44%) 24 (-75%)
6 Conclusion
We investigated ambiguities arising from mis-
matches between a natural language expressions?
lexical meaning and its conceptual modelling in an
ontology. Employing ontological reasoning for dis-
ambiguation allowed us to significantly reduce the
number of constructed interpretations: the average
number of constructed queries per question can be
reduced by 44 %, the maximum number of queries
per question can be reduced even by 75 %.
48
References
Bunt, H.: Semantic Underspecification: Which Tech-
nique For What Purpose? In: Computing Meaning,
vol. 83, pp. 55?85. Springer Netherlands (2007)
Cimiano, P.: Flexible semantic composition with
DUDES. In: Proceedings of the 8th International Con-
ference on Computational Semantics (IWCS). Tilburg
(2009)
Unger, C., Hieber, F., Cimiano, P.: Generating LTAG
grammars from a lexicon-ontology interface. In: S.
Bangalore, R. Frank, and M. Romero (eds.): 10th In-
ternational Workshop on Tree Adjoining Grammars
and Related Formalisms (TAG+10), Yale University
(2010)
Unger, C., Cimiano, P.: Pythia: Compositional mean-
ing construction for ontology-based question answer-
ing on the Semantic Web. In: Proceedings of the 16th
International Conference on Applications of Natural
Language to Information Systems (NLDB) (2011)
Schabes, Y.: Mathematical and Computational Aspects
of Lexicalized Grammars. Ph. D. thesis, University of
Pennsylvania (1990)
Reyle, U.: Dealing with ambiguities by underspecifica-
tion: Construction, representation and deduction. Jour-
nal of Semantics 10, 123?179 (1993)
Kamp, H., Reyle, U.: From Discourse to Logic. Kluwer,
Dordrecht (1993)
Cimiano, P., Minock, M.: Natural Language Interfaces:
What?s the Problem? ? A Data-driven Quantitative
Analysis. In: Proceedings of the International Confer-
ence on Applications of Natural Language to Informa-
tion Systems (NLDB), pp. 192?206 (2009)
Damljanovic, D., Agatonovic, M., Cunningham, H.:
Natural Language Interfaces to Ontologies: Combin-
ing Syntactic Analysis and Ontology-based Lookup
through the User Interaction. In: Proceedings of the
7th Extended Semantic Web Conference, Springer
Verlag (2010)
Zettlemoyer, L., Collins, M.: Learning Context-
dependent Mappings from Sentences to Logical Form.
In: Proceedings of the Joint Conference of the As-
sociation for Computational Linguistics and Interna-
tional Joint Conference on Natural Language Process-
ing (ACL-IJCNLP), pp. 976?984 (2009)
Burger, J., Cardie, C., Chaudhri, V., Gaizauskas,
R., Israel, D., Jacquemin, C., Lin, C.-Y., Maio-
rano, S., Miller, G., Moldovan, D., Ogden,
B., Prager, J., Riloff, E., Singhal, A., Shrihari,
R., Strzalkowski, T., Voorhees, E., Weischedel,
R.: Issues, tasks, and program structures to
roadmap research in question & answering (Q & A).
http://www-nlpir.nist.gov/projects/duc/
papers/qa.Roadmap-paper v2.doc (2001)
Kate, R., Mooney, R.: Learning Language Semantics
from Ambiguous Supervision. In: Proceedings of the
22nd Conference on Artificial Intelligence (AAAI-07),
pp. 895?900 (2007)
49
NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 1?2,
Montre?al, Canada, June 7, 2012. c?2012 Association for Computational Linguistics
Up from Limited Dialog Systems!
Giuseppe Riccardi
University of Trento
via Sommarive, 14
38050, Trento, Italy
riccardi@disi.unitn.it
Philipp Cimiano
Bielefeld University
Universita?tsstra?e 21?23
33615, Bielefeld, Germany
cimiano@cit-ec.uni-bielefeld.de
Alexandros Potamianos
Technical University of Crete
73100, Chania
Crete, Greece
potam@telecom.tuc.gr
Christina Unger
Bielefeld University
Universita?tsstra?e 21?23
33615, Bielefeld, Germany
cunger@cit-ec.uni-bielefeld.de
Abstract
In the last two decades, information-seeking
spoken dialog systems (SDS) have moved
from research prototypes to real-life commer-
cial applications. Still, dialog systems are lim-
ited by the scale, complexity of the task and
coverage of knowledge required by problem-
solving machines or mobile personal assis-
tants. Future spoken interaction are required
to be multilingual, understand and act on large
scale knowledge bases in all its forms (from
structured to unstructured). The Web re-
search community have striven to build large
scale and open multilingual resources (e.g.
Wikipedia) and knowledge bases (e.g. Yago).
We argue that a) it is crucial to leverage
this massive amount of Web lightly structured
knowledge and b) the scale issue can be ad-
dressed collaboratively and design open stan-
dards to make tools and resources available to
the whole speech and language community.
1 Introduction
In the last two decades, interactive spoken dialog
systems (SDS) have moved from research proto-
types to real-life commercial applications (Tur and
De Mori, 2011). Generally, SDS are built for a
specific task (e.g. call routing) with ad-hoc lim-
ited knowledge base and for a predefined target lan-
guage. However, one major limitation in commer-
cial SDS prototyping is that they are not easily and
quickly extensible and portable to new domains or
languages. Such porting requirements range from
defining (or extending) a domain ontology to hand-
crafting a new grammar or training stochastic mod-
els for speech recognition and understanding. These
are the research and engineering goals motivating
the PortDial project whose objectives include the
engagement of the whole technical community. In
the PortDial project we would like to engage re-
searchers in building resources that may be gener-
ated via top-down processes (grammars), bottom-up
processes (statistical models) or via a fusion of both.
In this position paper we want to address the crit-
ical limitations of SDS systems: a) poor ability to
cover the knowledge space and its interface to the
SDS components (speech recognition, language un-
derstanding and dialog manager) and b) collabora-
tively design open standards to make tools and re-
sources available to the whole speech and language
community.
2 Exploiting top-down knowledge
There are at least three main kinds of structured
knowledge sources that SDS modules may ex-
ploit: ontologies, grammars, and lexica. Ontolo-
gies explicitly model background knowledge about
a certain domain. In the last years, many free
and open collaboratively created resources have
emerged, including large multi-lingual corpora such
as Wikipedia, and broad-coverage ontologies, e.g.
as part of the Linked Data Cloud (Bizer et al, 2009),
either created manually or extracted automatically
from existing data (such as DBpedia or Yago). How-
ever, while also lexica such as Wiktionary are avail-
able today on the Web, ontologies typically lack in-
formation about linguistic realization. For this rea-
son, ontologies available on the Web are not di-
rectly exploitable by dialog systems. Linguistic in-
1
formation is commonly captured in grammars, that
are either hand-crafted or created by means of ma-
chine learning techniques. In order to be able to
generate high-quality grammars with as little man-
ual effort as possible, we aim at (semi) automat-
ing the knowledge-based generation of lexica and
grammars. To achieve this, it is crucial to lever-
age Web resources for enriching ontologies with
lexical and linguistic information, i.e. informa-
tion about how ontological concepts are lexicalized
in different languages, capturing in particular lex-
ical and syntactic variation (Unger et al, 2010).
This knowledge-centered grammar generation pro-
cess may be merged with methods for automatically
inferring structure from lightly annotated corpus, in-
cluding data harvested from the Web, in a bottom-
up fashion (Tur and De Mori, 2011). For a dialog
system to be able to exploit ontologies, lexica and
grammars, these three resources need to be tightly
aligned, i.e. they need to share domain-relevant vo-
cabulary. For this alignment, we propose to build on
Semantic Web standards, mainly in order to support
the incorporation of already existing data, to share
resources for SDS engineering, and facilitate collab-
orative knowledge engineering. From a larger per-
spective, such an approach has the potential of cre-
ating SDS resources (ontologies, lexica and gram-
mars) that are strongly aligned with each other as
well as with other resources available on the Web,
thus fostering the creation of an eco-system of linked
resources that can be reused to facilitate the process
of engineering and porting a dialog system to new
domains and languages.
3 Collaboratively building and sharing
knowledge
Today the lack of reusable linguistic resources and
annotated data hinders the rapid development of
spoken dialog systems in industry and academia
alike. Despite progress in standardization of the
format of SDS grammars and semantic represen-
tations, the data proper has to be hand-crafted for
new applications and languages with little or no au-
tomation available. We argue above that language
engineering technology is now mature to help cre-
ate such linguistic resources automatically or semi-
automatically using data that is either harvested
from the web or via community crowdsourcing us-
ing the ?collective wisdom of expert crowds?. Al-
though providing linguistic resources and tools for
cost-effective SDS development is important and
relevant, a data pool that is not openly sharable and
continuously enriched fails its purpose. It is thus im-
portant to guarantee the sustainability of the linguis-
tic SDS resources engineered via a community that
both uses and actively develops the data pool. To-
wards this end, we envision both a free and premium
data exchange targeting non-commercial users that
can maintain and enrich the free version of the data
pool, and commercial speech services developers
that can contribute to the premium data pool via
an electronic marketplace. This is the model we
are launching within the EC-funded PortDial project
and aiming at involving the research community at
large and existing communities for sharing linguistic
resources, such as METANET and METASHARE1.
We believe that the creation of sharable SDS data
and linguistic resources for both academic and com-
mercial use will lead to the democratization of spo-
ken dialog systems development, reduce the barrier
to entry for new developers, as well as lead to im-
proved technologies for authoring speech services.
References
C. Bizer, T. Heath, and T. Berners-Lee. 2009. Linked
data-the story so far. International Journal on Seman-
tic Web and Information Systems, 14:9.
G. Tur and R. De Mori, editors. 2011. Spoken Language
Understanding: Systems for Extracting Semantic In-
formation from Speech. Wiley.
Christina Unger, Felix Hieber, and Philipp Cimiano.
2010. Generating LTAG grammars from a lexicon-
ontology interface. In Srinivas Bangalore, Robert
Frank, and Maribel Romero, editors, Proceedings of
the 10th International Workshop on Tree Adjoining
Grammars and Related Formalisms (TAG+10), pages
61?68, 06/2010.
1http://www.meta-net.eu/meta-share
2
Proceedings of the 14th European Workshop on Natural Language Generation, pages 10?19,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Exploiting ontology lexica for
generating natural language texts from RDF data
Philipp Cimiano, Janna Lu?ker, David Nagel, Christina Unger
Semantic Computing Group
Cognitive Interaction Technology ? Center of Excellence (CITEC),
Bielefeld University, Germany
Abstract
The increasing amount of machine-
readable data available in the context
of the Semantic Web creates a need
for methods that transform such data
into human-comprehensible text. In
this paper we develop and evaluate a
Natural Language Generation (NLG)
system that converts RDF data into
natural language text based on an on-
tology and an associated ontology lex-
icon. While it follows a classical NLG
pipeline, it diverges from most cur-
rent NLG systems in that it exploits
an ontology lexicon in order to capture
context-specific lexicalisations of ontol-
ogy concepts, and combines the use of
such a lexicon with the choice of lexical
items and syntactic structures based on
statistical information extracted from a
domain-specific corpus. We apply the
developed approach to the cooking do-
main, providing both an ontology and
an ontology lexicon in lemon format.
Finally, we evaluate fluency and ade-
quacy of the generated recipes with re-
spect to two target audiences: cooking
novices and advanced cooks.
1 Introduction
The goal of the Semantic Web is to en-
rich the current web by a layer of machine-
readable and machine-understandable con-
tent (Berners-Lee et al, 2001). In recent years,
the growth of data published on the web ac-
cording to Semantic Web formalisms and data
models (e.g. RDF(S) and OWL) has been
exponential, leading to more than 30 billion
RDF triples1 available as part of the Linked
1http://www4.wiwiss.fu-berlin.de/lodcloud/
state/
Open Data cloud, which contains a wide range
of factual knowledge that is very interesting
to many applications and for many purposes.
However, due to the fact that it is available as
RDF, it is not directly accessible to humans.
Thus, natural language generation from RDF
data has recently become an important topic
for research, leading to the development of var-
ious systems generating natural language text
from knowledge bases (Bouayad-Agha et al,
2012a; Mellish and Sun, 2006; Sun and Mel-
lish, 2007; Wilcock and Jokinen, 2003) as well
as corresponding shared tasks (Banik et al,
2012; Bouayad-Agha et al, 2012b).
Natural language generation (NLG) from
knowledge bases requires knowledge about
how the concepts in the underlying ontology?
individuals, classes and relations?are realised
linguistically. For this purpose, lemon, a lex-
icon model for ontologies, has been devel-
oped (McCrae et al, 2011). One of the use
cases of lemon is to support natural language
generation systems that take as input a knowl-
edge base structured with respect to a given
ontology. In this paper, we present a system
that relies on lemon lexica for selecting suit-
able lexicalisations of a given concept, showing
how ontology lexica can be exploited in a stan-
dard generation architecture.
We apply our system to the domain of
cooking, generating natural language texts for
recipes modeled as RDF data based on a cook-
ing ontology. Our system relies on a large text
corpus of cooking recipes that is used to ex-
tract frequency information for single terms
and n-grams as well as syntactic trees, which
are then used in the selection process for lex-
icalisation and surface realisation. Addition-
ally, we provide a manually created lemon lex-
icon for the underlying ontology that was en-
riched with inflectional variants derived from
10
Wiktionary. The lexicon also includes con-
textual information regarding which lexicalisa-
tions to prefer depending on the target group,
and thereby allows our system to personalize
the output to different groups of users. We
demonstrate the flexibility of our system by
showing that it can be easily tuned to gen-
erate recipe descriptions both for novices and
for advanced cooks and that this adaptation is
clearly recognized by users.
The remainder of this paper is structured
as follows. In Section 2 we describe the re-
sources we created and employed, in particular
a domain ontology, a corresponding ontology
lexicon enriching ontology concepts with lexi-
cal information, and a parsed domain corpus.
In Section 3 we describe the architecture of
the system, in particular the use of a corpus
for selecting appropriate syntactic structures
and surface realisations of concepts. Then we
present the results of an extensive user study
in Section 4, compare our approach to related
work in Section 5 and finally give an outlook
on future work in Section 6.
2 Resources
2.1 Domain ontology and lexicon
In order to be able to model cooking recipes
as RDF data, we created a domain ontology
in which recipes are modeled comprising the
following information (for a similar modeling
see (Ribeiro et al, 2006)):
? An indication of the number of people
that it serves.
? A set of ingredients used in the recipe.
? An ordered list of steps involving a certain
action (e.g. cutting) on a set of ingredi-
ents. Each action in turn allows one or
many modifiers (e.g. to indicate cutting
granularity).
? Interim ingredients that are produced as
the result of some step and can be reused
later in another step.
An excerpt from the RDF recipe for mar-
ble cake is given in Figure 1. It shows two
steps, one for mixing the ingredients butter,
flour and egg, using a bowl, thereby creating
1 :Marmorkuchen a :Nachspeise;
2
3 :hasStep [ a :Step ;
4 :hasStepNumber 7??xsd:integer ;
5 :hasAction action:mischen ;
6 :hasMixType prop:vermengen ;
7 :hasIngredient
8 [ a ingredient:Butter ;
9 :hasAmount amount:Gramm ;
10 :hasValue "300" ],
11 [ a ingredient:Mehl ;
12 :hasAmount amount:Gramm ;
13 :hasValue "375" ],
14 [ a ingredient:Ei ;
15 :hasAmount amount:Stueck
16 :hasValue "5" ] ;
17 :hasIndirectIngredient
18 tool:Schuessel ;
19 :creates tool:Marmorkuchen_Interim_1
20 ] ;
21
22 :hasStep [ a :Step ;
23 :hasStepNumber 8??xsd:integer ;
24 :hasAction action:backen ;
25 :isPassive "true "??xsd:boolean ;
26 :hasTimeUnit prop:Minute ;
27 :hasTimeValue 45.0?? xsd:double ;
28 :hasIngredient
29 tool:Marmorkuchen_Interim_1 ;
30 :hasIndirectIngredient
31 tool:Backofen
32 ] .
Figure 1: An excerpt from the RDF recipe for
marble cake.
the dough as an interim object, and a subse-
quent one in which this interim object is being
baked in the oven for 45 minutes.
In general, each step comprises:
? A step number indicating the order in a
list of steps.
? An associated action indicating the type
of action performed in the step, e.g. to
fold in.
? One or more ingredients used in the ac-
tion. This is either an ingredient from the
ingredient list of the recipe, or an object
that was created as a result of some other
step.
? A passivity flag indicating whether a step
does not require an active action by the
cook, e.g. Let the cake cool for 1 hour.
? Further modifiers such as mixType indi-
cating the way in which the ingredients
11
are mixed (e.g. beating or folding), tem-
poral modifiers specifying a time unit and
time value (e.g. 45 minutes). These mod-
ifiers later affect the grouping of steps and
their lexicalisation.
? A flag indicating whether this is a key step
within the recipe, for example a step that
requires particular care and thus should
get emphasis in the verbalization, like
Quickly fry the meat!
Overall, the ontology comprises 54 different
action types that we used to manually model
37 recipes. Further, we created a lemon lexi-
con specifying how the different actions and in-
gredients specified in the ontology are verbal-
ized in German. In total the lexicon contains
1,530 lexical entries, on average 1.13 lexical
variants for each ingredient and 1.96 variants
for each action.
Figure 2 gives an example entry for the
verb schneiden (to cut), specifying its part
of speech, two form variants, the infinitive
and the past participle, and a semantic ref-
erence to the ontology action of cutting. Fig-
ure 3 gives an excerpt from the lexical entry
for tranchieren (to carve), which refers to the
same cutting action but is restricted to cases
where the ingredient is of type meat, modelled
using a logical condition that can be issued
as a query to the knowledge base. This verb
would therefore only be used in the context of
technical registers, i.e. with advanced cooks
as target group.
After having manually created lexical en-
tries with their base forms, we automatically
enrich them with inflectional forms extracted
from Wiktionary, as already indicated in Fig-
ure 2.
The ontology, the RDF recipes as well
as the ontology lexicon can be accessed
at http://www.sc.cit-ec.uni-bielefeld.
de/natural-language-generation.
Although the manual creation of lemon lex-
ica is feasible for small domains (and sup-
ported by tools such as lemon source (McCrae
et al, 2012)), it does not scale to larger do-
mains without a significant amount of effort.
Therefore corpus-based methods for the semi-
automatic creation of ontology lexica are cur-
rently developed, see (Walter et al, 2013).
1 :schneiden a lemon:LexicalEntry ;
2 lexinfo:partOfSpeech lexinfo:verb ;
3
4 lemon:canonicalForm [
5 lemon:writtenRep "schneiden"@de ;
6 lexinfo:tense lexinfo:present ;
7 lexinfo:mood lexinfo:infinitive
8 ];
9 lemon:otherForm [
10 lemon:writtenRep "geschnitten"@de ;
11 lexinfo:verbFormMood
12 lexinfo:participle ;
13 lexinfo:aspect lexinfo:perfective
14 ];
15
16 lemon:sense
17 [ lemon:reference action:schneiden ].
Figure 2: Lexical entry for the verb schneiden,
denoting a cutting action.
1 :tranchieren a lemon:LexicalEntry ;
2 lexinfo:partOfSpeech lexinfo:verb ;
3
4 lemon:canonicalForm [
5 lemon:writtenRep "tranchieren"@de ];
6
7 lemon:sense
8 [ lemon:reference action:schneiden;
9 lemon:condition [ lemon:value
10 "exists ?x :
11 :hasIngredient (?x,?y),
12 :Step(?x),
13 ingredient:Fleisch (?y)" ];
14 lemon:context
15 isocat:technicalRegister ] .
Figure 3: Lexical entry for the verb
tranchieren, denoting a cutting action re-
stricted to meat and marked as a technical
term.
2.2 Domain corpus
In order to build a domain corpus, we crawled
the recipe collection website http://www.
chefkoch.de, which at that point contained
more than 215 000 recipes with a total amount
of 1.9 million sentences. We extracted the
recipe text as well as the list of ingredients and
the specified level of difficulty ? easy, normal
and complicated.
The extracted text was tokenized using the
unsupervised method described by Schmid
(Schmid, 2000), and for each recipe an n-gram
index (considering 2, 3 and 4-grams) for both
the recipe text and the ingredient list was con-
structed. Furthermore, 65 000 sentences were
parsed using the Stanford parser, trained on
12
the German TIGER corpus, also enriching the
training data of the parser with fragments de-
rived from the ontology lexicon in order to en-
sure that the lexical entries in the ontology
lexicon are actually covered. This resulted in
20 000 different phrase structure trees where
the leafs were replaced by lists of all terms oc-
curring at that position in the parse tree. Both
trees and leaf terms were stored together with
the number of their occurrences. Leaf terms
were additionally annotated with lexical senses
by comparing them to the already created lex-
ical entries and thus connecting them to on-
tology concepts.
3 System architecture
Our system implements a classical NLG
pipeline comprising the following three
steps (Reiter and Dale, 2000):
? Document planning
? Microplanning
? Surface realisation
Document planning in our case is quite
straightforward as the recipes already com-
prise exactly the information that needs to be
verbalized. In the following we present the two
remaining steps in more detail, followed by a
brief description of how the text generation is
parametrized with respect to the target group
(novices or experts).
3.1 Microplanning
Following Reiter & Dale (Reiter and Dale,
2000), microplanning comprises three steps:
aggregation, referring expression generation,
and lexicalisation.
Aggregation Aggregation serves to collapse
information using grouping rules in order to
avoid redundancies and repetitions. In our
case, the main goal of aggregation is to group
steps of recipes, deciding which steps should
be verbalized within the same sentences and
which ones should be separated, based on the
following hand-crafted rules:
? Steps are grouped if
? they have the same step number, or
? the actions associated with the steps
are the same, or
? the same ingredient is processed in
subsequent actions, e.g. peeling and
chopping onions.
? Steps that are marked as important in the
ontology can only be grouped with other
important steps.
? If the grouping of steps would result in too
many ingredients to still form a readable
sentence, the steps are not grouped. Cur-
rently we consider more than six ingredi-
ents to be too many, as there are hardly
any trees in the corpus that could gener-
ate corresponding sentences.
? If there is a big enough time difference
between two steps, as e.g. between baking
a cake for 60 minutes and then decorating
it, the steps are not grouped.
Each of these rules contributes to a numeri-
cal value indicating the probability with which
steps will be grouped. The use of the rules is
also controlled by a system parameter ?length
that can be set to a value between 0 and 1,
where 0 gives a strong preference to short sen-
tences, while 1 always favors longer sentences.
Referring expression generation The
generation of referring expressions is also rule-
based and mainly concerns ingredients, as ac-
tions are commonly verbalized as verbs and
tools (such as bowls and the oven) usually
do not re-occur often enough. In deciding
whether to generate a pronoun, the following
rule is used: A re-occurring ingredient is re-
placed by a pronoun if there is no other ingre-
dient mentioned in the previous sentence that
has the same number and gender. A system
parameter ?pronoun can be set to determine the
relative frequency of pronouns to be generated.
If an ingredient is not replaced by a pro-
noun, then one of the following expressions is
generated:
? A full noun phrase based on the verbal-
ization given in the ontology lexicon, e.g.
two eggs.
? A definite expression describing a super-
category of the given ingredient. The
super-category is extracted from the on-
tology and its verbalization from the on-
13
tology lexicon. For instance, if the ingre-
dient in question is pork, the expression
meat would be generated.
? A zero anaphora, i.e. an empty referring
expression, as in Bake for 60 minutes or
Simmer until done.
The use of those variants is regulated by a sys-
tem parameter ?pronoun, where a high value
forces the use of abstract expressions and zero
anaphora, while a low value prefers the use
of exact ingredient names. In future work
the decision of which referring expression to
use should be decided on the basis of gen-
eral principles, such as uniqueness of the refer-
ent, avoidance of unnecessary and inappropri-
ate modifiers, brevity, and preference for sim-
ple lexical items, see, e.g., (Reiter and Dale,
1992).
An exception to the above rules are interim
ingredients, whose realisation is determined as
follows. If there is a lexical entry for the in-
terim, it is used for verbalization. If there is
no lexical entry, then the name of the main
ingredient used in the creation of the interim
is used. Furthermore, we define and exploit
manually specified meaning postulates to cre-
ate names for specific, common interims. For
example dough is used if the interim is gener-
ated from flour and at least one of the ingre-
dients butter, sugar, egg or backing powder.
Lexicalisation In order to lexicalise actions
and ingredients, the ontology lexicon is con-
sulted. Especially for actions, the lexicon con-
tains several lexical variants, usually accompa-
nied by a restriction that specifies the context
in which the lexicalisation is appropriate. For
example the action to cut can be lexicalised
in German as hacken (to chop) if the specified
granularity is rough, as bla?ttrig schneiden (to
thinly slice) if the specified granularity is fine,
or tranchieren (to carve) in case the ingredient
is of type meat.
The conditions under which a lexicalisa-
tion can be used felicitously are given in the
lexicon as logical expressions, as exemplified
in Figure 3 above, which are translated into
SPARQL queries that can be used to check
whether the condition is satisfied with respect
to the recipe database.
In addition, we rely on statistics derived
from our domain corpus in order to choose a
lexicalisation in case the conditions of more
than one lexical variant are fulfilled, by pre-
ferring terms and term combinations with a
higher frequency in the domain corpus. Again,
the system implements a parameter, ?variance,
that regulates how much overall lexical vari-
ability is desired. This, however, should be
used with care, as choosing variants that are
less frequent in the corpus could easily lead to
strange or inappropriate verbalizations.
3.2 Surface realisation
The input to the surface realisation compo-
nent is a list of concepts (spanning one or more
recipe steps) together with appropriate lexical-
isations as selected by the lexicalisation com-
ponent. The task of the surface realiser then
is to find an appropriate syntactic tree from
the parsed corpus that can be used to realise
the involved concepts. An example of such a
parse tree with annotated leaf probabilities is
shown in Figure 4.
All trees retrieved from the index are
weighted to identify the best fitting tree com-
bining the following measures: i) the normal-
ized probability of the syntax tree in the do-
main corpus, ii) a comparison of the part-of-
speech tag, synonyms and the lexical sense of a
given lexicalisation with those of the terms in
the retrieved tree, iii) the node distances of re-
lated words inside each tree, and iv) an n-gram
score for each resulting sentence. These scores
are added up and weighted w.r.t. the size of
n, such that, for example, 4-grams have more
influence on the score than 3-grams. Also,
sentences with unbalanced measure, i.e. that
score very well w.r.t. one measure but very
poorly w.r.t. another one, are penalized.
3.3 Personalization
On the basis of conditions on the context of use
provided in the ontology lexicon, it is possible
to distinguish lexicalisations that are suitable
for experts from lexical variants that are suit-
able for novices. Thus, texts can be generated
either containing a high amount of technical
terms, in case the user has a high proficiency
level, or avoiding technical terms at all, in case
the user is a novice. Furthermore, the com-
plexity of texts can be varied by adjusting the
14
S (0.005)
VP
VVINF
schlagen (0.33)
wu?rfeln (0.22)
stellen (0.13)
. . .
ADJD
steif (0.32)
fein (0.18)
kalt (0.08)
. . .
NP
NN
Sahne (0.20)
Eiwei? (0.09)
Zwiebel (0.07)
. . .
ART
Die (0.60)
Das (0.18)
Den (0.21)
. . .
Figure 4: Example of a parse tree extracted
from the corpus, annotated with leaf proba-
bilities
sentence length and the number of adjectives
used. We used this as an additional parameter
?context for tailoring texts to their target group,
preferring complex structures in expert texts
and simple structures in texts for novices. The
influence of this parameter is tested as part of
the user study described in the next section.
Personalization thus has been implemented
at the level of microplanning. In addition,
personalization is possible on the level of text
planning. For example, experts often require
less detailed descriptions of actions, such that
they can be summarized in one step, while
they need to be broken down into several steps
for beginners. This will be subject of future
work.
4 Evaluation
The system was evaluated in an online study
with 93 participants?mainly students re-
cruited via email or Facebook. The major-
ity of the participants (70%) were between 18
and 34 years old; the native tongue of almost
all participants (95%) was German. About
half of the participants regarded themselves as
novices, while the other half regarded them-
selves as advanced cooks.
For each participant, 20 recipes were ran-
domly selected and split into two groups. For
ten recipes, test subjects were asked to rate
the fluency and adequacy of the automatically
generated text along the categories very good,
good, sufficient and insufficient. The other ten
recipes were used to compare the effect of pa-
rameters of the generation system and thus
were presented in two different versions, vary-
ing the sentence length and complexity as well
as the level of proficiency. Participants were
asked to rate texts as being appropriate for
novices or for advanced cooks.
The parameters that were varied in our ex-
perimental setting are the following:
? ?context: The context of the used terms, in
particular novice or advanced.
? ?pronoun: Amount of proper nouns, where
a high value prefers pronouns over proper
nouns, while a low value generates only
proper nouns.
? ?variance: Amount of repetitions, where
low values lead to always using the same
term, whereas high values lead to fewer
repetitions.
? ?length: Length of the created sentences,
where a low value creates short sentences,
and high values merge short sentences
into longer ones.
The values of these parameters that were
used in the different configurations are sum-
marized in Table 1. The parameter ?pronoun is
not varied but set to a fixed value that yields
a satisfactory generation of referring expres-
sions, as texts with smaller or higher values
tend to sound artificial or incomprehensible.
?context ?pronoun ?variance ?length
Standard novice 0.5 0.5 0.5
Novice vs novice 0.5 0.5 0.3
Advanced advanced 0.5 0.5 0.7
Simple vs novice 0.5 0.0 0.3
Complex novice 0.5 1.0 0.7
Table 1: The used parameter sets
Fluency and adequacy of the generated
texts Each participant was asked to rate flu-
ency and adequacy of ten automatically gen-
erated texts. The results are given in Figures
5 and 6. The fluency of the majority of gen-
erated texts (85.8%) were perceived as very
good or good, whereas only 1% of the generated
texts were rated as insufficient. Similarly, the
adequacy of 92.5% of the generated texts were
rated as very good or good, and again only 1%
of the generated texts were rated as insuffi-
cient. There was no significant difference be-
tween judgments of novices and experts; nei-
ther did the category of the recipe (main or
15
side dish, dessert, etc.) have any influence.
Overall, these results clearly show that the
quality of the texts generated by our system
is high.
Figure 5: Results for text fluency
Figure 6: Results for text adequacy
Error analysis The most frequent errors
found in the generated texts can be grouped
into the following categories:
? Content (39.4%): Errors in document
planning (e.g. due to the ontology miss-
ing details about tools, such as for cut-
ting cookies, or the recipe missing infor-
mation about the amount of ingredients)
or aggregation (e.g. sentences with highly
related content were not aggregated), as
well as sentence repetitions.
? Language (29.4%): Errors in the re-
ferring expression generation or lexicali-
sation steps (e.g. wrong use of function
words like as well) and grammar errors
(e.g. wrong use of definite or indefinite
determiners).
? Other (31.3%): Some users specified
that they would prefer another ordering
of the involved steps, or that they lack
knowledge of particular terms. Also short
sentences with exclamation marks are of-
ten perceived as impolite.
Influence of parameter settings We set
up the following hypotheses, validating them
by means of a ?2-test by comparing answers
across two conditions corresponding to differ-
ent parameter settings. We regarded a p-value
of 0.05 as sufficient to reject the corresponding
null hypothesis.
H1 Users prefer longer sentences: Re-
jecting the null hypothesis that users rate
texts with longer sentences and texts with
shorter sentences in the same way (p-
value: 3 ? 10?5).
H2 Texts for professionals are regarded
as not suitable for novices: Reject-
ing the null hypothesis that texts gen-
erated for professionals are regarded as
many times as suitable for novices as for
professionals (p-value: 2 ? 10?7).
H3 Beginners prefer texts generated
for novices: The null hypothesis that
novices equally prefer texts targeted to
novices and texts targeted to experts
could not be rejected.
H4 Advanced cooks prefer texts gener-
ated for advanced cooks: Rejecting
the null hypothesis that advanced cooks
equally prefer texts targeted to novices
and texts targeted to experts (p-value:
0.0005).
The confirmation of H1 shows that users per-
ceive a difference in sentence length and pre-
fer texts with longer sentences, probably due
to perceived higher fluency. The confirmation
of H2 and H4, on the other hand, corrobo-
rates the successful adaptation of the gener-
ated texts to specific target groups, showing
16
that texts generated for professionals are in-
deed perceived as being generated for profes-
sionals, and that such texts are preferred by
advanced cooks. The rejection of H3 might
be caused by the fact that recipes for ad-
vanced cooks include some but actually not
many technical terms and are therefore also
comprehensible for novices.
5 Related work
There have been different approaches to
natural language generation, ranging from
template-based to statistical architectures.
While early NLG systems were mainly based
on manually created rules (Bourbeau et al,
1990; Reiter et al, 1992), later approaches
started applying statistical methods to the
subtasks involved in generation (Belz, 2005),
focusing on scalability and easy portability
and often relying on overgeneration and sub-
sequent ranking of generation possibilities.
Personalization has been a concern in both
strands of research. PEBA-II (Milosavljevic
et al, 1996), for example, generates target-
group-specific texts for novice and experts
users from taxonomical information, relying
on a phrasal lexicon that is similar in spirit to
our ontology lexicon. Statistical approaches
such as (Isard et al, 2006), on the other
hand, use text corpora to generate personal-
ized texts.
Our approach is hybrid in the sense that it
enriches a classical rule-based approach with
statistical data in the microplanning and reali-
sation steps, thus being comparable to systems
like HALogen (Langkilde and Knight, 1998)
and pCRU (Belz, 2008). The main difference
is that it uses Semantic Web data as base.
Since the emergence of the Semantic Web
there has been a strong interest in NLG
from Semantic Web data, especially for pro-
viding users with natural language access to
structured data. Work in this area com-
prises verbalization of ontologies as well as
RDF knowledge bases; for an overview see
(Bouayad-Agha et al, to appear). Of par-
ticular interest in the context of our work is
NaturalOWL (Galanis and Androutsopoulos,
2007), a system that produces descriptions of
entities and classes relying on linguistic anno-
tations of domain data in RDF format, similar
to our exploitation of ontology lexica. We thus
share with NaturalOWL the use of linguis-
tic resources encoded using standard Semantic
Web formats. The main difference is that the
annotations used by NaturalOWL comprise
not only lexical information but also micro-
plans for sentence planning, which in our case
are derived statistically and represented out-
side the lexicon. Separating lexical informa-
tion and sentence plans makes it easier to use
the same lexicon for generating different forms
of texts, either with respect to specific target
groups or stylistic variants.
6 Conclusion and future work
We have presented a principled natural lan-
guage generation architecture that follows a
classical NLG architecture but exploits an on-
tology lexicon as well as statistical information
derived from a domain corpus in the lexicali-
sation and surface realisation steps. The sys-
tem has been implemented and adapted to the
task of generating cooking recipe texts on the
basis of RDF representations of recipes. In an
evaluation with 93 participants we have shown
that the system is indeed effective and gener-
ates natural language texts that are perceived
as fluent and adequate. A particular feature
of the system is that it can personalize the
generation to particular target groups, in our
case cooking novices and advanced cooks. The
information about which lexicalisation to pre-
fer depending on the target group is included
in the ontology lexicon. In fact, the ontology
lexicon is the main driver of the generation
process, as it also guides the search for ap-
propriate parse trees. It thus is a central and
crucial component of the architecture.
While the system has been adapted to the
particulars of the cooking domain, especially
concerning the generation of referring expres-
sions, the architecture of the system is fairly
general and in principle the system could be
adapted to any domain by replacing the on-
tology, the corresponding ontology lexicon and
by providing a suitable domain corpus. This
flexibility is in our view a clear strength of our
system architecture.
A further characteristic of our system is the
consistent use of standards, i.e. OWL for
the ontology, RDF for the actual data to be
17
verbalized, SPARQL for modelling contextual
conditions under which a certain lexicalisa-
tion is to be used, and the lemon format for
the representation of the lexicon-ontology in-
terface. One important goal for future work
will be to clearly understand which knowledge
an ontology lexicon has to include in order
to optimally support NLG. To this end, we
intend to test the system on other domains,
and at the same time invite other researchers
to test their systems on our data, available
at http://www.sc.cit-ec.uni-bielefeld.
de/natural-language-generation.
Acknowledgment
This work was partially funded within the EU
project PortDial (FP7-296170).
References
E. Banik, C. Gardent, D. Scott, N. Dinesh, and
F. Liang. 2012. KBGen: text generation from
knowledge bases as a new shared task. In Proc.
Seventh International Natural Language Gener-
ation Conference (INLG 2012), pages 141?145.
A. Belz. 2005. Statistical generation: Three meth-
ods compared and evaluated. In Proc. 10th Eu-
ropean Workshop on Natural Language Genera-
tion (ENLG ?05), pages 15?23.
A. Belz. 2008. Automatic generation of weather
forecast texts using comprehensive probabilistic
generation-space models. Natural Language En-
gineering, 14(4):431?455.
T. Berners-Lee, J. Hendler, and O. Lassila. 2001.
The Semantic Web. Scientific American Maga-
zine.
N. Bouayad-Agha, G. Casamayor, S. Mille,
M. Rospocher, H. Saggion, L. Serafini, and
L. Wanner. 2012a. From ontology to NL: Gener-
ation of multilingual user-oriented environmen-
tal reports. In Proc. 17th International Confer-
ence on Applications of Natural Language Pro-
cessing to Information Systems (NLDB 2012),
pages 216?221.
N. Bouayad-Agha, G. Casamayor, L. Wanner, and
C. Mellish. 2012b. Content selection from Se-
mantic Web data. In Proc. Seventh Interna-
tional Natural Language Generation Conference
(INLG 2012), pages 146?149.
N. Bouayad-Agha, G. Casamayor, and L. Wanner.
to appear. Natural Language Generation in the
context of the Semantic Web. Semantic Web
Journal.
L. Bourbeau, D. Carcagno, E. Goldberg, R. Kit-
tredge, and A. Polgue`re. 1990. Bilingual gener-
ation of weather forecasts in an operations en-
vironment. In Proc. 13th International Con-
ference on Computational Linguistics (COLING
1990), pages 318?320.
D. Galanis and I. Androutsopoulos. 2007. Gen-
erating multilingual descriptions from linguis-
tically annotated OWL ontologies: the Nat-
uralOWL system. In Proc. 11th European
Workshop on Natural Language Generation
(ENLG ?07), pages 143?146.
A. Isard, C. Brockmann, and J. Oberlander. 2006.
Individuality and alignment in generated dia-
logues. In Proc. Fourth International Natural
Language Generation Conference (INLG 2006),
pages 25?32.
I. Langkilde and K. Knight. 1998. Generation that
exploits corpus-based statistical knowledge. In
Proc. 17th International Conference on Compu-
tational Linguistics (COLING ?98), pages 704?
710.
J. McCrae, D. Spohr, and P. Cimiano. 2011.
Linking lexical resources and ontologies on the
semantic web with lemon. In Proc. 8th Ex-
tended Semantic Web Conference on The Se-
mantic Web: Research and Applications (ESWC
2011), pages 245?259.
J. McCrae, E. Montiel-Ponsoda, and P. Cimiano.
2012. Collaborative semantic editing of linked
data lexica. In Proceedings of the 2012 Inter-
national Conference on Language Resource and
Evaluation.
C. Mellish and X. Sun. 2006. The Semantic Web
as a linguistic resource: Opportunities for nat-
ural language generation. Knowl.-Based Syst.,
19(5):298?303.
M. Milosavljevic, A. Tulloch, and R. Dale. 1996.
Text generation in a dynamic hypertext environ-
ment. In Proc. 19th Australian Computer Sci-
ence Conference, pages 417?426.
E. Reiter and R. Dale. 1992. A fast algorithm for
the generation of referring expressions.
E. Reiter and R. Dale. 2000. Building natural
language generation systems. Cambridge Uni-
versity Press.
E. Reiter, C. Mellish, and J. Levine. 1992. Au-
tomatic generation of on-line documentation in
the IDAS project. In Proc. Third Conference on
Applied Natural Language Processing (ANLP),
pages 64?71.
R. Ribeiro, F. Batista, J.P. Pardal, N.J. Mamede,
and H.S. Pinto. 2006. Cooking an ontology. In
Proceedings of the 12th international conference
on Artificial Intelligence: methodology, Systems,
18
and Applications, AIMSA?06, pages 213?221.
Springer.
Helmut Schmid. 2000. Unsupervised learning of
period disambiguation for tokenisation. Techni-
cal report, IMS-CL, University of Stuttgart.
X. Sun and C. Mellish. 2007. An experiment on
?free generation? from single RDF triples. In
Proc. 11th European Workshop on Natural Lan-
guage Generation (ENLG ?07), pages 105?108.
S. Walter, C. Unger, and P. Cimiano. 2013. A
corpus-based approach for the induction of on-
tology lexica. In Proceedings of the 18th Inter-
national Conference on the Application of Nat-
ural Language to Information Systems (NLDB
2013).
G. Wilcock and K. Jokinen. 2003. Generating re-
sponses and explanations from RDF/XML and
DAML+OIL. In Knowledge and Reasoning in
Practical Dialogue Systems, IJCAI 2003 Work-
shop, pages 58?63.
19
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 198?209,
Dublin, Ireland, August 23, 2014.
Modelling the Semantics of Adjectives in the Ontology-Lexicon Interface
John P. M
c
Crae
Universit?at Bielefeld
Bielefeld
Germany
jmccrae@cit-ec.uni-bielefeld.de
Christina Unger
Universit?at Bielefeld
Bielefeld
Germany
cunger@cit-ec.uni-bielefeld.de
Francesca Quattri
Hong Kong Polytechnic University
Hong Kong
francesca.quattri@connect.polyu.hk
Philipp Cimiano
Universit?at Bielefeld
Bielefeld
Germany
cimiano@cit-ec.uni-bielefeld.de
Abstract
The modelling of the semantics of adjectives is notoriously challenging. We consider this prob-
lem in the context of the so called ontology-lexicon interface, which attempts to capture the
semantics of words by reference to an ontology in description logics or some other, typically
first-order, logical formalism. The use of first order logic (hence also description logics), while
effective for nouns and verbs, breaks down in the case of adjectives. We argue that this is primar-
ily due to a lack of logical expressivity in the underlying ontology languages. In particular, be-
yond the straightforward intersective adjectives, there exist gradable adjectives, requiring fuzzy
or non-monotonic semantics, as well as operator adjectives, requiring second-order logic for
modelling. We consider how we can extend the ontology-lexicon interface as realized by extant
models such as lemon in the face of the issues mentioned above, in particular those arising in the
context of modelling the ontological semantics of adjectives. We show howmore complex logical
formalisms that are required to capture the ontological semantics of adjectives can be backward
engineered into OWL-based modelling by means of pseudo-classes. We discuss the implications
of this modelling in the context of application to ontology-based question answering.
1 Introduction
Ontology-lexicon models, such as lemon (Lexicon Model for Ontologies) (M
c
Crae et al., 2012) model
the semantics of open class words by capturing their semantics with respect to the semantic vocabulary
defined in a given ontology. Such ontology-lexica are built around the separation of a lexical layer, de-
scribing how a word or phrase acts syntactically and morphologically, and a semantic layer describing
how the meaning of a word is expressed in a formal logical model, such as OWL (Web Ontology Lan-
guage) (Deborah L. M
c
Guinness and others, 2004). As such, the modelling is based around a lexical
entry which describes the morphology and syntax of a word, and is linked by means of a lexical sense
to an ontology entity defined in a given ontology described in formal logic. It has been shown that this
principle known as semantics by reference (Buitelaar, 2010) is an effective model that can support the
task of developing question answering systems (Unger and Cimiano, 2011) and natural language gen-
eration (Cimiano et al., 2013) over backends based on Semantic Web data models. The Pythia system,
which builds on the lemon formalism to declaratively capture the lexicon-ontology interface, for exam-
ple, has been instantiated to the case of answering questions from DBpedia (Unger and Cimiano, 2011).
However, as has been shown by the Question Answering over Linked Data (Lopez et al., 2013, QALD)
benchmarking campaigns, there are many questions that can be asked over this database that require a
deeper representation of the semantics of words, adjectives in particular. For example, questions such
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
198
as (1a) require understanding of the semantics of ?high? in a manner that goes beyond the expressivity of
OWL. The formalization of this question as an executable query formulated with respect to the SPARQL
query language is provided in (1b). In particular, the interpretation of this question involves the formal
interpretation of the word ?high? as relating to the property dbo:elevation, including ordering and
subset selection operations.
1. (a) What is the highest mountain in Australia?
(b) SELECT DISTINCT ?uri WHERE {
?uri rdf:type dbo:Mountain .
?uri dbo:locatedInArea res:Australia .
?uri dbo:elevation ?elevation .
} ORDER BY DESC(?elevation) LIMIT 1
In the above query, we select an entity denoted by the query variable ?uri that has the properties
that i) the entity?s type is a mountain, ii) it is located in Australia, and iii) it has an elevation bound to
the variable ?elevation. We then sort the query in descending order by the value of the elevation
and limit so the query returns only the first result, in effect choosing the largest value in the data set.
It has been claimed that first-order logic and thus by extension description logics, such as OWL, ?fail
decidedly when it comes to adjectives? (Bankston, 2003). In fact, we largely agree that the semantics of
many adjectives are difficult or impossible to describe in first-order logic. However, from the point of
view of the ontology-lexicon interface, the logical expressivity of the ontology is not a limiting factor. In
fact, due to the separation of the lexical and ontology layers in a model such as lemon, it is possible to
express the meaning of words without worrying about the formalism used in the ontology. To this extent,
we will first demonstrate that adjectives are in general a case where the use of description logics (DL)
breaks down, and for which more sophisticated logical formalisms must be applied. We then consider
to what extent this can be handled in the context of the ontology-lexicon, and introduce pseudo-classes,
that is OWL classes with annotations, which we use to express the semantics of adjectives in a manner
that would allow reasoning with fuzzy, high-order models. To this extent, we base our models on the
previously introduced design patterns (M
c
Crae and Unger, 2014) for modelling ontology-lexica. Finally,
we show how these semantics can be helpful in practical applications of question answering over the
DBpedia knowledge base.
2 Classification of adjectives
There are a number of classifications of adjectives. First we will start with the most fundamental dis-
tinction between attributive and predicative usage, that is the use of adjectives in noun phrases (?X is a
A N?) versus as objects of the copula (?X is A?). It should be noted that there are many adjectives for
which only predicative or attributive usage is allowed, as shown in (3a) and (3).
2. (a) Clinton is a former president.
(b)
?
Clinton is former.
3. (a) The baby is awake.
(b)
?
The awake baby.
One of the principle classifications of the semantics of adjectives (for example (Partee, 2003; Bouillon
and Viegas, 1999; Morzycki, 2013b)) is based on the meaning of adjective noun compounds relative to
the meaning of the single words that form the compound. This classification is as follows (where ?
denotes entailment).
Intersective (X is a A N ? X is A ? X is a N ) Such adjectives work as if they were another noun
and indicate that the compound noun phrase is a member of class denoted by the noun and the class
denoted by the adjective. For example, in the phrase ?Belgian violinist? it refers to a person in the
class intersection Belgian ? V iolinist(X), and hence we can infer that a ?Belgian violinist? is a
subclass of a ?Belgian?. Furthermore, we could conclude that if the same person were a surgeon,
he/she would also be a ?Belgian Surgeon?.
199
Subsective (X is a AN ? X is a N , but X is a A N ?? X is A) Such adjectives acquire their specific
meaning in combination with the noun the modify. For example, a ?skilful violinist? is certainly in
the class V iolinist(X) but the described person is ?skilful as a violinist?, but not skilful in general,
e.g. as a surgeon.
Privative (X is a A N ?? X is a N ) These adjectives modify the meaning of a noun phrase to create a
noun phrase that is potentially incompatible with the original meaning. For example, a ?fake gun?
is not a member of the class of guns.
Another important distinction is whether adjectives are gradable, i.e. whether a comparative or su-
perlative statement with these adjectives makes sense. For example, adjectives such as ?big? or ?tall? can
express relationships such as ?X is bigger than Y ?. However it is not possible to say that one individ-
ual is ?more former?. Most gradable adjectives are subsective (e. g.?a big mouse? is not ?a big animal?
(Morzycki, 2013a)).
Finally, we consider operator or property-modifying adjectives. They can be understood along the
lines of privative adjectives but differ in that they represent operators that modify some property in the
qualia structure (Pustejovsky, 1991) of the class. For instance, we may express the adjective ?former? in
lambda calculus as a function that takes a class C as input and returns the class of entities that were a
member of C to some prior time point t (Partee, 2003):
?C[?x?tC(x, t) ? t < now]
Such adjectives have not only a difference in semantic meaning but can also frequently have syntactic
impact, for example in adjective ordering restrictions, as they may be reordered with only semantic
impact (Teodorescu, 2006), e.g.,
4. (a) A big red car.
(b)
?
A red big car.
5. (a) A famous former actor.
(b) A former famous actor.
Finally, we define object-relational adjectives as those adjectives which have a meaning that expresses
a relationship between two individuals or events
1
, for example:
6. He is related to her.
7. She is similar to her brother.
8. This is useful for something.
3 Representation of adjectives in the ontology-lexicon interface
In general it is assumed that adjectives form frames with exactly one argument except for extra arguments
provided by adjuncts, typically prepositional phrases. Most adjectives are thus associated with a pred-
icative frame, which much like the standard noun predicate frame (X is a N ) is stereotyped in English
as:
X is A
The attributive usage of an adjective is associate to a stereotypical frame where the N? argument is
not semantically bound, but can instead be obtained by syntactic unification to a noun predicate frame:
X is A N?
As such, when we encounter the attributive usage of an adjective such as in 9, we understand this as
the realization of two frames, given in 10.
9. Juan is a Spanish researcher.
10. (a) Juan is a researcher.
(b) Juan is a Spanish N?
Note that we do not provide modelling for adjectives where the meaning is unique for a particular
noun phrase, such as ?polar bear?, which we would capture as a normal noun phrase with meaning ursus
maritimus.
1
Our definition of relational here is borrowed from the idea of relational nouns (De Bruin and Scha, 1988) as a word that requires
an argument. Our definition is also different from the one for ?relational adjectives? as proposed by (Morzycki, 2013a).
200
Figure 1: Modelling of an intersective adjective ?Belgian? in lemon
3.1 Intersective adjectives
Intersective adjectives are the most straightforward class, as in many cases they can be modelled es-
sentially as a noun or verb (e.g. deverbal adjectives such as ?broken?). Intersective adjectives take one
argument and can thus be modelled as unary predicates in first-order logic or classes in OWL, as de-
scribed by M
c
Crae and Unger (2014). For practical modelling examples, we will use the lemon model,
since it is the most prominent implementation of the ontology-lexicon interface.
The primary mechanism of modelling the syntax-semantics interface in the context of lemon is by
means of assigning a frame as a syntactic behaviour of an entry and giving it syntactic arguments, which
can then be linked to the lexical sense, which stands proxy for a true semantic frame in the ontology. For
example, the modelling of an adjective such as ?Belgian? can be achieved as follows (depicted in Figure
1)
2
.
lexicon:belgian a lemon:LexicalEntry ;
lemon:canonicalForm belgian:Lemma ;
lemon:synBehavior belgian:AttrFrame ,
belgian:PredFrame ;
lemon:sense belgian:Sense .
belgian:Lemma lemon:writtenRep "Belgian"@eng .
belgian:AttrFrame lexinfo:attributiveArg belgian:AttrSynArg .
belgian:PredFrame lexinfo:copulativeArg belgian:PredSynArg .
belgian:sense lemon:reference [ a owl:Restriction ;
owl:onProperty dbpedia:nationality ;
owl:hasValue dbpedia:Belgium ] ;
lemon:isA belgian:AttrSynArg , belgian:PredSynArg .
In this example, the word ?Belgian? is associated with a lemma with representation ?Belgian?, two
frame objects and a lexical sense. The frame objects describe the attributive and predicative usage,
and are associated with an attributive and copulative argument respectively. The sense links the word
to the anonymous ontological class for objects that have ?Belgium? as the value of their ?national-
ity? property and furthermore the arguments of each frame are linked to the sense in order to estab-
lish a correspondence between the ontology class and the syntactic frames. Note that here we use
the external vocabulary defined in the LexInfo ontology (Cimiano et al., 2011) to define the mean-
ing of the arguments of the frame as the attributive argument, corresponding to the frame stereo-
type ?X is A N?? and the copulative argument for the frame stereotype ?X is A?. Furthermore, the
2
We assume that the namespaces are defined for the lexicon as lexicon, e.g., http://www.example.org/lexicon
and for the entry, e.g., belgian is http://www.example.org/lexicon/belgian#. Other namespaces are as-
sumed to be as usual.
201
class of Belgians is not named in our reference ontology DBpedia, so we introduce an anonymous
class with the axiomatization, i.e. ? nationality .Belgium. It is in fact common that the referent of
an adjective is not named in an ontology. An obvious choice is thus to model denominal adjec-
tives as classes of the form ? prop.Value, where Value is an individual that represents the seman-
tics of the noun from which the adjective was derived. This modelling is so common that it has al-
ready been encoded as two design patterns, called IntersectiveObjectPropertyAdjective
and IntersectiveDatatypePropertyAdjective (see (M
c
Crae and Unger, 2014)). Simi-
larly, most deverbal adjectives refer to an event, and as such a common modelling is of the form
? theme
?1
.EventClass. For example, ?vandalized? may be ? theme
?1
.VandalismEvent.
3.2 Gradable adjectives and relevant observables
Gradable adjectives have a number of properties which differentiate them from intersective adjectives:
? They occur in comparative constructions, in English with either ?-er? or ?more? (Kennedy and Mc-
Nally, 1999), e.g. ?smaller? and ?more frequent?, as opposed to intersectives such as ?*less geologi-
cal? and ?*more wooden?.
? Gradable adjectives can be defined as ?scalar?, since their value can ideally be measured on a scale
of set degrees
? They have a context-dependent truth-conditional variability, meaning that their positive form is un-
derstood in relation to the class of the object modified by the adjective. For example, an ?expensive
watch? has a different price scale to an ?expensive bottle of water?.
? They are frequently fuzzy (or vague) (Kennedy, 2007).
? There may be a minimum or maximum of the adjective?s scale, which can be determined by, for
example, whether they can modified by adverbs such as ?completely? or ?utterly?.
As such, we define gradable adjectives relative to a particular property. These adjectives are also
called ?observable? (Bennett, 2006)
3
as they are related to some observable or measurable property, e.g.
size in the case of ?big?. However, a specification of the observable property is clearly not sufficient to
differentiate between the meaning of antonyms such as big and small. Thus, we introduce the notions of
covariance and contravariance, which specify whether the comparative form indicates a higher property
value for the subject or the object. In this sense ?big? is covariant with size, as bigger things have a
higher size value, and ?small? is contravariant with size.
4
We also introduce a third concept, i.e. the one
of absolute gradability, which expresses the fact that the degree of membership in the denotation of the
adjective is stronger the more it approaches a prototypical or ideal value. A common example of this is
colours, where we may say that some object is redder than another if it is closer to some ideal value of
red (e.g., RGB 0xff0000).
While these notions can handle the comparative structure of the semantics of adjectives, the predicative
and superlative usage of adjectives is complicated by three factors that we will outline below. We notice
that gradable classes are not crisply defined like in the case of many intersective adjectives. In fact, while
we can clearly define all people in the world as ?Belgian? or ?not Belgian?, according to whom holds
a Belgian passport or not, it is not easy to split the world?s population into ?tall? and ?not tall? (This is
known as sorites paradox (Bennett, 2006)). Furthermore, while it may be easy to say that someone with
height 6?6? (198cm) is ?tall?, it is not clear whether someone with height 6? (182cm) is ?tall?, although
compared to an average (different) height for a man, they are ?taller?. As such, one frequently used way
to deal with this class of vague adjectives (and nouns) is via fuzzy logic (Goguen, 1969; Zadeh, 1975;
Zadeh, 1965; Dubois and Prade, 1988; Bennett, 2006). Secondly, we notice that these class boundaries
are non-monotonic, that is that with knowledge of more instances of the relative class we must revise
our class boundaries. This is especially the case for superlatives, as the discovery of a new tallest person
3
Note that in many cases the property is quite abstract such as in ?breakable?.
4
The use of these terms is borrowed from type systems, and resembles the concept of ?converse observables? as introduced by
((Bennett, 2006):42). As stated by the author, adjectives often come in pairs of polar opposites (e. g. conv(tall) = short, and
both refer to the same observable (in this case size). Some observables analogously hold converse relationships with other
observables (e. g. conv(flexibility) = rigidity or conv(tallness) = shortness).
202
in the world would remove the existing tallest person in the world from the class of tallest person in the
world. This non-monotonicity also affects the class boundaries of the gradable class itself. For example,
in the 18th century, the average height of a male was 5?5? (165cm)
5
; as such a male of 6? would have
clearly been considered tall.
It follows from this that each instance added to our ontology might lead to a revision of the class
boundaries of a gradable class, hence leading to the fact that gradable adjectives are fundamentally non-
monotonic. We must also notice that gradability can only be understood relative to the class that we wish
to grade. Thus, while it is a priori unclear whether 6? is tall for a male, it is clear that 6? is tall for a
female given the current average height of a female being about 5?4? (162cm).
We can therefore conclude that gradable adjectives are fuzzy, non-monotonic and context-sensitive, all
of which are incompatible with the description logic used in OWL.
Pseudo-classes in lemonOILS
Currently there are only limited models for representing fuzzy logic in the context of the Web (Zhao and
Boley, 2008). In order to capture the properties of gradable adjectives, we introduce a new model which
we name lemonOILS (The lemon Ontology for the Interpretation of Lexical Semantics)
6
. This ontology
introduces three new classes:
? CovariantScalar, indicating that the adjective is covariant with its bound property
? ContravariantScalar, indicating that the adjective is contravariant with its bound property
? AbsoluteScalar, indicating that the property represents similarity to an absolute value
In addition, the following properties are introduced to enable the description of gradable adjectives.
Note that all these properties are typed as annotation properties in the OWL ontology, so that they do
not interfere with the standard OWL reasoning.
? boundTo indicates the property that a scalar refers to (e.g., ?size? for ?big?)
? threshold specifies a sensible minimal value for which the adjective can be said to hold
? absoluteValue is the ideal value of an absolute scalar
? degree is specified as weak, medium, strong or very strong, corresponding to approxi-
mately 50%, 25%, 5% or 1% of all known individuals
? comparator indicates an object property that is equivalent to the comparison of the adjective
(e.g., an object property biggerThan may be considered a comparator for the adjective class
big)
? measure indicates a unit that can be used as a measure for this adjective, e.g., ?John is 175 cen-
timetres tall?.
Using such classes we can capture the semantics of gradable adjectives syntactically but not formally
within an OWL model. As such, we call these introduced classes pseudo-classes. An example of mod-
elling an adjective such as ?high? is given below (and depicted in Figure 2).
lexicon:high a lemon:LexicalEntry ;
lemon:canonicalForm high:Lemma ;
lemon:synBehavior high:PredFrame ;
lemon:sense high:Sense .
high:Lemma lemon:writtenRep "high"@eng .
high:PredFrame lexinfo:copulativeArg high:PredArg .
high:Sense lemon:reference [
rdfs:subClassOf oils:CovariantScalar ;
oils:boundTo dbpedia:elevation ;
oils:degree oils:strong ] ;
lemon:isA high:PredArg .
5
https://en.wikipedia.org/wiki/Human_height
6
http://lemon-model.net/oils
203
Figure 2: An example of the modelling of ?high? in lemon
As an example of a logic in which these annotations could be interpreted, we consider Markov
Logic (Richardson and Domingos, 2006), which is an extension of first-order logic in which each clause
is given a cost. The process of reasoning is thus transformed into an optimization problem of finding
the extension which minimizes the summed weight of all violated clauses. As such, we can formulate
a gradable adjective based on the number of known instances. For example, we can specify ?big? with
respect to size for some class C as in (11).
11. ?x ? C, y ? C : size(x) > size(y) ? big
C
(x) : ?
?x ? C, y ? C : size(x) < size(y) ? ?big
C
(x) : ?
In this way, the classification of an object into ?big? or ?small? can be defined as follows. For an individual
x ? C, the property big
C
(x) holds if and only if:
|{y ? C, size(y) > size(x)}|? < |{y ? C, size(y) < size(x)}|?
where the values of ? and ? are related to the degree defined in the ontology.
We see that ?big? defined in this way has the three properties outlined above: it is non-monotonic (in
that more individuals may change whether we consider an individual to be ?big? or not), it is fuzzy (given
by the strength of the probability of the proposition big
C
(x)), and it is context-sensitive (as whether an
individual counts as big or not depends on the class C). Furthermore, our definition does not rely on
defining ?big? for a given class, but instead is inferred from some known number of instances of this
class. This eliminates the need to define a threshold for each individual class, or even to define the
predicate big
C
on a per-class basis.
The supervaluation theory and SUMO
Another way to capture the meaning of these vague terms can be achieved by supervaluation semantics.
Through supervaluation theory, the modelling or positioning of sorites vague concepts is grounded in a
judgement or meaning that lies on arbitrary thresholds, but these thresholds are based on a number of
relevant objective measures (Bennett, 2006).
A recent extension of the SUMO ontology (Niles and Pease, 2001, Suggested Upper Merged On-
tology)
7
includes default measurements (currently amounting to 300+) added to the Artifacts,
Devices and Objects enlisted in the ontology (and marked with capitals). The compilation of
defaultMeasurements in SUMO has been just conducted on observables, not on predicates. Given
for instance an Artifact such as Book, the compilation of its default measurements would look like:
;;Book
(defaultMinimumHeight Book (MeasureFn 10 Inch))
(defaultMaximumHeight Book (MeasureFn 11 Inch))
(defaultMinimumLength Book (MeasureFn 5.5 Inch))
(defaultMaximumLength Book (MeasureFn 7 Inch))
(defaultMinimumWidth Book (MeasureFn 1.2 Inch))
(defaultMaximumWidth Book (MeasureFn 5.5 Inch))
7
www.ontologyportal.org
204
The example for Book shows that the default measurements for the observable reflect a standard kind
of book, i.e., one of the most commonly known kinds of the same artifact. As for this case, SUMO
implies Book to be a physical object with a certain length, height and width (and possibly weight). A
weakness here is that the there is no systematic connection between the defaultMinimumHeight
and Height or Width, since these physical properties have been defined in SUMO just in terms of
first-order logic, and have not been assigned default measurements yet. With lemonOILS we can add this
information as follows:
sumo:Book oils:default [
oils:defaultFor sumo:height ;
oils:defaultMin "10in" ;
oils:defaultMax "11in" ] .
Then, if we understand a lexical entry ?high? as referring to a scalar covariant pseudo-class for
sumo:height, it is possible to understand that a ?high? object exceeds the default minimum set es-
tablished for the same object and owns at the same time a value for ?high? which does not go beyond the
established default maximum. A further weakness of this approach is captured by the following example:
12. Avery Johnson is a short basketball player.
Here, we see the difficulty in interpreting the sentence, as Avery Johnson is in fact of average height
(5?10?) but for the class of basketball players he is unusually short. While SUMO has some very specific
listings of subsets for the same Artifact
8
, SUMO does not provide a well-structured subset net for
e. g. Person.As a way to address this bottleneck, we could introduce default values for every subclass
of Person, as well as to introduce default values for the same Artifact in conjunction with a predicate
or adjective (e. g. BigPerson, BulkyPerson). The creation of such ad hoc subclasses is not feasible
in general, as we would have to introduce a new class into the ontology for every combination of an
adjective and a noun. On the other side though, the SUMO default measurements serve the purpose
they were originally conceived for, namely to be an arbitrary, yet computable approximation of physical
measures.
3.3 Operator adjectives
Operator adjectives are those that combine with a noun to modify the meaning of the noun itself. There
are two primary issues with the understanding of the adjective in this manner. Firstly, the reference
of the lexical item does not generally refer to an existing item in the ontology, but rather is novel and
productive, in the sense that it generates a new class. Secondly, the compositional nature of adjective-
noun compounds is no longer simple, as in the cases of intersective and gradable adjectives. This means
that, in order to understand a concept such as a ?fake gun?, we must first derive a class of FakeGuns
from the class of Guns. Thus the modified noun phrase must be an argument of the operator adjective.
To this extent we claim that it is not generally possibly to represent the meaning of an operator adjective
within the context of an OWL ontology. Instead, following Bankston (Bankston, 2003), we claim that the
reference of an operator adjective must be a higher order predicate. If we assume that there are operators
of the form of a function, then the argument of an operator is the attributed noun phrase. As such, we
introduce a frame operator attributive, that has one argument which is the noun. Thus we understand
that the interpretation of ?fake gun? is by means of an operator fake, which is a function that takes
a class and produces a new class, i.e., [fake(Gun)](X). Capturing such an operator lies beyond the
expressivity of first-order logic. To fully capture the semantics of such an operator adjective, formalisms
beyond first-order logic are thus clearly needed.
3.4 Object-relational adjectives
Object-relational adjectives are those that require a second argument, such as ?known?, which can only
be understood as being ?known? to some person, in comparison to ?famous?. Thus, the modelling of the
relational adjective known is quite similar to the semantics of the corresponding verb know. It can be
modelled for instance via the frame ?X is known to Y ? and reference foaf:knows as:
8
For example, some of the subsets Car are: CrewDormCar, GalleryCar, MotorRailcar, FreightCar, BoxCar,
RefrigeratorCar, FiveWellStackCar, and more.
205
lexicon:known a lemon:LexicalEntry ;
lemon:canonicalForm known:Lemma ;
lemon:sense known:Sense ;
lemon:synBehavior known:Frame .
known:Lemma lemon:writtenRep "known"@eng .
known:Frame lexinfo:attributeArg known:Subject ;
lexinfo:prepositionalObject known:Object .
known:Sense lemon:reference foaf:knows ;
lemon:subjOfProp known:Subject ;
lemon:objOfProp known:Object .
known:Object lemon:marker lexicon:to .
4 Adjectives in question answering
In this section we empirically analyze the adequacy of the modelling proposed in this paper with respect
to the QALD-4
9
dataset, a shared dataset for Question Answering over Linked Data. The 250 training
and test questions of the QALD-4 benchmark contain 76 adjectives in total (not counting adjectives in
names such as ?Mean Hamster Software?).
18 of the occurring adjectives do not have a semantic contribution w.r.t. the underlying DBpedia
ontology, or at least none that is separable from the noun, as exemplified in the noun phrases in (13) and
(14).
10
13. (a) [[official website]] = dbo:website
(b) [[national anthem]] = dbo:anthem
14. (a) [[official languages]] = dbo:officialLanguages
(b) [[military conflicts]] = dbo:battle
Otherwise, the most common kinds of adjectives among them are gradable (27) and intersective (13)
adjectives.
All intersective adjectives denote restriction classes that are not explicitely named in DBpedia, in
correspondence with the modelling proposed in Section 3.1 above, for example:
15. (a) [[Danish]] = ?dbo:country .res:Denmark
(b) [[female]] = ?dbo:gender .res:Female
(c) [[Methodist]] = ?dbo:religion .res:Methodism
In some cases these intersectives have a context-dependent and highly ontology-specific meaning,
often tightly interwoven with the meaning of the noun, as in the following examples:
16. (a) [[first president of the United States]] = ?dbo:office . ?1st President of the United States?
(b) [[first season]] = ?dbo:seasonNumber . 1
All gradable adjectives that occur in the QALD-4 question set can be captured in terms of lemonOILS
as CovariantScalar (e.g. ?high?) or ContravariantScalar (e.g. ?young?) (cf. Section 3.2
above), bound to a DBpedia datatype property (e.g. elevation or birthDate). The positive form
of those adjectives only occurs in ?how (much)? questions, denoting the property they are bound to, for
example:
17. (a) [[deep]] = dbo:depth in ?How deep is Lake Placid??
(b) [[tall]] = dbo:height in ?How tall is Michael Jordan??
9
http://www.sc.cit-ec.uni-bielefeld.de/qald/
10
[[?]] stands for ?denotes? and the prefixes dbo and res abbreviate the DBpedia namespaces
http://dbpedia.org/ontology/ and http://dbpedia.org/resource/, respectively.
206
The comparative form denotes the property they are bound to, together with an aggregation operation,
usually a filter invoking a term of comparison that depends on whether the adjective is covariant or
contravariant.
18. (a) [[Which mountains are higher than the Nanga Parbat?]] =
SELECT DISTINCT ?uri WHERE {
res:Nanga_Parbat dbo:elevation ?x .
?uri rdf:type dbo:Mountain .
?uri dbo:elevation ?y .
FILTER (?y > ?x)
}
Finally, the superlative form denotes the property they are bound to, together with an aggregation
operation, usually an ordering with a cut-off of all results except the first one, as exemplified in (19). In
some cases, the superlative property is already encoded in the ontology, e.g., in the case of the property
dbo:highestPlace.
19. [[What is the longest river?]] =
SELECT DISTINCT ?uri WHERE {
?uri rdf:type dbo:River .
?uri dbo:length ?l .
} ORDER BY DESC(?l) OFFSET 0 LIMIT 1
There are three instances of operator adjectives. Examples are ?former?, as in 20, which does not
refer to an element in the DBpedia ontology but is instead a disambiguation clue in the given query, and
?professional?, which refers to the property dbo:occupation, see 21.
20. [[the former Dutch queen Juliana]] = res:Juliana
21. [[professional surfer]] = ?dbo:occupation .res:Surfing
Finally, there were 8 remaining adjectives totalling 15 occurrences, which do not correspond to mean-
ing in an ontology, but instead are part of the discourse structure, each ?same?, ?other?.
5 Related work
The categorization of adjectives in terms of formal semantics goes back to Montague (1970) and
Vendler (1968). However, one of the most significant attempts to assign a formal meaning was car-
ried out in the Mikrokosmos project (Raskin and Nirenburg, 1995). The approach to adjective modelling
in the Mikrokosmos provided one of the first computational implementations of a microtheory of adjec-
tive meaning. The modelling of adjectives presented in this paper is clearly inspired by the modelling
of adjectives adopted in the Mikrokosmos project. In particular, scalar adjectives in the Microkosmos
project are modeled by association with an attribute and a range, e.g., ?big? is described as being >0.75
(i.e., 75% of all known instances) on the size-attribute. Still, these classifications do not clearly
separate meaning and syntax and also require a separate modelling of comparatives and class-specific
meanings for many adjectives.
Amoia and Gardent (2006) handled the problem of adjectives in the context of textual entailment. They
analyzed 15 classes that show the subtle interaction between the semantic class (e.g., ?privative?) and the
issues of attributive/predicative use and gradability. Abdullah and Frost (2005) focused on the modelling
of privative adjectives by arguing that these adjectives modify the underlying set itself in a manner that
is naturally second-order. Similarly, Partee (2003) proposed a limited second-order model by means of
the ?head primary principle? requiring that adjectives are interpreted within their context. Bankston?s
analysis (2003), however, shows that the fundamental nature of many adjectives is higher-order, and pro-
vides a very sophisticated formal representation framework for adjectives. A more thorough discussion
of non-gradable, non-intersective adjectives is given by Morzycki (2013a). Bouillion and Viegas (1999)
consider the case of the French adjective ?vieux? (?old?), which they interprete as selecting two differ-
ent elements in the event structure of an attributed noun, that is whether the state, e.g., ?being a mayor?
for ?mayor?, is considered old or the individual itself. In this way, the introduction of two senses for
?vieux? is avoided, however it remains unclear if such reasoning introduces more complexity than the
207
extra senses. In his analysis of adjectives, Larson (1998) suggests that many adjectives denote properties
of events, rather than of simple heads or nouns (which does not fall very far from the statement, made
above, that relational adjectives denote properties of kinds). Pustejovsky (1992; 1991) and Lenci (2000)
state that lexical and semantic decomposition can be achieved generatively, assigning to each lexical item
a specific qualia structure. For instance, in an expression like:
22. The round, heavy, wooden, inlaid magnifying glass
? ?round? represents the Formal role (giving indications of shape and dimensionality)
? ?heavy? and ?wooden? related to the Constitutive role and indicate the relation between the
object and its parts (e. g. by specifying weight, material, parts and components)
? ?inlaid? is the Agentive role of the lexical item, denoting the factors that have been involved in
the generation of the objects, such as creator, artifact, natural kind, and causal chain
? ?magnifying? describes the Telic role of ?glass?, since it shows its purpose and function
Finally, Peters and Peters (2000) provide one of the few other practical reports on modelling adjectives
with ontologies, in the context of the SIMPLE lexica. This work is primarily focussed on the categoriza-
tion of by means of intensional and extensional properties, rather than due to their logical modelling.
6 Conclusion
In this paper we have proposed an approach to model the semantics of adjectives in the context of the
lexicon-ontology interface with a focus on the ontology-lexicon model lemon. We have argued that the
semantics of adjectives, in particular gradable and privative adjectives, is beyond what can be expressed
in first-order logics, OWL in particular. Instead, capturing the semantics of such adjectives requires
formalisms that are non-monotonic, second-order and can represent fuzzy concepts. We have proposed
an extension of lemon by the lemonOILS vocabulary that adds ?syntactic sugar? that allows us to represent
the semantics of adjectives in a way that abstracts from the actual representational formalism used. This
work has been used in the construction of lexical resources to support a question answering system,
and we found that this framework is sufficient to enable tractable computation of natural language to
SPARQL mapping over at least a small but varied set of test questions used in the QALD evaluation
task. Future work will show whether this model is scalable and applicable to most adjectives as well as
domains and natural languages.
References
Nabil Abdullah and Richard A Frost. 2005. Adjectives: A uniform semantic approach. In Advances in Artificial
Intelligence, pages 330?341. Springer.
Marilisa Amoia and Claire Gardent. 2006. Adjective based inference. In Proceedings of the Workshop KRAQ?06
on Knowledge and Reasoning for Language Processing, pages 20?27. Association for Computational Linguis-
tics.
Paul Bankston. 2003. Modeling nonintersective adjectives using operator logics. The Review of Modern Logic,
9(1-2):9?28.
Brandon Bennett. 2006. A theory of vague adjectives grounded in relevant observables. In John Mylopoulos
Patrick Doherty and Christopher A. Welty, editors, Proceedings of the Tenth International Conference on Prin-
ciples of Knowledge Representation and Reasoning, pages 36?45. AAAI Press.
Pierrette Bouillon and Evelyne Viegas. 1999. The description of adjectives for natural language processing: Theo-
retical and applied perspectives. In Proceedings of Description des Adjectifs pour les Traitements Informatiques.
Traitement Automatique des Langues Naturelles. Citeseer.
Pierrette Bouillon. 1999. The adjective ?vieux?: The point of view of ?generative lexicon?. In Breadth and depth
of semantic lexicons, pages 147?166. Springer.
Paul Buitelaar, 2010. Ontology-based Semantic Lexicons: Mapping between Terms and Object Descriptions,
pages 212?223. Cambridge University Press.
Philipp Cimiano, Paul Buitelaar, John M
c
Crae, and Michael Sintek. 2011. Lexinfo: A declarative model for the
lexicon-ontology interface. Web Semantics: Science, Services and Agents on the World Wide Web, 9(1):29?51.
Philipp Cimiano, Janna L?uker, David Nagel, and Christina Unger. 2013. Exploiting ontology lexica for generating
natural language texts from rdf data. In Proceedings of the 14th European Workshop on Natural Language
Generation, pages 10?19.
208
Jos De Bruin and Remko Scha. 1988. The interpretation of relational nouns. In Proceedings of the 26th annual
meeting on Association for Computational Linguistics, pages 25?32. Association for Computational Linguistics.
Frank Van Harmelen Deborah L. M
c
Guinness et al. 2004. Owl web ontology language overview. W3C recom-
mendation, 10(2004-03):10.
Didier Dubois and Henri Prade. 1988. Possibility theory. Plenum Press, New York.
Joseph H. Goguen. 1969. The logic of inexact concepts. Synthese, 19:325?373.
Christopher Kennedy and Louise McNally. 1999. Deriving the scalar structure of deverbal adjectives. Catalan
Working Papers in Linguistics, 7:125?139.
Christopher Kennedy. 2007. Vagueness and grammar: the semantics of relative and absolute gradable adjectives.
Linguistics and philosophy, 30:1?45.
Richard K. Larson. 1998. Events and modification in nominals. In Devon Strolovitch and Aaron Lawson, editors,
Proceedings from Semantics and Linguistic Theory (SALT) VIII, pages 145?168. CLC Publications, Itaca, New
York.
Alessandro Lenci et al. 2000. Simple work package 2, linguistic specifications, deliverable d2.1.
Vanessa Lopez, Christina Unger, Philipp Cimiano, and Enrico Motta. 2013. Evaluating question answering over
linked data. Web Semantics: Science, Services and Agents on the World Wide Web, 21:3?13.
Louise McNally and Gemma Boleda. 2004. Relational adjectives as properties of kinds. Empirical issues in
formal syntax and semantics, 5:179?196.
Richard Montague. 1970. English as a formal language. In Bruno Visentini et al, editor, Linguaggi nella societa
e nella tecnica, pages 189?224. Milan: Edizioni di Comunit`a.
Marcin Morzycki. 2013a. The lexical semantics of adjectives: More than just scales. Ms., Michigan State
University. Draft of a chapter in Modification, a book in preparation for the Cambridge University Press series
Key Topics in Semantics and Pragmatics.
Marcin Morzycki. 2013b. Modification. Cambridge University Press.
John P. M
c
Crae and Christina Unger. 2014. Design patterns for the ontology-lexicon interface. In Paul Buitelaar
and Philipp Cimiano, editors, Towards the Multilingual Semantic Web: Principles, Methods and Applications.
Springer.
John M
c
Crae, Guadalupe Aguado-de Cea, Paul Buitelaar, Philipp Cimiano, Thierry Declerck, Asunci?on G?omez-
P?erez, Jorge Gracia, Laura Hollink, Elena Montiel-Ponsoda, Dennis Spohr, et al. 2012. Interchanging lexical
resources on the semantic web. Language Resources and Evaluation, 46(4):701?719.
Ian Niles and Adam Pease. 2001. Towards a standard upper ontology.
Barbara H Partee. 2003. Are there privative adjectives. In Conference on the Philosophy of Terry Parsons,
University of Massachusetts, Amherst.
Ivonne Peters and Wim Peters. 2000. The treatment of adjectives in simple: Theoretical observations. In LREC.
James Pustejovsky. 1991. The generative lexicon. Computational linguistics, 17(4):409?441.
James Pustejovsky. 1992. The syntax of event structure. In Bett Levin and Steven Pinker, editors, Lexical &
Conceptual Semantics, pages 47?83. Oxford: Blackwell.
Victor Raskin and Sergei Nirenburg. 1995. Lexical semantics of adjectives. New Mexico State University, Com-
puting Research Laboratory Technical Report, MCCS-95-288.
Matthew Richardson and Pedro Domingos. 2006. Markov logic networks. Machine learning, 62(1-2):107?136.
Alexandra Teodorescu. 2006. Adjective ordering restrictions revisited. In Proceedings of the 25th West Coast
Conference on Formal Linguistics, pages 399?407. Citeseer.
Christina Unger and Philipp Cimiano. 2011. Pythia: Compositional meaning construction for ontology-based
question answering on the semantic web. In Rafael Munoz, editor, Natural Language Processing and Infor-
mation Systems: 16th International Conference on Applications of Natural Language to Information Systems,
NLDB 2011, Alicante, Spain, June 28-30, 2011. Proceedings, volume 6716, pages 153?160. Springer.
Zeno Vendler. 1968. Adjectives and nominalizations. Number 5 in Papers on formal linguistics. Mouton.
Lofti A. Zadeh. 1965. Fuzzy sets. Information and Control, 8:338?353.
Lofti A. Zadeh. 1975. The concept of linguistic variable and its application to approximate reasoningi. Informa-
tion Sciences, 8:199?249.
Jidi Zhao and Harold Boley. 2008. Uncertainty treatment in the rule interchange format: From encoding to
extension. In URSW.
209
