Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 304?311,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Bootstrapping Word Alignment via Word Packing
Yanjun Ma, Nicolas Stroppa, Andy Way
School of Computing
Dublin City University
Glasnevin, Dublin 9, Ireland
{yma,nstroppa,away}@computing.dcu.ie
Abstract
We introduce a simple method to pack words
for statistical word alignment. Our goal is to
simplify the task of automatic word align-
ment by packing several consecutive words
together when we believe they correspond
to a single word in the opposite language.
This is done using the word aligner itself,
i.e. by bootstrapping on its output. We
evaluate the performance of our approach
on a Chinese-to-English machine translation
task, and report a 12.2% relative increase in
BLEU score over a state-of-the art phrase-
based SMT system.
1 Introduction
Automatic word alignment can be defined as the
problem of determining a translational correspon-
dence at word level given a parallel corpus of aligned
sentences. Most current statistical models (Brown
et al, 1993; Vogel et al, 1996; Deng and Byrne,
2005) treat the aligned sentences in the corpus as se-
quences of tokens that are meant to be words; the
goal of the alignment process is to find links be-
tween source and target words. Before applying
such aligners, we thus need to segment the sentences
into words ? a task which can be quite hard for lan-
guages such as Chinese for which word boundaries
are not orthographically marked. More importantly,
however, this segmentation is often performed in a
monolingual context, which makes the word align-
ment task more difficult since different languages
may realize the same concept using varying num-
bers of words (see e.g. (Wu, 1997)). Moreover, a
segmentation considered to be ?good? from a mono-
lingual point of view may be unadapted for training
alignment models.
Although some statistical alignment models al-
low for 1-to-n word alignments for those reasons,
they rarely question the monolingual tokenization
and the basic unit of the alignment process remains
the word. In this paper, we focus on 1-to-n align-
ments with the goal of simplifying the task of auto-
matic word aligners by packing several consecutive
words together when we believe they correspond to a
single word in the opposite language; by identifying
enough such cases, we reduce the number of 1-to-n
alignments, thus making the task of word alignment
both easier and more natural.
Our approach consists of using the output from
an existing statistical word aligner to obtain a set of
candidates for word packing. We evaluate the re-
liability of these candidates, using simple metrics
based on co-occurence frequencies, similar to those
used in associative approaches to word alignment
(Kitamura and Matsumoto, 1996; Melamed, 2000;
Tiedemann, 2003). We then modify the segmenta-
tion of the sentences in the parallel corpus accord-
ing to this packing of words; these modified sen-
tences are then given back to the word aligner, which
produces new alignments. We evaluate the validity
of our approach by measuring the influence of the
alignment process on a Chinese-to-English Machine
Translation (MT) task.
The remainder of this paper is organized as fol-
lows. In Section 2, we study the case of 1-to-
n word alignment. Section 3 introduces an auto-
matic method to pack together groups of consecutive
304
1: 0 1: 1 1: 2 1: 3 1:n (n > 3)
IWSLT Chinese?English 21.64 63.76 9.49 3.36 1.75
IWSLT English?Chinese 29.77 57.47 10.03 1.65 1.08
IWSLT Italian?English 13.71 72.87 9.77 3.23 0.42
IWSLT English?Italian 20.45 71.08 7.02 0.9 0.55
Europarl Dutch?English 24.71 67.04 5.35 1.4 1.5
Europarl English?Dutch 23.76 69.07 4.85 1.2 1.12
Table 1: Distribution of alignment types for different language pairs (%)
words based on the output from a word aligner. In
Section 4, the experimental setting is described. In
Section 5, we evaluate the influence of our method
on the alignment process on a Chinese to English
MT task, and experimental results are presented.
Section 6 concludes the paper and gives avenues for
future work.
2 The Case of 1-to-n Alignment
The same concept can be expressed in different lan-
guages using varying numbers of words; for exam-
ple, a single Chinese word may surface as a com-
pound or a collocation in English. This is fre-
quent for languages as different as Chinese and En-
glish. To quickly (and approximately) evaluate this
phenomenon, we trained the statistical IBM word-
alignment model 4 (Brown et al, 1993),1 using the
GIZA++ software (Och and Ney, 2003) for the fol-
lowing language pairs: Chinese?English, Italian?
English, and Dutch?English, using the IWSLT-2006
corpus (Takezawa et al, 2002; Paul, 2006) for the
first two language pairs, and the Europarl corpus
(Koehn, 2005) for the last one. These asymmet-
ric models produce 1-to-n alignments, with n ? 0,
in both directions. Here, it is important to mention
that the segmentation of sentences is performed to-
tally independently of the bilingual alignment pro-
cess, i.e. it is done in a monolingual context. For Eu-
ropean languages, we apply the maximum-entropy
based tokenizer of OpenNLP2; the Chinese sen-
tences were human segmented (Paul, 2006).
In Table 1, we report the frequencies of the dif-
ferent types of alignments for the various languages
and directions. As expected, the number of 1:n
1More specifically, we performed 5 iterations of Model 1, 5
iterations of HMM, 5 iterations of Model 3, and 5 iterations of
Model 4.
2http://opennlp.sourceforge.net/.
alignments with n 6= 1 is high for Chinese?English
(' 40%), and significantly higher than for the Eu-
ropean languages. The case of 1-to-n alignments is,
therefore, obviously an important issue when deal-
ing with Chinese?English word alignment.3
2.1 The Treatment of 1-to-n Alignments
Fertility-based models such as IBM models 3, 4, and
5 allow for alignments between one word and sev-
eral words (1-to-n or 1:n alignments in what fol-
lows), in particular for the reasons specified above.
They can be seen as extensions of the simpler IBM
models 1 and 2 (Brown et al, 1993). Similarly,
Deng and Byrne (2005) propose an HMM frame-
work capable of dealing with 1-to-n alignment,
which is an extension of the original model of (Vogel
et al, 1996).
However, these models rarely question the mono-
lingual tokenization, i.e. the basic unit of the align-
ment process is the word.4 One alternative to ex-
tending the expressivity of one model (and usually
its complexity) is to focus on the input representa-
tion; in particular, we argue that the alignment pro-
cess can benefit from a simplification of the input,
which consists of trying to reduce the number of
1-to-n alignments to consider. Note that the need
to consider segmentation and alignment at the same
time is also mentioned in (Tiedemann, 2003), and
related issues are reported in (Wu, 1997).
2.2 Notation
While in this paper, we focus on Chinese?English,
the method proposed is applicable to any language
3Note that a 1: 0 alignment may denote a failure to capture
a 1:n alignment with n > 1.
4Interestingly, this is actually even the case for approaches
that directly model alignments between phrases (Marcu and
Wong, 2002; Birch et al, 2006).
305
pair ? even for closely related languages, we ex-
pect improvements to be seen. The notation how-
ever assume Chinese?English MT. Given a Chi-
nese sentence cJ1 consisting of J words {c1, . . . , cJ}
and an English sentence eI1 consisting of I words
{e1, . . . , eI}, AC?E (resp. AE?C) will denote a
Chinese-to-English (resp. an English-to-Chinese)
word alignment between cJ1 and eI1. Since we are
primarily interested in 1-to-n alignments, AC?E
can be represented as a set of pairs aj = ?cj , Ej?
denoting a link between one single Chinese word
cj and a few English words Ej (and similarly for
AE?C). The set Ej is empty if the word cj is not
aligned to any word in eI1.
3 Automatic Word Repacking
Our approach consists of packing consecutive words
together when we believe they correspond to a sin-
gle word in the other language. This bilingually
motivated packing of words changes the basic unit
of the alignment process, and simplifies the task of
automatic word alignment. We thus minimize the
number of 1-to-n alignments in order to obtain more
comparable segmentations in the two languages. In
this section, we present an automatic method that
builds upon the output from an existing automatic
word aligner. More specifically, we (i) use a word
aligner to obtain 1-to-n alignments, (ii) extract can-
didates for word packing, (iii) estimate the reliability
of these candidates, (iv) replace the groups of words
to pack by a single token in the parallel corpus, and
(v) re-iterate the alignment process using the up-
dated corpus. The first three steps are performed
in both directions, and produce two bilingual dic-
tionaries (source-target and target-source) of groups
of words to pack.
3.1 Candidate Extraction
In the following, we assume the availability of an
automatic word aligner that can output alignments
AC?E and AE?C for any sentence pair (cJ1 , eI1)
in a parallel corpus. We also assume that AC?E
and AE?C contain 1:n alignments. Our method for
repacking words is very simple: whenever a single
word is aligned with several consecutive words, they
are considered candidates for repacking. Formally,
given an alignment AC?E between cJ1 and eI1, if
aj = ?cj , Ej? ? AC?E , with Ej = {ej1 , . . . , ejm}
and ?k ? J1,m? 1K, jk+1 ? jk = 1, then the align-
ment aj between cj and the sequence of words Ej
is considered a candidate for word repacking. The
same goes for AE?C . Some examples of such 1-
to-n alignments between Chinese and English (in
both directions) we can derive automatically are dis-
played in Figure 1.
????: white wine
????: department store
??: excuse me
??: call the police
?: cup of
??: have to
closest: ? ?
fifteen: ? ?
fine: ? ?
flight: ? ?? 
get: ? ?
here:  ? ??
Figure 1: Example of 1-to-n word alignments be-
tween Chinese and English
3.2 Candidate Reliability Estimation
Of course, the process described above is error-
prone and if we want to change the input to give to
the word aligner, we need to make sure that we are
not making harmful modifications.5 We thus addi-
tionally evaluate the reliability of the candidates we
extract and filter them before inclusion in our bilin-
gual dictionary. To perform this filtering, we use
two simple statistical measures. In the following,
aj = ?cj , Ej? denotes a candidate.
The first measure we consider is co-occurrence
frequency (COOC(cj , Ej)), i.e. the number of
times cj and Ej co-occur in the bilingual corpus.
This very simple measure is frequently used in as-
sociative approaches (Melamed, 1997; Tiedemann,
2003). The second measure is the alignment confi-
dence, defined as
AC(aj) =
C(aj)
COOC(cj , Ej)
,
where C(aj) denotes the number of alignments pro-
posed by the word aligner that are identical to aj .
In other words, AC(aj) measures how often the
5Consequently, if we compare our approach to the problem
of collocation identification, we may say that we are more in-
terested in precision than recall (Smadja et al, 1996). However,
note that our goal is not recognizing specific sequences of words
such as compounds or collocations; it is making (bilingually
motivated) changes that simplify the alignment process.
306
aligner aligns cj and Ej when they co-occur. We
also impose that |Ej | ? k, where k is a fixed inte-
ger that may depend on the language pair (between
3 and 5 in practice). The rationale behind this is that
it is very rare to get reliable alignment between one
word and k consecutive words when k is high.
The candidates are included in our bilingual dic-
tionary if and only if their measures are above some
fixed thresholds tcooc and tac, which allow for the
control of the size of the dictionary and the quality
of its contents. Some other measures (including the
Dice coefficient) could be considered; however, it
has to be noted that we are more interested here in
the filtering than in the discovery of alignment, since
our method builds upon an existing aligner. More-
over, we will see that even these simple measures
can lead to an improvement of the alignment pro-
cess in a MT context (cf. Section 5).
3.3 Bootstrapped Word Repacking
Once the candidates are extracted, we repack the
words in the bilingual dictionaries constructed using
the method described above; this provides us with
an updated training corpus, in which some word se-
quences have been replaced by a single token. This
update is totally naive: if an entry aj = ?cj , Ej? is
present in the dictionary and matches one sentence
pair (cJ1 , eI1) (i.e. cj and Ej are respectively con-
tained in cJ1 and eI1), then we replace the sequence
of words Ej with a single token which becomes a
new lexical unit.6 Note that this replacement occurs
even if no alignment was found between cj and Ej
for the pair (cJ1 , eI1). This is motivated by the fact
that the filtering described above is quite conserva-
tive; we trust the entry ai to be correct. This update
is performed in both directions. It is then possible to
run the word aligner using the updated (simplified)
parallel corpus, in order to get new alignments. By
performing a deterministic word packing, we avoid
the computation of the fertility parameters associ-
ated with fertility-based models.
Word packing can be applied several times: once
we have grouped some words together, they become
the new basic unit to consider, and we can re-run
the same method to get additional groupings. How-
6In case of overlap between several groups of words to re-
place, we select the one with highest confidence (according to
tac).
ever, we have not seen in practice much benefit from
running it more than twice (few new candidates are
extracted after two iterations).
It is also important to note that this process is
bilingually motivated and strongly depends on the
language pair. For example, white wine, excuse me,
call the police, and cup of (cf. Figure 1) translate re-
spectively as vin blanc, excusez-moi, appellez la po-
lice, and tasse de in French. Those groupings would
not be found for a language pair such as French?
English, which is consistent with the fact that they
are less useful for French?English than for Chinese?
English in a MT perspective.
3.4 Using Manually Developed Dictionaries
We wanted to compare this automatic approach to
manually developed resources. For this purpose,
we used a dictionary built by the MT group of
Harbin Institute of Technology, as a preprocessing
step to Chinese?English word alignment, and moti-
vated by several years of Chinese?English MT prac-
tice. Some examples extracted from this resource
are displayed in Figure 2.
?: whiti en 
??:?dp aw wr
??: aiim arw
??: ea str aw rs
?: pn nrra  pn
?: orrx pw
Figure 2: Examples of entries from the manually de-
veloped dictionary
4 Experimental Setting
4.1 Evaluation
The intrinsic quality of word alignment can be as-
sessed using the Alignment Error Rate (AER) met-
ric (Och and Ney, 2003), that compares a system?s
alignment output to a set of gold-standard align-
ment. While this method gives a direct evaluation of
the quality of word alignment, it is faced with sev-
eral limitations. First, it is really difficult to build
a reliable and objective gold-standard set, especially
for languages as different as Chinese and English.
Second, an increase in AER does not necessarily im-
ply an improvement in translation quality (Liang et
al., 2006) and vice-versa (Vilar et al, 2006). The
307
relationship between word alignments and their im-
pact on MT is also investigated in (Ayan and Dorr,
2006; Lopez and Resnik, 2006; Fraser and Marcu,
2006). Consequently, we chose to extrinsically eval-
uate the performance of our approach via the transla-
tion task, i.e. we measure the influence of the align-
ment process on the final translation output. The
quality of the translation output is evaluated using
BLEU (Papineni et al, 2002).
4.2 Data
The experiments were carried out using the
Chinese?English datasets provided within the
IWSLT 2006 evaluation campaign (Paul, 2006), ex-
tracted from the Basic Travel Expression Corpus
(BTEC) (Takezawa et al, 2002). This multilingual
speech corpus contains sentences similar to those
that are usually found in phrase-books for tourists
going abroad. Training was performed using the de-
fault training set, to which we added the sets de-
vset1, devset2, and devset3.7 The English side of
the test set was not available at the time we con-
ducted our experiments, so we split the development
set (devset 4) into two parts: one was kept for testing
(200 aligned sentences) with the rest (289 aligned
sentences) used for development purposes.
As a pre-processing step, the English sentences
were tokenized using the maximum-entropy based
tokenizer of the OpenNLP toolkit, and case infor-
mation was removed. For Chinese, the data pro-
vided were tokenized according to the output format
of ASR systems, and human-corrected (Paul, 2006).
Since segmentations are human-corrected, we are
sure that they are good from a monolingual point of
view. Table 2 contains the various corpus statistics.
4.3 Baseline
We use a standard log-linear phrase-based statistical
machine translation system as a baseline: GIZA++
implementation of IBM word alignment model 4
(Brown et al, 1993; Och and Ney, 2003),8 the re-
finement and phrase-extraction heuristics described
in (Koehn et al, 2003), minimum-error-rate training
7More specifically, we choose the first English reference
from the 7 references and the Chinese sentence to construct new
sentence pairs.
8Training is performed using the same number of iterations
as in Section 2.
Chinese English
Train Sentences 41,465
Running words 361,780 375,938
Vocabulary size 11,427 9,851
Dev. Sentences 289 (7 refs.)
Running words 3,350 26,223
Vocabulary size 897 1,331
Eval. Sentences 200 (7 refs.)
Running words 1,864 14,437
Vocabulary size 569 1,081
Table 2: Chinese?English corpus statistics
(Och, 2003) using Phramer (Olteanu et al, 2006),
a 3-gram language model with Kneser-Ney smooth-
ing trained with SRILM (Stolcke, 2002) on the En-
glish side of the training data and Pharaoh (Koehn,
2004) with default settings to decode. The log-linear
model is also based on standard features: condi-
tional probabilities and lexical smoothing of phrases
in both directions, and phrase penalty (Zens and
Ney, 2004).
5 Experimental Results
5.1 Results
The initial word alignments are obtained using the
baseline configuration described above. From these,
we build two bilingual 1-to-n dictionaries (one for
each direction), and the training corpus is updated
by repacking the words in the dictionaries, using the
method presented in Section 2. As previously men-
tioned, this process can be repeated several times; at
each step, we can also choose to exploit only one of
the two available dictionaries, if so desired. We then
extract aligned phrases using the same procedure as
for the baseline system; the only difference is the ba-
sic unit we are considering. Once the phrases are ex-
tracted, we perform the estimation of the features of
the log-linear model and unpack the grouped words
to recover the initial words. Finally, minimum-error-
rate training and decoding are performed.
The various parameters of the method (k, tcooc,
tac, cf. Section 2) have been optimized on the devel-
opment set. We found out that it was enough to per-
form two iterations of repacking: the optimal set of
values was found to be k = 3, tac = 0.5, tcooc = 20
for the first iteration, and tcooc = 10 for the second
308
BLEU[%]
Baseline 15.14
n=1. with C-E dict. 15.92
n=1. with E-C dict. 15.77
n=1. with both 16.59
n=2. with C-E dict. 16.99
n=2. with E-C dict. 16.59
n=2. with both 16.88
Table 3: Influence of word repacking on Chinese-to-
English MT
iteration, for both directions.9 In Table 3, we report
the results obtained on the test set, where n denotes
the iteration. We first considered the inclusion of
only the Chinese?English dictionary, then only the
English?Chinese dictionary, and then both.
After the first step, we can already see an im-
provement over the baseline when considering one
of the two dictionaries. When using both, we ob-
serve an increase of 1.45 BLEU points, which cor-
responds to a 9.6% relative increase. Moreover, we
can gain from performing another step. However,
the inclusion of the English?Chinese dictionary is
harmful in this case, probably because 1-to-n align-
ments are less frequent for this direction, and have
been captured during the first step. By including the
Chinese?English dictionary only, we can achieve an
increase of 1.85 absolute BLEU points (12.2% rela-
tive) over the initial baseline.10
Quality of the Dictionaries To assess the qual-
ity of the extraction procedure, we simply manu-
ally evaluated the ratio of incorrect entries in the
dictionaries. After one step of word packing, the
Chinese?English and the English?Chinese dictio-
naries respectively contain 7.4% and 13.5% incor-
rect entries. After two steps of packing, they only
contain 5.9% and 10.3% incorrect entries.
5.2 Alignment Types
Intuitively, the word alignments obtained after word
packing are more likely to be 1-to-1 than before. In-
9The parameters k, tac, and tcooc are optimized for each
step, and the alignment obtained using the best set of parameters
for a given step are used as input for the following step.
10Note that this setting (using both dictionaries for the first
step and only the Chinese dictionary for the second step) is also
the best setting on the development set.
deed, the word sequences in one language that usu-
ally align to one single word in the other language
have been grouped together to form one single to-
ken. Table 4 shows the detail of the distribution of
alignment types after one and two steps of automatic
repacking. In particular, we can observe that the 1: 1
1: 0 1: 1 1: 2 1: 3 1:n
(n > 3)
C-E Base. 21.64 63.76 9.49 3.36 1.75
n=1 19.69 69.43 6.32 2.79 1.78
n=2 19.67 71.57 4.87 2.12 1.76
E-C Base. 29.77 57.47 10.03 1.65 1.08
n=1 26.59 61.95 8.82 1.55 1.09
n=2 25.10 62.73 9.38 1.68 1.12
Table 4: Distribution of alignment types (%)
alignments are more frequent after the application
of repacking: the ratio of this type of alignment has
increased by 7.81% for Chinese?English and 5.26%
for English?Chinese.
5.3 Influence of Word Segmentation
To test the influence of the initial word segmenta-
tion on the process of word packing, we considered
an additional segmentation configuration, based on
an automatic segmenter combining rule-based and
statistical techniques (Zhao et al, 2001).
BLEU[%]
Original segmentation 15.14
Original segmentation + Word packing 16.99
Automatic segmentation 14.91
Automatic segmentation + Word packing 17.51
Table 5: Influence of Chinese segmentation
The results obtained are displayed in Table 5. As
expected, the automatic segmenter leads to slightly
lower results than the human-corrected segmenta-
tion. However, the proposed method seems to be
beneficial irrespective of the choice of segmentation.
Indeed, we can also observe an improvement in the
new setting: 2.6 points absolute increase in BLEU
(17.4% relative).11
11We could actually consider an extreme case, which would
consist of splitting the sentences into characters, i.e. each char-
acter would be blindly treated as one word. The segmentation
309
5.4 Exploiting Manually Developed Resources
We also compared our technique for automatic pack-
ing of words with the exploitation of manually
developed resources. More specifically, we used
a 1-to-n Chinese?English bilingual dictionary, de-
scribed in Section 3.4, and used it in place of the
automatically acquired dictionary. Words are thus
grouped according to this dictionary, and we then
apply the same word aligner as for previous experi-
ments. In this case, since we are not bootstrapping
from the output of a word aligner, this can actually
be seen as a pre-processing step prior to alignment.
These resources follow more or less the same for-
mat as the output of the word segmenter mentioned
in Section 5.1.2 (Zhao et al, 2001), so the experi-
ments are carried out using this segmentation.
BLEU[%]
Baseline 14.91
Automatic word packing 17.51
Packing with ?manual? dictionary 16.15
Table 6: Exploiting manually developed resources
The results obtained are displayed in Table 6.We
can observe that the use of the manually developed
dictionary provides us with an improvement in trans-
lation quality: 1.24 BLEU points absolute (8.3% rel-
ative). However, there does not seem to be a clear
gain when compared with the automatic method.
Even if those manual resources were extended, we
do not believe the improvement is sufficient enough
to justify this additional effort.
6 Conclusion and Future Work
In this paper, we have introduced a simple yet effec-
tive method to pack words together in order to give
a different and simplified input to automatic word
aligners. We use a bootstrap approach in which we
first extract 1-to-n word alignments using an exist-
ing word aligner, and then estimate the confidence
of those alignments to decide whether or not the n
words have to be grouped; if so, this group is con-
would thus be completely driven by the bilingual alignment pro-
cess (see also (Wu, 1997; Tiedemann, 2003) for related consid-
erations). In this case, our approach would be similar to the
approach of (Xu et al, 2004), except for the estimation of can-
didates.
sidered a new basic unit to consider. We can finally
re-apply the word aligner to the updated sentences.
We have evaluated the performance of our ap-
proach by measuring the influence of this process
on a Chinese-to-English MT task, based on the
IWSLT 2006 evaluation campaign. We report a
12.2% relative increase in BLEU score over a stan-
dard phrase-based SMT system. We have verified
that this process actually reduces the number of 1:n
alignments with n 6= 1, and that it is rather indepen-
dent from the (Chinese) segmentation strategy.
As for future work, we first plan to consider dif-
ferent confidence measures for the filtering of the
alignment candidates. We also want to bootstrap on
different word aligners; in particular, one possibility
is to use the flexible HMM word-to-phrase model of
Deng and Byrne (2005) in place of IBM model 4.
Finally, we would like to apply this method to other
corpora and language pairs.
Acknowledgment
This work is supported by Science Foundation Ire-
land (grant number OS/IN/1732). Prof. Tiejun Zhao
and Dr. Muyun Yang from the MT group of Harbin
Institute of Technology, and Yajuan Lv from the In-
stitute of Computing Technology, Chinese Academy
of Sciences, are kindly acknowledged for provid-
ing us with the Chinese segmenter and the manually
developed bilingual dictionary used in our experi-
ments.
References
Necip Fazil Ayan and Bonnie J. Dorr. 2006. Going be-
yond aer: An extensive analysis of word alignments
and their impact on mt. In Proceedings of COLING-
ACL 2006, pages 9?16, Sydney, Australia.
Alexandra Birch, Chris Callison-Burch, and Miles Os-
borne. 2006. Constraining the phrase-based, joint
probability statistical translation model. In Proceed-
ings of AMTA 2006, pages 10?18, Boston, MA.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational Linguistics, 19(2):263?311.
Yonggang Deng and William Byrne. 2005. HMM word
and phrase alignment for statistical machine transla-
tion. In Proceedings of HLT-EMNLP 2005, pages
169?176, Vancouver, Canada.
310
Alexander Fraser and Daniel Marcu. 2006. Measuring
word alignment quality for statistical machine transla-
tion. Technical Report ISI-TR-616, ISI/University of
Southern California.
Mihoko Kitamura and Yuji Matsumoto. 1996. Auto-
matic extraction of word sequence correspondences in
parallel corpora. In Proceedings of the 4th Workshop
on Very Large Corpora, pages 79?87, Copenhagen,
Denmark.
Philip Koehn, Franz Och, and Daniel Marcu. 2003. Sta-
tistical phrase-based translation. In Proceedings of
HLT-NAACL 2003, pages 48?54, Edmonton, Canada.
Philip Koehn. 2004. Pharaoh: A beam search decoder
for phrase-based statistical machine translation mod-
els. In Proceedings of AMTA 2004, pages 115?124,
Washington, District of Columbia.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Machine Transla-
tion Summit X, pages 79?86, Phuket, Thailand.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of HLT-NAACL
2006, pages 104?111, New York, NY.
Adam Lopez and Philip Resnik. 2006. Word-based
alignment, phrase-based translation: What?s the link?
In Proceedings of AMTA 2006, pages 90?99, Cam-
bridge, MA.
Daniel Marcu and William Wong. 2002. A phrase-based,
joint probability model for statistical machine transla-
tion. In Proceedings of EMNLP 2002, pages 133?139,
Morristown, NJ.
I. Dan Melamed. 1997. Automatic discovery of non-
compositional compounds in parallel data. In Pro-
ceedings of EMNLP 1997, pages 97?108, Somerset,
New Jersey.
I. Dan Melamed. 2000. Models of translational equiv-
alence among words. Computational Linguistics,
26(2):221?249.
Franz Och and Hermann Ney. 2003. A systematic com-
parison of various statistical alignment models. Com-
putational Linguistics, 29(1):19?51.
Franz Och. 2003. Minimum error rate training in statisti-
cal machine translation. In Proceedings of ACL 2003,
pages 160?167, Sapporo, Japan.
Marian Olteanu, Chris Davis, Ionut Volosen, and Dan
Moldovan. 2006. Phramer - an open source statis-
tical phrase-based translator. In Proceedings of the
NAACL 2006 Workshop on Statistical Machine Trans-
lation, pages 146?149, New York, NY.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proceedings of ACL
2002, pages 311?318, Philadelphia, PA.
Michael Paul. 2006. Overview of the IWSLT 2006 Eval-
uation Campaign. In Proceedings of IWSLT 2006,
pages 1?15, Kyoto, Japan.
Frank Smadja, Kathleen R. McKeown, and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: A statistical approach. Computa-
tional Linguistics, 22(1):1?38.
Andrea Stolcke. 2002. SRILM ? An extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken Language Processing,
pages 901?904, Denver, Colorado.
T. Takezawa, E. Sumita, F. Sugaya, H. Yamamoto, and
S. Yamamoto. 2002. Toward a broad-coverage bilin-
gual corpus for speech translation of travel conversa-
tions in the real world. In Proceedings of LREC 2002,
pages 147?152, Las Palmas, Spain.
Jo?rg Tiedemann. 2003. Combining clues for word align-
ment. In Proceedings of EACL 2003, pages 339?346,
Budapest, Hungary.
David Vilar, Maja Popovic, and Hermann Ney. 2006.
AER: Do we need to ?improve? our alignments? In
Proceedings of IWSLT 2006, pages 205?212, Kyoto,
Japan.
Stefan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of COLING 1996, pages 836?
841, Copenhagen, Denmark.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?403.
Jia Xu, Richard Zens, and Hermann Ney. 2004. Do
we need chinese word segmentation for statistical
machine translation? In Proceedings of the Third
SIGHAN Workshop on Chinese Language Learning,
pages 122?128, Barcelona, Spain.
Richard Zens and Hermann Ney. 2004. Improvements
in phrase-based statistical machine translation. In
Proceedings of HLT-NAACL 2004, pages 257?264,
Boston, MA.
Tiejun Zhao, Yajuan Lu?, and Hao Yu. 2001. Increas-
ing accuracy of chinese segmentation with strategy of
multi-step processing. Journal of Chinese Information
Processing, 15(1):13?18.
311
Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL),
pages 120?127, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
An Analogical Learner for Morphological Analysis
Nicolas Stroppa & Franc?ois Yvon
GET/ENST & LTCI, UMR 5141
46 rue Barrault, 75013 Paris, France
{stroppa,yvon}@enst.fr
Abstract
Analogical learning is based on a two-
step inference process: (i) computation
of a structural mapping between a new
and a memorized situation; (ii) transfer
of knowledge from the known to the un-
known situation. This approach requires
the ability to search for and exploit such
mappings, hence the need to properly de-
fine analogical relationships, and to effi-
ciently implement their computation.
In this paper, we propose a unified defini-
tion for the notion of (formal) analogical
proportion, which applies to a wide range
of algebraic structures. We show that this
definition is suitable for learning in do-
mains involving large databases of struc-
tured data, as is especially the case in Nat-
ural Language Processing (NLP). We then
present experimental results obtained on
two morphological analysis tasks which
demonstrate the flexibility and accuracy of
this approach.
1 Introduction
Analogical learning (Gentner et al, 2001) is based
on a two-step inductive process. The first step con-
sists in the construction of a structural mapping be-
tween a new instance of a problem and solved in-
stances of the same problem. Once this mapping
is established, solutions for the new instance can be
induced, based on one or several analogs. The im-
plementation of this kind of inference process re-
quires techniques for searching for, and reasoning
with, structural mappings, hence the need to prop-
erly define the notion of analogical relationships and
to efficiently implement their computation.
In Natural Language Processing (NLP), the typ-
ical dimensionality of databases, which are made
up of hundreds of thousands of instances, makes
the search for complex structural mappings a very
challenging task. It is however possible to take ad-
vantage of the specific nature of linguistic data to
work around this problem. Formal (surface) analog-
ical relationships between linguistic representations
are often a good sign of deeper analogies: a surface
similarity between the word strings write and writer
denotes a deeper (semantic) similarity between the
related concepts. Surface similarities can of course
be misleading. In order to minimize such confu-
sions, one can take advantage of other specificities
of linguistic data: (i) their systemic organization in
(pseudo)-paradigms, and (ii) their high level of re-
dundancy. In a large lexicon, we can indeed expect
to find many instances of pairs like write-writer: for
instance read -reader, review-reviewer...
Complementing surface analogies with statistical
information thus has the potential to make the search
problem tractable, while still providing with many
good analogs. Various attempts have been made to
use surface analogies in various contexts: automatic
word pronunciation (Yvon, 1999), morphological
analysis (Lepage, 1999a; Pirrelli and Yvon, 1999)
and syntactical analysis (Lepage, 1999b). These ex-
periments have mainly focused on linear represen-
120
tations of linguistic data, taking the form of finite
sequences of symbols, using a restrictive and some-
times ad-hoc definition of the notion of an analogy.
The first contribution of this paper is to propose a
general definition of formal analogical proportions
for algebraic structures commonly used in NLP:
attribute-value vectors, words on finite alphabets and
labeled trees. The second contribution is to show
how these formal definitions can be used within an
instance-based learning framework to learn morpho-
logical regularities.
This paper is organized as follows. In Section 2,
our interpretation of analogical learning is intro-
duced and related to other models of analogical
learning and reasoning. Section 3 presents a general
algebraic framework for defining analogical propor-
tions as well as its instantiation to the case of words
and labeled trees. This section also discusses the
algorithmic complexity of the inference procedure.
Section 4 reports the results of experiments aimed
at demonstrating the flexibility of this model and at
assessing its generalization performance. We con-
clude by discussing current limitations of this model
and by suggesting possible extensions.
2 Principles of analogical learning
2.1 Analogical reasoning
The ability to identify analogical relationships be-
tween what looks like unrelated situations, and to
use these relationships to solve complex problems,
lies at the core of human cognition (Gentner et al,
2001). A number of models of this ability have
been proposed, based on symbolic (e.g. (Falken-
heimer and Gentner, 1986; Thagard et al, 1990;
Hofstadter and the Fluid Analogies Research group,
1995)) or subsymbolic (e.g. (Plate, 2000; Holyoak
and Hummel, 2001)) approaches. The main focus
of these models is the dynamic process of analogy
making, which involves the identification of a struc-
tural mappings between a memorized and a new sit-
uation. Structural mapping relates situations which,
while being apparently very different, share a set of
common high-level relationships. The building of
a structural mapping between two situations utilizes
several subparts of their descriptions and the rela-
tionships between them.
Analogy-making seems to play a central role in
our reasoning ability; it is also invoked to explain
some human skills which do not involve any sort of
conscious reasoning. This is the case for many tasks
related to the perception and production of language:
lexical access, morphological parsing, word pronun-
ciation, etc. In this context, analogical models have
been proposed as a viable alternative to rule-based
models, and many implementation of these low-
level analogical processes have been proposed such
as decision trees, neural networks or instance-based
learning methods (see e.g. (Skousen, 1989; Daele-
mans et al, 1999)). These models share an accepta-
tion of analogy which mainly relies on surface simi-
larities between instances.
Our learner tries to bridge the gap between these
approaches and attempts to remain faithful to the
idea of structural analogies, which prevails in the
AI literature, while also exploiting the intuitions of
large-scale, instance-based learning models.
2.2 Analogical learning
We consider the following supervised learning task:
a learner is given a set S of training instances
{X1, . . . , Xn} independently drawn from some un-
known distribution. Each instance Xi is a vector
containing m features: ?Xi1, . . . , Xim?. Given S,
the task is to predict the missing features of partially
informed new instances. Put in more standard terms,
the set of known (resp. unknown) features for a new
value X forms the input space (resp. output space):
the projections of X onto the input (resp. output)
space will be denoted I(X) (resp. O(X)). This set-
ting is more general than the simpler classification
task, in which only one feature (the class label) is
unknown, and covers many other interesting tasks.
The inference procedure can be sketched as fol-
lows: training examples are simply stored for fu-
ture use; no generalization (abstraction) of the data
is performed, which is characteristic of lazy learning
(Aha, 1997). Given a new instance X , we identify
formal analogical proportions involving X in the in-
put space; known objects involved in these propor-
tions are then used to infer the missing features.
An analogical proportion is a relation involv-
ing four objects A, B, C and D, denoted by
A : B :: C : D and which reads A is to B as C is
to D. The definition and computation of these pro-
portions are studied in Section 3. For the moment,
121
we contend that it is possible to construct analogical
proportions between (possibly partially informed)
objects in S. Let I(X) be a partially described ob-
ject not seen during training. The analogical infer-
ence process is formalized as:
1. Construct the set T (X) ? S3 defined as:
T (X) = {(A,B,C) ? S3 |
I(A) : I(B) :: I(C) : I(X)}
2. For each (A,B,C) ? T (X), compute hy-
potheses O?(X) by solving the equation:
O?(X) = O(A) : O(B) :: O(C) :?
This inference procedure shows lots of similari-
ties with the k-nearest neighbors classifier (k-NN)
which, given a new instance, (i) searches the training
set for close neighbors, (ii) compute the unknown
class label according to the neighbors? labels. Our
model, however, does not use any metric between
objects: we only rely on the definition of analogical
proportions, which reveal systemic, rather than su-
perficial, similarities. Moreover, inputs and outputs
are regarded in a symmetrical way: outputs are not
restricted to a set of labels, and can also be structured
objects such as sequences. The implementation of
the model still has to address two specific issues.
? When exploring S3, an exhaustive search eval-
uates |S|3 triples, which can prove to be in-
tractable. Moreover, objects in S may be
unequally relevant, and we might expect the
search procedure to treat them accordingly.
? Whenever several competing hypotheses are
proposed for O?(X), a ranking must be per-
formed. In our current implementation, hy-
potheses are ranked based on frequency counts.
These issues are well-known problems for k-NN
classifiers. The second one does not appear to be
critical and is usually solved based on a majority
rule. In contrast, a considerable amount of effort has
been devoted to reduce and optimize the search pro-
cess, via editing and condensing methods, as stud-
ied e.g. in (Dasarathy, 1990; Wilson and Martinez,
2000). Proposals for solving this problem are dis-
cussed in Section 3.4.
3 An algebraic framework for analogical
proportions
Our inductive model requires the availability of a de-
vice for computing analogical proportions on feature
vectors. We consider that an analogical proportion
holds between four feature vectors when the propor-
tion holds for all components. In this section, we
propose a unified algebraic framework for defining
analogical proportions between individual features.
After giving the general definition, we present its in-
stantiation for two types of features: words over a
finite alphabet and sets of labelled trees.
3.1 Analogical proportions
Our starting point will be analogical proportions in
a set U , which we define as follows: ?x, y, z, t ?
U, x : y :: z : t if and only if either x = y and z = t
or x = z and y = t. In the sequel, we assume that
U is additionally provided with an associative inter-
nal composition law?, which makes (U,?) a semi-
group. The generalization of proportions to semi-
groups involves two key ideas: the decomposition of
objects into smaller parts, subject to alternation con-
straints. To formalize the idea of decomposition, we
define the factorization of an element u in U as:
Definition 1 (Factorization)
A factorization of u ? U is a sequence u1 . . . un,
with ?i, ui ? U , such that: u1 ? . . . ? un = u.
Each term ui is a factor of u.
The alternation constraint expresses the fact that
analogically related objects should be made of alter-
nating factors: for x : y :: z : t to hold, each factor
in x should be found alternatively in y and in z. This
yields a first definition of analogical proportions:
Definition 2 (Analogical proportion)
(x, y, z, t) ? U form an analogical proportion, de-
noted by x : y :: z : t if and only if there exists some
factorizations x1? . . . ?xd = x, y1? . . . ?yd = y,
z1 ? . . . ? zd = z, t1 ? . . . ? td = t such that
?i, (yi, zi) ? {(xi, ti), (ti, xi)}. The smallest d for
which such factorizations exist is termed the degree
of the analogical proportion.
This definition is valid for any semigroup, and a
fortiori for any richer algebraic structure. Thus, it
readily applies to the case of groups, vector spaces,
free monoids, sets and attribute-value structures.
122
3.2 Words over Finite Alphabets
3.2.1 Analogical Proportions between Words
Let ? be a finite alphabet. ?? denotes the set of
finite sequences of elements of ?, called words over
?. ??, provided with the concatenation operation .
is a free monoid whose identity element is the empty
word ?. For w ? ??, w(i) denotes the ith symbol in
w. In this context, definition (2) can be re-stated as:
Definition 3 (Analogical proportion in (??,.))
(x, y, z, t) ? ?? form an analogical proportion, de-
noted by x : y :: z : t if and only if there exists some
integer d and some factorizations x1 . . . xd = x,
y1 . . . yd = y, z1 . . . zd = z, t1 . . . td = t such that
?i, (yi, zi) ? {(xi, ti), (ti, xi)}.
An example of analogy between words is:
viewing : reviewer :: searching : researcher
with x1 = ?, x2 = view, x3 = ing and t1 = re,
t2 = search, t3 = er. This definition generalizes
the proposal of (Lepage, 1998). It does not ensure
the existence of a solution to an analogical equation,
nor its uniqueness when it exists. (Lepage, 1998)
gives a set of necessary conditions for a solution to
exist. These conditions also apply here. In particu-
lar, if t is a solution of x : y :: z :?, then t contains,
in the same relative order, all the symbols in y and z
that are not in x. As a consequence, all solutions of
an equation have the same length.
3.2.2 A Finite-state Solver
Definition (3) yields an efficient procedure for
solving analogical equations, based on finite-state
transducers. The main steps of the procedure are
sketched here. A full description can be found in
(Yvon, 2003). To start with, let us introduce the no-
tions of complementary set and shuffle product.
Complementary set If v is a subword of w, the
complementary set of v with respect to w, denoted
by w\v is the set of subwords of w obtained by re-
moving from w, in a left-to-right fashion, the sym-
bols in v. For example, eea is a complementary sub-
word of xmplr with respect to exemplar. When v is
not a subword of w, w\v is empty. This notion can
be generalized to any regular language.
The complementary set of v with respect to w is
a regular set: it is the output language of the finite-
state transducer Tw (see Figure 1) for the input v.
0 1 k
w(1) : ?
? : w(1)
w(k) : ?
? : w(k)
Figure 1: The transducer Tw computing comple-
mentary sets wrt w.
Shuffle The shuffle u ? v of two words u and v is
introduced e.g. in (Sakarovitch, 2003) as follows:
u ? v = {u1v1u2v2 . . . unvn, st. ui, vi ? ??,
u1 . . . un = u, v1 . . . vn = v}
The shuffle of two words u and v contains all the
words w which can be composed using all the sym-
bols in u and v, subject to the condition that if a
precedes b in u (or in v), then it precedes b in w.
Taking, for instance, u = abc and v = def , the
words abcdef , abdefc, adbecf are in u ? v; this
is not the case with abefcd. This operation gen-
eralizes straightforwardly to languages. The shuf-
fle of two regular languages is regular (Sakarovitch,
2003); the automaton A, computing K?L, is derived
from the automata AK = (?, QK , q0K , FK , ?K) and
AL = (?, QL, q0L, FL, ?L) recognizing respectively
K and L as the product automata A = (?, QK ?
QL, (q0K , q
0
L), FK ? FL, ?), where ? is defined as:
?((qK , qL), a) = (rK , rL) if and only if either
?K(qK , a) = rK and qL = rL or ?L(qL, a) = rL
and qK = rK .
The notions of complementary set and shuffle are
related through the following property, which is a
direct consequence of the definitions.
w ? u ? v ? u ? w\v
Solving analogical equations The notions of
shuffle and complementary sets yield another
characterization of analogical proportion between
words, based on the following proposition:
Proposition 1.
?x, y, z, t ? ??, x : y :: z : t? x ? t ? y ? z 6= ?
An analogical proportion is thus established if the
symbols in x and t are also found in y and z, and ap-
pear in the same relative order. A corollary follows:
123
Proposition 2.
t is a solution of x : y :: z :?? t ? (y ? z)\x
The set of solutions of an analogical equation
x : y :: z :? is a regular set, which can be computed
with a finite-state transducer. It can also be shown
that this analogical solver generalizes the approach
based on edit distance proposed in (Lepage, 1998).
3.3 Trees
Labelled trees are very common structures in NLP
tasks: they can represent syntactic structures, or
terms in a logical representation of a sentence. To
express the definition of analogical proportion be-
tween trees, we introduce the notion of substitution.
Definition 4 (Substitution)
A (single) substitution is a pair (variable ? tree).
The application of the substitution (v ? t?) to a tree
t consists in replacing each leaf of t labelled by v by
the tree t?. The result of this operation is denoted:
t(v ? t?). For each variable v, we define the binary
operator /v as t /v t? = t (v ? t?).
Definition 2 can then be extended as:
Definition 5 (Analogical proportion (trees))
(x, y, z, t) ? U form an analogical propor-
tion, denoted by x : y :: z : t iff there exists some
variables (v1, . . . , vn?1) and some factorizations
x1 /v1 . . . /vn?1 xn = x, y1 /v1 . . . /vn?1 yn = y,
z1 /v1 . . . /vn?1 zn = z, t1 /v1 . . . /vn?1 tn = t such
that ?i, (yi, zi) ? {(xi, ti), (ti, xi)}.
An example of such a proportion is illustrated on
Figure 2 with syntactic parse trees.
This definition yields an effective algorithm
computing analogical proportions between trees
(Stroppa and Yvon, 2005). We consider here a sim-
pler heuristic approach, consisting in (i) linearizing
labelled trees into parenthesized sequences of sym-
bols and (ii) using the analogical solver for words
introduced above. This approach yields a faster, al-
beit approximative algorithm, which makes analogi-
cal inference tractable even for large tree databases.
3.4 Algorithmic issues
We have seen how to compute analogical relation-
ships for features whose values are words and trees.
S
NP
the police
VP
have VP
impounded
NP
his car
:
S
NP
his car
VP
AUX
have
VP
been VP
impounded
PP
by NP
the police
::
S
NP
the mouse
VP
has VP
eaten
NP
the cat
:
S
NP
the cat
VP
AUX
has
VP
been VP
eaten
PP
by NP
the mouse
Figure 2: Analogical proportion between trees.
If we use, for trees, the solver based on tree lin-
earizations, the resolution of an equation amounts,
in both cases, to solving analogies on words.
The learning algorithm introduced in Section 2.2
is a two-step procedure: a search step and a trans-
fer step. The latter step only involves the resolu-
tion of (a restricted number of) analogical equations.
When x, y and z are known, solving x : y :: z :?
amounts to computing the output language of the
transducer representing (y ? z)\x: the automaton
for this language has a number of states bounded by
|x |? |y |? |z |. Given the typical length of words in
our experiments, and given that the worst-case ex-
ponential bound for determinizing this automaton is
hardly met, the solving procedure is quite efficient.
The problem faced during the search procedure
is more challenging: given x, we need to retrieve
all possible triples (y, z, t) in a finite set L such
that x : y :: z : t. An exhaustive search requires
the computation of the intersection of the finite-
state automaton representing the output language of
(L ? L)\x with the automaton for L. Given the size
of L in our experiments (several hundreds of thou-
sands of words), a complete search is intractable and
we resort to the following heuristic approach.
L is first split into K bins {L1, ..., LK}, with |Li |
small with respect to |L |. We then randomly select
k bins and compute, for each bin Li, the output lan-
guage of (Li ?Li)\x, which is then intersected with
L: we thus only consider triples containing at least
124
two words from the same bin. It has to be noted that
the bins are not randomly constructed: training ex-
amples are grouped into inflectional or derivational
families. To further speed up the search, we also im-
pose an upper bound on the degree of proportions.
All triples retrieved during these k partial searches
are then merged and considered for the transfer step.
The computation of analogical relationships has
been implemented in a generic analogical solver;
this solver is based on Vaucanson, an automata ma-
nipulation library using high performance generic
programming (Lombardy et al, 2003).
4 Experiments
4.1 Methodology
The main purpose of these experiments is to demon-
strate the flexibility of the analogical learner. We
considered two different supervised learning tasks,
both aimed at performing the lexical analysis of iso-
lated word forms. Each of these tasks represents a
possible instantiation of the learning procedure in-
troduced in Section 2.2.
The first experiment consists in computing one
or several vector(s) of morphosyntactic features to
be associated with a form. Each vector comprises
the lemma, the part-of-speech, and, based on the
part-of-speech, additional features such as number,
gender, case, tense, mood, etc. An (English) in-
put/output pair for this tasks thus looks like: in-
put=replying; output={reply; V-pp--}, where the
placeholder ?-? denotes irrelevant features. Lexi-
cal analysis is useful for many applications: a POS
tagger, for instance, needs to ?guess? the possi-
ble part(s)-of-speech of unknown words (Mikheev,
1997). For this task, we use the definition of analog-
ical proportions for ?flat? feature vectors (see sec-
tion 3.1) and for word strings (section 3.2). The
training data is a list of fully informed lexical en-
tries; the test data is a list of isolated word forms
not represented in the lexicon. Bins are constructed
based on inflectional families.
The second experiment consists in computing a
morphological parse of unknown lemmas: for each
input lemma, the output of the system is one or sev-
eral parse trees representing a possible hierarchical
decomposition of the input into (morphologically
categorized) morphemes (see Figure 3). This kind
of analysis makes it possible to reconstruct the series
of morphological operations deriving a lemma, to
compute its root, its part-of-speech, and to identify
morpheme boundaries. This information is required,
for instance, to compute the pronunciation of an un-
known word; or to infer the compositional meaning
of a complex (derived or compound) lemma. Bins
gather entries sharing a common root.
input=acrobatically; output =
B


HH
H
A
 HH
N
acrobat
A|N.
ic
B|A.
ally
Figure 3: Input/output pair for task 2. Bound mor-
phemes have a compositional type: B|A. denotes a
suffix that turns adjectives into adverbs.
These experiments use the English, German, and
Dutch morphological tables of the CELEX database
(Burnage, 1990). For task 1, these tables contain
respectively 89 000, 342 000 and 324 000 different
word forms, and the number of features to predict is
respectively 6, 12, and 10. For task 2, which was
only conducted with English lemma, the total num-
ber of different entries is 48 407.
For each experiment, we perform 10 runs, using
1 000 randomly selected entries for testing1. Gen-
eralization performance is measured as follows: the
system?s output is compared with the reference val-
ues (due to lexical ambiguity, a form may be asso-
ciated in the database with several feature vectors
or parse trees). Per instance precision is computed
as the relative number of correct hypotheses, i.e.
hypotheses which exactly match the reference: for
task 1, all features have to be correct; for task 2, the
parse tree has to be identical to the reference tree.
Per instance recall is the relative number of refer-
ence values that were actually hypothesized. Preci-
sion and recall are averaged over the test set; num-
bers reported below are averaged over the 10 runs.
Various parameters affect the performance: k, the
number of randomly selected bins considered during
the search step (see Section 3.4) and d, the upper
1Due to lexical ambiguity, the number of tested instances is
usually greater than 1 000.
125
bound of the degree of extracted proportions.
4.2 Experimental results
Experimental results for task 1 are given in Tables 1,
2 and 3. For each main category, two recall and pre-
cision scores are computed: one for the sole lemma
and POS attributes (left column); and one for the
lemma and all the morpho-syntactic features (on the
right). In these experiments, parameters are set as
follows: k = 150 and d = 3. As k grows, both recall
and precision increase (up to a limit); k = 150 ap-
pears to be a reasonable trade-off between efficiency
and accuracy. A further increase of d does not sig-
nificantly improve accuracy: taking d = 3 or d = 4
yields very comparable results.
Lemma + POS Lemma + Features
Rec. Prec. Rec. Prec.
Nouns 76.66 94.64 75.26 95.37
Verbs 94.83 97.14 94.79 97.37
Adjectives 26.68 72.24 27.89 87.67
Table 1: Results on task 1 for English
Lemma + POS Lemma + Features
Rec. Prec. Rec. Prec.
Nouns 71.39 92.17 54.59 74.75
Verbs 96.75 97.85 93.26 94.36
Adjectives 91.59 96.09 90.02 95.33
Table 2: Results on task 1 for Dutch
Lemma + POS Lemma + Features
Rec. Prec. Rec. Prec.
Nouns 93.51 98.28 77.32 81.70
Verbs 99.55 99.69 90.50 90.63
Adjectives 99.14 99.28 99.01 99.15
Table 3: Results on task 1 for German
As a general comment, one can note that high
generalization performance is achieved for lan-
guages and categories involving rich inflectional
paradigms: this is exemplified by the performance
on all German categories. English adjectives, at
the other end of this spectrum, are very difficult to
analyze. A simple and effective workaround for
this problem consists in increasing the size the sub-
lexicons (Li in Section 3.4) so as to incorporate in a
given bin all the members of the same derivational
(rather than inflectional) family. For Dutch, these
results are comparable with the results reported in
(van den Bosch and Daelemans, 1999), who report
an accuracy of about 92% on the task of predicting
the main syntactic category.
Rec. Prec.
Morphologically Complex 46.71 70.92
Others 17.00 46.86
Table 4: Results on task 2 for English
The second task is more challenging since the ex-
act parse tree of a lemma must be computed. For
morphologically complex lemmas (involving affixa-
tion or compounding), it is nevertheless possible to
obtain acceptable results (see Table 4, showing that
some derivational phenomena have been captured.
Further analysis is required to assess more precisely
the potential of this method.
From a theoretical perspective, it is important to
realize that our model does not commit us to a
morpheme-based approach of morphological pro-
cesses. This is obvious in task 1; and even if
task 2 aims at predicting a morphematic parse of in-
put lemmas, this goal is achieved without segment-
ing the input lemma into smaller units. For in-
stance, our learner parses the lemma enigmatically
as: [[[.N enigma][.A|N ical]]B|A. ly], that is with-
out trying to decide to which morph the orthographic
t should belong. In this model, input and output
spaces are treated symmetrically and correspond to
distinct levels of representation.
5 Discussion and future work
In this paper, we have presented a generic analog-
ical inference procedure, which applies to a wide
range of actual learning tasks, and we have detailed
its instantiation for common feature types. Prelimi-
nary experiments have been conducted on two mor-
phological analysis tasks and have shown promising
generalization performance.
These results suggest that our main hypotheses
are valid: (i) searching for triples is tractable even
with databases containing several hundred of thou-
sands instances; (ii) formal analogical proportions
are a reliable sign of deeper analogies between lin-
126
guistic entities; they can thus be used to devise flex-
ible and effective learners for NLP tasks.
This work is currently being developed in various
directions: first, we are gathering additional experi-
mental results on several NLP tasks, to get a deeper
understanding of the generalization capabilities of
our analogical learner. One interesting issue, not
addressed in this paper, is the integration of vari-
ous forms of linguistic knowledge in the definition
of analogical proportions, or in the specification of
the search procedure. We are also considering al-
ternative heuristic search procedures, which could
improve or complement the approaches presented in
this paper. A possible extension would be to define
and take advantage of non-uniform distributions of
training instances, which could be used both during
the searching and ranking steps. We finally believe
that this approach might also prove useful in other
application domains involving structured data and
are willing to experiment with other kinds of data.
References
David W. Aha. 1997. Editorial. Artificial Intelligence
Review, 11(1-5):7?10. Special Issue on Lazy Learn-
ing.
Gavin Burnage. 1990. CELEX: a guide for users. Tech-
nical report, University of Nijmegen, Center for Lexi-
cal Information, Nijmegen.
Walter Daelemans, Antal Van Den Bosch, and Jakub Za-
vrel. 1999. Forgetting exceptions is harmful in lan-
guage learning. Machine Learning, 34(1?3):11?41.
B.V. Dasarathy, editor. 1990. Nearest neighbor (NN)
Norms: NN Pattern Classification Techniques. IEEE
Computer Society Press, Los Alamitos, CA.
Brian Falkenheimer and Dedre Gentner. 1986. The
structure-mapping engine. In Proceedings of the meet-
ing of the American Association for Artificial Intelli-
gence (AAAI), pages 272?277.
Dedre Gentner, Keith J. Holyoak, and Boicho N.
Konikov, editors. 2001. The Analogical Mind. The
MIT Press, Cambridge, MA.
Douglas Hofstadter and the Fluid Analogies Research
group, editors. 1995. Fluid Concepts and Creative
Analogies. Basic Books.
Keith J. Holyoak and John E. Hummel. 2001. Under-
standing analogy within a biological symbol system.
In Dedre Gentner, Keith J. Holyoak, and Boicho N.
Konikov, editors, The analogical mind, pages 161?
195. The MIT Press, Cambridge, MA.
Yves Lepage. 1998. Solving analogies on words: An
algorithm. In Proceedings of COLING-ACL ?98, vol-
ume 2, pages 728?735, Montre?al, Canada.
Yves Lepage. 1999a. Analogy+tables=conjugation.
In G. Friedl and H.G. Mayr, editors, Proceedings of
NLDB ?99, pages 197?201, Klagenfurt, Germany.
Yves Lepage. 1999b. Open set experiments with direct
analysis by analogy. In Proceedings of NLPRS ?99,
volume 2, pages 363?368, Beijing, China.
Sylvain Lombardy, Raphae?l Poss, Yann Re?gis-Gianas,
and Jacques Sakarovitch. 2003. Introducing Vaucan-
son. In Proceedings of CIAA 2003, pages 96?107.
Andrei Mikheev. 1997. Automatic rule induction for
unknown word guessing. Computational Linguistics,
23(3):405?423.
Vito Pirrelli and Franc?ois Yvon. 1999. Analogy in the
lexicon: a probe into analogy-based machine learning
of language. In Proceedings of the 6th International
Symposium on Human Communication, Santiago de
Cuba, Cuba.
Tony A. Plate. 2000. Analogy retrieval and processing
with distributed vector representations. Expert sys-
tems, 17(1):29?40.
Jacques Sakarovitch. 2003. Ele?ments de the?orie des au-
tomates. Vuibert, Paris.
Royal Skousen. 1989. Analogical Modeling of Lan-
guage. Kluwer, Dordrecht.
Nicolas Stroppa and Franc?ois Yvon. 2005. Formal
models of analogical relationships. Technical report,
ENST, Paris, France.
Paul Thagard, Keith J. Holoyak, Greg Nelson, and David
Gochfeld. 1990. Analog retrieval by constraint satis-
faction. Artificial Intelligence, 46(3):259?310.
Antal van den Bosch and Walter Daelemans. 1999.
Memory-based morphological processing. In Pro-
ceedings of ACL, pages 285?292, Maryland.
D. Randall Wilson and Tony R. Martinez. 2000. Reduc-
tion techniques for instance-based learning algorithms.
Machine Learning, 38(3):257?286.
Franc?ois Yvon. 1999. Pronouncing unknown words us-
ing multi-dimensional analogies. In Proc. Eurospeech,
volume 1, pages 199?202, Budapest, Hungary.
Franc?ois Yvon. 2003. Finite-state machines solving
analogies on words. Technical report, ENST.
127
