Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 45?48, Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Multimodal Generation in the COMIC Dialogue System
Mary Ellen Foster and Michael White
Institute for Communicating and Collaborative Systems
School of Informatics, University of Edinburgh
{M.E.Foster,Michael.White}@ed.ac.uk
Andrea Setzer and Roberta Catizone
Natural Language Processing Group
Department of Computer Science, University of Sheffield
{A.Setzer,R.Catizone}@dcs.shef.ac.uk
Abstract
We describe how context-sensitive, user-
tailored output is specified and produced
in the COMIC multimodal dialogue sys-
tem. At the conference, we will demon-
strate the user-adapted features of the dia-
logue manager and text planner.
1 Introduction
COMIC1 is an EU IST 5th Framework project com-
bining fundamental research on human-human inter-
action with advanced technology development for
multimodal conversational systems. The project
demonstrator system adds a dialogue interface to a
CAD-like application used in bathroom sales situa-
tions to help clients redesign their rooms. The input
to the system includes speech, handwriting, and pen
gestures; the output combines synthesised speech, a
talking head, and control of the underlying applica-
tion. Figure 1 shows screen shots of the COMIC
interface.
There are four main phases in the demonstra-
tor. First, the user specifies the shape of their
own bathroom, using a combination of speech in-
put, pen-gesture recognition and handwriting recog-
nition. Next, the user chooses a layout for the sani-
tary ware in the room. After that, the system guides
the user in browsing through a range of tiling op-
tions for the bathroom. Finally, the user is given a
1COnversational Multimodal Interaction with Computers;
http://www.hcrc.ed.ac.uk/comic/.
three-dimensional walkthrough of the finished bath-
room. We will focus on how context-sensitive, user-
tailored output is generated in the third, guided-
browsing phase of the interaction. Figure 2 shows
a typical user request and response from COMIC in
this phase. The pitch accents and multimodal ac-
tions are indicated; there is also facial emphasis cor-
responding to the accented words.
The primary goal of COMIC?s guided-browsing
phase is to help users become better informed about
the range of tiling options for their bathroom. In
this regard, it is similar to the web-based system
M-PIRO (Isard et al, 2003), which generates per-
sonalised descriptions of museum objects, and con-
trasts with task-oriented embodied dialogue systems
such as SmartKom (Wahlster, 2003). Since guided
browsing requires extended descriptions, in COMIC
we have placed greater emphasis on producing high-
quality adaptive output than have previous embodied
dialogue projects such as August (Gustafson et al,
1999) and Rea (Cassell et al, 1999). To generate
its adaptive output, COMIC uses information from
the dialogue history and the user model throughout
the generation process, as in FLIGHTS (Moore et
al., 2004); both systems build upon earlier work on
adaptive content planning (Carenini, 2000; Walker
et al, 2002). An experimental study (Foster and
White, 2005) has shown that this adaptation is per-
ceptible to users of COMIC.
2 Dialogue Management
The task of the Dialogue and Action Manager
(DAM) is to decide what the system will show and
say in response to user input. The input to the
45
(a) Bathroom-design application (b) Talking head
Figure 1: Components of the COMIC interface
User Tell me about this design [click on Alt Mettlach]
COMIC [Look at screen]
THIS DESIGN is in the CLASSIC style.
[circle tiles]
As you can see, the colours are DARK RED and OFF WHITE.
[point at tiles]
The tiles are from the ALT METTLACH collection by VILLEROY AND BOCH.
[point at design name]
Figure 2: Sample COMIC input and output
DAM consists of multiple scored hypotheses con-
taining high-level, modality-independent specifica-
tions of the user input; the output is a similar high-
level specification of the system action. The DAM
itself is modality-independent. For example, the in-
put in Figure 2 could equally well have been the user
simply pointing to a design on the screen, with no
speech at all. This would have resulted in the same
abstract DAM input, and thus in the same output: a
request to show and describe the given design.
The COMIC DAM (Catizone et al, 2003) is
a general-purpose dialogue manager which can
handle different dialogue management styles such
as system-driven, user-driven or mixed-initiative.
The general-purpose part of the DAM is a sim-
ple stack architecture with a control structure;
all the application-dependent information is stored
in a variation of Augmented Transition Networks
(ATNs) called Dialogue Action Forms (DAFs).
These DAFs represent general dialogue moves, as
well as sub-tasks or topics, and are pushed onto and
popped off of the stack as the dialogue proceeds.
When processing a user input, the control struc-
ture decides whether the DAM can stay within the
current topic (and thus the current DAF), or whether
a topic shift has occurred. In the latter case, a new
DAF is pushed onto the stack and executed. After
that topic has been exhausted, the DAM returns to
the previous topic automatically. The same princi-
ple holds for error handling, which is implemented
at different levels in our approach.
In the guided-browsing phase of the COMIC sys-
tem, the user may browse tiling designs by colour,
style or manufacturer, look at designs in detail, or
change the amount of border and decoration tiles.
The DAM uses the system ontology to retrieve de-
signs according to the chosen feature, and consults
the user model and dialogue history to narrow down
the resulting designs to a small set to be shown and
described to the user.
46
3 Presentation Planning
The COMIC fission module processes high-level
system-output specifications generated by the DAM.
For the example in Figure 2, the DAM output indi-
cates that the given tile design should be shown and
described, and that the description must mention the
style. The fission module fleshes out such specifica-
tions by selecting and structuring content, planning
the surface form of the text to realise that content,
choosing multimodal behaviours to accompany the
text, and controlling the output of the whole sched-
ule. In this section, we describe the planning pro-
cess; output coordination is dealt with in Section 6.
Full technical details of the fission module are given
in (Foster, 2005).
To create the textual content of a description, the
fission module proceeds as follows. First, it gath-
ers all of the properties of the specified design from
the system ontology. Next, it selects the properties
to include in the description, using information from
the dialogue history and the user model, along with
any properties specifically requested by the dialogue
manager. It then creates a structure for the selected
properties and creates logical forms as input for the
OpenCCG surface realiser. The logical forms may
include explicit alternatives in cases where there are
multiple ways of expressing a property; for exam-
ple, it could say either This design is in the classic
style or This design is classic. OpenCCG makes use
of statistical language models to choose among such
alternatives. This process is described in detail in
(Foster and White, 2004; Foster and White, 2005).
In addition to text, the output of COMIC
also incorporates multimodal behaviours including
prosodic specifications for the speech synthesiser
(pitch accents and boundary tones), facial behaviour
specifications (expressions and gaze shifts), and de-
ictic gestures at objects on the application screen us-
ing a simulated pointer. Pitch accents and bound-
ary tones are selected by the realiser based on the
context-sensitive information-structure annotations
(theme/rheme; marked/unmarked) included in the
logical forms. At the moment, the other multimodal
coarticulations are specified directly by the fission
module, but we are currently experimenting with
using the OpenCCG realiser?s language models to
choose them, using example-driven techniques.
4 Surface Realisation
Surface realisation in COMIC is performed by the
OpenCCG2 realiser, a practical, open-source realiser
based on Combinatory Categorial Grammar (CCG)
(Steedman, 2000b). It employs a novel ensemble of
methods for improving the efficiency of CCG reali-
sation, and in particular, makes integrated use of n-
gram scoring of possible realisations in its chart re-
alisation algorithm (White, 2004; White, 2005). The
n-gram scoring allows the realiser to work in ?any-
time? mode?able at any time to return the highest-
scoring complete realisation?and ensures that a
good realisation can be found reasonably quickly
even when the number of possibilities is exponen-
tial. This makes it particularly suited for use in an
interactive dialogue system such as COMIC.
In COMIC, the OpenCCG realiser uses factored
language models (Bilmes and Kirchhoff, 2003) over
words and multimodal coarticulations to select the
highest-scoring realisation licensed by the grammar
that satisfies the specification given by the fission
module. Steedman?s (Steedman, 2000a) theory of
information structure and intonation is used to con-
strain the choice of pitch accents and boundary tones
for the speech synthesiser.
5 Speech Synthesis
The COMIC speech-synthesis module is imple-
mented as a client to the Festival speech-synthesis
system.3 We take advantage of recent advances in
version 2 of Festival (Clark et al, 2004) by using
a custom-built unit-selection voice with support for
APML prosodic annotation (de Carolis et al, 2004).
Experiments have shown that synthesised speech
with contextually appropriate prosodic features can
be perceptibly more natural (Baker et al, 2004).
Because the fission module needs the timing in-
formation from the speech synthesiser to finalise the
schedules for the other modalities, the synthesiser
first prepares and stores the waveform for its input
text; the sound is then played at a later time, when
the fission module indicates that it is required.
2http://openccg.sourceforge.net/
3http://www.cstr.ed.ac.uk/projects/festival/
47
6 Output Coordination
In addition to planning the presentation content as
described earlier, the fission module also controls
the system output to ensure that all parts of the pre-
sentation are properly coordinated, using the tim-
ing information returned by the speech synthesiser
to create a full schedule for the turn to be generated.
As described in (Foster, 2005), the fission module
allows multiple segments to be prepared in advance,
even while the preceding segments are being played.
This serves to minimise the output delay, as there is
no need to wait until a whole turn is fully prepared
before output begins, and the time taken to speak the
earlier parts of the turn can also be used to prepare
the later parts.
7 Acknowledgements
This work was supported by the COMIC project
(IST-2001-32311). This paper describes only part
of the work done in the project; please see http://
www.hcrc.ed.ac.uk/comic/ for full details. We
thank the other members of COMIC for their col-
laboration during the course of the project.
References
Rachel Baker, Robert A.J. Clark, and Michael White.
2004. Synthesizing contextually appropriate intona-
tion in limited domains. In Proceedings of 5th ISCA
workshop on speech synthesis.
Jeff Bilmes and Katrin Kirchhoff. 2003. Factored lan-
guage models and general parallelized backoff. In
Proceedings of HLT-03.
Giuseppe Carenini. 2000. Generating and Evaluating
Evaluative Arguments. Ph.D. thesis, Intelligent Sys-
tems Program, University of Pittsburgh.
Justine Cassell, Timothy Bickmore, Mark Billinghurst,
Lee Campbell, Kenny Chang, Hannes Vilhja?lmsson,
and Hao Yan. 1999. Embodiment in conversational
interfaces: Rea. In Proceedings of CHI99.
Roberta Catizone, Andrea Setzer, and Yorick Wilks.
2003. Multimodal dialogue management in the
COMIC project. In Proceedings of EACL 2003 Work-
shop on Dialogue Systems: Interaction, adaptation,
and styles of management.
Robert A.J. Clark, Korin Richmond, and Simon King.
2004. Festival 2 ? build your own general purpose
unit selection speech synthesiser. In Proceedings of
5th ISCA workshop on speech synthesis.
Berardina de Carolis, Catherine Pelachaud, Isabella
Poggi, and Mark Steedman. 2004. APML, a
mark-up language for believable behaviour generation.
In H Prendinger, editor, Life-like Characters, Tools,
Affective Functions and Applications, pages 65?85.
Springer.
Mary Ellen Foster and Michael White. 2004. Tech-
niques for text planning with XSLT. In Proceedings
of NLPXML-2004.
Mary Ellen Foster and Michael White. 2005. Assessing
the impact of adaptive generation in the COMIC multi-
modal dialogue system. In Proceedings of IJCAI-2005
Workshop on Knowledge and Reasoning in Practical
Dialogue Systems. To appear.
Mary Ellen Foster. 2005. Interleaved planning and out-
put in the COMIC fission module. Submitted.
Joakim Gustafson, Nikolaj Lindberg, and Magnus Lun-
deberg. 1999. The August spoken dialogue system.
In Proceedings of Eurospeech 1999.
Amy Isard, Jon Oberlander, Ion Androtsopoulos, and
Colin Matheson. 2003. Speaking the users? lan-
guages. IEEE Intelligent Systems, 18(1):40?45.
Johanna Moore, Mary Ellen Foster, Oliver Lemon, and
Michael White. 2004. Generating tailored, compara-
tive descriptions in spoken dialogue. In Proceedings
of FLAIRS 2004.
Mark Steedman. 2000a. Information structure and
the syntax-phonology interface. Linguistic Inquiry,
31(4):649?689.
Mark Steedman. 2000b. The Syntactic Process. MIT
Press.
Wolfgang Wahlster. 2003. SmartKom: Symmetric mul-
timodality in an adaptive and reusable dialogue shell.
In Proceedings of the Human Computer Interaction
Status Conference 2003.
M.A. Walker, S. Whittaker, A. Stent, P. Maloor, J.D.
Moore, M. Johnston, and G. Vasireddy. 2002. Speech-
plans: Generating evaluative responses in spoken dia-
logue. In Proceedings of INLG 2002.
Michael White. 2004. Reining in CCG chart realization.
In Proceedings of INLG 2004.
Michael White. 2005. Efficient realization of coordinate
structures in Combinatory Categorial Grammar. Re-
search on Language and Computation. To appear.
48
Multilingual Authoring: the NAMIC approach
R. Basili, M.T. Pazienza
F. Zanzotto
Dept. of Computer Science
University of Rome, Tor Vergata
Via di Tor Vergata,
00133 Roma
Italy
basili@info.uniroma2.it
pazienza@info.uniroma2.it
zanzotto@info.uniroma2.it
R. Catizone, A. Setzer
N. Webb, Y. Wilks
Department of Computer Science
University of Sheffield
Regent Court
211 Portobello Street,
Sheffield S1 4DP, UK
R.Catizone@dcs.shef.ac.uk
A.Setzer@dcs.shef.ac.uk
N.Webb@dcs.shef.ac.uk
Y.Wilks@dcs.shef.ac.uk
L. Padro?, G. Rigau
Dept. Llenguatges i Sistemes Informa`tics
Universitat Polite`cnica de Catalunya
Centre de Recerca TALP
Jordi Girona Salgado 1-3,
08034 Barcelona
Spain
padro@lsi.upc.es
g.rigau@lsi.upc.es
Abstract
With increasing amounts of elec-
tronic information available, and the
increase in the variety of languages
used to produce documents of the
same type, the problem of how to
manage similar documents in dif-
ferent languages arises. This pa-
per proposes an approach to process-
ing/structuring text so that Multi-
lingual Authoring (creating hyper-
text links) can be effectively car-
ried out. This work, funded by
the European Union, is applied to
the Multilingual Authoring of news
agency text. We have applied meth-
ods from Natural Language Process-
ing, especially Information Extrac-
tion technology, to both monolingual
and Multilingual Authoring.
1 Introduction
Modern Information Technologies are faced
with the problem of selecting, filtering and
managing growing amounts of multilingual
information to which access is usually criti-
cal. Traditional Information Retrieval (IR)
approaches are too general in their selection
of relevant documents where as traditional
Information Extraction (IE) (Gaizauskas and
Wilks, 1998; Pazienza, 1997) approaches are
too specific and inflexible. Automatic Au-
thoring is a good example of how these two
methods can be improved and used to cre-
ate a hypertextual organisation of (multilin-
gual) information. This kind of information
is ?added value? to the information embodied
in the text and is not in contrast with other
retrieval paradigms. Automatic Authoring
is the activity of processing news items in
streams, detecting and extracting relevant in-
formation from them and, accordingly, organ-
ising texts in a non-linear fashion.
While IE systems like the ones participat-
ing in the Message Understanding Conference
(MUC, 1998) are oriented towards specific
phenomena (e.g. joint ventures) in restricted
domains, the scope of Automatic Authoring
is wider. In Automatic Authoring, the hy-
pertextual structure has to provide naviga-
tion guidelines to the final user which can also
refuse the system suggestions.
In this paper an architecture for Automatic
Multilingual Authoring is presented based on
knowledge-intensive and large-scale Informa-
tion Extraction. The general architecture
is presented capitalising robust methods of
Information Extraction (Cunningham et al,
1999) and large-scale multilingual resources
(e.g. EuroWordNet). The system is de-
veloped within a European project in the
Human Language Technologies area, called
NAMIC (News Agencies Multilingual Infor-
mation Categorisation)1. It aims to extract
relevant facts from the news streams of large
European news agencies and newspaper pro-
ducers2, to provide hypertextual structures
within each (monolingual) stream and then
produce cross-lingual links between streams.
2 Authoring
2.1 Automatic Authoring
As Automatic Authoring is the task of au-
tomatically deriving a hypertextual structure
from a set of available news articles (in three
different languages English, Spanish and Ital-
ian in our case), the complexity of the overall
framework requires a suitable decomposition:
Text processing requires at least the de-
tection of morphosyntactic information char-
acterising the source texts: recognition, nor-
malisation, and assignment of roles is required
for the main participants for the different
events/facts described.
Event Matching is then the activity of
selecting the relevant facts of a news arti-
cle, in terms of their general type (e.g. sell-
ing or buying companies, winning a football
match), their participants and their related
roles (e.g. the company sold or the winning
football team).
Authoring is thus the activity of gener-
ating links between news articles according
to relationships established among facts de-
tected in the previous phase.
For instance, a company acquisition can be
referred to in one (or more) news items as:
? Intel, the world?s largest chipmaker,
bought a unit of Danish cable maker NKT
that designs high-speed computer chips ...
1See http://namic.itaca.it.
2EFE and ANSA, the major news agencies in Spain
and Italy respectively, and the Financial Times are all
members of the NAMIC consortium.
? The giant chip maker Intel said it ac-
quired the closely held ICP Vortex Com-
putersysteme, a German maker of sys-
tems ...
? Intel ha acquistato Xircom inc. per 748
milioni di dollari.
The hypothesis underlying Authoring is
that all the above news items deal with facts
in the same area of interest to a potential class
of readers. They should be thus linked and
links should suggest to the user that the un-
derlying motivation (used to decide whether
or not to follow an available link) is that they
all refer to Intel acquisitions.
Notice that a link generation process based
only upon words would fail in the above case
as the common word (that could play the role
of anchor in linking) is the proper noun Intel.
As no other information is available, the re-
sulting set of potential matches can be huge
and the connectivity too high.
In order to get the suitable links the equiv-
alence between the senses of bought and ac-
quired in the first two news items must be
known. Although such a relation can be
drawn by mechanisms like query expansion or
thesauri of synonyms (e.g. WordNet (Miller,
1990)), word polysemy and noise may re-
sult in an inherent proliferation of irrelevant
matches. Contextual information is critical
here. Notice that the senses of ?buy? and ?ac-
quire? are constrained by the role played by
Intel as ?agent ? and NKT or ICP Vortex be-
ing the sold companies. In fact, Intel buys
silicon represents an unwanted sense of the
verb and should be distinguished.
The relevant information concerning Intel
should be thus limited to:
? Intel buys a unit of NKT
? Intel acquires ICP Vortex.
These descriptions provide the core infor-
mation able to establish equivalence among
the underlying events. Whenever base event
descriptions are available the linking process
can be carried out via simpler equivalence in-
ferences. The Authoring problem is thus a
side effect of the overall language-processing
task.
According to the suggested decomposition
all the above steps are mandatory. First text
processing is responsible for morpho-syntactic
recognition. Morphological units and syntac-
tic relations are produced for each sentence at
this stage. However, syntactic relations (e.g.
among subjects and verbs) are not sufficient
for proper event characterisation. In the ex-
ample(s), the subject of the verb acquire is
a pronoun only anaphorically referring to In-
tel. Co-reference resolution is usually applied
to this kind of mismatch at the surface level.
This capability is under the responsibility of
the event matching phase. Moreover, in or-
der to keep track of events over syntactic rep-
resentations, references to a target ontology
are required. In such an ontology, equiva-
lence among facts (e.g. buying companies) is
represented. For instance, the relation among
buy and acquire can be encoded under a more
general notion of financial acquisition. On-
tologies also define the set of relevant facts of
the target domain. A financial acquisition is
a perfect example of what is needed in cor-
porate industrial news but is less important,
for example, in sports news, where hiring of
players seems a more relevant event class.
Conceptual differences among facts (de-
tected during event matching) motivate a se-
lective notion of hyperlinking. These links
can be thus generated during the automatic
authoring phase. They are ontologically jus-
tified as their conceptual representation is al-
ready available at this stage. Types as same
acquisition fact, same person, or company can
be used to distinguish links and make expla-
nations available to the user.
2.2 Multilingual Automatic
Authoring
?From a multilingual perspective, the prob-
lem is to establish links among news in dif-
ferent languages. Full-text approaches can
rely only on language independent phenom-
ena (e.g. proper nouns like Intel) that are
very limited in texts. Most of the above-
mentioned inferences require language neu-
tral information (i.e. conceptual and not lexi-
cal constraints). The inherent overgeneration
related to word polysemy affects the results
of translation-based approaches. Again prin-
cipled representations made available by IE
processes (i.e. templates) provide a viable
solution. The different event realisations (in
the different languages) can be handled dur-
ing the overall event matching. A lexical in-
terface to the ontology is able to factor the
language specific information. As syntactic
differences are handled during text process-
ing, the result is a common domain model for
IE plus independent lexical interfaces. The
unified representation of the set of facts ac-
tivates multilingual linking at a conceptual
level, thus making the Authoring a language
independent process. Some challenges of such
a framework are:
? the size of the ontological resources re-
quired in terms of taxonomic (i.e. IS A
relations) and conceptual information
(i.e. classes of events and implied
participant-event relations)
? the size of the lexical interfaces to the
ontology available for the different lan-
guages
? the amount of task dependent knowledge.
For example the definition of the set of
events useful for the target application is
underspecified.
In the following, we propose a complex ar-
chitecture where the above problems are
approached according to well-assessed tech-
niques presented elsewhere. Robust Informa-
tion Extraction is adopted (Humphreys et al,
1998) as an overall method for text process-
ing and event matching. Target events are
semiautomatically derived from domain texts
and represented in the IE engine ontology. Fi-
nally, multilinguality is realised by assuming a
large-scale multilingual lexical hierarchy as a
reference ontology for nominal concepts. The
resulting architecture for Multilingual Auto-
matic Authoring is presented in Section 3.4.
3 The NAMIC system
3.1 Large scale IE for Automatic
Authoring
Information Extraction is a very good ap-
proach to Automatic Authoring for a num-
ber of reasons. The key components of an IE
system are events and objects - the kind of
components that trigger hyperlinks in an Au-
thoring system. Coreference is a significant
part of Information Extraction and indeed a
necessary component in Authoring. Named
Entities - people, places, and organisations,
etc. - play an important part in Authoring
and again are firmly addressed in Information
Extraction systems.
The role of a world model as a method
for event matching and coreferencing
The world model is an ontological represen-
tation of events and objects for a particular
domain or set of domains. The world model
is made up of a set of event and object types,
with attributes. The event types characterise
a set of events in a particular domain and
are usually represented in a text by verbs.
Object Types on the other hand, are best
thought of as characterising a set of people,
places or things and are usually represented
in a text by nouns (both proper and com-
mon). When used as part of an Information
Extraction system, the instances of each type
are inserted/added to the world model. Once
the instances have been added, a procedure
is carried out to link those instances that re-
fer to the same thing - achieving coreference
resolution.
In NAMIC, the world model is created
using the XI cross-classification hierarchy
(Gaizauskas and Humphreys, 1996). The def-
inition of a XI cross-classification hierarchy is
referred to as an ontology, and this together
with an association of attributes with nodes
in the ontology forms the world model. Pro-
cessing a text acts to populate this initially
bare world model with the various instances
and relations mentioned in the text, convert-
ing it into a discourse model specific to the
particular text.
The attributes associated with nodes in
the ontology are simple attribute:value pairs
where the value may either be fixed, as in
the attribute animate:yes which is associ-
ated with the person node, or where the value
may be dependent on various conditions, the
evaluation of which makes reference to other
information in the model.
3.1.1 The Description of LaSIE
LaSIE is a Large-scale Information Ex-
traction system, developed for MUC (Mes-
sage Understanding Conference) competi-
tions, comprised of a variety of modules, see
(Humphreys et al, 1998; MUC, 1998). Al-
though we are not using the complete LaSIE
system in NAMIC, we are using 2 of the key
modules - the Named Entity Matcher and the
Discourse Processor. Below is a description of
each of these modules.
Named Entity Matcher The Named En-
tity Matcher finds named entities through
a secondary phase of parsing which uses a
named entity grammar and a set of gazetteer
lists. It takes as input parsed text from the
first phase of parsing and the named entity
grammar which contains rules for finding a
predefined set of named entities and a set of
gazetteer lists containing proper nouns. The
Name Entity Matcher returns the text with
the Named Entities marked. The Named En-
tities in NAMIC are PERSONS, ORGANI-
SATIONS, LOCATIONS, and DATES. The
Named Entity grammar contains rules for
coreferring abbreviations as well as different
ways of expressing the same named entity
such as Dr. Smith, John Smith and Mr.
Smith occurring in the same article.
Discourse Processor The Discourse Pro-
cessor module translates the semantic rep-
resentation produced by the parser into a
representation of instances, their ontolog-
ical classes and their attributes, in the
XI knowledge representation language (see
Gaizauskas(1996)). XI allows a straightfor-
ward definition of cross-classification hierar-
chies, the association of arbitrary attributes
with classes or instances, and a simple mech-
anism to inherit attributes from classes or in-
stances higher in the hierarchy.
The semantic representation produced by
the parser for a single sentence is processed
by adding its instances, together with their
attributes, to the discourse model which has
been constructed so far for the text.
Following the addition of the instances
mentioned in the current sentence, together
with any presuppositions that they inherit,
the coreference algorithm is applied to at-
tempt to resolve, or in fact merge, each of
the newly added instances with instances cur-
rently in the discourse model.
The merging of instances involves the re-
moval of the least specific instance (i.e. the
highest in the ontology) and the addition of
all its attributes to the other instance. This
results in a single instance with more than one
realisation attribute, which corresponds to a
single entity mentioned more than once in the
text, i.e. a coreference.
3.2 Ontological Modeling
As we have seen in section 3.1, some critical
issues of the NAMIC project rely on the per-
formance of the lexical and conceptual compo-
nents of all linguistic processors. As NAMIC
faces large-scale coverage of news in several
languages we decided to adopt EuroWordNet
(Vossen, 1998) as a common semantic formal-
ism to support:
? lexical semantic inferences (e.g. general-
isation, disambiguation)
? broad coverage (e.g. lexical and semanti-
cal) and
? a common interlingual platform for link-
ing events from different documents.
The NAMIC ontology consists of 40 prede-
fined object classes and 46 attribute types re-
lated to Name Entity objects and nearly 1000
objects relating to EuroWordNet base con-
cepts.
3.2.1 EuroWordNet as a Multilingual
Lexical Knowledge Base
Since the world model aims to describe the
language used in a given domain via events
and objects, the accuracy and breadth of the
model will impact how well the information
extraction works.
EuroWordNet (Vossen, 1998) is a multilin-
gual lexical knowledge base (LKB) with word-
nets for several European languages (Dutch,
Italian, Spanish, German, French, Czech and
Estonian). The wordnets are structured
in the same way as the American wordnet
for English developed at Princeton (Miller,
1990) containing synsets (sets of synonymous
words) with basic semantic relations between
them.
Each wordnet represents a unique
language-internal system of lexicalisa-
tions. In addition, the wordnets are linked
to an Inter-Lingual-Index (ILI), based on
the Princeton WordNet 1.5. WordNet 1.6 is
also connected to the ILI as another English
WordNet (Daude et al, 2000). Via this
index, the languages are interconnected so
that it is possible to go from the words in
one language to words in any other language
having similar meaning. The index also
gives access to a shared top-ontology and
a subset of 1024 Base Concepts (BC). The
Base Concepts provide a common seman-
tic framework for all the languages, while
language specific properties are maintained
in the individual wordnets. The LKB can
be used, among others, for monolingual and
cross-lingual information retrieval, which
has been demonstrated in other projects
(Gonzalo et al, 1998).
3.3 Multilingual Event description
The traditional limitations of a knowledge-
based information extraction system such as
LaSIE have been the need to hand-code in-
formation for the world model - specifically
relating to the event structure of the domain.
For the NAMIC project, we have decided
to semi-automate the process of adding new
?event descriptions? to the World Model. To
us, event descriptions can be categorised as a
set of regularly occurring verbs within our do-
main, complete with their subcategorisation
information.
These verbs can be extracted with simple
statistical techniques and are, for the moment
subjected to hand pruning. Once a list of
verbs has been extracted, subcategorisation
patterns can be generated automatically using
a Galois lattice (as described in (Basili et al,
2000b)). These frames can then be uploaded
into the event hierarchy of the discourse in-
terpreter world model.
The world model can have a structure
which is essentially language independent in
all but the lowest level - at which stage lexi-
calisations relating to each representative lan-
guage are required. Associated with these lex-
icalisations are language dependent scenario
rules which control the behaviour of instances
of these events with a Discourse Model. These
rules are expected to differ across languages in
the way they control coreference for languages
which are constrained to lesser or greater de-
gree.
The lattice generates patterns which refer
to synsets in the WordNet hierarchy. For
our purposes, we will use patterns referring to
Base Concepts in the EuroWordNet hierarchy
- which allows us to exploit the Inter-Lingual-
Index as described in the previous section.
These Base Concepts serve as a level of mul-
tilingual abstraction for the conceptual con-
straints of our events, and allow us to extend
the number of semantic classes from seven
(the MUC Named Entity classifications) to
1024 - the number of base concepts in EWN.
3.4 The NAMIC Architecture
The complexity of the overall NAMIC sys-
tem required the adoption of a distributed
computing paradigm in the design. The sys-
tem is a distributed object oriented system
where services (like text processing or Multi-
lingual Authoring) are provided by indepen-
dent components and asynchronous communi-
cation is allowed. Independent news streams
for the different languages (English, Spanish,
and Italian) are assumed. Language specific
processors (LPs) are thus responsible for text
processing and event matching in indepen-
dent text units in each stream. LPs com-
pile an objective representation (see Fig. 1)
for each source texts, including the detected
morphosyntactic information, categorisation
in news standards (IPTC classes) and descrip-
tion of the relevant events. Any later Au-
thoring activity is based on this canonical
representation of the news. In particular a
monolingual process is carried out within any
stream by the three monolingual Authoring
Engines (English AE, Spanish AE, and Ital-
ian AE). A second phase is foreseen to take
into account links across streams, i.e. multi-
lingual hyper-linking: a Multilingual Author-
ing Engine (M-AE) is here foreseen. Figure
1 represents the overall flow of information.
The Language Processors are composed of a
morphosyntactic (Eng, Ita and Spa MS) and
an event-matching component (EM). The lex-
ical interfaces (ELI, SLI and ItLI) to the uni-
fied Domain model are also used during event
matching.
The linguistic processors are in charge of
producing the objective representation of in-
coming news. This task is performed during
MS analysis by two main subprocessors:
? a modular and lexicalised shallow
morpho-syntactic parser (Basili et al,
2000c), providing name entity match-
ing and extracting dependency graphs
from source sentences. Ambiguity is
controlled by part-of-speech tagging and
domain verb-subcategorisation frames
that guide the dependency recognition
phase.
? a statistical linear text classifier based
upon some of the derived linguistic fea-
tures (Basili et al, 2000a) (lemmas, POS
tags and proper nouns)
The results are then input to the event
matcher that by means of the discourse in-
terpreter (Humphreys et al, 1998) derive the
objective representation. As discussed in sec-
tion 3.1, coreferencing is a side effect of the
discourse interpretation (Humphreys et al,
1998). It is based on the multilingual domain
model where relevant events are described and
nominal concepts represented.
The overall architecture is highly modular
and open to load balancing activity as well as
to adaptation and porting. The communica-
tion interfaces among the MS and EM com-
ponents as well as among the AEs and the M-
AE processors are specified via XML DTDs.
This allows for user-friendly uploading of a
back-end database with the detected material
as well as the easy design and management of
the front-end databases (available for tempo-
rary tasks, like event matching after MS). All
the servers are objects in a distributed archi-
tecture within a CORBA environment. The
current version includes the linguistic proces-
sors (MS and EM) for all the three languages.
The English and Italian linguistic processors
are fully object oriented modules based on
EnglishMS
SpanishMS
ItalianMS
EnglishAE
SpanishAE
ItalianAE
news ObjectiveRepresentation Monolingual Links
Multilingual Links
EnglishEM
SpanishEM
ItalianEM
DomainModel
ELI
SLI
ItLI
Multi-LingualAuthoringEngine
Language Processors
Figure 1: Namic Architecture
Java. They integrate libraries written in C,
C++, Prolog, and Perl for specific functional-
ities (e.g. parsing) running under a Windows
NT platform. The Spanish linguistic proces-
sor shares the discourse interpreter and the
text classifier with the other modules, while
the morpho syntactic component is currently
a Unix server based on Perl. The use of a dis-
tributed architecture under CORBA allowed
a flexible solution to its integration into the
overall architecture. The servers can be in-
stantiated in multiple copies throughout the
network if the amount of required computa-
tion exceeds the capability of a current con-
figuration. As the workload of a news stream
is not easily predictable, distribution and dy-
namic load balancing is the only realistic ap-
proach.
4 Discussion and Future Work
The above sections have provided the out-
line of a general NLP-based approach to auto-
matic authoring. The emphasis given to tra-
ditional capabilities of Information Extraction
depends on the relevance of news content in
the target Web service scenarios as well as
on their inherent multilinguality. The bet-
ter is the generalisation provided by the IE
component, the higher is the independence
from the text source language. As a result,
IE is here seen as a natural approach to cross-
lingual hypertextual authoring. Other works
in this area make extensive use of traditional
IR techniques (e.g. full text search) or rely
on already traced (i.e. manually coded) hy-
perlinks (e.g. (Chakrabarti et al, 1998; Klein-
berg, 1999)). The suggested NAMIC architec-
ture exploits linguistic capabilities for deriv-
ing entirely original (ex novo) resources, over
dynamic, previously unreleased, streams of in-
formation.
The result is a large-scale multilingual NLP
application capitalising existing methods and
resources within an advanced software engi-
neering process. The use of a distributed
Java/CORBA architecture makes the system
very attractive for its scalability and adaptiv-
ity. It results in a very complex (but realis-
tic) NLP architecture. Its organisation (lexi-
cal interfaces with respect to the multilingual
ontology) makes it very well suited for cus-
tomisation and porting to large domains. Al-
though the current version is a prototype, it
realises the complete set of core functionali-
ties, including the main IE steps and the dis-
tributed Java/CORBA layer.
It is worth noticing that a set of extensions
are made viable within the proposed architec-
ture. A first line is the extension of the avail-
able multilingual lexical knowledge. The Dis-
course Model can be used to better reflect on-
tological relationships within a particular do-
main. These relationships could be examined
to confirm known word sense usage as well
as to postulate/propose novel word sense us-
age. Using the mechanism for the addition of
events (as categorised by verbs) to the world
model, users can specify new events which can
be added to the IE system, to achieve User
Driven IE, and deliver a form of adaptive in-
formation extraction.
The instantiated domain models can be
thus used as a basis for ontological resource
expansion as a form of adaptive process.
For example, the stored instantiations of dis-
course models within a specific domain can be
compared: it may be thus possible to recog-
nise new sets of events or objects which are
not currently utilised within the system.
The evaluation strategy that is made possi-
ble within the NAMIC consortium will make
use of the current users (i.e. news agencies)
expertise. The agreed evaluation methods
will provide evidence about the viability of
the proposed large-scale IE-based approach to
authoring, as a valuable paradigm for infor-
mation access.
Acknowledgements
This research is funded by the European
Union, grant number IST-1999-12392. We
would also like to thank all of the partners
in the NAMIC consortium.
References
R. Basili, A. Moschitti, and M.T. Pazienza. 2000a.
Language sensitive text classification. In In
proceeding of 6th RIAO Conference (RIAO
2000), Content-Based Multimedia Information
Access, Coll ge de France, Paris, France.
R. Basili, M.T. Pazienza, and M. Vindigni. 2000b.
Corpus-driven learning of event recognition
rules. In Proc. of Machine Learning for Infor-
mation Extraction workshop, held jointly with
the ECAI2000, Berlin, Germany.
R. Basili, M.T. Pazienza, and F.M. Zanzotto.
2000c. Customizable modular lexicalized pars-
ing. In Proc. of the 6th International Workshop
on Parsing Technology, IWPT2000, Trento,
Italy.
S. Chakrabarti, B. Dom, D. Gibson, J. Kleinberg,
P. Raghavan, and S. Rajagopalan. 1998. Auto-
matic resource compilation by analysing hyper-
link structure and associated text. In Proceed-
ings of the 7th International World Wide Web
Conference, Brisbane, Australia.
C. Cunningham, R. Gaizauskas, K. Humphreys,
and Y. Wilks. 1999. Experience with a lan-
guage engineering architecture: 3 years of gate.
In Proceedings of the AISB?99 Workshop on
Reference Architectures and Data Standards for
NLP, Edinburgh, UK.
J. Daude, L. Padro, and G. Rigau. 2000. Map-
ping wordnets using structural information.
In Proceedings of the 38th Annual Meeting of
the Association for Computational Linguistics
ACL?00, Hong Kong, China.
R. Gaizauskas and K. Humphreys. 1996. Xi:
A simple prolog-based language for cross-
classification and inheritance. In Proceedings of
the 6th International Conference on Artificial
Intelligence: Methodologies, Systems, Applica-
tions (AIMSA96), pages 86?95.
R. Gaizauskas and Y. Wilks. 1998. Information
Extraction: Beyond Document Retrieval. Jour-
nal of Documentation, 54(1):70?105.
J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigar-
ran. 1998. Indexing with wordnet synsets
can improve text retrieval. In Proceedings of
the COLING/ACL?98 Workshop on Usage of
WordNet for NLP, Montreal, Canada.
K. Humphreys, R. Gaizauskas, S. Azzam,
C. Huyck, B. Mitchell, H. Cunningham, and
Y. Wilks. 1998. University of sheffield: De-
scription of the lasie-ii system as used for muc-7.
In Proceedings of the Seventh Message Under-
standing Conferences (MUC-7). Morgan Kauf-
man. Available at http://www.saic.com.
Jon M. Kleinberg. 1999. Authoritative sources
in a hyperlinked environment. Journal of the
ACM, 46(5):604?632.
G. Miller. 1990. Five papers on wordnet. Inter-
national Journal of Lexicography, 4(3).
1998. Proceedings of the Seventh Message Under-
standing Conference (MUC-7). Morgan Kauf-
man. Available at http://www.saic.com.
M.T. Pazienza, editor. 1997. Information Ex-
traction. A Multidisciplinary Approach to an
Emerging Information Technology. Number
1299 in LNAI. Springer-Verlag, Heidelberg,
Germany.
P. Vossen. 1998. EuroWordNet: A Multilin-
gual Database with Lexical Semantic Networks.
Kluwer Academic Publishers, Dordrecht.
Knowledge-Based Multilingual Document Analysis
R. Basili
 
and R. Catizone  and L. Padro  and M.T. Pazienza  
G. Rigau  and A. Setzer  and N. Webb 
F. Zanzotto
 
 
Dept. of Computer Science, Systems and Production
University of Rome, Tor Vergata
Via di Tor Vergata
00133 Roma, Italy
basili, pazienza, zanzotto@info.uniroma2.it
 Department of Computer Science
University of Sheffield
Regent Court, 211 Portobello Street
Sheffield S1 4DP, UK
R.Catizone, A.Setzer, N.Webb@dcs.shef.ac.uk
 Departament de Llenguatges i Sistemes Informatics
Universitat Politecnica de Catalunya
Centre de Recerca TALP
Jordi Girona Salgado 1-3
08034 Barcelona, Spain
l.padro, g.rigau@lsi.upc.es
Abstract
The growing availability of multilingual resources,
like EuroWordnet, has recently inspired the develop-
ment of large scale linguistic technologies, e.g. mul-
tilingual IE and Q&A, that were considered infeasi-
ble until a few years ago. In this paper a system
for categorisation and automatic authoring of news
streams in different languages is presented. In our
system, a knowledge-based approach to Information
Extraction is adopted as a support for hyperlinking.
Authoring across documents in different languages
is triggered by Named Entities and event recogni-
tion. The matching of events in texts is carried out
by discourse processing driven by a large scale world
model. This kind of multilingual analysis relies on a
lexical knowledge base of nouns(i.e. the EuroWord-
net Base Concepts) shared among English, Spanish
and Italian lexicons. The impact of the design choices
on the language independence and the possibilities it
opens for automatic learning of the event hierarchy
will be discussed.
1 Introduction
Modern information technologies are faced with the
problem of selecting, filtering, linking and manag-
ing growing amounts of multilingual information to
which access is usually critical. Our work is moti-
vated by the linking of multilingual information in a
wide range of domains. Although this problem ap-
pears to be directly related to the Information Re-
trieval task, we aimed to link articles, not in the broad
sense of clustering documents related to the same
topic, but rather more specifically linking particular
pieces of information together from different docu-
ments. Furthermore, we found that IE research, al-
though appropriate for our task, was not designed for
the scale/variety of different domains that we needed
to process. In general, creating the world model nec-
essary for the addition of a new domain to an IE sys-
tem is a time-consuming process. As such, we de-
signed an IE system that could be semi-automatically
and easily adapted to new domains - a process we will
refer to as large scale IE. The key to creating new
world models relied on incorporating large amounts
of domain knowledge. As a result we selected Eu-
roWordnet as our base knowledge source. EuroWord-
net has the advantages of 1) providing the foundation
for broad knowledge across many domains and 2) is
multilingual in nature. In this paper, we will explain
how our system works, how the knowledge base was
incorporated and a discussion of other applications
that could make use of the same technology.
2 The Application
In the 5th Framework NAMIC Project (News Agen-
cies Multilingual Information Categorisation), the de-
fined task of the system was to support the automatic
authoring of multilingual news agencies texts where
the chosen languages were English, Italian and Span-
ish. The goal was the Hypertextual linking of related
articles in one language as well as related articles in
the other project languages. One of the intermediate
goals of NAMIC was to categorise incoming news ar-
ticles, in one of the three target languages and use
Natural Language Technology to derive an ?objec-
tive representation? of the events and agents contained
within the news. This representation which is ini-
tially created once using representative news corpora
is stored in a repository and accessed in the authoring
process.
2.1 Automatic Authoring
Automatic Authoring is the task of automatically de-
riving a hypertextual structure from a set of available
news articles (in three different languages English,
Spanish and Italian in our case). This relies on the ac-
tivity of event matching. Event matching is the pro-
cess of selecting the relevant facts in a news article
in terms of their general type (e.g. selling or buying
companies, winning a football match), their partici-
pants and their related roles (e.g. the company sold or
the winning football team) Authoring is the activity
of generating links between news articles according
to relationships established among facts detected in
the previous phase.
For instance, a company acquisition can be referred
to in one (or more) news items as:
 Intel, the world?s largest chipmaker, bought a
unit of Danish cable maker NKT that designs
high-speed computer chips used in products that
direct traffic across the internet and corporate
networks.
 The giant chip maker Intel said it acquired the
closely held ICP Vortex Computersysteme, a
German maker of systems for storing data on
computer networks, to enhance its array of data-
storage products.
 Intel ha acquistato Xircom inc. per 748 milioni
di dollari.
 Le dichiarazioni della Microsoft, infatti, sono
state precedute da un certo fermento, dovuto
all?interesse verso Linux di grandi ditte quali
Corel, Compaq e non ultima Intel (che ha ac-
quistato quote della Red Hat) ...
The hypothesis underlying Authoring is that all the
above news items deal with facts in the same area of
interest to a potential class of readers. They should be
thus linked and links should suggest to the user that
the underlying motivation is that they all refer to Intel
acquisitions.
3 The NAMIC Architecture
The NAMIC system uses a modularised IE architec-
ture whose principal components, used to create the
IE repository, are morpho-syntactic analysis, cate-
gorisation and semantic analysis. During Morpho-
Syntactic analysis, a modular and lexicalised shal-
low morpho-syntactic parser (Basili et al, 2000b),
provides the extraction of dependency graphs from
source sentences. Ambiguity is controlled by part-
of-speech tagging and domain verb-subcategorisation
frames that guide the dependency recognition phase.
It is within the semantic analysis, which relies on the
output of this parser, that objects in the text, and their
relationships to key events are captured. This process
is explained in more detail in 4. In the next two sec-
tions, we will elaborate on the IE engine. For a full
description of the NAMIC Architecture see (Basili et
al., 2001).
3.1 LaSIE
In NAMIC, we have integrated a key part of the Infor-
mation Extraction system called LaSIE (Large-scale
Information Extraction system, (Humphreys et al,
1998)). Specifically, we have taken the Named Entity
Matcher and the Discourse Processor from the over-
all architecture of LaSIE. The roles of each of these
modules is outlined below.
3.1.1 Named Entity Matcher
The Named Entity (NE) Matcher finds named enti-
ties (persons, organisations, locations, and dates, in
our case) through a secondary phase of parsing which
uses a NE grammar and a set of gazetteer lists. It takes
as input parsed text from the first phase of parsing and
the NE grammar which contains rules for finding a
predefined set of named entities and a set of gazetteer
lists containing proper nouns. The NE Matcher re-
turns the text with the Named Entities marked. The
NE grammar contains rules for coreferring abbrevia-
tions as well as different ways of expressing the same
named entity such as Dr. Smith, John Smith and Mr.
Smith occurring in the same article.
3.1.2 Discourse Processor
The Discourse Processor module translates the se-
mantic representation produced by the parser into a
representation of instances, their ontological classes
and their attributes, in the XI knowledge representa-
tion language (Gaizauskas and Humphreys, 1996).
XI allows a straightforward definition of cross-
classification hierarchies, the association of arbitrary
attributes with classes or instances, and a simple
mechanism to inherit attributes from classes or in-
stances higher in the hierarchy.
The semantic representation produced by the
parser for a single sentence is processed by adding
its instances, together with their attributes, to the dis-
course model which has been constructed for a text.
Following the addition of the instances mentioned
in the current sentence, together with any presuppo-
sitions that they inherit, the coreference algorithm is
applied to attempt to resolve, or in fact merge, each
of the newly added instances with instances currently
in the discourse model.
The merging of instances involves the removal of
the least specific instance (i.e. the highest in the on-
tology) and the addition of all its attributes to the other
instance. This results in a single instance with more
than one realisation attribute, which corresponds to a
single entity mentioned more than once in the text,
i.e. a coreference.
The mechanism described here is an extremely
powerful tool for accomplishing the IE task, however,
in common with all knowledge-based approaches,
and as highlighted in the introduction to this paper,
the significant overhead in terms of development and
deployment is in the creation of the world model rep-
resentation.
4 Large-Scale World Model Acquisition
The traditional limitations of a knowledge-based in-
formation extraction system such as LaSIE have been
the need to hand-code information for the world
model - specifically relating to the event structure of
the domain. This is also valid for NAMIC. To aid the
development of the world model, a semi-automatic
boot-strapping process has been developed, which
creates the event type component of the world model.
To us, event descriptions can be categorised as a set
of regularly occurring verbs within our domain, com-
plete with their subcategorisation information.
4.1 Event Hierarchy
The domain verbs can be selected according to sta-
tistical techniques and are, for the moment, subjected
to hand pruning. Once a list of verbs has been ex-
tracted, subcategorisation patterns can be generated
automatically using a combination of weakly super-
vised example-driven machine learning algorithms.
There are mainly three induction steps. First, syn-
tactic properties are derived for each verb, express-
ing the major subcategorisation information under-
lying those verbal senses which are more important
in the domain. Then, in a second phase, verb usage
examples are used to induce the semantic properties
of nouns in argumental positions. This information
relates to selectional constraints, independently as-
signed to each verb subcategorisation pattern. Thus,
different verb senses are derived, able to describe the
main properties of the domain events (e.g. Compa-
nies acquire companies). In a third and final phase
event types are derived by grouping verbs accord-
ing to their syntactic-semantic similarities. Here,
shared properties are used to generalise from the lex-
ical level, and generate verbal groups expressing spe-
cific semantic (and thus conceptual) aspects. These
types are then fed into the event hierarchy as required
for their straightforward application within the target
IE scenario.
4.1.1 Acquisition of Subcategorisation Patterns
Each verb  is separately processed. First, each local
context (extracted from sentences in the source cor-
pus) is mapped into a feature vector describing:
 the verb  of each vector (i.e. the lexical head of
the source clause);
 the different grammatical relationships (e.g.
Subj and Obj for grammatical subject and ob-
jects respectively) as observed in the clause;
 the lexical items, usually nouns, occurring in
specific grammatical positions, e.g. the subject
Named Entity, in the clause.
Then, vectors are clustered according to the set of
shared grammatical (not lexical) properties: Only the
clauses showing the same relationships (e.g. all the
Subj- 
	 -Obj triples) enter in the same subset  .
Each cluster thus expresses a specific grammatical be-
haviour shared by several contexts (i.e. clauses) in the
corpus. The shared properties in  characterise the
cluster, as they are necessary and sufficient member-
ship conditions for the grouped contexts.
As one context can enter in more than one cluster
(as it can share all (or part) of its relations with the
others), the inclusion property establishes a natural
partial order among clusters. A cluster  is included
in another cluster  if its set of properties is larger
(i.e.  ) but it is shown only by a subset of the
contexts of the latter   . The larger the set of mem-
bership constraints is, the smaller the resulting cluster
is. In this way, clusters are naturally organised into
a lattice (called Galois lattice). Complete properties
express for each cluster candidate subcategorisation
patterns for the target verb  .
Finally, the lattice is traversed top-down and the
search stops at the more important clusters (i.e. those
showing a large set of members and characterised
by linguistically appealing properties): they are re-
tained and a lexicon of subcategorisation structures
(i.e. grammatical patterns describing different us-
ages of the same verb) is compiled for the target verb
 . For example, (buy, [Subj:X, Obj:Y]) can
be used to describe the transitive usage of the verb
	 . More details can be found in (Basili et al, 1997).
4.1.2 Corpus-driven Induction of Verb
Selectional Restrictions
The lattice can be further refined to express seman-
tic constraints over the syntactic patterns specified at
the previous stage. A technique proposed in (Basili
et al, 2000a) is adopted by deriving semantic con-
straints via synsets (i.e. synonymy sets) in the Word-
Net 1.6 base concepts (part of EuroWordNet). When
a given lattice node expresses a set of syntactic prop-
erties, then this suggests:
 a set of grammatical relations necessary to ex-
press a given verb meaning, Proceedings of the ACL 2010 System Demonstrations, pages 72?77,
Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics
Demonstration of a prototype for a Conversational Companion for  reminiscing about images  Yorick Wilks IHMC, Florida ywilks@ihmc.us Roberta Catizone University of Sheffield, UK r.catizone@dcs.shef.ac.uk Alexiei Dingli University of Malta, Malta alexiei.dingli@um.edu.mt Weiwei Cheng University of Sheffield, UK w.cheng@dcs.shef.ac.uk  Abstract 
This paper describes an initial prototype demonstrator of a Companion, designed as a platform for novel approaches to the following:  1) The use of Informa-tion Extraction (IE) techniques to extract the content of incoming dialogue utterances after an Automatic Speech Recognition (ASR) phase, 2) The conversion of the input to Resource Descriptor Format (RDF)  to allow the generation of new facts from existing ones, under the control of a Dialogue Manger (DM), that also has access to stored knowledge and to open knowledge accessed in real time from the web, all in RDF form, 3) A DM implemented as a stack and net-work virtual machine that models mixed initiative in dialogue control, and 4) A tuned dialogue act detector based on corpus evidence. The prototype platform was evaluated, and we describe this briefly; it is also designed to support more extensive forms of emotion detection carried by both speech and lexical content, as well as extended forms of machine learning. 1. Introduction This demonstrator Senior Companion (SC) was built during the initial phase of the Companions project and  aims to change the way we think about the relationships of people to computers and the internet by developing a virtual conver-sational 'Companion that will be an agent or 'presence' that stays with the user for long peri-ods of time, developing a relationship and 'know-ing its owners? preferences and wishes. The Companion communicates with the user primar-ily through speech, but also using other tech-nologies such as touch screens and sensors. This paper describes the functionality and system modules of the Senior Companion, one of two initial prototypes built in the first two years of the project. The SC provides a multimodal inter-face for eliciting, retrieving and inferring per-sonal information from elderly users by means of conversation about their photographs. The Com-panion, through conversation, elicits life memo-
ries and reminiscences, often prompted by dis-cussion of their photographs; the aim is that the Companion should come to know a great deal about its user, their tastes, likes, dislikes, emo-tional reactions etc, through long periods of con-versation. It is assumed that most life informa-tion will soon be stored on the internet (as in the Memories for Life project: http://www.memoriesforlife.org/) and we have linked the SC directly to photo inventories in Facebook (see below). The overall aim of the SC project (not yet achieved) is to produce a coher-ent life narrative for its user from conversations about personal photos, although its short-term goals, reported here, are to assist, amuse and en-tertain the user.  The technical content of the project is to use a number of types of machine learning  (ML) to achieve these ends in original ways, initially us-ing a methodology developed in earlier research: first, by means of an Information Extraction (IE) approach to deriving content from user input ut-terances; secondly, using a training method for attaching Dialogue Acts to these utterance and, lastly, using a specific type of dialogue manager (DM) that uses Dialogue Action Forms  (DAF) to determine the context of any utterance. A stack of these DAFs is the virtual machine that models the ongoing dialogue by means of shared user and Companion initiative and generates ap-propriate responses. In this description of the demo, we shall: 
? describe the current SC prototype?s func-tionality; 
? set out its architecture and modules, fo-cusing on the Natural Language Under-standing module and the Dialogue Man-ager. A mini-version of the demo running in real time can be seen at:  URL   
72
http://www.youtube.com/watch?v=-Xx5hgjD-Mw 2. The Senior Companion System The Senior Companion prototype (Wilks, 2010)  was designed to make a rapid advance in the first two years of the project so as to be basis for a second round of prototypes embodying more advanced ML. This strategy was deliberately chosen to avoid a well-known problem with ex-perimental AI systems: that a whole project is spent in design so that a prototype never emerges until the very end, but which is then never fully evaluated and, most importantly, nothing is ever built on the experience obtained in its construc-tion. The central function of the SC is engaging the user in discussion about their photographs: where and when they were taken, details about the people in them and their relationship to the user and each other.  Once a photo is loaded, it is processed with face recognition software to identify any faces in it. The recognition software, OpenCV, provides positional information by identifying the face coordinates and this information is exploited in the Dialogue Manager by making explicit refer-ence to the position of people in the photograph (the person on the left, right, center, etc.) as well as recognizing when there are groups of people. The system discusses properties of the photo as well as properties and relationships of the people in the photos.   The news reading feature adds an interesting ac-companiment to the photo domain and demon-strates the ability of the system to handle more than one kind of application at a time, and news has, of course, an unconstrained vocabulary. The following is a fairly typical example of its cur-rent capacity, depending of course on the images loaded, and comes from the middle part of a sample dialogue generated by the system when discussing a group photo from a vacation in Zan-zibar, and after the system had already stored, from an earlier conversation, that the user has a daughter Zoe (using researchers? children to avoid any problems):  SC: What is your relationship to the doctor? User: There is no relationship. SC: Please tell me how you know the doctor U: Uh, he's a friend. SC: How old was the doctor when this photo was taken? U: I'm not sure but I think about 30. 
SC: How do you know Octavia? U: She's my daughter. SC: Aha! I see. Octavia's sister is Zoe. SC: How old was your daughter Octavia when this photo was taken? U: Octavia was 19 years old. SC: What was the occasion of this photo? U: This was another family holiday. SC: Where was this photo taken? U: This photo was taken in Tanzania. SC: have you ever been to Zanzibar? U: Yes, I have. SC: Great place, I hope you saw the beaches. When was this photo taken? U: last year.  It is a key feature of the SC that it can make sim-ple inferences from family relationships it al-ready knows (e.g. that daughters of the same par-ent are siblings) and that it can access real-time information about places to show that it has some knowledge of what is being talked about, in this case the beaches on Zanzibar, and how this is done is discussed below. This real time access to unconstrained place information on the internet is an attempt to break out of classic AI systems that only know the budget of facts they have been primed with.  This basic system provides the components for future development of the SC, as well as its main use as a device to generate more conversation data for machine learning research in the future. Key features of the SC are listed below followed by a description of the system architecture and modules. The SC: ? Contains a visually appealing multi-modal interface with a character avatar to mediate the system?s functionality to the user. ? Interacts with the user using multiple modalities ? speech and touch. ? Includes face detection software for identifying the position of faces in the photos. ? Accepts pre-annotated (XML) photo in-ventories as a means for creating richer dialogues more quickly.  ? Engages in conversation with the user about topics within the photo domain: when and where the photo was taken, discussion of the people in the photo in-cluding their relationships to the user. ? Reads news from three categories: poli-tics, business and sports. 
73
? Tells jokes taken from an internet-based  joke website. ? Retains all user input for reference in re-peat user sessions, in addition to the knowledge base that has been updated by the Dialogue Manager on the basis of what was said. ? Contains a fully integrated Knowledge Base for maintaining user information including: o Ontological information which is exploited by the Dialogue Manager and provides domain-specific relations between fun-damental concepts.  o A mechanism for storing infor-mation in a triple store (Subject-Predicate-Object) - the RDF Semantic Web format - for han-dling unexpected user input that falls outside of the photo do-main, e.g. arbitrary locations in which photos might have been taken. o A reasoning module for reason-ing over the Knowledge Base and world knowledge obtained in RDF format from the internet; the SC is thus a primitive Se-mantic Web device (see refernce8, 2008) ? Contains basic photo management capa-bility allowing the user, in conversation, to select photos as well as display a set of photos with a particular feature.  
 Figure 1: The Senior Companion Interface 
 3. System Architecture  In this section we will review the components of the SC architecture. As can be seen from Figure 2, the architecture contains three abstract level components ? Connectors, Input Handlers and Application Services ?together with the Dialogue Manager and the Natural Language Understander (NLU). 
  Figure 2: Senior Companion system architecture  Connectors form a communication bridge be-tween the core system and external applications. The external application refers to any modules or systems which provide a specific set of function-alities that might be changed in the future. There is one connector for each external application. It hides the underlying complex communication protocol details and provides a general interface for the main system to use. This abstraction de-couples the connection of external and internal modules and makes changing and adding new external modules easier. At this moment, there are two connectors in the system ? Napier Inter-face Connector and CrazyTalk Avatar Connec-tor. Both of them are using network sockets to send/receive messages.  Input Handlers are a set of modules for process-ing messages according to message types. Each handler deals with a category of messages where categories are coarse-grained and could include one or more message types. The handlers sepa-rate the code handling inputs into different places and make the code easier to locate and change. Three handlers have been implemented in the Senior Companion system ? Setup Handler, Dragon Events Handler and General Handler. The Setup Handler is responsible for loading the photo annotations if any, performing face detec-tion if no annotation file is associated with the photo and checking the Knowledge Base in case 
74
the photo being processed has been discussed in earlier sessions. Dragon Event Handler deals with dragon speech recognition commands sent from the interface while the General Handler processes user utterances and photo change events of the interface.  Application Services are a group of internal modules which provide interfaces for the Dia-logue Action Forms (DAF) to use. It has an easy-to-use high-level interface for general DAF de-signers to code associated tests and actions as well as a low level interface for advanced DAFs. It also provides the communication link between DAFs and the internal system and enables DAFs to access system functionalities. Following is a brief summary of modules grouped into Applica-tion Services.  News Feeders are a set of RSS Feeders for fetch-ing news from the internet. Three different news feeders have been implemented for fetching news from BBC website Sports, Politics and Business channels. There is also a Jokes Feeder to fetch Jokes from internet in a similar way. During the conversation, the user can request news about particular topics and the SC simply reads the news downloaded through the feeds.  The DAF Repository is a list of DAFs loaded from files generated by the DAF Editor.   The Natural Language Generation (NLG) mod-ule is responsible for randomly selecting a sys-tem utterance from a template. An optional vari-able can be passed when calling methods on this module. The variable will be used to replace spe-cial symbols in the text template if applicable.   Session Knowledge is the place where global information for a particular running session is stored. For example, the name of the user who is running the session, the list of photos being dis-cussed in this session and the list of user utter-ances etc.  The Knowledge Base is the data store of persis-tent knowledge. It is implemented as an RDF triplestore using a Jena implementation. The tri-plestore API is a layer built upon a traditional relational database. The application can save/retrieve information as RDF triples rather than table records. The structure of knowledge represented in RDF triples is discussed later.  
The Reasoner is used to perform inference on existing knowledge in the Knowledge Base (see example in next section).  The Output Manager deals with sending mes-sages to external applications. It has been im-plemented in a publisher/subscriber fashion. There are three different channels in the system: the text channel, the interface command channel and the avatar command channel. Those chan-nels could be subscribed to by any connectors and handled respectively.  4. Dialogue understanding and inference Every utterance is passed through the Natural Language Understanding (NLU) module for processing. This module uses a set of well-established natural language processing tools such as those found in the GATE (Cunningham, et al, 1997) system. The basic processes carried out by GATE are: tokenizing, sentence splitting, POS tagging, parsing and Named Entity Recog-nition. These components have been further en-hanced for the SC system by adding 1) new and improved gazetteers including family relations and 2) accompanying extraction rules .The Named Entity (NE) recognizer is a key part of the NLU module and recognizes the significant entities required to process dialogue in the photo domain: PERSON NAMES, LOCATION NAMES, FAMILY RELATIONS and DATES. Although GATE recognizes basic entities, more complex entities are not handled. Apart from the gazetteers mentioned earlier and the hundreds of extraction rules already present in GATE, about 20 new extraction rules using the JAPE rule lan-guage were also developed for the SC module. These included rules which identify complex dates, family relationships, negations and other information related to the SC domain. The fol-lowing is an example of a simple rule used to identify relationship in utterances such as ?Mary is my sister?:  Macro: RELATIONSHIP_IDENTIFIER ( ({To-ken.category=="PRP$"}|{Token.category=="PRP"}|{Lookup.majorType=="person_first"}):person2 ({Token.string=="is"}) ({Token.string=="my"}):person1  ({Lookup.minorType=="Relationship"}):relationship) 
75
Using this rule with the example mentioned ear-lier, the rule interprets person1 as referring to the speaker so, if the name of the user speaking is John (which was known from previous conversa-tions), it is utilized. Person 2 is then the name of the person mentioned, i.e. Mary. This name is recognised by using the gazetteers we have in the system (which contain about 40,000 first names). The relationship is once again identified using the almost 800 unique relationships added to the gazetteer.  With this information, the NLU mod-ule identifies Information Extraction patterns in the dialogue that represent significant content with respect to a user's life and photos.   The information obtained (such as Mary=sister-of John) is passed to the Dialogue Manager (DM) and then stored in the knowledge base (KB). The DM filters what to include and ex-clude from the KB. Given, in the example above, that Mary is the sister of John, the NLU knows that sister is a relationship between two people and is a key relationship. However, the NLU also discovers syntactical information such as the fact the both Mary and John are nouns. Even though this information is important, it is too low level to be of any use by the SC with respect to the user, i.e. the user is not interested in the parts-of-speech of a word. Thus, this information is dis-carded by the DM and not stored in the KB. The NLU module also identifies a Dialogue Act Tag for each user utterance based on the DAMSL set of DA tags and prior work done jointly with the University of Albany (Webb et al, 2008).  The KB is a long-term store of information which makes it possible for the SC to retrieve information stored between different sessions. The information can be accessed anytime it is needed by simply invoking the relevant calls. The structure of the data in the database is an RDF triple, and the KB is more commonly re-ferred to as a triple store. In mathematical terms, a triple store is nothing more than a large data-base of interconnected graphs. Each triple is made up of a subject, a predicate and an object. So, if we took the previous example, Mary sister-of John; Mary would be the subject, sister-of would be the predicate and John would be the object. The inference engine is an important part of the system because it allows us to discover new facts beyond what is elicited from the con-versation with the user.    
Uncle Inference Rule:   (?a sisterOf ?b), (?x sonOf ?a), (?b gender male) -> (?b uncleOf ?x)    Triples: (Mary  sisterOf  John) (Tom   sonOf   Mary)  Triples produced automatically by ANNIE (the semantic tagger): (John  gender   male)  Inference: (Mary  sisterOf  John) (Tom   sonOf   Mary) (John  gender   male)  ->  (John uncleOf Tom)  This kind of inference is already used by the SC and we have about 50 inference rules aimed at producing new data on the relationships domain. This combination of triple store, inference engine and inference rules makes a system which is weak but powerful enough to mimic human rea-soning in this domain and thus simulate basic intelligence in the SC. For our prototype, we are using the JENA Semantic Web Framework for the inference engine together with a MySQL da-tabase as the knowledge base. However, this sys-tem of family relationships is not enough to cover all the possible topics which can crop up during a conversation and, in such circum-stances, the DM switches to an open-world model and instructs the NLU to seek further in-formation online.  5. The Hybrid-world approach When the DM requests further information on a particular topic, the NLU first checks with the KB whether the topic is about something known. At this stage, we have to keep in mind that any topic requested by the DM should be already in the KB since it was preprocessed by the NLU when it was mentioned in the utterance. So, if the user informs the system that the photograph was taken in Paris, (in response to a system question asking where the photo was taken), the utterance is first processed by the NLU which discovers that ?Paris? is a location using its semantic tag-ger ANNIE (A Nearly New Information Extrac-tion engine). The semantic tagger makes use of gazetteers and IE rules in order to accomplish 
76
this task. It also goes through the KB and re-trieves any triples related to ?Paris?. Inference is then performed on this data and the new informa-tion generated by this process is stored back in the KB.   Once the type of information is identified, the NLU can use various predefined strategies: In the case of LOCATIONS, one of the strategies used is to seek for information in Wiki-Travel or Virtual Tourists. The system already knows how to query these sites and interpret their output by using predefined wrappers. This is then used to extract relevant information from the mentioned sites webpages by sending an online query to these sites and storing the information retrieved in the triple-store. This information is then used by the DM to generate a reply. In the previous example, the system manages to extract the best sightseeing spots in Paris. The NLU would then store in the KB triples such as [Paris, sight-seeing, Eiffel Tower] and the DM with the help of the NLG would ask the user ?I?ve heard that the X is a very famous spot. Have you seen it while you were there?? Obviously in this case, X would  be replaced by the ?Eiffel Tower?.  On the other hand, if the topic requested by the DM is unknown, or the semantic tagger is not capable of understanding the semantic category, the system uses a normal search engine (and this is what we call ?hybrid-world?: the move outside the world the system already knows). A query containing the unknown term in context is sent to standard engines and the top pages are retrieved. These pages are then processed using ANNIE and their tagged attributes are analyzed. The standard attributes returned by ANNIE include information about Dialogue Acts, Polarity (i.e. whether a sentence has positive, negative or neu-tral connotations), Named Entities, Semantic Categories (such as dates and currency), etc. The system then filters the information collected by using more generic patterns and generates a reply from the resultant information. ANNIE?s polarity methods have been shown to be an adequate im-plementation of the general word-based polarity methods pioneered by Wiebe and her colleagues (see e.g. Akkaya et al, 2009). 6. Evaluation  The notion of companionship is not yet one with any agreed evaluation strategy or metric, though developing one is part of the main project itself.  
Again, there are established measures for the as-sessment of dialogue programs but they have all been developed for standard task-based dia-logues and the SC is not of that type: there is no specific task either in reminiscing conversations, nor in the elicitation of the content of photos, that can be assessed in standard ways, since there is no clear point at which an informal dialogue need stop, having been completed.  Conventional dialogue evaluations often use measures like ?stickiness? to determine how much a user will stay with or stick with a dialogue system and not leave it, presumably because they are disap-pointed or find it lacking in some feature. But it is hard to separate that feature out from a task rapidly and effectively completed, where sticki-ness would be low not high. Traum (Traum et al, 2004) has developed a methodology for dialogue evaluation based on ?appropriateness? of re-sponses and the Companions project has devel-oped a model of evaluation for the SC based on that (Benyon et al, 2008).  Acknowledgement  This work was funded by the Companions project  (2006-2009) sponsored by the European Commission as part of the Information Society Technologies (IST) programme under EC grant number IST-FP6-034434.  References David Benyon, Prem Hansen and Nick Webb, 2008. Evaluating Human-Computer Conversation in Companions. In: Proc.4th International Workshop on Human-Computer Conversation, Bellagio, Italy. Cem Akkaya, Jan Wiebe, and Rada Mihalcea,. 2009. Subjectivity Word Sense Disambiguation, In:  EMNLP 2009. Hamish Cunningham, Kevin Humphreys, Robert Gai-zauskas, and Yorick Wilks, 1997. GATE -- a TIP-STER based General Architecture for Text Engi-neering. In: Proceedings of the TIPSTER Text Pro-gram (Phase III) 6 Month Workshop. Morgan Kaufmann, CA. David Traum, Susan Robinson, and Jens Stephan. 2004.  Evaluation of multi-party virtual reality dia-logue interaction, In: Proceedings of Fourth International Conference on Language Resources and Evaluation (LREC 2004), pp.1699-1702 Yorick Wilks (ed.) 2010. Artificial Companions in Society: scientific, economic, psychological and philosophical perspectives. John Benjamins: Am-sterdam.  
77
