An Empirical Assessment of Semantic Interpretation 
Mart in  Romacker  &: Udo  Hahn 
Text Understanding Lab, \ [ -~ Group, 
Freiburg University, Freiburg, D-79085, Germany 
{mr, hahn}~coling, uni-freiburg, de 
Abst rac t  
We introduce a framework for semantic interpreta- 
tion in which dependency structures are mapped to 
conceptual representations based on a parsimonious 
set of interpretation schemata. Our focus is on the 
empirical evaluation of this approach to semantic in- 
terpretation, i.e., its quality in terms of recall and 
precision. Measurements are taken with respect o 
two real-world omains, viz. information technology 
test reports and medical finding reports. 
1 Introduction 
Semantic interpretation has been an actively investi- 
gated issue on the research agenda of the logic-based 
paradigm of NLP in the late eighties (e.g., Charniak 
and Goldman (1988), Moore (1989), Pereira and 
Pollack (1991)). With the emergence of empirical 
methodologies in the early nineties, attention has al- 
most completely shifted away from this topic. Since 
then, semantic issues have mainly been dealt with 
under a lexical perspective, viz. in terms of the res- 
olution of lexico-semantie ambiguities (e.g., Schfitze 
(1998), Pedersen and Bruce (1998)) and the gener- 
ation of lexical hierarchies from large text corpora 
(e.g., Li and Abe (1996), Hirakawa et al (1996)) 
massively using statistical techniques. 
The research on semantic interpretation that was 
conducted in the pre-empiricist age of NLP was 
mainly driven by an interest in logical formalisms 
as carriers for appropriate semantic representations 
of NL utterances. With this representational bias, 
computational matters - -  how can semantic repre- 
sentation structures be properly derived from parse 
trees for a large variety of linguistic phenomena? - -
became a secondary issue. In particular, this re- 
search lacked entirely quantitative data reflecting 
the accuracy of the proposed semantic interpreta- 
tion mechanisms on real-world language data. 
One might be tempted to argue that recent eval- 
uation efforts within the field of information extrac- 
tion (IE) systems (Chinchor et al, 1993) are going to 
remedy this shortcoming. Given, however, the fixed 
number of knowledge templates and the restricted 
types of entities, locations, and events they encode 
as target information to be extracted, one readily re- 
alizes that such an evaluation framework provides, 
at best, a considerably biased, overly selective test 
environment for judging the understanding potential 
of text analysis ystems which are not tuned for this 
special application. 
On the other hand, the IE experiments clearly in- 
dicate the need for a quantitative assessment of the 
interpretative p rformance of natural anguage un- 
derstanding systems. We will focus on this challenge 
and propose such a general evaluation framework. 
We first outline the model of semantic interpretation 
underlying our approach and then focus on 'its em- 
pirical assessment for two basic syntactic structures 
of the German language, viz. genitives and auxiliary 
constructions, in two domains. 
2 The  Bas ic  Mode l  for  Semant ic  
Interpretation 
The problem of semantic interpretation can be de- 
scribed as the mapping from syntactic to semantic 
(or conceptual) representation structures. In our ap- 
proach, the syntactic representation structures are 
given as dependency graphs (Hahn et al, 1994). Un- 
like constituency-based syntactic descriptions, de- 
pendency graphs consist of lexical nodes only, and 
these nodes are connected by vertices, each one of 
which is labeled by a particular dependency relation 
(cf. Figure 1). 
For the purpose of semantic interpretation, de- 
pendency graphs can be decomposed into semanti- 
cally interpretable subgraphs3 Basically, two types 
of semantically interpretable subgraphs can be dis- 
tinguished. The first one consists of lexical nodes 
which are labeled by content words only (lexical in- 
stances of verbs, nouns, adjectives or adverbs) and 
which are directly linked by a single dependency re- 
lation of any type whatsoever. Such a subgraph is 
illustrated in Figure 1 by 8peicher- genatt - Com- 
puters. The second type of subgraph is also delim- 
ited by labels of content words but, in addition, a 
series of n -- 1... 4 intermediary lexical nodes may 
1This notion and all subsequent criteria for interpretation 
are  formally described in Romacker et al (1999). 
327 
pro  : 
kann subject: L _ 
/ Der  Computers  . e rwe i te r t  
I spec i f ie r /~  I 
I des * m~ject :  
SDRAM-Modu len  
/The  memory, o f  the computer  -- can  -- with SDRAM-modu les  -- ex tended -- be\]  
The memory of the computer can be extended with SDRAM-modules 
Figure 1: Dependency Graph for a Sample Sentence 
appear between these content words, all of which are 
labeled by non-content words (such as auxiliary or 
modal verbs, prepositions). Hence, in contrast o 
direct linkage we speak here of indirect linkage be- 
tween content words. Such a subgraph, with two 
intervening non-content words - the modal "kann" 
and the auxiliary "werden" -, is given in Figure 1 by 
Spe ieher -  subject - kann-  verbpart - werden-  
verbpart - erweitert .  Another subgraph with just 
one intervening non-content word - the preposition 
"mit" - is illustrated by erwe i te r t -  ppadjunct - mit  
- pobject - SDRAM-Modu len .  From these consid- 
erations follows that, e.g., the subgraph spanned by 
Spe ieher  and SDRAM-Modu len  does not form a 
semantically interpretable subgraph, since the con- 
tent word erwe i te r t  intervenes on the linking path. 
Our approach to semantic interpretation sub- 
scribes to the principles of locality and composition- 
ality. It operates on discrete and well-defined units 
(subgraphs) of the parse tree, and the results of se- 
mantic interpretation are incrementally combined by 
fusing semantically interpretable subgraphs. 
As semantic target language we have chosen the 
framework of KL-ONE-type description logics (DL) 
(Woods and Schmohe, 1992). Since these logics are 
characterized by a settheoretical semantics we stay 
on solid formal ground. Fhrthermore, we take ad- 
vantage of the powerful inference ngine of DL sys- 
tems, the description classifier, which turns out to be 
essential for embedded reasoning during the seman- 
tic interpretation process. By equating the semantic 
representation language with the conceptual one, we 
follow arguments discussed by Allen (1993). 
The basic idea for semantic interpretation is as 
follows: Each lexical surface form of a content word 
is associated with a set of concept identifiers repre- 
senting its (different) lexical meanings. This way, 
lexical ambiguity is accounted for. These concep- 
tual correlates are internal to the domain knowledge 
base, where they are described by a list of attributes 
or conceptual roles, and corresponding restrictions 
on permitted attribute values or role fillers are asso- 
ciated with them. 
, , ~s -~0~iN0-~0~Y f .  ' - l 
@ / 
!XTENS I 0N-PATIENT 
EXTENSION. 04 ~ r , 
k~ MODALITY L ....... , 
Figure 2: Concept Graph for a Sample Sentence 
As an example, consider the description for the 
concept COMPUTER-SYSTEM. It may be character- 
ized by a set of roles, such as HAS-HARD-DISK Or HAS- 
WORKING-MEMORY, with corresponding restrictions 
on the concept ypes of potential role fillers. HAS- 
WORKING-MEMORY, e.g., sanctions only fillers of 
the concept ype MEMORY. These conceptual con- 
straints are used for semantic filtering, i.e., for the 
elimination of syntactically admissible dependency 
graphs which, nevertheless, do not have a valid se- 
mantic interpretation. 
Semantic interpretation, in effect, boils down to 
finding appropriate conceptual relations in the do- 
main knowledge that link the conceptual correlates 
of the two content words spanning the semanti- 
cally interpretable subgraph, irrespective of whether 
a direct or an indirect linkage holds at the syn- 
tactic level. Accordingly, Figure 2 depicts the se- 
mantic/conceptual interpretation of the dependency 
structure given in Figure 1. Instances represent- 
ing the concrete discourse entities and events in 
the sample sentence are visualized as solid rectan- 
gles containing a unique identifier (e.g., COMPUTER- 
SYSTEM.02). Labeled and directed edges indicate 
instance roles. Dashed rectangles characterize sym- 
bols used as makers for tense and modality. 2 
Note that in Figure 2 each tuple of content words 
which configures a minimal subgraph in Figure 1 
has already received an interpretation i terms of a 
relation linking the conceptual correlates. For exam- 
ple, Spe icher -  genatt - Computers  (cf. Figure 1, 
box 1) is mapped to COMPUTER-SYSTEM.02 HAS- 
WORKING-MEMORY MEMORY.01 (cf. Figure 2, box 
1). However, the search for a valid conceptual rela- 
tion is not only limited to a simple one-link slot-filler 
structure. We rather may determine conceptual re- 
lation paths between conceptual correlates of lexical 
items, the length of which may be greater than 1. 
2We current ly do not further interpret the information con- 
tained in tense or modal i ty  markers. 
328 
VerbTrans iliary 
<subject: {agent patient}> 
<dirobject: {patient co-patient}>i 
erweitern (extend) werden_.passive 
<{patient co-patient}> 
Lexeme 
Nominal Pre ~osition 
Noun _ Pronoun: <genitive attribute:~ > :: 
Speicher (memory) mlt (with) 
<{has-part instrument ...}> 
Figure 3: Fragment of the Lexeme Class Hierarchy 
(Thus, the need for role composition in the DL lan- 
guage becomes evident.) The directed search in the 
concept graph of the domain knowledge requires o- 
phisticated structural and topological constraints to 
be manageable at all. These constraints are encap- 
sulated in a special path finding and path evaluation 
algorithm specified in Markert and Hahn (1997). 
Besides these conceptual constraints holding in 
the domain knowledge, we further attempt to reduce 
the search space for finding relation paths by two 
kinds of syntactic riteria. First, the search may be 
constrained by the type of dependency relation hold- 
ing between the content words of the currently con- 
sidered semantically interpretable subgraph (direct 
linkage), or it may be constrained by the intervening 
lexical material, viz. the non-content words (indirect 
linkage). Each of these syntactic onstraints has an 
immediate mapping to conceptual ones. 
For some dependency configurations, however, no 
syntactic onstraints may apply. Such a case of un- 
constrained semantic interpretation (e.g., for geni- 
tive attributes directly linked by the genatt relation) 
leads to an exhaustive directed search in the knowl- 
edge base in order to find all conceptually compati- 
ble role fillings among the two concepts involved. 
Syntactic restrictions on semantic interpretation 
either come from lexeme classes or concrete lexemes. 
They are organized in terms of the lexeme class hi- 
erarchy superimposed on the fully lexicalized epen- 
dency grammar we use (Hahn et al, 1994). In the 
fragment depicted in Figure 3, the lexeme class of 
transitive verbs, VERBTRANS, requires that when- 
ever a subject dependency relation is encountered, 
semantic interpretation is constrained to the con- 
ceptual roles AGENT or PATIENT and all their sub- 
relations (such as EXTENSION-PATIENT). All other 
conceptual roles are excluded from the subsequent 
semantic interpretation. Exploiting the property in- 
heritance mechanisms provided by the hierarchic or- 
ganization of the lexicalized ependency grammar, 
all concrete lexemes ubsumed by the lexeme class 
VERBTRANS, like "erweitern" (extend), inherit the 
corresponding constraint. However, there are lexeme 
classes uch as NOUN which do not render any con- 
straints for dependency relations uch as evidenced 
by gen\[itive\] att\[ribute\] (cf. Fig. 3). 
It may even happen that such restrictions can only 
be attached to concrete lexemes in order to avoid 
overgeneralization. Fortunately, we observed that 
this only happened to be the case for closed-class, 
i.e., non-content words. Accordingly, in Figure 3 
the preposition "with" is characterized by the con- 
straint hat only the conceptual roles HAS-PART, IN- 
STRUMENT, etc. must be taken into consideration for 
semantic interpretation. 
Since the constraints at the lexeme class or the lex- 
eme level are hard-wired in the class hierarchy, we 
refer to the mapping of dependency relations (or id- 
iosyncratic lexemes) to a set of conceptual relations 
(expanded to their transitive closure) as static inter- 
pretation. In contradistinction, the computation of 
relation paths for tuples of concepts during the sen- 
tence analysis process is called dynamic interpreta- 
tion, since the latter process incorporates additional 
conceptual constraints on the fly. 
The above-mentioned conventions allow the 
specification of high-level semantic interpretation 
schemata covering a large variety of different syntac- 
tic constructions by a single schema. For instance, 
each syntactic onstruction for which no conceptual 
constraints apply (e.g., the interpretation of geni- 
tives, most adjectives, etc.) receives its semantic 
interpretation by instantiating the same interpreta- 
tion schema (Romacker et al, 1999). The power of 
this approach comes from the fact that these high- 
level schemata re instantiated in the course of the 
parsing process by exploiting the dense specifications 
of the inheritance hierarchies both at the grammar 
level (the lexeme class hierarchy), as well as the con- 
ceptual evel (the concept and role hierarchies). 
We currently supply up to ten semantic interpre- 
tation schemata for declaratives, relatives, and pas- 
329 
sives at the clause level, complement subcategoriza- 
tion via PPs, auxiliaries, all tenses at the VP level, 
pre- and and postnominal modifiers at the NP level, 
and anaphoric expressions. We currently do not ac- 
count for control verbs (work in progress), coordina- 
tion and quantification. 
3 The  Eva luat ion  o f  Semant ic  
In terpretat ion  
In this section, we want to discuss, for two particular 
types of German language phenomena, the adequacy 
of our approach in the light of concrete language 
data taken from the two corpora we work with. This 
part of the enterprise, the empirical assessment ofse- 
mantic interpretation, is almost entirely neglected in 
the literature (for two notable exceptions, cf. Bon- 
nema et al (1997) and Bean et al (1998)). 
Though similarities exist (viz. dealing with the 
performance of NLP systems in terms of their abil- 
ity to generate semantic/conceptual structures), the 
semantic interpretation (SI) task has to be clearly 
distinguished from the information extraction (IE) 
task and its standard evaluation settings (Chinchor 
et al, 1993). In the IE task, a small subset of the 
templates from the entire domain is selected into 
which information from the texts are mapped. Also, 
the design of these templates focus on particularly 
interesting facets (roles, in our terminology), so that 
an IE system does not have to deal with the full 
range of qualifications that might occur - -  even re- 
lating to relevant, selected concepts. Note that in 
any case, a priori relevance decisions limit the range 
of a posteriori fact retrieval. 
The SI task, however, is far less restricted. We 
here evaluate the adequacy of the conceptual rep- 
resentation structures relating, in principle (only re- 
stricted, of course, by the limits of the knowledge ac- 
quisition devices), to the entire domain of discourse, 
with all qualifications mentioned in a text. Whether 
these are relevant or not for a particular application 
has to be determined by subsequent data/knowledge 
cleansing. In this sense, semantic interpretation 
might deliver the raw data for transformation i to 
appropriate IE target structures. Only because 
of feasibility reasons, the designers of IE systems 
equate IE with SI. The cross-linking of IE and SI 
tasks, however, bears the risk of having to determine, 
in advance, what will be relevant or not for later re- 
trieval processes, assumptions which are likely to be 
flawed by the dynamics of domains and the unpre- 
dictability of the full range of interests of prospective 
users. 
3.1 Methodo log ica l  Issues 
Our methodology to deal with the evaluation of se- 
mantic interpretation is based on a triple division of 
test conditions. The first category relates to checks 
whether so-called static constraints, effected by the 
mapping from a single dependency relation to one 
or more conceptual relations, are valid (cf. Figure 3 
for restrictions of this type). Second, one may in- 
vestigate the appropriateness of the results from the 
search of the domain knowledge base, i.e., whether a
relation between two concepts can be determined at 
all, and, if so, whether that relation (or role chain) 
is adequate. The conceptual constraints which come 
into play at this stage of processing are here referred 
to as dynamic onstraint propagation, since they are 
to be computed on the fly, while judging the valid- 
ity of the role chain in question. 3 Third, interactions 
between the above-mentioned static constraints and 
dynamic constraint propagation may occur. This 
is the case for the interpretation of auxiliaries or 
prepositions, where intervening lexical material and 
associated constraints have to be accounted for si- 
multaneously. 
In our evaluation study, we investigated the effects 
of category II and category III phenomena by consid- 
ering genitives and modal as well as auxiliary verbs, 
respectively. The knowledge background is consti- 
tuted by a domain ontology that is divided into an 
upper generic part (containing about 1,500 concepts 
and relations) and domain-specific extensions. We 
here report on the two specialized omains we deal 
with - -  a hardware-biased information technology 
(IT) domain model and an ontology covering parts 
of anatomical medicine (MED). Each of these two 
domain models adds roughly about 1,400 concepts 
and relations to the upper model. Corresponding 
lexeme entries in the lexicon provide linkages to the 
entire ontology. In order to avoid error chaining, we 
always assume a correct parse to be delivered for the 
semantic interpretation process. 
We took a random selection of 54 texts (compris- 
ing 18,500 words) from the two text corpora, viz. 
IT test reports and MEDical finding reports. For 
evaluation purposes (cf. Table 1), we concentrated 
on the interpretation of genitives (as an instance of 
direct linkage; GEN) and on the interpretation of 
periphrastic verbal complexes, i.e., passive, tempo- 
ral and modal constructions (as instances of indirect 
linkage; MODAUX). 
The choice of these two grammatical patterns al- 
lows us to ignore the problems caused by syntac- 
tic ambiguity, since in our data no structural am- 
3Note that computations at the domain knowledge level 
which go beyond mere type checking are usually located out- 
side the scope the semantic onsiderations. This is due to 
the fact that encyclopedic knowledge and its repercussions on
the understanding process are typically not considered part 
of the semantic interpretation task proper. While this may 
be true from a strict linguistic point of view, from the com- 
putational perspective of NLP this position cannot seriously 
be maintained. Even more so, when semantic and conceptual 
representations are collapsed. 
330 
biguities occurred. If one were to investigate the 
combined effects of syntactic ambiguity and seman- 
tic interpretation the evaluation scenario had to be 
changed. Methodologically, the first step were to ex- 
plore the precision of a semantic interpretation task 
without structural ambiguities (as we do) and then, 
in the next step, incorporate the treatment of syn- 
tactic ambiguities (e.g., by semantic filtering devices, 
cf. Bonnema et al (1997)). 
Several guidelines were defined for the evaluation 
procedure. A major issue dealt with the correctness 
of a semantic interpretation. In cases with interpre- 
tation, we considered a semantic interpretation to 
be a correct one, if the conceptual relation between 
the two concepts involved was considered adequate 
by introspection (otherwise, incorrect). This qualifi- 
cation is not as subjective as it may sound, since we 
applied really strict conditions adjusted to the fine- 
grained domain knowledge. 4 Interpretations were 
considered to be correct in those cases which con- 
tained exactly one relation, as well as cases of se- 
mantical/conceptual ambiguities (up to three read- 
ings, the most), presumed the relation set contained 
the correct one. 5 A special case of incorrectness, 
called nil, occurred when no relation path could be 
determined though the two concepts under scrutiny 
were contained in the domain knowledge base and 
an interpretation should have been computed. 
We further categorized the cases where the sys- 
tem failed to produce an interpretation due to at 
least one concept specification missing (with respect 
to the two linked content words in a semantically 
interpretable subgraph). In all those cases with- 
out interpretation, insufficient coverage of the upper 
model was contrasted with that of the two domain 
models in focus, MED and IT, and with cases in 
which concepts referred to other domains, e.g., fash- 
ion or food. Ontological subareas that could nei- 
ther be assigned to the upper model nor to partic- 
ular domains were denoted by phrases referring to 
time (e.g., "the beginning of the year"), space (e.g., 
4The major i ty  of cases were easy to judge. For instance, 
"the infiltration of the stroma" resulted in a correct reading 
- STROMA being the PATIENT of the INF ILTRAT ION event - ,  
as well as in an incorrect one - being the AGENT of the IN- 
FILTRATION. Among the incorrect semant ic  interpretat ions we 
also categorized, e.g., the interpretat ion of the expression "the 
prices of the manufacturers" as a conceptual inkage from 
PRICE via PRICE-OF to PRODUCT via HAS-MANUFACTURER to 
MANUFACTURER (this type of role chaining can be considered 
an intr iguing example of the embedded reasoning performed 
by the description logic inference ngine), since it did not ac- 
count for the interpretation that MANUFACTURERS fix PRICES 
as part of their market ing strategies. After all, correct inter- 
pretat ions always boiled down to entirely evident cases, e.g., 
HARD-DISK PART-OF COMPUTER. 
5At the level of semantic interpretation, the notion of se- 
mant ic  ambiguity relates to the fact that  the search algor i thm 
for valid conceptual relation paths retrieves more than a single 
relation (chain). 
"the surface of the storage medium"), and abstract 
notions (e.g., "the acceptance of IT technology"). 
Finally, we further distinguished evaluative xpres- 
sions (e.g., "the advantages ofplasma display") from 
figurative language, including idiomatic expressions 
(e.g., "the heart of the notebook"). 
At first glance, the choice of genitives may appear 
somewhat rivial. From a syntactic point of view, 
genitives are directly linked and, indeed, constitute 
an easy case to deal with at the dependency level. 
From a conceptual perspective, however, they pro- 
vide a real challenge. Since no static constraints are 
involved in the interpretation ofgenitives (cf. Figure 
3, lexeme class NOUN) and, hence, no prescriptions 
of (dis)allowed conceptual relations are made, an un- 
constrained search (apart from connectivity condi- 
tions imposed on the emerging role chains) of the 
domain knowledge base is started. Hence, the main 
burden rests on the dynamic constraint processing 
part of semantic interpretation, i.e., the path find- 
ing procedure muddling through the complete do- 
main knowledge base in order to select he adequate 
conceptual reading(s). Therefore, genitives make a 
strong case for test category II mentioned above. 
Dependency graphs involving modal verbs or aux- 
iliaries are certainly more complex at the syntac- 
tic level, since the corresponding semantically in- 
terpretable subgraphs may be composed of up to 
six lexical nodes. However, all intervening non- 
content-word nodes accumulate constraints for the 
search of a valid relation for semantic interpretations 
and, hence, allows us to test category III phenom- 
ena. The search space is usually pruned, since only 
those relations that are sanctioned by the interven- 
ing nodes have to be taken into consideration. 
3.2 Eva luat ion  Data  
We considered a total of almost 250 genitives in all 
these texts, from which about 59%/33% (MED/IT) 
received an interpretation. 6 Out of the total loss due 
to incomplete conceptual coverage, 56%/58% (23 of 
41 genitives/57 of 98 genitives) can be attributed to 
insufficient coverage of the domain models. Only the 
remaining 44%/42% are due to the residual factors 
listed in Table 1. 
In our sample, the number of syntactic onstruc- 
tions containing modal verbs or auxiliaries amout to 
292 examples. Compared to genitives, we obtained 
a more favorable recall for both domains: 66% for 
MED and 40% for IT. As for genitives, lacking in- 
terpretations, in the majority of cases, can be at- 
tributed to insufficient conceptual coverage. For the 
IT domain, however, a dramatic increase in the num- 
ber of missing concepts is due to gaps in the upper 
model (78 or 63%) indicating that a large number of 
6Confidence intervals at a 95% reliability level are given in 
brackets in Table 1. 
331 
MED-GEN IT-GEN MED-MODAUX IT-MODAUX 
# texts 29 25 29 25 
# words 4,300 14,200 4,300 14,200 
recall 57% 31% 66% 40% 
precision 97% 94% 95% 85% 
100 # occurrences ... 
? . .  w i th  in terpretat ion  
\[confidence intervals\] 
correct (single reading) 
? correct (multiple readings) 
incorrect 
nil 
? . .  w i thout  in terpretat ion  
domain model (MED/IT) 
59 (59%) 
\[48%-67%1 
53 (53%) 
4 (4%) 
0 
2 
41 (41%) 
23 (23%) 
147 
49 (33%) 
\[24%-41%\] 
28 (19%) 
18 (12%) 
3 
0 
98 (67%) 
57 (39%) 
58 
40 (69%) 
\[56%-81%\] 
38 (66%) 
0 (0%) 
0 
2 
18 (31%) 
11 (19%) 
upper model 
other domains 
? time 
?. space 
?. abstracta, generics 
?. evaluative xpressions 
.. figurative language 
. . . . . . .  miscellaneous 
3 
0 
0 
7 
11 
0 
1 
0 
23 
4 
15 
8 
12 
8 
17 
1 
234 
Ill (47%) 
\[40%-53%\] 
88 (38%) 
6 (3%) 
14 
3 
123 (53%) 
42 (34%) 
78 
0 
I 
5 
16 
3 
24 
3 
Table 1: Empirical Results for the Semantic Interpretation of Genitives (GEN) and Modal Verbs and Aux- 
iliaries (MODAUX) in the IT and MED domains 
essential concepts for verbs were not modeled. Also, 
figurative speech plays a more important role in IT 
with 24 occurrences. Both observations mirror the 
fact that IT  reports are linguistically far less con- 
strained and are rhetorically more advanced than 
their MED counterparts. 
Another interesting observation which is not made 
explicit in Table 1 concerns the distribution of modal 
verbs and auxiliaries. In MED, we encountered 57 
passives and just one modal verb and no temporal 
auxiliaries, i.e., our data are in line with prevailing 
findings about the basic patterns of medical sublan- 
guage (Dunham, 1986). For the IT  domain, cor- 
responding occurrences were far less biased, viz. 80 
passives, 131 modal verbs, and 23 temporal auxil- 
iaries. Finally, for the two domains 25 samples con- 
tained both modal verbs and auxiliaries, thus form- 
ing semantically interpretable subgraphs with four 
word nodes. 
One might be tempted to formulate a null hy- 
pothesis concerning the detrimental impact of the 
length of semantically interpretable subgraphs (i.e., 
the number of intervening lexical nodes carrying 
non-content words) on the quality of semantic inter- 
pretation. In order to assess the role of the length 
of the path in a dependency graph, we separately 
investigated the results for these subclasses of com- 
bined verbal complexes? From the entire four-node 
set (cf. Table 2) with 25 occurrences (3 for MED and 
22 for IT), 16 received an interpretation (3 for MED, 
13 for IT). While we neglect the MED data due to 
the small absolute numbers, the IT domain revealed 
MED IT 
4-nodes 4-nodes 
recall - 59% 
precision - 85% 
# occurrences ... 3 22 
? .. with interpretat ion 3 13 
. . . . . . .  correct 3 11 
Table 2: Interpretation Results for Semantically In- 
terpretable Graphs Consisting of Four Nodes 
59% recall and 85% precision. If we compare this 
to the overall figures for recall (40%) and precision 
(85%), the data might indicate a gain in recall for 
longer subgraphs, while precision keeps stable. 
The results we have worked out are just a first step 
into a larger series of broader and deeper evaluation 
efforts. The concrete values we present, sobering as 
they may be for recall (57%/31% for genitives and 
66%/40% for modal verbs and auxiliaries), encour- 
aging, however, for precision (97%/94% for genitives 
and 95%/85% for modal verbs and auxiliaries), can 
only be interpreted relative to other data still lacking 
on a broader scale. 
As with any such evaluation, idiosyncrasies of the 
coverage of the knowledge bases are inevitably tied 
with the results and, thus, put limits on too far- 
reaching generalizations. However, our data reflect 
the intention to submit a knowledge-intensive text 
understander to a realistic, i.e., conceptually un- 
constrained and therefore "unfriendly" test environ- 
ment. 
332 
Judged from the figures of our recall data, there 
is no doubt, whatsoever, that conceptual coverage 
of the domain constitutes the bottleneck for any 
knowledge-based approach to NLP. ~ Sublanguage 
differences are also mirrored systematically in these 
data, since medical texts adhere more closely to well- 
established concept taxonomies and writing stan- 
dards than magazine articles in the IT domain. 
4 Re la ted  Work  
After a period of active research within the logic- 
based paradigm (e.g., Charniak and Goldman 
(1988), Moore (1989), Pereira and Pollack (1991)), 
work on semantic interpretation has almost ceased 
with the emergence of the empiricist movement in 
NLP (cf. Bos et al (1996) for one of the more recent 
studies dealing with logic-based semantic interpreta- 
tion in the framework of the VERBMOBIL project). 
Only few methodological proposals for semantic 
computations were made since then (e.g., higher- 
order colored unification as a mechanism to avoid 
over-generation i herent to unconstrained higher- 
order unification (Gardent and Kohlhase, 1996)). 
An issue which has lately received more focused at- 
tention are ways to cope with the tremendous com- 
plexity of semantic interpretations in the light of an 
exploding number of (scope) ambiguities. Within 
the underspecification framework of semantic repre- 
sentations, e.g., DSrre (1997) proposes a polynomial 
algorithm which constructs packed semantic repre- 
sentations directly from parse forests. 
All the previously mentioned studies (with the ex- 
ception of the experimental setup in DSrre (1997)), 
however, lack an empirical foundation of their var- 
ious claims. Though the MUC evaluation rounds 
(Chinchor et al, 1993) yield the flavor of an empiri- 
cal assessment of semantic structures, their scope is 
far too limited to count as an adequate valuation 
platform for semantic interpretation. Nirenburg et 
al. (1996) already criticize the 'black-box' architec- 
ture underlying MUC-style evaluations, which pre- 
cludes to draw serious conclusions from the short- 
comings of MUC-style systems as far as single lin- 
guistic modules are concerned. More generally, in 
this paper the rationale underlying size (of the lex- 
icons, knowledge or rule bases) as the major assess- 
ment category is questioned. Rather dimensions re- 
lating to the depth and breadth of the knowledge 
sources involved in complex system behavior should 
be taken more seriously into consideration. This is 
exactly what we intended to provide in this paper. 
As far as evaluation studies are concerned ealing 
with the assessment of semantic interpretations, few 
7At least for the medical domain, we are currently actively 
pursuing research on the semiautomatic creation of large-scale 
ontologies from weak knowledge sources (medical terminolo- 
gies); cf. Schulz and Hahn (2000). 
have been carried out, some of which under severe 
restrictions. For instance, Bean et al (1998) nar- 
row semantic interpretation down to a very limited 
range of spatial relations in anatomy, while Gomez et 
al. (1997) bias the result by preselecting only those 
phrases that were already covered by their domain 
models, thus optimizing for precision while shunting 
aside recall considerations. 
A recent study by Bonnema et al (1997) comes 
closest o a serious confrontation with a wide range 
of real-world ata (Dutch dialogues on a train travel 
domain). This study proceeds from a corpus of 
annotated parse trees to which are assigned type- 
logical formulae which express the corresponding se- 
mantic interpretation. The goal of this work is to 
compute the most probable semantic interpretation 
for a given parse tree. Accuracy (i.e., precision) is 
rather high and ranges between 89,2%-92,3% de- 
pending on the training size and depth of the parse 
tree. Our accuracy criterion is weaker (the intended 
meaning must be included in the set of all read- 
ings), which might explain the slightly higher rates 
we achieve for precision. However, this study does 
not distinguish between different syntactic onstruc- 
tions that undergo semantic interpretation, or does 
it consider the level of conceptual interpretation (we 
focus on) as distinguished from the level of semantic 
interpretation to which Bonnema et al refer. 
5 Conc lus ions  
The evaluation of the quality and adequacy of se- 
mantic interpretation data is still in its infancy. Our 
approach which confronts semantic interpretation 
devices with a random sample of textual real-world 
data, without intentionally constraining the selec- 
tion of these language data, is a real challenge for 
the proposed methodology and it is unique in its 
experimental rigor. 
However, our work is just a step in the right di- 
rection rather than giving a complete picture or al- 
lowing final conclusions. Two reasons may be given 
for the lack of such experiments. First, interest in 
the deeper conceptual aspects of text interpretation 
has ceased in the past years, with almost all efforts 
devoted to robust and shallow syntactic processing 
of large data sets. This also results in a lack of so- 
phisticated semantic and conceptual specifications, 
in particular, for larger text analysis systems. Sec- 
ond, providing a gold standard for semantic inter- 
pretation is, in itself, an incredibly underconstrained 
and time-consuming process for which almost no re- 
sources have been allocated in the NLP community 
up to now. 
Acknowledgements .  We want to thank the mem- 
bers of the ~-~ group for close cooperation. Martin Ro- 
macker is supported by a grant from DFG (Ha 2097/5-1). 
333 
References  
James F. Allen. 1993. Natural language, knowledge 
representation, and logical form. In M. Bates and 
R. M. Weischedel, editors, Challenges in Natural 
Language Processing, pages 146-175. Cambridge: 
Cambridge University Press. 
Carol A. Bean, Thomas C. Rindflesch, and 
Charles A. Sneiderman. 1998. Automatic seman- 
tic interpretation ofanatomic spatial relationships 
in clinical text. In Proceedings of the 1998 AMIA 
Annual Fall Symposium., pages 897-901. Orlando, 
Florida, November 7-11, 1998. 
Remko Bonnema, Rens Bod, and Remko Scha. 1997. 
A DOP model for semantic interpretation. In Pro- 
ceedings of the 35th Annual Meeting of the Asso- 
ciation for Computational Linguistics ~ 8th Con- 
ference of the European Chapter of the ACL, pages 
159-167. Madrid, Spain, July 7-12, 1997. 
Johan Bos, BjSrn Gamb~ick, Christian Lieske, 
Yoshiki Mori, Manfred Pinkal, and Karsten 
Worm. 1996. Compositional semantics in VERB- 
MOBIL. In COLING'96 - Proceedings of the 16th 
International Conference on Computational Lin- 
guistics, pages 131-136. Copenhagen, Denmark, 
August 5-9, 1996. 
Eugene Charniak and Robert Goldman. 1988. A 
logic for semantic interpretation. In Proceedings 
of the 26th Annual Meeting of the Association for 
Computational Linguistics, pages 87-94. Buffalo, 
New York, U.S.A., 7-10 June 1988. 
Nancy Chinchor, Lynette Hirschman, and David D. 
Lewis. 1993. Evaluating message understanding 
systems: an analysis of the third Message Un- 
derstanding Conference (MUC-3). Computational 
Linguistics, 19(3):409-447. 
Jochen DSrre. 1997. Efficient construction of un- 
derspecified semantics under massive ambiguity. 
In Proceedings of the 35th Annual Meeting of the 
Association for Computational Linguistics ~ 8th 
Conference of the European Chapter of the A CL, 
pages 386-393. Madrid, Spain, July 7-12, 1997. 
George Dunham. 1986. The role of syntax in the 
sublanguage of medical diagnostic statements. In 
R. Grishman and R. Kittredge, editors, Analyz- 
ing Language in Restricted Domains: Sublanguage 
Description and Processing, pages 175-194. Hills- 
dale, NJ & London: Lawrence Erlbaum. 
Claire Gardent and Michael Kohlhase. 1996. 
Higher-order coloured unification and natural an- 
guage semantics. In ACL'96 - Proceedings of the 
34th Annual Meeting of the Association for Com- 
putational Linguistics, pages 1-9. Santa Cruz, 
California, U.S.A., 24-27 June 1996. 
Fernando Gomez, Carlos Segami, and Richard 
Hull. 1997. Determining prepositional attach- 
ment, prepositional meaning, verb meaning and 
thematic roles. Computational Intell., 13(1):1-31. 
Udo Hahn, Susanne Schacht, and Norbert Br5ker. 
1994. Concurrent, object-oriented natural lan- 
guage parsing: the PARSETALK model. Inter- 
national Journal of Human-Computer Studies, 
41(1/2):179-222. 
Hideki Hirakawa, Zhonghui Xu, and Kenneth Haase. 
1996. Inherited feature-based similarity measure 
based on large semantic hierarchy and large text 
corpus. In COLING'96 - Proceedings of the 16th 
International Conference on Computational Lin- 
guistics, pages 508-513. Copenhagen, Denmark, 
August 5-9, 1996. 
Hang Li and Naoki Abe. 1996. Clustering words 
with the MDL principle. In COLING'96 - Pro- 
ceedings of the 16th International Conference on 
Computational Linguistics, pages 4-9. Copen- 
hagen, Denmark, August 5-9, 1996. 
Katja Markert and Udo Hahn. 1997. On the in- 
teraction of metonymies and anaphora. In IJ- 
CA I '97-  Proceedings of the 15th International 
Joint Conference on Artificial Intelligence, pages 
1010-1015. Nagoya, Japan, August 23-29, 1997. 
Robert C. Moore. 1989. Unification-based seman- 
tic interpretation. In Proceedings of the 27th An- 
nual Meeting of the Association for Computa- 
tional Linguistics, pages 33-41. Vancouver, B.C., 
Canada, 26-29 June 1989. 
Sergei Nirenburg, Kavi Mahesh, and Stephen Beale. 
1996. Measuring semantic coverage. In COL- 
ING'96 - Proceedings of the 16th International 
Conference on Computational Linguistics, pages 
83-88. Copenhagen, Denmark, August 5-9, 1996. 
Ted Pedersen and Rebecca Bruce. 1998. Knowledge 
lean word-sense disambiguation. In AAAI'98 - 
Proceedings of the 15th National Conference on 
Artificial Intelligence, pages 800-805. Madison, 
Wisconsin, July 26-30, 1998. 
Fernando C.N. Pereira and Martha E. Pollack. 1991. 
Incremental interpretation. Artificial Intelligence, 
50(1):37-82. 
Martin Romacker, Katja Markert, and Udo Hahn. 
1999. Lean semantic interpretation. In IJCAI'99 
- Proceedings of the 16th International Joint Con- 
ference on Artificial Intelligence, pages 868-875. 
Stockholm, Sweden, July 31 - August 6, 1999. 
Stefan Schulz and Udo Hahn. 2000. Knowledge n- 
gineering by large-scale knowledge reuse: experi- 
ence from the medical domain. In Proceedings of 
the 7th International Conference on Principles of 
Knowledge Representation and Reasoning. Breck- 
enridge, CO, USA, April 12-15, 2000. 
Hinrich Schiitze. 1998. Automatic word sense 
discrimination. Computational Linguistics, 
24(1):97-124. 
William A. Woods and James G. Schmolze. 1992. 
The KL-ONE family. Computers ~ Mathematics 
with Applications, 23(2/5):133-177. 
334 
An Integrated Model of Semantic and Conceptual Interpretation 
fl'Oln Dependency Structures 
Udo Hahn Mart in  Romacker 
I~,: .... Groul), Text Understanding Lab, 
Fre, iburg University, D-79085 Freilmrg, Germany 
ht tp  ://www. coling, uni-freiburg, de/ 
Abstract  
\Ve propose a two-layered model for computing se- 
mantic and (:onceI)tual interpretations from del)en- 
dency struetm'es. Abstract interl)retatio,t s(:hemata 
generate semantic interpretations of 'minimal' de- 
pendency sul)gral)hs , while production rules whose 
sl)eeitieation is rooted ill ontologi(:al categories de- 
rive a canonical con(:eptual i ~terl)retation from se- 
lna.ntic int;ert)retal;ion sl;ruel;ures. Configm'ational 
descriptions of del)endeney gral)hs increase the lin- 
guistic generality of interl)rel,ation s(:hemata, while 
interfimillg sehemata nd t)ro(htcl;ions t() lexi(:al and 
COll(:el)l:tl~ll (;lass hierarchies re(ht(:es the amount and 
complexity of semantic sl)e(:iti(:atJons. 
1 Introduct ion 
The syntax/semanti(:s interface has always t)een a 
matter of com:ern  for (:OllStit; l lell(:y-l)ased feal; l lre 
grammar theories (of., e.g., Creary an(1 Pollard 
( \ ]9S5) ,  ~.'~ooIx, ( i \[989), \ ] )ah'y l l l l ) le  (1.992), Wedekind 
and Kaplan (1993)). Within the dependen(:y gram- 
lllal' COllllllllllil;y: f3r loss at, te, ntion has 1)een l)ai(t t() 
l;his tel)it:. As a (:onse(tuen(:e, ther(~ is no consensus 
how syntactic del)en(lency structures might l)e a(t- 
e(tuately transl'()rm(~d into semanti(: interl)rel;aiions 
(el., naji~:ova (:t987), Milward (1992), Lombardo et 
al. (1998) for alt;ernative proposals). 
In this paper, we introduce, a two-layered inter- 
pretation model. In a first; pass, dependency graph 
structures which result fl'om in(:remental parsing are 
immediately submitted to a semantic intcrl)reta- 
tion process. Such a process is triggered by gen- 
eral schemata whenever a semantically interl)retable 
subgraph of a syntactic dependency gral)h t)ecomes 
ava.ilable (el. Section 3). As a result, lexical items 
and the del)endency relations holding 1)etwe.en them 
are directly mat)ped to associated concel)tual enti- 
ties mid relations at; the level of semantic represen- 
tation (cf. Sections 4 mtd 5). In a subsequent steI), 
the (quasi-inferential) iml)lications of the knowledge 
representation structures emerging from the seman- 
tic interpretation stet) are accounted for l)y a pro- 
eess we here refer to as concepl, 'aal interpretation. 
The (:orresl)onding ot)erations relate to the (:(mcel)- 
tua\] representation level only and are triggered by 
a variety of production rules rooted in ontological 
categories in order to generate a canonical concep- 
tual representation f the parsed sentence (el. Sec- 
tion 6). This second level of interpretation is usually 
not taken into consideration by computational mod- 
els of semantic interpretation, either constituency- 
based nor (lei)endency-based ones, although it turns 
out to crucial for natural anguage ',,ndeTwtandin.q. 
2 Grammar  and Concept Knowledge 
Grammatical knowledge for syntactic analysis is 
t)ased on a fully texicalized dependency gl'alllltla\] 
(Itahn et al, 1994). ()ur preference for dependency 
structures is motivated, among other things, t)y the 
observation that the corresl)ondence of det)endency 
relations (holding between lexical items) to con(:ep- 
tual relations (holding between the, concepts they 
denote) is much closer than t.'or constituency-based 
grammars (Ilajicova, 1987). Ilence, a dependency- 
based al)i)roach cases inherently the descrit)tion of 
the regularities mMerlying selnantic inl;erl)retation. 
In this lexicalized el)endeney framework, lexeme 
sl)eeitications form the leaf nodes of a lexicon I)AG, 
which are further al)sl:racted in terms of lexeme 
class specilical;ions at different levels of generalit:y 
(of. Figure 1), This lea& to a lexeme (:lass hier- 
archy, which consists of lexeme (:lass names 142 := 
{VE1HIAL, VEllBINTII.ANS, NOMINAL~ NOUN~ ...} a l ld  
a subsuinption relation i.saw = {(VEI{IIINTI{ANS, 
gexenle 
Verba l  ... Preposi l ion ... Nomina l  
Verbhltrans Auxiliary Pronoun Noun 
Df'J. '= 1,,.101 , Dg'""'":= \[ \] 
D"'I~J:= { \] i D- v''n'm .= \[ \] 
I I)PP'O:= \[sul o, dirobj, imlirobj} 
VelbTrallS u,erde*t passive Sl~eicherOncmory) 
::lglir?bj:- \[di,'ol,j} R+:= \[patten! CO-l,ali,'nt } 
:. qdm,l,j:= \[ } mit (with) 
)i~:lt!rll (deliver) R+ := \[has-part instrmm,nt co-patient ..} 
Figure l: Fragnmnt of the Lexeme Class Hierarchy 
271 
propo: ____~ 
ka~n sublCCt: ~- -  ~_~ovorbpar t  
Fesl latte S p ~ t t :  werden 
v~orDpa rt. 
Die Compellers pps~ferl spec:~. ~ ~..~.att 
des mit yon pobjo~,:'?"~ "-~o~jo~t 
350Mhz-OPU Transtec 
7he hard disk of flw ?vmlputer with 3.$OMhz-CPU call - b)' 7ra/t.~lrt:- be delivrred. 
Figure 2: A Sample Dependen(:y Grat)h 
VERBAL), (NOUN, NOMINAL) ,  . . .}  C "l/V X \]/V. Inher -  
i tance  of grammar knowledge is based on the idea 
that constraints are attached to the most general 
lexeme classes to which they apply, leaving room for 
more and more specific (possibly, even idiosyncratic) 
specifications when one descends this hierarchy. 
A dependency grammar captures binary con- 
straints between a syntactic head (e.g., a noun) and 
one of its possible modifiers (e.g., a determiner or 
an adjective). In order to establish a dependency 
relation ~ C :D := {specifier, s~fl~iect, dirobject, ...} 
between a head and a Inodifier, lexenle-class-specific 
constraints oil word order, comt)atit)ility of Inor- 
phosyntactic features and senmntic integrity must 
be fiflfilled. Figure 2 depicts a dependency graph in 
which word nodes are given in bold face and depen- 
dency relations are indicated I)y labeled edges. 
Conceptual knowledge of the underlying domain is 
expressed in terms of a KL-ONE-like knowledge rep- 
resentation language (Woods and Schmolze, 1992). 
The domain ontology consists of a set of concei)t 
names 9 r := {COMPANY,  tIAI~I)-.DI.g\[<, ...} and a sub- 
sunlI)tion relation i saf  = {(HAIiD-DISK, NTOHACF- 
DFVICF), (TRANS'rI.:(~', COMPANY), ...} C ~P x 
Y.  The set of re lat ion nantes ?g : - -  {IIAS-t'All;F~ 
I )EI,  IVE I~-AGENT,  . . .}  denotes con(:eptual relations 
which are also organized in a subsmnption hierarchy 
isa?z = {(ttAS-IIARI)-DISK, ItAS-PItYSICAL-PAVI'), 
( I lAS -PHYS ICAL-PAR.T ,  I tA.q-PAltSI ' ) ,  . . .} .1 Examples 
of emerging concept mid relation hierarchies are de- 
picted in Figure 3 (right box). 
Ill our at)proach, the representation languages for 
semantics and domain knowledge coincide (for argu- 
ments supporting this view, el. Allen (1993)). Link- 
ing lexical items and concet)tual entities proceeds 
as follows: Upon entering the parsing process, each 
lexical itern w that has a (:onceptual correlate C in 
the domain knowledge base, w.C E Y (mostly verbs, 
Ilouns and adjectives), gets immediately instantiated 
in the knowledge base, such that for any instance Iw, 
initially, 2 type(I,,) = w.C holds (e.g., w = :'Fest- 
platte", I,,, = HAI{D-Dlst,:.2, w.C = type(HaI~.D- 
DISK.2) = HARD-DISK). If several conceptual cor- 
relates exist, either due to honmnymy or polysemy, 
I Atl sllbstllnpl;ioIl ,elations, isaw, isa:v, and isw~, arc 
considered to be transitive and reflexive. 
2For instance, anaphora might necessitate changes of this 
initial reference assignment, el. Strube and Ilahn (1999). 
i Syntactic Level -> Conceptual Level 
I 10op-'o,~): 
!subl\[ecl\]'~-------------t-~aecnt Action C,'dcgory 
I)l.'.~',d?lfe.c't\]~paticnt~,s.a..< is-at: i~-~?: 
dirobjfect\] ~ ' \ \  \[CAT-Vrans fct'-no,)d 
: I1" oo-pa,i . 
has-part \ ~k ..... :C' - -  Persal 
gen\[itive\]att\[ribute\] I " \ \ l ,  divery 
\ l  delivcr.aealt 
vcrbpart II instrumcnt "},,a;,,2J',,:ti2 '~"""~' 
ppatt\[ributc\] II destination ~ ?--! ..... P ...... -- I deliver-recipient 
spcc\[ificr\] / I  
l ,  : . . . .  ~ L 
Figure 3: Relating Grammatical ( eft box) and Con- 
ceptual I(nowledge (right box) 
each lexical ambiguity is processed independent.ly 
within set)arate (:ontext partitions of the km)wledge 
base (Romacker and Hahn, 2000a). 
3 Interpretable Subgraphs 
II1 the parse tree from Figure 2, we can distinguish 
lexical nodes that have a conceptual correlate (e.g., 
"Fcstplatte" relating to HAl{D-DIsK, "gelicfert " re- 
lating to DEIAVh;RY) from others that do not have 
Such a correlate (e.g., "mit" (with), "yon" (by)). Se- 
mantic interpretation capitalizes oil this distinction 
in order to tind adequate conceptual relations be- 
tween the corresl)onding concept, insta.nces: 
D i rect  L inkage.  If two word no(tes with (:oncet)- 
tual correlates are linked by a single depen(ten(:y re- 
lation, a direct linkage is given. Such a subgraph 
can immediately be interpreted in ternis of a (:on- 
ceptual relation licensed by the correspondiitg de- 
l)endency relation. This is illustrated in Figure 2 by 
the direct linkage between "Festplatte" (hard disk) 
and "Computers" via the gen\[itive\]att\[ribut(~\] rela- 
tion, which gets nmpped to tile IIARD-DISK-OF role 
linking the corresponding con(:eptual correlates, viz. 
HARD-DISK.2 alld C()MPUTER-,~YSTFM.4, respec- 
tively (see Figure 4). This interpretation uses only 
knowledge about the concet)tual correlates and the 
linking dependency relation. 
Ind i rect  L inkage. If two word nodes with con- 
ceptual correlates are linked via a series of depen- 
Delivery.10 
. . . . . .  c~. . . . . .  Transtec.9 
de|lver -agent !  
. . . .  - - -41~- - -  Hm'd-Disk.2 ! deliver -pattellt 
\[ - - (~}- -  COlllpllie\[ Syst('lll.4 
hard-disk-of 
\[ (Ji 350Mhz CPU.6 
hai-qm 
Figure 4: Semantic Interpretation of the Depen- 
dency Graph fl'om Figure '2 
272 
dency relations and none of tile il ltervening no(les 
have a conceptual correlate, an indirect linkage is 
given. For such a "nfinimal" sut)grat)h, semantic in- 
tert)retal;ion is made dependent on lexical informa- 
tion from the, intervening nodes, as well as knowledge 
aboul; the conceptual correlates and del)cn(lency i'e- 
lations. Figure 2 il lustrates such a eontiguration 
lay tile linkage between "Com,putcr.s" and "350Mhz- 
CPU"  via the intervening node "mit" (will O and 
the pI)att\[ributc\] mid l>objc, ct relations, the re, suit <)f 
which is a conceptual linkage between COMI'UTFI/.- 
SYSTI,'M.4 and 350N/IIIZ-Cl'U.6 via the relation HAS- 
CI'U in Figure 4. 
In oMer to increase tile generality and to t)reserve 
the simi)licity of semantic interpretat ion we intro- 
duce a generalization of the notion of del)emlency 
relation such that it incorporates direct as well as 
indirect linkage: Two content words (nouns, adjec- 
tives, adverbs or flfll verl)s) stand in a 'me.dialed syn- 
tactic relation, if one can t)ass from one word to 
the other along the connecting edges of the (tcl)en- 
(tency gral)h wit;hour traversing word nodes other 
than t)repositions, modal or auxil iary verl)s (i.e., el- 
ements of eh)sed woM classes). In Figure 2, e.g., 
the tuples ( "Fcstplattc.", "Co'm,p',,ter.s ") or ( "6'om,- 
putcrs", "350Mh, z-CPU") stand in mediated syntac- 
t i t  relations, whereas, e.g,, the tuple ("Fest, plattc", 
"Tra'nstcc") does not, since the comiecting 1)ath COlt- 
rains "gelicfc.rt" (dclivcrcd), a (;Ollt;elll; word. 
This leads to the following detinition: Let w and 
'w' be l, wo  (:onl;enI; words  in a senten( ; ( ;  ,5'. 1111 addi- 
l;i(-)n, lel; 'w2 , . . .  , 'wn-1 E S ('11, ~ 2) l)e l / re l )os i l ; i ons  , 
auxil iary or modal verl)s, and wl := 'w an(1 w,  := 
'u/. Then we say thaJ; 'w and 'w' st:and in a 'nt(:diat('d 
syntactic r(:lat, ion, iff there exists an inde.x I C {1, 
. . . ,  n} so that the following two (:on(litions hold: 
1. 'wi is modifier of'wi+l for i C {1, . . . ,  l-1}; 
2. wi is head of wi+\] for i E {I , . . . ,  n- l}. 
We call a subgral)h identitie(1 t)y su(:h a s(!rics 'w j, 
. . .  , w ,  a, sc'm, anl, ically intcrFrc, tabh', .s"u, bgraph, of 1;11(,' 
dependency graph of S. The, detinMon of a medi- 
ated syntactic relation encoml)asses the notion of a 
direct linkage (n := 2, so t;hat an empty set of in- 
tervening nodes emerges). The special eases 1 := 1 
and I := n yield an ascending and descending series 
of head-modif ier relations, resl)ectively. 
4 Semant ic  In terpretat ion  Mode l  
The model of semantic intert)re.tatiol~ we l)rOl)OSe 
(:Oral)rises two (:onsl,raint layers. First, sl, atic (:on- 
straints fl)r semmltic intert)retation derived from di- 
rectly mapping dependency relations to conceptual 
roles, and, second, a search of the knowledge t)ase 
which dynamically takes these static constraints into 
account. The translation from the syntacti(" to the 
semantic level is achieved in a strictly COml)ositional 
way l)y incrementally c()mbining the conc(;ptual l"(;I)- 
resentations of semantically interl)retat)le sul)gral)hs 
until the entire del)endeney graph ix processed. 
S ta t i c  Const ra in ts .  Intert)retation 1)rocedures 
operat ing on semantical ly interi)retable, subgrai)hs 
may inherit restrictions from the tyl)e of dependency 
relations or from the lexical material  they incor- 
1)orate. Constraint knowledge from the g;ranmmr 
level comes in two varieties, viz. via a positive list,, 
Icx v.l D4 . . . .  , and a negative list,, D\]  (''~'~'?l, of det)endcncy 
relations, tronl which adlnitted as well as excluded 
concel)tual relations, //,~ and /~,_, resl)ectively, are 
derived 1)y a silnple static symbol mal)l)ing. 
Knowledge at)out D_~ .......... I and Dj  c*val is part of 
the valen(:y sl)e(;itications. It is encoded at the level 
of lexeme classes l/V, such that lcxval C )IV x "D. By 
way of 1)rol)erty inheritance this knowledge is passed 
on to :ill subsumed lexical classes and instances. 
For insta.nce (of. Figure l), the lexeme class of in- 
transit ive verbs, VEI IBINTI /ANS G ~/~), d()\[ i i les fo r  igs 
sul).icct valency D ~! v''W"rr' .......... kiccO := {sul).icct} 
~lll(l \ ] )  {r, crbinlrans, sul, jccl.) _ ' := (/), whereas for 1)ret)osi- 
? I )  (vcrbinlrans, plmdj) tiolml a(liuncts we i'equire ~.~_ := 0 
anti D (,,~,.I,h,,. .. .... m,a4i) := {sul)ject, dirob.ject, in- 
dirol)ject}. All these constl'ainl;s arc inherited t)y 
the lexenm class VIgtlBTI/AN,S. \?e thell  distinguish 
tin'co t)asic cases how (:orrespmMing constraints may 
alib, ct semantic interl)rctation 1)roc(!sses: 
I. Knowledge availalfle f lom ,qy'lfl;ax deter'minas 
tim st;mind;it interl)retation , if Dq{ c~:v"! ~- 0 and 
D\ ]  ......... t = ~ (e.g., the subject of a verb). 
2. Knowledge availal)le from syntax vt',stricLs' t.he 
semanl;i(-intcrpr(;l.a.tion~ if' Dq{ (':''''''t = ~ mM 
1)\] .......... t ?_ 0 (e.g., for 1)reposit.ional djuncts). 
3. if' Dq{ ....... I = 0 all(1 D / ........ 1 = (/), l ie  syntact i ( :  
(:(mStl'aints ap1)ly and semanl.ic interl)re, l;ation 
pr()(-eeds e, ntire, ly concept-driven; i.e., it relies 
on domain knowledge only (e.g., for genitives).a 
hl order to transfer syntacl;ic constraints to l;}le 
eoncel)tual level, we define i: 7) --+ 2 "n, a mal)t)ing 
fi'onl det)endency relations onto sets of concel)tual 
relations. Some of these mal)l)ings are already de- 
I)icted in Figure 3 (e.g., i(subjecO := (aC~NT, PA- 
TIENT}). For del)en(lency relations 5 E "D that can- 
not })e linke, d ;I priori to a concel)tual relation (e.g., 
g(,n\[itiv@,tt\[ributeJ), we require i(5) := 0. 
The (:oncel)tual restrictions, R+ and/~,_, must be 
(:Oinlmt.ezl from Dq{ <':vat and D_ h,xvaz, respectively, 
1)y al)l)lying the interi)retation flmction i to each el- 
ement of the corresponding sets. This leads us to 
1~+ := {,  I :': e V,!  ........... z/~ y C i(:,,)} ~uld \]~ := 
{V I :" e n2 '* ' "  a , e i(:,')}. 
a\Ve hawe current ly  ilo eml)irical evidence for the fourth 
possible (:as('., where 1) lca'wd ~k 0 and 1) lcxval ~ O. 
273 
Dynamic Constraint Processing. Semantic 
interpretation implies a search in the knowledge base 
which takes the constraints into account that de- 
rive fl'om a particular dependency parse tree. Two 
sorts of knowledge then lmve to be combined - -  first, 
a pair of concepts for which a connecting relation 
path has to be determined; second, conceptual COl> 
straints on permitted and excluded conceptual rela- 
tions when connected relations are being computed. 
The first constraint ype ineorporates the content 
words linked by the semantically interpretable sub- 
graph, the latter accounts for the pm'ticular depen- 
dency relation(s) holding between them. Schema (1) 
describes the most general mapping fl'om the coil- 
ceptual correlates, h.Cfrom and 11t.Cto~ ill ~ of tile 
two syntactically linked lexical items, h and m, re- 
spectively, to connected relation paths 12~o,,.. 
)c x 2 ~ x 2 v? x .7 -~ 2/~ .... 
";: (CI,.o,,~ , 12+, 12- ,  C,o) ~ 12~o~,, (1) 
A connected relation path rel~o,, C R .... is defined 
by: 
relcon((rt,..., rn)) :?:;' Vi C {1, ..., n - 1} : 
A relation path is called connected, if for all its n 
constituent, noncomposite relations ri the concept 
type of the domain of the relation ri+l subsumes 
the concept ype of the range of the relation ri. 
To compute a semantic interpretatiol~, si triggers 
a search through the knowledge base and identifies 
all commeted relation paths from Cf~.o,, to Cto. Due 
to potential conceptual ambiguities in interpreting 
syntactic relations, more than one such path may 
exist (hence, we mat) to the power set of 12~o,~). In 
order to constrain connectivity, si takes into con- 
sideration all conceptual relations 12+ C Td a priori 
permitted for semantic interpretation, as well as all 
relations R_ C 7~ a priori excluded. Both of them re- 
flect the constraints set 11 t) by particular (lel)endency 
relations or non-content words figuring as lexical re- 
lators of content words. Thus, tel G R~o,, holds, if 
tel is a connected relation path from Cf,.o,,~ to Cto, 
obeying the restrictions imposed by 12+ and 12_. 
If the fllnction si returns the empty set (i.e., no 
valid interpretation can be comtmted), no depen- 
dency relation will be estat)lished. Otherwise, tbr 
all resulting relation paths RELi E I~con an asser- 
tional axiom of tile form (h.Cfro,n I~.ELi m.Cto) is 
added to the knowledge base, where RELi denotes 
tile i th reading. If i > 1, conceptual ambiguities oc- 
cur, resolution strategies for which m'e described ill 
Romaclmr and Hahn (2000a). 
To match a concept definition C against ile con- 
straints imposed by 12+ and 12_, we define the func- 
tion get-roles(C) =: CR, where C12 denotes the set 
of conceptual roles associated with C, which are then 
used as starting points for the path search. For ease 
and generality of st)ecification , R+ and li~_ consist of 
the most general conceptual relations only. Hence, 
the concrete conceptual roles CR and the general 
ones in R+ and R_ may not always be compatible. 
So prior to semantic interpretation, we expand I2+ 
and R_ into their transitive closures, incort)orating 
all their subrelations in the relation hierarchy. Thus, 
12; :-- { ,.* e I ,' 12+ : is,  ,. }. R*_ is 
correspondingly defined. 12+ restricts the search to 
relations contained in C12 rq 12"4-, iffR+ is not empty 
(otherwise, all elements of C12 are allowed), whereas 
12_ allows only for relations in C12 \ 12"_. 
5 A Sample  Semant ic  In terpretat ion  
Whenever a semantically interpretable subgraph is 
complete, selnantic interpretation gets started inl- 
mediately. As an example, we will consider a case of 
indirect linkage, as illustrated by the occurrence of 
auxiliary and modal verbs within a passive clause. 
When interpreting indirect syntactic relations, in- 
fl)rmation not only about content word nodes but 
also about intervening noncontent word nodes be- 
comes available. This way, further static constraints 
are imposed on R+ (and 12_) in terms of a list RI~.~. 
C T~. of permitted conceptual relations. This infor- 
mation is always specified at the lexcme level. Since 
12t~:~ relates to closed-class i|;ems only, the required 
nmnber of specifications i easy to survey. 
In our example (ef. Figure 2), the content words 
"Festplatte" (h, ard disk) and "flcliefcrt" (dclivered) 
are linked by a mediating modal verb ("lvann" (can)) 
and a passive auxiliary (%;erden" (bq ..... i,,c)). The 
semantic interI)retation schema tbr passive auxil- 
im'ies (2) addresses the concept ype of the instance 
fbr their syntactic subject, Cs,o,j = t!/pe(I.~ul, j) = 
HARI)-DISK, and that tbr their verbpart, C,,e,,1,pa,.t 
= type(Iv~:,.bv~rt) = DELIVERY. The relation be- 
tween these two, however, is determined by Rva**a,~:~. 
:= {PATIENT, CO-PATIENT}, constraint knowledge 
which resides in the lexeme specification for %mr- 
den" as passive auxiliary (of. Figure 1). 
: , , 12 o,,, (2) 
With sia,,x(DELIVEI{Y, {PATIENT, CO-PATIENT}, 
~, HAIl.D-DISK), we get the concet)tual relation 
DEH\ Ea-IATmNT (of. Figure 3), since HM{D-DISK 
is subsumed by PI~ODUCT and, thus, a legal filler of 
DELIVER-PATIENT C 12passaux" 
6 Conceptua l  In terpretat ion  
Conceptual interpretation uses a production rule sys- 
tem (Yen et al, 1991.) which accounts for charac- 
teristic patterns of assertions that result froth the 
semantic interpretation process. While the outcome 
of semantic intert)retation (cf. Figure 4) still adheres 
274 
to the surfa(:e fOl'Ill ()t' Ill(} parse(l sent(m('('. (:(m(:el)- 
tual i(ltt?l'pl(~tali()ll abstla(:ts away' fr()ill 1 }IOS(~ Slll'faC(} 
1)\]1(UH)I11(~I1~1 ~11((\[ CI'O,~/L(~a ~l ; l IO l ' I l I~d iz (~d '~ ( :a l tO l l i ca l  
(:OllCel)tual ret)resentatiolt of lhe inlmt, as need(~(t, 
e.g., for mfiformly queryilig th(} kl(owlr;dge lmse. 
As an exanq)le of such inferences consider Figure 
5. with the I)ELI\:I't/S relation linking TI/ANS'II.'(;.9, 
a haMware supplier, aud H..\IiI)-I)I.sI,:.2. By (:om- 
imting a (:on(:eptual relation representing the m> 
de(lying A(:TION TI/AN.qTE(:.!) and tIAItl)-I)I.qK.2 
are integrated in a n(n'malized (:(m(:ept graph. Note 
that the corl'eSlmnding lexi(:al it(!ins, "Tran.s'tec" and 
'q+stplatte" (hard disk), are not linked via a me- 
diated synta.cti(: relation in Figure 2. tlence, we 
lnay (:learly discern semanti(: interl)retation , which 
operates on sinqh, semantically interl)retabl(~' sub- 
graphs only, from concel)tual interi)retation , where 
the inferenc(>llased interl)retati(m of relationshil)s 
among different sift)graphs (:onles int(~ I)lay. 
An ind(~t}(uldent level for (:(m(:ei)tual imerpreta- 
(tOll also bo.came a necessity due to analyti(: consid- 
erations. Often the to(:al constraints for (:onc(~t)tual 
roles of ACTION, ~T..VI'E, or EVENT concepts (:armor 
be formulated restrictive enough for the semantic 
interpretation process. For exanlple, the. (xmceptual 
correlate of the verb "possess" does not impose any 
restri(:tion on its I'ATIENT role (linked to the siltlj(}(:t 
(lotmn(tency relation in a ,~enlantically into.rpretal)lc' 
sul)grat)\[ O. I{ather, restric.tions apply to l(roperly 
relatin9 the filM of the. PATIENT slot with that of 
the CO-PATIENT slot (dirobjoct, at lh0. do.1)enden(:y 
h.'vel). C, oncet)tual interl)retation rules are a means 
to further constrain these :cont(.~xt--sensitive ' aslm('ts 
of the interpretation I)rocess. 
Sin(:(} verbs play a prominent role in dcI)emlency 
gratmnars, the production rule system for con(:el> 
tual interpretation is ba.qed ut)on the conceptual COl'- 
relat, es of verbs (h/}ncetiwth verb concepts) in the 
k(lowl(.,(lg(.' base. Ditfer(}nt views are defined for ve,b 
con(:epts t) 3' using three ~d)st;racti(m dinmnsi(ms. 
First, verb concel)tS are classified, ac(:()rding to 
the set of thematic roles riley supply, as ACTION, 
~TA'I'E or Pt(OCES$. I)EIAVH{Y, e.g., is assigned to 
:\(TI'ION, Sill(;(} both A(;ENT and I'ATIENT form part 
of the concept detinition (of. Figure 3, right box). 
The second level of al~straction (:ol).sists (~f (:at:ego- 
r izations which reflect a ('omnmn core meaning. The 
upnlost conceptual node in this hierarchy is CATI.;- 
(;()I/Y. \]-)HAVH/Y, e.g., is considered as a C(}IIcopi 
whi(:h repres(}l~tS he ACTION of transfering a GOOl) 
"l'l'al IS;t ec.9 
i ?:~:, I la l 'd- i ) isk.2 
deliverl \[ . . . . .  I.l . . . .  ('OIllplll el" Sysielln.4 
hard di,k-ur \[ ~I~:: , 35(Mhz-CPU 6 
has-cpu 
Figure 5: A Sample Concel~tual Interllretati(m of the 
1)op(m(lency Graph fl'om Figure 2 
t() a customer. All verb (:(mcet)ts belonging t() this 
Ci ( l ; (~ro l 'y  HI'O S l l l )S ( l l l lOd  })y the correst)onding COl> 
COl)t. (2AT--TIIAN.qFI.;II..G()OD. (\Ve here make llse 
of nnfll, ilfle inheritance ln(!(:hanisnls.) 
Finally, every verb con(:et)t is linked to s(-)Ill(~ 
\-Iqt/I/-~IOI)F.I, \])I'LI\;EI/X/or ally other \,el'l) concept 
()f the C_-\T--TII.\NSI.'EI/-(~OOl) category is a con-. 
stiLu(,.nt i)hase of the BI;Y-ANI)-,~I.;IdJ-~\[OI)EL. "l\]() 
gem'.ralize appr()t)riately fr(nn individual verbs, vml) 
cat.egorie:; were extracted from ore text corpora that 
further refin(~ a large-scale taxononly for Gernmn 
verbs (Balhner and Brelmenstuhl, 1986). hi this 
\v(M(, a total  of about  20,000 verbs \\;ere subsumed 
by 700 categories to reflect a semantic generalization 
ill l:erms of a hie.rarchy of verb categories. 
The production rules for cont:el)tual interim;Cation 
operate on this calegorial hierarchy. Every verb con- 
Cel)t in the hierarchy is a sul)con(:ept of exactly one 
(:ateg()ry in the knowledge base. Whe,mver the pre- 
c(mditions of ;111 imert)retati(m rule are fulfilled, a 
concel)tual interl)l'(.'tat, iolx ix con(puled. 
Coil(:el)tual and semanti(: int(U'l)retation d('.pend 
on each other, since the bast(: interpretation schema 
(of. expression (1) in Section 4) is supplied with ac- 
tual t)aramete.rs frolll t)rodu(:tion rules. We there- 
fore may de.line another specialization of the basic 
int(.wl)retation schenla for (;on(:el)tllal interpretation 
sico,,,,. In particular, path searches are triggere(l 
that are re.~;ia'i(:ted by a positive list l'end(~red l)y the 
apl)licable production rule. 
For our ,~ample sent(}n(:e (of. Figures 2 and 4), the 
/:oncel)tual (:orr(,latc' for the verb "delivers" (DI,:- 
IAVEH.Y) is a sul)concept of A(:TIt)N. Addition- 
ally, l)l.'l.IVl.:l/Y is a mlbconcei)t of the (:ategory 
CAT--Tt/:\';SFI.'I~-Go()I) ((:f. Figure. 3). The. corre- 
sponding (:on(:el)tual interl)retation rule is given in 
Fi{{(lro, (J. Wht}llever }111 instance of /,he category 
(~A'I'-TItAN,qFEIt-.(~OOI) is encounter(,.d and \[)oth its 
:\(IENT and I'ATIF.NT r(}los ale. filled, relation paths 
are (:omput;ed from th(; types of the two instances 
involved, a and p, reslm(:tively. For each relation 
found by the search algorithnl (l~\]'2L in Figure 6), 
a correspondil~g assertion is added to the knowledg(.' 
base (TELL  in Figure 6). In the examt>le, the in- 
terl)retatioll s(:hmna is inst;mMated with the 4-tuple 
((:OMI':\NY, {TI~:\NSI"I':I~S-(;O()D}, {}, H.M~I/-I)IsK) 
resulting in t, he comfmtation of {I)I:.LIVFA/S} as the 
in'Olw.r re.lation link (of. Figure 5), since it is a sub- 
ro.lation of TI/AN.qFEI/S-(;OOI). 
EXISTS v, a, p: 
t; : CAT-TRANSH.:R-(~OOI)F1 
t' A ( IENT ,'1 M o PAT I I , 'NT  p 
IF .~i ........ (tUp,'(,z), {T,..~NSF,.:RS-GOO,)}, {}, tVp,~(p)) ? 
TItEN 
I{EL := .,;i ........ (t!jpc(~), {TII~.NSI.'I.:ItS-C;OOl)}, {}, type(p)) 
TELl, o, Itl,;l~ p FOR,AId; Itl,:l, ~ HEL 
Figure 6: Samt~le (~onceptual Imo.rpr0.tati(m I/,ule 
275 
7 Evaluat ion 
We evaluated this approach to senmntie intert)reta- 
tion on a random selection of 54 texts (comprising 
18,500 words) from two text corpora, viz. consumer 
product test reports and medical finding reports. 
For evaluation purposes, we concentrated on the in- 
terpretation of genitives (as an instance of direct 
linkage) and on the interpreta.tion of t)eriphrastic 
verbal complexes, i.e., passive, temporal and modal 
constructions (as instances of indirect linkage). 
The underlying ontology consists of an upper 
generic part (containing about 1,500 concepts and 
relations) and domain-specific extensions relating to 
information technology (IT) and (parts of) mmtomi- 
cal medicine (MED). Each of these two dolnain mod- 
els adds about 1,400 concepts and relations to the 
upper model. Corresponding lexeme entries in the 
lexicon provide linkages to the entire ontology. 
We considered a total of 247 genitives in the smn- 
ple. Recall was higher for medical texts (57%) than 
for IT documents (31%), though, in general, rather 
low. However, precision peaked at 97% and 94% fo," 
medical and IT texts, respectively. The mnnt)er of 
syntactic onstructions with modal verbs or auxil- 
iaries amour to 292 exmnples. Compared to geni- 
tives, we obtained a slightly more favorable recall 
for both doinains 66% tbr MED, 40% for IT - - ,  
while precision dropped slightly to 95% and 85% for 
nmdical and IT documents, respectively. 4 
As with any such evaluation, idiosyncrasies of the 
(;overage of the knowledge bases are inevitably tied 
with the results and, thus, put limits on too far- 
reaching generalizations. However, our data reflect 
the intention to submit a knowledge-intensive text 
un(lerstmlder to a realistic, i.e., conceptually un- 
constrained and therefore "unfriendly" test environ- 
ment. Judged from tile figures of our recall data, 
there is no doubt, whatsoever, that conceptual cov- 
erage of the domain constitutes the bottleneck for 
any knowledge-based approach to NLP. s Sublan- 
guage differences are also mirrored systematically in 
these data, since medical texts adhere more closely 
to well-established concept axonomies and writing 
standards than magazine articles ill the IT domain, 
whose rhetorical styles vary to a larger degree. 
8 Re lated  Work 
The standard way of deriving a semantic interpre- 
tation for constituency-based grammars is to assign 
each syntactic rule one or more semantic interpreta- 
tion rules (e.g., van Eijck and Moore (1992)), and to 
4A more detailed presentation of this evaluation study is 
given in Romacker and Itahn (20001)). 
5For the medical domain at least, we are currently actively 
pursuing research on the semiautomatic creation of large-scale 
ontologies from weak knowledge sources, viz. medical termi- 
nologies; cf. Schulz and Hahn (2000). 
determine the meaning of the syntactic head fl'om its 
constituents. This approach as also been adopted 
in the few explicit attempts at incorporating seman- 
tic interpretation i to a dependency grmninar fi'mne- 
work (Milward, 1992; Lombardo et al, 1998). There 
are no constraints on how to design and orgmfize this 
rule set despite those that are imI)lied by the choice 
of the semantic theory. In particular, abstraction 
mechanisms (going beyond the level of sortal tax- 
onomies for semantic labels, cf., e.g., Creary and 
Pollard (1985)), such as property inheritance, de- 
faults, are lacking. Accordingly, the number of rules 
increases rapidly and easily reaches orders of sev- 
eral lmndreds in a real-world setting (Bean cta l . ,  
1998). As an alternative, we provide a small set 
of gencric semantic interpretation schemata (by the 
order of 10) and conceptual interpretation rules (by 
the order of 30 for 200 verb concepts) instead of 
assigning specific interpretation rules to each gram- 
mar item (in our case, single lexemes), and incor- 
porate inheritance-based abstraction in the use of 
these schemata during the intert)retation process in 
the knowledge base. We clearly want to point out 
that while this rule system covers a wide variety 
of standard syntactic constructions (such as gent- 
tives, prepositional phrases, various tense and modal 
forms), it currently does not account fbr quantifica- 
tional issues (like scope ambiguities) for which en- 
tirely logic-based approach (Charniak and Goldman, 
1988; Moore, 1989; Pereira and Pollack, 1991) pro- 
vide quite sophisticated solutions. 
Sondheilner et al (1984) and Itirst (1988) treat 
semantic interpretation as a direct mapt)ing front 
syntactic to conceptual rel)resentations. They also 
shm:e with us tim representation f doinain knowl- 
edge using Kl,-ONE-style terminological languages, 
and, hence, they nmke heavy use of property inher- 
itance (or typing) inechanisms. The main diflbrence 
to our approach lies in the status of the semantic 
rules. Sondheimer et al (1984) attach single in- 
terpretatiotl rules to each r'olc (filler) and, hence, 
have to provide utterly detailed specifications re- 
flecting the idiosyncrasies of each semantically rele- 
vant (role) attachment. Property inheritmme comes 
only into play when the selection of alternative se- 
mantic rules is constrained to the one(s) inherited 
from the most specific case frame. In a similar way, 
Hirst (1988) uses strong typing at the coueeptual 
object level only, while we use it simultaneously at 
the grmnmar and the domain knowledge level for the 
processing of semantic schemata. 
9 Conclus ions 
We introduced an al)proach to the design of com- 
pact, yet highly expressive senmntic interpretation 
sdmmata. They derive their power from two sources. 
First;, the organization of grammar and domain 
276 
knowledge, its well as semantic interpretation mcch- 
alliSllIS: al'e lmsed on inheritance principles. Soc- 
ou(1, interpretation schemata l)stract from 1)articu- 
lar linguistic phenomena (spe('ilic lexical items, lex- 
eme classes or dependency relations) ill terms of gen- 
eral contiguration l)atterns in (tepo.nden(-y gral)hs. 
Underlying these design decisions is a strict sep- 
aration of linguistic and eouceptual knowledge. A 
clearly defined interface is provided which a.llows 
these st)ecitications to nmke reference to line-grained 
hierarchical knowledge, no ma.tter whether it is of 
gramnmtical or conceptual origin. The interface is 
divided into two levels. O11o nmkes use of static, 
high-level (:onstraints ut)l)lied l)y the nlal)l)ing of 
syntactic to conceptual roles or sut/1)lied its the 
meaning of closed word classes. The other uses these 
constraints in a dynanfic search through a knowl- 
edge base, that is l/arametrized by few and simI)le 
schenmta. Finally, at the level of conceptual in- 
terprotatiou inferences emerging fl'om senmntic rq)- 
resentations are COml)uted by a s(.'l; of t)roductious 
which make reference to a verbcategorial hierarchy. 
Also since the numl)er of s(:hentata at the semantic 
description layer remains ratho.r sulall, their o.x('.cu- 
tion is easy to tra(:e and thus SUl)l)orts the main- 
tenanco of largo-scale NLP systenls. The high ab- 
straction level 1)rovided by inheritance-based seman- 
tic sl)ecilications allows easy 1)orting across (liflhr- 
ent al)l)lication domains. Our exl)orienco resls on 
reusing the set of s(;mald;ie sehenmta once deveh)t/ed 
for the information technoh)gy domain in the nm(ti- 
ca\] domain without further (:hallges. 
A(-knowledgments.  Wc want to thank the members 
of the l~{group for close (;OOl)eration. M. Romacker was 
SUl)t)ortcd by a grant fi'om DFC (Ita 2097/5-11. 
Re ferences  
J. Allen. 1993. Natural language, knowledge rep- 
resentation, and logical tbrm. In M. Bates and 
R. Weischedel, editors, Challc'nges in Natural Lan- 
guage Proccssinfl, pages 146 175. Cambridge Uni- 
versity Press. 
T. Balhn(?r and W. Brenncnstuhl. 1986. Deutsche 
Vcrbcn. Einc ,sprach, analytisch, c Untcrsuchunfl des 
deutschcn Verbwortschatzcs. Tiil)ingen: G. Narr. 
C. Bean, T. Rindtlesch, and C. Sneidernlan. 1998. 
Automatic semantic intert)retation of anatonfic 
spatial relationshil)s in clinical text. Ill Prec. 1998 
AMIA Annual Fall Symposium, pages 897 901. 
E. Charniak and 1{. Goldman. 1988. A logic for se- 
nmntic interl)retation. In Prec. of the 261h Annual 
Meeting of the. A CL, 1)ages 87-94. 
L. Crea.ry and C. Pollard. 1985. A computational 
semantics for natural language. 111 Prec. of the 
23rd Annual Mcctinfl of the ACL, pages 172 179. 
M. Dalrymple. 1992. Categorial semantics tbr LFG. 
In COLING'92 --- Proceedings of th, c I5th, \[sic! 
ldth,\] International Conference, pages 212-218. 
U. Itahn, S. Sohacht, and N. BrSker. 1994. Con- 
current, object-oriented natural anguage t)arsing: 
the PAI{SE'I'AIA{ model. International Journal of 
II'aman-Computcr Studies, 41(1/2):179 222. 
E. Hajieova. 1987. Linguistic meaning as related to 
syntax and to senmntic interpretation. Ii1 M. Na- 
gao, editor, Language and Artificial Intelligence, 
pages 327-351. North-Holland. 
G. Hirst. 1988. Senlantic intert/retation and ambi- 
guity. Artificial Intelligence, 34(21:131-177. 
V. Lombardo, L. Lesmo, L. Perraris, and C. Sei- 
donari. 1998. Incremental interpretation and lex- 
icalized grmnmar. In CogSci'98 - Proceedings of 
the 20th Annual Conference, pages 621-626. 
D. Milward. 1992. Dynamics, dependency grammar 
and incremental inte.rl)retation, ht COLING'92 
15vccedinfls of the 15th, \[sic! l~th\] International 
Coufcrcncc, pages 1095 1099. 
R. Moore.. 1989. Unitication-based semantic in- 
terl)r(;tation. In Proceedings of the 27th Annual 
Meeting of th, e A CL, pago, s 33--4:1. 
F. Pereira and M. Pollack. 1991. Incremental inter- 
pretation. Artificial Intelligence, 50(11:37-82. 
M. \]~,mmck(?r and U. tIahu. 2000a. Coping with dif- 
ti?rent ypes of anlbiguity using a uniform context 
haudling nmchanism. In Applications of Natural 
Lang'aaflc to h~formation Systcm.s. PTvccedinfls of 
the 5th, NLDB Confc~w~,cc. 
M. l{omacker and U. Italm. 2000b. An empMcal 
assessment of scnlantic interpretation. Ill P~vC. of 
the 6th Applied Nat'aral Language Processing Con- 
fc,'re',,cc, ?4 1.st Co'nfercncc of the, North American 
Chapter of the A CL, pages 327 334. 
S. $chlflZ and U. lIahn. 2000. Knowledge ngineer- 
ing I)y large-scale knowledge rollS(?: OXl)eriem:e 
from the inedical donm.in. In KR '200(\] Prec. ~\[t\[t 
Inter'national Conference., l)ages 601-610. 
N. Sondheimer, R. Weischedel, and R. Bobrow. 
1984. Semantic interpretation using KL-ONI,'. In 
COLING'84 Prec. IOth \]?tl. Coufcrcucc ~ 22rid 
Annual Mooting of the, ACL, pages 101 107. 
M. Strube and \[J. Ilahn. 1999. Nmetional centering: 
grounding referential coherence in information 
structure. Computational Linguistics, 25 (3) :309 
344. 
a. van Eijck and R. Moore. 1992. Semantic rules 
for English. In H. Alshawi, editor, The Core Lan- 
flua.qc Engine, pages 83-115. MIT Press. 
J. Wedekind and R. Kaplan. 1993. \[Type-driven se- 
mantic interpretation of f-structures << .1, W > 
,< R ,K  >>\]. In EACL'93 Proc. 6th, Conf. Eu- 
ropean Chapter of the ACL, pages 404 d11. 
W. Woods and J. Schmolze. 1992. The KL-ONE 
fiunily. Computers "U Mathematics with Applica- 
tions, 2312/51:133 177. 
J. Yen, R. Neches, and R. MacGregor. 1991. 
CLASP: integrating term subsuml/tion systems 
and l)roduction systems. IEEE Transactions on 
Knowlcd.qc and Data Engineering, 3(1):25--32. 
277 
The SynDiKATe Text Knowledge Base Generator
Udo Hahn
Text Knowledge Engineering Lab
Albert-Ludwigs-Universita?t Freiburg
D-79085 Freiburg, Germany
hahn@coling.uni-freiburg.de
Martin Romacker
Text Knowledge Engineering Lab
Albert-Ludwigs-Universita?t Freiburg
D-79085 Freiburg, Germany
romacker@coling.uni-freiburg.de
ABSTRACT
SynDiKATe comprises a family of text understanding sys-
tems for automatically acquiring knowledge from real-world
texts, viz. information technology test reports and medical
nding reports. Their content is transformed to formal rep-
resentation structures which constitute corresponding text
knowledge bases. SynDiKATe's architecture integrates re-
quirements from the analysis of single sentences, as well as
those of referentially linked sentences forming cohesive texts.
Besides centering-based discourse analysis mechanisms for
pronominal, nominal and bridging anaphora, SynDiKATe
is supplied with a learning module for automatically boot-
strapping its domain knowledge as text analysis proceeds.
1. INTRODUCTION
The SynDiKATe system belongs to the broad family of
information extraction (IE) systems [1]. Signicant progress
has been made already, as current IE systems provide robust
shallow text processing such that frame-style templates are
lled with factual information about particular entities (lo-
cations, persons, event types, etc.) from the analyzed doc-
uments. Nevertheless, typical MUC-style systems are also
limited in several ways. They provide no inferencing ca-
pabilities which allow substantial reasoning about the tem-
plate llers (hence, their understanding depth is low), and
their potential to deal with textual phenomena is highly
constrained, if it is available at all. Also novel and unex-
pected though potentially relevant information which does
not match given template structures is hard to account for,
since system designers commit to a xed collection of do-
main knowledge templates (i.e., they have no concept learn-
ing facilities).
With SynDiKATe, we are addressing these shortcomings
and aim at a more sophisticated level of knowledge acqui-
sition from real-world texts. The documents we deal with
are technical narratives in German language taken from two
domains, viz. test reports from the information technology
(IT) domain as processed by the itSynDiKATe system [8],
.
and nding reports from a medical subdomain (MED), the
framework of the medSynDiKATe system [10, 9]. Our rst
goal is to extract conceptually and inferentially richer forms
of knowledge than those captured by standard IE systems
such as evaluative assertions and comparisons [25, 24], tem-
poral [26] and spatial information [22]. Second, we also
want to dynamically enhance the set of knowledge templates
through incremental taxonomy learning devices [12] so that
the information extraction capability of the system is in-
creased in a bootstrapping manner. Third, SynDiKATe is
particularly sensitive to the treatment of textual reference
relations [27, 6, 14]. The capability to properly deal with
various forms of anaphora is a prerequisite for the sound-
ness and validity of the knowledge bases we create as a re-
sult of the text understanding process and likewise for the
feasibility of sophisticated retrieval and question answering
applications based on the acquired text knowledge.
2. SYSTEM ARCHITECTURE
The overall architecture of SynDiKATe, an acronymwhich
stands for \Synthesis of Distributed Knowledge Acquired
from Texts", is summarized in Figure 1. Incoming texts, T
i
,
are mapped into corresponding text knowledge bases, TKB
i
,
which contain a representation of T
i
's content. This knowl-
edge base platform may feed various information services,
such as inferentially supported question answering (fact re-
trieval), text passage retrieval or text summarization [7].
2.1 Sentence-Level Understanding
Grammatical knowledge for syntactic analysis is based
on a fully lexicalized dependency grammar [11], we refer to
as Lexicon in Figure 1. Basic word forms (lexemes) con-
stitute the leaf nodes of the lexicon tree, which are further
abstracted in terms of a hierarchy of lexeme class speci-
cations at dierent levels of generality. The Generic Lexi-
con in Figure 1 contains lexical material which is domain-
independent (lexemes such as move, with, or month), while
domain-specic extensions are kept in specialized lexicons
serving the needs of particular subdomains, e.g., IT (hard
disk, color printer, etc.) or MED (gastritis, surface mucus,
etc.). Dependency grammars capture binary valency con-
straints between a syntactic head (e.g., a noun) and possi-
ble modiers (e.g., a determiner or an adjective). To estab-
lish a dependency relation between a head and a modier,
all the lexicalized constraints on word order, compatibility
of morphosyntactic features, and semantic criteria must be
fullled. This leads to a strictly local computation scheme
which inherently lends itself to robust partial parsing [5].
Figure 1: Architecture of a SynDiKATe System
Conceptual knowledge about the dierent domains is
expressed in a Kl-One-like description logic language [28].
Corresponding to the division at the lexical level, the on-
tologies we provide are split up between one that is used by
all applications, the Upper Ontology, while several dedicated
ontologies account for the conceptual requirements of par-
ticular domains, e.g., IT (HardDisk, ColorPrinter, etc.)
or MED (Gastritis, SurfaceMucus, etc.).
Semantic knowledge accounts for emerging conceptual
relations between conceptual items according to those de-
pendency relations that are established between their cor-
responding lexical items. Semantic interpretation schemata
mediate between both levels in a way as abstract and general
as possible [20]. These schemata are applied to semantically
interpretable subgraphs which are, from a semantic point of
view, \minimal" subgraphs of the incrementally built depen-
dency graph. Their bounding nodes contain content words
(i.e., nouns, verbs, and adjectives, all of which have a concep-
tual correlate in the domain ontologies), while all possibly
intervening nodes (zero up to four) contain only noncon-
tent words (such as prepositions, articles, auxiliaries, etc.,
all of which have no conceptual correlates). Semantic in-
terpretation schemata are fully embedded in the knowledge
representation model and system (cf. Figure 1).
The ParseTalk system, which comprises the lexicalized
grammar and associated dependency parser, is embedded in
an object-oriented computation model. So, the dependency
relations are computed by lexical objects, so-called word ac-
tors, through strictly local message passing, only involving
the lexical items they represent. To illustrate how a de-
pendency relation is established computationally, we give a
sketch of the basic protocol for incremental parsing [5]:
 After a word has been read from textual input by
the WordScanner (step A
1
in Figure 1), its associated
lexeme (specied in the Lexicon) is identied (step
A
2
) and a corresponding word actor gets initialized
(step B
1
). As all content words are directly linked to
the conceptual system, each lexical item w that has a
conceptual correlate C in the domain knowledge base
(step A
3
) gets instantiated in the text knowledge base
(step B
2
). The lexical item Festplatte (hard disk)
with the conceptual correlate Hard-Disk is instanti-
ated, e.g., by Hard-Disk.3, the particular item being
talked about in a given text.
1
 For integration in the parse tree, the newly created
word actor searches its head (alternatively, its modi-
er) by sending parallel requests for dependential gov-
ernment to its left context (step C). The search space
is restricted, since these requests are propagated up-
wards only along the `right shoulder' of the depen-
dency graph constructed so far. All word actors ad-
dressed this way check, in parallel, whether their va-
lency restrictions, i.e., grammatical and conceptual con-
straints, are met by the requesting word actor. Step
D simulates a conceptual check in the text knowledge
base, step E illustrates a test in the discourse memory.
 If all required constraints are fullled by one of the
targeted word actors, an immediate semantic interpre-
tation is performed. This usually alters the conceptual
representation structures by way of slot lling (step F ).
Semantic interpretation consists of nding a relational
link between the conceptual correlates of the two content
words bounding the associated semantically interpretable
subgraph. The linkage may either be constrained by depen-
dency relations (e.g., the subject: relation of a transitive
verb such as \sell" may only be interpreted conceptually
in terms of agent or patient roles), by intervening lexical
material (e.g., some prepositions impose special role con-
straints, such as mit (with) does in terms of has-part or
instrument roles), or it may be constrained by concep-
tual criteria only (as with the genitive: dependency rela-
tion, which unlike subject: imposes no additional selective
conceptual constraints for interpretation). The correspond-
ing knowledge about these language-specic constraints is
densely encoded in the Lexicon class hierarchy, an approach
which heavily relies on the property inheritance mechanisms
inherent to the object-oriented paradigm.
2.2 Text-Level Understanding
2.2.1 Referential Text Phenomena
The textual phenomena we deal with in SynDiKATe es-
tablish referential links between consecutive utterances in a
coherent text such as illustrated by three possible continua-
tions of sentence (1), with three dierent forms of extrasen-
tential anaphora:
(1) Compaq verkauft ein Notebook mit einer Festplatte, die
von Seagate hergestellt wird.
(Compaq sells a notebook with a hard disk that is man-
ufactured by Seagate.)
(2) Pronominal Anaphora:
Es ist mit einer Pentium-III-CPU ausgestattet.
(It comes with a Pentium-III CPU.)
(3) Nominal Anaphora:
Der Rechner ist mit einer Pentium-III-CPU ausgestattet.
(The machine comes with a Pentium-III CPU.)
(4) Functional Anaphora:
Der Arbeitsspeicher kann auf 96 MB erweitert werden.
(The main memory can be expanded up to 96MB.)
1
Due to the recognition of referential relations at the text
level of analysis this instantiation might be readjusted by
subsequent coreference declarations (cf. Section 2.2).
Compaq sells a Notebook with a hard disk that is manufactured by Seagate.
3
ein
4
2
5
1
Compaq
subject:
propo:
verkauft
die
,
delimiter:
subject:
relative:specifier:
Notebook
hergestellt
von
Seagate
ppadjunct:
pobject:
wird
ppatt:
pobject:
object:
mit
specifier:
Festplatte
.
einer
verbpart:
Figure 2: Dependency Parse for Sentence (1)
Figure 3: Conceptual Interpretation for Sentence (1)
The results of sentence-level analysis for sentence (1) are
given in Figure 2, which contains a syntactic dependency
graph (together with ve congurations of semantically in-
terpretable subgraphs), and Figure 3, which displays its con-
ceptual representation. For text-level analysis, pronominal
anaphora still heavily depend on grammatical conditions {
the agreement of the antecedent (\Notebook") and the pro-
noun (\Es" (it)) in gender and number; also conceptual cri-
teria apply insofar as a potential antecedent must t the
conceptual role (or case frame) restrictions when it is in-
tegrated in governing structures, say, the head verb of the
clause. In general, however, the inuence of grammatical
criteria gradually diminishes for other types of text phe-
nomena, while the inuence of conceptual criteria increases.
For nominal anaphora, number constraints are still valid,
while a generalization relation between the anaphoric noun
(\Rechner" (machine)) and its proper antecedent (\Note-
book") must hold, in addition. In the case of functional
anaphora, no grammar constraints at all apply, while quite
sophisticated conceptual role path conditions come into play,
e.g., \Arbeitsspeicher" (main memory) being a constituent
physical part of \Notebook".
The problems text phenomena cause are of vital impor-
tance for the adequacy of the representation structures re-
sulting from text processing, and are centered around the no-
tions of incomplete, invalid and incoherent knowledge bases.
Incomplete knowledge bases emerge when references to
already established discourse entities are simply not recog-
nized, as in the case of pronominal anaphora. Consider the
reference relationship between the pronoun \Es" (it) in sen-
tence (2) which refers to the noun phrase \ein Notebook"
(a notebook) in sentence (1). The occurrence of the pro-
noun is not reected at the conceptual level, since pronouns
(as noncontent words) do not have conceptual correlates.
Hence, an incomplete concept graph emerges as shown in
Figure 4 | the referent for the pronoun \Es" (it), Note-
book.2, is not linked to Pentium-III-CPU.6. An adequate
treatment with a properly resolved anaphor is shown in Fig-
ure 6, where the representation of the relevant portions of
sentence (1) is linked to the one of sentence (2), in particu-
Figure 4: Unresolved Pronominal Anaphor, Sentence (2)
Figure 5: Unresolved Nominal Anaphor, Sentence (3)
Figure 6: Resolved Anaphors, Sentences (1) and (2)/(3)
lar by determining the equip-patient role between Equip.7
and the proper referent, Notebook.2.
Invalid knowledge bases emerge when each entity which
has a dierent denotation at the text surface is treated as
a formally distinct conceptual item at the symbol level of
knowledge representation, although all dierent denotations
refer literally to the same conceptual entity. This is the
case for nominal anaphora, an example of which is given by
the reference relation between the noun phrase \Der Rech-
ner" (the machine) in sentence (3) and the noun phrase \ein
Notebook" (a notebook) in sentence (1). An invalid referen-
tial description appears in Figure 5, where Computer.5 is
introduced as a new entity in the discourse, whereas Figure
6 shows the valid conceptual representation capturing the
intended meaning at the representation level, viz. maintain-
ing Notebook.2 as the proper referent (note that pronom-
inal as well as nominal anaphora are two equivalent ways to
corefer to the discourse entity denoted by Notebook.2).
Finally, incoherent knowledge bases emerge when entities
which are linked by nontaxonomic conceptual relations at
the knowledge level occur in a text such that an implicit
reference to these relations can be made in the text source.
Unlike the previously discussed cases of coference, these
relations have to be made explicit at the symbol level of
the targeted text knowledge base by a search for connect-
ing paths between the concepts involved [6]. This is the
basic scenario for functional (or bridging) anaphora. Con-
sider, e.g., the relationship holding between the noun phrase
\Der Arbeitsspeicher" (the main memory) in sentence (4),
which refers to the noun phrase \ein Notebook" (a note-
book) in sentence (1). In Figure 8 the relational link miss-
ing in Figure 7 between Main-Memory.8 and Notebook.2
is established (via a has-part-type relation, viz. has-main-
memory), and, hence, representational coherence at the sym-
bol level of knowledge representation is preserved.
Figure 7: Unresolved Functional Anaphor, Sentence (4)
Figure 8: Resolved Functional Anaphor, Sentences (1)
and (4)
Disregarding textual phenomena will cause dysfunctional
system behavior. A query Q such as
Q : (retrieve ?x (Computer ?x))
A-: (|I| Notebook.2, |I| Computer.5)
A+: (|I| Notebook.2)
triggers a search for all instances of Computer in the text
knowledge base. Given an invalid knowledge base (cf. Fig-
ures 3 and 5), the incorrect answer (A-) contains two entities,
viz. Notebook.2 and Computer.5 | both are in the ex-
tension of the concept Computer. If, however, a valid text
knowledge base such as the one in Figure 6 or 8 is given,
only the correct answer, Notebook.2, is inferred (A+).
Rendering also quantitative substance to our claims, we
analyzed a randomly chosen sample of 100 reports on his-
tological ndings with approximately 14,000 text tokens [9].
In IT texts, (pro)nominal anaphora and functional anaphora
occur at an almost balanced rate [27]. In the medical texts,
however, functional anaphora turn out to be the major glue
for establishing local coherence, while anaphora, pronomi-
nal anaphora in particular, play a far less important role
than in other text genres. The high proportion of func-
tional anaphora (45%) [42%-48%]
2
and the remarkable rate
of nominal (34%) [31%-37%] compared to extrasentential
pronominal anaphora (2%) [1%-3%] is clearly an indication
of the primary orientation in medical texts to convey facts
in a very compact manner. Two consequences can be drawn
from this observation. First, resolution procedures for func-
tional anaphora { supplementing well-researched procedures
for (pro)nominal anaphora { have to be provided urgently
(cf. [6] for a fully worked out approach). Second, functional
anaphora presuppose a considerable amount of deep back-
ground knowledge, with emphasis on partonomic reasoning
[13], supplementing well-known principles of taxonomic rea-
soning for text understanding.
2
For all percentage numbers 95% condence intervals are
supplied in square brackets.
2.2.2 Centering Model for Anaphora Resolution
In order to avoid the emergence of incomplete, invalid and
incoherent text knowledge bases we consider discourse enti-
ties for establishing reference relations with upcoming items
from the textual input at a local [27] and at a global level
[14] of cohesion. To preserve adequate text representation
structures a centering mechanism is used. The discourse en-
tities which occur in an utterance U
i
constitute its set of
forward-looking centers, C
f
(U
i
). The elements in C
f
(U
i
)
are ordered to reect relative prominence in U
i
in the sense
that the most highly ranked element of C
f
(U
i
) is the most
likely antecedent of an anaphoric expression in U
i+1
, while
the remaining elements are ordered according to decreasing
preference for establishing referential links.
While it is usually assumed (for the English language,
in particular) that grammatical roles are the major deter-
minant for the ranking on the C
f
[4], we claim that for
German { a language with relatively free word order { it
is the functional information structure of the sentence [27].
Accordingly, the constraints on the ordering of entries in
C
f
(U
i
) prefer hearer-old (either evoked or unused) elements
in an utterance (i.e., those that can be related to previ-
ously introduced discourse elements or generally accessi-
ble world knowledge) over mediated (inferrable) ones, while
these are preferred over hearer-new (brand-new) elements
for anaphora resolution. If two elements belong to the same
category, then preference is dened in terms of linear prece-
dence of the discourse units in the source text.
When we apply these criteria to sentence (1), Table 1 de-
picts the resulting order of forward-looking centers in C
f
(S
1
).
Since we have no discourse-bound elements in the rst sen-
tence, textual precedence applies exclusively to the ordering
of the center list items. Only nouns and their conceptual
correlates are taken into consideration. The tuple notation
takes the conceptual correlate of the lexical item in the text
knowledge base in the rst place, while the lexical surface
form appears in the second place.
(1) Cf: [Compaq: Compaq, Notebook.2: Notebook,
Hard-Disk.3: Festplatte, Seagate: Seagate]
Table 1: Centering Data for Sentence (1)
Processing of the centering list C
f
(S
1
) for sentence (3)
until the generalization constraint is fullled, nally, results
in a query whether Notebook is subsumed by Computer,
the conceptual correlate of the lexical item \Rechner". As
this relationship obviously holds, in the conceptual represen-
tation structure of sentence (3) (cf. Figure 5) Computer.5,
the literal instance identier, is declared coreferent toNote-
book.2, the referentially valid identier. Instead of having
two unlinked sentence graphs, Figures 3 and 5, the reference
resolution for (pro)nominal anaphora leads to joining them
in a common valid text graph (Figure 6). In particular,
Notebook.2 links to the relation equip-patient, formerly
occupied by Computer.5. The corresponding centering list
at the end of the analysis of sentence (3) is provided in Table
2 (C
f
(S
1
) has been updated to reect the consumption of
the antecedent, Notebook.2, in the processing of C
f
(S
3
)).
(1) Cf: [Compaq: Compaq, Notebook.2: Notebook,
Hard-Disk.3: Festplatte, Seagate: Seagate]
(3) Cf: [Notebook.2: Rechner,
Pentium-III-CPU.6: Pentium-III-CPU]
Table 2: Centering Data for Sentences (1) and (3)
2.3 Textual Learning
The approach to learning new concepts as a result of text
understanding builds on two dierent sources of evidence |
the prior knowledge of the domain the texts are about, and
grammatical constructions in which unknown lexical items
occur in the texts. The architecture of SynDiKATe's con-
cept learning component is depicted in Figure 9.
linguistic
quality
labels
conceptual
labels
Hypothesis
space-p
Hypothesis
Qualifier
quality
space-q
Quality Machine
1
2
space-1
space-i
space-n
Hypothesis
Hypothesis
Hypothesis
Language Processor
dependency parse graph
text knowledge base
Figure 9: SynDiKATe's Learning Component
The ParseTalk system generates dependency parse graphs.
The kinds of syntactic constructions (e.g., genitive, apposi-
tive, comparative), in which unknown lexical items appear,
are recorded and later assessed relative to the credit they
lend to a particular concept hypothesis, e.g., high for ap-
positives (\the notebook X"), lower for genitives (\Compaq's
X"). The conceptual interpretation of parse trees involving
unknown lexical items in the text knowledge base leads to the
deduction of concept hypotheses. These are further enriched
by conceptual annotations which reect structural patterns
of consistency, mutual justication, analogy, etc. relative to
already available concept descriptions in the text knowledge
base or other hypothesis spaces. Both kinds of evidence, in
particular their predictive `goodness' for the learning task,
are represented by corresponding sets of linguistic and con-
ceptual quality labels.
Alternative concept hypotheses for each unknown lexi-
cal item are organized in terms of corresponding hypothesis
spaces, each of which holds a dierent conceptual reading.
An inference engine embedded in the terminological system,
the so-called quality machine, determines the overall credi-
bility of single concept hypotheses by taking the available set
of quality labels for each hypothesis into account. The qual-
ier, a terminological classier extended by an evaluation
metric for quality classes, computes a preference ranking of
those hypotheses which remain valid after the text has been
processed completely (cf. [12] for details).
3. COVERAGE AND EVALUATION
SynDiKATe's coverage varies considerably depending on
the target domain. The generic lexicon currently includes
3,000 entries, the IT lexicon adds 5,000, while the MED
lexicon contributes 70,000 entries each. The Upper Ontology
contains 1,200 concepts and roles, to which the IT ontology
adds 3,000 and the MED ontology contributes 240,000 items.
The IT domain was chosen as a testbed that can be ex-
tended on demand. The MED domain, however, is subject
to ontology engineering eorts on a larger scale. In order
to cope with the enormous knowledge engineering require-
ments, we semi-automatically transformed large portions of
a semantically weak, yet high-volume medical terminology
(UMLS) to a very large terminological knowledge base [21].
Admittedly, SynDiKATe has not yet undergone a thor-
ough empirical evaluation in one of the envisaged applica-
tion dimensions. We have, however, carefully evaluated its
subcomponents. The results can be summarized as follows:
Sentence Parsing. We compared a standard active chart
parser with full backtracking capabilities with the parser
of SynDiKATe, which is characterized by limited memo-
ization and restricted backtracking capabilities, using the
same grammar specications. On average, SynDiKATe's
parser exhibits a linear time complexity the factor of which
is dependent on ambiguity rates of input sentences. The
active chart parser runs into exponential time complexity
whenever it encounters extragrammatical or ungrammatical
input, since then it conducts an exhaustive search of the en-
tire parse space. The loss of structural descriptions due to
the parser's incompleteness amounts to 10% compared with
the complete, though intractable parser [5].
Text Parsing. While with respect to resolution capac-
ity (eectiveness) no signicant dierences could be deter-
mined, the functional centering model we propose outper-
forms the best-known centering algorithms by a rate of 50%
with respect to a measure of computation costs which con-
siders \cheap" and \expensive" transitional moves between
utterances to assess a text's coherency. Hence, the proce-
dure we propose is more e?cient [27].
Semantic Interpretation. Our group has been pioneer-
ing work on the empirical evaluation of meaning representa-
tions. We assessed the quality and coverage of semantic in-
terpretation for randomly sampled texts in the two domains
we consider. While recall was rather low (57% for MED, 31%
for IT), precision peaked at 97% and 94%, respectively [19].
\Heavy" Semantics. We can deal with intricate seman-
tic phenomena for which we have provided the rst empirical
evaluation data available at all. This relates to the resolu-
tion of metonymies, where we have determined a gain in
eectiveness that amounts to 16% compared with the best
procedures known so far [16], as well as it relates to compar-
atives and evaluative assertions, where gains in eectiveness
were almost tripled [25].
Concept Learning. The performance of the concept
learning component has been compared to standard learning
mechanisms based on the terminological classier available
in any sort of description logics systems. Our data indicate
an increase of performance of 8% (87% accuracy, while that
of standard classiers is on the order of 79%) [12].
Evaluating a text knowledge acquisition rather than an IE
system poses hard methodological problems [2]. The main
reason being that a gold standard for comparison | what
constitutes a canonical, commonly agreed upon interpreta-
tion of the content of a text? | is hard to establish, even
for technical texts. A follow-up problem is constituted by
the lack of a signicant amount of annotated text knowl-
edge bases on which comparative analyses might be assessed.
MUC-style evaluation metrics, e.g., have already been qual-
ied not to adequately reect the functionality of less con-
strained text understanders [29].
4. CONCLUSIONS
A major hypothesis underlying the design of SynDiKATe
is that ignoring the referential relations between adjacent
utterances will lead to referentially incomplete, invalid, or
incoherent text knowledge bases. We determine plausible
discourse units for reference resolution using the centering
model. This allows us to deal with various forms of pronom-
inal, nominal and functional anaphora in a uniform way.
In order to establish local coherence at the text represen-
tation level, single discourse entities related by anaphoric
expressions have to be conceptually linked. We claim that
only sophisticated knowledge representation languages with
powerful terminological reasoning capabilities, such as those
from the KL-ONE family, are able to deal with the full range
of challenges of referentially adequate text understanding, in
particular considering nominal and functional anaphora.
These two types of anaphora pose an enormous burden
on the availability of rich domain knowledge. We respond
to this challenge in two ways. In a large-scale knowledge
engineering eort, we semi-automatically transform a se-
mantically weak though huge thesaurus-style medical knowl-
edge source into a terminological knowledge base. If such a
human-made resource is missing, we turn to a purely auto-
matic approach of bootstrapping a given domain knowledge
base as part of on-going text understanding processes.
The depth of understanding we provide comes closest to
systems such as Scisor [18], Tacitus [15] or Pundit/Kernel
[17], but SynDiKATe's knowledge acquisition strategies or
learning capabilities have no counterpart there. Text under-
standers which incorporate learning components are even
rarer but systems such as Snowy [3] or Wrap-Up [23] ei-
ther have a very narrow domain theory and lack robustness
for dealing with unseen input eectively, or fail to account
for a wide range of referential text phenomena, respectively.
5. ACKNOWLEDGMENTS
The development of the SynDiKATe system has been sup-
ported by various grants from Deutsche Forschungsgemeinschaft
under Ha 2097/*. SynDiKATe would not have come to existence
without the exciting contributions and enthusiasm of current and
former members of the group, in particular, Steen Staab,
Katja Markert, Michael Strube, Martin Romacker, Stefan Schulz,
Klemens Schnattinger, Norbert Broker, Peter Neuhaus, Susanne
Schacht, Manfred Klenner, and Holger Schauer.
6. REFERENCES
[1] Jim Cowie and Wendy Lehnert. Information extraction.
Communications of the ACM, 39(1):80{91, 1996.
[2] Carol Friedman and George Hripcsak. Evaluating natural
language processors in the clinical domain. Methods of
Information in Medicine, 37(4/5):334{344, 1998.
[3] Fernando Gomez and Carlos Segami. The recognition and
classication of concepts in understanding scientic texts.
Journal of Experimental and Theoretical Articial
Intelligence, 1(1):51{77, 1989.
[4] Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.
Centering: A framework for modeling the local coherence of
discourse. Computational Linguistics, 21(2):203{225, 1995.
[5] Udo Hahn, Norbert Broker, and Peter Neuhaus. Let's
ParseTalk: Message-passing protocols for object-oriented
parsing. In H. Bunt and A. Nijholt, editors, Advances in
Probabilistic and other Parsing Technologies, pages
177{201. Kluwer, 2000.
[6] Udo Hahn, Katja Markert, and Michael Strube. A
conceptual reasoning approach to textual ellipsis. In
Proceedings of the ECAI'96, pages 572{576, 1996.
[7] Udo Hahn and Ulrich Reimer. Knowledge-based text
summarization: Salience and generalization operators for
knowledge base abstraction. In I. Mani and M. Maybury,
editors, Advances in Automatic Text Summarization, pages
215{232. MIT Press, 1999.
[8] Udo Hahn and Martin Romacker. Content management in
the SynDiKATe system: How technical documents are
automatically transformed to text knowledge bases. Data &
Knowledge Engineering, 35(2):137{159, 2000.
[9] Udo Hahn, Martin Romacker, and Stefan Schulz. Discourse
structures in medical reports { watch out! The generation
of referentially coherent and valid text knowledge bases in
the medSynDiKATe system. International Journal of
Medical Informatics, 53(1):1{28, 1999.
[10] Udo Hahn, Martin Romacker, and Stefan Schulz. How
knowledge drives understanding: Matching medical
ontologies with the needs of medical language processing.
Articial Intelligence in Medicine, 15(1):25{51, 1999.
[11] Udo Hahn, Susanne Schacht, and Norbert Broker.
Concurrent, object-oriented natural language parsing: The
ParseTalk model. International Journal of
Human-Computer Studies, 41(1/2):179{222, 1994.
[12] Udo Hahn and Klemens Schnattinger. Towards text
knowledge engineering. In Proceedings of the AAAI'98,
pages 524{531, 1998.
[13] Udo Hahn, Stefan Schulz, and Martin Romacker.
Partonomic reasoning as taxonomic reasoning in medicine.
In Proceedings of the AAAI'99, pages 271{276, 1999.
[14] Udo Hahn and Michael Strube. Centering in-the-large:
Computing referential discourse segments. In Proceedings of
the ACL'97/EACL'97, pages 104{111, 1997.
[15] Jerry R. Hobbs, Mark E. Stickel, Douglas E. Appelt, and
Paul Martin. Interpretation as abduction. Articial
Intelligence, 63(1/2):69{142, 1993.
[16] Katja Markert and Udo Hahn. On the interaction of
metonymies and anaphora. In Proceedings of the IJCAI'97,
pages 1010{1015, 1997.
[17] Martha S. Palmer, Rebecca J. Passonneau, Carl Weir, and
Tim Finin. The Kernel text understanding system.
Articial Intelligence, 63(1/2):17{68, 1993.
[18] Lisa F. Rau, Paul S. Jacobs, and Uri Zernik. Information
extraction and text summarization using linguistic
knowledge acquisition. Information Processing &
Management, 25(4):419{428, 1989.
[19] Martin Romacker and Udo Hahn. An empirical assessment
of semantic interpretation. In Proceedings of the NAACL
2000, pages 327{334, 2000.
[20] Martin Romacker, Katja Markert, and Udo Hahn. Lean
semantic interpretation. In Proceedings of the IJCAI'99,
pages 868{875, 1999.
[21] Stefan Schulz and Udo Hahn. Knowledge engineering by
large-scale knowledge reuse: Experience from the medical
domain. In Proceedings of KR 2000, pages 601{610, 2000.
[22] Stefan Schulz, Udo Hahn, and Martin Romacker. Modeling
anatomical spatial relations with description logics. In
Proceedings of the AMIA 2000, pages 779{783, 2000.
[23] Stephen Soderland and Wendy Lehnert. Wrap-up: A
trainable discourse module for information extraction.
Journal of Articial Intelligence Research, 2:131{158, 1994.
[24] Steen Staab and Udo Hahn. Comparatives in context. In
Proceedings of the AAAI'97, pages 616{621, 1997.
[25] Steen Staab and Udo Hahn. \Tall", \good", \high" {
compared to what? In Proceedings of the IJCAI'97, pages
996{1001, 1997.
[26] Steen Staab and Udo Hahn. Scalable temporal reasoning.
In Proceedings of the IJCAI'99, pages 1247{1252, 1999.
[27] Michael Strube and Udo Hahn. Functional centering:
Grounding referential coherence in information structure.
Computational Linguistics, 25(3):309{344, 1999.
[28] William A. Woods and James G. Schmolze. The Kl-One
family. Computers & Mathematics with Applications,
23(2/5):133{177, 1992.
[29] P. Zweigenbaum, J. Bouaud, B. Bachimont, J. Charlet, and
J.-F. Boisvieux. Evaluating a normalized conceptual repre-
sentation produced from natural language patient discharge
summaries. In Proceedings of the AMIA'97, pages 590{594.
