Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, pages 84?93,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
On the Information Conveyed by Discourse Markers
Fatemeh Torabi Asr
MMCI Cluster of Excellence
Saarland University
Germany
fatemeh@coli.uni-saarland.de
Vera Demberg
MMCI Cluster of Excellence
Saarland University
Germany
vera@coli.uni-saarland.de
Abstract
Discourse connectives play an impor-
tant role in making a text coherent
and helping humans to infer relations
between spans of text. Using the
Penn Discourse Treebank, we investi-
gate what information relevant to in-
ferring discourse relations is conveyed
by discourse connectives, and whether
the specificity of discourse relations re-
flects general cognitive biases for estab-
lishing coherence. We also propose an
approach to measure the effect of a dis-
course marker on sense identification
according to the different levels of a re-
lation sense hierarchy. This will open a
way to the computational modeling of
discourse processing.
1 Introduction
A central question in psycholinguistic model-
ing is the development of models for human
sentence processing difficulty. An approach
that has received a lot of interest in recent
years is the information-theoretic measure of
surprisal (Hale, 2001). Recent studies have
shown that surprisal can successfully account
for a range of psycholinguistic effects (Levy,
2008), as well as account for effects in nat-
uralistic broad-coverage texts (Demberg and
Keller, 2008; Roark et al, 2009; Frank, 2009;
Mitchell et al, 2010). : what work of Roark
and Frank you mean here? Under the no-
tion of the Uniform Information Density hy-
pothesis (UID, Levy and Jaeger, 2007; Frank
and Jaeger, 2008), surprisal has also been
used to explain choices in language produc-
tion: When their language gives people the
option to choose between different linguistic
encodings, people tend to choose the encod-
ing that distributes the information more uni-
formly across the sentence (where the informa-
tion conveyed by a word is its surprisal).
When using surprisal as a cognitive model
of processing difficulty, we hypothesize that
the processing difficulty incurred by the hu-
man when processing the word is proportional
to the update of the interpretation, i.e. the in-
formation conveyed by the word (Hale, 2001;
Levy, 2008). We can try to estimate partic-
ular aspects of the information conveyed by a
word, e.g., the information conveyed about the
syntactic structure of the sentence, the seman-
tic interpretation, or about discourse relations
within the text.
This paper does not go all the way to
proposing a model of discourse relation sur-
prisal, but discusses first steps towards a
model for the information conveyed by dis-
course connectors about discourse relations,
based on available resources like the Penn Dis-
course Treebank (Prasad et al, 2008). First,
we quantify how unambiguously specific dis-
course relations are marked by their typical
connectors (Section 4.1) and test whether eas-
ily inferable relations are on average marked
more ambiguously than relations which are
less expected according to the default assump-
tion of a reader. This idea is shaped with
respect to the UID hypothesis: expected re-
lations can afford to be signaled by weaker
markers and less expected ones should be
marked by strong connectors in order to keep
the discourse-level information density smooth
throughout the text (Section 4.2). We then
investigate in more detail the types of ambi-
guity that a reader might face when process-
ing discourse relations. While some ambigui-
ties lie in discourse connectors, it also happens
that more than one relation exist at the same
time between two text spans. We show that
84
some discourse markers also signal the pres-
ence of several relations (Section 5). In com-
putational modeling as well as laboratory set-
ups, one should therefore have a strategy to
deal with the different types of ambiguities.
Finally, we ask what granularity of distinction
from other discourse relations (with respect to
the PDTB relation sense hierarchy) each En-
glish discourse connective conveys (Section 6).
2 Discourse Relations and their
Markers
A cognitive approach to discourse process-
ing emphasizes on the procedural role of the
connectives to constrain the way readers re-
late the propositions in a text (Blakemore,
1992; Blass, 1993). Experimental findings
suggest that these markers can facilitate the
inference of specific discourse relations (De-
gand and Sanders, 2002), and that discourse
connectors are processed incrementally Ko?hne
and Demberg (2013). People can however in-
fer discourse relations also in the absence of
discourse connecotrs, relying on the propo-
sitional content of the sentences and their
world-knowledge (Hobbs, 1979; Asher and
Lascarides, 1998). Asr and Demberg (2012b)
point out that similar inferences are also nec-
essary for discourse relations which are only
marked with a weak connector which can be
used for many relations, such as and. Further-
more, we know that the inference of discourse
relations is affected by a set of general cog-
nitive biases. To illuminate the role of these
factors let?s have a look at (1). While the type
of relation between the two events is clearly in-
ferable in (1-a) and (1-b) due to the discourse
connectives, in (1-c), the reader would have
to access their knowledge, e.g., about Harry
(from larger context) or the usual affairs be-
tween bosses and employees, in order to con-
struct a discourse relation.
(1) a. The boss was angry because Harry skipped
the meeting (reason).
b. The boss was angry, so Harry skipped the
meeting (result).
c. The boss was angry and Harry skipped the
meeting.
Here, not only both reason and result inter-
pretations but even an independent parallel re-
lation (simple Conjunction) between the two
events are possible to be inferred as a relatively
neutral connective, i.e., and is used. Levinson
(2000) notes in his discussion on presumptive
meanings that ?when events are conjoined they
tend to be read as temporally successive and if
at all plausible, as causally linked?. If this is
true then the result reading is most probable
for (1-c). General preferences of this kind have
been investigated via experimental approaches
(Segal et al, 1991; Murray, 1997; Sanders,
2005; Kuperberg et al, 2011). Segal et al
(1991) and Murray (1997) argue that readers
expect a sentence to be continuous with re-
spect to its preceding context (the continuity
hypothesis). Continuous discourse relations in
terms of congruency and/or temporality are
consequently easier to process than the dis-
continuous ones. Sanders (2005) proposes that
causal relatedness entails the maximum degree
of coherence in a text, therefore readers always
start by attempting to find cause-consequence
relations between neighboring sentences (the
causality-by-default hypothesis). In a similar
vein, Kuperberg et al (2011) shows that read-
ers face comprehension difficulty when sen-
tences in short text spans cannot be put into
causal relation and no marker of other rela-
tions (e.g., Concession) is available.
Taken together, these findings suggest that
world knowledge, general cognitive biases, and
linguistic features of the sentences such as the
presence of a weak or strong marker contribute
to the relational inference. With a look back
to the information theoretic approach to the
linguistic patterns, one could hypothesize that
when one factor is strongly triggering expec-
tation for a specific type of relation the other
factors could remain silent in order to keep the
information distribution uniform. With this
perspective, Asr and Demberg (2012a) tested
whether the predictability of discourse rela-
tions due to general cognitive biases (towards
causality and continuity) can explain the pres-
ence vs. absence of the discourse connectors.
They found that connectors were more likely
to be dropped in the more predictable (causal
or continuous) relations than in others. Our
investigation of the explicit relations in this
paper (the first experiment) looks into this
question in a stricter manner considering how
much information a connective delivers about
discourse relations. Since this information is
85
Figure 1: Hierarchy of senses in PDTB
(Prasad et al, 2008)
closely related to the ambiguities a connec-
tive removes (or maybe adds to the context)
in the course of reading, we dedicate a sepa-
rate section in this paper to illuminate differ-
ent types of ambiguities. Also, a more detail
question would be what types of informa-
tion a connective can convey about one or sev-
eral discourse relations. To our best of knowl-
edge there has been no corpus-based study so
far about this last point which we will try to
model in our third experiment.
3 Penn Discourse Treebank
The Penn Discourse Treebank (PDTB, Prasad
et al, 2008) is a large corpus annotated with
discourse relations, (covering the Wall Street
Journal part of the Penn Treebank). The an-
notation includes sentence connectives, spans
of their arguments and the sense of discourse
relations implied by the connectives. The rela-
tion labels are chosen according to a hierarchy
of senses (Figure 1). Annotators were asked
to find the Explicit discourse connectives and
respectively select a sense (as much specific as
possible) from the hierarchy. For neighboring
sentences where no explicit marker existed in
the original text they were asked to first insert
a suitable connective between the two argu-
ments and then annotate a relation sense, in
this case categorized as Implicit. If an expres-
sion ? not belonging to the list of constituted
connectives ? in one of the involved sentences
is already indicative of a specific relation, then
instead they marked that expression and put
the relation into the AltLex category. In all
of our experiments only the explicit relation
are considered. Some connectives were anno-
tated with two sense labels in the PDTB. In
our analyses below, we count these text spans
twice (i.e., once for each sense), resulting in a
total of 19,458 relation instances.
4 Are Unexpected Relations
Strongly Marked?
4.1 Markedness Measure
Point-wise mutual information (pmi) is an
information-theoretic measure of association
between two factors. For our purpose of mea-
suring the markedness degree of a relation r in
the corpus, we calculate the normalized pmi of
it with any of the connectives, written as c that
it co-occurs with:
npmi(r; c) =
pmi(r; c)
? log p(r, c)
=
log p(r,c)p(r)p(c)
? log p(r, c)
=
log p(r)p(c)
log p(r, c)
? 1
npmi is calculated in base 2 and ranges be-
tween ?1 and 1. For our markedness measure,
we scale it to the interval of [0, 1] and weigh it
by the probability of the connector given the
relation.
0 <
npmi(r; c) + 1
2
< 1
markedness(r) =
?
c
p(c|r)
npmi(r; c) + 1
2
Intuitively, the markedness measure tells us
whether a relation has very specific markers
(high markedness) or whether it is usually
marked by connectors that also mark many
other relations (low markedness).
4.2 Discourse Expectations and
Marker Strength
Given the markedness measure, we are now
able to test whether those relations which are
more expected given general cognitive biases
86
0.62	 ?
0.64	 ?
0.66	 ?
0.68	 ?
0.7	 ?
0.72	 ?
0.74	 ?
0.76	 ?
Temporal	 ?(3696)	 ? Con?gency	 ?(3741)	 ? Expansion	 ?(6431)	 ? Comparison	 ?(5590)	 ?
Markedness	 ?
Figure 2: Markedness of level-1 explicit rela-
tions in the PDTB (frequencies of the relations
given in brackets).
(expecting continuous and causal relations)
are marked less strongly than e.g. discontinu-
ous relations. Figure 2 compares the marked-
ness associated to the explicit relations of the
PDTB when the first level relation sense dis-
tinction is considered.
Figure 2 shows that COMPARISON rela-
tions exhibit higher markedness than other
relations, meaning that discontinuity is
marked with little ambiguity, i.e. markers
of COMPARISON relations are only very rarely
used in other types of discourse relations.
COMPARISON relations are exactly those rela-
tions which were classified in Asr and Demberg
(2012a) as a class of discontinuous relations.
Further experimental evidence also shows that
these relations are more likely to cause pro-
cessing difficulty than others when no connec-
tor is present (Murray, 1997), and that their
markers have a more strongly disruptive effect
than other markers when used incorrectly. Un-
der the information density view, these obser-
vations can be interpreted as markers for com-
parison relations causing a larger context up-
date. The high markedness of COMPARISON re-
lations is thus in line with the hypothesis that
unpredictable relations are marked strongly.
CONTINGENCY relations, on the other hand,
exhibit a lower score of markedness. This
indeed complies with the prediction of
the causality-by-default hypothesis (Sanders,
2005) in conjunction with the UID hypothe-
sis: causal relations can still be easily inferred
even in the presence of ambiguous connectives
because they are preferred by default.
As also discussed in Asr and Demberg
(2012a), some types of EXPANSION relations
are continuous while others are discontinuous;
finding that the level of markedness is near the
average of all relations therefore comes as no
surprise.
More interesting is the case of TEMPORAL
relations: these relations have low marked-
ness, even though this class includes contin-
uous (temporal succession) relations as well as
discontinuous (temporal precedence) relations,
and we would thus have expected a higher level
of markedness than we actually find. Even
when calculating markedness at the more fine-
grained relation distinction level, did not find
a significant difference between the marked-
ness of the temporally forward vs. backward
relations. A low level of markedness means
that the connectors used to mark temporal re-
lations are also used to mark other relations,
in particular, temporal connectives are often
used to mark CONTINGENCY relations. This
observation brings us to the question of gen-
eral patterns of ambiguity in discourse markers
and the ambiguity of discourse relations them-
selves, see Section 5.
5 Ambiguous Connective
vs. Ambiguous Relation
Some discourse connectives (e.g., since, which
can be temporal or causal, or while, which can
be temporal or contrastive) are ambiguous. In
this section, we would like to distinguish be-
tween three different types of ambiguity (all
with respect to the PDTB relation hierarchy):
1. A connector expressing different relations,
where it is possible to say that one but not
the other relation holds between the text
spans, for example since.
2. A connector expressing a class of relations
but being ambiguous with respect to the
subclasses of that relation, for example
but, which always expresses a COMPARISON
relationship but may express any subtype
of the comparison relation.
3. the ambiguity inherent in the relation be-
tween two text spans, where several rela-
87
Relation pair #R1 (total) #R2 (total) #Pair ?2
T.Synchrony?CON.Cause.reason 507 (1594) 353 (1488) 187 1.08E+00
T.Asynchronous.succession?CON.Cause.reason 189 (1101) 353 (1488) 159 2.43E+02 ***
E.Conjunction?CON.Cause.result 352 (5320) 162 (752) 140 2.22E+02 ***
T.Synchrony?EXP.Conjunction 507 (1594) 352 (5320) 123 5.43E+01 ***?
T.Synchrony?CON.Condition.reneral 507 (1594) 70 (362) 52 1.67E+01 ***
T.Synchrony?COM.Contrast.juxtaposition 507 (1594) 77 (1186) 45 1.97E+00
T.Asynchronous.precedence?E.Conjunction 66 (986) 352 (5320) 36 1.15E+01 ***
T.Synchrony?COM.Contrast 507 (1594) 37 (2380) 28 9.55E+00 ***
T.Synchrony?COM.Contrast.opposition 507 (1594) 28 (362) 21 6.78E+00 **
Table 1: Most frequent co-occurring relations in the PDTB, their frequency among multi-labels
(and in the entire corpus)
tions can be identified to hold at the same
time.
The first and second notion of ambiguity re-
fer to what we so far have been talking about:
we showed that some connectors mark can
mark differnt types of relations, and that some
connectives marking a general relation type
but not marking specific subrelations.
The third type of ambiguity is also anno-
tated in the PDTB. Relations which are am-
biguous by nature are either labeled with a
coarse-grained sense in the hierarchy (e.g.,
COMPARISON.Contrast the second most fre-
quent label in the corpus chosen by the anno-
tators when they could not agree on a more
specific relation sense), or are labelled with
two senses. Table 1 lists which two relation
senses were most often annotated to hold at
the same time in the PDTB, along with the
individual frequency (also frequency in the
entire corpus inside brackets). Sub-types of
Cause and TEMPORAL relations appear most
often together, while TEMPORAL.Synchrony is
a label that appears significantly more than
expected among the multi-label instances,
even with a higher frequency than that of
EXPANSION.Conjunction, the most frequent
label in the corpus. Such observations confirm
the existence of the third type of ambiguity in
discourse relations.
Interestingly, these inherently ambiguous
relations also have their own specific mark-
ers, such as meanwhile which occurs in about
70% of its instances with two relation senses1.
1This connective is mostly labeled with
TEMPORAL.Synchrony and EXPANSION.Conjunction.
Interestingly these two labels appear together signif-
icanly less frequently than expected (as marked in
the table with ***?) but when such a cooccurrance
happened in the corpus it has been for the connective
meanwhile.
On the other hand, other well-known ambigu-
ous connectors like since rarely mark inher-
ently ambiguous relations, and most often can
be identified as one specific relation sense by
looking at the content of the arguments. The
importance of the possibility to annotate a
second sense and hence explicitly mark the
inherently ambiguous relations has also been
pointed out by Versley (2011). In fact, a con-
nective like meanwhile can be thought of as
delivering information not only about the pos-
sible relation senses it can express, but also
about the fact that two discourse relations
hold simultaneously.
In conclusion, it is possible that more than
one discourse relation hold between two text
spans. We believe that taking into account
the different types of ambiguity in discourse
relations can also benefit automatic discourse
relation classification methods, that so far ig-
nore multiple relation senses. Relations with
two senses mostly include one temporal sense.
This also (at least partially) explains the low
level of markedness of temporal relations in
Figure 2. Of particular interest is also the find-
ing that there seem to be specific connectors
such as meanwhile which are used to mark in-
herently ambiguous relations.
6 Type of Information Conveyed
by a Discourse Connector
In this experiment, we focus on the differ-
ences among individual connectives in reflect-
ing information about discourse relations from
coarse to fine grained granularity.
6.1 Measure of Information Gain
The mutual information between two discrete
variables which is indicative of the amount of
uncertainty that one removes for inference of
88
the other, can be decomposed in the following
manner:
I(X;Y ) =
?
c
p(c)
?
r
p(r|c) log
p(r|c)
p(r)
The inner sum is known as Kullback-Leibler di-
vergence or relative entropy of the distribution
of relations p(r) independent of the connector
c and the distribution of relations p(r|c) af-
ter observing c2. The relative entropy thus
quantifies in how far knowing the connector c
changes the distribution of relations.
gain(c) = DKL(p(r|c)||p(r))
This formulation also allows us to calculate
the change in distribution for different levels of
the PDTB relation sense hierarchy and thus to
analyse which connectors convey information
about which level of the hierarchy. We define
the measure of enhancement to formalize this
notion:
enhancementxy(c) = gainy(c)? gainx(c)
The enhancementxy(c) indicates the amount
of information delivered by cue c for the
classification of the instances into finer-
grained relation subtypes. For exam-
ple, enhancement01(because) describes how
much information gain because provides
for distinguishing the level-1 relations it
marks from other relations. Similarly,
high enhancement23(because) indicates that
this connective is important for distinguish-
ing among level 3 relations (here, distin-
guishing CONTINGENCY.Cause.reason from
CONTINGENCY.Cause.result relations), while
low enhancement23(if) indicates that if does
not contribute almost any information for
distinguishing among the subtypes of the
CONTINGENCY.Condition relation.
2Note that this formulation is closely related to sur-
prisal: Levy (2008) shows that surprisal(wk+1) =
? logP (wk+1|w1..wk) is equivalent to the KL diver-
gence D(P (T |w1..j+1)||P (T |w1..j)) for ?any stochas-
tic generative process P , conditioned on some (pos-
sibly null) external context, that generates complete
structures T , each consisting at least partly of sur-
face strings to be identified with serial linguistic in-
put?. Note however that in our current formula-
tion of a discourse relation, the simplification to gen-
eral structure-independent surprisal does not hold
(DKL(p(r|c)||p(r)) 6= ? log p(c)) because our relations
(as they are defined here) do not satisfy the above con-
dition for T , in particular, P (r, c) 6= P (r).
6.2 Connective Help in Hierarchical
Classification
Figure 3 shows the amount of enhancement
for 27 frequent (> 100 occurrences) connec-
tives in the corpus in three transitions, namely
from no information to the first level classifi-
cation, from first to the second level and from
second to the third. Most of the connectives
contribute most strongly at the coarsest level
of classification, i.e., their L1-Root enhance-
ment is the highest. In particular, we find that
some of the most frequent connectives such as
but, and, and also only help distinguishing dis-
course relation meaning at the coarsest level of
the PDTB relation hierarchy, but contribute
little to distinguish among e.g. different sub-
types of COMPARISON or EXPANSION. An inter-
esting observation is also that frequent mark-
ers of comparison relations but, though, still
and however provide almost no information
about the second or third level of the hierar-
chy.
Another group of connectors, for example,
instead, indeed and or contribute significantly
more information in transition from the first
to the second level. These are specific markers
of some level-2 relation senses. Among these,
instead and or even help more for the deepest
classification3.
Temporal and causal connectives such as be-
fore, after, so, then ,when and thus have more
contribution to the deepest classification level.
This reflects the distinctions employed in the
definition of the third level senses which has
a direct correlation with the temporal order-
ing, i.e., forward vs. backward transition be-
tween the involved sentences. In other words,
regardless of whatever high-level class of rela-
tion such markers fit in, the temporal infor-
mation they hold make them beneficial for the
3rd level classification.
There are also a few connectives (if, indeed,
for example) that convey a lot of information
about the distinctions made at the first and
second level of the hierarchy, but not about the
third level. The reason for this is either that
the third level distinction can only be made
based on the propositional information in the
3Markers of EXPANSION.Alternative.conjunction
and EXPANSION.Alternative.chosen alternative re-
spectively.
89
0	 ?
0.5	 ?
1	 ?
1.5	 ?
2	 ?
2.5	 ?
3	 ? enhancement	 ?0-??>1	 ?
enhancement	 ?1-??>2	 ?
enhancement	 ?2-??>3	 ?
4.4	 ? 4.0	 ? 3.5	 ?
Figure 3: Enhancement through three levels of relation sense classification obtained by 27 most
frequent connectives in the PDTB ? ordered left to right by frequency.
arguments (this is the case for the sub-types
of conditionals), or that the connector usually
marks a relation which does not have a third
level (e.g., for example is a good marker of
the EXPANSION.Instantiation relation which
does not have any subtypes).
It is worth noting that a sum over enhance-
ments obtained in the three levels results in the
total relative entropy the distribution of dis-
course relations before vs. after encountering
the connective. As expected, ambiguous con-
nectors of the first type of ambiguity (while,
since, when) convey a little bit of information
at each level of distinction, while overall in-
formation gain is relatively small. Ambigu-
ous connectors of the second type of ambigu-
ity (e.g., but, and, if ) convey almost no infor-
mation about specific sub-types of relations.
Finally, markers of inherently ambiguous rela-
tions (meanwhile) stand out for very low in-
formation gain at all levels.
6.3 Discussion
The notion of the information conveyed by a
discourse connector about a discourse relation
can also help to explain two previous find-
ings on the relative facilitative effect of causal
and adversative connectors, that at first glance
seem contradictory.
While Murray (1997) showed a generally
more salient effect for a group of adversative
cues such as however, yet, nevertheless and
but compared with causal connectives there-
fore, so, thus and consequently, others reported
different patterns when particular pairs of con-
nectives were compared: Caron et al (1988)
found greater inference activity and recall ac-
curacy for because sentences than sentences
connected with but. Also, Millis and Just
(1994) found a faster reading time and bet-
ter response to the comprehension questions
in the case of because than that of although
sentences. Interestingly, by looking at Figure
3, we find that because is a more constrain-
ing connective than but and even although,
given that the information gain obtain by this
connective in all levels of relation classifica-
tion is greater than that of but and although.
While adversative connectives are reliable sig-
nals to distinguish comparison relations in a
high-level from the other three major types of
relations, most causal connectives deliver spe-
cific information down to the finer grains. In
particular, because is a distinguished marker of
the reason relation; hence, it should be associ-
ated with a more constraining discourse effect,
while a generally used connective such as but
can serve as the marker of a variety of adver-
sative relations, e.g., a simple Contrast vs. a
Concession relation.
The information-theoretic view can also ac-
count for the larger facilitating effect of highly
constraining causal and adversative connec-
tives on discourse comprehension compared
to additive connectives such as and, also and
moreover (Murray, 1995, 1997; Ben-Anath,
2006). We also can see from the Figure 3 that
the mentioned additive connectives show a rel-
atively lower sum of enhancement.
In summary, the broad classification of a dis-
course connector (Murray, 1997; Halliday and
Hasan, 1976) is not the only factor that deter-
mines how constraining it is, or how difficult it
will be to process. Instead, one should look at
its usage in different context (i.e., specificity
of the connective usage in the natural text).
For example, based on the measurements pre-
sented in the Figure 3 we would expect a rel-
atively high constraining effect of the connec-
tives such as for example and instead. Note
90
however that these predictions strongly de-
pend on the discourse relation sense inventory
and the discourse relation hierarchy. In partic-
ular, it is important to ask in how far compu-
tational linguistics resources, like the PDTB,
reflect the inference processes in humans ? in
how far are the sense distinction and hierar-
chical classification cognitively adequate?
7 Discussion and Conclusion
Discourse Relation Hierarchy and Fea-
ture Space Dimensions Psycholingusitic
models that need to be trained on annotated
data from computational linguistics resources
also have to be concerned about the psycholin-
guistic adequacy of the annotation. In par-
ticular, for a model of discourse relation sur-
prisal, we need to ask which discourse relations
are relevant to humans, and which distinctions
between relations are relevant to them? For
example, it may be possible that the distinc-
tion between cause and consequence (3rd level
PDTB hierarchy) is more important in the in-
ference process than the distinction between
conjunction and list (2nd level PDTB hierar-
chy). Given the fact that more than one dis-
course relation (or none) can hold between two
text segments, one should also ask whether a
hierarchy is the right way to think about the
discourse relation senses at all ? it might be
more adequate to think about discourse con-
nectives conveying information about tempo-
rality, causality, contrast etc, with each con-
nector possibly conveying information about
more than one of these aspects at the same
time.
These questions are also relevant for auto-
matic discourse relation identification: many
approaches to discourse relation identification
have simplified the task to only distinguish
between e.g. the level-1 sense distinctions, or
level-2 distinctions (Versley, 2011; Lin et al,
2011; Hernault et al, 2011; Park and Cardie,
2012), but may be missing to differentiate as-
pects that are important also for many text
interpretation tasks, such as distinguishing be-
tween causes and consequences.
Towards discourse relation surprisal A
computational model of discourse relation sur-
prisal would have to take the actual local con-
text into account, i.e. factors other than just
the connective, and model the interplay of dif-
ferent factors in the arguments of the discourse
relation. We would then be in a position to
argue about the predictability of a specific in-
stance of a discourse relation, as opposed to
arguing based on general cognitive biases such
as the causality-by-default or continuity hy-
potheses.
From the three studies in this paper, we note
that our findings so far are compatible with
a surprisal account at the discourse relation
level: The first study showed that discourse
relations that seem to cause a larger context
update are marked by less ambiguous connec-
tives than relations for which less information
needs to be conveyed in order to be inferred.
This is in line with the UID and the conti-
nuity and causality-by-default hypotheses put
forth by Murray (1997) and Sanders (2005).
The second study then went on to show that
one can distinguish several types of ambiguity
among discourse relations, in particular, more
than one relation can hold between two propo-
sitions, and there are some connectives which
express this inherent ambiguity. In the third
study, we also showed that the effect of par-
ticular discourse markers varies with respect
to their contribution in different levels of re-
lation classification. Some connectives such as
the majority of the adversative ones, simply
help to distinguish contrastive relations from
other classes, while those with a temporal di-
rectionality contribute most in the deeper level
of the PDTB hierarchical classification. The
enhancement measure introduced in this pa-
per can be employed for measuring the effect
of any discriminative feature through the hi-
erarchical classification of the relations. This
work is a first step towards the computational
modeling of the discourse processing with re-
spect to the linguistic markers of the abstract
discourse relations. In future work, we would
like to look at the contribution of different
types of relational markers including sentence
connectives, sentiment words, implicit causal-
ity verbs, negation markers, event modals etc.,
which in the laboratory setup have proven to
affect the expectation of the readers about
an upcoming discourse relation (Kehler et al,
2008; Webber, 2013).
91
References
Asher, N. and Lascarides, A. (1998). Bridging.
Journal of Semantics, 15(1):83?113.
Asr, F. T. and Demberg, V. (2012a). Implic-
itness of discourse relations. In Proceedings
of COLING, Mumbai, India.
Asr, F. T. and Demberg, V. (2012b). Mea-
suring the strength of the discourse cues.
In workshop on the Advances in Discourse
Analysis and its Computational Aspects,
Mumbai, India.
Ben-Anath, D. (2006). The role of connec-
tives in text comprehension. Teachers Col-
lege, Columbia University Working Papers
in TESOL & Applied Linguistics, 5(2).
Blakemore, D. (1992). Understanding ut-
terances: An introduction to pragmatics.
Blackwell Oxford.
Blass, R. (1993). Are there logical relations in
a text? Lingua, 90(1-2):91?110.
Caron, J., Micko, H. C., and Thuring, M.
(1988). Conjunctions and the recall of com-
posite sentences. Journal of Memory and
Language, 27(3):309?323.
Degand, L. and Sanders, T. (2002). The im-
pact of relational markers on expository text
comprehension in l1 and l2. Reading and
Writing, 15(7):739?757.
Demberg, V. and Keller, F. (2008). Data from
eye-tracking corpora as evidence for theories
of syntactic processing complexity. Cogni-
tion, 109(2):193?210.
Frank, A. and Jaeger, T. (2008). Speaking ra-
tionally: Uniform information density as an
optimal strategy for language production.
Proceedings of the 28th meeting of the Cog-
nitive Science Society.
Frank, S. (2009). Surprisal-based compari-
son between a symbolic and a connectionist
model of sentence processing. In Proceedings
of the 31st annual conference of the cogni-
tive science society, pages 1139?1144.
Hale, J. (2001). A probabilistic earley parser
as a psycholinguistic model. In Second meet-
ing of the North American Chapter of the
Association for Computational Linguistics
on Language technologies 2001, pages 1?8.
Halliday, M. and Hasan, R. (1976). Cohesion
in English. Longman (London).
Hernault, H., Bollegala, D., and Ishizuka, M.
(2011). Semi-supervised discourse relation
classification with structural learning. Com-
putational Linguistics and Intelligent Text
Processing, pages 340?352.
Hobbs, J. R. (1979). Coherence and corefer-
ence. Cognitive science, 3(1):67?90.
Kehler, A., Kertz, L., Rohde, H., and Elman,
J. L. (2008). Coherence and coreference re-
visited. Journal of Semantics, 25(1):1?44.
Ko?hne, J. and Demberg, V. (2013). The time-
course of processing discourse connectives.
In Proceedings of the 35th Annual Meeting
of the Cognitive Science Society.
Kuperberg, G., Paczynski, M., and Ditman,
T. (2011). Establishing causal coherence
across sentences: An ERP study. Journal of
Cognitive Neuroscience, 23(5):1230?1246.
Levinson, S. (2000). Presumptive Meanings:
The Theory of Generalized Conversational
Implicature. The MIT Press.
Levy, R. (2008). Expectation-based syntac-
tic comprehension. Cognition, 106(3):1126?
1177.
Levy, R. and Jaeger, T. F. (2007). Speakers
optimize information density through syn-
tactic reduction. In Advances in Neural In-
formation Processing Systems.
Lin, Z., Ng, H., and Kan, M. (2011). Automat-
ically evaluating text coherence using dis-
course relations. In Proceedings of the 49th
Annual Meeting of the Association for Com-
putational Linguistics: Human Language
Technologies-Volume 1, pages 997?1006.
Millis, K. and Just, M. (1994). The influence
of connectives on sentence comprehension.
Journal of Memory and Language.
Mitchell, J., Lapata, M., Demberg, V., and
Keller, F. (2010). Syntactic and seman-
tic factors in processing difficulty: An inte-
grated measure. In Proceedings of the 48th
Annual Meeting of the Association for Com-
putational Linguistics, pages 196?206.
Murray, J. (1995). Logical connectives and
local coherence. Sources of Coherence in
Reading, pages 107?125.
92
Murray, J. (1997). Connectives and narrative
text: The role of continuity. Memory and
Cognition, 25(2):227?236.
Park, J. and Cardie, C. (2012). Improving im-
plicit discourse relation recognition through
feature set optimization. In Proceedings of
the 13th Annual Meeting of the Special In-
terest Group on Discourse and Dialogue,
pages 108?112. Association for Computa-
tional Linguistics.
Prasad, R., Dinesh, N., Lee, A., Miltsakaki,
E., Robaldo, L., Joshi, A., and Webber, B.
(2008). The Penn Discourse Treebank 2.0.
In Proceedings of the 6th International Con-
ference on Language Resources and Evalua-
tion, pages 2961?2968.
Roark, B., Bachrach, A., Cardenas, C., and
Pallier, C. (2009). Deriving lexical and syn-
tactic expectation-based measures for psy-
cholinguistic modeling via incremental top-
down parsing. In Proceedings of the 2009
Conference on Empirical Methods in Nat-
ural Language Processing, pages 324?333,
Singapore. Association for Computational
Linguistics.
Sanders, T. (2005). Coherence, causality and
cognitive complexity in discourse. In Pro-
ceedings/Actes SEM-05, First International
Symposium on the Exploration and Mod-
elling of Meaning, pages 105?114.
Segal, E., Duchan, J., and Scott, P. (1991).
The role of interclausal connectives in nar-
rative structuring: Evidence from adults? in-
terpretations of simple stories. Discourse
Processes, 14(1):27?54.
Versley, Y. (2011). Towards finer-grained
tagging of discourse connectives. In Pro-
ceedings of the Workshop Beyound Seman-
tics: Corpus-based Investigations of Prag-
matic and Discourse Phenomena.
Webber, B. (2013). What excludes an alterna-
tive in coherence relations? In Proceedings
of the IWCS.
93
Proceedings of the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 35?44,
Baltimore, Maryland, USA, June 22-27, 2014.
c?2014 Association for Computational Linguistics
Conceptual and Practical Steps in
Event Coreference Analysis of Large-scale Data
Fatemeh Torabi Asr
1
, Jonathan Sonntag
2
, Yulia Grishina
2
and Manfred Stede
2
1
MMCI Cluster of Excellence, Saarland University, Germany
fatemeh@coli.uni-saarland.de
2
Applied Computational Linguistics, University of Potsdam, Germany
sonntag|grishina|stede@uni-potsdam.de
Abstract
A simple conceptual model is employed
to investigate events, and break the task
of coreference resolution into two steps:
semantic class detection and similarity-
based matching. With this perspective an
algorithm is implemented to cluster event
mentions in a large-scale corpus. Results
on test data from AQUAINT TimeML,
which we annotated manually with coref-
erence links, reveal how semantic conven-
tions vs. information available in the con-
text of event mentions affect decisions in
coreference analysis.
1 Introduction
In a joint project with political scientists, we are
concerned with various tasks of indexing the con-
tent of a large corpus of newspaper articles. To
supplement other NLP tools and as an interest-
ing information for the political scientists by itself,
we are interested in keeping track of discussions
around headline events such as attacks and crises.
The main challenges in the project include:
1. proposing a definition of event identity, and
2. finding the actual mentions in natural text,
to construct clusters of, so-called, coreferential
events. We refer to the former task as a formal
convention, a vital step in order for useful results
to be delivered to the human text analysts. The lat-
ter is basically an information extraction task once
a clear problem specification is obtained.
The main objective of the paper is to shed
light on each of the above tasks by applying a
three-layer event ontology
1
. Terminologies from
1
The term ontology is used to refer to a conceptual model
of events and connections between them rather than a partic-
ular knowledge base implementation.
earlier theories (Davidson, 1969) up until recent
work (Hovy et al., 2013a) are combined to draw an
integrated picture of the event coreference prob-
lem. The semantic layer is established with the
help of WordNet synsets. Related entities and
timestamps are considered as fundamental event
attributes that in practice can be resolved from the
context of a mention. We implement an incremen-
tal event clustering algorithm with respect to the
adapted ontology of events and use a minimal lin-
guistic procedure to extract values from text for
every event attribute. This system is being devel-
oped to work within a pipeline annotation project
where incremental clustering performs efficiently
on large-scale data.
In order to evaluate our proposed method, we
have manually annotated a random selection of
event mentions in the AQUAINT TimeML cor-
pus (UzZaman et al., 2013). Performance of the
automatic system in pair-wise coreference reso-
lution is comparable to that of more sophisti-
cated clustering methods, which at the same time
consider a variety of linguistic features (Bejan
and Harabagiu, 2010). The differences between
the human annotator pair-wise decisions and the
output of our clustering algorithm reveal inter-
esting cases where coreference labeling is per-
formed based upon the adapted semantic conven-
tion rather than information available in the text
about time, location and participants of an event
instance. In the following, we provide an overview
of the adapted ontology, background on event
coreference, and finally our implementation and
experiments within the proposed framework on
real data as well as the annotated corpus. We point
to related work at the various appropriate places in
the paper.
2 An Object Oriented Ontology
The general impression one gets by a review of
the coreference literature, is that at the semantic
35
formalism level, events are engaged with a higher
degree of complexity and more variety than en-
tities. That is probably because of the concrete
nature of entities: intuitively, an event happens,
whereas, an entity exists. As a subject matter, the
latter is more straightforward to get decomposed
into smaller components and be identified by cer-
tain feature attributes. The ontology explained in
this chapter is general in the sense that one could
(perhaps should) start understanding it by exam-
ples about entities.
A realized entity belongs to a class of enti-
ties sharing the same set of attributes. For ex-
ample, president Obama, as long as being talked
in a political context is considered as an instance
of the class PRESIDENT, comprising attributes
such as Country, Party and Duration of
presidency. Any other president can be compared
against Obama, with respect to the attribute values
associated with them. Therefore, Bush is a differ-
ent instance of the class PRESIDENT regarding
the fact that a different political Party as well
as a different presidential Duration are assigned
to him. Detecting mentions of these PRESIDENT
instances in text corpora would be a technical task
once the semantic representation was fixed. At this
level, instead we face questions like, whether or
not a named entity somewhere in the text detected
by our text processor, e.g., ?Barack Hossein?, is
referring to the one PRESIDENT instance that we
named above as Obama.
Figure 1 illustrates similar levels of abstraction
for event classes, event instances, and event men-
tions. The distinction between the second and the
third layer are more obvious and previously con-
sidered as clearly in other frameworks. The dis-
tinction between the first and the second layer,
though, is often left implicit, even in recently pub-
lished event annotation guidelines. For example in
a Grounded Annotation for Events (GAF, Fokkens
et al. 2013), event mentions are clearly distin-
guished from instances. However, the first two
layers have been taken as one, i.e., the semantic
layer. In their work, event type which is an artifact
of the adapted semantic ontology (SEM, Klyne
and Carroll 2004), implicitly works similar to the
classes in our definition. Nevertheless, these three
layers are intuitively separable and familiar for lin-
guists working on event and entity recognition.
Bejan and Harabagiu (2010), for example, intro-
duce the event coreference resolution with an ex-
ample put into a similar three-layer hierarchy, de-
spite their purely data-driven approach leaving off
prior semantic specifications. Here, we explain
each layer of the model separately. Issues specific
to coreference detection will be presented in the
following section.
2.1 Event Classes
The first layer of the ontology determines event
type definitions. Each class can have totally dif-
ferent attributes depending on the interests of a
particular study. Some events might be identi-
fied only by their time and place, while others by
participants of prioritized importance. A very flat
semantic representation would attribute all types
of events with a fixed set of entities, e.g.: par-
ticipants, time and location. Note, however, that
structural and semantic differences exist among
events of different natures, even if these complex
phenomena are reduced into something more fa-
miliar and tangible such as verb frames (Fillmore
et al., 2003). For example, a KILLING event is es-
sentially attributed with its Agent and Patient,
while salient attributes of an EARTHQUAKE
include Location, Magnitude, Time and
Human Impacts, in a typical news context.
This becomes even more clear when event types
are taken and compared against one another from
different genres of text (Pivovarova et al., 2013;
Shaw, 2013). A scientific attitude toward the
analysis of EARTHQUAKE events might character-
ize them with Natural Impacts rather than
Human Impacts. Thus, the first layer of the
model needs to be designed with respect to the
specific information extraction goals of the partic-
ular study, be it a pure linguistic or an application-
oriented one.
Ambiguities about the granularity of attributes,
subevent-ness, scope and most importantly, iden-
tity between event instances are dealt with at the
definition layer for and between classes. For ex-
ample, if the modeler wants to allow coreference
between instances of KILLING and SHOOTING
to indicate some type of coreference between an
event and its possible subevent then this needs to
be introduced at the class level, along with a pro-
cedure to compare instances of the two classes,
which possess different sets of attribute
2
. Remarks
2
The same applies even to a more flexible case, when
the modeler wants to allow coreference between KILLING
and DYING instances (e.g., if a KILLING?s Patient is the
same as a DYING?s Theme).
36
  
Class KILLINGAgent;Patient;Time;Location;
Class SHOOTINGAgent;Patient;Time;Location;Weapon;
Class EARTQUAKEMagnitude;Human Impacts;Time;Location;
Shooting instance 1Agent: Lee Harvey OswaldPatient:  John Fitzgerald KennedyWeapon: a rifleTime: 22.11.1963Location: Dealey Plaza, Dallas
Mention 4? Shortly after noon on November 22, 1963, President John F. Kennedy was assassinated as he rode in a motorcade through Dealey Plaza. ?
Earthquake instance 1Magnitude: 6.6 to 7Human Impacts:  injury and deathTime: 20.04.2013Location: Sichuan, China
Mentions 2 and 3? Lushan, China (CNN) -- A strong earthquake that struck the southwestern Chinese province of Sichuan this weekend has killed 186 people, sent nearly 8,200 to hospitals and created a dire dearth of drinking water, Chinese state-run Xinhua reported Sunday. Earlier reports had said as many as 11,200 people were injured. ?
1 n m q
        Formalism                                  Realization                                           Text 
Killing instance 1Agent: Lee Harvey OswaldPatient:  John Fitzgerald KennedyTime: 22.11.1963Location: Dealey Plaza, Dallas
Killing instance 2Agent: an earthquakePatient: local peopleTime: 20.04.2013Location: Sichuan, China
Mention 1? President Kennedy was killed three days before he was to make these amendments public.?
Figure 1: A three-layer ontology of events: classes, instances and mentions
of Hovy et al. (2013b) on different types of iden-
tity according to lexicosyntactic similarity, syn-
onymy and paraphrasing indicate that the model-
ers have a wide choice of identity definition for
event types. In section 4.3 we explain how to adapt
an extended version of synonymy in order to de-
fine event classes prior to similarity-based cluster-
ing of the mentions.
2.2 Event Instances
Layer 2 indicates perfect instantiation, representa-
tive of the human common sense intuition of phe-
nomena in real world. Instances in this layer corre-
spond to the Davidsonian notion of events as con-
crete objects with certain locations in space-time,
something that is happening, happened, or will
happen at some point (Davidson, 1969). There-
fore, links from classes to instances represent
a one-to-many relation. Every instance of the
EARTHQUAKE is determined with a unique set
of attribute values. Two EARTHQUAKE instanti-
ations with exactly similar attribute values are just
identical. In order to keep a clear and simple rep-
resentation specific to the study of coreference,
the model does not allow any connection or rela-
tion between two event instances unless via their
classes. Note that in Figure 1, for each realized
object, only attributes included in the formalism
layer are presented with their values, while in re-
ality events occur with possibly infinite number of
attributes.
2.3 Event Mentions
Facing an event mention in the text, one should
first determine its class and then the unique event
instance, to which the mention points. Detection
of the class depends on the semantic layer defi-
nitions, while discovering the particular instance
that the mention is talking about relies on the at-
tribute values extractable from the mention con-
text.
Usually, mentions provide only partial informa-
tion about their target event instance. They can
be compared against one another and (if available)
against a fully representative mention, which most
clearly expresses the target event by providing all
necessary attribute values. Fokkens et al. (2013)
refer to such a mention as the trigger event. Some-
times it is possible that the context is even more in-
formative than necessary to resolve the unique real
world corresponding event (see details about the
impact of the earthquake in mention 3, Figure 1).
In natural text a mention can refer to more than
one event instance of the same type, for example
when a plural case is used: ? ... droughts, floods
and earthquakes cost China 421 billion yuan in
2013?. Hovy et al. (2013b) propose partial coref-
erence between singular and plural mentions. In
37
our model plural mentions are not treated seman-
tically differently, they only point to several in-
stances, thus, are coreferential with any single
mention of them as long as the attribute values al-
low
3
.
With respect to the above discussion, links from
layer 2 to 3 represent many-to-many relations: an
event instance can have several mentions in the
text, and a single mention can point to more than
one event instance at a time.
3 Towards Coreference Analysis
In terms of method, two different approaches have
been tried in the literature under the notion of
event coreference resolution (Chen and Ji, 2009;
Bejan and Harabagiu, 2010; Lee et al., 2012;
Hovy et al., 2013b). The first and most theoreti-
cally founded strategy is to decide for every pair
of event mentions, whether or not they refer to
the same event instance. Since in this approach
decisions are independently made for every pair
of event mentions, a clear formalism is needed to
determine exactly what types of coreference are
possible and how they are detected by looking
at textual mentions (Chen and Ji, 2009; Hovy
et al., 2013b). Some related work on predicate
alignment also fit into this category of research
(Roth and Frank, 2012; Wolfe et al., 2013).
Alternatively, in automatic event clustering, the
objective is basically discovering event instances:
all we know about an event in the world is the
collective information obtained from mentions
referring to that in a text corpus. Each cluster
in the end ideally represents a unique event in
reality with all its attribute values (Bejan and
Harabagiu, 2010; Lee et al., 2012). Some formal
and technical differences exist between the two
approaches.
Boolean choice: traditionally, clusters shape with
the idea that all mentions within a cluster are of
the same identity. Every randomly chosen pair
of mentions are coreferent if they are found in a
single cluster at the end, and non-coreferent oth-
erwise. Therefore, taking this approach implies a
level of formalism, which rules out partial coref-
erence. On the other hand, pair-wise classifica-
tion could consider partial coreference whenever
3
The other type of quasi-identity discussed by Hovy et al.
(2013b) engaged with sub-events is handled in the semantic
level.
two event mentions are neither identical nor totally
different (Hovy et al., 2013b). Soft-clustering can
compensate some deficiencies of traditional clus-
tering approaches
4
.
Transitivity: all mentions in a single cluster
are coreferential, whereas pair-wise labels allow
for non-transitive relations among event mentions.
Depending on the specific goal of a study, this
could be an advantage or a disadvantage. Lack
of transitivity could be considered as an error if it
is not consciously permitted in the underlying se-
mantic formalism.
Complexity and coverage: event mentions can
appear in noisy or sparse context where informa-
tion for detection of their target event instance is
not available. Dealing with such cases is usually
easier in a clustering framework where similarity
scores are calculated against the collective infor-
mation obtained from a population of mentions,
rather than an individual occurrence. Classifica-
tion approaches could comparatively handle this
only if sufficiently representative labeled data is
available for training.
Exploration: a general advantage of cluster anal-
ysis is that it provides an exploratory framework
to assess the nature of similar input records, and
at the end it results in a global distributional
representation. This is specially desired here,
since computational research on event coreference
is in its early ages. Evaluation corpora and
methodology are still not established, thus, the
problem is not yet in the phase of ?look for higher
precision?!
The method we are going to propose in the next
section combines a rule-based initial stage with a
similarity-based clustering procedure. This is par-
tially inspired by the work of Rao et al. (2010),
where entity coreference links are looked up in
high-volume streaming data. They employ a lex-
icon of named entities for cluster nomination to
reduce the search space. Once a mention is visited
only the candidates among all incrementally con-
structed clusters up to that point are examined. In-
cremental clustering strategies are in general suit-
able for a pipeline project by efficiently providing
single visits of every mention in its context. Fea-
ture values of a mention can be extracted from the
document text, used for clustering, and combined
4
For example, multi-assignment would allow plural men-
tions to take part in several different clusters, each represen-
tative of one event instance.
38
into the feature representation of the assigned clus-
ter in a compressed format.
4 Event Coreference System
The original data in our study is a text corpus au-
tomatically annotated with several layers of syn-
tactic and semantic information (Blessing et al.,
2013). The English portion includes news and
commentary articles of several British and Amer-
ican publishers from 1990 to 2012. An approx-
imate average of 100 event mentions per docu-
ment with the large number of total documents per
month (avg. 1200) requires us to think of different
ways to reduce the search space and also design a
low-complexity coreference resolution algorithm.
4.1 Partitioning
In cross-document analysis, typically, a topic-
based document partitioning is performed prior to
the coreference chain detection (Lee et al., 2012;
Cybulska and Vossen, 2013). Since we are in-
terested to track discussions about a certain event
possibly appearing in different contexts, this tech-
nique is not desired as coreference between men-
tions of a single real word event in two differ-
ent topics would remain unknown. For example,
when an articles reviews several instances of a cer-
tain event type such as different attacks that has
happened in a wide temporal range and in differ-
ent locations, such articles would not be included
in any of the individual topics each focused on
one event instance. As an alternative to the pre-
vious approach, we perform a time-window par-
titioning based on the article publication date be-
fore feeding the data into the coreference analysis
algorithm. Larger windows would capture more
coreference links: this is a parameter that can be
set with respect to the available resources in trade-
off with the desired search scope. In the future, we
would like to invent an efficient procedure to com-
bine the resulting clusters from consecutive time-
windows in order to further enhance the recall of
the system.
4.2 Event Mention and Feature Identification
In order to extract event mentions we use the
ClearTK UIMA library (Ogren et al., 2008), check
the PoS of the head word in the extracted text
span and take all verbal and nominal mentions
into account. In the current implementation all
event classes are identified by a fixed set of at-
tributes including Timestamps and Related
Entities. While being very coarse-grained,
this way of attribution is quite intuitive: events
are identified by times, places and participants
directly or vaguely attached to them. Temporal
expressions are extracted also by ClearTK and
normalized using SUTime (Chang and Manning,
2012). Named entities of all types except Date
are used which are obtained from previous work
on the same dataset (Blessing et al., 2013).
4.3 The Two-step Algorithm
Having all required annotations, we select a
time window and perform the following two
steps for event mentions of the TimeML classes
Occurrence, I-Action, Perception and
Aspectual
5
.
1) Semantic class identification: WordNet
synsets provide a rich resource in order to be
adapted as event classes (Fellbaum, 1999). They
cover a large lexicon and the variety of rela-
tional links between words enables us to specify
a clear semantic convention for the coreference
system. In addition to the mentions coming from
the same synset, we allow coreference between
events belonging to two different synsets that are
directly connected via hypernymy or morphose-
mantic links. While every WordNet synset com-
prises words only from a single part of speech,
morphosemantic relations allow the model to es-
tablish cross-PoS identity among words sharing
a stem with the same meaning which is desired
here: observe (verb) and observation (noun)
6
. A
Java library is employed to access WordNet anno-
tations (Finlayson, 2014).
2) Similarity-based clustering: A mention is
compared against previously constructed clus-
ters with respect to the attribute values that are
extractable from its context. In order to fill
the Timestamps attribute we have employed a
back-off strategy: first we look at all time expres-
sions in the same paragraph where the event men-
tion appears, if we found enough temporal infor-
mation, that would suffice. Otherwise, we look
into the content of the entire article for tempo-
ral expressions. The Related Entities at-
5
Other types, namely, Report, State and I-State
events are not interesting for us, therefore such mentions are
simply skipped.
6
When a mention is visited all compatible synsets accord-
ing to the head lemma are tried because in the current imple-
mentation we do not perform word sense disambiguation.
39
tribute is filled similarly by looking at the named
entities in the context of the event mention. The
first step is a procedure to candidate clusters con-
taining mentions of related types. If no cluster
is a candidate, a singleton cluster is created and
its class is added to the index of visited event
types (synsets). If candidate clusters already ex-
ist, we calculate the feature-based similarity score
for each. If the best score is below a threshold a
new singleton cluster is created but in this case for
the reason that, perhaps, not a new type but a new
event instance is visited.
5 Manual Annotation and Evaluation
The Event Coreference Bank, which is the largest
available corpus with cross-document corefer-
ence labels, supports only a within topic evalu-
ation (ECB, Bejan and Harabagiu 2010). In or-
der to perform a more realistic evaluation of the
method presented in this paper, we selected a sub-
set of events from the AQUAINT TimeML cor-
pus and annotated those with coreferentiality. The
AQUAINT TimeML data has recently served as
one of the benchmarks in the TempEval shared
task (UzZaman et al., 2013) and is available for
public use
7
. It contains 73 news report docu-
ments from four topics, annotated with 4431 event
mentions and 652 temporal expressions which
make it suitable for our task. Two main differ-
ences between our annotation and the ECB data
are: 1) event mentions here are selected semi-
randomly
8
and across topics rather than topic-
based, 2) they are shown pair-wise to the anno-
tator (in order to catch the transitivity patterns
after the analysis), whereas, in the ECB, event
mentions are clustered. Furthermore, the data
already comes with manually assigned mention
boundaries, event types, temporal expressions and
links between events and temporal expressions, all
according to the TimeML standards (Hobbs and
Pustejovsky, 2003). These serve exactly as fea-
tures that our algorithm uses for construction of
clusters. We only had to perform named entity
recognition automatically to have data ready for
evaluation of the model. The manual annotation
7
http://www.cs.york.ac.uk/
semeval-2013/task1
8
Since the number of coreferential mentions is much
smaller than non-coreferent ones, we adapted a heuristic mea-
sure to make sure that we will have some similar mentions
among the 100 records. Therefore, we would call it a semi-
random selection, still different from the fully selective strat-
egy employed for ECB.
of 4950 pairs resulting from 100 selected event
mentions (
100!
2!(100?2)!
) was done with the help of a
simple user interface, which showed each of the
two event mentions within its context to the an-
notator and asked for pushing yes, no or next
(undecided) button to proceed to the next pair.
After studying the annotation guideline published
by Cybulska and Vossen (2014), our expert spent
some hours during a week for the job. Decisions
made in shorter than 500 ms were revised after-
wards. There was one no answer which the an-
notator found unsure after revision, as it resulted
in a transitivity violation, but we left it unchanged
due to the nature of pair-wise decisions. In the end
we came up with a total of 36 yes, and 4914 no
pairs.
6 Experiments
This section provides an insight into how clusters
of event mentions are created for a portion of our
large news corpus. We also run the algorithm on
the manually annotated data to perform an error
analysis.
6.1 Construction of Event Clusters
News text from New York Times and Washing-
ton Post are combined to demonstrate a show-
case of clustering for a time-window of two weeks
(250 articles)
9
. Figure 2 shows the creation curve
of event classes (type index entries) and event
instances (clusters) as the number of the vis-
ited mentions increases. Comparison between the
number of mentions with that of clusters indicates
that a great deal of event instances are mentioned
only once in the text. Since, for each mention, all
compatible synsets are added to the type index (if
not there already) during the early stages of clus-
tering the number of the type index entries is times
the number of visited mentions. In the middle
to the end phases the type index contains a large
collection of event classes, also a decent number
of non-singleton clusters (repeatedly mentioned
event instances) are created. Statistics of the type
of clusters obtained after performing the algorithm
on the processed mentions are presented in Ta-
ble 1. A significant number of non-singleton clus-
ters contain mentions only from a single paragraph
or a single article, which is expected given the type
9
This collection is processed within a few minutes on a
normal PC by the proposed algorithm starting with zero clus-
ters.
40
Figure 2: Number of clusters and the type index entries as mentions are visited in 250 articles
of features; remember that Timestamps and
Named Entities are looked up in a paragraph
scope. Clusters containing mentions from several
articles, namely, the popular ones are most inter-
esting for us as they would be representative of the
systems performance on cross-document corefer-
ence analysis. By looking at those we found that
the named entities have a very important role in
finding similar subtopics within and between doc-
uments. Temporal expressions are less helpful as
they are rare, and otherwise introduce some noise
when documents are already being processed in
a specific publication time-window. For example,
the word today which appears in most articles of
the same day (and would be normalized to that
day?s date, e.g., ?1990.01.12?) would gather men-
tions of a general event type, e.g., meet, although,
they might not be pointing to the same instance.
The employed semantic convention establishes a
balance between efficiency and recall of the sys-
tem. Nevertheless, it sometimes allows clustering
of intuitively unrelated actions. In order to en-
hance the clustering performance in terms of the
precision, we have a parameter to give priority to
within synset coreference.
Cluster type Freq. Avg. content
Singleton 12895 1
Single paragraph 1360 2.36
Single article 807 3.95
Popular 182 2.99
Table 1: Different types of resulting clusters
6.2 Error Analysis
We fed all event mentions from the AQUAINT
TimeML corpus into the algorithm exactly in the
same way that we did in case of our large news
corpora. The algorithm has a few parameters
which we set by looking at samples of resulting
clusters prior to the measurement on the labeled
portion. This is a minimal NLP system given that
neither syntactic/semantic dependency of entities
to the event head word nor the type of attachment
to temporal expressions in the context are taken
into account. Nevertheless, we obtain 51.3% pre-
cision and 55.6% recall for the pair-wise corefer-
ence resolution task on the annotated data. The
resulting F-score of 53.4% is comparable with the
best F-scores reported in the work of Bejan and
Harabagiu (52.1% on ECB for the similar task)
while they use a rich linguistic feature set, as well
as a more sophisticated clustering method.
Coreference Total Related class Same doc.
True positive 20 100% 25%
True negative 4895 16% 2%
False positive 19 100% 36%
False negative 16 33% 7%
Total 4950 15% 2%
Table 2: Pair-wise decisions
Table 2 shows false positive and negative answers
separately. As reflected in the results, positive
labels are given only to mention pairs of related
classes (headwords need to share a synset, or are
related via hypernym and morphosemantic links
in WordNet). 36% of positive labels are given to
pairs within some article which is expected given
that common contextual features are easy to find
for them. In such cases, usually linguistic features
are needed to resolve participants or the relative
temporality of one mention against the other:
a. some people are born rich, some are born
poor.
b. the bullet bounced off a cabinet and rico-
cheted into the living room.
41
In some cases, on the other hand, the disagreement
depends on the semantic approach to the defini-
tion of identity, and therefore, is more controver-
sial. The human annotator has apparently been
more conservative to annotate coreference when
the head words of the mentions were a bit different
in meaning, whereas the system?s decision bene-
fited from some flexibility:
a. the immigration service decided the boy
should go home. / they made a reasonable
decision Wednesday in ruling that...
b. if he goes, he will immediately become...
It is not clear, for example, whether ruling is a sub-
event of the decision or exactly the same event. A
similar distinction needs to be made in case of the
false negative labels. The automatic clustering is
not able to detect coreference mostly in case of
sparse context, where enough information is not
available to resolve the similarity. That is why
false negative happens more frequently for men-
tions coming from different articles (specifically
paragraphs sharing few named entities) and only
7% of the time when they happen within a docu-
ment:
a. the Clinton administration has pushed for
the boy?s return. / his son said he didn?t
want to go.
Sparse context results either in the creation of a
singleton cluster for the mention or careless as-
signment to some wrong cluster, which in the fu-
ture would decrease the chance of meeting coref-
erent mentions. False negatives happening for
mentions of unrelated semantic classes are due to
the missing links between possibly synonym words
in WordNet, one of the issues that need to be in-
vestigated and cured in the future work.
7 Conclusion
This paper presented a variety of material concern-
ing event coreference resolution:
1. A general ontology is explained that can be
employed in different studies on events.
2. An algorithm is designed, regardingly, to
gather coreferential event in a large corpus.
3. A set of event mentions in AQUAINT
TimeML is annotated with pair-wise corefer-
ence tags within and between topics
10
.
4. An implementation of the method consider-
ing simple and scalable features is tested on
real data and the annotated corpus.
5. Finally, we performed an error analysis of the
automatically assigned labels to identify fu-
ture directions.
Separating the semantic layer definition of coref-
erence from textual attribution of event mentions
has two benefits in our framework. First, it pro-
vides us with an efficient partitioning procedure
to reduce the search space. Second, it makes the
model flexible to allow for different possible se-
mantic conventions which could vary from one
application to another. Our adaptation of Word-
Net synsets allows for integrative future exten-
sion of the model ? e.g., to capture metaphori-
cal and subevent relations based on Methonymy
and Entailment links. The intuition of using
named entities for identification of important real-
world events resulted in balanced precision and re-
call on the test data. In the future, we would like to
investigate the effect of linguistic features on im-
proving the performance of the algorithm. In par-
ticular, it would be interesting to see whether exact
specification of event head arguments would out-
perform the vague attribution with related entities.
The state-of-the-art result in the supervised predi-
cate alignment approach is a hint for rich linguistic
features to be helpful (Wolfe et al., 2013). On the
other hand, depending on the adapted event iden-
tity definition, coreferential events might not re-
ally share identical arguments (Hasler and Orasan,
2009). There are differences between real data
collections and the available annotated corpora,
including ours, which needs to be investigated as
well. For example, small collections do not in-
clude enough same-class event mentions pointing
to different event instances, and it brings about
unrealistic evaluations. Furthermore, annotation
guidelines are usually biased towards a specific
theory of event identity which affect the resulting
data in one way or another. Some applications de-
mand different semantic conventions perhaps with
broader/narrower definition of identity. This is a
dilemma that needs to be resolved through more
theoretical studies in touch with real world prob-
lems such as the one we introduced in this paper.
10
The annotation is available at: http://www.coli.
uni-saarland.de/
?
fatemeh/resources.htm
42
References
Bejan, C. A. and Harabagiu, S. (2010). Unsuper-
vised event coreference resolution with rich lin-
guistic features. In Proceedings of the 48th An-
nual Meeting of the Association for Computa-
tional Linguistics, pages 1412?1422. Associa-
tion for Computational Linguistics.
Blessing, A., Sonntag, J., Kliche, F., Heid, U.,
Kuhn, J., and Stede, M. (2013). Towards a
tool for interactive concept building for large
scale analysis in the humanities. In Proceed-
ings of the 7th Workshop on Language Technol-
ogy for Cultural Heritage, Social Sciences, and
Humanities, pages 55?64, Sofia, Bulgaria. As-
sociation for Computational Linguistics.
Chang, A. X. and Manning, C. (2012). Sutime:
A library for recognizing and normalizing time
expressions. In LREC, pages 3735?3740.
Chen, Z. and Ji, H. (2009). Graph-based event
coreference resolution. In Proceedings of the
2009 Workshop on Graph-based Methods for
Natural Language Processing, pages 54?57.
Association for Computational Linguistics.
Cybulska, A. and Vossen, P. (2013). Semantic re-
lations between events and their time, locations
and participants for event coreference resolu-
tion. In RANLP, volume 2013, page 8.
Cybulska, A. and Vossen, P. (2014). Guidelines for
ecb+ annotation of events and their coreference.
Technical report, Technical Report NWR-2014-
1, VU University Amsterdam.
Davidson, D. (1969). The individuation of events.
In Essays in honor of Carl G. Hempel, pages
216?234. Springer.
Fellbaum, C. (1999). WordNet. Wiley Online Li-
brary.
Fillmore, C. J., Johnson, C. R., and Petruck, M. R.
(2003). Background to framenet. International
journal of lexicography, 16(3):235?250.
Finlayson, M. A. (2014). Java libraries for ac-
cessing the princeton wordnet: Comparison and
evaluation. In Proceedings of the 7th Global
Wordnet Conference, pages 78?85.
Fokkens, A., van Erp, M., Vossen, P., Tonelli, S.,
van Hage, W. R., SynerScope, B., Serafini, L.,
Sprugnoli, R., and Hoeksema, J. (2013). Gaf: A
grounded annotation framework for events. In
NAACL HLT, volume 2013, page 11.
Hasler, L. and Orasan, C. (2009). Do corefer-
ential arguments make event mentions corefer-
ential. In Proc. the 7th Discourse Anaphora
and Anaphor Resolution Colloquium (DAARC
2009).
Hobbs, J. and Pustejovsky, J. (2003). Annotating
and reasoning about time and events. In Pro-
ceedings of AAAI Spring Symposium on Logical
Formalizations of Commonsense Reasoning.
Hovy, E., Mitamura, T., and Palmer, M. (2013a).
The 1st workshop on events: Definition, detec-
tion, coreference, and representation.
Hovy, E., Mitamura, T., Verdejo, F., Araki, J.,
and Philpot, A. (2013b). Events are not sim-
ple: Identity, non-identity, and quasi-identity.
NAACL HLT 2013, page 21.
Klyne, G. and Carroll, J. J. (2004). Resource
description framework (rdf): Concepts and ab-
stract syntax. w3c recommendation, 10 feb.
2004.
Lee, H., Recasens, M., Chang, A., Surdeanu,
M., and Jurafsky, D. (2012). Joint entity and
event coreference resolution across documents.
In Proceedings of the 2012 Joint Conference
on Empirical Methods in Natural Language
Processing and Computational Natural Lan-
guage Learning, pages 489?500. Association
for Computational Linguistics.
Ogren, P. V., Wetzler, P. G., and Bethard, S. J.
(2008). Cleartk: A uima toolkit for statisti-
cal natural language processing. Towards En-
hanced Interoperability for Large HLT Systems:
UIMA for NLP, 32.
Pivovarova, L., Huttunen, S., and Yangarber, R.
(2013). Event representation across genre.
NAACL HLT 2013, page 29.
Rao, D., McNamee, P., and Dredze, M. (2010).
Streaming cross document entity coreference
resolution. In Proceedings of the 23rd Inter-
national Conference on Computational Linguis-
tics: Posters, pages 1050?1058. Association for
Computational Linguistics.
Roth, M. and Frank, A. (2012). Aligning predicate
argument structures in monolingual comparable
texts: A new corpus for a new task. In Proceed-
ings of the First Joint Conference on Lexical
and Computational Semantics-Volume 1: Pro-
ceedings of the main conference and the shared
43
task, and Volume 2: Proceedings of the Sixth In-
ternational Workshop on Semantic Evaluation,
pages 218?227. Association for Computational
Linguistics.
Shaw, R. (2013). A semantic tool for historical
events. NAACL HLT 2013, page 38.
UzZaman, N., Llorens, H., Derczynski, L., Verha-
gen, M., Allen, J., and Pustejovsky, J. (2013).
Semeval-2013 task 1: Tempeval-3: Evaluat-
ing time expressions, events, and temporal rela-
tions. In Second joint conference on lexical and
computational semantics (* SEM), volume 2,
pages 1?9.
Wolfe, T., Van Durme, B., Dredze, M., Andrews,
N., Beller, C., Callison-Burch, C., DeYoung,
J., Snyder, J., Weese, J., Xu, T., et al. (2013).
Parma: A predicate argument aligner.
44
