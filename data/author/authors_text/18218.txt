Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1139?1145,
October 25-29, 2014, Doha, Qatar. c?2014 Association for Computational Linguistics
Exploiting Social Relations and Sentiment for Stock Prediction 
 
Jianfeng Si* Arjun Mukherjee? Bing Liu? Sinno Jialin Pan* Qing Li? Huayi Li? 
* Institute for Infocomm Research, Singapore 
{ thankjeff@gmail.com, jspan@i2r.a-star.edu.sg} 
?Department of Computer Science, University of Illinois at Chicago, Chicago, IL 60607, USA 
{ arjun4787@gmail.com, liub@cs.uic.edu, lhymvp@gmail.com} 
? Department of Computer Science, City University of Hong Kong, Hong Kong, China 
qing.li@cityu.edu.hk 
 
 
Abstract 
In this paper we first exploit cash-tags (?$? fol-
lowed by stocks? ticker symbols) in Twitter to 
build a stock network, where nodes are stocks 
connected by edges when two stocks co-occur 
frequently in tweets. We then employ a labeled 
topic model to jointly model both the tweets and 
the network structure to assign each node and 
each edge a topic respectively. This Semantic 
Stock Network (SSN) summarizes discussion 
topics about stocks and stock relations. We fur-
ther show that social sentiment about stock 
(node) topics and stock relationship (edge) topics 
are predictive of each stock?s market. For predic-
tion, we propose to regress the topic-sentiment 
time-series and the stock?s price time series. Ex-
perimental results demonstrate that topic senti-
ments from close neighbors are able to help im-
prove the prediction of a stock markedly. 
1 Introduction 
Existing research has shown the usefulness of 
public sentiment in social media across a wide 
range of applications. Several works showed so-
cial media as a promising tool for stock market 
prediction (Bollen et al., 2011; Ruiz et al., 2012; 
Si et al., 2013). However, the semantic relation-
ships between stocks have not yet been explored. 
In this paper, we show that the latent semantic 
relations among stocks and the associated social 
sentiment can yield a better prediction model.  
On Twitter, cash-tags (e.g., $aapl for Apple 
Inc.) are used in a tweet to indicate that the tweet 
talks about the stocks or some other related in-
formation about the companies. For example, 
one tweet containing cash-tags: $aapl and $goog 
(Google Inc.), is ?$AAPL is loosing customers. 
everybody is buying android phones! $GOOG?. 
Such joint mentions directly reflect some kind of 
latent relationship between the involved stocks, 
which motivates us to exploit such information 
for the stock prediction.  
We propose a notion of Semantic Stock Net-
work (SSN) and use it to summarize the latent 
semantics of stocks from social discussions. To 
our knowledge, this is the first work that uses 
cash-tags in Twitter for mining stock semantic 
relations. Our stock network is constructed based 
on the co-occurrences of cash-tags in tweets. 
With the SSN, we employ a labeled topic model 
to jointly model both the tweets and the network 
structure to assign each node and each edge a 
topic respectively. Then, a lexicon-based senti-
ment analysis method is used to compute a sen-
timent score for each node and each edge topic. 
To predict each stock?s performance (i.e., the 
up/down movement of the stock?s closing price), 
we use the sentiment time-series over the SSN 
and the price time series in a vector autoregres-
sion (VAR) framework.  
We will show that the neighbor relationships in 
SSN give very useful insights into the dynamics 
of the stock market. Our experimental results 
demonstrate that topic sentiments from close 
neighbors of a stock can help improve the predic-
tion of the stock market markedly. 
2 Related work 
2.1 Social Media & Economic Indices 
Many algorithms have been proposed to produce 
meaningful insights from massive social media 
data. Related works include detecting and sum-
marizing events (Weng and Lee, 2011; Weng et 
al., 2011; Baldwin et al., 2012; Gao et al., 2012) 
and analyzing sentiments about them (Pang and 
Lee, 2008; Liu, 2012), etc. Some recent literature 
also used Twitter as a sentiment source for stock 
market prediction (Bollen et al., 2011; Si et al., 
2013). This paper extends beyond the correlation 
between social media and stock market, but fur-
1139
ther exploits the social relations between stocks 
from the social media context. 
  Topic modeling has been widely used in social 
media. Various extensions of the traditional LDA 
model (Blei et al., 2003) has been proposed for 
modeling social media data (Wang et al., 2011, 
Jo and Oh, 2011; Liu et al., 2007; Mei et al., 
2007; Diao et al., 2012). Ramage et al. (2009; 
2011) presented a partially supervised learning 
model called Labeled LDA to utilize supervision 
signal in topic modeling. Ma et al. (2013) pre-
dicted the topic popularity based on hash-tags on 
Twitter in a classification framework. 
2.2 Financial Networks for Stock 
Financial network models study the correlations 
of stocks in a graph-based view (Tse et al., 2010; 
Mantegna, 1999; Vandewalle et al., 2001; On-
nela et al., 2003; Bonanno et al., 2001). The usu-
al approach is to measure the pairwise correla-
tion of stocks? historical price series and then 
connect the stocks based on correlation strengths 
to build a correlation stock network (CSN). 
However, our approach leverages social media 
posts on stock tickers. The rationale behind is 
that micro-blogging activities have been shown 
to be highly correlated with the stock market 
(Ruiz et al., 2012; Mao et al., 2012). It is more 
informative, granular to incorporate latest devel-
opments of the market as reflected in social me-
dia instead of relying on stocks? historical price.  
3 Semantic Stock Network (SSN) 
3.1 Construction of SSN 
We collected five months (Nov. 2 2012 - Apr. 3 
2013) of English tweets for a set of stocks in the 
Standard & Poor's 100 list via Twitter?s REST 
API, using cash-tags as query keywords. For 
preprocessing, we removed tweets mentioning 
more than five continuous stock tickers as such 
tweets usually do not convey much meaning for 
our task. Finally, we obtained 629,977 tweets in 
total. Table 1 shows the top five most frequent 
stocks jointly mentioned with Apple Inc. in our 
dataset. Formally, we define the stock network as 
an undirected graph ? = {? , ?}. The node set 
? comprises of stocks, ??,? ? ?  stands for the 
edge between stock nodes ? and ? and the edge 
weight is the number of co-occurrences. On ex-
ploring the co-occurrence statistics in pilot stud-
ies, we set a minimum weight threshold of 400 to 
filter most non-informative edges. Figure 1 
demonstrates a segment of the stock network 
constructed from our dataset. 
3.2 Semantic Topics over the Network 
Figure 2 illustrates our annotation for each tweet. 
For a tweet, ? with three cash-tags: {?1, ?2, ?3}, we annotate ?  with the label set, ?? =
 {?1, ?2, ?3, ?1,2, ?1,3, ?2,3}. (?1,2 is ?aapl_goog? 
if ?1is ?aapl? and ?2 is ?goog?). Then, the topic assignments of words in ? are constrained to top-
ics indexed by its label set, ??. Given the annota-tions as labels, we use the Labeled LDA model 
(Ramage et al., 2009) to jointly learn the topics 
over nodes and edges. Labeled-LDA assumes 
that the set of topics are the distinct labels in a 
labeled set of documents, and each label corre-
sponds to a unique topic. Similar to LDA (Blei et 
al., 2003), Labeled-LDA models each document 
as an admixture of latent topics and generates 
each word from a chosen topic. Moreover, La-
beled-LDA incorporates supervision by simply 
constraining the model to use only those topics 
that correspond to a document?s observed label 
set (Ramage et al., 2009). For model inference, 
we use collapsed Gibbs sampling (Bishop, 2006) 
and the symmetric Dirichlet Priors are set to: 
? = 0.01, ? = 0.01 as suggested in (Ramage et 
al., 2010). The Gibbs Sampler is given as: 
?(?? = ?|???)~
 ?(??,?)?1+ ?
?(??,?)?1+ |???|??
? ?(?,??)?1+??(?,?)?1+ |? |?? (1) 
where ?(??, ?) is the number of words in ?? as-signed to topic ?, while ?(??,?) is the marginal-ized sum. |??? | is the size of label subset of ??. 
 Figure 2. Tweet label design. 
$goog $amzn $ebay $msft $intc
43263 23266 14437 11891 2486
Table 1. co-occurrence statistics with $aapl. 
 
Figure 1. An example stock network. 
1140
?(?, ?) is the term frequency of word ? in topic 
?. |? | is the vocabulary size. The subscript -1 is 
used to exclude the count assignment of the cur-
rent word ?? . The posterior on the document?s topic distribution {??,?} and topic?s word distri-
bution {??,?} can be estimated as follows: 
??,? =  
?(??,?)+ ?
?(??,?)+ |???|??
                (2) 
??,? =  
?(?,??)+?
?(?,?)+ |? |??                   (3) 
Later, parameters {??,?} will be used to compute 
the sentiment score for topics. 
3.3 Leveraging Sentiment over SSN for 
Stock Prediction 
We define a lexicon based sentiment score in the 
form of opinion polarity for each node-indexed 
and edge-indexed topic as follows: 
?(?) = ? ??,?
|? |
?=1
?(?), ?(?) ? [?1,1]  (4) 
where ?(?) denotes the opinion polarity of word 
?. ??,?  is the word probability of ? in topic ? 
(Eq.3). Based on an opinion lexicon ?, ?(?) = 
+1 if ? ? ????, ?(?) = -1 if ? ? ???? and ?(?) 
= 0 otherwise. We use the opinion English lexi-
con contributed by Hu and Liu (2004).  
Considering the inherent dynamics of both the 
stock markets and social sentiment, we organize 
the tweets into daily based sub-sets according to 
their timestamps to construct one ????  ( ? ?
[1, ? ]) for each day. Then, we apply a Labeled 
LDA for each ???? and compute the sentiment scores for each ???? ?s nodes and edges. This yields a sentiment time series for the node, ? , 
{?(?)1, ?(?)2, ? , ?(?)? } and for the edge, ??,?, 
{?(??,?)1, ?(??,?)2, ? , ?(??,?)? } . We intro-
duce a vector autoregression model (VAR) 
(Shumway and Stoffer, 2011) by regressing sen-
timent time series together with the stock price 
time series to predict the up/down movement of 
the stock?s daily closing price. 
As usual in time series analysis, the regression 
parameters are learned during a training phase 
and then are used for forecasting under sliding 
windows, i.e., to train in period [?, ? + ?] and to 
predict on time ? + ? + 1. Here the window size 
? refers to the number of days in series used in 
model training. A VAR model for two variables 
{??} and {??} can be written as: 
?? =  ? (??????? + ???????)????=1 + ??  (5) where {?} are white noises, {?} are model pa-
rameters, and ??? notes the time steps of histori-
cal information to use. In our experiment, {??} is the target stock?s price time series, {??} is the covariate sentiment/price time series, and we will 
try ??? ? ?2,3?. We use the ?dse? library in R 
language to fit our VAR model based on least 
square regression. 
4 Experiments 
4.1 Tweets in Relation to the Stock Market 
Micro-blogging activities are well correlated 
with the stock market. Figure 3 shows us how the 
Twitter activities response to a report announce-
ment of $aapl (Jan. 23 2013). The report was 
made public soon after the market closed at 
4:00pm, while the tweets volume rose about two 
hours earlier and reached the peak at the time of 
announcement, then it arrived the second peak at 
the time near the market?s next opening (9:30am). 
By further accumulating all days? tweet volume 
in our dataset as hourly based statistics, we plot 
the volume distribution in Figure 4. Again, we 
note that trading activities are well reflected by 
tweet activities. The volume starts to rise drasti-
cally two or three hours before the market opens, 
and then reaches a peak at 9:00pm. It drops dur-
ing the lunch time and reaches the second peak 
around 2:00pm (after lunch). Above observations 
clearly show that market dynamics are discussed 
in tweets and the content in tweets? discussion 
very well reflects the fine-grained aspects of 
stock market trading, opening and closing. 
 
Figure 3. Tweet activity around $aapl?s earnings 
report date on Jan. 23 2013. 
 
Figure 4. Tweet volume distribution in our data 
over hours averaged across each day. 
0
500
1000
1500
2000
2500
Time (date-hour)
0
0.02
0.04
0.06
0.08
0.1
0 2 4 6 8 10 12 14 16 18 20 22
Time (hourly)
1141
4.2 Stock Prediction 
This section demonstrates the effectiveness of 
our SSN based approach for stock prediction. 
We leverage the sentiment time-series on two 
kinds of topics from SSN: 1). Node topic from 
the target stock itself, 2). Neighbor node/edge 
topics. We note that the price correlation stock 
network (CSN) (e.g., Bonanno et al., 2001; Man-
tegna, 1999) also defines neighbor relationships 
based on the Pearson's correlation coefficient 
(Tse et al., 2010) between pair of past price se-
ries (We get the stock dataset from Yahoo! Fi-
nance, between Nov. 2 2012 and Apr. 3 2013).  
 We build a two variables VAR model to pre-
dict the movement of a stock?s daily closing 
price. One variable is the price time series of the 
target stock ({??} in Eq.5); another is the covari-ate sentiment/price time series ({??}  in Eq.5). We setup two baselines according to the sources 
of the covariate time series as follows: 
1. Covariate price time series from CSN, we try 
the price time series from the target stock?s 
closest neighbor which takes the maximum 
historical price correlation in CSN. 
2. With no covariate time series, we try the tar-
get stock?s price only based on the univariate 
autoregression (AR) model. 
 To summarize, we try different covariate sen-
timent (?(. )) or price (?(. )) time series from 
SSN or CSN together with the target stock?s 
price time series (? ?) to predict the movement of 
one day ahead price (???). The accuracy is com-
puted based on the correctness of the predicted 
directions as follows, i.e., if the prediction ??? 
takes the same direction as the actual price value, 
we increment #(???????) by 1, #(?????????) is 
the total number of test.  
???????? = #(???????)#(?????????)       (6) 
 Figure 5 details the prediction of $aapl on dif-
ferent training window sizes of [15, 60] and lags. 
{?(????), ?(????), ?(????), ?(????_????)} are 
from SSN, ?(????)  is from CSN ($dell (Dell 
Inc.) takes the maximum price correlation score 
of 0.92 with $aapl), and ? ? =  ?(????)  is the 
univariate AR model, using the target stock?s 
price time series only. Table 2 further summariz-
es the performance comparison of different ap-
proaches reporting the average (and best) predic-
tion accuracies over all time windows and dif-
ferent lag settings. Comparing to the univariate 
AR model (?? only), we see that the sentiment 
based time-series improve performances signifi-
cantly. Among SSN sentiment based approach-
es, the ?(????) helps improve the performance 
mostly and gets the best accuracy of 0.78 on ??? 
2 and training window size of 53. On average, 
?(????) achieves a net gain over ?(????) in the 
range of 29% with lag 2 (0.62 = 1.29 x 0.48) and 
14% with lag 3 (0.57 = 1.14 x 0.50). Also, 
?(????_????)  performs better than ?(????) . 
The result indicates that $aapl?s stock perfor-
mance is highly influenced by its competitor. 
?(????) also performs well, but we will see rela-
tionships from CSN may not be so reliable. 
We further summarize some other prediction 
cases in Table 3 to show how different covariate 
sentiment sources ( ?(. ) ) and price sources 
(?(. )) from their closest neighbor nodes help 
predict their stocks, which gives consistent con-
clusions. We compute the ?-test for SSN based 
prediction accuracies against that of CSN or 
price only based approaches among all testing 
 Source Lag = 2 Lag = 3 
?? only self 0.49(0.57)	 0.47(0.52)
CSN: 
P(.)+??	 dell	 0.55(0.64)	 0.57(0.67)	
 
SSN: 
S(.)+?? 
aapl 0.48(0.56)	 0.50(0.61)
goog 0.62(0.78) 0.57(0.69) 
aapl_goog 0.55(0.65) 0.52(0.56) 
msft 0.52(0.65) 0.54(0.61) 
Table 2. Performance comparison of the average and 
best (in parentheses) prediction accuracies over all 
training window sizes for prediction on $aapl. 
 
 
Figure 5. Prediction on $aapl. (x-axis is the training 
window size, y-axis is the prediction accuracy) 
with different covariate sources. 
0.2
0.3
0.4
0.5
0.6
0.7
0.8
15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60
(a) Prediction of $aapl on lag 2
P* P(dell)+P*
S(aapl)+P* S(goog)+P*
S(aapl_goog)+P* S(msft)+P*
0.2
0.3
0.4
0.5
0.6
0.7
15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60
(b) Prediction of $aapl on lag 3
P* P(dell)+P*
S(aapl)+P* S(goog)+P*
S(aapl_goog)+P* S(msft)+P*
1142
window sizes ([15, 60]), and find that SSN based 
approaches are significantly (? -value < 0.001) 
better than others.  
We note that tweet volumes of most S&P100 
stocks are too small for effective model building, 
as tweets discuss only popular stocks, other 
stocks are not included due to their deficient 
tweet volume.  
We make the following observations: 
  1. CSN may find some correlated stock pairs 
like $ebay and $amzn, $wmt and $tgt, but some-
times, it also produces pairs without real-world 
relationships like $tgt and $vz, $qcom and $pfe, 
etc. In contrast, SSN is built on large statistics of 
human recognition in social media, which is like-
ly to be more reliable as shown. 
  2. Sentiment based approaches {?(?)} consist-
ently perform better than all price based ones 
{??, ? (?)}. For ?(?)  based predictions, senti-
ment discovered from the target stock?s closest 
neighbors in SSN performs best in general. This 
empirical finding dovetails with qualitative re-
sults in the financial analysis community (Mizik 
& Jacobson, 2003; Porter, 2008), where compa-
nies? market performances are more likely to be 
influenced by their competitors. But for Google, 
its stock market is not so much influenced by 
other companies (it gets the best prediction accu-
racy on ?(????), i.e., the internal factor). It can 
be explained by Google Inc.?s relatively stable 
revenue structure, which is well supported by its 
leading position in the search engine market. 
  3. The business of offline companies like Target 
Corp. ($tgt) and Wal-Mart Stores Inc. ($wmt) are 
highly affected by online companies like $amzn. 
Although competition exists between $tag and 
$wmt, their performances seem to be affected 
more by a third-party like $amzn (In Table 3, 
??????? predicts the best for both). Not surpris-
ingly, these offline companies have already been 
trying to establish their own online stores and 
markets. 
5 Conclusion 
This paper proposed to build a stock network 
from co-occurrences of ticker symbols in tweets. 
The properties of SSN reveal some close rela-
tionships between involved stocks, which pro-
vide good information for predicting stocks 
based on social sentiment. Our experiments show 
that SSN is more robust than CSN in capturing 
the neighbor relationships, and topic sentiments 
from close neighbors of a stock significantly im-
prove the prediction of the stock market.   
Acknowledgments 
This work was supported in part by a grant from 
the National Science Foundation (NSF) under 
grant no. IIS-1111092). 
Target ? ???? only CSN:  P(.)+?? SSN:  S(.)+?? 
 
goog 
  dis(0.96) goog aapl amzn 
2 0.48(0.59) 0.53(0.60) 0.59(0.65) 0.44(0.53) 0.42(0.49) 
3 0.46(0.54) 0.53(0.62) 0.56(0.67) 0.50(0.59) 0.43(0.49) 
 
amzn 
  csco(0.90) amzn goog msft 
2 0.48(0.54) 0.48(0.55) 0.47(0.54) 0.57(0.66) 0.60(0.68) 
3 0.46(0.53) 0.49(0.53) 0.43(0.50) 0.55(0.63) 0.57(0.66) 
 
ebay 
  amzn(0.81) ebay amzn goog 
2 0.49(0.55) 0.51(0.57) 0.44(0.53) 0.57(0.64) 0.56(0.62) 
3 0.48(0.58) 0.49(0.54) 0.45(0.58) 0.54(0.64) 0.54(0.61) 
 
tgt 
  vz(0.88) tgt wmt amzn 
2 0.43(0.53) 0.43(0.54) 0.46(0.55) 0.49(0.56) 0.49(0.59) 
3 0.44(0.50) 0.40(0.53) 0.44(0.48) 0.41(0.48) 0.48(0.54) 
 
wmt 
  tgt(0.86) wmt tgt amzn 
2 0.53(0.59) 0.53(0.63) 0.52(0.61) 0.52(0.60) 0.60(0.65) 
3 0.53(0.64) 0.48(0.57) 0.55(0.66) 0.48(0.58) 0.58(0.66) 
 
qcom 
  pfe(0.88) qcom aapl intc 
2 0.53(0.6) 0.55(0.63) 0.57(0.61) 0.46(0.54) 0.63(0.70) 
3 0.54(0.61) 0.48(0.55) 0.56(0.65) 0.51(0.61) 0.61(0.67) 
Table 3. Average and best (in parentheses) prediction accuracies (over window sizes of [15, 
60]) of some other cases with different covariates, cell of dis(0.96) means ?$dis? takes the 
maximum price correlation strength of 0.96 with ?$goog? (similar for others in column 
CSN). The best performances are highlighted in bold.  
1143
References 
Baldwin T., Cook P., Han B., Harwood A., Karuna-
sekera S., and Moshtaghi M. 2012. A support plat-
form for event detection using social intelligence. 
In Proceedings of the Demonstrations at the 13th 
Conference of the European Chapter of the Associ-
ation for Computational Linguistics (EACL '12). 
Association for Computational Linguistics, 
Stroudsburg, PA, USA, 69-72. 
Bishop C.M. 2006. Pattern Recognition and Machine 
Learning. Springer. 
Blei D., NG A., and Jordan M. 2003. Latent Dirichlet 
allocation. Journal of Machine Learning Research 
3:993-1022. 
Bollen J., Mao H., and Zeng X.J. 2011. Twitter mood 
predicts the stock market. Journal of Computer 
Science 2(1):1-8.  
Bonanno G., Lillo F., and Mantegna R.N. 2001. High- 
frequency cross-correlation in a set of stocks, 
Quantitative Finance, Taylor and Francis Journals, 
vol. 1(1), 96-104. 
Cohen J., Cohen P., West S.G., and Aiken L.S. 2003. 
Applied Multiple Regression/Correlation Analysis 
for the Behavioral Sciences, (3rd ed.) Hillsdale, NJ: 
Lawrence Erlbaum Associates. 
Diao Q., Jiang J., Zhu F., and Lim E.P. 2012. Finding 
bursty topics from microblogs. In Proceedings of 
the 50th Annual Meeting of the Association for 
Computational Linguistics: Long Papers - Volume 
1 (ACL '12), Vol. 1. Association for Computational 
Linguistics, Stroudsburg, PA, USA, 536-544. 
Gao W., Li P., and Darwish K. 2012. Joint topic mod-
eling for event summarization across news and so-
cial media streams. CIKM 2012: 1173-1182 
Hu M. and Liu B. 2004. Mining and summarizing 
customer reviews.  In Proceedings of the ACM 
SIGKDD International Conference on Knowledge 
Discovery & Data Mining, 22-25. Seattle, Wash-
ington (KDD-2004). 
Jo Y. and Oh A. 2011. Aspect and sentiment unifica-
tion model for online review analysis. In ACM 
Conference in Web Search and Data Mining 
(WSDM-2011). 
Liu B. 2012. Sentiment analysis and opinion mining. 
Morgan & Claypool Publishers. 
Liu Y., Huang X., An A., and Yu X. 2007. ARSA: a 
sentiment-aware model for predicting sales per-
formance using blogs. In Proceedings of the 30th 
Annual International ACM SIGIR Conference on 
Research and Development in Information Retriev-
al, 607-614. ACM, New York, NY. 
Ma Z., Sun A., and Cong G. 2013. On predicting the 
popularity of newly emerging hashtags in Twitter. 
In Journal of the American Society for Information 
Science and Technology, 64(7): 1399-1410 (2013) 
Mantegna R. 1999. Hierarchical structure in financial 
markets, The European Physical Journal B - Con-
densed Matter and Complex Systems, Springer, vol. 
11(1), pages 193-197, September. 
Mao Y., Wei W., Wang B., and Liu B. 2012. Corre-
lating S&P 500 stocks with Twitter data. In Pro-
ceedings of the First ACM International Workshop 
on Hot Topics on Interdisciplinary Social Net-
works Research (HotSocial '12). ACM, New York, 
NY, USA, 69-72 
Mei Q., Ling X., Wondra M., Su H., and Zhai C. 2007. 
Topic sentiment mixture: modeling facets and 
opinions in weblogs. In Proceedings of Interna-
tional Conference on World Wide Web (WWW-
2007). 
Mizik N. and Jacobson R. 2003. Trading off between 
value creation and value appropriation: The finan-
cial implications of shifts in strategic emphasis. 
Journal of Marketing, 63-76. 
Onnela J.P., Chakraborti A., and Kaski K. 2003. Dy-
namics of market correlations: taxonomy and port-
folio analysis, Phys. Rev. E 68, 056110. 
Pang B. and Lee L. 2008. Opinion Mining and Senti-
ment Analysis. Now Publishers Inc. 
Porter M.E. 2008. The Five Competitive Forces That 
Shape Strategy.HBR, Harvard Business Review. 
Ramage D., Dumais S.T., and Liebling D. 2010. 
Characterizing microblogging using latent topic 
models. In Proceedings of ICWSM 2010. 
Ramage D., Hall D., Nallapati R., and Manning C.D. 
2009. Labeled LDA: A supervised topic model for 
credit attribution in multi-labeled corpora. In Pro-
ceedings of the 2009 Conference on Empirical 
Methods in Natural Language Processing (EMNLP 
2009). 
Ramage D., Manning C.D., and Dumais S.T. 2011. 
Partially labeled topic models for interpretable text 
mining. In Proceedings of KDD 2011 
Ruiz E.J., Hristidis V., Castillo C., Gionis A., and 
Jaimes A. 2012. Correlating financial time series 
with micro-blogging activity. In Proceedings of the 
fifth ACM international conference on Web search 
and data mining, pp. 513-522. ACM Press, NY 
(WSDM-2012). 
Shumway R.H. and Stoffer D.S. 2011. Time Series 
Analysis and Its Applications: With R Examples, 
3rd ed. 
Si J., Mukherjee A., Liu B., Li Q., Li H., and Deng X. 
2013. Exploiting Topic based Twitter Sentiment 
for Stock Prediction. In Proceedings of the 51st 
1144
Annual Meeting of the Association for Computa-
tional Linguistics. ACL?13, Sofia, Bulgaria, 24-29.   
Tse C.K., Liu J., and Lau F.C.M. 2010. A network 
perspective of the stock market, Journal of Empiri-
cal Finance. 17(4): 659-667. 
Vandewalle N., Brisbois F., and Tordoir X. 2001. 
Self-organized critical topology of stock markets, 
Quantit. Finan., 1, 372?375. 
Wang X., Wei F., Liu X., Zhou M., and Zhang M. 
2011. Topic sentiment analysis in twitter: a graph-
based hashtag sentiment classification approach. 
CIKM 2011: 1031-1040 
Weng J. and Lee B.S. 2011. Event Detection in Twit-
ter. In Proceedings of the International AAAI Con-
ference on Weblogs and Social Media 2011. 
Weng J.Y., Yang C.L., Chen B.N., Wang Y.K., and 
Lin S.D. 2011. IMASS: An Intelligent Microblog 
Analysis and Summarization System. ACL (Sys-
tem Demonstrations) 2011: 133-138. 
 
1145
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 24?29,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Exploiting Topic based Twitter Sentiment for Stock Prediction 
Jianfeng Si* Arjun Mukherjee? Bing Liu? Qing Li* Huayi Li? Xiaotie Deng? 
*Department of Computer Science, City University of Hong Kong, Hong Kong, China 
*{ thankjeff@gmail.com, qing.li@cityu.edu.hk} 
?Department of Computer Science, University of Illinois at Chicago, Chicago, IL 60607, USA 
?{ arjun4787@gmail.com, liub@cs.uic.edu, lhymvp@gmail.com} 
?AIMS Lab, Department of Computer Science, Shanghai Jiaotong University, Shanghai, China 
?deng-xt@cs.sjtu.edu.cn  
 
Abstract 
This paper proposes a technique to leverage 
topic based sentiments from Twitter to help 
predict the stock market. We first utilize a con-
tinuous Dirichlet Process Mixture model to 
learn the daily topic set. Then, for each topic 
we derive its sentiment according to its opin-
ion words distribution to build a sentiment 
time series. We then regress the stock index 
and the Twitter sentiment time series to predict 
the market. Experiments on real-life S&P100 
Index show that our approach is effective and 
performs better than existing state-of-the-art 
non-topic based methods. 
1 Introduction 
Social media websites such as Twitter, Facebook, 
etc., have become ubiquitous platforms for social 
networking and content sharing. Every day, they 
generate a huge number of messages, which give 
researchers an unprecedented opportunity to uti-
lize the messages and the public opinions con-
tained in them for a wide range of applications 
(Liu, 2012). In this paper, we use them for the 
application of stock index time series analysis. 
Here are some example tweets upon querying 
the keyword ?$aapl? (which is the stock symbol 
for Apple Inc.) in Twitter: 
1. ?Shanghai Oriental Morning Post confirm-
ing w Sources that $AAPL TV will debut 
in May, Prices range from $1600-$3200, 
but $32,000 for a 50"wow.? 
2. ?$AAPL permanently lost its bid for a ban 
on U.S. sales of the Samsung Galaxy Nex-
us http://dthin.gs/XqcY74.? 
3. ?$AAPL is loosing customers. everybody is 
buying android phones! $GOOG.? 
As shown, the retrieved tweets may talk about 
Apple?s products, Apple?s competition relation-
ship with other companies, etc. These messages 
are often related to people?s sentiments about 
Apple Inc., which can affect or reflect its stock 
trading since positive sentiments can impact 
sales and financial gains. Naturally, this hints 
that topic based sentiment is a useful factor to 
consider for stock prediction as they reflect peo-
ple?s sentiment on different topics in a certain 
time frame. 
This paper focuses on daily one-day-ahead 
prediction of stock index based on the temporal 
characteristics of topics in Twitter in the recent 
past. Specifically, we propose a non-parametric 
topic-based sentiment time series approach to 
analyzing the streaming Twitter data. The key 
motivation here is that Twitter?s streaming mes-
sages reflect fresh sentiments of people which 
are likely to be correlated with stocks in a short 
time frame. We also analyze the effect of training 
window size which best fits the temporal dynam-
ics of stocks. Here window size refers to the 
number of days of tweets used in model building. 
Our final prediction model is built using vec-
tor autoregression (VAR). To our knowledge, 
this is the first attempt to use non-parametric 
continuous topic based Twitter sentiments for 
stock prediction in an autoregressive framework. 
2 Related Work 
2.1 Market Prediction and Social Media 
Stock market prediction has attracted a great deal 
of attention in the past. Some recent researches 
suggest that news and social media such as blogs, 
micro-blogs, etc., can be analyzed to extract pub-
lic sentiments to help predict the market (La-
vrenko et al, 2000; Schumaker and Chen, 2009). 
Bollen et al (2011) used tweet based public 
mood to predict the movement of Dow Jones 
*   The work was done when the first author was visiting 
University of Illinois at Chicago. 
 
 
 
 
 
 
24
Industrial Average index. Ruiz et al (2012) stud-
ied the relationship between Twitter activities 
and stock market under a graph based view. 
Feldman et al (2011) introduced a hybrid ap-
proach for stock sentiment analysis based on 
companies? news articles.  
2.2 Aspect and Sentiment Models 
Topic modeling as a task of corpus exploration 
has attracted significant attention in recent years. 
One of the basic and most widely used models is 
Latent Dirichlet Allocation (LDA) (Blei et al, 
2003). LDA can learn a predefined number of 
topics and has been widely applied in its extend-
ed forms in sentiment analysis and many other 
tasks (Mei et al, 2007; Branavan et al, 2008; Lin 
and He, 2009; Zhao et al, 2010; Wang et al, 
2010; Brody and Elhadad, 2010; Jo and Oh, 2011; 
Moghaddam and Ester, 2011; Sauper et al, 2011; 
Mukherjee and Liu, 2012; He et al, 2012).  
The Dirichlet Processes Mixture (DPM) model 
is a non-parametric extension of LDA (Teh et al, 
2006), which can estimate the number of topics 
inherent in the data itself. In this work, we em-
ploy topic based sentiment analysis using DPM 
on Twitter posts (or tweets). First, we employ a 
DPM to estimate the number of topics in the 
streaming snapshot of tweets in each day.  
Next, we build a sentiment time series based 
on the estimated topics of daily tweets. Lastly, 
we regress the stock index and the sentiment 
time series in an autoregressive framework. 
3 Model 
We now present our stock prediction framework. 
3.1 Continuous DPM Model 
Comparing to edited articles, it is much harder to 
preset the number of topics to best fit continuous 
streaming Twitter data due to the large topic di-
versity in tweets. Thus, we resort to a non-
parametric approach: the Dirichlet Process Mix-
ture (DPM) model, and let the model estimate the 
number of topics inherent in the data itself. 
Mixture model is widely used in clustering and 
can be formalized as follows: 
   ?      (       )
 
              (1) 
where    is a data point,    is its cluster label, K 
is the number of topics,  (       ) is the sta-
tistical (topic) models: *  +   
  and     is the 
component weight satisfying      and  
?      . 
In our setting of DPM, the number of mixture 
components (topics) K is unfixed apriori but es-
timated from tweets in each day. DPM is defined 
as in (Neal, 2010): 
               (  )  
              
         (   )                 (2) 
where    is the parameter of the model that      
belongs to, and   is defined as a Dirichlet Pro-
cess with the base measure H and the concentra-
tion parameter   (Neal, 2010). 
We note that neighboring days may share the 
same or closely related topics because some top-
ics may last for a long period of time covering 
multiple days, while other topics may just last for 
a short period of time. Given a set of time-
stamped tweets, the overall generative process 
should be dynamic as the topics evolve over time. 
There are several ways to model this dynamic 
nature (Sun et al, 2010; Kim and Oh, 2011; 
Chua and Asur, 2012; Blei and Lafferty, 2006; 
Wang et al, 2008). In this paper, we follow the 
approach of Sun et al (2010) due to its generality 
and extensibility. 
Figure 1 shows the graphical model of our con-
tinuous version of DPM (which we call cDPM). 
As shown, the tweets set is divided into daily 
based collections: *         +  *    +   
     are the 
observed tweets and *    +   
     are the model pa-
rameters (latent topics) that generate these tweets. 
For each subset of tweets,    (tweets of day  ), 
we build a DPM on it. For the first day (   ), 
the model functions the same as a standard DPM, 
i.e., all the topics use the same base measure, 
      ( ). However, for later days (   ), 
besides the base measure,      ( ), we make 
use of topics learned from previous days as pri-
ors. This ensures smooth topic chains or links 
(details in ?3.2). For efficiency, we only consider 
topics of one previous day as priors. 
We use collapsed Gibbs sampling (Bishop, 
2006) for model inference. Hyper-parameters are 
set to:              ;       as in 
(Sun et al, 2010; Teh et al, 2006) which have 
been shown to work well. Because a tweet has at 
most 140 characters, we assume that each tweet 
contains only one topic. Hence, we only need to 
 
 
 
 
 
 
 
 
Figure 1: Continuous DPM. 
? 
 
   
 
   
        
 
   
 
     
 
     
 
   
 
    
    
    
   
 
 
     
 
     
 
 
     
 
           
25
sample the topic assignment    for each tweet   . 
According to different situations with respect 
to a topic?s prior, for each tweet    in   , the 
conditional distribution for    given all other 
tweets? topic assignments, denoted by    , can be 
summarized as follows: 
1.    is a new topic: Its candidate priors contain 
the symmetric base prior    ( )  and topics 
*      +   
     learned from            .  
? If    takes a symmetric base prior: 
 (     
           )  
 
     
 (    )
 (       )
?  (      )
   
   
?  ( )
   
   
           (3) 
where the first part denotes the prior proba-
bility according to the Dirichlet Process and 
the second part is the data likelihood (this 
interpretation can similarly be applied to the 
following three equations).  
? If    takes one topic k from *      +   
     as 
its prior: 
 (      
            )   
 
       
     
 (    )
 (       )
?  (         ( )     )
   
   
?  (         ( ))
   
   
 (4) 
2. k is an existing topic: We already know its 
prior. 
? If k takes a symmetric base prior: 
  (               )  
 
  
  
     
 (        ( )
  )
 (           ( )
  )
?  (           
  )
   
   
?  (      
  )
   
   
 (5) 
? If k takes topic        as its prior:  
  (               )  
  
  
     
 .        ( )
  /
 .           ( )
  /
?  (         ( )          
  )
   
   
?  (         ( )     
  )
   
   
 (6) 
Notations in the above equations are listed as 
follows: 
?      is the number of topics learned in day t-1. 
? |V| is the vocabulary size. 
?    is the document length of   . 
?      is the term frequency of word   in   . 
?       ( ) is the probability of word   in pre-
vious day?s topic k.  
?   
   is the number of tweets assigned to topic k 
excluding the current one   .  
?     
   is the term frequency of word   in topic k, 
with statistic from    excluded. While    ( )
   
denotes the marginalized sum of all words in 
topic k with statistic from    excluded. 
Similarly, the posteriors on *    ( )+  (topic 
word distributions) are given according to their 
prior situations as follows: 
? If topic k takes the base prior: 
           ( )   (      ) (         ( )) ?     (7) 
where      is the frequency of word   in topic 
k and    ( )  is the marginalized sum over all 
words. 
? otherwise, it is defined recursively as: 
    ( )  (          ( )      ) (         ( ))?  (8) 
where       serves as the topic prior for     . 
Finally, for each day we estimate the topic 
weights,    as follows:  
        ?      ?                              (9) 
where    is the number of tweets in topic k. 
3.2 Topic-based Sentiment Time Series 
Based on an opinion lexicon   (a list of positive 
and negative opinion words, e.g., good and bad), 
each opinion word,     is assigned with a po-
larity label  ( ) as ?+1? if it is positive and ?-1? 
if negative. We spilt each tweet?s text into opin-
ion part and non-opinion part. Only non-opinion 
words in tweets are used for Gibbs sampling. 
Based on DPM, we learn a set of topics from 
the non-opinion words space  . The correspond-
ing tweets? opinion words share the same topic 
assignments as its tweet. Then, we compute the 
posterior on opinion word probability,     
 ( ) 
for topic   analogously to equations (7) and (8). 
Finally, we define the topic based sentiment 
score  (   ) of topic   in day t as a weighted 
linear combination of the opinion polarity labels: 
 (   )   ?     
 ( )
   
    ( );  (   )   ,    -    (10) 
According to the generative process of cDPM, 
topics between neighboring days are linked if a 
topic k takes another topic as its prior. We regard 
this as evolution of topic k. Although there may 
be slight semantic variation, the assumption is 
reasonable. Then, the sentiment scores for each 
topic series form the sentiment time series {?, 
S(t-1, k), S(t, k), S(t+1, k), ...}. 
Figure 2 demonstrates the linking process 
where a triangle denotes a new topic (with base 
symmetric prior), a circle denotes a middle topic 
(taking a topic from the previous day as its prior, 
 
 
 
 
           0      ?       t-1          t         t+1    ?    N 
Figure 2: Linking the continuous topics via 
neighboring priors. 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: Continuous DPM  
 
 
? 
... 
 
 
? 
 
 
.
.
. 
 
 
? 
 
 
? ? 
26
while also supplying prior for the next day) and 
an ellipse denotes an end topic (no further topics 
use it as a prior). In this example, two continuous 
topic chains or links (via linked priors) exist for 
the time interval [t-1, t+1]: one in light grey color, 
and the other in black. As shown, there may be 
more than one topic chain/link (5-20 in our ex-
periments) for a certain time interval1.Thus, we 
sort multiple sentiment series according to their 
accumulative weights of topics over each link: 
?     
  
    
. In our experiments, we try the top 
five series and use the one that gives the best re-
sult, which is mostly the first (top ranked) series 
with a few exceptions of the second series. The 
topics mostly focus on hot keywords like: news, 
stocknews, earning, report, which stimulate ac-
tive discussions on the social media platform. 
3.3 Time Series Analysis with VAR 
For model building, we use vector autoregression 
(VAR). The first order (time steps of historical 
information to use: lag = 1) VAR model for two 
time series *  + and *  + is given by:  
                                                   
                                               (11) 
where * + are the white noises and * + are model 
parameters. We use the ?dse? library2 in the R 
language to fit our VAR model based on least 
square regression. 
 Instead of training in one period and predicting 
over another disjointed period, we use a moving 
training and prediction process under sliding 
windows3 (i.e., train in [t, t + w] and predict in-
dex on t + w + 1) with two main considerations: 
? Due to the dynamic and random nature of both 
the stock market and public sentiments, we are 
more interested in their short term relationship. 
? Based on the sliding windows, we have more 
training and testing points.  
Figure 3 details the algorithm for stock index 
prediction. The accuracy is computed based on 
the index up and down dynamics, the function 
     (    ) returns True only if   (our predic-
tion) and   (actual value) share the same index 
up or down direction. 
 
 
                                                 
1 The actual topic priors for topic links are governed by the 
four cases of the Gibbs Sampler. 
2 http://cran.r-project.org/web/packages/dse 
3  This is similar to the autoregressive moving average 
(ARMA) models. 
4 Dataset 
We collected the tweets via Twitter?s REST API 
for streaming data, using symbols of the Stand-
ard & Poor's 100 stocks (S&P100) as keywords. 
In this study, we focus only on predicting the 
S&P100 index. The time period of our dataset is 
between Nov. 2, 2012 and Feb. 7, 2013, which 
gave us 624782 tweets. We obtained the S&P100 
index?s daily close values from Yahoo Finance. 
5 Experiment 
5.1 Selecting a Sentiment Metric 
Bollen et al (2011) used the mood dimension, 
Calm together with the index value itself to pre-
dict the Dow Jones Industrial Average. However, 
their Calm lexicon is not publicly available. We 
thus are unable to perform a direct comparison 
with their system. We identified and labeled a 
Calm lexicon (words like ?anxious?, ?shocked?, 
?settled? and ?dormant?) using the opinion lexi-
con4 of Hu and Liu (2004) and computed the sen-
timent score using the method of Bollen et al 
(2011) (sentiment ratio). Our pilot experiments 
showed that using the full opinion lexicon of Hu 
and Liu (2004) actually performs consistently 
better than the Calm lexicon. Hence, we use the 
entire opinion lexicon in Hu and Liu (2004). 
5.2 S&P100INDEX Movement Prediction 
We evaluate the performance of our method by 
comparing with two baselines. The first (Index) 
uses only the index itself, which reduces the 
VAR model to the univariate autoregressive 
model (AR), resulting in only one index time 
series {  } in the algorithm of Figure 3.  
                                                 
4 http://cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar 
Parameter:  
w: training window size; lag: the order of VAR;  
Input:   : the date of time series; {  }: sentiment time 
series; {  }: index time series; 
Output: prediction accuracy. 
1. for t = 0, 1, 2, ?, N-w-1 
2. { 
3.        = VAR( ,     -  ,     -, lag); 
4.             
 =      .Predict(x[t+w+1-lag, t+w],  
  y[t+w+1-lag, t+w]); 
5.       if (     (      
        ) )   
 rightNum++;  
6.     } 
7.    Accuracy = rightNum / (N-w); 
8.    Return Accuracy; 
Figure 3: Prediction algorithm and accuracy 
 
 
 
 
 
 
 
 
 
Figure 1: Continuous DPM  
27
 When considering Twitter sentiments, existing 
works (Bollen et al, 2011, Ruiz et al, 2012) 
simply compute the sentiment score as ratio of 
pos/neg opinion words per day. This generates a 
lexicon-based sentiment time series, which is 
then combined with the index value series to give 
us the second baseline Raw.  
 In summary, Index uses index only with the 
AR model while Raw uses index and opinion 
lexicon based time series. Our cDPM uses index 
and the proposed topic based sentiment time se-
ries. Both Raw and cDPM employ the two di-
mensional VAR model. We experiment with dif-
ferent lag settings from 1-3 days. 
 We also experiment with different training 
window sizes, ranging from 15 - 30 days, and 
compute the prediction accuracy for each win-
dow size. Table 1 shows the respective average 
and best accuracies over all window sizes for 
each lag and Table 2 summarizes the pairwise 
performance improvements of averaged scores 
over all training window sizes. Figure 4 show the 
detailed accuracy comparison for lag 1 and lag 3.  
    From Table 1, 2, and Figure 4, we note: 
i. Topic-based public sentiments from tweets 
can improve stock prediction over simple sen-
timent ratio which may suffer from backchan-
nel noise and lack of focus on prevailing top-
ics. For example, on lag 2, Raw performs 
worse by 8.6% than Index itself. 
ii. cDPM outperforms all others in terms of both 
the best accuracy (lag 3) and the average ac-
curacies for different window sizes. The max-
imum average improvement reaches 25.0% 
compared to Index at lag 1 and 15.1% com-
pared to Raw at lag 3. This is due to the fact 
that cDPM learns the topic based sentiments 
instead of just using the opinion words? ratio 
like Raw, and in a short time period, some 
topics are more correlated with the stock mar-
ket than others. Our proposed sentiment time 
series using cDPM can capture this phenome-
non and also help reduce backchannel noise 
of raw sentiments.  
iii. On average, cDPM gets the best performance 
for training window sizes within [21, 22], and 
the best prediction accuracy is 68.0% on win-
dow size 22 at lag 3. 
6 Conclusions 
Predicting the stock market is an important but 
difficult problem. This paper showed that Twit-
ter?s topic based sentiment can improve the pre-
diction accuracy beyond existing non-topic based 
approaches. Specifically, a non-parametric topic-
based sentiment time series approach was pro-
posed for the Twitter stream. For prediction, vec-
tor autoregression was used to regress S&P100 
index with the learned sentiment time series. Be-
sides the short term dynamics based prediction, 
we believe that the proposed method can be ex-
tended for long range dependency analysis of 
Twitter sentiments and stocks, which can render 
deep insights into the complex phenomenon of 
stock market. This will be part of our future work. 
Acknowledgments 
This work was supported in part by a grant from 
the National Science Foundation (NSF) under 
grant no. IIS-1111092 and a strategic research 
grant from City University of Hong Kong (pro-
ject number: 7002770). 
Lag Index Raw cDPM 
1 0.48(0.54) 0.57(0.59) 0.60(0.64) 
2 0.58(0.65) 0.53(0.62) 0.60(0.63) 
3 0.52(0.56) 0.53(0.60) 0.61(0.68) 
Table 1: Average (best) accuracies over all 
training window sizes and different lags 1, 2, 3. 
Lag Raw vs. Index cDPM vs. Index cDPM vs. Raw 
1 18.8% 25.0% 5.3% 
2 -8.6% 3.4% 13.2% 
3 1.9% 17.3% 15.1% 
Table 2: Pairwise improvements among Index, 
Raw and cDPM averaged over all training win-
dow sizes. 
 
Figure 4: Comparison of prediction accuracy of 
up/down stock index on S&P 100 index for dif-
ferent training window sizes. 
0.25
0.45
0.65
15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
A
cc
u
ra
cy
 
Training window size 
Comparison on Lag 1 
Index Raw cDPM
0.25
0.35
0.45
0.55
0.65
0.75
18 19 20 21 22 23 24 25 26 27 28 29 30
A
cc
u
ra
cy
 
Training Window size 
Comparison on Lag 3 
Index Raw cDPM
28
References 
Bishop, C. M. 2006. Pattern Recognition and Machine 
Learning. Springer. 
Blei, D., Ng, A. and Jordan, M. 2003. Latent Dirichlet 
allocation. Journal of Machine Learning Research 
3:993?1022. 
Blei, D. and Lafferty, J. 2006. Dynamic topic models. 
In Proceedings of the 23rd International Confer-
ence on Machine Learning (ICML-2006). 
Bollen, J., Mao, H. N., and Zeng, X. J. 2011. Twitter 
mood predicts the stock market. Journal of Com-
puter Science 2(1):1-8.  
Branavan, S., Chen, H., Eisenstein J. and Barzilay, R. 
2008. Learning document-level semantic properties 
from free-text annotations. In Proceedings of the 
Annual Meeting of the Association for Computa-
tional Linguistics (ACL-2008). 
Brody, S. and Elhadad, S. 2010. An unsupervised 
aspect-sentiment model for online reviews. In Pro-
ceedings of the 2010 Annual Conference of the 
North American Chapter of the ACL (NAACL-
2010). 
Chua, F. C. T. and Asur, S. 2012. Automatic Summa-
rization of Events from Social Media, Technical 
Report, HP Labs. 
Feldman, R., Benjamin, R., Roy, B. H. and Moshe, F. 
2011. The Stock Sonar - Sentiment analysis of 
stocks based on a hybrid approach. In Proceedings 
of 23rd IAAI Conference on Artificial Intelligence 
(IAAI-2011). 
He, Y., Lin, C., Gao, W., and Wong, K. F. 2012. 
Tracking sentiment and topic dynamics from social 
media. In Proceedings of the 6th International 
AAAI Conference on Weblogs and Social Media 
(ICWSM-2012). 
Hu, M. and Liu, B. 2004. Mining and summarizing 
customer reviews. In Proceedings of the ACM 
SIGKDD International Conference on Knowledge 
Discovery & Data Mining (KDD-2004). 
Jo, Y. and Oh, A. 2011. Aspect and sentiment unifica-
tion model for online review analysis. In Proceed-
ings of ACM Conference in Web Search and Data 
Mining (WSDM-2011). 
Kim, D. and Oh, A. 2011. Topic chains for under-
standing a news corpus. CICLing (2): 163-176. 
Lavrenko, V., Schmill, M., Lawrie, D., Ogilvie, P., 
Jensen, D. and Allan, J. 2000. Mining of concur-
rent text and time series. In Proceedings of the 6th 
KDD Workshop on Text Mining, 37?44. 
Lin, C. and He, Y. 2009. Joint sentiment/topic model 
for sentiment analysis. In Proceedings of ACM In-
ternational Conference on Information and 
Knowledge Management (CIKM-2009). 
Liu, B. 2012. Sentiment analysis and opinion mining. 
Morgan & Claypool Publishers.  
Mei, Q., Ling, X., Wondra, M., Su, H. and Zhai, C. 
2007. Topic sentiment mixture: modeling facets 
and opinions in weblogs. In Proceedings of Interna-
tional Conference on World Wide Web (WWW-
2007). 
Moghaddam, S. and Ester, M. 2011. ILDA: Interde-
pendent LDA model for learning latent aspects and 
their ratings from online product reviews.  In Pro-
ceedings of the Annual ACM SIGIR International 
conference on Research and Development in In-
formation Retrieval (SIGIR-2011). 
Mukherjee A. and Liu, B. 2012. Aspect extraction 
through semi-supervised modeling. In Proceedings 
of the 50th Annual Meeting of the Association for 
Computational Linguistics (ACL-2012).  
Neal, R.M. 2000. Markov chain sampling methods for 
dirichlet process mixture models. Journal of Com-
putational and Graphical Statistics, 9(2):249-265. 
Ruiz, E. J., Hristidis, V., Castillo, C., Gionis, A. and 
Jaimes, A. 2012. Correlating financial time series 
with micro-blogging activity. In Proceedings of the 
fifth ACM international conference on Web search 
and data mining (WSDM-2012), 513-522.  
Sauper, C., Haghighi, A. and Barzilay, R. 2011. Con-
tent models with attitude. Proceedings of the 49th 
Annual Meeting of the Association for Computa-
tional Linguistics (ACL). 
Schumaker, R. P. and Chen, H. 2009. Textual analysis 
of stock market prediction using breaking financial 
news. ACM Transactions on Information Systems 
27(February (2)):1?19. 
Sun, Y. Z., Tang, J. Han, J., Gupta M. and Zhao, B. 
2010. Community Evolution Detection in Dynamic 
Heterogeneous Information Networks. In Proceed-
ings of KDD Workshop on Mining and Learning 
with Graphs (MLG'2010), Washington, D.C. 
Teh, Y., Jordan M., Beal, M. and Blei, D. 2006. Hier-
archical Dirichlet processes. Journal of the Ameri-
can Statistical Association, 101[476]:1566-1581. 
Wang, C. Blei, D. and Heckerman, D. 2008. Continu-
ous Time Dynamic Topic Models. Uncertainty in 
Artificial Intelligence (UAI 2008), 579-586 
Wang, H., Lu, Y.  and Zhai, C. 2010. Latent aspect 
rating analysis on review text data: a rating regres-
sion approach. Proceedings of ACM SIGKDD In-
ternational Conference on Knowledge Discovery 
and Data Mining (KDD-2010). 
Zhao, W. Jiang, J. Yan, Y. and Li, X. 2010. Jointly 
modeling aspects and opinions with a MaxEnt-
LDA hybrid. In Proceedings of Conference on Em-
pirical Methods in Natural Language Processing 
(EMNLP-2010). 
29
