Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 121?124,
New York, June 2006. c?2006 Association for Computational Linguistics
Computational Modelling of Structural Priming in Dialogue
David Reitter, Frank Keller, Johanna D. Moore
dreitter | keller | jmoore @ inf.ed.ac.uk
School of Informatics
University of Edinburgh
United Kingdom
Abstract
Syntactic priming effects, modelled as in-
crease in repetition probability shortly af-
ter a use of a syntactic rule, have the
potential to improve language processing
components. We model priming of syn-
tactic rules in annotated corpora of spo-
ken dialogue, extending previous work
that was confined to selected construc-
tions. We find that speakers are more re-
ceptive to priming from their interlocutor
in task-oriented dialogue than in spona-
neous conversation. Low-frequency rules
are more likely to show priming.
1 Introduction
Current dialogue systems overlook an interesting
fact of language-based communication. Speakers
tend to repeat their linguistic decisions rather than
making them from scratch, creating entrainment
over time. Repetition is evident not just on the ob-
vious lexical level: syntactic choices depend on pre-
ceding ones in a way that can be modelled and, ul-
timately, be leveraged in parsing and language gen-
eration. The statistical analysis in this paper aims to
make headway towards such a model.
Recently, priming phenomena1 have been ex-
ploited to aid automated processing, for instance in
automatic speech recognition using cache models,
but only recently have attempts been made at using
1The term priming refers to a process that influences lin-
guistic decision-making. An instance of priming occurs when a
syntactic structure or lexical item giving evidence of a linguistic
choice (prime) influences the recipient to make the same deci-
sion, i.e. re-use the structure, at a later choice-point (target).
them in parsing (Charniak and Johnson, 2005). In
natural language generation, repetition can be used
to increase the alignment of human and computers.
A surface-level approach is possible by biasing the
n-gram language model used to select the output
string from a variety of possible utterances (Brock-
mann et al, 2005).
Priming effects are common and well known. For
instance, speakers access lexical items more quickly
after a semantically or phonologically similar prime.
Recent work demonstrates large effects for partic-
ular synonymous alternations (e.g., active vs. pas-
sive voice) using traditional laboratory experiments
with human subjects (Bock, 1986; Branigan et al,
2000). In this study, we look at the effect from a
computational perspective, that is, we assume some
form of parsing and syntax-driven generation com-
ponents. While previous studies singled out syntac-
tic phenomena, we assume a phrase-structure gram-
mar where all syntactic rules may receive priming.
We use large-scale corpora, which reflect the reali-
ties of natural interaction, where limited control ex-
ists over syntax and the semantics of the utterances.
Thus, we quantify priming for the general case in
the realistic setting provided by corpus based exper-
iments. As a first hypothesis, we predict that after a a
syntactic rule occurs, it is more likely to be repeated
shortly than a long time afterwards.
From a theoretical perspective, priming opens a
peephole into the architecture of the human lan-
guage faculty. By identifying units in which prim-
ing occurs, we can pinpoint the structures used in
processing. Also, priming may help explain the ease
with which humans engange in conversations.
This study is interested in the differences relevant
to systems implementing language-based human-
121
computer interaction. Often, HCI is a means for
user and system to jointly plan or carry out a task.
Thus, we look at repetition effects in task-oriented
dialogue. A recent psychological perspective mod-
els Interactive Alignment between speakers (Picker-
ing and Garrod, 2004), where mutual understand-
ing about task and situation depends on lower-level
priming effects. Under the model, we expect prim-
ing effects to be stronger when a task requires high-
level alignment of situation models.
2 Method
2.1 Dialogue types
We examined two corpora. Switchboard con-
tains 80,000 utterances of spontaneous spoken con-
versations over the telephone among randomly
paired, North American speakers, syntactically an-
notated with phrase-structure grammar (Marcus
et al, 1994). The HCRC Map Task corpus comprises
more than 110 dialogues with a total of 20, 400 ut-
terances (Anderson et al, 1991). Like Switchboard,
HCRC Map Task is a corpus of spoken, two-person
dialogue in English. However, Map Task contains
task-oriented dialogue: interlocutors work together
to achieve a task as quickly and efficiently as pos-
sible. Subjects were asked to give each other direc-
tions with the help of a map. The interlocutors are in
the same room, but have separate, slightly different
maps and are unable to see each other?s maps.
2.2 Syntactic repetitions
Both corpora are annotated with phrase structure
trees. Each tree was converted into the set of phrase
structure productions that license it. This allows us
to identify the repeated use of rules. Structural prim-
ing would predict that a rule (target) occurs more
often shortly after a potential prime of the same rule
than long afterwards ? any repetition at great dis-
tance is seen as coincidental. Therefore, we can cor-
relate the probability of repetition with the elapsed
time (DIST) between prime and target.
We considered very pair of two equal syntactic
rules up to a predefined maximal distance to be a
potential case of priming-enhanced production. If
we consider priming at distances 1 . . . n, each rule
instance produces up to n data points. Our binary
response variable indicates whether there is a prime
for the target between n ? 0.5 and n + 0.5 seconds
before the target. As a prime, we see the invocation
of the same rule. Syntactic repetitions resulting from
lexical repetition and repetitions of unary rules are
excluded. We looked for repetitions within windows
(DIST) of n = 15 seconds (Section 3.1).
Without priming, one would expect that there is a
constant probability of syntactic repetition, no mat-
ter the distance between prime and target. The anal-
ysis tries to reject this null hypothesis and show a
correlation of the effect size with the type of corpus
used. We expect to see the syntactic priming effect
found experimentally should translate to more cases
for shorter repetition distances, since priming effects
usually decay rapidly (Branigan et al, 1999).
The target utterance is included as a random fac-
tor in our model, grouping all 15 measurements of
all rules of an utterance as repeated measurements,
since they depend on the same target rule occurrence
or at least on other other rules in the utterance, and
are, thus, partially inter-dependent.
We distinguish production-production priming
within (PP) and comprehension-production priming
between speakers (CP), encoded in the factor ROLE.
Models were estimated on joint data sets derived
from both corpora, with a factor SOURCE included
to discriminate the two dialogue types.
Additionally, we build a model estimating the ef-
fect of the raw frequency of a particular syntactic
rule on the priming effect (FREQ). This is of par-
ticular interest for priming in applications, where a
statistical model will, all other things equal, prefer
the more frequent linguistic choice; recall for com-
peting low-frequency rules will be low.
2.3 Generalized Linear Mixed Effect
Regression
In this study, we built generalized linear mixed ef-
fects regression models (GLMM). In all cases, a rule
instance target is counted as a repetition at distance
d iff there is an utterance prime which contains the
same rule, and prime and target are d units apart.
GLMMs with a logit-link function are a form of lo-
gistic regression.2
2We trained our models using Penalized Quasi-Likelihood
(Venables and Ripley, 2002). We will not generally give classi-
calR2 figures, as this metric is not appropriate to such GLMMs.
The below experiments were conducted on a sample of 250,000
122
SWBD PP MT PP MT CP
?0
.1
0
?0
.0
5
0.
00
0.
05
0.
10
0.
15
0.
20
Switchboard Map Task
PP PP CPCP
*
*
*
-
-
-
-
0 5 10 15
0.0
10
0.0
12
0.0
14
0.0
16
0.0
18
0.0
20
distance: Temporal Distance between prime and target (seconds)
p(p
rim
e=t
arg
et|t
arg
et,d
ista
nce
)
Map Task: 
production-production
Switchboard: 
production-production
Map Task: 
comprehension-production
Switchboard: 
comprehension-production
Figure 1: Left: Estimated priming strength (repetition probability decay rate) for Switchboard and Map
Task, for within-speaker (PP) and between-speaker (CP) priming. Right: Fitted model for the development
of repetition probability (y axis) over time (x axis, in seconds). Here, decay (slope) is the relevant factor for
priming strength, as shown on the left. These are derived from models without FREQ.
Regression allows us not only to show that prim-
ing exists, but it allows us to predict the decline of
repetition probability with increasing distance be-
tween prime and target and depending on other vari-
ables. If we see priming as a form of pre-activation
of syntactic nodes, it indicates the decay rate of pre-
activation. Our method quantifies priming and cor-
relates the effect with secondary factors.
3 Results
3.1 Task-oriented and spontaneous dialogue
Structural repetition between speakers occured in
both corpora and its probability decreases logarith-
mically with the distance between prime and target.
Figure 1 provides the model for the influence
of the four factorial combinations of ROLE and
SOURCE on priming (left) and the development of
repetition probability at increasing distance (right).
SOURCE=Map Task has an interaction effect on the
priming decay ln(DIST), both for PP priming (? =
?0.024, t = ?2.0, p < 0.05) and for CP priming
(? = ?0.059, t = ?4.0, p < 0.0005). (Lower coef-
ficients indicate more decay, hence more priming.)
data points per corpus.
In both corpora, we find positive priming effects.
However, PP priming is stronger, and CP priming is
much stronger in Map Task.
The choice of corpus exhibits a marked interac-
tion with priming effect. Spontaneous conversation
shows significantly less priming than task-oriented
dialogue. We believe this is not a side-effect of vary-
ing grammar size or a different syntactic entropy in
the two types of dialogue, since we examine the de-
cay of repetition probability with increasing distance
(interactions with DIST), and not the overall proba-
bility of chance repetition (intercepts / main effects
except DIST).
3.2 Frequency effects
An additional model was built which included
ln(FREQ) as a predictor that may interact with the
effect coefficient for ln(DIST).
ln(FREQ) is inversely correlated with
the priming effect (Paraphrase: ?lnDist =
?1.05, ?lnDist:lnFreq = 0.54, Map Task:
?lnDist = ?2.18, ?lnDist:lnFreq = 0.35, all
p < 0.001). Priming weakens with higher
(logarithmic) frequency of a syntactic rule.
123
4 Discussion
Evidence from Wizard-of-Oz experiments (with sys-
tems simulated by human operators) have shown
that users of dialogue systems strongly align their
syntax with that of a (simulated) computer (Brani-
gan et al, 2003). Such an effect can be leveraged
in an application, provided there is a priming model
interfacing syntactic processing.
We found evidence of priming in general, that is,
when we assume priming of each phrase structure
rule. The priming effects decay quickly and non-
linearly, which means that a dialogue system would
best only take a relatively short preceding context
into account, e.g., the previous few utterances.
An important consideration in the context of di-
alogue systems is whether user and system collab-
orate on solving a task, such as booking tickets or
retrieving information. Here, syntactic priming be-
tween human speakers is strong, so a system should
implement it. In other situations, systems do not
have to use a unified syntactic architecture for pars-
ing and generation, but bias their output on previous
system utterances, and possibly improve parsing by
looking at previously recognized inputs.
The fact that priming is more pronounced within
(PP) a speaker suggests that optimizing parsing and
generation separately is the most promising avenue
in either type of dialogue system.
One explanation for this lies in a reduced cog-
nitive load of spontaneous, everyday conversation.
Consequently, the more accessible, highly-frequent
rules prime less.
In task-oriented dialogue, speakers need to pro-
duce a common situation model. Interactive Align-
ment Model argues that this process is aided by syn-
tactic priming. In support of this model, we find
more priming in task-oriented dialogue.3
5 Conclusions
Syntactic priming effects are reliably present in di-
alogue even in computational models where the full
range of syntactic rules is considered instead of se-
lected constructions with known strong priming.
This is good news for dialogue systems, which
tend to be task-oriented. Linguistically motivated
3For a more detailed analysis from the perspective of inter-
active alignment, see Reitter et al (2006).
systems can possibly exploit the user?s tendency to
repeat syntactic structures by anticipating repetition.
Future systems may also align their output with their
recognition capabilities and actively align with the
user to signal understanding. Parsers and realizers in
natural language generation modules may make the
most of priming if they respect important factors that
influence priming effects, such as task-orientation of
the dialogue and frequency of the syntactic rule.
Acknowledgements
The authors would like to thank Amit Dubey, Roger Levy and
Martin Pickering. The first author?s work is supported by a grant
from the Edinburgh Stanford Link.
References
A. Anderson, M. Bader, E. Bard, E. Boyle, G. M. Doherty,
S. Garrod, S. Isard, J. Kowtko, J. McAllister, J. Miller,
C. Sotillo, H. Thompson, and R. Weinert. 1991. The HCRC
Map Task corpus. Language and Speech, 34(4):351?366.
J. Kathryn Bock. 1986. Syntactic persistence in language pro-
duction. Cognitive Psychology, 18:355?387.
Holly P. Branigan, Martin J. Pickering, and Alexandra A. Cle-
land. 1999. Syntactic priming in language production: Ev-
idence for rapid decay. Psychonomic Bulletin and Review,
6(4):635?640.
Holly P. Branigan, Martin J. Pickering, and Alexandra A. Cle-
land. 2000. Syntactic co-ordination in dialogue. Cognition,
75:B13?25.
Holly P. Branigan, Martin J. Pickering, Jamie Pearson, Janet F.
McLean, and Clifford Nass. 2003. Syntactic alignment be-
tween computers and people: the role of belief about mental
states. In Proceedings of the Twenty-fifth Annual Conference
of the Cognitive Science Society.
Carsten Brockmann, Amy Isard, Jon Oberlander, and Michael
White. 2005. Modelling alignment for affective dialogue. In
Workshop on Adapting the Interaction Style to Affective Fac-
tors at the 10th International Conference on User Modeling
(UM-05). Edinburgh, UK.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-fine n-
best parsing and MaxEnt discriminative reranking. In Proc.
43th ACL.
M. Marcus, G. Kim, M. Marcinkiewicz, R. MacIntyre, A. Bies,
M. Ferguson, K. Katz, and B. Schasberger. 1994. The Penn
treebank: Annotating predicate argument structure. In Proc.
ARPA Human Language Technology Workshop.
Martin J. Pickering and Simon Garrod. 2004. Toward a mech-
anistic psychology of dialogue. Behavioral and Brain Sci-
ences, 27:169?225.
David Reitter, Johanna D. Moore, and Frank Keller. 2006. Prim-
ing of syntactic rules in task-oriented dialogue and sponta-
neous conversation. In Proceedings of the 28th Annual Con-
ference of the Cognitive Science Society.
William N. Venables and Brian D. Ripley. 2002. Modern Ap-
plied Statistics with S. Fourth Edition. Springer.
124
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 808?815,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Predicting Success in Dialogue
David Reitter and Johanna D. Moore
dreitter | jmoore @ inf.ed.ac.uk
School of Informatics
University of Edinburgh
United Kingdom
Abstract
Task-solving in dialogue depends on the lin-
guistic alignment of the interlocutors, which
Pickering & Garrod (2004) have suggested
to be based on mechanistic repetition ef-
fects. In this paper, we seek confirmation
of this hypothesis by looking at repetition
in corpora, and whether repetition is cor-
related with task success. We show that
the relevant repetition tendency is based on
slow adaptation rather than short-term prim-
ing and demonstrate that lexical and syntac-
tic repetition is a reliable predictor of task
success given the first five minutes of a task-
oriented dialogue.
1 Introduction
While humans are remarkably efficient, flexible and
reliable communicators, we are far from perfect.
Our dialogues differ in how successfully informa-
tion is conveyed. In task-oriented dialogue, where
the interlocutors are communicating to solve a prob-
lem, task success is a crucial indicator of the success
of the communication.
An automatic measure of task success would be
useful for evaluating conversations among humans,
e.g., for evaluating agents in a call center. In human-
computer dialogues, predicting the task success after
just a first few turns of the conversation could avoid
disappointment: if the conversation isn?t going well,
a caller may be passed on to a human operator, or
the system may switch dialogue strategies. As a first
step, we focus on human-human dialogue, since cur-
rent spoken dialogue systems do not yet yield long,
syntactically complex conversations.
In this paper, we use syntactic and lexical features
to predict task success in an environment where we
assume no speaker model, no semantic information
and no information typical for a human-computer
dialogue system, e.g., ASR confidence. The fea-
tures we use are based on a psychological theory,
linking alignment between dialogue participants to
low-level syntactic priming. An examination of this
priming reveals differences between short-term and
long-term effects.
1.1 Repetition supports dialogue
In their Interactive Alignment Model (IAM), Pick-
ering and Garrod (2004) suggest that dialogue be-
tween humans is greatly aided by aligning repre-
sentations on several linguistic and conceptual lev-
els. This effect is assumed to be driven by a cas-
cade of linguistic priming effects, where interlocu-
tors tend to re-use lexical, syntactic and other lin-
guistic structures after their introduction. Such re-
use leads speakers to agree on a common situa-
tion model. Several studies have shown that speak-
ers copy their interlocutor?s syntax (Branigan et al,
1999). This effect is usually referred to as structural
(or: syntactic) priming. These persistence effects
are inter-related, as lexical repetition implies pref-
erences for syntactic choices, and syntactic choices
lead to preferred semantic interpretations. Without
demanding additional cognitive resources, the ef-
fects form a causal chain that will benefit the inter-
locutor?s purposes. Or, at the very least, it will be
easier for them to repeat linguistic choices than to
808
actively discuss their terminology and keep track of
each other?s current knowledge of the situation in
order to come to a mutual understanding.
1.2 Structural priming
The repetition effect at the center of this paper, prim-
ing, is defined as a tendency to repeat linguistic de-
cisions. Priming has been shown to affect language
production and, to a lesser extent, comprehension, at
different levels of linguistic analysis. This tendency
may show up in various ways, for instance in the
case of lexical priming as a shorter response time in
lexical decision making tasks, or as a preference for
one syntactic construction over an alternative one in
syntactic priming (Bock, 1986). In an experimental
study (Branigan et al, 1999), subjects were primed
by completing either sentence (1a) or (1b):
1a. The racing driver showed the torn overall...
1b. The racing driver showed the helpful mechanic...
Sentence (1a) was to be completed with a prepo-
sitional object (?to the helpful mechanic?), while
(1b) required a double object construction (?the torn
overall?). Subsequently, subjects were allowed to
freely complete a sentence such as the following
one, describing a picture they were shown:
2. The patient showed ...
Subjects were more likely to complete (2) with a
double-object construction when primed with (1b),
and with a prepositional object construction when
primed with (1a).
In a previous corpus-study, using transcriptions
of spontaneous, task-oriented and non-task-oriented
dialogue, utterances were annotated with syntactic
trees, which we then used to determine the phrase-
structure rules that licensed production (and com-
prehension) of the utterances (Reitter et al, 2006b).
For each rule, the time of its occurrence was noted,
e.g. we noted
3. 117.9s NP ? AT AP NN a fenced meadow
4. 125.5s NP ? AT AP NN the abandoned cottage
In this study, we then found that the re-occurrence
of a rule (as in 4) was correlated with the temporal
distance to the first occurrence (3), e.g., 7.6 seconds.
The shorter the distance between prime (3) and tar-
get (4), the more likely were rules to re-occur.
In a conversation, priming may lead a speaker
to choose a verb over a synonym because their in-
terlocutor has used it a few seconds before. This,
in turn, will increase the likelihood of the struc-
tural form of the arguments in the governed verbal
phrase?simply because lexical items have their pref-
erences for particular syntactic structures, but also
because structural priming may be stronger if lexi-
cal items are repeated (lexical boost, Pickering and
Branigan (1998)). Additionally, the structural prim-
ing effects introduced above will make a previously
observed or produced syntactic structure more likely
to be re-used. This chain reaction leads interlocu-
tors in dialogue to reach a common situation model.
Note that the IAM, in which interlocutors automati-
cally and cheaply build a common representation of
common knowledge, is at odds with views that af-
ford each dialogue participant an explicit and sepa-
rate representation of their interlocutor?s knowledge.
The connection between linguistic persistence or
priming effects and the success of dialogue is cru-
cial for the IAM. The predictions arising from this,
however, have eluded testing so far. In our previous
study (Reitter et al, 2006b), we found more syn-
tactic priming in the task-oriented dialogues of the
Map Task corpus than in the spontaneous conversa-
tion collected in the Switchboard corpus. However,
we compared priming effects across two datasets,
where participants and conversation topics differed
greatly. Switchboard contains spontaneous conver-
sation over the telephone, while the task-oriented
Map Task corpus was recorded with interlocutors
co-present. While the result (more priming in
task-oriented dialogue) supported the predictions of
IAM, cognitive load effects could not be distin-
guished from priming. In the current study, we ex-
amine structural repetition in task-oriented dialogue
only and focus on an extrinsic measure, namely task
success.
2 Related Work
Prior work on predicting task success has been
done in the context of human-computer spoken di-
alogue systems. Features such as recognition er-
ror rates, natural language understanding confidence
and context shifts, confirmations and re-prompts (di-
alogue management) have been used classify dia-
809
logues into successful and problematic ones (Walker
et al, 2000). With these automatically obtainable
features, an accuracy of 79% can be achieved given
the first two turns of ?How may I help you?? di-
alogues, where callers are supposed to be routed
given a short statement from them about what they
would like to do. From the whole interaction (very
rarely more than five turns), 87% accuracy can be
achieved (36% of dialogues had been hand-labeled
?problematic?). However, the most predictive fea-
tures, which related to automatic speech recognition
errors, are neither available in the human-human di-
alogue we are concerned with, nor are they likely to
be the cause of communication problems there.
Moreover, failures in the Map Task dialogues are
due to the actual goings-on when two interlocutors
engage in collaborative problem-solving to jointly
reach an understanding. In such dialogues, inter-
locutors work over a period of about half an hour.
To predict their degree of success, we will leverage
the phenomenon of persistence, or priming.
In previous work, two paradigms have seen exten-
sive use to measure repetition and priming effects.
Experimental studies expose subjects to a particular
syntactic construction, either by having them pro-
duce the construction by completing a sample sen-
tence, or by having an experimenter or confederate
interlocutor use the construction. Then, subjects are
asked to describe a picture or continue with a given
task, eliciting the target construction or a compet-
ing, semantically equivalent alternative. The analy-
sis then shows an effect of the controlled condition
on the subject?s use of the target construction.
Observational studies use naturalistic data, such
as text and dialogue found in corpora. Here, the
prime construction is not controlled?but again, a
correlation between primes and targets is sought.
Specific competing constructions such as ac-
tive/passive, verbal particle placement or that-
deletion in English are often the object of study
(Szmrecsanyi, 2005; Gries, 2005; Dubey et al,
2005; Ja?ger, 2006), but the effect can also be gen-
eralized to syntactic phrase-structure rules or com-
binatorial categories (Reitter et al, 2006a).
Church (2000) proposes adaptive language mod-
els to account for lexical adaptation. Each document
is split into prime and target halves. Then, for se-
lected words w, the model estimates
P (+adapt) = P (w ? target|w ? prime)
P (+adapt) is higher than Pprior = P (w ?
target), which is not surprising, since texts are usu-
ally about a limited number of topics.
This method looks at repetition over whole doc-
ument halves, independently of decay. In this pa-
per, we apply the same technique to syntactic rules,
where we expect to estimate syntactic priming ef-
fects of the long-term variety.
3 Repetition-based Success Prediction
3.1 The Success Prediction Task
In the following, we define two variants of the task
and then describe a model that uses repetition effects
to predict success.
Task 1: Success is estimated when an entire di-
alogue is given. All linguistic and non-linguistic
information available may be used. This task re-
flects post-hoc analysis applications, where dia-
logues need to be evaluated without the actual suc-
cess measure being available for each dialogue. This
covers cases where, e.g., it is unclear whether a call
center agent or an automated system actually re-
sponded to the call satisfactorily.
Task 2: Success is predicted when just the initial
5-minute portion of the dialogue is available. A dia-
logue system?s or a call center agent?s strategy may
be influenced depending on such a prediction.
3.2 Method
To address the tasks described in the previous Sec-
tion, we train support vector machines (SVM) to
predict the task success score of a dialogue from
lexical and syntactic repetition information accumu-
lated up to a specified point in time in the dialogue.
Data
The HCRC Map Task corpus (Anderson et al,
1991) contains 128 dialogues between subjects, who
were given two slightly different maps depicting the
same (imaginary) landscape. One subject gives di-
rections for a predefined route to another subject,
who follows them and draws a route on their map.
The spoken interactions were recorded, tran-
scribed and syntactically annotated with phrase-
structure grammar.
810
The Map Task provides us with a precise measure
of success, namely the deviation of the predefined
and followed route. Success can be quantified by
computing the inverse deviation between subjects?
paths. Both subjects in each trial were asked to draw
?their? respective route on the map that they were
given. The deviation between the respective paths
drawn by interlocutors was then determined as the
area covered in between the paths (PATHDEV).
Features
Repetition is measured on a lexical and a syntactic
level. To do so, we identify all constituents in the
utterances as per phrase-structure analysis. [Go [to
[the [[white house] [on [the right]]]]]] would yield
11 constituents. Each constituent is licensed by a
syntactic rule, for instance VP ? V PP for the top-
most constituent in the above example.
For each constituent, we check whether it is a lex-
ical or syntactic repetition, i.e. if the same words
occurred before, or if the licensing rule has occurred
before in the same dialogue. If so, we increment
counters for lexical and/or syntactic repetitions, and
increase a further counter for string repetition by the
length of the phrase (in characters). The latter vari-
able accounts for the repetition of long phrases.
We include a data point for each 10-second inter-
val of the dialogue, with features reporting the lexi-
cal (LEXREP), syntactic (SYNREP) and character-
based (CHARREP) repetitions up to that point in
time. A time stamp and the total numbers of con-
stituents and characters are also included (LENGTH).
This way, the model may work with repetition pro-
portions rather than the absolute counts.
We train a support vector machine for regression
with a radial basis function kernel (? = 5), using the
features as described above and the PATHDEV score
as output.
3.3 Evaluation
We cast the task as a regression problem. To pre-
dict a dialogue?s score, we apply the SVM to its data
points. The mean outcome is the estimated score.
A suitable evaluation measure, the classical r2,
indicates the proportion of the variance in the ac-
tual task success score that can be predicted by
the model. All results reported here are produced
from 10-fold cross-validated 90% training / 10% test
Task 1 Task 2
ALL Features 0.17 0.14
ALL w/o SYNREP 0.15 0.06
ALL w/o LEX/CHARREP 0.09 0.07
LENGTH ONLY 0.09 n/a
Baseline 0.01 0.01
Table 1: Portion of variance explained (r2)
splits of the dialogues. No full dialogue was in-
cluded in both test and training sets.
Task 1 was evaluated with all data, the Task 2
model was trained and tested on data points sampled
from the first 5 minutes of the dialogue.
For Task 1 (full dialogues), the results (Table 1)
indicate that ALL repetition features together with
the LENGTH of the conversation, account for about
17% of the total score variance. The repetition fea-
tures improve on the performance achieved from di-
alogue length alone (about 9%).
For the more difficult Task 2, ALL features to-
gether achieve 14% of the variance. (Note that
LENGTH is not available.) When the syntactic repe-
tition feature is taken out and only lexical (LEXREP)
and character repetition (CHARREP) are used, we
achieve 6% in explained variance.
The baseline is implemented as a model that al-
ways estimates the mean score. It should, theoreti-
cally, be close to 0.
3.4 Discussion
Obviously, linguistic information alone will not ex-
plain the majority of the task-solving abilities. Apart
from subject-related factors, communicative strate-
gies will play a role.
However, linguistic repetition serves as a good
predictor of how well interlocutors will complete
their joint task. The features used are relatively sim-
ple: provided there is some syntactic annotation,
rule repetition can easily be detected. Even with-
out syntactic information, lexical repetition already
goes a long way.
But what kind of repetition is it that plays a role in
task-oriented dialogue? Leaving out features is not
an ideal method to quantify their influence?in par-
ticular, where features inter-correlate. The contribu-
tion of syntactic repetition is still unclear from the
811
present results: it acts as a useful predictor only over
the course of the whole dialogues, but not within a
5-minute time span, where the SVM cannot incor-
porate its informational content.
We will therefore turn to a more detailed analysis
of structural repetition, which should help us draw
conclusions relating to the psycholinguistics of dia-
logue.
4 Long term and short term priming
In the following, we will examine syntactic (struc-
tural) priming as one of the driving forces behind
alignment. We choose syntactic over lexical priming
for two reasons. Lexical repetition due to priming is
difficult to distinguish from repetition that is due to
interlocutors attending to a particular topic of con-
versation, which, in coherent dialogue, means that
topics are clustered. Lexical choice reflects those
topics, hence we expect clusters of particular termi-
nology. Secondly: the maps used to collect the dia-
logues in the Map Task corpus contained landmarks
with labels. It is only natural (even if by means
to cross-modal priming) that speakers will identify
landmarks using the labels and show little variability
in lexical choice. We will measure repetition of syn-
tactic rules, whereby word-by-word repetition (topi-
cality effects, parroting) is explicitly excluded.
For syntactic priming1, two repetition effects
have been identified. Classical priming effects are
strong: around 10% for syntactic rules (Reitter et al,
2006b). However, they decay quickly (Branigan
et al, 1999) and reach a low plateau after a few sec-
onds, which likens to the effect to semantic (similar-
ity) priming. What complicates matters is that there
is also a different, long-term adaptation effect that is
also commonly called (repetition) priming.
Adaptation has been shown to last longer, from
minutes (Bock and Griffin, 2000) to several days.
Lexical boost interactions, where the lexical rep-
etition of material within the repeated structure
strengthens structural priming, have been observed
for short-term priming, but not for long-term prim-
ing trials where material intervened between prime
and target utterances (Konopka and Bock, 2005).
Thus, short- and long-term adaptation effects may
1in production and comprehension, which we will not dis-
tinguish further for space reasons. Our data are (off-line) pro-
duction data.
well be due to separate cognitive processes, as re-
cently argued by (Ferreira and Bock, 2006). Section
5 deals with decay-based short-term priming, Sec-
tion 6 with long-term adaptation.
Pickering and Garrod (2004) do not make the type
of priming supporting alignment explicit. Should
we find differences in the way task success interacts
with different kinds of repetition effects, then this
would be a good indication about what effect sup-
ports IAM. More concretely, we could say whether
alignment is due to the automatic, classical priming
effect, or whether it is based on a long-term effect
that is possibly closer to implicit learning (Chang
et al, 2006).
5 Short-term priming
In this section, we attempt to detect differences in
the strength of short-term priming in successful and
less successful dialogues. To do so, we use the mea-
sure of priming strength established by Reitter et al
(2006b), which then allows us to test whether prim-
ing interacts with task success. Under the assump-
tions of IAM we would expect successful dialogues
to show more priming than unsuccessful ones.
Obviously, difficulties with the task at hand may
be due to a range of problems that the subjects may
have, linguistic and otherwise. But given that the di-
alogues contain variable levels of syntactic priming,
one would expect that this has at least some influ-
ence on the outcome of the task.
5.1 Method: Logistic Regression
We used mixed-effects regression models that pre-
dict a binary outcome (repetition) using a number of
discrete and continuous factors.2
As a first step, our modeling effort tries to estab-
lish a priming effect. To do so, we can make use
of the fact that the priming effect decays over time.
How strong that decay is gives us an indication of
how much repetition probability we see shortly after
the stimulus (prime) compared to the probability of
chance repetition?without ever explicitly calculating
such a prior.
Thus we define the strength of priming as the de-
cay rate of repetition probability, from shortly after
2We use Generalized Linear Mixed Effects models fitted us-
ing GlmmPQL in the MASS R library.
812
the prime to 15 seconds afterward (predictor: DIST).
Thus, we take several samples at varying distances
(d), looking at cases of structural repetition, and
cases where structure has not been repeated.
In the syntactic context, syntactic rules such as VP
? VP PP reflect syntactic decisions. Priming of a
syntactic construction shows up in the tendency to
repeat such rules in different lexical contexts. Thus,
we examine whether syntactic rules have been re-
peated at a distance d. For each syntactic rule that
occurs at time t1, we check a one-second time pe-
riod [t1 ? d ? 0.5, t1 ? d + 0.5] for an occurrence
of the same rule, which would constitute a prime.
Thus, the model will be able to implicitly estimate
the probability of repetition.
Generalized Linear Regression Models (GLMs)
can then model the decay by estimating the rela-
tionship between d and the probability of rule repe-
tition. The model is designed to predict whether rep-
etition will occur, or, more precisely, whether there
is a prime for a given target (priming). Under a no-
priming null-hypothesis, we would assume that the
priming probability is independent of d. If there is
priming, however, increasing d will negatively influ-
ence the priming probability (decay). So, we expect
a model parameter (DIST) for d that is reliably neg-
ative, and lower, if there is more priming.
With this method, we draw multiple samples from
the same utterance?for different d, but also for dif-
ferent syntactic rules occurring in those utterances.
Because these samples are inter-dependent, we use
a grouping variable indicating the source utterance.
Because the dataset is sparse with respect to PRIME,
balanced sampling is needed to ensure an equal
number of data points of priming and non-priming
cases (PRIME) is included.
This method has been previously used to confirm
priming effects for the general case of syntactic rules
by Reitter et al (2006b). Additionally, the GLM can
take into account categorical and continuous covari-
ates that may interact with the priming effect. In
the present experiment, we use an interaction term
to model the effect of task success.3 The crucial in-
teraction, in our case, is task success: PATHDEV is
the deviation of the paths that the interlocutors drew,
3We use the A?B operator in the model formulas to indicate
the inclusion of main effects of the features A and B and their
interactions A : B.
normalized to the range [0,1]. The core model is
thus PRIME ? log(DIST) ? PATHDEV.
If IAM is correct, we would expect that the devia-
tion of paths, which indicates negative task success,
will negatively correlate with the priming effect.
5.2 Results
Short-term priming reliably correlated (negatively)
with the distance, hence we see a decay and priming
effect (DIST, b = ?0.151, p < 0.0001, as shown in
previous work).
Notably, path deviation and short-term priming
did not correlate. The model showed was no such
interaction (DIST:PATHDEV, p = 0.91).
We also tested for an interaction with an ad-
ditional factor indicating whether prime and tar-
get were uttered by the same or a different
speaker (comprehension-production vs. production-
production priming). No such interaction ap-
proached reliability (log(DIST):PATHDEV:ROLE,
p = 0.60).
We also tested whether priming changes over time
over the course of each dialogue. It does not. There
were no reliable interaction effects of centered
prime/target times (log(DIST):log(STARTTIME),
p = 0.75, log(DIST):PATHDEV:log(STARTTIME),
p = 0.63). Reducing the model by removing
unreliable interactions did not yield any reliable
effects.
5.3 Discussion
We have shown that while there is a clear priming
effect in the short term, the size of this priming effect
does not correlate with task success. There is no
reliable interaction with success.
Does this indicate that there is no strong func-
tional component to priming in the dialogue con-
text? There may still be an influence of cognitive
load due to speakers working on the task, or an over-
all disposition for higher priming in task-oriented di-
alogue: Reitter et al (2006b) point at stronger prim-
ing in such situations. But our results here are diffi-
cult to reconcile with the model suggested by Picker-
ing and Garrod (2004), if we take short-term priming
as the driving force behind IAM.
Short-term priming decays within a few seconds.
Thus, to what extent could syntactic priming help in-
terlocutors align their situation models? In the Map
813
Task experiments, interlocutors need to refer to land-
marks regularly?but not every few seconds. It would
be sensible to expect longer-term adaptation (within
minutes) to drive dialogue success.
6 Long-term adapation
Long-term adaptation is a form of priming that
occurs over minutes and could, therefore, support
linguistic and situation model alignment in task-
oriented dialogue. IAM and the success of the
SVM based method could be based on such an ef-
fect instead of short-term priming. Analogous to the
the previous experiment, we hypothesize that more
adaptation relates to more task success.
6.1 Method
After the initial few seconds, structural repetition
shows little decay, but can be demonstrated even
minutes or longer after the stimulus. To measure this
type of adapation, we need a different strategy to es-
timate the size of this effect.
While short-term priming can be pin-pointed us-
ing the characteristic decay, for long-term priming
we need to inspect whole dialogues and construct
and contrast dialogues where priming is possible and
ones where it is not. Factor SAMEDOC distinguishes
the two situations: 1) Priming can happen in con-
tiguous dialogues. We treat the first half of the dia-
logue as priming period, and the rule instances in the
second half as targets. 2) The control case is when
priming cannot have taken place, i.e., between unre-
lated dialogues. Prime period and targets stem from
separate randomly sampled dialogue halves that al-
ways come from different dialogues.
Thus, our model (PRIME ? SAMEDOC ?
PATHDEV) estimates the influence of priming on
rule us. From a Bayesian perspective, we would
say that the second kind of data (non-priming) al-
low the model to estimate a prior for rule repetitions.
The goal is now to establish a correlation between
SAMEDOC and the existence of repetition. If and
only if there is long-term adapation would we ex-
pect such a correlation.
Analogous to the short-term priming model, we
define repetition as the occurrence of a prime within
the first document half (PRIME), and sample rule in-
stances from the second document half. To exclude
?
?
?
?
?
?
?
?
? ?
?
?
0.0 0.5 1.0
0.8
2
0.8
4
0.8
6
0.8
8
0.9
0
0.9
2
log path deviation (inverse success)
rela
tive
 re
pet
itio
n (
log
?o
dds
)
more less
success
l
e
s
s
m
o
r
e
s
y
n
.
 
a
d
a
p
t
a
t
i
o
n
Figure 1: Relative rule repetition probability
(chance repetition exluded) over (neg.) task success.
short-term priming effects, we drop a 10-second por-
tion in the middle of the dialogues.
Task success is inverse path deviation PATHDEV
as before, which should, under IAM assumptions,
interact with the effect estimated for SAMEDOC.
6.2 Results
Long-term repetition showed a positive priming ef-
fect (SAMEDOC, b = 3.303, p < 0.0001). This
generalizes previous experimental priming results in
long-term priming.
Long-term-repetition did not inter-
act with (normalized) rule frequency
(SAMEDOC:log(RULEFREQ, b = ?0.044, p =
0.35). The interaction was removed for all other
parameters reported.4
The effect interacted reliably with the path
deviation scores (SAMEDOC:PATHDEV, b =
?0.624, p < 0.05). We find a reliable correlation
of task success and syntactic priming. Stronger path
deviations relate to weaker priming.
6.3 Discussion
The more priming we see, the better subjects per-
form at synchronizing their routes on the maps. This
is exactly what one would expect under the assump-
4Such an interaction also could not be found in a reduced
model with only SAMEDOC and RULEFREQ.
814
tion of IAM. Also, there is no evidence for stronger
long-term adaptation of rare rules, which may point
out a qualitative difference to short-term priming.
Of course, this correlation does not necessarily in-
dicate a causal relationship. However, participants
in Map Task did not receive an explicit indication
about whether they were on the ?right track?. Mis-
takes, such as passing a landmark on its East and
not on the West side, were made and went unno-
ticed. Thus, it is not very likely that task success
caused alignment to improve at large. We suspect
such a possibility, however, for very unsuccessful
dialogues. A closer look at the correlation (Figure
1) reveals that while adaptation indeed decreases as
task success decreases, adaptation increased again
for some of the least successful dialogues. It is pos-
sible that here, miscoordination became apparent to
the participants, who then tried to switch strategies.
Or, simply put: too much alignment (and too little
risk-taking) is unhelpful. Further, qualitative, work
needs to be done to investigate this hypothesis.
From an applied perspective, the correlation
shows that of the repetition effects included in our
task-success prediction model, it is long-term syn-
tactic adaptation as opposed to the more automatic
short-term priming effect that contributes to predic-
tion accuracy. We take this as an indication to in-
clude adaptation rather than just priming in a model
of alignment in dialogue.
7 Conclusion
Task success in human-human dialogue is
predictable?the more successfully speakers collab-
orate, the more they show linguistic adaptation.
This confirms our initial hypothesis of IAM. In the
applied model, knowledge of lexical and syntactic
repetition helps to determine task success even after
just a few minutes of the conversation.
We suggested two application-oriented tasks (es-
timating and predicting task success) and an ap-
proach to address them. They now provide an op-
portunity to explore and exploit other linguistic and
extra-linguistic parameters.
The second contribution is a closer inspection of
structural repetition, which showed that it is long-
term adaptation that varies with task success, while
short-term priming appears largely autonomous.
Long-term adaptation may thus be a strategy that
aids dialogue partners in aligning their language and
their situation models.
Acknowledgments
The authors would like to thank Frank Keller and the reviewers.
The first author is supported by the Edinburgh-Stanford Link.
References
A. Anderson, M. Bader, E. Bard, E. Boyle, G. M. Doherty,
S. Garrod, S. Isard, J. Kowtko, J. McAllister, J. Miller,
C. Sotillo, H. Thompson, and R. Weinert. 1991. The HCRC
Map Task corpus. Language and Speech, 34(4):351?366.
J. Kathryn Bock. 1986. Syntactic persistence in language pro-
duction. Cognitive Psychology, 18:355?387.
J. Kathryn Bock and Zenzi Griffin. 2000. The persistence of
structural priming: transient activation or implicit learning?
J of Experimental Psychology: General, 129:177?192.
H. P. Branigan, M. J. Pickering, and A. A. Cleland. 1999. Syn-
tactic priming in language production: evidence for rapid
decay. Psychonomic Bulletin and Review, 6(4):635?640.
F. Chang, G. Dell, and K. Bock. 2006. Becoming syntactic.
Psychological Review, 113(2):234?272.
Kenneth W. Church. 2000. Empirial estimates of adaptation:
The chance of two noriegas is closer to p/2 than p2. In
Coling-2000, Saarbru?cken, Germany.
A. Dubey, F. Keller, and P. Sturt. 2005. Parallelism in coordi-
nation as an instance of syntactic priming: Evidence from
corpus-based modeling. In Proc. HLT/EMNLP-2005, pp.
827?834. Vancouver, Canada.
Vic Ferreira and Kathryn Bock. 2006. The functions of struc-
tural priming. Language and Cognitive Processes, 21(7-8).
Stefan Th. Gries. 2005. Syntactic priming: A corpus-based ap-
proach. J of Psycholinguistic Research, 34(4):365?399.
T. Florian Ja?ger. 2006. Redundancy and Syntactic Reduction in
Spontaneous Speech. Ph.D. thesis, Stanford University.
Agnieszka Konopka and J. Kathryn Bock. 2005. Helping syntax
out: What do words do? In Proc. 18th CUNY. Tucson, AZ.
Martin J. Pickering and Holly P. Branigan. 1998. The represen-
tation of verbs: Evidence from syntactic priming in language
production. Journal of Memory and Language, 39:633?651.
Martin J. Pickering and Simon Garrod. 2004. Toward a mech-
anistic psychology of dialogue. Behavioral and Brain Sci-
ences, 27:169?225.
D. Reitter, J. Hockenmaier, and F. Keller. 2006a. Prim-
ing effects in Combinatory Categorial Grammar. In Proc.
EMNLP-2006, pp.308?316. Sydney, Australia.
D. Reitter, J. D. Moore, and F. Keller. 2006b. Priming of syn-
tactic rules in task-oriented dialogue and spontaneous con-
versation. In Proc. CogSci-2006, pp. 685?690. Vancouver,
Canada.
Benedikt Szmrecsanyi. 2005. Creatures of habit: A corpus-
linguistic analysis of persistence in spoken english. Corpus
Linguistics and Linguistic Theory, 1(1):113?149.
M. Walker, I. Langkilde, J. Wright, A. Gorin, and D. Litman.
2000. Learning to predict problematic situations in a spoken
dialogue system: experiments with How may I help you? In
Proc. NAACL-2000, pp. 210?217. San Francisco, CA.
815
Proceedings of the Workshop on Task-Focused Summarization and Question Answering, pages 1?7,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Dimensionality Reduction Aids Term Co-Occurrence Based
Multi-Document Summarization
Ben Hachey, Gabriel Murray & David Reitter
School of Informatics
University of Edinburgh
2 Buccleuch Place, Edinburgh EH8 9LW
bhachey@inf.ed.ac.uk, gabriel.murray@ed.ac.uk, dreitter@inf.ed.ac.uk
Abstract
A key task in an extraction system for
query-oriented multi-document summari-
sation, necessary for computing relevance
and redundancy, is modelling text seman-
tics. In the Embra system, we use a repre-
sentation derived from the singular value
decomposition of a term co-occurrence
matrix. We present methods to show the
reliability of performance improvements.
We find that Embra performs better with
dimensionality reduction.
1 Introduction
We present experiments on the task of query-
oriented multi-document summarisation as ex-
plored in the DUC 2005 and DUC 2006 shared
tasks, which aim to model real-world complex
question-answering. Input consists of a detailed
query1 and a set of 25 to 50 relevant docu-
ments. We implement an extractive approach
where pieces of the original texts are selected to
form a summary and then smoothing is performed
to create a discursively coherent summary text.
The key modelling task in the extraction phase
of such a system consists of estimating responsive-
ness to the query and avoiding redundancy. Both
of these are often approached through some tex-
tual measure of semantic similarity. In the Embra2
system, we follow this approach in a sentence ex-
traction framework. However, we model the se-
mantics of a sentence using a very large distri-
butional semantics (i.e. term co-occurrence) space
reduced by singular value decomposition. Our hy-
1On average, queries contain approximately 34 words
words and three sentences.
2Edinburgh Multi-document Breviloquence Assay
pothesis is that this dimensionality reduction us-
ing a large corpus can outperform a simple term
co-occurrence model.
A number of papers in the literature look at sin-
gular value decomposition and compare it to unre-
duced term ? document or term co-occurrence
matrix representations. These explore varied tasks
and obtain mixed results. For example, Peder-
sen et al (2005) find that SVD does not improve
performance in a name discrimination task while
Matveeva et al (2005) and Rohde et al (In prep)
find that dimensionality reduction with SVD does
help on word similarity tasks.
The experiments contained herein investigate
the contribution of singular value decomposition
on the query-oriented multi-document summarisa-
tion task. We compare the singular value decom-
position of a term co-occurrence matrix derived
from a corpus of approximately 100 million words
(DS+SVD) to an unreduced version of the matrix
(DS). These representations are described in Sec-
tion 2. Next, Section 3 contains a discussion of
related work using SVD for summarisation and a
description of the sentence selection component in
the Embra system. The paper goes on to give an
overview of the experimental design and results in
Section 4. This includes a detailed analysis of the
statistical significance of the results.
2 Representing Sentence Semantics
The following three subsections discuss various
ways of representing sentence meaning for infor-
mation extraction purposes. While the first ap-
proach relies solely on weighted term frequencies
in a vector space, the subsequent methods attempt
to use term context information to better represent
the meanings of sentences.
1
2.1 Terms and Term Weighting (TF.IDF)
The traditional model for measuring semantic sim-
ilarity in information retrieval and text mining is
based on a vector representation of the distribution
of terms in documents. Within the vector space
model, each term is assigned a weight which sig-
nifies the semantic importance of the term. Often,
tf.idf is used for this weight, which is a scheme
that combines the importance of a term within the
current document3 and the distribution of the term
across the text collection. The former is often
represented by the term frequency and the latter
by the inverse document frequency (idfi = Ndfi ),
where N is the number of documents and dfi is
the number of documents containing term ti.
2.2 Term Co-occurrence (DS)
Another approach eschews the traditional vector
space model in favour of the distributional seman-
tics approach. The DS model is based on the in-
tuition that two words are semantically similar if
they appear in a similar set of contexts. We can
obtain a representation of a document?s semantics
by averaging the context vectors of the document
terms. (See Besanc?on et al (1999), where the DS
model is contrasted with a term ? document vec-
tor space representation.)
2.3 Singular Value Decomposition
(DS+SVD)
Our third approach uses dimensionality reduction.
Singular value decomposition is a technique for
dimensionality reduction that has been used ex-
tensively for the analysis of lexical semantics un-
der the name of latent semantic analysis (Landauer
et al, 1998). Here, a rectangular (e.g., term ?
document) matrix is decomposed into the product
of three matrices (Xw?p = Ww?nSn?n(Pp?n)T )
with n ?latent semantic? dimensions. W and P
represent terms and documents in the new space.
And S is a diagonal matrix of singular values in
decreasing order.
Taking the product Ww?kSk?k(Pp?k)T over
the first k columns gives the best least square ap-
proximation of the original matrix X by a matrix
of rank k, i.e. a reduction of the original matrix to
k dimensions. Similarity between documents can
then be computed in the space obtained by taking
the rank k product of S and P .
3The local importance of a term can also be computed
over other textual units, e.g. sentence in extractive summari-
sation or the context of an entity pair in relation discovery.
This decomposition abstracts away from terms
and can be used to model a semantic similarity
that is more linguistic in nature. Furthermore, it
has been successfully used to model human intu-
itions about meaning. For example, Landauer et
al. (1998) show that latent semantic analysis cor-
relates well with human judgements of word sim-
ilarity and Foltz (1998) shows that it is a good es-
timator for textual coherence.
It is hoped that these latter two techniques (di-
mensionality reduction and the DS model) will
provide for a more robust representation of term
contexts and therefore better representation of sen-
tence meaning, enabling us to achieve more reli-
able sentence similarity measurements for extrac-
tive summarisation.
3 SVD in Summarisation
This section describes ways in which SVD has
been used for summarisation and details the im-
plementation in the Embra system.
3.1 Related Work
In seminal work by Gong and Liu (2001), the au-
thors proposed that the rows of P T may be re-
garded as defining topics, with the columns rep-
resenting sentences from the document. In their
SVD method, summarisation proceeds by choos-
ing, for each row in P T , the sentence with the
highest value. This process continues until the de-
sired summary length is reached.
Steinberger and Jez?ek (2004) have offered two
criticisms of the Gong and Liu approach. Firstly,
the method described above ties the dimension-
ality reduction to the desired summary length.
Secondly, a sentence may score highly but never
?win? in any dimension, and thus will not be ex-
tracted despite being a good candidate. Their solu-
tion is to assign each sentence an SVD-based score
using:
ScSV Di =
?
?
?
?
n?
i=1
v(i, k)2 ? ?(k)2 ,
where v(i, k) is the kth element of the ith sen-
tence vector and ?(k) is the corresponding singu-
lar value.
Murray et al (2005a) address the same concerns
but retain the Gong and Liu framework. Rather
than extracting the best sentence for each topic,
the n best sentences are extracted, with n deter-
mined by the corresponding singular values from
2
matrix S. Thus, dimensionality reduction is no
longer tied to summary length and more than one
sentence per topic can be chosen.
A similar approach in DUC 2005 using term
co-occurrence models and SVD was presented by
Jagarlamudi et al (2005). Their system performs
SVD over a term ? sentence matrix and combines
a relevance measurement based on this representa-
tion with relevance based on a term co-occurrence
model by a weighted linear combination.
3.2 Sentence Selection in Embra
The Embra system developed for DUC 2005 at-
tempts to derive more robust representations of
sentences by building a large semantic space us-
ing SVD on a very large corpus. While researchers
have used such large semantic spaces to aid in au-
tomatically judging the coherence of documents
(Foltz et al, 1998; Barzilay and Lapata, 2005), to
our knowledge this is a novel technique in sum-
marisation.
Using a concatenation of Aquaint and DUC
2005 data (100+ million words), we utilised the
Infomap tool4 to build a semantic model based on
singular value decomposition (SVD). The decom-
position and projection of the matrix to a lower-
dimensionality space results in a semantic model
based on underlying term relations. In the current
experiments, we set dimension of the reduced rep-
resentation to 100. This is a reduction of 90% from
the full dimensionality of 1000 content-bearing
terms in the original DS matrix. This was found
to perform better than 25, 50, 250 and 500 dur-
ing parameter optimisation. A given sentence is
represented as a vector which is the average of its
constituent word vectors. This sentence represen-
tation is then fed into an MMR-style algorithm.
MMR (Maximal Marginal Relevance) is a com-
mon approach for determining relevance and re-
dundancy in multi-document summarisation, in
which candidate sentences are represented as
weighted term-frequency vectors which can thus
be compared to query vectors to gauge similarity
and already-extracted sentence vectors to gauge
redundancy, via the cosine of the vector pairs
(Carbonell and Goldstein, 1998). While this has
proved successful to a degree, the sentences are
represented merely according to weighted term
frequency in the document, and so two similar sen-
tences stand a chance of not being considered sim-
4http://infomap.stanford.edu/
for each sentence in document:
for each word in sentence:
get word vector from semantic model
average word vectors to form sentence vector
sim1 = cossim(sentence vector, query vector)
sim2 = highest(cossim(sentence vector, all extracted vectors))
score = ?*sim1 - (1-?)*sim2
extract sentence with highest score
repeat until desired length
Figure 1: Sentence extraction algorithm
ilar if they do not share the same terms.
Our implementation of MMR (Figure 1) uses ?
annealing following (Murray et al, 2005a). ? de-
creases as the summary length increases, thereby
emphasising relevance at the outset but increas-
ingly prioritising redundancy removal as the pro-
cess continues.
4 Experiment
The experimental setup uses the DUC 2005 data
(Dang, 2005) and the Rouge evaluation met-
ric to explore the hypothesis that query-oriented
multi-document summarisation using a term co-
occurrence representation can be improved using
SVD. We frame the research question as follows:
Does SVD dimensionality reduction
lead to an increase in Rouge score com-
pared to the DS representation?
4.1 Materials
The DUC 2005 task5 was motivated by Amigo et
al.?s (2004) suggestion of evaluations that model
real-world complex question answering. The goal
is to synthesise a well-organised, fluent answer of
no more than 250 words to a complex question
from a set of 25 to 50 relevant documents. The
data includes a detailed query, a document set, and
at least 4 human summaries for each of 50 topics.
The preprocessing was largely based on LT TTT
and LT XML tools (Grover et al, 2000; Thomp-
son et al, 1997). First, we perform tokenisation
and sentence identification. This is followed by
lemmatisation.
At the core of preprocessing is the LT TTT
program fsgmatch, a general purpose transducer
which processes an input stream and adds annota-
tions using rules provided in a hand-written gram-
mar file. We also use the statistical combined part-
of-speech (POS) tagger and sentence boundary
disambiguation module from LT TTT (Mikheev,
5http://www-nlpir.nist.gov/projects/
duc/duc2005/tasks.html
3
1997). Using these tools, we produce an XML
markup with sentence and word elements. Further
linguistic markup is added using the morpha lem-
matiser (Minnen et al, 2000) and the C&C named
entity tagger (Curran and Clark, 2003) trained on
the data from MUC-7.
4.2 Methods
The different system configurations (DS,
DS+SVD, TF.IDF) were evaluated against
the human upper bound and a baseline using
Rouge-2 and Rouge-SU4. Rouge estimates the
coverage of appropriate concepts (Lin and Hovy,
2003) in a summary by comparing it several
human-created reference summaries. Rouge-2
does so by computing precision and recall based
on macro-averaged bigram overlap. Rouge-SU4
allows bigrams to be composed of non-contiguous
words, with as many as four words intervening.
We use the same configuration as the official DUC
2005 evaluation,6 which is based on word stems
(rather than full forms) and uses jackknifing (k?1
cross-evaluation) so that human gold-standard and
automatic system summaries can be compared.
The independent variable in the experiment is
the model of sentence semantics used by the sen-
tence selection algorithm. We are primarily inter-
ested in the relative performance of the DS and
DS+SVD representations. As well as this, we
include the DUC 2005 baseline, which is a lead
summary created by taking the first 250 words of
the most recent document for each topic. We also
include a tf.idf -weighted term ? sentence repre-
sentation (TF.IDF) for comparison with a conven-
tional MMR approach.7 Finally, we include an up-
per bound calculated using the DUC 2005 human
reference summaries. Preprocessing and all other
aspects of the sentence selection algorithm remain
constant over all systems.
In general, Rouge shows a large variance across
data sets (and so does system performance). It is
important to test whether obtained nominal differ-
ences are due to chance or are actually statistically
significant.
To test whether the Rouge metric showed a re-
liably different performance for the systems, the
6i.e. ROUGE-1.5.5.pl -n 2 -x -m -2 4 -u
-c 95 -r 1000 -f A -p 0.5 -t 0 d
7Specifically, we use tfi,j ? log( Ndfi ) for term weighting
where tfi,j is the number of times term i occurs in sentence
j, N is the number of sentences, and dfi is the number of
sentences containing term i.
p Metric hypothesis
0.000262 Rouge-2 base<TF.IDF ***
0.021640 Rouge-2 base<DS *
0.000508 Rouge-2 base<DS+SVD ***
0.014845 Rouge-2 DS<TF.IDF *
0.507702 Rouge-2 TF.IDF<DS+SVD
0.047016 Rouge-2 DS<DS+SVD *
0.000080 Rouge-SU4 base<TF.IDF ***
0.006803 Rouge-SU4 base<DS **
0.000006 Rouge-SU4 base<DS+SVD ***
0.012815 Rouge-SU4 DS<TF.IDF *
0.320083 Rouge-SU4 TF.IDF<DS+SVD
0.001053 Rouge-SU4 DS<DS+SVD **
Table 1: Holm-corrected Wilcoxon hypothesis test
results.
Friedman rank sum test (Friedman, 1940; Dems?ar,
2006) can be used. This is a hypothesis test not
unlike an ANOVA, however, it is non-parametric,
i.e. it does not assume a normal distribution of
the measures (i.e. precision, recall and F-score).
More importantly, it does not require homogene-
ity of variances.
To (partially) rank the systems against each
other, we used a cascade of Wilcoxon signed ranks
tests. These tests are again non-parametric (as they
rank the differences between the system results for
the datasets). As discussed by Dems?ar (2006), we
used Holm?s procedure for multiple tests to correct
our error estimates (p).
4.3 Results
Friedman tests for each Rouge metric (with
F-score, precision and recall included as ob-
servations, with the dataset as group) showed
a reliable effect of the system configuration
(?2F,SU4 = 106.6, ?2P,SU4 = 96.1,
?2R,SU4 = 105.5, all p < 0.00001).
Post-hoc analysis (Wilcoxon) showed (see Ta-
ble 1) that all three systems performed reliably
better than the baseline. TF.IDF performed bet-
ter than simple DS in Rouge-2 and Rouge-SU4.
DS+SVD performed better than DS (p2 < 0.05,
pSU4 < 0.005). There is no evidence to support
a claim that DS+SVD performed differently from
TF.IDF.
However, when we specifically compared the
performance of TF.IDF and DS+SVD with the
Rouge-SU4 F score for only the specific (as
opposed to general) summaries, we found that
DS+SVD scored reliably, but only slightly better
4
baseline
TF.IDF MMR
DS MMR
DS+SVD MMR
Human
Mean Rouge F?Scores          
0.00 0.05 0.10 0.15
Figure 2: Mean system performance over 50
datasets (F-scores). Precision and Recall look
qualitatively similar.
(Wilcoxon, p<0.05). This result is unadjusted,
and post-hoc comparisons with other scores or for
the general summaries did not show reliable dif-
ferences.
Having established the reliable performance im-
provement of DS+SVD over DS, it it important
to take the effect size into consideration (with
enough data, small effects may be statistically sig-
nificant, but practically unimportant). Figure 2 il-
lustrates that the gain in mean performance is sub-
stantial. If the mean Rouge-SU4 score for human
performance is seen as upper bound, the DS+SVD
system showed a 25.4 percent reduction in error
compared to the DS system.8
A similar analysis for precision and recall gives
qualitatively comparable results.
5 Discussion and Future Work
The positive message from the experimental re-
sults is that SVD dimensionality reduction im-
proves performance over a term co-occurrence
model for computing relevance and redundancy in
a MMR framework. We note that we cannot con-
clude that the DS or DS+SVD systems outper-
form a conventional tf.idf -weighted term ? sen-
tence representation on this task. However, results
from Jagarlamudi et al (2005) suggest that the DS
and term ? sentence representations may be com-
plementary in which case we would expect a fur-
ther improvement through an ensemble technique.
Previous results comparing SVD with unre-
duced representations show mixed results. For
example, Pedersen et al (2005) experiment with
term co-occurrence representations with and with-
out SVD on a name discrimination task and find
8Pairwise effect size estimates over datasets aren?t sensi-
ble. Averaging of differences between pairs was affected by
outliers, presumably caused by Rouge?s error distribution.
that the unreduced representation tends to perform
better. Rohde et al (In prep), on the other hand,
find that a reduced matrix does perform better on
word pair similarity and multiple-choice vocabu-
lary tests. One crucial factor here may be the size
of the corpus. SVD may not offer any reliable ?la-
tent semantic? advantage when the corpus is small,
in which case the efficiency gain from dimension-
ality reduction is less of a motivation anyway.
We plan to address the question of corpus size
in future work by comparing DS and DS+SVD
derived from corpora of varying size. We hypoth-
esise that the larger the corpus used to compile
the term co-occurrence information, the larger the
potential contribution from dimensionality reduc-
tion. This will be explored by running the experi-
ment described in this paper a number of times us-
ing corpora of different sizes (e.g. 0.5m, 1m, 10m
and 100m words).
Unlike official DUC evaluations, which rely on
human judgements of readability and informative-
ness, our experiments rely solely on Rouge n-
gram evaluation metrics. It has been shown in
DUC 2005 and in work by Murray et al (2005b;
2006) that Rouge does not always correlate well
with human evaluations, though there is more sta-
bility when examining the correlations of macro-
averaged scores. Rouge suffers from a lack of
power to discriminate between systems whose per-
formance is judged to differ by human annotators.
Thus, it is likely that future human evaluations
would be more informative. Another way that the
evaluation issue might be addressed is by using an
annotated sentence extraction corpus. This could
proceed by comparing gold standard alignments
between abstract and full document sentences with
predicted alignments using correlation analysis.
6 Conclusions
We have presented experiments with query-
oriented multi-document summarisation. The ex-
periments explore the question of whether SVD
dimensionality reduction offers any improvement
over a term co-occurrence representation for sen-
tence semantics for measuring relevance and re-
dundancy. While the experiments show that
our system does not outperform a term ? sen-
tence tf.idf system, we have shown that the SVD
reduced representation of a term co-occurrence
space built from a large corpora performs better
than the unreduced representation. This contra-
5
dicts related work where SVD did not provide
an improvement over unreduced representations
on the name discrimination task (Pedersen et al,
2005). However, it is compatible with other work
where SVD has been shown to help on the task
of estimating human notions of word similarity
(Matveeva et al, 2005; Rohde et al, In prep).
A detailed analysis using the Friedman test and
a cascade of Wilcoxon signed ranks tests suggest
that our results are statistically valid despite the
unreliability of the Rouge evaluation metric due to
its low variance across systems.
Acknowledgements
This work was supported in part by Scottish Enter-
prise Edinburgh-Stanford Link grant R36410 and,
as part of the EASIE project, grant R37588. It
was also supported in part by the European Union
6th FWP IST Integrated Project AMI (Augmented
Multiparty Interaction, FP6-506811, publication).
We would like to thank James Clarke for de-
tailed comments and discussion. We would also
like to thank the anonymous reviewers for their
comments.
References
Enrique Amigo, Julio Gonzalo, Victor Peinado,
Anselmo Penas, and Felisa Verdejo. 2004. An
empirical study of information synthesis tasks. In
Proceedings of the 42nd Annual Meeting of the As-
sociation for Computational Linguistics, Barcelona,
Spain.
Regina Barzilay and Mirella Lapata. 2005. Modeling
local coherence: an entity-based approach. In Pro-
ceedings of the 43rd Annual Meeting of the Associa-
tion for Computational Linguistics, Ann Arbor, MI,
USA.
Romaric Besanc?on, Martin Rajman, and Jean-Ce?dric
Chappelier. 1999. Textual similarities based on
a distributional approach. In Proceedings of the
10th International Workshop on Database And Ex-
pert Systems Applications, Firenze, Italy.
Jaime G. Carbonell and Jade Goldstein. 1998. The
use of mmr, diversity-based reranking for reordering
documents and producing summaries. In Proceed-
ings of the 21st Annual International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, Melbourne, Australia.
James R. Curran and Stephen Clark. 2003. Language
independent NER using a maximum entropy tag-
ger. In Proceedings of the 2003 Conference on Com-
putational Natural Language Learning, Edmonton,
Canada.
Hoa T. Dang. 2005. Overview of DUC 2005. In
Proceedings of the Document Understanding Con-
ference, Vancouver, B.C., Canada.
Janez Dems?ar. 2006. Statistical comparisons of clas-
sifiers over multiple data sets. Journal of Machine
Learning Research, 7:1?30, Jan.
Peter W. Foltz, Walter Kintsch, and Thomas K. Lan-
dauer. 1998. The measurement of textual coherence
with latent semantic analysis. Discourse Processes,
25.
Milton Friedman. 1940. A comparison of alternative
tests of significance for the problem of m rankings.
The Annals of Mathematical Statistics, 11:86?92.
Yihon Gong and Xin Liu. 2001. Generic text summa-
rization using relevance measure and latent semantic
analysis. In Proceedings of the 24th Annual Interna-
tional ACM SIGIR Conference on Research and De-
velopment in Information Retrieval, New Orleans,
LA, USA.
Claire Grover, Colin Matheson, Andrei Mikheev, and
Marc Moens. 2000. LT TTT?a flexible tokeni-
sation tool. In Proceedings of the 2nd International
Conference on Language Resources and Evaluation,
Athens, Greece.
Ben Hachey and Claire Grover. 2004. A rhetorical
status classifier for legal text summarisation. In
Proceedings of the ACL-2004 Text Summarization
Branches Out Workshop, Barcelona, Spain.
Jagadeesh Jagarlamudi, Prasad Pingali, and Vasudeva
Varma. 2005. A relevance-based language mod-
eling approach to DUC 2005. In Proceedings of
the Document Understanding Conference, Vancou-
ver, B.C., Canada.
Thomas K. Landauer, Peter W. Foltz, and Darrell La-
ham. 1998. Introduction to latent semantic analysis.
Discourse Processes, 25.
Chin-Yew Lin and Eduard H. Hovy. 2003. Au-
tomatic evaluation of summaries using n-gram
co-occurrence statistics. In Proceedings of the
Joint Human Language Technology Conference and
North American Chapter of the Association for
Computational Linguistics Annual Meeting, Edmon-
ton, Alberta, Canada.
Irina Matveeva, Gina-Anne Levow, Ayman Farahat,
and Christiaan Royer. 2005. Term represetation
with generalized latent semantic analysis. In Pro-
ceedings of the 2005 Conference on Recent Ad-
vances in Natural Language Processing, Borovets,
Bulgaria.
Andrei Mikheev. 1997. Automatic rule induction for
unknown word guessing. Computational Linguis-
tics, 23(3).
6
Guido Minnen, John Carroll, and Darren Pearce. 2000.
Robust, applied morphological generation. In Pro-
ceedings of the 1st International Natural Language
Generation Conference, Mitzpe Ramon, Israel.
Gabriel Murray, Steve Renals, and Jean Carletta.
2005a. Extractive summarization of meeting record-
ings. In Proceedings of the 9th European Con-
ference on Speech Communication and Technology,
Lisbon, Portugal.
Gabriel Murray, Steve Renals, Jean Carletta, and Jo-
hanna Moore. 2005b. Evaluating automatic sum-
maries of meeting recordings. In Proceedings of the
43rd Annual Meeting of the Association for Compu-
tational Linguistics, Ann Arbor, MI, USA.
Gabriel Murray, Steve Renals, Jean Carletta, and Jo-
hanna Moore. 2006. Incorporating speaker and
discourse features into speech summarization. In
Proceedings of the Joint Human Language Technol-
ogy Conference and North American Chapter of the
Association for Computational Linguistics Annual
Meeting, New York City, NY, USA.
Ted Pedersen, Amruta Purandare, and Anagha Kulka-
rni. 2005. Name discrimination by clustering simi-
lar contexts. In Proceedings of the 6th International
Conference on Intelligent Text Processing and Com-
putational Linguistics, Mexico City, Mexico.
Douglas L. T. Rohde, Laur M. Gonnerman, and
David C. Plaut. In prep. An improved
method for deriving word meaning from lexical
co-occurrence. http://dlt4.mit.edu/?dr/
COALS/Coals.pdf (1 May 2006).
Josef Steinberger and Karel Jez?ek. 2004. Using latent
semantic analysis in text summarization and sum-
mary evaluation. In Proceedings of the 5th Inter-
national Conference on Information Systems Imple-
mentation and Modelling, Ostrava, Czech Republic.
Henry Thompson, Richard Tobin, David McK-
elvie, and Chris Brew. 1997. LT XML:
Software API and toolkit for XML processing.
http://www.ltg.ed.ac.uk/software/.
7
Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 308?316,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Priming Effects in Combinatory Categorial Grammar
David Reitter
School of Informatics
University of Edinburgh
2 Buccleuch Place
Edinburgh EH8 9LW, UK
dreitter@inf.ed.ac.uk
Julia Hockenmaier
Inst. for Res. in Cognitive Science
University of Pennsylvania
3401 Walnut Street
Philadelphia PA 19104, USA
juliahr@cis.upenn.edu
Frank Keller
School of Informatics
University of Edinburgh
2 Buccleuch Place
Edinburgh EH8 9LW, UK
keller@inf.ed.ac.uk
Abstract
This paper presents a corpus-based ac-
count of structural priming in human sen-
tence processing, focusing on the role that
syntactic representations play in such an
account. We estimate the strength of struc-
tural priming effects from a corpus of
spontaneous spoken dialogue, annotated
syntactically with Combinatory Catego-
rial Grammar (CCG) derivations. This
methodology allows us to test a range of
predictions that CCG makes about prim-
ing. In particular, we present evidence
for priming between lexical and syntactic
categories encoding partially satisfied sub-
categorization frames, and we show that
priming effects exist both for incremental
and normal-form CCG derivations.
1 Introduction
In psycholinguistics, priming refers to the fact that
speakers prefer to reuse recently encountered lin-
guistic material. Priming effects typically man-
ifest themselves in shorter processing times or
higher usage frequencies for reused material com-
pared to non-reused material. These effects are at-
tested both in language comprehension and in lan-
guage production. Structural priming occurs when
a speaker repeats a syntactic decision, and has
been demonstrated in numerous experiments over
the past two decades (e.g., Bock, 1986; Branigan
et al, 2000). These experimental findings show
that subjects are more likely to choose, e.g., a
passive voice construction if they have previously
comprehended or produced such a construction.
Recent studies have used syntactically anno-
tated corpora to investigate structural priming.
The results have demonstrated the existence of
priming effects in corpus data: they occur for spe-
cific syntactic constructions (Gries, 2005; Szm-
recsanyi, 2005), consistent with the experimen-
tal literature, but also generalize to syntactic rules
across the board, which repeated more often than
expected by chance (Reitter et al, 2006b; Dubey
et al, 2006). In the present paper, we build on
this corpus-based approach to priming, but focus
on the role of the underlying syntactic represen-
tations. In particular, we use priming to evaluate
claims resulting from a particular syntactic theory,
which is a way of testing the representational as-
sumptions it makes.
Using priming effects to inform syntactic the-
ory is a novel idea; previous corpus-based priming
studies have simply worked with uncontroversial
classes of constructions (e.g., passive/active). The
contribution of this paper is to overcome this limi-
tation by defining a computational model of prim-
ing with a clear interface to a particular syntac-
tic framework. The general assumption we make
is that priming is a phenomenon relating to gram-
matical constituents ? these constituents determine
the syntactic choices whose repetition can lead to
priming. Crucially, grammatical frameworks dif-
fer in the grammatical constituents they assume,
and therefore predict different sets of priming ef-
fects.
We require the following ingredients to pursue
this approach: a syntactic theory that identifies
a set of constituents, a corpus of linguistic data
annotated according to that syntactic theory, and
a statistical model that estimates the strength of
priming based on a set of external factors. We can
then derive predictions for the influence of these
factors from the syntactic theory, and test them
using the statistical model. In this paper, we use
regression models to quantify structural priming
effects and to verify predictions made by Com-
binatory Categorial Grammar (CCG, Steedman
(2000)), a syntactic framework that has the theo-
retical potential to elegantly explain some of the
phenomena discovered in priming experiments.
308
CCG is distinguished from most other gram-
matical theories by the fact that its rules are
type-dependent, rather than structure-dependent
like classical transformations. Such rules adhere
strictly to the constituent condition on rules, i.e.,
they apply to and yield constituents. Moreover,
the syntactic types that determine the applicability
of rules in derivations are transparent to (i.e., are
determined, though not necessarily uniquely, by)
the semantic types that they are associated with.
As a consequence, syntactic types are more ex-
pressive and more numerous than standard parts of
speech: there are around 500 highly frequent CCG
types, against the standard 50 or so Penn Treebank
POS tags. As we will see below, these properties
allow CCG to discard a number of traditional as-
sumptions concerning surface constituency. They
also allow us to make a number of testable pre-
dictions concerning priming effects, most impor-
tantly (a) that priming effects are type-driven and
independent of derivation, and, as a corollary;
(b) that lexical and derived constituents of the
same type can prime each other. These effects are
not expected under more traditional views of prim-
ing as structure-dependent.
This paper is organized as follows: Section 2
explains the relationship between structural prim-
ing and CCG, which leads to a set of specific pre-
dictions, detailed in Section 3. Sections 4 and 5
present the methodology employed to test these
predictions, describing the corpus data and the sta-
tistical analysis used. Section 6 then presents the
results of three experiments that deal with priming
of lexical vs. phrasal categories, priming in incre-
mental vs. normal form derivations, and frequency
effects in priming. Section 7 provides a discussion
of the implications of these findings.
2 Background
2.1 Structural Priming
Previous studies of structural priming (Bock,
1986; Branigan et al, 2000) have made few the-
oretical assumptions about syntax, regardless of
whether the studies were based on planned exper-
iments or corpora. They leverage the fact that al-
ternations such as He gave Raquel the car keys vs.
He gave the car keys to Raquel are nearly equiva-
lent in semantics, but differ in their syntactic struc-
ture (double object vs. prepositional object). In
such experiments, subjects are first exposed to a
prime, i.e., they have to comprehend or produce
either the double object or the prepositional ob-
ject structure. In the subsequent trial, the target,
they are the free to produce or comprehend either
of the two structures, but they tend to prefer the
one that has been primed. In corpus studies, the
frequencies of the alternative constructions can be
compared in a similar fashion (Gries, 2005; Szm-
recsanyi, 2005).
Reitter et al (2006b) present a different method
to examine priming effects in the general case.
Rather than selecting specific syntactic alterna-
tions, general syntactic units are identified. This
method detects syntactic repetition in corpora and
correlates its probability with the distance between
prime and target, where at great distance, any rep-
etition can be attributed to chance. The size of
the priming effect is then estimated as the differ-
ence between the repetition probability close to
the prime and far away from the prime. This is
a way of factoring out chance repetition (which
is required if we do not deal with syntactic alter-
nations). By relying on syntactic units, the prim-
ing model includes implicit assumptions about the
particular syntactic framework used to annotate
the corpus under investigation.
2.2 Priming and Lexicalized Grammar
Previous work has demonstrated that priming ef-
fects on different linguistic levels are not indepen-
dent (Pickering and Branigan, 1998). Lexical rep-
etition makes repetition on the syntactic level more
likely. For instance, suppose we have two verbal
phrases (prime, target) produced only a few sec-
onds apart. Priming means that the target is more
likely to assume the same syntactic form (e.g., a
passive) as the prime. Furthermore, if the head
verbs in prime and target are identical, experi-
ments have demonstrated a stronger priming ef-
fect. This effect seems to indicate that lexical and
syntactic representations in the grammar share the
same information (e.g., subcategorization infor-
mation), and therefore these representations can
prime each other.
Consequently, we treat subcategorization as
coterminous with syntactic type, rather than as a
feature exclusively associated with lexemes. Such
types determine the context of a lexeme or phrase,
and are determined by derivation. Such an anal-
ysis is exactly what categorial grammars suggest.
The rich set of syntactic types that categories af-
ford may be just sufficient to describe all and only
309
the units that can show priming effects during
syntactic processing. That is to say that syntac-
tic priming is categorial type-priming, rather than
structural priming.
Consistent with this view, Pickering and Brani-
gan (1998) assume that morphosyntactic features
such as tense, aspect or number are represented in-
dependently from combinatorial properties which
specify the contextual requirements of a lexical
item. Property groups are represented centrally
and shared between lexicon entries, so that they
may ? separately ? prime each other. For ex-
ample, the pre-nominal adjective red in the red
book primes other pre-nominal adjectives, but not
a post-nominal relative clause (the book that?s red)
(Cleland and Pickering, 2003; Scheepers, 2003).
However, if a lexical item can prime a phrasal
constituent of the same type, and vice versa, then
a type-driven grammar formalism like CCG can
provide a simple account of the effect, because
lexical and derived syntactic types have the same
combinatory potential, which is completely spec-
ified by the type, whereas in structure-driven the-
ories, this information is only implicitly given in
the derivational process.
2.3 Combinatory Categorial Grammar
CCG (Steedman, 2000) is a mildly context-
sensitive, lexicalized grammar formalism with a
transparent syntax-semantics interface and a flex-
ible constituent structure that is of particular in-
terest to psycholinguistics, since it allows the con-
struction of incremental derivations. CCG has also
enjoyed the interest of the NLP community, with
high-accuracy wide-coverage parsers(Clark and
Curran, 2004; Hockenmaier and Steedman, 2002)
and generators1 available (White and Baldridge,
2003).
Words are associated with lexical categories
which specify their subcategorization behaviour,
eg. ((S[dcl]\NP)/NP)/NP is the lexical category
for (tensed) ditransitive verbs in English such as
gives or send, which expect two NP objects to
their right, and one NP subject to their left. Com-
plex categories X/Y or X\Y are functors which
yield a constituent with category X, if they are ap-
plied to a constituent with category Y to their right
(/Y) or to their left (\Y).
Constituents are combined via a small set of
combinatory rule schemata:
Forward Application: X/Y Y ?> X
1http://opennlp.sourceforge.net/
Backward Application: Y X\Y ?> X
Forward Composition: X/Y Y/Z ?B X/Z
Backward Composition: Y\Z X\Y ?B X\Z
Backw. Crossed Composition: Y/Z X\Y ?B X/Z
Forward Type-raising: X ?T T/(T\X)
Coordination: X conj X ?? X
Function application is the most basic operation
(and used by all variants of categorial grammar):
I saw the man
NP (S\NP)/NP NP
>
S\NP
<
S
Composition (B) and type-raising (T) are neces-
sary for the analysis of long-range dependencies
and for incremental derivations. CCG uses the
same lexical categories for long-range dependen-
cies that arise eg. in wh-movement or coordina-
tion as for local dependencies, and does not re-
quire traces:
the man that I saw
NP (NP\NP)/(S/NP) NP (S\NP)/NP
>T
S/(S\NP)
>B
S/NP
>
NP\NP
I saw and you heard the man
NP (S\NP)/NP conj NP (S\NP)/NP
>T >T
S/(S\NP) S/(S\NP)
>B >B
S/NP S/NP
<?>
S/NP
>
S
The combinatory rules of CCG allow multiple,
semantically equivalent, syntactic derivations of
the same sentence. This spurious ambiguity is
the result of CCG?s flexible constituent structure,
which can account for long-range dependencies
and coordination (as in the above example), and
also for interaction with information structure.
CCG parsers often limit the use of the combi-
natory rules (in particular: type-raising) to obtain
a single right-branching normal form derivation
(Eisner, 1996) for each possible semantic inter-
pretation. Such normal form derivations only use
composition and type-raising where syntactically
necessary (eg. in relative clauses).
3 Predictions
3.1 Priming Effects
We expect priming effects to apply to CCG cat-
egories, which describe the type of a constituent
including the arguments it expects. Under our as-
sumption that priming manifests itself as a ten-
dency for repetition, repetition probability should
be higher for short distances from a prime (see
Section 5.2 for details).
310
3.2 Terminal and Non-terminal Categories
In categorial grammar, lexical categories specify
the subcategorization behavior of their heads, cap-
turing local and non-local arguments, and a small
set of rule schemata defines how constituents can
be combined.
Phrasal constituents may have the same cate-
gories as lexical items. For example, the verb saw
might have the (lexical) category (S\NP)/NP,
which allows it to combine with an NP to the right.
The resulting constituent for saw Johanna would
be of category S\NP ? a constituent which expects
an NP (the subject) to its left, and also the lexi-
cal category of an intransitive verb. Similarly, the
constituent consisting of a ditransitive verb and its
object, gives the money, has the same category as
saw. Under the assumption that priming occurs for
these categories, we proceed to test a hypothesis
that follows from the fact that categories merely
encode unsatisfied subcategorized arguments.
Given that a transitive verb has the same cat-
egory as the constituent formed by a ditransitive
verb and its direct object, we would expect that
both categories can prime each other, if they are
cognitive units. More generally, we would expect
that lexical (terminal) and phrasal (non-terminal)
categories of the same syntactic type may prime
each other. The interaction of such conditions with
the priming effect can be quantified in the statisti-
cal model.
3.3 Incrementality of Analyses
Type-raising and composition allow derivations
that are mostly left-branching, or incremental.
Adopting a left-to-right processing order for a sen-
tence is important, if the syntactic theory is to
make psycholinguistically viable predictions (Niv,
1994; Steedman, 2000).
Pickering et al (2002) present priming experi-
ments that suggest that, in production, structural
dominance and linearization do not take place in
different stages. Their argument involves verbal
phrases with a shifted prepositional object such
as showed to the mechanic a torn overall. At a
dominance-only level, such phrases are equivalent
to non-shifted prepositional constructions (showed
a torn overall to the mechanic), but the two vari-
ants may be differentiated at a linearization stage.
Shifted primes do not prime prepositional objects
in their canonical position, thus priming must oc-
cur at a linearized level, and a separate dominance
level seems unlikely (unless priming is selective).
CCG is compatible with one-stage formulations of
syntax, as no transformation is assumed and cate-
gories encode linearization together with subcate-
gorization.
CCG assumes that the processor may produce
syntactically different, but semantically equivalent
derivations.2 So, while neither the incremental
analysis we generate, nor the normal-form, rep-
resent one single correct derivation, they are two
extremes of a ?spectrum? of derivations. We hy-
pothesize that priming effects predicted on the ba-
sis of incremental CCG analyses will be as strong
than those predicted on the basis of their normal-
form equivalents.
4 Corpus Data
4.1 The Switchboard Corpus
The Switchboard (Marcus et al, 1994) corpus con-
tains transcriptions of spoken, spontaneous con-
versation annotated with phrase-structure trees.
Dialogues were recorded over the telephone
among randomly paired North American speak-
ers, who were just given a general topic to talk
about. 80,000 utterances of the corpus have been
annotated with syntactic structure. This portion,
included in the Penn Treebank, has been time-
aligned (per word) in the Paraphrase project (Car-
letta et al, 2004).
Using the same regression technique as em-
ployed here, Reitter et al (2006b) found a marked
structural priming effect for Penn-Treebank style
phrase structure rules in Switchboard.
4.2 Disfluencies
Speech is often disfluent, and speech repairs are
known to repeat large portions of the preceding
context (Johnson and Charniak, 2004). The orig-
inal Switchboard transcripts contains these disflu-
encies (marked up as EDITED):
( (S >>>(EDITED
(RM (-DFL- \bs [) )
(EDITED
(RM (-DFL- \bs [) )
(CC And)
(, ,)
(IP (-DFL- \bs +) ))
(CC and)
(, ,)
(RS (-DFL- \bs ]) )
(IP (-DFL- \bs +) ))<<<
2Selectional criteria such as information structure and in-
tonation allow to distinguish between semantically different
analyses.
311
(CC and)
>>>(RS (-DFL- \bs ]) )<<<
(NP-SBJ (PRP I) )
(VP (VBP guess)
(SBAR (-NONE- 0)
(S (NP-SBJ (DT that) )
(VP (BES ?s)
(SBAR-NOM-PRD
(WHNP-1 (WP what) )
(S (NP-SBJ (PRP I) )
(ADVP (RB really) )
(VP (VBP like)
(NP (-NONE- *T*-1) ))))))))
(. .) (-DFL- E_S) ))
It is unclear to what extent these repetitions
are due to priming rather than simple correc-
tion. In disfluent utterances, we therefore elimi-
nate reparanda and only keep repairs (the portions
marked with >...< are removed). Hesitations (uh,
etc.), and utterances with unfinished constituents
are also ignored.
4.3 Translating Switchboard to CCG
Since the Switchboard annotation is almost iden-
tical to the one of the Penn Treebank, we use a
similar translation algorithm to Hockenmaier and
Steedman (2005). We identify heads, arguments
and adjuncts, binarize the trees, and assign cat-
egories in a recursive top-down fashion. Nonlo-
cal dependencies that arise through wh-movement
and right node raising (*T* and *RNR* traces) are
captured in the resulting derivation. Figure 1 (left)
shows the rightmost normal form CCG derivation
we obtain for the above tree. We then transform
this normal form derivation into the most incre-
mental (i.e., left-branching) derivation possible, as
shown in Figure 1 (right).
This transformation is done by a top-down re-
cursive procedure, which changes each tree of
depth two into an equivalent left-branching anal-
ysis if the combinatory rules allow it. This pro-
cedure is run until no further transformation can
be executed. The lexical categories of both deriva-
tions are identical.
5 Statistical Analysis
5.1 Priming of Categories
CCG assumes a minimal set of combinatory rule
schemata. Much more than in those rules, syntac-
tic decisions are evident from the categories that
occur in the derivation.
Given the categories for each utterance, we can
identify their repeated use. A certain amount
of repetition will obviously be coincidental. But
structural priming predicts that a target category
will occur more frequently closer to a potential
prime of the same category. Therefore, we can
correlate the probability of repetition with the dis-
tance between prime and target. Generalized Lin-
ear Mixed Effects Models (GLMMs, see next sec-
tion) allow us to evaluate and quantify this corre-
lation.
Every syntactic category is counted as a poten-
tial prime and (almost always) as a target for prim-
ing. Because interlocutors tend to stick to a topic
during a conversation for some time, we exclude
cases of syntactic repetition that are a results of
the repetition of a whole phrase.
Previous work points out that priming is sensi-
tive to frequency (Scheepers (2003) for high/low
relative clause attachments, (Reitter et al, 2006a)
for phrase structure rules). Highly frequent items
do not receive (as much) priming. We include
the logarithm of the raw frequency of the syntac-
tic category in Switchboard (LNFREQ) to approx-
imate the effect that frequency has on accessibility
of the category.
5.2 Generalized Linear Mixed Effects
Regression
We use generalized linear mixed effects regression
models (GLMM, Venables and Ripley (2002)) to
predict a response for a number of given categorial
(?factor?) or continuous (?predictor?) explanatory
variables (features). Our data is made up of in-
stances of repetition examples and non-repetition
examples from the corpus. For each target in-
stance of a syntactic category c occurring in a
derivation and spanning a constituent that begins
at time t, we look back for possible instances of
constituents with the same category (the prime)
in a time frame of [t ? d ? 0.5; t ? d + 0.5] sec-
onds. If such instances can be found, we have a
positive example of repetition. Otherwise, c is in-
cluded as a data point with a negative outcome.
We do so for a range of different distances d, com-
monly 1 ? d ? 15 seconds.3 For each data point,
we include the logarithm of the distance d between
priming period and target as an explanatory vari-
able LNDIST. (See Reitter et al (2006b) for a
worked example.)
In order to eliminate cases of lexical repeti-
tion of a phrase, e.g., names or lexicalized noun
3This approach uses a number of data points per target,
looking backwards for primes. The opposite way ? looking
forwards for targets ? would make similar predictions.
312
Normal form derivation Incremental derivation
S[dcl]
S/S
and
S[dcl]
S/(S\NP)
NP
I
S[dcl]\NP
(S[dcl]\NP)/S[dcl]
guess
S[dcl]
S/(S\NP)
NP
that
S[dcl]\NP
(S[dcl]\NP)/NP
?s
NP
NP/(S[dcl]/NP)
what
S[dcl]/NP
S/(S\NP)
NP
I
(S[dcl]\NP)/NP
(S\NP)/(S\NP)
really
(S[dcl]\NP)/NP
like
S[dcl]
S[dcl]/(S[dcl]/NP)
S[dcl]/NP
S[dcl]/(S\NP)
S[dcl]/S[dcl]
S/(S\NP)
S/S
and
S/(S\NP)
NP
I
(S[dcl]\NP)/S[dcl]
guess
S/(S\NP)
NP
that
(S[dcl]\NP)/NP
?s
NP/(S[dcl]/NP)
what
S[dcl]/NP
S/(S\NP)
S/(S\NP)
NP
I
(S\NP)/(S\NP)
really
(S[dcl]\NP)/NP
like
Figure 1: Two derivations (normal form: left), incremental: right) for the sentence fragment and I guess
that?s what I really like from Switchboard.
phrases, which we consider topic-dependent or in-
stances of lexical priming, we only collect syntac-
tic repetitions with at least one differing word.
Without syntactic priming, we would assume
that there is no correlation between the probabil-
ity that a data point is positive (repetition occurs)
and distance d. With priming, we would expect
that the probability is inversely proportional to d.
Our model uses lnd as predictor LNDIST, since
memory effects usually decay exponentially.
The regression model fitted is then simply a
choice of coefficients ?i, among them one for each
explanatory variable i. ?i expresses the contribu-
tion of i to the probability of the outcome event,
that is, in our case, successful priming. The coeffi-
cient of interest is the one for the time correlation,
i.e. ?lnDist . It specifies the strength of decay of
repetition probability over time. If no other vari-
ables are present, a model estimates the repetition
probability for a data point i as
p?i = ?0 +?lnDist ln DISTi
Priming is present if the estimated parameter is
negative, i.e. the repetition probability decreases
with increasing distance between prime and target.
Other explanatory variables, such as ROLE,
which indicates whether priming occurs within a
speaker (production-production priming, PP) or
in between speakers (comprehension-production
priming, CP), receive an interaction coefficient
that adds linearly to ?lnDist . Additional interac-
tion variables are included depending on the ex-
perimental question.4
4Lastly, we identify the target utterance in a random fac-
tor in our model, grouping the several measurements (15 for
the different distances from each target) as repeated measure-
ments, since they depend on the same target category occur-
rence and are partially inter-dependent.
From the data produced, we include all cases
of reptition and a an equal number of randomly
sampled non-repetition cases.5
6 Experiments
6.1 Experiment 1: Priming in Incremental
and Normal-form Derivations
Hypothesis CCG assumes a multiplicity of se-
mantically equivalent derivations with different
syntactic constituent structures. Here, we in-
vestigate whether two of these, the normal-form
and the most incremental derivation, differ in the
strength with which syntactic priming occurs.
Method A joint model was built containing rep-
etition data from both types of derivations. Since
we are only interested in cases where the two
derivations differ, we excluded all constituents
where a string of words was analyzed as a con-
stituent in both derivations. This produced a data
set where the two derivations could be contrasted.
A factor DERIVATION in the model indicates
whether the repetition occurred in a normal-form
(NF) or an incremental derivation (INC).
Results Significant and substantial priming is
present in both types of derivations, for both PP
and CP priming. There is no significant difference
in priming strength between normal-form and
incremental derivations (?lnDist:NF = 0.008, p =
0.95). The logarithm of the raw category fre-
quency is negatively correlated with the priming
strength (?lnDist:lnFreq = 0.151, p < 0.0001. Note
that a negative coefficient for LNDIST indicates
5We trained our models using Penalized Quasi-
Likelihood (Venables and Ripley, 2002). This technique
works best if data is balanced, i.e. we avoid having very rare
positive examples in the data. Experiment 2 was conducted
on a subset of the data.
313
CP:NormalForm
PP:NormalForm
CP:Incremental
PP:Incremental
1.0 1.2 1.4 1.6
- - - -
Figure 2: Decay effect sizes in Experiment 1
for combinations of comprehension-production or
production-production priming and in incremental
or normal-form derivations. Error bars show (non-
simultaneous) 95% confidence intervals.
decay. The lower this coefficient, the more decay,
hence priming).
If there was no priming of categories for incre-
mentally formed constituents, we would expect to
see a large effect of DERIVATION. In the contrary,
we see no effect at a high p, where the that the
regression method used is demonstrably powerful
enough to detect even small changes in the prim-
ing effect. We conclude that there is no detectable
difference in priming between the two derivation
types. In Fig. 2, we give the estimated priming
effect sizes for the four conditions.6
The result is compatible with CCG?s separation
of derivation structure and the type of the result
of derivation. It is not the derivation structure that
primes, but rather the type of the result. It is also
compatible with the possibility of a non-traditional
constituent structure (such as the incremental anal-
ysis), even though it is clear that neither incremen-
tal nor normal-form derivations necessarily repre-
sent the ideal analysis.
The category sets occurring in both derivation
variants was largely disjunct, making testing for
actual overlap between different derivations im-
possible.
6.2 Experiment 2: Priming between Lexical
and Phrasal Categories
Hypothesis Since CCG categories simply en-
code unsatisfied subcategorization constraints,
constituents which are very different from a tradi-
tional linguistic perspective can receive the same
category. This is, perhaps, most evident in phrasal
6Note that Figures 2 and 3 stem from nested models that
estimate the effect of LNDIST within the four/eight condi-
tions. Confidence intervals will be larger, as fewer data-
points are available than when the overall effect of a single
factor is compared.
CP:lex?lex
PP:lex?lex
CP:lex?phr
PP:lex?phr
CP:phr?lex
PP:phr?lex
CP:phr?phr
PP:phr?phr
?1.0 ?1.2 ?1.4 ?1.6 ?1.8 ?2.0
Figure 3: Decay effect sizes in Experiment 2,
for combinations of comprehension-production
or production-production priming and lexical or
phrasal primes and targets, e.g. the third bar
denotes the decay in repetition probability of a
phrasal category as prime and a lexical one as
target, where prime and target occurred in utter-
ances by the same speaker. Error bars show (non-
simultaneous) 95% confidence intervals.
and lexical categories (where, e.g., an intransitive
verb is indistinguishable from a verb phrase).
Bock and Loebell (1990)?s experiments suggest
that priming effects are independent of the subcat-
egorization frame. There, an active voice sentence
primed a passive voice one with the same phrase
structure, but a different subcategorization. If we
find priming from lexical to phrasal categories,
then our model demonstrates priming of subcat-
egorization frames.
From a processing point of view, phrasal cat-
egories are distinct from lexical ones. Lexical
categories are bound to the lemma and thereby
linked to the lexicon, while phrasal categories
are the result of a structural composition or de-
composition process. The latter ones represent
temporary states, encoding the syntactic process.
Here, we test whether lexical and phrasal cate-
gories can prime each other, and if so, contrast the
strength of these priming effects.
Method We built a model which allowed lex-
ical and phrasal categories to prime each other.
A factor, STRUCTURAL LEVEL was introduced
314
to distinguish the four cases: priming in between
phrasal categories and in between lexical ones,
from lexical ones to phrasal ones and from phrasal
ones to lexical ones.
Recall that each data point encodes a possibility
to repeat a CCG category, referring to a particular
instance of a target category at time t and a time
span of duration of one second [t?d?0.5, t?d +
0.5] in which a priming instance of the same cate-
gory could occur. If it occurred at least once, the
data point was counted as a possible example of
priming (response variable: true), otherwise it was
included as a counter-example (response variable:
false). For the target category, its type (lexical or
phrasal) was clear. For the category of the prime,
we included two data points, one for each type,
with a response indicating whether a prime of the
category of such a type occurred in the time win-
dow. We built separate models for incremental and
normal form derivations. Models were fitted to
a balanced subset, including all repetitions and a
randomly sampled subset of non-repetitions.
Results Both the normal-form and the incre-
mental model show qualitatively the same re-
sults. STRUCTURALLEVEL has a significant
influence on priming strength (LN DIST) for
the cases where a lexical item serves as prime
(e.g., normal-form PP: ?lnDist:lex?lex = 0.261,
p < 0.0001; ?lnDist:lex?phr = 0.166, p < 0.0001;
?lnDist:phr?lex = 0.056, p < 0.05; as compared to
the baseline phr? phr. N.B. higher values denote
less decay & priming). Phrasal categories prime
other phrasal and lexical categories, but there is a
lower priming effect to be seen from lexical cate-
gories. Figure 3 presents the resulting effect sizes.
Albeit significant, we assume the effect of prime
type is attributable to processing differences rather
than the strong difference that would indicate that
there is no priming of, e.g., lexical subcategoriza-
tion frames. As the analysis of effect sizes shows,
we can see priming from and in between both lex-
ical and phrasal categories.
Additionally, there is no evidence suggesting
that, once frequency is taken into account, syntac-
tic processes happening high up in derivation trees
show more priming (see Scheepers 2003).
7 Discussion
We can confirm the syntactic priming effect for
CCG categories. Priming occurs in incremental
as well as in normal-form CCG derivations, and at
different syntactic levels in those derivations: we
demonstrated that priming effects persists across
syntactic stages, from the lowest one (lexical cate-
gories) up to higher ones (phrasal categories). This
is what CCG predicts if priming of categories is
assumed.
Linguistic data is inherently noisy. Annotations
contain errors, and conversions such as the one to
CCG may add further error. However, since noise
is distributed across the corpus, it is unlikely to af-
fect priming effect strength or its interaction with
the factors we used: priming, in this study, is de-
fined as decay of repetition probability. We see
the lack of control in the collection of a corpus like
Switchboard not only as a challenge, but also as an
advantage: it means that realistic data is present in
the corpus, allowing us to conduct a controlled ex-
periments to validate a claim about a specific the-
ory of competence grammar.
The fact that CCG categories prime could be
explained in a model that includes a basic form
of subcategorization. All categories, if lexical or
phrasal, contain a subcategorization frame, with
only those categories present that have yet to be
satisfied. Our CCG based models make predic-
tions for experimental studies, e.g., that specific
heads with open subcategorization slots (such as
transitive verbs) will be primed by phrases that re-
quire the same kinds of arguments (such as verbal
phrases with a ditransitive verb and an argument).
The models presented take the frequency of the
syntactic category into account, reducing noise,
especially in the conditions with lower numbers
of (positive) reptition examples (e.g., CP and in-
cremental derivations in Experiment 1). Whether
there are significant qualitative and quantitative
differences of PP and CP priming with respect to
choice of derivation type ? which would point out
processing differences in comprehension vs. pro-
duction priming ? will be a matter of future work.
At this point, we do not explicitly discriminate
different syntactic frameworks. Comparing prim-
ing effects in a corpus annotated in parallel accord-
ing to different theories will be a matter of future
work.
8 Conclusions
We have discussed an empirical, corpus-based ap-
proach to use priming effects in the validation of
general syntactic models. The analysis we pre-
sented is compatible with the reality of a lexical-
315
ized, categorial grammar such as CCG as a com-
ponent of the human sentence processor. CCG is
unusual in allowing us to compare different types
of derivational analyses within the same grammar
framework. Focusing on CCG allowed us to con-
trast priming under different conditions, while still
making a statistical and general statement about
the priming effects for all syntactic phenomena
covered by the grammar.
Acknowledgements
We would like to thank Mark Steedman, Roger Levy, Jo-
hanna Moore and three anonymous reviewers for their com-
ments. The authors are grateful for being supported by the
following grants: DR by The Edinburgh Stanford Link, JH
by NSF ITR grant 0205456, FK by The Leverhulme Trust
(grant F/00 159/AL ? Syntactic Parallelism).
References
J. Kathryn Bock. 1986. Syntactic persistence in language pro-
duction. Cognitive Psychology, 18:355?387.
J. Kathryn Bock and Helga Loebell. 1990. Framing sen-
tences. Cognition, 35:1?39.
Holly P. Branigan, Martin J. Pickering, and Alexandra A. Cle-
land. 2000. Syntactic co-ordination in dialogue. Cogni-
tion, 75:B13?25.
Jean Carletta, S. Dingare, Malvina Nissim, and T. Nikitina.
2004. Using the NITE XML toolkit on the Switchboard
corpus to study syntactic choice: a case study. In Proc. 4th
Language Resources and Evaluation Conference. Lisbon,
Portugal.
Stephen Clark and James R. Curran. 2004. Parsing the WSJ
using CCG and log-linear models. In Proc. of the 42nd
Annual Meeting of the Association for Computational Lin-
guistics. Barcelona, Spain.
A. A. Cleland and M. J. Pickering. 2003. The use of lexi-
cal and syntactic information in language production: Ev-
idence from the priming of noun-phrase structure. Journal
of Memory and Language, 49:214?230.
Amit Dubey, Frank Keller, and Patrick Sturt. 2006. Inte-
grating syntactic priming into an incremental probabilistic
parser, with an application to psycholinguistic modeling.
In Proc. of the 21st International Conference on Computa-
tional Linguistics and 44th Annual Mtg of the Association
for Computational Linguistics. Sydney, Australia.
Jason Eisner. 1996. Efficient normal-form parsing for com-
binatory categorial grammar. In Proceedings of the 34th
Annual Meeting of the Association for Computational Lin-
guistics, pages 79?86. Santa Cruz,CA.
Stefan Th. Gries. 2005. Syntactic priming: A corpus-
based approach. Journal of Psycholinguistic Research,
34(4):365?399.
Julia Hockenmaier and Mark Steedman. 2002. Generative
models for statistical parsing with Combinatory Catego-
rial Grammar. In Proc. 40th Annual Meeting of the Asso-
ciation for Computational Linguistics. Philadelphia, PA.
Julia Hockenmaier and Mark Steedman. 2005. CCGbank:
Users? manual. Technical Report MS-CIS-05-09, Com-
puter and Information Science, University of Pennsylva-
nia.
Mark Johnson and Eugene Charniak. 2004. A tag-based noisy
channel model of speech repairs. In Proc. 42nd Annual
Meeting of the Association for Computational Linguistics,
pages 33?39. Barcelona, Spain.
M. Marcus, G. Kim, M. Marcinkiewicz, R. MacIntyre,
A. Bies, M. Ferguson, K. Katz, and B. Schasberger. 1994.
The Penn treebank: Annotating predicate argument struc-
ture. In Proc. ARPA Human Language Technology Work-
shop. Plainsboro, NJ.
Michael Niv. 1994. A psycholinguistically motivated parser
for CCG. In Mtg. of the Association for Computational
Linguistics, pages 125?132.
Martin J. Pickering and Holly P. Branigan. 1998. The rep-
resentation of verbs: Evidence from syntactic priming in
language production. Journal of Memory and Language,
39:633?651.
Martin J. Pickering, Holly P. Branigan, and Janet F. McLean.
2002. Constituent structure is formulated in one stage.
Journal of Memory and Language, 46:586?605.
David Reitter, Frank Keller, and Johanna D. Moore. 2006a.
Computational modelling of structural priming in dia-
logue. In Proc. Human Language Technology conference
- North American chapter of the Association for Compu-
tational Linguistics annual mtg. New York City.
David Reitter, Johanna D. Moore, and Frank Keller. 2006b.
Priming of syntactic rules in task-oriented dialogue and
spontaneous conversation. In Proc. 28th Annual Confer-
ence of the Cognitive Science Society.
Christoph Scheepers. 2003. Syntactic priming of relative
clause attachments: Persistence of structural configuration
in sentence production. Cognition, 89:179?205.
Mark Steedman. 2000. The Syntactic Process. MIT Press.
Benedikt Szmrecsanyi. 2005. Creatures of habit: A corpus-
linguistic analysis of persistence in spoken english. Cor-
pus Linguistics and Linguistic Theory, 1(1):113?149.
William N. Venables and Brian D. Ripley. 2002. Modern
Applied Statistics with S. Fourth Edition. Springer.
Mike White and Jason Baldridge. 2003. Adapting chart re-
alization to CCG. In Proc. 9th European Workshop on
Natural Language Generation. Budapest, Hungary.
316
XML/XSL in the Dictionary: The Case of Discourse Markers
Daniela Berger and David Reitter and Manfred Stede
University of Potsdam
Dept. of Linguistics / Applied Computational Linguistics
P.O. Box 601553 / D-14415 Potsdam / Germany
{berger|reitter|stede}@ling.uni-potsdam.de
Abstract
We describe our ongoing work on an application
of XML/XSL technology to a dictionary, from
whose source representation various views for
the human reader as well as for automatic text
generation and understanding are derived. Our
case study is a dictionary of discourse markers,
the words (often, but not always, conjunctions)
that signal the presence of a disocurse relation
between adjacent spans of text.
1 Overview
Electronic dictionaries have made extensive use
of SGML encoding in the past, but to our
knowledge, the advantages of contemporary
frameworks such as XML/XSL are only be-
ginning to be explored. We are applying this
framework to our work on a lexicon of ?dis-
course markers? and will outline the advantages
of deriving a variety of views from the common
underlying lexical resource: different views for
different demands by the human eye, but also
application-specific views that tailor the dictio-
nary to either the parsing or the generation task
(a third one would be machine translation but
is not covered in this paper), and that respect
the conventions of the specific underlying pro-
gramming language. Using XSL style sheets for
producing the views automatically is especially
useful when the lexicon is still under develop-
ment: the ramifications of particular modifica-
tions or extensions can be made visible easily
by running the conversion and testing the ap-
plications in question.
Discourse markers are words (predominantly
conjunctions) that signal the kind of semantic or
rhetorical relationship between adjacent spans
of text. In text generation, when given a rep-
resentation of propositions and relations hold-
ing between them, the task is to select an ap-
propriate discourse marker in the context. In
text understanding, discourse markers are the
most important clues for inferring the ?rhetori-
cal structure? of the text, a task that has lately
been called ?rhetorical parsing?. While these
discourse markers are a somewhat idiosyncratic
class of lexical items, we believe that our general
approach to applying XML/XSL can be fruitful
to other branches of the dictionary as well (in
particular to the open-class ?content words?).
After reviewing some earlier work on XML-
based dictionaries (Section 2) and discussing the
notion of discourse markers (Section 3), we pro-
ceed to outline the particular requirements on
a discourse marker lexicon from both the text
generation and the text understanding perspec-
tive (Section 4). Then, Section 5 describes our
XML/XSL encoding of the source lexicon and
the views for the human eye, for automatic text
generation, and for text understanding. Finally,
Section 6 draws some conclusions.
2 Dictionaries and XML: Related
work
Recent research in lexicology has been focused
on two different goals: the mark-up process
for existing print dictionaries, and the success-
ful construction of machine-readable dictionar-
ies from scratch.
The first approach has received more at-
tention in the past. This is partly due to
the fact that the transformation of existing
print dictionaries into modules for NLP applica-
tions promises to be less time-consuming than
the construction of a new machine-readable
database. Lexicologists agree on the fact that a
dictionary entry is inherently hierarchical, i.e.,
it consists out of atomic elements grouped to-
gether within non-atomic elements in a tree-like
hierarchy. Many approaches place orthograph-
ical and phonological information together in
one group, while grammatical information is put
in a different group. This hierarchical approach
also allows to denote scope by inserting informa-
tion at different levels of the hierarchy. Again,
information about orthography and phonology
generally applies to every facet of the headword
and are thus placed high in the hierarchy, while
other information might only apply to single
definitions and thus ranks lower hierarchically
(Amsler/Tompa, 1988; Ide, Ve?ronis, 1995; Ide
et al, 2000).
A common problem of lexicologists working
with print dictionaries is the fact that there is
a certain variation between entries in any two
given dictionaries or even within the same dic-
tionary. This results in a neccessary trade-off
between the descriptive power and the gener-
ality of an approach, i.e. to design a SGML
application that is both descriptive enough to
be of practical value and general enough to ac-
comodate the variation.
There has been, on the other hand, only little
research on machine-readable dictionaries that
are not based on print dictionaries. To our
knowledge, only (Ide et al, 1993) deals with
this issue by reviewing several approaches to-
wards encoding machine-readable dictionaries.
One of these is the use of text models that ap-
ply a rather flat hierarchy to mark up dictio-
nary entries. These text models might chiefly
use typographical or grammatical information.
Another approach is using relational databases,
in which the information contained in a dictio-
nary entry is distributed over several databases.
A third approach is based on feature structures
that impose a rich hierarchical structure on the
data. The authors finally describe an example
application that uses feature structures encoded
in SGML to set up a machine-readable dictio-
nary.
The papers mentioned above agree on us-
ing SGML for the mark-up. We found that
their SGML code is, however, in general XML-
compliant.
3 Discourse markers
Several contemporary discourse theories posit
that important aspects of a text?s coherence
can be formally described (and represented) by
means of discourse relations holding between
adjacent spans of text (e.g. Asher, 1993; Mann,
Thompson, 1988). We use the term discourse
marker for those lexical items that (in addition
to non-lexical means such as punctuation, as-
pectual and focus shifts, etc.) can signal the
presence of such a relation at the linguistic sur-
face. Typically, a discourse relation is associ-
ated with a wide range of such markers; con-
sider, for instance, the following variety of Con-
cessions, which all express the same underly-
ing propositional content. The words that we
treat as discourse markers are underlined.
We were in SoHo; {nevertheless | nonetheless
| however | still | yet}, we found a cheap bar.
We were in SoHo, but we found a cheap bar
anyway.
Despite the fact that we were in SoHo, we
found a cheap bar.
Notwithstanding the fact that we were in
SoHo, we found a cheap bar.
Although we were in SoHo, we found a cheap
bar.
If one accepts these sentences as paraphrases,
then the various discourse markers all need to
be associated with the information that they
signal a concessive relationship between the two
propositions involved. Notice that the markers
belong to different syntactic categories and thus
impose quite different syntactic constraints on
their environment in the sentence. Discourse
markers do not form a homogeneous class from
the syntactican?s viewpoint, but from a func-
tional perspective they should nonetheless be
treated as alternatives in a paradigmatic choice.
A detailled characterization of discourse
markers, together with a test procedure for
identifying them in text, has been provided for
English by (Knott, 1996). Recently, (Grote, to
appear) adapted Knott?s procedure for the Ger-
man language. Very briefly, to identify a dis-
course marker (e.g., because) in a text, isolate
the clause containing a candidate from the text,
resolve any anaphors and make elided items ex-
plicit; if the resulting text is incomplete (e.g.,
because the woman bought a Macintosh), then
the candidate is indeed a ?relational phrase?, or
for our purposes, a two-place discourse marker.
In addition to the syntactic features, the dif-
ferences in meaning and style between similar
markers need to be discerned; one such differ-
ence is the degree of specificity: for example,
but can mark a general Contrast or a more
specific Concession. Another one is the no-
table difference in formality between, say but ...
anyway and notwithstanding.
From the perspective of text generation, not
all paraphrases listed above are equally felici-
tous in specific contexts. In order to choose
the most appropriate variant, a generator needs
knowledge about the fine-grained differences be-
tween similar markers for the same relation.
Furthermore, it needs to account for the interac-
tions between marker choice and other genera-
tion decisions and hence needs knowledge about
the syntagmatic constraints associated with dif-
ferent markers. We will discuss this perspective
in Section 4.1
From the perspective of text understanding,
discourse markers can be used as one source of
information for guessing the rhetorical structure
of a text, or automatic rhetorical parsing. We
will characterize this application in Section 4.2.
4 Requirements on a discourse
marker lexicon
As the following two subsections will show, text
generation and understanding have quite dif-
ferent preferences on the information coded in
a discourse marker lexicon, or ?DiMLex? for
short. In addition, different systems employ dif-
ferent programming languages, and the format
of the lexicon has to be adapted accordingly.
Yet we want to avoid coding different lexicons
manually and thus seek a common ?core rep-
resentation? for DiMLex from which the var-
ious application-specific instantiations can be
derived. Before proposing such a representa-
tion, though, we have to examine in more detail
the different requirements.
4.1 The text generation perspective
Present text generation systems are typically
not very good at choosing discourse mark-
ers. Even though a few systems have incor-
porated some more sophisticated mappings for
specific relations (e.g., in DRAFTER (Paris et
al., 1995)), there is still a general tendency to
treat discourse marker selection as a task to
be performed as a ?side effect? by the gram-
mar, much like for other function words such as
prepositions.
To improve this situation, we propose to view
discourse marker selection as one subtask of the
general lexical choice process, so that ? to con-
tinue the example given above ? one or another
form of Concession can be produced in the
light of the specific utterance parameters and
the context. Obviously, marker selection also
includes the decision whether to use any marker
at all or leave the relation implicit. When these
decisions can be systematically controlled, the
text can be tailored much better to the specific
goals of the generation process.
The generation task imposes a particular view
of the information coded in DiMLex: the en-
try point to the lexicon is the discourse relation
to be realized, and the lookup yields the range
of alternatives. But many markers have more
semantic and pragmatic constraints associated
with them, which have to be verified in the gen-
erator?s input representation for the marker to
be a candidate. Then, discourse markers place
(predominantly syntactic) constraints on their
immediate context, which affects the interac-
tions between marker choice and other realiza-
tion decisions. And finally, markers that are still
equivalent after evaluating these constraints are
subject to a choice process that can utilize pref-
erential (e.g. stylistic or length-based) criteria.
Therefore, under the generation view, the infor-
mation in DiMLex is grouped into the following
three classes:
? Applicability conditions: The necessary
conditions for using a discourse marker, i.e., the
features or structural configurations that need
to be present in the input specification.
? Syntagmatic constraints: The constraints
regarding the combination of a marker and the
neighbouring constituents; most of them are
syntactic and appear at the beginning of the list
given above (part of speech, linear order, etc.).
? Paradigmatic features: Features that label
the differences between similar markers sharing
the same applicability conditions, such as stylis-
tic features and degrees of emphasis.
Very briefly, we see discourse marker choice
as one aspect of the sentence planning task
(e.g. (Wanner, Hovy, 1996)). In order to
account for the intricate interactions between
marker choice and other generation decisions,
the idea is to employ DiMLex as a declara-
tive resource supporting the sentence planning
process, which comprises determining sentence
boundaries and sentence structure, linear order-
ing of constituents (e.g. thematizations), and
lexical choice. All these decisions are heavily
interdependent, and in order to produce truly
adequate text, the various realization options
need to be weighted against each other (in con-
trast to a simple, fixed sequence of making the
types of decisions), which presupposes a flexible
computational mechanism based on resources
as declarative as possible. This generation ap-
proach is described in more detail in (Grote,
Stede, 1998).
4.2 The text understanding perspective
In text understanding, discourse markers serve
as cues for inferring the rhetorical or semantic
structure of the text. In the approach proposed
in (Marcu, 1997), for example, the presence of
discourse markers is used to hypothesize indi-
vidual textual units and relations holding be-
tween them. Then, the overall discourse struc-
ture tree is built using constraint satisfaction
techniques. Our analysis method uses the lexi-
con for an initial identification and disambigua-
tion of discourse markers. They serve as one
of several other shallow features that determine
through a statistical, learned language model
the optimal rhetorical analysis.
In contrast to the use of markers in genera-
tion, the list of cues is significantly longer and
includes phrasal items like aus diesem Grund
(for this reason) or genauer genommen (more
precisely).
5 Our XML/XSL solution
In the following we show some sample represen-
tations and style sheets that have been abridged
for presentation purposes.
5.1 Source representation
In our hierarchical XML structure, the
<dictionary> root tag encloses the entire file,
and every single entry rests in an <entry>
tag, which unambigously identifies every entry
with its id attribute. Within the <entry> tag
there are four subordinate tags: <form>, <syn>,
<sem>, and <examples>.
The <form> tag contains the orthographic
form of the headword; at present this amounts
to two slots for alternative orthographies. The
<syn> area contains the syntactic information
about the headword. In this shortened exam-
ple, there is only the <init field> tag present,
<?xml version="1.0" ?>
<?xml-stylesheet type="text/xsl"
href="short_dictionary.xsl" ?>
<!DOCTYPE dictionary SYSTEM "DTD.dtd">
5 <dictionary>
<entry id="05">
<form>
<orth>denn</orth>
<alt_orth>none</alt_orth>
10 <!-- . . . -->
</form>
<syn>
<init_field>-</init_field>
<!-- . . . -->
15 </syn>
<sem>
<function>causal</function>
<!-- . . . -->
</sem>
20 <examples>
<example>Das Konzert muss ausfallen,
*denn* die S&auml;ngerin ist erkrankt.
</example>
<example>Die Blumen auf dem Balkon sind
25 erfroren, *denn* es hat heute nacht
Frost gegeben.</example>
</examples>
</entry>
<entry>
30 <!-- more entries -->
</entry>
</dictionary>
Figure 1: The XML structure
which shows whether the headword can be used
in the initial field of a sentence. Correspond-
ingly, <sem> contains semantic features such as
the <function> tag, which contains the seman-
tic/discourse relation expressed by the head-
word. Finally, <examples>, contains one or
more <example> tags that may each give an ex-
ample sentence.
We have shortened this presentation consider-
ably; the full lexicon contains more fine-grained
features for all three areas: within <form>, in-
formation on pronounciation, syllable structure,
and hyphenation; within <syn>, information
about syntactic subcategorization and possible
positions in the clause; within <sem>, for exam-
ple the feature whether the information subor-
dinated by the marker is presupposed or not.
5.2 HTML views
The listing in Figure 4 shows a style sheet that
provides an HTML by listing the XML data in
a format that roughly resembles a print dictio-
nary. Figure 2 shows the output that results
from applying this XSL file to the XML source
in figure 1.
05: denn
Occurrences: middle field / Nullstelle
Semantics: kausal
Related markers: weil da
Examples: Das Konzert muss ausfallen, *denn* die
Sa?ngerin ist erkrankt.
Die Blumen auf dem Balkon sind erfroren, *denn* es hat
heute nacht Frost gegeben.
Figure 2: One HTML view of the data
We assume that the general structure of the
formatting part of XSL is familiar to the reader.
We would like to highlight some details.
XLINK is used to ensure that the entry con-
tains an HTML-anchor named after the head-
word (ll. 14-20). This way it is possible to link
to a certain entry from the <rel> tag of a dif-
ferent entry (39-45).
We also employ the XSL equivalent to
an if/then/else construct (24-31). The
<xsl:choose> tag encloses the choices to be
made. The <xsl:when> tag contains the con-
dition match=".[alt orth=?none?]" that does
nothing if the <alt orth> tag contains the
data none. Every other case is covered by
the <xsl:otherwise> tag that prints out the
<alt orth> information if it is not no entry.
Entry alt orth init field mid field . . .
denn none - + . . .
da none + + . . .
zumal none - - . . .
weil none - - . . .
als none - - . . .
Figure 3: Another possible HTML view of the
data
Figure 3 shows another possible view for the
data. In this case the data is presented in table
form, ordered by the value of the mid field tag.
It would be easy to show that it is possible to
use a <xsl:choose> construct as shown in the
example before to print out only those entries
that satisfy a certain condition.
5.3 The text generation view
For the lexicon to be applied in our text
generation system ?Polibox? (Stede, 2002),
we need a Lisp-based version of DiM-
Lex. Using the (defstruct <name> <slot1>
<?xml version="1.0"?>
<xsl:stylesheet
xmlns:xsl=
"http://www.w3.org/1999/XSL/Transform">
5 <xsl:template match="/">
<FONT SIZE="-2">
<xsl:apply-templates/>
</FONT>
</xsl:template>
10 <xsl:template match="dictionary">
<xsl:apply-templates/>
</xsl:template>
<xsl:template match="entry">
<P><font size="2"><B><A>
15 <xsl:attribute name="NAME">
<xsl:value-of select="form/orth"/>
</xsl:attribute>
<xsl:value-of select="./@id"/>:
<xsl:value-of select="form/orth"/>
20 </A></b></font>
<xsl:apply-templates/></P>
</xsl:template>
<xsl:template match="form">
<xsl:choose>
25 <xsl:when match=".[alt_orth=?none?]">
</xsl:when>
<xsl:otherwise>
<BR/><B>Alternative orthography:</B>
<xsl:value-of select="alt_orth"/>
30 </xsl:otherwise>
</xsl:choose>
</xsl:template>
<xsl:template match="sem">
<BR/><B>Semantics:</B>
35 <xsl:value-of select="ko_sub"/>
/ <xsl:value-of select="function"/>
<br/><b>Related markers:</b>
<xsl:for-each select="rel">
<A><xsl:attribute name="HREF">
40 #<xsl:value-of select="."/>
</xsl:attribute>
<xsl:value-of select="."/></A>
</xsl:for-each>
</xsl:template>
45 <xsl:template match="syn">
<BR/><B>Occurrences:</B>
<xsl:choose>
<xsl:when match=".[init\_field=?-?]">
</xsl:when>
50 <xsl:otherwise>
initial field /
</xsl:otherwise>
</xsl:choose>
</xsl:template>
55 <xsl:template match="examples">
<BR/><B>Examples:</B>
<xsl:for-each select="example">
<xsl:value-of select="."/><BR/>
</xsl:for-each>
60 </xsl:template>
</xsl:stylesheet>
Figure 4: The XSL file for the HTML view
shown in Figure 2
.. <slotn>) construct, we define a class of ob-
jects for discourse markers, where the features
needed for generation are stored in the slots.
Again, we abbreviate slightly:
(defstruct DiscMarker
Relation N-Complexity S-Complexity
Ortho POS ... Style)
Now, a Lisp-object for each individual dis-
course marker entry is created with the func-
tion make-Discmarker, which provides the val-
ues for the slots. Figure 5 shows the shape of the
entry for denn, whose XML-source was given in
figure 1.
Again, we aim at deriving these entries au-
tomatically via an XSL sheet (which we do not
show here). Notice that the mapping task is
now somewhat different from the HTML cases,
since the transformation part of XSL (XSLT)
comes into play here. Instead of merely display-
ing the data in a web browser as in the examples
before, an XSLT processor may transform data
for use in some XML based client application.
As explained in Section 4.1, in the generation
scenario we are given a tree fragment consist-
ing of a discourse relation node and two daugh-
ters representing the related material, the nu-
cleus and the satellite of the relation. In order
to decide whether a particular marker can be
used, one important constraint is the ?size? of
the daughter material, which can be a single
proposition or an entire sub-tree. The gener-
ator needs to estimate whether it will fit into
a single phrase, clause, sentence, or into a se-
quence of sentences; a subordinating conjunc-
tion, for instance, can only be used if the ma-
terial can be expressed within a clause. Thus,
the Lisp-entry contains slots N-Complexity and
S-Complexity, which are highly application-
specific and thus do not have a simple corre-
sponding feature in the XML source represen-
tation of the dictionary. The XSL sheet thus
inspects certain combinations of daughter at-
tributes of <syn> and maps them to new names
for the fillers of the two Complexity slots in
the Lisp structure. (Similar mappings occur in
other places as well, which we do not show here.)
5.4 The text understanding view
Our analysis method recasts rhetorical parsing
as a set of classification decisions, where a pars-
(make-Discmarker
:Relation cause
:N-Complexity sent
:S-Complexity sent
5 :Ortho denn
:POS coordconj
:Style unmarked)
Figure 5: Lisp-version of generation-oriented
dictionary entry for denn (abridged)
ing framework builds a tree structured analy-
sis. Each of the decisions is based on a set of
features. Feature types range from syntactical
configuration to the presence of a certain dis-
course marker. The mapping from a pattern of
observed features to a rhetorical relation may be
learned automatically by a classification learn-
ing algorithm.
Learning and analysis applications use a pars-
ing framework that gives us a set of text span
pairs. Every two text spans are subject to a
classification learning algorithm (during train-
ing) or the actual classifier. So, a rhetorical rela-
tion is assigned to these two spans of text along
with a score so that the parsing framework may
decide which of several competing classifications
to accept.
Learning and actual rhetorical analysis are
accomplished by a set of distinct tools that add
specific annotations to a given input text, be-
fore resulting relations are learned or guessed.
These tools include a data mining component, a
part-of-speech tagger and a segmenter. They all
access data organized in an XML syntax. The
central learning and parsing application makes
use of a Document Object Model (DOM) repre-
sentation of the corpus. This data structure is
effectively used for information interchange be-
tween several components, because it allows us
to easily visualize and modify the current data
at each processing step during development.
With the present corpus data, the learning al-
gorithm is theoretically able to identify rhetori-
cal markers automatically and could thus com-
pile a marker lexicon. However, markers are
highly ambiguous. Even though many of them
can be tagged as adverbials or conjunctions,
markers often lack distinctive syntactic and/or
positional properties; some of them are phrasal,
some are discontinuous. To identify significant
cue - relation correlations, a lot of annotated
data is necessary: more than is usually avail-
able. In a sparse data situation, we want to
easen the learning task for the rhetorical lan-
guage model: It makes sense to use a discourse
marker lexicon.
On the other hand, we do not expect a hand-
crafted lexicon to contain all contextual con-
straints that would enable us to assign a sin-
gle rhetorical relation. These constraints can be
very subtle; some of them should be represented
as probabilistic scalar information.
Thus, DiMLex contributes to initial dis-
course marker disambiguation. From each en-
try, we interpret syntactic positioning informa-
tion, morphosyntactic contextual information
and a scope class (sentential, phrasal, discourse-
level) as a conjunction of constraints. The pres-
ence of a certain discourse marker in a specified
configuration is one of the features to be ob-
served in the text.
Depending on the depth of the syntactic and
semantic analysis carried out by the text un-
derstanding system, different features provided
by DiMLex can be taken into account. Certain
structural configurations can be tested with-
out any deep understanding; for instance, the
German marker wa?hrend is generally ambigu-
ous between a Contrast and a Temporal-
Cooccurrence reading, but when followed by
a noun phrase, only the latter reading is avail-
able (wa?hrend corresponds not only to the En-
glish while but also to during).
In the parsing client application, DiMLex
serves as resource for the identification of cue
phrases in specific structural configurations.
Rhetorical information from the DiMLex entries
may serve as one of several cues for the classi-
fication engine. The final linking from cue pat-
terns to rhetorical relations is learned from a
corpus annotated with rhetorical structures.
6 Summary
We have presented our ongoing work on con-
structing an XML-based dictionary of discourse
markers, from which a variety of views are de-
rived by XSL sheets: For the dictionary de-
signer or application developer, we present the
dictionary in tabular form or in a form resem-
bling print dictionaries, but with hyperlinks in-
cluded for easy cross-referencing. Similarly, text
generation and understanding systems are on
the one hand written in different programming
languages and thus expect different dictionary
formats; on the other hand, the information
needed for generation and parsing is also not
identical, which is accounted for by the XSL
sheets. Evaluation of the approach will depend
on the client applications. Their implementa-
tion will determine the final shape of DiMLex.
References
R.A. Amsler and F.W. Tompa, ?An SGML-
Based Standard for English Monolingual Dic-
tionaries.? In: Information in Text: Fourth
Annual Conference of the UW Center for the
New Oxford English Dictionary, University of
Waterloo Center for the New Oxford English
Dictionary, Waterloo, Ontario, 1988, pp. 61-
79.
N. Asher. Reference to Abstract Objects in Dis-
course. Dordrecht: Kluwer, 1993.
B. Grote, M. Stede. ?Discourse marker choice
in sentence planning.? In: Proceedings of
the Ninth International Workshop on Natural
Language Generation, Niagara-on-the-Lake,
Canada, 1998.
B. Grote. ?Signalling coherence relations: tem-
poral markers and their role in text genera-
tion.? Doctoral dissertation, Universita?t Bre-
men, forthcoming.
N. M. Ide, J. Le Maitre, and J. Ve?ronis, ?Out-
line of a Model for Lexical Databases.? In-
formation Processing and Management, 29, 2
(1993), 159-186.
N. M. Ide and J. Ve?ronis. Encoding Dictionar-
ies.Computers and the Humanities, 29:167-
180, 1995
N. M. Ide, Kilgarriff, A., and Romary, L.A For-
mal Model of Dictionary Structure and Con-
tent. In Proceedings of EURALEX 2000, pp.
113-126, Stuttgart.
A. Knott. ?A data-driven methodology for mo-
tivating a set of coherence relations.? Doc-
toral dissertation, University of Edinburgh,
1996.
W. Mann, S. Thompson. ?Rhetorical structure
theory: Towards a functional theory of text
organization.? In: TEXT, 8:243-281, 1988.
D. Marcu. ?The Rhetorical Parsing of Un-
restricted Natural Language Texts.?
Proceedings of the Thirty-Fifth Annual
Meeting of the Association for Computa-
tional Linguistics and Eighth Conference of
the European Chapter of the Association for
Computational Linguistics, Somerset, New
Jersey, 1997.
C. Paris, K. Van der Linden, M. Fischer, A.
Hartley, L. Pemberton, R. Power and D.R.
Scott, ?Drafter: A Drafting Tool for Produc-
ing Multilingual Instructions?, Proceedings of
the 5th European Workshop on Natural Lan-
guage Generation, pp. 239-242, Leiden, the
Netherlands, 1995.
M. Stede. ?Polibox: Generating, descriptions,
comparisons, and recommendations from a
database.? In Proceedings of COLING-2002.
L. Wanner, E. Hovy. ?The HealthDoc Sentence
Planner.? Proceedings of the 8th Interna-
tional Workshop on Natural Language Gen-
eration, Hearstmonceux Castle, 1996.
Web References
Domain Object Model
W3C Recommendation, 13 November 2000
http://www.w3.org/TR/DOM-Level-2-Core
Extensible Stylesheet Language (XSL) 1.0
W3C Recommendation, 15 October 2001
http://www.w3.org/TR/xsl
XML Base
W3C Recommendation 27 June 2001
http://www.w3.org/TR/xmlbase
XSL Transformations (XSLT) 1.0
W3C Recommendation, 16 November 1999
http://www.w3.org/TR/xslt
UI on the Fly: Generating a Multimodal User Interface
David Reitter
Media Lab Europe
Dublin, Ireland
{reitter,erin}@mle.media.mit.edu
Erin Marie Panttaja
Media Lab Europe
Dublin, Ireland
Fred Cummins
University College Dublin
Dublin, Ireland
fred.cummins@ucd.ie
Abstract
UI on the Fly is a system that dynami-
cally presents coordinated multimodal content
through natural language and a small-screen
graphical user interface. It adapts to the
user?s preferences and situation. Multimodal
Functional Unification Grammar (MUG) is a
unification-based formalism that uses rules to
generate content that is coordinated across sev-
eral communication modes. Faithful variants
are scored with a heuristic function.
1 Introduction
Multimodal user interfaces are everywhere. The use of
a keyboard and mouse on a desktop PC is ubiquitous,
if not natural. However, the click-then-type paradigm
of common interfaces misses the cross-modal synchro-
nization of timing and meaning that is evident in human-
human communication. With coordinated output, novice
users could get explanations (redundant content) and ex-
perienced users could receive additional (complemen-
tary) information, increasing the bandwidth of the inter-
face. Coordinated input (?put that there!?) speeds up in-
put and relieves speech recognition of notoriously hard-
to-recognize referring expressions such as names. If a
user interface is generated on the fly, it can adapt to the
situation and special needs of the user as well as to the
device.
While users are not necessarily prone to make multi-
modal inputs (Oviatt, 1999), they can still integrate com-
plementary output or use redundant output in noisy sit-
uations. Consequently, this paper deals with generating
output. We propose a grammar formalism that general-
izes decisions about how to deliver content in an adapt-
able multimodal user interface. We demonstrate it in the
context of a user interface for a mobile personal informa-
tion manager.
2 Related Work
Since Bolt?s (1980) Put-That-There system introduced
cross-modal coordination in multimodal user input, vari-
ous projects have investigated multimodal input and out-
put methods. Users display a preference for the touch-
screen in map-based positioning acts and object selection
(Oviatt et al, 1997). WIP (Andre? et al, 1993) and other
systems (Feiner and McKeown, 1990; Roth and Hefley,
1993) generate static multimodal documents. In an in-
teractive user interface, however, layout should remain
consistent (Woods and Roth, 1988, perceived stability).
SmartKom (Wahlster, 2002) is a recent effort that pro-
duces a multimodal user interface, using XML/XSLT
techniques to render the output. These are determinis-
tic, which makes soft constraints such as usability hard to
implement. SUPPLE (Gajos and Weld, 2004) overcomes
this problem in its model of the user and the expected
workload for various interfaces, generating a unimodal
(graphical) user interface without natural language gener-
ation elements. On the integration side, Johnston (1998)
presents a unification-based grammar that recasts multi-
modal signal fusion as a parsing problem.
Our approach employs a non-deterministic grammar to
derive variants which are evaluated with a comparatively
simple user and situation model according to their utility
(information conveyed) and the projected cognitive load
imposed on the user. It also removes the requirement in-
herent in Johnston?s system of explicitly defining rules to
integrate multimodal information.
In the following, we discuss the grammar formalism
used to create output, as well as consistency and adapta-
tion considerations.
3 Formalism
In this section, we will explain how the Multimodal Func-
tional Unification Grammar (MUG) allows us to generate
content. Our formalism and the associated evaluation al-
gorithm work closely with a dialogue manager. As in-
put, they receive an unambiguous, language- and mode-
independent representation of the next dialogue turn.
26
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
type askconfirmation
initiative implicit
experience novice
error none
action
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
type task
contexttype email
task
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
type send-email
email
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
type email
to
2
6
4
type contact
firstname Fred
lastname Cummins
3
7
5
cc
2
6
4
type contact
firstname Erin
lastname Panttaja
3
7
5
from
"
type emailaddress
adr reitter@mle.ie
#
subject
"
type text
content Aussie weather
#
body
"
type text
content G?day mates....-Dave
#
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
Figure 1: Input representation: confirmation of sending
of an email
3.1 Dialogue acts as input
Although the semantic input is independent of mode
(screen, voice) and language (Portuguese), the input se-
mantics are domain-specific. The representation uses the
following types of dialogue acts at the top level: ask for
missing information, ask for a confirmation of an action
or data, inform the user about the state of objects, or give
context-dependent help.
An example is shown in Figure 1. The input-FD spec-
ifies type of act in progress (askconfirmation), and the
details of the interaction type. It then specifies the details
of the current action, in this case, the email that the user
is sending.
Furthermore, the dialogue manager may indicate the
need to realize a certain portion of an utterance with an
attribute realize. The input format integrates with princi-
pled, object-oriented dialogue managers.
3.2 The domain: a personal assistant.
In this example, we have constructed a personal assistant
to be used in the domain of sending email messages.
We implemented a MUG for a PDA-size handheld de-
vice with a color touch-screen (see Figure 2a). The initial
steps to adapt it to a mobile phone (Figure 2b) involved
creating a device profile that uses no GUI widgets and
associates a higher cost (see Section 5) with the screen
(a) (b)
Figure 2: a) Voice: ?Do you want to send the email? Yes
or No??. b) Voice: ?Send the email regarding Aussie
weather to Fred Cummins now??
output, as the screen is smaller. All devices used have
server-driven TTS output capabilities.
3.3 The grammar
MUG is a collection of components. Each of them spec-
ifies a realization variant for a given partial semantic or
syntactic representation. This representation may be spe-
cific to a mode or general. We call these components
functional descriptions (FDs) in the tradition of the Func-
tional Unification Grammar (Kay, 1979), from which
MUG is derived.
For each output, the MUG identifies an utterance plan,
consisting of separate constituents in the output. For
example, when we ask for missing information (?Who
would you like to send the e-mail to??), the utterance con-
sists of an instruction and an interaction section. Such a
plan is defined in a component, as is each more specific
generation level down to the choice of GUI widgets or
lexicon entries.
MUG is based on the unification of such attribute-value
structures. Unification can be seen as a process that aug-
ments an FD with additional information. FDs are re-
cursive: a value can be atomic or a nested FD. Values in
an FD can be bound to the values in a substructure FD
(structure sharing).
To realize a semantic representation R, we unify a suit-
able grammar component FD with each m-constituent
substructure F in R, until all substructures have been ex-
panded. An m-constituent is an FD that has an attribute
path m|cat, that is, which has been designated as a con-
stituent for mode m. Note that zero or one grammar com-
ponents for a given mode can be unified with F .
Components from the grammar invoke each other by
instantiating the cat attribute in the mode-specific part of
a substructure. Figure 3 shows a component that applies
to all modes.
There may be several competing components in the
grammar. This creates the ambiguity needed to gener-
ate a variety of outputs from the same input. Each out-
put will be faithful to the original input. However, only
one variant will be optimally adapted to the given situa-
tion, user, and device (see Section 5). Our final markup
is text for the text to speech system as well as HTML to
be displayed in a browser, similar to the MATCH system
(Johnston et al, 2002).
The nested attribute-value structures and unification
are powerful principles that allow us to cover a broad
range of planning tasks, including syntactic and lexical
choices. The declarative nature of the grammar allows us
to easily add new ways to express a given semantic en-
tity. The information that each component has access to
is explicitly encapsulated by an FD.
A grammar workbench allows us to debug the genera-
tion grammar. We could improve the debugging process
with a type-hierarchy, which defines allowed attributes
for each type.
2
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
4
action 3
2
4
Mode
h
cat 1
i
type 1
3
5
instruction
2
6
6
4
action 3
Mode
"
cat confirm-mod
text 4
#
3
7
7
5
user-input
2
4Mode
"
cat yesnolist
text 5
#3
5
Mode
"
cat askconfirmation
text concat([ 4 , 5 ])
#
3
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
7
5
Figure 3: A MUG component that handles the confirma-
tion of tasks or user input. The mode in variable Mode
may be voice or screen.
4 Planning for Coherence
Coherence is a key element in designing a multimodal
user interface, where the potential for confusion is in-
creased. Our user interface attempts to be both consis-
tent and coherent. For example, lexical choice does not
vary: it is either ?mobile phone? or ?cell phone,? but it
is the same whether it is in text or voice. This is in line
with priming effects, which are known to occur in human-
human dialogue.
Like humans (McNeill, 1992; Oviatt et al, 1997),
our system aims to be coherent and consistent across all
modes. We present redundant content, for example, by
choosing the same lexical realizations (never mix cell
phone and mobile phone). We present complementary
input in linked components. If, for example, a deictic
expression such as these two e-mails (by voice) requires
the e-mails to be put in focus on the screen, it will set a
feature accordingly in the complementary mode.
This is possible because of a very simple principle en-
coded in the generation algorithm: all components real-
izing one semantic entity must unify. Components may
still specify mode-specific information. This is done in
a feature named after the mode, so it will not interfere
with the realization instructions of a component that real-
izes the same semantic entity in another mode. The FDs
allow us to distinguish information a) that needs to be
shared across all output modes, b) that is specific to a par-
ticular output mode, or c) that requires collaboration be-
tween two modes, such as deictic pronouns. The unifica-
tion principle replaces explicit integration rules for each
coordination scheme, such as the ones used by Johnston
(1998), which accounts for the integration of user input.
5 Adaptively Choosing the Best Variant
The application of the MUG generates several output
variants. They may include or exclude pieces of infor-
mation, which may be of more or less utility to the user.
(When information is being confirmed, it should be fully
described, but in later interactions, the email could be re-
ferred to as ?it.?)
For example, several components applied to the sub-
FD for task in Figure 1 may depend more on the screen
(Figure 2a) or be redundant in screen and voice output
(Figure 2b). This allows the system to reflect a low ben-
efit for output on the screen if the user is driving a car
or to increase the cost of voice output if the user is in a
meeting, or reflect the fact that one doesn?t hear the voice
output on a mobile phone while reading the screen.
The system adapts to the user?s abilities, her prefer-
ences, and the situation she is in by choosing an appro-
priate variant. These properties are scalar, and the result-
ing constraints are to be weighted against each other in
our objective function. Each piece of output is scored ac-
cording to a simple trade-off: a) realize content where re-
quested, b) maximize utility to the user, and c) minimize
cognitive load in perceiving and analyzing the output.
These constraints are formalized in a score that is as-
signed to each variant ?, given a set of available Modes
M , a situation model < ?, ? >, a device model ? and a
utility/time trade-off coefficient ?:
s(?) = ?
?
<e,d>?E(?)
u(e, d) +maxm?M (?mtm(?))
u(e, d) = P (d,
?
m?M
(?m?mem|realized), erealize)
The first part of the sum in s describes the utility ben-
efit. The function E returns a set of semantic entities
in e (substructures) and their embedding depths in d.
The function P penalizes the non-realization of requested
(attribute realize) semantic entities, while rewarding the
(possibly redundant) realization of an entity. The reward
decreases with the embedding depth d of the semantic en-
tity. (Deeper entities give less relevant details by default.)
The cognitive load (second part of the sum) is repre-
sented by a prediction of the time tm(?) it would take to
interpret the output. This is the utterance output time for
text spoken by the text-to-speech system, or an estimated
reading time for text on the screen.
Further work will allow us to cover the range of
novice to experienced users by relying on natural lan-
guage phrases versus graphical user interface widgets.
6 Conclusion
We have demonstrated a formalism that generates coher-
ent multimodal user interfaces, as well its application in
a small-screen email client. As the generation algorithm
makes use of both hard constraints and scalar scores, it
caters for adaptability. We have proven its functionality
and efficiency in a series of examples in the context of a
dialogue system, where content is generated in real-time
for various usage situations and different devices.
Further evaluation will show whether the fitness func-
tion can accurately mirror user satisfaction with a given
output variant and whether our form of adaptivity is ac-
tually an advantage to users on the go. Without a gold
standard for a generation system for dynamic multimodal
user interfaces to qualitatively compare against, con-
trolled user trials will allow us to evaluate the usability
of the interfaces we have created. Task completion times,
user frustration levels, and user satisfaction can then be
used to evaluate the success of this model of multimodal
interactions.
The underlying formalism is intended to be used in cre-
ating, using the MUG Workbench, any multimodal sys-
tem that can be constructed compositionally, using natu-
ral language and other auditory and visual components.
As possible examples for future applications, we see a
multimodal interface that allows mobile users or users
with sensory impairments to traverse information-rich so-
cial networks, and a kiosk for multimodal, multilingual
access to public transportation options.
7 Acknowledgement
The authors would like to thank Stefan Agamanolis,
Robert Dale, John Kelleher, Kerry Robinson, and the
anonymous reviewers. This research was partially funded
by the European Commission under the FASiL project,
contract number: IST-2001-38685.
References
E. Andre?, W. Finkler, W. Graf, T. Rist, A. Schauder, and
W. Wahlster. 1993. Wip: The automatic synthesis of
multimodal presentations. In M. T. Maybury, editor,
Intelligent Multimedia Interfaces. AAAI Press, Menlo
Park, CA.
Richard A. Bolt. 1980. Put-that-there:voice and gesture
at the graphics interface. In Proceedings of the 7th an-
nual conference on Computer graphics and interactive
techniques, pages 262 ? 270, Seattle.
Steven Feiner and Kathleen McKeown. 1990. Coordi-
nating text and graphics in explanation generation. In
Proc. of AAAI-90, pages 442?449, Boston, MA.
Krzysztof Gajos and Daniel S. Weld. 2004. Supple: Au-
tomatically generating user interfaces. In Proceedings
of IUI-2004, Funchal, Portugal.
M. Johnston, S. Bangalore, G. Vasireddy, A. Stent,
P. Ehlen, M. Walker, S. Whittaker, and P. Maloor.
2002. Match: An architecture for multimodal dialogue
systems. In Proceedings of ACL-2002.
Michael Johnston. 1998. Unification-based multimodal
parsing. In Proceedings of COLING-ACL 1998, pages
624?630.
Martin Kay. 1979. Functional grammar. In Proceedings
of the Fifth Meeting of the Berkeley Linguistics Society,
pages 142?158, Berkeley, CA.
David McNeill. 1992. Hand and mind: What gestures
reveal about thought. University of Chicago Press.
Sharon Oviatt, Antonella DeAngeli, and Karen Kuhn.
1997. Integration and synchronization of input modes
during multimodal human-computer interaction. In
Proceedings of the SIGCHI conference on Human
factors in computing systems, pages 415?422. ACM
Press.
Sharon Oviatt. 1999. Ten myths of multimodal interac-
tion. Communications of the ACM, 42(11):74?81.
Steven F. Roth and William E. Hefley. 1993. Intelligent
multimedia presentation systems: Research and princi-
ples. In M. T. Maybury, editor, Intelligent Multimedia
Interfaces. AAAI Press, Menlo Park, CA.
Wolfgang Wahlster. 2002. Smartkom: Fusion and fission
of speech, gestures, and facial expressions. In Pro-
ceedings of the 1st International Workshop on Man-
Machine Symbiotic Systems, Kyoto, Japan.
David Woods and Emilie Roth. 1988. Cognitive sys-
tems engineering. In M. Helander, editor, Handbook
of Human-Computer Interaction, pages 1?43. Elsevier,
North Holland.
Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics, ACL 2010, pages 9?17,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Did Social Networks Shape Language Evolution?
A Multi-Agent Cognitive Simulation
David Reitter
Department of Psychology
Carnegie Mellon University
Pittsburgh, PA, USA
reitter@cmu.edu
Christian Lebiere
Department of Psychology
Carnegie Mellon University
Pittsburgh, PA, USA
cl@cmu.edu
Abstract
Natural language as well as other commu-
nication forms are constrained by cogni-
tive function and evolved through a social
process. Here, we examine whether hu-
man memory may be uniquely adapted to
the social structures prevalent in groups,
specifically small-world networks. The
emergence of domain languages is simu-
lated using an empirically evaluated ACT-
R-based cognitive model of agents in a
naming game played within communi-
ties. Several community structures are ex-
amined (grids, trees, random graphs and
small-world networks). We present pre-
liminary results from small-scale simula-
tions, showing relative robustness of cog-
nitive models to network structure.
1 Introduction
A language, even if shared among the members
of a community, is hardly static. It is constantly
evolving and adapting to the needs of its speak-
ers. Adaptivity in natural language has been found
at various linguistic levels. Models of dialogue
describe how interlocutors develop representation
systems in order to communicate; such systems
can, for instance, be observed using referring ex-
pressions such as the wall straight ahead that iden-
tify locations in a maze. Experiments have shown
that communities converge on a common standard
for such expressions (Garrod and Doherty, 1994).
Models of the horizontal transmission of cul-
tural information within generations show on a
much larger scale how beliefs or communicative
standards spread within a single generation of hu-
mans. Recently, language change has accelerated
through the use of communication technologies,
achieving changes that used to take generations
in years or even months or weeks. However, the
structure of electronic networks mimics that of
more traditional social networks, and even com-
munication via mass media follows a power-law-
driven network topology.
The individual agents that are effecting the lan-
guage change depend on their cognitive abilities
such as memory retrieval and language processing
to control and accept novel communication stan-
dards. Do the local, cognitive constraints at the
individual level interact with the structure of large-
scale networks? Both social structure and individ-
ual cognitive systems have evolved over a long pe-
riod of time, leading to the hypothesis that certain
network structures are more suitable than others to
convergence, given the specific human cognitive
apparatus. Some properties of human cognition
are well established, e.g., in cognitive frameworks
(Anderson et al, 2004). Was human cognition
shaped by social networks? Why are memory pa-
rameters the way they are? Social network struc-
tures may hold an answer to this question. If so,
we should find that naturally occurring networks
structures are uniquely suited to human learning,
while others will perform less well when human
learners are present.
The environment may have been influenced by
individual cognition as well. Why are social net-
works structured the way they are? Human mem-
ory and possibly human learning strategies are
the result of an evolutionary process. Social net-
work structures can be explained by models such
as Preferential Attachment (Barabasi and Albert,
1999), yet, even that is tied to evolved distribu-
tions of preferences in human agents. Dall?Asta
et al (2006) argue that the dynamic of agreement
in small-world networks shows, at times, proper-
ties that ease the (cognitive) memory burden on
the individuals. It is possible that the human mem-
ory apparatus and social preferences governing
network structures have co-evolved. Such a the-
ory would, again, suggest the hypothesis underly-
9
ing this study: that network structure and human
memory are co-dependent.
2 Modeling Language Change
Network structure, on a small scale, does influ-
ence the evolving patterns of communication. The
dichotomy between individual and community-
based learning motivated experiments by Garrod
et al (2007) and Fay et al (2010), where partic-
ipants played the Pictionary game. In each trial
of this naming game, each participant is paired up
with another participant. One of them is then to
make a drawing to convey a given concept out of
a small set of known concepts; the other one is to
select the concept from that list without engaging
in verbal communication. Over time, participants
develop common standards codifying those con-
cepts: they develop a system of meaning-symbol
pairs, or, signs. We take this system as the lex-
ical core of the shared language. The conver-
gence rate and the actual language developed dif-
fered as a function of the structure of the small
participant communities: Fay (2010) either asked
the same pairs of participants to engage in the
activity repeatedly, or matched up different pairs
of participants over time. Fay and Garrod?s Pic-
tionary experiments served as the empirical basis
for a cognitive process model developed by (Reit-
ter and Lebiere, 2009). Our model has agents pro-
pose signs by combining more elementary signs
from their divergent knowledge bases, and also
adopt other agent?s proposals of signs for later re-
use. The model, designed to match Fay?s com-
munities, was studied in a condition involving
groups of eight agents, with two network struc-
tures: maximally disjoint with the same pairs of
agents throughout the simulation, and maximally
connected, with interactions between all possible
pairs of agents.
Reitter and Lebiere?s (2009) cognitive model re-
flects the Pictionary game. The model explains
the convergence as a result of basic learning and
memory retrieval processes, which have been well
understood and made available for simulation in a
cognitive modeling framework, ACT-R Anderson
et al (2004). Thus, properties of human memory
and of the agent?s learning strategies dictate how
quickly they adopt signs or establish new signs:
processes such as learning, forgetting and noise to-
gether with their fundamental parameters that are
within well-established ranges provide strong con-
straints on the behavior of each agent and in turn
the evolution of their communication within the
network. This approach acknowledges that cul-
tural evolution is constrained by individual learn-
ing; each agent learns according to their cognitive
faculty (cf., Christiansen and Chater, 2008). With
non-cognitive models, language change has been
simulated on a larger scale as well (e.g., Kirby and
Hurford, 2002; Brighton et al, 2005).
It is because adaptation according to experi-
ence is determined by human learning behav-
ior that simulation in validated learning frame-
works is crucial. Griffiths and Kalish (2007)
for instance model language evolution through
iteration among rational learners in a Bayesian
framework; the purpose of the present project is
to tie the simulation of language evolution to a
concrete experiment and a more process-oriented
cognitive architecture than the Bayesian frame-
work. ACT-R?s learning mechanisms extend the
Bayesian view with at least a notion of recency.
Work on language processing has pointed out its
relationship to memory retrieval from within the
ACT-R framework, both for language comprehen-
sion (Budiu and Anderson, 2002; Lewis and Va-
sishth, 2005; Crescentini and Stocco, 2005; Ball
et al, 2007) and for language production (Reitter,
2008). The individual language faculty as a result
of biological evolution and adaptation to cultural
language has been the focus of psycholinguis-
tic models proposing specialized mechanisms (the
Chomskian viewpoint); our model does not pro-
pose a specialized mechanism but rather declara-
tive memory as store for lexical information, and
procedural cognitive processes as regulators of
certain communicative functions. Our multi-agent
model sees part of the linguistic process as an in-
stantiation of general cognition: the composition
and retrieval of signs follows general cognitive
mechanisms and can be formulated within cogni-
tive frameworks such as ACT-R (Anderson et al,
2004) or SOAR (Laird and Rosenbloom, 1987).
In this study, we adapted the 2009 model and
simulated language convergence in several larger-
scale networks. We investigate the relationship
between human memory function in the retrieval
of linguistic items and the structure of social net-
works on which humans depend to communicate.
10
3 Network structures
Differences in naturally occurring social networks
are hardly as extreme as in Fay?s experiment.
Some agents will be connected to a large number
of other ones, while many agents will have just a
few connections each. Concretely, the number of
interaction partners of a randomly chosen commu-
nity member is not normally distributed and cen-
tered around a mean. It shows a (Zipfian) power
law distribution, with a number of hubs attracting
many network neighbors, and a long tail of sub-
jects interacting with just a few other ones each.
Social networks are small world networks: the av-
erage distance between any two nodes in the net-
works is low, since many of them are connected to
hubs. Non-organically connected communication
and command networks follow other normals?tree
graphs for instance. However, natural communica-
tion standards develop in networks that have very
specific properties that can be observed in most or-
ganically developed networks.
Realistic social networks commonly show very
specific properties. Social networks, in which
links symbolize communication pathways or some
form of social acquaintance, frequently exhibit the
small world property. The mean minimum dis-
tance between any two nodes is relatively low, and
the clustering coefficient is high (Watts and Stro-
gatz, 1998).
Other forms of networks include tree hierar-
chies with a constant or variable branching factor
(directed acyclic graphs). Such networks ressem-
ble communication and command hierarchies in
military or business organizations. N-dimensional
grid networks have nodes with constant degrees,
which are connected to each of their two neigh-
bors along each dimension in a lattice.
Much work on information or belief propaga-
tion, or decision-making in networks has used
large artificial networks modeled after social ones;
nodes in such networks are commonly simple
agents that make decisions based on input fed to
them by their neighbor nodes and pass on infor-
mation. These often state-less agents do not nec-
essarily employ learning or adaptivity, and when
they do, learning does not reflect known cognitive
properties of human memory. The mechanisms
governing learning and retrieval in human mem-
ory have been studied in detail, leading to formal
models of process that detail the units that may be
stored in and retrieved from memory, the retrieval
time and accuracy depending on the frequency and
recency of prior rehearsals, on contextual cues that
may facilitate retrieval, and on individual differ-
ences. Cognitive agents can serve as a more real-
istic basis for network simulations (Sun, 2001).
Frequency, recency, contextual cues and chunk-
ing of the stored information determine retrieval
probability, which is crucial when novel idioms
are required to express meaning in communica-
tion. The process leads to the choice of one of
several available synonyms. Our model sees this
decision-making process as a matter of memory
retrieval: given the desired meaning, which sign
(word or drawing, compound noun or drawings)
can be used to express it. This process is implicit
(not consciously controlled), and it follows re-
cent suggestions from cognitive psychology: Pick-
ering and Garrod?s (2004) Interactive Alignment
Model proposes that explicit negotiation and sepa-
rate models of the interlocutor?s mental state aren?t
necessary, as long as each speaker is coherent and
adapts to their interlocutors, as speakers are known
to do on even simple, linguistic levels (lexical,
syntactic). This shifts the weight of the task from
a sophisticated reasoning device to the simpler,
more constrained implicit learning mechanism of
the individual.
The social network controls the interactions that
the agents can experience. Each interaction is an
opportunity to develop new signs and adapt the ex-
isting communication systems. It can be shown
that even separate pairs of agents develop spe-
cialized communication systems, both empirically
(Garrod and Doherty, 1994; Reitter and Moore,
2007; Kirby and Hurford, 2002) and in the specific
model used here.When communication partners
change, convergence towards a common system
and the final transmission accuracy is slower (Fay
et al, 2008). At this point it is unclear how the
structure of the communication network and the
learning process interact. Given that some types
of networks show a wide distribution of degrees,
where some nodes communicate much more often
and with a wide variety of neighbors, while others
communicate less often, recency and frequency of
memory access will vary substantially. Other com-
munication networks may reflect command hier-
archies in organizations, which are constructed to
ensure, among other things, more predictable in-
formation propagation.
We hypothesize that the human memory ap-
11
paratus and preferred social network structures
have co-evolved to be uniquely suited to create
a macro-organism that adapts its communication
structures and reasoning mechanisms to novel sit-
uations. There is limited opportunity to test such a
hypothesis under controlled conditions with a suf-
ficiently large human network; however, cognitive
models that have been developed to explain and
predict human performance in isolated cognitive
situations can be leveraged to study the develop-
ment of sign systems.
In a simulated network with cognitive mod-
els representing agents at the network nodes,
and communication between agents along network
links, we expect that the social network structures
lead to better, if not optimal, adaptivity during the
establishment of a communication system. We ex-
pect that scale-free small world networks do best,
outperforming tree hierarchies, random networks
and regular grids (lattices).
3.1 Architecture
ACT-R?s memory associates symbolic chunks of
information (sets of feature-value pairs) with sub-
symbolic, activation values. Learning occurs
through the creation of such a chunk, which is
then reinforced through repeated presentation, and
forgotten through decay over time. The symbolic
information stored in chunks is available for ex-
plicit reasoning, while the subsymbolic informa-
tion moderates retrieval, both in speed and in re-
trieval probability. The assumption of rationality
in ACT-R implies that retrievability is governed
by the expectation to make use of a piece of in-
formation at a later point. Important to our ap-
plication, retrieval is further aided by contextual
cues. When other chunks are in use (e.g., parlia-
ment), they support the retrieval of related chunks
(building).
The properties of memory retrieval in terms of
time and of retrieval success are governed by the
activation of a chunk that is to be retrieved. Three
components of activation are crucial in the context
of this model: base-level activation, spreading ac-
tivation and transient noise (). Base-level activa-
tion is predictive of retrieval probability indepen-
dent of the concurrent context. It is determined by
the frequency and recency of use of the particular
chunk, with tj indicating the time elapsed since
use k of the chunk. d indicates a base-level decay
parameter, usually 0.5):
HOSPITAL
PARAMEDIC
FIRE STATION
Figure 1: Example of a small ontology with ab-
stract concepts (spelled-out words) and concrete
ones (drawings).
Ai = log
pres?
k=1
t?dk +
cues?
j
wjSji + 
Retrieval is contextualized by cues available
through spreading activation. It is proportional
to the strengths of association (Sji) of all of the
cues with the target chunk. While the base-level
term (first term of the sum) can be seen as a prior,
spreading activation models the conditional proba-
bility of retrieval given the available cues. Finally,
 is sampled from a logistic distribution shaped by
canonical parameters. Ai must surpass a minimum
retrieval threshold.
The model is implemented using the ACT-UP
toolbox, which makes the components of the ACT-
R theory are directly accessible. The cognitive
model does not specify other model components
(perceptual, manual, procedural), as they are nei-
ther subject to evaluation nor considered to make a
significant contribution to learning or convergence
effects.
3.2 Communication model
We assume that the communication system, or
language, is a system of signs. Concretely, it is
a set of tuples (signs), each associating a mean-
ing with a set of up to three symbols (a simpli-
fying assumption). If the communication system
uses natural language, symbols consist of spoken
or written words. The communication system es-
tablished by the participants of Garrod?s and Fay?s
12
experiments uses drawings as symbols?the princi-
ple stays the same. Agents start out with a knowl-
edge base containing signs for concrete concepts
that are immediately representable as drawings or
nouns; the target concepts to be conveyed by the
participants, however, are more abstract and re-
quire the combination of such concrete concepts.
A concept such as hospital, for instance, could in-
volve the drawings for house, ambulance, and a
sad face. A participant could choose among many
ways to express hospital.
The goal of our cognitive models is to com-
municate meaning from one agent to another one.
Put in natural language-oriented terminology, the
director role is the speaker, a role that involves
selecting the right concrete concepts that can ex-
press a given target concepts; the matcher role (lis-
tener) involves decoding the concrete drawings (or
words) to retrieve the target.
A single ACT-R model implements the director
and matcher roles. As a director, the model es-
tablishes new combinations of drawings for given
target concepts. As a matcher, the model makes
guesses. In each role, the model revises its internal
mappings between drawings and target concepts.
The model is copied to instantiate a community of
agents, one for each node in the network.
The simplest form of representing a communi-
cation system in ACT-R memory chunks is as a set
of signs. Each sign pairs a concept with a set of
drawings. Competing signs can be used to assign
multiple drawings for one conceptTo reflect se-
mantic relationships, we need to introduce a sub-
symbolic notion of relatedness. We use ACT-R?s
spreading activation mechanism and weights be-
tween concepts to reflect relatedness. Spreading
activation facilitates retrieval of a chunk if the cur-
rent context offers cues related to the chunk. Re-
latedness is expressed as a value in log-odds space
(Sji values).
When the model is faced with the task to draw
a given concept such as Russell Crowe (one of the
concepts in the experiment) or Hospital (as in Fig-
ure 1) that has no canonical form as a drawing,
a related but concrete concept is retrieved from
declarative memory (such as Syringe in the exam-
ple). In drawing-based communication, this would
be a concept that can be drawn, while in natural-
language based communication, this is an existing
drawing expressing a similar, partial or otherwise
related concept. We request two other such con-
cepts, reflecting the desire of the communicator
to come up with a distinctive rather than just fit-
ting depiction of the target concept. The case of a
model recognizing a novel combination of draw-
ings is similar; we retrieve the concept using the
drawings as cues that spread activation, making
the target concept the one that is the most related
one to the drawings.
After drawings have been produced or recog-
nized and mapped to a target, the target or guessed
concept, along with the component drawings, is
stored symbolically in memory as a chunk for
later reuse (domain sign). These signs differ from
the pre-existing concepts in the network, although
they also allow for the retrieval of suitable draw-
ings given a concept, and for a concept given some
drawings. When drawing or recognizing at a later
stage, the memorized domain signs are strictly
preferred as a strategy over the retrieval of related
concepts. The system of domain signs encodes
what is agreed upon as a language system between
two communicators; they will be reused readily
during drawing when interacting with a new part-
ner, but they will be of only limited use when at-
tempting to recognize a drawing combination that
adheres to somebody else?s independently devel-
oped communication system.
Thus, the model has two avenues to express and
recognize an abstract concept: by associative re-
trieval and by idiomatic domain concept. A mes-
sage constructed by domain concept retrieval is
often decoded by the matcher by association, and
vice versa.
The identification accuracy of the model shows
characteristics observed in empirical work (Fay et
al. 2008). See Reitter and Lebiere (subm) for a de-
tailed description of the model and its evaluation.
3.3 Knowledge
Agents start out with shared world knowledge.
This is expressed as a network of concepts, con-
nected by weighted links (Sji). The distribution
of link strengths is important in this context, as it
determines how easily we can find drawing combi-
nations that reliably express target concepts. Thus,
the Sji were sampled randomly from an empir-
ical distribution: log-odds derived from the fre-
quencies of collocations found in text corpus data.
From the Wall Street Journal corpus we extracted
and counted pairs of nouns that co-occurred in the
same sentence (e.g., ?market?, ?plunge?). As ex-
13
ID accuracy (empirical)
42 Games over 7 rounds
Iden
tific
atio
n ac
cura
cy
0.75
0.80
0.85
0.90
0.95
0 10 20 30 40
Communities
Isolated Pairs
42 Games over 7 rounds
Iden
tifica
tion 
accu
racy
0.65
0.70
0.75
0.80
0.85
10 20 30 40
Communities
Isolated Pairs
Figure 2: Identification accuracy for isolated
pairs and communities: (a) human data as pro-
vided by Fay (p.c.), (b) simulation. One-tailed
standard-error based 95% confidence intervals
(upper bounds for communities, lower bounds for
pairs) for human data; two-tailed 95% via boot-
strapping for simulations. As in the human data,
both community pairs and isolated pairs converge
most in the early rounds, but community pairs lose
much accuracy when switching partners.
pected, the frequencies of such collocations are
distributed according to a power law.
Such knowledge is, however, not fully shared
between agents. Each agent has their own knowl-
edge network resulting from life experience. This
difference is essential to the difficulty of the task:
if all agents came to the same conclusions about
the strongest representation of target concepts,
there would be little need to establish the domain
language. We control the noise applied to the
link strengths between concepts j and i for agent
M (SMji ) by combining the common ground Sji
(shared between all agents) with a random sample
NMji in a mixture model: S
M
ji = (1 ? n)Sji +
nNMji ; sign identification accuracy was found to
be stable for n up to about 0.4; we set it to 0.3 for
Simulation 1.
4 Simulation 1
Networks of individual cognitive agents were cre-
ated to differentiate performance between four dif-
ferent network structures. Random networks
contain N nodes with randomly assigned links
between them, on average d links for each node
(Erdo?s and Re?nyi, 1959). n-dimensional Grids
contain N nodes with a constant numer of links
d per node, with links between neighbors along
each dimension. The width w is kept the same
along each dimension, i.e. there are w nodes per
row. We use 6-dimensional lattices. Trees are di-
rected acyclic graphs with 1 link leading up, and
d ? 1 links (branching factor) leading down the
hierarchy of a total of N nodes. Scale-free net-
works are constructed using the preferential at-
tachment method as follows (Barabasi and Albert,
1999). N nodes are created and each is connected
to one randomly selected other node. Then, two
links< a, b > and< a?, b? > are chosen randomly
out of the existing set of links, and a new link
< a, b? > is added, until the mean degree d (links
per node) is reached. Preferential attachment en-
sures that nodes with a high number of links ac-
quire further links more quickly than other nodes
(the rich get richer). This yields a power-law dis-
tribution of degrees. Our scale-free networks dis-
play small world properties.
For the first Simulation, we control N at 85 and
d at 5 1. 35 iterations were simulated in each trial;
20 trials were run. During each round, each agent
(network node) plays one game (16 concepts) with
one of its neighbors. The order of neighbors is
shuffled initially, but constant across the rounds.
A variable Round coded iterations from 1to35.
Results Figure 3 shows the learning curve for
agent pairs in the four networks. Agents in all net-
works converge. Confidence intervals obtained via
bootstrapping indicated no apparent differences at
any specific iteration. A linear model was fit-
ted estimating the effects of network type over-
all (as a baseline) for each of the four types. It
also fitted interactions of iteration (1?35) with the
network types, which indicate significant learn-
ing effects as follows. For each network type,
we found a significant learning effect (effect of
Round) (? 0.002, p < 0.001).
Planned comparisons of the learning rate in
Small World networks revealed no difference with
either of the other three network types (p > 0.3).
1We found that networks need to be sufficiently large to
display meaningful differences in community structure. The
sizes were chosen to be computationally feasible (4h/CPU
core per network).
14
iteration
Iden
tifica
tion 
accu
racy
0.6
0.7
0.8
0 10 20 30
grid
smallworld
tree
random
Figure 3: Identification accuracy between con-
nected agents for communities of different net-
work structures.
5 Simulation 2
The success of a community is not only deter-
mined by how successfully individuals communi-
cate in their local environment, that is, with their
network neighbors. Communities require commu-
nicative success outside of well-acquainted agents.
Agents? languages would ideally converge on a
global scale. One way to test this is to have ran-
domly paired agents play the Pictionary game at
regular intervals throughout the game and thus
measure identification accuracy outside of the net-
work that defines the social structure.
This simulation was identical to Simulation 1,
except that we scaled up the simulation to examine
whether the lack of effect was possibly due to size
or density of the nodes (N = 512, d = 6, noise
level: 0.2, repetitions: 20). In this simulation, we
measured ID accuracy between pairs of randomly
chosen agents after each round. For three network
types, Grid, Small World and Random we found
significant interactions with round, i.e. significant
convergence, (all ? > 0.016, z > 2.1, p < 0.05).
For the network type Tree we found no significant
interaction (? = 0.012, z = 1.55, p = 0.12).2
2All regressions in this simulation where (generalized)
mixed-effects models, with ID accuracy as response via logit
link, Round as predictor, and Condition as factor for four net-
work types. A random intercept was fitted, grouped by repeti-
tion (1?20), to account for repeated measures. The predictor
was centered; no substantial collinearity remained. The anal-
ysis of Simulation 1 was a simple linear model; ID accuracy
iteration
ID a
ccur
acy 
of ra
ndom
ly pa
ired 
agen
ts
0.60
0.65
0.70
0 10 20 30
grid
smallworld tree
random
Figure 4: (Aggregate) Identification accuracy be-
tween random agent pairs for communities of dif-
ferent network structures.
To test the initial hypothesis, we re-coded the
conditions with a SmallWorld factor, contrasting
the small world networks with all other conditions.
We found an effect of Round (? = 0.017, z =
3.66, p < 0.001), indicating convergence, but no
interaction with SmallWorld (? = ?0.00027, z =
?0.03, p = 0.98).3
Results Figure 4 shows network-global conver-
gence. Again, a linear model was fitted to estimate
the learning rate in different network types (inter-
action of network type and iteration) (baseline in-
tercepts were fitted for each network type). We
found significant interactions with iteration for the
following network types: Grid (? = 0.004, p <
0.001), Small World (? = 0.003, p < 0.01), and
Random (? = 0.003, p < 0.005), but not for Tree
(p = 0.991).
Planned comparisons revealed an interaction of
network type and iteration for Tree compared to
Small World (? = ?0.003, p < 0.05), but not
for Grid nor Random compared to Small World
(p > 0.35). This indicates slower across-network
convergence for trees than for small worlds. It also
suggests that convergence across the network does
not differ much between grids, random networks
and small worlds.
was, for all levels, not near either extreme (? = 0.77).
3Further, unreported, experiments, showed a similar pic-
ture with a smaller network as in Simulation 1.
15
6 Discussion
We find that convergence is relatively stable across
the four network types. Analyzing the differences
between the networks, we find that the average de-
gree, which was controlled for grids, random net-
works and small worlds, was substantially lower
for trees (d = 1.9) due to the large number of
leaves with degree 1. This (or the correlated al-
gebraic connectivity of the network) may prove to
be a deciding correlate with cross-network conver-
gence. Other metrics, such as the clustering coef-
ficient (Watts and Strogatz, 1998), which gives an
indication of the degree of neighborhood cohesion
We see these results still as preliminary. More
work needs to be done to investigate how well
learning scales with network growth, and how net-
work analytics such as clustering coefficients af-
fect the dispersion of information.
Further work will explore range of networks
and the possibly unique suitability of human learn-
ing mechanisms to succeed in such networks. We
will explore the (subsymbolic) parameters govern-
ing adaptation, and to what extend the quantitative
parameters we find universal to humans are sub-
stantially optimized to deal with the small-world
networks and pareto degree-distributions found in
human communities.
7 Conclusion
Cognition may appear to be adapted to the so-
cial structures prevalent in communities of flocks,
packs and human teams. There are many reasons
why such social structures themselves could have
evolved; if cognitive constraints play a role, we ex-
pect it to be only a small factor among many. The
present simulation results certainly do not support
this view: they are much more compatible with
a humans-as-generalists theory that proposes that
humans have evolved to handle a variety of net-
work structures well, or that their recency- and
frequency-based learning mechanism is not spe-
cialized.
Learning, if adapted to social structure in any
way, may go beyond the current, mechanistic
and implicit mechanisms implemented in ACT-R
and comparable theories: learning may rely on
more explicit strategies, analyzing one?s interac-
tion partners and their current knowledge, and it
needs to judge information according to its sources
(trust). Meta-cognition could also play a role in
determining when a set of signs is substantially
novel and better than the current system, and thus
worth enduring the cost of switching from a settled
set of language conventions.
We have evaluated only a small, initial part of a
co-evolution theory we proposed. Also, the prob-
lem we describe may be best operationalized at
a higher abstraction level: Consensus problems
and information spread have been intensively stud-
ied (e.g., Latora and Marchiori, 2001; Wu et al,
2004). Comparing community convergence in a
number of differently-structured networks, so far
we see little evidence supporting our hypothesis,
namely that cognition (memory) has specialized to
accommodate social structures as defined by con-
temporary network science, and that those struc-
tures accommodate cognitive properties. Instead,
we find that the simulated cognitive agents con-
verge in their communication systems quite well
regardless of the network structures, at least as
long as those networks are relatively small and of
similar average degrees.
Acknowledgments
This work was funded by the Air Force
Office of Scientific Research (MURI grant
FA95500810356).
References
Anderson, J. R., Bothell, D., Byrne, M. D., Dou-
glass, S., Lebiere, C., and Quin, Y. (2004). An
integrated theory of mind. Psychological Re-
view, 111:1036?1060.
Ball, J., Heiberg, A., and Silber, R. (2007). Toward
a large-scale model of language comprehension
in act-r 6. In Proceedings of the 8th Interna-
tional Conference on Cognitive Modeling, Ann
Arbor, MI.
Barabasi, A. L. and Albert, R. (1999). Emer-
gence of scaling in random networks. Science,
286(5439):509?512.
Brighton, H., Smith, K., and Kirby, S. (2005).
Language as an evolutionary system. Physics
of Life Reviews, 2(3):177?226.
Budiu, R. and Anderson, J. R. (2002). Compre-
hending anaphoric metaphors. Memory & Cog-
nition, 30:158?165.
Christiansen, M. H. and Chater, N. (2008). Lan-
guage as shaped by the brain. Behavioral and
Brain Sciences, 31(5):489?509.
16
Crescentini, C. and Stocco, A. (2005). Agramma-
tism as a failure in the lexical activation process.
In Proceedings of the 27th Annual Conference
of the Cognitive Science Society.
Dall?Asta, L., Baronchelli, A., Barrat, A., and
Loreto, V. (2006). Agreement dynamics on
small-world networks. EPL (Europhysics Let-
ters), 73(6):969.
Erdo?s, P. and Re?nyi, A. (1959). On random
graphs. I. Publ. Math. Debrecen, 6:290?297.
Fay, N., Garrod, S., and Roberts, L. (2008). The
fitness and functionality of culturally evolved
communication systems. Philosophical Trans-
actions of the Royal Society B: Biological Sci-
ences, 363(1509):3553?3561.
Fay, N., Garrod, S., Roberts, L., and Swoboda,
N. (2010). The interactive evolution of hu-
man communication systems. Cognitive Sci-
ence, 34(3):351?386.
Garrod, S. and Doherty, G. M. (1994). Conversa-
tion, co-ordination and convention: An empir-
ical investigation of how groups establish lin-
guistic conventions. Cognition, 53:181?215.
Garrod, S., Fay, N., Lee, J., Oberlander, J., and
Macleod, T. (2007). Foundations of represen-
tation: Where might graphical symbol systems
come from? Cognitive Science, 31(6):961?987.
Griffiths, T. L. and Kalish, M. L. (2007).
Language evolution by iterated learning with
Bayesian agents. Cognitive Science, 31(3):441?
480.
Kirby, S. and Hurford, J. (2002). The emergence
of linguistic structure: An overview of the it-
erated learning model. In Cangelosi, A. and
Parisi, D., editors, Simulating the Evolution of
Language, chapter 6, pages 121?148. Springer
Verlag, London.
Laird, J. E. and Rosenbloom, P. S. (1987). Soar:
An architecture for general intelligence. Artifi-
cial Intelligence, 33(1):1?64.
Latora, V. and Marchiori, M. (2001). Efficient
behavior of small-world networks. Phys. Rev.
Lett., 87(19):198701.
Lewis, R. L. and Vasishth, S. (2005). An
activation-based model of sentence processing
as skilled memory retrieval. Cognitive Science,
29:1?45.
Pickering, M. J. and Garrod, S. (2004). Toward
a mechanistic psychology of dialogue. Behav-
ioral and Brain Sciences, 27:169?225.
Reitter, D. (2008). Context Effects in Language
Production: Models of Syntactic Priming in Di-
alogue Corpora. PhD thesis, University of Ed-
inburgh.
Reitter, D. and Lebiere, C. (2009). Towards ex-
plaining the evolution of domain languages with
cognitive simulation. In Proceedings of the 9th
International Conference on Cognitive Model-
ing (ICCM), Manchester, UK.
Reitter, D. and Lebiere, C. (subm.). Towards ex-
plaining the evolution of domain languages with
cognitive simulation. Cognitive Systems Re-
search.
Reitter, D. and Moore, J. D. (2007). Predict-
ing success in dialogue. In Proceedings of the
45th Annual Meeting of the Association of Com-
putational Linguistics (ACL), pages 808?815,
Prague, Czech Republic.
Steedman, M. (2000). The Syntactic Process. MIT
Press, Cambridge, MA.
Sun, R. (2001). Cognitive science meets multi-
agent systems: A prolegomenon. Philosophical
Psychology, 14(1):5?28.
Watts, D. J. and Strogatz, S. H. (1998). Collective
dynamics of /?small-world/? networks. Nature,
393(6684):440?442.
Wu, F., Huberman, B. A., Adamic, L. A., and
Tyler, J. R. (2004). Information flow in social
groups. Physica A: Statistical and Theoretical
Physics, 337(1-2):327 ? 335.
17
Proceedings of the 2014 ACL Workshop on Cognitive Modeling and Computational Linguistics, pages 55?62,
Baltimore, Maryland USA, June 26 2014.
c?2014 Association for Computational Linguistics
Linguistic Adaptation in Conversation Threads:
Analyzing Alignment in Online Health Communities
Yafei Wang, David Reitter, and John Yen
Information Science and Technology
Penn State University
University Park, PA, 16801
yxw184@ist.psu.edu, reitter@psu.edu, jyen@ist.psu.edu
Abstract
Previous studies of alignment have
focused on two-party conversations. We
study multi-party conversation in online
health communities, which have shown
benefits for their members from forum
conversations. So far, our understanding
of the relationship between alignment in
such multi-party conversations and its
possible connection to member benefits
has been limited. This paper quantifies
linguistic alignment in the oldest and the
largest cancer online forum. Alignment
at lexical and syntactic levels, as well as
decay of alignment was observed in forum
threads, although the decay was slower
than commonly found in psycholinguistic
studies. The different pattern of adaptation
to the initial post on a thread suggests that
specific roles in the online forum (e.g.,
seeking support from the community) can
potentially be revealed through alignment
theory and its extensions.
1 Introduction
Linguistic alignment leads conversation partners
to adapt their language patterns to match their
conversation partners. Such patterns comprise of
word choice, sentence structure, and more. For
example, if one conversation partner uses passive
voice in the conversation, other conversation
participants tend to use passive voice at a later
point in time. The mechanism of adaptation are
better understood now (Bock and Griffin, 2000;
Pickering and Ferreira, 2008; Kaschak et al.,
2011a; Reitter et al., 2011). The Interactive
Alignment Model (IAM) (Pickering and Garrod,
2004) attributes dialogic function to the priming
effect; it suggests that adaptation helps people
reach mutual understanding. Some recent studies
(Reitter and Moore, 2007; Fusaroli et al., 2012)
lend empirical confirmation to this thesis.
Repetition effects are not purely mechanistic.
They are sometimes moderated in response to
situational requirements or framing. For example,
they can vary in strength when humans (believe
to) communicate with computers (Branigan et al.,
2010). Repetition intensifies when the purpose of
conversation is to collaborate on a common task
(Reitter et al., 2006). Of course, communication
between individuals is more than a linguistic
event; it is also social. For example, it can be
found as a cue to social relationships in film scripts
(Danescu-Niculescu-Mizil and Lee, 2011). A
more specific aspect of language-based interaction
is pragmatic convention in multi-party dialogue,
which determines turn-taking, shifts in topic, and
more.
One would expect alignment to also occur in
social situations involving multiple speakers. The
social moderators and functions of adaptation
effects, however, are largely unclear. The question
we ask in this paper is whether alignment is
moderated by the role of a speaker?s contribution
to the conversation. In this paper, we deal with
written interaction only; our data are internet
forum conversations.
The first question is whether linguistic
adaptation exists in online communities and
online groups. Dialogues in threads of online
communities are different from previous types of
dialogues. Unlike some spontaneous, free-form
dialogues, threaded conversations have specific
topic. In addition, thread conversations do not
have specific tasks. Therefore, we investigate
whether dialogues in the threads also exhibit
linguistic adaptation, be it as an artifact of
mechanistic language processing or because
adaptation acts as a social or conversational signal.
Adaptation tends to decay over time, although this
decay has not been studied in the context of such
55
slow, asychronuous communication. Therefore,
we will characterize the time-scale of dacay.
More generally, if alignment exists in forums, is it
correlated with the communicative role of a text
or the social role of its author?
The contributions of this paper are: (1)
an exploratory analysis of linguistic adaptation
based on 3,000 conversations threads and 23,045
posts in an online cancer survivor community
(http://csn.cancer.org). Specifically,
we find reliable linguistic adaptation effects in
this corpus. (2) We show that properties of
conversation threads that are different from regular
conversations.
In the following sections, we first survey related
work on linguistic adaptation. Then, we describe
our data and make preliminary definitions. We
then introduce measures of linguistic adaptation.
Last, we discuss a set of properties in online
thread conversations which are unlike other types
of dialogues.
2 Related Work
Linguistic alignment phenomenon in social
interaction has been well explored in previous
literature. It happens because of multiple reasons.
Firstly, it could be due to unconscious linguistic
adaptation. Pickering and Garrod (2004) suggests
that conversations have linguistic coordination
at lexical level. Branigan et al. (2000) and Gries
(2005) show that priming effects exist at the
syntactic level. However, linguistic alignment
could happen consciously by conversation
participants. Some literature suggest that people
flexibly adapt their linguistic patterns to each
other?s in order to improve collective performance
and social coordination (Healey and Mills, 2006;
Garrod and Pickering, 2009).
Linguistic alignment has been found in written
communication as well, which is close to our
work. Danescu-Niculescu-Mizil et al. (2011)
examines conversations in a Twitter corpus,
showing convergence of Linguistic Inquiry and
Word Count (LIWC) measures. This result
confirms that linguistic alignment exists in written
online social media. Furthermore, in Huffaker
et al. (2006); Scissors et al. (2008); Backstrom
et al. (2013) also show that people adjust their
linguistic style, such as linguistic features, in the
online written chatroom and online community.
Also, priming effects at syntactic level (Gries,
2005; Branigan et al., 2000) have been explored
in several written dataset settings (Pickering and
Ferreira, 2008).
In order to quantify the linguistic alignment
phenomenon, researchers have introduced several
quantitative measures. Several methods evaluate
repetition of linguistic events, such as the use of
words, syntactic rules or a small set of expressions
(Church, 2000; Reitter et al., 2006; Fusaroli et al.,
2012). These approaches typically test whether
linguistic alignment is due to linguistic adaptation
or intrinsic repetition. Moreover, linguistic
feature similarity (Stenchikova and Stent, 2007;
Danescu-Niculescu-Mizil et al., 2011) is also
widely used to measure linguistic adaptation
precisely.
3 Online Health Communities
Online health communities (OHC) typically
include features such as discussion boards where
cancer survivors and their caregivers can interact
with each other. Support and information
from people with similar cancers or problems
is very valuable because cancer experiences are
unique. Therefore, an online community for
cancer survivors and caregivers enables them to
share experiences related to cancer, seek solutions
to daily living issues, and in general support
one another (Bambina, 2007) in ways that is not
often possible with other close family, friends
or even health care providers. Benefits to
cancer survivors who have participated in an
OHC are reported in the literature. Studies
of cancer OHC have indicated that participation
increases social support (Dunkel-Schetter, 1984;
Rodgers and Chen, 2005), reduces levels of
stress, depression, and psychological trauma
(Beaudoin and Tao, 2008; Winzelberg et al.,
2003), and helps participants be more optimistic
about the course of their life with cancer (Rodgers
and Chen, 2005). The support received from
other OHC members help cancer patients better
cope with their disease and improve their lives
both physically and mentally (Dunkel-Schetter,
1984). Further understanding about these
benefits has been provided by computational text
analysis and machine learning methods, which
enable fine-grained analysis of the sentiments of
individual posts in the discussion forum of cancer
OHC Qiu et al. (2011). It has been shown that
those who started a thread in a cancer OHC often
56
show a more positive sentiment in their posts
later in the thread, after other OHC members
provided replies Qiu et al. (2011); Portier et al.
(2013). However, the potential relationship
between alignment theory and these benefits of
cancer OHC has not been explored. This motivates
us to study the alignment of posts on a thread to the
initial post that starts the thread.
4 Data Description and Preliminary
Definitions
The data used in this study stem from the
Cancer Survivor?s Network (CSN) (http://
csn.cancer.org). The CSN is the oldest and
the largest cancer online community for cancer
survivors, which includes cancer patients, and
their friends and families. CSN has more than
166,000 members (Portier et al., 2013). Members
in CSN present their concerns, ask questions,
share their personal experience and provide social
support to each other through discussion threads.
Similar to other online communities, CSN threads
consist of an initial post followed by a sequence
of reply posts ordered by time. A thread
could be represented as a sequence of post, <
P
1
, P
2
, ? ? ? , P
i
, ? ? ? , P
n
>. In order to better
explain the problem, we show some properties of
a post in the thread.
Absolute Position: Given a post P
i
in a thread, the
absolute position of post P
i
is i
Relative Position: Given a post P
i
in a thread with
n posts, the relative position of P
i
is i/n
We construct the CSN corpus by randomly
sampling 3,000 threads from CSN between 2000
and 2010. Using Stanford?s CoreNLP tool (Klein
and Manning, 2003), we generate the syntactic
structure of the text in each post. In order
to calculate linguistic adaptation, we convert
every syntactic tree into structure rules in phrases
(Reitter et al., 2006). The data distribution of CSN
corpus is shown in Figure 1.
5 Measures of Linguistic Adaptation
Following previous work, we implement
Indiscriminate Local Linguistic Alignment
(Fusaroli et al., 2012) at the levels of syntax and
lexicon. In general, indiscriminate local linguistic
alignment measures the repetition of language use
in the target post repeating prime posts. LILA, as
defined, is a normalized measure of the number of
words that occur in both the prime and the target.
l l l l l l l llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll
l
l
1 2 5 10 20 50 100 200
1
10
100
100
0
100
00
 
Post Distance
# o
f Po
st P
airs
Figure 1: The distribution of posts based on post
distance.
The normalization factor is the product of the
length of the prime and the length of the target.
Alignment has been demonstrated for
syntax and lexicon, ranging from controlled
experimentation to broad-coverage naturalistic
text (e.g., Bock, 1986; Gries, 2005; Ferreira
and Bock, 2006; Reitter et al., 2006). In this
paper, we present primarily exploratory analyses
that emphasize minimal filtering and data
processing. While some priming effects discussed
in the literature indeed require careful post-hoc
control using many explanatory variables,
the phenomena we discuss are evident with
exploratory, early-stage methods.
5.1 Indiscriminate local linguistic alignment
at the lexical level
Lexical Indiscriminate Local Linguistic Alignment
(LILLA) measures word repetition between one
or more prime post and a target post. The
prime always precedes the target. LILLA, in our
implementation, can be seen as the probability
of a word occurring in a single location, given it
occurred in a prime period. Formally,
LILLA(target, prime) =
p(target|prime)
p(target)
(1)
=
?
word
i
target
?(word
i
)
length(prime) ? length(target)
(2)
57
?(word
i
) =
{
1 if word
i
 prime
0 otherwise
(3)
where length(X) is the number of words in post
X , and target post is any post following the
prime post. The distance between the two posts
is measured in posts. In different experiment
settings, we focus on certain prime posts, such as
the first post of a thread, or all posts written by a
certain author.
To sum up, LILLA is measured as word
repetition conditioned on the word having been
primed in a previous post. A high value of
LILLA indicates an increased level of linguistic
alignment. Alignment at the lexical level can
have a number of underlying causes, including
lexical priming, but also simply topicality of the
posts. Therefore, it is important to also inspect
indiscriminate local linguistic alignment at the
syntactic level.
5.2 Indiscriminate local linguistic alignment
at the syntactic level
Here, we consider a priming effect of syntactic
structure, which shows users? implicit linguistic
adaptation. Similar to Reitter et al. (2006), our
cancer survivor network corpus was annotated
with phrase structure trees; unlike in previous
work, we do so using a parser (from the Stanford
CoreNLP package (Klein and Manning, 2003)).
Each post is encoded as a series of syntactic rules.
Indiscriminate local linguistic alignment at the
syntactic level (SILLA) measures the repetition of
syntactic rules in the target post. Similar to our
experiments in lexical repetition, prime posts will
vary in different experimental settings.
5.3 Alignment and Adaptation
In this paper, we distinguish alignment and
adaptation. Alignment is the general adoption
of words, phrases, syntax, and any linguistic
representation that was heard, read, spoken or
written previously. Adaptation is a special case
of alignment: here, speakers permanently adjust
their linguistic preferences, or they learn from
their linguistic experiences. Alignment can be
due to a memory effect (e.g., priming), while
adaptation may alternatively be the result of
speakers discussing a topic. When they do, they
are more likely to use the same words. Both
alignment and adaptation may decay over time.
0.000 0.002 0.004 0.006 0.008
0
200
400
600
800
 
Lexical Indiscriminate Local Linguistic Alignment
Den
sity
NotOneThreadOneThread
Figure 2: Distribution of lexical indiscriminate
local linguistic alignment compared to a control
(NotOneThread).
6 Linguistic properties of conversation
threads
In this section, we will set up four experiments
to show the alignment properties of conversation
threads. For simplification, we will only consider
replies whose post distance is less than 100 (data
distribution shown in Figure 1).
6.1 Linguistic alignment
We assume that there is a constant level of random
indiscriminate local linguistic repetition in human
language, both lexically and syntactically.
We designed a post-hoc experiment to test
whether linguistic alignment effect is due to
linguistic adaptation or intrinsic repetition in
human language, following methodology to
measure long-term adaptation developed in Reitter
and Moore (2007). We split each of 3,000 threads
into two equal-size (by posts) halves. Out of the
resulting 6,000 thread halves, we produce pairs
combining any two sampled thread halves.
We define the binary OneThread variable,
indicating whether a pair consists of material from
the same thread, or if it consists of a first half
from one thread, but a second half from another
thread. This allows us to contrast repetition within
and between threads. If linguistic adaptation exist,
linguistic repetition at the lexical and syntactic
levels between the two halves of a pair will be
58
0.000 0.005 0.010 0.015 0.020
0
50
100
150
200
250
 
Syntactic Indiscriminate Local Linguistic Alignment
Den
sity
NotOneThreadOneThread
Figure 3: Distribution of syntactic indiscriminate
local linguistic alignment compared to a control
(NotOneThread).
more common if OneThread is true.
Figures 2 and 3 show that linguistic
repetition in the same thread is greater than
the control (repetition between different
threads) (Wilcoxon-test p
LILLA
< 0.001,
p
SILLA
< 0.001). However, despite the statistical
difference, it is obvious that there is a strong
lexical alignment effect, but much less syntactic
alignment. As a result, we conclude that at
least some linguistic repetition in the online
conversation is due to linguistic adaptation.
Again, at the lexical level, we would expect
some of this repetition to be due to the preferred
repetition of topical words; at the syntactic level,
this is unlikely to be the case.
6.2 Linguistic Adaptation Decays
Strong syntactic repetition has been shown
to diminish within seconds (Reitter et al.,
2006). Precisely, given an use of a syntactic
construction at one point in time, the probability
of this construction being used again is strongly
increased for the first seconds, but decays rapidly
towards its prior probability. In our experiment,
we replicate the decay of linguistic repetition
at the larger scale of forum threads. From a
psycholinguistic perspective, one would expect
only a relatively weak effect, given that syntactic
short-term priming is often short-lived (Branigan
et al., 1999). However, there is also weaker, slow,
long-term persistence (Bock and Griffin, 2000),
which can even be cumulative (Jaeger and Snider,
2007; Kaschak et al., 2011b). The messages in
such forums are written at a much larger timescale
than the priming models and short-term priming
lab experiments investigate.
In the experiment, we split a thread into a
sequence of posts. Given a target post P
j
, the
prime post is one post in the subsequence of posts
< P
1
, ? ? ? , P
i
, ? ? ? , P
j?1
>. We calculate LILLA
and SILLA of posts for prime-target distances
below 100. We will use the same method in this
and following experiments.
Figures 4 and 5 show that LILLA and SILLA
drop as the post-distance between a target post and
a prime post in the thread increases. Comparing
syntactic and lexical decay, we note that the
slope of LILLA?s decay is stronger than that of
SILLA?s decay. Both two measurements imply
that linguistic alignment decays over time, by
?utterance? (for some definition of utterance), or
by post. These results parallel standard results
from the priming literature. Surprisingly, for
forum threads we find this effect at a much larger
scale than in one-on-one spoken dialogue.
6.3 Linguistic adaptation to the initial post
So far, we have largely replicated a known
alignment effect for the case of written
communication in the online forum. There
are some properties of the forum communication
that allow us to investigate a number of open
questions pertaining to alignment in multi-party
dialogue. The main question concerns the
function of alignment. Is it more than an artifact
of low-level memory effects (priming)? Does
it, as Pickering and Garrod (2004) have argued,
contribute to mutual understanding? Or is it,
beyond that, a mechanism to express or establish
social relationships? If alignment is not just a
purely functional phenomenon, but also carries
pragmatic weight or social functions, we would
not expect it to be blind to the role of the author
of the source (prime) post.
In a self-help online discussion forum, the
role of the initial post differs from that of
other messages. The initial post raises an issue
generally, or it poses a concrete question. In
this experiment, we test whether initial posts in
the thread are more important than other replies
59
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
ll
l
l
l l
l
l0.002
0.003
0.004
0.005
0 25 50 75 100Post distance between prime and target post
LIL
LA(w
ord
 ?
 
targ
et | w
ord
 ?
 
prim
e po
st)
primeType
l
l
l
initial post
any post by initial author
any post
Figure 4: Lexical indiscriminate local linguistic
adaptation to any post, the initial post and the posts
from the initial author of the thread. The light
gray horizontal line shows the mean LILLA to any
post in the thread. Error bars: standard errors.
(The dashed horizontal line shows the prior, which
is large due to the large number of many short
threads.)
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
0.004
0.006
0.008
0.010
0.012
0 25 50 75 100Post distance between prime and target post
SIL
LA(r
ule 
?
 
targ
et | r
ule 
?
 
prim
e po
st)
primeType
l
l
l
initial post
any post by initial author
any post
Figure 5: Syntactic indiscriminate local linguistic
adaptation to any post, the initial post, and the
posts from the initial author in the thread. The
light gray horizontal line shows the mean SILLA
to any post in the thread.
in online conversations. That is, given an initial
post, does linguistic alignment still decline with
increasing post distance between the initial post
and the reply post in the online discussion thread?
Also, is linguistic alignment to the initial post
higher than that to any post?
Figure 4 plots lexical alignment (LILLA). We
can see that lexical alignment is present for the
initial post as well, but not more so than in general.
In fact, the absolute level as well as the decay of
LILLA to the initial post is weaker than that of
LILLA to any post in the thread.
To distinguish linguistic adaptation from more
general alignment effects, we also test syntactic
alignment, SILLA. Figure 5 plots this measure.
SILLA shows a different story compared to
LILLA. It shows that syntactic adaptation takes
place (and decays) for all posts, but that there
is less, if even initial anti-alignment with the
posts from the initial author. The results may be
supported by properties of conversation in internet
threads. In an online community, initial posts
generally raise questions. Different sentence types
(e.g., questions) may be used by someone seeking
help. So, alignment with the initial post may
seem to decay after post 25, but also shows more
variance (due to fewer data-points).
In sum, both measurements suggest that
linguistic alignment takes place with general
material presented before the target text, and
that repetition probability does decrease over
time or linguistic material (posts) as theoretically
predicted. We do not see evidence for a strong
social role of alignment.
6.4 Linguistic adaptation to the author of the
first post
As the previous experiment showed, lexical
alignment to the initial post decays over time.
There is no evidence that alignment with the initial
post is related to its informational role in the
thread. However, is alignment affected by the
social role taken on by the author that asks the
initial question? In other words, do writers align
more with posts from the initial author than with
others?
Figure 4 shows that LILLA drops gradually
when prime posts are restricted to the initial
author. Lexical alignment to the initial author
behaves similarly to alignment with the initial
post. At the lexical level, repetition of material
60
provided by the initial author or initial post
does not drop as rapidly as it does for general
material, and it starts at a lower level. Further
investigations will be needed to better understand
the alignment effects and the slow decay with
the thread-initiating post. For example, further
analysis is needed to investigate whether the
slow decay is related to the support function
the community provides to the thread initiators.
Syntactic alignment (SILLA, Figure 5) suggests
weaker alignment effects for the initial author
and the initial post. Further investigations will
also be needed to study the syntactic alignment
of replying posts to early reply posts. If such
alignment exists, it provides further insights about
the leadership role in the community (Zhao et al.,
2014).
This finding result may be supported by
properties of online support communities.
Specifically, the author of the initial post is the
person that would like to receive support from
other community members. People who reply
provide support to that initial author. Therefore,
replies in the thread are likely to have expressions
different from those used in the initial post and by
the initial author.
7 Conclusion
Motivated by analyzing linguistic adaptation
behavior in online communities, we provide
a descriptive analysis that qualifies linguistic
alignment at both the lexical and syntactic levels.
A novel observation is that we find reliable
linguistic adaptation in online communities. We
replicate the temporal, logarithmic decay, but we
found it at a much slower pace or larger scale than
psycholinguistic work has done in experiment or
corpus studies.
The distinction we make between syntactic and
lexical alignment has implications for the possible
mechanisms behind the adaptation effect. A
writer?s lexical choices are influenced by topic,
while syntactic composition happens implicitly,
i.e., without (conscious) attention. Topics do
not remain the same during a conversation: they
shift throughout the thread. This clustering of
topics can create alignment and decay but as far
as permanent adaptation is concerned there is
nothing but the illusion of it.
Our study provides some insight into properties
of linguistic alignment particularly in thread-based
discussions. Different from regular dialogues,
the initial post and the author of the initial
post may have a special role in such dialogues.
We see differences in lexical and syntactic
alignment. We assume that these are likely due
to conversational properties rather than underlying
cognitive processes.
This phenomenon provides an interesting
angle to study online communities as well as
linguistic alignment from the perspectives of
communication and psycholinguistics.
Following these exploratory studies, we plan
to measure discriminate alignment next. Here,
priming spans across semantic relationships rather
than only word identity (Swinney et al., 1979).
Also, a next step would be to build a model that
can quantify alignment (or even adaptation) and
relate it to the factors pertinent to the discussion
and the community, such as network measures and
an individual propensity to align.
8 Acknowledgements
This research was made possible by a
collaboration agreement between Penn State
and the American Cancer Society. The authors
would like to thank the society and collaborators
Kenneth Portier and Greta E. Greer for their work
in producing the CSN dataset, as well as Prasenjit
Mitra and Yang Xu.
References
Lars Backstrom, Jon Kleinberg, Lillian Lee, and Cristian
Danescu-Niculescu-Mizil. Characterizing and curating
conversation threads: expansion, focus, volume, re-entry.
In Proceedings of the sixth ACM international conference
onWeb search and data mining, pages 13?22. ACM, 2013.
Antonina Bambina. Online social support: the interplay of
social networks and computer-mediated communication.
Cambria press, 2007.
Christopher E Beaudoin and Chen-Chao Tao. Modeling the
impact of online cancer resources on supporters of cancer
patients. New Media & Society, 10(2):321?344, 2008.
J Kathryn Bock. Syntactic persistence in language
production. Cognitive psychology, 18(3):355?387, 1986.
Kathryn Bock and Zenzi M Griffin. The persistence
of structural priming: Transient activation or implicit
learning? Journal of Experimental Psychology: General,
129(2):177, 2000.
Holly P. Branigan, Martin J. Pickering, and Alexandra A.
Cleland. Syntactic priming in language production:
Evidence for rapid decay. Psychonomic Bulletin and
Review, 6(4):635?640, 1999.
Holly P Branigan, Martin J Pickering, and Alexandra A
Cleland. Syntactic co-ordination in dialogue. Cognition,
75(2):B13?B25, 2000.
61
Holly P Branigan, Martin J Pickering, Jamie Pearson, and
Janet F McLean. Linguistic alignment between people
and computers. Journal of Pragmatics, 42(9):2355?2368,
2010.
Kenneth W. Church. Empirial estimates of adaptation: The
chance of two Noriegas is closer to p/2 than p
2
. In
Proceedings of the 18th Conference on Computational
Linguistics (COLING), pages 180?186, Saarbr?ucken,
Germany, 2000.
Cristian Danescu-Niculescu-Mizil and Lillian Lee.
Chameleons in imagined conversations: A new approach
to understanding coordination of linguistic style in
dialogs. In Proceedings of the 2nd Workshop on Cognitive
Modeling and Computational Linguistics, pages 76?87.
Association for Computational Linguistics, 2011.
Cristian Danescu-Niculescu-Mizil, Michael Gamon, and
Susan Dumais. Mark my words!: linguistic style
accommodation in social media. In Proceedings of the
20th international conference on World Wide Web, pages
745?754. ACM, 2011.
Christine Dunkel-Schetter. Social support and cancer:
Findings based on patient interviews and their
implications. Journal of Social Issues, 40(4):77?98,
1984.
Victor Ferreira and Kathryn Bock. The functions of structural
priming. Language and Cognitive Processes, 21(7-8):
1011?1029, 2006.
Riccardo Fusaroli, Bahador Bahrami, Karsten Olsen,
Andreas Roepstorff, Geraint Rees, Chris Frith, and
Kristian Tyl?en. Coming to terms quantifying the benefits
of linguistic coordination. Psychological Science, 23(8):
931?939, 2012.
Simon Garrod and Martin J Pickering. Joint action,
interactive alignment, and dialog. Topics in Cognitive
Science, 1(2):292?304, 2009.
Stefan Th. Gries. Syntactic priming: A corpus-based
approach. Journal of Psycholinguistic Research, 34(4):
365?399, 2005.
Patrick GT Healey and Gregory Mills. Participation,
precedence and co-ordination in dialogue. In Proceedings
of the 28th Annual Conference of the Cognitive Science
Society, pages 1470?1475, 2006.
David Huffaker, Joseph Jorgensen, Francisco Iacobelli, Paul
Tepper, and Justine Cassell. Computational measures for
language similarity across time in online communities.
In Proceedings of the HLT-NAACL 2006 Workshop on
Analyzing Conversations in Text and Speech, pages 15?22.
Association for Computational Linguistics, 2006.
T. Florian Jaeger and Neal Snider. Implicit learning
and syntactic persistence: Surprisal and cumulativity.
University of Rochester Working Papers in the Language
Sciences, 3(1):26?44, 2007.
Michael P Kaschak, Timothy J Kutta, and John L Jones.
Structural priming as implicit learning: Cumulative
priming effects and individual differences. Psychonomic
Bulletin & Review, 18(6):1133?1139, 2011a.
Michael P Kaschak, Timothy J Kutta, and Christopher
Schatschneider. Long-term cumulative structural priming
persists for (at least) one week. Memory & Cognition, 39
(3):381?388, 2011b.
Dan Klein and Christopher D Manning. Fast exact inference
with a factored model for natural language parsing.
Advances in Neural Information Processing Systems,
pages 3?10, 2003.
Martin J Pickering and Victor S Ferreira. Structural priming:
a critical review. Psychological Bulletin, 134(3):427,
2008.
Martin J Pickering and Simon Garrod. The
interactive-alignment model: Developments and
refinements. Behavioral and Brain Sciences, 27
(02):212?225, 2004.
Kenneth Portier, Greta E Greer, Lior Rokach, Nir Ofek, Yafei
Wang, Prakhar Biyani, Mo Yu, Siddhartha Banerjee, Kang
Zhao, Prasenjit Mitra, et al. Understanding topics and
sentiment in an online cancer survivor community. JNCI
Monographs, 2013(47):195?198, 2013.
Baojun Qiu, Kang Zhao, Prasenjit Mitra, Dinghao Wu,
Cornelia Caragea, John Yen, Greta E Greer, and Kenneth
Portier. Get online support, feel better?sentiment analysis
and dynamics in an online cancer survivor community.
In Privacy, security, risk and trust (passat), 2011 ieee
third international conference on and 2011 ieee third
international conference on social computing (socialcom),
pages 274?281. IEEE, 2011.
David Reitter and Johanna D Moore. Predicting success
in dialogue. In Annual Meeting of the Association for
Computational Linguistics, volume 45, page 808, 2007.
David Reitter, Johanna D. Moore, and Frank Keller.
Priming of syntactic rules in task-oriented dialogue and
spontaneous conversation. In Proceedings of the 28th
Annual Conference of the Cognitive Science Society
(CogSci), pages 685?690, Vancouver, Canada, 2006.
David Reitter, Frank Keller, and Johanna D. Moore. A
computational cognitive model of syntactic priming.
Cognitive Science, 35(4):587?637, 2011.
Shelly Rodgers and Qimei Chen. Internet community
group participation: Psychosocial benefits for women
with breast cancer. Journal of Computer-Mediated
Communication, 10(4):00?00, 2005.
Lauren E Scissors, Alastair J Gill, and Darren Gergle.
Linguistic mimicry and trust in text-based cmc. In
Proceedings of the 2008 ACM Conference on Computer
Supported Cooperative Work, pages 277?280. ACM,
2008.
Svetlana Stenchikova and Amanda Stent. Measuring
adaptation between dialogs. In Proc. of the 8th SIGdial
Workshop on Discourse and Dialogue. Citeseer, 2007.
David Swinney, W. Onifer, P. Prather, and M. Hirshkowitz.
Semantic facilitation across modalities in the processing
of individual words and sentences. Memory and
Cognition, 7:159?165, 1979.
Andrew J Winzelberg, Catherine Classen, Georg W Alpers,
Heidi Roberts, Cheryl Koopman, Robert E Adams,
Heidemarie Ernst, Parvati Dev, and C Barr Taylor.
Evaluation of an internet support group for women with
primary breast cancer. Cancer, 97(5):1164?1173, 2003.
Kang Zhao, John Yen, Greta Greer, Baojun Qiu, Prasenjit
Mitra, and Kenneth Portier. Finding inuential users
of online health communities: a new metric based on
sentiment inuence. J Am Med Inform Assoc, 2014. doi:
10.1136/amiajnl-2013-002282.
62
