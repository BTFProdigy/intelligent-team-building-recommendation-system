Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 369?374, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational Linguistics
UNITOR: Combining Syntactic and Semantic Kernels for
Twitter Sentiment Analysis
Giuseppe Castellucci(?), Simone Filice(?), Danilo Croce(?), Roberto Basili(?)
(?) Dept. of Electronic Engineering
(?) Dept. of Civil Engineering and Computer Science Engineering
(?) Dept. of Enterprise Engineering
University of Rome, Tor Vergata
Rome, Italy
{castellucci,filice,croce,basili}@info.uniroma2.it
Abstract
In this paper, the UNITOR system participat-
ing in the SemEval-2013 Sentiment Analysis
in Twitter task is presented. The polarity de-
tection of a tweet is modeled as a classifica-
tion task, tackled through a Multiple Kernel
approach. It allows to combine the contribu-
tion of complex kernel functions, such as the
Latent Semantic Kernel and Smoothed Par-
tial Tree Kernel, to implicitly integrate syn-
tactic and lexical information of annotated ex-
amples. In the challenge, UNITOR system
achieves good results, even considering that
no manual feature engineering is performed
and no manually coded resources are em-
ployed. These kernels in-fact embed distri-
butional models of lexical semantics to deter-
mine expressive generalization of tweets.
1 Introduction
Web 2.0 and Social Networks technologies allow
users to generate contents on blogs, forums and new
forms of communication (such as micro-blogging)
writing their opinion about facts, things, events. The
analysis of this information is crucial for companies,
politicians or other users in order to learn what peo-
ple think, and consequently to adjust their strategies.
In such a scenario, the interest in the analysis of the
sentiment expressed by people is rapidly growing.
Twitter1 represents an intriguing source of informa-
tion as it is used to share opinions and sentiments
about brands, products, or situations (Jansen et al,
2009).
1http://www.twitter.com
On the other hand, tweet analysis represents a
challenging task for natural language processing
systems. Let us consider the following tweets, evok-
ing a positive (1), and negative (2) polarity, respec-
tively.
Porto amazing as the sun sets... http://bit.ly/c28w (1)
@knickfan82 Nooooo ;( they delayed the knicks game
until Monday! (2)
Tweets are short, informal and characterized by
their own particular language with ?Twitter syntax?,
e.g. retweets (?RT?), user references (?@?), hash-
tags (?#?) or other typical web abbreviations, such
as emoticons or acronyms.
Classical approaches to sentiment analysis (Pang
et al, 2002; Pang and Lee, 2008) are not directly ap-
plicable to tweets: most of them focus on relatively
large texts, e.g. movie or product reviews, and per-
formance drops are experimented in tweets scenario.
Some recent works tried to model the sentiment in
tweets (Go et al, 2009; Pak and Paroubek, 2010;
Kouloumpis et al, 2011; Davidov et al, 2010; Bifet
and Frank, 2010; Croce and Basili, 2012; Barbosa
and Feng, 2010; Agarwal et al, 2011). Specific ap-
proaches and feature modeling are used to achieve
good accuracy levels in tweet polarity recognition.
For example, the use of n-grams, POS tags, polar-
ity lexicon and tweet specific features (e.g. hash-
tag, retweet) are some of the component exploited
by these works in combination with different ma-
chine learning algorithms (e.g. Naive Bayes (Pak
and Paroubek, 2010), k-NN strategies (Davidov et
al., 2010), SVM and Tree Kernels (Agarwal et al,
2011)).
In this paper, the UNITOR system participating
369
in the SemEval-2013 Sentiment Analysis in Twit-
ter task (Wilson et al, 2013) models the senti-
ment analysis stage as a classification task. A Sup-
port Vector Machine (SVM) classifier learns the as-
sociation between short texts and polarity classes
(i.e. positive, negative, neutral). Different kernel
functions (Shawe-Taylor and Cristianini, 2004) have
been used: each kernel aims at capturing specific as-
pects of the semantic similarity between two tweets,
according to syntactic and lexical information. In
particular, in line with the idea of using convolu-
tion tree kernels to model complex semantic tasks,
e.g. (Collins and Duffy, 2001; Moschitti et al, 2008;
Croce et al, 2011), we adopted the Smoothed Par-
tial Tree Kernel (Croce et al, 2011) (SPTK). It is
a state-of-the-art convolution kernel that allows to
measure the similarity between syntactic structures,
which are partially similar and whose nodes can dif-
fer but are nevertheless semantically related. More-
over, a Bag-of-Word and a Latent Semantic Kernel
(Cristianini et al, 2002) are also combined with the
SPTK in a multi-kernel approach.
Our aim is to design a system that exhibits wide
applicability and robustness. This objective is pur-
sued by adopting an approach that avoids the use
of any manually coded resource (e.g. a polarity
lexicon), but mainly exploits distributional analysis
of unlabeled corpora: the generalization of words
meaning is achieved through the construction of a
Word Space (Sahlgren, 2006), which provides an ef-
fective distributional model of lexical semantics.
In the rest of the paper, in Section 2 we will
deeply explain our approach. In Section 3 the re-
sults achieved by our system in the SemEval-2013
challenge are described and discussed.
2 System Description
This section describes the approach behind the
UNITOR system. Tweets pre-processing and lin-
guistic analysis is described in Section 2.1, while the
core modeling is described in 2.2.
2.1 Tweet Preprocessing
Tweets are noisy texts and a pre-processing phase is
required to reduce data sparseness and improve the
generalization capability of the learning algorithms.
The following set of actions is performed before ap-
plying the natural language processing chain:
? fully capitalized words are converted in their
lowercase counterparts;
? reply marks are replaced with the pseudo-token
USER, and POS tag is set to $USR;
? hyperlinks are replaced by the token LINK,
whose POS is $URL;
? hashtags are replaced by the pseudo-token
HASHTAG, whose POS is imposed to $HTG;
? characters consecutively repeated more than
three times are cleaned as they cause high lev-
els of lexical data sparseness (e.g. ?nooo!!!!!?
and ?nooooo!!!? are both converted into
?noo!!?);
? all emoticons are replaced by SML CLS, where
CLS is an element of a list of classified emoti-
cons (113 emoticons in 13 classes).
For example, the tweet in the example 2 is nor-
malized in ?user noo sml cry they delayed the knicks
game until monday?. Then, we apply an almost stan-
dard NLP chain with Chaos (Basili and Zanzotto,
2002). In particular, we process each tweet to pro-
duce chunks. We adapt the POS Tagging and Chunk-
ing phases in order to correctly manage the pseudo-
tokens introduced in the normalization step. This is
necessary because tokens like SML SAD are tagged
as nouns, and they influence the chunking quality.
2.2 Modeling Kernel Functions
Following a summary of the employed kernel func-
tions is provided.
Bag of Word Kernel (BOWK) A basic kernel func-
tion that reflects the lexical overlap between tweets.
Each text is represented as a vector whose dimen-
sions correspond to different words. Each dimen-
sion represents a boolean indicator of the presence
or not of a word in the text. The kernel function is
the cosine similarity between vector pairs.
Lexical Semantic Kernel (LSK) A kernel function
is obtained to generalize the lexical information of
tweets, without exploiting any manually coded re-
source. Basic lexical information is obtained by
a co-occurrence Word Space built accordingly to
the methodology described in (Sahlgren, 2006) and
(Croce and Previtali, 2010). A word-by-context ma-
trixM is obtained through a large scale corpus anal-
ysis. Then the Latent Semantic Analysis (Lan-
370
dauer and Dumais, 1997) technique is applied as fol-
lows. The matrix M is decomposed through Singu-
lar Value Decomposition (SVD) (Golub and Kahan,
1965) into the product of three new matrices: U , S,
and V so that S is diagonal and M = USV T . M is
then approximated by Mk = UkSkV Tk , where only
the first k columns of U and V are used, correspond-
ing to the first k greatest singular values. The orig-
inal statistical information about M is captured by
the new k-dimensional space, which preserves the
global structure while removing low-variant dimen-
sions, i.e. distribution noise. The result is that every
word is projected in the reduced Word Space and
an entire tweet is represented by applying an addi-
tive linear combination. Finally, the resulting ker-
nel function is the cosine similarity between vector
pairs, in line with (Cristianini et al, 2002).
Smoothed Partial Tree Kernel (SPTK) In order
to exploit the syntactic information of tweets, the
Smoothed Partial Tree Kernel proposed in (Croce et
al., 2011) is adopted. Tree kernels exploit syntactic
similarity through the idea of convolutions among
substructures. Any tree kernel evaluates the number
of common substructures between two trees T1 and
T2 without explicitly considering the whole frag-
ment space. Its general equation is reported here-
after:
TK(T1, T2) =
?
n1?NT1
?
n2?NT2
?(n1, n2), (3)
where NT1 and NT2 are the sets of the T1?s and
T2?s nodes, respectively and ?(n1, n2) is equal to
the number of common fragments rooted in the n1
and n2 nodes. The function ? determines the na-
ture of the kernel space. In the SPTK formulation
(Croce et al, 2011) this function emphasizes lexical
nodes. It computes the similarity between lexical
nodes as the similarity between words in the Word
Space. So, this kernel allows a generalization both
from the syntactic and the lexical point of view.
However, tree kernel methods are biased by pars-
ing accuracy and standard NLP parsers suffer accu-
racy loss in this scenario (Foster et al, 2011). It
is mainly due to the complexities of the language
adopted in tweets. In this work, we do not use a
representation that depends on full parse trees. A
syntactic representation derived from tweets chunk-
ing (Tjong Kim Sang and Buchholz, 2000) is here
adopted, as shown in Figure 1.
Notice that no explicit manual feature engineering
is applied. On the contrary we expect that discrim-
inative lexical and syntactic information (e.g. nega-
tion) is captured by the kernel in the implicit feature
space, as discussed in (Collins and Duffy, 2001).
A multiple kernel approach Kernel methods are
appealing as they can be integrated in various ma-
chine learning algorithms, such as SVM. Moreover
a combination of kernels is still a kernel function
(Shawe-Taylor and Cristianini, 2004). We employed
a linear combination ?BOWK + ?LSK + ?SPTK
in order to exploit the lexical properties captured by
BOWK (and generalized by LSK) and the syntac-
tic information of the SPTK. In our experiments, the
kernel weights ?, ? and ? are set to 1.
3 Results and Discussion
In this section experimental results of the UNITOR
system are reported.
3.1 Experimental setup
In the Sentiment Analysis in Twitter task, two
subtasks are defined: Contextual Polarity
Disambiguation (Task A), and Message
Polarity Classification (Task B). The for-
mer deals with the polarity classification (positive,
negative or neutral) of a marked occurrence of a
word or phrase in a tweet context. For example
the adjective ?amazing? in example 1 expresses a
positive marked word. The latter deals with the
classification of an entire tweet with respect to
the three classes positive, negative and neutral. In
both subtasks, we computed a fixed (80%-20%)
split of the training data for classifiers parameter
tuning. Tuned parameters are the regularization
parameter and the cost factor (Morik et al, 1999)
of the SVM formulation. The former represents the
trade off between a training error and the margin.
The latter controls the trade off between positive
and negative examples. The learning phase is made
available by an extended version of SVM-LightTK2,
implementing the smooth matching between tree
nodes.
We built a Word Space based on about 1.5 mil-
lion of tweets downloaded during the challenge pe-
riod using the topic name from the trial material as
2
http://disi.unitn.it/moschitti/Tree-Kernel.htm
371
TW
LINK
$URL
link::$
punt
.
.::.
VerFin
VBZ
set::v
Prep
NN
sun::n
DT
the::d
IN
as::i
Agg
JJ
amazing::j
Nom
NNP
porto::n
(a)
TW
punt
.
!::.
Prep
NNP
monday::n
IN
until::i
Nom
NN
game::n
NNS
knicks::n
VerFin
VBD
delay::v
Nom
PRP
they::p
SMILE
$SML
sml cry::
UH
UH
noo::u
USER
$USR
user::$
(b)
Figure 1: Chunk-based tree derived from examples (1) and (2)
query terms. We normalized and analyzed tweets as
described in section 2.1. Words occurring more than
100 times in the source corpus are represented as
vectors. The 10, 000 most frequent words in the cor-
pus are considered as contexts and the co-occurrence
scores are measured in a window of size n = ?5.
Vector components are weighted through the Point-
wise Mutual Information (PMI), and dimensional-
ity reduction is applied through SVD with a cut of
k = 250.
The task requires to classify two different texts:
tweets and sms. Sms classification is intended to
verify how well a system can scale on a different
domain. In the testing phase two types of submis-
sions are allowed. Constrained results refer to the
case where systems are trained only with the re-
leased data. Unconstrained results refer to the case
where additional training material is allowed. Eval-
uation metrics adopted to compare systems are Pre-
cision, Recall and F1-Measure. Average F1 of the
positive and negative classes is then used to generate
ranks. Further information about the task is avail-
able in (Wilson et al, 2013).
3.2 Results over Contextual Polarity
Disambiguation
We tackled Task A with a multi-kernel approach
combining the kernel functions described in Section
2.2. The final kernel is computed as the linear com-
bination of the kernels, as shown in Equation 4.
k(t1, t2) = SPTK(?A(t1), ?A(t2))
+BOWK(?A(t1), ?A(t2))
+ LSK(?A(t1), ?A(t2)) (4)
where t1, t2 are two tweet examples. The ?A(x)
function extracts the 4-level chunk tree from the
tweet x; nodes (except leaves) covering the marked
instance in x are highlighted in the tree with -POL.
The ?A(x) function extracts the vector representing
the Bag-of-Word of the words inside the marked in-
stance of x, while ?A builds the LSA vectors of the
words occurring within the marked span of x. Re-
ferring to example 1, both ?A(x) and ?A point to
the ?amazing? adjective. Finally, k(t1, t2) returns
the similarity between t1 and t2 accordingly to our
modeling. As three polarity classes are considered,
we adopt a multi-classification schema accordingly
to a One-Vs-All strategy (Rifkin and Klautau, 2004):
the final decision function consists in the selection
of the category associated with the maximum SVM
margin.
Rank 4/19
class precision recall f1
positive .8375 .7750 .8050
Avg-F1 .8249
negative .8103 .8822 .8448
neutral .3475 .3082 .3267
Table 1: Task A results for the sms dataset
Rank 7/21
class precision recall f1
positive .8739 .8844 .8791
Avg-F1 .8460
negative .8273 .7988 .8128
neutral .2778 .3125 .2941
Table 2: Task A results for the twitter dataset
Tables 1 and 2 report the results of the UNITOR
system in the Task A. Only the constrained set-
ting has been submitted. The performance of the
proposed approach is among the best ones and we
ranked 4th and 7th among about 20 systems.
The system seems to be able to generalize well
from the provided training data, and results are re-
markable, especially considering that no manual an-
notated lexical resources were adopted and no man-
ual feature engineering is exploited. It demonstrates
that a multi-kernel approach, with the proposed shal-
low syntactic representation, is able to correctly
classify the sentiment in out-of-domain contexts too.
Syntax is well captured by the SPTK and the lexical
generalization provided by the Word Space allows
to generalize in the sms scenario.
372
3.3 Results over Message Polarity
Classification
A multi-kernel approach is adopted for this task too,
as described in the following Equation 5:
k(t1, t2) = SPTK(?B(t1), ?B(t2))
+BOWK(?B(t1), ?B(t2))
+ LSK(?B(t1), ?B(t2)) (5)
The ?B(x) function extracts a tree representation of
x. In this case no nodes in the trees are marked.
The ?B(x) function extracts Bag-of-Word vectors
for all the words in the tweet x, while ?B(x) extracts
the linear combination of vectors in the Word Space
for adjectives, nouns, verbs and special tokens (e.g.
hashtag, smiles) of the words in x. Again, a One-Vs-
All strategy (Rifkin and Klautau, 2004) is applied.
Constrained run. Tables 3 and 4 report the result
in the constrained case. In the sms dataset our sys-
tem suffers more with respect to the tweet one. In
both cases, the system shows a performance drop
on the negative class. It seems that the multi-kernel
approach needs more examples to correctly disam-
biguate elements within this class. Indeed, nega-
tive class cardinality was about 15% of the training
data, while the positive and neutral classes approxi-
mately equally divided the remaining 85%. More-
over, it seems that our system confuses polarized
classes with the neutral one. For example, the tweet
?going Hilton hotel on Thursday for #cantwait? is
classified as neutral (the gold label is positive). In
this case, the hashtag is the sentiment bearer, and
our model is not able to capture this information.
Rank 13/29
class precision recall f1
positive .5224 .7358 .6110
Avg-F1 .5122
negative .6019 .3147 .4133
neutral .7883 .7798 .7840
Table 3: Task B results for the sms dataset in the
constrained case
Rank 13/36
class precision recall f1
positive .7394 .6514 .6926
Avg-F1 .5827
negative .6366 .3760 .4728
neutral .6397 .8085 .7142
Table 4: Task B results for the twitter dataset in the
constrained case
Unconstrained run. In the unconstrained case we
trained our system adding 2000 positive examples
and 2000 negative examples to the provided training
set. These additional tweets were downloaded from
Twitter during the challenge period using positive
and negative emoticons as query terms. The under-
lying hypothesis is that the polarity of the emoticons
can be extended to the tweet (Pak and Paroubek,
2010; Croce and Basili, 2012). In tables 5 and 6
performance measures in this setting are reported.
Rank 10/15
class precision recall f1
positive .4337 .7317 .5446
Avg-F1 .4888
negative .3294 .6320 .4330
neutral .8524 .3584 .5047
Table 5: Task B results for the sms dataset in the
unconstrained case
Rank 5/15
class precision recall f1
positive .7375 .6399 .6853
Avg-F1 .5950
negative .5729 .4509 .5047
neutral .6478 .7805 .7080
Table 6: Task B results for the twitter dataset in the
unconstrained case
In this scenario, sms performances are again
lower than the twitter case. This is probably due to
the fact that the sms context is quite different from
the twitter one. This is not true for Task A: polar ex-
pressions are more similar in sms and tweets. Again,
we report a performance drop on the negative class.
However, using more negative tweets seems to be
beneficial. The F1 for this class increased of about
3 points for both datasets. Our approach thus needs
more examples to better generalize from data.
In the future, we should check the redundancy and
novelty of the downloaded material, as early dis-
cussed in (Zanzotto et al, 2011). Moreover, we will
explore the possibility to automatically learn the ker-
nel linear combination coefficients in order to op-
timize the balancing between kernel contributions
(Go?nen and Alpaydin, 2011).
Acknowledgements
This work has been partially funded by the Ital-
ian Ministry of Industry within the ?Industria
2015? Framework, under the project DIVINO
(MI01 00234).
373
References
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow,
and Rebecca Passonneau. 2011. Sentiment analysis of
twitter data. In Proceedings of the Workshop on Lan-
guages in Social Media, pages 30?38, Stroudsburg,
PA, USA. Association for Computational Linguistics.
Luciano Barbosa and Junlan Feng. 2010. Robust senti-
ment detection on twitter from biased and noisy data.
In COLING, pages 36?44, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Roberto Basili and Fabio Massimo Zanzotto. 2002. Pars-
ing engineering and empirical robustness. Nat. Lang.
Eng., 8(3):97?120, June.
Albert Bifet and Eibe Frank. 2010. Sentiment knowl-
edge discovery in twitter streaming data. In Proceed-
ings of the 13th international conference on Discov-
ery science, pages 1?15, Berlin, Heidelberg. Springer-
Verlag.
Michael Collins and Nigel Duffy. 2001. Convolution
kernels for natural language. In Proceedings of Neural
Information Processing Systems (NIPS?2001), pages
625?632.
Nello Cristianini, John Shawe-Taylor, and Huma Lodhi.
2002. Latent semantic kernels. J. Intell. Inf. Syst.,
18(2-3):127?152.
Danilo Croce and Roberto Basili. 2012. Grammatical
feature engineering for fine-grained ir tasks. In IIR,
pages 133?143.
Danilo Croce and Daniele Previtali. 2010. Manifold
learning for the semi-supervised induction of framenet
predicates: an empirical investigation. In GEMS 2010,
pages 7?16, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Danilo Croce, Alessandro Moschitti, and Roberto Basili.
2011. Structured lexical similarity via convolution
kernels on dependency trees. In Proceedings of
EMNLP, Edinburgh, Scotland, UK.
Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Enhanced sentiment learning using twitter hashtags
and smileys. In COLING, pages 241?249, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Jennifer Foster, O?zlem C?etinoglu, Joachim Wagner,
Joseph Le Roux, Stephen Hogan, Joakim Nivre,
Deirdre Hogan, and Josef van Genabith. 2011. #hard-
toparse: Pos tagging and parsing the twitterverse. In
Analyzing Microtext.
Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter
sentiment classification using distant supervision.
G. Golub and W. Kahan. 1965. Calculating the singular
values and pseudo-inverse of a matrix. Journal of the
Society for Industrial and Applied Mathematics: Se-
ries B, Numerical Analysis, 2(2):pp. 205?224.
Mehmet Go?nen and Ethem Alpaydin. 2011. Multi-
ple kernel learning algorithms. Journal of Machine
Learning Research, 12:2211?2268.
Bernard J. Jansen, Mimi Zhang, Kate Sobel, and Abdur
Chowdury. 2009. Twitter power: Tweets as elec-
tronic word of mouth. J. Am. Soc. Inf. Sci. Technol.,
60(11):2169?2188, November.
Efthymios Kouloumpis, Theresa Wilson, and Johanna
Moore. 2011. Twitter sentiment analysis: The good
the bad and the omg! In ICWSM.
Tom Landauer and Sue Dumais. 1997. A solution to
plato?s problem: The latent semantic analysis theory
of acquisition, induction and representation of knowl-
edge. Psychological Review, 104.
Katharina Morik, Peter Brockhausen, and Thorsten
Joachims. 1999. Combining statistical learning with a
knowledge-based approach - a case study in intensive
care monitoring. In ICML, pages 268?277, San Fran-
cisco, CA, USA. Morgan Kaufmann Publishers Inc.
Alessandro Moschitti, Daniele Pighin, and Robert Basili.
2008. Tree kernels for semantic role labeling. Com-
putational Linguistics, 34.
Alexander Pak and Patrick Paroubek. 2010. Twitter as a
corpus for sentiment analysis and opinion mining. In
LREC.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1?
135, January.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using ma-
chine learning techniques. In EMNLP, volume 10,
pages 79?86, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Ryan Rifkin and Aldebaro Klautau. 2004. In defense of
one-vs-all classification. J. Mach. Learn. Res., 5:101?
141, December.
Magnus Sahlgren. 2006. The Word-Space Model. Ph.D.
thesis, Stockholm University.
John Shawe-Taylor and Nello Cristianini. 2004. Kernel
Methods for Pattern Analysis. Cambridge University
Press, New York, NY, USA.
Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. In-
troduction to the conll-2000 shared task: chunking. In
ConLL ?00, pages 127?132, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Alan
Ritter, Sara Rosenthal, and Veselin Stoyonov. 2013.
Semeval-2013 task 2: Sentiment analysis in twitter.
In Proceedings of the 7th International Workshop on
Semantic Evaluation. Association for Computational
Linguistics.
Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Kostas Tsioutsiouliklis. 2011. Linguistic redundancy
in twitter. In EMNLP, pages 659?669.
374
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 761?767,
Dublin, Ireland, August 23-24, 2014.
UNITOR: Aspect Based Sentiment Analysis with Structured Learning
Giuseppe Castellucci
(?)
, Simone Filice
(?)
, Danilo Croce
(?)
, Roberto Basili
(?)
(?) Dept. of Electronic Engineering
(?) Dept. of Civil Engineering and Computer Science Engineering
(?) Dept. of Enterprise Engineering
University of Roma, Tor Vergata, Italy
{castellucci,filice}@ing.uniroma2.it; {croce,basili}@info.uniroma2.it
Abstract
In this paper, the UNITOR system partici-
pating in the SemEval-2014 Aspect Based
Sentiment Analysis competition is pre-
sented. The task is tackled exploiting Ker-
nel Methods within the Support Vector
Machine framework. The Aspect Term
Extraction is modeled as a sequential tag-
ging task, tackled through SVM
hmm
. The
Aspect Term Polarity, Aspect Category
and Aspect Category Polarity detection are
tackled as a classification problem where
multiple kernels are linearly combined to
generalize several linguistic information.
In the challenge, UNITOR system achieves
good results, scoring in almost all rank-
ings between the 2
nd
and the 8
th
position
within about 30 competitors.
1 Introduction
In recent years, many websites started offering a
high level interaction with users, who are no more
a passive audience, but can actively produce new
contents. For instance, platforms like Amazon
1
or
TripAdvisor
2
allow people to express their opin-
ions on products, such as food, electronic items
or clothes. Obviously, companies are interested
in understanding what customers think about their
brands and products, in order to implement correc-
tive strategies on products themselves or on mar-
keting solutions. Performing an automatic analy-
sis of user opinions is then a very hot topic. The
automatic extraction of subjective information in
text materials is generally referred as Sentiment
Analysis or Opinion Mining and it is performed
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
1
http://www.amazon.com
2
http://www.tripadvisor.com
via natural language processing, text analysis and
computational linguistics techniques. Task 4 in
SemEval 2014 edition
3
(Pontiki et al., 2014) aims
at promoting research on Aspect Based Opinion
Mining (Liu, 2007), which is approached as a cas-
cade of 4 subtasks. For example, let us consider
the sentence:
The fried rice is amazing here. (1)
The Aspect Term Extraction (ATE) subtask aims
at finding words suggesting the presence of as-
pects on which an opinion is expressed, e.g.
fried rice in sentence 1. In the Aspect Term
Polarity (ATP) task the polarity evoked for each
aspect is recognized, i.e. a positive polarity is
expressed with respect to fried rice. In the
Aspect Category Detection (ACD) task the cate-
gory evoked in a sentence is identified, e.g. the
food category in sentence 1). In the Aspect Cat-
egory Polarity (ACP) task the polarity of each ex-
pressed category is recognized, e.g. a positive
category polarity is expressed in sentence 1.
Different strategies have been experimented in
recent years. Classical approaches are based on
machine learning techniques and rely on sim-
ple representation features, such as unigrams, bi-
grams, Part-Of-Speech (POS) tags (Pang et al.,
2002; Pang and Lee, 2008; Wiebe et al., 1999).
Other approaches adopt sentiment lexicons in or-
der to exploit some sort of prior knowledge about
the polar orientation of words. These resources are
usually semi-automatically compiled and provide
scores associating individual words to sentiments
or polarity orientation.
In this paper, the UNITOR system participat-
ing to the SemEval-2014 Aspect Based Sentiment
Analysis task (Pontiki et al., 2014) is presented.
The ATE task is modeled as a sequential labeling
problem. A sentence is considered as a sequence
of tokens: a Markovian algorithm is adopted in
3
http://alt.qcri.org/semeval2014/task4/
761
order to decide what is an aspect term . All the
remaining tasks are modeled as multi-kernel clas-
sification problems based on Support Vector Ma-
chines (SVMs). Various representation have been
exploited using proper kernel functions (Shawe-
Taylor and Cristianini, 2004a). Tree Kernels
(Collins and Duffy, 2001; Moschitti et al., 2008;
Croce et al., 2011) are adopted in order to capture
structural sentence information derived from the
parse tree. Moreover, corpus-driven methods are
used in order to acquire meaning generalizations
in an unsupervised fashion (e.g. see (Pado and La-
pata, 2007)) through the analysis of distributions
of word occurrences in texts. It is obtained by the
construction of a Word Space (Sahlgren, 2006),
which provides a distributional model of lexical
semantics. Latent Semantic Kernel (Cristianini et
al., 2002) is thus applied within such space.
In the remaining, in Section 2 and 3 we will ex-
plain our approach in more depth. Section 4 dis-
cusses the results in the SemEval-2014 challenge.
2 Sequence Labeling for ATE
The Aspect Term Extraction (ATE) has been mod-
eled as a sequential tagging process. We con-
sider each token representing the beginning (B),
the inside (I) or the outside (O) of an argu-
ment. Following this IOB notation, the resulting
ATE representation of a sentence like ?The [fried
rice]
ASPECTTERM
is amazing here? can be expressed
by labeling each word according to its relative po-
sition, i.e.: [The]
O
[fried]
B
[rice]
I
[is]
O
[amaz-
ing]
O
[here]
O
.
The ATE task is thus a labeling process that
determines the individual (correct IOB) class for
each token. The labeling algorithm used is
SVM
hmm
(Altun et al., 2003)
4
: it combines
both a discriminative approach to estimate the
probabilities in the model and a generative ap-
proach to retrieve the most likely sequence of
tags that explains a sequence. Given an input
sequence x = (x
1
. . . x
l
) ? X of feature vec-
tors x
1
. . . x
l
, the model predicts a tag sequence
y = (y
1
. . . y
l
) ? Y after learning a linear dis-
criminant function F : X ? Y ? R over input-
output pairs. The labeling f(x) is thus defined as:
f(x) = arg max
y?Y
F (x,y;w) and it is obtained
by maximizing F over the response variable, y,
for a specific given input x. F is linear in some
4
www.cs.cornell.edu/People/tj/svm light/svm hmm.html
combined feature representation of inputs and out-
puts ?(x,y), i.e. F (x,y;w) = ?w,?(x,y)?.
In SVM
hmm
the observations x
1
. . . x
l
can be
naturally expressed in terms of feature vectors. In
particular, we modeled each word through a set of
lexical and syntactic features, as described in the
following section.
2.1 Modeling Features for ATE
In the discriminative view of SVM
hmm
, each
word is represented by a feature vector, describ-
ing its different observable properties. For in-
stance, the word rice in the example 1 is modeled
through the following features: Lexical features:
its lemma (rice) and POS tag (NN); Prefixes and
Suffixes: the first n and the last m characters of
the word (n = m = 3) (e.g. ric and ice); Con-
textual features: the left and right lexical contexts
represented by the 3 words before (BEGIN::BB
the::DT fried::JJ) and after (is::VBZ amazing::JJ
here::RB); the left and right syntactic contexts as
the POS bi-grams and tri-grams occurring before
(i.e. BB DT DT JJ BB DT JJ) and after (i.e.
VBZ JJ JJ RB VBZ JJ RB) the word; Gram-
matical features: features derived from the de-
pendency graph associated to the sentence, i.e.
boolean indicators that capture if the token is in-
volved in a Subj, Obj or Amod relation in the cor-
responding graph.
3 Multiple Kernel Approach for Polarity
and Category Detection
We approached the remaining three subtasks of the
pipeline as classification problems with multiple
kernels, in line with (Castellucci et al., 2013). We
used Support Vector Machines (SVMs) (Joachims,
1999), a maximum-margin classifier that realizes
a linear discriminative model. The kernelized ver-
sion of SVM learns from instances x
i
exploiting
rich similarity measures (i.e.the kernel functions)
K(x
i
, x
j
) = ??(x
i
) ? ?(x
j
)?. In this way projec-
tion functions ?(?) can be implicitly used in order
to transform the initial feature space into a more
expressive one, where a hyperplane that separates
the data with the widest margin can be found.
Kernels can directly operate on variegate forms
of representation, such as feature vectors, trees,
sequences or graphs. Then, modeling instances
in different representations, specific kernels can
be defined in order to explore different linguis-
tic information. These variety of kernel functions
762
K1
. . .K
n
can be independently defined and the
combinations K
1
+ K
2
+ . . . of multiple func-
tions can be integrated into SVM as they are still
kernels. The next section describes the represen-
tations as well as the kernel functions.
3.1 Representing Lexical Information
The Bag of Word (BoW) is a simple repre-
sentation reflecting the lexical information of the
sentence. Each text is represented as a vector
whose dimensions correspond to different words,
i.e. they represent a boolean indicator of the pres-
ence or not of a word in the text. The resulting
kernel function is the cosine similarity (or linear
kernel) between vector pairs, i.e. lin
BoW
. In line
with (Shawe-Taylor and Cristianini, 2004b) we in-
vestigated the contribution of the Polynomial Ker-
nel of degree 2, poly
2
BoW
as it defines an implicit
space where also feature pairs, i.e. words pairs,
are considered.
In the polarity detection tasks, several polarity
lexicons have been exploited in order to have use-
ful hints of the intrinsic polarity of words. We
adopted MPQA Subjectivity Lexicon
5
(Wilson et
al., 2005) and NRC Emotion Lexicon (Moham-
mad and Turney, 2013): they are large collection
of words provided with the underlying emotion
they generally evoke. While the former consid-
ers only positive and negative sentiments, the lat-
ter considers also eight primary emotions, orga-
nized in four opposing pairs, joy-sadness, anger-
fear, trust-disgust, and anticipation-surprise. We
define the Lexicon Based (LB) vectors as follows.
For each lexicon, let E = {e
1
, ..., e
|E|
} be the
emotion vocabulary defined in it. Let w ? s be
a word occurring in sentence s, with I(w, i) be-
ing the indicator function whose output is 1 if w
is associated to the emotion label e
i
, or 0 other-
wise. Then, given a sentence s, each e
i
, i.e. a di-
mension of the emotional vocabularyE, receives a
score s
i
=
?
w?s
I(w, i). Each sentence produces
a vector ~s ? R
|E|
, for each lexicon, on which a lin-
ear kernel lin
LB
is applied.
3.2 Generalizing Lexical Information
Another representation is used to generalize the
lexical information of each text, without exploit-
ing any manually coded resource. Basic lexical
information is obtained by a co-occurrence Word
Space (WS) built accordingly to the methodology
5
http://mpqa.cs.pitt.edu/lexicons/subj lexicon
described in (Sahlgren, 2006) and (Croce and Pre-
vitali, 2010). A word-by-context matrix M is ob-
tained through a large scale corpus analysis. Then
the Latent Semantic Analysis (Landauer and Du-
mais, 1997) technique is applied as follows. The
matrix M is decomposed through Singular Value
Decomposition (SVD) (Golub and Kahan, 1965)
into the product of three new matrices: U , S, and
V so that S is diagonal and M = USV
T
. M
is then approximated by M
k
= U
k
S
k
V
T
k
, where
only the first k columns of U and V are used,
corresponding to the first k greatest singular val-
ues. This approximation supplies a way to project
a generic wordw
i
into the k-dimensional space us-
ing W = U
k
S
1/2
k
, where each row corresponds to
the representation vector ~w
i
. The result is that ev-
ery word is projected in the reduced Word Space
and a sentence is represented by applying an addi-
tive model as an unbiased linear combination. We
adopted these vector representations using a linear
kernel, as in (Cristianini et al., 2002), i.e. lin
WS
and a Radial Basis Function Kernel rbf
WS
.
In Aspect Category Detection, and more gen-
erally in topic classification tasks, some specific
words can be an effective indicator of the under-
lying topic. For instance, in the restaurant do-
main, the word tasty may refer to the quality of
food. These kind of word-topic relationships can
be automatically captured by a Bag-of-Word ap-
proach, but with some limitations. As an exam-
ple, a BoW representation may not capture syn-
onyms or semantically related terms. This lack
of word generalization is partially compensated
by the already discussed Word Space. However,
this last representation aims at capturing the sense
of an overall sentence, and no particular rele-
vance is given to individual words, even if they
can be strong topic indicators. To apply a model-
ing more focused on topics, we manually selected
m seed words {?
1
, . . . , ?
m
} that we consider re-
liable topic-indicators, for example spaghetti for
food. Notice that for every seed ?
i
, as well as for
every word w the similarity function sim(?
i
, w)
can be derived from the Word Space represen-
tations ~?
i
and ~w, respectively. What we need
is a specific seed-based representation reflecting
the similarity between topic indicators and sen-
tences s. Given the words w occurring in s, the
Seed-Oriented (SO) representation of s is an m-
dimensional vector ~so(s) whose components are:
so
i
(s) = max
w?s
sim(?
i
, w). Alternatively, as
763
seeds ? refer to a set of evoked topics (i.e. as-
pect categories such as food) ?
1
, ...,?
t
, we can
define a t-dimensional vector
~
to(s) called Topic-
Oriented (TO) representation for s, whose fea-
tures are: to
i
(s) = max
w?s,?
k
??
i
sim(?
k
, w).
The adopted word similarity function sim(?, ?)
over ~so(s) and
~
to(s) depends on the experiments.
In the unconstrained setting, i.e. the Word Space
Topic Oriented WSTO system, sim(?, ?) consists
in the dot product over the Word Space represen-
tations ~?
i
and ~w. In the constrained case sim(?, ?)
corresponds to the Wu & Palmer similarity based
on WordNet (Wu and Palmer, 1994), in the so
called WordNet Seed Oriented WNSO system.
The Radial Basis Function (RBF) kernel is then
applied onto the resulting feature vectors
~
to(s) and
~so(s) in the rbf
WSTO
and rbf
WNSO
, respectively.
3.3 Generalizing Syntactic Information
In order to exploit the syntactic information, Tree
Kernel functions proposed in (Collins and Duffy,
2001) are adopted. Tree kernels exploit syntactic
similarity through the idea of convolutions among
syntactic tree substructures. Any tree kernel evalu-
ates the number of common substructures between
two trees T
1
and T
2
without explicitly considering
the whole fragment space. Many tree represen-
tations can be derived to represent the syntactic
information, according to different syntactic theo-
ries. For this experiment, dependency formalism
of parse trees is employed to capture sentences
syntactic information. As proposed in (Croce et
al., 2011), the kernel function is applied to ex-
amples modeled according the Grammatical Rela-
tion Centered Tree representation from the orig-
inal dependency parse structures, shown in Fig.
1: non-terminal nodes reflect syntactic relations,
such as NSUBJ, pre-terminals are the Part-Of-
Speech tags, such as nouns, and leaves are lex-
emes, such as rice::n and amazing::j
6
. In each ex-
ample, the aspect terms and the covering nodes are
enriched with a a suffix and all lexical nodes are
duplicated by the node asp in order to reduce data
sparseness. Moreover, prior information derived
by the lexicon can be injected in the tree, by du-
plicating all lexical nodes annotated in the MPQA
Subjectivity Lexicon, e.g. the adjective amazing,
with a node expressing the polarity (pos).
Given two tree structures T
1
and T
2
, the
6
Each word is lemmatized to reduce data sparseness, but
they are enriched with POS tags.
ROOT
ADVM
RB
here::r
JJ
posamazing::j
COP
VBZ
be::v
NSUBJ
a
NN
a
asprice::n
AMOD
a
VBN
a
aspfry::v
DET
DT
the::d
Figure 1: Tree representation of the sentence 1.
Tree Kernel formulation is reported hereafter:
TK(T
1
, T
2
) =
?
n
1
?N
T
1
?
n
2
?N
T
2
?(n
1
, n
2
)
where N
T
1
and N
T
2
are the sets of the T
1
?s and
T
2
?s nodes, respectively and ?(n
1
, n
2
) is equal to
the number of common fragments rooted in the n
1
and n
2
nodes. The function ? determines the na-
ture of the kernel space. In the constrained case the
Partial Tree Kernel formulation (Moschitti, 2006)
is used, i.e. ptk
GRCT
. In the unconstrained set-
ting the Smoothed Partial Tree Kernel formulation
(Croce et al., 2011) is adopted to emphasizes the
lexicon in the Word Space, i.e. the sptk
GRCT
. It
computes the similarity between lexical nodes as
the similarity between words in the Word Space.
So, this kernel allows a generalization both from a
syntactic and lexical point of view.
4 Results
In this Section the experimental results of the
UNITOR system in the four different subtasks of
Semeval 2014 competition are discussed. Teams
were allowed to submit two different outcomes for
each task: constrained submissions (expressed by
the suffix C in all the tables) are intended to mea-
sure systems ability to learn sentiment analysis
models only over the provided data; unconstrained
(expressed by the suffix U in all the tables) sub-
missions allows teams to exploit additional train-
ing data. The first two tasks, i.e. ATE and ATP,
are defined on the laptop and restaurant domains,
while the last two tasks, i.e. ACD and ACP, are
defined for the restaurant dataset only.
The unconstrained versions are derived by ex-
ploiting word vectors derived in an unsupervised
fashion through the analysis of large scale cor-
pora. All words in a corpus occurring more than
100 times (i.e. the targets) are represented through
vectors. The original space dimensions are gen-
erated from the set of the 20,000 most frequent
words (i.e. features) in the corpus. One dimension
describes the Point-wise Mutual Information score
between one feature, as it occurs on a left or right
window of 3 tokens around a target. Left contexts
of targets are distinguished from the right ones, in
order to capture asymmetric syntactic behaviors
764
(e.g., useful for verbs): 40,000 dimensional vec-
tors are thus derived for each target. The Singular
Value Decomposition is applied and the space di-
mensionality is reduced to k = 250. Two corpora
are used for generating two different Word Spaces,
one for the laptop and one for the restaurant do-
main. The Opinosis dataset (Ganesan et al., 2010)
is used to build the electronic domain Word Space,
while the restaurant domain corpus adopted is the
TripAdvisor dataset
7
. Both provided data and in-
domain data are first pre-processed through the
Stanford Parser (Klein and Manning, 2003) in or-
der to obtain POS tags or Dependency Trees.
A modified version of LibSVM has been
adopted to implement Tree Kernel. Parameters
such as the SVM regularization coefficient C, the
kernel parameters (for instance the degree of the
polynomial kernel) have been selected after a tun-
ing stage based on a 5-fold cross validation.
4.1 Aspect Term Extraction
The Aspect Term Extraction task is modeled as a
sequential labeling problem. The feature represen-
tation described in Section 2.1, where each token
is associated to a specific target class according to
the IOB notation, is used in the SVM
hmm
learn-
ing algorithm. In the constrained version of the
UNITOR system only the training data are used
to derive features. In the unconstrained case the
UNITOR system exploits lexical vectors derived
from a Word Space. Each token feature repre-
sentation is, in this sense, augmented through dis-
tributional vectors derived from the Word Spaces
described above. Obviously, the Opinosis Word
Space is used in the laptop subtask, while the Tri-
pAdvisor Word Space is used in the restaurant sub-
task. These allow the system to generalize the lex-
ical information, enabling a smoother match be-
tween words during training and test phases, hope-
fully capturing similarity phenomena such as the
relation between screen and monitor.
In Table 1 results in the laptop case are reported.
Our system performed quite well, and ranked in
6
th
and 10
th
position over 28 submitted systems.
In this case, the use of the Word Space is effec-
tive, as noticed by the 4 position gain in the final
ranking (almost 2 points in F1-measure). In Table
2 results in the restaurant case are reported. Here,
the use of Word Space does not give an improve-
ment in the final performance.
7
http://sifaka.cs.uiuc.edu/?wang296/Data/index.html
Table 1: Aspect Term Extraction Results - Laptop.
System (Rank) P R F1
UNITOR-C (10/28) .7741 .5764 .6608
UNITOR-U (6/28) .7575 .6162 .6795
Best-System-C (1/28) .8479 .6651 .7455
Best-System-U (2/28) .8251 .6712 .7403
Table 2: Aspect Term Extraction - Restaurants.
System (Rank) P R F1
UNITOR-C (5/29) .8244 .7786 .8009
UNITOR-U (6/29) .8131 .7865 .7996
Best-System-C (2/29) .8624 .8183 .8398
Best-System-U (1/29) .8535 .8271 .8401
In both cases, we observed that most of the
errors were associated to aspect terms composed
by multiple words. For example, in the sen-
tence The portions of the food that came out were
mediocre the gold aspect term is portions of
the food while our system was able only to re-
trieve food as aspect term. The system is mainly
able to recognize single word aspect terms and, in
most of the cases, double words aspect terms.
4.2 Aspect Term Polarity
The Aspect Term Polarity subtask has been mod-
eled as a multi-class classification problem: for
a given set of aspect terms within a sentence, it
aims at determining whether the polarity of each
aspect term is positive, negative, neutral or con-
flict. It has been tackled using multi-kernel SVMs
in a One-vs-All Schema. In the constrained set-
ting, the linear combination of the following ker-
nel functions have been used: ptk
GRCT
, poly
2
BoW
that consider all the lemmatized terms in the sen-
tence, a poly
2
BoW
that considers only the aspect
terms, poly
2
BoW
of the terms around the aspect
terms in a window of size 5, lin
LB
derived from
the Emolex lexicon. In the unconstrained setting
the sptk
GRCT
replaces the ptk counterpart and
the rbf
WS
is added by linearly combining Word
Space vectors for verbs, nouns adjective and ad-
verbs. Results in Table 3 show that the proposed
kernel combination allows to achieve the 8
th
posi-
tion with the unconstrained system in the restau-
rant domain. The differences with the constrained
setting demonstrate the contribution of the Word
Space acquired from the TripAdvisor corpus. Un-
fortunately, it is not true in the laptop domain, as
shown in Table 4. The use of the Opinosis corpus
lets to a performance drop of the unconstrained
setting. An error analysis shows that the main lim-
765
itation of the proposed model is the inability to
capture deep semantic phenomena such as irony,
as in the negative sentence ?the two waitress?s
looked like they had been sucking on lemons?.
Table 3: Aspect Term Polarity Results - Restau-
rant.
System (Rank) Accuracy
UNITOR-C (12/36) .7248
UNITOR-U (8/36) .7495
Best-System-C (1/36) .8095
Best-System-U (5/36) .7768
Table 4: Aspect Term Polarity Results - Laptop.
System (Rank) Accuracy
UNITOR-C (10/32) .6299
UNITOR-U (17/32) .5856
Best-System-C (1/32) .7048
Best-System-U (5/32) .6666
4.3 Aspect Category Detection
The Aspect Category Detection has been mod-
eled as a multi-label classification task where 5
categories (ambience, service, food, price, anec-
dotes/miscellaneous) must be recognized. In the
constrained version, each class has been tack-
led using a binary multi-kernel SVM equipped
with a linear combination of poly
2
BoW
and
rbf
WNSO
. A category is assigned if the SVM
classifiers provides a positive prediction. The
anecdotes/miscellaneous acceptance threshold has
been set to 0.3 (it has been estimated over a de-
velopment set) due to its poor precision observed
during the tuning phase. Moreover, considering
each sentence is always associated to at least one
category, if no label has been assigned, then the
sentence is labelled with the category associated
to the highest prediction.
In the unconstrained case, each class has been
tackled using an ensemble of a two binary SVM-
based classifiers. The first classifier is a multi-
kernel SVM operating on a linear combination of
rbf
WS
and poly
2
BoW
. The second classifier is a
SVM equipped with a rbf
WSTO
. A sentence is la-
belled with a category if at least one of the two cor-
responding classifiers predicts that label. The first
classifier assigns a label if the corresponding pre-
diction is positive. A more conservative strategy
is applied to the second classifier, and a category
is selected if its corresponding prediction is higher
than 0.3; again this threshold has been estimated
over a development set. As in the constrained ver-
sion, we observed a poor precision in the anec-
dotes/miscellaneous category, so we increased the
first classifier acceptance threshold to 0.3, while
the second classifier output is completely ignored.
Finally, if no label has been assigned, the sentence
is labelled with the category associated to the high-
est prediction of the first classifier.
Table 5: Aspect Category Detection Results.
System (Rank) P R F1
UNITOR-C (6/21) .8368 .7804 .8076
UNITOR-U (2/21) .8498 .8556 .8526
Best-System-C (1/21) .9104 .8624 .8857
Best-System-U (4/21) .8435 .7892 .8155
Table 5 reports the achieved results. Consider-
ing the simplicity of the proposed approach, the
results are impressive. The ensemble schema,
adopted in the unconstrained version, is very use-
ful in improving the recall and allows the system
to achieve the second position in the competition.
4.4 Aspect Category Polarity
The Aspect Category Polarity subtask has been
modeled as a multi-class classification problem:
given a set of pre-identified aspect categories for a
sentence, it aims at determining the polarity (pos-
itive, negative, neutral or conflict) of each cate-
gory. It has been tackled using multi-kernel SVMs
in a One-vs-All Schema. In the constrained set-
ting, the linear combination of the following ker-
nel functions has been used: ptk
GRCT
, poly
2
BoW
that consider all the lemmatized terms in the sen-
tence, a poly
2
BoW
that considers only verbs, nouns
adjective and adverbs in the sentence, lin
LB
de-
rived from the MPQA sentiment lexicon. In the
unconstrained case the sptk
GRCT
replaces the ptk
counterpart and the rbf
WS
is added by linearly
combining Word Space vectors for verbs, nouns
adjective and adverbs.
Again, results shown in Table 6 suggest the pos-
itive contribution of the lexical generalization pro-
vided by the Word Space (in the sptk
GRCT
and
rbf
WS
) allows to achieve a good rank, i.e. the
4
th
position with the unconstrained system in the
restaurant domain. The error analysis underlines
that the proposed features do not capture irony.
Table 6: Aspect Category Polarity Results.
System (Rank) Accuracy
UNITOR-C (7/25) .7307
UNITOR-U (4/25) .7629
Best-System-C (1/25) .8292
Best-System-U (9/25) .7278
766
References
Yasemin Altun, I. Tsochantaridis, and T. Hofmann.
2003. Hidden Markov support vector machines. In
Proceedings of the International Conference on Ma-
chine Learning.
Giuseppe Castellucci, Simone Filice, Danilo Croce,
and Roberto Basili. 2013. Unitor: Combining
syntactic and semantic kernels for twitter sentiment
analysis. In Second Joint Conference on Lexical and
Computational Semantics (*SEM), Volume 2: Pro-
ceedings of the Seventh International Workshop on
Semantic Evaluation (SemEval 2013), pages 369?
374, Atlanta, Georgia, USA, June. ACL.
Michael Collins and Nigel Duffy. 2001. Convolution
kernels for natural language. In Proceedings of Neu-
ral Information Processing Systems (NIPS?2001),
pages 625?632.
Nello Cristianini, John Shawe-Taylor, and Huma
Lodhi. 2002. Latent semantic kernels. J. Intell.
Inf. Syst., 18(2-3):127?152.
Danilo Croce and Daniele Previtali. 2010. Mani-
fold learning for the semi-supervised induction of
framenet predicates: an empirical investigation. In
GEMS 2010, pages 7?16, Stroudsburg, PA, USA.
ACL.
Danilo Croce, Alessandro Moschitti, and Roberto
Basili. 2011. Structured lexical similarity via con-
volution kernels on dependency trees. In Proceed-
ings of EMNLP, Edinburgh, Scotland, UK.
Kavita Ganesan, ChengXiang Zhai, and Jiawei Han.
2010. Opinosis: a graph-based approach to abstrac-
tive summarization of highly redundant opinions. In
Proceedings of the 23rd International Conference on
Computational Linguistics, pages 340?348. ACL.
Gene Golub and W. Kahan. 1965. Calculating the sin-
gular values and pseudo-inverse of a matrix. Journal
of the Society for Industrial and Applied Mathemat-
ics: Series B, Numerical Analysis, 2(2):pp. 205?224.
Thorsten Joachims. 1999. Making large-Scale SVM
Learning Practical. MIT Press, Cambridge, MA.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of
ACL?03, pages 423?430.
Tom Landauer and Sue Dumais. 1997. A solution to
plato?s problem: The latent semantic analysis the-
ory of acquisition, induction and representation of
knowledge. Psychological Review, 104.
Bing Liu. 2007. Web data mining. Springer.
Saif Mohammad and Peter D. Turney. 2013. Crowd-
sourcing a word-emotion association lexicon. Com-
putational Intelligence, 29(3):436?465.
Alessandro Moschitti, Daniele Pighin, and Robert
Basili. 2008. Tree kernels for semantic role label-
ing. Computational Linguistics, 34.
Alessandro Moschitti. 2006. Efficient convolution ker-
nels for dependency and constituent syntactic trees.
In ECML, Berlin, Germany, September.
Sebastian Pado and Mirella Lapata. 2007.
Dependency-based construction of semantic
space models. Computational Linguistics, 33(2).
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-
2):1?135, January.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification us-
ing machine learning techniques. In EMNLP, vol-
ume 10, pages 79?86, Stroudsburg, PA, USA. ACL.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Harris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. Semeval-2014 task 4:
Aspect based sentiment analysis. In Proceedings of
the International Workshop on Semantic Evaluation
(SemEval).
Magnus Sahlgren. 2006. The Word-Space Model.
Ph.D. thesis, Stockholm University.
John Shawe-Taylor and Nello Cristianini. 2004a. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press, New York, NY, USA.
John Shawe-Taylor and Nello Cristianini. 2004b. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press.
Janyce M. Wiebe, Rebecca F. Bruce, and Thomas P.
O?Hara. 1999. Development and use of a gold-
standard data set for subjectivity classifications. In
Proceedings of the 37th annual meeting of the
ACL on Computational Linguistics, pages 246?253,
Stroudsburg, PA, USA. ACL.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of Human
Language Technologies Conference/Conference on
Empirical Methods in Natural Language Processing
(HLT/EMNLP 2005), Vancouver, CA.
Zhibiao Wu and Martha Palmer. 1994. Verbs seman-
tics and lexical selection. In Proceedings of the
32Nd Annual Meeting of ACL, ACL ?94, pages 133?
138, Stroudsburg, PA, USA. ACL.
767
