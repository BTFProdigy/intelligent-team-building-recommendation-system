Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 83?88,
Prague, June 2007. c?2007 Association for Computational Linguistics
Dependency-based paraphrasing for recognizing textual entailment
Erwin Marsi, Emiel Krahmer
Communication & Cognition
Tilburg University
The Netherlands
e.c.marsi@uvt.nl
e.j.krahmer@uvt.nl
Wauter Bosma
Human Media Interaction
University of Twente
The Netherlands
w.e.bosma@ewi.utwente.nl
Abstract
This paper addresses syntax-based para-
phrasing methods for Recognizing Textual
Entailment (RTE). In particular, we de-
scribe a dependency-based paraphrasing al-
gorithm, using the DIRT data set, and its
application in the context of a straightfor-
ward RTE system based on aligning depen-
dency trees. We find a small positive effect
of dependency-based paraphrasing on both
the RTE3 development and test sets, but the
added value of this type of paraphrasing de-
serves further analysis.
1 Introduction
Coping with paraphrases appears to be an essential
subtask in Recognizing Textual Entailment (RTE).
Most RTE systems incorporate some form of lex-
ical paraphrasing, usually relying on WordNet to
identify synonym, hypernym and hyponym rela-
tions among word pairs from text and hypothesis
(Bar-Haim et al, 2006, Table 2). Many systems
also address paraphrasing above the lexical level.
This can take the form of identifying or substitut-
ing equivalent multi-word strings, e.g., (Bosma and
Callison-Burch, 2006). A drawback of this approach
is that it is hard to cope with discontinuous para-
phrases containing one or more gaps. Other ap-
proaches exploit syntactic knowledge in the form
of parse trees. Hand-crafted transformation rules
can account for systematic syntactic alternation like
active-passive form, e.g., (Marsi et al, 2006). Al-
ternatively, such paraphrase rules may be automati-
cally derived from huge text corpora (Lin and Pan-
tel, 2001). There are at least two key advantages of
syntax-based over string-based paraphrasing which
are relevant for RTE: (1) it can cope with discontin-
uous paraphrases; (2) syntactic information such as
dominance relations, phrasal syntactic labels and de-
pendency relations, can be used to refine the coarse
matching on words only.
Here we investigate paraphrasing on the basis of
of syntactic dependency analyses. Our sole resource
is the DIRT data set (Lin and Pantel, 2001), an exten-
sive collection of automatically derived paraphrases.
These have been used for RTE before (de Salvo Braz
et al, 2005; Raina et al, 2005), and similar ap-
proaches to paraphrase mining have been applied
as well (Nielsen et al, 2006; Hickl et al, 2006).
However, in these approaches paraphrasing is al-
ways one factor in a complex system, and as a result
little is known of the contribution of paraphrasing
for the RTE task. In this paper, we focus entirely
on dependency-based paraphrasing in order to get a
better understanding of its usefulness for RTE. In the
next Section, we describe the DIRT data and present
an algorithm for dependency-based paraphrasing in
order to bring a pair?s text closer to its hypothesis.
We present statistics on coverage as well as qual-
itative discussion of the results. Section 3 then de-
scribes our RTE system and results with and without
dependency-based paraphrasing.
2 Dependency-based paraphrasing
2.1 Preprocessing RTE data
Starting from the text-hypothesis pairs in the RTE
XML format, we first preprocess the data. As the
text part may consist of more than one sentence,
we first perform sentence splitting using Mxtermi-
nator (Reynar and Ratnaparkhi, 1997), a maximum
83
entropy-based end of sentence classifier trained on
the Penn Treebank data. Next, each sentence is to-
kenized and syntactically parsed using the Minipar
parser (Lin, 1998). From the parser?s tabular output
we extract the word forms, lemmas, part-of-speech
tags and dependency relations. This information is
then stored in an ad-hoc XML format which repre-
sents the trees as an hierarchy of node elements in
order to facilitate tree matching.
2.2 DIRT data
The DIRT (Discovering Inference Rules from Text)
method is based on extending Harris Distributional
Hypothesis, which states that words that occurred in
the same contexts tend to be similar, to dependency
paths in parse trees (Lin and Pantel, 2001). Each
dependency path consists of at least three nodes: a
root node, and two non-root terminal nodes, which
are nouns. The DIRT data set we used consists of
over 182k paraphrase clusters derived from 1GB of
newspaper text. Each cluster consists of a unique
dependency path, which we will call the paraphrase
source, and a list of equivalent dependency paths,
which we will refer to as the paraphrase transla-
tions, ordered in decreasing value of point-wise mu-
tual information. A small sample in the original for-
mat is
(N:by:V<buy>V:obj:N (sims
N:to:V<sell>V:obj:N 0.211704
N:subj:V<buy>V:obj:N 0.198728
...
))
The first two lines represent the inference rule: X
bought by Y entails X sold to Y.
We preprocess the DIRT data by restoring prepo-
sitions, which were originally folded into a depen-
dency relation, to individual nodes, as this eases
alignment with the parsed RTE data. For the same
reason, paths are converted to the same ad-hoc XML
format as the parsed RTE data.
2.3 Paraphrase substitution
Conceptually, our paraphrase substitution algorithm
takes a straightforward approach. For the purpose of
explanation only, Figure 1 presents pseudo-code for
a naive implementation. The main function takes
two arguments (cf. line 1). The first is a prepro-
cessed RTE data set in which all sentences from text
and hypothesis are dependency parsed. The second
is a collection of DIRT paraphrases, each one map-
ping a source path to one or more translation paths.
For each text/hypothesis pair (cf. line 2), we look
at all the subtrees of the text parses (cf. line 3-4)
and attempt to find a suitable paraphrase of this sub-
tree (cf. line 5). We search the DIRT paraphrases
(cf. line 8) for a source path that matches the text
subtree at hand (cf. line 9). If found, we check
if any of the corresponding paraphrase translation
paths (cf. line 10) matches a subtree of the hypoth-
esis parse (cf. line 11-12). If so, we modify the
text tree by substituting this translation path (cf. line
13). The intuition behind this is that we only accept
paraphrases that bring the text closer to the hypothe-
sis. The DIRT paraphrases are ordered in decreasing
likelihood, so after a successful paraphrase substitu-
tion, we discard the remaining possibilities and con-
tinue with the next text subtree (cf. line 14).
The Match function, which is used for matching
the source path to a text subtree and the translation
path to an hypothesis subtree, requires the path to
occur in the subtree. That is, all lemmas, part-of-
speech tags and dependency relations from the path
must have identical counterparts in the subtree; skip-
ping nodes is not allowed. As the path?s terminals
specify no lemma, the only requirement is that their
counterparts are nouns.
The Substitute function replaces the matched path
in the text tree by the paraphrase?s translation path.
Intuitively, the path ?overlays? a part of the sub-
tree, changing lemmas and dependency relations,
but leaving most of the daughter nodes unaffected.
Note that the new path may be longer or shorter than
the original one, thus introducing or removing nodes
from the text tree.
As an example, we will trace our algorithm as ap-
plied to the first pair of the RTE3 dev set (id=1).
Text: The sale was made to pay Yukos? US$ 27.5 billion tax
bill, Yuganskneftegaz was originally sold for US$ 9.4 bil-
lion to a little known company Baikalfinansgroup which
was later bought by the Russian state-owned oil company
Rosneft.
Hypothesis: Baikalfinansgroup was sold to Rosneft.
Entailment: Yes
While traversing the parse tree of the text, our
algorithm encounters a node with POS tag V and
lemma buy. The relevant part of the parse tree is
shown at the right top of Figure 2. The logical argu-
ments inferred by Minipar are shown between curly
84
(1) def Paraphrase(parsed-rte-data, dirt-paraphrases):
(2) for pair in parsed-rte-data:
(3) for text-tree in pair.text-parses:
(4) for text-subtree in text-tree:
(5) Paraphrase-subtree(text-subtree, dirt-paraphrases, pair.hyp-parse)
(6)
(7) def Paraphrase-subtree(text-subtree, dirt-paraphrases, hyp-tree):
(8) for (source-path, translations) in dirt-paraphrases:
(9) if Match(source-path, text-subtree):
(10) for trans-path in translations:
(11) for hyp-subtree in hyp-tree:
(12) if Match(trans-path, hyp-subtree):
(13) text-subtree = Substitute(trans-path, text-subtree)
(14) return
Figure 1: Pseudo-code for a naive implementation of the dependency-based paraphrase substitution algo-
rithm
brackets, e.g., US$ 9.4 billion. For this combination
of verb and lemma, the DIRT data contains 340 para-
phrase sets, with a total of 26950 paraphrases. The
algorithm starts searching for a paraphrase source
which matches the text. It finds the path shown
at the left top of Figure 2: buy with a PP modi-
fier headed by preposition by, and a nominal object.
This paraphrase source has 108 alternative transla-
tions. It searches for paraphrase translations which
match the hypothesis. The first, and therefore most
likely (probability is 0.22) path it finds is rooted in
sell, with a PP-modifier headed by to and a nominal
object. This translation path, as well as its alignment
to the hypothesis parse tree, is shown in the mid-
dle part of Figure 2. Finally, the source path in the
text tree is substituted by the translation path. The
bottom part of Figure 2 shows the updated text tree
as well as its improved alignment to the hypothesis
tree. The paraphrasing procedure can in effect be
viewed as making the inference that Baikalfinans-
group was bought by Rosneft, therefore Baikalfi-
nansgroup was sold to Rosneft.
The naive implementation of the algorithm is of
course not very efficient. Our actual implementa-
tion uses a number of shortcuts to reduce process-
ing time. For instance, the DIRT paraphrases are
indexed on the lemma of their root in order to speed
up retrieval. As another example, text nodes with
less than two child nodes (i.e. terminal and unary-
branching nodes) are immediately skipped, as they
will never match a paraphrase path.
2.4 Paraphrasing results
We applied our paraphrasing algorithm to the RTE3
development set. Table 1 gives an impression of how
many paraphrases were substituted. The first row
lists the total number of nodes in the dependency
trees of the text parts. The second row shows that
for roughly 15% of these nodes, the DIRT data con-
tains a paraphrase with the same lemma. The next
two rows show in how many cases the source path
matches the text and the translation path matches the
hypothesis (i.e. giving rise to a paraphrase substitu-
tion). Clearly, the number of actual paraphrase sub-
stitutions is relatively small: on average about 0.5%
of all text subtrees are subject to paraphrasing. Still,
about one in six sentences is subject to paraphras-
ing, and close to half of all pairs is paraphrased at
least once. Sentences triggering more than one para-
phrase do occur. Also note that paraphrasing occurs
more frequently in true entailment pairs than in false
entailment pairs. This is to be expected, given that
text and hypothesis are more similar when an entail-
ment relation holds.
2.5 Discussion on paraphrasing
Type of paraphrases A substantial number of the
paraphrases applied are single word synonyms or
verb plus particle combinations which might as well
be obtained from string-based substitution on the ba-
sis of a lexical resource like WordNet. Some ran-
domly chosen examples include X announces Y en-
tails X supports Y, X makes Y entails X sells Y, and
locates X at Y, discovers X at Y. Nevertheless, more
interesting paraphrases do occur. In the pair below
(id=452), we find the paraphrase X wins Y entails X
85
Table 1: Frequency of (partial) paraphrase matches on the RTE3 dev set
IE: IR: QA: SUM: Total:
Text nodes: 8899 10610 10502 8196 38207
Matching paraphrase lemma: 1439 1724 1581 1429 6173
Matching paraphrase source: 566 584 543 518 2211
Matching paraphrase translation: 71 55 23 79 228
Text sentences: 272 350 306 229 1157
Paraphrased text sentences: 63 51 20 66 200
Paraphrased true-entailment pairs: 32 25 12 39 108
Paraphrased false-entailment pairs: 26 21 5 23 75
(is) Y champion.
Text: Boris Becker is a true legend in the sport of tennis. Aged
just seventeen, he won Wimbledon for the first time and
went on to become the most prolific tennis player.
Hypothesis: Boris Becker is a Wimbledon champion.
Entailment: True
Another intriguing paraphrase, which appears to be
false on first sight, is X flies from Y entails X makes
(a) flight to Y. However, in the context of the next
pair (id=777), it turns out to be correct.
Text: The Hercules transporter plane which flew straight here
from the first round of the trip in Pakistan, touched down
and it was just a brisk 100m stroll to the handshakes.
Hypothesis: The Hercules transporter plane made a flight to
Pakistan.
Entailment: True
Coverage Although the DIRT data constitutes a
relatively large collection of paraphrases, it is clear
that many paraphrases required for the RTE3 data
are missing. We tried to improve coverage to some
extent by relaxing the Match function: instead of
an exact match, we allowed for small mismatches
in POS tag and dependency relation, reversing the
order of a path?s left and right side, and even for
skipping nodes. However, subjective evaluation sug-
gested that the results deteriorated. Alternatively,
the coverage might be increased by deducing para-
phrases on the fly using the web as a corpus, e.g.,
(Hickl et al, 2006).
Somewhat surprisingly, the vast majority of para-
phrases concerns verbs. Even though the DIRT data
contains paraphrases for nouns, adjectives and com-
plementizers, the coverage of these word classes is
apparently not nearly as extensive as that of verbs.
Another observation is that fewer paraphrases oc-
cur in pairs from the QA task. We have no explana-
tion for this.
False paraphrases Since the DIRT data was au-
tomatically derived and was not manually checked,
it contains noise in the form of questionable or even
false paraphrases. While some of these surface in
paraphrased RTE3 data (e.g. X leaves for Y entails
X departs Y, and X feeds Y entails Y feeds X), their
number appears to be limited. We conjecture this is
because of the double constraint that a paraphrase
must match both text and hypothesis.
Relevance Not all paraphrase substitutions are rel-
evant for the purpose of recognizing textual entail-
ment. Evidently, paraphrases in false entailment
pairs are counterproductive. However, even in true
entailment pairs paraphrases might occur in parts
of the text that are irrelevant to the task at hand.
Consider the following pair from the RTE3 dev set
(id=417).
Text: When comparing Michele Granger and Brian Goodell,
Brian has to be the clear winner. In 1976, while still a
student at Mission Viejo High, Brian won two Olympic
gold medals at Montreal, breaking his own world records
in both the 400 - and 1,500 - meter freestyle events. He
went on to win three gold medals in he 1979 Pan Ameri-
can Games.
Hypothesis: Brian Goodell won three gold medals in the 1979
Pan American Games.
Entailment: True
The second text sentence and hypothesis match
the paraphrases: (1) X medal at Y entails X medal in
Y, and (2) X record in Y entails X medal in Y. Even
so, virtually all of the important information is in the
third text sentence.
3 Results on RTE3 data
Since our contribution focuses on syntactic para-
phrasing, our RTE3 system is a simplified version
86
Table 2: Percent accuracy on RTE3 set without
paraphrasing (?) and with paraphrasing (+)
Task Dev? Dev+ Test? Test+
IE 59.5 61.0 53.0 53.5
IR 67.0 68.0 58.5 61.5
QA 76.0 76.5 69.0 68.0
SUM 66.0 67.5 53.0 53.5
Overall 66.9 68.2 58.6 59.1
of our RTE2 system as described in (ref supressed
for blind reviewing) The core of the system is still
the tree alignment algorithm from (Meyers et al,
1996), but without normalization of node weights
and applied to Minipar instead of Maltparser out-
put. To keep things simple, we do not apply syntac-
tic normalization, nor do we use WordNet or other
resources to improve node matching. Instead, we
simply align each text tree to the corresponding hy-
pothesis tree and calculate the coverage, which is
defined as the proportion of aligned content words
in the hypothesis. If the coverage is above a task-
specific threshold, we say entailment is true, other-
wise it is false.
The results are summarized in Table 2. Overall
results on the test set are considerably worse than
on the development set, which is most likely due to
overfitting task-specific parameters for node match-
ing and coverage. Our main interest is to what extent
dependency-based paraphrasing improves our base-
line prediction. The improvement on the develop-
ment set is more than 1%. This is reduced to 0.5%
in the case of the test set.
Our preliminary results indicate a small positive
effect of dependency-based paraphrasing on the re-
sults of our RTE system. Unlike most earlier work,
we did not add resources other than Minipar depen-
dency trees and DIRT paraphrase trees, in order to
isolate the contribution of syntactic paraphrases to
RTE. Nevertheless, our RTE3 system may be im-
proved by using WordNet or other lexical resources
to improve node matching, both in the paraphrasing
step and in the tree-alignment step. In future work,
we hope to improve both the paraphrasing method
(along the lines discussed in Section 2.5) and the
RTE system itself.
Acknowledgments We would like to thank Dekang Lin and
Patrick Pantel for allowing us to use the DIRT data. This work
was jointly conducted within the DAESO project funded by the
Stevin program (De Nederlandse Taalunie) and the IMOGEN
project funded by the Netherlands Organization for Scientific
Research (NWO).
References
R. Bar-Haim, I. Dagan, B. Dolan, L. Ferro, D. Giampic-
colo, B. Magnini, and I. Szpektor. 2006. The second
pascal recognising textual entailment challenge. In
Proceedings of the Second PASCAL Challenges Work-
shop on Recognising Textual Entailment, pages 1?9,
Venice, Italy.
W. Bosma and C. Callison-Burch. 2006. Paraphrase sub-
stitution for recognizing textual entailment. In Pro-
ceedings of CLEF.
R. de Salvo Braz, R. Girju, V. Punyakanok, D. Roth, and
M. Sammons. 2005. An inference model for seman-
tic entailemnt in natural language. In Proceedings of
the First Pascal Challenge Workshop on Recognizing
Textual Entailment, pages 29?32.
A. Hickl, J. Williams, J. Bensley, K. Roberts, B. Rink,
and Y. Shi. 2006. Recognizing textual entailment
with lccs groundhog system. In Proceedings of the
Second PASCAL Challenges Workshop on Recognis-
ing Textual Entailment, pages 80?85, Venice, Italy.
Dekang Lin and Patrick Pantel. 2001. Discovery of infer-
ence rules for question answering. Natural Language
Engineering, 7(4):343?360.
Dekang Lin. 1998. Dependency-based evaluation of
minipar. In Proceedings of the Workshop on Evalua-
tion of Parsing Systems at LREC 1998, pages 317?330,
Granada, Spain.
E. Marsi, E. Krahmer, W. Bosma, and M. Theune. 2006.
Normalized alignment of dependency trees for detect-
ing textual entailment. In Proceedings of the Second
PASCAL Challenges Workshop on Recognising Tex-
tual Entailment, pages 56?61, venice, Italy.
Adam Meyers, Roman Yangarber, and Ralph Grisham.
1996. Alignment of shared forests for bilingual cor-
pora. In Proceedings of 16th International Conference
on Computational Linguistics (COLING-96), pages
460?465, Copenhagen, Denmark.
R. Nielsen, W. Ward, and J.H. Martin. 2006. Toward
dependency path based entailment. In Proceedings of
the Second PASCAL Challenges Workshop on Recog-
nising Textual Entailment, pages 44?49, Venice, Italy.
R. Raina, A. Haghighi, C. Cox, J. Finkel, J. Michels,
K. Toutanova, B. MacCartney, M.C. deMarneffe, C.D.
Manning, and A.Y. Ng. 2005. Robust textual infer-
ence using diverse knowledge sources. In Proceedings
of PASCAL Recognising Textual Entailment Workshop.
J. C. Reynar and A. Ratnaparkhi. 1997. A maximum en-
tropy approach to identifying sentence boundaries. In
Proceedings of the Fifth Conference on Applied Natu-
ral Language Processing, Washington, D.C.
87
buy
by
mod
...
obj
buy
...
pcomp-n
by
Rosneft
{US$ 9.4 billion}Baikalfinansgroup
s mod obj
{Baikalfinansgroup}
subj
known
mod
company
nn
{fin}
rel
which
whn
be
i
later
pred
{which}
subj
pcomp-n
the
det
Russian
mod
state-owned
mod
oil company
nn
state
lex-mod
-
lex-mod
oil
lex-mod
sell
to
mod
...
obj
sell
...
pcomp-n
to
Rosneft
{Baikalfinansgroup}Baikalfinansgroup
s
be
be mod obj
pcomp-n
sell
Baikalfinansgroup
s
to
mod
{US$ 9.4 billion}
obj
{Baikalfinansgroup}
subj
known
mod
company
nn
{fin}
rel
which
whn
be
i
later
pred
{which}
subj
Rosneft
pcomp-n
the
det
Russian
mod
state-owned
mod
oil company
nn
state
lex-mod
-
lex-mod
oil
lex-mod
sell
Baikalfinansgroup
s
be
be
to
mod
{Baikalfinansgroup}
obj
Rosneft
pcomp-n
Figure 2: Alignment of paraphrase source to text (top), alignment of paraphrase translation to hypothesis
(mid), and alignment of hypothesis to paraphrased text (bottom) for pair 1 from RTE3 dev set
88
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 417?420,
Uppsala, Sweden, 15-16 July 2010.
c
?2010 Association for Computational Linguistics
Kyoto: An Integrated System for Specific Domain WSD
Aitor Soroa, Eneko Agirre, Oier Lopez de Lacalle
University of the Basque Country
a.soroa@ehu.es
Monica Monachini
Istituto di Linguistica Computazionale
monica.monachini@ilc.cnr.it
Jessie Lo, Shu-Kai Hsieh
National Taiwan Normal University
shukai@ntnu.edu.tw
Wauter Bosma, Piek Vossen
Vrije Universiteit
{p.vossen,w.bosma}@let.vu.nl
Abstract
This document describes the prelimi-
nary release of the integrated Kyoto sys-
tem for specific domain WSD. The sys-
tem uses concept miners (Tybots) to ex-
tract domain-related terms and produces
a domain-related thesaurus, followed by
knowledge-based WSD based on word-
net graphs (UKB). The resulting system
can be applied to any language with a
lexical knowledge base, and is based on
publicly available software and resources.
Our participation in Semeval task #17 fo-
cused on producing running systems for
all languages in the task, and we attained
good results in all except Chinese. Due
to the pressure of the time-constraints in
the competition, the system is still under
development, and we expect results to im-
prove in the near future.
1 Introduction
In this paper we describe the participation of the
integrated Kyoto system on the ?SemEval-2010
task #17: All-words Word Sense Disambigua-
tion on a Specific Domain? task (Agirre et al,
2010). The goal of our participation was to eval-
uate the preliminary release of the integrated sys-
tem for specific domain WSD developed for the
Kyoto project
1
. Besides, we wanted to test the
performance of our domain specific WSD system
(Agirre et al, 2009) on this test set, and to inte-
grate the thesaurus construction software (Tybots)
developed for the project. The system can be run
for any language and domain if provided with a
lexical knowledge base and some background doc-
uments on the domain.
We will first present the components of our sys-
tem, followed by the experimental design and the
1
http://www.kyoto-project.eu
results. Finally, the conclusions are presented.
2 The Kyoto System for Domain Specific
WSD
We will present in turn UKB, the Tybots, and the
lexical knowledge-bases used.
2.1 UKB
UKB is a knowledge-based unsupervised WSD
system which exploits the structure of an under-
lying Language Knowledge Base (LKB) and finds
the most relevant concepts given an input con-
text (Agirre and Soroa, 2009). UKB starts by tak-
ing the LKB as a graph of concepts G = (V,E)
with a set of vertices V derived from LKB con-
cepts and a set of edges E representing relations
among them. Giving an input context, UKB ap-
plies the so called Personalized PageRank (Haveli-
wala, 2002) over it to obtain the most representa-
tive senses for the context.
PageRank (Brin and Page, 1998) is a method
for scoring the vertices V of a graph according
to each node?s structural importance. The algo-
rithm can be viewed as random walk process that
postulate the existence of a particle that randomly
traverses the graph, but at any time may jump to
a new vertex with a given damping factor (also
called teleport probability). After PageRank cal-
culation, the final weight of node i represents the
proportion of time that a random particle spends
visiting node i after a sufficiently long time. In
standard PageRank, the teleport vector is chosen
uniformly, whereas for Personalized PageRank it
is chosen from a nonuniform distribution of nodes,
specified by a teleport vector.
UKB concentrates the initial probability mass
of the teleport vector in the words occurring in
the context of the target word, causing all random
jumps on the walk to return to these words and
thus assigning a higher rank to the senses linked to
these words. Moreover, the high rank of the words
417
spreads through the links in the graph and make
all the nodes in its vicinity also receive high ranks.
Given a target word, the system checks which is
the relative ranking of its senses, and the WSD
system would output the one ranking highest.
UKB is very flexible and can be use to perform
WSD on different settings, depending on the con-
text used for disambiguating a word instance. In
this paper we use it to perform general and do-
main specific WSD, as shown in section 3. PageR-
ank is calculated by applying an iterative algo-
rithm until convergence below a given threshold
is achieved. Following usual practice, we used a
damping value of 0.85 and set the threshold value
at 0.001. We did not optimize these parameters.
2.2 Tybots
Tybots (Term Yielding Robots) are text mining
software that mine domain terms from corpus
(e.g. web pages), organizing them in a hierar-
chical structure, connecting them to wordnets and
ontologies to create a semantic model for the do-
main (Bosma and Vossen, 2010). The software is
freely available using Subversion
2
. Tybots try to
establish a view on the terminology of the domain
which is as complete as possible, discovering rela-
tions between terms and ranking terms by domain
relevance.
Preceding term extraction, we perform tok-
enization, part-of-speech tagging and lemmatiza-
tion, which is stored in Kyoto Annotation For-
mat (KAF) (Bosma et al, 2009). Tybots work
through KAF documents, acquire domain relevant
terms based on the syntactic features, gather co-
occurrence statistics to decide which terms are sig-
nificant in the domain and produce a thesaurus
with sets of related words. Section 3.3 describes
the specific settings that we used.
2.3 Lexical Knowledge bases
We used the following wordnets, as suggested by
the organizers:
WN30g: English WordNet 3.0 with gloss relations
(Fellbaum, 1998).
Dutch: The Dutch LKB is part of the Cor-
netto database version 1.3 (Vossen et al, 2008).
The Cornetto database can be obtained from
the Dutch/Flanders Taalunie
3
. Cornetto com-
prises taxonomic relations and equivalence rela-
2
http://kyoto.let.vu.nl/svn/kyoto/trunk
3
http://www.inl.nl/nl/lexica/780
#entries #synsets #rels. #WN30g
Monolingual
Chinese 8,186 14,243 20,433 20,584
Dutch 83,812 70,024 224,493 83,669
Italian 46,724 49,513 65,567 52,524
WN30g 147,306 117,522 525,351 n/a
Bilingual
Chinese-eng 8,186 141,561 566,368
Dutch-eng 83,812 188,511 833,513
Italian-eng 46,724 167,094 643,442
Table 1: Wordnets and their sizes (entries, synsets,
relations and links to WN30g).
tions from both WordNet 2.0 and 3.0. Cornetto
concepts are mapped to English WordNet 3.0.
Italian: Italwordnet (Roventini et al, 2003) was
created in the framework of the EuroWordNet,
employs the same set of semantic relations used
in EuroWordNet, and includes links to WordNet
3.0 synsets.
Chinese: The Chinese WordNet (Version 1.6) is
now partially open to the public
4
(Tsai et al,
2001). The Chinese WordNet is also mapped to
WordNet 3.0.
Table 1 shows the sizes of the graphs created
using each LKB as a source. The upper part shows
the number of lexical entries, synsets and relations
of each LKB. It also depicts the number of links to
English WordNet 3.0 synsets.
In addition, we also created bilingual graphs for
Dutch, Italian and Chinese, comprising the orig-
inal monolingual LKB, the links to WordNet 3.0
and WordNet 3.0 itself. We expected this richer
graphs to perform better performance. The sizes
of the bilingual graphs are shown in the lower side
of Table 1.
3 Experimental setting
All test documents were lemmatized and PoS-
tagged using the linguistic processors available
within the Kyoto project. In this section we de-
scribe the submitted runs.
3.1 UKB parameters
We use UKB with the default parameters. In par-
ticular, we don?t use dictionary weights, which in
the case of English come from annotated corpora.
This is done in order to make the system fully un-
supervised. It?s also worth mentioning that in the
default setting parts of speech were not used.
4
http://cwn.ling.sinica.edu.tw
418
RANK RUN P R R-NOUN R-VERB
Chinese
- 1sense 0.562 0.562 0.589 0.518
1 Best 0.559 0.559 - -
- Random 0.321 0.321 0.326 0.312
4 kyoto-3 0.322 0.296 0.257 0.360
3 kyoto-2 0.342 0.285 0.251 0.342
5 kyoto-1 0.310 0.258 0.256 0.261
Dutch
1 kyoto-3 0.526 0.526 0.575 0.450
2 kyoto-2 0.519 0.519 0.561 0.454
- 1sense 0.480 0.480 0.600 0.291
3 kyoto-1 0.465 0.465 0.505 0.403
- Random 0.328 0.328 0.350 0.293
English
1 Best 0.570 0.555 - -
- 1sense 0.505 0.505 0.519 0.454
10 kyoto-2 0.481 0.481 0.487 0.462
22 kyoto-1 0.384 0.384 0.382 0.391
- Random 0.232 0.232 0.253 0.172
Italian
1 kyoto-3 0.529 0.529 0.530 0.528
2 kyoto-2 0.521 0.521 0.522 0.519
3 kyoto-1 0.496 0.496 0.507 0.468
- 1sense 0.462 0.462 0.472 0.437
- Random 0.294 0.294 0.308 0.257
Table 2: Overall results of our runs, including pre-
cision (P) and recall (R), overall and for each PoS.
We include the First Sense (1sense) and random
baselines, as well as the best run, as provided by
the organizers.
3.2 Run1: UKB using context
The first run is an application of the UKB tool in
the standard setting, as described in (Agirre and
Soroa, 2009). Given the input text, we split it in
sentences, and we disambiguate each sentence at a
time. We extract the lemmas which have an entry
in the LKB and then apply Personalized PageR-
ank over all of them, obtaining a score for every
concept of the LKB. To disambiguate the words in
the sentence we just choose its associated concept
(sense) with maximum score.
In our experiments we build a context of at least
20 content words for each sentence to be disam-
biguated, taking the sentences immediately before
when necessary. UKB allows two main methods
of disambiguation, namely ppr and ppr w2w. We
used the latter method, as it has been shown to per-
form best.
In this setting we used the monolingual graphs
for each language (cf. section 2.3). Note that
in this run there is no domain adaptation, it thus
serves us as a baseline for assessing the benefits of
applying domain adaptation techniques.
3.3 Run2: UKB using related words
Instead of disambiguating words using their con-
text of occurrence, we follow the method de-
scribed in (Agirre et al, 2009). The idea is to first
obtain a list of related words for each of the tar-
get words, as collected from a domain corpus. On
a second step each target word is disambiguated
using the N most related words as context (see
below). For instance, in order to disambiguate
the word environment, we would not take into
account the context of occurrence (as in Section
3.2), but we would use the list of most related
words in the thesaurus (e.g. ?biodiversity, agri-
culture, ecosystem, nature, life, climate, . . .?). Us-
ing UKB over these contexts we obtain the most
predominant sense for each target word in the do-
main(McCarthy et al, 2007), which is used to la-
bel all occurrences of the target word in the test
dataset.
In order to build the thesaurus with the lists of
related words, we used Tybots (c.f. section 2.2),
one for each corpus of the evaluation dataset, i.e.
Chinese, Dutch, English, and Italian. We used the
background documents provided by the organiz-
ers, which we processed using the linguistic pro-
cessors of the project to obtain the documents in
KAF. We used the Tybots with the following set-
tings. We discarded co-occurring words with fre-
quencies below 10
5
. Distributional similarity was
computed using (Lin, 1998). Finally, we used up
to 50 related words for each target word.
As in run1, we used the monolingual graphs for
the LKBs in each language.
3.4 Run3: UKB using related words and
bilingual graphs
The third run is exactly the same as run2, except
that we used bilingual graphs instead of monolin-
gual ones for all languages other than English (cf.
section 2.3). There is no run3 for English.
4 Results
Table 2 shows the results of our system on the
different languages. We will analyze different as-
pects of the results in turn.
Domain adaptation: Using Personalized Pager-
ank over related words (run2 and run3) con-
sistently outperforms the standard setting (run1)
in all languages. This result is consistent with
5
In the case of Dutch we did not use any threshold due to
the small size of the background corpus.
419
our previous work on English (Agirre et al,
2009), and shows that domain adaptation works
for knowledge-based systems.
Monolingual vs. Bilingual graphs: As ex-
pected, we obtained better results using the bilin-
gual graphs (run3) than with monolingual graphs
(run2), showing that the English WordNet has a
richer set of relations, and that those relations can
be successfully ported to other languages. This
confirms that aligning different wordnets at the
synset level is highly beneficial.
Overall results: the results of our runs are highly
satisfactory. In two languages (Dutch and Ital-
ian) our best runs perform better than the first
sense baseline, which is typically hard to beat for
knowledge-based systems. In English, our system
performs close but below the first sense baseline,
and in Chinese our method performed below the
random baseline.
The poor results obtained for Chinese can be
due the LKB topology; an analysis over the graph
shows that it is formed by a large number of
small components, unrelated with each other. This
?flat? structure heavily penalizes the graph based
method, which is many times unable to discrimi-
nate among the concepts of a word. We are cur-
rently inspecting the results, and we don?t discard
bugs, due to the preliminary status of our software.
In particular, we need to re-examine the output of
the Tybot for Chinese.
5 Conclusions
This paper describes the results of the prelimi-
nary release of he integrated Kyoto system for do-
main specific WSD. It comprises Tybots to con-
struct a domain-related thesaurus, and UKB for
knowledge-based WSD based on wordnet graphs.
We applied our system to all languages in the
dataset, obtaining good results. In fact, our sys-
tem can be applied to any language with a lexical
knowledge base, and is based on publicly available
software and resources. We used the wordnets and
background texts provided by the organizers of the
task.
Our results show that we were succesful in
adapting our system to the domain, as we man-
aged to beat the first sense baseline in two lan-
guages. Our results also show that adding the En-
glish WordNet to the other language wordnets via
the available links is beneficial.
Our participation focused on producing running
systems for all languages in the task, and we at-
tained good results in all except Chinese. Due to
the pressure and the time-constraints in the com-
petition, the system is still under development. We
are currently revising our system for bugs and fine-
tuning it.
Acknowledgments
This work task is partially funded by the Eu-
ropean Commission (KYOTO ICT-2007-211423),
the Spanish Research Department (KNOW-2
TIN2009-14715-C04-01) and the Basque Govern-
ment (BERBATEK IE09-262).
References
E. Agirre and A. Soroa. 2009. Personalizing pagerank for
word sense disambiguation. In Proceedings of EACL09,
pages 33?41. Association for Computational Linguistics.
E. Agirre, O. L?opez de Lacalle, and A. Soroa. 2009.
Knowledge-based wsd on specific domains: Performing
better than generic supervised wsd. In Proceedigns of IJ-
CAI. pp. 1501-1506.?.
E. Agirre, O. L?opez de Lacalle, C. Fellbaum, S.K. Hsieh,
M. Tesconi, M. Monachini, P. Vossen, and R. Segers.
2010. Semeval-2010 task 17: All-words word sense dis-
ambiguation on a specific domain. In Same volume.
W. E. Bosma and P. Vossen. 2010. Bootstrapping language
neutral term extraction. In Proceedings of LREC2010,
May.
W. E. Bosma, P. Vossen, A. Soroa, G. Rigau, M. Tesconi,
A. Marchetti, M. Monachini, and C. Aliprandi. 2009.
KAF: a generic semantic annotation format. In Proceed-
ings of the GL2009 Workshop on Semantic Annotation.
S. Brin and L. Page. 1998. The anatomy of a large-scale
hypertextual web search engine. Computer Networks and
ISDN Systems, 30(1-7).
C. Fellbaum. 1998. WordNet: An Electronical Lexical
Database. The MIT Press, Cambridge, MA.
T. H. Haveliwala. 2002. Topic-sensitive pagerank. In WWW
?02: Proceedings of the 11th international conference on
WWW, pages 517?526, New York, NY, USA. ACM.
D. Lin. 1998. Automatic retrieval and clustering of similar
words. In Proceedings of ACL98, Montreal, Canada.
D. McCarthy, R. Koeling, J. Weeds, and J. Carroll. 2007.
Unsupervised acquisition of predominant word senses.
Computational Linguistics, 33(4).
A. Roventini, A. Alonge, F. Bertagna, N. Calzolari, J. Can-
cila, C. Girardi, B. Magnini, R. Marinelli, M. Speranza,
and A. Zampolli. 2003. Italwordnet: building a large
semantic database for the automatic treatment of Italian.
Linguistica Computazionale, Special Issue (XVIII-XIX),
pages 745?791.
B.S. Tsai, C.R. Huang, S.c. Tseng, J.Y. Lin, K.J. Chen, and
Y.S. Chuang. 2001. Definition and tests for lexical se-
mantic relations in Chinese. In Proceedings CLSW 2001.
P. Vossen, I. Maks, R. Segers, H. van der Vliet, and H. van
Zutphen. 2008. The cornetto database: the architecture
and alignment issues. In Proceedings GWC 2008, pages
485?506.
420
