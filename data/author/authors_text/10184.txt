Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 145?152,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Query Expansion using LMF-Compliant Lexical Resources
Tokunaga Takenobu
Tokyo Inst. of Tech.
Dain Kaplan
Tokyo Inst. of Tech.
Nicoletta Calzolari
ILC/CNR
Monica Monachini
ILC/CNR
Claudia Soria
ILC/CNR
Virach Sornlertlamvanich
TCL, NICT
Thatsanee Charoenporn
TCL, NICT
Xia Yingju
Fujitsu R&D Center
Chu-Ren Huang
The Hong Kong Polytec. Univ.
Shu-Kai Hsieh
National Taiwan Normal Univ.
Shirai Kiyoaki
JAIST
Abstract
This paper reports prototype multilin-
gual query expansion system relying on
LMF compliant lexical resources. The
system is one of the deliverables of a
three-year project aiming at establish-
ing an international standard for language
resources which is applicable to Asian
languages. Our important contributions
to ISO 24613, standard Lexical Markup
Framework (LMF) include its robustness
to deal with Asian languages, and its ap-
plicability to cross-lingual query tasks, as
illustrated by the prototype introduced in
this paper.
1 Introduction
During the last two decades corpus-based ap-
proaches have come to the forefront of NLP re-
search. Since without corpora there can be no
corpus-based research, the creation of such lan-
guage resources has also necessarily advanced
as well, in a mutually beneficial synergetic re-
lationship. One of the advantages of corpus-
based approaches is that the techniques used
are less language specific than classical rule-
based approaches where a human analyses the
behaviour of target languages and constructs
rules manually. This naturally led the way
for international resource standardisation, and in-
deed there is a long standing precedent in the
West for it. The Human Language Technol-
ogy (HLT) society in Europe has been particu-
larly zealous in this regard, propelling the cre-
ation of resource interoperability through a se-
ries of initiatives, namely EAGLES (Sanfilippo et
al., 1999), PAROLE/SIMPLE (Lenci et al, 2000),
ISLE/MILE (Ide et al, 2003), and LIRICS1. These
1http://lirics.loria.fr/
continuous efforts have matured into activities in
ISO-TC37/SC42, which aims at making an inter-
national standard for language resources.
However, due to the great diversity of languages
themselves and the differing degree of technolog-
ical development for each, Asian languages, have
received less attention for creating resources than
their Western counterparts. Thus, it has yet to be
determined if corpus-based techniques developed
for well-computerised languages are applicable on
a broader scale to all languages. In order to effi-
ciently develop Asian language resources, utilis-
ing an international standard in this creation has
substantial merits.
We launched a three-year project to create an
international standard for language resources that
includes Asian languages. We took the following
approach in seeking this goal.
? Based on existing description frameworks,
each research member tries to describe sev-
eral lexical entries and find problems with
them.
? Through periodical meetings, we exchange
information about problems found and gen-
eralise them to propose solutions.
? Through an implementation of an application
system, we verify the effectiveness of the pro-
posed framework.
Below we summarise our significant contribution
to an International Standard (ISO24613; Lexical
Markup Framework: LMF).
1st year After considering many characteristics
of Asian languages, we elucidated the shortcom-
ings of the LMF draft (ISO24613 Rev.9). The
draft lacks the following devices for Asian lan-
guages.
2http://www.tc37sc4.org/
145
(1) A mapping mechanism between syntactic
and semantic arguments
(2) Derivation (including reduplication)
(3) Classifiers
(4) Orthography
(5) Honorifics
Among these, we proposed solutions for (1) and
(2) to the ISO-TC37 SC4 working group.
2nd year We proposed solutions for above the
(2), (3) and (4) in the comments of the Committee
Draft (ISO24613 Rev. 13) to the ISO-TC37 SC4
working group. Our proposal was included in DIS
(Draft International Standard).
(2?) a package for derivational morphology
(3?) the syntax-semantic interface resolving the
problem of classifiers
(4?) representational issues with the richness of
writing systems in Asian languages
3rd year Since ISO 24613 was in the FDIS stage
and fairly stable, we built sample lexicons in Chi-
nese, English, Italian, Japanese, and Thai based
on ISO24613. At the same time, we implemented
a query expansion system utilising rich linguis-
tic resources including lexicons described in the
ISO 24613 framework. We confirmed that a sys-
tem was feasible which worked on the tested lan-
guages (including both Western and Asian lan-
guages) when given lexicons compliant with the
framework. ISO 24613 (LMF) was approved by
the October 2008 ballot and published as ISO-
24613:2008 on 17th November 2008.
Since we have already reported our first 2 year
activities elsewhere (Tokunaga and others, 2006;
Tokunaga and others, 2008), we focus on the
above query expansion system in this paper.
2 Query expansion using
LMF-compliant lexical resources
We evaluated the effectiveness of LMF on a mul-
tilingual information retrieval system, particularly
the effectiveness for linguistically motivated query
expansion.
The linguistically motivated query expansion
system aims to refine a user?s query by exploiting
the richer information contained within a lexicon
described using the adapted LMF framework. Our
lexicons are completely complaint with this inter-
national standard. For example, a user inputs a
keyword ?ticket? as a query. Conventional query
expansion techniques expand this keyword to a
set of related words by using thesauri or ontolo-
gies (Baeza-Yates and Ribeiro-Neto, 1999). Using
the framework proposed by this project, expand-
ing the user?s query becomes a matter of following
links within the lexicon, from the source lexical
entry or entries through predicate-argument struc-
tures to all relevant entries (Figure 1). We focus
on expanding the user inputted list of nouns to rel-
evant verbs, but the reverse would also be possible
using the same technique and the same lexicon.
This link between entries is established through
the semantic type of a given sense within a lexical
entry. These semantic types are defined by higher-
level ontologies, such as MILO or SIMPLE (Lenci
et al, 2000) and are used in semantic predicates
that take such semantic types as a restriction ar-
gument. Since senses for verbs contain a link to
a semantic predicate, using this semantic type, the
system can then find any/all entries within the lexi-
con that have this semantic type as the value of the
restriction feature of a semantic predicate for any
of their senses. As a concrete example, let us con-
tinue using the ?ticket? scenario from above. The
lexical entry for ?ticket? might contain a semantic
type definition something like in Figure 2.
<LexicalEntry ...>
<feat att="POS" val="N"/>
<Lemma>
<feat att="writtenForm"
val="ticket"/>
</Lemma>
<Sense ...>
<feat att="semanticType"
val="ARTIFACT"/>
...
</Sense>
...
</LexicalEntry>
Figure 2: Lexical entry for ?ticket?
By referring to the lexicon, we can then derive
any actions and events that take the semantic type
?ARTIFACT? as an argument.
First all semantic predicates are searched for ar-
guments that have an appropriate restriction, in
this case ?ARTIFACT? as shown in Figure 3, and
then any lexical entries that refer to these predi-
cates are returned. An equally similar definition
would exist for ?buy?, ?find? and so on. Thus,
by referring to the predicate-argument structure of
related verbs, we know that these verbs can take
146
<LexicalEntry ...>
  <feat att="POS" val="Noun"/>
  <Lemma>
    <feat att="writtenForm" val="ticket"/>
  </Lemma>
  <Sense ...>
    <feat att="semanticType" val="ARTIFACT"/>
    ...
  </Sense>
  ...
</LexicalEntry>
User Inputs
ticket
<Sense>
<SemanticFeature>
Semantic Features of type 
"restriction" that take 
Sense's semanticType
All senses for 
matched nouns
<SemanticPredicate 
  id="pred-sell-1">
  <SemanticArgument>
    <feat att="label" val="X"/>
    <feat att="semanticRole" val="Agent"/>
    <feat att="restriction" val="Human"/>
  </SemanticArgument>
  ...
  <SemanticArgument>
    <feat att="label" val="Z"/>
    <feat att="semanticRole" val="Patient"/>
    <feat att="restriction" 
          val="ARTIFACT,LOCATION"/>
  </SemanticArgument>
</SemanticPredicate>
All Semantic Predicates 
that contain matched 
Semantic Features
<Sense>
Senses that use matched 
Semantic Predicates
<LexicalEntry ...>
  <feat att="POS" val="Verb"/>
  <Lemma>
    <feat att="writtenForm" val="sell"/>
  </Lemma>
  <Sense id="sell-1" ...>
    ...
    <PredicativeRepresentation
      predicate="pred-sell-1" ...>
  </Sense>
</LexicalEntry>
<LexicalEntry>
<SemanticPredicate>
<LexicalEntry>
System outputs
"sell", ...
For each <Sense> find all 
<SemanticArgument> that 
take this semanticType as 
a feature of type 
"restriction"
Find all verbs <LexicalEntry> 
that use these 
<SemanticPredicate>
All verbs that have 
matched Senses
Figure 1: QE Process Flow
147
<LexicalEntry ...>
<feat att="POS" val="V"/>
<Lemma>
<feat att="writtenForm"
val="sell"/>
</Lemma>
<Sense id="sell-1" ...>
<feat att="semanticType"
val="Transaction"/>
<PredicativeRepresentation
predicate="pred-sell-1"
correspondences="map-sell1">
</Sense>
</LexicalEntry>
<SemanticPredicate id="pred-sell-1">
<SemanticArgument ...>
...
<feat att="restriction"
val="ARTIFACT"/>
</SemanticArgument>
</SemanticPredicate>
Figure 3: Lexical entry for ?sell? with its semantic
predicate
?ticket? in the role of object. The system then re-
turns all relevant entries, here ?buy?, ?sell? and
?find?, in response to the user?s query. Figure 1
schematically shows this flow.
3 A prototype system in detail
3.1 Overview
To test the efficacy of the LMF-compliant lexi-
cal resources, we created a system implementing
the query expansion mechanism explained above.
The system was developed in Java for its ?com-
pile once, run anywhere? portability and its high-
availability of reusable off-the-shelf components.
On top of Java 5, the system was developed us-
ing JBoss Application Server 4.2.3, the latest stan-
dard, stable version of the product at the time of
development. To provide fast access times, and
easy traversal of relational data, a RDB was used.
The most popular free open-source database was
selected, MySQL, to store all lexicons imported
into the system, and the system was accessed, as a
web-application, via any web browser.
3.2 Database
The finalised database schema is shown in Fig-
ure 4. It describes the relationships between en-
tities, and more or less mirrors the classes found
within the adapted LMF framework, with mostly
only minor exceptions where it was efficacious for
querying the data. Due to space constraints, meta-
data fields, such as creation time-stamps have been
left out of this diagram. Since the system also al-
lows for multiple lexicons to co-exist, a lexicon id
resides in every table. This foreign key has been
highlighted in a different color, but not connected
via arrows to make the diagram easier to read. In
addition, though in actuality this foreign key is not
required for all tables, it has been inserted as a con-
venience for querying data more efficiently, even
within join tables (indicated in blue). Having mul-
tiple lexical resources co-existing within the same
database allows for several advantageous features,
and will be described later. Some tables also con-
tain a text id, which stores the original id attribute
for that element found within the XML. This is
not used in the system itself, and is stored only for
reference.
3.3 System design
As mentioned above, the application is deployed
to JBoss AS as an ear-file. The system it-
self is composed of java classes encapsulating
the data contained within the database, a Pars-
ing/Importing class for handling the LMF XML
files after they have been validated, and JSPs,
which contain HTML, for displaying the inter-
face to the user. There are three main sections
to the application: Search, Browse, and Config-
ure. Explaining last to first, the Configure section,
shown in Figure 5, allows users to create a new
lexicon within the system or append to an exist-
ing lexicon by uploading a LMF XML file from
their web browser, or delete existing lexicons that
are no longer needed/used. After import, the data
may be immediately queried upon with no other
changes to system configuration, from within both
the Browse and Search sections. Regardless of
language, the rich syntactic/semantic information
contained within the lexicon is sufficient for car-
rying out query expansion on its own.
The Browse section (Figure 6) allows the user to
select any available lexicon to see the relationships
contained within it, which contains tabs for view-
ing all noun to verb connections, a list of nouns, a
list of verbs, and a list of semantic types. Each has
appropriate links allowing the user to easily jump
to a different tab of the system. Clicking on a noun
takes them to the Search section (Figure 7). In this
section, the user may select many lexicons to per-
form query extraction on, as is visible in Figure 7.
148
semantic_link 
VARCHAR (64)
sense
sense_id
PRIMARY KEY
synset_id
FOREIGN KEY
syn_sem_correspondence_id
FOREIGN KEY
semantic_predicate_id
FOREIGN KEY
semantic_type
VARCHAR (64)
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
lexicon_id
FOREIGN KEY
text_id
VARCHAR (100)
semantic_predicate_id
PRIMARY KEY
semantic_predicate
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
semantic_argument_id
PRIMARY KEY
semantic_argument
value
VARCHAR (100)
attribute
VARCHAR (100)
lexicon_id
FOREIGN KEY
semantic_feature_id
PRIMARY KEY
semantic_feature
lexicon_id
FOREIGN KEY
semantic_argument_id
FOREIGN KEY
semantic_predicate_id
FOREIGN KEY
semantic_predicate_to_argument
lexicon_id
FOREIGN KEY
semantic_feature_id
FOREIGN KEY
semantic_argument_id 
FOREIGN KEY
semantic_argument_to_feature
description
TEXT
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
synset_id
PRIMARY KEY
synset
written_form
VARCHAR (64) NOT NULL
part_of_speech
ENUM( 'Verb', 'Noun' , 'Unknown')
lexical_entry
text_id
VARCHAR (64)
entry_id 
PRIMARY KEY
lexicon_id 
FOREIGN KEY
semantic_feature
FOREIGN KEY
syntactic_feature
FOREIGN KEY
lexicon_id
FOREIGN KEY
argument_map_id
PRIMARY KEY
syn_sem_argument_map
lexicon_id
FOREIGN KEY
argument_map_id
FOREIGN KEY
syn_sem_correspondence_id 
FOREIGN KEY
syn_sem_correspondence_to_map
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
syn_sem_correspondence_id
PRIMARY KEY
syn_sem_correspondence
lexicon_id
FOREIGN KEY
sense_id
FOREIGN KEY
entry_id
FOREIGN KEY
lexical_entry_to_sense
lexicon_id
FOREIGN KEY
text_id
VARCHAR (100)
frame_id
PRIMARY KEY
subcat_frame
lexicon_id
FOREIGN KEY
frame_id
FOREIGN KEY
sense_id
FOREIGN KEY
entry_id
FOREIGN KEY
lexical_entry_to_subcat_frame
lexicon_id
FOREIGN KEY
text_id
VARCHAR (64)
syntactic_argument_id
PRIMARY KEY
syntactic_argument
value
VARCHAR (100)
attribute
VARCHAR (100)
lexicon_id
FOREIGN KEY
syntactic_feature_id
PRIMARY KEY
syntactic_feature
lexicon_id
FOREIGN KEY
syntactic_argument_id
FOREIGN KEY
frame_id
FOREIGN KEY
subcat_frame_to_argument
lexicon_id
FOREIGN KEY
syntactic_feature_id
FOREIGN KEY
syntactic_argument_id 
FOREIGN KEY
syntactic_argument_to_feature
description
VARCHAR(128)
language
VARCHAR(64)
lexicon_id
PRIMARY KEY
lexicon
relation_type 
VARCHAR (64)
lexicon_id
FOREIGN KEY
related_sense_id
FOREIGN KEY
sense_id
FOREIGN KEY
sense_relation
Figure 4: Database schema
Figure 5: QE System - Configure Figure 6: QE System - Browse
149
Figure 7: QE System - Search
3.4 Semantic information
This new type of query expansion requires rich
lexical information. We augmented our data using
the SIMPLE ontology for semantic types, using
the same data for different languages. This had
the added benefit of allowing cross-language ex-
pansion as a result. In steps two and three of Fig-
ure 1 when senses are retrieved that take specific
semantic types as arguments, this process can be
done across all (or as many as are selected) lex-
icons in the database. Thus, results such as are
shown in Figure 7 are possible. In this figure the
Japanese word for ?nail? is entered, and results for
both selected languages, Japanese and Italian, are
returned. This feature requires the unification of
the semantic type ontology strata.
3.5 Possible extension
Next steps for the QE platform are to explore the
use of other information already defined within the
adapted framework, specifically sense relations.
Given to the small size of our sample lexicon, data
sparsity is naturally an issue, but hopefully by ex-
ploring and exploiting these sense relations prop-
erly, the system may be able to further expand a
user?s query to include a broader range of selec-
tions using any additional semantic types belong-
ing to these related senses. The framework also
contains information about the order in which syn-
tactic arguments should be placed. This informa-
tion should be used to format the results from the
user?s query appropriately.
4 An Additional Evaluation
We conducted some additional query expansion
experiments using a corpus that was acquired from
Chinese LDC (No. ?2004-863-009?) as a base (see
below). This corpus marked an initial achievement
in building a multi-lingual parallel corpus for sup-
porting development of cross-lingual NLP appli-
cations catering to the Beijing 2008 Olympics.
The corpus contains parallel texts in Chinese,
English and Japanese and covers 5 domains that
are closely related to the Olympics: traveling, din-
ing, sports, traffic and business. The corpus con-
sists of example sentences, typical dialogues and
articles from the Internet, as well as other language
teaching materials. To deal with the different lan-
guages in a uniform manner, we converted the cor-
pus into our proposed LMF-compliant lexical re-
sources framework, which allowed the system to
expand the query between all the languages within
the converted resources without additional modifi-
cations.
As an example of how this IR system func-
tioned, suppose that Mr. Smith will be visiting
Beijing to see the Olympic games and wants to
know how to buy a newspaper. Using this system,
he would first enter the query ?newspaper?. For
this query, with the given corpus, the system re-
turns 31 documents, fragments of the first 5 shown
below.
(1) I?ll bring an English newspaper immediately.
(2) Would you please hand me the newspaper.
(3) There?s no use to go over the newspaper ads.
(4) Let?s consult the newspaper for such a film.
(5) I have little confidence in what the newspa-
pers say.
Yet it can be seen that the displayed results are not
yet useful enough to know how to buy a newspa-
per, though useful information may in fact be in-
cluded within some of the 31 documents. Using
the lexical resources, the query expansion module
suggests ?buy?, ?send?, ?get?, ?read?, and ?sell?
as candidates to add for a revised query.
Mr. Smith wants to buy a newspaper, so he se-
lects ?buy? as the expansion term. With this query
the system returns 11 documents, fragments of the
first 5 listed below.
(6) I?d like some newspapers, please.
150
(7) Oh, we have a barber shop, a laundry, a store,
telegram services, a newspaper stand, table
tennis, video games and so on.
(8) We can put an ad in the newspaper.
(9) Have you read about the Olympic Games of
Table Tennis in today?s newspaper, Miss?
(10) newspaper says we must be cautious about
tidal waves.
This list shows improvement, as information about
newspapers and shopping is present, but still ap-
pears to lack any documents directly related to
how to buy a newspaper.
Using co-occurrence indexes, the IR system
returns document (11) below, because the noun
?newspaper? and the verb ?buy? appear in the
same sentence.
(11) You can make change at some stores, just buy
a newspaper or something.
From this example it is apparent that this sort
of query expansion is still too naive to apply to
real IR systems. It should be noted, however, that
our current aim of evaluation was in confirming
the advantage of LMF in dealing with multiple
languages, for which we conducted a similar run
with Chinese and Japanese. Results of these tests
showed that in following the LMF framework in
describing lexical resources, it was possibile to
deal with all three languages without changing the
mechanics of the system at all.
5 Discussion
LMF is, admittedly, a ?high-level? specification,
that is, an abstract model that needs to be fur-
ther developed, adapted and specified by the lex-
icon encoder. LMF does not provide any off-the-
shelf representation for a lexical resource; instead,
it gives the basic structural components of a lexi-
con, leaving full freedom for modeling the partic-
ular features of a lexical resource. One drawback
is that LMF provides only a specification manual
with a few examples. Specifications are by no
means instructions, exactly as XML specifications
are by no means instructions on how to represent
a particular type of data.
Going from LMF specifications to a true instan-
tiation of an LMF-compliant lexicon is a long way,
and comprehensive, illustrative and detailed ex-
amples for doing this are needed. Our prototype
system provides a good starting example for this
direction. LMF is often taken as a prescriptive
description, and its examples taken as pre-defined
normative examples to be used as coding guide-
lines. Controlled and careful examples of conver-
sion to LMF-compliant formats are also needed to
avoid too subjective an interpretation of the stan-
dard.
We believe that LMF will be a major base
for various SemanticWeb applications because it
provides interoperability across languages and di-
rectly contributes to the applications themselves,
such as multilingual translation, machine aided
translation and terminology access in different lan-
guages.
From the viewpoint of LMF, our prototype
demonstrates the adaptability of LMF to a rep-
resentation of real-scale lexicons, thus promoting
its adoption to a wider community. This project
is one of the first test-beds for LMF (as one of
its drawbacks being that it has not been tested on
a wide variety of lexicons), particularly relevant
since it is related to both Western and Asian lan-
guage lexicons. This project is a concrete attempt
to specify an LMF-compliant XML format, tested
for representative and parsing efficiency, and to
provide guidelines for the implementation of an
LMF-compliant format, thus contributing to the
reduction of subjectivity in interpretation of stan-
dards.
From our viewpoint, LMF has provided a for-
mat for exchange of information across differently
conceived lexicons. Thus LMF provides a stan-
dardised format for relating them to other lexical
models, in a linguistically controlled way. This
seems an important and promising achievement in
order to move the sector forward.
6 Conclusion
This paper described the results of a three-year
project for creating an international standard for
language resources in cooperation with other ini-
tiatives. In particular, we focused on query expan-
sion using the standard.
Our main contribution can be summarised as
follows.
? We have contributed to ISO TC37/SC4 ac-
tivities, by testing and ensuring the portabil-
ity and applicability of LMF to the devel-
opment of a description framework for NLP
lexicons for Asian languages. Our contribu-
tion includes (1) a package for derivational
151
morphology, (2) the syntax-semantic inter-
face with the problem of classifiers, and (3)
representational issues with the richness of
writing systems in Asian languages. As of
October 2008, LMF including our contribu-
tions has been approved as the international
standard ISO 26413.
? We discussed Data Categories necessary
for Asian languages, and exemplified sev-
eral Data Categories including reduplication,
classifier, honorifics and orthography. We
will continue to harmonise our activity with
that of ISO TC37/SC4 TDG2 with respect to
Data Categories.
? We designed and implemented an evaluation
platform of our description framework. We
focused on linguistically motivated query ex-
pansion module. The system works with lexi-
cons compliant with LMF and ontologies. Its
most significant feature is that the system can
deal with any language as far as the those lex-
icons are described according to LMF. To our
knowledge, this is the first working system
adopting LMF.
In this project, we mainly worked on three
Asian languages, Chinese, Japanese and Thai, on
top of the existing framework which was designed
mainly for European languages. We plan to dis-
tribute our results to HLT societies of other Asian
languages, requesting for their feedback through
various networks, such as the Asian language re-
source committee network under Asian Federation
of Natural Language Processing (AFNLP)3, and
the Asian Language Resource Network project4.
We believe our efforts contribute to international
activities like ISO-TC37/SC45 (Francopoulo et al,
2006).
Acknowledgments
This research was carried out through financial
support provided under the NEDO International
Joint Research Grant Program (NEDO Grant).
References
R. Baeza-Yates and B. Ribeiro-Neto. 1999. Modern
Information Retrieval. Addison-Wesley.
3http://www.afnlp.org/
4http://www.language-resource.net/
5http://www.tc37sc4.org/
G. Francopoulo, G. Monte, N. Calzolari, M. Mona-
chini, N. Bel, M. Pet, and C. Soria. 2006. Lex-
ical markup framework (LMF). In Proceedings of
LREC2006.
N. Ide, A. Lenci, and N. Calzolari. 2003. RDF in-
stantiation of ISLE/MILE lexical entries. In Pro-
ceedings of the ACL 2003 Workshop on Linguistic
Annotation: Getting the Model Right, pages 25?34.
A. Lenci, N. Bel, F. Busa, N. Calzolari, E. Gola,
M. Monachini, A. Ogonowsky, I. Peters, W. Peters,
N. Ruimy, M. Villegas, and A. Zampolli. 2000.
SIMPLE: A general framework for the development
of multilingual lexicons. International Journal of
Lexicography, Special Issue, Dictionaries, Thesauri
and Lexical-Semantic Relations, XIII(4):249?263.
A. Sanfilippo, N. Calzolari, S. Ananiadou,
R. Gaizauskas, P. Saint-Dizier, and P. Vossen.
1999. EAGLES recommendations on semantic
encoding. EAGLES LE3-4244 Final Report.
T. Tokunaga et al 2006. Infrastructure for standard-
ization of Asian language resources. In Proceedings
of the COLING/ACL 2006 Main Conference Poster
Sessions, pages 827?834.
T. Tokunaga et al 2008. Adapting international stan-
dard for asian language technologies. In Proceed-
ings of the Sixth International Language Resources
and Evaluation (LREC?08).
152
Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries, ACL-IJCNLP 2009, pages 88?95,
Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLP
Automatic Extraction of Citation Contexts for Research Paper
Summarization: A Coreference-chain based Approach
Dain Kaplan Ryu Iida
Department of Computer Science
Tokyo Institute of Technology
{dain,ryu-i,take}@cl.cs.titech.ac.jp
Takenobu Tokunaga
Abstract
This paper proposes a new method based
on coreference-chains for extracting cita-
tions from research papers. To evaluate
our method we created a corpus of cita-
tions comprised of citing papers for 4 cited
papers. We analyze some phenomena of
citations that are present in our corpus,
and then evaluate our method against a
cue-phrase-based technique. Our method
demonstrates higher precision by 7?10%.
1 Introduction
Review and comprehension of existing research is
fundamental to the ongoing process of conducting
research; however, the ever increasing volume of
research papers makes accomplishing this task in-
creasingly more difficult. To mitigate this problem
of information overload, a form of knowledge re-
duction may be necessary.
Past research (Garfield et al, 1964; Small,
1973) has shown that citations contain a plethora
of latent information available and that much
can be gained by exploiting it. Indeed, there
is a wealth of literature on topic-clustering, e.g.
bibliographic coupling (Kessler, 1963), or co-
citation analysis (Small, 1973). Subsequent re-
search demonstrated that citations could be clus-
tered on their quality, using keywords that ap-
peared in the running-text of the citation (Wein-
stock, 1971; Nanba et al, 2000; Nanba et al,
2004; Teufel et al, 2006).
Similarly, other work has shown the utility in
the IR domain of ranking the relevance of cited pa-
pers by using supplementary index terms extracted
from the content of citations in citing papers,
including methods that search through a fixed
character-length window (O?Connor, 1982; Brad-
shaw, 2003), or that focus solely on the sentence
containing the citation (Ritchie et al, 2008) for
acquiring these terms. A prior case study (Ritchie
et al, 2006) pointed out the challenges in proper
identification of the full span of a citation in run-
ning text and acknowledged that fixed-width win-
dows have their limits. In contrast to this, en-
deavors have been made to extract the entire span
of a citation by using cue-phrases collected and
deemed salient by statistical merit (Nanba et al,
2000; Nanba et al, 2004). This has met in evalua-
tions with some success.
The Cite-Sum system (Kaplan and Tokunaga,
2008) also aims at knowledge reduction through
use of citations. It receives a paper title as a query
and attempts to generate a summary of the paper
by finding citing papers1 and extracting citations
in the running-text that refer to the paper. Before
outputting a summary, it also classifies extracted
citation text, and removes citations with redun-
dant content. Another similar study (Qazvinian
and Radev, 2008) aims at using the content of ci-
tations within citing papers to generate summaries
of fields of research.
It is clear that merit exists behind extraction
of citations in running text. This paper proposes
a new method for performing this task based on
coreference-chains. To evaluate our method we
created a corpus of citations comprised of citing
papers for 4 cited papers. We also analyze some
phenomena of citations that are present in our cor-
pus.
The paper organization is as follows. We first
define terminology, discuss the construction of our
corpus and the results found through its analysis,
and then move on to our proposed method us-
ing coreference-chains. We evaluate the proposed
method by using the constructed corpus, and then
conclude the paper.
1Papers are downloaded automatically from the web.
88
2 Terminology
So that we may dispense with convoluted explana-
tions for the rest of this paper, we introduce several
terms.
An anchor is the string of characters that marks
the occurrence of a citation in the running-text of a
paper, such as ?(Fakeman 2007)? or ?[57]?.2 The
sentence that this anchor resides within is then the
anchor sentence. The citation continues from be-
fore and after this anchor as long as the text con-
tinues to refer to the cited work; this block of text
may span more than a single sentence. We intro-
duce the citation-site, or c-site for short, to rep-
resent this block of text that discusses the cited
work. Since more than once sentence may discuss
the cited work, each of these sentences is called a
c-site sentence. For clarity will also call the an-
chor the c-site anchor henceforth. A citing paper
contains the c-site that refers to the cited paper.
Finally, the reference at the end of the paper pro-
vides details about a c-site anchor (and the c-site).
Figure 1 shows a sample c-site with the c-site
anchor wavy-underlined, and the c-site itself itali-
cized; the non-italicized text is unrelated to the c-
site. The reference for this c-site is also provided
below the dotted line. In all subsequent examples,
the c-site will be in italics and the current place of
emphasis wavy-underlined.
?. . . Our area of interest is plant growth. In past
research (
:::::::
Fakeman
::
et
:::
al.,
::::
2001), the relationship
between sunlight and plant growth was shown to
directly correlate. It was also shown to adhere
to simple equations for deducing this relation-
ship, the equation varying by plant. We propose
a method that . . . ?
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
J. Fakeman: Changing Plant Growth Factors
during Global Warming. In: Proceedings of
SCANLP 2001.
Figure 1: A sample c-site and its reference
3 Corpus Construction and Analysis
We created a corpus comprised of 38 papers citing
4 (cited) papers taken from Computational Lin-
guistics: Special Issue on the Web as Corpus, Vol-
ume 29, Number 3, 2003 as our data set and pre-
processed it to automatically mark c-site anchors
2In practice the anchor does not include brackets, though
the brackets do signal the start/end of the anchor. This is be-
cause multiple anchors may be present at once, e.g. (Fakeman
2007; Noman 2008).
to facilitate the annotation process. The citing pa-
pers were downloaded from CiteSeer-X;3 see Ta-
ble 1 for details.
We then proceeded to manually annotate the
corpus using SLAT (Noguchi et al, 2008), a
browser-based multi-purpose annotation tool. We
devised the following guidelines for annotation.
Since the tool allows for two types of annotation,
namely segments that demarcate a region of text,
and links, that allow an annotator to assign rela-
tionships between them, we created four segment
types and three link types. Segments were used
to mark c-site anchors, c-sites, background infor-
mation (explained presently), and references. We
used the term background information to refer to
any running-text that elaborates on a c-site but is
not strictly part of the c-site itself (refer to Fig-
ure 2 for an example). Even during annotation,
however, we encountered situations that felt am-
biguous, making this a rather contentious issue.
Our corpus had a limited number of background
information annotations, or we would likely have
experienced more issues. That being said, it is at
least important to recognize that such kinds of sup-
plementary content exist (that may not be part of
the c-site but is still beneficial to be included), and
needs to be considered more in the future.
We then linked each c-site to its anchor, each an-
chor to its reference, and any background informa-
tion to the c-site supplemented. We also decided
on annotating entire sentences, even if only part
of a sentence referred to the cited paper. Table 1
outlines our corpus.
Table 1: Corpus composition
Paper ID 1 2 3 4 Total
Citing papers 2 14 15 7 38
C-sites 3 17 18 12 50
C-site sentences 6 27 33 28 94
To our knowledge, this is the first corpus con-
structed in the context of paper summarization re-
lated to collections of citing papers.4
Analysis of the corpus provided some interest-
ing insights, though a larger corpus is required to
confirm the frequency and validity of such phe-
nomena. The more salient discoveries are item-
ized below. These phenomena may also co-occur.
3http://citeseerx.ist.psu.edu
4Though not specific to the task of summarization through
use of c-sites, citation corpora have been constructed in the
past, e.g. (Teufel et al, 2006).
89
Background Information Though not strictly
part of a c-site, background information may need
to be included for the citation to be comprehensi-
ble. Take Figure 2 for example (background infor-
mation is wavy-underlined) for the c-site anchor
?(Resnik & Smith 2003)?. The authors insert their
own research into the c-site (illustrated with wavy-
underlines); this information is important for un-
derstanding the following c-site sentence, but is
not strictly discussing the cited paper. Background
information is thus a form of ?meta-information?
about the c-site.
In well written papers, often the flow of content
is gradual, which can make distinguishing back-
ground information difficult.
?. . .Resnik and his colleagues (Resnik & Smith
2003) proposed a new approach, STRAND,
. . . The databases for parallel texts in several lan-
guages with download tools are available from
the STRAND webpage. Recently they also ap-
plied the same technique for collecting a set of
links to monolingual pages identified as Russian
by http://www.archive.org, and Internet archiv-
ing service.
::
We
:::::
have
:::::::::
evaluated
:::
the
:::::::
Russian
:::::::
database
::::::::
produced
::
by
:::
this
:::::::
method
:::
and
::::::::
identified
:
a
:::::::
number
::
of
::::::
serious
::::::::
problems
:::::
with
::
it. First, it
does not identify the time when the page was
downloaded and stored in the Internet archive
. . . ?
Figure 2: A non-contiguous c-site w/ background
information (from (Sharoff, 2006))
Contiguity C-sites are not necessarily contigu-
ous. We found in fact that authors tend to in-
sert opinions or comments related to their own
work with sentences/clauses in between actual c-
site sentences/clauses, that would be best omitted
from the c-site. In Figure 2 the wavy-underlined
text shows the author?s opinion portion. This cre-
ates problems for cue-phrase based techniques, as
though they detect the sentence following it, they
fail on the opinion sentence. Incorporation of a le-
niency for a gap in such techniques may be pos-
sible, but seems more problematic and likely to
misidentify c-site sentences altogether.
Related/Itemization Authors often list several
works (namely, insert several c-site anchors) in the
same sentence using connectives. The works may
likely be related, and though this may be useful
information for certain tasks, it is important to dif-
ferentiate which material is related to the c-site,
and which is the c-site itself.
In Figure 3 the second sentence discusses both
c-site anchors (and should be included in both
their c-sites); the first sentence, however, contains
two main clauses connected with a connective,
each clause a different c-site (one with the anchor
?[3]? and one with ?[4]?). Sub-clausal analysis is
necessary for resolving issues such as these. For
our current task, however, we annotated only sen-
tences, and so in this example the second c-site
anchor is included in the first.
?. . . STRAND system [4] searches the web for
parallel text
:::
and
:::
[3]
:::::::
extracts
::::::::::
translations
::::
pairs
:::::
among
::::::
anchor
::::
texts
:::::::
pointing
:::::::
together
::
to
:::
the
::::
same
:::::::
webpage. However they all suffered from the lack
of such bilingual resources available on the web
. . . ?
Figure 3: Itemized c-sites partially overlapping
(from (Zhang et al, 2005))
Nesting C-sites may be nested. In Figure 4
the nested citation (?[Lafferty and Zhai 2001,
Lavrenko and Croft 2001]?) should be included in
the parent one (?[Kraaij et al 2002]?). The wavy-
underlined portion shows the sentence needed for
full comprehension of the c-site.
?. . .
::
In
:::::
recent
:::::
years,
:::
the
:::
use
::
of
::::::::
language
::::::
models
::
in
::
IR
:::
has
::::
been
::
a
::::
great
::::::
success
::::::::
[Lafferty
:::
and
::::
Zhai
::::
2001,
::::::::
Lavrenko
::::
and
:::::
Croft
::::::
2001]. It is possible
to extend the approach to CLIR by integrating a
translation model. This is the approach proposed
in [Kraaij et al 2002] . . . ?
Figure 4: Separate c-site anchors does not mean
separate c-sites (from (Nie, 2002))
Aliases Figure 5 demonstrates another issue:
aliasing. The author redefines how they cite the
paper, in this case using the acronym ?K&L?.
?. . . To address the data-sparsity issue, we em-
ployed the technique used in Keller and Lapata
(2003, K&L) to get a more robust approxima-
tion of predicate-argument counts.
::::
K&L use this
technique to obtain frequencies for predicate-
argument bigrams that were unseen in a given
corpus, showing that the massive size of the web
outweighs the noisy and unbalanced nature of
searches performed on it to produce statistics
that correlate well with corpus data . . . ?
Figure 5: C-Site with Aliasing for anchor ?Keller
and Lapata (2003, K&L)? (from (Kehler, 2004))
4 Coreference Chain-based Extraction
Some of the issues found in our corpus, namely
identification of background information, non-
contiguous c-sites, and aliases, show promise of
90
Table 2: Evaluation results for coreference resolution against the MUC-7 formal corpus.
MUC-7 Task Sentence Eval.
System Setting R P F R P F
All Features 35.71 74.71 48.33 36.27 80.49 50.00
w/o SOON STR MATCH 48.35 83.81 61.32 48.35 88.00 62.41
w/o COSINE SIMILARITY 46.70 82.52 59.65 46.70 86.73 60.71
resolution with coreference-chains. This is be-
cause coreference-chains match noun phrases that
appear with other noun phrases to which they re-
fer, a characteristic present in these three cate-
gories. On the other hand, cue-phrases do not
detect any c-site sentence that does not use key-
words (e.g. ?In addition?). In the following sec-
tion we discuss our implementation of a corefer-
ence chain-based extraction technique, and how
we then applied it to the c-site extraction task. An
analysis of the results then follows.
4.1 Training the Coreference Resolver
To create and train our coreference resolver, we
used a combination of techniques as outlined orig-
inally by (Soon et al, 2001) and subsequently
extended by (Ng and Cardie, 2002). Mim-
icking their approaches, we used the corpora
provided for the MUC-7 coreference resolution
task (LDC2001T02, 2001), which includes sets of
newspaper articles, annotated with coreference re-
lations, for both training and testing. They also
outlined a list of features to extract for training
the resolver to recognize the coreference relations.
Specifically, (Soon et al, 2001) established a list
of 12 features that compare a given anaphor with
a candidate antecedent, e.g. gender agreement,
number agreement, both being pronouns, both part
of the same semantic class (i.e. WordNet synset
hyponyms/hypernyms), etc.
For training the resolver, a corpus annotated
with anaphors and their antecedents is processed,
and pairs of anaphor and candidate antecedents are
created so as to have only one positive instance
per anaphor (the annotated antecedent). Negative
examples are created by taking all occurrences of
noun phrases that occur between the anaphor and
its antecedent in the text. The antecedent in these
steps is also always considered to be to the left of,
or preceding, the anaphor; cataphors are not ad-
dressed in this technique.
We implemented, at least minimally, all 12 of
these features, with a few additions of what (Ng
and Cardie, 2002) hand selected as being most
salient for increased performance. We also ex-
tended this list by adding a cosine-similarity met-
ric between two noun phrases; it uses bag-of-
words to create a vector for each noun phrase
(where each word is a term in the vector) to com-
pute their similarity. The intuition behind this is
that noun phrases with more similar surface forms
should be more likely to corefer.
We further optimized string recognition and
plurality detection for handling citation-strings.
See Table 3 for the full list of our features. While
both (Soon et al, 2001) and (Ng and Cardie, 2002)
induced decision trees (C5 and C4.5, respectively)
we opted for using an SVM-based approach in-
stead (Vapnik, 1998; Joachims, 1999). SVMs are
known for being reliable and having good perfor-
mance.
4.2 Evaluating the Coreference Resolver
We ran our trained SVM classifier against the
MUC-7 formal evaluation corpus; the results are
shown in Table 2.
The results using all features listed in Table 3
are inferior to those set forth by (Soon et al,
2001; Ng and Cardie, 2002); likely this is due
to poorer selection of features. Upon analysis, it
seems that half of the misidentified antecedents
were still chosen within the correct sentence and
more than 10% identified the proper antecedent,
but selected the entire noun phrase (when that
antecedent was marked as, for example, only its
head); the majority of these cases involved the
antecedent being only one sentence away from
the anaphor. Since the former seemed suspect of
a partial string matching feature, we decided to
re-run the tests first excluding our implementa-
tion of the SOON STR MATCH feature, and then
our COSINE SIMILARITY feature. The results
for this are shown in Table 2. It can be seen
that using either of the two string comparison fea-
tures works substantially better than with both of
them in tandem, with the COSINE SIMILARITY
feature showing signs of overall better perfor-
mance which is competitive to (Soon et al,
91
Table 3: Features used for coreference resolution.
Feature Possible Values Brief Description (where necessary)
ANAPHOR IS PRONOUN T/F
ANAPHOR IS INDEFINITE T/F
ANAPHOR IS DEMONSTRATIVE T/F
ANTECEDENT IS PRONOUN T/F
ANTECEDENT IS EMBEDDED T/F Boolean indicating if the candidate antecedent is within another
NP.
SOON STR MATCH T/F As per (Soon et al, 2001). Articles and demonstrative pronouns
removed before comparing NPs. If any part of the NP matches
between candidate and anaphor set to true (T); false otherwise.
ALIAS MATCH T/F Creates abbreviations for organizations and proper names in an
attempt to find an alias.
BOTH PROPER NAMES T/F
BOTH PRONOUNS T/F/?
NUMBER AGREEMENT T/F/? Basic morphological rules applied to the words to see if they are
plural.
COSINE SIMILARITY NUM A cosine similarity score between zero and one is applied to the
head words of each NP.
GENDER AGREEMENT T/F/? If the semantic class is Male or Female, use that gender, other-
wise if a salutation is present, or lastly set to Unknown.
SEMANTIC CLASS AGREEMENT T/F/? Followed (Soon et al, 2001) specifications for using basic
WordNet synsets, specifically: Female and Male belonging to
Person, Organization, Location, Date, Time, Money, Percent
belonging to Object. Any other semantic classes mapped to
Unknown.
2001; Ng and Cardie, 2002). We exclude the
SOON STR MATCH feature in the following ex-
periments.
However, the MUC-7 task measures the ability
to identity the proper antecedent from a list of can-
didates; the c-site extraction task is less ambitious
in that it must only identify if a sentence contains
the antecedent, not which noun phrase it is. When
we evaluate our resolver using these loosened con-
ditions it is expected that it will perform better.
To accomplish this we reevaluate the results
from the resolver in a sentence-wise manner; we
group the test instances by anaphor, and then by
sentence. If any noun phrase within the sentence
is marked as positive when there is in fact a pos-
itive noun phrase in the sentence, the sentence is
marked as correct, and incorrect otherwise. The
results in Table 2 for this simplified task show
an increase in recall, and subsequently F-measure.
The numbers for the loosened constraints eval-
uation are counted by sentence; the original is
counted by noun phrase only.
Our system also generates many fewer training
instances than the previous research, which we at-
tribute to a more stringent noun phrase extraction
procedure, but have not investigated thoroughly
yet.
4.3 Application to the c-site extraction task
As outlined above, we used the resolver with the
loosened constraints, namely evaluating the sen-
tence a potential antecedent is in as likely or not,
and not which noun phrase within the sentence is
the actual antecedent. Using this principle as a
base, we devised an algorithm for scanning sen-
tences around a c-site anchor sentence to deter-
mine their likelihood of being part of the c-site.
The algorithm, shown in simplified form in Fig-
ure 6, is described below.
Starting at the beginning of a c-site anchor
sentence AS, scan left-to-right; for every noun
phrase encountered within AS, begin a right-to-
left sentence-by-sentence search; prepend any sen-
tence S containing an antecedent above a certain
likelihood THRESHOLD, until DISTANCE sen-
tences have been scanned and no suitable candi-
date sentences have been found. We set the like-
lihood score to 1.0, tested ad-hoc for best results,
and the distance-threshold to 5 sentences, having
noted in our corpus that no citation is discontinu-
ous by more than 4.
In a similar fashion, the algorithm then pro-
ceeds to scan text following AS; for every noun
phrase NP encountered (moving left-to-right), be-
gin a right-to-left search for a suitable antecedent.
If a sentence is not evaluated above THRESHOLD,
92
Table 4: Evaluation results for c-site extraction w/o background information
Sentence (Micro-average) C-site (Macro-average)
Method R P F R P F
Baseline 1 (anchor sentence) 53.2 100 69.4 74.6 100 85.5
Baseline 2 (random) 75.5 58.2 65.7 87.4 71.2 78.5
Cue-phrases (CP) 64.9 64.9 64.9 84.0 80.9 82.4
Coref-chains (CC)) 64.9 74.4 69.3 81.0 87.2 84.0
CP/CC Union 74.5 58.8 65.7 88.4 75.0 81.1
CP/CC Intersection 55.3 91.2 69.0 76.6 95.7 85.1
set CSITE to AS
pre:
foreach NP in AS
foreach sentence S preceding AS
if DISTANCE > MAX-DIST goto post
if likelihood > THRESHOLD then
set CSITE to S + CSITE
reset DISTANCE
end
end
end
post:
foreach sentence S after AS
foreach NP in S
foreach sentence S2 until S
if DISTANCE > MAX-DIST stop
if S2 has link then
if likelihood > THRESHOLD then
set S2 has link
end
end
end
end
end
Figure 6: Simplified c-site extraction algorithm
using coreference-chains
it will be ignored when the algorithm backtracks
to look for candidate noun phrases for a subse-
quent sentence, thus preserving the coreference-
chain and preventing additional spurious chains.
If more than DISTANCE sentences are scanned
without finding a c-site sentence, the process is
aborted and the collection of sentences returned.
4.4 Experiment Setup
To evaluate our coreference-chain extraction
method we compare it with a cue-phrases tech-
nique (Nanba et al, 2004) and two baselines.
Baseline 1 extracts only the c-site anchor sen-
tence as the c-site; baseline 2 includes sentences
before/after the c-site anchor sentence as part of
the c-site with a 50/50 probability ? it tosses
a coin for each consecutive sentence to decide
its inclusion. We also created two hybrid meth-
ods that combine the results of the cue-phrases
and coreference-chain techniques, one the union
of their results (includes the extracted sentences
of both methods), and the other the intersection
(includes sentences only for which both methods
agree), to measure their mutual compatibility.
The annotated corpus provided the locations of
c-site anchors for the cited paper within the citing
paper?s running-text. We then compared the ex-
tracted c-sites of each method to the c-sites of the
annotated corpus.
4.5 Evaluation
The results of our experiments are presented in Ta-
ble 4. We evaluated each method as follows. Re-
call and precision were measured for a c-site based
on the number of extracted sentences; if an ex-
tracted sentence was annotated as part of the c-site,
it counted as correct, and if an extracted sentence
was not part of a c-site, incorrect; sentences an-
notated as being part of the c-site not extracted by
the method counted as part of the total sentences
for that c-site. As an example, if an annotated c-
site has 3 sentences (including the c-site anchor
sentence), and the evaluated method extracted 2 of
these and 1 incorrect sentence, then the recall for
this c-site using this method would be 2/3, and the
precision 2/(2 + 1).
Since the evaluation is inherently sentence-
based, we provide two averages in Table 4. The
micro-average is for sentences across all c-sites;
in other words, we tallied the correct and incorrect
sentence count for the whole corpus and then di-
vided by the total number of sentences (94). This
average provides a clearer picture on the efficacy
of each method than does the macro-average. The
macro-average was computed per c-site (as ex-
plained above) and then averaged over the total
number of c-sites in the corpus (50).
With the exception of a 3% lead in macro-
average recall, coreference-chains outperform
cue-phrases in every way. We can see a substan-
93
tial difference in micro-average precision (74.4
vs. 64.9), which results in nearly a 5% higher
F-measure. The macro-average precision is also
higher by more than 6%. It matches more and
misses far less. The loss in the macro-average
recall can be attributed to the coreference-chain
method missing one of two sentences for several
c-sites, which would lower its overall recall score;
keep in mind that since in the macro-average all c-
sites are treated equally, even large c-sites in which
the coreference-chain method performs well, such
an advantage will be reduced with averaging and
is therefore misleading.
Baseline 2 performed as expected, i.e. higher
than baseline 1 for recall. Looking only at F-
measures for evaluating performance in this case
is misleading. This is particularly the case because
precision is more important than recall ? we want
accuracy. Coreference-chains achieved a precision
of over 87.2 compared to the 71.2 of baseline 2.
The combined methods also showed promise.
In particular, the intersection method had very
high precision (91.2 and 95.7), and marginally
managed to extract more sentences than base-
line 1. The union method has more conservative
scores.
We also understood from our corpus that only
about half of c-sites were represented by c-site an-
chor sentences. The largest c-site in the corpus
was 6 sentences, and the average 1.8. This means
using the c-site anchor sentence alone excludes on
average about half of the valuable data.
These results are promising, but a larger corpus
is necessary to validate the results presented here.
5 Conclusions and Future Work
The results demonstrate that a coreference-chain-
based approach may be useful to the c-site ex-
traction task. We can also see that there is still
much work to be done. The scores for the hy-
brid methods also indicate potential for a method
that more tightly couples these two tasks, such
as Rhetorical Structure Theory (RST) (Thompson
and Mann, 1987; Marcu, 2000). Though it has
demonstrated superior performance, coreference
resolution is not a light-weight task; this makes
real-time application more difficult than with cue-
phrase-based approaches.
Our plans for future work include the construc-
tion of a larger corpus of c-sites, investigation of
other features for improving our coreference re-
solver, and applying RST to c-site extraction.
Acknowledgments
The authors would like to express appreciation to
Microsoft for their contribution to this research by
selecting it as a recipient of the 2008 WEBSCALE
Grant (Web-Scale NLP 2008, 2008).
References
Shannon Bradshaw. 2003. Reference directed index-
ing: Redeeming relevance for subject search in cita-
tion indexes. In Proceedings of the 7th ECDL, pages
499?510.
Eugene Garfield, Irving H. Sher, and Richard J. Torpie.
1964. The use of citation data in writing the his-
tory of science. Institute for Scientific Information,
Philadelphia, Pennsylvania.
Thorsten Joachims. 1999. Making large-scale sup-
port vector machine learning practical. In Bernhard
Scho?lkopf, Christopher J. C. Burges, and Alexan-
der J. Smola, editors, Advances in kernel methods:
support vector learning, pages 169?184. MIT Press,
Cambridge, MA, USA.
Dain Kaplan and Takenobu Tokunaga. 2008. Sighting
citation sites: A collective-intelligence approach for
automatic summarization of research papers using
c-sites. In ASWC 2008 Workshops Proceedings.
Andrew Kehler. 2004. The (non)utility of predicate-
argument frequencies for pronoun interpretation. In
In: Proceedings of 2004 North American chapter of
the Association for Computational Linguistics an-
nual meeting, pages 289?296.
M. M. Kessler. 1963. Bibliographic coupling be-
tween scientific papers. American Documentation,
14(1):10?25.
LDC2001T02. 2001. Message understanding confer-
ence (MUC) 7.
Daniel Marcu. 2000. The rhetorical parsing of unre-
stricted texts: A surface-based approach. Computa-
tional Linguistics, 26(3):395?448.
Hidetsugu Nanba, Noriko Kando, and Manabu Oku-
mura. 2000. Classification of research papers using
citation links and citation types: Towards automatic
review article generation. In Proceedings of 11th
SIG/CR Workshop, pages 117?134.
Hidetsugu Nanba, Takeshi Abekawa, Manabu Oku-
mura, and Suguru Saito. 2004. Bilingual presri inte-
gration of multiple research paper databases. In Pro-
ceedings of RIAO 2004, pages 195?211, Avignon,
France.
94
Vincent Ng and Claire Cardie. 2002. Improving ma-
chine learning approaches to coreference resolution.
In Proceedings of the 40th Annual Meeting on Asso-
ciation for Computational Linguistics, pages 104?
111.
J. Nie. 2002. Towards a unified approach to clir and
multilingual ir. In In: Workshop on Cross Language
Information Retrieval: A Research Roadmap in the
25th Annual International ACM SIGIR Conference
on Research and Development in Information Re-
trieval, pages 8?14.
Masaki Noguchi, Kenta Miyoshi, Takenobu Tokunaga,
Ryu Iida, Mamoru Komachi, and Kentaro Inui.
2008. Multiple purpose annotation using SLAT ?
Segment and link-based annotation tool ?. In Pro-
ceedings of 2nd Linguistic Annotation Workshop,
pages 61?64, May.
John O?Connor. 1982. Citing statements: Computer
recognition and use to improve retrieval. Informa-
tion Processing & Management., 18(3):125?131.
Vahed Qazvinian and Dragomir R. Radev. 2008. Sci-
entific paper summarization using citation summary
networks.
Anna Ritchie, Simone Teufel, and Stephen Robertson.
2006. How to find better index terms through cita-
tions. In Proceedings of the Workshop on How Can
Computational Linguistics Improve Information Re-
trieval?, pages 25?32, Sydney, Australia, July. As-
sociation for Computational Linguistics.
Anna Ritchie, Stephen Robertson, and Simone Teufel.
2008. Comparing citation contexts for informa-
tion retrieval. In CIKM ?08: Proceedings of the
17th ACM conference on Information and knowl-
edge management, pages 213?222, New York, NY,
USA. ACM.
Serge Sharoff. 2006. Creating general-purpose cor-
pora using automated search engine queries. In
WaCky! Working papers on the Web as Corpus.
Gedit.
H. Small. 1973. Co-citation in the scientific literature:
A newmeasure of the relationship between two doc-
uments. JASIS, 24:265?269.
Wee Meng Soon, Daniel Chung, Daniel Chung Yong
Lim, Yong Lim, and Hwee Tou Ng. 2001. A
machine learning approach to coreference resolu-
tion of noun phrases. Computational Linguistics,
27(4):521?544.
Simone Teufel, Advaith Siddharthan, and Dan Tidhar.
2006. Automatic classification of citation function.
In In Proceedings of EMNLP-06.
Sandra A. Thompson and William C. Mann. 1987.
Rhetorical structure theory: A framework for the
analysis of texts. Pragmatics, 1(1):79?105.
Vladimir N. Vapnik. 1998. Statistical Learning The-
ory. Adaptive and Learning Systems for Signal Pro-
cessing Communications, and control. JohnWiley &
Sons.
Web-Scale NLP 2008. 2008. http:
//research.microsoft.com/ur/asia/
research/NLP.aspx.
M. Weinstock. 1971. Citation indexes. Encyclopedia
of Library and Information Science, 5:16?41.
Ying Zhang, Fei Huang, and Stephan Vogel. 2005.
Mining translations of oov terms from the web
through. In International Conference on Natural
Language Processing and Knowledge Engineering
(NLP-KE ?03), pages 669?670.
95
