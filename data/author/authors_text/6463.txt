Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 936?943,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Much ado about nothing:                                         
A social network model of Russian paradigmatic gaps 
Robert Daland Andrea D. Sims Janet Pierrehumbert 
Department of Linguistics 
Northwestern University 
2016 Sheridan Road 
Evanston, IL 60208 USA 
r-daland, andrea-sims, jbp@northwestern.edu 
 
 
 
 
 
Abstract 
A number of Russian verbs lack 1sg non-
past forms. These paradigmatic gaps are 
puzzling because they seemingly contradict 
the highly productive nature of inflectional 
systems. We model the persistence and 
spread of Russian gaps via a multi-agent 
model with Bayesian learning. We ran 
three simulations: no grammar learning, 
learning with arbitrary analogical pressure, 
and morphophonologically conditioned 
learning. We compare the results to the 
attested historical development of the gaps. 
Contradicting previous accounts, we 
propose that the persistence of gaps can be 
explained in the absence of synchronic 
competition between forms. 
1 Introduction 
Paradigmatic gaps present an interesting challenge 
for theories of inflectional structure and language 
learning. Wug tests, analogical change and 
children?s overextensions of regular patterns 
demonstrate that inflectional morphology is highly 
productive. Yet lemmas sometimes have ?missing? 
inflected forms. For example, in Russian the 
majority of verbs have first person singular (1sg) 
non-past forms (e.g., posadit? ?to plant?, posa?u ?I 
will plant?), but no 1sg form for a number of 
similar verbs (e.g., pobedit? ?to win?, *pobe?u ?I 
will win?). The challenge lies in explaining this 
apparent contradiction. Given the highly produc-
tive nature of inflection, why do paradigmatic gaps 
arise? Why do they persist?     
One approach explains paradigmatic gaps as a 
problem in generating an acceptable form.  Under 
this hypothesis, gaps result from irreconcilable 
conflict between two or more inflectional patterns.  
For example, Albright (2003) presents an analysis 
of Spanish verbal gaps based on the Minimal 
Generalization Learner (Albright and Hayes 2002). 
In his account, competition between mid-vowel 
diphthongization (e.g., s[e]ntir ?to feel?, s[je]nto ?I 
feel?) and non-diphthongization (e.g., p[e]dir ?to 
ask?, p[i]do ?I ask?) leads to paradigmatic gaps in 
lexemes for which the applicability of diphthon-
gization has low reliability (e.g., abolir ?to abolish, 
*ab[we]lo, *ab[o]lo ?I abolish?).   
However, this approach both overpredicts and 
underpredicts the existence of gaps cross-
linguistically.  First, it predicts that gaps should 
occur whenever the analogical forces determining 
word forms are contradictory and evenly weighted. 
However, variation between two inflectional 
patterns seems to more commonly result from such 
a scenario.  Second, the model predicts that if the 
form-based conflict disappears, the gaps should 
also disappear. However, in Russian and probably 
in other languages, gaps persist even after the loss 
of competing inflectional patterns or other 
synchronic form-based motivation (Sims 2006).   
By contrast, our approach operates at the level 
of inflectional property sets (IPS), or more 
properly, at the level of inflectional paradigms.  
We propose that once gaps are established in a 
language for whatever reason, they persist because 
learners infer the relative non-use of a given 
 1
936
combination of stem and IPS.1  Put differently, we 
hypothesize that speakers possess at least two 
kinds of knowledge about inflectional structure: (1) 
knowledge of how to generate the appropriate form 
for a given lemma and IPS, and (2) knowledge of 
the probability with which that combination of 
lemma and property set is expressed, regardless of 
the form. Our approach differs from previous 
accounts in that persistence of gaps is attributed to 
the latter kind of knowledge, and does not depend 
on synchronic morphological competition. 
We present a case study of the Russian verbal 
gaps, which are notable for their persistence.  They 
arose between the mid 19th and early 20th century 
(Baerman 2007), and are still strongly attested in 
the modern language, but have no apparent 
synchronic morphological cause.   
We model the persistence and spread of the 
Russian verbal gaps with a multi-agent model with 
Bayesian learning.  Our model has two kinds of 
agents, adults and children. A model cycle consists 
of two phases: a production-perception phase, and 
a learning-maturation phase. In the production-
perception phase, adults produce a batch of 
linguistic data (verb forms), and children listen to 
the productions from the adults they know. In the 
learning-maturation phase, children build a 
grammar based on the input they have received, 
then mature into adults.  The existing adults die off, 
and the next generation of children is born. 
Our model exhibits similar behavior to what is 
known about the development of Russian gaps. 
2 The historical and distributional facts 
of Russian verbal gaps 
2.1 Traditional descriptions 
Grammars and dictionaries of Russian frequently 
cite paradigmatic gaps in the 1sg non-past.  Nine 
major dictionaries and grammars, including 
?vedova (1982) and Zaliznjak (1977), yielded a 
combined list of 96 gaps representing 68 distinct 
stems.  These verbal gaps fall almost entirely into 
the second conjugation class, and they 
overwhelmingly affect the subgroup of dental 
stems.  Commonly cited gaps include: *gal?u ?I 
make a hubbub?; *o?u?us? ?I come to be (REFL)?; 
1SG *o??u??u ?I feel?; *pobe?u ?I will win?; and 
*ube?u ?I will convince?.2 
                                                 
                                                
1 Paradigmatic gaps also probably serve a sociolinguistic 
purpose, for example as markers of education, but socio-
linguistic issues are beyond the scope of this paper. 
There is no satisfactory synchronic reason for 
the existence of the gaps.  The grouping of gaps 
among 2nd conjugation dental stems is seemingly 
non-arbitrary because these are exactly the forms 
that would be subject to a palatalizing morphopho-
nological alternation (tj ? tS or Sj, dj ? Z, sj ? S, zj 
? Z). Yet the Russian gaps do not meet the criteria 
for morphophonological competition as intended 
by Albright?s (2003) model, because the 
alternations apply automatically in Contemporary 
Standard Russian. Analogical forces should thus 
heavily favor a single form, for example, pobe?u. 
Traditional explanations for the gaps, such as 
homophony avoidance (?vedova 1982) are also 
unsatisfactory since they can, at best, explain only 
a small percentage of the gaps. 
Thus, the data suggest that gaps persist in 
Russian primarily because they are not uttered, and 
this non-use is learned by succeeding generations 
of Russian speakers.3  The clustering of the gaps 
among 2nd conjugation dental stems most likely is 
partially a remnant of their original causes, and 
partially represents analogic extension of gaps 
along morphophonological lines (see 2.3 below). 
2.2 Empirical evidence for and operational 
definition of gaps 
When dealing with descriptions in semi- 
prescriptive sources such as dictionaries, we must 
always ask whether they accurately represent 
language use. In other words, is there empirical 
evidence that speakers fail to use these words? 
We sought evidence of gaps from the Russian 
National Corpus (RNC). 4  The RNC is a balanced 
textual corpus with 77.6 million words consisting 
primarily of the contemporary Russian literary 
language.  The content is prose, plays, memoirs 
and biographies, literary criticism, newspaper and 
magazine articles, school texts, religious and 
 
2  We use here the standard Cyrillic transliteration used by 
linguists.  It should not be considered an accurate 
phonological representation.  Elsewhere, when phonological 
issues are relevant, we use IPA. 
3 See Manning (2003) and Zuraw (2003) on learning from 
implicit negative evidence. 
4 Documentation: http://ruscorpora.ru/corpora-structure.html 
Mirror site used for searching: 
http://corpus.leeds.ac.uk/ruscorpora.html.    
 
 2
937
philosophical materials, technical and scientific 
texts, judicial and governmental publications, etc. 
We gathered token frequencies for the six non-
past forms of 3,265 randomly selected second 
conjugation verb lemmas.  This produced 11,729 
inflected forms with non-zero frequency. 5   As 
described in Section 3 below, these 11,729 form 
frequencies became our model?s seed data. 
To test the claim that Russian has verbal gaps, 
we examined a subsample of 557 2nd conjugation 
lemmas meeting the following criteria: (a) total 
non-past frequency greater than 36 raw tokens, and 
(b) 3sg and 3pl constituting less than 85% of total 
non-past frequency. 6   These constraints were 
designed to select verbs for which all six person-
number combinations should be robustly attested, 
and to minimize sampling errors by removing 
lemmas with low attestation. 
We calculated the probability of the 1sg 
inflection by dividing the number of 1sg forms by 
the total number of non-past forms. The subset was 
bimodally distributed with one peak near 0%, a 
trough at around 2%, and the other peak at 13.3%.  
The first peak represents lemmas in which the 1sg 
form is basically not used ? gaps. Accordingly, we 
define gaps as second conjugation verbs which 
meet criteria (a) and (b) above, and for which the 
1sg non-past form constitutes less than 2% of total 
non-past frequency for that lemma (N=56). 
In accordance with the grammatical descrip-
tions, our criteria are disproportionately likely to 
identify dental stems as gaps. Still, only 43 of 412 
dental stems (10.4%) have gaps, compared with 13 
gaps among 397 examples of other stems (3.3%).   
Second, not all dental stems are equally affected.  
There seems to be a weak prototypicality effect 
centered around stems ending in /dj/, from which 
/tj/ and /zj/ each differ by one phonological feature.  
There may also be some weak semantic factors that 
we do not consider here. 
 
/dj/ /tj/ /zj/ /sj/ /stj/ 
13.3% 
(19/143) 
12.4% 
(14/118) 
11.9% 
(5/42) 
4.8% 
(3/62) 
4.3% 
(2/47) 
Table 1. Distribution of Russian verbal gaps 
among dental stems 
                                                 
5  We excluded 29 high-frequency lemmas for which the 
corpus did not provide accurate counts. 
6 Russian has a number of verbs for which only the 3sg and 
3pl are regularly used. 
2.3 Some relevant historical facts 
A significant difference between the morpho-
logical competition approach and our statistical 
learning approach is that the former attempts to 
provide a single account for both the rise and the 
perpetuation of paradigmatic gaps.  By contrast, 
our statistical learning model does not require that 
the morphological system provide synchronic 
motivation. The following question thus arises: 
Were the Russian gaps originally caused by forces 
which are no longer in play in the language? 
Baerman and Corbett (2006) find evidence that 
the gaps began with a single root, -bed- (e.g., 
pobedit? ?to win?), and subsequently spread 
analogically within dental stems.  Baerman (2007) 
expands on the historical evidence, finding that a 
conspiracy of several factors provided the initial 
push towards defective 1sg forms. Most important 
among these, many of the verbs with 1sg gaps in 
modern Russian are historically associated with 
aberrant morphophonological alternations. He 
argues that when these unusual alternations were 
eliminated in the language, some of the words 
failed to be integrated into the new morphological 
patterns, which resulted in lexically specified gaps. 
Important to the point here is that the 
elimination of marginal alternations removed an 
earlier synchronic motivation for the gaps.  Yet 
gaps have persisted and new gaps have arisen (e.g., 
pylesosit? ?to vacuum?). This persistence is the 
behavior that we seek to model. 
3 Formal aspects of the model 
We take up two questions: How much machinery 
do we need for gaps to persist? How much 
machinery do we need for gaps to spread to phono-
logically similar words?  We model three scenarios.  
In the first scenario there is no grammar learning.   
Adult agents produce forms by random sampling 
from the forms that heard as children, and child 
agents hear those forms. In the subsequent 
generation children become adults. In this scenario 
there is thus no analogical pressure. Any perse-
verance of gaps results from word-specific learning. 
The second scenario is similar to the first, except 
that the learning process includes analogical 
pressure from a random set of words.  Specifically, 
for a target concept, the estimated distribution of 
its IPS is influenced by the distribution of known 
words. This enables the learner to express a known 
 3
938
concept with a novel IPS. For example, imagine 
that a learner hears the present tense verb form 
googles, but not the past tense googled. By analogy 
with other verbs, learners can expect the past tense 
to occur with a certain frequency, even if they have 
not encountered it.   
The third scenario builds upon the second.  In 
this version, the analogical pressure is not 
completely random.  Instead, it is weighted by 
morphophonological similarity ? similar word 
forms contribute more to the analogical force on a 
target concept than do dissimilar forms.  This 
addition to the model is motivated by the pervasive 
importance of stem shape in the Russian 
morphological system generally, and potentially 
provides an account for the phonological 
prototypicality effect among Russian gaps. 
The three scenarios thus represent increasing 
machinery for the model, and we use them to 
explore the conditions necessary for gaps to persist 
and spread.  We created a multi-agent network 
model with Bayesian learning component.  In the 
following sections we describe the model?s 
structure, and outline the criteria by which we 
evaluate its output under the various conditions. 
3.1 Social structure 
Our model includes two generations of agents.  
Adult agents output linguistic forms, which 
provide linguistic input for child agents.  
Output/input occurs in batches.7  After each batch 
all adults die, all children mature into adults, and a 
new generation of children is born. Each run of the 
model included 10 generations of agents.   
We model the social structure with a random 
network.  Each adult produces 100,000 verb forms, 
and each child is exposed to every production from 
every adult to whom they are connected. Each 
generation consisted of 50 adult agents, and child 
agents are connected to adults with some 
probability p.  On average, each child agent is 
connected to 10 adult agents, meaning that each 
child hears, on average, 1,000,000 tokens. 
3.2 Linguistic events 
Russian gaps are localized to second conjugation 
non-past verb forms, so productions of these forms 
are the focus of interest.  Formally, we define a 
linguistic event as a concept-inflection-form (C,I,F) 
triple. The concept serves to connect the different 
forms and inflections of the same lemma. 
                                                 
7  See Niyogi (2006) for why batch learning is a 
reasonable approximation in this context. 
3.3 Definition of grammar  
A grammar is defined as a probability distribution 
over linguistic events. This gives rise to natural 
formulations of learning and production as 
statistical processes: learning is estimating a 
probability distribution from existing data, and 
production is sampling from a probability 
distribution.  The grammar can be factored into 
modular components: 
 
p(C, I, F) = p(C) ? p(I | C) ? p(F | C, I) 
 
In this paper we focus on the probability 
distribution of concept-inflection pairs.  In other 
words, we focus on the relative frequency of 
inflectional property sets (IPS) on a lemma-by-
lemma basis, represented by the middle term above. 
Accordingly, we made the simplest possible 
assumptions for the first and last terms. To 
calculate the probability of a concept, children use 
the sample frequency (e.g., if they hear 10 tokens 
of the concept ?eat?, and 1,000 tokens total, then 
p(?eat?) = 10/1000 = .01). Learning of forms is 
perfect. That is, learners always produce the 
correct form for every concept-inflection pair. 
3.4 Learning model 
Although production in the real world is governed 
by semantics, we treat it here as a statistical 
process, much like rolling a six-sided die which 
may or may not be fair. When producing a Russian 
non-past verb, there are six possible combinations 
of inflectional properties (3 persons * 2 numbers).  
In our model, word learning involves estimating 
the probability distribution over the frequencies of 
the six forms on a lemma-by-lemma basis. A 
hypothetical example that introduces our variables: 
 
 
jest? 1sg 2sg 3sg 1pl 2pl 3pl SUM 
D 15 5 45 5 5 25 100 
d 0.15 0.05 0.45 0.05 0.05 0.25 1 
Table 2. Hypothetical probability distribution 
 
The first row indicates the concept and the 
inflections. The second row (D) indicates the 
 4
939
hypothetical number of tokens of jest? ?eat? that the 
learner heard for each inflection (bolding indicates 
a six-vector).  We use |D| to indicate the sum of 
this row (=100), which is the concept frequency.  
The third row (d) indicates the sample probability 
of that inflection, which is simply the second row 
divided by |D|.   
The learner?s goal is to estimate the distribution 
that generated this data. We assume the 
multinomial distribution, whose parameter is 
simply the vector of probabilities of each IPS. For 
each concept, the learner?s task is to estimate the 
probability of each IPS, represented by h in the 
equations below.  We begin with Bayes? rule: 
 
p(h | D) ? p(h) ? multinom(D | h) 
 
The prior distribution constitutes the analogical 
pressure on the lemma. It is generated from the 
?expected? behavior, h0, which is an average of the 
known behavior from a random sample of other 
lemmas. The parameter ? determines the number 
of lemmas that are sampled for this purpose ? it 
represents how many existing words affect a new 
word. To model the effect of morphophonological 
similarity (mpSim), in one variant of the model we 
weight this average by the similarity of the stem-
final consonant.8  For example, this has the effect 
that existing dental stems have more of an effect 
on dental stems.  In this case, we define 
 
h0 = ?c? in sample d c? ? mpSim(c, c?)/? mpSim(c, c?) 
 
We use a featural definition of similarity, so that if 
the stem-final consonants differ by 0, 1, 2, or 3 or 
more phonological features, the resulting similarity 
is 1, 2/3, 1/3, or 0, respectively. 
The prior distribution should assign higher 
probability to hypotheses that are ?closer? to this 
expected behavior h0. Since the hypothesis is itself 
a probability distribution, the natural measure to 
use is the KL divergence. We used an 
exponentially distributed prior with parameter ?: 
 
p(h) ? exp(-?? h0 || h) 
 
                                                 
8  In Russian, the stem-final consonant is important for 
morphological behavior generally. Any successful Russian 
learner would have to extract the generalization, completely 
apart from the issues posed by gaps. 
As will be shown shortly, ? has a natural 
interpretation as the relative strength of the prior 
with respect to the observed data. 
The learner calculates their final grammar by 
taking the mode of the posterior distribution 
(MAP). It can be shown that this value is given by 
 
arg max p(h | D) = (?? h0 + |D|? d)/(?+|D|) 
 
Thus, the output of this learning rule is a 
probability vector h that represents the estimated 
probability of each of the six possible IPS?s for 
that concept. As can be seen from the equation 
above, this probability vector is an average of the 
expected behavior h0 and the observed data d, 
weighted by ? and the amount of observed data |D|, 
respectively. 
Our approach entails that from the perspective 
of a language learner, gaps are not qualitatively 
distinct from productive forms.  Instead, 1sg non-
past gaps represent one extreme of a range of 
probabilities that the first person singular will be 
produced.  In this sense, ?gaps? represent an 
artificial boundary which we place on a gradient 
structure for the purpose of evaluating our model.  
The contrast between our learning model and the 
account of gaps presented in Albright (2003) 
merits emphasis at this point.  Generally speaking, 
learning a word involves at least two tasks:  
learning how to generate the appropriate 
phonological form for a given concept and 
inflectional property set, and learning the 
probability that a concept and inflectional property 
set will be produced at all.  Albright?s model 
focuses on the former aspect; our model focuses on 
the latter. In short, our account of gaps lies in the 
likelihood of a concept-IPS pair being expressed, 
not in the likelihood of a form being expressed. 
3.5 Production model 
We model language production as sampling from 
the probability distribution that is the output of the 
learning rule. 
3.6 Seeding the model 
The input to the first generation was sampled from 
the verbs identified in the corpus search (see 2.2). 
Each input set contained 1,000,000 tokens, which 
was the average amount of input for agents in all 
succeeding generations.  This made the first 
 5
940
generation?s input as similar as possible to the 
input of all succeeding generations. 
3.7 Parameter space in the three scenarios 
In our model we manipulate two parameters ? the 
strength of the analogical force on a target concept 
during the learning process (?), and the number of 
concepts which create the analogical force (?), 
taken randomly from known concepts.   
As discussed above, we model three scenarios.  
In the first scenario, there is no grammar learning, 
so there is only one condition (? = 0).  For the 
second and third scenarios, we run the model with 
four values for ?, ranging from weak to strong 
analogical force (0.05, 0.25, 1.25, 6.25), and two 
values for ?, representing influence from a small or 
large set of other words (30, 300). 
4 Evaluating the output of the model 
We evaluate the output of our model against the 
following question: How well do gaps persist?   
We count as gaps any forms meeting the criteria 
outlined in 2.2 above, tabulating the number of 
gaps which exist for only one generation, for two 
total generations, etc.  We define ? as the expected 
number of generations (out of 10) that a given 
concept meets the gap criteria.  Thus, ? represents a 
gap?s ?life expectancy? (see Figure 1). 
We found that this distribution is exponential ? 
there are few gaps that exist for all ten generations, 
and lots of gaps that exist for only one, so we 
calculated ? with a log linear regression.  Each 
value reported is an average over 10 runs.   
As discussed above, our goal was to discover 
whether the model can exhibit the same qualitative 
behavior as the historical development of Russian 
gaps.  Persistence across a handful of generations 
(so far) and spread to a limited number of similar 
forms should be reflected by a non-negligible ?.  
5 Results 
In this section we present the results of our model 
under the scenarios and parameter settings above. 
Remember that in the first scenario there is no 
grammar learning. This run of the model represents 
the baseline condition ? completely word-specific 
knowledge.  Sampling results in random walks on 
form frequencies, so once a word form disappears 
it never returns to the sample.  Word-specific 
learning is thus sufficient for the perseverance of 
existing paradigmatic gaps and the creation of new 
ones.  With no analogical pressure, gaps are 
robustly attested (? = 6.32).  However, the new 
gaps are not restricted to the 1sg, and under this 
scenario, learners are unable to generalize to a 
novel pairing of lexeme + IPS.   
The second scenario presents a more 
complicated picture.  As shown in Table 3, as 
analogical pressure (?) increases, gap life 
expectancy (?) decreases.  In other words, high 
analogical pressure quickly eliminates atypical 
frequency distributions, such as those exhibited by 
gaps. The runs with low values of ? are particularly 
interesting because they represent an approximate 
balance between elimination of gaps as a general 
behavior, and the short-term persistence and even 
spread of gaps due to sampling artifacts and the 
influence of existing gaps. Thus, although the limit 
behavior is for gaps to disappear, this scenario 
retains the ability to explain persistence of gaps 
due to word-specific learning when there is weak 
analogical force. 
At the same time, the facts of Russian differ 
from the behavior of the model in that the Russian 
gaps spread to morphophonologically similar 
forms, not random ones.  The third version of our 
model weights the analogical strength of different 
concepts based upon morphophonological 
similarity to the target.   
 
? ? ? (random) 
?  
(phono.) 
-- 0 6.32 
 
30 0.05 4.95 5.77 
30 0.25 3.46 5.28 
30 1.25 1.91 3.07 
30 6.25 2.59 1.87 
 
300 0.05 4.97 5.99 
300 0.25 3.72 5.14 
300 1.25 1.90 3.10 
300 6.25 2.62 1.84 
Table 3. Life expectancy of gaps, as a function of 
the strength of random analogical forces 
 
Under these conditions we get two interesting 
results, presented in Table 3 above.  First, gaps 
persist slightly better overall in scenario 3 than in 
 6
941
scenario 2 for all levels of ? and ?. 9  Compare the 
? values for random analogical force (scenario 2) 
with the ? values for morphophonologically 
weighted analogical force (scenario 3). 
Second, strength of analogical force matters. 
When there is weak analogical pressure, weighting 
for morphophonological similarity has little effect 
on the persistence and spread of gaps.  However, 
when there is relatively strong analogical pressure, 
morphophonological similarity helps atypical 
frequency distributions to persist, as shown in 
Figure 1.  This results from the fact that there is a 
prototypicality effect for gaps.  Since dental stems 
are more likely to be gaps, incorporating sensitivity 
to stem shape causes the analogical pressure on 
target dental stems to be relatively stronger from 
words that are gaps. Correspondingly, the 
analogical pressure on non-dental stems is 
relatively stronger from words that are not gaps.  
The prototypical stem shape for a gap is thereby 
perpetuated and gaps spread to new dental stems. 
 
0
1
2
3
4
5
6
1 2 3 4 5 6 7 8 9 10
# of generations
log
(# 
of
 ga
ps
)
random, ? = 0.05 random, ? = 1.25
phonological, ? = 0.05 phonological, ? = 1.25
Figure 1. Gap life expectancy (?=0.05, ?=30) 
  
                                                 
9 The apparent increase in gap half-life when ?=6.25 is 
an artifact of the regression model. There were a few 
well-entrenched gaps whose high lemma frequency 
enables them to resist even high levels of analogical 
pressure over 10 generations.  These data points skewed 
the regression, as shown by a much lower R2 (0.5 vs. 
0.85 or higher for all the other conditions).  
6 Discussion 
In conclusion, our model has in many respects 
succeeded in getting gaps to perpetuate and spread.  
With word-specific learning alone, well-
entrenched gaps can be maintained across multiple 
generations.  More significantly, weak analogical 
pressure, especially if weighted for morpho-
phonological similarity, results in the perseverance 
and short-term growth of gaps.   This is essentially 
the historical pattern of the Russian verbal gaps.  
These results highlight several issues regarding 
both the nature of paradigmatic gaps and the 
structure of inflectional systems generally. 
We claim that it is not necessary to posit an 
irreconcilable conflict in the generation of inflected 
forms in order to account for gaps.  Remember that 
in our model, agents face no conflict in terms of 
which form to produce ? there is only one 
possibility.  Yet the gaps persist in part because of 
analogical pressure from existing gaps.  Albright 
(2003) himself is agnostic on the issue of whether 
form-based competition is necessary for the 
existence and persistence of gaps, but Hudson 
(2000), among others, claims that gaps could not 
exist in the absence of it.  We have presented 
evidence that this claim is unfounded. 
But why would someone assume that grammar 
competition is necessary?  Hudson?s claim arises 
from a confusion of two issues.  Discussing the 
English paradigmatic gap amn?t, Hudson states 
that ?a simple application of [the usage-based 
learning] principle would be to say that the gap 
exists simply because nobody says amn?t...  But 
this explanation is too simple... There are many 
inflected words that may never have been uttered, 
but which we can nevertheless imagine ourselves 
using, given the need; we generate them by 
generalization? (Hudson 2000:300).  By his logic, 
there must therefore be some source of grammar 
conflict which prevents speakers from generalizing.   
However, there is a substantial difference 
between having no information about a word, and 
having information about the non-usage of a word.  
We do not dispute learners? ability to generalize.  
We only claim that information of non-usage is 
sufficient to block such generalizations.  When 
confronted with a new word, speakers will happily 
generalize a word form, but this is not the same 
task that they perform when faced with gaps. 
 7
942
The perseverance of gaps in the absence of 
form-based competition shows that a different, 
non-form level of representation is at issue.  
Generating inflectional morphology involves at 
least two different types of knowledge: knowledge 
about the appropriate word form to express a given 
concept and IPS on the one hand, and knowledge 
of how often that concept and IPS is expressed on 
the other. The emergence of paradigmatic gaps 
may be closely tied to the first type of knowledge, 
but the Russian gaps, at least, persist because of 
the second type of knowledge.  We therefore 
propose that morphology may be defective at the 
morphosyntactic level. 
This returns us to the question that we began this 
paper with ?  how paradigmatic gaps can persist in 
light of the overwhelming productivity of 
inflectional morphology.  Our model suggests that 
the apparent contradiction is, at least in some cases, 
illusory.  Productivity refers to the likelihood of a 
given inflectional pattern applying to a given 
combination of stem and IPS.  Our account is 
based in the likelihood of the stem and inflectional 
property set being expressed at all, regardless of 
the form.  In short, the Russian paradigmatic gaps 
represent an issue which is orthogonal to 
productivity.  The two issues are easily confused, 
however.  An unusual frequency distribution can 
make it appear that there is in fact a problem at the 
level of form, even when there may not be. 
Finally, our simulations raise the question of 
whether the 1sg non-past gaps in Russian will 
persist in the language in the long term. In our 
model, analogical forces delay convergence to the 
mean, but the limit behavior is that all gaps 
disappear.  Although there is evidence in Russian 
that words can develop new gaps, we do not know 
with any great accuracy whether the set of gaps is 
currently expanding, contracting, or approximately 
stable.  Our model predicts that in the long run, the 
gaps will disappear under general analogical 
pressure.  However, another possibility is that our 
model includes only enough factors (e.g., 
morphophonological similarity) to approximate the 
short-term influences on the Russian gaps and that 
we would need more factors, such as semantics, to 
successfully model their long-term development.  
This remains an open question. 
 
References 
Albright, Adam. 2003. A quantitative study of Spanish 
paradigm gaps. In West Coast Conference on Formal 
Linguistics 22 proceedings, eds. Gina Garding and 
Mimu Tsujimura. Somerville, MA: Cascadilla Press, 
1-14. 
Albright, Adam, and Bruce Hayes. 2002. Modeling 
English past tense intuitions with minimal 
generalization. In Proceedings of the Sixth Meeting of 
the Association for Computational Linguistics 
Special Interest Group in Computational Phonology 
in Philadelphia, July 2002, ed. Michael Maxwell. 
Cambridge, MA: Association for Computational 
Linguistics, 58-69. 
Baerman, Matthew. 2007. The diachrony of 
defectiveness. Paper presented at 43rd Annual 
Meeting of the Chicago Linguistic Society in 
Chicago, IL, May 3-5, 2007. 
Baerman, Matthew, and Greville Corbett. 2006. Three 
types of defective paradigms. Paper presented at The 
Annual Meeting of the Linguistic Society of America 
in Albuquerque, NM, January 5-8, 2006. 
Hudson, Richard. 2000. *I amn?t. Language 76 (2):297-
323. 
Manning, Christopher. 2003. Probabilistic syntax. In 
Probabilistic linguistics, eds. Rens Bod, Jennifer Hay 
and Stephanie Jannedy. Cambridge, MA: MIT Press, 
289-341. 
Niyogi, Partha. 2006. The computational nature of 
language learning and evolution. Cambridge, MA: 
MIT Press. 
Sims, Andrea. 2006. Minding the gaps: Inflectional 
defectiveness in paradigmatic morphology. Ph.D. 
thesis: Linguistics Department, The Ohio State 
University. 
?vedova, Julja. 1982. Grammatika sovremennogo 
russkogo literaturnogo jayzka. Moscow: Nauka. 
Zaliznjak, A.A., ed. 1977. Grammati?eskij slovar' 
russkogo jazyka: Slovoizmenenie. Moskva: Russkij 
jazyk. 
Zuraw, Kie. 2003. Probability in language change. In 
Probabilistic linguistics, eds. Rens Bod, Jennifer Hay 
and Stephanie Jannedy. Cambridge, MA: MIT Press, 
139-176. 
 
 8
943
Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 55?63,
Baltimore, Maryland USA, June 27 2014.
c?2014 Association for Computational Linguistics
Rules, Analogy, and Social Factors codetermine past-tense formation
patterns in English
P
?
eter R
?
acz
New Zealand Institute of
Language Brain and Behaviour,
University of Canterbury
peter.racz@
Clay Beckner
New Zealand Institute of
Language Brain and Behaviour,
University of Canterbury
clayton.beckner@
canterbury.ac.nz
Jennifer B. Hay
New Zealand Institute of
Language Brain and Behaviour,
University of Canterbury
jen.hay@
Janet B. Pierrehumbert
Department of Linguistics / NICO
Northwestern University.
New Zealand Institute of
Language Brain and Behaviour,
University of Canterbury
jbp@northwestern.edu
Abstract
We investigate past-tense formation pref-
erences for five irregular English verb
classes. We gathered data on a large scale
using a nonce probe study implemented on
Amazon Mechanical Turk. We compare
a Minimal Generalization Learner (which
infers stochastic rules) with a General-
ized Context Model (which evaluates new
items via analogy with existing items) as
models of participant choices. Overall,
the GCM is a better predictor, but the
the MGL provides some additional pre-
dictive power. Because variation across
speakers is greater than variation across
items, we also explore individual-level
factors as predictors. Females exhibited
significantly more categorical choices than
males, a finding that can be related to re-
sults in sociolinguistics.
1 Introduction
In this report, we present a psycholinguistic study
of English past tense categories, using a nonce-
probe experiment implemented on Amazon Me-
chanical Turk. The English past tense has been
a testing-ground for a wide range of theories
and predictions in psycholinguistics, including the
processes of acquisition, the nature of lexical rep-
resentation, and the representation of inflectional
patterns as rules or as generalizations over spe-
cific items (Bybee and Slobin, 1982a; Rumelhart
and McClelland, 1985; McClelland and Patterson,
2002; Albright and Hayes, 2003).
The present study investigates the factors in-
fluencing patterns of preferred past tense forms
for particular verb classes. English past tenses
are not merely a memorized list, but rather, verb
categories can shrink, or expand to include new
items. In everyday speech, there is evidence of
ongoing influences from multiple verb classes, as
verbs exhibit variation and slowly shift in their us-
age (dived vs. dove, sneaked vs. snuck), (Haber,
1976; Bybee and Moder, 1983).
Given that speakers can adapt their verbal cate-
gories to new situations, what is the best represen-
tation for the relevant morphological generaliza-
tions? In analogical models, the focus is on exist-
ing stored items in memory. The acceptability of
a candidate past tense formation pattern for a par-
ticular candidate item is determined by patterns of
similarity to stored items. Morphological innova-
tion and productivity arises from generalizations
over existing forms in the lexicon. To account for a
speech error such as glew as the past tense of glow
(Bybee and Slobin, 1982a), an analogical explana-
tion would highlight the close similarity between
glow and the present tense forms blow, throw,
know, which provide the basis for an analogy with
the past forms blew, threw, knew. Of particular
interest is the Generalized Context Model (GCM)
(Nosofsky, 1990; Albright and Hayes, 2003), an
analogical model which assesses a category?s suit-
ability to a target item on the basis of feature-
based similarities summed over category items,
in addition to the category?s size. It has already
been successfully applied to model regular and ir-
regular patterns in Arabic morphology (Dawdy-
Hesterberg and Pierrehumbert, 2014).
Rule-based approaches propose more abstract
representations of generalizations. Originally pro-
posed to handle broadly applicable default pat-
terns, (such as ?add -ed to express the past
tense?), rule-based approaches have recently been
extended to incorporate multiple stochastic rules.
Albright and Hayes (2003) assign scores to mor-
phological rules by training a Minimal General-
ization Learner (MGL) over a dataset, an algo-
rithm that iterates over pairs of words in the lexi-
con, hypothesizing generalizations conservatively
on the basis of any phonological features that are
55
shared across the words. A rule is scored accord-
ing to how many items it applies to in the lexi-
con, weighted against cases in which the inferred
phonological context is present but the rule fails
to apply. The resulting system consists of a cat-
alog of weighted natural class-based generaliza-
tions which compete with one another, and which
are more or less likely to apply in various phono-
logical contexts (for regular as well as irregular
verbs). Albright and Hayes argue that the MGL
outperforms the GCM in predicting participant be-
havior in a nonce-verb production task they con-
ducted.
2 Experiment
We collected a large amount of data on irregular
past tense formation in English with a nonce probe
test, a classic method for exploring the produc-
tivity of inflectional morphology (Berko, 1958).
Earlier studies used 30 or fewer participants per
condition (Bybee and Slobin, 1982a; Albright and
Hayes, 2003). By using Amazon Mechanical
Turk, a burgeoning forum for psycholinguistic re-
search (Munro et al., 2010), we were able to re-
cruit a large number of participants and explore
the role of individual-level factors in the choice
of morphological patterns. Moreover, we tested
participant preferences across a large dataset (316
nonce verbs) based on broad phonological sam-
pling within verb classes, allowing for repeated
trials across similar items for each participant.
Participants in our online study were presented
with a forced choice task in which they had to pick
either the regular or the irregular past tense form
for an English nonce verb, presented in a carrier
sentence. This was followed by a vocabulary task
in which participants had to rate the familiarity of
English nouns.
2.1 Stimuli
We set up five categories of irregular past tense
formation based on phonological form of the
present tense verb, and its corresponding candi-
date tense past forms. Each category exhibits
phonological variability within the category, while
also allowing for a specific phonological descrip-
tion. We avoided ?miscellaneous? verb classes, as
well as wholly idiosyncratic patterns (such as go?
went). Moreover, we are particularly interested
in morphological classes which are known to dis-
play some indeterminacy (Haber, 1976), i.e., those
classes which display some regular/irregular vari-
ation (dived vs. dove), due to the ready availabil-
ity of multiple generalizations. The literature con-
tains various taxonomies of English irregular verb
classes (Bybee and Slobin, 1982a), but our current
classification mostly represents a subset of the de-
tailed verb classes outlined by Moder (1992).
The five categories of interest are as follows.
? SANG. Verbs that form the past tense with a
vowel change from [I] to [?] (e.g. sing?sang,
sink?sank, swim?swam).
? BURNT. Verbs that form the past tense by
adding a [t], with no change in the stem vowel
(e.g. burn?burnt, spill?spilt, learn?learnt).
These items constitute a distinct set from reg-
ular English pasts such as boss?bossed which
are articulated with a [t] allomorph, insofar as
the burnt verb bases actually end in a voiced
consonant but are nonetheless affixed with a
voiceless stop.
? KEPT. Verbs that form the past tense by
adding a final [t] and changing the stem
vowel from [i] to [E] (e.g. keep?kept, mean?
meant, feel?felt ).
? DROVE. Verbs that form the past tense with
a vowel change from [aI] or [i] to [oU] (e.g.
drive?drove, weave?wove, ride?rode).
? CUT. No-change past tense verbs, that is,
verbs the past tense form of which is identi-
cal to their present tense form. (e.g. cut?cut,
cost?cost, hurt?hurt). Verb bases in this class
end in sounds that are already associated with
the English past tense ([t] or [d]) (Bybee
and Slobin, 1982a), although the nonce verb
bases in the present study all end in [t].
We generated nonce verb forms by combining
the category-specific restrictions spelled out above
on the stem with a set of syllable onsets that oc-
cur in English. Using CELEX (Baayen et al.,
1993), we then filtered the orthographic and pho-
netic transcriptions of the nonce stems, as well as
the resulting past tense forms, to exclude real En-
glish words. Two native speakers checked the final
list to remove additional real words that were not
filtered out via the CELEX database (e.g., slang
and informal terms). All our verb forms were
monosyllabic? as are almost all English irregular
verbs in general. The method used to generate the
56
stimuli means that some nonce forms looked more
similar to real English verbs than others. This way
we can tell whether similarities to a single form
will strongly influence people?s behavior in the
case where the nonce form is highly similar to a
single real form.
The sang and cut categories consist of 60
forms. The burnt category has 40, drove has 76,
and kept has 80. The total number of nonce verbs
is 316.
2.2 Setup
The experiment consisted of a forced choice task,
in which participants had to pick a regular or ir-
regular past tense form for each verb. Verbs were
presented one at a time, visually, in a carrier sen-
tence of the form ?I really like to VERB. Yester-
day, I .?. Two buttons were presented under the
carrier sentence, one with the regular past tense,
adding -ed, and one with the irregular past tense.
The irregular past tense was always the dominant
pattern for the category. (So, for cut, it was identi-
cal to the present tense, etc.) The order of the two
buttons was randomized for each verb. Each verb
was presented once and the order of verbs was ran-
domized for each participant.
The experiment was appended by a word fa-
miliarity rating task. The rating task was based
on Frisch and Brea-Spahn (2010). It consisted of
50 nouns of varying familiarity, as well as 10 ex-
tremely common nouns and 10 nonce words. The
70 words were presented in a random order. The
participant had to select, on a scale of 1-5, how
familiar the given word was. Incorrect answers to
the extremely common nouns and the nonce words
were used as an exclusion criterion. Answers for
the other items were used as an index of vocabu-
lary level, which is predicted to affect morpholog-
ical choices in both the GCM and MGL models.
2.3 Participants
111 people took part in the experiment on Amazon
Mechanical Turk during the course of two days.
51 were women, 60 were men, and 1 did not spec-
ify. The age range of the participants was 20-65,
and the mean age was 34. All participants were
native speakers of American English. Participants
were paid three dollars. We excluded ten partici-
pants from the analysis because they failed to dif-
ferentiate familiar from unfamiliar words in the
vocabulary test.
Category Experiment Nonce Examples
drove 0.52 skride: skrode, skrided
sang 0.58 sking: skang, skinged
kept 0.59 skeep: skept, skeeped
burnt 0.67 skurn: skurnt, skurned
cut 0.83 skast: skast, skasted
Table 1: Categories and mean regularization rat-
ings.
2.4 Results
The nonce verb categories have different rates of
regular vs. irregular usage, as can be seen in Ta-
ble 1. The Experiment column shows the mean
regularization rates of the categories in our exper-
iment. The drove class was regularized the least
often, and the cut class the most often, with a con-
siderable difference between the two.
The trends across verb classes are similar to
those of Moder?s (1992) nonce experiment. Note
in particular the high regularization rate (83%) of
the no-change class of verbs (cut). A search of
CELEX indicates that no-change [t]-final verbs
are quite widespread in English, represented by
more than 30 types. Yet based on nonce responses,
the English no-change pattern is not very prone to
being applied to novel items. This finding matches
observations by Bybee (1982b) that the no-change
verb class has been on the decline in English, as
evident from increasing regularization. One note-
worthy feature of the cut-type verbs is that the
phonological shape of the base is a quite unreliable
indicator of verb class. That is to say, there are
many [t]- final verb stems which typically take the
regular -ed suffix (e.g., gritted, salted, blasted, and
these provide counterexamples to the no-change
pattern (cf. Moder (1992) on cue validity).
We fit a simple stepwise logistic mixed-effects
regression model to the results with a maximal
random effects structure, using regularization of
individual verb form (yes or no) as an outcome
variable and category as predictor. This model
confirms the general finding that there is signif-
icant variation across the verb classes. (Signifi-
cance values reported are based on difference with
the sang class.) The cut class shows the highest
rate of regularization (p<0.001), followed by the
burnt class (p<0.01). It is followed by the sang
and kept classes (these two do not differ signifi-
cantly). The drove class shows the lowest rate of
regularization (p<0.01).
57
Participant gender, age, and vocabulary size are
not significant predictors of regularization in the
simple logistic mixed effects model. However an
examination of the data (Figure 1) reveals that for
each verb class, variation across subjects is consid-
erably greater than variation across items. This ob-
servation suggests that individual traits may play
a role in morphological choices in a way that the
simple model fails to capture. We will return
to this issue after presenting the GCM and MGL
model fits, and will find in the end that gender does
affect response patterns.
l
burnt cut drove kept sang
0.4
0.6
0.8
category
m
ea
n 
ra
te 
of 
reg
ula
riza
tio
n items
l
burnt cut drove kept sang
0.0
0.2
0.4
0.6
0.8
1.0
category
m
ea
n 
ra
te 
of 
reg
ula
riza
tio
n
subjects
Figure 1: Across-item variation in regularization
rates across category (above). Across-subject vari-
ation in regularization rates across category (be-
low).
3 Algorithmic Learning Models
We now turn our attention from the baseline ef-
fects of category variables, to investigate the pre-
dictions of particular algorithmic learning models
that provide alternate representations for general-
izations on the basis of similarity. Our analyses fo-
cus on the predictions of the Minimal Generaliza-
tion Learner and the Generalized Context Model
(Albright and Hayes, 2003; Nosofsky, 1990).
3.1 The two models
The Minimal Generalization Learner (MGL) (Al-
bright and Hayes, 2002; Albright and Hayes,
2003) is an algorithm for inferring stochastic
morphophonological generalizations over a set of
training items (e.g., paired present and past tense
forms). For each pair of items in the lexicon, the
learner maximally aligns wordforms and analyzes
shared phonetic features, thereby merging word-
specific rules (ring/rang and stink/stank) into rules
that express the most general applicable environ-
ment: [I]? [?] / [+coronal, + cont] [N].
Each rule inferred in this way is then fur-
ther generalized on the basis of more compar-
isons; for instance, taking note of swim/swam ex-
pands the [I] ? [?] rule to specify that it oc-
curs before all [+nasal] consonants. The algorithm
thus infers a set of natural-class based generaliza-
tions, which are weighted by comparing the num-
ber of hits for the past tense pattern (ring/rang,
drink/drank, sing/sang, stink/stank, swim/swam,
etc.) divided by the number of cases in which the
alternation fails to apply although it could apply
(thus tallying exceptions such as think and blink).
This appproach favors generalizations that cover
many cases, but penalizes those that are too broad
because their phonetic environments encompass
many exceptions. The MGL reliability metric is
further adjusted to a confidence score, in which
generalizations that apply to a smaller number of
word types are penalized.
Note that the MGL algorithm automatically
groups together items on the basis of shared
phonological properties; thus, monosyllabic verbs
are most likely to form strong generalizations with
other monosyllabic verbs. Attempts to merge
diverse wordforms under a single generalization
would be more likely to incur penalties (i.e., ex-
ceptions). This feature of the MGL is impor-
tant for comparing with the methods of the GCM
(see below). Both algorithms allow for category-
58
specific similarities to play a role.
The Minimal Generalization Learner is imple-
mented here from materials made available by Al-
bright and Hayes (2003), including their Segmen-
tal Similarity Calculator based on Frisch et al.
(2004). The MGL is trained on regular and irreg-
ular English verbs with a minimum frequency cut-
off of 10 in COBUILD (Baayen et al., 1993), and
excluding prefixed verb forms, thus encompassing
4253 past/present verb transcriptions. The MGL is
implemented here with its default settings, which
includes a lower 75% confidence interval for pur-
poses of adjusting the reliability score.
The Generalized Context Model (GCM) is an
instance-based model of categorization. To as-
sign category membership to a novel instance, it
first calculates its similarity to instances in pre-
existing categories. Then, it selects the category
with members that are most similar to the novel
instance (Nosofsky, 1990). Our implementation
of the GCM has three notable aspects to it.
First, we used the GCM to categorize our nonce
verb stimuli, basing the categories on real English
verb types extracted from CELEX (as with the
MGL). Second, we used the same segmental sim-
ilarity calculator developed and used by Albright
and Hayes and used by the Minimal Generaliza-
tion Learner to calculate the similarity of phoneti-
cally transcribed word forms to each other, so that
we could take the phonetic similarity of speech
sounds into account instead of calculating simi-
larity between word forms based on edit distance
alone. We did not weight parts of the word forms
differently, because there is evidence that although
past tense formation in English is predominantly
driven by similarities in word endings, onsets also
play a role. (cf. the predominance of s+stop on-
sets in irregular verbs forming the past tense with
a vowel change, e.g. sing, sink, etc.) (Bybee and
Moder, 1983).
Third, our implementation of the GCM re-
flected the structure of the task. Recall from Sec-
tion 2 that participants were presented with the
stems of the nonce verbs in a sequence and had to
pick either a regular or an irregular past tense form
for them. The irregular past tense form was pre-
determined by category, so that, for a given verb,
the participants could only choose between the
regular past tense form or the irregular past tense
form we assigned to the verb. (So, for instance,
for spling, they could choose either splinged or
splang, but not splung or splingt, etc.) For a given
category (such as sang verbs), the GCM had a
choice between two sets. The irregular set con-
sisted of verb types in CELEX that form their past
tense according to the pattern captured by the cat-
egory (such as an [I]?[?] alternation). The regular
set consisted of verb types that have a stem that
matches the category (such as ?monosyllabic and
stem vowel [I]?) but have a regular past tense. The
model calculated the similarity of a given nonce
verb to these two sets (depending on its category).
In this paper, we report on category weights as-
signed to the regular category, which are compa-
rable with both the results of the Minimal Gener-
alization Learner and the rate of regularization in
our experiment. We only used monosyllabic verbs
in identifying relevant matches, for regular as well
as irregular items.
Values reported here were generated with no
frequency cutoff. Alternate runs with the fre-
quency threshold enforced produce no change in
the model. The model is run with the default pa-
rameter settings of s = 0.3, p = 1 with respect
to calculating the weighted similarities between
items. When p is set to 1, as here, the similar-
ity function is exponential, rather than Gaussian.
The weighting parameter s controls the tradeoff in
the relative importance of the size of the verb cat-
egory (the ?gang size?) vs. the amount of similar-
ity (measured via edit distance between phonolog-
ical forms) (Nosofsky, 1990; Nakisa et al., 2001;
Albright and Hayes, 2003; Dawdy-Hesterberg and
Pierrehumbert, 2014).
Figure 2 shows three plots. The first one de-
picts the relationship between the predictions of
the GCM (regular category weight) and experi-
mental ratings (mean participant regularization)
for individual verb types used in the experiment.
The Spearman rank correlation is highly signifi-
cant (rho = 0.497, p < 0.001). The second one
depicts the relationship between the MGL model
predictions (reliability rating of the regular form)
and mean participant regularization in the exper-
iment. The Spearman rank correlation between
these variables is highly significant (rho = 0.393,
p < 0.001). The predictions of the two models are
z-scored to allow for comparability. The third plot
shows the relationship between the predictions of
the GCM and the MGL for individual verb types
in the experiment. The Spearman rank correla-
tion between these variables is highly significant
59
CATEGORY GCM MGL
SANG 0.65 0.55
CUT 0.18 -0.19
DROVE 0.37 0.64
KEPT 0.52 0.18
BURNT 0.48 0.24
ALL 0.5 0.39
Table 2: Correlations table: Spearman?s rank cor-
relations between mean regularization in the ex-
periment and the predictions of the two models
(rho = 0.347, p < 0.001), but the correlation is
far from perfect. Comparing the overall correla-
tions and patterns in Figure 2, it appears that the
GCM is doing a better job of predicting the varia-
tion across items than the MGL is. We now turn to
an examination of the predictions within our verb
classes.
3.2 Model comparisons within verb class
Table 2 shows Spearman rank correlations be-
tween mean regularization in the experiment and
the predictions of the two models for the five verb
categories. Overall, GCM does a better job. The
no-change (cut) verb class is especially illustra-
tive of the differences between the two models.
Note that the MGL is negatively correlated with
our experimental data for this category. As noted
above, this verb class appears to be strikingly non-
productive; participants display a strong prefer-
ence for regularizing a wide range of t-final forms.
The MGL underestimates the regularization of
nonce verbs that resemble cut and hit, while over-
estimating the regularization of forms like vurt,
slurt, plurt. The no-change irregular form of such
verbs must be modeled on a pattern with a sole En-
glish exemplar (hurt?hurt), and the Minimal Gen-
eralization model (in contrast with the GCM) is
swayed very little in such cases. This is one of sev-
eral cases where the GCM predicts subject pref-
erences better than the MGL does, seemingly be-
cause the irregular form requires modeling a re-
sponse on a sole exemplar.
There is one verb category where the MGL out-
performs the GCM: the drove class. Here, the
MGL does especially well because it makes an ac-
curate prediction about one subcategory of items:
nonce verbs like quine and sline are regularized by
participants (quined,slined) more often than other
members of the drove class. Here, it seems that
l
l
l
l
l
l
l
l
l
l
l
l
l l
l
l ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l l
l
l
l
l
l
l
l
l l l
l
l
l
ll
l
l
l l
l l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
ll
l
l
l l
l
l
l l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l l
l
l
lll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l l
l
l
l
l l
l
ll
l
l
ll
l
l
l
l l
ll
l
l
l
l
l
l
ll
l
l
ll
l
l l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
ll
ll
ll
l
l
l
ll
l
l
l
l
l
l
l
l l
l
l
l
l l
l
ll
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
?3 ?2 ?1 0 1
0.4
0.5
0.6
0.7
0.8
0.9
predicted regularity
av
er
ag
e r
eg
ula
rity
 in 
exp
eri
me
nt
Ratings vs. GCM
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
lll
l
l
ll
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
ll
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
l
ll
l
l
l
l
l
l
ll
l
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
l
l
l
ll
l
l
l
l
l
ll
l
l
l l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
?3 ?2 ?1 0 1
0.4
0.5
0.6
0.7
0.8
0.9
predicted regularity
av
er
ag
e r
eg
ula
rity
 in 
exp
eri
me
nt
Ratings vs. MGL
l
l
l
l
lll
l
ll
l
l
l
ll
l
ll
l
l
ll
l
ll
ll
l
l
ll
ll
ll
l
l
ll
ll
l
ll
ll
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
lll
l
l
l
l
l
l
ll
l
ll
ll
ll
ll
lll
lll
l
l
l
ll
l
l
ll
l
l
l
l
ll
l
ll
l
lll
l
l
ll
lll
ll
lll
l
ll
l
ll
l
ll
ll
ll
lll
l
l
l
ll
ll
l
ll
lll
lll
ll
l
l
l
l
ll
ll
ll
ll
ll
llll
lll
ll
lll
ll
l
ll
l
ll
ll
ll
ll
lll
ll
ll
lll
lll
lll
ll
ll
l
ll
ll
lll
l
l
l
ll
ll
l
lll
ll
l
?3 ?2 ?1 0 1
?
3
?
2
?
1
0
1
MGL
GC
M
GCM vs. MGL
Figure 2: Above: experimental ratings versus
GCM predictions. Middle: experimental ratings
versus MGL predictions. Below: MGL predic-
tions vs. GCM predictions. (With lowess lines
added.)
60
the irregular past would need to be modeled on
one closely-related English item (shine?shone),
but similar English verbs offer many exceptions
to any abstract generalization (line?lined, mine?
mined, whine?whined, not to mention the transi-
tive verb shine?shined). Such a situation causes
the MGL to correctly classify all -ine final verbs as
highly prone to regularization, because -ine/-one
type irregulars are all dispreferred in the experi-
ment. However, the GCM makes a wide range of
predictions for these stimuli on the basis of differ-
ent segmental similarities with training items (e.g.,
based on the syllable onsets).
On the whole, comparing the two models on the
verb classes suggests that analogy to individual in-
stances is a better approximation of the behavior
of our subjects than recourse to abstract general-
izations. It is true, however, that both the GCM
and the MGL each only explain a part of the ob-
served variance. In order to test whether the two
models contribute differently to explaining partic-
ipant behavior in our dataset, we fitted a simple
stepwise logistic mixed-effects regression model
on the results with maximal random effects struc-
ture, using regularization on the individual verb
form (yes or no) as an outcome variable. Instead
of verb category, we used the GCM and the MGL
regularization rates as predictors. Both predictors
are significant. An analysis of variance test reveals
that the regression model that includes the predic-
tions of both categorization models provides a sig-
nificantly better fit than the models including ei-
ther alone. We tested nonlinear effects of MGL
and GCM, using restricted cubic splines, but non-
linearity did not significantly improve the model.
Participant age and gender are not significant. Vo-
cabulary size explains some variation, though does
not quite meet the threshold of .05 for significance.
The interaction of GCM predictions and partici-
pant gender, however, is significant. The model
coefficients can be seen in Table 3.
3.3 Individual-level factors
As both MGL and GCM make reference to exist-
ing patterns in the lexicon, we hypothesized that
the precise size and contents of an individual?s vo-
cabulary is likely to produce individual variation
in terms of the lexical support available for cer-
tain patterns. Individuals with higher vocabulary
scores may be more likely to have robust stored
instances of irregular, lower frequency, minority
Predictor b z sig.
(Intercept) 0.71 4.5 ***
MGL 12.4 3.38 ***
GCM 1.11 5.05 ***
gender (male) -0.02 -0.07 (n.s.)
vocabulary -0.25 -1.77 .
GCM : gender (male) 0.47 2.12 *
Table 3: Effects of rules vs. analogy in the regres-
sion model
past tense patterns. We might therefore predict
that they are more accepting of irregular realiza-
tions. This is, to some degree, confirmed by the
strength of vocabulary as a predictor of regulariza-
tion in our final model. A potential interaction of
vocabulary size and the two models of past tense
formation is that these models likely have differ-
ent predictions when trained on vocabulary sets of
various sizes ? this is a clear direction of future
research.
We also tested the effects of participant gender,
as women have been reported to be more biased
towards more standard language (Labov, 2001).
This would mean that conformity to speech com-
munity standards in whether a form is irregular
or regular (essentially, getting it ?right?) could be
highly valued by women. Consistent with this
observation, we find a significant interaction be-
tween GCM and participant gender. Females show
a steeper slope for the GCM than the males do.
When there is low analogical support for regular-
ization, females have a tendency to prefer irregular
forms more than males do, but this difference is re-
versed for items where the GCM provides strong
support for the regular. In that case, females prefer
regular forms more than males do. To put it differ-
ently, females categorize the verb forms more in
our dataset than the males do.
It is interesting to note that our results differ
from Hartshorne and Ullman?s (2006) child data
on real English verbs. They found more over-
regularization for girls than for boys. The mecha-
nism they suggest relies on girls having more pre-
cocious verbal ability, as is commonly reported.
These results may seem hard to reconcile, since
the adult women in our study did not regularize
more than men (there was no significant overall
effect of gender), nor did they have larger vocab-
ularies, as measured by our vocabulary inventory.
However, they are compatible if we assume that
61
the real verbal lexicon is rather well learned by
adulthood (as reflected in the weakness of vocab-
ulary level as a statistical predictor in our model)
and that the gender difference we observed taps
the social factors mentioned by Labov, which are
learned gradually during childhood and adoles-
cence.
4 Conclusions
Our results suggest that both the GCM and MGL
models contribute important insights into factors
underpinning perceived wellformedness. Individ-
uals are heavily influenced by the combined ana-
logical force of existing lexical forms. They gen-
eralize over items. However, they also, it appears,
generalize over these generalizations - forming
more abstract ?rules? or associations that operate in
parallel with the token-based analogical processes.
While this seems to be the interpretation that is
pointed to by this current data set, verification of
the joint role of these types of processes clearly
requires a lot more explicit testing in different and
varied data sets, including real verbs in addition to
nonce forms. Recent models in phonological pro-
cessing and speech perception certainly point to a
hybrid model, in which instance-based processing
and reasoning sits alongside more abstract struc-
tures, and in which both types of processes may
be jointly operative ? with the balance affected by
many factors including the particular nature of the
task at hand (Pierrehumbert, 2006). Indeed, we
would predict that it should be possible to design
morphological tasks which more readily tap into
purely analogical processes, or into more abstract
generalizations.
Acknowledgments
This project was made possible through a grant
from the John Templeton Foundation. The opin-
ions expressed in this publication are those of the
authors and do not necessarily reflect the views of
the John Templeton Foundation. Hay and Beckner
were also supported by a Rutherford Discovery
Fellowship awarded to Hay. The authors would
like to thank Adam Albright, Patrick LaShell,
Chun Liang Chan, and Lisa Garnard Dawdy-
Hesterberg. All faults remain ours.
References
Adam Albright and Bruce Hayes. 2002. Modeling En-
glish past tense intuitions with minimal generaliza-
tion. In Proceedings of the ACL-02 workshop on
Morphological and phonological learning-Volume
6, pages 58?69. Association for Computational Lin-
guistics.
Adam Albright and Bruce Hayes. 2003. Rules
vs. analogy in English past tenses: A computa-
tional/experimental study. Cognition, 90(2):119?
161.
R Harald Baayen, Richard Piepenbrock, and Rijn van
H. 1993. The CELEX lexical data base on CD-
ROM.
Jean Berko. 1958. The child?s learning of English mor-
phology. Word, 14:150?177.
Joan L Bybee and Carol Lynn Moder. 1983. Mor-
phological classes as natural categories. Language,
pages 251?270.
Joan L Bybee and Dan I Slobin. 1982a. Rules and
schemas in the development and use of the English
past tense. Language, pages 265?289.
Joan L Bybee and Dan I Slobin. 1982b. Why small
children cannot change language on their own: Sug-
gestions from the English past tense. In Papers from
the 5th international conference on historical lin-
guistics, volume 21.
Lisa Garnand Dawdy-Hesterberg and Janet B Pierre-
humbert. 2014. Learnability and generalisation of
Arabic broken plural nouns. Language, Cognition
and Neuroscience, (ahead-of-print):1?15.
Stefan A Frisch and Maria R Brea-Spahn. 2010.
Metalinguistic judgments of phonotactics by mono-
linguals and bilinguals. Laboratory Phonology,
1(2):345?360.
Stefan Frisch, Michael Broe, and Janet Pierrehumbert.
2004. Similarity avoidance and the OCP. Natural
Language and Linguistic Theory, 22:179?228.
Lyn R Haber. 1976. Leaped and leapt: a theoretical
account of linguistic variation. Foundations of Lan-
guage, pages 211?238.
Joshua K Hartshorne and Michael T Ullman. 2006.
Why girls say holded more than boys. Developmen-
tal Science, 9(1):21?32.
William Labov. 2001. Principles of linguistic change
Volume 2: Social factors. Blackwell.
James L McClelland and Karalyn Patterson. 2002.
Rules or connections in past-tense inflections: What
does the evidence rule out? Trends in cognitive sci-
ences, 6(11):465?472.
Carol Lynn Moder. 1992. Productivity and categoriza-
tion in morphological classes. Ph.D. thesis, State
University of New York at Buffalo.
62
Robert Munro, Steven Bethard, Victor Kuperman,
Vicky Tzuyin Lai, Robin Melnick, Christopher
Potts, Tyler Schnoebelen, and Harry Tily. 2010.
Crowdsourcing and language studies: the new gen-
eration of linguistic data. In Proceedings of the
NAACL HLT 2010 Workshop on Creating Speech
and Language Data with Amazon?s Mechanical
Turk, pages 122?130. Association for Computa-
tional Linguistics.
Ramin C. Nakisa, Kim Plunkett, and Ulrike Hahn.
2001. A cross-linguistic comparison of single and
dual-route models of inflectional morphology. Peter
Broeder, & Jaap Murre, Models of Language Acqui-
sition: Inductive and Deductive Approaches, pages
201?222.
Robert M Nosofsky. 1990. Relations between
exemplar-similarity and likelihood models of clas-
sification. Journal of Mathematical Psychology,
34(4):393?418.
Janet B Pierrehumbert. 2006. The next toolkit. Jour-
nal of Phonetics, 34(4):516?530.
David E Rumelhart and James L McClelland. 1985.
On learning the past tenses of English verbs. Insti-
tute for Cognitive Science, University of California,
San Diego.
63
