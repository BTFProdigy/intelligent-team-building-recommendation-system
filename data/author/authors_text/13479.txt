Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 653?661,
Beijing, August 2010
Structure-Aware Review Mining and Summarization
Fangtao Li1, Chao Han1, Minlie Huang1, Xiaoyan Zhu1,
Ying-Ju Xia2, Shu Zhang2 and Hao Yu2
1State Key Laboratory of Intelligent Technology and Systems?
1Tsinghua National Laboratory for Information Science and Technology?
1Department of Computer Science and Technology, Tsinghua University
2Fujitsu Research and Development Center
fangtao06@gmail.com; zxy_dcs@tsinghua.edu.cn
Abstract
In this paper, we focus on object feature 1
1 Introduction
based review summarization. Different from 
most of previous work with linguistic rules or 
statistical methods, we formulate the review
mining task as a joint structure tagging prob-
lem. We propose a new machine learning 
framework based on Conditional Random 
Fields (CRFs). It can employ rich features to 
jointly extract positive opinions, negative opi-
nions and object features for review sentences.
The linguistic structure can be naturally inte-
grated into model representation. Besides li-
near-chain structure, we also investigate con-
junction structure and syntactic tree structure
in this framework. Through extensive experi-
ments on movie review and product review 
data sets, we show that structure-aware mod-
els outperform many state-of-the-art ap-
proaches to review mining.
With the rapid expansion of e-commerce, people 
are more likely to express their opinions and 
hands-on experiences on products or services
they have purchased. These reviews are impor-
tant for both business organizations and personal 
costumers. Companies can decide on their strat-
egies for marketing and products improvement. 
Customers can make a better decision when pur-
1 Note that there are two meanings for word ?feature?. 
We use ?object feature? to represent the target entity,
which the opinion expressed on, and use ?feature? as
the input for machine learning methods.
chasing products or services. Unfortunately, 
reading through all customer reviews is difficult, 
especially for popular items, the number of re-
views can be up to hundreds or even thousands. 
Therefore, it is necessary to provide coherent 
and concise summaries for these reviews.
Figure 1. Feature based Review Summarization
Inspired by previous work (Hu and Liu, 2004; 
Jin and Ho, 2009), we aim to provide object fea-
ture based review summarization. Figure 1 
shows a summary example for movie ?Gone 
with the wind?. The object (movie) features, 
such as ?movie?, ?actor?, with their correspond-
ing positive opinions and negative opinions, are 
listed in a structured way. The opinions are 
ranked by their frequencies. This provides a con-
cise view for reviews. To accomplish this goal, 
we need to do three tasks:  1), extract all the ob-
ject features and opinions; 2), determine the sen-
timent polarities for opinions; 3), for each object 
feature, determine the relevant opinions, i.e. ob-
ject feature-opinion pairs.
For the first two tasks, most previous studies
employ linguistic rules or statistical methods (Hu 
and Liu, 2004; Popescu and Etzioni 2005). They 
mainly use unsupervised learning methods,
which lack an effective way to address infre-
quent object features and opinions. They are also
hard to incorporate rich overlapping features.
Gone With The Wind:
Movie:
     Positive: great, good, amazing, ? , breathtaking
     Negative: bad, boring, waste time, ? , mistake
Actor: 
     Positive: charming , brilliant , great, ? , smart 
     Negative: poor, fail, dirty, ? , lame
Music:
     Positive: great, beautiful, very good, ? , top
     Negative: annoying, noise, too long, ? , unnecessary 
    ? ?
653
Actually, there are many useful features, which 
have not been fully exploited for review mining.
Meanwhile, most of previous methods extract 
object features, opinions, and determine the po-
larities for opinions separately. In fact, the object 
features, positive opinions and negative opinions
correlate with each other. 
In this paper, we formulate the first two tasks,
i.e. object feature, opinion extraction and opi-
nion polarity detection, as a joint structure tag-
ging problem, and propose a new machine learn-
ing framework based on Conditional Random 
Fields (CRFs). For each sentence in reviews, we 
employ CRFs to jointly extract object features,
positive opinions and negative opinions, which 
appear in the review sentence. This framework
can naturally encode the linguistic structure. Be-
sides the neighbor context with linear-chain 
CRFs, we propose to use Skip-chain CRFs and 
Tree CRFs to utilize the conjunction structure
and syntactic tree structure. We also propose a
new unified model, Skip-Tree CRFs to integrate 
these structures. Here, ?structure-aware? refers 
to the output structure, which model the relation-
ship among output labels. This is significantly 
different from the previous input structure me-
thods, which consider the linguistic structure as 
heuristic rules (Ding and Liu, 2007) or input fea-
tures for classification (Wilson et al 2009). Our 
proposed framework has the following advan-
tages: First, it can employ rich features for re-
view mining. We will analyze the effect of fea-
tures for review mining in this framework.
Second, the framework can utilize the relation-
ship among object features, positive opinions 
and negative opinions. It jointly extracts these 
three types of expressions in a unified way.
Third, the linguistic structure information can be 
naturally integrated into model representation,
which provides more semantic dependency for 
output labels. Through extensive experiments on 
movie review and product review, we show our 
proposed framework is effective for review min-
ing.
The rest of this paper is organized as follows: 
In Section 2, we review related work. We de-
scribe our structure aware review mining me-
thods in Section 3. Section 4 demonstrates the 
process of summary generation. In Section 5, we 
present and discuss the experiment results. Sec-
tion 6 is the conclusion and future work.
2 Related Work
Object feature based review summary has been 
studied in several papers. Zhuang et al (2006) 
summarized movie reviews by extracting object 
feature keywords and opinion keywords. Object 
feature-opinion pairs were identified by using a 
dependency grammar graph. However, it used a
manually annotated list of keywords to recognize 
movie features and opinions, and thus the system 
capability is limited. Hu and Liu (2004) pro-
posed a statistical approach to capture object 
features using association rules. They only con-
sidered adjective as opinions, and the polarities 
of opinions are recognized with WordNet expan-
sion to manually selected opinion seeds. Popescu 
and Etzioni (2005) proposed a relaxation labe-
ling approach to utilize linguistic rules for opi-
nion polarity detection. However, most of these 
studies focus on unsupervised methods, which
are hard to integrate various features. Some stu-
dies (Breck et al 2007; Wilson et al 2009; Ko-
bayashi et al 2007) have used classification 
based methods to integrate various features. But 
these methods separately extract object features
and opinions, which ignore the correlation 
among output labels, i.e. object features and opi-
nions. Qiu et al (2009) exploit the relations of 
opinions and object features by adding some lin-
guistic rules. However, they didn?t care the opi-
nion polarity. Our framework can not only em-
ploy various features, but also exploit the corre-
lations among the three types of expressions, i.e.
object features, positive opinions, and negative 
opinions, in a unified framework. Recently, Jin 
and Ho (2009) propose to use Lexicalized HMM
for review mining. Lexicalized HMM is a va-
riant of HMM. It is a generative model, which is 
hard to integrate rich, overlapping features. It 
may encounter sparse data problem, especially 
when simultaneously integrating multiple fea-
tures. Our framework is based on Conditional 
Random Fields (CRFs). CRFs is a discriminative 
model, which can easily integrate various fea-
tures.
These are some studies on opinion mining with 
Conditional Random Fields. For example, with 
CRFs, Zhao et al(2008) and McDonald et al 
(2007) performed sentiment classification in sen-
tence and document level; Breck et al(2007) 
identified opinion expressions from newswire 
documents; Choi et al (2005) determined opi-
654
nion holders to opinions also from newswire da-
ta. None of previous work focuses on jointly ex-
tracting object features, positive opinions and 
negative opinions simultaneously from review 
data. More importantly, we also show how to 
encode the linguistic structure, such as conjunc-
tion structure and syntactic tree structure, into 
model representation in our framework. This is 
significantly different from most of previous 
studies, which consider the structure information 
as heuristic rules (Hu and Liu, 2004) or input 
features (Wilson et al 2009).
Recently, there are some studies on joint sen-
timent/topic extraction (Mei et al 2007; Titov 
and McDonald, 2008; Snyder and Barzilay, 
2007). These methods represent reviews as sev-
eral coarse-grained topics, which can be consi-
dered as clusters of object features. They are
hard to indentify the low-frequency object fea-
tures and opinions. While in this paper, we will 
extract all the present object features and corres-
ponding opinions with their polarities. Besides, 
the joint sentiment/topic methods are mainly
based on review document for topic extraction.
In our framework, we focus on sentence-level
review extraction.
3 Structure Aware Review Mining
3.1 Problem Definition
To produce review summaries, we need to first 
finish two tasks: identifying object features, opi-
nions, and determining the polarities for opi-
nions. In this paper, we formulate these two 
tasks as a joint structure tagging problem. We
first describe some related definitions:
Definition (Object Feature): is defined as whole 
target expression that the subjective expressions 
have been commented on. Object features can be 
products, services or their elements and proper-
ties, such as ?character?, ?movie?, ?director? for 
movie review, and ?battery?, ?battery life?,
?memory card? for product review.
Definition (Review Opinion): is defined as the 
whole subjective expression on object features.
For example, in sentence ?The camera is easy to 
use?, ?easy to use? is a review opinion. ?opinion? 
is used for short.
Definition (Opinion Polarity): is defined as the 
sentiment category for review opinion. In this 
paper, we consider two types of polarities: posi-
tive opinion and negative opinion. For example,
?easy to use? belongs to positive opinion.
For our review mining task, we need to 
represent three types of expressions: object fea-
tures, positive opinions, and negative opinions. 
These expressions may be words, or whole
phrases. We use BIO encoding for tag represen-
tation, where the non-opinion and neutral opi-
nion words are represented as ?O?. With Nega-
tion (N), which is only one word, such as ?not?,
?don?t?, as an independent tag, there are totally 8 
tags, as shown in Table 1. The following is an 
example to denote the tags:
The/O camera/FB comes/O with/O a/O piti-
ful/CB 32mb/FB compact/FI flash/FI card/FI ./O
FB Feature Beginning CB Negative Beginning
FI Feature Inside CI Negative Inside
PB Positive Beginning N Negation Word 
PI Positive Inside O Other 
Table 1. Basic Tag Set for Review Mining
3.2 Structure Aware Model
In this section, we describe how to encode dif-
ferent linguistic structure into model representa-
tion based on our CRFs framework.
3.2.1 Using Linear CRFs.
For each sentence in a review, our task is to ex-
tract all the object features, positive opinions and 
negative opinions. This task can be modeled as a 
classification problem. Traditional classification 
tools, e.g. Maximum Entropy model (Berger et 
al, 1996), can be employed, where each word or 
phrase will be treated as an instance. However, 
they independently consider each word or 
phrase, and ignore the dependency relationship 
among them.
Actually, the context information plays an im-
portant role for review mining. For example, 
given two continuous words with same part of 
speech, if the previous word is a positive opi-
nion, the next word is more likely a positive opi-
nion. Another example is that if the previous 
word is an adjective, and it is an opinion, the 
next noun word is more likely an object feature.
To this end, we formulate the review mining 
task as a joint structure tagging problem, and 
propose a general framework based on Condi-
tional Random Fields (CRFs) (Lafferty et al, 
2001) which are able to model the dependencies 
655
y1 yn-1y3y2 yn
x1 xn-1x3x2 xn
(a) Linear-chain  CRFs
y4
x1 xn-1x3x2 xnxn-2
?
x4
y1 yn-2y3 yn
y2 yn-1
(c) Tree-CRFs
y4
x1 xn-1x3x2 xnxn-2
?
x4
y1 yn-2y3 yn
y2 yn-1
(d) Skip-Tree CRFs
(b) Skip-chain  CRFs
Figure 2 CRFs models
between nodes. (See Section 3.2.5 for more 
about CRFs)
In this section, we propose to use linear-chain
CRFs to model the sequential dependencies be-
tween continuous words, as discussed above. It 
views each word in the sentence as a node, and 
adjacent nodes are connected by an edge. The 
graphical representation is shown in Figure 2(a).
Linear CRFs can make use of dependency rela-
tionship among adjacent words.
3.2.2 Leveraging Conjunction Structure
We observe that the conjunctions play important 
roles on review mining: If the words or phrases 
are connected by conjunction ?and?, they mostly 
belong to the same opinion polarity. If the words 
or phrases are connected by conjunction ?but?, 
they mostly belong to different opinion polarity,
as reported in (Hatzivassiloglou and McKeown,
1997; Ding and Liu, 2007). For example, ?This
phone has a very cool and useful feature ? the
speakerphone?, if we only detect ?cool?, it is 
hard to determine its opinion polarity. But if we 
see ?cool? is connected with ?useful? by con-
junction ?and?, we can easily acquire the polari-
ty of ?cool? as positive. This conjunction struc-
ture not only helps to determine the opinions, but 
also helps to recognize object features. For ex-
ample, ?I like the special effects and music in 
this movie?, with word ?music? and conjunction
?and?, we can easily detect that ?special effects? 
as an object feature.
To model the long distance dependency with 
conjunctions, we use Skip-chain CRFs model to 
detect object features and opinions. The graphi-
cal representation of a Skip-chain CRFs, given in 
Figure 2(b), consists of two types of edges: li-
near-edge (

to 

) and skip-edge (

to 

). 
The linear-edge is described as linear CRFs. The 
skip-edge is imported as follows:
We first identify the conjunctions in the re-
view sentence, with a collected conjunction set,
including ?and?, ?but?, ?or?, ?however?, ?al-
though? etc. For each conjunction, we extract its 
connected two text sequences. The nearest two 
words with same part of speech from the two 
text sequences are connected with the skip-edge. 
Here, we just consider the noun, adjective, and 
adverb. For example, in ?good pictures and 
beautiful music?, there are two skip-edges: one 
connects two adjective words ?good? and ?beau-
tiful?; the other connects two nouns ?pictures? 
and ?music?. We also employ the general senti-
ment lexicons, SentiWordNet (Esuli and Sebas-
tiani, 2006), to connect opinions. Two nearest 
opinion words, detected by sentiment lexicon,
from two sequences, will also be connected by 
skip-edge. If the nearest distance exceeds the 
threshold, this skip edge will be discarded. Here,
we consider the threshold as nine.
Skip-chain CRFs improve the performance of 
review mining, because it naturally encodes the 
conjunction structure into model representation 
with skip-edges.
3.2.3 Leveraging Syntactic Tree Structure
Besides the conjunction structure, the syntactic 
tree structure also helps for review mining. The
tree denotes the syntactic relationship among 
words. In a syntactic dependency representation, 
each node is a surface word. For example, the 
corresponding dependency tree (Klein and Man-
ning, 2003) for the sentence, ?I really like this 
long movie?, is shown in Figure 3.
y1 yn-1y3y2 yn
x1 xn-1x3x2 xn
656
like
longthis
really movieI
nsubj dobjadvmod
det amod
Figure 3. Syntactic Dependency Tree Representation
In linear-chain structure and skip-chain structure, 
?like? and ?movie? have no direct edge, but in 
syntactic tree, ?movie? is directly connected 
with ?like?, and their relationship ?dobj? is also 
included, which shows ?movie? is an objective 
of ?like?. It can provide deeper syntactic depen-
dencies for object features, positive opinions and 
negative opinions. Therefore, it is important to 
consider the syntactic structure in the review 
mining task. 
In this section, we propose to use Tree CRFs to
model the syntactic tree structure for review 
mining. The representation of a Tree CRFs is 
shown in Figure 2(c). The syntactic tree structure 
is encoded into our model representation. Each 
node is corresponding to a word in the depen-
dency tree. The edge is corresponding to depen-
dency tree edge. Tree CRFs can make use of de-
pendency relationship in syntactic tree structure
to boost the performance.
3.2.4 Integrating Conjunction Structure and 
Syntactic Tree Structure
Conjunction structure provides the semantic re-
lations correlated with conjunctions. Syntactic 
tree structure provides dependency relation in 
the syntactic tree. They represent different se-
mantic dependencies. It is interesting to consider 
these two dependencies in a unified model. We 
propose Skip-Tree CRFs, to combine these two 
structure information. The graphical representa-
tion of a Skip-Tree CRFs, given in Figure 2(d),
consists of two types of edges: tree edges and 
conjunction skip-edges. We hope to simulta-
neously model the dependency in conjunction 
structure and syntactic tree structure.
We also notice that there is a relationship 
?conj? in syntactic dependency tree. However, 
we find that it only connects two head words for 
a few coordinating conjunction, such as ?and", 
?or", ?but?. Our designed conjunction skip-edge
provides more information for joint structure 
tagging. We analyze more conjunctions to con-
nect not only two head words, but also the words 
with same part of speech. We also connect the 
words with sentiment lexicon. We will show that 
the skip-tree CRFs, which combine the two 
structures, is effective in the experiment section.
3.2.5 Conditional Random Fields
A CRFs is an undirected graphical model G of 
the conditional distribution (	|
). Y are the 
random variables over the labels of the nodes 
that are globally conditioned on X, which are the 
random variables of the observations. The condi-
tional probability is defined as: 
P
(
	 
|


)
=  
1
(
)
    



(, 	|, 
)
,
+   



(, 	|, 
)
