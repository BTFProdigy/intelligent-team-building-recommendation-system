Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 54?59,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Resolution of Referents Groupings in Practical Dialogues 
 
 
Alexandre Denis,  Guillaume Pitel,  Matthieu Quignard 
LORIA  
BP239 F-54206 Vandoeuvre-l?s-nancy, France 
denis@loria.fr,pitel@loria.fr,quignard@loria.fr 
 
  
Abstract 
This paper presents an extension to the 
Reference Domain Theory (Salmon-Alt, 
2001) in order to solve plural references. 
While this theory doesn?t take plural 
reference into account in its original 
form, this paper shows how several 
entities can be grouped together by 
building a new domain and how they can 
be accessed later on. We introduce the 
notion of super-domain, representing the 
access structure to all the plural referents 
of a given type. 
1 Introduction 
In the course of a discourse or a dialogue, 
referents introduced separately could be 
referenced with a single plural expression 
(pronoun, demonstratives, etc.). The grouping of 
these referents may depend on many factors: it 
may be explicit if they were syntactically 
coordinated or juxtaposed or implicit if they just 
share common semantic features (Eschenbach et 
al., 1989). Time is also an important factor while 
it may be difficult to group old mentioned 
referents with new ones. Because of this 
multiplicity of factors, choosing the right 
discursive grouping for a referential plural 
expression is ambiguous, and this ambiguity 
needs to be explicitly described.  
We present a model of grouping based on 
reference domains theory (Salmon-Alt, 2001) 
that considers that a reference operation consists 
of extracting a referent in a domain. However the 
original theory barely takes into account plural 
reference. This paper shows how several entities 
can be grouped together by building a new 
domain and how they can be accessed later on. It 
introduces also the notion of super-domain D+ 
that represents the access structure to all the 
plural referents of type D. This work is currently 
being implemented and evaluated in the MEDIA 
project of the EVALDA framework, a national 
french understanding evaluation campaign 
(Devillers, 2004). 
2 Groupings of Referents  
Several kinds of clues can specify that referents 
should be grouped together, or at least could be 
grouped together. These clues may occur at 
several language levels, from the noun phrase 
level to the rhetorical structure level. We have 
not explored in detail the different ways of 
groupings entities together in a discourse or 
dialogue. What is described here are just some of 
the phenomenon we got confronted with while 
developing a reference resolution module for a 
dialogue understanding system. 
 Explicit Coordination - The most basic 
way to explicitly express the grouping of two 
or more referents is using a connector such as 
and, or, as well as, etc.  
?Good afternoon, I would like to book a 
single room and a double room? 
 Implicit Sentential Coordination - An 
implicit coordination occurs when two or 
more referents of the same kind are present in 
one sentence, without explicit connector 
between them. ?Does the hotel de la gare 
have a restaurant, like the Holiday Inn?? 
 Implicit Discursive Coordination ? 
Such a coordination occurs when several 
reference are evoked in separate sentences. 
The grouping must be done based on 
rhetorical structuring. Here we consider short 
pieces of dialogue, admitting only one level 
of implicit discursive coordination.  ?I would 
like an hotel close to the sea... I also need an 
hotel downtown... And the hotels have to 
accept dogs.? 
54
 Repetitions/Specifications ? In some 
particular cases, groupings make explicit a 
previous expression. For instance ?Two 
rooms. A single room, a double room?. 
3 Reference Domain Theory 
We are willing to try a pragmatic approach to 
reference resolution in practical multimodal 
dialogues (Gieselman, 2004). For example we 
need to process frequent phenomena like 
ordinals for choosing in a list (discursive, or 
visual) or otherness when re-evoking old 
referents. Hence keeping the track of the way the 
context is modified when introducing a referent 
or referring, is mandatory. The Reference 
Domains Theory (Salmon-Alt, 2001) supposes 
that every act of reference is related to a certain 
domain of interpretation. It endorses the 
cognitive grammar concept of domain, defined  
as a cognitive structure presupposed by the 
semantics of the expression (Kumar et al, 2003).  
In other words, a referring expression has to be 
interpreted in a given domain, highlighting and 
specifying a particular referent in this domain. A 
reference domain is composed of a group of 
entities in the hearer?s memory which can be 
discursive referents, visual objects, or concepts. 
It describes how each entity could be addressed 
through a referential expression.  
This theory views the referring process as a 
dynamic extraction of a referent in a domain 
instead of a binding between two entities 
(Salmon-Alt, 2000). Hence doing a reference act 
consists in isolating a particular entity from other 
rejected candidates, amongst all the accessible 
entities composing the domain (Olson, 1970). 
This dynamic discrimination relies on projecting 
an access structure focusing the referent in the 
domain.  The domain then becomes salient for 
further interpretations. The preferences for 
choosing a suitable domain are inspired from the 
Relevance theory (Sperber & Wilson, 1986) 
taking into account such focalization and 
salience.  
Landragin & Romary (2003) have also studied 
the usage of reference domains in order to model 
a visual scene. The grouping factors for visual 
objects are those given by the Gestalt theory, 
proximity, similarity, and good continuation. 
Each perceptual groups or groups designated by 
a gesture could be the base domain for an 
extraction. Referential expressions work the 
same way either the domains are discursive, 
perceptual or gestural, they extract and highlight 
referents in these domains. See (Landragin et al, 
2001) for a review of perceptual groupings.  
4 Basic Type 
A referential domain is defined by:  
? a set of entities accessible through this 
domain (ground of domain), 
? a description subsuming the description 
of all these entities (type of domain), 
? a set of access structures to these 
entities. 
For instance: ?the Ibis hotel (h1) and the hotel 
Lafayette (h2)? forms a referential domain, 
whose type would be Hotel, and whose 
accessible entities would be h1 and h2, 
themselves defined as domains of type Hotel. 
These two hotels could be accessed later on by 
their names. 
4.1 Access structures 
We suppose that the distinction between the 
referents from the excluded alternatives requires 
highlighting a discrimination criterion opposing 
them. This criterion behaves like a partition of 
the accessible entities, grouping them together 
according to their similarities and their 
differences. A partition may have one of its parts 
focused. There are, at least, three kinds of 
discrimination criteria: 
? discrimination on description. Entities 
can be discriminated by their type, their 
properties, or by the relations they have with 
other entities. For example the name of the 
hotels is a discrimination criterion in ?the Ibis 
hotel and the hotel Lafayette?. 
? discrimination on focus. Entities can 
also be discriminated by the focus they have 
when they are mentioned in the discourse or 
designed by a gesture. For example, ?this 
room? would select a focused referent in a 
domain, whereas ?the other room? would 
select a non-focused one. 
? discrimination on time of occurrence. 
Entities can finally be discriminated by their 
occurrence in the discourse. For example ?the 
second hotel? would discriminate this hotel 
by its rank in the domain. 
4.2 Classical resolution algorithm 
Each activated domain belongs to list of domains 
ordered along their recentness (the referential 
55
space).  The resolution algorithm consists of two 
phases: 
1. Searching a suitable, preferred domain in 
the referential space when interpreting a 
referring expression. The suitability is 
defined by the minimal conditions the domain 
has to conform to in order to be the base of an 
interpretation (particular description, or 
presence of a particular access structure with 
focus or not). The main preference factor is 
the minimization of the access cost 
(recentness or salience), however other 
criteria like thematic structure could be taken 
into account and will be future work. Each 
domain is tested according to the constraints 
given by the referential expression. We allow 
several layers of constraints for each type of 
expression : if the stronger constraints are not 
met, then weaker constraints are tried. 
2. Extracting a referent and restructuring the 
referential space, taking into account this 
extraction. It not only focuses the referent in 
its domain, but also moves the domain itself 
to a more recent place. When one referent 
acquires the focus, the alternative  members 
of the same partition loose it. 
This generic scheme is instantiated for each type 
of access modes (a modality plus an expression). 
For example a definite ?the N? will search for a 
domain in which a particular entity of type ?N? 
can be discriminated, and the restructuring 
consists in focalizing in this domain the referent 
found. See (Landragin & Romary, 2003) for a 
description of the different access modes. 
The algorithm highlights the two types of 
ambiguities, domain or referent ambiguities, 
which occur when there is no preference 
available to make a choice between multiples 
entities in the first or the second phase. We guess 
that natural ambiguities should eventually be 
solved through the dialogue between the agents 
of the communication.  
5 Super-Domains 
In order to take groupings into account in the 
Reference Domains Theory, we introduce two 
constructs in our formal toolbox. Indeed, having 
only one kind of domain construct doesn?t allow 
for a correct distinction between different 
referent statuses.  
First we distinguish plural and simple domains. 
The simple domains D serve as bases for 
profiling, or highlighting, a subpart, or related 
part of a simple referent. For instance, if D = 
Room, then one can profile a Price from D. The 
plural domains D* serve as either as a generic 
base or as a plural representative for profiling 
a simple domain D. A generic base is mandatory 
in our model to support the insertion of new 
extra-linguistic referents evoked with an 
indefinite construct (for instance ?I saw a black 
bird on the roof?), while plural representatives 
are used for explicit groupings. A domain D*1 
can also be profiled from a D*0, provided D*1 
profiles a subset of the elements of D*0. 
Second, we introduce the notion of super-
domain D+, from which a D* can be profiled. 
The relations allowed between domains are  
represented on figure 1. A super-domain D+ is 
the domain of all groupings D*, including a 
special D*all grouping which is the representative 
of all evoked instances of a given category. This 
configuration is not intended to deal with long 
dialogues where several, trans-sentential 
groupings occur, and where older groupings may 
become out of access. Doing this would require 
a rhetorically driven structuring of the D*all.  
 
Figure 1: Access structure of Reference 
Domains 
 
As Reference Domain Theory is primarily 
targeted toward extra-linguistic referents 
occurring in practical dialogue, the construction 
of the domain trees, representing the supposed 
structuring of referents accessibility, is based on 
ontology. As a consequence, for each ?natural? 
type and each subtype (for instance 
Room?Single), a domain tree is potentially 
created (actually, one can easily imagine how 
this creation may be driven ?on-demand?). 
Another evolution from the initial Reference 
Domain Theory is the possibility to focalize 
several items of a partition. Indeed, since the 
resolution algorithm can focalize a whole plural 
domain, all elements of this domain must be 
focalized in all the plural domains they occur in. 
In order to refer to plural entities the idea is to 
build plural domains dynamically : when some 
sentence-level grouping, either implicit or 
explicit occurs or when a plural extra-linguistic 
referent is evoked, a D* is created and focussed 
D+ 
D* D D* 
D+ : super-domain 
D* : plural domain 
D  : simple domain 
 
        : gives access to 
56
in D+, with each of its components as children, 
when possible (that is, when each component is 
described). When new extra-linguistic referents 
(singular or plural) are evoked, they are 
individually profiled under the D*all 
corresponding to their types (that is, their 
?natural? type, and all the subtypes they are 
eligible to). 
In short, for all referents of type D: 
? they become subdomains of D*all 
? if they are plural referents, they also build 
up a focalized subdomain of D+
 
?
 all the referents of a given type are then 
grouped together under a new focalized 
subdomain of D+.  
  Figure 2 illustrates the state of the Hotel+ 
domain tree after a scenario with three dialogue 
acts, the first one introducing Hotel1, the second 
one inserting a grouping of Hotel2 and Hotel3. 
and the third one referring to it.  
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2: A domain tree built from a scenario 
above (focus in bold) 
The operations are the following : 
U1 : Hotel1 becomes a subdomain of Hotel*all 
which gains focus in Hotel+. 
S1 : Hotel2 and Hotel3 become subdomains of 
Hotel*all. In addition Hotel2 and Hotel3 are 
grouped in Hotel*1 which gains the focus in 
Hotel+ while Hotel*all loses it. 
U2 : The pronoun is solved in Hotel+, and Hotel*1 
is retrieved. 
One can see that Hotel*all is inaccessible by a  
generic expression like a demonstrative without 
modifiers but only by a special expression like 
"all the hotels". In our point of view, the reason 
is that the grouping Hotel*1 lowers the salience 
of Hotel*all. 
6 Implementation  
We used description logics for modelling 
domains and domain-reasoning. One has to deal 
with plural entities and can follow (Franconi, 93) 
by using collection theory, representing 
collections as individuals and membership by a 
role (plus plural quantifiers). But we should use 
another way considering that the inference 
engine we use, Racer (Haarslev and M?ller, 03), 
does not take into account ALCS. Hence we 
tried representing the domains by concepts, 
given their semantic are set of individuals. The 
domain D+ corresponds to the concept D, and 
the domain-subdomain relation is a 
subsumption. All basic manipulation with 
domains could be done using Tbox assertions. 
Additionnally, a partition structure is simply a 
sequence of subdomains which are different 
from each other (disjoint concepts) and whose 
elements could be focussed. The algorithm goes 
through the referential space and tests each 
domain in the recency order against the 
constraints given by the referential expression. 
Conceptual tests on the description and 
partitional tests on the focus or possible 
discriminations are made to retrieve the domain 
and the referent. If none are found, they may be 
created by accomodation. Groupings are created 
only for explicit coordinations, implicit 
sentential coordinations (two referents could be 
grouped if they have the same basic type) and 
some kind of specifications.  
Domains and groupings creation entails the 
creation of new concepts in the Tbox. Each 
concept insertion requires a costly 
reclassification, therefore we preferred an 
approximation considering only that new 
groupings assert primitive concepts. Other 
domains are concept terms i.e. descriptions 
which do not have to be asserted in the Tbox 
automatically. 
Implicit discursive groupings are not 
implemented considering the need of a rhetorical 
structure  (like in SDRT, Asher 93) or a mental 
space model. The following example shows the 
needs : 
 U1 : I would like an hotel (h1) 
 S1 : I propose you the hotel Ibis (h2) and 
 the Lafayette hotel (h3). 
Hotel h1 could very hardly be grouped with h2 
and h3, even by ?all these hotels? (or maybe by a 
third speaker). We guess among other factors 
that they belong to different levels of 
interpretation, h1 in the domain of the desires of 
Hotel+ 
Hotel*all Hotel*1 
Hotel1 Hotel2 Hotel3 
U1: The Ibis Hotel (Hotel1) is too expensive 
S1: Maybe the Hotel Lafayette (Hotel2) or 
the Hotel de la cloche (Hotel3) 
U2: Those hotels are too far from the airport. 
 
57
the user, and the others in the domain of existing 
hotels. The link between the two domains is 
possible if one knows that S1 is an answer of to 
U's request. Such discrimination criterion and 
high level domains are not yet implemented. 
Instead we concentrated on extra-linguistic 
referents which are assumed to be interpreted in 
the real/system world (like hotels, rooms). We 
are currently testing the approach to see if it 
could be extended to any type of entities 
provided accurate discrimination criteria (like 
the predication). 
7 Example 
A sample dialogue (table 1) is analyzed through 
the preceding algorithm. This example shows 
how the referents introduced in an explicit 
coordination could be referenced as a whole ?the 
two hotels?, or extracted discriminately by an 
ordinal ?the second one? or by an otherness 
expression ?the other one?. All the subdomains 
of H+ (i.e. the plural domains of hotels) are 
indicated after each interpretation using a 
simplified notation. Only the ordered list of 
accessible entities and their focalization (bold) 
are noted for each subdomain. For instance 
H*all= (h1, h2, h3) means that the domain H*all is 
focalized in H+, and that h3 is focalized in H*all. 
Table 1: Example of dialogue (focus in bold) 
 
In order to interpret U1, U2 or U3 one needs to 
rely on the previous structuring of H+. In U1, the 
previously focalized domain H*1 is preferred to 
be the base for interpreting ?the second one? 
because of the order discrimination. This leads 
to extracting h1 hence focalizing it in H*1 but 
also in H*0 and in H*all. In U2, H*1 cannot be the 
base for interpreting ?the third one? because no 
entity could be discriminate this way. Therefore 
the only suitable domain is H*all. It is also 
impossible to interpret U3 : ?the other one? in 
H*1 because of the lack of a focus discrimination 
between h1 and h2.  
It is however possible to choose H*all for the 
domain of interpretation: the excluded referents 
h1 and h2 are unfocused while h3 gains focus. 
 
8 Evaluation in progress 
This work is currently being evaluated in the 
MEDIA/EVALDA framework, a national 
understanding evaluation campaign. (Devillers et 
al., 04). It aims to evaluate the semantic and 
referential abilities of systems with various 
approaches of natural language processing. The 
results of each system are compared to manually 
annotated utterances transcribed from a Woz 
corpus in a hotel reservation task. For the 
referential facet, referential expressions 
(excluding indefinites, and proper names) are 
annotated by a semantic description of their 
referents. 
Our system which relies on a symbolic approach 
using deep parsing and description logics for 
semantic currently scores 64% (f-measure) for 
identifying and describing accurately the 
referents. We guess that such evaluation will be 
an occasion for us to test different hypothesis on  
reference resolution using domains (for exemple 
different criteria for grouping). However we do 
not have yet more precise results on plurals and 
ordinals specifically.  
9 Conclusion 
The extension we made to the Reference 
Domains Theory is still limited because it 
considers only extra-linguistic referents, i.e. 
those also having an existence outside discourse. 
In addition the trans-sentential groupings are not 
fully studied yet. We guess that such groupings 
should need a rhetorical description of the 
discourse or dialogue. In spite of its limits, the 
extension can render dynamic effects allowing 
ordinals and otherness in plural contexts. An 
Dialogue H+ 
U: Is there a bathroom at 
the Ibis hotel (h1) and the 
hotel Lafayette (h2)? 
H*0 = (h1, h2) 
H*all = (h1, h2) 
S: No they don't have 
bathrooms 
H*0 = (h1, h2) 
H*all = (h1, h2) 
S: But I propose you the 
Campanile hotel (h3) 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
U: Hmm no, how much 
were the two hotels? 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
S: The hotel Lafayette is 
100 euros, the Ibis hotel is 
75 euros 
H*1 = (h2, h1) 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
U1: Ok, I take the second 
one 
H*1 = (h2, h1) 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
U2: Ok, I take the third 
one 
U3 : and the other one ? 
H*1 = (h2, h1) 
H*0 = (h1, h2) 
H*all = (h1, h2, h3) 
58
implementation in description logics is  currently 
being evaluated in the MEDIA/EVALDA 
framework. 
References 
Nicholas Asher. 1993. Reference to Abstract Objects   
in English: A Philosophical Semantics for Natural 
Language Metaphysics. In Studies in Linguistics 
and Philosophy, Kluwer, Dordrecht. 
Laurence Devillers, H?l?ne Maynard, St?phanie 
Rosset, Patrice Paroubek, Kevin McTait, Djamel 
Mostefa, Khalid Choukri, Caroline Bousquet, 
Laurent Charnay, Nadine Vigouroux, Fr?d?ric 
B?chet, Laurent Romary, Jean-Yves Antoine, 
Jeanne Villaneau, Myriam Vergnes, and J?r?me 
Goulian. 2004. The French MEDIA/EVALDA 
Project : the Evaluation of the Understanding 
Capability of Spoken Language Dialog System. In 
Proceedings of LREC 2004, Lisbon, Portugal. 
Carola Eschenbach, Christopher Habel, Michael 
Herweg, Klaus Rehk?mper. 1989. Remarks on 
plural anaphora. In Proc. Fourth Conference of the 
European Chapter of the Association for 
Computational Linguistics. 
Enrico Franconi. 1993. A treatment of plurals and 
plural quantifications based on a theory of 
collections. Minds and Machines (3)4:453-474, 
Kluwer Academic Publishers, November 1993 
Petra Gieselmann: 2004. Reference Resolution 
Mechanisms in Dialogue Management. In: 
Proceedings of the Eighth Workshop on the 
Semantics and Pragmatics of Dialogue 
(CATALOG), Barcelona, 2004. 
Volker Haarslev, and Ralf M?ller. 2003. Racer: A 
Core Inference Engine for the Semantic Web. In 
Proceedings of the 2nd International Workshop on 
Evaluation of Ontology-based Tools (EON2003), 
located at the 2nd International Semantic Web 
Conference ISWC 2003, Sanibel Island, Florida, 
USA, October 20, 2003, pp. 27-36. 
Ashwani Kumar, Susanne Salmon-Alt, and Laurent 
Romary. 2003. Reference resolution as a 
facilitating process towards robust multimodal 
dialogue management: A cognitive grammar 
approach. In International Symposium on 
Reference Resolution and Its Application to 
Question Answering and Summarization. 
Fr?d?ric Landragin, and Laurent Romary. 2003. 
Referring to Objects Through Sub-Contexts in 
Multimodal Human-Computer Interaction. In Proc. 
Seventh Workshop on the Semantics and 
Pragmatics of Dialogue (DiaBruck'03), 
Saarbr?cken, Germany, 2003, pp. 67-74. 
Fr?d?ric Landragin, Nadia Bellalem and Laurent 
Romary. 2001. Visual Salience and Perceptual 
Grouping in Multimodal Interactivity. In: First 
International Workshop on Information 
Presentation and Natural Multimodal Dialogue, 
Verona, Italy, 2001 
David R. Olson. 1970. Language and Thought: 
Aspects of a Cognitive Theory of Semantics. 
Psychological Review, 77/4, 257-273. 
Susanne Salmon-alt. 2000. Interpreting referring 
expressions by restructuring context. Proc. ESSLLI 
2000, Student Session, Birmingham, UK, August 
2000. 
Susanne Salmon-Alt. 2001. Reference Resolution 
within the Framework of Cognitive Grammar. 
Proc. International Colloquium on Cognitive 
Science, San Sebastian, Spain 
Dan Sperber and Deirdre Wilson. 1986. Relevance, 
Communication and Cognition. Basil Blackwell, 
Oxford. 
59
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 62?67,
Portland, Oregon, USA, 21 June 2011. c?2011 Association for Computational Linguistics
Prototyping virtual instructors from human-human corpora
Luciana Benotti
PLN Group, FAMAF
National University of Co?rdoba
Co?rdoba, Argentina
luciana.benotti@gmail.com
Alexandre Denis
TALARIS team, LORIA/CNRS
Lorraine. Campus scientifique, BP 239
Vandoeuvre-le`s-Nancy, France
alexandre.denis@loria.fr
Abstract
Virtual instructors can be used in several ap-
plications, ranging from trainers in simulated
worlds to non player characters for virtual
games. In this paper we present a novel
algorithm for rapidly prototyping virtual in-
structors from human-human corpora without
manual annotation. Automatically prototyp-
ing full-fledged dialogue systems from cor-
pora is far from being a reality nowadays. Our
algorithm is restricted in that only the virtual
instructor can perform speech acts while the
user responses are limited to physical actions
in the virtual world. We evaluate a virtual in-
structor, generated using this algorithm, with
human users. We compare our results both
with human instructors and rule-based virtual
instructors hand-coded for the same task.
1 Introduction
Virtual human characters constitute a promising
contribution to many fields, including simulation,
training and interactive games (Kenny et al, 2007;
Jan et al, 2009). The ability to communicate using
natural language is important for believable and ef-
fective virtual humans. Such ability has to be good
enough to engage the trainee or the gamer in the ac-
tivity. Nowadays, most conversational systems oper-
ate on a dialogue-act level and require extensive an-
notation efforts in order to be fit for their task (Rieser
and Lemon, 2010). Semantic annotation and rule
authoring have long been known as bottlenecks for
developing conversational systems for new domains.
In this paper, we present novel a algorithm for
generating virtual instructors from automatically an-
notated human-human corpora. Our algorithm,
when given a task-based corpus situated in a virtual
world, generates an instructor that robustly helps a
user achieve a given task in the virtual world of the
corpus. There are two main approaches toward au-
tomatically producing dialogue utterances. One is
the selection approach, in which the task is to pick
the appropriate output from a corpus of possible out-
puts. The other is the generation approach, in which
the output is dynamically assembled using some
composition procedure, e.g. grammar rules. The se-
lection approach to generation has only been used
in conversational systems that are not task-oriented
such as negotiating agents (Gandhe and Traum,
2007), question answering characters (Kenny et al,
2007), and virtual patients (Leuski et al, 2006). Our
algorithm can be seen as a novel way of doing robust
generation by selection and interaction management
for task-oriented systems.
In the next section we introduce the corpora used
in this paper. Section 3 presents the two phases of
our algorithm, namely automatic annotation and di-
alogue management through selection. In Section 4
we present a fragment of an interaction with a vir-
tual instructor generated using the corpus and the
algorithm introduced in the previous sections. We
evaluate the virtual instructor in interactions with
human subjects using objective as well as subjec-
tive metrics. We present the results of the evaluation
in Section 5. We compare our results with both hu-
man and rule-based virtual instructors hand-coded
for the same task. Finally, Section 6 concludes the
paper proposing an improved virtual instructor de-
signed as a result of our error analysis.
62
2 The GIVE corpus
The Challenge on Generating Instructions in Vir-
tual Environments (GIVE; Koller et al (2010)) is
a shared task in which Natural Language Gener-
ation systems must generate real-time instructions
that guide a user in a virtual world. In this paper, we
use the GIVE-2 Corpus (Gargett et al, 2010), a cor-
pus of human instruction giving in virtual environ-
ments. We use the English part of the corpus which
consists of 63 American English written discourses
in which one subject guided another in a treasure
hunting task in 3 different 3D worlds.
The task setup involved pairs of human partners,
each of whom played one of two different roles. The
?direction follower? (DF) moved about in the vir-
tual world with the goal of completing a treasure
hunting task, but had no knowledge of the map of
the world or the specific behavior of objects within
that world (such as, which buttons to press to open
doors). The other partner acted as the ?direction
giver? (DG), who was given complete knowledge of
the world and had to give instructions to the DF to
guide him/her to accomplish the task.
The GIVE-2 corpus is a multimodal corpus which
consists of all the instructions uttered by the DG, and
all the object manipulations done by the DF with the
corresponding timestamp. Furthermore, the DF?s
position and orientation is logged every 200 mil-
liseconds, making it possible to extract information
about his/her movements.
3 The unsupervised conversational model
Our algorithm consists of two phases: an annotation
phase and a selection phase. The annotation phase
is performed only once and consists of automatically
associating the DG instruction to the DF reaction.
The selection phase is performed every time the vir-
tual instructor generates an instruction and consists
of picking out from the annotated corpus the most
appropriate instruction at a given point.
3.1 The automatic annotation
The basic idea of the annotation is straightforward:
associate each utterance with its corresponding re-
action. We assume that a reaction captures the se-
mantics of its associated instruction. Defining re-
action involves two subtle issues, namely boundary
determination and discretization. We discuss these
issues in turn and then give a formal definition of
reaction.
We define the boundaries of a reaction as follows.
A reaction rk to an instruction uk begins right af-
ter the instruction uk is uttered and ends right before
the next instruction uk+1 is uttered. In the follow-
ing example, instruction 1 corresponds to the reac-
tion ?2, 3, 4?, instruction 5 corresponds to ?6?, and
instruction 7 to ?8?.
DG(1): hit the red you see in the far room
DF(2): [enters the far room]
DF(3): [pushes the red button]
DF(4): [turns right]
DG(5): hit far side green
DF(6): [moves next to the wrong green]
DG(7): no
DF(8): [moves to the right green and pushes it]
As the example shows, our definition of bound-
aries is not always semantically correct. For in-
stance, it can be argued that it includes too much
because 4 is not strictly part of the semantics of 1.
Furthermore, misinterpreted instructions (as 5) and
corrections (e.g., 7) result in clearly inappropriate
instruction-reaction associations. Since we want to
avoid any manual annotation, we decided to use this
naive definition of boundaries anyway. We discuss
in Section 5 the impact that inappropriate associa-
tions have on the performance of a virtual instructor.
The second issue that we address here is dis-
cretization of the reaction. It is well known that there
is not a unique way to discretize an action into sub-
actions. For example, we could decompose action 2
into ?enter the room? or into ?get close to the door
and pass the door?. Our algorithm is not dependent
on a particular discretization. However, the same
discretization mechanism used for annotation has to
be used during selection, for the dialogue manager
to work properly. For selection (i.e., in order to de-
cide what to say next) any virtual instructor needs
to have a planner and a planning domain represen-
tation, i.e., a specification of how the virtual world
works and a way to represent the state of the virtual
world. Therefore, we decided to use them in order
to discretize the reaction.
Now we are ready to define reaction formally. Let
Sk be the state of the virtual world when uttering in-
63
struction uk, Sk+1 be the state of the world when
uttering the next utterance uk+1 and D be the plan-
ning domain representation. The reaction to uk is
defined as the sequence of actions returned by the
planner with Sk as initial state, Sk+1 as goal state
and D as planning domain.
The annotation of the corpus then consists of au-
tomatically associating each utterance to its (dis-
cretized) reaction.
3.2 Selecting what to say next
In this section we describe how the selection phase is
performed every time the virtual instructor generates
an instruction.
The instruction selection algorithm consists in
finding in the corpus the set of candidate utterances
C for the current task plan P ; P being the se-
quence of actions returned by the same planner and
planning domain used for discretization. We define
C = {U ? Corpus | U.Reaction is a prefix of P}.
In other words, an utterance U belongs to C if the
first actions of the current plan P exactly match the
reaction associated to the utterance. All the utter-
ances that pass this test are considered paraphrases
and hence suitable in the current context.
While P does not change, the virtual instructor
iterates through the set C, verbalizing a different ut-
terance at fixed time intervals (e.g., every 3 seconds).
In other words, the virtual instructor offers alterna-
tive paraphrases of the intended instruction. When
P changes as a result of the actions of the DF, C is
recalculated.
It is important to notice that the discretization
used for annotation and selection directly impacts
the behavior of the virtual instructor. It is crucial
then to find an appropriate granularity of the dis-
cretization. If the granularity is too coarse, many
instructions in the corpus will have an empty asso-
ciated reaction. For instance, in the absence of the
representation of the user orientation in the planning
domain (as is the case for the virtual instructor we
evaluate in Section 5), instructions like ?turn left?
and ?turn right? will have empty reactions making
them indistinguishable during selection. However,
if the granularity is too fine the user may get into sit-
uations that do not occur in the corpus, causing the
selection algorithm to return an empty set of candi-
date utterances. It is the responsibility of the virtual
instructor developer to find a granularity sufficient
to capture the diversity of the instructions he wants
to distinguish during selection.
4 A virtual instructor for a virtual world
We implemented an English virtual instructor for
one of the worlds used in the corpus collection we
presented in Section 2. The English fragment of the
corpus that we used has 21 interactions and a total
of 1136 instructions. Games consisted on average
of 54.2 instructions from the human DG, and took
about 543 seconds on average for the human DF to
complete the task.
On Figures 1 to 4 we show an excerpt of an in-
teraction between the system and a real user that we
collected during the evaluation. The figures show a
2D map from top view and the 3D in-game view. In
Figure 1, the user, represented by a blue character,
has just entered the upper left room. He has to push
the button close to the chair. The first candidate ut-
terance selected is ?red closest to the chair in front of
you?. Notice that the referring expression uniquely
identifies the target object using the spatial proxim-
ity of the target to the chair. This referring expres-
sion is generated without any reasoning on the tar-
get distractors, just by considering the current state
of the task plan and the user position.
Figure 1: ?red closest to the chair in front of you?
After receiving the instruction the user gets closer
to the button as shown in Figure 2. As a result of the
new user position, a new task plan exists, the set of
candidate utterances is recalculated and the system
selects a new utterance, namely ?the closet one?.
The generation of the ellipsis of the button or the
64
Figure 2: ?the closet one?
Figure 3: ?good?
Figure 4: ?exit the way you entered?
chair is a direct consequence of the utterances nor-
mally said in the corpus at this stage of the task plan
(that is, when the user is about to manipulate this ob-
ject). From the point of view of referring expression
algorithms, the referring expression may not be op-
timal because it is over-specified (a pronoun would
be preferred as in ?click it?), Furthermore, the in-
struction contains a spelling error (?closet? instead
of ?closest?). In spite of this non optimality, the in-
struction led our user to execute the intended reac-
tion, namely pushing the button.
Right after the user clicks on the button (Figure 3),
the system selects an utterance corresponding to the
new task plan. The player position stayed the same
so the only change in the plan is that the button no
longer needs to be pushed. In this task state, DGs
usually give acknowledgements and this then what
our selection algorithm selects: ?good?.
After receiving the acknowledgement, the user
turns around and walks forward, and the next action
in the plan is to leave the room (Figure 4). The sys-
tem selects the utterance ?exit the way you entered?
which refers to the previous interaction. Again, the
system keeps no representation of the past actions
of the user, but such utterances are the ones that are
found at this stage of the task plan.
5 Evaluation and error analysis
In this section we present the results of the evalu-
ation we carried out on the virtual instructor pre-
sented in Section 4 which was generated using the
dialogue model algorithm introduced in Section 3.
We collected data from 13 subjects. The partici-
pants were mostly graduate students; 7 female and
6 male. They were not English native speakers but
rated their English skills as near-native or very good.
The evaluation contains both objective measures
which we discuss in Section 5.1 and subjective mea-
sures which we discuss in Section 5.2.
5.1 Objective metrics
The objective metrics we extracted from the logs of
interaction are summarized in Table 1. The table
compares our results with both human instructors
and the three rule-based virtual instructors that were
top rated in the GIVE-2 Challenge. Their results cor-
respond to those published in (Koller et al, 2010)
which were collected not in a laboratory but con-
necting the systems to users over the Internet. These
hand-coded systems are called NA, NM and Saar.
We refer to our system as OUR.
65
Human NA Saar NM OUR
Task success 100% 47% 40% 30% 70%
Canceled 0% 24% n/a 35% 7%
Lost 0% 29% n/a 35% 23%
Time (sec) 543 344 467 435 692
Mouse actions 12 17 17 18 14
Utterances 53 224 244 244 194
Table 1: Results for the objective metrics
In the table we show the percentage of games that
users completed successfully with the different in-
structors. Unsuccessful games can be either can-
celed or lost. To ensure comparability, time until
task completion, number of instructions received by
users, and mouse actions are only counted on suc-
cessfully completed games.
In terms of task success, our system performs bet-
ter than all hand-coded systems. We duly notice that,
for the GIVE Challenge in particular (and proba-
bly for human evaluations in general) the success
rates in the laboratory tend to be higher than the suc-
cess rate online (this is also the case for completion
times) (Koller et al, 2009).
In any case, our results are preliminary given the
amount of subjects that we tested (13 versus around
290 for GIVE-2), but they are indeed encouraging.
In particular, our system helped users to identify bet-
ter the objects that they needed to manipulate in the
virtual world, as shown by the low number of mouse
actions required to complete the task (a high number
indicates that the user must have manipulated wrong
objects). This correlates with the subjective evalu-
ation of referring expression quality (see next sec-
tion).
We performed a detailed analysis of the instruc-
tions uttered by our system that were unsuccessful,
that is, all the instructions that did not cause the in-
tended reaction as annotated in the corpus. From the
2081 instructions uttered in the 13 interactions, 1304
(63%) of them were successful and 777 (37%) were
unsuccessful.
Given the limitations of the annotation discussed
in Section 3.1 (wrong annotation of correction ut-
terances and no representation of user orientation)
we classified the unsuccessful utterances using lexi-
cal cues into 1) correction (?no?,?don?t?,?keep?, etc.),
2) orientation instruction (?left?, ?straight?, ?behind?,
etc.) and 3) other. We found that 25% of the unsuc-
cessful utterances are of type 1, 40% are type 2, 34%
are type 3 (1% corresponds to the default utterance
?go? that our system utters when the set of candidate
utterances is empty). Frequently, these errors led to
contradictions confusing the player and significantly
affecting the completion time of the task as shown in
Table 1. In Section 6 we propose an improved virtual
instructor designed as a result of this error analysis.
5.2 Subjective metrics
The subjective measures were obtained from re-
sponses to the GIVE-2 questionnaire that was pre-
sented to users after each game. It asked users to rate
different statements about the system using a contin-
uous slider. The slider position was translated to a
number between -100 and 100. As done in GIVE-
2, for negative statements, we report the reversed
scores, so that in Tables 2 and 3 greater numbers
are always better. In this section we compare our re-
sults with the systems NA, Saar and NM as we did
in Section 5.1, we cannot compare against human in-
structors because these subjective metrics were not
collected in (Gargett et al, 2010).
The GIVE-2 Challenge questionnaire includes
twenty-two subjective metrics. Metrics Q1 to Q13
and Q22 assess the effectiveness and reliability of
instructions. For almost all of these metrics we got
similar or slightly lower results than those obtained
by the three hand-coded systems, except for three
metrics which we show in Table 2. We suspect that
the low results obtained for Q5 and Q22 relate to
the unsuccessful utterances identified and discussed
in Section 5.1. The high unexpected result in Q6 is
probably correlated with the low number of mouse
actions mentioned in Section 5.1.
NA Saar NM OUR
Q5: I was confused about which direction to go in
29 5 9 -12
Q6: I had no difficulty with identifying the objects the
system described for me
18 20 13 40
Q22: I felt I could trust the system?s instructions
37 21 23 0
Table 2: Results for the subjective measures assessing the
efficiency and effectiveness of the instructions
Metrics Q14 to Q20 are intended to assess the nat-
66
uralness of the instructions, as well as the immer-
sion and engagement of the interaction. As Table 3
shows, in spite of the unsuccessful utterances, our
system is rated as more natural and more engaging
(in general) than the best systems that competed in
the GIVE-2 Challenge.
NA Saar NM OUR
Q14: The system?s instructions sounded robotic
-4 5 -1 28
Q15: The system?s instructions were repetitive
-31 -26 -28 -8
Q16: I really wanted to find that trophy
-11 -7 -8 7
Q17: I lost track of time while solving the task
-16 -11 -18 16
Q18: I enjoyed solving the task
-8 -5 -4 4
Q19: Interacting with the system was really annoying
8 -2 -2 4
Q20: I would recommend this game to a friend
-30 -25 -24 -28
Table 3: Results for the subjective measures assessing the
naturalness and engagement of the instructions
6 Conclusions and future work
In this paper we presented a novel algorithm for
rapidly prototyping virtual instructors from human-
human corpora without manual annotation. Using
our algorithm and the GIVE corpus we have gener-
ated a virtual instructor1 for a game-like virtual en-
vironment. We obtained encouraging results in the
evaluation with human users that we did on the vir-
tual instructor. Our system outperforms rule-based
virtual instructors hand-coded for the same task both
in terms of objective and subjective metrics. It is
important to mention that the GIVE-2 hand-coded
systems do not need a corpus but are tightly linked
to the GIVE task. Our algorithm requires human-
human corpora collected on the target task and en-
vironment, but it is independent of the particular in-
struction giving task. For instance, it could be used
for implementing game tutorials, real world naviga-
tion systems or task-based language teaching.
In the near future we plan to build a new version
of the system that improves based on the error anal-
ysis that we did. For instance, we plan to change
1Demo at cs.famaf.unc.edu.ar/?luciana/give-OUR
our discretization mechanism in order to take orien-
tation into account. This is supported by our algo-
rithm although we may need to enlarge the corpus
we used so as not to increase the number of situa-
tions in which the system does not find anything to
say. Finally, if we could identify corrections auto-
matically, as suggested in (Raux and Nakano, 2010),
we could get another increase in performance, be-
cause we would be able to treat them as corrections
and not as instructions as we do now.
In sum, this paper presents a novel way of au-
tomatically prototyping task-oriented virtual agents
from corpora who are able to effectively and natu-
rally help a user complete a task in a virtual world.
References
Sudeep Gandhe and David Traum. 2007. Creating spo-
ken dialogue characters from corpora without annota-
tions. In Proceedings of Interspeech, Belgium.
Andrew Gargett, Konstantina Garoufi, Alexander Koller,
and Kristina Striegnitz. 2010. The GIVE-2 corpus of
giving instructions in virtual environments. In Proc. of
the LREC, Malta.
Dusan Jan, Antonio Roque, Anton Leuski, Jacki Morie,
and David Traum. 2009. A virtual tour guide for
virtual worlds. In Proc. of IVA, pages 372?378, The
Netherlands. Springer-Verlag.
Patrick Kenny, Thomas D. Parsons, Jonathan Gratch, An-
ton Leuski, and Albert A. Rizzo. 2007. Virtual pa-
tients for clinical therapist skills training. In Proc. of
IVA, pages 197?210, France. Springer-Verlag.
Alexander Koller, Kristina Striegnitz, Donna Byron, Jus-
tine Cassell, Robert Dale, Sara Dalzel-Job, Johanna
Moore, and Jon Oberlander. 2009. Validating the
web-based evaluation of nlg systems. In Proc. of ACL-
IJCNLP, Singapore.
Alexander Koller, Kristina Striegnitz, Andrew Gargett,
Donna Byron, Justine Cassell, Robert Dale, Johanna
Moore, and Jon Oberlander. 2010. Report on the sec-
ond challenge on generating instructions in virtual en-
vironments (GIVE-2). In Proc. of INLG, Dublin.
Anton Leuski, Ronakkumar Patel, David Traum, and
Brandon Kennedy. 2006. Building effective question
answering characters. In Proc. of SIGDIAL, pages 18?
27, Australia. ACL.
Antoine Raux and Mikio Nakano. 2010. The dynamics
of action corrections in situated interaction. In Proc.
of SIGDIAL, pages 165?174, Japan. ACL.
Verena Rieser and Oliver Lemon. 2010. Learning hu-
man multimodal dialogue strategies. Natural Lan-
guage Engineering, 16:3?23.
67
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 605?609,
Dublin, Ireland, August 23-24, 2014.
Synalp-Empathic: A Valence Shifting Hybrid System for Sentiment
Analysis
Alexandre Denis, Samuel Cruz-Lara, Nadia Bellalem and Lotfi Bellalem
LORIA/University of Lorraine
Nancy, France
{alexandre.denis, samuel.cruz-lara, nadia.bellalem, lotfi.bellalem}@loria.fr
Abstract
This paper describes the Synalp-Empathic
system that competed in SemEval-2014
Task 9B Sentiment Analysis in Twitter.
Our system combines syntactic-based va-
lence shifting rules with a supervised
learning algorithm (Sequential Minimal
Optimization). We present the system, its
features and evaluate their impact. We
show that both the valence shifting mech-
anism and the supervised model enable to
reach good results.
1 Introduction
Sentiment Analysis (SA) is the determination of
the polarity of a piece of text (positive, nega-
tive, neutral). It is not an easy task, as proven
by the moderate agreement between human an-
notators when facing this task. Their agreement
varies whether considering document or sentence
level sentiment analysis, and different domains
may show different agreements as well (Berming-
ham and Smeaton, 2009).
As difficult the task is for human beings, it is
even more difficult for machines which face syn-
tactic, semantic or pragmatic difficulties. Consider
for instance irrealis phenomena such as ?if this is
good? or ?it would be good if ? that are both neu-
tral. Irrealis is also present in questions (?is this
good??) but presupposition of existence does mat-
ter: ?can you fix this terrible printer?? would be
polarized while ?can you give me a good advice??
would not. Negation and irrealis interact as well,
compare for instance ?this could be good? (neutral
or slightly positive) and ?this could not be good?
(clearly negative). Other difficult phenomena in-
clude semantic or pragmatic effects, such as point
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
of view (?Israel failed to defeat Hezbollah?, nega-
tive for Israel, positive for Hezbollah), background
knowledge (?this car uses a lot of gas?), seman-
tic polysemy (?this vacuum cleaner sucks? vs ?this
movie sucks?), etc.
From the start, machine learning has been the
widely dominant approach to sentiment analy-
sis since it tries to capture these phenomena all-
together (Liu, 2012). Starting from simple n-
grams (Pang et al., 2002), more recent approaches
tend to include syntactic contexts (Socher et al.,
2011). However these supervised approaches
all require a training corpus. Unsupervised ap-
proaches such as the seminal paper of (Turney,
2002) require training corpus as well but do not
require annotations. We propose in this paper to
look first at approaches that do not require any
corpus because annotating a corpus is in general
costly, especially in sentiment analysis in which
several annotators are required to maintain a high
level of agreement
1
. Nevertheless supervised ma-
chine learning can be useful to adapt the system
to a particular domain and we will consider it as
well.
Hence, we propose in this paper to first consider
a domain independent sentiment analysis tool that
does not require any training corpus (section 2).
Once the performance of this tool is assessed (sec-
tion 2.4) we propose to consider how the system
can be extended with machine learning in sec-
tion 3. We show the results on the SemEval 2013
and 2014 corpora in section 4.
2 Sentiment Analysis without Corpus
We present here a system that does sentiment anal-
ysis without requiring a training corpus. We do so
in three steps: we first present a raw lexical base-
line that naively considers average valence taking
the prior valence of words from polarity lexicons.
1
as done in SemEval2013 SA task (Nakov et al., 2013)
605
We then show how to adapt this baseline to the
Twitter domain. Finally, we describe a method
wich takes into account the syntactic context of
polarized words. All methods and strategies are
then evaluated.
2.1 Raw Lexical Baseline
The raw lexical baseline is a simple system that
only relies on polarity lexicons and takes the aver-
age valence of all the words. The valence is mod-
eled using a continuous value in [0, 1], 0.5 being
neutral. The algorithm is as follows:
1. perform part of speech tagging of the input
text using the Stanford CoreNLP tool suite,
2. for all words in the input text, retrieve their
polarity from the lexicons using lemma and
part of speech information. If the word is
found in several lexicons, return the average
of the found polarities. Otherwise if the word
is not found, return 0.5.
3. then for the tweet, simply compute the aver-
age valence among all words.
We tried several lexicons but ended with fo-
cusing on the Liu?s lexicon (Hu and Liu, 2004)
which proved to offer the best results. However
Liu?s lexicon is missing slang or bad words. We
therefore extended the lexicon using the onlines-
langdictionary.com website which provides a list
of slang words expressing either positive or neg-
ative properties. We extracted around 100 words
from this lexicon which we call urban lexicon.
2.2 Twitter Adaptations
From this lexical base we considered several small
improvements to adapt to the Twitter material. We
first observed that the Stanford part of speech tag-
ger had a tendency to mistag the first position
in the sentence as proper noun. Since in tweets
this position is often in fact a common noun, we
systematically retagged these words as common
nouns. Second, we used a set of 150 hand writ-
ten rules designed to handle chat colloquialism
i.e., abbreviations (?wtf ?? ?what the f***?, twit-
ter specific expressions (?mistweet? ? ?regretted
tweet?), missing apostrophe (?isnt? ? ?isn?t?),
and smileys. Third, we applied hashtag splitting
(e.g. ?#ihatemondays?? ?i hate mondays?). Fi-
nally we refined the lexicon lookup strategy to
handle discrepancies between lexicon and part of
speech tagger. For instance, while the part of
speech tagger may tag stabbed as an adjective with
lemma stabbed, the lexicon might list it as a verb
with lemma stab. To improve robustness we there-
fore look first for the inflected form then for the
lemma.
2.3 Syntactic Enhancements
Valence Shifting Valence shifting refers to the
differential between the prior polarity of a word
(polarity from lexicons) and its contextual po-
larity (Polanyi and Zaenen, 2006). Follow-
ing (Moilanen and Pulman, 2007), we apply polar-
ity rewriting rules over the parsing structure. How-
ever we differ from them in that we consider de-
pendency rather than phrase structure trees.
The algorithm is as follows:
1. perform dependency parsing of the text (with
Stanford CoreNLP)
2. annotate each word with its prior polarity as
found in polarity lexicons
3. rewrite prior polarities using dependency
matching, hand-crafted rules
4. return the root polarity
Table 1 shows example rules. Each rule is com-
posed of a matching part and a rewriting part. Both
parts have the form (N,L
G
, P
G
, L
D
, P
D
) where
N is the dependency name, L
G
and L
D
are re-
spectively the lemmas of the governor and de-
pendent words, P
G
and P
D
are the polarity of
the governor and dependent words. We write the
rules in short form by prefixing them with the
name of the dependency and either the lemma or
the polarity for the arguments, e.g. N(P
G
, P
D
).
For instance, the inversion rule ?neg(P
G
, P
D
) ?
neg(!P
G
, P
D
)? inverts the polarity of the gover-
nor P
G
for dependencies named neg. One impor-
tant rule is the propagation rule ?N (0.5, P
D
) ?
N (P
D
,P
D
)? which propagates the polarity of the
dependent word P
D
to the governor only if it is
neutral. Another useful rule is the overwrite rule
?amod(1,0)? amod(0,0)? which erases for amod
dependencies, the positive polarity of the governor
given a negative modifier.
The main algorithm for rule application consists
in testing all rules (in a fixed order) on all de-
pendencies iteratively. Whenever a rule fires, the
whole set of rules is tested again. Potential looping
606
Rule Example
neg(P
G
, P
D
) ? neg(!P
G
, P
D
) he?s not happy
det(P
G
, ?no?) ? det(!P
G
,?no?) there is no hate
amod(1,0) ? amod(0,0) a missed opportunity
nsubj(0,1) ? nsubj(0,0) my dreams are crushed
nsubj(1,0) ? nsubj(1,1) my problem is fixed
N (0.5, P
D
) ? N (P
D
,P
D
) (propagation)
Table 1: Excerpt of valence shifting rules.
is prevented because (i) the dependency graph re-
turned by the Stanford Parser is a directed acyclic
graph (de Marneffe and Manning, 2008) and (ii)
the same rule cannot apply twice to the same de-
pendency.
For instance, in the sentence ?I do not think it
is a missed opportunity?, the verb ?missed? has
negative polarity and the noun ?opportunity? has
positive polarity. The graph in Figure 1 shows dif-
ferent rules application: first the overwrite rule (1.)
changes the positive polarity of ?opportunity? to a
negative polarity which is then transferred to the
main verb ?think? thanks to the propagation rule
(2.). Finally, the inversion rule (3.) inverts the neg-
ative polarity of think. As a result, the polarity of
the sentence is positive.
Figure 1: Rules application example.
Various Phenomena Several other phenomena
need to be taken into account when considering
the co-text. Because of irrealis phenomena men-
tioned in the introduction, we completely ignored
questions. We also ignored proper nouns (such as
in ?u need 2 c the documentary The Devil Inside?)
which were a frequent source of errors. These two
phenomena are labeled Ignoring forms in Table 2.
Finally since our approach is sentence-based we
need to consider valence of tweets with several
sentences and we simply considered the average.
2.4 Results on SemEval2013
We measure the performance of the different
strategies on the 3270 tweets that we downloaded
from the SemEval 2013 Task 2 (Nakov et al.,
2013) test corpus
2
. The used metrics is the same
2
Because of Twitter policy the test corpus is not dis-
tributed by organizers but tweets must be downloaded using
than SemEval 2013 one, an unweighted average
between positive and negative F-score.
System F-score Gain
Raw lexical baseline 54.75
+ Part of speech fix 55.00 +0.25
+ Colloqualism rewriting 57.66 +2.66
+ Hashtag splitting 57.80 +0.14
+ Lexicon fetch strategy 58.25 +0.45
+ Valence shifting 62.37 +4.12
+ Ignoring forms 62.97 +0.60
Table 2: Results of syntactic system.
As shown in Table 2, the raw lexical baseline
starts at 54.75% F-score. The two best improve-
ments are Colloquialism rewriting (+2.66) that
seems to capture useful polarized elements and
Valence shifting (+4.12) which provides an accu-
rate account for shifting phenomena. Overall other
strategies taken separately do not contribute much
but enable to have an accumulated +1.44 gain of
F-score. The final result is 62.97%, and we will
refer to this first system as the Syntactic system.
3 Machine Learning Optimization
The best F-score attained with the syntactic system
(62.97%) is still below the best system that par-
ticipated in SemEval2013 (69.02%)
3
. To improve
performance, we input the valence computed by
the syntactic system as a feature in a supervised
machine learning (ML) algorithm. While there ex-
ists other methods such as (Choi and Cardie, 2008)
which incorporates syntax at the heart in the ma-
chine algorithm, this approach has the advantage
to be very simple and independent of any specific
ML algorithm. We chose the Sequential Minimal
Optimization (SMO) which is an optimization of
Support Vector Machine (Platt, 1999) since it was
shown (Balahur and Turchi, 2012) to have good
results that we observed ourselves.
In addition to the valence output by our syntac-
tic system, we considered the following additional
low level features:
? 1-grams words: we observed lower results
with n-grams (n > 1) and decided to keep
1-grams only. The words were lemmatized
and no tf-idf weighting was applied since it
showed lower results.
? polarity counts: it is interesting to in-
clude low level polarity counts in case the
their identifiers, resulting in discrepancies from the official
campaign (3814 tweets).
3
Evaluated on full 3814 tweets corpus
607
syntactic system does not correctly cap-
ture valence shifts. We thus included
independent features counting the number
of positive/negative/neutral words accord-
ing to several lexicons: Liu?s lexicon (Hu
and Liu, 2004), our urban lexicon, Senti-
Wordnet (Baccianella et al., 2010), QWord-
net (Agerri and Garca-Serrano, 2010) and
MPQA lexicon (Wilson et al., 2005).
? punctuation count: exclamation and interro-
gation marks are important, so we have an
independent feature counting occurrences of
???, ?!?, ??!?, ?!??.
Thanks to the ML approach, we can obtain for
a given tweet the different probabilities for each
class. We were then able to adapt each probabili-
ties to favor the SemEval metrics by weighting the
probabilities thanks to the SemEval 2013 training
and development corpus using 10-fold cross vali-
dation (the weights were trained on 90% and eval-
uated on 10%). The resulting weights reduce the
probability to assign the neutral class to a given
tweet while raising the positive/negative probabil-
ities. This optimization is called metrics weighting
in Table 3.
4 Optimization Results
We describe here the results of integrating the syn-
tactic system as a feature of the SMO along with
other low level features. The SemEval 2014 gold
test corpus was not available at the time of this
writing hence we detail the features only on the
SemEval 2013 gold test corpus.
4.1 On SemEval 2013
The results displayed in Table 3 are obtained with
the SMO classifier trained using the WEKA li-
brary (Hall et al., 2009) on our downloaded Se-
mEval 2013 development and training corpora
(7595 tweets). As before, the given score is the
average F-score computed on the SemEval 2013
test corpus. Note that the gain of each feature
must be interpreted in the context of other features
(e.g. Polarity counts needs to be understood as
Words+Polarity Counts).
The syntactic system feature, that is consider-
ing only one training feature which is the valence
annotated by the syntactic system, starts very low
(33.69%) since it appears to systematically fa-
vor positive and neutral classes. However adding
Features F-score Gain
Syntactic system 33.69
+ Words 63.03 +29.34
+ Polarity counts 65.02 +1.99
+ Punctuation 65.65 +0.63
+ Metrics weighting 67.83 +2.18
Table 3: Detailed results on SemEval 2013.
the 1-gram lemmatized words raises the result to
63.03%, slightly above the syntactic system alone
(62.97%). Considering polarity counts raises the
F-score to 65.02% showing that the syntactic sys-
tem does not capture correctly all valence shifts
(or valence neutralizations). Considering an inde-
pendent feature for punctuation slightly raises the
result. Metrics weighting, while not being a train-
ing feature per se, provides an important boost for
the final F-score (67.83%).
4.2 On SemEval 2014
We participated to SemEval 2014 task B as the
Synalp-Empathic team (Rosenthal et al., 2014).
The results are 67.43% on the Twitter 2014
dataset, 3.53 points below the best system. In-
terestingly the score obtained on Twitter 2014 is
very close to the score we computed ourselves on
Twitter 2013 (67.83%) suggesting no overfitting to
our training corpus. However, we observed a big
drop in the Twitter 2013 evaluation as carried out
by organizers (63.65%), we assume that the differ-
ence in results could be explained by difference in
datasets coverage caused by Twitter policy.
5 Discussion and Conclusion
We presented a two-steps approach for sentiment
analysis on Twitter. We first developed a lexico-
syntactic approach that does not require any train-
ing corpus and enables to reach 62.97% on Se-
mEval 2013. We then showed how to adapt the
approach given a training corpus which enables
reaching 67.43% on SemEval 2014, 3.53 points
below the best system. We further showed that
the approach is not sensitive to overfitting since it
proved to be as efficient on the SemEval 2013 and
the SemEval 2014 test corpus. In order to improve
the performance, it could be possible adapt the
lexicons to the specific Twitter domain (Demiroz
et al., 2012). It may also be possible to investi-
gate how to learn automatically the valence shift-
ing rules, for instance with Monte Carlo methods.
608
Acknowledgements
This work was conducted in the context of the
ITEA2 1105 Empathic Products project, and is
supported by funding from the French Services, In-
dustry and Competitivity General Direction. We
would like to thank Christophe Cerisara for the in-
sights regarding the machine learning system and
Claire Gardent for her advices regarding the read-
ability of the paper.
References
Rodrigo Agerri and Ana Garca-Serrano. 2010. Q-
wordnet: Extracting polarity from wordnet senses.
In Proceedings of the Seventh International Con-
ference on Language Resources and Evaluation
(LREC?10), Valletta, Malta, may. European Lan-
guage Resources Association (ELRA).
Stefano Baccianella, Andrea Esuli, and Fabrizio Se-
bastiani. 2010. Sentiwordnet 3.0: An enhanced
lexical resource for sentiment analysis and opinion
mining. In Proceedings of the Seventh International
Conference on Language Resources and Evaluation
(LREC?10), Valletta, Malta, may. European Lan-
guage Resources Association (ELRA).
Alexandra Balahur and Marco Turchi. 2012. Mul-
tilingual sentiment analysis using machine transla-
tion? In Proceedings of the 3rd Workshop in Com-
putational Approaches to Subjectivity and Sentiment
Analysis, WASSA ?12, pages 52?60, Stroudsburg,
PA, USA.
Adam Bermingham and Alan F. Smeaton. 2009. A
study of inter-annotator agreement for opinion re-
trieval. In James Allan, Javed A. Aslam, Mark
Sanderson, ChengXiang Zhai, and Justin Zobel, ed-
itors, SIGIR, pages 784?785. ACM.
Yejin Choi and Claire Cardie. 2008. Learning with
compositional semantics as structural inference for
subsentential sentiment analysis. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, EMNLP ?08, pages 793?801,
Stroudsburg, PA, USA.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. Stanford typed dependencies manual.
Technical report.
Gulsen Demiroz, Berrin Yanikoglu, Dilek Tapucu, and
Y?ucel Saygin. 2012. Learning domain-specific
polarity lexicons. In Proceedings of the 12th In-
ternational Conference of Data Mining Workshops
(ICDMW), pages 674?679, Dec.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: An update.
SIGKDD Explor. Newsl., 11(1):10?18, November.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the 10th
International Conference on Knowledge Discovery
and Data Mining, pages 168?177.
Bing Liu, 2012. Sentiment Analysis and Opinion Min-
ing. Morgan & Claypool Publishers, May.
Karo Moilanen and Stephen Pulman. 2007. Sentiment
composition. In Proceedings of Recent Advances in
Natural Language Processing (RANLP 2007), pages
378?382, September 27-29.
Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva,
Veselin Stoyanov, Alan Ritter, and Theresa Wilson.
2013. SemEval-2013 task 2: sentiment analysis
in twitter. In Proceedings of the 7th International
Workshop on Semantic Evaluation.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classication using
machine learning techniques. In Proceedings of the
2002 Conference on Empirical Methods in Natural
Language Processing, pages 79?86, Philadelphia,
PA.
John C. Platt. 1999. Fast training of support vector
machines using sequential minimal optimization. In
Advances in Kernel Methods, pages 185?208. MIT
Press, Cambridge, MA, USA.
Livia Polanyi and Annie Zaenen. 2006. Contextual
valence shifters. In JamesG. Shanahan, Yan Qu, and
Janyce Wiebe, editors, Computing Attitude and Af-
fect in Text: Theory and Applications, volume 20
of The Information Retrieval Series, pages 1?10.
Springer Netherlands.
Sara Rosenthal, Preslav Nakov, Alan Ritter, and
Veselin Stoyanov. 2014. SemEval-2014 task 9:
Sentiment analysis in twitter. In Proceedings of the
8th International Workshop on Semantic Evaluation.
Richard Socher, Jeffrey Pennington, Eric H. Huang,
Andrew Y. Ng, and Christopher D. Manning. 2011.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
2011 Conference on Empirical Methods in Natural
Language Processing, pages 151?161, Edinburgh.
Peter Turney. 2002. Thumbs up or thumbs down? se-
mantic orientation applied to unsupervised classica-
tion of reviews. In Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics, pages 417?424, Philadelphia, PA.
Theresa Wilson, Janyce Wiebe, and Paul Hoff-
mann. 2005. Recognizing Contextual Polar-
ity in Phrase-Level Sentiment Analysis. In Pro-
ceedings of Human Language Technologies Confer-
ence/Conference on Empirical Methods in Natural
Language Processing (HLT/EMNLP 2005), Vancou-
ver, CA.
609
Generating Referring Expressions with Reference Domain Theory
Alexandre Denis
TALARIS team / UMR 7503 LORIA/INRIA
Lorraine. Campus scientifique, BP 239
F-54506 Vandoeuvre-le`s-Nancy cedex
alexandre.denis@loria.fr
Abstract
In this paper we present a reference gen-
eration model based on Reference Domain
Theory which gives a dynamic account of
reference. This reference model assumes
that each referring act both relies and up-
dates the reference context. We present a
formal definition of a reference domain, a
generation algorithm and its instantiation
in the GIVE challenge.
1 Introduction
Reference is a process in which participants interpret
and produce their referring expressions according to
the previous context. But as Stalnaker puts it: the
discourse context ?is both the object on which speech
acts act and the source of the information relative to
which speech acts are interpreted? (Stalnaker, 1998).
To put it briefly, referring acts not only rely on the
context to produce a reference but also modify it.
This aspect is not taken into account in the classi-
cal generation algorithm by (Dale and Reiter, 1995).
Each referent is generated by discriminating it inside
a context. However, the construction and update of
this context is not adressed.
Further literature on reference generation partially
gives an account for the dynamic nature of the re-
ferring process. For example in (Krahmer and The-
une, 2002), each referring act increases the salience
of the referent such that further references can be
made according to a smaller context, namely the set
of objects whose salience is greater than the referent?s
salience. Reference Domain Theory (RDT) (Reboul,
1998; Salmon-Alt and Romary, 2001) goes a step fur-
ther by assuming that referring acts make salient the
context sets themselves. This theory addresses the
construction and update of the context sets, called
in this theory reference domains. The goal of a re-
ferring act is then to discriminate a referent inside
a reference domain but also a reference domain in
a set of reference domains that we call here referen-
tial space. Moreover each referring act presupposes
a given state of the referential space, and the ex-
plicit representation of these presuppositions as con-
straints on the suitable domain for interpretation or
generation allows the implementation of a reversible
reference module. We will focus here on generation.
Details about the interpretation side of RDT can be
found in (Salmon-Alt and Romary, 2001; Denis et
al., 2006).
However most of the previous work on RDT
does not address computational details. Although
(Salmon-Alt and Romary, 2000) provides a genera-
tion algorithm, the formal definition of a reference
domain and the explicit representation of the con-
straints are not provided. In this paper we show how
RDT can be used to generate referring expressions.
The context of our work is the GIVE challenge (By-
ron et al, 2007; Byron et al, 2009). This challenge
aims to evaluate instruction generation systems in a
situated setting. The goal is to provide instructions
to a player in a 3D maze in order to guide him to find
a hidden trophy. We are here interested with the re-
ferring aspect involved in GIVE: the player has to
push buttons to open doors or disable alarms, thus
the system has to generate referring expressions to
these buttons.
We first present in section 2 some definitions, then
in section 3 we detail a generic generation algorithm.
Section 4 shows a use case of RDT in the context of
the GIVE challenge and provides a detailed exam-
ple of the reference process. The presented model is
generic, but all the examples given throughout the
paper refer to the GIVE setting. Eventually, in sec-
tion 6 we conclude the paper by demonstrating the
success of RDT in an evaluation based on the GIVE
setting.
2 Definitions
The referring process is a discrimination process
whose goal is to discriminate one or more individ-
uals in a context set. The discrimination can make
use of different sources of information. It can be a
semantic discrimination, for instance by uttering se-
mantic properties possessed by the referent to rule
out distractors, e.g. ?the blue button?. It can be
a discrimination of the focus, that is to make use of
the current center of attention, e.g. ?this button?
or ?the other button?. The discrimination can also
rely on the previous referring acts, for instance when
uttering ?Push a blue button. Yes this one?, where
?this one? would be unambiguously uttered in a con-
text of a red and a blue button thanks to the mention
of ?a blue button?. A reference model has to take
into account these different ways to discriminate.
On the other hand, a reference model has also to
consider how objects are grouped together to form
the context sets. They can be constructed thanks to
similarity or proximity of objects (Thorisson, 1994),
by the gestures that are made (Landragin, 2006) or
by the discourse itself (Denis et al, 2006). We will
be limited to the dimension of semantic similarity in
this paper.
RDT claims that the context sets (reference do-
mains or RD) are structures that both gather indi-
viduals and discriminate them. A reference domain
is basically a set of objects that share some seman-
tic description N . A partition that discriminates the
elements is also attached to the domain. The parti-
tion is based on a differentiation criterion such that
two elements being discriminated with this criterion
are put in two different equivalency classes. For in-
stance, in a domain of two buttons, one blue and
one red, the two individuals share the same type and
are differentiated with the color. While each one is
?a button?, they can unambiguously be referred to
with ?the blue button? and ?the red button? (or even
shorter ?blue?, ?red?).
Different elements of a domain may be more or less
focused/salient depending on the visual scene, or on
the previous discriminations. We are assuming that
the focus is defined as the most salient parts of the
partition of a domain and can thus be represented as
a subset of the partition. This is a binary state, that
is, a part is focused or not. While it removes the
possibility to have different degrees of focus inside a
domain, it would help modeling a preference to focus
similar objects together. We did not explore though
the empirical relevance of this hypothesis.
We assume that each domain could be said more
or less salient in a set of reference domains, called
a referential space or RS. The referential space is a
storage for the domains that have been created so
far. We consider here it is unique and shared. In the
GIVE setting, the RS is actually not shared because
the player does not know the maze a priori while the
system knows it completely. But we assume that the
RS is limited to the current room where the player is
standing. Each time the player enters a new room,
the RS is refreshed and a new one is built. We then
suppose that the player is able to access the objects
by walking around, and hence that the RS is shared,
removing problems related to asymmetry.
The referential space provides a traversal order for
the reference domains it contains. The most salient
RD are tested first. While it would be interesting
to model visual salience in the GIVE setting (Lan-
dragin, 2006), we are limited to equate salience and
recency. Thus, each domain will be associated to a
number indicating how recently it has been selected.
The way the salience or the whole RS is affected by
the discrimination process is described in section 3.2.
We now provide a formal definition of a reference do-
main and a referential space building algorithm.
2.1 Reference domains
We assume that ?E, V ? is an environment composed
of E, the universe of all objects and V , the set
of ground predicates that hold in the environment.
Props is a set of unary predicates names such as blue,
red, left, or right. Types is a set of types of unary
predicates such as color, or position. We distinguish
two disjoint subsets of Types, Typespers the persis-
tent types, that are all the properties that describe
permanently the objects, and Typestrans the tran-
sient types, that are all the properties that change
across time. val is the function val : Types? 2Props
which maps a type on the predicates names, e.g.
val(color) = {blue, red, green, yellow}
A reference domain D is a tuple
?GD, SD, ?D, (c, P, F )?
where:
? GD ? E is the set of objects of the domain,
called the ground of the domain.
? SD ? Props is the semantic description of the
domain, such that ?p ? SD,?x ? GD, p(x) ? V ,
that is, SD is a description satisfied for all the
elements of the ground.
? ?D ? N is the salience of the domain
And (c, P, F ) is a partition structure where:
? c ? Types is a differentiation criterion
? P is the partition generated by c, that is, if we
define the equivalence relation
Rc(x, y) ? ?p ? val(c), p(x) ? V ? p(y) ? V
then P = GD/Rc, i.e. P is the quotient set of
GD by Rc.
? F ? P is the focus of P .
For instance, a domain composed of two buttons,
b1 a blue button and b2 a red button, with a salience
equal to 3, where b1 and b2 are differentiated using
the color, and where b1 is in focus, would be noted
as:
D =?{b1, b2}, {button}, 3,
(color, {{b1}, {b2}}, {{b1}})?
2.2 Referential space
The referential space RS is the set of existing do-
mains. In the GIVE context, we assumed that it is
both shared and refreshed each time the player enters
a room. The initial construction of the RS consists
in grouping all the objects of the room that are sim-
ilar inside new reference domains. The RS can be
viewed as a tree-like structure whose nodes are RD.
The root node is a RD whose ground is all objects of
the room. For a node domain D, and for each part
of its partition which is not a singleton, there exists
a child domain which discriminates the elements of
the part. In other words, if a domain does not dis-
criminate some individuals of its ground there exists
another domain which does. Formally, the RS has to
respect the following proposition where PD denotes
the partition of D.
?D ? RS,?P ? PD,
|P | > 1? ?D? ? RS;GD? = P ? |PD? | > 1
In order to make sure that all the individuals could
be discriminated, and thus focused, we introduce the
default partition structure of a set X, which is a par-
tition structure where the criterion is the identifier
of objects and that contains then only singletons, we
note def(X) the default partition of a set X, that is
def(X) = (id, X/Rid, ?).
To build initially the RS, the grouping algorithm
(figure 1) is the following: it takes a list of types T
(T0 means the head, and T1..n the tail) which corre-
sponds to different properties to group the objects.
We are here only using the permanent properties of
objects, that is in GIVE their type and their color,
ordered arbitrarly. It takes also an input domain
which has a default partition. It then tries to parti-
tion the ground of this domain with the first prop-
erty. If this property does not partition the ground,
the next property is tested. If this property parti-
tions the ground, a new domain is created for each
non-singleton part of the partition, and the algo-
rithm tries to partition it with the next property,
so on recursively. We note sh(X, c) the set of prop-
erties of the type c that are shared by all elements of
X: sh(X, c) = {p|p ? val(c),?x ? X; p(x) ? V }.
This partitioning algorithm is slightly different
from the partitioning algorithm called IApart found
in (Gatt and van Deemter, 2007). First, it only par-
titions a set of objects using one unique property,
whereas in IApart the same set of objects can be
partitioned several times. And second, while IApart
?destroys? the ground that is partitioned, our par-
titioning algorithm maintains both the ground and
the partition attached to the domain.
1: RS ? RS ? {D}
2: if T 6= ? then
3: P ? GD/RT0
4: if |P | = 1 then
5: SD ? SD ? sh(GD, T0)
6: createPartitions(D, T1..n, RS)
7: else
8: set (T0, P, ?) as D?s partition structure
9: for all X ? P such that |X| > 1 do
10: D? ? ?X,SD ? sh(X,T0), ?D,def(X)?
11: createPartitions(D?, T1..n, RS)
12: end for
13: end if
14: end if
Figure 1: createPartitions(D, T , RS)
3 Referring
In this section we detail the generation algorithm
in RDT. It implements a dynamic view of referring
whereby each referring act updates the current ref-
erential space. This incremental update of the refer-
ential space proceeds in three steps. First, a domain
containing the referent is found. Then this domain
is used to match a so called underspecified domain
(Salmon-Alt and Romary, 2001). Third, the input
RS is restructured relative to the selected reference
domain.
The approach enables the implementation of a
type B reversible reference module (Klarner, 2005),
that is a module in which both directions share the
Expression U(N, t) matches D iff ?(c, P, F ) ? D;
this one F = {{t}} ? msd(D)
this N F = {{t}} ? t ? NI
the N t ? NI ? {t} ? P ? ?X?P,X 6={t}?X?NI =?
the other one F 6= ? ? P \ F = {{t}} ? msd(D)
the other N F 6= ? ? P \ F = {{t}} ?GD ? N
I
another one F 6= ? ? {t} ? P \ F ? msd(D)
another N F 6= ? ? {t} ? P \ F ?GD ? N
I
a N t ? NI ? t ? GD
Table 1: Underspecified domains for each type of
referring expression
same resources, namely a set of underspecified do-
mains. In interpretation, the goal is to check for
each existing domain if it matches the underspeci-
fied domain obtained from the referring expression.
In generation, the idea is the opposite, that is, to
check from an existing domain and a referent, which
underspecified domain matches them.
We first introduce the different types of underspec-
ified domains. We then present the overall referring
algorithm and the process steering the continuous
update of the referential space.
3.1 Underspecified domains
An underspecified domain (UD) represents a par-
tially specified reference domain corresponding to the
constraints carried by a referring act. We will say
that an underspecified domain matches a reference
domain if all the constraints of the UD are satis-
fied for the reference domain. There may be con-
straints on the ground of the domain, its salience
or the existence of a particular partition structure.
Table 1 summarizes most of the types of under-
specified domains described in (Salmon-Alt and Ro-
mary, 2000; Salmon-Alt and Romary, 2001). Each
underspecified domain is noted U(N, t), where t is
the intended referent and N ? Props is a seman-
tic description. We will note NI the set of ob-
jects that have the semantic description N that is
NI = {x|x ? E,?p ? N, p(x) ? V }. We assume
there is for each description N a given wording, and
we will write for instance ?the N? to denote a defi-
nite RE where N has to be replaced by the wording
of N . The notation msd(D) stands for most salient
description, that is, there is no more salient domain
than D with a different description. This is equiva-
lent to @D? ? RS;?D? ? ?D ? SD? 6= SD.
The indefinite ?a N? can always be generated but
may be ambiguous. The only constraint placed on a
domain by the corresponding UD is that it contains
an element of type N. For example, the domain D1 =
?{b1, b2, b3}, {button}, 0, (color, {{b1, b2}, {b3}}, ?)?
does not differentiate b1 from b2, the only way we
could access to b1 would be by uttering ?a blue
button?.
The definite expression ?the N? requires that the
target forms a semantically disjoint part in the ref-
erence domain partition. For example, in the above
domain D1, ?the red button? can be used to refer to
b3.
Like the definite and indefinite, the demonstrative
?this N? requires that the referent is of type N (be-
longs to NI), but also requires the existence of a fo-
cused partition containing exactly the referent. For
example, if a domain of blue buttons contains a par-
tition structure such that P = {{b1}, {b2}}, it is pos-
sible to refer to b1 given that F = {{b1}} by uttering
?this blue button?, but it would not be the case if
F = {{b1}, {b2}}.
Alternative phrases such as ?another/the other N?
both require that there is already something in focus
which is not the referent. Definite alternative phrases
require that the unfocused part of the partition con-
tains exactly the target referent while indefinites only
require that the unfocused part contains the referent.
For example, if there is a domain of three blue but-
tons b1, b2, b3 with a partition structure such that
F = {{b2}}, it is possible to use the indefinite ?an-
other blue button? to refer to b1 while it would not be
possible to use the definite ?the other blue button?.
One-anaphora of the form ?this/another/the other
one? can be generated only if the description of the
domain in which the referent has to be discriminated
is already salient, in other words that msd(D) is true.
For example, if the most salient domain in RS is a
domain of blue buttons, it would not be possible to
utter ?this one? to refer to a red button inside a less
salient domain.
3.2 Generation algorithm
The referring algorithm (figure 2) proceeds in three
steps as follows.
The first step (line 1?2) determines in which refer-
ence domain, referring will be processed and thereby,
which description will be used for instantiating the
underspecified domains. The selected RD is the most
salient RD with the smallest ground containing the
target referent. If there are several such RD, an
arbitrary one is picked. If the selected domain is
D = ?GD, SD, ?D, (c, P, F )?, then the description S
used to instantiate the underspecified domain is the
conjunction of the properties in the description SD
with the value of the differentiation criterion used
to create the partition namely, properties of val(c)
true of the referent (line 2). If the criterion is the
identifier, it is ignored in S. For instance, if there is
a domain of buttons with a partition on color, the
description might be {button, blue}.
In the second step, the algorithm iterates through
the underspecified domains instantiated with S and
selects the first that matches. The order in which
underspecified domains are tested is particularly im-
portant. We use (Gundel et al, 1993) Givenness hi-
erarchy and ordered the UDs based on the cognitive
status of the corresponding referent. We extended
the hierarchy to include alternative NPs: ?this one?
> ?this N? > ?the N? > ?the other one? > ?the
other N? > ?another one? > ?another N? > ?a N?.
In the third step, the referential space is restruc-
tured by either creating a new domain or increasing
the salience of an existing domain (Figure 3). The
goal of this restructuring step is to be able to re-
strict the further focus to a smaller domain. For
instance, when dealing with red buttons we want
to avoid focusing the blue buttons. The function
first gathers all objects of D that have the persis-
tent part of description S (Gp and Sp), and if there
is already a domain composed by these objects, its
salience is increased such that it is the most salient
(line 4). If there is no such domain, a new most
salient domain is created with these objects and a
default partition. Transient properties are not taken
into account to regroup the objects because it would
restrict too much further focus. For instance, limit-
ing the restructuring to persistent properties avoids
sequences like ?Push the button on the right. Yeah
this one?.
For example in a domain D containing a button
b1 and a chair c1,
D =?{b1, c1}, ?, 0,
(objType, {{b1}, {c1}}, ?)?
a reference to b1 could lead to the generation of
the expression ?the button?, the restructuring makes
sure to create a new domain whose ground is only
{b1}. Therefore, we avoid producing unecessary ref-
erence to the chair such as ?Not this chair! Look for
the button? (see section 4).
3.3 Dealing with plurals
The plurals treatment is quite similar to the singu-
lar cases, but we need to do two modifications to
be able to generate plurals. The first modification
is about the underspecified domains. Whereas we
had individuals, here we want to generate an RE to
a set of targets T = {t1..tn}. The UDs can eas-
ily be modified by just replacing every occurrence
of {t} by T (and t ? NI by T ? NI). With this
modification, we can only generate plurals for sets of
1: D ? most salient/specific domain containing t
2: S ? SD ? {p|p ? val(c), p(t) ? V }
3: for all U(S, t) sorted by Givenness do
4: if U(S, t) matches D then
5: restructure(D, S, RS)
6: return U(S, t)
7: end if
8: end for
9: return failure
Figure 2: generate(t, RS)
1: Sp ? {p|p ? S, val?1(p) ? Typespers}
2: Gp ? {x|x ? GD,?p ? Sp, p(x) ? V }
3: if ?D? ? RS;GD? = Gp then
4: ?D? ? max?(RS) + 1
5: else
6: D? ? ?Gp, Sp,max?(RS) + 1,def(Gp)?
7: RS ? RS ? {D?}
8: end if
Figure 3: restructure(D, S, RS)
objects that are parts of an existing partition. Imag-
ine we have GD = {b1, b2, b3, b4}, and a partition
P = {{b1, b2}, {b3, b4}} then it is not possible to refer
to {b2, b3} using a demonstrative because they can-
not be focused together. It may be possible to adapt
the UD to consider
?
F instead of F , that is for in-
stance instead of F = {T} we would require that
?
F = T . But this possibility and its side-effects
have not been yet explored.
The second modification is related to the gener-
ation algorithm and the description used to build
the underspecified domains. Instead of retrieving the
properties of the differentiation criterion for a single
target we need to make sure that the properties are
true for all the targets, that is (line 2), we need to
have S ? SD ? {p|p ? val(c),?t ? T, p(t) ? V }.
4 Generation in the GIVE challenge
We present here how the generation module has been
instantiated in the second edition of the GIVE chal-
lenge (Byron et al, 2007).
First, each time the player enters a new room,
the partition algorithm is called on an initial domain
Dr = ?Gr, ?, 0,def(Gr)?, with Gr ? E the set of all
objects in the room, and the list of GIVE persistent
types, that is objType, the type of objects, and color.
We then use the above referring algorithm in two
ways. First, it is used to produce a first mention us-
ing only persistent properties and without updating
the focus. Second, it is used to produce a series of
additional subsequent mentions whose function is to
guide the player search. In this second step, tran-
sient spatial properties are used and the visual focus
is continuously updated.
4.1 First mention
The referring algorithm just described (cf. Figure 2)
takes as input the current referential space RS, gen-
erates a referring expression for the target referent
t and outputs a push instruction of the form ?Push
?+v(generate(t, RS)) where v is the verbalization
function. Note that the referential space may con-
tain domains with focused partitions coming from
previous references to other objects, and therefore is
not limited to producing definite or indefinite NPs.
4.2 Subsequent mentions
All the subsequent mentions assume that the first
mention has been performed but has not succeeded
yet in identifying the referent. They are all based on
focus and potentially on transient properties. The
focus is defined as the set of visible objects. The al-
gorithm (figure 4) first updates the focus of the parti-
tion of the most salient/specific domain D containing
the target t. Then the rest of the algorithm gener-
ates different instructions depending on whether the
target is or is not focused.
The lines 7?8 refine the focus using relative spa-
tial properties of objects in their domain. It first
computes these new properties hpos and vpos for all
objects in
?
F , and adds them in V . The refinement
is made by calling the partition function (algorithm
1) on a new domain DF = ?GF , SD, ?D+1,def(GF )?,
using [hpos,vpos]. The salience of DF is just higher
than the salience of D such that DF is preferred
over D when generating. This refinement allows
producing expressions like ?the blue button on the
right?. Because these properties are transient, they
are erased from V after the generation and all the
domains and partitions that may have been created
using them including DF are also erased.
Other lines produce expressions if the referent is
not in focus. If there is nothing in focus, it produces
?Look for X? where X is an RE for the referent. If
there is something in focus which is not the referent,
it first produces ?Not X? where X is an RE designat-
ing what is in focus, then ?Look for X? where X is an
RE for the referent. Note that this is the only place
where plurals can be generated (see section 3.3).
5 Detailed example
We present here a detailed example of the behavior
of the reference module in the GIVE setting (Table
2). We assume that the player U enters a room with
1: D ? most salient/specific domain containing t
2: F ? focus of the visible objects in D
3: GF ?
?
F
4: if t ? GF then
5: if |GF | > 1 then
6: computePositions(GF )
7: DF ? ?GF , SD, ?D + 1,def(GF )?
8: createPartitions(DF , [hpos,vpos], RS)
9: end if
10: return ?Yeah!?+v(generate(t, RS))+? !?
11: else
12: if |GF | = 0 then
13: return ?Look for ?+v(generate(t, RS))
14: else
15: return ?Not ?+v(generate(GF , RS))+? !
Look for ?+v(generate(t, RS))+? !?
16: end if
17: end if
Figure 4: Algorithm to instruct the search for a ref-
erent
state of U utterance of S
Push a blue button (b1)
see(b2) Not this one! Look for the other one!
see(b1,b2) Yeah! The blue button on the right!
see(b1) Yeah! This one!
push(b1)
Push the red button (b3)
see(b3) Yeah! This one!
push(b3)
Push the other blue button (b2)
Table 2: Utterances produced by the system S
three buttons, two blue buttons, b1 and b2 and a red
button b3.
5.1 Initializing the referential space
As soon as the player enters the room, the partition
algorithm is called on the initial domain:
D0 = ?Gr, ?, 0, def(Gr)?
with Gr = {b1, b2, b3}. The result is the RS :
D0 =?{b1, b2, b3}, {button}, 0,
(color, {{b1, b2}, {b3}}, ?)?
D1 =?{b1, b2}, {button, blue}, 0,
(id, {{b1}, {b2}}, ?)?
We will note the RS by grouping the domains that
have the same salience and indicating the salience
of a set of domains in subscript. That is, after the
construction, the RS is: {{D0, D1}0}.
5.2 ?Push a blue button?
The system is first required to refer to b1. As all the
domains all are equally salient, the algorithm tries to
pick the most specific domain containing b1, and it
finds D1. The description used to refer to b1 is the
description of the domain SD1 = {button, blue} and
the value for the criterion which is the identifier and
is then ignored. Inside D1 it then tries to refer to
b1 by iterating through the underspecified domains
to find the first one that matches D1. Because there
is no focus at this moment, the first found UD that
matches is ?a N?. It then performs restructuration
of the RS, by trying to build a new subdomain of
D1. However, because there are only blue buttons
in D1, no subdomain is created and the salience of
D1 is increased. Eventually, the expression is verbal-
ized and ?Push a blue button? is uttered. After this
reference, the RS is then {{D1}1, {D0}0}.
5.3 ?Not this one! Look for the other one!?
Before the subsequent mentions to b1 are made, the
focus of the most salient/specific domain containing
b1 is updated. We assume first that only b2 is visible,
thus D1 becomes:
D1 =?{b1, b2}, {button, blue}, 1,
(id, {{b1}, {b2}}, {{b2}})?
According to the algorithm in figure 4, a reference
to b2 has to be made first ?Not b2!?. Underspeci-
fied domains are iterated and the first that matches
is ?this one? considering that {blue, button} is the
most salient description and b2 is in focus. No sub-
domain is created when restructuring the RS, only
the salience of D1 is increased. The uttered expres-
sion is then ?Not this one!?. As for the reference
to b1, the reference is still made in D1 and the first
UD that matches is ?the other one?. No restructur-
ing apart from increasing salience is performed and
the returned expression is eventually ?Look for the
other one!?. So, after referring to b2 and b1, the RS
is {{D1}3, {D0}0}.
5.4 ?The blue button on the right?
We enjoined the player to turn around to search for
b1. We assume here that he did so and now can see
both b1 and b2. Before any reference can take place,
the focus of D1 is updated:
D1 =?{b1, b2}, {button, blue}, 3,
(id, {{b1}, {b2}}, {{b1}, {b2}})?
However, the focus can no more discriminate both
buttons, and a refinement with the position has to be
performed according to the algorithm 4. We assume
that b1 is on the right while b2 is on the left. Positions
are computed and new ground predicates are added
to V : {right(b1), left(b2)}. A new domain D2 with a
ground equal to the focus of D1, that is {b1, b2}, is
built and used as input for the partition algorithm.
It is partitioned along the horizontal position (hpos),
and then added to the RS, that is:
D2 =?{b1, b2}, {button, blue}, 4,
(hpos, {{b1}, {b2}}, ?)?
Before the reference to b1, the RS is then
{{D2}4, {D1}3, {D0}0}. A new reference to b1 is
then made, but as D2 is more salient than D1 it
is preferred for the reference. The first UD that
matches is the definite ?the N? built with the de-
scription {button, blue, right}, and ?the blue button
on the right? is uttered. However, because D2 was
built with transient properties, it is erased from the
RS and is recreated before each reference unless the
player changes its visual focus.
5.5 ?Yeah! This one!?
Now we assume that the player turned around again
and only sees now b1. The most salient/specific do-
main containing b1 is D1 and its focus is updated:
D1 =?{b1, b2}, {button, blue}, 3,
(id, {{b1}, {b2}}, {{b1}})?
The first matching UD is the demonstrative one-
anaphora ?this one?, no restructuring takes place ex-
cept the increased salience of D1 and ?Yeah! This
one!? is produced. The RS is thus {{D1}4, {D0}0}.
5.6 ?Push the red button?
We assume that given all these referring expressions,
the player is at last able to push b1. A new reference
has to be made, this time to b3, the red button. The
most salient/specific domain containing b3 is actually
D0. In D0, the first matching underspecified domain
is the definite ?the N?. The restructuring leads this
time to create a new most salient domain D3 com-
posed only of b3 (because it is the only red button):
D3 =?{b3}, {button, red}, 5,
(id, {{b3}}, ?)
The further reference to objects will thus avoid re-
ferring to something else than red buttons (see sec-
tion 3.2). The RS is then {{D3}5, {D1}4, {D0}0}.
5.7 ?Yeah! This one!?
Provided that D3 is now the most salient/specific
container of b3, b3 can be focalized in the default
partition of D3, resulting in:
D3 =?{b3}, {button, red}, 5,
(id, {{b3}}, {{b3}})?
The first matching UD is then ?this one?, the re-
structuring just increases the salience of D3 and the
system utters eventually ?Yeah! This one!?. The
RS is then {{D3}6, {D1}4, {D0}0}. Note that, even
if the player would turn around and see b1 or b2 in
the same time than b3, D3 being the current most
salient/specific domain, b1 or b2 would not be fo-
cused.
5.8 ?Push the other blue button?
We now have to refer to the last button b2. The
most salient/specific domain containing b2 is D1,
however D1 contains already a focus to b1. Thus,
the first matching UD is ?the other N?. Note that
we only considered visual focus, therefore the alter-
native anaphora ?the other? does not refer to b2 be-
cause we already mentioned b1 but only because it
is the last object the player saw in D1. By chance,
in the GIVE setting, the visual focus corresponds
to the linguistic focus and thus uttering ?Push the
other blue button? sounds natural. It would be more
complex to handle a setting with both the linguistic
and the visual focus, but we think that the RDT is
well-equipped to resolve this issue.
6 Evaluation
We evaluated the RDT generation model by compar-
ing its performances with another system also com-
peting in the GIVE challenge but based on a clas-
sical approach on (Dale and Haddock, 1991) that is
restricted to generating definite and indefinite NPs.
We designed a special evaluation world to test several
reference cases, and for both approaches, we mea-
sured the average time from the moment of uttering
a first mention designating a button to the moment
of completion, that is when the button is success-
fully pushed. We also measured the average number
of instructions that were provided in the meantime.
The evaluation has been conducted with 30 subjects
resulting in 20 valid games. The results show that
the RDT performs better than the classical strategy,
both for the average completion time (8.8 seconds
versus 12.5 seconds) and for the number of instruc-
tions (6.4 versus 9.3). We conjecture that the good
results of RDT can be explained by the lower cog-
nitive load resulting from the use of demonstrative
NPs and one-anaphoras.
7 Other works and extensions
While some RE generation models focus on the side
of generating the description itself (Dale and Re-
iter, 1995; Krahmer et al, 2003), we tried to focus
more on the side of generating the determiner. While
works such as (Poesio et al, 1999) also generates the
determiner, they rely on statistical learning of this
determiner. On the contrary we did so by represent-
ing logically the constraints carried by a referring ex-
pressions on the context of its interpretation. How-
ever, the presented model has several limits. First,
as (Landragin and Romary, 2003) describe, there is
no one-to-one relation between the referring expres-
sions and the referring modes. In order to tackle this
problem we can associate a set of UD to a referring
expression. We only need then to add an additional
loop on the different UDs for a given type of referring
expression. The second extension is the possibility
to have several partitions. It is also possible to it-
erate over the set of partitions of a domain, but we
then need to consider the salience of each partition.
In addition, the restructuring has to be amended to
increase the salience of the partition in which a gen-
eration is made.
8 Conclusions
We presented a reference generation algorithm based
on Reference Domain Theory. The main improve-
ment of this algorithm over existing approaches is
the construction and update of a set of local con-
texts called a referential space. Each local context
(reference domain) can be used as a context for re-
ferring. The dynamic aspect of the reference process
consists both in the continuous update of the ref-
erence domains and in the update of the referential
space. Thus, the presented algorithm can generate a
variety of referring expressions ranging from definite,
indefinite to demonstrative, alternative phrases, one-
anaphora and plurals. The instantiation in the GIVE
challenge was a baptism for the generation algorithm
and the GIVE setting offered us a good opportunity
to test the serial nature of the reference process. It
enabled us to evaluate the RDT approach and proved
that it is successful.
We would like to thank Luciana Benotti, Claire
Gardent, and the people participating to the GIVE
challenge at the LORIA for their help during the
model development. We also would like to thank the
anonymous reviewers for their precious insights.
References
Donna K. Byron, Alexander Koller, Jon Oberlander,
Laura Stoia, and Kristina Striegnitz. 2007. Gener-
ating instructions in virtual environments (GIVE):
A challenge and an evaluation testbed for NLG.
In Proceedings of the Workshop on Shared Tasks
and Comparative Evaluation in Natural Language
Generation, Washington, DC.
Donna Byron, Alexander Koller, Kristina Striegnitz,
Justine Cassell, Robert Dale, Johanna Moore, and
Jon Oberlander. 2009. Report on the First NLG
Challenge on Generating Instructions in Virtual
Environments (GIVE). In Proceedings of the 12th
European Workshop on Natural Language Gen-
eration (ENLG 2009), pages 165?173, Athens,
Greece, March. Association for Computational
Linguistics.
Robert Dale and Nicholas J. Haddock. 1991. Gener-
ating referring expressions involving relations. In
Proceedings of the 5th Conference of the European
Chapter of the ACL, EACL-91.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the gricean maxims in the gen-
eration of referring expressions. Cognitive Science,
19(2):233?263.
Alexandre Denis, Guillaume Pitel, and Matthieu
Quignard. 2006. Resolution of Referents Group-
ings in Practical Dialogues. In Proceedings of the
7th SIGDial Workshop on Discourse and Dialogue
- SIGdial?06, Sydney Australia.
Albert Gatt and Kees van Deemter. 2007. Incre-
mental generation of plural descriptions: Similar-
ity and partitioning. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language
Processing, EMNLP-07.
Jeanette K. Gundel, Nancy Hedberg, and Ron
Zacharski. 1993. Cognitive status and the form
of referring expressions in discourse. Language,
69(2):274?307.
Martin Klarner. 2005. Reversibility and re-usability
of resources in NLG and natural language dia-
log systems. In Proceedings of the 10th Euro-
pean Workshop on Natural Language Generation
(ENLG-05), Aberdeen, Scotland.
Emiel Krahmer and Marit Theune. 2002. Effi-
cient context-sensitive generation of referring ex-
pressions. In K. van Deemter and R. Kibble, edi-
tors, Information sharing: Givenness and newness
in language processing, pages 223?264. CSLI Pub-
lications, Stanford.
Emiel Krahmer, Sebastiaan van Erk, and Andr Ver-
leg. 2003. Graph-based generation of referring
expressions. Computational Linguistics, 23:53?72.
Fre?de?ric Landragin and Laurent Romary. 2003. Re-
ferring to Objects Through Sub-Contexts in Multi-
modal Human-Computer Interaction. In Proceed-
ings of the Seventh Workshop on the Semantics
and Pragmatics of Dialogue (DiaBruck?03), pages
67?74. Saarland University.
Fre?de?ric Landragin. 2006. Visual perception, lan-
guage and gesture: A model for their understand-
ing in multimodal dialogue systems. Signal Pro-
cessing, 86(12):3578?3595.
Massimo Poesio, Renate Henschel, Janet Hitzeman,
and Rodger Kibble. 1999. Statistical NP genera-
tion: A first report. In Proceedings of the ESSLLI
Workshop on NP Generation, Utrecht.
Anne Reboul. 1998. A relevance theoretic approach
to reference. In Acts of the Relevance Theory
Workshop, University of Luton, England.
Susanne Salmon-Alt and Laurent Romary. 2000.
Generating referring expressions in multimodal
contexts. In Workshop on Coherence in Generated
Multimedia - INLG 2000, Mitzpe Ramon, Israel.
Susanne Salmon-Alt and Laurent Romary. 2001.
Reference resolution within the framework of cog-
nitive grammar. In Proceeding of the International
Colloquium on Cognitive Science, San Sebastian,
Spain.
Robert Stalnaker. 1998. On the representation of
context. Journal of Logic, Language and Informa-
tion, 7(1):3?19.
Kristinn R. Thorisson. 1994. Simulated perceptual
grouping: An application to human-computer in-
teraction. In Proceedings of the Sixteenth Annual
Conference of the Cognitive Science Society, At-
lanta, Georgia.
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 79?82,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Reference reversibility with Reference Domain Theory
Alexandre Denis
TALARIS team / UMR 7503 LORIA/INRIA
Lorraine. Campus scientifique, BP 239
F-54506 Vandoeuvre-le`s-Nancy cedex
alexandre.denis@loria.fr
Abstract
In this paper we present a reference model
based on Reference Domain Theory that
can work both in interpretation and gener-
ation. We introduce a formalization of key
concepts of RDT, the interpretation and
generation algorithms and show an exam-
ple of behavior in the dynamic, asymmetric
and multimodal GIVE environment.
1 Introduction
The reference task in a dialogue system is two-fold.
On the one hand the system has to interpret the
referring expressions (RE) produced by the user in
his utterances. On the other hand the system has
to generate the REs for the objects it aims to refer
to. We present in this paper a framework that con-
siders that reference interpretation and generation
are two sides of the same coin, hence avoiding any
potential misunderstanding arising from the two
modules discrepancies. Reference Domain Theory
(RDT) (Salmon-Alt and Romary, 2000; Salmon-
Alt and Romary, 2001) proposes to represent the
diversity of referring acts by the diversity of con-
straints they impose on their context of use. The
reversibility then lies in the possibility to express
these constraints independently of the considered
task.
In (Denis, 2010) we described the generation side
of RDT in the context of the GIVE-2 challenge
(Koller et al, 2010) which is an evaluation of in-
struction generation systems in a 3D maze. In this
paper we propose the interpretation counterpart
and show the required modeling to consider the
dynamic, asymmetric and multimodal context of
GIVE. We first present the reference model in sec-
tion 2 and 3, discuss the interpretation problems
in GIVE in section 4, detail an example in section
5 and present evaluation results in section 6.
2 Reference Domains
A rich contextual structure is required to give an
account for the different kinds of discrimination
we observe in REs such as semantic discrimina-
tion (e.g. ?the blue button?), focus discrimination
(e.g. ?this button?) and salience discrimination
(e.g. ?this one?). We introduce here the struc-
ture of reference domain which is a local context
supporting these different discriminations.
We assume that Props is the set of unary predi-
cate names e.g. {blue, left, ...}, Types is the set of
types of predicates e.g. {color, position, ...}, and
val is the function val : Types? 2Props which maps
a type on the predicates names. Finally, E is the
set of all objects and V the set of ground predicates
e.g. {blue(b1), ...}.
A reference domain D is then a tuple
?GD, SD, ?D, (c, P, F )?
where GD ? E is the set of objects of the do-
main, called the ground of the domain; SD ? Props
is the semantic description of the domain, satis-
fied by all elements of the ground; ?D ? N is the
salience of the domain. And (c, P, F ) is a parti-
tion structure where c ? Types is a differentiation
criterion; P is the partition generated by c; and
F ? P is the focus of P .
For instance, a domain composed of a blue but-
ton b1 and a red button b2, with a salience equal
to 3, where b1 and b2 are differentiated using the
color, and where b1 is in focus, would be noted as:
D =?{b1, b2}, {button}, 3,
(color, {{b1}, {b2}}, {{b1}})?
Finally we define a referential space (RS) as a
set of reference domains (RD) ordered by salience.
3 Referring
A RE impose some constraints on the context in
which it can be uttered, that is in which RD the
interpretation has to be made. The constraints are
represented as underspecified domains (UD), spec-
ifying the structure of the suitable RD in terms of
ground, salience or partition. The explicit defini-
tions of the UDs makes possible to share these def-
initions between the interpretation and the gener-
ation modules, hence allowing the implementation
of a type B reversible reference module (Klarner,
2005), that is a module in which both directions
share the same resources.
79
Expression U(N, t) matches D iff ?(c, P, F ) ? D;
this one F = {{t}} ? msd(D)
this N F = {{t}} ? t ? NI
the N t ? NI ? {t} ? P ? ?X?P,X 6={t}?X?NI =?
the other one F 6= ? ? P \ F = {{t}} ? msd(D)
the other N F 6= ? ? P \ F = {{t}} ?GD ? N
I
another one F 6= ? ? {t} ? P \ F ? msd(D)
another N F 6= ? ? {t} ? P \ F ?GD ? N
I
a N t ? NI ? t ? GD
Table 1: Underspecified domains for each type of
referring expression
3.1 Underspecified domains
The different types of UDs are presented in table 1.
Each UD is a parametric conjunction of constraints
on a RD, noted U(N, t), where t is the intended
referent and N ? Props is a semantic description.
NI stands for the extension of N , and msd(D)
stands for most salient description, that is, there
is no more or equally salient domain than D in the
current RS with a different description. Each UD
is associated to a wording combining a determiner
and a wording of the semantic description, for in-
stance ?the N? is a shortcut for a definite expres-
sion whose head noun and modifiers are provided
by the wording of N . Finally we say that an UD
matches a RD if all the constraints of the UD are
satisfied by the RD.
3.2 Referring processes
Interpretation and generation can now be defined
in terms of UD. The two processes are illustrated
in figure 1 and the algorithms are presented in fig-
ure 2.
The interpretation algorithm consists in finding
or creating a RD from the input UD, U(N, .) cre-
ated from the input RE type and description N .
The algorithm then iterates through the RS in
salience order, and through all the individuals t of
the tested domain to retrieve the first one match-
ing U(N, t). If a matching domain D is found, a
restructuring operation is applied and the referent
t is focused in the partition of D. On the other
hand, if no domain is found, the UD is accommo-
dated, that is a new domain and a new referent sat-
isfying the constraints of U(N, t) are created. Ac-
cording to the task, this accommodation may not
be possible for all REs, but for sake of simplicity
we assume here this operation is always possible.
The generation side is the opposite, that is it
finds an UD from an input RD. It first selects a
RD containing the target referent to generate t,
assuming here that the most salient domain has to
be preferred. The description N used to instan-
tiate the UDs is composed of the description of
the domain and the description of the referent in
the partition (line 2). It then iterates through the
Underspecified
Domains
Existing
Domains
interpretation
generation
referent
referring
expression
Figure 1: Reference processes
different UDs by Givenness order (Gundel et al,
1993) and selects the first one that matches. A re-
structuring operation is applied and the found UD
is returned, eventually providing the RE.
The restructuring operation, detailed in (Denis,
2010), aims to restrict the current context by cre-
ating a new domain around the referent in the ref-
erential space or by increasing the salience of the
domain containg the referent. This operation helps
to perform focalization in restricted domains.
4 The complex context of GIVE
The dynamic, asymmetric and multimodal context
of GIVE requires additional mechanisms for inter-
pretation. Asymmetry causes the late visual con-
text integration, when the direction giver produces
a RE to objects not yet known by the direction
follower, that are only visually discovered later on.
Space prevents us to describe in details the late in-
tegration algorithm, but the idea is, given a new
physical object t, to scan existing domains of the
actual RS to check if t can be merged semantically
with any previous object t?. If this could be the
case, the integration leads to create two parallel
RS, one in which t = t? (the fusion hypothesis)
and one in which t 6= t? (the separation hypoth-
esis). If this cannot be the case, t is added as a
new object. Following (DeVault and Stone, 2007),
these alternative contexts can persist across time
and further referring expressions may reject one or
the other hypothesis as illustrated in section 5.
The second required mechanism is the proper
handling of the multimodal dynamic focus, that
is the combination of the linguistic focus result-
ing from RE, and the visual focus. It is possible
to have two referential spaces for the linguistic or
visual context as in (Kelleher et al, 2005; Byron
et al, 2005), or to have two foci in a partition.
We can also model interleaved focus, that is, only
one focus per domain but that dynamically corre-
sponds to the linguistic focus or the visual focus.
The idea is that after each RE, the referent receives
the focus as described in algorithm 1, but whenever
the visual context changes, the focus is updated to
the visible objects. Although interleaved focus pre-
vents anaphora while the visual context changes,
its complexity is enough for our setup.
80
Algorithm 1 interpret(U(N, .), RS)
1: for all domain D in RS by salience order do
2: for all t ? GD do
3: if U(N, t) matches D then
4: restructure(D, N , RS)
5: focus t in D
6: return t
7: end if
8: end for
9: end for
10: return accommodate(U(N, .), RS)
Algorithm 2 generate(t, RS)
1: D ? most salient domain containing t
2: N ? SD ? {p|p ? val(c), p(t) ? V }
3: for all U(N, t) sorted by Givenness do
4: if U(N, t) matches D then
5: restructure(D, N , RS)
6: return U(N, t)
7: end if
8: end for
9: return failure
Figure 2: Reference algorithms, relying on the same underspecified domains
5 Example
In this section we present the interpretation side
of some expressions we generated in the GIVE set-
ting (table 2). The detailed generation side of this
example can be found in (Denis, 2010). S is the
system that interprets the RE of U the user. The
situation is: S enters a room with two blue but-
tons b1 and b2, none of them being visible when he
enters and U wants to refer to b1.
state of S utterance of U
Push a blue button (b1)
see(b2) Not this one! Look for the other one!
see(b1) Yeah! This one!
Table 2: Utterances produced by U
When S enters the room, U generates an indef-
inite RE ?Push a blue button?. S first constructs
an indefinite UD ?a N? with N = {blue, button}.
However, because there exists no RD at first, he
has to accommodate the UD, hence creating a new
domain D1 containing a new linguistically focused
individual t:
D1 =?{t}, {button, blue}, 1,
(id, {{t}}, {{t}})?
We assume that S moves and now sees the blue
button b2 without knowing yet if this is the in-
tended one. The integration of this new physical
object then leads to two hypothesis. In the fu-
sion hypothesis, b2 = t, and in the separation hy-
pothesis, b2 6= t. In both cases, the visible button
is focused in the two versions of D1, D1FUS and
D1SEP :
D1FUS =?{t}, {button, blue}, 2,
(id, {{t}}, {{t}})?
D1SEP =?{t, b2}, {button, blue}, 2,
(id, {{t}, {b2}}, {{b2}})?
However, U utters ?Not this one!? rejecting then
the fusion hypothesis. To be able to consider the ef-
fects of this utterance, we have to take into account
the ellipsis. This can be done by assuming that U
is asserting properties of the target of his first RE,
that is, he is actually stating that ?[t is] not this
one!?. The RE ?this one? leads to the construction
of a demonstrative one-anaphora UD that matches
t in D1FUS but b2 in D1SEP . The following schema
shows the contradiction in the fusion hypothesis:
t is not this one
fusion t 6= t
separation t 6= b2
Being contradictory, the fusion hypothesis is re-
jected and only D1SEP is maintained. For the
readability of the presentation, D1SEP is rewrit-
ten as D1.
The interpretation of ?Look for the other one!?
is straightforward. A definite alternative one-
anaphora UD is built, and both t and b2 are tested
in D1 but only t is matched because it is unfocused
(see the definition of the alternative one-anaphora
in table 1).
Now S moves again and sees b1. As for b2, the
integration of b1 in the referential space leads to
two alternative RS. The buttons b2 and b1 cannot
be merged (we assume here that S can clearly see
they are two different buttons), thus the two alter-
native RS are whether b1 = t or b1 6= t:
D1FUS =?{t, b2}, {button, blue}, 3,
(id, {{t}, {b2}}, {{t}})?
D1SEP =?{t, b1, b2}, {button, blue}, 3,
(id, {{t}, {b1}, {b2}}, {{b1}})?
Eventually S has to interpret ?this one?. Like
previously, in order to take into account the effects
of this utterance, S has to resolve the ellipsis and
must consider ?[t is] this one?. The RE ?this one?
is resolved on t in D1FUS but on b1 in D1SEP .
81
t is this one
fusion t = t
separation t = b1
This is now the separation hypothesis which is
inconsistent because we assumed that b1 6= t. This
RS is then ruled out, and only the fusion RS re-
mains.
6 Evaluation
Only the generation direction has been evaluated
in the GIVE challenge. The results (Koller et al,
2010) show that the system embedding Reference
Domain Theory proves to rely on less instructions
than other systems (224) and proves to be the most
successful (47% of task success) while being the
fastest (344 seconds). We conjecture that the good
results of RDT can be explained by the low cogni-
tive load resulting from the use of demonstrative
NPs and one-anaphoras, but the role of the over-
all generation strategy has also to be taken into
account in these good results (Denis et al, 2010).
Although it would be very interesting, the in-
terpretation side has not yet been evaluated in
the GIVE setting, but only in the MEDIA cam-
paign (Bonneau Maynard et al, 2009) which is an
unimodal setting. The results show that the in-
terpretation side of RDT achieves a fair precision
in identification (75.2%) but a low recall (44.7%).
We assume that the low recall of the module is
caused by the cascade of errors, one error at the
start of a reference chain leading to several other
errors. Nonetheless, we estimate that error cascad-
ing would be less problematic in the GIVE setting
because of its dynamicity.
7 Conclusions
We presented a reference framework extending
(Salmon-Alt and Romary, 2001) in which interpre-
tation and generation can be defined in terms of the
constraints imposed by the referring expressions on
their context of use. The two modules sharing the
same library of constraints, the model is then said
reversible. However, because of the asymmetry and
dynamicity of our setup, the GIVE challenge, ad-
ditional mechanisms such as uncertainty have to
be modeled. In particular, we have to maintain
different interpretation contexts like (DeVault and
Stone, 2007) to take into account the ambiguity
arising from the late integration of the visual con-
text. It would be interesting now to explore deeper
our reversibility claim by evaluating the interaction
between the two reference algorithms in the GIVE
setting.
References
He?le`ne Bonneau Maynard, Matthieu Quignard,
and Alexandre Denis. 2009. MEDIA: a seman-
tically annotated corpus of task oriented dialogs
in French. Language Resources and Evaluation,
43(4):329?354.
Donna K. Byron, Thomas Mampilly, Vinay
Sharma, and Tianfang Xu. 2005. Utilizing vi-
sual attention for cross-modal coreference inter-
pretation. In Proceedings of Context-05, pages
83?96.
Alexandre Denis, Marilisa Amoia, Luciana
Benotti, Laura Perez-Beltrachini, Claire Gar-
dent, and Tarik Osswald. 2010. The GIVE-2
Nancy Generation Systems NA and NM.
Technical report.
Alexandre Denis. 2010. Generating referring ex-
pressions with Reference Domain Theory. In
Proceedings of the 6th International Natural
Language Generation Conference - INLG 2010,
Dublin, Ireland.
David DeVault and Matthew Stone. 2007. Man-
aging ambiguities across utterances in dialogue.
In Proceedings of the 2007 Workshop on the Se-
mantics and Pragmatics of Dialogue (DECA-
LOG 2007), Trento, Italy.
Jeanette K. Gundel, Nancy Hedberg, and Ron
Zacharski. 1993. Cognitive status and the form
of referring expressions in discourse. Language,
69(2):274?307.
John Kelleher, Fintan Costello, and Josef van Gen-
abith. 2005. Dynamically structuring, updating
and interrelating representations of visual and
linguistic discourse context. Artificial Intelli-
gence, 167(1-2):62?102.
Martin Klarner. 2005. Reversibility and re-
usability of resources in NLG and natural lan-
guage dialog systems. In Proceedings of the 10th
European Workshop on Natural Language Gen-
eration (ENLG-05), Aberdeen, Scotland.
Alexander Koller, Kristina Striegnitz, Andrew
Gargett, Donna Byron, Justine Cassell, Robert
Dale, Johanna Moore, and Jon Oberlander.
2010. Report on the second NLG challenge on
generating instructions in virtual environments
(GIVE-2). In Proceedings of the 6th Interna-
tional Natural Language Generation Conference
- INLG 2010, Dublin, Ireland.
Susanne Salmon-Alt and Laurent Romary. 2000.
Generating referring expressions in multimodal
contexts. In Workshop on Coherence in Gener-
ated Multimedia - INLG 2000, Israel.
Susanne Salmon-Alt and Laurent Romary. 2001.
Reference resolution within the framework of
cognitive grammar. In Proceeding of the Inter-
national Colloquium on Cognitive Science, San
Sebastian, Spain.
82
Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 68?77,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Giving instructions in virtual environments by corpus based selection
Luciana Benotti
PLN Group, FAMAF
National University of Co?rdoba
Co?rdoba, Argentina
luciana.benotti@gmail.com
Alexandre Denis
TALARIS team, LORIA/CNRS
Lorraine. Campus scientifique, BP 239
Vandoeuvre-le`s-Nancy, France
alexandre.denis@loria.fr
Abstract
Instruction giving can be used in several
applications, ranging from trainers in sim-
ulated worlds to non player characters for
virtual games. In this paper we present a
novel algorithm for rapidly prototyping virtual
instruction-giving agents from human-human
corpora without manual annotation. Automat-
ically prototyping full-fledged dialogue sys-
tems from corpora is far from being a reality
nowadays. Our approach is restricted in that
only the virtual instructor can perform speech
acts while the user responses are limited to
physical actions in the virtual worlds.
We have defined an algorithm that, given a
task-based corpus situated in a virtual world,
which contains human instructor?s speech acts
and the user?s responses as physical actions,
generates a virtual instructor that robustly
helps a user achieve a given task in the vir-
tual world. We explain how this algorithm
can be used for generating a virtual instructor
for a game-like, task-oriented virtual world.
We evaluate the virtual instructor with human
users using task-oriented as well as user satis-
faction metrics. We compare our results with
both human and rule-based virtual instructors
hand-coded for the same task.
1 Introduction
Virtual human characters constitute a promising
contribution to many fields, including simulation,
training and interactive games (Kenny et al, 2007;
Jan et al, 2009). The ability to communicate using
natural language is important for believable and ef-
fective virtual humans. Such ability has to be good
enough to engage the trainee or the gamer in the ac-
tivity. Nowadays, most conversational systems oper-
ate on a dialogue-act level and require extensive an-
notation efforts in order to be fit for their task (Rieser
and Lemon, 2010). Semantic annotation and rule
authoring have long been known as bottlenecks for
developing conversational systems for new domains.
In this paper, we present a novel algorithm for
generating virtual instructors from automatically an-
notated human-human corpora. Our algorithm,
when given a task-based corpus situated in a virtual
world, generates an instructor that robustly helps a
user achieve a given task in the virtual world of the
corpus. There are two main approaches toward au-
tomatically producing dialogue utterances. One is
the selection approach, in which the task is to pick
the appropriate output from a corpus of possible out-
puts. The other is the generation approach, in which
the output is dynamically assembled using some
composition procedure, e.g. grammar rules. The se-
lection approach to generation has only been used
in conversational systems that are not task-oriented
such as negotiating agents (Gandhe and Traum,
2007a), question answering characters (Kenny et al,
2007), and virtual patients (Leuski et al, 2006). To
the best of our knowledge, our algorithm is the first
one proposed for doing corpus based generation and
interaction management for task-oriented systems.
The advantages of corpus based generation are
many. To start with, it affords the use of complex
and human-like sentences without detailed analysis.
Moreover, the system may easily use recorded au-
dio clips rather than speech synthesis and recorded
video for animating virtual humans. Finally, no
68
rule writing by a dialogue expert or manual an-
notations is needed. The disadvantage of corpus
based generation is that the resulting dialogue may
not be fully coherent. For non-task oriented sys-
tems, dialogue management through corpus based
methods has shown coherence related problems.
Shawar and Atwell (2003; 2005) present a method
for learning pattern matching rules from corpora in
order to obtain the dialogue manager for a chat-
bot. Gandhe and Traum (2007b) investigate several
dialogue models for negotiating virtual agents that
are trained on an unannotated human-human corpus.
Both approaches report that the dialogues obtained
by these methods are still to be improved because
the lack of dialogue history management results in
incoherences. Since in task-based systems, the di-
alogue history is restricted by the structure of the
task, the absence of dialogue history management is
alleviated by tracking the current state of the task.
In the next section we introduce the corpora used
in this paper. Section 3 presents the two phases of
our algorithm, namely automatic annotation and di-
alogue management through selection. In Section 4
we present a fragment of an interaction with a virtual
instructor generated using the corpus and the algo-
rithm introduced in the previous sections. We evalu-
ate the virtual instructor in interactions with human
subjects using objective as well as subjective met-
rics. We present the results of the evaluation in Sec-
tion 5. We compare our results with both human
and rule-based virtual instructors hand-coded for the
same task. Finally, Section 7 discusses the weak-
nesses of the approach for developing instruction
giving agents, as well as its advantages and draw-
backs with respect to hand-coded systems. In this
last section we also discuss improvements on our al-
gorithms designed as a result of our error analysis.
2 The GIVE corpus
The Challenge on Generating Instructions in Vir-
tual Environments (GIVE; Koller et al (2010)) is
a shared task in which Natural Language Gener-
ation systems must generate real-time instructions
that guide a user in a virtual world. In this paper,
we use the GIVE-2 Corpus (Gargett et al, 2010), a
freely available corpus of human instruction giving
in virtual environments. We use the English part of
the corpus which consists of 63 American English
written discourses in which one subject guided an-
other in a treasure hunting task in 3 different 3D
worlds.
The task setup involved pairs of human partners,
each of whom played one of two different roles. The
?direction follower? (DF) moved about in the vir-
tual world with the goal of completing a treasure
hunting task, but had no knowledge of the map of
the world or the specific behavior of objects within
that world (such as, which buttons to press to open
doors). The other partner acted as the ?direction
giver? (DG), who was given complete knowledge of
the world and had to give instructions to the DF to
guide him/her to accomplish the task.
The GIVE-2 corpus is a multi-modal corpus
which consists of all the instructions uttered by the
DG, and all the object manipulations done by the DF
with the corresponding timestamp. Furthermore, the
DF?s position and orientation is logged every 200
milliseconds, making it possible to extract informa-
tion about his/her movements.
3 The unsupervised conversational model
Our algorithm consists of two phases: an annotation
phase and a selection phase. The annotation phase
is performed only once and consists of automatically
associating the DG instruction to the DF reaction.
The selection phase is performed every time the vir-
tual instructor generates an instruction and consists
of picking out from the annotated corpus the most
appropriate instruction at a given point.
3.1 The automatic annotation
The basic idea of the annotation is straightforward:
associate each utterance with its corresponding re-
action. We assume that a reaction captures the se-
mantics of its associated instruction. Defining re-
action involves two subtle issues, namely boundary
determination and discretization. We discuss these
issues in turn and then give a formal definition of
reaction.
We define the boundaries of a reaction as follows.
A reaction Rk to an instruction Uk begins right af-
ter the instruction Uk is uttered and ends right before
the next instruction Uk+1 is uttered. In the follow-
ing example, instruction 1 corresponds to the reac-
69
tion ?2, 3, 4?, instruction 5 corresponds to ?6?, and
instruction 7 to ?8?.
DG(1): hit the red you see in the far room
DF(2): [enters the far room]
DF(3): [pushes the red button]
DF(4): [turns right]
DG(5): hit far side green
DF(6): [moves next to the wrong green]
DG(7): no
DF(8): [moves to the right green and pushes it]
As the example shows, our definition of bound-
aries is not always semantically correct. For in-
stance, it can be argued that it includes too much
because 4 is not strictly part of the semantics of 1.
Furthermore, misinterpreted instructions (as 5) and
corrections (e.g., 7) result in clearly inappropriate
instruction-reaction associations. Since we want to
avoid any manual annotation, we decided to use this
naive definition of boundaries anyway. We discuss
in Section 5 the impact that inappropriate associa-
tions have on the performance of a virtual instructor.
The second issue that we address here is dis-
cretization of the reaction. It is well known that there
is not a unique way to discretize an action into sub-
actions. For example, we could decompose action 2
into ?enter the room? or into ?get close to the door
and pass the door?. Our algorithm is not dependent
on a particular discretization. However, the same
discretization mechanism used for annotation has to
be used during selection, for the dialogue manager
to work properly. For selection (i.e., in order to de-
cide what to say next) any virtual instructor needs
to have a planner and a planning problem: i.e., a
specification of how the virtual world works (i.e.,
the actions), a way to represent the states of the vir-
tual world (i.e., the state representation) and a way
to represent the objective of the task (i.e., the goal).
Therefore, we decided to use them in order to dis-
cretize the reaction.
For the virtual instructor we present in Section 4
we used the planner LazyFF and the planning prob-
lem provided with the GIVE Framework. The
planner LazyFF is a reimplementation (in Java) of
the classical artificial intelligence planner FF (Hoff-
mann and Nebel, 2001). The GIVE framework (Gar-
gett et al, 2010) provides a standard PDDL (Hsu et
al., 2006) planning problem which formalizes how
the GIVE virtual worlds work. Both the LazzyFF
planner and the GIVE planning problem are freely
available on the web1.
Now we are ready to define reaction formally. Let
Sk be the state of the virtual world when uttering in-
struction Uk, Sk+1 be the state of the world when ut-
tering the next utterance Uk+1 and Acts be the rep-
resentation of the virtual world actions. The reaction
to Uk is defined as the sequence of actions returned
by the planner with Sk as the initial state, Sk+1 as
the goal state and Acts as the actions.
Given this reaction definition, the annotation of
the corpus then consists of automatically associat-
ing each utterance to its (discretized) reaction. The
simple algorithm that implements this annotation is
shown in Figure 1. Moreover, we provide a fragment
of the resulting annotated corpus in Appendix A.
1: Acts? world possible actions
2: for all utterance Uk in the corpus do
3: Sk ? world state at Uk
4: Sk+1 ? world state at Uk+1
5: Uk.Reaction? plan(Sk, Sk+1, Acts)
6: end for
Figure 1: Annotation algorithm
3.2 Selecting what to say next
In this section we describe how the selection phase is
performed every time the virtual instructor generates
an instruction.
The instruction selection algorithm, displayed in
Figure 2, consists in finding in the corpus the set of
candidate utterances C for the current task plan P
(P is the sequence of actions that needs to be exe-
cuted in the current state of the virtual world in or-
der to complete the task). We define C = {U ?
Corpus | P starts with U.Reaction}. In other words,
an utterance U belongs to C if the first actions of the
current plan P exactly match the reaction associated
to the utterance U . All the utterances that pass this
test are considered paraphrases and hence suitable in
the current context.
Whenever the plan P changes, as a result of the
actions of the DF, we call the selection algorithm in
order to regenerate the set of candidate utterances C.
1http://www.give-challenge.org/
70
1: C ? ?
2: Plan? current task plan
3: for all utterance U in the corpus do
4: if Plan starts with U.Reaction then
5: C ? C ? {U}
6: end if
7: end for
8: return C
Figure 2: Selection algorithm
While the plan P doesn?t change, because the
DF is staying still, the virtual instructor offers al-
ternative paraphrases of the intended instruction.
Each paraphrase is selected by picking an utterance
from C and verbalizing it, at fixed time intervals
(every 3 seconds). The order in which utterances
are selected depends on the length of the utterance
reaction (in terms of number of actions), starting
from the longest ones. Hence, in general, instruc-
tions such as ?go back again to the room with the
lamp? are uttered before instructions such as ?go
straight?, because the reaction of the former utter-
ance is longer than the reaction of the later.
It is important to notice that the discretization
used for annotation and selection directly impacts
the behavior of the virtual instructor. It is crucial
then to find an appropriate granularity of the dis-
cretization. If the granularity is too coarse, many
instructions in the corpus will have an empty reac-
tion. For instance, in the absence of the representa-
tion of the user orientation in the planning domain
(as is the case for the virtual instructor we evaluate
in Section 5), instructions like ?turn left? and ?turn
right? will have empty reactions making them indis-
tinguishable during selection. However, if the gran-
ularity is too fine the user may get into situations
that do not occur in the corpus, causing the selec-
tion algorithm to return an empty set of candidate
utterances. It is the responsibility of the virtual in-
structor developer to find a granularity sufficient to
capture the diversity of the instructions he wants to
distinguish during selection.
4 A virtual instructor for a virtual world
We implemented an English virtual instructor for
one of the worlds used in the corpus collection we
presented in Section 2. The English fragment of the
corpus that we used has 21 interactions and a total
of 1136 instructions. Games consisted on average
of 54.2 instructions from the human DG, and took
about 543 seconds on average for the human DF to
complete the task.
On Figures 4 to 7 we show an excerpt of an in-
teraction between the system and a user. The fig-
ures show a 2D map from top view and the 3D in-
game view. In Figure 4, the user, represented by a
blue character, has just entered the upper left room.
He has to push the button close to the chair. The
first candidate utterance selected is ?red closest to
the chair in front of you?. Notice that the referring
expression uniquely identifies the target object us-
ing the spatial proximity of the target to the chair.
This referring expression is generated without any
reasoning on the target distractors, just by consid-
ering the current state of the task plan and the user
position.
Figure 4: ?red closest to the chair in front of you?
After receiving the instruction the user gets closer
to the button as shown in Figure 5. As a result of the
new user position, a new task plan exists, the set of
candidate utterances is recalculated and the system
selects a new utterance, namely ?the closet one?.
The generation of the ellipsis of the button or the
chair is a direct consequence of the utterances nor-
mally said in the corpus at this stage of the task plan
(that is, when the user is about to manipulate this ob-
ject). From the point of view of referring expression
algorithms, the referring expression may not be op-
timal because it is over-specified (a pronoun would
71
L go
yes left
straight now go back
go back out now go back out
closest the door down the passage
go back to the hallway nowin to the shade room
go back out of the room out the way you came in
exit the way you entered ok now go out the same door
back to the room with the lamp go back to the door you came in
Go through the opening on the left okay now go back to the original room
okay now go back to where you came from ok go back again to the room with the lamp
now i ned u to go back to the original room Go through the opening on the left with the yellow wall paper
Figure 3: All candidate selected utterances when exiting the room in Figure 7
Figure 5: ?the closet one?
Figure 6: ?good?
be preferred as in ?click it?), Furthermore, the in-
struction contains a spelling error (?closet? instead
Figure 7: ?go back to the room with the lamp?
of ?closest?). In spite of this non optimality, the in-
struction led our user to execute the intended reac-
tion, namely pushing the button.
Right after the user clicks on the button (Figure 6),
the system selects an utterance corresponding to the
new task plan. The player position stayed the same
so the only change in the plan is that the button no
longer needs to be pushed. In this task state, DGs
usually give acknowledgements and this is then what
our selection algorithm selects: ?good?.
After receiving the acknowledgement, the user
turns around and walks forward, and the next ac-
tion in the plan is to leave the room (Figure 7). The
system selects the utterance ?go back to the room
with the lamp? which refers to the previous interac-
tion. Again, the system keeps no representation of
the past actions of the user, but such utterances are
the ones that are found at this stage of the task plan.
72
We show in Figure 3 all candidate utterances se-
lected when exiting the room in Figure 7. That is,
for our system purposes, all the utterances in the fig-
ure are paraphrases of the one that is actually uttered
in Figure 7. As we explained in Section 3.2, the
utterance with the longest reaction is selected first
(?go back to the room with the lamp?), the second
utterance with the longest reaction is selected sec-
ond (?ok go back again to the room with the lamp?),
and so on. As you can observe in Figure 3 the ut-
terances in the candidate set can range from tele-
graphic style like ?L? to complex sentences like ?Go
through the opening on the left with the yellow wall
paper?. Several kinds of instructions are displayed,
acknowledgements such as ?yes?, pure moving in-
structions like ?left? or ?straight?, instructions that
refer to the local previous history such as ?go back
out the room? or ?ok now go out the same door? and
instructions that refer back to the global history such
as ?okay now go back to the original room?.
Due to the lack of orientation consideration in our
system, some orientation dependent utterances are
inappropriate in this particular context. For instance,
?left? is incorrect given that the player does not have
to turn left but go straight in order to go through
the correct door. However, most of the instructions,
even if quite different among themselves, could have
been successfully used in the context of Figure 7.
5 Evaluation and error analysis
In this section we present the results of the evalu-
ation we carried out on the virtual instructor pre-
sented in Section 4 which was generated using the
dialogue model algorithm introduced in Section 3.
We collected data from 13 subjects. The partici-
pants were mostly graduate students; 7 female and
6 male. They were not English native speakers but
rated their English skills as near-native or very good.
The evaluation contains both objective measures
which we discuss in Section 5.1 and subjective mea-
sures which we discuss in Section 5.2.
5.1 Objective metrics
The objective metrics we extracted from the logs of
interaction are summarized in Table 1. The table
compares our results with both human instructors
and the three rule-based virtual instructors that were
top rated in the GIVE-2 Challenge. Their results cor-
respond to those published in (Koller et al, 2010)
which were collected not in a laboratory but con-
necting the systems to users over the Internet. These
hand-coded systems are called NA, NM and Saar.
We refer to our system as OUR.
Human NA Saar NM OUR
Task success 100% 47% 40% 30% 70%
Canceled 0% 24% n/a 35% 7%
Lost 0% 29% n/a 35% 23%
Time (sec) 543 344 467 435 692
Mouse actions 12 17 17 18 14
Utterances 53 224 244 244 194
Table 1: Results for the objective metrics
In the table we show the percentage of games that
users completed successfully with the different in-
structors. Unsuccessful games can be either can-
celed or lost. We also measured the average time
until task completion, and the average number of ut-
terances users received from each system. To ensure
comparability, we only counted successfully com-
pleted games.
In terms of task success, our system performs bet-
ter than all hand-coded systems. We duly notice that,
for the GIVE Challenge in particular (and proba-
bly for human evaluations in general) the success
rates in the laboratory tend to be higher than the suc-
cess rate online (this is also the case for completion
times) (Koller et al, 2009). Koller et al justify this
difference by stating that the laboratory subject is
being discouraged from canceling a frustrating task
while the online user is not. However, it is also pos-
sible that people canceled less because they found
the interaction more natural and engaging as sug-
gested by the results of the subjective metrics (see
next section).
In any case, our results are preliminary given the
amount of subjects that we tested, but they are in-
deed encouraging. In particular, our system helped
users to identify better the objects that they needed
to manipulate in the virtual world, as shown by the
low number of mouse actions required to complete
the task (a high number indicates that the user must
have manipulated wrong objects). This correlates
with the subjective evaluation of referring expres-
sion quality (see next section).
73
We performed a detailed analysis of the instruc-
tions uttered by our system that were unsuccessful,
that is, all the instructions that did not cause the in-
tended reaction as annotated in the corpus. From the
2081 instructions uttered in total (adding all the ut-
terances of the 13 interactions), 1304 (63%) of them
were successful and 777 (37%) were unsuccessful.
Given the limitations of the annotation discussed
in Section 3.1 (wrong annotation of correction utter-
ances and no representation of user orientation) we
classified the unsuccessful utterances using lexical
cues into 1) correction like ?no? or ?wrong?, 2) ori-
entation instruction such as ?left? or ?straight?, and
3) other. We found that 25% of the unsuccessful ut-
terances are of type 1, 40% are type 2, 34% are type
3 (1% corresponds to the default utterance ?go? that
our system utters when the set of candidate utter-
ances is empty). In Section 7 we propose an im-
proved virtual instructor designed as a result of this
error analysis.
5.2 Subjective metrics
The subjective measures were obtained from re-
sponses to the GIVE-2 questionnaire that was pre-
sented to users after each game. It asked users to rate
different statements about the system using a contin-
uous slider. The slider position was translated to a
number between -100 and 100. As done in GIVE-
2, for negative statements, we report the reversed
scores, so that in Tables 2 and 3 greater numbers
indicates that the system is better (for example, Q14
shows that OUR system is less robotic than the rest).
In this section we compare our results with the sys-
tems NA, Saar and NM as we did in Section 5.1, we
cannot compare against human instructors because
these subjective metrics were not collected in (Gar-
gett et al, 2010).
The GIVE-2 Challenge questionnaire includes
twenty-two subjective metrics. Metrics Q1 to Q13
and Q22 assess the effectiveness and reliability of
instructions. For almost all of these metrics we got
similar or slightly lower results than those obtained
by the three hand-coded systems, except for three
metrics which we show in Table 2. We suspect that
the low results obtained for Q5 and Q22 relate to
the unsuccessful utterances identified and discussed
in Section 5.1 (for instance, corrections were some-
times contradictory causing confusion and resulting
in subjects ignoring them as they advanced in the in-
teraction). The high unexpected result in Q6, that
is indirectly assessing the quality of referring ex-
pressions, demonstrates the efficiency of the refer-
ring process despite the fact that nothing in the algo-
rithms is dedicated to reference. This good result is
probably correlated with the low number of mouse
actions mentioned in Section 5.1.
NA Saar NM OUR
Q5: I was confused about which direction to go in
29 5 9 -12
Q6: I had no difficulty with identifying the objects the
system described for me
18 20 13 40
Q22: I felt I could trust the system?s instructions
37 21 23 0
Table 2: Results for the significantly different subjective
measures assessing the effectiveness of the instructions
(the greater the number, the better the system)
Metrics Q14 to Q20 are intended to assess the nat-
uralness of the instructions, as well as the immer-
sion and engagement of the interaction. As Table 3
shows, in spite of the unsuccessful utterances, our
system is rated as more natural and more engaging
(in general) than the best systems that competed in
the GIVE-2 Challenge.
NA Saar NM OUR
Q14: The system?s instructions sounded robotic
-4 5 -1 28
Q15: The system?s instructions were repetitive
-31 -26 -28 -8
Q16: I really wanted to find that trophy
-11 -7 -8 7
Q17: I lost track of time while solving the task
-16 -11 -18 16
Q18: I enjoyed solving the task
-8 -5 -4 4
Q19: Interacting with the system was really annoying
8 -2 -2 4
Q20: I would recommend this game to a friend
-30 -25 -24 -28
Table 3: Results for the subjective measures assessing
the naturalness and engagement of the instructions (the
greater the number, the better the system)
74
6 Portability to other virtual environments
The hand-coded systems, which we compared to, do
not need a corpus in a particular GIVE virtual world
in order to generate instructions for any GIVE vir-
tual world, while our system cannot do without such
corpus. These hand-coded systems are designed to
work on different GIVE virtual worlds without the
need of training data, hence their algorithms are
more complex (e.g. they include domain indepen-
dent algorithms for generation of referring expres-
sions) and take a longer time to develop.
Our algorithm is independent of any particular
virtual world. In fact, it can be ported to any other
instruction giving task (where the DF has to per-
form a physical task) with the same effort than re-
quired to port it to a new GIVE world. This is not
true for the hand-coded GIVE systems. The inputs
of our algorithm are an off-the-shelf planner, a for-
mal planning problem representation of the task and
a human-human corpus collected on the very same
task the system aims to instruct. It is important to
notice that any virtual instructor, in order to give in-
structions that are both causally appropriate at the
point of the task and relevant for the goal cannot do
without such planning problem representation. Fur-
thermore, it is quite a normal practice nowadays to
collect a human-human corpus on the target task do-
main. It is reasonable, then, to assume that all the
inputs of our algorithm are already available when
developing the virtual instructor, which was indeed
the case for the GIVE framework.
Another advantage of our approach is that vir-
tual instructor can be generated by developers with-
out any knowledge of generation of natural language
techniques. Furthermore, the actual implementation
of our algorithms is extremely simple as shown in
Figures 1 and 2. This makes our approach promising
for application areas such as games and simulation
training.
7 Future work and conclusions
In this paper we presented a novel algorithm for
automatically prototyping virtual instructors from
human-human corpora without manual annotation.
Using our algorithms and the GIVE corpus we have
generated a virtual instructor for a game-like vir-
tual environment. A video of our virtual instruc-
tor is available in http://cs.famaf.unc.edu.ar/
?luciana/give-OUR. We obtained encouraging re-
sults in the evaluation with human users that we did
on the virtual instructor. In our evaluation, our sys-
tem outperforms rule-based virtual instructors hand-
coded for the same task both in terms of objective
and subjective metrics. We plan to participate in the
GIVE Challenge 20112 in order to get more evalua-
tion data from online users and to evaluate our algo-
rithms on multiple worlds.
The algorithms we presented solely rely on the
plan to define what constitutes the context of utter-
ing. It may be interesting though to make use of
other kinds of features. For instance, in order to inte-
grate spatial orientation and differentiate ?turn left?
and ?turn right?, the orientation can be either added
to the planning domain or treated as a context fea-
ture. While it may be possible to add orientation
in the planning domain of GIVE, it is not straight-
forward to include the diversity of possible features
in the same formalization, like modeling the global
discourse history or corrections. Thus we plan to in-
vestigate the possibility of considering the context of
an utterance as a set of features, including plan, ori-
entation, discourse history and so forth, in order to
extend the algorithms presented in terms of context
building and feature matching operations.
In the near future we plan to build a new version
of the system that improves based on the error anal-
ysis that we did. For instance, we plan to take ori-
entation into account during selection. As a result
of these extensions however we may need to enlarge
the corpus we used so as not to increase the number
of situations in which the system does not find any-
thing to say. Finally, if we could identify corrections
automatically, as suggested in (Raux and Nakano,
2010), we could get an increase in performance, be-
cause we would be able to treat them as corrections
and not as instructions as we do now.
In sum, this paper presents the first existing al-
gorithm for fully-automatically prototyping task-
oriented virtual agents from corpora. The generated
agents are able to effectively and naturally help a
user complete a task in a virtual world by giving
her/him instructions.
2http://www.give-challenge.org/research
75
References
Sudeep Gandhe and David Traum. 2007a. Creating spo-
ken dialogue characters from corpora without annota-
tions. In Proceedings of 8th Conference in the Annual
Series of Interspeech Events, pages 2201?2204, Bel-
gium.
Sudeep Gandhe and David Traum. 2007b. First
steps toward dialogue modelling from an un-annotated
human-human corpus. In IJCAI Workshop on Knowl-
edge and Reasoning in Practical Dialogue Systems,
Hyderabad, India.
Andrew Gargett, Konstantina Garoufi, Alexander Koller,
and Kristina Striegnitz. 2010. The GIVE-2 corpus
of giving instructions in virtual environments. In Pro-
ceedings of the 7th International Conference on Lan-
guage Resources and Evaluation (LREC), Malta.
Jo?rg Hoffmann and Bernhard Nebel. 2001. The FF plan-
ning system: Fast plan generation through heuristic
search. JAIR, 14:253?302.
Chih-Wei Hsu, Benjamin W. Wah, Ruoyun Huang,
and Yixin Chen. 2006. New features in SGPlan
for handling soft constraints and goal preferences in
PDDL3.0. In Proceedings of ICAPS.
Dusan Jan, Antonio Roque, Anton Leuski, Jacki Morie,
and David Traum. 2009. A virtual tour guide for vir-
tual worlds. In Proceedings of the 9th International
Conference on Intelligent Virtual Agents, IVA ?09,
pages 372?378, Berlin, Heidelberg. Springer-Verlag.
Patrick Kenny, Thomas D. Parsons, Jonathan Gratch, An-
ton Leuski, and Albert A. Rizzo. 2007. Virtual pa-
tients for clinical therapist skills training. In Proceed-
ings of the 7th international conference on Intelligent
Virtual Agents, IVA ?07, pages 197?210, Berlin, Hei-
delberg. Springer-Verlag.
Alexander Koller, Kristina Striegnitz, Donna Byron, Jus-
tine Cassell, Robert Dale, Sara Dalzel-Job, Johanna
Moore, and Jon Oberlander. 2009. Validating the
web-based evaluation of nlg systems. In Proceedings
of ACL-IJCNLP 2009 (Short Papers), Singapore.
Alexander Koller, Kristina Striegnitz, Andrew Gargett,
Donna Byron, Justine Cassell, Robert Dale, Johanna
Moore, and Jon Oberlander. 2010. Report on the sec-
ond NLG challenge on generating instructions in vir-
tual environments (GIVE-2). In Proceedings of the In-
ternational Natural Language Generation Conference
(INLG), Dublin.
Anton Leuski, Ronakkumar Patel, David Traum, and
Brandon Kennedy. 2006. Building effective question
answering characters. In Proceedings of the 7th SIG-
dial Workshop on Discourse and Dialogue, SigDIAL
?06, pages 18?27, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Antoine Raux and Mikio Nakano. 2010. The dynam-
ics of action corrections in situated interaction. In
Proceedings of the SIGDIAL 2010 Conference, pages
165?174, Tokyo, Japan, September. Association for
Computational Linguistics.
Verena Rieser and Oliver Lemon. 2010. Learning hu-
man multimodal dialogue strategies. Natural Lan-
guage Engineering, 16:3?23.
Bayan Abu Shawar and Eric Atwell. 2003. Using di-
alogue corpora to retrain a chatbot system. In Pro-
ceedings of the Corpus Linguistics Conference, pages
681?690, United Kingdom.
Bayan Abu Shawar and Eric Atwell. 2005. Using cor-
pora in machine-learning chatbot systems. volume 10,
pages 489?516.
76
A Automatically annotated fragment of the GIVE corpus
Utterance: make a left and exit the room
Reaction: ?move(b2-room-1-9,room-1-9), move(room-1-9,room-1-8), move(room-1-8,room-1-7),
move(room-1-7,room-1-6), move(room-1-6,room-1-3), move(room-1-3,room-1-4),
move(room-1-4,room-1-5), move(room-1-5,d3-room-1-5)?
Utterance: go forward and turn 90 degrees
Reaction: ?move(d3-room-1-5,d3-room-2), move(d3-room-2,room-2)?
Utterance: go into the room on the right
Reaction: ?move(room-2,d6-room-2), move(d6-room-2,a2-d6-room-3), move(a2-d6-room-3,room-3)?
Utterance: push the green button to the left of the red button
Reaction: ?move(room-3,b6-room-3), manipulate-stateless(b6), move(b6-room-3,room-3)?
Utterance: go into the room on your right
Reaction: ?move(room-3,d11-room-3), move(d11-room-3,d11-room-7), move(d11-room-7,room-7)?
Utterance: turn 90 degrees right and push the red button
Reaction: ?move(room-7,b11-room-7), manipulate(b11), move(b11-room-7,room-7)?
Utterance: on your right, push the yellow button
Reaction: ?move(room-7,b10-room-7), manipulate-stateless(b10), move(b10-room-7,room-7)?
Utterance: turn 180 degrees and push the red button next to the plant
Reaction: ?move(room-7,b12-room-7), manipulate-stateless(b12), move(b12-room-7,room-7)?
Utterance: turn 180 degrees and push the blue button in the middle of the yellow and blue button
Reaction: ?move(room-7,b8-b9-room-7), manipulate-stateless(b9), move(b8-b9-room-7,room-7)?
Utterance: turn 90 degrees left
Reaction: ??
Utterance: go into the room on the right
Reaction: ?move(room-7,d10-room-7), move(d10-room-7,d10-room-6), move(d10-room-6,room-6)?
Utterance: turn right and proceed down the room
Reaction: ??
Utterance: push the red button next to the blue button on your right
Reaction: ?move(room-6,b13-b14-room-6), manipulate(b14), move(b13-b14-room-6,room-6)?
Utterance: turn left 120 degrees left
Reaction: ??
Utterance: and walk through the hall
Reaction: ?move(room-6,d9-room-6), move(d9-room-6,d9-room-5), move(d9-room-5,room-5)?
77
