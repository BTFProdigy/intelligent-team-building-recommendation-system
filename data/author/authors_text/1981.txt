Proceedings of the 5th Workshop on Important Unresolved Matters, pages 136?143,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Validation and Regression Testing for a Cross-linguisic Grammar Resource
Emily M. Bender, Laurie Poulson, Scott Drellishak, Chris Evans
University of Washington
Department of Linguistics
Seattle WA 98195-4340 USA
{ebender,lpoulson,sfd,chrisev@u.washington.edu}
Abstract
We present a validation methodology for
a cross-linguistic grammar resource which
produces output in the form of small gram-
mars based on elicited typological descrip-
tions. Evaluating the resource entails sam-
pling from a very large space of language
types, the type and range of which preclude
the use of standard test suites development
techniques. We produce a database from
which gold standard test suites for these
grammars can be generated on demand, in-
cluding well-formed strings paired with all
of their valid semantic representations as
well as a sample of ill-formed strings. These
string-semantics pairs are selected from a
set of candidates by a system of regular-
expression based filters. The filters amount
to an alternative grammar building system,
whose generative capacity is limited com-
pared to the actual grammars. We perform
error analysis of the discrepancies between
the test suites and grammars for a range of
language types, and update both systems ap-
propriately. The resulting resource serves as
a point of comparison for regression testing
in future development.
1 Introduction
The development and maintenance of test suites is
integral to the process of writing deep linguistic
grammars (Oepen and Flickinger, 1998; Butt and
King, 2003). Such test suites typically contain hand-
constructed examples illustrating the grammatical
phenomena treated by the grammar as well as rep-
resentative examples taken from texts from the tar-
get domain. In combination with test suite manage-
ment software such as [incr tsdb()] (Oepen, 2002),
they are used for validation and regression testing of
precision (deep linguistic) grammars as well as the
exploration of potential changes to the grammar.
In this paper, we consider what happens when the
precision grammar resource being developed isn?t a
grammar of a particular language, but rather a cross-
linguistic grammar resource. In particular, we con-
sider the LinGO Grammar Matrix (Bender et al,
2002; Bender and Flickinger, 2005). There are sev-
eral (related) obstacles to making effective use of
test suites in this scenario: (1) The Matrix core
grammar isn?t itself a grammar, and therefore can?t
parse any strings. (2) There is no single language
modeled by the cross-linguistic resource from which
to draw test strings. (3) The space of possible gram-
mars (alternatively, language types) modeled by the
resource is enormous, well beyond the scope of what
can be thoroughly explored.
We present a methodology for the validation and
regression testing of the Grammar Matrix that ad-
dresses these obstacles, developing the ideas origi-
nally proposed in (Poulson, 2006). In its broad out-
lines, our methodology looks like this:
? Define an abstract vocabulary to be used for test
suite purposes.
? Define an initial small set of string-semantics
pairs.
? Construct a large set of variations on the string-
semantics pairs.
136
? Define a set of filters that can delineate the le-
gitimate string-semantics pairs for a particular
language type
The filters in effect constitute a parallel grammar
definition system, albeit one that creates ?grammars?
of very limited generative capacity. As such, the out-
put of the filters cannot be taken as ground truth.
Rather, it serves as a point of comparison that al-
lows us to find discrepancies between the filters and
the Grammar Matrix which in turn can lead us to
errors in the Grammar Matrix.
2 Background
The Grammar Matrix is an open-source starter kit
designed to jump-start the development of broad-
coverage precision grammars, capable of both pars-
ing and generation and suitable for use in a vari-
ety of NLP applications. The Grammar Matrix is
written within the HPSG framework (Pollard and
Sag, 1994), using Minimal Recursion Semantics
(Copestake et al, 2005) for the semantic represen-
tations. The particular formalism we use is TDL
(type description language) as interpreted by the
LKB (Copestake, 2002) grammar development en-
vironment. Initial work on the Matrix (Bender et
al., 2002; Flickinger and Bender, 2003) focused on
the development of a cross-linguistic core grammar.
The core grammar provides a solid foundation for
sustained development of linguistically-motivated
yet computationally tractable grammars (e.g., (Hel-
lan and Haugereid, 2003; Kordoni and Neu, 2005)).
However, the core grammar alone cannot parse
and generate sentences: it needs to be specialized
with language-specific information such as the or-
der of daughters in its rules (e.g., head-subject or
subject-head), and it needs a lexicon. Although
word order and many other phenomena vary across
languages, there are still recurring patterns. To al-
low reuse of grammar code across languages and to
increase the size of the jump-start provided by the
Matrix, in more recent work (Bender and Flickinger,
2005; Drellishak and Bender, 2005), we have been
developing ?libraries? implementing realizations of
various linguistic phenomena. Through a web in-
terface, grammar developers can configure an initial
starter grammar by filling out a typological question-
naire about their language, which in turn calls a CGI
script to ?compile? a grammar (including language-
specific rule types, lexical entry types, rule entries,
and lexical entries) by making appropriate selections
from the libraries. These little grammars describe
very small fragments of the languages they model,
but they are not toys. Their purpose is to be good
starting points for further development.
The initial set of libraries includes: basic word or-
der of major constituents in matrix clauses (SOV et
al), optionality/obligatoriness of determiners, noun-
determiner order, NP v. PP arguments of intransitive
and transitive verbs, strategies for expressing senten-
tial negation and yes-no questions, and strategies for
constituent coordination. Even with this small set of
phenomena covered (and limiting ourselves for test-
ing purposes to maximally two coordination strate-
gies per language), we have already defined a space
of hundreds of thousands of possible grammars.1
3 The Non-modularity of Linguistic
Phenomena
In this section we discuss our findings so far about
the non-modularity of linguistic phenomena, and ar-
gue that this makes the testing of a broad sample of
grammars even more pressing.
The Grammar Matrix customization system reads
in the user?s language specification and then outputs
language-specific definitions of types (rule types,
lexical entry types and ancillary structures) that in-
herit from types defined in the crosslinguistic core
of the Matrix but add constraints appropriate for the
language at hand. Usability considerations put two
important constraints on this system: (1) The ques-
tions must be ones that are sensible to linguists, who
tend to consider phenomena one at a time. (2) The
output grammar code must be both readable and
maintainable. To achieve readable grammar code
in the output TDL, among other things, we follow
the guideline that any given constraint is stated only
once. If multiple types require the same constraint,
they should all inherit from some supertype bearing
that constraint. In addition, all constraints pertaining
to a particular type are stated in one place.
In light of the these usability considerations, we
1If all of the choices in the customization system were in-
dependent, we would have more than 2 x 1027 grammars. In
actuality, constraints on possible combinations of choices limit
this space considerably.
137
comp-head-phrase := basic-head-1st-comp-phrase & head-final.
subj-head-phrase := basic-head-subj-phrase & head-final &
[ HEAD-DTR.SYNSEM.LOCAL.CAT.VAL.COMPS < > ].
Figure 1: Specialized phrase structure rule types for SOV language
have found that it is not possible to treat the li-
braries as black-box modules with respect to each
other. The libraries are interdependent, and the por-
tions of the script that interpret one part of the input
questionnaire frequently need to make reference to
information elicited by other parts of the question-
naire. For example, the customization system imple-
ments major constituent word order by specializing
the head-complement and head-subject rule types
provided in the core grammar. In an SOV language,
these would both be cross-classified with the type
head-final, and the head-subject rule would further
be constrained to take only complement-saturated
phrases as its head daughter. The TDL encoding of
these constraints is shown in Figure 1.
Following standard practice in HPSG, we use the
head-complement phrase not only for ordinary VPs,
but also for PPs, CPs, and auxiliary-headed VPs,
etc. Consider Polish, a free word order language that
nonetheless has prepositions. To allow complements
on either side of the head, we instantiate both head-
comp and comp-head rules, inheriting from head-
initial and head-final respectively. Yet the preposi-
tions must be barred from the head-final version lest
the grammar license postpositional phrases by mis-
take. We do this by constraining the HEAD value of
the comp-head phrase. Similarly, question particles
(such as est-ce que in French or ma in Mandarin)
are treated as complementizers: heads that select for
an S complement. Since these, too, may differ in
their word order properties from verbs (and preposi-
tions), we need information about the question par-
ticles (elicited with the rest of the information about
yes-no questions) before we have complete informa-
tion about the head-complement rule. Furthermore,
it is not simply a question of adding constraints to
existing types. Consider the case of an SOV lan-
guage with prepositions and sentence-initial ques-
tion particles. This language would need a head-
initial head-comp rule that can take only preposi-
tions and complementizers as its head. To express
the disjunction, we must use the supertype to prep
and comp. This, in turn, means that we can?t decide
what constraint to put on the head value of the head-
comp rule until we?ve considered questions as well
as the basic word order facts.
We expect to study the issue of (non-)modularity
as we add additional libraries to the resource and to
investigate whether the grammar code can be refac-
tored in such a way as to make the libraries into true
modules. We suspect it might be possible to reduce
the degree of interdependence, but not to achieve
completely independent libraries, because syntactic
phenomena are inherently interdependent. Agree-
ment in NP coordination provides an example. In
English and many other languages, coordinated NPs
are always plural and the person of the coordinated
NP is the minimal person value of the coordinands.
(1) a. A cat and a dog are/*is chasing a mouse.
b. Kim and I should handle this ourselves.
c. You and Kim should handle this yourselves.
Gender systems often display a similar hierarchy of
values, as with French coordinated NPs, where the
whole NP is feminine iff all coordinands are femi-
nine and masculine otherwise. Thus it appears that
it is not possible to define all of the necessary con-
straints on the coordination rules without having ac-
cess to information about the agreement system.
Even if we were able to make our analyses of
different linguistic phenomena completely modular,
however, we would still need to test their interaction
in the analysis of particular sentences. Any sentence
that illustrates sentential negation, a matrix yes-no
question, or coordination also necessarily illustrates
at least some aspects of word order, the presence
v. absence of determiners and case-marking adpo-
sitions, and the subcategorization of the verb that
heads the sentence. Furthermore, broad-coverage
grammars need to allow negation, questions, coor-
dination etc. all to appear in the same sentence.
Given this non-modularity, we would ideally like
to be able to validate (and do regression testing on)
the full set of grammars generable by the customiza-
138
Form Description Options
det determiner
n1, n2 nouns det is optional, obligatory, impossible
iv, tv intransitive, transitive verb subj, obj are NP or PP
p-nom, p-acc case-marking adpositions preposition or postposition
neg negative element adverb, prefix, suffix
co1, co2 coordination marks word, prefix, suffix
qpart question particle
Table 1: Standardized lexicon
tion system. To approximate such thoroughness, we
instead sample from the grammar space.
4 Methodology
This section describes in some detail our methodol-
ogy for creating test suites on the basis of language-
type descriptions. A language type is a collection
of feature-value pairs representing a possible set
of answers to the Matrix customization question-
naire. We refer to these as language types rather
than languages, because the grammars produced by
the customization system are underspecified with re-
spect to actual languages, i.e., one and the same
starter grammar might be extended into multiple
models corresponding to multiple actual human lan-
guages. Accordingly, when we talk about the pre-
dicted (well)formedness, or (un)grammaticality, of a
candidate string, we are referring to its predicted sta-
tus with respect to a language type definition, not its
grammaticality in any particular (human) language.
4.1 Implementation: Python and MySQL
The test suite generation system includes a MySQL
database, a collection of Python scripts that interact
with the database, and some stored SQL queries. As
the set of items we are manipulating is quite large
(and will grow as new items are added to test ad-
ditional libraries), using a database is essential for
rapid retrieval of relevant items. Furthermore, the
database facilitates the separation of procedural and
declarative knowledge in the definition of the filters.
4.2 Abstract vocabulary for abstract strings
A grammar needs not just syntactic constructions
and lexical types, but also an actual lexicon. Since
we are working at the level of language types, we
are free to define this lexicon in whatever way is
most convenient. Much of the idiosyncrasy in lan-
guage resides in the lexicon, both in the form of mor-
phemes and in the particular grammatical and collo-
cational constraints associated with them. Of these
three, only the grammatical constraints are manip-
ulated in any interesting way within the Grammar
Matrix customization system. Therefore, for the test
suite, we define all of the language types to draw the
forms of their lexical items from a shared, standard-
ized vocabulary. Table 1 illustrates the vocabulary
along with the options that are currently available
for varying the grammatical constraints on the lex-
ical entries. Using the same word forms for each
grammar contributes substantially to building a sin-
gle resource that can be adapted for the testing of
each language type.
4.3 Constructing master item set
We use string to refer to a sequence of words to
be input to a grammar and result as the (expected)
semantic representation. An item is a particular
pair of string and result. Among strings, we have
seed strings provided by the Matrix developers to
seed the test suite, and constructed strings derived
from those seed strings. The constructor function
is the algorithm for deriving new strings from the
seed strings. Seed strings are arranged into seman-
tic equivalence classes, from which one representa-
tive is designated the harvester string. We parse the
harvester string with some appropriate grammar (de-
rived from the Matrix customization system) to ex-
tract the semantic representation (result) to be paired
with each member of the equivalence class.
The seed strings, when looked at as bags of words,
should cover all possible realizations of the phe-
nomenon treated by the library. For example, the
negation library allows both inflectional and adver-
bial negation, as well as negation expressed through
both inflection and an adverb together. To illustrate
139
negation of transitive sentences (allowing for lan-
guages with and without determiners2), we require
the seed strings in (2):
(2) Semtag: neg1 Semtag: neg2
n1 n2 neg tv det n1 det n2 neg tv
n1 n2 neg-tv det n1 det n2 neg-tv
n1 n2 tv-neg det n1 det n2 tv-neg
n1 n2 neg neg-tv det n1 det n2 neg neg-tv
n1 n2 neg tv-neg det n1 det n2 neg tv-neg
Sentential negation has the same semantic reflex
across all of its realizations, but the presence v. ab-
sence of overt determiners does have a semantic ef-
fect. Accordingly, the seed strings shown in (2) can
be grouped into two semantic equivalence classes,
shown as the first and second columns in the table,
and associated with the semantic tags ?neg1? and
?neg2?, respectively. The two strings in the first row
could be designated as the harvester strings, associ-
ated with a grammar for an SOV language with op-
tional determiners preceding the noun and sentential
negation expressed as a pre-head modifier of V.
We use the LKB in conjunction with [incr tsdb()]
to parse the harvester strings from all of the equiva-
lence classes with the appropriate grammars. Then
the seed strings and the parsing results from the har-
vester strings, as well as their semantic tags, are
stored and linked in our relational database. We use
the constructor function to create new strings from
these seed strings. This produces the master item set
that provides the basis for the test suites.
Currently, we have only one constructor function
(?permute?) which takes in a seed string and returns
all unique permutations of the morphemes in that
seed string.3 This constructor function is effective
in producing test items that cover the range of word
order variations currently permitted by the Grammar
Matrix customization system. Currently, most of the
other kinds of variation countenanced (e.g., adver-
bial v. inflectional negation or presence v. absence
of determiners) is handled through the initial seed
string construction. As the range of phenomena han-
dled by the customization system expands, we will
develop more sophisticated constructor functions to
2We require additional seed strings to account for languages
with and without case-marking adpositions
3
?permute? strips off any affixes, permutes the stems, and
then attaches the affixes to the stems in all possible ways.
handle, for example, the addition of all possible case
suffixes to each noun in the sentence.
4.4 Filters
The master item set provides us with an inventory
from which we can find positive (grammatical) ex-
amples for any language type generated by the sys-
tem as well as interesting negative examples for any
language type. To do so, we filter the master item
set, in two steps.
4.4.1 Universal Filters
The first step is the application of ?universal? fil-
ters, which mark any item known to be ungrammat-
ical across all language types currently produced by
the system. For example, the word order library does
not currently provide an analysis of radically non-
configurational languages with discontinuous NPs
(e.g., Warlpiri (Hale, 1981)). Accordingly, (3) will
be ungrammatical across all language types:
(3) det det n1 n2 tv
The universal filter definitions (provided by the
developers) each comprise one or more regular ex-
pressions, a filter type that specifies how the regular
expressions are to be applied, and a list of seman-
tic tags specifying which equivalence classes they
apply to. For example, the filter that would catch
example (3) above is defined as in (4):
(4) Filter Type: reject-unless-match
Regexp: (det (n1|n2).*det (n1|n2))|
(det (n1|n2).*(n1|n2) det)|
((n1|n2) det.*det (n1|n2))|
((n1|n2) det.*(n1|n2) det)
Sem-class: [semantic classes for all transitive
sentences with two determiners.]
We apply each filter to every item in the database.
For each filter whose semantic-class value includes
the semantic class of the item at hand, we store the
result (pass or fail) of the filter on that item. We can
then query the database to produce a list of all of the
potentially well-formed items.
4.4.2 Specific Filters
The next step is to run the filters that find the
grammatical examples for a particular language
type. In order to facilitate sampling of the entire
language space, we define these filters to be sensi-
tive not to complete language type definitions, but
140
rather to particular features (or small sets of fea-
tures) of a language type. Thus in addition to the
filter type, regular expression, and semantic class
fields, the language-specific filters also encode par-
tial descriptions of the language types to which they
apply, in the form of feature-value declarations. For
example, the filter in (5) plays a role in selecting
the correct form of negated sentences for language
types with both inflectional and adverbial negation
in complementary distribution (like English n?t and
sentential not). The first regular expression checks
for neg surrounded by white space (i.e., the negative
adverb) and the second for the negative affixes.
(5) Filter Type: reject-if-both-match
Regexp1: (\s|?)neg(\s|$)
Regexp2: -neg|neg-
Sem-class: [sem. classes for all neg. sent.]
Lg-feat: and(infl neg:on,adv neg:on,
multineg:comp)
This filter uses a conjunctive language feature spec-
ification (three feature-value pairs that must apply),
but disjunctions are also possible. These specifica-
tions are converted to disjunctive normal form be-
fore further processing.
As with the universal filters, the results of the spe-
cific filters are stored in the database. We process
each item that passed all of the universal filters with
each specific filter. Whenever a filter?s semantic-
class value matches the semantic-class of the item
at hand, we store the value assigned by the filter
(pass or fail). We also store the feature-value pairs
required by each filter, so that we can look up the
relevant filters for a language-type definition.
4.4.3 Recursive Linguistic Phenomena
Making the filters relative to particular semantic
classes allows us to use information about the lexi-
cal items in the sentences in the definition of the fil-
ters. This makes it easier to write regular-expression
based filters that can work across many different
complete language types. Complications arise, how-
ever, in examples illustrating recursive phenomena
To handle such phenomena with our finite-state sys-
tem, we do multiple passes with the filters. All items
with coordination are first processed with the co-
ordination filters, and then rewritten to replace any
well-formed coordinations with single constituents.
These rewritten strings are then processed with the
rest of the filters, and we store the results as the re-
sults for those filters on the original strings.
4.5 Language types
The final kind of information we store in the
database is definitions of language types. Even
though our system allows us to create test suites for
new language types on demand, we still store the
language-type definitions of language types we have
tested, for future regression testing purposes. When
a language type is read in, the list of feature-value
pairs defining it is compared to the list of feature-
groups declared by the filters. For each group of
feature-value pairs present in the language-type def-
inition, we find all of the filters that use that group.
We then query the database for all items that pass
the filters relevant to the language type. This list
of items represents all those in the master item set
predicted to be well-formed for this language type.
From the complement of this set, we also take a ran-
dom selection of items to test for overgeneration.
4.6 Validation of grammars
Once we have created the test suite for a partic-
ular language type, the developer runs the Matrix
customization system to get a starter grammar for
the same language type. The test suite is loaded
into [incr tsdb()] and processed with the grammar.
[incr tsdb()] allows the developer to compare the
grammar?s output with the test suite at varying lev-
els of detail: Do all and only the items predicted to
be well-formed parse? Do they get the same number
of readings as predicted? Do they get the semantic
representations predicted? A discrepancy at any of
these levels points to an error in either the Grammar
Matrix or the test suite generation system. The de-
veloper can query the database to find which filters
passed or failed a particular example as well as to
discover the provenance of the example and which
phenomena it is meant to test.
This methodology provides the ability to gener-
ate test suites for any arbitrary language type on de-
mand. Although this appears to eliminate the need to
store the test suites we do, in fact, store information
about previous test suites. This allows us to track the
evolution of the Grammar Matrix in relation to those
particular language types over time.
141
4.7 Investment and Return
The input required from the developer in order to test
any new library is as follows: (1) Seed strings illus-
trating the range of expressions handled by the new
library, organized into equivalence classes. (2) Des-
ignated harvester strings for each equivalence class
and a grammar or grammars that can parse them to
get the target semantic representation. (3) Universal
filters specific to the phenomenon and seed strings.
(4) Specific filters picking out the right items for
each language type. (5) Analysis of discrepancies
between the test suite and the generated grammars.
This is a substantial investment on the part of the de-
veloper but we believe the investment is worth it for
the return of being able to validate a library addition
and test for any loss of coverage going forward.
Arnold et al (1994) note that writing grammars
to generate test suites is impractical if the test suite
generating grammars aren?t substantially simpler to
write than the ?actual? grammars being tested. Even
though this system requires some effort to maintain,
we believe the methodology remains practical for
two reasons. First, the input required from the de-
veloper enumerated above is closely related to the
knowledge discovered in the course of building the
libraries in the first place. Second, the fact that the
filters are sensitive to only particular features of lan-
guage types means that a relatively small number of
filters can create test suites for a very large number
of language types.
5 Related Work
Kinyon and Rambow (2003) present an approach to
generating test suites on the basis of descriptions
of languages. The language descriptions are Meta-
Grammar (MG) hierarchies. Their approach appears
to be more flexible than the one presented here in
some ways, and more constrained in others. It does
not need any input strings, but rather produces test
items from the language description. In addition,
it annotates the output in multiple ways, including
phrase structure, dependency structure, and LFG F-
structure. On the other hand, there is no apparent
provision for creating negative (ungrammatical) test
data and it is does not appear possible to compose
new MG descriptions on the fly. Furthermore, the
focus of the MG test suite work appears to be the
generation of test suites for other grammar develop-
ment projects, but the MGs themselves are crosslin-
guistic resources in need of validation and testing.
An interesting area for future work would be the
comparison between the test suites generated by the
system described here and the MG test suites.
The key to the test-suite development process pro-
posed here is to leverage the work already being
done by the Matrix developers into a largely auto-
mated process for creating test-suite items. The in-
formation required from the developers is essentially
a structured and systematic version of the knowledge
that is required for the creation of libraries in the first
place. This basic approach, is also the basis for the
approach taken in (Bro?ker, 2000); the specific forms
of knowledge leveraged, and the test-suite develop-
ment strategies used, however, are quite different.
6 Future Work
The addition of the next library to the Grammar Ma-
trix will provide us with an opportunity to try to
quantify the effect of this methodology. With the
Grammar Matrix and the filters stabilized, the vali-
dation of a new library can be carefully tracked. We
can try to quantify the number of errors obtained and
the source of the errors, e.g., library or filters.
In addition to this kind of quantification and error
analysis as a means of validating this methodology,
we also intend to undertake a comparison of the test
suites created from our database to hand built cre-
ated for Matrix-derived grammars by students in the
multilingual grammar engineering course at the Uni-
versity of Washington.4 Students in this class each
develop grammars for a different language, and cre-
ate test suites of positive and negative examples as
part of their development process. We plan to use
the lexical types in the grammars to define a map-
ping from the surface lexical items used in the test
suites to our abstract vocabulary. We can then com-
pare the hand built and autogenerated test suites in
order to gauge the thoroughness of the system pre-
sented here.
7 Conclusion
The methodology outlined in this paper addresses
the three obstacles noted in the introduction: Al-
4http://courses.washington.edu/ling567
142
though the Grammar Matrix core itself isn?t a gram-
mar (1), we test it by deriving grammars from it.
Since we are testing the derived grammars, we are
simultaneously testing both the Matrix core gram-
mar, the libraries, and the customization script. Al-
though there is no single language being modeled
from which to draw strings (2), we can nonethe-
less find a relevant set of strings and associate
these strings with annotations of expected well-
formedness. The lexical formatives of the strings
are drawn from a standardized set of abstract forms.
The well-formedness predictions are made on the
basis of the system of filters. The system of filters
doesn?t represent ground truth, but rather a second
pathway to the judgments in addition to the direct
use of the Matrix-derived starter grammars. These
pathways are independent enough that the one can
serve as an error check on the other. The space of
possible language types remains too large for thor-
ough testing (3). However, since our system allows
for the efficient derivation of a test suite for any arbi-
trary language type, it is inexpensive to sample that
language-type space in many different ways.
Acknowledgments
This work has been supported by NSF grant BCS-
0644097.
References
Doug Arnold, Martin Rondell, and Frederik Fouvry.
1994. Design and implementation of test suite tools.
Technical Report LRE 62-089 D-WP5, University of
Essex, UK.
Emily M. Bender and Dan Flickinger. 2005. Rapid pro-
totyping of scalable grammars: Towards modularity in
extensions to a language-independent core. In Proc.
IJCNLP-05 (Posters/Demos).
Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2002. The grammar matrix: An open-source starter-
kit for the rapid development of cross-linguistically
consistent broad-coverage precision grammars. In
Proc. the Workshop on Grammar Engineering and
Evaluation COLING 2002, pages 8?14.
Norbert Bro?ker. 2000. The use of instrumentation in
grammar engineering. In Proc. COLING 2000, pages
118?124.
Miriam Butt and Tracy Holloway King. 2003. Gram-
mar writing, testing, and evaluation. In Handbook for
Language Engineers, pages 129?179. CSLI.
Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan A.
Sag. 2005. Minimal recursion semantics: An intro-
duction. Research on Language & Computation, 3(2?
3):281?332.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI.
Scott Drellishak and Emily M. Bender. 2005. A coordi-
nation module for a crosslinguistic grammar resource.
In Stefan Mu?ller, editor, The Proc. HPSG 2005, pages
108?128. CSLI.
Dan Flickinger and Emily M. Bender. 2003. Compo-
sitional semantics in a multilingual grammar resource.
In Proc. the Workshop on Ideas and Strategies for Mul-
tilingual Grammar Development, ESSLLI 2003, pages
33?42.
Kenneth Hale. 1981. On the position of Warlpiri in the
typology of the base. Distributed by Indiana Univer-
sity Linguistics Club, Bloomington.
Lars Hellan and Petter Haugereid. 2003. NorSource: An
exercise in Matrix grammar-building design. In Proc.
the Workshop on Ideas and Strategies for Multilingual
Grammar Development, ESSLLI 2003, pages 41?48.
Alexandra Kinyon and Owen Rambow. 2003. The meta-
grammar: A cross-framework and cross-language test-
suite generation tool. In Proc. 4th International Work-
shop on Linguistically Interpreted Corpora.
Valia Kordoni and Julia Neu. 2005. Deep analysis
of Modern Greek. In Keh-Yih Su, Jun?ichi Tsujii,
and Jong-Hyeok Lee, editors, Lecture Notes in Com-
puter Science, volume 3248, pages 674?683. Springer-
Verlag.
Stephan Oepen and Daniel P. Flickinger. 1998. Towards
systematic grammar profiling. Test suite technology
ten years after. Journal of Computer Speech and Lan-
guage, 12 (4) (Special Issue on Evaluation):411 ? 436.
Stephan Oepen. 2002. Competence and Performance
Profiling for Constraint-based Grammars: A New
Methodology, Toolkit, and Applications. Ph.D. thesis,
Universita?t des Saarlandes.
Carl Pollard and Ivan A. Sag. 1994. Head-Driven Phrase
Structure Grammar. The University of Chicago Press.
Laurie Poulson. 2006. Evaluating a cross-linguistic
grammar model: Methodology and gold-standard re-
source development. Master?s thesis, University of
Washington.
143
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 254?262,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Testing a Grammar Customization System with Sahaptin
Scott Drellishak
University of Washington
Seattle, WA, USA
sfd@u.washington.edu
Abstract
I briefly describe a system for automatically
creating an implemented grammar of a natu-
ral language based on answers to a web-based
questionnaire, then present a grammar of Sa-
haptin, a language of the Pacific Northwest
with complex argument-marking and agree-
ment patterns, that was developed to test the
system. The development of this grammar
has proved useful in three ways: (1) verifying
the correct functioning of the grammar cus-
tomization system, (2) motivating the addition
of a new pattern of agreement to the system,
and (3) making detailed predictions that un-
covered gaps in the linguistic descriptions of
Sahaptin.
1 Introduction
The LinGO Grammar Matrix
(Bender et al, 2002) is a resource for building im-
plemented precision HPSG (Pollard and Sag, 1994)
grammars of natural languages. Grammars based
on the Matrix are expressed in the Type Description
Language (TDL) (Krieger and Sch?fer, 1994), are
interpretable by the Linguistic Knowledge Building
system (LKB) (Copestake, 2002) (a software tool
for developing constraint-based grammars), and
have semantic representations that are compat-
ible with Minimal Recursion Semantics (MRS)
(Copestake et al, 2005). The Grammar Matrix
project, in particular the customization system
described below, has drawn on the linguistics and
linguistic typology literature during its develop-
ment; the system is now complex enough that it is
capable making contributions back to linguistics.
1.1 Matrix Customization System
In its earliest form, the Matrix provided a set of pre-
defined types intended to give grammar engineers
a head start, allowing them to avoid duplicating
the effort required to develop analyses of linguistic
structures thought to occur in all languages. How-
ever, there exist many linguistic phenomena that are
widespread, but not universal. If the Matrix were
restricted to supporting only what is truly univer-
sal, it would be a much less useful resource for
grammar-writers working on languages containing
such non-universal phenomena. Our solution has
been to provide the Matrix customization system,
which presents a linguist with a web-based typologi-
cal questionnaire designed to elicit a description of a
target language and, based on it, automatically pro-
duce a grammar that parses and generates the target
language.1 The grammars produced are not encum-
bered by phenomena that do not occur in the target
language; rather, they contain just enough complex-
ity to model it as described. Although the grammars
produced by the customization system are intended
as a starting point for further grammar engineering,
that starting point is now far enough along that even
without enhancement the grammars can be used for
interesting linguistic work.
The customization system is conceived of as con-
sisting of a set of libraries, each of which sup-
ports a particular linguistic phenomenon, and in-
cludes a section of the questionnaire and a syntac-
tic analysis of the target phenomenon that can be
1A frozen version of the customization sys-
tem as described here can be found on the Web at
depts.washington.edu/uwcl/matrix/sfddiss/.
254
customized and included in output grammars. Re-
cently, I have added three new libraries to the sys-
tem (Drellishak, 2009). A library for case-marking
supports a variety of patterns for the marking of up
to two mandatory verbal arguments, including the
nominative-accusative, ergative-absolutive, and tri-
partite patterns, as well as various split-ergative sys-
tems and Austronesian alignment (see Blake (2001)
for definitions of these terms). A library for agree-
ment supports agreement in syntactic and seman-
tic features between verbs and their arguments. Fi-
nally, a library for so-called direct-inverse argument
marking supports languages in which the mark-
ing of verbs and verbal arguments is conditioned
on a grammatical scale?for example, languages
in which clauses with a first person subject and a
second person object are marked differently than
clauses with a second person subject and a first per-
son object. Languages can contain none, some, or all
of these phenomena, and the customization system
must produce consistent grammars for every combi-
nation.
1.2 Testing the Customization System
Work to add new libraries to the customization sys-
tem is ongoing. Since the grammatical analyses
of different phenomena can interact in unexpected
ways, we utilize a system of regression testing to
verify that the implementation new libraries does not
break older libraries.
A customization system regression test consists
of three parts. First, each test includes a stored
set of answers to the questionnaire describing a lan-
guage that illustrates one or more linguistic phenom-
ena; this can be fed into the customization system
to create a grammar. Second, each test has a list
of strings, some grammatical and some ungrammat-
ical in the test?s language, that probe the behavior
of the grammar with respect to the phenomena in
question. Third, each test has the expected results,
including semantic representations in the format of
Oepen (2001), that are produced by the grammar
when it parses the test sentences.
At the time of this writing, the regression test suite
includes 112 tests that fall roughly into two cate-
gories. The first category contains small artificial
languages that illustrate a single phenomenon (e.g.
nominative-accusative case marking or a particular
word order). The second category contains larger
grammars based on natural languages that illustrate
a wider range of phenomena, and therefore test the
interaction of the associated libraries. The largest
and most complex test in the latter category is the
regression test for Sahaptin.
2 Sahaptin
Sahaptin [uma] (Penutian) is a family of closely re-
lated dialects spoken in Washington, Idaho, and Ore-
gon. The details of Sahaptin grammar are drawn
primarily from a description of the language by
Rigsby and Rude (1996) (henceforth R&R). It hap-
pens that Sahaptin contains extremely complex ar-
gument marking and agreement patterns that illus-
trate, in a single grammar, a number of phenom-
ena covered by my recently-implemented Matrix li-
braries, including:
? Case marking on verbal arguments.
? Argument marking sensitive to a grammatical
scale, including patterns analyzed here as prox-
imate and obviative marking on third-person
nominals.
? Two loci of agreement (a verbal prefix and a
second-position enclitic) with both the subject
and the object.
? A distinction in number between singular, dual,
and plural on nominals, but only between sin-
gular and plural on agreement morphology.
? An inclusive/exclusive distinction in person re-
flected only in the second-position enclitic.
2.1 Sahaptin Grammar
This section contains a brief sketch of the structure
of Sahaptin sentences. Consider the following sim-
ple sentence:
(1) ?n=a? ?-tux
?
nana y?ama?-na
I=1SG 3ABS-shot mule.deer-OBJ
?I shot the mule deer.? [uma]
(Rigsby and Rude, 1996, 676)
In (1) the first word consists of the first person sin-
gular pronoun in its unmarked form, the nominative,
followed by a second-position enclitic that agrees
with the pronoun. The second word is the verb, con-
sisting of a verbal prefix appropriate to the person
and number of the subject and object (glossed by
255
R&R as 3ABS, but see ?3.6 below for a different
analysis) and the verb stem. The third word consists
of the noun stem meaning ?mule deer? and a suffix
marking the objective case.
R&R describe several cases in Sahaptin, includ-
ing an unmarked ?nominative? case, a marked ?ob-
jective? case, an ?inverse ergative? case, and an ?ob-
viative ergative? case. In spite of their use of the
term ?ergative?, R&R make it clear that the sub-
ject generally appears in the nominative case in both
transitive and intransitive clauses, and that the object
consistently appears in the objective case in transi-
tive clauses. The ?inverse ergative? and ?obviative
ergative? forms only occur with third person singu-
lar nominals, both nouns and pronouns, in addition
to the subject and object forms, and they are used to
distinguish the subject from the object in transitive
clauses.
In addition to case marking on nominals, Sahap-
tin has two ways to cross-reference the arguments of
verbs: a verbal prefix and a second-position enclitic
that attaches to whichever word comes first in the
sentence. R&R characterize the prefixes and encl-
itics in two ways: first, they provide a general de-
scription of the distribution of each; second, they
provide detailed paradigms of intransitive and tran-
sitive sentence patterns that cover most, but not all,
of the logical combinations.
Enclitic Description
=na? ? =a? ? =? ?first-person singular?
=na ?first-person plural
inclusive?
=nata? ? =ata? ? =ta? ?first-person plural
exclusive?
=nam ? =am ? =m ?second-person singular?
=pam ?second-person plural?
=ma? ?second-person object
with first-person subject
(both singular)?
=mata? ?second-person object
with first-person subject
(one or both plural)?
Table 1: Sahaptin enclitics (Rigsby and Rude, 1996, 675)
R&R describe Sahaptin?s second-position encli-
tics as shown in Table 1. Notice in particular that
several of the enclitics are associated with a per-
son and number, but R&R do not mention whether
those values are associated with the subject or the
object. The reason for this becomes clear when we
examine the full paradigm of clauses. The enclitic
=nata?, for example, occurs with first person plural
exclusive subjects in intransitive clauses; in transi-
tive clauses, however, it occurs when one argument
is first person plural exclusive and the other is third
person, regardless of which is the subject and which
is the object. A similar pattern can be observed for
=na and =na?. This variant of scale-sensitive ar-
gument marking motivated an enhancement to the
customization system described in ?5 below.
Prefix Description
i- ?third-person nominative?
pa- ?third-person plural nominative?
?- ? ?w- ?third-person absolutive?
p?- ?inverse?
pat?- ? pat?w- ?third-person plural subject with
third-person object?
Table 2: Sahaptin prefixes (Rigsby and Rude, 1996, 675)
As for Sahaptin?s verbal prefixes, R&R describe
them as shown in Table 2.2 These descriptions are
less straightforward than those for the enclitics. In
particular, the description of ?- ? ?w- as ?absolu-
tive? is misleading. Regarding that prefix, R&R
write, ?...this pronominal marks subjects in intran-
sitive clauses when they are possessors, and objects
in transitive clauses when the subject is first or sec-
ond person.? (675) In other words, it does not occur
in all transitive clauses, and only in those intransi-
tive clauses where the subject is possessive. Fur-
thermore, all the prefixes above appear on the verb,
not the nominal arguments, as one might expect for
an ?absolutive? affix. In spite of the use of the term
?absolutive?, the distribution of the prefix ?- ? ?w-
does not give evidence of ergative alignment in Sa-
haptin. Similarly, although there is evidence of argu-
ment marking sensitive to a grammatical scale, the
description of p?- as ?inverse? is misleading, since
that prefix does not appear if and only if the object
outranks the subject.
2There are three further verbal prefixes in Sahaptin that mark
reflexives and reciprocals, but there is currently no support for
these phenomena in the customization system.
256
3 Sahaptin Test Case
The phenomena described above make Sahaptin an
excellent test case for demonstrating the flexibility
and expressive power of the customization system.
In this section, I will show how a significant frag-
ment of Sahaptin can be described in the customiza-
tion system questionnaire, producing a grammar that
correctly models some of the complexity of Sahap-
tin morphosyntax.
It should be noted that some aspects of Sahap-
tin are beyond the current capabilities of the cus-
tomization system, so some simplifying assump-
tions were necessary. For instance, the customiza-
tion system models complex morphosyntax but not
complex morphophonology. In effect, the grammars
it outputs expect a morpheme-by-morpheme gloss as
input rather than orthography, leaving the problem
of morphological analysis to other systems.3 The
Sahaptin test grammar therefore uses only a single
spelling for each stem and morpheme, and the mor-
phemes are separated by ?-? or ?=? characters. The
facts of Sahaptin word order are also too complex
for the customization system; in particular, it can-
not model truly free word order (i.e., discontinuous
noun phrases), and the attachment behavior of the
second-position enclitic is similarly beyond its ca-
pability. However, given these simplifying assump-
tions, the customization system is capable of model-
ing all the agreement and marking patterns of Sa-
haptin intransitive and transitive clauses shown in
Tables 7 and 8 in R&R (1996, 676).
After the design and implementation of the li-
braries for case, direct-inverse languages, and agree-
ment were completed, the construction of the Sa-
haptin test case took only about 80 hours of work,
including the creation of test sentences (described
in more detail in ?4 below), a linguistic analysis of
Sahaptin, filling out the questionnaire to reflect that
analysis, and debugging the answers to the question-
naire.
3.1 Word Order
In the test grammar, I treat Sahaptin as a VSO lan-
guage, and the enclitic as a suffix on verbs. This
3The construction of such systems is well-understood
(Beesley and Karttunen, 2003), as is the method for hooking up
such a system to the LKB.
means that the sentences recognized and generated
by the grammar are in a legal word order?VSO sen-
tences with the verb followed by the second-position
enclitic are grammatical in Sahaptin?but there are
other legal word orders that the test grammar will not
accept. The analysis of the enclitic is therefore lim-
ited by the current capabilities of the customization
system?s word order library; however, if that library
is enhanced in the future to support second-position
clitics, the analysis presented below should transfer
straightforwardly.
3.2 Number
I analyze Sahaptin as having three values of number:
singular (sg), dual (du), and plural (pl). All three
values are distinguished on pronouns, as shown in
Table 3; however, agreement with enclitics and ver-
bal prefixes only shows a singular/plural distinction
(with dual pronouns agreeing with the plural mor-
pheme). It will be necessary in several places for the
grammar to refer to a non-singular category cover-
ing du and pl. The questionnaire allows the explicit
description of such a category; however, it also al-
lows the user to select multiple values for a feature,
and from those values infers the existence of cate-
gories like non-singular. I have made use of the lat-
ter mechanism in this grammar.
Table 3 shows the Sahaptin pronoun forms that
distinguish singular, dual, and plural; in the ques-
tionnaire, therefore, I specified a number value on
each. So-called plural agreement morphemes, on the
other hand, do not distinguish between the dual and
plural so are simply specified as covering both val-
ues.
3.3 Person
Sahaptin distinguishes three values of person: first,
second, and third. The enclitics (but, interestingly,
not the pronouns) further distinguish a first person
inclusive and first person exclusive. I filled out the
person section of the questionnaire with answers re-
flecting the presence of an inclusive/exclusive dis-
tinction.
3.4 Case
As described above, Sahaptin has a nominative case
that marks intransitive and transitive subjects and an
objective case that marks transitive objects. This
257
Singular Dual Plural
Subject Object Subject Object Subject Object
1 ?n in?y napiin? napiinaman?y n?ma naaman?y
2 ?m iman?y imiin? imiinaman?y im?y imaaman?y
3 p(?n paan?y piin? piinaman?y pm?y paaman?y
3 obv erg piin?
3 inv erg pn?(m
Table 3: Umatilla Sahaptin Pronouns (Rigsby and Rude, 1996, 682?683)
is the common nominative-accusative pattern, so in
the case section of the questionnaire I describe it as
such. Note that I do not analyze the inverse ergative
and obviative ergative as case; see ?3.6 for details.
3.5 Direct-Inverse
I analyze Sahaptin as a direct-inverse language?
that is, a language whose argument marking is sen-
sitive to a grammatical scale?though one that lacks
clear direct or inverse forms of the verb, with the ex-
ception of the p?- prefix. The scale I propose for
Sahaptin is:
(2) 1P > 2P > 3P topic > 3P non-topic
The customization system interprets this scale,
creating a series of rules that constrain the value of
a feature DIRECTION on verbs. This feature takes
the values direct and inverse and can be used to con-
strain the form either of verbs themselves or of their
arguments.
3.6 Other Features
I use two additional features in my analysis of Sa-
haptin: a semantic TOPICALITY feature and a syn-
tactic PROXIMITY feature, both on nominals.
Marking of Sahaptin transitive clauses distin-
guishes between topical and non-topical third person
arguments. There is no overt marking of topicality
on nominals, but clausal marking is conditioned on
pragmatic distinctions that influence the felicity of
the sentence in different discourse contexts. In order
to systematically test this aspect of Sahaptin gram-
mar in terms of string grammaticality, I introduced
an artificial mark on topical noun phrases, the suffix
-TOP. This suffix constrains the value of the TOPI-
CALITY feature on nominal indices.
I use the syntactic PROXIMITY feature to model
the ?inverse ergative? and ?obviative ergative? forms
of nominals. In Sahaptin transitive clauses, the in-
verse ergative occurs precisely when the subject is
third person singular and the clause is inverse (that
is, the object is higher on the scale). The obviative
ergative occurs in exactly one case: when the sub-
ject is third person singular and the object is a top-
ical third person singular. These ?ergative? forms
function very much like the so-called proximate and
obviative forms in Algonquian languages. However,
in contrast to those languages, I analyze Sahaptin as
having three values of the PROXIMITY feature rather
than two: proximate, corresponding to the inverse
ergative -n?(m, which promotes the marked nominal
up the scale; obviative, corresponding to the obvia-
tive ergative -in, which demotes the marked nomi-
nal down the scale; and neutral, the unmarked form,
which does not affect the nominal?s position on the
scale.4
3.7 Lexicon
Having defined the necessary features and values,
we can now describe the lexicon of the Sahaptin
grammar, which includes lexical types and inflec-
tional morphemes. In the questionnaire, inflectional
morphology is described as a series of slots, each at-
taching to one or more lexical types or other slots,
and each containing one or more morphemes, each
of which in turn specifies features. In order to pre-
vent spurious ambiguity, the features on each set of
morphemes are specified in such a way that no mor-
pheme overlaps another, but also so that no legal
combination of features goes unexpressed.
The simplest grammars are those that do not re-
sort to homophony?that is, they do not have mul-
tiple lexical items or morphemes with the same
4Note that, for consistency with R&R?s description, I
nonetheless continue to refer to the marked forms as the ?in-
verse ergative? and ?obviative ergative?.
258
spelling but different semantics or features. It is of-
ten possible to avoid homophony by adding com-
plexity to feature hierarchies, but overly complex
hierarchies can be as difficult to manage as exten-
sive homophony. In the Sahaptin grammar, I have
attempted to strike a balance between homophony
and hierarchy complexity. For example, to make the
grammar easier for users to understand, I segregated
verbal prefixes and enclitics each into two classes:
those attaching to intransitive stems and those at-
taching to transitive stems. This produced two ho-
mophonous variants of the prefixes i- and pa-, and of
the enclitics =na?, =na, =nata?, =nam, and =pam.
Furthermore, the distributions of two transitive pre-
fixes (p?- and the null variant) and of three transi-
tive enclitics (=nam, =pam, and =mata?) were eas-
ier to model using homophonous variants. Finally,
the third person singular obviative pronoun and the
third person dual subject pronoun are both piin? (as
shown in Table 3) and it seemed simplest to repre-
sent these using two separate lexical entries. The
grammar, then, contains 22 lexical items, of which
only two are homophonous, and 24 non-null inflec-
tional morphemes representing 12 distinctly spelled
prefixes and enclitics.
A full description of the morphosyntactic details
of the Sahaptin test grammar would be too long for
this paper; instead, I will provide a summary.5 The
lexicon of the test grammar contains six inflectional
slots: a slot for the topic morpheme described above
that attaches to nominals; a slot for verbal prefixes
that attach to intransitive verbs; a slot for verbal pre-
fixes that attach to transitive verbs; a slot for encl-
itics that attach to intransitive verbs; a slot for en-
clitics that attach to transitive verbs; and a slot that
contains no overt morphemes, but is used to produce
lexical rules that constrain the appearance of topic,
proximate, and obviative on a verb?s nominal argu-
ments. Each of these slots contains morphemes, on
which are specified values for one or more features.
To give an idea of what this looks like, Table 4 shows
5The full details of the Sahaptin grammar can be found
in my dissertation (Drellishak, 2009). How the ques-
tionnaire can be filled out to model Sahaptin can be
seen by visiting the customization system web site at
depts.washington.edu/uwcl/matrix/sfddiss/
and clicking the Umatilla Sahaptin link at the bottom of the
main page, which fills out the questionnaire automatically.
the features that are defined for the most complex of
these slots, the one that contains transitive prefixes.
4 Testing the Sahaptin Grammar
In order to test the correctness of the Sahaptin gram-
mar, it was necessary to create a suite of test sen-
tences, some grammatical and some not, that probe
its expected lexical and grammatical coverage. I
started with the sentence patterns in R&R?s Tables
7 and 8 (Rigsby and Rude, 1996, 676); from each, I
created a sentence with the appropriate prefix, verb,
enclitic, subject, and object. In every case where
a plural argument was called for, I actually cre-
ated two sentences, one with a dual argument?and
in cases with two plural arguments, I created four:
du/du, du/pl, pl/du, and pl/pl.
All these sentences were expected to be gram-
matical based on the descriptions in R&R. To gen-
erate ungrammatical sentences, I initially permuted
the grammatical sentences in the following ways:
1. For each grammatical sentence with a prefix, I
created an ungrammatical variant with the pre-
fix missing.
2. For each grammatical sentence with an enclitic,
I created an ungrammatical variant with the en-
clitic missing.
3. For each grammatical sentence, I created vari-
ants that contained every incorrect prefix and
variants that contained every incorrect enclitic.
After duplicates were removed, this produced a
list of 89 grammatical and 220 ungrammatical sen-
tences, for a total of 309.
The permutation of the grammatical sentences as
described above was sufficient to test the phenom-
ena of interest for intransitive sentences, producing
ungrammatical sentences consisting of correctly-
formed words in the correct basic word order but
with an ungrammatical agreement pattern, and this
permutation was a small enough job to perform by
hand. For transitive sentences, though, there is a
much larger space of sentences with the right word
order but wrong agreement, so in order to test the
grammar thoroughly, I decided to supplement the
ungrammatical sentences I created by hand by writ-
ing a small program to generate every sentence con-
taining the verb q??nun ?see? that followed the pattern:
259
Transitive Subject Subject Object Object
prefix PERNUM TOPICALITY PERNUM TOPICALITY
i- 3sg non-topic
pa- 3du, 3pl non-topic
?- 1st, 2nd 3rd
p?- 2sg 1sg
p?- 3sg non-topic 3sg topic
pat?- 3du, 3pl non-topic 3sg topic
? 1st 2nd
? 2du, 2pl 1st
? 2sg 1du, 1pl
Table 4: Morphemes appearing in the transitive prefix slot
(3) prefix-q??nun=enclitic subject object
The possible fillers for each position in (3) are
shown in Table 5:
prefix i-, pa-, ?-, p?-, pat?-, and ?
enclitic =na?, =na, =nata?, =nam, =pam,
=ma?, =mata?, and ?
subject subject forms in Table 3
object object forms in Table 3
Table 5: Fillers for positions in (3)
As mentioned above, the lexicon of the Sahaptin
grammar, and consequently the test sentences, uses
the various forms of the personal pronoun to rep-
resent the possible person, number, case, and prox-
imity values of subject and object noun phrases. In
addition to plain case-marked pronouns, the subject
and object positions may also contain third person
pronouns marked as the topic with -TOP.
Generating every sentence that followed the pat-
tern in (3) produced 6048 sentences, but some ad-
ditional filtering was required. First, since it ap-
pears that topic marking is only relevant when dis-
ambiguating third person arguments, I removed all
sentences where the -TOP suffix appeared with a
first or second person pronoun. Second, 192 of the
permutations of (3) are actually duplicates of the
ungrammatical transitive test sentences created by
hand above, so I removed those as well. After fil-
tering, a total of 5856 programmatically-generated
sentences remained. Added to the aforementioned
309 examples, this made 6165 unique test sentences.
After using the customization system to generate
a grammar of Sahaptin, I used that grammar to at-
tempt to parse every test sentence. All 89 sentences
corresponding to R&R?s grammatical transitive and
intransitive patterns parsed and were assigned ex-
actly one analysis.6 Among the ungrammatical sen-
tences, 5848 out of 5856 failed to parse, as expected.
To my surprise, however, eight of the sentences did
parse. These sentences were:
(4) a. i-q??nun p?(n-TOP piinaman?y
3SG-see 3SG.NOM-TOP 3DU.OBJ
?He saw them (DU).?
b. i-q??nun p(?n-TOP paaman?y
3SG-see 3SG.NOM-TOP 3PL.OBJ
?He saw them.?
c. pa-q??nun piin? paan?y
3NONSG-see 3DU.NOM 3SG.OBJ
?They (DU) saw him.?
d. pa-q??nun pm?y paan?y
3NONSG-see 3PL.NOM 3SG.OBJ
?They saw him.?
e. pa-q??nun piin?-TOP piinaman?y
3NONSG-see 3DU.NOM-TOP 3DU.OBJ
?They (DU) saw them (DU).?
f. pa-q??nun piin?-TOP paaman?y
3NONSG-see 3DU.NOM-TOP 3PL.OBJ
?They (DU) saw them.?
g. pa-q??nun pm?y-TOP piinaman?y
3NONSG-see 3PL.NOM-TOP 3DU.OBJ
?They saw them (DU).?
h. pa-q??nun pm?y-TOP paaman?y
3NONSG-see 3PL-TOP.NOM 3PL.OBJ
?They saw them.?
6Multiple analyses would not necessarily have been
wrong?some sentences in some languages are structurally
ambiguous?but the grammatical Sahaptin sentences in the test
suite are marked explicitly enough for agreement that none was
ambiguous.
260
Notice that the eight sentences fall into three pat-
terns. The first two sentences have a third person sin-
gular topical subject and a third person non-singular
non-topical object, the next two have a third person
non-singular non-topical subject and a third person
singular non-topical object, and the last four have a
third person non-singular topical subject and a third
person non-topical object. These are precisely the
patterns that are absent from R&R?s Table 8; corre-
sponding sentences were therefore not included in
the list of 89 grammatical sentences. In develop-
ing the Sahaptin grammar, I had, without consider-
ing these eight patterns, defined the prefixes in such
a way that the grammar expected i- to appear in the
first two sentences and pa- in the last six.
In order to determine whether this analysis was
correct, Sharon Hargus presented the Yakima Sahap-
tin equivalents of the sentences in (4) by telephone
to Virginia Beavert, a native speaker of that dialect,
who accepted all eight of them with the readings
shown in (4). Note that, in order for these sentences
to be acceptable, they had to be cast in the past tense,
a feature not modeled in my Sahaptin grammar frag-
ment. Note also that Dr. Beavert considered sen-
tence (4c) somewhat less acceptable, saying that it
is ?[a] little awkward, but has meaning.?
The Sahaptin grammar, then, which was created
using the customization system and based on its sup-
port for case, direct-inverse languages, and agree-
ment, correctly analysed all 6165 of the test sen-
tences, including eight that fell outside of the pat-
terns described in the linguistic literature.
5 Summary and Discussion
Based on these results, I conclude that even Sahap-
tin, a language with extremely complex argument
marking morphology, can be modeled using the cus-
tomization system. Note that the system was not de-
signed with the facts of Sahaptin in mind, and with
two exceptions, the system did not need to be modi-
fied to enable it to handle Sahaptin.
One of the exceptions was trivial: formerly, gram-
mars produced by the system treated ?=? as punctua-
tion, stripping it out and breaking words containing
it. The other exception concerns an unusual agree-
ment pattern I first encountered in Sahaptin: mor-
phemes that agree, not with the subject or the object
of a verb, but with the nominal argument that is more
highly ranked on the direct-inverse scale. Support-
ing this agreement pattern proved worthwhile later,
when it was used again in a test grammar for Plains
Cree [crk] (Algonquian), another direct-inverse lan-
guage. Although this latter change was a substan-
tive one that allows grammars to be described more
compactly, it did not increase the descriptive power
of the system?languages showing that pattern of
agreement could still be modeled using duplicated,
homophonous morphemes. Such an enhancement to
the system is an example of the feedback loop be-
tween grammar engineering and customization sys-
tem development, where new languages with new
phenomena (or new variations of old phenomena)
inform the design and, in some cases, the descrip-
tive power of the system.
After constructing the Sahaptin grammar and test
suite described here, it was natural to include it in
two places in the customization system. First, it
is now one of the regression tests that is regularly
run to ensure that future enhancement of the system
does not break earlier features. Second, Sahaptin
has been added to the list of sample grammars ac-
cessible from the main page of the questionnaire?
by clicking on links in this list, users can see detailed
examples of how the questionnaire can be filled out
to model a target language.
The Sahaptin grammar, developed using the cus-
tomization system, has proved itself useful?not
only to the Grammar Matrix project, where it in-
spired the addition of support for scale-sensitive
agreement and serves as a regression test of the cor-
rect functioning of the system, but also to the field
of linguistics. By analyzing Sahaptin in the precise
detail required by the customization system, I found
unnoticed gaps in linguistic descriptions of the lan-
guage, and in collaboration with linguists studying
the language was able to help resolve those gaps.
Acknowledgments
My thanks go to Emily Bender and the Matrix team,
Sharon Hargus, and Virginia Beavert. This work
was supported by a gift to the Turing Center from
the Utilika Foundation, by the Max Planck Institute
for Evolutionary Anthropology, and by the National
Science Foundation under Grant No. 0644097.
261
References
[Beesley and Karttunen2003] Kenneth R. Beesley and
Lauri Karttunen. 2003. Finite State Morphology.
CSLI, Stanford.
[Bender et al2002] Emily M. Bender, Dan Flickinger,
and Stephan Oepen. 2002. The grammar matrix. In
Proceedings of COLING 2002 Workshop on Grammar
Engineering and Evaluation, Taipei, Taiwan.
[Blake2001] Barry J. Blake. 2001. Case, Second Edition.
Cambridge University Press, Cambridge.
[Copestake et al2005] Ann Copestake, Dan Flickinger,
Carl Pollard, and Ivan A. Sag. 2005. Minimal re-
cursion semantics: An introduction. Research on Lan-
guage & Computation, 3(2?3):281?332.
[Copestake2002] Ann Copestake. 2002. Implementing
Typed Feature Structure Grammars. CSLI, Stanford.
[Drellishak2009] Scott Drellishak. 2009. Widespread,
but Not Universal: Improving the Typological Cover-
age of the Grammar Matrix. Ph.D. thesis, University
of Washington.
[Krieger and Sch?fer1994] Hans-Ulrich Krieger and Ul-
rich Sch?fer. 1994. Tdl ? a type description language
for constraint-based grammars. In Proceedings of the
15th International Conference on Computational Lin-
guistics, pages 893?899, Kyoto, Japan.
[Oepen2001] Stephan Oepen. 2001. [incr tsdb()] ?
Competence and performance laboratory. User man-
ual. Technical report, Saarbr?cken, Germany.
[Pollard and Sag1994] Carl Pollard and Ivan A. Sag.
1994. Head-Driven Phrase Structure Grammar.
CSLI, Stanford.
[Rigsby and Rude1996] Bruce Rigsby and Noel Rude.
1996. Sketch of sahaptin, a sahaptian language.
In Ives Goddard, editor, Languages, pages 666?92.
Smithsonian Institution, Washington DC.
262
Proceedings of the ACL 2010 System Demonstrations, pages 1?6,
Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational Linguistics
Grammar Prototyping and Testing with the
LinGO Grammar Matrix Customization System
Emily M. Bender, Scott Drellishak, Antske Fokkens, Michael Wayne Goodman,
Daniel P. Mills, Laurie Poulson, and Safiyyah Saleem
University of Washington, Seattle, Washington, USA
{ebender,sfd,goodmami,dpmills,lpoulson,ssaleem}@uw.edu,
afokkens@coli.uni-saarland.de
Abstract
This demonstration presents the LinGO
Grammar Matrix grammar customization
system: a repository of distilled linguis-
tic knowledge and a web-based service
which elicits a typological description of
a language from the user and yields a cus-
tomized grammar fragment ready for sus-
tained development into a broad-coverage
grammar. We describe the implementation
of this repository with an emphasis on how
the information is made available to users,
including in-browser testing capabilities.
1 Introduction
This demonstration presents the LinGO Gram-
mar Matrix grammar customization system1 and
its functionality for rapidly prototyping grammars.
The LinGO Grammar Matrix project (Bender et
al., 2002) is situated within the DELPH-IN2 col-
laboration and is both a repository of reusable
linguistic knowledge and a method of delivering
this knowledge to a user in the form of an ex-
tensible precision implemented grammar. The
stored knowledge includes both a cross-linguistic
core grammar and a series of ?libraries? contain-
ing analyses of cross-linguistically variable phe-
nomena. The core grammar handles basic phrase
types, semantic compositionality, and general in-
frastructure such as the feature geometry, while
the current set of libraries includes analyses of
word order, person/number/gender, tense/aspect,
case, coordination, pro-drop, sentential negation,
yes/no questions, and direct-inverse marking, as
well as facilities for defining classes (types) of lex-
ical entries and lexical rules which apply to those
types. The grammars produced are compatible
with both the grammar development tools and the
1
http://www.delph-in.net/matrix/customize/
2
http://www.delph-in.net
grammar-based applications produced by DELPH-
IN. The grammar framework used is Head-driven
Phrase Structure Grammar (HPSG) (Pollard and
Sag, 1994) and the grammars map bidirectionally
between surface strings and semantic representa-
tions in the format of Minimal Recursion Seman-
tics (Copestake et al, 2005).
The Grammar Matrix project has three goals?
one engineering and two scientific. The engineer-
ing goal is to reduce the cost of creating gram-
mars by distilling the solutions developed in exist-
ing DELPH-IN grammars and making them easily
available for new projects. The first scientific goal
is to support grammar engineering for linguistic
hypothesis testing, allowing users to quickly cus-
tomize a basic grammar and use it as a medium in
which to develop and test analyses of more inter-
esting phenomena.3 The second scientific goal is
to use computational methods to combine the re-
sults of typological research and formal syntactic
analysis into a single resource that achieves both
typological breadth (handling the known range of
realizations of the phenomena analyzed) and ana-
lytical depth (producing analyses which work to-
gether to map surface strings to semantic represen-
tations) (Drellishak, 2009).
2 System Overview
Grammar customization with the LinGO Gram-
mar Matrix consists of three primary activities:
filling out the questionnaire, preliminary testing of
the grammar fragment, and grammar creation.
2.1 Questionnaire
Most of the linguistic phenomena supported by the
questionnaire vary across languages along multi-
ple dimensions. It is not enough, for example,
3Research of this type based on the Grammar Matrix
includes (Crysmann, 2009) (tone change in Hausa) and
(Fokkens et al, 2009) (Turkish suspended affixation).
1
simply to know that the target language has coor-
dination. It is also necessary to know, among other
things, what types of phrases can be coordinated,
how those phrases are marked, and what patterns
of marking appear in the language. Supporting a
linguistic phenomenon, therefore, requires elicit-
ing the answers to such questions from the user.
The customization system elicits these answers us-
ing a detailed, web-based, typological question-
naire, then interprets the answers without human
intervention and produces a grammar in the format
expected by the LKB (Copestake, 2002), namely
TDL (type description language).
The questionnaire is designed for linguists who
want to create computational grammars of natu-
ral languages, and therefore it freely uses techni-
cal linguistic terminology, but avoids, when possi-
ble, mentioning the internals of the grammar that
will be produced, although a user who intends to
extend the grammar will need to become familiar
with HPSG and TDL before doing so.
The questionnaire is presented to the user as a
series of connected web pages. The first page the
user sees (the ?main page?) contains some intro-
ductory text and hyperlinks to direct the user to
other sections of the questionnaire (?subpages?).
Each subpage contains a set of related questions
that (with some exceptions) covers the range of
a single Matrix library. The actual questions in
the questionnaire are represented by HTML form
fields, including: text fields, check boxes, ra-
dio buttons, drop-downs, and multi-select drop-
downs. The values of these form fields are stored
in a ?choices file?, which is the object passed on
to the grammar customization stage.
2.1.1 Unbounded Content
Early versions of the customization system (Ben-
der and Flickinger, 2005; Drellishak and Bender,
2005) only allowed a finite (and small) number
of entries for things like lexical types. For in-
stance, users were required to provide exactly one
transitive verb type and one intransitive verb type.
The current system has an iterator mechanism in
the questionnaire that allows for repeated sections,
and thus unlimited entries. These repeated sec-
tions can also be nested, which allows for much
more richly structured information.
The utility of the iterator mechanism is most
apparent when filling out the Lexicon subpage.
Users can create an arbitrary number of lexical
rule ?slots?, each with an arbitrary number of
morphemes which each in turn bear any num-
ber of feature constraints. For example, the
user could create a tense-agreement morpholog-
ical slot, which contains multiple portmanteau
morphemes each expressing some combination of
tense, subject person and subject number values
(e.g., French -ez expresses 2nd person plural sub-
ject agreement together with present tense).
The ability provided by the iterators to create
unbounded content facilitates the creation of sub-
stantial grammars through the customization sys-
tem. Furthermore, the system allows users to ex-
pand on some iterators while leaving others un-
specified, thus modeling complex rule interactions
even when it cannot cover features provided by
these rules. A user can correctly model the mor-
photactic framework of the language using ?skele-
tal? lexical rules?those that specify morphemes?
forms and their co-occurrence restrictions, but per-
haps not their morphosyntactic features. The user
can then, post-customization, augment these rules
with the missing information.
2.1.2 Dynamic Content
In earlier versions of the customization system, the
questionnaire was static. Not only was the num-
ber of form fields static, but the questions were
the same, regardless of user input. The current
questionnaire is more dynamic. When the user
loads the customization system?s main page or
subpages, appropriate HTML is created on the fly
on the basis of the information already collected
from the user as well as language-independent in-
formation provided by the system.
The questionnaire has two kinds of dynamic
content: expandable lists for unbounded entry
fields, and the population of drop-down selec-
tors. The lists in an iterated section can be ex-
panded or shortened with ?Add? and ?Delete? but-
tons near the items in question. Drop-down selec-
tors can be automatically populated in several dif-
ferent ways.4 These dynamic drop-downs greatly
lessen the amount of information the user must
remember while filling out the questionnaire and
can prevent the user from trying to enter an invalid
value. Both of these operations occur without re-
freshing the page, saving time for the user.
4These include: the names of currently-defined features,
the currently-defined values of a feature, or the values of vari-
ables that match a particular regular expression.
2
2.2 Validation
It makes no sense to attempt to create a consis-
tent grammar from an empty questionnaire, an in-
complete questionnaire, or a questionnaire con-
taining contradictory answers, so the customiza-
tion system first sends a user?s answers through
?form validation?. This component places a set
of arbitrarily complex constraints on the answers
provided. The system insists, for example, that
the user not state the language contains no deter-
miners but then provide one in the Lexicon sub-
page. When a question fails form validation, it
is marked with a red asterisk in the questionnaire,
and if the user hovers the mouse cursor over the as-
terisk, a pop-up message appears describing how
form validation failed. The validation component
can also produce warnings (marked with red ques-
tion marks) in cases where the system can gen-
erate a grammar from the user?s answers, but we
have reason to believe the grammar won?t behave
as expected. This occurs, for example, when there
are no verbal lexical entries provided, yielding a
grammar that cannot parse any sentences.
2.3 Creating a Grammar
After the questionnaire has passed validation, the
system enables two more buttons on the main
page: ?Test by Generation? and ?Create Gram-
mar?. ?Test by Generation? allows the user to test
the performance of the current state of the gram-
mar without leaving the browser, and is described
in ?3. ?Create Grammar? causes the customiza-
tion system to output an LKB-compatible grammar
that includes all the types in the core Matrix, along
with the types from each library, tailored appropri-
ately, according to the specific answers provided
for the language described in the questionnaire.
2.4 Summary
This section has briefly presented the structure
of the customization system. While we antici-
pate some future improvements (e.g., visualiza-
tion tools to assist with designing type hierarchies
and morphotactic dependencies), we believe that
this system is sufficiently general to support the
addition of analyses of many different linguistic
phenomena. The system has been used to create
starter grammars for more than 40 languages in the
context of a graduate grammar engineering course.
To give sense of the size of the grammars
produced by the customization system, Table 1
compares the English Resource Grammar (ERG)
(Flickinger, 2000), a broad-coverage precision
grammar in the same framework under develop-
ment since 1994, to 11 grammars produced with
the customization system by graduate students in
a grammar engineering class at the University of
Washington. The students developed these gram-
mars over three weeks using reference materials
and the customization system. We compare the
grammars in terms of the number types they de-
fine, as well as the number of lexical rule and
phrase structure rule instances.5 We separate
types defined in the Matrix core grammar from
language-specific types defined by the customiza-
tion system. Not all of the Matrix-provided types
are used in the definition of the language-specific
rules, but they are nonetheless an important part of
the grammar, serving as the foundation for further
hand-development. The Matrix core grammar in-
cludes a larger number of types whose function is
to provide disjunctions of parts of speech. These
are given in Table 1, as ?head types?. The final col-
umn in the table gives the number of ?choices? or
specifications that the users gave to the customiza-
tion system in order to derive these grammars.
3 Test-by-generation
The purpose of the test-by-generation feature is to
provide a quick method for testing the grammar
compiled from a choices file. It accomplishes this
by generating sentences the grammar deems gram-
matical. This is useful to the user in two main
ways: it quickly shows whether any ungrammat-
ical sentences are being licensed by the grammar
and, by providing an exhaustive list of licensed
sentences for an input template, allows users to see
if an expected sentence is not being produced.
It is worth emphasizing that this feature of the
customization system relies on the bidirectional-
ity of the grammars; that is, the fact that the same
grammar can be used for both parsing and genera-
tion. Our experience has shown that grammar de-
velopers quickly find generation provides a more
stringent test than parsing, especially for the abil-
ity of a grammar to model ungrammaticality.
3.1 Underspecified MRS
Testing by generation takes advantage of the gen-
eration algorithm include in the LKB (Carroll et al,
5Serious lexicon development is taken as a separate task
and thus lexicon size is not included in the table.
3
Language Family Lg-specific types Matrix types Head types Lex rules Phrasal rules Choices
ERG Germanic 3654 N/A N/A 71 226 N/A
Breton Celtic 220 413 510 57 49 1692
Cherokee Iroquoian 182 413 510 95 27 985
French Romance 137 413 510 29 22 740
Jamamad?? Arauan 188 413 510 87 11 1151
Lushootseed Salish 95 413 510 20 8 391
Nishnaabemwin Algonquian 289 413 510 124 50 1754
Pashto Iranian 234 413 510 86 19 1839
Pali Indo-Aryan 237 413 510 92 55 1310
Russian Slavic 190 413 510 56 35 993
Shona Bantu 136 413 510 51 9 591
Vietnamese Austro-Asiatic 105 413 510 2 26 362
Average 182.9 413 510 63.5 28.3 1073.5
Table 1: Grammar sizes in comparison to ERG
1999). This algorithm takes input in the form of
Minimal Recursion Semantics (MRS) (Copestake
et al, 2005): a bag of elementary predications,
each bearing features encoding a predicate string,
a label, and one or more argument positions that
can be filled with variables or with labels of other
elementary predications.6 Each variable can fur-
ther bear features encoding ?variable properties?
such as tense, aspect, mood, sentential force, per-
son, number or gender.
In order to test our starter grammars by gen-
eration, therefore, we must provide input MRSs.
The shared core grammar ensures that all of
the grammars produce and interpret valid MRSs,
but there are still language-specific properties in
these semantic representations. Most notably, the
predicate strings are user-defined (and language-
specific), as are the variable properties. In addi-
tion, some coarser-grained typological properties
(such as the presence or absence of determiners)
lead to differences in the semantic representations.
Therefore, we cannot simply store a set of MRSs
from one grammar to use as input to the generator.
Instead, we take a set of stored template MRSs
and generalize them by removing all variable
properties (allowing the generator to explore all
possible values), leaving only the predicate strings
and links between the elementary predications.
We then replace the stored predicate strings with
ones selected from among those provided by the
user. Figure 1a shows an MRS produced by a
grammar fragment for English. Figure 1b shows
the MRS with the variable properties removed
and the predicate strings replaced with generic
place-holders. One such template is needed for
every sentence type (e.g., intransitive, transitive,
6This latter type of argument encodes scopal dependen-
cies. We abstract away here from the MRS approach to scope
underspecification which is nonetheless critical for its com-
putational tractability.
a. ? h1,e2, {h7: cat n rel(x4:SG:THIRD),
h3:exist q rel(x4, h5, h6),
h1: sleep v rel(e2:PRES, x4)},
{h5 qeq h7} ?
b. ? h1,e2, {h7:#NOUN1#(x4),
h3:#DET1#(x4, h5, h6),
h1:#VERB#(e2, x4)},
{h5 qeq h7} ?
Figure 1: Original and underspecified MRS
negated-intransitive, etc.). In order to ensure that
the generated strings are maximally informative to
the user testing a grammar, we take advantage of
the lexical type system. Because words in lexical
types as defined by the customization system dif-
fer only in orthography and predicate string, and
not in syntactic behavior, we need only consider
one word of each type. This allows us to focus the
range of variation produced by the generator on
(a) the differences between lexical types and (b)
the variable properties.
3.2 Test by generation process
The first step of the test-by-generation process is
to compile the choices file into a grammar. Next,
a copy of the LKB is initialized on the web server
that is hosting the Matrix system, and the newly-
created grammar is loaded into this LKB session.
We then construct the underspecified MRSs in
order to generate from them. To do this, the pro-
cess needs to find the proper predicates to use for
verbs, nouns, determiners, and any other parts of
speech that a given MRS template may require. For
nouns and determiners, the choices file is searched
for the predicate for one noun of each lexical noun
type, all of the determiner predicates, and whether
or not each noun type needs a determiner or not.
For verbs, the process is more complicated, re-
quiring valence information as well as predicate
strings in order to select the correct MRS template.
In order to get this information, the process tra-
verses the type hierarchy above the verbal lexical
4
types until it finds a type that gives valence infor-
mation about the verb. Once the process has all
of this information, it matches verbs to MRS tem-
plates and fills in appropriate predicates.
The test-by-generation process then sends these
constructed MRSs to the LKB process and displays
the generation results, along with a brief explana-
tion of the input semantics that gave rise to them,
in HTML for the user.7
4 Related Work
As stated above, the engineering goal of the Gram-
mar Matrix is to facilitate the rapid development
of large-scale precision grammars. The starter
grammars output by the customization system are
compatible in format and semantic representations
with existing DELPH-IN tools, including software
for grammar development and for applications in-
cluding machine translation (Oepen et al, 2007)
and robust textual entailment (Bergmair, 2008).
More broadly, the Grammar Matrix is situated
in the field of multilingual grammar engineer-
ing, or the practice of developing linguistically-
motivated grammars for multiple languages within
a consistent framework. Other projects in this
field include ParGram (Butt et al, 2002; King
et al, 2005) (LFG), the CoreGram project8 (e.g.,
(Mu?ller, 2009)) (HPSG), and the MetaGrammar
project (de la Clergerie, 2005) (TAG).
To our knowledge, however, there is only one
other system that elicits typological information
about a language and outputs an appropriately cus-
tomized implemented grammar. The system, de-
scribed in (Black, 2004) and (Black and Black,
2009), is called PAWS (Parser And Writer for
Syntax) and is available for download online.9
PAWS is being developed by SIL in the context
of both descriptive (prose) grammar writing and
?computer-assisted related language adaptation?,
the practice of writing a text in a target language
by starting with a translation of that text in a
related source language and mapping the words
from target to source. Accordingly, the output of
PAWS consists of both a prose descriptive grammar
7This set-up scales well to multiple users, as the user?s in-
teraction with the LKB is done once per customized grammar,
providing output for the user to peruse as his or her leisure.
The LKB process does not persist, but can be started again
by reinvoking test-by-generation, such as when the user has
updated the grammar definition.
8
http://hpsg.fu-berlin.de/Projects/core.html
9
http://www.sil.org/computing/catalog/show_
software.asp?id=85
and an implemented grammar. The latter is in the
format required by PC-PATR (McConnel, 1995),
and is used primarily to disambiguate morpholog-
ical analyses of lexical items in the input string.
Other systems that attempt to elicit linguistic in-
formation from a user include the Expedition (Mc-
Shane and Nirenburg, 2003) and Avenue projects
(Monson et al, 2008), which are specifically tar-
geted at developing machine translation for low-
density languages. These projects differ from the
Grammar Matrix customization system in elic-
iting information from native speakers (such as
paradigms or translations of specifically tailored
corpora), rather than linguists. Further, unlike the
Grammar Matrix customization system, they do
not produce resources meant to sustain further de-
velopment by a linguist.
5 Demonstration Plan
Our demonstration illustrates how the customiza-
tion system can be used to create starter gram-
mars and test them by invoking test-by-generation.
We first walk through the questionnaire to illus-
trate the functionality of libraries and the way that
the user interacts with the system to enter infor-
mation. Then, using a sample grammar for En-
glish, we demonstrate how test-by-generation can
expose both overgeneration (ungrammatical gen-
erated strings) and undergeneration (gaps in gen-
erated paradigms). Finally, we return to the ques-
tionnaire to address the bugs in the sample gram-
mar and retest to show the result.
6 Conclusion
This paper has presented an overview of the
LinGO Grammar Matrix Customization System,
highlighting the ways in which it provides ac-
cess to its repository of linguistic knowledge. The
current customization system covers a sufficiently
wide range of phenomena that the grammars it
produces are non-trivial. In addition, it is not al-
ways apparent to a user what the implications will
be of selecting various options in the question-
naire, nor how analyses of different phenomena
will interact. The test-by-generation methodology
allows users to interactively explore the conse-
quences of different linguistic analyses within the
platform. We anticipate that it will, as a result, en-
courage users to develop more complex grammars
within the customization system (before moving
on to hand-editing) and thereby gain more benefit.
5
Acknowledgments
This material is based upon work supported by
the National Science Foundation under Grant No.
0644097. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the views of the National Science Foundation.
References
Emily M. Bender and Dan Flickinger. 2005. Rapid
prototyping of scalable grammars: Towards modu-
larity in extensions to a language-independent core.
In Proc. of IJCNLP-05 (Posters/Demos).
Emily M. Bender, Dan Flickinger, and Stephan Oepen.
2002. The grammar matrix: An open-source starter-
kit for the rapid development of cross-linguistically
consistent broad-coverage precision grammars. In
Proc. of the Workshop on Grammar Engineering
and Evaluation at COLING 2002, pages 8?14.
Richard Bergmair. 2008. Monte Carlo semantics:
McPIET at RTE4. In Text Analysis Conference (TAC
2008) Workshop-RTE-4 Track. National Institute of
Standards and Technology, pages 17?19.
Cheryl A. Black and H. Andrew Black. 2009. PAWS:
Parser and writer for syntax: Drafting syntactic
grammars in the third wave. In SIL Forum for Lan-
guage Fieldwork, volume 2.
Cheryl A. Black. 2004. Parser and writer for syn-
tax. Paper presented at the International Confer-
ence on Translation with Computer-Assisted Tech-
nology: Changes in Research, Teaching, Evaluation,
and Practice, University of Rome ?La Sapienza?,
April 2004.
Miriam Butt, Helge Dyvik, Tracy Holloway King, Hi-
roshi Masuichi, and Christian Rohrer. 2002. The
parallel grammar project. In Proc. of the Workshop
on Grammar Engineering and Evaluation at COL-
ING 2002, pages 1?7.
John Carroll, Ann Copestake, Dan Flickinger, and Vic-
tor Poznan?ski. 1999. An efficient chart generator
for (semi-) lexicalist grammars. In Proc. of the 7th
European workshop on natural language generation
(EWNLG99), pages 86?95.
Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal recursion semantics:
An introduction. Research on Language & Compu-
tation, 3(4):281?332.
Ann Copestake. 2002. Implementing Typed Feature
Structure Grammars. CSLI, Stanford.
Berthold Crysmann. 2009. Autosegmental representa-
tions in an HPSG for Hausa. In Proc. of the Work-
shop on Grammar Engineering Across Frameworks
2009.
E?ric Villemonte de la Clergerie. 2005. From meta-
grammars to factorized TAG/TIG parsers. In Proc.
of IWPT?05, pages 190?191.
Scott Drellishak and Emily M. Bender. 2005. A co-
ordination module for a crosslinguistic grammar re-
source. In Stefan Mu?ller, editor, Proc. of HPSG
2005, pages 108?128, Stanford. CSLI.
Scott Drellishak. 2009. Widespread But Not Uni-
versal: Improving the Typological Coverage of the
Grammar Matrix. Ph.D. thesis, University of Wash-
ington.
Dan Flickinger. 2000. On building a more efficient
grammar by exploiting types. Natural Language
Engineering, 6:15 ? 28.
Antske Fokkens, Laurie Poulson, and Emily M. Ben-
der. 2009. Inflectional morphology in Turkish VP-
coordination. In Stefan Mu?ller, editor, Proc. of
HPSG 2009, pages 110?130, Stanford. CSLI.
Tracy Holloway King, Martin Forst, Jonas Kuhn, and
Miriam Butt. 2005. The feature space in parallel
grammar writing. Research on Language & Com-
putation, 3(2):139?163.
Stephen McConnel. 1995. PC-PATR Refer-
ence Manual. Summer Institute for Linguistics.
http://www.sil.org/pcpatr/manual/pcpatr.html.
Marjorie McShane and Sergei Nirenburg. 2003. Pa-
rameterizing and eliciting text elements across lan-
guages for use in natural language processing sys-
tems. Machine Translation, 18:129?165.
Christian Monson, Ariadna Font Llitjs, Vamshi Am-
bati, Lori Levin, Alon Lavie, Alison Alvarez,
Roberto Aranovich, Jaime Carbonell, Robert Fred-
erking, Erik Peterson, and Katharina Probst. 2008.
Linguistic structure and bilingual informants help
induce machine translation of lesser-resourced lan-
guages. In LREC?08.
Stefan Mu?ller. 2009. Towards an HPSG analysis of
Maltese. In Bernard Comrie, Ray Fabri, Beth Hume,
Manwel Mifsud, Thomas Stolz, and Martine Van-
hove, editors, Introducing Maltese linguistics. Pa-
pers from the 1st International Conference on Mal-
tese Linguistics, pages 83?112. Benjamins, Amster-
dam.
Stephan Oepen, Erik Velldal, Jan Tore Lnning, Paul
Meurer, Victoria Rosn, and Dan Flickinger. 2007.
Towards hybrid quality-oriented machine transla-
tion. On linguistics and probabilities in MT. In
11th International Conference on Theoretical and
Methodological Issues in Machine Translation.
Carl Pollard and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. The University of
Chicago Press, Chicago, IL.
6
