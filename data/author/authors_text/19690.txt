Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1007?1014, Dublin, Ireland, August 23-29 2014.
 
Identification of Basic Phrases for Kazakh Language using 
Maximum Entropy Model 
         Gulila Altenbek*,+      Xiaolong Wang*      Gulizhada Haisha+ 
*School of Computer Science and Technology, Harbin Instituteof Technology,150001,China. 
+College of Information Science and Engineering, Xinjiang University,830046, China. 
+The Base of Kazakh and Kirghiz Language of National Language Resource Monitoring and   
Research Centre Minority Languages, Xinjiang, 830046, China.  
                gla@insun.hit.edu.cn, gla@xju.edu.cn, wangxl@insun.hit.edu.cn 
Abstract 
This paper proposes the definition, classification and structure of the Kazakh basic phrases, and sets up a 
framework for classifying them according to their syntactic functions. Meanwhile, the structure of the 
Kazakh basic phrases were analyzed; and the determination of the Kazakh basic phrases collocation and 
extraction of the Kazakh basic phrases based on rules were followed. The Maximum Entropy (ME) 
model uses for the identification of the phrases from texts and achieved a result of automatic identifica-
tion of Kazakh phrases with an accuracy of 78.22% based on rules System and additional artificial mod-
ification. Design feature of this ME model join rely on templates of Kazakh Word, part of speech, affix-
es. Experimental results show that the accuracy rate reached 87.89?? 
 
1 Introduction 
Automatic phrase identification is an important task in natural language processing. A phrase is a 
group of words that work together. Phrase recognition is a grammatical unit agent between words and 
sentences in natural language processing. Phrase identification Parser has been developed for different 
languages, for example, the Church's Base NP Recognition for English (Church, 1988). The rule-based 
Model and Maximum Entropy Model (ME) are the most commonly used technology for phrase repre-
sentation and parsing. 
Kazakh Language belongs to the Turkish Language group in the Altaic language family. It is an agglu-
tinative language with word structures formed by adding derivational or inflectional affixes to root 
words. Phrase identification is also an indispensable part for Kazakh information processing. In the 
past a few year, we have put forward methods for Kazakh morphological analysis, which includes 
stem extraction, part of speech(POS) tagging, spelling check, etc. Recently, we are working on syntax 
parsing, analysis of phrase structure, automatic identification of phrase and in-depth analysis of sen-
tence structure. 
Kazakh phrases are syntactic units consisting of two or more than two words. The phrases can be clas-
sified into two categories, which are free phrase and fixed phrase. We are exploring methods which 
are more suitable for shallow syntactic parsing of Kazakh according to the nature of Kazakh language. 
The research includes a systematic study on information regularity and disambiguation of the Kazakh 
phrase, and automatic recognition of basic phrases of Kazakh language. We have developed a rule-
based method for the automatic recognition of Kazakh basic phrases, and automatic identification of 
verb phrase, noun phrase and adjective phrase based on maximum entropy in Kazakh language at the 
same time. Moreover, the ambiguity of structures is also resolved based on rules. 
This study solves the problem of Kazakh phrase recognition by providing some effective methods. 
This sets up a basis for further syntactic process and tree bank building. This research also provides a 
way to build database for various fields like knowledge acquisition, syntactic understanding, Chinese-
Kazakh machine translation, the process of large-scale corpus, etc. 
  
This work is lice ced under a Creative Commons Attribution 4.0 International License Place licence. Page numbers and p oceedi gs f ot r are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 
1007
 In this paper, our work focuses on identifying noun phrases, adjective phrase and verb phrases, which 
are the most difficult aspects of Kazakh phrase recognition analysis. This is achieved by using rules 
are ME method. 
2 Related work 
There are a variety of techniques used for phrase recognition, which include rule-based technique, sta-
tistical technique, and a combination of them. Church's (1988) approach used manual or semi-
automatic annotation phrase corpus as a training corpus. Another popular method is to use a Chunk 
parsing for statistics model to determine the boundary (Koeling, 2000). Chunk parsing was first intro-
duced by Abney (1991), which is one of the most widely used syntactic parsing methods. The main 
idea of chunk parsing lies in seeking the appropriate breakthrough point, and decomposing the full 
parsing problems into a syntax topology statistical structure and syntactic relations. Zhao and Huang 
(1998) are pioneers in Chinese phrase studies; Tsinghua University had also completed its TCT 
(Tsinghua Chinese Treebank) for Chinese (Zhou, 2004). The method has been also applied into studies 
of other languages, such as Kazakh Base NP recognition (Altenbek et al, 2009), and Uyghur Base VP 
Recognition by CRF (Mamatmin et al, 2012). 
Maximum Entropy was first introduced to NLP area by Berger et al (1996) and Della Pietra et al. 
(1997). Maximum Entropy is an extremely flexible technique for linguistic modelling. It can use a vir-
tually unrestricted and rich feature set in the framework of a probability model. It is a conditional, dis-
criminative model and allows mutually dependent variables (Ratnaparkhi, 1999). 
3 Kazakh Phase Parsing 
3.1 Kazakh Morphology 
Morphological analysis is an important task in natural language processing research. It was developed 
for different languages, included English  (Porter, 1980), Finnish  (Karttunen, 1983), Turkish  (Oflaz-
er, 1994; G?l?en, 2004), and Arabic (Beesley, 1996). 
Comparing with other languages, the Kazakh morphological system uses a large number of suffixes 
and a small number of prefixes. Every word has a root, or a stem (Milat, 2003;Zhang 2004). The basic 
Kazakh phrase is an adjacent and non-nested phrase which does not contain recursive structure.  
3.2 The Categories of Kazakh Phrase 
Parsing is one of the most basic and fundamental components in natural language processing. Chunk 
parsing intends to obtain a fragment without thinking deeply.  
A Kazakh phrase is composed of two or more than two words which connected with meaning and 
grammatical structure. There is only a core word in a Kazakh phrase. In the case of Kazakh, Kazakh 
phrases can be divided into fixed phrases and temporary phrases by the meanings of the phrases.  
Abney propose the first complete description of lexical chunks system. In this study the basic phrase 
chunks base was found according to Abney?s system. The five most common phrase in Kazakh are  
NO. Category Explanation Example (Kazakh) Example (English? 
1 NP noun phrase  The golden autumn 
2 VP verb phrase  Achieve dreams 
3 ADJP adjective phrase  Very clean 
4 NUMP Numeral phrases  Eight & nine thousand 
5 ADVP Adverb phrase  The front of 
Table 1.  Part of Kazakh phrase categories. 
 
 
 
 
 1008
 noun phrase, verb phrase, adjective phrase, Numeral phrases, Adverb phrase as shown in table 1. 
Kazakh language is rich in the external morphology which shows prominent in phrase structure. 
3.3 The Basic Kazakh phrase mark specification 
Basic Kazakh phrase marks both its own attribute, for example part of speech, stems and affixes, and 
types of phrase. We used IOB Tagging to mark the start and end of chunks. 
Basic Kazakh phrase start of chunks Inner tag of chunks Out tag of chunks 
noun phrase B-NP I-NP  
 
O 
verb phrase B-VP I-VP 
adjective phrase B-ADJP I-ADJP 
Adverb phrases B-ADVP I-ADVP 
Numeral phrase B-NUMP I-NUMP 
Table 2.  The Basic Kazakh phrase IOB Tagging. 
4 Statistics and Analysis of Kazakh Phrase Structure 
Referring to modern Kazakh grammar (Milat, 2003; Dingjing Zhong. 2004), the basic rules of phrase 
structure of Kazakh language was summarized. The phrase structures are extracted from the corpus, 
and a set of rules are created based on it as well.  
In the representation of basic phrase structures, the following part of speech tagging symbols are used 
in XML documents of Kazakh corpus: v (verb), n. (noun), adj. (adjective), num. (number), adv. (ad-
verb), pron. (pronoun), ono. (onomatopoeia), int.(interjections), conj. (conjunction), part. (partical). 
The Kazakh phrases Structure divided by the function of phrases in our system are shown below.   
Kazakh verb phrase structure: 
1) n+v;   2) v+v;   3) adv+v;  4) adj+v;  5) v+adv;  6) v+v+v;  7) pron+v; 8) n+part+v; 9) n+conj+v; 
10) ono+v; 11) int+v; 12) v+part+v; 13)v+part; 14) v+conj+v;  15)pron+part+v. 
Kazakh noun phrase structure: 
1) n+n; 2) n+conj+n; 3) pron+conj+pron; 4) pron+n; 5) adj+conj+adj; 6) adj+n; 7) adj+adv+n;  
8) num+n; 9) v+n; 10) [ ]+n. 
Kazakh adjective phrase structure: 
1) adj+n; 2) adj+v; 3) adj+n+v; 4) pron+adj; 5) adv+adj+n; 6) adj+adj+n; 7) num+adv+n;  
Collocations, like v+adv, n+part+v, pron+adv, v+part+v, v+part, also exist in other phrase except verb 
phrase. These conditions easily cause ambiguity.  
5 Rule-based phrase tagging 
Kazakh language has two characteristics that have to be taken into account: agglutinative morphology 
and rather free word order with explicit case marking. 
The corpus we used in this process has been already segmented. The way we extracted stem and affix 
was briefly mentioned in the paper. In this paper we used the segmented results of early work, as it is 
not the core part of the algorithm. 
Input: word segmentation (extraction stem and affix) and POS tagged corpus (test.xml); 
Output: First: Phrase tagged file; Second: Phrase file; 
Based on the basic rules of phrase, we have done extraction of phrases from POS tagged Kazakh cor-
pus. The extraction process is as follows: 
(a) First roughly segmented XML corpus. The common segmentation marks include semicolon, com-
ma, full stop, exclamation mark, question mark. 
(b) For the segmented data, we extract the three elements of basic phrase: part of speech (POS), affix, 
and the word. 
 
 
 
 1009
 (c) Look for the matched rule in the rule set. If found, save the basic phrase. Otherwise go back step 1. 
According to combination rules of basic Kazakh phrase, basic phrase was extracted from corpus and 
modified by manual work. The correct combination of basic Kazakh phrase was marked. 
6 Analysis of Kazakh phrase structure ambiguity 
Ambiguity computer analysis of language structure has been one of the difficulties problems. This ar-
ticle from the delimitation ambiguity and structural relationship is to study two aspects of phrase struc-
ture ambiguity.  
One of the difficulties in Kazakh phrase research is the phrase disambiguation problem. Ambiguous 
reasons is word POS ambiguity, phrase boundaries is not easy to determine, POS with the same se-
quence, E.g.  there are five  ambiguous forms: 
(1) VD form (v + adv ) 
Eg.1a?   is verb phrase. (Admission to reduce) 
Eg.1b?  is adverb phrase. ( Admission to more than) 
(2) ND for (n+adv, pron+adv) 
Eg.2a?  is verb phrase.( Change a new clothes) 
Eg.2b?  is adverb phrase.( Good record) 
(3) NPV form? n+part+v,  pron+part+v) 
Eg.3a?  is verb phrase.( Learn about unity) 
Eg.3b?  is noun phrase.( only Ashan) 
(4) VPV form (v+part+v) 
Eg.4a?  is verb phrase.( came then left) 
Eg.4b?  is adverb phrase. (Relevant research to understand) 
(5) VP form (v+part) 
Eg.5a?  is verb phrase.( Speaking before) 
Eg.5b?  is verb phrase.( Organize the relevant) 
For these ambiguities, we can't simply use the rules to match ways to eliminate, but rather to use max-
imum entropy model to solve the problem. 
7 Kazakh Phrase Identification based Maximum Entropy Model 
Maximum Entropy Model is an effective machine learning model which is proposed to solve the POS 
tagging problem, it using ME model is the ability to incorporate various features into the conditional 
probability. The Kazakh phrase recognition task is presented as follow.  
The entropy model P:    ??? yx yxyxppH , ),log(),()(            (1) 
Note: X represents the environmental context words to be marked and y is the output. 
Maximum Entropy Model? Such a model can be shown to have the following form:  
)(maxarg* pHp Cp??                                                      (2) 
Goal: select a distribution p from a set of allowed distributions that maximizes H(y|X).   
7.1 Feature defined 
Kazakh language is an agglutinative language with word structures formed by adding derivational, 
inflectional affixes or suffixes to root words. The features include words, part of speech (POS), inflec-
tional affixes of the training corpus. It seems that the features are na?ve. However, these three kinds of 
features are the most important components of Kazakh language, and they reflect the characteristic of 
Kazakh language. 
According to its own characteristics of a Kazakh, this feature space is defined as follows: 
(1) the word, including the current word, the previous word and next word. 
 
 
 
 
1010
 (2) part of speech(POS), including the part-of-speech types of the current word, previous word and  
next word. 
(3) Affix ingredients, including the current word and the word about the additional ingredient info-
mation. 
(4) Phrase tag that contains the current word and the words to the right and the left two words Phrase 
marker. 
This rule-based approach was applied to generate the maximum entropy model training corpus. Based 
on Kazakh linguistics, the atomic feature space is as shown in table 3. 
Feature tag Feature explanation Feature tag Feature explanation 
W(-1) 
previous one word POS (-2) 
POS (-1) 
POS of previous two word and POS 
of previous one word 
W(0) 
the current word POS (-1) 
POS (0) 
POS of previous one word and POS 
of the current word 
W(+1) 
next one word POS (0) 
POS (+1) 
POS of the current word and POS of 
next one word 
W(-1) 
W(0) 
previous one word 
and the current word 
POS (+1) 
POS (+2) 
POS of next one word and POS of 
next two word 
W(0) 
W(+1) 
the current word and 
next one word 
POS (-2? 
POS (-1)  
POS (0) 
POS of previous two word and POS 
of previous one word and POS of the 
current word 
W(-1) 
W(0? 
W(+1) 
previous one word 
and the current word 
and next one word 
POS (-1)  
POS (0) 
POS (+1) 
POS of previous one word and POS 
of the current word and POS of next 
one word 
POS (-2) 
POS of previous two 
word 
POS (0)  
POS (+1) 
POS (+2) 
POS of the current word and POS of 
next one word and POS of next two 
word 
POS (-1) 
POS of previous one 
word 
Affix(-1) 
affix of previous word  
POS (0? 
POS of the current 
word 
Affix(0) 
affix of current word 
POS (+1) POS of next one word Affix(1) affix of next one word 
POS (+2) POS of next two word   
Table 3.  Atomic feature templates. 
7.2  Feature selection 
Basic phrases with statistical model recognition need to select a high correlation, and the Kazakh lan-
guage features to train with good effect. Establish model based on rule of the language, this work se-
lected feature through templates. After several rounds of experimental debugging, then used artificial 
selection, twenty one templates were selected for Kazakh verb  phrase, only considered important fea-
tures. According to each one?s feature, templates were defined as follow. 
No. template No. template No. template 
1 LPos,Cpos,RPos 8 CVP,RVP,RRVP 15 CWord,RWord 
2 LLPos,Lpos,CPos 9 LVPCPosRVP 16 LPos,LVP 
3 CPos,Rpos,RRPos 10 LPos, LAffix, LVP 17 RWord,RPos 
4 CPos,CAffix,RPos 11 Cpos, CAffix, CVP 18 RPos,RVP 
5 LPosLAffixCPos 12 CWord,RWord,RAffix 19 CPos,RPos 
6 LVP,CVP,RVP 13 CWord,CPos 20 LPos,CPos 
7 LLVP,LVP,CVP 14 LWord,LPos 21 LWord,LVP 
                           Table 4.  Combined  feature of Kz Base VP. 
In order to get the best template, this work structured and processed six template based on Table 4.  
 
 
1011
 Each information function valued in the context of current word, combine the various function values 
into the premise of features, got the characteristics of the movement through the word tag, then it can 
extract features. 
Template A: [RRPos, RRVP, RWord, RAffix, RPos, RVP, CPos, CVP, CWord, CAffix, LLPos, 
LLVP, LWord, LAffix, LPos, LVP] Observation of effects of all the words in the feature space on the 
result of the experiment.  
Template B: [CPos, CVP, CWord, CAffix, LLPos, LLVP, LWord, LAffix, LPos, LVP] Observation of 
effects of left side two words of the candidate word on the result of the experiment. 
Template C:[ RRPos?RRVP?RWord?RAffix?RPos?RVP?CPos?CVP?CWord,CAffix] Ob-
servation of effects of right side two words of the candidate word on the result of the experiment. 
Template D:[ RWord?RAffix?RPos?RVP?CPos?CVP?CWord,CAffix? LWord?LAffix?
LPos?LVP] Observation of effects of each side one word of the candidate word on the result of the 
experiment. 
Template E:[ RWord?RAffix?RPos?RVP?CPos?CVP?CWord?CAffix, LLPos?LLVP?
LWord?LAffix?LPos?LVP] Observation of effects of left side two words and right side one word 
of the candidate word on the result of the experiment.  
Template F:[ RRPos?RRVP?RWord?RAffix?RPos?RVP?CPos?CVP?CWord?CAffix?
LWord?LAffix?LPos?LVP] Observation of effects of left side one word and right side two words 
of the candidate word on the result of the experiment. 
We selected some corpus from Xinjiang Daily tested on six features above, we got different influences 
of different characters. It shows that the C and F template give us the most highest result, namely the 
two words on the right have the biggest influence to the result. It proves Kazakh verb phrases are 
commonly at the end of the sentence.  
7.3    General threshold selection 
There are two general feature selection methods: incremental feature selection and feature selection of 
based on frequency threshold. The frequency is greater than a threshold value equal to a characteristic. 
Through repeating them many times, the frequency threshold value was characterized k = 5, character-
ized in that the use of the frequency characteristic is greater than 5. 
8 Kazakh Phrase Recognition System 
Kazakh phrase recognition system, which based on Maximum Entropy Model, consists of four mod-
ules, namely, pre-processing module, training module, Feature selection module, identification mod-
ule. System training process as shown flow as figure 1. 
Feature 
module base
Training 
corpus
Learning 
documentPreprocessing Feature selection
Parameter 
estimation 
algorithm
  
Figure 1.  Training data flow diagram. 
System testing process as shown flow as figure 2. 
learning 
documents
Test 
corpus
Preprocessing Feature 
extraction
decoding
Identify  
output
 
Figure 2. Testing data flow diagram. 
The Kazakh basic verb phrase recognition results such as shown figure 3: 
1012
  
Figure 3. The Kazakh language basic verb phrase recognition. 
By following a comprehensive analysis of Kazakh words, the following is the Kazakh shallow parsing 
process: 
?1?Sentence? 
 
Golden autumn is coming, Hambar came to the place whish has very strong winds together with 
sheep. 
?2? POS: 
 
?3?Phrase POS: 
 
9   Experiment Results and Analysis 
9.1 Data set 
In this paper, according to the data set, we used the data of January 2008 of the Xinjiang Daily (Ka-
zakh version) corpus. The corpus consists of the raw texts and the POS tagged XML format texts, ex-
periments were done for phrase extraction. 
9.2 Experiment results 
The experiments of the accuracy rates are evaluated using as follow standard evaluation measures: 
 
Precision:    
%100?? baP          (3)
 
Recall     
%100?? dcR
             (4) 
F-measure    
PR PRF ???? 2
              (5) 
Note: a is number of correctly identified phrases. b is number of identified phrases. c is number of all phrases, d 
is number of should correct identify. 
 
In the test corpus, there are 3000 correct tagged sentences as training data, and other 1000 sentences 
are for the test. 
 
 
 
 
 1013
 Method Precision (%) Recall (%) F-measure (%) 
Rule 78.22 70.01 85.25 
ME 87.89 83.13 87.46 
               Table 5.  Phrase recognition test. 
10 Conclusion 
This paper provided solution for identifying Kazakh basic phrases. We have tried rule-based and the 
maximum entropy methods. The Kazakh words, part of speech, affixes context information are used to 
design template of features for maximum entropy model. Based on statistical methods, higher accura-
cy could be obtained in the test, but it was requires more training data.  
The recognition of basic Kazakh phrase could simplify sentence structure, reduce the difficulty of syn-
tactic analyzer. This work put maximum entropy model into recognition of basic Kazakh phrase. 
However, there are still space for improvement on scale and accuracy rate comparing to English and 
Chinese. In the future, our work will focus on completing of corpus and other models. 
Acknowledgments 
This work is funded by the Natural Science Foundation of P.R. China (NSFC)(No.61363062,  No. 
61063025  and No.61272383), Science and Technology Research and Development Funds of Shen-
zhen City (No. JC201005260118A). 
Reference 
Church K. A stochastic parts program and noun phrase parser for unrestricted text. 1988. In Proceedings of the 
Second Conference on Applied Natural Language Processing. Texas, USA. 19(8):136-143. 
Rob Koeling . Chunking with Maximum Entropy Models. 2000. Proceedings of CoNLL-2000 and LLL-2000. 
109(15):139-141. 
Steven Abney. Parsing by chunks. 1991. Dordrecht: Kluwer Academic Publishers. 257-278. 
Zhao Jun and Huang Changning. 1999. Chinese basic noun phrase structure analysis model, Computer science . 
22(2):141-146? 
Qiang Zhou. 2004. Annotation scheme for Chinese Treebank, Journal of Chinese Information Processing. Vol 
18(4):1-8. 
Gulila Altenbek, Ruina-Sun. 2010. Kazakh Noun Phrase Extraction based on N-gram and Rules, International 
Conference on Asian Language Processing (IALP2010). Harbin, China. 305-308. 
Gulila A. and Dawel, A. and Muheyat, N. 2009. A Study of Word Tagging Corpus for the Modern Kazakh Lan-
guage, Journal of Xinjiang University. 26(4):394-401. 
Zulpiya Mamatmin  et al, 2012.Uyghur Base Verb phrases Recognition . A master's degree thesis, Beijing uni-
versity of posts and telecommunications. 
Adam Berger, Stephen Della Pietra, and Vincent Della Pietra. 1996. A Maximum Entropy Approach to Natural 
Language ,Processing Computational Linguistics, 22(1):39-71. 
Adwait Ratnaparkhi. 1999. Learning to parse natural language with maximum entropy models.  Machine Learn-
ing, 341(3):151-176 
Porter, M.F. 1980. An algorithm for suffix stripping, Program, 14(3):130?137. 
Karttunen, Lauri. 1983. KIMMO: A general morphological processor. Texas Linguistic Forum, 22:163?186. 
Kemal Oflazer. 1994. Two-level description of Turkish morphology. Literary and Linguistic Computing, 
9(2):137-148. 
G?l?en, E. and E?ref, A. 2004. An affix stripping morphological analyzer for Turkish, Proceedings of the Inter-
national Conference on Artificial Intelligence and Application, Austria, 299-304. 
Beesley, K.R. 1996. Arabic finite-state morphological analysis and generation. In COLING-96, Copenhagen, 89-
94. 
Milat, A. 2003. Modern Kazakh language, Xinjiang People's press, China. 
Dingjing Zhang. 2004. Practical Grammar of Modern Kazakh Language. Beijing: Central University for Na-
tionalities Press. 
1014
 Kazakh Segmentation System of Inflectional Affixes  
Gulila.Altenbek 
1.Information Science and Engineering Colleges 
Xinjiang University,  
  Xinjiang Lab. of Multilanguage Information Technology , 
830046?P.R. China. 
2?Harbin Institute of Technology, Harbin
gla@xju.edu.cn 
WANG Xiao-long  
Institute of Computer Science and Technology,  
Harbin Institute of Technology, Harbin,  
150001, P.R. China. 
wangxl@insun.hit.edu.cn
Abstract
This paper focuses on the automatic segmentation 
of inflectional affixes of the Kazakh Language (KL) 
on the basis of studying the corpus of KL. Kazakh is 
an agglutinative language with word structures 
formed by productive affixation of derivational and 
inflectional suffixes to stems. Based on the analysis 
of the configuration of inflectional affixes, it firstly 
constructs the Finite-State Automation and the 
segmentation of inflectional affixes. Secondly it 
targets at specially constructing the Finite-State 
Automations of nouns and verbs, which are the 
most changeable and complex part of speech of KL. 
And thirdly it adopts the methods of Bidirectional 
Omni-Word Segmentation and lexical analysis to 
achieve the goal of stemming and fine segmentation 
of inflectional affixes of KL. And finally it gives an 
additional account of studying the segmentation of 
ambiguous inflectional affixes. The paper intends 
to improve the accuracy and the quickness of 
stemming the inflectional affixes of KL.  
1 Introduction 
Lexical or morphemic analysis is to turn the character 
string of natural language into ?the word string?. 
During the process, at first it takes ?the word? out,, and 
then conducts the morphological analysis of the 
internal components of ?the word?, and finally it ends 
up with the tagging. Many language processing tasks, 
including parsing, semantic analysis, information 
retrieval, and machine translation usually require a 
morphological analysis of the language beforehand.  
As we know, Kazakh Language belongs to Turkish 
Language group of Altaic Language Family, whose 
unique language features decide that we should focus 
on its Inflectional Morphology is inflectionally 
changed. Kazakh language is written right-to-left in 
the Arabic alphabet with some modifications.  
 This paper attaches importance to analyzing the 
nouns and the verbs, which have great difficulties in 
affixes segmentation. And this paper will definitely 
contribute to the further study of lexical analysis of 
KL.
2 Related works 
There have been some related studies, such as, Martin 
Porter has proposed ?English Stemming Processor? 
(1980), which is most widely used; The 
Longest-March put forward by Kut is a type of word 
Segmentation algorithm based on the Turkish 
Lexicon(1995).Beihang University has finished its 
CDWS Chinese Word Segmentation System 
(nan-yuan.Liang, 1987); Tsinghua University has also 
completed its SEG Chinese Word Segmentation 
System(Da-yang Shen et al,1997); and <The 
Grammatical Knowledge-base of Contemporary 
Chinese> edited  by Peking University was also 
published(Shi-Wen,Yu, 2003).  
And the study of lexical analysis of minority 
languages has also achieved a lot in China, Some 
researches(A.Gulila and A.M i j i t?2004, K.Aykiz et 
al.,2006, YuSufu, 2005)  have been done in the 
lexical analysis of Uighur Language conducted 
Xinjiang; the Automatic Segmentation System of 
Mongolian language conducted by Inner Mongolia 
University (U.Nasun, 1997) ; And the lexical analysis 
of kazakh Language conducted by our project is in 
progress (A.Gulila and A.Dawel,2007) and so on. 
There have been several main approaches or 
algorithms to segment inflectional affixes, including 
maximum matching algorithm based on mechanic 
matching of character strings, rules-based algorithm, 
statistics-based algorithm, and the combination of both 
rules-based and statistics-based algorithms.  
3 Kazakh Morphology 
3.1 Kazakh Morphology 
Kazakh is an agglutinative language with word 
structures formed by affixes to grammatically or 
meaningfully change the words.Kazakh morphology is 
an affixal system consisting mainly of suffixes and a 
few prefixes. According to linguistic theory, the word 
of the text consists of the root or the stem and the 
affix.( Milat etc. 2003, ding-jin Zhang. 2004). 
gWord root is the core of the whole word structure, 
which is the essential morpheme to convey the basic 
content of its meaning.  
gWord stem is a new word generated by adding 
various affixes to the root, which is also called a 
derivative word. It expresses the complete and full 
meaning.
gAffixes are divided into inflectional affixes and 
derivational affixes. The study of derivational affixes 
focuses on the derivational words, which can be 
formed by adding prefixes or suffixes or prefixes plus 
suffixes. Meanwhile the meanings of the derivational 
words will be changed. While the study of inflectional 
affixes pays attention to the Inflectional Morphology, 
which shows grammatical changes between words but 
does not change word meanings.  
3.2 The Analysis of Inflectional Affixes 
We focus on most general morphological rules which 
are common rules related to morpheme segmentation. 
The inflectional affixes in Kazakhh language are 
divided into the following four types: 
1) Plural: KL has six various affixes to express the 
plural form of words, which usually are directly linked 
to the general nouns, pronouns and numerals.   
2) Personal pronoun possessive: KL has six various 
affixes to express the possessive forms of personal 
pronouns.  
3) Case: KL has seven various affixes to express the 
different cases. So KL has seven cases. Case endings 
are applied only to the last element of a noun phrase, 
which are closely linked to the following verbs. 
4) Predicative Person: The first, second and third 
personal pronouns are usually followed by the words 
with additive predicative personal elements.  
The above-mentioned four types of inflectional affixes 
can be used separately or linked together. Suffixes in 
Kazakh are complex, especially when a stem is linked 
with many suffixes. There are some rules we can 
follow to add affixes to word roots. See Figure 1: 
(Right-to-Left)
Figure 1. Rules to guide the connections of inflectional 
affixes 
3.3 The Finite-state Automaton model of 
inflectional affixes of KL  
Finite-State Automata (FSA) can be used to describe 
the possible word forms of a language. We have 
already applied the model of FSA into the lexical 
analysis of KL. The following figure shows a FSA 
model of inflectional changes of a noun. See Figure 2: 
Figure 2. The FSA model of inflectional changes of a noun. 
4 The Finite-state Transducer (FST) of 
Kazakh Words 
As a typical agglutinative language, Kazakh words are 
formed by adding various suffix to word roots. But the 
Kazakh language itself does not have prefixes with 
exception of some borrowed or loaned prefixes from 
foreign words. And there are some rules guiding the 
usage and connection of various suffixes. Thus we can 
apply FST to establish a model for Kazakh words. The 
process of establishing a FST model can be divided 
into the following steps(E.G?l?en & A.E?ref. 2004): 
Step 1: Establish a Right-to-Left FSM. 
Step 2: Tag affixes  
Step 3: Reverse the Right-to-Left FSM, and get a 
Non-deterministic Finite-state Automaton (NFA) 
Step 4: Convert the NFA to a Deterministic 
Finite-state Automaton (DFA) and establish a 
Left-to-Right FSM.  
The Kazakh words that can be added affixes to 
themselves are the followings: nouns, numerals, 
adjectives, pronouns, verbs, adverbs and so on. 
Among them, nouns and verbs are the most difficult 
parts of speech to be segmented. Take these two parts 
of speech as examples: 
4.1 Inflectional Affixes of Nouns 
Step 1: Establish a Right-to-Left FSM . 
The four types of inflectional affixes can be added to 
stems under the guidance of some rules which also 
decide the FSM. We can apply the FSM to segment 
stens and we can analyze the FSM from right to left. 
See Figure 3: 
Figure 3.  Right-to-Left FSM of inflectional affixes. 
Step 2: Tag affixes 
How to tag depends on the types of inflectional 
affixes, in which each type is given a value as its 
expressing value. Those affixes will be stored in the 
database as well as those expressing values. See Table 1   
Table 1. Types and Expressing Values of Inflectional 
Affixes of Nouns. 
inflectional affixes 
Type 
value Inflectional affixes 
type 
value
Plural 1 Personal pronoun 
possessive: plural 
4
Case 2 predicative person: 
singular  
5
Personal pronoun 
possessive: 
singular 
3 predicative person: 
plural  
6
Step 3: Reverse the Right-to-Left FSM to form a 
Left-to-Right  FSM 
Reverse the Right-to-Left FSM, and form a 
Non-deterministic Finite-state Automaton (NFA) (See 
Figure 4). The number in each circle of Figure 4 
represents the state value consistent with the state 
value of Figure 3. The types and expressing values are 
also marked above the lines in Figure 4. 
Figure 4.  Left-to-Right NFA of inflectional affixes. 
Step 4: Convert NFA to DFA  
The multi-switches and "?" switches of an expressing 
value of NFA makes the realization of NFA on 
computer very complex. Therefore, we should convert 
the NFA to be a DFA with the purpose of making each 
inputted expressing value facing one switch and 
making "?" switch nonexistent. We adopt ?subset 
construction algorithm?[A.V.Aho et al ,1986] to 
conduct the operation. We make each state of the new 
DFA correspondent to a subset of the NFA. As Table 2 
shows, the start state (A)of DFA contains one element 
?0? and the start state of  NFA. We know that all other 
states can be achieved from the state ?0? through "?"
switches. Thus, the start state of DFA could be 
A={0? 1? 2? 3? 4? 5}. The numbers in the 
brackets represent inputted expressing values or types 
of affixes. The next state of DFA should be started 
with A and ?1? 2? 3? 4? 5?can be separately 
inputted as expressing values. The FAS can thus be 
established.
Table 2. The Conversion from NFA to DFA of Inflectional 
Affixes. 
?-closure(C,1)={1} 
B
?-closure(D,1)={1} 
B
?-closure({0})={0,1,2,3,4,5}*A 
?-closure(A,1)={1} *B 
?-closure(A,2)={1,2,3} *C 
?-closure(A,4)={2,4} *D 
?-closure(A,6)={2} *E ?-closure(E,1)={1} B
Figure 5. FSM of Inflectional Affixes of Nouns. 
inflectional affixes of verbs.  
5 Approaches to the Segmentation of 
Inflectional Affixes of Kazakh Words 
Some mathematical frameworks or modeling 
methodologies can be used for morphology learning  
and word segmentation: maximum likelihood (ML) 
modeling, probabilistic maximum a posteriori (MAP) 
models, finite state automata (FSA), etc.  
The algorithms suitable for the segmentation of 
inflectional affixes of Kazakh words include the 
followings: Bidirectional Maximum Matching and 
Omni-word Segmentation. 
5.1 Bidirectional Matching Algorithm 
Forward and backward algorithm is applied for the 
segmentation of a given word is examined for the 
words whose surface forms change after concatenation.   
The basic idea of this approach is to conduct the 
segmentation of inflectional affixes from left side of a 
character string to its right side and vice versa. But 
during the process, the critical issue is to determine the 
border between stens and inflectional affixes. Under 
many situations, vague borders between stens and 
inflectional affixes cause the inaccurate stemming. 
Thus, this algorithm can solve this problem. 
5.2 Omni-word Segmentation Algorithm 
The basic idea of this algorithm is to find all the 
segmentation forms of character strings waited for the 
segmentation starting from position ?i?. For Kazakh 
text, we should find all the segmentation forms of a 
word. We just leave the issue of ambiguity for later 
discussion.
5.3 The Combination of Bidirectional 
Omni-word Segmentation Algorithm and 
The Lexical Analysis 
1) The segmentation of inflectional affixes is 
conducted from the left side of a Kazakh word and 
then matched with the table of inflectional affixes. In 
general the inflectional affixes are formed by short 
character strings. Therefore some inflectional affixes 
maybe become sub-strings of other inflectional affixes. 
It is very possible that there are many successful 
matches of inflectional affixes, that is to say, there will 
be various segmentations of inflectional affixes of a 
word, But only one of them is accurate. So we need to 
classify the inflectional affixes and enact the rules to 
guide their connection order. According to those rules 
we just search one type of inflectional affixes and 
adopt Maximum matching algorithm to avoid the 
problem of many segmentations of an affix. When 
conducting the segmentation of inflectional affixes 
and the stem extraction, we call the far right side of 
segmentation border ?candidate border? . 
2) The extract stems is conducted from the right side of 
a Kazakh word and then matched with the lexicon in 
order to find the candidate border of the sten. The 
ability to form new words for some affixes is very 
strong, so many stems which are added to various 
derivational affixes become new stems of other words. 
So the situation is the same with the segmentation of 
inflectional affixes. We should conduct Omni-word 
Segmentation and list all the possible segmentation 
forms of affixes.  
We should deal with some special problems when 
conducting segmentation of inflectional affixes. 
Borders of stens will be changed somewhat when 
some inflectional affixes are added to the stens. 
Changes would occur like vowel deletion and lenition 
reduction. Sometimes it is impossible to find the 
complete match in the lexicon. Under such situation, 
we should apply orthographic rule of Kazakh language 
to deal with it. 
6 The Analysis of the Ambiguity of 
Inflectional Affixes 
6.1 Rule-based analysis of Ambiguity 
To prevent over-segmentation and secure the semantic 
identity of a word, stem and suffix boundary is chosen 
as the primary target of segmentation.  
 Suppose the right border of inflectional affix is 
indicated as S1 while the left border of sten as S2. The 
ambiguity probably occurred in the segmentation is 
listed below as well as its solution.  
1) S1=S2  (Under various situations, it is possible that 
S1 is S2):  Under this situation we should segment the 
longest sten.  
2) S1 ?S2 (Under this situation, we also consider the 
following two cases see Figure 8) 
Case 1:  
(1) The sub-string on the right side of S1 will be 
regarded as the candidate stem. And then we should 
apply orthographic rule to make a choice of the 
candidate stem and the sub-string on the left side of S1.  
(2) If some variants of the words do exist, a new sten is 
formed; otherwise, go to Step 5. 
(3) We should search the new sten in the lexicon 
(4) If we succeed to find the new sten in the lexicon, 
please tag the stem and the inflectional affix (the left 
sub-string of S1) 
(5) End 
Case 2:We should apply probability statistics to solve 
the problem. 
Figure 6(a).  Case 1: (S1 ?S2). 
Figure 6(b).  Case 2: (S1 ?S2). 
3) Non-matched stems but with matched inflectional 
affixes
We adopt the same solution to deal with this 
situation. That is to say, we at first should apply 
orthographic rule to make a choice of the sub-string on 
the left side of S1 and the sub-string on the right side of 
S1.And we also try to find the existence of lenition 
reduction. If we could not find the new sten in the 
lexicon, we should change to apply probability 
statistics to analyze. 
4) Non-matched stens with non-matched inflectional 
affixes
We should search the inflectional affixes from the 
left side of the word to be segmented. If we could not 
find the match in the lexicon, we should judge the 
suffix and the sub-string on the right side by use of 
orthographic rule. And then we continue to search the 
candidate stem in the lexicon. If the match does exist, 
we tag the word as a sten; otherwise we tag it as an 
unregistered word. 
5) Non-matched inflectional affixes with matched 
stems. 
We consider the sub-string on the left side of the 
stem as the candidate derivational affix and search the 
match in the table of derivational affixes. If  the match 
could be found in the table and its type is the same with 
the stem , we should tag the word as a stem; otherwise 
we tag it as an unregistered word.  
6.2 The ambiguity analysis based on Bayesian 
classification
The principle of Semantic Bayesian classifier is to 
consider the information of surrounding words of 
ambiguous words in a large context.  Each practical 
word contains potentially useful information to imply 
the possible semantics of the ambiguous words. This 
Classifier is not a features selection but a combination 
of all features. The ambiguous words of the corpus 
should be semantically tagged in advance.Table 3 lists 
some symbols presented by this paper.      
Table 3.  Symbols Agreement. 
Symbol Meaning 
W An ambiguous word 
s1,?,sk,?,sK ALL the different segmentations 
of W 
c1,?,ci,?,cI the context in which W is in the 
corpus
v1,?,vj,?,vJ the context features of the 
Disambiguation  
When selecting the types, the Bayesian classifier using 
Bayesian decision-making rules could be used; those 
rules can minimize the error probability (R. O.Duda, P. 
E. Hart. ,1973). 
According to simple Bayesian assumption, we have 
revised the decision making rules, as follows:  
Simple Bayesian decision-making rules. 
Decide 
'
s  if 
'
s =argmaxsk[logP(sk) + ?vj in clogP(vj|sk)]  ?1?
P (vj | sk) and P (sk) in the formula can be calculated 
using the maximum likelihood estimates from the 
tagging of training in Corpus: 
)](log)(max[logarg
)()(maxarg
)(
)(
)(
maxarg
)(maxarg'
kks
kks
k
k
s
ks
sPscP
sPscP
sP
cP
scP
csPs
k
k
k
k
 
 
 
 
)(
)(
)(
),(
),(
)|(
wC
sC
sP
svC
svC
svP
k
k
ktt
kj
kj
 
 
?
                   ?2?
C(vj,sk) in the formula is the number to show how 
many times sk is to be segmented by vj in the context 
of training materials; C (sk) is the number to show how 
many times that sk occur in the training corpus; and C 
(w) is the total number to show how many times the 
unambiguous words occur.     
Figure 7.  Bayes Disambiguation. 
7 The Design of the System 
In the process of segmenting affixes in Kazakh 
language, the main task is to segment the prefixes, 
stems, and inflectional affixes. For this purpose, About 
60,000 stems and  438 tables of affixes are collected 
as the basis of segmentation. The stem list consists of 
almost all the common stems except from the domain 
specific words and rarely used words. The realization 
of the whole system experiences the following steps: 
1) Take a Kazakh word from a text.  
2) Establish a FSM of a noun or a verb. If possible, 
directly give the result of segmentation and return to 
step 1;otherwise turn to the next step.  
3) Adopt the combination of Bidirectional Omni-word 
Segmentation Algorithm and the Lexical Analysis to 
analyze for the words to be segmented. If possibly 
segmented, directly give the result of the segmentation 
and return to step 1; otherwise adopt Bayesian 
Classification by use of the parameters from the 
training corpus to select the correct segmentation of 
ambiguous words.  
4) The result of tagging the segmentation of affixes . 
The corpus contains 150?992 words, among which 
51% is used as training corpus while the rest as test 
corpus. The accuracy rates generated from the testes 
conducted for this paper include Precision 1 and 
Precision 2. We can define two evaluation functions, 
as follows: 
Definition 1:The accuracy rate of inflectional affixes 
segmentation of words. 
numbers of correct extracted stems
1 100%
total words
precision  u
 (3) 
Definition 2: The accuracy rate of inflectional affixes 
segmentation of ambiguous words 
numbers of correct extracted ambiguous words
2 100%
total number of ambiguous words
precision  u
 (4) 
8 Experimental results 
8.1 The comparison of the segmentation speeds  
Table 5 shows the comparison of the segmentation 
speeds, in which we compare the system adopting 
FSM to the system not adopting FSM. We have tested 
10?000 words and the result of the comparison is 
quite obvious, which indicates the high segmentation 
speed of the system adopting FSM.   
Table 4. The comparison of Two segmentation speeds. 
Type of 
segmentation  
The
number 
of tested 
words 
Total time 
used for 
segmentation 
(Ms) 
average 
velocity 
(Ms/words)
not adopting 
FSM
100,00 24?422 2.4422 
adopting 
FSM
100,00 19?408 1.9408 
8.2 The Analysis of the result of inflectional 
affixes segmentation  
This paper adopts the combination of bidirectional 
omni-segmentation and rule-based segmentation to 
segment inflectional affixes and extract stems.  
Table 5. The contrast of affix segmentations by use of 
different algorithms. 
Algorithms  
Precision1
?%?
Omni-word Segmentation  78.1 
Maximum matching 74.2 
Combination of bidirectional 
omni-segmentation and lexical analysis 
84.0 
The tests show that the final one improves the 
accuracy rate of affix segmentation and realizes the 
segmentation of inflectional affixes.  
8.3 The Analysis of segmentation of ambiguous 
words
This paper puts forward that we should firstly adopt 
rule-based approach or algorithm to the segmentation 
of ambiguous words, if without any result, we should 
adopt Bayesian Classification to the segmentation of 
ambiguous words.  In the test corpora, among 74,026 
words 922 words are ambiguous words. So at first we 
should adopt rule-based algorithm to deal with those 
ambiguous words, in which 600 ambiguous words can 
be correctly dealt with; and then we should adopt 
Bayesian Classification Algorithm to further improve 
the accuracy rate of the segmentation of ambiguous 
words. As a result, the accuracy rate of the 
segmentation of ambiguous words can be reached to 
84.38%. Table 7 shows the analysis of the 
segmentation of ambiguous words.  
Table 6. The analysis of the segmentation of ambiguous 
words. 
Algorithm to deal
with ambiguous
words 
Total number 
of ambiguous 
words of test 
corpora
Number of 
correctly
segmented 
ambiguous 
words 
Precision2
?%?
Rule-based 
segmentation of 
ambiguous 
words 
922 532 57.70% 
Bayesian 
classification
390 246 63.07% 
9 Conclusion and Future Study  
This paper firstly analyzes the morphemic structure in 
the corpus of Kazakh Language, and especially studies 
stem extraction and affix segmentation. It establishes 
the FSM of inflectional affixes and then conducts the 
segmentation of inflectional affixes. The process starts 
with the analysis of FSM of the words to be segmented. 
If successfully achieved, the result would be 
considered as the result of segmentation. Otherwise, 
the algorithm of combining the bidirectional 
omni-word segmentation and ruled based 
segmentation should be adopted to segment the 
inflectional affixes, which better solves the problem of 
segmenting inflectional affixes. At last the paper 
presents that we should apply the method of statistics 
to disambiguate the segmentation of inflectional 
affixes of ambiguous words. Compared to other 
approaches, this approach improves the accuracy rate 
and the segmentation speed of segmenting inflectional 
affixes.
But there exist other problems presented in this paper, 
such as unregistered words. We should continue to 
make efforts to improve the accuracy rate of the 
segmentation of inflectional affixes through further 
enlarging the vocabulary of the dictionary and 
adopting the method of statistics. And we should be 
well-trained in obtaining parameters of segmentation 
models of Kazakh Language, making the language 
model close to the reality language itself.  
Acknowledgment 
This work is funded by the Natural Science 
Foundation of China(NSFC)(No.60763005), And  the 
Project of China Ministry of Education 
(No.MZ115-92). 
References 
A.Kut, A. Aplko?ak, E.?zkarahan. 1995.Bilgi bulma 
sistemleri i?in otomatic turk?e dizinleme y?ntemi. 
In Bili?im Bildirileri, Dokuz Eyl?l University, ?zmir, 
Turkey. 
A.V.Aho,R.Sethi&J.D.Ullman. 1986. Compilers: 
principles,techniques,tools[R].Reading,MA:Addiso
n Wesley. 
A.Gulila ,A.M i j i t.2004 .Reseach on Uighur Word 
Segmentation, Journal of Chinese information 
processing ,l . 18( 6):61-65.  
A.Gulila, A.Dawel.2007.Study on the Rule-based 
Kazakh Word Lemmatization, 11TH  Symposium 
national language and information 
Proceedings ,Xishuangbanna, 109-114. 
E.G?l?en , A.E?ref. 2004. An affix stripping 
morphological analyzer for Turkish, Proceedings of 
the International Conference on Artificial 
Intelligence and Application,Austria,299-304. 
K.Aykiz,K.Kaysar,I.Turgun,2006.Morphological 
Analysis of Uighur Noun for Natural Language 
Information Processing,Journal of Chinese 
information processing?20(3)?43-48. 
Liang nan-yuan. 1987.The Mordern Printed Chinese 
Distinguishing Word System, Journal of Chinese 
information processing,l . 1 (2)?44-52. 
M.F.Porter. 1980.An algorithm for suffix stripping?, 
Program ,14(3)?130?137. 
Milat etc. 2003.Contemporary Kazakh language, 
Xinjiang People's Publishing House. 
R. O.Duda, P. E. Hart. 1973. Pattern Classification and 
Scene Analysis,John Wiley and Sons, New 
York,10-43. 
Shen Da-yang,Huang Chang-ning,Sun Moa-song, 
1997. The approaches of Information integration 
and bestpath seaching inCWASS, Journal of 
Chinese information processing, l . 11 (2??34-47. 
 U.Nasun, 1997 .The automatic segmentation system 
of Mongolian roots, stems, word, Journal of  Inner 
Mongolia University ,NO2?53-57.
YuShi-Wen,2003.TheGrammatical Knowledge-base 
of Contemporary Chinese-A Complete 
Specification, Tsinghua University Press. 
Zhang ding-jin. 2004.Modern Kazakh language 
practicality grammar?The central University for 
Nationalities Publishing House. 
Yusup Abaidula ? Rezwangul, Abdiryim Sali. 
2005.The Research and Development of Computer 
Aided Contemporary Uighur Language Tagging 
System. Journal of Chinese Language and 
Computing.  
