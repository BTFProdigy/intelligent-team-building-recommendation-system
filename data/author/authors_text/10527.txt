Coling 2008: Companion volume ? Posters and Demonstrations, pages 67?70
Manchester, August 2008
Modelling Multilinguality in Ontologies 
Elena Montiel-Ponsoda, Guadalupe Aguado de Cea, 
Asunci?n G?mez-P?rez 
Ontology Engineering Group 
Universidad Polit?cnica de Madrid 
emontiel@delicias.dia.fi.upm.es, 
{lupe,asun}@fi.upm.es 
Wim Peters 
Sheffield Natural Language 
Processing Group 
University of Sheffield 
w.peters@dcs.shef.ac.uk 
Abstract 
Multilinguality in ontologies has become 
an impending need for institutions 
worldwide with valuable linguistic re-
sources in different natural languages. 
Since most ontologies are developed in 
one language, obtaining multilingual on-
tologies implies to localize or adapt them 
to a concrete language and culture com-
munity. As the adaptation of the ontology 
conceptualization demands considerable 
efforts, we propose to modify the ontol-
ogy terminological layer, and provide a 
model called Linguistic Information Re-
pository (LIR) that associated to the on-
tology meta-model allows terminological 
layer localization.  
1 Introduction 
Multilinguality in ontologies is nowadays de-
manded by institutions worldwide with a huge 
number of resources in different languages. One 
of these institutions is the FAO 1 . Within the 
NeOn project2, the FAO is currently leading a 
case study on fishery stocks in order to improve 
the interoperability of its information systems. 
The FAO, as an international organization with 
five official languages -English, French, Spanish, 
Arabic and Chinese- deals with heterogeneous 
and multilingual linguistic resources with differ-
ent granularity levels. This scenario is an illustra-
tive example of the need for semantically orga-
nizing great amounts of multilingual data. When 
providing ontologies with multilingual data, one 
of the activities identified in the NeOn ontology 
                                                 
? 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported 
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved. 
1 http://www.fao.org/ 
2 http://www.neon-project.org/ 
network development process is the Ontology 
Localization Activity, that consists in adapting 
an ontology to a concrete language and culture 
community, as defined in (Su?rez-Figueroa et al, 
2007). In particular, our aim is to obtain multi-
lingual ontologies by localizing its terminologi-
cal layer (terms or labels that name ontology 
classes), rather than modifying its conceptualiza-
tion. Thus, we propose to link ontologies with a 
linguistic model, called LIR, whose main feature 
is that it is holistic in the sense that it (1) pro-
vides a complete and complementary amount of 
linguistic data that allows localization of ontol-
ogy concepts to a specific linguistic and cultural 
universe, and, (2) provides a unified access to 
aggregated multilingual data. The model we pre-
sent in this paper is an enhanced version of the 
one introduced in (Peters et al, 2007). 
2 Related work 
The most widespread modality for introducing 
multilingual data in ontology meta-models con-
sists in using some ontology properties 
(rdfs:label and rdfs:comment3)that define 
labels and descriptions in natural language of 
ontology classes. In this system, information is 
embedded in the ontology. In a similar way, the 
Simple Knowledge Organization System 
(SKOS4) data model for semantically structuring 
thesauri, taxonomies, etc., permits the labelling 
of ontology classes with multilingual strings, and 
even the establishment of some relations between 
labels (preferred label against the alternative 
one). In any case, however, both modelling mo-
dalities restrict the amount of linguistic data that 
can be included in the ontology, and assume full 
synonym relations among the multilingual labels 
associated to one and the same concept.  
A further multilingual model is one adopted by 
the general purpose lexicon EuroWordNet 5 
                                                 
3 www.w3.org/TR/rdf-schema/ 
4 http://www.w3.org/2004/02/skos/specs 
5 http://www.illc.uva.nl/EuroWordNet/ 
67
(EWN). EWN consists of monolingual ontolo-
gies, each one reflecting the linguistic and cul-
tural specificities of a certain language, linked to 
each other through an interlingual set of common 
concepts that allows building equivalences 
among ontologies. Although concept equiva-
lences among localized ontologies are reliable 
and reflect cultural differences, the quantity of 
linguistic information is also limited to labels and 
definitions attached to concepts.  
Finally, we come to the upward trend in recent 
research for providing ontologies with linguistic 
data, which is the association of the ontology 
meta-model to a linguistic model keeping both 
separate. The model for representing and orga-
nizing the linguistic information can be a data 
base (as in GENOMA-KB6 or OncoTerm7), or an 
ontology (as in the case of LingInfo (Buitelaar et 
al., 2006) or LexOnto (Cimiano et al 2007)). 
The main advantage of this modeling modality is 
that it allows the inclusion of as much linguistic 
information as wished, as well as the possibility 
of establishing relations among linguistic ele-
ments. Thus, conceptual information is greatly 
enriched with linguistic data. Additionally, these 
systems are considered domain independent, and 
can be linked to any domain ontology.  
The differentiating aspect among the men-
tioned systems is determined by the kind of lin-
guistic classes that make up each model. De-
pending on the linguistic needs of the end user, 
some models will be more suitable than others. 
LingInfo or LexOnto can offer not only multilin-
gual strings to classes and properties of the on-
tology, but also a deeper morphosyntactic de-
composition of linguistic elements, in the case of 
LingInfo, or a greater focus on syntactic struc-
tures by means of subcategorization frames, in 
LexOnto. Our LIR model, however, is more in 
the line of GENOMA-KB or OncoTerm, in the 
sense that they follow localization or transla-
tional approaches. The main objective of the LIR 
is to localize a certain ontology category to the 
linguistic and cultural universe of a certain natu-
ral language and to capture translation specifici-
ties among languages. Morphosyntactic informa-
tion is left in the background, although interop-
erability with ISO standards for representing that 
sort of information is foreseen. Contrary to GE-
NOMA-KB or OncoTerm, the LIR is represented 
as an ontology and will be provided with the 
necessary infrastructure to access external re-
                                                 
6 http://genoma.iula.upf.edu:8080/genoma 
7 http://www.ugr.es/~oncoterm/alpha-index.html 
sources for obtaining linguistic data and main-
taining links to supplier resources (cf. 5). 
2.1 Interoperability with existing standards 
Lexical knowledge is expressed in various ways 
in terminological and linguistic resources. There 
is a wealth of proposals for enhancing the inter-
operability of lexical knowledge by encoding it 
following standard models. As the most impor-
tant initiatives we take into account two ISO (In-
ternational Organization for Standardization 8 ) 
standards: The Terminological Markup Frame-
work (TMF9) (and the associated TermBase eX-
change format; TBX10), which captures the un-
derlying structure and representation of comput-
erized terminologies, and the Lexical Markup 
Framework (LMF) (Francopoulo et al, 2006), an 
abstract meta-model that provides a common, 
standardized framework for the construction of 
computational lexicons.  
The LIR model adopts a number of data cate-
gories from these standards in order to guarantee 
interoperability with them. For instance, the no-
tion of lexical entry or lexeme, in itself a well 
known central linguistic notion of a unit of form 
and meaning, has been taken from LMF, whereas 
the attribute term type, which covers representa-
tional aspects such as full forms versus abbrevia-
tions,  has been taken from TMF.  
3 Linguistic Information Repository 
As shown in Figure 1, the linguistic information 
captured in the LIR is organized around the 
LexicalEntry class. A lexical entry is a unit of 
form and meaning in a certain language (Saloni 
et al, 1990). Therefore, it is associated to the 
classes Language, Lexicalization and 
Sense. A set of related lexicalizations or term 
variants shares the same meaning within the spe-
cific context of a certain cultural and linguistic 
universe. E.g., Food and Agriculture Organiza-
tion and FAO would be two lexicalizations 
linked to the same sense. Thanks to the expres-
siveness of the hasVariant relation, it is possi-
ble to say that the one is acronym of the other.  
The Language class at the LexicalEntry 
level allows launching searches in which just 
those lexical entries related to one natural lan-
guage are shown to the user, thus displaying the 
ontology in the selected language.  
                                                 
8 www.iso.org 
9 http://www.loria.fr/projets/TMF/ 
10 http://www.lisa.org/standards/tbx/ 
68
Sense is considered a language-specific unit 
of intensional lexical semantic description 
(ibidem), which comes to fruition through the 
Definition class expressed in natural lan-
guage. Therefore, Sense is an empty class real-
ized by means of the Definition. By keeping 
senses in the linguistic model independent from 
ontology concepts, we allow capturing cultural 
specificities that may slightly differ from the 
concept expressed in the ontology. Definition 
has a pointer to the linguistic resource it has been 
obtained from. In this way reliability and author-
ity of definitions are guaranteed.  
Then, Lexicalization is related to its 
Source or provenance, to a Note class and to a 
UsageContext class. The Source class aims 
again at being a pointer to the resource where the 
information has been extracted from. Note is 
here linked to Lexicalization, but it could be 
linked to any other class in the model. It allows 
the inclusion of supplemental information; e.g., 
usage specificities of a certain lexicalization 
within its language system. By linking Note to 
the Sense or Definition classes we could 
make explicit possible differences among senses 
in different languages. The UsageContext class 
provides information about the behaviour of a 
certain lexicalization within the language system 
it belongs to. Finally, lexical semantic equiva-
lences are established among lexical entries 
within the same language (hasSynonym or 
hasAntonym), or across languages (hasTrans-
lation). Note that we use the latter label to es-
tablish equivalences between lexicalizations in 
different languages, although it is assumed that 
words identified as translation equivalents are 
rarely identical in sense. As Hirst (2004) stated, 
more usually they are merely cross-lingual near-
synonyms, but this approach is adopted for the 
practical reason of providing multilinguality. 
The LIR is linked to the OntologyElement 
class of the OWL meta-model permitting in this 
way the association of multilingual information 
to any element of the ontology. Finally, it is left 
to say that the rationale underlying LIR is not to 
design a lexicon for different natural languages 
and then establish links to ontology concepts, but 
to associate multilingual linguistic knowledge to 
the conceptual knowledge represented by the 
ontology. What the LIR does is to associate word 
senses ?as defined by Hirst (2004)- in different 
languages to ontology concepts, although word 
senses and concepts can not be said to overlap 
since they are tightly related to the particular vi-
sion of a language and its culture, whereas ontol-
ogy concepts try to capture objects of the real 
world, and are defined and organized according 
to expert criteria agreed by consensus.  
4 Application of the LIR in NeOn 
The LIR has been developed within the NeOn 
project and is currently being implemented. In 
order to check its suitability, it was evaluated 
against the linguistic requirements of the use 
cases participating in this project (see Note 2): 
the Spanish pharmaceutical industry, and the 
Fisheries Stock system of the FAO. Both use 
cases are working in the development of ontolo-
gies for organizing the information they have in 
several languages. As a consequence, one of the 
requirements for the NeOn architecture was to 
support multilingual ontologies.  
As already introduced, the LIR not only pro-
vides multilingual information to any ontology 
element, but it also enables unified access to ag-
gregated multilingual data, previously scattered 
in heterogeneous resources. In that way, it inte-
grates the necessary linguistic information from 
use case resources and offers a complete and 
complementary amount of linguistic data.  
Regarding the FAO use case, the LIR was 
evaluated against the recent developed model for 
the AGROVOC thesaurus, the AGROVOC Con-
cept Server (Liang et al, 2008). This is a con-
cept-based multilingual repository, which, com-
pared to a traditional Knowledge Organization 
System, allows the representation of more se-
mantics such as specific relationships between 
concepts and relationships between multilingual 
lexicalizations. It serves as a pool of agricultural 
concepts and is a starting point in the develop-
ment of domain ontologies. The adequacy of the 
LIR model was positively evaluated against the 
linguistic requirements of the Concept Server in 
terms of flexible association of language specific 
lexicalizations with agricultural domain con-
cepts, and compatibility with TBX.  
5 Conclusions and future research 
In this contribution we have raised the impending 
need of international organizations dealing with 
multilingual information for representing multi-
linguality in ontologies. In order to obtain multi-
lingual ontologies, we have proposed the associa-
tion of the ontology meta-model to a linguistic   
69
 
Figure 1. LIR model. 
model, the LIR. The LIR has proven to be a ho-
listic linguistic information repository with the 
following benefits:  
? Provision of a complete and complementary 
set of linguistic elements in each language for 
localizing ontology elements 
? Homogeneous access to linguistic information 
distributed in heterogeneous resources with dif-
ferent granularity 
? Establishment of relations between linguistic 
elements, and solution to conceptualization mis-
matches among different cultures 
Besides, within NeOn there is a current research 
regarding the integration of the LIR with the La-
belTranslator tool (Espinoza et al, 2007), that 
allows: (1) quick access to external multilingual 
resources, (2) an automatic translation of the on-
tology terminological layer, (3) an automatic 
storage of the resulting multilingual information 
in the LIR, and (4) convenient editing possibili-
ties for users in distributed environments. 
Acknowlegements. This research was supported 
by the NeOn project (FP6-027595)  
References 
Buitelaar, P., M. Sintek, M. Kiesel. 2006. A Multi-
lingual/Multimedia Lexicon Model for Ontologies. 
In Proc. of  ESWC, Budva, Montenegro.  
Cimiano, P., P. Haase, M. Herold, M. Mantel, P. Bui-
telaar. 2007. LexOnto: A Model for Ontology Lexi-
cons for Ontology-based NLP. Proc. of OntoLex.  
Espinoza, M., A. G?mez-P?rez, and E. Mena. 2008. 
Enriching an Ontology with Multilingual Informa-
tion. Proc. of ESWC, Tenerife, Spain.  
Francopoulo, G, M. George, N. Calzolari, M. 
Monachini, N. Bel, M. Pet, C. Soria. 2006. Lexical 
Markup Framework (LMF). Proc. of LREC. 
Hirst, G. 2004. Ontology and the Lexicon. In S. Staab, 
and R. Studer (eds.) Handbook on Ontologies and 
Information Systems. Springer, Berlin.  
Liang, A.C., B. Lauser, M. Sini, J. Keizer, S. Katz. 
2008. From AGROVOC to the Agricultural Ontol-
ogy Service/Concept Server. An OWL model for 
managing ontologies in the agricultural domain. In 
Proc. of the ?OWL: Experiences and Directions? 
Workshop, Mancherter, U.K.  
Peters, W., E. Montiel-Ponsoda, G. Aguado de Cea. 
2007.Localizing Ontologies in OWL.Proc. OntoLex 
Saloni, Z., S. Szpakowicz, M. Swidzinski. 1990. The 
Design of a Universal Basic Dictionary of Con-
temporary Polish. International Journal of Lexi-
cography, vol. 3 no1. Oxford University Press.  
Su?rez-Figueroa, M.C. (coord.) 2007. NeOn Devel-
opment Process and Ontology Life Cycle. NeOn 
Project D5.3.1 
70
Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 116?125,
ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational Linguistics
Combining statistical and semantic approaches to the translation of
ontologies and taxonomies
John McCrae
AG Semantic Computing
Universita?t Bielefeld
Bielefeld, Germany
jmccrae@cit-ec.uni-bielefeld.de
Mauricio Espinoza
Universidad de Cuenca
Cuenca, Ecuador
mauricio.espinoza@ucuenca.edu.ec
Elena Montiel-Ponsoda, Guadalupe Aguado-de-Cea
Ontology Engineering Group
Universidad Polite?cnica de Madrid
Madrid, Spain
{emontiel, lupe}@fi.upm.es
Philipp Cimiano
AG Semantic Computing
Universita?t Bielefeld
Bielefeld, Germany
cimiano@cit-ec.uni-bielefeld.de
Abstract
Ontologies and taxonomies are widely used to
organize concepts providing the basis for ac-
tivities such as indexing, and as background
knowledge for NLP tasks. As such, trans-
lation of these resources would prove use-
ful to adapt these systems to new languages.
However, we show that the nature of these
resources is significantly different from the
?free-text? paradigm used to train most sta-
tistical machine translation systems. In par-
ticular, we see significant differences in the
linguistic nature of these resources and such
resources have rich additional semantics. We
demonstrate that as a result of these linguistic
differences, standard SMT methods, in partic-
ular evaluation metrics, can produce poor per-
formance. We then look to the task of leverag-
ing these semantics for translation, which we
approach in three ways: by adapting the trans-
lation system to the domain of the resource;
by examining if semantics can help to predict
the syntactic structure used in translation; and
by evaluating if we can use existing translated
taxonomies to disambiguate translations. We
present some early results from these experi-
ments, which shed light on the degree of suc-
cess we may have with each approach.
1 Introduction
Taxonomies and ontologies are data structures that
organise conceptual information by establishing re-
lations among concepts, hierarchical and partitive
relations being the most important ones. Nowadays,
ontologies have a wide range of uses in many do-
mains, for example, finance (International Account-
ing Standards Board, 2007), bio-medicine (Col-
lier et al, 2008) (Ashburner et al, 2000) and li-
braries (Mischo, 1982). These resources normally
attach labels in natural language to the concepts and
relations that define their structure, and these la-
bels can be used for a number of purposes, such
as providing user interface localization (McCrae et
al., 2010), multilingual data access (Declerck et al,
2010), information extraction (Mu?ller et al, 2004)
and natural language generation (Bontcheva, 2005).
It seems natural that for applications that use such
ontologies and taxonomies, translation of the natu-
ral language descriptions associated with them is re-
quired in order to adapt these methods to new lan-
guages. Currently, there has been some work on
this in the context of ontology localisation, such
as Espinoza et al (2008) and (2009), Cimiano et
al. (2010), Fu et al (2010) and Navigli and Pen-
zetto (2010). However, this work has focused on the
case in which exact or partial translations are found
in other similar resources such as bilingual lexica.
Instead, in this paper we look at how we may gain an
adequate translation using statistical machine trans-
lation approaches that also utilise the semantic in-
formation beyond the label or term describing the
concept, that is relations among the concepts in the
ontology, as well as the attributes or properties that
describe concepts, as will be explained in more de-
tail in section 2.
Current work in machine translation has shown
that word sense disambiguation can play an im-
portant role by using the surrounding words as
context to disambiguate terms (Carpuat and Wu,
2007) (Apidianaki, 2009). Such techniques have
116
been extrapolated to the translation of taxonomies
and ontologies, in which the ?context? of a taxon-
omy or ontology label corresponds to the ontology
structure that surrounds the label in question. This
structure, which is made up of the lexical informa-
tion provided by labels and the semantic informa-
tion provided by the ontology structure, defines the
sense of the concept and can be exploited in the dis-
ambiguation process (Espinoza et al, 2008).
2 Definition of Taxonomy and Ontology
Translation
2.1 Formal Definition
We define a taxonomy as a set of concepts, C, with
equivalence (synonymy) links, S, subsumption (hy-
pernymy) links, H , and a labelling function l that
maps each concept to a single label from a language
??. Formally we define a taxonomy, T , as a set of
tuples (C, S,H, l) such that S ? P(C ? C) and
H ? P(C ? C) and l is a function in C ? ??. We
also require that S is a transitive, symmetric and re-
flexive relation, and H is transitive. While we note
here that this abstraction does not come close to cap-
turing the full expressive power of many ontologies
(or even taxonomies), it is sufficient for this paper to
focus on the use of only equivalence and subsump-
tion relationships for translation.
2.2 Analysis of ontology labels
Another important issue to note here is that the
kind of language used within ontologies and tax-
onomies is significantly different from that found
within free text. In particular, we observe that the
terms used to designate concepts are frequently just
noun phrases and are significantly shorter than a
usual sentence. In the case of the relations between
concepts (dubbed object properties) and attributes
of concepts (data type properties), these are occa-
sionally labelled by means of verbal phrases. We
demonstrate this by looking at three widely used on-
tologies/taxonomies.
1. Friend of a friend: The Friend of a Friend
(FOAF) ontology is used to describe social
networks on the Semantic Web (Brickley and
Miller, 2010). It is a small taxonomy with very
short labels. Labels for concepts are compound
words made up of up to three words.
2. Gene Ontology: The Gene Ontology (Ash-
burner et al, 2000) is a very large database of
terminology related to genetics. We note that
while some of the terms are technical and do
not require translation, e.g., ESCRT-I, the ma-
jority do, e.g., cytokinesis by cell plate forma-
tion.
3. IFRS 2009: The IFRS taxonomy (International
Accounting Standards Board, 2007) is used for
providing electronic financial reports for audit-
ing. The terms contained within this taxon-
omy are frequently long and are entirely noun
phrases.
We applied tokenization and manual phrase anal-
ysis to the labels in these resources and the results
are summarized in table 1. As can be observed,
the variety of types of labels we may come across
when linguistically analysing and translating ontol-
ogy and taxonomy labels is quite large. We can
identify the two following properties that may influ-
ence the translation process of taxonomy and ontol-
ogy labels. Firstly, the length of terms ranges from
single words to highly complex compound phrases,
but is still generally shorter than a sentence. Sec-
ondly, terms are frequently about highly specialized
domains of knowledge.
For properties in the ontology we also identify
terms which consist of:
? Noun phrases identifying concepts.
? Verbal phrases that are only made up of the
verb with an optional preposition.
? Complex verbal phrases that include the predi-
cate.
? Noun phrases that indicate possession of a par-
ticular characteristic (e.g., interest meaning X
has an interest in Y).
3 Creation of a corpus for taxonomy and
ontology translation
For the purpose of training systems to work on the
translation of ontologies and taxonomies, it is nec-
essary to create a corpus that has similar linguistic
structure to that found in ontologies and taxonomies.
We used the titles of Wikipedia1 for the following
1http://www.wikipedia.org
117
Size Mean tokens per label Noun Phrases Verb Phrases
FOAF 79 1.57 94.9% 8.9%
Gene Ontology 33795 4.45 100.0% 0.0%
IFRS 2009 2757 8.39 100.0% 0.0%
Table 1: Lexical Analysis of labels
Link Direct Fragment Broken
German 487372 484314 1735 1323
Spanish 347953 346941 330 682
Table 2: Number of translation for pages in Wikipedia
reasons:
? Links to articles in different languages can be
viewed as translations of the page titles.
? The titles of articles have similar properties to
the ontologies labels mentioned above with an
average of 2.46 tokens.
? There are a very large number of labels. In fact
we found that there were 5,941,8902 articles of
which 3,515,640 were content pages (i.e., not
special pages such as category pages)
We included non-content pages (in particular, cat-
egory pages) in the corpus as they were generally
useful for translation, especially the titles of cat-
egory pages. In table 2 we see the number of
translations, which we further grouped according to
whether they actually corresponded to pages in the
other languages, as it is also possible that the trans-
lations links pointed to subsections of an article or
to missing pages.
Wikipedia also includes redirect links that allow
for alternative titles to be mapped to a given con-
cept. These can be useful as they contain synonyms,
but also introduce a lot more noise into the corpus
as they also include misspelled and foreign terms.
To evaluate the effectiveness of including these data
for creating a machine translation corpus, we took
a random sample of 100 pages which at least one
page redirects to (there are 1,244,647 of these pages
in total). We found that these pages had a total
of 242 extra titles from the redirect page of which
2All statistics are based on the dump on 17th March 2011
204 (84.3%) where true synonyms, 19 (7.9%) were
misspellings, 8 (3.3%) were foreign names for con-
cepts (e.g., the French name for ?Zeebrugge?), and
11 (4.5%) were unrelated. As such, we conclude
that these extra titles were useful for constructing the
corpus, increasing the size of the corpus by approx-
imately 50% across all languages. There are sev-
eral advantages to deriving a corpus fromWikipedia,
for example it is possible to provide some hierarchi-
cal links by the use of the category that a page be-
longs to, such as has been performed by the DBpedia
project (Auer et al, 2007).
4 Evaluation metrics for taxonomy and
ontology translation
Given the linguistic differences in taxonomy and
ontology labels, it seems necessary to investigate
the effectiveness of various metrics for the evalua-
tion of translation quality. There are a number of
metrics that are widely used for evaluating trans-
lation. Here we will focus on some of the most
widely used, namely BLEU (Papineni et al, 2002),
NIST (Doddington, 2002), METEOR (Banerjee and
Lavie, 2005) and WER (McCowan et al, 2004).
However, it is not clear which of these methods cor-
relate best with human evaluation, particularly for
the ontologies with short labels. To evaluate this
we collected a mixture of ontologies with short la-
bels on the topics of human diseases, agriculture,
geometry and project management, producing 437
labels. These were translated with web transla-
tion services from English to Spanish, in particu-
lar Google Translate3, Yahoo! BabelFish4 and SDL
FreeTranslation5. Having obtained translations for
each label in the ontology we calculated the evalua-
tion scores using the four metrics mentioned above.
We found that the source ontologies had an average
3http://translate.google.com
4http://babelfish.yahoo.com
5http://www.freetranslation.com
118
BLEU NIST METEOR WER
Evaluator 1,
Fluency 0.108 0.036 0.134 0.122
Evaluator 1,
Adequacy 0.209 0.214 0.303 0.169
Evaluator 2,
Fluency 0.183 0.062 0.266 0.164
Evaluator 2,
Adequacy 0.177 0.111 0.251 0.194
Evaluator 3,
Fluency 0.151 0.067 0.210 0.204
Evaluator 3,
Adequacy 0.143 0.129 0.221 0.120
Table 3: Correlation between manual evaluation results
and automatic evaluation scores
label length of 2.45 tokens and the translations gen-
erated had an average length of 2.16 tokens. We then
created a data set by mixing the translations from the
web translation services with a number of transla-
tions from the source ontologies, to act as a control.
We then gave these translations to 3 evaluators, who
scored them for adequacy and fluency as described
in Koehn (2010). Finally, we calculated the Pearson
correlation coefficient between the automatic scores
and the manual scores obtained. These are presented
in table 3 and figure 1.
As we can see from these results, one metric,
namely METEOR, seems to perform best in evaluat-
ing the quality of the translations. In fact this is not
surprising as there is a clear mathematical deficiency
that both NIST and BLEU have for evaluating trans-
lations for very short labels like the ones we have
here. To illustrate this, we recall the formulation of
BLEU as given in (Papineni et al, 2002):
BLEU = BP ? exp(
N
?
n=1
wn log pn)
WhereBP is a brevity penalty, wn a weight value
and pn represents the n-gram precision, indicating
how many times a particular n-gram in the source
text is found among the target translations. We note,
however, that for very short labels it is highly likely
that pn will be zero. This creates a significant issue,
as from the equation above, if any of the values of pn
are zero, the overall score, BLEU, will also be zero.
Figure 1: Correlation between manual evaluation results
and automatic evaluation scores
For the results above we chose N = 2, and cor-
rected for single-word labels. However, the scores
were still significantly worse, similar problems af-
fect the NIST metric. As such, for the taxonomy
and ontology translation task we do not recommend
using BLEU or NIST as an evaluation metric. We
note that METEOR is a more sophisticated method
than WER and, as expected, performs better.
5 Approaches for taxonomy and ontology
translation
5.1 Domain adaptation
It is generally the case that many ontologies and tax-
onomies focus on only a very specific domain, thus
it seems likely that adaptation of translation systems
by use of an in-domain corpus may improve trans-
lation quality. This is particularly valid in the case
of ontologies which frequently contain ?subject? an-
notations6 for not only the whole data structure but
often individual elements. To demonstrate this we
tried to translate the IFRS 2009 taxonomy using
the Moses Decoder (Koehn et al, 2007), which we
trained on the EuroParl corpus (Koehn, 2005), trans-
lating from Spanish to English. As the IFRS taxon-
omy is on the topic of finance and accounting, we
6For example from the Dublin Core vocabulary: see http:
//dublincore.org/
119
Baseline With domain adaptation
WER? 0.135 0.138
METEOR 0.324 0.335
NIST 1.229 1.278
BLEU 0.090 0.116
Table 4: Results of domain-adapted translation. ?Lower
WER scores are better
chose all terms from our Wikipedia corpus which
belonged to categories containing the words: ?fi-
nance?, ?financial?, ?accounting?, ?accountancy?,
?bank?, ?banking?, ?economy?, ?economic?, ?in-
vestment?, ?insurance?and ?actuarial? and as such
we had a domain corpus of approximately 5000
terms. We then proceeded to recompute the phrase
table using the methodology as described in Wu et
al, (2008), computing the probabilities as follows for
some weighting factor 0 < ? < 1:
p(e|f) = ?p1(e|f) + (1? ?)pd(e|f)
Where p1 is the EuroParl trained probability and pd
the scores on our domain subset. The evaluation for
these metrics is given in table 4. As can be seen
with the exception of the WER metric, the domain
adaption does seem to help in translation, which cor-
roborates the results obtained by other authors.
5.2 Syntactic Analysis
One key question to figure out is: if we have a se-
mantic model can this be used to predict the syntac-
tic structure of the translation to a significant degree?
As an example of this we consider the taxonomic
term ?statement?, which is translated by Google
Translate7 to German as ?Erkla?rung?, whereas the
term ?annual statement? is translated as ?Jahresab-
schluss?. However, if the taxonomy contains a sub-
sumption (hypernymy) relationship between these
terms we can deduce that the translation ?Erkla?rung?
is not correct and the translation ?Abschluss? should
be preferred. We chose to evaluate this idea on the
IFRS taxonomy as the labels it contains are much
longer and more structured than some of the other
resources. Furthermore, in this taxonomy the origi-
nal English labels have been translated into ten lan-
guages, so that it is already a multilingual resource
7Translations results obtained 8th March 2011
P (syn|s) P (syn|p) P (syn|n)
English 0.147 0.012 0.001
Dutch 0.137 0.011 0.001
German 0.125 0.007 0.001
Spanish 0.126 0.012 0.001
Table 5: Probability of syntactic relationship given a se-
mantic relationship in IFRS labels
that can be used as gold standard. Regarding the
syntax of labels, it is often the case that one term is
derived from another by addition of a complemen-
tary phrase. For example the following terms all ex-
ist in the taxonomy:
1. Minimum finance lease payments receivable
2. Minimum finance lease payments receivable, at
present value
3. Minimum finance lease payments receivable, at
present value, end of period not later than one
year
4. Minimum finance lease payments receivable, at
present value, end of period later than one year
and not later than five years
A high-quality translation of these terms would
ideally preserve this same syntactic structure in the
target language.We attempt to answer how useful
ontological structure is by trying to deduce if there
is a semantic relationship between terms then is it
more likely that there is a syntactic relationship. We
started by simplifying the idea of syntactic depen-
dency to the following: we say that two terms are
syntactically related if one label is a sub-string of
another, so that in the example above the first label
is syntactically related to the other three and the sec-
ond is related to the last two. For English, we found
that there were 3744 syntactically related terms ac-
cording to this criteria, corresponding to 0.1% of all
label pairs within the taxonomy, for all languages.
For ontology structure we used the number of rela-
tions indicated in the taxonomy, of which there are
1070 indicating a subsumption relationship and 987
indicating a partitive relationship8. This means that
8IFRS includes links for calculating certain values, i.e., that
?Total Assets? is a sum of values such as ?Total Assets in Prop-
120
e ? f P (synf |syne, s) P (synf |syne, p) P (synf |syne, n)
English ? Spanish 0.813 ? 0.059 0.750 ? 0.205 0.835 ? 0.013
English ? German 0.835 ? 0.062 0.417 ? 0.212 0.790 ? 0.013
English ? Dutch 0.875 ? 0.063 0.833 ? 0.226 0.898 ? 0.013
Average 0.841 ? 0.035 0.665 ? 0.101 0.841 ? 0.008
Table 6: Probability of cross-lingual preservation of syntax given semantic relationship in IFRS. Note here s refers to
the source language and t to the target language. Error values are 95% of standard deviation.
0.08% of label pairs were semantically related. We
then examined if the semantic relation could predict
whether there was a syntactic relationship between
the terms in a single language. We define Ns as the
number of label pairs with a subsumption relation-
ship and similarly define Np, Nn and Nsyn for parti-
tive, semantically unrelated and syntactically related
pairs. We also define Ns?syn, Np?syn and Nn?syn
for label pairs with both subsumption, partitive or no
semantic relation and a syntactic relationships. As
such we define the following values
P (syn|s) = Ns?syn
Ns
Similarly we define P (syn|p) and P (syn|n) and
present these values in table 5 for four languages.
As we can see from these results, it seems that
both subsumption and partitive relationships are
strongly indicative of syntactic relationships as we
might expect. The second question is: is it more
likely that we see a syntactic dependency in trans-
lation if we have a semantic relationship, i.e., is the
syntax more likely to be preserved if these terms are
semantically related. We define Nsyne as the value
of Nsyn for a language e, e.g., Nsynen is the num-
ber of syntactically related English label pairs in the
taxonomy. As each label has exactly one transla-
tion we can also define Nsyne?synf?s as the number
of concepts whose labels are syntactically related in
both language e and f and are semantically related
by a subsumption relationship; similarly we define
Nsyne?synf?p and Nsyne?synf?n. Hence we can de-
fine
P (synf |syne, s) =
Nsynf?syne?s
Nsyne?s
erty, Plant and Equipment?, we view such a relationship as se-
mantically indicative that one term is part of another, i.e., as
partitive or meronymic
And similarly define P (synf |syne, p) and
P (synf |syne, n). We calculated these values on
the IFRS taxonomies, the results of which are
represented in table 6.
The partitive data was very sparse, due to the fact
that only 15 concepts in the source taxonomy had a
partitive relationship and were syntactically related,
so we cannot draw any strong conclusions from it.
For the subsumption relationship we have a clearer
result and in fact averaged across all language pairs
we found that the likelihood of the syntax being pre-
served in the translation was nearly exactly the same
for semantically related and semantically unrelated
concepts. From this result we can conclude that
the probability of syntax given either subsumptive or
partitive relationship is not very large, at least from
the reduced syntactic model we used here. While
our model reduces syntax to n-gram overlap, we
believe that if there was a stronger correlation us-
ing a more sophisticated syntactic model, we would
still see some noticable effect here as we did mono-
lingually. We also note that we applied this to only
one taxonomy and it is possible that the result may
be different in a different resource. Furthermore,
we note there is a strong relationship between se-
mantics and syntax in a mono-lingual context and
as such adaption of a language model to incorporate
this bias may improve the translation of ontologies
and taxonomies.
5.3 Comparison of ontology structure
Our third intuition in approaching ontology trans-
lation is that the comparison of ontology or taxon-
omy structures containing source and target labels
may help in the disambiguation process of transla-
tion candidates. A prerequisite in this sense is the
availability of equivalent (or similar) ontology struc-
tures to be compared.
121
Figure 2: Two approaches to translate ontology labels.
From a technical point of view, we consider the
translation task as a word sense disambiguation task.
We identify two methods for comparing ontology
structures, which are illustrated in Figure 2.
The first method relies on a multilingual resource,
i.e., a multilingual ontology or taxonomy. The on-
tology represented on the left-hand side of the fig-
ure consists of several monolingual conceptualiza-
tions related to each other by means of an inter-
lingual index, as is the case in the EuroWordNet lex-
icon (Vossen, 1999). For example, if the original
label is chair for seat in English, several translations
for it are obtained in Spanish such as: silla (for seat),
ca?tedra (for university position), presidente (for per-
son leading a meeting). Each of these correspond
to a sense in the English WordNet, and hence each
translation selects a hierachical structure with En-
glish labels. The next step is to compare the input
structure of the original ontology containing chair
against the three different structures in English rep-
resenting the several senses of chair and obtain the
corresponding label in Spanish.
The second method relies on a monolingual re-
source, i.e., on monolingual ontologies in the tar-
get language, which means that we need to compare
structures documented with labels in different lan-
guages. As such we obtain a separate translated on-
tologies for each combination of label translations
suggested by the baseline system. Selecting the cor-
rect translations is then clearly a hard optimization
problem.
For the time being, we have only experimented
with the first approach using EuroWordNet. Sev-
eral solutions have been proposed in the context of
ontology matching in a monolingual scenario (see
(Shvaiko and Euzenat, 2005) or (Giunchiglia et al,
2006)). The ranking method we use to compare
structures relies on an equivalence probability mea-
sure between two candidate structures, as proposed
in (Trillo et al, 2007).
We assume that we have a taxonomy or ontology
entity o1 and we wish to deduce if it is similar to
another taxonomy or ontology entity o2 from a ref-
erence taxonomy or ontology (i.e., EuroWordNet) in
the same language. We shall make a simplifying as-
sumption that each ontology entity is associated with
a unique label, e.g., lo1 . As such we wish to deduce
if o1 represents the same concept as o2 and hence if
lo2 is a translation for lo1 . Our model relies on the
Vector Space Model (Raghavan and Wong, 1986)
to calculate the similarity between different labels,
which essentially involves calculating a vector from
the bag of words contained within each labels and
then calculating the cosine similarity between these
vectors. We shall denotes this as v(o1, o2). We then
use four main features in the calculation of the sim-
ilarity
? The VSM-similarity between the labels of enti-
ties, o1, o2.
? The VSM-similarity between any glosses (de-
scriptions) that may exist in the source or refer-
ence taxonomy/ontology.
? The hypernym similarity given to a fixed depth
d, given that set of hypernyms of an entity oi is
given as a set
hO(oi) = {h|(oi, h) ? H}
Then we calculate the similarity for d > 1 re-
cursively as
122
sh(o1, o2, d) =
?
h1?hO(o1),h2?hO(o2) ?(h1, h2, d)
|hO(o1)||hO(o2)|
?(h1, h2, d) = ?v(h1, h2)+(1??)sh(h1, h2, d?1)
And for d = 1 it is given as
sh(o1, o2, 1) =
?
h1?hO(o1),h2?hO(o2) v(h1, h2)
|hO(o1)||hO(o2)|
? The hyponym similarity, calculated as the hy-
pernym similarity but using the hyponym set
given by
HO(oi) = {h|(h, oi) ? H}
We then incorporate these factors into a vector x
and calculate the similarity of two entities as
s(o1, o2) = wTx
Where w is a weight vector of non-negative reals
and satisfies ||w|| = 1, which we set manually.
We then applied this to the FOAF ontol-
ogy (Brickley and Miller, 2010), which was manu-
ally translated to give us a reference translation. Af-
ter that, we collected a set of candidate translations
obtained by using the web translation resources ref-
erenced in section 3, along with additional candi-
dates found in our multilingual resource. Finally,
we used EuroWordNet (Vossen, 1999) as the refer-
ence taxonomy and ranked the translations accord-
ing to the score given by the metric above. In table
7, we present the results where our system selected
the candidate translation with the highest similarity
to our source ontology entity. In the case that we
could not find a reference translation we split the la-
bel into tokens and found the translation by select-
ing the best token. We compared these results to a
baseline method that selected one of the reference
translations at random.
These results are in all cases significantly stronger
than the baseline results showing that by compar-
ing the structure of ontology elements it is possible
to significantly improve the quality of translation.
These results are encouraging and we believe that
more research is needed in this sense. In particular,
we would like to investigate the benefits of perform-
ing a cross-lingual ontology alignment in which we
measure the semantic similarity of terms in different
languages.
Baseline Best Translation
WER? 0.725 0.617
METEOR 0.089 0.157
NIST 0.070 0.139
BLEU 0.103 0.187
Table 7: Results of selecting translation by structural
comparison. ?Lower WER scores are better
6 Conclusion
In this paper we presented the problem of ontology
and taxonomy translation as a special case of ma-
chine translation that has certain extra characteris-
tics. Our examination of the problem showed that
the main two differences are the presence of struc-
tured semantics and shorter, hence more ambiguous,
labels. We demonstrated that as a result of this lin-
guistic nature, some machine translation metrics do
not perform as well as they do in free-text trans-
lations. We then presented the results of early in-
vestigations into how we may use the special fea-
tures of taxonomy and ontology translation to im-
prove quality of translation. The first of these was
domain adaptation, which in line with other authors
is useful for texts in a particular domain. We also in-
vestigated the possibility of using the link between
syntactic similarity and semantic similarity to help,
however although we find that mono-lingually there
was a strong correspondence between syntax and se-
mantics, this result did not seem to extend well to a
cross-lingual setting. As such we believe there may
only be slight benefits of using techniques, however
further investigation is needed. Finally, we looked at
using word sense disambiguation by comparing the
structure of the input ontology to that of an already
translated reference ontology. We found this method
to be very effective in choosing the best translations.
However it is dependent on the existence of a mul-
tilingual resource that already has such terms. As
such, we view the topic of taxonomy and ontology
translation as an interesting sub-problem of machine
translation and believe there is still much fruitful
work to be done to obtain a system that can cor-
rectly leverage the semantics present in these data
structures in a way that improves translation quality.
123
References
Marianna Apidianaki. 2009. Data-driven semantic anal-
ysis for multilingual WSD and lexical selection in
translation. In Proceedings of the 12th Conference of
the European Chapter of the Association for Compu-
tational Linguistics (EACL).
Michael Ashburner, Catherine Ball, Judith Blake, David
Botstein, Heather Butler, J. Michael Cherry, Allan
Davis, et al 2000. Gene ontology: tool for the uni-
fication of biology. The Gene Ontology Consortium.
Nature genetics, 25(1):25?29.
So?ren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives. 2007.
Dbpedia: A nucleus for a web of open data. The Se-
mantic Web, 4825:722?735.
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An automatic metric for MT evaluation with improved
correlation with human judgments. Intrinsic and Ex-
trinsic Evaluation Measures for Machine Translation
and/or Summarization, page 65.
Kalina Bontcheva. 2005. Generating tailored textual
summaries from ontologies. In The Semantic Web:
Research and Applications, pages 531?545. Springer.
Dan Brickley and Libby Miller, 2010. FOAF Vocabulary
Specification 0.98. Accessed 3 December 2010.
Marine Carpuat and Dekai Wu. 2007. Improving Sta-
tistical Machine Translation using Word Sense Disam-
biguation. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL 2007).
Philipp Cimiano, Elena Montiel-Ponsoda, Paul Buite-
laar, Mauricio Espinoza, and Asuncio?n Go?mez-Pe?rez.
2010. A note on ontology localization. Journal of Ap-
plied Ontology (JAO), 5:127?137.
Nigel Collier, Son Doan, Ai Kawazoe, Reiko Matsuda
Goodwin, Mike Conway, Yoshio Tateno, Quoc-Hung
Ngo, Dinh Dien, Asanee Kawtrakul, Koichi Takeuchi,
Mika Shigematsu, and Kiyosu Taniguchi. 2008. Bio-
Caster: detecting public health rumors with a Web-
based text mining system. Oxford Bioinformatics,
24(24):2940?2941.
Thierry Declerck, Hans-Ullrich Krieger, Susan Marie
Thomas, Paul Buitelaar, Sean O?Riain, Tobias Wun-
ner, Gilles Maguet, John McCrae, Dennis Spohr, and
Elena Montiel-Ponsoda. 2010. Ontology-based Mul-
tilingual Access to Financial Reports for Sharing Busi-
ness Knowledge across Europe. In Jo?zsef Roo?z and
Ja?nos Ivanyos, editors, Internal Financial Control As-
sessment Applying Multilingual Ontology Framework,
pages 67?76. HVG Press Kft.
George Doddington. 2002. Automatic evaluation of ma-
chine translation quality using n-gram co-occurrence
statistics. In Proceedings of the second interna-
tional conference on Human Language Technology
Research, pages 138?145. Morgan Kaufmann Publish-
ers Inc.
Mauricio Espinoza, Asuncio?n Go?mez-Pe?rez, and Ed-
uardo Mena. 2008. Enriching an Ontology with
Multilingual Information. In Proceedings of the 5th
Annual of the European Semantic Web Conference
(ESWC08), pages 333?347.
Mauricio Espinoza, Elena Montiel-Ponsoda, and
Asuncio?n Go?mez-Pe?rez. 2009. Ontology Local-
ization. In Proceedings of the 5th International
Conference on Knowledge Capture (KCAP09), pages
33?40.
Bo Fu, Rob Brennan, and Declan O?Sullivan. 2010.
Cross-Lingual Ontology Mapping and Its Use on the
Multilingual Semantic Web. In Proceedings of the
1st Workshop on the Multilingual Semantic Web, at
the 19th International World Wide Web Conference
(WWW 2010).
Fausto Giunchiglia, Pavel Shvaiko, and Mikalai Yatske-
vich. 2006. Discovering missing background knowl-
edge in ontology matching. In Proceeding of the 17th
European Conference on Artificial Intelligence, pages
382?386.
International Accounting Standards Board, 2007. Inter-
national Financial Reporting Standards 2007 (includ-
ing International Accounting Standards (IAS) and In-
terpretations as at 1 January 2007).
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al 2007. Moses: Open source toolkit for sta-
tistical machine translation. In Proceedings of the 45th
Annual Meeting of the ACL on Interactive Poster and
Demonstration Sessions, pages 177?180.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of the
Tenth Machine Translation Summit.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.
Iain McCowan, Darren Moore, John Dines, Daniel
Gatica-Perez, Mike Flynn, Pierre Wellner, and Herve?
Bourlard. 2004. On the use of information retrieval
measures for speech recognition evaluation. Technical
report, IDIAP.
John McCrae, Jesu?s Campana, and Philipp Cimiano.
2010. CLOVA: An Architecture for Cross-Language
Semantic Data Querying. In Proceedings of the First
Mutlilingual Semantic Web Workshop.
William Mischo. 1982. Library of Congress Subject
Headings. Cataloging & Classification Quarterly,
1(2):105?124.
124
Hans-Michael Mu?ller, Eimear E Kenny, and Paul W
Sternberg. 2004. Textpresso: An ontology-based in-
formation retrieval and extraction system for biologi-
cal literature. PLoS Biol, 2(11):e309.
Roberto Navigli and Simone Paolo Ponzetto. 2010. Ba-
belnet: Building a very large multilingual semantic
network. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics,
pages 216?225.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th annual meeting on association for computational
linguistics, pages 311?318. Association for Computa-
tional Linguistics.
V.Vijay Raghavan and S.K.M. Wong. 1986. A criti-
cal analysis of vector space model for information re-
trieval. Journal of the American Society for Informa-
tion Science, 37(5):279?287.
Pavel Shvaiko and Jerome Euzenat. 2005. A survey of
schema-based matching approaches. Journal on Data
Semantics IV, pages 146?171.
Fabian Suchanek, Gjergji Kasneci, and Gerhard Weikum.
2007. Yago: a core of semantic knowledge. In Pro-
ceedings of the 16th international conference on World
Wide Web, pages 697?706.
Raquel Trillo, Jorge Gracia, Mauricio Espinoza, and Ed-
uardo Mena. 2007. Discovering the semantics of user
keywords. Journal of Universal Computer Science,
13(12):1908?1935.
Piek Vossen. 1999. EuroWordNet a multilingual
database with lexical semantic networks. Computa-
tional Linguistics, 25(4).
Hua Wu, Haifeng Wang, and Chengqing Zong. 2008.
Domain adaptation for statistical machine translation
with domain dictionary and monolingual corpora. In
Proceedings of the 22nd International Conference
on Computational Linguistics-Volume 1, pages 993?
1000. Association for Computational Linguistics.
125
